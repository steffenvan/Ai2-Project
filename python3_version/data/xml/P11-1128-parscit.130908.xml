<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000030">
<title confidence="0.99037">
Adjoining Tree-to-String Translation
</title>
<author confidence="0.999025">
Yang Liu, Qun Liu, and Yajuan L¨u
</author>
<affiliation confidence="0.989319333333333">
Key Laboratory of Intelligent Information Processing
Institute of Computing Technology
Chinese Academy of Sciences
</affiliation>
<address confidence="0.861247">
P.O. Box 2704, Beijing 100190, China
</address>
<email confidence="0.999435">
{yliu,liuqun,lvyajuan}@ict.ac.cn
</email>
<sectionHeader confidence="0.998603" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999399">
We introduce synchronous tree adjoining
grammars (TAG) into tree-to-string transla-
tion, which converts a source tree to a target
string. Without reconstructing TAG deriva-
tions explicitly, our rule extraction algo-
rithm directly learns tree-to-string rules from
aligned Treebank-style trees. As tree-to-string
translation casts decoding as a tree parsing
problem rather than parsing, the decoder still
runs fast when adjoining is included. Less
than 2 times slower, the adjoining tree-to-
string system improves translation quality by
+0.7 BLEU over the baseline system only al-
lowing for tree substitution on NIST Chinese-
English test sets.
</bodyText>
<sectionHeader confidence="0.999521" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99943205882353">
Syntax-based translation models, which exploit hi-
erarchical structures of natural languages to guide
machine translation, have become increasingly pop-
ular in recent years. So far, most of them have
been based on synchronous context-free grammars
(CFG) (Chiang, 2007), tree substitution grammars
(TSG) (Eisner, 2003; Galley et al., 2006; Liu et
al., 2006; Huang et al., 2006; Zhang et al., 2008),
and inversion transduction grammars (ITG) (Wu,
1997; Xiong et al., 2006). Although these for-
malisms present simple and precise mechanisms for
describing the basic recursive structure of sentences,
they are not powerful enough to model some impor-
tant features of natural language syntax. For ex-
ample, Chiang (2006) points out that the transla-
tion of languages that can stack an unbounded num-
ber of clauses in an “inside-out” way (Wu, 1997)
provably goes beyond the expressive power of syn-
chronous CFG and TSG. Therefore, it is necessary
to find ways to take advantage of more powerful syn-
chronous grammars to improve machine translation.
Synchronous tree adjoining grammars (TAG)
(Shieber and Schabes, 1990) are a good candidate.
As a formal tree rewriting system, TAG (Joshi et al.,
1975; Joshi, 1985) provides a larger domain of lo-
cality than CFG to state linguistic dependencies that
are far apart since the formalism treats trees as basic
building blocks. As a mildly context-sensitive gram-
mar, TAG is conjectured to be powerful enough to
model natural languages. Synchronous TAG gener-
alizes TAG by allowing the construction of a pair
of trees using the TAG operations of substitution
and adjoining on tree pairs. The idea of using syn-
chronous TAG in machine translation has been pur-
sued by several researchers (Abeille et al., 1990;
Prigent, 1994; Dras, 1999), but only recently in
its probabilistic form (Nesson et al., 2006; De-
Neefe and Knight, 2009). Shieber (2007) argues that
probabilistic synchronous TAG possesses appealing
properties such as expressivity and trainability for
building a machine translation system.
However, one major challenge for applying syn-
chronous TAG to machine translation is computa-
tional complexity. While TAG requires O(n6) time
for monolingual parsing, synchronous TAG requires
O(n12) for bilingual parsing. One solution is to use
tree insertion grammars (TIG) introduced by Sch-
abes and Waters (1995). As a restricted form of
TAG, TIG still allows for adjoining of unbounded
trees but only requires O(n3) time for monolingual
parsing. Nesson et al. (2006) firstly demonstrate
</bodyText>
<page confidence="0.934046">
1278
</page>
<note confidence="0.986516">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1278–1287,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<figure confidence="0.992463477272727">
α1
101
z6ngt6ng
NN
NP
1
President
X
α2
)�Q
m6igu6
NR
NP
1
NP
X
X
US
1
01
NP∗ NP↓
X∗ X↓
NP
NP∗ NP
NN
X
X∗ X
President
02
1
NP
X
NR
NP
NN
NP
1
US
X
President
X
α3
101 )�Q ,0.
z6ngt6ng m6igu6 z6ngt6ng
</figure>
<figureCaption confidence="0.7215985">
Figure 1: Initial and auxiliary tree pairs. The source side (Chinese) is a Treebank-style linguistic tree. The target side
(English) is a purely structural tree using a single non-terminal (X). By convention, substitution and foot nodes are
marked with a down arrow (t) and an asterisk (*), respectively. The dashed lines link substitution sites (e.g., NP↓ and
X↓ in 01) and adjoining sites (e.g., NP and X in α2) in tree pairs. Substituting the initial tree pair α1 at the NP↓-X↓
node pair in the auxiliary tree pair 01 yields a derived tree pair 02, which can be adjoined at NN-X in α2 to generate
α3.
</figureCaption>
<bodyText confidence="0.999148222222222">
the use of synchronous TIG for machine translation
and report promising results. DeNeefe and Knight
(2009) prove that adjoining can improve translation
quality significantly over a state-of-the-art string-
to-tree system (Galley et al., 2006) that uses syn-
chronous TSG with tractable computational com-
plexity.
In this paper, we introduce synchronous TAG into
tree-to-string translation (Liu et al., 2006; Huang et
al., 2006), which is the simplest and fastest among
syntax-based approaches (Section 2). We propose
a new rule extraction algorithm based on GHKM
(Galley et al., 2004) that directly induces a syn-
chronous TAG from an aligned and parsed bilingual
corpus without converting Treebank-style trees to
TAG derivations explicitly (Section 3). As tree-to-
string translation takes a source parse tree as input,
the decoding can be cast as a tree parsing problem
(Eisner, 2003): reconstructing TAG derivations from
a derived tree using tree-to-string rules that allow for
both substitution and adjoining. We describe how to
convert TAG derivations to translation forest (Sec-
tion 4). We evaluated the new tree-to-string system
on NIST Chinese-English tests and obtained con-
sistent improvements (+0.7 BLEU) over the STSG-
based baseline system without significant loss in ef-
ficiency (1.6 times slower) (Section 5).
</bodyText>
<sectionHeader confidence="0.986839" genericHeader="introduction">
2 Model
</sectionHeader>
<bodyText confidence="0.999884904761905">
A synchronous TAG consists of a set of linked ele-
mentary tree pairs: initial and auxiliary. An initial
tree is a tree of which the interior nodes are all la-
beled with non-terminal symbols, and the nodes on
the frontier are either words or non-terminal sym-
bols marked with a down arrow (1). An auxiliary
tree is defined as an initial tree, except that exactly
one of its frontier nodes must be marked as foot
node (*). The foot node must be labeled with a non-
terminal symbol that is the same as the label of the
root node.
Synchronous TAG defines two operations to build
derived tree pairs from elementary tree pairs: substi-
tution and adjoining. Nodes in initial and auxiliary
tree pairs are linked to indicate the correspondence
between substitution and adjoining sites. Figure 1
shows three initial tree pairs (i.e., α1, α2, and α3)
and two auxiliary tree pairs (i.e., 01 and 02). The
dashed lines link substitution nodes (e.g., NPj and
Xj in 01) and adjoining sites (e.g., NP and X in α2)
in tree pairs. Substituting the initial tree pair α1 at
</bodyText>
<page confidence="0.989638">
1279
</page>
<figure confidence="0.871683">
IP
m6igu6 z6ngt6ng aobama duiqiangjishijian yuyiqianz6
0 1 2 3 4 5 6 7 8
US President Obama has condemned the shooting incident
</figure>
<figureCaption confidence="0.995865">
Figure 2: A training example. Tree-to-string rules can be extracted from shaded nodes.
</figureCaption>
<table confidence="0.999245346153846">
node minimal initial rule minimal auxiliary rule
NR0,1 [1] ( NR mˇeigu´o ) → US
NP0,1 [2] ( NP ( x1:NRI ) ) → x1
NN1,2 [3] ( NN zˇongtˇong ) → President
NP1,2 [4] ( NP ( x1:NNI ) ) → x1
NP0,2 [5] ( NP ( x1:NPI ) ( x2:NPI ) ) → x1 x2 [7] ( NP ( x1:NP* ) ( x2:NPI)) → x1 x2
[6] ( NP0:1 (x1:NRI)) → x1 [8] ( NP0:2 ( x1:NP* ) ( x2:NPI)) → x1 x2
[9] ( NP0:1 ( x1:NNI ) ) → x1 [10] ( NP (x1:NPI ) ( x2:NP* ) ) → x1 x2
[11] ( NP0:2 ( x1:NPI ) ( x2:NP* ) ) → x1 x2
NR2,3 [12] ( NR `aob¯amˇa ) → Obama
NP2,3 [13] ( NP (x1:NRI)) → x1
NP0,3 [14] ( NP ( x1:NPI ) ( x2:NPI ) ) → x1 x2 [16] ( NP ( x1:NP* ) (x2:NPI)) → x1 x2
[15] ( NP0:2 ( x1:NPI ) (x2:NPI)) → x1 x2 [18] ( NP (x1:NPI) ( x2:NP* ) ) → x1 x2
[17] ( NP0:1 ( x1:NRI ) ) → x1
[19] ( NP0:1 (x1:NNI)) → x1
[20] ( NP0:1 ( x1:NRI ) ) → x1
NN4,5 [21] ( NN qi¯angji) → shooting
NN5,6 [22] ( NN shiji`an ) → incident
NP4,6 [23] ( NP (x1:NNI) (x2:NNI)) → x1 x2
PP3,6 [24] ( PP ( dui) (x1:NPI)) → x1
NN7,8 [25] ( NN qiˇanz´e ) → condemned
NP7,8 [26] ( NP ( x1:NNI ) ) → x1
VP6,8 [27] ( VP ( VV yˇuyi) (x1:NPI)) → x1
VP3,8 [28] ( VP ( x1:PPI ) ( x2:VPI ) ) → x2 the x1 [30] ( VP ( x1:PPI) ( x2:VP* ) ) → x2 the x1
[29] ( VP0:1 ( VV yˇuyi) ( x1:NPI) ) → x1
IP0,8 [31] ( IP (x1:NPI ) (x2:VPI ) ) → x1 has x2
</table>
<tableCaption confidence="0.98679125">
Table 1: Minimal initial and auxiliary rules extracted from Figure 2. Note that an adjoining site has a span as subscript.
For example, NP0:1 in rule 6 indicates that the node is an adjoining site linked to a target node dominating the target
string spanning from position 0 to position 1 (i.e., x1). The target tree is hidden because tree-to-string translation only
considers the target surface string.
</tableCaption>
<figure confidence="0.987041181818182">
NP VP
101,`k IkE—L� XI fi^e11� J5it -T-L� i
NR
NP
NP
NN NR P NN NN VV
NP NP NP
PP
VP
NN
NP
</figure>
<page confidence="0.952625">
1280
</page>
<bodyText confidence="0.9983482">
the NPj-Xj node pair in the auxiliary tree pair β1
yields a derived tree pair β2, which can be adjoined
at NN-X in α2 to generate α3.
For simplicity, we represent α2 as a tree-to-string
rule:
</bodyText>
<equation confidence="0.574407">
( NP0:1 ( NR mˇeigu´o ) ) → US
</equation>
<bodyText confidence="0.998267333333333">
where NP0:1 indicates that the node is an adjoin-
ing site linked to a target node dominating the tar-
get string spanning from position 0 to position 1
(i.e., “US”). The target tree is hidden because tree-
to-string translation only considers the target surface
string. Similarly, β1 can be written as
</bodyText>
<equation confidence="0.993519">
(NP(x1:NP* )(x2:NPI ) ) → x1 x2
</equation>
<bodyText confidence="0.9991382">
where x denotes a non-terminal and the subscripts
indicate the correspondence between source and tar-
get non-terminals.
The parameters of a probabilistic synchronous
TAG are
</bodyText>
<equation confidence="0.958258142857143">
1:
Pi(α) = 1 (1)
a
1: Ps(α|η) = 1 (2)
a
1: Pa(β|η) + Pa(NONE|η) = 1 (3)
a
</equation>
<bodyText confidence="0.999946692307692">
where α ranges over initial tree pairs, β over aux-
iliary tree pairs, and η over node pairs. Pi(α) is
the probability of beginning a derivation with α;
Ps(α|η) is the probability of substituting α at η;
Pa(β|η) is the probability of adjoining β at η; fi-
nally, Pa(NONE|η) is the probability of nothing ad-
joining at η.
For tree-to-string translation, these parameters
can be treated as feature functions of a discrimi-
native framework (Och, 2003) combined with other
conventional features such as relative frequency, lex-
ical weight, rule count, language model, and word
count (Liu et al., 2006).
</bodyText>
<sectionHeader confidence="0.985332" genericHeader="method">
3 Rule Extraction
</sectionHeader>
<bodyText confidence="0.999801363636363">
Inducing a synchronous TAG from training data
often begins with converting Treebank-style parse
trees to TAG derivations (Xia, 1999; Chen and
Vijay-Shanker, 2000; Chiang, 2003). DeNeefe and
Knight (2009) propose an algorithm to extract syn-
chronous TIG rules from an aligned and parsed
bilingual corpus. They first classify tree nodes
into heads, arguments, and adjuncts using heuristics
(Collins, 2003), then transform a Treebank-style tree
into a TIG derivation, and finally extract minimally-
sized rules from the derivation tree and the string on
the other side, constrained by the alignments. Proba-
bilistic models can be estimated by collecting counts
over the derivation trees.
However, one challenge is that there are many
TAG derivations that can yield the same derived tree,
even with respect to a single grammar. It is difficult
to choose appropriate single derivations that enable
the resulting grammar to translate unseen data well.
DeNeefe and Knight (2009) indicate that the way to
reconstruct TIG derivations has a direct effect on fi-
nal translation quality. They suggest that one possi-
ble solution is to use derivation forest rather than a
single derivation tree for rule extraction.
Alternatively, we extend the GHKM algorithm
(Galley et al., 2004) to directly extract tree-to-string
rules that allow for both substitution and adjoining
from aligned and parsed data. There is no need for
transforming a parse tree into a TAG derivation ex-
plicitly before rule extraction and all derivations can
be easily reconstructed using extracted rules. 1 Our
rule extraction algorithm involves two steps: (1) ex-
tracting minimal rules and (2) composition.
</bodyText>
<subsectionHeader confidence="0.999804">
3.1 Extracting Minimal Rules
</subsectionHeader>
<bodyText confidence="0.893948411764706">
Figure 2 shows a training example, which consists of
a Chinese parse tree, an English string, and the word
alignment between them. By convention, shaded
nodes are called frontier nodes from which tree-to-
string rules can be extracted. Note that the source
phrase dominated by a frontier node and its corre-
sponding target phrase are consistent with the word
alignment: all words in the source phrase are aligned
to all words in the corresponding target phrase and
vice versa.
We distinguish between three categories of tree-
1Note that our algorithm does not take heads, complements,
and adjuncts into consideration and extracts all possible rules
with respect to word alignment. Our hope is that this treatment
would make our system more robust in the presence of noisy
data. It is possible to use the linguistic preferences as features.
We leave this for future work.
</bodyText>
<page confidence="0.947594">
1281
</page>
<listItem confidence="0.971009">
to-string rules:
1. substitution rules, in which the source tree is
an initial tree without adjoining sites.
2. adjoining rules, in which the source tree is an
initial tree with at least one adjoining site.
3. auxiliary rules, in which the source tree is an
auxiliary tree.
</listItem>
<bodyText confidence="0.992380964285714">
For example, in Figure 1, α1 is a substitution rule,
α2 is an adjoining rule, and 01 is an auxiliary rule.
Minimal substitution rules are the same with those
in STSG (Galley et al., 2004; Liu et al., 2006) and
therefore can be extracted directly using GHKM. By
minimal, we mean that the interior nodes are not
frontier and cannot be decomposed. For example,
in Table 2, rule 1 (for short r1) is a minimal substi-
tution rule extracted from NR0,1.
Minimal adjoining rules are defined as minimal
substitution rules, except that each root node must
be an adjoining site. In Table 2, r2 is a minimal
substitution rule extracted from NP0,1. As NP0,1 is
a descendant of NP0,2 with the same label, NP0,1
is a possible adjoining site. Therefore, r6 can be
derived from r2 and licensed as a minimal adjoining
rule extracted from NP0,2. Similarly, four minimal
adjoining rules are extracted from NP0,3 because it
has four frontier descendants labeled with NP.
Minimal auxiliary rules are derived from minimal
substitution and adjoining rules. For example, in Ta-
ble 2, r7 and r10 are derived from the minimal sub-
stitution rule r5 while r8 and r11 are derived from
r15. Note that a minimal auxiliary rule can have ad-
joining sites (e.g., r8).
Table 1 lists 17 minimal substitution rules, 7 min-
imal adjoining rules, and 7 minimal auxiliary rules
extracted from Figure 2.
</bodyText>
<subsectionHeader confidence="0.995225">
3.2 Composition
</subsectionHeader>
<bodyText confidence="0.9999542">
We can obtain composed rules that capture rich con-
texts by substituting and adjoining minimal initial
and auxiliary rules. For example, the composition
of r12, r17, r25, r26, r29, and r31 yields an initial
rule with two adjoining sites:
</bodyText>
<listItem confidence="0.820666">
( IP ( NP0:1 ( NR `aob¯amˇa ) ) ( VP2:3 ( VV yˇuyˇı )
( NP ( NN qiˇanz´e ) ) ) ) → Obama has condemned
</listItem>
<bodyText confidence="0.997966714285714">
Note that the source phrase “`aob¯amˇa ... yˇuyˇı qiˇanz´e”
is discontinuous. Our model allows both the source
and target phrases of an initial rule with adjoining
sites to be discontinuous, which goes beyond the ex-
pressive power of synchronous CFG and TSG.
Similarly, the composition of two auxiliary rules
r8 and r16 yields a new auxiliary rule:
</bodyText>
<equation confidence="0.610768">
( NP ( NP ( x1:NP* ) ( x2:NP1 ) ) ( x3:NP ) ) → x1x2x3
</equation>
<bodyText confidence="0.99987">
We first compose initial rules and then com-
pose auxiliary rules, both in a bottom-up way. To
maintain a reasonable grammar size, we follow Liu
(2006) to restrict that the tree height of a rule is no
greater than 3 and the source surface string is no
longer than 7.
To learn the probability models Pi(α), P3(αJq),
Pa(0Jq), and Pa(NONEJq), we collect and normal-
ize counts over these extracted rules following De-
Neefe and Knight (2009).
</bodyText>
<sectionHeader confidence="0.998317" genericHeader="method">
4 Decoding
</sectionHeader>
<bodyText confidence="0.966322">
Given a synchronous TAG and a derived source tree
7r, a tree-to-string decoder finds the English yield
of the best derivation of which the Chinese yield
matches 7r:
</bodyText>
<equation confidence="0.939180333333333">
� 1
e� = e arg max P(D) (4)
D s.t. f(D)=7r
</equation>
<bodyText confidence="0.942202">
This is called tree parsing (Eisner, 2003) as the de-
coder finds ways of decomposing 7r into elementary
trees.
Tree-to-string decoding with STSG is usually
treated as forest rescoring (Huang and Chiang,
2007) that involves two steps. The decoder first con-
verts the input tree into a translation forest using a
translation rule set by pattern matching. Huang et
al. (2006) show that this step is a depth-first search
with memorization in O(n) time. Then, the decoder
searches for the best derivation in the translation for-
est intersected with n-gram language models and
outputs the target string. 2
Decoding with STAG, however, poses one major
challenge to forest rescoring. As translation forest
only supports substitution, it is difficult to construct
a translation forest for STAG derivations because of
2Mi et al. (2008) give a detailed description of the two-step
decoding process. Huang and Mi (2010) systematically analyze
the decoding complexity of tree-to-string translation.
</bodyText>
<page confidence="0.821974">
1282
</page>
<equation confidence="0.618490947368421">
α2
NR2,3
,1*1,E—!�
aobama
α3
NN2,3
1;:IL�
zongtong
α1
IP0,8
NP2,3 VP3,8
↓
NR2,3
↓
β2
NP0,3
NP0,2 NP2,3
↓ ∗
β3
NP0,2
1,2
NP0,1 NP∗
NR0,1
↓
β1
NP0,3
NP1,2 NP2,3
∗
NN1,2
↓
elementary tree translation rule
α1 r1 ( IP ( NP0:1 ( x1:NR↓ ) ) ( x2:VP↓ ) ) → x1 x2
α��2 r2 ( NR `aob¯amˇa ) → Obama
/
/�1 r3 ( NP ( NP0:1 ( x1:NN↓ ) ) ( x2:NP∗ ) ) → x1 x2
/N2 r4 ( NP ( x1:NP↓ ) ( x2:NP∗ ) ) → x1 x2
N3 r5 ( NP ( NP ( x1:NR↓ ) ) ( x2:NP∗ ) ) → x1 x2
α3 rs ( NN zˇongtˇong ) → President
</equation>
<figureCaption confidence="0.947583">
Figure 3: Matched trees and corresponding rules. Each node in a matched tree is annotated with a span as superscript
to facilitate identification. For example, IP0,8 in α1 indicates that IP0,8 in Figure 2 is matched. Note that its left child
NP2,3 is not its direct descendant in Figure 2, suggesting that adjoining is required at this site.
</figureCaption>
<equation confidence="0.996791615384615">
α1
α2(1.1) β1(1) β2(1)
β3(1) α3(1.1)
NP0,2 VP3,8
NR0,1 NN1,2 NR2,3
e3 e4
IP0,8
e1 e2
hyperedge translation rule
e1 r1 + r4 ( IP ( NP ( x1:NP↓ ) ( NP ( x2:NR↓ ) ) ) ( x3:VP↓ ) → x1 x2 x3
e2 r1 + r3 + r5 ( IP ( NP ( NP ( x1:NP↓ ) ( x2:NP↓ ) ) ( NP ( x3:NR↓ ) ) ) ( x4:VP↓ ) ) → x1 x2 x3 x4
e3 rs ( NN zˇongtˇong ) → President
e4 r2 ( NR `aob¯amˇa ) → Obama
</equation>
<figureCaption confidence="0.799253666666667">
Figure 4: Converting a derivation forest to a translation forest. In a derivation forest, a node in a derivation forest is a
matched elementary tree. A hyperedge corresponds to operations on related trees: substitution (dashed) or adjoining
(solid). We use Gorn addresses as tree addresses. α2(1.1) denotes that α2 is substituted in the tree α1 at the node NR2,3
</figureCaption>
<bodyText confidence="0.90535375">
↓
of address 1.1 (i.e., the first child of the first child of the root node). As translation forest only supports substitution, we
combine trees with adjoining sites to form an equivalent tree without adjoining sites. Rules are composed accordingly
(e.g., r1 + r4).
</bodyText>
<page confidence="0.944919">
1283
</page>
<bodyText confidence="0.9049505">
adjoining. Therefore, we divide forest rescoring for
STAG into three steps:
</bodyText>
<listItem confidence="0.4550005">
1. matching, matching STAG rules against the in-
put tree to obtain a TAG derivation forest;
</listItem>
<bodyText confidence="0.695657333333333">
should be interpreted as follows: α2 is substituted in
the tree α1 at the node NR2,3
� of address 1.1 (i.e., the
first child of the first child of the root node) and 01 is
adjoined in the tree α1 at the node NP2,3 of address
1.
</bodyText>
<listItem confidence="0.8965965">
2. conversion, converting the TAG derivation for-
est into a translation forest;
3. intersection, intersecting the translation forest
with an n-gram language model.
</listItem>
<bodyText confidence="0.999709407407407">
Given a tree-to-string rule, rule matching is to find
a subtree of the input tree that is identical to the
source side of the rule. While matching STSG rules
against a derived tree is straightforward, it is some-
what non-trivial for STAG rules that move beyond
nodes of a local tree. We follow Liu et al. (2006) to
enumerate all elementary subtrees and match STAG
rules against these subtrees. This can be done by first
enumerating all minimal initial and auxiliary trees
and then combining them to obtain composed trees,
assuming that every node in the input tree is fron-
tier (see Section 3). We impose the same restrictions
on the tree height and length as in rule extraction.
Figure 3 shows some matched trees and correspond-
ing rules. Each node in a matched tree is annotated
with a span as superscript to facilitate identification.
For example, IP0,8 in α1 means that IP0,8 in Figure
2 is matched. Note that its left child NP2,3 is not
its direct descendant in Figure 2, suggesting that ad-
joining is required at this site.
A TAG derivation tree specifies uniquely how
a derived tree is constructed using elementary trees
(Joshi, 1985). A node in a derivation tree is an ele-
mentary tree and an edge corresponds to operations
on related elementary trees: substitution or adjoin-
ing. We introduce TAG derivation forest, a com-
pact representation of multiple TAG derivation trees,
to encodes all matched TAG derivation trees of the
input derived tree.
Figure 4 shows part of a TAG derivation forest.
The six matched elementary trees are nodes in the
derivation forest. Dashed and solid lines represent
substitution and adjoining, respectively. We use
Gorn addresses as tree addresses: 0 is the address
of the root node, p is the address of the pth child of
the root node, and p · q is the address of the qth child
of the node at the address p. The derivation forest
To take advantage of existing decoding tech-
niques, it is necessary to convert a derivation forest
to a translation forest. A hyperedge in a transla-
tion forest corresponds to a translation rule. Mi et
al. (2008) describe how to convert a derived tree
to a translation forest using tree-to-string rules only
allowing for substitution. Unfortunately, it is not
straightforward to convert a derivation forest includ-
ing adjoining to a translation forest. To alleviate this
problem, we combine initial rules with adjoining
sites and associated auxiliary rules to form equiv-
alent initial rules without adjoining sites on the fly
during decoding.
Consider α1 in Figure 3. It has an adjoining site
NP2,3. Adjoining 02 in α1 at the node NP2,3 pro-
duces an equivalent initial tree with only substitution
sites:
</bodyText>
<equation confidence="0.967944333333333">
( IP0,8 (NP0,3 ( NP0,2
� ) (NP2,3 ( NR2,3 �) ) ) ( VPI,
8) )
</equation>
<bodyText confidence="0.999957727272727">
The corresponding composed rule r1 + r� has no
adjoining sites and can be added to translation forest.
We define that the elementary trees needed to be
composed (e.g., α1 and 02) form a composition tree
in a derivation forest. A node in a composition tree is
a matched elementary tree and an edge corresponds
to adjoining operations. The root node must be an
initial tree with at least one adjoining site. The de-
scendants of the root node must all be auxiliary trees.
For example, ( α1 ( 02 ) ) and ( α1 ( 01 ( 03 ) ) ) are
two composition trees in Figure 4. The number of
children of a node in a composition tree depends on
the number of adjoining sites in the node. We use
composition forest to encode all possible composi-
tion trees.
Often, a node in a composition tree may have mul-
tiple matched rules. As a large amount of composi-
tion trees and composed rules can be identified and
constructed on the fly during forest conversion, we
used cube pruning (Chiang, 2007; Huang and Chi-
ang, 2007) to achieve a balance between translation
quality and decoding efficiency.
</bodyText>
<page confidence="0.985392">
1284
</page>
<table confidence="0.989309727272727">
category description number
VP verb phrase
NP noun phrase
IP simple clause
QP quantifier phrase
CP clause headed by C
PP preposition phrase
CLP classifier phrase
ADJP adjective phrase
LCP phrase formed by “XP+LC”
DNP phrase formed by “XP+DEG”
</table>
<tableCaption confidence="0.996057">
Table 2: Top-10 phrase categories of foot nodes and their
average occurrences in training corpus.
</tableCaption>
<figure confidence="0.998353846153846">
12.40
7.69
7.26
0.14
0.10
0.09
0.02
0.02
0.02
0.01
VP
IP
NP
0 1 2 3 4 5 6 7 8 9 10 11
distance
4.5
4.0
average occurrence
3.5
3.0
2.5
2.0
1.5
1.0
0.5
0.0
</figure>
<figureCaption confidence="0.976688">
Figure 5: Average occurrences of foot node labels VP,
NP, and IP over various distances.
</figureCaption>
<sectionHeader confidence="0.996736" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.99958165625">
We evaluated our adjoining tree-to-string translation
system on Chinese-English translation. The bilin-
gual corpus consists of 1.5M sentences with 42.1M
Chinese words and 48.3M English words. The Chi-
nese sentences in the bilingual corpus were parsed
by an in-house parser. To maintain a reasonable
grammar size, we follow Liu et al. (2006) to re-
strict that the height of a rule tree is no greater than
3 and the surface string’s length is no greater than 7.
After running GIZA++ (Och and Ney, 2003) to ob-
tain word alignment, our rule extraction algorithm
extracted 23.0M initial rules without adjoining sites,
6.6M initial rules with adjoining sites, and 5.3M
auxiliary rules. We used the SRILM toolkit (Stol-
cke, 2002) to train a 4-gram language model on the
Xinhua portion of the GIGAWORD corpus, which
contains 238M English words. We used the 2002
NIST MT Chinese-English test set as the develop-
ment set and the 2003-2005 NIST test sets as the
test sets. We evaluated translation quality using the
BLEU metric, as calculated by mteval-v11b.pl with
case-insensitive matching of n-grams.
Table 2 shows top-10 phrase categories of foot
nodes and their average occurrences in training cor-
pus. We find that VP (verb phrase) is most likely
to be the label of a foot node in an auxiliary rule.
On average, there are 12.4 nodes labeled with VP
are identical to one of its ancestors per tree. NP and
IP are also found to be foot node labels frequently.
Figure 4 shows the average occurrences of foot node
labels VP, NP, and IP over various distances. A dis-
tance is the difference of levels between a foot node
</bodyText>
<table confidence="0.99824">
system grammar MT03 MT04 MT05
Moses - 33.10 33.96 32.17
hierarchical SCFG 33.40 34.65 32.88
tree-to-string STSG 33.13 34.55 31.94
STAG 33.64 35.28 32.71
</table>
<tableCaption confidence="0.980970333333333">
Table 3: BLEU scores on NIST Chinese-English test sets.
Scores marked in bold are significantly better that those
of STSG at pl.01 level.
</tableCaption>
<bodyText confidence="0.999937565217391">
and the root node. For example, in Figure 2, the dis-
tance between NP0,1 and NP0,3 is 2 and the distance
between VP6,8 and VP3,8 is 1. As most foot nodes
are usually very close to the root nodes, we restrict
that a foot node must be the direct descendant of the
root node in our experiments.
Table 3 shows the BLEU scores on the NIST
Chinese-English test sets. Our baseline system is the
tree-to-string system using STSG (Liu et al., 2006;
Huang et al., 2006). The STAG system outper-
forms the STSG system significantly on the MT04
and MT05 test sets at pl.01 level. Table 3 also
gives the results of Moses (Koehn et al., 2007) and
an in-house hierarchical phrase-based system (Chi-
ang, 2007). Our STAG system achieves compara-
ble performance with the hierarchical system. The
absolute improvement of +0.7 BLEU over STSG is
close to the finding of DeNeefe and Knight (2009)
on string-to-tree translation. We feel that one major
obstacle for achieving further improvement is that
composed rules generated on the fly during decod-
ing (e.g., r1 + r3 + r5 in Figure 4) usually have too
many non-terminals, making cube pruning in the in-
</bodyText>
<page confidence="0.953069">
1285
</page>
<table confidence="0.998794666666667">
STSG STAG
matching 0.086 0.109
conversion 0.000 0.562
intersection 0.946 1.064
other 0.012 0.028
total 1.044 1.763
</table>
<tableCaption confidence="0.999951">
Table 4: Comparison of average decoding time.
</tableCaption>
<bodyText confidence="0.9998269">
tersection phase suffering from severe search errors
(only a tiny fraction of the search space can be ex-
plored). To produce the 1-best translations on the
MT05 test set that contains 1,082 sentences, while
the STSG system used 40,169 initial rules without
adjoining sites, the STAG system used 28,046 initial
rules without adjoining sites, 1,057 initial rules with
adjoining sites, and 1,527 auxiliary rules.
Table 4 shows the average decoding time on the
MT05 test set. While rule matching for STSG needs
0.086 second per sentence, the matching time for
STAG only increases to 0.109 second. For STAG,
the conversion of derivation forests to translation
forests takes 0.562 second when we restrict that at
most 200 rules can be generated on the fly for each
node. As we use cube pruning, although the trans-
lation forest of STAG is bigger than that of STSG,
the intersection time barely increases. In total, the
STAG system runs in 1.763 seconds per sentence,
only 1.6 times slower than the baseline system.
</bodyText>
<sectionHeader confidence="0.999541" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999989166666667">
We have presented a new tree-to-string translation
system based on synchronous TAG. With translation
rules learned from Treebank-style trees, the adjoin-
ing tree-to-string system outperforms the baseline
system using STSG without significant loss in effi-
ciency. We plan to introduce left-to-right target gen-
eration (Huang and Mi, 2010) into the STAG tree-
to-string system. Our work can also be extended to
forest-based rule extraction and decoding (Mi et al.,
2008; Mi and Huang, 2008). It is also interesting to
introduce STAG into tree-to-tree translation (Zhang
et al., 2008; Liu et al., 2009; Chiang, 2010).
</bodyText>
<sectionHeader confidence="0.997753" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.991613">
The authors were supported by National Natural
Science Foundation of China Contracts 60736014,
60873167, and 60903138. We thank the anonymous
reviewers for their insightful comments.
</bodyText>
<sectionHeader confidence="0.996584" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999206693877551">
Anne Abeille, Yves Schabes, and Aravind Joshi. 1990.
Using lexicalized tags for machine translation. In
Proc. of COLING 1990.
John Chen and K. Vijay-Shanker. 2000. Automated ex-
traction of tags from the penn treebank. In Proc. of
IWPT 2000.
David Chiang. 2003. Statistical parsing with an au-
tomatically extracted tree adjoining grammar. Data-
Oriented Parsing.
David Chiang. 2006. An introduction to synchronous
grammars. ACL Tutorial.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201–228.
David Chiang. 2010. Learning to translate with source
and target syntax. In Proc. ofACL 2010.
Michael Collins. 2003. Head-driven statistical models
for natural language parsing. Computational Linguis-
tics, 29(4).
Steve DeNeefe and Kevin Knight. 2009. Synchronous
tree adjoining machine translation. In Proc. of
EMNLP 2009.
Mark Dras. 1999. A meta-level grammar: Redefining
synchronous tag for translation and paraphrase. In
Proc. ofACL 1999.
Jason Eisner. 2003. Learning non-isomorphic tree map-
pings for machine translation. In Proc. ofACL 2003.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What’s in a translation rule? In Proc.
ofNAACL 2004.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In Proc. of
ACL 2006.
Liang Huang and David Chiang. 2007. Forest rescoring:
Faster decoding with integrated language models. In
Proc. ofACL 2007.
Liang Huang and Haitao Mi. 2010. Efficient incremen-
tal decoding for tree-to-string translation. In Proc. of
EMNLP 2010.
Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
Statistical syntax-directed translation with extended
domain of locality. In Proc. ofAMTA 2006.
Aravind Joshi, L. Levy, and M. Takahashi. 1975. Tree
adjunct grammars. Journal of Computer and System
Sciences, 10(1).
Aravind Joshi. 1985. How much contextsensitiv-
ity is necessary for characterizing structural descrip-
tions-tree adjoining grammars. Natural Language
</reference>
<page confidence="0.786255">
1286
</page>
<reference confidence="0.999825965517241">
Processing-Theoretical, Computational, and Psy-
chological Perspectives.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In Pro-
ceedings of ACL 2007 (poster), pages 77–80, Prague,
Czech Republic, June.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-to-
string alignment template for statistical machine trans-
lation. In Proc. ofACL 2006.
Yang Liu, Yajuan L¨u, and Qun Liu. 2009. Improving
tree-to-tree translation with packed forests. In Proc. of
ACL 2009.
Haitao Mi and Liang Huang. 2008. Forest-based transla-
tion rule extraction. In Proceedings ofEMNLP 2008.
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
based translation. In Proceedings of ACL/HLT 2008,
pages 192–199, Columbus, Ohio, USA, June.
Rebecca Nesson, Stuart Shieber, and Alexander Rush.
2006. Induction of probabilistic synchronous tree-
insertion grammars for machine translation. In Proc.
ofAMTA 2006.
Franz J. Och and Hermann Ney. 2003. A systematic
comparison of various statistical alignment models.
Computational Linguistics, 29(1):19–51.
Franz Och. 2003. Minimum error rate training in statis-
tical machine translation. In Proc. ofACL 2003.
Gilles Prigent. 1994. Synchronous tags and machine
translation. In Proc. of TAG+3.
Yves Schabes and Richard Waters. 1995. A cubic-time,
parsable formalism that lexicalizes context-free gram-
mar without changing the trees produced. Computa-
tional Linguistics, 21(4).
Stuart M. Shieber and Yves Schabes. 1990. Synchronous
tree-adjoining grammars. In Proc. of COLING 1990.
Stuart M. Shieber. 2007. Probabilistic synchronous tree-
adjoining grammars for machine translation: The ar-
gument from bilingual dictionaries. In Proc. of SSST
2007.
Andreas Stolcke. 2002. Srilm - an extensible language
modeling toolkit. In Proceedings of ICSLP 2002,
pages 901–904.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377–404.
Fei Xia. 1999. Extracting tree adjoining grammars from
bracketed corpora. In Proc. of the Fifth Natural Lan-
guage Processing Pacific Rim Symposium.
Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Maxi-
mum entropy based phrase reordering model for sta-
tistical machine translation. In Proc. ofACL 2006.
Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li,
Chew Lim Tan, and Sheng Li. 2008. A tree se-
quence alignment-based tree-to-tree translation model.
In Proc. ofACL 2008.
</reference>
<page confidence="0.992252">
1287
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.615973">
<title confidence="0.998988">Adjoining Tree-to-String Translation</title>
<author confidence="0.94799">Qun Liu Liu</author>
<affiliation confidence="0.9653305">Key Laboratory of Intelligent Information Institute of Computing</affiliation>
<address confidence="0.9344335">Chinese Academy of P.O. Box 2704, Beijing 100190,</address>
<abstract confidence="0.9733228125">We introduce synchronous tree adjoining grammars (TAG) into tree-to-string translation, which converts a source tree to a target string. Without reconstructing TAG derivations explicitly, our rule extraction algorithm directly learns tree-to-string rules from aligned Treebank-style trees. As tree-to-string translation casts decoding as a tree parsing problem rather than parsing, the decoder still runs fast when adjoining is included. Less than 2 times slower, the adjoining tree-tostring system improves translation quality by +0.7 BLEU over the baseline system only allowing for tree substitution on NIST Chinese- English test sets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeille</author>
<author>Yves Schabes</author>
<author>Aravind Joshi</author>
</authors>
<title>Using lexicalized tags for machine translation.</title>
<date>1990</date>
<booktitle>In Proc. of COLING</booktitle>
<contexts>
<context position="2647" citStr="Abeille et al., 1990" startWordPosition="401" endWordPosition="404">od candidate. As a formal tree rewriting system, TAG (Joshi et al., 1975; Joshi, 1985) provides a larger domain of locality than CFG to state linguistic dependencies that are far apart since the formalism treats trees as basic building blocks. As a mildly context-sensitive grammar, TAG is conjectured to be powerful enough to model natural languages. Synchronous TAG generalizes TAG by allowing the construction of a pair of trees using the TAG operations of substitution and adjoining on tree pairs. The idea of using synchronous TAG in machine translation has been pursued by several researchers (Abeille et al., 1990; Prigent, 1994; Dras, 1999), but only recently in its probabilistic form (Nesson et al., 2006; DeNeefe and Knight, 2009). Shieber (2007) argues that probabilistic synchronous TAG possesses appealing properties such as expressivity and trainability for building a machine translation system. However, one major challenge for applying synchronous TAG to machine translation is computational complexity. While TAG requires O(n6) time for monolingual parsing, synchronous TAG requires O(n12) for bilingual parsing. One solution is to use tree insertion grammars (TIG) introduced by Schabes and Waters (1</context>
</contexts>
<marker>Abeille, Schabes, Joshi, 1990</marker>
<rawString>Anne Abeille, Yves Schabes, and Aravind Joshi. 1990. Using lexicalized tags for machine translation. In Proc. of COLING 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Chen</author>
<author>K Vijay-Shanker</author>
</authors>
<title>Automated extraction of tags from the penn treebank.</title>
<date>2000</date>
<booktitle>In Proc. of IWPT</booktitle>
<contexts>
<context position="10325" citStr="Chen and Vijay-Shanker, 2000" startWordPosition="1806" endWordPosition="1809">with α; Ps(α|η) is the probability of substituting α at η; Pa(β|η) is the probability of adjoining β at η; finally, Pa(NONE|η) is the probability of nothing adjoining at η. For tree-to-string translation, these parameters can be treated as feature functions of a discriminative framework (Och, 2003) combined with other conventional features such as relative frequency, lexical weight, rule count, language model, and word count (Liu et al., 2006). 3 Rule Extraction Inducing a synchronous TAG from training data often begins with converting Treebank-style parse trees to TAG derivations (Xia, 1999; Chen and Vijay-Shanker, 2000; Chiang, 2003). DeNeefe and Knight (2009) propose an algorithm to extract synchronous TIG rules from an aligned and parsed bilingual corpus. They first classify tree nodes into heads, arguments, and adjuncts using heuristics (Collins, 2003), then transform a Treebank-style tree into a TIG derivation, and finally extract minimallysized rules from the derivation tree and the string on the other side, constrained by the alignments. Probabilistic models can be estimated by collecting counts over the derivation trees. However, one challenge is that there are many TAG derivations that can yield the</context>
</contexts>
<marker>Chen, Vijay-Shanker, 2000</marker>
<rawString>John Chen and K. Vijay-Shanker. 2000. Automated extraction of tags from the penn treebank. In Proc. of IWPT 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Statistical parsing with an automatically extracted tree adjoining grammar. DataOriented Parsing.</title>
<date>2003</date>
<contexts>
<context position="10340" citStr="Chiang, 2003" startWordPosition="1810" endWordPosition="1811">lity of substituting α at η; Pa(β|η) is the probability of adjoining β at η; finally, Pa(NONE|η) is the probability of nothing adjoining at η. For tree-to-string translation, these parameters can be treated as feature functions of a discriminative framework (Och, 2003) combined with other conventional features such as relative frequency, lexical weight, rule count, language model, and word count (Liu et al., 2006). 3 Rule Extraction Inducing a synchronous TAG from training data often begins with converting Treebank-style parse trees to TAG derivations (Xia, 1999; Chen and Vijay-Shanker, 2000; Chiang, 2003). DeNeefe and Knight (2009) propose an algorithm to extract synchronous TIG rules from an aligned and parsed bilingual corpus. They first classify tree nodes into heads, arguments, and adjuncts using heuristics (Collins, 2003), then transform a Treebank-style tree into a TIG derivation, and finally extract minimallysized rules from the derivation tree and the string on the other side, constrained by the alignments. Probabilistic models can be estimated by collecting counts over the derivation trees. However, one challenge is that there are many TAG derivations that can yield the same derived t</context>
</contexts>
<marker>Chiang, 2003</marker>
<rawString>David Chiang. 2003. Statistical parsing with an automatically extracted tree adjoining grammar. DataOriented Parsing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>An introduction to synchronous grammars.</title>
<date>2006</date>
<journal>ACL Tutorial.</journal>
<contexts>
<context position="1625" citStr="Chiang (2006)" startWordPosition="233" endWordPosition="234">uide machine translation, have become increasingly popular in recent years. So far, most of them have been based on synchronous context-free grammars (CFG) (Chiang, 2007), tree substitution grammars (TSG) (Eisner, 2003; Galley et al., 2006; Liu et al., 2006; Huang et al., 2006; Zhang et al., 2008), and inversion transduction grammars (ITG) (Wu, 1997; Xiong et al., 2006). Although these formalisms present simple and precise mechanisms for describing the basic recursive structure of sentences, they are not powerful enough to model some important features of natural language syntax. For example, Chiang (2006) points out that the translation of languages that can stack an unbounded number of clauses in an “inside-out” way (Wu, 1997) provably goes beyond the expressive power of synchronous CFG and TSG. Therefore, it is necessary to find ways to take advantage of more powerful synchronous grammars to improve machine translation. Synchronous tree adjoining grammars (TAG) (Shieber and Schabes, 1990) are a good candidate. As a formal tree rewriting system, TAG (Joshi et al., 1975; Joshi, 1985) provides a larger domain of locality than CFG to state linguistic dependencies that are far apart since the for</context>
</contexts>
<marker>Chiang, 2006</marker>
<rawString>David Chiang. 2006. An introduction to synchronous grammars. ACL Tutorial.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="1182" citStr="Chiang, 2007" startWordPosition="163" endWordPosition="164">ing translation casts decoding as a tree parsing problem rather than parsing, the decoder still runs fast when adjoining is included. Less than 2 times slower, the adjoining tree-tostring system improves translation quality by +0.7 BLEU over the baseline system only allowing for tree substitution on NIST ChineseEnglish test sets. 1 Introduction Syntax-based translation models, which exploit hierarchical structures of natural languages to guide machine translation, have become increasingly popular in recent years. So far, most of them have been based on synchronous context-free grammars (CFG) (Chiang, 2007), tree substitution grammars (TSG) (Eisner, 2003; Galley et al., 2006; Liu et al., 2006; Huang et al., 2006; Zhang et al., 2008), and inversion transduction grammars (ITG) (Wu, 1997; Xiong et al., 2006). Although these formalisms present simple and precise mechanisms for describing the basic recursive structure of sentences, they are not powerful enough to model some important features of natural language syntax. For example, Chiang (2006) points out that the translation of languages that can stack an unbounded number of clauses in an “inside-out” way (Wu, 1997) provably goes beyond the expres</context>
<context position="15969" citStr="Chiang, 2007" startWordPosition="2766" endWordPosition="2767">no longer than 7. To learn the probability models Pi(α), P3(αJq), Pa(0Jq), and Pa(NONEJq), we collect and normalize counts over these extracted rules following DeNeefe and Knight (2009). 4 Decoding Given a synchronous TAG and a derived source tree 7r, a tree-to-string decoder finds the English yield of the best derivation of which the Chinese yield matches 7r: � 1 e� = e arg max P(D) (4) D s.t. f(D)=7r This is called tree parsing (Eisner, 2003) as the decoder finds ways of decomposing 7r into elementary trees. Tree-to-string decoding with STSG is usually treated as forest rescoring (Huang and Chiang, 2007) that involves two steps. The decoder first converts the input tree into a translation forest using a translation rule set by pattern matching. Huang et al. (2006) show that this step is a depth-first search with memorization in O(n) time. Then, the decoder searches for the best derivation in the translation forest intersected with n-gram language models and outputs the target string. 2 Decoding with STAG, however, poses one major challenge to forest rescoring. As translation forest only supports substitution, it is difficult to construct a translation forest for STAG derivations because of 2M</context>
<context position="22804" citStr="Chiang, 2007" startWordPosition="4016" endWordPosition="4017">an initial tree with at least one adjoining site. The descendants of the root node must all be auxiliary trees. For example, ( α1 ( 02 ) ) and ( α1 ( 01 ( 03 ) ) ) are two composition trees in Figure 4. The number of children of a node in a composition tree depends on the number of adjoining sites in the node. We use composition forest to encode all possible composition trees. Often, a node in a composition tree may have multiple matched rules. As a large amount of composition trees and composed rules can be identified and constructed on the fly during forest conversion, we used cube pruning (Chiang, 2007; Huang and Chiang, 2007) to achieve a balance between translation quality and decoding efficiency. 1284 category description number VP verb phrase NP noun phrase IP simple clause QP quantifier phrase CP clause headed by C PP preposition phrase CLP classifier phrase ADJP adjective phrase LCP phrase formed by “XP+LC” DNP phrase formed by “XP+DEG” Table 2: Top-10 phrase categories of foot nodes and their average occurrences in training corpus. 12.40 7.69 7.26 0.14 0.10 0.09 0.02 0.02 0.02 0.01 VP IP NP 0 1 2 3 4 5 6 7 8 9 10 11 distance 4.5 4.0 average occurrence 3.5 3.0 2.5 2.0 1.5 1.0 0.5 0.0 </context>
<context position="26088" citStr="Chiang, 2007" startWordPosition="4588" endWordPosition="4590">NP0,3 is 2 and the distance between VP6,8 and VP3,8 is 1. As most foot nodes are usually very close to the root nodes, we restrict that a foot node must be the direct descendant of the root node in our experiments. Table 3 shows the BLEU scores on the NIST Chinese-English test sets. Our baseline system is the tree-to-string system using STSG (Liu et al., 2006; Huang et al., 2006). The STAG system outperforms the STSG system significantly on the MT04 and MT05 test sets at pl.01 level. Table 3 also gives the results of Moses (Koehn et al., 2007) and an in-house hierarchical phrase-based system (Chiang, 2007). Our STAG system achieves comparable performance with the hierarchical system. The absolute improvement of +0.7 BLEU over STSG is close to the finding of DeNeefe and Knight (2009) on string-to-tree translation. We feel that one major obstacle for achieving further improvement is that composed rules generated on the fly during decoding (e.g., r1 + r3 + r5 in Figure 4) usually have too many non-terminals, making cube pruning in the in1285 STSG STAG matching 0.086 0.109 conversion 0.000 0.562 intersection 0.946 1.064 other 0.012 0.028 total 1.044 1.763 Table 4: Comparison of average decoding tim</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Learning to translate with source and target syntax.</title>
<date>2010</date>
<booktitle>In Proc. ofACL</booktitle>
<marker>Chiang, 2010</marker>
<rawString>David Chiang. 2010. Learning to translate with source and target syntax. In Proc. ofACL 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-driven statistical models for natural language parsing.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>4</issue>
<contexts>
<context position="10566" citStr="Collins, 2003" startWordPosition="1844" endWordPosition="1845">ns of a discriminative framework (Och, 2003) combined with other conventional features such as relative frequency, lexical weight, rule count, language model, and word count (Liu et al., 2006). 3 Rule Extraction Inducing a synchronous TAG from training data often begins with converting Treebank-style parse trees to TAG derivations (Xia, 1999; Chen and Vijay-Shanker, 2000; Chiang, 2003). DeNeefe and Knight (2009) propose an algorithm to extract synchronous TIG rules from an aligned and parsed bilingual corpus. They first classify tree nodes into heads, arguments, and adjuncts using heuristics (Collins, 2003), then transform a Treebank-style tree into a TIG derivation, and finally extract minimallysized rules from the derivation tree and the string on the other side, constrained by the alignments. Probabilistic models can be estimated by collecting counts over the derivation trees. However, one challenge is that there are many TAG derivations that can yield the same derived tree, even with respect to a single grammar. It is difficult to choose appropriate single derivations that enable the resulting grammar to translate unseen data well. DeNeefe and Knight (2009) indicate that the way to reconstru</context>
</contexts>
<marker>Collins, 2003</marker>
<rawString>Michael Collins. 2003. Head-driven statistical models for natural language parsing. Computational Linguistics, 29(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve DeNeefe</author>
<author>Kevin Knight</author>
</authors>
<title>Synchronous tree adjoining machine translation.</title>
<date>2009</date>
<booktitle>In Proc. of EMNLP</booktitle>
<contexts>
<context position="2768" citStr="DeNeefe and Knight, 2009" startWordPosition="420" endWordPosition="424">ocality than CFG to state linguistic dependencies that are far apart since the formalism treats trees as basic building blocks. As a mildly context-sensitive grammar, TAG is conjectured to be powerful enough to model natural languages. Synchronous TAG generalizes TAG by allowing the construction of a pair of trees using the TAG operations of substitution and adjoining on tree pairs. The idea of using synchronous TAG in machine translation has been pursued by several researchers (Abeille et al., 1990; Prigent, 1994; Dras, 1999), but only recently in its probabilistic form (Nesson et al., 2006; DeNeefe and Knight, 2009). Shieber (2007) argues that probabilistic synchronous TAG possesses appealing properties such as expressivity and trainability for building a machine translation system. However, one major challenge for applying synchronous TAG to machine translation is computational complexity. While TAG requires O(n6) time for monolingual parsing, synchronous TAG requires O(n12) for bilingual parsing. One solution is to use tree insertion grammars (TIG) introduced by Schabes and Waters (1995). As a restricted form of TAG, TIG still allows for adjoining of unbounded trees but only requires O(n3) time for mon</context>
<context position="4531" citStr="DeNeefe and Knight (2009)" startWordPosition="716" endWordPosition="719">tyle linguistic tree. The target side (English) is a purely structural tree using a single non-terminal (X). By convention, substitution and foot nodes are marked with a down arrow (t) and an asterisk (*), respectively. The dashed lines link substitution sites (e.g., NP↓ and X↓ in 01) and adjoining sites (e.g., NP and X in α2) in tree pairs. Substituting the initial tree pair α1 at the NP↓-X↓ node pair in the auxiliary tree pair 01 yields a derived tree pair 02, which can be adjoined at NN-X in α2 to generate α3. the use of synchronous TIG for machine translation and report promising results. DeNeefe and Knight (2009) prove that adjoining can improve translation quality significantly over a state-of-the-art stringto-tree system (Galley et al., 2006) that uses synchronous TSG with tractable computational complexity. In this paper, we introduce synchronous TAG into tree-to-string translation (Liu et al., 2006; Huang et al., 2006), which is the simplest and fastest among syntax-based approaches (Section 2). We propose a new rule extraction algorithm based on GHKM (Galley et al., 2004) that directly induces a synchronous TAG from an aligned and parsed bilingual corpus without converting Treebank-style trees to</context>
<context position="10367" citStr="DeNeefe and Knight (2009)" startWordPosition="1812" endWordPosition="1815">uting α at η; Pa(β|η) is the probability of adjoining β at η; finally, Pa(NONE|η) is the probability of nothing adjoining at η. For tree-to-string translation, these parameters can be treated as feature functions of a discriminative framework (Och, 2003) combined with other conventional features such as relative frequency, lexical weight, rule count, language model, and word count (Liu et al., 2006). 3 Rule Extraction Inducing a synchronous TAG from training data often begins with converting Treebank-style parse trees to TAG derivations (Xia, 1999; Chen and Vijay-Shanker, 2000; Chiang, 2003). DeNeefe and Knight (2009) propose an algorithm to extract synchronous TIG rules from an aligned and parsed bilingual corpus. They first classify tree nodes into heads, arguments, and adjuncts using heuristics (Collins, 2003), then transform a Treebank-style tree into a TIG derivation, and finally extract minimallysized rules from the derivation tree and the string on the other side, constrained by the alignments. Probabilistic models can be estimated by collecting counts over the derivation trees. However, one challenge is that there are many TAG derivations that can yield the same derived tree, even with respect to a</context>
<context position="15541" citStr="DeNeefe and Knight (2009)" startWordPosition="2688" endWordPosition="2692">he expressive power of synchronous CFG and TSG. Similarly, the composition of two auxiliary rules r8 and r16 yields a new auxiliary rule: ( NP ( NP ( x1:NP* ) ( x2:NP1 ) ) ( x3:NP ) ) → x1x2x3 We first compose initial rules and then compose auxiliary rules, both in a bottom-up way. To maintain a reasonable grammar size, we follow Liu (2006) to restrict that the tree height of a rule is no greater than 3 and the source surface string is no longer than 7. To learn the probability models Pi(α), P3(αJq), Pa(0Jq), and Pa(NONEJq), we collect and normalize counts over these extracted rules following DeNeefe and Knight (2009). 4 Decoding Given a synchronous TAG and a derived source tree 7r, a tree-to-string decoder finds the English yield of the best derivation of which the Chinese yield matches 7r: � 1 e� = e arg max P(D) (4) D s.t. f(D)=7r This is called tree parsing (Eisner, 2003) as the decoder finds ways of decomposing 7r into elementary trees. Tree-to-string decoding with STSG is usually treated as forest rescoring (Huang and Chiang, 2007) that involves two steps. The decoder first converts the input tree into a translation forest using a translation rule set by pattern matching. Huang et al. (2006) show tha</context>
<context position="26268" citStr="DeNeefe and Knight (2009)" startWordPosition="4616" endWordPosition="4619">escendant of the root node in our experiments. Table 3 shows the BLEU scores on the NIST Chinese-English test sets. Our baseline system is the tree-to-string system using STSG (Liu et al., 2006; Huang et al., 2006). The STAG system outperforms the STSG system significantly on the MT04 and MT05 test sets at pl.01 level. Table 3 also gives the results of Moses (Koehn et al., 2007) and an in-house hierarchical phrase-based system (Chiang, 2007). Our STAG system achieves comparable performance with the hierarchical system. The absolute improvement of +0.7 BLEU over STSG is close to the finding of DeNeefe and Knight (2009) on string-to-tree translation. We feel that one major obstacle for achieving further improvement is that composed rules generated on the fly during decoding (e.g., r1 + r3 + r5 in Figure 4) usually have too many non-terminals, making cube pruning in the in1285 STSG STAG matching 0.086 0.109 conversion 0.000 0.562 intersection 0.946 1.064 other 0.012 0.028 total 1.044 1.763 Table 4: Comparison of average decoding time. tersection phase suffering from severe search errors (only a tiny fraction of the search space can be explored). To produce the 1-best translations on the MT05 test set that con</context>
</contexts>
<marker>DeNeefe, Knight, 2009</marker>
<rawString>Steve DeNeefe and Kevin Knight. 2009. Synchronous tree adjoining machine translation. In Proc. of EMNLP 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dras</author>
</authors>
<title>A meta-level grammar: Redefining synchronous tag for translation and paraphrase.</title>
<date>1999</date>
<booktitle>In Proc. ofACL</booktitle>
<contexts>
<context position="2675" citStr="Dras, 1999" startWordPosition="407" endWordPosition="408">ing system, TAG (Joshi et al., 1975; Joshi, 1985) provides a larger domain of locality than CFG to state linguistic dependencies that are far apart since the formalism treats trees as basic building blocks. As a mildly context-sensitive grammar, TAG is conjectured to be powerful enough to model natural languages. Synchronous TAG generalizes TAG by allowing the construction of a pair of trees using the TAG operations of substitution and adjoining on tree pairs. The idea of using synchronous TAG in machine translation has been pursued by several researchers (Abeille et al., 1990; Prigent, 1994; Dras, 1999), but only recently in its probabilistic form (Nesson et al., 2006; DeNeefe and Knight, 2009). Shieber (2007) argues that probabilistic synchronous TAG possesses appealing properties such as expressivity and trainability for building a machine translation system. However, one major challenge for applying synchronous TAG to machine translation is computational complexity. While TAG requires O(n6) time for monolingual parsing, synchronous TAG requires O(n12) for bilingual parsing. One solution is to use tree insertion grammars (TIG) introduced by Schabes and Waters (1995). As a restricted form o</context>
</contexts>
<marker>Dras, 1999</marker>
<rawString>Mark Dras. 1999. A meta-level grammar: Redefining synchronous tag for translation and paraphrase. In Proc. ofACL 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Learning non-isomorphic tree mappings for machine translation.</title>
<date>2003</date>
<booktitle>In Proc. ofACL</booktitle>
<contexts>
<context position="1230" citStr="Eisner, 2003" startWordPosition="169" endWordPosition="170">problem rather than parsing, the decoder still runs fast when adjoining is included. Less than 2 times slower, the adjoining tree-tostring system improves translation quality by +0.7 BLEU over the baseline system only allowing for tree substitution on NIST ChineseEnglish test sets. 1 Introduction Syntax-based translation models, which exploit hierarchical structures of natural languages to guide machine translation, have become increasingly popular in recent years. So far, most of them have been based on synchronous context-free grammars (CFG) (Chiang, 2007), tree substitution grammars (TSG) (Eisner, 2003; Galley et al., 2006; Liu et al., 2006; Huang et al., 2006; Zhang et al., 2008), and inversion transduction grammars (ITG) (Wu, 1997; Xiong et al., 2006). Although these formalisms present simple and precise mechanisms for describing the basic recursive structure of sentences, they are not powerful enough to model some important features of natural language syntax. For example, Chiang (2006) points out that the translation of languages that can stack an unbounded number of clauses in an “inside-out” way (Wu, 1997) provably goes beyond the expressive power of synchronous CFG and TSG. Therefore</context>
<context position="5302" citStr="Eisner, 2003" startWordPosition="836" endWordPosition="837">SG with tractable computational complexity. In this paper, we introduce synchronous TAG into tree-to-string translation (Liu et al., 2006; Huang et al., 2006), which is the simplest and fastest among syntax-based approaches (Section 2). We propose a new rule extraction algorithm based on GHKM (Galley et al., 2004) that directly induces a synchronous TAG from an aligned and parsed bilingual corpus without converting Treebank-style trees to TAG derivations explicitly (Section 3). As tree-tostring translation takes a source parse tree as input, the decoding can be cast as a tree parsing problem (Eisner, 2003): reconstructing TAG derivations from a derived tree using tree-to-string rules that allow for both substitution and adjoining. We describe how to convert TAG derivations to translation forest (Section 4). We evaluated the new tree-to-string system on NIST Chinese-English tests and obtained consistent improvements (+0.7 BLEU) over the STSGbased baseline system without significant loss in efficiency (1.6 times slower) (Section 5). 2 Model A synchronous TAG consists of a set of linked elementary tree pairs: initial and auxiliary. An initial tree is a tree of which the interior nodes are all labe</context>
<context position="15804" citStr="Eisner, 2003" startWordPosition="2740" endWordPosition="2741">up way. To maintain a reasonable grammar size, we follow Liu (2006) to restrict that the tree height of a rule is no greater than 3 and the source surface string is no longer than 7. To learn the probability models Pi(α), P3(αJq), Pa(0Jq), and Pa(NONEJq), we collect and normalize counts over these extracted rules following DeNeefe and Knight (2009). 4 Decoding Given a synchronous TAG and a derived source tree 7r, a tree-to-string decoder finds the English yield of the best derivation of which the Chinese yield matches 7r: � 1 e� = e arg max P(D) (4) D s.t. f(D)=7r This is called tree parsing (Eisner, 2003) as the decoder finds ways of decomposing 7r into elementary trees. Tree-to-string decoding with STSG is usually treated as forest rescoring (Huang and Chiang, 2007) that involves two steps. The decoder first converts the input tree into a translation forest using a translation rule set by pattern matching. Huang et al. (2006) show that this step is a depth-first search with memorization in O(n) time. Then, the decoder searches for the best derivation in the translation forest intersected with n-gram language models and outputs the target string. 2 Decoding with STAG, however, poses one major </context>
</contexts>
<marker>Eisner, 2003</marker>
<rawString>Jason Eisner. 2003. Learning non-isomorphic tree mappings for machine translation. In Proc. ofACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>What’s in a translation rule?</title>
<date>2004</date>
<booktitle>In Proc. ofNAACL</booktitle>
<contexts>
<context position="5004" citStr="Galley et al., 2004" startWordPosition="787" endWordPosition="790">e adjoined at NN-X in α2 to generate α3. the use of synchronous TIG for machine translation and report promising results. DeNeefe and Knight (2009) prove that adjoining can improve translation quality significantly over a state-of-the-art stringto-tree system (Galley et al., 2006) that uses synchronous TSG with tractable computational complexity. In this paper, we introduce synchronous TAG into tree-to-string translation (Liu et al., 2006; Huang et al., 2006), which is the simplest and fastest among syntax-based approaches (Section 2). We propose a new rule extraction algorithm based on GHKM (Galley et al., 2004) that directly induces a synchronous TAG from an aligned and parsed bilingual corpus without converting Treebank-style trees to TAG derivations explicitly (Section 3). As tree-tostring translation takes a source parse tree as input, the decoding can be cast as a tree parsing problem (Eisner, 2003): reconstructing TAG derivations from a derived tree using tree-to-string rules that allow for both substitution and adjoining. We describe how to convert TAG derivations to translation forest (Section 4). We evaluated the new tree-to-string system on NIST Chinese-English tests and obtained consistent</context>
<context position="11426" citStr="Galley et al., 2004" startWordPosition="1979" endWordPosition="1982">ting counts over the derivation trees. However, one challenge is that there are many TAG derivations that can yield the same derived tree, even with respect to a single grammar. It is difficult to choose appropriate single derivations that enable the resulting grammar to translate unseen data well. DeNeefe and Knight (2009) indicate that the way to reconstruct TIG derivations has a direct effect on final translation quality. They suggest that one possible solution is to use derivation forest rather than a single derivation tree for rule extraction. Alternatively, we extend the GHKM algorithm (Galley et al., 2004) to directly extract tree-to-string rules that allow for both substitution and adjoining from aligned and parsed data. There is no need for transforming a parse tree into a TAG derivation explicitly before rule extraction and all derivations can be easily reconstructed using extracted rules. 1 Our rule extraction algorithm involves two steps: (1) extracting minimal rules and (2) composition. 3.1 Extracting Minimal Rules Figure 2 shows a training example, which consists of a Chinese parse tree, an English string, and the word alignment between them. By convention, shaded nodes are called fronti</context>
<context position="13181" citStr="Galley et al., 2004" startWordPosition="2270" endWordPosition="2273">d make our system more robust in the presence of noisy data. It is possible to use the linguistic preferences as features. We leave this for future work. 1281 to-string rules: 1. substitution rules, in which the source tree is an initial tree without adjoining sites. 2. adjoining rules, in which the source tree is an initial tree with at least one adjoining site. 3. auxiliary rules, in which the source tree is an auxiliary tree. For example, in Figure 1, α1 is a substitution rule, α2 is an adjoining rule, and 01 is an auxiliary rule. Minimal substitution rules are the same with those in STSG (Galley et al., 2004; Liu et al., 2006) and therefore can be extracted directly using GHKM. By minimal, we mean that the interior nodes are not frontier and cannot be decomposed. For example, in Table 2, rule 1 (for short r1) is a minimal substitution rule extracted from NR0,1. Minimal adjoining rules are defined as minimal substitution rules, except that each root node must be an adjoining site. In Table 2, r2 is a minimal substitution rule extracted from NP0,1. As NP0,1 is a descendant of NP0,2 with the same label, NP0,1 is a possible adjoining site. Therefore, r6 can be derived from r2 and licensed as a minima</context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What’s in a translation rule? In Proc. ofNAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Steve DeNeefe</author>
<author>Wei Wang</author>
<author>Ignacio Thayer</author>
</authors>
<title>Scalable inference and training of context-rich syntactic translation models.</title>
<date>2006</date>
<booktitle>In Proc. of ACL</booktitle>
<contexts>
<context position="1251" citStr="Galley et al., 2006" startWordPosition="171" endWordPosition="174"> than parsing, the decoder still runs fast when adjoining is included. Less than 2 times slower, the adjoining tree-tostring system improves translation quality by +0.7 BLEU over the baseline system only allowing for tree substitution on NIST ChineseEnglish test sets. 1 Introduction Syntax-based translation models, which exploit hierarchical structures of natural languages to guide machine translation, have become increasingly popular in recent years. So far, most of them have been based on synchronous context-free grammars (CFG) (Chiang, 2007), tree substitution grammars (TSG) (Eisner, 2003; Galley et al., 2006; Liu et al., 2006; Huang et al., 2006; Zhang et al., 2008), and inversion transduction grammars (ITG) (Wu, 1997; Xiong et al., 2006). Although these formalisms present simple and precise mechanisms for describing the basic recursive structure of sentences, they are not powerful enough to model some important features of natural language syntax. For example, Chiang (2006) points out that the translation of languages that can stack an unbounded number of clauses in an “inside-out” way (Wu, 1997) provably goes beyond the expressive power of synchronous CFG and TSG. Therefore, it is necessary to </context>
<context position="4665" citStr="Galley et al., 2006" startWordPosition="734" endWordPosition="737">d foot nodes are marked with a down arrow (t) and an asterisk (*), respectively. The dashed lines link substitution sites (e.g., NP↓ and X↓ in 01) and adjoining sites (e.g., NP and X in α2) in tree pairs. Substituting the initial tree pair α1 at the NP↓-X↓ node pair in the auxiliary tree pair 01 yields a derived tree pair 02, which can be adjoined at NN-X in α2 to generate α3. the use of synchronous TIG for machine translation and report promising results. DeNeefe and Knight (2009) prove that adjoining can improve translation quality significantly over a state-of-the-art stringto-tree system (Galley et al., 2006) that uses synchronous TSG with tractable computational complexity. In this paper, we introduce synchronous TAG into tree-to-string translation (Liu et al., 2006; Huang et al., 2006), which is the simplest and fastest among syntax-based approaches (Section 2). We propose a new rule extraction algorithm based on GHKM (Galley et al., 2004) that directly induces a synchronous TAG from an aligned and parsed bilingual corpus without converting Treebank-style trees to TAG derivations explicitly (Section 3). As tree-tostring translation takes a source parse tree as input, the decoding can be cast as </context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, DeNeefe, Wang, Thayer, 2006</marker>
<rawString>Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve DeNeefe, Wei Wang, and Ignacio Thayer. 2006. Scalable inference and training of context-rich syntactic translation models. In Proc. of ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Forest rescoring: Faster decoding with integrated language models.</title>
<date>2007</date>
<booktitle>In Proc. ofACL</booktitle>
<contexts>
<context position="15969" citStr="Huang and Chiang, 2007" startWordPosition="2764" endWordPosition="2767">string is no longer than 7. To learn the probability models Pi(α), P3(αJq), Pa(0Jq), and Pa(NONEJq), we collect and normalize counts over these extracted rules following DeNeefe and Knight (2009). 4 Decoding Given a synchronous TAG and a derived source tree 7r, a tree-to-string decoder finds the English yield of the best derivation of which the Chinese yield matches 7r: � 1 e� = e arg max P(D) (4) D s.t. f(D)=7r This is called tree parsing (Eisner, 2003) as the decoder finds ways of decomposing 7r into elementary trees. Tree-to-string decoding with STSG is usually treated as forest rescoring (Huang and Chiang, 2007) that involves two steps. The decoder first converts the input tree into a translation forest using a translation rule set by pattern matching. Huang et al. (2006) show that this step is a depth-first search with memorization in O(n) time. Then, the decoder searches for the best derivation in the translation forest intersected with n-gram language models and outputs the target string. 2 Decoding with STAG, however, poses one major challenge to forest rescoring. As translation forest only supports substitution, it is difficult to construct a translation forest for STAG derivations because of 2M</context>
<context position="22829" citStr="Huang and Chiang, 2007" startWordPosition="4018" endWordPosition="4022">e with at least one adjoining site. The descendants of the root node must all be auxiliary trees. For example, ( α1 ( 02 ) ) and ( α1 ( 01 ( 03 ) ) ) are two composition trees in Figure 4. The number of children of a node in a composition tree depends on the number of adjoining sites in the node. We use composition forest to encode all possible composition trees. Often, a node in a composition tree may have multiple matched rules. As a large amount of composition trees and composed rules can be identified and constructed on the fly during forest conversion, we used cube pruning (Chiang, 2007; Huang and Chiang, 2007) to achieve a balance between translation quality and decoding efficiency. 1284 category description number VP verb phrase NP noun phrase IP simple clause QP quantifier phrase CP clause headed by C PP preposition phrase CLP classifier phrase ADJP adjective phrase LCP phrase formed by “XP+LC” DNP phrase formed by “XP+DEG” Table 2: Top-10 phrase categories of foot nodes and their average occurrences in training corpus. 12.40 7.69 7.26 0.14 0.10 0.09 0.02 0.02 0.02 0.01 VP IP NP 0 1 2 3 4 5 6 7 8 9 10 11 distance 4.5 4.0 average occurrence 3.5 3.0 2.5 2.0 1.5 1.0 0.5 0.0 Figure 5: Average occurre</context>
</contexts>
<marker>Huang, Chiang, 2007</marker>
<rawString>Liang Huang and David Chiang. 2007. Forest rescoring: Faster decoding with integrated language models. In Proc. ofACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Haitao Mi</author>
</authors>
<title>Efficient incremental decoding for tree-to-string translation.</title>
<date>2010</date>
<booktitle>In Proc. of EMNLP</booktitle>
<contexts>
<context position="16666" citStr="Huang and Mi (2010)" startWordPosition="2876" endWordPosition="2879">nslation forest using a translation rule set by pattern matching. Huang et al. (2006) show that this step is a depth-first search with memorization in O(n) time. Then, the decoder searches for the best derivation in the translation forest intersected with n-gram language models and outputs the target string. 2 Decoding with STAG, however, poses one major challenge to forest rescoring. As translation forest only supports substitution, it is difficult to construct a translation forest for STAG derivations because of 2Mi et al. (2008) give a detailed description of the two-step decoding process. Huang and Mi (2010) systematically analyze the decoding complexity of tree-to-string translation. 1282 α2 NR2,3 ,1*1,E—!� aobama α3 NN2,3 1;:IL� zongtong α1 IP0,8 NP2,3 VP3,8 ↓ NR2,3 ↓ β2 NP0,3 NP0,2 NP2,3 ↓ ∗ β3 NP0,2 1,2 NP0,1 NP∗ NR0,1 ↓ β1 NP0,3 NP1,2 NP2,3 ∗ NN1,2 ↓ elementary tree translation rule α1 r1 ( IP ( NP0:1 ( x1:NR↓ ) ) ( x2:VP↓ ) ) → x1 x2 α��2 r2 ( NR `aob¯amˇa ) → Obama / /�1 r3 ( NP ( NP0:1 ( x1:NN↓ ) ) ( x2:NP∗ ) ) → x1 x2 /N2 r4 ( NP ( x1:NP↓ ) ( x2:NP∗ ) ) → x1 x2 N3 r5 ( NP ( NP ( x1:NR↓ ) ) ( x2:NP∗ ) ) → x1 x2 α3 rs ( NN zˇongtˇong ) → President Figure 3: Matched trees and corresponding </context>
</contexts>
<marker>Huang, Mi, 2010</marker>
<rawString>Liang Huang and Haitao Mi. 2010. Efficient incremental decoding for tree-to-string translation. In Proc. of EMNLP 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kevin Knight</author>
<author>Aravind Joshi</author>
</authors>
<title>Statistical syntax-directed translation with extended domain of locality.</title>
<date>2006</date>
<booktitle>In Proc. ofAMTA</booktitle>
<contexts>
<context position="1289" citStr="Huang et al., 2006" startWordPosition="179" endWordPosition="182">ast when adjoining is included. Less than 2 times slower, the adjoining tree-tostring system improves translation quality by +0.7 BLEU over the baseline system only allowing for tree substitution on NIST ChineseEnglish test sets. 1 Introduction Syntax-based translation models, which exploit hierarchical structures of natural languages to guide machine translation, have become increasingly popular in recent years. So far, most of them have been based on synchronous context-free grammars (CFG) (Chiang, 2007), tree substitution grammars (TSG) (Eisner, 2003; Galley et al., 2006; Liu et al., 2006; Huang et al., 2006; Zhang et al., 2008), and inversion transduction grammars (ITG) (Wu, 1997; Xiong et al., 2006). Although these formalisms present simple and precise mechanisms for describing the basic recursive structure of sentences, they are not powerful enough to model some important features of natural language syntax. For example, Chiang (2006) points out that the translation of languages that can stack an unbounded number of clauses in an “inside-out” way (Wu, 1997) provably goes beyond the expressive power of synchronous CFG and TSG. Therefore, it is necessary to find ways to take advantage of more po</context>
<context position="4847" citStr="Huang et al., 2006" startWordPosition="762" endWordPosition="765">in α2) in tree pairs. Substituting the initial tree pair α1 at the NP↓-X↓ node pair in the auxiliary tree pair 01 yields a derived tree pair 02, which can be adjoined at NN-X in α2 to generate α3. the use of synchronous TIG for machine translation and report promising results. DeNeefe and Knight (2009) prove that adjoining can improve translation quality significantly over a state-of-the-art stringto-tree system (Galley et al., 2006) that uses synchronous TSG with tractable computational complexity. In this paper, we introduce synchronous TAG into tree-to-string translation (Liu et al., 2006; Huang et al., 2006), which is the simplest and fastest among syntax-based approaches (Section 2). We propose a new rule extraction algorithm based on GHKM (Galley et al., 2004) that directly induces a synchronous TAG from an aligned and parsed bilingual corpus without converting Treebank-style trees to TAG derivations explicitly (Section 3). As tree-tostring translation takes a source parse tree as input, the decoding can be cast as a tree parsing problem (Eisner, 2003): reconstructing TAG derivations from a derived tree using tree-to-string rules that allow for both substitution and adjoining. We describe how t</context>
<context position="16132" citStr="Huang et al. (2006)" startWordPosition="2792" endWordPosition="2795">ng DeNeefe and Knight (2009). 4 Decoding Given a synchronous TAG and a derived source tree 7r, a tree-to-string decoder finds the English yield of the best derivation of which the Chinese yield matches 7r: � 1 e� = e arg max P(D) (4) D s.t. f(D)=7r This is called tree parsing (Eisner, 2003) as the decoder finds ways of decomposing 7r into elementary trees. Tree-to-string decoding with STSG is usually treated as forest rescoring (Huang and Chiang, 2007) that involves two steps. The decoder first converts the input tree into a translation forest using a translation rule set by pattern matching. Huang et al. (2006) show that this step is a depth-first search with memorization in O(n) time. Then, the decoder searches for the best derivation in the translation forest intersected with n-gram language models and outputs the target string. 2 Decoding with STAG, however, poses one major challenge to forest rescoring. As translation forest only supports substitution, it is difficult to construct a translation forest for STAG derivations because of 2Mi et al. (2008) give a detailed description of the two-step decoding process. Huang and Mi (2010) systematically analyze the decoding complexity of tree-to-string </context>
<context position="25857" citStr="Huang et al., 2006" startWordPosition="4547" endWordPosition="4550">STAG 33.64 35.28 32.71 Table 3: BLEU scores on NIST Chinese-English test sets. Scores marked in bold are significantly better that those of STSG at pl.01 level. and the root node. For example, in Figure 2, the distance between NP0,1 and NP0,3 is 2 and the distance between VP6,8 and VP3,8 is 1. As most foot nodes are usually very close to the root nodes, we restrict that a foot node must be the direct descendant of the root node in our experiments. Table 3 shows the BLEU scores on the NIST Chinese-English test sets. Our baseline system is the tree-to-string system using STSG (Liu et al., 2006; Huang et al., 2006). The STAG system outperforms the STSG system significantly on the MT04 and MT05 test sets at pl.01 level. Table 3 also gives the results of Moses (Koehn et al., 2007) and an in-house hierarchical phrase-based system (Chiang, 2007). Our STAG system achieves comparable performance with the hierarchical system. The absolute improvement of +0.7 BLEU over STSG is close to the finding of DeNeefe and Knight (2009) on string-to-tree translation. We feel that one major obstacle for achieving further improvement is that composed rules generated on the fly during decoding (e.g., r1 + r3 + r5 in Figure 4</context>
</contexts>
<marker>Huang, Knight, Joshi, 2006</marker>
<rawString>Liang Huang, Kevin Knight, and Aravind Joshi. 2006. Statistical syntax-directed translation with extended domain of locality. In Proc. ofAMTA 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind Joshi</author>
<author>L Levy</author>
<author>M Takahashi</author>
</authors>
<title>Tree adjunct grammars.</title>
<date>1975</date>
<journal>Journal of Computer and System Sciences,</journal>
<volume>10</volume>
<issue>1</issue>
<contexts>
<context position="2099" citStr="Joshi et al., 1975" startWordPosition="310" endWordPosition="313">ive structure of sentences, they are not powerful enough to model some important features of natural language syntax. For example, Chiang (2006) points out that the translation of languages that can stack an unbounded number of clauses in an “inside-out” way (Wu, 1997) provably goes beyond the expressive power of synchronous CFG and TSG. Therefore, it is necessary to find ways to take advantage of more powerful synchronous grammars to improve machine translation. Synchronous tree adjoining grammars (TAG) (Shieber and Schabes, 1990) are a good candidate. As a formal tree rewriting system, TAG (Joshi et al., 1975; Joshi, 1985) provides a larger domain of locality than CFG to state linguistic dependencies that are far apart since the formalism treats trees as basic building blocks. As a mildly context-sensitive grammar, TAG is conjectured to be powerful enough to model natural languages. Synchronous TAG generalizes TAG by allowing the construction of a pair of trees using the TAG operations of substitution and adjoining on tree pairs. The idea of using synchronous TAG in machine translation has been pursued by several researchers (Abeille et al., 1990; Prigent, 1994; Dras, 1999), but only recently in i</context>
</contexts>
<marker>Joshi, Levy, Takahashi, 1975</marker>
<rawString>Aravind Joshi, L. Levy, and M. Takahashi. 1975. Tree adjunct grammars. Journal of Computer and System Sciences, 10(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind Joshi</author>
</authors>
<title>How much contextsensitivity is necessary for characterizing structural descriptions-tree adjoining grammars. Natural Language Processing-Theoretical, Computational, and Psychological Perspectives.</title>
<date>1985</date>
<contexts>
<context position="2113" citStr="Joshi, 1985" startWordPosition="314" endWordPosition="315">tences, they are not powerful enough to model some important features of natural language syntax. For example, Chiang (2006) points out that the translation of languages that can stack an unbounded number of clauses in an “inside-out” way (Wu, 1997) provably goes beyond the expressive power of synchronous CFG and TSG. Therefore, it is necessary to find ways to take advantage of more powerful synchronous grammars to improve machine translation. Synchronous tree adjoining grammars (TAG) (Shieber and Schabes, 1990) are a good candidate. As a formal tree rewriting system, TAG (Joshi et al., 1975; Joshi, 1985) provides a larger domain of locality than CFG to state linguistic dependencies that are far apart since the formalism treats trees as basic building blocks. As a mildly context-sensitive grammar, TAG is conjectured to be powerful enough to model natural languages. Synchronous TAG generalizes TAG by allowing the construction of a pair of trees using the TAG operations of substitution and adjoining on tree pairs. The idea of using synchronous TAG in machine translation has been pursued by several researchers (Abeille et al., 1990; Prigent, 1994; Dras, 1999), but only recently in its probabilist</context>
<context position="20250" citStr="Joshi, 1985" startWordPosition="3560" endWordPosition="3561">ming that every node in the input tree is frontier (see Section 3). We impose the same restrictions on the tree height and length as in rule extraction. Figure 3 shows some matched trees and corresponding rules. Each node in a matched tree is annotated with a span as superscript to facilitate identification. For example, IP0,8 in α1 means that IP0,8 in Figure 2 is matched. Note that its left child NP2,3 is not its direct descendant in Figure 2, suggesting that adjoining is required at this site. A TAG derivation tree specifies uniquely how a derived tree is constructed using elementary trees (Joshi, 1985). A node in a derivation tree is an elementary tree and an edge corresponds to operations on related elementary trees: substitution or adjoining. We introduce TAG derivation forest, a compact representation of multiple TAG derivation trees, to encodes all matched TAG derivation trees of the input derived tree. Figure 4 shows part of a TAG derivation forest. The six matched elementary trees are nodes in the derivation forest. Dashed and solid lines represent substitution and adjoining, respectively. We use Gorn addresses as tree addresses: 0 is the address of the root node, p is the address of </context>
</contexts>
<marker>Joshi, 1985</marker>
<rawString>Aravind Joshi. 1985. How much contextsensitivity is necessary for characterizing structural descriptions-tree adjoining grammars. Natural Language Processing-Theoretical, Computational, and Psychological Perspectives.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>77--80</pages>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="26024" citStr="Koehn et al., 2007" startWordPosition="4578" endWordPosition="4581">e root node. For example, in Figure 2, the distance between NP0,1 and NP0,3 is 2 and the distance between VP6,8 and VP3,8 is 1. As most foot nodes are usually very close to the root nodes, we restrict that a foot node must be the direct descendant of the root node in our experiments. Table 3 shows the BLEU scores on the NIST Chinese-English test sets. Our baseline system is the tree-to-string system using STSG (Liu et al., 2006; Huang et al., 2006). The STAG system outperforms the STSG system significantly on the MT04 and MT05 test sets at pl.01 level. Table 3 also gives the results of Moses (Koehn et al., 2007) and an in-house hierarchical phrase-based system (Chiang, 2007). Our STAG system achieves comparable performance with the hierarchical system. The absolute improvement of +0.7 BLEU over STSG is close to the finding of DeNeefe and Knight (2009) on string-to-tree translation. We feel that one major obstacle for achieving further improvement is that composed rules generated on the fly during decoding (e.g., r1 + r3 + r5 in Figure 4) usually have too many non-terminals, making cube pruning in the in1285 STSG STAG matching 0.086 0.109 conversion 0.000 0.562 intersection 0.946 1.064 other 0.012 0.0</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of ACL 2007 (poster), pages 77–80, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Tree-tostring alignment template for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proc. ofACL</booktitle>
<contexts>
<context position="1269" citStr="Liu et al., 2006" startWordPosition="175" endWordPosition="178">coder still runs fast when adjoining is included. Less than 2 times slower, the adjoining tree-tostring system improves translation quality by +0.7 BLEU over the baseline system only allowing for tree substitution on NIST ChineseEnglish test sets. 1 Introduction Syntax-based translation models, which exploit hierarchical structures of natural languages to guide machine translation, have become increasingly popular in recent years. So far, most of them have been based on synchronous context-free grammars (CFG) (Chiang, 2007), tree substitution grammars (TSG) (Eisner, 2003; Galley et al., 2006; Liu et al., 2006; Huang et al., 2006; Zhang et al., 2008), and inversion transduction grammars (ITG) (Wu, 1997; Xiong et al., 2006). Although these formalisms present simple and precise mechanisms for describing the basic recursive structure of sentences, they are not powerful enough to model some important features of natural language syntax. For example, Chiang (2006) points out that the translation of languages that can stack an unbounded number of clauses in an “inside-out” way (Wu, 1997) provably goes beyond the expressive power of synchronous CFG and TSG. Therefore, it is necessary to find ways to take </context>
<context position="4826" citStr="Liu et al., 2006" startWordPosition="758" endWordPosition="761">s (e.g., NP and X in α2) in tree pairs. Substituting the initial tree pair α1 at the NP↓-X↓ node pair in the auxiliary tree pair 01 yields a derived tree pair 02, which can be adjoined at NN-X in α2 to generate α3. the use of synchronous TIG for machine translation and report promising results. DeNeefe and Knight (2009) prove that adjoining can improve translation quality significantly over a state-of-the-art stringto-tree system (Galley et al., 2006) that uses synchronous TSG with tractable computational complexity. In this paper, we introduce synchronous TAG into tree-to-string translation (Liu et al., 2006; Huang et al., 2006), which is the simplest and fastest among syntax-based approaches (Section 2). We propose a new rule extraction algorithm based on GHKM (Galley et al., 2004) that directly induces a synchronous TAG from an aligned and parsed bilingual corpus without converting Treebank-style trees to TAG derivations explicitly (Section 3). As tree-tostring translation takes a source parse tree as input, the decoding can be cast as a tree parsing problem (Eisner, 2003): reconstructing TAG derivations from a derived tree using tree-to-string rules that allow for both substitution and adjoini</context>
<context position="10144" citStr="Liu et al., 2006" startWordPosition="1780" endWordPosition="1783">|η) + Pa(NONE|η) = 1 (3) a where α ranges over initial tree pairs, β over auxiliary tree pairs, and η over node pairs. Pi(α) is the probability of beginning a derivation with α; Ps(α|η) is the probability of substituting α at η; Pa(β|η) is the probability of adjoining β at η; finally, Pa(NONE|η) is the probability of nothing adjoining at η. For tree-to-string translation, these parameters can be treated as feature functions of a discriminative framework (Och, 2003) combined with other conventional features such as relative frequency, lexical weight, rule count, language model, and word count (Liu et al., 2006). 3 Rule Extraction Inducing a synchronous TAG from training data often begins with converting Treebank-style parse trees to TAG derivations (Xia, 1999; Chen and Vijay-Shanker, 2000; Chiang, 2003). DeNeefe and Knight (2009) propose an algorithm to extract synchronous TIG rules from an aligned and parsed bilingual corpus. They first classify tree nodes into heads, arguments, and adjuncts using heuristics (Collins, 2003), then transform a Treebank-style tree into a TIG derivation, and finally extract minimallysized rules from the derivation tree and the string on the other side, constrained by t</context>
<context position="13200" citStr="Liu et al., 2006" startWordPosition="2274" endWordPosition="2277">e robust in the presence of noisy data. It is possible to use the linguistic preferences as features. We leave this for future work. 1281 to-string rules: 1. substitution rules, in which the source tree is an initial tree without adjoining sites. 2. adjoining rules, in which the source tree is an initial tree with at least one adjoining site. 3. auxiliary rules, in which the source tree is an auxiliary tree. For example, in Figure 1, α1 is a substitution rule, α2 is an adjoining rule, and 01 is an auxiliary rule. Minimal substitution rules are the same with those in STSG (Galley et al., 2004; Liu et al., 2006) and therefore can be extracted directly using GHKM. By minimal, we mean that the interior nodes are not frontier and cannot be decomposed. For example, in Table 2, rule 1 (for short r1) is a minimal substitution rule extracted from NR0,1. Minimal adjoining rules are defined as minimal substitution rules, except that each root node must be an adjoining site. In Table 2, r2 is a minimal substitution rule extracted from NP0,1. As NP0,1 is a descendant of NP0,2 with the same label, NP0,1 is a possible adjoining site. Therefore, r6 can be derived from r2 and licensed as a minimal adjoining rule ex</context>
<context position="19423" citStr="Liu et al. (2006)" startWordPosition="3417" endWordPosition="3420"> � of address 1.1 (i.e., the first child of the first child of the root node) and 01 is adjoined in the tree α1 at the node NP2,3 of address 1. 2. conversion, converting the TAG derivation forest into a translation forest; 3. intersection, intersecting the translation forest with an n-gram language model. Given a tree-to-string rule, rule matching is to find a subtree of the input tree that is identical to the source side of the rule. While matching STSG rules against a derived tree is straightforward, it is somewhat non-trivial for STAG rules that move beyond nodes of a local tree. We follow Liu et al. (2006) to enumerate all elementary subtrees and match STAG rules against these subtrees. This can be done by first enumerating all minimal initial and auxiliary trees and then combining them to obtain composed trees, assuming that every node in the input tree is frontier (see Section 3). We impose the same restrictions on the tree height and length as in rule extraction. Figure 3 shows some matched trees and corresponding rules. Each node in a matched tree is annotated with a span as superscript to facilitate identification. For example, IP0,8 in α1 means that IP0,8 in Figure 2 is matched. Note that</context>
<context position="23844" citStr="Liu et al. (2006)" startWordPosition="4191" endWordPosition="4194">es in training corpus. 12.40 7.69 7.26 0.14 0.10 0.09 0.02 0.02 0.02 0.01 VP IP NP 0 1 2 3 4 5 6 7 8 9 10 11 distance 4.5 4.0 average occurrence 3.5 3.0 2.5 2.0 1.5 1.0 0.5 0.0 Figure 5: Average occurrences of foot node labels VP, NP, and IP over various distances. 5 Evaluation We evaluated our adjoining tree-to-string translation system on Chinese-English translation. The bilingual corpus consists of 1.5M sentences with 42.1M Chinese words and 48.3M English words. The Chinese sentences in the bilingual corpus were parsed by an in-house parser. To maintain a reasonable grammar size, we follow Liu et al. (2006) to restrict that the height of a rule tree is no greater than 3 and the surface string’s length is no greater than 7. After running GIZA++ (Och and Ney, 2003) to obtain word alignment, our rule extraction algorithm extracted 23.0M initial rules without adjoining sites, 6.6M initial rules with adjoining sites, and 5.3M auxiliary rules. We used the SRILM toolkit (Stolcke, 2002) to train a 4-gram language model on the Xinhua portion of the GIGAWORD corpus, which contains 238M English words. We used the 2002 NIST MT Chinese-English test set as the development set and the 2003-2005 NIST test sets </context>
<context position="25836" citStr="Liu et al., 2006" startWordPosition="4543" endWordPosition="4546">33.13 34.55 31.94 STAG 33.64 35.28 32.71 Table 3: BLEU scores on NIST Chinese-English test sets. Scores marked in bold are significantly better that those of STSG at pl.01 level. and the root node. For example, in Figure 2, the distance between NP0,1 and NP0,3 is 2 and the distance between VP6,8 and VP3,8 is 1. As most foot nodes are usually very close to the root nodes, we restrict that a foot node must be the direct descendant of the root node in our experiments. Table 3 shows the BLEU scores on the NIST Chinese-English test sets. Our baseline system is the tree-to-string system using STSG (Liu et al., 2006; Huang et al., 2006). The STAG system outperforms the STSG system significantly on the MT04 and MT05 test sets at pl.01 level. Table 3 also gives the results of Moses (Koehn et al., 2007) and an in-house hierarchical phrase-based system (Chiang, 2007). Our STAG system achieves comparable performance with the hierarchical system. The absolute improvement of +0.7 BLEU over STSG is close to the finding of DeNeefe and Knight (2009) on string-to-tree translation. We feel that one major obstacle for achieving further improvement is that composed rules generated on the fly during decoding (e.g., r1 </context>
</contexts>
<marker>Liu, Liu, Lin, 2006</marker>
<rawString>Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-tostring alignment template for statistical machine translation. In Proc. ofACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Yajuan L¨u</author>
<author>Qun Liu</author>
</authors>
<title>Improving tree-to-tree translation with packed forests.</title>
<date>2009</date>
<booktitle>In Proc. of ACL</booktitle>
<marker>Liu, L¨u, Liu, 2009</marker>
<rawString>Yang Liu, Yajuan L¨u, and Qun Liu. 2009. Improving tree-to-tree translation with packed forests. In Proc. of ACL 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haitao Mi</author>
<author>Liang Huang</author>
</authors>
<title>Forest-based translation rule extraction.</title>
<date>2008</date>
<booktitle>In Proceedings ofEMNLP</booktitle>
<marker>Mi, Huang, 2008</marker>
<rawString>Haitao Mi and Liang Huang. 2008. Forest-based translation rule extraction. In Proceedings ofEMNLP 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haitao Mi</author>
<author>Liang Huang</author>
<author>Qun Liu</author>
</authors>
<title>Forestbased translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL/HLT</booktitle>
<pages>192--199</pages>
<location>Columbus, Ohio, USA,</location>
<contexts>
<context position="16584" citStr="Mi et al. (2008)" startWordPosition="2863" endWordPosition="2866">) that involves two steps. The decoder first converts the input tree into a translation forest using a translation rule set by pattern matching. Huang et al. (2006) show that this step is a depth-first search with memorization in O(n) time. Then, the decoder searches for the best derivation in the translation forest intersected with n-gram language models and outputs the target string. 2 Decoding with STAG, however, poses one major challenge to forest rescoring. As translation forest only supports substitution, it is difficult to construct a translation forest for STAG derivations because of 2Mi et al. (2008) give a detailed description of the two-step decoding process. Huang and Mi (2010) systematically analyze the decoding complexity of tree-to-string translation. 1282 α2 NR2,3 ,1*1,E—!� aobama α3 NN2,3 1;:IL� zongtong α1 IP0,8 NP2,3 VP3,8 ↓ NR2,3 ↓ β2 NP0,3 NP0,2 NP2,3 ↓ ∗ β3 NP0,2 1,2 NP0,1 NP∗ NR0,1 ↓ β1 NP0,3 NP1,2 NP2,3 ∗ NN1,2 ↓ elementary tree translation rule α1 r1 ( IP ( NP0:1 ( x1:NR↓ ) ) ( x2:VP↓ ) ) → x1 x2 α��2 r2 ( NR `aob¯amˇa ) → Obama / /�1 r3 ( NP ( NP0:1 ( x1:NN↓ ) ) ( x2:NP∗ ) ) → x1 x2 /N2 r4 ( NP ( x1:NP↓ ) ( x2:NP∗ ) ) → x1 x2 N3 r5 ( NP ( NP ( x1:NR↓ ) ) ( x2:NP∗ ) ) → x1</context>
<context position="21186" citStr="Mi et al. (2008)" startWordPosition="3722" endWordPosition="3725"> shows part of a TAG derivation forest. The six matched elementary trees are nodes in the derivation forest. Dashed and solid lines represent substitution and adjoining, respectively. We use Gorn addresses as tree addresses: 0 is the address of the root node, p is the address of the pth child of the root node, and p · q is the address of the qth child of the node at the address p. The derivation forest To take advantage of existing decoding techniques, it is necessary to convert a derivation forest to a translation forest. A hyperedge in a translation forest corresponds to a translation rule. Mi et al. (2008) describe how to convert a derived tree to a translation forest using tree-to-string rules only allowing for substitution. Unfortunately, it is not straightforward to convert a derivation forest including adjoining to a translation forest. To alleviate this problem, we combine initial rules with adjoining sites and associated auxiliary rules to form equivalent initial rules without adjoining sites on the fly during decoding. Consider α1 in Figure 3. It has an adjoining site NP2,3. Adjoining 02 in α1 at the node NP2,3 produces an equivalent initial tree with only substitution sites: ( IP0,8 (NP</context>
</contexts>
<marker>Mi, Huang, Liu, 2008</marker>
<rawString>Haitao Mi, Liang Huang, and Qun Liu. 2008. Forestbased translation. In Proceedings of ACL/HLT 2008, pages 192–199, Columbus, Ohio, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Nesson</author>
<author>Stuart Shieber</author>
<author>Alexander Rush</author>
</authors>
<title>Induction of probabilistic synchronous treeinsertion grammars for machine translation.</title>
<date>2006</date>
<booktitle>In Proc. ofAMTA</booktitle>
<contexts>
<context position="2741" citStr="Nesson et al., 2006" startWordPosition="416" endWordPosition="419"> a larger domain of locality than CFG to state linguistic dependencies that are far apart since the formalism treats trees as basic building blocks. As a mildly context-sensitive grammar, TAG is conjectured to be powerful enough to model natural languages. Synchronous TAG generalizes TAG by allowing the construction of a pair of trees using the TAG operations of substitution and adjoining on tree pairs. The idea of using synchronous TAG in machine translation has been pursued by several researchers (Abeille et al., 1990; Prigent, 1994; Dras, 1999), but only recently in its probabilistic form (Nesson et al., 2006; DeNeefe and Knight, 2009). Shieber (2007) argues that probabilistic synchronous TAG possesses appealing properties such as expressivity and trainability for building a machine translation system. However, one major challenge for applying synchronous TAG to machine translation is computational complexity. While TAG requires O(n6) time for monolingual parsing, synchronous TAG requires O(n12) for bilingual parsing. One solution is to use tree insertion grammars (TIG) introduced by Schabes and Waters (1995). As a restricted form of TAG, TIG still allows for adjoining of unbounded trees but only </context>
</contexts>
<marker>Nesson, Shieber, Rush, 2006</marker>
<rawString>Rebecca Nesson, Stuart Shieber, and Alexander Rush. 2006. Induction of probabilistic synchronous treeinsertion grammars for machine translation. In Proc. ofAMTA 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="24003" citStr="Och and Ney, 2003" startWordPosition="4223" endWordPosition="4226">.0 1.5 1.0 0.5 0.0 Figure 5: Average occurrences of foot node labels VP, NP, and IP over various distances. 5 Evaluation We evaluated our adjoining tree-to-string translation system on Chinese-English translation. The bilingual corpus consists of 1.5M sentences with 42.1M Chinese words and 48.3M English words. The Chinese sentences in the bilingual corpus were parsed by an in-house parser. To maintain a reasonable grammar size, we follow Liu et al. (2006) to restrict that the height of a rule tree is no greater than 3 and the surface string’s length is no greater than 7. After running GIZA++ (Och and Ney, 2003) to obtain word alignment, our rule extraction algorithm extracted 23.0M initial rules without adjoining sites, 6.6M initial rules with adjoining sites, and 5.3M auxiliary rules. We used the SRILM toolkit (Stolcke, 2002) to train a 4-gram language model on the Xinhua portion of the GIGAWORD corpus, which contains 238M English words. We used the 2002 NIST MT Chinese-English test set as the development set and the 2003-2005 NIST test sets as the test sets. We evaluated translation quality using the BLEU metric, as calculated by mteval-v11b.pl with case-insensitive matching of n-grams. Table 2 sh</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. ofACL</booktitle>
<contexts>
<context position="9996" citStr="Och, 2003" startWordPosition="1759" endWordPosition="1760">etween source and target non-terminals. The parameters of a probabilistic synchronous TAG are 1: Pi(α) = 1 (1) a 1: Ps(α|η) = 1 (2) a 1: Pa(β|η) + Pa(NONE|η) = 1 (3) a where α ranges over initial tree pairs, β over auxiliary tree pairs, and η over node pairs. Pi(α) is the probability of beginning a derivation with α; Ps(α|η) is the probability of substituting α at η; Pa(β|η) is the probability of adjoining β at η; finally, Pa(NONE|η) is the probability of nothing adjoining at η. For tree-to-string translation, these parameters can be treated as feature functions of a discriminative framework (Och, 2003) combined with other conventional features such as relative frequency, lexical weight, rule count, language model, and word count (Liu et al., 2006). 3 Rule Extraction Inducing a synchronous TAG from training data often begins with converting Treebank-style parse trees to TAG derivations (Xia, 1999; Chen and Vijay-Shanker, 2000; Chiang, 2003). DeNeefe and Knight (2009) propose an algorithm to extract synchronous TIG rules from an aligned and parsed bilingual corpus. They first classify tree nodes into heads, arguments, and adjuncts using heuristics (Collins, 2003), then transform a Treebank-st</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Och. 2003. Minimum error rate training in statistical machine translation. In Proc. ofACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gilles Prigent</author>
</authors>
<title>Synchronous tags and machine translation.</title>
<date>1994</date>
<booktitle>In Proc. of TAG+3.</booktitle>
<contexts>
<context position="2662" citStr="Prigent, 1994" startWordPosition="405" endWordPosition="406">mal tree rewriting system, TAG (Joshi et al., 1975; Joshi, 1985) provides a larger domain of locality than CFG to state linguistic dependencies that are far apart since the formalism treats trees as basic building blocks. As a mildly context-sensitive grammar, TAG is conjectured to be powerful enough to model natural languages. Synchronous TAG generalizes TAG by allowing the construction of a pair of trees using the TAG operations of substitution and adjoining on tree pairs. The idea of using synchronous TAG in machine translation has been pursued by several researchers (Abeille et al., 1990; Prigent, 1994; Dras, 1999), but only recently in its probabilistic form (Nesson et al., 2006; DeNeefe and Knight, 2009). Shieber (2007) argues that probabilistic synchronous TAG possesses appealing properties such as expressivity and trainability for building a machine translation system. However, one major challenge for applying synchronous TAG to machine translation is computational complexity. While TAG requires O(n6) time for monolingual parsing, synchronous TAG requires O(n12) for bilingual parsing. One solution is to use tree insertion grammars (TIG) introduced by Schabes and Waters (1995). As a rest</context>
</contexts>
<marker>Prigent, 1994</marker>
<rawString>Gilles Prigent. 1994. Synchronous tags and machine translation. In Proc. of TAG+3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>Richard Waters</author>
</authors>
<title>A cubic-time, parsable formalism that lexicalizes context-free grammar without changing the trees produced.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="3251" citStr="Schabes and Waters (1995)" startWordPosition="488" endWordPosition="492">(Abeille et al., 1990; Prigent, 1994; Dras, 1999), but only recently in its probabilistic form (Nesson et al., 2006; DeNeefe and Knight, 2009). Shieber (2007) argues that probabilistic synchronous TAG possesses appealing properties such as expressivity and trainability for building a machine translation system. However, one major challenge for applying synchronous TAG to machine translation is computational complexity. While TAG requires O(n6) time for monolingual parsing, synchronous TAG requires O(n12) for bilingual parsing. One solution is to use tree insertion grammars (TIG) introduced by Schabes and Waters (1995). As a restricted form of TAG, TIG still allows for adjoining of unbounded trees but only requires O(n3) time for monolingual parsing. Nesson et al. (2006) firstly demonstrate 1278 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1278–1287, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics α1 101 z6ngt6ng NN NP 1 President X α2 )�Q m6igu6 NR NP 1 NP X X US 1 01 NP∗ NP↓ X∗ X↓ NP NP∗ NP NN X X∗ X President 02 1 NP X NR NP NN NP 1 US X President X α3 101 )�Q ,0. z6ngt6ng m6igu6 z6ngt6ng Figure 1: Initial and auxiliar</context>
</contexts>
<marker>Schabes, Waters, 1995</marker>
<rawString>Yves Schabes and Richard Waters. 1995. A cubic-time, parsable formalism that lexicalizes context-free grammar without changing the trees produced. Computational Linguistics, 21(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
<author>Yves Schabes</author>
</authors>
<title>Synchronous tree-adjoining grammars.</title>
<date>1990</date>
<booktitle>In Proc. of COLING</booktitle>
<contexts>
<context position="2018" citStr="Shieber and Schabes, 1990" startWordPosition="295" endWordPosition="298">gh these formalisms present simple and precise mechanisms for describing the basic recursive structure of sentences, they are not powerful enough to model some important features of natural language syntax. For example, Chiang (2006) points out that the translation of languages that can stack an unbounded number of clauses in an “inside-out” way (Wu, 1997) provably goes beyond the expressive power of synchronous CFG and TSG. Therefore, it is necessary to find ways to take advantage of more powerful synchronous grammars to improve machine translation. Synchronous tree adjoining grammars (TAG) (Shieber and Schabes, 1990) are a good candidate. As a formal tree rewriting system, TAG (Joshi et al., 1975; Joshi, 1985) provides a larger domain of locality than CFG to state linguistic dependencies that are far apart since the formalism treats trees as basic building blocks. As a mildly context-sensitive grammar, TAG is conjectured to be powerful enough to model natural languages. Synchronous TAG generalizes TAG by allowing the construction of a pair of trees using the TAG operations of substitution and adjoining on tree pairs. The idea of using synchronous TAG in machine translation has been pursued by several rese</context>
</contexts>
<marker>Shieber, Schabes, 1990</marker>
<rawString>Stuart M. Shieber and Yves Schabes. 1990. Synchronous tree-adjoining grammars. In Proc. of COLING 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>Probabilistic synchronous treeadjoining grammars for machine translation: The argument from bilingual dictionaries.</title>
<date>2007</date>
<booktitle>In Proc. of SSST</booktitle>
<contexts>
<context position="2784" citStr="Shieber (2007)" startWordPosition="425" endWordPosition="426">inguistic dependencies that are far apart since the formalism treats trees as basic building blocks. As a mildly context-sensitive grammar, TAG is conjectured to be powerful enough to model natural languages. Synchronous TAG generalizes TAG by allowing the construction of a pair of trees using the TAG operations of substitution and adjoining on tree pairs. The idea of using synchronous TAG in machine translation has been pursued by several researchers (Abeille et al., 1990; Prigent, 1994; Dras, 1999), but only recently in its probabilistic form (Nesson et al., 2006; DeNeefe and Knight, 2009). Shieber (2007) argues that probabilistic synchronous TAG possesses appealing properties such as expressivity and trainability for building a machine translation system. However, one major challenge for applying synchronous TAG to machine translation is computational complexity. While TAG requires O(n6) time for monolingual parsing, synchronous TAG requires O(n12) for bilingual parsing. One solution is to use tree insertion grammars (TIG) introduced by Schabes and Waters (1995). As a restricted form of TAG, TIG still allows for adjoining of unbounded trees but only requires O(n3) time for monolingual parsing</context>
</contexts>
<marker>Shieber, 2007</marker>
<rawString>Stuart M. Shieber. 2007. Probabilistic synchronous treeadjoining grammars for machine translation: The argument from bilingual dictionaries. In Proc. of SSST 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>Srilm - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of ICSLP</booktitle>
<pages>901--904</pages>
<contexts>
<context position="24223" citStr="Stolcke, 2002" startWordPosition="4258" endWordPosition="4260">ual corpus consists of 1.5M sentences with 42.1M Chinese words and 48.3M English words. The Chinese sentences in the bilingual corpus were parsed by an in-house parser. To maintain a reasonable grammar size, we follow Liu et al. (2006) to restrict that the height of a rule tree is no greater than 3 and the surface string’s length is no greater than 7. After running GIZA++ (Och and Ney, 2003) to obtain word alignment, our rule extraction algorithm extracted 23.0M initial rules without adjoining sites, 6.6M initial rules with adjoining sites, and 5.3M auxiliary rules. We used the SRILM toolkit (Stolcke, 2002) to train a 4-gram language model on the Xinhua portion of the GIGAWORD corpus, which contains 238M English words. We used the 2002 NIST MT Chinese-English test set as the development set and the 2003-2005 NIST test sets as the test sets. We evaluated translation quality using the BLEU metric, as calculated by mteval-v11b.pl with case-insensitive matching of n-grams. Table 2 shows top-10 phrase categories of foot nodes and their average occurrences in training corpus. We find that VP (verb phrase) is most likely to be the label of a foot node in an auxiliary rule. On average, there are 12.4 no</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. Srilm - an extensible language modeling toolkit. In Proceedings of ICSLP 2002, pages 901–904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="1363" citStr="Wu, 1997" startWordPosition="192" endWordPosition="193">g system improves translation quality by +0.7 BLEU over the baseline system only allowing for tree substitution on NIST ChineseEnglish test sets. 1 Introduction Syntax-based translation models, which exploit hierarchical structures of natural languages to guide machine translation, have become increasingly popular in recent years. So far, most of them have been based on synchronous context-free grammars (CFG) (Chiang, 2007), tree substitution grammars (TSG) (Eisner, 2003; Galley et al., 2006; Liu et al., 2006; Huang et al., 2006; Zhang et al., 2008), and inversion transduction grammars (ITG) (Wu, 1997; Xiong et al., 2006). Although these formalisms present simple and precise mechanisms for describing the basic recursive structure of sentences, they are not powerful enough to model some important features of natural language syntax. For example, Chiang (2006) points out that the translation of languages that can stack an unbounded number of clauses in an “inside-out” way (Wu, 1997) provably goes beyond the expressive power of synchronous CFG and TSG. Therefore, it is necessary to find ways to take advantage of more powerful synchronous grammars to improve machine translation. Synchronous tr</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377–404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
</authors>
<title>Extracting tree adjoining grammars from bracketed corpora.</title>
<date>1999</date>
<booktitle>In Proc. of the Fifth Natural Language Processing Pacific Rim Symposium.</booktitle>
<contexts>
<context position="10295" citStr="Xia, 1999" startWordPosition="1804" endWordPosition="1805">derivation with α; Ps(α|η) is the probability of substituting α at η; Pa(β|η) is the probability of adjoining β at η; finally, Pa(NONE|η) is the probability of nothing adjoining at η. For tree-to-string translation, these parameters can be treated as feature functions of a discriminative framework (Och, 2003) combined with other conventional features such as relative frequency, lexical weight, rule count, language model, and word count (Liu et al., 2006). 3 Rule Extraction Inducing a synchronous TAG from training data often begins with converting Treebank-style parse trees to TAG derivations (Xia, 1999; Chen and Vijay-Shanker, 2000; Chiang, 2003). DeNeefe and Knight (2009) propose an algorithm to extract synchronous TIG rules from an aligned and parsed bilingual corpus. They first classify tree nodes into heads, arguments, and adjuncts using heuristics (Collins, 2003), then transform a Treebank-style tree into a TIG derivation, and finally extract minimallysized rules from the derivation tree and the string on the other side, constrained by the alignments. Probabilistic models can be estimated by collecting counts over the derivation trees. However, one challenge is that there are many TAG </context>
</contexts>
<marker>Xia, 1999</marker>
<rawString>Fei Xia. 1999. Extracting tree adjoining grammars from bracketed corpora. In Proc. of the Fifth Natural Language Processing Pacific Rim Symposium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Maximum entropy based phrase reordering model for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proc. ofACL</booktitle>
<contexts>
<context position="1384" citStr="Xiong et al., 2006" startWordPosition="194" endWordPosition="197">mproves translation quality by +0.7 BLEU over the baseline system only allowing for tree substitution on NIST ChineseEnglish test sets. 1 Introduction Syntax-based translation models, which exploit hierarchical structures of natural languages to guide machine translation, have become increasingly popular in recent years. So far, most of them have been based on synchronous context-free grammars (CFG) (Chiang, 2007), tree substitution grammars (TSG) (Eisner, 2003; Galley et al., 2006; Liu et al., 2006; Huang et al., 2006; Zhang et al., 2008), and inversion transduction grammars (ITG) (Wu, 1997; Xiong et al., 2006). Although these formalisms present simple and precise mechanisms for describing the basic recursive structure of sentences, they are not powerful enough to model some important features of natural language syntax. For example, Chiang (2006) points out that the translation of languages that can stack an unbounded number of clauses in an “inside-out” way (Wu, 1997) provably goes beyond the expressive power of synchronous CFG and TSG. Therefore, it is necessary to find ways to take advantage of more powerful synchronous grammars to improve machine translation. Synchronous tree adjoining grammars</context>
</contexts>
<marker>Xiong, Liu, Lin, 2006</marker>
<rawString>Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Maximum entropy based phrase reordering model for statistical machine translation. In Proc. ofACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Hongfei Jiang</author>
<author>Aiti Aw</author>
<author>Haizhou Li</author>
<author>Chew Lim Tan</author>
<author>Sheng Li</author>
</authors>
<title>A tree sequence alignment-based tree-to-tree translation model.</title>
<date>2008</date>
<booktitle>In Proc. ofACL</booktitle>
<contexts>
<context position="1310" citStr="Zhang et al., 2008" startWordPosition="183" endWordPosition="186">s included. Less than 2 times slower, the adjoining tree-tostring system improves translation quality by +0.7 BLEU over the baseline system only allowing for tree substitution on NIST ChineseEnglish test sets. 1 Introduction Syntax-based translation models, which exploit hierarchical structures of natural languages to guide machine translation, have become increasingly popular in recent years. So far, most of them have been based on synchronous context-free grammars (CFG) (Chiang, 2007), tree substitution grammars (TSG) (Eisner, 2003; Galley et al., 2006; Liu et al., 2006; Huang et al., 2006; Zhang et al., 2008), and inversion transduction grammars (ITG) (Wu, 1997; Xiong et al., 2006). Although these formalisms present simple and precise mechanisms for describing the basic recursive structure of sentences, they are not powerful enough to model some important features of natural language syntax. For example, Chiang (2006) points out that the translation of languages that can stack an unbounded number of clauses in an “inside-out” way (Wu, 1997) provably goes beyond the expressive power of synchronous CFG and TSG. Therefore, it is necessary to find ways to take advantage of more powerful synchronous gr</context>
</contexts>
<marker>Zhang, Jiang, Aw, Li, Tan, Li, 2008</marker>
<rawString>Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li, Chew Lim Tan, and Sheng Li. 2008. A tree sequence alignment-based tree-to-tree translation model. In Proc. ofACL 2008.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>