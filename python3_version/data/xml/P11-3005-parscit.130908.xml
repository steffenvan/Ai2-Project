<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000222">
<title confidence="0.989682">
Extracting and Classifying Urdu Multiword Expressions
</title>
<author confidence="0.994117">
Annette Hautli Sebastian Sulger
</author>
<affiliation confidence="0.9991835">
Department of Linguistics Department of Linguistics
University of Konstanz, Germany University of Konstanz, Germany
</affiliation>
<email confidence="0.635698">
annette.hautli@uni-konstanz.de sebastian.sulger@uni-konstanz.de
</email>
<sectionHeader confidence="0.996433" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997358529411765">
This paper describes a method for automati-
cally extracting and classifying multiword ex-
pressions (MWEs) for Urdu on the basis of a
relatively small unannotated corpus (around
8.12 million tokens). The MWEs are extracted
by an unsupervised method and classified into
two distinct classes, namely locations and per-
son names. The classification is based on sim-
ple heuristics that take the co-occurrence of
MWEs with distinct postpositions into account.
The resulting classes are evaluated against a
hand-annotated gold standard and achieve an
f-score of 0.5 and 0.746 for locations and
persons, respectively. A target application is
the Urdu ParGram grammar, where MWEs are
needed to generate a more precise syntactic
and semantic analysis.
</bodyText>
<sectionHeader confidence="0.999511" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999344357142857">
Multiword expressions (MWEs) are expressions
which can be semantically and syntactically idiosyn-
cratic in nature; acting as a single unit, their mean-
ing is not always predictable from their components.
Their identification is therefore an important task for
any Natural Language Processing (NLP) application
that goes beyond the analysis of pure surface struc-
ture, in particular for languages with few other NLP
tools available.
There is a vast amount of literature on extract-
ing and classifying MWEs automatically; many ap-
proaches rely on already available resources that aid
during the acquisition process. In the case of the
Indo-Aryan language Urdu, a lack of linguistic re-
</bodyText>
<page confidence="0.980041">
24
</page>
<bodyText confidence="0.999918333333333">
sources such as annotated corpora or lexical knowl-
edge bases impedes the task of detecting and classi-
fying MWEs. Nevertheless, statistical measures and
language-specific syntactic information can be em-
ployed to extract and classify MWEs.
Therefore, the method described in this paper can
partly overcome the bottleneck of resource sparsity,
despite the relatively small size of the available cor-
pus and the simplistic approach taken. With the help
of heuristics as to the occurrence of Urdu MWEs with
characteristic postpositions and other cues, it is pos-
sible to cluster the MWEs into two groups: locations
and person names. It is also possible to detect junk
MWEs. The classification is then evaluated against a
hand-annotated gold standard of Urdu MWEs.
An NLP tool where the MWEs can be employed is
the Urdu ParGram grammar (Butt and King, 2007;
B¨ogel et al., 2007; B¨ogel et al., 2009), which is
based on the Lexical-Functional Grammar (LFG)
formalism (Dalrymple, 2001). For this task, differ-
ent types of MWEs need to be distinguished as they
are treated differently in the syntactic analysis.
The paper is structured as follows: Section 2 pro-
vides a brief review of related work, in particular
on MWE extraction in Indo-Aryan languages. Sec-
tion 3 describes our methodology, with the evalua-
tion following in Section 4. Section 5 presents the
Urdu ParGram Grammar and its treatment of MWEs,
followed by the discussion and the summary of the
paper in Section 6.
</bodyText>
<sectionHeader confidence="0.999873" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9563285">
MWE extraction and classification has been the focus
of a large amount of research. However, much work
</bodyText>
<subsectionHeader confidence="0.371995">
Proceedings of the ACL-HLT 2011 Student Session, pages 24–29,
</subsectionHeader>
<bodyText confidence="0.990190625">
Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics
has been conducted for well-resourced languages
such as English, benefiting from large enough cor-
pora (Attia et al., 2010), parallel data (Zarrieß and
Kuhn, 2009) and NLP tools such as taggers or depen-
dency parsers (Martens and Vandeghinste (2010),
among others) and lexical resources (Pearce, 2001).
Related work on Indo-Aryan languages has
mostly focused on the extraction of complex pred-
icates, with the focus on Hindi (Mukerjee et al.,
2006; Chakrabarti et al., 2008; Sinha, 2009) and
Bengali (Das et al., 2010; Chakraborty and Bandy-
opadhyay, 2010). While complex predicates also
make up a large part of the verbal inventory in Urdu
(Butt, 1993), for the scope of this paper, we restrict
ourselves to classifying MWEs as locations or person
names and filter out junk bigrams.
Our approach deviates in several aspects to the re-
lated work in Indo-Aryan: First, we do not concen-
trate on specific POS constructions or dependency
relations, but use an unannotated middle-sized cor-
pus. For classification, we use simple heuristics by
taking the postpositions of the MWEs into account.
These can provide hints as to the nature of the MWE.
</bodyText>
<sectionHeader confidence="0.999769" genericHeader="method">
3 Methodology
</sectionHeader>
<subsectionHeader confidence="0.9982325">
3.1 Extraction and Identification of MWE
Candidates
</subsectionHeader>
<bodyText confidence="0.999892388888889">
The bigram extraction was carried out on a corpus of
around 8.12 million tokens of Urdu newspaper text,
collected by the Center for Research in Urdu Lan-
guage Processing (CRULP) (Hussain, 2008). We did
not perform any pre-processing such as POS tagging
or stop word removal.
Due to the relatively small size of our corpus, the
frequency cut-off for bigrams was set to 5, i.e. all
bigrams that occurred five times or more in the cor-
pus were considered. This rendered a list of 172,847
bigrams which were then ranked with the X2 asso-
ciation measure, using the UCS toolkit.1
The reasons for employing the X2 association
measure are twofold. First, papers using compara-
tively sized corpora reported encouraging results for
similar experiments (Ramisch et al., 2008; Kizito et
al., 2009). Second, initial manual comparison be-
tween MWE lists ranked according to all measures
</bodyText>
<footnote confidence="0.996017">
1Available at http://www.collocations.de. See
Evert (2004) for documentation.
</footnote>
<bodyText confidence="0.9988896">
implemented in the UCS toolkit revealed the most
convincing results for the X2 test.
For the time being, we focus on bigram MWE
extraction. While the UCS toolkit readily supports
work on Unicode-based languages such as Urdu,
it does not support trigram extraction; other freely
available tools such as TEXT-NSP2 do come with
trigram support, but cannot handle Unicode script.
As a consequence, we currently implement our own
scripts to overcome these limitations.
</bodyText>
<subsectionHeader confidence="0.999418">
3.2 Syntactic Cues
</subsectionHeader>
<bodyText confidence="0.999769272727273">
The clustering approach taken in this paper is based
on Urdu-specific syntactic information that can be
gathered straightforwardly from the corpus. Urdu
has a number of postpositions that can be used to
identify the nature of an MWE. Typographical cues
such as initial capital letters do not exist in the Urdu
script.
Locative postpositions The postposition J, (par)
either expresses location on something which has a
surface or that an object is next to something.3 In
addition, it expresses movement to a destination.
</bodyText>
<equation confidence="0.9413305">
(1) ���� ��� �� ����� ��� �������
��
</equation>
<bodyText confidence="0.989883">
nAdiyah t3ul AbEb par gAyI
Nadya Tel Aviv to go.Perf.Fem.Sg
‘Nadya went to Tel Aviv.’
vu (mEN) expresses location in or at a point in
space or time, whereas &amp; (tak) denotes that some-
thing extends to a specific point in space. (sE)
shows movement away from a certain point in space.
These postpositions mostly occur with locations
and are thus syntactic indicators for this type of
MWE. However, in special cases, they can also occur
with other nouns, in which case we predict wrong
results during classification.
Person-indicating syntactic cues To classify an
MWE as a person, we consider syntactic cues that
usually occur after such MWEs. The ergative marker
j (nE) describes an agentive subject in transitive
</bodyText>
<footnote confidence="0.8463934">
2Available at http://search.cpan.org/dist/
Text-NSP. See Banerjee and Pedersen (2003) for
documentation.
3The employed transliteration scheme is explained in Malik
et al. (2010).
</footnote>
<page confidence="0.98824">
25
</page>
<table confidence="0.9972165">
Locative Instr. Ergative Possessive Acc./Dat.
QK� (par) ál 1/2; (tak) ú ú A¿ (kA) ú ú ñ» (kO)
Ó (mEN) æ... (sE) G (nE) » (kE) » (kI)
LOC √ √ √ √ — — — — —
PERS — — — √ √ √ √ √ √
JUNK — — — — — — — — —
</table>
<tableCaption confidence="0.998468">
Table 1: Heuristics for clustering Urdu MWEs by different postpositions
</tableCaption>
<bodyText confidence="0.8853592">
sentences; therefore, it forms part of our heuristic
for finding person MWEs.
(2) @PAÓñ»�á��ƒAK
ú
G� éK�XA K
nAdiyah nE yAsIn kO mArA
Nadya Erg Yasin Acc hit.Perf.Masc.Sg
‘Nadya hit Yasin.’
The same holds for the possessive markers
A¿ (kA), ú» (kE) and ú» (kI)
� �
The accusative and dative case marker ñ» (kO) is
also a possible indicator that the preceding MWE is
a person.
These cues can also appear with common nouns,
but the combination of MWE and syntactic cue hints
to a person MWE. However, consider cases such as
New Delhi said that the taxes will rise., where New
Delhi is treated as an agent with nE attached to it,
providing a wrong clue as to the nature of the MWE.
</bodyText>
<subsectionHeader confidence="0.999105">
3.3 Classifying Urdu MWEs
</subsectionHeader>
<bodyText confidence="0.999872">
The classification of the extracted bigrams is solely
based on syntactic information as described in the
previous section. For every bigram, the postpo-
sitions that it occurs with are extracted from the
corpus, together with the frequency of the co-
occurrence.
Table 1 shows which postpositions are expected
to occur with which type of MWE. The first stipula-
tion is that only bigrams that occur with one of the
locative postpositions plus the ablative/instrumental
marker ú
æ... (sE) one or more times are considered
to be locative MWEs (LOC). In contrast, bigrams
are judged as persons (PERS) when they co-occur
with all postpositions apart from the locative post-
positions one or more times. If a bigram occurs with
none of the postpositions, it is judged as being junk
(JUNK). As a consequence this means that theoreti-
cally valid MWEs such as complex predicates, which
never occur with a postposition, are misclassified as
being JUNK.
Without any further processing, the resulting clus-
ters are then evaluated against a hand-annotated gold
standard, as described in the following section.
</bodyText>
<sectionHeader confidence="0.999928" genericHeader="method">
4 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.998634">
4.1 Gold Standard
</subsectionHeader>
<bodyText confidence="0.999987318181818">
Our gold standard comprises the 1300 highest
ranked Urdu multiword candidates extracted from
the CRULP corpus, using the X2 association mea-
sure. The bigrams are then hand-annotated by a na-
tive speaker of Urdu and clustered into the following
classes: locations, person names, companies, mis-
cellaneous MWEs and junk. For the scope of this
paper, we restrict ourselves to classifying MWEs as
either locations or person names,. This also lies in
the nature of the corpus: companies can usually be
detected by endings such as “Corp.” or “Ltd.”, as is
the case in English. However, these markers are of-
ten left out and are not present in the corpus at hand.
Therefore, they cannot be used for our clustering.
The class of miscellaneous MWEs contains complex
predicates that we do not attempt to deal with here.
In total, the gold standard comprises 30 compa-
nies, 95 locations, 411 person names, 512 miscella-
neous MWEs (mostly complex predicates) and 252
junk bigrams. We have not analyzed the gold stan-
dard any further, and restricting it to n &lt; 1300 might
improve the evaluation results.
</bodyText>
<sectionHeader confidence="0.824324" genericHeader="method">
4.2 Results
</sectionHeader>
<bodyText confidence="0.763485625">
The bigrams are classified according to the heuris-
tics outlined in Section 3.3. Evaluating against the
hand-annotated gold standard yields the results in
Table 2.
While the results are encouraging for persons with
an f-score of 0.746, there is still room for improve-
ment for locative MWEs. Part of the problem for per-
.
</bodyText>
<page confidence="0.943207">
26
</page>
<table confidence="0.9999525">
Precision Recall F-Score #total #found
LOC 0.453 0.558 0.5 95 43
PERS 0.727 0.765 0.746 411 298
JUNK 0.472 0.317 0.379 252 119
</table>
<tableCaption confidence="0.995789">
Table 2: Results for MWE clustering
</tableCaption>
<bodyText confidence="0.9999335625">
son names is that Urdu names are generally longer
than two words, and as we have not considered tri-
grams yet, it is impossible to find a postposition after
an incomplete though generally valid name. Loca-
tions tend to have the same problem, however the
reasons for missing out on a large part of the loca-
tive MWEs are not quite clear and are currently being
investigated.
Junk bigrams can be detected with an f-score of
0.379. Due to the heterogeneous nature of the mis-
cellaneous MWEs (e.g., complex predicates), many
of them are judged as being junk because they never
occur with a postposition. If one could detect com-
plex predicate and, possibly, other subgroups from
the miscellaneous class, then classifying the junk
MWEs would become easier.
</bodyText>
<sectionHeader confidence="0.9828825" genericHeader="method">
5 Integration into the Urdu ParGram
Grammar
</sectionHeader>
<bodyText confidence="0.985269511111111">
The extracted MWEs are integrated into the Urdu
ParGram grammar (Butt and King, 2007; B¨ogel et
al., 2007; B¨ogel et al., 2009), a computational gram-
mar for Urdu running with XLE (Crouch et al., 2010)
and based on the syntax formalism of LFG (Dal-
rymple, 2001). XLE grammars are generally hand-
written and not acquired a machine learning pro-
cess or the like. This makes grammar development a
very conscious task and it is imperative to deal with
MWEs in order to achieve a linguistically valid and
deep syntactic analysis that can be used for an addi-
tional semantic analysis.
MWEs that are correctly classified according to the
gold standard are automatically integrated into the
multiword lexicon of the grammar, accompanied by
information about their nature (see example (3)).
In general, grammar input is first tokenized by a
standard tokenizer that separates the input string into
single tokens and replaces the white spaces with a
special token boundary symbol. Each token is then
passed through a cascade of finite-state morpholog-
ical analyzers (Beesley and Karttunen, 2003). For
MWEs, the matter is different as they are treated as
a single unit to preserve the semantic information
they carry. Apart from the meaning preservation, in-
tegrating MWEs into the grammar reduces parsing
ambiguity and parsing time, while the perspicuity of
the syntactic analyses is increased (Butt et al., 1999).
In order to prevent the MWEs from being inde-
pendently analyzed by the finite-state morphology,
a look-up is performed in a transducer which only
contains MWEs with their morphological informa-
tion. So instead of analyzing t3ul and AbEb sep-
arately, for example, they are analyzed as a sin-
gle item carrying the morphological information
+Noun+Location.4
(3) t3ul` AbEb: /t3ul` AbEb/ +Noun
+Location
The resulting stem and tag sequence is then
passed on to the grammar. See (4) for an example
and Figures 1 and 2 for the corresponding c- and
f-structure; the +Location tag in (3) is used to
produce the location analysis in the f-structure. Note
also that t3ul AbEb is displayed as a multiword
under the N node in the c-structure.
</bodyText>
<figure confidence="0.6199656">
(4) ���� ��� �� ����� ��� �������
��
nAdiyah t3ul AbEb par gAyI
Nadya Tel Aviv to go.Perf.Fem.Sg
‘Nadya went to Tel Aviv.’
</figure>
<figureCaption confidence="0.993181">
Figure 1: C-structure for (4)
</figureCaption>
<footnote confidence="0.7079145">
4The ` symbol is an escape character, yielding a literal white
space.
</footnote>
<figure confidence="0.624834928571429">
V
K
NP
NP
VCmain
KP
CS 1: ROOT
Sadj
S
KP
N N par gAyI
nAdiyah t3ul AbEb
27
&amp;quot;nAdiyah t3ul AbEb par gAyI&amp;quot;
</figure>
<figureCaption confidence="0.959645">
Figure 2: F-structure for (4)
</figureCaption>
<sectionHeader confidence="0.59209" genericHeader="method">
6 Discussion, Summary and Future Work
</sectionHeader>
<bodyText confidence="0.999988307692308">
Despite the simplistic approach for extracting and
clustering Urdu MWEs taken in this paper, the re-
sults are encouraging with f-scores of 0.5 and 0.746
for locations and person names, respectively. We
are well aware that this paper does not present a
complete approach to classifying Urdu multiwords,
but considering the targeted tool, the Urdu ParGram
grammar, this methodology provides us with a set of
MWEs that can be implemented to improve the syn-
tactic analyses.
The methodology provided here can also guide
MWE work in other languages facing the same re-
source sparsity as Urdu, given that distinctive syn-
tactic cues are available in the language.
For Urdu, the syntactic cues are good indica-
tions of the nature of the MWE; future work on
this subtopic might prove beneficial to the clustering
regarding companies, complex predicates and junk
MWEs. Another area for future work is to extend
the extraction and classification to trigrams to im-
prove the results especially for locations and person
names. We also consider harvesting data sources
from the web such as lists of cities, common names
and companies in Pakistan and India. Such lists are
not numerous for Urdu, but they may nevertheless
help to generate a larger MWE lexicon.
</bodyText>
<sectionHeader confidence="0.99171" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999437">
We would like to thank Samreen Khan for annotat-
ing the gold standard, as well as the anonymous re-
viewers for their valuable comments. This research
was in part supported by the Deutsche Forschungs-
gemeinschaft (DFG).
</bodyText>
<sectionHeader confidence="0.990352" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9916664">
Mohammed Attia, Antonio Toral, Lamia Tounsi, Pavel
Pecina, and Josef van Genabith. 2010. Automatic
Extraction of Arabic Multiword Expressions. In Pro-
ceedings of the Workshop on Multiword Expressions:
from Theory to Applications (MWE 2010).
Satanjeev Banerjee and Ted Pedersen. 2003. The De-
sign, Implementation and Use of the Ngram Statistics
Package. In Proceedings of the Fourth International
Conference on Intelligent Text Processing and Com-
putational Linguistics.
Kenneth Beesley and Lauri Karttunen. 2003. Finite State
Morphology. CSLI Publications, Stanford, CA.
Tina B¨ogel, Miriam Butt, Annette Hautli, and Sebastian
Sulger. 2007. Developing a Finite-State Morpholog-
ical Analyzer for Urdu and Hindi: Some Issues. In
Proceedings of FSMNLP07, Potsdam, Germany.
Tina B¨ogel, Miriam Butt, Annette Hautli, and Sebastian
Sulger. 2009. Urdu and the Modular Architecture of
ParGram. In Proceedings of the Conference on Lan-
guage and Technology 2009 (CLT09).
Miriam Butt and Tracy Holloway King. 2007. Urdu in
a Parallel Grammar Development Environment. Lan-
guage Resources and Evaluation, 41(2):191–207.
Miriam Butt, Tracy Holloway King, Mar´ıa-Eugenia
Ni˜no, and Fr´ed´erique Segond. 1999. A Grammar
Writer’s Cookbook. CSLI Publications.
Miriam Butt. 1993. The Structure of Complex Predicates
in Urdu. Ph.D. thesis, Stanford University.
Debasri Chakrabarti, Vaijayanthi M. Sarma, and Pushpak
Bhattacharyya. 2008. Hindi Compound Verbs and
their Automatic Extraction. In Proceedings of COL-
ING 2008, pages 27–30.
Tanmoy Chakraborty and Sivaji Bandyopadhyay. 2010.
Identification of Reduplication in Bengali Corpus and
their Semantic Analysis: A Rule-Based Approach.
In Proceedings of the Workshop on Multiword Ex-
pressions: from Theory to Applications (MWE 2010),
pages 72–75.
Dick Crouch, Mary Dalrymple, Ronald M. Kaplan,
Tracy Holloway King, John T. Maxwell III, and Paula
Newman, 2010. XLE Documentation. Palo Alto Re-
search Center.
Mary Dalrymple. 2001. Lexical Functional Grammar,
volume 34 of Syntax and Semantics. Academic Press.
Dipankar Das, Santanu Pal, Tapabrata Mondal, Tanmoy
Chakraborty, and Sivaji Bandyopadhyay. 2010. Au-
tomatic Extraction of Complex Predicates in Bengali.
In Proceedings of the Workshop on Multiword Ex-
pressions: from Theory to Applications (MWE 2010),
pages 37–45.
</reference>
<figure confidence="0.985709">
PRED &apos;gA&lt;[1:nAdiyah]&gt;&apos;
PRED &apos;nAdiyah&apos;
NTYPE
PROPER-TYPE name
NSYN
CASE nom, GEND fem, NUM sg, PERS 3
proper
NSEM PROPER
PRED &apos;t3ul AbEb&apos;
SUBJ
1
ADJUNCT
NTYPE
NSEM PROPER
NSYN proper
PROPER-TYPE location
21 ADJUNCT-TYPE loc, CASE loc, NUM sg, PERS 3
TNS-ASP ASPECT perf, MOOD indicative
CLAUSE-TYPE decl, PASSIVE -, VTYPE main
42
</figure>
<page confidence="0.993898">
28
</page>
<reference confidence="0.999856340425532">
Stefan Evert. 2004. The Statistics of Word Cooccur-
rences: Word Pairs and Collocations. Ph.D. thesis,
IMS, University of Stuttgart.
Sarmad Hussain. 2008. Resources for Urdu Language
Processing. In Proceedings of the 6th Workshop on
Asian Language Resources, IJCNLP’08.
John Kizito, Ismail Fahmi, Erik Tjong Kim Sang, Gosse
Bouma, and John Nerbonne. 2009. Computational
Linguistics and the History of Science. In Liborio
Dibattista, editor, Storia della Scienza e Linguistica
Computazionale. FrancoAngeli.
Muhammad Kamran Malik, Tafseer Ahmed, Sebastian
Sulger, Tina B¨ogel, Atif Gulzar, Ghulam Raza, Sar-
mad Hussain, and Miriam Butt. 2010. Transliter-
ating Urdu for a Broad-Coverage Urdu/Hindi LFG
Grammar. In Proceedings of the Seventh Conference
on International Language Resources and Evaluation
(LREC’10).
Scott Martens and Vincent Vandeghinste. 2010. An Effi-
cient, Generic Approach to Extracting Multi-Word Ex-
pressions from Dependency Trees. In Proceedings of
the Workshop on Multiword Expressions: from Theory
to Applications (MWE 2010), pages 84–87.
Amitabha Mukerjee, Ankit Soni, and Achla M. Raina.
2006. Detecting Complex Predicates in Hindi using
POS Projection across Parallel Corpora. In Proceed-
ings of the Workshop on Multiword Expressions: Iden-
tifying and Exploiting Underlying Properties (MWE
’06), pages 28–35.
David Pearce. 2001. Synonymy in Collocation Extrac-
tion. In WordNet and Other Lexical Resources: Appli-
cations, Extensions &amp; Customizations, pages 41–46.
Carlos Ramisch, Paulo Schreiner, Marco Idiart, and Aline
Villavicencio. 2008. An Evaluation of Methods for
the Extraction of Multiword Expressions. In Proceed-
ings of the Workshop on Multiword Expressions: To-
wards a Shared Taskfor Multiword Expressions (MWE
2008).
R. Mahesh K. Sinha. 2009. Mining Complex Predicates
in Hindi Using a Parallel Hindi-English Corpus. In
Proceedings of the 2009 Workshop on Multiword Ex-
pressions, ACL-IJCNLP 2009, pages 40–46.
Sina Zarrieß and Jonas Kuhn. 2009. Exploiting Transla-
tional Correspondences for Pattern-Independent MWE
Identification. In Proceedings of the 2009 Workshop
on Multiword Expressions, ACL-IJCNLP 2009, pages
23–30.
</reference>
<page confidence="0.999114">
29
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.697537">
<title confidence="0.999731">Extracting and Classifying Urdu Multiword Expressions</title>
<author confidence="0.999967">Annette Hautli Sebastian Sulger</author>
<affiliation confidence="0.922324">Department of Linguistics Department of Linguistics University of Konstanz, Germany University of Konstanz, Germany</affiliation>
<email confidence="0.843927">annette.hautli@uni-konstanz.desebastian.sulger@uni-konstanz.de</email>
<abstract confidence="0.999670166666667">This paper describes a method for automatically extracting and classifying multiword exfor Urdu on the basis of a relatively small unannotated corpus (around million tokens). The are extracted by an unsupervised method and classified into two distinct classes, namely locations and person names. The classification is based on simple heuristics that take the co-occurrence of with distinct postpositions into account. The resulting classes are evaluated against a hand-annotated gold standard and achieve an f-score of 0.5 and 0.746 for locations and persons, respectively. A target application is Urdu ParGram grammar, where are needed to generate a more precise syntactic and semantic analysis.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mohammed Attia</author>
<author>Antonio Toral</author>
<author>Lamia Tounsi</author>
<author>Pavel Pecina</author>
<author>Josef van Genabith</author>
</authors>
<title>Automatic Extraction of Arabic Multiword Expressions.</title>
<date>2010</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: from Theory to Applications (MWE</booktitle>
<marker>Attia, Toral, Tounsi, Pecina, van Genabith, 2010</marker>
<rawString>Mohammed Attia, Antonio Toral, Lamia Tounsi, Pavel Pecina, and Josef van Genabith. 2010. Automatic Extraction of Arabic Multiword Expressions. In Proceedings of the Workshop on Multiword Expressions: from Theory to Applications (MWE 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Ted Pedersen</author>
</authors>
<title>The Design, Implementation and Use of the Ngram Statistics Package.</title>
<date>2003</date>
<booktitle>In Proceedings of the Fourth International Conference on Intelligent Text Processing and Computational Linguistics.</booktitle>
<contexts>
<context position="7423" citStr="Banerjee and Pedersen (2003)" startWordPosition="1165" endWordPosition="1168">tes that something extends to a specific point in space. (sE) shows movement away from a certain point in space. These postpositions mostly occur with locations and are thus syntactic indicators for this type of MWE. However, in special cases, they can also occur with other nouns, in which case we predict wrong results during classification. Person-indicating syntactic cues To classify an MWE as a person, we consider syntactic cues that usually occur after such MWEs. The ergative marker j (nE) describes an agentive subject in transitive 2Available at http://search.cpan.org/dist/ Text-NSP. See Banerjee and Pedersen (2003) for documentation. 3The employed transliteration scheme is explained in Malik et al. (2010). 25 Locative Instr. Ergative Possessive Acc./Dat. QK� (par) ál 1/2; (tak) ú ú A¿ (kA) ú ú ñ» (kO) Ó (mEN) æ... (sE) G (nE) » (kE) » (kI) LOC √ √ √ √ — — — — — PERS — — — √ √ √ √ √ √ JUNK — — — — — — — — — Table 1: Heuristics for clustering Urdu MWEs by different postpositions sentences; therefore, it forms part of our heuristic for finding person MWEs. (2) @PAÓñ»�á��ƒAK ú G� éK�XA K nAdiyah nE yAsIn kO mArA Nadya Erg Yasin Acc hit.Perf.Masc.Sg ‘Nadya hit Yasin.’ The same holds for the possessive marker</context>
</contexts>
<marker>Banerjee, Pedersen, 2003</marker>
<rawString>Satanjeev Banerjee and Ted Pedersen. 2003. The Design, Implementation and Use of the Ngram Statistics Package. In Proceedings of the Fourth International Conference on Intelligent Text Processing and Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Beesley</author>
<author>Lauri Karttunen</author>
</authors>
<title>Finite State Morphology.</title>
<date>2003</date>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="13067" citStr="Beesley and Karttunen, 2003" startWordPosition="2137" endWordPosition="2140">n order to achieve a linguistically valid and deep syntactic analysis that can be used for an additional semantic analysis. MWEs that are correctly classified according to the gold standard are automatically integrated into the multiword lexicon of the grammar, accompanied by information about their nature (see example (3)). In general, grammar input is first tokenized by a standard tokenizer that separates the input string into single tokens and replaces the white spaces with a special token boundary symbol. Each token is then passed through a cascade of finite-state morphological analyzers (Beesley and Karttunen, 2003). For MWEs, the matter is different as they are treated as a single unit to preserve the semantic information they carry. Apart from the meaning preservation, integrating MWEs into the grammar reduces parsing ambiguity and parsing time, while the perspicuity of the syntactic analyses is increased (Butt et al., 1999). In order to prevent the MWEs from being independently analyzed by the finite-state morphology, a look-up is performed in a transducer which only contains MWEs with their morphological information. So instead of analyzing t3ul and AbEb separately, for example, they are analyzed as </context>
</contexts>
<marker>Beesley, Karttunen, 2003</marker>
<rawString>Kenneth Beesley and Lauri Karttunen. 2003. Finite State Morphology. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tina B¨ogel</author>
<author>Miriam Butt</author>
<author>Annette Hautli</author>
<author>Sebastian Sulger</author>
</authors>
<title>Developing a Finite-State Morphological Analyzer for Urdu and Hindi: Some Issues.</title>
<date>2007</date>
<booktitle>In Proceedings of FSMNLP07,</booktitle>
<location>Potsdam, Germany.</location>
<marker>B¨ogel, Butt, Hautli, Sulger, 2007</marker>
<rawString>Tina B¨ogel, Miriam Butt, Annette Hautli, and Sebastian Sulger. 2007. Developing a Finite-State Morphological Analyzer for Urdu and Hindi: Some Issues. In Proceedings of FSMNLP07, Potsdam, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tina B¨ogel</author>
<author>Miriam Butt</author>
<author>Annette Hautli</author>
<author>Sebastian Sulger</author>
</authors>
<title>Urdu and the Modular Architecture of ParGram.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Language and Technology</booktitle>
<marker>B¨ogel, Butt, Hautli, Sulger, 2009</marker>
<rawString>Tina B¨ogel, Miriam Butt, Annette Hautli, and Sebastian Sulger. 2009. Urdu and the Modular Architecture of ParGram. In Proceedings of the Conference on Language and Technology 2009 (CLT09).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
<author>Tracy Holloway King</author>
</authors>
<title>Urdu in a Parallel Grammar Development Environment. Language Resources and Evaluation,</title>
<date>2007</date>
<pages>41--2</pages>
<contexts>
<context position="2556" citStr="Butt and King, 2007" startWordPosition="381" endWordPosition="384">fy MWEs. Therefore, the method described in this paper can partly overcome the bottleneck of resource sparsity, despite the relatively small size of the available corpus and the simplistic approach taken. With the help of heuristics as to the occurrence of Urdu MWEs with characteristic postpositions and other cues, it is possible to cluster the MWEs into two groups: locations and person names. It is also possible to detect junk MWEs. The classification is then evaluated against a hand-annotated gold standard of Urdu MWEs. An NLP tool where the MWEs can be employed is the Urdu ParGram grammar (Butt and King, 2007; B¨ogel et al., 2007; B¨ogel et al., 2009), which is based on the Lexical-Functional Grammar (LFG) formalism (Dalrymple, 2001). For this task, different types of MWEs need to be distinguished as they are treated differently in the syntactic analysis. The paper is structured as follows: Section 2 provides a brief review of related work, in particular on MWE extraction in Indo-Aryan languages. Section 3 describes our methodology, with the evaluation following in Section 4. Section 5 presents the Urdu ParGram Grammar and its treatment of MWEs, followed by the discussion and the summary of the pa</context>
<context position="12073" citStr="Butt and King, 2007" startWordPosition="1975" endWordPosition="1978">ons for missing out on a large part of the locative MWEs are not quite clear and are currently being investigated. Junk bigrams can be detected with an f-score of 0.379. Due to the heterogeneous nature of the miscellaneous MWEs (e.g., complex predicates), many of them are judged as being junk because they never occur with a postposition. If one could detect complex predicate and, possibly, other subgroups from the miscellaneous class, then classifying the junk MWEs would become easier. 5 Integration into the Urdu ParGram Grammar The extracted MWEs are integrated into the Urdu ParGram grammar (Butt and King, 2007; B¨ogel et al., 2007; B¨ogel et al., 2009), a computational grammar for Urdu running with XLE (Crouch et al., 2010) and based on the syntax formalism of LFG (Dalrymple, 2001). XLE grammars are generally handwritten and not acquired a machine learning process or the like. This makes grammar development a very conscious task and it is imperative to deal with MWEs in order to achieve a linguistically valid and deep syntactic analysis that can be used for an additional semantic analysis. MWEs that are correctly classified according to the gold standard are automatically integrated into the multiw</context>
</contexts>
<marker>Butt, King, 2007</marker>
<rawString>Miriam Butt and Tracy Holloway King. 2007. Urdu in a Parallel Grammar Development Environment. Language Resources and Evaluation, 41(2):191–207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
<author>Tracy Holloway King</author>
<author>Mar´ıa-Eugenia Ni˜no</author>
<author>Fr´ed´erique Segond</author>
</authors>
<title>A Grammar Writer’s Cookbook.</title>
<date>1999</date>
<publisher>CSLI Publications.</publisher>
<marker>Butt, King, Ni˜no, Segond, 1999</marker>
<rawString>Miriam Butt, Tracy Holloway King, Mar´ıa-Eugenia Ni˜no, and Fr´ed´erique Segond. 1999. A Grammar Writer’s Cookbook. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
</authors>
<date>1993</date>
<booktitle>The Structure of Complex Predicates in Urdu. Ph.D. thesis,</booktitle>
<institution>Stanford University.</institution>
<contexts>
<context position="4087" citStr="Butt, 1993" startWordPosition="630" endWordPosition="631">languages such as English, benefiting from large enough corpora (Attia et al., 2010), parallel data (Zarrieß and Kuhn, 2009) and NLP tools such as taggers or dependency parsers (Martens and Vandeghinste (2010), among others) and lexical resources (Pearce, 2001). Related work on Indo-Aryan languages has mostly focused on the extraction of complex predicates, with the focus on Hindi (Mukerjee et al., 2006; Chakrabarti et al., 2008; Sinha, 2009) and Bengali (Das et al., 2010; Chakraborty and Bandyopadhyay, 2010). While complex predicates also make up a large part of the verbal inventory in Urdu (Butt, 1993), for the scope of this paper, we restrict ourselves to classifying MWEs as locations or person names and filter out junk bigrams. Our approach deviates in several aspects to the related work in Indo-Aryan: First, we do not concentrate on specific POS constructions or dependency relations, but use an unannotated middle-sized corpus. For classification, we use simple heuristics by taking the postpositions of the MWEs into account. These can provide hints as to the nature of the MWE. 3 Methodology 3.1 Extraction and Identification of MWE Candidates The bigram extraction was carried out on a corp</context>
</contexts>
<marker>Butt, 1993</marker>
<rawString>Miriam Butt. 1993. The Structure of Complex Predicates in Urdu. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Debasri Chakrabarti</author>
<author>Vaijayanthi M Sarma</author>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>Hindi Compound Verbs and their Automatic Extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>27--30</pages>
<contexts>
<context position="3908" citStr="Chakrabarti et al., 2008" startWordPosition="598" endWordPosition="601">ch work Proceedings of the ACL-HLT 2011 Student Session, pages 24–29, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics has been conducted for well-resourced languages such as English, benefiting from large enough corpora (Attia et al., 2010), parallel data (Zarrieß and Kuhn, 2009) and NLP tools such as taggers or dependency parsers (Martens and Vandeghinste (2010), among others) and lexical resources (Pearce, 2001). Related work on Indo-Aryan languages has mostly focused on the extraction of complex predicates, with the focus on Hindi (Mukerjee et al., 2006; Chakrabarti et al., 2008; Sinha, 2009) and Bengali (Das et al., 2010; Chakraborty and Bandyopadhyay, 2010). While complex predicates also make up a large part of the verbal inventory in Urdu (Butt, 1993), for the scope of this paper, we restrict ourselves to classifying MWEs as locations or person names and filter out junk bigrams. Our approach deviates in several aspects to the related work in Indo-Aryan: First, we do not concentrate on specific POS constructions or dependency relations, but use an unannotated middle-sized corpus. For classification, we use simple heuristics by taking the postpositions of the MWEs i</context>
</contexts>
<marker>Chakrabarti, Sarma, Bhattacharyya, 2008</marker>
<rawString>Debasri Chakrabarti, Vaijayanthi M. Sarma, and Pushpak Bhattacharyya. 2008. Hindi Compound Verbs and their Automatic Extraction. In Proceedings of COLING 2008, pages 27–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tanmoy Chakraborty</author>
<author>Sivaji Bandyopadhyay</author>
</authors>
<title>Identification of Reduplication in Bengali Corpus and their Semantic Analysis: A Rule-Based Approach.</title>
<date>2010</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: from Theory to Applications (MWE</booktitle>
<pages>72--75</pages>
<contexts>
<context position="3990" citStr="Chakraborty and Bandyopadhyay, 2010" startWordPosition="610" endWordPosition="614">Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics has been conducted for well-resourced languages such as English, benefiting from large enough corpora (Attia et al., 2010), parallel data (Zarrieß and Kuhn, 2009) and NLP tools such as taggers or dependency parsers (Martens and Vandeghinste (2010), among others) and lexical resources (Pearce, 2001). Related work on Indo-Aryan languages has mostly focused on the extraction of complex predicates, with the focus on Hindi (Mukerjee et al., 2006; Chakrabarti et al., 2008; Sinha, 2009) and Bengali (Das et al., 2010; Chakraborty and Bandyopadhyay, 2010). While complex predicates also make up a large part of the verbal inventory in Urdu (Butt, 1993), for the scope of this paper, we restrict ourselves to classifying MWEs as locations or person names and filter out junk bigrams. Our approach deviates in several aspects to the related work in Indo-Aryan: First, we do not concentrate on specific POS constructions or dependency relations, but use an unannotated middle-sized corpus. For classification, we use simple heuristics by taking the postpositions of the MWEs into account. These can provide hints as to the nature of the MWE. 3 Methodology 3.</context>
</contexts>
<marker>Chakraborty, Bandyopadhyay, 2010</marker>
<rawString>Tanmoy Chakraborty and Sivaji Bandyopadhyay. 2010. Identification of Reduplication in Bengali Corpus and their Semantic Analysis: A Rule-Based Approach. In Proceedings of the Workshop on Multiword Expressions: from Theory to Applications (MWE 2010), pages 72–75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dick Crouch</author>
<author>Mary Dalrymple</author>
<author>Ronald M Kaplan</author>
<author>Tracy Holloway King</author>
<author>John T Maxwell</author>
<author>Paula Newman</author>
</authors>
<title>XLE Documentation. Palo Alto Research Center.</title>
<date>2010</date>
<contexts>
<context position="12189" citStr="Crouch et al., 2010" startWordPosition="1996" endWordPosition="1999">Junk bigrams can be detected with an f-score of 0.379. Due to the heterogeneous nature of the miscellaneous MWEs (e.g., complex predicates), many of them are judged as being junk because they never occur with a postposition. If one could detect complex predicate and, possibly, other subgroups from the miscellaneous class, then classifying the junk MWEs would become easier. 5 Integration into the Urdu ParGram Grammar The extracted MWEs are integrated into the Urdu ParGram grammar (Butt and King, 2007; B¨ogel et al., 2007; B¨ogel et al., 2009), a computational grammar for Urdu running with XLE (Crouch et al., 2010) and based on the syntax formalism of LFG (Dalrymple, 2001). XLE grammars are generally handwritten and not acquired a machine learning process or the like. This makes grammar development a very conscious task and it is imperative to deal with MWEs in order to achieve a linguistically valid and deep syntactic analysis that can be used for an additional semantic analysis. MWEs that are correctly classified according to the gold standard are automatically integrated into the multiword lexicon of the grammar, accompanied by information about their nature (see example (3)). In general, grammar inp</context>
</contexts>
<marker>Crouch, Dalrymple, Kaplan, King, Maxwell, Newman, 2010</marker>
<rawString>Dick Crouch, Mary Dalrymple, Ronald M. Kaplan, Tracy Holloway King, John T. Maxwell III, and Paula Newman, 2010. XLE Documentation. Palo Alto Research Center.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Dalrymple</author>
</authors>
<title>Lexical Functional Grammar,</title>
<date>2001</date>
<volume>34</volume>
<publisher>Academic Press.</publisher>
<contexts>
<context position="2683" citStr="Dalrymple, 2001" startWordPosition="402" endWordPosition="403">vely small size of the available corpus and the simplistic approach taken. With the help of heuristics as to the occurrence of Urdu MWEs with characteristic postpositions and other cues, it is possible to cluster the MWEs into two groups: locations and person names. It is also possible to detect junk MWEs. The classification is then evaluated against a hand-annotated gold standard of Urdu MWEs. An NLP tool where the MWEs can be employed is the Urdu ParGram grammar (Butt and King, 2007; B¨ogel et al., 2007; B¨ogel et al., 2009), which is based on the Lexical-Functional Grammar (LFG) formalism (Dalrymple, 2001). For this task, different types of MWEs need to be distinguished as they are treated differently in the syntactic analysis. The paper is structured as follows: Section 2 provides a brief review of related work, in particular on MWE extraction in Indo-Aryan languages. Section 3 describes our methodology, with the evaluation following in Section 4. Section 5 presents the Urdu ParGram Grammar and its treatment of MWEs, followed by the discussion and the summary of the paper in Section 6. 2 Related Work MWE extraction and classification has been the focus of a large amount of research. However, m</context>
<context position="12248" citStr="Dalrymple, 2001" startWordPosition="2008" endWordPosition="2010">he heterogeneous nature of the miscellaneous MWEs (e.g., complex predicates), many of them are judged as being junk because they never occur with a postposition. If one could detect complex predicate and, possibly, other subgroups from the miscellaneous class, then classifying the junk MWEs would become easier. 5 Integration into the Urdu ParGram Grammar The extracted MWEs are integrated into the Urdu ParGram grammar (Butt and King, 2007; B¨ogel et al., 2007; B¨ogel et al., 2009), a computational grammar for Urdu running with XLE (Crouch et al., 2010) and based on the syntax formalism of LFG (Dalrymple, 2001). XLE grammars are generally handwritten and not acquired a machine learning process or the like. This makes grammar development a very conscious task and it is imperative to deal with MWEs in order to achieve a linguistically valid and deep syntactic analysis that can be used for an additional semantic analysis. MWEs that are correctly classified according to the gold standard are automatically integrated into the multiword lexicon of the grammar, accompanied by information about their nature (see example (3)). In general, grammar input is first tokenized by a standard tokenizer that separate</context>
</contexts>
<marker>Dalrymple, 2001</marker>
<rawString>Mary Dalrymple. 2001. Lexical Functional Grammar, volume 34 of Syntax and Semantics. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipankar Das</author>
</authors>
<title>Santanu Pal, Tapabrata Mondal, Tanmoy Chakraborty, and Sivaji Bandyopadhyay.</title>
<date>2010</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: from Theory to Applications (MWE</booktitle>
<pages>37--45</pages>
<marker>Das, 2010</marker>
<rawString>Dipankar Das, Santanu Pal, Tapabrata Mondal, Tanmoy Chakraborty, and Sivaji Bandyopadhyay. 2010. Automatic Extraction of Complex Predicates in Bengali. In Proceedings of the Workshop on Multiword Expressions: from Theory to Applications (MWE 2010), pages 37–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
</authors>
<title>The Statistics of Word Cooccurrences: Word Pairs and Collocations.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>IMS, University of Stuttgart.</institution>
<contexts>
<context position="5566" citStr="Evert (2004)" startWordPosition="870" endWordPosition="871">corpus, the frequency cut-off for bigrams was set to 5, i.e. all bigrams that occurred five times or more in the corpus were considered. This rendered a list of 172,847 bigrams which were then ranked with the X2 association measure, using the UCS toolkit.1 The reasons for employing the X2 association measure are twofold. First, papers using comparatively sized corpora reported encouraging results for similar experiments (Ramisch et al., 2008; Kizito et al., 2009). Second, initial manual comparison between MWE lists ranked according to all measures 1Available at http://www.collocations.de. See Evert (2004) for documentation. implemented in the UCS toolkit revealed the most convincing results for the X2 test. For the time being, we focus on bigram MWE extraction. While the UCS toolkit readily supports work on Unicode-based languages such as Urdu, it does not support trigram extraction; other freely available tools such as TEXT-NSP2 do come with trigram support, but cannot handle Unicode script. As a consequence, we currently implement our own scripts to overcome these limitations. 3.2 Syntactic Cues The clustering approach taken in this paper is based on Urdu-specific syntactic information that </context>
</contexts>
<marker>Evert, 2004</marker>
<rawString>Stefan Evert. 2004. The Statistics of Word Cooccurrences: Word Pairs and Collocations. Ph.D. thesis, IMS, University of Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarmad Hussain</author>
</authors>
<title>Resources for Urdu Language Processing.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th Workshop on Asian Language Resources, IJCNLP’08.</booktitle>
<contexts>
<context position="4832" citStr="Hussain, 2008" startWordPosition="752" endWordPosition="753">Our approach deviates in several aspects to the related work in Indo-Aryan: First, we do not concentrate on specific POS constructions or dependency relations, but use an unannotated middle-sized corpus. For classification, we use simple heuristics by taking the postpositions of the MWEs into account. These can provide hints as to the nature of the MWE. 3 Methodology 3.1 Extraction and Identification of MWE Candidates The bigram extraction was carried out on a corpus of around 8.12 million tokens of Urdu newspaper text, collected by the Center for Research in Urdu Language Processing (CRULP) (Hussain, 2008). We did not perform any pre-processing such as POS tagging or stop word removal. Due to the relatively small size of our corpus, the frequency cut-off for bigrams was set to 5, i.e. all bigrams that occurred five times or more in the corpus were considered. This rendered a list of 172,847 bigrams which were then ranked with the X2 association measure, using the UCS toolkit.1 The reasons for employing the X2 association measure are twofold. First, papers using comparatively sized corpora reported encouraging results for similar experiments (Ramisch et al., 2008; Kizito et al., 2009). Second, i</context>
</contexts>
<marker>Hussain, 2008</marker>
<rawString>Sarmad Hussain. 2008. Resources for Urdu Language Processing. In Proceedings of the 6th Workshop on Asian Language Resources, IJCNLP’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Kizito</author>
</authors>
<title>Ismail Fahmi, Erik Tjong Kim Sang, Gosse Bouma, and</title>
<date>2009</date>
<booktitle>Computational Linguistics and the History of Science. In Liborio Dibattista, editor, Storia della Scienza e Linguistica Computazionale. FrancoAngeli.</booktitle>
<marker>Kizito, 2009</marker>
<rawString>John Kizito, Ismail Fahmi, Erik Tjong Kim Sang, Gosse Bouma, and John Nerbonne. 2009. Computational Linguistics and the History of Science. In Liborio Dibattista, editor, Storia della Scienza e Linguistica Computazionale. FrancoAngeli.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Muhammad Kamran Malik</author>
<author>Tafseer Ahmed</author>
<author>Sebastian Sulger</author>
<author>Tina B¨ogel</author>
<author>Atif Gulzar</author>
<author>Ghulam Raza</author>
<author>Sarmad Hussain</author>
<author>Miriam Butt</author>
</authors>
<title>Transliterating Urdu for a Broad-Coverage Urdu/Hindi LFG Grammar.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC’10).</booktitle>
<marker>Malik, Ahmed, Sulger, B¨ogel, Gulzar, Raza, Hussain, Butt, 2010</marker>
<rawString>Muhammad Kamran Malik, Tafseer Ahmed, Sebastian Sulger, Tina B¨ogel, Atif Gulzar, Ghulam Raza, Sarmad Hussain, and Miriam Butt. 2010. Transliterating Urdu for a Broad-Coverage Urdu/Hindi LFG Grammar. In Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC’10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Martens</author>
<author>Vincent Vandeghinste</author>
</authors>
<title>An Efficient, Generic Approach to Extracting Multi-Word Expressions from Dependency Trees.</title>
<date>2010</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: from Theory to Applications (MWE</booktitle>
<pages>84--87</pages>
<contexts>
<context position="3685" citStr="Martens and Vandeghinste (2010)" startWordPosition="563" endWordPosition="566">e Urdu ParGram Grammar and its treatment of MWEs, followed by the discussion and the summary of the paper in Section 6. 2 Related Work MWE extraction and classification has been the focus of a large amount of research. However, much work Proceedings of the ACL-HLT 2011 Student Session, pages 24–29, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics has been conducted for well-resourced languages such as English, benefiting from large enough corpora (Attia et al., 2010), parallel data (Zarrieß and Kuhn, 2009) and NLP tools such as taggers or dependency parsers (Martens and Vandeghinste (2010), among others) and lexical resources (Pearce, 2001). Related work on Indo-Aryan languages has mostly focused on the extraction of complex predicates, with the focus on Hindi (Mukerjee et al., 2006; Chakrabarti et al., 2008; Sinha, 2009) and Bengali (Das et al., 2010; Chakraborty and Bandyopadhyay, 2010). While complex predicates also make up a large part of the verbal inventory in Urdu (Butt, 1993), for the scope of this paper, we restrict ourselves to classifying MWEs as locations or person names and filter out junk bigrams. Our approach deviates in several aspects to the related work in Ind</context>
</contexts>
<marker>Martens, Vandeghinste, 2010</marker>
<rawString>Scott Martens and Vincent Vandeghinste. 2010. An Efficient, Generic Approach to Extracting Multi-Word Expressions from Dependency Trees. In Proceedings of the Workshop on Multiword Expressions: from Theory to Applications (MWE 2010), pages 84–87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amitabha Mukerjee</author>
<author>Ankit Soni</author>
<author>Achla M Raina</author>
</authors>
<title>Detecting Complex Predicates in Hindi using POS Projection across Parallel Corpora.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties (MWE ’06),</booktitle>
<pages>28--35</pages>
<contexts>
<context position="3882" citStr="Mukerjee et al., 2006" startWordPosition="594" endWordPosition="597">f research. However, much work Proceedings of the ACL-HLT 2011 Student Session, pages 24–29, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics has been conducted for well-resourced languages such as English, benefiting from large enough corpora (Attia et al., 2010), parallel data (Zarrieß and Kuhn, 2009) and NLP tools such as taggers or dependency parsers (Martens and Vandeghinste (2010), among others) and lexical resources (Pearce, 2001). Related work on Indo-Aryan languages has mostly focused on the extraction of complex predicates, with the focus on Hindi (Mukerjee et al., 2006; Chakrabarti et al., 2008; Sinha, 2009) and Bengali (Das et al., 2010; Chakraborty and Bandyopadhyay, 2010). While complex predicates also make up a large part of the verbal inventory in Urdu (Butt, 1993), for the scope of this paper, we restrict ourselves to classifying MWEs as locations or person names and filter out junk bigrams. Our approach deviates in several aspects to the related work in Indo-Aryan: First, we do not concentrate on specific POS constructions or dependency relations, but use an unannotated middle-sized corpus. For classification, we use simple heuristics by taking the p</context>
</contexts>
<marker>Mukerjee, Soni, Raina, 2006</marker>
<rawString>Amitabha Mukerjee, Ankit Soni, and Achla M. Raina. 2006. Detecting Complex Predicates in Hindi using POS Projection across Parallel Corpora. In Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties (MWE ’06), pages 28–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Pearce</author>
</authors>
<title>Synonymy in Collocation Extraction.</title>
<date>2001</date>
<booktitle>In WordNet and Other Lexical Resources: Applications, Extensions &amp; Customizations,</booktitle>
<pages>41--46</pages>
<contexts>
<context position="3737" citStr="Pearce, 2001" startWordPosition="572" endWordPosition="573">ussion and the summary of the paper in Section 6. 2 Related Work MWE extraction and classification has been the focus of a large amount of research. However, much work Proceedings of the ACL-HLT 2011 Student Session, pages 24–29, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics has been conducted for well-resourced languages such as English, benefiting from large enough corpora (Attia et al., 2010), parallel data (Zarrieß and Kuhn, 2009) and NLP tools such as taggers or dependency parsers (Martens and Vandeghinste (2010), among others) and lexical resources (Pearce, 2001). Related work on Indo-Aryan languages has mostly focused on the extraction of complex predicates, with the focus on Hindi (Mukerjee et al., 2006; Chakrabarti et al., 2008; Sinha, 2009) and Bengali (Das et al., 2010; Chakraborty and Bandyopadhyay, 2010). While complex predicates also make up a large part of the verbal inventory in Urdu (Butt, 1993), for the scope of this paper, we restrict ourselves to classifying MWEs as locations or person names and filter out junk bigrams. Our approach deviates in several aspects to the related work in Indo-Aryan: First, we do not concentrate on specific PO</context>
</contexts>
<marker>Pearce, 2001</marker>
<rawString>David Pearce. 2001. Synonymy in Collocation Extraction. In WordNet and Other Lexical Resources: Applications, Extensions &amp; Customizations, pages 41–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Ramisch</author>
<author>Paulo Schreiner</author>
<author>Marco Idiart</author>
<author>Aline Villavicencio</author>
</authors>
<title>An Evaluation of Methods for the Extraction of Multiword Expressions.</title>
<date>2008</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: Towards a Shared Taskfor Multiword Expressions (MWE</booktitle>
<contexts>
<context position="5399" citStr="Ramisch et al., 2008" startWordPosition="845" endWordPosition="848">h in Urdu Language Processing (CRULP) (Hussain, 2008). We did not perform any pre-processing such as POS tagging or stop word removal. Due to the relatively small size of our corpus, the frequency cut-off for bigrams was set to 5, i.e. all bigrams that occurred five times or more in the corpus were considered. This rendered a list of 172,847 bigrams which were then ranked with the X2 association measure, using the UCS toolkit.1 The reasons for employing the X2 association measure are twofold. First, papers using comparatively sized corpora reported encouraging results for similar experiments (Ramisch et al., 2008; Kizito et al., 2009). Second, initial manual comparison between MWE lists ranked according to all measures 1Available at http://www.collocations.de. See Evert (2004) for documentation. implemented in the UCS toolkit revealed the most convincing results for the X2 test. For the time being, we focus on bigram MWE extraction. While the UCS toolkit readily supports work on Unicode-based languages such as Urdu, it does not support trigram extraction; other freely available tools such as TEXT-NSP2 do come with trigram support, but cannot handle Unicode script. As a consequence, we currently implem</context>
</contexts>
<marker>Ramisch, Schreiner, Idiart, Villavicencio, 2008</marker>
<rawString>Carlos Ramisch, Paulo Schreiner, Marco Idiart, and Aline Villavicencio. 2008. An Evaluation of Methods for the Extraction of Multiword Expressions. In Proceedings of the Workshop on Multiword Expressions: Towards a Shared Taskfor Multiword Expressions (MWE 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mahesh K Sinha</author>
</authors>
<title>Mining Complex Predicates in Hindi Using a Parallel Hindi-English Corpus.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Workshop on Multiword Expressions, ACL-IJCNLP</booktitle>
<pages>40--46</pages>
<contexts>
<context position="3922" citStr="Sinha, 2009" startWordPosition="602" endWordPosition="603"> ACL-HLT 2011 Student Session, pages 24–29, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics has been conducted for well-resourced languages such as English, benefiting from large enough corpora (Attia et al., 2010), parallel data (Zarrieß and Kuhn, 2009) and NLP tools such as taggers or dependency parsers (Martens and Vandeghinste (2010), among others) and lexical resources (Pearce, 2001). Related work on Indo-Aryan languages has mostly focused on the extraction of complex predicates, with the focus on Hindi (Mukerjee et al., 2006; Chakrabarti et al., 2008; Sinha, 2009) and Bengali (Das et al., 2010; Chakraborty and Bandyopadhyay, 2010). While complex predicates also make up a large part of the verbal inventory in Urdu (Butt, 1993), for the scope of this paper, we restrict ourselves to classifying MWEs as locations or person names and filter out junk bigrams. Our approach deviates in several aspects to the related work in Indo-Aryan: First, we do not concentrate on specific POS constructions or dependency relations, but use an unannotated middle-sized corpus. For classification, we use simple heuristics by taking the postpositions of the MWEs into account. T</context>
</contexts>
<marker>Sinha, 2009</marker>
<rawString>R. Mahesh K. Sinha. 2009. Mining Complex Predicates in Hindi Using a Parallel Hindi-English Corpus. In Proceedings of the 2009 Workshop on Multiword Expressions, ACL-IJCNLP 2009, pages 40–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sina Zarrieß</author>
<author>Jonas Kuhn</author>
</authors>
<title>Exploiting Translational Correspondences for Pattern-Independent MWE Identification.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Workshop on Multiword Expressions, ACL-IJCNLP</booktitle>
<pages>23--30</pages>
<contexts>
<context position="3600" citStr="Zarrieß and Kuhn, 2009" startWordPosition="549" endWordPosition="552">ethodology, with the evaluation following in Section 4. Section 5 presents the Urdu ParGram Grammar and its treatment of MWEs, followed by the discussion and the summary of the paper in Section 6. 2 Related Work MWE extraction and classification has been the focus of a large amount of research. However, much work Proceedings of the ACL-HLT 2011 Student Session, pages 24–29, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics has been conducted for well-resourced languages such as English, benefiting from large enough corpora (Attia et al., 2010), parallel data (Zarrieß and Kuhn, 2009) and NLP tools such as taggers or dependency parsers (Martens and Vandeghinste (2010), among others) and lexical resources (Pearce, 2001). Related work on Indo-Aryan languages has mostly focused on the extraction of complex predicates, with the focus on Hindi (Mukerjee et al., 2006; Chakrabarti et al., 2008; Sinha, 2009) and Bengali (Das et al., 2010; Chakraborty and Bandyopadhyay, 2010). While complex predicates also make up a large part of the verbal inventory in Urdu (Butt, 1993), for the scope of this paper, we restrict ourselves to classifying MWEs as locations or person names and filter </context>
</contexts>
<marker>Zarrieß, Kuhn, 2009</marker>
<rawString>Sina Zarrieß and Jonas Kuhn. 2009. Exploiting Translational Correspondences for Pattern-Independent MWE Identification. In Proceedings of the 2009 Workshop on Multiword Expressions, ACL-IJCNLP 2009, pages 23–30.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>