<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000770">
<title confidence="0.962002">
An Unsupervised Morpheme-Based HMM for Hebrew
Morphological Disambiguation
</title>
<author confidence="0.98094">
Meni Adler
</author>
<affiliation confidence="0.9726305">
Department of Computer Science
Ben Gurion University of the Negev
</affiliation>
<address confidence="0.885703">
84105 Beer Sheva, Israel
</address>
<email confidence="0.998723">
adlerm@cs.bgu.ac.il
</email>
<author confidence="0.991182">
Michael Elhadad
</author>
<affiliation confidence="0.9726715">
Department of Computer Science
Ben Gurion University of the Negev
</affiliation>
<address confidence="0.885934">
84105 Beer Sheva, Israel
</address>
<email confidence="0.999336">
elhadad@cs.bgu.ac.il
</email>
<sectionHeader confidence="0.997395" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99997624137931">
Morphological disambiguation is the pro-
cess of assigning one set of morphologi-
cal features to each individual word in a
text. When the word is ambiguous (there
are several possible analyses for the word),
a disambiguation procedure based on the
word context must be applied. This paper
deals with morphological disambiguation
of the Hebrew language, which combines
morphemes into a word in both agglutina-
tive and fusional ways. We present an un-
supervised stochastic model – the only re-
source we use is a morphological analyzer –
which deals with the data sparseness prob-
lem caused by the affixational morphology
of the Hebrew language.
We present a text encoding method for
languages with affixational morphology in
which the knowledge of word formation
rules (which are quite restricted in He-
brew) helps in the disambiguation. We
adapt HMM algorithms for learning and
searching this text representation, in such
a way that segmentation and tagging can
be learned in parallel in one step. Results
on a large scale evaluation indicate that
this learning improves disambiguation for
complex tag sets. Our method is applicable
to other languages with affix morphology.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999921666666667">
Morphological disambiguation is the process of as-
signing one set of morphological features to each
individual word in a text, according to the word
context.
In this work, we investigate morphological dis-
ambiguation in Modern Hebrew. We explore unsu-
pervised learning method, which is more challeng-
ing than the supervised case. The main motivation
for this approach is that despite the development
</bodyText>
<note confidence="0.89850725">
*This work is supported by the Lynn and William
Frankel Center for Computer Sciences, and by the
Knowledge Center for Hebrew Processing, Israel Sci-
ence Ministry.
</note>
<bodyText confidence="0.999859804878049">
of annotated corpora in Hebrew&apos;, there is still not
enough data available for supervised training. The
other reason, is that unsupervised methods can
handle the dynamic nature of Modern Hebrew, as
it evolves over time.
In the case of English, because morphology is
simpler, morphological disambiguation is generally
covered under the task of part-of-speech tagging.
The main morphological variations are embedded
in the tag name (for example, Ns and Np for
noun singular or plural). The tagging accuracy
of supervised stochastic taggers is around 96%-
97% (Manning and Schutze, 1999, 10.6.1). Meri-
aldo (1994) reports an accuracy of 86.6% for an un-
supervised word-based HMM, trained on a corpus
of 42,186 sentences (about 1M words), over a tag
set of 159 different tags. Elworthy (1994), in con-
trast, reports an accuracy of 75.49%, 80.87% and
79.12% for unsupervised word-based HMM trained
on parts of the LOB corpora, with a tagset of
134 tags. With good initial conditions, such as
good approximation of the tag distribution for each
word, Elworthy reports an improvement to 94.6%,
92.27% and 94.51% on the same data sets. Meri-
aldo, on the other hand, reports an improvement
to 92.6% and 94.4% for the case where 100 and
2000 sentences of the training corpus are manually
tagged.
Modern Hebrew is characterized by rich mor-
phology, with a high level of ambiguity. On aver-
age, in our corpus, the number of possible analyses
per word reached 2.4 (in contrast to 1.4 for En-
glish). In Hebrew, several morphemes combine into
a single word in both agglutinative and fusional
ways. This results in a potentially high number of
tags for each word.
In contrast to English tag sets whose sizes range
from 48 to 195, the number of tags for Hebrew,
based on all combinations of the morphological
attributes (part-of-speech, gender, number, per-
son, tense, status, and the affixes&apos; properties2),
</bodyText>
<note confidence="0.6510954">
&apos;The Knowledge Center for Hebrew processing is
developing such corpora: http://mila.cs.technion.ac.il/
2The list of morphological attributes is described in
(Yona and Wintner, 2005). An in-depth discussion of
the Hebrew word form is provided in (Allon, 1995, pp.
</note>
<page confidence="0.959623">
665
</page>
<note confidence="0.545825">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 665–672,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999873666666667">
can grow theoretically to about 300,000 tags. In
practice, we found only 1,934 tags in a corpus of
news stories we gathered, which contains about 6M
words.
The large size of such a tag set (about 10 times
larger than the most comprehensive English tag
set) is problematic in term of data sparseness.
Each morphological combination appears rarely,
and more samples are required in order to learn
the probabilistic model.
In this paper, we hypothesize that the large set
of morphological features of Hebrew words, should
be modeled by a compact morpheme model, based
on the segmented words (into prefix, baseform, and
suffix). Our main result is that best performance
is obtained when learning segmentation and mor-
pheme tagging in one step, which is made possible
by an appropriate text representation.
</bodyText>
<sectionHeader confidence="0.953933" genericHeader="introduction">
2 Hebrew and Arabic Tagging -
</sectionHeader>
<subsectionHeader confidence="0.550327">
Previous Work
</subsectionHeader>
<bodyText confidence="0.99618970212766">
Several works have dealt with Hebrew tagging in
the past decade. In Hebrew, morphological anal-
ysis requires complex processing according to the
rules of Hebrew word formation. The task of a
morphological analyzer is to produce all possible
analyses for a given word. Recent analyzers pro-
vide good performance and documentation of this
process (Yona and Wintner, 2005; Segal, 2000).
Morphological analyzers rely on a dictionary, and
their performance is, therefore, impacted by the oc-
currence of unknown words. The task of a morpho-
logical disambiguation system is to pick the most
likely analysis produced by an analyzer in the con-
text of a full sentence.
Levinger et al. (1995) developed a context-free
method in order to acquire the morpho-lexical
probabilities, from an untagged corpus. Their
method handles the data sparseness problem by
using a set of similar words for each word, built
according to a set of rules. The rules produce vari-
ations of the morphological properties of the word
analyses. Their tests indicate an accuracy of about
88% for context-free analysis selection based on the
approximated analysis distribution. In tests we re-
produced on a larger data set (30K tagged words),
the accuracy is only 78.2%. In order to improve
the results, the authors recommend merging their
method together with other morphological disam-
biguation methods – which is the approach we pur-
sue in this work.
Levinger&apos;s morphological disambiguation sys-
tem (Levinger, 1992) combines the above approx-
imated probabilities with an expert system, based
on a manual set of 16 syntactic constraints . In
the first phase, the expert system is applied, dis-
24–86).
ambiguating 35% of the ambiguous words with an
accuracy of 99.6%. In order to increase the applica-
bility of the disambiguation, approximated proba-
bilities are used for words that were not disam-
biguated in the first stage. Finally, the expert sys-
tem is used again over the new probabilities that
were set in the previous stage. Levinger reports
an accuracy of about 94% for disambiguation of
85% of the words in the text (overall 80% disam-
biguation). The system was also applied to prune
out the least likely analyses in a corpus but with-
out, necessarily, selecting a single analysis for each
word. For this task, an accuracy of 94% was re-
ported while reducing 92% of the ambiguous anal-
yses.
Carmel and Maarek (1999) use the fact that
on average 45% of the Hebrew words are unam-
biguous, to rank analyses, based on the number
of disambiguated occurrences in the text, normal-
ized by the total number of occurrences for each
word. Their application – indexing for an informa-
tion retrieval system – does not require all of the
morphological attributes but only the lemma and
the PoS of each word. As a result, for this case,
75% of the words remain with one analysis with
95% accuracy, 20% with two analyses and 5% with
three analyses.
Segal (2000) built a transformation-based tag-
ger in the spirit of Brill (1995). In the first phase,
the analyses of each word are ranked according to
the frequencies of the possible lemmas and tags in
a training corpus of about 5,000 words. Selection
of the highest ranked analysis for each word gives
an accuracy of 83% of the test text – which con-
sists of about 1,000 words. In the second stage,
a transformation learning algorithm is applied (in
contrast to Brill, the observed transformations are
not applied, but used for re-estimation of the word
couples probabilities). After this stage, the accu-
racy is about 93%. The last stage uses a bottom-
up parser over a hand-crafted grammar with 150
rules, in order to select the analysis which causes
the parsing to be more accurate. Segal reports an
accuracy of 95%. Testing his system over a larger
test corpus, gives poorer results: Lembersky (2001)
reports an accuracy of about 85%.
Bar-Haim et al. (2005) developed a word seg-
menter and PoS tagger for Hebrew. In their archi-
tecture, words are first segmented into morphemes,
and then, as a second stage, these morphemes are
tagged with PoS. The method proceeds in two
sequential steps: segmentation into morphemes,
then tagging over morphemes. The segmentation
is based on an HMM and trained over a set of 30K
annotated words. The segmentation step reaches
an accuracy of 96.74%. PoS tagging, based on un-
supervised estimation which combines a small an-
notated corpus with an untagged corpus of 340K
</bodyText>
<page confidence="0.996224">
666
</page>
<table confidence="0.999650636363636">
Word Segmentation Tag Translation
bclm bclm PNN name of a human rights association (Betselem)
bclm bclm VB while taking a picture
bclm bcl-m cons-NNM-suf their onion
bclm b-cl-m P1-NNM-suf under their shadow
bclm b-clm P1-NNM in a photographer
bclm b-clm P1-cons-NNM in a photographer
bclm b-clm P1-h-NNM in the photographer
hn`im h-n`im P1-VBR that are moving
hn`im hn`im P1-h-JJM the lovely
hn`im hn`im VBP made pleasant
</table>
<tableCaption confidence="0.999932">
Table 1: Possible analyses for the words bclm hn`im
</tableCaption>
<bodyText confidence="0.997870283333334">
words by using smoothing technique, gives an ac-
curacy of 90.51%.
As noted earlier, there is as yet no large scale
Hebrew annotated corpus. We are in the process
of developing such a corpus, and we have devel-
oped tagging guidelines (Elhadad et al., 2005) to
define a comprehensive tag set, and assist human
taggers achieve high agreement. The results dis-
cussed above should be taken as rough approxima-
tions of the real performance of the systems, until
they can be re-evaluated on such a large scale cor-
pus with a standard tag set.
Arabic is a language with morphology quite sim-
ilar to Hebrew. Theoretically, there might be
330,000 possible morphological tags, but in prac-
tice, Habash and Rambow (2005) extracted 2,200
different tags from their corpus, with an average
number of 2 possible tags per word. As reported
by Habash and Rambow, the first work on Arabic
tagging which used a corpus for training and eval-
uation was the work of Diab et al. (2004). Habash
and Rambow were the first to use a morphological
analyzer as part of their tagger. They developed a
supervised morphological disambiguator, based on
training corpora of two sets of 120K words, which
combines several classifiers of individual morpho-
logical features. The accuracy of their analyzer
is 94.8% – 96.2% (depending on the test corpus).
An unsupervised HMM model for dialectal Ara-
bic (which is harder to be tagged than written
Arabic), with accurracy of 69.83%, was presented
by Duh and Kirchhoff (2005). Their supervised
model, trained on a manually annotated corpus,
reached an accuracy of 92.53%.
Arabic morphology seems to be similar to He-
brew morphology, in term of complexity and data
sparseness, but comparison of the performances
of the baseline tagger used by Habash and Ram-
bow – which selects the most frequent tag for a
given word in the training corpus – for Hebrew and
Arabic, shows some intriguing differences: 92.53%
for Arabic and 71.85% for Hebrew. Furthermore,
as mentioned above, even the use of a sophisti-
cated context-free tagger, based on (Levinger et
al., 1995), gives low accuracy of 78.2%. This might
imply that, despite the similarities, morphological
disambiguation in Hebrew might be harder than in
Arabic. It could also mean that the tag set used
for the Arabic corpora has not been adapted to the
specific nature of Arabic morphology (a comment
also made in (Habash and Rambow, 2005)).
We propose an unsupervised morpheme-based
HMM to address the data sparseness problem. In
contrast to Bar-Haim et al., our model combines
segmentation and morphological disambiguation,
in parallel. The only resource we use in this work is
a morphological analyzer. The analyzer itself can
be generated from a word list and a morphologi-
cal generation module, such as the HSpell wordlist
(Har&apos;el and Kenigsberg, 2004).
</bodyText>
<sectionHeader confidence="0.9959925" genericHeader="method">
3 Morpheme-Based Model for
Hebrew
</sectionHeader>
<subsectionHeader confidence="0.999175">
3.1 Morpheme-Based HMM
</subsectionHeader>
<bodyText confidence="0.999986636363636">
The lexical items of word-based models are the
words of the language. The implication of this
decision is that both lexical and syntagmatic re-
lations of the model, are based on a word-oriented
tagset. With such a tagset, it must be possible to
tag any word of the language with at least one tag.
Let us consider, for instance, the Hebrew phrase
bclm hn`im3, which contains two words. The word
bclm has several possible morpheme segmentations
and analyses as described in Table 1. In word-
based HMM, we consider such a phrase to be gen-
erated by a Markov process, based on the word-
oriented tagset of N = 1934 tags/states and about
M = 175K word types. Line W of Table 2 de-
scribes the size of a first-order word-based HMM,
built over our corpus. In this model, we found 834
entries for the II vector (which models the distri-
bution of tags in first position in sentences) out of
possibly N = 1934, about 250K entries for the A
matrix (which models the transition probabilities
from tag to tag) out of possibly N2 ;::Li 3.7M, and
about 300K entries for the B matrix (which models
</bodyText>
<subsectionHeader confidence="0.521409">
3Transcription according to Ornan (2002).
</subsectionHeader>
<footnote confidence="0.9487765">
4The tagset we use for the annotation follows the
guidelines we have developed (Elhadad et al., 2005).
</footnote>
<page confidence="0.986206">
667
</page>
<table confidence="0.971116333333333">
States PI A A2 B B2
W 1934 834 250K 7M 300K 5M
M 202 145 20K 700K 130K 1.7M
</table>
<tableCaption confidence="0.982979">
Table 2: Model Sizes
</tableCaption>
<bodyText confidence="0.9999740625">
the emission probabilities from tag to word) out of
possibly M · N ;::Li 350M. For the case of a second-
order HMM, the size of the A2 matrix (which mod-
els the transition probabilities from two tags to the
third one), grows to about 7M entries, where the
size of the B2 matrix (which models the emission
probabilities from two tags to a word) is about 5M.
Despite the sparseness of these matrices, the num-
ber of their entries is still high, since we model the
whole set of features of the complex word forms.
Let us assume, that the right segmentation for
the sentence is provided to us – for example: b
clm hn`im – as is the case for English text. In
such a way, the observation is composed of mor-
phemes, generated by a Markov process, based
on a morpheme-based tagset. The size of such a
tagset for Hebrew is about 200, where the size of
the II,A,B,A2 and B2 matrices is reduced to 145,
16K, 140K, 700K, and 1.7M correspondingly, as
described in line M of Table 2 – a reduction of
90% when compared with the size of a word-based
model.
The problem in this approach, is that ”someone”
along the way, agglutinates the morphemes of each
word leaving the observed morphemes uncertain.
For example, the word bclm can be segmented in
four different ways in Table 1, as indicated by the
placement of the &apos;-&apos; in the Segmentation column,
while the word hn`im can be segmented in two dif-
ferent ways. In the next section, we adapt the pa-
rameter estimation and the searching algorithms
for such uncertain output observation.
</bodyText>
<subsectionHeader confidence="0.9505375">
3.2 Learning and Searching Algorithms
for Uncertain Output Observation
</subsectionHeader>
<bodyText confidence="0.999968166666667">
In contrast to standard HMM, the output observa-
tions of the above morpheme-based HMM are am-
biguous. We adapted Baum-Welch (Baum, 1972)
and Viterbi (Manning and Schutze, 1999, 9.3.2) al-
gorithms for such uncertain observation. We first
formalize the output representation and then de-
scribe the algorithms.
Output Representation The learning and
searching algorithms of HMM are based on the
output sequence of the underlying Markov pro-
cess. For the case of a morpheme-based model,
the output sequence is uncertain – we don’t see the
emitted morphemes but the words they form. If,
for instance, the Markov process emitted the mor-
phemes b clm h nim, we would see two words (bclm
hn`im) instead. In order to handle the output am-
biguity, we use static knowledge of how morphemes
are combined into a word, such as the four known
combinations of the word bclm, the two possible
combinations of the word hn`im, and their possi-
ble tags within the original words. Based on this
information, we encode the sentence into a struc-
ture that represents all the possible “readings” of
the sentence, according to the possible morpheme
combinations of the words, and their possible tags.
The representation consists of a set of vectors,
each vector containing the possible morphemes and
their tags for each specific “time” (sequential posi-
tion within the morpheme expansion of the words
of the sentence). A morpheme is represented by
a tuple (symbol, state, prev, next), where symbol
denotes a morpheme, state is one possible tag for
this morpheme, prev and next are sets of indexes,
denoting the indexes of the morphemes (of the pre-
vious and the next vectors) that precede and follow
the current morpheme in the overall lattice, repre-
senting the sentence. Fig. 2 describes the repre-
sentation of the sentence bclm hn`im. An emission
is denoted in this figure by its symbol, its state
index, directed edges from its previous emissions,
and directed edges to its next emissions.
In order to meet the condition of Baum-Eagon
inequality (Baum, 1972) that the polynomial
P(O|µ) – which represents the probability of an
observed sequence O given a model µ – be homo-
geneous, we must add a sequence of special EOS
(end of sentence) symbols at the end of each path
up to the last vector, so that all the paths reach
the same length.
The above text representation can be used to
model multi-word expressions (MWEs). Consider
the Hebrew sentence: hw&apos; `wrk dyn gdwl, which can
be interpreted as composed of 3 units (he lawyer
great / he is a great lawyer) or as 4 units (he edits
law big / he is editing an important legal deci-
sion). In order to select the correct interpretation,
we must determine whether `wrk dyn is an MWE.
This is another case of uncertain output observa-
tion, which can be represented by our text encod-
ing, as done in Fig. 1.
</bodyText>
<figureCaption confidence="0.998664">
Figure 1: The sentence hw&apos; `wrk dyn gdwl
</figureCaption>
<bodyText confidence="0.9999853">
This representation seems to be expensive in
term of the number of emissions per sentence.
However, we observe in our data that most of the
words have only one or two possible segmentations,
and most of the segmentations consist of at most
one affix. In practice, we found the average number
of emissions per sentence in our corpus (where each
symbol is counted as the number of its predecessor
emissions) to be 455, where the average number
of words per sentence is about 18. That is, the
</bodyText>
<equation confidence="0.754918">
hw’ 20
‘wrk dyn 6 gdwl 19 EOS 17 EOS 17
‘wrk 18
dyn 6 gdwl 19
</equation>
<page confidence="0.985534">
668
</page>
<bodyText confidence="0.998470674698795">
cost of operating over an ambiguous sentence rep-
resentation increases the size of the sentence (from
18 to 455), but on the other hand, it reduces the
probabilistic model by a factor of 10 (as discussed
above).
Morphological disambiguation over such a se-
quence of vectors of uncertain morphemes is similar
to words extraction in automatic speech recogni-
tion (ASR)(Jurafsky and Martin, 2000, chp. 5,7).
The states of the ASR model are phones, where
each observation is a vector of spectral features.
Given a sequence of observations for a sentence,
the encoding – based on the lattice formed by the
phones distribution of the observations, and the
language model – searches for the set of words,
made of phones, which maximizes the acoustic like-
lihood and the language model probabilities. In a
similar manner, the supervised training of a speech
recognizer combines a training corpus of speech
wave files, together with word-transcription, and
language model probabilities, in order to learn the
phones model.
There are two main differences between the typi-
cal ASR model and ours: (1) an ASR decoder deals
with one aspect - segmentation of the observations
into a set of words, where this segmentation can
be modeled at several levels: subphones, phones
and words. These levels can be trained individ-
ually (such as training a language model from a
written corpus, and training the phones model for
each word type, given transcripted wave file), and
then combined together (in a hierarchical model).
Morphological disambiguation over uncertain mor-
phemes, on the other hand, deals with both mor-
pheme segmentation and the tagging of each mor-
pheme with its morphological features. Model-
ing morpheme segmentation, within a given word,
without its morphology features would be insuf-
ficient. (2) The supervised resources of ASR are
not available for morphological disambiguation: we
don’t have a model of morphological features se-
quences (equivalent to the language model of ASR)
nor a tagged corpus (equivalent to the transcripted
wave files of ASR).
These two differences require a design which
combines the two dimensions of the problem, in or-
der to support unsupervised learning (and search-
ing) of morpheme sequences and their morpholog-
ical features, simultaneously.
Parameter Estimation We present a variation
of the Baum-Welch algorithm (Baum, 1972) which
operates over the lattice representation we have de-
fined above. The algorithm starts with a proba-
bilistic model µ (which can be chosen randomly
or obtained from good initial conditions), and at
each iteration, a new model µ� is derived in order to
better explain the given output observations. For a
given sentence, we define T as the number of words
in the sentence, and T as the number of vectors of
the output representation O = {ot},1 &lt; t &lt; T,
where each item in the output is denoted by olt =
(sym, state, prev, next),1 &lt; t &lt; T,1 &lt; l &lt; |ot|.
We define a(t, l) as the probability to reach olt at
time t, and 0(t, l) as the probability to end the se-
quence from olt. Fig. 3 describes the expectation
and the maximization steps of the learning algo-
rithm for a first-order HMM. The algorithm works
in O(T) time complexity, where T is the total num-
ber of symbols in the output sequence encoding,
where each symbol is counted as the size of its prev
set.
Searching for best state sequence The
searching algorithm gets an observation sequence
O and a probabilistic model µ, and looks for the
best state sequence that generates the observation.
We define S(t, l) as the probability of the best state
sequence that leads to emission olt, and�(t, l) as
the index of the emission at time t−1 that precedes
olt in the best state sequence that leads to it. Fig. 4
describes the adaptation of the Viterbi (Manning
and Schutze, 1999, 9.3.2) algorithm to our text rep-
resentation for first-order HMM, which works in
O(T) time.
</bodyText>
<sectionHeader confidence="0.997844" genericHeader="evaluation">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.999589870967742">
We ran a series of experiments on a Hebrew corpus
to compare various approaches to the full morpho-
logical disambiguation and PoS tagging tasks. The
training corpus is obtained from various newspa-
per sources and is characterized by the following
statistics: 6M word occurrences, 178,580 distinct
words, 64,541 distinct lemmas. Overall, the ambi-
guity level is 2.4 (average number of analyses per
word).
We tested the results on a test corpus, manually
annotated by 2 taggers according to the guidelines
we published and checked for agreement. The test
corpus contains about 30K words. We compared
two unsupervised models over this data set: Word
model [W], and Morpheme model [M]. We also
tested two different sets of initial conditions. Uni-
form distribution [Uniform]: For each word, each
analysis provided by the analyzer is estimated with
an equal likelihood. Context Free approximation
[CF]: We applied the CF algorithm of Levinger et
al.(1995) to estimate the likelihood of each analy-
sis.
Table 3 reports the results of full morphologi-
cal disambiguation. For each morpheme and word
models, three types of models were tested: [1]
First-order HMM, [2-] Partial second-order HMM -
only state transitions were modeled (excluding B2
matrix), [2] Second-order HMM (including the B2
matrix).
Analysis If we consider the tagger which selects
the most probable morphological analysis for each
</bodyText>
<page confidence="0.985776">
669
</page>
<figure confidence="0.972474033333333">
bcl 6
bclm 5
b 0
b 1
m 3
clm 7 hn‘im 14
hn‘im 15
h 2
hn‘im 11
hn‘im 12
h 2 EOS 17
clm 10
cl 9
hn‘im 14
hn‘im 15
hn‘im 11
hn‘im 12
clm 8
m 4
n‘im 16
n‘im 16
hn‘im 14
hn‘im 15
h 2
hn‘im 11
hn‘im 12
EOS 17
n‘im 16
EOS 17
EOS 17
</figure>
<figureCaption confidence="0.998489">
Figure 2: Representation of the sentence bclm Wim
</figureCaption>
<equation confidence="0.98852396875">
Expectation
α(1, l) = πol 1.statebol (1)
1.state,ol 1.sym
Xα(t, l) = bolt.state,olt.sym
l0Eolt.prev
β( T, l) = 1 (2)
X aolt.state,ol0t+1.statebol0
β(t, l) = t+1.state,ol0
t+1.symβ(t + 1, l&apos;)
l0Eolt.next
i)
α(t − 1, l Clol0
t− 1.state,olt.state
ai,j =
P
l:ol1.state=i α(1, l)β(1, l) (3)
Pl α(1, l)β(1, l)
PT �` //��//
t=2 Pl:olt.state=j EVEolt.prev:ot� 1.state=i α(t — 1, ll)ai,jbj of symNlt, l)
P T−1 P t.state=i α(t, l)β(t, l)
t=1 l:ol
Maximization
πi =
(4)
P
�bi,k =
P
T t.state=i α(t, l)β(t, l)
t=1 l:olt.sym=k,ol
T� (5)
t=1 Pl:olt.state=i α(t, l)β(t, l)
P
</equation>
<figureCaption confidence="0.997457">
Figure 3: The learning algorithm for first-order model
</figureCaption>
<table confidence="0.599794222222222">
Initialization
δ(1,l) = πol 1.statebol (6)
1.state,ol 1.sym
Induction
δ(t, l) =max δ(t − 1, l&apos;)aol0 (7)
l0Eolt.prev t−1.state,ol t.statebol t.state,ol t.sym
ψ(t, l) = argmax δ(t − 1,l&apos;)aol0 (�)
l0Eolt.prev t−1.state,ol t.statebol t.state,ol t.sym
Termination and path readout
</table>
<equation confidence="0.993051142857143">
XT� = argmax_
1&lt;l&lt; |T|
Xt = ψ(t + 1,
δ( T, l) (9)
Xt+1)
P( X) = max δ( T,l) (10)
1&lt;l&lt;|O T¯|
</equation>
<figureCaption confidence="0.998352">
Figure 4: The searching algorithm for first-order model
</figureCaption>
<page confidence="0.966646">
670
</page>
<table confidence="0.999910428571429">
Order Uniform CF
W 1 82.01 84.08
W 2- 80.44 85.75
W 2 79.88 85.78
M 1 81.08 84.54
M 2- 81.53 88.5
M 2 83.39 85.83
</table>
<tableCaption confidence="0.997395">
Table 3: Morphological Disambiguation
</tableCaption>
<bodyText confidence="0.99906006">
word in the text, according to Levinger et al. (1995)
approximations, with accuracy of 78.2%, as the
baseline tagger, four steps of error reduction can
be identified. (1) Contextual information: The
simplest first-order word-based HMM with uniform
initial conditions, achieves error reduction of 17.5%
(78.2 – 82.01). (2) Initial conditions: Error reduc-
tions in the range: 11.5% – 37.8% (82.01 – 84.08
for word model 1, and 81.53 – 88.5 for morhpeme
model 2-) were achieved by initializing the various
models with context-free approximations. While
this observation confirms Elworthy (1994), the im-
pact of error reduction is much less than reported
there for English - about 70% (79 – 94). The key
difference (beside the unclear characteristic of El-
worthy initial condition - since he made use of an
annotated corpus) is the much higher quality of the
uniform distribution for Hebrew. (3) Model order:
The partial second-order HMM [2-] produced the
best results for both word (85.75%) and morpheme
(88.5%) models over the initial condition. The full
second-order HMM [2] didn’t upgrade the accu-
racy of the partial second-order, but achieved the
best results for the uniform distribution morpheme
model. This is because the context-free approxima-
tion does not take into account the tag of the previ-
ous word, which is part of model 2. We believe that
initializing the morpheme model over a small set of
annotated corpus will set much stronger initial con-
dition for this model. (4) Model type: The main
result of this paper is the error reduction of the
morpheme model with respect to the word model:
about 19.3% (85.75 – 88.5).
In addition, we apply the above models for the
simpler task of segmentation and PoS tagging, as
reported in Table 4. The task requires picking the
correct morphemes of each word with their correct
PoS (excluding all other morphological features).
The best result for this task is obtained with the
morpheme model 2: 92.32%. For this simpler task,
the improvement brought by the morpheme model
over the word model is less significant, but still
consists of a 5% error reduction.
Unknown words account for a significant
chunk of the errors. Table 5 shows the distribution
of errors contributed by unknown words (words
that cannot be analyzed by the morphological an-
alyzer). 7.5% of the words in the test corpus are
unknown: 4% are not recognized at all by the mor-
phological analyzer (marked as [None] in the ta-
</bodyText>
<table confidence="0.999718428571429">
Order Uniform CF
W 1 91.07 91.47
W 2- 90.45 91.93
W 2 90.21 91.84
M 1 89.23 91.42
M 2- 89.77 91.76
M 2 91.42 92.32
</table>
<tableCaption confidence="0.999676">
Table 4: Segmentation and PoS Tagging
</tableCaption>
<bodyText confidence="0.9999093125">
ble), and for 3.5%, the set of analyses proposed by
the analyzer does not contain the correct analy-
sis [Missing]. We extended the lexicon to include
missing and none lexemes of the closed sets. In
addition, we modified the analyzer to extract all
possible segmentations of unknown words, with all
the possible tags for the segmented affixes, where
the remaining unknown baseforms are tagged as
UK. The model was trained over this set. In the
next phase, the corpus was automatically tagged,
according to the trained model, in order to form a
tag distribution for each unknown word, according
to its context and its form. Finally, the tag for
each unknown word were selected according to its
tag distribution. This strategy accounts for about
half of the 7.5% unknown words.
</bodyText>
<table confidence="0.9991995">
None Missing %
Proper name 26 36 62
Closed Set 8 5.6 13.6
Other 16.5 5.4 21.9
Junk 2.5 0 2.5
53 47 100
</table>
<tableCaption confidence="0.999029">
Table 5: Unknown Word Distribution
</tableCaption>
<bodyText confidence="0.9965507">
Table 6 shows the confusion matrix for known
words (5% and up). The key confusions can be at-
tributed to linguistic properties of Modern Hebrew:
most Hebrew proper names are also nouns (and
they are not marked by capitalization) – which ex-
plains the PN/N confusion. The verb/noun and
verb/adjective confusions are explained by the na-
ture of the participle form in Hebrew (beinoni) –
participles behave syntactically almost in an iden-
tical manner as nouns.
</bodyText>
<table confidence="0.998098">
Correct Error %
proper name noun 17.9
noun verb 15.3
noun proper name 6.6
verb noun 6.3
adjective noun 5.4
adjective verb 5.0
</table>
<tableCaption confidence="0.998824">
Table 6: Confusion Matrix for Known Words
</tableCaption>
<sectionHeader confidence="0.996288" genericHeader="conclusions">
5 Conclusions and future Work
</sectionHeader>
<bodyText confidence="0.9995975">
In this work, we have introduced a new text encod-
ing method that captures rules of word formation
in a language with affixational morphology such as
Hebrew. This text encoding method allows us to
</bodyText>
<page confidence="0.996644">
671
</page>
<bodyText confidence="0.99990716">
learn in parallel segmentation and tagging rules in
an unsupervised manner, despite the high ambigu-
ity level of the morphological data (average num-
ber of 2.4 analyses per word). Reported results on
a large scale corpus (6M words) with fully unsu-
pervised learning are 92.32% for PoS tagging and
88.5% for full morphological disambiguation.
In this work, we used the backoff smoothing
method, suggested by Thede and Harper (1999),
with an extension of additive smoothing (Chen,
1996, 2.2.1) for the lexical probabilities (B and B2
matrices). To complete this study, we are currently
investigating several smoothing techniques (Chen,
1996), in order to check whether the morpheme
model is critical for the data sparseness problem,
or whether it can be handled with smoothing over
a word model.
We are currently investigating two major meth-
ods to improve our results: first, we have started
gathering a larger corpus of manually tagged text
and plan to perform semi-supervised learning on
a corpus of 100K manually tagged words. Second,
we plan to improve the unknown word model, such
as integrating it with named entity recognition sys-
tem (Ben-Mordechai, 2005).
</bodyText>
<sectionHeader confidence="0.999446" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999772209876543">
Emmanuel Allon. 1995. Unvocalized Hebrew Writ-
ing. Ben Gurion University Press. (in Hebrew).
Roy Bar-Haim, Khalil Sima&apos;an, and Yoad Winter.
2005. Choosing an optimal architecture for seg-
mentation and pos-tagging of modern Hebrew.
In Proceedings of ACL-05 Workshop on Compu-
tational Approaches to Semitic Languages.
Leonard E. Baum. 1972. An inequality and asso-
ciated maximization technique in statistical es-
timation for probabilistic functions of a Markov
process. Inequalities, 3:1–8.
Na&apos;ama Ben-Mordechai. 2005. Named entities
recognition in Hebrew. Master’s thesis, Ben Gu-
rion University of the Negev, Beer Sheva, Israel.
(in Hebrew).
Eric Brill. 1995. Transformation-based error-
driven learning and natural languge processing:
A case study in part-of-speech tagging. Compu-
tational Linguistics, 21:543–565.
David Carmel and Yoelle S. Maarek. 1999. Mor-
phological disambiguation for Hebrew search
systems. In Proceeding of NGITS-99.
Stanley F. Chen. 1996. Building Probabilistic
Models for Natural Language. Ph.D. thesis, Har-
vard University, Cambridge, MA.
Mona Diab, Kadri Hacioglu, and Daniel Jurafsky.
2004. Automatic tagging of Arabic text: From
raw text to base phrase chunks. In Proceeding
of HLT-NAACL-04.
Kevin Duh and Katrin Kirchhoff. 2005. Pos tag-
ging of dialectal Arabic: A minimally supervised
approach. In Proceedings of ACL-05 Workshop
on Computational Approaches to Semitic Lan-
guages.
Michael Elhadad, Yael Netzer, David Gabay, and
Meni Adler. 2005. Hebrew morphological tag-
ging guidelines. Technical report, Ben Gurion
University, Dept. of Computer Science.
David Elworthy. 1994. Does Baum-Welch re-
estimation help taggers? In Proceeding of
ANLP-94.
Nizar Habash and Owen Rambow. 2005. Arabic
tokenization, part-of-speech tagging and mor-
phological disambiguation in one fell swoop. In
Proceeding of ACL-05.
Nadav Har&apos;el and Dan Kenigsberg. 2004. HSpell
- the free Hebrew spell checker and morphologi-
cal analyzer. Israeli Seminar on Computational
Linguistics, December 2004.
Daniel Jurafsky and James H. Martin. 2000.
Speech and language processing. Prentice-Hall.
Gennady Lembersky. 2001. Named entities recog-
nition; compounds: approaches and recognitions
methods. Master’s thesis, Ben Gurion Univer-
sity of the Negev, Beer Sheva, Israel. (in He-
brew).
Moshe Levinger, Uzi Ornan, and Alon Itai. 1995.
Learning morpholexical probabilities from an
untagged corpus with an application to Hebrew.
Computational Linguistics, 21:383–404.
Moshe Levinger. 1992. Morhphological disam-
biguation in hebrew. Master’s thesis, Technion,
Haifa, Israel. (in Hebrew).
Christopher D. Manning and Hinrich Schutze.
1999. Foundation of Statistical Language Pro-
cessing. MIT Press.
Bernard Merialdo. 1994. Tagging English text
with probabilistic model. Computatinal Linguis-
tics, 20:155–171.
Uzi Ornan. 2002. Hebrew in latin script.
Lesonenu, LXIV:137–151. (in Hebrew).
Erel Segal. 2000. Hebrew morphological ana-
lyzer for Hebrew undotted texts. Master’s the-
sis, Technion, Haifa, Israel. (in Hebrew).
Scott M. Thede and Mary P. Harper. 1999. A
second-order hidden Markov model for part-of-
speech tagging. In Proceeding of ACL-99.
Shlomo Yona and Shuly Wintner. 2005. A finite-
state morphological grammar of Hebrew. In
Proceedings of ACL-05 Workshop on Computa-
tional Approaches to Semitic Languages.
</reference>
<page confidence="0.99826">
672
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.459346">
<title confidence="0.999011">An Unsupervised Morpheme-Based HMM for Hebrew Morphological Disambiguation</title>
<author confidence="0.997777">Meni Adler</author>
<affiliation confidence="0.8480925">Department of Computer Science Ben Gurion University of the Negev</affiliation>
<address confidence="0.99894">84105 Beer Sheva, Israel</address>
<email confidence="0.998493">adlerm@cs.bgu.ac.il</email>
<author confidence="0.999751">Michael Elhadad</author>
<affiliation confidence="0.8474945">Department of Computer Science Ben Gurion University of the Negev</affiliation>
<address confidence="0.999212">84105 Beer Sheva, Israel</address>
<email confidence="0.999501">elhadad@cs.bgu.ac.il</email>
<abstract confidence="0.9982871">Morphological disambiguation is the process of assigning one set of morphological features to each individual word in a text. When the word is ambiguous (there are several possible analyses for the word), a disambiguation procedure based on the word context must be applied. This paper deals with morphological disambiguation of the Hebrew language, which combines morphemes into a word in both agglutinative and fusional ways. We present an unsupervised stochastic model – the only resource we use is a morphological analyzer – which deals with the data sparseness problem caused by the affixational morphology of the Hebrew language. We present a text encoding method for languages with affixational morphology in which the knowledge of word formation rules (which are quite restricted in Hebrew) helps in the disambiguation. We adapt HMM algorithms for learning and searching this text representation, in such a way that segmentation and tagging can be learned in parallel in one step. Results on a large scale evaluation indicate that this learning improves disambiguation for complex tag sets. Our method is applicable to other languages with affix morphology.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Emmanuel Allon</author>
</authors>
<title>Unvocalized Hebrew Writing. Ben Gurion University Press.</title>
<date>1995</date>
<note>(in Hebrew).</note>
<contexts>
<context position="4212" citStr="Allon, 1995" startWordPosition="665" endWordPosition="666"> word in both agglutinative and fusional ways. This results in a potentially high number of tags for each word. In contrast to English tag sets whose sizes range from 48 to 195, the number of tags for Hebrew, based on all combinations of the morphological attributes (part-of-speech, gender, number, person, tense, status, and the affixes&apos; properties2), &apos;The Knowledge Center for Hebrew processing is developing such corpora: http://mila.cs.technion.ac.il/ 2The list of morphological attributes is described in (Yona and Wintner, 2005). An in-depth discussion of the Hebrew word form is provided in (Allon, 1995, pp. 665 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 665–672, Sydney, July 2006. c�2006 Association for Computational Linguistics can grow theoretically to about 300,000 tags. In practice, we found only 1,934 tags in a corpus of news stories we gathered, which contains about 6M words. The large size of such a tag set (about 10 times larger than the most comprehensive English tag set) is problematic in term of data sparseness. Each morphological combination appears rarely, and more samples are required in order to lear</context>
</contexts>
<marker>Allon, 1995</marker>
<rawString>Emmanuel Allon. 1995. Unvocalized Hebrew Writing. Ben Gurion University Press. (in Hebrew).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Bar-Haim</author>
<author>Khalil Sima&apos;an</author>
<author>Yoad Winter</author>
</authors>
<title>Choosing an optimal architecture for segmentation and pos-tagging of modern Hebrew.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-05 Workshop on Computational Approaches to Semitic Languages.</booktitle>
<contexts>
<context position="9105" citStr="Bar-Haim et al. (2005)" startWordPosition="1478" endWordPosition="1481">xt – which consists of about 1,000 words. In the second stage, a transformation learning algorithm is applied (in contrast to Brill, the observed transformations are not applied, but used for re-estimation of the word couples probabilities). After this stage, the accuracy is about 93%. The last stage uses a bottomup parser over a hand-crafted grammar with 150 rules, in order to select the analysis which causes the parsing to be more accurate. Segal reports an accuracy of 95%. Testing his system over a larger test corpus, gives poorer results: Lembersky (2001) reports an accuracy of about 85%. Bar-Haim et al. (2005) developed a word segmenter and PoS tagger for Hebrew. In their architecture, words are first segmented into morphemes, and then, as a second stage, these morphemes are tagged with PoS. The method proceeds in two sequential steps: segmentation into morphemes, then tagging over morphemes. The segmentation is based on an HMM and trained over a set of 30K annotated words. The segmentation step reaches an accuracy of 96.74%. PoS tagging, based on unsupervised estimation which combines a small annotated corpus with an untagged corpus of 340K 666 Word Segmentation Tag Translation bclm bclm PNN name </context>
</contexts>
<marker>Bar-Haim, Sima&apos;an, Winter, 2005</marker>
<rawString>Roy Bar-Haim, Khalil Sima&apos;an, and Yoad Winter. 2005. Choosing an optimal architecture for segmentation and pos-tagging of modern Hebrew. In Proceedings of ACL-05 Workshop on Computational Approaches to Semitic Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard E Baum</author>
</authors>
<title>An inequality and associated maximization technique in statistical estimation for probabilistic functions of a Markov process.</title>
<date>1972</date>
<journal>Inequalities,</journal>
<volume>3</volume>
<contexts>
<context position="16025" citStr="Baum, 1972" startWordPosition="2671" endWordPosition="2672">ates the morphemes of each word leaving the observed morphemes uncertain. For example, the word bclm can be segmented in four different ways in Table 1, as indicated by the placement of the &apos;-&apos; in the Segmentation column, while the word hn`im can be segmented in two different ways. In the next section, we adapt the parameter estimation and the searching algorithms for such uncertain output observation. 3.2 Learning and Searching Algorithms for Uncertain Output Observation In contrast to standard HMM, the output observations of the above morpheme-based HMM are ambiguous. We adapted Baum-Welch (Baum, 1972) and Viterbi (Manning and Schutze, 1999, 9.3.2) algorithms for such uncertain observation. We first formalize the output representation and then describe the algorithms. Output Representation The learning and searching algorithms of HMM are based on the output sequence of the underlying Markov process. For the case of a morpheme-based model, the output sequence is uncertain – we don’t see the emitted morphemes but the words they form. If, for instance, the Markov process emitted the morphemes b clm h nim, we would see two words (bclm hn`im) instead. In order to handle the output ambiguity, we </context>
<context position="17915" citStr="Baum, 1972" startWordPosition="2986" endWordPosition="2987">a tuple (symbol, state, prev, next), where symbol denotes a morpheme, state is one possible tag for this morpheme, prev and next are sets of indexes, denoting the indexes of the morphemes (of the previous and the next vectors) that precede and follow the current morpheme in the overall lattice, representing the sentence. Fig. 2 describes the representation of the sentence bclm hn`im. An emission is denoted in this figure by its symbol, its state index, directed edges from its previous emissions, and directed edges to its next emissions. In order to meet the condition of Baum-Eagon inequality (Baum, 1972) that the polynomial P(O|µ) – which represents the probability of an observed sequence O given a model µ – be homogeneous, we must add a sequence of special EOS (end of sentence) symbols at the end of each path up to the last vector, so that all the paths reach the same length. The above text representation can be used to model multi-word expressions (MWEs). Consider the Hebrew sentence: hw&apos; `wrk dyn gdwl, which can be interpreted as composed of 3 units (he lawyer great / he is a great lawyer) or as 4 units (he edits law big / he is editing an important legal decision). In order to select the </context>
<context position="21650" citStr="Baum, 1972" startWordPosition="3621" endWordPosition="3622"> its morphology features would be insufficient. (2) The supervised resources of ASR are not available for morphological disambiguation: we don’t have a model of morphological features sequences (equivalent to the language model of ASR) nor a tagged corpus (equivalent to the transcripted wave files of ASR). These two differences require a design which combines the two dimensions of the problem, in order to support unsupervised learning (and searching) of morpheme sequences and their morphological features, simultaneously. Parameter Estimation We present a variation of the Baum-Welch algorithm (Baum, 1972) which operates over the lattice representation we have defined above. The algorithm starts with a probabilistic model µ (which can be chosen randomly or obtained from good initial conditions), and at each iteration, a new model µ� is derived in order to better explain the given output observations. For a given sentence, we define T as the number of words in the sentence, and T as the number of vectors of the output representation O = {ot},1 &lt; t &lt; T, where each item in the output is denoted by olt = (sym, state, prev, next),1 &lt; t &lt; T,1 &lt; l &lt; |ot|. We define a(t, l) as the probability to reach </context>
</contexts>
<marker>Baum, 1972</marker>
<rawString>Leonard E. Baum. 1972. An inequality and associated maximization technique in statistical estimation for probabilistic functions of a Markov process. Inequalities, 3:1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Na&apos;ama Ben-Mordechai</author>
</authors>
<title>Named entities recognition in Hebrew. Master’s thesis,</title>
<date>2005</date>
<institution>Ben Gurion University of the Negev, Beer Sheva,</institution>
<note>(in Hebrew).</note>
<marker>Ben-Mordechai, 2005</marker>
<rawString>Na&apos;ama Ben-Mordechai. 2005. Named entities recognition in Hebrew. Master’s thesis, Ben Gurion University of the Negev, Beer Sheva, Israel. (in Hebrew).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based errordriven learning and natural languge processing: A case study in part-of-speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--543</pages>
<contexts>
<context position="8226" citStr="Brill (1995)" startWordPosition="1329" endWordPosition="1330"> and Maarek (1999) use the fact that on average 45% of the Hebrew words are unambiguous, to rank analyses, based on the number of disambiguated occurrences in the text, normalized by the total number of occurrences for each word. Their application – indexing for an information retrieval system – does not require all of the morphological attributes but only the lemma and the PoS of each word. As a result, for this case, 75% of the words remain with one analysis with 95% accuracy, 20% with two analyses and 5% with three analyses. Segal (2000) built a transformation-based tagger in the spirit of Brill (1995). In the first phase, the analyses of each word are ranked according to the frequencies of the possible lemmas and tags in a training corpus of about 5,000 words. Selection of the highest ranked analysis for each word gives an accuracy of 83% of the test text – which consists of about 1,000 words. In the second stage, a transformation learning algorithm is applied (in contrast to Brill, the observed transformations are not applied, but used for re-estimation of the word couples probabilities). After this stage, the accuracy is about 93%. The last stage uses a bottomup parser over a hand-crafte</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Eric Brill. 1995. Transformation-based errordriven learning and natural languge processing: A case study in part-of-speech tagging. Computational Linguistics, 21:543–565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Carmel</author>
<author>Yoelle S Maarek</author>
</authors>
<title>Morphological disambiguation for Hebrew search systems.</title>
<date>1999</date>
<booktitle>In Proceeding of NGITS-99.</booktitle>
<contexts>
<context position="7632" citStr="Carmel and Maarek (1999)" startWordPosition="1221" endWordPosition="1224">applicability of the disambiguation, approximated probabilities are used for words that were not disambiguated in the first stage. Finally, the expert system is used again over the new probabilities that were set in the previous stage. Levinger reports an accuracy of about 94% for disambiguation of 85% of the words in the text (overall 80% disambiguation). The system was also applied to prune out the least likely analyses in a corpus but without, necessarily, selecting a single analysis for each word. For this task, an accuracy of 94% was reported while reducing 92% of the ambiguous analyses. Carmel and Maarek (1999) use the fact that on average 45% of the Hebrew words are unambiguous, to rank analyses, based on the number of disambiguated occurrences in the text, normalized by the total number of occurrences for each word. Their application – indexing for an information retrieval system – does not require all of the morphological attributes but only the lemma and the PoS of each word. As a result, for this case, 75% of the words remain with one analysis with 95% accuracy, 20% with two analyses and 5% with three analyses. Segal (2000) built a transformation-based tagger in the spirit of Brill (1995). In t</context>
</contexts>
<marker>Carmel, Maarek, 1999</marker>
<rawString>David Carmel and Yoelle S. Maarek. 1999. Morphological disambiguation for Hebrew search systems. In Proceeding of NGITS-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
</authors>
<title>Building Probabilistic Models for Natural Language.</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<institution>Harvard University,</institution>
<location>Cambridge, MA.</location>
<contexts>
<context position="30887" citStr="Chen, 1996" startWordPosition="5223" endWordPosition="5224">res rules of word formation in a language with affixational morphology such as Hebrew. This text encoding method allows us to 671 learn in parallel segmentation and tagging rules in an unsupervised manner, despite the high ambiguity level of the morphological data (average number of 2.4 analyses per word). Reported results on a large scale corpus (6M words) with fully unsupervised learning are 92.32% for PoS tagging and 88.5% for full morphological disambiguation. In this work, we used the backoff smoothing method, suggested by Thede and Harper (1999), with an extension of additive smoothing (Chen, 1996, 2.2.1) for the lexical probabilities (B and B2 matrices). To complete this study, we are currently investigating several smoothing techniques (Chen, 1996), in order to check whether the morpheme model is critical for the data sparseness problem, or whether it can be handled with smoothing over a word model. We are currently investigating two major methods to improve our results: first, we have started gathering a larger corpus of manually tagged text and plan to perform semi-supervised learning on a corpus of 100K manually tagged words. Second, we plan to improve the unknown word model, such</context>
</contexts>
<marker>Chen, 1996</marker>
<rawString>Stanley F. Chen. 1996. Building Probabilistic Models for Natural Language. Ph.D. thesis, Harvard University, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Kadri Hacioglu</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic tagging of Arabic text: From raw text to base phrase chunks.</title>
<date>2004</date>
<booktitle>In Proceeding of HLT-NAACL-04.</booktitle>
<contexts>
<context position="11080" citStr="Diab et al. (2004)" startWordPosition="1811" endWordPosition="1814">t. The results discussed above should be taken as rough approximations of the real performance of the systems, until they can be re-evaluated on such a large scale corpus with a standard tag set. Arabic is a language with morphology quite similar to Hebrew. Theoretically, there might be 330,000 possible morphological tags, but in practice, Habash and Rambow (2005) extracted 2,200 different tags from their corpus, with an average number of 2 possible tags per word. As reported by Habash and Rambow, the first work on Arabic tagging which used a corpus for training and evaluation was the work of Diab et al. (2004). Habash and Rambow were the first to use a morphological analyzer as part of their tagger. They developed a supervised morphological disambiguator, based on training corpora of two sets of 120K words, which combines several classifiers of individual morphological features. The accuracy of their analyzer is 94.8% – 96.2% (depending on the test corpus). An unsupervised HMM model for dialectal Arabic (which is harder to be tagged than written Arabic), with accurracy of 69.83%, was presented by Duh and Kirchhoff (2005). Their supervised model, trained on a manually annotated corpus, reached an ac</context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2004</marker>
<rawString>Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004. Automatic tagging of Arabic text: From raw text to base phrase chunks. In Proceeding of HLT-NAACL-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Duh</author>
<author>Katrin Kirchhoff</author>
</authors>
<title>Pos tagging of dialectal Arabic: A minimally supervised approach.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-05 Workshop on Computational Approaches to Semitic Languages.</booktitle>
<contexts>
<context position="11601" citStr="Duh and Kirchhoff (2005)" startWordPosition="1894" endWordPosition="1897">rk on Arabic tagging which used a corpus for training and evaluation was the work of Diab et al. (2004). Habash and Rambow were the first to use a morphological analyzer as part of their tagger. They developed a supervised morphological disambiguator, based on training corpora of two sets of 120K words, which combines several classifiers of individual morphological features. The accuracy of their analyzer is 94.8% – 96.2% (depending on the test corpus). An unsupervised HMM model for dialectal Arabic (which is harder to be tagged than written Arabic), with accurracy of 69.83%, was presented by Duh and Kirchhoff (2005). Their supervised model, trained on a manually annotated corpus, reached an accuracy of 92.53%. Arabic morphology seems to be similar to Hebrew morphology, in term of complexity and data sparseness, but comparison of the performances of the baseline tagger used by Habash and Rambow – which selects the most frequent tag for a given word in the training corpus – for Hebrew and Arabic, shows some intriguing differences: 92.53% for Arabic and 71.85% for Hebrew. Furthermore, as mentioned above, even the use of a sophisticated context-free tagger, based on (Levinger et al., 1995), gives low accurac</context>
</contexts>
<marker>Duh, Kirchhoff, 2005</marker>
<rawString>Kevin Duh and Katrin Kirchhoff. 2005. Pos tagging of dialectal Arabic: A minimally supervised approach. In Proceedings of ACL-05 Workshop on Computational Approaches to Semitic Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Elhadad</author>
<author>Yael Netzer</author>
<author>David Gabay</author>
<author>Meni Adler</author>
</authors>
<title>Hebrew morphological tagging guidelines.</title>
<date>2005</date>
<tech>Technical report,</tech>
<institution>Ben Gurion University, Dept. of Computer Science.</institution>
<contexts>
<context position="10380" citStr="Elhadad et al., 2005" startWordPosition="1689" endWordPosition="1692">while taking a picture bclm bcl-m cons-NNM-suf their onion bclm b-cl-m P1-NNM-suf under their shadow bclm b-clm P1-NNM in a photographer bclm b-clm P1-cons-NNM in a photographer bclm b-clm P1-h-NNM in the photographer hn`im h-n`im P1-VBR that are moving hn`im hn`im P1-h-JJM the lovely hn`im hn`im VBP made pleasant Table 1: Possible analyses for the words bclm hn`im words by using smoothing technique, gives an accuracy of 90.51%. As noted earlier, there is as yet no large scale Hebrew annotated corpus. We are in the process of developing such a corpus, and we have developed tagging guidelines (Elhadad et al., 2005) to define a comprehensive tag set, and assist human taggers achieve high agreement. The results discussed above should be taken as rough approximations of the real performance of the systems, until they can be re-evaluated on such a large scale corpus with a standard tag set. Arabic is a language with morphology quite similar to Hebrew. Theoretically, there might be 330,000 possible morphological tags, but in practice, Habash and Rambow (2005) extracted 2,200 different tags from their corpus, with an average number of 2 possible tags per word. As reported by Habash and Rambow, the first work </context>
<context position="14204" citStr="Elhadad et al., 2005" startWordPosition="2336" endWordPosition="2339"> N = 1934 tags/states and about M = 175K word types. Line W of Table 2 describes the size of a first-order word-based HMM, built over our corpus. In this model, we found 834 entries for the II vector (which models the distribution of tags in first position in sentences) out of possibly N = 1934, about 250K entries for the A matrix (which models the transition probabilities from tag to tag) out of possibly N2 ;::Li 3.7M, and about 300K entries for the B matrix (which models 3Transcription according to Ornan (2002). 4The tagset we use for the annotation follows the guidelines we have developed (Elhadad et al., 2005). 667 States PI A A2 B B2 W 1934 834 250K 7M 300K 5M M 202 145 20K 700K 130K 1.7M Table 2: Model Sizes the emission probabilities from tag to word) out of possibly M · N ;::Li 350M. For the case of a secondorder HMM, the size of the A2 matrix (which models the transition probabilities from two tags to the third one), grows to about 7M entries, where the size of the B2 matrix (which models the emission probabilities from two tags to a word) is about 5M. Despite the sparseness of these matrices, the number of their entries is still high, since we model the whole set of features of the complex wo</context>
</contexts>
<marker>Elhadad, Netzer, Gabay, Adler, 2005</marker>
<rawString>Michael Elhadad, Yael Netzer, David Gabay, and Meni Adler. 2005. Hebrew morphological tagging guidelines. Technical report, Ben Gurion University, Dept. of Computer Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Elworthy</author>
</authors>
<title>Does Baum-Welch reestimation help taggers?</title>
<date>1994</date>
<booktitle>In Proceeding of ANLP-94.</booktitle>
<contexts>
<context position="2858" citStr="Elworthy (1994)" startWordPosition="443" endWordPosition="444">ature of Modern Hebrew, as it evolves over time. In the case of English, because morphology is simpler, morphological disambiguation is generally covered under the task of part-of-speech tagging. The main morphological variations are embedded in the tag name (for example, Ns and Np for noun singular or plural). The tagging accuracy of supervised stochastic taggers is around 96%- 97% (Manning and Schutze, 1999, 10.6.1). Merialdo (1994) reports an accuracy of 86.6% for an unsupervised word-based HMM, trained on a corpus of 42,186 sentences (about 1M words), over a tag set of 159 different tags. Elworthy (1994), in contrast, reports an accuracy of 75.49%, 80.87% and 79.12% for unsupervised word-based HMM trained on parts of the LOB corpora, with a tagset of 134 tags. With good initial conditions, such as good approximation of the tag distribution for each word, Elworthy reports an improvement to 94.6%, 92.27% and 94.51% on the same data sets. Merialdo, on the other hand, reports an improvement to 92.6% and 94.4% for the case where 100 and 2000 sentences of the training corpus are manually tagged. Modern Hebrew is characterized by rich morphology, with a high level of ambiguity. On average, in our co</context>
<context position="26645" citStr="Elworthy (1994)" startWordPosition="4492" endWordPosition="4493">hological Disambiguation word in the text, according to Levinger et al. (1995) approximations, with accuracy of 78.2%, as the baseline tagger, four steps of error reduction can be identified. (1) Contextual information: The simplest first-order word-based HMM with uniform initial conditions, achieves error reduction of 17.5% (78.2 – 82.01). (2) Initial conditions: Error reductions in the range: 11.5% – 37.8% (82.01 – 84.08 for word model 1, and 81.53 – 88.5 for morhpeme model 2-) were achieved by initializing the various models with context-free approximations. While this observation confirms Elworthy (1994), the impact of error reduction is much less than reported there for English - about 70% (79 – 94). The key difference (beside the unclear characteristic of Elworthy initial condition - since he made use of an annotated corpus) is the much higher quality of the uniform distribution for Hebrew. (3) Model order: The partial second-order HMM [2-] produced the best results for both word (85.75%) and morpheme (88.5%) models over the initial condition. The full second-order HMM [2] didn’t upgrade the accuracy of the partial second-order, but achieved the best results for the uniform distribution mor</context>
</contexts>
<marker>Elworthy, 1994</marker>
<rawString>David Elworthy. 1994. Does Baum-Welch reestimation help taggers? In Proceeding of ANLP-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic tokenization, part-of-speech tagging and morphological disambiguation in one fell swoop.</title>
<date>2005</date>
<booktitle>In Proceeding of ACL-05.</booktitle>
<contexts>
<context position="10828" citStr="Habash and Rambow (2005)" startWordPosition="1765" endWordPosition="1768">lier, there is as yet no large scale Hebrew annotated corpus. We are in the process of developing such a corpus, and we have developed tagging guidelines (Elhadad et al., 2005) to define a comprehensive tag set, and assist human taggers achieve high agreement. The results discussed above should be taken as rough approximations of the real performance of the systems, until they can be re-evaluated on such a large scale corpus with a standard tag set. Arabic is a language with morphology quite similar to Hebrew. Theoretically, there might be 330,000 possible morphological tags, but in practice, Habash and Rambow (2005) extracted 2,200 different tags from their corpus, with an average number of 2 possible tags per word. As reported by Habash and Rambow, the first work on Arabic tagging which used a corpus for training and evaluation was the work of Diab et al. (2004). Habash and Rambow were the first to use a morphological analyzer as part of their tagger. They developed a supervised morphological disambiguator, based on training corpora of two sets of 120K words, which combines several classifiers of individual morphological features. The accuracy of their analyzer is 94.8% – 96.2% (depending on the test co</context>
<context position="12511" citStr="Habash and Rambow, 2005" startWordPosition="2045" endWordPosition="2048">which selects the most frequent tag for a given word in the training corpus – for Hebrew and Arabic, shows some intriguing differences: 92.53% for Arabic and 71.85% for Hebrew. Furthermore, as mentioned above, even the use of a sophisticated context-free tagger, based on (Levinger et al., 1995), gives low accuracy of 78.2%. This might imply that, despite the similarities, morphological disambiguation in Hebrew might be harder than in Arabic. It could also mean that the tag set used for the Arabic corpora has not been adapted to the specific nature of Arabic morphology (a comment also made in (Habash and Rambow, 2005)). We propose an unsupervised morpheme-based HMM to address the data sparseness problem. In contrast to Bar-Haim et al., our model combines segmentation and morphological disambiguation, in parallel. The only resource we use in this work is a morphological analyzer. The analyzer itself can be generated from a word list and a morphological generation module, such as the HSpell wordlist (Har&apos;el and Kenigsberg, 2004). 3 Morpheme-Based Model for Hebrew 3.1 Morpheme-Based HMM The lexical items of word-based models are the words of the language. The implication of this decision is that both lexical </context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic tokenization, part-of-speech tagging and morphological disambiguation in one fell swoop. In Proceeding of ACL-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nadav Har&apos;el and Dan Kenigsberg</author>
</authors>
<title>HSpell - the free Hebrew spell checker and morphological analyzer. Israeli Seminar on Computational Linguistics,</title>
<date>2004</date>
<contexts>
<context position="12928" citStr="Kenigsberg, 2004" startWordPosition="2111" endWordPosition="2112">arder than in Arabic. It could also mean that the tag set used for the Arabic corpora has not been adapted to the specific nature of Arabic morphology (a comment also made in (Habash and Rambow, 2005)). We propose an unsupervised morpheme-based HMM to address the data sparseness problem. In contrast to Bar-Haim et al., our model combines segmentation and morphological disambiguation, in parallel. The only resource we use in this work is a morphological analyzer. The analyzer itself can be generated from a word list and a morphological generation module, such as the HSpell wordlist (Har&apos;el and Kenigsberg, 2004). 3 Morpheme-Based Model for Hebrew 3.1 Morpheme-Based HMM The lexical items of word-based models are the words of the language. The implication of this decision is that both lexical and syntagmatic relations of the model, are based on a word-oriented tagset. With such a tagset, it must be possible to tag any word of the language with at least one tag. Let us consider, for instance, the Hebrew phrase bclm hn`im3, which contains two words. The word bclm has several possible morpheme segmentations and analyses as described in Table 1. In wordbased HMM, we consider such a phrase to be generated b</context>
</contexts>
<marker>Kenigsberg, 2004</marker>
<rawString>Nadav Har&apos;el and Dan Kenigsberg. 2004. HSpell - the free Hebrew spell checker and morphological analyzer. Israeli Seminar on Computational Linguistics, December 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James H Martin</author>
</authors>
<title>Speech and language processing.</title>
<date>2000</date>
<publisher>Prentice-Hall.</publisher>
<contexts>
<context position="19691" citStr="Jurafsky and Martin, 2000" startWordPosition="3308" endWordPosition="3311"> our corpus (where each symbol is counted as the number of its predecessor emissions) to be 455, where the average number of words per sentence is about 18. That is, the hw’ 20 ‘wrk dyn 6 gdwl 19 EOS 17 EOS 17 ‘wrk 18 dyn 6 gdwl 19 668 cost of operating over an ambiguous sentence representation increases the size of the sentence (from 18 to 455), but on the other hand, it reduces the probabilistic model by a factor of 10 (as discussed above). Morphological disambiguation over such a sequence of vectors of uncertain morphemes is similar to words extraction in automatic speech recognition (ASR)(Jurafsky and Martin, 2000, chp. 5,7). The states of the ASR model are phones, where each observation is a vector of spectral features. Given a sequence of observations for a sentence, the encoding – based on the lattice formed by the phones distribution of the observations, and the language model – searches for the set of words, made of phones, which maximizes the acoustic likelihood and the language model probabilities. In a similar manner, the supervised training of a speech recognizer combines a training corpus of speech wave files, together with word-transcription, and language model probabilities, in order to lea</context>
</contexts>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Daniel Jurafsky and James H. Martin. 2000. Speech and language processing. Prentice-Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gennady Lembersky</author>
</authors>
<title>Named entities recognition; compounds: approaches and recognitions methods. Master’s thesis,</title>
<date>2001</date>
<institution>Ben Gurion University of the Negev, Beer Sheva,</institution>
<note>(in Hebrew).</note>
<contexts>
<context position="9048" citStr="Lembersky (2001)" startWordPosition="1470" endWordPosition="1471">r each word gives an accuracy of 83% of the test text – which consists of about 1,000 words. In the second stage, a transformation learning algorithm is applied (in contrast to Brill, the observed transformations are not applied, but used for re-estimation of the word couples probabilities). After this stage, the accuracy is about 93%. The last stage uses a bottomup parser over a hand-crafted grammar with 150 rules, in order to select the analysis which causes the parsing to be more accurate. Segal reports an accuracy of 95%. Testing his system over a larger test corpus, gives poorer results: Lembersky (2001) reports an accuracy of about 85%. Bar-Haim et al. (2005) developed a word segmenter and PoS tagger for Hebrew. In their architecture, words are first segmented into morphemes, and then, as a second stage, these morphemes are tagged with PoS. The method proceeds in two sequential steps: segmentation into morphemes, then tagging over morphemes. The segmentation is based on an HMM and trained over a set of 30K annotated words. The segmentation step reaches an accuracy of 96.74%. PoS tagging, based on unsupervised estimation which combines a small annotated corpus with an untagged corpus of 340K </context>
</contexts>
<marker>Lembersky, 2001</marker>
<rawString>Gennady Lembersky. 2001. Named entities recognition; compounds: approaches and recognitions methods. Master’s thesis, Ben Gurion University of the Negev, Beer Sheva, Israel. (in Hebrew).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moshe Levinger</author>
<author>Uzi Ornan</author>
<author>Alon Itai</author>
</authors>
<title>Learning morpholexical probabilities from an untagged corpus with an application to Hebrew. Computational Linguistics,</title>
<date>1995</date>
<pages>21--383</pages>
<contexts>
<context position="5941" citStr="Levinger et al. (1995)" startWordPosition="940" endWordPosition="943">t decade. In Hebrew, morphological analysis requires complex processing according to the rules of Hebrew word formation. The task of a morphological analyzer is to produce all possible analyses for a given word. Recent analyzers provide good performance and documentation of this process (Yona and Wintner, 2005; Segal, 2000). Morphological analyzers rely on a dictionary, and their performance is, therefore, impacted by the occurrence of unknown words. The task of a morphological disambiguation system is to pick the most likely analysis produced by an analyzer in the context of a full sentence. Levinger et al. (1995) developed a context-free method in order to acquire the morpho-lexical probabilities, from an untagged corpus. Their method handles the data sparseness problem by using a set of similar words for each word, built according to a set of rules. The rules produce variations of the morphological properties of the word analyses. Their tests indicate an accuracy of about 88% for context-free analysis selection based on the approximated analysis distribution. In tests we reproduced on a larger data set (30K tagged words), the accuracy is only 78.2%. In order to improve the results, the authors recomm</context>
<context position="12182" citStr="Levinger et al., 1995" startWordPosition="1990" endWordPosition="1993">was presented by Duh and Kirchhoff (2005). Their supervised model, trained on a manually annotated corpus, reached an accuracy of 92.53%. Arabic morphology seems to be similar to Hebrew morphology, in term of complexity and data sparseness, but comparison of the performances of the baseline tagger used by Habash and Rambow – which selects the most frequent tag for a given word in the training corpus – for Hebrew and Arabic, shows some intriguing differences: 92.53% for Arabic and 71.85% for Hebrew. Furthermore, as mentioned above, even the use of a sophisticated context-free tagger, based on (Levinger et al., 1995), gives low accuracy of 78.2%. This might imply that, despite the similarities, morphological disambiguation in Hebrew might be harder than in Arabic. It could also mean that the tag set used for the Arabic corpora has not been adapted to the specific nature of Arabic morphology (a comment also made in (Habash and Rambow, 2005)). We propose an unsupervised morpheme-based HMM to address the data sparseness problem. In contrast to Bar-Haim et al., our model combines segmentation and morphological disambiguation, in parallel. The only resource we use in this work is a morphological analyzer. The </context>
<context position="26108" citStr="Levinger et al. (1995)" startWordPosition="4410" endWordPosition="4413">ion δ(1,l) = πol 1.statebol (6) 1.state,ol 1.sym Induction δ(t, l) =max δ(t − 1, l&apos;)aol0 (7) l0Eolt.prev t−1.state,ol t.statebol t.state,ol t.sym ψ(t, l) = argmax δ(t − 1,l&apos;)aol0 (�) l0Eolt.prev t−1.state,ol t.statebol t.state,ol t.sym Termination and path readout XT� = argmax_ 1&lt;l&lt; |T| Xt = ψ(t + 1, δ( T, l) (9) Xt+1) P( X) = max δ( T,l) (10) 1&lt;l&lt;|O T¯| Figure 4: The searching algorithm for first-order model 670 Order Uniform CF W 1 82.01 84.08 W 2- 80.44 85.75 W 2 79.88 85.78 M 1 81.08 84.54 M 2- 81.53 88.5 M 2 83.39 85.83 Table 3: Morphological Disambiguation word in the text, according to Levinger et al. (1995) approximations, with accuracy of 78.2%, as the baseline tagger, four steps of error reduction can be identified. (1) Contextual information: The simplest first-order word-based HMM with uniform initial conditions, achieves error reduction of 17.5% (78.2 – 82.01). (2) Initial conditions: Error reductions in the range: 11.5% – 37.8% (82.01 – 84.08 for word model 1, and 81.53 – 88.5 for morhpeme model 2-) were achieved by initializing the various models with context-free approximations. While this observation confirms Elworthy (1994), the impact of error reduction is much less than reported ther</context>
</contexts>
<marker>Levinger, Ornan, Itai, 1995</marker>
<rawString>Moshe Levinger, Uzi Ornan, and Alon Itai. 1995. Learning morpholexical probabilities from an untagged corpus with an application to Hebrew. Computational Linguistics, 21:383–404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moshe Levinger</author>
</authors>
<title>Morhphological disambiguation in hebrew.</title>
<date>1992</date>
<booktitle>Master’s thesis, Technion,</booktitle>
<location>Haifa,</location>
<note>(in Hebrew).</note>
<contexts>
<context position="6734" citStr="Levinger, 1992" startWordPosition="1067" endWordPosition="1068"> similar words for each word, built according to a set of rules. The rules produce variations of the morphological properties of the word analyses. Their tests indicate an accuracy of about 88% for context-free analysis selection based on the approximated analysis distribution. In tests we reproduced on a larger data set (30K tagged words), the accuracy is only 78.2%. In order to improve the results, the authors recommend merging their method together with other morphological disambiguation methods – which is the approach we pursue in this work. Levinger&apos;s morphological disambiguation system (Levinger, 1992) combines the above approximated probabilities with an expert system, based on a manual set of 16 syntactic constraints . In the first phase, the expert system is applied, dis24–86). ambiguating 35% of the ambiguous words with an accuracy of 99.6%. In order to increase the applicability of the disambiguation, approximated probabilities are used for words that were not disambiguated in the first stage. Finally, the expert system is used again over the new probabilities that were set in the previous stage. Levinger reports an accuracy of about 94% for disambiguation of 85% of the words in the te</context>
</contexts>
<marker>Levinger, 1992</marker>
<rawString>Moshe Levinger. 1992. Morhphological disambiguation in hebrew. Master’s thesis, Technion, Haifa, Israel. (in Hebrew).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Schutze</author>
</authors>
<title>Foundation of Statistical Language Processing.</title>
<date>1999</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2655" citStr="Manning and Schutze, 1999" startWordPosition="406" endWordPosition="409">ebrew Processing, Israel Science Ministry. of annotated corpora in Hebrew&apos;, there is still not enough data available for supervised training. The other reason, is that unsupervised methods can handle the dynamic nature of Modern Hebrew, as it evolves over time. In the case of English, because morphology is simpler, morphological disambiguation is generally covered under the task of part-of-speech tagging. The main morphological variations are embedded in the tag name (for example, Ns and Np for noun singular or plural). The tagging accuracy of supervised stochastic taggers is around 96%- 97% (Manning and Schutze, 1999, 10.6.1). Merialdo (1994) reports an accuracy of 86.6% for an unsupervised word-based HMM, trained on a corpus of 42,186 sentences (about 1M words), over a tag set of 159 different tags. Elworthy (1994), in contrast, reports an accuracy of 75.49%, 80.87% and 79.12% for unsupervised word-based HMM trained on parts of the LOB corpora, with a tagset of 134 tags. With good initial conditions, such as good approximation of the tag distribution for each word, Elworthy reports an improvement to 94.6%, 92.27% and 94.51% on the same data sets. Merialdo, on the other hand, reports an improvement to 92.</context>
<context position="16064" citStr="Manning and Schutze, 1999" startWordPosition="2675" endWordPosition="2678">h word leaving the observed morphemes uncertain. For example, the word bclm can be segmented in four different ways in Table 1, as indicated by the placement of the &apos;-&apos; in the Segmentation column, while the word hn`im can be segmented in two different ways. In the next section, we adapt the parameter estimation and the searching algorithms for such uncertain output observation. 3.2 Learning and Searching Algorithms for Uncertain Output Observation In contrast to standard HMM, the output observations of the above morpheme-based HMM are ambiguous. We adapted Baum-Welch (Baum, 1972) and Viterbi (Manning and Schutze, 1999, 9.3.2) algorithms for such uncertain observation. We first formalize the output representation and then describe the algorithms. Output Representation The learning and searching algorithms of HMM are based on the output sequence of the underlying Markov process. For the case of a morpheme-based model, the output sequence is uncertain – we don’t see the emitted morphemes but the words they form. If, for instance, the Markov process emitted the morphemes b clm h nim, we would see two words (bclm hn`im) instead. In order to handle the output ambiguity, we use static knowledge of how morphemes a</context>
<context position="23078" citStr="Manning and Schutze, 1999" startWordPosition="3883" endWordPosition="3886">s in O(T) time complexity, where T is the total number of symbols in the output sequence encoding, where each symbol is counted as the size of its prev set. Searching for best state sequence The searching algorithm gets an observation sequence O and a probabilistic model µ, and looks for the best state sequence that generates the observation. We define S(t, l) as the probability of the best state sequence that leads to emission olt, and�(t, l) as the index of the emission at time t−1 that precedes olt in the best state sequence that leads to it. Fig. 4 describes the adaptation of the Viterbi (Manning and Schutze, 1999, 9.3.2) algorithm to our text representation for first-order HMM, which works in O(T) time. 4 Experimental Results We ran a series of experiments on a Hebrew corpus to compare various approaches to the full morphological disambiguation and PoS tagging tasks. The training corpus is obtained from various newspaper sources and is characterized by the following statistics: 6M word occurrences, 178,580 distinct words, 64,541 distinct lemmas. Overall, the ambiguity level is 2.4 (average number of analyses per word). We tested the results on a test corpus, manually annotated by 2 taggers according t</context>
</contexts>
<marker>Manning, Schutze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Schutze. 1999. Foundation of Statistical Language Processing. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard Merialdo</author>
</authors>
<title>Tagging English text with probabilistic model.</title>
<date>1994</date>
<journal>Computatinal Linguistics,</journal>
<pages>20--155</pages>
<contexts>
<context position="2681" citStr="Merialdo (1994)" startWordPosition="411" endWordPosition="413">istry. of annotated corpora in Hebrew&apos;, there is still not enough data available for supervised training. The other reason, is that unsupervised methods can handle the dynamic nature of Modern Hebrew, as it evolves over time. In the case of English, because morphology is simpler, morphological disambiguation is generally covered under the task of part-of-speech tagging. The main morphological variations are embedded in the tag name (for example, Ns and Np for noun singular or plural). The tagging accuracy of supervised stochastic taggers is around 96%- 97% (Manning and Schutze, 1999, 10.6.1). Merialdo (1994) reports an accuracy of 86.6% for an unsupervised word-based HMM, trained on a corpus of 42,186 sentences (about 1M words), over a tag set of 159 different tags. Elworthy (1994), in contrast, reports an accuracy of 75.49%, 80.87% and 79.12% for unsupervised word-based HMM trained on parts of the LOB corpora, with a tagset of 134 tags. With good initial conditions, such as good approximation of the tag distribution for each word, Elworthy reports an improvement to 94.6%, 92.27% and 94.51% on the same data sets. Merialdo, on the other hand, reports an improvement to 92.6% and 94.4% for the case </context>
</contexts>
<marker>Merialdo, 1994</marker>
<rawString>Bernard Merialdo. 1994. Tagging English text with probabilistic model. Computatinal Linguistics, 20:155–171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Uzi Ornan</author>
</authors>
<date>2002</date>
<note>Hebrew in latin script. Lesonenu, LXIV:137–151. (in Hebrew).</note>
<contexts>
<context position="14101" citStr="Ornan (2002)" startWordPosition="2321" endWordPosition="2322">onsider such a phrase to be generated by a Markov process, based on the wordoriented tagset of N = 1934 tags/states and about M = 175K word types. Line W of Table 2 describes the size of a first-order word-based HMM, built over our corpus. In this model, we found 834 entries for the II vector (which models the distribution of tags in first position in sentences) out of possibly N = 1934, about 250K entries for the A matrix (which models the transition probabilities from tag to tag) out of possibly N2 ;::Li 3.7M, and about 300K entries for the B matrix (which models 3Transcription according to Ornan (2002). 4The tagset we use for the annotation follows the guidelines we have developed (Elhadad et al., 2005). 667 States PI A A2 B B2 W 1934 834 250K 7M 300K 5M M 202 145 20K 700K 130K 1.7M Table 2: Model Sizes the emission probabilities from tag to word) out of possibly M · N ;::Li 350M. For the case of a secondorder HMM, the size of the A2 matrix (which models the transition probabilities from two tags to the third one), grows to about 7M entries, where the size of the B2 matrix (which models the emission probabilities from two tags to a word) is about 5M. Despite the sparseness of these matrices</context>
</contexts>
<marker>Ornan, 2002</marker>
<rawString>Uzi Ornan. 2002. Hebrew in latin script. Lesonenu, LXIV:137–151. (in Hebrew).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erel Segal</author>
</authors>
<title>Hebrew morphological analyzer for Hebrew undotted texts.</title>
<date>2000</date>
<booktitle>Master’s thesis, Technion,</booktitle>
<location>Haifa,</location>
<note>(in Hebrew).</note>
<contexts>
<context position="5644" citStr="Segal, 2000" startWordPosition="892" endWordPosition="893">nd suffix). Our main result is that best performance is obtained when learning segmentation and morpheme tagging in one step, which is made possible by an appropriate text representation. 2 Hebrew and Arabic Tagging - Previous Work Several works have dealt with Hebrew tagging in the past decade. In Hebrew, morphological analysis requires complex processing according to the rules of Hebrew word formation. The task of a morphological analyzer is to produce all possible analyses for a given word. Recent analyzers provide good performance and documentation of this process (Yona and Wintner, 2005; Segal, 2000). Morphological analyzers rely on a dictionary, and their performance is, therefore, impacted by the occurrence of unknown words. The task of a morphological disambiguation system is to pick the most likely analysis produced by an analyzer in the context of a full sentence. Levinger et al. (1995) developed a context-free method in order to acquire the morpho-lexical probabilities, from an untagged corpus. Their method handles the data sparseness problem by using a set of similar words for each word, built according to a set of rules. The rules produce variations of the morphological properties</context>
<context position="8160" citStr="Segal (2000)" startWordPosition="1318" endWordPosition="1319"> was reported while reducing 92% of the ambiguous analyses. Carmel and Maarek (1999) use the fact that on average 45% of the Hebrew words are unambiguous, to rank analyses, based on the number of disambiguated occurrences in the text, normalized by the total number of occurrences for each word. Their application – indexing for an information retrieval system – does not require all of the morphological attributes but only the lemma and the PoS of each word. As a result, for this case, 75% of the words remain with one analysis with 95% accuracy, 20% with two analyses and 5% with three analyses. Segal (2000) built a transformation-based tagger in the spirit of Brill (1995). In the first phase, the analyses of each word are ranked according to the frequencies of the possible lemmas and tags in a training corpus of about 5,000 words. Selection of the highest ranked analysis for each word gives an accuracy of 83% of the test text – which consists of about 1,000 words. In the second stage, a transformation learning algorithm is applied (in contrast to Brill, the observed transformations are not applied, but used for re-estimation of the word couples probabilities). After this stage, the accuracy is a</context>
</contexts>
<marker>Segal, 2000</marker>
<rawString>Erel Segal. 2000. Hebrew morphological analyzer for Hebrew undotted texts. Master’s thesis, Technion, Haifa, Israel. (in Hebrew).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott M Thede</author>
<author>Mary P Harper</author>
</authors>
<title>A second-order hidden Markov model for part-ofspeech tagging.</title>
<date>1999</date>
<booktitle>In Proceeding of ACL-99.</booktitle>
<contexts>
<context position="30834" citStr="Thede and Harper (1999)" startWordPosition="5213" endWordPosition="5216">his work, we have introduced a new text encoding method that captures rules of word formation in a language with affixational morphology such as Hebrew. This text encoding method allows us to 671 learn in parallel segmentation and tagging rules in an unsupervised manner, despite the high ambiguity level of the morphological data (average number of 2.4 analyses per word). Reported results on a large scale corpus (6M words) with fully unsupervised learning are 92.32% for PoS tagging and 88.5% for full morphological disambiguation. In this work, we used the backoff smoothing method, suggested by Thede and Harper (1999), with an extension of additive smoothing (Chen, 1996, 2.2.1) for the lexical probabilities (B and B2 matrices). To complete this study, we are currently investigating several smoothing techniques (Chen, 1996), in order to check whether the morpheme model is critical for the data sparseness problem, or whether it can be handled with smoothing over a word model. We are currently investigating two major methods to improve our results: first, we have started gathering a larger corpus of manually tagged text and plan to perform semi-supervised learning on a corpus of 100K manually tagged words. Se</context>
</contexts>
<marker>Thede, Harper, 1999</marker>
<rawString>Scott M. Thede and Mary P. Harper. 1999. A second-order hidden Markov model for part-ofspeech tagging. In Proceeding of ACL-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shlomo Yona</author>
<author>Shuly Wintner</author>
</authors>
<title>A finitestate morphological grammar of Hebrew.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-05 Workshop on Computational Approaches to Semitic Languages.</booktitle>
<contexts>
<context position="4136" citStr="Yona and Wintner, 2005" startWordPosition="650" endWordPosition="653">2.4 (in contrast to 1.4 for English). In Hebrew, several morphemes combine into a single word in both agglutinative and fusional ways. This results in a potentially high number of tags for each word. In contrast to English tag sets whose sizes range from 48 to 195, the number of tags for Hebrew, based on all combinations of the morphological attributes (part-of-speech, gender, number, person, tense, status, and the affixes&apos; properties2), &apos;The Knowledge Center for Hebrew processing is developing such corpora: http://mila.cs.technion.ac.il/ 2The list of morphological attributes is described in (Yona and Wintner, 2005). An in-depth discussion of the Hebrew word form is provided in (Allon, 1995, pp. 665 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 665–672, Sydney, July 2006. c�2006 Association for Computational Linguistics can grow theoretically to about 300,000 tags. In practice, we found only 1,934 tags in a corpus of news stories we gathered, which contains about 6M words. The large size of such a tag set (about 10 times larger than the most comprehensive English tag set) is problematic in term of data sparseness. Each morphologica</context>
<context position="5630" citStr="Yona and Wintner, 2005" startWordPosition="888" endWordPosition="891">into prefix, baseform, and suffix). Our main result is that best performance is obtained when learning segmentation and morpheme tagging in one step, which is made possible by an appropriate text representation. 2 Hebrew and Arabic Tagging - Previous Work Several works have dealt with Hebrew tagging in the past decade. In Hebrew, morphological analysis requires complex processing according to the rules of Hebrew word formation. The task of a morphological analyzer is to produce all possible analyses for a given word. Recent analyzers provide good performance and documentation of this process (Yona and Wintner, 2005; Segal, 2000). Morphological analyzers rely on a dictionary, and their performance is, therefore, impacted by the occurrence of unknown words. The task of a morphological disambiguation system is to pick the most likely analysis produced by an analyzer in the context of a full sentence. Levinger et al. (1995) developed a context-free method in order to acquire the morpho-lexical probabilities, from an untagged corpus. Their method handles the data sparseness problem by using a set of similar words for each word, built according to a set of rules. The rules produce variations of the morphologi</context>
</contexts>
<marker>Yona, Wintner, 2005</marker>
<rawString>Shlomo Yona and Shuly Wintner. 2005. A finitestate morphological grammar of Hebrew. In Proceedings of ACL-05 Workshop on Computational Approaches to Semitic Languages.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>