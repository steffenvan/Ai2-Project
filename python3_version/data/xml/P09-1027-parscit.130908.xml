<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.050187">
<title confidence="0.962684">
Co-Training for Cross-Lingual Sentiment Classification
</title>
<author confidence="0.997582">
Xiaojun Wan
</author>
<affiliation confidence="0.782425333333333">
Institute of Compute Science and Technology &amp; Key Laboratory of Computational Lin-
guistics, MOE
Peking University, Beijing 100871, China
</affiliation>
<email confidence="0.940838">
wanxiaojun@icst.pku.edu.cn
</email>
<sectionHeader confidence="0.991821" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999219157894737">
The lack of Chinese sentiment corpora limits
the research progress on Chinese sentiment
classification. However, there are many freely
available English sentiment corpora on the
Web. This paper focuses on the problem of
cross-lingual sentiment classification, which
leverages an available English corpus for Chi-
nese sentiment classification by using the Eng-
lish corpus as training data. Machine transla-
tion services are used for eliminating the lan-
guage gap between the training set and test set,
and English features and Chinese features are
considered as two independent views of the
classification problem. We propose a co-
training approach to making use of unlabeled
Chinese data. Experimental results show the
effectiveness of the proposed approach, which
can outperform the standard inductive classifi-
ers and the transductive classifiers.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999970461538462">
Sentiment classification is the task of identifying
the sentiment polarity of a given text. The senti-
ment polarity is usually positive or negative and
the text genre is usually product review. In recent
years, sentiment classification has drawn much
attention in the NLP field and it has many useful
applications, such as opinion mining and summa-
rization (Liu et al., 2005; Ku et al., 2006; Titov
and McDonald, 2008).
To date, a variety of corpus-based methods
have been developed for sentiment classification.
The methods usually rely heavily on an anno-
tated corpus for training the sentiment classifier.
The sentiment corpora are considered as the most
valuable resources for the sentiment classifica-
tion task. However, such resources in different
languages are very imbalanced. Because most
previous work focuses on English sentiment
classification, many annotated corpora for Eng-
lish sentiment classification are freely available
on the Web. However, the annotated corpora for
Chinese sentiment classification are scarce and it
is not a trivial task to manually label reliable
Chinese sentiment corpora. The challenge before
us is how to leverage rich English corpora for
Chinese sentiment classification. In this study,
we focus on the problem of cross-lingual senti-
ment classification, which leverages only English
training data for supervised sentiment classifica-
tion of Chinese product reviews, without using
any Chinese resources. Note that the above prob-
lem is not only defined for Chinese sentiment
classification, but also for various sentiment
analysis tasks in other different languages.
Though pilot studies have been performed to
make use of English corpora for subjectivity
classification in other languages (Mihalcea et al.,
2007; Banea et al., 2008), the methods are very
straightforward by directly employing an induc-
tive classifier (e.g. SVM, NB), and the classifica-
tion performance is far from satisfactory because
of the language gap between the original lan-
guage and the translated language.
In this study, we propose a co-training ap-
proach to improving the classification accuracy
of polarity identification of Chinese product re-
views. Unlabeled Chinese reviews can be fully
leveraged in the proposed approach. First, ma-
chine translation services are used to translate
English training reviews into Chinese reviews
and also translate Chinese test reviews and addi-
tional unlabeled reviews into English reviews.
Then, we can view the classification problem in
two independent views: Chinese view with only
Chinese features and English view with only
English features. We then use the co-training
approach to making full use of the two redundant
views of features. The SVM classifier is adopted
as the basic classifier in the proposed approach.
Experimental results show that the proposed ap-
proach can outperform the baseline inductive
classifiers and the more advanced transductive
classifiers.
The rest of this paper is organized as follows:
Section 2 introduces related work. The proposed
</bodyText>
<page confidence="0.977283">
235
</page>
<note confidence="0.9996115">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 235–243,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.991209333333333">
co-training approach is described in detail in
Section 3. Section 4 shows the experimental re-
sults. Lastly we conclude this paper in Section 5.
</bodyText>
<sectionHeader confidence="0.999653" genericHeader="related work">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.99691">
2.1 Sentiment Classification
</subsectionHeader>
<bodyText confidence="0.999547415384615">
Sentiment classification can be performed on
words, sentences or documents. In this paper we
focus on document sentiment classification. The
methods for document sentiment classification
can be generally categorized into lexicon-based
and corpus-based.
Lexicon-based methods usually involve deriv-
ing a sentiment measure for text based on senti-
ment lexicons. Turney (2002) predicates the sen-
timent orientation of a review by the average se-
mantic orientation of the phrases in the review
that contain adjectives or adverbs, which is de-
noted as the semantic oriented method. Kim and
Hovy (2004) build three models to assign a sen-
timent category to a given sentence by combin-
ing the individual sentiments of sentiment-
bearing words. Hiroshi et al. (2004) use the tech-
nique of deep language analysis for machine
translation to extract sentiment units in text
documents. Kennedy and Inkpen (2006) deter-
mine the sentiment of a customer review by
counting positive and negative terms and taking
into account contextual valence shifters, such as
negations and intensifiers. Devitt and Ahmad
(2007) explore a computable metric of positive
or negative polarity in financial news text.
Corpus-based methods usually consider the
sentiment analysis task as a classification task
and they use a labeled corpus to train a sentiment
classifier. Since the work of Pang et al. (2002),
various classification models and linguistic fea-
tures have been proposed to improve the classifi-
cation performance (Pang and Lee, 2004; Mullen
and Collier, 2004; Wilson et al., 2005; Read,
2005). Most recently, McDonald et al. (2007)
investigate a structured model for jointly classi-
fying the sentiment of text at varying levels of
granularity. Blitzer et al. (2007) investigate do-
main adaptation for sentiment classifiers, focus-
ing on online reviews for different types of prod-
ucts. Andreevskaia and Bergler (2008) present a
new system consisting of the ensemble of a cor-
pus-based classifier and a lexicon-based classi-
fier with precision-based vote weighting.
Chinese sentiment analysis has also been stud-
ied (Tsou et al., 2005; Ye et al., 2006; Li and Sun,
2007) and most such work uses similar lexicon-
based or corpus-based methods for Chinese sen-
timent classification.
To date, several pilot studies have been per-
formed to leverage rich English resources for
sentiment analysis in other languages. Standard
Naïve Bayes and SVM classifiers have been ap-
plied for subjectivity classification in Romanian
(Mihalcea et al., 2007; Banea et al., 2008), and
the results show that automatic translation is a
viable alternative for the construction of re-
sources and tools for subjectivity analysis in a
new target language. Wan (2008) focuses on lev-
eraging both Chinese and English lexicons to
improve Chinese sentiment analysis by using
lexicon-based methods. In this study, we focus
on improving the corpus-based method for cross-
lingual sentiment classification of Chinese prod-
uct reviews by developing novel approaches.
</bodyText>
<subsectionHeader confidence="0.999448">
2.2 Cross-Domain Text Classification
</subsectionHeader>
<bodyText confidence="0.999959294117647">
Cross-domain text classification can be consid-
ered as a more general task than cross-lingual
sentiment classification. In the problem of cross-
domain text classification, the labeled and unla-
beled data come from different domains, and
their underlying distributions are often different
from each other, which violates the basic as-
sumption of traditional classification learning.
To date, many semi-supervised learning algo-
rithms have been developed for addressing the
cross-domain text classification problem by
transferring knowledge across domains, includ-
ing Transductive SVM (Joachims, 1999),
EM(Nigam et al., 2000), EM-based Naïve Bayes
classifier (Dai et al., 2007a), Topic-bridged
PLSA (Xue et al., 2008), Co-Clustering based
classification (Dai et al., 2007b), two-stage ap-
proach (Jiang and Zhai, 2007). DauméIII and
Marcu (2006) introduce a statistical formulation
of this problem in terms of a simple mixture
model.
In particular, several previous studies focus on
the problem of cross-lingual text classification,
which can be considered as a special case of
general cross-domain text classification. Bel et al.
(2003) present practical and cost-effective solu-
tions. A few novel models have been proposed to
address the problem, e.g. the EM-based algo-
rithm (Rigutini et al., 2005), the information bot-
tleneck approach (Ling et al., 2008), the multi-
lingual domain models (Gliozzo and Strapparava,
2005), etc. To the best of our knowledge, co-
training has not yet been investigated for cross-
domain or cross-lingual text classification.
</bodyText>
<page confidence="0.998659">
236
</page>
<sectionHeader confidence="0.969469" genericHeader="method">
3 The Co-Training Approach
</sectionHeader>
<subsectionHeader confidence="0.989328">
3.1 Overview
</subsectionHeader>
<bodyText confidence="0.947866979166667">
The purpose of our approach is to make use of
the annotated English corpus for sentiment polar-
ity identification of Chinese reviews in a super-
vised framework, without using any Chinese re-
sources. Given the labeled English reviews and
unlabeled Chinese reviews, two straightforward
methods for addressing the problem are as fol-
lows:
1) We first learn a classifier based on the la-
beled English reviews, and then translate Chi-
nese reviews into English reviews. Lastly, we
use the classifier to classify the translated Eng-
lish reviews.
2) We first translate the labeled English re-
views into Chinese reviews, and then learn a
classifier based on the translated Chinese reviews
with labels. Lastly, we use the classifier to clas-
sify the unlabeled Chinese reviews.
The above two methods have been used in
(Banea et al., 2008) for Romanian subjectivity
analysis, but the experimental results are not very
promising. As shown in our experiments, the
above two methods do not perform well for Chi-
nese sentiment classification, either, because the
underlying distribution between the original lan-
guage and the translated language are different.
In order to address the above problem, we
propose to use the co-training approach to make
use of some amounts of unlabeled Chinese re-
views to improve the classification accuracy. The
co-training approach can make full use of both
the English features and the Chinese features in a
unified framework. The framework of the pro-
posed approach is illustrated in Figure 1.
The framework consists of a training phase
and a classification phase. In the training phase,
the input is the labeled English reviews and some
amounts of unlabeled Chinese reviews1. The la-
beled English reviews are translated into labeled
Chinese reviews, and the unlabeled Chinese re-
views are translated into unlabeled English re-
views, by using machine translation services.
Therefore, each review is associated with an
English version and a Chinese version. The Eng-
lish features and the Chinese features for each
review are considered two independent and re-
dundant views of the review. The co-training
algorithm is then applied to learn two classifiers
</bodyText>
<footnote confidence="0.868540333333333">
1 The unlabeled Chinese reviews used for co-training do not
include the unlabeled Chinese reviews for testing, i.e., the
Chinese reviews for testing are blind to the training phase.
</footnote>
<bodyText confidence="0.999974444444444">
and finally the two classifiers are combined into
a single sentiment classifier. In the classification
phase, each unlabeled Chinese review for testing
is first translated into English review, and then
the learned classifier is applied to classify the
review into either positive or negative.
The steps of review translation and the co-
training algorithm are described in details in the
next sections, respectively.
</bodyText>
<subsectionHeader confidence="0.999359">
3.2 Review Translation
</subsectionHeader>
<bodyText confidence="0.999566">
In order to overcome the language gap, we must
translate one language into another language.
Fortunately, machine translation techniques have
been well developed in the NLP field, though the
translation performance is far from satisfactory.
A few commercial machine translation services
can be publicly accessed, e.g. Google Translate2,
Yahoo Babel Fish3 and Windows Live Translate4.
</bodyText>
<footnote confidence="0.986812666666667">
2 http://translate.google.com/translate_t
3 http://babelfish.yahoo.com/translatetxt
4 http://www.windowslivetranslator.c_om/
</footnote>
<figure confidence="0.997997">
Chinese View English View
Machine
Translation
(CN-EN)
Unlabeled
Chinese
Reviews
Labeled
Chinese
Reviews
Test
Chinese
Review
Test
English
Review
Machine
Translation
(CN-EN)
Machine
Translation
(EN-CN)
Co-Training
Sentiment
Classifier
Training Phase
Classification Phase
Unlabeled
English
Reviews
Labeled
English
Reviews
Pos\Neg
</figure>
<figureCaption confidence="0.999847">
Figure 1. Framework of the proposed approach
</figureCaption>
<page confidence="0.970186">
237
</page>
<bodyText confidence="0.9998703">
In this study, we adopt Google Translate for both
English-to-Chinese Translation and Chinese-to-
English Translation, because it is one of the
state-of-the-art commercial machine translation
systems used today. Google Translate applies
statistical learning techniques to build a transla-
tion model based on both monolingual text in the
target language and aligned text consisting of
examples of human translations between the lan-
guages.
</bodyText>
<subsectionHeader confidence="0.999473">
3.3 The Co-Training Algorithm
</subsectionHeader>
<bodyText confidence="0.991586412698412">
The co-training algorithm (Blum and Mitchell,
1998) is a typical bootstrapping method, which
starts with a set of labeled data, and increase the
amount of annotated data using some amounts of
unlabeled data in an incremental way. One im-
portant aspect of co-training is that two condi-
tional independent views are required for co-
training to work, but the independence assump-
tion can be relaxed. Till now, co-training has
been successfully applied to statistical parsing
(Sarkar, 2001), reference resolution (Ng and
Cardie, 2003), part of speech tagging (Clark et
al., 2003), word sense disambiguation (Mihalcea,
2004) and email classification (Kiritchenko and
Matwin, 2001).
In the context of cross-lingual sentiment clas-
sification, each labeled English review or unla-
beled Chinese review has two views of features:
English features and Chinese features. Here, a
review is used to indicate both its Chinese ver-
sion and its English version, until stated other-
wise. The co-training algorithm is illustrated in
Figure 2. In the algorithm, the class distribution
in the labeled data is maintained by balancing the
parameter values of p and n at each iteration.
The intuition of the co-training algorithm is
that if one classifier can confidently predict the
class of an example, which is very similar to
some of labeled ones, it can provide one more
training example for the other classifier. But, of
course, if this example happens to be easy to be
classified by the first classifier, it does not mean
that this example will be easy to be classified by
the second classifier, so the second classifier will
get useful information to improve itself and vice
versa (Kiritchenko and Matwin, 2001).
In the co-training algorithm, a basic classifica-
tion algorithm is required to construct Cen and
C,n. Typical text classifiers include Support Vec-
tor Machine (SVM), Naïve Bayes (NB), Maxi-
mum Entropy (ME), K-Nearest Neighbor (KNN) ,
etc. In this study, we adopt the widely-used SVM
classifier (Joachims, 2002). Viewing input data
as two sets of vectors in a feature space, SVM
constructs a separating hyperplane in the space
by maximizing the margin between the two data
sets. The English or Chinese features used in this
study include both unigrams and bigrams5 and
the feature weight is simply set to term fre-
quency6. Feature selection methods (e.g. Docu-
ment Frequency (DF), Information Gain (IG),
and Mutual Information (MI)) can be used for
dimension reduction. But we use all the features
in the experiments for comparative analysis, be-
cause there is no significant performance im-
provement after applying the feature selection
techniques in our empirical study. The output
value of the SVM classifier for a review indi-
cates the confidence level of the review’s classi-
fication. Usually, the sentiment polarity of a re-
view is indicated by the sign of the prediction
value.
Given:
</bodyText>
<listItem confidence="0.974628583333333">
- Fen and F,n are redundantly sufficient
sets of features, where Fen represents
the English features, F,n represents the
Chinese features;
- L is a set of labeled training reviews;
- U is a set of unlabeled reviews;
Loop for I iterations:
1. Learn the first classifier Cen from L
based on Fen;
2. Use Cen to label reviews from U
based on Fen;
3. Choose p positive and n negative the
most confidently predicted reviews
Een from U;
4. Learn the second classifier C,n from L
based on F,n;
5. Use C,n to label reviews from U
based on F,n;
6. Choose p positive and n negative the
most confidently predicted reviews
E,n from U;
7. Removes reviews EenUE,n from U7;
8. Add reviews EenUE,n with the corre-
sponding labels to L;
</listItem>
<figureCaption confidence="0.999831">
Figure 2. The co-training algorithm
</figureCaption>
<bodyText confidence="0.990969">
In the training phase, the co-training algorithm
learns two separate classifiers: Cen and C,n.
</bodyText>
<footnote confidence="0.9240895">
5 For Chinese text, a unigram refers to a Chinese word and a
bigram refers to two adjacent Chinese words.
6 Term frequency performs better than TFIDF by our em-
pirical analysis.
7 Note that the examples with conflicting labels are not in-
cluded in EenUE,n In other words, if an example is in both
Een and E,n, but the labels for the example is conflicting, the
example will be excluded from EenUE,n.
</footnote>
<page confidence="0.99255">
238
</page>
<bodyText confidence="0.999969">
Therefore, in the classification phase, we can
obtain two prediction values for a test review.
We normalize the prediction values into [-1, 1]
by dividing the maximum absolute value. Finally,
the average of the normalized values is used as
the overall prediction value of the review.
</bodyText>
<sectionHeader confidence="0.991621" genericHeader="method">
4 Empirical Evaluation
</sectionHeader>
<subsectionHeader confidence="0.988507">
4.1 Evaluation Setup
</subsectionHeader>
<subsubsectionHeader confidence="0.992688">
4.1.1 Data set
</subsubsectionHeader>
<bodyText confidence="0.995448277777778">
The following three datasets were collected and
used in the experiments:
Test Set (Labeled Chinese Reviews): In or-
der to assess the performance of the proposed
approach, we collected and labeled 886 product
reviews (451 positive reviews + 435 negative
reviews) from a popular Chinese IT product web
site-IT1688. The reviews focused on such prod-
ucts as mp3 players, mobile phones, digital cam-
era and laptop computers.
Training Set (Labeled English Reviews):
There are many labeled English corpora avail-
able on the Web and we used the corpus con-
structed for multi-domain sentiment classifica-
tion (Blitzer et al., 2007)9, because the corpus
was large-scale and it was within similar do-
mains as the test set. The dataset consisted of
8000 Amazon product reviews (4000 positive
reviews + 4000 negative reviews) for four differ-
ent product types: books, DVDs, electronics and
kitchen appliances.
Unlabeled Set (Unlabeled Chinese Reviews):
We downloaded additional 1000 Chinese product
reviews from IT168 and used the reviews as the
unlabeled set. Therefore, the unlabeled set and
the test set were in the same domain and had
similar underlying feature distributions.
Each Chinese review was translated into Eng-
lish review, and each English review was trans-
lated into Chinese review. Therefore, each re-
view has two independent views: English view
and Chinese view. A review is represented by
both its English view and its Chinese view.
Note that the training set and the unlabeled set
are used in the training phase, while the test set is
blind to the training phase.
</bodyText>
<subsubsectionHeader confidence="0.998032">
4.1.2 Evaluation Metric
</subsubsectionHeader>
<bodyText confidence="0.99902">
We used the standard precision, recall and F-
measure to measure the performance of positive
and negative class, respectively, and used the
</bodyText>
<footnote confidence="0.988387">
8 http://www.it168.com
9 http://www.cis.upenn.edu/~mdredze/datasets/sentiment/
</footnote>
<bodyText confidence="0.992524">
accuracy metric to measure the overall perform-
ance of the system. The metrics are defined the
same as in general text categorization.
</bodyText>
<subsubsectionHeader confidence="0.976936">
4.1.3 Baseline Methods
</subsubsectionHeader>
<bodyText confidence="0.999125770833333">
In the experiments, the proposed co-training ap-
proach (CoTrain) is compared with the following
baseline methods:
SVM(CN): This method applies the inductive
SVM with only Chinese features for sentiment
classification in the Chinese view. Only English-
to-Chinese translation is needed. And the unla-
beled set is not used.
SVM(EN): This method applies the inductive
SVM with only English features for sentiment
classification in the English view. Only Chinese-
to-English translation is needed. And the unla-
beled set is not used.
SVM(ENCN1): This method applies the in-
ductive SVM with both English and Chinese fea-
tures for sentiment classification in the two
views. Both English-to-Chinese and Chinese-to-
English translations are required. And the unla-
beled set is not used.
SVM(ENCN2): This method combines the re-
sults of SVM(EN) and SVM(CN) by averaging
the prediction values in the same way with the
co-training approach.
TSVM(CN): This method applies the trans-
ductive SVM with only Chinese features for sen-
timent classification in the Chinese view. Only
English-to-Chinese translation is needed. And
the unlabeled set is used.
TSVM(EN): This method applies the trans-
ductive SVM with only English features for sen-
timent classification in the English view. Only
Chinese-to-English translation is needed. And
the unlabeled set is used.
TSVM(ENCN1): This method applies the
transductive SVM with both English and Chinese
features for sentiment classification in the two
views. Both English-to-Chinese and Chinese-to-
English translations are required. And the unla-
beled set is used.
TSVM(ENCN2): This method combines the
results of TSVM(EN) and TSVM(CN) by aver-
aging the prediction values.
Note that the first four methods are straight-
forward methods used in previous work, while
the latter four methods are strong baselines be-
cause the transductive SVM has been widely
used for improving the classification accuracy by
leveraging additional unlabeled examples.
</bodyText>
<page confidence="0.995291">
239
</page>
<subsectionHeader confidence="0.944278">
4.2 Evaluation Results
</subsectionHeader>
<subsubsectionHeader confidence="0.975554">
4.2.1 Method Comparison
</subsubsectionHeader>
<bodyText confidence="0.999974310344828">
In the experiments, we first compare the pro-
posed co-training approach (I=40 and p=n=5)
with the eight baseline methods. The three pa-
rameters in the co-training approach are empiri-
cally set by considering the total number (i.e.
1000) of the unlabeled Chinese reviews. In our
empirical study, the proposed approach can per-
form well with a wide range of parameter values,
which will be shown later. Table 1 shows the
comparison results.
Seen from the table, the proposed co-training
approach outperforms all eight baseline methods
over all metrics. Among the eight baselines, the
best one is TSVM(ENCN2), which combines the
results of two transductive SVM classifiers. Ac-
tually, TSVM(ENCN2) is similar to CoTrain
because CoTrain also combines the results of
two classifiers in the same way. However, the
co-training approach can train two more effective
classifiers, and the accuracy values of the com-
ponent English and Chinese classifiers are 0.775
and 0.790, respectively, which are higher than
the corresponding TSVM classifiers. Overall, the
use of transductive learning and the combination
of English and Chinese views are beneficial to
the final classification accuracy, and the co-
training approach is more suitable for making
use of the unlabeled Chinese reviews than the
transductive SVM.
</bodyText>
<subsubsectionHeader confidence="0.991993">
4.2.2 Influences of Iteration Number (I)
</subsubsectionHeader>
<bodyText confidence="0.99958252">
Figure 3 shows the accuracy curve of the co-
training approach (Combined Classifier) with
different numbers of iterations. The iteration
number I is varied from 1 to 80. When I is set to
1, the co-training approach is degenerated into
SVM(ENCN2). The accuracy curves of the com-
ponent English and Chinese classifiers learned in
the co-training approach are also shown in the
figure. We can see that the proposed co-training
approach can outperform the best baseline-
TSVM(ENCN2) after 20 iterations. After a large
number of iterations, the performance of the co-
training approach decreases because noisy train-
ing examples may be selected from the remain-
ing unlabeled set. Finally, the performance of the
approach does not change any more, because the
algorithm runs out of all possible examples in the
unlabeled set. Fortunately, the proposed ap-
proach performs well with a wide range of itera-
tion numbers. We can also see that the two com-
ponent classifier has similar trends with the co-
training approach. It is encouraging that the com-
ponent Chinese classifier alone can perform bet-
ter than the best baseline when the iteration
number is set between 40 and 70.
</bodyText>
<subsubsectionHeader confidence="0.969712">
4.2.3 Influences of Growth Size (p, n)
</subsubsectionHeader>
<bodyText confidence="0.999465090909091">
Figure 4 shows how the growth size at each it-
eration (p positive and n negative confident ex-
amples) influences the accuracy of the proposed
co-training approach. In the above experiments,
we set p=n, which is considered as a balanced
growth. When p differs very much from n, the
growth is considered as an imbalanced growth.
Balanced growth of (2, 2), (5, 5), (10, 10) and
(15, 15) examples and imbalanced growth of (1,
5), (5, 1) examples are compared in the figure.
We can see that the performance of the co-
training approach with the balanced growth can
be improved after a few iterations. And the per-
formance of the co-training approach with large
p and n will more quickly become unchanged,
because the approach runs out of the limited ex-
amples in the unlabeled set more quickly. How-
ever, the performance of the co-training ap-
proaches with the two imbalanced growths is
always going down quite rapidly, because the
labeled unbalanced examples hurt the perform-
ance badly at each iteration.
</bodyText>
<table confidence="0.999800833333333">
Method Positive Negative Total
Precision Recall F-measure Precision Recall F-measure Accuracy
SVM(CN) 0.733 0.865 0.793 0.828 0.674 0.743 0.771
SVM(EN) 0.717 0.803 0.757 0.766 0.671 0.716 0.738
SVM(ENCN1) 0.744 0.820 0.781 0.792 0.708 0.748 0.765
SVM(ENCN2) 0.746 0.847 0.793 0.816 0.701 0.754 0.775
TSVM(CN) 0.724 0.878 0.794 0.838 0.653 0.734 0.767
TSVM(EN) 0.732 0.860 0.791 0.823 0.674 0.741 0.769
TSVM(ENCN1) 0.743 0.878 0.805 0.844 0.685 0.756 0.783
TSVM(ENCN2) 0.744 0.896 0.813 0.863 0.680 0.761 0.790
CoTrain 0.768 0.905 0.831 0.879 0.717 0.790 0.813
(I=40; p=n=5)
</table>
<tableCaption confidence="0.999927">
Table 1. Comparison results
</tableCaption>
<page confidence="0.946514">
240
</page>
<figure confidence="0.99974075">
Accuracy
0.82
0.81
0.79
0.78
0.77
0.76
0.75
0.74
0.73
0.72
0.8
1 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80
English Classifier(CoTrain) Chinese Classifier(CoTrain)
Combined Classifier(CoTrain) TSVM(ENCN2)
Iteration Number (I)
</figure>
<figureCaption confidence="0.999996333333333">
Figure 3. Accuracy vs. number of iterations for co-training (p=n=5)
Figure 4. Accuracy vs. different (p, n) for co-training
Figure 5. Influences of feature size
</figureCaption>
<figure confidence="0.996789565217391">
Accuracy
0.75
0.65
0.55
0.8
0.7
0.6
0.5
1 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80
Iteration Number (I )
(p=2,n=2) (p=5,n=5) (p=10,n=10)
(p=15,n=15) (p=1,n=5) (p=5,n=1)
Accuracy
0.82
0.81
0.79
0.78
0.77
0.76
0.8
TSVM(ENCN1) TSVM(ENCN2) CoTrain (I=40; p=n=5)
25% 50% 75% 100%
Feature size
</figure>
<page confidence="0.959747">
241
</page>
<subsubsectionHeader confidence="0.913324">
4.2.4 Influences of Feature Selection
</subsubsectionHeader>
<bodyText confidence="0.999985523809524">
In the above experiments, all features (unigram +
bigram) are used. As mentioned earlier, feature
selection techniques are widely used for dimen-
sion reduction. In this section, we further con-
duct experiments to investigate the influences of
feature selection techniques on the classification
results. We use the simple but effective docu-
ment frequency (DF) for feature selection. Fig-
ures 6 show the comparison results of different
feature sizes for the co-training approach and
two strong baselines. The feature size is meas-
ured as the proportion of the selected features
against the total features (i.e. 100%).
We can see from the figure that the feature se-
lection technique has very slight influences on
the classification accuracy of the methods. It can
be seen that the co-training approach can always
outperform the two baselines with different fea-
ture sizes. The results further demonstrate the
effectiveness and robustness of the proposed co-
training approach.
</bodyText>
<sectionHeader confidence="0.99104" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999894714285715">
In this paper, we propose to use the co-training
approach to address the problem of cross-lingual
sentiment classification. The experimental results
show the effectiveness of the proposed approach.
In future work, we will improve the sentiment
classification accuracy in the following two ways:
1) The smoothed co-training approach used in
(Mihalcea, 2004) will be adopted for sentiment
classification. The approach has the effect of
“smoothing” the learning curves. During the
bootstrapping process of smoothed co-training,
the classifier at each iteration is replaced with a
majority voting scheme applied to all classifiers
constructed at previous iterations.
2) The feature distributions of the translated
text and the natural text in the same language are
still different due to the inaccuracy of the ma-
chine translation service. We will employ the
structural correspondence learning (SCL) domain
adaption algorithm used in (Blitzer et al., 2007)
for linking the translated text and the natural text.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99958">
This work was supported by NSFC (60873155),
RFDP (20070001059), Beijing Nova Program
(2008B03), National High-tech R&amp;D Program
(2008AA01Z421) and NCET (NCET-08-0006).
We also thank the anonymous reviewers for their
useful comments.
</bodyText>
<sectionHeader confidence="0.989469" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998668745098039">
A. Andreevskaia and S. Bergler. 2008. When special-
ists and generalists work together: overcoming
domain dependence in sentiment tagging. In Pro-
ceedings of ACL-08: HLT.
C. Banea, R. Mihalcea, J. Wiebe and S. Hassan. 2008.
Multilingual subjectivity analysis using machine
translation. In Proceedings of EMNLP-2008.
N. Bel, C. H. A. Koster, and M. Villegas. 2003.
Cross-lingual text categorization. In Proceedings of
ECDL-03.
J. Blitzer, M. Dredze and F. Pereira. 2007. Biogra-
phies, bollywood, boom-boxes and blenders: do-
main adaptation for sentiment classification. In
Proceedings of ACL-07.
A. Blum and T. Mitchell. 1998. Combining labeled
and unlabeled data with cotraining. In Proceedings
of COLT-98.
S. Brody, R. Navigli and M. Lapata. 2006. Ensemble
methods for unsupervised WSD. In Proceedings of
COLING-ACL-2006.
S. Clark, J. R. Curran, and M. Osborne. 2003. Boot-
strapping POS taggers using unlabelled data. In
Proceedings of CoNLL-2003.
W. Dai, G.-R. Xue, Q. Yang, Y. Yu. 2007a. Transfer-
ring Naïve Bayes Classifiers for text classification.
In Proceedings of AAAI-07.
W. Dai, G.-R. Xue, Q. Yang, Y. Yu. 2007b. Co-
clustering based classification for out-of-domain
documents. In Proceedings of KDD-07.
H. DauméIII and D. Marcu. 2006. Domain adaptation
for statistical classifiers. Journal of Artificial Intel-
ligence Research, 26:101–126.
A. Devitt and K. Ahmad. 2007. Sentiment polarity
identification in financial news: a cohesion-based
approach. In Proceedings of ACL2007.
T. G. Dietterich. 1997. Machine learning research:
four current directions. AI Magazine, 18(4), 1997.
A. Gliozzo and C. Strapparava. 2005. Cross language
text categorization by acquiring multilingual do-
main models from comparable corpora. In Pro-
ceedings of the ACL Workshop on Building and
Using Parallel Texts.
K. Hiroshi, N. Tetsuya and W. Hideo. 2004. Deeper
sentiment analysis using machine translation tech-
nology. In Proceedings of COLING-04.
J. Jiang and C. Zhai. 2007. A two-stage approach to
domain adaptation for statistical classifiers. In Pro-
ceedings of CIKM-07.
T. Joachims. 1999. Transductive inference for text
classification using support vector machines. In
Proceedings of ICML-99.
</reference>
<page confidence="0.962697">
242
</page>
<reference confidence="0.99994076744186">
T. Joachims. 2002. Learning to classify text using
support vector machines. Dissertation, Kluwer,
2002.
A. Kennedy and D. Inkpen. 2006. Sentiment classifi-
cation of movie reviews using contextual valence
shifters. Computational Intelligence, 22(2):110-
125.
S.-M. Kim and E. Hovy. 2004. Determining the sen-
timent of opinions. In Proceedings of COLING-04.
S. Kiritchenko and S. Matwin. 2001. Email classifica-
tion with co-training. In Proceedings of the 2001
Conference of the Centre for Advanced Studies on
Collaborative Research.
L.-W. Ku, Y.-T. Liang and H.-H. Chen. 2006. Opin-
ion extraction, summarization and tracking in news
and blog corpora. In Proceedings of AAAI-2006.
J. Li and M. Sun. 2007. Experimental study on senti-
ment classification of Chinese review using ma-
chine learning techniques. In Proceeding of IEEE-
NLPKE-07.
X. Ling, W. Dai, Y. Jiang, G.-R. Xue, Q. Yang, and Y.
Yu. 2008. Can Chinese Web pages be classified
with English data source? In Proceedings of
WWW-08.
B. Liu, M. Hu and J. Cheng. 2005. Opinion observer:
Analyzing and comparing opinions on the web. In
Proceedings of WWW-2005.
R. McDonald, K. Hannan, T. Neylon, M. Wells and J.
Reynar. 2007. Structured models for fine-to-coarse
sentiment analysis. In Proceedings of ACL-07.
R. Mihalcea. 2004. Co-training and self-training for
word sense disambiguation. In Proceedings of
CONLL-04.
R. Mihalcea, C. Banea and J. Wiebe. 2007. Learning
multilingual subjective language via cross-lingual
projections. In Proceedings of ACL-2007.
T. Mullen and N. Collier. 2004. Sentiment analysis
using support vector machines with diverse infor-
mation sources. In Proceedings of EMNLP-04.
V. Ng and C. Cardie. 2003. Weakly supervised natu-
ral language learning without redundant views. In
Proceedings of HLT-NAACL-03.
K. Nigam, A. K. McCallum, S. Thrun, and T.
Mitchell. 2000. Text Classification from Labeled
and Unlabeled Documents using EM. Machine
Learning, 39(2-3):103–134.
B. Pang, L. Lee and S. Vaithyanathan. 2002. Thumbs
up? sentiment classification using machine learn-
ing techniques. In Proceedings of EMNLP-02.
B. Pang and L. Lee. 2004. A sentimental education:
sentiment analysis using subjectivity summariza-
tion based on minimum cuts. In Proceedings of
ACL-04.
J. Read. 2005. Using emoticons to reduce dependency
in machine learning techniques for sentiment clas-
sification. In Proceedings of ACL-05.
L. Rigutini, M. Maggini and B. Liu. 2005. An EM
based training algorithm for cross-language text
categorization. In Proceedings of WI-05.
A. Sarkar. 2001. Applying cotraining methods to sta-
tistical parsing. In Proceedings of NAACL-2001.
I. Titov and R. McDonald. 2008. A joint model of text
and aspect ratings for sentiment summarization. In
Proceedings of ACL-08:HLT.
B. K. Y. Tsou, R. W. M. Yuen, O. Y. Kwong, T. B. Y.
La and W. L. Wong. 2005. Polarity classification
of celebrity coverage in the Chinese press. In Pro-
ceedings of International Conference on Intelli-
gence Analysis.
P. Turney. 2002. Thumbs up or thumbs down? seman-
tic orientation applied to unsupervised classifica-
tion of reviews. In Proceedings of ACL-2002.
X. Wan. 2008. Using bilingual knowledge and en-
semble techniques for unsupervised Chinese sen-
timent analysis. In Proceedings of EMNLP-2008.
T. Wilson, J. Wiebe and P. Hoffmann. 2005. Recog-
nizing Contextual Polarity in Phrase-Level Senti-
ment Analysis. In Proceedings of HLT/EMNLP-05.
G.-R. Xue, W. Dai, Q. Yang, Y. Yu. 2008. Topic-
bridged PLSA for cross-domain text classification.
In Proceedings of SIGIR-08.
Q. Ye, W. Shi and Y. Li. 2006. Sentiment classifica-
tion for movie reviews in Chinese by improved
semantic oriented approach. In Proceedings of 39th
Hawaii International Conference on System Sci-
ences, 2006.
</reference>
<page confidence="0.999053">
243
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.292916">
<title confidence="0.999905">Co-Training for Cross-Lingual Sentiment Classification</title>
<author confidence="0.999711">Xiaojun Wan</author>
<affiliation confidence="0.800513">of Compute Science and Technology &amp; Key Laboratory of Computational guistics, MOE</affiliation>
<address confidence="0.602647">Peking University, Beijing 100871, China</address>
<email confidence="0.983759">wanxiaojun@icst.pku.edu.cn</email>
<abstract confidence="0.998111">The lack of Chinese sentiment corpora limits the research progress on Chinese sentiment classification. However, there are many freely available English sentiment corpora on the Web. This paper focuses on the problem of cross-lingual sentiment classification, which leverages an available English corpus for Chinese sentiment classification by using the English corpus as training data. Machine translation services are used for eliminating the language gap between the training set and test set, and English features and Chinese features are considered as two independent views of the classification problem. We propose a cotraining approach to making use of unlabeled Chinese data. Experimental results show the effectiveness of the proposed approach, which can outperform the standard inductive classifiers and the transductive classifiers.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Andreevskaia</author>
<author>S Bergler</author>
</authors>
<title>When specialists and generalists work together: overcoming domain dependence in sentiment tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT.</booktitle>
<contexts>
<context position="6339" citStr="Andreevskaia and Bergler (2008)" startWordPosition="958" endWordPosition="961">ification task and they use a labeled corpus to train a sentiment classifier. Since the work of Pang et al. (2002), various classification models and linguistic features have been proposed to improve the classification performance (Pang and Lee, 2004; Mullen and Collier, 2004; Wilson et al., 2005; Read, 2005). Most recently, McDonald et al. (2007) investigate a structured model for jointly classifying the sentiment of text at varying levels of granularity. Blitzer et al. (2007) investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. Andreevskaia and Bergler (2008) present a new system consisting of the ensemble of a corpus-based classifier and a lexicon-based classifier with precision-based vote weighting. Chinese sentiment analysis has also been studied (Tsou et al., 2005; Ye et al., 2006; Li and Sun, 2007) and most such work uses similar lexiconbased or corpus-based methods for Chinese sentiment classification. To date, several pilot studies have been performed to leverage rich English resources for sentiment analysis in other languages. Standard Naïve Bayes and SVM classifiers have been applied for subjectivity classification in Romanian (Mihalcea e</context>
</contexts>
<marker>Andreevskaia, Bergler, 2008</marker>
<rawString>A. Andreevskaia and S. Bergler. 2008. When specialists and generalists work together: overcoming domain dependence in sentiment tagging. In Proceedings of ACL-08: HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Banea</author>
<author>R Mihalcea</author>
<author>J Wiebe</author>
<author>S Hassan</author>
</authors>
<title>Multilingual subjectivity analysis using machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP-2008.</booktitle>
<contexts>
<context position="2866" citStr="Banea et al., 2008" startWordPosition="419" endWordPosition="422">e rich English corpora for Chinese sentiment classification. In this study, we focus on the problem of cross-lingual sentiment classification, which leverages only English training data for supervised sentiment classification of Chinese product reviews, without using any Chinese resources. Note that the above problem is not only defined for Chinese sentiment classification, but also for various sentiment analysis tasks in other different languages. Though pilot studies have been performed to make use of English corpora for subjectivity classification in other languages (Mihalcea et al., 2007; Banea et al., 2008), the methods are very straightforward by directly employing an inductive classifier (e.g. SVM, NB), and the classification performance is far from satisfactory because of the language gap between the original language and the translated language. In this study, we propose a co-training approach to improving the classification accuracy of polarity identification of Chinese product reviews. Unlabeled Chinese reviews can be fully leveraged in the proposed approach. First, machine translation services are used to translate English training reviews into Chinese reviews and also translate Chinese t</context>
<context position="6971" citStr="Banea et al., 2008" startWordPosition="1059" endWordPosition="1062">w system consisting of the ensemble of a corpus-based classifier and a lexicon-based classifier with precision-based vote weighting. Chinese sentiment analysis has also been studied (Tsou et al., 2005; Ye et al., 2006; Li and Sun, 2007) and most such work uses similar lexiconbased or corpus-based methods for Chinese sentiment classification. To date, several pilot studies have been performed to leverage rich English resources for sentiment analysis in other languages. Standard Naïve Bayes and SVM classifiers have been applied for subjectivity classification in Romanian (Mihalcea et al., 2007; Banea et al., 2008), and the results show that automatic translation is a viable alternative for the construction of resources and tools for subjectivity analysis in a new target language. Wan (2008) focuses on leveraging both Chinese and English lexicons to improve Chinese sentiment analysis by using lexicon-based methods. In this study, we focus on improving the corpus-based method for crosslingual sentiment classification of Chinese product reviews by developing novel approaches. 2.2 Cross-Domain Text Classification Cross-domain text classification can be considered as a more general task than cross-lingual s</context>
<context position="9881" citStr="Banea et al., 2008" startWordPosition="1504" endWordPosition="1507">en the labeled English reviews and unlabeled Chinese reviews, two straightforward methods for addressing the problem are as follows: 1) We first learn a classifier based on the labeled English reviews, and then translate Chinese reviews into English reviews. Lastly, we use the classifier to classify the translated English reviews. 2) We first translate the labeled English reviews into Chinese reviews, and then learn a classifier based on the translated Chinese reviews with labels. Lastly, we use the classifier to classify the unlabeled Chinese reviews. The above two methods have been used in (Banea et al., 2008) for Romanian subjectivity analysis, but the experimental results are not very promising. As shown in our experiments, the above two methods do not perform well for Chinese sentiment classification, either, because the underlying distribution between the original language and the translated language are different. In order to address the above problem, we propose to use the co-training approach to make use of some amounts of unlabeled Chinese reviews to improve the classification accuracy. The co-training approach can make full use of both the English features and the Chinese features in a uni</context>
</contexts>
<marker>Banea, Mihalcea, Wiebe, Hassan, 2008</marker>
<rawString>C. Banea, R. Mihalcea, J. Wiebe and S. Hassan. 2008. Multilingual subjectivity analysis using machine translation. In Proceedings of EMNLP-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Bel</author>
<author>C H A Koster</author>
<author>M Villegas</author>
</authors>
<title>Cross-lingual text categorization.</title>
<date>2003</date>
<booktitle>In Proceedings of ECDL-03.</booktitle>
<contexts>
<context position="8604" citStr="Bel et al. (2003)" startWordPosition="1296" endWordPosition="1299"> transferring knowledge across domains, including Transductive SVM (Joachims, 1999), EM(Nigam et al., 2000), EM-based Naïve Bayes classifier (Dai et al., 2007a), Topic-bridged PLSA (Xue et al., 2008), Co-Clustering based classification (Dai et al., 2007b), two-stage approach (Jiang and Zhai, 2007). DauméIII and Marcu (2006) introduce a statistical formulation of this problem in terms of a simple mixture model. In particular, several previous studies focus on the problem of cross-lingual text classification, which can be considered as a special case of general cross-domain text classification. Bel et al. (2003) present practical and cost-effective solutions. A few novel models have been proposed to address the problem, e.g. the EM-based algorithm (Rigutini et al., 2005), the information bottleneck approach (Ling et al., 2008), the multilingual domain models (Gliozzo and Strapparava, 2005), etc. To the best of our knowledge, cotraining has not yet been investigated for crossdomain or cross-lingual text classification. 236 3 The Co-Training Approach 3.1 Overview The purpose of our approach is to make use of the annotated English corpus for sentiment polarity identification of Chinese reviews in a supe</context>
</contexts>
<marker>Bel, Koster, Villegas, 2003</marker>
<rawString>N. Bel, C. H. A. Koster, and M. Villegas. 2003. Cross-lingual text categorization. In Proceedings of ECDL-03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Blitzer</author>
<author>M Dredze</author>
<author>F Pereira</author>
</authors>
<title>Biographies, bollywood, boom-boxes and blenders: domain adaptation for sentiment classification.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL-07.</booktitle>
<contexts>
<context position="6190" citStr="Blitzer et al. (2007)" startWordPosition="936" endWordPosition="939">etric of positive or negative polarity in financial news text. Corpus-based methods usually consider the sentiment analysis task as a classification task and they use a labeled corpus to train a sentiment classifier. Since the work of Pang et al. (2002), various classification models and linguistic features have been proposed to improve the classification performance (Pang and Lee, 2004; Mullen and Collier, 2004; Wilson et al., 2005; Read, 2005). Most recently, McDonald et al. (2007) investigate a structured model for jointly classifying the sentiment of text at varying levels of granularity. Blitzer et al. (2007) investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. Andreevskaia and Bergler (2008) present a new system consisting of the ensemble of a corpus-based classifier and a lexicon-based classifier with precision-based vote weighting. Chinese sentiment analysis has also been studied (Tsou et al., 2005; Ye et al., 2006; Li and Sun, 2007) and most such work uses similar lexiconbased or corpus-based methods for Chinese sentiment classification. To date, several pilot studies have been performed to leverage rich English resources for sent</context>
<context position="18267" citStr="Blitzer et al., 2007" startWordPosition="2829" endWordPosition="2832"> set The following three datasets were collected and used in the experiments: Test Set (Labeled Chinese Reviews): In order to assess the performance of the proposed approach, we collected and labeled 886 product reviews (451 positive reviews + 435 negative reviews) from a popular Chinese IT product web site-IT1688. The reviews focused on such products as mp3 players, mobile phones, digital camera and laptop computers. Training Set (Labeled English Reviews): There are many labeled English corpora available on the Web and we used the corpus constructed for multi-domain sentiment classification (Blitzer et al., 2007)9, because the corpus was large-scale and it was within similar domains as the test set. The dataset consisted of 8000 Amazon product reviews (4000 positive reviews + 4000 negative reviews) for four different product types: books, DVDs, electronics and kitchen appliances. Unlabeled Set (Unlabeled Chinese Reviews): We downloaded additional 1000 Chinese product reviews from IT168 and used the reviews as the unlabeled set. Therefore, the unlabeled set and the test set were in the same domain and had similar underlying feature distributions. Each Chinese review was translated into English review, </context>
</contexts>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>J. Blitzer, M. Dredze and F. Pereira. 2007. Biographies, bollywood, boom-boxes and blenders: domain adaptation for sentiment classification. In Proceedings of ACL-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Blum</author>
<author>T Mitchell</author>
</authors>
<title>Combining labeled and unlabeled data with cotraining.</title>
<date>1998</date>
<booktitle>In Proceedings of COLT-98.</booktitle>
<contexts>
<context position="13239" citStr="Blum and Mitchell, 1998" startWordPosition="1991" endWordPosition="1994">e Unlabeled English Reviews Labeled English Reviews Pos\Neg Figure 1. Framework of the proposed approach 237 In this study, we adopt Google Translate for both English-to-Chinese Translation and Chinese-toEnglish Translation, because it is one of the state-of-the-art commercial machine translation systems used today. Google Translate applies statistical learning techniques to build a translation model based on both monolingual text in the target language and aligned text consisting of examples of human translations between the languages. 3.3 The Co-Training Algorithm The co-training algorithm (Blum and Mitchell, 1998) is a typical bootstrapping method, which starts with a set of labeled data, and increase the amount of annotated data using some amounts of unlabeled data in an incremental way. One important aspect of co-training is that two conditional independent views are required for cotraining to work, but the independence assumption can be relaxed. Till now, co-training has been successfully applied to statistical parsing (Sarkar, 2001), reference resolution (Ng and Cardie, 2003), part of speech tagging (Clark et al., 2003), word sense disambiguation (Mihalcea, 2004) and email classification (Kiritchen</context>
</contexts>
<marker>Blum, Mitchell, 1998</marker>
<rawString>A. Blum and T. Mitchell. 1998. Combining labeled and unlabeled data with cotraining. In Proceedings of COLT-98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brody</author>
<author>R Navigli</author>
<author>M Lapata</author>
</authors>
<title>Ensemble methods for unsupervised WSD.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL-2006.</booktitle>
<marker>Brody, Navigli, Lapata, 2006</marker>
<rawString>S. Brody, R. Navigli and M. Lapata. 2006. Ensemble methods for unsupervised WSD. In Proceedings of COLING-ACL-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Clark</author>
<author>J R Curran</author>
<author>M Osborne</author>
</authors>
<title>Bootstrapping POS taggers using unlabelled data.</title>
<date>2003</date>
<booktitle>In Proceedings of CoNLL-2003.</booktitle>
<contexts>
<context position="13759" citStr="Clark et al., 2003" startWordPosition="2075" endWordPosition="2078">en the languages. 3.3 The Co-Training Algorithm The co-training algorithm (Blum and Mitchell, 1998) is a typical bootstrapping method, which starts with a set of labeled data, and increase the amount of annotated data using some amounts of unlabeled data in an incremental way. One important aspect of co-training is that two conditional independent views are required for cotraining to work, but the independence assumption can be relaxed. Till now, co-training has been successfully applied to statistical parsing (Sarkar, 2001), reference resolution (Ng and Cardie, 2003), part of speech tagging (Clark et al., 2003), word sense disambiguation (Mihalcea, 2004) and email classification (Kiritchenko and Matwin, 2001). In the context of cross-lingual sentiment classification, each labeled English review or unlabeled Chinese review has two views of features: English features and Chinese features. Here, a review is used to indicate both its Chinese version and its English version, until stated otherwise. The co-training algorithm is illustrated in Figure 2. In the algorithm, the class distribution in the labeled data is maintained by balancing the parameter values of p and n at each iteration. The intuition of</context>
</contexts>
<marker>Clark, Curran, Osborne, 2003</marker>
<rawString>S. Clark, J. R. Curran, and M. Osborne. 2003. Bootstrapping POS taggers using unlabelled data. In Proceedings of CoNLL-2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Dai</author>
<author>G-R Xue</author>
<author>Q Yang</author>
<author>Y Yu</author>
</authors>
<title>Transferring Naïve Bayes Classifiers for text classification.</title>
<date>2007</date>
<booktitle>In Proceedings of AAAI-07.</booktitle>
<contexts>
<context position="8145" citStr="Dai et al., 2007" startWordPosition="1228" endWordPosition="1231">s a more general task than cross-lingual sentiment classification. In the problem of crossdomain text classification, the labeled and unlabeled data come from different domains, and their underlying distributions are often different from each other, which violates the basic assumption of traditional classification learning. To date, many semi-supervised learning algorithms have been developed for addressing the cross-domain text classification problem by transferring knowledge across domains, including Transductive SVM (Joachims, 1999), EM(Nigam et al., 2000), EM-based Naïve Bayes classifier (Dai et al., 2007a), Topic-bridged PLSA (Xue et al., 2008), Co-Clustering based classification (Dai et al., 2007b), two-stage approach (Jiang and Zhai, 2007). DauméIII and Marcu (2006) introduce a statistical formulation of this problem in terms of a simple mixture model. In particular, several previous studies focus on the problem of cross-lingual text classification, which can be considered as a special case of general cross-domain text classification. Bel et al. (2003) present practical and cost-effective solutions. A few novel models have been proposed to address the problem, e.g. the EM-based algorithm (R</context>
</contexts>
<marker>Dai, Xue, Yang, Yu, 2007</marker>
<rawString>W. Dai, G.-R. Xue, Q. Yang, Y. Yu. 2007a. Transferring Naïve Bayes Classifiers for text classification. In Proceedings of AAAI-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Dai</author>
<author>G-R Xue</author>
<author>Q Yang</author>
<author>Y Yu</author>
</authors>
<title>Coclustering based classification for out-of-domain documents.</title>
<date>2007</date>
<booktitle>In Proceedings of KDD-07.</booktitle>
<contexts>
<context position="8145" citStr="Dai et al., 2007" startWordPosition="1228" endWordPosition="1231">s a more general task than cross-lingual sentiment classification. In the problem of crossdomain text classification, the labeled and unlabeled data come from different domains, and their underlying distributions are often different from each other, which violates the basic assumption of traditional classification learning. To date, many semi-supervised learning algorithms have been developed for addressing the cross-domain text classification problem by transferring knowledge across domains, including Transductive SVM (Joachims, 1999), EM(Nigam et al., 2000), EM-based Naïve Bayes classifier (Dai et al., 2007a), Topic-bridged PLSA (Xue et al., 2008), Co-Clustering based classification (Dai et al., 2007b), two-stage approach (Jiang and Zhai, 2007). DauméIII and Marcu (2006) introduce a statistical formulation of this problem in terms of a simple mixture model. In particular, several previous studies focus on the problem of cross-lingual text classification, which can be considered as a special case of general cross-domain text classification. Bel et al. (2003) present practical and cost-effective solutions. A few novel models have been proposed to address the problem, e.g. the EM-based algorithm (R</context>
</contexts>
<marker>Dai, Xue, Yang, Yu, 2007</marker>
<rawString>W. Dai, G.-R. Xue, Q. Yang, Y. Yu. 2007b. Coclustering based classification for out-of-domain documents. In Proceedings of KDD-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H DauméIII</author>
<author>D Marcu</author>
</authors>
<title>Domain adaptation for statistical classifiers.</title>
<date>2006</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>26--101</pages>
<contexts>
<context position="8312" citStr="DauméIII and Marcu (2006)" startWordPosition="1252" endWordPosition="1255"> different domains, and their underlying distributions are often different from each other, which violates the basic assumption of traditional classification learning. To date, many semi-supervised learning algorithms have been developed for addressing the cross-domain text classification problem by transferring knowledge across domains, including Transductive SVM (Joachims, 1999), EM(Nigam et al., 2000), EM-based Naïve Bayes classifier (Dai et al., 2007a), Topic-bridged PLSA (Xue et al., 2008), Co-Clustering based classification (Dai et al., 2007b), two-stage approach (Jiang and Zhai, 2007). DauméIII and Marcu (2006) introduce a statistical formulation of this problem in terms of a simple mixture model. In particular, several previous studies focus on the problem of cross-lingual text classification, which can be considered as a special case of general cross-domain text classification. Bel et al. (2003) present practical and cost-effective solutions. A few novel models have been proposed to address the problem, e.g. the EM-based algorithm (Rigutini et al., 2005), the information bottleneck approach (Ling et al., 2008), the multilingual domain models (Gliozzo and Strapparava, 2005), etc. To the best of our</context>
</contexts>
<marker>DauméIII, Marcu, 2006</marker>
<rawString>H. DauméIII and D. Marcu. 2006. Domain adaptation for statistical classifiers. Journal of Artificial Intelligence Research, 26:101–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Devitt</author>
<author>K Ahmad</author>
</authors>
<title>Sentiment polarity identification in financial news: a cohesion-based approach.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL2007.</booktitle>
<contexts>
<context position="5546" citStr="Devitt and Ahmad (2007)" startWordPosition="835" endWordPosition="838">phrases in the review that contain adjectives or adverbs, which is denoted as the semantic oriented method. Kim and Hovy (2004) build three models to assign a sentiment category to a given sentence by combining the individual sentiments of sentimentbearing words. Hiroshi et al. (2004) use the technique of deep language analysis for machine translation to extract sentiment units in text documents. Kennedy and Inkpen (2006) determine the sentiment of a customer review by counting positive and negative terms and taking into account contextual valence shifters, such as negations and intensifiers. Devitt and Ahmad (2007) explore a computable metric of positive or negative polarity in financial news text. Corpus-based methods usually consider the sentiment analysis task as a classification task and they use a labeled corpus to train a sentiment classifier. Since the work of Pang et al. (2002), various classification models and linguistic features have been proposed to improve the classification performance (Pang and Lee, 2004; Mullen and Collier, 2004; Wilson et al., 2005; Read, 2005). Most recently, McDonald et al. (2007) investigate a structured model for jointly classifying the sentiment of text at varying </context>
</contexts>
<marker>Devitt, Ahmad, 2007</marker>
<rawString>A. Devitt and K. Ahmad. 2007. Sentiment polarity identification in financial news: a cohesion-based approach. In Proceedings of ACL2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T G Dietterich</author>
</authors>
<title>Machine learning research: four current directions.</title>
<date>1997</date>
<journal>AI Magazine,</journal>
<volume>18</volume>
<issue>4</issue>
<marker>Dietterich, 1997</marker>
<rawString>T. G. Dietterich. 1997. Machine learning research: four current directions. AI Magazine, 18(4), 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gliozzo</author>
<author>C Strapparava</author>
</authors>
<title>Cross language text categorization by acquiring multilingual domain models from comparable corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Building and Using Parallel Texts.</booktitle>
<contexts>
<context position="8887" citStr="Gliozzo and Strapparava, 2005" startWordPosition="1340" endWordPosition="1343">roach (Jiang and Zhai, 2007). DauméIII and Marcu (2006) introduce a statistical formulation of this problem in terms of a simple mixture model. In particular, several previous studies focus on the problem of cross-lingual text classification, which can be considered as a special case of general cross-domain text classification. Bel et al. (2003) present practical and cost-effective solutions. A few novel models have been proposed to address the problem, e.g. the EM-based algorithm (Rigutini et al., 2005), the information bottleneck approach (Ling et al., 2008), the multilingual domain models (Gliozzo and Strapparava, 2005), etc. To the best of our knowledge, cotraining has not yet been investigated for crossdomain or cross-lingual text classification. 236 3 The Co-Training Approach 3.1 Overview The purpose of our approach is to make use of the annotated English corpus for sentiment polarity identification of Chinese reviews in a supervised framework, without using any Chinese resources. Given the labeled English reviews and unlabeled Chinese reviews, two straightforward methods for addressing the problem are as follows: 1) We first learn a classifier based on the labeled English reviews, and then translate Chin</context>
</contexts>
<marker>Gliozzo, Strapparava, 2005</marker>
<rawString>A. Gliozzo and C. Strapparava. 2005. Cross language text categorization by acquiring multilingual domain models from comparable corpora. In Proceedings of the ACL Workshop on Building and Using Parallel Texts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hiroshi</author>
<author>N Tetsuya</author>
<author>W Hideo</author>
</authors>
<title>Deeper sentiment analysis using machine translation technology.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING-04.</booktitle>
<contexts>
<context position="5208" citStr="Hiroshi et al. (2004)" startWordPosition="783" endWordPosition="786">ication. The methods for document sentiment classification can be generally categorized into lexicon-based and corpus-based. Lexicon-based methods usually involve deriving a sentiment measure for text based on sentiment lexicons. Turney (2002) predicates the sentiment orientation of a review by the average semantic orientation of the phrases in the review that contain adjectives or adverbs, which is denoted as the semantic oriented method. Kim and Hovy (2004) build three models to assign a sentiment category to a given sentence by combining the individual sentiments of sentimentbearing words. Hiroshi et al. (2004) use the technique of deep language analysis for machine translation to extract sentiment units in text documents. Kennedy and Inkpen (2006) determine the sentiment of a customer review by counting positive and negative terms and taking into account contextual valence shifters, such as negations and intensifiers. Devitt and Ahmad (2007) explore a computable metric of positive or negative polarity in financial news text. Corpus-based methods usually consider the sentiment analysis task as a classification task and they use a labeled corpus to train a sentiment classifier. Since the work of Pang</context>
</contexts>
<marker>Hiroshi, Tetsuya, Hideo, 2004</marker>
<rawString>K. Hiroshi, N. Tetsuya and W. Hideo. 2004. Deeper sentiment analysis using machine translation technology. In Proceedings of COLING-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jiang</author>
<author>C Zhai</author>
</authors>
<title>A two-stage approach to domain adaptation for statistical classifiers.</title>
<date>2007</date>
<booktitle>In Proceedings of CIKM-07.</booktitle>
<contexts>
<context position="8285" citStr="Jiang and Zhai, 2007" startWordPosition="1248" endWordPosition="1251">nlabeled data come from different domains, and their underlying distributions are often different from each other, which violates the basic assumption of traditional classification learning. To date, many semi-supervised learning algorithms have been developed for addressing the cross-domain text classification problem by transferring knowledge across domains, including Transductive SVM (Joachims, 1999), EM(Nigam et al., 2000), EM-based Naïve Bayes classifier (Dai et al., 2007a), Topic-bridged PLSA (Xue et al., 2008), Co-Clustering based classification (Dai et al., 2007b), two-stage approach (Jiang and Zhai, 2007). DauméIII and Marcu (2006) introduce a statistical formulation of this problem in terms of a simple mixture model. In particular, several previous studies focus on the problem of cross-lingual text classification, which can be considered as a special case of general cross-domain text classification. Bel et al. (2003) present practical and cost-effective solutions. A few novel models have been proposed to address the problem, e.g. the EM-based algorithm (Rigutini et al., 2005), the information bottleneck approach (Ling et al., 2008), the multilingual domain models (Gliozzo and Strapparava, 200</context>
</contexts>
<marker>Jiang, Zhai, 2007</marker>
<rawString>J. Jiang and C. Zhai. 2007. A two-stage approach to domain adaptation for statistical classifiers. In Proceedings of CIKM-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Transductive inference for text classification using support vector machines.</title>
<date>1999</date>
<booktitle>In Proceedings of ICML-99.</booktitle>
<contexts>
<context position="8070" citStr="Joachims, 1999" startWordPosition="1218" endWordPosition="1219">n Text Classification Cross-domain text classification can be considered as a more general task than cross-lingual sentiment classification. In the problem of crossdomain text classification, the labeled and unlabeled data come from different domains, and their underlying distributions are often different from each other, which violates the basic assumption of traditional classification learning. To date, many semi-supervised learning algorithms have been developed for addressing the cross-domain text classification problem by transferring knowledge across domains, including Transductive SVM (Joachims, 1999), EM(Nigam et al., 2000), EM-based Naïve Bayes classifier (Dai et al., 2007a), Topic-bridged PLSA (Xue et al., 2008), Co-Clustering based classification (Dai et al., 2007b), two-stage approach (Jiang and Zhai, 2007). DauméIII and Marcu (2006) introduce a statistical formulation of this problem in terms of a simple mixture model. In particular, several previous studies focus on the problem of cross-lingual text classification, which can be considered as a special case of general cross-domain text classification. Bel et al. (2003) present practical and cost-effective solutions. A few novel model</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>T. Joachims. 1999. Transductive inference for text classification using support vector machines. In Proceedings of ICML-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Learning to classify text using support vector machines.</title>
<date>2002</date>
<publisher>Dissertation, Kluwer,</publisher>
<contexts>
<context position="15184" citStr="Joachims, 2002" startWordPosition="2307" endWordPosition="2308">fier. But, of course, if this example happens to be easy to be classified by the first classifier, it does not mean that this example will be easy to be classified by the second classifier, so the second classifier will get useful information to improve itself and vice versa (Kiritchenko and Matwin, 2001). In the co-training algorithm, a basic classification algorithm is required to construct Cen and C,n. Typical text classifiers include Support Vector Machine (SVM), Naïve Bayes (NB), Maximum Entropy (ME), K-Nearest Neighbor (KNN) , etc. In this study, we adopt the widely-used SVM classifier (Joachims, 2002). Viewing input data as two sets of vectors in a feature space, SVM constructs a separating hyperplane in the space by maximizing the margin between the two data sets. The English or Chinese features used in this study include both unigrams and bigrams5 and the feature weight is simply set to term frequency6. Feature selection methods (e.g. Document Frequency (DF), Information Gain (IG), and Mutual Information (MI)) can be used for dimension reduction. But we use all the features in the experiments for comparative analysis, because there is no significant performance improvement after applying</context>
</contexts>
<marker>Joachims, 2002</marker>
<rawString>T. Joachims. 2002. Learning to classify text using support vector machines. Dissertation, Kluwer, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kennedy</author>
<author>D Inkpen</author>
</authors>
<title>Sentiment classification of movie reviews using contextual valence shifters.</title>
<date>2006</date>
<journal>Computational Intelligence,</journal>
<pages>22--2</pages>
<contexts>
<context position="5348" citStr="Kennedy and Inkpen (2006)" startWordPosition="805" endWordPosition="808">ed methods usually involve deriving a sentiment measure for text based on sentiment lexicons. Turney (2002) predicates the sentiment orientation of a review by the average semantic orientation of the phrases in the review that contain adjectives or adverbs, which is denoted as the semantic oriented method. Kim and Hovy (2004) build three models to assign a sentiment category to a given sentence by combining the individual sentiments of sentimentbearing words. Hiroshi et al. (2004) use the technique of deep language analysis for machine translation to extract sentiment units in text documents. Kennedy and Inkpen (2006) determine the sentiment of a customer review by counting positive and negative terms and taking into account contextual valence shifters, such as negations and intensifiers. Devitt and Ahmad (2007) explore a computable metric of positive or negative polarity in financial news text. Corpus-based methods usually consider the sentiment analysis task as a classification task and they use a labeled corpus to train a sentiment classifier. Since the work of Pang et al. (2002), various classification models and linguistic features have been proposed to improve the classification performance (Pang and</context>
</contexts>
<marker>Kennedy, Inkpen, 2006</marker>
<rawString>A. Kennedy and D. Inkpen. 2006. Sentiment classification of movie reviews using contextual valence shifters. Computational Intelligence, 22(2):110-125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S-M Kim</author>
<author>E Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING-04.</booktitle>
<contexts>
<context position="5050" citStr="Kim and Hovy (2004)" startWordPosition="756" endWordPosition="759">.1 Sentiment Classification Sentiment classification can be performed on words, sentences or documents. In this paper we focus on document sentiment classification. The methods for document sentiment classification can be generally categorized into lexicon-based and corpus-based. Lexicon-based methods usually involve deriving a sentiment measure for text based on sentiment lexicons. Turney (2002) predicates the sentiment orientation of a review by the average semantic orientation of the phrases in the review that contain adjectives or adverbs, which is denoted as the semantic oriented method. Kim and Hovy (2004) build three models to assign a sentiment category to a given sentence by combining the individual sentiments of sentimentbearing words. Hiroshi et al. (2004) use the technique of deep language analysis for machine translation to extract sentiment units in text documents. Kennedy and Inkpen (2006) determine the sentiment of a customer review by counting positive and negative terms and taking into account contextual valence shifters, such as negations and intensifiers. Devitt and Ahmad (2007) explore a computable metric of positive or negative polarity in financial news text. Corpus-based metho</context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>S.-M. Kim and E. Hovy. 2004. Determining the sentiment of opinions. In Proceedings of COLING-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kiritchenko</author>
<author>S Matwin</author>
</authors>
<title>Email classification with co-training.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2001 Conference of the Centre for Advanced Studies on Collaborative Research.</booktitle>
<contexts>
<context position="13859" citStr="Kiritchenko and Matwin, 2001" startWordPosition="2087" endWordPosition="2090">ll, 1998) is a typical bootstrapping method, which starts with a set of labeled data, and increase the amount of annotated data using some amounts of unlabeled data in an incremental way. One important aspect of co-training is that two conditional independent views are required for cotraining to work, but the independence assumption can be relaxed. Till now, co-training has been successfully applied to statistical parsing (Sarkar, 2001), reference resolution (Ng and Cardie, 2003), part of speech tagging (Clark et al., 2003), word sense disambiguation (Mihalcea, 2004) and email classification (Kiritchenko and Matwin, 2001). In the context of cross-lingual sentiment classification, each labeled English review or unlabeled Chinese review has two views of features: English features and Chinese features. Here, a review is used to indicate both its Chinese version and its English version, until stated otherwise. The co-training algorithm is illustrated in Figure 2. In the algorithm, the class distribution in the labeled data is maintained by balancing the parameter values of p and n at each iteration. The intuition of the co-training algorithm is that if one classifier can confidently predict the class of an example</context>
</contexts>
<marker>Kiritchenko, Matwin, 2001</marker>
<rawString>S. Kiritchenko and S. Matwin. 2001. Email classification with co-training. In Proceedings of the 2001 Conference of the Centre for Advanced Studies on Collaborative Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L-W Ku</author>
<author>Y-T Liang</author>
<author>H-H Chen</author>
</authors>
<title>Opinion extraction, summarization and tracking in news and blog corpora.</title>
<date>2006</date>
<booktitle>In Proceedings of AAAI-2006.</booktitle>
<contexts>
<context position="1487" citStr="Ku et al., 2006" startWordPosition="216" endWordPosition="219"> approach to making use of unlabeled Chinese data. Experimental results show the effectiveness of the proposed approach, which can outperform the standard inductive classifiers and the transductive classifiers. 1 Introduction Sentiment classification is the task of identifying the sentiment polarity of a given text. The sentiment polarity is usually positive or negative and the text genre is usually product review. In recent years, sentiment classification has drawn much attention in the NLP field and it has many useful applications, such as opinion mining and summarization (Liu et al., 2005; Ku et al., 2006; Titov and McDonald, 2008). To date, a variety of corpus-based methods have been developed for sentiment classification. The methods usually rely heavily on an annotated corpus for training the sentiment classifier. The sentiment corpora are considered as the most valuable resources for the sentiment classification task. However, such resources in different languages are very imbalanced. Because most previous work focuses on English sentiment classification, many annotated corpora for English sentiment classification are freely available on the Web. However, the annotated corpora for Chinese </context>
</contexts>
<marker>Ku, Liang, Chen, 2006</marker>
<rawString>L.-W. Ku, Y.-T. Liang and H.-H. Chen. 2006. Opinion extraction, summarization and tracking in news and blog corpora. In Proceedings of AAAI-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Li</author>
<author>M Sun</author>
</authors>
<title>Experimental study on sentiment classification of Chinese review using machine learning techniques.</title>
<date>2007</date>
<booktitle>In Proceeding of IEEENLPKE-07.</booktitle>
<contexts>
<context position="6588" citStr="Li and Sun, 2007" startWordPosition="1000" endWordPosition="1003">Collier, 2004; Wilson et al., 2005; Read, 2005). Most recently, McDonald et al. (2007) investigate a structured model for jointly classifying the sentiment of text at varying levels of granularity. Blitzer et al. (2007) investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. Andreevskaia and Bergler (2008) present a new system consisting of the ensemble of a corpus-based classifier and a lexicon-based classifier with precision-based vote weighting. Chinese sentiment analysis has also been studied (Tsou et al., 2005; Ye et al., 2006; Li and Sun, 2007) and most such work uses similar lexiconbased or corpus-based methods for Chinese sentiment classification. To date, several pilot studies have been performed to leverage rich English resources for sentiment analysis in other languages. Standard Naïve Bayes and SVM classifiers have been applied for subjectivity classification in Romanian (Mihalcea et al., 2007; Banea et al., 2008), and the results show that automatic translation is a viable alternative for the construction of resources and tools for subjectivity analysis in a new target language. Wan (2008) focuses on leveraging both Chinese a</context>
</contexts>
<marker>Li, Sun, 2007</marker>
<rawString>J. Li and M. Sun. 2007. Experimental study on sentiment classification of Chinese review using machine learning techniques. In Proceeding of IEEENLPKE-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Ling</author>
<author>W Dai</author>
<author>Y Jiang</author>
<author>G-R Xue</author>
<author>Q Yang</author>
<author>Y Yu</author>
</authors>
<title>Can Chinese Web pages be classified with English data source?</title>
<date>2008</date>
<booktitle>In Proceedings of WWW-08.</booktitle>
<contexts>
<context position="8823" citStr="Ling et al., 2008" startWordPosition="1331" endWordPosition="1334">ed classification (Dai et al., 2007b), two-stage approach (Jiang and Zhai, 2007). DauméIII and Marcu (2006) introduce a statistical formulation of this problem in terms of a simple mixture model. In particular, several previous studies focus on the problem of cross-lingual text classification, which can be considered as a special case of general cross-domain text classification. Bel et al. (2003) present practical and cost-effective solutions. A few novel models have been proposed to address the problem, e.g. the EM-based algorithm (Rigutini et al., 2005), the information bottleneck approach (Ling et al., 2008), the multilingual domain models (Gliozzo and Strapparava, 2005), etc. To the best of our knowledge, cotraining has not yet been investigated for crossdomain or cross-lingual text classification. 236 3 The Co-Training Approach 3.1 Overview The purpose of our approach is to make use of the annotated English corpus for sentiment polarity identification of Chinese reviews in a supervised framework, without using any Chinese resources. Given the labeled English reviews and unlabeled Chinese reviews, two straightforward methods for addressing the problem are as follows: 1) We first learn a classifi</context>
</contexts>
<marker>Ling, Dai, Jiang, Xue, Yang, Yu, 2008</marker>
<rawString>X. Ling, W. Dai, Y. Jiang, G.-R. Xue, Q. Yang, and Y. Yu. 2008. Can Chinese Web pages be classified with English data source? In Proceedings of WWW-08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Liu</author>
<author>M Hu</author>
<author>J Cheng</author>
</authors>
<title>Opinion observer: Analyzing and comparing opinions on the web.</title>
<date>2005</date>
<booktitle>In Proceedings of WWW-2005.</booktitle>
<contexts>
<context position="1470" citStr="Liu et al., 2005" startWordPosition="212" endWordPosition="215">opose a cotraining approach to making use of unlabeled Chinese data. Experimental results show the effectiveness of the proposed approach, which can outperform the standard inductive classifiers and the transductive classifiers. 1 Introduction Sentiment classification is the task of identifying the sentiment polarity of a given text. The sentiment polarity is usually positive or negative and the text genre is usually product review. In recent years, sentiment classification has drawn much attention in the NLP field and it has many useful applications, such as opinion mining and summarization (Liu et al., 2005; Ku et al., 2006; Titov and McDonald, 2008). To date, a variety of corpus-based methods have been developed for sentiment classification. The methods usually rely heavily on an annotated corpus for training the sentiment classifier. The sentiment corpora are considered as the most valuable resources for the sentiment classification task. However, such resources in different languages are very imbalanced. Because most previous work focuses on English sentiment classification, many annotated corpora for English sentiment classification are freely available on the Web. However, the annotated cor</context>
</contexts>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>B. Liu, M. Hu and J. Cheng. 2005. Opinion observer: Analyzing and comparing opinions on the web. In Proceedings of WWW-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Hannan</author>
<author>T Neylon</author>
<author>M Wells</author>
<author>J Reynar</author>
</authors>
<title>Structured models for fine-to-coarse sentiment analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL-07.</booktitle>
<contexts>
<context position="6057" citStr="McDonald et al. (2007)" startWordPosition="915" endWordPosition="918">nd taking into account contextual valence shifters, such as negations and intensifiers. Devitt and Ahmad (2007) explore a computable metric of positive or negative polarity in financial news text. Corpus-based methods usually consider the sentiment analysis task as a classification task and they use a labeled corpus to train a sentiment classifier. Since the work of Pang et al. (2002), various classification models and linguistic features have been proposed to improve the classification performance (Pang and Lee, 2004; Mullen and Collier, 2004; Wilson et al., 2005; Read, 2005). Most recently, McDonald et al. (2007) investigate a structured model for jointly classifying the sentiment of text at varying levels of granularity. Blitzer et al. (2007) investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. Andreevskaia and Bergler (2008) present a new system consisting of the ensemble of a corpus-based classifier and a lexicon-based classifier with precision-based vote weighting. Chinese sentiment analysis has also been studied (Tsou et al., 2005; Ye et al., 2006; Li and Sun, 2007) and most such work uses similar lexiconbased or corpus-based methods</context>
</contexts>
<marker>McDonald, Hannan, Neylon, Wells, Reynar, 2007</marker>
<rawString>R. McDonald, K. Hannan, T. Neylon, M. Wells and J. Reynar. 2007. Structured models for fine-to-coarse sentiment analysis. In Proceedings of ACL-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
</authors>
<title>Co-training and self-training for word sense disambiguation.</title>
<date>2004</date>
<booktitle>In Proceedings of CONLL-04.</booktitle>
<contexts>
<context position="13803" citStr="Mihalcea, 2004" startWordPosition="2082" endWordPosition="2083">The co-training algorithm (Blum and Mitchell, 1998) is a typical bootstrapping method, which starts with a set of labeled data, and increase the amount of annotated data using some amounts of unlabeled data in an incremental way. One important aspect of co-training is that two conditional independent views are required for cotraining to work, but the independence assumption can be relaxed. Till now, co-training has been successfully applied to statistical parsing (Sarkar, 2001), reference resolution (Ng and Cardie, 2003), part of speech tagging (Clark et al., 2003), word sense disambiguation (Mihalcea, 2004) and email classification (Kiritchenko and Matwin, 2001). In the context of cross-lingual sentiment classification, each labeled English review or unlabeled Chinese review has two views of features: English features and Chinese features. Here, a review is used to indicate both its Chinese version and its English version, until stated otherwise. The co-training algorithm is illustrated in Figure 2. In the algorithm, the class distribution in the labeled data is maintained by balancing the parameter values of p and n at each iteration. The intuition of the co-training algorithm is that if one cl</context>
<context position="27820" citStr="Mihalcea, 2004" startWordPosition="4344" endWordPosition="4345">the methods. It can be seen that the co-training approach can always outperform the two baselines with different feature sizes. The results further demonstrate the effectiveness and robustness of the proposed cotraining approach. 5 Conclusion and Future Work In this paper, we propose to use the co-training approach to address the problem of cross-lingual sentiment classification. The experimental results show the effectiveness of the proposed approach. In future work, we will improve the sentiment classification accuracy in the following two ways: 1) The smoothed co-training approach used in (Mihalcea, 2004) will be adopted for sentiment classification. The approach has the effect of “smoothing” the learning curves. During the bootstrapping process of smoothed co-training, the classifier at each iteration is replaced with a majority voting scheme applied to all classifiers constructed at previous iterations. 2) The feature distributions of the translated text and the natural text in the same language are still different due to the inaccuracy of the machine translation service. We will employ the structural correspondence learning (SCL) domain adaption algorithm used in (Blitzer et al., 2007) for </context>
</contexts>
<marker>Mihalcea, 2004</marker>
<rawString>R. Mihalcea. 2004. Co-training and self-training for word sense disambiguation. In Proceedings of CONLL-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>C Banea</author>
<author>J Wiebe</author>
</authors>
<title>Learning multilingual subjective language via cross-lingual projections.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL-2007.</booktitle>
<contexts>
<context position="2845" citStr="Mihalcea et al., 2007" startWordPosition="415" endWordPosition="418">re us is how to leverage rich English corpora for Chinese sentiment classification. In this study, we focus on the problem of cross-lingual sentiment classification, which leverages only English training data for supervised sentiment classification of Chinese product reviews, without using any Chinese resources. Note that the above problem is not only defined for Chinese sentiment classification, but also for various sentiment analysis tasks in other different languages. Though pilot studies have been performed to make use of English corpora for subjectivity classification in other languages (Mihalcea et al., 2007; Banea et al., 2008), the methods are very straightforward by directly employing an inductive classifier (e.g. SVM, NB), and the classification performance is far from satisfactory because of the language gap between the original language and the translated language. In this study, we propose a co-training approach to improving the classification accuracy of polarity identification of Chinese product reviews. Unlabeled Chinese reviews can be fully leveraged in the proposed approach. First, machine translation services are used to translate English training reviews into Chinese reviews and als</context>
<context position="6950" citStr="Mihalcea et al., 2007" startWordPosition="1055" endWordPosition="1058">ler (2008) present a new system consisting of the ensemble of a corpus-based classifier and a lexicon-based classifier with precision-based vote weighting. Chinese sentiment analysis has also been studied (Tsou et al., 2005; Ye et al., 2006; Li and Sun, 2007) and most such work uses similar lexiconbased or corpus-based methods for Chinese sentiment classification. To date, several pilot studies have been performed to leverage rich English resources for sentiment analysis in other languages. Standard Naïve Bayes and SVM classifiers have been applied for subjectivity classification in Romanian (Mihalcea et al., 2007; Banea et al., 2008), and the results show that automatic translation is a viable alternative for the construction of resources and tools for subjectivity analysis in a new target language. Wan (2008) focuses on leveraging both Chinese and English lexicons to improve Chinese sentiment analysis by using lexicon-based methods. In this study, we focus on improving the corpus-based method for crosslingual sentiment classification of Chinese product reviews by developing novel approaches. 2.2 Cross-Domain Text Classification Cross-domain text classification can be considered as a more general task</context>
</contexts>
<marker>Mihalcea, Banea, Wiebe, 2007</marker>
<rawString>R. Mihalcea, C. Banea and J. Wiebe. 2007. Learning multilingual subjective language via cross-lingual projections. In Proceedings of ACL-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mullen</author>
<author>N Collier</author>
</authors>
<title>Sentiment analysis using support vector machines with diverse information sources.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP-04.</booktitle>
<contexts>
<context position="5984" citStr="Mullen and Collier, 2004" startWordPosition="903" endWordPosition="906">he sentiment of a customer review by counting positive and negative terms and taking into account contextual valence shifters, such as negations and intensifiers. Devitt and Ahmad (2007) explore a computable metric of positive or negative polarity in financial news text. Corpus-based methods usually consider the sentiment analysis task as a classification task and they use a labeled corpus to train a sentiment classifier. Since the work of Pang et al. (2002), various classification models and linguistic features have been proposed to improve the classification performance (Pang and Lee, 2004; Mullen and Collier, 2004; Wilson et al., 2005; Read, 2005). Most recently, McDonald et al. (2007) investigate a structured model for jointly classifying the sentiment of text at varying levels of granularity. Blitzer et al. (2007) investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. Andreevskaia and Bergler (2008) present a new system consisting of the ensemble of a corpus-based classifier and a lexicon-based classifier with precision-based vote weighting. Chinese sentiment analysis has also been studied (Tsou et al., 2005; Ye et al., 2006; Li and Sun, 2</context>
</contexts>
<marker>Mullen, Collier, 2004</marker>
<rawString>T. Mullen and N. Collier. 2004. Sentiment analysis using support vector machines with diverse information sources. In Proceedings of EMNLP-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
<author>C Cardie</author>
</authors>
<title>Weakly supervised natural language learning without redundant views.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL-03.</booktitle>
<contexts>
<context position="13714" citStr="Ng and Cardie, 2003" startWordPosition="2067" endWordPosition="2070">isting of examples of human translations between the languages. 3.3 The Co-Training Algorithm The co-training algorithm (Blum and Mitchell, 1998) is a typical bootstrapping method, which starts with a set of labeled data, and increase the amount of annotated data using some amounts of unlabeled data in an incremental way. One important aspect of co-training is that two conditional independent views are required for cotraining to work, but the independence assumption can be relaxed. Till now, co-training has been successfully applied to statistical parsing (Sarkar, 2001), reference resolution (Ng and Cardie, 2003), part of speech tagging (Clark et al., 2003), word sense disambiguation (Mihalcea, 2004) and email classification (Kiritchenko and Matwin, 2001). In the context of cross-lingual sentiment classification, each labeled English review or unlabeled Chinese review has two views of features: English features and Chinese features. Here, a review is used to indicate both its Chinese version and its English version, until stated otherwise. The co-training algorithm is illustrated in Figure 2. In the algorithm, the class distribution in the labeled data is maintained by balancing the parameter values o</context>
</contexts>
<marker>Ng, Cardie, 2003</marker>
<rawString>V. Ng and C. Cardie. 2003. Weakly supervised natural language learning without redundant views. In Proceedings of HLT-NAACL-03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Nigam</author>
<author>A K McCallum</author>
<author>S Thrun</author>
<author>T Mitchell</author>
</authors>
<title>Text Classification from Labeled and Unlabeled Documents using EM.</title>
<date>2000</date>
<booktitle>Machine Learning,</booktitle>
<pages>39--2</pages>
<contexts>
<context position="8094" citStr="Nigam et al., 2000" startWordPosition="1220" endWordPosition="1223">n Cross-domain text classification can be considered as a more general task than cross-lingual sentiment classification. In the problem of crossdomain text classification, the labeled and unlabeled data come from different domains, and their underlying distributions are often different from each other, which violates the basic assumption of traditional classification learning. To date, many semi-supervised learning algorithms have been developed for addressing the cross-domain text classification problem by transferring knowledge across domains, including Transductive SVM (Joachims, 1999), EM(Nigam et al., 2000), EM-based Naïve Bayes classifier (Dai et al., 2007a), Topic-bridged PLSA (Xue et al., 2008), Co-Clustering based classification (Dai et al., 2007b), two-stage approach (Jiang and Zhai, 2007). DauméIII and Marcu (2006) introduce a statistical formulation of this problem in terms of a simple mixture model. In particular, several previous studies focus on the problem of cross-lingual text classification, which can be considered as a special case of general cross-domain text classification. Bel et al. (2003) present practical and cost-effective solutions. A few novel models have been proposed to </context>
</contexts>
<marker>Nigam, McCallum, Thrun, Mitchell, 2000</marker>
<rawString>K. Nigam, A. K. McCallum, S. Thrun, and T. Mitchell. 2000. Text Classification from Labeled and Unlabeled Documents using EM. Machine Learning, 39(2-3):103–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
<author>S Vaithyanathan</author>
</authors>
<title>Thumbs up? sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP-02.</booktitle>
<contexts>
<context position="5822" citStr="Pang et al. (2002)" startWordPosition="879" endWordPosition="882">004) use the technique of deep language analysis for machine translation to extract sentiment units in text documents. Kennedy and Inkpen (2006) determine the sentiment of a customer review by counting positive and negative terms and taking into account contextual valence shifters, such as negations and intensifiers. Devitt and Ahmad (2007) explore a computable metric of positive or negative polarity in financial news text. Corpus-based methods usually consider the sentiment analysis task as a classification task and they use a labeled corpus to train a sentiment classifier. Since the work of Pang et al. (2002), various classification models and linguistic features have been proposed to improve the classification performance (Pang and Lee, 2004; Mullen and Collier, 2004; Wilson et al., 2005; Read, 2005). Most recently, McDonald et al. (2007) investigate a structured model for jointly classifying the sentiment of text at varying levels of granularity. Blitzer et al. (2007) investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. Andreevskaia and Bergler (2008) present a new system consisting of the ensemble of a corpus-based classifier and a</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>B. Pang, L. Lee and S. Vaithyanathan. 2002. Thumbs up? sentiment classification using machine learning techniques. In Proceedings of EMNLP-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>A sentimental education: sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL-04.</booktitle>
<contexts>
<context position="5958" citStr="Pang and Lee, 2004" startWordPosition="899" endWordPosition="902">n (2006) determine the sentiment of a customer review by counting positive and negative terms and taking into account contextual valence shifters, such as negations and intensifiers. Devitt and Ahmad (2007) explore a computable metric of positive or negative polarity in financial news text. Corpus-based methods usually consider the sentiment analysis task as a classification task and they use a labeled corpus to train a sentiment classifier. Since the work of Pang et al. (2002), various classification models and linguistic features have been proposed to improve the classification performance (Pang and Lee, 2004; Mullen and Collier, 2004; Wilson et al., 2005; Read, 2005). Most recently, McDonald et al. (2007) investigate a structured model for jointly classifying the sentiment of text at varying levels of granularity. Blitzer et al. (2007) investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. Andreevskaia and Bergler (2008) present a new system consisting of the ensemble of a corpus-based classifier and a lexicon-based classifier with precision-based vote weighting. Chinese sentiment analysis has also been studied (Tsou et al., 2005; Ye e</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>B. Pang and L. Lee. 2004. A sentimental education: sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of ACL-04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Read</author>
</authors>
<title>Using emoticons to reduce dependency in machine learning techniques for sentiment classification.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-05.</booktitle>
<contexts>
<context position="6018" citStr="Read, 2005" startWordPosition="911" endWordPosition="912">ositive and negative terms and taking into account contextual valence shifters, such as negations and intensifiers. Devitt and Ahmad (2007) explore a computable metric of positive or negative polarity in financial news text. Corpus-based methods usually consider the sentiment analysis task as a classification task and they use a labeled corpus to train a sentiment classifier. Since the work of Pang et al. (2002), various classification models and linguistic features have been proposed to improve the classification performance (Pang and Lee, 2004; Mullen and Collier, 2004; Wilson et al., 2005; Read, 2005). Most recently, McDonald et al. (2007) investigate a structured model for jointly classifying the sentiment of text at varying levels of granularity. Blitzer et al. (2007) investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. Andreevskaia and Bergler (2008) present a new system consisting of the ensemble of a corpus-based classifier and a lexicon-based classifier with precision-based vote weighting. Chinese sentiment analysis has also been studied (Tsou et al., 2005; Ye et al., 2006; Li and Sun, 2007) and most such work uses simil</context>
</contexts>
<marker>Read, 2005</marker>
<rawString>J. Read. 2005. Using emoticons to reduce dependency in machine learning techniques for sentiment classification. In Proceedings of ACL-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Rigutini</author>
<author>M Maggini</author>
<author>B Liu</author>
</authors>
<title>An EM based training algorithm for cross-language text categorization.</title>
<date>2005</date>
<booktitle>In Proceedings of WI-05.</booktitle>
<contexts>
<context position="8766" citStr="Rigutini et al., 2005" startWordPosition="1322" endWordPosition="1325">7a), Topic-bridged PLSA (Xue et al., 2008), Co-Clustering based classification (Dai et al., 2007b), two-stage approach (Jiang and Zhai, 2007). DauméIII and Marcu (2006) introduce a statistical formulation of this problem in terms of a simple mixture model. In particular, several previous studies focus on the problem of cross-lingual text classification, which can be considered as a special case of general cross-domain text classification. Bel et al. (2003) present practical and cost-effective solutions. A few novel models have been proposed to address the problem, e.g. the EM-based algorithm (Rigutini et al., 2005), the information bottleneck approach (Ling et al., 2008), the multilingual domain models (Gliozzo and Strapparava, 2005), etc. To the best of our knowledge, cotraining has not yet been investigated for crossdomain or cross-lingual text classification. 236 3 The Co-Training Approach 3.1 Overview The purpose of our approach is to make use of the annotated English corpus for sentiment polarity identification of Chinese reviews in a supervised framework, without using any Chinese resources. Given the labeled English reviews and unlabeled Chinese reviews, two straightforward methods for addressing</context>
</contexts>
<marker>Rigutini, Maggini, Liu, 2005</marker>
<rawString>L. Rigutini, M. Maggini and B. Liu. 2005. An EM based training algorithm for cross-language text categorization. In Proceedings of WI-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Sarkar</author>
</authors>
<title>Applying cotraining methods to statistical parsing.</title>
<date>2001</date>
<booktitle>In Proceedings of NAACL-2001.</booktitle>
<contexts>
<context position="13670" citStr="Sarkar, 2001" startWordPosition="2063" endWordPosition="2064">target language and aligned text consisting of examples of human translations between the languages. 3.3 The Co-Training Algorithm The co-training algorithm (Blum and Mitchell, 1998) is a typical bootstrapping method, which starts with a set of labeled data, and increase the amount of annotated data using some amounts of unlabeled data in an incremental way. One important aspect of co-training is that two conditional independent views are required for cotraining to work, but the independence assumption can be relaxed. Till now, co-training has been successfully applied to statistical parsing (Sarkar, 2001), reference resolution (Ng and Cardie, 2003), part of speech tagging (Clark et al., 2003), word sense disambiguation (Mihalcea, 2004) and email classification (Kiritchenko and Matwin, 2001). In the context of cross-lingual sentiment classification, each labeled English review or unlabeled Chinese review has two views of features: English features and Chinese features. Here, a review is used to indicate both its Chinese version and its English version, until stated otherwise. The co-training algorithm is illustrated in Figure 2. In the algorithm, the class distribution in the labeled data is ma</context>
</contexts>
<marker>Sarkar, 2001</marker>
<rawString>A. Sarkar. 2001. Applying cotraining methods to statistical parsing. In Proceedings of NAACL-2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>R McDonald</author>
</authors>
<title>A joint model of text and aspect ratings for sentiment summarization.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08:HLT.</booktitle>
<contexts>
<context position="1514" citStr="Titov and McDonald, 2008" startWordPosition="220" endWordPosition="223">ng use of unlabeled Chinese data. Experimental results show the effectiveness of the proposed approach, which can outperform the standard inductive classifiers and the transductive classifiers. 1 Introduction Sentiment classification is the task of identifying the sentiment polarity of a given text. The sentiment polarity is usually positive or negative and the text genre is usually product review. In recent years, sentiment classification has drawn much attention in the NLP field and it has many useful applications, such as opinion mining and summarization (Liu et al., 2005; Ku et al., 2006; Titov and McDonald, 2008). To date, a variety of corpus-based methods have been developed for sentiment classification. The methods usually rely heavily on an annotated corpus for training the sentiment classifier. The sentiment corpora are considered as the most valuable resources for the sentiment classification task. However, such resources in different languages are very imbalanced. Because most previous work focuses on English sentiment classification, many annotated corpora for English sentiment classification are freely available on the Web. However, the annotated corpora for Chinese sentiment classification ar</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>I. Titov and R. McDonald. 2008. A joint model of text and aspect ratings for sentiment summarization. In Proceedings of ACL-08:HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B K Y Tsou</author>
<author>R W M Yuen</author>
<author>O Y Kwong</author>
<author>T B Y La</author>
<author>W L Wong</author>
</authors>
<title>Polarity classification of celebrity coverage in the Chinese press.</title>
<date>2005</date>
<booktitle>In Proceedings of International Conference on Intelligence Analysis.</booktitle>
<contexts>
<context position="6552" citStr="Tsou et al., 2005" startWordPosition="992" endWordPosition="995">nce (Pang and Lee, 2004; Mullen and Collier, 2004; Wilson et al., 2005; Read, 2005). Most recently, McDonald et al. (2007) investigate a structured model for jointly classifying the sentiment of text at varying levels of granularity. Blitzer et al. (2007) investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. Andreevskaia and Bergler (2008) present a new system consisting of the ensemble of a corpus-based classifier and a lexicon-based classifier with precision-based vote weighting. Chinese sentiment analysis has also been studied (Tsou et al., 2005; Ye et al., 2006; Li and Sun, 2007) and most such work uses similar lexiconbased or corpus-based methods for Chinese sentiment classification. To date, several pilot studies have been performed to leverage rich English resources for sentiment analysis in other languages. Standard Naïve Bayes and SVM classifiers have been applied for subjectivity classification in Romanian (Mihalcea et al., 2007; Banea et al., 2008), and the results show that automatic translation is a viable alternative for the construction of resources and tools for subjectivity analysis in a new target language. Wan (2008) </context>
</contexts>
<marker>Tsou, Yuen, Kwong, La, Wong, 2005</marker>
<rawString>B. K. Y. Tsou, R. W. M. Yuen, O. Y. Kwong, T. B. Y. La and W. L. Wong. 2005. Polarity classification of celebrity coverage in the Chinese press. In Proceedings of International Conference on Intelligence Analysis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
</authors>
<title>Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL-2002.</booktitle>
<contexts>
<context position="4830" citStr="Turney (2002)" startWordPosition="720" endWordPosition="721">tec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP co-training approach is described in detail in Section 3. Section 4 shows the experimental results. Lastly we conclude this paper in Section 5. 2 Related Work 2.1 Sentiment Classification Sentiment classification can be performed on words, sentences or documents. In this paper we focus on document sentiment classification. The methods for document sentiment classification can be generally categorized into lexicon-based and corpus-based. Lexicon-based methods usually involve deriving a sentiment measure for text based on sentiment lexicons. Turney (2002) predicates the sentiment orientation of a review by the average semantic orientation of the phrases in the review that contain adjectives or adverbs, which is denoted as the semantic oriented method. Kim and Hovy (2004) build three models to assign a sentiment category to a given sentence by combining the individual sentiments of sentimentbearing words. Hiroshi et al. (2004) use the technique of deep language analysis for machine translation to extract sentiment units in text documents. Kennedy and Inkpen (2006) determine the sentiment of a customer review by counting positive and negative te</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>P. Turney. 2002. Thumbs up or thumbs down? semantic orientation applied to unsupervised classification of reviews. In Proceedings of ACL-2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wan</author>
</authors>
<title>Using bilingual knowledge and ensemble techniques for unsupervised Chinese sentiment analysis.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP-2008.</booktitle>
<contexts>
<context position="7151" citStr="Wan (2008)" startWordPosition="1090" endWordPosition="1091">t al., 2005; Ye et al., 2006; Li and Sun, 2007) and most such work uses similar lexiconbased or corpus-based methods for Chinese sentiment classification. To date, several pilot studies have been performed to leverage rich English resources for sentiment analysis in other languages. Standard Naïve Bayes and SVM classifiers have been applied for subjectivity classification in Romanian (Mihalcea et al., 2007; Banea et al., 2008), and the results show that automatic translation is a viable alternative for the construction of resources and tools for subjectivity analysis in a new target language. Wan (2008) focuses on leveraging both Chinese and English lexicons to improve Chinese sentiment analysis by using lexicon-based methods. In this study, we focus on improving the corpus-based method for crosslingual sentiment classification of Chinese product reviews by developing novel approaches. 2.2 Cross-Domain Text Classification Cross-domain text classification can be considered as a more general task than cross-lingual sentiment classification. In the problem of crossdomain text classification, the labeled and unlabeled data come from different domains, and their underlying distributions are often</context>
</contexts>
<marker>Wan, 2008</marker>
<rawString>X. Wan. 2008. Using bilingual knowledge and ensemble techniques for unsupervised Chinese sentiment analysis. In Proceedings of EMNLP-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>J Wiebe</author>
<author>P Hoffmann</author>
</authors>
<title>Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP-05.</booktitle>
<contexts>
<context position="6005" citStr="Wilson et al., 2005" startWordPosition="907" endWordPosition="910"> review by counting positive and negative terms and taking into account contextual valence shifters, such as negations and intensifiers. Devitt and Ahmad (2007) explore a computable metric of positive or negative polarity in financial news text. Corpus-based methods usually consider the sentiment analysis task as a classification task and they use a labeled corpus to train a sentiment classifier. Since the work of Pang et al. (2002), various classification models and linguistic features have been proposed to improve the classification performance (Pang and Lee, 2004; Mullen and Collier, 2004; Wilson et al., 2005; Read, 2005). Most recently, McDonald et al. (2007) investigate a structured model for jointly classifying the sentiment of text at varying levels of granularity. Blitzer et al. (2007) investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. Andreevskaia and Bergler (2008) present a new system consisting of the ensemble of a corpus-based classifier and a lexicon-based classifier with precision-based vote weighting. Chinese sentiment analysis has also been studied (Tsou et al., 2005; Ye et al., 2006; Li and Sun, 2007) and most such wo</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>T. Wilson, J. Wiebe and P. Hoffmann. 2005. Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis. In Proceedings of HLT/EMNLP-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G-R Xue</author>
<author>W Dai</author>
<author>Q Yang</author>
<author>Y Yu</author>
</authors>
<title>Topicbridged PLSA for cross-domain text classification.</title>
<date>2008</date>
<booktitle>In Proceedings of SIGIR-08.</booktitle>
<contexts>
<context position="8186" citStr="Xue et al., 2008" startWordPosition="1234" endWordPosition="1237"> sentiment classification. In the problem of crossdomain text classification, the labeled and unlabeled data come from different domains, and their underlying distributions are often different from each other, which violates the basic assumption of traditional classification learning. To date, many semi-supervised learning algorithms have been developed for addressing the cross-domain text classification problem by transferring knowledge across domains, including Transductive SVM (Joachims, 1999), EM(Nigam et al., 2000), EM-based Naïve Bayes classifier (Dai et al., 2007a), Topic-bridged PLSA (Xue et al., 2008), Co-Clustering based classification (Dai et al., 2007b), two-stage approach (Jiang and Zhai, 2007). DauméIII and Marcu (2006) introduce a statistical formulation of this problem in terms of a simple mixture model. In particular, several previous studies focus on the problem of cross-lingual text classification, which can be considered as a special case of general cross-domain text classification. Bel et al. (2003) present practical and cost-effective solutions. A few novel models have been proposed to address the problem, e.g. the EM-based algorithm (Rigutini et al., 2005), the information bo</context>
</contexts>
<marker>Xue, Dai, Yang, Yu, 2008</marker>
<rawString>G.-R. Xue, W. Dai, Q. Yang, Y. Yu. 2008. Topicbridged PLSA for cross-domain text classification. In Proceedings of SIGIR-08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Ye</author>
<author>W Shi</author>
<author>Y Li</author>
</authors>
<title>Sentiment classification for movie reviews in Chinese by improved semantic oriented approach.</title>
<date>2006</date>
<booktitle>In Proceedings of 39th Hawaii International Conference on System Sciences,</booktitle>
<contexts>
<context position="6569" citStr="Ye et al., 2006" startWordPosition="996" endWordPosition="999">2004; Mullen and Collier, 2004; Wilson et al., 2005; Read, 2005). Most recently, McDonald et al. (2007) investigate a structured model for jointly classifying the sentiment of text at varying levels of granularity. Blitzer et al. (2007) investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. Andreevskaia and Bergler (2008) present a new system consisting of the ensemble of a corpus-based classifier and a lexicon-based classifier with precision-based vote weighting. Chinese sentiment analysis has also been studied (Tsou et al., 2005; Ye et al., 2006; Li and Sun, 2007) and most such work uses similar lexiconbased or corpus-based methods for Chinese sentiment classification. To date, several pilot studies have been performed to leverage rich English resources for sentiment analysis in other languages. Standard Naïve Bayes and SVM classifiers have been applied for subjectivity classification in Romanian (Mihalcea et al., 2007; Banea et al., 2008), and the results show that automatic translation is a viable alternative for the construction of resources and tools for subjectivity analysis in a new target language. Wan (2008) focuses on levera</context>
</contexts>
<marker>Ye, Shi, Li, 2006</marker>
<rawString>Q. Ye, W. Shi and Y. Li. 2006. Sentiment classification for movie reviews in Chinese by improved semantic oriented approach. In Proceedings of 39th Hawaii International Conference on System Sciences, 2006.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>