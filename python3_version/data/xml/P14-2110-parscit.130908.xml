<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000862">
<title confidence="0.9989765">
Learning Polylingual Topic Models from
Code-Switched Social Media Documents
</title>
<author confidence="0.997157">
Nanyun Peng Yiming Wang Mark Dredze
</author>
<affiliation confidence="0.910203333333333">
Human Language Technology Center of Excellence
Center for Language and Speech Processing
Johns Hopkins University, Baltimore, MD USA
</affiliation>
<email confidence="0.998417">
{npeng1,freewym,mdredze}@jhu.edu
</email>
<sectionHeader confidence="0.993854" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9987828">
Code-switched documents are common
in social media, providing evidence for
polylingual topic models to infer aligned
topics across languages. We present
Code-Switched LDA (csLDA), which in-
fers language specific topic distributions
based on code-switched documents to fa-
cilitate multi-lingual corpus analysis. We
experiment on two code-switching cor-
pora (English-Spanish Twitter data and
English-Chinese Weibo data) and show
that csLDA improves perplexity over
LDA, and learns semantically coherent
aligned topics as judged by human anno-
tators.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999308">
Topic models (Blei et al., 2003) have become stan-
dard tools for analyzing document collections, and
topic analyses are quite common for social media
(Paul and Dredze, 2011; Zhao et al., 2011; Hong
and Davison, 2010; Ramage et al., 2010; Eisen-
stein et al., 2010). Their popularity owes in part to
their data driven nature, allowing them to adapt to
new corpora and languages. In social media espe-
cially, there is a large diversity in terms of both the
topic and language, necessitating the modeling of
multiple languages simultaneously. A good candi-
date for multi-lingual topic analyses are polylin-
gual topic models (Mimno et al., 2009), which
learn topics for multiple languages, creating tuples
of language specific distributions over monolin-
gual vocabularies for each topic. Polylingual topic
models enable cross language analysis by group-
ing documents by topic regardless of language.
Training of polylingual topic models requires
parallel or comparable corpora: document tuples
from multiple languages that discuss the same
topic. While additional non-aligned documents
</bodyText>
<figureCaption confidence="0.6868938">
User 1: ¡Don Samuel es un crack! #VamosM´exico #DaleTri
RT @User4: Arriba! Viva Mexico! Advanced to GOLD.
medal match in “Football”!
User 2: @user1 rodo que tal el nuevo Mountain ?
User 3: @User1 @User4 wow this is something !! Ja ja ja
Football well said
Figure 1: Three users discuss Mexico’s football
team advancing to the Gold medal game in the
2012 Olympics in code-switched Spanish and En-
glish.
</figureCaption>
<bodyText confidence="0.99984384375">
can be folded in during training, the “glue” doc-
uments are required to aid in the alignment across
languages. However, the ever changing vocabu-
lary and topics of social media (Eisenstein, 2013)
make finding suitable comparable corpora diffi-
cult. Standard techniques – such as relying on ma-
chine translation parallel corpora or comparable
documents extracted from Wikipedia in different
languages – fail to capture the specific terminol-
ogy of social media. Alternate methods that rely
on bilingual lexicons (Jagarlamudi and Daum´e,
2010) similarly fail to adapt to shifting vocabular-
ies. The result: an inability to train polylingual
models on social media.
In this paper, we offer a solution: utilize code-
switched social media to discover correlations
across languages. Social media is filled with ex-
amples of code-switching, where users switch be-
tween two or more languages, both in a conversa-
tion and even a single message (Ling et al., 2013).
This mixture of languages in the same context sug-
gests alignments between words across languages
through the common topics discussed in the con-
text.
We learn from code-switched social media by
extending the polylingual topic model framework
to infer the language of each token and then auto-
matically processing the learned topics to identify
aligned topics. Our model improves both in terms
of perplexity and a human evaluation, and we pro-
vide some example analyses of social media that
rely on our learned topics.
</bodyText>
<page confidence="0.985844">
674
</page>
<bodyText confidence="0.597715">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 674–679,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</bodyText>
<sectionHeader confidence="0.686954" genericHeader="introduction">
2 Code-Switching
</sectionHeader>
<bodyText confidence="0.995515784313726">
Code-switched documents has received consider-
able attention in the NLP community. Several
tasks have focused on identification and analysis,
including mining translations in code-switched
documents (Ling et al., 2013), predicting code-
switched points (Solorio and Liu, 2008a), identi-
fying code-switched tokens (Lignos and Marcus,
2013; Yu et al., 2012; Elfardy and Diab, 2012),
adding code-switched support to language mod-
els (Li and Fung, 2012), linguistic processing of
code switched data (Solorio and Liu, 2008b), cor-
pus creation (Li et al., 2012; Diab and Kamboj,
2011), and computational linguistic analyses and
theories of code-switching (Sankofl, 1998; Joshi,
1982).
Code-switching specifically in social media has
also received some recent attention. Lignos and
Marcus (2013) trained a supervised token level
language identification system for Spanish and
English code-switched social media to study code-
switching behaviors. Ling et al. (2013) mined
translation spans for Chinese and English in code-
switched documents to improve a translation sys-
tem, relying on an existing translation model to aid
in the identification and extraction task. In contrast
to this work, we take an unsupervised approach,
relying only on readily available document level
language ID systems to utilize code-switched data.
Additionally, our focus is not on individual mes-
sages, rather we aim to train a model that can be
used to analyze entire corpora.
In this work we consider two types of code-
switched documents: single messages and conver-
sations, and two language pairs: Chinese-English
and Spanish-English. Figure 1 shows an exam-
ple of a code-switched Spanish-English conversa-
tion, in which three users discuss Mexico’s foot-
ball team advancing to the Gold medal game in
the 2012 Summer Olympics. In this conversation,
some tweets are code-switched and some are in a
single language. By collecting the entire conver-
sation into a single document we provide the topic
model with additional content. An example of a
Chinese-English code-switched messages is given
by Ling et al. (2013):
watup Kenny Mayne!! - Kenny Mayne
最近这么样啊!!
Here a user switches between languages in a single
message. We empirically evaluate our model on
both conversations and messages. In the model
presentation we will refer to both as “documents.”
</bodyText>
<sectionHeader confidence="0.997143" genericHeader="method">
3 csLDA
</sectionHeader>
<bodyText confidence="0.999983723404255">
To train a polylingual topic model on social me-
dia, we make two modifications to the model of
Mimno et al. (2009): add a token specific language
variable, and a process for identifying aligned top-
ics.
First, polylingual topic models require paral-
lel or comparable corpora in which each docu-
ment has an assigned language. In the case of
code-switched social media data, we require aper-
token language variable. However, while docu-
ment level language identification (LID) systems
are common place, very few languages have per-
token LID systems (King and Abney, 2013; Lig-
nos and Marcus, 2013).
To address the lack of available LID systems,
we add a per-token latent language variable to the
polylingual topic model. For documents that are
not code-switched, we observe these variables to
be the output of a document level LID system. In
the case of code-switched documents, these vari-
ables are inferred during model inference.
Second, polylingual topic models assume the
aligned topics are from parallel or comparable cor-
pora, which implicitly assumes that a topics pop-
ularity is balanced across languages. Topics that
show up in one language necessarily show up in
another. However, in the case of social media,
we can make no such assumption. The topics
discussed are influenced by users, time, and lo-
cation, all factors intertwined with choice of lan-
guage. For example, English speakers will more
likely discuss Olympic basketball while Spanish
speakers football. There may be little or no docu-
ments on a given topic in one language, while they
are plentiful in another. In this case, a polylin-
gual topic model, which necessarily infers a topic-
specific word distribution for each topic in each
language, would learn two unrelated word dis-
tributions in two languages for a single topic.
Therefore, naively using the produced topics as
“aligned” across languages is ill-advised.
Our solution is to automatically identify aligned
polylingual topics after learning by examining
a topic’s distribution across code-switched docu-
ments. Our metric relies on distributional proper-
ties of an inferred topic across the entire collec-
tion.
</bodyText>
<page confidence="0.995797">
675
</page>
<bodyText confidence="0.9058595">
To summarize, based on the model of Mimno et
al. (2009) we will learn:
</bodyText>
<listItem confidence="0.975129166666667">
• For each topic, a language specific word distri-
bution.
• For each (code-switched) token, a language.
• For each topic, an identification as to whether
the topic captures an alignment across lan-
guages.
</listItem>
<bodyText confidence="0.974808333333333">
The first two goals are achieved by incorporat-
ing new hidden variables in the traditional polylin-
gual topic model. The third goal requires an auto-
mated post-processing step. We call the resulting
model Code-Switched LDA (csLDA). The gener-
ative process is as follows:
</bodyText>
<listItem confidence="0.99983675">
• For each topic z E T
• For each language l E L
• Draw word distribution
φlz—Dir(βl)
• For each document d E D:
• Draw a topic distribution θd — Dir(α)
• Draw a language distribution
ψd—Dir(γ)
• For each token i E d:
• Draw a topic zi — θd
• Draw a language li — ψd
• Draw a word wi — φlz
</listItem>
<bodyText confidence="0.999950272727273">
For monolingual documents, we fix li to the LID
tag for all tokens. Additionally, we use a single
background distribution for each language to cap-
ture stopwords; a control variable π, which fol-
lows a Dirichlet distribution with prior parameter-
ized by δ, is introduced to decide the choice be-
tween background words and topic words follow-
ing (Chemudugunta et al., 2006)1. We use asym-
metric Dirichlet priors (Wallach et al., 2009), and
let the optimization process learn the hyperparam-
eters. The graphical model is shown in Figure 2.
</bodyText>
<subsectionHeader confidence="0.891085">
3.1 Inference
</subsectionHeader>
<bodyText confidence="0.9998885">
Inference for csLDA follows directly from LDA.
A Gibbs sampler learns the word distributions φlz
for each language and topic. We use a block Gibbs
sampler to jointly sample topic and language vari-
ables for each token. As is customary, we collapse
out φ, θ and ψ. The sampling posterior is:
</bodyText>
<equation confidence="0.9974656">
P(zi, li|w, z−i, l−i, α, β, γ) a
ol,d−i +
γ
X (1)
od−i + Gγ
</equation>
<bodyText confidence="0.9880495">
where (nl,z )−i is the number of times the type for
wi
</bodyText>
<footnote confidence="0.814935">
word wi assigned to topic z and language l (ex-
1Omitted from the generative process but shown in Fig. 2.
</footnote>
<figureCaption confidence="0.9655115">
Figure 2: The graphical model for csLDA.
cluding current word wi), mz,d
</figureCaption>
<bodyText confidence="0.999853529411765">
−i is the number of
tokens assigned to topic z in document d (exclud-
ing current word wi), ol,d−i is the number of tokens
assigned to language l in document d (excluding
current word wi), and these variables with super-
scripts or subscripts omitted are totals across all
values for the variable. W is the number of words
in the corpus. All counts omit words assigned
to the background. During sampling, words are
first assigned to the background/topic distribution
and then topic and language are sampled for non-
background words.
We optimize the hyperparameters α, β, γ and δ
by interleaving sampling iterations with a Newton-
Raphson update to obtain the MLE estimate for
the hyperparameters. Taking α as an example, one
step of the Newton-Raphson update is:
</bodyText>
<equation confidence="0.830125">
αnew = αold − H−1 ∂L (2)
</equation>
<bodyText confidence="0.942197857142857">
∂α
where H is the Hessian matrix and ∂L
∂α is the gra-
dient of the likelihood function with respect to
the optimizing hyperparameter. We interleave 200
sampling iterations with one Newton-Raphson up-
date.
</bodyText>
<subsectionHeader confidence="0.999847">
3.2 Selecting Aligned Topics
</subsectionHeader>
<bodyText confidence="0.999900545454545">
We next identify learned topics (a set of related
word-distributions) that truly represent an aligned
topic across languages, as opposed to an unrelated
set of distributions for which there is no support-
ing alignment evidence in the corpus. We begin by
measuring how often each topic occurs in code-
switched documents. If a topic never occurs in
a code-switched document, then there can be no
evidence to support alignment across languages.
For the topics that appear at least once in a code-
switched document, we estimate their probability
</bodyText>
<figure confidence="0.730728263157895">
γ ψd li
α θd
δ B
zi
bi
φlz φlb
T
wi
β
N
D
L
X
nl,z
−i + Wβ
mz,d −i + α
md −i + Tα
(nl,z) + β
wi −i
</figure>
<page confidence="0.989753">
676
</page>
<bodyText confidence="0.9997238">
in the code-switched documents by a MAP esti-
mate of θ. Topics appearing in at least one code-
switched document with probability greater than
a threshold p are selected as candidates for true
cross-language topics.
</bodyText>
<sectionHeader confidence="0.99713" genericHeader="method">
4 Data
</sectionHeader>
<bodyText confidence="0.999949515151515">
We used two datasets: a Sina Weibo Chinese-
English corpus (Ling et al., 2013) and a Spanish-
English Twitter corpus.
Weibo Ling et al. (2013) extracted over 1m
Chinese-English parallel segments from Sina
Weibo, which are code-switched messages. We
randomly sampled 29,705 code-switched mes-
sages along with 42,116 Chinese and 42,116 En-
glish messages from the the same time frame. We
used these data for training. We then sampled
an additional 2475 code-switched messages, 4221
English and 4211 Chinese messages as test data.
Olympics We collected tweets from July 27,
2012 to August 12, 2012, and identified 302,775
tweets about the Olympics based on related hash-
tags and keywords (e.g. olympics, #london2012,
etc.) We identified code-switched tweets using
the Chromium Language Detector2. This system
provides the top three possible languages for a
given document with confidence scores; we iden-
tify a tweet as code-switched if two predicted lan-
guages each have confidence greater than 33%.
We then used the tagger of Lignos and Marcus
(2013) to obtain token level LID tags, and only
tweets with tokens in both Spanish and English are
used as code-switched tweets. In total we iden-
tified 822 Spanish-English code-switched tweets.
We further expanded the mined tweets to full con-
versations, yielding 1055 Spanish-English code-
switched documents (including both tweets and
conversations), along with 4007 English and 4421
Spanish tweets composes our data set. We reserve
10% of the data for testing.
</bodyText>
<sectionHeader confidence="0.999609" genericHeader="conclusions">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999965571428571">
We evaluated csLDA on the two datasets and eval-
uated each model using perplexity on held out data
and human judgements. While our goal is to learn
polylingual topics, we cannot compare to previous
polylingual models since they require comparable
data, which we lack. Instead, we constructed a
baseline from LDA run on the entire dataset (no
</bodyText>
<footnote confidence="0.768476">
2https://code.google.com/p/chromium-compact-language-detector/
</footnote>
<bodyText confidence="0.999935892857143">
language information.) For each model, we mea-
sured the document completion perplexity (Rosen-
Zvi et al., 2004) on the held out data. We ex-
perimented with different numbers of topics (T).
Since csLDA duplicates topic distributions (T xL)
we used twice as many topics for LDA.
Figure 3 shows test perplexity for varying T and
perplexity for the best setting of csLDA (T =60)
and LDA (T=120). The table lists both mono-
lingual and code-switched test data; csLDA im-
proves over LDA in almost every case, and across
all values of T . The background distribution (-bg)
has mixed results for LDA, whereas for csLDA
it shows consistent improvement. Table 4 shows
some csLDA topics. While there are some mis-
takes, overall the topics are coherent and aligned.
We use the available per-token LID system
(Lignos and Marcus, 2013) for Spanish/English
to justify csLDA’s ability to infer the hidden lan-
guage variables. We ran csLDA-bg with lz set to
the value provided by the LID system for code-
switched documents (csLDA-bg with LID), which
gives csLDA high quality LID labels. While we
see gains for the code-switched data, overall the
results for csLDA-bg and csLDA-bg with LID are
similar, suggesting that the model can operate ef-
fectively even without a supervised per-token LID
system.
</bodyText>
<subsectionHeader confidence="0.992029">
5.1 Human Evaluation
</subsectionHeader>
<bodyText confidence="0.999969952380952">
We evaluate topic alignment quality through a hu-
man judgements (Chang et al., 2009). For each
aligned topic, we show an annotator the 20 most
frequent words from the foreign language topic
(Chinese or Spanish) with the 20 most frequent
words from the aligned English topic and two ran-
dom English topics. The annotators are asked to
select the most related English topic among the
three; the one with the most votes is considered
the aligned topic. We count how often the model’s
alignments agree.
LDA may learn comparable topics in different
languages but gives no explicit alignments. We
create alignments by classifying each LDA topic
by language using the KL-divergence between the
topic’s words distribution and a word distribution
for the English/foreign language inferred from the
monolingual documents. Language is assigned to
a topic by taking the minimum KL. For Weibo
data, this was not effective since the vocabularies
of each language are highly unbalanced. Instead,
</bodyText>
<page confidence="0.995655">
677
</page>
<table confidence="0.98713125">
T =60/120 Olympics Weibo
En Es CS En Cn CS
LDA 11.32 9.44 6.97 29.19 23.06 11.69
LDA-bg 11.35 9.51 6.79 40.87 27.56 10.91
csLDA 8.72 7.94 6.17 18.20 17.31 12.72
csLDA-bg 8.72 7.73 6.04 18.25 17.74 12.46
csLDA-bg 8.73 7.93 4.91 - - -
with LID
</table>
<figure confidence="0.976527857142857">
30000
28000
LDA
LDA-bg
csLDA-bg
csLDA
20/40 30/60 40/80 50/100 60/120 70/140
# Topics
20/40 30/60 40/80 50/100 60/120 70/140
# Topics
10000
9500
;SS
lexlty
LDA
LDA-bg
csLDA-bg with LID
csLDA-bg
csLDA
8500
8000
Perp exity
9000
26000
24000
22000
20000
18000
</figure>
<figureCaption confidence="0.9952105">
Figure 3: Plots show perplexity for different T (Olympics left, Weibo right). Perplexity in the table are
in magnitude of 1 x 103.
</figureCaption>
<table confidence="0.9981525">
English Football English Basketball
Spanish Spanish
mexico mucho game espa˜na
brazil argentina basketball baloncesto
soccer m´exico year basketball
vs brasil finals bronce
womens ganar´a gonna china
football tri nba final
mens yahel castillo obama rusia
final delpo lebron espa˜nola
Social Media English Transportation
English Chinese Chinese
twitter 啊啊啊 car 汽_11i_
bitly 微博 drive 7$个
facebook 更新 road 真真
check 下R line 明年
use 发 train 自行_11i_
blog 视频 harry _11i_型
free pm 汽_11i_ 奔驰
post 推特 bus 大众
</table>
<figureCaption confidence="0.999336">
Figure 4: Examples of aligned topics from Olympics (left) and Weibo (right).
</figureCaption>
<bodyText confidence="0.981171972972973">
we manually labeled the topics by language. We
then pair topics across languages using the cosine
similarity of their co-occurrence statistics in code-
switched documents. Topic pairs with similarity
above t are considered aligned topics. We also
used a threshold p (§3.2) to select aligned topics
in csLDA. To ensure a fair comparison, we select
the same number of aligned topics for LDA and
csLDA.3. We used the best performing setting:
csLDA T=60, LDA T=120, which produced 12
alignments from Olympics and 28 from Weibo.
Using Mechanical Turk we collected multiple
judgements per alignment. For Spanish, we re-
moved workers who disagreed with the majority
more than 50% of the time (83 deletions), leav-
ing 6.5 annotations for each alignment (85.47%
inter-annotator agreement.) For Chinese, since
quality of general Chinese turkers is low (Pavlick
et al., 2014) we invited specific workers and
obtained 9.3 annotations per alignment (78.72%
inter-annotator agreement.) For Olympics, LDA
alignments matched the judgements 25% of the
time, while csLDA matched 50% of the time.
While csLDA found 12 alignments and LDA 29,
the 12 topics evaluated from both models show
that csLDA’s alignments are higher quality. For
the Weibo data, LDA matched judgements 71.4%,
while csLDA matched 75%. Both obtained high
3We used thresholds p = 0.2 and t = 0.0001. We limited
the model with more alignments to match the one with less.
quality alignments – likely due both to the fact
that the code-switched data is curated to find trans-
lations and we hand labeled topic language – but
csLDA found many more alignments: 60 as com-
pared to 28. These results confirm our automated
results: csLDA finds higher quality topics that
span both languages.
</bodyText>
<sectionHeader confidence="0.998699" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998049142857143">
David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent dirichlet allocation. Journal of Ma-
chine Learning Research (JMLR), 3:993–1022.
Jonathan Chang, Sean Gerrish, Chong Wang, Jordan L
Boyd-graber, and David M Blei. 2009. Reading
tea leaves: How humans interpret topic models. In
Advances in neural information processing systems,
pages 288–296.
Chaitanya Chemudugunta, Padhraic Smyth, and Mark
Steyvers. 2006. Modeling general and specific as-
pects of documents with a probabilistic topic model.
In NIPS.
Mona Diab and Ankit Kamboj. 2011. Feasibility of
leveraging crowd sourcing for the creation of a large
scale annotated resource for Hindi English code
switched data: A pilot annotation. In Proceedings
of the 9th Workshop on Asian Language Resources,
pages 36–40, Chiang Mai, Thailand, November.
Asian Federation of Natural Language Processing.
Jacob Eisenstein, Brendan O’Connor, Noah A Smith,
and Eric P Xing. 2010. A latent variable model
</reference>
<page confidence="0.993512">
678
</page>
<reference confidence="0.996337728971963">
for geographic lexical variation. In Proceedings of
the 2010 Conference on Empirical Methods in Nat-
ural Language Processing, pages 1277–1287. Asso-
ciation for Computational Linguistics.
Jacob Eisenstein. 2013. What to do about bad lan-
guage on the internet. In NAACL.
Heba Elfardy and Mona Diab. 2012. Token level
identification of linguistic code switching. In Pro-
ceedings of COLING 2012: Posters, pages 287–296,
Mumbai, India, December. The COLING 2012 Or-
ganizing Committee.
Liangjie Hong and Brian D Davison. 2010. Empirical
study of topic modeling in twitter. In Proceedings of
the First Workshop on Social Media Analytics, pages
80–88. ACM.
Jagadeesh Jagarlamudi and Hal Daum´e. 2010. Ex-
tracting multilingual topics from unaligned compa-
rable corpora. Advances in Information Retrieval,
pages 444–456.
Aravind K Joshi. 1982. Processing of sentences
with intra-sentential code-switching. In Proceed-
ings of the 9th Conference on Computational lin-
guistics (COLING), pages 145–150.
Ben King and Steven Abney. 2013. Labeling the lan-
guages of words in mixed-language documents us-
ing weakly supervised methods. In NAACL.
Ying Li and Pascale Fung. 2012. Code-switch lan-
guage model with inversion constraints for mixed
language speech recognition. In Proceedings of
COLING 2012, pages 1671–1680, Mumbai, India,
December. The COLING 2012 Organizing Commit-
tee.
Ying Li, Yue Yu, and Pascale Fung. 2012. A
mandarin-english code-switching corpus. In Nico-
letta Calzolari, Khalid Choukri, Thierry Declerck,
Mehmet U˘gur Do˘gan, Bente Maegaard, Joseph Mar-
iani, Jan Odijk, and Stelios Piperidis, editors, Pro-
ceedings of the Eighth International Conference on
Language Resources and Evaluation (LREC-2012),
pages 2515–2519, Istanbul, Turkey, May. European
Language Resources Association (ELRA). ACL
Anthology Identifier: L12-1573.
Constantine Lignos and Mitch Marcus. 2013. To-
ward web-scale analysis of codeswitching. In An-
nual Meeting of the Linguistic Society of America.
Wang Ling, Guang Xiang, Chris Dyer, Alan Black, and
Isabel Trancoso. 2013. Microblogs as parallel cor-
pora. In Proceedings of the 51st Annual Meeting
on Association for Computational Linguistics, ACL
’13. Association for Computational Linguistics.
David Mimno, Hanna M Wallach, Jason Naradowsky,
David A Smith, and Andrew McCallum. 2009.
Polylingual topic models. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing: Volume 2-Volume 2, pages
880–889. Association for Computational Linguis-
tics.
Michael J Paul and Mark Dredze. 2011. You are what
you tweet: Analyzing twitter for public health. In
ICWSM.
Ellie Pavlick, Matt Post, Ann Irvine, Dmitry Kachaev,
and Chris Callison-Burch. 2014. The language de-
mographics of Amazon Mechanical Turk. Transac-
tions of the Association for Computational Linguis-
tics, 2(Feb):79–92.
Daniel Ramage, Susan T Dumais, and Daniel J
Liebling. 2010. Characterizing microblogs with
topic models. In ICWSM.
Michal Rosen-Zvi, Thomas Griffiths, Mark Steyvers,
and Padhraic Smyth. 2004. The author-topic model
for authors and documents. In Proceedings of the
20th conference on Uncertainty in artificial intelli-
gence, pages 487–494. AUAI Press.
David Sankofl. 1998. The production of code-mixed
discourse. In Proceedings of the 36th Annual Meet-
ing of the Association for Computational Linguis-
tics and 17th International Conference on Computa-
tional Linguistics, Volume 1, pages 8–21, Montreal,
Quebec, Canada, August. Association for Computa-
tional Linguistics.
Thamar Solorio and Yang Liu. 2008a. Learning to
predict code-switching points. In Proceedings of
the 2008 Conference on Empirical Methods in Nat-
ural Language Processing, pages 973–981, Hon-
olulu, Hawaii, October. Association for Computa-
tional Linguistics.
Thamar Solorio and Yang Liu. 2008b. Part-of-Speech
tagging for English-Spanish code-switched text. In
Proceedings of the 2008 Conference on Empirical
Methods in Natural Language Processing, pages
1051–1060, Honolulu, Hawaii, October. Associa-
tion for Computational Linguistics.
Hanna M Wallach, David M Mimno, and Andrew Mc-
Callum. 2009. Rethinking lda: Why priors matter.
In NIPS, volume 22, pages 1973–1981.
Liang-Chih Yu, Wei-Cheng He, and Wei-Nan Chien.
2012. A language modeling approach to identify-
ing code-switched sentences and words. In Pro-
ceedings of the Second CIPS-SIGHAN Joint Confer-
ence on Chinese Language Processing, pages 3–8,
Tianjin, China, December. Association for Compu-
tational Linguistics.
Wayne Xin Zhao, Jing Jiang, Jianshu Weng, Jing
He, Ee-Peng Lim, Hongfei Yan, and Xiaoming Li.
2011. Comparing twitter and traditional media us-
ing topic models. In Advances in Information Re-
trieval, pages 338–349. Springer.
</reference>
<page confidence="0.999037">
679
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.464975">
<title confidence="0.99167">Learning Polylingual Topic Models Code-Switched Social Media Documents</title>
<author confidence="0.958895">Nanyun Peng Yiming Wang Mark</author>
<affiliation confidence="0.9231595">Human Language Technology Center of Center for Language and Speech</affiliation>
<address confidence="0.57719">Johns Hopkins University, Baltimore, MD</address>
<abstract confidence="0.990810625">Code-switched documents are in social media, providing evidence polylingual topic models to infer aligned topics across languages. We Code-Switched LDA (csLDA), which infers language specific topic distributions based on code-switched documents to facilitate multi-lingual corpus analysis. We experiment on two code-switching corpora (English-Spanish Twitter data and English-Chinese Weibo data) and show that csLDA improves perplexity over LDA, and learns semantically coherent aligned topics as judged by human annotators.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research (JMLR),</journal>
<pages>3--993</pages>
<contexts>
<context position="878" citStr="Blei et al., 2003" startWordPosition="114" endWordPosition="117">,mdredze}@jhu.edu Abstract Code-switched documents are common in social media, providing evidence for polylingual topic models to infer aligned topics across languages. We present Code-Switched LDA (csLDA), which infers language specific topic distributions based on code-switched documents to facilitate multi-lingual corpus analysis. We experiment on two code-switching corpora (English-Spanish Twitter data and English-Chinese Weibo data) and show that csLDA improves perplexity over LDA, and learns semantically coherent aligned topics as judged by human annotators. 1 Introduction Topic models (Blei et al., 2003) have become standard tools for analyzing document collections, and topic analyses are quite common for social media (Paul and Dredze, 2011; Zhao et al., 2011; Hong and Davison, 2010; Ramage et al., 2010; Eisenstein et al., 2010). Their popularity owes in part to their data driven nature, allowing them to adapt to new corpora and languages. In social media especially, there is a large diversity in terms of both the topic and language, necessitating the modeling of multiple languages simultaneously. A good candidate for multi-lingual topic analyses are polylingual topic models (Mimno et al., 20</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research (JMLR), 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Chang</author>
<author>Sean Gerrish</author>
<author>Chong Wang</author>
<author>Jordan L Boyd-graber</author>
<author>David M Blei</author>
</authors>
<title>Reading tea leaves: How humans interpret topic models. In Advances in neural information processing systems,</title>
<date>2009</date>
<pages>288--296</pages>
<contexts>
<context position="15583" citStr="Chang et al., 2009" startWordPosition="2528" endWordPosition="2531">vailable per-token LID system (Lignos and Marcus, 2013) for Spanish/English to justify csLDA’s ability to infer the hidden language variables. We ran csLDA-bg with lz set to the value provided by the LID system for codeswitched documents (csLDA-bg with LID), which gives csLDA high quality LID labels. While we see gains for the code-switched data, overall the results for csLDA-bg and csLDA-bg with LID are similar, suggesting that the model can operate effectively even without a supervised per-token LID system. 5.1 Human Evaluation We evaluate topic alignment quality through a human judgements (Chang et al., 2009). For each aligned topic, we show an annotator the 20 most frequent words from the foreign language topic (Chinese or Spanish) with the 20 most frequent words from the aligned English topic and two random English topics. The annotators are asked to select the most related English topic among the three; the one with the most votes is considered the aligned topic. We count how often the model’s alignments agree. LDA may learn comparable topics in different languages but gives no explicit alignments. We create alignments by classifying each LDA topic by language using the KL-divergence between th</context>
</contexts>
<marker>Chang, Gerrish, Wang, Boyd-graber, Blei, 2009</marker>
<rawString>Jonathan Chang, Sean Gerrish, Chong Wang, Jordan L Boyd-graber, and David M Blei. 2009. Reading tea leaves: How humans interpret topic models. In Advances in neural information processing systems, pages 288–296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chaitanya Chemudugunta</author>
<author>Padhraic Smyth</author>
<author>Mark Steyvers</author>
</authors>
<title>Modeling general and specific aspects of documents with a probabilistic topic model.</title>
<date>2006</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="9659" citStr="Chemudugunta et al., 2006" startWordPosition="1527" endWordPosition="1530">ch language l E L • Draw word distribution φlz—Dir(βl) • For each document d E D: • Draw a topic distribution θd — Dir(α) • Draw a language distribution ψd—Dir(γ) • For each token i E d: • Draw a topic zi — θd • Draw a language li — ψd • Draw a word wi — φlz For monolingual documents, we fix li to the LID tag for all tokens. Additionally, we use a single background distribution for each language to capture stopwords; a control variable π, which follows a Dirichlet distribution with prior parameterized by δ, is introduced to decide the choice between background words and topic words following (Chemudugunta et al., 2006)1. We use asymmetric Dirichlet priors (Wallach et al., 2009), and let the optimization process learn the hyperparameters. The graphical model is shown in Figure 2. 3.1 Inference Inference for csLDA follows directly from LDA. A Gibbs sampler learns the word distributions φlz for each language and topic. We use a block Gibbs sampler to jointly sample topic and language variables for each token. As is customary, we collapse out φ, θ and ψ. The sampling posterior is: P(zi, li|w, z−i, l−i, α, β, γ) a ol,d−i + γ X (1) od−i + Gγ where (nl,z )−i is the number of times the type for wi word wi assigned </context>
</contexts>
<marker>Chemudugunta, Smyth, Steyvers, 2006</marker>
<rawString>Chaitanya Chemudugunta, Padhraic Smyth, and Mark Steyvers. 2006. Modeling general and specific aspects of documents with a probabilistic topic model. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Ankit Kamboj</author>
</authors>
<title>Feasibility of leveraging crowd sourcing for the creation of a large scale annotated resource for Hindi English code switched data: A pilot annotation.</title>
<date>2011</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the 9th Workshop on Asian Language Resources,</booktitle>
<pages>36--40</pages>
<location>Chiang Mai, Thailand,</location>
<contexts>
<context position="4586" citStr="Diab and Kamboj, 2011" startWordPosition="692" endWordPosition="695">on for Computational Linguistics 2 Code-Switching Code-switched documents has received considerable attention in the NLP community. Several tasks have focused on identification and analysis, including mining translations in code-switched documents (Ling et al., 2013), predicting codeswitched points (Solorio and Liu, 2008a), identifying code-switched tokens (Lignos and Marcus, 2013; Yu et al., 2012; Elfardy and Diab, 2012), adding code-switched support to language models (Li and Fung, 2012), linguistic processing of code switched data (Solorio and Liu, 2008b), corpus creation (Li et al., 2012; Diab and Kamboj, 2011), and computational linguistic analyses and theories of code-switching (Sankofl, 1998; Joshi, 1982). Code-switching specifically in social media has also received some recent attention. Lignos and Marcus (2013) trained a supervised token level language identification system for Spanish and English code-switched social media to study codeswitching behaviors. Ling et al. (2013) mined translation spans for Chinese and English in codeswitched documents to improve a translation system, relying on an existing translation model to aid in the identification and extraction task. In contrast to this wor</context>
</contexts>
<marker>Diab, Kamboj, 2011</marker>
<rawString>Mona Diab and Ankit Kamboj. 2011. Feasibility of leveraging crowd sourcing for the creation of a large scale annotated resource for Hindi English code switched data: A pilot annotation. In Proceedings of the 9th Workshop on Asian Language Resources, pages 36–40, Chiang Mai, Thailand, November. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
<author>Brendan O’Connor</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>A latent variable model for geographic lexical variation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1277--1287</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Eisenstein, O’Connor, Smith, Xing, 2010</marker>
<rawString>Jacob Eisenstein, Brendan O’Connor, Noah A Smith, and Eric P Xing. 2010. A latent variable model for geographic lexical variation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1277–1287. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
</authors>
<title>What to do about bad language on the internet.</title>
<date>2013</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="2514" citStr="Eisenstein, 2013" startWordPosition="377" endWordPosition="378"> non-aligned documents User 1: ¡Don Samuel es un crack! #VamosM´exico #DaleTri RT @User4: Arriba! Viva Mexico! Advanced to GOLD. medal match in “Football”! User 2: @user1 rodo que tal el nuevo Mountain ? User 3: @User1 @User4 wow this is something !! Ja ja ja Football well said Figure 1: Three users discuss Mexico’s football team advancing to the Gold medal game in the 2012 Olympics in code-switched Spanish and English. can be folded in during training, the “glue” documents are required to aid in the alignment across languages. However, the ever changing vocabulary and topics of social media (Eisenstein, 2013) make finding suitable comparable corpora difficult. Standard techniques – such as relying on machine translation parallel corpora or comparable documents extracted from Wikipedia in different languages – fail to capture the specific terminology of social media. Alternate methods that rely on bilingual lexicons (Jagarlamudi and Daum´e, 2010) similarly fail to adapt to shifting vocabularies. The result: an inability to train polylingual models on social media. In this paper, we offer a solution: utilize codeswitched social media to discover correlations across languages. Social media is filled </context>
</contexts>
<marker>Eisenstein, 2013</marker>
<rawString>Jacob Eisenstein. 2013. What to do about bad language on the internet. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heba Elfardy</author>
<author>Mona Diab</author>
</authors>
<title>Token level identification of linguistic code switching.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING 2012: Posters,</booktitle>
<pages>287--296</pages>
<location>Mumbai, India,</location>
<contexts>
<context position="4389" citStr="Elfardy and Diab, 2012" startWordPosition="660" endWordPosition="663">learned topics. 674 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 674–679, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Code-Switching Code-switched documents has received considerable attention in the NLP community. Several tasks have focused on identification and analysis, including mining translations in code-switched documents (Ling et al., 2013), predicting codeswitched points (Solorio and Liu, 2008a), identifying code-switched tokens (Lignos and Marcus, 2013; Yu et al., 2012; Elfardy and Diab, 2012), adding code-switched support to language models (Li and Fung, 2012), linguistic processing of code switched data (Solorio and Liu, 2008b), corpus creation (Li et al., 2012; Diab and Kamboj, 2011), and computational linguistic analyses and theories of code-switching (Sankofl, 1998; Joshi, 1982). Code-switching specifically in social media has also received some recent attention. Lignos and Marcus (2013) trained a supervised token level language identification system for Spanish and English code-switched social media to study codeswitching behaviors. Ling et al. (2013) mined translation spans </context>
</contexts>
<marker>Elfardy, Diab, 2012</marker>
<rawString>Heba Elfardy and Mona Diab. 2012. Token level identification of linguistic code switching. In Proceedings of COLING 2012: Posters, pages 287–296, Mumbai, India, December. The COLING 2012 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liangjie Hong</author>
<author>Brian D Davison</author>
</authors>
<title>Empirical study of topic modeling in twitter.</title>
<date>2010</date>
<booktitle>In Proceedings of the First Workshop on Social Media Analytics,</booktitle>
<pages>80--88</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1060" citStr="Hong and Davison, 2010" startWordPosition="144" endWordPosition="147">t Code-Switched LDA (csLDA), which infers language specific topic distributions based on code-switched documents to facilitate multi-lingual corpus analysis. We experiment on two code-switching corpora (English-Spanish Twitter data and English-Chinese Weibo data) and show that csLDA improves perplexity over LDA, and learns semantically coherent aligned topics as judged by human annotators. 1 Introduction Topic models (Blei et al., 2003) have become standard tools for analyzing document collections, and topic analyses are quite common for social media (Paul and Dredze, 2011; Zhao et al., 2011; Hong and Davison, 2010; Ramage et al., 2010; Eisenstein et al., 2010). Their popularity owes in part to their data driven nature, allowing them to adapt to new corpora and languages. In social media especially, there is a large diversity in terms of both the topic and language, necessitating the modeling of multiple languages simultaneously. A good candidate for multi-lingual topic analyses are polylingual topic models (Mimno et al., 2009), which learn topics for multiple languages, creating tuples of language specific distributions over monolingual vocabularies for each topic. Polylingual topic models enable cross</context>
</contexts>
<marker>Hong, Davison, 2010</marker>
<rawString>Liangjie Hong and Brian D Davison. 2010. Empirical study of topic modeling in twitter. In Proceedings of the First Workshop on Social Media Analytics, pages 80–88. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jagadeesh Jagarlamudi</author>
<author>Hal Daum´e</author>
</authors>
<title>Extracting multilingual topics from unaligned comparable corpora. Advances in Information Retrieval,</title>
<date>2010</date>
<pages>444--456</pages>
<marker>Jagarlamudi, Daum´e, 2010</marker>
<rawString>Jagadeesh Jagarlamudi and Hal Daum´e. 2010. Extracting multilingual topics from unaligned comparable corpora. Advances in Information Retrieval, pages 444–456.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
</authors>
<title>Processing of sentences with intra-sentential code-switching.</title>
<date>1982</date>
<booktitle>In Proceedings of the 9th Conference on Computational linguistics (COLING),</booktitle>
<pages>145--150</pages>
<contexts>
<context position="4685" citStr="Joshi, 1982" startWordPosition="706" endWordPosition="707"> in the NLP community. Several tasks have focused on identification and analysis, including mining translations in code-switched documents (Ling et al., 2013), predicting codeswitched points (Solorio and Liu, 2008a), identifying code-switched tokens (Lignos and Marcus, 2013; Yu et al., 2012; Elfardy and Diab, 2012), adding code-switched support to language models (Li and Fung, 2012), linguistic processing of code switched data (Solorio and Liu, 2008b), corpus creation (Li et al., 2012; Diab and Kamboj, 2011), and computational linguistic analyses and theories of code-switching (Sankofl, 1998; Joshi, 1982). Code-switching specifically in social media has also received some recent attention. Lignos and Marcus (2013) trained a supervised token level language identification system for Spanish and English code-switched social media to study codeswitching behaviors. Ling et al. (2013) mined translation spans for Chinese and English in codeswitched documents to improve a translation system, relying on an existing translation model to aid in the identification and extraction task. In contrast to this work, we take an unsupervised approach, relying only on readily available document level language ID s</context>
</contexts>
<marker>Joshi, 1982</marker>
<rawString>Aravind K Joshi. 1982. Processing of sentences with intra-sentential code-switching. In Proceedings of the 9th Conference on Computational linguistics (COLING), pages 145–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben King</author>
<author>Steven Abney</author>
</authors>
<title>Labeling the languages of words in mixed-language documents using weakly supervised methods.</title>
<date>2013</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="6893" citStr="King and Abney, 2013" startWordPosition="1056" endWordPosition="1059">presentation we will refer to both as “documents.” 3 csLDA To train a polylingual topic model on social media, we make two modifications to the model of Mimno et al. (2009): add a token specific language variable, and a process for identifying aligned topics. First, polylingual topic models require parallel or comparable corpora in which each document has an assigned language. In the case of code-switched social media data, we require apertoken language variable. However, while document level language identification (LID) systems are common place, very few languages have pertoken LID systems (King and Abney, 2013; Lignos and Marcus, 2013). To address the lack of available LID systems, we add a per-token latent language variable to the polylingual topic model. For documents that are not code-switched, we observe these variables to be the output of a document level LID system. In the case of code-switched documents, these variables are inferred during model inference. Second, polylingual topic models assume the aligned topics are from parallel or comparable corpora, which implicitly assumes that a topics popularity is balanced across languages. Topics that show up in one language necessarily show up in </context>
</contexts>
<marker>King, Abney, 2013</marker>
<rawString>Ben King and Steven Abney. 2013. Labeling the languages of words in mixed-language documents using weakly supervised methods. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Li</author>
<author>Pascale Fung</author>
</authors>
<title>Code-switch language model with inversion constraints for mixed language speech recognition.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING 2012,</booktitle>
<pages>1671--1680</pages>
<location>Mumbai, India,</location>
<contexts>
<context position="4458" citStr="Li and Fung, 2012" startWordPosition="671" endWordPosition="674">ion for Computational Linguistics (Short Papers), pages 674–679, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Code-Switching Code-switched documents has received considerable attention in the NLP community. Several tasks have focused on identification and analysis, including mining translations in code-switched documents (Ling et al., 2013), predicting codeswitched points (Solorio and Liu, 2008a), identifying code-switched tokens (Lignos and Marcus, 2013; Yu et al., 2012; Elfardy and Diab, 2012), adding code-switched support to language models (Li and Fung, 2012), linguistic processing of code switched data (Solorio and Liu, 2008b), corpus creation (Li et al., 2012; Diab and Kamboj, 2011), and computational linguistic analyses and theories of code-switching (Sankofl, 1998; Joshi, 1982). Code-switching specifically in social media has also received some recent attention. Lignos and Marcus (2013) trained a supervised token level language identification system for Spanish and English code-switched social media to study codeswitching behaviors. Ling et al. (2013) mined translation spans for Chinese and English in codeswitched documents to improve a transl</context>
</contexts>
<marker>Li, Fung, 2012</marker>
<rawString>Ying Li and Pascale Fung. 2012. Code-switch language model with inversion constraints for mixed language speech recognition. In Proceedings of COLING 2012, pages 1671–1680, Mumbai, India, December. The COLING 2012 Organizing Committee.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ying Li</author>
<author>Yue Yu</author>
<author>Pascale Fung</author>
</authors>
<title>A mandarin-english code-switching corpus.</title>
<date>2012</date>
<booktitle>Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC-2012),</booktitle>
<pages>2515--2519</pages>
<editor>In Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Mehmet U˘gur Do˘gan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, editors,</editor>
<location>Istanbul, Turkey,</location>
<contexts>
<context position="4562" citStr="Li et al., 2012" startWordPosition="688" endWordPosition="691"> c�2014 Association for Computational Linguistics 2 Code-Switching Code-switched documents has received considerable attention in the NLP community. Several tasks have focused on identification and analysis, including mining translations in code-switched documents (Ling et al., 2013), predicting codeswitched points (Solorio and Liu, 2008a), identifying code-switched tokens (Lignos and Marcus, 2013; Yu et al., 2012; Elfardy and Diab, 2012), adding code-switched support to language models (Li and Fung, 2012), linguistic processing of code switched data (Solorio and Liu, 2008b), corpus creation (Li et al., 2012; Diab and Kamboj, 2011), and computational linguistic analyses and theories of code-switching (Sankofl, 1998; Joshi, 1982). Code-switching specifically in social media has also received some recent attention. Lignos and Marcus (2013) trained a supervised token level language identification system for Spanish and English code-switched social media to study codeswitching behaviors. Ling et al. (2013) mined translation spans for Chinese and English in codeswitched documents to improve a translation system, relying on an existing translation model to aid in the identification and extraction task.</context>
</contexts>
<marker>Li, Yu, Fung, 2012</marker>
<rawString>Ying Li, Yue Yu, and Pascale Fung. 2012. A mandarin-english code-switching corpus. In Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Mehmet U˘gur Do˘gan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC-2012), pages 2515–2519, Istanbul, Turkey, May. European Language Resources Association (ELRA). ACL Anthology Identifier: L12-1573.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Constantine Lignos</author>
<author>Mitch Marcus</author>
</authors>
<title>Toward web-scale analysis of codeswitching.</title>
<date>2013</date>
<booktitle>In Annual Meeting of the Linguistic</booktitle>
<publisher>Society of America.</publisher>
<contexts>
<context position="4347" citStr="Lignos and Marcus, 2013" startWordPosition="652" endWordPosition="655">analyses of social media that rely on our learned topics. 674 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 674–679, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Code-Switching Code-switched documents has received considerable attention in the NLP community. Several tasks have focused on identification and analysis, including mining translations in code-switched documents (Ling et al., 2013), predicting codeswitched points (Solorio and Liu, 2008a), identifying code-switched tokens (Lignos and Marcus, 2013; Yu et al., 2012; Elfardy and Diab, 2012), adding code-switched support to language models (Li and Fung, 2012), linguistic processing of code switched data (Solorio and Liu, 2008b), corpus creation (Li et al., 2012; Diab and Kamboj, 2011), and computational linguistic analyses and theories of code-switching (Sankofl, 1998; Joshi, 1982). Code-switching specifically in social media has also received some recent attention. Lignos and Marcus (2013) trained a supervised token level language identification system for Spanish and English code-switched social media to study codeswitching behaviors. L</context>
<context position="6919" citStr="Lignos and Marcus, 2013" startWordPosition="1060" endWordPosition="1064">efer to both as “documents.” 3 csLDA To train a polylingual topic model on social media, we make two modifications to the model of Mimno et al. (2009): add a token specific language variable, and a process for identifying aligned topics. First, polylingual topic models require parallel or comparable corpora in which each document has an assigned language. In the case of code-switched social media data, we require apertoken language variable. However, while document level language identification (LID) systems are common place, very few languages have pertoken LID systems (King and Abney, 2013; Lignos and Marcus, 2013). To address the lack of available LID systems, we add a per-token latent language variable to the polylingual topic model. For documents that are not code-switched, we observe these variables to be the output of a document level LID system. In the case of code-switched documents, these variables are inferred during model inference. Second, polylingual topic models assume the aligned topics are from parallel or comparable corpora, which implicitly assumes that a topics popularity is balanced across languages. Topics that show up in one language necessarily show up in another. However, in the c</context>
<context position="13332" citStr="Lignos and Marcus (2013)" startWordPosition="2166" endWordPosition="2169">n sampled an additional 2475 code-switched messages, 4221 English and 4211 Chinese messages as test data. Olympics We collected tweets from July 27, 2012 to August 12, 2012, and identified 302,775 tweets about the Olympics based on related hashtags and keywords (e.g. olympics, #london2012, etc.) We identified code-switched tweets using the Chromium Language Detector2. This system provides the top three possible languages for a given document with confidence scores; we identify a tweet as code-switched if two predicted languages each have confidence greater than 33%. We then used the tagger of Lignos and Marcus (2013) to obtain token level LID tags, and only tweets with tokens in both Spanish and English are used as code-switched tweets. In total we identified 822 Spanish-English code-switched tweets. We further expanded the mined tweets to full conversations, yielding 1055 Spanish-English codeswitched documents (including both tweets and conversations), along with 4007 English and 4421 Spanish tweets composes our data set. We reserve 10% of the data for testing. 5 Experiments We evaluated csLDA on the two datasets and evaluated each model using perplexity on held out data and human judgements. While our g</context>
<context position="15019" citStr="Lignos and Marcus, 2013" startWordPosition="2436" endWordPosition="2439">e csLDA duplicates topic distributions (T xL) we used twice as many topics for LDA. Figure 3 shows test perplexity for varying T and perplexity for the best setting of csLDA (T =60) and LDA (T=120). The table lists both monolingual and code-switched test data; csLDA improves over LDA in almost every case, and across all values of T . The background distribution (-bg) has mixed results for LDA, whereas for csLDA it shows consistent improvement. Table 4 shows some csLDA topics. While there are some mistakes, overall the topics are coherent and aligned. We use the available per-token LID system (Lignos and Marcus, 2013) for Spanish/English to justify csLDA’s ability to infer the hidden language variables. We ran csLDA-bg with lz set to the value provided by the LID system for codeswitched documents (csLDA-bg with LID), which gives csLDA high quality LID labels. While we see gains for the code-switched data, overall the results for csLDA-bg and csLDA-bg with LID are similar, suggesting that the model can operate effectively even without a supervised per-token LID system. 5.1 Human Evaluation We evaluate topic alignment quality through a human judgements (Chang et al., 2009). For each aligned topic, we show an</context>
</contexts>
<marker>Lignos, Marcus, 2013</marker>
<rawString>Constantine Lignos and Mitch Marcus. 2013. Toward web-scale analysis of codeswitching. In Annual Meeting of the Linguistic Society of America.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wang Ling</author>
<author>Guang Xiang</author>
<author>Chris Dyer</author>
<author>Alan Black</author>
<author>Isabel Trancoso</author>
</authors>
<title>Microblogs as parallel corpora.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting on Association for Computational Linguistics, ACL ’13. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3265" citStr="Ling et al., 2013" startWordPosition="493" endWordPosition="496"> comparable documents extracted from Wikipedia in different languages – fail to capture the specific terminology of social media. Alternate methods that rely on bilingual lexicons (Jagarlamudi and Daum´e, 2010) similarly fail to adapt to shifting vocabularies. The result: an inability to train polylingual models on social media. In this paper, we offer a solution: utilize codeswitched social media to discover correlations across languages. Social media is filled with examples of code-switching, where users switch between two or more languages, both in a conversation and even a single message (Ling et al., 2013). This mixture of languages in the same context suggests alignments between words across languages through the common topics discussed in the context. We learn from code-switched social media by extending the polylingual topic model framework to infer the language of each token and then automatically processing the learned topics to identify aligned topics. Our model improves both in terms of perplexity and a human evaluation, and we provide some example analyses of social media that rely on our learned topics. 674 Proceedings of the 52nd Annual Meeting of the Association for Computational Lin</context>
<context position="4964" citStr="Ling et al. (2013)" startWordPosition="743" endWordPosition="746">3; Yu et al., 2012; Elfardy and Diab, 2012), adding code-switched support to language models (Li and Fung, 2012), linguistic processing of code switched data (Solorio and Liu, 2008b), corpus creation (Li et al., 2012; Diab and Kamboj, 2011), and computational linguistic analyses and theories of code-switching (Sankofl, 1998; Joshi, 1982). Code-switching specifically in social media has also received some recent attention. Lignos and Marcus (2013) trained a supervised token level language identification system for Spanish and English code-switched social media to study codeswitching behaviors. Ling et al. (2013) mined translation spans for Chinese and English in codeswitched documents to improve a translation system, relying on an existing translation model to aid in the identification and extraction task. In contrast to this work, we take an unsupervised approach, relying only on readily available document level language ID systems to utilize code-switched data. Additionally, our focus is not on individual messages, rather we aim to train a model that can be used to analyze entire corpora. In this work we consider two types of codeswitched documents: single messages and conversations, and two langua</context>
<context position="12369" citStr="Ling et al., 2013" startWordPosition="2015" endWordPosition="2018"> a topic never occurs in a code-switched document, then there can be no evidence to support alignment across languages. For the topics that appear at least once in a codeswitched document, we estimate their probability γ ψd li α θd δ B zi bi φlz φlb T wi β N D L X nl,z −i + Wβ mz,d −i + α md −i + Tα (nl,z) + β wi −i 676 in the code-switched documents by a MAP estimate of θ. Topics appearing in at least one codeswitched document with probability greater than a threshold p are selected as candidates for true cross-language topics. 4 Data We used two datasets: a Sina Weibo ChineseEnglish corpus (Ling et al., 2013) and a SpanishEnglish Twitter corpus. Weibo Ling et al. (2013) extracted over 1m Chinese-English parallel segments from Sina Weibo, which are code-switched messages. We randomly sampled 29,705 code-switched messages along with 42,116 Chinese and 42,116 English messages from the the same time frame. We used these data for training. We then sampled an additional 2475 code-switched messages, 4221 English and 4211 Chinese messages as test data. Olympics We collected tweets from July 27, 2012 to August 12, 2012, and identified 302,775 tweets about the Olympics based on related hashtags and keywords</context>
</contexts>
<marker>Ling, Xiang, Dyer, Black, Trancoso, 2013</marker>
<rawString>Wang Ling, Guang Xiang, Chris Dyer, Alan Black, and Isabel Trancoso. 2013. Microblogs as parallel corpora. In Proceedings of the 51st Annual Meeting on Association for Computational Linguistics, ACL ’13. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Mimno</author>
<author>Hanna M Wallach</author>
<author>Jason Naradowsky</author>
<author>David A Smith</author>
<author>Andrew McCallum</author>
</authors>
<title>Polylingual topic models.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>2</volume>
<pages>880--889</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1481" citStr="Mimno et al., 2009" startWordPosition="214" endWordPosition="217">ei et al., 2003) have become standard tools for analyzing document collections, and topic analyses are quite common for social media (Paul and Dredze, 2011; Zhao et al., 2011; Hong and Davison, 2010; Ramage et al., 2010; Eisenstein et al., 2010). Their popularity owes in part to their data driven nature, allowing them to adapt to new corpora and languages. In social media especially, there is a large diversity in terms of both the topic and language, necessitating the modeling of multiple languages simultaneously. A good candidate for multi-lingual topic analyses are polylingual topic models (Mimno et al., 2009), which learn topics for multiple languages, creating tuples of language specific distributions over monolingual vocabularies for each topic. Polylingual topic models enable cross language analysis by grouping documents by topic regardless of language. Training of polylingual topic models requires parallel or comparable corpora: document tuples from multiple languages that discuss the same topic. While additional non-aligned documents User 1: ¡Don Samuel es un crack! #VamosM´exico #DaleTri RT @User4: Arriba! Viva Mexico! Advanced to GOLD. medal match in “Football”! User 2: @user1 rodo que tal </context>
<context position="6445" citStr="Mimno et al. (2009)" startWordPosition="985" endWordPosition="988"> tweets are code-switched and some are in a single language. By collecting the entire conversation into a single document we provide the topic model with additional content. An example of a Chinese-English code-switched messages is given by Ling et al. (2013): watup Kenny Mayne!! - Kenny Mayne 最近这么样啊!! Here a user switches between languages in a single message. We empirically evaluate our model on both conversations and messages. In the model presentation we will refer to both as “documents.” 3 csLDA To train a polylingual topic model on social media, we make two modifications to the model of Mimno et al. (2009): add a token specific language variable, and a process for identifying aligned topics. First, polylingual topic models require parallel or comparable corpora in which each document has an assigned language. In the case of code-switched social media data, we require apertoken language variable. However, while document level language identification (LID) systems are common place, very few languages have pertoken LID systems (King and Abney, 2013; Lignos and Marcus, 2013). To address the lack of available LID systems, we add a per-token latent language variable to the polylingual topic model. Fo</context>
<context position="8516" citStr="Mimno et al. (2009)" startWordPosition="1317" endWordPosition="1320">er. In this case, a polylingual topic model, which necessarily infers a topicspecific word distribution for each topic in each language, would learn two unrelated word distributions in two languages for a single topic. Therefore, naively using the produced topics as “aligned” across languages is ill-advised. Our solution is to automatically identify aligned polylingual topics after learning by examining a topic’s distribution across code-switched documents. Our metric relies on distributional properties of an inferred topic across the entire collection. 675 To summarize, based on the model of Mimno et al. (2009) we will learn: • For each topic, a language specific word distribution. • For each (code-switched) token, a language. • For each topic, an identification as to whether the topic captures an alignment across languages. The first two goals are achieved by incorporating new hidden variables in the traditional polylingual topic model. The third goal requires an automated post-processing step. We call the resulting model Code-Switched LDA (csLDA). The generative process is as follows: • For each topic z E T • For each language l E L • Draw word distribution φlz—Dir(βl) • For each document d E D: •</context>
</contexts>
<marker>Mimno, Wallach, Naradowsky, Smith, McCallum, 2009</marker>
<rawString>David Mimno, Hanna M Wallach, Jason Naradowsky, David A Smith, and Andrew McCallum. 2009. Polylingual topic models. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2-Volume 2, pages 880–889. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Paul</author>
<author>Mark Dredze</author>
</authors>
<title>You are what you tweet: Analyzing twitter for public health.</title>
<date>2011</date>
<booktitle>In ICWSM.</booktitle>
<contexts>
<context position="1017" citStr="Paul and Dredze, 2011" startWordPosition="136" endWordPosition="139">aligned topics across languages. We present Code-Switched LDA (csLDA), which infers language specific topic distributions based on code-switched documents to facilitate multi-lingual corpus analysis. We experiment on two code-switching corpora (English-Spanish Twitter data and English-Chinese Weibo data) and show that csLDA improves perplexity over LDA, and learns semantically coherent aligned topics as judged by human annotators. 1 Introduction Topic models (Blei et al., 2003) have become standard tools for analyzing document collections, and topic analyses are quite common for social media (Paul and Dredze, 2011; Zhao et al., 2011; Hong and Davison, 2010; Ramage et al., 2010; Eisenstein et al., 2010). Their popularity owes in part to their data driven nature, allowing them to adapt to new corpora and languages. In social media especially, there is a large diversity in terms of both the topic and language, necessitating the modeling of multiple languages simultaneously. A good candidate for multi-lingual topic analyses are polylingual topic models (Mimno et al., 2009), which learn topics for multiple languages, creating tuples of language specific distributions over monolingual vocabularies for each t</context>
</contexts>
<marker>Paul, Dredze, 2011</marker>
<rawString>Michael J Paul and Mark Dredze. 2011. You are what you tweet: Analyzing twitter for public health. In ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellie Pavlick</author>
<author>Matt Post</author>
<author>Ann Irvine</author>
<author>Dmitry Kachaev</author>
<author>Chris Callison-Burch</author>
</authors>
<title>The language demographics of Amazon Mechanical Turk. Transactions of the Association for Computational Linguistics,</title>
<date>2014</date>
<contexts>
<context position="18545" citStr="Pavlick et al., 2014" startWordPosition="3012" endWordPosition="3015"> also used a threshold p (§3.2) to select aligned topics in csLDA. To ensure a fair comparison, we select the same number of aligned topics for LDA and csLDA.3. We used the best performing setting: csLDA T=60, LDA T=120, which produced 12 alignments from Olympics and 28 from Weibo. Using Mechanical Turk we collected multiple judgements per alignment. For Spanish, we removed workers who disagreed with the majority more than 50% of the time (83 deletions), leaving 6.5 annotations for each alignment (85.47% inter-annotator agreement.) For Chinese, since quality of general Chinese turkers is low (Pavlick et al., 2014) we invited specific workers and obtained 9.3 annotations per alignment (78.72% inter-annotator agreement.) For Olympics, LDA alignments matched the judgements 25% of the time, while csLDA matched 50% of the time. While csLDA found 12 alignments and LDA 29, the 12 topics evaluated from both models show that csLDA’s alignments are higher quality. For the Weibo data, LDA matched judgements 71.4%, while csLDA matched 75%. Both obtained high 3We used thresholds p = 0.2 and t = 0.0001. We limited the model with more alignments to match the one with less. quality alignments – likely due both to the </context>
</contexts>
<marker>Pavlick, Post, Irvine, Kachaev, Callison-Burch, 2014</marker>
<rawString>Ellie Pavlick, Matt Post, Ann Irvine, Dmitry Kachaev, and Chris Callison-Burch. 2014. The language demographics of Amazon Mechanical Turk. Transactions of the Association for Computational Linguistics, 2(Feb):79–92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Ramage</author>
<author>Susan T Dumais</author>
<author>Daniel J Liebling</author>
</authors>
<title>Characterizing microblogs with topic models.</title>
<date>2010</date>
<booktitle>In ICWSM.</booktitle>
<contexts>
<context position="1081" citStr="Ramage et al., 2010" startWordPosition="148" endWordPosition="151">DA), which infers language specific topic distributions based on code-switched documents to facilitate multi-lingual corpus analysis. We experiment on two code-switching corpora (English-Spanish Twitter data and English-Chinese Weibo data) and show that csLDA improves perplexity over LDA, and learns semantically coherent aligned topics as judged by human annotators. 1 Introduction Topic models (Blei et al., 2003) have become standard tools for analyzing document collections, and topic analyses are quite common for social media (Paul and Dredze, 2011; Zhao et al., 2011; Hong and Davison, 2010; Ramage et al., 2010; Eisenstein et al., 2010). Their popularity owes in part to their data driven nature, allowing them to adapt to new corpora and languages. In social media especially, there is a large diversity in terms of both the topic and language, necessitating the modeling of multiple languages simultaneously. A good candidate for multi-lingual topic analyses are polylingual topic models (Mimno et al., 2009), which learn topics for multiple languages, creating tuples of language specific distributions over monolingual vocabularies for each topic. Polylingual topic models enable cross language analysis by</context>
</contexts>
<marker>Ramage, Dumais, Liebling, 2010</marker>
<rawString>Daniel Ramage, Susan T Dumais, and Daniel J Liebling. 2010. Characterizing microblogs with topic models. In ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michal Rosen-Zvi</author>
<author>Thomas Griffiths</author>
<author>Mark Steyvers</author>
<author>Padhraic Smyth</author>
</authors>
<title>The author-topic model for authors and documents.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th conference on Uncertainty in artificial intelligence,</booktitle>
<pages>487--494</pages>
<publisher>AUAI Press.</publisher>
<marker>Rosen-Zvi, Griffiths, Steyvers, Smyth, 2004</marker>
<rawString>Michal Rosen-Zvi, Thomas Griffiths, Mark Steyvers, and Padhraic Smyth. 2004. The author-topic model for authors and documents. In Proceedings of the 20th conference on Uncertainty in artificial intelligence, pages 487–494. AUAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Sankofl</author>
</authors>
<title>The production of code-mixed discourse.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>8--21</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montreal, Quebec, Canada,</location>
<contexts>
<context position="4671" citStr="Sankofl, 1998" startWordPosition="704" endWordPosition="705">rable attention in the NLP community. Several tasks have focused on identification and analysis, including mining translations in code-switched documents (Ling et al., 2013), predicting codeswitched points (Solorio and Liu, 2008a), identifying code-switched tokens (Lignos and Marcus, 2013; Yu et al., 2012; Elfardy and Diab, 2012), adding code-switched support to language models (Li and Fung, 2012), linguistic processing of code switched data (Solorio and Liu, 2008b), corpus creation (Li et al., 2012; Diab and Kamboj, 2011), and computational linguistic analyses and theories of code-switching (Sankofl, 1998; Joshi, 1982). Code-switching specifically in social media has also received some recent attention. Lignos and Marcus (2013) trained a supervised token level language identification system for Spanish and English code-switched social media to study codeswitching behaviors. Ling et al. (2013) mined translation spans for Chinese and English in codeswitched documents to improve a translation system, relying on an existing translation model to aid in the identification and extraction task. In contrast to this work, we take an unsupervised approach, relying only on readily available document level</context>
</contexts>
<marker>Sankofl, 1998</marker>
<rawString>David Sankofl. 1998. The production of code-mixed discourse. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1, pages 8–21, Montreal, Quebec, Canada, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thamar Solorio</author>
<author>Yang Liu</author>
</authors>
<title>Learning to predict code-switching points.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>973--981</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="4286" citStr="Solorio and Liu, 2008" startWordPosition="644" endWordPosition="647">lexity and a human evaluation, and we provide some example analyses of social media that rely on our learned topics. 674 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 674–679, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Code-Switching Code-switched documents has received considerable attention in the NLP community. Several tasks have focused on identification and analysis, including mining translations in code-switched documents (Ling et al., 2013), predicting codeswitched points (Solorio and Liu, 2008a), identifying code-switched tokens (Lignos and Marcus, 2013; Yu et al., 2012; Elfardy and Diab, 2012), adding code-switched support to language models (Li and Fung, 2012), linguistic processing of code switched data (Solorio and Liu, 2008b), corpus creation (Li et al., 2012; Diab and Kamboj, 2011), and computational linguistic analyses and theories of code-switching (Sankofl, 1998; Joshi, 1982). Code-switching specifically in social media has also received some recent attention. Lignos and Marcus (2013) trained a supervised token level language identification system for Spanish and English c</context>
</contexts>
<marker>Solorio, Liu, 2008</marker>
<rawString>Thamar Solorio and Yang Liu. 2008a. Learning to predict code-switching points. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 973–981, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thamar Solorio</author>
<author>Yang Liu</author>
</authors>
<title>Part-of-Speech tagging for English-Spanish code-switched text.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1051--1060</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="4286" citStr="Solorio and Liu, 2008" startWordPosition="644" endWordPosition="647">lexity and a human evaluation, and we provide some example analyses of social media that rely on our learned topics. 674 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 674–679, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Code-Switching Code-switched documents has received considerable attention in the NLP community. Several tasks have focused on identification and analysis, including mining translations in code-switched documents (Ling et al., 2013), predicting codeswitched points (Solorio and Liu, 2008a), identifying code-switched tokens (Lignos and Marcus, 2013; Yu et al., 2012; Elfardy and Diab, 2012), adding code-switched support to language models (Li and Fung, 2012), linguistic processing of code switched data (Solorio and Liu, 2008b), corpus creation (Li et al., 2012; Diab and Kamboj, 2011), and computational linguistic analyses and theories of code-switching (Sankofl, 1998; Joshi, 1982). Code-switching specifically in social media has also received some recent attention. Lignos and Marcus (2013) trained a supervised token level language identification system for Spanish and English c</context>
</contexts>
<marker>Solorio, Liu, 2008</marker>
<rawString>Thamar Solorio and Yang Liu. 2008b. Part-of-Speech tagging for English-Spanish code-switched text. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 1051–1060, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hanna M Wallach</author>
<author>David M Mimno</author>
<author>Andrew McCallum</author>
</authors>
<title>Rethinking lda: Why priors matter.</title>
<date>2009</date>
<booktitle>In NIPS,</booktitle>
<volume>22</volume>
<pages>1973--1981</pages>
<contexts>
<context position="9719" citStr="Wallach et al., 2009" startWordPosition="1537" endWordPosition="1540"> document d E D: • Draw a topic distribution θd — Dir(α) • Draw a language distribution ψd—Dir(γ) • For each token i E d: • Draw a topic zi — θd • Draw a language li — ψd • Draw a word wi — φlz For monolingual documents, we fix li to the LID tag for all tokens. Additionally, we use a single background distribution for each language to capture stopwords; a control variable π, which follows a Dirichlet distribution with prior parameterized by δ, is introduced to decide the choice between background words and topic words following (Chemudugunta et al., 2006)1. We use asymmetric Dirichlet priors (Wallach et al., 2009), and let the optimization process learn the hyperparameters. The graphical model is shown in Figure 2. 3.1 Inference Inference for csLDA follows directly from LDA. A Gibbs sampler learns the word distributions φlz for each language and topic. We use a block Gibbs sampler to jointly sample topic and language variables for each token. As is customary, we collapse out φ, θ and ψ. The sampling posterior is: P(zi, li|w, z−i, l−i, α, β, γ) a ol,d−i + γ X (1) od−i + Gγ where (nl,z )−i is the number of times the type for wi word wi assigned to topic z and language l (ex1Omitted from the generative pr</context>
</contexts>
<marker>Wallach, Mimno, McCallum, 2009</marker>
<rawString>Hanna M Wallach, David M Mimno, and Andrew McCallum. 2009. Rethinking lda: Why priors matter. In NIPS, volume 22, pages 1973–1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang-Chih Yu</author>
<author>Wei-Cheng He</author>
<author>Wei-Nan Chien</author>
</authors>
<title>A language modeling approach to identifying code-switched sentences and words.</title>
<date>2012</date>
<booktitle>In Proceedings of the Second CIPS-SIGHAN Joint Conference on Chinese Language Processing,</booktitle>
<pages>3--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Tianjin, China,</location>
<contexts>
<context position="4364" citStr="Yu et al., 2012" startWordPosition="656" endWordPosition="659">that rely on our learned topics. 674 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 674–679, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 Code-Switching Code-switched documents has received considerable attention in the NLP community. Several tasks have focused on identification and analysis, including mining translations in code-switched documents (Ling et al., 2013), predicting codeswitched points (Solorio and Liu, 2008a), identifying code-switched tokens (Lignos and Marcus, 2013; Yu et al., 2012; Elfardy and Diab, 2012), adding code-switched support to language models (Li and Fung, 2012), linguistic processing of code switched data (Solorio and Liu, 2008b), corpus creation (Li et al., 2012; Diab and Kamboj, 2011), and computational linguistic analyses and theories of code-switching (Sankofl, 1998; Joshi, 1982). Code-switching specifically in social media has also received some recent attention. Lignos and Marcus (2013) trained a supervised token level language identification system for Spanish and English code-switched social media to study codeswitching behaviors. Ling et al. (2013)</context>
</contexts>
<marker>Yu, He, Chien, 2012</marker>
<rawString>Liang-Chih Yu, Wei-Cheng He, and Wei-Nan Chien. 2012. A language modeling approach to identifying code-switched sentences and words. In Proceedings of the Second CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 3–8, Tianjin, China, December. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wayne Xin Zhao</author>
<author>Jing Jiang</author>
<author>Jianshu Weng</author>
<author>Jing He</author>
<author>Ee-Peng Lim</author>
<author>Hongfei Yan</author>
<author>Xiaoming Li</author>
</authors>
<title>Comparing twitter and traditional media using topic models.</title>
<date>2011</date>
<booktitle>In Advances in Information Retrieval,</booktitle>
<pages>338--349</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1036" citStr="Zhao et al., 2011" startWordPosition="140" endWordPosition="143">anguages. We present Code-Switched LDA (csLDA), which infers language specific topic distributions based on code-switched documents to facilitate multi-lingual corpus analysis. We experiment on two code-switching corpora (English-Spanish Twitter data and English-Chinese Weibo data) and show that csLDA improves perplexity over LDA, and learns semantically coherent aligned topics as judged by human annotators. 1 Introduction Topic models (Blei et al., 2003) have become standard tools for analyzing document collections, and topic analyses are quite common for social media (Paul and Dredze, 2011; Zhao et al., 2011; Hong and Davison, 2010; Ramage et al., 2010; Eisenstein et al., 2010). Their popularity owes in part to their data driven nature, allowing them to adapt to new corpora and languages. In social media especially, there is a large diversity in terms of both the topic and language, necessitating the modeling of multiple languages simultaneously. A good candidate for multi-lingual topic analyses are polylingual topic models (Mimno et al., 2009), which learn topics for multiple languages, creating tuples of language specific distributions over monolingual vocabularies for each topic. Polylingual t</context>
</contexts>
<marker>Zhao, Jiang, Weng, He, Lim, Yan, Li, 2011</marker>
<rawString>Wayne Xin Zhao, Jing Jiang, Jianshu Weng, Jing He, Ee-Peng Lim, Hongfei Yan, and Xiaoming Li. 2011. Comparing twitter and traditional media using topic models. In Advances in Information Retrieval, pages 338–349. Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>