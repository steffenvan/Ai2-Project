<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009339">
<title confidence="0.997234">
Aspect Ranking: Identifying Important Product Aspects from Online
Consumer Reviews
</title>
<author confidence="0.999214">
Jianxing Yu, Zheng-Jun Zha, Meng Wang, Tat-Seng Chua
</author>
<affiliation confidence="0.9994275">
School of Computing
National University of Singapore
</affiliation>
<email confidence="0.989697">
{jianxing, zhazj, wangm, chuats}@comp.nus.edu.sg
</email>
<sectionHeader confidence="0.99556" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99978212">
In this paper, we dedicate to the topic of aspect
ranking, which aims to automatically identify
important product aspects from online con-
sumer reviews. The important aspects are
identified according to two observations: (a)
the important aspects of a product are usually
commented by a large number of consumers;
and (b) consumers’ opinions on the important
aspects greatly influence their overall opin-
ions on the product. In particular, given con-
sumer reviews of a product, we first identify
the product aspects by a shallow dependency
parser and determine consumers’ opinions on
these aspects via a sentiment classifier. We
then develop an aspect ranking algorithm to
identify the important aspects by simultane-
ously considering the aspect frequency and
the influence of consumers’ opinions given to
each aspect on their overall opinions. The ex-
perimental results on 11 popular products in
four domains demonstrate the effectiveness of
our approach. We further apply the aspect
ranking results to the application of document-
level sentiment classification, and improve the
performance significantly.
</bodyText>
<sectionHeader confidence="0.999338" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999781142857143">
The rapidly expanding e-commerce has facilitated
consumers to purchase products online. More than
$156 million online product retail sales have been
done in the US market during 2009 (Forrester Re-
search, 2009). Most retail Web sites encourage con-
sumers to write reviews to express their opinions on
various aspects of the products. This gives rise to
</bodyText>
<figureCaption confidence="0.997704">
Figure 1: Sample reviews on iPhone 3GS product
</figureCaption>
<bodyText confidence="0.999940826086957">
huge collections of consumer reviews on the Web.
These reviews have become an important resource
for both consumers and firms. Consumers com-
monly seek quality information from online con-
sumer reviews prior to purchasing a product, while
many firms use online consumer reviews as an im-
portant resource in their product development, mar-
keting, and consumer relationship management. As
illustrated in Figure 1, most online reviews express
consumers’ overall opinion ratings on the product,
and their opinions on multiple aspects of the prod-
uct. While a product may have hundreds of aspects,
we argue that some aspects are more important than
the others and have greater influence on consumers’
purchase decisions as well as firms’ product devel-
opment strategies. Take iPhone 3GS as an exam-
ple, some aspects like “battery” and “speed,” are
more important than the others like “moisture sen-
sor.” Generally, identifying the important product
aspects will benefit both consumers and firms. Con-
sumers can conveniently make wise purchase deci-
sion by paying attentions on the important aspects,
while firms can focus on improving the quality of
</bodyText>
<page confidence="0.931767">
1496
</page>
<note confidence="0.979221">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1496–1505,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.965462695652174">
these aspects and thus enhance the product reputa- periments on 11 popular products in four domains.
tion effectively. However, it is impractical for people The consumer reviews on these products are crawled
to identify the important aspects from the numerous from the prevalent forum Web sites (e.g., cnet.com
reviews manually. Thus, it becomes a compelling and viewpoint.com etc.) More details of our review
need to automatically identify the important aspects corpus are discussed in Section 3. The experimen-
from consumer reviews. tal results demonstrate the effectiveness of our ap-
A straightforward solution for important aspect proach on important aspects identification. Further-
identification is to select the aspects that are fre- more, we apply the aspect ranking results to the ap-
quently commented in consumer reviews as the im- plication of document-level sentiment classification
portant ones. However, consumers’ opinions on by carrying out the term-weighting based on the as-
the frequent aspects may not influence their over- pect importance. The results show that our approach
all opinions on the product, and thus not influence can improve the performance significantly.
consumers’ purchase decisions. For example, most The main contributions of this paper include,
consumers frequently criticize the bad “signal con- 1) We dedicate to the topic of aspect ranking,
nection” of iPhone 4, but they may still give high which aims to automatically identify important as-
overall ratings to iPhone 4. On the other hand, pects of a product from consumer reviews.
some aspects, such as “design” and “speed,” may not 2) We develop an aspect ranking algorithm to
be frequently commented, but usually more impor- identify the important aspects by simultaneously
tant than “signal connection.” Hence, the frequency- considering the aspect frequency and the influence
based solution is not able to identify the truly impor- of consumers’ opinions given to each aspect on their
tant aspects. overall opinions.
Motivated by the above observations, in this pa- 3) We apply aspect ranking results to the applica-
per, we propose an effective approach to automat- tion of document-level sentiment classification, and
ically identify the important product aspects from improve the performance significantly.
consumer reviews. Our assumption is that the There is another work named aspect ranking
important aspects of a product should be the as- (Snyder et al., 2007). The task in this work is differ-
pects that are frequently commented by consumers, ent from ours. This work mainly focuses on predict-
and consumers’ opinions on the important aspects ing opinionated ratings on aspects rather than iden-
greatly influence their overall opinions on the prod- tifying important aspects.
uct. Given the online consumer reviews of a spe- The rest of this paper is organized as follows. Sec-
cific product, we first identify the aspects in the re- tion 2 elaborates our aspect ranking approach. Sec-
views using a shallow dependency parser (Wu et al., tion 3 presents the experimental results, while Sec-
2009), and determine consumers’ opinions on these tion 4 introduces the application of document-level
aspects via a sentiment classifier. We then design an sentiment classification. Section 5 reviews related
aspect ranking algorithm to identify the important work and Section 6 concludes this paper with future
aspects by simultaneously taking into account the works.
aspect frequency and the influence of consumers’ 2 Aspect Ranking Framework
opinions given to each aspect on their overall opin- In this section, we first present some notations and
ions. Specifically, we assume that consumer’s over- then elaborate the key components of our approach,
all opinion rating on a product is generated based including the aspect identification, sentiment classi-
on a weighted sum of his/her specific opinions on fication, and aspect ranking algorithm.
multiple aspects of the product, where the weights 2.1 Notations and Problem Formulation
essentially measure the degree of importance of the Let R = {ri, · · · , rjj,j} denotes a set of online con-
aspects. A probabilistic regression algorithm is then sumer reviews of a specific product. Each review
developed to derive these importance weights by r E R is associated with an overall opinion rating
leveraging the aspect frequency and the consistency
between the overall opinions and the weighted sum
of opinions on various aspects. We conduct ex-
1497
Or, and covers several aspects with consumer com- unigram feature.
ments on these aspects. Suppose there are m aspects 2.3 Aspect Sentiment Classification
A = {a1, · · · , am} involved in the review corpus Since the Pros and Cons reviews explicitly express
R, where ak is the k-th aspect. We define ork as the positive and negative opinions on the aspects, re-
opinion on aspect ak in review r. We assume that spectively, our task is to determine the opinions in
the overall opinion rating Or is generated based on free text reviews. To this end, we here utilize Pros
a weighted sum of the opinions on specific aspects and Cons reviews to train a SVM sentiment classifier.
offrk (Wang et al., 2010). The weights are denoted as Specifically, we collect sentiment terms in the Pros
lwrk}mk=1, each of which essentially measures the and Cons reviews as features and represent each re-
degree of importance of the aspect ak in review r. view into feature vector using Boolean weighting.
Our task is to derive the important weights of as- Note that we select sentiment terms as those appear
pects, and identify the important aspects. in the sentiment lexicon provided by MPQA project
Next, we will introduce the key components of (Wilson et al., 2005). With these features, we then
our approach, including aspect identification that train a SVM classifier based on Pros and Cons re-
identifies the aspects ak in each review r, aspect sen- views. Given a free text review, since it may cover
timent classification which determines consumers’ various opinions on multiple aspects, we first locate
opinions ork on various aspects, and aspect ranking the opinionated expression modifying each aspect,
algorithm that identifies the important aspects. and determine the opinion on the aspect using the
2.2 Aspect Identification learned SVM classifier. In particular, since the opin-
As illustrated in Figure 1, there are usually two types ionated expression on each aspect tends to contain
of reviews, Pros and Cons review and free text re- sentiment terms and appear closely to the aspect (Hu
views on the Web. For Pros and Cons reviews, the and Liu, 2004), we select the expressions which con-
aspects are identified as the frequent noun terms in tain sentiment terms and are at the distance of less
the reviews, since the aspects are usually noun or than 5 from the aspect NP in the parsing tree.
noun phrases (Liu, 2009), and it has been shown 2.4 Aspect Ranking
that simply extracting the frequent noun terms from Generally, consumer’s opinion on each specific as-
the Pros and Cons reviews can get high accurate pect in the review influences his/her overall opin-
aspect terms (Liu el al., 2005). To identify the as- ion on the product. Thus, we assume that the con-
pects in free text reviews, we first parse each review sumer gives the overall opinion rating Or based on
using the Stanford parser 1, and extract the noun the weighted sum of his/her opinion ork on each as-
phrases (NP) from the parsing tree as aspect can- pect ak: Emk=1 wrkork, which can be rewritten as
didates. While these candidates may contain much ωrT or, where ωr and or are the weight and opinion
noise, we leverage the Pros and Cons reviews to vectors. Inspired by the work of Wang et al. (2010),
assist identify aspects from the candidates. In par- we view Or as a sample drawn from a Gaussian Dis-
ticular, we explore the frequent noun terms in Pros tribution, with mean ωrTor and variance σ2,
and Cons reviews as features, and train a one-class 1 exp[−(Or − ωrT or)2
SVM (Manevitz et al., 2002) to identify aspects in p(Or) = √ (1)
the candidates. While the obtained aspects may con- 2πσ2 2σ2
tain some synonym terms, such as “earphone” and To model the uncertainty of the importance
“headphone,” we further perform synonym cluster- weights ωr in each review, we assume ωr as a sam-
ing to get unique aspects. Specifically, we first ex- ple drawn from a Multivariate Gaussian Distribu-
pand each aspect term with its synonym terms ob- tion, with µ as the mean vector and E as the covari-
tained from the synonym terms Web site 2, and then ance matrix,
cluster the terms to obtain unique aspects based on 1
p(wr) _ (2�)��2|�|1�2 exp[−2(wr − µ)T 1(wr − µ)].
1
(2)
lhttp://nlp.stanford.edu/software/lex-parser.shtml
zhttp://thesaurus.com
1498
We further incorporate aspect frequency as a prior
knowledge to define the distribution of µ and Σ.
Specifically, the distribution of µ and Σ is defined
based on its Kullback-Leibler (KL) divergence to a
prior distribution with a mean vector µ0 and an iden-
tity covariance matrix I in Eq.3. Each element in µ0
is defined as the frequency of the corresponding as-
pect: frequency(ak)/ ∑mi=1 frequency(ai).
p(µ, Σ) = exp[−cp · KL(Q(µ, Σ)||Q(µ0, I))],
(3)
where KL(·, ·) is the KL divergence, Q(µ, Σ) de-
notes a Multivariate Gaussian Distribution, and cp is
a tradeoff parameter.
Base on the above definition, the probability of
generating the overall opinion rating Or on review r
is given as,
</bodyText>
<equation confidence="0.9988795">
p(Or|Ψ, r) = ∫ p(Or|ωrTor, U2) ·(4)
p(ωr  |µ, Σ) · p(µ, Σ)dωr,
</equation>
<bodyText confidence="0.999697666666667">
where Ψ = {ω, µ, Σ, U2} are the model parameters.
Next, we utilize Maximum Log-likelihood (ML)
to estimate the model parameters given the con-
sumer reviews corpus. In particular, we aim to find
an optimal Ψˆ to maximize the probability of observ-
ing the overall opinion ratings in the reviews corpus.
</bodyText>
<equation confidence="0.997146">
Ψˆ = arg max
Ψ
= arg min
Ψ (|R |− 1) log det(Σ) + ∑ [log U2+
r∈R
(Or−rT or)2 + (ωr − µ)T Σ−1(ωr − µ)]+
σ2
(tr(Σ) + (µ0 − µ)TI(µ0 − µ)).
</equation>
<bodyText confidence="0.9953276">
For the sake of simplicity, we denote the objective
function ∑r∈R lo9(p(Or|Ψ, r)) as Γ(Ψ).
The derivative of the objective function with re-
spect to each model parameter vanishes at the mini-
mizer:
</bodyText>
<equation confidence="0.98366952631579">
∂Γ(Ψ)= −(rT or−Or)or − Σ−1(ωr − µ)
∂r σ2
= 0;
[−Σ−1(ωr − µ)] − cp · I(µ0 − µ)
{−(Σ−1)T − [−(Σ−1)T(ωr − µ)
(ωr − µ)T (Σ−1)T]} + cp · [(Σ−1)T − I] = 0; (8)
∂Γ(Ψ)
∂σ2 = ∑ (−σ2 1 + (Or−rT or)2 σ4 ) = 0,
r∈R
(9)
which lead to the following solutions:
ˆωr = (ororT
σ2 + Σ−1)−1(Oror σ2+ Σ−1µ);
(12)
ˆU2 =1
|R |r∈R
∑ (Or − ωr or)
T 2
(13)
</equation>
<bodyText confidence="0.999300538461538">
We can see that the above parameters are involved
in each other’s solution. We here utilize Alternating
Optimization technique to derive the optimal param-
eters in an iterative manner. We first hold the param-
eters µ, Σ and U2 fixed and update the parameters
ωr for each review r ∈ R. Then, we update the
parameters µ, Σ and U2 with fixed ωr (r ∈ R).
These two steps are alternatively iterated until the
Eq.5 converges. As a result, we obtain the optimal
importance weights ωr which measure the impor-
tance of aspects in review r ∈ R. We then compute
the final importance score ϖk for each aspect ak by
integrating its importance score in all the reviews as,
</bodyText>
<equation confidence="0.954523">
ϖk = |R |∑r∈R ωrk, k = 1,··· ,m (14)
1
</equation>
<bodyText confidence="0.99991975">
It is worth noting that the aspect frequency is con-
sidered again in this integration process. According
to the importance score ϖk, we can identify impor-
tant aspects.
</bodyText>
<sectionHeader confidence="0.997202" genericHeader="method">
3 Evaluations
</sectionHeader>
<bodyText confidence="0.999555">
In this section, we evaluate the effectiveness of our
approach on aspect identification, sentiment classi-
fication, and aspect ranking.
</bodyText>
<subsectionHeader confidence="0.997802">
3.1 Data and Experimental Setting
</subsectionHeader>
<bodyText confidence="0.999966333333333">
The details of our product review data set is given
in Table 1. This data set contains consumer reviews
on 11 popular products in 4 domains. These reviews
were crawled from the prevalent forum Web sites,
including cnet.com, viewpoints.com, reevoo.com
and gsmarena.com. All of the reviews were posted
</bodyText>
<equation confidence="0.995179">
∑ lo9(p(Or|Ψ, r))
r∈R
∂Γ(Ψ)
∂µ = ∑ r∈R
= 0;
∂Γ(Ψ) = ∑
∂E
r∈R
µˆ = (|R|Σ−1+ cp · I)−1(Σ−1 ∑ ωr + cp · Iµ0);
r∈R
∑ [(ωr − µ)(ωr − µ)T] +
Σˆ = {[φ 1
r∈R
(|R|−φ)2I]1/2 − (|R|−φ)I}T;
2φ 2φ
</equation>
<page confidence="0.968442">
1499
</page>
<bodyText confidence="0.99822425">
between June, 2009 and Sep 2010. The aspects of
the reviews, as well as the opinions on the aspects
were manually annotated as the gold standard for
evaluations.
</bodyText>
<table confidence="0.999822083333333">
Product Name Domain Review# Sentence#
Canon EOS 450D (Canon EOS) camera 440 628
Fujifilm Finepix AX245W (Fujifilm) camera 541 839
Panasonic Lumix DMC-TZ7 (Panasonic) camera 650 1,546
Apple MacBook Pro (MacBook) laptop 552 4,221
Samsung NC10 (Samsung) laptop 2,712 4,946
Apple iPod Touch 2nd (iPod Touch) MP3 4,567 10,846
Sony NWZ-S63916GB (Sony NWZ) MP3 341 773
BlackBerry Bold 9700 (BlackBerry) phone 4,070 11,008
iPhone 3GS 16GB (iPhone 3GS) phone 12,418 43,527
Nokia 5800 XpressMusic (Nokia 5800) phone 28,129 75,001
Nokia N95 phone 15,939 44,379
</table>
<tableCaption confidence="0.9907655">
Table 1: Statistics of the Data Sets, # denotes the size of
the reviews/sentences.
</tableCaption>
<bodyText confidence="0.9919108">
To examine the performance on aspect identifi-
cation and sentiment classification, we employed
F1-measure, which was the combination of preci-
sion and recall, as the evaluation metric. To evalu-
ate the performance on aspect ranking, we adopted
</bodyText>
<listItem confidence="0.53900825">
Normalized Discounted Cumulative Gain at top k
(NDCG@k) (Jarvelin and Kekalainen, 2002) as the
performance metric. Given an aspect ranking list
a1, · · · , ak, NDCG@k is calculated by
</listItem>
<equation confidence="0.999366">
2t(Z) − 1 (15)
log(1 + i),
</equation>
<bodyText confidence="0.999946043478261">
where t(i) is the function that represents the reward
given to the aspect at position i, Z is a normaliza-
tion term derived from the top k aspects of a perfect
ranking, so as to normalize NDCG@k to be within
[0, 1]. This evaluation metric will favor the ranking
which ranks the most important aspects at the top.
For the reward t(i), we labeled each aspect as one of
the three scores: Un-important (score 1), Ordinary
(score 2) and Important (score 3). Three volunteers
were invited in the annotation process as follows.
We first collected the top k aspects in all the rank-
ings produced by various evaluated methods (maxi-
mum k is 15 in our experiment). We then sampled
some reviews covering these aspects, and provided
the reviews to each annotator to read. Each review
contains the overall opinion rating, the highlighted
aspects, and opinion terms. Afterward, the annota-
tors were required to assign an importance score to
each aspect. Finally, we took the average of their
scorings as the corresponding importance scores of
the aspects. In addition, there is only one parameter
(p that needs to be tuned in our approach. Through-
out the experiments, we empirically set (p as 0.001.
</bodyText>
<subsectionHeader confidence="0.999063">
3.2 Evaluations on Aspect Identification
</subsectionHeader>
<bodyText confidence="0.998433928571429">
We compared our aspect identification approach
against two baselines: a) the method proposed by
Hu and Liu (2004), which was based on the asso-
ciation rule mining, and b) the method proposed by
Wu et al. (2009), which was based on a dependency
parser.
The results are presented in Table 2. On average,
our approach significantly outperforms Hu’s method
and Wu’ method in terms of F1-measure by over
5.87% and 3.27%, respectively. In particular, our
approach obtains high precision. Such results imply
that our approach can accurately identify the aspects
from consumer reviews by leveraging the Pros and
Cons reviews.
</bodyText>
<table confidence="0.99987475">
Data set Hu’s Method Wu’s Method Our Method
Canon EOS 0.681 0.686 0.728
Fujifilm 0.685 0.666 0.710
Panasonic 0.636 0.661 0.706
MacBook 0.680 0.733 0.747
Samsung 0.594 0.631 0.712
iPod Touch 0.650 0.660 0.718
Sony NWZ 0.631 0.692 0.760
BlackBerry 0.721 0.730 0.734
iPhone 3GS 0.697 0.736 0.740
Nokia 5800 0.715 0.745 0.747
Nokia N95 0.700 0.737 0.741
</table>
<tableCaption confidence="0.9917705">
Table 2: Evaluations on Aspect Identification. * signifi-
cant t-test, p-values&lt;0.05.
</tableCaption>
<subsectionHeader confidence="0.997037">
3.3 Evaluations on Sentiment Classification
</subsectionHeader>
<bodyText confidence="0.998064666666667">
In this experiment, we implemented the follow-
ing sentiment classification methods (Pang and Lee,
2008):
</bodyText>
<listItem confidence="0.9961687">
1) Unsupervised method. We employed one un-
supervised method which was based on opinion-
ated term counting via SentiWordNet (Ohana et al.,
2009).
2) Supervised method. We employed three su-
pervised methods proposed in Pang et al. (2002),
including Naive Bayes (NB), Maximum Entropy
(ME), SVM. These classifiers were trained based on
the Pros and Cons reviews as described in Section
2.3.
</listItem>
<equation confidence="0.9732335">
1
NDCG@k = Z
k
Z=1
</equation>
<page confidence="0.769816">
1500
</page>
<bodyText confidence="0.999254636363636">
The comparison results are showed in Table 3. We
can see that supervised methods significantly outper-
form unsupervised method. For example, the SVM
classifier outperforms the unsupervised method in
terms of average F1-measure by over 10.37%. Thus,
we can deduce from such results that the Pros and
Cons reviews are useful for sentiment classification.
In addition, among the supervised classifiers, SVM
classifier performs the best in most products, which
is consistent with the previous research (Pang et al.,
2002).
</bodyText>
<table confidence="0.999841666666667">
Data set Senti NB SVM ME
Canon EOS 0.628 0.720 0.739 0.726
Fujifilm 0.690 0.781 0.791 0.778
Panasonic 0.625 0.694 0.719 0.697
MacBook 0.708 0.820 0.828 0.797
Samsung 0.675 0.723 0.717 0.714
iPod Touch 0.711 0.792 0.805 0.791
Sony NWZ 0.621 0.722 0.737 0.725
BlackBerry 0.699 0.819 0.794 0.788
iPhone 3GS 0.717 0.811 0.829 0.822
Nokia 5800 0.736 0.840 0.851 0.817
Nokia N95 0.706 0.829 0.849 0.826
</table>
<tableCaption confidence="0.997864666666667">
Table 3: Evaluations on Sentiment Classification. Senti
denotes the method based on SentiWordNet. * significant
t-test, p-values&lt;0.05.
</tableCaption>
<subsectionHeader confidence="0.99376">
3.4 Evaluations on Aspect Ranking
</subsectionHeader>
<bodyText confidence="0.9999405">
In this section, we compared our aspect ranking al-
gorithm against the following three methods.
</bodyText>
<listItem confidence="0.986643416666667">
1) Frequency-based method. The method ranks
the aspects based on aspect frequency.
2) Correlation-based method. This method mea-
sures the correlation between the opinions on spe-
cific aspects and the overall opinion. It counts the
number of the cases when such two kinds of opin-
ions are consistent, and ranks the aspects based on
the number of the consistent cases.
3) Hybrid method. This method captures both the
aspect frequency and correlation by a linear combi-
nation, as A· Frequency-based Ranking + (1 − A)·
Correlation-based Ranking, where A is set to 0.5.
</listItem>
<bodyText confidence="0.999058666666667">
The comparison results are showed in Table 4. On
average, our approach outperforms the frequency-
based method, correlation-based method, and hy-
brid method in terms of NDCG@5 by over 6.24%,
5.79% and 5.56%, respectively. It improves the
performance over such three methods in terms of
NDCG@10 by over 3.47%, 2.94% and 2.58%, re-
spectively, while in terms of NDCG@15 by over
4.08%, 3.04% and 3.49%, respectively. We can de-
duce from the results that our aspect ranking algo-
rithm can effectively identify the important aspects
from consumer reviews by leveraging the aspect fre-
quency and the influence of consumers’ opinions
given to each aspect on their overall opinions. Ta-
ble 5 shows the aspect ranking results of these four
methods. Due to the space limitation, we here only
show top 10 aspects of the product iphone 3GS. We
can see that our approach performs better than the
others. For example, the aspect “phone” is ranked at
the top by the other methods. However, “phone” is
a general but not important aspect.
</bodyText>
<table confidence="0.995602181818182">
# Frequency Correlated Hybrid Our Method
1 Phone Phone Phone Usability
2 Usability Usability Usability Apps
3 3G Apps Apps 3G
4 Apps 3G 3G Battery
5 Camera Camera Camera Looking
6 Feature Looking Looking Storage
7 Looking Feature Feature Price
8 Battery Screen Battery Software
9 Screen Battery Screen Camera
10 Flash Bluetooth Flash Call quality
</table>
<tableCaption confidence="0.999768">
Table 5: iPhone 3GS Aspect Ranking Results.
</tableCaption>
<bodyText confidence="0.999982230769231">
To further investigate the reasonability of our
ranking results, we refer to one of the public user
feedback reports, the “china unicom 100 customers
iPhone user feedback report” (Chinaunicom Report,
2009). The report demonstrates that the top four as-
pects of iPhone product, which users most concern
with, are “3G Network” (30%), “usability” (30%),
“out-looking design” (26%), “application” (15%).
All of these aspects are in the top 10 of our rank-
ing results.
Therefore, we can conclude that our approach is
able to automatically identify the important aspects
from numerous consumer reviews.
</bodyText>
<sectionHeader confidence="0.998249" genericHeader="method">
4 Applications
</sectionHeader>
<bodyText confidence="0.993737">
The identification of important aspects can support
a wide range of applications. For example, we can
</bodyText>
<page confidence="0.96975">
1501
</page>
<table confidence="0.999375230769231">
Frequency Correlation Hybrid Our Method
Data set @5 @10 @15 @5 @10 @15 @5 @10 @15 @5 @10 @15
Canon EOS 0.735 0.771 0.740 0.735 0.762 0.779 0.735 0.798 0.742 0.862 0.824 0.794
Fujifilm 0.816 0.705 0.693 0.760 0.756 0.680 0.816 0.759 0.682 0.863 0.801 0.760
Panasonic 0.744 0.807 0.783 0.763 0.815 0.792 0.744 0.804 0.786 0.796 0.834 0.815
MacBook 0.744 0.771 0.762 0.763 0.746 0.769 0.763 0.785 0.772 0.874 0.776 0.760
Samsung 0.964 0.765 0.794 0.964 0.820 0.840 0.964 0.820 0.838 0.968 0.826 0.854
iPod Touch 0.836 0.830 0.727 0.959 0.851 0.744 0.948 0.785 0.733 0.959 0.817 0.801
Sony NWZ 0.937 0.743 0.742 0.937 0.781 0.797 0.937 0.740 0.794 0.944 0.775 0.815
BlackBerry 0.837 0.824 0.766 0.847 0.825 0.771 0.847 0.829 0.768 0.874 0.797 0.779
iPhone 3GS 0.897 0.836 0.832 0.886 0.814 0.825 0.886 0.829 0.826 0.948 0.902 0.860
Nokia 5800 0.834 0.779 0.796 0.834 0.781 0.779 0.834 0.781 0.779 0.903 0.811 0.814
Nokia N95 0.675 0.680 0.717 0.619 0.619 0.691 0.619 0.678 0.696 0.716 0.731 0.748
</table>
<tableCaption confidence="0.9870945">
Table 4: Evaluations on Aspect Ranking. @5, @10, @15 denote the evaluation metrics of NDCG@5, NDCG@10,
and NDCG@15, respectively. * significant t-test, p-values&lt;0.05.
</tableCaption>
<bodyText confidence="0.999697927272728">
provide product comparison on the important as-
pects to users, so that users can make wise purchase
decisions conveniently.
In the following, we apply the aspect ranking re-
sults to assist document-level review sentiment clas-
sification. Generally, a review document contains
consumer’s positive/negative opinions on various as-
pects of the product. It is difficult to get the ac-
curate overall opinion of the whole review without
knowing the importance of these aspects. In ad-
dition, when we learn a document-level sentiment
classifier, the features generated from unimportant
aspects lack of discriminability and thus may dete-
riorate the performance of the classifier (Fang et al.,
2010). While the important aspects and the senti-
ment terms on these aspects can greatly influence the
overall opinions of the review, they are highly likely
to be discriminative features for sentiment classifica-
tion. These observations motivate us to utilize aspect
ranking results to assist classifying the sentiment of
review documents.
Specifically, we randomly sampled 100 reviews of
each product as the testing data and used the remain-
ing reviews as the training data. We first utilized our
approach to identify the importance aspects from the
training data. We then explored the aspect terms and
sentiment terms as features, based on which each re-
view is represented as a feature vector. Here, we
give more emphasis on the important aspects and
the sentiment terms that modify these aspects. In
particular, we set the term-weighting as 1 + co · Wk,
where Wk is the importance score of the aspect ak,
co is set to 100. Based on the weighted features, we
then trained a SVM classifier using the training re-
views to determine the overall opinions on the test-
ing reviews. For the performance comparison, we
compared our approach against two baselines, in-
cluding Boolean weighting method and frequency
weighting (if) method (Paltoglou et al., 2010) that
do not utilize the importance of aspects. The com-
parison results are shown in Table 6. We can see
that our approach (IA) significantly outperforms the
other methods in terms of average Fi-measure by
over 2.79% and 4.07%, respectively. The results
also show that the Boolean weighting method out-
performs the frequency weighting method in terms
of average Fi-measure by over 1.25%, which are
consistent with the previous research by Pang et al.
(2002). On the other hand, from the IA weight-
ing formula, we observe that without using the im-
portant aspects, our term-weighting function will be
equal to Boolean weighting. Thus, we can speculate
that the identification of important aspects is ben-
eficial to improving the performance of document-
level sentiment classification.
</bodyText>
<sectionHeader confidence="0.999904" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.997668285714286">
Existing researches mainly focused on determining
opinions on the reviews, or identifying aspects from
these reviews. They viewed each aspect equally
without distinguishing the important ones. In this
section, we review existing researches related to our
work.
Analysis of the opinion on whole review text had
</bodyText>
<page confidence="0.98291">
1502
</page>
<table confidence="0.998351538461539">
SVM + Boolean SVM + tf SVM + IA
Data set P R F1 P R F1 P R F1
Canon EOS 0.689 0.663 0.676 0.679 0.654 0.666 0.704 0.721 0.713
Fujifilm 0.700 0.687 0.693 0.690 0.670 0.680 0.731 0.724 0.727
Panasonic 0.659 0.717 0.687 0.650 0.693 0.671 0.696 0.713 0.705
MacBook 0.744 0.700 0.721 0.768 0.675 0.718 0.790 0.717 0.752
Samsung 0.755 0.690 0.721 0.716 0.725 0.720 0.732 0.765 0.748
iPod Touch 0.686 0.746 0.714 0.718 0.667 0.691 0.749 0.726 0.737
Sony NWZ 0.719 0.652 0.684 0.665 0.646 0.655 0.732 0.684 0.707
BlackBerry 0.763 0.719 0.740 0.752 0.709 0.730 0.782 0.758 0.770
iPhone 3GS 0.777 0.775 0.776 0.772 0.762 0.767 0.820 0.788 0.804
Nokia 5800 0.755 0.836 0.793 0.744 0.815 0.778 0.805 0.821 0.813
Nokia N95 0.722 0.699 0.710 0.695 0.708 0.701 0.768 0.732 0.750
</table>
<tableCaption confidence="0.9974795">
Table 6: Evaluations on Term Weighting methods for Document-level Review Sentiment Classification. IA denotes
the term weighing based on the important aspects. * significant t-test, p-values&lt;0.05.
</tableCaption>
<bodyText confidence="0.999922484375">
been extensively studied (Pang and Lee, 2008). Ear-
lier research had been studied unsupervised (Kim et
al., 2004), supervised (Pang et al., 2002; Pang et al.,
2005) and semi-supervised approaches (Goldberg et
al., 2006) for the classification. For example, Mullen
et al. (2004) proposed an unsupervised classifica-
tion method which exploited pointwise mutual in-
formation (PMI) with syntactic relations and other
attributes. Pang et al. (2002) explored several ma-
chine learning classifiers, including Naive Bayes,
Maximum Entropy, SVM, for sentiment classifica-
tion. Goldberg et al. (2006) classified the sentiment
of the review using the graph-based semi-supervised
learning techniques, while Li el al. (2009) tackled
the problem using matrix factorization techniques
with lexical prior knowledge.
Since the consumer reviews usually expressed
opinions on multiple aspects, some works had
drilled down to the aspect-level sentiment analysis,
which aimed to identify the aspects from the reviews
and to determine the opinions on the specific aspects
instead of the overall opinion. For the topic of aspect
identification, Hu and Liu (2004) presented the asso-
ciation mining method to extract the frequent terms
as the aspects. Subsequently, Popescu et al. (2005)
proposed their system OPINE, which extracted the
aspects based on the KnowItAll Web information
extraction system (Etzioni et al., 2005). Liu el al.
(2005) proposed a supervised method based on lan-
guage pattern mining to identify the aspects in the
reviews. Later, Mei et al. (2007) proposed a prob-
abilistic topic model to capture the mixture of as-
pects and sentiments simultaneously. Afterwards,
Wu et al. (2009) utilized the dependency parser to
extract the noun phrases and verb phrases from the
reviews as the aspect candidates. They then trained
a language model to refine the candidate set, and
to obtain the aspects. On the other hand, for the
topic of sentiment classification on the specific as-
pect, Snyder et al. (2007) considered the situation
when the consumers’ opinions on one aspect could
influence their opinions on others. They thus built
a graph to analyze the meta-relations between opin-
ions, such as agreement and contrast. And they pro-
posed a Good Grief algorithm to leveraging such
meta-relations to improve the prediction accuracy
of aspect opinion ratings. In addition, Wang et al.
(2010) proposed the topic of latent aspect rating
which aimed to infer the opinion rating on the as-
pect. They first employed a bootstrapping-based al-
gorithm to identify the major aspects via a few seed
word aspects. They then proposed a generative La-
tent Rating Regression model (LRR) to infer aspect
opinion ratings based on the review content and the
associated overall rating.
While there were usually huge collection of re-
views, some works had concerned the topic of
aspect-based sentiment summarization to combat
the information overload. They aimed to summa-
rize all the reviews and integrate major opinions on
various aspects for a given product. For example,
Titov et al. (2008) explored a topic modeling method
to generate a summary based on multiple aspects.
They utilized topics to describe aspects and incor-
</bodyText>
<page confidence="0.671462">
1503
</page>
<bodyText confidence="0.945189813953488">
porated a regression model fed by the ground-truth References
opinion ratings. Additionally, Lu el al. (2009) pro- P. Beineke, T. Hastie, C. Manning, and S. Vaithyanathan.
posed a structured PLSA method, which modeled An Exploration of Sentiment Summarization. AAAI,
the dependency structure of terms, to extract the as- 2003.
pects in the reviews. They then aggregated opinions G. Carenini, R.T. Ng, and E. Zwart. Extracting Knowl-
on each specific aspects and selected representative edge from Evaluative Text. K-CAP, 2005.
text segment to generate a summary. G. Carenini, R.T. Ng, and E. Zwart. Multi-document
In addition, some works proposed the topic of Summarization of Evaluative Text. ACL, 2006.
product ranking which aimed to identify the best China Unicom 100 Customers iPhone User Feedback
products for each specific aspect (Zhang et al., Report, 2009.
2010). They used a PageRank style algorithm to Y. Choi and C. Cardie. Hierarchical Sequential Learning
mine the aspect-opinion graph, and to rank the prod- for Extracting Opinions and Their Attributes. ACL,
ucts for each aspect. 2010.
Different from previous researches, we dedicate H. Cui, V. Mittal, and M. Datar. Comparative Experi-
our work to identifying the important aspects from ments on Sentiment Classification for Online Product
the consumer reviews of a specific product. Reviews. AAAI, 2006.
6 Conclusions and Future Works S. Dasgupta and V. Ng. Mine the Easy, Classify the Hard:
In this paper, we have proposed to identify the im- A Semi-supervised Approach to Automatic Sentiment
portant aspects of a product from online consumer Classification. ACL, 2009.
reviews. Our assumption is that the important as- K. Dave, S. Lawrence, and D.M. Pennock. Opinion Ex-
pects of a product should be the aspects that are fre- traction and Semantic Classification of Product Re-
quently commented by consumers and consumers’ views. WWW, 2003.
opinions on the important aspects greatly influence A. Esuli and F. Sebastiani. A Publicly Available Lexical
their overall opinions on the product. Based on this Resource for Opinion Mining. LREC, 2006.
assumption, we have developed an aspect ranking al- O. Etzioni, M. Cafarella, D. Downey, A. Popescu,
gorithm to identify the important aspects by simulta- T. Shaked, S. Soderland, D. Weld, and A. Yates. Un-
neously considering the aspect frequency and the in- supervised Named-entity Extraction from the Web: An
fluence of consumers’ opinions given to each aspect Experimental Study. Artificial Intelligence, 2005.
on their overall opinions. We have conducted exper- J. Fang, B. Price, and L. Price. Pruning Non-Informative
iments on 11 popular products in four domains. Ex- Text Through Non-Expert Annotations to Improve
perimental results have demonstrated the effective- Aspect-Level Sentiment Classification. COLING,
ness of our approach on important aspects identifi- 2010.
cation. We have further applied the aspect ranking O. Feiguina and G. Lapalme. Query-based Summariza-
results to the application of document-level senti- tion of Customer Reviews. AI, 2007.
ment classification, and have significantly improved Forrester Research. State of Retailing Online 2009: Mar-
the classification performance. In the future, we will keting Report. http://www.shop.org/soro, 2009.
apply our approach to support other applications. A. Goldberg and X. Zhu. Seeing Stars when There aren’t
Acknowledgments Many Stars: Graph-based Semi-supervised Learning
This work is supported in part by NUS-Tsinghua Ex- for Sentiment Categorization. ACL, 2006.
treme Search (NExT) project under the grant num- M. Gamon, A. Aue, S. Corston-Oliver, and E. Ringger.
ber: R-252-300-001-490. We give warm thanks to Pulse: Mining Customer Opinions from Free Text.
the project and anonymous reviewers for their com- IDA, 2005.
ments. M. Hu and B. Liu. Mining and Summarizing Customer
</bodyText>
<reference confidence="0.994495530434783">
1504 Reviews. SIGKDD, 2004.
K. Jarvelin and J. Kekalainen. Cumulated Gain-based
Evaluation of IR Techniques. TOIS, 2002.
S. Kim and E. Hovy. Determining the Sentiment of Opin-
ions. COLING, 2004.
J. Kim, J.J. Li, and J.H. Lee. Discovering the Discrimi-
native Views: Measuring Term Weights for Sentiment
Analysis. ACL, 2009.
Kelsey Research and comscore. Online Consumer-
Generated Reviews Have Significant Impact on Offline
Purchase Behavior.
K. Lerman, S. Blair-Goldensohn, and R. McDonald.
Sentiment Summarization: Evaluating and Learning
User Preferences. EACL, 2009.
B. Li, L. Zhou, S. Feng, and K.F. Wong. A Unified Graph
Model for Sentence-Based Opinion Retrieval. ACL,
2010.
T. Li and Y. Zhang, and V. Sindhwani. A Non-negative
Matrix Tri-factorization Approach to Sentiment Clas-
sification with Lexical Prior Knowledge. ACL, 2009.
B. Liu, M. Hu, and J. Cheng. Opinion Observer: Ana-
lyzing and Comparing Opinions on the Web. WWW,
2005.
B. Liu. Handbook Chapter: Sentiment Analysis and Sub-
jectivity. Handbook of Natural Language Processing.
Marcel Dekker, Inc. New York, NY, USA, 2009.
Y. Lu, C. Zhai, and N. Sundaresan. Rated Aspect Sum-
marization of Short Comments. WWW, 2009.
L.M. Manevitz and M. Yousef. One-class svms for Doc-
ument Classification. The Journal of Machine Learn-
ing, 2002.
R. McDonal, K. Hannan, T. Neylon, M. Wells, and
J. Reynar. Structured Models for Fine-to-coarse Sen-
timent Analysis. ACL, 2007.
Q. Mei, X. Ling, M. Wondra, H. Su, and C.X. Zhai. Topic
Sentiment Mixture: Modeling Facets and Opinions in
Weblogs. WWW, 2007.
H.J. Min and J.C. Park. Toward Finer-grained Sentiment
Identification in Product Reviews Through Linguistic
and Ontological Analyses. ACL, 2009.
T. Mullen and N. Collier. Sentiment Analysis using
Support Vector Machines with Diverse Information
Sources. EMNLP, 2004.
N. Nanas, V. Uren, and A.D. Roeck. Building and Ap-
plying a Concept Hierarchy Representation of a User
Profile. SIGIR, 2003.
H. Nishikawa, T. Hasegawa, Y. Matsuo, and G. Kikui.
Optimizing Informativeness and Readability for Senti-
ment Summarization. ACL, 2010.
B. Ohana and B. Tierney. Sentiment Classification of Re-
views Using SentiWordNet. IT&amp;T Conference, 2009.
G. Paltoglou and M. Thelwall. A study of Information
Retrieval Weighting Schemes for Sentiment Analysis.
ACL, 2010.
B. Pang, L. Lee, and S. Vaithyanathan. Thumbs up? Sen-
timent Classification using Machine Learning Tech-
niques. EMNLP, 2002.
B. Pang, L. Lee, and S. Vaithyanathan. A Sentimen-
tal Education: Sentiment Analysis using Subjectivity
Summarization based on Minimum cuts Techniques.
ACL, 2004.
B. Pang and L. Lee. Seeing stars: Exploiting Class Re-
lationships for Sentiment Categorization with Respect
to Rating Scales. ACL, 2005.
B. Pang and L. Lee. Opinion mining and sentiment
analysis. Foundations and Trends in Information Re-
trieval, 2008.
A.-M. Popescu and O. Etzioni. Extracting Product Fea-
tures and Opinions from Reviews. HLT/EMNLP,
2005.
R. Prabowo and M. Thelwall. Sentiment analysis: A
Combined Approach. Journal of Informetrics, 2009.
G. Qiu, B. Liu, J. Bu, and C. Chen.. Expanding Domain
Sentiment Lexicon through Double Propagation. IJ-
CAI, 2009.
M. Sanderson and B. Croft. Document-word Co-
regularization for Semi-supervised Sentiment Analy-
sis. ICDM, 2008.
B. Snyder and R. Barzilay. Multiple Aspect Ranking us-
ing the Good Grief Algorithm. NAACL HLT, 2007.
S. Somasundaran, G. Namata, L. Getoor, and J. Wiebe.
Opinion Graphs for Polarity and Discourse Classifica-
tion. ACL, 2009.
Q. Su, X. Xu, H. Guo, X. Wu, X. Zhang, B. Swen, and
Z. Su. Hidden Sentiment Association in Chinese Web
Opinion Mining. WWW, 2008.
C. Toprak, N. Jakob, and I. Gurevych. Sentence and
Expression Level Annotation of Opinions in User-
Generated Discourse. ACL, 2010.
P. Turney. Thumbs up or Thumbs down? Semantic Ori-
entation Applied to Unsupervised Classification of Re-
views. ACL, 2002.
I. Titov and R. McDonald. A Joint Model of Text and
Aspect Ratings for Sentiment Summarization. ACL,
2008.
H. Wang, Y. Lu, and C.X. Zhai. Latent Aspect Rating
Analysis on Review Text Data: A Rating Regression
Approach. KDD, 2010.
B. Wei and C. Pal. Cross Lingual Adaptation: An Exper-
iment on Sentiment Classifications. ACL, 2010.
T. Wilson, J. Wiebe, and P. Hoffmann. Recognizing
Contextual Polarity in Phrase-level Sentiment Analy-
sis. HLT/EMNLP, 2005.
T. Wilson and J. Wiebe. Annotating Attributions and Pri-
vate States. ACL, 2005.
Y. Wu, Q. Zhang, X. Huang, and L. Wu. Phrase Depen-
dency Parsing for Opinion Mining. ACL, 2009.
K. Zhang, R. Narayanan, and A. Choudhary. Voice of
the Customers: Mining Online Customer Reviews for
Product Feature-based Ranking. WOSN, 2010.
J. Zhu, H. Wang, and B.K. Tsou. Aspect-based Sentence
Segmentation for Sentiment Summarization. TSA,
2009.
L. Zhuang, F. Jing, and X.Y. Zhu. Movie Review Mining
and Summarization. CIKM, 2006.
</reference>
<page confidence="0.992491">
1505
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.855979">
<title confidence="0.981602">Aspect Ranking: Identifying Important Product Aspects from Consumer Reviews</title>
<author confidence="0.996703">Jianxing Yu</author>
<author confidence="0.996703">Zheng-Jun Zha</author>
<author confidence="0.996703">Meng Wang</author>
<author confidence="0.996703">Tat-Seng</author>
<affiliation confidence="0.998249">School of National University of</affiliation>
<email confidence="0.894585">zhazj,wangm,</email>
<abstract confidence="0.999766461538462">In this paper, we dedicate to the topic of aspect ranking, which aims to automatically identify important product aspects from online consumer reviews. The important aspects are identified according to two observations: (a) the important aspects of a product are usually commented by a large number of consumers; and (b) consumers’ opinions on the important aspects greatly influence their overall opinions on the product. In particular, given consumer reviews of a product, we first identify the product aspects by a shallow dependency parser and determine consumers’ opinions on these aspects via a sentiment classifier. We then develop an aspect ranking algorithm to identify the important aspects by simultaneously considering the aspect frequency and the influence of consumers’ opinions given to each aspect on their overall opinions. The experimental results on 11 popular products in four domains demonstrate the effectiveness of our approach. We further apply the aspect ranking results to the application of documentlevel sentiment classification, and improve the performance significantly.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>