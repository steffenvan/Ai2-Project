<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000017">
<title confidence="0.955296">
Exploring Semi-Supervised Coreference Resolution of Medical Concepts
using Semantic and Temporal Features
</title>
<author confidence="0.997481">
Preethi Raghavan*, Eric Fosler-Lussier*, and Albert M. Lai†
</author>
<affiliation confidence="0.998316666666667">
*Department of Computer Science and Engineering
†Department of Biomedical Informatics
The Ohio State University, Columbus, Ohio, USA
</affiliation>
<email confidence="0.994809">
{raghavap, fosler}@cse.ohio-state.edu, albert.lai@osumc.edu
</email>
<sectionHeader confidence="0.996643" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.994534238095238">
We investigate the task of medical concept
coreference resolution in clinical text using
two semi-supervised methods, co-training and
multi-view learning with posterior regulariza-
tion. By extracting semantic and temporal
features of medical concepts found in clinical
text, we create conditionally independent data
views; co-training MaxEnt classifiers on this
data works almost as well as supervised learn-
ing for the task of pairwise coreference resolu-
tion of medical concepts. We also train Max-
Ent models with expectation constraints, using
posterior regularization, and find that poste-
rior regularization performs comparably to or
slightly better than co-training. We describe
the process of semantic and temporal feature
extraction and demonstrate our methods on a
corpus of case reports from the New England
Journal of Medicine and a corpus of patient
narratives obtained from The Ohio State Uni-
versity Wexner Medical Center.
</bodyText>
<sectionHeader confidence="0.998851" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999956222222223">
The clinical community creates and uses a variety
of semi-structured and unstructured electronic tex-
tual documents that include medical reports such
as admission notes, progress notes, pathology re-
ports, radiology reports and hospital discharge sum-
maries. The documents, collectively termed clini-
cal narratives, account for various medical condi-
tions, procedures, diagnoses and assessments in a
patient’s medical history. Researchers have inves-
tigated ways in which clinical text can be automati-
cally processed for enabling access to relevant infor-
mation for physicians and health researchers (Embi
and Payne, 2009). One application is to support pa-
tient recruitment into clinical trials (research studies
that try to answer scientific questions to find bet-
ter ways to prevent, diagnose, or treat a disease)
by matching patient characteristics against eligibil-
ity criteria (Raghavan and Lai, 2010). While there
has been significant efforts to move to structured
data collection, clinical narratives remain a critical
data source for these tasks.
Extracting structured information from unstruc-
tured clinical text using natural language processing
(NLP) is complicated by the distinct clinical report-
ing sub-language characterized by incomplete sen-
tences and domain specific abbreviations (Friedman
et al., 2002). The large number of clinical narra-
tives generated per patient, over the years, along
with redundant information within and across narra-
tives, further adds to the complexity of using infor-
mation structured using NLP. There is a tendency to
copy and edit parts of an old clinical narrative when-
ever a new one is created, thus leading to redundant
information in clinical narratives of a patient. Fur-
thermore, since different types of clinical narratives
are created for different purposes, certain narratives
may summarize information from various other, at
times older, clinical narratives. All of this makes the
task of automatically processing unstructured clin-
ical narratives significantly difficult. However, the
ability to resolve medical concept coreferences helps
deal with redundant information within and across
clinical narratives and thus produce a unique list of
medical concepts in the patient’s clinical history.
We investigate the task of resolving references to
</bodyText>
<page confidence="0.643033666666667">
731
2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 731–741,
Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics
</page>
<bodyText confidence="0.810347333333333">
the same medical concept in the clinical narratives
of a patient using supervised and semi-supervised
methods. Our main contributions are as follows:
</bodyText>
<listItem confidence="0.959047052631579">
1. Since manual coreference annotation of patient
narratives is a slow and expensive process and pub-
licly available datasets are difficult to acquire, we
study the application of semi-supervised methods,
co-training and using expectation constraints with
posterior regularization, to medical concept coref-
erence resolution (MCCR).
2. We work with the hypothesis that if two medical
concepts have the same meaning and have occurred
at the same time, there is a very high probability that
they corefer. Based on this hypothesis, we explain
extraction of semantic and temporal feature sets that
are effectively used for MCCR.
3. We propose a method to associate medical con-
cepts with time durations centered around admission
and discharge dates of the patient using CRFs.
4. With the help of corpora created from the New
England Journal of Medicine (NEJM) and actual pa-
tient narratives obtained from the medical center, we
</listItem>
<bodyText confidence="0.872806333333333">
demonstrate that the semi-supervised methods per-
form comparably with supervised learning for pair-
wise MCCR using a MaxEnt classifier.
</bodyText>
<sectionHeader confidence="0.999717" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99984">
Free-text reports form a significant portion of the
information content in a patient’s medical record.
There is great need for tools that can structure the
information in clinical text for use in various stud-
ies studies such as clinical trials, quality assess-
ment of healthcare delivery in institutions, and pub-
lic health research. Researchers have been investi-
gating ways in which clinical free-text can be struc-
tured to transform the information content in a clin-
ical narrative into a representation suitable for com-
putational analysis (Ananiadou et al., 2004). Medi-
cal NLP systems like Mayo’s cTakes (Savova et al.,
2010), IBM’s MedKAT,1 and MedLEE (Chiang et
al., 2010), have components specifically trained or
designed for the clinical domain, to support tasks
such as named entity recognition. Previous at-
tempts at learning temporal relations between med-
ical events in clinical text include work by Jung et
</bodyText>
<footnote confidence="0.9333165">
1https://cabig-kc.nci.nih.gov/Vocab/KC/
index.php/OHNLP
</footnote>
<bodyText confidence="0.999275422222222">
al. (2011) and Zhou et al. (2006). Gaizauskas et
al. (2006) learn the temporal relations before, after,
is included between events from a corpus of clinical
text much like the event-event relation tlink learn-
ing in Timebank (Pustejovsky et al., 2003). A com-
prehensive survey of temporal reasoning in medi-
cal data is provided by Zhou and Hripcsak (2007).
Chapman et al. (2011) discuss barriers to NLP de-
velopment in the clinical domain.
Coreference resolution is a well-studied prob-
lem in computational linguistics (Ng, 2010; Raghu-
nathan et al., 2010). Supervised machine learn-
ing algorithms have been previously used for noun
phrase coreference resolution with fairly good re-
sults (Soon et al., 2001; Raghunathan et al., 2010).
Recently, the i2b2 challenge2 on coreference reso-
lution examined coreference resolution in clinical
data. The problem addressed in our paper is simi-
lar to the task described in the i2b2 challenge.3 Be-
sides the i2b2 challenge, there has not been signifi-
cant work in MCCR. This may be due to various pri-
vacy concerns and the efforts required to anonymize
and annotate massive amounts of patient narratives.
Zheng et al. (2011) review heuristic-based, super-
vised and unsupervised methods for coreference res-
olution in the context of the clinical domain. He
(2007) studied coreference resolution in discharge
summaries, treating coreference resolution as a bi-
nary classification problem and investigated critical
features for coreference resolution for entities that
fall into five medical semantic categories commonly
appearing in discharge summaries. However, we fo-
cus on feature extraction to determine the similarity
between medical concepts, both in terms of meaning
and time of occurrence, for resolving coreferences
within and across all types of clinical narratives.
A disadvantage of supervised machine learning
approaches is the need for an unknown amount of
annotated training data for optimal performance.
Researchers then began to experiment with weakly
supervised machine learning algorithms such as co-
training (Blum and Mitchell, 1998). Muller et al.
(2002) investigate the practical applicability of co-
training for the task of building a classifier for coref-
erence resolution and observed that the results were
</bodyText>
<footnote confidence="0.995191">
2https://www.i2b2.org/NLP/Coreference/
3https://www.i2b2.org/NLP/Coreference/assets/
CoreferenceGuidelines.pdf
</footnote>
<page confidence="0.99672">
732
</page>
<bodyText confidence="0.999818647058824">
mostly negative for their dataset.
Ganchev et al. (2010) propose a posterior regular-
ization framework for weakly supervised learning to
derive a multi-view learning algorithm. Multi-view
methods typically begin by assuming that each view
alone can yield a good predictor. Under this as-
sumption, we can regularize the models from each
view by constraining the amount by which we per-
mit them to disagree on unlabeled instances. In the
proposed approach, they train a model for each view,
and use constraints that the models should agree on
the label distribution.
We investigate the applicability of these two weakly
supervised methods to the task of MCCR using se-
mantic and temporal views. Savova et al. (2011) dis-
cuss the creation of a corpus for coreference resolu-
tion in the clinical narrative. We annotate a corpus of
clinical narratives to tag medical concepts, temporal
relations, and coreference information. We use this
corpus as a gold standard to evaluate the proposed
approach to resolving coreferences between medical
concepts in clinical text.
To summarize, we study the problem of intra and
cross-narrative coreference resolution on longitudi-
nal patient data using relatedness between medical
concepts in terms of semantics and time. Further,
we importantly demonstrate that this task gives us
reasonable results even when modeled as a semi-
supervised problem. Creating annotated clinical cor-
pora is tedious, time consuming, and costly, as it
requires experts with medical domain knowledge.
Thus, the ability to train semi-supervised models
with limited labeled data for MCCR would be of
tremendous value.
</bodyText>
<sectionHeader confidence="0.982333" genericHeader="method">
3 Problem Description
</sectionHeader>
<bodyText confidence="0.999687911764706">
Coreference resolution in clinical text refers to the
problem of identifying all medical concepts that re-
fer to the same medical concept. Medical con-
cepts are medical entities, events or states associ-
ated with the patient’s medical condition and health-
care. These include medical conditions, drugs ad-
ministered, diseases, procedures and lab tests as well
as normal health situations like pregnancy affecting
the patient’s health. The task of MCCR is similar to
noun phrase coreference resolution. However, med-
ical concepts are not restricted to noun phrases. For
instance, the actions cauterize and cauterization are
both considered medical concepts.
To make the task of identifying medical concepts
from clinical text more deterministic, any contigu-
ous group of words that have a direct or close match
in the Unified Medical Language System (UMLS)
Metathesaurus4 is considered a medical concept.
The UMLS includes a large Metathesaurus of con-
cepts and terms from many biomedical vocabular-
ies and a lexicon which contains syntactic, morpho-
logical, and orthographic information for biomedi-
cal and common words in the English language.
Problem Formulation. Consider a corpus of clini-
cal narratives, where multiple clinical narratives are
associated with each patient. If PZ, i E {1, 2,..., n}
where n is the number of patients in corpus, then
for each PZ, we have a set of associated clinical nar-
ratives. Each clinical narrative in turn has a set of
medical concepts. Thus, each PZ has a set of associ-
ated medical concepts, M = {M1, M2, M3, ..} that
occur within each clinical narrative as well as across
clinical narratives for that PZ. We study the problem
of MCCR of all medical concepts in M for each PZ.
</bodyText>
<sectionHeader confidence="0.968092" genericHeader="method">
4 Semantic and Temporal Features
</sectionHeader>
<bodyText confidence="0.999929571428571">
We extract features based on semantic and tempo-
ral relatedness for each pair of medical concepts.
Semantic relatedness measures closeness between
medical concepts in terms of their meaning. This is
quantified by measuring distance between medical
events in the UMLS Metathesaurus graph structure
(Xiang et al., 2011). Temporal relatedness measures
the closeness between medical concepts in terms of
when they occurred. This is achieved by first, learn-
ing to assign every medical concept to a time-bin,
and then using the time-bin as a feature for learn-
ing to resolve coreferences. Extracting semantic and
temporal features helps identify conditionally inde-
pendent views of the data for co-training classifiers.
As previously noted by Nigam and Ghani (2000), it
is hard to identify conditionally independent views
for real-data problems. However, we believe there
are no natural dependencies between the semantic
and temporal feature sets. While semantic features
help identify synonymous medical concepts, that
alone may not guarantee coreference. Medical con-
</bodyText>
<footnote confidence="0.954047">
4https://uts.nlm.nih.gov/home.html
</footnote>
<page confidence="0.996332">
733
</page>
<figure confidence="0.6374385">
Section 5
Section 4
</figure>
<figureCaption confidence="0.99523125">
Figure 1: MCCR pipeline: Extract semantic and tempo-
ral features from clinical text to train MaxEnt classifiers
for medical concept coreference resolution using 1) Co-
training or 2) Posterior Regularization
</figureCaption>
<bodyText confidence="0.999786259259259">
cepts that are similar in meaning, but dissimilar in
terms of their time of occurrence, most probably do
not corefer. Similarly, medical concepts that occur
during the same time duration but are dissimilar in
terms of meaning, most probably do not corefer.
Semantic Relatedness. We leverage the UMLS
to derive a semantic relatedness score between med-
ical concepts. The UMLS codifies concepts found
in various medical vocabularies (e.g., ICD5 and
SNOMED-CT6) and includes relationships between
various concepts. The medical concepts and their
relationships are modeled in a graph structure. We
use the k-Neighborhood decentralization method
(kDLS) (Xiang et al., 2011) to index and transi-
tively traverse associated relations between concept
unique identifiers (CUIs) in the UMLS graph. The
UMLS uses semantic relations to mark the avail-
able links between two concepts. Around 2,404,937
CUIs and 15,333,246 links between them are seen in
the full UMLS graph structure. The kDLS method
is shown to outperform both breadth-first and depth-
first search in terms of speed and various other
measures in finding important information, such as
reachability, distance, and a summary of paths, be-
tween two concepts in the UMLS graph structure.
The relation between two concepts Mj (denoted by
x) and Mk (denoted by y) is measured as follows.
</bodyText>
<equation confidence="0.955327">
�
R(x, y) =
pED(x,y)
</equation>
<bodyText confidence="0.9547345">
where D(x, y) is the set of paths from x to y and
D(y, x) is the set of paths from y to x obtained us-
</bodyText>
<footnote confidence="0.9996075">
5http://www.cdc.gov/nchs/icd.htm
6http://www.ihtsdo.org/snomed-ct/
</footnote>
<bodyText confidence="0.999222304347826">
ing the kDLS method, excluding paths with length
equal to 1. In order to make the measurement be-
tween a medical concepts unbiased against the avail-
able links in the UMLS that directly connect them,
the paths with length being 1 between them are not
counted. Each path’s contribution to the relation
score R(x, y) is determined by its length and -y. -y is
varied between 1 to 50; if -y is set to 1, then all paths
contribute equally to R irrespective of their lengths.
When -y increases, more weight will be placed on
the short paths as opposed to the long paths. Xiang
et al. (2011) observe several fold enrichment values
when -y is varied between 5 and 15.
Besides traversing the UMLS graph structure us-
ing the kDLS method to obtain a similarity score
between medical concepts, we also measure similar-
ity between medical concepts by taking into account
the surrounding context. We do so by measuring
the KL-divergence between the sentences to which
the medical concepts belong. In order to avoid the
possibility of an empty set when calculating the in-
tersection of the probability distributions, we use a
smoothing method that makes the probability distri-
butions sum to 1 (Brigitte, 2003).
Another important semantic feature is the type of
relation between the medical concepts. This feature
is calculated by first computing the stemmed word
overlap between the medical concepts and deriving
features based on exact and partial matches between
the word stems of the medical concepts. If there is
no exact or partial match between the concepts, we
query the UMLS to check if the stem of one of the
medical concepts occurs in the UMLS definition or
atoms of the other medical event. An atom is the
smallest unit of naming within the UMLS. A med-
ical concept in UMLS represents a single meaning
and contains all atoms in the UMLS that express that
meaning in any way, whether formal or casual, ver-
bose or abbreviated. All of the atoms within a con-
cept are synonymous.
Besides the described features, we also include
the UMLS semantic category of each medical con-
cept and the WordNet7 similarity score between sen-
tences containing the medical concept.
Temporal Relatedness. Clinical text is fre-
quently characterized by temporal expressions co-
</bodyText>
<footnote confidence="0.50593">
7http://wordnet.princeton.edu/
</footnote>
<figure confidence="0.9988084">
Clinical
Text
Temporal Feature
Extraction using
CRFs
Medical Concept
Coreference Resolution
(MCCR)
Co-train
Posterior
Regularization
OR
Coreference
decisions
Semantic Feature
Extraction
1 � 1
-ylength(p)−1 +
qED(y,x)
-ylength(q)−1
</figure>
<page confidence="0.990697">
734
</page>
<bodyText confidence="0.999969359375">
occurring with medical concepts (Zhou and Hripc-
sak, 2007). For instance, two days ago, fever started
4 days before rash, July 10th, 2010 etc. The abil-
ity to associate medical concepts with temporal ex-
pressions helps order medical concepts and deter-
mine potential temporal overlap between them. This
in turn could be a powerful discriminatory feature
in MCCR. Consider the medical concept chest pain
that occurs multiple times in a clinical narrative. If
these mentions of chest pain have occurred at the
same time, there is a possibility that they all refer to
the same instance of the medical concept chest pain.
Instead of relying on implicit temporal references
that may or may be evident from the clinical nar-
rative, we focus on temporal expressions that are
found in most clinical narratives. We do so by lever-
aging structural properties of clinical narratives such
as section information and explicit temporal infor-
mation such as admission and discharge dates, to
learn to assign medical concepts to time periods we
refer to as time-bins.
We now proceed to explain the process of assign-
ing medical concepts to time-bins using CRFs. Clin-
ical narratives are usually formatted with a struc-
tured header with information that includes the pa-
tient admission and discharge date. Clinical narra-
tives are also typically divided into sections. Sec-
tions represent a logical, and at times, temporal
grouping of information in the narrative. Sections
such as “history of present illness,” “physical ex-
amination,” “review of systems,” “impression,” and
“assessment plan” tend to occur in a certain order
within each clinical narrative. Thus, section tran-
sitions may indicate a temporal pattern for medical
concepts across those sections. For example, “past
medical history” (before admission), followed by
“findings on admission” (on admission), followed
by “physical examination” (after admission). Sec-
tions of certain types may also exhibit certain tem-
poral patterns. A “history of present illness” sec-
tion may start with diseases and diagnoses 30 years
ago and then proceed to talk about them in the con-
text of a medical condition that happened few years
ago and finally describe the patient’s condition on
admission. Given the temporal patterns within sec-
tions and at section transitions, it works well to treat
the list of medical concepts from each clinical nar-
rative as a sequence (considering them in narrative
order) and learning to label them with a correspond-
ing time-bin. We define the following sequence of
time-bins centered around admission and discharge,
{way before admission, before admission, on admis-
sion, after admission, after discharge}.
We model the problem of assigning medical con-
cepts to time-bins as a sequence labeling task using
a CRF where we predict labels from the set {way be-
fore admission, before admission, on admission, af-
ter admission, after discharge} as a sequence Y pre-
dicted from the detected medical concepts X. CRFs
use two types of features in classification, state fea-
tures and transition features. State features con-
sider relating the label y (time-bin) of a single ver-
tex (medical concept) to features corresponding to a
medical concept x, and are given by,
</bodyText>
<equation confidence="0.930098">
S(x, y, i) = Ej Ajsj(y, x, i)
</equation>
<bodyText confidence="0.99953325">
Transition features consider the mutual depen-
dence of labels yi−1 and yi (dependence between the
time-bins of the current and previous medical event
in the sequence) and are given by,
</bodyText>
<equation confidence="0.945611">
T(x, y, i) = Ek µktk(yi−1, yi, x, i)
</equation>
<bodyText confidence="0.99673216">
Above, sj is a state feature function, and Aj is its
associated weight and tk is a transition function, and
µk is its associated weight. In contrast to the state
function, the transition function takes as input the
current label as well as the previous label, in addition
to the data.
Example state features include indicator features
based on verbs patterns in the same sentence as that
of the medical concept, last verb before the medical
concept, and type of clinical narrative. We also in-
clude position of medical event in the narrative as
well as within each section, the temporal expres-
sions and dates co-occurring with the medical con-
cept as features and the difference between these
dates and the admission date on each clinical nar-
rative. Example transition features include section
transitions based on the sections under which the
medical concept occurs, UMLS relatedness score
between the previous and current medical concept,
difference in verb patterns between the previous and
current medical concept, difference in dates (if any)
between the dates co-occurring with the previous
and current medical concept.
In order to enable feature extraction for this learn-
ing task, we use the following heuristic-based al-
</bodyText>
<page confidence="0.991608">
735
</page>
<bodyText confidence="0.884285">
gorithm to automatically identify sections and asso-
ciate medical concepts with them.
</bodyText>
<listItem confidence="0.9813484">
1. Extract lines that are all upper-case, and longer
than a word, from all narratives in corpus. They
mostly correspond to section titles.
2. Derive the stem of each word in the title using a
Porter stemming algorithm8 and sort stemmed
titles by frequency. If two or more words in
the title overlap, they are considered the same.
This gives us a candidate set of section titles.
3. When parsing a clinical narrative, and encoun-
tering a stemmed ngram matching a section ti-
</listItem>
<bodyText confidence="0.872723636363636">
tle from the frequent list, all subsequent sen-
tences are associated with that section until a
new section title is encountered. If an exact
match is not found, we allow partially match-
ing ngrams to be considered as section titles.
Along with the time-bin that are learned using the
process described above, dates and temporal expres-
sions extracted from the annotations in our corpus
are also used as temporal features. The list of fea-
tures extracted for the task of MCCR include the
following:
</bodyText>
<listItem confidence="0.99876875">
1. Verb pattern in the sentence in which the med-
ical concept occurs.
2. Last verb before the medical concept in the
same sentence.
3. Type of clinical narrative.
4. Section under which the medical concept is
mentioned.
5. Position of the medical concept.
6. Dates that fall in the same sentence as the med-
ical concept.
7. Difference between admission date and the date
in the same sentence as the clinical narrative.
</listItem>
<bodyText confidence="0.8215476">
8. The learned time-bin of each medical concept.
We also derive features based on the overlap-
ping in time-bins for the medical concept pair
and the nature of time-bin (past, present, fu-
ture).
</bodyText>
<listItem confidence="0.99554825">
9. Difference in verb patterns in the sentences of
the medical concept pair.
10. Difference in dates between the medical con-
cept pair.
</listItem>
<footnote confidence="0.758489">
8http://tartarus.org/martin/PorterStemmer/
</footnote>
<bodyText confidence="0.9434295">
11. UMLS relatedness score between the medical
concept pair and all the UMLS related and
other features described previously in the se-
mantic relatedness section.
When applying CRFs to the problem of assigning
medical concepts to time-bins, an observation se-
quence is medical concepts in the order in which
they appear in a clinical narrative, and the state se-
quence is the corresponding label sequence of time
bins. Thus, given a sequence of concepts in narrative
order {M1, M2, M3, ..}, we learn a corresponding
label sequence of time-bins {way before admission,
before admission, on admission, after admission, af-
ter discharge}. The learned label sequence is now
used as part of the temporal feature set in co-training
and posterior regularization for MCCR.
</bodyText>
<sectionHeader confidence="0.976602" genericHeader="method">
5 Weakly Supervised Learning
</sectionHeader>
<subsectionHeader confidence="0.997985">
5.1 Co-training
</subsectionHeader>
<bodyText confidence="0.999968678571429">
We co-train two MaxEnt classifiers, one each on the
semantic features f� and temporal features f� of the
data, to classify pairs of medical concepts as core-
fer or no-corefer in a semi-supervised fashion. We
use the co-training algorithm proposed by Blum and
Mitchell (1998).
The assumption here is that each feature set contains
sufficient information to train a model for classifica-
tion of medical concepts. Consider the concept pair,
{renal inflammation, posterior uveitis} that core-
fer. The semantic view for this concept pair may
not strongly indicate coreference. The “UMLS rela-
tion type” feature indicates that the two concepts are
not similar in meaning. However, both concepts are
mapped to the same time-bin after admission. Thus,
the time-bin along with features extracted based on
explicit temporal expressions co-occurring with the
medical concepts indicate a coreference between the
pair of medical concepts. Similarly, the semantic
view is confident about confident about the corefer-
ence of certain medical concept pairs which do not
occur in the same time-bin. The classifiers trained
on each view complement each other in the learn-
ing process. Thus, we can leverage the predictions
made by each classifier on the unlabeled dataset to
augment the training data of both classifiers.
The co-training algorithm is shown in Table 1. We
set a threshold for an unlabeled sample to be added
</bodyText>
<page confidence="0.995367">
736
</page>
<figure confidence="0.293779375">
Function coTrain
Repeat till all unlabeled data is labeled.
1. Train classifier c1 on tfs to obtain model m1
2. Train classifier c2 on tft to obtain model m2
3. Use m1 to classify a subset of unlabeled data
and update the training data as,
tfs.subset = fusubset1, predicted label}
iff classifier confidence &gt; 1/number of labels
4. Use m2 to classify a subset of unlabeled data
and update the training data as,
tft.subset = fusubset2, predicted label}
iff classifier confidence &gt; 1/number of labels
5. tfs = tfs + tf t.subset +
fusubset1, predicted label}
6. tft = tft + tfs.subset +
fusubset2, predicted label}
</figure>
<tableCaption confidence="0.997884">
Table 1: Co-training algorithm for the binary pairwise
classification task of MCCR (Blum and Mitchell, 1998).
</tableCaption>
<equation confidence="0.88344925">
c = classifier, u = unlabeled data.
usubset1, usubset2 = subsets of unlabeled data.
usubset1 and usubset2 are mutually exclusive.
F = {fs, ft} is the features space divided into condition-
</equation>
<construct confidence="0.3368388">
ally independent semantic and temporal feature sets.
tf s = {fs,l} training data consisting of semantic features
of a medical concept pair along with class label.
tf t = {ft,l} training data consisting of temporal features
of a medical concept pair along with class label.
</construct>
<bodyText confidence="0.999896529411765">
into the labeled pool. An unlabeled sample is la-
beled in a particular iteration, if classifier confidence
&gt; 1/number of labels. In the next iteration, ran-
domly pick a subset of unlabeled samples and label
all samples in this subset. This could include sam-
ples that have already been labeled in previous iter-
ations. A label is assigned in a subsequent iteration
if: the sample was previously labeled OR if classi-
fier confidence &gt; threshold. The parameters in this
algorithm are the number of iterations, the pool size
of examples selected from the unlabeled set in each
iteration and the number of labeled examples added
at each iteration to the labeled data pool. Similar to
Blum and Mitchell (1998), we update the pool size
by 2p + 2n in each iteration, where p is the number
of medical pairs that corefer and n is the number of
medical concept pairs that do not corefer.
</bodyText>
<subsectionHeader confidence="0.999928">
5.2 MaxEnt with Posterior Regularization
</subsectionHeader>
<bodyText confidence="0.999974730769231">
The next semi-supervised learning method applied
to MCCR is MaxEnt with posterior regularization
using expectation constraints (Ganchev et al., 2010).
This method incorporates prior knowledge directly
on the output variables during learning. The prior
knowledge is expressed as inequalities on the ex-
pected value under the posterior distribution of user-
defined constraint features. Thus, posterior regular-
ization incorporates side-information into unsuper-
vised estimation in the form of constraints on the
model’s posteriors. It is similar to the EM algorithm
during learning, but it solves a problem similar to
Maximum Entropy inside the E-Step to enforce the
constraints.
Posterior regularization is used to derive a multi-
view learning algorithm while specifying constraints
that the models should agree on the label distri-
bution. We train MaxEnt models based on two
views of the data, semantic and temporal. This
method starts by considering the setting of complete
agreement where there is a common desired out-
put for the two models and each of the two views
is sufficiently rich to predict labels accurately. The
search is restricted to model pairs p1,p2 that sat-
isfy p1(y|x) Pz� p2(y|x), where p1 and p2 each de-
fine a distribution over labels. The product dis-
tribution p1(y1)p2(y2) is considered and constraint
features are defined such that the proposal distri-
bution q(y1, y2) will have the same marginal for
y1 and y2. There is one constraint feature defined
for each label y given by, Oy(y1, y2) = S(y1 =
y)S(y2 = y), where S(.) is the 0-1 indicator func-
tion. The constraint set Q = q : Eq[O] = 0 re-
quires that the marginals over the two output vari-
ables are identical q(y1) = q(y2). An agreement
between two models is defined as agree(p1, p2) =
argmin KL(q(y1,y2)||p1(y1)p2(y2))  |Eq [O] = 0.
In the semantic feature set, we convert the follow-
ing feature (described in Section 4) into expectation
constraints. The type of relation between the pair
of medical concepts, is derived from matching the
word stems and querying the UMLS definition and
atoms of the medical concepts. Based on the relation
between the medical concepts (i.e., partial match,
complete match, UMLS definition match, UMLS
atom match, and no match), we indicate the prob-
ability of label distribution coref and no-coref. If
the relation turns out to be no match, there is a high
probability that the medical concepts do not corefer.
In the temporal feature set, we convert the features
based on time-bins of the medical concepts in the
pair into expectation constraints.
</bodyText>
<page confidence="0.991476">
737
</page>
<table confidence="0.999434166666667">
Class(time-bin) Precision Recall
after discharge 96.05 62.53
before admission 94.02 92.44
on admission 33.25 75.16
way before admission 50.42 66.72
after admission 93.62 99.14
</table>
<tableCaption confidence="0.9787075">
Table 2: Sequence tagging of medical concepts with
time-bins using CRFs.
</tableCaption>
<sectionHeader confidence="0.983555" genericHeader="method">
6 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.999477">
6.1 Corpus Annotation
</subsectionHeader>
<bodyText confidence="0.999990428571429">
Annotation of clinical text is a time consuming and
costly process. Many annotation efforts have used
physicians to annotate the data. Instead, we use an-
notators that are students or recently graduated stu-
dents from diverse clinical backgrounds with vary-
ing levels of clinical experience. In spite of this di-
versity, the annotation agreement across our team of
annotators is high; all annotators agreed on 89.5% of
the events and our overall inter-annotator Cohen’s
kappa statistic (Conger, 1980) for medical events
was 0.865. The annotators mark medical concepts,
coereference chains and temporal expressions in the
clinical narratives and the NEJM case reports. They
also map each medical concept to a UMLS CUI.
</bodyText>
<subsectionHeader confidence="0.999815">
6.2 Feature Extraction
</subsectionHeader>
<bodyText confidence="0.999937315789474">
The first step involves extraction of semantic and
temporal features for the annotated medical con-
cepts, as described in Section 4 from both corpora.
The semantic relatedness scores are computed us-
ing the kDLS (Xiang et al., 2011) method to calcu-
late the relationship between concepts in the UMLS
with value of -y set to 7. The type of relation be-
tween medical concepts is derived by matching word
stems in each medical concept using the Lucene9
implementation of the Porter stemming algorithm.
We query the latest release (UMLS 2011AB) of the
UMLS Metathesaurus for finding a match between
medical concept and the UMLS definition or UMLS
atoms. The WordNet similarity score is computed
using Java API for WordNet Searching (JAWS).10
Explicit temporal expressions annotated in the
corpora are included in our temporal feature set.
Medical concepts in the NEJM are mostly de-
scribed temporally relative to the patient’s admis-
</bodyText>
<footnote confidence="0.99945">
9http://lucene.apache.org/
10http://lyle.smu.edu/˜tspell/jaws/
</footnote>
<table confidence="0.9997915">
Class NEJM Clinical Narratives
Precision Recall Precision Recall
coref 79.24 94.53 74.81 88.33
no-coref 86.71 90.62 83.92 94.86
</table>
<tableCaption confidence="0.999811">
Table 3: Supervised learning for MCCR.
</tableCaption>
<bodyText confidence="0.999978419354839">
sion. Temporal expressions like “2 years before ad-
mission” and “3 weeks before admission” are com-
mon. Hence, we use a heuristic-based algorithm
to associate medical concepts with explicit tempo-
ral expressions in the NEJM corpus. The algo-
rithm parses case reports and identifies the tempo-
ral expressions anchored to admission. All medi-
cal concepts following such a temporal expression
are anchored to it until a new temporal expression
is encountered. Over 88% of the medical concept-
temporal expression associations done with the al-
gorithm above is accurate when compared against
the NEJM gold standard.
As described in Section 4, we apply sequence tag-
ging using a CRF to assign medical concepts in clin-
ical narratives to time-bins. We use the implementa-
tion of CRF in Mallet,11 trained by Limited-Memory
BFGS for our experiments. We use the Stanford
POS tagger12 to identify verbs and derive verb pat-
terns. The dataset for the task of assigning medi-
cal concepts to time-bins consisted of 1613 medical
concepts. We used a 60-40 train-test split to train a
CRF using a sequence of medical concepts and ob-
served an overall accuracy of 92%. The precision
and recall values for each time-bin class is indicated
in Table 2. The percentage of medical concepts that
fall under “way before admission” and “on admis-
sion” are less than 5%, affecting the learning accu-
racy of those classes. When modeled as a multi-
class classification task using MaxEnt, we achieve
around 86% accuracy.
</bodyText>
<sectionHeader confidence="0.948033" genericHeader="method">
7 MCCR Results and Discussion
</sectionHeader>
<bodyText confidence="0.999886666666667">
We perform the following experiments for pairwise
MCCR: 1) Supervised learning with a MaxEnt clas-
sifier, using the combined semantic and temporal
feature set, 2) Co-training two MaxEnt models, 3)
Training MaxEnt models with using posterior regu-
larization.
</bodyText>
<footnote confidence="0.992371">
11http://mallet.cs.umass.edu/
12http://nlp.stanford.edu/software/tagger.
shtml
</footnote>
<page confidence="0.980872">
738
</page>
<table confidence="0.999904714285714">
Class NEJM Clinical Narratives
Co-train Precision Recall Precision Recall
coref 70.32 82.54 69.26 87.31
no-coref 82.54 84.85 71.15 89.44
PR Precision Recall Precision Recall
coref 76.63 90.41 74.81 84.25
no-coref 80.35 89.21 78.93 87.46
</table>
<tableCaption confidence="0.914163">
Table 4: Co-training and posterior regularization (PR) for
MCCR using semantic and temporal feature sets.
</tableCaption>
<bodyText confidence="0.999971056603774">
We use the MaxEnt classifier available in Mallet
for 1) and 2) and the the Mallet implementation of
MaxEnt models with posterior regularization for 3).
The NEJM corpus has 722 medical concepts,
12576 candidate pairs of medical concepts includ-
ing 137 pairs that corefer. We include all 12576
pairs in our experiments. The clinical narrative cor-
pus has 1613 medical concepts. The candidate pairs
and coreference chains for each patient is as follows.
Patient 1 has 241001 candidate pairs, 29 corefer-
ence chains. Patient 2 has 149604 candidate pairs,
9 coreference chains. Patient 3 has 6,446,521 can-
didate pairs, 20 coreference chains. From all the
candidate pairs in the clinical narrative corpus, 1025
pairs corefer. We randomly sample the no-coref in-
stances to restrict the corpus size to 1 million candi-
date pairs of medical concepts.
The results for all 3 experiments for both corpora
is shown in Tables 3, 4. We also train-test a super-
vised MaxEnt classifier on a 60-40 split of the en-
tire corpus. This gives us a precision of 74.81% and
88.33% recall (coref) for the binary classification
task of pairwise MCCR in the clinical narratives cor-
pus. In the both the semi-supervised experiments,
we use an initial labeled pool size of 30 where 12
medical concept pairs that corefer (p) and 18 that do
not corefer (n). The growth size is each iteration of
co-training is 2p+2n. At each iteration, confidently
labeled examples are added to the training set from
the previous iteration. The co-training algorithm
is run until all unlabeled instances become labeled.
The parameters in the posterior regularization im-
plementation include the regularization penalty for
each step and the number of iterations. We use the
default values (maxIterations=100, pGaussianPrior-
Variance=0.1, qGaussianPriorVariance=1000) sug-
gested on the Mallet toolkit page (Bellare et al.,
2009). Co-training two MaxEnt models based on
independent semantic and temporal views of the
data results in 69.26% precision and 87.31% recall
(coref), whereas training MaxEnt models with ex-
pectation constraints gives us 74.81% precision and
84.25% recall (coref), on the corpus of clinical nar-
ratives.
Posterior regularization does better than co-training
and the performance of both the semi-supervised
methods is comparable to if not as good as the super-
vised classifier trained on a 60-40 split of the corpus.
Thus, our results indicate that the use of semantic
and temporal features is effective for MCCR in clin-
ical text. It is clear from the co-training and poste-
rior regularization results that treating MCCR as a
semi-supervised problem works.
</bodyText>
<sectionHeader confidence="0.999247" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.99999019047619">
We investigated the task of MCCR in clinical text us-
ing supervised and semi-supervised learning meth-
ods. We create annotated corpora of clinical text
with case reports from the NEJM and narratives ob-
tained from The Ohio State University Wexner Med-
ical Center. We work with the hypothesis that de-
termining semantic and temporal similarity between
medical concepts helps resolve coreferences. In
order to test this hypothesis, we describe the pro-
cess of semantic and temporal feature extraction
from clinical text. We demonstrate the effective-
ness of the extracted features in a supervised binary
classification task for MCCR with MaxEnt classi-
fiers (using the combined feature set) as well as us-
ing semi-supervised methods of co-training MaxEnt
classifiers and training MaxEnt models using pos-
terior regularization (using two independent views
of the data - semantic view and temporal view).
Thus, we show that MCRR can be performed using
semi-supervised learning with semantic and tempo-
ral views of the data.
</bodyText>
<sectionHeader confidence="0.99698" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999941222222222">
The project described was supported by the
National Center for Research Resources,
Grant UL1RR025755, KL2RR025754, and
TL1RR025753, and is now at the National
Center for Advancing Translational Sciences,
Grant 8KL2TR000112-05, 8UL1TR000090-05,
8TL1TR000091-05. The content is solely the re-
sponsibility of the authors and does not necessarily
represent the official views of the NIH.
</bodyText>
<page confidence="0.997714">
739
</page>
<sectionHeader confidence="0.993864" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999947179245283">
Sophia Ananiadou, Carol Freidman, and Junichi Tsu-
jii. 2004. Introduction: named entity recognition in
biomedicine. J. ofBiomedical Informatics, pages 393–
395.
Kedar Bellare, Gregory Druck, and Andrew McCallum.
2009. Alternating projections for learning with expec-
tation constraints. In Proceedings of the Twenty-Fifth
Conference on Uncertainty in Artificial Intelligence,
UAI ’09, pages 43–50.
Avrim Blum and Tom M. Mitchell. 1998. Combin-
ing labeled and unlabeled data with co-training. In
COLT’98, pages 92–100.
Bigi Brigitte. 2003. Using Kullback-Leibler distance for
text categorization. In Proceedings of the 25th Euro-
pean conference on IR research, ECIR’03, pages 305–
319.
Wendy W Chapman, Prakash M Nadkarni, Lynette
Hirschman, Guergana K Savova Leonard W D’Avolio,
and Ozlem Uzuner. 2011. Overcoming barriers to
NLP for clinical text: the role of shared tasks and the
need for additional creative solutions. In JAMIA.
Jung-Hsien Chiang, Jou-Wei Lin, and Chen-Wei Yang.
2010. Automated evaluation of electronic discharge
notes to assess quality of care for cardiovascular dis-
eases using Medical Language Extraction and Encod-
ing System (MedLEE). JAMIA, pages 245–252.
A.J. Conger. 1980. Integration and generalization of
kappas for multiple raters. In Psychological Bulletin
Vol 88(2), pages 322–328.
Peter J Embi and Philip Payne. 2009. Clinical research
informatics: challenges, opportunities and definition
for an emerging domain. Journal of the American
Medical Informatics Association, 16(3):316–327.
Carol Friedman, Pauline Kra, and Andrey Rzhetsky.
2002. Two biomedical sublanguages: a description
based on the theories of Zellig Harris. Journal of
Biomedical Informatics, 35(4):222–235.
Rob Gaizauskas, Henk Harkema, Mark Hepple, and An-
drea Setzer. 2006. Task-oriented extraction of tem-
poral information: The case of clinical narratives.
In Proceedings of the Thirteenth International Sym-
posium on Temporal Representation and Reasoning,
TIME ’06, pages 188–195.
Kuzman Ganchev, Joo Graa, Jennifer Gillenwater, and
Ben Taskar. 2010. Posterior regularization for struc-
tured latent variable models. Journal of Machine
Learning Research, pages 2001–2049.
Tian Ye He. 2007. Coreference Resolution on Entities
and Events for Hospital Discharge Summaries. EECS,
Cambridge, MA, MIT. M.Eng.
Hyuckchul Jung, James Allen, Nate Blaylock, Will
de Beaumont, Lucian Galescu, and Mary Swift. 2011.
Building timelines from narrative clinical records: ini-
tial results based-on deep natural language under-
standing. In Proceedings of BioNLP 2011 Workshop,
BioNLP ’11, pages 146–154.
Christoph Muller, Stefan Rapp, and Michael Strube.
2002. Applying co-training to reference resolution. In
ACL, pages 352–359.
Vincent Ng. 2010. Supervised noun phrase coreference
research: The first fifteen years. In Proceedings of the
ACL, pages 1396–1411.
Kamal Nigam and Rayid Ghani. 2000. Analyzing
the effectiveness and applicability of co-training. In
CIKM’00, pages 86–93.
James Pustejovsky, Jos M. Castao, Robert Ingria, Roser
Sauri, Robert J. Gaizauskas, Andrea Setzer, Graham
Katz, and Dragomir R. Radev. 2003. Timeml: Robust
specification of event and temporal expressions in text.
In New Directions in Question Answering’03, pages
28–34.
Preethi Raghavan and Albert M. Lai. 2010. Leveraging
natural language processing of clinical narratives for
phenotype modeling. In PIKM’10, pages 57–66.
Karthik Raghunathan, Heeyoung Lee, Sudarshan Ran-
garajan, Nathanael Chambers, Mihai Surdeanu, Dan
Jurafsky, and Christopher Manning. 2010. A multi-
pass sieve for coreference resolution. In Proceedings
of the 2010 Conference on Empirical Methods in Nat-
ural Language Processing, EMNLP ’10, pages 492–
501, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Guergana K. Savova, James J. Masanz, Philip V.
Ogren, Jiaping Zheng, Sunghwan Sohn, Karin Kip-
per Schuler, and Christopher G. Chute. 2010. Mayo
clinical text analysis and knowledge extraction sys-
tem (cTAKES): architecture, component evaluation
and applications. JAMIA, pages 507–513.
Guergana K. Savova, Wendy Webber Chapman, Jiaping
Zheng, and Rebecca S. Crowley. 2011. Anaphoric
relations in the clinical narrative: corpus creation.
JAMIA, 18(4):459–465.
Wee Meng Soon, Hwee Tou Ng, and Chung Yong Lim.
2001. A machine learning approach to coreference
resolution of noun phrases. Computational Linguis-
tics, pages 521–544.
Yang Xiang, Kewei Lu, Stephen L James, Tara B Bor-
lawsky, Kun Huang, and Philip R O Payne. 2011. k-
neighborhood decentralization: A comprehensive so-
lution to index the UMLS for scale knowledge discov-
ery. In Journal of Biomedical Informatics.
Jiaping Zheng, Wendy Webber Chapman, Rebecca S.
Crowley, and Guergana K. Savova. 2011. Coreference
resolution: A review of general methodologies and ap-
plications in the clinical domain. Journal of Biomedi-
cal Informatics, 44(6):1113–1122.
</reference>
<page confidence="0.965459">
740
</page>
<reference confidence="0.945019444444445">
Li Zhou and George Hripcsak. 2007. Temporal rea-
soning with medical data - a review with emphasis
on medical natural language processing. Journal of
Biomedical Informatics, pages 183–202.
Li Zhou, Genevieve B. Melton, Simon Parsons, and
George Hripcsak. 2006. A temporal constraint struc-
ture for extracting temporal information from clinical
narrative. Journal of Biomedical Informatics, pages
424–439.
</reference>
<page confidence="0.997855">
741
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.297676">
<title confidence="0.9993385">Exploring Semi-Supervised Coreference Resolution of Medical Concepts using Semantic and Temporal Features</title>
<author confidence="0.990641">Eric</author>
<author confidence="0.990641">M Albert</author>
<affiliation confidence="0.944586333333333">of Computer Science and of Biomedical The Ohio State University, Columbus, Ohio,</affiliation>
<email confidence="0.999788">albert.lai@osumc.edu</email>
<abstract confidence="0.952836045454546">We investigate the task of medical concept coreference resolution in clinical text using two semi-supervised methods, co-training and multi-view learning with posterior regularization. By extracting semantic and temporal features of medical concepts found in clinical text, we create conditionally independent data views; co-training MaxEnt classifiers on this data works almost as well as supervised learning for the task of pairwise coreference resolution of medical concepts. We also train Max- Ent models with expectation constraints, using posterior regularization, and find that posterior regularization performs comparably to or slightly better than co-training. We describe the process of semantic and temporal feature extraction and demonstrate our methods on a corpus of case reports from the New England Journal of Medicine and a corpus of patient narratives obtained from The Ohio State University Wexner Medical Center.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sophia Ananiadou</author>
<author>Carol Freidman</author>
<author>Junichi Tsujii</author>
</authors>
<title>Introduction: named entity recognition in biomedicine.</title>
<date>2004</date>
<journal>J. ofBiomedical Informatics,</journal>
<pages>393--395</pages>
<contexts>
<context position="5612" citStr="Ananiadou et al., 2004" startWordPosition="818" endWordPosition="821"> for pairwise MCCR using a MaxEnt classifier. 2 Related Work Free-text reports form a significant portion of the information content in a patient’s medical record. There is great need for tools that can structure the information in clinical text for use in various studies studies such as clinical trials, quality assessment of healthcare delivery in institutions, and public health research. Researchers have been investigating ways in which clinical free-text can be structured to transform the information content in a clinical narrative into a representation suitable for computational analysis (Ananiadou et al., 2004). Medical NLP systems like Mayo’s cTakes (Savova et al., 2010), IBM’s MedKAT,1 and MedLEE (Chiang et al., 2010), have components specifically trained or designed for the clinical domain, to support tasks such as named entity recognition. Previous attempts at learning temporal relations between medical events in clinical text include work by Jung et 1https://cabig-kc.nci.nih.gov/Vocab/KC/ index.php/OHNLP al. (2011) and Zhou et al. (2006). Gaizauskas et al. (2006) learn the temporal relations before, after, is included between events from a corpus of clinical text much like the event-event relat</context>
</contexts>
<marker>Ananiadou, Freidman, Tsujii, 2004</marker>
<rawString>Sophia Ananiadou, Carol Freidman, and Junichi Tsujii. 2004. Introduction: named entity recognition in biomedicine. J. ofBiomedical Informatics, pages 393– 395.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kedar Bellare</author>
<author>Gregory Druck</author>
<author>Andrew McCallum</author>
</authors>
<title>Alternating projections for learning with expectation constraints.</title>
<date>2009</date>
<booktitle>In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, UAI ’09,</booktitle>
<pages>43--50</pages>
<contexts>
<context position="36717" citStr="Bellare et al., 2009" startWordPosition="5779" endWordPosition="5782">2 medical concept pairs that corefer (p) and 18 that do not corefer (n). The growth size is each iteration of co-training is 2p+2n. At each iteration, confidently labeled examples are added to the training set from the previous iteration. The co-training algorithm is run until all unlabeled instances become labeled. The parameters in the posterior regularization implementation include the regularization penalty for each step and the number of iterations. We use the default values (maxIterations=100, pGaussianPriorVariance=0.1, qGaussianPriorVariance=1000) suggested on the Mallet toolkit page (Bellare et al., 2009). Co-training two MaxEnt models based on independent semantic and temporal views of the data results in 69.26% precision and 87.31% recall (coref), whereas training MaxEnt models with expectation constraints gives us 74.81% precision and 84.25% recall (coref), on the corpus of clinical narratives. Posterior regularization does better than co-training and the performance of both the semi-supervised methods is comparable to if not as good as the supervised classifier trained on a 60-40 split of the corpus. Thus, our results indicate that the use of semantic and temporal features is effective for</context>
</contexts>
<marker>Bellare, Druck, McCallum, 2009</marker>
<rawString>Kedar Bellare, Gregory Druck, and Andrew McCallum. 2009. Alternating projections for learning with expectation constraints. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence, UAI ’09, pages 43–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avrim Blum</author>
<author>Tom M Mitchell</author>
</authors>
<title>Combining labeled and unlabeled data with co-training.</title>
<date>1998</date>
<booktitle>In COLT’98,</booktitle>
<pages>92--100</pages>
<contexts>
<context position="8093" citStr="Blum and Mitchell, 1998" startWordPosition="1194" endWordPosition="1197">coreference resolution for entities that fall into five medical semantic categories commonly appearing in discharge summaries. However, we focus on feature extraction to determine the similarity between medical concepts, both in terms of meaning and time of occurrence, for resolving coreferences within and across all types of clinical narratives. A disadvantage of supervised machine learning approaches is the need for an unknown amount of annotated training data for optimal performance. Researchers then began to experiment with weakly supervised machine learning algorithms such as cotraining (Blum and Mitchell, 1998). Muller et al. (2002) investigate the practical applicability of cotraining for the task of building a classifier for coreference resolution and observed that the results were 2https://www.i2b2.org/NLP/Coreference/ 3https://www.i2b2.org/NLP/Coreference/assets/ CoreferenceGuidelines.pdf 732 mostly negative for their dataset. Ganchev et al. (2010) propose a posterior regularization framework for weakly supervised learning to derive a multi-view learning algorithm. Multi-view methods typically begin by assuming that each view alone can yield a good predictor. Under this assumption, we can regula</context>
<context position="24704" citStr="Blum and Mitchell (1998)" startWordPosition="3853" endWordPosition="3856">narrative order {M1, M2, M3, ..}, we learn a corresponding label sequence of time-bins {way before admission, before admission, on admission, after admission, after discharge}. The learned label sequence is now used as part of the temporal feature set in co-training and posterior regularization for MCCR. 5 Weakly Supervised Learning 5.1 Co-training We co-train two MaxEnt classifiers, one each on the semantic features f� and temporal features f� of the data, to classify pairs of medical concepts as corefer or no-corefer in a semi-supervised fashion. We use the co-training algorithm proposed by Blum and Mitchell (1998). The assumption here is that each feature set contains sufficient information to train a model for classification of medical concepts. Consider the concept pair, {renal inflammation, posterior uveitis} that corefer. The semantic view for this concept pair may not strongly indicate coreference. The “UMLS relation type” feature indicates that the two concepts are not similar in meaning. However, both concepts are mapped to the same time-bin after admission. Thus, the time-bin along with features extracted based on explicit temporal expressions co-occurring with the medical concepts indicate a c</context>
<context position="26553" citStr="Blum and Mitchell, 1998" startWordPosition="4153" endWordPosition="4156">tain model m1 2. Train classifier c2 on tft to obtain model m2 3. Use m1 to classify a subset of unlabeled data and update the training data as, tfs.subset = fusubset1, predicted label} iff classifier confidence &gt; 1/number of labels 4. Use m2 to classify a subset of unlabeled data and update the training data as, tft.subset = fusubset2, predicted label} iff classifier confidence &gt; 1/number of labels 5. tfs = tfs + tf t.subset + fusubset1, predicted label} 6. tft = tft + tfs.subset + fusubset2, predicted label} Table 1: Co-training algorithm for the binary pairwise classification task of MCCR (Blum and Mitchell, 1998). c = classifier, u = unlabeled data. usubset1, usubset2 = subsets of unlabeled data. usubset1 and usubset2 are mutually exclusive. F = {fs, ft} is the features space divided into conditionally independent semantic and temporal feature sets. tf s = {fs,l} training data consisting of semantic features of a medical concept pair along with class label. tf t = {ft,l} training data consisting of temporal features of a medical concept pair along with class label. into the labeled pool. An unlabeled sample is labeled in a particular iteration, if classifier confidence &gt; 1/number of labels. In the nex</context>
</contexts>
<marker>Blum, Mitchell, 1998</marker>
<rawString>Avrim Blum and Tom M. Mitchell. 1998. Combining labeled and unlabeled data with co-training. In COLT’98, pages 92–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bigi Brigitte</author>
</authors>
<title>Using Kullback-Leibler distance for text categorization.</title>
<date>2003</date>
<booktitle>In Proceedings of the 25th European conference on IR research, ECIR’03,</booktitle>
<pages>305--319</pages>
<contexts>
<context position="15796" citStr="Brigitte, 2003" startWordPosition="2407" endWordPosition="2408">. (2011) observe several fold enrichment values when -y is varied between 5 and 15. Besides traversing the UMLS graph structure using the kDLS method to obtain a similarity score between medical concepts, we also measure similarity between medical concepts by taking into account the surrounding context. We do so by measuring the KL-divergence between the sentences to which the medical concepts belong. In order to avoid the possibility of an empty set when calculating the intersection of the probability distributions, we use a smoothing method that makes the probability distributions sum to 1 (Brigitte, 2003). Another important semantic feature is the type of relation between the medical concepts. This feature is calculated by first computing the stemmed word overlap between the medical concepts and deriving features based on exact and partial matches between the word stems of the medical concepts. If there is no exact or partial match between the concepts, we query the UMLS to check if the stem of one of the medical concepts occurs in the UMLS definition or atoms of the other medical event. An atom is the smallest unit of naming within the UMLS. A medical concept in UMLS represents a single meani</context>
</contexts>
<marker>Brigitte, 2003</marker>
<rawString>Bigi Brigitte. 2003. Using Kullback-Leibler distance for text categorization. In Proceedings of the 25th European conference on IR research, ECIR’03, pages 305– 319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wendy W Chapman</author>
<author>Prakash M Nadkarni</author>
<author>Lynette Hirschman</author>
<author>Guergana K Savova Leonard W D’Avolio</author>
<author>Ozlem Uzuner</author>
</authors>
<title>Overcoming barriers to NLP for clinical text: the role of shared tasks and the need for additional creative solutions.</title>
<date>2011</date>
<booktitle>In JAMIA.</booktitle>
<marker>Chapman, Nadkarni, Hirschman, D’Avolio, Uzuner, 2011</marker>
<rawString>Wendy W Chapman, Prakash M Nadkarni, Lynette Hirschman, Guergana K Savova Leonard W D’Avolio, and Ozlem Uzuner. 2011. Overcoming barriers to NLP for clinical text: the role of shared tasks and the need for additional creative solutions. In JAMIA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jung-Hsien Chiang</author>
<author>Jou-Wei Lin</author>
<author>Chen-Wei Yang</author>
</authors>
<title>Automated evaluation of electronic discharge notes to assess quality of care for cardiovascular diseases using Medical Language Extraction and Encoding System (MedLEE).</title>
<date>2010</date>
<pages>245--252</pages>
<publisher>JAMIA,</publisher>
<contexts>
<context position="5723" citStr="Chiang et al., 2010" startWordPosition="837" endWordPosition="840">nformation content in a patient’s medical record. There is great need for tools that can structure the information in clinical text for use in various studies studies such as clinical trials, quality assessment of healthcare delivery in institutions, and public health research. Researchers have been investigating ways in which clinical free-text can be structured to transform the information content in a clinical narrative into a representation suitable for computational analysis (Ananiadou et al., 2004). Medical NLP systems like Mayo’s cTakes (Savova et al., 2010), IBM’s MedKAT,1 and MedLEE (Chiang et al., 2010), have components specifically trained or designed for the clinical domain, to support tasks such as named entity recognition. Previous attempts at learning temporal relations between medical events in clinical text include work by Jung et 1https://cabig-kc.nci.nih.gov/Vocab/KC/ index.php/OHNLP al. (2011) and Zhou et al. (2006). Gaizauskas et al. (2006) learn the temporal relations before, after, is included between events from a corpus of clinical text much like the event-event relation tlink learning in Timebank (Pustejovsky et al., 2003). A comprehensive survey of temporal reasoning in medi</context>
</contexts>
<marker>Chiang, Lin, Yang, 2010</marker>
<rawString>Jung-Hsien Chiang, Jou-Wei Lin, and Chen-Wei Yang. 2010. Automated evaluation of electronic discharge notes to assess quality of care for cardiovascular diseases using Medical Language Extraction and Encoding System (MedLEE). JAMIA, pages 245–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A J Conger</author>
</authors>
<title>Integration and generalization of kappas for multiple raters.</title>
<date>1980</date>
<journal>In Psychological Bulletin Vol</journal>
<volume>88</volume>
<issue>2</issue>
<pages>322--328</pages>
<contexts>
<context position="31271" citStr="Conger, 1980" startWordPosition="4927" endWordPosition="4928"> Table 2: Sequence tagging of medical concepts with time-bins using CRFs. 6 Experimental Setup 6.1 Corpus Annotation Annotation of clinical text is a time consuming and costly process. Many annotation efforts have used physicians to annotate the data. Instead, we use annotators that are students or recently graduated students from diverse clinical backgrounds with varying levels of clinical experience. In spite of this diversity, the annotation agreement across our team of annotators is high; all annotators agreed on 89.5% of the events and our overall inter-annotator Cohen’s kappa statistic (Conger, 1980) for medical events was 0.865. The annotators mark medical concepts, coereference chains and temporal expressions in the clinical narratives and the NEJM case reports. They also map each medical concept to a UMLS CUI. 6.2 Feature Extraction The first step involves extraction of semantic and temporal features for the annotated medical concepts, as described in Section 4 from both corpora. The semantic relatedness scores are computed using the kDLS (Xiang et al., 2011) method to calculate the relationship between concepts in the UMLS with value of -y set to 7. The type of relation between medica</context>
</contexts>
<marker>Conger, 1980</marker>
<rawString>A.J. Conger. 1980. Integration and generalization of kappas for multiple raters. In Psychological Bulletin Vol 88(2), pages 322–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter J Embi</author>
<author>Philip Payne</author>
</authors>
<title>Clinical research informatics: challenges, opportunities and definition for an emerging domain.</title>
<date>2009</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>16</volume>
<issue>3</issue>
<contexts>
<context position="1929" citStr="Embi and Payne, 2009" startWordPosition="264" endWordPosition="267">ction The clinical community creates and uses a variety of semi-structured and unstructured electronic textual documents that include medical reports such as admission notes, progress notes, pathology reports, radiology reports and hospital discharge summaries. The documents, collectively termed clinical narratives, account for various medical conditions, procedures, diagnoses and assessments in a patient’s medical history. Researchers have investigated ways in which clinical text can be automatically processed for enabling access to relevant information for physicians and health researchers (Embi and Payne, 2009). One application is to support patient recruitment into clinical trials (research studies that try to answer scientific questions to find better ways to prevent, diagnose, or treat a disease) by matching patient characteristics against eligibility criteria (Raghavan and Lai, 2010). While there has been significant efforts to move to structured data collection, clinical narratives remain a critical data source for these tasks. Extracting structured information from unstructured clinical text using natural language processing (NLP) is complicated by the distinct clinical reporting sub-language </context>
</contexts>
<marker>Embi, Payne, 2009</marker>
<rawString>Peter J Embi and Philip Payne. 2009. Clinical research informatics: challenges, opportunities and definition for an emerging domain. Journal of the American Medical Informatics Association, 16(3):316–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carol Friedman</author>
<author>Pauline Kra</author>
<author>Andrey Rzhetsky</author>
</authors>
<title>Two biomedical sublanguages: a description based on the theories of Zellig Harris.</title>
<date>2002</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>35</volume>
<issue>4</issue>
<contexts>
<context position="2624" citStr="Friedman et al., 2002" startWordPosition="364" endWordPosition="367">(research studies that try to answer scientific questions to find better ways to prevent, diagnose, or treat a disease) by matching patient characteristics against eligibility criteria (Raghavan and Lai, 2010). While there has been significant efforts to move to structured data collection, clinical narratives remain a critical data source for these tasks. Extracting structured information from unstructured clinical text using natural language processing (NLP) is complicated by the distinct clinical reporting sub-language characterized by incomplete sentences and domain specific abbreviations (Friedman et al., 2002). The large number of clinical narratives generated per patient, over the years, along with redundant information within and across narratives, further adds to the complexity of using information structured using NLP. There is a tendency to copy and edit parts of an old clinical narrative whenever a new one is created, thus leading to redundant information in clinical narratives of a patient. Furthermore, since different types of clinical narratives are created for different purposes, certain narratives may summarize information from various other, at times older, clinical narratives. All of t</context>
</contexts>
<marker>Friedman, Kra, Rzhetsky, 2002</marker>
<rawString>Carol Friedman, Pauline Kra, and Andrey Rzhetsky. 2002. Two biomedical sublanguages: a description based on the theories of Zellig Harris. Journal of Biomedical Informatics, 35(4):222–235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rob Gaizauskas</author>
<author>Henk Harkema</author>
<author>Mark Hepple</author>
<author>Andrea Setzer</author>
</authors>
<title>Task-oriented extraction of temporal information: The case of clinical narratives.</title>
<date>2006</date>
<booktitle>In Proceedings of the Thirteenth International Symposium on Temporal Representation and Reasoning, TIME ’06,</booktitle>
<pages>188--195</pages>
<contexts>
<context position="6078" citStr="Gaizauskas et al. (2006)" startWordPosition="887" endWordPosition="890"> be structured to transform the information content in a clinical narrative into a representation suitable for computational analysis (Ananiadou et al., 2004). Medical NLP systems like Mayo’s cTakes (Savova et al., 2010), IBM’s MedKAT,1 and MedLEE (Chiang et al., 2010), have components specifically trained or designed for the clinical domain, to support tasks such as named entity recognition. Previous attempts at learning temporal relations between medical events in clinical text include work by Jung et 1https://cabig-kc.nci.nih.gov/Vocab/KC/ index.php/OHNLP al. (2011) and Zhou et al. (2006). Gaizauskas et al. (2006) learn the temporal relations before, after, is included between events from a corpus of clinical text much like the event-event relation tlink learning in Timebank (Pustejovsky et al., 2003). A comprehensive survey of temporal reasoning in medical data is provided by Zhou and Hripcsak (2007). Chapman et al. (2011) discuss barriers to NLP development in the clinical domain. Coreference resolution is a well-studied problem in computational linguistics (Ng, 2010; Raghunathan et al., 2010). Supervised machine learning algorithms have been previously used for noun phrase coreference resolution wit</context>
</contexts>
<marker>Gaizauskas, Harkema, Hepple, Setzer, 2006</marker>
<rawString>Rob Gaizauskas, Henk Harkema, Mark Hepple, and Andrea Setzer. 2006. Task-oriented extraction of temporal information: The case of clinical narratives. In Proceedings of the Thirteenth International Symposium on Temporal Representation and Reasoning, TIME ’06, pages 188–195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Joo Graa</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Posterior regularization for structured latent variable models.</title>
<date>2010</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>2001--2049</pages>
<contexts>
<context position="8441" citStr="Ganchev et al. (2010)" startWordPosition="1235" endWordPosition="1238">disadvantage of supervised machine learning approaches is the need for an unknown amount of annotated training data for optimal performance. Researchers then began to experiment with weakly supervised machine learning algorithms such as cotraining (Blum and Mitchell, 1998). Muller et al. (2002) investigate the practical applicability of cotraining for the task of building a classifier for coreference resolution and observed that the results were 2https://www.i2b2.org/NLP/Coreference/ 3https://www.i2b2.org/NLP/Coreference/assets/ CoreferenceGuidelines.pdf 732 mostly negative for their dataset. Ganchev et al. (2010) propose a posterior regularization framework for weakly supervised learning to derive a multi-view learning algorithm. Multi-view methods typically begin by assuming that each view alone can yield a good predictor. Under this assumption, we can regularize the models from each view by constraining the amount by which we permit them to disagree on unlabeled instances. In the proposed approach, they train a model for each view, and use constraints that the models should agree on the label distribution. We investigate the applicability of these two weakly supervised methods to the task of MCCR us</context>
<context position="28078" citStr="Ganchev et al., 2010" startWordPosition="4408" endWordPosition="4411">e parameters in this algorithm are the number of iterations, the pool size of examples selected from the unlabeled set in each iteration and the number of labeled examples added at each iteration to the labeled data pool. Similar to Blum and Mitchell (1998), we update the pool size by 2p + 2n in each iteration, where p is the number of medical pairs that corefer and n is the number of medical concept pairs that do not corefer. 5.2 MaxEnt with Posterior Regularization The next semi-supervised learning method applied to MCCR is MaxEnt with posterior regularization using expectation constraints (Ganchev et al., 2010). This method incorporates prior knowledge directly on the output variables during learning. The prior knowledge is expressed as inequalities on the expected value under the posterior distribution of userdefined constraint features. Thus, posterior regularization incorporates side-information into unsupervised estimation in the form of constraints on the model’s posteriors. It is similar to the EM algorithm during learning, but it solves a problem similar to Maximum Entropy inside the E-Step to enforce the constraints. Posterior regularization is used to derive a multiview learning algorithm w</context>
</contexts>
<marker>Ganchev, Graa, Gillenwater, Taskar, 2010</marker>
<rawString>Kuzman Ganchev, Joo Graa, Jennifer Gillenwater, and Ben Taskar. 2010. Posterior regularization for structured latent variable models. Journal of Machine Learning Research, pages 2001–2049.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tian Ye He</author>
</authors>
<title>Coreference Resolution on Entities and Events for Hospital Discharge Summaries. EECS,</title>
<date>2007</date>
<location>Cambridge, MA, MIT. M.Eng.</location>
<contexts>
<context position="7307" citStr="He (2007)" startWordPosition="1086" endWordPosition="1087">s (Soon et al., 2001; Raghunathan et al., 2010). Recently, the i2b2 challenge2 on coreference resolution examined coreference resolution in clinical data. The problem addressed in our paper is similar to the task described in the i2b2 challenge.3 Besides the i2b2 challenge, there has not been significant work in MCCR. This may be due to various privacy concerns and the efforts required to anonymize and annotate massive amounts of patient narratives. Zheng et al. (2011) review heuristic-based, supervised and unsupervised methods for coreference resolution in the context of the clinical domain. He (2007) studied coreference resolution in discharge summaries, treating coreference resolution as a binary classification problem and investigated critical features for coreference resolution for entities that fall into five medical semantic categories commonly appearing in discharge summaries. However, we focus on feature extraction to determine the similarity between medical concepts, both in terms of meaning and time of occurrence, for resolving coreferences within and across all types of clinical narratives. A disadvantage of supervised machine learning approaches is the need for an unknown amoun</context>
</contexts>
<marker>He, 2007</marker>
<rawString>Tian Ye He. 2007. Coreference Resolution on Entities and Events for Hospital Discharge Summaries. EECS, Cambridge, MA, MIT. M.Eng.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hyuckchul Jung</author>
<author>James Allen</author>
<author>Nate Blaylock</author>
<author>Will de Beaumont</author>
<author>Lucian Galescu</author>
<author>Mary Swift</author>
</authors>
<title>Building timelines from narrative clinical records: initial results based-on deep natural language understanding.</title>
<date>2011</date>
<journal>Workshop, BioNLP</journal>
<booktitle>In Proceedings of BioNLP</booktitle>
<volume>11</volume>
<pages>146--154</pages>
<marker>Jung, Allen, Blaylock, de Beaumont, Galescu, Swift, 2011</marker>
<rawString>Hyuckchul Jung, James Allen, Nate Blaylock, Will de Beaumont, Lucian Galescu, and Mary Swift. 2011. Building timelines from narrative clinical records: initial results based-on deep natural language understanding. In Proceedings of BioNLP 2011 Workshop, BioNLP ’11, pages 146–154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Muller</author>
<author>Stefan Rapp</author>
<author>Michael Strube</author>
</authors>
<title>Applying co-training to reference resolution.</title>
<date>2002</date>
<booktitle>In ACL,</booktitle>
<pages>352--359</pages>
<contexts>
<context position="8115" citStr="Muller et al. (2002)" startWordPosition="1198" endWordPosition="1201"> entities that fall into five medical semantic categories commonly appearing in discharge summaries. However, we focus on feature extraction to determine the similarity between medical concepts, both in terms of meaning and time of occurrence, for resolving coreferences within and across all types of clinical narratives. A disadvantage of supervised machine learning approaches is the need for an unknown amount of annotated training data for optimal performance. Researchers then began to experiment with weakly supervised machine learning algorithms such as cotraining (Blum and Mitchell, 1998). Muller et al. (2002) investigate the practical applicability of cotraining for the task of building a classifier for coreference resolution and observed that the results were 2https://www.i2b2.org/NLP/Coreference/ 3https://www.i2b2.org/NLP/Coreference/assets/ CoreferenceGuidelines.pdf 732 mostly negative for their dataset. Ganchev et al. (2010) propose a posterior regularization framework for weakly supervised learning to derive a multi-view learning algorithm. Multi-view methods typically begin by assuming that each view alone can yield a good predictor. Under this assumption, we can regularize the models from e</context>
</contexts>
<marker>Muller, Rapp, Strube, 2002</marker>
<rawString>Christoph Muller, Stefan Rapp, and Michael Strube. 2002. Applying co-training to reference resolution. In ACL, pages 352–359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Supervised noun phrase coreference research: The first fifteen years.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>1396--1411</pages>
<contexts>
<context position="6542" citStr="Ng, 2010" startWordPosition="963" endWordPosition="964">text include work by Jung et 1https://cabig-kc.nci.nih.gov/Vocab/KC/ index.php/OHNLP al. (2011) and Zhou et al. (2006). Gaizauskas et al. (2006) learn the temporal relations before, after, is included between events from a corpus of clinical text much like the event-event relation tlink learning in Timebank (Pustejovsky et al., 2003). A comprehensive survey of temporal reasoning in medical data is provided by Zhou and Hripcsak (2007). Chapman et al. (2011) discuss barriers to NLP development in the clinical domain. Coreference resolution is a well-studied problem in computational linguistics (Ng, 2010; Raghunathan et al., 2010). Supervised machine learning algorithms have been previously used for noun phrase coreference resolution with fairly good results (Soon et al., 2001; Raghunathan et al., 2010). Recently, the i2b2 challenge2 on coreference resolution examined coreference resolution in clinical data. The problem addressed in our paper is similar to the task described in the i2b2 challenge.3 Besides the i2b2 challenge, there has not been significant work in MCCR. This may be due to various privacy concerns and the efforts required to anonymize and annotate massive amounts of patient na</context>
</contexts>
<marker>Ng, 2010</marker>
<rawString>Vincent Ng. 2010. Supervised noun phrase coreference research: The first fifteen years. In Proceedings of the ACL, pages 1396–1411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kamal Nigam</author>
<author>Rayid Ghani</author>
</authors>
<title>Analyzing the effectiveness and applicability of co-training.</title>
<date>2000</date>
<booktitle>In CIKM’00,</booktitle>
<pages>86--93</pages>
<contexts>
<context position="12521" citStr="Nigam and Ghani (2000)" startWordPosition="1880" endWordPosition="1883">ess between medical concepts in terms of their meaning. This is quantified by measuring distance between medical events in the UMLS Metathesaurus graph structure (Xiang et al., 2011). Temporal relatedness measures the closeness between medical concepts in terms of when they occurred. This is achieved by first, learning to assign every medical concept to a time-bin, and then using the time-bin as a feature for learning to resolve coreferences. Extracting semantic and temporal features helps identify conditionally independent views of the data for co-training classifiers. As previously noted by Nigam and Ghani (2000), it is hard to identify conditionally independent views for real-data problems. However, we believe there are no natural dependencies between the semantic and temporal feature sets. While semantic features help identify synonymous medical concepts, that alone may not guarantee coreference. Medical con4https://uts.nlm.nih.gov/home.html 733 Section 5 Section 4 Figure 1: MCCR pipeline: Extract semantic and temporal features from clinical text to train MaxEnt classifiers for medical concept coreference resolution using 1) Cotraining or 2) Posterior Regularization cepts that are similar in meaning</context>
</contexts>
<marker>Nigam, Ghani, 2000</marker>
<rawString>Kamal Nigam and Rayid Ghani. 2000. Analyzing the effectiveness and applicability of co-training. In CIKM’00, pages 86–93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Jos M Castao</author>
<author>Robert Ingria</author>
<author>Roser Sauri</author>
<author>Robert J Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Graham Katz</author>
<author>Dragomir R Radev</author>
</authors>
<title>Timeml: Robust specification of event and temporal expressions in text.</title>
<date>2003</date>
<booktitle>In New Directions in Question Answering’03,</booktitle>
<pages>28--34</pages>
<contexts>
<context position="6269" citStr="Pustejovsky et al., 2003" startWordPosition="917" endWordPosition="920">s cTakes (Savova et al., 2010), IBM’s MedKAT,1 and MedLEE (Chiang et al., 2010), have components specifically trained or designed for the clinical domain, to support tasks such as named entity recognition. Previous attempts at learning temporal relations between medical events in clinical text include work by Jung et 1https://cabig-kc.nci.nih.gov/Vocab/KC/ index.php/OHNLP al. (2011) and Zhou et al. (2006). Gaizauskas et al. (2006) learn the temporal relations before, after, is included between events from a corpus of clinical text much like the event-event relation tlink learning in Timebank (Pustejovsky et al., 2003). A comprehensive survey of temporal reasoning in medical data is provided by Zhou and Hripcsak (2007). Chapman et al. (2011) discuss barriers to NLP development in the clinical domain. Coreference resolution is a well-studied problem in computational linguistics (Ng, 2010; Raghunathan et al., 2010). Supervised machine learning algorithms have been previously used for noun phrase coreference resolution with fairly good results (Soon et al., 2001; Raghunathan et al., 2010). Recently, the i2b2 challenge2 on coreference resolution examined coreference resolution in clinical data. The problem addr</context>
</contexts>
<marker>Pustejovsky, Castao, Ingria, Sauri, Gaizauskas, Setzer, Katz, Radev, 2003</marker>
<rawString>James Pustejovsky, Jos M. Castao, Robert Ingria, Roser Sauri, Robert J. Gaizauskas, Andrea Setzer, Graham Katz, and Dragomir R. Radev. 2003. Timeml: Robust specification of event and temporal expressions in text. In New Directions in Question Answering’03, pages 28–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preethi Raghavan</author>
<author>Albert M Lai</author>
</authors>
<title>Leveraging natural language processing of clinical narratives for phenotype modeling. In</title>
<date>2010</date>
<booktitle>PIKM’10,</booktitle>
<pages>57--66</pages>
<contexts>
<context position="2211" citStr="Raghavan and Lai, 2010" startWordPosition="307" endWordPosition="310">lectively termed clinical narratives, account for various medical conditions, procedures, diagnoses and assessments in a patient’s medical history. Researchers have investigated ways in which clinical text can be automatically processed for enabling access to relevant information for physicians and health researchers (Embi and Payne, 2009). One application is to support patient recruitment into clinical trials (research studies that try to answer scientific questions to find better ways to prevent, diagnose, or treat a disease) by matching patient characteristics against eligibility criteria (Raghavan and Lai, 2010). While there has been significant efforts to move to structured data collection, clinical narratives remain a critical data source for these tasks. Extracting structured information from unstructured clinical text using natural language processing (NLP) is complicated by the distinct clinical reporting sub-language characterized by incomplete sentences and domain specific abbreviations (Friedman et al., 2002). The large number of clinical narratives generated per patient, over the years, along with redundant information within and across narratives, further adds to the complexity of using inf</context>
</contexts>
<marker>Raghavan, Lai, 2010</marker>
<rawString>Preethi Raghavan and Albert M. Lai. 2010. Leveraging natural language processing of clinical narratives for phenotype modeling. In PIKM’10, pages 57–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karthik Raghunathan</author>
<author>Heeyoung Lee</author>
<author>Sudarshan Rangarajan</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
<author>Christopher Manning</author>
</authors>
<title>A multipass sieve for coreference resolution.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10,</booktitle>
<pages>492--501</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6569" citStr="Raghunathan et al., 2010" startWordPosition="965" endWordPosition="969">de work by Jung et 1https://cabig-kc.nci.nih.gov/Vocab/KC/ index.php/OHNLP al. (2011) and Zhou et al. (2006). Gaizauskas et al. (2006) learn the temporal relations before, after, is included between events from a corpus of clinical text much like the event-event relation tlink learning in Timebank (Pustejovsky et al., 2003). A comprehensive survey of temporal reasoning in medical data is provided by Zhou and Hripcsak (2007). Chapman et al. (2011) discuss barriers to NLP development in the clinical domain. Coreference resolution is a well-studied problem in computational linguistics (Ng, 2010; Raghunathan et al., 2010). Supervised machine learning algorithms have been previously used for noun phrase coreference resolution with fairly good results (Soon et al., 2001; Raghunathan et al., 2010). Recently, the i2b2 challenge2 on coreference resolution examined coreference resolution in clinical data. The problem addressed in our paper is similar to the task described in the i2b2 challenge.3 Besides the i2b2 challenge, there has not been significant work in MCCR. This may be due to various privacy concerns and the efforts required to anonymize and annotate massive amounts of patient narratives. Zheng et al. (201</context>
</contexts>
<marker>Raghunathan, Lee, Rangarajan, Chambers, Surdeanu, Jurafsky, Manning, 2010</marker>
<rawString>Karthik Raghunathan, Heeyoung Lee, Sudarshan Rangarajan, Nathanael Chambers, Mihai Surdeanu, Dan Jurafsky, and Christopher Manning. 2010. A multipass sieve for coreference resolution. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10, pages 492– 501, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guergana K Savova</author>
<author>James J Masanz</author>
<author>Philip V Ogren</author>
<author>Jiaping Zheng</author>
<author>Sunghwan Sohn</author>
<author>Karin Kipper Schuler</author>
<author>Christopher G Chute</author>
</authors>
<title>Mayo clinical text analysis and knowledge extraction system (cTAKES): architecture, component evaluation and applications.</title>
<date>2010</date>
<pages>507--513</pages>
<publisher>JAMIA,</publisher>
<contexts>
<context position="5674" citStr="Savova et al., 2010" startWordPosition="829" endWordPosition="832">-text reports form a significant portion of the information content in a patient’s medical record. There is great need for tools that can structure the information in clinical text for use in various studies studies such as clinical trials, quality assessment of healthcare delivery in institutions, and public health research. Researchers have been investigating ways in which clinical free-text can be structured to transform the information content in a clinical narrative into a representation suitable for computational analysis (Ananiadou et al., 2004). Medical NLP systems like Mayo’s cTakes (Savova et al., 2010), IBM’s MedKAT,1 and MedLEE (Chiang et al., 2010), have components specifically trained or designed for the clinical domain, to support tasks such as named entity recognition. Previous attempts at learning temporal relations between medical events in clinical text include work by Jung et 1https://cabig-kc.nci.nih.gov/Vocab/KC/ index.php/OHNLP al. (2011) and Zhou et al. (2006). Gaizauskas et al. (2006) learn the temporal relations before, after, is included between events from a corpus of clinical text much like the event-event relation tlink learning in Timebank (Pustejovsky et al., 2003). A c</context>
</contexts>
<marker>Savova, Masanz, Ogren, Zheng, Sohn, Schuler, Chute, 2010</marker>
<rawString>Guergana K. Savova, James J. Masanz, Philip V. Ogren, Jiaping Zheng, Sunghwan Sohn, Karin Kipper Schuler, and Christopher G. Chute. 2010. Mayo clinical text analysis and knowledge extraction system (cTAKES): architecture, component evaluation and applications. JAMIA, pages 507–513.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guergana K Savova</author>
<author>Wendy Webber Chapman</author>
<author>Jiaping Zheng</author>
<author>Rebecca S Crowley</author>
</authors>
<title>Anaphoric relations in the clinical narrative: corpus creation.</title>
<date>2011</date>
<journal>JAMIA,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="9094" citStr="Savova et al. (2011)" startWordPosition="1341" endWordPosition="1344">on framework for weakly supervised learning to derive a multi-view learning algorithm. Multi-view methods typically begin by assuming that each view alone can yield a good predictor. Under this assumption, we can regularize the models from each view by constraining the amount by which we permit them to disagree on unlabeled instances. In the proposed approach, they train a model for each view, and use constraints that the models should agree on the label distribution. We investigate the applicability of these two weakly supervised methods to the task of MCCR using semantic and temporal views. Savova et al. (2011) discuss the creation of a corpus for coreference resolution in the clinical narrative. We annotate a corpus of clinical narratives to tag medical concepts, temporal relations, and coreference information. We use this corpus as a gold standard to evaluate the proposed approach to resolving coreferences between medical concepts in clinical text. To summarize, we study the problem of intra and cross-narrative coreference resolution on longitudinal patient data using relatedness between medical concepts in terms of semantics and time. Further, we importantly demonstrate that this task gives us re</context>
</contexts>
<marker>Savova, Chapman, Zheng, Crowley, 2011</marker>
<rawString>Guergana K. Savova, Wendy Webber Chapman, Jiaping Zheng, and Rebecca S. Crowley. 2011. Anaphoric relations in the clinical narrative: corpus creation. JAMIA, 18(4):459–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Chung Yong Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases. Computational Linguistics,</title>
<date>2001</date>
<pages>521--544</pages>
<contexts>
<context position="6718" citStr="Soon et al., 2001" startWordPosition="989" endWordPosition="992">ations before, after, is included between events from a corpus of clinical text much like the event-event relation tlink learning in Timebank (Pustejovsky et al., 2003). A comprehensive survey of temporal reasoning in medical data is provided by Zhou and Hripcsak (2007). Chapman et al. (2011) discuss barriers to NLP development in the clinical domain. Coreference resolution is a well-studied problem in computational linguistics (Ng, 2010; Raghunathan et al., 2010). Supervised machine learning algorithms have been previously used for noun phrase coreference resolution with fairly good results (Soon et al., 2001; Raghunathan et al., 2010). Recently, the i2b2 challenge2 on coreference resolution examined coreference resolution in clinical data. The problem addressed in our paper is similar to the task described in the i2b2 challenge.3 Besides the i2b2 challenge, there has not been significant work in MCCR. This may be due to various privacy concerns and the efforts required to anonymize and annotate massive amounts of patient narratives. Zheng et al. (2011) review heuristic-based, supervised and unsupervised methods for coreference resolution in the context of the clinical domain. He (2007) studied co</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Chung Yong Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, pages 521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Xiang</author>
<author>Kewei Lu</author>
<author>Stephen L James</author>
<author>Tara B Borlawsky</author>
<author>Kun Huang</author>
<author>Philip R O Payne</author>
</authors>
<title>kneighborhood decentralization: A comprehensive solution to index the UMLS for scale knowledge discovery.</title>
<date>2011</date>
<journal>In Journal of Biomedical Informatics.</journal>
<contexts>
<context position="12081" citStr="Xiang et al., 2011" startWordPosition="1812" endWordPosition="1815">s a set of medical concepts. Thus, each PZ has a set of associated medical concepts, M = {M1, M2, M3, ..} that occur within each clinical narrative as well as across clinical narratives for that PZ. We study the problem of MCCR of all medical concepts in M for each PZ. 4 Semantic and Temporal Features We extract features based on semantic and temporal relatedness for each pair of medical concepts. Semantic relatedness measures closeness between medical concepts in terms of their meaning. This is quantified by measuring distance between medical events in the UMLS Metathesaurus graph structure (Xiang et al., 2011). Temporal relatedness measures the closeness between medical concepts in terms of when they occurred. This is achieved by first, learning to assign every medical concept to a time-bin, and then using the time-bin as a feature for learning to resolve coreferences. Extracting semantic and temporal features helps identify conditionally independent views of the data for co-training classifiers. As previously noted by Nigam and Ghani (2000), it is hard to identify conditionally independent views for real-data problems. However, we believe there are no natural dependencies between the semantic and </context>
<context position="13755" citStr="Xiang et al., 2011" startWordPosition="2058" endWordPosition="2061">r in terms of their time of occurrence, most probably do not corefer. Similarly, medical concepts that occur during the same time duration but are dissimilar in terms of meaning, most probably do not corefer. Semantic Relatedness. We leverage the UMLS to derive a semantic relatedness score between medical concepts. The UMLS codifies concepts found in various medical vocabularies (e.g., ICD5 and SNOMED-CT6) and includes relationships between various concepts. The medical concepts and their relationships are modeled in a graph structure. We use the k-Neighborhood decentralization method (kDLS) (Xiang et al., 2011) to index and transitively traverse associated relations between concept unique identifiers (CUIs) in the UMLS graph. The UMLS uses semantic relations to mark the available links between two concepts. Around 2,404,937 CUIs and 15,333,246 links between them are seen in the full UMLS graph structure. The kDLS method is shown to outperform both breadth-first and depthfirst search in terms of speed and various other measures in finding important information, such as reachability, distance, and a summary of paths, between two concepts in the UMLS graph structure. The relation between two concepts M</context>
<context position="15189" citStr="Xiang et al. (2011)" startWordPosition="2307" endWordPosition="2310">tm 6http://www.ihtsdo.org/snomed-ct/ ing the kDLS method, excluding paths with length equal to 1. In order to make the measurement between a medical concepts unbiased against the available links in the UMLS that directly connect them, the paths with length being 1 between them are not counted. Each path’s contribution to the relation score R(x, y) is determined by its length and -y. -y is varied between 1 to 50; if -y is set to 1, then all paths contribute equally to R irrespective of their lengths. When -y increases, more weight will be placed on the short paths as opposed to the long paths. Xiang et al. (2011) observe several fold enrichment values when -y is varied between 5 and 15. Besides traversing the UMLS graph structure using the kDLS method to obtain a similarity score between medical concepts, we also measure similarity between medical concepts by taking into account the surrounding context. We do so by measuring the KL-divergence between the sentences to which the medical concepts belong. In order to avoid the possibility of an empty set when calculating the intersection of the probability distributions, we use a smoothing method that makes the probability distributions sum to 1 (Brigitte</context>
<context position="31742" citStr="Xiang et al., 2011" startWordPosition="5000" endWordPosition="5003"> our team of annotators is high; all annotators agreed on 89.5% of the events and our overall inter-annotator Cohen’s kappa statistic (Conger, 1980) for medical events was 0.865. The annotators mark medical concepts, coereference chains and temporal expressions in the clinical narratives and the NEJM case reports. They also map each medical concept to a UMLS CUI. 6.2 Feature Extraction The first step involves extraction of semantic and temporal features for the annotated medical concepts, as described in Section 4 from both corpora. The semantic relatedness scores are computed using the kDLS (Xiang et al., 2011) method to calculate the relationship between concepts in the UMLS with value of -y set to 7. The type of relation between medical concepts is derived by matching word stems in each medical concept using the Lucene9 implementation of the Porter stemming algorithm. We query the latest release (UMLS 2011AB) of the UMLS Metathesaurus for finding a match between medical concept and the UMLS definition or UMLS atoms. The WordNet similarity score is computed using Java API for WordNet Searching (JAWS).10 Explicit temporal expressions annotated in the corpora are included in our temporal feature set.</context>
</contexts>
<marker>Xiang, Lu, James, Borlawsky, Huang, Payne, 2011</marker>
<rawString>Yang Xiang, Kewei Lu, Stephen L James, Tara B Borlawsky, Kun Huang, and Philip R O Payne. 2011. kneighborhood decentralization: A comprehensive solution to index the UMLS for scale knowledge discovery. In Journal of Biomedical Informatics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiaping Zheng</author>
<author>Wendy Webber Chapman</author>
<author>Rebecca S Crowley</author>
<author>Guergana K Savova</author>
</authors>
<title>Coreference resolution: A review of general methodologies and applications in the clinical domain.</title>
<date>2011</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>44</volume>
<issue>6</issue>
<contexts>
<context position="7171" citStr="Zheng et al. (2011)" startWordPosition="1064" endWordPosition="1067">han et al., 2010). Supervised machine learning algorithms have been previously used for noun phrase coreference resolution with fairly good results (Soon et al., 2001; Raghunathan et al., 2010). Recently, the i2b2 challenge2 on coreference resolution examined coreference resolution in clinical data. The problem addressed in our paper is similar to the task described in the i2b2 challenge.3 Besides the i2b2 challenge, there has not been significant work in MCCR. This may be due to various privacy concerns and the efforts required to anonymize and annotate massive amounts of patient narratives. Zheng et al. (2011) review heuristic-based, supervised and unsupervised methods for coreference resolution in the context of the clinical domain. He (2007) studied coreference resolution in discharge summaries, treating coreference resolution as a binary classification problem and investigated critical features for coreference resolution for entities that fall into five medical semantic categories commonly appearing in discharge summaries. However, we focus on feature extraction to determine the similarity between medical concepts, both in terms of meaning and time of occurrence, for resolving coreferences withi</context>
</contexts>
<marker>Zheng, Chapman, Crowley, Savova, 2011</marker>
<rawString>Jiaping Zheng, Wendy Webber Chapman, Rebecca S. Crowley, and Guergana K. Savova. 2011. Coreference resolution: A review of general methodologies and applications in the clinical domain. Journal of Biomedical Informatics, 44(6):1113–1122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Zhou</author>
<author>George Hripcsak</author>
</authors>
<title>Temporal reasoning with medical data - a review with emphasis on medical natural language processing.</title>
<date>2007</date>
<journal>Journal of Biomedical Informatics,</journal>
<pages>183--202</pages>
<contexts>
<context position="6371" citStr="Zhou and Hripcsak (2007)" startWordPosition="935" endWordPosition="938">ically trained or designed for the clinical domain, to support tasks such as named entity recognition. Previous attempts at learning temporal relations between medical events in clinical text include work by Jung et 1https://cabig-kc.nci.nih.gov/Vocab/KC/ index.php/OHNLP al. (2011) and Zhou et al. (2006). Gaizauskas et al. (2006) learn the temporal relations before, after, is included between events from a corpus of clinical text much like the event-event relation tlink learning in Timebank (Pustejovsky et al., 2003). A comprehensive survey of temporal reasoning in medical data is provided by Zhou and Hripcsak (2007). Chapman et al. (2011) discuss barriers to NLP development in the clinical domain. Coreference resolution is a well-studied problem in computational linguistics (Ng, 2010; Raghunathan et al., 2010). Supervised machine learning algorithms have been previously used for noun phrase coreference resolution with fairly good results (Soon et al., 2001; Raghunathan et al., 2010). Recently, the i2b2 challenge2 on coreference resolution examined coreference resolution in clinical data. The problem addressed in our paper is similar to the task described in the i2b2 challenge.3 Besides the i2b2 challenge</context>
<context position="17168" citStr="Zhou and Hripcsak, 2007" startWordPosition="2619" endWordPosition="2623">n a concept are synonymous. Besides the described features, we also include the UMLS semantic category of each medical concept and the WordNet7 similarity score between sentences containing the medical concept. Temporal Relatedness. Clinical text is frequently characterized by temporal expressions co7http://wordnet.princeton.edu/ Clinical Text Temporal Feature Extraction using CRFs Medical Concept Coreference Resolution (MCCR) Co-train Posterior Regularization OR Coreference decisions Semantic Feature Extraction 1 � 1 -ylength(p)−1 + qED(y,x) -ylength(q)−1 734 occurring with medical concepts (Zhou and Hripcsak, 2007). For instance, two days ago, fever started 4 days before rash, July 10th, 2010 etc. The ability to associate medical concepts with temporal expressions helps order medical concepts and determine potential temporal overlap between them. This in turn could be a powerful discriminatory feature in MCCR. Consider the medical concept chest pain that occurs multiple times in a clinical narrative. If these mentions of chest pain have occurred at the same time, there is a possibility that they all refer to the same instance of the medical concept chest pain. Instead of relying on implicit temporal ref</context>
</contexts>
<marker>Zhou, Hripcsak, 2007</marker>
<rawString>Li Zhou and George Hripcsak. 2007. Temporal reasoning with medical data - a review with emphasis on medical natural language processing. Journal of Biomedical Informatics, pages 183–202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Zhou</author>
<author>Genevieve B Melton</author>
<author>Simon Parsons</author>
<author>George Hripcsak</author>
</authors>
<title>A temporal constraint structure for extracting temporal information from clinical narrative.</title>
<date>2006</date>
<journal>Journal of Biomedical Informatics,</journal>
<pages>424--439</pages>
<contexts>
<context position="6052" citStr="Zhou et al. (2006)" startWordPosition="883" endWordPosition="886">inical free-text can be structured to transform the information content in a clinical narrative into a representation suitable for computational analysis (Ananiadou et al., 2004). Medical NLP systems like Mayo’s cTakes (Savova et al., 2010), IBM’s MedKAT,1 and MedLEE (Chiang et al., 2010), have components specifically trained or designed for the clinical domain, to support tasks such as named entity recognition. Previous attempts at learning temporal relations between medical events in clinical text include work by Jung et 1https://cabig-kc.nci.nih.gov/Vocab/KC/ index.php/OHNLP al. (2011) and Zhou et al. (2006). Gaizauskas et al. (2006) learn the temporal relations before, after, is included between events from a corpus of clinical text much like the event-event relation tlink learning in Timebank (Pustejovsky et al., 2003). A comprehensive survey of temporal reasoning in medical data is provided by Zhou and Hripcsak (2007). Chapman et al. (2011) discuss barriers to NLP development in the clinical domain. Coreference resolution is a well-studied problem in computational linguistics (Ng, 2010; Raghunathan et al., 2010). Supervised machine learning algorithms have been previously used for noun phrase </context>
</contexts>
<marker>Zhou, Melton, Parsons, Hripcsak, 2006</marker>
<rawString>Li Zhou, Genevieve B. Melton, Simon Parsons, and George Hripcsak. 2006. A temporal constraint structure for extracting temporal information from clinical narrative. Journal of Biomedical Informatics, pages 424–439.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>