<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.995193">
Exploiting Timelines to Enhance Multi-document Summarization
</title>
<author confidence="0.999691">
Jun-Ping Ng1,2, Yan Chen3, Min-Yen Kan2,4, Zhoujun Li3
</author>
<affiliation confidence="0.89842975">
1DSO National Laboratories, Singapore
2School of Computing, National University of Singapore, Singapore
3State Key Laboratory of Software Development Environment, Beihang University, China
4Interactive and Digital Media Institute, National University of Singapore, Singapore
</affiliation>
<email confidence="0.996039">
njunping@dso.org.sg
</email>
<sectionHeader confidence="0.993835" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999973863636364">
We study the use of temporal information
in the form of timelines to enhance multi-
document summarization. We employ a
fully automated temporal processing sys-
tem to generate a timeline for each in-
put document. We derive three features
from these timelines, and show that their
use in supervised summarization lead to a
significant 4.1% improvement in ROUGE
performance over a state-of-the-art base-
line. In addition, we propose TIMEMMR,
a modification to Maximal Marginal Rel-
evance that promotes temporal diversity
by way of computing time span similar-
ity, and show its utility in summarizing
certain document sets. We also propose a
filtering metric to discard noisy timelines
generated by our automatic processes, to
purify the timeline input for summariza-
tion. By selectively using timelines guided
by filtering, overall summarization perfor-
mance is increased by a significant 5.9%.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999953703703704">
There has been a good amount of research in-
vested into improving the temporal interpretation
of text. Besides the increasing availability of an-
notation standards (e.g., TIMEML (Pustejovsky et
al., 2003a)) and corpora (e.g., TIDES (Ferro et
al., 2000), TimeBank (Pustejovsky et al., 2003b)),
the community has also organized three success-
ful evaluation workshops — TempEval-1 (Verha-
gen et al., 2009), -2 (Verhagen et al., 2010), and
-3 (Uzzaman et al., 2013). As the state-of-the-
art improves, these workshops have moved away
from the piecemeal evaluation of individual tem-
poral processing tasks and towards the evaluation
of complete end-to-end systems in TempEval-3.
We believe our understanding of the temporal in-
formation found in text is sufficiently robust, and
that there is an opportunity to now leverage this in-
formation in downstream applications. In this pa-
per, we present our work in incorporating the use
of such temporal information into multi-document
summarization.
The goal of multi-document summarization is
to generate a summary which includes the main
points from an input collection of documents with
minimal repetition of similar points. We hope to
improve the quality of the summaries that are gen-
erated by considering temporal information found
in the input text. To motivate how temporal in-
formation can be useful in summarization, let us
refer to Figure 1. The three sentences describe a
recent cyclone and a previous one which happened
in 1991. Recognizing that sentence (3) is about a
storm that had happened in the past is important
when writing a summary about the recent storm,
as it is not relevant and can likely be excluded.
It is reasonable to expect that a collection of
documents about the recent storm will contain
more references to it, compared with the earlier
one that happened in 1991. Visualized on a time-
line, this will translate to more events (bolded in
Figure 1) around the time when the recent storm
occurred. There should be fewer events mentioned
in the collection for the earlier 1991 time period.
Figure 2 illustrates a possible timeline laid out
with the events found in Figure 1. The events
from the more recent storm are found together at
the same time. There are fewer events which talk
about the previous storm. Thus, temporal informa-
tion does assist in identifying which sentences are
more relevant to the final summary.
Our work is significant as it addresses an im-
portant gap in the exploitation of temporal infor-
mation. While there has been prior work making
use of temporal information for multi-document
</bodyText>
<page confidence="0.979975">
923
</page>
<note confidence="0.755554">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 923–933,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<listItem confidence="0.9218355">
(1) A fierce cyclone packing extreme winds and torrential rain smashed into Bangladesh’s southwestern coast Thursday,
wiping out homes and trees in what officials described as the worst storm in years.
(2) More than 100,000 coastal villagers have been evacuated before the cyclone made landfall.
(3) The storm matched one in 1991 that sparked a tidal wave that killed an estimated 138,000 people, Karmakar told AFP.
</listItem>
<figureCaption confidence="0.836838">
Figure 1: Modified extract from a news article which describes a cyclone landfall. Several events which
appear in Figure 2 are bolded.
</figureCaption>
<figure confidence="0.300275">
Storm in 1991 Latest cyclone
</figure>
<figureCaption confidence="0.997104">
Figure 2: Possible timeline for events in Figure 1.
</figureCaption>
<bodyText confidence="0.999860178571429">
summarization, they 1) have been largely con-
fined to helping to chronologically order content
within summaries (Barzilay et al., 1999), or 2)
focus only on the use of recency as an indicator
of saliency (Goldstein et al., 2000; Wan, 2007).
In this work we construct timelines (as a repre-
sentation of temporal information) automatically
and incorporate them into a state-of-the-art multi-
document summarization system. This is achieved
with 1) three novel features derived from time-
lines to help measure the saliency of sentences,
as well as 2) TIMEMMR, a modification to the
traditional Maximal Marginal Relevance (MMR)
(Carbonell and Goldstein, 1998). TimeMMR pro-
motes diversity by additionally considering tem-
poral information instead of just lexical similari-
ties. Through these, we demonstrate that temporal
information is useful for multi-document summa-
rization. Compared to a competitive baseline, sig-
nificant improvements of up to 4.1% are obtained.
Automatic temporal processing systems are not
perfect yet, and this may have an impact on their
use for downstream applications. This work ad-
ditionally proposes the use of the lengths of time-
lines as a metric to gauge the usefulness of time-
lines. Together with the earlier described contribu-
tions, this metric further improves summarization,
yielding an overall 5.9% performance increase.
</bodyText>
<sectionHeader confidence="0.999853" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999840039215686">
Barzilay et al. (1999) were one of the first to use
time for multi-document summarization. They
recognized the importance of generating a sum-
mary which presents the time perspective of the
summarized documents correctly. They estimated
the chronological ordering of events with a small
set of heuristics, and also made use of lexical pat-
terns to perform basic time normalization on terms
like “today” relative to the document creation
time. The induced ordering is used to present the
selected summary content, following the chrono-
logical order in the original documents.
In another line of work, Goldstein et al. (2000)
made use of the temporal ordering of documents
to be summarized. In computing the relevance of a
passage for inclusion into the final summary, they
considered the recency of the passage’s source
document. Passages from more recent documents
are deemed to be more important. Wan (2007)
and Demartini et al. (2010) made similar assump-
tions in their work on TIMEDTEXTRANK and en-
tity summarization, respectively.
Instead of just considering the notion of re-
cency, Liu et al. (2009) proposed an interesting
approach using a temporal graph. Events within
a document set correspond to vertices in their pro-
posed graph, while edges are determined by the
temporal ordering of events. From the resulting
weakly-connected graph, the largest forests are as-
sumed to contain key topics within the document
set and used to influence a scoring mechanism
which prefers sentences touching on these topics.
Wu (2008) also made use of the relative or-
dering of events. He assigned complete times-
tamps to events extracted from text. After lay-
ing out these events onto a timeline by making
use of these timestamps, the number of events that
happen within the same day is used to influence
sentence scoring. The motivation behind this ap-
proach is that days which have a large number of
events should be more important and more worthy
of reporting than others.
These prior works target either 1) sentence re-
ordering, or 2) the use of recency as an indicator of
saliency. In sentence re-ordering, final summaries
are re-arranged so that the extracted sentences that
form the summary are in a chronological order.
We argue that this may not be appropriate for all
summaries. Depending on the style of writing or
journalistic guidelines, a summary can arguably be
written in a number of ways. The use of recency
</bodyText>
<figure confidence="0.99034225">
wiping
smashed
evacuated
packing
described
killed ...
sparked
2013-Feb-13 11:32 +0000
</figure>
<page confidence="0.996616">
924
</page>
<bodyText confidence="0.999985966666667">
as an indicator of saliency is useful, yet disregards
other accessible temporal information. If a sum-
mary of a whole sequence of events is desired, re-
cency becomes less useful.
The work of Wu (2008) is closely related to one
of the features proposed in this paper. He had also
made use of temporal information to weight sen-
tences to generate summaries. However his ap-
proach is guided by the number of events hap-
pening within the same time span, and relies on
event co-referencing. In this work, we have sim-
plified this idea by dropping the need for event co-
referencing (removing a source of propagated er-
ror), and augmented it with two additional features
derived from timelines. By doing so, we are able
to make better use of the available temporal infor-
mation, taking into account all known events and
the time in which they occur.
A useful note here is that this work is ar-
guably different from the Temporal Summariza-
tion (TmpSum) track at the Text Retrieval Confer-
ence (Aslam et al., 2013). Given a large stream
of data in real-time, the purpose of the TmpSum
track is to look out for a query event, and retrieve
specific details about the event over a period of
time. Systems are also expected to identify the
source sentences from which these details are re-
trieved. This is not the same as our approach here,
which makes use of temporal information encoded
in timelines to generate prose summaries.
</bodyText>
<sectionHeader confidence="0.998443" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.9780935">
To incorporate temporal information into multi-
document summarization, we adopt the workflow
in Figure 3, which has two key processes: 1) tem-
poral processing, and 2) summarization.
</bodyText>
<figureCaption confidence="0.9596255">
Figure 3: Incorporating temporal information into
the SWING summarization pipeline.
</figureCaption>
<bodyText confidence="0.999689243243243">
Temporal Processing generates timelines from
text, one for each input document. Timelines are
well-understood constructs which have often been
used to represent temporal information (Denis and
Muller, 2011; Do et al., 2012). They indicate the
temporal relationships between two basic tempo-
ral units: 1) events, and 2) time expressions (or
timexes for short). In this work, we adopt the
definitions proposed in the standardized TIMEML
annotation (Pustejovsky et al., 2003a). An event
refers to an eventuality, a situation that occurs or
an action; while a timex is a reference to a partic-
ular date or time (e.g. “2013 December 31”).
Following the “divide-and-conquer” approach
described in Verhagen et al. (2010), results from
the three temporal processing steps: 1) timex nor-
malization, 2) event-timex temporal relationship
classification, and 3) event-event temporal rela-
tionship classification, are merged to obtain time-
lines (top half of Figure 3). We tap on existing
systems for each of these steps (Ng and Kan, 2012;
Str¨otgen and Gertz, 2013; Ng et al., 2013).
Summarization. We make use of a state-of-
the-art summarization system, SWING (Ng et al.,
2012) (bottom half of Figure 3). SWING is a su-
pervised, extractive summarization system which
ranks sentences based on scores computed using
a set of features in the Sentence Scoring phase.
The Maximal Marginal Relevance (MMR) algo-
rithm is then used in the Sentence Re-ordering
phase to re-order and select sentences to form the
final summary. The timelines built in the ear-
lier temporal processing can be incorporated into
this pipeline by deriving a set of features used to
score sentences in Sentence Scoring, and as input
to the MMR algorithm when computing similarity
in Sentence Re-ordering.
</bodyText>
<subsectionHeader confidence="0.998118">
3.1 Timelines from Temporal Processing
</subsectionHeader>
<bodyText confidence="0.998205428571429">
A typical timeline used in this work has been
shown earlier in Figure 2. The arrowed, horizon-
tal axis is the timeline itself. The timeline can
be viewed as a continuum of time, with points on
the timeline referring to specific moments of time.
Small solid blocks on the timeline itself are ref-
erences to absolute timestamps along the timeline
(e.g., “2013-Feb-13 11:32 +0000” in the figure).
The black square boxes above the timeline de-
note events. Events can either occur at a specific
instance of time (e.g., an explosion), or over a pe-
riod of time (e.g. a football match). Generalizing,
we refer to the time period an event takes place in
as its time span (vertical dotted lines). As a simpli-
</bodyText>
<figure confidence="0.998864185185185">
Temporal Processing
Summarization Pipeline
Event and Timex
Extraction
Pre-processing
ments
p
oment
Input
Documents
Sentence
Scoring
Timex
Normalization
E-T
Temporal
Classification
E-E
Temporal
Classification
Sentence
Re-ordering
Timeline
Generation
Timenes
Timelines
Summary
</figure>
<page confidence="0.723757">
925
</page>
<figureCaption confidence="0.993345">
Figure 4: A simplified timeline illustrating how
</figureCaption>
<bodyText confidence="0.948891111111111">
the various timeline features can be derived.
fying assumption, events are laid out on the time-
line based on the starting time of their time span.
Note that in our work, time spans may not cor-
respond to specific instances of time, but instead
help in inferring an ordering of events. Events
which appear to the left of others take place ear-
lier, while events within the same time span hap-
pen together over the same time period.
</bodyText>
<subsectionHeader confidence="0.99917">
3.2 Sentence Scoring with Timelines
</subsectionHeader>
<bodyText confidence="0.998662833333333">
We derive three features from the constructed
timelines, which are then used for downstream
Sentence Scoring. Figure 4 shows a simplified
timeline, along with annotations that are refer-
enced in this section to help explain how these
timeline features are derived.
</bodyText>
<listItem confidence="0.544306">
1. Time Span Importance (TSI). We hypothe-
</listItem>
<bodyText confidence="0.998452388888889">
size that when more events happen within a partic-
ular time span, that time span is potentially more
relevant for summarization. Sentences that men-
tion events found in such a time span should be as-
signed higher scores. Referring to Figure 1, whose
timeline is shown in Figure 2, we see that the time
span with the most number of events is when the
latest cyclone made landfall. Assigning higher
scores for sentences which contain events in this
time span will help us to select more relevant sen-
tences if we want a summary about the cyclone.
Let TSL be the time span with the largest num-
ber of events in a timeline. The importance of
a time span TSi is computed by normalizing the
number of events in TSi against the number of
events in TSL. The TSI of a sentence s is then
the sum of the time span importance associated to
all the words in s:
</bodyText>
<equation confidence="0.985942">
|TSw |
TSI(s) = �w∈s |TSL |(1)
|s|
</equation>
<bodyText confidence="0.999957666666667">
where T Sw denotes the time span which a word
w is associated with, and |T Sw |is the number of
events within the time span.
</bodyText>
<listItem confidence="0.481492">
2. Contextual Time Span Importance
</listItem>
<bodyText confidence="0.991886551724138">
(CTSI). The importance of a time span may not
depend solely on the number of events that hap-
pen within it. If it is near time spans which are
“important” (i.e., one that has a large number of
events), it should also be of relative importance. A
more concrete illustration of this can also be seen
in Figure 1. Sentence (2) explains that a lot of peo-
ple have been evacuated prior to the cyclone mak-
ing landfall. It is imaginable that this can be use-
ful information to be included in a summary, even
though from looking at the corresponding timeline
in Figure 2, the “evacuated” event falls in a time
span with a low importance score (i.e., the time
span only has one event). CTSI seeks to promote
sentences such as this.
We derive the CTSI of a sentence by first com-
puting the contextual importance of words in the
sentence. We define the contextual importance of
a word found in time span TSi as a weighted sum
of the time span importance of the two nearest
peaks T Slp and T Srp found to the left and right
of TSi, respectively. In Figure 4, taking reference
from event e (shaded in black), the left peak to the
time span which e is in happens to be time span
A, while the right peak is time span A + 4. The
contribution of each peak to the weighted sum is
decayed by its distance from TSi. Formally, the
contextual time span importance of a word w can
be expressed as: l ( l
</bodyText>
<equation confidence="0.584893">
ζm= αC|TSwI�pTSlp|/ X(1—a)\|TSrp −PTSw|/ (2)
</equation>
<bodyText confidence="0.999048625">
where T Sw is the time span associated with w. Ilp
and Irp are the time span importance of the peaks
to the left and right of T Sw respectively, while
|TSw − TSlp |and |TSrp − TSw |are the num-
ber of time spans between the left and right peaks
of T Sw respectively. α balances the importance of
the left and right peaks, intuitively set to 0.5. The
CTSI of a sentence is computed as:
</bodyText>
<equation confidence="0.994872">
CTSI(s) = Ee EE (e) (3)
</equation>
<bodyText confidence="0.999452">
where Es denotes the set of events words in s.
</bodyText>
<listItem confidence="0.459686142857143">
3. Sentence Temporal Coverage Density
(TCD). We first define the temporal coverage of a
sentence. This corresponds to the number of time
spans that the events in a sentence talk about. Sup-
pose a sentence contains events which are associ-
ated with time spans TSa, TSb, TSc. The time
spans are ordered in the sequence they appear on
</listItem>
<figure confidence="0.92347775">
left peak of e right peak of e
biggest cluster
Time Span A Time Span A+4
e
</figure>
<page confidence="0.990589">
926
</page>
<bodyText confidence="0.999952083333333">
the timeline. Then the temporal coverage of a sen-
tence is defined as the number of time spans be-
tween the earliest time span TS,, and the latest
time span TS, Referring to Figure 4, suppose
a sentence contains the three events which have
been shaded black. The temporal coverage in this
case includes all the time spans from time span A
to time span A + 4, inclusive.
The constraint on the number of sentences that
can be included in a summary requires us to select
compact sentences which contain as many rele-
vant facts as possible. Traditional lexical measures
may attempt to achieve this by computing the ra-
tio of keyphrases to the number of words in a sen-
tence (Gong and Liu, 2001). Stated equivalently,
when two sentences are of the same length, if one
contains more keyphrases, it should contain more
useful facts. TCD parallels this idea with the use
of temporal information, i.e. if two sentences are
of the same temporal coverage, then the one with
more events should carry more useful facts.
Formally, if a sentence s contains events ]E3 =
{e1,... , e,}, where each event is associated with
a time span T Si, then TCD is computed using:
</bodyText>
<equation confidence="0.9982465">
TCD(s) = |E3 |(4)
|TS� − T S1|
</equation>
<bodyText confidence="0.9995695">
where |E3 |is the number of events found in s, and
|TS,, − TS1 |is the temporal coverage of s.
</bodyText>
<subsectionHeader confidence="0.971846">
3.3 Enhancing MMR with TimeMMR
</subsectionHeader>
<bodyText confidence="0.999881916666666">
In the sentence re-ordering stage of the SWING
pipeline, the iterative MMR algorithm is used to
adjust the score of a candidate sentence, s. In each
iteration, s is penalized if it is lexically similar to
other sentences that have already been selected to
form the eventual summary S = {s1, s2, ...}. The
motivating idea is to reduce repeated information
by preferring sentences which bring in new facts.
Incorporating temporal information can poten-
tially improve this. In Figure 5, the sentences de-
scribe many events which took place within the
same time span. They describe the destruction
caused by a hurricane with trees uprooted and
buildings blown away. A summary about the hur-
ricane need not contain all of these sentences as
they are all describing the same thing. However
it is not trivial for the lexically-motivated MMR
algorithm to detect that events like “passed”, “up-
rooted” or “damaged” are in fact repetitive.
Thus, we propose further penalizing the score
of s if it contains events that happen in similar
time spans as those contained in sentences within
S. We refer to this as TIMEMMR. Modifying the
MMR equation from Ng et al. (2012):
</bodyText>
<equation confidence="0.997647">
TimeMMR(s) = Score(s) − -yR2(s, S) − (1 − -y)T (s, S) (5)
</equation>
<bodyText confidence="0.999984777777778">
where Score(s) is the score of s, S is the set of
sentences already selected to be in the summary
from previous iterations, and R2 is the predicted
ROUGE-2 score of s with respect to the already
selected sentences (S). γ is a weighting parameter
which is empirically set to 0.9 after tuning over a
development dataset. T is the proportion of events
in s which happen in the same time span as another
event in any other sentence in S. Two events are
said to be in the same time span if one happens
within the time period the other happens in. For
example, an event that takes place in “2014 June”
is said to take place within the year “2014”.
While TIMEMMR is proposed here as an im-
provement over MMR, the premise is that incor-
porating temporal information can be helpful to
minimize redundancy in summaries. In future
work, one could apply it to other state-of-the-art
lexical-based approaches including that of Hen-
drickx et al. (2009) and Celikyilmaz and Hakkani-
Tur (2010). We also believe the same idea can be
transplanted even to non-lexical motivated tech-
niques such as the corpus-based similarity mea-
sure proposed by Xie and Liu (2008). We chose
to use MMR here as a proof-of-concept to demon-
strate the viability of such a technique, and to eas-
ily integrate our work into SWING.
</bodyText>
<subsectionHeader confidence="0.972966">
3.4 Gauging Usefulness of Timelines
</subsectionHeader>
<bodyText confidence="0.999915222222222">
Temporal processing is imperfect. Together with
the simplifying assumptions that were made in
timeline construction, our generated timelines
have errors which propagate into the summariza-
tion process. With this in mind, we selectively em-
ploy timelines to generate summaries only when
we are confident of their accuracy. This can be
done by computing a metric which can be used to
decide whether or not timelines should be used for
a particular input document collection. We refer to
this as reliability filtering.
We postulate that the length of a timeline can
serve as a simple reliability filtering metric. The
intuition for this is that for longer timelines (which
contain more events), possible errors are spread
over the entire timeline, and do not overpower any
useful signal that can be obtained from the time-
line features outlined earlier. Errors are however
</bodyText>
<page confidence="0.973965">
927
</page>
<listItem confidence="0.9990104">
(1) An official in Barisal, 120 kilometres south of Dhaka, spoke of severe destruction as the 500 kilometre-wide mass of cloud
passed overhead.
(2) “Many trees have been uprooted and houses and schools blown away,” Mostofa Kamal, a district relief and rehabilitation
officer, told AFP by telephone.
(3) “Mud huts have been damaged and the roofs of several houses blown off,” said the state’s relief minister, Mortaza Hossain.
</listItem>
<figureCaption confidence="0.9291295">
Figure 5: Extract from a news article which describes several events (bolded) happening at the same
time.
</figureCaption>
<bodyText confidence="0.999306375">
very easily propagated into summary generation
for shorter timelines, leading to less useful results.
We incorporate this into our process as follows:
given an input document collection (which con-
sists of 10 documents), the average size of all the
timelines for each of these 10 documents is com-
puted. Only when this value is larger than a thresh-
old value are the timelines used.
</bodyText>
<sectionHeader confidence="0.998422" genericHeader="method">
4 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999933852941177">
The proposed timeline features and TIMEMMR
were implemented on top of SWING, and eval-
uated on the test documents from TAC-2011
(Owczarzak and Dang, 2011). SWING makes use
of three generic features and two features targeted
specifically at guided summarization. Since the
focus of this paper is on multi-document summa-
rization, we employ only the three generic fea-
tures, i.e., 1) sentence position, 2) sentence length,
and 3) interpolated n-gram document frequency
in our experiments below. Summarization evalua-
tion is done using ROUGE-2 (R-2) (Lin and Hovy,
2003), as it has previously been shown to correlate
well with human assessment (Lin, 2004) and is of-
ten used to evaluate automatic text summarization.
The results obtained are shown in Table 1. In
the table, each row refers to a specific summariza-
tion system configuration. We also show the re-
sults of two reference systems, CLASSY (Conroy
et al., 2011) and POLYCOM (Zhang et al., 2011),
as benchmarks. CLASSY and POLYCOM are top
performing systems at TAC-2011 (ranked 2nd and
3rd by R-2 in TAC 2011, respectively; the full ver-
sion of SWING was ranked 1st with a R-2 score
of 0.1380). From these results, we can see that
SWING is a very competitive baseline.
Rows 9 to 16 additionally incorporate our time-
line reliability filtering. We assume that the var-
ious input document sets to be summarized are
available at the time of processing. Hence in these
experiments, the threshold for filtering is set to be
the average of all the timeline sizes over the whole
input dataset. In a production environment where
this assumption may not hold, this threshold could
</bodyText>
<table confidence="0.953914545454545">
Configuration R-2 Sig
R SWING 0.1339 NA
B1 CLASSY 0.1278 -
B2 POLYCOM 0.1227 **
Without Filtering
1 SWING+TSI+CTSI+TCD 0.1394 *
2 SWING+TSI+CTSI 0.1372 -
3 SWING+TSI+TCD 0.1372 -
4 SWING+CTSI+TCD 0.1387 *
5 SWING+TSI+CTSI+TCD+TMMR 0.1389 -
6 SWING+TSI+CTSI+TMMR 0.1374 -
7 SWING+TSI+TCD+TMMR 0.1343 -
8 SWING+CTSI+TCD+TMMR 0.1363 -
With Filtering
9 SWING+TSI+CTSI+TCD 0.1418 **
10 SWING+TSI+CTSI 0.1378 **
11 SWING+TSI+TCD 0.1389 **
12 SWING+CTSI+TCD 0.1401 **
13 SWING+TSI+CTSI+TCD+TMMR 0.1402 **
14 SWING+TSI+CTSI+TMMR 0.1397 **
15 SWING+TSI+TCD+TMMR 0.1376 *
16 SWING+CTSI+TCD+TMMR 0.1390 **
</table>
<tableCaption confidence="0.997082">
Table 1: R-2 scores after incorporating temporal
</tableCaption>
<bodyText confidence="0.995794">
information into SWING. ‘**’ and ‘*’ denotes sig-
nificant differences with respect to Row R (paired
one-tailed Student’s t-test; p &lt; 0.05 and p &lt; 0.1
respectively), and TMMR denotes TIMEMMR.
be set by empirical tuning over a development set.
Row 1 shows the usefulness of the proposed
timeline-based features. A statistically significant
improvement of 4.1% is obtained with the use of
all three features over SWING. When we use re-
liability filtering (Row 9), this improvement in-
creases to 5.9%.
The ablation test results in Rows 2 to 4 show
a drop in R-2 each time a feature is left out. With
the exception of Row 4, removing a feature lessens
the improvement in R-2 to be insignificant from
SWING’s. The same drop occurs even when reli-
ability filtering is used (Rows 9 to 12). These in-
dicate that all the proposed features are important
and need to be used together to be effective.
Rows 5 to 8 and Rows 13 to 16 show the ef-
fect of TIMEMMR. While the results do not uni-
formly show that TIMEMMR is effective, it can be
helpful, such as when comparing Rows 2 and 6, or
Rows 10 and 14, where R-2 improves marginally.
Looking at Rows 1 to 8, and Rows 9 to 16, we
see the importance of reliability filtering. It is able
</bodyText>
<page confidence="0.995891">
928
</page>
<bodyText confidence="0.997079444444445">
to guide the use of timelines such that significant
improvements in R-2 over SWING are obtained.
To help visualize what the differences in these
ROUGE scores mean, Figure 7 shows two sum-
maries1 generated for document set D1117C of the
TAC-2011 dataset. The left one is produced by the
configuration in Row 9, and the right one is pro-
duced by SWING without the use of any temporal
information.
</bodyText>
<figure confidence="0.671193">
SP Length INDF TSI CTSI TCD
Features
</figure>
<figureCaption confidence="0.998054">
Figure 6: Breakdown of raw feature scores for sen-
tences (L2) and (R2) from Figure 7.
</figureCaption>
<bodyText confidence="0.999980785714286">
The higher R-2 score obtained by the summary
on the left (0.0873) compared to the one on the
right (0.0723) suggests that temporal information
can help to identify salient sentences more accu-
rately. A closer look at sentences (L2) and (R2)
and their R-2 scores (0.0424 and 0.0249, respec-
tively) is instructive. Figure 6 shows the raw fea-
ture scores of both sentences. Both sentences
score similarly for the SWING features of sen-
tence position (SP), sentence length (Length), and
interpolated n-gram document frequency (INDF);
however, the scores for all three timeline features
higher for (L2) than (R2). This helps our time sen-
sitive system prefer (L2).
</bodyText>
<sectionHeader confidence="0.999244" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.9996808">
We now examine the proposed 1) timeline fea-
tures, 2) TIMEMMR algorithm, and 3) reliabil-
ity filtering metric in greater detail to gain insight
into their efficacy. For the analysis on timeline
features, we only present an analysis for TSI and
CTSI due to space constraints.
Time Span Importance. Figure 8 shows the
last sentences from a pair of summaries generated
with and without the use of TSI (all other sen-
tences were the same). The original articles de-
scribe an accident where casualties were suffered
when a crane toppled onto a building. It is easy to
see why (L1) scores higher for R-2 — it describes
the cause of the accident just as it occurred. (R1)
however talks about events which happened before
</bodyText>
<footnote confidence="0.9907655">
1The produced summaries are truncated to fit within a
100-word limit imposed by the TAC-2011 guidelines.
</footnote>
<bodyText confidence="0.984160813953488">
the accident itself (e.g., how much of the tower had
already been erected). In this case time span im-
portance is able to correctly guide summary gen-
eration by favoring time spans containing events
related to the actual toppling.
Contextual Time Span Importance. CTSI
recognizes that events which happen around the
time of a big cluster of other events can be im-
portant too. The benefits of this feature can be
clearly seen in Figure 9. The summary on the left
achieved a R-2 score of 0.1215 while the one on
the right achieved 0.0861. (L2) and (L3) were
both boosted by the use of the contextual impor-
tance feature.
Figure 10 shows an extract of the timeline gen-
erated for the source document from which (L3)
is extracted. The two events inside (L3) fall in
time spans A and B marked in the figure. Their
proximity to the peak P between them gives the
sentence a higher score for CTSI. This boost re-
sults in the sentence being selected for inclusion
in the final summary. It turns out that this sentence
was lifted exactly in one of the model summaries
for this document set, resulting in a very good R-2
score when contextual importance is used.
Peak here affects time span contextual importance of A and B
Figure 10: Extract of timeline generated for doc-
ument APW ENG 20070615.0356 from the TAC-
2011 dataset.
Is TIMEMMR Useful? The experimental re-
sults do not conclusively affirm the usefulness of
TIMEMMR. However we believe it is because
the ROUGE measures that are used for evalua-
tion are not suited for this purpose. Recall that
TIMEMMR seeks to eliminate redundancy based
on time span similarities and not lexical likeness.
ROUGE, however, measures the latter.
An interesting case in point is given in Fig-
ure 11. The summary on the left is generated
using TIMEMMR and achieved a lower ROUGE
score. The one on the right is generated with-
out TIMEMMR and scores higher, suggesting that
TIMEMMR is not helpful. The key difference in
</bodyText>
<figure confidence="0.998068">
L2 R2
A P B
warn
disappear
Feature Score 1.0
0.8
0.6
0.4
0.2
0.0
</figure>
<page confidence="0.834261">
929
</page>
<figureCaption confidence="0.9815315">
Figure 7: Generated summaries for document set D1117C from the TAC-2011 dataset. Left summary is
generated by SWING+TSI+CTSI+TCD with filtering; right summary is by SWING.
</figureCaption>
<figure confidence="0.4866825">
R-2: 0.1683 R-2: 0.1533
(L1) A piece of steel fell and sheared off one of the 5454 (R1) About 19 of the 44 stories of the crane had
</figure>
<figureCaption confidence="0.7125575">
ties holding it to the building, causing it to detach been erected and it was to be extended when a
and topple, said Stephen Kaplan piece of steel fell and sheared
Figure 8: Extract from summaries for document set D1137G from the TAC-2011 dataset. Left extract is
generated by SWING+TSI+CTSI+TCD; right extract is by SWING+CTSI+TCD.
</figureCaption>
<table confidence="0.959214117647059">
R-2: 0.0873 R-2: 0.0723
(L1,R1) The Army’s surgeon general criticized stories in The Washington Post disclosing problems at Walter
Reed Army Medical Center, saying the series unfairly characterized the living conditions and care for soldiers
recuperating from wounds at the hospital’s facilities.
(L2) Defense Secretary Robert Gates says people 5454 (R2) A top Army general vowed to personally
found to have been responsible for allowing sub- oversee the upgrading of Walter Reed Army Medi-
standard living conditions for soldier outpatients at cal Center’s Building 18, a dilapidated former hotel
Walter Reed Army Medical Center in Washington that houses wounded soldiers as outpatients.
will be “held accountable,” although so far no one
in the Army chain of command has offered to re-
sign.
(L3) Top Army officials visited Building 18, the 5454 (R3) “I’m not sure it was an accurate representa-
decrepit former hotel housing more than 80 recov- tion,” Lt. Gen. Kevin Kiley, chief of the Army
ering soldiers, outside Medical Command which oversees Walter Reed
and all Army health care, told reporters during a
news conference.
&gt;&gt; (R4) The Washington
</table>
<bodyText confidence="0.999758307692308">
the two summaries is (R3). (L3) is the equivalent
of (R4), while (L4) is the full version of the trun-
cated (R5). TIMEMMR penalizes (R3). (R3) re-
ports that the shoe-throwing incident happened as
the U.S. President Bush appeared together with the
Iraqi Prime Minister Nouri al-Maliki. However
their joint appearance is already reported in (R1)
(and similarly (L1)). (R3) repeats what had been
presented earlier. Since (R1) and (R3) talk about
the same time span, TIMEMMR down-weights
(R3). We argue that this is better even though the
ROUGE scores indicate otherwise. In future work
it will be worthwhile to consider the use of metrics
like Pyramid (Passonneau et al., 2005) which are
less bound to superficial lexicons.
Reliability Filtering. Table 2 shows the ef-
fect of varying the filtering threshold on R-2 for
the best performing configuration from Table 1
(i.e., SWING+TSI+CTSI+TCD). The result ob-
tained in Row 9 using a threshold of 42.68 is also
re-produced for reference. T=0 means that time-
lines are used for all input document sets, whereas
T=100 means that no timelines are used, as the
length of the longest timeline is less than 100.
As the threshold increases from 0 to 40–50,
summarization performance improves while the
</bodyText>
<table confidence="0.973817714285714">
T R-2 Sig # T R-2 Sig #
0 0.1394 * 44 50 0.1386 ** 13
10 0.1382 - 43 60 0.1361 * 7
20 0.1377 - 41 70 0.1351 - 3
30 0.1393 ** 35 80 0.1351 - 2
40 0.1426 ** 22 90 0.1353 - 1
42.68 0.1418 ** 21 100 0.1339 - 0
</table>
<tableCaption confidence="0.7959675">
Table 2: Effect of different reliability filtering
thresholds for SWING+TSI+CTSI+TCD. ‘T’ is
</tableCaption>
<bodyText confidence="0.988320944444445">
the threshold used; ‘#’ is the number of input col-
lections (out of 44) where timelines are used; ‘**’
and ‘*’ is statistical significance over SWING of
p &lt; 0.05 and p &lt; 0.1, respectively.
number of document sets where temporal informa-
tion is used is reduced. This suggests that filtering
is successful in identifying timelines that are not
sufficiently accurate to be useful for summariza-
tion. R-2 performance peaks around a threshold
of 40. This affirms our use of the average length
of timelines as the threshold value in our earlier
experiments. Beyond 60, the R-2 scores are still
higher than that obtained by SWING, but no longer
significantly different. At these higher thresholds,
temporal information is still able to help get an im-
provement in R-2. However as this affects only
very few out of the 44 document sets, statistical
variances mean that these R-2 scores are no longer
</bodyText>
<page confidence="0.962789">
930
</page>
<table confidence="0.4841588">
R-2: 0.1215 R-2: 0.0861
((L1,R1) Caribbean coral species essential to the region’s reef ecosystems are at risk of extinction as a result of
climate change.
(L2) But destructive fishing methods and over- 5454 (R2) The Coral Reef Task Force, created in the
harvesting have reduced worldwide catches by 90 Clinton administration, regularly assesses coral
percent in the past two decades. health.
(L3) Scientists warn that up to half of the world’s 5454 (R3) With a finished necklace retailing for up
coral reefs could disappear by 2045. to 20,000 dollars (15,000 euros), red corals are
among the world’s most expensive wildlife com-
modities.
</table>
<figureCaption confidence="0.98362275">
Figure 9: Extract from summaries for document set D1131F from the TAC-2011 dataset. Left extract is
generated by SWING+TSI+CTSI+TCD; right extract is by SWING+TSI+TCD.
Figure 11: Summaries for document set D1126E from the TAC-2011 dataset. Left summary is generated
by SWING+TSI+CTSI+TCD+TIMEMMR; right summary is by SWING+TSI+CTSI+TCD.
</figureCaption>
<figure confidence="0.9684936">
R-2: 0.2643 R-2: 0.2772
(L1,R1) – An Iraqi reporter threw his shoes at visiting U.S. President George W. Bush and called him a ”dog” in
Arabic during a news conference with Iraqi Prime Minister Nuri al-Maliki in Baghdad
(L2,R2) ”All I can report is it is a size 10,.
(L3) Muntadhar al-Zaidi, reporter of Baghdadiya 5454 (R3) The incident occurred as Bush was appearing
</figure>
<bodyText confidence="0.924028">
television jumped and threw his two shoes one by with Iraqi Prime Minister Nouri al-Maliki.
one at the president, who ducked and thus narrowly
missed being struck, raising chaos in the hall in
Baghdad’s heavily fortified green Zone.
(L4) The president lowered his head and the first 5454 (R4) Muntadhar al-Zaidi, reporter of Baghdadiya
shoe hit the American and Iraqi flags behind the television jumped and threw his two shoes one by
two leaders. one at the president, who ducked and thus narrowly
missed being struck, raising chaos in the hall in
Baghdad’s heavily fortified green Zone.
(L5) The 5454 (R5) The president lowered his head and the
significant from that produced by SWING.
</bodyText>
<sectionHeader confidence="0.998666" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999985034482759">
We have shown in this work how temporal in-
formation in the form of timelines can be incor-
porated into multi-document summarization. We
achieve this through two means, using: 1) three
novel features derived from timelines to mea-
sure the saliency of sentences, and 2) TIMEMMR
which considers time span similarity to enhance
the traditional MMR’s lexical diversity measure.
To overcome errors propagated from the under-
lying temporal processing systems, we proposed
a reliability filtering metric which can be used to
help decide when temporal information should be
used for summarization. The use of this metric
leads to an overall 5.9% gain in R-2 over the com-
petitive SWING baseline.
In future work, we are keen to study our pro-
posed timeline-related features more intrinsically
in the context of human-generated summaries.
This can help us better understand their value in
improving content selection. As noted earlier,
it will be also be useful to repeat our experi-
ments with less lexicon-influenced measures like
the Pyramid method (Passonneau et al., 2005).
Manual assessment of the generated summaries
can also be done to give a better picture of the
quality of the summaries generated with the use
of timelines. Finally, given the importance of re-
liability filtering, a natural question is if there are
other metrics that can be used to get better results.
</bodyText>
<sectionHeader confidence="0.99749" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.995991666666667">
This research is supported by the Singapore Na-
tional Research Foundation under its International
Research Centre @ Singapore Funding Initiative
and administered by the IDM Programme Office.
This work is also partially supported by the
National Natural Science Foundation of China
(Grant Nos. 61170189, 61370126, 61202239),
the Fund of the State Key Laboratory of Software
Development Environment (Grant No. SKLSDE-
2013ZX-19), and the Innovation Foundation of
Beihang University for Ph.D. Graduates (YWF-
13-T-YJSY-024).
</bodyText>
<page confidence="0.996642">
931
</page>
<sectionHeader confidence="0.985996" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999702379629629">
Javed Aslam, Matthew Ekstrand-Abueg, Virgil Pavlu,
Fernado Diaz, and Tetsuya Sakai. 2013. TREC
2013 Temporal Summarization. In Proceedings of
the 22nd Text Retrieval Conference (TREC), Novem-
ber.
Regina Barzilay, Kathleen McKeown, and Michael El-
hadad. 1999. Information Fusion in the Context of
Multi-document Summarization. In Proceedings of
the 37th Annual Meeting of the Association for Com-
putational Linguistics on Computational Linguistics
(ACL), pages 550–557, June.
Jaime Carbonell and Jade Goldstein. 1998. The Use
of MMR, Diversity-based Reranking for Reordering
Documents and Producing Summaries. In Proceed-
ings of the 21st Annual International ACM Confer-
ence on Research and Development in Information
Retrieval (SIGIR), pages 335–336, August.
Asli Celikyilmaz and Dilek Hakkani-Tur. 2010. A Hy-
brid Hierarchical Model for Multi-document Sum-
marization. In Proceedings of the 48th Annual
Meeting of the Association for Computational Lin-
guistics (ACL), pages 815–824, July.
John M. Conroy, Judith D. Schlesinger, Jeff Kubina,
Peter A. Rankel, and Dianne P. O’Leary. 2011.
CLASSY 2011 at TAC: Guided and Multi-lingual
Summaries and Evaluation Metrics. In Proceedings
of the Text Analysis Conference (TAC), November.
Gianluca Demartini, Malik Muhammad Saad Missen,
Roi Blanco, and Hugo Zaragoza. 2010. Entity
Summarization of News Articles. In Proceedings of
the 33rd Annual International ACM Conference on
Research and Development in Information Retrieval
(SIGIR), pages 798–796, July.
Pascal Denis and Philippe Muller. 2011. Predicting
Globally-Coherent Temporal Structures from Texts
via Endpoint Inference and Graph Decomposition.
In Proceedings of the 22nd International Joint Con-
ference on Artificial Intelligence (IJCAI), July.
Quang Xuan Do, Wei Lu, and Dan Roth. 2012. Joint
Inference for Event Timeline Construction. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP),
pages 677–689, July.
Lisa Ferro, Laurie Gerber, Inderjeet Mani, Beth Sund-
heim, and George Wilson. 2000. Instruction Man-
ual for the Annotation of Temporal Expressions.
Technical report, The MITRE Corporation.
Jade Goldstein, Vibhu Mittal, Jaime Carbonell, and
Mark Kantrowitz. 2000. Multi-document Sum-
marization by Sentence Extraction. In Proceedings
of the 2000 NAACL-ANLP Workshop on Automatic
Summarization, volume 4, pages 40–48, April.
Yihong Gong and Xin Liu. 2001. Generic Text Sum-
marization Using Relevance Measure and Latent Se-
mantic Analysis. In Proceedings of the 24th Annual
International ACM Conference on Research and De-
velopment in Information Retrieval (SIGIR), pages
19–25, September.
Iris Hendrickx, Walter Daelemans, Erwin Marsi, and
Emiel Krahmer. 2009. Reducing Redundancy in
Multi-document Summarization using Lexical Se-
mantic Similarity. In Proceedings of the Workshop
on Language Generation and Summarisation (UC-
NLG+Sum), pages 63–66, August.
Chin-Yew Lin and Eduard Hovy. 2003. Auto-
matic Evaluation of Summaries Using N-gram Co-
occurrence Statistics. In Proceedings of the Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics on Human Lan-
guage Technology (NAACL), volume 1, pages 71–
78, May.
Chin-Yew Lin. 2004. Looking for a Few Good Met-
rics: ROUGE and its Evaluation. In Working Notes
of the 4th NTCIR Workshop Meeting, June.
Maofu Liu, Wenjie Li, and Huijun Hu. 2009. Extrac-
tive Summarization Based on Event Term Temporal
Relation Graph and Critical Chain. In Information
Retrieval Technology, volume 5839 of Lecture Notes
in Computer Science, pages 87–99. Springer Berlin
Heidelberg.
Jun-Ping Ng and Min-Yen Kan. 2012. Improved
Temporal Relation Classification using Dependency
Parses and Selective Crowdsourced Annotations.
In Proceedings of the International Conference on
Computational Linguistics (COLING), pages 2109–
2124, December.
Jun-Ping Ng, Praveen Bysani, Ziheng Lin, Min-Yen
Kan, and Chew-Lim Tan. 2012. Exploiting
Category-Specific Information for Multi-Document
Summarization. In Proceedings of the International
Conference on Computational Linguistics (COL-
ING), pages 2093–2108, December.
Jun-Ping Ng, Min-Yen Kan, Ziheng Lin, Wei Feng, Bin
Chen, Jian Su, and Chew-Lim Tan. 2013. Exploit-
ing Discourse Analysis for Article-Wide Temporal
Classification. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 12–23, October.
Karolina Owczarzak and Hoa Dang. 2011. Overview
of the TAC 2011 Summarization Track: Guided
Task and AESOP Task. In Proceedings of the Text
Analysis Conference (TAC), November.
Rebecca J. Passonneau, Ani Nenkova, Kathleen McK-
eown, and Sergey Sigelman. 2005. Applying the
Pyramid Method in DUC 2005. In Proceedings of
the Document Understanding Conference Workshop
on Text Summarization, October.
</reference>
<page confidence="0.97339">
932
</page>
<reference confidence="0.999565568627451">
James Pustejovsky, Jos´e Castano, Robert Ingria, Roser
Sauri, Robert Gaizauskas, Andrea Setzer, and Gra-
ham Katz. 2003a. TimeML: Robust Specification
of Event and Temporal Expressions in Text. In Pro-
ceedings of the 5th International Workshop on Com-
putational Semantics (IWCS), January.
James Pustejovsky, Patrick Hanks, Roser Sauri, An-
drew See, Robert Gaizauskas, Andrea Setzer,
Dragomir Radev, Beth Sundheim, David Day, Lisa
Ferro, and Marcia Lazo. 2003b. The TIMEBANK
corpus. In Proceedings of Corpus Linguistics, pages
647–656, March.
Jannik Str¨otgen and Michael Gertz. 2013. Multilin-
gual and Cross-domain Temporal Tagging. Lan-
guage Resources and Evaluation, 47(2):269–298.
Naushad Uzzaman, Hector Llorens, Leon Derczynski,
Marc Verhagen, James F. Allen, and James Puste-
jovsky. 2013. SemEval-2013 Task 1: TEMPEVAL-
3: Evaluating Time Expressions, Events, and Tem-
poral Relations. In Proceedings of the 7th Interna-
tional Workshop on Semantic Evaluation (SemEval),
June.
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Jessica Moszkowicz, and James
Pustejovsky. 2009. The TempEval Challenge: Iden-
tifying Temporal Relations in Text. Language Re-
sources and Evaluation, 43(2):161–179.
Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. SemEval-2010 Task 13:
TempEval-2. In Proceedings of the 5th Interna-
tional Workshop on Semantic Evaluation (SemEval),
pages 57–62, July.
Xiaojun Wan. 2007. TimedTextRank: Adding the
Temporal Dimension to Multi-Document Summa-
rization. In Proceedings of the 30th Annual Interna-
tional ACM Conference on Research and Develop-
ment in Information Retrieval (SIGIR), pages 867–
868, July.
Mingli Wu. 2008. Investigations on Temporal-
Oriented Event-Based Extractive Summarization.
Ph.D. thesis, Hong Kong Polytechnic University.
Shasha Xie and Yang Liu. 2008. Using Corpus
and Knowledge-based Similarity Measure in Max-
imum Marginal Relevance for Meeting Summariza-
tion. In Proceedings of the International Confer-
ence on Acoustics, Speech, and Signal Processing
(ICASSP), pages 4985–4988, March.
Renxian Zhang, You Ouyang, and Wenjie Li. 2011.
Guided Summarization with Aspect Recognition. In
Proceedings of the Text Analysis Conference (TAC),
November.
</reference>
<page confidence="0.999066">
933
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.959500">
<title confidence="0.999984">Exploiting Timelines to Enhance Multi-document Summarization</title>
<author confidence="0.996933">Yan Min-Yen Zhoujun</author>
<affiliation confidence="0.9976415">National Laboratories, of Computing, National University of Singapore, Key Laboratory of Software Development Environment, Beihang University, and Digital Media Institute, National University of Singapore,</affiliation>
<email confidence="0.988161">njunping@dso.org.sg</email>
<abstract confidence="0.999228260869566">We study the use of temporal information in the form of timelines to enhance multidocument summarization. We employ a fully automated temporal processing system to generate a timeline for each input document. We derive three features from these timelines, and show that their use in supervised summarization lead to a significant 4.1% improvement in ROUGE performance over a state-of-the-art base- In addition, we propose a modification to Maximal Marginal Relevance that promotes temporal diversity by way of computing time span similarity, and show its utility in summarizing certain document sets. We also propose a filtering metric to discard noisy timelines generated by our automatic processes, to purify the timeline input for summarization. By selectively using timelines guided by filtering, overall summarization performance is increased by a significant 5.9%.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Javed Aslam</author>
<author>Matthew Ekstrand-Abueg</author>
<author>Virgil Pavlu</author>
<author>Fernado Diaz</author>
<author>Tetsuya Sakai</author>
</authors>
<title>TREC 2013 Temporal Summarization.</title>
<date>2013</date>
<booktitle>In Proceedings of the 22nd Text Retrieval Conference (TREC),</booktitle>
<contexts>
<context position="9564" citStr="Aslam et al., 2013" startWordPosition="1525" endWordPosition="1528">is guided by the number of events happening within the same time span, and relies on event co-referencing. In this work, we have simplified this idea by dropping the need for event coreferencing (removing a source of propagated error), and augmented it with two additional features derived from timelines. By doing so, we are able to make better use of the available temporal information, taking into account all known events and the time in which they occur. A useful note here is that this work is arguably different from the Temporal Summarization (TmpSum) track at the Text Retrieval Conference (Aslam et al., 2013). Given a large stream of data in real-time, the purpose of the TmpSum track is to look out for a query event, and retrieve specific details about the event over a period of time. Systems are also expected to identify the source sentences from which these details are retrieved. This is not the same as our approach here, which makes use of temporal information encoded in timelines to generate prose summaries. 3 Methodology To incorporate temporal information into multidocument summarization, we adopt the workflow in Figure 3, which has two key processes: 1) temporal processing, and 2) summariza</context>
</contexts>
<marker>Aslam, Ekstrand-Abueg, Pavlu, Diaz, Sakai, 2013</marker>
<rawString>Javed Aslam, Matthew Ekstrand-Abueg, Virgil Pavlu, Fernado Diaz, and Tetsuya Sakai. 2013. TREC 2013 Temporal Summarization. In Proceedings of the 22nd Text Retrieval Conference (TREC), November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen McKeown</author>
<author>Michael Elhadad</author>
</authors>
<title>Information Fusion in the Context of Multi-document Summarization.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics on Computational Linguistics (ACL),</booktitle>
<pages>550--557</pages>
<contexts>
<context position="4851" citStr="Barzilay et al., 1999" startWordPosition="751" endWordPosition="754"> in what officials described as the worst storm in years. (2) More than 100,000 coastal villagers have been evacuated before the cyclone made landfall. (3) The storm matched one in 1991 that sparked a tidal wave that killed an estimated 138,000 people, Karmakar told AFP. Figure 1: Modified extract from a news article which describes a cyclone landfall. Several events which appear in Figure 2 are bolded. Storm in 1991 Latest cyclone Figure 2: Possible timeline for events in Figure 1. summarization, they 1) have been largely confined to helping to chronologically order content within summaries (Barzilay et al., 1999), or 2) focus only on the use of recency as an indicator of saliency (Goldstein et al., 2000; Wan, 2007). In this work we construct timelines (as a representation of temporal information) automatically and incorporate them into a state-of-the-art multidocument summarization system. This is achieved with 1) three novel features derived from timelines to help measure the saliency of sentences, as well as 2) TIMEMMR, a modification to the traditional Maximal Marginal Relevance (MMR) (Carbonell and Goldstein, 1998). TimeMMR promotes diversity by additionally considering temporal information instea</context>
<context position="6098" citStr="Barzilay et al. (1999)" startWordPosition="943" endWordPosition="946">ities. Through these, we demonstrate that temporal information is useful for multi-document summarization. Compared to a competitive baseline, significant improvements of up to 4.1% are obtained. Automatic temporal processing systems are not perfect yet, and this may have an impact on their use for downstream applications. This work additionally proposes the use of the lengths of timelines as a metric to gauge the usefulness of timelines. Together with the earlier described contributions, this metric further improves summarization, yielding an overall 5.9% performance increase. 2 Related Work Barzilay et al. (1999) were one of the first to use time for multi-document summarization. They recognized the importance of generating a summary which presents the time perspective of the summarized documents correctly. They estimated the chronological ordering of events with a small set of heuristics, and also made use of lexical patterns to perform basic time normalization on terms like “today” relative to the document creation time. The induced ordering is used to present the selected summary content, following the chronological order in the original documents. In another line of work, Goldstein et al. (2000) m</context>
</contexts>
<marker>Barzilay, McKeown, Elhadad, 1999</marker>
<rawString>Regina Barzilay, Kathleen McKeown, and Michael Elhadad. 1999. Information Fusion in the Context of Multi-document Summarization. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics on Computational Linguistics (ACL), pages 550–557, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime Carbonell</author>
<author>Jade Goldstein</author>
</authors>
<title>The Use of MMR, Diversity-based Reranking for Reordering Documents and Producing Summaries.</title>
<date>1998</date>
<booktitle>In Proceedings of the 21st Annual International ACM Conference on Research and Development in Information Retrieval (SIGIR),</booktitle>
<pages>335--336</pages>
<contexts>
<context position="5367" citStr="Carbonell and Goldstein, 1998" startWordPosition="832" endWordPosition="835">1) have been largely confined to helping to chronologically order content within summaries (Barzilay et al., 1999), or 2) focus only on the use of recency as an indicator of saliency (Goldstein et al., 2000; Wan, 2007). In this work we construct timelines (as a representation of temporal information) automatically and incorporate them into a state-of-the-art multidocument summarization system. This is achieved with 1) three novel features derived from timelines to help measure the saliency of sentences, as well as 2) TIMEMMR, a modification to the traditional Maximal Marginal Relevance (MMR) (Carbonell and Goldstein, 1998). TimeMMR promotes diversity by additionally considering temporal information instead of just lexical similarities. Through these, we demonstrate that temporal information is useful for multi-document summarization. Compared to a competitive baseline, significant improvements of up to 4.1% are obtained. Automatic temporal processing systems are not perfect yet, and this may have an impact on their use for downstream applications. This work additionally proposes the use of the lengths of timelines as a metric to gauge the usefulness of timelines. Together with the earlier described contribution</context>
</contexts>
<marker>Carbonell, Goldstein, 1998</marker>
<rawString>Jaime Carbonell and Jade Goldstein. 1998. The Use of MMR, Diversity-based Reranking for Reordering Documents and Producing Summaries. In Proceedings of the 21st Annual International ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 335–336, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asli Celikyilmaz</author>
<author>Dilek Hakkani-Tur</author>
</authors>
<title>A Hybrid Hierarchical Model for Multi-document Summarization.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>815--824</pages>
<marker>Celikyilmaz, Hakkani-Tur, 2010</marker>
<rawString>Asli Celikyilmaz and Dilek Hakkani-Tur. 2010. A Hybrid Hierarchical Model for Multi-document Summarization. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL), pages 815–824, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John M Conroy</author>
<author>Judith D Schlesinger</author>
<author>Jeff Kubina</author>
<author>Peter A Rankel</author>
<author>Dianne P O’Leary</author>
</authors>
<title>at TAC: Guided and Multi-lingual Summaries and Evaluation Metrics.</title>
<date>2011</date>
<booktitle>In Proceedings of the Text Analysis Conference (TAC),</booktitle>
<publisher>CLASSY</publisher>
<marker>Conroy, Schlesinger, Kubina, Rankel, O’Leary, 2011</marker>
<rawString>John M. Conroy, Judith D. Schlesinger, Jeff Kubina, Peter A. Rankel, and Dianne P. O’Leary. 2011. CLASSY 2011 at TAC: Guided and Multi-lingual Summaries and Evaluation Metrics. In Proceedings of the Text Analysis Conference (TAC), November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gianluca Demartini</author>
<author>Malik Muhammad Saad Missen</author>
<author>Roi Blanco</author>
<author>Hugo Zaragoza</author>
</authors>
<title>Entity Summarization of News Articles.</title>
<date>2010</date>
<booktitle>In Proceedings of the 33rd Annual International ACM Conference on Research and Development in Information Retrieval (SIGIR),</booktitle>
<pages>798--796</pages>
<contexts>
<context position="7009" citStr="Demartini et al. (2010)" startWordPosition="1089" endWordPosition="1092">lso made use of lexical patterns to perform basic time normalization on terms like “today” relative to the document creation time. The induced ordering is used to present the selected summary content, following the chronological order in the original documents. In another line of work, Goldstein et al. (2000) made use of the temporal ordering of documents to be summarized. In computing the relevance of a passage for inclusion into the final summary, they considered the recency of the passage’s source document. Passages from more recent documents are deemed to be more important. Wan (2007) and Demartini et al. (2010) made similar assumptions in their work on TIMEDTEXTRANK and entity summarization, respectively. Instead of just considering the notion of recency, Liu et al. (2009) proposed an interesting approach using a temporal graph. Events within a document set correspond to vertices in their proposed graph, while edges are determined by the temporal ordering of events. From the resulting weakly-connected graph, the largest forests are assumed to contain key topics within the document set and used to influence a scoring mechanism which prefers sentences touching on these topics. Wu (2008) also made use </context>
</contexts>
<marker>Demartini, Missen, Blanco, Zaragoza, 2010</marker>
<rawString>Gianluca Demartini, Malik Muhammad Saad Missen, Roi Blanco, and Hugo Zaragoza. 2010. Entity Summarization of News Articles. In Proceedings of the 33rd Annual International ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 798–796, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascal Denis</author>
<author>Philippe Muller</author>
</authors>
<title>Predicting Globally-Coherent Temporal Structures from Texts via Endpoint Inference and Graph Decomposition.</title>
<date>2011</date>
<booktitle>In Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI),</booktitle>
<contexts>
<context position="10459" citStr="Denis and Muller, 2011" startWordPosition="1664" endWordPosition="1667">eved. This is not the same as our approach here, which makes use of temporal information encoded in timelines to generate prose summaries. 3 Methodology To incorporate temporal information into multidocument summarization, we adopt the workflow in Figure 3, which has two key processes: 1) temporal processing, and 2) summarization. Figure 3: Incorporating temporal information into the SWING summarization pipeline. Temporal Processing generates timelines from text, one for each input document. Timelines are well-understood constructs which have often been used to represent temporal information (Denis and Muller, 2011; Do et al., 2012). They indicate the temporal relationships between two basic temporal units: 1) events, and 2) time expressions (or timexes for short). In this work, we adopt the definitions proposed in the standardized TIMEML annotation (Pustejovsky et al., 2003a). An event refers to an eventuality, a situation that occurs or an action; while a timex is a reference to a particular date or time (e.g. “2013 December 31”). Following the “divide-and-conquer” approach described in Verhagen et al. (2010), results from the three temporal processing steps: 1) timex normalization, 2) event-timex tem</context>
</contexts>
<marker>Denis, Muller, 2011</marker>
<rawString>Pascal Denis and Philippe Muller. 2011. Predicting Globally-Coherent Temporal Structures from Texts via Endpoint Inference and Graph Decomposition. In Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI), July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quang Xuan Do</author>
<author>Wei Lu</author>
<author>Dan Roth</author>
</authors>
<title>Joint Inference for Event Timeline Construction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP),</booktitle>
<pages>677--689</pages>
<contexts>
<context position="10477" citStr="Do et al., 2012" startWordPosition="1668" endWordPosition="1671">me as our approach here, which makes use of temporal information encoded in timelines to generate prose summaries. 3 Methodology To incorporate temporal information into multidocument summarization, we adopt the workflow in Figure 3, which has two key processes: 1) temporal processing, and 2) summarization. Figure 3: Incorporating temporal information into the SWING summarization pipeline. Temporal Processing generates timelines from text, one for each input document. Timelines are well-understood constructs which have often been used to represent temporal information (Denis and Muller, 2011; Do et al., 2012). They indicate the temporal relationships between two basic temporal units: 1) events, and 2) time expressions (or timexes for short). In this work, we adopt the definitions proposed in the standardized TIMEML annotation (Pustejovsky et al., 2003a). An event refers to an eventuality, a situation that occurs or an action; while a timex is a reference to a particular date or time (e.g. “2013 December 31”). Following the “divide-and-conquer” approach described in Verhagen et al. (2010), results from the three temporal processing steps: 1) timex normalization, 2) event-timex temporal relationship</context>
</contexts>
<marker>Do, Lu, Roth, 2012</marker>
<rawString>Quang Xuan Do, Wei Lu, and Dan Roth. 2012. Joint Inference for Event Timeline Construction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP), pages 677–689, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lisa Ferro</author>
<author>Laurie Gerber</author>
<author>Inderjeet Mani</author>
<author>Beth Sundheim</author>
<author>George Wilson</author>
</authors>
<title>Instruction Manual for the Annotation of Temporal Expressions.</title>
<date>2000</date>
<tech>Technical report, The MITRE</tech>
<publisher>Corporation.</publisher>
<contexts>
<context position="1569" citStr="Ferro et al., 2000" startWordPosition="222" endWordPosition="225">ng time span similarity, and show its utility in summarizing certain document sets. We also propose a filtering metric to discard noisy timelines generated by our automatic processes, to purify the timeline input for summarization. By selectively using timelines guided by filtering, overall summarization performance is increased by a significant 5.9%. 1 Introduction There has been a good amount of research invested into improving the temporal interpretation of text. Besides the increasing availability of annotation standards (e.g., TIMEML (Pustejovsky et al., 2003a)) and corpora (e.g., TIDES (Ferro et al., 2000), TimeBank (Pustejovsky et al., 2003b)), the community has also organized three successful evaluation workshops — TempEval-1 (Verhagen et al., 2009), -2 (Verhagen et al., 2010), and -3 (Uzzaman et al., 2013). As the state-of-theart improves, these workshops have moved away from the piecemeal evaluation of individual temporal processing tasks and towards the evaluation of complete end-to-end systems in TempEval-3. We believe our understanding of the temporal information found in text is sufficiently robust, and that there is an opportunity to now leverage this information in downstream applicat</context>
</contexts>
<marker>Ferro, Gerber, Mani, Sundheim, Wilson, 2000</marker>
<rawString>Lisa Ferro, Laurie Gerber, Inderjeet Mani, Beth Sundheim, and George Wilson. 2000. Instruction Manual for the Annotation of Temporal Expressions. Technical report, The MITRE Corporation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jade Goldstein</author>
<author>Vibhu Mittal</author>
<author>Jaime Carbonell</author>
<author>Mark Kantrowitz</author>
</authors>
<title>Multi-document Summarization by Sentence Extraction.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2000 NAACL-ANLP Workshop on Automatic Summarization,</booktitle>
<volume>4</volume>
<pages>40--48</pages>
<contexts>
<context position="4943" citStr="Goldstein et al., 2000" startWordPosition="769" endWordPosition="772">agers have been evacuated before the cyclone made landfall. (3) The storm matched one in 1991 that sparked a tidal wave that killed an estimated 138,000 people, Karmakar told AFP. Figure 1: Modified extract from a news article which describes a cyclone landfall. Several events which appear in Figure 2 are bolded. Storm in 1991 Latest cyclone Figure 2: Possible timeline for events in Figure 1. summarization, they 1) have been largely confined to helping to chronologically order content within summaries (Barzilay et al., 1999), or 2) focus only on the use of recency as an indicator of saliency (Goldstein et al., 2000; Wan, 2007). In this work we construct timelines (as a representation of temporal information) automatically and incorporate them into a state-of-the-art multidocument summarization system. This is achieved with 1) three novel features derived from timelines to help measure the saliency of sentences, as well as 2) TIMEMMR, a modification to the traditional Maximal Marginal Relevance (MMR) (Carbonell and Goldstein, 1998). TimeMMR promotes diversity by additionally considering temporal information instead of just lexical similarities. Through these, we demonstrate that temporal information is u</context>
<context position="6696" citStr="Goldstein et al. (2000)" startWordPosition="1038" endWordPosition="1041">rk Barzilay et al. (1999) were one of the first to use time for multi-document summarization. They recognized the importance of generating a summary which presents the time perspective of the summarized documents correctly. They estimated the chronological ordering of events with a small set of heuristics, and also made use of lexical patterns to perform basic time normalization on terms like “today” relative to the document creation time. The induced ordering is used to present the selected summary content, following the chronological order in the original documents. In another line of work, Goldstein et al. (2000) made use of the temporal ordering of documents to be summarized. In computing the relevance of a passage for inclusion into the final summary, they considered the recency of the passage’s source document. Passages from more recent documents are deemed to be more important. Wan (2007) and Demartini et al. (2010) made similar assumptions in their work on TIMEDTEXTRANK and entity summarization, respectively. Instead of just considering the notion of recency, Liu et al. (2009) proposed an interesting approach using a temporal graph. Events within a document set correspond to vertices in their pro</context>
</contexts>
<marker>Goldstein, Mittal, Carbonell, Kantrowitz, 2000</marker>
<rawString>Jade Goldstein, Vibhu Mittal, Jaime Carbonell, and Mark Kantrowitz. 2000. Multi-document Summarization by Sentence Extraction. In Proceedings of the 2000 NAACL-ANLP Workshop on Automatic Summarization, volume 4, pages 40–48, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yihong Gong</author>
<author>Xin Liu</author>
</authors>
<title>Generic Text Summarization Using Relevance Measure and Latent Semantic Analysis.</title>
<date>2001</date>
<booktitle>In Proceedings of the 24th Annual International ACM Conference on Research and Development in Information Retrieval (SIGIR),</booktitle>
<pages>pages</pages>
<contexts>
<context position="17846" citStr="Gong and Liu, 2001" startWordPosition="2974" endWordPosition="2977">as the number of time spans between the earliest time span TS,, and the latest time span TS, Referring to Figure 4, suppose a sentence contains the three events which have been shaded black. The temporal coverage in this case includes all the time spans from time span A to time span A + 4, inclusive. The constraint on the number of sentences that can be included in a summary requires us to select compact sentences which contain as many relevant facts as possible. Traditional lexical measures may attempt to achieve this by computing the ratio of keyphrases to the number of words in a sentence (Gong and Liu, 2001). Stated equivalently, when two sentences are of the same length, if one contains more keyphrases, it should contain more useful facts. TCD parallels this idea with the use of temporal information, i.e. if two sentences are of the same temporal coverage, then the one with more events should carry more useful facts. Formally, if a sentence s contains events ]E3 = {e1,... , e,}, where each event is associated with a time span T Si, then TCD is computed using: TCD(s) = |E3 |(4) |TS� − T S1| where |E3 |is the number of events found in s, and |TS,, − TS1 |is the temporal coverage of s. 3.3 Enhancin</context>
</contexts>
<marker>Gong, Liu, 2001</marker>
<rawString>Yihong Gong and Xin Liu. 2001. Generic Text Summarization Using Relevance Measure and Latent Semantic Analysis. In Proceedings of the 24th Annual International ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 19–25, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iris Hendrickx</author>
<author>Walter Daelemans</author>
<author>Erwin Marsi</author>
<author>Emiel Krahmer</author>
</authors>
<title>Reducing Redundancy in Multi-document Summarization using Lexical Semantic Similarity.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Language Generation and Summarisation (UCNLG+Sum),</booktitle>
<pages>63--66</pages>
<contexts>
<context position="20612" citStr="Hendrickx et al. (2009)" startWordPosition="3463" endWordPosition="3467">taset. T is the proportion of events in s which happen in the same time span as another event in any other sentence in S. Two events are said to be in the same time span if one happens within the time period the other happens in. For example, an event that takes place in “2014 June” is said to take place within the year “2014”. While TIMEMMR is proposed here as an improvement over MMR, the premise is that incorporating temporal information can be helpful to minimize redundancy in summaries. In future work, one could apply it to other state-of-the-art lexical-based approaches including that of Hendrickx et al. (2009) and Celikyilmaz and HakkaniTur (2010). We also believe the same idea can be transplanted even to non-lexical motivated techniques such as the corpus-based similarity measure proposed by Xie and Liu (2008). We chose to use MMR here as a proof-of-concept to demonstrate the viability of such a technique, and to easily integrate our work into SWING. 3.4 Gauging Usefulness of Timelines Temporal processing is imperfect. Together with the simplifying assumptions that were made in timeline construction, our generated timelines have errors which propagate into the summarization process. With this in m</context>
</contexts>
<marker>Hendrickx, Daelemans, Marsi, Krahmer, 2009</marker>
<rawString>Iris Hendrickx, Walter Daelemans, Erwin Marsi, and Emiel Krahmer. 2009. Reducing Redundancy in Multi-document Summarization using Lexical Semantic Similarity. In Proceedings of the Workshop on Language Generation and Summarisation (UCNLG+Sum), pages 63–66, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
<author>Eduard Hovy</author>
</authors>
<title>Automatic Evaluation of Summaries Using N-gram Cooccurrence Statistics.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL),</booktitle>
<volume>1</volume>
<pages>71--78</pages>
<contexts>
<context position="23369" citStr="Lin and Hovy, 2003" startWordPosition="3911" endWordPosition="3914">value are the timelines used. 4 Experiments and Results The proposed timeline features and TIMEMMR were implemented on top of SWING, and evaluated on the test documents from TAC-2011 (Owczarzak and Dang, 2011). SWING makes use of three generic features and two features targeted specifically at guided summarization. Since the focus of this paper is on multi-document summarization, we employ only the three generic features, i.e., 1) sentence position, 2) sentence length, and 3) interpolated n-gram document frequency in our experiments below. Summarization evaluation is done using ROUGE-2 (R-2) (Lin and Hovy, 2003), as it has previously been shown to correlate well with human assessment (Lin, 2004) and is often used to evaluate automatic text summarization. The results obtained are shown in Table 1. In the table, each row refers to a specific summarization system configuration. We also show the results of two reference systems, CLASSY (Conroy et al., 2011) and POLYCOM (Zhang et al., 2011), as benchmarks. CLASSY and POLYCOM are top performing systems at TAC-2011 (ranked 2nd and 3rd by R-2 in TAC 2011, respectively; the full version of SWING was ranked 1st with a R-2 score of 0.1380). From these results, </context>
</contexts>
<marker>Lin, Hovy, 2003</marker>
<rawString>Chin-Yew Lin and Eduard Hovy. 2003. Automatic Evaluation of Summaries Using N-gram Cooccurrence Statistics. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL), volume 1, pages 71– 78, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
</authors>
<title>Looking for a Few Good Metrics: ROUGE and its Evaluation.</title>
<date>2004</date>
<booktitle>In Working Notes of the 4th NTCIR Workshop Meeting,</booktitle>
<contexts>
<context position="23454" citStr="Lin, 2004" startWordPosition="3927" endWordPosition="3928">EMMR were implemented on top of SWING, and evaluated on the test documents from TAC-2011 (Owczarzak and Dang, 2011). SWING makes use of three generic features and two features targeted specifically at guided summarization. Since the focus of this paper is on multi-document summarization, we employ only the three generic features, i.e., 1) sentence position, 2) sentence length, and 3) interpolated n-gram document frequency in our experiments below. Summarization evaluation is done using ROUGE-2 (R-2) (Lin and Hovy, 2003), as it has previously been shown to correlate well with human assessment (Lin, 2004) and is often used to evaluate automatic text summarization. The results obtained are shown in Table 1. In the table, each row refers to a specific summarization system configuration. We also show the results of two reference systems, CLASSY (Conroy et al., 2011) and POLYCOM (Zhang et al., 2011), as benchmarks. CLASSY and POLYCOM are top performing systems at TAC-2011 (ranked 2nd and 3rd by R-2 in TAC 2011, respectively; the full version of SWING was ranked 1st with a R-2 score of 0.1380). From these results, we can see that SWING is a very competitive baseline. Rows 9 to 16 additionally incor</context>
</contexts>
<marker>Lin, 2004</marker>
<rawString>Chin-Yew Lin. 2004. Looking for a Few Good Metrics: ROUGE and its Evaluation. In Working Notes of the 4th NTCIR Workshop Meeting, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maofu Liu</author>
<author>Wenjie Li</author>
<author>Huijun Hu</author>
</authors>
<title>Extractive Summarization Based on Event Term Temporal Relation Graph and Critical Chain.</title>
<date>2009</date>
<booktitle>In Information Retrieval Technology,</booktitle>
<volume>5839</volume>
<pages>87--99</pages>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="7174" citStr="Liu et al. (2009)" startWordPosition="1116" endWordPosition="1119">the selected summary content, following the chronological order in the original documents. In another line of work, Goldstein et al. (2000) made use of the temporal ordering of documents to be summarized. In computing the relevance of a passage for inclusion into the final summary, they considered the recency of the passage’s source document. Passages from more recent documents are deemed to be more important. Wan (2007) and Demartini et al. (2010) made similar assumptions in their work on TIMEDTEXTRANK and entity summarization, respectively. Instead of just considering the notion of recency, Liu et al. (2009) proposed an interesting approach using a temporal graph. Events within a document set correspond to vertices in their proposed graph, while edges are determined by the temporal ordering of events. From the resulting weakly-connected graph, the largest forests are assumed to contain key topics within the document set and used to influence a scoring mechanism which prefers sentences touching on these topics. Wu (2008) also made use of the relative ordering of events. He assigned complete timestamps to events extracted from text. After laying out these events onto a timeline by making use of the</context>
</contexts>
<marker>Liu, Li, Hu, 2009</marker>
<rawString>Maofu Liu, Wenjie Li, and Huijun Hu. 2009. Extractive Summarization Based on Event Term Temporal Relation Graph and Critical Chain. In Information Retrieval Technology, volume 5839 of Lecture Notes in Computer Science, pages 87–99. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun-Ping Ng</author>
<author>Min-Yen Kan</author>
</authors>
<title>Improved Temporal Relation Classification using Dependency Parses and Selective Crowdsourced Annotations.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING),</booktitle>
<pages>2109--2124</pages>
<contexts>
<context position="11274" citStr="Ng and Kan, 2012" startWordPosition="1794" endWordPosition="1797">ed in the standardized TIMEML annotation (Pustejovsky et al., 2003a). An event refers to an eventuality, a situation that occurs or an action; while a timex is a reference to a particular date or time (e.g. “2013 December 31”). Following the “divide-and-conquer” approach described in Verhagen et al. (2010), results from the three temporal processing steps: 1) timex normalization, 2) event-timex temporal relationship classification, and 3) event-event temporal relationship classification, are merged to obtain timelines (top half of Figure 3). We tap on existing systems for each of these steps (Ng and Kan, 2012; Str¨otgen and Gertz, 2013; Ng et al., 2013). Summarization. We make use of a state-ofthe-art summarization system, SWING (Ng et al., 2012) (bottom half of Figure 3). SWING is a supervised, extractive summarization system which ranks sentences based on scores computed using a set of features in the Sentence Scoring phase. The Maximal Marginal Relevance (MMR) algorithm is then used in the Sentence Re-ordering phase to re-order and select sentences to form the final summary. The timelines built in the earlier temporal processing can be incorporated into this pipeline by deriving a set of featur</context>
</contexts>
<marker>Ng, Kan, 2012</marker>
<rawString>Jun-Ping Ng and Min-Yen Kan. 2012. Improved Temporal Relation Classification using Dependency Parses and Selective Crowdsourced Annotations. In Proceedings of the International Conference on Computational Linguistics (COLING), pages 2109– 2124, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun-Ping Ng</author>
<author>Praveen Bysani</author>
<author>Ziheng Lin</author>
<author>Min-Yen Kan</author>
<author>Chew-Lim Tan</author>
</authors>
<title>Exploiting Category-Specific Information for Multi-Document Summarization.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING),</booktitle>
<pages>2093--2108</pages>
<contexts>
<context position="11414" citStr="Ng et al., 2012" startWordPosition="1817" endWordPosition="1820">n; while a timex is a reference to a particular date or time (e.g. “2013 December 31”). Following the “divide-and-conquer” approach described in Verhagen et al. (2010), results from the three temporal processing steps: 1) timex normalization, 2) event-timex temporal relationship classification, and 3) event-event temporal relationship classification, are merged to obtain timelines (top half of Figure 3). We tap on existing systems for each of these steps (Ng and Kan, 2012; Str¨otgen and Gertz, 2013; Ng et al., 2013). Summarization. We make use of a state-ofthe-art summarization system, SWING (Ng et al., 2012) (bottom half of Figure 3). SWING is a supervised, extractive summarization system which ranks sentences based on scores computed using a set of features in the Sentence Scoring phase. The Maximal Marginal Relevance (MMR) algorithm is then used in the Sentence Re-ordering phase to re-order and select sentences to form the final summary. The timelines built in the earlier temporal processing can be incorporated into this pipeline by deriving a set of features used to score sentences in Sentence Scoring, and as input to the MMR algorithm when computing similarity in Sentence Re-ordering. 3.1 Tim</context>
<context position="19617" citStr="Ng et al. (2012)" startWordPosition="3282" endWordPosition="3285">ithin the same time span. They describe the destruction caused by a hurricane with trees uprooted and buildings blown away. A summary about the hurricane need not contain all of these sentences as they are all describing the same thing. However it is not trivial for the lexically-motivated MMR algorithm to detect that events like “passed”, “uprooted” or “damaged” are in fact repetitive. Thus, we propose further penalizing the score of s if it contains events that happen in similar time spans as those contained in sentences within S. We refer to this as TIMEMMR. Modifying the MMR equation from Ng et al. (2012): TimeMMR(s) = Score(s) − -yR2(s, S) − (1 − -y)T (s, S) (5) where Score(s) is the score of s, S is the set of sentences already selected to be in the summary from previous iterations, and R2 is the predicted ROUGE-2 score of s with respect to the already selected sentences (S). γ is a weighting parameter which is empirically set to 0.9 after tuning over a development dataset. T is the proportion of events in s which happen in the same time span as another event in any other sentence in S. Two events are said to be in the same time span if one happens within the time period the other happens in</context>
</contexts>
<marker>Ng, Bysani, Lin, Kan, Tan, 2012</marker>
<rawString>Jun-Ping Ng, Praveen Bysani, Ziheng Lin, Min-Yen Kan, and Chew-Lim Tan. 2012. Exploiting Category-Specific Information for Multi-Document Summarization. In Proceedings of the International Conference on Computational Linguistics (COLING), pages 2093–2108, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun-Ping Ng</author>
<author>Min-Yen Kan</author>
<author>Ziheng Lin</author>
<author>Wei Feng</author>
<author>Bin Chen</author>
<author>Jian Su</author>
<author>Chew-Lim Tan</author>
</authors>
<title>Exploiting Discourse Analysis for Article-Wide Temporal Classification.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>12--23</pages>
<contexts>
<context position="11319" citStr="Ng et al., 2013" startWordPosition="1802" endWordPosition="1805">tejovsky et al., 2003a). An event refers to an eventuality, a situation that occurs or an action; while a timex is a reference to a particular date or time (e.g. “2013 December 31”). Following the “divide-and-conquer” approach described in Verhagen et al. (2010), results from the three temporal processing steps: 1) timex normalization, 2) event-timex temporal relationship classification, and 3) event-event temporal relationship classification, are merged to obtain timelines (top half of Figure 3). We tap on existing systems for each of these steps (Ng and Kan, 2012; Str¨otgen and Gertz, 2013; Ng et al., 2013). Summarization. We make use of a state-ofthe-art summarization system, SWING (Ng et al., 2012) (bottom half of Figure 3). SWING is a supervised, extractive summarization system which ranks sentences based on scores computed using a set of features in the Sentence Scoring phase. The Maximal Marginal Relevance (MMR) algorithm is then used in the Sentence Re-ordering phase to re-order and select sentences to form the final summary. The timelines built in the earlier temporal processing can be incorporated into this pipeline by deriving a set of features used to score sentences in Sentence Scorin</context>
</contexts>
<marker>Ng, Kan, Lin, Feng, Chen, Su, Tan, 2013</marker>
<rawString>Jun-Ping Ng, Min-Yen Kan, Ziheng Lin, Wei Feng, Bin Chen, Jian Su, and Chew-Lim Tan. 2013. Exploiting Discourse Analysis for Article-Wide Temporal Classification. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 12–23, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karolina Owczarzak</author>
<author>Hoa Dang</author>
</authors>
<title>Overview of the TAC 2011 Summarization Track: Guided Task and AESOP Task.</title>
<date>2011</date>
<booktitle>In Proceedings of the Text Analysis Conference (TAC),</booktitle>
<contexts>
<context position="22959" citStr="Owczarzak and Dang, 2011" startWordPosition="3848" endWordPosition="3851">ich describes several events (bolded) happening at the same time. very easily propagated into summary generation for shorter timelines, leading to less useful results. We incorporate this into our process as follows: given an input document collection (which consists of 10 documents), the average size of all the timelines for each of these 10 documents is computed. Only when this value is larger than a threshold value are the timelines used. 4 Experiments and Results The proposed timeline features and TIMEMMR were implemented on top of SWING, and evaluated on the test documents from TAC-2011 (Owczarzak and Dang, 2011). SWING makes use of three generic features and two features targeted specifically at guided summarization. Since the focus of this paper is on multi-document summarization, we employ only the three generic features, i.e., 1) sentence position, 2) sentence length, and 3) interpolated n-gram document frequency in our experiments below. Summarization evaluation is done using ROUGE-2 (R-2) (Lin and Hovy, 2003), as it has previously been shown to correlate well with human assessment (Lin, 2004) and is often used to evaluate automatic text summarization. The results obtained are shown in Table 1. I</context>
</contexts>
<marker>Owczarzak, Dang, 2011</marker>
<rawString>Karolina Owczarzak and Hoa Dang. 2011. Overview of the TAC 2011 Summarization Track: Guided Task and AESOP Task. In Proceedings of the Text Analysis Conference (TAC), November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca J Passonneau</author>
<author>Ani Nenkova</author>
<author>Kathleen McKeown</author>
<author>Sergey Sigelman</author>
</authors>
<title>Applying the Pyramid Method in DUC</title>
<date>2005</date>
<booktitle>In Proceedings of the Document Understanding Conference Workshop on Text Summarization,</booktitle>
<contexts>
<context position="32745" citStr="Passonneau et al., 2005" startWordPosition="5506" endWordPosition="5509">t of (R4), while (L4) is the full version of the truncated (R5). TIMEMMR penalizes (R3). (R3) reports that the shoe-throwing incident happened as the U.S. President Bush appeared together with the Iraqi Prime Minister Nouri al-Maliki. However their joint appearance is already reported in (R1) (and similarly (L1)). (R3) repeats what had been presented earlier. Since (R1) and (R3) talk about the same time span, TIMEMMR down-weights (R3). We argue that this is better even though the ROUGE scores indicate otherwise. In future work it will be worthwhile to consider the use of metrics like Pyramid (Passonneau et al., 2005) which are less bound to superficial lexicons. Reliability Filtering. Table 2 shows the effect of varying the filtering threshold on R-2 for the best performing configuration from Table 1 (i.e., SWING+TSI+CTSI+TCD). The result obtained in Row 9 using a threshold of 42.68 is also re-produced for reference. T=0 means that timelines are used for all input document sets, whereas T=100 means that no timelines are used, as the length of the longest timeline is less than 100. As the threshold increases from 0 to 40–50, summarization performance improves while the T R-2 Sig # T R-2 Sig # 0 0.1394 * 44</context>
<context position="37602" citStr="Passonneau et al., 2005" startWordPosition="6316" endWordPosition="6319">ssing systems, we proposed a reliability filtering metric which can be used to help decide when temporal information should be used for summarization. The use of this metric leads to an overall 5.9% gain in R-2 over the competitive SWING baseline. In future work, we are keen to study our proposed timeline-related features more intrinsically in the context of human-generated summaries. This can help us better understand their value in improving content selection. As noted earlier, it will be also be useful to repeat our experiments with less lexicon-influenced measures like the Pyramid method (Passonneau et al., 2005). Manual assessment of the generated summaries can also be done to give a better picture of the quality of the summaries generated with the use of timelines. Finally, given the importance of reliability filtering, a natural question is if there are other metrics that can be used to get better results. Acknowledgments This research is supported by the Singapore National Research Foundation under its International Research Centre @ Singapore Funding Initiative and administered by the IDM Programme Office. This work is also partially supported by the National Natural Science Foundation of China (</context>
</contexts>
<marker>Passonneau, Nenkova, McKeown, Sigelman, 2005</marker>
<rawString>Rebecca J. Passonneau, Ani Nenkova, Kathleen McKeown, and Sergey Sigelman. 2005. Applying the Pyramid Method in DUC 2005. In Proceedings of the Document Understanding Conference Workshop on Text Summarization, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Jos´e Castano</author>
<author>Robert Ingria</author>
<author>Roser Sauri</author>
<author>Robert Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Graham Katz</author>
</authors>
<title>TimeML: Robust Specification of Event and Temporal Expressions in Text.</title>
<date>2003</date>
<booktitle>In Proceedings of the 5th International Workshop on Computational Semantics (IWCS),</booktitle>
<contexts>
<context position="1520" citStr="Pustejovsky et al., 2003" startWordPosition="214" endWordPosition="217">nce that promotes temporal diversity by way of computing time span similarity, and show its utility in summarizing certain document sets. We also propose a filtering metric to discard noisy timelines generated by our automatic processes, to purify the timeline input for summarization. By selectively using timelines guided by filtering, overall summarization performance is increased by a significant 5.9%. 1 Introduction There has been a good amount of research invested into improving the temporal interpretation of text. Besides the increasing availability of annotation standards (e.g., TIMEML (Pustejovsky et al., 2003a)) and corpora (e.g., TIDES (Ferro et al., 2000), TimeBank (Pustejovsky et al., 2003b)), the community has also organized three successful evaluation workshops — TempEval-1 (Verhagen et al., 2009), -2 (Verhagen et al., 2010), and -3 (Uzzaman et al., 2013). As the state-of-theart improves, these workshops have moved away from the piecemeal evaluation of individual temporal processing tasks and towards the evaluation of complete end-to-end systems in TempEval-3. We believe our understanding of the temporal information found in text is sufficiently robust, and that there is an opportunity to now</context>
<context position="10724" citStr="Pustejovsky et al., 2003" startWordPosition="1706" endWordPosition="1709"> has two key processes: 1) temporal processing, and 2) summarization. Figure 3: Incorporating temporal information into the SWING summarization pipeline. Temporal Processing generates timelines from text, one for each input document. Timelines are well-understood constructs which have often been used to represent temporal information (Denis and Muller, 2011; Do et al., 2012). They indicate the temporal relationships between two basic temporal units: 1) events, and 2) time expressions (or timexes for short). In this work, we adopt the definitions proposed in the standardized TIMEML annotation (Pustejovsky et al., 2003a). An event refers to an eventuality, a situation that occurs or an action; while a timex is a reference to a particular date or time (e.g. “2013 December 31”). Following the “divide-and-conquer” approach described in Verhagen et al. (2010), results from the three temporal processing steps: 1) timex normalization, 2) event-timex temporal relationship classification, and 3) event-event temporal relationship classification, are merged to obtain timelines (top half of Figure 3). We tap on existing systems for each of these steps (Ng and Kan, 2012; Str¨otgen and Gertz, 2013; Ng et al., 2013). Sum</context>
</contexts>
<marker>Pustejovsky, Castano, Ingria, Sauri, Gaizauskas, Setzer, Katz, 2003</marker>
<rawString>James Pustejovsky, Jos´e Castano, Robert Ingria, Roser Sauri, Robert Gaizauskas, Andrea Setzer, and Graham Katz. 2003a. TimeML: Robust Specification of Event and Temporal Expressions in Text. In Proceedings of the 5th International Workshop on Computational Semantics (IWCS), January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Patrick Hanks</author>
<author>Roser Sauri</author>
<author>Andrew See</author>
<author>Robert Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Dragomir Radev</author>
<author>Beth Sundheim</author>
<author>David Day</author>
<author>Lisa Ferro</author>
<author>Marcia Lazo</author>
</authors>
<title>The TIMEBANK corpus.</title>
<date>2003</date>
<booktitle>In Proceedings of Corpus Linguistics,</booktitle>
<pages>647--656</pages>
<contexts>
<context position="1520" citStr="Pustejovsky et al., 2003" startWordPosition="214" endWordPosition="217">nce that promotes temporal diversity by way of computing time span similarity, and show its utility in summarizing certain document sets. We also propose a filtering metric to discard noisy timelines generated by our automatic processes, to purify the timeline input for summarization. By selectively using timelines guided by filtering, overall summarization performance is increased by a significant 5.9%. 1 Introduction There has been a good amount of research invested into improving the temporal interpretation of text. Besides the increasing availability of annotation standards (e.g., TIMEML (Pustejovsky et al., 2003a)) and corpora (e.g., TIDES (Ferro et al., 2000), TimeBank (Pustejovsky et al., 2003b)), the community has also organized three successful evaluation workshops — TempEval-1 (Verhagen et al., 2009), -2 (Verhagen et al., 2010), and -3 (Uzzaman et al., 2013). As the state-of-theart improves, these workshops have moved away from the piecemeal evaluation of individual temporal processing tasks and towards the evaluation of complete end-to-end systems in TempEval-3. We believe our understanding of the temporal information found in text is sufficiently robust, and that there is an opportunity to now</context>
<context position="10724" citStr="Pustejovsky et al., 2003" startWordPosition="1706" endWordPosition="1709"> has two key processes: 1) temporal processing, and 2) summarization. Figure 3: Incorporating temporal information into the SWING summarization pipeline. Temporal Processing generates timelines from text, one for each input document. Timelines are well-understood constructs which have often been used to represent temporal information (Denis and Muller, 2011; Do et al., 2012). They indicate the temporal relationships between two basic temporal units: 1) events, and 2) time expressions (or timexes for short). In this work, we adopt the definitions proposed in the standardized TIMEML annotation (Pustejovsky et al., 2003a). An event refers to an eventuality, a situation that occurs or an action; while a timex is a reference to a particular date or time (e.g. “2013 December 31”). Following the “divide-and-conquer” approach described in Verhagen et al. (2010), results from the three temporal processing steps: 1) timex normalization, 2) event-timex temporal relationship classification, and 3) event-event temporal relationship classification, are merged to obtain timelines (top half of Figure 3). We tap on existing systems for each of these steps (Ng and Kan, 2012; Str¨otgen and Gertz, 2013; Ng et al., 2013). Sum</context>
</contexts>
<marker>Pustejovsky, Hanks, Sauri, See, Gaizauskas, Setzer, Radev, Sundheim, Day, Ferro, Lazo, 2003</marker>
<rawString>James Pustejovsky, Patrick Hanks, Roser Sauri, Andrew See, Robert Gaizauskas, Andrea Setzer, Dragomir Radev, Beth Sundheim, David Day, Lisa Ferro, and Marcia Lazo. 2003b. The TIMEBANK corpus. In Proceedings of Corpus Linguistics, pages 647–656, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jannik Str¨otgen</author>
<author>Michael Gertz</author>
</authors>
<title>Multilingual and Cross-domain Temporal Tagging. Language Resources and Evaluation,</title>
<date>2013</date>
<volume>47</volume>
<issue>2</issue>
<marker>Str¨otgen, Gertz, 2013</marker>
<rawString>Jannik Str¨otgen and Michael Gertz. 2013. Multilingual and Cross-domain Temporal Tagging. Language Resources and Evaluation, 47(2):269–298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naushad Uzzaman</author>
<author>Hector Llorens</author>
<author>Leon Derczynski</author>
<author>Marc Verhagen</author>
<author>James F Allen</author>
<author>James Pustejovsky</author>
</authors>
<title>SemEval-2013 Task 1: TEMPEVAL3: Evaluating Time Expressions, Events, and Temporal Relations.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval),</booktitle>
<contexts>
<context position="1776" citStr="Uzzaman et al., 2013" startWordPosition="255" endWordPosition="258">e input for summarization. By selectively using timelines guided by filtering, overall summarization performance is increased by a significant 5.9%. 1 Introduction There has been a good amount of research invested into improving the temporal interpretation of text. Besides the increasing availability of annotation standards (e.g., TIMEML (Pustejovsky et al., 2003a)) and corpora (e.g., TIDES (Ferro et al., 2000), TimeBank (Pustejovsky et al., 2003b)), the community has also organized three successful evaluation workshops — TempEval-1 (Verhagen et al., 2009), -2 (Verhagen et al., 2010), and -3 (Uzzaman et al., 2013). As the state-of-theart improves, these workshops have moved away from the piecemeal evaluation of individual temporal processing tasks and towards the evaluation of complete end-to-end systems in TempEval-3. We believe our understanding of the temporal information found in text is sufficiently robust, and that there is an opportunity to now leverage this information in downstream applications. In this paper, we present our work in incorporating the use of such temporal information into multi-document summarization. The goal of multi-document summarization is to generate a summary which inclu</context>
</contexts>
<marker>Uzzaman, Llorens, Derczynski, Verhagen, Allen, Pustejovsky, 2013</marker>
<rawString>Naushad Uzzaman, Hector Llorens, Leon Derczynski, Marc Verhagen, James F. Allen, and James Pustejovsky. 2013. SemEval-2013 Task 1: TEMPEVAL3: Evaluating Time Expressions, Events, and Temporal Relations. In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval), June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>Jessica Moszkowicz</author>
<author>James Pustejovsky</author>
</authors>
<title>The TempEval Challenge: Identifying Temporal Relations in Text. Language Resources and Evaluation,</title>
<date>2009</date>
<volume>43</volume>
<issue>2</issue>
<contexts>
<context position="1717" citStr="Verhagen et al., 2009" startWordPosition="243" endWordPosition="247"> generated by our automatic processes, to purify the timeline input for summarization. By selectively using timelines guided by filtering, overall summarization performance is increased by a significant 5.9%. 1 Introduction There has been a good amount of research invested into improving the temporal interpretation of text. Besides the increasing availability of annotation standards (e.g., TIMEML (Pustejovsky et al., 2003a)) and corpora (e.g., TIDES (Ferro et al., 2000), TimeBank (Pustejovsky et al., 2003b)), the community has also organized three successful evaluation workshops — TempEval-1 (Verhagen et al., 2009), -2 (Verhagen et al., 2010), and -3 (Uzzaman et al., 2013). As the state-of-theart improves, these workshops have moved away from the piecemeal evaluation of individual temporal processing tasks and towards the evaluation of complete end-to-end systems in TempEval-3. We believe our understanding of the temporal information found in text is sufficiently robust, and that there is an opportunity to now leverage this information in downstream applications. In this paper, we present our work in incorporating the use of such temporal information into multi-document summarization. The goal of multi-</context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Moszkowicz, Pustejovsky, 2009</marker>
<rawString>Marc Verhagen, Robert Gaizauskas, Frank Schilder, Mark Hepple, Jessica Moszkowicz, and James Pustejovsky. 2009. The TempEval Challenge: Identifying Temporal Relations in Text. Language Resources and Evaluation, 43(2):161–179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Roser Sauri</author>
<author>Tommaso Caselli</author>
<author>James Pustejovsky</author>
</authors>
<date>2010</date>
<booktitle>SemEval-2010 Task 13: TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval),</booktitle>
<pages>57--62</pages>
<contexts>
<context position="1745" citStr="Verhagen et al., 2010" startWordPosition="249" endWordPosition="252">processes, to purify the timeline input for summarization. By selectively using timelines guided by filtering, overall summarization performance is increased by a significant 5.9%. 1 Introduction There has been a good amount of research invested into improving the temporal interpretation of text. Besides the increasing availability of annotation standards (e.g., TIMEML (Pustejovsky et al., 2003a)) and corpora (e.g., TIDES (Ferro et al., 2000), TimeBank (Pustejovsky et al., 2003b)), the community has also organized three successful evaluation workshops — TempEval-1 (Verhagen et al., 2009), -2 (Verhagen et al., 2010), and -3 (Uzzaman et al., 2013). As the state-of-theart improves, these workshops have moved away from the piecemeal evaluation of individual temporal processing tasks and towards the evaluation of complete end-to-end systems in TempEval-3. We believe our understanding of the temporal information found in text is sufficiently robust, and that there is an opportunity to now leverage this information in downstream applications. In this paper, we present our work in incorporating the use of such temporal information into multi-document summarization. The goal of multi-document summarization is to</context>
<context position="10965" citStr="Verhagen et al. (2010)" startWordPosition="1746" endWordPosition="1749"> are well-understood constructs which have often been used to represent temporal information (Denis and Muller, 2011; Do et al., 2012). They indicate the temporal relationships between two basic temporal units: 1) events, and 2) time expressions (or timexes for short). In this work, we adopt the definitions proposed in the standardized TIMEML annotation (Pustejovsky et al., 2003a). An event refers to an eventuality, a situation that occurs or an action; while a timex is a reference to a particular date or time (e.g. “2013 December 31”). Following the “divide-and-conquer” approach described in Verhagen et al. (2010), results from the three temporal processing steps: 1) timex normalization, 2) event-timex temporal relationship classification, and 3) event-event temporal relationship classification, are merged to obtain timelines (top half of Figure 3). We tap on existing systems for each of these steps (Ng and Kan, 2012; Str¨otgen and Gertz, 2013; Ng et al., 2013). Summarization. We make use of a state-ofthe-art summarization system, SWING (Ng et al., 2012) (bottom half of Figure 3). SWING is a supervised, extractive summarization system which ranks sentences based on scores computed using a set of featur</context>
</contexts>
<marker>Verhagen, Sauri, Caselli, Pustejovsky, 2010</marker>
<rawString>Marc Verhagen, Roser Sauri, Tommaso Caselli, and James Pustejovsky. 2010. SemEval-2010 Task 13: TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval), pages 57–62, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojun Wan</author>
</authors>
<title>TimedTextRank: Adding the Temporal Dimension to Multi-Document Summarization.</title>
<date>2007</date>
<booktitle>In Proceedings of the 30th Annual International ACM Conference on Research and Development in Information Retrieval (SIGIR),</booktitle>
<pages>867--868</pages>
<contexts>
<context position="4955" citStr="Wan, 2007" startWordPosition="773" endWordPosition="774">d before the cyclone made landfall. (3) The storm matched one in 1991 that sparked a tidal wave that killed an estimated 138,000 people, Karmakar told AFP. Figure 1: Modified extract from a news article which describes a cyclone landfall. Several events which appear in Figure 2 are bolded. Storm in 1991 Latest cyclone Figure 2: Possible timeline for events in Figure 1. summarization, they 1) have been largely confined to helping to chronologically order content within summaries (Barzilay et al., 1999), or 2) focus only on the use of recency as an indicator of saliency (Goldstein et al., 2000; Wan, 2007). In this work we construct timelines (as a representation of temporal information) automatically and incorporate them into a state-of-the-art multidocument summarization system. This is achieved with 1) three novel features derived from timelines to help measure the saliency of sentences, as well as 2) TIMEMMR, a modification to the traditional Maximal Marginal Relevance (MMR) (Carbonell and Goldstein, 1998). TimeMMR promotes diversity by additionally considering temporal information instead of just lexical similarities. Through these, we demonstrate that temporal information is useful for mu</context>
<context position="6981" citStr="Wan (2007)" startWordPosition="1086" endWordPosition="1087">uristics, and also made use of lexical patterns to perform basic time normalization on terms like “today” relative to the document creation time. The induced ordering is used to present the selected summary content, following the chronological order in the original documents. In another line of work, Goldstein et al. (2000) made use of the temporal ordering of documents to be summarized. In computing the relevance of a passage for inclusion into the final summary, they considered the recency of the passage’s source document. Passages from more recent documents are deemed to be more important. Wan (2007) and Demartini et al. (2010) made similar assumptions in their work on TIMEDTEXTRANK and entity summarization, respectively. Instead of just considering the notion of recency, Liu et al. (2009) proposed an interesting approach using a temporal graph. Events within a document set correspond to vertices in their proposed graph, while edges are determined by the temporal ordering of events. From the resulting weakly-connected graph, the largest forests are assumed to contain key topics within the document set and used to influence a scoring mechanism which prefers sentences touching on these topi</context>
</contexts>
<marker>Wan, 2007</marker>
<rawString>Xiaojun Wan. 2007. TimedTextRank: Adding the Temporal Dimension to Multi-Document Summarization. In Proceedings of the 30th Annual International ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 867– 868, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mingli Wu</author>
</authors>
<title>Investigations on TemporalOriented Event-Based Extractive Summarization.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>Hong Kong Polytechnic University.</institution>
<contexts>
<context position="7594" citStr="Wu (2008)" startWordPosition="1184" endWordPosition="1185"> Demartini et al. (2010) made similar assumptions in their work on TIMEDTEXTRANK and entity summarization, respectively. Instead of just considering the notion of recency, Liu et al. (2009) proposed an interesting approach using a temporal graph. Events within a document set correspond to vertices in their proposed graph, while edges are determined by the temporal ordering of events. From the resulting weakly-connected graph, the largest forests are assumed to contain key topics within the document set and used to influence a scoring mechanism which prefers sentences touching on these topics. Wu (2008) also made use of the relative ordering of events. He assigned complete timestamps to events extracted from text. After laying out these events onto a timeline by making use of these timestamps, the number of events that happen within the same day is used to influence sentence scoring. The motivation behind this approach is that days which have a large number of events should be more important and more worthy of reporting than others. These prior works target either 1) sentence reordering, or 2) the use of recency as an indicator of saliency. In sentence re-ordering, final summaries are re-arr</context>
</contexts>
<marker>Wu, 2008</marker>
<rawString>Mingli Wu. 2008. Investigations on TemporalOriented Event-Based Extractive Summarization. Ph.D. thesis, Hong Kong Polytechnic University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shasha Xie</author>
<author>Yang Liu</author>
</authors>
<title>Using Corpus and Knowledge-based Similarity Measure in Maximum Marginal Relevance for Meeting Summarization.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP),</booktitle>
<pages>4985--4988</pages>
<contexts>
<context position="20817" citStr="Xie and Liu (2008)" startWordPosition="3498" endWordPosition="3501">e other happens in. For example, an event that takes place in “2014 June” is said to take place within the year “2014”. While TIMEMMR is proposed here as an improvement over MMR, the premise is that incorporating temporal information can be helpful to minimize redundancy in summaries. In future work, one could apply it to other state-of-the-art lexical-based approaches including that of Hendrickx et al. (2009) and Celikyilmaz and HakkaniTur (2010). We also believe the same idea can be transplanted even to non-lexical motivated techniques such as the corpus-based similarity measure proposed by Xie and Liu (2008). We chose to use MMR here as a proof-of-concept to demonstrate the viability of such a technique, and to easily integrate our work into SWING. 3.4 Gauging Usefulness of Timelines Temporal processing is imperfect. Together with the simplifying assumptions that were made in timeline construction, our generated timelines have errors which propagate into the summarization process. With this in mind, we selectively employ timelines to generate summaries only when we are confident of their accuracy. This can be done by computing a metric which can be used to decide whether or not timelines should b</context>
</contexts>
<marker>Xie, Liu, 2008</marker>
<rawString>Shasha Xie and Yang Liu. 2008. Using Corpus and Knowledge-based Similarity Measure in Maximum Marginal Relevance for Meeting Summarization. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP), pages 4985–4988, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Renxian Zhang</author>
<author>You Ouyang</author>
<author>Wenjie Li</author>
</authors>
<title>Guided Summarization with Aspect Recognition.</title>
<date>2011</date>
<booktitle>In Proceedings of the Text Analysis Conference (TAC),</booktitle>
<contexts>
<context position="23750" citStr="Zhang et al., 2011" startWordPosition="3977" endWordPosition="3980">, we employ only the three generic features, i.e., 1) sentence position, 2) sentence length, and 3) interpolated n-gram document frequency in our experiments below. Summarization evaluation is done using ROUGE-2 (R-2) (Lin and Hovy, 2003), as it has previously been shown to correlate well with human assessment (Lin, 2004) and is often used to evaluate automatic text summarization. The results obtained are shown in Table 1. In the table, each row refers to a specific summarization system configuration. We also show the results of two reference systems, CLASSY (Conroy et al., 2011) and POLYCOM (Zhang et al., 2011), as benchmarks. CLASSY and POLYCOM are top performing systems at TAC-2011 (ranked 2nd and 3rd by R-2 in TAC 2011, respectively; the full version of SWING was ranked 1st with a R-2 score of 0.1380). From these results, we can see that SWING is a very competitive baseline. Rows 9 to 16 additionally incorporate our timeline reliability filtering. We assume that the various input document sets to be summarized are available at the time of processing. Hence in these experiments, the threshold for filtering is set to be the average of all the timeline sizes over the whole input dataset. In a produc</context>
</contexts>
<marker>Zhang, Ouyang, Li, 2011</marker>
<rawString>Renxian Zhang, You Ouyang, and Wenjie Li. 2011. Guided Summarization with Aspect Recognition. In Proceedings of the Text Analysis Conference (TAC), November.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>