<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000331">
<title confidence="0.92092">
Text and Knowledge Mining for Coreference Resolution
</title>
<author confidence="0.995549">
Sanda M. Harabagiu, Razvan C. Bunescu and Steven J. Maiorano
</author>
<affiliation confidence="0.8483765">
Department of Computer Science and Engineering
Southern Methodist University
</affiliation>
<address confidence="0.780073">
Dallas, TX 75275-0122
</address>
<email confidence="0.996127">
Isanda,razvan,stevel@renoinseas.smu.edu
</email>
<sectionHeader confidence="0.979822" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999834">
Traditionally coreference is resolved by satisfy-
ing a combination of salience, syntactic, seman-
tic and discourse constraints. The acquisition of
such knowledge is time-consuming, difficult and
error-prone. Therefore, we present a knowledge-
minimalist methodology of mining coreference rules
from annotated text corpora. Semantic consistency
evidence, which is a form of knowledge required by
coreference, is easily retrieved from WordNet. Ad-
ditional consistency knowledge is discovered by a
meta-bootstrapping algorithm applied to unlabeled
texts.
</bodyText>
<sectionHeader confidence="0.955088" genericHeader="keywords">
1 Background
</sectionHeader>
<bodyText confidence="0.999957803030303">
Reference resolution is an important task for dis-
course or dialogue processing systems since iden-
tity relations between anaphoric textual entities and
their antecedents is a prerequisite to the understand-
ing of text or conversation. Traditionally, coref-
erence resolution has been performed by combin-
ing linguistic and cognitive knowledge of language.
Linguistic information is provided mostly by syn-
tactic and semantic modeling of language whereas
cognitive information is incorporated in computa-
tional models of discourse. Computational meth-
ods based on linguistic and congitive information
were presented in (Hobbs 1978), (Lappin and Le-
ass 1994), (Brennan et al.1987), (Grosz et al.1995)
and (Webber 1988). The acquisition of exten-
sive linguistic and discourse knowledge necessary
for resolving coreference is time consuming, diffi-
cult and error-prone. Neverthless, recent results
show that knowledge-poor, empirical methods per-
form with amazing accuracy on certain forms of
coreference (cf. (Mitkov 1998) (Kennedy and Bogu-
raev 1996) (Kameyama 1997)). For example, COG-
NIAC (Baldwin 1997), a system based on just seven
ordered heuristics, generates high-precision resolu-
tion (over 90%) for some cases of pronominal refer-
ence.
In our work, we approached the coreference res-
olution problem by trying to determine how much
more knowledge is required to supplement the above-
mentioned knowledge-poor methods and how to de-
rive that knowledge. To this end we (1) analyze
the data to find what types of anaphor-antecedent
pairs are most popular in real-world texts; (2) devise
knowledge-minimalist rules for handling the major-
ity of those popular cases; and (3) discover what
supplementary knowledge is needed for remaining,
more difficult cases.
To analyze coreference data we use a corpus of
annotated texts. To devise minimalist coreference
resolution rules we consider (1) strong indicators of
cohesion, such as repetitions, name aliases or apposi-
tions; and (2) gender, number and class agreements.
WordNet (Miller 1995), the vast semantic knowledge
base, provides suplementary knowledge in the form
of semantic consistency between coreferring nouns.
Additional semantic consistency knowledge is gener-
ated by a bootstrapping mechanism when our corefer-
ence resolution system, COCKTAIL&apos;, processes new
texts. This bootstrapping mechanism inspired by
the technique presented in (Riloff and Jones 1999)
targets one of the most problematic forms of knowl-
edge needed for coreference resolution: the semantic
consistency of corefering nominals.
The rest of the paper is organized as follows.
Section 2 discusses our text mining methodology
for analysing the data and devising knowledge-
minimalist rules for resolving the most popular
coreference cases. Section 3 presents the knowledge-
mining components of COCKTAIL that use WordNet
for deriving semantic consistency as well as gender
information. Section 4 presents an entropy-based
method for optimally combining coreference rules
and Section 5 presents the bootstrapping mecha-
nism. Section 6 reports and discusses the experi-
mental results while Section 7 summarizes the con-
clusions.
</bodyText>
<footnote confidence="0.476493">
&apos;COCKTAIL iS a pun on CoGNIAC, because COCKTAIL uses
multiple coreference resolution rules corresponding to differ-
ent forms of coreference, blended together in a single system.
</footnote>
<figure confidence="0.987186418181818">
Bill Clinton
Bill Clinton
Bill Clinton
his
his
his
he
he
he
his
his Clinton
his Clinton
Clinton
(a) (b) (c)
LEGEND:
Original Annotation AutoTag-Coref Annotation
E1
E1
E1
E2
R1
E2
apposition
E2
apposition
apposition
E3
E3
E3
(b)
(a)
(c)
E4
E4
E4
E5
E5
E5
R2
E6
E6
E6
RULE-1-Filter-1-Pronoun (R1F1Pron)
If (( Syntactic_Category(Anaphor)== Pronoun) AND oRepetition (Anaphor, Antecedent) )
then Cast_in_Chain(Antecedent, Anaphor)
RULE-1-Filter-1-Nominal (R1F1Nom)
If (( Syntactic_Category(Anaphor)== Common Noun) AND o(Anaphor == Apposition(Antecedent) )
then Cast_in_Chain(Antecedent, Anaphor)
RULE-2-Filter-1-Nominal (R2F1Nom)
If (( Syntactic_Category(Anaphor)== oSyntactic_Category(Antecedent)==Proper Noun) AND oSame-Category(Antecedent,Anaphor) )
If ( Category(Anaphor) == PERSON) AND ( []Last_Name(Antecedent)==Last_Name(Anaphor) ) AND
AND (Gender(Antecedent) = Gender(Anaphor) AND []Surface_Distance(Anaphor,Antecedent)=min)
then Cast_in_Chain(Antecedent, Anaphor)
If ( Category(Anaphor) == ORGANIZATION) AND []Acronym(Anaphor,Antecedent))
then Cast_in_Chain(Antecedent, Anaphor)
</figure>
<bodyText confidence="0.906667">
of a nominal, or a disjunct of two or three of them,
as illustrated in Table 2. The gender attributes may
have the values:
</bodyText>
<listItem confidence="0.9891355">
• m for masculine nouns;
• f for feminine nouns; and
• n for all the nouns that either are not from the
PERSON category or are polysemous&apos; and at least
one of the senses does not belong to the PERSON
category.
</listItem>
<table confidence="0.993075142857143">
G Noun examples #
m V f V n client, leader, neighbour 807
m V f lawyer, loser, patron, newborn 5217
m V n king, antique, father 42
f V n maiden, mezzo, nanny, harpy 81
m groom, housefather, nobleman 208
f woman, daughter, bride, sheika 417
</table>
<tableCaption confidence="0.9966">
Table 2: Distribution of gender information.
</tableCaption>
<bodyText confidence="0.878985574999999">
Gender attributes are assigned by the two follow-
ing heuristics:
Heuristic 1 If a collocation fom a WordNet synset
contains the word male, the expression G for the
whole sysnet is m. If the collocation contains the
words female or woman, G= f .
Heuristic 2 Consider the first four words from the
synset gloss. If any of the gloss words have been as-
signed gender information, propagate the same in-
formation to the defined synset as well.
Each hyponym of the concept {person, individual,
human}, categorized as PERSON has expression G
initialized to f V m, since all lexemes represent per-
sons, that can be either males or females. Whenever
one of the two heuristics previously defined can be
applied at any node S from this subhierarchy, three
operations take place:
t&gt; Operation 1: We update G with the new expres-
sion brough forward by the heuristic.
t&gt; Operation 2: We propagate all the expression to
the hyponyms of S;
t&gt; Operation 3: We revisit the whole PERSON sub-
hierarchy, in search for concepts D that are defined
with glosses that use any of the words from synset
S or any word from any of its hyponyms. Whenever
we find such a word, we update its G expression
to G(S). We also note that many words are polyse-
mous, thus a word w may have multiple senses under
the PERSON sub-hierarchy and moreover, each sense
might have a different G expression. In this case, all
words from the synsets containing w receive the dis-
junct of the gender attributes corresponding to each
sense of w.
Mining semantic information from WordNet
We used the WordNet knowledge base to mine pat-
terns of WordNet paths that connect pairs of core-
ferring nouns from the annotated chains. The paths
are combinations of any of the following WordNet
6A polysemous noun has multiple semantic senses and
therefore has multiple entries in the WordNet dictionary.
</bodyText>
<listItem confidence="0.972421333333333">
relations:
• SYNONYM connecting all elements of a synset;
• IS-A connecting nouns and verbs from the same
hierarchies. We also consider the reversed IS-A re-
lation, denote RIs-A;
• GLOSS connecting any element of a synset with
the genus of its glossed definition. We also consider
its reverse relation, named DEFINES;
• IN-GLOSS connecting any element of a synset with
one of the first four words of its glossed definition.
We also consider its reversed relation, named IN-
DEFINITION
• HAS-PART connecting a concept to its meronyms.
We also consider the reversed IS-PART relation;
• MORPHO-DERIVATION connecting a word to its
morphological derivations.
• COLLIDE-SENSE connecting several senses of the
same word.
</listItem>
<bodyText confidence="0.99927464">
To determine the confidence of the path we con-
sider three factors:
*Factor fi has only two values. It is set to 1 when
another coreference chain contains elements in the
same NPs as the anaphor and the anetcedent. For
example, if NPi is &amp;quot;the professor&apos;s son&amp;quot; and NP2
is &amp;quot;his father&amp;quot;, the semantic consistency between fa-
ther and professor is more likely, given that his and
son corefer. Otherwise, fi is set to 0.
*Factor f2 favors (a) relations that are consid-
ered &amp;quot;stronger&amp;quot; (e.g. SYNONYMY, GLOSS); and
(b) shorter paths. For this purpose we assign
the following weights to each relation considered:
W(SYNONYM) = 1.0; w(IS-A) = 0.9; w(GLoss) =
0.9; w(IN-GLoss) = 0.3; w(HAs-PART) = 0.7;
w(MoRPHo-DERIVATION) = 0.6; and W(COLLIDE-
SENSE) = 0.5. When computing the f2 factor, we
assume that whenever at least two relations of the
same kind repeat, we should consider the sequence
of relations equivalent to a single relation, having
the weight devided by the length of the sequence. If
we denote by rir„i the number of different relation
types encountered in a path, and rirsame(rel) de-
notes the number of links of type rel in a sequence,
then we define f2 with the formula:
</bodyText>
<equation confidence="0.944176666666667">
1 w(rel)
f2 — E
nrrel relEPath nrsame(rel)
</equation>
<bodyText confidence="0.464284636363636">
*Factor h is a semantic measure operating on a con-
ceptual space. When searching for a lexico-semantic
path, a search space SS is created, which contains
all WordNet content words that can be reached from
the candidate antecedent or the anaphor in at most
five combinations of the seven relations used by the
third filter. We denote by N the total number of
nouns and verbs in the search space. C represents
the number of nouns and verbs that can be reached
by both nominals. In addition rirtotal is the num-
ber of concepts along all paths established, whereas
</bodyText>
<figure confidence="0.98807264">
rel(p+)
1
0.5
0
-0.5
-1
0 0.5 1
R3
B
A
R2
CN1
CN2
R1
CN1
New semantic consistency
path = New coreference rule
Semantic consistency Path:
Mropho-Derivation : Is-A : Collide-Sense
Coreference Rule:
If (x is Morpho-Derivation ( Anaphor) ) AND
AND (y is one of the hypernyms of x) AND
AND (z is SYNONYM of y) AND
AND (z is SYNONYM of anaphor)
then Cast_in_Chain(Anaphor,antecedent)
</figure>
<bodyText confidence="0.999630615384615">
(Riloff and Jones 1999) note that the performance
of the mutual bootstrapping algorithm can deterio-
rate rapidly if erroneous rules are entered. To make
the algorithm more robust we use the same solu-
tion by introducing a second level of bootrapping.
The outer level, called meta-bootstrapping identifies
the most reliable k rules based on semantic consis-
tency and discard all the others before restarting
the mutual bootstrapping loop again. In our experi-
ments we have retained only those rules for which the
new performance, given by the F-measure was larger
than the median of the past four loops. The for-
mula for the van Rijsbergen&apos;s F-measure combines
</bodyText>
<equation confidence="0.35779">
2 xpP±XRR
</equation>
<bodyText confidence="0.916624">
the precision P with the recall R in F =
</bodyText>
<sectionHeader confidence="0.996597" genericHeader="introduction">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.99909475">
To measure the performance of COCKTAIL we have
trained the system on 30 MUC-6 and MUC-7 texts
and tested it on the remaining 30 documents.
We computed the precision, the recall and the F-
measure. The performance measures have been ob-
tained automatically using the MUC-6 coreference
scoring program (Vilain et al. 1995). Table 4 lists
the results.
</bodyText>
<table confidence="0.999801571428572">
Precision Recall F-measure
COCKTAIL 87.1% 61.7% 72.3%
rules
COCKTAIL 91.3% 58.6% 71.8%
rules combined
COCKTAIL 92.0% 73.9% 81.9%
+bootstrapping
</table>
<tableCaption confidence="0.999928">
Table 4: Bootstrapping effect on COCKTAIL
</tableCaption>
<bodyText confidence="0.890096777777778">
Table 4 shows that the seed set of rules had good pre-
cision but poor recall. By combining the rules with the
entropy-based measure, we obtained further enhance-
ment in precision, but the recall dropped. The appli-
cation of the bootstrapping methodology determined an
enhancement of recall, and thus of the F-measure. In the
future we intend to compare the overall effect of rules
that recognize referential expressions on the overall per-
formance of the system.
</bodyText>
<sectionHeader confidence="0.998809" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.998924363636364">
We have introduced a new data-driven method for coref-
erence resolution, implemented in the COCKTAIL sys-
tem. Unlike other knowledge-poor methods for coref-
erence resolution (Baldwin 1997) (Mitkov 1998), COCK-
TAIL filters its most performant rules through massive
training data, generated by its AUTOTAG-COFtEF com-
ponent. Furthermore, by using an entropy-based method
we determine the best partition of corefering expressions
in coreference chains. New rules are learned by applying
a bootstrapping methodology that uncovers additional
semantic consistency data.
</bodyText>
<sectionHeader confidence="0.998232" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999619637931035">
Breck Baldwin. 1997. CogNIAC: high precision corefer-
ence with limited knowledge and linguistic resources.
In Proceedings of the ACL&apos;97/EACL&apos;97 Workshop on
Operational factors in practical, robust anaphora res-
olution, pages 38-45, Madrid, Spain.
Susan E. Brennan, Marilyn Walker Friedman and Carl
J. Pollard. 1987. A centering approach to pronouns.
In Proceedings of ACL-87, pages 155-162.
Claire Cardie and Kiri Wagstaff. 1999. Noun phrase
coreference as clustering. In Proceedings of the Joint
Conference on Empirical Methods in NLP and Very
Large Corpora, pages 82-89.
Barbara J. Grosz, Aravind K. Joshi and Scott Weinstein.
1995. Centering: A Framework for Modeling the Local
Coherence of Discourse. Computational Linguistics,
21(2).
Lynette Hirshman, Patricia Robinson, John Burger and
Marc Vilain. 1998. The role of Annotated Training
Data. Unpublished manuscript.
Jerry R. Hobbs. 1978. Resolving pronoun references.
Lingua, 44:311-338.
Shalom Lappin and Herbert Leass. 1994. An algorithm
for pronominal anaphora resolution. Computational
Linguistics, 20(4):535-562.
Megumi Kameyama. 1997. Recognizing Referential
Links: An Information Extraction Perspective. In
Proceedings of the A CL &apos;97/EA CL &apos;97 Workshop on
Operational factors in practical, robust anaphora res-
olution, pages 46-53, Madrid, Spain.
Christopher Kennedy and Branimir Bogureav. 1996.
Anaphora for everyone: Pronominal anaphora resolu-
tion without a parser. In Proceedings of COLING-96.
George A. Miller. 1995. WordNet: A Lexical Database.
Communication of the ACM, 38(11):39-41.
Ruslan Mitkov. 1998. Robust pronoun resolution
with limited knowledge. In Proceedings of COLING-
ACL &apos;98, pages 869-875.
Ellen Riloff. 1996. Automatically Generating Extrac-
tion Patterns from Untagged Text. In Proceedings of
AAAI-96, pages 1044-1049, Portland, OR, July.
Ellen Riloff and Rosie Jones. 1999. Learning Dictionar-
ies for Information Extraction by Multi-Level Boot-
strapping. In Proceedings of AAAI-99.
Gerald Salton and Chris Buckley. 1988. Term-weighting
approaches in automatic retrieval. Information Pro-
cessing and Management, 24(5):513-523.
Marc Vilain, John Burger, John Aberdeen, Dan Con-
nolly and Lynette Hirshman. 1995. A model-theoretic
coreference scoring scheme. Proceedings of MUC-6,
Morgan Kaufmann, San Mateo, CA.
C.J. van Rijsbergen. 1979. Information Retrieval. But-
terworths, Glasgow, UK.
Bonnie Webber. Discourse deixis: Reference to discourse
segments. In Proceedings of ACL-88, pages 113-121.
Janyce M. Wiebe, Rebecca F. Bruce and Thomas P.
O&apos;Hara. 1999. Development and use of a gold-
standard data set for subjectivity classifications. In
Proceedings of ACL-99, pages 246-253.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.999771">Text and Knowledge Mining for Coreference Resolution</title>
<author confidence="0.998208">M Harabagiu</author>
<author confidence="0.998208">Razvan C Bunescu J</author>
<affiliation confidence="0.8922805">Department of Computer Science and Southern Methodist</affiliation>
<author confidence="0.451541">TX Dallas</author>
<email confidence="0.931998">Isanda,razvan,stevel@renoinseas.smu.edu</email>
<abstract confidence="0.997989204819277">Traditionally coreference is resolved by satisfying a combination of salience, syntactic, semantic and discourse constraints. The acquisition of such knowledge is time-consuming, difficult and error-prone. Therefore, we present a knowledgeminimalist methodology of mining coreference rules from annotated text corpora. Semantic consistency evidence, which is a form of knowledge required by coreference, is easily retrieved from WordNet. Additional consistency knowledge is discovered by a applied to unlabeled texts. 1 Background Reference resolution is an important task for disor dialogue processing systems since idenbetween anaphoric textual entities and their antecedents is a prerequisite to the understanding of text or conversation. Traditionally, coreference resolution has been performed by combining linguistic and cognitive knowledge of language. Linguistic information is provided mostly by syntactic and semantic modeling of language whereas cognitive information is incorporated in computational models of discourse. Computational methods based on linguistic and congitive information were presented in (Hobbs 1978), (Lappin and Leass 1994), (Brennan et al.1987), (Grosz et al.1995) and (Webber 1988). The acquisition of extensive linguistic and discourse knowledge necessary for resolving coreference is time consuming, difficult and error-prone. Neverthless, recent results show that knowledge-poor, empirical methods perform with amazing accuracy on certain forms of coreference (cf. (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)). For example, COG- NIAC (Baldwin 1997), a system based on just seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal reference. In our work, we approached the coreference resolution problem by trying to determine how much more knowledge is required to supplement the abovementioned knowledge-poor methods and how to derive that knowledge. To this end we (1) analyze the data to find what types of anaphor-antecedent pairs are most popular in real-world texts; (2) devise knowledge-minimalist rules for handling the majority of those popular cases; and (3) discover what supplementary knowledge is needed for remaining, more difficult cases. To analyze coreference data we use a corpus of annotated texts. To devise minimalist coreference resolution rules we consider (1) strong indicators of cohesion, such as repetitions, name aliases or appositions; and (2) gender, number and class agreements. WordNet (Miller 1995), the vast semantic knowledge base, provides suplementary knowledge in the form of semantic consistency between coreferring nouns. Additional semantic consistency knowledge is generby a when our coreference resolution system, COCKTAIL&apos;, processes new texts. This bootstrapping mechanism inspired by the technique presented in (Riloff and Jones 1999) targets one of the most problematic forms of knowledge needed for coreference resolution: the semantic consistency of corefering nominals. The rest of the paper is organized as follows. Section 2 discusses our text mining methodology for analysing the data and devising knowledgeminimalist rules for resolving the most popular coreference cases. Section 3 presents the knowledgemining components of COCKTAIL that use WordNet for deriving semantic consistency as well as gender information. Section 4 presents an entropy-based method for optimally combining coreference rules and Section 5 presents the bootstrapping mechanism. Section 6 reports and discusses the experimental results while Section 7 summarizes the conclusions. pun on CoGNIAC, because COCKTAIL uses multiple coreference resolution rules corresponding to different forms of coreference, blended together in a single system.</abstract>
<author confidence="0.987612333333333">Bill Clinton Bill Clinton Bill Clinton</author>
<abstract confidence="0.922255222222222">his his his he he he his his Clinton his Clinton</abstract>
<note confidence="0.756910023255814">Clinton (a) (b) (c) LEGEND: Original Annotation AutoTag-Coref Annotation E1 E1 E1 E2 R1 E2 apposition E2 apposition apposition E3 E3 E3 (b) (a) (c) E4 E4 E4 E5 E5 E5 R2 E6 E6 E6 RULE-1-Filter-1-Pronoun (R1F1Pron) If (( Syntactic_Category(Anaphor)== Pronoun) AND oRepetition (Anaphor, Antecedent) ) then Cast_in_Chain(Antecedent, Anaphor) RULE-1-Filter-1-Nominal (R1F1Nom) If (( Syntactic_Category(Anaphor)== Common Noun) AND o(Anaphor == Apposition(Antecedent) ) then Cast_in_Chain(Antecedent, Anaphor) RULE-2-Filter-1-Nominal (R2F1Nom) If (( Syntactic_Category(Anaphor)== oSyntactic_Category(Antecedent)==Proper Noun) AND oSame-Category(Antecedent,Anaphor) ) If ( Category(Anaphor) == PERSON) AND ( []Last_Name(Antecedent)==Last_Name(Anaphor) ) AND AND (Gender(Antecedent) = Gender(Anaphor) AND []Surface_Distance(Anaphor,Antecedent)=min) then Cast_in_Chain(Antecedent, Anaphor) If ( Category(Anaphor) == ORGANIZATION) AND []Acronym(Anaphor,Antecedent)) then Cast_in_Chain(Antecedent, Anaphor)</note>
<abstract confidence="0.998890695652174">of a nominal, or a disjunct of two or three of them, as illustrated in Table 2. The gender attributes may have the values: • m for masculine nouns; f feminine nouns; and • n for all the nouns that either are not from the PERSON category or are polysemous&apos; and at least one of the senses does not belong to the PERSON category. G Noun examples # V n client, leader, neighbour 807 V lawyer, loser, patron, newborn 5217 m V n king, antique, father 42 n maiden, mezzo, nanny, harpy 81 m groom, housefather, nobleman 208 f woman, daughter, bride, sheika 417 Table 2: Distribution of gender information. Gender attributes are assigned by the two following heuristics: 1If a collocation fom a WordNet synset the word expression the whole sysnet is m. If the collocation contains the G= f . 2Consider the first four words from the synset gloss. If any of the gloss words have been assigned gender information, propagate the same information to the defined synset as well. hyponym of the concept individual, as PERSON has expression to V since all lexemes represent persons, that can be either males or females. Whenever one of the two heuristics previously defined can be at any node this subhierarchy, three operations take place: Operation 1: update the new expression brough forward by the heuristic. Operation 2: propagate all the expression to hyponyms of Operation 3: revisit the whole PERSON subin search for concepts are defined with glosses that use any of the words from synset any word from any of its hyponyms. Whenever find such a word, we update its also note that many words are polysemous, thus a word w may have multiple senses under the PERSON sub-hierarchy and moreover, each sense have a different In this case, all words from the synsets containing w receive the disjunct of the gender attributes corresponding to each sense of w. Mining semantic information from WordNet used the WordNet knowledge base to mine patof WordNet paths connect pairs of coreferring nouns from the annotated chains. The paths are combinations of any of the following WordNet polysemous noun has multiple semantic senses and therefore has multiple entries in the WordNet dictionary. relations: • SYNONYM connecting all elements of a synset; • IS-A connecting nouns and verbs from the same hierarchies. We also consider the reversed IS-A relation, denote RIs-A; • GLOSS connecting any element of a synset with the genus of its glossed definition. We also consider its reverse relation, named DEFINES; • IN-GLOSS connecting any element of a synset with one of the first four words of its glossed definition. We also consider its reversed relation, named IN- DEFINITION • HAS-PART connecting a concept to its meronyms. We also consider the reversed IS-PART relation; • MORPHO-DERIVATION connecting a word to its morphological derivations. • COLLIDE-SENSE connecting several senses of the same word. determine the the path we consider three factors: has only two values. It is set to 1 when another coreference chain contains elements in the same NPs as the anaphor and the anetcedent. For if is professor&apos;s son&amp;quot; &amp;quot;his father&amp;quot;, semantic consistency between famore likely, given that Otherwise, is set to 0. *Factorfavors (a) relations that are considered &amp;quot;stronger&amp;quot; (e.g. SYNONYMY, GLOSS); and (b) shorter paths. For this purpose we assign the following weights to each relation considered: W(SYNONYM) = 1.0; w(IS-A) = 0.9; w(GLoss) = 0.9; w(IN-GLoss) = 0.3; w(HAs-PART) = 0.7; w(MoRPHo-DERIVATION) = 0.6; and W(COLLIDE- = 0.5. When computing the factor, we assume that whenever at least two relations of the same kind repeat, we should consider the sequence of relations equivalent to a single relation, having the weight devided by the length of the sequence. If denote by number of different relation encountered in a path, and dethe number of links of type a sequence, we define with the formula: 1 w(rel) — relEPathnrsame(rel) his a semantic measure operating on a conceptual space. When searching for a lexico-semantic a search space created, which contains all WordNet content words that can be reached from the candidate antecedent or the anaphor in at most five combinations of the seven relations used by the filter. We denote by total number of and verbs in the search space. the number of nouns and verbs that can be reached both nominals. In addition rirtotalis the number of concepts along all paths established, whereas rel(p+)</abstract>
<note confidence="0.7059308125">1 0.5 0 -0.5 -1 0 0.5 1 R3 B A R2 CN1 CN2 R1 CN1 New semantic consistency path = New coreference rule</note>
<title confidence="0.832019">Semantic consistency Path: Mropho-Derivation : Is-A : Collide-Sense Coreference Rule: If (x is Morpho-Derivation ( Anaphor) ) AND</title>
<abstract confidence="0.981583892857143">AND (y is one of the hypernyms of x) AND AND (z is SYNONYM of y) AND AND (z is SYNONYM of anaphor) then Cast_in_Chain(Anaphor,antecedent) (Riloff and Jones 1999) note that the performance of the mutual bootstrapping algorithm can deteriorate rapidly if erroneous rules are entered. To make the algorithm more robust we use the same solution by introducing a second level of bootrapping. outer level, called most reliable based on semantic consistency and discard all the others before restarting the mutual bootstrapping loop again. In our experiments we have retained only those rules for which the new performance, given by the F-measure was larger than the median of the past four loops. The formula for the van Rijsbergen&apos;s F-measure combines precision the recall = 6 Evaluation To measure the performance of COCKTAIL we have trained the system on 30 MUC-6 and MUC-7 texts and tested it on the remaining 30 documents. computed the the Fperformance measures have been obtained automatically using the MUC-6 coreference scoring program (Vilain et al. 1995). Table 4 lists the results. Precision Recall F-measure rules 87.1% 61.7% 72.3% rules combined 91.3% 58.6% 71.8% +bootstrapping 92.0% 73.9% 81.9% Table 4: Bootstrapping effect on COCKTAIL Table 4 shows that the seed set of rules had good precision but poor recall. By combining the rules with the entropy-based measure, we obtained further enhancement in precision, but the recall dropped. The application of the bootstrapping methodology determined an enhancement of recall, and thus of the F-measure. In the future we intend to compare the overall effect of rules that recognize referential expressions on the overall performance of the system. 7 Conclusion We have introduced a new data-driven method for corefresolution, implemented in the system. Unlike other knowledge-poor methods for corefresolution (Baldwin 1997) (Mitkov 1998), COCKits most performant rules through massive data, generated by its component. Furthermore, by using an entropy-based method we determine the best partition of corefering expressions chains. rules are learned by applying a bootstrapping methodology that uncovers additional semantic consistency data. References Breck Baldwin. 1997. CogNIAC: high precision coreference with limited knowledge and linguistic resources.</abstract>
<note confidence="0.881067731707317">of the ACL&apos;97/EACL&apos;97 Workshop on Operational factors in practical, robust anaphora res- 38-45, Madrid, Spain. Susan E. Brennan, Marilyn Walker Friedman and Carl J. Pollard. 1987. A centering approach to pronouns. of Claire Cardie and Kiri Wagstaff. 1999. Noun phrase as clustering. In of the Joint Conference on Empirical Methods in NLP and Very Corpora, Barbara J. Grosz, Aravind K. Joshi and Scott Weinstein. 1995. Centering: A Framework for Modeling the Local of Discourse. Linguistics, 21(2). Lynette Hirshman, Patricia Robinson, John Burger and Marc Vilain. 1998. The role of Annotated Training Data. Unpublished manuscript. Jerry R. Hobbs. 1978. Resolving pronoun references. Shalom Lappin and Herbert Leass. 1994. An algorithm pronominal anaphora resolution. Megumi Kameyama. 1997. Recognizing Referential Links: An Information Extraction Perspective. In Proceedings of the A CL &apos;97/EA CL &apos;97 Workshop on Operational factors in practical, robust anaphora res- 46-53, Madrid, Spain. Christopher Kennedy and Branimir Bogureav. 1996. Anaphora for everyone: Pronominal anaphora resoluwithout a parser. In of George A. Miller. 1995. WordNet: A Lexical Database. of the ACM, Ruslan Mitkov. 1998. Robust pronoun resolution limited knowledge. In of COLING- &apos;98, 869-875. Ellen Riloff. 1996. Automatically Generating Extrac- Patterns from Untagged Text. In of 1044-1049, Portland, OR, July. Ellen Riloff and Rosie Jones. 1999. Learning Dictionaries for Information Extraction by Multi-Level Boot- In of Gerald Salton and Chris Buckley. 1988. Term-weighting in automatic retrieval. Pro-</note>
<title confidence="0.508332">and Management,</title>
<author confidence="0.841887">Marc Vilain</author>
<author confidence="0.841887">John Burger</author>
<author confidence="0.841887">John Aberdeen</author>
<author confidence="0.841887">Dan Con-</author>
<note confidence="0.858519545454546">nolly and Lynette Hirshman. 1995. A model-theoretic scoring scheme. of Morgan Kaufmann, San Mateo, CA. van Rijsbergen. 1979. Retrieval. Butterworths, Glasgow, UK. Bonnie Webber. Discourse deixis: Reference to discourse In of 113-121. Janyce M. Wiebe, Rebecca F. Bruce and Thomas P. O&apos;Hara. 1999. Development and use of a goldstandard data set for subjectivity classifications. In of ACL-99,</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Breck Baldwin</author>
</authors>
<title>CogNIAC: high precision coreference with limited knowledge and linguistic resources.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL&apos;97/EACL&apos;97 Workshop on Operational factors in practical, robust anaphora resolution,</booktitle>
<pages>38--45</pages>
<location>Madrid,</location>
<contexts>
<context position="1911" citStr="Baldwin 1997" startWordPosition="261" endWordPosition="262">orporated in computational models of discourse. Computational methods based on linguistic and congitive information were presented in (Hobbs 1978), (Lappin and Leass 1994), (Brennan et al.1987), (Grosz et al.1995) and (Webber 1988). The acquisition of extensive linguistic and discourse knowledge necessary for resolving coreference is time consuming, difficult and error-prone. Neverthless, recent results show that knowledge-poor, empirical methods perform with amazing accuracy on certain forms of coreference (cf. (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)). For example, COGNIAC (Baldwin 1997), a system based on just seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal reference. In our work, we approached the coreference resolution problem by trying to determine how much more knowledge is required to supplement the abovementioned knowledge-poor methods and how to derive that knowledge. To this end we (1) analyze the data to find what types of anaphor-antecedent pairs are most popular in real-world texts; (2) devise knowledge-minimalist rules for handling the majority of those popular cases; and (3) discover what supplementary knowle</context>
</contexts>
<marker>Baldwin, 1997</marker>
<rawString>Breck Baldwin. 1997. CogNIAC: high precision coreference with limited knowledge and linguistic resources. In Proceedings of the ACL&apos;97/EACL&apos;97 Workshop on Operational factors in practical, robust anaphora resolution, pages 38-45, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan E Brennan</author>
<author>Marilyn Walker Friedman</author>
<author>Carl J Pollard</author>
</authors>
<title>A centering approach to pronouns.</title>
<date>1987</date>
<booktitle>In Proceedings of ACL-87,</booktitle>
<pages>155--162</pages>
<marker>Brennan, Friedman, Pollard, 1987</marker>
<rawString>Susan E. Brennan, Marilyn Walker Friedman and Carl J. Pollard. 1987. A centering approach to pronouns. In Proceedings of ACL-87, pages 155-162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Cardie</author>
<author>Kiri Wagstaff</author>
</authors>
<title>Noun phrase coreference as clustering.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in NLP and Very Large Corpora,</booktitle>
<pages>82--89</pages>
<marker>Cardie, Wagstaff, 1999</marker>
<rawString>Claire Cardie and Kiri Wagstaff. 1999. Noun phrase coreference as clustering. In Proceedings of the Joint Conference on Empirical Methods in NLP and Very Large Corpora, pages 82-89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Aravind K Joshi</author>
<author>Scott Weinstein</author>
</authors>
<title>Centering: A Framework for Modeling the Local Coherence of Discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>Barbara J. Grosz, Aravind K. Joshi and Scott Weinstein. 1995. Centering: A Framework for Modeling the Local Coherence of Discourse. Computational Linguistics, 21(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynette Hirshman</author>
<author>Patricia Robinson</author>
<author>John Burger</author>
<author>Marc Vilain</author>
</authors>
<title>The role of Annotated Training Data.</title>
<date>1998</date>
<note>Unpublished manuscript.</note>
<marker>Hirshman, Robinson, Burger, Vilain, 1998</marker>
<rawString>Lynette Hirshman, Patricia Robinson, John Burger and Marc Vilain. 1998. The role of Annotated Training Data. Unpublished manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Resolving pronoun references.</title>
<date>1978</date>
<journal>Lingua,</journal>
<pages>44--311</pages>
<contexts>
<context position="1444" citStr="Hobbs 1978" startWordPosition="193" endWordPosition="194">esolution is an important task for discourse or dialogue processing systems since identity relations between anaphoric textual entities and their antecedents is a prerequisite to the understanding of text or conversation. Traditionally, coreference resolution has been performed by combining linguistic and cognitive knowledge of language. Linguistic information is provided mostly by syntactic and semantic modeling of language whereas cognitive information is incorporated in computational models of discourse. Computational methods based on linguistic and congitive information were presented in (Hobbs 1978), (Lappin and Leass 1994), (Brennan et al.1987), (Grosz et al.1995) and (Webber 1988). The acquisition of extensive linguistic and discourse knowledge necessary for resolving coreference is time consuming, difficult and error-prone. Neverthless, recent results show that knowledge-poor, empirical methods perform with amazing accuracy on certain forms of coreference (cf. (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)). For example, COGNIAC (Baldwin 1997), a system based on just seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal refere</context>
</contexts>
<marker>Hobbs, 1978</marker>
<rawString>Jerry R. Hobbs. 1978. Resolving pronoun references. Lingua, 44:311-338.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
<author>Herbert Leass</author>
</authors>
<title>An algorithm for pronominal anaphora resolution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--4</pages>
<contexts>
<context position="1469" citStr="Lappin and Leass 1994" startWordPosition="195" endWordPosition="199">n important task for discourse or dialogue processing systems since identity relations between anaphoric textual entities and their antecedents is a prerequisite to the understanding of text or conversation. Traditionally, coreference resolution has been performed by combining linguistic and cognitive knowledge of language. Linguistic information is provided mostly by syntactic and semantic modeling of language whereas cognitive information is incorporated in computational models of discourse. Computational methods based on linguistic and congitive information were presented in (Hobbs 1978), (Lappin and Leass 1994), (Brennan et al.1987), (Grosz et al.1995) and (Webber 1988). The acquisition of extensive linguistic and discourse knowledge necessary for resolving coreference is time consuming, difficult and error-prone. Neverthless, recent results show that knowledge-poor, empirical methods perform with amazing accuracy on certain forms of coreference (cf. (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)). For example, COGNIAC (Baldwin 1997), a system based on just seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal reference. In our work, we appr</context>
</contexts>
<marker>Lappin, Leass, 1994</marker>
<rawString>Shalom Lappin and Herbert Leass. 1994. An algorithm for pronominal anaphora resolution. Computational Linguistics, 20(4):535-562.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Megumi Kameyama</author>
</authors>
<title>Recognizing Referential Links: An Information Extraction Perspective.</title>
<date>1997</date>
<booktitle>In Proceedings of the A CL &apos;97/EA CL &apos;97 Workshop on Operational factors in practical, robust anaphora resolution,</booktitle>
<pages>46--53</pages>
<location>Madrid,</location>
<contexts>
<context position="1873" citStr="Kameyama 1997" startWordPosition="255" endWordPosition="256">ge whereas cognitive information is incorporated in computational models of discourse. Computational methods based on linguistic and congitive information were presented in (Hobbs 1978), (Lappin and Leass 1994), (Brennan et al.1987), (Grosz et al.1995) and (Webber 1988). The acquisition of extensive linguistic and discourse knowledge necessary for resolving coreference is time consuming, difficult and error-prone. Neverthless, recent results show that knowledge-poor, empirical methods perform with amazing accuracy on certain forms of coreference (cf. (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)). For example, COGNIAC (Baldwin 1997), a system based on just seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal reference. In our work, we approached the coreference resolution problem by trying to determine how much more knowledge is required to supplement the abovementioned knowledge-poor methods and how to derive that knowledge. To this end we (1) analyze the data to find what types of anaphor-antecedent pairs are most popular in real-world texts; (2) devise knowledge-minimalist rules for handling the majority of those popular cases; and </context>
</contexts>
<marker>Kameyama, 1997</marker>
<rawString>Megumi Kameyama. 1997. Recognizing Referential Links: An Information Extraction Perspective. In Proceedings of the A CL &apos;97/EA CL &apos;97 Workshop on Operational factors in practical, robust anaphora resolution, pages 46-53, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Kennedy</author>
<author>Branimir Bogureav</author>
</authors>
<title>Anaphora for everyone: Pronominal anaphora resolution without a parser.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING-96.</booktitle>
<marker>Kennedy, Bogureav, 1996</marker>
<rawString>Christopher Kennedy and Branimir Bogureav. 1996. Anaphora for everyone: Pronominal anaphora resolution without a parser. In Proceedings of COLING-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>WordNet: A Lexical Database.</title>
<date>1995</date>
<journal>Communication of the ACM,</journal>
<pages>38--11</pages>
<contexts>
<context position="2839" citStr="Miller 1995" startWordPosition="405" endWordPosition="406">nd how to derive that knowledge. To this end we (1) analyze the data to find what types of anaphor-antecedent pairs are most popular in real-world texts; (2) devise knowledge-minimalist rules for handling the majority of those popular cases; and (3) discover what supplementary knowledge is needed for remaining, more difficult cases. To analyze coreference data we use a corpus of annotated texts. To devise minimalist coreference resolution rules we consider (1) strong indicators of cohesion, such as repetitions, name aliases or appositions; and (2) gender, number and class agreements. WordNet (Miller 1995), the vast semantic knowledge base, provides suplementary knowledge in the form of semantic consistency between coreferring nouns. Additional semantic consistency knowledge is generated by a bootstrapping mechanism when our coreference resolution system, COCKTAIL&apos;, processes new texts. This bootstrapping mechanism inspired by the technique presented in (Riloff and Jones 1999) targets one of the most problematic forms of knowledge needed for coreference resolution: the semantic consistency of corefering nominals. The rest of the paper is organized as follows. Section 2 discusses our text mining</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. WordNet: A Lexical Database. Communication of the ACM, 38(11):39-41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Robust pronoun resolution with limited knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of COLINGACL &apos;98,</booktitle>
<pages>869--875</pages>
<contexts>
<context position="1829" citStr="Mitkov 1998" startWordPosition="248" endWordPosition="249"> syntactic and semantic modeling of language whereas cognitive information is incorporated in computational models of discourse. Computational methods based on linguistic and congitive information were presented in (Hobbs 1978), (Lappin and Leass 1994), (Brennan et al.1987), (Grosz et al.1995) and (Webber 1988). The acquisition of extensive linguistic and discourse knowledge necessary for resolving coreference is time consuming, difficult and error-prone. Neverthless, recent results show that knowledge-poor, empirical methods perform with amazing accuracy on certain forms of coreference (cf. (Mitkov 1998) (Kennedy and Boguraev 1996) (Kameyama 1997)). For example, COGNIAC (Baldwin 1997), a system based on just seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal reference. In our work, we approached the coreference resolution problem by trying to determine how much more knowledge is required to supplement the abovementioned knowledge-poor methods and how to derive that knowledge. To this end we (1) analyze the data to find what types of anaphor-antecedent pairs are most popular in real-world texts; (2) devise knowledge-minimalist rules for handli</context>
</contexts>
<marker>Mitkov, 1998</marker>
<rawString>Ruslan Mitkov. 1998. Robust pronoun resolution with limited knowledge. In Proceedings of COLINGACL &apos;98, pages 869-875.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
</authors>
<title>Automatically Generating Extraction Patterns from Untagged Text.</title>
<date>1996</date>
<booktitle>In Proceedings of AAAI-96,</booktitle>
<pages>1044--1049</pages>
<location>Portland, OR,</location>
<marker>Riloff, 1996</marker>
<rawString>Ellen Riloff. 1996. Automatically Generating Extraction Patterns from Untagged Text. In Proceedings of AAAI-96, pages 1044-1049, Portland, OR, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Rosie Jones</author>
</authors>
<title>Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping.</title>
<date>1999</date>
<booktitle>In Proceedings of AAAI-99.</booktitle>
<contexts>
<context position="3217" citStr="Riloff and Jones 1999" startWordPosition="454" endWordPosition="457">e a corpus of annotated texts. To devise minimalist coreference resolution rules we consider (1) strong indicators of cohesion, such as repetitions, name aliases or appositions; and (2) gender, number and class agreements. WordNet (Miller 1995), the vast semantic knowledge base, provides suplementary knowledge in the form of semantic consistency between coreferring nouns. Additional semantic consistency knowledge is generated by a bootstrapping mechanism when our coreference resolution system, COCKTAIL&apos;, processes new texts. This bootstrapping mechanism inspired by the technique presented in (Riloff and Jones 1999) targets one of the most problematic forms of knowledge needed for coreference resolution: the semantic consistency of corefering nominals. The rest of the paper is organized as follows. Section 2 discusses our text mining methodology for analysing the data and devising knowledgeminimalist rules for resolving the most popular coreference cases. Section 3 presents the knowledgemining components of COCKTAIL that use WordNet for deriving semantic consistency as well as gender information. Section 4 presents an entropy-based method for optimally combining coreference rules and Section 5 presents t</context>
<context position="10543" citStr="Riloff and Jones 1999" startWordPosition="1643" endWordPosition="1646">he total number of nouns and verbs in the search space. C represents the number of nouns and verbs that can be reached by both nominals. In addition rirtotal is the number of concepts along all paths established, whereas rel(p+) 1 0.5 0 -0.5 -1 0 0.5 1 R3 B A R2 CN1 CN2 R1 CN1 New semantic consistency path = New coreference rule Semantic consistency Path: Mropho-Derivation : Is-A : Collide-Sense Coreference Rule: If (x is Morpho-Derivation ( Anaphor) ) AND AND (y is one of the hypernyms of x) AND AND (z is SYNONYM of y) AND AND (z is SYNONYM of anaphor) then Cast_in_Chain(Anaphor,antecedent) (Riloff and Jones 1999) note that the performance of the mutual bootstrapping algorithm can deteriorate rapidly if erroneous rules are entered. To make the algorithm more robust we use the same solution by introducing a second level of bootrapping. The outer level, called meta-bootstrapping identifies the most reliable k rules based on semantic consistency and discard all the others before restarting the mutual bootstrapping loop again. In our experiments we have retained only those rules for which the new performance, given by the F-measure was larger than the median of the past four loops. The formula for the van </context>
</contexts>
<marker>Riloff, Jones, 1999</marker>
<rawString>Ellen Riloff and Rosie Jones. 1999. Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping. In Proceedings of AAAI-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Salton</author>
<author>Chris Buckley</author>
</authors>
<title>Term-weighting approaches in automatic retrieval.</title>
<date>1988</date>
<booktitle>Information Processing and Management,</booktitle>
<pages>24--5</pages>
<marker>Salton, Buckley, 1988</marker>
<rawString>Gerald Salton and Chris Buckley. 1988. Term-weighting approaches in automatic retrieval. Information Processing and Management, 24(5):513-523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Vilain</author>
<author>John Burger</author>
<author>John Aberdeen</author>
<author>Dan Connolly</author>
<author>Lynette Hirshman</author>
</authors>
<title>A model-theoretic coreference scoring scheme.</title>
<date>1995</date>
<booktitle>Proceedings of MUC-6,</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<location>San Mateo, CA.</location>
<contexts>
<context position="11556" citStr="Vilain et al. 1995" startWordPosition="1813" endWordPosition="1816">otstrapping loop again. In our experiments we have retained only those rules for which the new performance, given by the F-measure was larger than the median of the past four loops. The formula for the van Rijsbergen&apos;s F-measure combines 2 xpP±XRR the precision P with the recall R in F = 6 Evaluation To measure the performance of COCKTAIL we have trained the system on 30 MUC-6 and MUC-7 texts and tested it on the remaining 30 documents. We computed the precision, the recall and the Fmeasure. The performance measures have been obtained automatically using the MUC-6 coreference scoring program (Vilain et al. 1995). Table 4 lists the results. Precision Recall F-measure COCKTAIL 87.1% 61.7% 72.3% rules COCKTAIL 91.3% 58.6% 71.8% rules combined COCKTAIL 92.0% 73.9% 81.9% +bootstrapping Table 4: Bootstrapping effect on COCKTAIL Table 4 shows that the seed set of rules had good precision but poor recall. By combining the rules with the entropy-based measure, we obtained further enhancement in precision, but the recall dropped. The application of the bootstrapping methodology determined an enhancement of recall, and thus of the F-measure. In the future we intend to compare the overall effect of rules that re</context>
</contexts>
<marker>Vilain, Burger, Aberdeen, Connolly, Hirshman, 1995</marker>
<rawString>Marc Vilain, John Burger, John Aberdeen, Dan Connolly and Lynette Hirshman. 1995. A model-theoretic coreference scoring scheme. Proceedings of MUC-6, Morgan Kaufmann, San Mateo, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J van Rijsbergen</author>
</authors>
<title>Information Retrieval.</title>
<date>1979</date>
<publisher>Butterworths,</publisher>
<location>Glasgow, UK.</location>
<marker>van Rijsbergen, 1979</marker>
<rawString>C.J. van Rijsbergen. 1979. Information Retrieval. Butterworths, Glasgow, UK.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Bonnie Webber</author>
</authors>
<title>Discourse deixis: Reference to discourse segments.</title>
<booktitle>In Proceedings of ACL-88,</booktitle>
<pages>113--121</pages>
<marker>Webber, </marker>
<rawString>Bonnie Webber. Discourse deixis: Reference to discourse segments. In Proceedings of ACL-88, pages 113-121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce M Wiebe</author>
<author>Rebecca F Bruce</author>
<author>Thomas P O&apos;Hara</author>
</authors>
<title>Development and use of a goldstandard data set for subjectivity classifications.</title>
<date>1999</date>
<booktitle>In Proceedings of ACL-99,</booktitle>
<pages>246--253</pages>
<marker>Wiebe, Bruce, O&apos;Hara, 1999</marker>
<rawString>Janyce M. Wiebe, Rebecca F. Bruce and Thomas P. O&apos;Hara. 1999. Development and use of a goldstandard data set for subjectivity classifications. In Proceedings of ACL-99, pages 246-253.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>