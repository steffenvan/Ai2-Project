<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.038487">
<title confidence="0.962078">
Just Title It! (by an Online Application)
</title>
<author confidence="0.993358">
C´edric Lopez, Violaine Prince, and Mathieu Roche
</author>
<affiliation confidence="0.986291">
LIRMM, CNRS, University of Montpellier 2
</affiliation>
<address confidence="0.776005">
161, rue Ada
Montpellier, France
</address>
<email confidence="0.999508">
{lopez,prince,mroche}@lirmm.fr
</email>
<sectionHeader confidence="0.997398" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999669923076923">
This paper deals with an application of au-
tomatic titling. The aim of such application
is to attribute a title for a given text. So,
our application relies on three very differ-
ent automatic titling methods. The first one
extracts relevant noun phrases for their use
as a heading, the second one automatically
constructs headings by selecting words ap-
pearing in the text, and, finally, the third
one uses nominalization in order to propose
informative and catchy titles. Experiments
based on 1048 titles have shown that our
methods provide relevant titles.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999972925925926">
The important amount of textual documents is
in perpetual growth and requires robust applica-
tions. Automatic titling is an essential task for
several applications: Automatic titling of e-mails
without subjects, text generation, summarization,
and so forth. Furthermore, a system able to ti-
tle HTML documents and so, to respect one of
the W3C standards about Web site accessibility,
is quite useful. The titling process goal is to pro-
vide a relevant representation of a document con-
tent. It might use metaphors, humor, or emphasis,
thus separating a titling task from a summariza-
tion process, proving the importance of the rhetor-
ical status in both tasks.
This paper presents an original application con-
sisting in titling all kinds of texts. For that pur-
pose, our application offers three main meth-
ods. The first one (called POSTIT) extracts noun
phrases to be used as headings, the second one
(called CATIT) automatically builds titles by se-
lecting words appearing in the text, and, finally,
the third one (called NOMIT) uses nominalization
in order to propose relevant titles. Morphologic
and semantic treatments are applied to obtain ti-
tles close to real titles. In particular, titles have to
respect two characteristics: Relevance and catch-
iness.
</bodyText>
<sectionHeader confidence="0.953802" genericHeader="method">
2 Text Titling Application
</sectionHeader>
<bodyText confidence="0.998637">
The application presented in this paper was de-
veloped with PHP, and it is available on the
Web1. It is based on several methods using Nat-
ural Language Processing (NLP) and Information
Retrieval (IR) techniques. So, the input is a text
and the output is a set of titles based on different
kinds of strategies.
A single automatic titling method is not suffi-
cient to title texts. Actually, it cannot respect di-
versity, noticed in real titles, which vary accord-
ing to the writer’s personal interests or/and his/her
writing style. With the aim of getting closer to this
variety, the user can choose the more relevant title
according to his personal criteria among a list of
titles automatically proposed by our system.
A few other applications have focused on ti-
tling: One of the most typical, (Banko, 2000),
consists in generating coherent summaries that
are shorter than a single sentence. These sum-
maries are called ”headlines”. The main diffi-
culty is to adjust the threshold (i.e, the headline
length), in order to obtain syntactically correct
titles. Whereas our methods create titles which
are intrinsically correct, both syntactically and se-
mantically.
In this section, we present the POSTIT, CATIT,
and NOMIT methods. These three methods run
</bodyText>
<footnote confidence="0.997138">
1https://www2.lirmm.fr/˜lopez/Titrage_
general/
</footnote>
<page confidence="0.999149">
31
</page>
<bodyText confidence="0.948750533333333">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 31–34,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
in parallel, without interaction with each other.
Three very different titles are thus determined for
every text. For each of them, an example of the
produced title is given on the following sample
text: ”In her speech, Mrs Merkel has promised
concrete steps towards a fiscal union - in effect
close integration of the tax-and-spend polices of
individual eurozone countries, with Brussels im-
posing penalties on members that break the rules.
[...]”. Even if examples are in English, the ap-
plication is actually in French (but easily repro-
ducible in English). The POS tagging was per-
formed by Sygfran (Chauch´e, 1984).
</bodyText>
<subsectionHeader confidence="0.843991">
2.1 POSTIT
</subsectionHeader>
<bodyText confidence="0.999842352941177">
(Jin, 2001) implemented a set of title generation
methods and evaluated them: The statistical ap-
proach based on the TF-IDF obtains the best re-
sults. In the same way, the POSTIT (Titling using
Position and Statistical Information) method uses
statistical information. Related works have shown
that verbs are not as widely spread as nouns,
named entities, and adjectives (Lopez, 2011a).
Moreover, it was noticed that elements appearing
in the title are often present in the body of the text
(Zajic et al., 2002). (Zhou and Hovy, 2003) sup-
ports this idea and shows that the covering rate of
those words present in titles, is very high in the
first sentences of a text. So, the main idea is to
extract noun phrases from the text and to select
the more relevant for its use as title. The POSTIT
approach is composed of the following steps:
</bodyText>
<listItem confidence="0.952526529411765">
1. Candidate Sentence Determination. We as-
sume that any text contains only a few rel-
evant sentences for titling. The goal of this
step consists in recognizing them. Statistical
analysis shows that, very often, terms useful
for titling are located in the first sentences of
the text.
2. Extracting Candidate Noun Phrases for Ti-
tling. This step uses syntactical filters re-
lying on the statistical studies previously
led. For that purpose, texts are tagged with
Sygfran. Our syntactical patterns allowing
noun phrase extraction are also inspired from
(Daille, 1996).
3. Selecting a Title. Last, candidate noun
phrases (t) are ranked according to a score
based on the use of TF-IDF and information
</listItem>
<bodyText confidence="0.997490333333333">
about noun phrase position (NPPOS) (see
Lopez, 2011a). With A = 0.5, this method
obtains good results (see Formula 1).
</bodyText>
<equation confidence="0.999744">
NPs.,,(t) = A x NPPOS(t)
+ (1 − A) X NPTF−IDF(t) (1)
</equation>
<bodyText confidence="0.995372428571429">
Example of title with POSTIT: Concrete steps
towards a fiscal union.
On one hand, this method proposes titles which
are syntactically correct. But on the other hand,
provided titles can not be considered as original.
Next method, called CATIT, enables to generate
more ’original’ titles.
</bodyText>
<subsectionHeader confidence="0.882518">
2.2 CATIT
</subsectionHeader>
<bodyText confidence="0.993456333333333">
CATIT (Automatic Construction of Titles) is an
automatic process that constructs short titles. Ti-
tles have to show coherence with both the text and
the Web, as well as with their dynamic context
(Lopez, 2011b). This process is based on a global
approach consisting in three main stages:
</bodyText>
<listItem confidence="0.999031346153846">
1. Generation of Candidates Titles. The pur-
pose is to extract relevant nouns (using TF-
IDF criterion) and adjectives (using TF cri-
terion) from the text. Potential relevant cou-
ples (candidate titles) are built respecting the
”Noun Adjective” and/or ”Adjective Noun”
syntactical patterns.
2. Coherence of Candidate Titles. Among the
list of candidate titles, which ones are gram-
matically and semantically consistent ? The
produced titles are supposed to be consis-
tent with the text through the use of TF-
IDF. To reinforce coherence, we set up a
distance coefficient between a noun and an
adjective which constitutes a new coherence
criterion in candidate titles. Besides, the fre-
quency of appearance of candidate titles on
the Web (with Dice measure) is used in order
to measure the dependence between the noun
and the adjective composing a candidate ti-
tle. This method thus automatically favors
well-formed candidates.
3. Dynamic Contextualization of Candidate Ti-
tles. To determine the most relevant candi-
date title, the text context is compared with
the context in which these candidates are met
</listItem>
<page confidence="0.99604">
32
</page>
<bodyText confidence="0.997998818181818">
on the Web. They are both modeled as vec-
tors, according to Salton’s vector model.
Example of title with CATIT: Fiscal penalties.
The automatic generation of titles is a complex
task because titles have to be coherent, grammat-
ically correct, informative, and catchy. These cri-
teria are a brake in the generation of longer ti-
tles (being studied). That is why we suggest a
new approach consisting in reformulating rele-
vant phrases in order to determine informative and
catchy ”long” titles.
</bodyText>
<subsectionHeader confidence="0.850428">
2.3 NOMIT
</subsectionHeader>
<bodyText confidence="0.999522">
Based on statistical analysis, NOMIT (Nominal-
ization for Titling) provides original titles relying
on several rules to transform a verbal phrase in a
noun phrase.
</bodyText>
<listItem confidence="0.978248578947368">
1. Extracting Candidates. First step consists in
extracting segments of phrases which con-
tain a past participle (in French). For exam-
ple: In her speech, Mrs Merkel has promised
”concrete steps towards a fiscal union” -
in effect close integration of the tax-and-
spend polices of individual eurozone coun-
tries, with Brussels imposing penalties on
members that break the rules.
2. Linguistic Treatment. The linguistic treat-
ment of the segments retained in the previous
step consists of two steps aiming at nominal-
izing the ”auxiliary + past participle” form
(very frequent in French). First step consists
in associating a noun for each past participle.
Second step uses transforming rules in order
to obtain nominalized segments. For exam-
ple: has promised ==&gt;. promise.
3. Selecting a Title. Selection of the most rel-
</listItem>
<bodyText confidence="0.9276901">
evant title relies on a Web validation. The
interest of this validation is double. On one
hand, the objective is to validate the connec-
tion between the nominalized past partici-
ple and the complement. On the other hand,
the interest is to eliminate incorrect semantic
constituents or not popular ones (e.g., ”an-
nunciation of the winners ”), to prefer those
which are more popular on Web (e.g. , ”an-
nouncement of the winners”).
</bodyText>
<figureCaption confidence="0.999797">
Figure 1: Screenshot of Automatic Titling Evaluation
</figureCaption>
<bodyText confidence="0.993013571428571">
Example of title with NOMIT: Mrs Merkel:
Promise of a concrete step towards a fiscal union.
This method enables to obtain even more orig-
inal titles than the previous one (i.e. CATIT).
A positive aspect is that new transforming rules
can be easily added in order to respect morpho-
syntactical patterns of real titles.
</bodyText>
<sectionHeader confidence="0.99949" genericHeader="method">
3 Evaluations
</sectionHeader>
<subsectionHeader confidence="0.999876">
3.1 Protocol Description
</subsectionHeader>
<bodyText confidence="0.999858625">
An online evaluation has been set up, accessi-
ble to all people (cf. Figure 1)2. The benefit of
such evaluation is to compare different automatic
methods according to several judgements. So, for
each text proposed to the human user, several ti-
tles are presented, each one resulting from one of
the automatic titling methods presented in this pa-
per (POSTIT, CATIT, and NOMIT). Furthermore,
random titles stemming from CATIT and POSTIT
methods are evaluated (CATIT-R, and POSTIT-
R), i.e., candidate titles built by our methods but
not selected because of their bad score. The idea
is to measure the efficiency of our ranking func-
tions.
This evaluation is run on French articles stem-
ming from the daily newspaper ’Le Monde’. We
retained the first article published every day for
the year 1994, up to a total of 200 journalistic ar-
ticles. 190 people have participated to the online
experiment, evaluating a total of 1048 titles. On
average, every person has evaluated 41 titles. Ev-
ery title has been evaluated by several people (be-
tween 2 and 10). The total number of obtained
evaluations is 7764.
</bodyText>
<footnote confidence="0.9756265">
2URL: http://www2.lirmm.fr/˜lopez/
Titrage_general/evaluation_web2/
</footnote>
<page confidence="0.998173">
33
</page>
<subsectionHeader confidence="0.935747">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.998776782608696">
Results of this evaluation indicate that the most
adapted titling method for articles is NOMIT. This
one enables to title 82.7% of texts in a relevant
way (cf. Table 1). However, NOMIT does not de-
termine titles for all the texts (in this evaluation,
NOMIT determined a title for 58 texts). Indeed,
if no past participle is present in the text, there is
no title returned with this method. It is thus essen-
tial to consider the other methods which assure a
title for every text. POSTIT enables to title 70%
of texts in a relevant way. It is interesting to note
that both gathered methods POSTIT and NOMIT
provide at least one relevant title for 74 % of texts
(cf. Table 2). Finally, even if CATIT obtains a
weak score, this method provides a relevant title
where POSTIT and NOMIT are silent. So, these
three gathered methods propose at least one rele-
vant title for 81% of journalistic articles.
Concerning catchiness, the three methods seem
equivalent, proposing catchy titles for approxi-
mately 50% of texts. The three gathered methods
propose at least one catchy title for 78% of texts.
Real titles (RT) obtain close score (80.5%).
</bodyText>
<table confidence="0.998632571428571">
% POSTIT POSTIT-R CATIT CATIT-R NOMIT RT
Very relevant (VR) 39.1 16.4 15.7 10.3 60.3 71.4
Relevant (R) 30.9 22.3 21.3 14.5 22.4 16.4
(VR) and (R) 70.0 38.7 37.0 24.8 82.7 87.8
Not relevant 30.0 61.4 63.0 75.2 17.2 12.3
Catchy 49.1 30.9 47.2 32.2 53.4 80.5
Not catchy 50.9 69.1 52.8 67.8 46.6 19.5
</table>
<tableCaption confidence="0.996236">
Table 1: Average scores of our application.
</tableCaption>
<table confidence="0.982575">
% POSTIT&amp;NOMIT POSTIT&amp;CATIT NOMIT&amp;CATIT POSTIT,CATIT,&amp;NOMIT
(VR) 47 46 28 54
(R) or (VR) 74 78 49 81
Catchy 57 73 55 78
</table>
<tableCaption confidence="0.999535">
Table 2: Results of gathered methods.
</tableCaption>
<bodyText confidence="0.915399666666667">
Also, let us note that our ranking functions
are relevant since CATIT-R and POSTIT-R obtain
weak results compared with CATIT and POSTIT.
</bodyText>
<sectionHeader confidence="0.999616" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999888708333333">
In this paper, we have compared the efficiency of
three methods using various techniques. POSTIT
uses noun phrases extracted from the text, CATIT
consists in constructing short titles, and NOMIT
uses nominalization. We proposed three different
methods to approach the real context. Two per-
sons can propose different titles for the same text,
depending on personal criteria and on its own in-
terests. That is why automatic titling is a complex
task as much as evaluation of catchiness which
remains subjective. Evaluation shows that our ap-
plication provides relevant titles for 81% of texts
and catchy titles for 78 % of texts. These re-
sults are very encouraging because real titles ob-
tain close results.
A future work will consist in taking into ac-
count a context defined by the user. For exam-
ple, the generated titles could depend on a polit-
ical context if the user chooses to select a given
thread. Furthermore, an ”extended” context, au-
tomatically determined from the user’s choice,
could enhance or refine user’s desiderata.
A next work will consist in adapting this appli-
cation for English.
</bodyText>
<sectionHeader confidence="0.999658" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999782538461539">
Michele Banko, Vibhu O. Mittal, and Michael J Wit-
brock. 1996. Headline generation based on statisti-
cal translation. COLING’96. p. 318–325.
Jacques Chauch´e. 1984. Un outil multidimensionnel
de l’analyse du discours. COLING’84. p. 11-15.
B´eatrice Daille. 1996. Study and implementation
of combined techniques for automatic extraction of
terminology. The Balancing Act: Combining Sym-
bolic and StatisticalApproaches to language. p. 29-
36.
Rong Jin, and Alexander G. Hauptmann. 1996. Au-
tomatic title generation for spoken broadcast news.
Proceedings of the first international conference on
Human language technology research. p. 1–3.
C´edric Lopez, Violaine Prince, and Mathieu Roche.
2011. Automatic titling of Articles Using Position
and Statistical Information. RANLP’11. p. 727-
732.
C´edric Lopez, Violaine Prince, and Mathieu Roche.
2011. Automatic Generation of Short Titles.
LTC’11. p. 461-465.
Gerard Salton and Christopher Buckley. 1988. Term-
weighting approaches in automatic text retrieval.
Information Processing and Management 24. p.
513-523.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. International Confer-
ence on New Methods in Language Processing. p.
44-49.
Franck Smadja, Kathleen R. McKeown, and Vasileios
Hatzivassiloglou. 1996. Translating collocations
for bilingual lexicons: A statistical approach. Com-
putational linguistics, 22(1). p. 1-38.
David Zajic, Bonnie Door, and Rich Schwarz. 2002.
Automatic headline generation for newspaper sto-
ries. ACL 2002. Philadelphia.
Liang Zhou and Eduard Hovy. 2002. Headline sum-
marization at ISI. DUC 2003. Edmonton, Alberta,
Canada.
</reference>
<page confidence="0.999314">
34
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.612973">
<title confidence="0.986311">Just Title It! (by an Online Application)</title>
<author confidence="0.985205">C´edric Lopez</author>
<author confidence="0.985205">Violaine Prince</author>
<author confidence="0.985205">Mathieu</author>
<affiliation confidence="0.99237">LIRMM, CNRS, University of Montpellier</affiliation>
<address confidence="0.803068">161, rue Montpellier,</address>
<abstract confidence="0.999837142857143">This paper deals with an application of automatic titling. The aim of such application is to attribute a title for a given text. So, our application relies on three very different automatic titling methods. The first one extracts relevant noun phrases for their use as a heading, the second one automatically constructs headings by selecting words appearing in the text, and, finally, the third one uses nominalization in order to propose informative and catchy titles. Experiments based on 1048 titles have shown that our methods provide relevant titles.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Vibhu O Mittal</author>
<author>Michael J Witbrock</author>
</authors>
<title>Headline generation based on statistical translation.</title>
<date>1996</date>
<booktitle>COLING’96.</booktitle>
<pages>318--325</pages>
<marker>Banko, Mittal, Witbrock, 1996</marker>
<rawString>Michele Banko, Vibhu O. Mittal, and Michael J Witbrock. 1996. Headline generation based on statistical translation. COLING’96. p. 318–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacques Chauch´e</author>
</authors>
<title>Un outil multidimensionnel de l’analyse du discours.</title>
<date>1984</date>
<pages>84--11</pages>
<marker>Chauch´e, 1984</marker>
<rawString>Jacques Chauch´e. 1984. Un outil multidimensionnel de l’analyse du discours. COLING’84. p. 11-15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B´eatrice Daille</author>
</authors>
<title>Study and implementation of combined techniques for automatic extraction of terminology. The Balancing Act: Combining Symbolic and StatisticalApproaches to language.</title>
<date>1996</date>
<pages>29--36</pages>
<contexts>
<context position="5583" citStr="Daille, 1996" startWordPosition="896" endWordPosition="897">OSTIT approach is composed of the following steps: 1. Candidate Sentence Determination. We assume that any text contains only a few relevant sentences for titling. The goal of this step consists in recognizing them. Statistical analysis shows that, very often, terms useful for titling are located in the first sentences of the text. 2. Extracting Candidate Noun Phrases for Titling. This step uses syntactical filters relying on the statistical studies previously led. For that purpose, texts are tagged with Sygfran. Our syntactical patterns allowing noun phrase extraction are also inspired from (Daille, 1996). 3. Selecting a Title. Last, candidate noun phrases (t) are ranked according to a score based on the use of TF-IDF and information about noun phrase position (NPPOS) (see Lopez, 2011a). With A = 0.5, this method obtains good results (see Formula 1). NPs.,,(t) = A x NPPOS(t) + (1 − A) X NPTF−IDF(t) (1) Example of title with POSTIT: Concrete steps towards a fiscal union. On one hand, this method proposes titles which are syntactically correct. But on the other hand, provided titles can not be considered as original. Next method, called CATIT, enables to generate more ’original’ titles. 2.2 CATI</context>
</contexts>
<marker>Daille, 1996</marker>
<rawString>B´eatrice Daille. 1996. Study and implementation of combined techniques for automatic extraction of terminology. The Balancing Act: Combining Symbolic and StatisticalApproaches to language. p. 29-36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong Jin</author>
<author>Alexander G Hauptmann</author>
</authors>
<title>Automatic title generation for spoken broadcast news.</title>
<date>1996</date>
<booktitle>Proceedings of the first international conference on Human language technology research.</booktitle>
<pages>1--3</pages>
<marker>Jin, Hauptmann, 1996</marker>
<rawString>Rong Jin, and Alexander G. Hauptmann. 1996. Automatic title generation for spoken broadcast news. Proceedings of the first international conference on Human language technology research. p. 1–3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C´edric Lopez</author>
<author>Violaine Prince</author>
<author>Mathieu Roche</author>
</authors>
<date>2011</date>
<booktitle>Automatic titling of Articles Using Position and Statistical Information. RANLP’11.</booktitle>
<pages>727--732</pages>
<marker>Lopez, Prince, Roche, 2011</marker>
<rawString>C´edric Lopez, Violaine Prince, and Mathieu Roche. 2011. Automatic titling of Articles Using Position and Statistical Information. RANLP’11. p. 727-732.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C´edric Lopez</author>
<author>Violaine Prince</author>
<author>Mathieu Roche</author>
</authors>
<title>Automatic Generation of Short Titles.</title>
<date>2011</date>
<pages>461--465</pages>
<marker>Lopez, Prince, Roche, 2011</marker>
<rawString>C´edric Lopez, Violaine Prince, and Mathieu Roche. 2011. Automatic Generation of Short Titles. LTC’11. p. 461-465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Christopher Buckley</author>
</authors>
<title>Termweighting approaches in automatic text retrieval.</title>
<date>1988</date>
<journal>Information Processing and Management</journal>
<volume>24</volume>
<pages>513--523</pages>
<marker>Salton, Buckley, 1988</marker>
<rawString>Gerard Salton and Christopher Buckley. 1988. Termweighting approaches in automatic text retrieval. Information Processing and Management 24. p. 513-523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>International Conference on New Methods in Language Processing.</booktitle>
<pages>44--49</pages>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. International Conference on New Methods in Language Processing. p. 44-49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franck Smadja</author>
<author>Kathleen R McKeown</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Translating collocations for bilingual lexicons: A statistical approach.</title>
<date>1996</date>
<journal>Computational linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<pages>1--38</pages>
<marker>Smadja, McKeown, Hatzivassiloglou, 1996</marker>
<rawString>Franck Smadja, Kathleen R. McKeown, and Vasileios Hatzivassiloglou. 1996. Translating collocations for bilingual lexicons: A statistical approach. Computational linguistics, 22(1). p. 1-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Zajic</author>
<author>Bonnie Door</author>
<author>Rich Schwarz</author>
</authors>
<title>Automatic headline generation for newspaper stories. ACL</title>
<date>2002</date>
<location>Philadelphia.</location>
<contexts>
<context position="4695" citStr="Zajic et al., 2002" startWordPosition="743" endWordPosition="746">h (but easily reproducible in English). The POS tagging was performed by Sygfran (Chauch´e, 1984). 2.1 POSTIT (Jin, 2001) implemented a set of title generation methods and evaluated them: The statistical approach based on the TF-IDF obtains the best results. In the same way, the POSTIT (Titling using Position and Statistical Information) method uses statistical information. Related works have shown that verbs are not as widely spread as nouns, named entities, and adjectives (Lopez, 2011a). Moreover, it was noticed that elements appearing in the title are often present in the body of the text (Zajic et al., 2002). (Zhou and Hovy, 2003) supports this idea and shows that the covering rate of those words present in titles, is very high in the first sentences of a text. So, the main idea is to extract noun phrases from the text and to select the more relevant for its use as title. The POSTIT approach is composed of the following steps: 1. Candidate Sentence Determination. We assume that any text contains only a few relevant sentences for titling. The goal of this step consists in recognizing them. Statistical analysis shows that, very often, terms useful for titling are located in the first sentences of t</context>
</contexts>
<marker>Zajic, Door, Schwarz, 2002</marker>
<rawString>David Zajic, Bonnie Door, and Rich Schwarz. 2002. Automatic headline generation for newspaper stories. ACL 2002. Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Zhou</author>
<author>Eduard Hovy</author>
</authors>
<date>2002</date>
<booktitle>Headline summarization at ISI. DUC 2003.</booktitle>
<location>Edmonton, Alberta, Canada.</location>
<marker>Zhou, Hovy, 2002</marker>
<rawString>Liang Zhou and Eduard Hovy. 2002. Headline summarization at ISI. DUC 2003. Edmonton, Alberta, Canada.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>