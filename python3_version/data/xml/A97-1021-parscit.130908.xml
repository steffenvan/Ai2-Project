<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.990846">
Large-Scale Acquisition of LCS-Based Lexicons
for Foreign Language Tutoring
</title>
<author confidence="0.995371">
Bonnie J. Dorr
</author>
<affiliation confidence="0.997349">
Department of Computer Science
University of Maryland
</affiliation>
<address confidence="0.936943">
College Park, MD 20742, USA
</address>
<email confidence="0.973271">
bonnieOcs.umd.edu
</email>
<sectionHeader confidence="0.981301" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999072588235294">
We focus on the problem of building large
repositories of lexical conceptual structure
(LCS) representations for verbs in multi-
ple languages. One of the main results
of this work is the definition of a rela-
tion between broad semantic classes and
LCS meaning components. Our acquisi-
tion program—LEXICALL takes, as in-
put, the result of previous work on verb
classification and thematic grid tagging,
and outputs LCS representations for differ-
ent languages. These representations have
been ported into English, Arabic and Span-
ish lexicons, each containing approximately
9000 verbs. We are currently using these
lexicons in an operational foreign language
tutoring and machine translation.
</bodyText>
<sectionHeader confidence="0.996281" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998108106060606">
A wide range of new capabilities in NLP applications
such as foreign language tutoring (FLT) has been
made possible by recent advances in lexical seman-
tics (Carrier and Randall, 1993; Dowty, 1991; Fill-
more, 1968; Foley and Van Valin, 1984; Grimshaw,
1990; Gruber, 1965; Hale and Keyser, 1993; Jack-
endoff, 1983; Jackendoff, 1990; Jackendoff, 1996;
Levin, 1993; Levin and Rappaport Hova.v, To ap-
pear; Pesetsky, 1982; Pinker, 1989). Many of these
researchers adopt the hypothesis that verbs can be
grouped into broad classes, each of which corre-
sponds to some combination of basic meaning com-
ponents. This is the basic premise underlying our
approach to multilingual lexicon construction. In
particular, we have organized verbs into broad se-
mantic classes and subsequently designed a set of
lexical conceptual structures (LCS), for each class.
These representations have been ported into English,
Arabic, and Spanish lexicons, each containing ap-
proximately 9000 verbs.
An example of a NLP application for which these
lexicons are currently in use is an operational foreign
language tutoring (FLT) system called Military Lan-
guage Tutor (MILT). This system provides a wide
range of lessons for use in language training. One
of the tutoring lessons, the MicroWorld Lesson (see
Figure 1) requires the capability of the language-
learner to state domain-specific actions in a variety
of different ways. For example, the language-learner
might command the agent (pictured at the left in
the graphical interface) to take the following action:
Walk to the table and pick up the document. The
same action should be taken if the user says: Go to
the table and remove document, Retrieve the docu-
ment from the table, etc. The LCS representation
provides the capability to execute various forms of
the same command without hardcoding them as part.
of the graphical interface.
In another tutoring lesson, Question-Answering,
the student is asked to answer questions about a
foreign language text that they have read. Their
answer is converted into an LCS which is matched
against a prestored LCS corresponding to an answer
typed in by a human instructor (henceforth, called
the &amp;quot;author&amp;quot;). The prestored LCS is an idealized
form of the answer to a question, which can take one
of many forms. Suppose, for example, the question
posed to the user is: Where did Jack put the book?
(or Adonde puso Jack el libro? in Spanish). The
author&apos;s answer, e.g., Jack put the book in the trash,
has been stored as an LCS by the tutoring system.
If the student types Jack threw the book in the trash,
or Jack moved the book from the table into the trash,
the system is able to match against the prestored
LCS a.nd determine that all three of these responses
are semantically appropriate.
We have developed an acquisition program
LEXICALL that allows us to construct LCS-based
lexicons for the FLT system. This program is de-
signed to be used for multiple languages, and also for
other NLP applications (e.g., machine translation).
One of the main results of this work is the definition
of a relation between broad semantic classes (based
on work by Levin (1993)) and LCS meaning com-
ponents. We build on previous work, where verbs
were classified automatically (Dorr and Jones, 1996;
</bodyText>
<page confidence="0.998001">
139
</page>
<figureCaption confidence="0.998383">
Figure 1: MicroWorld Lesson in MILT
</figureCaption>
<figure confidence="0.991366">
MicroWorld Lesson
U.S. A.R.MY RESEARCH INSTITUTE
&apos;l Ott
Execute Comm
heck Answer
</figure>
<bodyText confidence="0.988403607142857">
Dorr, To appear) and tagged with thematic grid in-
formation (Dorr, Garman, and Weinberg, 1995). We
use these pre-assigned classes and thematic grids as
input to LEXICALL. The output is a set of LCS&apos;s
corresponding to individual verb entries in our lexi-
con.
Previous research in automatic acquisition focuses
primarily on the use of statistical techniques, such as
bilingual alignment (Church and Hanks, 1990; Kia-
vans and Tzoukermann, 1995; Wu and Xia, 1995)
or extraction of syntactic constructions from on-
line dictionaries and corpora (Brent, 1993). Others
have taken a more knowledge-based (interlingual)
approach (Lonsdale, Mitamura, and Nyberg, 1995).
Still others (Copestake et al., 1995), use English-
based grammatical codes for acquisition of lexical
representations.
Our approach differs from these in that it exploits
certain linguistic constraints that govern the rela-
tion between a word&apos;s surface behavior and its cor-
responding semantic class. We demonstrate that—
by assigning a LCS representation to each semantic
class we can produce verb entries on a broad scale;
these, in turn, are ported into multiple languages.
We first show how the LCS is used in a FLT system.
We then present an overview of the LCS acquisition
process. Finally, we describe how LEXICALL con-
structs entries for specific lexical items.
</bodyText>
<sectionHeader confidence="0.626329" genericHeader="introduction">
2 Application of the LCS
Representation to FLT
</sectionHeader>
<bodyText confidence="0.99999028">
One of the types of knowledge that must be cap-
tured in FLT is linguistic knowledge at the level
of the lexicon, which covers a wide range of infor-
mation types such as verbal subcategorization for
events (e.g., that a transitive verb such as hit occurs
with an object noun phrase), featural information
(e.g., that the direct object of a verb such as frighten
is animate), thematic information (e.g., that Mary is
the agent in Mary hit the ball), and lexical-semantic
information (e.g., spatial verbs such as throw are
conceptually distinct from verbs of possession such
as give). By modularizing the lexicon, we treat each
information type separately, thus allowing us to vary
the degree of dependence on each level so that we
can address the question of how much knowledge is
necessary for the success of the particular NLP ap-
plication.
This section describes the use of the LCS repre-
sentation in a question-answering component of the
MILT system (Sams, 1993; Weinberg et al., 1995).
As described above, the LCS representation is used
as the basis of matching routines for assessing stu-
dents&apos; answers to free response questions about a
short foreign language passage. In order to inform
the student whether a question has been answered
</bodyText>
<page confidence="0.999362">
140
</page>
<tableCaption confidence="0.999799">
Table 1: Correspondence Between NLP Output and Tutor Feedback
</tableCaption>
<bodyText confidence="0.957745807692308">
System Prompt: Where did Jack put the book?
Student Answer Prestored Answer Matcher Output Feedback
Jack threw the book in the trash Jack threw the book in the trash exact match &amp;quot;That&apos;s right&amp;quot;
Jack put the book in the trash Jack threw the book in the trash missing MANNER &amp;quot;How?&amp;quot;
Jack threw the book in the trash Jack put the book in the trash extra MANNER &amp;quot;You&apos;re assuming things&amp;quot;
Jack is friendly Jack put the book in the trash mismatch primitive &amp;quot;Please reread&amp;quot;
Jack threw the book Jack put the book in the trash missing argument &amp;quot;Where?&amp;quot;
correctly, the author of the lesson must provide the
desired response in advance. The system parses and
semantically analyzes the author&apos;s response into a
corresponding LCS representation which is then pre-
stored in a database of possible responses. Once the
question answering lesson is activated, each of the
student&apos;s responses is parsed and semantically ana-
lyzed into a LCS representation which is checked for
a match against the corresponding prestored LCS
representation. The student is then informed as to
whether the question has been answered correctly
depending on how closely the student&apos;s response
LCS matches the author&apos;s prestored LCS.
Consider what happens in a lesson if the author
has specified that a correct answer to the question
Adeinde puso Jack el libro? in Spanish is Jack tiro
el libro a la basura (`Jack threw out the book into
the trash&apos;). This answer is processed by the system
to produce the following LCS:
</bodyText>
<figure confidence="0.891485375">
(1) [Event CAUSE
([Thing JACK],
[Event GOLoc
( [Thing BOOK],
[Path TOLoc
([Position ATLoc
([Thing BOOK], [Thing TRASH])])])],
[ma,„„„ THROWINGLY])]
</figure>
<bodyText confidence="0.992540714285714">
The LCS is stored by the tutor and then later
matched against the student&apos;s answer. If the stu-
dent types Jack movio&apos; el libro de la mesa a la basura
(&apos;Jack moved the book from the table to the trash&apos;),
the system must determine if these two match. The
student&apos;s sentence is processed and the following
LCS structure is produced:
</bodyText>
<figure confidence="0.739359625">
(2) [Event CAUSE
([Thing JACK],
[Event GOLoc
( [Thing BOOK],
[Path TOLoc ([position ATLoc
([Thing BOOK], [Thing TRASH])])],
[Path FROMLoc ([position ATLoc
([Thing BOOK], [Thing TABLE])])])])]
</figure>
<bodyText confidence="0.9464955">
The matcher compares these two, and produces the
following output:
</bodyText>
<sectionHeader confidence="0.838743" genericHeader="method">
Missing: MANNER THROWINGLY
Extra: FROM LOC
</sectionHeader>
<bodyText confidence="0.999977909090909">
The system identifies the student&apos;s response as a.
match with the prestored answer, hut it also recog-
nizes that there is one piece of missing information
and one piece of extra information.
The &amp;quot;Missing&amp;quot; and &amp;quot;Extra&amp;quot; output is internal to
the NLP component of the Tutor, i.e., this is not
the final response displayed to the student. The sys-
tem must convert this information into meaningful
feedback so that the student knows how to repair
the answer that was originally given. For example,
the instructor can program the tutor to notify the
student about the omitted information in the form
of a &apos;How&apos; question, or it can choose to ignore it.
The extra information is generally ignored, although
it is recorded in case the instructor decides to pro-
gram the system to notify the student about this
as well. The full range of feedback is not presented
here. Some possibilities are summarized (in English)
in Table 1 (adapted from (Holland, 1994)). Note
that the main advantage of using the LCS is that it
allows the author to type in an answer that is general
enough to match any number of additional answers.
</bodyText>
<sectionHeader confidence="0.937261" genericHeader="method">
3 Overview of LCS Acquisition
</sectionHeader>
<bodyText confidence="0.999212619047619">
We use Levin&apos;s publicly available online index
(Levin, 1993) as a starting point for building LCS-
based verb entries.&apos; While this index provides a
unique and extensive catalog of verb classes, it does
not define the underlying meaning components of
each class. One of the main contributions of our
work is that it provides a relation between Levin&apos;s
classes and meaning components as defined in the
LCS representation.
Table 2 shows three broad semantic categories and
example verbs along with their associated LCS rep-
resentations. We have hand-constructed a database
containing 191 LCS templates, i.e., one for each verb
class in (Levin, 1993). In addition, we have gener-
ated LCS templates for 26 additional classes that are
not included in Levin&apos;s system. Several of these cor-
respond to verbs that take sentential complements
(e.g., coerce).
We focus on building entries for verbs; however,
we have approximately 30,000 non-verb entries per
language.
</bodyText>
<page confidence="0.999063">
141
</page>
<tableCaption confidence="0.99483">
Table 2: Sample Templates Stored in the LCS Database
</tableCaption>
<table confidence="0.991866083333333">
Category Verb Class Grid LCS
Location suspend 9.2 , ag_th , loc 0 [CAUSE (X,
[BEL,,c (Y, [AT,Loc (Y, Z)])], [BY (MANNER)])]
touch 47.8 _th_loc [BELoc (Y,[ATLoc (Y, Z)l, [BY (MANNER)])]
Motion abandon 51.2 _th,src [GOLoc (Y, [(DIRECTION)Loc (Y, [ATLoc (Y, Z)D1)]
float 51.3.1 _th , src 0 ,goal() [GOLoc (Y, [BY (MANNER)])]
Placement adorn 9.8 _ag_th,mod-poss(with) [CAUSE (X,
[GOIdent (Y,
[TOWARDiacni (Y,
[ATident (Y,
RSTATE)Ident ([(WITH)poss (*HEAD*, Z)])])])])])]
spill 9.5 ,ag_th [CAUSE (X, [COLoc (Y)J, [BY (MANNER)])]
</table>
<bodyText confidence="0.940245666666667">
A full entry in the database includes a semantic
class number with a list of possible verbs, a thematic
grid, and a LCS template:
</bodyText>
<listItem confidence="0.9799">
(3) Class 47.8: adjoin, intersect, meet, touch, ...
Thematic Grid: _th_loc
LCS Template:
</listItem>
<equation confidence="0.413250333333333">
(be loc (thing 2)
(at loc (thing 2) (thing 11))
(!!-ingly 26))
</equation>
<bodyText confidence="0.999962363636364">
The semantic class label 47.8 above is taken from
Levin&apos;s 1993 book (Verbs of Contiguous Location),
i.e., the class to which the verb touch has been
assigned.2 A verb, together with its semantic class
uniquely identifies the word sense, or LCS tem-
plate, to which the verb refers. The thematic grid
(_th_loc) indicates that the verb has two obligatory
arguments, a theme and a location.&apos; The ! ! in the
LCS Template acts as a wildcard; it will be filled by
a lexeme (i.e., a root form of the verb). The resulting
form is called a constant, i.e., the idiosyncratic part
of the meaning that distinguishes among members
of a verb class (in the spirit of (Grimshaw, 1993;
Levin and Rappaport Hovav, To appear; Pinker,
1989; Talmy, 1985)).4
Three inputs are required for acquisition of verb
entries: a semantic class, a thematic grid, and
a lexeme, which we will henceforth abbreviate as
&amp;quot;class/grid/lexeme.&amp;quot; The output is a Lisp-like ex-
pression corresponding to the LCS representation.
An example of input/output for our acquisition pro-
cedure is shown here:
</bodyText>
<listItem confidence="0.844383">
(4) Acquisition of LCS for: touch
Input: 47.8; _th_loc; &amp;quot;touch&amp;quot;
</listItem>
<footnote confidence="0.979057">
2 Verbs not occurring in Levin&apos;s book are also assigned
to classes using techniques described in (Dorr and Jones,
1996; Dorr, To appear).
3An underscore (_) designates an obligatory role and
a comma (,) designates an optional role.
4The ! ! in the Lisp representation corresponds to the
angle-bracketed constants in Table 2. e.g., ! !-ingly cor-
responds to (MANNER).
</footnote>
<equation confidence="0.602441">
Output:
(be loc (* thing 2)
(at loc (thing 2) (* thing 11))
(touchingly 26))
</equation>
<bodyText confidence="0.98889025">
Language-specific annotations such as the *-marker
in the LCS Output are added to the templates by
processing the components of thematic grid specifi-
cations, as we will see in more detail next.
</bodyText>
<sectionHeader confidence="0.998814" genericHeader="method">
4 Language-Specific Annotations
</sectionHeader>
<bodyText confidence="0.999463">
In our on-going example (4), the thematic grid
_th_loc indicates that the theme and the loca-
tion are both obligatory (in English) and should
be annotated as such in the instantiated LCS. This
is achieved by inserting a *-marker appropriately.
Consider the structural divergence between the fol-
lowing English/Spanish equivalents:
</bodyText>
<listItem confidence="0.758059">
(5) Structural Divergence:
E: John entered the house.
5: John entrO a la casa.
</listItem>
<bodyText confidence="0.979425714285714">
&apos;John entered into the house.&apos;
The English sentence differs structurally from the
Spanish in that the noun phrase the house corre-
sponds to a prepositional phrase a la casa. This
distinction is characterized by different positionings
of the *-marker in the lexical entries produced by
LEXICALL:
</bodyText>
<listItem confidence="0.861026">
(6) Lexical Entries:
enter: (go loc (* thing 2)
</listItem>
<equation confidence="0.983587714285714">
(toward loc (thing 2)
(in loc (thing 2) (* thing 6)))
(enteringly 26))
entrar (go loc (* thing 2)
((* toward 5) loc (thing 2)
(in loc (thing 2) (thing 6)))
(enteringly 26))
</equation>
<bodyText confidence="0.98707675">
The lexicon entries for enter and entrar both mean
&amp;quot;X (= Thing 2) goes into location Y (= Thing 6).&amp;quot;
Variable positions (designated by numbers, such as
2, 5 and 6) are used in place of the ultimate fillers
</bodyText>
<page confidence="0.991888">
142
</page>
<bodyText confidence="0.997414714285714">
such as john and house. The structural divergence
of (5) is accommodated as follows: the *-marked leaf
node, i.e., (thing 6) in the enter definition, is filled
directly, whereas the *-marked non-leaf node, i.e.,
((toward 5) loc ) in the entrar definition, is
filled in through unification at the internal toward
node.
</bodyText>
<sectionHeader confidence="0.762833" genericHeader="method">
5 Construction of Lexical Entries
</sectionHeader>
<bodyText confidence="0.657280333333333">
Consider the construction of a lexical entry for the
verb adorn. The LCS for this verb is in the class of
Fill Verbs (9.8):5
</bodyText>
<equation confidence="0.546156">
(7) (cause (thing 1)
(go ident (thing 2)
(toward ident (thing 2)
(at ident (thing 2) (!!-ed 9))))
(with poss (*head*) (thing 16)))
</equation>
<bodyText confidence="0.942260266666667">
This list structure recursively associates logi-
cal heads with their arguments and modifiers.
The logical head is represented as a primi-
tive/field combination, e.g., GOident is repre-
sented as (go ident ...). The arguments
for CAUSE are (thing 1) and (go ident ...).
The substructure GO itself has two arguments
(thing 2) and (toward ident ) and a modi-
fier (with poss ...) .6 The ! !-ed constant refers
to a resulting state, e.g., adorned for the verb adorn.
The LCS produced by our program for this verb is:
(8) (cause (thing 1)
(go ident (thing 2)
(toward ident (thing 2)
(at ident (thing 2) (adorned 9))))
(with poss (*head*) (thing 16)))
The variables in the representation map between
LCS positions and their corresponding thematic
roles. In the LCS framework, thematic roles provide
semantic information about properties of the argu-
ment and modifier structures. In (7) and (8) above,
the numbers 1, 2, 9, and 16 correspond to the roles
agent (ag), theme (th), predicate (pred), and pos-
sessional modifier (mod-poss), respectively. These
numbers enter into the construction of LCS entries:
they correspond to argument positions in the LCS
template (extracted using the class/grid/lexeme
specification). Information is filled into the LCS
template using these numbers, coupled with the the-
matic grid tag for the particular word being defined.
</bodyText>
<subsectionHeader confidence="0.769344">
5.1 Fundamentals
</subsectionHeader>
<bodyText confidence="0.9397495">
LEXICALL locates the appropriate template in the
LCS database using the class/grid pairing as an in-
</bodyText>
<footnote confidence="0.967799">
5Some of the other 9.8 verbs are: anoint. bandage,
flood, frame, garland, stud, suffuse surround. veil.
6The *head* symbol—used for modifiers—is a place-
holder that points to the root (cause) of the overall lex-
ical entry.
</footnote>
<bodyText confidence="0.999515481481482">
dex, and then determines the language-specific an-
notations to instantiate for that template. The de-
fault position of the *-marker is the left-most oc-
currence of the LCS node corresponding to a par-
ticular thematic role. However, if a preposition oc-
curs in the grid, the *-marker may be placed dif-
ferently. In such a case, a primitive representation
(e.g., (to loc (at lc))) is extracted from a set
of predefined mappings. If this representation cor-
responds to a subcomponent of the LCS template,
the program recognizes this as a match against the
grid, and the *-marker is placed in the template at
the level where this match occurs (as in the entry
for cut ray given in (6) above).
If a preposition occurs in the grid but there is no
matching primitive representation, the preposition is
considered to be a. collocation, and it is placed in a
special slot—: collocations—which indicates that
the LCS already covers the semantics of the verb
and the preposition is an idiosyncratic variation (as
in learn about, know of, etc.).
If a preposition is required but it is not specified
(i.e., empty parentheses ()), then the *-marker is po-
sitioned at the level dominating the node that cor-
responds to that role—which indicates that several
different prepositions might apply (as in put on, put
under, put through, etc.).
</bodyText>
<subsectionHeader confidence="0.975557">
5.2 Examples
</subsectionHeader>
<bodyText confidence="0.996857857142857">
The input to LEXICALL is a class/grid/lexeme
specification, where each piece of information is sep-
arated by a hash sign (#):
&lt;class&gt;#&lt;grid&gt;#&lt;lexeme&gt;#
&lt;other semantic information&gt;
For example, the input specification for the verb re-
plant (a word not classified by Levin) is:
</bodyText>
<equation confidence="0.7512235">
9.7#_ag_th,mod-poss(with)#replant#
!!-ed = planted (manner = again)
</equation>
<bodyText confidence="0.9996239">
This input indicates that the class assigned to re-
plant is 9.7 (Levin&apos;s Spray/Load verbs) and its grid
has an obligatory agent (ag), theme (th), and an
optional possessional modifier with preposition with.
(mod-poss (with)). The information following the
final # is optional; this information was previously
hand-added to the assigned thematic grids. In the
current example, the ! !-ed designates the form of
the constant planted which, in this case, is a mor-
phological variant of the lexeme replant.7 Also, the
</bodyText>
<footnote confidence="0.780243714285714">
7The constant. takes one of several forms, including:
! !-ingly for a manner, ! !-er for an instrument, and
! !-ed for resulting states. If this information has not
been hand-added to the class/grid/lexeme specification
(as is the case with most of the verbs), a default mor-
phological process produces the appropriate form from
the lexeme.
</footnote>
<page confidence="0.998819">
143
</page>
<bodyText confidence="0.9994248">
manner again is specified as an additional semantic
component.
For presentational purposes, the remainder of this
section uses English examples. However, as we saw
in Section 4, the representations used here carry over
to other languages as well. In fact, we have used
the same acquisition program, without. modification,
for building our Spanish and Arabic LCS-based lex-
icons, each of size comparable to our English LCS-
based lexicon.
</bodyText>
<listItem confidence="0.87649875">
I. Thematic Roles without Prepositions
(9) Example: The flower decorated the room.
Input: 9.8#_mod-poss_th#decorate#
Template:
</listItem>
<bodyText confidence="0.923260875">
(be ident (thing 2)
(at ident (thing 2) (!!-ed 9))
(with poss (*head*) (thing 16)))
Two thematic roles, th and mod-poss, are specified
for the above sense of the English verb decorate. The
thematic code numbers-2 and 16, respectively are
*-marked and the constant decorated replaces the
wildcard:
</bodyText>
<listItem confidence="0.817220142857143">
(10) Output:
(be ident (* thing 2)
(at ident (thing 2) (decorated 9))
(with poss (*head*) (* thing 16)))
II. Thematic Roles with Unspecified Preposi-
tions
(11) Example: We parked the car near the store.
</listItem>
<bodyText confidence="0.995611">
We parked the car in the garage.
</bodyText>
<equation confidence="0.953590857142857">
Input: 9.1#_ag_th_goal()#park#
Template:
(cause (thing 1)
(go loc (thing 2)
(toward loc (thing 2)
([at] loc (thing 2) (thing 6))))
(!!-ingly 26))
</equation>
<bodyText confidence="0.999738888888889">
The input for this example indicates that the goal is
headed by an unspecified preposition. The thematic
roles ag, th, and goal() correspond to code num-
bers 1, 2, and 6, respectively. The variable positions
for ag and th are *-marked just as in the previous
case, whereas goal() requires a different treatment.
When a required preposition is left unspecified, the
*-marker is associated with a LCS node dominating
a generic [at] position:
</bodyText>
<listItem confidence="0.810718">
(12) Output:
</listItem>
<equation confidence="0.9525942">
(cause (* thing 1)
(go loc (* thing 2)
((* toward 5) loc (thing 2)
([at] loc (thing 2) (thing 6))))
(parkingly 26))}
</equation>
<bodyText confidence="0.7838675">
III. Thematic roles with Specified Preposi-
tions
</bodyText>
<listItem confidence="0.842661">
(13) Example: We decorated the room with flowers.
Input: 9.8#_ag_th ,mod-poss (with)#decoratelt
Template:
</listItem>
<equation confidence="0.69755">
(cause (thing 1)
(go ident (thing 2)
(toward ident (thing 2)
</equation>
<bodyText confidence="0.8798345">
(at ident (thing 2) (!!-ed 9))))
(with poss (*head*) (thing 16)))
Here, the mod-poss role requires the preposition
with in the modifier position:
</bodyText>
<listItem confidence="0.664667">
(14) Output:
</listItem>
<equation confidence="0.8806558">
(cause (* thing 1)
(go ident (* thing 2)
(toward ident (thing 2)
(at ident (thing 2) (decorated 9))))
((* with 15) poss (*head*) (thing 16)))
</equation>
<bodyText confidence="0.99896875">
In order to determine the position of the *-marker
for a thematic role with a required preposition,
LEXICALL consults a set of predefined mappings
between prepositions (or postpositions, in a lan-
guage like Korean) and their corresponding primi-
tive representations.8 In the current case, the prepo-
sition with is mapped to the following primitive rep-
resentation: (with poss). Since this matches a
sub-component of the LCS template, the program
recognizes this as a match against the grid, and the
*-marker is placed in the template at the level of
with.
</bodyText>
<sectionHeader confidence="0.937597" genericHeader="conclusions">
6 Limitations and Conclusions
</sectionHeader>
<bodyText confidence="0.957098">
We have described techniques for automatic con-
struction of dictionaries for use in large-scale
FLT. The dictionaries are based on a language-
independent representation called lexical conceptual
structure (LCS). Significant enhancements to LCS-
based tutoring could be achieved by combining this
representation with a mechanism for handling issues
related to discourse and pragmatics. For example,
although the LCS processor is capable of determin-
ing that the phrase in the trash partially matches the
answer to Where did John put the book?, a prag-
matic component would be required to determine
that this answer is (perhaps) more appropriate than
the full answer, He put the book in the trash. Repre-
senting conversational context and dynamic context
updating (Traum et al., 1996; Haller, 1996; DiEu-
genio and Webber, 1996) would provide a frame-
work for this type of response &amp;quot;relaxation.&amp;quot; Along
8We have defined approximately 100 such mappings
per language. For example, the mapping produces
the following primitive representations for the English
word to: (to loc (at lc)), (to poss (at poss)),
(to temp (at temp)), (toward loc (at lc)),
(toward poss (at poss)). We have similar mappings
defined in Arabic and Spanish. For example, the follow-
ing primitive representations are produced for the Span-
ish word o: (at lc), (to loc (at lc)), (to poss
(at poss)), (toward loc (at lc)).
</bodyText>
<page confidence="0.997238">
144
</page>
<bodyText confidence="0.999969021276596">
these same lines, a pragmatic component could pro-
vide a. mechanism for determining that certain fully
matched responses (e.g John hurled the book into
the trash) are not as &amp;quot;realistic sounding&amp;quot; as partially
matched alternatives.
Initially, LEXICALL was designed to support the
development of LCS&apos;s for English only; however, the
same techniques can be used for multilingual acquisi-
tion. As the lexicon covera.ge for other languages ex-
pands, it is expected that our acquisition techniques
will help further in the cross-linguistic investigation
of the relationship between Levin &apos;s verb classes and
the basic meaning components in the LCS represen-
tation. In addition, it is expected that verbs in the
same Levin class may have finer distinctions than
what we have specified in the current LCS templates.
We view the importation of LCS&apos;s from the En-
glish LCS database into Arabic and Spanish as
a first approximation to the development of com-
plete lexicons for these languages. The results have
been hand-checked by native speakers using the
class/grid/lexeme format (which is much easier to
check than the fully expanded LCS&apos;s). The lexical
verification process took only two weeks by the na-
tive speakers. We estimate that. it. would take at
least. 6 months to build such a lexicon from scratch
(by human recall and data entry alone), and in such
a case, the potential for error would be at least twice
as high.
One important benefit of using the Levin classi-
fication as the basis of our program is that, once
the mapping between verb classes and LCS repre-
sentations has been established, we can acquire the
LCS representation for a. new verb (i.e., one not in
Levin) simply by associating it with one of the 191
classes. We see our approach as a first step toward
compression of lexical entries in that it allows lex-
icons to be stored in terms of the more condensed
class/grid/lexeme specifications; these can expanded
online, as needed, during sentence processing in the
NLP application.
We conclude that, while human intervention is
necessary for the acquisition of class/grid informa-
tion, this intervention is virtually eliminated from
the LCS construction process because of our pro-
vision of a mapping between semantic classes and
primitive meaning components.
</bodyText>
<sectionHeader confidence="0.998044" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.939428">
I would like to thank Jungshin Park and Mine Ulku
Sencan for their aid in the development of certain
components of the LEXICALL program. In ad-
dition, comments from five anonymous reviewers
greatly enhanced the presentation of this work. The
author has been supported, in part, by Army Re-
search Office contract DAAL03-91-C-0034 through
Battelle Corporation, NSF NYI IRI-9357731 and
Logos Corporation, NSF CNRS INT-9314583, Ad-
vanced Research Projects Agency and ONR contract
N00014-92-J-1929, Alfred P. Sloan Research Fellow
Award BR.3336, Army Research Institute contract
MDA-903-92-R-0035 and Microelectronics and De-
sign, Inc., and the University of Maryland General
Research Board.
</bodyText>
<sectionHeader confidence="0.99219" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999868869565217">
Brent, Michael. 1993. Unsupervised Learning
of Lexical Syntax. Computational Linguistics,
19:243-262.
Carrier, Jill and Janet H. Randall. 1993. Lexical
mapping. In Eric Reuland and Werner Abraham,
editors, Knowledge and Language II: Lexical and
Conceptual Structure. Kluwer, Dordrecht, pages
119-142.
Church, Kenneth and P. Hanks. 1990. Word Asso-
ciation Norms, Mutual Information and Lexicog-
raphy. Computational Linguistics, 16:22-29.
Copestake, Ann, Ted Briscoe, P. Vossen, A. Ageno,
I. Castellon, F. Ribas, G. Rigau, H. Rodriguez,
and A. Samiotou. 1995. Acquisition of Lexi-
cal Translation Relations from MRDS. Machine
Translation, 9:183-219.
DiEugenio, Barbara and Bonnie Lynn Webber.
1996. Pragmatic Overloading in Natural Lan-
guage Instructions. International Journal of Ex-
pert Systems, 9(1):53-84.
Dorr, Bonnie J. To appear. Large-Scale Dictio-
nary Construction for Foreign Language Tutoring
and Interlingual Machine Translation. Machine
Translation, 12(1).
Dorr, Bonnie J., Joseph Garman, and Amy Wein-
berg. 1995. From Syntactic Encodings to The-
matic Roles: Building Lexical Entries for Interlin-
gual MT. Machine Translation, 9:71-100.
Dorr, Bonnie J. and Douglas Jones. 1996. Role
of Word Sense Disambiguation in Lexical Ac-
quisition: Predicting Semantics from Syntactic
Cues. In Proceedings of the International Con-
ference on Computational Linguistics, pages 322-
333, Copenhagen, Denmark.
Dowty, David. 1991. The Effects of Aspectual Class
on the Temporal Structure of Discourse: Seman-
tics or Pragmatics? Language, 67:547-619.
Fillmore, Charles. 1968. The Case for Case. In
E. Bach and R. Harms, editors, Universals in,
Linguistic Theory. Holt, Rinehart, and Winston,
pages 1-88.
Foley, William A. and Robert D. Van Valin. 1984.
Functional Syntax and Universal Grammar. Cam-
bridge University Press, Cambridge.
Grimsha.w, Jane. 1990. Argument Structure. MIT
Press. Cambridge, MA.
</reference>
<page confidence="0.986442">
145
</page>
<reference confidence="0.9995498125">
Grimshaw, Jane. 1993. Semantic Structure
and Semantic Content. in Lexical Representa-
tion. unpublished ms., Rutgers University, New
Brunswick, NJ.
Gruber, Jeffrey S. 1965. Studies in Lexical Rela-
tions. Ph.D. thesis, MIT, Cambridge, MA.
Hale,. Ken and Samuel J. Keyser. 1993. On Argu-
ment Structure and Lexical Expression of Syntac-
tic Relations. In Ken Hale and Samuel J. Keyser,
editors, The View from Building 20: Essays in.
Honor of Sylvain Bromberger. MIT Press, Cam-
bridge, MA.
Haller, Susan. 1996. Planning Text About Plans In-
teractively. International Journal of Expert Sys-
tems, 9(1):85-112.
Holland, Melissa. 1994. Intelligent Tutors for For-
eign Languages: How Parsers and Lexical Se-
mantics can Help Learners and Assess Learning.
In Proceedings of the Educational Testing Service
Conference on Natural Language Processing Tech-
niques and Technology in Assessment and Educa-
tion, Princeton, NJ: ETS.
Jackendoff, Ray. 1983. Semantics and Cognition..
MIT Press, Cambridge, MA.
Jackendoff, Ray. 1990. Semantic Structures. MIT
Press, Cambridge, MA.
Jackendoff, Ray. 1996. The Proper Treatment of
Measuring Out, Telicity, and Perhaps Even Quan-
tification in English. Natural Language and Lin-
guistic Theory, 14:305-354.
Klavans, Judith L. and Evelynne Tzoukermann.
1995. Dictionaries and Corpora: Combining Cor-
pus and Machine-Readable Dictionary Data. for
Building Bilingual Lexicons. Machine Transla-
tion, 10:185-218.
Levin, Beth. 1993. English Verb Classes and Alter-
nations: A Preliminary Investigation. Chicago,
IL.
Levin, Beth and Malka Rappaport Hovav. To ap-
pear. Building Verb Meanings. In M. Butt and
W. Gauder, editors, The Projection. of Arguments:
Lexical and Syntactic Constraints. CSLI.
Lonsdale, Deryle, Teruko Mita.mura., and Eric Ny-
berg. 1995. Acquisition of Large Lexicons for
Practical Knowledge-Based MT. Machine Trans-
lation, 9:251-283.
Pesetsky, David. 1982. Paths and Categories. Ph.D.
thesis, MIT, Cambridge, MA.
Pinker, Steven. 1989. Learnability and Cognition:
The Acquisition of Argument Structure. MIT
Press, Cambridge, MA.
Sams, Michelle. 1993. An Intelligent Foreign Lan-
guage Tutor Incorporating Natural Language Pro-
cessing. In Proceedings of Conference on Intelli-
gent Computer-Aided Training and Virtual Envi-
ronment Technology, NASA: Houston, TX.
Talmy, Leonard. 1985. Lexicalization Patterns: Se-
mantic Structure in Lexical Forms. In T. Shopen,
editor, Language Typology and Syntactic Descrip-
tion. 3: Grammatical Categories and the Lexicon.
University Press, Cambridge, England, pages 57-
149.
Traum,
David R., Lenhart K. Schu-
bert, Nathaniel G. Martin, Chung Hee Hwang, Pe-
ter Heeman, George Ferguson, James Allen, Mas-
simo Poesio, and Marc Light. 1996. Knowledge
Representation in the TRAINS-93 Conversation
System. International Journal of Expert Systems,
9(1):173-223.
Weinberg, Amy, Joseph Garman, Jeffery Martin,
and Paola Merlo. 1995. Principle-Based Parser
for Foreign Language Training in German and
Arabic. In Melissa Holland, Jonathan Kaplan,
and Michelle Sams, editors, Intelligent Language
Tutors: Theory Shaping Technology. Lawrence
Erlbaum Associates, Hillsdale, NJ.
Wu, D. and X. Xia. 1995. Large-Scale Automatic
Extraction of an English-Chinese Translation Lex-
icon. Machine Translation, 9:285-313.
</reference>
<page confidence="0.998819">
146
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.978013">
<title confidence="0.9982965">Large-Scale Acquisition of LCS-Based Lexicons for Foreign Language Tutoring</title>
<author confidence="0.999997">Bonnie J Dorr</author>
<affiliation confidence="0.999987">Department of Computer Science University of Maryland</affiliation>
<address confidence="0.999922">College Park, MD 20742, USA</address>
<email confidence="0.999827">bonnieOcs.umd.edu</email>
<abstract confidence="0.998972388888889">We focus on the problem of building large of conceptual structure (LCS) representations for verbs in multiple languages. One of the main results of this work is the definition of a relation between broad semantic classes and meaning components. Our acquisiprogram—LEXICALL takes, as put, the result of previous work on verb classification and thematic grid tagging, and outputs LCS representations for different languages. These representations have been ported into English, Arabic and Spanish lexicons, each containing approximately 9000 verbs. We are currently using these lexicons in an operational foreign language tutoring and machine translation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michael Brent</author>
</authors>
<date>1993</date>
<booktitle>Unsupervised Learning of Lexical Syntax. Computational Linguistics,</booktitle>
<pages>19--243</pages>
<contexts>
<context position="4817" citStr="Brent, 1993" startWordPosition="769" endWordPosition="770"> U.S. A.R.MY RESEARCH INSTITUTE &apos;l Ott Execute Comm heck Answer Dorr, To appear) and tagged with thematic grid information (Dorr, Garman, and Weinberg, 1995). We use these pre-assigned classes and thematic grids as input to LEXICALL. The output is a set of LCS&apos;s corresponding to individual verb entries in our lexicon. Previous research in automatic acquisition focuses primarily on the use of statistical techniques, such as bilingual alignment (Church and Hanks, 1990; Kiavans and Tzoukermann, 1995; Wu and Xia, 1995) or extraction of syntactic constructions from online dictionaries and corpora (Brent, 1993). Others have taken a more knowledge-based (interlingual) approach (Lonsdale, Mitamura, and Nyberg, 1995). Still others (Copestake et al., 1995), use Englishbased grammatical codes for acquisition of lexical representations. Our approach differs from these in that it exploits certain linguistic constraints that govern the relation between a word&apos;s surface behavior and its corresponding semantic class. We demonstrate that— by assigning a LCS representation to each semantic class we can produce verb entries on a broad scale; these, in turn, are ported into multiple languages. We first show how t</context>
</contexts>
<marker>Brent, 1993</marker>
<rawString>Brent, Michael. 1993. Unsupervised Learning of Lexical Syntax. Computational Linguistics, 19:243-262.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jill Carrier</author>
<author>Janet H Randall</author>
</authors>
<title>Lexical mapping.</title>
<date>1993</date>
<booktitle>Knowledge and Language II: Lexical and Conceptual Structure.</booktitle>
<pages>119--142</pages>
<editor>In Eric Reuland and Werner Abraham, editors,</editor>
<publisher>Kluwer,</publisher>
<location>Dordrecht,</location>
<contexts>
<context position="1083" citStr="Carrier and Randall, 1993" startWordPosition="158" endWordPosition="161">components. Our acquisition program—LEXICALL takes, as input, the result of previous work on verb classification and thematic grid tagging, and outputs LCS representations for different languages. These representations have been ported into English, Arabic and Spanish lexicons, each containing approximately 9000 verbs. We are currently using these lexicons in an operational foreign language tutoring and machine translation. 1 Introduction A wide range of new capabilities in NLP applications such as foreign language tutoring (FLT) has been made possible by recent advances in lexical semantics (Carrier and Randall, 1993; Dowty, 1991; Fillmore, 1968; Foley and Van Valin, 1984; Grimshaw, 1990; Gruber, 1965; Hale and Keyser, 1993; Jackendoff, 1983; Jackendoff, 1990; Jackendoff, 1996; Levin, 1993; Levin and Rappaport Hova.v, To appear; Pesetsky, 1982; Pinker, 1989). Many of these researchers adopt the hypothesis that verbs can be grouped into broad classes, each of which corresponds to some combination of basic meaning components. This is the basic premise underlying our approach to multilingual lexicon construction. In particular, we have organized verbs into broad semantic classes and subsequently designed a s</context>
</contexts>
<marker>Carrier, Randall, 1993</marker>
<rawString>Carrier, Jill and Janet H. Randall. 1993. Lexical mapping. In Eric Reuland and Werner Abraham, editors, Knowledge and Language II: Lexical and Conceptual Structure. Kluwer, Dordrecht, pages 119-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
<author>P Hanks</author>
</authors>
<date>1990</date>
<journal>Word Association Norms, Mutual Information and Lexicography. Computational Linguistics,</journal>
<pages>16--22</pages>
<contexts>
<context position="4675" citStr="Church and Hanks, 1990" startWordPosition="745" endWordPosition="748">s. We build on previous work, where verbs were classified automatically (Dorr and Jones, 1996; 139 Figure 1: MicroWorld Lesson in MILT MicroWorld Lesson U.S. A.R.MY RESEARCH INSTITUTE &apos;l Ott Execute Comm heck Answer Dorr, To appear) and tagged with thematic grid information (Dorr, Garman, and Weinberg, 1995). We use these pre-assigned classes and thematic grids as input to LEXICALL. The output is a set of LCS&apos;s corresponding to individual verb entries in our lexicon. Previous research in automatic acquisition focuses primarily on the use of statistical techniques, such as bilingual alignment (Church and Hanks, 1990; Kiavans and Tzoukermann, 1995; Wu and Xia, 1995) or extraction of syntactic constructions from online dictionaries and corpora (Brent, 1993). Others have taken a more knowledge-based (interlingual) approach (Lonsdale, Mitamura, and Nyberg, 1995). Still others (Copestake et al., 1995), use Englishbased grammatical codes for acquisition of lexical representations. Our approach differs from these in that it exploits certain linguistic constraints that govern the relation between a word&apos;s surface behavior and its corresponding semantic class. We demonstrate that— by assigning a LCS representatio</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Church, Kenneth and P. Hanks. 1990. Word Association Norms, Mutual Information and Lexicography. Computational Linguistics, 16:22-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Ted Briscoe</author>
<author>P Vossen</author>
<author>A Ageno</author>
<author>I Castellon</author>
<author>F Ribas</author>
<author>G Rigau</author>
<author>H Rodriguez</author>
<author>A Samiotou</author>
</authors>
<date>1995</date>
<booktitle>Acquisition of Lexical Translation Relations from MRDS. Machine Translation,</booktitle>
<pages>9--183</pages>
<contexts>
<context position="4961" citStr="Copestake et al., 1995" startWordPosition="786" endWordPosition="789">man, and Weinberg, 1995). We use these pre-assigned classes and thematic grids as input to LEXICALL. The output is a set of LCS&apos;s corresponding to individual verb entries in our lexicon. Previous research in automatic acquisition focuses primarily on the use of statistical techniques, such as bilingual alignment (Church and Hanks, 1990; Kiavans and Tzoukermann, 1995; Wu and Xia, 1995) or extraction of syntactic constructions from online dictionaries and corpora (Brent, 1993). Others have taken a more knowledge-based (interlingual) approach (Lonsdale, Mitamura, and Nyberg, 1995). Still others (Copestake et al., 1995), use Englishbased grammatical codes for acquisition of lexical representations. Our approach differs from these in that it exploits certain linguistic constraints that govern the relation between a word&apos;s surface behavior and its corresponding semantic class. We demonstrate that— by assigning a LCS representation to each semantic class we can produce verb entries on a broad scale; these, in turn, are ported into multiple languages. We first show how the LCS is used in a FLT system. We then present an overview of the LCS acquisition process. Finally, we describe how LEXICALL constructs entries</context>
</contexts>
<marker>Copestake, Briscoe, Vossen, Ageno, Castellon, Ribas, Rigau, Rodriguez, Samiotou, 1995</marker>
<rawString>Copestake, Ann, Ted Briscoe, P. Vossen, A. Ageno, I. Castellon, F. Ribas, G. Rigau, H. Rodriguez, and A. Samiotou. 1995. Acquisition of Lexical Translation Relations from MRDS. Machine Translation, 9:183-219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara DiEugenio</author>
<author>Bonnie Lynn Webber</author>
</authors>
<title>Pragmatic Overloading in Natural Language Instructions.</title>
<date>1996</date>
<journal>International Journal of Expert Systems,</journal>
<pages>9--1</pages>
<contexts>
<context position="23606" citStr="DiEugenio and Webber, 1996" startWordPosition="3842" endWordPosition="3846">al structure (LCS). Significant enhancements to LCSbased tutoring could be achieved by combining this representation with a mechanism for handling issues related to discourse and pragmatics. For example, although the LCS processor is capable of determining that the phrase in the trash partially matches the answer to Where did John put the book?, a pragmatic component would be required to determine that this answer is (perhaps) more appropriate than the full answer, He put the book in the trash. Representing conversational context and dynamic context updating (Traum et al., 1996; Haller, 1996; DiEugenio and Webber, 1996) would provide a framework for this type of response &amp;quot;relaxation.&amp;quot; Along 8We have defined approximately 100 such mappings per language. For example, the mapping produces the following primitive representations for the English word to: (to loc (at lc)), (to poss (at poss)), (to temp (at temp)), (toward loc (at lc)), (toward poss (at poss)). We have similar mappings defined in Arabic and Spanish. For example, the following primitive representations are produced for the Spanish word o: (at lc), (to loc (at lc)), (to poss (at poss)), (toward loc (at lc)). 144 these same lines, a pragmatic componen</context>
</contexts>
<marker>DiEugenio, Webber, 1996</marker>
<rawString>DiEugenio, Barbara and Bonnie Lynn Webber. 1996. Pragmatic Overloading in Natural Language Instructions. International Journal of Expert Systems, 9(1):53-84.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Bonnie J Dorr</author>
</authors>
<title>To appear. Large-Scale Dictionary Construction for Foreign Language Tutoring and Interlingual Machine Translation.</title>
<journal>Machine Translation,</journal>
<volume>12</volume>
<issue>1</issue>
<marker>Dorr, </marker>
<rawString>Dorr, Bonnie J. To appear. Large-Scale Dictionary Construction for Foreign Language Tutoring and Interlingual Machine Translation. Machine Translation, 12(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
<author>Joseph Garman</author>
<author>Amy Weinberg</author>
</authors>
<title>From Syntactic Encodings to Thematic Roles: Building Lexical Entries for Interlingual MT.</title>
<date>1995</date>
<journal>Machine Translation,</journal>
<pages>9--71</pages>
<contexts>
<context position="4361" citStr="Dorr, Garman, and Weinberg, 1995" startWordPosition="695" endWordPosition="699">ct LCS-based lexicons for the FLT system. This program is designed to be used for multiple languages, and also for other NLP applications (e.g., machine translation). One of the main results of this work is the definition of a relation between broad semantic classes (based on work by Levin (1993)) and LCS meaning components. We build on previous work, where verbs were classified automatically (Dorr and Jones, 1996; 139 Figure 1: MicroWorld Lesson in MILT MicroWorld Lesson U.S. A.R.MY RESEARCH INSTITUTE &apos;l Ott Execute Comm heck Answer Dorr, To appear) and tagged with thematic grid information (Dorr, Garman, and Weinberg, 1995). We use these pre-assigned classes and thematic grids as input to LEXICALL. The output is a set of LCS&apos;s corresponding to individual verb entries in our lexicon. Previous research in automatic acquisition focuses primarily on the use of statistical techniques, such as bilingual alignment (Church and Hanks, 1990; Kiavans and Tzoukermann, 1995; Wu and Xia, 1995) or extraction of syntactic constructions from online dictionaries and corpora (Brent, 1993). Others have taken a more knowledge-based (interlingual) approach (Lonsdale, Mitamura, and Nyberg, 1995). Still others (Copestake et al., 1995)</context>
</contexts>
<marker>Dorr, Garman, Weinberg, 1995</marker>
<rawString>Dorr, Bonnie J., Joseph Garman, and Amy Weinberg. 1995. From Syntactic Encodings to Thematic Roles: Building Lexical Entries for Interlingual MT. Machine Translation, 9:71-100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
<author>Douglas Jones</author>
</authors>
<title>Role of Word Sense Disambiguation in Lexical Acquisition: Predicting Semantics from Syntactic Cues.</title>
<date>1996</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics,</booktitle>
<pages>322--333</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="4146" citStr="Dorr and Jones, 1996" startWordPosition="662" endWordPosition="665">ystem is able to match against the prestored LCS a.nd determine that all three of these responses are semantically appropriate. We have developed an acquisition program LEXICALL that allows us to construct LCS-based lexicons for the FLT system. This program is designed to be used for multiple languages, and also for other NLP applications (e.g., machine translation). One of the main results of this work is the definition of a relation between broad semantic classes (based on work by Levin (1993)) and LCS meaning components. We build on previous work, where verbs were classified automatically (Dorr and Jones, 1996; 139 Figure 1: MicroWorld Lesson in MILT MicroWorld Lesson U.S. A.R.MY RESEARCH INSTITUTE &apos;l Ott Execute Comm heck Answer Dorr, To appear) and tagged with thematic grid information (Dorr, Garman, and Weinberg, 1995). We use these pre-assigned classes and thematic grids as input to LEXICALL. The output is a set of LCS&apos;s corresponding to individual verb entries in our lexicon. Previous research in automatic acquisition focuses primarily on the use of statistical techniques, such as bilingual alignment (Church and Hanks, 1990; Kiavans and Tzoukermann, 1995; Wu and Xia, 1995) or extraction of syn</context>
<context position="13383" citStr="Dorr and Jones, 1996" startWordPosition="2175" endWordPosition="2178"> of a verb class (in the spirit of (Grimshaw, 1993; Levin and Rappaport Hovav, To appear; Pinker, 1989; Talmy, 1985)).4 Three inputs are required for acquisition of verb entries: a semantic class, a thematic grid, and a lexeme, which we will henceforth abbreviate as &amp;quot;class/grid/lexeme.&amp;quot; The output is a Lisp-like expression corresponding to the LCS representation. An example of input/output for our acquisition procedure is shown here: (4) Acquisition of LCS for: touch Input: 47.8; _th_loc; &amp;quot;touch&amp;quot; 2 Verbs not occurring in Levin&apos;s book are also assigned to classes using techniques described in (Dorr and Jones, 1996; Dorr, To appear). 3An underscore (_) designates an obligatory role and a comma (,) designates an optional role. 4The ! ! in the Lisp representation corresponds to the angle-bracketed constants in Table 2. e.g., ! !-ingly corresponds to (MANNER). Output: (be loc (* thing 2) (at loc (thing 2) (* thing 11)) (touchingly 26)) Language-specific annotations such as the *-marker in the LCS Output are added to the templates by processing the components of thematic grid specifications, as we will see in more detail next. 4 Language-Specific Annotations In our on-going example (4), the thematic grid _t</context>
</contexts>
<marker>Dorr, Jones, 1996</marker>
<rawString>Dorr, Bonnie J. and Douglas Jones. 1996. Role of Word Sense Disambiguation in Lexical Acquisition: Predicting Semantics from Syntactic Cues. In Proceedings of the International Conference on Computational Linguistics, pages 322-333, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Dowty</author>
</authors>
<title>The Effects of Aspectual Class on the Temporal Structure of Discourse: Semantics or Pragmatics? Language,</title>
<date>1991</date>
<pages>67--547</pages>
<contexts>
<context position="1096" citStr="Dowty, 1991" startWordPosition="162" endWordPosition="163"> program—LEXICALL takes, as input, the result of previous work on verb classification and thematic grid tagging, and outputs LCS representations for different languages. These representations have been ported into English, Arabic and Spanish lexicons, each containing approximately 9000 verbs. We are currently using these lexicons in an operational foreign language tutoring and machine translation. 1 Introduction A wide range of new capabilities in NLP applications such as foreign language tutoring (FLT) has been made possible by recent advances in lexical semantics (Carrier and Randall, 1993; Dowty, 1991; Fillmore, 1968; Foley and Van Valin, 1984; Grimshaw, 1990; Gruber, 1965; Hale and Keyser, 1993; Jackendoff, 1983; Jackendoff, 1990; Jackendoff, 1996; Levin, 1993; Levin and Rappaport Hova.v, To appear; Pesetsky, 1982; Pinker, 1989). Many of these researchers adopt the hypothesis that verbs can be grouped into broad classes, each of which corresponds to some combination of basic meaning components. This is the basic premise underlying our approach to multilingual lexicon construction. In particular, we have organized verbs into broad semantic classes and subsequently designed a set of lexical</context>
</contexts>
<marker>Dowty, 1991</marker>
<rawString>Dowty, David. 1991. The Effects of Aspectual Class on the Temporal Structure of Discourse: Semantics or Pragmatics? Language, 67:547-619.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Fillmore</author>
</authors>
<title>The Case for Case.</title>
<date>1968</date>
<pages>1--88</pages>
<editor>In E. Bach and R. Harms, editors, Universals in, Linguistic Theory. Holt, Rinehart, and Winston,</editor>
<contexts>
<context position="1112" citStr="Fillmore, 1968" startWordPosition="164" endWordPosition="166">CALL takes, as input, the result of previous work on verb classification and thematic grid tagging, and outputs LCS representations for different languages. These representations have been ported into English, Arabic and Spanish lexicons, each containing approximately 9000 verbs. We are currently using these lexicons in an operational foreign language tutoring and machine translation. 1 Introduction A wide range of new capabilities in NLP applications such as foreign language tutoring (FLT) has been made possible by recent advances in lexical semantics (Carrier and Randall, 1993; Dowty, 1991; Fillmore, 1968; Foley and Van Valin, 1984; Grimshaw, 1990; Gruber, 1965; Hale and Keyser, 1993; Jackendoff, 1983; Jackendoff, 1990; Jackendoff, 1996; Levin, 1993; Levin and Rappaport Hova.v, To appear; Pesetsky, 1982; Pinker, 1989). Many of these researchers adopt the hypothesis that verbs can be grouped into broad classes, each of which corresponds to some combination of basic meaning components. This is the basic premise underlying our approach to multilingual lexicon construction. In particular, we have organized verbs into broad semantic classes and subsequently designed a set of lexical conceptual stru</context>
</contexts>
<marker>Fillmore, 1968</marker>
<rawString>Fillmore, Charles. 1968. The Case for Case. In E. Bach and R. Harms, editors, Universals in, Linguistic Theory. Holt, Rinehart, and Winston, pages 1-88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Foley</author>
<author>Robert D Van Valin</author>
</authors>
<title>Functional Syntax and Universal Grammar.</title>
<date>1984</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<marker>Foley, Van Valin, 1984</marker>
<rawString>Foley, William A. and Robert D. Van Valin. 1984. Functional Syntax and Universal Grammar. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Grimsha w</author>
</authors>
<title>Argument Structure.</title>
<date>1990</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1155" citStr="w, 1990" startWordPosition="172" endWordPosition="173">on verb classification and thematic grid tagging, and outputs LCS representations for different languages. These representations have been ported into English, Arabic and Spanish lexicons, each containing approximately 9000 verbs. We are currently using these lexicons in an operational foreign language tutoring and machine translation. 1 Introduction A wide range of new capabilities in NLP applications such as foreign language tutoring (FLT) has been made possible by recent advances in lexical semantics (Carrier and Randall, 1993; Dowty, 1991; Fillmore, 1968; Foley and Van Valin, 1984; Grimshaw, 1990; Gruber, 1965; Hale and Keyser, 1993; Jackendoff, 1983; Jackendoff, 1990; Jackendoff, 1996; Levin, 1993; Levin and Rappaport Hova.v, To appear; Pesetsky, 1982; Pinker, 1989). Many of these researchers adopt the hypothesis that verbs can be grouped into broad classes, each of which corresponds to some combination of basic meaning components. This is the basic premise underlying our approach to multilingual lexicon construction. In particular, we have organized verbs into broad semantic classes and subsequently designed a set of lexical conceptual structures (LCS), for each class. These represe</context>
</contexts>
<marker>w, 1990</marker>
<rawString>Grimsha.w, Jane. 1990. Argument Structure. MIT Press. Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Grimshaw</author>
</authors>
<title>Semantic Structure and Semantic Content. in Lexical Representation. unpublished ms.,</title>
<date>1993</date>
<institution>Rutgers University,</institution>
<location>New Brunswick, NJ.</location>
<contexts>
<context position="12813" citStr="Grimshaw, 1993" startWordPosition="2088" endWordPosition="2089">evin&apos;s 1993 book (Verbs of Contiguous Location), i.e., the class to which the verb touch has been assigned.2 A verb, together with its semantic class uniquely identifies the word sense, or LCS template, to which the verb refers. The thematic grid (_th_loc) indicates that the verb has two obligatory arguments, a theme and a location.&apos; The ! ! in the LCS Template acts as a wildcard; it will be filled by a lexeme (i.e., a root form of the verb). The resulting form is called a constant, i.e., the idiosyncratic part of the meaning that distinguishes among members of a verb class (in the spirit of (Grimshaw, 1993; Levin and Rappaport Hovav, To appear; Pinker, 1989; Talmy, 1985)).4 Three inputs are required for acquisition of verb entries: a semantic class, a thematic grid, and a lexeme, which we will henceforth abbreviate as &amp;quot;class/grid/lexeme.&amp;quot; The output is a Lisp-like expression corresponding to the LCS representation. An example of input/output for our acquisition procedure is shown here: (4) Acquisition of LCS for: touch Input: 47.8; _th_loc; &amp;quot;touch&amp;quot; 2 Verbs not occurring in Levin&apos;s book are also assigned to classes using techniques described in (Dorr and Jones, 1996; Dorr, To appear). 3An unders</context>
</contexts>
<marker>Grimshaw, 1993</marker>
<rawString>Grimshaw, Jane. 1993. Semantic Structure and Semantic Content. in Lexical Representation. unpublished ms., Rutgers University, New Brunswick, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey S Gruber</author>
</authors>
<date>1965</date>
<booktitle>Studies in Lexical Relations. Ph.D. thesis, MIT,</booktitle>
<location>Cambridge, MA.</location>
<contexts>
<context position="1169" citStr="Gruber, 1965" startWordPosition="174" endWordPosition="175">lassification and thematic grid tagging, and outputs LCS representations for different languages. These representations have been ported into English, Arabic and Spanish lexicons, each containing approximately 9000 verbs. We are currently using these lexicons in an operational foreign language tutoring and machine translation. 1 Introduction A wide range of new capabilities in NLP applications such as foreign language tutoring (FLT) has been made possible by recent advances in lexical semantics (Carrier and Randall, 1993; Dowty, 1991; Fillmore, 1968; Foley and Van Valin, 1984; Grimshaw, 1990; Gruber, 1965; Hale and Keyser, 1993; Jackendoff, 1983; Jackendoff, 1990; Jackendoff, 1996; Levin, 1993; Levin and Rappaport Hova.v, To appear; Pesetsky, 1982; Pinker, 1989). Many of these researchers adopt the hypothesis that verbs can be grouped into broad classes, each of which corresponds to some combination of basic meaning components. This is the basic premise underlying our approach to multilingual lexicon construction. In particular, we have organized verbs into broad semantic classes and subsequently designed a set of lexical conceptual structures (LCS), for each class. These representations have </context>
</contexts>
<marker>Gruber, 1965</marker>
<rawString>Gruber, Jeffrey S. 1965. Studies in Lexical Relations. Ph.D. thesis, MIT, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken</author>
<author>Samuel J Keyser</author>
</authors>
<title>On Argument Structure and Lexical Expression of Syntactic Relations.</title>
<date>1993</date>
<booktitle>The View from Building 20: Essays in. Honor of Sylvain Bromberger.</booktitle>
<editor>In Ken Hale and Samuel J. Keyser, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Ken, Keyser, 1993</marker>
<rawString>Hale,. Ken and Samuel J. Keyser. 1993. On Argument Structure and Lexical Expression of Syntactic Relations. In Ken Hale and Samuel J. Keyser, editors, The View from Building 20: Essays in. Honor of Sylvain Bromberger. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Haller</author>
</authors>
<title>Planning Text About Plans Interactively.</title>
<date>1996</date>
<journal>International Journal of Expert Systems,</journal>
<pages>9--1</pages>
<contexts>
<context position="23577" citStr="Haller, 1996" startWordPosition="3840" endWordPosition="3841">xical conceptual structure (LCS). Significant enhancements to LCSbased tutoring could be achieved by combining this representation with a mechanism for handling issues related to discourse and pragmatics. For example, although the LCS processor is capable of determining that the phrase in the trash partially matches the answer to Where did John put the book?, a pragmatic component would be required to determine that this answer is (perhaps) more appropriate than the full answer, He put the book in the trash. Representing conversational context and dynamic context updating (Traum et al., 1996; Haller, 1996; DiEugenio and Webber, 1996) would provide a framework for this type of response &amp;quot;relaxation.&amp;quot; Along 8We have defined approximately 100 such mappings per language. For example, the mapping produces the following primitive representations for the English word to: (to loc (at lc)), (to poss (at poss)), (to temp (at temp)), (toward loc (at lc)), (toward poss (at poss)). We have similar mappings defined in Arabic and Spanish. For example, the following primitive representations are produced for the Spanish word o: (at lc), (to loc (at lc)), (to poss (at poss)), (toward loc (at lc)). 144 these sam</context>
</contexts>
<marker>Haller, 1996</marker>
<rawString>Haller, Susan. 1996. Planning Text About Plans Interactively. International Journal of Expert Systems, 9(1):85-112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Melissa Holland</author>
</authors>
<title>Intelligent Tutors for Foreign Languages: How Parsers and Lexical Semantics can Help Learners and Assess Learning.</title>
<date>1994</date>
<booktitle>In Proceedings of the Educational Testing Service Conference on Natural Language Processing Techniques and Technology in Assessment and Education,</booktitle>
<publisher>ETS.</publisher>
<location>Princeton, NJ:</location>
<contexts>
<context position="10138" citStr="Holland, 1994" startWordPosition="1646" endWordPosition="1647">nt. The system must convert this information into meaningful feedback so that the student knows how to repair the answer that was originally given. For example, the instructor can program the tutor to notify the student about the omitted information in the form of a &apos;How&apos; question, or it can choose to ignore it. The extra information is generally ignored, although it is recorded in case the instructor decides to program the system to notify the student about this as well. The full range of feedback is not presented here. Some possibilities are summarized (in English) in Table 1 (adapted from (Holland, 1994)). Note that the main advantage of using the LCS is that it allows the author to type in an answer that is general enough to match any number of additional answers. 3 Overview of LCS Acquisition We use Levin&apos;s publicly available online index (Levin, 1993) as a starting point for building LCSbased verb entries.&apos; While this index provides a unique and extensive catalog of verb classes, it does not define the underlying meaning components of each class. One of the main contributions of our work is that it provides a relation between Levin&apos;s classes and meaning components as defined in the LCS rep</context>
</contexts>
<marker>Holland, 1994</marker>
<rawString>Holland, Melissa. 1994. Intelligent Tutors for Foreign Languages: How Parsers and Lexical Semantics can Help Learners and Assess Learning. In Proceedings of the Educational Testing Service Conference on Natural Language Processing Techniques and Technology in Assessment and Education, Princeton, NJ: ETS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>Semantics and Cognition..</title>
<date>1983</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1210" citStr="Jackendoff, 1983" startWordPosition="180" endWordPosition="182">ng, and outputs LCS representations for different languages. These representations have been ported into English, Arabic and Spanish lexicons, each containing approximately 9000 verbs. We are currently using these lexicons in an operational foreign language tutoring and machine translation. 1 Introduction A wide range of new capabilities in NLP applications such as foreign language tutoring (FLT) has been made possible by recent advances in lexical semantics (Carrier and Randall, 1993; Dowty, 1991; Fillmore, 1968; Foley and Van Valin, 1984; Grimshaw, 1990; Gruber, 1965; Hale and Keyser, 1993; Jackendoff, 1983; Jackendoff, 1990; Jackendoff, 1996; Levin, 1993; Levin and Rappaport Hova.v, To appear; Pesetsky, 1982; Pinker, 1989). Many of these researchers adopt the hypothesis that verbs can be grouped into broad classes, each of which corresponds to some combination of basic meaning components. This is the basic premise underlying our approach to multilingual lexicon construction. In particular, we have organized verbs into broad semantic classes and subsequently designed a set of lexical conceptual structures (LCS), for each class. These representations have been ported into English, Arabic, and Spa</context>
</contexts>
<marker>Jackendoff, 1983</marker>
<rawString>Jackendoff, Ray. 1983. Semantics and Cognition.. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>Semantic Structures.</title>
<date>1990</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1228" citStr="Jackendoff, 1990" startWordPosition="183" endWordPosition="184">S representations for different languages. These representations have been ported into English, Arabic and Spanish lexicons, each containing approximately 9000 verbs. We are currently using these lexicons in an operational foreign language tutoring and machine translation. 1 Introduction A wide range of new capabilities in NLP applications such as foreign language tutoring (FLT) has been made possible by recent advances in lexical semantics (Carrier and Randall, 1993; Dowty, 1991; Fillmore, 1968; Foley and Van Valin, 1984; Grimshaw, 1990; Gruber, 1965; Hale and Keyser, 1993; Jackendoff, 1983; Jackendoff, 1990; Jackendoff, 1996; Levin, 1993; Levin and Rappaport Hova.v, To appear; Pesetsky, 1982; Pinker, 1989). Many of these researchers adopt the hypothesis that verbs can be grouped into broad classes, each of which corresponds to some combination of basic meaning components. This is the basic premise underlying our approach to multilingual lexicon construction. In particular, we have organized verbs into broad semantic classes and subsequently designed a set of lexical conceptual structures (LCS), for each class. These representations have been ported into English, Arabic, and Spanish lexicons, eac</context>
</contexts>
<marker>Jackendoff, 1990</marker>
<rawString>Jackendoff, Ray. 1990. Semantic Structures. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>The Proper Treatment of Measuring Out, Telicity, and Perhaps Even Quantification</title>
<date>1996</date>
<booktitle>in English. Natural Language and Linguistic Theory,</booktitle>
<pages>14--305</pages>
<contexts>
<context position="1246" citStr="Jackendoff, 1996" startWordPosition="185" endWordPosition="186">for different languages. These representations have been ported into English, Arabic and Spanish lexicons, each containing approximately 9000 verbs. We are currently using these lexicons in an operational foreign language tutoring and machine translation. 1 Introduction A wide range of new capabilities in NLP applications such as foreign language tutoring (FLT) has been made possible by recent advances in lexical semantics (Carrier and Randall, 1993; Dowty, 1991; Fillmore, 1968; Foley and Van Valin, 1984; Grimshaw, 1990; Gruber, 1965; Hale and Keyser, 1993; Jackendoff, 1983; Jackendoff, 1990; Jackendoff, 1996; Levin, 1993; Levin and Rappaport Hova.v, To appear; Pesetsky, 1982; Pinker, 1989). Many of these researchers adopt the hypothesis that verbs can be grouped into broad classes, each of which corresponds to some combination of basic meaning components. This is the basic premise underlying our approach to multilingual lexicon construction. In particular, we have organized verbs into broad semantic classes and subsequently designed a set of lexical conceptual structures (LCS), for each class. These representations have been ported into English, Arabic, and Spanish lexicons, each containing appro</context>
</contexts>
<marker>Jackendoff, 1996</marker>
<rawString>Jackendoff, Ray. 1996. The Proper Treatment of Measuring Out, Telicity, and Perhaps Even Quantification in English. Natural Language and Linguistic Theory, 14:305-354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith L Klavans</author>
<author>Evelynne Tzoukermann</author>
</authors>
<title>Dictionaries and Corpora: Combining Corpus and Machine-Readable Dictionary Data. for Building Bilingual Lexicons.</title>
<date>1995</date>
<journal>Machine Translation,</journal>
<pages>10--185</pages>
<marker>Klavans, Tzoukermann, 1995</marker>
<rawString>Klavans, Judith L. and Evelynne Tzoukermann. 1995. Dictionaries and Corpora: Combining Corpus and Machine-Readable Dictionary Data. for Building Bilingual Lexicons. Machine Translation, 10:185-218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes and Alternations: A Preliminary Investigation.</title>
<date>1993</date>
<location>Chicago, IL.</location>
<contexts>
<context position="1259" citStr="Levin, 1993" startWordPosition="187" endWordPosition="188">uages. These representations have been ported into English, Arabic and Spanish lexicons, each containing approximately 9000 verbs. We are currently using these lexicons in an operational foreign language tutoring and machine translation. 1 Introduction A wide range of new capabilities in NLP applications such as foreign language tutoring (FLT) has been made possible by recent advances in lexical semantics (Carrier and Randall, 1993; Dowty, 1991; Fillmore, 1968; Foley and Van Valin, 1984; Grimshaw, 1990; Gruber, 1965; Hale and Keyser, 1993; Jackendoff, 1983; Jackendoff, 1990; Jackendoff, 1996; Levin, 1993; Levin and Rappaport Hova.v, To appear; Pesetsky, 1982; Pinker, 1989). Many of these researchers adopt the hypothesis that verbs can be grouped into broad classes, each of which corresponds to some combination of basic meaning components. This is the basic premise underlying our approach to multilingual lexicon construction. In particular, we have organized verbs into broad semantic classes and subsequently designed a set of lexical conceptual structures (LCS), for each class. These representations have been ported into English, Arabic, and Spanish lexicons, each containing approximately 9000</context>
<context position="4026" citStr="Levin (1993)" startWordPosition="645" endWordPosition="646"> the student types Jack threw the book in the trash, or Jack moved the book from the table into the trash, the system is able to match against the prestored LCS a.nd determine that all three of these responses are semantically appropriate. We have developed an acquisition program LEXICALL that allows us to construct LCS-based lexicons for the FLT system. This program is designed to be used for multiple languages, and also for other NLP applications (e.g., machine translation). One of the main results of this work is the definition of a relation between broad semantic classes (based on work by Levin (1993)) and LCS meaning components. We build on previous work, where verbs were classified automatically (Dorr and Jones, 1996; 139 Figure 1: MicroWorld Lesson in MILT MicroWorld Lesson U.S. A.R.MY RESEARCH INSTITUTE &apos;l Ott Execute Comm heck Answer Dorr, To appear) and tagged with thematic grid information (Dorr, Garman, and Weinberg, 1995). We use these pre-assigned classes and thematic grids as input to LEXICALL. The output is a set of LCS&apos;s corresponding to individual verb entries in our lexicon. Previous research in automatic acquisition focuses primarily on the use of statistical techniques, su</context>
<context position="10393" citStr="Levin, 1993" startWordPosition="1691" endWordPosition="1692">form of a &apos;How&apos; question, or it can choose to ignore it. The extra information is generally ignored, although it is recorded in case the instructor decides to program the system to notify the student about this as well. The full range of feedback is not presented here. Some possibilities are summarized (in English) in Table 1 (adapted from (Holland, 1994)). Note that the main advantage of using the LCS is that it allows the author to type in an answer that is general enough to match any number of additional answers. 3 Overview of LCS Acquisition We use Levin&apos;s publicly available online index (Levin, 1993) as a starting point for building LCSbased verb entries.&apos; While this index provides a unique and extensive catalog of verb classes, it does not define the underlying meaning components of each class. One of the main contributions of our work is that it provides a relation between Levin&apos;s classes and meaning components as defined in the LCS representation. Table 2 shows three broad semantic categories and example verbs along with their associated LCS representations. We have hand-constructed a database containing 191 LCS templates, i.e., one for each verb class in (Levin, 1993). In addition, we</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Levin, Beth. 1993. English Verb Classes and Alternations: A Preliminary Investigation. Chicago, IL.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Beth Levin</author>
<author>Malka Rappaport</author>
</authors>
<title>Hovav. To appear. Building Verb Meanings.</title>
<booktitle>The Projection. of Arguments: Lexical and Syntactic Constraints. CSLI.</booktitle>
<editor>In M. Butt and W. Gauder, editors,</editor>
<marker>Levin, Rappaport, </marker>
<rawString>Levin, Beth and Malka Rappaport Hovav. To appear. Building Verb Meanings. In M. Butt and W. Gauder, editors, The Projection. of Arguments: Lexical and Syntactic Constraints. CSLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deryle Lonsdale</author>
<author>Teruko Mita mura</author>
<author>Eric Nyberg</author>
</authors>
<title>Acquisition of Large Lexicons for Practical Knowledge-Based MT.</title>
<date>1995</date>
<journal>Machine Translation,</journal>
<pages>9--251</pages>
<marker>Lonsdale, mura, Nyberg, 1995</marker>
<rawString>Lonsdale, Deryle, Teruko Mita.mura., and Eric Nyberg. 1995. Acquisition of Large Lexicons for Practical Knowledge-Based MT. Machine Translation, 9:251-283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Pesetsky</author>
</authors>
<title>Paths and Categories.</title>
<date>1982</date>
<booktitle>Ph.D. thesis, MIT,</booktitle>
<location>Cambridge, MA.</location>
<contexts>
<context position="1314" citStr="Pesetsky, 1982" startWordPosition="196" endWordPosition="197">nglish, Arabic and Spanish lexicons, each containing approximately 9000 verbs. We are currently using these lexicons in an operational foreign language tutoring and machine translation. 1 Introduction A wide range of new capabilities in NLP applications such as foreign language tutoring (FLT) has been made possible by recent advances in lexical semantics (Carrier and Randall, 1993; Dowty, 1991; Fillmore, 1968; Foley and Van Valin, 1984; Grimshaw, 1990; Gruber, 1965; Hale and Keyser, 1993; Jackendoff, 1983; Jackendoff, 1990; Jackendoff, 1996; Levin, 1993; Levin and Rappaport Hova.v, To appear; Pesetsky, 1982; Pinker, 1989). Many of these researchers adopt the hypothesis that verbs can be grouped into broad classes, each of which corresponds to some combination of basic meaning components. This is the basic premise underlying our approach to multilingual lexicon construction. In particular, we have organized verbs into broad semantic classes and subsequently designed a set of lexical conceptual structures (LCS), for each class. These representations have been ported into English, Arabic, and Spanish lexicons, each containing approximately 9000 verbs. An example of a NLP application for which these</context>
</contexts>
<marker>Pesetsky, 1982</marker>
<rawString>Pesetsky, David. 1982. Paths and Categories. Ph.D. thesis, MIT, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Pinker</author>
</authors>
<title>Learnability and Cognition: The Acquisition of Argument Structure.</title>
<date>1989</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1329" citStr="Pinker, 1989" startWordPosition="198" endWordPosition="199">nd Spanish lexicons, each containing approximately 9000 verbs. We are currently using these lexicons in an operational foreign language tutoring and machine translation. 1 Introduction A wide range of new capabilities in NLP applications such as foreign language tutoring (FLT) has been made possible by recent advances in lexical semantics (Carrier and Randall, 1993; Dowty, 1991; Fillmore, 1968; Foley and Van Valin, 1984; Grimshaw, 1990; Gruber, 1965; Hale and Keyser, 1993; Jackendoff, 1983; Jackendoff, 1990; Jackendoff, 1996; Levin, 1993; Levin and Rappaport Hova.v, To appear; Pesetsky, 1982; Pinker, 1989). Many of these researchers adopt the hypothesis that verbs can be grouped into broad classes, each of which corresponds to some combination of basic meaning components. This is the basic premise underlying our approach to multilingual lexicon construction. In particular, we have organized verbs into broad semantic classes and subsequently designed a set of lexical conceptual structures (LCS), for each class. These representations have been ported into English, Arabic, and Spanish lexicons, each containing approximately 9000 verbs. An example of a NLP application for which these lexicons are c</context>
<context position="12865" citStr="Pinker, 1989" startWordPosition="2096" endWordPosition="2097"> the class to which the verb touch has been assigned.2 A verb, together with its semantic class uniquely identifies the word sense, or LCS template, to which the verb refers. The thematic grid (_th_loc) indicates that the verb has two obligatory arguments, a theme and a location.&apos; The ! ! in the LCS Template acts as a wildcard; it will be filled by a lexeme (i.e., a root form of the verb). The resulting form is called a constant, i.e., the idiosyncratic part of the meaning that distinguishes among members of a verb class (in the spirit of (Grimshaw, 1993; Levin and Rappaport Hovav, To appear; Pinker, 1989; Talmy, 1985)).4 Three inputs are required for acquisition of verb entries: a semantic class, a thematic grid, and a lexeme, which we will henceforth abbreviate as &amp;quot;class/grid/lexeme.&amp;quot; The output is a Lisp-like expression corresponding to the LCS representation. An example of input/output for our acquisition procedure is shown here: (4) Acquisition of LCS for: touch Input: 47.8; _th_loc; &amp;quot;touch&amp;quot; 2 Verbs not occurring in Levin&apos;s book are also assigned to classes using techniques described in (Dorr and Jones, 1996; Dorr, To appear). 3An underscore (_) designates an obligatory role and a comma (</context>
</contexts>
<marker>Pinker, 1989</marker>
<rawString>Pinker, Steven. 1989. Learnability and Cognition: The Acquisition of Argument Structure. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michelle Sams</author>
</authors>
<title>An Intelligent Foreign Language Tutor Incorporating Natural Language Processing.</title>
<date>1993</date>
<booktitle>In Proceedings of Conference on Intelligent Computer-Aided Training and Virtual Environment Technology,</booktitle>
<location>NASA: Houston, TX.</location>
<contexts>
<context position="6596" citStr="Sams, 1993" startWordPosition="1059" endWordPosition="1060"> frighten is animate), thematic information (e.g., that Mary is the agent in Mary hit the ball), and lexical-semantic information (e.g., spatial verbs such as throw are conceptually distinct from verbs of possession such as give). By modularizing the lexicon, we treat each information type separately, thus allowing us to vary the degree of dependence on each level so that we can address the question of how much knowledge is necessary for the success of the particular NLP application. This section describes the use of the LCS representation in a question-answering component of the MILT system (Sams, 1993; Weinberg et al., 1995). As described above, the LCS representation is used as the basis of matching routines for assessing students&apos; answers to free response questions about a short foreign language passage. In order to inform the student whether a question has been answered 140 Table 1: Correspondence Between NLP Output and Tutor Feedback System Prompt: Where did Jack put the book? Student Answer Prestored Answer Matcher Output Feedback Jack threw the book in the trash Jack threw the book in the trash exact match &amp;quot;That&apos;s right&amp;quot; Jack put the book in the trash Jack threw the book in the trash</context>
</contexts>
<marker>Sams, 1993</marker>
<rawString>Sams, Michelle. 1993. An Intelligent Foreign Language Tutor Incorporating Natural Language Processing. In Proceedings of Conference on Intelligent Computer-Aided Training and Virtual Environment Technology, NASA: Houston, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Talmy</author>
</authors>
<title>Lexicalization Patterns: Semantic Structure in Lexical Forms. In</title>
<date>1985</date>
<booktitle>Language Typology and Syntactic Description. 3: Grammatical Categories and the Lexicon.</booktitle>
<pages>57--149</pages>
<editor>T. Shopen, editor,</editor>
<publisher>University Press,</publisher>
<location>Cambridge, England,</location>
<contexts>
<context position="12879" citStr="Talmy, 1985" startWordPosition="2098" endWordPosition="2099">which the verb touch has been assigned.2 A verb, together with its semantic class uniquely identifies the word sense, or LCS template, to which the verb refers. The thematic grid (_th_loc) indicates that the verb has two obligatory arguments, a theme and a location.&apos; The ! ! in the LCS Template acts as a wildcard; it will be filled by a lexeme (i.e., a root form of the verb). The resulting form is called a constant, i.e., the idiosyncratic part of the meaning that distinguishes among members of a verb class (in the spirit of (Grimshaw, 1993; Levin and Rappaport Hovav, To appear; Pinker, 1989; Talmy, 1985)).4 Three inputs are required for acquisition of verb entries: a semantic class, a thematic grid, and a lexeme, which we will henceforth abbreviate as &amp;quot;class/grid/lexeme.&amp;quot; The output is a Lisp-like expression corresponding to the LCS representation. An example of input/output for our acquisition procedure is shown here: (4) Acquisition of LCS for: touch Input: 47.8; _th_loc; &amp;quot;touch&amp;quot; 2 Verbs not occurring in Levin&apos;s book are also assigned to classes using techniques described in (Dorr and Jones, 1996; Dorr, To appear). 3An underscore (_) designates an obligatory role and a comma (,) designates </context>
</contexts>
<marker>Talmy, 1985</marker>
<rawString>Talmy, Leonard. 1985. Lexicalization Patterns: Semantic Structure in Lexical Forms. In T. Shopen, editor, Language Typology and Syntactic Description. 3: Grammatical Categories and the Lexicon. University Press, Cambridge, England, pages 57-149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R Traum</author>
<author>Lenhart K Schubert</author>
<author>Nathaniel G Martin</author>
<author>Chung Hee Hwang</author>
<author>Peter Heeman</author>
<author>George Ferguson</author>
<author>James Allen</author>
<author>Massimo Poesio</author>
<author>Marc Light</author>
</authors>
<title>Knowledge Representation in the TRAINS-93 Conversation System.</title>
<date>1996</date>
<journal>International Journal of Expert Systems,</journal>
<pages>9--1</pages>
<contexts>
<context position="23563" citStr="Traum et al., 1996" startWordPosition="3836" endWordPosition="3839">esentation called lexical conceptual structure (LCS). Significant enhancements to LCSbased tutoring could be achieved by combining this representation with a mechanism for handling issues related to discourse and pragmatics. For example, although the LCS processor is capable of determining that the phrase in the trash partially matches the answer to Where did John put the book?, a pragmatic component would be required to determine that this answer is (perhaps) more appropriate than the full answer, He put the book in the trash. Representing conversational context and dynamic context updating (Traum et al., 1996; Haller, 1996; DiEugenio and Webber, 1996) would provide a framework for this type of response &amp;quot;relaxation.&amp;quot; Along 8We have defined approximately 100 such mappings per language. For example, the mapping produces the following primitive representations for the English word to: (to loc (at lc)), (to poss (at poss)), (to temp (at temp)), (toward loc (at lc)), (toward poss (at poss)). We have similar mappings defined in Arabic and Spanish. For example, the following primitive representations are produced for the Spanish word o: (at lc), (to loc (at lc)), (to poss (at poss)), (toward loc (at lc)).</context>
</contexts>
<marker>Traum, Schubert, Martin, Hwang, Heeman, Ferguson, Allen, Poesio, Light, 1996</marker>
<rawString>Traum, David R., Lenhart K. Schubert, Nathaniel G. Martin, Chung Hee Hwang, Peter Heeman, George Ferguson, James Allen, Massimo Poesio, and Marc Light. 1996. Knowledge Representation in the TRAINS-93 Conversation System. International Journal of Expert Systems, 9(1):173-223.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amy Weinberg</author>
<author>Joseph Garman</author>
<author>Jeffery Martin</author>
<author>Paola Merlo</author>
</authors>
<title>Principle-Based Parser for Foreign Language Training in German and Arabic.</title>
<date>1995</date>
<editor>In Melissa Holland, Jonathan Kaplan, and Michelle Sams, editors,</editor>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="6620" citStr="Weinberg et al., 1995" startWordPosition="1061" endWordPosition="1064"> animate), thematic information (e.g., that Mary is the agent in Mary hit the ball), and lexical-semantic information (e.g., spatial verbs such as throw are conceptually distinct from verbs of possession such as give). By modularizing the lexicon, we treat each information type separately, thus allowing us to vary the degree of dependence on each level so that we can address the question of how much knowledge is necessary for the success of the particular NLP application. This section describes the use of the LCS representation in a question-answering component of the MILT system (Sams, 1993; Weinberg et al., 1995). As described above, the LCS representation is used as the basis of matching routines for assessing students&apos; answers to free response questions about a short foreign language passage. In order to inform the student whether a question has been answered 140 Table 1: Correspondence Between NLP Output and Tutor Feedback System Prompt: Where did Jack put the book? Student Answer Prestored Answer Matcher Output Feedback Jack threw the book in the trash Jack threw the book in the trash exact match &amp;quot;That&apos;s right&amp;quot; Jack put the book in the trash Jack threw the book in the trash missing MANNER &amp;quot;How?&amp;quot; J</context>
</contexts>
<marker>Weinberg, Garman, Martin, Merlo, 1995</marker>
<rawString>Weinberg, Amy, Joseph Garman, Jeffery Martin, and Paola Merlo. 1995. Principle-Based Parser for Foreign Language Training in German and Arabic. In Melissa Holland, Jonathan Kaplan, and Michelle Sams, editors, Intelligent Language Tutors: Theory Shaping Technology. Lawrence Erlbaum Associates, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
<author>X Xia</author>
</authors>
<title>Large-Scale Automatic Extraction of an English-Chinese Translation Lexicon.</title>
<date>1995</date>
<journal>Machine Translation,</journal>
<pages>9--285</pages>
<contexts>
<context position="4725" citStr="Wu and Xia, 1995" startWordPosition="754" endWordPosition="757">ed automatically (Dorr and Jones, 1996; 139 Figure 1: MicroWorld Lesson in MILT MicroWorld Lesson U.S. A.R.MY RESEARCH INSTITUTE &apos;l Ott Execute Comm heck Answer Dorr, To appear) and tagged with thematic grid information (Dorr, Garman, and Weinberg, 1995). We use these pre-assigned classes and thematic grids as input to LEXICALL. The output is a set of LCS&apos;s corresponding to individual verb entries in our lexicon. Previous research in automatic acquisition focuses primarily on the use of statistical techniques, such as bilingual alignment (Church and Hanks, 1990; Kiavans and Tzoukermann, 1995; Wu and Xia, 1995) or extraction of syntactic constructions from online dictionaries and corpora (Brent, 1993). Others have taken a more knowledge-based (interlingual) approach (Lonsdale, Mitamura, and Nyberg, 1995). Still others (Copestake et al., 1995), use Englishbased grammatical codes for acquisition of lexical representations. Our approach differs from these in that it exploits certain linguistic constraints that govern the relation between a word&apos;s surface behavior and its corresponding semantic class. We demonstrate that— by assigning a LCS representation to each semantic class we can produce verb entri</context>
</contexts>
<marker>Wu, Xia, 1995</marker>
<rawString>Wu, D. and X. Xia. 1995. Large-Scale Automatic Extraction of an English-Chinese Translation Lexicon. Machine Translation, 9:285-313.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>