<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000073">
<title confidence="0.994785">
Using the Web for Nominal Anaphora Resolution
</title>
<author confidence="0.998567">
Katja Markert, Malvina Nissim
</author>
<affiliation confidence="0.998487">
School of Informatics
University of Edinburgh
</affiliation>
<email confidence="0.9915505">
markert@inf.ed.ac.uk
mnissim@inf.ed.ac.uk
</email>
<author confidence="0.9457">
Natalia N. Modjeska
</author>
<affiliation confidence="0.99899325">
School of Informatics
University of Edinburgh and
Department of Computer Science
University of Toronto
</affiliation>
<email confidence="0.996562">
natalia@cs.toronto.edu
</email>
<sectionHeader confidence="0.995624" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998095">
We present a novel method for resolv-
ing non-pronominal anaphora. Instead
of using handcrafted lexical resources,
we search the Web with shallow patterns
which can be predetermined for the type
of anaphoric phenomenon. In experi-
ments for other-anaphora and bridging,
our shallow, almost knowledge-free and
unsupervised method achieves state-of-
the-art results.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99974475">
After having focussed on pronominal anaphora,
researchers are now devoting attention to other
nominal anaphors as well (Harabagiu and Maio-
rano, 1999; Vieira and Poesio, 2000; Bierner,
2001; Modjeska, 2002; Ng and Cardie, 2002).
These comprise such diverse phenomena as coref-
erence, bridging (Clark, 1975) (see also Exam-
ple (1)), and other-anaphora (Example (2)).1
</bodyText>
<listItem confidence="0.90501275">
(1) The apartment she shares with a 12-year-
old daughter and her sister was rattled,
books and crystal hit the floor, [... ]
(2) You either believe Seymour can do it
</listItem>
<bodyText confidence="0.939729756097561">
again or you don&apos;t. Beside the designer&apos;s
age, other risk factors for Mr. Cray&apos;s
company include the Cray-3&apos;s [... I chip
technology.
&apos;In all examples the anaphor is typed in bold face and the
antecedent in italics. All examples in this paper are from the
Wall Street Journal (WSJ), Penn Treebank, release 2.
In Example (1), the definite NP &amp;quot;the floor&amp;quot; can
be felicitously used because a related entity, &amp;quot;the
apartment&amp;quot; has already been introduced, and a
part-of relation between the two entities can be
established. In other-anaphora, other provides a
set-complement to an entity already evoked in the
discourse model. In Example (2), the NP &amp;quot;other
risk factors for Mr. Cray&apos;s company&amp;quot; refers to a
set of risk factors excluding the designer&apos;s age, and
can be paraphrased as &amp;quot;other risk factors (for Mr.
Cray&apos;s company) than the designer&apos;s age&amp;quot;.
There is evidence that grammatical salience
plays a lesser role for resolving anaphors with
full lexical heads, than for pronominal anaphora
(Strube and Hahn, 1999; Modjeska, 2002). In-
stead, a large and diverse amount of lexical or
world knowledge is necessary to understand ex-
amples like (1) and (2): for example, that floors
are parts of apartments or that age can be viewed
as a risk factor. Therefore, the state-of-the-art
resolution systems that handle these phenomena
rely heavily on handcrafted resources, such as the
WordNet lexical hierarchy (Fellbaum, 1998).
Using WordNet suffers from several major
drawbacks. Many expressions (e.g., risk fac-
tor), word senses and lexical relations (e.g., floor
as a part of an apartment) are missing from the
database. The hierarchy is structured such that
the desired information might not be straight-
forward to retrieve. For example, in WordNet,
&amp;quot;floor&amp;quot; is encoded as part of &amp;quot;building&amp;quot;, but not
as part of &amp;quot;apartment&amp;quot;, although &amp;quot;apartment&amp;quot; is it-
self a meronym of &amp;quot;apartment building&amp;quot; which in
turn is a hyponym of &amp;quot;building&amp;quot; (see also (Vieira
</bodyText>
<page confidence="0.998774">
39
</page>
<bodyText confidence="0.999905217391304">
and Poesio, 2000)). Moreover, manually built
resources are expensive and time-consuming to
build and maintain.
There have been efforts to extract missing lex-
ical relationships from corpora in order to build
new knowledge sources and enrich existing ones
(Hearst, 1992; Berland and Charniak, 1999; Poe-
sio et al., 2002). In our view there are two main
problems with these approaches.
Firstly, the size of the used corpora still leads
to data sparseness (Berland and Charniak, 1999)
and the extraction procedure can therefore require
extensive smoothing. Secondly, it is not clear
how much and which knowledge to include in a
fixed context-independent ontology, whether man-
ually built or derived from a corpus. Thus, should
metonymy, underspecified and point-of-view de-
pendent hyponymy relations (Hearst, 1992) be in-
cluded? Should age, for example, be classified as
a hyponym of risk factor independent of context?
To solve the first problem, we propose using
the Web, which with approximately 968M pages2
is the largest corpus available to the NLP com-
munity. Using the web has proved successful in
several fields of NLP, e.g., machine translation
(Grefenstette, 1999) and bigram frequency estima-
tion (Keller et al., 2002). In particular, (Keller et
al., 2002) have shown that using the Web handles
data sparseness better than smoothing. However,
to our knowledge, the Web has not been used for
anaphora resolution yet.
We do not offer a solution to the second prob-
lem, but instead claim that, for our task, we do
not need a predetermined fixed ontology at all. In
Example (2), we do not need to have and fix the
knowledge that age is always a risk factor, but only
that, among the possible NP antecedents &amp;quot;Sey-
mour&amp;quot;, &amp;quot;designer&amp;quot;, and &amp;quot;(designer&apos;s) age&amp;quot;, the lat-
ter is the most likely to be viewed as a risk factor.
In the next section, we introduce a method that
uses shallow lexico-syntactic patterns and their
web frequencies instead of a fixed ontology to
achieve this comparison between several possible
antecedents. We then present two experiments on
other-anaphora and bridging, respectively. Our
shallow technique, used on a noisy and unpro-
</bodyText>
<footnote confidence="0.9682845">
2http : / /www. searchengineshowdown com/
stat s / s i zee st . shtml, data from March 2002.
</footnote>
<bodyText confidence="0.99858375">
cessed corpus like the Web, achieves results com-
parable with state-of-the-art methods using hand-
crafted knowledge bases. Finally, the results are
discussed and compared to related work.
</bodyText>
<sectionHeader confidence="0.831767" genericHeader="method">
2 The Basic Idea
</sectionHeader>
<bodyText confidence="0.88780225">
In the phenomena we consider, the relation be-
tween anaphor and antecedent is implicitly ex-
pressed, i.e., anaphor and antecedent do not stand
in a structural or grammatical relationship. How-
ever, they are linked by a strong semantic relation
that is likely to be structurally explicitly expressed
in other texts. We exploit this insight by adopting
the following procedure:
</bodyText>
<listItem confidence="0.949643">
1. Dependent on the anaphoric phenomenon,
we determine which lexical relationships
usually hold between anaphor and an-
tecedent. For example, in other-anaphora,
a hyponymy/similarity relation between the
lexical heads of anaphor and antecedent is
stipulated by the context,3 e.g. age is viewed
as a risk factor.
2. We select patterns that structurally ex-
plicitly express the same lexical relation-
</listItem>
<bodyText confidence="0.9445416">
ships. For example, NP1 and other
NP2 is a pattern that usually expresses hy-
ponymy/similarity relations between the hy-
ponym NP1 and its hypernym NP2 (Hearst,
1992).
</bodyText>
<listItem confidence="0.84912575">
3. If the implicit lexical relationship between
anaphor and antecedent is strong, then it is
likely that anaphor and antecedent also fre-
quently cooccur in the selected explicit pat-
terns. We extract all possible antecedents
for each anaphor, and instantiate the explicit
pattern for all anaphor/antecedent pairs. In
Example (2) the pattern NP1 and other
NP2 can be instantiated with Seymour
and other risk factors, designer and
other risk factors, and age and other
risk factors.4 The instantiation of a pat-
</listItem>
<footnote confidence="0.8137188">
3From now on, we will often use &amp;quot;anaphor/antecedent&amp;quot;
instead of the more cumbersome &amp;quot;lexical heads of the
anaphor/antecedent&amp;quot;.
4These simplified instantiations serve as an example and
are not the final instantiations we use; see Section 3.2.
</footnote>
<page confidence="0.997029">
40
</page>
<bodyText confidence="0.999626857142857">
tern can be searched in any corpus to de-
termine its frequency. We now follow the
rationale that the most frequent of these in-
stantiated patterns determines the correct an-
tecedent.
4. As the patterns can be quite elaborate,
most corpora will be too small to deter-
mine the corresponding frequencies reli-
ably. The instantiation age and other risk
factors, for example, does not occur at all in
the British National Corpus (BNC), a 100M
words corpus of British English.5 Therefore
we use the largest corpus available, the Web.6
We submit all instantiated patterns as queries
to the Web making use of the GOOGLE
API technology and, as a first approximation,
select the instantiation yielding the highest
number of hits. Here, age and other risk
factors yields over 400 hits, whereas the
other two instantiations for this example yield
0 hits each.
</bodyText>
<sectionHeader confidence="0.970132" genericHeader="method">
3 Experiment I: Other-anaphora
</sectionHeader>
<bodyText confidence="0.999980857142857">
Here we restrict other-anaphora to referential lexi-
cal NPs with the modifiers other or another and
non-structurally given antecedents, as in Exam-
ple (2).7 The distance between an other-anaphor
and its antecedent can be large; (Modjeska, 2002)
observed a dependency that spans over 17 sen-
tences.
</bodyText>
<subsectionHeader confidence="0.999703">
3.1 Data Collection and Preparation
</subsectionHeader>
<bodyText confidence="0.9998194">
We tested our method on 120 samples of other-
anaphors from the Wall Street Journal corpus
(Penn Treebank release 2, first three sections).
These samples are part of the dataset reported in
(Modjeska, 2002). We used the samples in which
</bodyText>
<footnote confidence="0.837419">
5http://info.ox.ac.uk/bnc
</footnote>
<construct confidence="0.7053565">
6The Web is a constantly growing, changing and updating
resource. On the one hand, its size and changing potential are
an advantage as we can have access to such a large corpus
without having to create it. On the other hand, one has no
control over its content.
7In contrast, in Example (3), the (split) antecedent &amp;quot;jam
and cocoa&amp;quot; is the coordinated constituent to the left of the
conjunction &amp;quot;and&amp;quot;. Thus the antecedent is given structurally.
</construct>
<listItem confidence="0.544105">
(3) [..j it enabled her to buy jam, cocoa and other
war-rationed goodies.
</listItem>
<bodyText confidence="0.992282121212121">
the antecedents are NPs realized within a two-
sentence window, i.e., either in the sentence con-
taining the anaphor or in the preceding one.
Antecedent Extraction. For each anaphor we
extracted the set of all potential NP-antecedents in
the two-sentence window. This was done in three
steps. First, we extracted all base NPs, i.e., NPs
that contain no further NPs within them. NPs con-
taining a possessive modifier, e.g. &amp;quot;the designer&apos;s
age&amp;quot; were split into the possessor NP, &amp;quot;the de-
signer&apos;s&amp;quot; and the possessed phrase, &amp;quot;age&amp;quot;. Second,
we filtered out null elements (tagged -NONE-) and
pronouns. Pronouns can be antecedents of other-
anaphors but our method cannot deal with them
since they are lexically empty. Third, we split co-
ordinated NPs, e.g., &amp;quot;risk, technology and inno-
vation&amp;quot;, into their constituting parts using simple
heuristics. We also split proper names followed by
a common noun; therefore &amp;quot;Mips computers&amp;quot; was
automatically split into an antecedent &amp;quot;Mips&amp;quot; and
an antecedent &amp;quot;Mips computers&amp;quot;.
We call A the list of possible antecedents, and
ana the anaphor. For Example (2), this results in
A={Seymour, the designer&apos;s, age} and ana=other
risk factors for Mr Cray&apos;s company.
Antecedent Preparation and Named Entity
(NE) Recognition. All modification was elimi-
nated to avoid data sparseness. In addition only
the rightmost noun of compounds was kept.
For Example (2), this results in A={Seymour,
designer age} and ana=factors.
Using patterns containing NEs (like &amp;quot;Mr. Pick-
ens&amp;quot; in Example (4)) also leads to data sparseness.
</bodyText>
<listItem confidence="0.665691">
(4) Koito has refused to grant Mr Pickens
</listItem>
<bodyText confidence="0.977011727272727">
seats on its board, asserting he is a green-
mailer trying to pressure Koito&apos;s other
shareholders [... ]
We resolved NEs in two steps. First, we pro-
cessed the data using ANNIE, an IE software,
which is part of the GATE2 software package.8
We only used its classification into the ENAMEX
MUC-7 categories (Chinchor, 1997): PERSON,
ORGANIZATION and LOCATION. Second, we used
some heuristics to automatically obtain more fine-
grained distinctions for the categories LOCATION
</bodyText>
<footnote confidence="0.975244">
8http://gate.ac.uk
</footnote>
<page confidence="0.998772">
41
</page>
<bodyText confidence="0.997387">
and ORGANIZATION, whenever possible. We clas-
sified LOCATIONS into COUNTRY, (US) STATE,
CITY, RIVER, LAKE and OCEAN, using mainly
gazetteers.9 If an entity classified by GATE as
ORGANIZATION contained an indication of the or-
ganization type, we used this as a subclassifica-
tion; therefore &amp;quot;Bank of America&amp;quot; is classified as
BANK. No further distinctions were developed for
the category PERSON. For numeric and times enti-
ties we used simple heuristics to classify them fur-
ther into DAY, MONTH, YEAR as well as DOLLAR
or simply NUMBER.
Disregarding numeric and time entities, our
dataset included 262 possible NE antecedents.
Our method recognised 216 as proper names (82%
recall). Of these, 202 (93% precision) were cor-
rectly classified.
Finally, all elements of A were lemmatized.
For Example (2), this results in A={person
[=Seymourl, designer age} and ana=factor.
</bodyText>
<subsectionHeader confidence="0.999402">
3.2 Pattern Selection and Query Generation
</subsectionHeader>
<bodyText confidence="0.97930396969697">
We use the following pattern for other-anaphora:10
(01) (Ni{sg} OR Ni{p/}) and other N2{p/}
For common noun antecedents, we instantiate
the pattern by substituting Ni with a possible an-
tecedent, an element of A, and N2 with ana, as
normally N1 is a hyponym of N2 in (01), and
the antecedent is a hyponym of the anaphor. An
instantiated pattern for Example (2) is ( age OR
ages) and other factors (see /f in Table 1).11
For NE antecedents we instantiate (01) by sub-
stituting N1 with the NE category of the an-
tecedent, and N2 with ana. An instantiated pat-
tern for Example (4) is (person OR persons)
and other shareholders (see If in Table 1). In
this instantiation, N1 (&amp;quot;person&amp;quot;) is not a hyponym
of N2 (&amp;quot;shareholder&amp;quot;), instead N2 is a hyponym of
N1. This is a consequence of the substitution of the
antecedent (&amp;quot;Mr. Pickens&amp;quot;) with its NE category
&apos;We extracted the gazetteers from the Web. Small
gazetteers, containing in all about 500 entries, are sufficient.
This is the only external knowledge source we collected.
&amp;quot;In all the patterns in this paper, &amp;quot;OR&amp;quot; is the boolean op-
erator, &amp;quot;N1&amp;quot; and &amp;quot;N2&amp;quot; are variables, and all other words are
constants.
&apos; &apos; Common noun instantiations are marked by a superscript
&amp;quot;c&amp;quot; and proper name instantiations are marked by a super-
script &amp;quot;p&amp;quot;.
(&amp;quot;person&amp;quot;) (see also Figure 1). Such an instantia-
tion is normally not very frequent, since it violates
standard relations within (01). Therefore, we also
instantiate (01) by substituting N1 with ana, and
N2 with the NE category of the antecedent (see 4
in Table 1).
</bodyText>
<figure confidence="0.97589875">
person
shareholder ,,&apos; shareholder
[NER]
Mr. Pickens
</figure>
<figureCaption confidence="0.999994">
Figure 1: NER and Hyponymy Relation
</figureCaption>
<bodyText confidence="0.9341759">
Furthermore, for NE antecedents, we use an ad-
ditional pattern (02):
(02) N1 and other N2 {p/}
We instantiate it by substituting N1 with the
original NE antecedent, and N2 with ana (see 4
in Table 1).
Patterns and instantiations are summarised in
Table 1. We instantiate the patterns for each
anaphor/antecedent pair and submit these instan-
tiations as queries to the GOOGLE search engine.
</bodyText>
<subsectionHeader confidence="0.998594">
3.3 Scoring Method
</subsectionHeader>
<bodyText confidence="0.913812571428571">
For each antecedent ant in A we obtain the raw
frequencies of all instantiations it occurs in (If for
common nouns, or If, 4, 4 for proper names)
from the Web, yielding freq(If), or freq(If),
freq(g) and freq(4). We compute the max-
imum Mant over these frequencies for proper
names For common nouns Mara corresponds to
freq(If). The instantiation yielding Mara is then
called /maxant.
We then use two scoring methods. In our first
method, we select the antecedent with the highest
Mara as the correct antecedent.
The second method takes into account the indi-
vidual frequencies of ant and ana by adapting mu-
tual information. We call the first part of /maxarit
(e.g. &amp;quot;age OR ages&amp;quot;, or &amp;quot;shareholder OR share-
holders&amp;quot;) Xant, and the second part (e.g. &amp;quot;factors&amp;quot;
or &amp;quot;persons&amp;quot;) Yant. We compute the probability of
/maxant, Xant and Yant, using GOOGLE to de-
termine freq(Xarit) and
f req(Yant)•
</bodyText>
<page confidence="0.998905">
42
</page>
<tableCaption confidence="0.999734">
Table 1: Patterns and Instantiations for other-anaphora
</tableCaption>
<table confidence="0.986089823529412">
ANTECEDENT PATTERN INSTANTIATIONS
common noun (01): (N) {sg} OR Ni {p1} and other N2 {pi} -(age OR ages) and other factors&amp;quot;
proper name (01): (Ni{sg} OR Ni{p/}) and other N2 {p1} 4: &amp;quot;(person OR persons) and other shareholders&amp;quot;
4: &amp;quot;(shareholder OR shareholders) and other persons&amp;quot;
(02): Ni and other N2{p1} 4: &amp;quot;Mr. Pickens and other shareholders&amp;quot;
Table 2: Results for other-anaphora
Mant Web-raw Web-mut LEX
Pr(Imaxant) =
number of GOOGLE pages Corr 50 58 54
len 7 5 7
tot corr 57 63 61
freg(Xant)
PT (X
ant)
tot wrong 63 57 59
— number of GOOGLE pages
tot 120 120 120
</table>
<equation confidence="0.9642165">
f req(Yant)
Pr(Yat) =
</equation>
<bodyText confidence="0.993475">
number of GOOGLE pages
We then compute the final score M/ant.
</bodyText>
<equation confidence="0.949288">
Pr (I max ant)
M Iant =
</equation>
<bodyText confidence="0.651729">
We resolve to the antecedent with the highest
</bodyText>
<equation confidence="0.879376">
M -ant •
</equation>
<bodyText confidence="0.995394">
In both methods, if two antecedents achieve the
same score, a recency based tie-breaker chooses
the antecedent closest to the anaphor in the text.
</bodyText>
<sectionHeader confidence="0.508401" genericHeader="method">
3.4 Results and Error Analysis
</sectionHeader>
<bodyText confidence="0.999666790697675">
We postulate three categories for classifying the
results: (i) correct, when the antecedent selected
is the correct one; (ii) lenient, when the antecedent
selected refers to the same entity as the correct an-
tecedent; (iii) wrong in all other cases.
In Table 2, we compare our results with those
obtained by the algorithm LEX (Modjeska, 2002).
Although LEX makes extensive use of WordNet,
our algorithm achieves comparable results.
Our algorithm&apos;s mistakes are due to several fac-
tors.
NEs. As 58 (48.3%) out of the total 120
anaphors (48.3%) have NE antecedents, NE res-
olution is crucial for our algorithm. The low re-
call of our NE recognition module has a signif-
icant impact on our algorithm&apos;s performance as
it leads to missing instantiations. Moreover, in-
correct NE classifications yield incorrect instanti-
ations, although this problem is not very frequent
as the precision of our NE resolution module is
relatively high (93%).
Vague Anaphors. Anaphors that are semanti-
cally vague, such as &amp;quot;issue&amp;quot; or &amp;quot;problem&amp;quot;, are not
informative enough for a purely semantic-oriented
method.
Split Antecedents. Our algorithm cannot han-
dle split antecedents (6 cases in our dataset). In
Example (5), the antecedent of &amp;quot;other contract
months&amp;quot; is a set of referents consisting of &amp;quot;May&amp;quot;
and &amp;quot;July&amp;quot;.
(5) The May contract, which also is without
restraints, ended with a gain of 0.45 cent
to 14.26 cents. The July delivery rose
its daily permissible limit of 0.50 cent a
pound to 14.00 cent, while other contract
months showed near-limit advances.
Our algorithm is not able to distinguish between
proper cases of split antecedents (e.g. Exam-
ple (5)), where a tie-breaker should not be applied,
and cases where two similar entities are mentioned
but only one is the actual antecedent. It is normally
necessary to resort to sophisticated inference tech-
niques to make this distinction. As we always ap-
</bodyText>
<equation confidence="0.8124385">
log
Pr(Xarit)Pr (Yant)
</equation>
<page confidence="0.998265">
43
</page>
<bodyText confidence="0.999970785714286">
ply a tie-breaker, examples such as (5) cannot be
handled: only &amp;quot;July&amp;quot; (the most recent antecedent)
is selected and the result counts as wrong.
Pronouns. Our algorithm cannot handle pro-
noun antecedents as they are lexically empty. Con-
trary to intuition, this does not constitute a signif-
icant limitation as only 2 anaphors in our dataset
have pronominal antecedents that refer to an en-
tity that is not additionally mentioned by a full NP
within the 2 sentence window. In contrast, in Ex-
ample (4), the referent of the pronoun &amp;quot;he&amp;quot; is also
mentioned by the full NP &amp;quot;Mr. Pickens&amp;quot;, and the
algorithm is able to resolve the anaphor to &amp;quot;Mr.
Pickens&amp;quot;, thus yielding a lenient correct result.
</bodyText>
<sectionHeader confidence="0.994346" genericHeader="method">
4 Experiment II: Bridging
</sectionHeader>
<bodyText confidence="0.999885733333333">
For the scope of this paper, a bridging anaphor is
a definite NP that can be felicitously used only
because it refers to an entity which stands in a
meronymic relation with an already explicitly in-
troduced entity (see Example (1)).
We use the corpus described in (Poesio et al.,
2002), restricting ourselves to the examples clas-
sified as meronymy. Unfortunately, this yields
only 12 examples so that the current experiment
is only a very small pilot study to explore the ex-
tension of our method to other nominal anaphora.
In addition, we profit from the a priori knowledge
that we are dealing with an instance of meronymy
(one of the many relations bridging can express),
so that we do not operate in a completely realis-
tic scenario. This contrasts with our experiment
on other-anaphora, where the modifier other (to-
gether with the absence of a structurally given
antecedent) reliably signals the presence of an
anaphor and the lexical relations expressed are
more constrained.
For each anaphor, all possible NP antecedents in
a 5-sentence window have been already extracted
by Renata Vieira and Massimo Poesio, who also
had already deleted NEs from the original dataset.
Again, we stripped modification so that only the
heads of possible antecedents and of the anaphors
were used.
Meronymy is often explicitly expressed by the
following patterns:
</bodyText>
<equation confidence="0.790346">
010 (N11.swl OR 1711/ill) of (a OR an OR the
OR each OR every OR any)* N2{)w}
</equation>
<tableCaption confidence="0.946582">
Table 3: Results for bridging
</tableCaption>
<table confidence="0.99969375">
Web-raw Poesio-WN Poesio-BNC
corr 7 3 8
wrong 5 9 4
tot 12 12 12
</table>
<tableCaption confidence="0.932822">
(B2)1711/ill of (the OR all)* N21/ill
</tableCaption>
<bodyText confidence="0.987904875">
We instantiate both patterns by equating N1
with the anaphor and N2 with the antecedent. In
Example (1) the instantiations for the antecedent
&amp;quot;apartment&amp;quot; are (floor OR floors) of (a
OR an OR the OR each OR every OR any)*
apartment and floors of (the OR all)*
apartments.
For each antecedent ant we obtain the raw fre-
quencies of all instantiations it occurs in from the
Web. We then compute the maximum Mant over
these frequencies and select the antecedent with
the highest Mant as the correct one. We will
use mutual information for bridging on a larger
dataset.
Table 3 compares our results with those ob-
tained by the algorithms used in (Poesio et al.,
2002), of which one relies on WordNet and the
other on knowledge a priori extracted from a
parsed version of the BNC.
In this preliminary study, our results outper-
form the Wordnet method and are comparable to
those obtained from corpus-based knowledge ex-
traction, although we do not linguistically process
the web pages returned by our search.
</bodyText>
<sectionHeader confidence="0.999962" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999955307692308">
Most of the current resolution algorithms for non-
pronominal anaphora make heavy use of hand-
crafted ontologies. The COCKTAIL system for
coreference resolution (Harabagiu and Maiorano,
1999) combines sortal constraints and concep-
tual glosses from WordNet with co-occurence in-
formation from a treebank. (Vieira and Poesio,
2000)&apos;s system for definite descriptions (covering,
inter alia, coreference and bridging) also makes
use of WordNet, as well as handcrafted constraints
and consistency checks. LEX, a resolution al-
gorithm developed for other-anaphors (Modjeska,
2002), employs lexical information from WordNet
</bodyText>
<page confidence="0.997113">
44
</page>
<bodyText confidence="0.999992740740741">
and heuristics for resolving anaphora with NE an-
tecedents, presupposing they have previously been
classified into MUC-7 categories.12 All these ap-
proaches suffer from the shortcomings that we
outlined in Section 1.
In contrast, we do not use any external hand-
crafted knowledge. In addition, we use only shal-
low search patterns and do not process the pages
that GOOGLE returns in any way.13 We achieve
results comparable to knowledge- or processing-
intensive methods. Moreover, we only com-
pare the likelihood of several given antecedents to
cooccur in a given pattern with a given anaphor in-
stead of assuming context-independent lexical re-
lations. Thus, we can resolve anaphor/antecedent
relations that might or should not be included in a
lexical hierarchy (e.g. risk factor/age).
Our results confirm results by (Keller et al.,
2002) and (Grefenstette, 1999), who use the Web
successfully for other NLP applications (for an
overview of successful usage of the Web in NLP,
see (Keller et al., 2002)). In line with these re-
sults, ours also show that the large amount of data
available on the Web overcomes its intrinsic noise
as well as the lack of linguistic processing. To
our knowledge, ours is the first attempt to tackle
anaphora resolution using the Web.
</bodyText>
<sectionHeader confidence="0.995603" genericHeader="conclusions">
6 Contributions and Future Work
</sectionHeader>
<bodyText confidence="0.98661703125">
We have proposed a novel method for non-
pronominal anaphora resolution, using simple
Web searches with shallow linguistic patterns. We
show that the large amount of data available on
the Web makes anaphora resolution without hand-
crafted lexical knowledge feasible.
In particular, we have described two experi-
ments carried out on two different anaphoric phe-
nomena, namely other-anaphora and bridging. Ex-
ploiting free text achieves results comparable to
those obtained when using rich and structured
handcrafted resources.
Given the shallow techniques used and the state-
of-the-art results obtained, our method is promis-
121n the current evaluation of LEX, NEs are manually an-
notated.
13This is in contrast to other approaches that extract rela-
tions from corpora and that use chunkers/taggers/parsers for
this purpose (Hearst, 1992; Poesio et al., 2002).
ing. There is still room for improvement in sev-
eral directions. Our NE resolution module, for ex-
ample, is extremely simple and has a low recall
(82%). As a large number of antecedents for other-
anaphora are NEs (48.3%), including a state-of-
the-art NE resolution system would certainly im-
prove our algorithm&apos;s performance.
For each lexical relation we use variations of a
single pattern. In the future we will explore the
use of additional substantially different patterns.
As this is pilot study, the datasets we use are
small. We are currently testing our algorithm on a
larger dataset of other-anaphora.
</bodyText>
<sectionHeader confidence="0.994356" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.989240846153846">
Natalia N. Modjeska is supported by grant No.
GR/M75129 from the Engineering and Physi-
cal Sciences Research Council to the Univer-
sity of Edinburgh. Katja Markert is sup-
ported by an Emmy Noether Fellowship of the
Deutsche Forschungsgemeinschaft. We thank
Mark Chignell at the University of Toronto for
providing Natalia N. Modjeska with a good work
environment in the Interactive Media Lab.
We also would like to thank Massimo Poesio
for providing the bridging data, as well as Bonnie
Webber, Johan Bos and two anonymous reviewers
for helpful comments and suggestions.
</bodyText>
<sectionHeader confidence="0.997197" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994853375">
Matthew Berland and Eugene Charniak. 1999. Find-
ing parts in very large corpora. In Proc. of ACL-99,
pages 57-64.
Gann Bierner. 2001. Alternative phrases and natural
language information retrieval. In Proc. of ACL-01.
Nancy Chinchor. 1997. MUC-7 Named Entity Task
definition. In Proc. of MUC-7, 1997.
Herbert H. Clark. 1975. Bridging. In Proc. of the Con-
ference on Theoretical Issues in NLP, 1975, pages
169-174.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge,
Mass.
Gregory Grefenstette. 1999. The WWW as a resource
for example-based MT tasks. In Proc. of ASLIB&apos;99
Translating and the Computer 21.
</reference>
<page confidence="0.98632">
45
</page>
<reference confidence="0.990623107142857">
Sanda Harabagiu and Steven Maiorano. 1999.
Knowledge-lean coreference resolution and its rela-
tion to textual cohesion and coherence. In Proc. of
the ACL-99 Workshop on the Relation of Discourse
and Dialogue Structure and Reference, pages 29-38.
Marti Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proc. of
COLING-92.
Frank Keller, Maria Lapata, and Olga Ourioupina.
2002. Using the Web to overcome data sparseness.
In Proc. of EMNLP-02, pages 230-237.
Natalia N. Modjeska. 2002. Lexical and grammati-
cal role constraints in resolving other-anaphora. In
Proc. of DAARC-02.
Vincent Ng and Claire Cardie. 2002. Improving ma-
chine learning approaches to coreference resolution.
In Proc. of ACL-02, pages 104-111.
Massimo Poesio, Tomonori lshikawa, Sabine
Schulte im Walde, and Renata Viera. 2002.
Acquiring lexical knowledge for anaphora resolu-
tion. In Proc. of LREC-02, pages 1220-1224.
Michael Strube and Udo Hahn. 1999. Functional
centering — grounding referential coherence in
information structure. Computational Lingustics,
25(3):309-344.
Renata Vieira and Massimo Poesio. 2000. An
empirically-based system for processing definite de-
scriptions. Computational Linguistics, 26(4).
</reference>
<page confidence="0.999612">
46
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.536401">
<title confidence="0.999975">Using the Web for Nominal Anaphora Resolution</title>
<author confidence="0.999224">Katja Markert</author>
<author confidence="0.999224">Malvina</author>
<affiliation confidence="0.9983915">School of University of</affiliation>
<email confidence="0.953639">mnissim@inf.ed.ac.uk</email>
<author confidence="0.577745">N Natalia</author>
<affiliation confidence="0.9996935">School of University of Edinburgh Department of Computer University of</affiliation>
<email confidence="0.997848">natalia@cs.toronto.edu</email>
<abstract confidence="0.997305545454546">We present a novel method for resolving non-pronominal anaphora. Instead of using handcrafted lexical resources, we search the Web with shallow patterns which can be predetermined for the type of anaphoric phenomenon. In experiments for other-anaphora and bridging, our shallow, almost knowledge-free and unsupervised method achieves state-ofthe-art results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Matthew Berland</author>
<author>Eugene Charniak</author>
</authors>
<title>Finding parts in very large corpora.</title>
<date>1999</date>
<booktitle>In Proc. of ACL-99,</booktitle>
<pages>57--64</pages>
<contexts>
<context position="3457" citStr="Berland and Charniak, 1999" startWordPosition="531" endWordPosition="534"> The hierarchy is structured such that the desired information might not be straightforward to retrieve. For example, in WordNet, &amp;quot;floor&amp;quot; is encoded as part of &amp;quot;building&amp;quot;, but not as part of &amp;quot;apartment&amp;quot;, although &amp;quot;apartment&amp;quot; is itself a meronym of &amp;quot;apartment building&amp;quot; which in turn is a hyponym of &amp;quot;building&amp;quot; (see also (Vieira 39 and Poesio, 2000)). Moreover, manually built resources are expensive and time-consuming to build and maintain. There have been efforts to extract missing lexical relationships from corpora in order to build new knowledge sources and enrich existing ones (Hearst, 1992; Berland and Charniak, 1999; Poesio et al., 2002). In our view there are two main problems with these approaches. Firstly, the size of the used corpora still leads to data sparseness (Berland and Charniak, 1999) and the extraction procedure can therefore require extensive smoothing. Secondly, it is not clear how much and which knowledge to include in a fixed context-independent ontology, whether manually built or derived from a corpus. Thus, should metonymy, underspecified and point-of-view dependent hyponymy relations (Hearst, 1992) be included? Should age, for example, be classified as a hyponym of risk factor indepen</context>
</contexts>
<marker>Berland, Charniak, 1999</marker>
<rawString>Matthew Berland and Eugene Charniak. 1999. Finding parts in very large corpora. In Proc. of ACL-99, pages 57-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gann Bierner</author>
</authors>
<title>Alternative phrases and natural language information retrieval.</title>
<date>2001</date>
<booktitle>In Proc. of ACL-01.</booktitle>
<contexts>
<context position="881" citStr="Bierner, 2001" startWordPosition="117" endWordPosition="118">versity of Toronto natalia@cs.toronto.edu Abstract We present a novel method for resolving non-pronominal anaphora. Instead of using handcrafted lexical resources, we search the Web with shallow patterns which can be predetermined for the type of anaphoric phenomenon. In experiments for other-anaphora and bridging, our shallow, almost knowledge-free and unsupervised method achieves state-ofthe-art results. 1 Introduction After having focussed on pronominal anaphora, researchers are now devoting attention to other nominal anaphors as well (Harabagiu and Maiorano, 1999; Vieira and Poesio, 2000; Bierner, 2001; Modjeska, 2002; Ng and Cardie, 2002). These comprise such diverse phenomena as coreference, bridging (Clark, 1975) (see also Example (1)), and other-anaphora (Example (2)).1 (1) The apartment she shares with a 12-yearold daughter and her sister was rattled, books and crystal hit the floor, [... ] (2) You either believe Seymour can do it again or you don&apos;t. Beside the designer&apos;s age, other risk factors for Mr. Cray&apos;s company include the Cray-3&apos;s [... I chip technology. &apos;In all examples the anaphor is typed in bold face and the antecedent in italics. All examples in this paper are from the Wal</context>
</contexts>
<marker>Bierner, 2001</marker>
<rawString>Gann Bierner. 2001. Alternative phrases and natural language information retrieval. In Proc. of ACL-01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Chinchor</author>
</authors>
<title>MUC-7 Named Entity Task definition.</title>
<date>1997</date>
<booktitle>In Proc. of MUC-7,</booktitle>
<contexts>
<context position="11158" citStr="Chinchor, 1997" startWordPosition="1782" endWordPosition="1783">avoid data sparseness. In addition only the rightmost noun of compounds was kept. For Example (2), this results in A={Seymour, designer age} and ana=factors. Using patterns containing NEs (like &amp;quot;Mr. Pickens&amp;quot; in Example (4)) also leads to data sparseness. (4) Koito has refused to grant Mr Pickens seats on its board, asserting he is a greenmailer trying to pressure Koito&apos;s other shareholders [... ] We resolved NEs in two steps. First, we processed the data using ANNIE, an IE software, which is part of the GATE2 software package.8 We only used its classification into the ENAMEX MUC-7 categories (Chinchor, 1997): PERSON, ORGANIZATION and LOCATION. Second, we used some heuristics to automatically obtain more finegrained distinctions for the categories LOCATION 8http://gate.ac.uk 41 and ORGANIZATION, whenever possible. We classified LOCATIONS into COUNTRY, (US) STATE, CITY, RIVER, LAKE and OCEAN, using mainly gazetteers.9 If an entity classified by GATE as ORGANIZATION contained an indication of the organization type, we used this as a subclassification; therefore &amp;quot;Bank of America&amp;quot; is classified as BANK. No further distinctions were developed for the category PERSON. For numeric and times entities we u</context>
</contexts>
<marker>Chinchor, 1997</marker>
<rawString>Nancy Chinchor. 1997. MUC-7 Named Entity Task definition. In Proc. of MUC-7, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
</authors>
<title>Bridging.</title>
<date>1975</date>
<booktitle>In Proc. of the Conference on Theoretical Issues in NLP,</booktitle>
<pages>169--174</pages>
<contexts>
<context position="997" citStr="Clark, 1975" startWordPosition="134" endWordPosition="135">nstead of using handcrafted lexical resources, we search the Web with shallow patterns which can be predetermined for the type of anaphoric phenomenon. In experiments for other-anaphora and bridging, our shallow, almost knowledge-free and unsupervised method achieves state-ofthe-art results. 1 Introduction After having focussed on pronominal anaphora, researchers are now devoting attention to other nominal anaphors as well (Harabagiu and Maiorano, 1999; Vieira and Poesio, 2000; Bierner, 2001; Modjeska, 2002; Ng and Cardie, 2002). These comprise such diverse phenomena as coreference, bridging (Clark, 1975) (see also Example (1)), and other-anaphora (Example (2)).1 (1) The apartment she shares with a 12-yearold daughter and her sister was rattled, books and crystal hit the floor, [... ] (2) You either believe Seymour can do it again or you don&apos;t. Beside the designer&apos;s age, other risk factors for Mr. Cray&apos;s company include the Cray-3&apos;s [... I chip technology. &apos;In all examples the anaphor is typed in bold face and the antecedent in italics. All examples in this paper are from the Wall Street Journal (WSJ), Penn Treebank, release 2. In Example (1), the definite NP &amp;quot;the floor&amp;quot; can be felicitously us</context>
</contexts>
<marker>Clark, 1975</marker>
<rawString>Herbert H. Clark. 1975. Bridging. In Proc. of the Conference on Theoretical Issues in NLP, 1975, pages 169-174.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Mass.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
</authors>
<title>The WWW as a resource for example-based MT tasks.</title>
<date>1999</date>
<booktitle>In Proc. of ASLIB&apos;99 Translating and the Computer</booktitle>
<volume>21</volume>
<contexts>
<context position="4327" citStr="Grefenstette, 1999" startWordPosition="671" endWordPosition="672">hing. Secondly, it is not clear how much and which knowledge to include in a fixed context-independent ontology, whether manually built or derived from a corpus. Thus, should metonymy, underspecified and point-of-view dependent hyponymy relations (Hearst, 1992) be included? Should age, for example, be classified as a hyponym of risk factor independent of context? To solve the first problem, we propose using the Web, which with approximately 968M pages2 is the largest corpus available to the NLP community. Using the web has proved successful in several fields of NLP, e.g., machine translation (Grefenstette, 1999) and bigram frequency estimation (Keller et al., 2002). In particular, (Keller et al., 2002) have shown that using the Web handles data sparseness better than smoothing. However, to our knowledge, the Web has not been used for anaphora resolution yet. We do not offer a solution to the second problem, but instead claim that, for our task, we do not need a predetermined fixed ontology at all. In Example (2), we do not need to have and fix the knowledge that age is always a risk factor, but only that, among the possible NP antecedents &amp;quot;Seymour&amp;quot;, &amp;quot;designer&amp;quot;, and &amp;quot;(designer&apos;s) age&amp;quot;, the latter is t</context>
<context position="22786" citStr="Grefenstette, 1999" startWordPosition="3711" endWordPosition="3712">use any external handcrafted knowledge. In addition, we use only shallow search patterns and do not process the pages that GOOGLE returns in any way.13 We achieve results comparable to knowledge- or processingintensive methods. Moreover, we only compare the likelihood of several given antecedents to cooccur in a given pattern with a given anaphor instead of assuming context-independent lexical relations. Thus, we can resolve anaphor/antecedent relations that might or should not be included in a lexical hierarchy (e.g. risk factor/age). Our results confirm results by (Keller et al., 2002) and (Grefenstette, 1999), who use the Web successfully for other NLP applications (for an overview of successful usage of the Web in NLP, see (Keller et al., 2002)). In line with these results, ours also show that the large amount of data available on the Web overcomes its intrinsic noise as well as the lack of linguistic processing. To our knowledge, ours is the first attempt to tackle anaphora resolution using the Web. 6 Contributions and Future Work We have proposed a novel method for nonpronominal anaphora resolution, using simple Web searches with shallow linguistic patterns. We show that the large amount of dat</context>
</contexts>
<marker>Grefenstette, 1999</marker>
<rawString>Gregory Grefenstette. 1999. The WWW as a resource for example-based MT tasks. In Proc. of ASLIB&apos;99 Translating and the Computer 21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda Harabagiu</author>
<author>Steven Maiorano</author>
</authors>
<title>Knowledge-lean coreference resolution and its relation to textual cohesion and coherence.</title>
<date>1999</date>
<booktitle>In Proc. of the ACL-99 Workshop on the Relation of Discourse and Dialogue Structure and Reference,</booktitle>
<pages>29--38</pages>
<contexts>
<context position="841" citStr="Harabagiu and Maiorano, 1999" startWordPosition="108" endWordPosition="112">ity of Edinburgh and Department of Computer Science University of Toronto natalia@cs.toronto.edu Abstract We present a novel method for resolving non-pronominal anaphora. Instead of using handcrafted lexical resources, we search the Web with shallow patterns which can be predetermined for the type of anaphoric phenomenon. In experiments for other-anaphora and bridging, our shallow, almost knowledge-free and unsupervised method achieves state-ofthe-art results. 1 Introduction After having focussed on pronominal anaphora, researchers are now devoting attention to other nominal anaphors as well (Harabagiu and Maiorano, 1999; Vieira and Poesio, 2000; Bierner, 2001; Modjeska, 2002; Ng and Cardie, 2002). These comprise such diverse phenomena as coreference, bridging (Clark, 1975) (see also Example (1)), and other-anaphora (Example (2)).1 (1) The apartment she shares with a 12-yearold daughter and her sister was rattled, books and crystal hit the floor, [... ] (2) You either believe Seymour can do it again or you don&apos;t. Beside the designer&apos;s age, other risk factors for Mr. Cray&apos;s company include the Cray-3&apos;s [... I chip technology. &apos;In all examples the anaphor is typed in bold face and the antecedent in italics. All</context>
<context position="21502" citStr="Harabagiu and Maiorano, 1999" startWordPosition="3515" endWordPosition="3518">ompares our results with those obtained by the algorithms used in (Poesio et al., 2002), of which one relies on WordNet and the other on knowledge a priori extracted from a parsed version of the BNC. In this preliminary study, our results outperform the Wordnet method and are comparable to those obtained from corpus-based knowledge extraction, although we do not linguistically process the web pages returned by our search. 5 Related Work Most of the current resolution algorithms for nonpronominal anaphora make heavy use of handcrafted ontologies. The COCKTAIL system for coreference resolution (Harabagiu and Maiorano, 1999) combines sortal constraints and conceptual glosses from WordNet with co-occurence information from a treebank. (Vieira and Poesio, 2000)&apos;s system for definite descriptions (covering, inter alia, coreference and bridging) also makes use of WordNet, as well as handcrafted constraints and consistency checks. LEX, a resolution algorithm developed for other-anaphors (Modjeska, 2002), employs lexical information from WordNet 44 and heuristics for resolving anaphora with NE antecedents, presupposing they have previously been classified into MUC-7 categories.12 All these approaches suffer from the sh</context>
</contexts>
<marker>Harabagiu, Maiorano, 1999</marker>
<rawString>Sanda Harabagiu and Steven Maiorano. 1999. Knowledge-lean coreference resolution and its relation to textual cohesion and coherence. In Proc. of the ACL-99 Workshop on the Relation of Discourse and Dialogue Structure and Reference, pages 29-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proc. of COLING-92.</booktitle>
<contexts>
<context position="3429" citStr="Hearst, 1992" startWordPosition="529" endWordPosition="530"> the database. The hierarchy is structured such that the desired information might not be straightforward to retrieve. For example, in WordNet, &amp;quot;floor&amp;quot; is encoded as part of &amp;quot;building&amp;quot;, but not as part of &amp;quot;apartment&amp;quot;, although &amp;quot;apartment&amp;quot; is itself a meronym of &amp;quot;apartment building&amp;quot; which in turn is a hyponym of &amp;quot;building&amp;quot; (see also (Vieira 39 and Poesio, 2000)). Moreover, manually built resources are expensive and time-consuming to build and maintain. There have been efforts to extract missing lexical relationships from corpora in order to build new knowledge sources and enrich existing ones (Hearst, 1992; Berland and Charniak, 1999; Poesio et al., 2002). In our view there are two main problems with these approaches. Firstly, the size of the used corpora still leads to data sparseness (Berland and Charniak, 1999) and the extraction procedure can therefore require extensive smoothing. Secondly, it is not clear how much and which knowledge to include in a fixed context-independent ontology, whether manually built or derived from a corpus. Thus, should metonymy, underspecified and point-of-view dependent hyponymy relations (Hearst, 1992) be included? Should age, for example, be classified as a hy</context>
<context position="6532" citStr="Hearst, 1992" startWordPosition="1032" endWordPosition="1033">loit this insight by adopting the following procedure: 1. Dependent on the anaphoric phenomenon, we determine which lexical relationships usually hold between anaphor and antecedent. For example, in other-anaphora, a hyponymy/similarity relation between the lexical heads of anaphor and antecedent is stipulated by the context,3 e.g. age is viewed as a risk factor. 2. We select patterns that structurally explicitly express the same lexical relationships. For example, NP1 and other NP2 is a pattern that usually expresses hyponymy/similarity relations between the hyponym NP1 and its hypernym NP2 (Hearst, 1992). 3. If the implicit lexical relationship between anaphor and antecedent is strong, then it is likely that anaphor and antecedent also frequently cooccur in the selected explicit patterns. We extract all possible antecedents for each anaphor, and instantiate the explicit pattern for all anaphor/antecedent pairs. In Example (2) the pattern NP1 and other NP2 can be instantiated with Seymour and other risk factors, designer and other risk factors, and age and other risk factors.4 The instantiation of a pat3From now on, we will often use &amp;quot;anaphor/antecedent&amp;quot; instead of the more cumbersome &amp;quot;lexical</context>
<context position="24045" citStr="Hearst, 1992" startWordPosition="3912" endWordPosition="3913">n without handcrafted lexical knowledge feasible. In particular, we have described two experiments carried out on two different anaphoric phenomena, namely other-anaphora and bridging. Exploiting free text achieves results comparable to those obtained when using rich and structured handcrafted resources. Given the shallow techniques used and the stateof-the-art results obtained, our method is promis121n the current evaluation of LEX, NEs are manually annotated. 13This is in contrast to other approaches that extract relations from corpora and that use chunkers/taggers/parsers for this purpose (Hearst, 1992; Poesio et al., 2002). ing. There is still room for improvement in several directions. Our NE resolution module, for example, is extremely simple and has a low recall (82%). As a large number of antecedents for otheranaphora are NEs (48.3%), including a state-ofthe-art NE resolution system would certainly improve our algorithm&apos;s performance. For each lexical relation we use variations of a single pattern. In the future we will explore the use of additional substantially different patterns. As this is pilot study, the datasets we use are small. We are currently testing our algorithm on a large</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proc. of COLING-92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Keller</author>
<author>Maria Lapata</author>
<author>Olga Ourioupina</author>
</authors>
<title>Using the Web to overcome data sparseness.</title>
<date>2002</date>
<booktitle>In Proc. of EMNLP-02,</booktitle>
<pages>230--237</pages>
<contexts>
<context position="4381" citStr="Keller et al., 2002" startWordPosition="678" endWordPosition="681">owledge to include in a fixed context-independent ontology, whether manually built or derived from a corpus. Thus, should metonymy, underspecified and point-of-view dependent hyponymy relations (Hearst, 1992) be included? Should age, for example, be classified as a hyponym of risk factor independent of context? To solve the first problem, we propose using the Web, which with approximately 968M pages2 is the largest corpus available to the NLP community. Using the web has proved successful in several fields of NLP, e.g., machine translation (Grefenstette, 1999) and bigram frequency estimation (Keller et al., 2002). In particular, (Keller et al., 2002) have shown that using the Web handles data sparseness better than smoothing. However, to our knowledge, the Web has not been used for anaphora resolution yet. We do not offer a solution to the second problem, but instead claim that, for our task, we do not need a predetermined fixed ontology at all. In Example (2), we do not need to have and fix the knowledge that age is always a risk factor, but only that, among the possible NP antecedents &amp;quot;Seymour&amp;quot;, &amp;quot;designer&amp;quot;, and &amp;quot;(designer&apos;s) age&amp;quot;, the latter is the most likely to be viewed as a risk factor. In the n</context>
<context position="22761" citStr="Keller et al., 2002" startWordPosition="3706" endWordPosition="3709">1. In contrast, we do not use any external handcrafted knowledge. In addition, we use only shallow search patterns and do not process the pages that GOOGLE returns in any way.13 We achieve results comparable to knowledge- or processingintensive methods. Moreover, we only compare the likelihood of several given antecedents to cooccur in a given pattern with a given anaphor instead of assuming context-independent lexical relations. Thus, we can resolve anaphor/antecedent relations that might or should not be included in a lexical hierarchy (e.g. risk factor/age). Our results confirm results by (Keller et al., 2002) and (Grefenstette, 1999), who use the Web successfully for other NLP applications (for an overview of successful usage of the Web in NLP, see (Keller et al., 2002)). In line with these results, ours also show that the large amount of data available on the Web overcomes its intrinsic noise as well as the lack of linguistic processing. To our knowledge, ours is the first attempt to tackle anaphora resolution using the Web. 6 Contributions and Future Work We have proposed a novel method for nonpronominal anaphora resolution, using simple Web searches with shallow linguistic patterns. We show tha</context>
</contexts>
<marker>Keller, Lapata, Ourioupina, 2002</marker>
<rawString>Frank Keller, Maria Lapata, and Olga Ourioupina. 2002. Using the Web to overcome data sparseness. In Proc. of EMNLP-02, pages 230-237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Natalia N Modjeska</author>
</authors>
<title>Lexical and grammatical role constraints in resolving other-anaphora.</title>
<date>2002</date>
<booktitle>In Proc. of DAARC-02.</booktitle>
<contexts>
<context position="897" citStr="Modjeska, 2002" startWordPosition="119" endWordPosition="120">nto natalia@cs.toronto.edu Abstract We present a novel method for resolving non-pronominal anaphora. Instead of using handcrafted lexical resources, we search the Web with shallow patterns which can be predetermined for the type of anaphoric phenomenon. In experiments for other-anaphora and bridging, our shallow, almost knowledge-free and unsupervised method achieves state-ofthe-art results. 1 Introduction After having focussed on pronominal anaphora, researchers are now devoting attention to other nominal anaphors as well (Harabagiu and Maiorano, 1999; Vieira and Poesio, 2000; Bierner, 2001; Modjeska, 2002; Ng and Cardie, 2002). These comprise such diverse phenomena as coreference, bridging (Clark, 1975) (see also Example (1)), and other-anaphora (Example (2)).1 (1) The apartment she shares with a 12-yearold daughter and her sister was rattled, books and crystal hit the floor, [... ] (2) You either believe Seymour can do it again or you don&apos;t. Beside the designer&apos;s age, other risk factors for Mr. Cray&apos;s company include the Cray-3&apos;s [... I chip technology. &apos;In all examples the anaphor is typed in bold face and the antecedent in italics. All examples in this paper are from the Wall Street Journal</context>
<context position="2248" citStr="Modjeska, 2002" startWordPosition="341" endWordPosition="342">artment&amp;quot; has already been introduced, and a part-of relation between the two entities can be established. In other-anaphora, other provides a set-complement to an entity already evoked in the discourse model. In Example (2), the NP &amp;quot;other risk factors for Mr. Cray&apos;s company&amp;quot; refers to a set of risk factors excluding the designer&apos;s age, and can be paraphrased as &amp;quot;other risk factors (for Mr. Cray&apos;s company) than the designer&apos;s age&amp;quot;. There is evidence that grammatical salience plays a lesser role for resolving anaphors with full lexical heads, than for pronominal anaphora (Strube and Hahn, 1999; Modjeska, 2002). Instead, a large and diverse amount of lexical or world knowledge is necessary to understand examples like (1) and (2): for example, that floors are parts of apartments or that age can be viewed as a risk factor. Therefore, the state-of-the-art resolution systems that handle these phenomena rely heavily on handcrafted resources, such as the WordNet lexical hierarchy (Fellbaum, 1998). Using WordNet suffers from several major drawbacks. Many expressions (e.g., risk factor), word senses and lexical relations (e.g., floor as a part of an apartment) are missing from the database. The hierarchy is</context>
<context position="8401" citStr="Modjeska, 2002" startWordPosition="1333" endWordPosition="1334">s available, the Web.6 We submit all instantiated patterns as queries to the Web making use of the GOOGLE API technology and, as a first approximation, select the instantiation yielding the highest number of hits. Here, age and other risk factors yields over 400 hits, whereas the other two instantiations for this example yield 0 hits each. 3 Experiment I: Other-anaphora Here we restrict other-anaphora to referential lexical NPs with the modifiers other or another and non-structurally given antecedents, as in Example (2).7 The distance between an other-anaphor and its antecedent can be large; (Modjeska, 2002) observed a dependency that spans over 17 sentences. 3.1 Data Collection and Preparation We tested our method on 120 samples of otheranaphors from the Wall Street Journal corpus (Penn Treebank release 2, first three sections). These samples are part of the dataset reported in (Modjeska, 2002). We used the samples in which 5http://info.ox.ac.uk/bnc 6The Web is a constantly growing, changing and updating resource. On the one hand, its size and changing potential are an advantage as we can have access to such a large corpus without having to create it. On the other hand, one has no control over i</context>
<context position="16467" citStr="Modjeska, 2002" startWordPosition="2673" endWordPosition="2674">nal score M/ant. Pr (I max ant) M Iant = We resolve to the antecedent with the highest M -ant • In both methods, if two antecedents achieve the same score, a recency based tie-breaker chooses the antecedent closest to the anaphor in the text. 3.4 Results and Error Analysis We postulate three categories for classifying the results: (i) correct, when the antecedent selected is the correct one; (ii) lenient, when the antecedent selected refers to the same entity as the correct antecedent; (iii) wrong in all other cases. In Table 2, we compare our results with those obtained by the algorithm LEX (Modjeska, 2002). Although LEX makes extensive use of WordNet, our algorithm achieves comparable results. Our algorithm&apos;s mistakes are due to several factors. NEs. As 58 (48.3%) out of the total 120 anaphors (48.3%) have NE antecedents, NE resolution is crucial for our algorithm. The low recall of our NE recognition module has a significant impact on our algorithm&apos;s performance as it leads to missing instantiations. Moreover, incorrect NE classifications yield incorrect instantiations, although this problem is not very frequent as the precision of our NE resolution module is relatively high (93%). Vague Anaph</context>
<context position="21883" citStr="Modjeska, 2002" startWordPosition="3570" endWordPosition="3571"> pages returned by our search. 5 Related Work Most of the current resolution algorithms for nonpronominal anaphora make heavy use of handcrafted ontologies. The COCKTAIL system for coreference resolution (Harabagiu and Maiorano, 1999) combines sortal constraints and conceptual glosses from WordNet with co-occurence information from a treebank. (Vieira and Poesio, 2000)&apos;s system for definite descriptions (covering, inter alia, coreference and bridging) also makes use of WordNet, as well as handcrafted constraints and consistency checks. LEX, a resolution algorithm developed for other-anaphors (Modjeska, 2002), employs lexical information from WordNet 44 and heuristics for resolving anaphora with NE antecedents, presupposing they have previously been classified into MUC-7 categories.12 All these approaches suffer from the shortcomings that we outlined in Section 1. In contrast, we do not use any external handcrafted knowledge. In addition, we use only shallow search patterns and do not process the pages that GOOGLE returns in any way.13 We achieve results comparable to knowledge- or processingintensive methods. Moreover, we only compare the likelihood of several given antecedents to cooccur in a gi</context>
</contexts>
<marker>Modjeska, 2002</marker>
<rawString>Natalia N. Modjeska. 2002. Lexical and grammatical role constraints in resolving other-anaphora. In Proc. of DAARC-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
<author>Claire Cardie</author>
</authors>
<title>Improving machine learning approaches to coreference resolution.</title>
<date>2002</date>
<booktitle>In Proc. of ACL-02,</booktitle>
<pages>104--111</pages>
<contexts>
<context position="919" citStr="Ng and Cardie, 2002" startWordPosition="121" endWordPosition="124">oronto.edu Abstract We present a novel method for resolving non-pronominal anaphora. Instead of using handcrafted lexical resources, we search the Web with shallow patterns which can be predetermined for the type of anaphoric phenomenon. In experiments for other-anaphora and bridging, our shallow, almost knowledge-free and unsupervised method achieves state-ofthe-art results. 1 Introduction After having focussed on pronominal anaphora, researchers are now devoting attention to other nominal anaphors as well (Harabagiu and Maiorano, 1999; Vieira and Poesio, 2000; Bierner, 2001; Modjeska, 2002; Ng and Cardie, 2002). These comprise such diverse phenomena as coreference, bridging (Clark, 1975) (see also Example (1)), and other-anaphora (Example (2)).1 (1) The apartment she shares with a 12-yearold daughter and her sister was rattled, books and crystal hit the floor, [... ] (2) You either believe Seymour can do it again or you don&apos;t. Beside the designer&apos;s age, other risk factors for Mr. Cray&apos;s company include the Cray-3&apos;s [... I chip technology. &apos;In all examples the anaphor is typed in bold face and the antecedent in italics. All examples in this paper are from the Wall Street Journal (WSJ), Penn Treebank,</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Vincent Ng and Claire Cardie. 2002. Improving machine learning approaches to coreference resolution. In Proc. of ACL-02, pages 104-111.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Massimo Poesio</author>
</authors>
<location>Tomonori lshikawa, Sabine</location>
<marker>Poesio, </marker>
<rawString>Massimo Poesio, Tomonori lshikawa, Sabine</rawString>
</citation>
<citation valid="true">
<authors>
<author>Schulte im Walde</author>
<author>Renata Viera</author>
</authors>
<title>Acquiring lexical knowledge for anaphora resolution.</title>
<date>2002</date>
<booktitle>In Proc. of LREC-02,</booktitle>
<pages>1220--1224</pages>
<marker>Walde, Viera, 2002</marker>
<rawString>Schulte im Walde, and Renata Viera. 2002. Acquiring lexical knowledge for anaphora resolution. In Proc. of LREC-02, pages 1220-1224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Udo Hahn</author>
</authors>
<title>Functional centering — grounding referential coherence in information structure.</title>
<date>1999</date>
<journal>Computational Lingustics,</journal>
<pages>25--3</pages>
<contexts>
<context position="2231" citStr="Strube and Hahn, 1999" startWordPosition="337" endWordPosition="340">related entity, &amp;quot;the apartment&amp;quot; has already been introduced, and a part-of relation between the two entities can be established. In other-anaphora, other provides a set-complement to an entity already evoked in the discourse model. In Example (2), the NP &amp;quot;other risk factors for Mr. Cray&apos;s company&amp;quot; refers to a set of risk factors excluding the designer&apos;s age, and can be paraphrased as &amp;quot;other risk factors (for Mr. Cray&apos;s company) than the designer&apos;s age&amp;quot;. There is evidence that grammatical salience plays a lesser role for resolving anaphors with full lexical heads, than for pronominal anaphora (Strube and Hahn, 1999; Modjeska, 2002). Instead, a large and diverse amount of lexical or world knowledge is necessary to understand examples like (1) and (2): for example, that floors are parts of apartments or that age can be viewed as a risk factor. Therefore, the state-of-the-art resolution systems that handle these phenomena rely heavily on handcrafted resources, such as the WordNet lexical hierarchy (Fellbaum, 1998). Using WordNet suffers from several major drawbacks. Many expressions (e.g., risk factor), word senses and lexical relations (e.g., floor as a part of an apartment) are missing from the database.</context>
</contexts>
<marker>Strube, Hahn, 1999</marker>
<rawString>Michael Strube and Udo Hahn. 1999. Functional centering — grounding referential coherence in information structure. Computational Lingustics, 25(3):309-344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Renata Vieira</author>
<author>Massimo Poesio</author>
</authors>
<title>An empirically-based system for processing definite descriptions.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>4</issue>
<contexts>
<context position="866" citStr="Vieira and Poesio, 2000" startWordPosition="113" endWordPosition="116">t of Computer Science University of Toronto natalia@cs.toronto.edu Abstract We present a novel method for resolving non-pronominal anaphora. Instead of using handcrafted lexical resources, we search the Web with shallow patterns which can be predetermined for the type of anaphoric phenomenon. In experiments for other-anaphora and bridging, our shallow, almost knowledge-free and unsupervised method achieves state-ofthe-art results. 1 Introduction After having focussed on pronominal anaphora, researchers are now devoting attention to other nominal anaphors as well (Harabagiu and Maiorano, 1999; Vieira and Poesio, 2000; Bierner, 2001; Modjeska, 2002; Ng and Cardie, 2002). These comprise such diverse phenomena as coreference, bridging (Clark, 1975) (see also Example (1)), and other-anaphora (Example (2)).1 (1) The apartment she shares with a 12-yearold daughter and her sister was rattled, books and crystal hit the floor, [... ] (2) You either believe Seymour can do it again or you don&apos;t. Beside the designer&apos;s age, other risk factors for Mr. Cray&apos;s company include the Cray-3&apos;s [... I chip technology. &apos;In all examples the anaphor is typed in bold face and the antecedent in italics. All examples in this paper a</context>
<context position="21639" citStr="Vieira and Poesio, 2000" startWordPosition="3535" endWordPosition="3538">edge a priori extracted from a parsed version of the BNC. In this preliminary study, our results outperform the Wordnet method and are comparable to those obtained from corpus-based knowledge extraction, although we do not linguistically process the web pages returned by our search. 5 Related Work Most of the current resolution algorithms for nonpronominal anaphora make heavy use of handcrafted ontologies. The COCKTAIL system for coreference resolution (Harabagiu and Maiorano, 1999) combines sortal constraints and conceptual glosses from WordNet with co-occurence information from a treebank. (Vieira and Poesio, 2000)&apos;s system for definite descriptions (covering, inter alia, coreference and bridging) also makes use of WordNet, as well as handcrafted constraints and consistency checks. LEX, a resolution algorithm developed for other-anaphors (Modjeska, 2002), employs lexical information from WordNet 44 and heuristics for resolving anaphora with NE antecedents, presupposing they have previously been classified into MUC-7 categories.12 All these approaches suffer from the shortcomings that we outlined in Section 1. In contrast, we do not use any external handcrafted knowledge. In addition, we use only shallow</context>
</contexts>
<marker>Vieira, Poesio, 2000</marker>
<rawString>Renata Vieira and Massimo Poesio. 2000. An empirically-based system for processing definite descriptions. Computational Linguistics, 26(4).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>