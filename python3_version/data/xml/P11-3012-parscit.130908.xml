<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.038947">
<title confidence="0.997515">
An Error Analysis of Relation Extraction in Social Media Documents
</title>
<author confidence="0.994486">
Gregory Ichneumon Brown
</author>
<affiliation confidence="0.7526715">
University of Colorado at Boulder
Boulder, Colorado
</affiliation>
<email confidence="0.998955">
browngp@colorado.edu
</email>
<sectionHeader confidence="0.995219" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997144266666667">
Relation extraction in documents allows the
detection of how entities being discussed in a
document are related to one another (e.g. part-
of). This paper presents an analysis of a re-
lation extraction system based on prior work
but applied to the J.D. Power and Associates
Sentiment Corpus to examine how the system
works on documents from a range of social
media. The results are examined on three dif-
ferent subsets of the JDPA Corpus, showing
that the system performs much worse on doc-
uments from certain sources. The proposed
explanation is that the features used are more
appropriate to text with strong editorial stan-
dards than the informal writing style of blogs.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999511153846154">
To summarize accurately, determine the sentiment,
or answer questions about a document it is often nec-
essary to be able to determine the relationships be-
tween entities being discussed in the document (such
as part-of or member-of). In the simple sentiment
example
Example 1.1: I bought a new car yesterday. I love
the powerful engine.
determining the sentiment the author is expressing
about the car requires knowing that the engine is a
part of the car so that the positive sentiment being
expressed about the engine can also be attributed to
the car.
In this paper we examine our preliminary results
from applying a relation extraction system to the
J.D. Power and Associates (JDPA) Sentiment Cor-
pus (Kessler et al., 2010). Our system uses lex-
ical features from prior work to classify relations,
and we examine how the system works on different
subsets from the JDPA Sentiment Corpus, breaking
the source documents down into professionally writ-
ten reviews, blog reviews, and social networking re-
views. These three document types represent quite
different writing styles, and we see significant differ-
ence in how the relation extraction system performs
on the documents from different sources.
</bodyText>
<sectionHeader confidence="0.994353" genericHeader="method">
2 Relation Corpora
</sectionHeader>
<subsectionHeader confidence="0.875291">
2.1 ACE-2004 Corpus
</subsectionHeader>
<bodyText confidence="0.999843111111111">
The Automatic Content Extraction (ACE) Corpus
(Mitchell, et al., 2005) is one of the most common
corpora for performing relation extraction. In addi-
tion to the co-reference annotations, the Corpus is
annotated to indicate 23 different relations between
real-world entities that are mentioned in the same
sentence. The documents consist of broadcast news
transcripts and newswire articles from a variety of
news organizations.
</bodyText>
<subsectionHeader confidence="0.997233">
2.2 JDPA Sentiment Corpus
</subsectionHeader>
<bodyText confidence="0.9999335">
The JDPA Corpus consists of 457 documents con-
taining discussions about cars, and 180 documents
discussing cameras (Kessler et al., 2010). In this
work we only use the automotive documents. The
documents are drawn from a variety of sources,
and we particularly focus on the 24% of the doc-
uments from the JDPA Power Steering blog, 18%
from Blogspot, and 18% from LiveJournal.
</bodyText>
<page confidence="0.990851">
64
</page>
<subsectionHeader confidence="0.256622">
Proceedings of the ACL-HLT 2011 Student Session, pages 64–68,
</subsectionHeader>
<bodyText confidence="0.981753666666667">
Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics
The annotated mentions in the Corpus are single
or multi-word expressions which refer to a particu-
lar real world or abstract entity. The mentions are
annotated to indicate sets of mentions which con-
stitute co-reference groups referring to the same en-
tity. Five relationships are annotated between these
entities: PartOf, FeatureOf, Produces, InstanceOf,
and MemberOf. One significant difference between
these relation annotations and those in the ACE Cor-
pus is that the former are relations between sets of
mentions (the co-reference groups) rather than be-
tween individual mentions. This means that these
relations are not limited to being between mentions
in the same sentence. So in Example 1.1, “engine”
would be marked as a part of “car” in the JDPA Cor-
pus annotations, but there would be no relation an-
notated in the ACE Corpus. For a more direct com-
parison to the ACE Corpus results, we restrict our-
selves only to mentions within the same sentence
(we discuss this decision further in section 5.4).
</bodyText>
<sectionHeader confidence="0.953101" genericHeader="method">
3 Relation Extraction System
</sectionHeader>
<subsectionHeader confidence="0.986989">
3.1 Overview
</subsectionHeader>
<bodyText confidence="0.9999608">
The system extracts all pairs of mentions in a sen-
tence, and then classifies each pair of mentions as
either having a relationship, having an inverse rela-
tionship, or having no relationship. So for the PartOf
relation in the JDPA Sentiment Corpus we consider
both the relation “X is part of Y” and “Y is part of
X”. The classification of each mention pair is per-
formed using a support vector machine implemented
using libLinear (Fan et al., 2008).
To generate the features for each of the mention
pairs a proprietary JDPA Tokenizer is used for pars-
ing the document and the Stanford Parser (Klein and
Manning, 2003) is used to generate parse trees and
part of speech tags for the sentences in the docu-
ments.
</bodyText>
<subsectionHeader confidence="0.980131">
3.2 Features
</subsectionHeader>
<bodyText confidence="0.999455461538462">
We used Zhou et al.’s lexical features (Zhou et al.,
2005) as the basis for the features of our system sim-
ilar to what other researchers have done (Chan and
Roth, 2010). Additional work has extended these
features (Jiang and Zhai, 2007) or incorporated other
data sources (e.g. WordNet), but in this paper we fo-
cus solely on the initial step of applying these same
lexical features to the JDPA Corpus.
The Mention Level, Overlap, Base Phrase Chunk-
ing, Dependency Tree, and Parse Tree features are
the same as Zhou et al. (except for using the Stan-
ford Parser rather than the Collins Parser). The mi-
nor changes we have made are summarized below:
</bodyText>
<listItem confidence="0.996216421052632">
• Word Features: Identical, except rather than
using a heuristic to determine the head word of
the phrase it is chosen to be the noun (or any
other word if there are no nouns in the men-
tion) that is the least deep in the parse tree. This
change has minimal impact.
• Entity Types: Some of the entity types in the
JDPA Corpus indicate the type of the relation
(e.g. CarFeature, CarPart) and so we replace
those entity types with “Unknown”.
• Token Class: We added an additional feature
(TC12+ET12) indicating the Token Class of
the head words (e.g. Abbreviation, DollarAm-
mount, Honorific) combined with the entity
types.
• Semantic Information: These features are
specific to the ACE relations and so are not
used. In Zhou et al.’s work, this set of features
increases the overall F-Measure by 1.5.
</listItem>
<sectionHeader confidence="0.999664" genericHeader="method">
4 Results
</sectionHeader>
<subsectionHeader confidence="0.996578">
4.1 ACE Corpus Results
</subsectionHeader>
<bodyText confidence="0.999865727272727">
We ran our system on the ACE-2004 Corpus as a
baseline to prove that the system worked properly
and could approximately duplicate Zhou et al.’s re-
sults. Using 5-fold cross validation on the newswire
and broadcast news documents in the dataset we
achieved an average overall F-Measure of 50.6 on
the fine-grained relations. Although a bit lower than
Zhou et al.’s result of 55.5 (Zhou et al., 2005), we
attribute the difference to our use of a different tok-
enizer, different parser, and having not used the se-
mantic information features.
</bodyText>
<subsectionHeader confidence="0.906713">
4.2 JDPA Sentiment Corpus Results
</subsectionHeader>
<bodyText confidence="0.9999745">
We randomly divided the JDPA Corpus into train-
ing (70%), development (10%), and test (20%)
datasets. Table 1 shows relation extraction results
of the system on the test portion of the corpus.
The results are further broken out by three differ-
ent source types to highlight the differences caused
</bodyText>
<page confidence="0.995092">
65
</page>
<table confidence="0.9999385">
Relation All Documents F P LiveJournal F P Blogspot F P JDPA F
P R R R R
FEATURE OF 44.8 42.3 43.5 26.8 35.8 30.6 44.1 40.0 42.0 59.0 55.0 56.9
MEMBER OF 34.1 10.7 16.3 0.0 0.0 0.0 36.0 13.2 19.4 36.4 13.7 19.9
PART OF 46.5 34.7 39.8 41.4 17.5 24.6 48.1 35.6 40.9 48.8 43.9 46.2
PRODUCES 51.7 49.2 50.4 05.0 36.4 08.8 43.7 36.0 39.5 66.5 64.6 65.6
INSTANCE OF 37.1 16.7 23.0 44.8 14.9 22.4 42.1 13.0 19.9 30.9 29.6 30.2
Overall 46.0 36.2 40.5 27.1 22.6 24.6 45.2 33.3 38.3 53.7 46.5 49.9
</table>
<tableCaption confidence="0.996913">
Table 1: Relation extraction results on the JDPA Corpus test set, broken down by document source.
</tableCaption>
<table confidence="0.99980525">
LiveJournal Blogspot JDPA ACE
Tokens Per Sentence 19.2 18.6 16.5 19.7
Relations Per Sentence 1.08 1.71 2.56 0.56
Relations Not In Same Sentence 33% 30% 27% 0%
Training Mention Pairs in One Sentence 58,452 54,480 95,630 77,572
Mentions Per Sentence 4.26 4.32 4.03 3.16
Mentions Per Entity 1.73 1.63 1.33 2.36
Mentions With Only One Token 77.3% 73.2% 61.2% 56.2%
</table>
<tableCaption confidence="0.999505">
Table 2: Selected document statistics for three JDPA Corpus document sources.
</tableCaption>
<bodyText confidence="0.9998466">
by the writing styles from different types of media:
LiveJournal (livejournal.com), a social media site
where users comment and discuss stories with each
other; Blogspot (blospot.com), Google’s blogging
platform; and JDPA (jdpower.com’s Power Steering
blog), consisting of reviews of cars written by JDPA
professional writers/analysts. These subsets were
selected because they provide the extreme (JDPA
and LiveJournal) and average (Blogspot) results for
the overall dataset.
</bodyText>
<sectionHeader confidence="0.993588" genericHeader="evaluation">
5 Analysis
</sectionHeader>
<bodyText confidence="0.9999855">
Overall the system is not performing as well as it
does on the ACE-2004 dataset. However, there is
a 25 point F-Measure difference between the Live-
Journal and JDPA authored documents. This sug-
gests that the informal style of the LiveJournal doc-
uments may be reducing the effectiveness of the
features developed by Zhou et al., which were de-
veloped on newswire and broadcast news transcript
documents.
In the remainder of this section we look at a sta-
tistical analysis of the training portion of the JDPA
Corpus, separated by document source, and suggest
areas where improved features may be able to aid
relation extraction on the JDPA Corpus.
</bodyText>
<subsectionHeader confidence="0.998621">
5.1 Document Statistic Effects on Classifier
</subsectionHeader>
<bodyText confidence="0.99988">
Table 2 summarizes some important statistical dif-
ferences between the documents from different
sources. These differences suggest two reasons why
the instances being used to train the classifier could
be skewed disproportionately towards the JDPA au-
thored documents.
First, the JDPA written documents express a much
larger number of relations between entities. When
training the classifier, these differences will cause a
large share of the instances that have a relation to be
from a JDPA written document, skewing the clas-
sifier towards any language clues specific to these
documents.
Second, the number of mention pairs occurring
within one sentence is significantly higher in the
JDPA authored documents than the other docu-
ments. This disparity is even true on a per sentence
or per document basis. This provides the classifier
with significantly more negative examples written in
a JDPA written style.
</bodyText>
<page confidence="0.980495">
66
</page>
<table confidence="0.9999150625">
LiveJournal Blogspot JDPA
Mention % Mention % Mention %
Phrase Phrase Phrase
car 6.2 it 8.1 features 2.4
Maybach 5.6 car 2.1 vehicles 1.6
it 3.7 its 2.0 its 1.4
it’s 1.7 cars 2.0 Journey 1.3
Maybach 1.5 Hyundai 2.0 car 1.2
57 S
It 1.2 vehicle 1.5 2 T 1.2
Sport
mileage 1.1 one 1.5 G37 1.2
its 1.1 engine 1.5 models 1.1
engine 0.9 power 1.1 engine 1.1
57 S 0.9 interior 1.1 It 1.1
Total: 23.9% Total: 22.9% Total: 13.6%
</table>
<tableCaption confidence="0.958431666666667">
Table 3: Top 10 phrases in mention pairs whose relation
was incorrectly classified, and the total percentage of er-
rors from the top ten.
</tableCaption>
<subsectionHeader confidence="0.999754">
5.2 Common Errors
</subsectionHeader>
<bodyText confidence="0.999989705882353">
Table 3 shows the mention phrases that occur
most commonly in the incorrectly classified men-
tion pairs. For the LiveJournal and Blogspot data,
many more of the errors are due to a few specific
phrases being classified incorrectly such as “car”,
“Maybach”, and various forms of “it”. The top four
phrases constitute 17% of the errors for LiveJour-
nal and 14% for Blogspot. Whereas the JDPA doc-
uments have the errors spread more evenly across
mention phrases, with the top 10 phrases constitut-
ing 13.6% of the total errors.
Furthermore, the phrases causing many of the
problems for the LiveJournal and Blogspot relation
detection are generic nouns and pronouns such as
“car” and “it”. This suggests that the classifier
is having difficulty determining relationships when
these less descriptive words are involved.
</bodyText>
<subsectionHeader confidence="0.994438">
5.3 Vocabulary
</subsectionHeader>
<bodyText confidence="0.999686">
To investigate where these variations in phrase error
rates comes from, we performed two analyses of the
word frequencies in the documents: Table 4 shows
the frequency of some common words in the docu-
ments; Table 5 shows the frequency of a select set of
parts-of-speech per sentence in the document.
</bodyText>
<table confidence="0.968707875">
Word Percent of All Tokens in Documents ACE
LiveJournal Blogspot JDPA
car 0.86 0.71 0.20 0.01
I 1.91 1.28 0.24 0.21
it 1.42 0.97 0.23 0.63
It 0.33 0.27 0.35 0.09
its 0.25 0.18 0.22 0.19
the 4.43 4.60 3.54 4.81
</table>
<tableCaption confidence="0.993102">
Table 4: Frequency of some common words per token.
</tableCaption>
<table confidence="0.999930222222222">
POS LiveJournal POS Occurrence Sentence ACE
Per JDPA
Blogspot
NN 2.68 3.01 3.21 2.90
NNS 0.68 0.73 0.85 1.08
NNP 0.93 1.41 1.89 1.48
NNPS 0.03 0.03 0.03 0.06
PRP 0.98 0.70 0.20 0.57
PRP$ 0.21 0.18 0.07 0.20
</table>
<tableCaption confidence="0.999626">
Table 5: Frequency of select part-of-speech tags.
</tableCaption>
<bodyText confidence="0.999769611111111">
We find that despite all the documents discussing
cars, the JDPA reviews use the word “car” much less
often, and use proper nouns significantly more often.
Although “car” also appears in the top ten errors on
the JDPA documents, the total percentage of the er-
rors is one fifth of the error rate on the LiveJour-
nal documents. The JDPA authored documents also
tend to have more multi-word mention phrases (Ta-
ble 2) suggesting that the authors use more descrip-
tive language when referring to an entity. 77.3%
of the mentions in LiveJournal documents use only
a single word while 61.2% of mentions JDPA au-
thored documents are a single word.
Rather than descriptive noun phrases, the Live-
Journal and Blogspot documents make more use of
pronouns. LiveJournal especially uses pronouns of-
ten, to the point of averaging one per sentence, while
JDPA uses only one every five sentences.
</bodyText>
<subsectionHeader confidence="0.781279">
5.4 Extra-Sentential Relations
</subsectionHeader>
<bodyText confidence="0.9999424">
Many relations in the JDPA Corpus occur between
entities which are not mentioned in the same sen-
tence. Our system only detects relations between
mentions in the same sentence, causing about 29%
of entity relations to never be detected (Table 2).
</bodyText>
<page confidence="0.998205">
67
</page>
<bodyText confidence="0.99987725">
The LiveJournal documents are more likely to con-
tain relationships between entities that are not men-
tioned in the same sentence. In the semantic role
labeling (SRL) domain, extra-sentential arguments
have been shown to significantly improve SRL per-
formance (Gerber and Chai, 2010). Improvements
in entity relation extraction could likely be made by
extending Zhou et al.’s features across sentences.
</bodyText>
<sectionHeader confidence="0.999174" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999970344827586">
The above analysis shows that at least some of the
reason for the system performing worse on the JDPA
Corpus than on the ACE-2004 Corpus is that many
of the documents in the JDPA Corpus have a dif-
ferent writing style from the news articles in the
ACE Corpus. Both the ACE news documents, and
the JDPA authored documents are written by profes-
sional writers with stronger editorial standards than
the other JDPA Corpus documents, and the relation
extraction system performs much better on profes-
sionally edited documents. The heavy use of pro-
nouns and less descriptive mention phrases in the
other documents seems to be one cause of the re-
duction in relation extraction performance. There is
also some evidence that because of the greater num-
ber of relations in the JPDA authored documents that
the classifier training data could be skewed more to-
wards those documents.
Future work needs to explore features that can ad-
dress the difference in language usage that the dif-
ferent authors use. This work also does not ad-
dress whether the relation extraction task is being
negatively impacted by poor tokenization or pars-
ing of the documents rather than the problems being
caused by the relation classification itself. Further
work is also needed to classify extra-sentential rela-
tions, as the current methods look only at relations
occurring within a single sentence thus ignoring a
large percentage of relations between entities.
</bodyText>
<sectionHeader confidence="0.998844" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999216666666667">
This work was partially funded and supported by
J. D. Power and Associates. I would like to thank
Nicholas Nicolov, Jason Kessler, and Will Headden
for their help in formulating this work, and my the-
sis advisers: Jim Martin, Rodney Nielsen, and Mike
Mozer.
</bodyText>
<sectionHeader confidence="0.99631" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999112448275862">
Chan, Y. S. and Roth D. Exploiting Background Knowl-
edge for Relation Extraction. Proceedings of the 23rd
International Conference on Computational Linguis-
tics (Coling 2010).
R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and
C.-J. Lin. LIBLINEAR: A library for large linear
classification. Journal of Machine Learning Research
9(2008), 1871-1874. 2008.
Gerber, M. and Chai, J. Beyond NomBank: A Study of
Implicit Arguments for Nominal Predicates. Proceed-
ings of the 48th Annual Meeting of the Association for
Computational Linguistics, pages 1583-1592. 2010.
Jiang, J. and Zhai, C.X. A systematic exploration of the
feature space for relation extraction. In The Proceed-
ings of NAACL/HLT. 2007.
Kessler J., Eckert M., Clark L., and Nicolov N.. The
ICWSM 2010 JDPA Sentiment Corpus for the Auto-
motive Domain International AAAI Conference on
Weblogs and Social Media Data Challenge Workshop.
2010.
Klein D. and Manning C. Accurate Unlexicalized Pars-
ing. Proceedings of the 41st Meeting of the Asso-
ciation for Computational Linguistics, pp. 423-430.
2003.
Mitchell A., et al. ACE 2004 Multilingual Training Cor-
pus. Linguistic Data Consortium, Philadelphia. 2005.
Zhou G., Su J., Zhang J., and Zhang M. Exploring var-
ious knowledge in relation extraction. Proceedings of
the 43rd Annual Meeting of the ACL. 2005.
</reference>
<page confidence="0.999439">
68
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.667902">
<title confidence="0.99948">An Error Analysis of Relation Extraction in Social Media Documents</title>
<author confidence="0.999102">Gregory Ichneumon</author>
<affiliation confidence="0.845529">University of Colorado at Boulder,</affiliation>
<email confidence="0.999914">browngp@colorado.edu</email>
<abstract confidence="0.9978833125">Relation extraction in documents allows the detection of how entities being discussed in a document are related to one another (e.g. partof). This paper presents an analysis of a relation extraction system based on prior work but applied to the J.D. Power and Associates Sentiment Corpus to examine how the system works on documents from a range of social media. The results are examined on three different subsets of the JDPA Corpus, showing that the system performs much worse on documents from certain sources. The proposed explanation is that the features used are more appropriate to text with strong editorial standards than the informal writing style of blogs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y S Chan</author>
<author>D Roth</author>
</authors>
<title>Exploiting Background Knowledge for Relation Extraction.</title>
<date>2010</date>
<booktitle>Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<contexts>
<context position="5000" citStr="Chan and Roth, 2010" startWordPosition="814" endWordPosition="817">relation “X is part of Y” and “Y is part of X”. The classification of each mention pair is performed using a support vector machine implemented using libLinear (Fan et al., 2008). To generate the features for each of the mention pairs a proprietary JDPA Tokenizer is used for parsing the document and the Stanford Parser (Klein and Manning, 2003) is used to generate parse trees and part of speech tags for the sentences in the documents. 3.2 Features We used Zhou et al.’s lexical features (Zhou et al., 2005) as the basis for the features of our system similar to what other researchers have done (Chan and Roth, 2010). Additional work has extended these features (Jiang and Zhai, 2007) or incorporated other data sources (e.g. WordNet), but in this paper we focus solely on the initial step of applying these same lexical features to the JDPA Corpus. The Mention Level, Overlap, Base Phrase Chunking, Dependency Tree, and Parse Tree features are the same as Zhou et al. (except for using the Stanford Parser rather than the Collins Parser). The minor changes we have made are summarized below: • Word Features: Identical, except rather than using a heuristic to determine the head word of the phrase it is chosen to b</context>
</contexts>
<marker>Chan, Roth, 2010</marker>
<rawString>Chan, Y. S. and Roth D. Exploiting Background Knowledge for Relation Extraction. Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R-E Fan</author>
<author>K-W Chang</author>
<author>C-J Hsieh</author>
<author>X-R Wang</author>
<author>C-J Lin</author>
</authors>
<title>LIBLINEAR: A library for large linear classification.</title>
<date>2008</date>
<journal>Journal of Machine Learning Research</journal>
<volume>9</volume>
<issue>2008</issue>
<pages>1871--1874</pages>
<contexts>
<context position="4558" citStr="Fan et al., 2008" startWordPosition="733" endWordPosition="736">rpus results, we restrict ourselves only to mentions within the same sentence (we discuss this decision further in section 5.4). 3 Relation Extraction System 3.1 Overview The system extracts all pairs of mentions in a sentence, and then classifies each pair of mentions as either having a relationship, having an inverse relationship, or having no relationship. So for the PartOf relation in the JDPA Sentiment Corpus we consider both the relation “X is part of Y” and “Y is part of X”. The classification of each mention pair is performed using a support vector machine implemented using libLinear (Fan et al., 2008). To generate the features for each of the mention pairs a proprietary JDPA Tokenizer is used for parsing the document and the Stanford Parser (Klein and Manning, 2003) is used to generate parse trees and part of speech tags for the sentences in the documents. 3.2 Features We used Zhou et al.’s lexical features (Zhou et al., 2005) as the basis for the features of our system similar to what other researchers have done (Chan and Roth, 2010). Additional work has extended these features (Jiang and Zhai, 2007) or incorporated other data sources (e.g. WordNet), but in this paper we focus solely on t</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin. LIBLINEAR: A library for large linear classification. Journal of Machine Learning Research 9(2008), 1871-1874. 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Gerber</author>
<author>J Beyond Chai</author>
</authors>
<title>NomBank: A Study of Implicit Arguments for Nominal Predicates.</title>
<date>2010</date>
<booktitle>Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1583--1592</pages>
<contexts>
<context position="13941" citStr="Gerber and Chai, 2010" startWordPosition="2325" endWordPosition="2328"> per sentence, while JDPA uses only one every five sentences. 5.4 Extra-Sentential Relations Many relations in the JDPA Corpus occur between entities which are not mentioned in the same sentence. Our system only detects relations between mentions in the same sentence, causing about 29% of entity relations to never be detected (Table 2). 67 The LiveJournal documents are more likely to contain relationships between entities that are not mentioned in the same sentence. In the semantic role labeling (SRL) domain, extra-sentential arguments have been shown to significantly improve SRL performance (Gerber and Chai, 2010). Improvements in entity relation extraction could likely be made by extending Zhou et al.’s features across sentences. 6 Conclusion The above analysis shows that at least some of the reason for the system performing worse on the JDPA Corpus than on the ACE-2004 Corpus is that many of the documents in the JDPA Corpus have a different writing style from the news articles in the ACE Corpus. Both the ACE news documents, and the JDPA authored documents are written by professional writers with stronger editorial standards than the other JDPA Corpus documents, and the relation extraction system perf</context>
</contexts>
<marker>Gerber, Chai, 2010</marker>
<rawString>Gerber, M. and Chai, J. Beyond NomBank: A Study of Implicit Arguments for Nominal Predicates. Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1583-1592. 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jiang</author>
<author>C X Zhai</author>
</authors>
<title>A systematic exploration of the feature space for relation extraction.</title>
<date>2007</date>
<booktitle>In The Proceedings of NAACL/HLT.</booktitle>
<contexts>
<context position="5068" citStr="Jiang and Zhai, 2007" startWordPosition="824" endWordPosition="827">of each mention pair is performed using a support vector machine implemented using libLinear (Fan et al., 2008). To generate the features for each of the mention pairs a proprietary JDPA Tokenizer is used for parsing the document and the Stanford Parser (Klein and Manning, 2003) is used to generate parse trees and part of speech tags for the sentences in the documents. 3.2 Features We used Zhou et al.’s lexical features (Zhou et al., 2005) as the basis for the features of our system similar to what other researchers have done (Chan and Roth, 2010). Additional work has extended these features (Jiang and Zhai, 2007) or incorporated other data sources (e.g. WordNet), but in this paper we focus solely on the initial step of applying these same lexical features to the JDPA Corpus. The Mention Level, Overlap, Base Phrase Chunking, Dependency Tree, and Parse Tree features are the same as Zhou et al. (except for using the Stanford Parser rather than the Collins Parser). The minor changes we have made are summarized below: • Word Features: Identical, except rather than using a heuristic to determine the head word of the phrase it is chosen to be the noun (or any other word if there are no nouns in the mention) </context>
</contexts>
<marker>Jiang, Zhai, 2007</marker>
<rawString>Jiang, J. and Zhai, C.X. A systematic exploration of the feature space for relation extraction. In The Proceedings of NAACL/HLT. 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kessler</author>
<author>M Eckert</author>
<author>L Clark</author>
<author>N Nicolov</author>
</authors>
<date>2010</date>
<booktitle>The ICWSM 2010 JDPA Sentiment Corpus for the Automotive Domain International AAAI Conference on Weblogs and Social Media Data Challenge Workshop.</booktitle>
<contexts>
<context position="1580" citStr="Kessler et al., 2010" startWordPosition="254" endWordPosition="257">ssary to be able to determine the relationships between entities being discussed in the document (such as part-of or member-of). In the simple sentiment example Example 1.1: I bought a new car yesterday. I love the powerful engine. determining the sentiment the author is expressing about the car requires knowing that the engine is a part of the car so that the positive sentiment being expressed about the engine can also be attributed to the car. In this paper we examine our preliminary results from applying a relation extraction system to the J.D. Power and Associates (JDPA) Sentiment Corpus (Kessler et al., 2010). Our system uses lexical features from prior work to classify relations, and we examine how the system works on different subsets from the JDPA Sentiment Corpus, breaking the source documents down into professionally written reviews, blog reviews, and social networking reviews. These three document types represent quite different writing styles, and we see significant difference in how the relation extraction system performs on the documents from different sources. 2 Relation Corpora 2.1 ACE-2004 Corpus The Automatic Content Extraction (ACE) Corpus (Mitchell, et al., 2005) is one of the most </context>
</contexts>
<marker>Kessler, Eckert, Clark, Nicolov, 2010</marker>
<rawString>Kessler J., Eckert M., Clark L., and Nicolov N.. The ICWSM 2010 JDPA Sentiment Corpus for the Automotive Domain International AAAI Conference on Weblogs and Social Media Data Challenge Workshop. 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C Manning</author>
</authors>
<title>Accurate Unlexicalized Parsing.</title>
<date>2003</date>
<booktitle>Proceedings of the 41st Meeting of the Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="4726" citStr="Klein and Manning, 2003" startWordPosition="762" endWordPosition="765"> Overview The system extracts all pairs of mentions in a sentence, and then classifies each pair of mentions as either having a relationship, having an inverse relationship, or having no relationship. So for the PartOf relation in the JDPA Sentiment Corpus we consider both the relation “X is part of Y” and “Y is part of X”. The classification of each mention pair is performed using a support vector machine implemented using libLinear (Fan et al., 2008). To generate the features for each of the mention pairs a proprietary JDPA Tokenizer is used for parsing the document and the Stanford Parser (Klein and Manning, 2003) is used to generate parse trees and part of speech tags for the sentences in the documents. 3.2 Features We used Zhou et al.’s lexical features (Zhou et al., 2005) as the basis for the features of our system similar to what other researchers have done (Chan and Roth, 2010). Additional work has extended these features (Jiang and Zhai, 2007) or incorporated other data sources (e.g. WordNet), but in this paper we focus solely on the initial step of applying these same lexical features to the JDPA Corpus. The Mention Level, Overlap, Base Phrase Chunking, Dependency Tree, and Parse Tree features a</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Klein D. and Manning C. Accurate Unlexicalized Parsing. Proceedings of the 41st Meeting of the Association for Computational Linguistics, pp. 423-430. 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mitchell</author>
</authors>
<title>Multilingual Training Corpus. Linguistic Data Consortium,</title>
<date>2004</date>
<publisher>ACE</publisher>
<location>Philadelphia.</location>
<marker>Mitchell, 2004</marker>
<rawString>Mitchell A., et al. ACE 2004 Multilingual Training Corpus. Linguistic Data Consortium, Philadelphia. 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Zhou</author>
<author>J Su</author>
<author>J Zhang</author>
<author>M Zhang</author>
</authors>
<title>Exploring various knowledge in relation extraction.</title>
<date>2005</date>
<booktitle>Proceedings of the 43rd Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="4890" citStr="Zhou et al., 2005" startWordPosition="793" endWordPosition="796">ip, or having no relationship. So for the PartOf relation in the JDPA Sentiment Corpus we consider both the relation “X is part of Y” and “Y is part of X”. The classification of each mention pair is performed using a support vector machine implemented using libLinear (Fan et al., 2008). To generate the features for each of the mention pairs a proprietary JDPA Tokenizer is used for parsing the document and the Stanford Parser (Klein and Manning, 2003) is used to generate parse trees and part of speech tags for the sentences in the documents. 3.2 Features We used Zhou et al.’s lexical features (Zhou et al., 2005) as the basis for the features of our system similar to what other researchers have done (Chan and Roth, 2010). Additional work has extended these features (Jiang and Zhai, 2007) or incorporated other data sources (e.g. WordNet), but in this paper we focus solely on the initial step of applying these same lexical features to the JDPA Corpus. The Mention Level, Overlap, Base Phrase Chunking, Dependency Tree, and Parse Tree features are the same as Zhou et al. (except for using the Stanford Parser rather than the Collins Parser). The minor changes we have made are summarized below: • Word Featur</context>
<context position="6705" citStr="Zhou et al., 2005" startWordPosition="1110" endWordPosition="1113">ty types. • Semantic Information: These features are specific to the ACE relations and so are not used. In Zhou et al.’s work, this set of features increases the overall F-Measure by 1.5. 4 Results 4.1 ACE Corpus Results We ran our system on the ACE-2004 Corpus as a baseline to prove that the system worked properly and could approximately duplicate Zhou et al.’s results. Using 5-fold cross validation on the newswire and broadcast news documents in the dataset we achieved an average overall F-Measure of 50.6 on the fine-grained relations. Although a bit lower than Zhou et al.’s result of 55.5 (Zhou et al., 2005), we attribute the difference to our use of a different tokenizer, different parser, and having not used the semantic information features. 4.2 JDPA Sentiment Corpus Results We randomly divided the JDPA Corpus into training (70%), development (10%), and test (20%) datasets. Table 1 shows relation extraction results of the system on the test portion of the corpus. The results are further broken out by three different source types to highlight the differences caused 65 Relation All Documents F P LiveJournal F P Blogspot F P JDPA F P R R R R FEATURE OF 44.8 42.3 43.5 26.8 35.8 30.6 44.1 40.0 42.0</context>
</contexts>
<marker>Zhou, Su, Zhang, Zhang, 2005</marker>
<rawString>Zhou G., Su J., Zhang J., and Zhang M. Exploring various knowledge in relation extraction. Proceedings of the 43rd Annual Meeting of the ACL. 2005.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>