<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000010">
<title confidence="0.9941005">
Integrating Symbolic and Statistical Representations:
The Lexicon Pragmatics Interface
</title>
<author confidence="0.98609">
Ann Copestake
</author>
<affiliation confidence="0.8361195">
Center for the Study of Language and Information,
Stanford University,
</affiliation>
<address confidence="0.838495333333333">
Ventura Hall,
Stanford, CA 94305,
USA
</address>
<email confidence="0.93461">
aactIcsli.stanford.edu
</email>
<sectionHeader confidence="0.978916" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999963076923077">
We describe a formal framework for inter-
pretation of words and compounds in a
discourse context which integrates a sym-
bolic lexicon/grammar. word-sense proba-
bilities, and a pragmatic component. The
approach is motivated by the need to han-
dle productive word use. In this paper,
we concentrate on compound nominals.
We discuss the inadequacies of approaches
which consider compound interpretation as
either wholly lexico-grammatical or wholly
pragmatic, and provide an alternative inte-
grated account.
</bodyText>
<sectionHeader confidence="0.996234" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996995">
When words have multiple senses, these may have
very different frequencies. For example, the first two
senses of the noun diet given in WordNet are:
</bodyText>
<listItem confidence="0.9693506">
1. (a prescribed selection of foods)
=&gt; fare — (the food and drink that are regularly
consumed)
2. =&gt; legislature, legislative assembly, general as-
sembly, law-makers
</listItem>
<bodyText confidence="0.999219">
Most English speakers will share the intuition that
the first sense is much more common than the sec-
ond, and that this is (partly) a property of the word
and not its denotation, since near-synonyms oc-
cur with much greater frequency. Frequency differ-
ences are also found between senses of derived forms
(including morphological derivation, zero-derivation
and compounding). For example, canoe is less fre-
quent as a verb than as a noun. and the induced ac-
tion use (e.g., they canoed the kids across the lake) is
much less frequent than the intransitive form (with
</bodyText>
<author confidence="0.899031">
Alex Lascarides
</author>
<affiliation confidence="0.999175666666667">
Centre for Cognitive Science and
Human Communication Research Centre,
University of Edinburgh,
</affiliation>
<address confidence="0.874715666666667">
2, Buccleuch Place,
Edinburgh, EH8 9LW,
Scotland, UK
</address>
<email confidence="0.977676">
alex@cogsci.ed.ac.uk
</email>
<bodyText confidence="0.968207925">
location PP) (they canoed across the lake).&apos; A de-
rived form may become established with one mean-
ing, but this does not preclude other uses in suffi-
ciently marked contexts (e.g., Bauer&apos;s (1983) exam-
ple of garbage man with an interpretation analogous
to snowman).
Because of the difficulty of resolving lexical am-
biguity, it is usual in NLP applications to exclude
&apos;rare&apos; senses from the lexicon, and to explicitly list
frequent forms, rather than to derive them. But this
increases errors due to unexpected vocabulary, espe-
cially for highly productive derivational processes.
For this and other reasons it is preferable to as-
sume some generative devices in the lexicon (Puste-
jovsky, 1995). Briscoe and Copestake (1996) argue
that a differential estimation of the productivity of
derivation processes allows an approximation of the
probabilities of previously unseen derived uses. If
more probable senses are preferred by the system,
the proliferation of senses that results from uncon-
strained use of lexical rules or other generative de-
vices is effectively controlled. An interacting issue is
the granularity of meaning of derived forms. If the
lexicon produces a small number of very underspeci-
fied senses for a wordform, the ambiguity problem is
apparently reduced, but pragmatics may have insuf-
ficient information with which to resolve meanings,
or may find impossible interpretations.
We argue here that by utilising probabilities, a
language-specific component can offer hints to a
pragmatic module in order to prioritise and con-
trol the application of real-world reasoning to disam-
biguation. The objective is an architecture utilising
a general-purpose lexicon with domain-dependent
probabilities. The particular issues we consider here
are the integration of the statistical and symbolic
components, and the division of labour between Se-
and below we base our frequency judgements
on semi-automatic analysis of the written portion of the
tagged British National Corpus (sNc).
</bodyText>
<page confidence="0.997056">
136
</page>
<bodyText confidence="0.553195">
Arzttermin *doctor appointment doctor&apos;s appointment
Terminvorschlag * date proposal proposal for a date
Terminvereinbarung * date agreement agreement on a date
Januarhalfte * January half half of January
Friihlingsanfang * spring beginning beginning of spring
</bodyText>
<figureCaption confidence="0.999326">
Figure 1: Some German compounds with non-compound translations
</figureCaption>
<bodyText confidence="0.995853">
mantics and pragmatics in determining meaning.
We concentrate on (right-headed) compound nouns,
since these raise especially difficult problems for NLP
system architecture (Sparck Jones, 1983).
2 The grammar of compound nouns
Within linguistics, attempts to classify nominal com-
pounds using a small fixed set of meaning relations
(e.g., Levi (1978)) are usually thought to have failed,
because there appear to be exceptions to any clas-
sification. Compounds are attested with meanings
which can only be determined contextually. Down-
ing (1977) discusses apple juice seat, uttered in a
context in which it identifies a place-setting with a
glass of apple juice. Even for compounds with es-
tablished meanings, context can force an alternative
interpretation (Bauer, 1983).
These problems led to analyses in which the re-
lationship between the parts of a compound is un-
determined by the grammar, e.g., Dowty (1979),
Bauer (1983). Schematically this is equivalent to the
following rule, where R is undetermined (to simplify
exposition, we ignore the quantifier for y):
</bodyText>
<equation confidence="0.9974485">
NO —&gt; Ni N2
(1) Ax[P (x) A Q(y) A R(x , y)] Ay[Q(y)] Ax[P (x)]
</equation>
<bodyText confidence="0.999249779661017">
Similar approaches have been adopted in NLP with
further processing using domain restrictions to re-
solve the interpretation (e.g., Hobbs et al (1993)).
However, this is also unsatisfactory, because (1)
overgenerates and ignores systematic properties of
various classes of compounds. Overgeneration is
apparent when we consider translation of German
compounds, since many do not correspond straight-
forwardly to English compounds (e.g., Figure 1).
Since these exceptions are English-specific they can-
not be explained via pragmatics. Furthermore they
are not simply due to lexical idiosyncrasies: for
instance, Arztterminl* doctor appointment is repre-
sentative of many compounds with human-denoting
first elements, which require a possessive in English.
So we get blacksmith&apos;s hammer and not *blacksmith
hammer to mean &apos;hammer of a type convention-
ally associated with a blacksmith&apos; (also driver&apos;s cab,
widow&apos;s allowance etc). This is not the usual pos-
sessive: compare (((his blacksmith)&apos;s) hammer) with
(his (blacksmith&apos;s hammer)). Adjective placement is
also restricted: three English blacksmith&apos;s hammers/
*three blacksmith&apos;s English hammers. We treat these
as a subtype of noun-noun compound with the pos-
sessive analysed as a case marker.
In another subcategory of compounds, the head
provides the predicate (e.g., dog catcher, bottle
crusher). Again, there are restrictions: it is not
usually possible to form a compound with an agen-
tive predicate taking an argument that normally re-
quires a preposition (contrast water seeker with *wa-
ter looker). Stress assignment also demonstrates in-
adequacies in (1): compounds which have the in-
terpretation &apos;Y made of X&apos; (e.g., nylon rope, oak
table) generally have main stress on the righthand
noun, in contrast to most other compounds (Liber-
man and Sproat, 1992). Stress sometimes disam-
biguates meaning: e.g., with righthand stress cotton
bag has the interpretation bag made of cotton while
with leftmost stress an alternative reading, bag for
cotton, is available. Furthermore, ordering of ele-
ments is restricted: e.g., cotton garment bag/ * gar-
ment cotton bag.
The rule in (1) is therefore theoretically inade-
quate, because it predicts that all noun-noun com-
pounds are acceptable. Furthermore, it gives no hint
of likely interpretations, leaving an immense burden
to pragmatics.
We therefore take a position which is intermediate
between the two extremes outlined above. We as-
sume that the grammar/lexicon delimits the range
of compounds and indicates conventional interpre-
tations, but that some compounds may only be re-
solved by pragmatics and that non-conventional con-
textual interpretations are always available. We de-
fine a number of schemata which encode conven-
tional meanings. These cover the majority of com-
pounds, but for the remainder the interpretation is
left unspecified, to be resolved by pragmatics.
</bodyText>
<page confidence="0.985559">
137
</page>
<figure confidence="0.997102125">
general-nn
possessive made-of purpose-patient deverbal
/ I \
cardboard box
non-derived-pp
linen chest
deverbal-pp
ice-cream container
</figure>
<figureCaption confidence="0.9903825">
Figure 2: Fragment of hierarchy of noun-noun compound schemata. The boxed nodes indicate actual
schemata: other nodes are included for convenience in expressing generalisations.
</figureCaption>
<figure confidence="0.933294166666667">
general-nn
NO
Ax[P (x) A Q(y) A R(x , y)]
R = /general-nn
-&gt; Ni N2
Ay[Q(y)] Ax[P(x)]
anything anything
/stressed
substance physobj
/stressed
made-of R = made-of
purpose-patient R = TELIC(N2) anything artifact
</figure>
<figureCaption confidence="0.9866965">
Figure 3: Details of some schemata for noun-noun compounds. / indicates that the value to its right is
default information.
</figureCaption>
<bodyText confidence="0.994859692307692">
Space limitations preclude detailed discussion but
Figures 2 and 3 show a partial default inheri-
tance hierarchy of schemata (cf., Jones (1995)).2
Multiple schemata may apply to a single com-
pound: for example, cotton bag is an instantiation of
the made-of schema, the non-derived-purpose-
patient schema and also the general-nn schema.
Each applicable schema corresponds to a different
sense: so cotton bag is ambiguous rather than vague.
The interpretation of the hierarchy is that the use
of a more general schema implies that the meanings
given by specific subschemata are excluded, and thus
we have the following interpretations for cotton bag:
</bodyText>
<listItem confidence="0.997432666666667">
1. Ax[cotton(y) A bag(x) A made-of(y, x)]
2. Ax[cotton(y) A bag(x) A TELIC(bag)(y, x)] =
Ax[cotton(y) A bag(x) A contain(y, x)]
</listItem>
<bodyText confidence="0.8188095">
2We formalise this with typed default feature struc-
tures (Lascarides et al, 1996). Schemata can be re-
garded formally as lexical/grammar rules (lexical rules
and grammar rules being very similar in our framework)
but inefficiency due to multiple interpretations is avoided
in the implementation by using a form of packing.
</bodyText>
<listItem confidence="0.975843">
3. Ax[R(y, x) A -,(made-of(y, x) V contain(y, x) V
• • -)1
</listItem>
<bodyText confidence="0.99992535">
The predicate made-of is to be interpreted as ma-
terial constituency (e.g. Link (1983)). We follow
Johnston and Busa (1996) in using Pustejovsky&apos;s
(1995) concept of telic role to encode the purpose
of an artifact. These schemata give minimal indi-
cations of compound semantics: it may be desirable
to provide more information (Johnston et al, 1995),
but we will not discuss that here.
Established compounds may have idiosyncratic in-
terpretations or inherit from one or more schemata
(though compounds with multiple established senses
due to ambiguity in the relationship between con-
stituents rather than lexical ambiguity are fairly un-
usual). But established compounds may also have
unestablished interpretations, although, as discussed
in §3, these will have minimal probabilities. In
contrast, an unusual compound, such as apple-juice
seat, may only be compatible with general-nn, and
would be assigned the most underspecified interpre-
tation. As we will see in §4, this means pragmatics
</bodyText>
<page confidence="0.878554">
138
</page>
<equation confidence="0.9982752">
Unseen-prob-mass(cmp-form) = number-of-applicable-schemata(cmp-form)
f req(cmp-form)+number-of-applicable-schemata(cmp-form)
Prod(cs.)
Estimated-freq(interpretation, with cmp-form) = Unseen-prob-mass(cmp-form) x E
Prod(csi),...,Prod(cs..)
</equation>
<bodyText confidence="0.798964">
(where csi . cs,, are the compound schemata needed to derive the n unattested entries for the formj)
</bodyText>
<figureCaption confidence="0.722007">
Figure 4: Probabilities for unseen compounds: adapted from Briscoe and Copestake (1996)
</figureCaption>
<bodyText confidence="0.9998732">
must find a contextual interpretation. Thus, for any
compound there may be some context in which it
can be interpreted, but in the absence of a marked
context, only compounds which instantiate one of
the subschemata are acceptable.
</bodyText>
<sectionHeader confidence="0.971303" genericHeader="method">
3 Encoding Lexical Preferences
</sectionHeader>
<bodyText confidence="0.9999895">
In order to help pragmatics select between the multi-
ple possible interpretations, we utilise probabilities.
For an established form, derived or not, these de-
pend straightforwardly on the frequency of a par-
ticular sense. For example, in the BNC, diet has
probability of about 0.9 of occurring in the food
sense and 0.005 in the legislature sense (the remain-
der are metaphorical extensions. e.g.. diet of crime).
Smoothing is necessary to avoid giving a non-zero
probability for possible senses which are not found
in a particular corpus. For derived forms, the ap-
plicable lexical rules or schemata determine possi-
ble senses (Briscoe and Copestake, 1996). Thus
for known compounds, probabilities of established
senses depend on corpus frequencies but a residual
probability is distributed between unseen interpreta-
tions licensed by schemata, to allow for novel uses.
This distribution is weighted to allow for productiv-
ity differences between schemata. For unseen com-
pounds, all probabilities depend on schema produc-
tivity. Compound schemata range from the non-
productive (e.g., the verb-noun pattern exemplified
by pickpocket). to the almost fully productive (e.g.,
made-of) with many schemata being intermediate
(e.g., has-part: 4-door car is acceptable but the ap-
parently similar *sunroof car is not).
We use the following estimate for productivity
(adapted from Briscoe and Copestake (1996)):
</bodyText>
<equation confidence="0.973272">
ill + 1
Prod(cmp-schema) =
</equation>
<bodyText confidence="0.997021222222222">
(where N is the number of pairs of senses which
match the schema input and /II is the number
of attested two-noun output forms — we ignore
compounds with more than two nouns for simplic-
ity). Formulae for calculating the unseen probability
mass and for allocating it differentially according to
schema productivity are shown in Figure 4. Finer-
grained, more accurate productivity estimates can
be obtained by considering subsets of the possible
inputs — this allows for some real-world effects (e.g.,
the made-of schema is unlikely for liquid/physical-
artifact compounds).
Lexical probabilities should be combined to give
an overall probability for a logical form (LF): see
e.g., Resnik (1992). But we will ignore this here and
assume pragmatics has to distinguish between alter-
natives which differ only in the sense assigned to
one compound. (2) shows possible interpretations
for cotton bag with associated probabilities. LFS are
encoded in DRT. The probabilities given here are
based on productivity figures for fabric/container
compounds in the BNC, using WordNet as a source of
semantic categories. Pragmatics screens the LFS for
acceptability. If a LF contains an underspecified ele-
ment (e.g., arising from general-nn), this must be
instantiated by pragmatics from the discourse con-
text.
</bodyText>
<listItem confidence="0.715347">
(2) a. Mary put a skirt in a cotton bag
</listItem>
<construct confidence="0.966750882352941">
e, x, y, z, w, t, now
mary(x), skirt(y), cotton(w),
bag(z), put(e, x ,y , z),
hold(e, t), t now,
made-of(z ,w)
e, x, y, z,w,t, now
mary(x), skirt(y), cotton(w),
bag(z), put(e, x, y, z),
hold(e,t), t -&lt; now,
contain(z • w)
e,x,y, z, w. t, now
mary(x), skirt(y), cotton(w),
bag(z), put(e, x, y , z),
hold(e, t), t -‹ now,
12,(z , w) =?
-+(made-of(z ,w)V
contain(z,w) V . .)
</construct>
<equation confidence="0.998827333333333">
P = 0.84
P = 0.14
P = 0.02
</equation>
<page confidence="0.993295">
139
</page>
<sectionHeader confidence="0.9175055" genericHeader="method">
4 SDRT and the Resolution of
Underspecified Relations
</sectionHeader>
<bodyText confidence="0.999660272727273">
The frequency information discussed in §3 is insuf-
ficient on its own for disambiguating compounds.
Compounds like apple juice seat require marked con-
texts to be interpretable. And some discourse con-
texts favour interpretations associated with less fre-
quent senses. In particular. if the context makes the
usual meaning of a compound incoherent, then prag-
matics should resolve the compound to a less fre-
quent but conventionally licensed meaning, so long
as this improves coherence. This underlies the dis-
tinct interpretations of cotton bag in (3) vs. (4):
</bodyText>
<listItem confidence="0.999927166666667">
(3) a. Mary sorted her clothes into various large
bags.
b. She put her skirt in the cotton bag.
(4) a. Mary sorted her clothes into various bags
made from plastic.
b. She put her skirt into the cotton bag.
</listItem>
<bodyText confidence="0.999874304347826">
If the bag in (4b) were interpreted as being made
of cotton—in line with the (statistically) most fre-
quent sense of the compound—then the discourse
becomes incoherent because the definite descrip-
tion cannot be accommodated into the discourse
context. Instead, it must be interpreted as hav-
ing the (less frequent) sense given by purpose-
patient: this allows the definite description to
be accommodated and the discourse is coherent.
In this section, we&apos;ll give a brief overview of
the theory of discourse and pragmatics that we&apos;ll
use for modelling this interaction during disam-
biguation between discourse information and lex-
ical frequencies. We&apos;ll use Segmented Discourse
Representation Theory (SDRT) (e.g., Asher (1993))
and the accompanying pragmatic component Dis-
course in Commonsense Entailment (DICE) (Las-
carides and Asher. 1993). This framework has
already been successful in accounting for other
phenomena on the interface between the lexicon
and pragmatics. e.g.. Asher and Lascarides (1995).
Lascarides and Copestake (1995).
Lascarides. Copestake and Briscoe (1996).
SDRT is an extension of DRT (Ramp and ReyIe.
1993). where discourse is represented as a recursive
set of DRss representing the clauses, linked together
with rhetorical relations such as Elaboration and
Contrast. cf. Hobbs (1985). Polanyi (1985). Build-
ing an SDRS involves computing a rhetorical relation
between the representation of the current clause and
the SDRS built so far. DICE specifies how various
background knowledge resources interact to provide
clues about which rhetorical relation holds.
The rules in DICE include default conditions of the
form P&gt; Q. which means lip, then normally Q. For
example, Elaboration states: if 0 is to be attached
to a with a rhetorical relation, where a is part of the
discourse structure 7 already (i.e., (r, a, 3) holds).
and 3 is a subtype of a—which by Subtype means
that a&apos;s event is a subtype of O&apos;s, and the individ-
ual filling some role Oi in 3 is a subtype of the one
filling the same role in a—then normally, a and 3
are attached together with Elaboration (Asher and
Lascarides, 1995). The Coherence Constraint on
Elaboration states that an elaborating event must
be temporally included in the elaborated event.
</bodyText>
<listItem confidence="0.812462">
• Subtype:
(0,(ea.-)1) A 9/(e3.-v2) A
e-condn3 e-condn, A -72 ) -4
Subtype(3. a)
• Elaboration:
( (7, a. 3) A Subtype(3, a)) &gt; Elaboration(a, 3)
• Coherence Constraint on Elaboration:
</listItem>
<equation confidence="0.573393">
Elaboration(a. 3) e3 C ec,
</equation>
<bodyText confidence="0.999871269230769">
Subtype and Elaboration encapsulate clues about
rhetorical structure given by knowledge of subtype
relations among events and objects. Coherence
Constraint on Elaboration constrains the se-
mantic content of constituents connected by Elab-
oration in coherent discourse.
A distinctive feature of SDRT is that if the DICE ax-
ioms yield a nonmonotonic conclusion that the dis-
course relation is R. and information that&apos;s neces-
sary for the coherence of R isn&apos;t already in the con-
stituents connected with R (e.g., Elaboration(a, 3) is
nonmonotonically inferred, but e3 C ec, is not in a
or in 3). then this content can be added to the con-
stituents in a constrained manner through a process
known as SDRS Update. Informally. Update(7. a. 3)
is an SDRS, which includes (a) the discourse context
7, plus (b) the new information 3. and (c) an attach-
ment of 3 to a (which is part of 7) with a rhetorical
relation R that&apos;s computed via DICE, where (d) the
content of T. a and 3 are modified so that the co-
herence constraints on R are met.3 Note that this
is more complex than DRT&apos;S notion of update. Up-
datc models how interpreters are allowed and ex-
pected to fill in certain gaps in what the speaker
says: in essence affecting semantic contet through
context and pragmatics. We&apos;ll use this information
</bodyText>
<footnote confidence="0.919458666666667">
31f Ks coherence constraints can&apos;t be inferred, then
the logic underlying DICE guarantees that R won&apos;t be
nonmonotonically inferred.
</footnote>
<page confidence="0.997022">
140
</page>
<bodyText confidence="0.997985787234043">
flow between context and semantic content to rea-
son about the semantic content of compounds in dis-
course: simply put, we will ensure that words are as-
signed the most freqent possible sense that produces
a well defined SDRS Update function.
An SDRS S is well-defined (written 4. S) if there
are no conditions of the form x =? (i.e., there are
no unresolved anaphoric elements), and every con-
stituent is attached with a rhetorical relation. A
discourse is incoherent if –4. Update(T. (1.0) holds
for every available attachment point a in T. That
is. anaphora can&apos;t be resolved, or no rhetorical con-
nection can be computed via DICE.
For example. the representations of (5a.b) (in sim-
plifie(l form) are respectively n and 3:
(5) a. Mary put her clothes into various large
bags.
In words, the conditions in 3 require the object
denoted by the definite description to be linked
by some &apos;bridging relation B (possibly identity,
cf. van der Sandt (1992)) to an object u identi-
fied in the discourse context (Asher and Lascarides.
1996). In SDRT. the values of v and B are com-
puted as a byproduct of SDRT.5 Update function (cf.
Hobbs (1979)); one specifies u and B by inferring
the relevant new semantic content arising from R&apos;s
coherence constraints. where R is the rhetorical rela-
tion inferred via the DICE axioms. If one cannot re-
solve the conditions u =? or B =I&apos; through SDRS up-
date. then by the above definition of well-definedness
on spftss the discourse is incoherent (and we have
presupposition failure).
The detailed analysis of (3) and (52) involve rea-
soning about the values of v and B. But for rea-
sons of space. we gloss over the details given in
.Asher and Lascarides (1996) for specifying v and B
through the SDRT update procedure. However, the
axiom Assume Coherence below is derivable from
the axioms given there. First some notation: let
3[C] mean that /.3 contains condition C. and assume
that 3[C /C1 stands for the spits which is the same
as .3. save that the condition C in 3 is replaced by C&apos;.
Then in words, Assume Coherence stipulates that if
the discourse can be coherent only if the anaphor u
is resolved to x and B is resolved to the specific re-
lation P, then one monotonically assumes that they
are resolved this way:
</bodyText>
<listItem confidence="0.923727">
• Assume Coherence:
</listItem>
<equation confidence="0.6902994">
Update(r, O[u =?,B =?/u = x, B = PJ) A
(C&apos;O(u=xAB=P)--4
Update(r, a, Mu =?.B =?/C1))) --4
(Update(r,a, 3) 4-4
Update(r, a, 3tu =?, B =?/u = x,B = PJ))
</equation>
<bodyText confidence="0.999571259259259">
Intuitively, it should be clear that in (5a.b)
Update(a, 0) holds, unless the bag in (5b) is one
of the bags mentioned in (5a)—i.e., v = Z and
B = member-of. For otherwise the events in (5)
are too &apos;disconnected&apos; to support any rhetorical re-
lation. On the other hand. assigning u and B these
values allows us to use Subtype and Elaboration
to infer Elaboration (because skirt is a kind of cloth-
ing, and the bag in (5b) is one of the bags in (5a)).
So Assume Coherence, Subtype and Elaboration
yield that (5b) elaborates (5a) and the bag in (51))
is one of the bags in (5a).
Applying SDRT to compounds encodes the ef-
fects of pragmatics on the compounding relation.
For example, to reflect the fact that compounds
such as apple juice seat, which are compatible
only with general-nn, are acceptable only when
context resolves the compound relation, we as-
sume that the DRS conditions produced by this
schema are: Rc(y, x), R =?, and –,(made-of(y. x) V
contain(y,x) V ...). By the above definition of well-
definedness on spRss, the compound is coherent only
if we can resolve R, to a particular relation via the
SDRT Update function, which in turn is determined
by DICE. Rules such as Assume Coherence serve to
specify the necessary compound relation, so long as
context provides enough information.
</bodyText>
<sectionHeader confidence="0.713648" genericHeader="method">
5 Integrating Lexical Preferences
</sectionHeader>
<subsectionHeader confidence="0.499742">
and Pragmatics
</subsectionHeader>
<bodyText confidence="0.89758845">
We now extend SDRT and DICE to handle the prob-
abilistic information given in §3. We want the prag-
matic component to utilise this knowledge, while
still maintaining sufficient flexibility that less fre-
quent senses are favoured in certain discourse con-
texts.
Suppose that the new information to be in-
tegrated with the discourse context is ambigu-
ous between #31 , . Then we assume that
exactly one of Update(r. a„3i). 1 &lt; i &lt; n.
holds. We gloss this complex disjunctive formula as
.r. Y. Z. ec, . to. 71
mary(x). clothes(1- ). bag(Z).
put(eo,x.Y. Z). hold(eo . to). to -&lt; 77
i. She put her skirt into the bag made out of
cotton.
X. y. z, w. ej. t3. 71. U. B
mary(x), skirt(y). bag(z), cotton(w),
made-of(z,w), u =?. B (u. z). B =?,
put(ea , x, y, z). hold(e.3. to). t
</bodyText>
<page confidence="0.7444345">
3.
141
</page>
<bodyText confidence="0.9967786">
I V 1 &lt; &lt; n Update(T, a, 0,)). Let Ok 133 mean that
the probability of DRS Ok is greater than that of 03.
Then the rule schema below ensures that the most
frequent possible sense that produces discourse co-
herence is (monotonically) favoured:
</bodyText>
<listItem confidence="0.921520333333333">
• Prefer Frequent Senses:
( V1 &lt;i&lt;n( Update(&apos; r, a,
.1, Update(&apos; r, a, 03) A
</listItem>
<equation confidence="0.616009">
&gt;&amp;quot; 133 --&gt; Update(T,a,N ))) —&gt;
Update(r, a, 03)
</equation>
<bodyText confidence="0.997506128571428">
Prefer Frequent Senses is a declarative rule for
disambiguating constituents in a discourse context.
But from a procedural perspective it captures: try
to attach the DRS based on the most probable senses
first; if it works you&apos;re done; if not, try the next most
probable sense, and so on.
Let&apos;s examine the interpretation of compounds.
Consider (3). Let&apos;s consider the representation /3&apos;
of (3b) with the highest probability: i.e., the one
where cotton bag means bag made of cotton. Then
similarly to (5), Assume Coherence, Subtype and
Elaboration are used to infer that the cotton bag
is one of the bags mentioned in (3a) and Elab-
oration holds. Since this updated SDRS is well-
defined, Prefer Frequent Senses ensures that it&apos;s
true. And so cotton bag means bag made from cotton
in this context.
Contrast this with (4). Update(a, a, 0&apos;) is not
well-defined because the cotton bag cannot be
one of the bags in (4a). On the other hand,
Update(a, a, 0&amp;quot;) is well-defined, where 0&amp;quot; is the DRS
where cotton bag means bag containing cotton. This
is because one can now assume this bag is one of
the bags mentioned in (4a), and therefore Elabora-
tion can be inferred as before. So Prefer Frequent
Senses ensures that Update(a, a, 0&amp;quot;) holds but
Update(a, a, 0&apos;) does not.
Prefer Frequent Senses is designed for reason-
ing about word senses in general, and not just the
semantic content of compounds: it predicts diet has
its food sense in (6b) in isolation of the discourse
context (assuming Update(0,0, a) = a), but it has
the law-maker sense in (6), because SDRT&apos;S coher-
ence constraints on Contrast ((Asher, 1993))—which
is the relation required for Update because of the cue
word but—can&apos;t be met when diet means food.
(6) a. In theory, there should be cooperation be-
tween the different branches of government.
b. But the president hates the diet.
In general, pragmatic reasoning is computation-
ally expensive, even in very restricted domains. But
the account of disambiguation we&apos;ve offered circum-
scribes pragmatic reasoning as much as possible.
All nonmonotonic reasoning remains packed into the
definition of Update(r, a, 0), where one needs prag-
matic reasoning anyway for inferring rhetorical re-
lations. Prefer Frequent Senses is a monotonic
rule, it doesn&apos;t increase the load on nonmonotonic
reasoning, and it doesn&apos;t introduce extra pragmatic
machinery peculiar to the task of disambiguating
word senses. Indeed, this rule offers a way of check-
ing whether fully specified relations between com-
pounds are acceptable, rather than relying on (ex-
pensive) pragmatics to compute them.
We have mixed stochastic and symbolic reasoning.
Hobbs et al (1993) also mix numbers and rules by
means of weighted abduction. However, the theories
differ in several important respects. First, our prag-
matic component has no access to word forms and
syntax (and so it&apos;s not language specific), whereas
Hobbs et al&apos;s rules for pragmatic interpretation can
access these knowledge sources. Second, our prob-
abilities encode the frequency of word senses asso-
ciated with word forms. In contrast, the weights
that guide abduction correspond to a wider variety
of information, and do not necessarily correspond to
word sense/form frequencies. Indeed, it is unclear
what meaning is conveyed by the weights, and con-
sequently the means by which they can be computed
are not well understood.
</bodyText>
<sectionHeader confidence="0.997846" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999980153846154">
We have demonstrated that compound noun in-
terpretation requires the integration of the lexi-
con, probabilistic information and pragmatics. A
similar case can be made for the interpretation
of morphologically-derived forms and words in ex-
tended usages. We believe that the proposed archi-
tecture is theoretically well-motivated, but also prac-
tical, since large-scale semi-automatic acquisition of
the required frequencies from corpora is feasible,
though admittedly time-consuming. However fur-
ther work is required before we can demonstrate this,
in particular to validate or revise the formulae in §3
and to further develop the compound schemata.
</bodyText>
<sectionHeader confidence="0.997755" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999776333333333">
The authors would like to thank Ted Briscoe and
three anonymous reviewers for comments on previ-
ous drafts. This material is in part based upon work
supported by the National Science Foundation un-
der grant number IRI-9612682 and ESRC (UK) grant
number R000236052.
</bodyText>
<page confidence="0.993541">
142
</page>
<bodyText confidence="0.94610525">
Lascarides, A. and N. Asher (1993) &apos;Temporal Inter-
pretation, Discourse Relations and Commonsense
Entailment&apos;, Linguistics and Philosophy, vol.16.5,
437-493.
</bodyText>
<sectionHeader confidence="0.870179" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997417356321839">
Asher, N. (1993) Reference to Abstract Objects in
Discourse, Kluwer Academic Publishers.
Asher, N. and A. Lascarides (1995) &apos;Lexical Disam-
biguation in a Discourse Context&apos;, Journal of Se-
mantics, vol.12.1, 69-108.
Asher, N. and A. Lascarides (1996) Bridging, Pro-
ceedings of the International Workshop on Se-
mantic Underspecification, Berlin, October 1996,
available from the Max Plank Institute.
Bauer, L. (1983) English word-formation, Cam-
bridge University Press, Cambridge, England.
Briscoe, E.J. and A. Copestake (1996) &apos;Controlling
the application of lexical rules&apos;, Proceedings of the
ACL SIGLEX Workshop on Breadth and Depth of
Semantic Lexicons, Santa Cruz, CA.
Downing, P. (1977) &apos;On the Creation and Use of
English Compound Nouns&apos;, Language, vol.53(4),
810-842.
Dowty, D. (1979) Word meaning in Montague Gram-
mar, Reidel, Dordrecht.
Hobbs, J. (1979) &apos;Coherence and Coreference&apos;, Cog-
nitive Science, vol.3, 67-90.
Hobbs, J. (1985) On the Coherence and Structure of
Discourse, Report No. CSLI-85-37, Center for the
Study of Language and Information.
Hobbs, J.R., M. Stickel, D. Appelt and P. Martin
(1993) &apos;Interpretation as Abduction&apos;, Artificial In-
telligence, vol.63.1, 69-142.
Johnston, M., B. Boguraev and J. Pustejovsky
(1995) &apos;The acquisition and interpretation of com-
plex nominals&apos;, Proceedings of the AAAI Spring
Symposium on representation and acquisition of
lexical knowledge, Stanford, CA.
Johnston, M. and F. Busa (1996) &apos;Qualia struc-
ture and the compositional interpretation of com-
pounds&apos;, Proceedings of the ACL SIGLEX work-
shop on breadth and depth of semantic lexicons,
Santa Cruz, CA.
Jones, B. (1995) &apos;Predicting nominal compounds&apos;,
Proceedings of the 17th Annual conference of the
Cognitive Science Society, Pittsburgh, PA.
Kamp, H. and U. Reyle (1993) From Discourse to
Logic: an introduction to modeltheoretic seman-
tics, formal logic and Discourse Representation
Theory, Kluwer Academic Publishers, Dordrecht,
Germany.
Lascarides, A., E.J. Briscoe, N. Asher and A. Copes-
take (1996) &apos;Persistent and Order Independent
Typed Default Unification&apos;, Linguistics and Phi-
losophy, vol.19:1, 1-89.
Lascarides, A. and A. Copestake (in press) &apos;Prag-
matics and Word Meaning&apos;, Journal of Linguis-
tics,
Lascarides, A., A. Copestake and E. J. Briscoe
(1996) &apos;Ambiguity and Coherence&apos;, Journal of Se-
mantics, vol.13.1, 41-65.
Levi, J. (1978) The syntax and semantics of complex
nominals, Academic Press, New York.
Liberman, M. and R. Sproat (1992) &apos;The stress and
structure of modified noun phrases in English&apos; in
I.A. Sag and A. Szabolsci (eds.), Lexical matters,
CSLI Publications, pp. 131-182.
Link, G. (1983) &apos;The logical analysis of plurals
and mass terms: a lattice-theoretical approach&apos;
in Bauerle, Schwarze and von Stechow (eds.),
Meaning, use and interpretation of language, de
Gruyter, Berlin, pp. 302-323.
Polanyi, L. (1985) &apos;A Theory of Discourse Structure
and Discourse Coherence&apos;, Proceedings of the Pa-
pers from the General Session at the Twenty-First
Regional Meeting of the Chicago Linguistics Soci-
ety, Chicago, pp. 25-27.
Pustejovsky, J. (1995) The Generative Lexicon, MIT
Press, Cambridge, MA.
Resnik, P. (1992) &apos;Probabilistic Lexicalised Tree Ad-
joining Grammar&apos;, Proceedings of the Coling92,
Nantes, France.
van der Sandt, R. (1992) &apos;Presupposition Projection
as Anaphora Resolution&apos;, Journal of Semantics,
vol.19.4,
Sparck Jones, K. (1983) `So what about parsing com-
pound nouns?&apos; in K. Sparck Jones and Y. Wilks
(eds.), Automatic natural language parsing, Ellis
Horwood, Chichester, England, pp. 164-168.
Webber, B. (1991) &apos;Structure and Ostension in the
Interpretation of Discourse Deixis&apos;, Language and
Cognitive Processes, vol.6.2, 107-135.
</reference>
<page confidence="0.999131">
143
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.531004">
<title confidence="0.997668">Integrating Symbolic and Statistical Representations: The Lexicon Pragmatics Interface</title>
<author confidence="0.992662">Ann Copestake</author>
<affiliation confidence="0.9998145">Center for the Study of Language and Information, Stanford University,</affiliation>
<address confidence="0.99716">Ventura Hall, Stanford, CA 94305, USA</address>
<email confidence="0.999688">aactIcsli.stanford.edu</email>
<abstract confidence="0.9667205">We describe a formal framework for interpretation of words and compounds in a discourse context which integrates a symbolic lexicon/grammar. word-sense probabilities, and a pragmatic component. The approach is motivated by the need to handle productive word use. In this paper, we concentrate on compound nominals. We discuss the inadequacies of approaches which consider compound interpretation as either wholly lexico-grammatical or wholly pragmatic, and provide an alternative integrated account.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>N Asher</author>
</authors>
<title>Reference to Abstract Objects in Discourse,</title>
<date>1993</date>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="16283" citStr="Asher (1993)" startWordPosition="2503" endWordPosition="2504">sense of the compound—then the discourse becomes incoherent because the definite description cannot be accommodated into the discourse context. Instead, it must be interpreted as having the (less frequent) sense given by purposepatient: this allows the definite description to be accommodated and the discourse is coherent. In this section, we&apos;ll give a brief overview of the theory of discourse and pragmatics that we&apos;ll use for modelling this interaction during disambiguation between discourse information and lexical frequencies. We&apos;ll use Segmented Discourse Representation Theory (SDRT) (e.g., Asher (1993)) and the accompanying pragmatic component Discourse in Commonsense Entailment (DICE) (Lascarides and Asher. 1993). This framework has already been successful in accounting for other phenomena on the interface between the lexicon and pragmatics. e.g.. Asher and Lascarides (1995). Lascarides and Copestake (1995). Lascarides. Copestake and Briscoe (1996). SDRT is an extension of DRT (Ramp and ReyIe. 1993). where discourse is represented as a recursive set of DRss representing the clauses, linked together with rhetorical relations such as Elaboration and Contrast. cf. Hobbs (1985). Polanyi (1985)</context>
<context position="25930" citStr="Asher, 1993" startWordPosition="4185" endWordPosition="4186">e cotton bag means bag containing cotton. This is because one can now assume this bag is one of the bags mentioned in (4a), and therefore Elaboration can be inferred as before. So Prefer Frequent Senses ensures that Update(a, a, 0&amp;quot;) holds but Update(a, a, 0&apos;) does not. Prefer Frequent Senses is designed for reasoning about word senses in general, and not just the semantic content of compounds: it predicts diet has its food sense in (6b) in isolation of the discourse context (assuming Update(0,0, a) = a), but it has the law-maker sense in (6), because SDRT&apos;S coherence constraints on Contrast ((Asher, 1993))—which is the relation required for Update because of the cue word but—can&apos;t be met when diet means food. (6) a. In theory, there should be cooperation between the different branches of government. b. But the president hates the diet. In general, pragmatic reasoning is computationally expensive, even in very restricted domains. But the account of disambiguation we&apos;ve offered circumscribes pragmatic reasoning as much as possible. All nonmonotonic reasoning remains packed into the definition of Update(r, a, 0), where one needs pragmatic reasoning anyway for inferring rhetorical relations. Prefe</context>
</contexts>
<marker>Asher, 1993</marker>
<rawString>Asher, N. (1993) Reference to Abstract Objects in Discourse, Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Asher</author>
<author>A Lascarides</author>
</authors>
<title>Lexical Disambiguation in a Discourse Context&apos;,</title>
<date>1995</date>
<journal>Journal of Semantics,</journal>
<volume>12</volume>
<pages>69--108</pages>
<contexts>
<context position="16562" citStr="Asher and Lascarides (1995)" startWordPosition="2541" endWordPosition="2544">scription to be accommodated and the discourse is coherent. In this section, we&apos;ll give a brief overview of the theory of discourse and pragmatics that we&apos;ll use for modelling this interaction during disambiguation between discourse information and lexical frequencies. We&apos;ll use Segmented Discourse Representation Theory (SDRT) (e.g., Asher (1993)) and the accompanying pragmatic component Discourse in Commonsense Entailment (DICE) (Lascarides and Asher. 1993). This framework has already been successful in accounting for other phenomena on the interface between the lexicon and pragmatics. e.g.. Asher and Lascarides (1995). Lascarides and Copestake (1995). Lascarides. Copestake and Briscoe (1996). SDRT is an extension of DRT (Ramp and ReyIe. 1993). where discourse is represented as a recursive set of DRss representing the clauses, linked together with rhetorical relations such as Elaboration and Contrast. cf. Hobbs (1985). Polanyi (1985). Building an SDRS involves computing a rhetorical relation between the representation of the current clause and the SDRS built so far. DICE specifies how various background knowledge resources interact to provide clues about which rhetorical relation holds. The rules in DICE in</context>
</contexts>
<marker>Asher, Lascarides, 1995</marker>
<rawString>Asher, N. and A. Lascarides (1995) &apos;Lexical Disambiguation in a Discourse Context&apos;, Journal of Semantics, vol.12.1, 69-108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Asher</author>
<author>A Lascarides</author>
</authors>
<title>available from the Max Plank Institute.</title>
<date>1996</date>
<booktitle>Bridging, Proceedings of the International Workshop on Semantic Underspecification,</booktitle>
<location>Berlin,</location>
<contexts>
<context position="21115" citStr="Asher and Lascarides (1996)" startWordPosition="3321" endWordPosition="3324">v and B are computed as a byproduct of SDRT.5 Update function (cf. Hobbs (1979)); one specifies u and B by inferring the relevant new semantic content arising from R&apos;s coherence constraints. where R is the rhetorical relation inferred via the DICE axioms. If one cannot resolve the conditions u =? or B =I&apos; through SDRS update. then by the above definition of well-definedness on spftss the discourse is incoherent (and we have presupposition failure). The detailed analysis of (3) and (52) involve reasoning about the values of v and B. But for reasons of space. we gloss over the details given in .Asher and Lascarides (1996) for specifying v and B through the SDRT update procedure. However, the axiom Assume Coherence below is derivable from the axioms given there. First some notation: let 3[C] mean that /.3 contains condition C. and assume that 3[C /C1 stands for the spits which is the same as .3. save that the condition C in 3 is replaced by C&apos;. Then in words, Assume Coherence stipulates that if the discourse can be coherent only if the anaphor u is resolved to x and B is resolved to the specific relation P, then one monotonically assumes that they are resolved this way: • Assume Coherence: Update(r, O[u =?,B =?</context>
</contexts>
<marker>Asher, Lascarides, 1996</marker>
<rawString>Asher, N. and A. Lascarides (1996) Bridging, Proceedings of the International Workshop on Semantic Underspecification, Berlin, October 1996, available from the Max Plank Institute.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Bauer</author>
</authors>
<title>English word-formation,</title>
<date>1983</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, England.</location>
<contexts>
<context position="4893" citStr="Bauer, 1983" startWordPosition="735" endWordPosition="736">stem architecture (Sparck Jones, 1983). 2 The grammar of compound nouns Within linguistics, attempts to classify nominal compounds using a small fixed set of meaning relations (e.g., Levi (1978)) are usually thought to have failed, because there appear to be exceptions to any classification. Compounds are attested with meanings which can only be determined contextually. Downing (1977) discusses apple juice seat, uttered in a context in which it identifies a place-setting with a glass of apple juice. Even for compounds with established meanings, context can force an alternative interpretation (Bauer, 1983). These problems led to analyses in which the relationship between the parts of a compound is undetermined by the grammar, e.g., Dowty (1979), Bauer (1983). Schematically this is equivalent to the following rule, where R is undetermined (to simplify exposition, we ignore the quantifier for y): NO —&gt; Ni N2 (1) Ax[P (x) A Q(y) A R(x , y)] Ay[Q(y)] Ax[P (x)] Similar approaches have been adopted in NLP with further processing using domain restrictions to resolve the interpretation (e.g., Hobbs et al (1993)). However, this is also unsatisfactory, because (1) overgenerates and ignores systematic pro</context>
</contexts>
<marker>Bauer, 1983</marker>
<rawString>Bauer, L. (1983) English word-formation, Cambridge University Press, Cambridge, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E J Briscoe</author>
<author>A Copestake</author>
</authors>
<title>Controlling the application of lexical rules&apos;,</title>
<date>1996</date>
<booktitle>Proceedings of the ACL SIGLEX Workshop on Breadth and Depth of Semantic Lexicons,</booktitle>
<location>Santa Cruz, CA.</location>
<contexts>
<context position="2536" citStr="Briscoe and Copestake (1996)" startWordPosition="386" endWordPosition="389">ne meaning, but this does not preclude other uses in sufficiently marked contexts (e.g., Bauer&apos;s (1983) example of garbage man with an interpretation analogous to snowman). Because of the difficulty of resolving lexical ambiguity, it is usual in NLP applications to exclude &apos;rare&apos; senses from the lexicon, and to explicitly list frequent forms, rather than to derive them. But this increases errors due to unexpected vocabulary, especially for highly productive derivational processes. For this and other reasons it is preferable to assume some generative devices in the lexicon (Pustejovsky, 1995). Briscoe and Copestake (1996) argue that a differential estimation of the productivity of derivation processes allows an approximation of the probabilities of previously unseen derived uses. If more probable senses are preferred by the system, the proliferation of senses that results from unconstrained use of lexical rules or other generative devices is effectively controlled. An interacting issue is the granularity of meaning of derived forms. If the lexicon produces a small number of very underspecified senses for a wordform, the ambiguity problem is apparently reduced, but pragmatics may have insufficient information w</context>
<context position="11330" citStr="Briscoe and Copestake (1996)" startWordPosition="1704" endWordPosition="1707">st, an unusual compound, such as apple-juice seat, may only be compatible with general-nn, and would be assigned the most underspecified interpretation. As we will see in §4, this means pragmatics 138 Unseen-prob-mass(cmp-form) = number-of-applicable-schemata(cmp-form) f req(cmp-form)+number-of-applicable-schemata(cmp-form) Prod(cs.) Estimated-freq(interpretation, with cmp-form) = Unseen-prob-mass(cmp-form) x E Prod(csi),...,Prod(cs..) (where csi . cs,, are the compound schemata needed to derive the n unattested entries for the formj) Figure 4: Probabilities for unseen compounds: adapted from Briscoe and Copestake (1996) must find a contextual interpretation. Thus, for any compound there may be some context in which it can be interpreted, but in the absence of a marked context, only compounds which instantiate one of the subschemata are acceptable. 3 Encoding Lexical Preferences In order to help pragmatics select between the multiple possible interpretations, we utilise probabilities. For an established form, derived or not, these depend straightforwardly on the frequency of a particular sense. For example, in the BNC, diet has probability of about 0.9 of occurring in the food sense and 0.005 in the legislatu</context>
<context position="12985" citStr="Briscoe and Copestake (1996)" startWordPosition="1958" endWordPosition="1961">bability is distributed between unseen interpretations licensed by schemata, to allow for novel uses. This distribution is weighted to allow for productivity differences between schemata. For unseen compounds, all probabilities depend on schema productivity. Compound schemata range from the nonproductive (e.g., the verb-noun pattern exemplified by pickpocket). to the almost fully productive (e.g., made-of) with many schemata being intermediate (e.g., has-part: 4-door car is acceptable but the apparently similar *sunroof car is not). We use the following estimate for productivity (adapted from Briscoe and Copestake (1996)): ill + 1 Prod(cmp-schema) = (where N is the number of pairs of senses which match the schema input and /II is the number of attested two-noun output forms — we ignore compounds with more than two nouns for simplicity). Formulae for calculating the unseen probability mass and for allocating it differentially according to schema productivity are shown in Figure 4. Finergrained, more accurate productivity estimates can be obtained by considering subsets of the possible inputs — this allows for some real-world effects (e.g., the made-of schema is unlikely for liquid/physicalartifact compounds). </context>
</contexts>
<marker>Briscoe, Copestake, 1996</marker>
<rawString>Briscoe, E.J. and A. Copestake (1996) &apos;Controlling the application of lexical rules&apos;, Proceedings of the ACL SIGLEX Workshop on Breadth and Depth of Semantic Lexicons, Santa Cruz, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Downing</author>
</authors>
<title>On the Creation and Use</title>
<date>1977</date>
<journal>of English Compound Nouns&apos;, Language,</journal>
<volume>53</volume>
<issue>4</issue>
<pages>810--842</pages>
<contexts>
<context position="4668" citStr="Downing (1977)" startWordPosition="699" endWordPosition="701">of spring Figure 1: Some German compounds with non-compound translations mantics and pragmatics in determining meaning. We concentrate on (right-headed) compound nouns, since these raise especially difficult problems for NLP system architecture (Sparck Jones, 1983). 2 The grammar of compound nouns Within linguistics, attempts to classify nominal compounds using a small fixed set of meaning relations (e.g., Levi (1978)) are usually thought to have failed, because there appear to be exceptions to any classification. Compounds are attested with meanings which can only be determined contextually. Downing (1977) discusses apple juice seat, uttered in a context in which it identifies a place-setting with a glass of apple juice. Even for compounds with established meanings, context can force an alternative interpretation (Bauer, 1983). These problems led to analyses in which the relationship between the parts of a compound is undetermined by the grammar, e.g., Dowty (1979), Bauer (1983). Schematically this is equivalent to the following rule, where R is undetermined (to simplify exposition, we ignore the quantifier for y): NO —&gt; Ni N2 (1) Ax[P (x) A Q(y) A R(x , y)] Ay[Q(y)] Ax[P (x)] Similar approache</context>
</contexts>
<marker>Downing, 1977</marker>
<rawString>Downing, P. (1977) &apos;On the Creation and Use of English Compound Nouns&apos;, Language, vol.53(4), 810-842.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Dowty</author>
</authors>
<title>Word meaning in Montague Grammar,</title>
<date>1979</date>
<location>Reidel, Dordrecht.</location>
<contexts>
<context position="5034" citStr="Dowty (1979)" startWordPosition="760" endWordPosition="761">all fixed set of meaning relations (e.g., Levi (1978)) are usually thought to have failed, because there appear to be exceptions to any classification. Compounds are attested with meanings which can only be determined contextually. Downing (1977) discusses apple juice seat, uttered in a context in which it identifies a place-setting with a glass of apple juice. Even for compounds with established meanings, context can force an alternative interpretation (Bauer, 1983). These problems led to analyses in which the relationship between the parts of a compound is undetermined by the grammar, e.g., Dowty (1979), Bauer (1983). Schematically this is equivalent to the following rule, where R is undetermined (to simplify exposition, we ignore the quantifier for y): NO —&gt; Ni N2 (1) Ax[P (x) A Q(y) A R(x , y)] Ay[Q(y)] Ax[P (x)] Similar approaches have been adopted in NLP with further processing using domain restrictions to resolve the interpretation (e.g., Hobbs et al (1993)). However, this is also unsatisfactory, because (1) overgenerates and ignores systematic properties of various classes of compounds. Overgeneration is apparent when we consider translation of German compounds, since many do not corre</context>
</contexts>
<marker>Dowty, 1979</marker>
<rawString>Dowty, D. (1979) Word meaning in Montague Grammar, Reidel, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hobbs</author>
</authors>
<title>Coherence and Coreference&apos;,</title>
<date>1979</date>
<journal>Cognitive Science,</journal>
<volume>3</volume>
<pages>67--90</pages>
<contexts>
<context position="20567" citStr="Hobbs (1979)" startWordPosition="3226" endWordPosition="3227">chment point a in T. That is. anaphora can&apos;t be resolved, or no rhetorical connection can be computed via DICE. For example. the representations of (5a.b) (in simplifie(l form) are respectively n and 3: (5) a. Mary put her clothes into various large bags. In words, the conditions in 3 require the object denoted by the definite description to be linked by some &apos;bridging relation B (possibly identity, cf. van der Sandt (1992)) to an object u identified in the discourse context (Asher and Lascarides. 1996). In SDRT. the values of v and B are computed as a byproduct of SDRT.5 Update function (cf. Hobbs (1979)); one specifies u and B by inferring the relevant new semantic content arising from R&apos;s coherence constraints. where R is the rhetorical relation inferred via the DICE axioms. If one cannot resolve the conditions u =? or B =I&apos; through SDRS update. then by the above definition of well-definedness on spftss the discourse is incoherent (and we have presupposition failure). The detailed analysis of (3) and (52) involve reasoning about the values of v and B. But for reasons of space. we gloss over the details given in .Asher and Lascarides (1996) for specifying v and B through the SDRT update proc</context>
</contexts>
<marker>Hobbs, 1979</marker>
<rawString>Hobbs, J. (1979) &apos;Coherence and Coreference&apos;, Cognitive Science, vol.3, 67-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hobbs</author>
</authors>
<title>On the Coherence and Structure of Discourse,</title>
<date>1985</date>
<tech>Report No. CSLI-85-37,</tech>
<institution>Center for</institution>
<contexts>
<context position="16867" citStr="Hobbs (1985)" startWordPosition="2588" endWordPosition="2589">y (SDRT) (e.g., Asher (1993)) and the accompanying pragmatic component Discourse in Commonsense Entailment (DICE) (Lascarides and Asher. 1993). This framework has already been successful in accounting for other phenomena on the interface between the lexicon and pragmatics. e.g.. Asher and Lascarides (1995). Lascarides and Copestake (1995). Lascarides. Copestake and Briscoe (1996). SDRT is an extension of DRT (Ramp and ReyIe. 1993). where discourse is represented as a recursive set of DRss representing the clauses, linked together with rhetorical relations such as Elaboration and Contrast. cf. Hobbs (1985). Polanyi (1985). Building an SDRS involves computing a rhetorical relation between the representation of the current clause and the SDRS built so far. DICE specifies how various background knowledge resources interact to provide clues about which rhetorical relation holds. The rules in DICE include default conditions of the form P&gt; Q. which means lip, then normally Q. For example, Elaboration states: if 0 is to be attached to a with a rhetorical relation, where a is part of the discourse structure 7 already (i.e., (r, a, 3) holds). and 3 is a subtype of a—which by Subtype means that a&apos;s event</context>
</contexts>
<marker>Hobbs, 1985</marker>
<rawString>Hobbs, J. (1985) On the Coherence and Structure of Discourse, Report No. CSLI-85-37, Center for the Study of Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Hobbs</author>
<author>M Stickel</author>
<author>D Appelt</author>
<author>P Martin</author>
</authors>
<title>Interpretation as Abduction&apos;,</title>
<date>1993</date>
<journal>Artificial Intelligence,</journal>
<volume>63</volume>
<pages>69--142</pages>
<contexts>
<context position="5400" citStr="Hobbs et al (1993)" startWordPosition="820" endWordPosition="823">ce. Even for compounds with established meanings, context can force an alternative interpretation (Bauer, 1983). These problems led to analyses in which the relationship between the parts of a compound is undetermined by the grammar, e.g., Dowty (1979), Bauer (1983). Schematically this is equivalent to the following rule, where R is undetermined (to simplify exposition, we ignore the quantifier for y): NO —&gt; Ni N2 (1) Ax[P (x) A Q(y) A R(x , y)] Ay[Q(y)] Ax[P (x)] Similar approaches have been adopted in NLP with further processing using domain restrictions to resolve the interpretation (e.g., Hobbs et al (1993)). However, this is also unsatisfactory, because (1) overgenerates and ignores systematic properties of various classes of compounds. Overgeneration is apparent when we consider translation of German compounds, since many do not correspond straightforwardly to English compounds (e.g., Figure 1). Since these exceptions are English-specific they cannot be explained via pragmatics. Furthermore they are not simply due to lexical idiosyncrasies: for instance, Arztterminl* doctor appointment is representative of many compounds with human-denoting first elements, which require a possessive in English</context>
<context position="26969" citStr="Hobbs et al (1993)" startWordPosition="4344" endWordPosition="4347">as possible. All nonmonotonic reasoning remains packed into the definition of Update(r, a, 0), where one needs pragmatic reasoning anyway for inferring rhetorical relations. Prefer Frequent Senses is a monotonic rule, it doesn&apos;t increase the load on nonmonotonic reasoning, and it doesn&apos;t introduce extra pragmatic machinery peculiar to the task of disambiguating word senses. Indeed, this rule offers a way of checking whether fully specified relations between compounds are acceptable, rather than relying on (expensive) pragmatics to compute them. We have mixed stochastic and symbolic reasoning. Hobbs et al (1993) also mix numbers and rules by means of weighted abduction. However, the theories differ in several important respects. First, our pragmatic component has no access to word forms and syntax (and so it&apos;s not language specific), whereas Hobbs et al&apos;s rules for pragmatic interpretation can access these knowledge sources. Second, our probabilities encode the frequency of word senses associated with word forms. In contrast, the weights that guide abduction correspond to a wider variety of information, and do not necessarily correspond to word sense/form frequencies. Indeed, it is unclear what meani</context>
</contexts>
<marker>Hobbs, Stickel, Appelt, Martin, 1993</marker>
<rawString>Hobbs, J.R., M. Stickel, D. Appelt and P. Martin (1993) &apos;Interpretation as Abduction&apos;, Artificial Intelligence, vol.63.1, 69-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnston</author>
<author>B Boguraev</author>
<author>J Pustejovsky</author>
</authors>
<title>The acquisition and interpretation of complex nominals&apos;,</title>
<date>1995</date>
<booktitle>Proceedings of the AAAI Spring Symposium on</booktitle>
<location>Stanford, CA.</location>
<contexts>
<context position="10258" citStr="Johnston et al, 1995" startWordPosition="1564" endWordPosition="1567">d formally as lexical/grammar rules (lexical rules and grammar rules being very similar in our framework) but inefficiency due to multiple interpretations is avoided in the implementation by using a form of packing. 3. Ax[R(y, x) A -,(made-of(y, x) V contain(y, x) V • • -)1 The predicate made-of is to be interpreted as material constituency (e.g. Link (1983)). We follow Johnston and Busa (1996) in using Pustejovsky&apos;s (1995) concept of telic role to encode the purpose of an artifact. These schemata give minimal indications of compound semantics: it may be desirable to provide more information (Johnston et al, 1995), but we will not discuss that here. Established compounds may have idiosyncratic interpretations or inherit from one or more schemata (though compounds with multiple established senses due to ambiguity in the relationship between constituents rather than lexical ambiguity are fairly unusual). But established compounds may also have unestablished interpretations, although, as discussed in §3, these will have minimal probabilities. In contrast, an unusual compound, such as apple-juice seat, may only be compatible with general-nn, and would be assigned the most underspecified interpretation. As </context>
</contexts>
<marker>Johnston, Boguraev, Pustejovsky, 1995</marker>
<rawString>Johnston, M., B. Boguraev and J. Pustejovsky (1995) &apos;The acquisition and interpretation of complex nominals&apos;, Proceedings of the AAAI Spring Symposium on representation and acquisition of lexical knowledge, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnston</author>
<author>F Busa</author>
</authors>
<title>Qualia structure and the compositional interpretation of compounds&apos;,</title>
<date>1996</date>
<booktitle>Proceedings of the ACL SIGLEX workshop on breadth and depth of semantic lexicons,</booktitle>
<location>Santa Cruz, CA.</location>
<contexts>
<context position="10034" citStr="Johnston and Busa (1996)" startWordPosition="1528" endWordPosition="1531">otton(y) A bag(x) A made-of(y, x)] 2. Ax[cotton(y) A bag(x) A TELIC(bag)(y, x)] = Ax[cotton(y) A bag(x) A contain(y, x)] 2We formalise this with typed default feature structures (Lascarides et al, 1996). Schemata can be regarded formally as lexical/grammar rules (lexical rules and grammar rules being very similar in our framework) but inefficiency due to multiple interpretations is avoided in the implementation by using a form of packing. 3. Ax[R(y, x) A -,(made-of(y, x) V contain(y, x) V • • -)1 The predicate made-of is to be interpreted as material constituency (e.g. Link (1983)). We follow Johnston and Busa (1996) in using Pustejovsky&apos;s (1995) concept of telic role to encode the purpose of an artifact. These schemata give minimal indications of compound semantics: it may be desirable to provide more information (Johnston et al, 1995), but we will not discuss that here. Established compounds may have idiosyncratic interpretations or inherit from one or more schemata (though compounds with multiple established senses due to ambiguity in the relationship between constituents rather than lexical ambiguity are fairly unusual). But established compounds may also have unestablished interpretations, although, </context>
</contexts>
<marker>Johnston, Busa, 1996</marker>
<rawString>Johnston, M. and F. Busa (1996) &apos;Qualia structure and the compositional interpretation of compounds&apos;, Proceedings of the ACL SIGLEX workshop on breadth and depth of semantic lexicons, Santa Cruz, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Jones</author>
</authors>
<title>Predicting nominal compounds&apos;,</title>
<date>1995</date>
<booktitle>Proceedings of the 17th Annual conference of the Cognitive Science Society,</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="8899" citStr="Jones (1995)" startWordPosition="1347" endWordPosition="1348">oun compound schemata. The boxed nodes indicate actual schemata: other nodes are included for convenience in expressing generalisations. general-nn NO Ax[P (x) A Q(y) A R(x , y)] R = /general-nn -&gt; Ni N2 Ay[Q(y)] Ax[P(x)] anything anything /stressed substance physobj /stressed made-of R = made-of purpose-patient R = TELIC(N2) anything artifact Figure 3: Details of some schemata for noun-noun compounds. / indicates that the value to its right is default information. Space limitations preclude detailed discussion but Figures 2 and 3 show a partial default inheritance hierarchy of schemata (cf., Jones (1995)).2 Multiple schemata may apply to a single compound: for example, cotton bag is an instantiation of the made-of schema, the non-derived-purposepatient schema and also the general-nn schema. Each applicable schema corresponds to a different sense: so cotton bag is ambiguous rather than vague. The interpretation of the hierarchy is that the use of a more general schema implies that the meanings given by specific subschemata are excluded, and thus we have the following interpretations for cotton bag: 1. Ax[cotton(y) A bag(x) A made-of(y, x)] 2. Ax[cotton(y) A bag(x) A TELIC(bag)(y, x)] = Ax[cott</context>
</contexts>
<marker>Jones, 1995</marker>
<rawString>Jones, B. (1995) &apos;Predicting nominal compounds&apos;, Proceedings of the 17th Annual conference of the Cognitive Science Society, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kamp</author>
<author>U Reyle</author>
</authors>
<title>From Discourse to Logic: an introduction to modeltheoretic semantics, formal logic and Discourse Representation Theory,</title>
<date>1993</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht, Germany.</location>
<marker>Kamp, Reyle, 1993</marker>
<rawString>Kamp, H. and U. Reyle (1993) From Discourse to Logic: an introduction to modeltheoretic semantics, formal logic and Discourse Representation Theory, Kluwer Academic Publishers, Dordrecht, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lascarides</author>
<author>E J Briscoe</author>
<author>N Asher</author>
<author>A Copestake</author>
</authors>
<title>Persistent and Order Independent Typed Default Unification&apos;, Linguistics and Philosophy,</title>
<date>1996</date>
<volume>19</volume>
<pages>1--89</pages>
<contexts>
<context position="9612" citStr="Lascarides et al, 1996" startWordPosition="1458" endWordPosition="1461">tiation of the made-of schema, the non-derived-purposepatient schema and also the general-nn schema. Each applicable schema corresponds to a different sense: so cotton bag is ambiguous rather than vague. The interpretation of the hierarchy is that the use of a more general schema implies that the meanings given by specific subschemata are excluded, and thus we have the following interpretations for cotton bag: 1. Ax[cotton(y) A bag(x) A made-of(y, x)] 2. Ax[cotton(y) A bag(x) A TELIC(bag)(y, x)] = Ax[cotton(y) A bag(x) A contain(y, x)] 2We formalise this with typed default feature structures (Lascarides et al, 1996). Schemata can be regarded formally as lexical/grammar rules (lexical rules and grammar rules being very similar in our framework) but inefficiency due to multiple interpretations is avoided in the implementation by using a form of packing. 3. Ax[R(y, x) A -,(made-of(y, x) V contain(y, x) V • • -)1 The predicate made-of is to be interpreted as material constituency (e.g. Link (1983)). We follow Johnston and Busa (1996) in using Pustejovsky&apos;s (1995) concept of telic role to encode the purpose of an artifact. These schemata give minimal indications of compound semantics: it may be desirable to p</context>
</contexts>
<marker>Lascarides, Briscoe, Asher, Copestake, 1996</marker>
<rawString>Lascarides, A., E.J. Briscoe, N. Asher and A. Copestake (1996) &apos;Persistent and Order Independent Typed Default Unification&apos;, Linguistics and Philosophy, vol.19:1, 1-89.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Lascarides</author>
<author>A</author>
</authors>
<title>Copestake (in press) &apos;Pragmatics and Word Meaning&apos;,</title>
<journal>Journal of Linguistics,</journal>
<marker>Lascarides, A, </marker>
<rawString>Lascarides, A. and A. Copestake (in press) &apos;Pragmatics and Word Meaning&apos;, Journal of Linguistics,</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lascarides</author>
<author>A Copestake</author>
<author>E J Briscoe</author>
</authors>
<title>Ambiguity and Coherence&apos;,</title>
<date>1996</date>
<journal>Journal of Semantics,</journal>
<volume>13</volume>
<pages>41--65</pages>
<contexts>
<context position="9612" citStr="Lascarides et al, 1996" startWordPosition="1458" endWordPosition="1461">tiation of the made-of schema, the non-derived-purposepatient schema and also the general-nn schema. Each applicable schema corresponds to a different sense: so cotton bag is ambiguous rather than vague. The interpretation of the hierarchy is that the use of a more general schema implies that the meanings given by specific subschemata are excluded, and thus we have the following interpretations for cotton bag: 1. Ax[cotton(y) A bag(x) A made-of(y, x)] 2. Ax[cotton(y) A bag(x) A TELIC(bag)(y, x)] = Ax[cotton(y) A bag(x) A contain(y, x)] 2We formalise this with typed default feature structures (Lascarides et al, 1996). Schemata can be regarded formally as lexical/grammar rules (lexical rules and grammar rules being very similar in our framework) but inefficiency due to multiple interpretations is avoided in the implementation by using a form of packing. 3. Ax[R(y, x) A -,(made-of(y, x) V contain(y, x) V • • -)1 The predicate made-of is to be interpreted as material constituency (e.g. Link (1983)). We follow Johnston and Busa (1996) in using Pustejovsky&apos;s (1995) concept of telic role to encode the purpose of an artifact. These schemata give minimal indications of compound semantics: it may be desirable to p</context>
</contexts>
<marker>Lascarides, Copestake, Briscoe, 1996</marker>
<rawString>Lascarides, A., A. Copestake and E. J. Briscoe (1996) &apos;Ambiguity and Coherence&apos;, Journal of Semantics, vol.13.1, 41-65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Levi</author>
</authors>
<title>The syntax and semantics of complex nominals,</title>
<date>1978</date>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<contexts>
<context position="4475" citStr="Levi (1978)" startWordPosition="670" endWordPosition="671">rschlag * date proposal proposal for a date Terminvereinbarung * date agreement agreement on a date Januarhalfte * January half half of January Friihlingsanfang * spring beginning beginning of spring Figure 1: Some German compounds with non-compound translations mantics and pragmatics in determining meaning. We concentrate on (right-headed) compound nouns, since these raise especially difficult problems for NLP system architecture (Sparck Jones, 1983). 2 The grammar of compound nouns Within linguistics, attempts to classify nominal compounds using a small fixed set of meaning relations (e.g., Levi (1978)) are usually thought to have failed, because there appear to be exceptions to any classification. Compounds are attested with meanings which can only be determined contextually. Downing (1977) discusses apple juice seat, uttered in a context in which it identifies a place-setting with a glass of apple juice. Even for compounds with established meanings, context can force an alternative interpretation (Bauer, 1983). These problems led to analyses in which the relationship between the parts of a compound is undetermined by the grammar, e.g., Dowty (1979), Bauer (1983). Schematically this is equ</context>
</contexts>
<marker>Levi, 1978</marker>
<rawString>Levi, J. (1978) The syntax and semantics of complex nominals, Academic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Liberman</author>
<author>R Sproat</author>
</authors>
<title>The stress and structure of modified noun phrases in English&apos;</title>
<date>1992</date>
<pages>131--182</pages>
<editor>in I.A. Sag and A. Szabolsci (eds.), Lexical matters,</editor>
<publisher>CSLI Publications,</publisher>
<contexts>
<context position="7054" citStr="Liberman and Sproat, 1992" startWordPosition="1065" endWordPosition="1069">-noun compound with the possessive analysed as a case marker. In another subcategory of compounds, the head provides the predicate (e.g., dog catcher, bottle crusher). Again, there are restrictions: it is not usually possible to form a compound with an agentive predicate taking an argument that normally requires a preposition (contrast water seeker with *water looker). Stress assignment also demonstrates inadequacies in (1): compounds which have the interpretation &apos;Y made of X&apos; (e.g., nylon rope, oak table) generally have main stress on the righthand noun, in contrast to most other compounds (Liberman and Sproat, 1992). Stress sometimes disambiguates meaning: e.g., with righthand stress cotton bag has the interpretation bag made of cotton while with leftmost stress an alternative reading, bag for cotton, is available. Furthermore, ordering of elements is restricted: e.g., cotton garment bag/ * garment cotton bag. The rule in (1) is therefore theoretically inadequate, because it predicts that all noun-noun compounds are acceptable. Furthermore, it gives no hint of likely interpretations, leaving an immense burden to pragmatics. We therefore take a position which is intermediate between the two extremes outli</context>
</contexts>
<marker>Liberman, Sproat, 1992</marker>
<rawString>Liberman, M. and R. Sproat (1992) &apos;The stress and structure of modified noun phrases in English&apos; in I.A. Sag and A. Szabolsci (eds.), Lexical matters, CSLI Publications, pp. 131-182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Link</author>
</authors>
<title>The logical analysis of plurals and mass terms: a lattice-theoretical approach&apos;</title>
<date>1983</date>
<booktitle>in Bauerle, Schwarze and von Stechow (eds.), Meaning, use and interpretation of language, de Gruyter,</booktitle>
<pages>302--323</pages>
<location>Berlin,</location>
<contexts>
<context position="9997" citStr="Link (1983)" startWordPosition="1524" endWordPosition="1525"> for cotton bag: 1. Ax[cotton(y) A bag(x) A made-of(y, x)] 2. Ax[cotton(y) A bag(x) A TELIC(bag)(y, x)] = Ax[cotton(y) A bag(x) A contain(y, x)] 2We formalise this with typed default feature structures (Lascarides et al, 1996). Schemata can be regarded formally as lexical/grammar rules (lexical rules and grammar rules being very similar in our framework) but inefficiency due to multiple interpretations is avoided in the implementation by using a form of packing. 3. Ax[R(y, x) A -,(made-of(y, x) V contain(y, x) V • • -)1 The predicate made-of is to be interpreted as material constituency (e.g. Link (1983)). We follow Johnston and Busa (1996) in using Pustejovsky&apos;s (1995) concept of telic role to encode the purpose of an artifact. These schemata give minimal indications of compound semantics: it may be desirable to provide more information (Johnston et al, 1995), but we will not discuss that here. Established compounds may have idiosyncratic interpretations or inherit from one or more schemata (though compounds with multiple established senses due to ambiguity in the relationship between constituents rather than lexical ambiguity are fairly unusual). But established compounds may also have unes</context>
</contexts>
<marker>Link, 1983</marker>
<rawString>Link, G. (1983) &apos;The logical analysis of plurals and mass terms: a lattice-theoretical approach&apos; in Bauerle, Schwarze and von Stechow (eds.), Meaning, use and interpretation of language, de Gruyter, Berlin, pp. 302-323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Polanyi</author>
</authors>
<title>A Theory of Discourse Structure and Discourse Coherence&apos;,</title>
<date>1985</date>
<booktitle>Proceedings of the Papers from the General Session at the Twenty-First Regional Meeting of the Chicago Linguistics Society,</booktitle>
<pages>25--27</pages>
<location>Chicago,</location>
<contexts>
<context position="16883" citStr="Polanyi (1985)" startWordPosition="2590" endWordPosition="2591">, Asher (1993)) and the accompanying pragmatic component Discourse in Commonsense Entailment (DICE) (Lascarides and Asher. 1993). This framework has already been successful in accounting for other phenomena on the interface between the lexicon and pragmatics. e.g.. Asher and Lascarides (1995). Lascarides and Copestake (1995). Lascarides. Copestake and Briscoe (1996). SDRT is an extension of DRT (Ramp and ReyIe. 1993). where discourse is represented as a recursive set of DRss representing the clauses, linked together with rhetorical relations such as Elaboration and Contrast. cf. Hobbs (1985). Polanyi (1985). Building an SDRS involves computing a rhetorical relation between the representation of the current clause and the SDRS built so far. DICE specifies how various background knowledge resources interact to provide clues about which rhetorical relation holds. The rules in DICE include default conditions of the form P&gt; Q. which means lip, then normally Q. For example, Elaboration states: if 0 is to be attached to a with a rhetorical relation, where a is part of the discourse structure 7 already (i.e., (r, a, 3) holds). and 3 is a subtype of a—which by Subtype means that a&apos;s event is a subtype of</context>
</contexts>
<marker>Polanyi, 1985</marker>
<rawString>Polanyi, L. (1985) &apos;A Theory of Discourse Structure and Discourse Coherence&apos;, Proceedings of the Papers from the General Session at the Twenty-First Regional Meeting of the Chicago Linguistics Society, Chicago, pp. 25-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
</authors>
<title>The Generative Lexicon,</title>
<date>1995</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="2506" citStr="Pustejovsky, 1995" startWordPosition="383" endWordPosition="385">e established with one meaning, but this does not preclude other uses in sufficiently marked contexts (e.g., Bauer&apos;s (1983) example of garbage man with an interpretation analogous to snowman). Because of the difficulty of resolving lexical ambiguity, it is usual in NLP applications to exclude &apos;rare&apos; senses from the lexicon, and to explicitly list frequent forms, rather than to derive them. But this increases errors due to unexpected vocabulary, especially for highly productive derivational processes. For this and other reasons it is preferable to assume some generative devices in the lexicon (Pustejovsky, 1995). Briscoe and Copestake (1996) argue that a differential estimation of the productivity of derivation processes allows an approximation of the probabilities of previously unseen derived uses. If more probable senses are preferred by the system, the proliferation of senses that results from unconstrained use of lexical rules or other generative devices is effectively controlled. An interacting issue is the granularity of meaning of derived forms. If the lexicon produces a small number of very underspecified senses for a wordform, the ambiguity problem is apparently reduced, but pragmatics may h</context>
</contexts>
<marker>Pustejovsky, 1995</marker>
<rawString>Pustejovsky, J. (1995) The Generative Lexicon, MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Probabilistic Lexicalised Tree Adjoining Grammar&apos;,</title>
<date>1992</date>
<booktitle>Proceedings of the Coling92,</booktitle>
<location>Nantes, France.</location>
<contexts>
<context position="13705" citStr="Resnik (1992)" startWordPosition="2074" endWordPosition="2075">I is the number of attested two-noun output forms — we ignore compounds with more than two nouns for simplicity). Formulae for calculating the unseen probability mass and for allocating it differentially according to schema productivity are shown in Figure 4. Finergrained, more accurate productivity estimates can be obtained by considering subsets of the possible inputs — this allows for some real-world effects (e.g., the made-of schema is unlikely for liquid/physicalartifact compounds). Lexical probabilities should be combined to give an overall probability for a logical form (LF): see e.g., Resnik (1992). But we will ignore this here and assume pragmatics has to distinguish between alternatives which differ only in the sense assigned to one compound. (2) shows possible interpretations for cotton bag with associated probabilities. LFS are encoded in DRT. The probabilities given here are based on productivity figures for fabric/container compounds in the BNC, using WordNet as a source of semantic categories. Pragmatics screens the LFS for acceptability. If a LF contains an underspecified element (e.g., arising from general-nn), this must be instantiated by pragmatics from the discourse context.</context>
</contexts>
<marker>Resnik, 1992</marker>
<rawString>Resnik, P. (1992) &apos;Probabilistic Lexicalised Tree Adjoining Grammar&apos;, Proceedings of the Coling92, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R van der Sandt</author>
</authors>
<title>Presupposition Projection as Anaphora Resolution&apos;,</title>
<date>1992</date>
<journal>Journal of Semantics,</journal>
<volume>19</volume>
<marker>van der Sandt, 1992</marker>
<rawString>van der Sandt, R. (1992) &apos;Presupposition Projection as Anaphora Resolution&apos;, Journal of Semantics, vol.19.4,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sparck Jones</author>
<author>K</author>
</authors>
<title>So what about parsing compound nouns?&apos;</title>
<date>1983</date>
<booktitle>Automatic natural language parsing, Ellis Horwood,</booktitle>
<pages>164--168</pages>
<editor>in K. Sparck Jones and Y. Wilks (eds.),</editor>
<location>Chichester, England,</location>
<marker>Jones, K, 1983</marker>
<rawString>Sparck Jones, K. (1983) `So what about parsing compound nouns?&apos; in K. Sparck Jones and Y. Wilks (eds.), Automatic natural language parsing, Ellis Horwood, Chichester, England, pp. 164-168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Webber</author>
</authors>
<title>Structure and Ostension in the Interpretation of Discourse Deixis&apos;, Language and Cognitive Processes,</title>
<date>1991</date>
<volume>6</volume>
<pages>107--135</pages>
<marker>Webber, 1991</marker>
<rawString>Webber, B. (1991) &apos;Structure and Ostension in the Interpretation of Discourse Deixis&apos;, Language and Cognitive Processes, vol.6.2, 107-135.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>