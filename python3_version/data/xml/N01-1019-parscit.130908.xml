<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.989365">
Information-based Machine Translation
</title>
<author confidence="0.970569">
Keiko HORIGUCHI
</author>
<affiliation confidence="0.981837">
Spoken Language Technology, Sony US Research Laboratories
</affiliation>
<address confidence="0.948225">
3300 Zanker Road
San Jose, CA 95134
</address>
<email confidence="0.996793">
keiko@slt.sel.sony.com
</email>
<sectionHeader confidence="0.976703" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999989666666667">
This paper describes an approach to Machine
Translation that places linguistic information
at its foundation. The difficulty of translation
from English to Japanese is illustrated with
data that shows the influence of various
linguistic contextual factors. Next, a method
for natural language transfer is presented that
integrates translation examples (represented
as typed feature structures with source-target
indices) with linguistic rules and constraints.
The method has been implemented, and the
results of an evaluation are presented.
</bodyText>
<sectionHeader confidence="0.813248" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999589214285715">
High-quality automatic translation requires the
disambiguation of common, highly ambiguous
verbs, such as to have, to take, or to get. It also
requires the correct handling of
non-compositional, idiomatic expressions with
varying degrees of “fixedness”. We view
Machine Translation in terms of linguistic
information represented as typed feature
structures. By integrating translation information
represented as example pairs with other types of
linguistic information represented as rules, our
approach extends the capabilities of current
machine translation methods, and solves a
number of key problems.
</bodyText>
<sectionHeader confidence="0.910931" genericHeader="method">
1. Linguistic Context for Translation
</sectionHeader>
<bodyText confidence="0.9999375">
In translating different words, phrases, and
expressions, different types and amounts of
information from the context need to be
considered. (Only the sentential context is
considered here.) So far, a systematic solution to
this problem has not been found. This section
illustrates the extent of this problem, and the
remainder of this paper describes our approach.
</bodyText>
<subsectionHeader confidence="0.998915">
1.1. Expressions with to have
</subsectionHeader>
<bodyText confidence="0.9999719">
We examined the problem of translating the
English main verb to have into Japanese. The
verb to have was selected because it is quite
common in colloquial English, yet forms a large
variety of senses, collocations, and idioms. 615
different expressions containing the English verb
to have were extracted from a 7000-sentence
corpus from the “international travel” domain.
Each English expression was manually translated
into Japanese in the most general way possible.
</bodyText>
<subsectionHeader confidence="0.959081">
1.2. Target-language Distinctions
</subsectionHeader>
<bodyText confidence="0.964568294117647">
The most general translation for the construction
“X have Y” in this domain was found to be Xdf
Yea k6 (X-ni Y-ga aru):
The copy shop next door has a fax machine.
��������������������
tonari-no kopiiya-ni fakkusu-ga arimasu.
next-ATT copy shop-LOC fax-NOM exist
Other translations are often necessary when the
target language imposes finer semantic
distinction on the state or on the action that is
described. For example, if the object noun phrase
refers to one or more human beings, the Japanese
verb aru is changed into iru. Similarly, the word
pet or a pet animal as the object noun phrase
triggers the translation of to have as katteiru, a
Japanese verb for keeping an animal as a pet :
We have two sons.
</bodyText>
<equation confidence="0.353637">
,kT-lji��tt��
musuko-ga futari imasu.
son-NOM two-CONTR exist
Do you have pets?
������F��� L11*191-!0
</equation>
<bodyText confidence="0.904037333333333">
anata-wa petto-wo katte-imasu-ka
you-TOP pet-ACC keep-ST-Q
Other examples of finer target-language
distinctions include a symptom/disease as the
object of to have. While many physical
symptoms and minor diagnoses (e.g. pain, cavity,
fever, allergy) use the default translation (X-ga
aru), a serious illness or diagnosis is translated
into the copula construction. Many other to have
constructions with a symptom/disease object
require verbs that are specific to the object noun
phrase in Japanese:
</bodyText>
<figure confidence="0.936646166666667">
I have diabetes.
&amp;quot;�#$%&amp;��
watashi-wa toonyobyoo desu.
I-TOP diabetes COP
My wife had a stroke last year.
&apos;�()*+,&amp;-.1*/&amp;�
tsuma-wa kyonen noosocchu-de taoremashita
wife-NOM last year stroke-with fall-PST
My husband had a heart attack.
0~1234~56/~/~~
otto-ga shinzoohossa-wo okoshi-mashita
husband-NOM heart attack-ACC cause-PST
</figure>
<subsectionHeader confidence="0.881048">
1.3. Adjuncts in the Source Language
</subsectionHeader>
<bodyText confidence="0.983647769230769">
Some verbal adjuncts can affect the translation of
the to have construction, not by altering the basic
sense of ‘existing’, but by adding further
information to specify the way in which
something ‘exists’. One example of such an
adjunct is a prepositional phrase (PP) whose
object noun phrase shares its referent with the
SUBJ of have. For example, the utterance below
expresses that the map is held or carried by the
speaker, and the Japanese translation uses the
verb motte-iru, literally meaning to be
carrying/holding.
I have the map with me.
</bodyText>
<equation confidence="0.392067666666667">
&amp;quot;~7~89~:~ ����
watashi-wa sono chizu-wo motte-imasu.
TOP the map-ACC hold-ST
</equation>
<bodyText confidence="0.965127307692308">
If the subject noun phrase is inanimate, the
Japanese translation uses the verb tsuite-iru,
which literally means to be attached.
The main dish has a salad with it.
���������������������
meindisshu-ni-wa sarada-ga tsuite-imasu.
main dish-LOC-TOP salad-NOM attach-ST
Similarly, a construction with an on-PP is
translated into the Japanese construction
notte-iru, which literally means to be
written/placed on. A construction with an in-PP
is translated into the Japanese construction
haitte-iru, which literally means to be placed in:
</bodyText>
<equation confidence="0.807429375">
Does the map have subway lines on it.
7oO89IZ8;&lt;=/00_� �1*&apos;91_!o
Sono chizu-ni chikatetsusen-ga notte-imasu-ka.
the map-LOC subway line-NOM written-on-Q
The closet has extra hangers in it.
��������������� �����
kurozetto-ni yobun-no hangaa-ga haitte-imasu.
closet-LOC extra-ATT hanger-NOM placed-in-ST
</equation>
<bodyText confidence="0.985246333333333">
Adjunct adjectival phrases and past participles
also specify the way something exists. For
example, available in the have construction
generally changes the translation to aite-iru, to be
open or available:
We have one twin room available.
</bodyText>
<equation confidence="0.776291">
&gt;?@oAR/JaBCD~ �I*lt�
tsuin-no heya-ga hitotsu aite-imasu
twin-ATT room-NOM one-CONTR open-ST
</equation>
<subsectionHeader confidence="0.999574">
1.4. Source Language Ambiguities
</subsectionHeader>
<bodyText confidence="0.9669775">
In some cases, the to have construction in English
carries more than one sense, and some linguistic
contexts can bring out one of the senses as the
preferred meaning. For example, the construction
X has a Y taste is ambiguous between to be
exercising Y (personal) taste and to taste X. This
ambiguity is usually resolved by looking at the
semantic properties of the subject noun phrase, as
illustrated in the examples below:
He has simple tastes.
</bodyText>
<footnote confidence="0.591570714285714">
E�F@GH�IJ�/ ~K~
kare-ga shinpuru-na shumi-wo shiteiru
he-NOM simple taste-ACC do-ST
This wine has a very clean taste.
6~L?@~~ MNO!�J��K�
kono wain-wa totemo sawayaka-na aji-ga suru
this wine-TOP very refreshing taste-NOM do
</footnote>
<bodyText confidence="0.882714272727273">
When the object refers to a specific type of
information, such as number or address, the
construction is inherently ambiguous between to
know (the number), to be carrying (the number),
and (for the number) to exist. The construction
usually carries the meaning of to know, but if the
construction is negated, then the sense of to be
carrying becomes more preferred, since the
negative construction is more specific and only
negates the proposition that the object is
accessible:
</bodyText>
<equation confidence="0.33016675">
I don’t have his phone number.
&amp;quot;�E�PQRS�:� ����
watashi-ga kare-no denwabangoo-wo motteinai
I-NOM he-GEN phone number-ACC hold-ST-NEG
</equation>
<bodyText confidence="0.847443333333333">
On the other hand, if the object noun phrase is an
indefinite noun phrase, it is more likely to mean
to exist :
</bodyText>
<equation confidence="0.48993575">
Do you have an extension number?
T=RS/ab91*�91-!o
naisen bangou-ga arimasu-ka
extension number-NOM exist-Q
</equation>
<bodyText confidence="0.9998916">
Another example of the ambiguities of to have
concerns the two senses to have something
available and to eat, when the object noun phrase
refers to an edible entity. Our corpus analysis
shows that some of the linguistic contexts bring
out one of the two senses as clearly preferred.
For example, the past tense or the perfective
aspect brings out the to eat sense, whereas the
present tense without any aspect markers
suppresses this sense:
</bodyText>
<equation confidence="0.865746833333333">
I had raw fish for dinner.
U�VW�XY�YZ�/��
sakana-no sashimi-wo yuushoku-ni tabemashita
fish-ATT raw-ACC dinner-GOAL eat-PST
I don’t have any American beer on tap.
[\]^o_`_H tlb91*abo
</equation>
<bodyText confidence="0.5060175">
amerika-no namabiiru-wa arimasen.
America-ATT draft beer-TOP exist-NEG
</bodyText>
<subsectionHeader confidence="0.996608">
1.5. Support Verb Constructions and Idioms
</subsectionHeader>
<bodyText confidence="0.9999536">
In some of the constructions, to have functions as
a support verb. In the support verb construction
the object noun phrase constitutes a part of the
verbal predicate rather than an argument of the
verb. If the target language does not have an
equivalent support verb construction, such an
expression with a support verb construction has
to be translated into the corresponding single
verb construction.
Idiomatic expressions in the source and target
languages, and their varying degrees of
“fixedness”, also play a role. For example, the
word RM (kentoo), the Japanese translation of
a clue in I don’t have a clue, requires the special
verb ---) (tsuku), to constitute an idiomatic
expression ����� (kentoo-ga tsuku). As
another example, the English expression Have a
good one does not allow a compositional
translation into a Japanese construction with a
main verb plus an object.
</bodyText>
<subsectionHeader confidence="0.988251">
1.6. Discussion
</subsectionHeader>
<bodyText confidence="0.999057333333333">
From the data described above, it is clear that
there are various factors that contribute to the
different patterns of translation. In order to
handle these different translations correctly, it is
necessary to identify the linguistic features of the
context that trigger different translations, and to
determine how the different features and contexts
interact. In the case of the English to have
construction, the following surface linguistic
features are identified that can be interpreted as
‘triggers’ for translations other than the default
translation:
</bodyText>
<equation confidence="0.9490232">
1 111 past tense
1 111 interrogative or imperative constructions
1 111 negative
1 111 modal auxiliaries
1 111 progressive and/or perfective aspect
1 111 adjectival modifiers for the object NP
(noun phrase)
1 111 prepositional phrase modifiers for the
object NP
1 111 adjectival modifiers for the VP (verb
phrase)
1 111 prepositional phrase modifiers for the VP
1 111 adverbial modifiers for the VP
1 111 constructions that carry a pragmatic force
(request, suggestion, etc.)
</equation>
<bodyText confidence="0.999894">
We found that some of the factors have stronger
influence on the translation than others. For
example, consider the following expression:
</bodyText>
<footnote confidence="0.54123525">
Can I have a look at the room?
70AN4-cd.1* o
sono heya-wo mi-raremasu-ka.
the room-ACC look-PTN-Q
</footnote>
<bodyText confidence="0.979730047619048">
The source-language expression contains more
than one factor that can trigger a different
translation. The first factor is the construction
that usually carries the pragmatic force of
“request”, Can I have X?, which usually triggers
the X -t-.� G 1 V, t- t J-) (X-wo o-negai
dekimasu-ka) construction. At the same time, the
object noun phrase a look means that the verb to
have is used as a support verb. For this reason, the
combination of the verb have and the object noun
phrase a look has to be translated into Japanese as
the verbal predicate A6 (miru). This shows that
the translation preference that is triggered by the
root string of the object noun phrase is stronger
and should take preference over the translation
preference that is triggered by the pragmatic
force.
target-language
feature structure
source-language
feature structure
</bodyText>
<figure confidence="0.99859975">
Linguistic
Transfer
Procesure
Transfer
Grammar
source-language
feature structure
&amp;
most appropriate example
pair feature structures
&amp;
alignment information
source-language
feature structure &amp;
a set of conditions
Thesaurus
Example
Matching
Procedure
Bilingual
Example
Database
Cost
Database
</figure>
<figureCaption confidence="0.999966">
Figure 1: Overview of the Transfer Component
</figureCaption>
<sectionHeader confidence="0.997021" genericHeader="method">
2. Information-based MT
</sectionHeader>
<bodyText confidence="0.999989136363637">
We argue that the sorts of complex translation
correspondences that were illustrated in the
previous section are best represented as
translation examples, but that the transfer
procedure must use qualitative linguistic
constraints in order to choose the correct
examples. Given the types of linguistic features
that influence translation, a highly expressive
linguistic representation for both input and
translation examples is required. We employ
typed feature structures throughout all stages of
translation.
Since there are complex interactions among
different contextual factors, a single quantitative
matching function that calculates a distance
between the input and the examples is not
sufficient. Multiple steps of matching are needed,
each considering a small number of linguistic
dimensions, with the steps executed in the
appropriate order. This is best achieved with a
rule-based linguistic transfer procedure that
controls the example matching procedure.
</bodyText>
<subsectionHeader confidence="0.981589">
2.1. Transfer Component Architecture
</subsectionHeader>
<bodyText confidence="0.999858416666667">
The transfer component for information-based
MT consists of two main procedures, the
linguistic transfer procedure and the example
matching procedure. This is illustrated in Figure
1. The input to this component is the
source-language typed feature structure; this is
created by an analysis component that is not
described further here. Similarly, the output of
the transfer component is a target-language typed
feature structure, from which the target-language
expression is generated by the generation
component (also not described further).
</bodyText>
<subsectionHeader confidence="0.999309">
2.2. Linguistic Transfer
</subsectionHeader>
<bodyText confidence="0.999986033333333">
The linguistic transfer procedure is implemented
as a rewrite-grammar using the special-purpose
Grammar Programming Language (GPL) (Duan,
et al. 2000, Franz, et al. 2000a). The general role
of the transfer grammar is to operate on the input
feature structure in a recursive manner, and to
perform source-to-target transfer by invoking the
example matching procedure, and by using the
translation examples to construct a
target-language feature structure. The transfer
grammar implements the principle of ”large to
small” in covering the input feature structure.
When the transfer procedure invokes the example
matching procedure, it implements the principle
of “specific to general”. Since the linguistic
features interact with each other when they are
combined, and since some of the features have
more influence on the translation than others, it is
necessary to specify a number of separate
invocations of the example matching procedure,
and to pay particular attention to their order. The
invocations of the example matching procedure
are arranged so that each call focuses on one or
two features, making sure that both the input and
the example contain the same feature(s).
Different invocations of the matching procedure
are ordered so that the system checks the
existence of the most important factors first,
gradually progressing to the least important
factors.
</bodyText>
<subsectionHeader confidence="0.996787">
2.3. Example Matching
</subsectionHeader>
<bodyText confidence="0.999979666666666">
The example matching procedure matches the
input feature structure against the example
feature structures, and it returns the most
appropriate example. The architecture of this
module is shown in Figure 2.
When the transfer procedure invokes the example
matching procedure, it specifies a set of linguistic
constraints on which examples may be
considered. This is used to narrow down the
search space from all the examples to a much
smaller set. The examples that satisfy these
constraints are matched in detail against the input
feature structure. The detailed match is a
recursive process operating on the two feature
structures that is based on costs for inserting,
deleting, or altering features, and on certain
constraints for particular features. Lexical
similarity is calculated from the thesaurus on the
basis of the information content of the thesaurus
nodes.
During example matching, the input feature
structure is aligned with the example feature
structure. The alignment information is used by
the transfer procedure to handle differences
between the input and the example. For example,
if the input contains grammatical features,
modifiers, adjuncts, or sub-constituents that are
not in the examples, then they are transferred to
the target-language representation. Similarly, if
the example feature structure contains
information that is not present in the input, then
the transfer procedure deletes the relevant
information.
</bodyText>
<sectionHeader confidence="0.89325" genericHeader="method">
3. Example Database
</sectionHeader>
<bodyText confidence="0.999941111111111">
The example database contains a large set of
translation examples represented as pairs of
typed feature structures in the source and target
languages. Using a Treebanking tool, the
examples are disambiguated, and indices that
show corresponding constituents are added. In
addition to the type and complexity of the
example feature structures, there are three
methods for identifying the degree of linguistic
</bodyText>
<figure confidence="0.9960885">
source—language feature structures
�
set of constraints
Thesaurus
Example
Matching
Engine
souce—language feature structure
�
the best match pair of feature structure
�
alignment information
</figure>
<figureCaption confidence="0.999981">
Figure 2: Architecture of the Example Matching Procedure
</figureCaption>
<bodyText confidence="0.999412833333333">
specificity of an example: marked examples,
example indices, and semantic constraints. This
information is used by the transfer procedure and
the matching procedure to select the best example,
using the mechanism of linguistic matching
constraints that was described above.
</bodyText>
<subsectionHeader confidence="0.998413">
3.1. Marked Examples
</subsectionHeader>
<bodyText confidence="0.9999295">
Some of the features that were shown in Section 2
to influence the translation have been
traditionally described as “marked“. Examples
include negation, interrogative, and also the
presence of certain adjuncts. The transfer
procedure regards these examples as more
specific than unmarked examples, and (via the
linguistic constraints passed to the matching
procedure) only allows such examples when
appropriate.
</bodyText>
<subsectionHeader confidence="0.99665">
3.2. Example Indices
</subsectionHeader>
<bodyText confidence="0.9998813125">
Examples can contain two types of indices
linking a source-language sub-feature-structure
with a target-language sub-feature-structure. A
CORRESPOND-INDEX signals that the two
constituents correspond to each other, while a
REPLACE-INDEX signals that two constituents
correspond to each other and can be replaced by
similar constituents.
The absence of such indices in a major argument
phrase (such as the subject or object) indicates
that the example is more specific. A
CORRESPOND-INDEX is more specific than a
REPLACE-INDEX, since a CORRESPOND-
INDEX indicates that although the head of the
constituent allows modifiers, the constituent can
not be substituted. For example, the object the
</bodyText>
<figure confidence="0.9243468">
Cost
Database
Bilingual
Example
Database
</figure>
<bodyText confidence="0.999345571428571">
bucket in the example for the idiom to kick the
bucket does not contain any indices, since the
idiom does not allow substitution or modification.
On the other hand, a heart attack in to have a
heart attack allows modifiers (e.g. a severe heart
attack), so the example for the idiomatic
translation carries a CORRESPOND-INDEX.
</bodyText>
<subsectionHeader confidence="0.998947">
3.3. Semantic Constraints
</subsectionHeader>
<bodyText confidence="0.999996727272727">
The example database also contains certain
semantic constraints on source-language
sub-feature-structures. When an input feature
structure is matched with such an example, the
matching procedure checks whether the input
satisfies the semantic constraint. If it does, then
that example is preferred over other examples,
since it is more specific than other examples that
do not carry a semantic constraint. On the other
hand, if the input does not match the constraint,
then the match is rejected.
</bodyText>
<subsectionHeader confidence="0.999796">
3.4. Sample Entry
</subsectionHeader>
<bodyText confidence="0.997065">
Figure 3 shows the example pair for the
expressions Can I have your name? &lt;-&gt;�3�4o&apos;pU�_-
� 90 V, `, -;� 1 t 75a (o-namae-wo o-negai
dekimasu-ka). This example has a number of
marked features. The mood of the sentence is
yes-no question, the modal auxiliary can is
present, and the subject does not contain an index.
These features are used by the transfer procedure
to ensure that the example is only used to
translate appropriate input.
</bodyText>
<sectionHeader confidence="0.550255" genericHeader="evaluation">
4. Implementation and Evaluation
</sectionHeader>
<bodyText confidence="0.999934428571429">
A prototype implementation of this translation
method has been created by the Sony USRL
Speech Translation group (Franz et al. 200b). The
prototype was developed for the “overseas travel
domain”, which includes utterances and
expressions useful for travel between e.g. Japan
and the USA.
</bodyText>
<subsectionHeader confidence="0.99879">
4.1. Lexicon and Example Database
</subsectionHeader>
<bodyText confidence="0.986482666666667">
The English-to-Japanese translation system
includes an English dictionary with 6483 unique
English root forms, and the English-to-Japanese
example database contains 14,281 separate
example pairs. These entries consist of
constructions of various sizes, ranging from
</bodyText>
<table confidence="0.881828962962963">
HEAD ROOT &amp;quot;I&amp;quot;
THES HUM-INDIV
PRESON FIRST
CASE NOM
TYPE PRONOUNP
HEAD [ ROOT &amp;quot;have&amp;quot; ]
REPLACE-INDEX 1
GEN-NP HEAD [ ROOT &amp;quot;your&amp;quot; ]
PERSON SECOND
CASE GEN
TYPE PRONOUNP
HEAD ROOT &amp;quot;name&amp;quot;
THES NAME
TYPE SIMPLE-NP
TYPE VERBAL-VP
MODAL [HEAD [ROOT &amp;quot;can&amp;quot; ] ]
TYPE SENT
S-TYPE YN-QUESTION
VP VP
HONORIFIC HUMBLE
TYPE VERB
TYPE VERBAL-VP
VERB [ HEAD [ ROOT &amp;quot; Ci &amp;quot; ] ]
VP-SUFFIX-TYPE POTENTIAL
TYPE VP-SUFFIXP
TYPE SENT
S-TYPE YN-QUESTION
</table>
<figureCaption confidence="0.9599455">
Figure 3: Excerpt from the example database entry for
Can I have your name?
</figureCaption>
<bodyText confidence="0.999907833333333">
conjoined sentences to individual words. For
some example pairs, the system automatically
extracts corresponding parts from the source and
target expressions, and creates a new example
pair. As a result, the system has a total of 24,072
example database entries available.
</bodyText>
<subsectionHeader confidence="0.999609">
4.2. Development Set
</subsectionHeader>
<bodyText confidence="0.999663266666667">
We developed, tested, and refined the system
until all of the main predicates of the 615
development set sentences with to have were
translated correctly. For this, the system used 129
distinct example pairs with the main verb to have.
Many example pairs encode a specific
translation: 68 out of the 129 entries were used to
translate only one expression from the
development set. On the other hand, some entries
are very general, and are used to translate a large
number of expressions. The most frequently
used entry is Do you have sushi? &lt;-&gt; tUffik
91t75a (sushi-ga arimasu-ka), which is used
to translate 113 out of the 615 development set
expressions.
</bodyText>
<figure confidence="0.987707058823529">
E
J
VP
OBJ
SUBJ
REPLACE-INDEX 1
PREFIX HEAD [ROOT &amp;quot;N&amp;quot;]
TYPE PREFIX
HEAD ROOT &amp;quot;$RMf&amp;quot;
THES NAME
TYPE SIMPLE-NP
CASE-PART HEAD [ ROOT &amp;quot;&apos;,&apos; &amp;quot; ]
WO-NP
PREFIX HEAD [ROOT &amp;quot;N&amp;quot;]
HEAD ROOT &amp;quot;1113&amp;quot;
C-TYPE WA
VERB
</figure>
<subsectionHeader confidence="0.997818">
4.3. Linguistic Transfer
</subsectionHeader>
<bodyText confidence="0.999660444444444">
The transfer grammar contains 153 context-free
rules. Each rule includes a rule-body with GPL
statements, which can include calls to the
example matching procedure, and calls to
sub-transfer rules. To translate the 615
expression in the to have development set, the
system performed an average of 3.4
match-and-transfer steps. (In many cases, more
than one transfer path was pursued.) Only 26 out
of the 615 expressions were translated with only
one match-and-transfer step. Examples of such
expressions include Have a good one! and You
can have it. At the other extreme, the maximum
number of match-and-transfer steps required to
translate a single input expression was 9. One of
the expressions that required 9
match-and-transfer steps was The double on the
third floor has a really nice view of the ocean.
</bodyText>
<subsectionHeader confidence="0.984159">
4.4. Evaluation
</subsectionHeader>
<bodyText confidence="0.99401675">
The system was evaluated using a new corpus of
unseen expressions with the verb to have. The
evaluation data was collected from three different
travel phrase books published by Barron, Berlitz,
and Lonely Planet. The English expressions
containing to have as a regular verb (and have got
as a main predicate) were manually extracted
from the phrase books. There were 405 unique
expressions with have in the resulting evaluation
corpus, with an average of 5.5 words. The
evaluation corpus was translated by the
translation system, and each of the output
expressions was examined and manually
categorized according to its translation quality.
The result is shown in the table below:
.
</bodyText>
<table confidence="0.960556">
Flawless Translations 351 86.7%
Incomplete Translations 48 11.8%
due to OOV
Wrong Translations 6 1.5%
Total 405 100%
</table>
<bodyText confidence="0.980032">
The category “flawless translation” refers to
translations without any obvious flaws or
problems. “Incomplete translations due to OOV”
refers to translations where the main predicate
was correctly translated, but due to some
out-of-vocabulary (OOV) nouns or modifiers,
parts of the source-language input words were
carried through to the target language expression.
The category “wrong translation” refers to
translations where the main predicate is
slated, with or without
out-of-vocabulary words.
</bodyText>
<subsectionHeader confidence="0.934608">
4.5. Discussion
</subsectionHeader>
<bodyText confidence="0.851272">
predicates in Japan
ese, but which were not
covered in the example database. Examples of
these include the following :
incorrectly tran
</bodyText>
<figure confidence="0.963748545454545">
Input:
got a nosebleed.
Output:
hanaji-ga ari-masu
nosebleed-NOM exist
Appropriate Translation:
I’ve
efIJab9��
ef20h �1*&apos;91_
hanaji-ga dete-imasu
nosebleed-NOM come out-ST
</figure>
<bodyText confidence="0.9224975">
mark specificity of example entri
es are
applicable to expressions with other common
verbs besides have.
</bodyText>
<subsectionHeader confidence="0.951655">
4.6. Future Work
</subsectionHeader>
<bodyText confidence="0.9999481875">
modifiers can be treated across different support
verb constructions.
Some of the wrong translations are due to
ambiguities in the object noun phrase, such as a
fall in My child has had a fall, which the system
translated as watashi-no kodomo-wa aki-ga
arimashita (meaning My child had an autum).
There were also a number of expressions that
should have been translated into different
The evaluation shows that the information-based
translation method works reliably for translating
short, single-clause utterances. In support of the
generality of this method, we found that
translation accuracy could be improved by
adding more examples, and that the features that
One difficult problem remains in the treatment of
support verb constructions. When the object has
a modifier, the modifier has to be transferred as a
verbal modifier in the target language if the target
language requires a single verb construction. For
example, to have a close look is translated as to
look closely, and to have another look is
translated as to look again. There are, however,
not enough data in the development set to draw
any conclusions about how general these
One hypothesis is that there are different degrees
of proximity between the support verb and the
object noun phrase. In some cases, there might
be only one fixed phrase to be interpreted as the
support
verb construction, while other cases may
allow many different modifiers for the object
noun phrase. This is suggested by the case of to
have a seat in the development set. This phrase
allows the interpretation of to sit only if the
object noun phrase is exactly a seat. The
expression to have another seat cannot be
translated as to sit again, but more like for
another seat to exist. Further analysis of support
verb construction data, including instances with
other verbs besides have, will be necessary to
determine how these constructions can best be
handled in the current framework.
Another avenue for future work is the use of
Machine Learning techniques to select linguistic
features, and statistical methods (such as
loglinear models) to model the effect of feature
combinations.
</bodyText>
<sectionHeader confidence="0.847248" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999995736842105">
The approach described in this paper is based on
the conviction that natural language transfer must
be driven by qualitative, linguistic information.
The analysis of the problem of translating one
construction from English to Japanese has shown
that a significant amount of linguistic
information is necessary for achieving
high-quality translation of something as simple
as single-clause input. The transfer method that
this paper described as one possible solution can
integrate translation examples with linguistic
rules and constraints in an effective manner.
The linguistic information used in this approach
is general and domain-independent;
domain-specific translation knowledge is
confined to the example database. This modular
system architecture presents significant
advantages for developing, maintaining, and
extending a practical machine translation system.
</bodyText>
<sectionHeader confidence="0.988143" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999865">
I would like to thank my advisor Prof. Jun’ichi
Tsujii, my colleagues at Sony USRL in
California, my colleagues at Sony in Tokyo, and
the anonymous reviewers of this paper.
</bodyText>
<sectionHeader confidence="0.98513" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999923254901961">
Duan, L., A. Franz and K. Horiguchi (2000) “Practical
Spoken Language Translation Using Compiled
Feature Structure Grammars”, in Proceedings of
International Conference of Spoken Language
Processing (ICSLP-2000), Beijing, China.
Franz, A., K. Horiguchi and L. Duan (2000a) “An
Imperative Programming Language for Spoken
Language Translation”, in Proceedings of
International Conference of Spoken Language
Processing (ICSLP-2000), Beijing, China.
Franz, A., K. Horiguchi, L. Duan, D. Ecker, E. Koontz
and K. Uchida (2000b) “An Integrated Architecture
for Example-based Translation”, in Proceedings of
the 18th International Conference on Computational
Linguistics (COLING-2000), Saabrucken,
Germany.
Furuse, O. and H. Iida (1996) “Incremental
translation utilizing constituent-boundary patterns”,
in Proceedings of COLING-96, pages 412-417.
Horiguchi, K. (2000) Integrating Linguistic
Information into Example-based Machine
Translation, Ph.D. thesis, University of Manchester
Institute of Science and Technology.
Maruyama, H. and H. Watanabe (1992) “Tree cover
search algorithm for example-based translation”, in
Proceedings of the Fourth International Conference
on Theoretical and Methodological Issues in
Machine Translation (TMI-92), Montreal, pages
173-185.
Nagao, M. (1984) “A framework of a Machine
Translation between Japanese and English by
analogy principle”, in Artificial and Human
Intelligence, A. Elithorn and R. Banerji (eds.),
North Holland, pages 173—180.
Sato, S. and M. Nagao (1990) “Toward
memory-based translation”, in Proceedings of
COLING-90, vol. 3, Helsinki, Finland, pages
247—252.
Sumita, E., O. Furuse, and H. Iida (1993) “An
example-based disambiguation of prepositional
phrase attachment”, in Proceedings of the Fifth
International Conference on Theoretical and
Methodological Issues in Machine Translation
(TMI-93), Kyoto, pages 80-91.
Watanabe, H. (1992) “A similarity-driven transfer
system”, in Proceedings of COLING-92, Nantes,
France, pages 770-776.
Watanabe, H. and K. Takeda (1998) “A pattern-based
Machine Translation system extended by
example-based processing”, in Proceedings of
ACL-COLING-98, pages 1369-1373.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.730763">
<title confidence="0.998446">Information-based Machine Translation</title>
<author confidence="0.762126">Keiko</author>
<affiliation confidence="0.958559">Spoken Language Technology, Sony US Research</affiliation>
<address confidence="0.980951">3300 Zanker San Jose, CA</address>
<email confidence="0.999554">keiko@slt.sel.sony.com</email>
<abstract confidence="0.999470769230769">This paper describes an approach to Machine Translation that places linguistic information at its foundation. The difficulty of translation from English to Japanese is illustrated with data that shows the influence of various linguistic contextual factors. Next, a method for natural language transfer is presented that integrates translation examples (represented as typed feature structures with source-target indices) with linguistic rules and constraints. The method has been implemented, and the results of an evaluation are presented.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Duan</author>
<author>A Franz</author>
<author>K Horiguchi</author>
</authors>
<title>Practical Spoken Language Translation Using Compiled Feature Structure Grammars”,</title>
<date>2000</date>
<booktitle>in Proceedings of International Conference of Spoken Language Processing (ICSLP-2000),</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="13113" citStr="Duan, et al. 2000" startWordPosition="1951" endWordPosition="1954">fer procedure and the example matching procedure. This is illustrated in Figure 1. The input to this component is the source-language typed feature structure; this is created by an analysis component that is not described further here. Similarly, the output of the transfer component is a target-language typed feature structure, from which the target-language expression is generated by the generation component (also not described further). 2.2. Linguistic Transfer The linguistic transfer procedure is implemented as a rewrite-grammar using the special-purpose Grammar Programming Language (GPL) (Duan, et al. 2000, Franz, et al. 2000a). The general role of the transfer grammar is to operate on the input feature structure in a recursive manner, and to perform source-to-target transfer by invoking the example matching procedure, and by using the translation examples to construct a target-language feature structure. The transfer grammar implements the principle of ”large to small” in covering the input feature structure. When the transfer procedure invokes the example matching procedure, it implements the principle of “specific to general”. Since the linguistic features interact with each other when they </context>
</contexts>
<marker>Duan, Franz, Horiguchi, 2000</marker>
<rawString>Duan, L., A. Franz and K. Horiguchi (2000) “Practical Spoken Language Translation Using Compiled Feature Structure Grammars”, in Proceedings of International Conference of Spoken Language Processing (ICSLP-2000), Beijing, China.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Franz</author>
<author>K Horiguchi</author>
<author>L Duan</author>
</authors>
<title>(2000a) “An Imperative Programming Language for Spoken Language Translation”,</title>
<booktitle>in Proceedings of International Conference of Spoken Language Processing (ICSLP-2000),</booktitle>
<location>Beijing, China.</location>
<marker>Franz, Horiguchi, Duan, </marker>
<rawString>Franz, A., K. Horiguchi and L. Duan (2000a) “An Imperative Programming Language for Spoken Language Translation”, in Proceedings of International Conference of Spoken Language Processing (ICSLP-2000), Beijing, China.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Franz</author>
<author>K Horiguchi</author>
<author>L Duan</author>
<author>D Ecker</author>
<author>E Koontz</author>
<author>K Uchida</author>
</authors>
<title>(2000b) “An Integrated Architecture for Example-based Translation”,</title>
<booktitle>in Proceedings of the 18th International Conference on Computational Linguistics (COLING-2000),</booktitle>
<location>Saabrucken, Germany.</location>
<marker>Franz, Horiguchi, Duan, Ecker, Koontz, Uchida, </marker>
<rawString>Franz, A., K. Horiguchi, L. Duan, D. Ecker, E. Koontz and K. Uchida (2000b) “An Integrated Architecture for Example-based Translation”, in Proceedings of the 18th International Conference on Computational Linguistics (COLING-2000), Saabrucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Furuse</author>
<author>H Iida</author>
</authors>
<title>Incremental translation utilizing constituent-boundary patterns”,</title>
<date>1996</date>
<booktitle>in Proceedings of COLING-96,</booktitle>
<pages>412--417</pages>
<marker>Furuse, Iida, 1996</marker>
<rawString>Furuse, O. and H. Iida (1996) “Incremental translation utilizing constituent-boundary patterns”, in Proceedings of COLING-96, pages 412-417.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Horiguchi</author>
</authors>
<title>Integrating Linguistic Information into Example-based Machine Translation,</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Manchester Institute of Science and Technology.</institution>
<marker>Horiguchi, 2000</marker>
<rawString>Horiguchi, K. (2000) Integrating Linguistic Information into Example-based Machine Translation, Ph.D. thesis, University of Manchester Institute of Science and Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Maruyama</author>
<author>H Watanabe</author>
</authors>
<title>Tree cover search algorithm for example-based translation”,</title>
<date>1992</date>
<booktitle>in Proceedings of the Fourth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-92),</booktitle>
<pages>173--185</pages>
<location>Montreal,</location>
<marker>Maruyama, Watanabe, 1992</marker>
<rawString>Maruyama, H. and H. Watanabe (1992) “Tree cover search algorithm for example-based translation”, in Proceedings of the Fourth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-92), Montreal, pages 173-185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Nagao</author>
</authors>
<title>A framework of a Machine Translation between Japanese and English by analogy principle”,</title>
<date>1984</date>
<booktitle>in Artificial and Human Intelligence,</booktitle>
<pages>173--180</pages>
<editor>A. Elithorn and R. Banerji (eds.), North Holland,</editor>
<marker>Nagao, 1984</marker>
<rawString>Nagao, M. (1984) “A framework of a Machine Translation between Japanese and English by analogy principle”, in Artificial and Human Intelligence, A. Elithorn and R. Banerji (eds.), North Holland, pages 173—180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sato</author>
<author>M Nagao</author>
</authors>
<title>Toward memory-based translation”,</title>
<date>1990</date>
<booktitle>in Proceedings of COLING-90,</booktitle>
<volume>3</volume>
<pages>247--252</pages>
<location>Helsinki, Finland,</location>
<marker>Sato, Nagao, 1990</marker>
<rawString>Sato, S. and M. Nagao (1990) “Toward memory-based translation”, in Proceedings of COLING-90, vol. 3, Helsinki, Finland, pages 247—252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Sumita</author>
<author>O Furuse</author>
<author>H Iida</author>
</authors>
<title>An example-based disambiguation of prepositional phrase attachment”,</title>
<date>1993</date>
<booktitle>in Proceedings of the Fifth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-93), Kyoto,</booktitle>
<pages>80--91</pages>
<marker>Sumita, Furuse, Iida, 1993</marker>
<rawString>Sumita, E., O. Furuse, and H. Iida (1993) “An example-based disambiguation of prepositional phrase attachment”, in Proceedings of the Fifth International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-93), Kyoto, pages 80-91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Watanabe</author>
</authors>
<title>A similarity-driven transfer system”,</title>
<date>1992</date>
<booktitle>in Proceedings of COLING-92,</booktitle>
<pages>770--776</pages>
<location>Nantes, France,</location>
<marker>Watanabe, 1992</marker>
<rawString>Watanabe, H. (1992) “A similarity-driven transfer system”, in Proceedings of COLING-92, Nantes, France, pages 770-776.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Watanabe</author>
<author>K Takeda</author>
</authors>
<title>A pattern-based Machine Translation system extended by example-based processing”,</title>
<date>1998</date>
<booktitle>in Proceedings of ACL-COLING-98,</booktitle>
<pages>1369--1373</pages>
<marker>Watanabe, Takeda, 1998</marker>
<rawString>Watanabe, H. and K. Takeda (1998) “A pattern-based Machine Translation system extended by example-based processing”, in Proceedings of ACL-COLING-98, pages 1369-1373.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>