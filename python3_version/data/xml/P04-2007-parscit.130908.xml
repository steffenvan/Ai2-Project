<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.239805">
<title confidence="0.997614">
Towards a Semantic Classification of Spanish Verbs Based on
Subcategorisation Information
</title>
<author confidence="0.995108">
Eva Esteve Ferrer
</author>
<affiliation confidence="0.993166">
Department of Informatics
University of Sussex
</affiliation>
<address confidence="0.9966">
Brighton, BN1 9QH, UK
</address>
<email confidence="0.999754">
E.Esteve-Ferrer@sussex.ac.uk
</email>
<sectionHeader confidence="0.997401" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999866416666667">
We present experiments aiming at an automatic
classification of Spanish verbs into lexical semantic
classes. We apply well-known techniques that have
been developed for the English language to Span-
ish, proving that empirical methods can be re-used
through languages without substantial changes in
the methodology. Our results on subcategorisation
acquisition compare favourably to the state of the art
for English. For the verb classification task, we use
a hierarchical clustering algorithm, and we compare
the output clusters to a manually constructed classi-
fication.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999128">
Lexical semantic classes group together words that
have a similar meaning. Knowledge about verbs
is especially important, since verbs are the primary
means of structuring and conveying meaning in sen-
tences. Manually built semantic classifications of
English verbs have been used for different applica-
tions such as machine translation (Dorr, 1997), verb
subcategorisation acquisition (Korhonen, 2002a) or
parsing (Schneider, 2003). (Levin, 1993) has estab-
lished a large-scale classification of English verbs
based on the hypothesis that the meaning of a verb
and its syntactic behaviour are related, and there-
fore semantic information can be induced from the
syntactic behaviour of the verb. A classification
of Spanish verbs based on the same hypothesis has
been developed by (V´azquez et al., 2000). But man-
ually constructing large-scale verb classifications is
a labour-intensive task. For this reason, various
methods for automatically classifying verbs using
machine learning techniques have been attempted
((Merlo and Stevenson, 2001), (Stevenson and Joa-
nis, 2003), (Schulte im Walde, 2003)).
In this article we present experiments aiming at
automatically classifying Spanish verbs into lexi-
cal semantic classes based on their subcategorisa-
tion frames. We adopt the idea that a description of
verbs in terms of their syntactic behaviour is useful
for acquiring their semantic properties. The classi-
fication task at hand is achieved through a process
that requires different steps: we first extract from a
partially parsed corpus the probabilities of the sub-
categorisation frames for each verb. Then, the ac-
quired probabilities are used as features describing
the verbs and given as input to an unsupervised clas-
sification algorithm that clusters together the verbs
according to the similarity of their descriptions. For
the task of acquiring verb subcategorisation frames,
we adapt to the specificities of the Spanish language
well-known techniques that have been developed
for English, and our results compare favourably to
the sate of the art results obtained for English (Ko-
rhonen, 2002b). For the verb classification task, we
use a hierarchical clustering algorithm, and we com-
pare the output clusters to a manually constructed
classification developed by (V´azquez et al., 2000).
</bodyText>
<sectionHeader confidence="0.8497475" genericHeader="method">
2 Acquisition of Spanish
Subcategorisation Frames
</sectionHeader>
<bodyText confidence="0.999945">
Subcategorisation frames encode the information
of how many arguments are required by the verb,
and of what syntactic type. Acquiring the subcat-
egorization frames for a verb involves, in the first
place, distinguishing which constituents are its ar-
guments and which are adjuncts, elements that give
an additional piece of information to the sentence.
Moreover, sentences contain other constituents that
are not included in the subcategorisation frames of
verbs: these are sub-constituents that are not struc-
turally attached to the verb, but to other constituents.
</bodyText>
<subsectionHeader confidence="0.997118">
2.1 Methodology and Materials
</subsectionHeader>
<bodyText confidence="0.999850770833334">
We experiment our methodology on two corpora of
different sizes, both consisting of Spanish newswire
text: a 3 million word corpus, hereafter called small
corpus, and a 50 million word corpus, hereafter
called large corpus. They are both POS tagged
and partially parsed using the MS-analyzer, a par-
tial parser for Spanish that includes named entities
recognition (Atserias et al., 1998).
In order to collect the frequency distributions
of Spanish subcategorisation frames, we adapt a
methodology that has been developed for English
to the specificities of the Spanish language ((Brent,
1993), (Manning, 1993), (Korhonen, 2002b)). It
consists in extracting from the corpus pairs made
of a verb and its co-occurring constituents that are a
possible pattern of a frame, and then filtering out
the patterns that do not have a probability of co-
occurrence with the verb high enough to be consid-
ered its arguments.
We establish a set of 11 possible Spanish subcat-
egorisation frames. These are the plausible combi-
nations of a maximum of 2 of the following con-
stituents: nominal phrases, prepositional phrases,
temporal sentential clauses, gerundive sentential
clauses, infinitival sentential clauses, and infinitival
sentential clauses introduced by a preposition. The
individual prepositions are also taken into account
as part of the subcategorisation frame types.
Adapting a methodology that has been thought
for English presents a few problems, because En-
glish is a language with a strong word order con-
straint, while in Spanish the order of constituents is
freer. Although the unmarked order of constituents
is Subject Verb Object with the direct object pre-
ceding the indirect object, in naturally occurring
language the constituents can be moved to non-
canonical positions. Since we extract the patterns
from a partially parsed corpus, which has no infor-
mation on the attachment or grammatical function
of the constituents, we have to take into account
that the extraction is an approximation. There are
various phenomena that can lead us to an erroneous
extraction of the constituents. As an illustrative ex-
ample, in Spanish it is possible to have an inversion
in the order of the objects, as can be observed in
sentence (1), where the indirect object a Straw (“to
Straw”) precedes the direct object los alegatos (“the
pleas”).
</bodyText>
<listItem confidence="0.779243">
(1) El gobierno chileno presentar´a hoy a Straw
los alegatos (... ).
</listItem>
<bodyText confidence="0.993227745762712">
“The Chilean government will present today to
Straw the pleas (... )”.
Dealing with this kind of phenomenon introduces
some noise in the data. Matching a pattern for a
subcategorisation frame from sentence (1), for ex-
ample, we would misleadingly induce the pattern
[ PP(a)] for the verb presentar, “present”, when
in fact the correct pattern for this sentence is [ NP
PP(a)].
The solution we adopt for dealing with the vari-
ations in the order of constituents is to take into
account the functional information provided by cl-
itics. Clitics are unstressed pronouns that refer to
an antecedent in the discourse. In Spanish, clitic
pronouns can only refer to the subject, the direct
object, or the indirect object of the verb, and they
can in most cases be disambiguated taking into ac-
count their agreement (in person, number and gen-
der) with the verb. When we find a clitic pronoun in
a sentence, we know that an argument position is al-
ready filled by it, and the rest of the constituents that
are candidates for the position are either discarded
or moved to another position. Sentence (2) shows
an example of how the presence of clitic pronouns
allows us to transform the patterns extracted. The
sentence would normally match with the frame pat-
tern [ PP(por)], but the presence of the clitic (which
has the form le) allows us to deduce that the sen-
tence contains an indirect object, realised in the sub-
categorisation pattern with a prepositional phrase
headed by a in second position. Therefore, we look
for the following nominal phrase, la aparici´on del
cad´aver, to fill the slot of the direct object, that oth-
erwise would have not been included in the pattern.
(2) Por la tarde, agentes del cuerpo nacional
de policia le comunicaron por tel´efono la
aparici´on del cad´aver.
“In the afternoon, agents of the national police
clitic IO reported by phone the apparition of
the corpse.”.
The collection of pairs verb + pattern obtained
with the method described in the last section needs
to be filtered out, because we may have extracted
constituents that are in fact adjuncts, or elements
that are not attached to the verb, or errors in the
extraction process. We filter out the spurious pat-
terns with a Maximum Likelihood Estimate (MLE),
a method proposed by (Korhonen, 2002b) for this
task. MLE is calculated as the ratio of the frequency
of + over the frequency of .
Pairs of verb+pattern that do not have a probabil-
ity of co-occurring together higher than a certain
threshold are filtered out. The threshold is deter-
mined empirically using held-out data (20% of the
total of the corpus), by choosing from a range of val-
ues between 0.02 and 0.1 the value that yields better
results against a held-out gold standard of 10 verbs.
In our experiments, this method yields a threshold
value of 0.05.
</bodyText>
<subsectionHeader confidence="0.995883">
2.2 Experimental Evaluation
</subsectionHeader>
<bodyText confidence="0.9998795">
We evaluate the obtained subcategorisation frames
in terms of precision and recall compared to a gold
</bodyText>
<table confidence="0.9993285">
No Prep. Groups Preposition Groups
Corpus Prec Rec F Prec Rec F
Small 65 62 63 63 61 62
Baseline 25 78 38 31 82 45
Large 70 60 65 71 61 66
Baseline 8 96 14 8 96 14
</table>
<tableCaption confidence="0.971603">
Table 1: Results for the acquisition of subcategori-
sation frames.
</tableCaption>
<bodyText confidence="0.976457295454545">
standard. The gold standard is manually constructed
for a sample of 41 verbs. The verb sample is chosen
randomly from our data with the condition that both
frequent and infrequent verbs are represented, and
that we have examples of all our subcategorisation
frame types. We perform experiments on two cor-
pora of different sizes, expecting that the differences
in the results will show that a large amount of data
does significantly improve the performance of any
given system without any changes in the methodol-
ogy. After the extraction process, the small corpus
consists of 58493 pairs of verb+pattern, while the
large corpus contains 1253188 pairs.&apos; Since we in-
clude in our patterns the heads of the prepositional
phrases, the corpora contain a large number of pat-
tern types (838 in the small corpora, and 2099 in
the large corpora). We investigate grouping seman-
tically equivalent prepositions together, in order to
reduce the number of pattern types, and therefore
increment the probabilities on the patterns. The
preposition groups are established manually.
Table 1 shows the average results obtained on the
two different corpora for the 41 test verbs. The base-
lines are established by considering all the frame
patterns obtained in the extraction process as cor-
rect frames. The experiments on the large corpus
give better results than the ones on the small one,
and grouping similar prepositions together is useful
only on the large corpus. This is probably due to the
fact that the small corpus does not suffer from a too
large number of frame types, and the effect of the
groupings cannot be noticed. The F measure value
of 66% reported on the third line of table 1, ob-
tained on the large corpus with preposition groups,
compares favourably to the results reported on (Ko-
rhonen, 2002b) for a similar experiment on English
subcategorization frames, in which an F measure of
65.2 is achieved.
&apos;In all experiments, we post-process the data by eliminating
prepositional constituents in the second position of the pattern
that are introduced with the preposition de, “of”. This is moti-
vated by the observation that in 96.8% of the cases this prepo-
sition is attached to the preceding constituent, and not to the
verb.
</bodyText>
<sectionHeader confidence="0.980057" genericHeader="method">
3 Clustering Verbs into Classes
</sectionHeader>
<bodyText confidence="0.999996217391304">
We use a bottom-up hierarchical clustering algo-
rithm to group together 514 verbs into K classes.
The algorithm starts by finding the similarities be-
tween all the possible pairs of objects in the data ac-
cording to a similarity measure S. After having es-
tablished the distance between all the pairs, it links
together the closest pairs of objects by a linkage
method L, forming a binary cluster. The linking
process is repeated iteratively over the newly cre-
ated clusters until all the objects are grouped into
one cluster. K, S and L are parameters that can be
set for the clustering. For the similarity measure
S, we choose the Euclidean distance. For the link-
age method L, we choose the Ward linkage method
(Ward, 1963). Our choice of the parameter settings
is motivated by the work of (Stevenson and Joanis,
2003). Applying a clustering method to the verbs
in our data, we expect to find a natural division of
the data that will be in accordance with the classi-
fication of verbs that we have set as our target clas-
sification. We perform different experiments with
different values for K in order to test which of the
different granularities yields better results.
</bodyText>
<subsectionHeader confidence="0.998773">
3.1 The Target Classification
</subsectionHeader>
<bodyText confidence="0.999865458333333">
In order to be able to evaluate the clusters out-
put by the algorithm, we need to establish a man-
ual classification of sample verbs. We assume the
manual classification of Spanish verbs developed
by (V´azquez et al., 2000). In their classification,
verbs are organised on the basis of meaning com-
ponents, diathesis alternations and event structure.
They classify a large number of verbs into three
main classes (Trajectory, Change and Attitude) that
are further subdivided into a total of 31 subclasses.
Their classification follows the same basic hypothe-
ses as Levin’s, but the resulting classes differ in
some important aspects. For example, the Trajec-
tory class groups together Levin’s Verbs of Motion
(move), Verbs of Communication (tell) and verbs of
Change of Possession (give), among others. Their
justification for this grouping is that all the verbs
in this class have a Trajectory meaning compo-
nent, and that they all undergo the Underspecifica-
tion alternation (in Levin’s terminology, the Loca-
tive Preposition Drop and the Unspecified Object
alternations). The size of the classes at the lower
level of the classification hierarchy varies from 2 to
176.
</bodyText>
<subsectionHeader confidence="0.989996">
3.2 Materials
</subsectionHeader>
<bodyText confidence="0.999989633333333">
The input to the algorithm is a description of each
of the verbs in the form of a vector containing the
probabilities of their subcategorisation frames. We
obtain the subcategorisation frames with the method
described in the previous section that gave better re-
sults: using the large corpus, and reducing the num-
ber of frame types by merging individual preposi-
tions into groups. In order to reduce the number
of frame types still further, we only take into ac-
count the ones that occur more than 10 times in
the corpus. In this way, we have a set of 66 frame
types. Moreover, for the purpose of the classifica-
tion task, the subcategorisation frames are enhanced
with extra information that is intended to reflect
properties of the verbs that are relevant for the target
classification. The target classification is based on
three aspects of the verb properties: meaning com-
ponents, diathesis alternations, and event structure,
but the information provided by subcategorisation
frames only reflects on the second of them. We
expect to provide some information on the mean-
ing components participating in the action by taking
into account whether subjects and direct objects are
recognised by the partial parser as named entities.
Then, the possible labels for these constituents are
“no NE”, “persons”, “locations”, and “institutions”.
We introduce this new feature by splitting the proba-
bility mass of each frame among the possible labels,
according to their frequencies. Now, we have a total
of 97 features for each verb of our sample.
</bodyText>
<subsectionHeader confidence="0.999745">
3.3 Clustering Evaluation
</subsectionHeader>
<bodyText confidence="0.998980625">
Evaluating the results of a clustering experiment is a
complex task because ideally we would like the out-
put to fulfil different goals. One the one hand, the
clusters obtained should reflect a good partition of
the data, yielding consistent clusters. On the other
hand, the partition of the data obtained should be
as similar as possible to the manually constructed
classification, the gold standard. We use the Silhou-
ette measure (Kaufman and Rousseeuw, 1990) as an
indication of the consistency of the obtained clus-
ters, regardless of the division of the data in the gold
standard. For each clustering experiment, we calcu-
late the mean of the silhouette value of all the data
points, in order to get an indication of the overall
quality of the clusters created. The main difficulty in
evaluating unsupervised classification tasks against
a gold standard lies in the fact that the class labels
of the obtained clusters are unknown. Therefore, the
evaluation is done according to the pairs of objects
that the two groups have in common. (Schulte im
Walde, 2003) reports that the evaluation method that
is most appropriate to the task of unsupervised verb
classification is the Adjusted Rand measure. It gives
a value of 1 if the two classifications agree com-
</bodyText>
<table confidence="0.9990228">
No Named Entities
Task Mean Sil Baseline Radj
3-way 0.37 0 0.001
15-way 0.37 0 0.040
31-way 0.27 0 0.070
</table>
<tableCaption confidence="0.9278225">
Table 2: Clustering evaluation for the experiment
without Named Entities
</tableCaption>
<table confidence="0.9993754">
Named Entities
Task Mean Sil Baseline Radj
3-way 0.37 0 0.01
15-way 0.31 0 0.07
31-way 0.22 0 0.03
</table>
<tableCaption confidence="0.956867">
Table 3: Clustering evaluation for the experiment
with Named Entities
</tableCaption>
<bodyText confidence="0.9815425">
pletely in which pairs of objects are clustered to-
gether and which are not, while complete disagree-
ment between two classifications yields a value of
-1.
</bodyText>
<subsectionHeader confidence="0.994227">
3.4 Experimental Results
</subsectionHeader>
<bodyText confidence="0.999993490196079">
We perform various clustering experiments in or-
der to test, on the one hand, the usefulness of our
enhanced subcategorisation frames. On the other
hand, we intend to discover which is the natural par-
tition of the data that best accommodates our target
classification. The target classification is a hierar-
chy of three levels, each of them dividing the data
into 3, 15, or 31 levels. For this reason, we ex-
periment on 3, 15, and 31 desired output clusters,
and evaluate them on each of the target classifica-
tion levels, respectively.
Table 2 shows the evaluation results of the clus-
tering experiment that takes as input bare subcate-
gorisation frames. Table 3 shows the evaluation re-
sults of the experiment that includes named entity
recognition in the features describing the verbs. In
both tables, each line reports the results of a clas-
sification task. The average Silhouette measure is
shown in the second column. We can observe that
the best classification tasks in terms of the Silhou-
ette measure are the 3-way and 15-way classifica-
tions. The baseline is calculated, for each task, as
the average value of the Adjusted Rand measure for
100 random cluster assignations. Although all the
tasks perform better than the baseline, the increase
is so small that it is clear that some improvements
have to be done on the experiments. According
to the Adjusted Rand measure, the clustering algo-
rithm seems to perform better in the tasks with a
larger number of classes. On the other hand, the en-
hanced features are useful on the 15-way and 3-way
classifications, but they are harmful in the 31-way
classification. In spite of these results, a qualita-
tive observation of the output clusters reveals that
they are intuitively plausible, and that the evalua-
tion is penalised by the fact that the target classes
are of very different sizes. On the other hand, our
data takes into account syntactic information, while
the target classification is not only based on syn-
tax, but also on other aspects of the properties of the
verbs. These results compare poorly to the perfor-
mance achieved by (Schulte im Walde, 2003), who
obtains an Adjusted Rand measure of 0.15 in a sim-
ilar task, in which she classifies 168 German verbs
into 43 semantic verb classes. Nevertheless, our re-
sults are comparable to a subset of experiments re-
ported in (Stevenson and Joanis, 2003), where they
perform similar clustering experiments on English
verbs based on a general description of verbs, ob-
taining average Adjusted Rand measures of 0.04
and 0.07.
</bodyText>
<sectionHeader confidence="0.999137" genericHeader="conclusions">
4 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999990177419355">
We have presented a series of experiments that use
an unsupervised learning method to classify Span-
ish verbs into semantic classes based on subcate-
gorisation information. We apply well-known tech-
niques that have been developed for the English lan-
guage to Spanish, confirming that empirical meth-
ods can be re-used through languages without sub-
stantial changes in the methodology. In the task
of acquiring subcategorisation frames, we achieve
state of the art results. On the contrary, the task
of inducing semantic classes from syntactic infor-
mation using a clustering algorithm leaves room for
improvement. The future work for this task goes on
two directions.
On the one hand, the theoretical basis of the man-
ual verb classification suggests that, although the
syntactic behaviour of verbs is an important crite-
ria for a semantic classification, other properties of
the verbs should be taken into account. Therefore,
the description of verbs could be further enhanced
with features that reflect on meaning components
and event structure. The incorporation of name en-
tity recognition in the experiments reported here is
a first step in this direction, but it is probably a
too sparse feature in the data to make any signif-
icant contributions. The event structure of predi-
cates could be statistically approximated from text
by grasping the aspect of the verb. The aspect of
the verbs could, in turn, be approximated by devel-
oping features that would consider the usage of cer-
tain tenses, or the presence of certain types of ad-
verbs that imply a restriction on the aspect of the
verb. Adverbs such as ”suddenly”, ”continuously”,
”often”, or even adverbial sentences such as ”every
day” give information on the event structure of pred-
icates. As they are a closed class of words, a typol-
ogy of adverbs could be established to approximate
the event structure of the verb (Esteve Ferrer and
Merlo, 2003).
On the other hand, an observation of the verb
clusters output by the algorithm suggests that they
are intuitively more plausible than what the evalua-
tion measures indicate. For the purposes of possi-
ble applications, a hard clustering of verbs does not
seem to be necessary, especially when even man-
ually constructed classifications adopt arbitrary de-
cisions and do not agree with each other: knowing
which verbs are semantically similar to each other in
a more “fuzzy” way might be even more useful. For
this reason, a new approach could be envisaged for
this task, in the direction of the work by (Weeds and
Weir, 2003), by building rankings of similarity for
each verb. For the purpose of evaluation, the gold
standard classification could also be organised in the
form of similarity rankings, based on the distance
between the verbs in the hierarchy. Then, the rank-
ings for each verb could be evaluated. The two di-
rections appointed here, enriching the verb descrip-
tions with new features that grasp other properties
of the verbs, and envisaging a similarity ranking of
verbs instead of a hard clustering, are the next steps
to be taken for this work.
</bodyText>
<sectionHeader confidence="0.997365" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999405666666667">
The realisation of this work was possible thanks to
the funding of the Swiss FNRS project number 11-
65328.01.
</bodyText>
<sectionHeader confidence="0.999473" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999855441176471">
Jordi Atserias, Josep Carmona, Irene Castell´on,
Sergi Cervell, Montserrat Civit, Lluis M`arquez,
M. Antonia Marti, Lluis Padr´o, Roser Placer,
Horacio Rodriguez, Mariona Taul´e, and Jordi
Turmo. 1998. Morphosyntactic analysis and
parsing of unrestricted spanish text. In Proceed-
ings of the First International Conference on
Language Resources and Evaluation (LREC’98),
pages 1267–1272, Granada/Spain.
Michael Brent. 1993. From grammar to lexicon:
Unsupervised learning of lexical syntax. Compu-
tational Linguistics, 19(2):243–262.
Bonnie Dorr. 1997. Large-scale dictionary con-
struction for foreign language tutoring and in-
terlingual machine translation. Machine Transla-
tion, 12(4):1–55.
Eva Esteve Ferrer and Paola Merlo. 2003. Auto-
matic classification of english verbs. Technical
report, Universit´e de Gen`eve.
Leonard Kaufman and Peter J. Rousseeuw. 1990.
Finding Groups in Data - An Introduction to
Cluster Analysis. Probability and Mathematical
Statistics. Jonh Wiley and Sons, Inc., New York.
Anna Korhonen. 2002a. Semantically motivated
subcategorization acquisition. In Proceedings of
the Workshop of the ACL Special Interest Group
on the Lexicon on Unsupervised Lexical Acquisi-
tion, pages 51–58, Philadelphia,PA, July.
Anna Korhonen. 2002b. Subcategorisation Acqui-
sition. Ph.D. thesis, University of Cambridge.
distributed as UCAM-CL-TR-530.
Beth Levin. 1993. English Verb Classes and Alter-
nations. University of Chicago Press, Chicago,
IL.
Christopher Manning. 1993. Automatic acquisition
of a large subcategorization dictionary from cor-
pora. In Proceedings of the 31st Annual Meeting
of the ACL, pages 235–242, Columbus/Ohio.
Paola Merlo and Suzanne Stevenson. 2001. Auto-
matic verb classification based on statistical dis-
tributions of argument structure. Computational
Linguistics, 27(3):373–408.
Gerold Schneider. 2003. A low-complexity, broad
coverage probabilistic dependency parser for en-
glish. In Proceedings of NAACL/HLT 2003 Stu-
dent Session, pages 31–36, Edmonton/Canada.
Sabine Schulte im Walde. 2003. Experiments
on the Automatic Induction of German Se-
mantic Verb Classes. Ph.D. thesis, Institut
fur Maschinelle Sprachverarbeitung, Universitat
Stuttgart. Published as AIMS Report 9(2).
Suzanne Stevenson and Eric Joanis. 2003. Semi-
supervised verb class discovery using noisy fea-
tures. In Proceedings of the Seventh Conference
on Natural Language Learning (CoNLL-2003),
page, Edmonton/Canada.
Gloria V´azquez, Ana Fern´andez, Irene Castell´on,
and M. Antonia Mart´ı. 2000. Clasificaci´on ver-
bal: Alternancias de di´atesis. Quaderns de Sin-
tagma. Universitat de Lleida, 3.
Joe H. Ward. 1963. Hierarchical grouping to opti-
mize an objective function. Journal of the Amer-
ican Statistical Association, 58:236–244.
Julie Weeds and David Weir. 2003. A general
framework for distributional similarity. In Pro-
ceedings of the Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP-
2003), Sapporo/Japan.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.721039">
<title confidence="0.999592">Towards a Semantic Classification of Spanish Verbs Based on Subcategorisation Information</title>
<author confidence="0.99987">Eva Esteve Ferrer</author>
<affiliation confidence="0.9999065">Department of Informatics University of Sussex</affiliation>
<address confidence="0.999898">Brighton, BN1 9QH, UK</address>
<email confidence="0.99906">E.Esteve-Ferrer@sussex.ac.uk</email>
<abstract confidence="0.978385461538462">We present experiments aiming at an automatic classification of Spanish verbs into lexical semantic classes. We apply well-known techniques that have been developed for the English language to Spanish, proving that empirical methods can be re-used through languages without substantial changes in the methodology. Our results on subcategorisation acquisition compare favourably to the state of the art for English. For the verb classification task, we use a hierarchical clustering algorithm, and we compare the output clusters to a manually constructed classification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Jordi Atserias</author>
<author>Josep Carmona</author>
<author>Irene Castell´on</author>
<author>Sergi Cervell</author>
<author>Montserrat Civit</author>
<author>Lluis M`arquez</author>
<author>M Antonia Marti</author>
<author>Lluis Padr´o</author>
<author>Roser Placer</author>
<author>Horacio Rodriguez</author>
<author>Mariona Taul´e</author>
<author>Jordi Turmo</author>
</authors>
<title>Morphosyntactic analysis and parsing of unrestricted spanish text.</title>
<date>1998</date>
<booktitle>In Proceedings of the First International Conference on Language Resources and Evaluation (LREC’98),</booktitle>
<pages>1267--1272</pages>
<marker>Atserias, Carmona, Castell´on, Cervell, Civit, M`arquez, Marti, Padr´o, Placer, Rodriguez, Taul´e, Turmo, 1998</marker>
<rawString>Jordi Atserias, Josep Carmona, Irene Castell´on, Sergi Cervell, Montserrat Civit, Lluis M`arquez, M. Antonia Marti, Lluis Padr´o, Roser Placer, Horacio Rodriguez, Mariona Taul´e, and Jordi Turmo. 1998. Morphosyntactic analysis and parsing of unrestricted spanish text. In Proceedings of the First International Conference on Language Resources and Evaluation (LREC’98), pages 1267–1272, Granada/Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Brent</author>
</authors>
<title>From grammar to lexicon: Unsupervised learning of lexical syntax.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="4325" citStr="Brent, 1993" startWordPosition="639" endWordPosition="640">dology and Materials We experiment our methodology on two corpora of different sizes, both consisting of Spanish newswire text: a 3 million word corpus, hereafter called small corpus, and a 50 million word corpus, hereafter called large corpus. They are both POS tagged and partially parsed using the MS-analyzer, a partial parser for Spanish that includes named entities recognition (Atserias et al., 1998). In order to collect the frequency distributions of Spanish subcategorisation frames, we adapt a methodology that has been developed for English to the specificities of the Spanish language ((Brent, 1993), (Manning, 1993), (Korhonen, 2002b)). It consists in extracting from the corpus pairs made of a verb and its co-occurring constituents that are a possible pattern of a frame, and then filtering out the patterns that do not have a probability of cooccurrence with the verb high enough to be considered its arguments. We establish a set of 11 possible Spanish subcategorisation frames. These are the plausible combinations of a maximum of 2 of the following constituents: nominal phrases, prepositional phrases, temporal sentential clauses, gerundive sentential clauses, infinitival sentential clauses</context>
</contexts>
<marker>Brent, 1993</marker>
<rawString>Michael Brent. 1993. From grammar to lexicon: Unsupervised learning of lexical syntax. Computational Linguistics, 19(2):243–262.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Dorr</author>
</authors>
<title>Large-scale dictionary construction for foreign language tutoring and interlingual machine translation.</title>
<date>1997</date>
<journal>Machine Translation,</journal>
<volume>12</volume>
<issue>4</issue>
<contexts>
<context position="1146" citStr="Dorr, 1997" startWordPosition="160" endWordPosition="161">sults on subcategorisation acquisition compare favourably to the state of the art for English. For the verb classification task, we use a hierarchical clustering algorithm, and we compare the output clusters to a manually constructed classification. 1 Introduction Lexical semantic classes group together words that have a similar meaning. Knowledge about verbs is especially important, since verbs are the primary means of structuring and conveying meaning in sentences. Manually built semantic classifications of English verbs have been used for different applications such as machine translation (Dorr, 1997), verb subcategorisation acquisition (Korhonen, 2002a) or parsing (Schneider, 2003). (Levin, 1993) has established a large-scale classification of English verbs based on the hypothesis that the meaning of a verb and its syntactic behaviour are related, and therefore semantic information can be induced from the syntactic behaviour of the verb. A classification of Spanish verbs based on the same hypothesis has been developed by (V´azquez et al., 2000). But manually constructing large-scale verb classifications is a labour-intensive task. For this reason, various methods for automatically classif</context>
</contexts>
<marker>Dorr, 1997</marker>
<rawString>Bonnie Dorr. 1997. Large-scale dictionary construction for foreign language tutoring and interlingual machine translation. Machine Translation, 12(4):1–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eva Esteve Ferrer</author>
<author>Paola Merlo</author>
</authors>
<title>Automatic classification of english verbs.</title>
<date>2003</date>
<tech>Technical report, Universit´e de Gen`eve.</tech>
<contexts>
<context position="21704" citStr="Ferrer and Merlo, 2003" startWordPosition="3544" endWordPosition="3547">es could be statistically approximated from text by grasping the aspect of the verb. The aspect of the verbs could, in turn, be approximated by developing features that would consider the usage of certain tenses, or the presence of certain types of adverbs that imply a restriction on the aspect of the verb. Adverbs such as ”suddenly”, ”continuously”, ”often”, or even adverbial sentences such as ”every day” give information on the event structure of predicates. As they are a closed class of words, a typology of adverbs could be established to approximate the event structure of the verb (Esteve Ferrer and Merlo, 2003). On the other hand, an observation of the verb clusters output by the algorithm suggests that they are intuitively more plausible than what the evaluation measures indicate. For the purposes of possible applications, a hard clustering of verbs does not seem to be necessary, especially when even manually constructed classifications adopt arbitrary decisions and do not agree with each other: knowing which verbs are semantically similar to each other in a more “fuzzy” way might be even more useful. For this reason, a new approach could be envisaged for this task, in the direction of the work by </context>
</contexts>
<marker>Ferrer, Merlo, 2003</marker>
<rawString>Eva Esteve Ferrer and Paola Merlo. 2003. Automatic classification of english verbs. Technical report, Universit´e de Gen`eve.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Kaufman</author>
<author>Peter J Rousseeuw</author>
</authors>
<title>Finding Groups in Data - An Introduction to Cluster Analysis. Probability and Mathematical Statistics.</title>
<date>1990</date>
<publisher>Jonh Wiley and Sons, Inc.,</publisher>
<location>New York.</location>
<contexts>
<context position="15932" citStr="Kaufman and Rousseeuw, 1990" startWordPosition="2577" endWordPosition="2580">ass of each frame among the possible labels, according to their frequencies. Now, we have a total of 97 features for each verb of our sample. 3.3 Clustering Evaluation Evaluating the results of a clustering experiment is a complex task because ideally we would like the output to fulfil different goals. One the one hand, the clusters obtained should reflect a good partition of the data, yielding consistent clusters. On the other hand, the partition of the data obtained should be as similar as possible to the manually constructed classification, the gold standard. We use the Silhouette measure (Kaufman and Rousseeuw, 1990) as an indication of the consistency of the obtained clusters, regardless of the division of the data in the gold standard. For each clustering experiment, we calculate the mean of the silhouette value of all the data points, in order to get an indication of the overall quality of the clusters created. The main difficulty in evaluating unsupervised classification tasks against a gold standard lies in the fact that the class labels of the obtained clusters are unknown. Therefore, the evaluation is done according to the pairs of objects that the two groups have in common. (Schulte im Walde, 2003</context>
</contexts>
<marker>Kaufman, Rousseeuw, 1990</marker>
<rawString>Leonard Kaufman and Peter J. Rousseeuw. 1990. Finding Groups in Data - An Introduction to Cluster Analysis. Probability and Mathematical Statistics. Jonh Wiley and Sons, Inc., New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Korhonen</author>
</authors>
<title>Semantically motivated subcategorization acquisition.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop of the ACL Special Interest Group on the Lexicon on Unsupervised Lexical Acquisition,</booktitle>
<pages>51--58</pages>
<location>Philadelphia,PA,</location>
<contexts>
<context position="1198" citStr="Korhonen, 2002" startWordPosition="165" endWordPosition="166">vourably to the state of the art for English. For the verb classification task, we use a hierarchical clustering algorithm, and we compare the output clusters to a manually constructed classification. 1 Introduction Lexical semantic classes group together words that have a similar meaning. Knowledge about verbs is especially important, since verbs are the primary means of structuring and conveying meaning in sentences. Manually built semantic classifications of English verbs have been used for different applications such as machine translation (Dorr, 1997), verb subcategorisation acquisition (Korhonen, 2002a) or parsing (Schneider, 2003). (Levin, 1993) has established a large-scale classification of English verbs based on the hypothesis that the meaning of a verb and its syntactic behaviour are related, and therefore semantic information can be induced from the syntactic behaviour of the verb. A classification of Spanish verbs based on the same hypothesis has been developed by (V´azquez et al., 2000). But manually constructing large-scale verb classifications is a labour-intensive task. For this reason, various methods for automatically classifying verbs using machine learning techniques have be</context>
<context position="2894" citStr="Korhonen, 2002" startWordPosition="423" endWordPosition="425">teps: we first extract from a partially parsed corpus the probabilities of the subcategorisation frames for each verb. Then, the acquired probabilities are used as features describing the verbs and given as input to an unsupervised classification algorithm that clusters together the verbs according to the similarity of their descriptions. For the task of acquiring verb subcategorisation frames, we adapt to the specificities of the Spanish language well-known techniques that have been developed for English, and our results compare favourably to the sate of the art results obtained for English (Korhonen, 2002b). For the verb classification task, we use a hierarchical clustering algorithm, and we compare the output clusters to a manually constructed classification developed by (V´azquez et al., 2000). 2 Acquisition of Spanish Subcategorisation Frames Subcategorisation frames encode the information of how many arguments are required by the verb, and of what syntactic type. Acquiring the subcategorization frames for a verb involves, in the first place, distinguishing which constituents are its arguments and which are adjuncts, elements that give an additional piece of information to the sentence. Mor</context>
<context position="4359" citStr="Korhonen, 2002" startWordPosition="643" endWordPosition="644">nt our methodology on two corpora of different sizes, both consisting of Spanish newswire text: a 3 million word corpus, hereafter called small corpus, and a 50 million word corpus, hereafter called large corpus. They are both POS tagged and partially parsed using the MS-analyzer, a partial parser for Spanish that includes named entities recognition (Atserias et al., 1998). In order to collect the frequency distributions of Spanish subcategorisation frames, we adapt a methodology that has been developed for English to the specificities of the Spanish language ((Brent, 1993), (Manning, 1993), (Korhonen, 2002b)). It consists in extracting from the corpus pairs made of a verb and its co-occurring constituents that are a possible pattern of a frame, and then filtering out the patterns that do not have a probability of cooccurrence with the verb high enough to be considered its arguments. We establish a set of 11 possible Spanish subcategorisation frames. These are the plausible combinations of a maximum of 2 of the following constituents: nominal phrases, prepositional phrases, temporal sentential clauses, gerundive sentential clauses, infinitival sentential clauses, and infinitival sentential claus</context>
<context position="8403" citStr="Korhonen, 2002" startWordPosition="1318" endWordPosition="1319">n. (2) Por la tarde, agentes del cuerpo nacional de policia le comunicaron por tel´efono la aparici´on del cad´aver. “In the afternoon, agents of the national police clitic IO reported by phone the apparition of the corpse.”. The collection of pairs verb + pattern obtained with the method described in the last section needs to be filtered out, because we may have extracted constituents that are in fact adjuncts, or elements that are not attached to the verb, or errors in the extraction process. We filter out the spurious patterns with a Maximum Likelihood Estimate (MLE), a method proposed by (Korhonen, 2002b) for this task. MLE is calculated as the ratio of the frequency of + over the frequency of . Pairs of verb+pattern that do not have a probability of co-occurring together higher than a certain threshold are filtered out. The threshold is determined empirically using held-out data (20% of the total of the corpus), by choosing from a range of values between 0.02 and 0.1 the value that yields better results against a held-out gold standard of 10 verbs. In our experiments, this method yields a threshold value of 0.05. 2.2 Experimental Evaluation We evaluate the obtained subcategorisation frames </context>
<context position="11076" citStr="Korhonen, 2002" startWordPosition="1778" endWordPosition="1780">stablished by considering all the frame patterns obtained in the extraction process as correct frames. The experiments on the large corpus give better results than the ones on the small one, and grouping similar prepositions together is useful only on the large corpus. This is probably due to the fact that the small corpus does not suffer from a too large number of frame types, and the effect of the groupings cannot be noticed. The F measure value of 66% reported on the third line of table 1, obtained on the large corpus with preposition groups, compares favourably to the results reported on (Korhonen, 2002b) for a similar experiment on English subcategorization frames, in which an F measure of 65.2 is achieved. &apos;In all experiments, we post-process the data by eliminating prepositional constituents in the second position of the pattern that are introduced with the preposition de, “of”. This is motivated by the observation that in 96.8% of the cases this preposition is attached to the preceding constituent, and not to the verb. 3 Clustering Verbs into Classes We use a bottom-up hierarchical clustering algorithm to group together 514 verbs into K classes. The algorithm starts by finding the simila</context>
</contexts>
<marker>Korhonen, 2002</marker>
<rawString>Anna Korhonen. 2002a. Semantically motivated subcategorization acquisition. In Proceedings of the Workshop of the ACL Special Interest Group on the Lexicon on Unsupervised Lexical Acquisition, pages 51–58, Philadelphia,PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Korhonen</author>
</authors>
<title>Subcategorisation Acquisition.</title>
<date>2002</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Cambridge.</institution>
<note>distributed as UCAM-CL-TR-530.</note>
<contexts>
<context position="1198" citStr="Korhonen, 2002" startWordPosition="165" endWordPosition="166">vourably to the state of the art for English. For the verb classification task, we use a hierarchical clustering algorithm, and we compare the output clusters to a manually constructed classification. 1 Introduction Lexical semantic classes group together words that have a similar meaning. Knowledge about verbs is especially important, since verbs are the primary means of structuring and conveying meaning in sentences. Manually built semantic classifications of English verbs have been used for different applications such as machine translation (Dorr, 1997), verb subcategorisation acquisition (Korhonen, 2002a) or parsing (Schneider, 2003). (Levin, 1993) has established a large-scale classification of English verbs based on the hypothesis that the meaning of a verb and its syntactic behaviour are related, and therefore semantic information can be induced from the syntactic behaviour of the verb. A classification of Spanish verbs based on the same hypothesis has been developed by (V´azquez et al., 2000). But manually constructing large-scale verb classifications is a labour-intensive task. For this reason, various methods for automatically classifying verbs using machine learning techniques have be</context>
<context position="2894" citStr="Korhonen, 2002" startWordPosition="423" endWordPosition="425">teps: we first extract from a partially parsed corpus the probabilities of the subcategorisation frames for each verb. Then, the acquired probabilities are used as features describing the verbs and given as input to an unsupervised classification algorithm that clusters together the verbs according to the similarity of their descriptions. For the task of acquiring verb subcategorisation frames, we adapt to the specificities of the Spanish language well-known techniques that have been developed for English, and our results compare favourably to the sate of the art results obtained for English (Korhonen, 2002b). For the verb classification task, we use a hierarchical clustering algorithm, and we compare the output clusters to a manually constructed classification developed by (V´azquez et al., 2000). 2 Acquisition of Spanish Subcategorisation Frames Subcategorisation frames encode the information of how many arguments are required by the verb, and of what syntactic type. Acquiring the subcategorization frames for a verb involves, in the first place, distinguishing which constituents are its arguments and which are adjuncts, elements that give an additional piece of information to the sentence. Mor</context>
<context position="4359" citStr="Korhonen, 2002" startWordPosition="643" endWordPosition="644">nt our methodology on two corpora of different sizes, both consisting of Spanish newswire text: a 3 million word corpus, hereafter called small corpus, and a 50 million word corpus, hereafter called large corpus. They are both POS tagged and partially parsed using the MS-analyzer, a partial parser for Spanish that includes named entities recognition (Atserias et al., 1998). In order to collect the frequency distributions of Spanish subcategorisation frames, we adapt a methodology that has been developed for English to the specificities of the Spanish language ((Brent, 1993), (Manning, 1993), (Korhonen, 2002b)). It consists in extracting from the corpus pairs made of a verb and its co-occurring constituents that are a possible pattern of a frame, and then filtering out the patterns that do not have a probability of cooccurrence with the verb high enough to be considered its arguments. We establish a set of 11 possible Spanish subcategorisation frames. These are the plausible combinations of a maximum of 2 of the following constituents: nominal phrases, prepositional phrases, temporal sentential clauses, gerundive sentential clauses, infinitival sentential clauses, and infinitival sentential claus</context>
<context position="8403" citStr="Korhonen, 2002" startWordPosition="1318" endWordPosition="1319">n. (2) Por la tarde, agentes del cuerpo nacional de policia le comunicaron por tel´efono la aparici´on del cad´aver. “In the afternoon, agents of the national police clitic IO reported by phone the apparition of the corpse.”. The collection of pairs verb + pattern obtained with the method described in the last section needs to be filtered out, because we may have extracted constituents that are in fact adjuncts, or elements that are not attached to the verb, or errors in the extraction process. We filter out the spurious patterns with a Maximum Likelihood Estimate (MLE), a method proposed by (Korhonen, 2002b) for this task. MLE is calculated as the ratio of the frequency of + over the frequency of . Pairs of verb+pattern that do not have a probability of co-occurring together higher than a certain threshold are filtered out. The threshold is determined empirically using held-out data (20% of the total of the corpus), by choosing from a range of values between 0.02 and 0.1 the value that yields better results against a held-out gold standard of 10 verbs. In our experiments, this method yields a threshold value of 0.05. 2.2 Experimental Evaluation We evaluate the obtained subcategorisation frames </context>
<context position="11076" citStr="Korhonen, 2002" startWordPosition="1778" endWordPosition="1780">stablished by considering all the frame patterns obtained in the extraction process as correct frames. The experiments on the large corpus give better results than the ones on the small one, and grouping similar prepositions together is useful only on the large corpus. This is probably due to the fact that the small corpus does not suffer from a too large number of frame types, and the effect of the groupings cannot be noticed. The F measure value of 66% reported on the third line of table 1, obtained on the large corpus with preposition groups, compares favourably to the results reported on (Korhonen, 2002b) for a similar experiment on English subcategorization frames, in which an F measure of 65.2 is achieved. &apos;In all experiments, we post-process the data by eliminating prepositional constituents in the second position of the pattern that are introduced with the preposition de, “of”. This is motivated by the observation that in 96.8% of the cases this preposition is attached to the preceding constituent, and not to the verb. 3 Clustering Verbs into Classes We use a bottom-up hierarchical clustering algorithm to group together 514 verbs into K classes. The algorithm starts by finding the simila</context>
</contexts>
<marker>Korhonen, 2002</marker>
<rawString>Anna Korhonen. 2002b. Subcategorisation Acquisition. Ph.D. thesis, University of Cambridge. distributed as UCAM-CL-TR-530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes and Alternations.</title>
<date>1993</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago, IL.</location>
<contexts>
<context position="1244" citStr="Levin, 1993" startWordPosition="171" endWordPosition="172">r the verb classification task, we use a hierarchical clustering algorithm, and we compare the output clusters to a manually constructed classification. 1 Introduction Lexical semantic classes group together words that have a similar meaning. Knowledge about verbs is especially important, since verbs are the primary means of structuring and conveying meaning in sentences. Manually built semantic classifications of English verbs have been used for different applications such as machine translation (Dorr, 1997), verb subcategorisation acquisition (Korhonen, 2002a) or parsing (Schneider, 2003). (Levin, 1993) has established a large-scale classification of English verbs based on the hypothesis that the meaning of a verb and its syntactic behaviour are related, and therefore semantic information can be induced from the syntactic behaviour of the verb. A classification of Spanish verbs based on the same hypothesis has been developed by (V´azquez et al., 2000). But manually constructing large-scale verb classifications is a labour-intensive task. For this reason, various methods for automatically classifying verbs using machine learning techniques have been attempted ((Merlo and Stevenson, 2001), (St</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English Verb Classes and Alternations. University of Chicago Press, Chicago, IL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Manning</author>
</authors>
<title>Automatic acquisition of a large subcategorization dictionary from corpora.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the ACL,</booktitle>
<pages>235--242</pages>
<contexts>
<context position="4342" citStr="Manning, 1993" startWordPosition="641" endWordPosition="642">rials We experiment our methodology on two corpora of different sizes, both consisting of Spanish newswire text: a 3 million word corpus, hereafter called small corpus, and a 50 million word corpus, hereafter called large corpus. They are both POS tagged and partially parsed using the MS-analyzer, a partial parser for Spanish that includes named entities recognition (Atserias et al., 1998). In order to collect the frequency distributions of Spanish subcategorisation frames, we adapt a methodology that has been developed for English to the specificities of the Spanish language ((Brent, 1993), (Manning, 1993), (Korhonen, 2002b)). It consists in extracting from the corpus pairs made of a verb and its co-occurring constituents that are a possible pattern of a frame, and then filtering out the patterns that do not have a probability of cooccurrence with the verb high enough to be considered its arguments. We establish a set of 11 possible Spanish subcategorisation frames. These are the plausible combinations of a maximum of 2 of the following constituents: nominal phrases, prepositional phrases, temporal sentential clauses, gerundive sentential clauses, infinitival sentential clauses, and infinitival</context>
</contexts>
<marker>Manning, 1993</marker>
<rawString>Christopher Manning. 1993. Automatic acquisition of a large subcategorization dictionary from corpora. In Proceedings of the 31st Annual Meeting of the ACL, pages 235–242, Columbus/Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatic verb classification based on statistical distributions of argument structure.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>3</issue>
<contexts>
<context position="1839" citStr="Merlo and Stevenson, 2001" startWordPosition="258" endWordPosition="261">Schneider, 2003). (Levin, 1993) has established a large-scale classification of English verbs based on the hypothesis that the meaning of a verb and its syntactic behaviour are related, and therefore semantic information can be induced from the syntactic behaviour of the verb. A classification of Spanish verbs based on the same hypothesis has been developed by (V´azquez et al., 2000). But manually constructing large-scale verb classifications is a labour-intensive task. For this reason, various methods for automatically classifying verbs using machine learning techniques have been attempted ((Merlo and Stevenson, 2001), (Stevenson and Joanis, 2003), (Schulte im Walde, 2003)). In this article we present experiments aiming at automatically classifying Spanish verbs into lexical semantic classes based on their subcategorisation frames. We adopt the idea that a description of verbs in terms of their syntactic behaviour is useful for acquiring their semantic properties. The classification task at hand is achieved through a process that requires different steps: we first extract from a partially parsed corpus the probabilities of the subcategorisation frames for each verb. Then, the acquired probabilities are use</context>
</contexts>
<marker>Merlo, Stevenson, 2001</marker>
<rawString>Paola Merlo and Suzanne Stevenson. 2001. Automatic verb classification based on statistical distributions of argument structure. Computational Linguistics, 27(3):373–408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerold Schneider</author>
</authors>
<title>A low-complexity, broad coverage probabilistic dependency parser for english.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL/HLT 2003 Student Session,</booktitle>
<pages>31--36</pages>
<contexts>
<context position="1229" citStr="Schneider, 2003" startWordPosition="169" endWordPosition="170">art for English. For the verb classification task, we use a hierarchical clustering algorithm, and we compare the output clusters to a manually constructed classification. 1 Introduction Lexical semantic classes group together words that have a similar meaning. Knowledge about verbs is especially important, since verbs are the primary means of structuring and conveying meaning in sentences. Manually built semantic classifications of English verbs have been used for different applications such as machine translation (Dorr, 1997), verb subcategorisation acquisition (Korhonen, 2002a) or parsing (Schneider, 2003). (Levin, 1993) has established a large-scale classification of English verbs based on the hypothesis that the meaning of a verb and its syntactic behaviour are related, and therefore semantic information can be induced from the syntactic behaviour of the verb. A classification of Spanish verbs based on the same hypothesis has been developed by (V´azquez et al., 2000). But manually constructing large-scale verb classifications is a labour-intensive task. For this reason, various methods for automatically classifying verbs using machine learning techniques have been attempted ((Merlo and Steven</context>
</contexts>
<marker>Schneider, 2003</marker>
<rawString>Gerold Schneider. 2003. A low-complexity, broad coverage probabilistic dependency parser for english. In Proceedings of NAACL/HLT 2003 Student Session, pages 31–36, Edmonton/Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Experiments on the Automatic Induction of German Semantic Verb Classes.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>Institut fur Maschinelle Sprachverarbeitung, Universitat Stuttgart.</institution>
<note>Published as AIMS Report 9(2).</note>
<contexts>
<context position="1895" citStr="Walde, 2003" startWordPosition="269" endWordPosition="270">cation of English verbs based on the hypothesis that the meaning of a verb and its syntactic behaviour are related, and therefore semantic information can be induced from the syntactic behaviour of the verb. A classification of Spanish verbs based on the same hypothesis has been developed by (V´azquez et al., 2000). But manually constructing large-scale verb classifications is a labour-intensive task. For this reason, various methods for automatically classifying verbs using machine learning techniques have been attempted ((Merlo and Stevenson, 2001), (Stevenson and Joanis, 2003), (Schulte im Walde, 2003)). In this article we present experiments aiming at automatically classifying Spanish verbs into lexical semantic classes based on their subcategorisation frames. We adopt the idea that a description of verbs in terms of their syntactic behaviour is useful for acquiring their semantic properties. The classification task at hand is achieved through a process that requires different steps: we first extract from a partially parsed corpus the probabilities of the subcategorisation frames for each verb. Then, the acquired probabilities are used as features describing the verbs and given as input to</context>
<context position="16533" citStr="Walde, 2003" startWordPosition="2681" endWordPosition="2682">eeuw, 1990) as an indication of the consistency of the obtained clusters, regardless of the division of the data in the gold standard. For each clustering experiment, we calculate the mean of the silhouette value of all the data points, in order to get an indication of the overall quality of the clusters created. The main difficulty in evaluating unsupervised classification tasks against a gold standard lies in the fact that the class labels of the obtained clusters are unknown. Therefore, the evaluation is done according to the pairs of objects that the two groups have in common. (Schulte im Walde, 2003) reports that the evaluation method that is most appropriate to the task of unsupervised verb classification is the Adjusted Rand measure. It gives a value of 1 if the two classifications agree comNo Named Entities Task Mean Sil Baseline Radj 3-way 0.37 0 0.001 15-way 0.37 0 0.040 31-way 0.27 0 0.070 Table 2: Clustering evaluation for the experiment without Named Entities Named Entities Task Mean Sil Baseline Radj 3-way 0.37 0 0.01 15-way 0.31 0 0.07 31-way 0.22 0 0.03 Table 3: Clustering evaluation for the experiment with Named Entities pletely in which pairs of objects are clustered together</context>
<context position="19362" citStr="Walde, 2003" startWordPosition="3160" endWordPosition="3161">ced features are useful on the 15-way and 3-way classifications, but they are harmful in the 31-way classification. In spite of these results, a qualitative observation of the output clusters reveals that they are intuitively plausible, and that the evaluation is penalised by the fact that the target classes are of very different sizes. On the other hand, our data takes into account syntactic information, while the target classification is not only based on syntax, but also on other aspects of the properties of the verbs. These results compare poorly to the performance achieved by (Schulte im Walde, 2003), who obtains an Adjusted Rand measure of 0.15 in a similar task, in which she classifies 168 German verbs into 43 semantic verb classes. Nevertheless, our results are comparable to a subset of experiments reported in (Stevenson and Joanis, 2003), where they perform similar clustering experiments on English verbs based on a general description of verbs, obtaining average Adjusted Rand measures of 0.04 and 0.07. 4 Conclusions and Future Work We have presented a series of experiments that use an unsupervised learning method to classify Spanish verbs into semantic classes based on subcategorisati</context>
</contexts>
<marker>Walde, 2003</marker>
<rawString>Sabine Schulte im Walde. 2003. Experiments on the Automatic Induction of German Semantic Verb Classes. Ph.D. thesis, Institut fur Maschinelle Sprachverarbeitung, Universitat Stuttgart. Published as AIMS Report 9(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suzanne Stevenson</author>
<author>Eric Joanis</author>
</authors>
<title>Semisupervised verb class discovery using noisy features.</title>
<date>2003</date>
<booktitle>In Proceedings of the Seventh Conference on Natural Language Learning (CoNLL-2003),</booktitle>
<location>page, Edmonton/Canada.</location>
<contexts>
<context position="1869" citStr="Stevenson and Joanis, 2003" startWordPosition="262" endWordPosition="266">3) has established a large-scale classification of English verbs based on the hypothesis that the meaning of a verb and its syntactic behaviour are related, and therefore semantic information can be induced from the syntactic behaviour of the verb. A classification of Spanish verbs based on the same hypothesis has been developed by (V´azquez et al., 2000). But manually constructing large-scale verb classifications is a labour-intensive task. For this reason, various methods for automatically classifying verbs using machine learning techniques have been attempted ((Merlo and Stevenson, 2001), (Stevenson and Joanis, 2003), (Schulte im Walde, 2003)). In this article we present experiments aiming at automatically classifying Spanish verbs into lexical semantic classes based on their subcategorisation frames. We adopt the idea that a description of verbs in terms of their syntactic behaviour is useful for acquiring their semantic properties. The classification task at hand is achieved through a process that requires different steps: we first extract from a partially parsed corpus the probabilities of the subcategorisation frames for each verb. Then, the acquired probabilities are used as features describing the v</context>
<context position="12352" citStr="Stevenson and Joanis, 2003" startWordPosition="1994" endWordPosition="1997">in the data according to a similarity measure S. After having established the distance between all the pairs, it links together the closest pairs of objects by a linkage method L, forming a binary cluster. The linking process is repeated iteratively over the newly created clusters until all the objects are grouped into one cluster. K, S and L are parameters that can be set for the clustering. For the similarity measure S, we choose the Euclidean distance. For the linkage method L, we choose the Ward linkage method (Ward, 1963). Our choice of the parameter settings is motivated by the work of (Stevenson and Joanis, 2003). Applying a clustering method to the verbs in our data, we expect to find a natural division of the data that will be in accordance with the classification of verbs that we have set as our target classification. We perform different experiments with different values for K in order to test which of the different granularities yields better results. 3.1 The Target Classification In order to be able to evaluate the clusters output by the algorithm, we need to establish a manual classification of sample verbs. We assume the manual classification of Spanish verbs developed by (V´azquez et al., 200</context>
<context position="19608" citStr="Stevenson and Joanis, 2003" startWordPosition="3201" endWordPosition="3204">ible, and that the evaluation is penalised by the fact that the target classes are of very different sizes. On the other hand, our data takes into account syntactic information, while the target classification is not only based on syntax, but also on other aspects of the properties of the verbs. These results compare poorly to the performance achieved by (Schulte im Walde, 2003), who obtains an Adjusted Rand measure of 0.15 in a similar task, in which she classifies 168 German verbs into 43 semantic verb classes. Nevertheless, our results are comparable to a subset of experiments reported in (Stevenson and Joanis, 2003), where they perform similar clustering experiments on English verbs based on a general description of verbs, obtaining average Adjusted Rand measures of 0.04 and 0.07. 4 Conclusions and Future Work We have presented a series of experiments that use an unsupervised learning method to classify Spanish verbs into semantic classes based on subcategorisation information. We apply well-known techniques that have been developed for the English language to Spanish, confirming that empirical methods can be re-used through languages without substantial changes in the methodology. In the task of acquiri</context>
</contexts>
<marker>Stevenson, Joanis, 2003</marker>
<rawString>Suzanne Stevenson and Eric Joanis. 2003. Semisupervised verb class discovery using noisy features. In Proceedings of the Seventh Conference on Natural Language Learning (CoNLL-2003), page, Edmonton/Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gloria V´azquez</author>
<author>Ana Fern´andez</author>
<author>Irene Castell´on</author>
<author>M Antonia Mart´ı</author>
</authors>
<title>Clasificaci´on verbal: Alternancias de di´atesis. Quaderns de Sintagma. Universitat de</title>
<date>2000</date>
<location>Lleida, 3.</location>
<marker>V´azquez, Fern´andez, Castell´on, Mart´ı, 2000</marker>
<rawString>Gloria V´azquez, Ana Fern´andez, Irene Castell´on, and M. Antonia Mart´ı. 2000. Clasificaci´on verbal: Alternancias de di´atesis. Quaderns de Sintagma. Universitat de Lleida, 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joe H Ward</author>
</authors>
<title>Hierarchical grouping to optimize an objective function.</title>
<date>1963</date>
<journal>Journal of the American Statistical Association,</journal>
<pages>58--236</pages>
<contexts>
<context position="12257" citStr="Ward, 1963" startWordPosition="1980" endWordPosition="1981">m starts by finding the similarities between all the possible pairs of objects in the data according to a similarity measure S. After having established the distance between all the pairs, it links together the closest pairs of objects by a linkage method L, forming a binary cluster. The linking process is repeated iteratively over the newly created clusters until all the objects are grouped into one cluster. K, S and L are parameters that can be set for the clustering. For the similarity measure S, we choose the Euclidean distance. For the linkage method L, we choose the Ward linkage method (Ward, 1963). Our choice of the parameter settings is motivated by the work of (Stevenson and Joanis, 2003). Applying a clustering method to the verbs in our data, we expect to find a natural division of the data that will be in accordance with the classification of verbs that we have set as our target classification. We perform different experiments with different values for K in order to test which of the different granularities yields better results. 3.1 The Target Classification In order to be able to evaluate the clusters output by the algorithm, we need to establish a manual classification of sample</context>
</contexts>
<marker>Ward, 1963</marker>
<rawString>Joe H. Ward. 1963. Hierarchical grouping to optimize an objective function. Journal of the American Statistical Association, 58:236–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie Weeds</author>
<author>David Weir</author>
</authors>
<title>A general framework for distributional similarity.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP2003), Sapporo/Japan.</booktitle>
<contexts>
<context position="22326" citStr="Weeds and Weir, 2003" startWordPosition="3650" endWordPosition="3653"> On the other hand, an observation of the verb clusters output by the algorithm suggests that they are intuitively more plausible than what the evaluation measures indicate. For the purposes of possible applications, a hard clustering of verbs does not seem to be necessary, especially when even manually constructed classifications adopt arbitrary decisions and do not agree with each other: knowing which verbs are semantically similar to each other in a more “fuzzy” way might be even more useful. For this reason, a new approach could be envisaged for this task, in the direction of the work by (Weeds and Weir, 2003), by building rankings of similarity for each verb. For the purpose of evaluation, the gold standard classification could also be organised in the form of similarity rankings, based on the distance between the verbs in the hierarchy. Then, the rankings for each verb could be evaluated. The two directions appointed here, enriching the verb descriptions with new features that grasp other properties of the verbs, and envisaging a similarity ranking of verbs instead of a hard clustering, are the next steps to be taken for this work. Acknowledgements The realisation of this work was possible thanks</context>
</contexts>
<marker>Weeds, Weir, 2003</marker>
<rawString>Julie Weeds and David Weir. 2003. A general framework for distributional similarity. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP2003), Sapporo/Japan.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>