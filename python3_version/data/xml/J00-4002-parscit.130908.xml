<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.98541">
Bidirectional Contextual Resolution
</title>
<author confidence="0.993004">
Stephen G. Pulman.
</author>
<affiliation confidence="0.9219745">
Centre for Linguistics and Philology,
Oxford University
</affiliation>
<bodyText confidence="0.997566">
This paper describes a formalism and implementation for the interpretation and generation of
sentences containing context-dependent constructs like determiners, pronouns, focus, and ellipsis.
A variant of quasi-logical form is used as an underspecified meaning representation, related to
resolved logical forms via conditional equivalences. These equivalences define the interpretation
of contextually dependent constructs with respect to a given context. Higher-order unification
and abduction are used in relating expressions to contexts. The conditional equivalences can be
used unchanged in both the interpretation and the generation direction.
</bodyText>
<sectionHeader confidence="0.972662" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999652">
This paper has several aims. Firstly, it outlines a formalism within which quasi-logical
form–based theories of contextual interpretation of sentences can be stated in a way
which is completely reversible; that is to say, theories expressed within the formalism
can be used to provide interpretations for (utterances of) sentences containing con-
textually dependent constructs, given a context; and, given an interpretation and a
context, to generate a sentence which has that interpretation in that context. Process-
ing in both directions is done using exactly the same grammar, and the same set of
contextual interpretation rules.
To give an extremely simplified example, the aim is to have a way of interpreting
the sentences in the left-hand column below as expressing the logical forms in the
middle column, given that they are encountered in that order in an otherwise neutral
context: and the reverse—given a sequence of logical forms as in the middle column, to
be able to generate (among others) the sequence of sentences in the left-hand column,
rather than the unnatural although literally correct version given in the right-hand
column.
Joe sneezed. sneeze(joe) Joe sneezed.
He laughed. laugh( joe) Joe laughed.
Bill laughed too. laugh( bill) Bill laughed.
We will assume that if the context is loosely specified enough to permit alternative
realizations of the same content, then different versions of the same text could be
generated or analysed:
</bodyText>
<listItem confidence="0.585853">
(1) Joe sneezed and laughed. Bill laughed too.
</listItem>
<bodyText confidence="0.815435">
Joe sneezed. Joe and Bill laughed.
Joe sneezed. He laughed. So did Bill.
</bodyText>
<affiliation confidence="0.351097">
* Somerville College, Oxford 0X2 6HD. E-mail: stephen.pu1man011inguistics-philo1ogy.ox.aculk
2001 Association for Computational Linguistics
</affiliation>
<note confidence="0.758674">
Computational Linguistics Volume 26, Number 4
</note>
<bodyText confidence="0.999959878787879">
Secondly, we illustrate the formalism and the general approach by developing an
account of contextual interpretation based on a kind of quasi-logical form and giving
an account of a fragment (in the sense of Montague [1974d) that treats several core
phenomena of English contextual dependence.
We also have some theoretical objectives: the particular approach illustrated here,
like most computational approaches to contextual interpretation, uses an intermediate
quasi-logical form representation level. Using such a level of representation incurs an
obligation to say what it means (&amp;quot;no notation without denotation&amp;quot;). We try to show
how the theory presented here leads to a natural semantics for these quasi-logical
forms, and indeed leads to a truth theory for contextually dependent interpretation
that supports a natural consequence relation, and one appropriate for cases where
interpretations are not fully specified. We relate this approach both to the classical
tradition of formal linguistic semantics exemplified by Davidson (1972) and Mon-
tague (1974b) and more recent literature on the use of underspecification in seman-
tics.
The structure of the paper is as follows: In the next section we give an outline of
the formalism and illustrate with the small fragment of English that has been imple-
mented within this framework. We present analyses of the contextual interpretation of
pronouns, definites, ellipsis, focus, and quantifier scope. There is far more to say about
each of these phenomena, of course, and the analyses here are by no means claimed to
be definitive. The aim is merely to show that we can, to a first approximation, provide
a reasonably fully worked out description of these phenomena in a truly bidirectional
way.
We then go on to compare the current approach with that of some other theories
with similar aims: the &amp;quot;standard&amp;quot; version of quasi-logical form implemented in the
Core Language Engine, as rationally reconstructed by Alshawi and Crouch (1992) and
Crouch and Pulman (1994); underspecified Discourse Representation Theory (Reyle
1993); and the &amp;quot;glue language&amp;quot; approach of Dalrymple et al. (1996).
Finally, we discuss some of the semantic and logical issues raised by the approach
described here, in particular the extent to which the theory meets the desiderata for
accounts of underspecification outlined by van Eijck and Jaspars (1996), and the extent
to which the theory supplies a methodologically satisfactory account of truth and
interpretation for sentences involving contextually dependent constructs.
</bodyText>
<sectionHeader confidence="0.971346" genericHeader="method">
2. Contextual Interpretation
</sectionHeader>
<bodyText confidence="0.973745571428571">
The major components and assumptions of the approach to contextual interpretation
here are as follows:
1. We assume that the output of grammatical processing of a sentence is a
quasi-logical form, henceforth QLF. Of course, for anything other than a
trivial grammar, a given sentence will typically yield many QLFs. We
will assume that syntactic and lexical disambiguation have taken place
and that the only things still needed for a complete interpretation are the
resolution of constructs like pronouns, definites, ellipsis, and so on. We
return later to issues concerning robustness of linguistic coverage and to
the interleaving of contextual disambiguation with syntactic and
semantic processing.
For concreteness, we are assuming here that QLFs are built using a
simple unification grammar formalism of the type described in Pulman
(1996), and that a chart parser and semantic head-driven generator are
</bodyText>
<page confidence="0.997342">
498
</page>
<note confidence="0.58104">
Putman Bidirectional Contextual Resolution
</note>
<bodyText confidence="0.999913481481482">
used for the analysis of sentences to QLFs and vice versa. But little of
this detail is essential to our main aims: a wide range of grammatical
formalisms and interpreters would be compatible with the basic
assumptions of the contextual interpretation mechanism, assuming only
that the same grammatical description is used in both the analysis and
generation direction.
What is required is that QLFs are, as here, expressed in a typed
higher-order logic, augmented with constructs representing the
interpretation of context-dependent elements (pronouns, ellipsis, focus,
etc.). These constructs correspond as directly as possible to properties of
the linguistic structure that express them and are, to as small an extent
as possible, dependent on the requirements of contextual resolution
(unlike, say, the metavariables of standard QLFs [Alshawi and Crouch
1992], or the labels of UDRS [Reyle 1996], which are motivated entirely
by the mechanisms that operate on them after grammatical processing).
Syntactic properties relevant for binding constraints, parallelism, scope
constraints, and so on, are not directly represented at QLF (again unlike
standard QLFs) but are assumed to be available as components of the
linguistic context.&apos;
The context-independent meanings of sentences, which we refer to as
resolved logical forms (RLFs), are expressed in the &amp;quot;ordinary&amp;quot; subset of
the QLF language. A fully resolved RLF can be directly evaluated for
truth: it contains no QLF constructs. Since it is just an expression of
&amp;quot;ordinary&amp;quot; logic, it could serve as a knowledge representation and
reasoning language, and thus the output of some information system
producing such representations could in principle feed directly into
generation (modulo well-known &amp;quot;equivalence of logical form&amp;quot; problems).
</bodyText>
<listItem confidence="0.54483">
3. &amp;quot;Contexts&amp;quot; are here modeled by sets of sentences in the RLF subset of
</listItem>
<bodyText confidence="0.998697733333334">
this language, with some kind of salience ordering on them (recency, in
the implementation), about which we say nothing more. These sentences
may, but need not, arise from prior linguistic processing. Contexts
contain information about the form as well as the content of previous
utterances, as mentioned earlier. Context sentences may also reflect
features of the nonlinguistic context gained by direct observation or
inference.
This is a very minimal theory of context. We need to be able to reason
about context, hence we need it represented in a logic. We need to be
able to refer to properties of the form of linguistic utterances as well as
their content, hence context must contain this information too. We
obviously need some nonlinguistic information. We also need some
structure to reflect the fact that not all components of the context are
relevant to everything, hence salience. This is all we need for the time
being, although there is clearly much more to be said.
</bodyText>
<footnote confidence="0.6871265">
1 This is probably too strong a position to take. There are good arguments for allowing some syntactic
distinctions to be represented more directly.
</footnote>
<page confidence="0.997957">
499
</page>
<figure confidence="0.95404">
Computational Linguistics Volume 26, Number 4
4. QLFs are interpreted by conditional equivalences (Rayner and Alshawi
1992; Rayner 1993) of the form:
QLF &lt;=&gt; RLF
if
Conditioni,
,
Condition„.
</figure>
<bodyText confidence="0.999082888888889">
These state a contextual equivalence between an expression containing
one or more QLF constructs (the left-hand side) and an expression
containing at least one fewer QLF constructs (the right-hand side). QLF
and RLF are therefore sometimes used to signify partially as well as fully
(un)resolved LFs. An equivalence can be paraphrased as: &amp;quot;In a context
where these conditions hold, this QLF can be interpreted as this RLF,&amp;quot; or
&amp;quot;In a context where these conditions hold, this RLF can be expressed as
this QLF.&amp;quot; Conditional equivalences, if 4=;. is interpreted as material
equivalence, can be unpacked to a conjunction of implications:
</bodyText>
<equation confidence="0.9208745">
(Conditions 8,4 QLF RLF)
(Conditions &amp; RLF QLF)
</equation>
<bodyText confidence="0.94512425">
5. Conditions are treated as goals to be satisfied with respect to the current
context, in a way familiar from the theorem proving and logic
programming tradition. Variables in goals may or may not be
instantiated, and satisfying a goal can instantiate variables
nondeterministically. The scope of a variable is within the whole
equivalence. The interpretation of variables is as for Prolog.
Later, we extend the notion of inference involved in checking conditions
beyond that provided by Prolog and the like to allow conditions to be
&amp;quot;abduced&amp;quot; and added to the context if they cannot be proved directly,
always provided that adding them to the context does not cause a
contradiction. We assume some &amp;quot;cost&amp;quot; mechanism constrains this
process.
</bodyText>
<listItem confidence="0.969646666666667">
6. Equivalences describe QLF or RLF patterns, typically containing
variables. Determining whether an equivalence applies to a QLF or an
RLF is done by higher-order unification (henceforth, HOU) (Huet 1975;
Miller and Nadathur 4986; Pulman 1991; Dalrymple, Shieber, and Pereira
1991; Gawron 1992) of the logical form with the relevant pattern. Many
of the contextual conditions require a higher-order equation to be solved.
7. The interpretation of a QLF is given via the RLFs it can be equivalent to
with respect to given contexts. Given a fixed, fully-specified context, a
QLF will generally be equivalent to a single RLF (unless the
</listItem>
<bodyText confidence="0.980298666666667">
equivalences allow for several synonymous interpretations). In cases
where the context does not resolve an ambiguity, the QLF will
correspond to different RLFs depending on which assumptions are
added to the context. Likewise, given a partially specified context and an
RLF, there may be several QLFs that can express the content of the RLF.
Notice that the equivalence holds if the conditions hold, not iff.
</bodyText>
<page confidence="0.980651">
500
</page>
<figure confidence="0.645335714285714">
Pulman Bidirectional Contextual Resolution
The overall architecture of the system can be pictured very simply, as described
below.
parser equivalences
Sentence &lt; &gt; QLF &lt; &gt; RLF
generator + context
3. An Illustrative Fragment
</figure>
<subsectionHeader confidence="0.969331">
3.1 Pronouns
</subsectionHeader>
<bodyText confidence="0.996859074074074">
It is easiest to see how all this is supposed to work out by giving some examples.
Consider the simple discourse:
(2) Smith owned NLPCom. He disappeared.
The QLF we will assign to the first sentence will be:
existsl(Ae_pos(past(own(e,smith , nIpcom))))
We actually interpret sentences as predicates on eventualities (type ev), and interpret
tense and aspect markers as QLF operators, subject to contextual interpretation of a
complex kind (see Pulman [1997a] and Thomas and Pulman [1999] for an account of
reversible tense and aspect interpretation within this framework). But for the purposes
of this paper, we will simply assume that tense and aspect processing consists of quan-
tifying over the event variable, and further simplify by assuming that this happens in
the grammar rather than in resolution. In the logical form, pos is the opposite of neg
and is motivated as an explicit element of QLF by the fact that the positive polarity
of a sentence can be focused, as in Smith DID disappear.
The quantifier exists1,,„ is so called to distinguish it from the generalized quan-
tifier exists(,,„),„„,„ used later.&apos;
This QLF/RLF, given our simplifying assumptions, needs no resolution and will
form the context for the interpretation of the QLF for the subsequent sentence:
existsl (Af. pos„( past(d isa p pea rf„, he.))
Note that the interpretation of the pronoun is represented by the QLF construct he,
which adequately summarizes the properties of singularity and masculinity required
of an antecedent. (For computational economy, we might want to generalize this rep-
resentation in an implementation to something like pron(X), where X is he, she, etc., to
enable a single equivalence to cover all the cases, but there is no linguistic motivation
for including any more information than we have.)
Next we try to resolve the QLF construct he. We have, we will assume, an equiv-
alence of the form:
</bodyText>
<equation confidence="0.694359333333333">
Pron-he
Pred(he) &lt;=&gt; Precf(Ref)
if
</equation>
<bodyText confidence="0.827365166666667">
salientContext(pronoun,Context),
possibleAntecedent(Context, he, Ref),
binding_cenditions_hold...
which is one of several that might be applicable. (We follow Prolog-like notational
conventions: query variables begin with upper case; variables beginning with under-
score &amp;quot;_&amp;quot; are those whose instantiation we are not interested in; constants begin with
</bodyText>
<footnote confidence="0.586474">
2 Type subscripts will be omitted where they are easy to infer.
</footnote>
<page confidence="0.987979">
501
</page>
<note confidence="0.892349">
Computational Linguistics Volume 26, Number 4
</note>
<bodyText confidence="0.992162405405405">
lower case, and &amp;quot;,&amp;quot; between expressions is interpreted as conjunction. Lambda-bound
variables of type ev (eventuality) are e, f, g, ... and those of type e (individual) are x,
y, z ...). Applicability is determined in two steps: first, equivalences are indexed by
any QLF constructs that they involve (like he), and secondly, higher-order unification
is tried between the QLF and the left-hand side of an equivalence retrieved by the
indexing. The indexing step is necessary both for completeness and for efficiency: if
we just used HOU, then, since it is not decidable, equivalences that did not match
the QLF could lead to nontermination, or, at best, to spurious matches that would be
filtered out expensively when checking the conditions. (To see how this could be so,
consider that trying to higher order unify Pred(he) with any formula F of the appro-
priate type will succeed with Pred = Ax.F, where x does not occur in F.) Other than
this, application of equivalences is entirely free and nondeterministic. Of course, if in
the analysis direction we require full resolution, then we will have to continue until
all QLF constructs have been resolved. But in the generation direction, application of
some constructs will be optional (such as this pronoun one), and some will be in effect
obligatory (like the quantifier scoping equivalences described later) because failure
to apply will not result in a QLF that the grammar can generate from. Equivalences
currently apply to an entire QLF, although in reality this is an oversimplification and
some more dynamic and incremental control regime should be used. We return to this
issue later.
Note also that here and throughout the paper, there may be alternative solutions
to equations in equivalences, some corresponding to alternative interpretations, and
some that will hopefully be filtered out by the relevant conditions. We assume that it
is possible to represent structural constraints like binding and scoping principles as
conditions in an equivalence. To keep the presentation manageable, we abstract away
from these issues, and also avoid questions of how the correct interpretation is actually
chosen, where there is a choice.
The conditions in this pronoun equivalence are stated in terms of several predi-
cates that recur in the treatment of different phenomena. The predicate
salientContext(Construct,Context) finds a logical form that is a salient one for the current
construct in the context. Having the construct as a parameter enables search to be
reduced: pronouns and ellipsis typically find their antecedents in either an earlier por-
tion of the current sentence, or the preceding sentence (Hobbs 1979), whereas definites
frequently refer back over several previous sentences. We parameterize this predicate
so that these preferences can be respected.
The predicate possibleAntecedent(Context,Proform,Candidate) does most of the work. The
simplest clause in its definition is:
</bodyText>
<equation confidence="0.620537">
possibleAntecedent(Context,,he,ReQ
if
Context = _OtherPred(Ref),
isOfType(he,Ref).
</equation>
<bodyText confidence="0.999787">
where = means that the equation is solved by HOU, and the predicate isOfType carries
out the obvious number and gender checks. More complete definitions of possibleAn-
tecedent would include checks for the type of restriction often expressed as binding
constraints, and for the type of preference obtained by centering theory. We ignore
these details here since they are not our main focus.
The sequence of unifications now is that the QLF
</bodyText>
<equation confidence="0.903610333333333">
existsl(Af.pos(past(disappear(Che))))
will HOU with the expression Pred(he) to give
Pred=Ax.existsl(Af.pos(past(disappear(f,x))))
</equation>
<page confidence="0.97846">
502
</page>
<subsectionHeader confidence="0.504002">
Pulman Bidirectional Contextual Resolution
</subsectionHeader>
<bodyText confidence="0.999215">
SalientContext will return exists1()e.pos(past(own(e,smith,n1pcom)))) as the value of Context,
and when we attempt to solve the goal possibleAntecedent, we will have two nonvacuous
solutions for the equation in its definition:
</bodyText>
<equation confidence="0.78541">
Context = _OtherPred(Ref)
</equation>
<bodyText confidence="0.7434055">
with Ref=smith, or nIpcom. Of these, only the first will pass the IsOfType test, and so the
RLF side of the equivalence will be instantiated to:
</bodyText>
<equation confidence="0.568703">
fAx.existsl(Af.pos( past(disappear(f,x))))](smith)
which after beta-reduction will be the intended interpretation.
</equation>
<bodyText confidence="0.996079333333333">
Consider now what would happen if we were operating in the other direction;
that is to say, we have the sarne sequence of resolved logical forms and we wish to
generate sentences expressing them. The first logical form:
</bodyText>
<equation confidence="0.572896">
exists17ke.pos(past(own(e,smith,n1pcom))))
</equation>
<bodyText confidence="0.99513675">
has no relevant context (for our purposes) and thus leads directly to the sentence Smith
owned NLPCom. For the second logical form, one outcome is that it is also treated in a
context-independent way and the sentence Smith disappeared is generated. (We should
have some way of ranking this as dispreferred, but we will postpone that issue for
now.) The other possible outcome is that we apply the pronoun equivalence in the gen-
eration direction. Conditions for applicability are a little more difficult here, because we
often have no QLF constructs to index equivalences from. Instead we currently have to
rely on coarser indexing heuristics. Assuming that, we then use HOU to check the con-
ditions for applicability: we will unify Pred(Ref) with exists(M.pos(past(disappear(f,smith))))
and the conditions will locate the prior reference to Smith as constituting a sufficient
condition for realizing this occurrence of Smith by the pronoun he.
In fact, as the equivalence is stated, we will be able to also generate the sentence he
disappeared if the current RLF was existsl(Af.pos(past(disappear(f,jones))), which is dearly
incorrect. The reason for this is that the HOU in the possibleAntecedent condition might
also succeed with a vacuous solution, namely:
_Oth erP red -- Ax.existsl(Af.pos(past(disappear(f,sm ith)))
and the remainder of the conditions will also succeed. We must therefore restrict
solutions to this equation to nonvacuous ones: in fact, we will not lose anything by
making this a general restriction on admissible solutions, as we have already been
doing implicitly.3
Of course, this analysis of pronoun reference will cover only the simplest possible
cases of intersentential anaphora. Before going on to more complex cases, we will also
show how to deal with intrasentential anaphora, including reflexives, and binding of
a pronoun by a quantifier. The relevant equivalence is:
</bodyText>
<equation confidence="0.75457975">
Pron-he-intra
Rest(_„„(Ay.Pred(y,he)) &lt;4= Rest.„( Pred(y,y))
if
binding_conditions_hold....
</equation>
<bodyText confidence="0.990112666666667">
This equivalence is doing essentially the same job as Pereira&apos;s pronoun abstraction
schema in Pereira (1990). It will identify a pronoun with any term of type e elsewhere
in the QLF, relying on the binding conditions to prevent impossible associations.
</bodyText>
<footnote confidence="0.98750225">
3 For this case, and for many other types of restrictions currently handled by conditions, more elegant
solutions are available using the &amp;quot;sorted&amp;quot; and &amp;quot;colored&amp;quot; versions of higher-order unification developed
by Michael Kohlhase and colleagues (Gardent and Kohlhase 1996b, 1997; Gardent Kohlhase, and van
Leusen 1996; Gardent, Kohlhase, and Konrad 1999).
</footnote>
<page confidence="0.984903">
503
</page>
<note confidence="0.357947">
Computational Linguistics Volume 26, Number 4
</note>
<bodyText confidence="0.464104333333333">
We illustrate this equivalence with the relevant instantiations for the following
cases (in fact, the reflexive case is done with a separate equivalence differing only in
that it mentions he-self instead of he, with associated differences in binding conditions):
</bodyText>
<listItem confidence="0.961493">
(3) Smith admires himself.
</listItem>
<equation confidence="0.966340785714286">
QLF=existsl()e.pos(pres(like(e,smith,he-self))))
Rest= AQ.Q(smith)
Pred=Ax-Ny.existsl(Ae.pos(pres(like,e,x,y)))
RLF=existsl(Ne.pos(pres(like(e,smith,smith))))
(4) Smith likes his computer.
QLF=existsl(Ae.pos(pres(like(e,smith,of(he,computer)))))
Rest= .Q.Q(smith)
Pred=Ax.Ay.existsl(Ae.pos(pres(like,e,x,of(y,computer))))
RLF=existsl(Ae.pos(pres(like(e,smith,of(smith,computer)))))
(5) Every manager likes his computer.
QLF (partially resolved) = forall(manager,)x.existsl(Ae.pos(pres(like,e,x,of(he,computer)))))
Rest=-AQ.forall(manager,Q)
Pred=Aa.Aliexistsl(Ae.pos(pres(like,e,a,of(b,computer))))
RLF forall(manager,Ax.existsl(Ae.pos(pres(like,e,x,of(x,computer)))))
</equation>
<bodyText confidence="0.99798375">
Note that here we have assumed that the quantifier has already been scoped.
We return later to issues of the interaction of scoping with ellipsis and anaphora.
In the meantime, we simply point out that bound variable uses of pronouns need no
extra mechanisms than those required for simple intrasentential pronouns.&apos;
It is easy to extend to far more complex cases of intersentential anaphora by
extending the definition of possibleAntecedent to allow for reference to different types
of antecedent. For example, if we adopt a theory like Webber&apos;s (Webber 1983), we
can construct discourse referents from the representation of quantified NP meanings.
Recall that in Webber&apos;s approach, a logical form representing the meaning of a sentence
processed in a discourse will trigger the application of rewrite rules, which will add
new entities to the context. For example, given a logical form that in our notation
would be:
</bodyText>
<equation confidence="0.970421666666667">
exists(cat,AX saw(I,X)))
a discourse entity like:
iota(AX.cat(X) &amp; savv(I,X) &amp; evoke(s1,X))
</equation>
<bodyText confidence="0.9996955">
will be produced, where iota is a term-forming operator interpreted roughly like a
definite description. (The evoke predicate serves as a unique identifier for the referent,
tagging it with a label for its source sentence.)
Webber&apos;s rules lend themselves very naturally to a higher-order formulation, al-
though when systems based on her theory have been implemented on a realistic scale,
they have been implemented either as code or as Lisp pattern-matching rules (Ayuso
</bodyText>
<footnote confidence="0.98227875">
4 A referee queries whether generating back out from the resolved form of (5) might not leave a
dangling variable when the quantifier scoping is undone. This is not so, for the simple reason that no
valid application of HOU could result in a previously lambda-bound variable becoming free. We need
no free variable constraints given this mechanism.
</footnote>
<page confidence="0.99082">
504
</page>
<equation confidence="0.5305972">
Putman Bidirectional Contextual Resolution
1989). Using HOU we can formulate an axiom to infer the existence of an entity of the
appropriate type:
Pred„,(existsc„,),)„(Restriction,Body))
existsl„)„(Ax.x=iota(Ay.Restrictron(y) &amp; Body(y)))
</equation>
<bodyText confidence="0.998567333333333">
The operator iota,,,,„ means here &apos;the (unique) thing satisfying (the intersection of)
restriction and body&apos;. An additional clause in the definition of possibreAntecedent essen-
tially encodes this inference:
</bodyText>
<equation confidence="0.9935546">
possibleAntecedent(Contexthe,DE)
if
Context = Pred,„(exists(Restriction,Body)),
isOfType(he,iota(Ax.Restriction(x) &amp; Body(x))),
defined(DE.iota(Ax.Restriction(x) 84 Body(x))).
</equation>
<bodyText confidence="0.9945194">
The predicate defined will succeed if there is already a discourse referent defined in
terms of this iota description. If there is not, it will create one (essentially a new
Skolem constant) and identify it with the iota term, asserting the definition. It is thus
not a strictly logical predicate, but is necessary for thoroughly familiar reasons.
This inference rule will handle well-known Netherlandish examples like:
</bodyText>
<listItem confidence="0.99564625">
(6) A man walked in a park. He whistled.
or:
(7) Smith owned a computer. It disappeared.
with the antecedent sentence in the latter being resolved as:
</listItem>
<bodyText confidence="0.85258625">
exists(computer,existsl(Ae.Ax.pos(past(own(e,smith,x))))
(We will turn below to the resolution of quantified noun phrases, but for now will
just assume the appropriate resolved forms.) The pronoun it here will be interpreted
as (say) ii, equivalent to:
</bodyText>
<equation confidence="0.967703">
iota()x.computer(x) &amp; existsl(Ae.pos(past(own(e,smith,x)))
</equation>
<bodyText confidence="0.979083133333333">
giving an RIT existsl(Af.pos(past(disappear(f,iI))). Thus it, in this context, is interpreted,
roughly, as &apos;the computer that figures in the eventuality of being owned by Smith&apos;. (In
the simple cases covered here, uniqueness of the eventuality and thus of the denotation
of the iota term are not actually guaranteed: in a fuller treatment of tense and aspect,
the eventuality described by the sentence will be uniquely identified and thus this
problem will not arise.)
The quantifier exists,„,„„,„ is here the translation of the indefinite article, although
as is well known this is not the only alternative. We could encode DRT-like analyses
directly via an equivalence creating a new discourse referent for an indefinite. On such
an analysis, the earlier pronoun equivalence would apply to this discourse referent just
as for a proper name, provided the appropriate number and gender information was
available.
By extending the definition of possibleAntecedent, we can combine with Webber&apos;s
approach aspects of the DRT theory of plurals (Kamp and Reyle 1993) to account for
examples like:
</bodyText>
<listItem confidence="0.868495">
(8) Every manager liked Smith. They admired him.
</listItem>
<page confidence="0.986533">
505
</page>
<note confidence="0.366361">
Computational Linguistics Volume 26, Number 4
</note>
<equation confidence="0.9317314">
possibleAntecedent(Context,they,DE)
if
Context = Pred(forall(Restriction,Body)),
isOfType(they,sigma(Ax.Restriction(x) &amp; Body(x))),
ciefine(DE,sigma(Ax Restriction(x) &amp; Body(x))).
</equation>
<bodyText confidence="0.867221333333333">
The antecedent sentence will be resolved to:
forall(manager,Ax.existsl()e.pos(past(like(e,x,smith)))))
Here they will be interpreted as i2, equivalent to:
sigma()x.manager(x) &amp; existsl(Ae.pos(past(like(e,x,smith)))))
where sigm„„ is an operator meaning &apos;the maximal set of things satisfying both
restriction and body&apos;. To get the details completely right, we would need to add some
extra machinery to our existing logic to model the distinction between singular and
plural, but there is no problem of principle in doing so, nor of extending to cases
where universals scope over existentials:5
</bodyText>
<equation confidence="0.9887574">
possi bleAntecedent(Context,they, DE)
if
Context = Pred(forall(R1,Ax. _(exists(R2, Body))),
i5OfType(they,sigma(Ax.R2(x) 84 exists( R1,Body)),
define(DE,sigma(Ax R2(x) &amp; exists(R1,Body))_
</equation>
<bodyText confidence="0.5426555">
(9) Every manager owns a computer. NLPcom supplied them.
The antecedent sentence is resolved, on the relevant scoping, to:
</bodyText>
<equation confidence="0.972947666666667">
forall(manager,Ax.(exists(computerdiy.existsl(Ae.pos(pres(own(e,x,y)))))))
The pronoun is resolved, on the relevant interpretation:
them =- i3 = sigma(Ax.computer(x) &amp; exists(manager,Ay.existsl(Ae.own(e,y,x))))
</equation>
<bodyText confidence="0.9975795">
Using HOU, we can easily formulate many more inferences that create new dis-
course entities. For example, plurals can be created by assembling terms from indi-
viduals mentioned in the context. Define &amp;quot;+&amp;quot; as a functor creating plural individuals
from its arguments:
</bodyText>
<equation confidence="0.766756666666667">
possibleAntecedent(Context,they,DE)
if
Context = Pred,„(X,Y),
isOfType(heSheOrit,X),
isOfType(heSheOrlt,Y),
define(DE,X+Y).
</equation>
<bodyText confidence="0.758542">
Now we can interpret sequences like:
</bodyText>
<listItem confidence="0.811451142857143">
(10) Smith sells the machines to NLPCom. They have a contract.
On one interpretation, they will be interpreted as the complex individual smith+n Ipcom.
Depending on the approach taken towards phenomena like collective versus distribu-
tive predication, this construct may be taken as the QLF or the RLF corresponding to
NP conjunction. In the former case, it may need further contextual resolution: again,
5 Just as with the original analysis, we will need to write different equivalences for the case where two
or more universals are involved, which is a little clumsy.
</listItem>
<page confidence="0.99545">
506
</page>
<subsectionHeader confidence="0.416395">
Putman Bidirectional Contextual Resolution
</subsectionHeader>
<bodyText confidence="0.9964585">
this depends on whether these distinctions are matters of resolution or inference from
a resolved logical form.
Note that all of the equivalences are reversible: in the generation direction those
which assume quantified NP antecedents presuppose that the RLF contains a discourse
entity (or, with minimal change, a sigma or iota term).
It is also possible to give a plausible analysis within this framework of more
difficult phenomena such as &amp;quot;donkey&amp;quot; sentences and dependent plurals, but the details
would take us too far afield.
</bodyText>
<subsectionHeader confidence="0.999896">
3.2 Definite Descriptions
</subsectionHeader>
<bodyText confidence="0.999247">
We can implement a simple Russellian theory of definite descriptions by means of the
following equivalence:
</bodyText>
<equation confidence="0.925406666666667">
The
Pred„„(thec_„).„(Restr)) Pred(Ref,)
if
salientContext(definite,Context)
possibleAntecedent(Context,the,Ref),
unique(Ref,Restr)
</equation>
<bodyText confidence="0.952695444444445">
where unique(Ref,Restr) is defined so as to be true if Ref is the only thing in the local
context that satisfies Restr.
Clearly, possihleAntecedent will be largely the same for definites as for pronouns,
although there will have to be provision for inferred antecedents (a car . . . the steering
wheel). In particular, we need to be able to create discourse entities for quantified
antecedents, plurals, etc. that are analogous to those we have been discussing for
pronouns.
(11) Smith bought a computer. The computer disappeared.
Smith hired Jones. The managers wrote a report.
Every manager uses a computer. The managers .../The computers...
If we allow the expressions created by possibleAntecedent identifying discourse refer-
ents with iota terms to figure as elements of the context (sentences of the form de-
(Ined(DiscRetiotaTerm)), then an initially surprising but rather natural consequence of
this formulation of the definite equivalence emerges. The resolved logical form for a
sentence containing a definite will have either a normal constant (a name) or a dis-
course referent as the equivalent of the definite description. When we try to generate
back out from the resolved logical form, name constants will be expressed either as
names or pronouns. Discourse referents will not give rise to sentences with names,
since the discourse referents are not entries in our lexicon. But since the expressions
that equate them with iota or other terms will be possible contexts, the equivalence
above will generate both the original definite description and a fuller one that re-
states the whole content of the iota term. We can illustrate this informally with the
sequence:
(12) Smith bought a computer. The computer disappeared.
In processing the definite description, we will use our version of Webber&apos;s rule em-
bodied in possibleAntecedent to create a discourse referent, say ii, from the existential
quantifier arising from the indefinite description a computer in the RLF acting as the
</bodyText>
<page confidence="0.986843">
507
</page>
<note confidence="0.438223">
Computational Linguistics Volume 26, Number 4
</note>
<bodyText confidence="0.9971115">
context. If the condition unique(il,computer) succeeds, which it will, then a side effect
of resolving the definite will be to add to the context the definition:
</bodyText>
<equation confidence="0.848438333333334">
defined(iLiota(Ax.computer(x) &amp; existsI.(Ae.pos(past(buy(e,smith,x)))))
The RLF for the sentence will be:
existsl(Ae.pos(past(disa ppear(e,i1)))
</equation>
<bodyText confidence="0.9854575625">
In trying to generate a paraphrase of this resolved logical form several equiva-
lences can apply. We can realize il as a pronoun by the pronoun equivalence earlier.
We can also realize il as a definite the computer by using the definite description equiv-
alence with the same variable instantiations as were just used in the interpretation
direction. One QLF produced by the equivalence with the definition above as the
value of the Context variable will have as the QLF for the subject of disappeared the
term the(Ax computer(x) &amp; exists1(Ae.pos(past(buy(e,smith,x)))), because il and this lambda
expression will be one of the solutions to the condition unique(Ref,Pred) in the equiva-
lence. It so happens that in the current grammar this QLF can be realized as an NP
with a tensed relative clause, so another paraphrase of the resolved logical form will
be:
(13) The computer that Smith bought disappeared.
In fact, similar effects can be obtained for pronouns if some small tweaks to the
relevant conditions are made: this turns out to be more than a neat trick, and is very
useful in providing informative feedback on what resolutions have been chosen, when
developing the system, or in the context of an application.
</bodyText>
<subsectionHeader confidence="0.983942">
3.3 Ellipsis
</subsectionHeader>
<bodyText confidence="0.999665">
Not surprisingly, we can adapt a version of the HOU approach to ellipsis resolution
(Dalrymple, Shieber, and Pereira 1991; Pulman 1991; Gawron 1992, 1995) very easily
within this framework. On the DSP approach to VP ellipsis, an elliptical sentence like:
</bodyText>
<listItem confidence="0.631079">
(14) John likes fish and Mary does too.
</listItem>
<bodyText confidence="0.977968">
will be analyzed as follows. Firstly (ignoring tense, too, etc.) we represent the meaning
of the elliptical conjunct with a free variable applied to the subject:
Ellipsis(mary)
Secondly we locate an element in the antecedent like(john,fish) that is parallel to mars&apos;,
namely john. Next we construct a HOU equation:
</bodyText>
<equation confidence="0.991452">
Ellipsis(john) = like(john,fish)
</equation>
<bodyText confidence="0.999648">
the relevant solution to which instantiates the Ellipsis variable to Ax.like(x,fish), which
when substituted in the elliptical phrase yields the correct result.
Our analysis is similar in spirit. However, at QLF we represent the semantics of
the elliptical sentence not with a free variable but by using the construct vpEllipsis„,.„.
The interpretation of this construct is given by the relevant equivalence:
</bodyText>
<equation confidence="0.888564428571429">
vp-ellipsis
X,„(exists1(Ae.(PolarityTenseEtc,„(vpEllipsis(e,Subject)))))
X„,(existsl(Ae.(PolarityTenseEtc,„(P red i cate(e$ u bject)))))
if
sa lientContext(vpEllipsis,Context),
Context =- Y(existsl(Af.(CPolarityTenseEtc(Predicate(f,CSubject))))),
parallel(Subject,CSubject)
</equation>
<page confidence="0.952081">
508
</page>
<subsectionHeader confidence="0.326248">
Pulman Bidirectional Contextual Resolution
</subsectionHeader>
<bodyText confidence="0.9949204375">
The predicate parallel implements the use of parallelism in this analysis. Note that the
equation in the second line of the equivalence uses HOU to simultaneously suggest
candidates for parallel elements and the value of the Predicate that corresponds to the
Ellipsis variable in the description of DSP above.
Some sortal conditions within both the equivalence and the predicate parallel are
necessary to make sure that the variables PolarityTenseEtc are appropriately instanti-
ated, since there are many possibilities consistent with their type requirements. But no
extralogical mechanisms are needed, apart from the definition of &amp;quot;parallel,&amp;quot; which is
intended to correspond to the notion discussed in Dalrymple, Shieber, and Pereira
(1991), Priist (1992), Hobbs and Kehler (1997), and Gardent and Kohlhase (1997),
among others. Parallelism may involve syntactic, semantic, pragmatic, and discourse
components, depending on the construction involved. VP deletion, for example, re-
quires the parallel element to be the subject of the preceding conjunct as well as being
in the same domain of quantification as the remnant; whereas phrasal ellipsis like
and John merely requires the antecedent to be in the same domain of quantification.
Now given a sequence like:
</bodyText>
<listItem confidence="0.573369">
(15) Smith liked Sandy. Jones didn&apos;t.
</listItem>
<bodyText confidence="0.986469">
where the antecedent logical form and the QLF to be resolved are respectively:
</bodyText>
<equation confidence="0.969218625">
existsl(Ae.pos(past(like(e,smith,sandy)))
neg(exists1(Alpast(vpell(f,jones)))
the variables in the Nip-ellipsis equivalence will be instantiated thus:
vp-ellipsis
Xt„(existsi(Ae.(PoiarityTenseEtc(vpEllipsis(e,Subject)))))
X(existsl(Ae.(PolarityTenseEtc,„(Predicate(e,Subject)))))
if
salientContext(ypEllipsis,Context),
% Context = existsl(Ae.pos(past(like(e,smith,sandy)))
% X -=- identity function of type t&gt;t
Context = Y(existsl(M.(CPolarityCTenseEtc(Predicate(f,CSubject))))),
% PolarityTenseEtc = Ax.pos(past(x))
% Y=neg, CPolarityCTenseEtc = Ax.past(x)
% Predicate = Ag.As.like(g,s,sandy)
% Subject, CSubject jones, smith respectively
parallel(Subject,CSubjectC)
</equation>
<bodyText confidence="0.948777666666667">
When the Predicate is applied to the event and subject arguments on the right-hand
side of the equivalence, the correct interpretation is obtained.
Again, this is completely reversible. If we were instead generating from the se-
quence of logical forms:
existsl(Ae.pos(past(like(e,smith,sandy)))
neg(existsl(Af.past(like(f,jones,sandy)))
the equivalence, and the associated conditions, can apply in the same way to licence
a QLF with the ypEllipsis construct in it, causing an elliptical sentence to be generated
from that QLF.
</bodyText>
<subsectionHeader confidence="0.389269">
3.4 Focus
</subsectionHeader>
<bodyText confidence="0.552196333333333">
Let us turn now to examples involving focus-sensitive adverbs. (A more elaborate
treatment of a wider range of focus phenomena within the current framework can
be found in Pulman [1997b]. An extension of some of these analyses can be found in
</bodyText>
<page confidence="0.989974">
509
</page>
<bodyText confidence="0.761512">
Computational Linguistics Volume 26, Number 4
Gardent and Kohlhase [19964. We will illustrate with the adverb too, as in:
</bodyText>
<listItem confidence="0.538763">
(16) a. Smith likes Sandy. Jones likes Sandy too.
b. Smith likes Sandy. Jones does too.
</listItem>
<bodyText confidence="0.99956725">
To a first approximation, use of too is appropriate if the sentence asserts that
something similar but not identical to a previous event or state occurred. The two
sentences must share some information, or they must contain parallel information,
and must differ on at least one point: the different components are focused, in the
sense that the main stress when the sentence is spoken will fall on those constituents:
Jones in the example). We encode this analysis by treating too as a QLF construct
that takes as arguments the meaning of the focused constituent and the meaning of
the sentence itself (without too). The information structure requirements on too are
(partly) captured in the conditions on the following equivalence that interprets this
QLF construct: the instantiation of the Shared variable will contain what is similar
but the Focus variable states what is different. However, as for ellipsis, the focused
constituent must be parallel to the corresponding item in the antecedent expression.
</bodyText>
<equation confidence="0.945542777777778">
Too-focus
Rest1„(exists1 Ae.Rest,„(too(Focus,Pred(e,Focus))))
Restl,..„(exists1 )e.Rest,„(Pred(e, Focus))))
if
salientContext(too-focus,Context),
Context -= _X(existsl(Af.Shared(f,Anter,),
parallel(Shared,Pred),
paraliel(AnteTywFocusT,),
not(Ante=Focus)
</equation>
<bodyText confidence="0.999883333333333">
Since focus can fall on almost any constituent in a sentence, the type of the Focus
variable, and consequently that of too are not completely fixed. (Note that this poly-
morphism means that in the case where the type of a term cannot be inferred before
HOU, some preprocessing to instantiate the type variable with likely candidates may
be required, since the HOU algorithm requires the inputs to be fully typed.)
In processing the second sentence of (16a), variables will be instantiated as follows:
</bodyText>
<equation confidence="0.969624625">
QLF:existsl(Ae.too(jones,pos(pres(like(e,jones,sa ndy)))))
Too-focus
Rest1,=„(exists1 Ae.Rest,„(too(Focus,Pred(e,Focus))))
Rest1.„(exists1 Ae.Rest„„(Pred(e,Focus))))
if
sahentContext(too-focus,Context),
% Context = existsl(Af.pos(pres(like(f,smith,sandy))))
% Restl,Rest = identity
Context = _X(existsl(Af.Shared(CAnte,e),
% Shared = )g.Ax.pos(pres(like(g,x,sandy)))
Pred = Ah.Ay.pos(pres(like(h,y,sandy)))
% Ante smith, Focus = jones
parallel(Shared,Pred),
paraliel(Anter„,Focus,„.),
not(Ante-=-Focus)
RLF:existsl(Ah.pos(pres(like(h,jones,sandy))))
</equation>
<bodyText confidence="0.9942285">
On our analysis, too adds nothing to the truth conditions of an utterance, but
merely serves to compare and contrast with the context.
</bodyText>
<page confidence="0.958818">
510
</page>
<subsectionHeader confidence="0.254649">
Putman Bidirectional Contextual Resolution
</subsectionHeader>
<bodyText confidence="0.99150725">
Notice that Too-focus will also apply in (16b) along with VPEllipsis. The order of
application of equivalences is in general not significant, except that one order may be
computationally more efficient than another. In this case, both orders of application
result in the same interpretation. The exception to this is that the equivalences for
interpreting unscoped quantified NPs, described below, may apply several times in a
sentence containing more than one quantifier and different orders of application will
correspond to different scopings, if these are permitted by the contextual conditions.
Now consider an example in which we will assume that the focused element
cannot be determined from the linguistic form, and is thus represented at QLF by a
free variable. It is of course important for computational purposes not to be committed
to an analysis of focus that requires it to be overtly marked in a sentence, for essentially
the same reason that it is important not to require quantifier scopes to be explicitly
represented: combinatorial explosion. Narrow focus can be marked virtually anywhere
in a sentence and to treat a sentence with no apparent focus marking as ambiguous
between all possible focus markings would be computationally disastrous (as well as
not very plausible psychologically).
Assume that we are analyzing the same sequence as before (16a), but that the
focus is not marked intonationally. The QLF will be:
existsl(Ae.pos(pres(too(Focus,like(ejones,sandy))))
Applying the Too-focus equivalence will instantiate the variables in it as before,
except that since Focus is not instantiated there would, in the absence of any constraints
from context, be multiple solutions for it (and hence for Pred), in which Focus is in-
stantiated to any constituent of the sentence. However, if the contextual conditions in
the equivalence are to be satisfied, then only the solution on which Focus=jones will be
found, for on all the others it will be impossible to find values for Shared and Ante that
meet the various requirements of parallelism and nonidentity. This corresponds with
the observation that if focus is explicitly marked in the too sentence, it must fall on
Jones, for no other choice is coherent (in that context).
</bodyText>
<listItem confidence="0.955754">
(17) a. Smith likes Sandy. ??Jones likes SANDY too.
b. Smith likes Sandy. ??Jones LIKES Sandy too,
</listItem>
<bodyText confidence="0.9964088">
To conclude the focus examples, we illustrate the way that higher-order unification and
abduction can work together to add something to the context, in those cases where
there is a context, but where it does not at first sight support the appropriate use
of a focusing device. Consider the following sequence in a context where the hearer
happens not to know that an iMac is a computer:
</bodyText>
<listItem confidence="0.639722">
(18) a. Jones bought an iMac.
b. Smith has a new computer too.
</listItem>
<bodyText confidence="0.985664285714286">
We will simplify the QLF to:
existsl(Ae.pos(pres(too(smith,have(e,smith,a-new-computer))))
In attempting to satisfy the conditions for the Too-focus equivalence, we will not
be able, let us assume, to find a suitable Context to serve as an expression providing
an antecedent, nor be able to solve the equation Context=_X(exists1Pd.Shared(f,AnteTip.)).
However, we do know the values of Pred=Ag.Ax.pos(pres(have(g,x,a-new-computer))) and
Focus=smith.
</bodyText>
<page confidence="0.968049">
511
</page>
<note confidence="0.4178">
Computational Linguistics Volume 26, Number 4
</note>
<bodyText confidence="0.995195823529412">
Recall that we are assuming that the various conditions in equivalences are goals
to be proved in the manner of Prolog or similar inference methods. Thus a predicate
like parallel can be called with or without arguments instantiated. Defining such a
predicate in the general case is not trivial, but it is clear that one clause in its definition
should be parallel(A,A). Other clauses should search in the context for entities of similar
type and sortal status to any instantiated arguments. Thus if we call parallel(A,smith)
or parallel(B,Pred) we will get back as solutions (among others, perhaps) that A=jones
and that B=Pred--Agitx.pos(pres(have(g,x,a-new-compater))). These instantiations will also
instantiate the Context variable via the equations in the equivalence, to:
ex istsl ()e. pos( pres( h ave(e jones , a - new-com put er)) ))
By an abductive step, we can add this to the context as an irnplicature or &amp;quot;accom-
modation&amp;quot; that is needed to make sense of the focus structure of the sequence (18).
The relation between utterance, focus, and context is such that either of the lat-
ter two reiata can be incompletely specified without preventing interpretation of the
former. Any analysis of focus should be able to capture this phenomenon. The vi-
tal ingredient of the analysis here is the nondirectionality of inference provided by
higher-order unification, supplemented by abduction.
</bodyText>
<subsectionHeader confidence="0.862598">
3.5 Quantifier Scope
</subsectionHeader>
<bodyText confidence="0.99937925">
We can implement a deductive theory of quantifier scope using the conditional equiv-
alence mechanism. The version proposed here combines a basic insight from Lewin
(1990) with higher-order unification to give an analysis that has a strong resem-
blance to that proposed in Pereira (1990, 1991), with some differences that are com-
mented on below. Like Pereira&apos;s approach, it avoids the need for a free variable con-
straint, nor does it need the explicit recursion on the quantifier restriction imposed by
Lewin.
We analyze quantified NPs at the QLF level as illustrated in the QLF for:
</bodyText>
<listItem confidence="0.55575">
(19) Every manager uses a computer.
ex istsl ( e. pos( pres( u se(e,eve ry( m a na ger), a c.,„„(com put er))))
</listItem>
<bodyText confidence="0.958802307692308">
We assume that every determiner has its own equivalence, which resolves it as a
quantifier: sometimes this can be quite a complicated matter, as with any (Alshawi
1990), which will resolve in different ways depending on its linguistic context, but
here we avoid this complexity&apos;
6 Separate equivalences might also make it easier to encode determiner-specific preferences, such as that
of each for wide scope. A referee points out that the lack of any explicit ordering of application of
equivalences makes one natural way of doing this unavailable. But I am not convinced that this would
have been the right way in any case. These preferences are just that, not hard and fast rules, so we
need to be able to permit all permutations where the context, or the structure, prefers the less frequent
interpretation, as in examples like the following (from the LOB corpus), where the most salient reading
is that in which a bird outscopes each:
(i) Out of a total of 100 marks which are to be allocated, 15 are awarded for these attributes, and it has
to be remembered that a bird has to earn each one of them when on the judging bench.
</bodyText>
<page confidence="0.96925">
512
</page>
<figure confidence="0.526973428571429">
Pulman Bidirectional Contextual Resolution
The equivalence for every is:
Every
Rest,„(Pred„„(every(Nom„,)))t ,#• Rest.,„(forall(Nom„,,,Pred„j),
if
salientContext(q uant, Context),
scopelsLicensed.
</figure>
<bodyText confidence="0.98892">
The final condition is a placeholder to allow for the encoding of whatever struc-
tural constraints and preferences on quantifier scopes are thought to be necessary.
Applying the equivalence to the QLF above gives us this solution:
</bodyText>
<equation confidence="0.947329555555556">
Rest,„(Pred(every(Nom.„))), Rest,„(forall(Nom„„,Pred„)),
if
% Rest = identity
% Pred = Ax.exists10,e.pos(pres(own,e,x,a(computer))))
% Nom = manager
sa lientContext(qua nt,Context),
scopelsLicensed. .
The RLF is:
fora 11(manager,Ax.exists1(Ae.pos(pres(ovvn(e,x,a(com puter))))))
</equation>
<bodyText confidence="0.9868575">
This still contains the QLF construct a and so the analogous equivalence for a (which
we will continue to treat as a quantifier here for illustration) can apply:
</bodyText>
<equation confidence="0.459884625">
A
Rest„,(PrecL„(a(Nom))), &lt;=&gt; Rest(exists(Nome„, Precf,„)),
if
% Rest = identity
% Pred = Ay.forall(manager,Ax.existsl(Ae.pos(pres(own(e,x,y)))))
% Nom -= computer
salientContext(quant,Context),
scopelsLicensed.. .
</equation>
<bodyText confidence="0.936967142857143">
The final RLF is then:
exists(computer,Ay.forall(managerAx.existslpe.pos(pres(own(e,x,y))))))
provided that the scoping constraints and the context permit this interpretation.
The ordering of equivalences is not fixed: they simply apply nondeterministically
as permitted by the relevant contextual conditions. We could have applied the two
quantifier equivalences in a different order, leading to the alternative partial and then
full scoping:
</bodyText>
<equation confidence="0.63077">
exists(computerAi.exists1(Ae.pos( pres(own(e,every(manager),y)))))
forali(manager,Ax.exists(computer,Ay.existsl(Ae.pos(pres(use(e,x,y)))))
</equation>
<bodyText confidence="0.9813698">
This is a somewhat incomplete treatment of the relationship between events and
quantifier scope, of course.
Because of the particular logical syntax we are using, we need to add another
version of the quantifier equivalences to allow for application inside the restriction of
the body of an already scoped quantifier:
</bodyText>
<equation confidence="0.505599666666667">
Every2
Rest„(Ax. Pred„e„(x,every( Nom)))
Rest(,„)„(Ax.forall(Nom,Ay.PrecLe„(x,y)))
</equation>
<bodyText confidence="0.272235">
if
salientContext(quant,Context),
scopetsLicensed..
</bodyText>
<page confidence="0.978641">
513
</page>
<note confidence="0.627283">
Computational Linguistics Volume 26, Number 4
</note>
<bodyText confidence="0.933996625">
We could avoid this inelegance by using polymorphism in the equivalences, or
some &amp;quot;syntactic sugar&amp;quot; in the logical forms to produce a more uniform representation.
As will be seen below, we need in any case something like the pair quantifier notation
of Dalrymple, Shieber, and Pereira (1991), which would also solve this problem. With
this addition we are able to produce both scopings for examples like:
(20) Every manager in some company disappeared.
This is a rather oversimplified treatment of quantifier scope, which we will refine
a little shortly, but even as it stands the treatment has several advantages:
</bodyText>
<listItem confidence="0.84104975">
• in classic examples like:
(21) Every representative in a company saw most samples.
only the available five relative scopings of the quantifiers are produced
(Hobbs and Shieber 1987, 47), but without the need for a free variable
constraint—the HOU algorithm will not produce any solutions in which
a previously bound variable becomes free;
• the equivalences are reversible, and thus the above sentences cart be
generated from scoped logical forms;
• partial scopings are permitted (see Reyle [19961)
• scoping can be freely interleaved with other types of reference resolution;
• unscoped or partially scoped forms are available for inference or for
generation at every stage.
</listItem>
<subsectionHeader confidence="0.999566">
3.6 Comparison with Deductive Interpretation
</subsectionHeader>
<bodyText confidence="0.960324470588235">
It is interesting to compare this analysis with that described in Dalrymple, Shieber,
and Pereira (1991) and Pereira (1990, 1991). Recall that in their treatment, quantified
noun phrases are treated in two stages: firstly, what they call a &amp;quot;free variable&amp;quot; of
type e is introduced in the NP position, with an associated &amp;quot;quantifier assumption,&amp;quot;
which is added as a kind of premise. At a later stage the quantifier assumption is
&amp;quot;discharged,&amp;quot; capturing all occurrences of the free variable. Thus their analysis of
something like every manager disappeared would proceed as follows:
every manager --= every(x,manager(x)) x
disappeared disappear
every manager disappeared every(x,manager(x)) disappear(x)
- discharge the assumption: every(x,manager(x),disappear(x))
In the final logical form, I am using an informal representation of their &amp;quot;pair&amp;quot; no-
tation for generalized quantifiers, which uses the same variable in both the restriction
and the body, unlike the one we have been using. If we make a comparison between
the way phenomena such as antecedent contained deletion are treated in our two
frameworks, we can see that we also need such a notational change.
DSP&apos;s analysis of the relevant antecedent contained deletion cases goes like this:
</bodyText>
<listItem confidence="0.713621">
(22) a. John greeted every person when Bill did.
b. John greeted every person that Bill did.
</listItem>
<page confidence="0.975518">
514
</page>
<table confidence="0.449944">
Pulman Bidirectional Contextual Resolution
</table>
<bodyText confidence="0.860621">
In (22a), the context for the ellipsis is the first conjunct, analyzed as:
</bodyText>
<equation confidence="0.76594075">
every x person(x) greet(john,x) when P(bill)
The equation is P(john)greet(john,x), with P=Az.greet(z,x). The interpretation for the
whole sentence is now:
every x person(x) greet(john,x) when greet(bill,x)
When the quantifier is discharged, both occurrences of the variable x are bound:
every(x,person(x), greet(john,x) when greet(bill,x))
If the quantifier is discharged first, then the context for the ellipsis is:
every(x, person(x),greet(john,x))
</equation>
<bodyText confidence="0.922345">
and the equation is:
</bodyText>
<equation confidence="0.817809833333333">
every(x, person (x),greet( joh n ,x)) = P(john)
with P= Az.every(x,person(x),greet(z,x))
Now the interpretation for the whole sentence is:
every(x,person(x),greet(john,x)) when every(x,person(x),greet(bill,x))
For (22b), the QLF is
every x person(x) &amp; P(bill) H greet(john,x)
</equation>
<bodyText confidence="0.9692895">
The equation is: P(john)=greet(john,x),with P=Az.greet(z,x), immediately giving the right
result. If the quantifier is discharged first, then the QLF is
</bodyText>
<equation confidence="0.844965666666667">
every(x,person(x) &amp; P(bill),greet(john,x))
But now the equation will be
P(john) = every(x,person(x) &amp; P(bill),greet(john,x))
</equation>
<bodyText confidence="0.99003875">
which is invalid because P is on both sides, leading to an &amp;quot;occurs check&amp;quot; violation.
Note that there is a somewhat uneasy mixture of logic and metalogic involved in
the DSP analysis, caused by merging the deductive, assumption-based reasoning, and
straight higher-order unification. When the quantifier is undischarged, the associated
so-called free variable is not treated as such when solving the HOU equations. It has
to be treated as a (unique) constant in order to get the right result. When the quantifier
has been discharged, all occurrences of this constant are treated as bound variables.
We have to assume that the HOU algorithm has to be told what status particular
occurrences of the variable actually have, because their analysis involves applications
of HOU under both guises.&apos;
In our system we run into some of the same problems as DSP, but from a slightly
different perspective. The analogous QLF, represented in a simplified form akin to that
in DSP for ease of comparison, for (22a) is:
when(greet(johnrevery(person)), VPELL(bill))
If we use the first, unscoped, conjunct as context for the ellipsis, then we get the right
result:
</bodyText>
<equation confidence="0.970943">
VPELL(john) greet(john,every(person)), VPELL= Ay.greet(y,every(person))
when(greet(john,every(person))),greet(bill,every(person)))
</equation>
<bodyText confidence="0.910160666666667">
After scoping the two conjuncts we will get the reading on which the greetings are
independent. If we had scoped the QLF first we would get:
fora II(p erson Ax when (greet( jo h n ,x),VPELL(bill)))
</bodyText>
<footnote confidence="0.956367">
7 Pereira acknowledges this elsewhere: (Pereira 1991, footnote 3): &amp;quot;The direct replacement of ellipsis
equation solutions into derivations and subsequent normalisation of the result involve some abuse of
the formalism...&amp;quot;
</footnote>
<page confidence="0.979175">
515
</page>
<note confidence="0.632777">
Computational Linguistics Volume 26, Number 4
</note>
<bodyText confidence="0.9979733">
The equation we need is VPELL(john) = greet(john,x), which also requires us to treat
the x as a constant. However, it is plausible to assume that for sentence-internal ellipsis,
we will need a different control regime for application of equivalences. So far we have
been assuming that each equivalence applies to an entire QLF, but for cases where
some earlier portion of the sentence is acting as the context then this will not be
possible. Assuming instead that a recursive traversal of the QLF is involved, then this
particular unification equation will be formed and solved entirely within the scope of
the lambda binding x. In terms of Huet&apos;s algorithm, then, x will count as a &amp;quot;rigid&amp;quot;
variable, that is, it will be semantically like a constant.
For (22b), our QLF is
</bodyText>
<equation confidence="0.948393">
greetaohn,every(Ax.person(x) 8.4 VPELL(bill)))
</equation>
<bodyText confidence="0.999038">
With the every unscoped, there is no choice of context which contains a parallel ele-
ment to bill that does not also contain the VPELL functor, leading to an infinite regress,
analogous to the &amp;quot;occurs check&amp;quot; failure in DSP. Thus we correctly cannot produce the
unavailable reading. However, if we try to resolve the ellipsis after scoping, we have:
</bodyText>
<equation confidence="0.928013">
forall(Ax.person(x) &amp; VPELL(bill),Aygreet(john,y))
</equation>
<bodyText confidence="0.99980825">
This will not succeed either, because the choice of context will have to be greet(john,y),
but in this expression, y really is free and so we do not have a valid equation. We
would have to adopt Pereira&apos;s pair notation for our quantifiers in order to make sure
that the equation was valid:
</bodyText>
<equation confidence="0.764087">
forall()x. person(x) &amp; VPELL(bill),greet(john,x)))
</equation>
<bodyText confidence="0.999088956521739">
Now everything is taking place within the scope of the lambda, as above. Note that
this chain of reasoning is, rnutatis mutandis, exactly the same motivation for DSP&apos;s
use of the pair notation.
Given our different control regime for the application of equivalences, and the pair
quantifier notation, we appear to avoid the need for the sleight of hand involved in
the dual nature of DSP&apos;s assumption variables. However, what is arguably the same
problem in a different guise occurs when we examine the interaction of our scoping
equivalence and that for sentence-internal pronoun reference given earlier. Recall that
this equivalence will identify a pronoun with any term of type e elsewhere in the
QLF provided the usual binding and agreement conditions are met. Unfortunately,
in our analysis, quantified NPs are also of type e and thus we will produce invalid
interpretations in cases where the equivalence applies before the quantifier has been
scoped. Thus, as well as the correct bound variable interpretation for a sentence like
every manager likes his secretary, we will also produce the structure corresponding to
every manager likes every manager&apos;s secretary. What we need is some way of capturing
the fact that NPs like every manager, although of type e, have to be treated differently
than NPs like Smith. A simple way of doing this would be to introduce subtypes of
e, so that both types of NP would still be of type e but they could be distinguished
where necessary. The Pron-intra equivalences would then be restricted to apply only
to names or variables. This has the advantage that we still stay within the same logical
framework (Kohlhase and Pfenning [1993] show how to extend HOU to accommodate
subtypes), although of course we are really using subtypes here to record a syntactic
distinction that has been erased in the course of constructing the QLF.
</bodyText>
<sectionHeader confidence="0.536508" genericHeader="method">
4, An Implementation
</sectionHeader>
<bodyText confidence="0.992267">
A small implementation which (with the exception of the examples just discussed,
and those needing abduction) covers all of the phenomena described so far has been
developed. It uses a simple unification grammar (based on the formalism described in
</bodyText>
<page confidence="0.987156">
516
</page>
<table confidence="0.41726">
Putman Bidirectional Contextual Resolution
</table>
<bodyText confidence="0.98314324">
(Pulman, 1996)) to produce QLFs. The same grammar is used in generation to produce
sentences from QLFs.
Equivalences are interpreted using a Prolog implementation of Huet&apos;s algorithm
for higher order unification, with some additional heuristics to bound search in the
case where terms of high order are encountered. The implementation is aimed at clarity
rather than efficiency but is still not disastrously inefficient (rather to my surprise, I
might add). The whole process of parsing, resolving, and generating a paraphrase of
the resolved LF for the following tittle text takes about 30 seconds on a 300 MHz
laptop PC. (X —Body is the notation for Ax Body. Upper case in the input (or output)
corresponds to narrow focus intonation).
Smith hired Sandy.
They wrote a report.
Jones read it.
He liked the report.
He is a manager.
Sandy likes him.
Smith doesn&apos;t.
HE likes Roberts.
SANDY does too.
Working through the examples we show the input sentence; the (first) QLF found
for it; the (first) RLF found for the QLF given the context (usually just the preceding
RLF); and as full as possible a paraphrase of the RLF which we get by reversing
the equivalences and applying them in a null context to obtain a QLF which we
then generate from. Note that in this implementation the existentially quantified event
variable has been Skolemised.
</bodyText>
<table confidence="0.248007">
&gt; Input: Smith hired Sandy.
QLF:pos(past(hire(e0,smith,sandy)))
RLF:pos(past(hire(e0,smith,sandy)))
Resolved as: smith hired sandy.
No resolution is needed in this example, since there is no preceding context.
&gt; Input: They wrote a report.
CILF:pos(past(write(el,they,a(report))))
RLF:exists(report,A--pos(past(write(el,npand(smith,sandy),A))))
Resolved as: smith and sandy wrote a report.
</table>
<bodyText confidence="0.988269090909091">
npand is the &apos;+&apos; operator described in the text. it corresponds to one QLF construct for
NP conjunction, hence the informative paraphrase. If we ask for more paraphrases
with the previous sentence serving as a context we get:
he and sandy wrote a report.
he and sandy wrote some report,
he and she wrote a report.
he and she wrote some report.
smith and sandy wrote some report.
smith and she wrote a report.
smith and she wrote some report.
(Some&apos; is treated as synonymous with &apos;a&apos;, which is not quite correct).
</bodyText>
<page confidence="0.578909">
&gt; Input: Jones read it.
517
</page>
<figure confidence="0.458325">
Computational Linguistics Volume 26, Number 4
QLF:pos(past(read(e2,jones,it)))
RLF:pos(past(read(e2,jones,13)))
Resolved as: jones read the report that smith and sandy wrote.
</figure>
<bodyText confidence="0.9993965">
In this version we have incorporated the tweaks to allow for informative paraphrases
of pronouns described earlier. &apos;i3&apos; is a Webber-style discourse referent corresponding
to &apos;a report&apos;. It is identified with an iota term which supports the use of the definite
in paraphrasing the resolved LF. Further paraphrases reveal the well-known problem
that generated sentences may be ambiguous in a potentially confusing way:
jones read the report that he and sandy wrote.
jones read the report that he and she wrote.
Jones read the report that smith and she wrote.
</bodyText>
<listItem confidence="0.5679465">
&gt; Input: He liked the report.
QLF:pos(past(like(e4,he,the(report))))
RLF:pos(past(like(e4,jones,i3)))
Resolved as: jones liked the report that smith and sandy wrote.
</listItem>
<bodyText confidence="0.921176666666667">
The same paraphrasing behavior happens more or less automatically for definites.
Alternative paraphrases for the RLF should include &apos;Jones liked it&apos;, and &apos;Jones liked
the report&apos;.
</bodyText>
<listItem confidence="0.981189636363636">
&gt; Input: He is a manager.
QLF:pos(pres(be(e5,he,a(manager))))
RLF:exists(manager,A--pos(pres(be(e5,jones,A))))
Resolved as: jones is a manager.
&gt; Input: Sandy likes him.
QLF:pos(pres(like(e6,sandy,he)))
RLF:pos(pres(like(e6,sandy,jones)))
Resolved as: sandy likes jones.
&gt; Input: Smith doesn&apos;t.
QLF:neg(pres(vpell(e7,smith)))
RLF:neg(pres(like(e7,smith,jones)))
</listItem>
<bodyText confidence="0.8409258">
Resolved as: smith doesn&apos;t like jones.
This is an example of simple VP ellipsis. Alternative contextualized paraphrases are:
smith doesn&apos;t.
smith doesn&apos;t like him.
Now we have set up a context in which contrastive focus is appropriate:
</bodyText>
<equation confidence="0.870316">
&gt; Input: HE likes Roberts.
QLF:focus(he,pos(pres(1ike(e8,he,roherts))))
RLF:focus(smith,pos(pres(like(e8,smith,roberts))))
Resolved as: SMITH likes roberts.
</equation>
<bodyText confidence="0.947796333333333">
This example shows a QLF construct (from (Pulman, 1997b)) not discussed earlier,
and for which no equivalence has been written yet. Thus the input is only partly
resolved and focus is retained in the paraphrase.
</bodyText>
<footnote confidence="0.810826">
&gt; Input: SANDY does too.
QLF:pos(pres(too(sandy,vpell(e9,sandy))))
RLF:pos(pres(like(e9,sandy,roberts)))
Resolved as: sandy likes roberts.
</footnote>
<page confidence="0.94984">
518
</page>
<table confidence="0.510872285714286">
Putman Bidirectional Contextual Resolution
A combination of VP ellipsis and too-focus as described earlier. Contextualized alter-
natives are:
SANDY likes him too.
SANDY likes roberts too.
sandy does.
sandy likes him.
</table>
<bodyText confidence="0.95959325">
This reveals a bug somewhere, as we do not get out the sentence we put in, which
should always be one of the options.
Here is the Hobbs-Shieber scope example, from a slightly differently configured
version of the system in which the event variable is explicitly quantified rather than
</bodyText>
<equation confidence="0.984030275862069">
Skolemised.
I ?- ana(revery,manager,in,some,company,owns,a,cari,RLF,null:t),
display_in_readable_form(RLF,LF).
% every, some, a
LF = forall(A--exists(company,
B--and(manager(A),in(A,B))),
C--exists(car,
D--exists1(E--pos(pres(own(E,C,D))))))
% some, every, a
LF = exists(company,
A-^forall(B--and(manager(B),in(B,A)),
C—exists(car,
D--exists1(E--pos(pre5(own(E,C,D)))))))
% a, every, some
LF = exists(car,
A--forall(B--exists(company,C--and(manager(B),in(B,C))),
D--exists1(E--pos(pres(own(E,D,A))))))
% some, a, every
LF = exists(company,
A--exists(car,
B--forall(C--and(manager(C),in(C,A)),
D^-existsi(E--pos(pres(own(E,D,B)))))))
% a, some, every
LF = exists(,
A-^exists(company,
car
B--forall(C--and(manager(C),in(C,B)),
D--exists1(E--pos(pres(own(E,D,A))))))),
no
</equation>
<bodyText confidence="0.99699125">
The missing combination which is correctly excluded is every - a - some.
Clearly, these are small beginnings. But this small scale implementation demon-
strates that the approach is computationally viable in principle. Issues to do with how
to scale up to wider coverage are addressed later.
</bodyText>
<sectionHeader confidence="0.724952" genericHeader="method">
5. Comparison with Alternative Approaches
</sectionHeader>
<subsectionHeader confidence="0.785687">
5.1 Core Language Engine Quasi-Logical Form
</subsectionHeader>
<bodyText confidence="0.997297">
The starting point for the approach followed here was a dissatisfaction with certain
aspects of the theory of quasi-logical form as described in Alshawi (1990, 1992), and
implemented in SRI&apos;s Core Language Engine (CLE). In the CLE-QLF approach, as ra-
</bodyText>
<page confidence="0.994153">
519
</page>
<note confidence="0.643638">
Computational Linguistics Volume 26, Number 4
</note>
<bodyText confidence="0.999930055555556">
tionally reconstructed by Alshawi and Crouch (1992) and Crouch and Putman (1994),
the context-independent meaning of a sentence is given by one or more QLFs that
are built directly from syntactic and semantic rules. Just as here, these QLFs repre-
sent the basic predicate argument structure of the sentence, and contain constructs
which represent those aspects of the meaning of the sentence that are dependent on
context.
The effects of contextual resolution are uniformly represented via the instantiation
of metavariables. This instantiation is brought about by the operation of resolution
rules, which are essentially user-defined Prolog predicates finding appropriate instan-
tiations for metavariables from the current context. Contextual resolution is therefore
a process of adding information to an underspecified meaning representation until it
is sufficiently specified for the task at hand. (In translation, for example, it need not
be fully specified. For tasks like database query, it usually will have to be). This pro-
cess is completely monotonic and therefore fulfils a necessary (though not a sufficient)
condition for reversibility.
Some simplified examples will give the flavor of this theory. A pronoun is rep-
resented at QLF by a term containing essentially a syntactic category, an index, a
restriction predicate, and a metavariable; schematically:
</bodyText>
<equation confidence="0.643497">
term(pro,&lt;idx&gt;,&lt;restriction&gt;,&lt;metavrble&gt;)
</equation>
<bodyText confidence="0.99945625">
Thus a sentence like he sneezed will, ignoring tense and aspect, be represented as
follows at the QLF level; and, when the metavariable has been instantiated to the
contextually preferred candidate referent, at the resolved quasi-logical form (RQLF )
level:
</bodyText>
<equation confidence="0.999796">
QLF = sneeze(term(pro,+1,masc,Referent))
RQLF = sneeze(term(pro,+1,masc,john))
</equation>
<bodyText confidence="0.99874075">
Scoping of quantifiers is also a matter of instantiating metavariables. QLF formulas
containing quantifiers are prefixed by a scoping metavariable which scoping resolution
rules instantiate to a list of the indices associated with quantifiers, in an order that
indicates the preferred scoping:
</bodyText>
<equation confidence="0.9845913">
QLF =
Scope:like(term(q,every,+1,philosopher),
term(chsome,+2,book))
RQLF =
L+1,+2]:like(term(q,every,+1,philosopher),
term(q,some,+2,book))
% every some ...
[+2,+1]:1ike(term(q,every,+1,philosopher),
term(q,some,+2,book))
% some ... every ...
</equation>
<bodyText confidence="0.99993125">
The denotational semantics of RQLF structures involving instantiated scope and
referent metavariables is given in terms of simple interpretation rules that have the ef-
fect of interpreting the quantifiers as having the scopes indicated by the lists of indices,
and the pronouns as having the interpretation of the instantiation of the metavariable
(in these cases at least).
Alshawi and Crouch (1992) present an illustrative first-order fragment along these
lines and are able to supply a coherent formal semantics for the CLF-QLFs themselves,
using a technique essentially equivalent to supervaluations: a QLF is true iff all its
possible RQLFs are, false iff they are all false, and undefined otherwise.
There are many good things about this approach. It has proved itself amenable
to a large-scale implementation of impressive coverage, generality, and relative effi-
ciency (Alsha.wi 1992). It has the theoretically desirable property of monotonicity and,
</bodyText>
<page confidence="0.986362">
520
</page>
<table confidence="0.261639">
Pulman Bidirectional Contextual Resolution
</table>
<bodyText confidence="0.984226163265306">
in practice, a large degree of reversibility. In the implementation, generation can take
place from the QLF level, or from resolved QLF. (Which is the appropriate level de-
pends partly on the application: generation from QLF is all that is needed for many
types of translation, for example. Generation from resolved QLF is chiefly used for
checking with a user that resolution has accurately resolved contextually dependent
constructs.) Furthermore, QLF has, in principle at least, a coherent formal semantics via
the supervaluation technique—these are not uninterpreted representations (although
the supervaluation semantics does not lead to an appropriate consequence relation, as
we shall see below).
Nevertheless, there are several aspects of the theory that are not completely satis-
factory Firstly, the QLFs themselves, although they are built by technically composi-
tional semantic rules from syntactic structures, contain many constructs that are solely
motivated by the requirements of the resolution process. QLFs contain, to take the
most obvious example, indices and metavariables: constructs for which there is no
apparent motivation in the syntax and morphology of English.
Secondly, the semantic relation between underspecified QLFs and their further
specified RQLF representations is given entirely in terms of subsumption: a QLF sub-
sumes all its possible RQLFs. They differ syntactically only via the instantiation of
metavariables, giving a particularly simple way of determining subsumption. But this
notion of subsumption does not model the intuitive relationship between contextually
dependent sentences and (relatively) contextually independent paraphrases that one
might expect: the QLF for he sneezed, for example, does not subsume the RQLF of John
sneezed even in a context where he can only be interpreted as John. In fact, when the
CLE generates the sentence John sneezed as a check that he sneezed has been interpreted
correctly, it does not do so from the resolved QLF corresponding to the latter. This
RQLF has the form:
sneeze(term (pro,* 23,masc, John))
But the QLF corresponding to John sneezed is:
5neeze(term(name,+32,),Y.name(Y,john),Referent))
Some inference has to take place to relate the RQLF for the interpreted sentence
to a QLF that unambiguously expresses its contextualized meaning. This makes the
task of expressing the output of some application system in a context-dependent way
quite difficult: rather than being related to an RQLF, this output has to be related to
a QLF that is sufficiently instantiated for a contextually unambiguous sentence to be
generated from it. The resolution mechanism is not intended to be reversible, although
by redefining resolution rules, reversibility is achievable to some extent within the
limitations just discussed (Hurst 1994).
A third problem arises with the approach to the semantics of QLFs that this notion
of the relationship between QLF and RQLF encourages one to adopt: it is that taken by
Alshawi and Crouch (1992). This describes the semantics of QLFs via a supervaluation
over the semantics of the RQLFs that they subsume. Although the problem does not
arise for the simple fragment they illustrate there, if their approach were extended to
cover a wider range of constructions, it would be found that many QLFs subsumed
RQLFs that are not actually permitted by the resolution rules: for example, those that
can only arise via a violation of scoping or binding constraints. The role of resolu-
tion rules (for perfectly good presentational reasons) is completely ignored by their
treatment. However, it is really the case that in giving the semantics of a QLF, one is
interested only in the set of RQLFs that are obtainable from it under closure of the
resolution rules. Ideally, therefore, we would like a formal reconstruction of resolution
</bodyText>
<page confidence="0.992246">
521
</page>
<note confidence="0.642618">
Computational Linguistics Volume 26, Number 4
</note>
<bodyText confidence="0.999791769230769">
rules as well. This is so, not just for reasons of formal hygiene in trying to make logical
sense out of underspecified representations, but also because resolution rules and the
knowledge they express are an important object of study in their own right. Anyone
who has built a wide-coverage system knows that the range of context-dependent
phenomena encountered in real life is a lot wider than the preoccupations of many
linguists might suggest. In the CLE, for example, contextual resolution forms a larger
part of the system than do syntactic and semantic processing. Unfortunately, in the
CLE there is no formal theory of resolution rules, and thus no prospect of capturing
their role in assigning a semantics to QLFs.
A further problem, that the supervaluation semantics does not yield the right
consequence relation, is discussed below.
The QLF-based theory illustrated in the approach advocated here does not suffer
from these problems:
</bodyText>
<listItem confidence="0.8860727">
• QLFs contain only information for which there is a direct syntactic or
morphological reflex. In particular, there are no indices or metavariables.
• the relation between QLF and RLF is directly reversible.
• the semantics of QLFs is completely given by the conditional
equivalences that relate them to RLFs, thus avoiding the problem of the
subsumption-based treatment and the associated supervaluation
semantics. (More detail on precisely how this semantic account works is
given below.)
• conditional equivalences are a formal language for resolution rules, thus
bringing them within the scope of the theory.
</listItem>
<subsectionHeader confidence="0.99979">
5.2 Glue Language
</subsectionHeader>
<bodyText confidence="0.998696263157895">
Within the LFG framework, Dalrymple and her colleagues have been working on a
linear logic glue language approach to semantic assembly and uncierspecification (Dal-
rymple et al. 1996). LFG distinguishes two different levels of syntactic representation:
constituent structure and functional structure (f-structure) at which the basic syntactic
relations are distinguished (subject, object, etc.). Semantic interpretation is also at two
levels: a a-projection maps an f-structure to a a-structure. Although a-structures are
described as semantic structures, they are not themselves meanings. Rather they are
connected to meanings or logical forms via which the authors describe as an
otherwise uninterpreted binary predicate symbol. Given a a-structure and the mean-
ing constructors associated with the lexical items in the f-structure from which it was
projected, the initial semantic level is a (linear logic) conjunction of the meanings
associated with the lexical items. This is approximately the equivalent of our own
QLF level of representation, although there are enough different assumptions that this
equivalence is not very meaningful.
From the initial level, inferences can be drawn via linear logic derivations. These
inferences correspond roughly to our RLFs, in that they are logical forms that can be
evaluated directly for truth (I assume: this is not stated explicitly).
To illustrate, we show the derivation of the two different scopings of our earlier
example:
</bodyText>
<listItem confidence="0.628041">
(44) Every manager uses a computer.
</listItem>
<page confidence="0.985192">
522
</page>
<table confidence="0.993371571428572">
Pulman Bidirectional Contextual Resolution
This sentence will receive the following f-structure.
PRED use SPEC every
STA3.1
OBJ FRED manager
SPEC a
PRED computer
</table>
<tableCaption confidence="0.961432">
The (r-projections for g introduces initially empty VAR and RESTR attributes. The
lexical entry for every is
</tableCaption>
<figure confidence="0.959100142857143">
VG,R,S.
VAR) -a x -o RESTR) R(x))
(2)
x -o G S(x))
-o G every(R,S)
which can be paraphrased:
If
</figure>
<bodyText confidence="0.836482769230769">
if the variable of the NP cr-projection this is part of is arbitrary x
then the noun restriction of the NIP (7-projection is interpreted as R(x)
and
if the cr-projection of the whole NP is arbitrary x
then the scope is interpreted as S(x)
then the scope can be (re)interpreted as the quantification: every(R,S)
The semantic lexical entry for manager will be:
VX.(I, VAR) X -0 RESTR) manager(X)
When these lexical entries are unified with the f-structure the 1 will be instantiated
to ga. In the result, the entry for manager unifies with the nested implication in the
antecedent of the entry for every, allowing the deduction (by modus ponens, with
substitutions {(X,x),(R,martager)l) to the conclusion:
VG,S. (Vx. ga X -o G S(x))
</bodyText>
<sectionHeader confidence="0.623526" genericHeader="method">
-0 G every(manager,S)
</sectionHeader>
<bodyText confidence="0.8163624">
The meaning of a computer is constructed analogously:
VH,Q. (Vy. h, y H Q(x))
- H a(computer,Q)
The meaning for a transitive verb like use is of the form:
VX,Y.(1-0. SIM) X (L. OBJ) Y -0 1, use(X,Y)
</bodyText>
<page confidence="0.996205">
523
</page>
<note confidence="0.644365">
Computational Linguistics Volume 26, Number 4
</note>
<bodyText confidence="0.990144866666667">
i.e., if the subject means X and the object means Y then the sentence means use(X,Y)&apos;.
The meaning of a sentence is obtained from the conjunction of this expression with
the meanings of the subject and object. With nonquantified arguments, the meanings
of the subject and object simply satisfy the antecedent of the implication allowing the
consequent to be deduced, with X and Y instantiated to the subject and object mean-
ings. In the case of quantified arguments this inference will not go through directly.
Instead, the verb meaning is rewritten to one of two logically equivalent forms, where
g, and k, are the subject and object meanings:
usei: VX. g, X -o (VY. h, Y -of. use(X,Y))
use2: VY. h, Y -o (VX. g, X -of. use(X,Y))
(The theoretical status of these rewriting operations is not clear: it is presumably some-
thing that happens in the lexicon, but whether it counts as a spurious ambiguity of
verb meaning as in some similar categorial grammar treatments of quantifier scope is
not specified). From the meaning of usei and the meaning of a computer we can de-
duce the following formula, corresponding to the choice of narrow scope for a computer
</bodyText>
<equation confidence="0.909101">
(linear implication -o is like in that {q,p (q r) p r}).
VX.g„ X -o f, a(manager,)ivArse(X,v))
</equation>
<bodyText confidence="0.951094380952381">
The variable substitutions are {(H1)(Y,y),(Q,)vuse(X,v))}. We can now combine this
with every manager to give:
f, every(martager,)u.a(martager,Av.use(u,v)))
with substitution {(G,g,),(X,x),(S,Au.a(manager,Av.use(u,v))}.
To get the alternative scoping we combine every manager with u5e2 to get:
VY.h, Y -0 f„ ^-+ every(nrianager,Au.use(u,Y))
which then combines with a computer to give:
f, a(computer,Av.every(managenAu.use(u,v)))
There are several points of contact between this glue language analysis and our
own:
Both share the somewhat inelegant feature that a quantified noun phrase
has to have a denotation of type e at some level, because it is an
argument of a verb. In our case, this is achieved by resolving a
determiner like every of type ((e,t),e) as a quantifier like all, where the
scope is supplied by higher-order unification, which in effect abstracts
over this argument position. This means that we do not have a very
plausible story to tell about the independent denotation of QLF level
every—it just denotes some function from noun meanings to individuals.
In the glue language version, the same is true: the antecedent of the
relevant implication says &apos;if we can assign an arbitrary meaning x of
type e to the f-structure of the whole NT, ...&apos;.
</bodyText>
<page confidence="0.994344">
524
</page>
<subsectionHeader confidence="0.769765">
Pulman Bidirectional Contextual Resolution
</subsectionHeader>
<bodyText confidence="0.9671872">
2. both use higher-order unification: in order to assemble the correct values
for the variables R, S. and Q above, a higher-order unification is
necessary.
However, I would maintain that the QLF treatment has several distinct advantages:
it uses only HOU: we do not need to allow verb rewriting, in particular.
</bodyText>
<listItem confidence="0.981648636363636">
2. it is reversible: nothing further is required to be able to generate
sentences from scoped logical forms. The glue language treatment is not
obviously reversible, at least in its present form.
3. it is sensitive to context: the conditional equivalences require the context
to be an appropriate one for the scoping derived. The form of the
implication in the interpretation direction is `QLF &amp; Context I- RLF&apos;.•By
contrast, if I have understood correctly, the glue language deductions as
presented require only the linguistic forms to be present: thus all
interpretations of an ambiguous form will be derivable, whatever the
context. Some further specification of how context acts to eliminate
impossible readings is required.&apos;
</listItem>
<subsectionHeader confidence="0.99955">
5.3 Underspecified Discourse Representation Structures
</subsectionHeader>
<bodyText confidence="0.928303684210526">
In a series of papers, Reyle (1993, 1995, 1996) has elaborated a version of DRT that
is able to represent quantifier scope and other ambiguities in a single underspecified
representation. (In other respects like pronoun or definite description interpretation,
standard DRT is already an underspecification-based theory.) LIDRT differs from stan-
dard DRT in that the familiar &amp;quot;boxes&amp;quot; are partly replaced by a set of labels for the
conditions in the boxes and the relations between them, and partial relations of in-
clusion between (the components indexed by) these labels. When sentences are fully
scoped, the representations are like standard DRT with extra labels. Thus a sentence
like
(45) Every manager owns a computer.
would be represented in its different scopings by:
11: 12 14: 15:computer(y)
16:owns(x,y)
13:manager(x)
8 The glue language approach makes much of the &amp;quot;resource sensitivity&amp;quot; of linear logic. But in the
specific instances of the analysis of quantifier scope and pronouns discussed in Dalrymple et al. (1996),
the linearity and resource sensitivity of the logic assumed is, as far as I can see, subverted by the
device of &amp;quot;reinterpreting&amp;quot; constructs like the &amp;quot;scope&amp;quot; variable (see example 28) or the &amp;quot;reintroduction&amp;quot;
of pronoun meanings (see example 39).
</bodyText>
<page confidence="0.992619">
525
</page>
<figure confidence="0.786222636363636">
Computational Linguistics Volume 26, Number 4
15:computer(y)
12. 13:martager(x) 14 16:owns(x,y)
But a representation which does not specify the scoping in ambiguous cases can
be given by listing the component elements, along with the inclusion ordering that
determines the scoping. The components are:
and:
11:
14:
, 12:
13: manager(x) 15: computer(i4 16: owns(x,y)
</figure>
<bodyText confidence="0.907414428571429">
and the two orderings are:
{12 &lt; 11, 13 12, 14 -‹ 11, 15 -‹ 14, 16 -&lt; 14}
{12 &lt; 11, 13 -&lt; 12, 14 -&lt; 11, 15 &lt; 11, 16 -&lt; 14}
We now represent the unspecified scoping by (roughly) the intersection of these inclu-
sion constraints, which gives the following partial order, here determined just on the
basis of the syntactic structure of the sentence, This representation leaves it unresolved
as to whether the indefinite has wide or narrow scope:
</bodyText>
<equation confidence="0.5160566">
,15:
computer(y)
12: 13:manager(x)
14- 16:owns(x,y)
( 11
</equation>
<bodyText confidence="0.998574538461539">
Resolution of scoping consists of adding further inclusion constraints. Other than those
which are the result of general principles (e.g., binding constraints), it is not part of
the theory to say where these constraints come from. Just as for pronoun resolution,
(LT)DRT provides a representation that allows for the monotonic addition of infor-
mation to do the resolution, but has nothing to say about the mechanisms that do
this.
Reyle sketches various methodological requirements that should be met by a the-
ory of meaning underspecification (Reyle 1996, 241ff.). Firstly, it should be possible
to represent partial orders of scoping relations. Secondly, it should be able in effect
to emulate the DRT treatment of donkey sentences (p. 243) (a somewhat parochial
requirement, given that the case is not yet closed on whether this treatment is correct:
see Elworthy [19951, among others). Thirdly, the theory should not need anything like
the free variable constraint.
</bodyText>
<page confidence="0.995139">
526
</page>
<subsectionHeader confidence="0.331568">
Pulman Bidirectional Contextual Resolution
</subsectionHeader>
<bodyText confidence="0.99973995">
Clearly, UDRS meets these requirements, as does our own QLF-based approach.
There are some similarities between the UDRS and the glue language approaches, as
detailed in Crouch and van Geriabith (1997). There are also some differences: unlike
our approach, or the glue language approach, UDRS does not have the problem of
how to represent the meaning of quantified NPs as things of different type at dif-
ferent levels. However, it achieves this at the cost of not representing the meanings
of quantified NPs as independent units at all: determiner and restriction are separate
components that have no close connection to each other until the inclusion constraints
are imposed. It remains to be seen whether this unconstrained approach to semantic
assembly can be implemented on a large scale, given that it is prima facie not very
compositional.
Early versions of UDRS (Reyle 1993) treated ambiguity as disjunction, which as we
shall see, is not correct. The more recent version (Reyle 1996) remedies this. UDRS also
makes a serious attempt at developing a calculus for reasoning directly with under-
specified DRSs, a necessary move: the whole point of working on underspecification
is to be able to work with underspecified representations directly, rather than relying
on their fully specified resolutions. This is a deficit in our own account (and the glue
language account) that we shall begin to remedy below.
While there are many points of contact between the two approaches, there are at
least two dimensions along which I would maintain the QLF approach to be preferable:
</bodyText>
<listItem confidence="0.545318">
1. it is reversible. It may be possible to do reversible resolution within
</listItem>
<bodyText confidence="0.986932">
UDRT, but since the theory does not specify how to do resolution, we
cannot really say one way or the other.
2 the representations postulated are motivated only by overt linguistic
elements. LTDRS shares with the CLE-QLF approach a proliferation of
metaconstructs (labels, indices, ordering constraints, etc.) that are
motivated only by the resolution process, not by the linguistic forms of
sentences. It might be argued that this is an aesthetic preference rather
than a substantive one, but it is likely to have consequences for both
methodology and implementation: semantic assembly is surely going to
be a very unconstrained and noncompositional process in this
framework.
</bodyText>
<sectionHeader confidence="0.847234" genericHeader="method">
6. The Semantics of QLF
</sectionHeader>
<subsectionHeader confidence="0.999756">
6.1 The Meaning of
</subsectionHeader>
<bodyText confidence="0.807579142857143">
As was pointed out earlier, conditional equivalences of the form:
QLF RLF
if
Condition],
,
Condition,
are logically equivalent to the conjunction:
</bodyText>
<equation confidence="0.8967485">
(Conditionsi„.„ &amp; QLF RLF)
(Conditions, &amp; RLF QLF)
</equation>
<page confidence="0.988438">
527
</page>
<note confidence="0.728374">
Computational Linguistics Volume 26, Number 4
</note>
<bodyText confidence="0.9719184">
if the symbol &lt;,), is interpreted as material or logical equivalence.&apos; We would like to
preserve this interpretation, because by doing so we can claim that our conditional
equivalences collectively provide a truth definition for expressions of our QLF lan-
guage.
In, say, first-order logic, truth is defined directly via clauses like:
</bodyText>
<equation confidence="0.964187">
Rx P(x) is true ifl some value of x makes P(x) true.
P &amp; Q is true ifl P is true and Q is true.
etc.
</equation>
<bodyText confidence="0.7257545">
But for QLFs, truth is defined derivatively, via the truth conditions for the RLFs with
which a QLF is associated via the equivalences:
</bodyText>
<equation confidence="0.73207">
QLF RLF
if
CL ..C,,
</equation>
<bodyText confidence="0.9995408">
The RLFs themselves are assigned truth conditions directly via the usual interpretation
function for a typed higher-order logic of the kind we are assuming. An actual QLF
may require a sequence of equivalences in order to arrive at a fully truth evaluable
RLF, of course. But we can simplify by assuming that this sequence is represented as
a single equivalence, because:
</bodyText>
<equation confidence="0.96899">
(Q1 Q2 if C1 ) &amp; (Q2 &lt;4- Q3 if C2) 84 R if C)
is equivalent to:
Ch. &lt;=&gt; R if C1&amp; C2 &amp; • •
</equation>
<bodyText confidence="0.980503">
which has the same form as a single equivalence. (We ignore the possibility of abduc-
tion in this section and assume that all conditions are fully evaluable.)
So for a particular resolved QLF, the truth definition induced by the equivalences
will be an instance of a schema like:
if C1... C„ then P(he) is true ifl P(john)
if C1... C„, then P(every(R)) is true ifl forall(R,P)
etc.
Truth will be relative to a particular known context.
For an unresolved QLF, the truth definition will have to take into account all the
possible contexts in which it could be resolved, and all the ways within each context
that it could be resolved (there may be equally plausible choices of pronoun antecedent,
for example). In the general case, there could be an infinite number of these. The
number of different sequences of equivalence involved in resolutions will hopefully
be bounded by the number of QLF constructs appearing in the initial QLF, and the
number of valid solutions to attempts to match equivalences to them. (Unfortunately,
nothing in the formal mechanism itself guarantees this. It would be perfectly possible
to write equivalences that generated cycles. I am assuming—or rather, hoping—that
</bodyText>
<page confidence="0.792983">
9 I am grateful to Stanley Peters for helpful discussion of the issues in this section
528
</page>
<subsectionHeader confidence="0.322295">
Pulman Bidirectional Contextual Resolution
</subsectionHeader>
<bodyText confidence="0.98546425">
no such analysis would be linguistically plausible). Because many of the contextual
conditions are just variables over contextually available propositions, there will be no
fixed upper limit on the number of valid contexts that could be considered. So the
form of a truth definition for an unresolved QLF will be:
</bodyText>
<equation confidence="0.8133235">
C, (Q is true ift RI) &amp; C2 —* (Q is true iff R2) &amp; ...&amp; (Q is true ift
R„).
</equation>
<bodyText confidence="0.9998565">
This seems like an intuitively sound reconstruction of our basic intuitions about the
meaning of constructs like pronouns or ellipses. It doesn&apos;t make much sense (unless
talking theory) to ask &amp;quot;what does he mean?&amp;quot; in the abstract. But if we did, then an
answer like &amp;quot;Well, in this utterance context he means John, and in this utterance context
he means Bill, etc . . .&amp;quot; is a perfectly satisfactory answer. That is essentially the form
of answer that the current theory proposes. It does not assign a full meaning to QLF
constructs like he or every in isolation, but only in a context.
However, the coherence of such an approach is dependent on how fine-grained
our notion of context is made to be. For if our truth definition is defining meanings
as above:
</bodyText>
<equation confidence="0.9977375">
Cl (Q R1)
C2 (Q R2)
</equation>
<bodyText confidence="0.99984275">
then it will follow that if, for a QLF Q in a given situation both Cl and C2 are satisfied,
RI and R2 must be equivalent. It is clear that for the case of quantifier scope (at least)
there will be many examples where the same QLF appears to be capable of being
resolved to two nonequivalent or even incompatible logical forms.
</bodyText>
<equation confidence="0.9451576">
neg(leave(e,every( boy)))
(every boy didn&apos;t leave) can be resolved to
neg(every(boy,Ax.leave(e,x)))
or:
every(boy,Ax.neg(leave(e,x)))
</equation>
<bodyText confidence="0.999521294117647">
which are not equivalent. If we are to maintain that .;=&gt; is interpreted as logical equiv-
alence, then we must argue that such a situation cannot happen. Either the QLFs for
these cases will be different, or there will be something in the context that means that
only one interpretation can be derived. (Michael Kohlhase has pointed out to me that
this is equivalent to a requirement that a set of equivalences are &amp;quot;confluent&amp;quot; if viewed
as a rewriting system.)
In the quantifier scope example above it might be, for example, that there is stress-
marked focus on every (and falling intonation on the VP) leading to the wide-scope
every interpretation. An appropriate context for this would be where what is being
denied is the proposition that some(boys,Ax.neg(leave(e,x))). The other interpretation is
most naturally associated with stress on didn&apos;t, forcing the negation to have wide
scope. An appropriate context for this would be one in which what is being denied is
the proposition every(boy,Ax leave(e,x)).
If the focus is overtly marked, then the two QLFs will be different in that respect
and so only one interpretation will be obtained. But if the focus is underspecified, then
the two contexts are still incompatible with each other, and only one interpretation
will be derived, as is required by our interpretation of the equivalences.
</bodyText>
<page confidence="0.994671">
529
</page>
<note confidence="0.730753">
Computational Linguistics Volume 26, Number 4
</note>
<bodyText confidence="0.998471764705882">
My assumption is that this is always the case: if the equivalences are capable of
resolving the same QLF to two logically distinct RLFs, then there is no (full) context
that will simultaneously support both resolutions. What this amounts to is the question
of whether an utterance—an utterance, not a sentence is ever genuinely ambiguous.
There are of course cases of deliberate ambiguity for poetic or humorous effect (see
Poesio [19961), but I think it is legitimate to regard these as metalinguistic or parasitic
on the normal case (I read Barwise and Perry [1983, 40-411 as also taking this view). In
most cases the purpose of the ambiguity is precisely to cause the audience to become
aware of the two different contexts that are associated with the different interpretations.
It is not the case that the real circumstances of the utterance support both of these
contexts.
To summarize, on our theory, if we interpret as logical equivalence, then we are
committed to the claim that no utterance (where the context is fully specified) is truly
ambiguous. (This does not entail that particular speakers must be able to fully resolve
all utterances.) That is to say, there must be some feature of the form and content of
the utterance, or the context in which it is produced, that exclude all but one of the
possible interpretations.
</bodyText>
<subsectionHeader confidence="0.995279">
6.2 Truth and Consequence
</subsectionHeader>
<bodyText confidence="0.918684034482759">
In van Deemter (1996), van Eijck and Jaspars (1996), and Jaspars (1997), criteria for a
notion of ambiguous consequence are outlined. In the following, R1 and Rz are (all)
the resolutions of Q, and is an ambiguous consequence relation.
We can summarize these requirements as follows:
Q k, RI or R2
Ri and R2 Q
Q ja -R1 Or -7R2
-,R1 and -,R2 =a -Q
Q Ri and R2
Ri or R2 Q
and -,R2
-,E.1 or -1R2 -Q
If an ambiguous expression is true then at least one of its readings is true (1). But
the stronger version, that all readings are true, is not plausible (5). This would mean
that any expression with mutually contradictory readings would lead to inconsistency.
(The CLE-QLF supervaluation semantics falls prey to this problem.) On the other hand,
if we know both readings are true, then we can safely assert the ambiguous expression
(2). If only one reading is true, we cannot assert the ambiguous expression safely (6). To
do so would be to identify ambiguity with disjunction (given I), and as van Deemter
(1996) points out, this is to confuse the level at which the disjunction holds: When an
expression is ambiguous, then either it means P, or it means Q. This is not the same
as saying that it means either P or Q.
If we know that an ambiguous expression is false, then at least one of its inter-
pretations must be false (3). Again, we cannot strengthen this to the conclusion that
all readings are false (7) because that would lead us again to be regarding ambiguity
as equivalent to disjunction: -(P v Q) = P &amp; -Q. However, if we know that both
readings are false, we can assert that the ambiguous expression is false (4), but just
as before, we cannot do this on the basis of knowing that just one of the readings is
false (8).
</bodyText>
<page confidence="0.982248">
530
</page>
<note confidence="0.308796">
Putman Bidirectional Contextual Resolution
</note>
<bodyText confidence="0.9341345">
Is our account of truth for QLFs consistent with (1) to (8)? Consider (1). In the case
that R1 and R2 are the only disambiguations, then the truth definition tells us that:
</bodyText>
<equation confidence="0.647891">
(T) Cl (Q &amp; C2 (Q R2)
</equation>
<bodyText confidence="0.982646285714286">
If we know that Q is true, then, because Q can only be equivalent to one of RI or
R2, for T to hold it must be the case that either Cl holds and so Q is equivalent to R1
(and the other conjunct is vacuously true) or ditto for C2 and R2. So one of R1 or R2
will be true. Since T will hold here if only one of R1 or R2 is true, this shows that (5)
is valid also.
Consider (2). If both possible resolutions are true, for example, in a situation in
which there are two tall men, John and Bill, and thus both John is tall and Bill is tall are
true, a QLF corresponding to he is tall will count as true even if we do not know which
context holds. For T to hold where both R1 and R2 are true, either the equivalence
(Q iff RI) and the corresponding context, Cl, must both fail, or the equivalence (Q iff
R2) with context C2 must both fail. But Q will still be true by virtue of the remaining
equivalence. However, if only one of RI and R2 is true, then there is a model where
Q is false, namely where RI is true and Cl is false, and C2 is true but R2 is false, or
vice versa. This shows that (6) is valid.
Consider (3). If Q is false, then for T to hold either RI is false and Cl holds, or R2
is false and C2 holds. In either case the other conjunct is vacuously true. However, if
we try to strengthen this to the case where both Rl and R2 are false, T will only hold
if both Cl and C2 hold: this cannot be so on our account, showing that (7) is also true.
Consider finally (4). If R1 and R2 are both false, then if Q is true, for T to hold
Cl and C2 must both be false, which is impossible. If either of them is true, Q must
be false. If only one of R1 and R2 is false, then it is possible for T to hold and for Q
to be true, namely where RI and C1 are false and R2 and C2 are true, or vice versa.
This shows that (8) also holds for us.
So our truth definition appears to support the kind of consequence relation that is
appropriate for reasoning with ambiguous sentences. Notice that several other prop-
erties that are desirable will also fall out of our truth definition. For example, we want
it to be the case that
9. Q, —R1 R2
which says that if there is a true, two-ways ambiguous sentence and one of the in-
terpretations is not true, the other one must be: perhaps the most basic kind of dis-
ambiguation strategy. It is in fact not completely trivial to arrive at such a conclusion
without reducing ambiguity to disjunction: the logic of ambiguity in van Eijck and
Jaspars (1996), for example, does not have this property (Jaspars 1997). But a ver-
sion of (9) follows directly from T, with the additional conclusion that C2 must also
hold.
</bodyText>
<subsectionHeader confidence="0.999846">
6.3 Reasoning with QLFs
</subsectionHeader>
<bodyText confidence="0.9998065">
Why would we want to be sure that we have a coherent semantics for QLFs and a
sensible consequence relation? There are several reasons for doing so. Firstly, there are
overwhelming arguments that some level like QLF is essential as part of a theory of
utterance interpretation, both for linguistic and computational reasons. The practical
arguments for this position are well known and have been implicit in computational
practice since at least Woods (1968, 1978). It is simply not feasible to interleave the
processes of quantifier scope or reference and ellipsis resolution, for example, with the
otherwise compositional process of meaning assembly. The space of possible interpre-
</bodyText>
<page confidence="0.989518">
531
</page>
<note confidence="0.70436">
Computational Linguistics Volume 26, Number 4
</note>
<bodyText confidence="0.999474272727273">
tations becomes unmanageably large. However, postulating such a level of represen-
tation incurs an obligation to say what it means: logical and computational hygiene
require us to supply a semantic account of it.
Secondly, since the processes of contextual interpretation involve a certain amount
of inference to be successfully achieved, and since some of the ingredients in that
inference are components of meaning of the sentence itself (such as the fact that a
pronoun is masculine, or that a determiner like any is in the scope of a negative) we
need to be sure that our partly specified representations have enough of a semantics
that we can carry out this reasoning in a logically respectable way.
In fact some types of linguistic processing presuppose that meanings are not fully
resolved. Consider the following exchange:
</bodyText>
<listItem confidence="0.59922">
(46) A: She&apos;s here!
</listItem>
<bodyText confidence="0.983674764705882">
B: Who is?
The VP ellipsis in Ws response has to be resolved with respect to an antecedent
sentence that cannot be fully resolved: indeed, 13&apos;s question would be pointless if it
was. Observations like these compel the conclusion that partially resolved LFs need to
have enough of a semantics to support this kind of inference, while still being subject
to further linguistic processing.
Thirdly, there are many practical natural language processing applications that
can be carried out without needing (or being able) to produce a fully contextual-
ized interpretation of a sentence. Translation is an obvious example: while there will
always be some cases for which full interpretation is required for a correct transla-
tion to be possible, in general, translation on the basis of purely linguistic proper-
ties can often be perfectly adequate. A less obvious example is information extrac-
tion: since it is not possible at the current state of the art to find complete gram-
matical analyses for every sentence, let alone full contextual interpretations, infor-
mation extraction proceeds by reasoning from partial or underspecified representa-
tions that are in most logical respects the same kind of animal as the unresolved
QLFs we have been talking about. Information extraction systems typically carry
out such reasoning in a way that is, in Jerry Hobbs&apos; phrase, unhindered by the-
ory.
Developing a calculus for reasoning with QLFs is too large a task to be under-
taken here. But the general outlines are reasonably clear, and we can adapt some of
the UDRS (Reyle 1995) work to our own framework. Reyle points out that many of
the inferences involving underspecified representations that we would like to capture
rely on the assumption that whatever context disambiguates the premise also disam-
biguates the conclusion, even if we do not know what that context or disambiguation
is. His example is:
If the students get £10 then they buy books.
The students get .£10.
They buy books.
Our treatment of the interpretation of QLFs makes it a tautology that if one re-
solved form implies another, then the corresponding QLFs also do, given a fixed
context.
The other common patterns of inference that we want to capture are those in which
some (unambiguous) conclusion will follow from an unresolved form, whichever res-
</bodyText>
<page confidence="0.985455">
532
</page>
<table confidence="0.245708">
Pulman Bidirectional Contextual Resolution
</table>
<bodyText confidence="0.996836533333333">
olution of the unresolved form is correct. Examples of these are things like:
Every student went to a lecture.
Mary is a student.
Mary went to a lecture.
Two hundred companies lost more than $2 million last year.
Two hundred companies lost money last year.
A teacher who gave a low mark to every student was dismissed.
A teacher was dismissed.
The first argument is valid whichever scoping of the first premise is taken, and it
is possible that most people would accept the argument as valid without even noticing
the ambiguity. The second argument is valid whether the premise is construed in a
collective or a distributive way. The third argument is valid whichever scoping of the
relative clause is correct.
We can begin to capture such inferences by using proof rules for QLFs (partly
modeled after those for UDRS in Reyle 11995]) such as these:
</bodyText>
<figure confidence="0.675238">
CONJ: (where R is resolved, and Q may contain some unresolved constructs)
R &amp; Q
QUANT: (where Q is a downward monotone determiner, and P does not contain
a negative)
exists (R,P)
</figure>
<bodyText confidence="0.95949225">
COM and QUANT need considerable refinement in order to cover more than the
simplest cases, but they will give the correct results for the latter two examples. For
the first example something more is needed, perhaps along the lines suggested by
Muskens (1998).
</bodyText>
<sectionHeader confidence="0.442483" genericHeader="conclusions">
7. Conclusions and Further Work
</sectionHeader>
<bodyText confidence="0.9994690625">
We have presented what is probably the first fully bidirectional formalism for the
interpretation and generation of quasi-logical form representations and illustrated its
application with a fragment of English grammar that contains (admittedly simple)
instances of some of the most important types of context-dependent construct. This
fragment has been fully implemented and works as advertised.
We have tried to show that the interpretation of QLFs implicit in our treatment is
a logically coherent one, supplying a kind of contextual truth definition for unresolved
QLF constructs. We have also argued that this truth definition supports a notion of
logical consequence that meets all the obvious desiderata for such a relation and have
sketched how a calculus for reasoning directly with wholly or partially unresolved
QLFs could be developed, again in a logically coherent way.
We conclude with a brief discussion of a series of issues that arise in thinking how
to extend and apply the system described here.
Robustness. The work described here is an instance of what might be called &amp;quot;classical&amp;quot;
NLP: a (hopefully) neat bit of theory, a nice clean logical formulation, and a small-
scale implementation. This kind of thing is currently desperately unfashionable on the
</bodyText>
<page confidence="0.994241">
533
</page>
<note confidence="0.70671">
Computational Linguistics Volume 26, Number 4
</note>
<bodyText confidence="0.999976653061225">
grounds that such methods cannot scale up to real-world applications. (If you want
to get ahead, get a corpus.) This is not the place to argue over whether this view is
the correct one, but it is worth pointing out that the current theory is, at least in one
direction, consistent with the kind of large-scale statistical processing that is viewed as
the appropriate alternative. It was stated earlier that the grammatical formalism used
was not an essential component of the theory. Thus any alternative robust parsing
system could be plugged in instead.
What is required is that QLFs be stated in a typed higher-order logic. The QLFs
we have been dealing with correspond to complete and correct grammatical analyses
of sentences: in the real world, as we know, such things are not usually available.
But in fact for the current approach, they are not needed: a partial or fragmentary
analysis can be represented in QLF either by introducing a quantifier over a relation
that is assumed to hold between the components (thus presupposing that there was
a coherent message expressed by the partially analyzed sentence) or by introducing
Skolem-like predicate constants to achieve the same effect. (See Pinkal [1995] for a
similar suggestion.) The conditional equivalences will apply to such representations
directly, leaving the quantified relation or the Skolern constants in the resolved form.
Of course, the resulting system will not be fully reversible, but it would be capable in
principle of carrying out contextual disambiguation as part of a robust text-processing
system.
Disambiguation. We have been assuming that the &amp;quot;correct&amp;quot; QLF has been chosen before
applying our conditional equivalences. However, this is an unrealistic assumption in
the fully general case, because it is quite conceivable that lexical disambiguation could
require some contextual disambiguation first. Likewise, many PP attachment decisions
have to be made on contextual grounds.
There are several stategies that might be pursued. One is to adopt Pinkal&apos;s &amp;quot;radi-
cal underspecification&amp;quot; approach (Pirikal 1995) and use underspecified representations
for all types of ambiguity, even syntactic ambiguity. The more conservative approach
is to try to integrate existing statistical disambiguation schemes for QLFs, either in-
dividually or in a &amp;quot;packed&amp;quot; structure (Alshawi and Carter 1994), with the resolution
process as described here. Alternatively, I believe it is worth exploring the approach to
disambiguation described in Pulman (2000), which would mesh nicely with the theory
presented here.
Efficiency. Extending coverage of linguistic constructs, and trying to achieve robust-
ness or integrate with disambiguation schemes each pose the further problem of the
efficiency of the HOLT-based resolution process itself. While efficiency is acceptable for
the short, simple sentences illustrated earlier, the computational properties of HOU
mean that processing times increase in a highly nonlinear way when larger QLFs are
encountered.
There are several avenues worth exploring to solve this problem. While the equiv-
alences are stated in a direction-neutral mariner, there is scope in an implementation
for compiling them in different ways for the analysis and synthesis directions (recall
that the equivalences decompose to a conjunction of higher-order Horn clauses). Once
you know which direction you are going in, most of the unifications actually reduce
to matchings (since one side of the equation is fully instantiated), which may allow
for various optimizations to the unification algorithm itself. Prehofer (1994) describes
some tractable subcases of higher-order unification.
Another strategy is to change the control regime by which the equivalences apply.
The regime assumed here, and that implemented, is entirely nondeterministic. Equiv-
</bodyText>
<page confidence="0.992381">
534
</page>
<note confidence="0.317475">
Putman Bidirectional Contextual Resolution
</note>
<bodyText confidence="0.993961892857143">
alences apply to whole QLFs, in any order, whenever they can. This means that many
equivalences are tried which are later filtered out because their associated conditions
cannot be met. This is both expensive and an unrealistic model of language processing.
The other strategy is to make the resolution process incremental, rather than op-
erating on whole QLFs at a time. To some extent, the linguistic facts force this option
on us anyway, of course, because for many types of elliptical or anaphoric devices
the appropriate context is an earlier part of the same sentence. It ought to be a rela-
tively straightforward matter to devise a control strategy to resolve QLFs essentially a
component at a time, perhaps guided by the original syntactic structure. This would
bound the scope of higher order unify and keep it manageable, as well as having an
intuitively satisfactory &amp;quot;dynamic&amp;quot; aspect to the resolution process. (The strategy used
above is incremental and dynamic in that only one construct at a time is resolved, and
each resolution changes the context, but this does not necessarily always correspond
to a left-to-right traversal of the original sentence). There are some interesting inter-
actions with the incremental interpretation scheme proposed in Putman (1986) to be
explored here.
Contextual Resolution Primitives. Currently the content of the conditions in conditional
equivalences is rather unconstrained: any Prolog-definable predicate could be used.
My hope is that in developing descriptions of a wider range of context-dependent
phenomena, a set of conditions that recur (such as &amp;quot;parallel&amp;quot;) can be isolated and
defined in a way that covers their use in resolving different types of contextual de-
pendency. Eventually one might hope that all the equivalences necessary would call
on just a restricted range of such contextual predicates. These predicates would then
in effect constitute the primitives of the linguistic theory of contextual resolution, fac-
toring out all of the inferential processes that are not specifically linguistic. In moving
towards such a theory, the requirement of reversibility is a hard one, but I believe it
places a useful and productive methodological constraint on us, as well as yielding a
significant practical payoff.
</bodyText>
<sectionHeader confidence="0.985536" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<reference confidence="0.899423538461538">
This paper is a descendant of Pulman
(1994). Versions of it have been given at
Bilkent University, Ankara, IMS Stuttgart,
Cambridge, Edinburgh, ITRI Brighton,
Sheffield, Oxford, and at workshops in Bad
Teinach and SaarbrOckert. I thank the
audiences on these occasions: I can
remember (at least) Varol Akman, Nick
Asher, Robin Cooper, Dick Crouch, Kees
van Deemter, Jan van Eijck, Tim Fernando,
Josef van Genabith, Jan Jaspars, Hans
Kamp, Ron Kaplan, Stanley Peters, Manfred
Pinkal, and Massimo Poesio making
</reference>
<bodyText confidence="0.9334687">
suggestions that changed the content of the
paper in one way or another. The usual
absolutions apply. Apologies to those who
have forgotten. Thanks are also due to three
anonymous Computational Linguistics
referees for insightful comments and
criticisms, to Fernando Pereira for
answering various questions, and to
Michael Kohlhase for his detailed comments
and helpful discussion of the prefinal draft.
</bodyText>
<sectionHeader confidence="0.896897" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998992043478261">
Alshawi, Hiyan. 1990. Resolving quasi
logical forms. Computational Linguistics,
16(4133-144.
Alshawi, Hiyan. 1992. The Core Language
Engine. MIT Press.
Alshawi, Hiyan and David M. Carter. 1994.
Training and scaling preference functions
for disambiguation. Computational
Linguistics, 20(4):635-648.
Alshawi, Hiyan and Richard Crouch. 1992.
Monotonic semantic interpretation. In
Proceedings of the 30th Annual Meeting,
pages 33-39. Association for
Computational Linguistics.
Ayuso, Damaris M. 1989. Discourse entities
in Janus. In Proceedings of the 27th Annual
Meeting, pages 243-250, Vancouver.
Association for Computational
Linguistics.
Barwise, John and John Perry. 1983.
Situations and Attitudes. MIT Press.
Crouch, Richard and Josef van Genabith.
1997. On interpreting f-structures as
</reference>
<page confidence="0.963436">
535
</page>
<note confidence="0.360863">
Computational Linguistics Volume 26, Number 4
</note>
<reference confidence="0.999818278688525">
UDRSs. In Proceedings of the 35th Annual
Meeting of the ACL and the 8th Conference of
the European Chapter of the ACL,
pages 402-409. Association for
Computational Linguistics.
Crouch, Richard S. and Stephen G. Pulman.
1994. Monotonic semantics. In R. Cooper,
R. Crouch, J. van Eijck, C. Fox, J. van
Genabith, J. Jaspars, H. Kamp, M. Pinkal,
M. Pocsio, S. C. Pulman, and E. Vestre,
editors, Describing the Approaches:
Deliverable D8 of the FraCaS Project.
Cognitive Science, University of
Edinburgh, pages 184-218. Available from
ftp.cogsci.ed.ac.uk/pub/FRACAS.
Dalrymple, Mary, J. Lamping, Fernando
C. N. Pereira, and Vijay Saraswat. 1996.
Quantifiers, anaphora, and intensionality.
Journal of Logic, Language, and Information,
6(3):219-273.
Dalrymple, Mary, Stuart M. Shieber, and
Fernando C. N. Pereira. 1991. Ellipsis and
higher-order unification. Linguistics and
Philosophy, 14(4):399-452.
Davidson, Donald. 1972. Semantics for
natural languages. In D. Davidson and
G. Harman, editors, Semantics of Natural
Language. Reidel. Also in Davidson, 1984,
Inquiries into Truth and Interpretation,
Oxford, pages 55-64.
Elworthy, David A. H. 1995. A theory of
anaphoric information. Linguistics and
Philosophy, 18(3):297-332.
Gardent, Claire and Michael Kohlhase.
1996a. Focus and higher-order
unification. In Proceedings of the 16th
International Conference on Computational
Linguistics, pages 430-435, Copenhagen.
Gardent, Claire and Michael Kohlhase.
1996b. Higher-order colored unification
and natural language semantics. In
Proceedings of the 34th Annual Meeting,
pages 1-9. Association for Computational
Linguistics.
Gardent, Claire and Michael Kohlhase. 1997.
Computing parallelism in discourse. In
Proceedings of IJCAI &apos;97, pages 1016-1021,
Tokyo.
Gardent, Claire, Michael Kohlhase, and
Karsten Konrad. 1999. Higher-order
colored unification: A linguistic
application. Technique et Sciences
Informatiques, Special Issue for
JFPLC-UNIF&apos;97, 18(2):181-209.
Gardent, Claire, Michael Kohlhase, and
Noor van Leusen. 1996. Corrections and
higher-order unification. In Proceedings of
KONVENS&apos;96, pages 268-279, Bielefeld,
Germany. De Gruyter.
Gawron, Jean M. 1992. Pocus and ellipsis
in comparatives and superlatives: A case
study. In C. Barker and D. Dowty, editors,
Proceedings of the Second Conference on Se-
mantics and Linguistic Theory, Working Papers
in Linguistics No. 40, Ohio State University,
pages 79-98. Ohio University Press.
Gawron, Jean M. 1995. Comparatives,
superlatives, and resolution. Linguistics
and Philosophy, 18:333-380.
Hobbs, Jerry R. 1979. Coherence and
coreference. Cognitive Science, 3(1):67-90.
Hobbs, Jerry R. and Andrew Kehler. 1997. A
theory of parallelism and the case of
vp-ellipsis. in Proceedings of the 35th
Annual Meeting of the ACL, and the 8th
Conference of the European Chapter of the
ACL, pages 394-401. Association for
Computational Linguistics.
Hobbs, Jerry R. and Stuart M. Shieber. 1987.
An algorithm for generating quantifier
scopings. Computational Linguistics,
13(1-2):47-63.
Huet, Gerard. 1975. A unification algorithm
for typed A-calculus. Theoretical Computer
Science, 1:27-57.
Hurst, Matthew. 1994. Reversible resolution
with an application to paraphrasing. In
Proceedings of the 15th International
Conference on Computational Linguistics,
pages 551-555, Kyoto.
Jaspars, Jan. 1997. Minimal logics for
reasoning with ambiguous expressions.
Technical Report available from
www.turing.wins.uva.n1/,-jaspars.
Kamp, Hans and Uwe Reyle. 1993. From
Discourse to Logic: Introduction to Model
Theoretic Semantics of Natural Language,
Formal Logic and Discourse Representation
Theory. Kluwer.
Kohlhase, Michael and Frank Pfenning.
1993. Unification in a lambda calculus
with intersection types. In Dale Miller,
editor, Logic Programming: Proceedings of the
1993 International Symposium,
pages 488-505, Vancouver. MIT Press.
Lewin, Ian. 1990. A quantifier scoping
algorithm without a free variable
constraint. In Proceedings of the 13th
International Conference on Computational
Linguistics, Volume 3, pages 190-194,
Helsinki, Finland.
Miller, Dale and Gopalan Nadathur. 1986.
Some uses of higher order unification in
computational linguistics. in Proceedings of
the 24th Annual Meeting, pages 247-255.
Association for Computational
Linguistics.
Montague, Richard. 1974a. The proper
treatment of quantification in English. In
R. Thomason, editor, Formal Philosophy.
Yale University Press, New York,
pages 222-246.
</reference>
<page confidence="0.964976">
536
</page>
<reference confidence="0.994428460176991">
Pulrnan Bidirectional Contextual Resolution
Montague, Richard. 1974b. Universal
grammar. In R. Thomason, editor, Formal
Philosophy. Yale University Press, New
York.
Muskens, Reinhard. 1998. Logic, reasoning
and underspecificatiort of linguistic
structure. Presented at a workshop in Bad
Teinach, Germany, May.
Pereira, Fernando C. N. 1990. Categorial
semantics and scoping. Computational
Linguistics, 16:1-9,
Pereira, Fernando C. N. 1991. Deductive
interpretation. In E. Klein and F. Veltman,
editors, Natural Language and Speech.
Springer Verlag, pages 116-133.
Pinkal, Manfred. 1995. Radical
underspecification. In Proceedings of the
lath Amsterdam Colloquium on Formal
Semantics, pages 587-606.
Poesio, Massimo, 1996. Semantic ambiguity
and perceived ambiguity. In S. Peters and
K. van Deemter, editors, Semantic
Ambiguity and Underspecification. CSLI,
pages 159-202.
Prehofer, Christian. 1994. Decidable
higher-order unification problems. In
Automated Deduction CADE-12, 12th
International Conference on Automated
Deduction. Springer, pages 635-649.
Prtist, Hub. 1992. On Discourse Structure, VP
Anaphora, and Gapping. Ph.D. thesis,
University of Amsterdam.
Pulman, Stephen G. 1986. Grarrunars,
parsers and memory limitations. Language
and Cognitive Processes, 1(3):197-225.
Pulman„ Stephen G. 1991. Comparatives and
ellipsis. In Proceedings of the 5th European
Meeting of the Association for Computational
Linguistics, pages 1-6. Berlin: ACL.
Pulman, Stephen G. 1994. A computational
theory of context dependence. In H. Bunt,
R. Muskens, and G. Rentier, editors,
Proceedings: International Workshop on
Computational Semantics, pages 161-170.
Institute for Language Technology,
Tilburg University The Netherlands.
Pullman, Stephen G. 1996. Unification
encodings of grammatical notations.
Computational Linguistics, 22(3):295-328.
Pulman, Stephen G. 1997a. Aspectual shift
as type coercion. Transactions of the
Philological Society, 95(2)279-317.
Putman, Stephen G. 1997b. Higher order
unification and the interpretation of
focus. Linguistics and Philosophy, 20:73-115.
Putman, Stephen G. 2000. Statistical and
logical reasoning in disambiguation.
Philosophical Transactions of the Royal
Society, Series A, 358(1,769):1,267-1,280.
Rayner, Manny. 1993. Abductive Equivalential
Translation and its application to Natural
Language Database Inferencing. Ph.D. thesis,
Stockholm University. Also available at
http://www.cam.sri.com/tr.
Rayner, Manny and Hiyart Alshawi. 1992.
Deriving database queries from logical
forms by abductive definition expansion.
In Proceedings of the 3rd International
Conference on Applied Natural Language
Processing, pages 1-8, Trento, Italy.
Association for Computational
Linguistics.
Reyle, Uwe. 1993. Dealing with ambiguities
by underspecification. Journal of Semantics,
10:123-179.
Reyle, Uwe, 1995. On reasoning with
ambiguities. In Proceedings of EACL 95,
pages 1-8. Association for Computational
Linguistics.
Reyle, Uwe. 1996. Co-indexing labelled
DRSS to represent and reason with
ambiguities. In S. Peters and K. van
Deemter, editors, Semantic Ambiguity and
Underspecification, pages 239-268. CSLI,
Thomas, James and Stephen G. Pulman.
1999. Bidirectional interpretation of tense
and aspect. In H. Bunt et al., editors,
Proceedings of the Third International
Workshop on Computational Semantics,
pages 247-263.
van Deemter, Kees. 1996. Towards a logic of
ambiguous expressions. In S. Peters and
K. van Deemter, editors, Semantic
Ambiguity and Underspecification. CSLI,
pages 203-238.
van Eijck, Jan and Jan Jaspars. 1996.
Ambiguity and reasoning. CWI Technical
Report CS-R9616.
Webber, Bonnie L. 1983. So what can we
talk about now? In M. Brady and
R. Berwick, editors, Computational Models
of Discourse. MIT Press, pages 331-371.
Woods, William. 1968. Procedural semantics
for a question-answering machine. In
Proceedings of the Fall Joint Computer
Conference, New York, pages 457-471, New
York.
Woods, William. 1978. Semantics and
quantification in natural language
question answering. In Yovits, editor,
Advances in Computers. Academic Press,
New York, pages 2-64.
</reference>
<page confidence="0.997388">
537
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.953923">
<title confidence="0.999735">Bidirectional Contextual Resolution</title>
<author confidence="0.999584">Stephen G Pulman</author>
<affiliation confidence="0.9997185">Centre for Linguistics and Philology, Oxford University</affiliation>
<abstract confidence="0.993399571428571">This paper describes a formalism and implementation for the interpretation and generation of sentences containing context-dependent constructs like determiners, pronouns, focus, and ellipsis. A variant of quasi-logical form is used as an underspecified meaning representation, related to resolved logical forms via conditional equivalences. These equivalences define the interpretation of contextually dependent constructs with respect to a given context. Higher-order unification and abduction are used in relating expressions to contexts. The conditional equivalences can be used unchanged in both the interpretation and the generation direction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Jan van Eijck van Deemter</author>
<author>Tim Fernando</author>
<author>Josef van Genabith</author>
<author>Jan Jaspars</author>
<author>Hans Kamp</author>
<author>Ron Kaplan</author>
<author>Stanley Peters</author>
</authors>
<title>This paper is a descendant of Pulman</title>
<date>1994</date>
<location>Ankara, IMS Stuttgart, Cambridge, Edinburgh, ITRI Brighton, Sheffield, Oxford, and</location>
<marker>van Deemter, Fernando, van Genabith, Jaspars, Kamp, Kaplan, Peters, 1994</marker>
<rawString>This paper is a descendant of Pulman (1994). Versions of it have been given at Bilkent University, Ankara, IMS Stuttgart, Cambridge, Edinburgh, ITRI Brighton, Sheffield, Oxford, and at workshops in Bad Teinach and SaarbrOckert. I thank the audiences on these occasions: I can remember (at least) Varol Akman, Nick Asher, Robin Cooper, Dick Crouch, Kees van Deemter, Jan van Eijck, Tim Fernando, Josef van Genabith, Jan Jaspars, Hans Kamp, Ron Kaplan, Stanley Peters, Manfred Pinkal, and Massimo Poesio making</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
</authors>
<title>Resolving quasi logical forms.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--4133</pages>
<contexts>
<context position="46130" citStr="Alshawi 1990" startWordPosition="6791" endWordPosition="6792">e to that proposed in Pereira (1990, 1991), with some differences that are commented on below. Like Pereira&apos;s approach, it avoids the need for a free variable constraint, nor does it need the explicit recursion on the quantifier restriction imposed by Lewin. We analyze quantified NPs at the QLF level as illustrated in the QLF for: (19) Every manager uses a computer. ex istsl ( e. pos( pres( u se(e,eve ry( m a na ger), a c.,„„(com put er)))) We assume that every determiner has its own equivalence, which resolves it as a quantifier: sometimes this can be quite a complicated matter, as with any (Alshawi 1990), which will resolve in different ways depending on its linguistic context, but here we avoid this complexity&apos; 6 Separate equivalences might also make it easier to encode determiner-specific preferences, such as that of each for wide scope. A referee points out that the lack of any explicit ordering of application of equivalences makes one natural way of doing this unavailable. But I am not convinced that this would have been the right way in any case. These preferences are just that, not hard and fast rules, so we need to be able to permit all permutations where the context, or the structure,</context>
<context position="64853" citStr="Alshawi (1990" startWordPosition="9520" endWordPosition="9521">forall(C--and(manager(C),in(C,B)), D--exists1(E--pos(pres(own(E,D,A))))))), no The missing combination which is correctly excluded is every - a - some. Clearly, these are small beginnings. But this small scale implementation demonstrates that the approach is computationally viable in principle. Issues to do with how to scale up to wider coverage are addressed later. 5. Comparison with Alternative Approaches 5.1 Core Language Engine Quasi-Logical Form The starting point for the approach followed here was a dissatisfaction with certain aspects of the theory of quasi-logical form as described in Alshawi (1990, 1992), and implemented in SRI&apos;s Core Language Engine (CLE). In the CLE-QLF approach, as ra519 Computational Linguistics Volume 26, Number 4 tionally reconstructed by Alshawi and Crouch (1992) and Crouch and Putman (1994), the context-independent meaning of a sentence is given by one or more QLFs that are built directly from syntactic and semantic rules. Just as here, these QLFs represent the basic predicate argument structure of the sentence, and contain constructs which represent those aspects of the meaning of the sentence that are dependent on context. The effects of contextual resolution</context>
</contexts>
<marker>Alshawi, 1990</marker>
<rawString>Alshawi, Hiyan. 1990. Resolving quasi logical forms. Computational Linguistics, 16(4133-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
</authors>
<title>The Core Language Engine.</title>
<date>1992</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="9199" citStr="Alshawi 1992" startWordPosition="1387" endWordPosition="1388"> as their content, hence context must contain this information too. We obviously need some nonlinguistic information. We also need some structure to reflect the fact that not all components of the context are relevant to everything, hence salience. This is all we need for the time being, although there is clearly much more to be said. 1 This is probably too strong a position to take. There are good arguments for allowing some syntactic distinctions to be represented more directly. 499 Computational Linguistics Volume 26, Number 4 4. QLFs are interpreted by conditional equivalences (Rayner and Alshawi 1992; Rayner 1993) of the form: QLF &lt;=&gt; RLF if Conditioni, , Condition„. These state a contextual equivalence between an expression containing one or more QLF constructs (the left-hand side) and an expression containing at least one fewer QLF constructs (the right-hand side). QLF and RLF are therefore sometimes used to signify partially as well as fully (un)resolved LFs. An equivalence can be paraphrased as: &amp;quot;In a context where these conditions hold, this QLF can be interpreted as this RLF,&amp;quot; or &amp;quot;In a context where these conditions hold, this RLF can be expressed as this QLF.&amp;quot; Conditional equivalen</context>
</contexts>
<marker>Alshawi, 1992</marker>
<rawString>Alshawi, Hiyan. 1992. The Core Language Engine. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
<author>David M Carter</author>
</authors>
<title>Training and scaling preference functions for disambiguation.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--4</pages>
<contexts>
<context position="106408" citStr="Alshawi and Carter 1994" startWordPosition="16300" endWordPosition="16303">tion in the fully general case, because it is quite conceivable that lexical disambiguation could require some contextual disambiguation first. Likewise, many PP attachment decisions have to be made on contextual grounds. There are several stategies that might be pursued. One is to adopt Pinkal&apos;s &amp;quot;radical underspecification&amp;quot; approach (Pirikal 1995) and use underspecified representations for all types of ambiguity, even syntactic ambiguity. The more conservative approach is to try to integrate existing statistical disambiguation schemes for QLFs, either individually or in a &amp;quot;packed&amp;quot; structure (Alshawi and Carter 1994), with the resolution process as described here. Alternatively, I believe it is worth exploring the approach to disambiguation described in Pulman (2000), which would mesh nicely with the theory presented here. Efficiency. Extending coverage of linguistic constructs, and trying to achieve robustness or integrate with disambiguation schemes each pose the further problem of the efficiency of the HOLT-based resolution process itself. While efficiency is acceptable for the short, simple sentences illustrated earlier, the computational properties of HOU mean that processing times increase in a high</context>
</contexts>
<marker>Alshawi, Carter, 1994</marker>
<rawString>Alshawi, Hiyan and David M. Carter. 1994. Training and scaling preference functions for disambiguation. Computational Linguistics, 20(4):635-648.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
<author>Richard Crouch</author>
</authors>
<title>Monotonic semantic interpretation.</title>
<date>1992</date>
<booktitle>In Proceedings of the 30th Annual Meeting,</booktitle>
<pages>33--39</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4527" citStr="Alshawi and Crouch (1992)" startWordPosition="672" endWordPosition="675"> contextual interpretation of pronouns, definites, ellipsis, focus, and quantifier scope. There is far more to say about each of these phenomena, of course, and the analyses here are by no means claimed to be definitive. The aim is merely to show that we can, to a first approximation, provide a reasonably fully worked out description of these phenomena in a truly bidirectional way. We then go on to compare the current approach with that of some other theories with similar aims: the &amp;quot;standard&amp;quot; version of quasi-logical form implemented in the Core Language Engine, as rationally reconstructed by Alshawi and Crouch (1992) and Crouch and Pulman (1994); underspecified Discourse Representation Theory (Reyle 1993); and the &amp;quot;glue language&amp;quot; approach of Dalrymple et al. (1996). Finally, we discuss some of the semantic and logical issues raised by the approach described here, in particular the extent to which the theory meets the desiderata for accounts of underspecification outlined by van Eijck and Jaspars (1996), and the extent to which the theory supplies a methodologically satisfactory account of truth and interpretation for sentences involving contextually dependent constructs. 2. Contextual Interpretation The m</context>
<context position="6940" citStr="Alshawi and Crouch 1992" startWordPosition="1029" endWordPosition="1032">terpretation mechanism, assuming only that the same grammatical description is used in both the analysis and generation direction. What is required is that QLFs are, as here, expressed in a typed higher-order logic, augmented with constructs representing the interpretation of context-dependent elements (pronouns, ellipsis, focus, etc.). These constructs correspond as directly as possible to properties of the linguistic structure that express them and are, to as small an extent as possible, dependent on the requirements of contextual resolution (unlike, say, the metavariables of standard QLFs [Alshawi and Crouch 1992], or the labels of UDRS [Reyle 1996], which are motivated entirely by the mechanisms that operate on them after grammatical processing). Syntactic properties relevant for binding constraints, parallelism, scope constraints, and so on, are not directly represented at QLF (again unlike standard QLFs) but are assumed to be available as components of the linguistic context.&apos; The context-independent meanings of sentences, which we refer to as resolved logical forms (RLFs), are expressed in the &amp;quot;ordinary&amp;quot; subset of the QLF language. A fully resolved RLF can be directly evaluated for truth: it conta</context>
<context position="65046" citStr="Alshawi and Crouch (1992)" startWordPosition="9547" endWordPosition="9550">nnings. But this small scale implementation demonstrates that the approach is computationally viable in principle. Issues to do with how to scale up to wider coverage are addressed later. 5. Comparison with Alternative Approaches 5.1 Core Language Engine Quasi-Logical Form The starting point for the approach followed here was a dissatisfaction with certain aspects of the theory of quasi-logical form as described in Alshawi (1990, 1992), and implemented in SRI&apos;s Core Language Engine (CLE). In the CLE-QLF approach, as ra519 Computational Linguistics Volume 26, Number 4 tionally reconstructed by Alshawi and Crouch (1992) and Crouch and Putman (1994), the context-independent meaning of a sentence is given by one or more QLFs that are built directly from syntactic and semantic rules. Just as here, these QLFs represent the basic predicate argument structure of the sentence, and contain constructs which represent those aspects of the meaning of the sentence that are dependent on context. The effects of contextual resolution are uniformly represented via the instantiation of metavariables. This instantiation is brought about by the operation of resolution rules, which are essentially user-defined Prolog predicates</context>
<context position="67677" citStr="Alshawi and Crouch (1992)" startWordPosition="9913" endWordPosition="9916">erm(q,every,+1,philosopher), term(chsome,+2,book)) RQLF = L+1,+2]:like(term(q,every,+1,philosopher), term(q,some,+2,book)) % every some ... [+2,+1]:1ike(term(q,every,+1,philosopher), term(q,some,+2,book)) % some ... every ... The denotational semantics of RQLF structures involving instantiated scope and referent metavariables is given in terms of simple interpretation rules that have the effect of interpreting the quantifiers as having the scopes indicated by the lists of indices, and the pronouns as having the interpretation of the instantiation of the metavariable (in these cases at least). Alshawi and Crouch (1992) present an illustrative first-order fragment along these lines and are able to supply a coherent formal semantics for the CLF-QLFs themselves, using a technique essentially equivalent to supervaluations: a QLF is true iff all its possible RQLFs are, false iff they are all false, and undefined otherwise. There are many good things about this approach. It has proved itself amenable to a large-scale implementation of impressive coverage, generality, and relative efficiency (Alsha.wi 1992). It has the theoretically desirable property of monotonicity and, 520 Pulman Bidirectional Contextual Resolu</context>
<context position="71288" citStr="Alshawi and Crouch (1992)" startWordPosition="10456" endWordPosition="10459">lication system in a context-dependent way quite difficult: rather than being related to an RQLF, this output has to be related to a QLF that is sufficiently instantiated for a contextually unambiguous sentence to be generated from it. The resolution mechanism is not intended to be reversible, although by redefining resolution rules, reversibility is achievable to some extent within the limitations just discussed (Hurst 1994). A third problem arises with the approach to the semantics of QLFs that this notion of the relationship between QLF and RQLF encourages one to adopt: it is that taken by Alshawi and Crouch (1992). This describes the semantics of QLFs via a supervaluation over the semantics of the RQLFs that they subsume. Although the problem does not arise for the simple fragment they illustrate there, if their approach were extended to cover a wider range of constructions, it would be found that many QLFs subsumed RQLFs that are not actually permitted by the resolution rules: for example, those that can only arise via a violation of scoping or binding constraints. The role of resolution rules (for perfectly good presentational reasons) is completely ignored by their treatment. However, it is really t</context>
</contexts>
<marker>Alshawi, Crouch, 1992</marker>
<rawString>Alshawi, Hiyan and Richard Crouch. 1992. Monotonic semantic interpretation. In Proceedings of the 30th Annual Meeting, pages 33-39. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Damaris M Ayuso</author>
</authors>
<title>Discourse entities in Janus.</title>
<date>1989</date>
<booktitle>In Proceedings of the 27th Annual Meeting,</booktitle>
<pages>243--250</pages>
<institution>Vancouver. Association for Computational Linguistics.</institution>
<marker>Ayuso, 1989</marker>
<rawString>Ayuso, Damaris M. 1989. Discourse entities in Janus. In Proceedings of the 27th Annual Meeting, pages 243-250, Vancouver. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Barwise</author>
<author>John Perry</author>
</authors>
<title>Situations and Attitudes.</title>
<date>1983</date>
<publisher>MIT Press.</publisher>
<location>Crouch, Richard</location>
<marker>Barwise, Perry, 1983</marker>
<rawString>Barwise, John and John Perry. 1983. Situations and Attitudes. MIT Press. Crouch, Richard and Josef van Genabith.</rawString>
</citation>
<citation valid="true">
<title>On interpreting f-structures as UDRSs.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the ACL and the 8th Conference of the European Chapter of the ACL,</booktitle>
<pages>402--409</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="35799" citStr="(1997)" startWordPosition="5284" endWordPosition="5284">didates for parallel elements and the value of the Predicate that corresponds to the Ellipsis variable in the description of DSP above. Some sortal conditions within both the equivalence and the predicate parallel are necessary to make sure that the variables PolarityTenseEtc are appropriately instantiated, since there are many possibilities consistent with their type requirements. But no extralogical mechanisms are needed, apart from the definition of &amp;quot;parallel,&amp;quot; which is intended to correspond to the notion discussed in Dalrymple, Shieber, and Pereira (1991), Priist (1992), Hobbs and Kehler (1997), and Gardent and Kohlhase (1997), among others. Parallelism may involve syntactic, semantic, pragmatic, and discourse components, depending on the construction involved. VP deletion, for example, requires the parallel element to be the subject of the preceding conjunct as well as being in the same domain of quantification as the remnant; whereas phrasal ellipsis like and John merely requires the antecedent to be in the same domain of quantification. Now given a sequence like: (15) Smith liked Sandy. Jones didn&apos;t. where the antecedent logical form and the QLF to be resolved are respectively: e</context>
<context position="83646" citStr="(1997)" startWordPosition="12426" endWordPosition="12426">rtial orders of scoping relations. Secondly, it should be able in effect to emulate the DRT treatment of donkey sentences (p. 243) (a somewhat parochial requirement, given that the case is not yet closed on whether this treatment is correct: see Elworthy [19951, among others). Thirdly, the theory should not need anything like the free variable constraint. 526 Pulman Bidirectional Contextual Resolution Clearly, UDRS meets these requirements, as does our own QLF-based approach. There are some similarities between the UDRS and the glue language approaches, as detailed in Crouch and van Geriabith (1997). There are also some differences: unlike our approach, or the glue language approach, UDRS does not have the problem of how to represent the meaning of quantified NPs as things of different type at different levels. However, it achieves this at the cost of not representing the meanings of quantified NPs as independent units at all: determiner and restriction are separate components that have no close connection to each other until the inclusion constraints are imposed. It remains to be seen whether this unconstrained approach to semantic assembly can be implemented on a large scale, given tha</context>
<context position="92904" citStr="(1997)" startWordPosition="13980" endWordPosition="13980">s of the utterance support both of these contexts. To summarize, on our theory, if we interpret as logical equivalence, then we are committed to the claim that no utterance (where the context is fully specified) is truly ambiguous. (This does not entail that particular speakers must be able to fully resolve all utterances.) That is to say, there must be some feature of the form and content of the utterance, or the context in which it is produced, that exclude all but one of the possible interpretations. 6.2 Truth and Consequence In van Deemter (1996), van Eijck and Jaspars (1996), and Jaspars (1997), criteria for a notion of ambiguous consequence are outlined. In the following, R1 and Rz are (all) the resolutions of Q, and is an ambiguous consequence relation. We can summarize these requirements as follows: Q k, RI or R2 Ri and R2 Q Q ja -R1 Or -7R2 -,R1 and -,R2 =a -Q Q Ri and R2 Ri or R2 Q and -,R2 -,E.1 or -1R2 -Q If an ambiguous expression is true then at least one of its readings is true (1). But the stronger version, that all readings are true, is not plausible (5). This would mean that any expression with mutually contradictory readings would lead to inconsistency. (The CLE-QLF su</context>
</contexts>
<marker>1997</marker>
<rawString>1997. On interpreting f-structures as UDRSs. In Proceedings of the 35th Annual Meeting of the ACL and the 8th Conference of the European Chapter of the ACL, pages 402-409. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard S Crouch</author>
<author>Stephen G Pulman</author>
</authors>
<title>Monotonic semantics. In</title>
<date>1994</date>
<booktitle>Describing the Approaches: Deliverable D8 of the FraCaS Project. Cognitive Science, University of Edinburgh,</booktitle>
<pages>184--218</pages>
<editor>R. Cooper, R. Crouch, J. van Eijck, C. Fox, J. van Genabith, J. Jaspars, H. Kamp, M. Pinkal, M. Pocsio, S. C. Pulman, and E. Vestre, editors,</editor>
<note>Available from ftp.cogsci.ed.ac.uk/pub/FRACAS.</note>
<contexts>
<context position="4556" citStr="Crouch and Pulman (1994)" startWordPosition="677" endWordPosition="680">pronouns, definites, ellipsis, focus, and quantifier scope. There is far more to say about each of these phenomena, of course, and the analyses here are by no means claimed to be definitive. The aim is merely to show that we can, to a first approximation, provide a reasonably fully worked out description of these phenomena in a truly bidirectional way. We then go on to compare the current approach with that of some other theories with similar aims: the &amp;quot;standard&amp;quot; version of quasi-logical form implemented in the Core Language Engine, as rationally reconstructed by Alshawi and Crouch (1992) and Crouch and Pulman (1994); underspecified Discourse Representation Theory (Reyle 1993); and the &amp;quot;glue language&amp;quot; approach of Dalrymple et al. (1996). Finally, we discuss some of the semantic and logical issues raised by the approach described here, in particular the extent to which the theory meets the desiderata for accounts of underspecification outlined by van Eijck and Jaspars (1996), and the extent to which the theory supplies a methodologically satisfactory account of truth and interpretation for sentences involving contextually dependent constructs. 2. Contextual Interpretation The major components and assumptio</context>
</contexts>
<marker>Crouch, Pulman, 1994</marker>
<rawString>Crouch, Richard S. and Stephen G. Pulman. 1994. Monotonic semantics. In R. Cooper, R. Crouch, J. van Eijck, C. Fox, J. van Genabith, J. Jaspars, H. Kamp, M. Pinkal, M. Pocsio, S. C. Pulman, and E. Vestre, editors, Describing the Approaches: Deliverable D8 of the FraCaS Project. Cognitive Science, University of Edinburgh, pages 184-218. Available from ftp.cogsci.ed.ac.uk/pub/FRACAS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Dalrymple</author>
<author>J Lamping</author>
<author>Fernando C N Pereira</author>
<author>Vijay Saraswat</author>
</authors>
<title>Quantifiers, anaphora, and intensionality.</title>
<date>1996</date>
<journal>Journal of Logic, Language, and Information,</journal>
<pages>6--3</pages>
<contexts>
<context position="4678" citStr="Dalrymple et al. (1996)" startWordPosition="693" endWordPosition="696">se, and the analyses here are by no means claimed to be definitive. The aim is merely to show that we can, to a first approximation, provide a reasonably fully worked out description of these phenomena in a truly bidirectional way. We then go on to compare the current approach with that of some other theories with similar aims: the &amp;quot;standard&amp;quot; version of quasi-logical form implemented in the Core Language Engine, as rationally reconstructed by Alshawi and Crouch (1992) and Crouch and Pulman (1994); underspecified Discourse Representation Theory (Reyle 1993); and the &amp;quot;glue language&amp;quot; approach of Dalrymple et al. (1996). Finally, we discuss some of the semantic and logical issues raised by the approach described here, in particular the extent to which the theory meets the desiderata for accounts of underspecification outlined by van Eijck and Jaspars (1996), and the extent to which the theory supplies a methodologically satisfactory account of truth and interpretation for sentences involving contextually dependent constructs. 2. Contextual Interpretation The major components and assumptions of the approach to contextual interpretation here are as follows: 1. We assume that the output of grammatical processin</context>
<context position="73925" citStr="Dalrymple et al. 1996" startWordPosition="10875" endWordPosition="10879">ctly reversible. • the semantics of QLFs is completely given by the conditional equivalences that relate them to RLFs, thus avoiding the problem of the subsumption-based treatment and the associated supervaluation semantics. (More detail on precisely how this semantic account works is given below.) • conditional equivalences are a formal language for resolution rules, thus bringing them within the scope of the theory. 5.2 Glue Language Within the LFG framework, Dalrymple and her colleagues have been working on a linear logic glue language approach to semantic assembly and uncierspecification (Dalrymple et al. 1996). LFG distinguishes two different levels of syntactic representation: constituent structure and functional structure (f-structure) at which the basic syntactic relations are distinguished (subject, object, etc.). Semantic interpretation is also at two levels: a a-projection maps an f-structure to a a-structure. Although a-structures are described as semantic structures, they are not themselves meanings. Rather they are connected to meanings or logical forms via which the authors describe as an otherwise uninterpreted binary predicate symbol. Given a a-structure and the meaning constructors ass</context>
<context position="81313" citStr="Dalrymple et al. (1996)" startWordPosition="12050" endWordPosition="12053"> a set of labels for the conditions in the boxes and the relations between them, and partial relations of inclusion between (the components indexed by) these labels. When sentences are fully scoped, the representations are like standard DRT with extra labels. Thus a sentence like (45) Every manager owns a computer. would be represented in its different scopings by: 11: 12 14: 15:computer(y) 16:owns(x,y) 13:manager(x) 8 The glue language approach makes much of the &amp;quot;resource sensitivity&amp;quot; of linear logic. But in the specific instances of the analysis of quantifier scope and pronouns discussed in Dalrymple et al. (1996), the linearity and resource sensitivity of the logic assumed is, as far as I can see, subverted by the device of &amp;quot;reinterpreting&amp;quot; constructs like the &amp;quot;scope&amp;quot; variable (see example 28) or the &amp;quot;reintroduction&amp;quot; of pronoun meanings (see example 39). 525 Computational Linguistics Volume 26, Number 4 15:computer(y) 12. 13:martager(x) 14 16:owns(x,y) But a representation which does not specify the scoping in ambiguous cases can be given by listing the component elements, along with the inclusion ordering that determines the scoping. The components are: and: 11: 14: , 12: 13: manager(x) 15: computer(</context>
</contexts>
<marker>Dalrymple, Lamping, Pereira, Saraswat, 1996</marker>
<rawString>Dalrymple, Mary, J. Lamping, Fernando C. N. Pereira, and Vijay Saraswat. 1996. Quantifiers, anaphora, and intensionality. Journal of Logic, Language, and Information, 6(3):219-273.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Dalrymple</author>
<author>Stuart M Shieber</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Ellipsis and higher-order unification. Linguistics and Philosophy,</title>
<date>1991</date>
<pages>14--4</pages>
<marker>Dalrymple, Shieber, Pereira, 1991</marker>
<rawString>Dalrymple, Mary, Stuart M. Shieber, and Fernando C. N. Pereira. 1991. Ellipsis and higher-order unification. Linguistics and Philosophy, 14(4):399-452.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Davidson</author>
</authors>
<title>Semantics for natural languages. In</title>
<date>1972</date>
<booktitle>Semantics of Natural Language. Reidel. Also in Davidson, 1984, Inquiries into Truth and Interpretation,</booktitle>
<pages>55--64</pages>
<editor>D. Davidson and G. Harman, editors,</editor>
<location>Oxford,</location>
<contexts>
<context position="3583" citStr="Davidson (1972)" startWordPosition="517" endWordPosition="518">interpretation, uses an intermediate quasi-logical form representation level. Using such a level of representation incurs an obligation to say what it means (&amp;quot;no notation without denotation&amp;quot;). We try to show how the theory presented here leads to a natural semantics for these quasi-logical forms, and indeed leads to a truth theory for contextually dependent interpretation that supports a natural consequence relation, and one appropriate for cases where interpretations are not fully specified. We relate this approach both to the classical tradition of formal linguistic semantics exemplified by Davidson (1972) and Montague (1974b) and more recent literature on the use of underspecification in semantics. The structure of the paper is as follows: In the next section we give an outline of the formalism and illustrate with the small fragment of English that has been implemented within this framework. We present analyses of the contextual interpretation of pronouns, definites, ellipsis, focus, and quantifier scope. There is far more to say about each of these phenomena, of course, and the analyses here are by no means claimed to be definitive. The aim is merely to show that we can, to a first approximat</context>
</contexts>
<marker>Davidson, 1972</marker>
<rawString>Davidson, Donald. 1972. Semantics for natural languages. In D. Davidson and G. Harman, editors, Semantics of Natural Language. Reidel. Also in Davidson, 1984, Inquiries into Truth and Interpretation, Oxford, pages 55-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A H Elworthy</author>
</authors>
<title>A theory of anaphoric information.</title>
<date>1995</date>
<journal>Linguistics and Philosophy,</journal>
<pages>18--3</pages>
<marker>Elworthy, 1995</marker>
<rawString>Elworthy, David A. H. 1995. A theory of anaphoric information. Linguistics and Philosophy, 18(3):297-332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Gardent</author>
<author>Michael Kohlhase</author>
</authors>
<title>Focus and higher-order unification.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<pages>430--435</pages>
<location>Copenhagen.</location>
<contexts>
<context position="21313" citStr="Gardent and Kohlhase 1996" startWordPosition="3246" endWordPosition="3249">alence is: Pron-he-intra Rest(_„„(Ay.Pred(y,he)) &lt;4= Rest.„( Pred(y,y)) if binding_conditions_hold.... This equivalence is doing essentially the same job as Pereira&apos;s pronoun abstraction schema in Pereira (1990). It will identify a pronoun with any term of type e elsewhere in the QLF, relying on the binding conditions to prevent impossible associations. 3 For this case, and for many other types of restrictions currently handled by conditions, more elegant solutions are available using the &amp;quot;sorted&amp;quot; and &amp;quot;colored&amp;quot; versions of higher-order unification developed by Michael Kohlhase and colleagues (Gardent and Kohlhase 1996b, 1997; Gardent Kohlhase, and van Leusen 1996; Gardent, Kohlhase, and Konrad 1999). 503 Computational Linguistics Volume 26, Number 4 We illustrate this equivalence with the relevant instantiations for the following cases (in fact, the reflexive case is done with a separate equivalence differing only in that it mentions he-self instead of he, with associated differences in binding conditions): (3) Smith admires himself. QLF=existsl()e.pos(pres(like(e,smith,he-self)))) Rest= AQ.Q(smith) Pred=Ax-Ny.existsl(Ae.pos(pres(like,e,x,y))) RLF=existsl(Ne.pos(pres(like(e,smith,smith)))) (4) Smith likes </context>
</contexts>
<marker>Gardent, Kohlhase, 1996</marker>
<rawString>Gardent, Claire and Michael Kohlhase. 1996a. Focus and higher-order unification. In Proceedings of the 16th International Conference on Computational Linguistics, pages 430-435, Copenhagen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Gardent</author>
<author>Michael Kohlhase</author>
</authors>
<title>Higher-order colored unification and natural language semantics.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting,</booktitle>
<pages>1--9</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="21313" citStr="Gardent and Kohlhase 1996" startWordPosition="3246" endWordPosition="3249">alence is: Pron-he-intra Rest(_„„(Ay.Pred(y,he)) &lt;4= Rest.„( Pred(y,y)) if binding_conditions_hold.... This equivalence is doing essentially the same job as Pereira&apos;s pronoun abstraction schema in Pereira (1990). It will identify a pronoun with any term of type e elsewhere in the QLF, relying on the binding conditions to prevent impossible associations. 3 For this case, and for many other types of restrictions currently handled by conditions, more elegant solutions are available using the &amp;quot;sorted&amp;quot; and &amp;quot;colored&amp;quot; versions of higher-order unification developed by Michael Kohlhase and colleagues (Gardent and Kohlhase 1996b, 1997; Gardent Kohlhase, and van Leusen 1996; Gardent, Kohlhase, and Konrad 1999). 503 Computational Linguistics Volume 26, Number 4 We illustrate this equivalence with the relevant instantiations for the following cases (in fact, the reflexive case is done with a separate equivalence differing only in that it mentions he-self instead of he, with associated differences in binding conditions): (3) Smith admires himself. QLF=existsl()e.pos(pres(like(e,smith,he-self)))) Rest= AQ.Q(smith) Pred=Ax-Ny.existsl(Ae.pos(pres(like,e,x,y))) RLF=existsl(Ne.pos(pres(like(e,smith,smith)))) (4) Smith likes </context>
</contexts>
<marker>Gardent, Kohlhase, 1996</marker>
<rawString>Gardent, Claire and Michael Kohlhase. 1996b. Higher-order colored unification and natural language semantics. In Proceedings of the 34th Annual Meeting, pages 1-9. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Gardent</author>
<author>Michael Kohlhase</author>
</authors>
<title>Computing parallelism in discourse.</title>
<date>1997</date>
<booktitle>In Proceedings of IJCAI &apos;97,</booktitle>
<pages>1016--1021</pages>
<location>Tokyo.</location>
<contexts>
<context position="35832" citStr="Gardent and Kohlhase (1997)" startWordPosition="5286" endWordPosition="5289">parallel elements and the value of the Predicate that corresponds to the Ellipsis variable in the description of DSP above. Some sortal conditions within both the equivalence and the predicate parallel are necessary to make sure that the variables PolarityTenseEtc are appropriately instantiated, since there are many possibilities consistent with their type requirements. But no extralogical mechanisms are needed, apart from the definition of &amp;quot;parallel,&amp;quot; which is intended to correspond to the notion discussed in Dalrymple, Shieber, and Pereira (1991), Priist (1992), Hobbs and Kehler (1997), and Gardent and Kohlhase (1997), among others. Parallelism may involve syntactic, semantic, pragmatic, and discourse components, depending on the construction involved. VP deletion, for example, requires the parallel element to be the subject of the preceding conjunct as well as being in the same domain of quantification as the remnant; whereas phrasal ellipsis like and John merely requires the antecedent to be in the same domain of quantification. Now given a sequence like: (15) Smith liked Sandy. Jones didn&apos;t. where the antecedent logical form and the QLF to be resolved are respectively: existsl(Ae.pos(past(like(e,smith,s</context>
</contexts>
<marker>Gardent, Kohlhase, 1997</marker>
<rawString>Gardent, Claire and Michael Kohlhase. 1997. Computing parallelism in discourse. In Proceedings of IJCAI &apos;97, pages 1016-1021, Tokyo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Gardent</author>
<author>Michael Kohlhase</author>
<author>Karsten Konrad</author>
</authors>
<title>Higher-order colored unification: A linguistic application.</title>
<date>1999</date>
<booktitle>Technique et Sciences Informatiques, Special Issue for JFPLC-UNIF&apos;97,</booktitle>
<pages>18--2</pages>
<marker>Gardent, Kohlhase, Konrad, 1999</marker>
<rawString>Gardent, Claire, Michael Kohlhase, and Karsten Konrad. 1999. Higher-order colored unification: A linguistic application. Technique et Sciences Informatiques, Special Issue for JFPLC-UNIF&apos;97, 18(2):181-209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Gardent</author>
<author>Michael Kohlhase</author>
<author>Noor van Leusen</author>
</authors>
<title>Corrections and higher-order unification.</title>
<date>1996</date>
<booktitle>In Proceedings of KONVENS&apos;96,</booktitle>
<pages>268--279</pages>
<location>Bielefeld, Germany. De Gruyter.</location>
<marker>Gardent, Kohlhase, van Leusen, 1996</marker>
<rawString>Gardent, Claire, Michael Kohlhase, and Noor van Leusen. 1996. Corrections and higher-order unification. In Proceedings of KONVENS&apos;96, pages 268-279, Bielefeld, Germany. De Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean M Gawron</author>
</authors>
<title>Pocus and ellipsis in comparatives and superlatives: A case study.</title>
<date>1992</date>
<booktitle>Proceedings of the Second Conference on Semantics and Linguistic Theory, Working Papers in Linguistics No.</booktitle>
<volume>40</volume>
<pages>79--98</pages>
<editor>In C. Barker and D. Dowty, editors,</editor>
<publisher>Ohio University Press.</publisher>
<institution>Ohio State University,</institution>
<contexts>
<context position="10987" citStr="Gawron 1992" startWordPosition="1669" endWordPosition="1670">ference involved in checking conditions beyond that provided by Prolog and the like to allow conditions to be &amp;quot;abduced&amp;quot; and added to the context if they cannot be proved directly, always provided that adding them to the context does not cause a contradiction. We assume some &amp;quot;cost&amp;quot; mechanism constrains this process. 6. Equivalences describe QLF or RLF patterns, typically containing variables. Determining whether an equivalence applies to a QLF or an RLF is done by higher-order unification (henceforth, HOU) (Huet 1975; Miller and Nadathur 4986; Pulman 1991; Dalrymple, Shieber, and Pereira 1991; Gawron 1992) of the logical form with the relevant pattern. Many of the contextual conditions require a higher-order equation to be solved. 7. The interpretation of a QLF is given via the RLFs it can be equivalent to with respect to given contexts. Given a fixed, fully-specified context, a QLF will generally be equivalent to a single RLF (unless the equivalences allow for several synonymous interpretations). In cases where the context does not resolve an ambiguity, the QLF will correspond to different RLFs depending on which assumptions are added to the context. Likewise, given a partially specified conte</context>
<context position="33793" citStr="Gawron 1992" startWordPosition="5009" endWordPosition="5010">th a tensed relative clause, so another paraphrase of the resolved logical form will be: (13) The computer that Smith bought disappeared. In fact, similar effects can be obtained for pronouns if some small tweaks to the relevant conditions are made: this turns out to be more than a neat trick, and is very useful in providing informative feedback on what resolutions have been chosen, when developing the system, or in the context of an application. 3.3 Ellipsis Not surprisingly, we can adapt a version of the HOU approach to ellipsis resolution (Dalrymple, Shieber, and Pereira 1991; Pulman 1991; Gawron 1992, 1995) very easily within this framework. On the DSP approach to VP ellipsis, an elliptical sentence like: (14) John likes fish and Mary does too. will be analyzed as follows. Firstly (ignoring tense, too, etc.) we represent the meaning of the elliptical conjunct with a free variable applied to the subject: Ellipsis(mary) Secondly we locate an element in the antecedent like(john,fish) that is parallel to mars&apos;, namely john. Next we construct a HOU equation: Ellipsis(john) = like(john,fish) the relevant solution to which instantiates the Ellipsis variable to Ax.like(x,fish), which when substit</context>
</contexts>
<marker>Gawron, 1992</marker>
<rawString>Gawron, Jean M. 1992. Pocus and ellipsis in comparatives and superlatives: A case study. In C. Barker and D. Dowty, editors, Proceedings of the Second Conference on Semantics and Linguistic Theory, Working Papers in Linguistics No. 40, Ohio State University, pages 79-98. Ohio University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean M Gawron</author>
</authors>
<title>Comparatives, superlatives, and resolution.</title>
<date>1995</date>
<journal>Linguistics and Philosophy,</journal>
<pages>18--333</pages>
<marker>Gawron, 1995</marker>
<rawString>Gawron, Jean M. 1995. Comparatives, superlatives, and resolution. Linguistics and Philosophy, 18:333-380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Coherence and coreference.</title>
<date>1979</date>
<journal>Cognitive Science,</journal>
<pages>3--1</pages>
<contexts>
<context position="17049" citStr="Hobbs 1979" startWordPosition="2632" endWordPosition="2633">away from these issues, and also avoid questions of how the correct interpretation is actually chosen, where there is a choice. The conditions in this pronoun equivalence are stated in terms of several predicates that recur in the treatment of different phenomena. The predicate salientContext(Construct,Context) finds a logical form that is a salient one for the current construct in the context. Having the construct as a parameter enables search to be reduced: pronouns and ellipsis typically find their antecedents in either an earlier portion of the current sentence, or the preceding sentence (Hobbs 1979), whereas definites frequently refer back over several previous sentences. We parameterize this predicate so that these preferences can be respected. The predicate possibleAntecedent(Context,Proform,Candidate) does most of the work. The simplest clause in its definition is: possibleAntecedent(Context,,he,ReQ if Context = _OtherPred(Ref), isOfType(he,Ref). where = means that the equation is solved by HOU, and the predicate isOfType carries out the obvious number and gender checks. More complete definitions of possibleAntecedent would include checks for the type of restriction often expressed as</context>
</contexts>
<marker>Hobbs, 1979</marker>
<rawString>Hobbs, Jerry R. 1979. Coherence and coreference. Cognitive Science, 3(1):67-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>Andrew Kehler</author>
</authors>
<title>A theory of parallelism and the case of vp-ellipsis.</title>
<date>1997</date>
<booktitle>in Proceedings of the 35th Annual Meeting of the ACL, and the 8th Conference of the European Chapter of the ACL,</booktitle>
<pages>394--401</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="35799" citStr="Hobbs and Kehler (1997)" startWordPosition="5281" endWordPosition="5284">ously suggest candidates for parallel elements and the value of the Predicate that corresponds to the Ellipsis variable in the description of DSP above. Some sortal conditions within both the equivalence and the predicate parallel are necessary to make sure that the variables PolarityTenseEtc are appropriately instantiated, since there are many possibilities consistent with their type requirements. But no extralogical mechanisms are needed, apart from the definition of &amp;quot;parallel,&amp;quot; which is intended to correspond to the notion discussed in Dalrymple, Shieber, and Pereira (1991), Priist (1992), Hobbs and Kehler (1997), and Gardent and Kohlhase (1997), among others. Parallelism may involve syntactic, semantic, pragmatic, and discourse components, depending on the construction involved. VP deletion, for example, requires the parallel element to be the subject of the preceding conjunct as well as being in the same domain of quantification as the remnant; whereas phrasal ellipsis like and John merely requires the antecedent to be in the same domain of quantification. Now given a sequence like: (15) Smith liked Sandy. Jones didn&apos;t. where the antecedent logical form and the QLF to be resolved are respectively: e</context>
</contexts>
<marker>Hobbs, Kehler, 1997</marker>
<rawString>Hobbs, Jerry R. and Andrew Kehler. 1997. A theory of parallelism and the case of vp-ellipsis. in Proceedings of the 35th Annual Meeting of the ACL, and the 8th Conference of the European Chapter of the ACL, pages 394-401. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>Stuart M Shieber</author>
</authors>
<title>An algorithm for generating quantifier scopings.</title>
<date>1987</date>
<journal>Computational Linguistics,</journal>
<pages>13--1</pages>
<contexts>
<context position="50063" citStr="Hobbs and Shieber 1987" startWordPosition="7342" endWordPosition="7345">een below, we need in any case something like the pair quantifier notation of Dalrymple, Shieber, and Pereira (1991), which would also solve this problem. With this addition we are able to produce both scopings for examples like: (20) Every manager in some company disappeared. This is a rather oversimplified treatment of quantifier scope, which we will refine a little shortly, but even as it stands the treatment has several advantages: • in classic examples like: (21) Every representative in a company saw most samples. only the available five relative scopings of the quantifiers are produced (Hobbs and Shieber 1987, 47), but without the need for a free variable constraint—the HOU algorithm will not produce any solutions in which a previously bound variable becomes free; • the equivalences are reversible, and thus the above sentences cart be generated from scoped logical forms; • partial scopings are permitted (see Reyle [19961) • scoping can be freely interleaved with other types of reference resolution; • unscoped or partially scoped forms are available for inference or for generation at every stage. 3.6 Comparison with Deductive Interpretation It is interesting to compare this analysis with that descr</context>
</contexts>
<marker>Hobbs, Shieber, 1987</marker>
<rawString>Hobbs, Jerry R. and Stuart M. Shieber. 1987. An algorithm for generating quantifier scopings. Computational Linguistics, 13(1-2):47-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Huet</author>
</authors>
<title>A unification algorithm for typed A-calculus.</title>
<date>1975</date>
<journal>Theoretical Computer Science,</journal>
<pages>1--27</pages>
<contexts>
<context position="10896" citStr="Huet 1975" startWordPosition="1656" endWordPosition="1657">nce. The interpretation of variables is as for Prolog. Later, we extend the notion of inference involved in checking conditions beyond that provided by Prolog and the like to allow conditions to be &amp;quot;abduced&amp;quot; and added to the context if they cannot be proved directly, always provided that adding them to the context does not cause a contradiction. We assume some &amp;quot;cost&amp;quot; mechanism constrains this process. 6. Equivalences describe QLF or RLF patterns, typically containing variables. Determining whether an equivalence applies to a QLF or an RLF is done by higher-order unification (henceforth, HOU) (Huet 1975; Miller and Nadathur 4986; Pulman 1991; Dalrymple, Shieber, and Pereira 1991; Gawron 1992) of the logical form with the relevant pattern. Many of the contextual conditions require a higher-order equation to be solved. 7. The interpretation of a QLF is given via the RLFs it can be equivalent to with respect to given contexts. Given a fixed, fully-specified context, a QLF will generally be equivalent to a single RLF (unless the equivalences allow for several synonymous interpretations). In cases where the context does not resolve an ambiguity, the QLF will correspond to different RLFs depending</context>
</contexts>
<marker>Huet, 1975</marker>
<rawString>Huet, Gerard. 1975. A unification algorithm for typed A-calculus. Theoretical Computer Science, 1:27-57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Hurst</author>
</authors>
<title>Reversible resolution with an application to paraphrasing.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics,</booktitle>
<pages>551--555</pages>
<location>Kyoto.</location>
<contexts>
<context position="71092" citStr="Hurst 1994" startWordPosition="10423" endWordPosition="10424"> take place to relate the RQLF for the interpreted sentence to a QLF that unambiguously expresses its contextualized meaning. This makes the task of expressing the output of some application system in a context-dependent way quite difficult: rather than being related to an RQLF, this output has to be related to a QLF that is sufficiently instantiated for a contextually unambiguous sentence to be generated from it. The resolution mechanism is not intended to be reversible, although by redefining resolution rules, reversibility is achievable to some extent within the limitations just discussed (Hurst 1994). A third problem arises with the approach to the semantics of QLFs that this notion of the relationship between QLF and RQLF encourages one to adopt: it is that taken by Alshawi and Crouch (1992). This describes the semantics of QLFs via a supervaluation over the semantics of the RQLFs that they subsume. Although the problem does not arise for the simple fragment they illustrate there, if their approach were extended to cover a wider range of constructions, it would be found that many QLFs subsumed RQLFs that are not actually permitted by the resolution rules: for example, those that can only</context>
</contexts>
<marker>Hurst, 1994</marker>
<rawString>Hurst, Matthew. 1994. Reversible resolution with an application to paraphrasing. In Proceedings of the 15th International Conference on Computational Linguistics, pages 551-555, Kyoto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Jaspars</author>
</authors>
<title>Minimal logics for reasoning with ambiguous expressions.</title>
<date>1997</date>
<note>Technical Report available from www.turing.wins.uva.n1/,-jaspars.</note>
<contexts>
<context position="92904" citStr="Jaspars (1997)" startWordPosition="13979" endWordPosition="13980">umstances of the utterance support both of these contexts. To summarize, on our theory, if we interpret as logical equivalence, then we are committed to the claim that no utterance (where the context is fully specified) is truly ambiguous. (This does not entail that particular speakers must be able to fully resolve all utterances.) That is to say, there must be some feature of the form and content of the utterance, or the context in which it is produced, that exclude all but one of the possible interpretations. 6.2 Truth and Consequence In van Deemter (1996), van Eijck and Jaspars (1996), and Jaspars (1997), criteria for a notion of ambiguous consequence are outlined. In the following, R1 and Rz are (all) the resolutions of Q, and is an ambiguous consequence relation. We can summarize these requirements as follows: Q k, RI or R2 Ri and R2 Q Q ja -R1 Or -7R2 -,R1 and -,R2 =a -Q Q Ri and R2 Ri or R2 Q and -,R2 -,E.1 or -1R2 -Q If an ambiguous expression is true then at least one of its readings is true (1). But the stronger version, that all readings are true, is not plausible (5). This would mean that any expression with mutually contradictory readings would lead to inconsistency. (The CLE-QLF su</context>
<context position="97338" citStr="Jaspars 1997" startWordPosition="14845" endWordPosition="14846">priate for reasoning with ambiguous sentences. Notice that several other properties that are desirable will also fall out of our truth definition. For example, we want it to be the case that 9. Q, —R1 R2 which says that if there is a true, two-ways ambiguous sentence and one of the interpretations is not true, the other one must be: perhaps the most basic kind of disambiguation strategy. It is in fact not completely trivial to arrive at such a conclusion without reducing ambiguity to disjunction: the logic of ambiguity in van Eijck and Jaspars (1996), for example, does not have this property (Jaspars 1997). But a version of (9) follows directly from T, with the additional conclusion that C2 must also hold. 6.3 Reasoning with QLFs Why would we want to be sure that we have a coherent semantics for QLFs and a sensible consequence relation? There are several reasons for doing so. Firstly, there are overwhelming arguments that some level like QLF is essential as part of a theory of utterance interpretation, both for linguistic and computational reasons. The practical arguments for this position are well known and have been implicit in computational practice since at least Woods (1968, 1978). It is s</context>
</contexts>
<marker>Jaspars, 1997</marker>
<rawString>Jaspars, Jan. 1997. Minimal logics for reasoning with ambiguous expressions. Technical Report available from www.turing.wins.uva.n1/,-jaspars.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
<author>Uwe Reyle</author>
</authors>
<title>From Discourse to Logic: Introduction to Model Theoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory.</title>
<date>1993</date>
<publisher>Kluwer.</publisher>
<contexts>
<context position="26805" citStr="Kamp and Reyle 1993" startWordPosition="3988" endWordPosition="3991">his problem will not arise.) The quantifier exists,„,„„,„ is here the translation of the indefinite article, although as is well known this is not the only alternative. We could encode DRT-like analyses directly via an equivalence creating a new discourse referent for an indefinite. On such an analysis, the earlier pronoun equivalence would apply to this discourse referent just as for a proper name, provided the appropriate number and gender information was available. By extending the definition of possibleAntecedent, we can combine with Webber&apos;s approach aspects of the DRT theory of plurals (Kamp and Reyle 1993) to account for examples like: (8) Every manager liked Smith. They admired him. 505 Computational Linguistics Volume 26, Number 4 possibleAntecedent(Context,they,DE) if Context = Pred(forall(Restriction,Body)), isOfType(they,sigma(Ax.Restriction(x) &amp; Body(x))), ciefine(DE,sigma(Ax Restriction(x) &amp; Body(x))). The antecedent sentence will be resolved to: forall(manager,Ax.existsl()e.pos(past(like(e,x,smith))))) Here they will be interpreted as i2, equivalent to: sigma()x.manager(x) &amp; existsl(Ae.pos(past(like(e,x,smith))))) where sigm„„ is an operator meaning &apos;the maximal set of things satisfying</context>
</contexts>
<marker>Kamp, Reyle, 1993</marker>
<rawString>Kamp, Hans and Uwe Reyle. 1993. From Discourse to Logic: Introduction to Model Theoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Kohlhase</author>
<author>Frank Pfenning</author>
</authors>
<title>Unification in a lambda calculus with intersection types.</title>
<date>1993</date>
<booktitle>Logic Programming: Proceedings of the 1993 International Symposium,</booktitle>
<pages>488--505</pages>
<editor>In Dale Miller, editor,</editor>
<publisher>MIT Press.</publisher>
<location>Vancouver.</location>
<marker>Kohlhase, Pfenning, 1993</marker>
<rawString>Kohlhase, Michael and Frank Pfenning. 1993. Unification in a lambda calculus with intersection types. In Dale Miller, editor, Logic Programming: Proceedings of the 1993 International Symposium, pages 488-505, Vancouver. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Lewin</author>
</authors>
<title>A quantifier scoping algorithm without a free variable constraint.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics,</booktitle>
<volume>3</volume>
<pages>190--194</pages>
<location>Helsinki, Finland.</location>
<contexts>
<context position="45438" citStr="Lewin (1990)" startWordPosition="6670" endWordPosition="6671">ocus structure of the sequence (18). The relation between utterance, focus, and context is such that either of the latter two reiata can be incompletely specified without preventing interpretation of the former. Any analysis of focus should be able to capture this phenomenon. The vital ingredient of the analysis here is the nondirectionality of inference provided by higher-order unification, supplemented by abduction. 3.5 Quantifier Scope We can implement a deductive theory of quantifier scope using the conditional equivalence mechanism. The version proposed here combines a basic insight from Lewin (1990) with higher-order unification to give an analysis that has a strong resemblance to that proposed in Pereira (1990, 1991), with some differences that are commented on below. Like Pereira&apos;s approach, it avoids the need for a free variable constraint, nor does it need the explicit recursion on the quantifier restriction imposed by Lewin. We analyze quantified NPs at the QLF level as illustrated in the QLF for: (19) Every manager uses a computer. ex istsl ( e. pos( pres( u se(e,eve ry( m a na ger), a c.,„„(com put er)))) We assume that every determiner has its own equivalence, which resolves it a</context>
</contexts>
<marker>Lewin, 1990</marker>
<rawString>Lewin, Ian. 1990. A quantifier scoping algorithm without a free variable constraint. In Proceedings of the 13th International Conference on Computational Linguistics, Volume 3, pages 190-194, Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dale Miller</author>
<author>Gopalan Nadathur</author>
</authors>
<title>Some uses of higher order unification in computational linguistics.</title>
<date>1986</date>
<booktitle>in Proceedings of the 24th Annual Meeting,</booktitle>
<pages>247--255</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Miller, Nadathur, 1986</marker>
<rawString>Miller, Dale and Gopalan Nadathur. 1986. Some uses of higher order unification in computational linguistics. in Proceedings of the 24th Annual Meeting, pages 247-255. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Montague</author>
</authors>
<title>The proper treatment of quantification in English. In</title>
<date>1974</date>
<pages>222--246</pages>
<editor>R. Thomason, editor, Formal Philosophy.</editor>
<publisher>Yale University Press,</publisher>
<location>New York,</location>
<contexts>
<context position="3602" citStr="Montague (1974" startWordPosition="520" endWordPosition="522"> an intermediate quasi-logical form representation level. Using such a level of representation incurs an obligation to say what it means (&amp;quot;no notation without denotation&amp;quot;). We try to show how the theory presented here leads to a natural semantics for these quasi-logical forms, and indeed leads to a truth theory for contextually dependent interpretation that supports a natural consequence relation, and one appropriate for cases where interpretations are not fully specified. We relate this approach both to the classical tradition of formal linguistic semantics exemplified by Davidson (1972) and Montague (1974b) and more recent literature on the use of underspecification in semantics. The structure of the paper is as follows: In the next section we give an outline of the formalism and illustrate with the small fragment of English that has been implemented within this framework. We present analyses of the contextual interpretation of pronouns, definites, ellipsis, focus, and quantifier scope. There is far more to say about each of these phenomena, of course, and the analyses here are by no means claimed to be definitive. The aim is merely to show that we can, to a first approximation, provide a reas</context>
</contexts>
<marker>Montague, 1974</marker>
<rawString>Montague, Richard. 1974a. The proper treatment of quantification in English. In R. Thomason, editor, Formal Philosophy. Yale University Press, New York, pages 222-246.</rawString>
</citation>
<citation valid="false">
<institution>Pulrnan Bidirectional Contextual Resolution</institution>
<marker></marker>
<rawString>Pulrnan Bidirectional Contextual Resolution</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Montague</author>
</authors>
<title>Universal grammar.</title>
<date>1974</date>
<editor>In R. Thomason, editor, Formal Philosophy.</editor>
<publisher>Yale University Press,</publisher>
<location>New York.</location>
<contexts>
<context position="3602" citStr="Montague (1974" startWordPosition="520" endWordPosition="522"> an intermediate quasi-logical form representation level. Using such a level of representation incurs an obligation to say what it means (&amp;quot;no notation without denotation&amp;quot;). We try to show how the theory presented here leads to a natural semantics for these quasi-logical forms, and indeed leads to a truth theory for contextually dependent interpretation that supports a natural consequence relation, and one appropriate for cases where interpretations are not fully specified. We relate this approach both to the classical tradition of formal linguistic semantics exemplified by Davidson (1972) and Montague (1974b) and more recent literature on the use of underspecification in semantics. The structure of the paper is as follows: In the next section we give an outline of the formalism and illustrate with the small fragment of English that has been implemented within this framework. We present analyses of the contextual interpretation of pronouns, definites, ellipsis, focus, and quantifier scope. There is far more to say about each of these phenomena, of course, and the analyses here are by no means claimed to be definitive. The aim is merely to show that we can, to a first approximation, provide a reas</context>
</contexts>
<marker>Montague, 1974</marker>
<rawString>Montague, Richard. 1974b. Universal grammar. In R. Thomason, editor, Formal Philosophy. Yale University Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Muskens</author>
</authors>
<title>Logic, reasoning and underspecificatiort of linguistic structure. Presented at a workshop in</title>
<date>1998</date>
<location>Bad Teinach, Germany,</location>
<contexts>
<context position="102687" citStr="Muskens (1998)" startWordPosition="15726" endWordPosition="15727">ng of the relative clause is correct. We can begin to capture such inferences by using proof rules for QLFs (partly modeled after those for UDRS in Reyle 11995]) such as these: CONJ: (where R is resolved, and Q may contain some unresolved constructs) R &amp; Q QUANT: (where Q is a downward monotone determiner, and P does not contain a negative) exists (R,P) COM and QUANT need considerable refinement in order to cover more than the simplest cases, but they will give the correct results for the latter two examples. For the first example something more is needed, perhaps along the lines suggested by Muskens (1998). 7. Conclusions and Further Work We have presented what is probably the first fully bidirectional formalism for the interpretation and generation of quasi-logical form representations and illustrated its application with a fragment of English grammar that contains (admittedly simple) instances of some of the most important types of context-dependent construct. This fragment has been fully implemented and works as advertised. We have tried to show that the interpretation of QLFs implicit in our treatment is a logically coherent one, supplying a kind of contextual truth definition for unresolve</context>
</contexts>
<marker>Muskens, 1998</marker>
<rawString>Muskens, Reinhard. 1998. Logic, reasoning and underspecificatiort of linguistic structure. Presented at a workshop in Bad Teinach, Germany, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
</authors>
<title>Categorial semantics and scoping.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--1</pages>
<contexts>
<context position="20899" citStr="Pereira (1990)" startWordPosition="3185" endWordPosition="3186">making this a general restriction on admissible solutions, as we have already been doing implicitly.3 Of course, this analysis of pronoun reference will cover only the simplest possible cases of intersentential anaphora. Before going on to more complex cases, we will also show how to deal with intrasentential anaphora, including reflexives, and binding of a pronoun by a quantifier. The relevant equivalence is: Pron-he-intra Rest(_„„(Ay.Pred(y,he)) &lt;4= Rest.„( Pred(y,y)) if binding_conditions_hold.... This equivalence is doing essentially the same job as Pereira&apos;s pronoun abstraction schema in Pereira (1990). It will identify a pronoun with any term of type e elsewhere in the QLF, relying on the binding conditions to prevent impossible associations. 3 For this case, and for many other types of restrictions currently handled by conditions, more elegant solutions are available using the &amp;quot;sorted&amp;quot; and &amp;quot;colored&amp;quot; versions of higher-order unification developed by Michael Kohlhase and colleagues (Gardent and Kohlhase 1996b, 1997; Gardent Kohlhase, and van Leusen 1996; Gardent, Kohlhase, and Konrad 1999). 503 Computational Linguistics Volume 26, Number 4 We illustrate this equivalence with the relevant in</context>
<context position="45552" citStr="Pereira (1990" startWordPosition="6689" endWordPosition="6690">e latter two reiata can be incompletely specified without preventing interpretation of the former. Any analysis of focus should be able to capture this phenomenon. The vital ingredient of the analysis here is the nondirectionality of inference provided by higher-order unification, supplemented by abduction. 3.5 Quantifier Scope We can implement a deductive theory of quantifier scope using the conditional equivalence mechanism. The version proposed here combines a basic insight from Lewin (1990) with higher-order unification to give an analysis that has a strong resemblance to that proposed in Pereira (1990, 1991), with some differences that are commented on below. Like Pereira&apos;s approach, it avoids the need for a free variable constraint, nor does it need the explicit recursion on the quantifier restriction imposed by Lewin. We analyze quantified NPs at the QLF level as illustrated in the QLF for: (19) Every manager uses a computer. ex istsl ( e. pos( pres( u se(e,eve ry( m a na ger), a c.,„„(com put er)))) We assume that every determiner has its own equivalence, which resolves it as a quantifier: sometimes this can be quite a complicated matter, as with any (Alshawi 1990), which will resolve i</context>
<context position="50727" citStr="Pereira (1990" startWordPosition="7446" endWordPosition="7447">straint—the HOU algorithm will not produce any solutions in which a previously bound variable becomes free; • the equivalences are reversible, and thus the above sentences cart be generated from scoped logical forms; • partial scopings are permitted (see Reyle [19961) • scoping can be freely interleaved with other types of reference resolution; • unscoped or partially scoped forms are available for inference or for generation at every stage. 3.6 Comparison with Deductive Interpretation It is interesting to compare this analysis with that described in Dalrymple, Shieber, and Pereira (1991) and Pereira (1990, 1991). Recall that in their treatment, quantified noun phrases are treated in two stages: firstly, what they call a &amp;quot;free variable&amp;quot; of type e is introduced in the NP position, with an associated &amp;quot;quantifier assumption,&amp;quot; which is added as a kind of premise. At a later stage the quantifier assumption is &amp;quot;discharged,&amp;quot; capturing all occurrences of the free variable. Thus their analysis of something like every manager disappeared would proceed as follows: every manager --= every(x,manager(x)) x disappeared disappear every manager disappeared every(x,manager(x)) disappear(x) - discharge the assump</context>
</contexts>
<marker>Pereira, 1990</marker>
<rawString>Pereira, Fernando C. N. 1990. Categorial semantics and scoping. Computational Linguistics, 16:1-9,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
</authors>
<title>Deductive interpretation.</title>
<date>1991</date>
<booktitle>Natural Language and Speech.</booktitle>
<pages>116--133</pages>
<editor>In E. Klein and F. Veltman, editors,</editor>
<publisher>Springer Verlag,</publisher>
<contexts>
<context position="10973" citStr="Pereira 1991" startWordPosition="1667" endWordPosition="1668">e notion of inference involved in checking conditions beyond that provided by Prolog and the like to allow conditions to be &amp;quot;abduced&amp;quot; and added to the context if they cannot be proved directly, always provided that adding them to the context does not cause a contradiction. We assume some &amp;quot;cost&amp;quot; mechanism constrains this process. 6. Equivalences describe QLF or RLF patterns, typically containing variables. Determining whether an equivalence applies to a QLF or an RLF is done by higher-order unification (henceforth, HOU) (Huet 1975; Miller and Nadathur 4986; Pulman 1991; Dalrymple, Shieber, and Pereira 1991; Gawron 1992) of the logical form with the relevant pattern. Many of the contextual conditions require a higher-order equation to be solved. 7. The interpretation of a QLF is given via the RLFs it can be equivalent to with respect to given contexts. Given a fixed, fully-specified context, a QLF will generally be equivalent to a single RLF (unless the equivalences allow for several synonymous interpretations). In cases where the context does not resolve an ambiguity, the QLF will correspond to different RLFs depending on which assumptions are added to the context. Likewise, given a partially s</context>
<context position="33767" citStr="Pereira 1991" startWordPosition="5005" endWordPosition="5006">can be realized as an NP with a tensed relative clause, so another paraphrase of the resolved logical form will be: (13) The computer that Smith bought disappeared. In fact, similar effects can be obtained for pronouns if some small tweaks to the relevant conditions are made: this turns out to be more than a neat trick, and is very useful in providing informative feedback on what resolutions have been chosen, when developing the system, or in the context of an application. 3.3 Ellipsis Not surprisingly, we can adapt a version of the HOU approach to ellipsis resolution (Dalrymple, Shieber, and Pereira 1991; Pulman 1991; Gawron 1992, 1995) very easily within this framework. On the DSP approach to VP ellipsis, an elliptical sentence like: (14) John likes fish and Mary does too. will be analyzed as follows. Firstly (ignoring tense, too, etc.) we represent the meaning of the elliptical conjunct with a free variable applied to the subject: Ellipsis(mary) Secondly we locate an element in the antecedent like(john,fish) that is parallel to mars&apos;, namely john. Next we construct a HOU equation: Ellipsis(john) = like(john,fish) the relevant solution to which instantiates the Ellipsis variable to Ax.like(x</context>
<context position="35759" citStr="Pereira (1991)" startWordPosition="5277" endWordPosition="5278">uivalence uses HOU to simultaneously suggest candidates for parallel elements and the value of the Predicate that corresponds to the Ellipsis variable in the description of DSP above. Some sortal conditions within both the equivalence and the predicate parallel are necessary to make sure that the variables PolarityTenseEtc are appropriately instantiated, since there are many possibilities consistent with their type requirements. But no extralogical mechanisms are needed, apart from the definition of &amp;quot;parallel,&amp;quot; which is intended to correspond to the notion discussed in Dalrymple, Shieber, and Pereira (1991), Priist (1992), Hobbs and Kehler (1997), and Gardent and Kohlhase (1997), among others. Parallelism may involve syntactic, semantic, pragmatic, and discourse components, depending on the construction involved. VP deletion, for example, requires the parallel element to be the subject of the preceding conjunct as well as being in the same domain of quantification as the remnant; whereas phrasal ellipsis like and John merely requires the antecedent to be in the same domain of quantification. Now given a sequence like: (15) Smith liked Sandy. Jones didn&apos;t. where the antecedent logical form and th</context>
<context position="49557" citStr="Pereira (1991)" startWordPosition="7263" endWordPosition="7264">other version of the quantifier equivalences to allow for application inside the restriction of the body of an already scoped quantifier: Every2 Rest„(Ax. Pred„e„(x,every( Nom))) Rest(,„)„(Ax.forall(Nom,Ay.PrecLe„(x,y))) if salientContext(quant,Context), scopetsLicensed.. 513 Computational Linguistics Volume 26, Number 4 We could avoid this inelegance by using polymorphism in the equivalences, or some &amp;quot;syntactic sugar&amp;quot; in the logical forms to produce a more uniform representation. As will be seen below, we need in any case something like the pair quantifier notation of Dalrymple, Shieber, and Pereira (1991), which would also solve this problem. With this addition we are able to produce both scopings for examples like: (20) Every manager in some company disappeared. This is a rather oversimplified treatment of quantifier scope, which we will refine a little shortly, but even as it stands the treatment has several advantages: • in classic examples like: (21) Every representative in a company saw most samples. only the available five relative scopings of the quantifiers are produced (Hobbs and Shieber 1987, 47), but without the need for a free variable constraint—the HOU algorithm will not produce </context>
<context position="54619" citStr="Pereira 1991" startWordPosition="8014" endWordPosition="8015">esented in a simplified form akin to that in DSP for ease of comparison, for (22a) is: when(greet(johnrevery(person)), VPELL(bill)) If we use the first, unscoped, conjunct as context for the ellipsis, then we get the right result: VPELL(john) greet(john,every(person)), VPELL= Ay.greet(y,every(person)) when(greet(john,every(person))),greet(bill,every(person))) After scoping the two conjuncts we will get the reading on which the greetings are independent. If we had scoped the QLF first we would get: fora II(p erson Ax when (greet( jo h n ,x),VPELL(bill))) 7 Pereira acknowledges this elsewhere: (Pereira 1991, footnote 3): &amp;quot;The direct replacement of ellipsis equation solutions into derivations and subsequent normalisation of the result involve some abuse of the formalism...&amp;quot; 515 Computational Linguistics Volume 26, Number 4 The equation we need is VPELL(john) = greet(john,x), which also requires us to treat the x as a constant. However, it is plausible to assume that for sentence-internal ellipsis, we will need a different control regime for application of equivalences. So far we have been assuming that each equivalence applies to an entire QLF, but for cases where some earlier portion of the sent</context>
</contexts>
<marker>Pereira, 1991</marker>
<rawString>Pereira, Fernando C. N. 1991. Deductive interpretation. In E. Klein and F. Veltman, editors, Natural Language and Speech. Springer Verlag, pages 116-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Pinkal</author>
</authors>
<title>Radical underspecification.</title>
<date>1995</date>
<booktitle>In Proceedings of the lath Amsterdam Colloquium on Formal Semantics,</booktitle>
<pages>587--606</pages>
<marker>Pinkal, 1995</marker>
<rawString>Pinkal, Manfred. 1995. Radical underspecification. In Proceedings of the lath Amsterdam Colloquium on Formal Semantics, pages 587-606.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
</authors>
<title>Semantic ambiguity and perceived ambiguity.</title>
<date>1996</date>
<booktitle>Semantic Ambiguity and Underspecification. CSLI,</booktitle>
<pages>159--202</pages>
<editor>In S. Peters and K. van Deemter, editors,</editor>
<marker>Poesio, 1996</marker>
<rawString>Poesio, Massimo, 1996. Semantic ambiguity and perceived ambiguity. In S. Peters and K. van Deemter, editors, Semantic Ambiguity and Underspecification. CSLI, pages 159-202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Prehofer</author>
</authors>
<title>Decidable higher-order unification problems.</title>
<date>1994</date>
<booktitle>In Automated Deduction CADE-12, 12th International Conference on Automated Deduction.</booktitle>
<pages>635--649</pages>
<publisher>Springer,</publisher>
<contexts>
<context position="107645" citStr="Prehofer (1994)" startWordPosition="16484" endWordPosition="16485">larger QLFs are encountered. There are several avenues worth exploring to solve this problem. While the equivalences are stated in a direction-neutral mariner, there is scope in an implementation for compiling them in different ways for the analysis and synthesis directions (recall that the equivalences decompose to a conjunction of higher-order Horn clauses). Once you know which direction you are going in, most of the unifications actually reduce to matchings (since one side of the equation is fully instantiated), which may allow for various optimizations to the unification algorithm itself. Prehofer (1994) describes some tractable subcases of higher-order unification. Another strategy is to change the control regime by which the equivalences apply. The regime assumed here, and that implemented, is entirely nondeterministic. Equiv534 Putman Bidirectional Contextual Resolution alences apply to whole QLFs, in any order, whenever they can. This means that many equivalences are tried which are later filtered out because their associated conditions cannot be met. This is both expensive and an unrealistic model of language processing. The other strategy is to make the resolution process incremental, r</context>
</contexts>
<marker>Prehofer, 1994</marker>
<rawString>Prehofer, Christian. 1994. Decidable higher-order unification problems. In Automated Deduction CADE-12, 12th International Conference on Automated Deduction. Springer, pages 635-649.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hub Prtist</author>
</authors>
<date>1992</date>
<booktitle>On Discourse Structure, VP Anaphora, and Gapping. Ph.D. thesis,</booktitle>
<institution>University of Amsterdam.</institution>
<marker>Prtist, 1992</marker>
<rawString>Prtist, Hub. 1992. On Discourse Structure, VP Anaphora, and Gapping. Ph.D. thesis, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen G Pulman</author>
</authors>
<title>Grarrunars, parsers and memory limitations.</title>
<date>1986</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>1--3</pages>
<marker>Pulman, 1986</marker>
<rawString>Pulman, Stephen G. 1986. Grarrunars, parsers and memory limitations. Language and Cognitive Processes, 1(3):197-225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pulman„ Stephen G</author>
</authors>
<title>Comparatives and ellipsis.</title>
<date>1991</date>
<booktitle>In Proceedings of the 5th European Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1--6</pages>
<publisher>ACL.</publisher>
<location>Berlin:</location>
<marker>G, 1991</marker>
<rawString>Pulman„ Stephen G. 1991. Comparatives and ellipsis. In Proceedings of the 5th European Meeting of the Association for Computational Linguistics, pages 1-6. Berlin: ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen G Pulman</author>
</authors>
<title>A computational theory of context dependence.</title>
<date>1994</date>
<booktitle>Proceedings: International Workshop on Computational Semantics,</booktitle>
<pages>161--170</pages>
<editor>In H. Bunt, R. Muskens, and G. Rentier, editors,</editor>
<institution>Institute for Language Technology, Tilburg University The Netherlands.</institution>
<contexts>
<context position="4556" citStr="Pulman (1994)" startWordPosition="679" endWordPosition="680">efinites, ellipsis, focus, and quantifier scope. There is far more to say about each of these phenomena, of course, and the analyses here are by no means claimed to be definitive. The aim is merely to show that we can, to a first approximation, provide a reasonably fully worked out description of these phenomena in a truly bidirectional way. We then go on to compare the current approach with that of some other theories with similar aims: the &amp;quot;standard&amp;quot; version of quasi-logical form implemented in the Core Language Engine, as rationally reconstructed by Alshawi and Crouch (1992) and Crouch and Pulman (1994); underspecified Discourse Representation Theory (Reyle 1993); and the &amp;quot;glue language&amp;quot; approach of Dalrymple et al. (1996). Finally, we discuss some of the semantic and logical issues raised by the approach described here, in particular the extent to which the theory meets the desiderata for accounts of underspecification outlined by van Eijck and Jaspars (1996), and the extent to which the theory supplies a methodologically satisfactory account of truth and interpretation for sentences involving contextually dependent constructs. 2. Contextual Interpretation The major components and assumptio</context>
</contexts>
<marker>Pulman, 1994</marker>
<rawString>Pulman, Stephen G. 1994. A computational theory of context dependence. In H. Bunt, R. Muskens, and G. Rentier, editors, Proceedings: International Workshop on Computational Semantics, pages 161-170. Institute for Language Technology, Tilburg University The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen G Pullman</author>
</authors>
<title>Unification encodings of grammatical notations.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--3</pages>
<marker>Pullman, 1996</marker>
<rawString>Pullman, Stephen G. 1996. Unification encodings of grammatical notations. Computational Linguistics, 22(3):295-328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen G Pulman</author>
</authors>
<title>Aspectual shift as type coercion.</title>
<date>1997</date>
<journal>Transactions of the Philological Society,</journal>
<pages>95--2</pages>
<contexts>
<context position="62748" citStr="Pulman, 1997" startWordPosition="9262" endWordPosition="9263">he))) RLF:pos(pres(like(e6,sandy,jones))) Resolved as: sandy likes jones. &gt; Input: Smith doesn&apos;t. QLF:neg(pres(vpell(e7,smith))) RLF:neg(pres(like(e7,smith,jones))) Resolved as: smith doesn&apos;t like jones. This is an example of simple VP ellipsis. Alternative contextualized paraphrases are: smith doesn&apos;t. smith doesn&apos;t like him. Now we have set up a context in which contrastive focus is appropriate: &gt; Input: HE likes Roberts. QLF:focus(he,pos(pres(1ike(e8,he,roherts)))) RLF:focus(smith,pos(pres(like(e8,smith,roberts)))) Resolved as: SMITH likes roberts. This example shows a QLF construct (from (Pulman, 1997b)) not discussed earlier, and for which no equivalence has been written yet. Thus the input is only partly resolved and focus is retained in the paraphrase. &gt; Input: SANDY does too. QLF:pos(pres(too(sandy,vpell(e9,sandy)))) RLF:pos(pres(like(e9,sandy,roberts))) Resolved as: sandy likes roberts. 518 Putman Bidirectional Contextual Resolution A combination of VP ellipsis and too-focus as described earlier. Contextualized alternatives are: SANDY likes him too. SANDY likes roberts too. sandy does. sandy likes him. This reveals a bug somewhere, as we do not get out the sentence we put in, which sh</context>
</contexts>
<marker>Pulman, 1997</marker>
<rawString>Pulman, Stephen G. 1997a. Aspectual shift as type coercion. Transactions of the Philological Society, 95(2)279-317.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen G Putman</author>
</authors>
<title>Higher order unification and the interpretation of focus.</title>
<date>1997</date>
<journal>Linguistics and Philosophy,</journal>
<pages>20--73</pages>
<marker>Putman, 1997</marker>
<rawString>Putman, Stephen G. 1997b. Higher order unification and the interpretation of focus. Linguistics and Philosophy, 20:73-115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen G Putman</author>
</authors>
<title>Statistical and logical reasoning in disambiguation.</title>
<date>2000</date>
<journal>Philosophical Transactions of the Royal Society, Series A,</journal>
<pages>358--1</pages>
<marker>Putman, 2000</marker>
<rawString>Putman, Stephen G. 2000. Statistical and logical reasoning in disambiguation. Philosophical Transactions of the Royal Society, Series A, 358(1,769):1,267-1,280.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manny Rayner</author>
</authors>
<title>Abductive Equivalential Translation and its application to Natural Language Database Inferencing.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<institution>Stockholm University.</institution>
<note>Also available at http://www.cam.sri.com/tr.</note>
<contexts>
<context position="9213" citStr="Rayner 1993" startWordPosition="1389" endWordPosition="1390">ent, hence context must contain this information too. We obviously need some nonlinguistic information. We also need some structure to reflect the fact that not all components of the context are relevant to everything, hence salience. This is all we need for the time being, although there is clearly much more to be said. 1 This is probably too strong a position to take. There are good arguments for allowing some syntactic distinctions to be represented more directly. 499 Computational Linguistics Volume 26, Number 4 4. QLFs are interpreted by conditional equivalences (Rayner and Alshawi 1992; Rayner 1993) of the form: QLF &lt;=&gt; RLF if Conditioni, , Condition„. These state a contextual equivalence between an expression containing one or more QLF constructs (the left-hand side) and an expression containing at least one fewer QLF constructs (the right-hand side). QLF and RLF are therefore sometimes used to signify partially as well as fully (un)resolved LFs. An equivalence can be paraphrased as: &amp;quot;In a context where these conditions hold, this QLF can be interpreted as this RLF,&amp;quot; or &amp;quot;In a context where these conditions hold, this RLF can be expressed as this QLF.&amp;quot; Conditional equivalences, if 4=;. i</context>
</contexts>
<marker>Rayner, 1993</marker>
<rawString>Rayner, Manny. 1993. Abductive Equivalential Translation and its application to Natural Language Database Inferencing. Ph.D. thesis, Stockholm University. Also available at http://www.cam.sri.com/tr.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manny Rayner</author>
<author>Hiyart Alshawi</author>
</authors>
<title>Deriving database queries from logical forms by abductive definition expansion.</title>
<date>1992</date>
<booktitle>In Proceedings of the 3rd International Conference on Applied Natural Language Processing,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Trento, Italy.</location>
<contexts>
<context position="9199" citStr="Rayner and Alshawi 1992" startWordPosition="1385" endWordPosition="1388">ces as well as their content, hence context must contain this information too. We obviously need some nonlinguistic information. We also need some structure to reflect the fact that not all components of the context are relevant to everything, hence salience. This is all we need for the time being, although there is clearly much more to be said. 1 This is probably too strong a position to take. There are good arguments for allowing some syntactic distinctions to be represented more directly. 499 Computational Linguistics Volume 26, Number 4 4. QLFs are interpreted by conditional equivalences (Rayner and Alshawi 1992; Rayner 1993) of the form: QLF &lt;=&gt; RLF if Conditioni, , Condition„. These state a contextual equivalence between an expression containing one or more QLF constructs (the left-hand side) and an expression containing at least one fewer QLF constructs (the right-hand side). QLF and RLF are therefore sometimes used to signify partially as well as fully (un)resolved LFs. An equivalence can be paraphrased as: &amp;quot;In a context where these conditions hold, this QLF can be interpreted as this RLF,&amp;quot; or &amp;quot;In a context where these conditions hold, this RLF can be expressed as this QLF.&amp;quot; Conditional equivalen</context>
</contexts>
<marker>Rayner, Alshawi, 1992</marker>
<rawString>Rayner, Manny and Hiyart Alshawi. 1992. Deriving database queries from logical forms by abductive definition expansion. In Proceedings of the 3rd International Conference on Applied Natural Language Processing, pages 1-8, Trento, Italy. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Uwe Reyle</author>
</authors>
<title>Dealing with ambiguities by underspecification.</title>
<date>1993</date>
<journal>Journal of Semantics,</journal>
<pages>10--123</pages>
<contexts>
<context position="4617" citStr="Reyle 1993" startWordPosition="685" endWordPosition="686">ore to say about each of these phenomena, of course, and the analyses here are by no means claimed to be definitive. The aim is merely to show that we can, to a first approximation, provide a reasonably fully worked out description of these phenomena in a truly bidirectional way. We then go on to compare the current approach with that of some other theories with similar aims: the &amp;quot;standard&amp;quot; version of quasi-logical form implemented in the Core Language Engine, as rationally reconstructed by Alshawi and Crouch (1992) and Crouch and Pulman (1994); underspecified Discourse Representation Theory (Reyle 1993); and the &amp;quot;glue language&amp;quot; approach of Dalrymple et al. (1996). Finally, we discuss some of the semantic and logical issues raised by the approach described here, in particular the extent to which the theory meets the desiderata for accounts of underspecification outlined by van Eijck and Jaspars (1996), and the extent to which the theory supplies a methodologically satisfactory account of truth and interpretation for sentences involving contextually dependent constructs. 2. Contextual Interpretation The major components and assumptions of the approach to contextual interpretation here are as f</context>
<context position="26805" citStr="Reyle 1993" startWordPosition="3990" endWordPosition="3991">em will not arise.) The quantifier exists,„,„„,„ is here the translation of the indefinite article, although as is well known this is not the only alternative. We could encode DRT-like analyses directly via an equivalence creating a new discourse referent for an indefinite. On such an analysis, the earlier pronoun equivalence would apply to this discourse referent just as for a proper name, provided the appropriate number and gender information was available. By extending the definition of possibleAntecedent, we can combine with Webber&apos;s approach aspects of the DRT theory of plurals (Kamp and Reyle 1993) to account for examples like: (8) Every manager liked Smith. They admired him. 505 Computational Linguistics Volume 26, Number 4 possibleAntecedent(Context,they,DE) if Context = Pred(forall(Restriction,Body)), isOfType(they,sigma(Ax.Restriction(x) &amp; Body(x))), ciefine(DE,sigma(Ax Restriction(x) &amp; Body(x))). The antecedent sentence will be resolved to: forall(manager,Ax.existsl()e.pos(past(like(e,x,smith))))) Here they will be interpreted as i2, equivalent to: sigma()x.manager(x) &amp; existsl(Ae.pos(past(like(e,x,smith))))) where sigm„„ is an operator meaning &apos;the maximal set of things satisfying</context>
<context position="80320" citStr="Reyle (1993" startWordPosition="11899" endWordPosition="11900">sitive to context: the conditional equivalences require the context to be an appropriate one for the scoping derived. The form of the implication in the interpretation direction is `QLF &amp; Context I- RLF&apos;.•By contrast, if I have understood correctly, the glue language deductions as presented require only the linguistic forms to be present: thus all interpretations of an ambiguous form will be derivable, whatever the context. Some further specification of how context acts to eliminate impossible readings is required.&apos; 5.3 Underspecified Discourse Representation Structures In a series of papers, Reyle (1993, 1995, 1996) has elaborated a version of DRT that is able to represent quantifier scope and other ambiguities in a single underspecified representation. (In other respects like pronoun or definite description interpretation, standard DRT is already an underspecification-based theory.) LIDRT differs from standard DRT in that the familiar &amp;quot;boxes&amp;quot; are partly replaced by a set of labels for the conditions in the boxes and the relations between them, and partial relations of inclusion between (the components indexed by) these labels. When sentences are fully scoped, the representations are like st</context>
<context position="84325" citStr="Reyle 1993" startWordPosition="12536" endWordPosition="12537">language approach, UDRS does not have the problem of how to represent the meaning of quantified NPs as things of different type at different levels. However, it achieves this at the cost of not representing the meanings of quantified NPs as independent units at all: determiner and restriction are separate components that have no close connection to each other until the inclusion constraints are imposed. It remains to be seen whether this unconstrained approach to semantic assembly can be implemented on a large scale, given that it is prima facie not very compositional. Early versions of UDRS (Reyle 1993) treated ambiguity as disjunction, which as we shall see, is not correct. The more recent version (Reyle 1996) remedies this. UDRS also makes a serious attempt at developing a calculus for reasoning directly with underspecified DRSs, a necessary move: the whole point of working on underspecification is to be able to work with underspecified representations directly, rather than relying on their fully specified resolutions. This is a deficit in our own account (and the glue language account) that we shall begin to remedy below. While there are many points of contact between the two approaches, </context>
</contexts>
<marker>Reyle, 1993</marker>
<rawString>Reyle, Uwe. 1993. Dealing with ambiguities by underspecification. Journal of Semantics, 10:123-179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Uwe Reyle</author>
</authors>
<title>On reasoning with ambiguities.</title>
<date>1995</date>
<booktitle>In Proceedings of EACL 95,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="100610" citStr="Reyle 1995" startWordPosition="15376" endWordPosition="15377">find complete grammatical analyses for every sentence, let alone full contextual interpretations, information extraction proceeds by reasoning from partial or underspecified representations that are in most logical respects the same kind of animal as the unresolved QLFs we have been talking about. Information extraction systems typically carry out such reasoning in a way that is, in Jerry Hobbs&apos; phrase, unhindered by theory. Developing a calculus for reasoning with QLFs is too large a task to be undertaken here. But the general outlines are reasonably clear, and we can adapt some of the UDRS (Reyle 1995) work to our own framework. Reyle points out that many of the inferences involving underspecified representations that we would like to capture rely on the assumption that whatever context disambiguates the premise also disambiguates the conclusion, even if we do not know what that context or disambiguation is. His example is: If the students get £10 then they buy books. The students get .£10. They buy books. Our treatment of the interpretation of QLFs makes it a tautology that if one resolved form implies another, then the corresponding QLFs also do, given a fixed context. The other common pa</context>
</contexts>
<marker>Reyle, 1995</marker>
<rawString>Reyle, Uwe, 1995. On reasoning with ambiguities. In Proceedings of EACL 95, pages 1-8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Uwe Reyle</author>
</authors>
<title>Co-indexing labelled DRSS to represent and reason with ambiguities.</title>
<date>1996</date>
<booktitle>Semantic Ambiguity and Underspecification,</booktitle>
<pages>239--268</pages>
<editor>In S. Peters and K. van Deemter, editors,</editor>
<publisher>CSLI,</publisher>
<contexts>
<context position="6976" citStr="Reyle 1996" startWordPosition="1038" endWordPosition="1039">me grammatical description is used in both the analysis and generation direction. What is required is that QLFs are, as here, expressed in a typed higher-order logic, augmented with constructs representing the interpretation of context-dependent elements (pronouns, ellipsis, focus, etc.). These constructs correspond as directly as possible to properties of the linguistic structure that express them and are, to as small an extent as possible, dependent on the requirements of contextual resolution (unlike, say, the metavariables of standard QLFs [Alshawi and Crouch 1992], or the labels of UDRS [Reyle 1996], which are motivated entirely by the mechanisms that operate on them after grammatical processing). Syntactic properties relevant for binding constraints, parallelism, scope constraints, and so on, are not directly represented at QLF (again unlike standard QLFs) but are assumed to be available as components of the linguistic context.&apos; The context-independent meanings of sentences, which we refer to as resolved logical forms (RLFs), are expressed in the &amp;quot;ordinary&amp;quot; subset of the QLF language. A fully resolved RLF can be directly evaluated for truth: it contains no QLF constructs. Since it is j</context>
<context position="82983" citStr="Reyle 1996" startWordPosition="12324" endWordPosition="12325">5: computer(y) 12: 13:manager(x) 14- 16:owns(x,y) ( 11 Resolution of scoping consists of adding further inclusion constraints. Other than those which are the result of general principles (e.g., binding constraints), it is not part of the theory to say where these constraints come from. Just as for pronoun resolution, (LT)DRT provides a representation that allows for the monotonic addition of information to do the resolution, but has nothing to say about the mechanisms that do this. Reyle sketches various methodological requirements that should be met by a theory of meaning underspecification (Reyle 1996, 241ff.). Firstly, it should be possible to represent partial orders of scoping relations. Secondly, it should be able in effect to emulate the DRT treatment of donkey sentences (p. 243) (a somewhat parochial requirement, given that the case is not yet closed on whether this treatment is correct: see Elworthy [19951, among others). Thirdly, the theory should not need anything like the free variable constraint. 526 Pulman Bidirectional Contextual Resolution Clearly, UDRS meets these requirements, as does our own QLF-based approach. There are some similarities between the UDRS and the glue lang</context>
<context position="84435" citStr="Reyle 1996" startWordPosition="12554" endWordPosition="12555">of different type at different levels. However, it achieves this at the cost of not representing the meanings of quantified NPs as independent units at all: determiner and restriction are separate components that have no close connection to each other until the inclusion constraints are imposed. It remains to be seen whether this unconstrained approach to semantic assembly can be implemented on a large scale, given that it is prima facie not very compositional. Early versions of UDRS (Reyle 1993) treated ambiguity as disjunction, which as we shall see, is not correct. The more recent version (Reyle 1996) remedies this. UDRS also makes a serious attempt at developing a calculus for reasoning directly with underspecified DRSs, a necessary move: the whole point of working on underspecification is to be able to work with underspecified representations directly, rather than relying on their fully specified resolutions. This is a deficit in our own account (and the glue language account) that we shall begin to remedy below. While there are many points of contact between the two approaches, there are at least two dimensions along which I would maintain the QLF approach to be preferable: 1. it is rev</context>
</contexts>
<marker>Reyle, 1996</marker>
<rawString>Reyle, Uwe. 1996. Co-indexing labelled DRSS to represent and reason with ambiguities. In S. Peters and K. van Deemter, editors, Semantic Ambiguity and Underspecification, pages 239-268. CSLI,</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Thomas</author>
<author>Stephen G Pulman</author>
</authors>
<title>Bidirectional interpretation of tense and aspect.</title>
<date>1999</date>
<booktitle>Proceedings of the Third International Workshop on Computational Semantics,</booktitle>
<pages>247--263</pages>
<editor>In H. Bunt et al., editors,</editor>
<marker>Thomas, Pulman, 1999</marker>
<rawString>Thomas, James and Stephen G. Pulman. 1999. Bidirectional interpretation of tense and aspect. In H. Bunt et al., editors, Proceedings of the Third International Workshop on Computational Semantics, pages 247-263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kees van Deemter</author>
</authors>
<title>Towards a logic of ambiguous expressions.</title>
<date>1996</date>
<booktitle>Semantic Ambiguity and Underspecification. CSLI,</booktitle>
<pages>203--238</pages>
<editor>In S. Peters and K. van Deemter, editors,</editor>
<marker>van Deemter, 1996</marker>
<rawString>van Deemter, Kees. 1996. Towards a logic of ambiguous expressions. In S. Peters and K. van Deemter, editors, Semantic Ambiguity and Underspecification. CSLI, pages 203-238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan van Eijck</author>
<author>Jan Jaspars</author>
</authors>
<title>Ambiguity and reasoning.</title>
<date>1996</date>
<tech>CWI Technical Report CS-R9616.</tech>
<marker>van Eijck, Jaspars, 1996</marker>
<rawString>van Eijck, Jan and Jan Jaspars. 1996. Ambiguity and reasoning. CWI Technical Report CS-R9616.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie L Webber</author>
</authors>
<title>So what can we talk about now?</title>
<date>1983</date>
<booktitle>Computational Models of Discourse.</booktitle>
<pages>331--371</pages>
<editor>In M. Brady and R. Berwick, editors,</editor>
<publisher>MIT Press,</publisher>
<contexts>
<context position="22967" citStr="Webber 1983" startWordPosition="3430" endWordPosition="3431">,Ax.existsl(Ae.pos(pres(like,e,x,of(x,computer))))) Note that here we have assumed that the quantifier has already been scoped. We return later to issues of the interaction of scoping with ellipsis and anaphora. In the meantime, we simply point out that bound variable uses of pronouns need no extra mechanisms than those required for simple intrasentential pronouns.&apos; It is easy to extend to far more complex cases of intersentential anaphora by extending the definition of possibleAntecedent to allow for reference to different types of antecedent. For example, if we adopt a theory like Webber&apos;s (Webber 1983), we can construct discourse referents from the representation of quantified NP meanings. Recall that in Webber&apos;s approach, a logical form representing the meaning of a sentence processed in a discourse will trigger the application of rewrite rules, which will add new entities to the context. For example, given a logical form that in our notation would be: exists(cat,AX saw(I,X))) a discourse entity like: iota(AX.cat(X) &amp; savv(I,X) &amp; evoke(s1,X)) will be produced, where iota is a term-forming operator interpreted roughly like a definite description. (The evoke predicate serves as a unique iden</context>
</contexts>
<marker>Webber, 1983</marker>
<rawString>Webber, Bonnie L. 1983. So what can we talk about now? In M. Brady and R. Berwick, editors, Computational Models of Discourse. MIT Press, pages 331-371.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Woods</author>
</authors>
<title>Procedural semantics for a question-answering machine.</title>
<date>1968</date>
<booktitle>In Proceedings of the Fall Joint Computer Conference,</booktitle>
<pages>457--471</pages>
<location>New York,</location>
<contexts>
<context position="97922" citStr="Woods (1968" startWordPosition="14942" endWordPosition="14943">his property (Jaspars 1997). But a version of (9) follows directly from T, with the additional conclusion that C2 must also hold. 6.3 Reasoning with QLFs Why would we want to be sure that we have a coherent semantics for QLFs and a sensible consequence relation? There are several reasons for doing so. Firstly, there are overwhelming arguments that some level like QLF is essential as part of a theory of utterance interpretation, both for linguistic and computational reasons. The practical arguments for this position are well known and have been implicit in computational practice since at least Woods (1968, 1978). It is simply not feasible to interleave the processes of quantifier scope or reference and ellipsis resolution, for example, with the otherwise compositional process of meaning assembly. The space of possible interpre531 Computational Linguistics Volume 26, Number 4 tations becomes unmanageably large. However, postulating such a level of representation incurs an obligation to say what it means: logical and computational hygiene require us to supply a semantic account of it. Secondly, since the processes of contextual interpretation involve a certain amount of inference to be successfu</context>
</contexts>
<marker>Woods, 1968</marker>
<rawString>Woods, William. 1968. Procedural semantics for a question-answering machine. In Proceedings of the Fall Joint Computer Conference, New York, pages 457-471, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Woods</author>
</authors>
<title>Semantics and quantification in natural language question answering.</title>
<date>1978</date>
<booktitle>In Yovits, editor, Advances in Computers.</booktitle>
<pages>2--64</pages>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<marker>Woods, 1978</marker>
<rawString>Woods, William. 1978. Semantics and quantification in natural language question answering. In Yovits, editor, Advances in Computers. Academic Press, New York, pages 2-64.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>