<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001171">
<title confidence="0.647603">
Comparison between CFG filtering techniques for LTAG and HPSG
</title>
<affiliation confidence="0.657762">
Naoki Yoshinaga†† University of Tokyo
</affiliation>
<address confidence="0.9647615">
7-3-1 Hongo, Bunkyo-ku,
Tokyo, 113-0033, Japan
</address>
<email confidence="0.999372">
yoshinag@is.s.u-tokyo.ac.jp
</email>
<author confidence="0.972499">
Kentaro Torisawa$
</author>
<affiliation confidence="0.9712385">
$ Japan Advanced Institute
of Science and Technology
</affiliation>
<address confidence="0.983267">
1-1 Asahidai, Tatsunokuchi,
Ishikawa, 923-1292, Japan
</address>
<email confidence="0.999276">
torisawa@jaist.ac.jp
</email>
<note confidence="0.5021">
Jun’ichi Tsujii†*
* CREST, JST (Japan Science
and Technology Corporation)
</note>
<address confidence="0.81917">
Hon-cho 4-1-8, Kawaguchi-shi,
Saitama, 332-0012, Japan
</address>
<email confidence="0.999029">
tsujii@is.s.u-tokyo.ac.jp
</email>
<sectionHeader confidence="0.995644" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999891166666667">
An empirical comparison of CFG filtering
techniques for LTAG and HPSG is pre-
sented. We demonstrate that an approx-
imation of HPSG produces a more effec-
tive CFG filter than that of LTAG. We also
investigate the reason for that difference.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999953130434783">
Various parsing techniques have been developed
for lexicalized grammars such as Lexicalized
Tree Adjoining Grammar (LTAG) (Schabes et al.,
1988), and Head-Driven Phrase Structure Gram-
mar (HPSG) (Pollard and Sag, 1994). Along with
the independent development of parsing techniques
for individual grammar formalisms, some of them
have been adapted to other formalisms (Schabes et
al., 1988; van Noord, 1994; Yoshida et al., 1999;
Torisawa et al., 2000). However, these realiza-
tions sometimes exhibit quite different performance
in each grammar formalism (Yoshida et al., 1999;
Yoshinaga et al., 2001). If we could identify an al-
gorithmic difference that causes performance differ-
ence, it would reveal advantages and disadvantages
of the different realizations. This should also allow
us to integrate the advantages of the realizations into
one generic parsing technique, which yields the fur-
ther advancement of the whole parsing community.
In this paper, we compare CFG filtering tech-
niques for LTAG (Harbusch, 1990; Poller and
Becker, 1998) and HPSG (Torisawa et al., 2000;
Kiefer and Krieger, 2000), following an approach to
parsing comparison among different grammar for-
malisms (Yoshinaga et al., 2001). The key idea
of the approach is to use strongly equivalent gram-
mars, which generate equivalent parse results for the
same input, obtained by a grammar conversion as
demonstrated by Yoshinaga and Miyao (2001). The
parsers with CFG filtering predict possible parse
trees by a CFG approximated from a given grammar.
Comparison of those parsers are interesting because
effective CFG filters allow us to bring the empirical
time complexity of the parsers close to that of CFG
parsing. Investigating the difference between the
ways of context-free (CF) approximation of LTAG
and HPSG will thereby enlighten a way of further
optimization for both techniques.
We performed a comparison between the exist-
ing CFG filtering techniques for LTAG (Poller and
Becker, 1998) and HPSG (Torisawa et al., 2000),
using strongly equivalent grammars obtained by
converting LTAGs extracted from the Penn Tree-
bank (Marcus et al., 1993) into HPSG-style. We
compared the parsers with respect to the size of the
approximated CFG and its effectiveness as a filter.
</bodyText>
<sectionHeader confidence="0.982023" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.99927325">
In this section, we introduce a grammar conver-
sion (Yoshinaga and Miyao, 2001) and CFG filter-
ing (Harbusch, 1990; Poller and Becker, 1998; Tori-
sawa et al., 2000; Kiefer and Krieger, 2000).
</bodyText>
<subsectionHeader confidence="0.959449">
2.1 Grammar conversion
</subsectionHeader>
<bodyText confidence="0.998360333333333">
The grammar conversion consists of a conversion
of LTAG elementary trees to HPSG lexical entries
and an emulation of substitution and adjunction by
</bodyText>
<figureCaption confidence="0.999825">
Figure 1: Extraction of CFG from LTAG
</figureCaption>
<bodyText confidence="0.999542">
pre-determined grammar rules. An LTAG elemen-
tary tree is first converted into canonical elementary
trees which have only one anchor and whose sub-
trees of depth n (≥1) contain at least one anchor. A
canonical elementary tree is then converted into an
HPSG lexical entry by regarding the leaf nodes as
arguments and by storing them in a stack.
We can perform a comparison between LTAG and
HPSG parsers using strongly equivalent grammars
obtained by the above conversion. This is because
strongly equivalent grammars can be a substitute for
the same grammar in different grammar formalisms.
</bodyText>
<subsectionHeader confidence="0.997416">
2.2 CFG filtering techniques
</subsectionHeader>
<bodyText confidence="0.99997965">
An initial offline step of CFG filtering is performed
to approximate a given grammar with a CFG. The
obtained CFG is used as an efficient device to com-
pute the necessary conditions for parse trees.
The CFG filtering generally consists of two steps.
In phase 1, the parser first predicts possible parse
trees using the approximated CFG, and then filters
out irrelevant edges by a top-down traversal starting
from roots of successful context-free derivations. In
phase 2, it then eliminates invalid parse trees by us-
ing constraints in the given grammar. We call the
remaining edges that are used for the phase 2 pars-
ing essential edges.
The parsers with CFG filtering used in our ex-
periments follow the above parsing strategy, but are
different in the way the CF approximation and the
elimination of impossible parse trees in phase 2 are
performed. In the following sections, we briefly de-
scribe the CF approximation and the elimination of
impossible parse trees in each realization.
</bodyText>
<subsubsectionHeader confidence="0.659549">
2.2.1 CF approximation of LTAG
</subsubsectionHeader>
<bodyText confidence="0.999207352941176">
In CFG filtering techniques for LTAG (Harbusch,
1990; Poller and Becker, 1998), every branching of
elementary trees in a given grammar is extracted as
a CFG rule as shown in Figure 1.
Because the obtained CFG can reflect only local
constraints given in each local structure of the el-
ementary trees, it generates invalid parse trees that
connect local trees in different elementary trees. In
order to eliminate such parse trees, a link between
branchings is preserved as a node number which
records a unique node address (a subscript attached
to each node in Figure 1). We can eliminate these
parse trees by traversing essential edges in a bottom-
up manner and recursively propagating ok-flag from
a node number x to a node number y when a connec-
tion between x and y is allowed in the LTAG gram-
mar. We call this propagation ok-prop.
</bodyText>
<subsubsectionHeader confidence="0.629577">
2.2.2 CF approximation of HPSG
</subsubsectionHeader>
<bodyText confidence="0.999842761904762">
In CFG filtering techniques for HPSG (Torisawa
et al., 2000; Kiefer and Krieger, 2000), the extrac-
tion process of a CFG from a given HPSG gram-
mar starts by recursively instantiating daughters of a
grammar rule with lexical entries and generated fea-
ture structures until new feature structures are not
generated as shown in Figure 2. We must impose
restrictions on values of some features (i.e., ignor-
ing them) and/or the number of rule applications in
order to guarantee the termination of the rule appli-
cation. A CFG is obtained by regarding each initial
and generated feature structures as nonterminals and
transition relations between them as CFG rules.
Although the obtained CFG can reflect local and
global constraints given in the whole structure of
lexical entries, it generates invalid parse trees be-
cause they do not reflect upon constraints given by
the values of features that are ignored in phase 1.
These parse trees are eliminated in phase 2 by apply-
ing a grammar rule that corresponds to the applied
CFG rule. We call this rule application rule-app.
</bodyText>
<figure confidence="0.996534325">
Tree 5: Tree 9:
CFG rules
S 5.ε
S 9.ε
5.ε 5.1 5.2
9.ε 9.1 9.2
S NP VP
NP VP
5.1 5.2
NP VP
9.1
9.2
VP V NP
5.2 5.2.1 5.2.2
VP V S
9.2 9.2.1 9.2.2
V S
9.2.1 9.2.2
V NP
5.2.1 5.2.2
CFG rules
B X A
C Y B
C
phrasal
SYNSEM ...
phrasal
SYNSEM ...
sign sign
SYNSEM ... SYNSEM ...
Y
Grammar rule
phrasal
SYNSEM ...
phrasal
SYNSEM ...
sign
SYNSEM ...
B
sign sign
</figure>
<figureCaption confidence="0.96781">
Figure 2: Extraction of CFG from HPSG
</figureCaption>
<figure confidence="0.96709975">
SYNSEM ... SYNSEM ...
sign
SYNSEM ...
X
lexical
SYNSEM ...
A
Grammar rule
</figure>
<tableCaption confidence="0.833814666666667">
Table 1: The size of extracted LTAGs (tree tem-
plates) and approximated CFGs (above: the number
of nonterminals; below: the number of rules)
</tableCaption>
<table confidence="0.999957">
Grammar G2 G2-4 G2-6 G2-8 G2-10 G2-21
LTAG 1,488 2,412 3,139 3,536 3,999 6,085
CFGPB 65 66 66 66 67 67
716 954 1,090 1,158 1,229 1,552
CFGTNT 1,989 3,118 4,009 4,468 5,034 7,454
18,323 35,541 50,115 58,356 68,239 118,464
</table>
<tableCaption confidence="0.755226">
Table 2: Parsing performance (sec.) with the
strongly equivalent grammars for Section 2 of WSJ
</tableCaption>
<table confidence="0.996617333333333">
Parser G2 G2-4 G2-6 G2-8 G2-10 G2-21
PB 1.4 9.1 17.4 24.0 34.2 124.3
TNT 0.044 0.097 0.144 0.182 0.224 0.542
</table>
<sectionHeader confidence="0.913102" genericHeader="method">
3 Comparison with CFG filtering
</sectionHeader>
<bodyText confidence="0.99993328">
In this section, we compare a pair of CFG filter-
ing techniques for LTAG (Poller and Becker, 1998)
and HPSG (Torisawa et al., 2000) described in Sec-
tion 2.2.1 and 2.2.2. We hereafter refer to PB and
TNT for the C++ implementations of the former and
a valiant1 of the latter, respectively.2
We first acquired LTAGs by a method pro-
posed in Miyao et al. (2003) from Sections 2-21 of
the Wall Street Journal (WSJ) in the Penn Tree-
bank (Marcus et al., 1993) and its subsets.3 We then
converted them into strongly equivalent HPSG-style
grammars using the grammar conversion described
in Section 2.1. Table 1 shows the size of CFG ap-
proximated from the strongly equivalent grammars.
Gx, CFGPB, and CFGTNT henceforth refer to the
LTAG extracted from Section x of WSJ and CFGs
approximated from Gx by PB and TNT, respectively.
The size of CFGTNT is much larger than that of
CFGPB. By investigating parsing performance using
these CFGs, we show that the larger size of CFGTNT
resulted in better parsing performance.
Table 2 shows the parse time with 254 sentences
of length n (≤10) from Section 2 of WSJ (the av-
erage length is 6.72 words).4 This result shows not
only that TNT achieved a drastic speed-up against
</bodyText>
<footnote confidence="0.9983792">
1All daughters of rules are instantiated in the approximation.
2In phase 1, PB performs Earley (Earley, 1970) parsing
while TNT performs CKY (Younger, 1967) parsing.
3The elementary trees in the LTAGs are binarized.
4We used a subset of the training corpus to avoid the com-
</footnote>
<tableCaption confidence="0.761904">
plication of using default lexical entries for unknown words.
Table 3: The numbers of essential edges with the
</tableCaption>
<table confidence="0.90361275">
strongly equivalent grammars for Section 02 of WSJ
Parser G2 G2-4 G2-6 G2-8 G2-10 G2-21
PB 791 1,435 1,924 2,192 2,566 3,976
TNT 63 121 174 218 265 536
</table>
<tableCaption confidence="0.998172">
Table 4: The success rate (%) of phase 2 operations
</tableCaption>
<table confidence="0.998662333333333">
Operations G2 G2-4 G2-6 G2-8 G2-10 G2-21
ok-prop (PB) 38.5 34.3 33.1 32.3 31.7 31.0
rule-app (TNT) 100 100 100 100 100 100
</table>
<bodyText confidence="0.9982542">
PB, but also that performance difference between
them increases with the larger size of the grammars.
In order to estimate the degree of CF approxima-
tion, we measured the number of essential (inactive)
edges of phase 1. Table 3 shows the number of the
essential edges. The number of essential edges pro-
duced by PB is much larger than that produced by
TNT. We then investigated the effect on phase 2
as caused by the different number of the essential
edges. Table 4 shows the success rate of ok-prop
and rule-app. The success rate of rule-app is 100%,5
whereas that of ok-prop is quite low.6 These results
indicate that CFGTNT is superior to CFGPB with re-
spect to the degree of the CF approximation.
We can explain the reason for this difference by
investigating how TNT approximates HPSG-style
grammars converted from LTAGs. As described
in Section 2.1, the grammar conversion preserves
the whole structure of each elementary tree (pre-
cisely, a canonical elementary tree) in a stack, and
grammar rules manipulate a head element of the
stack. A generated feature structure in the approxi-
mation process thus corresponds to the whole unpro-
cessed portion of a canonical elementary tree. This
implies that successful context-free derivations ob-
tained by CFGTNT basically involve elementary trees
in which all substitution and adjunction have suc-
ceeded. However, CFGPB (also a CFG produced
by the other work (Harbusch, 1990)) cannot avoid
generating invalid parse trees that connect two lo-
</bodyText>
<footnote confidence="0.969056714285714">
5This means that the extracted LTAGs should be compatible
with CFG and were completely converted to CFGs by TNT.
6Similar results were obtained in preliminary experiments
using the XTAG English grammar (The XTAG Research Group,
2001) without features (parse time (sec.)/success rate (%) for
PB and TNT were 15.3/30.6 and 0.606/71.2 with the same sen-
tences), though space limitations preclude complete results.
</footnote>
<bodyText confidence="0.999911090909091">
cal structures where adjunction takes place between
them. We measured with G2-21 the proportion of the
number of ok-prop between two node numbers of
nodes that take adjunction and its success rate. It
occupied 87% of the total number of ok-prop and
its success rate was only 22%. These results sug-
gest that the global contexts in a given grammar is
essential to obtain an effective CFG filter.
It should be noted that the above investigation also
tells us another way of CF approximation of LTAG.
We first define a unique way of tree traversal such as
head-corner traversal (van Noord, 1994) on which
we can perform a sequential application of substitu-
tion and adjunction. We then recursively apply sub-
stitution and adjunction on that traversal to an ele-
mentary tree and a generated tree structure. Because
the processed portions of generated tree structures
are no longer used later, we regard the unprocessed
portions of the tree structures as nonterminals of
CFG. We can thereby construct another CFG filter-
ing for LTAG by combining this CFG filter with an
existing LTAG parsing algorithm (van Noord, 1994).
</bodyText>
<sectionHeader confidence="0.984029" genericHeader="evaluation">
4 Conclusion and future direction
</sectionHeader>
<bodyText confidence="0.999989705882353">
We presented an empirical comparison of LTAG and
HPSG parsers with CFG filtering. We compared the
parsers with strongly equivalent grammars obtained
by converting LTAGs extracted from the Penn Tree-
bank into HPSG-style. Experimental results showed
that the existing CF approximation of HPSG (Tori-
sawa et al., 2000) produced a more effective filter
than that of LTAG (Poller and Becker, 1998). By in-
vestigating the different ways of CF approximation,
we concluded that the global constraints in a given
grammar is essential to obtain an effective filter.
We are going to integrate the advantage of the CF
approximation of HPSG into that of LTAG in order
to establish another CFG filtering for LTAG. We will
also conduct experiments on trade-offs between the
degree of CF approximation and the size of approx-
imated CFGs as in Maxwell III and Kaplan (1993).
</bodyText>
<sectionHeader confidence="0.974759" genericHeader="conclusions">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.97614125">
We thank Yousuke Sakao for his help in profiling
TNT parser and anonymous reviewers for their help-
ful comments. This work was partially supported by
JSPS Research Fellowships for Young Scientists.
</bodyText>
<sectionHeader confidence="0.995873" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999974869565218">
J. Earley. 1970. An efficient context-free parsing algo-
rithm. Communications of the ACM, 6(8):451–455.
K. Harbusch. 1990. An efficient parsing algorithm for
Tree Adjoining Grammars. In Proc. of ACL, pages
284–291.
B. Kiefer and H.-U. Krieger. 2000. A Context-Free ap-
proximation of Head-Driven Phrase Structure Gram-
mar. In Proc. ofIWPT, pages 135–146.
M. Marcus, B. Santorini, and M. A. Marcinkiewicz.
1993. Building a large annotated corpus of En-
glish: the Penn Treebank. Computational Linguistics,
19(2):313–330.
J. T. Maxwell III and R. M. Kaplan. 1993. The interface
between phrasal and functional constraints. Computa-
tional Linguistics, 19(4):571–590.
Y. Miyao, T. Ninomiya, and J. Tsujii. 2003. Lexicalized
grammar acquisition. In Proc. of EACL companion
volume, pages 127–130.
C. Pollard and I. A. Sag. 1994. Head-Driven Phrase
Structure Grammar. University of Chicago Press.
P. Poller and T. Becker. 1998. Two-step TAG parsing
revisited. In Proc. of TAG+4, pages 143–146.
Y. Schabes, A. Abeill´e, and A. K. Joshi. 1988. Pars-
ing strategies with ‘lexicalized’ grammars: Applica-
tion to Tree Adjoining Grammars. In Proc. of COL-
ING, pages 578–583.
The XTAG Research Group. 2001. A Lexicalized Tree
Adjoining Grammar for English. Technical Report
IRCS-01-03, IRCS, University of Pennsylvania.
K. Torisawa, K. Nishida, Y. Miyao, and J. Tsujii. 2000.
An HPSG parser with CFG filtering. Natural Lan-
guage Engineering, 6(1):63–80.
G. van Noord. 1994. Head corner parsing for TAG.
Computational Intelligence, 10(4):525–534.
M. Yoshida, T. Ninomiya, K. Torisawa, T. Makino, and
J. Tsujii. 1999. Efficient FB-LTAG parser and its par-
allelization. In Proc. ofPACLING, pages 90–103.
N. Yoshinaga and Y. Miyao. 2001. Grammar conver-
sion from LTAG to HPSG. In Proc. ofESSLLI Student
Session, pages 309–324.
N. Yoshinaga, Y. Miyao, K. Torisawa, and J. Tsujii.
2001. Efficient LTAG parsing using HPSG parsers. In
Proc. of PACLING, pages 342–351.
D. H. Younger. 1967. Recognition and parsing of
context-free languages in time n3. Information and
Control, 2(10):189–208, February.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.739255">
<title confidence="0.927719">Comparison between CFG filtering techniques for LTAG and HPSG</title>
<affiliation confidence="0.999498">University of Tokyo</affiliation>
<address confidence="0.9981605">7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-0033, Japan</address>
<email confidence="0.979915">yoshinag@is.s.u-tokyo.ac.jp</email>
<affiliation confidence="0.980311">Japan Advanced Institute of Science and Technology</affiliation>
<address confidence="0.9944985">1-1 Asahidai, Tatsunokuchi, Ishikawa, 923-1292, Japan</address>
<email confidence="0.979816">torisawa@jaist.ac.jp</email>
<affiliation confidence="0.9626525">JST (Japan Science and Technology Corporation)</affiliation>
<address confidence="0.9815375">Hon-cho 4-1-8, Kawaguchi-shi, Saitama, 332-0012, Japan</address>
<email confidence="0.986141">tsujii@is.s.u-tokyo.ac.jp</email>
<abstract confidence="0.999336857142857">An empirical comparison of CFG filtering techniques for LTAG and HPSG is presented. We demonstrate that an approximation of HPSG produces a more effective CFG filter than that of LTAG. We also investigate the reason for that difference.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Earley</author>
</authors>
<title>An efficient context-free parsing algorithm.</title>
<date>1970</date>
<journal>Communications of the ACM,</journal>
<volume>6</volume>
<issue>8</issue>
<contexts>
<context position="9320" citStr="Earley, 1970" startWordPosition="1543" endWordPosition="1544">enceforth refer to the LTAG extracted from Section x of WSJ and CFGs approximated from Gx by PB and TNT, respectively. The size of CFGTNT is much larger than that of CFGPB. By investigating parsing performance using these CFGs, we show that the larger size of CFGTNT resulted in better parsing performance. Table 2 shows the parse time with 254 sentences of length n (≤10) from Section 2 of WSJ (the average length is 6.72 words).4 This result shows not only that TNT achieved a drastic speed-up against 1All daughters of rules are instantiated in the approximation. 2In phase 1, PB performs Earley (Earley, 1970) parsing while TNT performs CKY (Younger, 1967) parsing. 3The elementary trees in the LTAGs are binarized. 4We used a subset of the training corpus to avoid the complication of using default lexical entries for unknown words. Table 3: The numbers of essential edges with the strongly equivalent grammars for Section 02 of WSJ Parser G2 G2-4 G2-6 G2-8 G2-10 G2-21 PB 791 1,435 1,924 2,192 2,566 3,976 TNT 63 121 174 218 265 536 Table 4: The success rate (%) of phase 2 operations Operations G2 G2-4 G2-6 G2-8 G2-10 G2-21 ok-prop (PB) 38.5 34.3 33.1 32.3 31.7 31.0 rule-app (TNT) 100 100 100 100 100 10</context>
</contexts>
<marker>Earley, 1970</marker>
<rawString>J. Earley. 1970. An efficient context-free parsing algorithm. Communications of the ACM, 6(8):451–455.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Harbusch</author>
</authors>
<title>An efficient parsing algorithm for Tree Adjoining Grammars.</title>
<date>1990</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>284--291</pages>
<contexts>
<context position="1750" citStr="Harbusch, 1990" startWordPosition="249" endWordPosition="250"> 1994; Yoshida et al., 1999; Torisawa et al., 2000). However, these realizations sometimes exhibit quite different performance in each grammar formalism (Yoshida et al., 1999; Yoshinaga et al., 2001). If we could identify an algorithmic difference that causes performance difference, it would reveal advantages and disadvantages of the different realizations. This should also allow us to integrate the advantages of the realizations into one generic parsing technique, which yields the further advancement of the whole parsing community. In this paper, we compare CFG filtering techniques for LTAG (Harbusch, 1990; Poller and Becker, 1998) and HPSG (Torisawa et al., 2000; Kiefer and Krieger, 2000), following an approach to parsing comparison among different grammar formalisms (Yoshinaga et al., 2001). The key idea of the approach is to use strongly equivalent grammars, which generate equivalent parse results for the same input, obtained by a grammar conversion as demonstrated by Yoshinaga and Miyao (2001). The parsers with CFG filtering predict possible parse trees by a CFG approximated from a given grammar. Comparison of those parsers are interesting because effective CFG filters allow us to bring the</context>
<context position="3104" citStr="Harbusch, 1990" startWordPosition="464" endWordPosition="465">pproximation of LTAG and HPSG will thereby enlighten a way of further optimization for both techniques. We performed a comparison between the existing CFG filtering techniques for LTAG (Poller and Becker, 1998) and HPSG (Torisawa et al., 2000), using strongly equivalent grammars obtained by converting LTAGs extracted from the Penn Treebank (Marcus et al., 1993) into HPSG-style. We compared the parsers with respect to the size of the approximated CFG and its effectiveness as a filter. 2 Background In this section, we introduce a grammar conversion (Yoshinaga and Miyao, 2001) and CFG filtering (Harbusch, 1990; Poller and Becker, 1998; Torisawa et al., 2000; Kiefer and Krieger, 2000). 2.1 Grammar conversion The grammar conversion consists of a conversion of LTAG elementary trees to HPSG lexical entries and an emulation of substitution and adjunction by Figure 1: Extraction of CFG from LTAG pre-determined grammar rules. An LTAG elementary tree is first converted into canonical elementary trees which have only one anchor and whose subtrees of depth n (≥1) contain at least one anchor. A canonical elementary tree is then converted into an HPSG lexical entry by regarding the leaf nodes as arguments and </context>
<context position="5072" citStr="Harbusch, 1990" startWordPosition="787" endWordPosition="788">tions. In phase 2, it then eliminates invalid parse trees by using constraints in the given grammar. We call the remaining edges that are used for the phase 2 parsing essential edges. The parsers with CFG filtering used in our experiments follow the above parsing strategy, but are different in the way the CF approximation and the elimination of impossible parse trees in phase 2 are performed. In the following sections, we briefly describe the CF approximation and the elimination of impossible parse trees in each realization. 2.2.1 CF approximation of LTAG In CFG filtering techniques for LTAG (Harbusch, 1990; Poller and Becker, 1998), every branching of elementary trees in a given grammar is extracted as a CFG rule as shown in Figure 1. Because the obtained CFG can reflect only local constraints given in each local structure of the elementary trees, it generates invalid parse trees that connect local trees in different elementary trees. In order to eliminate such parse trees, a link between branchings is preserved as a node number which records a unique node address (a subscript attached to each node in Figure 1). We can eliminate these parse trees by traversing essential edges in a bottomup mann</context>
<context position="11340" citStr="Harbusch, 1990" startWordPosition="1885" endWordPosition="1886">converted from LTAGs. As described in Section 2.1, the grammar conversion preserves the whole structure of each elementary tree (precisely, a canonical elementary tree) in a stack, and grammar rules manipulate a head element of the stack. A generated feature structure in the approximation process thus corresponds to the whole unprocessed portion of a canonical elementary tree. This implies that successful context-free derivations obtained by CFGTNT basically involve elementary trees in which all substitution and adjunction have succeeded. However, CFGPB (also a CFG produced by the other work (Harbusch, 1990)) cannot avoid generating invalid parse trees that connect two lo5This means that the extracted LTAGs should be compatible with CFG and were completely converted to CFGs by TNT. 6Similar results were obtained in preliminary experiments using the XTAG English grammar (The XTAG Research Group, 2001) without features (parse time (sec.)/success rate (%) for PB and TNT were 15.3/30.6 and 0.606/71.2 with the same sentences), though space limitations preclude complete results. cal structures where adjunction takes place between them. We measured with G2-21 the proportion of the number of ok-prop betw</context>
</contexts>
<marker>Harbusch, 1990</marker>
<rawString>K. Harbusch. 1990. An efficient parsing algorithm for Tree Adjoining Grammars. In Proc. of ACL, pages 284–291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Kiefer</author>
<author>H-U Krieger</author>
</authors>
<title>A Context-Free approximation of Head-Driven Phrase Structure Grammar.</title>
<date>2000</date>
<booktitle>In Proc. ofIWPT,</booktitle>
<pages>135--146</pages>
<contexts>
<context position="1835" citStr="Kiefer and Krieger, 2000" startWordPosition="261" endWordPosition="264">ations sometimes exhibit quite different performance in each grammar formalism (Yoshida et al., 1999; Yoshinaga et al., 2001). If we could identify an algorithmic difference that causes performance difference, it would reveal advantages and disadvantages of the different realizations. This should also allow us to integrate the advantages of the realizations into one generic parsing technique, which yields the further advancement of the whole parsing community. In this paper, we compare CFG filtering techniques for LTAG (Harbusch, 1990; Poller and Becker, 1998) and HPSG (Torisawa et al., 2000; Kiefer and Krieger, 2000), following an approach to parsing comparison among different grammar formalisms (Yoshinaga et al., 2001). The key idea of the approach is to use strongly equivalent grammars, which generate equivalent parse results for the same input, obtained by a grammar conversion as demonstrated by Yoshinaga and Miyao (2001). The parsers with CFG filtering predict possible parse trees by a CFG approximated from a given grammar. Comparison of those parsers are interesting because effective CFG filters allow us to bring the empirical time complexity of the parsers close to that of CFG parsing. Investigating</context>
<context position="3179" citStr="Kiefer and Krieger, 2000" startWordPosition="475" endWordPosition="478">rther optimization for both techniques. We performed a comparison between the existing CFG filtering techniques for LTAG (Poller and Becker, 1998) and HPSG (Torisawa et al., 2000), using strongly equivalent grammars obtained by converting LTAGs extracted from the Penn Treebank (Marcus et al., 1993) into HPSG-style. We compared the parsers with respect to the size of the approximated CFG and its effectiveness as a filter. 2 Background In this section, we introduce a grammar conversion (Yoshinaga and Miyao, 2001) and CFG filtering (Harbusch, 1990; Poller and Becker, 1998; Torisawa et al., 2000; Kiefer and Krieger, 2000). 2.1 Grammar conversion The grammar conversion consists of a conversion of LTAG elementary trees to HPSG lexical entries and an emulation of substitution and adjunction by Figure 1: Extraction of CFG from LTAG pre-determined grammar rules. An LTAG elementary tree is first converted into canonical elementary trees which have only one anchor and whose subtrees of depth n (≥1) contain at least one anchor. A canonical elementary tree is then converted into an HPSG lexical entry by regarding the leaf nodes as arguments and by storing them in a stack. We can perform a comparison between LTAG and HP</context>
<context position="5968" citStr="Kiefer and Krieger, 2000" startWordPosition="941" endWordPosition="944">se trees that connect local trees in different elementary trees. In order to eliminate such parse trees, a link between branchings is preserved as a node number which records a unique node address (a subscript attached to each node in Figure 1). We can eliminate these parse trees by traversing essential edges in a bottomup manner and recursively propagating ok-flag from a node number x to a node number y when a connection between x and y is allowed in the LTAG grammar. We call this propagation ok-prop. 2.2.2 CF approximation of HPSG In CFG filtering techniques for HPSG (Torisawa et al., 2000; Kiefer and Krieger, 2000), the extraction process of a CFG from a given HPSG grammar starts by recursively instantiating daughters of a grammar rule with lexical entries and generated feature structures until new feature structures are not generated as shown in Figure 2. We must impose restrictions on values of some features (i.e., ignoring them) and/or the number of rule applications in order to guarantee the termination of the rule application. A CFG is obtained by regarding each initial and generated feature structures as nonterminals and transition relations between them as CFG rules. Although the obtained CFG can</context>
</contexts>
<marker>Kiefer, Krieger, 2000</marker>
<rawString>B. Kiefer and H.-U. Krieger. 2000. A Context-Free approximation of Head-Driven Phrase Structure Grammar. In Proc. ofIWPT, pages 135–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="2853" citStr="Marcus et al., 1993" startWordPosition="420" endWordPosition="423">from a given grammar. Comparison of those parsers are interesting because effective CFG filters allow us to bring the empirical time complexity of the parsers close to that of CFG parsing. Investigating the difference between the ways of context-free (CF) approximation of LTAG and HPSG will thereby enlighten a way of further optimization for both techniques. We performed a comparison between the existing CFG filtering techniques for LTAG (Poller and Becker, 1998) and HPSG (Torisawa et al., 2000), using strongly equivalent grammars obtained by converting LTAGs extracted from the Penn Treebank (Marcus et al., 1993) into HPSG-style. We compared the parsers with respect to the size of the approximated CFG and its effectiveness as a filter. 2 Background In this section, we introduce a grammar conversion (Yoshinaga and Miyao, 2001) and CFG filtering (Harbusch, 1990; Poller and Becker, 1998; Torisawa et al., 2000; Kiefer and Krieger, 2000). 2.1 Grammar conversion The grammar conversion consists of a conversion of LTAG elementary trees to HPSG lexical entries and an emulation of substitution and adjunction by Figure 1: Extraction of CFG from LTAG pre-determined grammar rules. An LTAG elementary tree is first </context>
<context position="8460" citStr="Marcus et al., 1993" startWordPosition="1397" endWordPosition="1400">ammars for Section 2 of WSJ Parser G2 G2-4 G2-6 G2-8 G2-10 G2-21 PB 1.4 9.1 17.4 24.0 34.2 124.3 TNT 0.044 0.097 0.144 0.182 0.224 0.542 3 Comparison with CFG filtering In this section, we compare a pair of CFG filtering techniques for LTAG (Poller and Becker, 1998) and HPSG (Torisawa et al., 2000) described in Section 2.2.1 and 2.2.2. We hereafter refer to PB and TNT for the C++ implementations of the former and a valiant1 of the latter, respectively.2 We first acquired LTAGs by a method proposed in Miyao et al. (2003) from Sections 2-21 of the Wall Street Journal (WSJ) in the Penn Treebank (Marcus et al., 1993) and its subsets.3 We then converted them into strongly equivalent HPSG-style grammars using the grammar conversion described in Section 2.1. Table 1 shows the size of CFG approximated from the strongly equivalent grammars. Gx, CFGPB, and CFGTNT henceforth refer to the LTAG extracted from Section x of WSJ and CFGs approximated from Gx by PB and TNT, respectively. The size of CFGTNT is much larger than that of CFGPB. By investigating parsing performance using these CFGs, we show that the larger size of CFGTNT resulted in better parsing performance. Table 2 shows the parse time with 254 sentence</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. Marcus, B. Santorini, and M. A. Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J T Maxwell</author>
<author>R M Kaplan</author>
</authors>
<title>The interface between phrasal and functional constraints.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>4</issue>
<marker>Maxwell, Kaplan, 1993</marker>
<rawString>J. T. Maxwell III and R. M. Kaplan. 1993. The interface between phrasal and functional constraints. Computational Linguistics, 19(4):571–590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Miyao</author>
<author>T Ninomiya</author>
<author>J Tsujii</author>
</authors>
<title>Lexicalized grammar acquisition.</title>
<date>2003</date>
<booktitle>In Proc. of EACL companion volume,</booktitle>
<pages>127--130</pages>
<contexts>
<context position="8365" citStr="Miyao et al. (2003)" startWordPosition="1379" endWordPosition="1382">,115 58,356 68,239 118,464 Table 2: Parsing performance (sec.) with the strongly equivalent grammars for Section 2 of WSJ Parser G2 G2-4 G2-6 G2-8 G2-10 G2-21 PB 1.4 9.1 17.4 24.0 34.2 124.3 TNT 0.044 0.097 0.144 0.182 0.224 0.542 3 Comparison with CFG filtering In this section, we compare a pair of CFG filtering techniques for LTAG (Poller and Becker, 1998) and HPSG (Torisawa et al., 2000) described in Section 2.2.1 and 2.2.2. We hereafter refer to PB and TNT for the C++ implementations of the former and a valiant1 of the latter, respectively.2 We first acquired LTAGs by a method proposed in Miyao et al. (2003) from Sections 2-21 of the Wall Street Journal (WSJ) in the Penn Treebank (Marcus et al., 1993) and its subsets.3 We then converted them into strongly equivalent HPSG-style grammars using the grammar conversion described in Section 2.1. Table 1 shows the size of CFG approximated from the strongly equivalent grammars. Gx, CFGPB, and CFGTNT henceforth refer to the LTAG extracted from Section x of WSJ and CFGs approximated from Gx by PB and TNT, respectively. The size of CFGTNT is much larger than that of CFGPB. By investigating parsing performance using these CFGs, we show that the larger size o</context>
</contexts>
<marker>Miyao, Ninomiya, Tsujii, 2003</marker>
<rawString>Y. Miyao, T. Ninomiya, and J. Tsujii. 2003. Lexicalized grammar acquisition. In Proc. of EACL companion volume, pages 127–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
<author>I A Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<booktitle>In Proc. of TAG+4,</booktitle>
<pages>143--146</pages>
<institution>University of Chicago</institution>
<contexts>
<context position="954" citStr="Pollard and Sag, 1994" startWordPosition="126" endWordPosition="129">ujii†* * CREST, JST (Japan Science and Technology Corporation) Hon-cho 4-1-8, Kawaguchi-shi, Saitama, 332-0012, Japan tsujii@is.s.u-tokyo.ac.jp Abstract An empirical comparison of CFG filtering techniques for LTAG and HPSG is presented. We demonstrate that an approximation of HPSG produces a more effective CFG filter than that of LTAG. We also investigate the reason for that difference. 1 Introduction Various parsing techniques have been developed for lexicalized grammars such as Lexicalized Tree Adjoining Grammar (LTAG) (Schabes et al., 1988), and Head-Driven Phrase Structure Grammar (HPSG) (Pollard and Sag, 1994). Along with the independent development of parsing techniques for individual grammar formalisms, some of them have been adapted to other formalisms (Schabes et al., 1988; van Noord, 1994; Yoshida et al., 1999; Torisawa et al., 2000). However, these realizations sometimes exhibit quite different performance in each grammar formalism (Yoshida et al., 1999; Yoshinaga et al., 2001). If we could identify an algorithmic difference that causes performance difference, it would reveal advantages and disadvantages of the different realizations. This should also allow us to integrate the advantages of t</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>C. Pollard and I. A. Sag. 1994. Head-Driven Phrase Structure Grammar. University of Chicago Press. P. Poller and T. Becker. 1998. Two-step TAG parsing revisited. In Proc. of TAG+4, pages 143–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Schabes</author>
<author>A Abeill´e</author>
<author>A K Joshi</author>
</authors>
<title>Parsing strategies with ‘lexicalized’ grammars: Application to Tree Adjoining Grammars.</title>
<date>1988</date>
<booktitle>In Proc. of COLING,</booktitle>
<pages>578--583</pages>
<marker>Schabes, Abeill´e, Joshi, 1988</marker>
<rawString>Y. Schabes, A. Abeill´e, and A. K. Joshi. 1988. Parsing strategies with ‘lexicalized’ grammars: Application to Tree Adjoining Grammars. In Proc. of COLING, pages 578–583.</rawString>
</citation>
<citation valid="true">
<authors>
<author>The XTAG Research Group</author>
</authors>
<title>A Lexicalized Tree Adjoining Grammar for English.</title>
<date>2001</date>
<tech>Technical Report IRCS-01-03,</tech>
<institution>IRCS, University of Pennsylvania.</institution>
<contexts>
<context position="11638" citStr="Group, 2001" startWordPosition="1931" endWordPosition="1932">s corresponds to the whole unprocessed portion of a canonical elementary tree. This implies that successful context-free derivations obtained by CFGTNT basically involve elementary trees in which all substitution and adjunction have succeeded. However, CFGPB (also a CFG produced by the other work (Harbusch, 1990)) cannot avoid generating invalid parse trees that connect two lo5This means that the extracted LTAGs should be compatible with CFG and were completely converted to CFGs by TNT. 6Similar results were obtained in preliminary experiments using the XTAG English grammar (The XTAG Research Group, 2001) without features (parse time (sec.)/success rate (%) for PB and TNT were 15.3/30.6 and 0.606/71.2 with the same sentences), though space limitations preclude complete results. cal structures where adjunction takes place between them. We measured with G2-21 the proportion of the number of ok-prop between two node numbers of nodes that take adjunction and its success rate. It occupied 87% of the total number of ok-prop and its success rate was only 22%. These results suggest that the global contexts in a given grammar is essential to obtain an effective CFG filter. It should be noted that the a</context>
</contexts>
<marker>Group, 2001</marker>
<rawString>The XTAG Research Group. 2001. A Lexicalized Tree Adjoining Grammar for English. Technical Report IRCS-01-03, IRCS, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Torisawa</author>
<author>K Nishida</author>
<author>Y Miyao</author>
<author>J Tsujii</author>
</authors>
<title>An HPSG parser with CFG filtering.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="1187" citStr="Torisawa et al., 2000" startWordPosition="162" endWordPosition="165">ed. We demonstrate that an approximation of HPSG produces a more effective CFG filter than that of LTAG. We also investigate the reason for that difference. 1 Introduction Various parsing techniques have been developed for lexicalized grammars such as Lexicalized Tree Adjoining Grammar (LTAG) (Schabes et al., 1988), and Head-Driven Phrase Structure Grammar (HPSG) (Pollard and Sag, 1994). Along with the independent development of parsing techniques for individual grammar formalisms, some of them have been adapted to other formalisms (Schabes et al., 1988; van Noord, 1994; Yoshida et al., 1999; Torisawa et al., 2000). However, these realizations sometimes exhibit quite different performance in each grammar formalism (Yoshida et al., 1999; Yoshinaga et al., 2001). If we could identify an algorithmic difference that causes performance difference, it would reveal advantages and disadvantages of the different realizations. This should also allow us to integrate the advantages of the realizations into one generic parsing technique, which yields the further advancement of the whole parsing community. In this paper, we compare CFG filtering techniques for LTAG (Harbusch, 1990; Poller and Becker, 1998) and HPSG (</context>
<context position="2733" citStr="Torisawa et al., 2000" startWordPosition="402" endWordPosition="405">nstrated by Yoshinaga and Miyao (2001). The parsers with CFG filtering predict possible parse trees by a CFG approximated from a given grammar. Comparison of those parsers are interesting because effective CFG filters allow us to bring the empirical time complexity of the parsers close to that of CFG parsing. Investigating the difference between the ways of context-free (CF) approximation of LTAG and HPSG will thereby enlighten a way of further optimization for both techniques. We performed a comparison between the existing CFG filtering techniques for LTAG (Poller and Becker, 1998) and HPSG (Torisawa et al., 2000), using strongly equivalent grammars obtained by converting LTAGs extracted from the Penn Treebank (Marcus et al., 1993) into HPSG-style. We compared the parsers with respect to the size of the approximated CFG and its effectiveness as a filter. 2 Background In this section, we introduce a grammar conversion (Yoshinaga and Miyao, 2001) and CFG filtering (Harbusch, 1990; Poller and Becker, 1998; Torisawa et al., 2000; Kiefer and Krieger, 2000). 2.1 Grammar conversion The grammar conversion consists of a conversion of LTAG elementary trees to HPSG lexical entries and an emulation of substitution</context>
<context position="5941" citStr="Torisawa et al., 2000" startWordPosition="937" endWordPosition="940">t generates invalid parse trees that connect local trees in different elementary trees. In order to eliminate such parse trees, a link between branchings is preserved as a node number which records a unique node address (a subscript attached to each node in Figure 1). We can eliminate these parse trees by traversing essential edges in a bottomup manner and recursively propagating ok-flag from a node number x to a node number y when a connection between x and y is allowed in the LTAG grammar. We call this propagation ok-prop. 2.2.2 CF approximation of HPSG In CFG filtering techniques for HPSG (Torisawa et al., 2000; Kiefer and Krieger, 2000), the extraction process of a CFG from a given HPSG grammar starts by recursively instantiating daughters of a grammar rule with lexical entries and generated feature structures until new feature structures are not generated as shown in Figure 2. We must impose restrictions on values of some features (i.e., ignoring them) and/or the number of rule applications in order to guarantee the termination of the rule application. A CFG is obtained by regarding each initial and generated feature structures as nonterminals and transition relations between them as CFG rules. Al</context>
<context position="8139" citStr="Torisawa et al., 2000" startWordPosition="1337" endWordPosition="1340">inals; below: the number of rules) Grammar G2 G2-4 G2-6 G2-8 G2-10 G2-21 LTAG 1,488 2,412 3,139 3,536 3,999 6,085 CFGPB 65 66 66 66 67 67 716 954 1,090 1,158 1,229 1,552 CFGTNT 1,989 3,118 4,009 4,468 5,034 7,454 18,323 35,541 50,115 58,356 68,239 118,464 Table 2: Parsing performance (sec.) with the strongly equivalent grammars for Section 2 of WSJ Parser G2 G2-4 G2-6 G2-8 G2-10 G2-21 PB 1.4 9.1 17.4 24.0 34.2 124.3 TNT 0.044 0.097 0.144 0.182 0.224 0.542 3 Comparison with CFG filtering In this section, we compare a pair of CFG filtering techniques for LTAG (Poller and Becker, 1998) and HPSG (Torisawa et al., 2000) described in Section 2.2.1 and 2.2.2. We hereafter refer to PB and TNT for the C++ implementations of the former and a valiant1 of the latter, respectively.2 We first acquired LTAGs by a method proposed in Miyao et al. (2003) from Sections 2-21 of the Wall Street Journal (WSJ) in the Penn Treebank (Marcus et al., 1993) and its subsets.3 We then converted them into strongly equivalent HPSG-style grammars using the grammar conversion described in Section 2.1. Table 1 shows the size of CFG approximated from the strongly equivalent grammars. Gx, CFGPB, and CFGTNT henceforth refer to the LTAG extr</context>
<context position="13273" citStr="Torisawa et al., 2000" startWordPosition="2193" endWordPosition="2197">erated tree structures are no longer used later, we regard the unprocessed portions of the tree structures as nonterminals of CFG. We can thereby construct another CFG filtering for LTAG by combining this CFG filter with an existing LTAG parsing algorithm (van Noord, 1994). 4 Conclusion and future direction We presented an empirical comparison of LTAG and HPSG parsers with CFG filtering. We compared the parsers with strongly equivalent grammars obtained by converting LTAGs extracted from the Penn Treebank into HPSG-style. Experimental results showed that the existing CF approximation of HPSG (Torisawa et al., 2000) produced a more effective filter than that of LTAG (Poller and Becker, 1998). By investigating the different ways of CF approximation, we concluded that the global constraints in a given grammar is essential to obtain an effective filter. We are going to integrate the advantage of the CF approximation of HPSG into that of LTAG in order to establish another CFG filtering for LTAG. We will also conduct experiments on trade-offs between the degree of CF approximation and the size of approximated CFGs as in Maxwell III and Kaplan (1993). Acknowledgment We thank Yousuke Sakao for his help in profi</context>
</contexts>
<marker>Torisawa, Nishida, Miyao, Tsujii, 2000</marker>
<rawString>K. Torisawa, K. Nishida, Y. Miyao, and J. Tsujii. 2000. An HPSG parser with CFG filtering. Natural Language Engineering, 6(1):63–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G van Noord</author>
</authors>
<title>Head corner parsing for TAG.</title>
<date>1994</date>
<journal>Computational Intelligence,</journal>
<volume>10</volume>
<issue>4</issue>
<marker>van Noord, 1994</marker>
<rawString>G. van Noord. 1994. Head corner parsing for TAG. Computational Intelligence, 10(4):525–534.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Yoshida</author>
<author>T Ninomiya</author>
<author>K Torisawa</author>
<author>T Makino</author>
<author>J Tsujii</author>
</authors>
<title>Efficient FB-LTAG parser and its parallelization.</title>
<date>1999</date>
<booktitle>In Proc. ofPACLING,</booktitle>
<pages>90--103</pages>
<contexts>
<context position="1163" citStr="Yoshida et al., 1999" startWordPosition="158" endWordPosition="161">AG and HPSG is presented. We demonstrate that an approximation of HPSG produces a more effective CFG filter than that of LTAG. We also investigate the reason for that difference. 1 Introduction Various parsing techniques have been developed for lexicalized grammars such as Lexicalized Tree Adjoining Grammar (LTAG) (Schabes et al., 1988), and Head-Driven Phrase Structure Grammar (HPSG) (Pollard and Sag, 1994). Along with the independent development of parsing techniques for individual grammar formalisms, some of them have been adapted to other formalisms (Schabes et al., 1988; van Noord, 1994; Yoshida et al., 1999; Torisawa et al., 2000). However, these realizations sometimes exhibit quite different performance in each grammar formalism (Yoshida et al., 1999; Yoshinaga et al., 2001). If we could identify an algorithmic difference that causes performance difference, it would reveal advantages and disadvantages of the different realizations. This should also allow us to integrate the advantages of the realizations into one generic parsing technique, which yields the further advancement of the whole parsing community. In this paper, we compare CFG filtering techniques for LTAG (Harbusch, 1990; Poller and </context>
</contexts>
<marker>Yoshida, Ninomiya, Torisawa, Makino, Tsujii, 1999</marker>
<rawString>M. Yoshida, T. Ninomiya, K. Torisawa, T. Makino, and J. Tsujii. 1999. Efficient FB-LTAG parser and its parallelization. In Proc. ofPACLING, pages 90–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Yoshinaga</author>
<author>Y Miyao</author>
</authors>
<title>Grammar conversion from LTAG to HPSG.</title>
<date>2001</date>
<booktitle>In Proc. ofESSLLI Student Session,</booktitle>
<pages>309--324</pages>
<contexts>
<context position="2149" citStr="Yoshinaga and Miyao (2001)" startWordPosition="310" endWordPosition="313">o integrate the advantages of the realizations into one generic parsing technique, which yields the further advancement of the whole parsing community. In this paper, we compare CFG filtering techniques for LTAG (Harbusch, 1990; Poller and Becker, 1998) and HPSG (Torisawa et al., 2000; Kiefer and Krieger, 2000), following an approach to parsing comparison among different grammar formalisms (Yoshinaga et al., 2001). The key idea of the approach is to use strongly equivalent grammars, which generate equivalent parse results for the same input, obtained by a grammar conversion as demonstrated by Yoshinaga and Miyao (2001). The parsers with CFG filtering predict possible parse trees by a CFG approximated from a given grammar. Comparison of those parsers are interesting because effective CFG filters allow us to bring the empirical time complexity of the parsers close to that of CFG parsing. Investigating the difference between the ways of context-free (CF) approximation of LTAG and HPSG will thereby enlighten a way of further optimization for both techniques. We performed a comparison between the existing CFG filtering techniques for LTAG (Poller and Becker, 1998) and HPSG (Torisawa et al., 2000), using strongly</context>
</contexts>
<marker>Yoshinaga, Miyao, 2001</marker>
<rawString>N. Yoshinaga and Y. Miyao. 2001. Grammar conversion from LTAG to HPSG. In Proc. ofESSLLI Student Session, pages 309–324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Yoshinaga</author>
<author>Y Miyao</author>
<author>K Torisawa</author>
<author>J Tsujii</author>
</authors>
<title>Efficient LTAG parsing using HPSG parsers.</title>
<date>2001</date>
<booktitle>In Proc. of PACLING,</booktitle>
<pages>342--351</pages>
<contexts>
<context position="1335" citStr="Yoshinaga et al., 2001" startWordPosition="183" endWordPosition="186">fference. 1 Introduction Various parsing techniques have been developed for lexicalized grammars such as Lexicalized Tree Adjoining Grammar (LTAG) (Schabes et al., 1988), and Head-Driven Phrase Structure Grammar (HPSG) (Pollard and Sag, 1994). Along with the independent development of parsing techniques for individual grammar formalisms, some of them have been adapted to other formalisms (Schabes et al., 1988; van Noord, 1994; Yoshida et al., 1999; Torisawa et al., 2000). However, these realizations sometimes exhibit quite different performance in each grammar formalism (Yoshida et al., 1999; Yoshinaga et al., 2001). If we could identify an algorithmic difference that causes performance difference, it would reveal advantages and disadvantages of the different realizations. This should also allow us to integrate the advantages of the realizations into one generic parsing technique, which yields the further advancement of the whole parsing community. In this paper, we compare CFG filtering techniques for LTAG (Harbusch, 1990; Poller and Becker, 1998) and HPSG (Torisawa et al., 2000; Kiefer and Krieger, 2000), following an approach to parsing comparison among different grammar formalisms (Yoshinaga et al., </context>
</contexts>
<marker>Yoshinaga, Miyao, Torisawa, Tsujii, 2001</marker>
<rawString>N. Yoshinaga, Y. Miyao, K. Torisawa, and J. Tsujii. 2001. Efficient LTAG parsing using HPSG parsers. In Proc. of PACLING, pages 342–351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D H Younger</author>
</authors>
<title>Recognition and parsing of context-free languages in time n3.</title>
<date>1967</date>
<journal>Information and Control,</journal>
<volume>2</volume>
<issue>10</issue>
<contexts>
<context position="9367" citStr="Younger, 1967" startWordPosition="1550" endWordPosition="1551">tion x of WSJ and CFGs approximated from Gx by PB and TNT, respectively. The size of CFGTNT is much larger than that of CFGPB. By investigating parsing performance using these CFGs, we show that the larger size of CFGTNT resulted in better parsing performance. Table 2 shows the parse time with 254 sentences of length n (≤10) from Section 2 of WSJ (the average length is 6.72 words).4 This result shows not only that TNT achieved a drastic speed-up against 1All daughters of rules are instantiated in the approximation. 2In phase 1, PB performs Earley (Earley, 1970) parsing while TNT performs CKY (Younger, 1967) parsing. 3The elementary trees in the LTAGs are binarized. 4We used a subset of the training corpus to avoid the complication of using default lexical entries for unknown words. Table 3: The numbers of essential edges with the strongly equivalent grammars for Section 02 of WSJ Parser G2 G2-4 G2-6 G2-8 G2-10 G2-21 PB 791 1,435 1,924 2,192 2,566 3,976 TNT 63 121 174 218 265 536 Table 4: The success rate (%) of phase 2 operations Operations G2 G2-4 G2-6 G2-8 G2-10 G2-21 ok-prop (PB) 38.5 34.3 33.1 32.3 31.7 31.0 rule-app (TNT) 100 100 100 100 100 100 PB, but also that performance difference betw</context>
</contexts>
<marker>Younger, 1967</marker>
<rawString>D. H. Younger. 1967. Recognition and parsing of context-free languages in time n3. Information and Control, 2(10):189–208, February.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>