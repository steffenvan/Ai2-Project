<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000071">
<title confidence="0.967647">
Techniques for Accelerating a Grammar-Checker
</title>
<author confidence="0.992543">
Karel Oliva
</author>
<affiliation confidence="0.986824">
Computational Linguistics
University of Saarland
</affiliation>
<address confidence="0.827165666666667">
Postfach 15 11 50
D - 66 041 Saarbriicken
Germany
</address>
<email confidence="0.912147">
email: olivacoli .uni-sb.de
</email>
<sectionHeader confidence="0.99335" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9993871">
The paper describes several possibilities of
using finite-state automata as means for
speeding up the performance of a grammar-
and-parsing-based (as opposed to pattern-
matching-based) grammar-checker able to
detect errors from a predefined set. The
ideas contained have been successfully im-
plemented in a grammar-checker for Czech,
a free-word-order language from the Slavic
group.
</bodyText>
<sectionHeader confidence="0.997818" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9993164375">
This paper describes an efficiency-supporting tool
for one of the two grammar-checker technologies de-
veloped in the framework of the PECO2824 Joint
Research Project sponsored by the European Union.
The project„ covering Bulgarian and Czech, two free-
word-order languages from the Slavic family, was
performed between January 1993 and mid 1996 by
a consortium consisting of both academic and indu-
strial partners.
The basic philosophy of the technology discussed
in this paper&apos; is that of linguistic-theoretically sound
grammar-and-parsing-based machinery able to de-
tect, by constraint relaxation, errors from a predefi-
ned set (as opposed to pattern-matching approaches,
which do not seem promising for a free word-order
language). The core of the system (broad-coverage
HPSG-based grammars of Bulgarian and Czech, and
a single language-independent parser) was developed
in the first three years of the project and was then
passed to the industrial partners Bulgarian Business
System IMC Sofia and Macron Prague., Ltd. While
the Bulgarian system remained in more or less a de-
monstrator stage only, the Czech one satisfied Ma-
cron&apos;s requirements as to syntactic coverage. Ho-
wever, Macron expressed serious worries about, the
speed of the system, should this be really introdu-
ced to the market.. Following this, several possibili-
&apos;As for the alternative technology, cf. (Holan,
and Platek, 1997)
ties of using finite-state automata (FSA) as means
for speeding up the performance of the system were
designed, developed and implemented, in particular:
</bodyText>
<listItem confidence="0.822348789473684">
• for detecting sentences where none of the prede-
fined errors can occur (thus ruling out such sent-
ences from the procedure of error-search proper)
• for detecting which one(s) of the predefined er-
ror types might possibly occur in a particular
sentence (hence, cutting down the search space
of the error-search proper)
• for detecting errors which are of such a nature
that their occurrence might be discovered by
a machinery simpler than full-fledged parsing
with constraint relaxation
• for splitting (certain cases of) complex sent-
ences into independent clauses, allowing thus
for the error-detection to be performed on shor-
ter strings.
2 Lexicalization of Error Search
Very many of the errors to be discovered by the sy-
stem can be traced down to mismatches of (values
of) features projected into the syntactic structure
from the lexicon. Even though the error searching
capabilities of the system are not limited in princi-
ple to these lexically induced errors, for a practical
implementation it turned out to be useful to narrow
down the error search of the system to almost only
these kinds of errors, for the following reasons:
1. the loss of generality of the system is in fact only
minimal, since the majority of errors which the
system is able to detect are of this nature any-
way (the only exception being agreement errors
involving NPs with complicated internal struc-
ture, e.g., ellipses or coordination)
2. this loss of error coverage (almost negligible for
a real application) is outweighed by substan-
tial gain in overall (statistical) speed of the sy-
stem, which is achieved by adding a preproces-
sing phase consisting of a finite state automaton
passing through the input string and looking for
a lexical trigger of a contingent error:
</listItem>
<page confidence="0.979683">
155
</page>
<listItem confidence="0.972481142857143">
• if this automaton does not, find any
such trigger, the time-consuming grammar-
checking process proper (i.e. parsing, pos-
sibly also reparsing with relaxed cons-
traints) is not, started at, all and the sent-
ence is immediately marked as one contai-
ning no detectable error
• if this automaton finds such a lexical trig-
ger of an error, it, &apos;remembers&apos; its nature
so that. in the following phases, only the
respective constraints are relaxed (which
helps to cut. down the search space, a.s
compared to reparsing with relaxing of all
predefined-errors-related constraints)
</listItem>
<bodyText confidence="0.999892578947368">
As an example of this idea., let us consider a sy-
stem dealing with errors in subject-verb agreement
in Czech (and taking - for the very purpose of this
example - detection of no other errors into account.).
Since the realistic part of such errors in Czech is the
`4/-Y&apos; dichotomy on homophonic past tense verb
endings occurring on plural verbs (`-F ending stan-
ding with plural masculine animate subjects, &apos;-Y en-
ding with plural masculine inanimate and feminine
subjects), the preprocessing finite-state automaton
marks all sentences not containing any of these forms
(i.e. all sentences containing only singular verbs, or
plural verbs but in present tense or in neuter gender,
or infinite verb forms) as &apos;containing no detectable
error&apos;, without any actual grammar-checking taking
place (it is, however, obvious that this does not ne-
cessarily mean that the sentences are truly correct -
they just do not contain the kind of error the system
is able to detect).
</bodyText>
<sectionHeader confidence="0.8799165" genericHeader="method">
3 Alternative Error-Classification
and Error Search by Finite Automata
</sectionHeader>
<bodyText confidence="0.999950535714286">
Another important step towards the application of
FSA to error-detection was developing a. new dimen-
sion of classification of errors to be detected: apart,
from the more standard criteria of frequency and
performance/competence, we developed a scale ba-
sed on the complexity of the formal apparatus nee-
ded for the detection of the particular error type (as
for error typology developed for the purpose of the
error detection techniques used in the project.. cf.
(Rodriguez Selles, Galvez, and Oliva, 1996)). On
the one end of this scale were errors recognizable wi-
thin a. strictly local context, such as commas missing
in front of a. certain kind of complementizers (sub-
ordinating conjunctions) or incorrect vocalization of
a preposition (in both Bulgarian and (.zech, certain
prepositions ending normally with a. consonant get. a
supporting vocal in case the word that follows them
also starts with a. consonant - the parallel in English
would be the opposition between the two forms a
and an. of the indefinite article). On the other end
of the scale we put, e.g., the general case of subject-
verb agreement, errors. Practically more iinportant
was the question whether there exists a class of er-
rors with complexity of detection lying between the
&amp;quot;trivial errors&amp;quot; and the errors for the detection of
which a full-fledged analysis is necessary - in other
words, the question whether there exist some errors
for the recognition of which
</bodyText>
<listItem confidence="0.984892777777778">
• on the one hand, a limited local context is insuf-
ficient. (i.e. it is necessary for this end to process
a. substring of length which cannot be set. in ad-
vance, in general the whole input. string),
• on the other hand, it is not, necessary to use the
power of the full-fledged parser, and, in parti-
cular, it is sufficient to use the power of a. fi-
nite state automaton or only slight, augmenta-
tion thereof.
</listItem>
<bodyText confidence="0.863051785714286">
Following some linguistic research, two such error
types have been selected for implementation, and
while one of them is just, a marginal subtype of an
error in subject-verb agreement., the other is an error
type of its own, and in addition one of really crucial
importance for practical grammar-checking due to
its high frequency of occurrence.
The former error to be detected by the finite state
machinery is a particular instance of an error where
a plural masculine animate subject is conjoined with
a verb in a plural feminine form (cf. also the example
above). The idea of detecting sonic particular cases
of this error by a finite state automaton results from
the combination of the following observations:
• the nominative plural form of masculine aid-
mate nouns of the declension types paw. and
pi-cliscda. is not ambiguous (homonymous) with
any other case forms (apart, form vocative case,
which we shall deal with immediately below);
tins means that. if such a form occurs in a sent-
ence, then this form can be only
either a subject„
or a. nominal predicate (with copula)
or a comparison to these, adjoined by
means of the conjunctions jako, jako.f.to or
cob by
or an exclamative expression (in nomina-
tive or vocative case)
</bodyText>
<listItem confidence="0.9742422">
• due to rules of Czech interpunction. any excla-
illative expression has to be separated from the
rest of the sentence by commas
• also, due to rules of Czech interpunction, two
finite verbs in Czech must be separated from
</listItem>
<bodyText confidence="0.810062">
each other by either a comma or by one of the
following coordinating conjunctions a, i and
71.ebo
Hence, if we build up a finite state at itomaton able
to recognize the following substrings:
1 &lt;unanibiguous masculine animate noun in no-
minative plural&gt; followed by any string contai-
ning neither a finite verb form nor a. conirn:
</bodyText>
<page confidence="0.997661">
156
</page>
<bodyText confidence="0.99922921875">
nor one of the conjunctions a, i and ntIw follo-
wed by &lt;unambiguous past participle in plural
feminine&gt;
or (due to free \void order)
2 &lt;unambiguous past participle in plu-
ral feminine&gt; followed by any string contai-
ning neither a finite verb form nor a comma.
nor one of the conjunctions a, i, acbo followed
by &lt;unambiguous masculine animate noun in
nominative plural&gt; and combine it with a sim-
ple automaton able to detect the absence of the
words jaka, jakofia and coby as well as the ab-
sence of any finite form of the copula b#1, (&apos;to
be&apos;) in the sentence, then we may conclude that,
we have built a device able to detect whether
a sentence contains a particular instance of a
subject-verb agreement violation.
The detection of the latter error is also based on
the Czech interpunction ride prescribing that. there
always must occur a. comma or a coordinating con-
junction between two finite verb forms. Hence, a.
simple finite state automaton checking whether bet-
ween any two finite verb forms a. comma or a coor-
dinating conjunction occurs is able to detect many
cases of the omission of a comma at the end of an
embedded subordinated clause, which is one of the
most frequent errors at all. (Of course, the word-
forms of the verb must be unambiguously identifia.-
ble as such - i.e. such forms a.s LE7111, tratim,
hall etc., do not qualify due to their part. of speech
ambiguity, which means that, in sentences containing
them this strategy cannot, be used).
</bodyText>
<sectionHeader confidence="0.990944" genericHeader="method">
4 Using FSA
</sectionHeader>
<subsectionHeader confidence="0.976145">
for Splitting a Sentence into Clauses
</subsectionHeader>
<bodyText confidence="0.99549975">
The last idea how to gain efficiency is that of split-
ting the sentence (if possible) into clauses before the
processing, which has a two-fold positive effect on
the overall process of grammar-checking:
</bodyText>
<listItem confidence="0.8218845">
1. it, is less time consuming to parse two &apos;shorter&apos;
strings than one longer (assuming that, parsing
is at least cubic in time., this follows trivially
from the inequality
</listItem>
<bodyText confidence="0.711110108108108">
,43 B3 &lt; 43 +3.,4&apos; B 3AB&apos; + =
for A,B positive - length of strings)
2. it is possible to detect. an error in one of the
substrings (clauses) irrespective to the results
of analysis of (any of) the other one(s); in par-
ticular, also in cases where at least one of them
was not analyzed and, hence, also the parsing
(including the parsing with relaxed constraints)
of the whole input, could not have been perfor-
med on the original string, which would have
hindered the error message pertinent to the sub-
string successfully parsed during the parsing
with constraint, relaxation to be issued.
In particular, this means that measures are to be
found which would allow for splitting the input sent-
ence into clauses by purely superficial criteria. Ob-
viously, this is not possible in all cases (for all sent-
ences), but on the other hand it. is also clear that in
a.ny language there exists a (statistically) huge sub-
set of sentences of this language where such techni-
ques are applicable. For (..zecli, such an approach
might be implemented using pattern matching tech-
niques which would recognize for example the follo-
wing patterns (and use them in an obvious way for
splitting the sentence into clauses):
I. &lt;any string&gt; &lt;finite verb&gt; &lt;any string&gt;
&lt;conjunctive coordinating conjunction&gt; &lt;any
string&gt; &lt;finite verb&gt; &lt;any string&gt; &lt;end of
sentence&gt;
2. &lt;any string&gt; &lt;finite verb&gt; &lt;any string&gt;
&lt;comma.&gt; &lt;non-conjunctive coordinating con-
junction or complementizer&gt; &lt;any string&gt;
&lt;finite verb&gt; &lt;any string&gt; &lt;end of sentence&gt;
3 &lt;complementizer&gt; &lt;any string&gt; &lt;finite verb&gt;
&lt;any string&gt; &lt;comma&gt; &lt;any string&gt; &lt;finite
verb&gt; &lt;any string&gt; &lt;end of sentence&gt;
where the expressions have the following meaning(s):
</bodyText>
<listItem confidence="0.958309166666667">
• &lt;caly string&gt; is a variable for any string not
containing elements of&apos; the following nature: fi-
nite verb or word form homonymous with a
finite verb, coordinating conjunction (of any
kind), complementizer, any interpunction sign
• &lt;finite verb&gt; is a variable
</listItem>
<bodyText confidence="0.947012">
— for a main verb (not for an auxiliary) spe-
cified for person,
— or for a past. participle of a. main verb;
neither of these might be homonymous in part,
of speech (but they might. be ambiguous within
the defined class - such verbs as po(irobi, proud/
do qualify)
</bodyText>
<listItem confidence="0.998793666666667">
• &lt;end of sentence&gt; is simply either a full-stop,
a. question-ma.rk, an exclaination-mark, a colon
or a semi-colon.
</listItem>
<bodyText confidence="0.9997765">
All the remaining expressions have clear mnemonics,
and also the classes which they stand for do not
contain elements which are ambiguous a,s to part, of
speech.
</bodyText>
<sectionHeader confidence="0.991527" genericHeader="conclusions">
5 Significance and Caveats
</sectionHeader>
<bodyText confidence="0.9999425">
The techniques to be used for gaining overall per-
formance, speed and memory efficiency etc..; of a
grammar-checking system presented result. solely
from research concerning relevant properties of the
syntax of a particular language ((zecn, in part also
Bulgarian), and, hence, they are strongly language-
dependent,. However, it seems to be self-evident that
the core idea is transferable to other languages. The
</bodyText>
<page confidence="0.992909">
157
</page>
<bodyText confidence="0.980566222222222">
introduction of these techniques contributes to the
process of ripening of the system into a real indu-
strial application at least in the following points:
• it speeds up the overall performance of the sy-
stem considerably (in the order ranging from
one to two magnitudes, depending on the text
to be processed) by avoiding full-fledged par-
sing to be performed in unnecessary cases or by
making this parsing simpler
</bodyText>
<listItem confidence="0.87354875">
• it extends its coverage, in particular the capa-
bilities of the system to recognize as error-free
also a large number of sentences which in the
original version of the system would be unana-
</listItem>
<bodyText confidence="0.979875444444444">
lyzable by the non-relaxed grammar (as well as
by the grammar with relaxed constraints, for
that matter) due to either incompleteness of the
grammar proper or the exhaustion of hardware
resources.
There is a serious caveat to be issued, however:
since they do not employ full analysis of the input
sentence, these techniques are - albeit probably only
rarely on the practical level - more likely to issue in-
correct error messages, in the sense that their capa-
bilities of detecting an erroneous sentence are cxactly
the same as on the full-fledged approach, but their
capabilities of detecting what kind of error occurred
in the sentence are slightly reduced. For example, in
(the Czech equivalent of) the sentence
*Your wife drives very drives fast
a grammar-checker based solely on the full-fledged
philosophy would correctly recognize that the same
verb is repeated twice, while a checker using only fi-
nite state automaton detecting the presence/absence
of a comma or a coordinating conjunction between
two finite verbs issues a message concerning exactly
the &apos;missing connna&apos; - and similar examples can be
constructed also for all the other cases. In other
words, there is a price to be paid for the speed-up
of the error-checking process by means of the tech-
niques proposed.
</bodyText>
<sectionHeader confidence="0.998782" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.952362625">
Holm, T., V. Kubon, and M. Platek. 1997. A pro-
totype of a grammar checker for Czech. In this
volume.
Rodriguez Selles, Y., M.R. Galvez, and K. Oliva.
19.96. Error detection techniques in grammar-
checking. Technical report of the PECO2824 pro-
ject, Autonomous University of Barcelona. and
University of Saarland.
</reference>
<page confidence="0.99742">
158
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.115489">
<title confidence="0.997152">Techniques for Accelerating a Grammar-Checker</title>
<author confidence="0.999933">Karel Oliva</author>
<affiliation confidence="0.9991285">Computational Linguistics University of Saarland</affiliation>
<address confidence="0.607506333333333">Postfach 15 11 50 D - 66 041 Saarbriicken Germany</address>
<email confidence="0.996737">olivacoli</email>
<abstract confidence="0.924071818181818">The paper describes several possibilities of using finite-state automata as means for speeding up the performance of a grammarand-parsing-based (as opposed to patternmatching-based) grammar-checker able to detect errors from a predefined set. The ideas contained have been successfully implemented in a grammar-checker for Czech, a free-word-order language from the Slavic group.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Holm</author>
<author>V Kubon</author>
<author>M Platek</author>
</authors>
<title>A prototype of a grammar checker for Czech. In this volume.</title>
<date>1997</date>
<marker>Holm, Kubon, Platek, 1997</marker>
<rawString>Holm, T., V. Kubon, and M. Platek. 1997. A prototype of a grammar checker for Czech. In this volume.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodriguez Selles</author>
<author>M R Galvez Y</author>
<author>K Oliva</author>
</authors>
<title>Error detection techniques in grammarchecking.</title>
<date></date>
<institution>Autonomous University of Barcelona. and University of Saarland.</institution>
<note>Technical report of the PECO2824 project,</note>
<marker>Selles, Y, Oliva, </marker>
<rawString>Rodriguez Selles, Y., M.R. Galvez, and K. Oliva. 19.96. Error detection techniques in grammarchecking. Technical report of the PECO2824 project, Autonomous University of Barcelona. and University of Saarland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>