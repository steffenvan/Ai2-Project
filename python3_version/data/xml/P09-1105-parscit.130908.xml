<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000819">
<title confidence="0.987271">
Confidence Measure for Word Alignment
</title>
<author confidence="0.99677">
Fei Huang
</author>
<affiliation confidence="0.995967">
IBM T.J.Watson Research Center
</affiliation>
<address confidence="0.588937">
Yorktown Heights, NY 10598, USA
</address>
<email confidence="0.995194">
huangfe@us.ibm.com
</email>
<sectionHeader confidence="0.994746" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999629111111111">
In this paper we present a confidence mea-
sure for word alignment based on the
posterior probability of alignment links.
We introduce sentence alignment confi-
dence measure and alignment link con-
fidence measure. Based on these mea-
sures, we improve the alignment qual-
ity by selecting high confidence sentence
alignments and alignment links from mul-
tiple word alignments of the same sen-
tence pair. Additionally, we remove
low confidence alignment links from the
word alignment of a bilingual training
corpus, which increases the alignment
F-score, improves Chinese-English and
Arabic-English translation quality and sig-
nificantly reduces the phrase translation
table size.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998815294117647">
Data-driven approaches have been quite active in
recent machine translation (MT) research. Many
MT systems, such as statistical phrase-based and
syntax-based systems, learn phrase translation
pairs or translation rules from large amount of
bilingual data with word alignment. The qual-
ity of the parallel data and the word alignment
have significant impacts on the learned transla-
tion models and ultimately the quality of transla-
tion output. Due to the high cost of commissioned
translation, many parallel sentences are automat-
ically extracted from comparable corpora, which
inevitably introduce many ”noises”, i.e., inaccu-
rate or non-literal translations. Given the huge
amount of bilingual training data, word alignments
are automatically generated using various algo-
rithms ((Brown et al., 1994), (Vogel et al., 1996)
</bodyText>
<figureCaption confidence="0.964182">
Figure 1: An example of inaccurate translation
and word alignment.
</figureCaption>
<bodyText confidence="0.998438038461539">
and (Ittycheriah and Roukos, 2005)), which also
introduce many word alignment errors.
The example in Figure 1 shows the word align-
ment of the given Chinese and English sentence
pair, where the English words following each Chi-
nese word is its literal translation. We find untrans-
lated Chinese and English words (marked with
underlines). These spurious words cause signifi-
cant word alignment errors (as shown with dash
lines), which in turn directly affect the quality of
phrase translation tables or translation rules that
are learned based on word alignment.
In this paper we introduce a confidence mea-
sure for word alignment, which is robust to extra
or missing words in the bilingual sentence pairs,
as well as word alignment errors. We propose
a sentence alignment confidence measure based
on the alignment’s posterior probability, and ex-
tend it to the alignment link confidence measure.
We illustrate the correlation between the align-
ment confidence measure and the alignment qual-
ity on the sentence level, and present several ap-
proaches to improve alignment accuracy based on
the proposed confidence measure: sentence align-
ment selection, alignment link combination and
alignment link filtering. Finally we demonstrate
</bodyText>
<page confidence="0.930397">
932
</page>
<note confidence="0.9996145">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 932–940,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999641454545454">
the improved alignments also lead to better MT
quality.
The paper is organized as follows: In section
2 we introduce the sentence and alignment link
confidence measures. In section 3 we demon-
strate two approaches to improve alignment accu-
racy through alignment combination. In section 4
we show how to improve a MaxEnt word align-
ment quality by removing low confidence align-
ment links, which also leads to improved transla-
tion quality as shown in section 5.
</bodyText>
<sectionHeader confidence="0.9954165" genericHeader="introduction">
2 Sentence Alignment Confidence
Measure
</sectionHeader>
<subsectionHeader confidence="0.986977">
2.1 Definition
</subsectionHeader>
<bodyText confidence="0.999312285714286">
Given a bilingual sentence pair (S,T) where
S={s1,..., sI} is the source sentence and T={t1,
...,tJ} is the target sentence. Let A = {aij} be
the alignment between S and T. The alignment
confidence measure C(A|S, T) is defined as the
geometric mean of the alignment posterior proba-
bilities calculated in both directions:
</bodyText>
<equation confidence="0.964564142857143">
p
C(A|S,T) = Ps2t(A|S,T)Pt2s(A|T,S), (1)
where
P(A, T |S)
Ps2t(A|S, T) = (2)
PA&apos; P(A&apos;, T|
S)
</equation>
<bodyText confidence="0.99970625">
When computing the source-to-target alignment
posterior probability, the numerator is the sentence
translation probability calculated according to the
given alignment A:
</bodyText>
<equation confidence="0.985636">
P(A, T |S) = YJ p(tj|si, aij E A). (3)
j=1
</equation>
<bodyText confidence="0.9988596">
It is the product of lexical translation probabili-
ties for the aligned word pairs. For unaligned tar-
get word tj, consider si = NULL. The source-to-
target lexical translation model p(t|s) and target-
to-source model p(s|t) can be obtained through
IBM Model-1 or HMM training. The denomina-
tor is the sentence translation probability summing
over all possible alignments, which can be calcu-
lated similar to IBM Model 1 in (Brown et al.,
1994):
</bodyText>
<equation confidence="0.573303">
p(tj|si). (4)
</equation>
<table confidence="0.999631">
Aligner F-score Cor. Coeff.
HMM 54.72 -0.710
BM 62.53 -0.699
MaxEnt 69.26 -0.699
</table>
<tableCaption confidence="0.885777">
Table 1: Correlation coefficients of multiple align-
ments.
</tableCaption>
<bodyText confidence="0.976458363636364">
Note that here only the word-based lexicon
model is used to compute the confidence measure.
More complex models such as alignment models,
fertility models and distortion models as described
in (Brown et al., 1994) could estimate the proba-
bility of a given alignment more accurately. How-
ever the summation over all possible alignments is
very complicated, even intractable, with the richer
models. For the efficient computation of the de-
nominator, we use the lexical translation model.
Similarly,
</bodyText>
<equation confidence="0.978699">
P (A, S|T )
Pt2s(A|T, S) = P A&apos; P (A&apos;, S|T ), (5)
and
P(A, S|T) = YI p(si|tj,aij E A). (6)
i=1
p(si|tj). (7)
</equation>
<bodyText confidence="0.999648117647059">
We randomly selected 512 Chinese-English (C-
E) sentence pairs and generated word alignment
using the MaxEnt aligner (Ittycheriah and Roukos,
2005). We evaluate per sentence alignment F-
scores by comparing the system output with a
reference alignment. For each sentence pair, we
also calculate the sentence alignment confidence
score −log C(A|S, T). We compute the corre-
lation coefficients between the alignment confi-
dence measure and the alignment F-scores. The
results in Figure 2 shows strong correlation be-
tween the confidence measure and the alignment
F-score, with the correlation coefficients equals to
-0.69. Such strong correlation is also observed on
an HMM alignment (Ge, 2004) and a Block Model
(BM) alignment (Zhao et al., 2005) with varying
alignment accuracies, as seen in Table1.
</bodyText>
<subsectionHeader confidence="0.99801">
2.2 Sentence Alignment Selection Based on
Confidence Measure
</subsectionHeader>
<bodyText confidence="0.9995005">
The strong correlation between the sentence align-
ment confidence measure and the alignment F-
</bodyText>
<equation confidence="0.986954583333333">
X P(A&apos;, T |S) =
A&apos;
YJ
j=1
XI
i=1
X P(A&apos;, S|T) =
A&apos;
YI
i=1
XJ
j=1
</equation>
<page confidence="0.996482">
933
</page>
<figureCaption confidence="0.9942165">
Figure 2: Correlation between sentence alignment
confidence measure and F-score.
</figureCaption>
<bodyText confidence="0.999565647058824">
measure suggests the possibility of selecting the
alignment with the highest confidence score to ob-
tain better alignments. For each sentence pair in
the C-E test set, we calculate the confidence scores
of the HMM alignment, the Block Model align-
ment and the MaxEnt alignment, then select the
alignment with the highest confidence score. As a
result, 82% of selected alignments have higher F-
scores, and the F-measure of the combined align-
ments is increased over the best aligner (the Max-
Ent aligner) by 0.8. This relatively small improve-
ment is mainly due to the selection of the whole
sentence alignment: for many sentences the best
alignment still contains alignment errors, some of
which could be fixed by other aligners. Therefore,
it is desirable to combine alignment links from dif-
ferent alignments.
</bodyText>
<sectionHeader confidence="0.964062" genericHeader="method">
3 Alignment Link Confidence Measure
</sectionHeader>
<subsectionHeader confidence="0.990462">
3.1 Definition
</subsectionHeader>
<bodyText confidence="0.999716333333333">
Similar to the sentence alignment confidence mea-
sure, the confidence of an alignment link aij in the
sentence pair (S, T) is defined as
</bodyText>
<equation confidence="0.978745">
�c(aij|S, T) = qs2t(aij|S, T )qt2s(aij|T, S)
(8)
</equation>
<bodyText confidence="0.9987595">
where the source-to-target link posterior probabil-
ity
</bodyText>
<equation confidence="0.983004">
qs2t (aij  |S, T) = p(tj  |si) (9)
Ej0=1 p(tj0|si)
</equation>
<bodyText confidence="0.999778333333333">
which is defined as the word translation probabil-
ity of the aligned word pair divided by the sum
of the translation probabilities over all the target
words in the sentence. The higher p(tj|si) is,
the higher confidence the link has. Similarly, the
target-to-source link posterior probability is de-
</bodyText>
<equation confidence="0.912877">
fined as:
qt2s(aij|T, S) = Ip(si|tj) (10)
Ei0=1 p(si0|tj)
</equation>
<bodyText confidence="0.756381166666667">
Intuitively, the above link confidence definition
compares the lexical translation probability of the
aligned word pair with the translation probabilities
of all the target words given the source word. If a
word t occurs N times in the target sentence, for
any i E 11, ..., I},
</bodyText>
<equation confidence="0.984553285714285">
J
� p(tj0|si) ? Np(t|si),
j0=1
thus for any tj = t,
1
qs2t(aij) :5
N .
</equation>
<bodyText confidence="0.999871454545454">
This indicates that the confidence score of any
link connecting tj to any source word is at most
1/N. On the one hand this is expected because
multiple occurrences of the same word does in-
crease the confusion for word alignment and re-
duce the link confidence. On the other hand, ad-
ditional information (such as the distance of the
word pair, the alignment of neighbor words) could
indicate higher likelihood for the alignment link.
We will introduce a context-dependent link confi-
dence measure in section 4.
</bodyText>
<subsectionHeader confidence="0.999775">
3.2 Alignment Link Selection
</subsectionHeader>
<bodyText confidence="0.9985358">
From multiple alignments of the same sentence
pair, we select high confidence links from different
alignments based on their link confidence scores
and alignment agreement ratio.
Typically, links appearing in multiple align-
ments are more likely correct alignments. The
alignment agreement ratio measures the popular-
ity of a link. Suppose the sentence pair (S, T) have
alignments A1,... , AD, the agreement ratio of a
link aij is defined as
</bodyText>
<equation confidence="0.990591">
r (aij  |S, T) = Ed C(Ad|S,T : aij E Ad), (11)
Ed0 C(Ad0 |S, T)
</equation>
<bodyText confidence="0.999914">
where C(A) is the confidence score of the align-
ment A as defined in formula 1. This formula
computes the sum of the alignment confidence
scores for the alignments containing aij, which is
</bodyText>
<page confidence="0.996888">
934
</page>
<figureCaption confidence="0.999856">
Figure 3: Example of alignment link selection by combining MaxEnt, HMM and BM alignments.
</figureCaption>
<bodyText confidence="0.99434525">
normalized by the sum of all alignments’ confi-
dence scores.
We collect all the links from all the alignments.
For each link we calculate the link confidence
score c(aij) and the alignment agreement ratio
r(aij). We link the word pair (si, tj) if either
c(aij) &gt; hi or r(aij) &gt; ri, where hi and ri are
empirically chosen thresholds.
We combine the HMM alignment, the BM
alignment and the MaxEnt alignment (ME) us-
ing the above link selection algorithm. Figure
3 shows such an example, where alignment er-
rors in the MaxEnt alignment are shown with dot-
ted lines. As some of the links are correctly
aligned in the HMM and BM alignments (shown
with solid lines), the combined alignment corrects
some alignment errors while still contains com-
mon incorrect alignment links.
Table 2 shows the precision, recall and F-score
of individual alignments and the combined align-
ment. F-content and F-function are the F-scores
for content words and function words, respec-
tively. The link selection algorithm improves
the recall over the best aligner (the ME align-
ment) by 7 points (from 65.4 to 72.5) while de-
creasing the precision by 4.4 points (from 73.6
to 69.2). Overall it improves the F-score by 1.5
points (from 69.3 to 70.8), 1.8 point improvement
for content words and 1.0 point for function words.
It also significantly outperforms the traditionally
used heuristics, ”intersection-union-refine” (Och
and Ney, 2003) by 6 points.
</bodyText>
<sectionHeader confidence="0.7826445" genericHeader="method">
4 Improved MaxEnt Aligner with
Confidence-based Link Filtering
</sectionHeader>
<bodyText confidence="0.99845475">
In addition to the alignment combination, we also
improve the performance of the MaxEnt aligner
through confidence-based alignment link filtering.
Here we select the MaxEnt aligner because it has
</bodyText>
<page confidence="0.986846">
935
</page>
<table confidence="0.999987333333333">
Precision Recall F-score F-content F-function
HMM 62.65 48.57 54.72 62.10 34.39
BM 72.76 54.82 62.53 68.64 43.93
ME 72.66 66.17 69.26 72.52 61.41
Link-Select 69.19 72.49 70.81 74.31 60.26
Intersection-Union-Refine 63.34 66.07 64.68 70.15 49.72
</table>
<tableCaption confidence="0.995315">
Table 2: Link Selection and Combination Results
</tableCaption>
<bodyText confidence="0.99674405">
the highest F-measure among the three aligners,
although the algorithm described below can be ap-
plied to any aligner.
It is often observed that words within a con-
stituent (such as NP, PP) are typically translated
together, and their alignments are close. As a re-
sult the confidence measure of an alignment link
aij can be boosted given the alignment of its con-
text words. From the initial sentence alignment
we first identify an anchor link amn, the high con-
fidence alignment link closest to aij. The an-
chor link is considered as the most reliable con-
nection between the source and target context.
The context is then defined as a window center-
ing at amn with window width proportional to
the distance between aij and amn. When com-
puting the context-dependent link confidence, we
only consider words within the context window.
The context-dependent alignment link confidence
is calculated in the following steps:
</bodyText>
<listItem confidence="0.998195777777778">
1. Calculate the context-independent link con-
fidence measure c(aij) according to formula
(8).
2. Sort all links based on their link confidence
measures in decreasing order.
3. Select links whose confidence scores are
higher than an empirically chosen threshold
H as anchor links 1.
4. Walking along the remaining sorted links.
</listItem>
<figure confidence="0.538865">
For each link {aij : c(aij) &lt; H},
(a) Find the closest anchor link amn2,
(b) Define the context window width w =
|m − i |+ |n − j|.
</figure>
<footnote confidence="0.9964436">
1H is selected to maximize the F-score on an alignment
devset.
2When two equally close alignment links have the same
confidence score), we randomly select one of the tied links as
the anchor link.
</footnote>
<listItem confidence="0.954735">
(c) Compute the link posterior probabilities
within the context window:
</listItem>
<equation confidence="0.9950598">
qs2t(aij|amn) = j+w
�j&apos;=j−w p(tj&apos; |si
qt2s(aij|amn) = �i+w �
i&apos;=i−w p(si&apos;|tj)
p(si|tj)
</equation>
<listItem confidence="0.872027857142857">
(d) Compute the context-dependent link
confidence score c(aij|amn) =
�qs2t(aij|amn)qt2s(aij|amn)-
If c(aij|amn) &gt; H, add aij into the set
of anchor links.
5. Only keep anchor links and remove all the re-
maining links with low confidence scores.
</listItem>
<bodyText confidence="0.996777666666667">
The above link filtering algorithm is designed to
remove incorrect links. Furthermore, it is possible
to create new links by relinking unaligned source
and target word pairs within the context window if
their context-dependent link posterior probability
is high.
Figure 4 shows context-independent link con-
fidence scores for the given sentence alignment.
The subscript following each word indicates the
word’s position. Incorrect alignment links are
shown with dashed lines, which have low confi-
dence scores (a5,7, a7,3, a8,2, a11,9) and will be
removed through filtering. When the anchor link
a4,11 is selected, the context-dependent link confi-
dence of a6,12 is increased from 0.12 to 0.51. Also
note that a new link a7,12 (shown as a dotted line)
is created because within the context window, the
link confidence score is as high as 0.96. This ex-
ample shows that the context-dependent link filter-
ing not only removes incorrect links, but also cre-
ate new links based on updated confidence scores.
We applied the confidence-based link filter-
ing on Chinese-English and Arabic-English word
alignment. The C-E alignment test set is the same
</bodyText>
<figure confidence="0.640729333333333">
p(tj|si)
�
)
</figure>
<page confidence="0.925429">
936
</page>
<figureCaption confidence="0.997195">
Figure 4: Alignment link filtering based on context-independent link confidence.
</figureCaption>
<table confidence="0.999745333333333">
Precision Recall F-score
Baseline 72.66 66.17 69.26
+ALF 78.14 64.36 70.59
</table>
<tableCaption confidence="0.9714875">
Table 3: Confidence-based Alignment Link Filter-
ing on C-E Alignment
</tableCaption>
<table confidence="0.999861">
Precision Recall F-score
Baseline 84.43 83.64 84.04
+ALF 88.29 83.14 85.64
</table>
<tableCaption confidence="0.9676035">
Table 4: Confidence-based Alignment Link Filter-
ing on A-E Alignment
</tableCaption>
<bodyText confidence="0.99584505">
512 sentence pairs, and the A-E alignment test
set is the 200 Arabic-English sentence pairs from
NIST MT03 test set.
Tables 3 and 4 show the improvement of
C-E and A-E alignment F-measures with the
confidence-based alignment link filtering (ALF).
For C-E alignment, removing low confidence
alignment links increased alignment precision by
5.5 point, while decreased recall by 1.8 point, and
the overall alignment F-measure is increased by
1.3 point. When looking into the alignment links
which are removed during the alignment link fil-
tering process, we found that 80% of the removed
links (1320 out of 1661 links) are incorrect align-
ments, For A-E alignment, it increased the pre-
cision by 3 points while reducing recall by 0.5
points, and the alignment F-measure is increased
by about 1.5 points absolute, a 10% relative align-
ment error rate reduction. Similarly, 90% of the
removed links are incorrect alignments.
</bodyText>
<sectionHeader confidence="0.99861" genericHeader="method">
5 Translation
</sectionHeader>
<bodyText confidence="0.999968431818182">
We evaluate the improved alignment on sev-
eral Chinese-English and Arabic-English machine
translation tasks. The documents to be trans-
lated are from difference genres: newswire (NW)
and web-blog (WB). The MT system is a phrase-
based SMT system as described in (Al-Onaizan
and Papineni, 2006). The training data are bilin-
gual sentence pairs with word alignment, from
which we obtained phrase translation pairs. We
extract phrase translation tables from the baseline
MaxEnt word alignment as well as the alignment
with confidence-based link filtering, then trans-
late the test set with each phrase translation ta-
ble. We measure the translation quality with au-
tomatic metrics including BLEU (Papineni et al.,
2001) and TER (Snover et al., 2006). The higher
the BLEU score is, or the lower the TER score
is, the better the translation quality is. We com-
bine the two metrics into (TER-BLEU)/2 and try
to minimize it. In addition to the whole test set’s
scores, we also measure the scores of the ”tail”
documents, whose (TER-BLEU)/2 scores are at
the bottom 10 percentile (for A-E translation) and
20 percentile (for C-E translation) and are consid-
ered the most difficult documents to translate.
In the Chinese-English MT experiment, we se-
lected 40 NW documents, 41 WB documents as
the test set, which includes 623 sentences with
16667 words. The training data includes 333 thou-
sand C-E sentence pairs subsampled from 10 mil-
lion sentence pairs according to the test data. Ta-
bles 5 and 6 show the newswire and web-blog
translation scores as well as the number of phrase
translation pairs obtained from each alignment.
Because the alignment link filtering removes many
incorrect alignment links, the number of phrase
translation pairs is reduced by 15%. For newswire,
the translation quality is improved by 0.44 on the
whole test set and 1.1 on the tail documents, as
measured by (TER-BLEU)/2. For web-blog, we
observed 0.2 improvement on the whole test set
and 0.5 on the tail documents. The tail documents
typically have lower phrase coverage, thus incor-
rect phrase translation pairs derived from incorrect
</bodyText>
<page confidence="0.991588">
937
</page>
<table confidence="0.9996995">
# phrase pairs Average Tail
TER BLEU (TER-BLEU)/2 TER BLEU (TER-BLEU)/2
Baseline 934206 60.74 28.05 16.35 69.02 17.83 25.60
ALF 797685 60.33 28.52 15.91 68.31 19.27 24.52
</table>
<tableCaption confidence="0.957079">
Table 5: Improved Chinese-English Newswire Translation with Alignment Link Filtering
</tableCaption>
<table confidence="0.99993375">
# phrase pairs Average Tail
TER BLEU (TER-BLEU)/2 TER BLEU (TER-BLEU)/2
Baseline 934206 62.87 25.08 18.89 66.55 18.80 23.88
ALF 797685 62.30 24.89 18.70 65.97 19.25 23.36
</table>
<tableCaption confidence="0.999051">
Table 6: Improved Chinese-English Web-Blog Translation with Alignment Link Filtering
</tableCaption>
<bodyText confidence="0.999763375">
alignment links are more likely to be selected. The
removal of incorrect alignment links and cleaner
phrase translation pairs brought more gains on the
tail documents.
In the Arabic-English MT, we selected 80 NW
documents and 55 WB documents. The NW train-
ing data includes 319 thousand A-E sentence pairs
subsampled from 7.2 million sentence pairs with
word alignments. The WB training data includes
240 thousand subsampled sentence pairs. Tables 7
and 8 show the corresponding translation results.
Similarly, the phrase table size is significantly re-
duced by 35%, while the gains on the tail docu-
ments range from 0.6 to 1.4. On the whole test
set the difference is smaller, 0.07 for the newswire
translation and 0.58 for the web-blog translation.
</bodyText>
<sectionHeader confidence="0.999863" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.9999904">
In the machine translation area, most research on
confidence measure focus on the confidence of
MT output: how accurate a translated sentence is.
(Gandrabur and Foster, 2003) used neural-net to
improve the confidence estimate for text predic-
tions in a machine-assisted translation tool. (Ueff-
ing et al., 2003) presented several word-level con-
fidence measures for machine translation based on
word posterior probabilities. (Blatz et al., 2004)
conducted extensive study incorporating various
sentence-level and word-level features thru multi-
layer perceptron and naive Bayes algorithms for
sentence and word confidence estimation. (Quirk,
2004) trained a sentence level confidence mea-
sure using a human annotated corpus. (Bach et
al., 2008) used the sentence-pair confidence scores
estimated with source and target language mod-
els to weight phrase translation pairs. However,
there has been little research focusing on confi-
dence measure for word alignment. This work
is the first attempt to address the alignment con-
fidence problem.
Regarding word alignment combination, in ad-
dition to the commonly used ”intersection-union-
refine” approach (Och and Ney, 2003), (Ayan
and Dorr, 2006b) and (Ayan et al., 2005) com-
bined alignment links from multiple word align-
ment based on a set of linguistic and alignment
features within the MaxEnt framework or a neural
net model. While in this paper, the alignment links
are combined based on their confidence scores and
alignment agreement ratios.
(Fraser and Marcu, 2007) discussed the impact
of word alignment’s precision and recall on MT
quality. Here removing low confidence links re-
sults in higher precision and slightly lower recall
for the alignment. In our phrase extraction, we
allow extracting phrase translation pairs with un-
aligned functional words at the boundary. This is
similar to the ”loose phrases” described in (Ayan
and Dorr, 2006a), which increased the number of
correct phrase translations and improved the trans-
lation quality. On the other hand, removing incor-
rect content word links produced cleaner phrase
translation tables. When translating documents
with lower phrase coverage (typically the “tail”
documents), high quality phrase translations are
particularly important because a bad phrase trans-
lation can be picked up more easily due to limited
phrase translation pairs available.
</bodyText>
<sectionHeader confidence="0.998781" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.99682">
In this paper we presented two alignment confi-
dence measures for word alignment. The first is
the sentence alignment confidence measure, based
on which the best whole sentence alignment is se-
</bodyText>
<page confidence="0.992073">
938
</page>
<table confidence="0.99962025">
# phrase pairs Average Tail
TER BLEU (TER-BLEU)/2 TER BLEU (TER-BLEU)/2
Baseline 939911 43.53 50.51 -3.49 53.14 40.60 6.27
ALF 618179 43.11 50.24 -3.56 51.75 42.05 4.85
</table>
<tableCaption confidence="0.953895">
Table 7: Improved Arabic-English Newswire Translation with Alignment Link Filtering
</tableCaption>
<table confidence="0.99991975">
# phrase pairs Average Tail
TER BLEU (TER-BLEU)/2 TER BLEU (TER-BLEU)/2
Baseline 598721 49.91 39.90 5.00 57.30 30.98 13.16
ALF 383561 48.94 40.00 4.42 55.99 31.92 12.04
</table>
<tableCaption confidence="0.99957">
Table 8: Improved Arabic-English Web-Blog Translation with Alignment Link Filtering
</tableCaption>
<bodyText confidence="0.999847">
lected among multiple alignments and it obtained
0.8 F-measure improvement over the single best
Chinese-English aligner. The second is the align-
ment link confidence measure, which selects the
most reliable links from multiple alignments and
obtained 1.5 F-measure improvement. When we
removed low confidence links from the MaxEnt
aligner, we reduced the Chinese-English align-
ment error by 5% and the Arabic-English align-
ment error by 10%. The cleaned alignment sig-
nificantly reduced the size of phrase translation ta-
bles by 15-35%. It furthermore led to better trans-
lation scores for Chinese and Arabic documents
with different genres. In particular, it improved the
translation scores of the tail documents by 0.5-1.4
points measured by the combined metric of (TER-
BLEU)/2.
For future work we would like to explore richer
models to estimate alignment posterior probabil-
ity. In most cases, exact calculation by summing
over all possible alignments is impossible, and ap-
proximation using N-best alignments is needed.
</bodyText>
<sectionHeader confidence="0.996979" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9990232">
We are grateful to Abraham Ittycheriah, Yaser Al-
Onaizan, Niyu Ge and Salim Roukos and anony-
mous reviewers for their constructive comments.
This work was supported in part by the DARPA
GALE project, contract No. HR0011-08-C-0110.
</bodyText>
<sectionHeader confidence="0.998083" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998372291666667">
Yaser Al-Onaizan and Kishore Papineni. 2006. Distor-
tion Models for Statistical Machine Translation. In
Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 529–536, Sydney, Australia, July. Asso-
ciation for Computational Linguistics.
Necip Fazil Ayan and Bonnie J. Dorr. 2006a. Going
beyond aer: An extensive analysis of word align-
ments and their impact on mt. In Proceedings of
the 21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 9–16,
Sydney, Australia, July. Association for Computa-
tional Linguistics.
Necip Fazil Ayan and Bonnie J. Dorr. 2006b. A max-
imum entropy approach to combining word align-
ments. In Proceedings of the Human Language
Technology Conference of the NAACL, Main Con-
ference, pages 96–103, New York City, USA, June.
Association for Computational Linguistics.
Necip Fazil Ayan, Bonnie J. Dorr, and Christof Monz.
2005. Neuralign: Combining word alignments us-
ing neural networks. In Proceedings of Human
Language Technology Conference and Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 65–72, Vancouver, British Columbia,
Canada, October. Association for Computational
Linguistics.
Nguyen Bach, Qin Gao, and Stephan Vogel. 2008. Im-
proving word alignment with language model based
confidence scores. In Proceedings of the Third
Workshop on Statistical Machine Translation, pages
151–154, Columbus, Ohio, June. Association for
Computational Linguistics.
John Blatz, Erin Fitzgerald, George Foster, Simona
Gandrabur, Cyril Goutte, Alex Kulesza, Alberto
Sanchis, and Nicola Ueffing. 2004. Confidence es-
timation for machine translation. In COLING ’04:
Proceedings of the 20th international conference on
Computational Linguistics, page 315, Morristown,
NJ, USA. Association for Computational Linguis-
tics.
Peter F. Brown, Stephen Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1994. The Mathe-
matic of Statistical Machine Translation: Parameter
Estimation. Computational Linguistics, 19(2):263–
311.
</reference>
<page confidence="0.986312">
939
</page>
<reference confidence="0.999837709090909">
Alexander Fraser and Daniel Marcu. 2007. Measuring
word alignment quality for statistical machine trans-
lation. Comput. Linguist., 33(3):293–303.
Simona Gandrabur and George Foster. 2003. Confi-
dence estimation for translation prediction. In Pro-
ceedings of the seventh conference on Natural lan-
guage learning at HLT-NAACL 2003, pages 95–102,
Morristown, NJ, USA. Association for Computa-
tional Linguistics.
Niyu Ge. 2004. Max-posterior hmm alignment
for machine translation. In Presentation given at
DARPA/TIDES NIST MT Evaluation workshop.
Abraham Ittycheriah and Salim Roukos. 2005. A
maximum entropy word aligner for arabic-english
machine translation. In HLT ’05: Proceedings of
the conference on Human Language Technology and
Empirical Methods in Natural Language Process-
ing, pages 89–96, Morristown, NJ, USA. Associa-
tion for Computational Linguistics.
Franz J. Och and Hermann Ney. 2003. A systematic
comparison of various statistical alignment models.
Comput. Linguist., 29(1):19–51, March.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. BLEU: a Method for Automatic
Evaluation of Machine Translation. In ACL ’02:
Proceedings of the 40th Annual Meeting on Asso-
ciation for Computational Linguistics, pages 311–
318, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
Chris Quirk. 2004. Training a sentence-level machine
translation confidence measure. In In Proc. LREC
2004, pages 825–828, Lisbon, Portual. Springer-
Verlag.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study
of Translation Edit Rate with Targeted Human An-
notation. In Proceedings ofAssociation for Machine
Translation in the Americas.
Nicola Ueffing, Klaus Macherey, and Hermann Ney.
2003. Confidence measures for statistical machine
translation. In In Proc. MT Summit IX, pages 394–
401. Springer-Verlag.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. Hmm-based word alignment in statistical
translation. In Proceedings of the 16th conference
on Computational linguistics, pages 836–841, Mor-
ristown, NJ, USA. Association for Computational
Linguistics.
Bing Zhao, Niyu Ge, and Kishore Papineni. 2005.
Inner-outer bracket models for word alignment us-
ing hidden blocks. In HLT ’05: Proceedings of
the conference on Human Language Technology and
Empirical Methods in Natural Language Process-
ing, pages 177–184, Morristown, NJ, USA. Asso-
ciation for Computational Linguistics.
</reference>
<page confidence="0.997776">
940
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.983392">
<title confidence="0.999866">Confidence Measure for Word Alignment</title>
<author confidence="0.999752">Fei Huang</author>
<affiliation confidence="0.999981">IBM T.J.Watson Research Center</affiliation>
<address confidence="0.993015">Yorktown Heights, NY 10598, USA</address>
<email confidence="0.999706">huangfe@us.ibm.com</email>
<abstract confidence="0.999513526315789">In this paper we present a confidence measure for word alignment based on the posterior probability of alignment links. We introduce sentence alignment confidence measure and alignment link confidence measure. Based on these measures, we improve the alignment quality by selecting high confidence sentence alignments and alignment links from multiple word alignments of the same sentence pair. Additionally, we remove low confidence alignment links from the word alignment of a bilingual training corpus, which increases the alignment F-score, improves Chinese-English and Arabic-English translation quality and significantly reduces the phrase translation table size.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Kishore Papineni</author>
</authors>
<title>Distortion Models for Statistical Machine Translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>529--536</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="16382" citStr="Al-Onaizan and Papineni, 2006" startWordPosition="2634" endWordPosition="2637"> (1320 out of 1661 links) are incorrect alignments, For A-E alignment, it increased the precision by 3 points while reducing recall by 0.5 points, and the alignment F-measure is increased by about 1.5 points absolute, a 10% relative alignment error rate reduction. Similarly, 90% of the removed links are incorrect alignments. 5 Translation We evaluate the improved alignment on several Chinese-English and Arabic-English machine translation tasks. The documents to be translated are from difference genres: newswire (NW) and web-blog (WB). The MT system is a phrasebased SMT system as described in (Al-Onaizan and Papineni, 2006). The training data are bilingual sentence pairs with word alignment, from which we obtained phrase translation pairs. We extract phrase translation tables from the baseline MaxEnt word alignment as well as the alignment with confidence-based link filtering, then translate the test set with each phrase translation table. We measure the translation quality with automatic metrics including BLEU (Papineni et al., 2001) and TER (Snover et al., 2006). The higher the BLEU score is, or the lower the TER score is, the better the translation quality is. We combine the two metrics into (TER-BLEU)/2 and </context>
</contexts>
<marker>Al-Onaizan, Papineni, 2006</marker>
<rawString>Yaser Al-Onaizan and Kishore Papineni. 2006. Distortion Models for Statistical Machine Translation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 529–536, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Necip Fazil Ayan</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Going beyond aer: An extensive analysis of word alignments and their impact on mt.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>9--16</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="20650" citStr="Ayan and Dorr, 2006" startWordPosition="3306" endWordPosition="3309">naive Bayes algorithms for sentence and word confidence estimation. (Quirk, 2004) trained a sentence level confidence measure using a human annotated corpus. (Bach et al., 2008) used the sentence-pair confidence scores estimated with source and target language models to weight phrase translation pairs. However, there has been little research focusing on confidence measure for word alignment. This work is the first attempt to address the alignment confidence problem. Regarding word alignment combination, in addition to the commonly used ”intersection-unionrefine” approach (Och and Ney, 2003), (Ayan and Dorr, 2006b) and (Ayan et al., 2005) combined alignment links from multiple word alignment based on a set of linguistic and alignment features within the MaxEnt framework or a neural net model. While in this paper, the alignment links are combined based on their confidence scores and alignment agreement ratios. (Fraser and Marcu, 2007) discussed the impact of word alignment’s precision and recall on MT quality. Here removing low confidence links results in higher precision and slightly lower recall for the alignment. In our phrase extraction, we allow extracting phrase translation pairs with unaligned f</context>
</contexts>
<marker>Ayan, Dorr, 2006</marker>
<rawString>Necip Fazil Ayan and Bonnie J. Dorr. 2006a. Going beyond aer: An extensive analysis of word alignments and their impact on mt. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 9–16, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Necip Fazil Ayan</author>
<author>Bonnie J Dorr</author>
</authors>
<title>A maximum entropy approach to combining word alignments.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,</booktitle>
<pages>96--103</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City, USA,</location>
<contexts>
<context position="20650" citStr="Ayan and Dorr, 2006" startWordPosition="3306" endWordPosition="3309">naive Bayes algorithms for sentence and word confidence estimation. (Quirk, 2004) trained a sentence level confidence measure using a human annotated corpus. (Bach et al., 2008) used the sentence-pair confidence scores estimated with source and target language models to weight phrase translation pairs. However, there has been little research focusing on confidence measure for word alignment. This work is the first attempt to address the alignment confidence problem. Regarding word alignment combination, in addition to the commonly used ”intersection-unionrefine” approach (Och and Ney, 2003), (Ayan and Dorr, 2006b) and (Ayan et al., 2005) combined alignment links from multiple word alignment based on a set of linguistic and alignment features within the MaxEnt framework or a neural net model. While in this paper, the alignment links are combined based on their confidence scores and alignment agreement ratios. (Fraser and Marcu, 2007) discussed the impact of word alignment’s precision and recall on MT quality. Here removing low confidence links results in higher precision and slightly lower recall for the alignment. In our phrase extraction, we allow extracting phrase translation pairs with unaligned f</context>
</contexts>
<marker>Ayan, Dorr, 2006</marker>
<rawString>Necip Fazil Ayan and Bonnie J. Dorr. 2006b. A maximum entropy approach to combining word alignments. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 96–103, New York City, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Necip Fazil Ayan</author>
<author>Bonnie J Dorr</author>
<author>Christof Monz</author>
</authors>
<title>Neuralign: Combining word alignments using neural networks.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>65--72</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Vancouver, British Columbia, Canada,</location>
<contexts>
<context position="20676" citStr="Ayan et al., 2005" startWordPosition="3311" endWordPosition="3314">sentence and word confidence estimation. (Quirk, 2004) trained a sentence level confidence measure using a human annotated corpus. (Bach et al., 2008) used the sentence-pair confidence scores estimated with source and target language models to weight phrase translation pairs. However, there has been little research focusing on confidence measure for word alignment. This work is the first attempt to address the alignment confidence problem. Regarding word alignment combination, in addition to the commonly used ”intersection-unionrefine” approach (Och and Ney, 2003), (Ayan and Dorr, 2006b) and (Ayan et al., 2005) combined alignment links from multiple word alignment based on a set of linguistic and alignment features within the MaxEnt framework or a neural net model. While in this paper, the alignment links are combined based on their confidence scores and alignment agreement ratios. (Fraser and Marcu, 2007) discussed the impact of word alignment’s precision and recall on MT quality. Here removing low confidence links results in higher precision and slightly lower recall for the alignment. In our phrase extraction, we allow extracting phrase translation pairs with unaligned functional words at the bou</context>
</contexts>
<marker>Ayan, Dorr, Monz, 2005</marker>
<rawString>Necip Fazil Ayan, Bonnie J. Dorr, and Christof Monz. 2005. Neuralign: Combining word alignments using neural networks. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 65–72, Vancouver, British Columbia, Canada, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nguyen Bach</author>
<author>Qin Gao</author>
<author>Stephan Vogel</author>
</authors>
<title>Improving word alignment with language model based confidence scores.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>151--154</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="20208" citStr="Bach et al., 2008" startWordPosition="3239" endWordPosition="3242">a translated sentence is. (Gandrabur and Foster, 2003) used neural-net to improve the confidence estimate for text predictions in a machine-assisted translation tool. (Ueffing et al., 2003) presented several word-level confidence measures for machine translation based on word posterior probabilities. (Blatz et al., 2004) conducted extensive study incorporating various sentence-level and word-level features thru multilayer perceptron and naive Bayes algorithms for sentence and word confidence estimation. (Quirk, 2004) trained a sentence level confidence measure using a human annotated corpus. (Bach et al., 2008) used the sentence-pair confidence scores estimated with source and target language models to weight phrase translation pairs. However, there has been little research focusing on confidence measure for word alignment. This work is the first attempt to address the alignment confidence problem. Regarding word alignment combination, in addition to the commonly used ”intersection-unionrefine” approach (Och and Ney, 2003), (Ayan and Dorr, 2006b) and (Ayan et al., 2005) combined alignment links from multiple word alignment based on a set of linguistic and alignment features within the MaxEnt framewo</context>
</contexts>
<marker>Bach, Gao, Vogel, 2008</marker>
<rawString>Nguyen Bach, Qin Gao, and Stephan Vogel. 2008. Improving word alignment with language model based confidence scores. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 151–154, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blatz</author>
<author>Erin Fitzgerald</author>
<author>George Foster</author>
<author>Simona Gandrabur</author>
<author>Cyril Goutte</author>
<author>Alex Kulesza</author>
<author>Alberto Sanchis</author>
<author>Nicola Ueffing</author>
</authors>
<title>Confidence estimation for machine translation.</title>
<date>2004</date>
<booktitle>In COLING ’04: Proceedings of the 20th international conference on Computational Linguistics,</booktitle>
<pages>315</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="19912" citStr="Blatz et al., 2004" startWordPosition="3198" endWordPosition="3201">e tail documents range from 0.6 to 1.4. On the whole test set the difference is smaller, 0.07 for the newswire translation and 0.58 for the web-blog translation. 6 Related Work In the machine translation area, most research on confidence measure focus on the confidence of MT output: how accurate a translated sentence is. (Gandrabur and Foster, 2003) used neural-net to improve the confidence estimate for text predictions in a machine-assisted translation tool. (Ueffing et al., 2003) presented several word-level confidence measures for machine translation based on word posterior probabilities. (Blatz et al., 2004) conducted extensive study incorporating various sentence-level and word-level features thru multilayer perceptron and naive Bayes algorithms for sentence and word confidence estimation. (Quirk, 2004) trained a sentence level confidence measure using a human annotated corpus. (Bach et al., 2008) used the sentence-pair confidence scores estimated with source and target language models to weight phrase translation pairs. However, there has been little research focusing on confidence measure for word alignment. This work is the first attempt to address the alignment confidence problem. Regarding </context>
</contexts>
<marker>Blatz, Fitzgerald, Foster, Gandrabur, Goutte, Kulesza, Sanchis, Ueffing, 2004</marker>
<rawString>John Blatz, Erin Fitzgerald, George Foster, Simona Gandrabur, Cyril Goutte, Alex Kulesza, Alberto Sanchis, and Nicola Ueffing. 2004. Confidence estimation for machine translation. In COLING ’04: Proceedings of the 20th international conference on Computational Linguistics, page 315, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The Mathematic of Statistical Machine Translation: Parameter Estimation.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>311</pages>
<contexts>
<context position="1619" citStr="Brown et al., 1994" startWordPosition="232" endWordPosition="235">se translation pairs or translation rules from large amount of bilingual data with word alignment. The quality of the parallel data and the word alignment have significant impacts on the learned translation models and ultimately the quality of translation output. Due to the high cost of commissioned translation, many parallel sentences are automatically extracted from comparable corpora, which inevitably introduce many ”noises”, i.e., inaccurate or non-literal translations. Given the huge amount of bilingual training data, word alignments are automatically generated using various algorithms ((Brown et al., 1994), (Vogel et al., 1996) Figure 1: An example of inaccurate translation and word alignment. and (Ittycheriah and Roukos, 2005)), which also introduce many word alignment errors. The example in Figure 1 shows the word alignment of the given Chinese and English sentence pair, where the English words following each Chinese word is its literal translation. We find untranslated Chinese and English words (marked with underlines). These spurious words cause significant word alignment errors (as shown with dash lines), which in turn directly affect the quality of phrase translation tables or translation</context>
<context position="4668" citStr="Brown et al., 1994" startWordPosition="724" endWordPosition="727">arget alignment posterior probability, the numerator is the sentence translation probability calculated according to the given alignment A: P(A, T |S) = YJ p(tj|si, aij E A). (3) j=1 It is the product of lexical translation probabilities for the aligned word pairs. For unaligned target word tj, consider si = NULL. The source-totarget lexical translation model p(t|s) and targetto-source model p(s|t) can be obtained through IBM Model-1 or HMM training. The denominator is the sentence translation probability summing over all possible alignments, which can be calculated similar to IBM Model 1 in (Brown et al., 1994): p(tj|si). (4) Aligner F-score Cor. Coeff. HMM 54.72 -0.710 BM 62.53 -0.699 MaxEnt 69.26 -0.699 Table 1: Correlation coefficients of multiple alignments. Note that here only the word-based lexicon model is used to compute the confidence measure. More complex models such as alignment models, fertility models and distortion models as described in (Brown et al., 1994) could estimate the probability of a given alignment more accurately. However the summation over all possible alignments is very complicated, even intractable, with the richer models. For the efficient computation of the denominator</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1994</marker>
<rawString>Peter F. Brown, Stephen Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1994. The Mathematic of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19(2):263– 311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Measuring word alignment quality for statistical machine translation.</title>
<date>2007</date>
<journal>Comput. Linguist.,</journal>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="20977" citStr="Fraser and Marcu, 2007" startWordPosition="3360" endWordPosition="3363">been little research focusing on confidence measure for word alignment. This work is the first attempt to address the alignment confidence problem. Regarding word alignment combination, in addition to the commonly used ”intersection-unionrefine” approach (Och and Ney, 2003), (Ayan and Dorr, 2006b) and (Ayan et al., 2005) combined alignment links from multiple word alignment based on a set of linguistic and alignment features within the MaxEnt framework or a neural net model. While in this paper, the alignment links are combined based on their confidence scores and alignment agreement ratios. (Fraser and Marcu, 2007) discussed the impact of word alignment’s precision and recall on MT quality. Here removing low confidence links results in higher precision and slightly lower recall for the alignment. In our phrase extraction, we allow extracting phrase translation pairs with unaligned functional words at the boundary. This is similar to the ”loose phrases” described in (Ayan and Dorr, 2006a), which increased the number of correct phrase translations and improved the translation quality. On the other hand, removing incorrect content word links produced cleaner phrase translation tables. When translating docu</context>
</contexts>
<marker>Fraser, Marcu, 2007</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2007. Measuring word alignment quality for statistical machine translation. Comput. Linguist., 33(3):293–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simona Gandrabur</author>
<author>George Foster</author>
</authors>
<title>Confidence estimation for translation prediction.</title>
<date>2003</date>
<booktitle>In Proceedings of the seventh conference on Natural language learning at HLT-NAACL</booktitle>
<pages>95--102</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="19644" citStr="Gandrabur and Foster, 2003" startWordPosition="3159" endWordPosition="3162">mpled from 7.2 million sentence pairs with word alignments. The WB training data includes 240 thousand subsampled sentence pairs. Tables 7 and 8 show the corresponding translation results. Similarly, the phrase table size is significantly reduced by 35%, while the gains on the tail documents range from 0.6 to 1.4. On the whole test set the difference is smaller, 0.07 for the newswire translation and 0.58 for the web-blog translation. 6 Related Work In the machine translation area, most research on confidence measure focus on the confidence of MT output: how accurate a translated sentence is. (Gandrabur and Foster, 2003) used neural-net to improve the confidence estimate for text predictions in a machine-assisted translation tool. (Ueffing et al., 2003) presented several word-level confidence measures for machine translation based on word posterior probabilities. (Blatz et al., 2004) conducted extensive study incorporating various sentence-level and word-level features thru multilayer perceptron and naive Bayes algorithms for sentence and word confidence estimation. (Quirk, 2004) trained a sentence level confidence measure using a human annotated corpus. (Bach et al., 2008) used the sentence-pair confidence s</context>
</contexts>
<marker>Gandrabur, Foster, 2003</marker>
<rawString>Simona Gandrabur and George Foster. 2003. Confidence estimation for translation prediction. In Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003, pages 95–102, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niyu Ge</author>
</authors>
<title>Max-posterior hmm alignment for machine translation.</title>
<date>2004</date>
<booktitle>In Presentation given at DARPA/TIDES NIST MT Evaluation workshop.</booktitle>
<contexts>
<context position="6113" citStr="Ge, 2004" startWordPosition="956" endWordPosition="957">ord alignment using the MaxEnt aligner (Ittycheriah and Roukos, 2005). We evaluate per sentence alignment Fscores by comparing the system output with a reference alignment. For each sentence pair, we also calculate the sentence alignment confidence score −log C(A|S, T). We compute the correlation coefficients between the alignment confidence measure and the alignment F-scores. The results in Figure 2 shows strong correlation between the confidence measure and the alignment F-score, with the correlation coefficients equals to -0.69. Such strong correlation is also observed on an HMM alignment (Ge, 2004) and a Block Model (BM) alignment (Zhao et al., 2005) with varying alignment accuracies, as seen in Table1. 2.2 Sentence Alignment Selection Based on Confidence Measure The strong correlation between the sentence alignment confidence measure and the alignment FX P(A&apos;, T |S) = A&apos; YJ j=1 XI i=1 X P(A&apos;, S|T) = A&apos; YI i=1 XJ j=1 933 Figure 2: Correlation between sentence alignment confidence measure and F-score. measure suggests the possibility of selecting the alignment with the highest confidence score to obtain better alignments. For each sentence pair in the C-E test set, we calculate the confi</context>
</contexts>
<marker>Ge, 2004</marker>
<rawString>Niyu Ge. 2004. Max-posterior hmm alignment for machine translation. In Presentation given at DARPA/TIDES NIST MT Evaluation workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abraham Ittycheriah</author>
<author>Salim Roukos</author>
</authors>
<title>A maximum entropy word aligner for arabic-english machine translation.</title>
<date>2005</date>
<booktitle>In HLT ’05: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>89--96</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1743" citStr="Ittycheriah and Roukos, 2005" startWordPosition="251" endWordPosition="254">the parallel data and the word alignment have significant impacts on the learned translation models and ultimately the quality of translation output. Due to the high cost of commissioned translation, many parallel sentences are automatically extracted from comparable corpora, which inevitably introduce many ”noises”, i.e., inaccurate or non-literal translations. Given the huge amount of bilingual training data, word alignments are automatically generated using various algorithms ((Brown et al., 1994), (Vogel et al., 1996) Figure 1: An example of inaccurate translation and word alignment. and (Ittycheriah and Roukos, 2005)), which also introduce many word alignment errors. The example in Figure 1 shows the word alignment of the given Chinese and English sentence pair, where the English words following each Chinese word is its literal translation. We find untranslated Chinese and English words (marked with underlines). These spurious words cause significant word alignment errors (as shown with dash lines), which in turn directly affect the quality of phrase translation tables or translation rules that are learned based on word alignment. In this paper we introduce a confidence measure for word alignment, which i</context>
<context position="5573" citStr="Ittycheriah and Roukos, 2005" startWordPosition="871" endWordPosition="874">lignment models, fertility models and distortion models as described in (Brown et al., 1994) could estimate the probability of a given alignment more accurately. However the summation over all possible alignments is very complicated, even intractable, with the richer models. For the efficient computation of the denominator, we use the lexical translation model. Similarly, P (A, S|T ) Pt2s(A|T, S) = P A&apos; P (A&apos;, S|T ), (5) and P(A, S|T) = YI p(si|tj,aij E A). (6) i=1 p(si|tj). (7) We randomly selected 512 Chinese-English (CE) sentence pairs and generated word alignment using the MaxEnt aligner (Ittycheriah and Roukos, 2005). We evaluate per sentence alignment Fscores by comparing the system output with a reference alignment. For each sentence pair, we also calculate the sentence alignment confidence score −log C(A|S, T). We compute the correlation coefficients between the alignment confidence measure and the alignment F-scores. The results in Figure 2 shows strong correlation between the confidence measure and the alignment F-score, with the correlation coefficients equals to -0.69. Such strong correlation is also observed on an HMM alignment (Ge, 2004) and a Block Model (BM) alignment (Zhao et al., 2005) with v</context>
</contexts>
<marker>Ittycheriah, Roukos, 2005</marker>
<rawString>Abraham Ittycheriah and Salim Roukos. 2005. A maximum entropy word aligner for arabic-english machine translation. In HLT ’05: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 89–96, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Comput. Linguist.,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="11100" citStr="Och and Ney, 2003" startWordPosition="1791" endWordPosition="1794">ision, recall and F-score of individual alignments and the combined alignment. F-content and F-function are the F-scores for content words and function words, respectively. The link selection algorithm improves the recall over the best aligner (the ME alignment) by 7 points (from 65.4 to 72.5) while decreasing the precision by 4.4 points (from 73.6 to 69.2). Overall it improves the F-score by 1.5 points (from 69.3 to 70.8), 1.8 point improvement for content words and 1.0 point for function words. It also significantly outperforms the traditionally used heuristics, ”intersection-union-refine” (Och and Ney, 2003) by 6 points. 4 Improved MaxEnt Aligner with Confidence-based Link Filtering In addition to the alignment combination, we also improve the performance of the MaxEnt aligner through confidence-based alignment link filtering. Here we select the MaxEnt aligner because it has 935 Precision Recall F-score F-content F-function HMM 62.65 48.57 54.72 62.10 34.39 BM 72.76 54.82 62.53 68.64 43.93 ME 72.66 66.17 69.26 72.52 61.41 Link-Select 69.19 72.49 70.81 74.31 60.26 Intersection-Union-Refine 63.34 66.07 64.68 70.15 49.72 Table 2: Link Selection and Combination Results the highest F-measure among the</context>
<context position="20628" citStr="Och and Ney, 2003" startWordPosition="3302" endWordPosition="3305">layer perceptron and naive Bayes algorithms for sentence and word confidence estimation. (Quirk, 2004) trained a sentence level confidence measure using a human annotated corpus. (Bach et al., 2008) used the sentence-pair confidence scores estimated with source and target language models to weight phrase translation pairs. However, there has been little research focusing on confidence measure for word alignment. This work is the first attempt to address the alignment confidence problem. Regarding word alignment combination, in addition to the commonly used ”intersection-unionrefine” approach (Och and Ney, 2003), (Ayan and Dorr, 2006b) and (Ayan et al., 2005) combined alignment links from multiple word alignment based on a set of linguistic and alignment features within the MaxEnt framework or a neural net model. While in this paper, the alignment links are combined based on their confidence scores and alignment agreement ratios. (Fraser and Marcu, 2007) discussed the impact of word alignment’s precision and recall on MT quality. Here removing low confidence links results in higher precision and slightly lower recall for the alignment. In our phrase extraction, we allow extracting phrase translation </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Comput. Linguist., 29(1):19–51, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2001</date>
<booktitle>In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="16801" citStr="Papineni et al., 2001" startWordPosition="2699" endWordPosition="2702">ne translation tasks. The documents to be translated are from difference genres: newswire (NW) and web-blog (WB). The MT system is a phrasebased SMT system as described in (Al-Onaizan and Papineni, 2006). The training data are bilingual sentence pairs with word alignment, from which we obtained phrase translation pairs. We extract phrase translation tables from the baseline MaxEnt word alignment as well as the alignment with confidence-based link filtering, then translate the test set with each phrase translation table. We measure the translation quality with automatic metrics including BLEU (Papineni et al., 2001) and TER (Snover et al., 2006). The higher the BLEU score is, or the lower the TER score is, the better the translation quality is. We combine the two metrics into (TER-BLEU)/2 and try to minimize it. In addition to the whole test set’s scores, we also measure the scores of the ”tail” documents, whose (TER-BLEU)/2 scores are at the bottom 10 percentile (for A-E translation) and 20 percentile (for C-E translation) and are considered the most difficult documents to translate. In the Chinese-English MT experiment, we selected 40 NW documents, 41 WB documents as the test set, which includes 623 se</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2001. BLEU: a Method for Automatic Evaluation of Machine Translation. In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 311– 318, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
</authors>
<title>Training a sentence-level machine translation confidence measure. In</title>
<date>2004</date>
<booktitle>In Proc. LREC 2004,</booktitle>
<pages>825--828</pages>
<publisher>SpringerVerlag.</publisher>
<location>Lisbon, Portual.</location>
<contexts>
<context position="20112" citStr="Quirk, 2004" startWordPosition="3225" endWordPosition="3226">a, most research on confidence measure focus on the confidence of MT output: how accurate a translated sentence is. (Gandrabur and Foster, 2003) used neural-net to improve the confidence estimate for text predictions in a machine-assisted translation tool. (Ueffing et al., 2003) presented several word-level confidence measures for machine translation based on word posterior probabilities. (Blatz et al., 2004) conducted extensive study incorporating various sentence-level and word-level features thru multilayer perceptron and naive Bayes algorithms for sentence and word confidence estimation. (Quirk, 2004) trained a sentence level confidence measure using a human annotated corpus. (Bach et al., 2008) used the sentence-pair confidence scores estimated with source and target language models to weight phrase translation pairs. However, there has been little research focusing on confidence measure for word alignment. This work is the first attempt to address the alignment confidence problem. Regarding word alignment combination, in addition to the commonly used ”intersection-unionrefine” approach (Och and Ney, 2003), (Ayan and Dorr, 2006b) and (Ayan et al., 2005) combined alignment links from multi</context>
</contexts>
<marker>Quirk, 2004</marker>
<rawString>Chris Quirk. 2004. Training a sentence-level machine translation confidence measure. In In Proc. LREC 2004, pages 825–828, Lisbon, Portual. SpringerVerlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A Study of Translation Edit Rate with Targeted Human Annotation.</title>
<date>2006</date>
<booktitle>In Proceedings ofAssociation for Machine Translation in the Americas.</booktitle>
<contexts>
<context position="16831" citStr="Snover et al., 2006" startWordPosition="2705" endWordPosition="2708">nts to be translated are from difference genres: newswire (NW) and web-blog (WB). The MT system is a phrasebased SMT system as described in (Al-Onaizan and Papineni, 2006). The training data are bilingual sentence pairs with word alignment, from which we obtained phrase translation pairs. We extract phrase translation tables from the baseline MaxEnt word alignment as well as the alignment with confidence-based link filtering, then translate the test set with each phrase translation table. We measure the translation quality with automatic metrics including BLEU (Papineni et al., 2001) and TER (Snover et al., 2006). The higher the BLEU score is, or the lower the TER score is, the better the translation quality is. We combine the two metrics into (TER-BLEU)/2 and try to minimize it. In addition to the whole test set’s scores, we also measure the scores of the ”tail” documents, whose (TER-BLEU)/2 scores are at the bottom 10 percentile (for A-E translation) and 20 percentile (for C-E translation) and are considered the most difficult documents to translate. In the Chinese-English MT experiment, we selected 40 NW documents, 41 WB documents as the test set, which includes 623 sentences with 16667 words. The </context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A Study of Translation Edit Rate with Targeted Human Annotation. In Proceedings ofAssociation for Machine Translation in the Americas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
<author>Klaus Macherey</author>
<author>Hermann Ney</author>
</authors>
<title>Confidence measures for statistical machine translation. In</title>
<date>2003</date>
<booktitle>In Proc. MT Summit IX,</booktitle>
<pages>394--401</pages>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="19779" citStr="Ueffing et al., 2003" startWordPosition="3179" endWordPosition="3183">d 8 show the corresponding translation results. Similarly, the phrase table size is significantly reduced by 35%, while the gains on the tail documents range from 0.6 to 1.4. On the whole test set the difference is smaller, 0.07 for the newswire translation and 0.58 for the web-blog translation. 6 Related Work In the machine translation area, most research on confidence measure focus on the confidence of MT output: how accurate a translated sentence is. (Gandrabur and Foster, 2003) used neural-net to improve the confidence estimate for text predictions in a machine-assisted translation tool. (Ueffing et al., 2003) presented several word-level confidence measures for machine translation based on word posterior probabilities. (Blatz et al., 2004) conducted extensive study incorporating various sentence-level and word-level features thru multilayer perceptron and naive Bayes algorithms for sentence and word confidence estimation. (Quirk, 2004) trained a sentence level confidence measure using a human annotated corpus. (Bach et al., 2008) used the sentence-pair confidence scores estimated with source and target language models to weight phrase translation pairs. However, there has been little research focu</context>
</contexts>
<marker>Ueffing, Macherey, Ney, 2003</marker>
<rawString>Nicola Ueffing, Klaus Macherey, and Hermann Ney. 2003. Confidence measures for statistical machine translation. In In Proc. MT Summit IX, pages 394– 401. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillmann</author>
</authors>
<title>Hmm-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th conference on Computational linguistics,</booktitle>
<pages>836--841</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1641" citStr="Vogel et al., 1996" startWordPosition="236" endWordPosition="239">r translation rules from large amount of bilingual data with word alignment. The quality of the parallel data and the word alignment have significant impacts on the learned translation models and ultimately the quality of translation output. Due to the high cost of commissioned translation, many parallel sentences are automatically extracted from comparable corpora, which inevitably introduce many ”noises”, i.e., inaccurate or non-literal translations. Given the huge amount of bilingual training data, word alignments are automatically generated using various algorithms ((Brown et al., 1994), (Vogel et al., 1996) Figure 1: An example of inaccurate translation and word alignment. and (Ittycheriah and Roukos, 2005)), which also introduce many word alignment errors. The example in Figure 1 shows the word alignment of the given Chinese and English sentence pair, where the English words following each Chinese word is its literal translation. We find untranslated Chinese and English words (marked with underlines). These spurious words cause significant word alignment errors (as shown with dash lines), which in turn directly affect the quality of phrase translation tables or translation rules that are learne</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>Stephan Vogel, Hermann Ney, and Christoph Tillmann. 1996. Hmm-based word alignment in statistical translation. In Proceedings of the 16th conference on Computational linguistics, pages 836–841, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Zhao</author>
<author>Niyu Ge</author>
<author>Kishore Papineni</author>
</authors>
<title>Inner-outer bracket models for word alignment using hidden blocks.</title>
<date>2005</date>
<booktitle>In HLT ’05: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>177--184</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6166" citStr="Zhao et al., 2005" startWordPosition="964" endWordPosition="967">cheriah and Roukos, 2005). We evaluate per sentence alignment Fscores by comparing the system output with a reference alignment. For each sentence pair, we also calculate the sentence alignment confidence score −log C(A|S, T). We compute the correlation coefficients between the alignment confidence measure and the alignment F-scores. The results in Figure 2 shows strong correlation between the confidence measure and the alignment F-score, with the correlation coefficients equals to -0.69. Such strong correlation is also observed on an HMM alignment (Ge, 2004) and a Block Model (BM) alignment (Zhao et al., 2005) with varying alignment accuracies, as seen in Table1. 2.2 Sentence Alignment Selection Based on Confidence Measure The strong correlation between the sentence alignment confidence measure and the alignment FX P(A&apos;, T |S) = A&apos; YJ j=1 XI i=1 X P(A&apos;, S|T) = A&apos; YI i=1 XJ j=1 933 Figure 2: Correlation between sentence alignment confidence measure and F-score. measure suggests the possibility of selecting the alignment with the highest confidence score to obtain better alignments. For each sentence pair in the C-E test set, we calculate the confidence scores of the HMM alignment, the Block Model al</context>
</contexts>
<marker>Zhao, Ge, Papineni, 2005</marker>
<rawString>Bing Zhao, Niyu Ge, and Kishore Papineni. 2005. Inner-outer bracket models for word alignment using hidden blocks. In HLT ’05: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 177–184, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>