<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.998067">
Accurate Information Extraction from Research Papers
using Conditional Random Fields
</title>
<author confidence="0.996946">
Fuchun Peng
</author>
<affiliation confidence="0.998392">
Department of Computer Science
University of Massachusetts
</affiliation>
<address confidence="0.730728">
Amherst, MA 01003
</address>
<email confidence="0.998355">
fuchun@cs.umass.edu
</email>
<author confidence="0.998267">
Andrew McCallum
</author>
<affiliation confidence="0.9984085">
Department of Computer Science
University of Massachusetts
</affiliation>
<address confidence="0.730995">
Amherst, MA 01003
</address>
<email confidence="0.998926">
mccallum@cs.umass.edu
</email>
<sectionHeader confidence="0.995638" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999957761904762">
With the increasing use of research paper
search engines, such as CiteSeer, for both lit-
erature search and hiring decisions, the accu-
racy of such systems is of paramount impor-
tance. This paper employs Conditional Ran-
dom Fields (CRFs) for the task of extracting
various common fields from the headers and
citation of research papers. The basic the-
ory of CRFs is becoming well-understood, but
best-practices for applying them to real-world
data requires additional exploration. This paper
makes an empirical exploration of several fac-
tors, including variations on Gaussian, expo-
nential and hyperbolic-Ll priors for improved
regularization, and several classes of features
and Markov order. On a standard benchmark
data set, we achieve new state-of-the-art perfor-
mance, reducing error in average F1 by 36%,
and word error rate by 78% in comparison with
the previous best SVM results. Accuracy com-
pares even more favorably against HMMs.
</bodyText>
<sectionHeader confidence="0.999336" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99997166">
Research paper search engines, such as CiteSeer
(Lawrence et al., 1999) and Cora (McCallum et al.,
2000), give researchers tremendous power and conve-
nience in their research. They are also becoming increas-
ingly used for recruiting and hiring decisions. Thus the
information quality of such systems is of significant im-
portance. This quality critically depends on an informa-
tion extraction component that extracts meta-data, such
as title, author, institution, etc, from paper headers and
references, because these meta-data are further used in
many component applications such as field-based search,
author analysis, and citation analysis.
Previous work in information extraction from research
papers has been based on two major machine learn-
ing techniques. The first is hidden Markov models
(HMM) (Seymore et al., 1999; Takasu, 2003). An
HMM learns a generative model over input sequence
and labeled sequence pairs. While enjoying wide his-
torical success, standard HMM models have difficulty
modeling multiple non-independent features of the ob-
servation sequence. The second technique is based
on discriminatively-trained SVM classifiers (Han et al.,
2003). These SVM classifiers can handle many non-
independent features. However, for this sequence label-
ing problem, Han et al. (2003) work in a two stages pro-
cess: first classifying each line independently to assign it
label, then adjusting these labels based on an additional
classifier that examines larger windows of labels. Solving
the information extraction problem in two steps looses
the tight interaction between state transitions and obser-
vations.
In this paper, we present results on this research paper
meta-data extraction task using a Conditional Random
Field (Lafferty et al., 2001), and explore several practi-
cal issues in applying CRFs to information extraction in
general. The CRF approach draws together the advan-
tages of both finite state HMM and discriminative SVM
techniques by allowing use of arbitrary, dependent fea-
tures and joint inference over entire sequences.
CRFs have been previously applied to other tasks such
as name entity extraction (McCallum and Li, 2003), table
extraction (Pinto et al., 2003) and shallow parsing (Sha
and Pereira, 2003). The basic theory of CRFs is now
well-understood, but the best-practices for applying them
to new, real-world data is still in an early-exploration
phase. Here we explore two key practical issues: (1) reg-
ularization, with an empirical study of Gaussian (Chen
and Rosenfeld, 2000), exponential (Goodman, 2003), and
hyperbolic-Ll (Pinto et al., 2003) priors; (2) exploration
of various families of features, including text, lexicons,
</bodyText>
<figure confidence="0.988392666666667">
12
10
8
6
4
2
0 −5 −4 −3 −2 −1
−6
lambda
</figure>
<figureCaption confidence="0.999141">
Figure 1: Empirical distribution of A
</figureCaption>
<equation confidence="0.960011">
{(xi, yi) : i = 1, ...M} is written
XLΛ = log PΛ(yi|xi)
i
counts of lamda (in log scale)
0 1 2 3
</equation>
<bodyText confidence="0.999616857142857">
and layout, as well as proposing a method for the bene-
ficial use of zero-count features without incurring large
memory penalties.
We describe a large collection of experimental results
on two traditional benchmark data sets. Dramatic im-
provements are obtained in comparison with previous
SVM and HMM based results.
</bodyText>
<sectionHeader confidence="0.954175" genericHeader="method">
2 Conditional Random Fields
</sectionHeader>
<bodyText confidence="0.985687">
Conditional random fields (CRFs) are undirected graph-
ical models trained to maximize a conditional probabil-
ity (Lafferty et al., 2001). A common special-case graph
structure is a linear chain, which corresponds to a finite
state machine, and is suitable for sequence labeling. A
linear-chain CRF with parameters A = {A,...} defines
a conditional probability for a state (or label1) sequence
y = y1...yT given an input sequence x = x1...xT to be
</bodyText>
<equation confidence="0.99637025">
1 X !Akfk(yt−1, yt, x, t) , X= T X !Akfk(yt−1, yt, x, t) − log Zxi .
Pλ(y|x) = Z XTt= k (1) i X k (2)
exp t=1
1
</equation>
<bodyText confidence="0.999956733333333">
where ZX is the normalization constant that makes
the probability of all state sequences sum to one,
fk(yt−1, yt, x, t) is a feature function which is often
binary-valued, but can be real-valued, and Ak is a learned
weight associated with feature fk. The feature functions
can measure any aspect of a state transition, yt−1 → yt,
and the observation sequence, x, centered at the current
time step, t. For example, one feature function might
have value 1 when yt−1 is the state TITLE, yt is the state
AUTHOR, and xt is a word appearing in a lexicon of peo-
ple’s first names. Large positive values for Ak indicate a
preference for such an event, while large negative values
make the event unlikely.
Given such a model as defined in Equ. (1), the most
probable labeling sequence for an input x,
</bodyText>
<equation confidence="0.9991715">
y∗ = arg max
Y PΛ(y|x),
</equation>
<bodyText confidence="0.9996732">
can be efficiently calculated by dynamic programming
using the Viterbi algorithm. Calculating the marginal
probability of states or transitions at each position in
the sequence by a dynamic-programming-based infer-
ence procedure very similar to forward-backward for hid-
den Markov models.
The parameters may be estimated by maximum
likelihood—maximizing the conditional probability of
a set of label sequences, each given their correspond-
ing input sequences. The log-likelihood of training set
</bodyText>
<footnote confidence="0.979282333333333">
1We consider here only finite state models in which there is
a one-to-one correspondence between states and labels; this is
not, however, strictly necessary.
</footnote>
<bodyText confidence="0.91483375">
Maximizing (2) corresponds to satisfying the follow-
ing equality, wherein the the empirical count of each fea-
ture matches its expected count according to the model
PΛ(y|x).
</bodyText>
<equation confidence="0.854087">
X Xfk(yt−1, yt, xi, t) = PΛ(y|x)fk(yt−1, yt, xi, t)
i i
</equation>
<bodyText confidence="0.999853846153846">
CRFs share many of the advantageous properties of
standard maximum entropy models, including their con-
vex likelihood function, which guarantees that the learn-
ing procedure converges to the global maximum. Tra-
ditional maximum entropy learning algorithms, such as
GIS and IIS (Pietra et al., 1995), can be used to train
CRFs, however, it has been found that a quasi-Newton
gradient-climber, BFGS, converges much faster (Malouf,
2002; Sha and Pereira, 2003). We use BFGS for opti-
mization. In our experiments, we shall focus instead on
two other aspects of CRF deployment, namely regulariza-
tion and selection of different model structure and feature
types.
</bodyText>
<subsectionHeader confidence="0.989041">
2.1 Regularization in CRFs
</subsectionHeader>
<bodyText confidence="0.999514444444444">
To avoid over-fitting, log-likelihood is often penalized by
some prior distribution over the parameters. Figure 1
shows an empirical distribution of parameters, A, learned
from an unpenalized likelihood, including only features
with non-zero count in the training set. Three prior dis-
tributions that have shape similar to this empirical dis-
tribution are the Gaussian prior, exponential prior, and
hyperbolic-L1 prior, each shown in Figure 2. In this pa-
per we provide an empirical study of these three priors.
</bodyText>
<figureCaption confidence="0.995692">
Figure 2: Shapes of prior distributions
</figureCaption>
<subsectionHeader confidence="0.770637">
2.1.1 Gaussian prior
</subsectionHeader>
<bodyText confidence="0.996981">
With a Gaussian prior, log-likelihood (2) is penalized
as follows:
</bodyText>
<equation confidence="0.9385108">
XLA = X λ2
i log PA(yi|xi) − k , (3)
k 2σ2 k
where σ2 k is a variance.
Maximizing (3) corresponds to satisfying
λk
fk(yt−1, yt, xi, t) − 2 =
σk
X PA(y|x)fk(yt−1, yt, xi, t)
i
</equation>
<bodyText confidence="0.998364">
This adjusted constraint (as well as the adjustments im-
posed by the other two priors) is intuitively understand-
able: rather than matching exact empirical feature fre-
quencies, the model is tuned to match discounted feature
frequencies. Chen and Rosenfeld (2000) discuss this in
the context of other discounting procedures common in
language modeling. We call the term subtracted from the
empirical counts (in this case λk/σ2) a discounted value.
The variance can be feature dependent. However for
simplicity, constant variance is often used for all features.
In this paper, however, we experiment with several alter-
nate versions of Gaussian prior in which the variance is
feature dependent.
Although Gaussian (and other) priors are gradually
overcome by increasing amounts of training data, per-
haps not at the right rate. The three methods below all
provide ways to alter this rate by changing the variance
of the Gaussian prior dependent on feature counts.
</bodyText>
<listItem confidence="0.994555125">
1. Threshold Cut: In language modeling, e.g, Good-
Turing smoothing, only low frequency words are
smoothed. Here we apply the same idea and only
smooth those features whose frequencies are lower
than a threshold (7 in our experiments, following
standard practice in language modeling).
2. Divide Count: Here we let the discounted value
for a feature depend on its frequency in the training
</listItem>
<figure confidence="0.854536">
0.3
0.25
0.2
0.15
0.1
0.05
0
−10 −8 −6 −4 −2 0 2 4 6 8 10
0.4
0.35
Gaussian varianec=2
Exponential a=0.5
Hyperbolic
X
i
set, ck = P Pt fk(yt−1, yt, x, t). The discounted
i
value used here is λk
</figure>
<bodyText confidence="0.96891875">
ckxσ2 where σ is a constant over
all features. In this way, we increase the smoothing
on the low frequency features more so than the high
frequency features.
</bodyText>
<listItem confidence="0.7515995">
3. Bin-Based: We divide features into classes based
on frequency. We bin features by frequency in the
training set, and let the features in the same bin share
the same variance. The discounted value is set to be
</listItem>
<bodyText confidence="0.8529606">
λk
fck/ xσ2 where ck is the count of features, N is
the bin size, and ra] is the ceiling function. Alterna-
tively, the variance in each bin may be set indepen-
dently by cross-validation.
</bodyText>
<subsubsectionHeader confidence="0.873478">
2.1.2 Exponential prior
</subsubsectionHeader>
<bodyText confidence="0.999877090909091">
Whereas the Gaussian prior penalizes according to the
square of the weights (an L2 penalizer), the intention here
is to create a smoothly differentiable analogue to penal-
izing the absolute-value of the weights (an L1 penalizer).
L1 penalizers often result in more “sparse solutions,” in
which many features have weight nearly at zero, and thus
provide a kind of soft feature selection that improves gen-
eralization.
Goodman (2003) proposes an exponential prior,
specifically a Laplacian prior, as an alternative to Gaus-
sian prior. Under this prior,
</bodyText>
<equation confidence="0.754741">
XLA = log PA(yi|xi) − X αk|λk |(4)
i k
where αk is a parameter in exponential distribution.
Maximizing (4) would satisfy
X Xfk(yt−1, yt, xi, t)−αk = PA(y|x)fk(yt−1, yt, xi, t)
i i
</equation>
<bodyText confidence="0.994954">
This corresponds to the absolute smoothing method in
language modeling. We set the αk = α; i.e. all features
share the same constant whose value can be determined
using absolute discounting α = n1
n1+2n2 , where n1 and n2
are the number of features occurring once and twice (Ney
et al., 1995).
</bodyText>
<subsubsectionHeader confidence="0.638776">
2.1.3 Hyperbolic-L1 prior
</subsubsectionHeader>
<bodyText confidence="0.9964765">
Another L1 penalizer is the hyperbolic-L1 prior, de-
scribed in (Pinto et al., 2003). The hyperbolic distribution
has log-linear tails. Consequently the class of hyperbolic
distribution is an important alternative to the class of nor-
mal distributions and has been used for analyzing data
from various scientific areas such as finance, though less
frequently used in natural language processing.
Under a hyperbolic prior,
</bodyText>
<equation confidence="0.965143125">
XLΛ = X log(eλk +e �k ) (5)
i log PΛ(Yi|Xi) − 2
k
which corresponds to satisfying
e|ak |− e−|ak|
fk(yt−1, yt, xi, t) − e|ak |+ e−|ak|
X PΛ(yj-)fi(yt−1, yt, xi, t)
i
</equation>
<bodyText confidence="0.999335">
The hyperbolic prior was also tested with CRFs in Mc-
Callum and Li (2003).
</bodyText>
<subsectionHeader confidence="0.999426">
2.2 Exploration of Feature Space
</subsectionHeader>
<bodyText confidence="0.999952333333333">
Wise choice of features is always vital the performance
of any machine learning solution. Feature induction (Mc-
Callum, 2003) has been shown to provide significant im-
provements in CRFs performance. In some experiments
described below we use feature induction. The focus in
this section is on three other aspects of the feature space.
</bodyText>
<subsubsectionHeader confidence="0.671146">
2.2.1 State transition features
</subsubsectionHeader>
<bodyText confidence="0.9992068">
In CRFs, state transitions are also represented as fea-
tures. The feature function fk(yt−1, yt, x, t) in Equ. (1)
is a general function over states and observations. Differ-
ent state transition features can be defined to form dif-
ferent Markov-order structures. We define four differ-
ent state transitions features corresponding to different
Markov order for different classes of features. Higher
order features model dependencies better, but also create
more data sparse problem and require more memory in
training.
</bodyText>
<listItem confidence="0.985164615384615">
1. First-order: Here the inputs are examined in the con-
text of the current state only. The feature functions
are represented as f(yt, x). There are no separate
parameters or preferences for state transitions at all.
2. First-order+transitions: Here we add parameters
corresponding to state transitions. The feature func-
tions used are f(yt, x), f(yt−1, yt).
3. Second-order: Here inputs are examined in the con-
text of the current and previous states. Feature func-
tion are represented as f(yt−1, yt, x).
4. Third-order: Here inputs are examined in the con-
text of the current, two previous states. Feature func-
tion are represented as f(yt−2, yt−1, yt, x).
</listItem>
<subsubsectionHeader confidence="0.696397">
2.2.2 Supported features and unsupported features
</subsubsectionHeader>
<bodyText confidence="0.999982592592593">
Before the use of prior distributions over parameters
was common in maximum entropy classifiers, standard
practice was to eliminate all features with zero count
in the training data (the so-called unsupported features).
However, unsupported, zero-count features can be ex-
tremely useful for pushing Viterbi inference away from
certain paths by assigning such features negative weight.
The use of a prior allows the incorporation of unsup-
ported features, however, doing so often greatly increases
the number parameters and thus the memory require-
ments.
Below we experiment with models containing and not
containing unsupported features—both with and without
regularization by priors, and we argue that non-supported
features are useful.
We present here incremental support, a method of in-
troducing some useful unsupported features without ex-
ploding the number of parameters with all unsupported
features. The model is trained for several iterations with
supported features only. Then inference determines the
label sequences assigned high probability by the model.
Incorrect transitions assigned high probability by the
model are used to selectively add to the model those un-
supported features that occur on those transitions, which
may help improve performance by being assigned nega-
tive weight in future training. If desired, several iterations
of this procedure may be performed.
</bodyText>
<sectionHeader confidence="0.6514515" genericHeader="method">
2.2.3 Local features, layout features and lexicon
features
</sectionHeader>
<bodyText confidence="0.999965625">
One of the advantages of CRFs and maximum entropy
models in general is that they easily afford the use of arbi-
trary features of the input. One can encode local spelling
features, layout features such as positions of line breaks,
as well as external lexicon features, all in one framework.
We study all these features in our research paper extrac-
tion problem, evaluate their individual contributions, and
give some guidelines for selecting good features.
</bodyText>
<sectionHeader confidence="0.999144" genericHeader="method">
3 Empirical Study
</sectionHeader>
<subsectionHeader confidence="0.999298">
3.1 Hidden Markov Models
</subsectionHeader>
<bodyText confidence="0.99920625">
Here we also briefly describe a HMM model we used
in our experiments. We relax the independence assump-
tion made in standard HMM and allow Markov depen-
dencies among observations, e.g., P(otlst, ot−1). We
can vary Markov orders in state transition and observa-
tion transitions. In our experiments, a model with second
order state transitions and first order observation transi-
tions performs the best. The state transition probabilities
and emission probabilities are estimated using maximum
likelihood estimation with absolute smoothing, which
was found to be effective in previous experiments, includ-
ing Seymore et al. (1999).
</bodyText>
<subsectionHeader confidence="0.979254">
3.2 Datasets
</subsectionHeader>
<bodyText confidence="0.998911428571429">
We experiment with two datasets of research paper con-
tent. One consists of the headers of research papers. The
other consists of pre-segmented citations from the refer-
ence sections of research papers. These data sets have
been used as standard benchmarks in several previous
studies (Seymore et al., 1999; McCallum et al., 2000;
Han et al., 2003).
</bodyText>
<equation confidence="0.861452333333333">
X
i
=
</equation>
<subsectionHeader confidence="0.687649">
3.2.1 Paper header dataset
</subsectionHeader>
<bodyText confidence="0.999886416666667">
The header of a research paper is defined to be all of
the words from the beginning of the paper up to either
the first section of the paper, usually the introduction,
or to the end of the first page, whichever occurs first.
It contains 15 fields to be extracted: title, author, affil-
iation, address, note, email, date, abstract, introduction,
phone, keywords, web, degree, publication number, and
page (Seymore et al., 1999). The header dataset contains
935 headers. Following previous research (Seymore et
al., 1999; McCallum et al., 2000; Han et al., 2003), for
each trial we randomly select 500 for training and the re-
maining 435 for testing. We refer this dataset as H.
</bodyText>
<subsectionHeader confidence="0.620284">
3.2.2 Paper reference dataset
</subsectionHeader>
<bodyText confidence="0.9995755">
The reference dataset was created by the Cora
project (McCallum et al., 2000). It contains 500 refer-
ences, we use 350 for training and the rest 150 for test-
ing. References contain 13 fields: author, title, editor,
booktitle, date, journal, volume, tech, institution, pages,
location, publisher, note. We refer this dataset as R.
</bodyText>
<subsectionHeader confidence="0.995777">
3.3 Performance Measures
</subsectionHeader>
<bodyText confidence="0.999984111111111">
To give a comprehensive evaluation, we measure per-
formance using several different metrics. In addition to
the previously-used word accuracy measure (which over-
emphasizes accuracy of the abstract field), we use per-
field F1 measure (both for individual fields and averaged
over all fields—called a “macro average” in the informa-
tion retrieval literature), and whole instance accuracy for
measuring overall performance in a way that is sensitive
to even a single error in any part of header or citation.
</bodyText>
<subsectionHeader confidence="0.629138">
3.3.1 Measuring field-specific performance
</subsectionHeader>
<listItem confidence="0.954862555555555">
1. Word Accuracy: We define A as the number of true
positive words, B as the number of false negative
words, C as the number of false positive words, D
as the number of true negative words, and A + B +
C + D is the total number of words. Word accuracy
is calculated to be A+D
A+B+C+D
2. F1-measure: Precision, recall and F1 measure are
defined as follows. Precision = A
</listItem>
<equation confidence="0.90968575">
A+C Recall = A
A+B
F1 = 2×Precision×Recall
Precision+Recall
</equation>
<subsectionHeader confidence="0.575002">
3.3.2 Measuring overall performance
</subsectionHeader>
<listItem confidence="0.962537125">
1. Overall word accuracy: Overall word accuracy
is the percentage of words whose predicted labels
equal their true labels. Word accuracy favors fields
with large number of words, such as the abstract.
2. Averaged F-measure: Averaged F-measure is com-
puted by averaging the F1-measures over all fields.
Average F-measure favors labels with small num-
ber of words, which complements word accuracy.
</listItem>
<bodyText confidence="0.878317">
Thus, we consider both word accuracy and average
F-measure in evaluation.
3. Whole instance accuracy: An instance here is de-
fined to be a single header or reference. Whole
instance accuracy is the percentage of instances in
which every word is correctly labeled.
</bodyText>
<subsectionHeader confidence="0.967103">
3.4 Experimental Results
</subsectionHeader>
<bodyText confidence="0.9999483125">
We first report the overall results by comparing CRFs
with HMMs, and with the previously best benchmark re-
sults obtained by SVMs (Han et al., 2003). We then break
down the results to analyze various factors individually.
Table 1 shows the results on dataset H with the best re-
sults in bold; (intro and page fields are not shown, fol-
lowing past practice (Seymore et al., 1999; Han et al.,
2003)). The results we obtained with CRFs use second-
order state transition features, layout features, as well as
supported and unsupported features. Feature induction
is used in experiments on dataset R; (it didn’t improve
accuracy on H). The results we obtained with the HMM
model use a second order model for transitions, and a first
order for observations. The results on SVM is obtained
from (Han et al., 2003) by computing F1 measures from
the precision and recall numbers they report.
</bodyText>
<table confidence="0.998564">
HMM CRF SVM
Overall acc. 93.1% 98.3% 92.9%
Instance acc. 4.13% 73.3% -
acc. F1 acc. F1 acc. F1
Title 98.2 82.2 99.7 97.1 98.9 96.5
Author 98.7 81.0 99.8 97.5 99.3 97.2
Affiliation 98.3 85.1 99.7 97.0 98.1 93.8
Address 99.1 84.8 99.7 95.8 99.1 94.7
Note 97.8 81.4 98.8 91.2 95.5 81.6
Email 99.9 92.5 99.9 95.3 99.6 91.7
Date 99.8 80.6 99.9 95.0 99.7 90.2
Abstract 97.1 98.0 99.6 99.7 97.5 93.8
Phone 99.8 53.8 99.9 97.9 99.9 92.4
Keyword 98.7 40.6 99.7 88.8 99.2 88.5
Web 99.9 68.6 99.9 94.1 99.9 92.4
Degree 99.5 68.8 99.8 84.9 99.5 70.1
Pubnum 99.8 64.2 99.9 86.6 99.9 89.2
Average F1 75.6 93.9 89.7
</table>
<tableCaption confidence="0.999944">
Table 1: Extraction results for paper headers on H
</tableCaption>
<bodyText confidence="0.571113">
Table 2 shows the results on dataset R. SVM results
are not available for these datasets.
</bodyText>
<subsectionHeader confidence="0.8969105">
3.5 Analysis
3.5.1 Overall performance comparison
</subsectionHeader>
<bodyText confidence="0.997413333333333">
From Table (1, 2), one can see that CRF performs
significantly better than HMMs, which again supports
the previous findings (Lafferty et al., 2001; Pinto et al.,
</bodyText>
<table confidence="0.999623555555555">
HMM CRF
Overall acc. 85.1% 95.37%
instance acc. 10% 77.33%
acc. F1 acc. F1
Author 96.8 92.7 99.9 99.4
Booktitle 94.4 0.85 97.7 93.7
Date 99.7 96.9 99.8 98.9
Editor 98.8 70.8 99.5 87.7
Institution 98.5 72.3 99.7 94.0
Journal 96.6 67.7 99.1 91.3
Location 99.1 81.8 99.3 87.2
Note 99.2 50.9 99.7 80.8
Pages 98.1 72.9 99.9 98.6
Publisher 99.4 79.2 99.4 76.1
Tech 98.8 74.9 99.4 86.7
Title 92.2 87.2 98.9 98.3
Volume 98.6 75.8 99.9 97.8
Average F1 77.6% 91.5%
</table>
<tableCaption confidence="0.999597">
Table 2: Extraction results for paper references on R
</tableCaption>
<bodyText confidence="0.999864733333333">
2003). CRFs also perform significantly better than SVM-
based approach, yielding new state of the art performance
on this task. CRFs increase the performance on nearly all
the fields. The overall word accuracy is improved from
92.9% to 98.3%, which corresponds to a 78% error rate
reduction. However, as we can see word accuracy can be
misleading since HMM model even has a higher word ac-
curacy than SVM, although it performs much worse than
SVM in most individual fields except abstract. Interest-
ingly, HMM performs much better on abstract field (98%
versus 93.8% F-measure) which pushes the overall accu-
racy up. A better comparison can be made by compar-
ing the field-based F-measures. Here, in comparison to
the SVM, CRFs improve the F1 measure from 89.7% to
93.9%, an error reduction of 36%.
</bodyText>
<subsectionHeader confidence="0.990228">
3.5.2 Effects of regularization
</subsectionHeader>
<bodyText confidence="0.999785941176471">
The results of different regularization methods are
summarized in Table (3). Setting Gaussian variance of
features depending on feature count performs better, from
90.5% to 91.2%, an error reduction of 7%, when only
using supported features, and an error reduction of 9%
when using supported and unsupported features. Re-
sults are averaged over 5 random runs, with an aver-
age variance of 0.2%. In our experiments we found the
Gaussian prior to consistently perform better than the
others. Surprisingly, exponential prior hurts the perfor-
mance significantly. It over penalizes the likelihood (sig-
nificantly increasing cost—defined as negative penalized
log-likelihood). We hypothesized that the problem could
be that the choice of constant α is inappropriate. So we
tried varying α instead of computing it using absolute
discounting, but found the alternatives to perform worse.
These results suggest that Gaussian prior is a safer prior
</bodyText>
<table confidence="0.9997058">
support feat. all features
Method F1 F1
Gaussian infinity 90.5 93.3
Gaussian variance = 0.1 81.7 91.8
Gaussian variance = 0.5 87.2 93.0
Gaussian variance = 5 90.1 93.7
Gaussian variance = 10 89.9 93.5
Gaussian cut 7 90.1 93.4
Gaussian divide count 90.9 92.8
Gaussian bin 5 90.9 93.6
Gaussian bin 10 90.2 92.9
Gaussian bin 15 91.2 93.9
Gaussian bin 20 90.4 93.2
Hyperbolic 89.4 92.8
Exponential 80.5 85.6
</table>
<tableCaption confidence="0.999696">
Table 3: Regularization comparisons: Gaussian infinity is
</tableCaption>
<bodyText confidence="0.9469255">
non-regularized, Gaussian variance = X sets variance to
be X. Gaussian cut 7 refers to the Threshold Cut method,
Gaussian divide count refers to the Divide Count method,
Gaussian bin N refers to the Bin-Based method with bin
size equals N, as described in 2.1.1
to use in practice.
</bodyText>
<subsectionHeader confidence="0.939119">
3.5.3 Effects of exploring feature space
</subsectionHeader>
<bodyText confidence="0.970394370370371">
State transition features and unsupported features.
We summarize the comparison of different state tran-
sition models using or not using unsupported features in
Table 4. The first column describes the four different state
transition models, the second column contains the overall
word accuracy of these models using only support fea-
tures, and the third column contains the result of using
all features, including unsupported features. Comparing
the rows, one can see that the second-order model per-
forms the best, but not dramatically better than the first-
order+transitions and the third order model. However, the
first-order model performs significantly worse. The dif-
ference does not come from sharing the weights, but from
ignoring the f(yt−1i yt). The first order transition feature
is vital here. We would expect the third order model to
perform better if enough training data were available.
Comparing the second and the third columns, we can
see that using all features including unsupported features,
consistently performs better than ignoring them. Our
preliminary experiments with incremental support have
shown performance in between that of supported-only
and all features, and are still ongoing.
Effects of layout features
To analyze the contribution of different kinds of fea-
tures, we divide the features into three categories: local
features, layout features, and external lexicon resources.
The features we used are summarized in Table 5.
</bodyText>
<table confidence="0.9991584">
support all
first-order 89.0 90.4
first-order+trans 95.6 -
second-order 96.0 96.5
third-order 95.3 96.1
</table>
<tableCaption confidence="0.9192805">
Table 4: Effects of using unsupported features and state
transitions on H
</tableCaption>
<table confidence="0.999921730769231">
Feature name Description
Local features
INITCAP Starts with a capitalized letter
ALLCAPS All characters are capitalized
CONTAINSDIGITS Contains at least one digit
ALLDIGITS All characters are digits
PHONEORZIP Phone number or zip code
CONTAINSDOTS Contains at least one dot
CONTAINSDASH Contains at least one -
ACRO Acronym
LONELYINITIAL Initials such as A.
SINGLECHAR One character only
CAPLETTER One capitalized character
PUNC Punctuation
URL Regular expression for URL
EMAIL Regular expression for e-address
WORD Word itself
Layout features
LINE START At the beginning of a line
LINE IN In middle of a line
LINE END At the end of a line
External lexicon features
BIBTEX AUTHOR Match word in author lexicon
BIBTEX DATE Words like Jan. Feb.
NOTES Words like appeared, submitted
AFFILIATION Words like institution, Labs, etc
</table>
<tableCaption confidence="0.999339">
Table 5: List of features used
</tableCaption>
<bodyText confidence="0.9998604">
The results of using different features are shown in Ta-
ble 6. The layout feature dramatically increases the per-
formance, raising the F1 measure from 88.8% to 93.9%,
whole sentence accuracy from 40.1% to 72.4%. Adding
lexicon features alone improves the performance. How-
ever, when combing lexicon features and layout fea-
tures, the performance is worse than using layout features
alone.
The lexicons were gathered from a large collection of
BibTeX files, and upon examination had difficult to re-
move noise, for example words in the author lexicon that
were also affiliations. In previous work, we have gained
significant benefits by dividing each lexicon into sections
based on point-wise information gain with respect to the
lexicon’s class.
</bodyText>
<sectionHeader confidence="0.570291" genericHeader="method">
3.5.4 Error analysis
</sectionHeader>
<tableCaption confidence="0.6465585">
Table 7 is the classification confusion matrix of header
extraction (field page is not shown to save space). Most
</tableCaption>
<table confidence="0.9997652">
Word Acc. F1 Inst. Acc.
local feature 96.5% 88.8% 40.1%
+lexicon 96.9% 89.9% 53.1%
+ layout feature 98.2% 93.4% 72.4%
+ layout + lexicon 98.0% 93.0% 71.7%
</table>
<tableCaption confidence="0.999482">
Table 6: Results of using different features on H
</tableCaption>
<bodyText confidence="0.999920454545455">
errors happen at the boundaries between two fields. Es-
pecially the transition from author to affiliation, from ab-
stract to keyword. The note field is the one most con-
fused with others, and upon inspection is actually labeled
inconsistently in the training data. Other errors could
be fixed with additional feature engineering—for exam-
ple, including additional specialized regular expressions
should make email accuracy nearly perfect. Increasing
the amount of training data would also be expected to
help significantly, as indicated by consistent nearly per-
fect accuracy on the training set.
</bodyText>
<sectionHeader confidence="0.998661" genericHeader="conclusions">
4 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999996">
This paper investigates the issues of regularization, fea-
ture spaces, and efficient use of unsupported features in
CRFs, with an application to information extraction from
research papers.
For regularization we find that the Gaussian prior with
variance depending on feature frequencies performs bet-
ter than several other alternatives in the literature. Feature
engineering is a key component of any machine learn-
ing solution—especially in conditionally-trained mod-
els with such freedom to choose arbitrary features—and
plays an even more important role than regularization.
We obtain new state-of-the-art performance in extract-
ing standard fields from research papers, with a signifi-
cant error reduction by several metrics. We also suggest
better evaluation metrics to facilitate future research in
this task—especially field-F1, rather than word accuracy.
We have provided an empirical exploration of a few
previously-published priors for conditionally-trained log-
linear models. Fundamental advances in regularization
for CRFs remains a significant open research area.
</bodyText>
<sectionHeader confidence="0.999641" genericHeader="acknowledgments">
5 Acknowledgments
</sectionHeader>
<bodyText confidence="0.99797244">
This work was supported in part by the Cen-
ter for Intelligent Information Retrieval, in part by
SPAWARSYSCEN-SD grant number N66001-02-1-
8903, in part by the National Science Foundation Co-
operative Agreement number ATM-9732665 through a
subcontract from the University Corporation for Atmo-
spheric Research (UCAR) and in part by The Cen-
tral Intelligence Agency, the National Security Agency
and National Science Foundation under NSF grant #IIS-
0326249. Any opinions, findings and conclusions or rec-
title auth. pubnum date abs. aff. addr. email deg. note ph. intro k.w. web
title 3446 0 6 0 22 0 0 0 9 25 0 0 12 0
author 0 2653 0 0 7 13 5 0 14 41 0 0 12 0
pubnum 0 14 278 2 0 2 7 0 0 39 0 0 0 0
date 0 0 3 336 0 1 3 0 0 18 0 0 0 0
abstract 0 0 0 0 53262 0 0 1 0 0 0 0 0 0
affil. 19 13 0 0 10 3852 27 0 28 34 0 0 0 1
address 0 11 3 0 0 35 2170 1 0 21 0 0 0 0
email 0 0 1 0 12 2 3 461 0 2 2 0 15 0
degree 2 2 0 2 0 2 0 5 465 95 0 0 2 0
note 52 2 9 6 219 52 59 0 5 4520 4 3 21 3
phone 0 0 0 0 0 0 0 1 0 2 215 0 0 0
intro 0 0 0 0 0 0 0 0 0 32 0 625 0 0
keyword 57 0 0 0 18 3 15 0 0 91 0 0 975 0
web 0 0 0 0 2 0 0 0 0 31 0 0 0 294
</bodyText>
<tableCaption confidence="0.984417">
Table 7: Confusion matrix on H
</tableCaption>
<bodyText confidence="0.914944">
ommendations expressed in this material are the author(s)
and do not necessarily reflect those of the sponsor.
</bodyText>
<sectionHeader confidence="0.99834" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999811316666667">
S. Chen and R. Rosenfeld. 2000. A Survey of Smoothing
Techniques for ME Models. IEEE Trans. Speech and
Audio Processing, 8(1), pp. 37–50. January 2000.
J. Goodman. 2003. Exponential Priors for Maximum
Entropy Models. MSR Technical report, 2003.
H. Han, C. Giles, E. Manavoglu, H. Zha, Z. Zhang, and E.
Fox. 2003. Automatic Document Meta-data Extrac-
tion using Support Vector Machines. In Proceedings
ofJoint Conference on Digital Libraries 2003.
J. Lafferty, A. McCallum and F. Pereira. 2001. Condi-
tional Random Fields: Probabilistic Models for Seg-
menting and Labeling Sequence Data. In Proceed-
ings ofInternational Conference on Machine Learning
2001.
S. Lawrence, C. L. Giles, and K. Bollacker. 1999. Digital
Libraries and Autonomous Citation Indexing. IEEE
Computer, 32(6): 67-71.
R. Malouf. 2002. A Comparison of Algorithms for Max-
imum Entropy Parameter Estimation. In Proceedings
ofthe Sixth Conference on Natural Language Learning
(CoNLL)
A. McCallum. 2003. Efficiently Inducing Features
of Conditional Random Fields. In Proceedings of
Conference on Uncertainty in Articifical Intelligence
(UAI).
A. McCallum, K. Nigam, J. Rennie, K. Seymore. 2000.
Automating the Construction of Internet Portals with
Machine Learning. Information Retrieval Journal,
volume 3, pages 127-163. Kluwer. 2000.
A. McCallum and W. Li. 2003. Early Results for Named
Entity Recognition with Conditional Random Fields,
Feature Induction and Web-Enhanced Lexicons. In
Proceedings of Seventh Conference on Natural Lan-
guage Learning (CoNLL).
H. Ney, U. Essen, and R. Kneser 1995. On the Estima-
tion of Small Probabilities by Leaving-One-Out. IEEE
Transactions on Pattern Analysis and Machine Intelli-
gence, 17(12):1202-1212, 1995.
S. Pietra, V. Pietra, J. Lafferty 1995. Inducing Fea-
tures Of Random Fields. IEEE Transactions on Pat-
tern Analysis and Machine Intelligence, Vol. 19, No.
4.
D. Pinto, A. McCallum, X. Wei and W. Croft. 2003. Ta-
ble Extraction Using Conditional Random Fields. In
Proceedins of the 26th Annual International ACM SI-
GIR Conference on Research and Development in In-
formation Retrieval (SIGIR’03)
K. Seymore, A. McCallum, R. Rosenfeld. 1999. Learn-
ing Hidden Markov Model Structure for Information
Extraction. In Proceedings of AAAI’99 Workshop on
Machine Learning for Information Extraction.
F. Sha and F. Pereira. 2003. Shallow Parsing with Con-
ditional Random Fields. In Proceedings of Human
Language Technology Conference and North Ameri-
can Chapter of the Association for Computational Lin-
guistics (HLT-NAACL’03)
A. Takasu. 2003. Bibliographic Attribute Extrac-
tion from Erroneous References Based on a Statistical
Model. In Proceedings ofJoint Conference on Digital
Libraries 2003.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.709331">
<title confidence="0.9847015">Accurate Information Extraction from Research using Conditional Random Fields</title>
<author confidence="0.863202">Fuchun</author>
<affiliation confidence="0.999743">Department of Computer University of</affiliation>
<address confidence="0.960121">Amherst, MA</address>
<email confidence="0.999778">fuchun@cs.umass.edu</email>
<author confidence="0.988954">Andrew</author>
<affiliation confidence="0.9998305">Department of Computer University of</affiliation>
<address confidence="0.909724">Amherst, MA</address>
<email confidence="0.999507">mccallum@cs.umass.edu</email>
<abstract confidence="0.998680409090909">With the increasing use of research paper search engines, such as CiteSeer, for both literature search and hiring decisions, the accuracy of such systems is of paramount importance. This paper employs Conditional Random Fields (CRFs) for the task of extracting various common fields from the headers and citation of research papers. The basic theory of CRFs is becoming well-understood, but best-practices for applying them to real-world data requires additional exploration. This paper makes an empirical exploration of several factors, including variations on Gaussian, expoand priors for improved regularization, and several classes of features and Markov order. On a standard benchmark data set, we achieve new state-of-the-art performance, reducing error in average F1 by 36%, and word error rate by 78% in comparison with the previous best SVM results. Accuracy compares even more favorably against HMMs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Chen</author>
<author>R Rosenfeld</author>
</authors>
<title>A Survey of Smoothing Techniques for ME Models.</title>
<date>2000</date>
<journal>IEEE Trans. Speech and Audio Processing,</journal>
<volume>8</volume>
<issue>1</issue>
<pages>37--50</pages>
<contexts>
<context position="3771" citStr="Chen and Rosenfeld, 2000" startWordPosition="562" endWordPosition="565">antages of both finite state HMM and discriminative SVM techniques by allowing use of arbitrary, dependent features and joint inference over entire sequences. CRFs have been previously applied to other tasks such as name entity extraction (McCallum and Li, 2003), table extraction (Pinto et al., 2003) and shallow parsing (Sha and Pereira, 2003). The basic theory of CRFs is now well-understood, but the best-practices for applying them to new, real-world data is still in an early-exploration phase. Here we explore two key practical issues: (1) regularization, with an empirical study of Gaussian (Chen and Rosenfeld, 2000), exponential (Goodman, 2003), and hyperbolic-Ll (Pinto et al., 2003) priors; (2) exploration of various families of features, including text, lexicons, 12 10 8 6 4 2 0 −5 −4 −3 −2 −1 −6 lambda Figure 1: Empirical distribution of A {(xi, yi) : i = 1, ...M} is written XLΛ = log PΛ(yi|xi) i counts of lamda (in log scale) 0 1 2 3 and layout, as well as proposing a method for the beneficial use of zero-count features without incurring large memory penalties. We describe a large collection of experimental results on two traditional benchmark data sets. Dramatic improvements are obtained in comparis</context>
<context position="8445" citStr="Chen and Rosenfeld (2000)" startWordPosition="1344" endWordPosition="1347">is paper we provide an empirical study of these three priors. Figure 2: Shapes of prior distributions 2.1.1 Gaussian prior With a Gaussian prior, log-likelihood (2) is penalized as follows: XLA = X λ2 i log PA(yi|xi) − k , (3) k 2σ2 k where σ2 k is a variance. Maximizing (3) corresponds to satisfying λk fk(yt−1, yt, xi, t) − 2 = σk X PA(y|x)fk(yt−1, yt, xi, t) i This adjusted constraint (as well as the adjustments imposed by the other two priors) is intuitively understandable: rather than matching exact empirical feature frequencies, the model is tuned to match discounted feature frequencies. Chen and Rosenfeld (2000) discuss this in the context of other discounting procedures common in language modeling. We call the term subtracted from the empirical counts (in this case λk/σ2) a discounted value. The variance can be feature dependent. However for simplicity, constant variance is often used for all features. In this paper, however, we experiment with several alternate versions of Gaussian prior in which the variance is feature dependent. Although Gaussian (and other) priors are gradually overcome by increasing amounts of training data, perhaps not at the right rate. The three methods below all provide way</context>
</contexts>
<marker>Chen, Rosenfeld, 2000</marker>
<rawString>S. Chen and R. Rosenfeld. 2000. A Survey of Smoothing Techniques for ME Models. IEEE Trans. Speech and Audio Processing, 8(1), pp. 37–50. January 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goodman</author>
</authors>
<title>Exponential Priors for Maximum Entropy Models.</title>
<date>2003</date>
<tech>MSR Technical report,</tech>
<contexts>
<context position="3800" citStr="Goodman, 2003" startWordPosition="567" endWordPosition="568">criminative SVM techniques by allowing use of arbitrary, dependent features and joint inference over entire sequences. CRFs have been previously applied to other tasks such as name entity extraction (McCallum and Li, 2003), table extraction (Pinto et al., 2003) and shallow parsing (Sha and Pereira, 2003). The basic theory of CRFs is now well-understood, but the best-practices for applying them to new, real-world data is still in an early-exploration phase. Here we explore two key practical issues: (1) regularization, with an empirical study of Gaussian (Chen and Rosenfeld, 2000), exponential (Goodman, 2003), and hyperbolic-Ll (Pinto et al., 2003) priors; (2) exploration of various families of features, including text, lexicons, 12 10 8 6 4 2 0 −5 −4 −3 −2 −1 −6 lambda Figure 1: Empirical distribution of A {(xi, yi) : i = 1, ...M} is written XLΛ = log PΛ(yi|xi) i counts of lamda (in log scale) 0 1 2 3 and layout, as well as proposing a method for the beneficial use of zero-count features without incurring large memory penalties. We describe a large collection of experimental results on two traditional benchmark data sets. Dramatic improvements are obtained in comparison with previous SVM and HMM </context>
<context position="10732" citStr="Goodman (2003)" startWordPosition="1736" endWordPosition="1737">the count of features, N is the bin size, and ra] is the ceiling function. Alternatively, the variance in each bin may be set independently by cross-validation. 2.1.2 Exponential prior Whereas the Gaussian prior penalizes according to the square of the weights (an L2 penalizer), the intention here is to create a smoothly differentiable analogue to penalizing the absolute-value of the weights (an L1 penalizer). L1 penalizers often result in more “sparse solutions,” in which many features have weight nearly at zero, and thus provide a kind of soft feature selection that improves generalization. Goodman (2003) proposes an exponential prior, specifically a Laplacian prior, as an alternative to Gaussian prior. Under this prior, XLA = log PA(yi|xi) − X αk|λk |(4) i k where αk is a parameter in exponential distribution. Maximizing (4) would satisfy X Xfk(yt−1, yt, xi, t)−αk = PA(y|x)fk(yt−1, yt, xi, t) i i This corresponds to the absolute smoothing method in language modeling. We set the αk = α; i.e. all features share the same constant whose value can be determined using absolute discounting α = n1 n1+2n2 , where n1 and n2 are the number of features occurring once and twice (Ney et al., 1995). 2.1.3 H</context>
</contexts>
<marker>Goodman, 2003</marker>
<rawString>J. Goodman. 2003. Exponential Priors for Maximum Entropy Models. MSR Technical report, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Han</author>
<author>C Giles</author>
<author>E Manavoglu</author>
<author>H Zha</author>
<author>Z Zhang</author>
<author>E Fox</author>
</authors>
<title>Automatic Document Meta-data Extraction using Support Vector Machines.</title>
<date>2003</date>
<booktitle>In Proceedings ofJoint Conference on Digital Libraries</booktitle>
<contexts>
<context position="2423" citStr="Han et al., 2003" startWordPosition="352" endWordPosition="355"> in many component applications such as field-based search, author analysis, and citation analysis. Previous work in information extraction from research papers has been based on two major machine learning techniques. The first is hidden Markov models (HMM) (Seymore et al., 1999; Takasu, 2003). An HMM learns a generative model over input sequence and labeled sequence pairs. While enjoying wide historical success, standard HMM models have difficulty modeling multiple non-independent features of the observation sequence. The second technique is based on discriminatively-trained SVM classifiers (Han et al., 2003). These SVM classifiers can handle many nonindependent features. However, for this sequence labeling problem, Han et al. (2003) work in a two stages process: first classifying each line independently to assign it label, then adjusting these labels based on an additional classifier that examines larger windows of labels. Solving the information extraction problem in two steps looses the tight interaction between state transitions and observations. In this paper, we present results on this research paper meta-data extraction task using a Conditional Random Field (Lafferty et al., 2001), and expl</context>
<context position="16544" citStr="Han et al., 2003" startWordPosition="2655" endWordPosition="2658">transitions performs the best. The state transition probabilities and emission probabilities are estimated using maximum likelihood estimation with absolute smoothing, which was found to be effective in previous experiments, including Seymore et al. (1999). 3.2 Datasets We experiment with two datasets of research paper content. One consists of the headers of research papers. The other consists of pre-segmented citations from the reference sections of research papers. These data sets have been used as standard benchmarks in several previous studies (Seymore et al., 1999; McCallum et al., 2000; Han et al., 2003). X i = 3.2.1 Paper header dataset The header of a research paper is defined to be all of the words from the beginning of the paper up to either the first section of the paper, usually the introduction, or to the end of the first page, whichever occurs first. It contains 15 fields to be extracted: title, author, affiliation, address, note, email, date, abstract, introduction, phone, keywords, web, degree, publication number, and page (Seymore et al., 1999). The header dataset contains 935 headers. Following previous research (Seymore et al., 1999; McCallum et al., 2000; Han et al., 2003), for </context>
<context position="19478" citStr="Han et al., 2003" startWordPosition="3139" endWordPosition="3142"> F-measure: Averaged F-measure is computed by averaging the F1-measures over all fields. Average F-measure favors labels with small number of words, which complements word accuracy. Thus, we consider both word accuracy and average F-measure in evaluation. 3. Whole instance accuracy: An instance here is defined to be a single header or reference. Whole instance accuracy is the percentage of instances in which every word is correctly labeled. 3.4 Experimental Results We first report the overall results by comparing CRFs with HMMs, and with the previously best benchmark results obtained by SVMs (Han et al., 2003). We then break down the results to analyze various factors individually. Table 1 shows the results on dataset H with the best results in bold; (intro and page fields are not shown, following past practice (Seymore et al., 1999; Han et al., 2003)). The results we obtained with CRFs use secondorder state transition features, layout features, as well as supported and unsupported features. Feature induction is used in experiments on dataset R; (it didn’t improve accuracy on H). The results we obtained with the HMM model use a second order model for transitions, and a first order for observations.</context>
</contexts>
<marker>Han, Giles, Manavoglu, Zha, Zhang, Fox, 2003</marker>
<rawString>H. Han, C. Giles, E. Manavoglu, H. Zha, Z. Zhang, and E. Fox. 2003. Automatic Document Meta-data Extraction using Support Vector Machines. In Proceedings ofJoint Conference on Digital Libraries 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.</title>
<date>2001</date>
<booktitle>In Proceedings ofInternational Conference on Machine Learning</booktitle>
<contexts>
<context position="3013" citStr="Lafferty et al., 2001" startWordPosition="443" endWordPosition="446">M classifiers (Han et al., 2003). These SVM classifiers can handle many nonindependent features. However, for this sequence labeling problem, Han et al. (2003) work in a two stages process: first classifying each line independently to assign it label, then adjusting these labels based on an additional classifier that examines larger windows of labels. Solving the information extraction problem in two steps looses the tight interaction between state transitions and observations. In this paper, we present results on this research paper meta-data extraction task using a Conditional Random Field (Lafferty et al., 2001), and explore several practical issues in applying CRFs to information extraction in general. The CRF approach draws together the advantages of both finite state HMM and discriminative SVM techniques by allowing use of arbitrary, dependent features and joint inference over entire sequences. CRFs have been previously applied to other tasks such as name entity extraction (McCallum and Li, 2003), table extraction (Pinto et al., 2003) and shallow parsing (Sha and Pereira, 2003). The basic theory of CRFs is now well-understood, but the best-practices for applying them to new, real-world data is sti</context>
<context position="4577" citStr="Lafferty et al., 2001" startWordPosition="699" endWordPosition="702">−6 lambda Figure 1: Empirical distribution of A {(xi, yi) : i = 1, ...M} is written XLΛ = log PΛ(yi|xi) i counts of lamda (in log scale) 0 1 2 3 and layout, as well as proposing a method for the beneficial use of zero-count features without incurring large memory penalties. We describe a large collection of experimental results on two traditional benchmark data sets. Dramatic improvements are obtained in comparison with previous SVM and HMM based results. 2 Conditional Random Fields Conditional random fields (CRFs) are undirected graphical models trained to maximize a conditional probability (Lafferty et al., 2001). A common special-case graph structure is a linear chain, which corresponds to a finite state machine, and is suitable for sequence labeling. A linear-chain CRF with parameters A = {A,...} defines a conditional probability for a state (or label1) sequence y = y1...yT given an input sequence x = x1...xT to be 1 X !Akfk(yt−1, yt, x, t) , X= T X !Akfk(yt−1, yt, x, t) − log Zxi . Pλ(y|x) = Z XTt= k (1) i X k (2) exp t=1 1 where ZX is the normalization constant that makes the probability of all state sequences sum to one, fk(yt−1, yt, x, t) is a feature function which is often binary-valued, but c</context>
<context position="21148" citStr="Lafferty et al., 2001" startWordPosition="3434" endWordPosition="3437">7 Date 99.8 80.6 99.9 95.0 99.7 90.2 Abstract 97.1 98.0 99.6 99.7 97.5 93.8 Phone 99.8 53.8 99.9 97.9 99.9 92.4 Keyword 98.7 40.6 99.7 88.8 99.2 88.5 Web 99.9 68.6 99.9 94.1 99.9 92.4 Degree 99.5 68.8 99.8 84.9 99.5 70.1 Pubnum 99.8 64.2 99.9 86.6 99.9 89.2 Average F1 75.6 93.9 89.7 Table 1: Extraction results for paper headers on H Table 2 shows the results on dataset R. SVM results are not available for these datasets. 3.5 Analysis 3.5.1 Overall performance comparison From Table (1, 2), one can see that CRF performs significantly better than HMMs, which again supports the previous findings (Lafferty et al., 2001; Pinto et al., HMM CRF Overall acc. 85.1% 95.37% instance acc. 10% 77.33% acc. F1 acc. F1 Author 96.8 92.7 99.9 99.4 Booktitle 94.4 0.85 97.7 93.7 Date 99.7 96.9 99.8 98.9 Editor 98.8 70.8 99.5 87.7 Institution 98.5 72.3 99.7 94.0 Journal 96.6 67.7 99.1 91.3 Location 99.1 81.8 99.3 87.2 Note 99.2 50.9 99.7 80.8 Pages 98.1 72.9 99.9 98.6 Publisher 99.4 79.2 99.4 76.1 Tech 98.8 74.9 99.4 86.7 Title 92.2 87.2 98.9 98.3 Volume 98.6 75.8 99.9 97.8 Average F1 77.6% 91.5% Table 2: Extraction results for paper references on R 2003). CRFs also perform significantly better than SVMbased approach, yield</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum and F. Pereira. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. In Proceedings ofInternational Conference on Machine Learning 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Lawrence</author>
<author>C L Giles</author>
<author>K Bollacker</author>
</authors>
<title>Digital Libraries and Autonomous Citation Indexing.</title>
<date>1999</date>
<journal>IEEE Computer,</journal>
<volume>32</volume>
<issue>6</issue>
<pages>67--71</pages>
<contexts>
<context position="1337" citStr="Lawrence et al., 1999" startWordPosition="192" endWordPosition="195">ractices for applying them to real-world data requires additional exploration. This paper makes an empirical exploration of several factors, including variations on Gaussian, exponential and hyperbolic-Ll priors for improved regularization, and several classes of features and Markov order. On a standard benchmark data set, we achieve new state-of-the-art performance, reducing error in average F1 by 36%, and word error rate by 78% in comparison with the previous best SVM results. Accuracy compares even more favorably against HMMs. 1 Introduction Research paper search engines, such as CiteSeer (Lawrence et al., 1999) and Cora (McCallum et al., 2000), give researchers tremendous power and convenience in their research. They are also becoming increasingly used for recruiting and hiring decisions. Thus the information quality of such systems is of significant importance. This quality critically depends on an information extraction component that extracts meta-data, such as title, author, institution, etc, from paper headers and references, because these meta-data are further used in many component applications such as field-based search, author analysis, and citation analysis. Previous work in information ex</context>
</contexts>
<marker>Lawrence, Giles, Bollacker, 1999</marker>
<rawString>S. Lawrence, C. L. Giles, and K. Bollacker. 1999. Digital Libraries and Autonomous Citation Indexing. IEEE Computer, 32(6): 67-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Malouf</author>
</authors>
<title>A Comparison of Algorithms for Maximum Entropy Parameter Estimation.</title>
<date>2002</date>
<booktitle>In Proceedings ofthe Sixth Conference on Natural Language Learning (CoNLL)</booktitle>
<contexts>
<context position="7123" citStr="Malouf, 2002" startWordPosition="1129" endWordPosition="1130">ollowing equality, wherein the the empirical count of each feature matches its expected count according to the model PΛ(y|x). X Xfk(yt−1, yt, xi, t) = PΛ(y|x)fk(yt−1, yt, xi, t) i i CRFs share many of the advantageous properties of standard maximum entropy models, including their convex likelihood function, which guarantees that the learning procedure converges to the global maximum. Traditional maximum entropy learning algorithms, such as GIS and IIS (Pietra et al., 1995), can be used to train CRFs, however, it has been found that a quasi-Newton gradient-climber, BFGS, converges much faster (Malouf, 2002; Sha and Pereira, 2003). We use BFGS for optimization. In our experiments, we shall focus instead on two other aspects of CRF deployment, namely regularization and selection of different model structure and feature types. 2.1 Regularization in CRFs To avoid over-fitting, log-likelihood is often penalized by some prior distribution over the parameters. Figure 1 shows an empirical distribution of parameters, A, learned from an unpenalized likelihood, including only features with non-zero count in the training set. Three prior distributions that have shape similar to this empirical distribution </context>
</contexts>
<marker>Malouf, 2002</marker>
<rawString>R. Malouf. 2002. A Comparison of Algorithms for Maximum Entropy Parameter Estimation. In Proceedings ofthe Sixth Conference on Natural Language Learning (CoNLL)</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
</authors>
<title>Efficiently Inducing Features of Conditional Random Fields.</title>
<date>2003</date>
<booktitle>In Proceedings of Conference on Uncertainty in Articifical Intelligence (UAI).</booktitle>
<contexts>
<context position="12166" citStr="McCallum, 2003" startWordPosition="1979" endWordPosition="1981">alternative to the class of normal distributions and has been used for analyzing data from various scientific areas such as finance, though less frequently used in natural language processing. Under a hyperbolic prior, XLΛ = X log(eλk +e �k ) (5) i log PΛ(Yi|Xi) − 2 k which corresponds to satisfying e|ak |− e−|ak| fk(yt−1, yt, xi, t) − e|ak |+ e−|ak| X PΛ(yj-)fi(yt−1, yt, xi, t) i The hyperbolic prior was also tested with CRFs in McCallum and Li (2003). 2.2 Exploration of Feature Space Wise choice of features is always vital the performance of any machine learning solution. Feature induction (McCallum, 2003) has been shown to provide significant improvements in CRFs performance. In some experiments described below we use feature induction. The focus in this section is on three other aspects of the feature space. 2.2.1 State transition features In CRFs, state transitions are also represented as features. The feature function fk(yt−1, yt, x, t) in Equ. (1) is a general function over states and observations. Different state transition features can be defined to form different Markov-order structures. We define four different state transitions features corresponding to different Markov order for diff</context>
</contexts>
<marker>McCallum, 2003</marker>
<rawString>A. McCallum. 2003. Efficiently Inducing Features of Conditional Random Fields. In Proceedings of Conference on Uncertainty in Articifical Intelligence (UAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>K Nigam</author>
<author>J Rennie</author>
<author>K Seymore</author>
</authors>
<date>2000</date>
<journal>Automating the Construction of Internet Portals with Machine Learning. Information Retrieval Journal,</journal>
<volume>3</volume>
<pages>127--163</pages>
<publisher>Kluwer.</publisher>
<contexts>
<context position="1370" citStr="McCallum et al., 2000" startWordPosition="198" endWordPosition="201">l-world data requires additional exploration. This paper makes an empirical exploration of several factors, including variations on Gaussian, exponential and hyperbolic-Ll priors for improved regularization, and several classes of features and Markov order. On a standard benchmark data set, we achieve new state-of-the-art performance, reducing error in average F1 by 36%, and word error rate by 78% in comparison with the previous best SVM results. Accuracy compares even more favorably against HMMs. 1 Introduction Research paper search engines, such as CiteSeer (Lawrence et al., 1999) and Cora (McCallum et al., 2000), give researchers tremendous power and convenience in their research. They are also becoming increasingly used for recruiting and hiring decisions. Thus the information quality of such systems is of significant importance. This quality critically depends on an information extraction component that extracts meta-data, such as title, author, institution, etc, from paper headers and references, because these meta-data are further used in many component applications such as field-based search, author analysis, and citation analysis. Previous work in information extraction from research papers has</context>
<context position="16525" citStr="McCallum et al., 2000" startWordPosition="2651" endWordPosition="2654">irst order observation transitions performs the best. The state transition probabilities and emission probabilities are estimated using maximum likelihood estimation with absolute smoothing, which was found to be effective in previous experiments, including Seymore et al. (1999). 3.2 Datasets We experiment with two datasets of research paper content. One consists of the headers of research papers. The other consists of pre-segmented citations from the reference sections of research papers. These data sets have been used as standard benchmarks in several previous studies (Seymore et al., 1999; McCallum et al., 2000; Han et al., 2003). X i = 3.2.1 Paper header dataset The header of a research paper is defined to be all of the words from the beginning of the paper up to either the first section of the paper, usually the introduction, or to the end of the first page, whichever occurs first. It contains 15 fields to be extracted: title, author, affiliation, address, note, email, date, abstract, introduction, phone, keywords, web, degree, publication number, and page (Seymore et al., 1999). The header dataset contains 935 headers. Following previous research (Seymore et al., 1999; McCallum et al., 2000; Han </context>
</contexts>
<marker>McCallum, Nigam, Rennie, Seymore, 2000</marker>
<rawString>A. McCallum, K. Nigam, J. Rennie, K. Seymore. 2000. Automating the Construction of Internet Portals with Machine Learning. Information Retrieval Journal, volume 3, pages 127-163. Kluwer. 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>W Li</author>
</authors>
<title>Early Results for Named Entity Recognition with Conditional Random Fields, Feature Induction and Web-Enhanced Lexicons.</title>
<date>2003</date>
<booktitle>In Proceedings of Seventh Conference on Natural Language Learning (CoNLL).</booktitle>
<contexts>
<context position="3408" citStr="McCallum and Li, 2003" startWordPosition="505" endWordPosition="508">m in two steps looses the tight interaction between state transitions and observations. In this paper, we present results on this research paper meta-data extraction task using a Conditional Random Field (Lafferty et al., 2001), and explore several practical issues in applying CRFs to information extraction in general. The CRF approach draws together the advantages of both finite state HMM and discriminative SVM techniques by allowing use of arbitrary, dependent features and joint inference over entire sequences. CRFs have been previously applied to other tasks such as name entity extraction (McCallum and Li, 2003), table extraction (Pinto et al., 2003) and shallow parsing (Sha and Pereira, 2003). The basic theory of CRFs is now well-understood, but the best-practices for applying them to new, real-world data is still in an early-exploration phase. Here we explore two key practical issues: (1) regularization, with an empirical study of Gaussian (Chen and Rosenfeld, 2000), exponential (Goodman, 2003), and hyperbolic-Ll (Pinto et al., 2003) priors; (2) exploration of various families of features, including text, lexicons, 12 10 8 6 4 2 0 −5 −4 −3 −2 −1 −6 lambda Figure 1: Empirical distribution of A {(xi,</context>
<context position="12007" citStr="McCallum and Li (2003)" startWordPosition="1953" endWordPosition="1957">olic-L1 prior, described in (Pinto et al., 2003). The hyperbolic distribution has log-linear tails. Consequently the class of hyperbolic distribution is an important alternative to the class of normal distributions and has been used for analyzing data from various scientific areas such as finance, though less frequently used in natural language processing. Under a hyperbolic prior, XLΛ = X log(eλk +e �k ) (5) i log PΛ(Yi|Xi) − 2 k which corresponds to satisfying e|ak |− e−|ak| fk(yt−1, yt, xi, t) − e|ak |+ e−|ak| X PΛ(yj-)fi(yt−1, yt, xi, t) i The hyperbolic prior was also tested with CRFs in McCallum and Li (2003). 2.2 Exploration of Feature Space Wise choice of features is always vital the performance of any machine learning solution. Feature induction (McCallum, 2003) has been shown to provide significant improvements in CRFs performance. In some experiments described below we use feature induction. The focus in this section is on three other aspects of the feature space. 2.2.1 State transition features In CRFs, state transitions are also represented as features. The feature function fk(yt−1, yt, x, t) in Equ. (1) is a general function over states and observations. Different state transition features</context>
</contexts>
<marker>McCallum, Li, 2003</marker>
<rawString>A. McCallum and W. Li. 2003. Early Results for Named Entity Recognition with Conditional Random Fields, Feature Induction and Web-Enhanced Lexicons. In Proceedings of Seventh Conference on Natural Language Learning (CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ney</author>
<author>U Essen</author>
<author>R Kneser</author>
</authors>
<title>On the Estimation of Small Probabilities by Leaving-One-Out.</title>
<date>1995</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<pages>17--12</pages>
<contexts>
<context position="11323" citStr="Ney et al., 1995" startWordPosition="1839" endWordPosition="1842">ralization. Goodman (2003) proposes an exponential prior, specifically a Laplacian prior, as an alternative to Gaussian prior. Under this prior, XLA = log PA(yi|xi) − X αk|λk |(4) i k where αk is a parameter in exponential distribution. Maximizing (4) would satisfy X Xfk(yt−1, yt, xi, t)−αk = PA(y|x)fk(yt−1, yt, xi, t) i i This corresponds to the absolute smoothing method in language modeling. We set the αk = α; i.e. all features share the same constant whose value can be determined using absolute discounting α = n1 n1+2n2 , where n1 and n2 are the number of features occurring once and twice (Ney et al., 1995). 2.1.3 Hyperbolic-L1 prior Another L1 penalizer is the hyperbolic-L1 prior, described in (Pinto et al., 2003). The hyperbolic distribution has log-linear tails. Consequently the class of hyperbolic distribution is an important alternative to the class of normal distributions and has been used for analyzing data from various scientific areas such as finance, though less frequently used in natural language processing. Under a hyperbolic prior, XLΛ = X log(eλk +e �k ) (5) i log PΛ(Yi|Xi) − 2 k which corresponds to satisfying e|ak |− e−|ak| fk(yt−1, yt, xi, t) − e|ak |+ e−|ak| X PΛ(yj-)fi(yt−1, y</context>
</contexts>
<marker>Ney, Essen, Kneser, 1995</marker>
<rawString>H. Ney, U. Essen, and R. Kneser 1995. On the Estimation of Small Probabilities by Leaving-One-Out. IEEE Transactions on Pattern Analysis and Machine Intelligence, 17(12):1202-1212, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pietra</author>
<author>V Pietra</author>
<author>J Lafferty</author>
</authors>
<title>Inducing Features Of Random Fields.</title>
<date>1995</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>19</volume>
<contexts>
<context position="6988" citStr="Pietra et al., 1995" startWordPosition="1106" endWordPosition="1109">a one-to-one correspondence between states and labels; this is not, however, strictly necessary. Maximizing (2) corresponds to satisfying the following equality, wherein the the empirical count of each feature matches its expected count according to the model PΛ(y|x). X Xfk(yt−1, yt, xi, t) = PΛ(y|x)fk(yt−1, yt, xi, t) i i CRFs share many of the advantageous properties of standard maximum entropy models, including their convex likelihood function, which guarantees that the learning procedure converges to the global maximum. Traditional maximum entropy learning algorithms, such as GIS and IIS (Pietra et al., 1995), can be used to train CRFs, however, it has been found that a quasi-Newton gradient-climber, BFGS, converges much faster (Malouf, 2002; Sha and Pereira, 2003). We use BFGS for optimization. In our experiments, we shall focus instead on two other aspects of CRF deployment, namely regularization and selection of different model structure and feature types. 2.1 Regularization in CRFs To avoid over-fitting, log-likelihood is often penalized by some prior distribution over the parameters. Figure 1 shows an empirical distribution of parameters, A, learned from an unpenalized likelihood, including o</context>
</contexts>
<marker>Pietra, Pietra, Lafferty, 1995</marker>
<rawString>S. Pietra, V. Pietra, J. Lafferty 1995. Inducing Features Of Random Fields. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 19, No. 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Pinto</author>
<author>A McCallum</author>
<author>X Wei</author>
<author>W Croft</author>
</authors>
<title>Table Extraction Using Conditional Random Fields.</title>
<date>2003</date>
<booktitle>In Proceedins of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’03)</booktitle>
<contexts>
<context position="3447" citStr="Pinto et al., 2003" startWordPosition="511" endWordPosition="514">n between state transitions and observations. In this paper, we present results on this research paper meta-data extraction task using a Conditional Random Field (Lafferty et al., 2001), and explore several practical issues in applying CRFs to information extraction in general. The CRF approach draws together the advantages of both finite state HMM and discriminative SVM techniques by allowing use of arbitrary, dependent features and joint inference over entire sequences. CRFs have been previously applied to other tasks such as name entity extraction (McCallum and Li, 2003), table extraction (Pinto et al., 2003) and shallow parsing (Sha and Pereira, 2003). The basic theory of CRFs is now well-understood, but the best-practices for applying them to new, real-world data is still in an early-exploration phase. Here we explore two key practical issues: (1) regularization, with an empirical study of Gaussian (Chen and Rosenfeld, 2000), exponential (Goodman, 2003), and hyperbolic-Ll (Pinto et al., 2003) priors; (2) exploration of various families of features, including text, lexicons, 12 10 8 6 4 2 0 −5 −4 −3 −2 −1 −6 lambda Figure 1: Empirical distribution of A {(xi, yi) : i = 1, ...M} is written XLΛ = lo</context>
<context position="11433" citStr="Pinto et al., 2003" startWordPosition="1856" endWordPosition="1859">to Gaussian prior. Under this prior, XLA = log PA(yi|xi) − X αk|λk |(4) i k where αk is a parameter in exponential distribution. Maximizing (4) would satisfy X Xfk(yt−1, yt, xi, t)−αk = PA(y|x)fk(yt−1, yt, xi, t) i i This corresponds to the absolute smoothing method in language modeling. We set the αk = α; i.e. all features share the same constant whose value can be determined using absolute discounting α = n1 n1+2n2 , where n1 and n2 are the number of features occurring once and twice (Ney et al., 1995). 2.1.3 Hyperbolic-L1 prior Another L1 penalizer is the hyperbolic-L1 prior, described in (Pinto et al., 2003). The hyperbolic distribution has log-linear tails. Consequently the class of hyperbolic distribution is an important alternative to the class of normal distributions and has been used for analyzing data from various scientific areas such as finance, though less frequently used in natural language processing. Under a hyperbolic prior, XLΛ = X log(eλk +e �k ) (5) i log PΛ(Yi|Xi) − 2 k which corresponds to satisfying e|ak |− e−|ak| fk(yt−1, yt, xi, t) − e|ak |+ e−|ak| X PΛ(yj-)fi(yt−1, yt, xi, t) i The hyperbolic prior was also tested with CRFs in McCallum and Li (2003). 2.2 Exploration of Featu</context>
</contexts>
<marker>Pinto, McCallum, Wei, Croft, 2003</marker>
<rawString>D. Pinto, A. McCallum, X. Wei and W. Croft. 2003. Table Extraction Using Conditional Random Fields. In Proceedins of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’03)</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Seymore</author>
<author>A McCallum</author>
<author>R Rosenfeld</author>
</authors>
<title>Learning Hidden Markov Model Structure for Information Extraction.</title>
<date>1999</date>
<booktitle>In Proceedings of AAAI’99 Workshop on Machine Learning for Information Extraction.</booktitle>
<contexts>
<context position="2085" citStr="Seymore et al., 1999" startWordPosition="304" endWordPosition="307">ncreasingly used for recruiting and hiring decisions. Thus the information quality of such systems is of significant importance. This quality critically depends on an information extraction component that extracts meta-data, such as title, author, institution, etc, from paper headers and references, because these meta-data are further used in many component applications such as field-based search, author analysis, and citation analysis. Previous work in information extraction from research papers has been based on two major machine learning techniques. The first is hidden Markov models (HMM) (Seymore et al., 1999; Takasu, 2003). An HMM learns a generative model over input sequence and labeled sequence pairs. While enjoying wide historical success, standard HMM models have difficulty modeling multiple non-independent features of the observation sequence. The second technique is based on discriminatively-trained SVM classifiers (Han et al., 2003). These SVM classifiers can handle many nonindependent features. However, for this sequence labeling problem, Han et al. (2003) work in a two stages process: first classifying each line independently to assign it label, then adjusting these labels based on an ad</context>
<context position="16183" citStr="Seymore et al. (1999)" startWordPosition="2596" endWordPosition="2599">re we also briefly describe a HMM model we used in our experiments. We relax the independence assumption made in standard HMM and allow Markov dependencies among observations, e.g., P(otlst, ot−1). We can vary Markov orders in state transition and observation transitions. In our experiments, a model with second order state transitions and first order observation transitions performs the best. The state transition probabilities and emission probabilities are estimated using maximum likelihood estimation with absolute smoothing, which was found to be effective in previous experiments, including Seymore et al. (1999). 3.2 Datasets We experiment with two datasets of research paper content. One consists of the headers of research papers. The other consists of pre-segmented citations from the reference sections of research papers. These data sets have been used as standard benchmarks in several previous studies (Seymore et al., 1999; McCallum et al., 2000; Han et al., 2003). X i = 3.2.1 Paper header dataset The header of a research paper is defined to be all of the words from the beginning of the paper up to either the first section of the paper, usually the introduction, or to the end of the first page, whi</context>
<context position="19705" citStr="Seymore et al., 1999" startWordPosition="3180" endWordPosition="3183">verage F-measure in evaluation. 3. Whole instance accuracy: An instance here is defined to be a single header or reference. Whole instance accuracy is the percentage of instances in which every word is correctly labeled. 3.4 Experimental Results We first report the overall results by comparing CRFs with HMMs, and with the previously best benchmark results obtained by SVMs (Han et al., 2003). We then break down the results to analyze various factors individually. Table 1 shows the results on dataset H with the best results in bold; (intro and page fields are not shown, following past practice (Seymore et al., 1999; Han et al., 2003)). The results we obtained with CRFs use secondorder state transition features, layout features, as well as supported and unsupported features. Feature induction is used in experiments on dataset R; (it didn’t improve accuracy on H). The results we obtained with the HMM model use a second order model for transitions, and a first order for observations. The results on SVM is obtained from (Han et al., 2003) by computing F1 measures from the precision and recall numbers they report. HMM CRF SVM Overall acc. 93.1% 98.3% 92.9% Instance acc. 4.13% 73.3% - acc. F1 acc. F1 acc. F1 </context>
</contexts>
<marker>Seymore, McCallum, Rosenfeld, 1999</marker>
<rawString>K. Seymore, A. McCallum, R. Rosenfeld. 1999. Learning Hidden Markov Model Structure for Information Extraction. In Proceedings of AAAI’99 Workshop on Machine Learning for Information Extraction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sha</author>
<author>F Pereira</author>
</authors>
<title>Shallow Parsing with Conditional Random Fields.</title>
<date>2003</date>
<booktitle>In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics (HLT-NAACL’03)</booktitle>
<contexts>
<context position="3491" citStr="Sha and Pereira, 2003" startWordPosition="518" endWordPosition="521">ons. In this paper, we present results on this research paper meta-data extraction task using a Conditional Random Field (Lafferty et al., 2001), and explore several practical issues in applying CRFs to information extraction in general. The CRF approach draws together the advantages of both finite state HMM and discriminative SVM techniques by allowing use of arbitrary, dependent features and joint inference over entire sequences. CRFs have been previously applied to other tasks such as name entity extraction (McCallum and Li, 2003), table extraction (Pinto et al., 2003) and shallow parsing (Sha and Pereira, 2003). The basic theory of CRFs is now well-understood, but the best-practices for applying them to new, real-world data is still in an early-exploration phase. Here we explore two key practical issues: (1) regularization, with an empirical study of Gaussian (Chen and Rosenfeld, 2000), exponential (Goodman, 2003), and hyperbolic-Ll (Pinto et al., 2003) priors; (2) exploration of various families of features, including text, lexicons, 12 10 8 6 4 2 0 −5 −4 −3 −2 −1 −6 lambda Figure 1: Empirical distribution of A {(xi, yi) : i = 1, ...M} is written XLΛ = log PΛ(yi|xi) i counts of lamda (in log scale)</context>
<context position="7147" citStr="Sha and Pereira, 2003" startWordPosition="1131" endWordPosition="1134">ity, wherein the the empirical count of each feature matches its expected count according to the model PΛ(y|x). X Xfk(yt−1, yt, xi, t) = PΛ(y|x)fk(yt−1, yt, xi, t) i i CRFs share many of the advantageous properties of standard maximum entropy models, including their convex likelihood function, which guarantees that the learning procedure converges to the global maximum. Traditional maximum entropy learning algorithms, such as GIS and IIS (Pietra et al., 1995), can be used to train CRFs, however, it has been found that a quasi-Newton gradient-climber, BFGS, converges much faster (Malouf, 2002; Sha and Pereira, 2003). We use BFGS for optimization. In our experiments, we shall focus instead on two other aspects of CRF deployment, namely regularization and selection of different model structure and feature types. 2.1 Regularization in CRFs To avoid over-fitting, log-likelihood is often penalized by some prior distribution over the parameters. Figure 1 shows an empirical distribution of parameters, A, learned from an unpenalized likelihood, including only features with non-zero count in the training set. Three prior distributions that have shape similar to this empirical distribution are the Gaussian prior, </context>
</contexts>
<marker>Sha, Pereira, 2003</marker>
<rawString>F. Sha and F. Pereira. 2003. Shallow Parsing with Conditional Random Fields. In Proceedings of Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics (HLT-NAACL’03)</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Takasu</author>
</authors>
<title>Bibliographic Attribute Extraction from Erroneous References Based on a Statistical Model.</title>
<date>2003</date>
<booktitle>In Proceedings ofJoint Conference on Digital Libraries</booktitle>
<contexts>
<context position="2100" citStr="Takasu, 2003" startWordPosition="308" endWordPosition="309">ecruiting and hiring decisions. Thus the information quality of such systems is of significant importance. This quality critically depends on an information extraction component that extracts meta-data, such as title, author, institution, etc, from paper headers and references, because these meta-data are further used in many component applications such as field-based search, author analysis, and citation analysis. Previous work in information extraction from research papers has been based on two major machine learning techniques. The first is hidden Markov models (HMM) (Seymore et al., 1999; Takasu, 2003). An HMM learns a generative model over input sequence and labeled sequence pairs. While enjoying wide historical success, standard HMM models have difficulty modeling multiple non-independent features of the observation sequence. The second technique is based on discriminatively-trained SVM classifiers (Han et al., 2003). These SVM classifiers can handle many nonindependent features. However, for this sequence labeling problem, Han et al. (2003) work in a two stages process: first classifying each line independently to assign it label, then adjusting these labels based on an additional classi</context>
</contexts>
<marker>Takasu, 2003</marker>
<rawString>A. Takasu. 2003. Bibliographic Attribute Extraction from Erroneous References Based on a Statistical Model. In Proceedings ofJoint Conference on Digital Libraries 2003.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>