<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000362">
<title confidence="0.9972095">
Exploring Different Representational Units in English-to-Turkish Statistical
Machine Translation
</title>
<author confidence="0.987725">
Kemal Oflazert,t
</author>
<affiliation confidence="0.9862535">
tLanguage Technologies Institute
Carnegie Mellon University
</affiliation>
<address confidence="0.569846">
Pittsburgh, PA, 15213, USA
</address>
<email confidence="0.998368">
oflazer@sabanciuniv.edu
</email>
<author confidence="0.934182">
ilknur Durgar El-Kahloutt
</author>
<affiliation confidence="0.845948">
t Faculty of Engineering and Natural Sciences
Sabancı University
Istanbul, Tuzla, 34956, Turkey
</affiliation>
<email confidence="0.998309">
ilknurdurgar@su.sabanciuniv.edu
</email>
<sectionHeader confidence="0.997388" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99998435">
We investigate different representational
granularities for sub-lexical representation
in statistical machine translation work from
English to Turkish. We find that (i) rep-
resenting both Turkish and English at the
morpheme-level but with some selective
morpheme-grouping on the Turkish side of
the training data, (ii) augmenting the train-
ing data with “sentences” comprising only
the content words of the original training
data to bias root word alignment, (iii) re-
ranking the n-best morpheme-sequence out-
puts of the decoder with a word-based lan-
guage model, and (iv) using model iteration
all provide a non-trivial improvement over
a fully word-based baseline. Despite our
very limited training data, we improve from
20.22 BLEU points for our simplest model
to 25.08 BLEU points for an improvement
of 4.86 points or 24% relative.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999842096774194">
Statistical machine translation (SMT) from English-
to-Turkish poses a number of difficulties. Typo-
logically English and Turkish are rather distant lan-
guages: while English has very limited morphology
and rather fixed SVO constituent order, Turkish is an
agglutinative language with a very rich and produc-
tive derivational and inflectional morphology, and a
very flexible (but SOV dominant) constituent order.
Another issue of practical significance is the lack of
large scale parallel text resources, with no substan-
tial improvement expected in the near future.
In this paper, we investigate different represen-
tational granularities for sub-lexical representation
of parallel data for English-to-Turkish phrase-based
SMT and compare them with a word-based base-
line. We also employ two-levels of language mod-
els: the decoder uses a morpheme based LM while it
is generating an n-best list. The n-best lists are then
rescored using a word-based LM.
The paper is structured as follows: We first briefly
discuss issues in SMT and Turkish, and review re-
lated work. We then outline how we exploit mor-
phology, and present results from our baseline and
morphologically segmented models, followed by
some sample outputs. We then describe discuss
model iteration. Finally, we present a comprehen-
sive discussion of our approach and results, and
briefly discuss word-repair – fixing morphologicaly
malformed words – and offer a few ideas about the
adaptation of BLEU to morphologically complex
languages like Turkish.
</bodyText>
<sectionHeader confidence="0.940939" genericHeader="introduction">
2 Turkish and SMT
</sectionHeader>
<bodyText confidence="0.999953823529412">
Our previous experience with SMT into Turkish
(Durgar El-Kahlout and Oflazer, 2006) hinted that
exploiting sub-lexical structure would be a fruitful
avenue to pursue. This was based on the observation
that a Turkish word would have to align with a com-
plete phrase on the English side, and that sometimes
these phrases on the English side could be discontin-
uous. Figure 1 shows a pair of English and Turkish
sentences that are aligned at the word (top) and mor-
pheme (bottom) levels. At the morpheme level, we
have split the Turkish words into their lexical mor-
phemes while English words with overt morphemes
have been stemmed, and such morphemes have been
marked with a tag.
The productive morphology of Turkish implies
potentially a very large vocabulary size. Thus,
sparseness which is more acute when very modest
</bodyText>
<page confidence="0.983533">
25
</page>
<note confidence="0.9902135">
Proceedings of the Second Workshop on Statistical Machine Translation, pages 25–32,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999817">
Figure 1: Word and morpheme alignments for a pair of English-Turkish sentences
</figureCaption>
<bodyText confidence="0.999909516129032">
parallel resources are available becomes an impor-
tant issue. However, Turkish employs about 30,000
root words and about 150 distinct suffixes, so when
morphemes are used as the units in the parallel texts,
the sparseness problem can be alleviated to some ex-
tent.
Our approach in this paper is to represent Turk-
ish words with their morphological segmentation.
We use lexical morphemes instead of surface mor-
phemes, as most surface distinctions are man-
ifestations of word-internal phenomena such as
vowel harmony, and morphotactics. With lexi-
cal morpheme representation, we can abstract away
such word-internal details and conflate statistics for
seemingly different suffixes, as at this level of repre-
sentation words that look very different on the sur-
face, look very similar.1 For instance, although the
words evinde ’in his house’ and masasında ’on his
table’ look quite different, the lexical morphemes
except for the root are the same: ev+sH+ndA vs.
masa+sH+ndA.
We should however note that although employ-
ing a morpheme based representations dramatically
reduces the vocabulary size on the Turkish side, it
also runs the risk of overloading distortion mecha-
nisms to account for both word-internal morpheme
sequencing and sentence level word ordering.
The segmentation of a word in general is not
unique. We first generate a representation that con-
tains both the lexical segments and the morpho-
logical features encoded for all possible segmenta-
</bodyText>
<footnote confidence="0.9691035">
1This is in a sense very similar to the more general problem
of lexical redundancy addressed by Talbot and Osborne (2006)
but our approach does not require the more sophisticated solu-
tion there.
</footnote>
<bodyText confidence="0.765106">
tions and interpretations of the word. For the word
emeli for instance, our morphological analyzer gen-
erates the following with lexical morphemes brack-
eted with (..):
</bodyText>
<equation confidence="0.911686166666667">
(em)em+Verb+Pos(+yAlH)ˆDB+Adverb+Since
since (someone) sucked (something)
(emel)emel+Noun+A3sg(+sH)+P3sg+Nom
his/her ambition
(emel)emel+Noun+A3sg+Pnon(+yH)+Acc
ambition (as object of a transitive verb)
</equation>
<bodyText confidence="0.991939739130435">
These analyses are then disambiguated with a sta-
tistical disambiguator (Y¨uret and T¨ure, 2006) which
operates on the morphological features.2 Finally, the
morphological features are removed from each parse
leaving the lexical morphemes.
Using morphology in SMT has been recently ad-
dressed by researchers translation from or into mor-
phologically rich(er) languages. Niessen and Ney
(2004) have used morphological decomposition to
improve alignment quality. Yang and Kirchhoff
(2006) use phrase-based backoff models to translate
words that are unknown to the decoder, by morpho-
logically decomposing the unknown source word.
They particularly apply their method to translating
from Finnish – another language with very similar
structural characteristics to Turkish. Corston-Oliver
and Gamon (2004) normalize inflectional morphol-
ogy by stemming the word for German-English
word alignment. Lee (2004) uses a morphologically
analyzed and tagged parallel corpus for Arabic-
English SMT. Zolmann et al. (2006) also exploit
morphology in Arabic-English SMT. Popovic and
Ney (2004) investigate improving translation qual-
</bodyText>
<footnote confidence="0.991237">
2This disambiguator has about 94% accuracy.
</footnote>
<page confidence="0.998635">
26
</page>
<bodyText confidence="0.99956325">
ity from inflected languages by using stems, suffixes
and part-of-speech tags. Goldwater and McClosky
(2005) use morphological analysis on Czech text to
get improvements in Czech to English SMT. Re-
cently, Minkov et al. (2007) have used morphologi-
cal postprocessing on the output side using structural
information and information from the source side, to
improve SMT quality.
</bodyText>
<sectionHeader confidence="0.984605" genericHeader="method">
3 Exploiting Morphology
</sectionHeader>
<bodyText confidence="0.973482928571429">
Our parallel data consists mainly of documents in
international relations and legal documents from
sources such as the Turkish Ministry of Foreign Af-
fairs, EU, etc. We process these as follows: (i) We
segment the words in our Turkish corpus into lex-
ical morphemes whereby differences in the surface
representations of morphemes due to word-internal
phenomena are abstracted out to improve statistics
during alignment.3 (ii) We tag the English side us-
ing TreeTagger (Schmid, 1994), which provides a
lemma and a part-of-speech for each word. We then
remove any tags which do not imply an explicit mor-
pheme or an exceptional form. So for instance, if
the word book gets tagged as +NN, we keep book
in the text, but remove +NN. For books tagged as
+NNS or booking tagged as +VVG, we keep book
and +NNS, and book and +VVG. A word like went is
replaced by go +VVD.4 (iii) From these morpholog-
ically segmented corpora, we also extract for each
sentence, the sequence of roots for open class con-
tent words (nouns, adjectives, adverbs, and verbs).
For Turkish, this corresponds to removing all mor-
phemes and any roots for closed classes. For En-
glish, this corresponds to removing all words tagged
as closed class words along with the tags such as
+VVG above that signal a morpheme on an open
class content word. We use this to augment the train-
ing corpus and bias content word alignments, with
the hope that such roots may get a chance to align
without any additional “noise” from morphemes and
other function words.
From such processed data, we compile the data
sets whose statistics are listed in Table 1. One can
note that Turkish has many more distinct word forms
(about twice as many as English), but has much less
3So for example, the surface plural morphemes +ler and
+lar get conflated to +lAr and their statistics are hence com-
bined.
4Ideally, it would have been very desirable to actually do
derivational morphological analysis on the English side, so that
one could for example analyze accession into access plus a
marker indicating nominalization.
</bodyText>
<table confidence="0.999428">
Turkish Sent. Words (UNK) Uniq. Words
Train 45,709 557,530 52,897
Train-Content 56,609 436,762 13,767
Tune 200 3,258 1,442
Test 649 10,334 (545) 4,355
English
Train 45,709 723,399 26,747
Train-Content 56,609 403,162 19,791
Test 649 13,484 (231) 3,220
Turkish Morph- Uniq. Morp./ Uniq. Uniq.
emes Morp. Word Roots Suff.
Train 1,005,045 15,081 1.80 14,976 105
Tune 6,240 859 1.92 810 49
Test 18,713 2,297 1.81 2,220 77
</table>
<tableCaption confidence="0.999005">
Table 1: Statistics on Turkish and English training
</tableCaption>
<bodyText confidence="0.99063">
and test data, and Turkish morphological structure
number of distinct content words than English.5 For
language models in decoding and n-best list rescor-
ing, we use, in addition to the training data, a mono-
lingual Turkish text of about 100,000 sentences (in
a segmented and disambiguated form).
A typical sentence pair in our data looks like
the following, where we have highlighted the con-
tent root words with bold font, coindexed them to
show their alignments and bracketed the “words”
that evaluation on test would consider.
</bodyText>
<listItem confidence="0.93885325">
• T: [kat1 +hl +ma] [ortaklık2 +sh +nhn]
[uygula3 +hn +ma +sh] [,] [ortaklık4]
[anlas¸ma5 +sh] [c¸erc¸eve6 +sh +nda]
[izle7 +hn +yacak +dhr] [.]
• E: the implementation3 of the acces-
sion1 partnership2 will be monitor7
+vvn in the framework6 of the
association4 agreement5 .
</listItem>
<bodyText confidence="0.99558625">
Note that when the morphemes/tags (starting with
a +) are concatenated, we get the “word-based”
version of the corpus, since surface words are di-
rectly recoverable from the concatenated represen-
tation. We use this word-based representation also
for word-based language models used for rescoring.
We employ the phrase-based SMT framework
(Koehn et al., 2003), and use the Moses toolkit
(Koehn et al., 2007), and the SRILM language mod-
elling toolkit (Stolcke, 2002), and evaluate our de-
coded translations using the BLEU measure (Pap-
ineni et al., 2002), using a single reference transla-
tion.
5The training set in the first row of 1 was limited to sen-
tences on the Turkish side which had at most 90 tokens (roots
and bound morphemes) in total in order to comply with require-
ments of the GIZA++ alignment tool. However when only the
content words are included, we have more sentences to include
since much less number of sentences violate the length restric-
tion when morphemes/function word are removed.
</bodyText>
<page confidence="0.994293">
27
</page>
<table confidence="0.980975666666667">
Moses Dec. Parms. BLEU BLEU-c
Default 16.29 16.13
dl = -1, -weight-d = 0.1 20.16 19.77
</table>
<tableCaption confidence="0.995778">
Table 2: BLEU results for baseline experiments.
</tableCaption>
<bodyText confidence="0.920658">
BLEU is for the model trained on the training set
BLEU-C is for the model trained on training set augmented with
the content words.
</bodyText>
<subsectionHeader confidence="0.999895">
3.1 The Baseline System
</subsectionHeader>
<bodyText confidence="0.999995866666667">
As a baseline system, we trained a model using
default Moses parameters (e.g., maximum phrase
length = 7), using the word-based training corpus.
The English test set was decoded with both default
decoder parameters and with the distortion limit (-dl
in Moses) set to unlimited (-1 in Moses) and distor-
tion weight (-weight-d in Moses) set to a very low
value of 0.1 to allow for long distance distortions.6
We also augmented the training set with the con-
tent word data and trained a second baseline model.
Minimum error rate training with the tune set did not
provide any tangible improvements.7 Table 2 shows
the BLEU results for baseline performance. It can
be seen that adding the content word training data
actually hampers the baseline performance.
</bodyText>
<subsectionHeader confidence="0.996666">
3.2 Fully Morphologically Segmented Model
</subsectionHeader>
<bodyText confidence="0.965415835820896">
We now trained a model using the fully morpho-
logically segmented training corpus with and with-
out content word parallel corpus augmentation. For
decoding, we used a 5-gram morpheme-based lan-
guage model with the hope of capturing local mor-
photactic ordering constraints, and perhaps some
sentence level ordering of words.8 We then decoded
and obtained 1000-best lists. The 1000-best sen-
tences were then converted to ”words” (by concate-
nating the morphemes) and then rescored with a 4-
gram word-based language model with the hope of
enforcing more distant word sequencing constraints.
For this, we followed the following procedure: We
6We arrived at this combination by experimenting with the
decoder to avoid the almost monotonic translation we were get-
ting with the default parameters.
7We ran MERT on the baseline model and the morphologi-
cally segmented models forcing -weight-d to range a very small
around 0.1, but letting the other parameters range in their sug-
gested ranges. Even though the procedure came back claiming
that it achieved a better BLEU score on the tune set, running
the new model on the test set did not show any improvement at
all. This may have been due to the fact that the initial choice
of -weight-d along with -dl set to 1 provides such a drastic
improvement that perturbations in the other parameters do not
have much impact.
8Given that on the average we have almost two bound mor-
phemes per “word” (for inflecting word classes), a morpheme
5-gram would cover about 2 “words”.
tried various linear combinations of the word-based
language model and the translation model scores on
the tune corpus, and used the combination that per-
formed best to evaluate the test corpus. We also ex-
perimented with both the default decoding parame-
ters, and the modified parameters used in the base-
line model decoding above.
The results in Table 3 indicate that the default de-
coding parameters used by the Moses decoder pro-
vide a very dismal results – much below the baseline
scores. We can speculate that as the constituent or-
ders of Turkish and English are very different, (root)
words may have to be scrambled to rather long dis-
tances along with the translations of functions words
and tags on the English side, to morphemes on the
Turkish side. Thus limiting maximum distortion
and penalizing distortions with the default higher
weight, result in these low BLEU results. Allowing
the decoder to consider longer range distortions and
penalizing such distortions much less with the mod-
ified decoding parameters, seem to make an enor-
mous difference in this case, providing close to al-
most 7 BLEU points improvement.9
We can also see that, contrary to the case with
the baseline word-based experiments, using the ad-
ditional content word corpus for training actually
provides a tangible improvement (about 6.2% rel-
ative (w/o rescoring)), most likely due to slightly
better alignments when content words are used.10
Rescoring the 1000-best sentence output with a 4-
gram word-based language model provides an addi-
tional 0.79 BLEU points (about 4% relative) – from
20.22 to 21.01 – for the model with the basic train-
ing set, and an additional 0.71 BLEU points (about
3% relative) – from 21.47 to 22.18– for the model
with the augmented training set. The cumulative im-
provement is 1.96 BLEU points or about 9.4% rela-
tive.
</bodyText>
<subsectionHeader confidence="0.998314">
3.3 Selectively Segmented Model
</subsectionHeader>
<bodyText confidence="0.999565666666667">
A systematic analysis of the alignment files pro-
duced by GIZA++ for a small subset of the train-
ing sentences showed that certain morphemes on the
</bodyText>
<footnote confidence="0.997616888888889">
9The “morpheme” BLEU scores are much higher (34.43
on the test set) where we measure BLEU using decoded mor-
phemes as tokens. This is just indicative and but correlates with
word-level BLEU which we report in Table 3, and can be used
to gauge relative improvements to the models.
10We also constructed phrase tables only from the actual
training set (w/o the content word section) after the alignment
phase. The resulting models fared slightly worse though we do
not yet understand why.
</footnote>
<page confidence="0.980348">
28
</page>
<table confidence="0.9987584">
Moses Dec. Parms. BLEU BLEU-c
Default 13.55 NA
dl = -1, -weight-d = 0.1 20.22 21.47
dl = -1, -weight-d = 0.1 21.01 22.18
+ word-level LM rescoring
</table>
<tableCaption confidence="0.986975">
Table 3: BLEU results for experiments with fully
morphologically segmented training set
</tableCaption>
<bodyText confidence="0.999246">
Turkish side were almost consistently never aligned
with anything on the English side: e.g., the com-
pound noun marker morpheme in Turkish (+sh) does
not have a corresponding unit on the English side
since English noun-noun compounds do not carry
any overt markers. Such markers were never aligned
to anything or were aligned almost randomly to to-
kens on the English side. Since we perform deriva-
tional morphological analysis on the Turkish side
but not on the English side, we noted that most ver-
bal nominalizations on the English side were just
aligned to the verb roots on the Turkish side and
the additional markers on the Turkish side indicat-
ing the nominalization and agreement markers etc.,
were mostly unaligned.
For just these cases, we selectively attached such
morphemes (and in the case of verbs, the interven-
ing morphemes) to the root, but otherwise kept other
morphemes, especially any case morphemes, still by
themselves, as they almost often align with preposi-
tions on the English side quite accurately.11
This time, we trained a model on just the content-
word augmented training corpus, with the better per-
forming parameters for the decoder and again did
1000-best rescoring.12 The results for this experi-
ment are shown in Table 4. The resulting BLEU
represents 2.43 points (11% relative) improvement
over the best fully segmented model (and 4.39 points
21.7% compared to the very initial morphologically
segmented model). This is a very encouraging result
that indicates we should perhaps consider a much
more detailed analysis of morpheme alignments to
uncover additional morphemes with similar status.
Table 5 provides additional details on the BLEU
11It should be noted that what to selectively attach to the root
should be considered on a per-language basis; if Turkish were
to be aligned with a language with similar morphological mark-
ers, this perhaps would not have been needed. Again one per-
haps can use methods similar to those suggested by Talbot and
Osborne (2006).
12Decoders for the fully-segmented model and selectively
segmented model use different 5-gram language models, since
the language model corpus should have the same selectively
segmented units as those in the training set. However, the word-
level language models used in rescoring are the same.
</bodyText>
<table confidence="0.998395428571428">
Moses Dec. Parms. BLEU-c
dl = -1, -weight-d = 0.1 22.18
+ word-level LM rescoring
(Full Segmentation (from Table 3))
dl = -1, -weight-d = 0.1 23.47
dl = -1, -weight-d = 0.1 24.61
+ word-level LM rescoring
</table>
<tableCaption confidence="0.994526666666667">
Table 4: BLEU results for experiments with selec-
tively segmented and content-word augmented train-
ing set
</tableCaption>
<table confidence="0.999923375">
Range Sent. BLEU-c
1 - 10 172 44.36
1 - 15 276 34.63
5 - 15 217 33.00
1 - 20 369 28.84
1 - 30 517 27.88
1 - 40 589 24.90
All 649 24.61
</table>
<tableCaption confidence="0.938416">
Table 5: BLEU Scores for different ranges of
</tableCaption>
<bodyText confidence="0.718266333333333">
(source) sentence length for the result in Table 4
scores for this model, for different ranges of (En-
glish source) sentence length.
</bodyText>
<sectionHeader confidence="0.826033" genericHeader="method">
4 Sample Rules and Translations
</sectionHeader>
<bodyText confidence="0.991337941176471">
We have extracted some additional statistics from
the translations produced from English test set. Of
the 10,563 words in the decoded test set, a total of
957 words (9.0 %) were not seen in the training cor-
pus. However, interestingly, of these 957 words, 432
(45%) were actually morphologically well-formed
(some as complex as having 4-5 morphemes!) This
indicates that the phrase-based translation model
is able to synthesize novel complex words.13 In
fact, some phrase table entries seem to capture
morphologically marked subcategorization patterns.
An example is the phrase translation pair
after examine +vvg =:&gt;.
+acc incele+dhk +abl sonra
which very much resembles a typical structural
transfer rule one would find in a symbolic machine
translation system
</bodyText>
<equation confidence="0.623751">
PP(after examine +vvg NP,,,) =:&gt;.
PP(NPtu,k+acc incele+dhk +abl sonra)
</equation>
<bodyText confidence="0.9994592">
in that the accusative marker is tacked to the
translation of the English NP.
Figure 2 shows how segments are translated to
Turkish for a sample sentence. Figure 3 shows the
translations of three sentences from the test data
</bodyText>
<footnote confidence="0.985528">
13Though whether such words are actually correct in their
context is not necessarily clear.
</footnote>
<page confidence="0.996413">
29
</page>
<figure confidence="0.499242444444444">
c¸ocuk [[ child ]]
hak+lar+sh +nhn [[ +nns +pos right ]]
koru+hn+ma+sh [[ protection ]]
+nhn [[ of ]]
tes¸vik et+hl+ma+sh [[ promote ]]
+loc [[ +nns in ]] ab [[ eu ]]
ve ulus+lararasi standart +lar
[[ and international standard +nns ]]
+dat uygun [[ line with ]] +dhr . [[ .]]
</figure>
<figureCaption confidence="0.861929153846154">
Figure 2: Phrasal translations selected for a sample
sentence
Inp.: 1 . everyone’s right to life shall be protected by law .
Trans.: 1 . herkesin yas¸ama hakki kanunla korunur.
Lit.: everyone’s living right is protected with law .
Ref.: 1 . herkesin yas¸am hakki yasanin korumasi altindadir .
Lit.: everyone’s life right is under the protection of the law.
Inp.: promote protection of children’s rights in line with eu and
international standards.
Trans.: c¸ocuk haklarinin korunmasinin ab ve uluslararası
standartlara uygun s¸ekilde gelis¸tirilmesi.
Lit.: develop protection of children’s rights in accordance with
eu and international standards .
</figureCaption>
<bodyText confidence="0.961120117647059">
Ref.: ab ve uluslararası standartlar doˇgrultusunda c¸ocuk
haklarinin korunmasinin tes¸vik edilmesi.
Lit.: in line with eu and international standards pro-
mote/motivate protection of children’s rights .
Inp.: as a key feature of such a strategy, an accession partner-
ship will be drawn up on the basis of previous european council
conclusions.
Trans.: bu stratejinin kilit unsuru bir katilim ortakliˇgi bel-
gesi hazirlanacak kadarin temelinde , bir ¨onceki avrupa konseyi
sonuc¸laridir .
Lit.: as a key feature of this strategy, accession partnership doc-
ument will be prepared ??? based are previous european council
resolutions .
Ref.: bu stratejinin kilit unsuru olarak , daha ¨onceki ab zirve
sonuc¸larina dayanilarak bir katilim ortakliˇgi olus¸turulacaktir.
Lit.: as a key feature of this strategy an accession partnership
based on earlier eu summit resolutions will be formed.
</bodyText>
<figureCaption confidence="0.996949">
Figure 3: Some sample translations
</figureCaption>
<bodyText confidence="0.99975675">
along with the literal paraphrases of the translation
and the reference versions. The first two are quite
accurate and acceptable translations while the third
clearly has missing and incorrect parts.
</bodyText>
<sectionHeader confidence="0.977676" genericHeader="method">
5 Model Iteration
</sectionHeader>
<bodyText confidence="0.999157444444444">
We have also experimented with an iterative ap-
proach to use multiple models to see if further im-
provements are possible. This is akin to post-editing
(though definitely not akin to the much more so-
phisticated approach in described in Simard et al.
(2007)). We proceeded as follows: We used the
selective segmentation based model above and de-
coded our English training data ETrain and English
test data ETest to obtain T1Train and T1Test re-
</bodyText>
<table confidence="0.99027425">
Step BLEU
From Table 4 24.61
Iter. 1 24.77
Iter.2 25.08
</table>
<tableCaption confidence="0.995094">
Table 6: BLEU results for two model iterations
</tableCaption>
<bodyText confidence="0.999323038461538">
spectively. We then trained the next model using
T1Train and TTrain, to build a model that hopefully
will improve upon the output of the previous model,
T1Test, to bring it closer to TTest. This model when
applied to T1Train and T1Test produce T2Train and
T2Test respectively.
We have not included the content word corpus
in these experiments, as (i) our few very prelimi-
nary experiments indicated that using a morpheme-
based models in subsequent iterations would per-
form worse than word-based models, and (ii) that for
word-based models adding the content word training
data was not helpful as our baseline experiments in-
dicated. The models were tested by decoding the
output of the previous model for original test data.
For word-based decoding in the additional iterations
we used a 3-gram word-based language model but
reranked the 1000-best outputs using a 4-gram lan-
guage model. Table 6 provides the BLEU results for
these experiments corresponding to two additional
model iterations.
The BLEU result for the second iteration, 25.08,
represents a cumulative 4.86 points (24% relative)
improvement over the initial fully morphologically
segmented model using only the basic training set
and no rescoring.
</bodyText>
<sectionHeader confidence="0.999063" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.998963764705882">
Translation into Turkish seems to involve processes
that are somewhat more complex than standard sta-
tistical translation models: sometimes words on the
Turkish side are synthesized from the translations
of two or more (SMT) phrases, and errors in any
translated morpheme or its morphotactic position
render the synthesized word incorrect, even though
the rest of the word can be quite fine. If we just
extract the root words (not just for content words
but all words) in the decoded test set and the ref-
erence set, and compute root word BLEU, we ob-
tain 30.62, [64.6/35.7/23.4/16.3]. The unigram pre-
cision score shows that we are getting almost 65% of
the root words correct. However, the unigram pre-
cision score with full words is about 52% for our
best model. Thus we are missing about 13% of the
words although we seem to be getting their roots
</bodyText>
<page confidence="0.99584">
30
</page>
<bodyText confidence="0.999917035714286">
correct. With a tool that we have developed, BLEU+
(Tantuˇg et al., 2007), we have investigated such mis-
matches and have found that most of these are ac-
tually morphologically bogus, in that, although they
have the root word right, the morphemes are either
not the applicable ones or are in a morphotactically
wrong position. These can easily be identified with
the morphological generator that we have. In many
cases, such morphologically bogus words are one
morpheme edit distance away from the correct form
in the reference file. Another avenue that could be
pursued is the use of skip language models (sup-
ported by the SRILM toolkit) so that the content
word order could directly be used by the decoder.14
At this point it is very hard to compare how our re-
sults fare in the grand scheme of things, since there
is not much prior results for English to Turkish SMT.
Koehn (2005) reports on translation from English to
Finnish, another language that is morphologically as
complex as Turkish, with the added complexity of
compounding and stricter agreement between mod-
ifiers and head nouns. A standard phrase-based sys-
tem trained with 941,890 pairs of sentences (about
20 times the data that we have!) gives a BLEU score
of 13.00. However, in this study, nothing specific for
Finnish was employed, and one can certainly em-
ploy techniques similar to presented here to improve
upon this.
</bodyText>
<subsectionHeader confidence="0.998211">
6.1 Word Repair
</subsectionHeader>
<bodyText confidence="0.898475242424242">
The fact that there are quite many erroneous words
which are actually easy to fix suggests some ideas to
improve unigram precision. One can utilize a mor-
pheme level “spelling corrector” that operates on
segmented representations, and corrects such forms
to possible morphologically correct words in or-
der to form a lattice which can again be rescored
to select the contextually correct one.15 With the
BLEU+ tool, we have done one experiment that
shows that if we could recover all morphologically
bogus words that are 1 and 2 morpheme edit dis-
tance from the correct form, the word BLEU score
could rise to 29.86, [60.0/34.9/23.3/16.] and 30.48
[63.3/35.6/23.4/16.4] respectively. Obviously, these
are upper-bound oracle scores, as subsequent candi-
date generation and lattice rescoring could make er-
14This was suggested by one of the reviewers.
15It would however perhaps be much better if the decoder
could be augmented with a filter that could be invoked at much
earlier stages of sentence generation to check if certain gener-
ated segments violate hard-constraints (such as morphotactic
constraints) regardless of what the statistics say.
rors, but nevertheless they are very close to the root
word BLEU scores above.
Another path to pursue in repairing words is to
identify morphologically correct words which are
either OOVs in the language model or for which
the language model has low confidence. One can
perhaps identify these using posterior probabilities
(e.g., using techniques in Zens and Ney (2006)) and
generate additional morphologically valid words
that are “close” and construct a lattice that can be
rescored.
</bodyText>
<subsectionHeader confidence="0.999332">
6.2 Some Thoughts on BLEU
</subsectionHeader>
<bodyText confidence="0.999439428571429">
BLEU is particularly harsh for Turkish and the mor-
pheme based-approach, because of the all-or-none
nature of token comparison, as discussed above.
There are also cases where words with different
morphemes have very close morphosemantics, con-
vey the relevant meaning and are almost inter-
changeable:
</bodyText>
<listItem confidence="0.9687395">
• gel+hyor (geliyor - he is coming) vs. gel+makta
(gelmekte - he is (in a state of) coming) are essentially
the same. On a scale of 0 to 1, one could rate these at
about 0.95 in similarity.
• gel+yacak (gelecek - he will come) vs. gel+yacak+dhr
(gelecektir - he will come) in a sentence final position.
Such pairs could be rated perhaps at 0.90 in similarity.
• gel+dh (geldi - he came (past tense)) vs. gel+mhs (gelmis¸
</listItem>
<bodyText confidence="0.97301975">
- he came (hearsay past tense)). These essentially mark
past tense but differ in how the speaker relates to the event
and could be rated at perhaps 0.70 similarity.
Note that using stems and their synonyms as used
in METEOR (Banerjee and Lavie, 2005) could also
be considered for word similarity.
Again using the BLEU+ tool and a slightly dif-
ferent formulation of token similarity in BLEU com-
putation, we find that using morphological similar-
ity our best score above, 25.08 BLEU increases to
25.14 BLEU, while using only root word synonymy
and very close hypernymy from Wordnet, gives us
25.45 BLEU. The combination of rules and Wordnet
match gives 25.46 BLEU. Note that these increases
are much less than what can (potentially) be gained
from solving the word-repair problem above.
</bodyText>
<sectionHeader confidence="0.999505" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999824857142857">
We have presented results from our investigation
into using different granularity of sub-lexical rep-
resentations for English to Turkish SMT. We have
found that employing a language-pair specific rep-
resentation somewhere in between using full word-
forms and fully morphologically segmented repre-
sentations and using content words as additional
</bodyText>
<page confidence="0.999581">
31
</page>
<bodyText confidence="0.999983214285714">
data provide a significant boost in BLEU scores,
in addition to contributions of word-level rescoring
of 1000-best outputs and model iteration, to give a
BLEU score of 25.08 points with very modest par-
allel text resources. Detailed analysis of the errors
point at a few directions such as word-repair, to im-
prove word accuracy. This also suggests perhaps
hooking into the decoder, a mechanism for imposing
hard constraints (such as morphotactic constraints)
during decoding to avoid generating morphologi-
cally bogus words. Another direction is to introduce
exploitation of limited structures such as bracketed
noun phrases before considering full-fledged syntac-
tic structure.
</bodyText>
<sectionHeader confidence="0.999024" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9998688">
This work was supported by T ¨UB˙ITAK – The Turk-
ish National Science and Technology Foundation
under project grant 105E020. We thank the anony-
mous reviewer for some very useful comments and
suggestions.
</bodyText>
<sectionHeader confidence="0.999451" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999902168539326">
Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An au-
tomatic metric for MT evaluation with improved correlation
with human judgments. In Proceedings of the ACL Work-
shop on Intrinsic and Extrinsic Evaluation Measures for Ma-
chine Translation and/or Summarization, pages 65–72, Ann
Arbor, Michigan, June.
Simon Corston-Oliver and Michael Gamon. 2004. Normaliz-
ing German and English inflectional morphology to improve
statistical word alignment. In Proceedings of AMTA, pages
48–57.
˙Ilknur Durgar El-Kahlout and Kemal Oflazer. 2006. Initial ex-
plorations in English to Turkish statistical machine transla-
tion. In Proceedings on the Workshop on Statistical Machine
Translation, pages 7–14, New York City, June.
Sharon Goldwater and David McClosky. 2005. Improving sta-
tistical MT through morphological analysis. In Proceedings
of Human Language Technology Conference and Confer-
ence on Empirical Methods in Natural Language Process-
ing, pages 676–683, Vancouver, British Columbia, Canada,
October.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings of
HLT/NAACL.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-
Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan,
Wade Shen, Christine Moran, Richard Zens, Chris Dyer, On-
drej Bojar, Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open source toolkit for statistical machine trans-
lation. In Proceedings of the 45th Annual Meeting of the
Association for Computational Linguistics (ACL’07) – Com-
panion Volume, June.
Philip Koehn. 2005. Europarl: A parallel corpus for statistical
machine translation. In MT Summit X, Phuket, Thailand.
Young-Suk Lee. 2004. Morphological analysis for statistical
machine translation. In Proceedings of HLT-NAACL 2004 -
Companion Volume, pages 57–60.
Einat Minkov, Kristina Toutanova, and Hisami Suzuki. 2007.
Generating complex morphology for machine translation. In
Proceedings of the 45th Annual Meeting of the Association
for Computational Linguistics (ACL’07), Prague, Czech Re-
public, June.
Sonja Niessen and Hermann Ney. 2004. Statistical machine
translation with scarce resources using morpho-syntatic in-
formation. Computational Linguistics, 30(2):181–204.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing
Zhu. 2002. Bleu: a method for automatic evaluation of ma-
chine translation. In Proceedings of the 40th Annual Meeting
of the Association for Computational Linguistics, University
of Pennsylvania.
Maja Popovic and Hermann Ney. 2004. Towards the use of
word stems and suffixes for statistical machine translation.
In Proceedings of the 4th International Conference on Lan-
guage Resources and Evaluation (LREC), pages 1585–1588,
May.
Helmut Schmid. 1994. Probabilistic part-of-speech tagging us-
ing decision trees. In Proceedings of International Confer-
ence on New Methods in Language Processing.
Michel Simard, Cyril Goutte, and Pierre Isabelle. 2007. Statis-
tical phrase-based post-editing. In Proceedings of NAACL,
April.
Andreas Stolcke. 2002. SRILM – an extensible language mod-
eling toolkit. In Proceedings of the Intl. Conf. on Spoken
Language Processing.
David Talbot and Miles Osborne. 2006. Modelling lexical re-
dundancy for machine translation. In Proceedings of the 21st
International Conference on Computational Linguistics and
44th Annual Meeting of the Association for Computational
Linguistics, pages 969–976, Sydney, Australia, July.
C¨uneyd Tantuˇg, Kemal Oflazer, and ˙Ilknur Durgar El-Kahlout.
2007. BLEU+: a tool for fine-grained BLEU computation.
in preparation.
Mei Yang and Katrin Kirchhoff. 2006. Phrase-based backoff
models for machine translation of highly inflected languages.
In Proceedings of EACL, pages 41–48.
Deniz Y¨uret and Ferhan T¨ure. 2006. Learning morphological
disambiguation rules for Turkish. In Proceedings of the Hu-
man Language Technology Conference of the NAACL, Main
Conference, pages 328–334, New York City, USA, June.
Richard Zens and Hermann Ney. 2006. N-gram posterior prob-
abilities for statistical machine translation. In Proceedings
on the Workshop on Statistical Machine Translation, pages
72–77, New York City, June. Association for Computational
Linguistics.
Andreas Zollmann, Ashish Venugopal, and Stephan Vogel.
2006. Bridging the inflection morphology gap for Arabic
statistical machine translation. In Proceedings of the Human
Language Technology Conference of the NAACL, Compan-
ion Volume: Short Papers, pages 201–204, New York City,
USA, June.
</reference>
<page confidence="0.999299">
32
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.121736">
<title confidence="0.999103">Exploring Different Representational Units in English-to-Turkish Statistical Machine Translation</title>
<author confidence="0.526084">Technologies</author>
<affiliation confidence="0.980961">Carnegie Mellon</affiliation>
<address confidence="0.991362">Pittsburgh, PA, 15213, USA</address>
<email confidence="0.998846">oflazer@sabanciuniv.edu</email>
<note confidence="0.425808333333333">Durgar of Engineering and Natural Sabancı</note>
<address confidence="0.914351">Istanbul, Tuzla, 34956, Turkey</address>
<email confidence="0.999409">ilknurdurgar@su.sabanciuniv.edu</email>
<abstract confidence="0.997225285714286">We investigate different representational granularities for sub-lexical representation in statistical machine translation work from English to Turkish. We find that (i) representing both Turkish and English at the morpheme-level but with some selective morpheme-grouping on the Turkish side of the training data, (ii) augmenting the training data with “sentences” comprising only the content words of the original training data to bias root word alignment, (iii) reranking the n-best morpheme-sequence outputs of the decoder with a word-based language model, and (iv) using model iteration all provide a non-trivial improvement over a fully word-based baseline. Despite our very limited training data, we improve from 20.22 BLEU points for our simplest model to 25.08 BLEU points for an improvement of 4.86 points or 24% relative.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Alon Lavie</author>
</authors>
<title>METEOR: An automatic metric for MT evaluation with improved correlation with human judgments.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization,</booktitle>
<pages>65--72</pages>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="29802" citStr="Banerjee and Lavie, 2005" startWordPosition="4798" endWordPosition="4801">kta (gelmekte - he is (in a state of) coming) are essentially the same. On a scale of 0 to 1, one could rate these at about 0.95 in similarity. • gel+yacak (gelecek - he will come) vs. gel+yacak+dhr (gelecektir - he will come) in a sentence final position. Such pairs could be rated perhaps at 0.90 in similarity. • gel+dh (geldi - he came (past tense)) vs. gel+mhs (gelmis¸ - he came (hearsay past tense)). These essentially mark past tense but differ in how the speaker relates to the event and could be rated at perhaps 0.70 similarity. Note that using stems and their synonyms as used in METEOR (Banerjee and Lavie, 2005) could also be considered for word similarity. Again using the BLEU+ tool and a slightly different formulation of token similarity in BLEU computation, we find that using morphological similarity our best score above, 25.08 BLEU increases to 25.14 BLEU, while using only root word synonymy and very close hypernymy from Wordnet, gives us 25.45 BLEU. The combination of rules and Wordnet match gives 25.46 BLEU. Note that these increases are much less than what can (potentially) be gained from solving the word-repair problem above. 7 Conclusions We have presented results from our investigation into</context>
</contexts>
<marker>Banerjee, Lavie, 2005</marker>
<rawString>Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pages 65–72, Ann Arbor, Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Corston-Oliver</author>
<author>Michael Gamon</author>
</authors>
<title>Normalizing German and English inflectional morphology to improve statistical word alignment.</title>
<date>2004</date>
<booktitle>In Proceedings of AMTA,</booktitle>
<pages>48--57</pages>
<contexts>
<context position="6612" citStr="Corston-Oliver and Gamon (2004)" startWordPosition="979" endWordPosition="982">gical features are removed from each parse leaving the lexical morphemes. Using morphology in SMT has been recently addressed by researchers translation from or into morphologically rich(er) languages. Niessen and Ney (2004) have used morphological decomposition to improve alignment quality. Yang and Kirchhoff (2006) use phrase-based backoff models to translate words that are unknown to the decoder, by morphologically decomposing the unknown source word. They particularly apply their method to translating from Finnish – another language with very similar structural characteristics to Turkish. Corston-Oliver and Gamon (2004) normalize inflectional morphology by stemming the word for German-English word alignment. Lee (2004) uses a morphologically analyzed and tagged parallel corpus for ArabicEnglish SMT. Zolmann et al. (2006) also exploit morphology in Arabic-English SMT. Popovic and Ney (2004) investigate improving translation qual2This disambiguator has about 94% accuracy. 26 ity from inflected languages by using stems, suffixes and part-of-speech tags. Goldwater and McClosky (2005) use morphological analysis on Czech text to get improvements in Czech to English SMT. Recently, Minkov et al. (2007) have used mor</context>
</contexts>
<marker>Corston-Oliver, Gamon, 2004</marker>
<rawString>Simon Corston-Oliver and Michael Gamon. 2004. Normalizing German and English inflectional morphology to improve statistical word alignment. In Proceedings of AMTA, pages 48–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>˙Ilknur Durgar El-Kahlout</author>
<author>Kemal Oflazer</author>
</authors>
<title>Initial explorations in English to Turkish statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings on the Workshop on Statistical Machine Translation,</booktitle>
<pages>7--14</pages>
<location>New York City,</location>
<contexts>
<context position="2839" citStr="El-Kahlout and Oflazer, 2006" startWordPosition="410" endWordPosition="413">ows: We first briefly discuss issues in SMT and Turkish, and review related work. We then outline how we exploit morphology, and present results from our baseline and morphologically segmented models, followed by some sample outputs. We then describe discuss model iteration. Finally, we present a comprehensive discussion of our approach and results, and briefly discuss word-repair – fixing morphologicaly malformed words – and offer a few ideas about the adaptation of BLEU to morphologically complex languages like Turkish. 2 Turkish and SMT Our previous experience with SMT into Turkish (Durgar El-Kahlout and Oflazer, 2006) hinted that exploiting sub-lexical structure would be a fruitful avenue to pursue. This was based on the observation that a Turkish word would have to align with a complete phrase on the English side, and that sometimes these phrases on the English side could be discontinuous. Figure 1 shows a pair of English and Turkish sentences that are aligned at the word (top) and morpheme (bottom) levels. At the morpheme level, we have split the Turkish words into their lexical morphemes while English words with overt morphemes have been stemmed, and such morphemes have been marked with a tag. The produ</context>
</contexts>
<marker>El-Kahlout, Oflazer, 2006</marker>
<rawString>˙Ilknur Durgar El-Kahlout and Kemal Oflazer. 2006. Initial explorations in English to Turkish statistical machine translation. In Proceedings on the Workshop on Statistical Machine Translation, pages 7–14, New York City, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>David McClosky</author>
</authors>
<title>Improving statistical MT through morphological analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>676--683</pages>
<location>Vancouver, British Columbia, Canada,</location>
<contexts>
<context position="7081" citStr="Goldwater and McClosky (2005)" startWordPosition="1045" endWordPosition="1048">larly apply their method to translating from Finnish – another language with very similar structural characteristics to Turkish. Corston-Oliver and Gamon (2004) normalize inflectional morphology by stemming the word for German-English word alignment. Lee (2004) uses a morphologically analyzed and tagged parallel corpus for ArabicEnglish SMT. Zolmann et al. (2006) also exploit morphology in Arabic-English SMT. Popovic and Ney (2004) investigate improving translation qual2This disambiguator has about 94% accuracy. 26 ity from inflected languages by using stems, suffixes and part-of-speech tags. Goldwater and McClosky (2005) use morphological analysis on Czech text to get improvements in Czech to English SMT. Recently, Minkov et al. (2007) have used morphological postprocessing on the output side using structural information and information from the source side, to improve SMT quality. 3 Exploiting Morphology Our parallel data consists mainly of documents in international relations and legal documents from sources such as the Turkish Ministry of Foreign Affairs, EU, etc. We process these as follows: (i) We segment the words in our Turkish corpus into lexical morphemes whereby differences in the surface representa</context>
</contexts>
<marker>Goldwater, McClosky, 2005</marker>
<rawString>Sharon Goldwater and David McClosky. 2005. Improving statistical MT through morphological analysis. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 676–683, Vancouver, British Columbia, Canada, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz J Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT/NAACL.</booktitle>
<contexts>
<context position="11051" citStr="Koehn et al., 2003" startWordPosition="1700" endWordPosition="1703">hl +ma] [ortaklık2 +sh +nhn] [uygula3 +hn +ma +sh] [,] [ortaklık4] [anlas¸ma5 +sh] [c¸erc¸eve6 +sh +nda] [izle7 +hn +yacak +dhr] [.] • E: the implementation3 of the accession1 partnership2 will be monitor7 +vvn in the framework6 of the association4 agreement5 . Note that when the morphemes/tags (starting with a +) are concatenated, we get the “word-based” version of the corpus, since surface words are directly recoverable from the concatenated representation. We use this word-based representation also for word-based language models used for rescoring. We employ the phrase-based SMT framework (Koehn et al., 2003), and use the Moses toolkit (Koehn et al., 2007), and the SRILM language modelling toolkit (Stolcke, 2002), and evaluate our decoded translations using the BLEU measure (Papineni et al., 2002), using a single reference translation. 5The training set in the first row of 1 was limited to sentences on the Turkish side which had at most 90 tokens (roots and bound morphemes) in total in order to comply with requirements of the GIZA++ alignment tool. However when only the content words are included, we have more sentences to include since much less number of sentences violate the length restriction </context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of HLT/NAACL.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris CallisonBurch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Chris Dyer, Ondrej Bojar,</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL’07) – Companion Volume,</booktitle>
<location>Alexandra</location>
<contexts>
<context position="11099" citStr="Koehn et al., 2007" startWordPosition="1709" endWordPosition="1712">h] [,] [ortaklık4] [anlas¸ma5 +sh] [c¸erc¸eve6 +sh +nda] [izle7 +hn +yacak +dhr] [.] • E: the implementation3 of the accession1 partnership2 will be monitor7 +vvn in the framework6 of the association4 agreement5 . Note that when the morphemes/tags (starting with a +) are concatenated, we get the “word-based” version of the corpus, since surface words are directly recoverable from the concatenated representation. We use this word-based representation also for word-based language models used for rescoring. We employ the phrase-based SMT framework (Koehn et al., 2003), and use the Moses toolkit (Koehn et al., 2007), and the SRILM language modelling toolkit (Stolcke, 2002), and evaluate our decoded translations using the BLEU measure (Papineni et al., 2002), using a single reference translation. 5The training set in the first row of 1 was limited to sentences on the Turkish side which had at most 90 tokens (roots and bound morphemes) in total in order to comply with requirements of the GIZA++ alignment tool. However when only the content words are included, we have more sentences to include since much less number of sentences violate the length restriction when morphemes/function word are removed. 27 Mos</context>
</contexts>
<marker>Koehn, Hoang, Birch, CallisonBurch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris CallisonBurch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL’07) – Companion Volume, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In MT Summit X,</booktitle>
<location>Phuket, Thailand.</location>
<contexts>
<context position="26658" citStr="Koehn (2005)" startWordPosition="4287" endWordPosition="4288">icable ones or are in a morphotactically wrong position. These can easily be identified with the morphological generator that we have. In many cases, such morphologically bogus words are one morpheme edit distance away from the correct form in the reference file. Another avenue that could be pursued is the use of skip language models (supported by the SRILM toolkit) so that the content word order could directly be used by the decoder.14 At this point it is very hard to compare how our results fare in the grand scheme of things, since there is not much prior results for English to Turkish SMT. Koehn (2005) reports on translation from English to Finnish, another language that is morphologically as complex as Turkish, with the added complexity of compounding and stricter agreement between modifiers and head nouns. A standard phrase-based system trained with 941,890 pairs of sentences (about 20 times the data that we have!) gives a BLEU score of 13.00. However, in this study, nothing specific for Finnish was employed, and one can certainly employ techniques similar to presented here to improve upon this. 6.1 Word Repair The fact that there are quite many erroneous words which are actually easy to </context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philip Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT Summit X, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Suk Lee</author>
</authors>
<title>Morphological analysis for statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL 2004 -Companion Volume,</booktitle>
<pages>57--60</pages>
<contexts>
<context position="6713" citStr="Lee (2004)" startWordPosition="995" endWordPosition="996">sed by researchers translation from or into morphologically rich(er) languages. Niessen and Ney (2004) have used morphological decomposition to improve alignment quality. Yang and Kirchhoff (2006) use phrase-based backoff models to translate words that are unknown to the decoder, by morphologically decomposing the unknown source word. They particularly apply their method to translating from Finnish – another language with very similar structural characteristics to Turkish. Corston-Oliver and Gamon (2004) normalize inflectional morphology by stemming the word for German-English word alignment. Lee (2004) uses a morphologically analyzed and tagged parallel corpus for ArabicEnglish SMT. Zolmann et al. (2006) also exploit morphology in Arabic-English SMT. Popovic and Ney (2004) investigate improving translation qual2This disambiguator has about 94% accuracy. 26 ity from inflected languages by using stems, suffixes and part-of-speech tags. Goldwater and McClosky (2005) use morphological analysis on Czech text to get improvements in Czech to English SMT. Recently, Minkov et al. (2007) have used morphological postprocessing on the output side using structural information and information from the so</context>
</contexts>
<marker>Lee, 2004</marker>
<rawString>Young-Suk Lee. 2004. Morphological analysis for statistical machine translation. In Proceedings of HLT-NAACL 2004 -Companion Volume, pages 57–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Einat Minkov</author>
<author>Kristina Toutanova</author>
<author>Hisami Suzuki</author>
</authors>
<title>Generating complex morphology for machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL’07),</booktitle>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="7198" citStr="Minkov et al. (2007)" startWordPosition="1065" endWordPosition="1068">h. Corston-Oliver and Gamon (2004) normalize inflectional morphology by stemming the word for German-English word alignment. Lee (2004) uses a morphologically analyzed and tagged parallel corpus for ArabicEnglish SMT. Zolmann et al. (2006) also exploit morphology in Arabic-English SMT. Popovic and Ney (2004) investigate improving translation qual2This disambiguator has about 94% accuracy. 26 ity from inflected languages by using stems, suffixes and part-of-speech tags. Goldwater and McClosky (2005) use morphological analysis on Czech text to get improvements in Czech to English SMT. Recently, Minkov et al. (2007) have used morphological postprocessing on the output side using structural information and information from the source side, to improve SMT quality. 3 Exploiting Morphology Our parallel data consists mainly of documents in international relations and legal documents from sources such as the Turkish Ministry of Foreign Affairs, EU, etc. We process these as follows: (i) We segment the words in our Turkish corpus into lexical morphemes whereby differences in the surface representations of morphemes due to word-internal phenomena are abstracted out to improve statistics during alignment.3 (ii) We</context>
</contexts>
<marker>Minkov, Toutanova, Suzuki, 2007</marker>
<rawString>Einat Minkov, Kristina Toutanova, and Hisami Suzuki. 2007. Generating complex morphology for machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL’07), Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sonja Niessen</author>
<author>Hermann Ney</author>
</authors>
<title>Statistical machine translation with scarce resources using morpho-syntatic information.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>2</issue>
<contexts>
<context position="6205" citStr="Niessen and Ney (2004)" startWordPosition="923" endWordPosition="926">morphemes bracketed with (..): (em)em+Verb+Pos(+yAlH)ˆDB+Adverb+Since since (someone) sucked (something) (emel)emel+Noun+A3sg(+sH)+P3sg+Nom his/her ambition (emel)emel+Noun+A3sg+Pnon(+yH)+Acc ambition (as object of a transitive verb) These analyses are then disambiguated with a statistical disambiguator (Y¨uret and T¨ure, 2006) which operates on the morphological features.2 Finally, the morphological features are removed from each parse leaving the lexical morphemes. Using morphology in SMT has been recently addressed by researchers translation from or into morphologically rich(er) languages. Niessen and Ney (2004) have used morphological decomposition to improve alignment quality. Yang and Kirchhoff (2006) use phrase-based backoff models to translate words that are unknown to the decoder, by morphologically decomposing the unknown source word. They particularly apply their method to translating from Finnish – another language with very similar structural characteristics to Turkish. Corston-Oliver and Gamon (2004) normalize inflectional morphology by stemming the word for German-English word alignment. Lee (2004) uses a morphologically analyzed and tagged parallel corpus for ArabicEnglish SMT. Zolmann e</context>
</contexts>
<marker>Niessen, Ney, 2004</marker>
<rawString>Sonja Niessen and Hermann Ney. 2004. Statistical machine translation with scarce resources using morpho-syntatic information. Computational Linguistics, 30(2):181–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association</booktitle>
<institution>for Computational Linguistics, University of Pennsylvania.</institution>
<contexts>
<context position="11243" citStr="Papineni et al., 2002" startWordPosition="1732" endWordPosition="1736">will be monitor7 +vvn in the framework6 of the association4 agreement5 . Note that when the morphemes/tags (starting with a +) are concatenated, we get the “word-based” version of the corpus, since surface words are directly recoverable from the concatenated representation. We use this word-based representation also for word-based language models used for rescoring. We employ the phrase-based SMT framework (Koehn et al., 2003), and use the Moses toolkit (Koehn et al., 2007), and the SRILM language modelling toolkit (Stolcke, 2002), and evaluate our decoded translations using the BLEU measure (Papineni et al., 2002), using a single reference translation. 5The training set in the first row of 1 was limited to sentences on the Turkish side which had at most 90 tokens (roots and bound morphemes) in total in order to comply with requirements of the GIZA++ alignment tool. However when only the content words are included, we have more sentences to include since much less number of sentences violate the length restriction when morphemes/function word are removed. 27 Moses Dec. Parms. BLEU BLEU-c Default 16.29 16.13 dl = -1, -weight-d = 0.1 20.16 19.77 Table 2: BLEU results for baseline experiments. BLEU is for </context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maja Popovic</author>
<author>Hermann Ney</author>
</authors>
<title>Towards the use of word stems and suffixes for statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>1585--1588</pages>
<contexts>
<context position="6887" citStr="Popovic and Ney (2004)" startWordPosition="1019" endWordPosition="1022">quality. Yang and Kirchhoff (2006) use phrase-based backoff models to translate words that are unknown to the decoder, by morphologically decomposing the unknown source word. They particularly apply their method to translating from Finnish – another language with very similar structural characteristics to Turkish. Corston-Oliver and Gamon (2004) normalize inflectional morphology by stemming the word for German-English word alignment. Lee (2004) uses a morphologically analyzed and tagged parallel corpus for ArabicEnglish SMT. Zolmann et al. (2006) also exploit morphology in Arabic-English SMT. Popovic and Ney (2004) investigate improving translation qual2This disambiguator has about 94% accuracy. 26 ity from inflected languages by using stems, suffixes and part-of-speech tags. Goldwater and McClosky (2005) use morphological analysis on Czech text to get improvements in Czech to English SMT. Recently, Minkov et al. (2007) have used morphological postprocessing on the output side using structural information and information from the source side, to improve SMT quality. 3 Exploiting Morphology Our parallel data consists mainly of documents in international relations and legal documents from sources such as </context>
</contexts>
<marker>Popovic, Ney, 2004</marker>
<rawString>Maja Popovic and Hermann Ney. 2004. Towards the use of word stems and suffixes for statistical machine translation. In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC), pages 1585–1588, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proceedings of International Conference on New Methods in Language Processing.</booktitle>
<contexts>
<context position="7851" citStr="Schmid, 1994" startWordPosition="1167" endWordPosition="1168">on the output side using structural information and information from the source side, to improve SMT quality. 3 Exploiting Morphology Our parallel data consists mainly of documents in international relations and legal documents from sources such as the Turkish Ministry of Foreign Affairs, EU, etc. We process these as follows: (i) We segment the words in our Turkish corpus into lexical morphemes whereby differences in the surface representations of morphemes due to word-internal phenomena are abstracted out to improve statistics during alignment.3 (ii) We tag the English side using TreeTagger (Schmid, 1994), which provides a lemma and a part-of-speech for each word. We then remove any tags which do not imply an explicit morpheme or an exceptional form. So for instance, if the word book gets tagged as +NN, we keep book in the text, but remove +NN. For books tagged as +NNS or booking tagged as +VVG, we keep book and +NNS, and book and +VVG. A word like went is replaced by go +VVD.4 (iii) From these morphologically segmented corpora, we also extract for each sentence, the sequence of roots for open class content words (nouns, adjectives, adverbs, and verbs). For Turkish, this corresponds to removin</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Proceedings of International Conference on New Methods in Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Simard</author>
<author>Cyril Goutte</author>
<author>Pierre Isabelle</author>
</authors>
<title>Statistical phrase-based post-editing.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<contexts>
<context position="23418" citStr="Simard et al. (2007)" startWordPosition="3741" endWordPosition="3744">s a key feature of this strategy an accession partnership based on earlier eu summit resolutions will be formed. Figure 3: Some sample translations along with the literal paraphrases of the translation and the reference versions. The first two are quite accurate and acceptable translations while the third clearly has missing and incorrect parts. 5 Model Iteration We have also experimented with an iterative approach to use multiple models to see if further improvements are possible. This is akin to post-editing (though definitely not akin to the much more sophisticated approach in described in Simard et al. (2007)). We proceeded as follows: We used the selective segmentation based model above and decoded our English training data ETrain and English test data ETest to obtain T1Train and T1Test reStep BLEU From Table 4 24.61 Iter. 1 24.77 Iter.2 25.08 Table 6: BLEU results for two model iterations spectively. We then trained the next model using T1Train and TTrain, to build a model that hopefully will improve upon the output of the previous model, T1Test, to bring it closer to TTest. This model when applied to T1Train and T1Test produce T2Train and T2Test respectively. We have not included the content wo</context>
</contexts>
<marker>Simard, Goutte, Isabelle, 2007</marker>
<rawString>Michel Simard, Cyril Goutte, and Pierre Isabelle. 2007. Statistical phrase-based post-editing. In Proceedings of NAACL, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM – an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the Intl. Conf. on Spoken Language Processing.</booktitle>
<contexts>
<context position="11157" citStr="Stolcke, 2002" startWordPosition="1720" endWordPosition="1721"> +hn +yacak +dhr] [.] • E: the implementation3 of the accession1 partnership2 will be monitor7 +vvn in the framework6 of the association4 agreement5 . Note that when the morphemes/tags (starting with a +) are concatenated, we get the “word-based” version of the corpus, since surface words are directly recoverable from the concatenated representation. We use this word-based representation also for word-based language models used for rescoring. We employ the phrase-based SMT framework (Koehn et al., 2003), and use the Moses toolkit (Koehn et al., 2007), and the SRILM language modelling toolkit (Stolcke, 2002), and evaluate our decoded translations using the BLEU measure (Papineni et al., 2002), using a single reference translation. 5The training set in the first row of 1 was limited to sentences on the Turkish side which had at most 90 tokens (roots and bound morphemes) in total in order to comply with requirements of the GIZA++ alignment tool. However when only the content words are included, we have more sentences to include since much less number of sentences violate the length restriction when morphemes/function word are removed. 27 Moses Dec. Parms. BLEU BLEU-c Default 16.29 16.13 dl = -1, -w</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM – an extensible language modeling toolkit. In Proceedings of the Intl. Conf. on Spoken Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Talbot</author>
<author>Miles Osborne</author>
</authors>
<title>Modelling lexical redundancy for machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>969--976</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="5373" citStr="Talbot and Osborne (2006)" startWordPosition="813" endWordPosition="816">H+ndA vs. masa+sH+ndA. We should however note that although employing a morpheme based representations dramatically reduces the vocabulary size on the Turkish side, it also runs the risk of overloading distortion mechanisms to account for both word-internal morpheme sequencing and sentence level word ordering. The segmentation of a word in general is not unique. We first generate a representation that contains both the lexical segments and the morphological features encoded for all possible segmenta1This is in a sense very similar to the more general problem of lexical redundancy addressed by Talbot and Osborne (2006) but our approach does not require the more sophisticated solution there. tions and interpretations of the word. For the word emeli for instance, our morphological analyzer generates the following with lexical morphemes bracketed with (..): (em)em+Verb+Pos(+yAlH)ˆDB+Adverb+Since since (someone) sucked (something) (emel)emel+Noun+A3sg(+sH)+P3sg+Nom his/her ambition (emel)emel+Noun+A3sg+Pnon(+yH)+Acc ambition (as object of a transitive verb) These analyses are then disambiguated with a statistical disambiguator (Y¨uret and T¨ure, 2006) which operates on the morphological features.2 Finally, the </context>
<context position="19003" citStr="Talbot and Osborne (2006)" startWordPosition="3028" endWordPosition="3031">ts 21.7% compared to the very initial morphologically segmented model). This is a very encouraging result that indicates we should perhaps consider a much more detailed analysis of morpheme alignments to uncover additional morphemes with similar status. Table 5 provides additional details on the BLEU 11It should be noted that what to selectively attach to the root should be considered on a per-language basis; if Turkish were to be aligned with a language with similar morphological markers, this perhaps would not have been needed. Again one perhaps can use methods similar to those suggested by Talbot and Osborne (2006). 12Decoders for the fully-segmented model and selectively segmented model use different 5-gram language models, since the language model corpus should have the same selectively segmented units as those in the training set. However, the wordlevel language models used in rescoring are the same. Moses Dec. Parms. BLEU-c dl = -1, -weight-d = 0.1 22.18 + word-level LM rescoring (Full Segmentation (from Table 3)) dl = -1, -weight-d = 0.1 23.47 dl = -1, -weight-d = 0.1 24.61 + word-level LM rescoring Table 4: BLEU results for experiments with selectively segmented and content-word augmented training</context>
</contexts>
<marker>Talbot, Osborne, 2006</marker>
<rawString>David Talbot and Miles Osborne. 2006. Modelling lexical redundancy for machine translation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 969–976, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C¨uneyd Tantuˇg</author>
</authors>
<title>Kemal Oflazer, and ˙Ilknur Durgar El-Kahlout.</title>
<date>2007</date>
<marker>Tantuˇg, 2007</marker>
<rawString>C¨uneyd Tantuˇg, Kemal Oflazer, and ˙Ilknur Durgar El-Kahlout. 2007. BLEU+: a tool for fine-grained BLEU computation. in preparation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mei Yang</author>
<author>Katrin Kirchhoff</author>
</authors>
<title>Phrase-based backoff models for machine translation of highly inflected languages.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>41--48</pages>
<contexts>
<context position="6299" citStr="Yang and Kirchhoff (2006)" startWordPosition="935" endWordPosition="938">d (something) (emel)emel+Noun+A3sg(+sH)+P3sg+Nom his/her ambition (emel)emel+Noun+A3sg+Pnon(+yH)+Acc ambition (as object of a transitive verb) These analyses are then disambiguated with a statistical disambiguator (Y¨uret and T¨ure, 2006) which operates on the morphological features.2 Finally, the morphological features are removed from each parse leaving the lexical morphemes. Using morphology in SMT has been recently addressed by researchers translation from or into morphologically rich(er) languages. Niessen and Ney (2004) have used morphological decomposition to improve alignment quality. Yang and Kirchhoff (2006) use phrase-based backoff models to translate words that are unknown to the decoder, by morphologically decomposing the unknown source word. They particularly apply their method to translating from Finnish – another language with very similar structural characteristics to Turkish. Corston-Oliver and Gamon (2004) normalize inflectional morphology by stemming the word for German-English word alignment. Lee (2004) uses a morphologically analyzed and tagged parallel corpus for ArabicEnglish SMT. Zolmann et al. (2006) also exploit morphology in Arabic-English SMT. Popovic and Ney (2004) investigate</context>
</contexts>
<marker>Yang, Kirchhoff, 2006</marker>
<rawString>Mei Yang and Katrin Kirchhoff. 2006. Phrase-based backoff models for machine translation of highly inflected languages. In Proceedings of EACL, pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deniz Y¨uret</author>
<author>Ferhan T¨ure</author>
</authors>
<title>Learning morphological disambiguation rules for Turkish.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,</booktitle>
<pages>328--334</pages>
<location>New York City, USA,</location>
<marker>Y¨uret, T¨ure, 2006</marker>
<rawString>Deniz Y¨uret and Ferhan T¨ure. 2006. Learning morphological disambiguation rules for Turkish. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 328–334, New York City, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Zens</author>
<author>Hermann Ney</author>
</authors>
<title>N-gram posterior probabilities for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings on the Workshop on Statistical Machine Translation,</booktitle>
<pages>72--77</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City,</location>
<contexts>
<context position="28690" citStr="Zens and Ney (2006)" startWordPosition="4609" endWordPosition="4612">he decoder could be augmented with a filter that could be invoked at much earlier stages of sentence generation to check if certain generated segments violate hard-constraints (such as morphotactic constraints) regardless of what the statistics say. rors, but nevertheless they are very close to the root word BLEU scores above. Another path to pursue in repairing words is to identify morphologically correct words which are either OOVs in the language model or for which the language model has low confidence. One can perhaps identify these using posterior probabilities (e.g., using techniques in Zens and Ney (2006)) and generate additional morphologically valid words that are “close” and construct a lattice that can be rescored. 6.2 Some Thoughts on BLEU BLEU is particularly harsh for Turkish and the morpheme based-approach, because of the all-or-none nature of token comparison, as discussed above. There are also cases where words with different morphemes have very close morphosemantics, convey the relevant meaning and are almost interchangeable: • gel+hyor (geliyor - he is coming) vs. gel+makta (gelmekte - he is (in a state of) coming) are essentially the same. On a scale of 0 to 1, one could rate thes</context>
</contexts>
<marker>Zens, Ney, 2006</marker>
<rawString>Richard Zens and Hermann Ney. 2006. N-gram posterior probabilities for statistical machine translation. In Proceedings on the Workshop on Statistical Machine Translation, pages 72–77, New York City, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Zollmann</author>
<author>Ashish Venugopal</author>
<author>Stephan Vogel</author>
</authors>
<title>Bridging the inflection morphology gap for Arabic statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers,</booktitle>
<pages>201--204</pages>
<location>New York City, USA,</location>
<marker>Zollmann, Venugopal, Vogel, 2006</marker>
<rawString>Andreas Zollmann, Ashish Venugopal, and Stephan Vogel. 2006. Bridging the inflection morphology gap for Arabic statistical machine translation. In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, pages 201–204, New York City, USA, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>