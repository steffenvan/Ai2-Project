<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003835">
<title confidence="0.8981695">
Graph-Based Seed Set Expansion for Relation Extraction Using
Random Walk Hitting Times
</title>
<author confidence="0.997372">
Joel Lang
</author>
<affiliation confidence="0.999619">
University of Geneva
</affiliation>
<address confidence="0.8626745">
7 Route de Drize
1227 Carouge, Switzerland
</address>
<email confidence="0.996634">
joel.lang@unige.ch
</email>
<author confidence="0.891948">
James Henderson
</author>
<affiliation confidence="0.87807">
Xerox Research Centre Europe
</affiliation>
<address confidence="0.954425">
6 Chemin de Maupertuis
38240 Meylan, France
</address>
<email confidence="0.998354">
james.henderson@xrce.xerox.com
</email>
<sectionHeader confidence="0.998515" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996915375">
Iterative bootstrapping methods are
widely employed for relation extraction,
especially because they require only a
small amount of human supervision.
Unfortunately, a phenomenon known
as semantic drift can affect the accuracy
of iterative bootstrapping and lead to
poor extractions. This paper proposes
an alternative bootstrapping method,
which ranks relation tuples by measuring
their distance to the seed tuples in a
bipartite tuple-pattern graph. In contrast
to previous bootstrapping methods, our
method is not susceptible to semantic
drift, and it empirically results in better
extractions than iterative methods.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99994846">
The goal of relation extraction is to extract tu-
ples of a particular relation from a corpus of
natural language text. A widely employed ap-
proach to relation extraction is based on iter-
ative bootstrapping (Brin, 1998; Agichtein and
Gravano, 2000; Pasca et al., 2006; Pantel and
Pennacchiotti, 2006), which can be applied with
only small amounts of supervision and which
scales well to very large datasets.
A well-known problem with iterative boot-
strapping is a phenomenon known as seman-
tic drift (Curran et al., 2007): as bootstrap-
ping proceeds it is likely that unreliable pat-
terns will lead to false extractions. These extrac-
tion errors are amplified in the following itera-
tions and the extracted relation will drift away
from the intended target. Semantic drift often
results in low precision extractions and there-
fore poses a major limitation of iterative boot-
strapping algorithms. Previous work on itera-
tive bootstrapping has addressed the issue of re-
ducing semantic drift for example by bagging
the results of various runs employing differing
seed tuples, constructing filters which identify
false tuples or patterns and adding further con-
straints to the bootstrapping process (T. McIn-
tosh, 2010; McIntosh and Curran, 2009; Curran
et al., 2007).
However, the analysis of Komachi et al.
(2008) has shown that semantic drift is an in-
herent property of iterative bootstrapping algo-
rithms and therefore poses a fundamental prob-
lem. They have shown that iterative bootstrap-
ping without pruning corresponds to an eigen-
vector computation and thus as the number of
iterations increases the resulting ranking will al-
ways converge towards the same static ranking
of tuples, regardless of the particular choice of
seed instances.
In this paper, we describe an alternative
method, that is not susceptible to semantic drift.
We represent our data as a bipartite graph,
whose vertices correspond to patterns and tu-
ples respectively and whose edges capture cooc-
currences and then measure the distance of a
tuple to the seed set in terms of random walk
hitting times. Experimental results confirm that
semantic drift is avoided by our method and
show that substantial improvements over iter-
ative forms of bootstrapping are possible.
</bodyText>
<page confidence="0.969516">
772
</page>
<subsectionHeader confidence="0.171753">
Proceedings of NAACL-HLT 2013, pages 772–776,
</subsectionHeader>
<bodyText confidence="0.360472">
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</bodyText>
<sectionHeader confidence="0.524538" genericHeader="method">
2 Scoring with Hitting Times
</sectionHeader>
<bodyText confidence="0.99981947368421">
From a given corpus, we extract a dataset con-
sisting of tuples and patterns. Tuples are pairs
of co-occurring strings in the corpus, such as
(Bill Gates, Microsoft), which potentially belong
to a particular relation of interest. In our case,
patterns are simply the sequence of tokens oc-
curring between tuple elements, e.g. “is the
founder of”. We represent all the tuple types1
X and all the extraction pattern types Y con-
tained in a given corpus through an undirected,
weighted, bipartite graph G = (V, E) with ver-
tices V = X U Y and edges E c X x Y , where
an edge (x, y) E E indicates that tuple x oc-
currs with pattern y somewhere in the corpus.
Edge weights are defined through a weight ma-
trix W which holds the weight Wi,j = w(vi, vj)
for edges (vi, vj) E E. Specifically, we use the
count of how many times a tuple occurs with
a pattern in the corpus and weights for uncon-
nected vertices are zero.
Our goal is to compute a score vector σ hold-
ing a score σi = σ(xi) for each tuple xi E X,
which quantifies how well the tuple matches the
seed tuples. Higher scores indicate that the tu-
ple is more likely to belong to the relation de-
fined through the seeds and thus the score vec-
tor effectively provides a ranking of the tuples.
We define scores of tuples based on their dis-
tance2 to the seed tuples in the graph. The dis-
tance of some tuple x to the seed set S can
be naturally formalized in terms of the aver-
age time it takes until a random walk starting
in S reaches x, the hitting time. The random
walk is defined through the probability distri-
bution over start vertices and through a ma-
trix of transition probabilities. Edge weights
are constrained to be non-negative, which al-
lows us to define the transition matrix P with
</bodyText>
<equation confidence="0.938657666666667">
Pi,j = p(vj|vi) = d1. w(vi, vj), where dv =
z
E
</equation>
<bodyText confidence="0.989840666666667">
vkEV w(v, vk) is the degree of a vertex v E V .
The distance of two vertices is measured in
terms of the average time of a random walk be-
</bodyText>
<footnote confidence="0.99085675">
1Note that we are using tuple and pattern types rather
than particular mentions in the corpus.
2The term is used informally. In particular, hitting times
are not a distance metric, since they can be asymmetric.
</footnote>
<bodyText confidence="0.9999142">
tween the two. Specifically, we adopt the notion
of T-truncated hitting time (Sarkar and Moore,
2007) defined as the expected number of steps
it takes until a random walk of at most T steps
starting at vi reaches vj for the first time:
</bodyText>
<equation confidence="0.9206045">
�
0 iff. vj = vi or T=0
hT (vj|vi) =
1 + EvkEV p(vk|vi)hT −1(vj|vk)
</equation>
<bodyText confidence="0.99988275">
The truncated hitting time hT (vj|vi) can be
approximately computed by sampling M inde-
pendent random walks starting at vi of length T
and computing
</bodyText>
<equation confidence="0.9845635">
m
tk + (1 − M )T (1)
</equation>
<bodyText confidence="0.853254181818182">
where {t1 ... tm} are the sampled first-hit times
of random walks which reach vj within T steps
(Sarkar et al., 2008).
The score σHT (v) of a vertex v E/ S to the seed
set S is then defined as the inverse of the aver-
age T-truncated hitting time of random walks
starting at a randomly chosen vertex s E S:
� hT(v|s) (2)
= hT (v|S) = 1
|S|
sES
</bodyText>
<sectionHeader confidence="0.998976" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999979117647059">
We extracted tuples and patterns from the fifth
edition of the Gigaword corpus (Parker et al.,
2011), by running a named entity tagger and
extracting all pairs of named entities and ex-
tracting occurring within the same sentence
which do not have another named entity stand-
ing between them. Gold standard seed and test
tuples for a set of relations were obtained from
YAGO (Suchanek et al., 2007). Specifically, we
took all relations for which there are at least
300 tuples, each of which occurs at least once
in the corpus. This resulted in the set of rela-
tions shown in Table 1, plus the development
relation hasWonPrixe.
For evaluation, we use the percentile rank of
the median test set element (PRM, see Francois
et al. 2007), which reflects the quality of the
</bodyText>
<equation confidence="0.9947205">
m
ˆhT (vj|vi) = 1
M
k=1
1
σHT (v)
</equation>
<page confidence="0.971099">
773
</page>
<bodyText confidence="0.9995796">
full produced ranking, not just the top N ele-
ments and is furthermore computable with only
a small set of labeled test tuples 3.
We compare our proposed method based on
hitting times (HT) with two variants of iterative
bootstrapping. The first one (IB1) does not em-
ploy pruning and corresponds to the algorithm
described in Komachi et al. (2008). The sec-
ond one (IB2) corresponds to a standard boot-
strapping algorithm which employs pruning af-
ter each step in order to reduce semantic drift.
Specifically, scores are pruned after projecting
from X onto Y and from Y onto X, retaining
only the top N(t) = N0t scores at iteration t and
setting all other scores to zero.
</bodyText>
<subsectionHeader confidence="0.991846">
3.1 Parametrizations
</subsectionHeader>
<bodyText confidence="0.999732884615385">
The experiments in this section were conducted
on the held out development relation hasWon-
Prize. The ranking produced by both forms of
iterative bootstrapping IB1 and IB2 depend on
the number of iterations, as shown in Figure 1.
IB1 achieves an optimal ranking after just one
iteration and thereafter scores get worse due to
semantic drift. In contrast, pruning helps avoid
semantic drift for IB2, which attains an optimal
score after 2 iterations and achieves relatively
constant scores for several iterations. However,
during iteration 9 an incorrect pattern is kept
and this at once leads to a drastic loss in ac-
curacy, showing that semantic drift is only de-
ferred and not completely eliminated.
Our method HT has parameter T, correspond-
ing to the truncation time, i.e., maximal number
of steps of a random walk. Figure 2 shows the
PRM of our method for different values of T.
Performance gets better as T increases and is
optimal for T = 12, whereas for larger values,
the performance gets slightly worse again. The
figure shows that, if T is large enough (&gt; 5), the
PRM is relatively constant and there is no phe-
nomenon comparable to semantic drift, which
causes instability in the produced rankings.
</bodyText>
<footnote confidence="0.896647">
3other common metrics do not satisfy these conditions.
</footnote>
<figureCaption confidence="0.949879833333333">
Figure 1: PRM for iterative bootstrapping with-
out pruning (IB1) and with pruning (IB2). A
lower PRM is better.
Figure 2: PRM for our method based on hitting
times, for different values of the truncation time
parameter T.
</figureCaption>
<subsectionHeader confidence="0.999867">
3.2 Method Comparison
</subsectionHeader>
<bodyText confidence="0.999874714285714">
To evaluate the methods, firstly the parameters
for each method were set to the optimal values
as determined in the previous section. For the
experiments here, we again use 200 randomly
chosen tuples as the seeds for each relation. All
the remaining gold standard tuples are used for
testing.
Table 1 shows the PRM for the three methods.
For a majority of the relations (12/16) HT at-
tains the best, i.e. lowest, PRM, which confirms
that hitting times constitute an accurate way of
measuring the distance of tuples to the seed set.
IB1 and IB2 each perform best on 2/16 of the
relations. A sign test on these results yields that
</bodyText>
<page confidence="0.996352">
774
</page>
<table confidence="0.999984">
Relation IB1 IB2 HT
created 1.82 1.71 0.803
dealsWith 0.0262 0.107 0.0481
diedIn 30.5 18.4 20.4
directed 0.171 0.238 0.166
hasChild 7.66 32.2 4.26
influences 5.93 5.48 6.60
isAffiliatedTo 1.54 2.01 1.30
isCitizenOf 1.74 1.87 1.68
isLeaderOf 1.37 1.91 0.401
isMarriedTo 4.69 4.14 1.27
isPoliticianOf 0.0117 0.110 0.0409
livesIn 3.17 2.48 1.70
owns 11.0 2.10 2.07
produced 1.55 0.967 0.240
wasBornIn 11.3 9.37 8.42
worksAt 1.52 2.21 0.193
</table>
<tableCaption confidence="0.987236">
Table 1: PRM in percent for all relations, for all
</tableCaption>
<figureCaption confidence="0.827645166666667">
three models. A lower PRM corresponds to a
better model, with the best score indicated in
bold.
Figure 3: PRM for the three methods, as a func-
tion of the size of the seed set for the relation
created.
</figureCaption>
<bodyText confidence="0.990387272727273">
HT is better than both IB1 and IB2 at signifi-
cance level α &lt; 0.01.
Moreover, the ranking produced by HT is sta-
ble and not affected by semantic drift, given that
even where results are worse than for IB1 or
IB2, they are still close to the best performing
method. In contrast, when semantic drift oc-
curs, the performance of IB1 and IB2 can dete-
riorate drastically, e.g. for the worksAt relation,
where both IB1 and IB2 produce rankings that
are a lot worse than the one produced by HT.
</bodyText>
<subsectionHeader confidence="0.999576">
3.3 Sensitivity to Seed Set Size
</subsectionHeader>
<bodyText confidence="0.999974733333333">
Figure 3 shows the PRM for each of the three
methods as a function of the size of the seed set
for the relation created. For small seed sets, the
performance of the iterative methods can be in-
creased by adding more seeds. However, from
a seed set size of 50 onwards, performance re-
mains relatively constant. In other words, iter-
ative bootstrapping is not benefitting from the
information provided by the additional labeled
data, and thus has a poor learning performance.
In contrast, for our method based on hitting
times, the performance continually improves as
the seed set size is increased. Thus, also in terms
of learning performance, our method is more
sound than iterative bootstrapping.
</bodyText>
<sectionHeader confidence="0.998778" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999994629629629">
The paper has presented a graph-based method
for seed set expansion which is not susceptible
to semantic drift and on most relations outper-
forms iterative bootstrapping. The method mea-
sures distance between vertices through random
walk hitting times. One property which makes
hitting times an appropriate distance measure
is their ability to reflect the overall connectivity
structure of the graph, in contrast to measures
such as the shortest path between two vertices.
The hitting time will decrease when the num-
ber of paths from the start vertex to the tar-
get vertex increases, when the length of paths
decreases or when the likelihood (weights) of
paths increases. These properties are particu-
larly important when the observed graph edges
must be assumed to be merely a sample of all
plausible edges, possibly perturbated by noise.
This has also been asserted by previous work,
which has shown that hitting times successfully
capture the notion of similarity for other natural
language processing problems such as learning
paraphrases (Kok and Brockett, 2010) and re-
lated problems such as query suggestion (Mei
et al., 2008). Future work will be aimed to-
wards employing our hitting time based method
in combination with a richer feature set.
</bodyText>
<page confidence="0.997493">
775
</page>
<sectionHeader confidence="0.996219" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998723513513514">
Agichtein, E. and Gravano, L. (2000). Snow-
ball: Extracting Relations from Large Plain-
text Collections. In Proceedings of the Fifth
ACM Conference on Digital Libraries.
Brin, S. (1998). Extracting Patterns and Rela-
tions from the World-Wide Web. In Proceed-
ings of the 1998 International Workshop on the
Web and Databases.
Curran, J., Murphy, T., and Scholz, B. (2007).
Minimising Semantic Drift with Mutual Exclu-
sion Bootstrapping. In Proceedings of the 10th
Conference of the Pacific Association for Com-
putational Linguistics.
Francois, F., Pirotte, A., Renders, J., and
Saerens, M. (2007). Random-Walk Computa-
tion of Similarities between Nodes of a Graph
with Application to Collaborative Recommen-
dation. IEEE Transactions on Knowledge and
Data Engineering, 19(3):355 –369.
Kok, S. and Brockett, C. (2010). Hitting the
Right Paraphrases in Good Time. In Proceed-
ings of the Annual Conference of the North
American Chapter of the Association for Com-
putational Linguistics.
Komachi, M., Kudo, T., Shimbo, M., and Mat-
sumoto, Y. (2008). Graph-based Analysis
of Semantic Drift in Espresso-like Bootstrap-
ping Algorithms. In Proceedings of the Con-
ference on Empirical Methods in Natural Lan-
guage Processing.
McIntosh, T. and Curran, J. (2009). Reduc-
ing Semantic Drift with Bagging and Distri-
butional Similarity. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the
ACL.
Mei, Q., Zhou, D., and Church, K. (2008). Query
Suggestion Using Hitting Time. In Proceed-
ings of the 17th ACM Conference on Informa-
tion and Knowledge Management.
Pantel, P. and Pennacchiotti, M. (2006).
Espresso: Leveraging Generic Patterns for Au-
tomatically Harvesting Semantic Relations. In
Proceedings of the 21st International Confer-
ence on Computational Linguistics and the 44th
Annual Meeting of the Association for Compu-
tational Linguistics.
Parker, R., Graff, D., Kong, J., Chen, K., and
Maeda, K. (2011). English Gigaword Fifth
Edition. Technical report, Linguistic Data
Consortium.
Pasca, M., Lin, D., Bigham, J., Lifchits, A., and
Jain, A. (2006). Organizing and Searching
the World Wide Web of Facts – Step One: the
One-million Fact Extraction Challenge. In Pro-
ceedings of the 21st National Conference on Ar-
tificial Intelligence (AAAI).
Sarkar, P. and Moore, A. (2007). A Tractable
Approach to Finding Closest Truncated-
commute-time Neighbors in Large Graphs. In
Proceedings of the 23rd Conference on Uncer-
tainty in Artificial Intelligence.
Sarkar, P., Moore, A., and Prakash, A. (2008).
Fast Incremental Proximity Search in Large
Graphs. In Proceedings of the 25th Interna-
tional Conference on Machine Learning.
Suchanek, F., Kasneci, G., and Weikum, G.
(2007). Yago: A Core of Semantic Knowl-
edge. In Proceedings of the International World
Wide Web Conference (WWW).
T. McIntosh (2010). Unsupervised Discovery
of Negative Categories in Lexicon Bootstrap-
ping. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Pro-
cessing.
</reference>
<page confidence="0.998519">
776
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.669338">
<title confidence="0.97098">Graph-Based Seed Set Expansion for Relation Extraction Random Walk Hitting Times</title>
<author confidence="0.988106">Joel</author>
<affiliation confidence="0.999802">University of</affiliation>
<address confidence="0.9386515">7 Route de 1227 Carouge,</address>
<email confidence="0.991794">joel.lang@unige.ch</email>
<author confidence="0.858921">James</author>
<affiliation confidence="0.997839">Xerox Research Centre</affiliation>
<address confidence="0.9769685">6 Chemin de 38240 Meylan,</address>
<email confidence="0.999951">james.henderson@xrce.xerox.com</email>
<abstract confidence="0.999680235294118">Iterative bootstrapping methods are widely employed for relation extraction, especially because they require only a small amount of human supervision. Unfortunately, a phenomenon known drift affect the accuracy of iterative bootstrapping and lead to poor extractions. This paper proposes an alternative bootstrapping method, which ranks relation tuples by measuring their distance to the seed tuples in a bipartite tuple-pattern graph. In contrast to previous bootstrapping methods, our method is not susceptible to semantic drift, and it empirically results in better extractions than iterative methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agichtein</author>
<author>L Gravano</author>
</authors>
<title>Snowball: Extracting Relations from Large Plaintext Collections.</title>
<date>2000</date>
<booktitle>In Proceedings of the Fifth ACM Conference on Digital Libraries.</booktitle>
<contexts>
<context position="1189" citStr="Agichtein and Gravano, 2000" startWordPosition="166" endWordPosition="169"> and lead to poor extractions. This paper proposes an alternative bootstrapping method, which ranks relation tuples by measuring their distance to the seed tuples in a bipartite tuple-pattern graph. In contrast to previous bootstrapping methods, our method is not susceptible to semantic drift, and it empirically results in better extractions than iterative methods. 1 Introduction The goal of relation extraction is to extract tuples of a particular relation from a corpus of natural language text. A widely employed approach to relation extraction is based on iterative bootstrapping (Brin, 1998; Agichtein and Gravano, 2000; Pasca et al., 2006; Pantel and Pennacchiotti, 2006), which can be applied with only small amounts of supervision and which scales well to very large datasets. A well-known problem with iterative bootstrapping is a phenomenon known as semantic drift (Curran et al., 2007): as bootstrapping proceeds it is likely that unreliable patterns will lead to false extractions. These extraction errors are amplified in the following iterations and the extracted relation will drift away from the intended target. Semantic drift often results in low precision extractions and therefore poses a major limitatio</context>
</contexts>
<marker>Agichtein, Gravano, 2000</marker>
<rawString>Agichtein, E. and Gravano, L. (2000). Snowball: Extracting Relations from Large Plaintext Collections. In Proceedings of the Fifth ACM Conference on Digital Libraries.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brin</author>
</authors>
<title>Extracting Patterns and Relations from the World-Wide Web. In</title>
<date>1998</date>
<booktitle>Proceedings of the 1998 International Workshop on the Web and Databases.</booktitle>
<contexts>
<context position="1160" citStr="Brin, 1998" startWordPosition="164" endWordPosition="165">ootstrapping and lead to poor extractions. This paper proposes an alternative bootstrapping method, which ranks relation tuples by measuring their distance to the seed tuples in a bipartite tuple-pattern graph. In contrast to previous bootstrapping methods, our method is not susceptible to semantic drift, and it empirically results in better extractions than iterative methods. 1 Introduction The goal of relation extraction is to extract tuples of a particular relation from a corpus of natural language text. A widely employed approach to relation extraction is based on iterative bootstrapping (Brin, 1998; Agichtein and Gravano, 2000; Pasca et al., 2006; Pantel and Pennacchiotti, 2006), which can be applied with only small amounts of supervision and which scales well to very large datasets. A well-known problem with iterative bootstrapping is a phenomenon known as semantic drift (Curran et al., 2007): as bootstrapping proceeds it is likely that unreliable patterns will lead to false extractions. These extraction errors are amplified in the following iterations and the extracted relation will drift away from the intended target. Semantic drift often results in low precision extractions and ther</context>
</contexts>
<marker>Brin, 1998</marker>
<rawString>Brin, S. (1998). Extracting Patterns and Relations from the World-Wide Web. In Proceedings of the 1998 International Workshop on the Web and Databases.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Curran</author>
<author>T Murphy</author>
<author>B Scholz</author>
</authors>
<title>Minimising Semantic Drift with Mutual Exclusion Bootstrapping.</title>
<date>2007</date>
<booktitle>In Proceedings of the 10th Conference of the Pacific Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1461" citStr="Curran et al., 2007" startWordPosition="211" endWordPosition="214">semantic drift, and it empirically results in better extractions than iterative methods. 1 Introduction The goal of relation extraction is to extract tuples of a particular relation from a corpus of natural language text. A widely employed approach to relation extraction is based on iterative bootstrapping (Brin, 1998; Agichtein and Gravano, 2000; Pasca et al., 2006; Pantel and Pennacchiotti, 2006), which can be applied with only small amounts of supervision and which scales well to very large datasets. A well-known problem with iterative bootstrapping is a phenomenon known as semantic drift (Curran et al., 2007): as bootstrapping proceeds it is likely that unreliable patterns will lead to false extractions. These extraction errors are amplified in the following iterations and the extracted relation will drift away from the intended target. Semantic drift often results in low precision extractions and therefore poses a major limitation of iterative bootstrapping algorithms. Previous work on iterative bootstrapping has addressed the issue of reducing semantic drift for example by bagging the results of various runs employing differing seed tuples, constructing filters which identify false tuples or pat</context>
</contexts>
<marker>Curran, Murphy, Scholz, 2007</marker>
<rawString>Curran, J., Murphy, T., and Scholz, B. (2007). Minimising Semantic Drift with Mutual Exclusion Bootstrapping. In Proceedings of the 10th Conference of the Pacific Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Francois</author>
<author>A Pirotte</author>
<author>J Renders</author>
<author>M Saerens</author>
</authors>
<title>Random-Walk Computation of Similarities between Nodes of a Graph with Application to Collaborative Recommendation.</title>
<date>2007</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<volume>19</volume>
<issue>3</issue>
<pages>369</pages>
<contexts>
<context position="7014" citStr="Francois et al. 2007" startWordPosition="1206" endWordPosition="1209">nning a named entity tagger and extracting all pairs of named entities and extracting occurring within the same sentence which do not have another named entity standing between them. Gold standard seed and test tuples for a set of relations were obtained from YAGO (Suchanek et al., 2007). Specifically, we took all relations for which there are at least 300 tuples, each of which occurs at least once in the corpus. This resulted in the set of relations shown in Table 1, plus the development relation hasWonPrixe. For evaluation, we use the percentile rank of the median test set element (PRM, see Francois et al. 2007), which reflects the quality of the m ˆhT (vj|vi) = 1 M k=1 1 σHT (v) 773 full produced ranking, not just the top N elements and is furthermore computable with only a small set of labeled test tuples 3. We compare our proposed method based on hitting times (HT) with two variants of iterative bootstrapping. The first one (IB1) does not employ pruning and corresponds to the algorithm described in Komachi et al. (2008). The second one (IB2) corresponds to a standard bootstrapping algorithm which employs pruning after each step in order to reduce semantic drift. Specifically, scores are pruned aft</context>
</contexts>
<marker>Francois, Pirotte, Renders, Saerens, 2007</marker>
<rawString>Francois, F., Pirotte, A., Renders, J., and Saerens, M. (2007). Random-Walk Computation of Similarities between Nodes of a Graph with Application to Collaborative Recommendation. IEEE Transactions on Knowledge and Data Engineering, 19(3):355 –369.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kok</author>
<author>C Brockett</author>
</authors>
<title>Hitting the Right Paraphrases in Good Time.</title>
<date>2010</date>
<booktitle>In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<marker>Kok, Brockett, 2010</marker>
<rawString>Kok, S. and Brockett, C. (2010). Hitting the Right Paraphrases in Good Time. In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Komachi</author>
<author>T Kudo</author>
<author>M Shimbo</author>
<author>Y Matsumoto</author>
</authors>
<title>Graph-based Analysis of Semantic Drift in Espresso-like Bootstrapping Algorithms.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="2242" citStr="Komachi et al. (2008)" startWordPosition="334" endWordPosition="337">ons and the extracted relation will drift away from the intended target. Semantic drift often results in low precision extractions and therefore poses a major limitation of iterative bootstrapping algorithms. Previous work on iterative bootstrapping has addressed the issue of reducing semantic drift for example by bagging the results of various runs employing differing seed tuples, constructing filters which identify false tuples or patterns and adding further constraints to the bootstrapping process (T. McIntosh, 2010; McIntosh and Curran, 2009; Curran et al., 2007). However, the analysis of Komachi et al. (2008) has shown that semantic drift is an inherent property of iterative bootstrapping algorithms and therefore poses a fundamental problem. They have shown that iterative bootstrapping without pruning corresponds to an eigenvector computation and thus as the number of iterations increases the resulting ranking will always converge towards the same static ranking of tuples, regardless of the particular choice of seed instances. In this paper, we describe an alternative method, that is not susceptible to semantic drift. We represent our data as a bipartite graph, whose vertices correspond to pattern</context>
<context position="7433" citStr="Komachi et al. (2008)" startWordPosition="1283" endWordPosition="1286">is resulted in the set of relations shown in Table 1, plus the development relation hasWonPrixe. For evaluation, we use the percentile rank of the median test set element (PRM, see Francois et al. 2007), which reflects the quality of the m ˆhT (vj|vi) = 1 M k=1 1 σHT (v) 773 full produced ranking, not just the top N elements and is furthermore computable with only a small set of labeled test tuples 3. We compare our proposed method based on hitting times (HT) with two variants of iterative bootstrapping. The first one (IB1) does not employ pruning and corresponds to the algorithm described in Komachi et al. (2008). The second one (IB2) corresponds to a standard bootstrapping algorithm which employs pruning after each step in order to reduce semantic drift. Specifically, scores are pruned after projecting from X onto Y and from Y onto X, retaining only the top N(t) = N0t scores at iteration t and setting all other scores to zero. 3.1 Parametrizations The experiments in this section were conducted on the held out development relation hasWonPrize. The ranking produced by both forms of iterative bootstrapping IB1 and IB2 depend on the number of iterations, as shown in Figure 1. IB1 achieves an optimal rank</context>
</contexts>
<marker>Komachi, Kudo, Shimbo, Matsumoto, 2008</marker>
<rawString>Komachi, M., Kudo, T., Shimbo, M., and Matsumoto, Y. (2008). Graph-based Analysis of Semantic Drift in Espresso-like Bootstrapping Algorithms. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T McIntosh</author>
<author>J Curran</author>
</authors>
<title>Reducing Semantic Drift with Bagging and Distributional Similarity.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="2172" citStr="McIntosh and Curran, 2009" startWordPosition="322" endWordPosition="325">xtractions. These extraction errors are amplified in the following iterations and the extracted relation will drift away from the intended target. Semantic drift often results in low precision extractions and therefore poses a major limitation of iterative bootstrapping algorithms. Previous work on iterative bootstrapping has addressed the issue of reducing semantic drift for example by bagging the results of various runs employing differing seed tuples, constructing filters which identify false tuples or patterns and adding further constraints to the bootstrapping process (T. McIntosh, 2010; McIntosh and Curran, 2009; Curran et al., 2007). However, the analysis of Komachi et al. (2008) has shown that semantic drift is an inherent property of iterative bootstrapping algorithms and therefore poses a fundamental problem. They have shown that iterative bootstrapping without pruning corresponds to an eigenvector computation and thus as the number of iterations increases the resulting ranking will always converge towards the same static ranking of tuples, regardless of the particular choice of seed instances. In this paper, we describe an alternative method, that is not susceptible to semantic drift. We represe</context>
</contexts>
<marker>McIntosh, Curran, 2009</marker>
<rawString>McIntosh, T. and Curran, J. (2009). Reducing Semantic Drift with Bagging and Distributional Similarity. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Mei</author>
<author>D Zhou</author>
<author>K Church</author>
</authors>
<title>Query Suggestion Using Hitting Time.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th ACM Conference on Information and Knowledge Management.</booktitle>
<marker>Mei, Zhou, Church, 2008</marker>
<rawString>Mei, Q., Zhou, D., and Church, K. (2008). Query Suggestion Using Hitting Time. In Proceedings of the 17th ACM Conference on Information and Knowledge Management.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
<author>M Pennacchiotti</author>
</authors>
<title>Espresso: Leveraging Generic Patterns for Automatically Harvesting Semantic Relations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1242" citStr="Pantel and Pennacchiotti, 2006" startWordPosition="174" endWordPosition="177">s an alternative bootstrapping method, which ranks relation tuples by measuring their distance to the seed tuples in a bipartite tuple-pattern graph. In contrast to previous bootstrapping methods, our method is not susceptible to semantic drift, and it empirically results in better extractions than iterative methods. 1 Introduction The goal of relation extraction is to extract tuples of a particular relation from a corpus of natural language text. A widely employed approach to relation extraction is based on iterative bootstrapping (Brin, 1998; Agichtein and Gravano, 2000; Pasca et al., 2006; Pantel and Pennacchiotti, 2006), which can be applied with only small amounts of supervision and which scales well to very large datasets. A well-known problem with iterative bootstrapping is a phenomenon known as semantic drift (Curran et al., 2007): as bootstrapping proceeds it is likely that unreliable patterns will lead to false extractions. These extraction errors are amplified in the following iterations and the extracted relation will drift away from the intended target. Semantic drift often results in low precision extractions and therefore poses a major limitation of iterative bootstrapping algorithms. Previous wor</context>
</contexts>
<marker>Pantel, Pennacchiotti, 2006</marker>
<rawString>Pantel, P. and Pennacchiotti, M. (2006). Espresso: Leveraging Generic Patterns for Automatically Harvesting Semantic Relations. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Parker</author>
<author>D Graff</author>
<author>J Kong</author>
<author>K Chen</author>
<author>K Maeda</author>
</authors>
<title>English Gigaword Fifth Edition.</title>
<date>2011</date>
<tech>Technical report,</tech>
<institution>Linguistic Data Consortium.</institution>
<contexts>
<context position="6386" citStr="Parker et al., 2011" startWordPosition="1096" endWordPosition="1099">runcated hitting time hT (vj|vi) can be approximately computed by sampling M independent random walks starting at vi of length T and computing m tk + (1 − M )T (1) where {t1 ... tm} are the sampled first-hit times of random walks which reach vj within T steps (Sarkar et al., 2008). The score σHT (v) of a vertex v E/ S to the seed set S is then defined as the inverse of the average T-truncated hitting time of random walks starting at a randomly chosen vertex s E S: � hT(v|s) (2) = hT (v|S) = 1 |S| sES 3 Experiments We extracted tuples and patterns from the fifth edition of the Gigaword corpus (Parker et al., 2011), by running a named entity tagger and extracting all pairs of named entities and extracting occurring within the same sentence which do not have another named entity standing between them. Gold standard seed and test tuples for a set of relations were obtained from YAGO (Suchanek et al., 2007). Specifically, we took all relations for which there are at least 300 tuples, each of which occurs at least once in the corpus. This resulted in the set of relations shown in Table 1, plus the development relation hasWonPrixe. For evaluation, we use the percentile rank of the median test set element (PR</context>
</contexts>
<marker>Parker, Graff, Kong, Chen, Maeda, 2011</marker>
<rawString>Parker, R., Graff, D., Kong, J., Chen, K., and Maeda, K. (2011). English Gigaword Fifth Edition. Technical report, Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pasca</author>
<author>D Lin</author>
<author>J Bigham</author>
<author>A Lifchits</author>
<author>A Jain</author>
</authors>
<title>Organizing and Searching the World Wide Web of Facts – Step One: the One-million Fact Extraction Challenge.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st National Conference on Artificial Intelligence (AAAI).</booktitle>
<contexts>
<context position="1209" citStr="Pasca et al., 2006" startWordPosition="170" endWordPosition="173">. This paper proposes an alternative bootstrapping method, which ranks relation tuples by measuring their distance to the seed tuples in a bipartite tuple-pattern graph. In contrast to previous bootstrapping methods, our method is not susceptible to semantic drift, and it empirically results in better extractions than iterative methods. 1 Introduction The goal of relation extraction is to extract tuples of a particular relation from a corpus of natural language text. A widely employed approach to relation extraction is based on iterative bootstrapping (Brin, 1998; Agichtein and Gravano, 2000; Pasca et al., 2006; Pantel and Pennacchiotti, 2006), which can be applied with only small amounts of supervision and which scales well to very large datasets. A well-known problem with iterative bootstrapping is a phenomenon known as semantic drift (Curran et al., 2007): as bootstrapping proceeds it is likely that unreliable patterns will lead to false extractions. These extraction errors are amplified in the following iterations and the extracted relation will drift away from the intended target. Semantic drift often results in low precision extractions and therefore poses a major limitation of iterative boots</context>
</contexts>
<marker>Pasca, Lin, Bigham, Lifchits, Jain, 2006</marker>
<rawString>Pasca, M., Lin, D., Bigham, J., Lifchits, A., and Jain, A. (2006). Organizing and Searching the World Wide Web of Facts – Step One: the One-million Fact Extraction Challenge. In Proceedings of the 21st National Conference on Artificial Intelligence (AAAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Sarkar</author>
<author>A Moore</author>
</authors>
<title>A Tractable Approach to Finding Closest Truncatedcommute-time Neighbors in Large Graphs.</title>
<date>2007</date>
<booktitle>In Proceedings of the 23rd Conference on Uncertainty in Artificial Intelligence.</booktitle>
<contexts>
<context position="5558" citStr="Sarkar and Moore, 2007" startWordPosition="929" endWordPosition="932">sition probabilities. Edge weights are constrained to be non-negative, which allows us to define the transition matrix P with Pi,j = p(vj|vi) = d1. w(vi, vj), where dv = z E vkEV w(v, vk) is the degree of a vertex v E V . The distance of two vertices is measured in terms of the average time of a random walk be1Note that we are using tuple and pattern types rather than particular mentions in the corpus. 2The term is used informally. In particular, hitting times are not a distance metric, since they can be asymmetric. tween the two. Specifically, we adopt the notion of T-truncated hitting time (Sarkar and Moore, 2007) defined as the expected number of steps it takes until a random walk of at most T steps starting at vi reaches vj for the first time: � 0 iff. vj = vi or T=0 hT (vj|vi) = 1 + EvkEV p(vk|vi)hT −1(vj|vk) The truncated hitting time hT (vj|vi) can be approximately computed by sampling M independent random walks starting at vi of length T and computing m tk + (1 − M )T (1) where {t1 ... tm} are the sampled first-hit times of random walks which reach vj within T steps (Sarkar et al., 2008). The score σHT (v) of a vertex v E/ S to the seed set S is then defined as the inverse of the average T-trunca</context>
</contexts>
<marker>Sarkar, Moore, 2007</marker>
<rawString>Sarkar, P. and Moore, A. (2007). A Tractable Approach to Finding Closest Truncatedcommute-time Neighbors in Large Graphs. In Proceedings of the 23rd Conference on Uncertainty in Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Sarkar</author>
<author>A Moore</author>
<author>A Prakash</author>
</authors>
<title>Fast Incremental Proximity Search in Large Graphs.</title>
<date>2008</date>
<booktitle>In Proceedings of the 25th International Conference on Machine Learning.</booktitle>
<contexts>
<context position="6047" citStr="Sarkar et al., 2008" startWordPosition="1027" endWordPosition="1030">since they can be asymmetric. tween the two. Specifically, we adopt the notion of T-truncated hitting time (Sarkar and Moore, 2007) defined as the expected number of steps it takes until a random walk of at most T steps starting at vi reaches vj for the first time: � 0 iff. vj = vi or T=0 hT (vj|vi) = 1 + EvkEV p(vk|vi)hT −1(vj|vk) The truncated hitting time hT (vj|vi) can be approximately computed by sampling M independent random walks starting at vi of length T and computing m tk + (1 − M )T (1) where {t1 ... tm} are the sampled first-hit times of random walks which reach vj within T steps (Sarkar et al., 2008). The score σHT (v) of a vertex v E/ S to the seed set S is then defined as the inverse of the average T-truncated hitting time of random walks starting at a randomly chosen vertex s E S: � hT(v|s) (2) = hT (v|S) = 1 |S| sES 3 Experiments We extracted tuples and patterns from the fifth edition of the Gigaword corpus (Parker et al., 2011), by running a named entity tagger and extracting all pairs of named entities and extracting occurring within the same sentence which do not have another named entity standing between them. Gold standard seed and test tuples for a set of relations were obtained</context>
</contexts>
<marker>Sarkar, Moore, Prakash, 2008</marker>
<rawString>Sarkar, P., Moore, A., and Prakash, A. (2008). Fast Incremental Proximity Search in Large Graphs. In Proceedings of the 25th International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Suchanek</author>
<author>G Kasneci</author>
<author>G Weikum</author>
</authors>
<title>Yago: A Core of Semantic Knowledge.</title>
<date>2007</date>
<booktitle>In Proceedings of the International World Wide Web Conference (WWW).</booktitle>
<contexts>
<context position="6681" citStr="Suchanek et al., 2007" startWordPosition="1147" endWordPosition="1150">σHT (v) of a vertex v E/ S to the seed set S is then defined as the inverse of the average T-truncated hitting time of random walks starting at a randomly chosen vertex s E S: � hT(v|s) (2) = hT (v|S) = 1 |S| sES 3 Experiments We extracted tuples and patterns from the fifth edition of the Gigaword corpus (Parker et al., 2011), by running a named entity tagger and extracting all pairs of named entities and extracting occurring within the same sentence which do not have another named entity standing between them. Gold standard seed and test tuples for a set of relations were obtained from YAGO (Suchanek et al., 2007). Specifically, we took all relations for which there are at least 300 tuples, each of which occurs at least once in the corpus. This resulted in the set of relations shown in Table 1, plus the development relation hasWonPrixe. For evaluation, we use the percentile rank of the median test set element (PRM, see Francois et al. 2007), which reflects the quality of the m ˆhT (vj|vi) = 1 M k=1 1 σHT (v) 773 full produced ranking, not just the top N elements and is furthermore computable with only a small set of labeled test tuples 3. We compare our proposed method based on hitting times (HT) with </context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Suchanek, F., Kasneci, G., and Weikum, G. (2007). Yago: A Core of Semantic Knowledge. In Proceedings of the International World Wide Web Conference (WWW).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T McIntosh</author>
</authors>
<title>Unsupervised Discovery of Negative Categories in Lexicon Bootstrapping.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="2145" citStr="McIntosh, 2010" startWordPosition="319" endWordPosition="321"> lead to false extractions. These extraction errors are amplified in the following iterations and the extracted relation will drift away from the intended target. Semantic drift often results in low precision extractions and therefore poses a major limitation of iterative bootstrapping algorithms. Previous work on iterative bootstrapping has addressed the issue of reducing semantic drift for example by bagging the results of various runs employing differing seed tuples, constructing filters which identify false tuples or patterns and adding further constraints to the bootstrapping process (T. McIntosh, 2010; McIntosh and Curran, 2009; Curran et al., 2007). However, the analysis of Komachi et al. (2008) has shown that semantic drift is an inherent property of iterative bootstrapping algorithms and therefore poses a fundamental problem. They have shown that iterative bootstrapping without pruning corresponds to an eigenvector computation and thus as the number of iterations increases the resulting ranking will always converge towards the same static ranking of tuples, regardless of the particular choice of seed instances. In this paper, we describe an alternative method, that is not susceptible to</context>
</contexts>
<marker>McIntosh, 2010</marker>
<rawString>T. McIntosh (2010). Unsupervised Discovery of Negative Categories in Lexicon Bootstrapping. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>