<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.848306">
One-Level Phonology: Autosegmental
Representations and Rules as Finite
Automata
</note>
<author confidence="0.998889">
Steven Bird* T. Mark Ellison*
</author>
<affiliation confidence="0.999233">
University of Edinburgh University of Edinburgh
</affiliation>
<bodyText confidence="0.982158714285714">
When phonological rules are regarded as declarative descriptions, it is possible to construct a model
of phonology in which rules and representations are no longer distinguished and such procedural
devices as rule-ordering are absent. In this paper we present a finite-state model of phonology
in which automata are the descriptions and tapes (or strings) are the objects being described.
This provides the formal semantics for an autosegmental phonology without structure-changing
rules. Logical operations on the phonological domain—such as conjunction, disjunction, and
negation—make sense since the phonological domain consists of descriptions rather than objects.
These operations as applied to automata are the straightforward operations of intersection, union,
and complement. If the arrow in a rewrite rule is viewed as logical implication, then a phonological
rule can also be represented as an automaton, albeit a less restrictive automaton than would be
required for a lexical representation. The model is then compared with the transducer models for
autosegmental phonology of Kay (1987), Kornai (1991), and Wiebe (1992). We conclude that the
declarative approach to phonology presents an attractive way of extending finite-state techniques
to autosegmental phonology while remaining within the confines of regular grammar.
</bodyText>
<sectionHeader confidence="0.985459" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999947181818182">
The decade since the publication of Koskenniemi&apos;s dissertation (1983) and since the
development of the KIMMO system (Karttunen 1983) has witnessed a spectacular flurry
of activity as the linguistic and computational consequences of this work have been
fleshed out. A considerable body of literature has grown up around TWO-LEVEL MOR-
PHOLOGY, along with texts&apos; and implementations.&apos; The existence of a rule compiler
(Koskenniemi 1985) has made it possible for the linguist to work at a conveniently
abstract level, and analyses of several languages now exemplify the approach. Today,
two-level morphology encompasses much of traditional segmental generative phonol-
ogy of the SPE variety (Chomsky and Halle 1968).3
Although further development and application of this model is set to continue for
some time, there is now a clear need to integrate it more closely with computational
</bodyText>
<footnote confidence="0.816099">
* University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW,
Scotland, U.K. E-mail: {steven,marke}@cogsci.ed.ac.uk
1 (Antworth 1990; Ritchie, Russell, Black, and Pulman 1992; Sproat 1992)
2 (Bear 1986; Antworth 1990; Schiller and Steffens 1991; Pulman and Hepple 1993)
3 Two caveats are necessary here. SPE rules must be restricted so as not to apply to their own output
(Johnson 1972) and there is no guarantee that the transducer encoding an SPE rule can be expressed
using the two-level rule notation (Ritchie 1992).
</footnote>
<note confidence="0.871535">
C) 1994 Association for Computational Linguistics
Computational Linguistics Volume 20, Number 1
</note>
<bodyText confidence="0.998764761904762">
grammar frameworks on the one hand and modern nonlinear phonology on the other.
The primary goal of this article is to show how the central tenets of autosegmental
phonology translate into an implemented finite state model.
The model is named ONE-LEVEL PHONOLOGY for two reasons. First, the model
is monostratal, in that there is only one level of linguistic description. Second, the
name is intended to contrast with models employing two levels (such as the FST
model mentioned above) or three levels (Goldsmith 1991; Touretzky and Wheeler
1990), or an unbounded number of levels (Chomsky and Halle 1968). The one-level
model represents the outgrowth of three independent strands of research: (i) the finite-
state modeling of phonology, (ii) the declarative approach to phonology,&apos; and (iii) the
automatic learning of phonological generalizations (Ellison 1992, 1993).
The paper is organized as follows. Section 2 presents an overview of autosegmen-
tal phonology and the temporal semantics of Bird and Klein (1990). Then we define
state-labeled automata (Section 3.1), show their equivalence to finite state automata
(Section 3.2), define the operations of concatenation, union, intersection, and com-
plement (Section 3.3), and further define state-labeled transducers (Section 3.4). The
central proposals of the paper are contained in Section 4. We show how autosegmental
association can be interpreted in terms of the synchronization of two automata, where
each automaton specifies an autosegmental tier. We now give a brief foretaste of this
procedure. Suppose that we have the autosegmental diagram in (1), encoding high
(hi) and round (rd) autosegments.
</bodyText>
<equation confidence="0.748986333333333">
1. +hi —hi
I / I
—rnd +rnd
</equation>
<bodyText confidence="0.989761">
This diagram is encoded as the following expression, where each numeral indicates
the number of association lines incident with its corresponding autosegment.
</bodyText>
<equation confidence="0.9641475">
+hi:1 —hi:2
—rnd : 2 +rnd :1
</equation>
<bodyText confidence="0.9653484">
From this encoding, we can write down the following regular expression. Although
such expressions will be opaque at this early stage of the exposition, it suffices to note
here that each line of the expression represents a tier and the tiers are combined using
the intersection operation (n). Moreover, the is act as synchronization marks between
the operands of the intersection operation.
(+hi, 0)* (+hi, 1) (+hi, 0)* (— hi, 0)* ( — hi, 1) (—hi, 0)* ( —hi, 1) (—hi, 0)*
n (—rnd, 0)*(—rnd, 1) (—rnd, 0)* ( —rnd, 1) (—rnd, 0)* (+rnd, 0)* (+rnd, 1) (+rnd, 0)*
The final step is to compute the intersection and project the first element of each tuple
(ignoring the is and Os). This produces the expression:
(+hi n —rnd)+ (—hi n —rnd)+ (—hi n +rnd)+
</bodyText>
<note confidence="0.322018">
4 Wheeler 1981; Bird 1990; Coleman 1991; Scobbie 1991; Broe 1993; Russell 1993; Mastroianni 1993.
</note>
<page confidence="0.990655">
56
</page>
<note confidence="0.556391">
Steven Bird and T. Mark Ellison One-Level Phonology
</note>
<bodyText confidence="0.999863833333333">
Given plausible interpretations of the high and round features, this last expression
simplifies to i±a+o+, which describes an automaton tape (or a string) divided into
three nonempty intervals, the first containing [i], the second containing [a], and the
third containing [o]. This, we shall claim, is the intended interpretation of (1).
After a detailed discussion of this procedure, the remainder of Section 4 is given
over to generalizing the procedure to an arbitrary number of autosegmental charts
(Section 4.4), an evaluation of the encoding with respect to Kornai&apos;s desiderata (Sec-
tion 4.5), and a presentation of the encoding of autosegmental rules (Section 4.6).
Finally, Section 5 compares our proposals with those of Kay (1987), Kornai (1991),
and Wiebe (1992). While our model has regular grammar power and is fully imple-
mented, these three models go beyond regular grammar power and to our knowledge
have never been implemented.
</bodyText>
<sectionHeader confidence="0.966441" genericHeader="keywords">
2. Background
</sectionHeader>
<bodyText confidence="0.9996695">
It has long been recognized that the SPE model lacks explanatory adequacy, a fact
noted in SPE itself (Chomsky and Halle 1968, pp. 400ff). For example, it is unable to
explain why a final devoicing rule like that in (2a) is commonplace in the languages
of the world, whereas the rule in (2b) is unattested (Kaye 1989, p. 61).
</bodyText>
<listItem confidence="0.979758">
2. (a) [—sonorant] —&gt; [—voice] / — #
(b) [—sonorant] [+nasal] / — #
(c) [] [anasal] / [anasal] — #
(d) [1 [around] / [anasal] — #
</listItem>
<bodyText confidence="0.99995475">
Similarly, the nasal harmony rule in (2c) occurs frequently, while the generalization
expressed in (2d) is as unlikely as (2b). Both SPE and the two-level model are unable
to express the fact that some rules are commonplace while others are highly unnatural.
Perhaps the SPE model could be rescued from these problems with additional
stipulations. However, a more fundamental problem for the model was raised by the
following tone language data (Leben 1973; Goldsmith 1976). At first blush, Mende
vowels appear to manifest five tone patterns, namely high (ko), low (kpa), falling
(mbil), rising (mba) and rise-fall (mbS). The SPE model would predict 25 tonal patterns
for two-syllable morphemes, but instead we find only 5. These are high-high, low-low,
high-low, low-high, and low-falling. Similarly, for three-syllable morphemes we get 5
patterns, not 125. Leben noticed that the one-, two-, and three-syllable morphemes
could be put into correspondence as shown in (3), from Leben (1978).
</bodyText>
<listItem confidence="0.880467">
3. H: k6 war pElt house hawama waistline
</listItem>
<bodyText confidence="0.98634525">
L: kpa debt bElE trousers kpakafi tripod chair
HL: mbil owl nglla dog felama junction
LH: mba rice fande cotton ndavtila sling
LHL: mba&apos; companion nyaha woman nikill groundnut
Goldsmith (1976) devised a graphical notation that made the above correspon-
dence clearer still. We display several examples of his notation in (4). Here, the H
indicates high tone, while L indicates low tone. (The association lines are assumed to
be incident with the vowels.)
</bodyText>
<page confidence="0.996881">
57
</page>
<note confidence="0.778807">
Computational Linguistics Volume 20, Number 1
</note>
<equation confidence="0.902417642857143">
4. k6 pt V ha Aga ma
1/
H H H
kpa bt V kpa ka 11
L L L
mbil ngi la fe la ma
1 \ 1 1 I 1 /
HL HL HL
mba fa nde nda vil la
I \ 1 I I 1 /
LH LH LH
mba‘ nya ha ni ki 11
/ I \ 1 1 \ 1 1 1
LHL LHL LHL
</equation>
<bodyText confidence="0.999940166666667">
Observe that each row of the table has the same tone pattern. Only the synchro-
nization varies. In diagrams like the ones in (4), units such as H and L are termed
AUTONOMOUS SEGMENTS, or AUTOSEGMENTS, and a linear sequence of autoseg-
ments is called a TIER. The synchronization markers are called ASSOCIATION LINES.
A pair of tiers linked by some association lines is called a CHART. A chart is called
WELL-FORMED if the following conditions hold (Goldsmith 1976, p. 27).
</bodyText>
<listItem confidence="0.96807975">
5. Well-Formedness Condition:
(a) All vowels are associated with at least one tone;
all tones are associated with at least one vowel.
(b) Association lines do not cross.
</listItem>
<bodyText confidence="0.9563545">
The reader can ascertain that the above charts are well-formed according to (5). How-
ever, (5) is insufficiently restrictive on its own, and a further stipulation is required.
</bodyText>
<sectionHeader confidence="0.428895" genericHeader="introduction">
6. Association Convention: Only the rightmost member of a tier can be
</sectionHeader>
<bodyText confidence="0.458895">
associated to more than one member of another tier.
</bodyText>
<page confidence="0.991073">
58
</page>
<note confidence="0.556131">
Steven Bird and T. Mark Ellison One-Level Phonology
</note>
<bodyText confidence="0.980947130434783">
When (5) and (6) are combined, we achieve the effect of one-to-one left-to-right
association, where multiple association (or SPREADING) occurs only at the right-hand
end. Observe also that the charts in (4) do not contain adjacent identical tones. For
example, there is no HH tone melody. This is expressed by a principle attributable to
Leben (1973).
7. Obligatory Contour Principle: At the melodic level of the grammar, any
two adjacent [autosegments] must be distinct. Thus HHL is not a
possible melodic pattern; it automatically simplifies to HL.
Although nonlinear models like autosegmental phonology represent a major ad-
vance on the linear model of SPE in the area of explanatory adequacy, it has sometimes
been pointed out (e.g., Bird and Ladd 1991) that the formal explicitness of the SPE
model has not been matched by these more recent proposals. Before we can begin
to compute with autosegmental representations and rules, they need to be given a
formal semantics. Our starting point here is the temporal semantics of Bird and Klein
(1990), based on Sagey&apos;s (1988) model, which has gained widespread acceptance in au-
tosegmental phonology. Under this temporal semantics, phonological properties are
attached to intervals that are related using precedence (an asymmetric, transitive re-
lation) and overlap (a reflexive, symmetric relation).
Bird (1990) showed how a phonological description language can be modeled by
such event structures, where the precedence relation models the linear ordering of
tiers and the overlap relation models association lines. In this paper, we shall pro-
vide an automaton-based semantics for precedence and overlap, thus arriving at a
computational semantics for the autosegmental notation.
</bodyText>
<sectionHeader confidence="0.962607" genericHeader="method">
3. State-Labeled Automata
</sectionHeader>
<bodyText confidence="0.999614666666667">
In this section we give definitions for a new device called a state-labeled finite automa-
ton, and then we define various useful operations on these automata. (Some readers
may prefer to skip Section 3 on a first reading.)
</bodyText>
<subsectionHeader confidence="0.858834">
3.1 Definitions
Definition 1
</subsectionHeader>
<bodyText confidence="0.520058">
A STATE-LABELED NONDETERMINISTIC FINITE AUTOMATON (SFA) is a septuple
(V, E, A, 6, S,F, e) where
</bodyText>
<figure confidence="0.877453">
V is a finite set, the set of STATES,
E is a finite set, the ALPHABET,
A c V x E is the LABELING RELATION (states are labeled with subsets of the
alphabet),5
cVxVisthe TRANSITION RELATION,
S C V is the set of START STATES, and
F c V is the set of FINAL STATES.
</figure>
<footnote confidence="0.903938333333333">
e is a Boolean flag that is true iff the null string A is accepted, and false otherwise.
5 Without loss of generality we have chosen to label states with segments (subsets of E), rather than
with strings (subsets of E*).
</footnote>
<page confidence="0.995689">
59
</page>
<note confidence="0.515584">
Computational Linguistics Volume 20, Number 1
</note>
<bodyText confidence="0.9181395">
Before describing the execution of an SFA, we need to define COMPATIBILITY.
Definition 2
We say that a state v is COMPATIBLE with an input a E E if (v, E A.
At each step in the execution of an SFA, a subset of the states is active while the
remainder are inactive. An SFA begins operation with those start states active that are
compatible with the first symbol in the input string. If, at a certain step in processing, a
subset T of states is active, then at the next step, the subset T&apos; of states reachable from T
and compatible with the next input become active. This operation is formalized below,
following the approach taken by Partee et al. (1990). First we define a SITUATION to
be the processing status of an SFA.
</bodyText>
<sectionHeader confidence="0.363682" genericHeader="method">
Definition 3
</sectionHeader>
<bodyText confidence="0.999915">
A SITUATION of an SFA, A, is a triple (x,T,y) where T C V is the set of currently
active states, and x and y are the portions of the input string to the left and right of
the reading head, respectively.
As an SFA operates, it moves through a sequence of these situations. Now HA is defined
as a successor relation on situations for an automaton A.
</bodyText>
<subsectionHeader confidence="0.298192">
Definition 4
</subsectionHeader>
<bodyText confidence="0.7434005">
Let (x, T,y) and (x&apos;, T&apos;,y&apos;) be two situations. Then (x, T,y) iff there is a
a E E such that
</bodyText>
<listItem confidence="0.661984">
(i) y = ay&apos; and x&apos; = xcr,
(ii) for each t&apos; E T&apos; there is atET such that (t, t&apos;) E 6, and
(iii) (t&apos;, o-) E A for each t&apos; ET&apos;.
</listItem>
<bodyText confidence="0.999884857142857">
The first condition in the definition concerns a, the tape symbol being scanned. This
symbol is the first in the string y and the last in the string x&apos;. The second condition
concerns the transition relation, requiring that the new situation must be reachable
from the previous situation. The third condition is a check that a is in the label set of
each currently active state. We define I-A to be the transitive closure of HA. Now we
can specify the conditions under which an SFA accepts a string, where A is the empty
string.
</bodyText>
<subsectionHeader confidence="0.363837">
Definition 5
</subsectionHeader>
<bodyText confidence="0.999734428571429">
Let A (V, E, 6, S,F,e) be an SFA and let WE E. A ACCEPTS w iff either e is true
and w = A, or (a, {s}, a) [-*A (aa, F&apos;, A), for some (s, a) E A, s c S. a E E* and FnF&apos; 0,
and where w = aa.
If no string can cause an SFA to have more than one active state at any processing step,
then we say that the SFA is DETERMINISTIC. In order to signify that an SFA accepts
the empty string A (i.e., if e is true), we shall include a special state, labeled with a
distinguished symbol 0, which is marked both initial and final.
</bodyText>
<page confidence="0.985738">
60
</page>
<bodyText confidence="0.631466">
Steven Bird and T. Mark Ellison One-Level Phonology
</bodyText>
<subsectionHeader confidence="0.980466">
3.2 Relationship to FSAs
</subsectionHeader>
<bodyText confidence="0.998358375">
The equivalence of SFAs and arc-labeled finite-state automata (FSAs) follows from the
equivalence of Mealy and Moore machines.&apos; Although SFAs are no more expressive
than FSAs, there are good linguistic reasons for wishing to use them. The primary
difference between the two devices lies in the relative ease with which particular gen-
eralizations can be expressed. As an illustration, we shall consider the automaton that
prohibits two adjacent occurrences of any given symbol in a string, a constraint known
in autosegmental phonology as the Obligatory Contour Principle. Here is the FSA ver-
sion, using the graphical conventions for representing FSAs adopted by Hoperoft and
Ullman (1979). Bullet marks a state, circled states are final, and states with incoming
arrow heads are initial.
a
The notation we use for state-labeled automata is different. Because states carry labels,
there is no need to use the contentless bullet symbol to mark a state. Instead, the label
itself marks the state. Initial and final states are indicated by arrowheads and circles,
as for FSAs. Arcs are unlabeled.
The SFA that does not admit adjacent occurrences of any symbol in the alphabet
is:
Notice that the number of labels required by the SFA is considerably smaller (5 labels)
than the number required in the FSA (12 labels), while the number of transitions is
the same for both. On the other hand, the SFA has an extra state, labelled with 0 to
show that the automaton accepts the null string (see the final clause of Definition 1).
The difference between the two devices becomes even clearer when we consider
the representations for a* (zero or more as) and a+ (one or more as). First, here are a*
and a+ expressed as FSAs.
</bodyText>
<equation confidence="0.968654">
a+ : •
</equation>
<bodyText confidence="0.885294">
Observe that the specification of the Kleene star requires one state, while Kleene plus
requires two. If we use SFAs instead, we find the reverse: Kleene star requires two
</bodyText>
<footnote confidence="0.868092">
6 See Hoperoft and Ullman (1979, p. 44) for a discussion of this equivalence. An FSA is a Mealy machine
that ignores its input, while an SFA is a Moore machine that ignores its input.
</footnote>
<page confidence="0.99397">
61
</page>
<figure confidence="0.5746428">
Computational Linguistics
Volume 20, Number 1
states, while Kleene plus only requires one.
I
a* &apos; CDI CI-
</figure>
<bodyText confidence="0.9996346">
As we shall see in Section 4, the semantics of phonological representations requires
frequent use of the Kleene plus and little use of the Kleene star. The intuition behind
this is simple. Recall from Section 2 that phonological entities such as distinctive fea-
tures are considered to be descriptions of phonetic events that may extend over an
interval of time. As we saw in the case of tone, the defining feature of an autosegment
may be spread across several segments. Crucially, however, an autosegment must be
present at at least one point, and so it makes sense to view phonological entities—such
as segments and autosegments—in terms of the Kleene plus rather than the Kleene
star.
It might be reasoned that our interval interpretation of segments is better pictured
with arc-labeled devices. After all, the states resemble points while the arcs resem-
ble extended intervals. Furthermore, it may be tempting to use a single arc between
two temporally distant points to show the spreading of an autosegment coarticulated
with two consecutive autosegments on another tier. For example, (8) shows a labial
autosegment, L, bridging two instants also bridged by a nasal segment, N, and stop, S.
</bodyText>
<equation confidence="0.955974666666667">
8. L
&gt;4 ---)- • ---)-I
N S
</equation>
<bodyText confidence="0.999625888888889">
However, this representation is flawed: the semantics assigned to coterminous paths
contradicts the standard interpretation of FSAs. The automaton pictured above would
normally be interpreted as either a nasal followed by a stop or by a single labial
articulation. Crucially, it could not be interpreted as necessarily both a nasal followed
by a stop and a labial articulation.
While viewing states as instants of time and arcs as intervals offers some iconicity,
it is also misleading. It is just as natural—and more in keeping with the logical founda-
tions presented in Section 2—to employ the states for temporally extended intervals,
and the arcs for the relationship of immediate precedence.
</bodyText>
<subsectionHeader confidence="0.999963">
3.3 Basic Operations
</subsectionHeader>
<bodyText confidence="0.999956333333333">
In this section we define the operations of concatenation, union, intersection, and
complement on SFAs. These operations correspond naturally to the operations on the
languages accepted by the automata, as indicated in the following table.
</bodyText>
<figure confidence="0.9132924375">
•\ ( D
r
operation
automata languages
concatenation
union
intersection
complement
Kleene plus
Kleene star
AB {al* E L(A) ,b E L(B)}
A U B L(A) U L(B)
Ans L(A) n L(B)
A L(A)
A+ L(A)+
A* L(A)*
</figure>
<page confidence="0.987216">
62
</page>
<bodyText confidence="0.98587465">
Steven Bird and T. Mark Ellison One-Level Phonology
The Kleene plus operation, which, when applied to a language L gives another L+,
contains the concatenation of one or more strings from L. The Kleene star operation
takes L to {A} U L+ and is written L*.
Recall that the structure (E*; u, n, --,, 0, E*), containing languages over an alphabet
E together with the standard set operations, is a Boolean algebra (Partee et al. 1990,
p. 297ff). Similarly, if A is the set of SFAs, then (A; U, n , --,, I, T) is also a Boolean
algebra, where 1 is the empty automaton (i.e., L(I) = 0) and T is the automaton that
accepts E* (i.e., L(T)
The concatenation of two SFAs A and B, written AB, has an arrow linking each
final state of the first SFA to each initial state of the second. The states that are initial
or final in AB depend on whether A or B accepts the empty string A, as specified in
the following table.
A B AB AB initials AB finals
A 0 L(A) A 0 L(B) A 0 L(AB) A initials B finals
A E L(A) A 0 L(B) A 0 L(AB) A &amp; B initials B finals
A 0 L(A) A E L(B) A 0 L(AB) A initials A &amp; B finals
A e L(A) A e L(B) A E L(AB) A &amp; B initials A &amp; B finals
Suppose we wished to recognize the language AB where A --= (12+3)+ and B =
(45+6)+. The SFAs describing A and B are the following.
</bodyText>
<figure confidence="0.577162">
A: &gt;
1 --&gt;-ID B: &apos; 4 ---&gt;fp
\ \iv
S
Linking final states of A to the initial states of B gives the concatenation.
AB:
</figure>
<bodyText confidence="0.89094">
Since neither A nor B accepts A, the initial state of AB is the initial state of A, and the
final state of AB is the final state of B.
The union (or disjunction) on SFAs is similar, in many ways, to the concatena-
tion operation. The difference is that rather than executing in sequence, the automata
operate in parallel. The union of two automata A and B, written A U B, accepts the
string s iff either A or B, or both, accept s. The union of A and B is expressed dia-
</bodyText>
<page confidence="0.9615985">
7 Of course, these algebras are different, for there are many languages that cannot be defined by SFAs.
63
</page>
<figure confidence="0.967174666666667">
Computational Linguistics Volume 20, Number 1
grammatically by placing the diagram for A alongside the diagram for B. The union
(12+3)+ U (45+6)± is drawn as:
A: &gt;-
ALJB:
\®
</figure>
<bodyText confidence="0.991756666666667">
The intersection of two SFAs A and B, written A n B, accepts a string s iff both A
and B accept s. Consider the intersection of the automata that recognize the languages
(12+3)+ and (1+23+)+. These two automata are:
</bodyText>
<equation confidence="0.934753">
B: ›- 1 &apos;2
\ \ i
S So
</equation>
<bodyText confidence="0.999676">
Two states are compatible if and only if their label sets have a nonempty intersection.
The intersection of these automata is formed by taking all pairs of states that are
compatible and linking these with arcs whenever both projections of the pairs are
linked. The intersection of the above automata is shown below.
</bodyText>
<equation confidence="0.8747725">
AI-1B: &gt; 1 --›- 2
\ 3
</equation>
<bodyText confidence="0.998188375">
This automaton recognizes the language (123)+. _
The complement of an automaton A, written A, accepts a string s iff A rejects s.
One way of forming the complement involves the following steps. First, the automaton
must be DETERMINIZED (Hoperoft and Ullman 1979, pp. 22ff). The next step is to form
the COMPLETION. A complete automaton is one that has a transition from every state
for each element of E. The final step is to mark all final states nonfinal, and all nonfinal
states final. So if S is the set of states and F is the set of final states, then S\F is the set
of final states in the complement.
</bodyText>
<subsectionHeader confidence="0.98949">
3.4 Transducers
</subsectionHeader>
<bodyText confidence="0.9864175">
In the previous three sections, we defined state-labeled automata and some operations
that can be used to combine them. We also saw that these automata are equivalent
</bodyText>
<page confidence="0.992779">
64
</page>
<bodyText confidence="0.992382476190476">
Steven Bird and T. Mark Ellison One-Level Phonology
to traditional, arc-labeled automata. Just as we can define arc-labeled automata called
finite-state transducers (FSTs), we can define state-labeled transducers (SFTs).
An (epsilon free) state-labeled transducer is just an SFA with a special alphabet.
Instead of labeling each state with a subset of a single alphabet, we label them with
subsets of the product of two alphabets. The strings accepted are sequences of pairs
consisting of one letter from each alphabet. A transducer can be used as a translator:
it takes as input one half of the label on a state, and simultaneously writes as output
the other half. All output strings generated by a path from initial to final states are
translations of the input string recognized by the same path. Since the SFT is also an
SFA, intersection is defined for SFTs.
The reader may wonder whether there is any distinction between one-level phonol-
ogy and two-level phonology if SFAs and SFTs are formally identical. There is an im-
portant distinction to be drawn, however. First, most two-level models employ FSTs
with epsilons, which are more powerful devices than FSAs. Second, in the one-level
model, representations and rules are interpreted as automata. In contrast, the two-
level model employs strings for representations and automata for rules. Finally, in
one-level phonology surface forms and generalizations about them are stated directly
in a hierarchical lexicon akin to that of head-driven phrase structure grammar (HPSG)
(Pollard and Sag 1987), rather than being mediated through a transducer (Bird and
Klein, in press).
</bodyText>
<subsectionHeader confidence="0.57905">
4. Association and Synchronization
</subsectionHeader>
<bodyText confidence="0.9959795">
In this section we present the automaton-based semantics for autosegmental phonol-
ogy.
</bodyText>
<subsectionHeader confidence="0.999244">
4.1 The Representation of Autosegments and Tiers
</subsectionHeader>
<bodyText confidence="0.9558345625">
Recall that an autosegment denotes a possibly extended interval. In terms of automata,
this means that an autosegment must allow multiple copies of its defining property.
This is expressed as follows.
cpu
This state of affairs fits well with our intuitive understanding that a pair of adjacent
intervals in which some property holds is indistinguishable from a single interval—the
union of the first two intervals—during which that same property holds. Furthermore,
such a claim connects with the Obligatory Contour Principle (7).8
Unfortunately, however, this definition of autosegment is inadequate. Suppose we
have a nasal segment N that is lexically unspecified for its place of articulation. In a
language with the nasals m and n, the intention is that this segment denotes intervals
such as the following:
However, there is nothing to stop N from denoting the following interval:
8 A consequence of this approach is that it circumvents some potential problems caused by our not
employing epsilons (cf. Section 3.1). If an autosegment alternates with zero, we do not employ c for the
zero alternant but permit surrounding autosegments to extend to &apos;fill in the gap.&apos;
</bodyText>
<page confidence="0.996751">
65
</page>
<note confidence="0.526389">
Computational Linguistics Volume 20, Number 1
</note>
<bodyText confidence="0.809334333333333">
Here, it is clear that N is behaving like a variable. If N is instantiated, then the
entire interval must remain homogeneous. So the representation of this N is not (9a)
but (9b).
</bodyText>
<listItem confidence="0.9589105">
9. (a)
(b)
</listItem>
<bodyText confidence="0.999638714285714">
Some autosegments, however, appear to lack this homogeneity property. For ex-
ample, the Turkish word peceleri contains several front vowels. An analysis of such
words that employs the principles of vowel harmony posits a +front autosegment that
is associated with every vowel of the word. Observe that this autosegment is heteroge-
neous, as it includes in its temporal extent both e and i. Accordingly, its interpretation
will follow the scheme of (9a) above. Briefly continuing in this vein, we can conceive
of a range of different kinds of segment, using varying numbers of states and varying
numbers of labels per state. Four options are described below:
Simple Segments. These capture the ordinary kind of segment and consist of a
single state labeled with a singleton set. In general, when we employ a
symbol like b it will be interpreted as a simple segment.
Homogeneous Segments. These represent slots (like N) and members of tem-
plates (like CVCCVC), and consist of more than one state. Each state is
labeled with a singleton set. An example of a homogeneous segment is
found in (9b).
Heterogeneous Segments. These represent spreading autosegments, like +high
(and b in Section 5.4). The automata have a single state which is labeled
with a nonsingleton set. An example of a heterogeneous segment is found
in (9a).
Hybrid Segments. These represent spreading autosegments that have greek letter
variables, like aplace or ahigh. An example of a hybrid segment for afront
is given in example (10).
Recall that an autosegmental tier is just a linear ordering of autosegments. There-
fore, if P. Q and R are segments (of any of the four kinds specified above), then a tier
P-Q-R is formed by simply concatenating P. Q, and R together.
Now we have seen the interpretation of autosegments and tiers. The synchronization
of tiers is controlled by association lines. The next section discusses the interpretation
of these lines.
</bodyText>
<page confidence="0.706302">
66
</page>
<bodyText confidence="0.796468">
Steven Bird and T. Mark Ellison One-Level Phonology
</bodyText>
<subsectionHeader confidence="0.992062">
4.2 The Interpretation of Association
</subsectionHeader>
<bodyText confidence="0.952254285714286">
In Section 2 we presented an interpretation of association based on temporal overlap.
Now we must find a way of simulating this temporal structure using automata. Let
us begin by considering the simplest possible autosegmental diagram.
11.
Since each autosegment denotes an interval and the two intervals must overlap, we
would like to interpret the above diagram as describing any of the following strings,
among others:9
</bodyText>
<figure confidence="0.9601782">
A A A • •
• • B BB
A A A A A
• • B B s
• • A
</figure>
<figureCaption confidence="0.476677">
What kind of automaton will give us the required behavior? The clue is that a pair
of intervals overlap if and only if they share a point in common (Bird and Klein 1990,
p. 36). Note that in each of the above diagrams, the third interval contains an instance
of both A and B, and the existence of this interval was both a necessary and sufficient
</figureCaption>
<bodyText confidence="0.990313166666667">
requirement for the association line to have its overlap interpretation. So we need an
automaton for each autosegment that captures the two required properties: (i) deno-
tation of an extended period, and (ii) existence of a special point. The &amp;quot;automaton&amp;quot;
required for the autosegment A is given in (12).
12.
This automaton accepts any string of one or more As, and requires that there is some
A that is coincident with an autosegment somewhere else. The line extending from
the middle state informally indicates that this state is simultaneous with a state in
another automaton. Now we must create a similar automaton for the autosegment B.
Recall from Section 4.1 that we need to construct tiers for A and B by concatenating
the autosegments to the left and right (elided in (11)). Finally, the automata are put
together as shown below:
</bodyText>
<equation confidence="0.475144">
-).-C)j + • • •
</equation>
<listItem confidence="0.7852235">
9 Note that in using such diagrams we are attempting to isolate the effects of two automata: those cells
containing both A and B should be understood as containing A n B.
</listItem>
<page confidence="0.99472">
67
</page>
<note confidence="0.558847">
Computational Linguistics Volume 20, Number 1
</note>
<bodyText confidence="0.995888428571429">
This unusual kind of automaton represents a halfway house between autosegmental
diagrams and SFAs; we shall call it a SYNCHRONIZED SFA. Such automata have a
simple interpretation: both component automata run in parallel, but the second state
of the A automaton is active iff the second state of the B automaton is simultaneously
active. In a sense, we have converted an autosegmental model involving intervals
and overlap into a simpler model involving atomic periods and simultaneity. Now
consider autosegmental diagram (13).
</bodyText>
<listItem confidence="0.505688">
13. A B
</listItem>
<equation confidence="0.8901965">
\ /
C
</equation>
<bodyText confidence="0.9687551">
Note that there is no additional material on either side of the group of three autoseg-
ments (cf. (11)). Therefore, we assume that both tiers are descriptions of a complete
utterance and so must begin and end simultaneously.&apos; In this diagram, C has two
associations. The automaton we need for C is more complex than before, since the
interval that C denotes must have two special points, one for overlap with A and the
other for overlap with B. The required automaton for C is given in (14).
&gt;- C r C
- c k i
Automaton (14) is the concatenation of two copies of an automaton like (12). Putting
the automata for A, B, and C together gives the synchronized automaton in (15).
</bodyText>
<figure confidence="0.9454632">
15.
k k RD
A B
) 91--9)
r
&gt;
A
&gt;-
C----)- ‘[--)
K
</figure>
<bodyText confidence="0.9862505">
The behavior of synchronized SFAs can be simulated by an ordinary SFA, as we show
in the next section.
</bodyText>
<subsectionHeader confidence="0.99999">
4.3 Simulating Synchronized Automata
</subsectionHeader>
<bodyText confidence="0.6810744">
To do this simulation, we need to do away with the synchronization lines connecting
the automata. Starting with (15), we add indices to each state: a 0 to unsynchronized
10 It is a trivial matter to do away with this restriction, since we can always add a completely unspecified
autosegment to the start and end of each tier, thereby permitting slippage between the substantive
material on each tier.
</bodyText>
<page confidence="0.989">
68
</page>
<figure confidence="0.4384215">
One-Level Phonology
Steven Bird and T. Mark Ellison
states and a 1 to synchronized states, and then erase the lines.
&gt;(A, 0) -N )&gt; (A, 1) (A, 0) (B, 0) &gt;
&amp;quot;(c,o) &gt;-(c,1) (c,o)
J
</figure>
<bodyText confidence="0.9070935">
Observe that each of these state labels is actually a pair. These automata are defined
over the product alphabet E x {0, 1}. The intersection of these automata is as follows:
</bodyText>
<equation confidence="0.854219">
AnC,o) (AnC,1)---&gt; (AnC,o) &gt; (BnC,O)
</equation>
<bodyText confidence="0.999949636363636">
The function of the indices was to rule out certain states in the intersection. Now that
the indices have served their purpose, we can erase them and further simplify the
automaton:
This, then, is the semantics assigned to (13). Since we no longer require the graphical
notation for synchronization, it will be convenient to represent SFAs using the notation
of regular expressions over ordered pairs. In order to do this it is useful to employ
some macros. An autosegment A is represented as s(A) =clef (A, •)±. Bullet (*) is used
here as a context-dependent wildcard, indicating an alphabet. (In this definition of
s(A), the bullet indicates the alphabet {0,1}; in the definition of a (n) below it indicates
the alphabet E.) The n association lines incident to an autosegment are expressed as
follows:
</bodyText>
<equation confidence="0.89999">
a(n) =def (I&apos;,13)* ((.,1) (e, 0)*)n
</equation>
<bodyText confidence="0.8652414">
Observe that a(m+n) = a(m)+a(n). Finally, we combine these two macros into a third
macro thus:
A: n -=def s(A) El a(n)
This states that A is an autosegment with n associations. Now we shall illustrate the
workings of these definitions. Consider diagram (13) again, reproduced below:
</bodyText>
<page confidence="0.981348">
69
</page>
<figure confidence="0.916793">
Computational Linguistics Volume 20, Number 1
13. A B
\ /
</figure>
<bodyText confidence="0.561705">
A singly associated autosegment, such as A, is written down as the following formula:
</bodyText>
<equation confidence="0.977253666666667">
A:1 s(A) a(1)
= (A, •)± n (*, 0)* (0,1) (0, 0)*
= (A,0)* (A,1) (A,0)*
</equation>
<bodyText confidence="0.954667636363636">
We can now simply write down a formula for (13):11 (A:1+B : 1) n C:2. This expression
evaluates to the following:
(A n c, o)* (A n c, 1) (A n c, o)* (B n c, o)* (B n c, 1) (B n c, 0)*
Now that the indices have served their purpose, we would like to ignore them by pro-
jecting the ordered pairs onto their first element. The result of evaluating this projection
for our current example is (A n C) (B n C)+, which is the intended interpretation of
diagram (13). We shall adopt the following notational convention: if D is the encoding
of a diagram then [D] is the projection of the encoding that ignores the indices.
As another example, consider an autosegmental diagram consisting of two tiers,
each with two autosegments, and two association lines between the tiers, as shown
in (16).
</bodyText>
<listItem confidence="0.534064">
16. AB
CD
</listItem>
<bodyText confidence="0.998788333333333">
The expression for (16) is (A: 1 B : 1) n (C: 1 D : 1). This evaluates to the follow-
ing expression under the projection: (A n C)+ ((A n D)±U (B n c)± u 0)(B n D)+. The
corresponding automaton for (16) is given in (17).
</bodyText>
<table confidence="0.660006666666667">
Anc AnD
Bnc
)
</table>
<footnote confidence="0.723443666666667">
11 It is important to notice that the numerals in this expression are not the same as the indices that occur
as the second member of pairs like (A, 1). The former represent degree of association, while the latter
function as synchronization marks in an automaton.
</footnote>
<page confidence="0.960381">
70
</page>
<figure confidence="0.6875824">
One-Level Phonology
Steven Bird and T. Mark Ellison
Automaton (17) will accept the following sequences, among others:
A B A B B A A B
C D C C D C D D
</figure>
<bodyText confidence="0.994537">
Note that all of these examples have A overlapping C and B overlapping D. The
second and third examples have an extra cell, for B overlapping C and A overlapping
D, respectively. This range of possibilities is compatible with (16), as it requires an A—C
overlap and a B—D overlap and optionally permits an A—D overlap or a B—C overlap
(but not both).
We have now seen an automaton-based interpretation of an autosegmental chart.
Next we consider how the above regular expressions defined over ordered pairs can
be generalized to representations consisting of more than one chart.
</bodyText>
<subsectionHeader confidence="0.989498">
4.4 Multiple Charts
</subsectionHeader>
<bodyText confidence="0.9978454">
It is straightforward to generalize the interpretation procedure for single charts to one
for representations with an arbitrary number of charts. Recall that for one chart we
needed to employ ordered pairs. In general, for n charts we must employ ordered
n + 1-tuples. The construction will be demonstrated using a diagram attributable to
Pulleyblank (1986, p. 13) involving three tiers and three charts.&apos;
</bodyText>
<table confidence="0.7346896">
(0, 0, •, •)* ((•, 1, •, *) (., 0, •, e)*)n
(0, •, 0, •)* (K., •, 1, •) (e, e, 0, o)*)n
(41, •, •, 0)* ((e, •, •, 1) c.., •, 0)* )n
18. A B C
E F
</table>
<bodyText confidence="0.9819705">
Now, since there are three charts in (18) we must employ 4-tuples. We adopt the
following abbreviatory conventions:
</bodyText>
<equation confidence="0.9796126">
s(a) =def (a,•,•,•)+
au (n) =def
a23(n) =def
a13(n) =def
A:p:q:r =def s(A) n au(p) fl a23(q) 11 a13(r)
</equation>
<bodyText confidence="0.964352">
We can now write down the expression for (18) as follows:
19. (A:1:0:0 B:0:0:1 C:1:0:0) n (E:2:0:0 F:0:1:0) ri D:0:1:1
The first three terms of this expression correspond to tier 1 of (18). The first term of
the expression concerns the autosegment A and its association line on chart 1-2. The
second term concerns B and its line on chart 1-3. Notice that lines AE and BD are in
</bodyText>
<footnote confidence="0.883322">
12 Pulleyblank observes that the temporal interpretation of this diagram is ill-defined if association is
assumed to be transitive. However, since overlap is not a transitive relation we do not have this
problem.
</footnote>
<page confidence="0.992142">
71
</page>
<note confidence="0.740874">
Computational Linguistics Volume 20, Number 1
</note>
<bodyText confidence="0.9261385">
different charts in (18) and so the count of association lines is in a different position in
the 4-tuple for A and B. The third term concerns C and its line in chart 1-2. The fourth
and fifth terms of the expression concern the E-F tier. Since E is doubly associated in
chart 1-2, a 2 is used for E&apos;s degree of association. D also has two associations, but they
are in different charts. Expanding and projecting this expression gives the following:
onDnp+(BnDnE)±(cnDnE)±(cnDnF)±
So the shortest string that satisfies the constraints expressed in diagram (18) is the
following:
</bodyText>
<sectionHeader confidence="0.922535666666667" genericHeader="method">
AB CC
DDDD
EEEF
</sectionHeader>
<bodyText confidence="0.993213125">
Recall that the encoding of the three-tier diagram (18) was given as expression
(19). In such expressions it is difficult to identify tiers. Therefore, in the remainder of
this paper we shall write expressions like (19) in the following format:
20. tier 1 A:1:0:0 B:0:0:1 C:1:0:0
tier 2 E:2:0:0 F:0:1:0
tier 3 D:0:1:1
In general, if D is a diagram, then E(D) is its encoding in the format exemplified
in (20).
</bodyText>
<subsectionHeader confidence="0.998621">
4.5 Evaluating the Encoding
</subsectionHeader>
<bodyText confidence="0.983181882352941">
Now, we evaluate our encoding with respect to Kornai&apos;s desiderata: computability,
compositionality, invertibility, and iconicity (Kornai 1991).
Computability: The number of terms in the encoding is equal to the number of
autosegments, and each term has a fixed size.&apos; Therefore, the encoding
can be computed in linear time.
Compositionality: If D1 and D2 are two autosegmental diagrams then E(DID2) =
E(D1)E(D2), where concatenation of encodings is done in a tier-wise man-
ner. Thus the encoding is compositional.
Invertibility: A representation can be reconstructed from its encoding.
Iconicity: If an autosegment in a diagram is changed, the effect on the encoding
is local, since only one term is altered. However, if an association line
is added or removed, two terms must be altered. Although these terms
may not be adjacent, we believe the encoding is more iconic than Kornai&apos;s
triple code (see Section 5.2), in which changes can affect an unbounded
amount of material.
In addition to these properties, our encoding can be used directly as a finite-state
recognizer of surface forms, simply by forming the intersection of the n tier encodings
</bodyText>
<footnote confidence="0.6682695">
13 Observe that when we expand these macros the resulting expression has s + 2a terms, where s is the
number of autosegments and a is the number of associations.
</footnote>
<page confidence="0.981687">
72
</page>
<bodyText confidence="0.932913666666667">
Steven Bird and T. Mark Ellison One-Level Phonology
and projecting the first elements of the tuples. Note that if we revert to the encoding in
(19), where the tier encodings are combined into a linear expression using intersection,
then compositionality is lost. Thus, the encoding is either linear or compositional, but
not both. Unfortunately, this is the best that we can hope for; Wiebe (1992) has shown
that a compositional linear encoding does not exist.
</bodyText>
<subsectionHeader confidence="0.998889">
4.6 Phonological Rules
</subsectionHeader>
<bodyText confidence="0.99984675">
Phonologists typically encode their descriptive generalizations in terms of RULES.
Often these rules are interpreted as processes that manipulate representations. In the
one-level approach they are interpreted as a logical implication between two descrip-
tions, which simplifies to a single description given the Boolean operations presented
in Section 3.3.
As our first example, consider the phenomenon of homorganic nasal assimilation,
whereby nasals agree in place of articulation with the following consonant. An SPE-
style rule for this is given in (21a), the corresponding logical implication in (21b).
</bodyText>
<listItem confidence="0.756487">
21. (a) [+nasal] keplacel / [+cons,aplaceJ
(b) f+nasalli+cons] [aplacellaplace]
</listItem>
<bodyText confidence="0.993425666666667">
Thus, the sequences mb and nd are allowed, while md and nb are ruled out. Let
N = {m,n}, S = {b,d}, L = {m,b}, and A = {11,4 The required constraint can be
expressed as NS -4 LL U AA. However, in order to make this rule apply to a whole
string (rather than just the first NS sequence it comes across), we must express it in
the following format!&apos;
22. --,(4•*(NS fl LL LJ AA)**)
This states that it is not possible to find anywhere a nasal-stop cluster (NS) that is
not made up of two labials (LL) or two alveolars (AA). We can simplify the above
expression to .-(mA).* n **(nL).*.
Now consider a general rule of the form SD -4 SC. Since SD and SC pertain to
parts of a string rather than a whole string, we have to ensure that the rule applies to
all substrings of an &apos;input&apos; string S. We do this as follows:
</bodyText>
<listItem confidence="0.97930625">
23. Vs C S, SD(s) —&gt; SC(s)
Vs c S, --,SD(s) V SC(s)
c S, SD(s) A --SC(s)
--,(**(SD SC).*)
</listItem>
<bodyText confidence="0.9891096">
This is how we arrived at (22) from (21b).
Autosegmental rules can also be expressed in this framework. Consider again the
case of assimilation. The following diagram is the autosegmental rule corresponding
to the SPE rule in (21). Here, aplace is a hybrid autosegment (see Section 4.1) ranging
over places of articulation.
</bodyText>
<footnote confidence="0.935809">
14 Note that we employ a &apos;—,&apos; sign or an overline to represent complement, depending upon which is
most convenient.
</footnote>
<page confidence="0.992527">
73
</page>
<figure confidence="0.87119275">
Computational Linguistics Volume 20, Number 1
24. NC
\ 1\
aplace
</figure>
<bodyText confidence="0.823747909090909">
This rule states that wherever an NC sequence can be found, if the C is associated
with an L, then the N is also associated with L. We can express this rule in the more
familiar rewrite notation:
N C --4 N C
\ 1
aplace aplace
We can give an automaton-based semantics to this rule. In order to do this, we must
employ two independent charts between the two tiers, one for the structural description
and one for the structural change. We can represent this as follows, where &apos;sd&apos; refers to
lines in the structural description chart, and &apos;sc&apos; refers to lines in the structural change
chart.
</bodyText>
<equation confidence="0.667782">
N C
</equation>
<bodyText confidence="0.8084505">
sX Isd
&amp;place
Now we can write down the formulas for the structural description and the structural
change independently and combine them into the rule format of (23).
</bodyText>
<equation confidence="0.918833">
[ .:0* N:0 C:1 •:0* 1:0:0* N:0:1 C:1:0 1:0:0*
I ]
25. -, ( .* n --i e*)
.:0* aplace: 1 1:0* [ .:0:0* aplace:1:1 .:0:0* sc sd
</equation>
<bodyText confidence="0.9999875">
In (25) the &apos;sd&apos; and &apos;sc&apos; subscripts on the brackets refer to projection functions that
ignore the structural description and structural change charts, respectively. So, in eval-
uating (25) we intersect the two tiers of the structural change part of the rule, and then
delete the second index of each tuple. The complement of this automaton is then inter-
sected with the structural description part of the rule and the first index of each tuple
is then deleted. The final step is to add the .* wildcards and form the complement
again. The result is an automaton that rejects any nonhomorganic NC clusters.
A more complex example of a phonological rule, this time concerning vowel har-
mony, will now be discussed. Since the advent of autosegmental phonology, vowel
harmony has been analyzed as the spreading of autosegments from left to right. Here
we show how such a rule can be translated into a regular constraint on surface forms.
Turkish exhibits two orthogonal types of vowel harmony: one requiring that con-
secutive vowels agree in fronting, the other requiring that consecutive vowels agree
in rounding unless the second vowel is low. As the rounding harmony is the more
complex of the two, we will take it as our example. To avoid the complications of
fronting harmony, we will only consider examples involving back vowels.
</bodyText>
<page confidence="0.959651">
74
</page>
<bodyText confidence="0.9771252">
Steven Bird and T. Mark Ellison One-Level Phonology
Turkish has eight vowels. Four of them (a e 1 i) are unrounded, and four (o ö u
ii) are rounded. Turkish is an agglutinating language, and the vowels in many affixes
depend on the final vowel in the root of the word. Compare, for instance, three of the
cases of the words son end and adam man displayed in (26).
26. case son adam
nominative son adam
accusative&apos; sonu adami
dative sona adama
When the rounded root vowel is followed by a high vowel in a suffix, this vowel must
agree with the root in rounding. Low vowels in harmonising suffixes are, however,
always unrounded.
The notation of autosegmental phonology makes it easy to state this generalization
as a rule. The rule spreads a rounding autosegment onto the next vowel if (and only
if) the next vowel is high.
</bodyText>
<equation confidence="0.84019">
27. +rnd
V V
[ + hi]
</equation>
<bodyText confidence="0.999934545454546">
This rule only applies on the vowel tier, skipping over consonants, and the in-
terpretation given to autosegments on this tier must reflect this. We use the idea of
heterogeneous autosegments (see Section 4.1) to differentiate ordinary segments from
autosegments on restricted tiers such as the vowel tier. A vowel on this tier may denote
not only a vowel but also consonants interspersed within this vowel as well. Whereas
a segmental a corresponds to an automaton with a single state having a singleton label
(this is what we have called a SIMPLE segment; see Section 4.1), an a on the vowel
tier corresponds to a single state automaton whose state accepts not only a but any
consonant as well (a HETEROGENEOUS segment).
Given that the vowel tier uses this kind of heterogeneous representation, we can
combine the charts of our rule into the regular expression in (28).
</bodyText>
<equation confidence="0.9936835">
•:0* + rnd: 1 •:0* 41:0:0* + rnd:1:1 .:0:0*
28. -&apos;(9
i **
sd).:0* V:0 + hi:1 .:0* .:0:0* V:0:1 + hi:1:0 .:0:0* sc
</equation>
<bodyText confidence="0.808902">
Using the procedure of Section 4.6, we can translate this into a regular expression that
</bodyText>
<page confidence="0.850298">
15 More precisely, the accusative case is used only for definite objects.
75
</page>
<note confidence="0.749762">
Computational Linguistics Volume 20, Number 1
</note>
<bodyText confidence="0.999725814814815">
implements rounding harmony as a constraint on surface forms. After simplification,
this automaton is:
Each of the states accepts the specified class of vowels and any consonant. Informally,
this automaton will accept any sequence of vowels except those in which a round
vowel is followed by an unrounded high vowel. This is precisely the intended effect
of the autosegmental version of the harmony rule (27). This concludes our discussion
of vowel harmony.
A comment is in order here about why two charts were required for the encoding
of autosegmental rules. After all, our use of an input and an output chart appears to be
a procedural device, and we have eschewed these from the outset. However, note that
it is not possible for our structural description and structural change to be encoded
on the same chart: the structural change has an association line not present in the
structural description, and so they are incompatible. Of course, the overlaps described
by the structural description and structural change are mutually compatible; it is only
the associations that are not. Once the structural change has been computed, we can
throw away the &apos;Sc&apos; chart, and once the structural description and structural change
have been combined, we can also throw away the &apos;sd&apos; chart. In this way, the rule
functions only as a filter on surface forms, and there is no way for two separate rules
to communicate via these rule-internal charts.
This approach permits us to interpret any nondestructive autosegmental rule.&apos;
Those rules involving deletion of autosegments or association lines must be approached
in a completely different way. Rather than deleting an element in a particular context,
we set up an alternation with zero, following Bloomfield (1926). See Bird and Klein
(in press) and Bird (in press) for detailed examples of this approach to deletion.
This concludes our discussion of the automaton-based semantics for autosegmen-
tal representations and rules. In the next section we review some other attempts to
treat autosegmental phonology using finite-state techniques.
</bodyText>
<sectionHeader confidence="0.920997" genericHeader="method">
5. Other Finite-State Approaches to Nonlinear Phonology
</sectionHeader>
<subsectionHeader confidence="0.991833">
5.1 Kay (1987)
</subsectionHeader>
<bodyText confidence="0.976931833333333">
The earliest treatment of autosegmental phonology in a finite-state setting is attributable
to Kay (1987). It is tailored to the framework of nonconcatenative morphology de-
veloped by McCarthy (1981) in which consonants and vowels are segregated onto
different tiers, as shown for the Arabic verb stem kattab in (29).
16 Applied to a destructive autosegmental rule, the interpretation determines the restriction imposed on
surface forms by the rule, were it the last rule in a derivation.
</bodyText>
<page confidence="0.874052">
76
</page>
<figure confidence="0.790334">
Steven Bird and T. Mark Ellison One-Level Phonology
29. a perfective active
CVCCVC causative
write
</figure>
<bodyText confidence="0.998902714285714">
This verb stem contains three morphemes. Together, they mean &apos;caused to write.&apos; The
challenge posed by Arabic morphology is to come up with a simple account of the
interleaving of the morphemes, relating the forms a, CVCCVC, and ktb to the stem
kattab.
Kay&apos;s solution, which we sketch here, involves the use of a kind of transducer
that reads four-tuples (rather than pairs like a normal FST). This transducer scans
four strings, one for each of the three tiers in (29) and one for the corresponding
surface form. In this way, Kay has identified tiers with tapes. The association relation
is encoded in the way the transducer scans these four tapes.
Kay specifies a transducer by providing a set of FRAMES. In effect, each frame
specifies an association between a CV-tier slot and a melodic unit, such as a k or an
a. This melodic unit appears on the current surface tape cell. Each frame is a four-
tuple whose components correspond to (i) the consonantal root, (ii) the CV-tier, (iii)
the vocalic melody, and (iv) the surface tape. A simple frame is the following:
</bodyText>
<equation confidence="0.961088">
k : C:c: k
</equation>
<bodyText confidence="0.999964764705882">
This frame specifies that when a k is being read from the consonantal tape and a C is
being read from the CV tape, then there is an empty transition on the vocalism tape
and the surface tape must have a k. There is a similar frame for each consonant. A
frame for the vowel a is e:V:a:a.
More work is necessary in order to capture the idea of autosegmental spreading.
Kay modifies the transducer model so that tape symbols can be inspected without
the reading head being advanced. Three notational devices manipulate the way this
revised model behaves. Square brackets around one of the components of a frame
causes the corresponding tape cell to be scanned without advancing the read head.
Braces around a frame component behave in the same way, but only if they are scan-
ning the final symbol on a tape. (This is required to prevent the spreading of i, which
will not be discussed here.) Finally, the symbol G is used instead of C for geminate
consonants. We shall see how these devices operate using a worked example, in which
the surface form kattab is derived from the three lexical forms of diagram (29).
Display (30) gives the initial configuration. The box shows the collection of symbols
currently being scanned on the four tapes. To the far right is the appropriate frame,
An empty pair of brackets is equivalent to E.
</bodyText>
<equation confidence="0.986061">
t b k
V G C V C C
[I
</equation>
<page confidence="0.994262">
77
</page>
<note confidence="0.749538">
Computational Linguistics Volume 20, Number 1
</note>
<bodyText confidence="0.999542">
The first CV tape symbol is a C and so the current consonant k is written onto the
surface tape and the read heads are advanced. Notice that the read head for the vowel
tape is left on the first cell. This is because the frame specified that there be no transition
on this tape.
</bodyText>
<figure confidence="0.942454">
k 1Th b V C V
C t GC { a }
V a
a
</figure>
<bodyText confidence="0.649943">
In (31), the CV tape symbol is a V, and so the a is copied to the surface tape. Since
this a is given in braces in the frame, there is no movement of the read head.
</bodyText>
<equation confidence="0.888703">
[ti
C V C
[1
</equation>
<bodyText confidence="0.9999186">
Having reached configuration (32), we read a G, which indicates a geminate. The t
is written to the surface tape and the read head for the consonant tape stays where
it is. The brackets around t in the frame mean that there is a nondeterministic choice
between moving the read head and leaving it in the same position. However, the G
symbol requires that the head stays put. Next we get a C on the CV tape.
</bodyText>
<equation confidence="0.951465">
Itl
V C
[1
</equation>
<bodyText confidence="0.8422224">
After (33), the consonant tape read head advances17 and the CV tape head moves on
to deal with another vowel (34).
17 Note that there is nondeterminism hidden here again. As it happens, if the consonant tape does not
advance then the b will never be used (i.e., we will get *kattat) and the transducer will fail, because of
the requirement that all read heads be at the end of their input for a successful completion.
</bodyText>
<figure confidence="0.976244933333334">
V
a
V
a
78
Steven Bird and T. Mark Ellison k t 1&amp;quot;----\ One-Level Phonology
b ii
C V GC V C V
34. a {a}
k a t t a a
Finally, the consonant b is transferred to the surface tape.
k t ( b [b]
C V GC V C C
35. a []
k a t t a b b
</figure>
<bodyText confidence="0.999900967741936">
The result on the surface tape is kattab as required. Of course, the transducer also
works for recognition. We could specify a surface tape and leave one or more of the
lexical tapes unspecified.
Kay&apos;s system is ingenious and we have not been able to demonstrate all of its
capabilities in this small space. Nevertheless, we believe it suffers from a number of
problems. The first concerns the form katab (form I) and the (corresponding) reflexive
form ktatab (form VIII) with an infixed t. Indeed, more than half of the forms that
Kay cites have infixes, although these are not explicitly analyzed in the model. Two
conservative extensions to the model that encompass this infixation are (i) to insert
infixes into the CV tape directly (so form VIII is CtVCVC) or (ii) to introduce another
CV tape symbol A (for affix), which directs the transducer to read from a fifth tape.
A second set of problems concerns the appropriateness of Kay&apos;s model for non-
linear phonology more generally. First, notational devices like G move the frame &apos;lan-
guage&apos; away from what it is supposed to represent, namely autosegmental structures.
No longer is gemination represented by association (perhaps derived by a spread-
ing rule), but by a special marking on the skeleton. Second, the model builds in the
assumption that each morpheme appears on a separate autosegmental tier. However,
most applications of autosegmental phonology employ morphemes with phonological
information arrayed on more than one tier (e.g., Clements and Ford 1979). Similarly,
the modeling of subsegmental feature geometry of the kind advocated by Clements
(1985) and others also involves a single morpheme having material on several tiers.
Third, the model breaks down in the area of MORPHEMIC SEGREGATION. Since there
is no principled upper bound on the number of morphemes that may be overlaid
in the way McCarthy advocates for Arabic, there is similarly no principled upper
bound on the number of tapes Kay&apos;s transducer would require. The assumption that
each morpheme defines its own set of tiers, implicit in early work (McCarthy 1981)
but explicit in more recent work (McCarthy 1989), is incompatible with a fixed upper
bound on the number of tapes. Finally, using Kay&apos;s model for recognition would lead
to much nondeterminism in positing G symbols, brackets, and braces. For example,
in processing kattab the lexical tapes kttb, CVCCVC, and aa could be generated. The
model generates all possible violations of the Obligatory Contour Principle.
</bodyText>
<page confidence="0.996295">
79
</page>
<note confidence="0.718047">
Computational Linguistics Volume 20, Number 1
</note>
<subsectionHeader confidence="0.987862">
5.2 Kornai (1991)
</subsectionHeader>
<bodyText confidence="0.988279027777778">
Kornai (1991) has developed a linear encoding of autosegmental representations that
allows the two-level transducer model to be applied to autosegmental phonology
We shall present Kornai&apos;s central innovation and describe a few of its strengths and
weaknesses.
As we saw in Section 4.5, Kornai presents four criteria under which an autoseg-
mental encoding should be judged. An encoding should be easily computable; ideally
by finite automata. It should also be invertible. An encoding should be iconic; minimally
changing the input should minimally change the output. Finally, it should be compo-
sitional, in the sense that the concatenation of the encodings of A1 and A2 ought to be
the same as the encoding of the concatenation of A1 and A2. Kornai demonstrates that
an optimal encoding under these criteria does not exist, and he sets about defining an
encoding that is claimed to be near-optimal.
We shall only cover one of the codes he considers, namely, the TRIPLE CODE.
This code represents two tiers of autosegments and a chart between them as a linear
description. There are four keywords in the code that are interpreted as instructions to
a device that is scanning two tiers (left to right) and drawing association lines between
certain pairs of segments. These keywords are as follows:
0 : leave the current segments unassociated and advance the read head on each
tier;
1 : draw an association line between the current segments on each tier and ad-
vance the read heads on each tier;
t : override the advance instruction on the bottom tier, i.e., only advance the read
head on the top tier; and
b : only advance the read head on the bottom tier; retain the same segment on
the top tier.
Each 0 or 1 is flanked by a statement of the current segments on the two tiers. A
number flanked by two segments forms the TRIPLE that gives the code its name.
Where this code could give a number of different representations of the same
autosegmental structure, Kornai (1991) restricts the encoding to operating in the same
manner as the association convention of Goldsmith (1976). Association, or the lack
of association, is marked left-to-right in a one-to-one fashion until one tier is devoid
of new autosegments. From that point, only one tier advances until all remaining
autosegments are represented in the linearization.
As examples, let us encode two charts, the first completely devoid of associations.
To show the pairs of current autosegments through the steps of the encoding, we link
them with dotted lines indexed by the count of the step in the derivation.
</bodyText>
<figure confidence="0.516893666666667">
ABCD
1 2 3 4
a b cde f
</figure>
<footnote confidence="0.275175">
The first four code steps give the following encoding (separating triples with full
stops):
A0a.B0b.00c.D0d
</footnote>
<page confidence="0.984166">
80
</page>
<bodyText confidence="0.921772176470588">
Steven Bird and T. Mark Ellison One-Level Phonology
For the remaining two steps, we must spread (in virtual associations, not real ones) the
final segment of the top tier, remembering to record the fact that only the read head
on the bottom tier advances. The total encoding of this chart is thus the following:
A0a.B0b.00c.D0d.b.D0e.b.D0f
As a second example, let us fill the same chart with some associations.
A BCD
a b cde f
The encoding for this chart is the following:
A1a.t.Bla.C1b.b.C1c.D1d.b.D1e.b.D0f
This code can be measured against the four criteria given above. The code is definitely
computable; we have just given an algorithm for constructing the code for an arbitrary
chart. Likewise the code is invertible: given any code, it is clearly possible to reproduce
the original chart. Similarly, given the chart decoded from any encoding, it is likewise
possible to reproduce the encoding.
The triple code is, however, neither iconic nor compositional. Consider the two
autosegmental representations given below.
</bodyText>
<equation confidence="0.377405">
ABC ABC
\
a b c a b c
</equation>
<bodyText confidence="0.9578765">
The triple code for the first representation is A0a . BOb. C0c. For the second representa-
tion, the triple code is the sequence:
A0a.b.A0b.b.A1c.t.B0c.t.00c
As we can see, a minor change in one part of the autosegmental representation has
resulted in major changes in much of the triple-coded representation. Thus the code
is not iconic.
Similarly, if we concatenate the two representations shown below
A BCD
</bodyText>
<footnote confidence="0.466628666666667">
we get a b c d
ABCD
a b cd
</footnote>
<page confidence="0.980706">
81
</page>
<note confidence="0.807621">
Computational Linguistics Volume 20, Number 1
</note>
<bodyText confidence="0.955947310344828">
If we concatenate the two encodings, we get A0a.b.A0b.b.A0c.B0d.t.00d.t.D0d, which is
not the same as the encoding of the concatenation: Ala.B1b.C1c.D1d. So the triple code
satisfies only two of the desiderata Kornai gives for linearizations of autosegmental
representations. As mentioned above, Wiebe (1992) has proven that linear encodings
cannot get much better than this: no linear encoding can be both invertible and com-
positional.
Under the triple code, a lot of phonological processes are not finite-state. For
example, consider the process of putting morphemic tiers together. In the case of the
Arabic example we saw in (29), we need to combine the root morpheme (with empty
template and vocalic tier) ktb and the template (with empty vocalic and consonantal
tiers) CVCCVC together in such a way that we end up with the encoding in (38).
In autosegmental representations, this is achieved by concatenation, and the &amp;quot;before&amp;quot;
and &amp;quot;after&amp;quot; diagrams appear in (36) and (37).
36. C V C C VC
ktb
Concatenation of codes does not bring the same result. Display (38) shows the two
concatenands, written with 0 as place holder for the empty tier.&apos;
38. C0O.V00.000.000.V00.000 + 00k.00t.00b
COk.V0t.00b.t.00b.t.V0b.t.00b
To obtain the correct result, we need a more complex operation than concatenation—
one that cannot be performed by any finite-state device.
If the ktb is read before the CVCCVC is read, it is necessary to have sufficient state
information to be able to store k, t, and b, which in an alphabet of about 28 consonants
involves at least log2(283) 15 extra bits of information in each state, compared to
an otherwise equivalent transducer. Suppose now that we wish to apply the well-
formedness condition (5), the association convention (6), and some other rules to (38)
to achieve the pattern of association between the two tiers given in (29), repeated
below. We are not interested here in the detail of how a transducer might perform this
operation, only whether a transducer can perform it.
</bodyText>
<listItem confidence="0.546265">
39. C V CC V C
</listItem>
<footnote confidence="0.941246">
18 As far as we have been able to find, Kornai (1991) does not discuss how to code a representation that
contains an empty tier. Here, we have filled empty tiers with a &apos;place holder&apos; segment, and then used
the triple code.
</footnote>
<page confidence="0.996527">
82
</page>
<bodyText confidence="0.98394216">
Steven Bird and T. Mark Ellison One-Level Phonology
The encoding of (39) is C1k.V0t.t.C1t.t.C1t.V0b.t.C1b. Observe that the t is met in the
second triple of the right-hand side of (38) and it must be &apos;stored&apos; until the fourth
triple in the output. In a form like tadaktraj, two consonants must be stored in this
way, leading again to an explosion of state information.&apos; If the template consisted
of n CV syllables, and the consonant tier consisted of n consonants, then the asso-
ciation mechanism would need to store at least [(n - 1)/2j autosegments. This is,
in principle, unbounded, and so the association mechanism for coded autosegmental
representations is not finite state.
In general there is no limit on the amount of information that needs to be pre-
served as state information in the transducer. Consequently, using the triple code,
certain phonological processes cannot be modeled using a finite state transducer. In-
deed, this is true of any linear code (Wiebe 1992). It is true that adding each individual
association—that is, finding the next position to associate, making the association and
shuffling the lower tier along—can be performed by a finite-state transducer. But no
principled bound on the length of the derivation can be made, and the quantity of
memory required is an increasing function of the length of the derivation. Conse-
quently, the step from unassociated to associated form cannot be made by a single
FST.
This type of problem with manipulating coded representations is not limited to
Arabic morphology. In fact, the problem arises whenever there is an autosegment that
has a restricted set of &apos;landing sites&apos; (such as the consonants or the high vowels), a very
common occurrence. Another example is that of accent systems: Kornai and Kalman
(1988, p. 185), citing Goldsmith (1982), state the Basic Tone Melody Association rule
for Ci-Ruri, a Bantu language of Tanzania, as follows:
</bodyText>
<subsectionHeader confidence="0.955716">
40. Basic Tone Melody Association Rule:
</subsectionHeader>
<bodyText confidence="0.99800375">
Associate the accented element of the Basic Tone Melody to the accented
element of a word.
In general, the accented element of a word may be an unbounded distance from the
start and end of a word. Goldsmith (1982, p. 53) gives the following example:
</bodyText>
<listItem confidence="0.6331965">
41. na a kam ir* e I milked
L H* L
</listItem>
<bodyText confidence="0.999788833333333">
As before, performing the association using the triple code requires a multiplication
in state information, which in the general case cannot be bounded. True, this example
only requires the automaton to store H; but Goldsmith (1982, p. 55) gives examples
where there are two stresses in the word, and, therefore, the association automaton
needs to store more tones (see Wiebe 1992, pp. 109-110 for the details).
Next, consider the problem of generalizing from one chart to an arbitrary number
</bodyText>
<footnote confidence="0.6447515">
19 Wiebe (1992, p. 112) points out that the final consonant does not need to be stored, as it is already
associated with the final C position.
</footnote>
<page confidence="0.997262">
83
</page>
<subsectionHeader confidence="0.483864">
Computational Linguistics Volume 20, Number 1
</subsectionHeader>
<bodyText confidence="0.8966875">
of charts. Kornai (1991, p. 70) gives the following example:
def
</bodyText>
<equation confidence="0.9312765">
/
g h i
/
k 1
</equation>
<bodyText confidence="0.975202333333333">
Each chart is encoded as a string and then these two strings are linked by association
lines. Each line indicates that the segments it connects are actually the same segment
(in the original diagram). Here is the first step of the encoding of the above diagram:2°
</bodyText>
<equation confidence="0.973428666666667">
dlgtelgfOhbfli
\/ / /\
gljthlki0kbila
</equation>
<bodyText confidence="0.999181285714286">
Next, this encoding can itself be encoded into a string 77 characters long. Kornai
himself admits (p. 72) that his encoding is impractical for autosegmental structures
having more than two charts.&apos; Kornai discusses another encoding, which involves
transducers that can read three (or more) tapes simultaneously. However, this comes in
for the same criticism leveled at Kay&apos;s system above, namely that there is no principled
upper bound on the number of tiers due to such considerations as complex feature
geometry and morphemic segregation.
</bodyText>
<subsectionHeader confidence="0.991189">
5.3 Wiebe (1992)
</subsectionHeader>
<bodyText confidence="0.91610725">
Wiebe (1992) has recently devised an encoding of autosegmental diagrams that over-
comes many of the problems of Kornai&apos;s triple code. It is called the MULTI-LINEAR
CODE. Consider again diagram (29), reproduced below.
29. a perfective active
</bodyText>
<equation confidence="0.536900333333333">
CV CCV C causative
/
write
</equation>
<bodyText confidence="0.9923706">
This diagram contains two charts. The upper chart, which connects the vowel to two
V slots will be referred to as chart 1, and the other chart as chart 2. Since there is a total
ordering on the associations in a given chart (Goldsmith 1976, p. 29), it is sufficient to
record how many associations each autosegment has on each chart, without specifying
where these associations lead. The multi-linear code for (29) is displayed in (42).
</bodyText>
<footnote confidence="0.9483495">
20 Here the dots separating the triples have been omitted to enable more convenient location of
association lines.
21 The encoding procedure would not terminate for Pulleyblank&apos;s example (18). This is because the first
application of the encoding would take the three-tiered structure and produce another (more
complicated) three-tiered structure. In fact, this is just a special case of a more general problem, for the
encoding fails for any tier structure containing a cycle, such as the one proposed by Clements (1991).
</footnote>
<page confidence="0.996621">
84
</page>
<note confidence="0.36845725">
Steven Bird and T. Mark Ellison One-Level Phonology
42. all
C2V1C2C2V1C2
k2t22b2
</note>
<bodyText confidence="0.9980080625">
Here, a numeral n following an autosegment A indicates that A has an association
on chart n. These numerals can be stacked up; the first line specifies that a has two
associations on chart 1. A given tier can participate in two charts; the second line of
(42) has Cs associated on chart 2 and Vs associated on chart 1. Wiebe shows how
the multi-linear code satisfies the criteria for computability, invertibility, iconicity, and
compositionality.
Wiebe&apos;s encoding has some similarities to our revised encoding presented in Sec-
tion 4.5. Here is our encoding of (29):
43. tier 1 a:2:0:0
tier 2 C:0:1:0 V:1:0:0 C:0:1:0 C:0:1:0 V:1:0:0 C:0:1:0
tier 3 k:0:1:0 t:0:2:0 b:0:1:0
Suppose that a:p:q:r is an arbitrary 4-tuple of the kind in (43). We use position in the
tuple to specify which chart an association line is in, and use numerals to specify the
number of association lines. However, Wiebe uses numerals to specify the chart and
repetitions to specify the number of lines. There is a mapping between terms like all
in Wiebe&apos;s encoding and a:2:0:0 in our encoding:
</bodyText>
<equation confidence="0.775429">
f(a:p:q:r) -,--- alP2q3r
</equation>
<bodyText confidence="0.92586105">
If we apply f to each term in (43), the result is as follows.
all
C2 V1C2C2 V1C2
k2t22b2
Now it should be clear that there is an isomorphism between the two encodings.
Wiebe goes on to show how his encodings can be processed by new devices
called MULTI-TAPE SFAs and SFTs,22 where each tape corresponds to a row in the
multi-linear code. The devices are used for checking well-formedness constraints and
applying (possibly destructive) autosegmental rules. Wiebe also demonstrates that
these devices are more powerful than FSTs without epsilon transitions, claiming that
they can recognize some (strictly) context-sensitive languages. He argues that this extra
computational power is crucially required for processing autosegmental analyses with
feature- or structure-modifying rules.
The read heads can scan n-tuples separated by arbitrary distances,
and each head reads one co-ordinate of the n-tuple under it. ... It
is precisely this ability to scan different parts of an input word at
the same time that is so important in modelling autosegmental rules.
Association lines can associate segments in any part of one tier to
segments in any part of the facing tier. In order for any computational
22 Wiebe borrows the terms SFA and SFT from an earlier version of this paper (Bird and Ellison 1992).
</bodyText>
<page confidence="0.998355">
85
</page>
<note confidence="0.801979">
Computational Linguistics Volume 20, Number 1
</note>
<bodyText confidence="0.999675529411765">
device to efficiently process autosegmental representations, it must be
able to scan two associated segments from widely separated parts of the
representation at the same time (Wiebe 1992, pp. 95-96, emphasis added).
While this is a reasonable statement regarding any model like Kornai&apos;s, it does
not apply to our one-level model since the notion &apos;widely separated&apos; is meaningless
in this context. Two terms in a multi-linear code are widely separated if they differ
significantly as to their distance from the left- or right-hand end of the encoding. Thus,
the longer and more slanted the line that associates the autosegments, the greater their
separation. Although this is true of the ink on a page, our semantics pays no attention
to the angle and length of association lines. If a pair of autosegments is associated
then they are ipso facto proximate. The temporal extent of autosegments expands or
shrinks to accommodate these temporal constraints imposed by association lines. The
intensional character of our approach gives rise to a flexibility of interpretation that
obviates the need for more powerful devices of the kind advocated by Wiebe.
Now that we have reviewed some details of other finite-state approaches to au-
tosegmental phonology, we present a one-level analysis of an aspect of Arabic verb
morphology.
</bodyText>
<subsectionHeader confidence="0.988789">
5.4 A One-Level Analysis
</subsectionHeader>
<bodyText confidence="0.949212482758621">
As an alternative to either the elaboration of the transducer or the reduction of the
nonlinear representation to a code, we present a partial analysis of the Arabic verb in
terms of SFAs.&apos; Rather than trying to generate one representation from another, we
construct a description of the individual Arabic word by taking the intersection of the
SFAs describing each of the morphemes. The forms we analyze here, like those given
in McCarthy (1981), do not include inflections and also assume that the following
suffix is consonant-initia0 We shall derive the stem kattab from three morphemes,
specifying the form, the root, and the voice/mood.
The form I SFA (44) generalizes over all verbs: it accepts/ generates all correct
verbs of this form, as well as a number of nonsense verbs, and factors out information
specific to the individual words.
44. C:1 V:0 C:1 V:0 C:1
The indices mark associations that will link this tier to the root.
Another tier is the consonantal tier. It contains heterogeneous autosegments cor-
responding to consonants. These symbols are heterogeneous because they allow not
only the corresponding consonant, but also any of the vowels. So the f autosegment on
the consonant-tier denotes any sequence of the segments f, a, i, or u. The two uses of f
are disambiguated by reference to the tiers on which they occur. Under this definition,
autosegments on the consonant tier can spread over vowels to the next consonantal
position.
The root SFA generalizes over all stems constructed from the same root. The en-
coding on the consonant tier describing the root fl, to do, appears in (45).
23 The reader interested in other finite-state models of Arabic phonology is directed to the work of
Narayanan and Hashem (1993), Beesley, Buckwater, and Newton (1989), and Beesley (1990). These have
not been discussed at length here, because they do not seek to implement autosegmental phonology.
24 Biliteral roots in forms I, III, IV, V. VI, VII, VIII, X, XI, XII, and XIV, triliteral roots in forms IX and XI,
and quadriliteral roots in form QIV reorder the consonant-vowel sequence in the final syllable of the
root if followed by a vowel-initial inflection. Where possible, the Arabic verb stem will metathesize or
delete short vowels to create a geminate with root consonants (McCarthy 1981, pp. 1970.
</bodyText>
<page confidence="0.991803">
86
</page>
<bodyText confidence="0.937166909090909">
Steven Bird and T. Mark Ellison One-Level Phonology
45. .:0* f:1 (.:0* 5:1)-* 1:1
The wildcards are necessary for affix consonants, such as the n- prefix of form VII or
the -t- infix of form VIII.
It might be argued that fixing the associations (by the indices) in the specification
of the morpheme is redundant—that the associations should be supplied by rule.
However, 3 of the 15 triliteral forms of the Arabic verb, namely forms II, V and XII,
violate the association convention, multiply associating central autosegments rather
than peripheral ones. For these forms there seems little choice but to lexically specify
the associations or else introduce an ad hoc, morphologically triggered, rule (McCarthy
1981, p. 392, rule 24). In our notation, we can specify these forms as:
46. II C:1 V:0 C:1 C:1 V:0 C:1
✓ t:1 V:0 C:1 V:0 C:1 C:1 V:0 C:1
XII C:1 C:1 V:0 w:0 C:1 V:0 C:1
The intersections of the three forms in (46) with the root automaton (45) are:
47. II f:1 V:0 V:0 1:1
✓ t:1 V:0 f:1 V:0 :1 C:1 V:0 1:1
XII f:1 1 V:0 w:0 V:0 1:1
The vocalism for the active perfect verb (except form I) is very simple to express: it
is a sequence of as interleaved with consonants. On a vowel plane, where each au-
tosegment is heterogeneous, accepting a vowel and any of the consonants, this aspect
may be expressed by the single autosegment a, which corresponds to the automaton
in (48).
Forming the intersection of this SFA with the intersections of roots and forms
shown in (47) gives the following forms.
49. II f:1 a:0 :1 a:0 1:1
✓ t:1 a:0 f:1 a:0 :1 Si a:0 1:1
XII f:1 . a:0 w:0 :1 a:0 1:1
This brief analysis shows the ease with which a computable analysis of nonconcate-
native morphology can be constructed in the SFA formalism. While it may not cover
all possible generalizations about Arabic verbal structure, the important point here is
that it captures generalizations that are always surface-true of the phonology of the
separate morphemes that come together to build up the verb.
</bodyText>
<subsectionHeader confidence="0.998353">
5.5 Automata versus Linearizations
</subsectionHeader>
<bodyText confidence="0.99794075">
We have seen that Kornai (1991) finds it necessary to choose between the imposition
of restrictions on autosegmental phonology and the loss of finite stateness in the trans-
duction relationship. As it turns out, the one-level approach does not suffer from this
problem. In this section we explain why.
</bodyText>
<page confidence="0.997158">
87
</page>
<note confidence="0.801073">
Computational Linguistics Volume 20, Number 1
</note>
<bodyText confidence="0.9688602">
Note that the natural processes by which finite-state automata are combined, and
therefore by which regular languages are manipulated, are not themselves regular. To
see why this is so, suppose we have two regular expressions describing the first form
and the root of the Arabic verb to write:
50. CVCVC
k (** 0+ .* b
The intersection is the following regular expression:
51. kVtVb
The associations fixing the incidence of k with the first consonant slot, t with the third,
and b with the final, are made by the intersection operation. The question arises as to
how we can construct the associations if the same operation for Kornai&apos;s system is not
regular. The operation we have applied here—intersection—cannot be performed by a
regular transducer. This does not invalidate our claim to regularity. What is regular in
our theory is each individual description and generalization about phonological data.
That is, the descriptions we use are all regular descriptions of phonological objects.
What is not regular in one-level phonology is the relationship between different
formats of the same description. There is no finite-state transducer that will form the
product of two regular expressions. Multilevel analyses necessarily seek to capture
relationships between different descriptions, and like the product operation, these
relationships often cannot be captured by finite-state transducers.
</bodyText>
<sectionHeader confidence="0.997231" genericHeader="conclusions">
6. Conclusions
</sectionHeader>
<bodyText confidence="0.99998825">
The starting point of this paper was the distinction between descriptions and objects.
Multidimensional phonological structures were taken to be descriptions of classes
of phonetic objects, following Wheeler (1981), Bird and Klein (1990), Pierrehumbert
(1990), Bird (1990), and Coleman (1992). Multiple tiers could be put together not by
a clever encoding but by the simple operation of intersection, which corresponds to
logical conjunction. Furthermore, this move of intensionalizing phonology enabled us
to provide a straightforward formal basis for adding logical negation and disjunction
to our representations.
One important consequence of this work is that there are now good prospects for
the incorporation of nonlinear phonology into constraint-based grammar formalisms
such as HPSG (Pollard and Sag 1987). Such a move gives rise to a novel view of the
relationship between phonology and the other modules of grammar, as some initial
investigation has already demonstrated (Bird 1992; Bird and Klein in press). Mak-
ing surface generalizations the only goal of analysis makes the machine learning of
analyses simpler (Ellison forthcoming). The automaton semantics for autosegmental
representations and rules gives us a mechanical way of comparing the empirical claims
made by a range of autosegmental and segmental accounts of natural language phe-
nomena. Finally, to the extent that phonologists are becoming increasingly committed
to a declarative, constraint-based view of their domain, we believe that the model
proposed here is well suited to their computational needs.
</bodyText>
<sectionHeader confidence="0.898636" genericHeader="acknowledgments">
Acknowledgments and Engineering Research Council, under
</sectionHeader>
<footnote confidence="0.451629">
This research is funded by the U.K. Science grant GR/G-22084. Computational Phonology:
</footnote>
<page confidence="0.994687">
88
</page>
<note confidence="0.706885">
Steven Bird and T. Mark Ellison One-Level Phonology
A Constraint-Based Approach. We are grateful
to John Coleman, Mark Johnson, Andras
Kornai, Ewan Klein, Henry Thompson,
Markus Walther, Bruce Wiebe, and two
</note>
<bodyText confidence="0.96110875">
anonymous reviewers for comments on this
work. We are also grateful to the students
who attended our course at the Fifth
European Summer School on Logic, Language
and Information (Lisbon, August 1993), and
gave valuable feedback on this work. The
authors take equal responsibility for the
material presented here.
</bodyText>
<sectionHeader confidence="0.986795" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999381495327103">
Antworth, E. (1990). PC-KIMMO: A
Two-Level Processor for Morphological
Analysis. Summer Institute of Linguistics.
Bear, J. (1986). &amp;quot;A morphological recognizer
with syntactic and phonological rules.&amp;quot; In
Proceedings, the 11th International Conference
on Computational Linguistics, 272-276.
Beesley, K. (1990). &amp;quot;Finite-state descriptions
of Arabic morphology.&amp;quot; In Proceedings,
Second Conference on Bilingual Computing in
Arabic and English.
Beesley, K.; Buckwater, T.; and Newton, S.
(1989). &amp;quot;Two-level finite state analysis of
Arabic.&amp;quot; In Proceedings, First Conference on
Bilingual Computing in Arabic and English.
Bird, S. (1990). Constraint-based phonology.
Doctoral dissertation, University of
Edinburgh.
Bird, S. (1992). &amp;quot;Finite-state phonology in
HPSG.&amp;quot; In Proceedings, Fifteenth
International Conference on Computational
Linguistics, 74-80.
Bird, S. (in press). Computational Phonology:
A Constraint-Based Approach. Studies in
Natural Language Processing. Cambridge
University Press.
Bird, S., and Ellison, T. M. (1992). &amp;quot;One
level phonology: autosegmental
representations and rules as finite-state
automata.&amp;quot; RP 51, University of
Edinburgh, Centre for Cognitive Science.
Bird, S., and Klein, E. (1990). &amp;quot;Phonological
events.&amp;quot; Journal of Linguistics 26,33-56.
Bird, S., and Klein, E. (in press).
&amp;quot;Phonological analysis in typed feature
systems.&amp;quot; Computational Linguistics, 20.
Bird, S., and Ladd, D. R. (1991). &amp;quot;Presenting
autosegmental phonology.&amp;quot; Journal of
Linguistics, 27,193-210.
Bloomfield, L. (1926). &amp;quot;A set of postulates
for the science of language.&amp;quot; Language, 2,
153-464. Reprinted in Readings in
Linguistics I: The Development of Descriptive
Linguistics in America 1925-56, edited by
Martin Joos, 26-31.
Broe, M. (1993). Specification Theory: The
treatment of redundancy in generative
phonology. Doctoral dissertation,
University of Edinburgh.
Chomsky, N., and Halle, M. (1968). The
Sound Pattern of English. Harper and Row.
Clements, G. N. (1985). &amp;quot;The geometry of
phonological features.&amp;quot; In Phonology
Yearbook 2, edited by C. Ewen and
J. Anderson, 225-252. Cambridge
University Press.
Clements, G. N. (1991). &amp;quot;Place of articulation
in consonants and vowels: a unified
theory.&amp;quot; In Working Papers of the Cornell
Phonetics Laboratory, Number 5, edited by
G. N. Clements and E. Hume, 77-123.
Phonetics Laboratory, Cornell University.
Clements, G. N., and Ford, K. C. (1979).
&amp;quot;Kikuyu tone shift and its synchronic
consequences.&amp;quot; Linguistic Inquiry, 10,
179-210.
Coleman, J. S. (1991). Phonological
representations-their names, forms and
powers. Doctoral dissertation, University
of York.
Coleman, J. S. (1992). &amp;quot;The phonetic
interpretation of headed phonological
structures containing overlapping
constituents.&amp;quot; Phonology, 9,1-44.
Ellison, T. M. (1992). &amp;quot;Discovering vowel
harmony.&amp;quot; In Background and Experiments
in Machine Learning of Natural Language,
edited by W. Daelemans and D. Powers,
131-136. ITK.
Ellison, T. M. (1993). The machine learning of
phonological structure. Doctoral
dissertation, University of Western
Australia.
Ellison, T. M. (forthcoming). &amp;quot;The iterative
learning of phonological constraints.&amp;quot;
Computational Linguistics.
Goldsmith, J. A. (1976). Autosegmental
phonology. Doctoral dissertation,
Massachusetts Institute of Technology.
Goldsmith, J. (1982). &amp;quot;Accent systems.&amp;quot; In
The Structure of Phonological Representations,
edited by H. van der Hulst and N. Smith,
47-63. Foris.
Goldsmith, J. (1991). &amp;quot;Phonology as an
intelligent system.&amp;quot; In Bridges Between
Psychology and Linguistics, edited by D. J.
Napoli and J. Kegl, 247-267. Lawrence
Erlbaum.
Hoperoft, J., and Ullman, J. D. (1979).
Introduction to Automata Theory, Languages
and Computation. Addison-Wesley.
Johnson, C. D. (1972). Formal Aspects of
Phonological Description. Mouton.
Karttunen, L. (1983). &amp;quot;KIMMO: A general
morphological processor.&amp;quot; Texas Linguistic
Forum, 22,163-186.
Kay, M. (1987). &amp;quot;Nonconcatenative
</reference>
<page confidence="0.990175">
89
</page>
<note confidence="0.481949">
Computational Linguistics Volume 20, Number 1
</note>
<reference confidence="0.999691194174757">
finite-state morphology.&amp;quot; In Proceedings,
Third Meeting of the European Chapter of the
Association for Computational Linguistics,
2-10.
Kaye, J. (1989). Phonology: A Cognitive View.
Erlbaum.
Kornai, A. (1991). Formal Phonology. Doctoral
dissertation, Stanford University.
Kornai, A., and Kalman, L. (1988).
&amp;quot;Hungarian sentence intonation.&amp;quot; In
Autosegmental Studies on Pitch Accent,
edited by H. van der Hu1st and N. Smith,
183-195. Foris.
Koskenniemi, K. (1983). Two-level morphology:
A general computational model for word-form
recognition and production. Doctoral
dissertation, University of Helsinki.
Koskenniemi, K. (1985). &amp;quot;Compilation of
automata from morphological two-level
rules.&amp;quot; In Papers from the Fifth Scandinavian
Conference of Computational Linguistics,
University of Helsinki, 143-149.
Leben, W. R. (1973). Suprasegmental
phonology. Doctoral dissertation,
Massachusetts Institute of Technology.
Leben, W. R. (1978). &amp;quot;The representation of
tone.&amp;quot; In Tone-A Linguistic Survey, edited
by V. A. Fromkin, 177-219. Academic
Press.
Mastroianni, M. (1993). &amp;quot;Attribute logic
phonology.&amp;quot; Technical Report CMU-LCL
93-4, Carnegie Mellon University.
McCarthy, J. (1981). &amp;quot;A prosodic theory of
non-concatenative morphology.&amp;quot;
Linguistic Inquiry, 12, 373-418.
McCarthy, J. (1989). &amp;quot;Linear order in
phonological representation.&amp;quot; Linguistic
Inquiry, 20(1), 71-99.
Narayanan, A., and Hashem, L. (1993). &amp;quot;On
abstract finite-state morphology.&amp;quot; In
Proceedings, Sixth Conference of the European
Chapter of the Association for Computational
Linguistics, 297-304.
Partee, B.; ter Meulen, A.; and Wall, R. E.
(1990). Mathematical Methods in Linguistics.
Studies in Linguistics and Philosophy.
Kluwer.
Pierrehumbert, J. (1990). &amp;quot;Phonological and
phonetic representation.&amp;quot; Journal of
Phonetics, 18, 375-394.
Pollard, C., and Sag, I. (1987).
Information-Based Syntax and Semantics,
Volume 13 of CSLI Lecture Notes. Stanford:
Center for the Study of Language and
Information.
Pulleyblank, D. (1986). Tone in Lexical
Phonology. Studies in Natural Language
and Linguistic Theory. Reidel.
Pulman, S. G., and Hepple, M. R. (1993). &amp;quot;A
feature-based formalism for two level
phonology: a description and
implementation.&amp;quot; Computer Speech and
Language, 7, 333-358.
Ritchie, G. D. (1992). &amp;quot;Languages generated
by two-level morphological rules.&amp;quot;
Computational Linguistics, 18(1), 41-59.
Ritchie, G. D.; Russell, G. J.; Black, A. W.;
and Pulman, S. G. (1992). Computational
Morphology: Practical Mechanisms for the
English Lexicon. MIT Press.
Russell, K. (1993). A constraint-based approach
to phonology. Doctoral dissertation,
University of Southern California.
Sagey, E. (1988). &amp;quot;On the ill-formedness of
crossing association lines.&amp;quot; Linguistic
Inquiry, 19, 109-118.
Schiller, A., and Steffens, P. (1991).
&amp;quot;Morphological processing in the
two-level paradigm.&amp;quot; In Text
Understanding in LILOG, edited by
0. Herzog and C.-R. Rollinger, 112-126.
Springer-Verlag.
Scobbie, J. (1991). Attribute-value phonology.
Doctoral dissertation, University of
Edinburgh.
Sproat, R. (1992). Morphology and
Computation. Natural Language
Processing. MIT Press.
Touretzky, D. S., and Wheeler, D. W. (1990).
&amp;quot;A computational basis for phonology.&amp;quot;
In Advances in Neural Information Processing
Systems 2: The Collected Papers of the 1989
IEEE Conference on Neural Information
Processing Systems, edited by
D. S. Touretzky. Morgan Kaufmann.
Wheeler, D. (1981). Aspects of a categorial
theory of phonology. Doctoral dissertation,
Unversity of Massachusetts, Amherst,
MA.
Wiebe, B. (1992). Modelling autosegmental
phonology with multi-tape finite state
transducers. Master&apos;s dissertation, Simon
Fraser University.
</reference>
<page confidence="0.99863">
90
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.898954">
<title confidence="0.990222">One-Level Phonology: Autosegmental Representations and Rules as Finite Automata</title>
<author confidence="0.999915">Steven Bird T Mark Ellison</author>
<affiliation confidence="0.998404">University of Edinburgh University of Edinburgh</affiliation>
<abstract confidence="0.994185571428572">When phonological rules are regarded as declarative descriptions, it is possible to construct a model of phonology in which rules and representations are no longer distinguished and such procedural devices as rule-ordering are absent. In this paper we present a finite-state model of phonology in which automata are the descriptions and tapes (or strings) are the objects being described. This provides the formal semantics for an autosegmental phonology without structure-changing rules. Logical operations on the phonological domain—such as conjunction, disjunction, and negation—make sense since the phonological domain consists of descriptions rather than objects. These operations as applied to automata are the straightforward operations of intersection, union, and complement. If the arrow in a rewrite rule is viewed as logical implication, then a phonological rule can also be represented as an automaton, albeit a less restrictive automaton than would be required for a lexical representation. The model is then compared with the transducer models for autosegmental phonology of Kay (1987), Kornai (1991), and Wiebe (1992). We conclude that the declarative approach to phonology presents an attractive way of extending finite-state techniques to autosegmental phonology while remaining within the confines of regular grammar.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Antworth</author>
</authors>
<title>PC-KIMMO: A Two-Level Processor for Morphological Analysis. Summer Institute of Linguistics.</title>
<date>1990</date>
<contexts>
<context position="2554" citStr="Antworth 1990" startWordPosition="366" endWordPosition="367">) has made it possible for the linguist to work at a conveniently abstract level, and analyses of several languages now exemplify the approach. Today, two-level morphology encompasses much of traditional segmental generative phonology of the SPE variety (Chomsky and Halle 1968).3 Although further development and application of this model is set to continue for some time, there is now a clear need to integrate it more closely with computational * University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland, U.K. E-mail: {steven,marke}@cogsci.ed.ac.uk 1 (Antworth 1990; Ritchie, Russell, Black, and Pulman 1992; Sproat 1992) 2 (Bear 1986; Antworth 1990; Schiller and Steffens 1991; Pulman and Hepple 1993) 3 Two caveats are necessary here. SPE rules must be restricted so as not to apply to their own output (Johnson 1972) and there is no guarantee that the transducer encoding an SPE rule can be expressed using the two-level rule notation (Ritchie 1992). C) 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 1 grammar frameworks on the one hand and modern nonlinear phonology on the other. The primary goal of this article is</context>
</contexts>
<marker>Antworth, 1990</marker>
<rawString>Antworth, E. (1990). PC-KIMMO: A Two-Level Processor for Morphological Analysis. Summer Institute of Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bear</author>
</authors>
<title>A morphological recognizer with syntactic and phonological rules.&amp;quot;</title>
<date>1986</date>
<booktitle>In Proceedings, the 11th International Conference on Computational Linguistics,</booktitle>
<pages>272--276</pages>
<contexts>
<context position="2623" citStr="Bear 1986" startWordPosition="377" endWordPosition="378">t level, and analyses of several languages now exemplify the approach. Today, two-level morphology encompasses much of traditional segmental generative phonology of the SPE variety (Chomsky and Halle 1968).3 Although further development and application of this model is set to continue for some time, there is now a clear need to integrate it more closely with computational * University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland, U.K. E-mail: {steven,marke}@cogsci.ed.ac.uk 1 (Antworth 1990; Ritchie, Russell, Black, and Pulman 1992; Sproat 1992) 2 (Bear 1986; Antworth 1990; Schiller and Steffens 1991; Pulman and Hepple 1993) 3 Two caveats are necessary here. SPE rules must be restricted so as not to apply to their own output (Johnson 1972) and there is no guarantee that the transducer encoding an SPE rule can be expressed using the two-level rule notation (Ritchie 1992). C) 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 1 grammar frameworks on the one hand and modern nonlinear phonology on the other. The primary goal of this article is to show how the central tenets of autosegmental phonology translate </context>
</contexts>
<marker>Bear, 1986</marker>
<rawString>Bear, J. (1986). &amp;quot;A morphological recognizer with syntactic and phonological rules.&amp;quot; In Proceedings, the 11th International Conference on Computational Linguistics, 272-276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Beesley</author>
</authors>
<title>Finite-state descriptions of Arabic morphology.&amp;quot;</title>
<date>1990</date>
<booktitle>In Proceedings, Second Conference on Bilingual Computing in Arabic and English.</booktitle>
<contexts>
<context position="72964" citStr="Beesley (1990)" startWordPosition="12457" endWordPosition="12458">on the consonant-tier denotes any sequence of the segments f, a, i, or u. The two uses of f are disambiguated by reference to the tiers on which they occur. Under this definition, autosegments on the consonant tier can spread over vowels to the next consonantal position. The root SFA generalizes over all stems constructed from the same root. The encoding on the consonant tier describing the root fl, to do, appears in (45). 23 The reader interested in other finite-state models of Arabic phonology is directed to the work of Narayanan and Hashem (1993), Beesley, Buckwater, and Newton (1989), and Beesley (1990). These have not been discussed at length here, because they do not seek to implement autosegmental phonology. 24 Biliteral roots in forms I, III, IV, V. VI, VII, VIII, X, XI, XII, and XIV, triliteral roots in forms IX and XI, and quadriliteral roots in form QIV reorder the consonant-vowel sequence in the final syllable of the root if followed by a vowel-initial inflection. Where possible, the Arabic verb stem will metathesize or delete short vowels to create a geminate with root consonants (McCarthy 1981, pp. 1970. 86 Steven Bird and T. Mark Ellison One-Level Phonology 45. .:0* f:1 (.:0* 5:1)</context>
</contexts>
<marker>Beesley, 1990</marker>
<rawString>Beesley, K. (1990). &amp;quot;Finite-state descriptions of Arabic morphology.&amp;quot; In Proceedings, Second Conference on Bilingual Computing in Arabic and English.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Beesley</author>
<author>T Buckwater</author>
<author>S Newton</author>
</authors>
<title>Two-level finite state analysis of Arabic.&amp;quot; In</title>
<date>1989</date>
<booktitle>Proceedings, First Conference on Bilingual Computing in Arabic and English.</booktitle>
<marker>Beesley, Buckwater, Newton, 1989</marker>
<rawString>Beesley, K.; Buckwater, T.; and Newton, S. (1989). &amp;quot;Two-level finite state analysis of Arabic.&amp;quot; In Proceedings, First Conference on Bilingual Computing in Arabic and English.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bird</author>
</authors>
<title>Constraint-based phonology. Doctoral dissertation,</title>
<date>1990</date>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="5683" citStr="Bird 1990" startWordPosition="870" endWordPosition="871"> to note here that each line of the expression represents a tier and the tiers are combined using the intersection operation (n). Moreover, the is act as synchronization marks between the operands of the intersection operation. (+hi, 0)* (+hi, 1) (+hi, 0)* (— hi, 0)* ( — hi, 1) (—hi, 0)* ( —hi, 1) (—hi, 0)* n (—rnd, 0)*(—rnd, 1) (—rnd, 0)* ( —rnd, 1) (—rnd, 0)* (+rnd, 0)* (+rnd, 1) (+rnd, 0)* The final step is to compute the intersection and project the first element of each tuple (ignoring the is and Os). This produces the expression: (+hi n —rnd)+ (—hi n —rnd)+ (—hi n +rnd)+ 4 Wheeler 1981; Bird 1990; Coleman 1991; Scobbie 1991; Broe 1993; Russell 1993; Mastroianni 1993. 56 Steven Bird and T. Mark Ellison One-Level Phonology Given plausible interpretations of the high and round features, this last expression simplifies to i±a+o+, which describes an automaton tape (or a string) divided into three nonempty intervals, the first containing [i], the second containing [a], and the third containing [o]. This, we shall claim, is the intended interpretation of (1). After a detailed discussion of this procedure, the remainder of Section 4 is given over to generalizing the procedure to an arbitrary </context>
<context position="11304" citStr="Bird (1990)" startWordPosition="1817" endWordPosition="1818">dd 1991) that the formal explicitness of the SPE model has not been matched by these more recent proposals. Before we can begin to compute with autosegmental representations and rules, they need to be given a formal semantics. Our starting point here is the temporal semantics of Bird and Klein (1990), based on Sagey&apos;s (1988) model, which has gained widespread acceptance in autosegmental phonology. Under this temporal semantics, phonological properties are attached to intervals that are related using precedence (an asymmetric, transitive relation) and overlap (a reflexive, symmetric relation). Bird (1990) showed how a phonological description language can be modeled by such event structures, where the precedence relation models the linear ordering of tiers and the overlap relation models association lines. In this paper, we shall provide an automaton-based semantics for precedence and overlap, thus arriving at a computational semantics for the autosegmental notation. 3. State-Labeled Automata In this section we give definitions for a new device called a state-labeled finite automaton, and then we define various useful operations on these automata. (Some readers may prefer to skip Section 3 on </context>
<context position="77545" citStr="Bird (1990)" startWordPosition="13213" endWordPosition="13214">formats of the same description. There is no finite-state transducer that will form the product of two regular expressions. Multilevel analyses necessarily seek to capture relationships between different descriptions, and like the product operation, these relationships often cannot be captured by finite-state transducers. 6. Conclusions The starting point of this paper was the distinction between descriptions and objects. Multidimensional phonological structures were taken to be descriptions of classes of phonetic objects, following Wheeler (1981), Bird and Klein (1990), Pierrehumbert (1990), Bird (1990), and Coleman (1992). Multiple tiers could be put together not by a clever encoding but by the simple operation of intersection, which corresponds to logical conjunction. Furthermore, this move of intensionalizing phonology enabled us to provide a straightforward formal basis for adding logical negation and disjunction to our representations. One important consequence of this work is that there are now good prospects for the incorporation of nonlinear phonology into constraint-based grammar formalisms such as HPSG (Pollard and Sag 1987). Such a move gives rise to a novel view of the relationsh</context>
</contexts>
<marker>Bird, 1990</marker>
<rawString>Bird, S. (1990). Constraint-based phonology. Doctoral dissertation, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bird</author>
</authors>
<title>Finite-state phonology in HPSG.&amp;quot;</title>
<date>1992</date>
<booktitle>In Proceedings, Fifteenth International Conference on Computational Linguistics,</booktitle>
<pages>74--80</pages>
<contexts>
<context position="78265" citStr="Bird 1992" startWordPosition="13321" endWordPosition="13322"> of intersection, which corresponds to logical conjunction. Furthermore, this move of intensionalizing phonology enabled us to provide a straightforward formal basis for adding logical negation and disjunction to our representations. One important consequence of this work is that there are now good prospects for the incorporation of nonlinear phonology into constraint-based grammar formalisms such as HPSG (Pollard and Sag 1987). Such a move gives rise to a novel view of the relationship between phonology and the other modules of grammar, as some initial investigation has already demonstrated (Bird 1992; Bird and Klein in press). Making surface generalizations the only goal of analysis makes the machine learning of analyses simpler (Ellison forthcoming). The automaton semantics for autosegmental representations and rules gives us a mechanical way of comparing the empirical claims made by a range of autosegmental and segmental accounts of natural language phenomena. Finally, to the extent that phonologists are becoming increasingly committed to a declarative, constraint-based view of their domain, we believe that the model proposed here is well suited to their computational needs. Acknowledgm</context>
</contexts>
<marker>Bird, 1992</marker>
<rawString>Bird, S. (1992). &amp;quot;Finite-state phonology in HPSG.&amp;quot; In Proceedings, Fifteenth International Conference on Computational Linguistics, 74-80.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Bird</author>
</authors>
<title>(in press). Computational Phonology: A Constraint-Based Approach.</title>
<booktitle>Studies in Natural Language Processing.</booktitle>
<publisher>Cambridge University Press.</publisher>
<marker>Bird, </marker>
<rawString>Bird, S. (in press). Computational Phonology: A Constraint-Based Approach. Studies in Natural Language Processing. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bird</author>
<author>T M Ellison</author>
</authors>
<title>One level phonology: autosegmental representations and rules as finite-state automata.&amp;quot; RP 51,</title>
<date>1992</date>
<institution>University of Edinburgh, Centre for Cognitive Science.</institution>
<contexts>
<context position="69767" citStr="Bird and Ellison 1992" startWordPosition="11937" endWordPosition="11940">wer is crucially required for processing autosegmental analyses with feature- or structure-modifying rules. The read heads can scan n-tuples separated by arbitrary distances, and each head reads one co-ordinate of the n-tuple under it. ... It is precisely this ability to scan different parts of an input word at the same time that is so important in modelling autosegmental rules. Association lines can associate segments in any part of one tier to segments in any part of the facing tier. In order for any computational 22 Wiebe borrows the terms SFA and SFT from an earlier version of this paper (Bird and Ellison 1992). 85 Computational Linguistics Volume 20, Number 1 device to efficiently process autosegmental representations, it must be able to scan two associated segments from widely separated parts of the representation at the same time (Wiebe 1992, pp. 95-96, emphasis added). While this is a reasonable statement regarding any model like Kornai&apos;s, it does not apply to our one-level model since the notion &apos;widely separated&apos; is meaningless in this context. Two terms in a multi-linear code are widely separated if they differ significantly as to their distance from the left- or right-hand end of the encodin</context>
</contexts>
<marker>Bird, Ellison, 1992</marker>
<rawString>Bird, S., and Ellison, T. M. (1992). &amp;quot;One level phonology: autosegmental representations and rules as finite-state automata.&amp;quot; RP 51, University of Edinburgh, Centre for Cognitive Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bird</author>
<author>E Klein</author>
</authors>
<title>Phonological events.&amp;quot;</title>
<date>1990</date>
<journal>Journal of Linguistics</journal>
<pages>26--33</pages>
<contexts>
<context position="4052" citStr="Bird and Klein (1990)" startWordPosition="599" endWordPosition="602">intended to contrast with models employing two levels (such as the FST model mentioned above) or three levels (Goldsmith 1991; Touretzky and Wheeler 1990), or an unbounded number of levels (Chomsky and Halle 1968). The one-level model represents the outgrowth of three independent strands of research: (i) the finitestate modeling of phonology, (ii) the declarative approach to phonology,&apos; and (iii) the automatic learning of phonological generalizations (Ellison 1992, 1993). The paper is organized as follows. Section 2 presents an overview of autosegmental phonology and the temporal semantics of Bird and Klein (1990). Then we define state-labeled automata (Section 3.1), show their equivalence to finite state automata (Section 3.2), define the operations of concatenation, union, intersection, and complement (Section 3.3), and further define state-labeled transducers (Section 3.4). The central proposals of the paper are contained in Section 4. We show how autosegmental association can be interpreted in terms of the synchronization of two automata, where each automaton specifies an autosegmental tier. We now give a brief foretaste of this procedure. Suppose that we have the autosegmental diagram in (1), enco</context>
<context position="10994" citStr="Bird and Klein (1990)" startWordPosition="1773" endWordPosition="1776">o adjacent [autosegments] must be distinct. Thus HHL is not a possible melodic pattern; it automatically simplifies to HL. Although nonlinear models like autosegmental phonology represent a major advance on the linear model of SPE in the area of explanatory adequacy, it has sometimes been pointed out (e.g., Bird and Ladd 1991) that the formal explicitness of the SPE model has not been matched by these more recent proposals. Before we can begin to compute with autosegmental representations and rules, they need to be given a formal semantics. Our starting point here is the temporal semantics of Bird and Klein (1990), based on Sagey&apos;s (1988) model, which has gained widespread acceptance in autosegmental phonology. Under this temporal semantics, phonological properties are attached to intervals that are related using precedence (an asymmetric, transitive relation) and overlap (a reflexive, symmetric relation). Bird (1990) showed how a phonological description language can be modeled by such event structures, where the precedence relation models the linear ordering of tiers and the overlap relation models association lines. In this paper, we shall provide an automaton-based semantics for precedence and over</context>
<context position="28959" citStr="Bird and Klein 1990" startWordPosition="4927" endWordPosition="4930">resented an interpretation of association based on temporal overlap. Now we must find a way of simulating this temporal structure using automata. Let us begin by considering the simplest possible autosegmental diagram. 11. Since each autosegment denotes an interval and the two intervals must overlap, we would like to interpret the above diagram as describing any of the following strings, among others:9 A A A • • • • B BB A A A A A • • B B s • • A What kind of automaton will give us the required behavior? The clue is that a pair of intervals overlap if and only if they share a point in common (Bird and Klein 1990, p. 36). Note that in each of the above diagrams, the third interval contains an instance of both A and B, and the existence of this interval was both a necessary and sufficient requirement for the association line to have its overlap interpretation. So we need an automaton for each autosegment that captures the two required properties: (i) denotation of an extended period, and (ii) existence of a special point. The &amp;quot;automaton&amp;quot; required for the autosegment A is given in (12). 12. This automaton accepts any string of one or more As, and requires that there is some A that is coincident with an </context>
<context position="77510" citStr="Bird and Klein (1990)" startWordPosition="13207" endWordPosition="13210">nology is the relationship between different formats of the same description. There is no finite-state transducer that will form the product of two regular expressions. Multilevel analyses necessarily seek to capture relationships between different descriptions, and like the product operation, these relationships often cannot be captured by finite-state transducers. 6. Conclusions The starting point of this paper was the distinction between descriptions and objects. Multidimensional phonological structures were taken to be descriptions of classes of phonetic objects, following Wheeler (1981), Bird and Klein (1990), Pierrehumbert (1990), Bird (1990), and Coleman (1992). Multiple tiers could be put together not by a clever encoding but by the simple operation of intersection, which corresponds to logical conjunction. Furthermore, this move of intensionalizing phonology enabled us to provide a straightforward formal basis for adding logical negation and disjunction to our representations. One important consequence of this work is that there are now good prospects for the incorporation of nonlinear phonology into constraint-based grammar formalisms such as HPSG (Pollard and Sag 1987). Such a move gives ris</context>
</contexts>
<marker>Bird, Klein, 1990</marker>
<rawString>Bird, S., and Klein, E. (1990). &amp;quot;Phonological events.&amp;quot; Journal of Linguistics 26,33-56.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Bird</author>
<author>E Klein</author>
</authors>
<title>(in press). &amp;quot;Phonological analysis in typed feature systems.&amp;quot;</title>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<marker>Bird, Klein, </marker>
<rawString>Bird, S., and Klein, E. (in press). &amp;quot;Phonological analysis in typed feature systems.&amp;quot; Computational Linguistics, 20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bird</author>
<author>D R Ladd</author>
</authors>
<title>Presenting autosegmental phonology.&amp;quot;</title>
<date>1991</date>
<journal>Journal of Linguistics,</journal>
<pages>27--193</pages>
<contexts>
<context position="10701" citStr="Bird and Ladd 1991" startWordPosition="1724" endWordPosition="1727">ccurs only at the right-hand end. Observe also that the charts in (4) do not contain adjacent identical tones. For example, there is no HH tone melody. This is expressed by a principle attributable to Leben (1973). 7. Obligatory Contour Principle: At the melodic level of the grammar, any two adjacent [autosegments] must be distinct. Thus HHL is not a possible melodic pattern; it automatically simplifies to HL. Although nonlinear models like autosegmental phonology represent a major advance on the linear model of SPE in the area of explanatory adequacy, it has sometimes been pointed out (e.g., Bird and Ladd 1991) that the formal explicitness of the SPE model has not been matched by these more recent proposals. Before we can begin to compute with autosegmental representations and rules, they need to be given a formal semantics. Our starting point here is the temporal semantics of Bird and Klein (1990), based on Sagey&apos;s (1988) model, which has gained widespread acceptance in autosegmental phonology. Under this temporal semantics, phonological properties are attached to intervals that are related using precedence (an asymmetric, transitive relation) and overlap (a reflexive, symmetric relation). Bird (19</context>
</contexts>
<marker>Bird, Ladd, 1991</marker>
<rawString>Bird, S., and Ladd, D. R. (1991). &amp;quot;Presenting autosegmental phonology.&amp;quot; Journal of Linguistics, 27,193-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Bloomfield</author>
</authors>
<title>A set of postulates for the science of language.&amp;quot;</title>
<date>1926</date>
<journal>Language,</journal>
<booktitle>Readings in Linguistics I: The Development of Descriptive Linguistics in America 1925-56, edited by Martin Joos,</booktitle>
<volume>2</volume>
<pages>153--464</pages>
<note>Reprinted in</note>
<contexts>
<context position="48137" citStr="Bloomfield (1926)" startWordPosition="8261" endWordPosition="8262">throw away the &apos;Sc&apos; chart, and once the structural description and structural change have been combined, we can also throw away the &apos;sd&apos; chart. In this way, the rule functions only as a filter on surface forms, and there is no way for two separate rules to communicate via these rule-internal charts. This approach permits us to interpret any nondestructive autosegmental rule.&apos; Those rules involving deletion of autosegments or association lines must be approached in a completely different way. Rather than deleting an element in a particular context, we set up an alternation with zero, following Bloomfield (1926). See Bird and Klein (in press) and Bird (in press) for detailed examples of this approach to deletion. This concludes our discussion of the automaton-based semantics for autosegmental representations and rules. In the next section we review some other attempts to treat autosegmental phonology using finite-state techniques. 5. Other Finite-State Approaches to Nonlinear Phonology 5.1 Kay (1987) The earliest treatment of autosegmental phonology in a finite-state setting is attributable to Kay (1987). It is tailored to the framework of nonconcatenative morphology developed by McCarthy (1981) in w</context>
</contexts>
<marker>Bloomfield, 1926</marker>
<rawString>Bloomfield, L. (1926). &amp;quot;A set of postulates for the science of language.&amp;quot; Language, 2, 153-464. Reprinted in Readings in Linguistics I: The Development of Descriptive Linguistics in America 1925-56, edited by Martin Joos, 26-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Broe</author>
</authors>
<title>Specification Theory: The treatment of redundancy in generative phonology. Doctoral dissertation,</title>
<date>1993</date>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="5722" citStr="Broe 1993" startWordPosition="876" endWordPosition="877">ression represents a tier and the tiers are combined using the intersection operation (n). Moreover, the is act as synchronization marks between the operands of the intersection operation. (+hi, 0)* (+hi, 1) (+hi, 0)* (— hi, 0)* ( — hi, 1) (—hi, 0)* ( —hi, 1) (—hi, 0)* n (—rnd, 0)*(—rnd, 1) (—rnd, 0)* ( —rnd, 1) (—rnd, 0)* (+rnd, 0)* (+rnd, 1) (+rnd, 0)* The final step is to compute the intersection and project the first element of each tuple (ignoring the is and Os). This produces the expression: (+hi n —rnd)+ (—hi n —rnd)+ (—hi n +rnd)+ 4 Wheeler 1981; Bird 1990; Coleman 1991; Scobbie 1991; Broe 1993; Russell 1993; Mastroianni 1993. 56 Steven Bird and T. Mark Ellison One-Level Phonology Given plausible interpretations of the high and round features, this last expression simplifies to i±a+o+, which describes an automaton tape (or a string) divided into three nonempty intervals, the first containing [i], the second containing [a], and the third containing [o]. This, we shall claim, is the intended interpretation of (1). After a detailed discussion of this procedure, the remainder of Section 4 is given over to generalizing the procedure to an arbitrary number of autosegmental charts (Section</context>
</contexts>
<marker>Broe, 1993</marker>
<rawString>Broe, M. (1993). Specification Theory: The treatment of redundancy in generative phonology. Doctoral dissertation, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
<author>M Halle</author>
</authors>
<title>The Sound Pattern of English. Harper and Row.</title>
<date>1968</date>
<contexts>
<context position="2219" citStr="Chomsky and Halle 1968" startWordPosition="315" endWordPosition="318">velopment of the KIMMO system (Karttunen 1983) has witnessed a spectacular flurry of activity as the linguistic and computational consequences of this work have been fleshed out. A considerable body of literature has grown up around TWO-LEVEL MORPHOLOGY, along with texts&apos; and implementations.&apos; The existence of a rule compiler (Koskenniemi 1985) has made it possible for the linguist to work at a conveniently abstract level, and analyses of several languages now exemplify the approach. Today, two-level morphology encompasses much of traditional segmental generative phonology of the SPE variety (Chomsky and Halle 1968).3 Although further development and application of this model is set to continue for some time, there is now a clear need to integrate it more closely with computational * University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland, U.K. E-mail: {steven,marke}@cogsci.ed.ac.uk 1 (Antworth 1990; Ritchie, Russell, Black, and Pulman 1992; Sproat 1992) 2 (Bear 1986; Antworth 1990; Schiller and Steffens 1991; Pulman and Hepple 1993) 3 Two caveats are necessary here. SPE rules must be restricted so as not to apply to their own output (Johnson 1972) and there </context>
<context position="3644" citStr="Chomsky and Halle 1968" startWordPosition="539" endWordPosition="542">lume 20, Number 1 grammar frameworks on the one hand and modern nonlinear phonology on the other. The primary goal of this article is to show how the central tenets of autosegmental phonology translate into an implemented finite state model. The model is named ONE-LEVEL PHONOLOGY for two reasons. First, the model is monostratal, in that there is only one level of linguistic description. Second, the name is intended to contrast with models employing two levels (such as the FST model mentioned above) or three levels (Goldsmith 1991; Touretzky and Wheeler 1990), or an unbounded number of levels (Chomsky and Halle 1968). The one-level model represents the outgrowth of three independent strands of research: (i) the finitestate modeling of phonology, (ii) the declarative approach to phonology,&apos; and (iii) the automatic learning of phonological generalizations (Ellison 1992, 1993). The paper is organized as follows. Section 2 presents an overview of autosegmental phonology and the temporal semantics of Bird and Klein (1990). Then we define state-labeled automata (Section 3.1), show their equivalence to finite state automata (Section 3.2), define the operations of concatenation, union, intersection, and complemen</context>
<context position="6892" citStr="Chomsky and Halle 1968" startWordPosition="1058" endWordPosition="1061">an arbitrary number of autosegmental charts (Section 4.4), an evaluation of the encoding with respect to Kornai&apos;s desiderata (Section 4.5), and a presentation of the encoding of autosegmental rules (Section 4.6). Finally, Section 5 compares our proposals with those of Kay (1987), Kornai (1991), and Wiebe (1992). While our model has regular grammar power and is fully implemented, these three models go beyond regular grammar power and to our knowledge have never been implemented. 2. Background It has long been recognized that the SPE model lacks explanatory adequacy, a fact noted in SPE itself (Chomsky and Halle 1968, pp. 400ff). For example, it is unable to explain why a final devoicing rule like that in (2a) is commonplace in the languages of the world, whereas the rule in (2b) is unattested (Kaye 1989, p. 61). 2. (a) [—sonorant] —&gt; [—voice] / — # (b) [—sonorant] [+nasal] / — # (c) [] [anasal] / [anasal] — # (d) [1 [around] / [anasal] — # Similarly, the nasal harmony rule in (2c) occurs frequently, while the generalization expressed in (2d) is as unlikely as (2b). Both SPE and the two-level model are unable to express the fact that some rules are commonplace while others are highly unnatural. Perhaps th</context>
</contexts>
<marker>Chomsky, Halle, 1968</marker>
<rawString>Chomsky, N., and Halle, M. (1968). The Sound Pattern of English. Harper and Row.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G N Clements</author>
</authors>
<title>The geometry of phonological features.&amp;quot;</title>
<date>1985</date>
<journal>In Phonology Yearbook</journal>
<volume>2</volume>
<pages>225--252</pages>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="54765" citStr="Clements (1985)" startWordPosition="9449" endWordPosition="9450"> devices like G move the frame &apos;language&apos; away from what it is supposed to represent, namely autosegmental structures. No longer is gemination represented by association (perhaps derived by a spreading rule), but by a special marking on the skeleton. Second, the model builds in the assumption that each morpheme appears on a separate autosegmental tier. However, most applications of autosegmental phonology employ morphemes with phonological information arrayed on more than one tier (e.g., Clements and Ford 1979). Similarly, the modeling of subsegmental feature geometry of the kind advocated by Clements (1985) and others also involves a single morpheme having material on several tiers. Third, the model breaks down in the area of MORPHEMIC SEGREGATION. Since there is no principled upper bound on the number of morphemes that may be overlaid in the way McCarthy advocates for Arabic, there is similarly no principled upper bound on the number of tapes Kay&apos;s transducer would require. The assumption that each morpheme defines its own set of tiers, implicit in early work (McCarthy 1981) but explicit in more recent work (McCarthy 1989), is incompatible with a fixed upper bound on the number of tapes. Finall</context>
</contexts>
<marker>Clements, 1985</marker>
<rawString>Clements, G. N. (1985). &amp;quot;The geometry of phonological features.&amp;quot; In Phonology Yearbook 2, edited by C. Ewen and J. Anderson, 225-252. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G N Clements</author>
</authors>
<title>Place of articulation in consonants and vowels: a unified theory.&amp;quot;</title>
<date>1991</date>
<journal>In Working Papers of the Cornell Phonetics Laboratory, Number</journal>
<volume>5</volume>
<pages>77--123</pages>
<institution>Phonetics Laboratory, Cornell University.</institution>
<note>edited by</note>
<contexts>
<context position="67291" citStr="Clements (1991)" startWordPosition="11532" endWordPosition="11533">pecifying where these associations lead. The multi-linear code for (29) is displayed in (42). 20 Here the dots separating the triples have been omitted to enable more convenient location of association lines. 21 The encoding procedure would not terminate for Pulleyblank&apos;s example (18). This is because the first application of the encoding would take the three-tiered structure and produce another (more complicated) three-tiered structure. In fact, this is just a special case of a more general problem, for the encoding fails for any tier structure containing a cycle, such as the one proposed by Clements (1991). 84 Steven Bird and T. Mark Ellison One-Level Phonology 42. all C2V1C2C2V1C2 k2t22b2 Here, a numeral n following an autosegment A indicates that A has an association on chart n. These numerals can be stacked up; the first line specifies that a has two associations on chart 1. A given tier can participate in two charts; the second line of (42) has Cs associated on chart 2 and Vs associated on chart 1. Wiebe shows how the multi-linear code satisfies the criteria for computability, invertibility, iconicity, and compositionality. Wiebe&apos;s encoding has some similarities to our revised encoding pres</context>
</contexts>
<marker>Clements, 1991</marker>
<rawString>Clements, G. N. (1991). &amp;quot;Place of articulation in consonants and vowels: a unified theory.&amp;quot; In Working Papers of the Cornell Phonetics Laboratory, Number 5, edited by G. N. Clements and E. Hume, 77-123. Phonetics Laboratory, Cornell University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G N Clements</author>
<author>K C Ford</author>
</authors>
<title>Kikuyu tone shift and its synchronic consequences.&amp;quot;</title>
<date>1979</date>
<journal>Linguistic Inquiry,</journal>
<volume>10</volume>
<pages>179--210</pages>
<contexts>
<context position="54666" citStr="Clements and Ford 1979" startWordPosition="9433" endWordPosition="9436">blems concerns the appropriateness of Kay&apos;s model for nonlinear phonology more generally. First, notational devices like G move the frame &apos;language&apos; away from what it is supposed to represent, namely autosegmental structures. No longer is gemination represented by association (perhaps derived by a spreading rule), but by a special marking on the skeleton. Second, the model builds in the assumption that each morpheme appears on a separate autosegmental tier. However, most applications of autosegmental phonology employ morphemes with phonological information arrayed on more than one tier (e.g., Clements and Ford 1979). Similarly, the modeling of subsegmental feature geometry of the kind advocated by Clements (1985) and others also involves a single morpheme having material on several tiers. Third, the model breaks down in the area of MORPHEMIC SEGREGATION. Since there is no principled upper bound on the number of morphemes that may be overlaid in the way McCarthy advocates for Arabic, there is similarly no principled upper bound on the number of tapes Kay&apos;s transducer would require. The assumption that each morpheme defines its own set of tiers, implicit in early work (McCarthy 1981) but explicit in more r</context>
</contexts>
<marker>Clements, Ford, 1979</marker>
<rawString>Clements, G. N., and Ford, K. C. (1979). &amp;quot;Kikuyu tone shift and its synchronic consequences.&amp;quot; Linguistic Inquiry, 10, 179-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Coleman</author>
</authors>
<title>Phonological representations-their names, forms and powers. Doctoral dissertation,</title>
<date>1991</date>
<institution>University of York.</institution>
<contexts>
<context position="5697" citStr="Coleman 1991" startWordPosition="872" endWordPosition="873">re that each line of the expression represents a tier and the tiers are combined using the intersection operation (n). Moreover, the is act as synchronization marks between the operands of the intersection operation. (+hi, 0)* (+hi, 1) (+hi, 0)* (— hi, 0)* ( — hi, 1) (—hi, 0)* ( —hi, 1) (—hi, 0)* n (—rnd, 0)*(—rnd, 1) (—rnd, 0)* ( —rnd, 1) (—rnd, 0)* (+rnd, 0)* (+rnd, 1) (+rnd, 0)* The final step is to compute the intersection and project the first element of each tuple (ignoring the is and Os). This produces the expression: (+hi n —rnd)+ (—hi n —rnd)+ (—hi n +rnd)+ 4 Wheeler 1981; Bird 1990; Coleman 1991; Scobbie 1991; Broe 1993; Russell 1993; Mastroianni 1993. 56 Steven Bird and T. Mark Ellison One-Level Phonology Given plausible interpretations of the high and round features, this last expression simplifies to i±a+o+, which describes an automaton tape (or a string) divided into three nonempty intervals, the first containing [i], the second containing [a], and the third containing [o]. This, we shall claim, is the intended interpretation of (1). After a detailed discussion of this procedure, the remainder of Section 4 is given over to generalizing the procedure to an arbitrary number of auto</context>
</contexts>
<marker>Coleman, 1991</marker>
<rawString>Coleman, J. S. (1991). Phonological representations-their names, forms and powers. Doctoral dissertation, University of York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Coleman</author>
</authors>
<title>The phonetic interpretation of headed phonological structures containing overlapping constituents.&amp;quot;</title>
<date>1992</date>
<journal>Phonology,</journal>
<pages>9--1</pages>
<contexts>
<context position="77565" citStr="Coleman (1992)" startWordPosition="13216" endWordPosition="13217">me description. There is no finite-state transducer that will form the product of two regular expressions. Multilevel analyses necessarily seek to capture relationships between different descriptions, and like the product operation, these relationships often cannot be captured by finite-state transducers. 6. Conclusions The starting point of this paper was the distinction between descriptions and objects. Multidimensional phonological structures were taken to be descriptions of classes of phonetic objects, following Wheeler (1981), Bird and Klein (1990), Pierrehumbert (1990), Bird (1990), and Coleman (1992). Multiple tiers could be put together not by a clever encoding but by the simple operation of intersection, which corresponds to logical conjunction. Furthermore, this move of intensionalizing phonology enabled us to provide a straightforward formal basis for adding logical negation and disjunction to our representations. One important consequence of this work is that there are now good prospects for the incorporation of nonlinear phonology into constraint-based grammar formalisms such as HPSG (Pollard and Sag 1987). Such a move gives rise to a novel view of the relationship between phonology</context>
</contexts>
<marker>Coleman, 1992</marker>
<rawString>Coleman, J. S. (1992). &amp;quot;The phonetic interpretation of headed phonological structures containing overlapping constituents.&amp;quot; Phonology, 9,1-44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T M Ellison</author>
</authors>
<title>Discovering vowel harmony.&amp;quot;</title>
<date>1992</date>
<booktitle>In Background and Experiments in Machine Learning of Natural Language, edited by W. Daelemans</booktitle>
<pages>131--136</pages>
<publisher>ITK.</publisher>
<contexts>
<context position="3899" citStr="Ellison 1992" startWordPosition="576" endWordPosition="577">EVEL PHONOLOGY for two reasons. First, the model is monostratal, in that there is only one level of linguistic description. Second, the name is intended to contrast with models employing two levels (such as the FST model mentioned above) or three levels (Goldsmith 1991; Touretzky and Wheeler 1990), or an unbounded number of levels (Chomsky and Halle 1968). The one-level model represents the outgrowth of three independent strands of research: (i) the finitestate modeling of phonology, (ii) the declarative approach to phonology,&apos; and (iii) the automatic learning of phonological generalizations (Ellison 1992, 1993). The paper is organized as follows. Section 2 presents an overview of autosegmental phonology and the temporal semantics of Bird and Klein (1990). Then we define state-labeled automata (Section 3.1), show their equivalence to finite state automata (Section 3.2), define the operations of concatenation, union, intersection, and complement (Section 3.3), and further define state-labeled transducers (Section 3.4). The central proposals of the paper are contained in Section 4. We show how autosegmental association can be interpreted in terms of the synchronization of two automata, where eac</context>
<context position="69767" citStr="Ellison 1992" startWordPosition="11939" endWordPosition="11940">ucially required for processing autosegmental analyses with feature- or structure-modifying rules. The read heads can scan n-tuples separated by arbitrary distances, and each head reads one co-ordinate of the n-tuple under it. ... It is precisely this ability to scan different parts of an input word at the same time that is so important in modelling autosegmental rules. Association lines can associate segments in any part of one tier to segments in any part of the facing tier. In order for any computational 22 Wiebe borrows the terms SFA and SFT from an earlier version of this paper (Bird and Ellison 1992). 85 Computational Linguistics Volume 20, Number 1 device to efficiently process autosegmental representations, it must be able to scan two associated segments from widely separated parts of the representation at the same time (Wiebe 1992, pp. 95-96, emphasis added). While this is a reasonable statement regarding any model like Kornai&apos;s, it does not apply to our one-level model since the notion &apos;widely separated&apos; is meaningless in this context. Two terms in a multi-linear code are widely separated if they differ significantly as to their distance from the left- or right-hand end of the encodin</context>
</contexts>
<marker>Ellison, 1992</marker>
<rawString>Ellison, T. M. (1992). &amp;quot;Discovering vowel harmony.&amp;quot; In Background and Experiments in Machine Learning of Natural Language, edited by W. Daelemans and D. Powers, 131-136. ITK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T M Ellison</author>
</authors>
<title>The machine learning of phonological structure. Doctoral dissertation,</title>
<date>1993</date>
<institution>University of Western Australia.</institution>
<marker>Ellison, 1993</marker>
<rawString>Ellison, T. M. (1993). The machine learning of phonological structure. Doctoral dissertation, University of Western Australia.</rawString>
</citation>
<citation valid="false">
<authors>
<author>T M Ellison</author>
</authors>
<title>The iterative learning of phonological constraints.&amp;quot;</title>
<journal>Computational Linguistics.</journal>
<marker>Ellison, </marker>
<rawString>Ellison, T. M. (forthcoming). &amp;quot;The iterative learning of phonological constraints.&amp;quot; Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Goldsmith</author>
</authors>
<title>Autosegmental phonology. Doctoral dissertation,</title>
<date>1976</date>
<institution>Massachusetts Institute of Technology.</institution>
<contexts>
<context position="7696" citStr="Goldsmith 1976" startWordPosition="1200" endWordPosition="1201">89, p. 61). 2. (a) [—sonorant] —&gt; [—voice] / — # (b) [—sonorant] [+nasal] / — # (c) [] [anasal] / [anasal] — # (d) [1 [around] / [anasal] — # Similarly, the nasal harmony rule in (2c) occurs frequently, while the generalization expressed in (2d) is as unlikely as (2b). Both SPE and the two-level model are unable to express the fact that some rules are commonplace while others are highly unnatural. Perhaps the SPE model could be rescued from these problems with additional stipulations. However, a more fundamental problem for the model was raised by the following tone language data (Leben 1973; Goldsmith 1976). At first blush, Mende vowels appear to manifest five tone patterns, namely high (ko), low (kpa), falling (mbil), rising (mba) and rise-fall (mbS). The SPE model would predict 25 tonal patterns for two-syllable morphemes, but instead we find only 5. These are high-high, low-low, high-low, low-high, and low-falling. Similarly, for three-syllable morphemes we get 5 patterns, not 125. Leben noticed that the one-, two-, and three-syllable morphemes could be put into correspondence as shown in (3), from Leben (1978). 3. H: k6 war pElt house hawama waistline L: kpa debt bElE trousers kpakafi tripod</context>
<context position="9413" citStr="Goldsmith 1976" startWordPosition="1517" endWordPosition="1518">a ka 11 L L L mbil ngi la fe la ma 1 \ 1 1 I 1 / HL HL HL mba fa nde nda vil la I \ 1 I I 1 / LH LH LH mba‘ nya ha ni ki 11 / I \ 1 1 \ 1 1 1 LHL LHL LHL Observe that each row of the table has the same tone pattern. Only the synchronization varies. In diagrams like the ones in (4), units such as H and L are termed AUTONOMOUS SEGMENTS, or AUTOSEGMENTS, and a linear sequence of autosegments is called a TIER. The synchronization markers are called ASSOCIATION LINES. A pair of tiers linked by some association lines is called a CHART. A chart is called WELL-FORMED if the following conditions hold (Goldsmith 1976, p. 27). 5. Well-Formedness Condition: (a) All vowels are associated with at least one tone; all tones are associated with at least one vowel. (b) Association lines do not cross. The reader can ascertain that the above charts are well-formed according to (5). However, (5) is insufficiently restrictive on its own, and a further stipulation is required. 6. Association Convention: Only the rightmost member of a tier can be associated to more than one member of another tier. 58 Steven Bird and T. Mark Ellison One-Level Phonology When (5) and (6) are combined, we achieve the effect of one-to-one l</context>
<context position="57796" citStr="Goldsmith (1976)" startWordPosition="9955" endWordPosition="9956">nce the read heads on each tier; t : override the advance instruction on the bottom tier, i.e., only advance the read head on the top tier; and b : only advance the read head on the bottom tier; retain the same segment on the top tier. Each 0 or 1 is flanked by a statement of the current segments on the two tiers. A number flanked by two segments forms the TRIPLE that gives the code its name. Where this code could give a number of different representations of the same autosegmental structure, Kornai (1991) restricts the encoding to operating in the same manner as the association convention of Goldsmith (1976). Association, or the lack of association, is marked left-to-right in a one-to-one fashion until one tier is devoid of new autosegments. From that point, only one tier advances until all remaining autosegments are represented in the linearization. As examples, let us encode two charts, the first completely devoid of associations. To show the pairs of current autosegments through the steps of the encoding, we link them with dotted lines indexed by the count of the step in the derivation. ABCD 1 2 3 4 a b cde f The first four code steps give the following encoding (separating triples with full s</context>
<context position="66572" citStr="Goldsmith 1976" startWordPosition="11419" endWordPosition="11420">of tiers due to such considerations as complex feature geometry and morphemic segregation. 5.3 Wiebe (1992) Wiebe (1992) has recently devised an encoding of autosegmental diagrams that overcomes many of the problems of Kornai&apos;s triple code. It is called the MULTI-LINEAR CODE. Consider again diagram (29), reproduced below. 29. a perfective active CV CCV C causative / write This diagram contains two charts. The upper chart, which connects the vowel to two V slots will be referred to as chart 1, and the other chart as chart 2. Since there is a total ordering on the associations in a given chart (Goldsmith 1976, p. 29), it is sufficient to record how many associations each autosegment has on each chart, without specifying where these associations lead. The multi-linear code for (29) is displayed in (42). 20 Here the dots separating the triples have been omitted to enable more convenient location of association lines. 21 The encoding procedure would not terminate for Pulleyblank&apos;s example (18). This is because the first application of the encoding would take the three-tiered structure and produce another (more complicated) three-tiered structure. In fact, this is just a special case of a more general</context>
</contexts>
<marker>Goldsmith, 1976</marker>
<rawString>Goldsmith, J. A. (1976). Autosegmental phonology. Doctoral dissertation, Massachusetts Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goldsmith</author>
</authors>
<title>Accent systems.&amp;quot;</title>
<date>1982</date>
<booktitle>In The Structure of Phonological Representations, edited</booktitle>
<pages>47--63</pages>
<publisher>Foris.</publisher>
<contexts>
<context position="64015" citStr="Goldsmith (1982)" startWordPosition="10985" endWordPosition="10986">ed bound on the length of the derivation can be made, and the quantity of memory required is an increasing function of the length of the derivation. Consequently, the step from unassociated to associated form cannot be made by a single FST. This type of problem with manipulating coded representations is not limited to Arabic morphology. In fact, the problem arises whenever there is an autosegment that has a restricted set of &apos;landing sites&apos; (such as the consonants or the high vowels), a very common occurrence. Another example is that of accent systems: Kornai and Kalman (1988, p. 185), citing Goldsmith (1982), state the Basic Tone Melody Association rule for Ci-Ruri, a Bantu language of Tanzania, as follows: 40. Basic Tone Melody Association Rule: Associate the accented element of the Basic Tone Melody to the accented element of a word. In general, the accented element of a word may be an unbounded distance from the start and end of a word. Goldsmith (1982, p. 53) gives the following example: 41. na a kam ir* e I milked L H* L As before, performing the association using the triple code requires a multiplication in state information, which in the general case cannot be bounded. True, this example o</context>
</contexts>
<marker>Goldsmith, 1982</marker>
<rawString>Goldsmith, J. (1982). &amp;quot;Accent systems.&amp;quot; In The Structure of Phonological Representations, edited by H. van der Hulst and N. Smith, 47-63. Foris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goldsmith</author>
</authors>
<title>Phonology as an intelligent system.&amp;quot;</title>
<date>1991</date>
<booktitle>In Bridges Between Psychology and Linguistics, edited</booktitle>
<pages>247--267</pages>
<institution>Lawrence Erlbaum.</institution>
<contexts>
<context position="3556" citStr="Goldsmith 1991" startWordPosition="527" endWordPosition="528"> C) 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 1 grammar frameworks on the one hand and modern nonlinear phonology on the other. The primary goal of this article is to show how the central tenets of autosegmental phonology translate into an implemented finite state model. The model is named ONE-LEVEL PHONOLOGY for two reasons. First, the model is monostratal, in that there is only one level of linguistic description. Second, the name is intended to contrast with models employing two levels (such as the FST model mentioned above) or three levels (Goldsmith 1991; Touretzky and Wheeler 1990), or an unbounded number of levels (Chomsky and Halle 1968). The one-level model represents the outgrowth of three independent strands of research: (i) the finitestate modeling of phonology, (ii) the declarative approach to phonology,&apos; and (iii) the automatic learning of phonological generalizations (Ellison 1992, 1993). The paper is organized as follows. Section 2 presents an overview of autosegmental phonology and the temporal semantics of Bird and Klein (1990). Then we define state-labeled automata (Section 3.1), show their equivalence to finite state automata (</context>
</contexts>
<marker>Goldsmith, 1991</marker>
<rawString>Goldsmith, J. (1991). &amp;quot;Phonology as an intelligent system.&amp;quot; In Bridges Between Psychology and Linguistics, edited by D. J. Napoli and J. Kegl, 247-267. Lawrence Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hoperoft</author>
<author>J D Ullman</author>
</authors>
<title>Introduction to Automata Theory, Languages and Computation.</title>
<date>1979</date>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="15718" citStr="Hoperoft and Ullman (1979)" startWordPosition="2625" endWordPosition="2628">(FSAs) follows from the equivalence of Mealy and Moore machines.&apos; Although SFAs are no more expressive than FSAs, there are good linguistic reasons for wishing to use them. The primary difference between the two devices lies in the relative ease with which particular generalizations can be expressed. As an illustration, we shall consider the automaton that prohibits two adjacent occurrences of any given symbol in a string, a constraint known in autosegmental phonology as the Obligatory Contour Principle. Here is the FSA version, using the graphical conventions for representing FSAs adopted by Hoperoft and Ullman (1979). Bullet marks a state, circled states are final, and states with incoming arrow heads are initial. a The notation we use for state-labeled automata is different. Because states carry labels, there is no need to use the contentless bullet symbol to mark a state. Instead, the label itself marks the state. Initial and final states are indicated by arrowheads and circles, as for FSAs. Arcs are unlabeled. The SFA that does not admit adjacent occurrences of any symbol in the alphabet is: Notice that the number of labels required by the SFA is considerably smaller (5 labels) than the number required</context>
<context position="16953" citStr="Hoperoft and Ullman (1979" startWordPosition="2843" endWordPosition="2846">A (12 labels), while the number of transitions is the same for both. On the other hand, the SFA has an extra state, labelled with 0 to show that the automaton accepts the null string (see the final clause of Definition 1). The difference between the two devices becomes even clearer when we consider the representations for a* (zero or more as) and a+ (one or more as). First, here are a* and a+ expressed as FSAs. a+ : • Observe that the specification of the Kleene star requires one state, while Kleene plus requires two. If we use SFAs instead, we find the reverse: Kleene star requires two 6 See Hoperoft and Ullman (1979, p. 44) for a discussion of this equivalence. An FSA is a Mealy machine that ignores its input, while an SFA is a Moore machine that ignores its input. 61 Computational Linguistics Volume 20, Number 1 states, while Kleene plus only requires one. I a* &apos; CDI CIAs we shall see in Section 4, the semantics of phonological representations requires frequent use of the Kleene plus and little use of the Kleene star. The intuition behind this is simple. Recall from Section 2 that phonological entities such as distinctive features are considered to be descriptions of phonetic events that may extend over</context>
<context position="22564" citStr="Hoperoft and Ullman 1979" startWordPosition="3866" endWordPosition="3869">: B: ›- 1 &apos;2 \ \ i S So Two states are compatible if and only if their label sets have a nonempty intersection. The intersection of these automata is formed by taking all pairs of states that are compatible and linking these with arcs whenever both projections of the pairs are linked. The intersection of the above automata is shown below. AI-1B: &gt; 1 --›- 2 \ 3 This automaton recognizes the language (123)+. _ The complement of an automaton A, written A, accepts a string s iff A rejects s. One way of forming the complement involves the following steps. First, the automaton must be DETERMINIZED (Hoperoft and Ullman 1979, pp. 22ff). The next step is to form the COMPLETION. A complete automaton is one that has a transition from every state for each element of E. The final step is to mark all final states nonfinal, and all nonfinal states final. So if S is the set of states and F is the set of final states, then S\F is the set of final states in the complement. 3.4 Transducers In the previous three sections, we defined state-labeled automata and some operations that can be used to combine them. We also saw that these automata are equivalent 64 Steven Bird and T. Mark Ellison One-Level Phonology to traditional, </context>
</contexts>
<marker>Hoperoft, Ullman, 1979</marker>
<rawString>Hoperoft, J., and Ullman, J. D. (1979). Introduction to Automata Theory, Languages and Computation. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Johnson</author>
</authors>
<title>Formal Aspects of Phonological Description.</title>
<date>1972</date>
<publisher>Mouton.</publisher>
<contexts>
<context position="2808" citStr="Johnson 1972" startWordPosition="409" endWordPosition="410">(Chomsky and Halle 1968).3 Although further development and application of this model is set to continue for some time, there is now a clear need to integrate it more closely with computational * University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland, U.K. E-mail: {steven,marke}@cogsci.ed.ac.uk 1 (Antworth 1990; Ritchie, Russell, Black, and Pulman 1992; Sproat 1992) 2 (Bear 1986; Antworth 1990; Schiller and Steffens 1991; Pulman and Hepple 1993) 3 Two caveats are necessary here. SPE rules must be restricted so as not to apply to their own output (Johnson 1972) and there is no guarantee that the transducer encoding an SPE rule can be expressed using the two-level rule notation (Ritchie 1992). C) 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 1 grammar frameworks on the one hand and modern nonlinear phonology on the other. The primary goal of this article is to show how the central tenets of autosegmental phonology translate into an implemented finite state model. The model is named ONE-LEVEL PHONOLOGY for two reasons. First, the model is monostratal, in that there is only one level of linguistic descriptio</context>
</contexts>
<marker>Johnson, 1972</marker>
<rawString>Johnson, C. D. (1972). Formal Aspects of Phonological Description. Mouton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Karttunen</author>
</authors>
<title>KIMMO: A general morphological processor.&amp;quot; Texas Linguistic Forum,</title>
<date>1983</date>
<pages>22--163</pages>
<contexts>
<context position="1642" citStr="Karttunen 1983" startWordPosition="230" endWordPosition="231">rule can also be represented as an automaton, albeit a less restrictive automaton than would be required for a lexical representation. The model is then compared with the transducer models for autosegmental phonology of Kay (1987), Kornai (1991), and Wiebe (1992). We conclude that the declarative approach to phonology presents an attractive way of extending finite-state techniques to autosegmental phonology while remaining within the confines of regular grammar. 1. Introduction The decade since the publication of Koskenniemi&apos;s dissertation (1983) and since the development of the KIMMO system (Karttunen 1983) has witnessed a spectacular flurry of activity as the linguistic and computational consequences of this work have been fleshed out. A considerable body of literature has grown up around TWO-LEVEL MORPHOLOGY, along with texts&apos; and implementations.&apos; The existence of a rule compiler (Koskenniemi 1985) has made it possible for the linguist to work at a conveniently abstract level, and analyses of several languages now exemplify the approach. Today, two-level morphology encompasses much of traditional segmental generative phonology of the SPE variety (Chomsky and Halle 1968).3 Although further dev</context>
</contexts>
<marker>Karttunen, 1983</marker>
<rawString>Karttunen, L. (1983). &amp;quot;KIMMO: A general morphological processor.&amp;quot; Texas Linguistic Forum, 22,163-186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>Nonconcatenative finite-state morphology.&amp;quot;</title>
<date>1987</date>
<booktitle>In Proceedings, Third Meeting of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>2--10</pages>
<contexts>
<context position="1257" citStr="Kay (1987)" startWordPosition="177" endWordPosition="178">Logical operations on the phonological domain—such as conjunction, disjunction, and negation—make sense since the phonological domain consists of descriptions rather than objects. These operations as applied to automata are the straightforward operations of intersection, union, and complement. If the arrow in a rewrite rule is viewed as logical implication, then a phonological rule can also be represented as an automaton, albeit a less restrictive automaton than would be required for a lexical representation. The model is then compared with the transducer models for autosegmental phonology of Kay (1987), Kornai (1991), and Wiebe (1992). We conclude that the declarative approach to phonology presents an attractive way of extending finite-state techniques to autosegmental phonology while remaining within the confines of regular grammar. 1. Introduction The decade since the publication of Koskenniemi&apos;s dissertation (1983) and since the development of the KIMMO system (Karttunen 1983) has witnessed a spectacular flurry of activity as the linguistic and computational consequences of this work have been fleshed out. A considerable body of literature has grown up around TWO-LEVEL MORPHOLOGY, along </context>
<context position="6549" citStr="Kay (1987)" startWordPosition="1003" endWordPosition="1004">tomaton tape (or a string) divided into three nonempty intervals, the first containing [i], the second containing [a], and the third containing [o]. This, we shall claim, is the intended interpretation of (1). After a detailed discussion of this procedure, the remainder of Section 4 is given over to generalizing the procedure to an arbitrary number of autosegmental charts (Section 4.4), an evaluation of the encoding with respect to Kornai&apos;s desiderata (Section 4.5), and a presentation of the encoding of autosegmental rules (Section 4.6). Finally, Section 5 compares our proposals with those of Kay (1987), Kornai (1991), and Wiebe (1992). While our model has regular grammar power and is fully implemented, these three models go beyond regular grammar power and to our knowledge have never been implemented. 2. Background It has long been recognized that the SPE model lacks explanatory adequacy, a fact noted in SPE itself (Chomsky and Halle 1968, pp. 400ff). For example, it is unable to explain why a final devoicing rule like that in (2a) is commonplace in the languages of the world, whereas the rule in (2b) is unattested (Kaye 1989, p. 61). 2. (a) [—sonorant] —&gt; [—voice] / — # (b) [—sonorant] [+n</context>
<context position="48533" citStr="Kay (1987)" startWordPosition="8319" endWordPosition="8320">letion of autosegments or association lines must be approached in a completely different way. Rather than deleting an element in a particular context, we set up an alternation with zero, following Bloomfield (1926). See Bird and Klein (in press) and Bird (in press) for detailed examples of this approach to deletion. This concludes our discussion of the automaton-based semantics for autosegmental representations and rules. In the next section we review some other attempts to treat autosegmental phonology using finite-state techniques. 5. Other Finite-State Approaches to Nonlinear Phonology 5.1 Kay (1987) The earliest treatment of autosegmental phonology in a finite-state setting is attributable to Kay (1987). It is tailored to the framework of nonconcatenative morphology developed by McCarthy (1981) in which consonants and vowels are segregated onto different tiers, as shown for the Arabic verb stem kattab in (29). 16 Applied to a destructive autosegmental rule, the interpretation determines the restriction imposed on surface forms by the rule, were it the last rule in a derivation. 76 Steven Bird and T. Mark Ellison One-Level Phonology 29. a perfective active CVCCVC causative write This verb</context>
</contexts>
<marker>Kay, 1987</marker>
<rawString>Kay, M. (1987). &amp;quot;Nonconcatenative finite-state morphology.&amp;quot; In Proceedings, Third Meeting of the European Chapter of the Association for Computational Linguistics, 2-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kaye</author>
</authors>
<title>Phonology: A Cognitive View.</title>
<date>1989</date>
<publisher>Erlbaum.</publisher>
<contexts>
<context position="7083" citStr="Kaye 1989" startWordPosition="1095" endWordPosition="1096">on 4.6). Finally, Section 5 compares our proposals with those of Kay (1987), Kornai (1991), and Wiebe (1992). While our model has regular grammar power and is fully implemented, these three models go beyond regular grammar power and to our knowledge have never been implemented. 2. Background It has long been recognized that the SPE model lacks explanatory adequacy, a fact noted in SPE itself (Chomsky and Halle 1968, pp. 400ff). For example, it is unable to explain why a final devoicing rule like that in (2a) is commonplace in the languages of the world, whereas the rule in (2b) is unattested (Kaye 1989, p. 61). 2. (a) [—sonorant] —&gt; [—voice] / — # (b) [—sonorant] [+nasal] / — # (c) [] [anasal] / [anasal] — # (d) [1 [around] / [anasal] — # Similarly, the nasal harmony rule in (2c) occurs frequently, while the generalization expressed in (2d) is as unlikely as (2b). Both SPE and the two-level model are unable to express the fact that some rules are commonplace while others are highly unnatural. Perhaps the SPE model could be rescued from these problems with additional stipulations. However, a more fundamental problem for the model was raised by the following tone language data (Leben 1973; Go</context>
</contexts>
<marker>Kaye, 1989</marker>
<rawString>Kaye, J. (1989). Phonology: A Cognitive View. Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kornai</author>
</authors>
<title>Formal Phonology. Doctoral dissertation,</title>
<date>1991</date>
<institution>Stanford University.</institution>
<contexts>
<context position="1272" citStr="Kornai (1991)" startWordPosition="179" endWordPosition="180">ations on the phonological domain—such as conjunction, disjunction, and negation—make sense since the phonological domain consists of descriptions rather than objects. These operations as applied to automata are the straightforward operations of intersection, union, and complement. If the arrow in a rewrite rule is viewed as logical implication, then a phonological rule can also be represented as an automaton, albeit a less restrictive automaton than would be required for a lexical representation. The model is then compared with the transducer models for autosegmental phonology of Kay (1987), Kornai (1991), and Wiebe (1992). We conclude that the declarative approach to phonology presents an attractive way of extending finite-state techniques to autosegmental phonology while remaining within the confines of regular grammar. 1. Introduction The decade since the publication of Koskenniemi&apos;s dissertation (1983) and since the development of the KIMMO system (Karttunen 1983) has witnessed a spectacular flurry of activity as the linguistic and computational consequences of this work have been fleshed out. A considerable body of literature has grown up around TWO-LEVEL MORPHOLOGY, along with texts&apos; and</context>
<context position="6564" citStr="Kornai (1991)" startWordPosition="1005" endWordPosition="1006"> (or a string) divided into three nonempty intervals, the first containing [i], the second containing [a], and the third containing [o]. This, we shall claim, is the intended interpretation of (1). After a detailed discussion of this procedure, the remainder of Section 4 is given over to generalizing the procedure to an arbitrary number of autosegmental charts (Section 4.4), an evaluation of the encoding with respect to Kornai&apos;s desiderata (Section 4.5), and a presentation of the encoding of autosegmental rules (Section 4.6). Finally, Section 5 compares our proposals with those of Kay (1987), Kornai (1991), and Wiebe (1992). While our model has regular grammar power and is fully implemented, these three models go beyond regular grammar power and to our knowledge have never been implemented. 2. Background It has long been recognized that the SPE model lacks explanatory adequacy, a fact noted in SPE itself (Chomsky and Halle 1968, pp. 400ff). For example, it is unable to explain why a final devoicing rule like that in (2a) is commonplace in the languages of the world, whereas the rule in (2b) is unattested (Kaye 1989, p. 61). 2. (a) [—sonorant] —&gt; [—voice] / — # (b) [—sonorant] [+nasal] / — # (c)</context>
<context position="38376" citStr="Kornai 1991" startWordPosition="6593" endWordPosition="6594"> the following: AB CC DDDD EEEF Recall that the encoding of the three-tier diagram (18) was given as expression (19). In such expressions it is difficult to identify tiers. Therefore, in the remainder of this paper we shall write expressions like (19) in the following format: 20. tier 1 A:1:0:0 B:0:0:1 C:1:0:0 tier 2 E:2:0:0 F:0:1:0 tier 3 D:0:1:1 In general, if D is a diagram, then E(D) is its encoding in the format exemplified in (20). 4.5 Evaluating the Encoding Now, we evaluate our encoding with respect to Kornai&apos;s desiderata: computability, compositionality, invertibility, and iconicity (Kornai 1991). Computability: The number of terms in the encoding is equal to the number of autosegments, and each term has a fixed size.&apos; Therefore, the encoding can be computed in linear time. Compositionality: If D1 and D2 are two autosegmental diagrams then E(DID2) = E(D1)E(D2), where concatenation of encodings is done in a tier-wise manner. Thus the encoding is compositional. Invertibility: A representation can be reconstructed from its encoding. Iconicity: If an autosegment in a diagram is changed, the effect on the encoding is local, since only one term is altered. However, if an association line is</context>
<context position="55721" citStr="Kornai (1991)" startWordPosition="9602" endWordPosition="9603"> Kay&apos;s transducer would require. The assumption that each morpheme defines its own set of tiers, implicit in early work (McCarthy 1981) but explicit in more recent work (McCarthy 1989), is incompatible with a fixed upper bound on the number of tapes. Finally, using Kay&apos;s model for recognition would lead to much nondeterminism in positing G symbols, brackets, and braces. For example, in processing kattab the lexical tapes kttb, CVCCVC, and aa could be generated. The model generates all possible violations of the Obligatory Contour Principle. 79 Computational Linguistics Volume 20, Number 1 5.2 Kornai (1991) Kornai (1991) has developed a linear encoding of autosegmental representations that allows the two-level transducer model to be applied to autosegmental phonology We shall present Kornai&apos;s central innovation and describe a few of its strengths and weaknesses. As we saw in Section 4.5, Kornai presents four criteria under which an autosegmental encoding should be judged. An encoding should be easily computable; ideally by finite automata. It should also be invertible. An encoding should be iconic; minimally changing the input should minimally change the output. Finally, it should be composition</context>
<context position="57691" citStr="Kornai (1991)" startWordPosition="9939" endWordPosition="9940">ead head on each tier; 1 : draw an association line between the current segments on each tier and advance the read heads on each tier; t : override the advance instruction on the bottom tier, i.e., only advance the read head on the top tier; and b : only advance the read head on the bottom tier; retain the same segment on the top tier. Each 0 or 1 is flanked by a statement of the current segments on the two tiers. A number flanked by two segments forms the TRIPLE that gives the code its name. Where this code could give a number of different representations of the same autosegmental structure, Kornai (1991) restricts the encoding to operating in the same manner as the association convention of Goldsmith (1976). Association, or the lack of association, is marked left-to-right in a one-to-one fashion until one tier is devoid of new autosegments. From that point, only one tier advances until all remaining autosegments are represented in the linearization. As examples, let us encode two charts, the first completely devoid of associations. To show the pairs of current autosegments through the steps of the encoding, we link them with dotted lines indexed by the count of the step in the derivation. ABC</context>
<context position="62028" citStr="Kornai (1991)" startWordPosition="10657" endWordPosition="10658"> able to store k, t, and b, which in an alphabet of about 28 consonants involves at least log2(283) 15 extra bits of information in each state, compared to an otherwise equivalent transducer. Suppose now that we wish to apply the wellformedness condition (5), the association convention (6), and some other rules to (38) to achieve the pattern of association between the two tiers given in (29), repeated below. We are not interested here in the detail of how a transducer might perform this operation, only whether a transducer can perform it. 39. C V CC V C 18 As far as we have been able to find, Kornai (1991) does not discuss how to code a representation that contains an empty tier. Here, we have filled empty tiers with a &apos;place holder&apos; segment, and then used the triple code. 82 Steven Bird and T. Mark Ellison One-Level Phonology The encoding of (39) is C1k.V0t.t.C1t.t.C1t.V0b.t.C1b. Observe that the t is met in the second triple of the right-hand side of (38) and it must be &apos;stored&apos; until the fourth triple in the output. In a form like tadaktraj, two consonants must be stored in this way, leading again to an explosion of state information.&apos; If the template consisted of n CV syllables, and the con</context>
<context position="65150" citStr="Kornai (1991" startWordPosition="11180" endWordPosition="11181">nformation, which in the general case cannot be bounded. True, this example only requires the automaton to store H; but Goldsmith (1982, p. 55) gives examples where there are two stresses in the word, and, therefore, the association automaton needs to store more tones (see Wiebe 1992, pp. 109-110 for the details). Next, consider the problem of generalizing from one chart to an arbitrary number 19 Wiebe (1992, p. 112) points out that the final consonant does not need to be stored, as it is already associated with the final C position. 83 Computational Linguistics Volume 20, Number 1 of charts. Kornai (1991, p. 70) gives the following example: def / g h i / k 1 Each chart is encoded as a string and then these two strings are linked by association lines. Each line indicates that the segments it connects are actually the same segment (in the original diagram). Here is the first step of the encoding of the above diagram:2° dlgtelgfOhbfli \/ / /\ gljthlki0kbila Next, this encoding can itself be encoded into a string 77 characters long. Kornai himself admits (p. 72) that his encoding is impractical for autosegmental structures having more than two charts.&apos; Kornai discusses another encoding, which inv</context>
<context position="75541" citStr="Kornai (1991)" startWordPosition="12909" endWordPosition="12910">ns of roots and forms shown in (47) gives the following forms. 49. II f:1 a:0 :1 a:0 1:1 ✓ t:1 a:0 f:1 a:0 :1 Si a:0 1:1 XII f:1 . a:0 w:0 :1 a:0 1:1 This brief analysis shows the ease with which a computable analysis of nonconcatenative morphology can be constructed in the SFA formalism. While it may not cover all possible generalizations about Arabic verbal structure, the important point here is that it captures generalizations that are always surface-true of the phonology of the separate morphemes that come together to build up the verb. 5.5 Automata versus Linearizations We have seen that Kornai (1991) finds it necessary to choose between the imposition of restrictions on autosegmental phonology and the loss of finite stateness in the transduction relationship. As it turns out, the one-level approach does not suffer from this problem. In this section we explain why. 87 Computational Linguistics Volume 20, Number 1 Note that the natural processes by which finite-state automata are combined, and therefore by which regular languages are manipulated, are not themselves regular. To see why this is so, suppose we have two regular expressions describing the first form and the root of the Arabic ve</context>
</contexts>
<marker>Kornai, 1991</marker>
<rawString>Kornai, A. (1991). Formal Phonology. Doctoral dissertation, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kornai</author>
<author>L Kalman</author>
</authors>
<title>Hungarian sentence intonation.&amp;quot;</title>
<date>1988</date>
<booktitle>In Autosegmental Studies on Pitch Accent, edited by H. van der Hu1st</booktitle>
<pages>183--195</pages>
<publisher>Foris.</publisher>
<contexts>
<context position="63981" citStr="Kornai and Kalman (1988" startWordPosition="10978" endWordPosition="10981"> finite-state transducer. But no principled bound on the length of the derivation can be made, and the quantity of memory required is an increasing function of the length of the derivation. Consequently, the step from unassociated to associated form cannot be made by a single FST. This type of problem with manipulating coded representations is not limited to Arabic morphology. In fact, the problem arises whenever there is an autosegment that has a restricted set of &apos;landing sites&apos; (such as the consonants or the high vowels), a very common occurrence. Another example is that of accent systems: Kornai and Kalman (1988, p. 185), citing Goldsmith (1982), state the Basic Tone Melody Association rule for Ci-Ruri, a Bantu language of Tanzania, as follows: 40. Basic Tone Melody Association Rule: Associate the accented element of the Basic Tone Melody to the accented element of a word. In general, the accented element of a word may be an unbounded distance from the start and end of a word. Goldsmith (1982, p. 53) gives the following example: 41. na a kam ir* e I milked L H* L As before, performing the association using the triple code requires a multiplication in state information, which in the general case canno</context>
</contexts>
<marker>Kornai, Kalman, 1988</marker>
<rawString>Kornai, A., and Kalman, L. (1988). &amp;quot;Hungarian sentence intonation.&amp;quot; In Autosegmental Studies on Pitch Accent, edited by H. van der Hu1st and N. Smith, 183-195. Foris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Koskenniemi</author>
</authors>
<title>Two-level morphology: A general computational model for word-form recognition and production. Doctoral dissertation,</title>
<date>1983</date>
<institution>University of Helsinki.</institution>
<marker>Koskenniemi, 1983</marker>
<rawString>Koskenniemi, K. (1983). Two-level morphology: A general computational model for word-form recognition and production. Doctoral dissertation, University of Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Koskenniemi</author>
</authors>
<title>Compilation of automata from morphological two-level rules.&amp;quot;</title>
<date>1985</date>
<booktitle>In Papers from the Fifth Scandinavian Conference of Computational Linguistics,</booktitle>
<pages>143--149</pages>
<institution>University of Helsinki,</institution>
<contexts>
<context position="1942" citStr="Koskenniemi 1985" startWordPosition="275" endWordPosition="276">approach to phonology presents an attractive way of extending finite-state techniques to autosegmental phonology while remaining within the confines of regular grammar. 1. Introduction The decade since the publication of Koskenniemi&apos;s dissertation (1983) and since the development of the KIMMO system (Karttunen 1983) has witnessed a spectacular flurry of activity as the linguistic and computational consequences of this work have been fleshed out. A considerable body of literature has grown up around TWO-LEVEL MORPHOLOGY, along with texts&apos; and implementations.&apos; The existence of a rule compiler (Koskenniemi 1985) has made it possible for the linguist to work at a conveniently abstract level, and analyses of several languages now exemplify the approach. Today, two-level morphology encompasses much of traditional segmental generative phonology of the SPE variety (Chomsky and Halle 1968).3 Although further development and application of this model is set to continue for some time, there is now a clear need to integrate it more closely with computational * University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland, U.K. E-mail: {steven,marke}@cogsci.ed.ac.uk 1 (A</context>
</contexts>
<marker>Koskenniemi, 1985</marker>
<rawString>Koskenniemi, K. (1985). &amp;quot;Compilation of automata from morphological two-level rules.&amp;quot; In Papers from the Fifth Scandinavian Conference of Computational Linguistics, University of Helsinki, 143-149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W R Leben</author>
</authors>
<title>Suprasegmental phonology. Doctoral dissertation,</title>
<date>1973</date>
<institution>Massachusetts Institute of Technology.</institution>
<contexts>
<context position="7679" citStr="Leben 1973" startWordPosition="1198" endWordPosition="1199">ted (Kaye 1989, p. 61). 2. (a) [—sonorant] —&gt; [—voice] / — # (b) [—sonorant] [+nasal] / — # (c) [] [anasal] / [anasal] — # (d) [1 [around] / [anasal] — # Similarly, the nasal harmony rule in (2c) occurs frequently, while the generalization expressed in (2d) is as unlikely as (2b). Both SPE and the two-level model are unable to express the fact that some rules are commonplace while others are highly unnatural. Perhaps the SPE model could be rescued from these problems with additional stipulations. However, a more fundamental problem for the model was raised by the following tone language data (Leben 1973; Goldsmith 1976). At first blush, Mende vowels appear to manifest five tone patterns, namely high (ko), low (kpa), falling (mbil), rising (mba) and rise-fall (mbS). The SPE model would predict 25 tonal patterns for two-syllable morphemes, but instead we find only 5. These are high-high, low-low, high-low, low-high, and low-falling. Similarly, for three-syllable morphemes we get 5 patterns, not 125. Leben noticed that the one-, two-, and three-syllable morphemes could be put into correspondence as shown in (3), from Leben (1978). 3. H: k6 war pElt house hawama waistline L: kpa debt bElE trouse</context>
<context position="10295" citStr="Leben (1973)" startWordPosition="1661" endWordPosition="1662">(5) is insufficiently restrictive on its own, and a further stipulation is required. 6. Association Convention: Only the rightmost member of a tier can be associated to more than one member of another tier. 58 Steven Bird and T. Mark Ellison One-Level Phonology When (5) and (6) are combined, we achieve the effect of one-to-one left-to-right association, where multiple association (or SPREADING) occurs only at the right-hand end. Observe also that the charts in (4) do not contain adjacent identical tones. For example, there is no HH tone melody. This is expressed by a principle attributable to Leben (1973). 7. Obligatory Contour Principle: At the melodic level of the grammar, any two adjacent [autosegments] must be distinct. Thus HHL is not a possible melodic pattern; it automatically simplifies to HL. Although nonlinear models like autosegmental phonology represent a major advance on the linear model of SPE in the area of explanatory adequacy, it has sometimes been pointed out (e.g., Bird and Ladd 1991) that the formal explicitness of the SPE model has not been matched by these more recent proposals. Before we can begin to compute with autosegmental representations and rules, they need to be g</context>
</contexts>
<marker>Leben, 1973</marker>
<rawString>Leben, W. R. (1973). Suprasegmental phonology. Doctoral dissertation, Massachusetts Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W R Leben</author>
</authors>
<title>The representation of tone.&amp;quot;</title>
<date>1978</date>
<journal>In Tone-A Linguistic Survey, edited by V. A. Fromkin,</journal>
<pages>177--219</pages>
<publisher>Academic Press.</publisher>
<contexts>
<context position="8213" citStr="Leben (1978)" startWordPosition="1279" endWordPosition="1280">oblem for the model was raised by the following tone language data (Leben 1973; Goldsmith 1976). At first blush, Mende vowels appear to manifest five tone patterns, namely high (ko), low (kpa), falling (mbil), rising (mba) and rise-fall (mbS). The SPE model would predict 25 tonal patterns for two-syllable morphemes, but instead we find only 5. These are high-high, low-low, high-low, low-high, and low-falling. Similarly, for three-syllable morphemes we get 5 patterns, not 125. Leben noticed that the one-, two-, and three-syllable morphemes could be put into correspondence as shown in (3), from Leben (1978). 3. H: k6 war pElt house hawama waistline L: kpa debt bElE trousers kpakafi tripod chair HL: mbil owl nglla dog felama junction LH: mba rice fande cotton ndavtila sling LHL: mba&apos; companion nyaha woman nikill groundnut Goldsmith (1976) devised a graphical notation that made the above correspondence clearer still. We display several examples of his notation in (4). Here, the H indicates high tone, while L indicates low tone. (The association lines are assumed to be incident with the vowels.) 57 Computational Linguistics Volume 20, Number 1 4. k6 pt V ha Aga ma 1/ H H H kpa bt V kpa ka 11 L L L </context>
</contexts>
<marker>Leben, 1978</marker>
<rawString>Leben, W. R. (1978). &amp;quot;The representation of tone.&amp;quot; In Tone-A Linguistic Survey, edited by V. A. Fromkin, 177-219. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mastroianni</author>
</authors>
<title>Attribute logic phonology.&amp;quot;</title>
<date>1993</date>
<tech>Technical Report CMU-LCL 93-4,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="5754" citStr="Mastroianni 1993" startWordPosition="880" endWordPosition="881"> and the tiers are combined using the intersection operation (n). Moreover, the is act as synchronization marks between the operands of the intersection operation. (+hi, 0)* (+hi, 1) (+hi, 0)* (— hi, 0)* ( — hi, 1) (—hi, 0)* ( —hi, 1) (—hi, 0)* n (—rnd, 0)*(—rnd, 1) (—rnd, 0)* ( —rnd, 1) (—rnd, 0)* (+rnd, 0)* (+rnd, 1) (+rnd, 0)* The final step is to compute the intersection and project the first element of each tuple (ignoring the is and Os). This produces the expression: (+hi n —rnd)+ (—hi n —rnd)+ (—hi n +rnd)+ 4 Wheeler 1981; Bird 1990; Coleman 1991; Scobbie 1991; Broe 1993; Russell 1993; Mastroianni 1993. 56 Steven Bird and T. Mark Ellison One-Level Phonology Given plausible interpretations of the high and round features, this last expression simplifies to i±a+o+, which describes an automaton tape (or a string) divided into three nonempty intervals, the first containing [i], the second containing [a], and the third containing [o]. This, we shall claim, is the intended interpretation of (1). After a detailed discussion of this procedure, the remainder of Section 4 is given over to generalizing the procedure to an arbitrary number of autosegmental charts (Section 4.4), an evaluation of the enco</context>
</contexts>
<marker>Mastroianni, 1993</marker>
<rawString>Mastroianni, M. (1993). &amp;quot;Attribute logic phonology.&amp;quot; Technical Report CMU-LCL 93-4, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J McCarthy</author>
</authors>
<title>A prosodic theory of non-concatenative morphology.&amp;quot;</title>
<date>1981</date>
<journal>Linguistic Inquiry,</journal>
<volume>12</volume>
<pages>373--418</pages>
<contexts>
<context position="48732" citStr="McCarthy (1981)" startWordPosition="8348" endWordPosition="8349">ng Bloomfield (1926). See Bird and Klein (in press) and Bird (in press) for detailed examples of this approach to deletion. This concludes our discussion of the automaton-based semantics for autosegmental representations and rules. In the next section we review some other attempts to treat autosegmental phonology using finite-state techniques. 5. Other Finite-State Approaches to Nonlinear Phonology 5.1 Kay (1987) The earliest treatment of autosegmental phonology in a finite-state setting is attributable to Kay (1987). It is tailored to the framework of nonconcatenative morphology developed by McCarthy (1981) in which consonants and vowels are segregated onto different tiers, as shown for the Arabic verb stem kattab in (29). 16 Applied to a destructive autosegmental rule, the interpretation determines the restriction imposed on surface forms by the rule, were it the last rule in a derivation. 76 Steven Bird and T. Mark Ellison One-Level Phonology 29. a perfective active CVCCVC causative write This verb stem contains three morphemes. Together, they mean &apos;caused to write.&apos; The challenge posed by Arabic morphology is to come up with a simple account of the interleaving of the morphemes, relating the </context>
<context position="55243" citStr="McCarthy 1981" startWordPosition="9528" endWordPosition="9529">e tier (e.g., Clements and Ford 1979). Similarly, the modeling of subsegmental feature geometry of the kind advocated by Clements (1985) and others also involves a single morpheme having material on several tiers. Third, the model breaks down in the area of MORPHEMIC SEGREGATION. Since there is no principled upper bound on the number of morphemes that may be overlaid in the way McCarthy advocates for Arabic, there is similarly no principled upper bound on the number of tapes Kay&apos;s transducer would require. The assumption that each morpheme defines its own set of tiers, implicit in early work (McCarthy 1981) but explicit in more recent work (McCarthy 1989), is incompatible with a fixed upper bound on the number of tapes. Finally, using Kay&apos;s model for recognition would lead to much nondeterminism in positing G symbols, brackets, and braces. For example, in processing kattab the lexical tapes kttb, CVCCVC, and aa could be generated. The model generates all possible violations of the Obligatory Contour Principle. 79 Computational Linguistics Volume 20, Number 1 5.2 Kornai (1991) Kornai (1991) has developed a linear encoding of autosegmental representations that allows the two-level transducer model</context>
<context position="71614" citStr="McCarthy (1981)" startWordPosition="12234" endWordPosition="12235">me details of other finite-state approaches to autosegmental phonology, we present a one-level analysis of an aspect of Arabic verb morphology. 5.4 A One-Level Analysis As an alternative to either the elaboration of the transducer or the reduction of the nonlinear representation to a code, we present a partial analysis of the Arabic verb in terms of SFAs.&apos; Rather than trying to generate one representation from another, we construct a description of the individual Arabic word by taking the intersection of the SFAs describing each of the morphemes. The forms we analyze here, like those given in McCarthy (1981), do not include inflections and also assume that the following suffix is consonant-initia0 We shall derive the stem kattab from three morphemes, specifying the form, the root, and the voice/mood. The form I SFA (44) generalizes over all verbs: it accepts/ generates all correct verbs of this form, as well as a number of nonsense verbs, and factors out information specific to the individual words. 44. C:1 V:0 C:1 V:0 C:1 The indices mark associations that will link this tier to the root. Another tier is the consonantal tier. It contains heterogeneous autosegments corresponding to consonants. Th</context>
<context position="73474" citStr="McCarthy 1981" startWordPosition="12542" endWordPosition="12543">d to the work of Narayanan and Hashem (1993), Beesley, Buckwater, and Newton (1989), and Beesley (1990). These have not been discussed at length here, because they do not seek to implement autosegmental phonology. 24 Biliteral roots in forms I, III, IV, V. VI, VII, VIII, X, XI, XII, and XIV, triliteral roots in forms IX and XI, and quadriliteral roots in form QIV reorder the consonant-vowel sequence in the final syllable of the root if followed by a vowel-initial inflection. Where possible, the Arabic verb stem will metathesize or delete short vowels to create a geminate with root consonants (McCarthy 1981, pp. 1970. 86 Steven Bird and T. Mark Ellison One-Level Phonology 45. .:0* f:1 (.:0* 5:1)-* 1:1 The wildcards are necessary for affix consonants, such as the n- prefix of form VII or the -t- infix of form VIII. It might be argued that fixing the associations (by the indices) in the specification of the morpheme is redundant—that the associations should be supplied by rule. However, 3 of the 15 triliteral forms of the Arabic verb, namely forms II, V and XII, violate the association convention, multiply associating central autosegments rather than peripheral ones. For these forms there seems li</context>
</contexts>
<marker>McCarthy, 1981</marker>
<rawString>McCarthy, J. (1981). &amp;quot;A prosodic theory of non-concatenative morphology.&amp;quot; Linguistic Inquiry, 12, 373-418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J McCarthy</author>
</authors>
<title>Linear order in phonological representation.&amp;quot;</title>
<date>1989</date>
<journal>Linguistic Inquiry,</journal>
<volume>20</volume>
<issue>1</issue>
<pages>71--99</pages>
<contexts>
<context position="55292" citStr="McCarthy 1989" startWordPosition="9536" endWordPosition="9537"> the modeling of subsegmental feature geometry of the kind advocated by Clements (1985) and others also involves a single morpheme having material on several tiers. Third, the model breaks down in the area of MORPHEMIC SEGREGATION. Since there is no principled upper bound on the number of morphemes that may be overlaid in the way McCarthy advocates for Arabic, there is similarly no principled upper bound on the number of tapes Kay&apos;s transducer would require. The assumption that each morpheme defines its own set of tiers, implicit in early work (McCarthy 1981) but explicit in more recent work (McCarthy 1989), is incompatible with a fixed upper bound on the number of tapes. Finally, using Kay&apos;s model for recognition would lead to much nondeterminism in positing G symbols, brackets, and braces. For example, in processing kattab the lexical tapes kttb, CVCCVC, and aa could be generated. The model generates all possible violations of the Obligatory Contour Principle. 79 Computational Linguistics Volume 20, Number 1 5.2 Kornai (1991) Kornai (1991) has developed a linear encoding of autosegmental representations that allows the two-level transducer model to be applied to autosegmental phonology We shal</context>
</contexts>
<marker>McCarthy, 1989</marker>
<rawString>McCarthy, J. (1989). &amp;quot;Linear order in phonological representation.&amp;quot; Linguistic Inquiry, 20(1), 71-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Narayanan</author>
<author>L Hashem</author>
</authors>
<title>On abstract finite-state morphology.&amp;quot;</title>
<date>1993</date>
<booktitle>In Proceedings, Sixth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>297--304</pages>
<contexts>
<context position="72905" citStr="Narayanan and Hashem (1993)" startWordPosition="12447" endWordPosition="12450">rresponding consonant, but also any of the vowels. So the f autosegment on the consonant-tier denotes any sequence of the segments f, a, i, or u. The two uses of f are disambiguated by reference to the tiers on which they occur. Under this definition, autosegments on the consonant tier can spread over vowels to the next consonantal position. The root SFA generalizes over all stems constructed from the same root. The encoding on the consonant tier describing the root fl, to do, appears in (45). 23 The reader interested in other finite-state models of Arabic phonology is directed to the work of Narayanan and Hashem (1993), Beesley, Buckwater, and Newton (1989), and Beesley (1990). These have not been discussed at length here, because they do not seek to implement autosegmental phonology. 24 Biliteral roots in forms I, III, IV, V. VI, VII, VIII, X, XI, XII, and XIV, triliteral roots in forms IX and XI, and quadriliteral roots in form QIV reorder the consonant-vowel sequence in the final syllable of the root if followed by a vowel-initial inflection. Where possible, the Arabic verb stem will metathesize or delete short vowels to create a geminate with root consonants (McCarthy 1981, pp. 1970. 86 Steven Bird and </context>
</contexts>
<marker>Narayanan, Hashem, 1993</marker>
<rawString>Narayanan, A., and Hashem, L. (1993). &amp;quot;On abstract finite-state morphology.&amp;quot; In Proceedings, Sixth Conference of the European Chapter of the Association for Computational Linguistics, 297-304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Partee</author>
<author>ter Meulen</author>
<author>A</author>
<author>R E Wall</author>
</authors>
<date>1990</date>
<booktitle>Mathematical Methods in Linguistics. Studies in Linguistics and Philosophy.</booktitle>
<publisher>Kluwer.</publisher>
<contexts>
<context position="13233" citStr="Partee et al. (1990)" startWordPosition="2155" endWordPosition="2158"> an SFA, we need to define COMPATIBILITY. Definition 2 We say that a state v is COMPATIBLE with an input a E E if (v, E A. At each step in the execution of an SFA, a subset of the states is active while the remainder are inactive. An SFA begins operation with those start states active that are compatible with the first symbol in the input string. If, at a certain step in processing, a subset T of states is active, then at the next step, the subset T&apos; of states reachable from T and compatible with the next input become active. This operation is formalized below, following the approach taken by Partee et al. (1990). First we define a SITUATION to be the processing status of an SFA. Definition 3 A SITUATION of an SFA, A, is a triple (x,T,y) where T C V is the set of currently active states, and x and y are the portions of the input string to the left and right of the reading head, respectively. As an SFA operates, it moves through a sequence of these situations. Now HA is defined as a successor relation on situations for an automaton A. Definition 4 Let (x, T,y) and (x&apos;, T&apos;,y&apos;) be two situations. Then (x, T,y) iff there is a a E E such that (i) y = ay&apos; and x&apos; = xcr, (ii) for each t&apos; E T&apos; there is atET su</context>
<context position="20015" citStr="Partee et al. 1990" startWordPosition="3356" endWordPosition="3359">D r operation automata languages concatenation union intersection complement Kleene plus Kleene star AB {al* E L(A) ,b E L(B)} A U B L(A) U L(B) Ans L(A) n L(B) A L(A) A+ L(A)+ A* L(A)* 62 Steven Bird and T. Mark Ellison One-Level Phonology The Kleene plus operation, which, when applied to a language L gives another L+, contains the concatenation of one or more strings from L. The Kleene star operation takes L to {A} U L+ and is written L*. Recall that the structure (E*; u, n, --,, 0, E*), containing languages over an alphabet E together with the standard set operations, is a Boolean algebra (Partee et al. 1990, p. 297ff). Similarly, if A is the set of SFAs, then (A; U, n , --,, I, T) is also a Boolean algebra, where 1 is the empty automaton (i.e., L(I) = 0) and T is the automaton that accepts E* (i.e., L(T) The concatenation of two SFAs A and B, written AB, has an arrow linking each final state of the first SFA to each initial state of the second. The states that are initial or final in AB depend on whether A or B accepts the empty string A, as specified in the following table. A B AB AB initials AB finals A 0 L(A) A 0 L(B) A 0 L(AB) A initials B finals A E L(A) A 0 L(B) A 0 L(AB) A &amp; B initials B </context>
</contexts>
<marker>Partee, Meulen, A, Wall, 1990</marker>
<rawString>Partee, B.; ter Meulen, A.; and Wall, R. E. (1990). Mathematical Methods in Linguistics. Studies in Linguistics and Philosophy. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pierrehumbert</author>
</authors>
<title>Phonological and phonetic representation.&amp;quot;</title>
<date>1990</date>
<journal>Journal of Phonetics,</journal>
<volume>18</volume>
<pages>375--394</pages>
<contexts>
<context position="77532" citStr="Pierrehumbert (1990)" startWordPosition="13211" endWordPosition="13212">hip between different formats of the same description. There is no finite-state transducer that will form the product of two regular expressions. Multilevel analyses necessarily seek to capture relationships between different descriptions, and like the product operation, these relationships often cannot be captured by finite-state transducers. 6. Conclusions The starting point of this paper was the distinction between descriptions and objects. Multidimensional phonological structures were taken to be descriptions of classes of phonetic objects, following Wheeler (1981), Bird and Klein (1990), Pierrehumbert (1990), Bird (1990), and Coleman (1992). Multiple tiers could be put together not by a clever encoding but by the simple operation of intersection, which corresponds to logical conjunction. Furthermore, this move of intensionalizing phonology enabled us to provide a straightforward formal basis for adding logical negation and disjunction to our representations. One important consequence of this work is that there are now good prospects for the incorporation of nonlinear phonology into constraint-based grammar formalisms such as HPSG (Pollard and Sag 1987). Such a move gives rise to a novel view of t</context>
</contexts>
<marker>Pierrehumbert, 1990</marker>
<rawString>Pierrehumbert, J. (1990). &amp;quot;Phonological and phonetic representation.&amp;quot; Journal of Phonetics, 18, 375-394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
<author>I Sag</author>
</authors>
<title>Information-Based Syntax and Semantics, Volume 13 of CSLI Lecture Notes. Stanford: Center for the Study of Language and Information.</title>
<date>1987</date>
<contexts>
<context position="24647" citStr="Pollard and Sag 1987" startWordPosition="4211" endWordPosition="4214">-level phonology and two-level phonology if SFAs and SFTs are formally identical. There is an important distinction to be drawn, however. First, most two-level models employ FSTs with epsilons, which are more powerful devices than FSAs. Second, in the one-level model, representations and rules are interpreted as automata. In contrast, the twolevel model employs strings for representations and automata for rules. Finally, in one-level phonology surface forms and generalizations about them are stated directly in a hierarchical lexicon akin to that of head-driven phrase structure grammar (HPSG) (Pollard and Sag 1987), rather than being mediated through a transducer (Bird and Klein, in press). 4. Association and Synchronization In this section we present the automaton-based semantics for autosegmental phonology. 4.1 The Representation of Autosegments and Tiers Recall that an autosegment denotes a possibly extended interval. In terms of automata, this means that an autosegment must allow multiple copies of its defining property. This is expressed as follows. cpu This state of affairs fits well with our intuitive understanding that a pair of adjacent intervals in which some property holds is indistinguishabl</context>
<context position="78087" citStr="Pollard and Sag 1987" startWordPosition="13290" endWordPosition="13293">lowing Wheeler (1981), Bird and Klein (1990), Pierrehumbert (1990), Bird (1990), and Coleman (1992). Multiple tiers could be put together not by a clever encoding but by the simple operation of intersection, which corresponds to logical conjunction. Furthermore, this move of intensionalizing phonology enabled us to provide a straightforward formal basis for adding logical negation and disjunction to our representations. One important consequence of this work is that there are now good prospects for the incorporation of nonlinear phonology into constraint-based grammar formalisms such as HPSG (Pollard and Sag 1987). Such a move gives rise to a novel view of the relationship between phonology and the other modules of grammar, as some initial investigation has already demonstrated (Bird 1992; Bird and Klein in press). Making surface generalizations the only goal of analysis makes the machine learning of analyses simpler (Ellison forthcoming). The automaton semantics for autosegmental representations and rules gives us a mechanical way of comparing the empirical claims made by a range of autosegmental and segmental accounts of natural language phenomena. Finally, to the extent that phonologists are becomin</context>
</contexts>
<marker>Pollard, Sag, 1987</marker>
<rawString>Pollard, C., and Sag, I. (1987). Information-Based Syntax and Semantics, Volume 13 of CSLI Lecture Notes. Stanford: Center for the Study of Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Pulleyblank</author>
</authors>
<date>1986</date>
<booktitle>Tone in Lexical Phonology. Studies in Natural Language and Linguistic Theory.</booktitle>
<location>Reidel.</location>
<contexts>
<context position="36147" citStr="Pulleyblank (1986" startWordPosition="6203" endWordPosition="6204"> not both). We have now seen an automaton-based interpretation of an autosegmental chart. Next we consider how the above regular expressions defined over ordered pairs can be generalized to representations consisting of more than one chart. 4.4 Multiple Charts It is straightforward to generalize the interpretation procedure for single charts to one for representations with an arbitrary number of charts. Recall that for one chart we needed to employ ordered pairs. In general, for n charts we must employ ordered n + 1-tuples. The construction will be demonstrated using a diagram attributable to Pulleyblank (1986, p. 13) involving three tiers and three charts.&apos; (0, 0, •, •)* ((•, 1, •, *) (., 0, •, e)*)n (0, •, 0, •)* (K., •, 1, •) (e, e, 0, o)*)n (41, •, •, 0)* ((e, •, •, 1) c.., •, 0)* )n 18. A B C E F Now, since there are three charts in (18) we must employ 4-tuples. We adopt the following abbreviatory conventions: s(a) =def (a,•,•,•)+ au (n) =def a23(n) =def a13(n) =def A:p:q:r =def s(A) n au(p) fl a23(q) 11 a13(r) We can now write down the expression for (18) as follows: 19. (A:1:0:0 B:0:0:1 C:1:0:0) n (E:2:0:0 F:0:1:0) ri D:0:1:1 The first three terms of this expression correspond to tier 1 of (</context>
</contexts>
<marker>Pulleyblank, 1986</marker>
<rawString>Pulleyblank, D. (1986). Tone in Lexical Phonology. Studies in Natural Language and Linguistic Theory. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S G Pulman</author>
<author>M R Hepple</author>
</authors>
<title>A feature-based formalism for two level phonology: a description and implementation.&amp;quot;</title>
<date>1993</date>
<journal>Computer Speech and Language,</journal>
<volume>7</volume>
<pages>333--358</pages>
<contexts>
<context position="2691" citStr="Pulman and Hepple 1993" startWordPosition="385" endWordPosition="388">fy the approach. Today, two-level morphology encompasses much of traditional segmental generative phonology of the SPE variety (Chomsky and Halle 1968).3 Although further development and application of this model is set to continue for some time, there is now a clear need to integrate it more closely with computational * University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland, U.K. E-mail: {steven,marke}@cogsci.ed.ac.uk 1 (Antworth 1990; Ritchie, Russell, Black, and Pulman 1992; Sproat 1992) 2 (Bear 1986; Antworth 1990; Schiller and Steffens 1991; Pulman and Hepple 1993) 3 Two caveats are necessary here. SPE rules must be restricted so as not to apply to their own output (Johnson 1972) and there is no guarantee that the transducer encoding an SPE rule can be expressed using the two-level rule notation (Ritchie 1992). C) 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 1 grammar frameworks on the one hand and modern nonlinear phonology on the other. The primary goal of this article is to show how the central tenets of autosegmental phonology translate into an implemented finite state model. The model is named ONE-LEVEL</context>
</contexts>
<marker>Pulman, Hepple, 1993</marker>
<rawString>Pulman, S. G., and Hepple, M. R. (1993). &amp;quot;A feature-based formalism for two level phonology: a description and implementation.&amp;quot; Computer Speech and Language, 7, 333-358.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G D Ritchie</author>
</authors>
<title>Languages generated by two-level morphological rules.&amp;quot;</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<issue>1</issue>
<pages>41--59</pages>
<contexts>
<context position="2941" citStr="Ritchie 1992" startWordPosition="431" endWordPosition="432">a clear need to integrate it more closely with computational * University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland, U.K. E-mail: {steven,marke}@cogsci.ed.ac.uk 1 (Antworth 1990; Ritchie, Russell, Black, and Pulman 1992; Sproat 1992) 2 (Bear 1986; Antworth 1990; Schiller and Steffens 1991; Pulman and Hepple 1993) 3 Two caveats are necessary here. SPE rules must be restricted so as not to apply to their own output (Johnson 1972) and there is no guarantee that the transducer encoding an SPE rule can be expressed using the two-level rule notation (Ritchie 1992). C) 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 1 grammar frameworks on the one hand and modern nonlinear phonology on the other. The primary goal of this article is to show how the central tenets of autosegmental phonology translate into an implemented finite state model. The model is named ONE-LEVEL PHONOLOGY for two reasons. First, the model is monostratal, in that there is only one level of linguistic description. Second, the name is intended to contrast with models employing two levels (such as the FST model mentioned above) or three levels </context>
</contexts>
<marker>Ritchie, 1992</marker>
<rawString>Ritchie, G. D. (1992). &amp;quot;Languages generated by two-level morphological rules.&amp;quot; Computational Linguistics, 18(1), 41-59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G D Ritchie</author>
<author>G J Russell</author>
<author>A W Black</author>
<author>S G Pulman</author>
</authors>
<title>Computational Morphology: Practical Mechanisms for the English Lexicon.</title>
<date>1992</date>
<publisher>MIT Press.</publisher>
<marker>Ritchie, Russell, Black, Pulman, 1992</marker>
<rawString>Ritchie, G. D.; Russell, G. J.; Black, A. W.; and Pulman, S. G. (1992). Computational Morphology: Practical Mechanisms for the English Lexicon. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Russell</author>
</authors>
<title>A constraint-based approach to phonology. Doctoral dissertation,</title>
<date>1993</date>
<institution>University of Southern California.</institution>
<contexts>
<context position="5736" citStr="Russell 1993" startWordPosition="878" endWordPosition="879">resents a tier and the tiers are combined using the intersection operation (n). Moreover, the is act as synchronization marks between the operands of the intersection operation. (+hi, 0)* (+hi, 1) (+hi, 0)* (— hi, 0)* ( — hi, 1) (—hi, 0)* ( —hi, 1) (—hi, 0)* n (—rnd, 0)*(—rnd, 1) (—rnd, 0)* ( —rnd, 1) (—rnd, 0)* (+rnd, 0)* (+rnd, 1) (+rnd, 0)* The final step is to compute the intersection and project the first element of each tuple (ignoring the is and Os). This produces the expression: (+hi n —rnd)+ (—hi n —rnd)+ (—hi n +rnd)+ 4 Wheeler 1981; Bird 1990; Coleman 1991; Scobbie 1991; Broe 1993; Russell 1993; Mastroianni 1993. 56 Steven Bird and T. Mark Ellison One-Level Phonology Given plausible interpretations of the high and round features, this last expression simplifies to i±a+o+, which describes an automaton tape (or a string) divided into three nonempty intervals, the first containing [i], the second containing [a], and the third containing [o]. This, we shall claim, is the intended interpretation of (1). After a detailed discussion of this procedure, the remainder of Section 4 is given over to generalizing the procedure to an arbitrary number of autosegmental charts (Section 4.4), an eval</context>
</contexts>
<marker>Russell, 1993</marker>
<rawString>Russell, K. (1993). A constraint-based approach to phonology. Doctoral dissertation, University of Southern California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Sagey</author>
</authors>
<title>On the ill-formedness of crossing association lines.&amp;quot;</title>
<date>1988</date>
<journal>Linguistic Inquiry,</journal>
<volume>19</volume>
<pages>109--118</pages>
<marker>Sagey, 1988</marker>
<rawString>Sagey, E. (1988). &amp;quot;On the ill-formedness of crossing association lines.&amp;quot; Linguistic Inquiry, 19, 109-118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Schiller</author>
<author>P Steffens</author>
</authors>
<title>Morphological processing in the two-level paradigm.&amp;quot;</title>
<date>1991</date>
<booktitle>In Text Understanding in LILOG, edited by 0. Herzog</booktitle>
<pages>112--126</pages>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="2666" citStr="Schiller and Steffens 1991" startWordPosition="381" endWordPosition="384">everal languages now exemplify the approach. Today, two-level morphology encompasses much of traditional segmental generative phonology of the SPE variety (Chomsky and Halle 1968).3 Although further development and application of this model is set to continue for some time, there is now a clear need to integrate it more closely with computational * University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland, U.K. E-mail: {steven,marke}@cogsci.ed.ac.uk 1 (Antworth 1990; Ritchie, Russell, Black, and Pulman 1992; Sproat 1992) 2 (Bear 1986; Antworth 1990; Schiller and Steffens 1991; Pulman and Hepple 1993) 3 Two caveats are necessary here. SPE rules must be restricted so as not to apply to their own output (Johnson 1972) and there is no guarantee that the transducer encoding an SPE rule can be expressed using the two-level rule notation (Ritchie 1992). C) 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 1 grammar frameworks on the one hand and modern nonlinear phonology on the other. The primary goal of this article is to show how the central tenets of autosegmental phonology translate into an implemented finite state model. The</context>
</contexts>
<marker>Schiller, Steffens, 1991</marker>
<rawString>Schiller, A., and Steffens, P. (1991). &amp;quot;Morphological processing in the two-level paradigm.&amp;quot; In Text Understanding in LILOG, edited by 0. Herzog and C.-R. Rollinger, 112-126. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Scobbie</author>
</authors>
<title>Attribute-value phonology. Doctoral dissertation,</title>
<date>1991</date>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="5711" citStr="Scobbie 1991" startWordPosition="874" endWordPosition="875">ine of the expression represents a tier and the tiers are combined using the intersection operation (n). Moreover, the is act as synchronization marks between the operands of the intersection operation. (+hi, 0)* (+hi, 1) (+hi, 0)* (— hi, 0)* ( — hi, 1) (—hi, 0)* ( —hi, 1) (—hi, 0)* n (—rnd, 0)*(—rnd, 1) (—rnd, 0)* ( —rnd, 1) (—rnd, 0)* (+rnd, 0)* (+rnd, 1) (+rnd, 0)* The final step is to compute the intersection and project the first element of each tuple (ignoring the is and Os). This produces the expression: (+hi n —rnd)+ (—hi n —rnd)+ (—hi n +rnd)+ 4 Wheeler 1981; Bird 1990; Coleman 1991; Scobbie 1991; Broe 1993; Russell 1993; Mastroianni 1993. 56 Steven Bird and T. Mark Ellison One-Level Phonology Given plausible interpretations of the high and round features, this last expression simplifies to i±a+o+, which describes an automaton tape (or a string) divided into three nonempty intervals, the first containing [i], the second containing [a], and the third containing [o]. This, we shall claim, is the intended interpretation of (1). After a detailed discussion of this procedure, the remainder of Section 4 is given over to generalizing the procedure to an arbitrary number of autosegmental char</context>
</contexts>
<marker>Scobbie, 1991</marker>
<rawString>Scobbie, J. (1991). Attribute-value phonology. Doctoral dissertation, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sproat</author>
</authors>
<title>Morphology and Computation. Natural Language Processing.</title>
<date>1992</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2610" citStr="Sproat 1992" startWordPosition="374" endWordPosition="375">eniently abstract level, and analyses of several languages now exemplify the approach. Today, two-level morphology encompasses much of traditional segmental generative phonology of the SPE variety (Chomsky and Halle 1968).3 Although further development and application of this model is set to continue for some time, there is now a clear need to integrate it more closely with computational * University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, Scotland, U.K. E-mail: {steven,marke}@cogsci.ed.ac.uk 1 (Antworth 1990; Ritchie, Russell, Black, and Pulman 1992; Sproat 1992) 2 (Bear 1986; Antworth 1990; Schiller and Steffens 1991; Pulman and Hepple 1993) 3 Two caveats are necessary here. SPE rules must be restricted so as not to apply to their own output (Johnson 1972) and there is no guarantee that the transducer encoding an SPE rule can be expressed using the two-level rule notation (Ritchie 1992). C) 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 1 grammar frameworks on the one hand and modern nonlinear phonology on the other. The primary goal of this article is to show how the central tenets of autosegmental phonolo</context>
</contexts>
<marker>Sproat, 1992</marker>
<rawString>Sproat, R. (1992). Morphology and Computation. Natural Language Processing. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D S Touretzky</author>
<author>D W Wheeler</author>
</authors>
<title>A computational basis for phonology.&amp;quot;</title>
<date>1990</date>
<booktitle>In Advances in Neural Information Processing Systems 2: The Collected Papers of the 1989 IEEE Conference on Neural Information Processing Systems, edited</booktitle>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="3585" citStr="Touretzky and Wheeler 1990" startWordPosition="529" endWordPosition="532">tion for Computational Linguistics Computational Linguistics Volume 20, Number 1 grammar frameworks on the one hand and modern nonlinear phonology on the other. The primary goal of this article is to show how the central tenets of autosegmental phonology translate into an implemented finite state model. The model is named ONE-LEVEL PHONOLOGY for two reasons. First, the model is monostratal, in that there is only one level of linguistic description. Second, the name is intended to contrast with models employing two levels (such as the FST model mentioned above) or three levels (Goldsmith 1991; Touretzky and Wheeler 1990), or an unbounded number of levels (Chomsky and Halle 1968). The one-level model represents the outgrowth of three independent strands of research: (i) the finitestate modeling of phonology, (ii) the declarative approach to phonology,&apos; and (iii) the automatic learning of phonological generalizations (Ellison 1992, 1993). The paper is organized as follows. Section 2 presents an overview of autosegmental phonology and the temporal semantics of Bird and Klein (1990). Then we define state-labeled automata (Section 3.1), show their equivalence to finite state automata (Section 3.2), define the oper</context>
</contexts>
<marker>Touretzky, Wheeler, 1990</marker>
<rawString>Touretzky, D. S., and Wheeler, D. W. (1990). &amp;quot;A computational basis for phonology.&amp;quot; In Advances in Neural Information Processing Systems 2: The Collected Papers of the 1989 IEEE Conference on Neural Information Processing Systems, edited by D. S. Touretzky. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wheeler</author>
</authors>
<title>Aspects of a categorial theory of phonology.</title>
<date>1981</date>
<institution>Unversity of Massachusetts,</institution>
<location>Amherst, MA.</location>
<note>Doctoral dissertation,</note>
<contexts>
<context position="5672" citStr="Wheeler 1981" startWordPosition="868" endWordPosition="869">n, it suffices to note here that each line of the expression represents a tier and the tiers are combined using the intersection operation (n). Moreover, the is act as synchronization marks between the operands of the intersection operation. (+hi, 0)* (+hi, 1) (+hi, 0)* (— hi, 0)* ( — hi, 1) (—hi, 0)* ( —hi, 1) (—hi, 0)* n (—rnd, 0)*(—rnd, 1) (—rnd, 0)* ( —rnd, 1) (—rnd, 0)* (+rnd, 0)* (+rnd, 1) (+rnd, 0)* The final step is to compute the intersection and project the first element of each tuple (ignoring the is and Os). This produces the expression: (+hi n —rnd)+ (—hi n —rnd)+ (—hi n +rnd)+ 4 Wheeler 1981; Bird 1990; Coleman 1991; Scobbie 1991; Broe 1993; Russell 1993; Mastroianni 1993. 56 Steven Bird and T. Mark Ellison One-Level Phonology Given plausible interpretations of the high and round features, this last expression simplifies to i±a+o+, which describes an automaton tape (or a string) divided into three nonempty intervals, the first containing [i], the second containing [a], and the third containing [o]. This, we shall claim, is the intended interpretation of (1). After a detailed discussion of this procedure, the remainder of Section 4 is given over to generalizing the procedure to an</context>
<context position="77487" citStr="Wheeler (1981)" startWordPosition="13205" endWordPosition="13206">in one-level phonology is the relationship between different formats of the same description. There is no finite-state transducer that will form the product of two regular expressions. Multilevel analyses necessarily seek to capture relationships between different descriptions, and like the product operation, these relationships often cannot be captured by finite-state transducers. 6. Conclusions The starting point of this paper was the distinction between descriptions and objects. Multidimensional phonological structures were taken to be descriptions of classes of phonetic objects, following Wheeler (1981), Bird and Klein (1990), Pierrehumbert (1990), Bird (1990), and Coleman (1992). Multiple tiers could be put together not by a clever encoding but by the simple operation of intersection, which corresponds to logical conjunction. Furthermore, this move of intensionalizing phonology enabled us to provide a straightforward formal basis for adding logical negation and disjunction to our representations. One important consequence of this work is that there are now good prospects for the incorporation of nonlinear phonology into constraint-based grammar formalisms such as HPSG (Pollard and Sag 1987)</context>
</contexts>
<marker>Wheeler, 1981</marker>
<rawString>Wheeler, D. (1981). Aspects of a categorial theory of phonology. Doctoral dissertation, Unversity of Massachusetts, Amherst, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Wiebe</author>
</authors>
<title>Modelling autosegmental phonology with multi-tape finite state transducers. Master&apos;s dissertation,</title>
<date>1992</date>
<institution>Simon Fraser University.</institution>
<contexts>
<context position="1290" citStr="Wiebe (1992)" startWordPosition="182" endWordPosition="183">logical domain—such as conjunction, disjunction, and negation—make sense since the phonological domain consists of descriptions rather than objects. These operations as applied to automata are the straightforward operations of intersection, union, and complement. If the arrow in a rewrite rule is viewed as logical implication, then a phonological rule can also be represented as an automaton, albeit a less restrictive automaton than would be required for a lexical representation. The model is then compared with the transducer models for autosegmental phonology of Kay (1987), Kornai (1991), and Wiebe (1992). We conclude that the declarative approach to phonology presents an attractive way of extending finite-state techniques to autosegmental phonology while remaining within the confines of regular grammar. 1. Introduction The decade since the publication of Koskenniemi&apos;s dissertation (1983) and since the development of the KIMMO system (Karttunen 1983) has witnessed a spectacular flurry of activity as the linguistic and computational consequences of this work have been fleshed out. A considerable body of literature has grown up around TWO-LEVEL MORPHOLOGY, along with texts&apos; and implementations.&apos;</context>
<context position="6582" citStr="Wiebe (1992)" startWordPosition="1008" endWordPosition="1009">ded into three nonempty intervals, the first containing [i], the second containing [a], and the third containing [o]. This, we shall claim, is the intended interpretation of (1). After a detailed discussion of this procedure, the remainder of Section 4 is given over to generalizing the procedure to an arbitrary number of autosegmental charts (Section 4.4), an evaluation of the encoding with respect to Kornai&apos;s desiderata (Section 4.5), and a presentation of the encoding of autosegmental rules (Section 4.6). Finally, Section 5 compares our proposals with those of Kay (1987), Kornai (1991), and Wiebe (1992). While our model has regular grammar power and is fully implemented, these three models go beyond regular grammar power and to our knowledge have never been implemented. 2. Background It has long been recognized that the SPE model lacks explanatory adequacy, a fact noted in SPE itself (Chomsky and Halle 1968, pp. 400ff). For example, it is unable to explain why a final devoicing rule like that in (2a) is commonplace in the languages of the world, whereas the rule in (2b) is unattested (Kaye 1989, p. 61). 2. (a) [—sonorant] —&gt; [—voice] / — # (b) [—sonorant] [+nasal] / — # (c) [] [anasal] / [an</context>
<context position="39944" citStr="Wiebe (1992)" startWordPosition="6853" endWordPosition="6854"> forming the intersection of the n tier encodings 13 Observe that when we expand these macros the resulting expression has s + 2a terms, where s is the number of autosegments and a is the number of associations. 72 Steven Bird and T. Mark Ellison One-Level Phonology and projecting the first elements of the tuples. Note that if we revert to the encoding in (19), where the tier encodings are combined into a linear expression using intersection, then compositionality is lost. Thus, the encoding is either linear or compositional, but not both. Unfortunately, this is the best that we can hope for; Wiebe (1992) has shown that a compositional linear encoding does not exist. 4.6 Phonological Rules Phonologists typically encode their descriptive generalizations in terms of RULES. Often these rules are interpreted as processes that manipulate representations. In the one-level approach they are interpreted as a logical implication between two descriptions, which simplifies to a single description given the Boolean operations presented in Section 3.3. As our first example, consider the phenomenon of homorganic nasal assimilation, whereby nasals agree in place of articulation with the following consonant. </context>
<context position="60261" citStr="Wiebe (1992)" startWordPosition="10356" endWordPosition="10357">hange in one part of the autosegmental representation has resulted in major changes in much of the triple-coded representation. Thus the code is not iconic. Similarly, if we concatenate the two representations shown below A BCD we get a b c d ABCD a b cd 81 Computational Linguistics Volume 20, Number 1 If we concatenate the two encodings, we get A0a.b.A0b.b.A0c.B0d.t.00d.t.D0d, which is not the same as the encoding of the concatenation: Ala.B1b.C1c.D1d. So the triple code satisfies only two of the desiderata Kornai gives for linearizations of autosegmental representations. As mentioned above, Wiebe (1992) has proven that linear encodings cannot get much better than this: no linear encoding can be both invertible and compositional. Under the triple code, a lot of phonological processes are not finite-state. For example, consider the process of putting morphemic tiers together. In the case of the Arabic example we saw in (29), we need to combine the root morpheme (with empty template and vocalic tier) ktb and the template (with empty vocalic and consonantal tiers) CVCCVC together in such a way that we end up with the encoding in (38). In autosegmental representations, this is achieved by concate</context>
<context position="63177" citStr="Wiebe 1992" startWordPosition="10850" endWordPosition="10851">ion.&apos; If the template consisted of n CV syllables, and the consonant tier consisted of n consonants, then the association mechanism would need to store at least [(n - 1)/2j autosegments. This is, in principle, unbounded, and so the association mechanism for coded autosegmental representations is not finite state. In general there is no limit on the amount of information that needs to be preserved as state information in the transducer. Consequently, using the triple code, certain phonological processes cannot be modeled using a finite state transducer. Indeed, this is true of any linear code (Wiebe 1992). It is true that adding each individual association—that is, finding the next position to associate, making the association and shuffling the lower tier along—can be performed by a finite-state transducer. But no principled bound on the length of the derivation can be made, and the quantity of memory required is an increasing function of the length of the derivation. Consequently, the step from unassociated to associated form cannot be made by a single FST. This type of problem with manipulating coded representations is not limited to Arabic morphology. In fact, the problem arises whenever th</context>
<context position="64822" citStr="Wiebe 1992" startWordPosition="11124" endWordPosition="11125"> to the accented element of a word. In general, the accented element of a word may be an unbounded distance from the start and end of a word. Goldsmith (1982, p. 53) gives the following example: 41. na a kam ir* e I milked L H* L As before, performing the association using the triple code requires a multiplication in state information, which in the general case cannot be bounded. True, this example only requires the automaton to store H; but Goldsmith (1982, p. 55) gives examples where there are two stresses in the word, and, therefore, the association automaton needs to store more tones (see Wiebe 1992, pp. 109-110 for the details). Next, consider the problem of generalizing from one chart to an arbitrary number 19 Wiebe (1992, p. 112) points out that the final consonant does not need to be stored, as it is already associated with the final C position. 83 Computational Linguistics Volume 20, Number 1 of charts. Kornai (1991, p. 70) gives the following example: def / g h i / k 1 Each chart is encoded as a string and then these two strings are linked by association lines. Each line indicates that the segments it connects are actually the same segment (in the original diagram). Here is the fir</context>
<context position="66065" citStr="Wiebe (1992)" startWordPosition="11331" endWordPosition="11332">above diagram:2° dlgtelgfOhbfli \/ / /\ gljthlki0kbila Next, this encoding can itself be encoded into a string 77 characters long. Kornai himself admits (p. 72) that his encoding is impractical for autosegmental structures having more than two charts.&apos; Kornai discusses another encoding, which involves transducers that can read three (or more) tapes simultaneously. However, this comes in for the same criticism leveled at Kay&apos;s system above, namely that there is no principled upper bound on the number of tiers due to such considerations as complex feature geometry and morphemic segregation. 5.3 Wiebe (1992) Wiebe (1992) has recently devised an encoding of autosegmental diagrams that overcomes many of the problems of Kornai&apos;s triple code. It is called the MULTI-LINEAR CODE. Consider again diagram (29), reproduced below. 29. a perfective active CV CCV C causative / write This diagram contains two charts. The upper chart, which connects the vowel to two V slots will be referred to as chart 1, and the other chart as chart 2. Since there is a total ordering on the associations in a given chart (Goldsmith 1976, p. 29), it is sufficient to record how many associations each autosegment has on each chart</context>
<context position="70005" citStr="Wiebe 1992" startWordPosition="11974" endWordPosition="11975">isely this ability to scan different parts of an input word at the same time that is so important in modelling autosegmental rules. Association lines can associate segments in any part of one tier to segments in any part of the facing tier. In order for any computational 22 Wiebe borrows the terms SFA and SFT from an earlier version of this paper (Bird and Ellison 1992). 85 Computational Linguistics Volume 20, Number 1 device to efficiently process autosegmental representations, it must be able to scan two associated segments from widely separated parts of the representation at the same time (Wiebe 1992, pp. 95-96, emphasis added). While this is a reasonable statement regarding any model like Kornai&apos;s, it does not apply to our one-level model since the notion &apos;widely separated&apos; is meaningless in this context. Two terms in a multi-linear code are widely separated if they differ significantly as to their distance from the left- or right-hand end of the encoding. Thus, the longer and more slanted the line that associates the autosegments, the greater their separation. Although this is true of the ink on a page, our semantics pays no attention to the angle and length of association lines. If a p</context>
</contexts>
<marker>Wiebe, 1992</marker>
<rawString>Wiebe, B. (1992). Modelling autosegmental phonology with multi-tape finite state transducers. Master&apos;s dissertation, Simon Fraser University.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>