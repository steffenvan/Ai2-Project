<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012888">
<title confidence="0.994352666666667">
In Defense of Syntax:
Informational, Intentional, and Rhetorical Structures
in Discourse
</title>
<author confidence="0.788318">
Eduard H. Hovy
</author>
<affiliation confidence="0.6157688">
Information Sciences Institute
of the University of Southern California
4676 Admiralty Way
Marina del Rey, CA 90292-6695
U.S.A.
</affiliation>
<address confidence="0.1423645">
tel: 310-822-1511
fax: 310-823-6714
</address>
<email confidence="0.778618">
email: hovy@isi.edu
</email>
<sectionHeader confidence="0.959751" genericHeader="abstract">
Introduction: The Point of this Paper
</sectionHeader>
<bodyText confidence="0.99095309375">
Much has been written on the nature and use of so-called rhetorical relations to govern the structure and
coherence of discourse, and much has been written on the need for communicative intentions to govern
discourse construction. In early research on automated text creation, the operationalized structural relations
from Rhetorical Structure Theory (RST) [Mann &amp; Thompson 88] were used both to carry the speaker&apos;s
communicative intention (which enabled the use of a NOAH-like top-down expansion planner) and also to
ensure coherence (by utilizing the constraints on Nucleus and Satellite from RST). This dual functionality
is characteristic of the operators used in the various text structure planners that have been built to date,
whether they were oriented more toward surface text structure (such as the relation/plans of the RST
Structurer [Hovy 88, Hovy 90]) or more toward the communicative intentions underlying the text (as the
text plans of the EES and PEA text planner in the later [Moore Sz Paris 89, Moore 89] work)i.
However, the resulting perspective shift from surface (RST) oriented toward intentional did engender
considerable discussion about the types of discourse structure relations and the form of discourse structure
itself. In work collecting and classifying relations from many sources, [Maier &amp; Hovy 91, Hovy &amp; Maier 93]
eventually created a taxonomy of three types of relations: ideational (semantic), interpersonal (intentional),
and textual (rhetorical); for a more expanded taxonomy see [Hovy et al. 92]. Though the details were not
explicitly spelled out, the idea was that a discourse can (arid should) be described by at least three structures
in parallel: the semantic, the interpersonal, and the rhetorical.
Recently, Moore and Pollack published a paper [Moore &amp; Pollack 92] in which they show the need for
two accounts of discourse structure, the semantic (what they call informational) and the interpersonal (what
they call intentional). They also offer a convincing example to show that these two structures are not in
general isomorphic. With these claims I have absolutely no problems — see the discussion of multiple parallel
relations in [Hovy et al. 92] — except the fact that it doesn&apos;t go far enough. It doesn&apos;t recognize the need
for the rhetorical relations. The current paper argues for the need for an additional, rhetorical, structure to
describe discourse.
11t is important to understand that merely using plan operators with more &amp;quot;intentional&amp;quot; IlaIlleS does not guarantee that
either the text planner or the resulting text structure encapsulate &amp;quot;intentionality&amp;quot; in a real way (whatever &amp;quot;intentionality&amp;quot; may
mean in this context). When a text plan library includes both &amp;quot;intentional plans&amp;quot; and RST-like operators side by side, and
the planner uses them interchangably, and they fulfill a similar function in the resulting discourse structure, then the difference
between the two types of operator as implemented is one of nomenclature rather than of true functionality, and is thus open to
McDermott&apos;s &amp;quot;Wishful Mnemonics&amp;quot; trap [McDermott 84 The shift of nomenclature does however reflect a shift of perspective,
namely the recognition that text planning should develop non-linguistic, intentionality-oriented terminology. The true import
of this shift is only gradually becoming apparent.
</bodyText>
<page confidence="0.998403">
35
</page>
<subsectionHeader confidence="0.692839">
Why is there Syntax?
</subsectionHeader>
<bodyText confidence="0.9996736875">
I would like to describe a more complete model of discourse structure by analogy to single sentence structure.
The typical model most of us have of single sentences includes two principal structures: a structure that
houses the semantic information (usually called the semantic structure, the f-structure in LFG [Bresnan 78],
or possibly the deep structure [Chomsky 65]; the distinction is not relevant here) and a syntactic structure
that expresses the surface form of the sentence.
Now ask yourself: why is syntactic structure necessary as a separate, autonomous construct? If you have
a well-formed semantic structure, possibly something like a case frame or a set of knowledge base assertions,
and you define a regular traversal algorithm, possibly a depth-first left-to-right strategy, then for the surface
sentence you can simply produce a string of pairs: semantic function and filler. In fact, most languages have
almost this form: English (with pairs of preposition and filler) somewhat so; Japanese (with pairs of case
marker and filler) more so. Under this view there&apos;s no need for a distinct surface structure -- the whole
semantic structure is straightforwardly recoverable from the sentence itself. Why then have all languages
evolved a syntax?
One may surmise: the syntax of the language is nothing other than the trace of the traversal of the
semantic structure.
Unfortunately, however, this cannot hold: in general, the syntactic structure and the semantic structure
are not isomorphic. That is to say, either the semantics is not derivable from the syntax, or the syntax
contains more information than the semantic structure. Regardless of what theories of syntax and semantics
one follows, the statement of non-isomorphism would be supported, I believe, by all experts.
Assuming that all required semantic structure is reflected in the syntactic structure, this non-isomorphism
implies that the syntactic structure contains other information as well. Short of random inclusion of noise,
there&apos;s no other explanation.
A moment&apos;s thought provides the answer: the syntactic structure of a sentence contains additional
non-semantic information. The difference between active and passive voice, for example, is thematic, not
semantic. The difference between &amp;quot;the door is closed&amp;quot; spoken normally (as a statement) and with a final
rising intonational contour (as a question) is not semantic, it is Speech Act-related, hence interpersonal.
Briefly, then, syntactic form is a structure that merges information about the sentence from several
sources: semantics (for the primary content), discourse (for theme and focus), interpersonal goals and plans
(for Speech Acts), and so on. The syntactic structure cannot be isomorphic to any one of these component
source structures alone, since it houses more information than any of them do individually. Necessarily, also,
the syntactic structure is much closer to the surface form of the sentence than any of the other structures
are.
</bodyText>
<subsectionHeader confidence="0.941966">
The Model of Discourse Structure
</subsectionHeader>
<bodyText confidence="0.9997404">
I now return to discourse structure. By analogy, I argue that the content of a discourse derives from several
sources, and that a common, surface-level-ish structure is needed to house them all. The major sources for
the content of a discourse are: the semantics of the message, the interpersonal Speech Acts, the &amp;quot;control&amp;quot;
information included by the speaker to assist the hearer&apos;s understanding (namely information signalling
theme, focus, and topic), and knowledge about stylistic preferability. We consider these four in turn.
</bodyText>
<listItem confidence="0.986095714285714">
1. Semantic information: In our normal computational approaches, semantic information consists
of propositions in a knowledge base, possibly represented as case frames using terms defined in a taxo-
nomic ontology. The interpropositional linkages are relations that have been called semantic, ideational,
or informational. These include relations such as CAUSE, PART-WHOLE, IS-A, TEMPORAL-SEQUENCE,
SPATIAL-SEQUENCE.
2. Interpersonal information: For computational discourse, interpersonal information takes the
form of communicative goals. Properly, the goals should refer to the speaker, the hearer, and the desired
</listItem>
<page confidence="0.992585">
36
</page>
<bodyText confidence="0.998851333333333">
effect on the hearer&apos; state of knowledge, state of happiness, state of belief, etc. (which includes portions
of semantic information). The interpersonal goals include MOTIVATE (someone to do something), JUSTIFY
(one&apos;s own actions), EXPLAIN (the operation or development of something or some events), CONCEDE (a
point of contention), and so on. Since we are still sorting out the various terms, the precise nature of these
goals in a discourse planning system is not yet clear; I believe for example that we are still confusing things
a little when we talk about &amp;quot;interpersonal relations&amp;quot;, since what&apos;s interpersonal are not relations but goals.
</bodyText>
<listItem confidence="0.990927772727273">
3. Control information: Despite the Attentional state in [Grosz &amp; Sidner 86] and [Moore 89], the
inclusion of control information in discourse planning systems has not received the attention it deserves,
primarily I think because we do not understand clearly enough how discourse analysis works. As argued
in [Lavid &amp; Hovy 93], the speaker signals theme to indicate to the hearer where in the evolving discourse
the new sentence or group of sentences attaches; the speaker signals focus in the sentence to indicate to the
hearer where in the clause the hearer should spend most inferential attention, and so on. Mechanisms to
perform this signalling include voice (active and passive), clause constituent ordering, pronoun use (pronouns
respect discourse boundaries), pitch range and stress (for spoken discourse), etc.
4. Style: As anyone knows after writing a text generator for a domain created by another person for
another task, the mismatch between representations suited to the task and representations suited to language
can be daunting. Usually, text generated directly from domain-oriented representations is stylistically awful,
to say the least. As argued in [Rambow &amp; Korelsky 92, Hovy 92], several so-called sentence planning tasks
must be performed after text content selection and structuring and before actual surface realization. These
tasks include:
• clause aggregation: the operation of merging very similar representations into conjunctive clauses so
as to remove redundancy (&amp;quot;Bush is sure to veto Bill 1711 and Bill 2104&amp;quot; instead of &amp;quot;Bush is sure to
veto Bill 1711. He is also sure to veto Bill 2104.&amp;quot;)
• pronominalization determination: this operation depends on discourse structure and on stylistic factors
• clause-internal structure: whether, for example, an attribute is realized as a relative clause (&amp;quot;the book,
which is blue...&amp;quot; ) or as an adjective (&amp;quot;the blue book...&amp;quot;)
• certain types of lexical choice: the determination of verbs can significantly affect the local structure of
the discourse
</listItem>
<bodyText confidence="0.761248">
An example of aggregation is given at the end of the paper.
</bodyText>
<subsectionHeader confidence="0.996483">
The Rhetorical Structure
</subsectionHeader>
<bodyText confidence="0.9999146875">
Pity the poor speaker. All this information, and more, must be packed into each clause! Small wonder that
a distinct structure, one much closer to the surface form of the discourse, is useful. Just as in the case of
single-sentence syntactic structures, the discourse-level rhetorical structures require their own, multipurpose,
type of interclause relation — rhetorical relations.
Rhetorical relations are the presentational analogue of both semantic relations and interpersonal goals.
While I do not think it is useful to identify a unique rhetorical partner for each semantic relation and each
interpersonal goal, it doesn&apos;t seem surprising that certain strong correlates exit. Just as semantic agent
and patient pattern closely in English sentences with syntactic subject and direct object, just so semantic
TEMPORAL-SEQUENCE patterns closely with rhetorical PRESENTATIONAL-SEQUENCE. In fact, it also pat-
terns closely with SPATIAL-SEQUENCE; such simplifications of semantic diversity are found in several areas,
as where the semantic relations PART-WHOLE, PLAN-STEP, ABSTRACT-INSTANCE all pattern with rhetori-
cal ELABORATION. Exactly which rhetorical relations are most useful to define as separate entities, and how
they co-pattern with semantic relations, interpersonal goals, and control information, remains a matter of
investigation.
The rhetorical discourse structure differs from the semantic and the intentional structure. Incorporating
as it does the effects of both, as well as of other constraints on the discourse, it is much closer to the surface
</bodyText>
<page confidence="0.998681">
37
</page>
<bodyText confidence="0.999946642857143">
form of the text. RST provides one attempt at providing rhetorical structure. What has often been called
a liability of RST, namely that its analyses mirror the text so closely, is in fact a virtue — it represents
a minimal step of abstraction away from the surface form, and does not discard information that is not
directly semantic or intentional. This is not to say that RST has no flaws; one of its principal problems is
the conflation of intentional, semantic, and rhetorical relations. Not all the relations of RST are rhetorical
— for example JUSTIFY and MOTIVATE are clearly intentional, and CAUSE and PART-WHOLE are clearly
semantic.
What then does a rhetorical structure look like? It is in fact a structure very familiar to us, the one
that first appears from considering text itself instead of the meaning or communicative intent thereof. To
illustrate, I conclude with the Bush example and the problem of aggregation.
One of the most common mismatches between the representations constructed for a domain-oriented
knowledge base and the representations needed for stylistically adequate generation occurs with multiple
copies of very similar information, which the text planner has to &amp;quot;aggregate&amp;quot; in order to reduce redundancy.
In most knowledge representations, it is overwhelmingly likely that the propositions underlying sentence (1):
</bodyText>
<listItem confidence="0.990137666666667">
(1). George Bush supports big business.
(2). He is sure to veto House bills 1711 and 2104.
will be stored separately, which under straightforward text production would give rise to
(1). George Bush supports big business.
(2). He is sure to veto House bill 1711.
(3). (And) He is sure (also) to veto House bill 2104.
</listItem>
<bodyText confidence="0.9999632">
The problem of aggregating partially similar representations has been studied by several people in the text
generation community (see for example [Mann Sr. Moore 80, Kempen 91, Dalianis &amp; Hovy 93]) but is still a
long way from being solved, involving as it does questions of conversational implicature (see [Horacek 92])
and of style (see [Hovy 87]). As described in [Hovy 90], the presence of a discourse structure greatly reduces
the problem of finding candidates for aggregation (from polynomial to sub-linear in the total number of
clause-sized representation clusters). This kind of operation can only be performed on a fairly surface-level
discourse structure; a semantic or interpersonal does not contain the appropriate information.
I think is is too early to try to define exactly what is and isn&apos;t part of the rhetorical structure; the most
useful answers seem to crystallize from practical experience. I believe that as examples of rhetorical structure
one should consider RST trees as given in [Mann &amp; Thompson 88], though few of the specific RST relations
used there are will in my opinion turn out to be most productive. Instead, I believe that the relations
identified in [Martin 92] and classified as Textual in [Hovy et al. 92] will be more useful. I also believe that
the rhetorical structure will not necessarily contain clauses at its leaves, but may in fact contain information
reaching &amp;quot;into&amp;quot; the clause itself; most likely as a set of attributes which the clause should exhibit, rather
along the lines outlined in [Meteer 90]. The notions of Nucleus and Satellite seem to me very useful however.
</bodyText>
<sectionHeader confidence="0.719971" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999968">
Given, in any text generation system, the stylistic necessity of performing such sentence planning tasks as
aggregation, pronominalization, etc., not to mention the reorganizations of material caused by lexical choice,
and given the complexity of managing the disparate effects of these operations, a fairly surface-level structure
that governs the realization of the text becomes a practical necessity. The interclausal relations employed
in such a structure have to be fairly neutral in character, carrying as they do semantic, interpersonal, and
&amp;quot;control&amp;quot; information simultaneously. Though the precise format of the rhetorical discourse structure and
its rhetorical relations remains a topic of ongoing study, the need for and utility of such constructs cannot
be denied by anyone who has actually tried to build a real system.
</bodyText>
<page confidence="0.998584">
38
</page>
<sectionHeader confidence="0.996366" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998850645833333">
[Bresnan 78] Bresnan, J. 1978. A Realistic Transformational Grammar. In Linguistic Theory and Psychological Re-
ality, M. Halle, J. Bresnan, and G. Miller (eds), Cambridge: MIT Press (39-49).
[Chomsky 65] Chomsky, N. 1965. Aspects of the Theory of Syntax. Cambridge: MIT Press.
[Dafianis &amp; Hovy 93] Dahauls, H. and Hovy, E.H. 1993. Aggregation in Natural Language Generation. In Proceedings
of the 5th European Workshop on Natural Language Generation, Pisa, Italy, 1993.
[Grosz At Sidner 86] Grosz, B.J. and Sidner, C.L. 1986. Attention, Intentions, and the Structure of Discourse. Journal
of Computational Linguistics 12(3) (175-204).
[Horacek 92] Horacek, H. 1992. An Integrated View of Text Planning. In Aspects of Automated Natural Language
Generation, R. Dale, E. Hovy, D. Rosner, 0. Stock (eds). Heidelberg: Springer Verlag Lecture Notes in Al number
587 (57-72).
[Hovy 87] Hovy, E.H. 1987. Interpretation in Generation. Proceedings of the 6th AAAI Conference, Seattle (545-549).
Also available as USC/Information Sciences Institute Research Report ISI/RS-88-186.
[Hovy 88] Hovy, E.H. 1988. Planning Coherent Multisentential Text. Proceedings of the 26th ACL Conference, Buffalo
(163-169).
[Hovy 90] Hovy, E.H. 1990. Unresolved Issues in Paragraph Planning. In Current Research in Natural Language
Generation, R. Dale, C. Mellish, M. Zock (eds), Academic Press.
[Hovy 92] Hovy, E.H. 1992. Sentence Planning Requirements for Automated Explanation Generation. DIAMOD-
Bericht no. 23, GMD, St. Augustin, Germany.
[Hovy et al. 92] Hovy, E.H., Lavid, J., Maier, E., Mittal, V., and Paris, C.L. 1992. Employing Knowledge Resources
in a New Text Planner Architecture. In Aspects of Automated Natural Language Generation, R. Dale, E. Hovy, D.
Wisner, 0. Stock (eds). Heidelberg: Springer Verlag Lecture Notes in AT number 587 (57-72).
[Hovy &amp; Maier 93] Hovy, E.H. and Maier, E. 1993. Parsimonious or Profligate: How Many and which Discourse
Structure Relations? Discourse Processes (to appear).
[Kempen 91] Kempen, G. 1991. Conjunction Reduction and Gapping in Clause-Level Coordination: An Inheritance-
Based Approach. Computational Intelligence 7(4).
[Lavid &amp; Hovy 93] Lavid, J.M. and Hovy, E.H. 1993. Focus, Theme, Given, and Other Dangerous Things. Working
paper.
[Maier &amp; Hovy 91] Maier, E. and Hovy, E.H. 1991. Organizing Discourse Structure Relations using Metafunctions.
In New Concepts in Natural Language Generation: Planning, Realization, and Systems, H. Horacek (ed), London:
Pinter (to appear).
[Mann &amp; Moore 80] Mann, W.C. and Moore, J.A. 1980. Computer as Author: Results and Prospects.
USC/Information Sciences Institute Research Report ISI/RR-79-82.
[Mann &amp; Thompson 88] Mann, W.C. and Thompson, S.A. 1988. Rhetorical Structure Theory: Toward a Functional
Theory of Text Organization. Text 8(3) (243-281). Also available as USC/Information Sciences Institute Research
Report RR-87-190.
[Martin 92] Martin, J.R. 1992. English Text: System and Structure. Amsterdam: Benjamins Press.
[McDermott 81] McDermott, D.V. 1981. Artificial Intelligence Meets Natural Stupidity. In Mind Design, J. Hauge-
land (ed), Cambridge: MIT Press, (143-160).
[Meteer 90] Meteer, M.W. 1990. The &amp;quot;Generation Gap&amp;quot;: The Problem of Expressibility in Text Planning. Ph.D.
dissertation, University of Massachusetts at Amherst. Available as BBN Report No, 7347, February 1990.
[Moore 89] Moore, J.D. 1989. A Reactive Approach to Explanation in Expert and Advice-Giving Systems. Ph.D.
dissertation, University of California in Los Angeles.
[Moore &amp; Paris 89] Moore, J.D. and Paris, C.L. 1989. Planning Text for Advisory Dialogues. Proceedings of the 27th
ACL Conference, Vancouver (67-75).
[Moore &amp; Pollack 92] Moore, J.D. and Pollack, M.E. 1992. A Problem for RST: The Need for Multi-Level Discourse
Analysis. Squib in Computational Linguistics 18(4).
[Rainbow &amp; Korelsky 92] Rainbow, 0. and Korelsky, T. 1992. Applied Text Generation. Proceedings of the Applied
Natural Language Processing Conference, Trento, Italy.
</reference>
<page confidence="0.999532">
39
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.256163">
<title confidence="0.989171333333333">In Defense of Syntax: Informational, Intentional, and Rhetorical in Discourse</title>
<author confidence="0.999082">H Eduard</author>
<affiliation confidence="0.977732">Information Sciences of the University of Southern</affiliation>
<address confidence="0.769178">4676 Admiralty Marina del Rey, CA</address>
<email confidence="0.820178666666667">tel:fax:email:hovy@isi.edu</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Bresnan</author>
</authors>
<title>A Realistic Transformational Grammar.</title>
<date>1978</date>
<booktitle>In Linguistic Theory and Psychological</booktitle>
<pages>39--49</pages>
<publisher>MIT Press</publisher>
<location>Cambridge:</location>
<marker>[Bresnan 78]</marker>
<rawString>Bresnan, J. 1978. A Realistic Transformational Grammar. In Linguistic Theory and Psychological Reality, M. Halle, J. Bresnan, and G. Miller (eds), Cambridge: MIT Press (39-49).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<title>Aspects of the Theory of Syntax.</title>
<date>1965</date>
<publisher>MIT Press.</publisher>
<location>Cambridge:</location>
<marker>[Chomsky 65]</marker>
<rawString>Chomsky, N. 1965. Aspects of the Theory of Syntax. Cambridge: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Dahauls</author>
<author>E H Hovy</author>
</authors>
<title>Aggregation in Natural Language Generation.</title>
<date>1993</date>
<booktitle>In Proceedings of the 5th European Workshop on Natural Language Generation,</booktitle>
<location>Pisa, Italy,</location>
<marker>[Dafianis &amp; Hovy 93]</marker>
<rawString>Dahauls, H. and Hovy, E.H. 1993. Aggregation in Natural Language Generation. In Proceedings of the 5th European Workshop on Natural Language Generation, Pisa, Italy, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>C L Sidner</author>
</authors>
<title>Attention, Intentions, and the Structure of Discourse.</title>
<date>1986</date>
<journal>Journal of Computational Linguistics</journal>
<volume>12</volume>
<issue>3</issue>
<pages>175--204</pages>
<marker>[Grosz At Sidner 86]</marker>
<rawString>Grosz, B.J. and Sidner, C.L. 1986. Attention, Intentions, and the Structure of Discourse. Journal of Computational Linguistics 12(3) (175-204).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Horacek</author>
</authors>
<title>An Integrated View of Text Planning.</title>
<date>1992</date>
<journal>In Aspects of Automated Natural Language</journal>
<booktitle>Stock (eds).</booktitle>
<volume>587</volume>
<pages>57--72</pages>
<publisher>Springer</publisher>
<location>Heidelberg:</location>
<marker>[Horacek 92]</marker>
<rawString>Horacek, H. 1992. An Integrated View of Text Planning. In Aspects of Automated Natural Language Generation, R. Dale, E. Hovy, D. Rosner, 0. Stock (eds). Heidelberg: Springer Verlag Lecture Notes in Al number 587 (57-72).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Hovy</author>
</authors>
<title>Interpretation in Generation.</title>
<date>1987</date>
<booktitle>Proceedings of the 6th AAAI Conference, Seattle (545-549). Also available as USC/Information Sciences Institute Research Report</booktitle>
<pages>88--186</pages>
<marker>[Hovy 87]</marker>
<rawString>Hovy, E.H. 1987. Interpretation in Generation. Proceedings of the 6th AAAI Conference, Seattle (545-549). Also available as USC/Information Sciences Institute Research Report ISI/RS-88-186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Hovy</author>
</authors>
<title>Planning Coherent Multisentential Text.</title>
<date>1988</date>
<booktitle>Proceedings of the 26th ACL Conference,</booktitle>
<location>Buffalo</location>
<marker>[Hovy 88]</marker>
<rawString>Hovy, E.H. 1988. Planning Coherent Multisentential Text. Proceedings of the 26th ACL Conference, Buffalo (163-169).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Hovy</author>
</authors>
<title>Unresolved Issues in Paragraph Planning.</title>
<date>1990</date>
<booktitle>In Current Research in Natural Language Generation,</booktitle>
<publisher>Academic Press.</publisher>
<marker>[Hovy 90]</marker>
<rawString>Hovy, E.H. 1990. Unresolved Issues in Paragraph Planning. In Current Research in Natural Language Generation, R. Dale, C. Mellish, M. Zock (eds), Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Hovy</author>
</authors>
<title>Sentence Planning Requirements for Automated Explanation Generation. DIAMODBericht no. 23, GMD,</title>
<date>1992</date>
<location>St. Augustin, Germany.</location>
<marker>[Hovy 92]</marker>
<rawString>Hovy, E.H. 1992. Sentence Planning Requirements for Automated Explanation Generation. DIAMODBericht no. 23, GMD, St. Augustin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Hovy</author>
<author>J Lavid</author>
<author>E Maier</author>
<author>V Mittal</author>
<author>C L Paris</author>
</authors>
<title>Employing Knowledge Resources in a New Text Planner Architecture. In</title>
<date>1992</date>
<journal>Aspects of Automated Natural Language</journal>
<booktitle>Stock (eds).</booktitle>
<volume>587</volume>
<pages>57--72</pages>
<publisher>Springer</publisher>
<location>Heidelberg:</location>
<marker>[Hovy et al. 92]</marker>
<rawString>Hovy, E.H., Lavid, J., Maier, E., Mittal, V., and Paris, C.L. 1992. Employing Knowledge Resources in a New Text Planner Architecture. In Aspects of Automated Natural Language Generation, R. Dale, E. Hovy, D. Wisner, 0. Stock (eds). Heidelberg: Springer Verlag Lecture Notes in AT number 587 (57-72).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Hovy</author>
<author>E Maier</author>
</authors>
<date>1993</date>
<booktitle>Parsimonious or Profligate: How Many and which Discourse Structure Relations? Discourse Processes</booktitle>
<note>(to appear).</note>
<marker>[Hovy &amp; Maier 93]</marker>
<rawString>Hovy, E.H. and Maier, E. 1993. Parsimonious or Profligate: How Many and which Discourse Structure Relations? Discourse Processes (to appear).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Kempen</author>
</authors>
<title>Conjunction Reduction and Gapping in Clause-Level Coordination: An InheritanceBased Approach.</title>
<date>1991</date>
<journal>Computational Intelligence</journal>
<volume>7</volume>
<issue>4</issue>
<marker>[Kempen 91]</marker>
<rawString>Kempen, G. 1991. Conjunction Reduction and Gapping in Clause-Level Coordination: An InheritanceBased Approach. Computational Intelligence 7(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Lavid</author>
<author>E H Hovy</author>
</authors>
<title>Focus, Theme, Given, and Other Dangerous Things. Working paper.</title>
<date>1993</date>
<marker>[Lavid &amp; Hovy 93]</marker>
<rawString>Lavid, J.M. and Hovy, E.H. 1993. Focus, Theme, Given, and Other Dangerous Things. Working paper.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Maier</author>
<author>E H Hovy</author>
</authors>
<title>Organizing Discourse Structure Relations using Metafunctions.</title>
<date>1991</date>
<booktitle>In New Concepts in Natural Language Generation: Planning, Realization, and Systems, H. Horacek (ed),</booktitle>
<publisher>Pinter</publisher>
<location>London:</location>
<note>(to appear).</note>
<marker>[Maier &amp; Hovy 91]</marker>
<rawString>Maier, E. and Hovy, E.H. 1991. Organizing Discourse Structure Relations using Metafunctions. In New Concepts in Natural Language Generation: Planning, Realization, and Systems, H. Horacek (ed), London: Pinter (to appear).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>J A Moore</author>
</authors>
<date>1980</date>
<booktitle>Computer as Author: Results and Prospects. USC/Information Sciences Institute Research Report</booktitle>
<pages>79--82</pages>
<marker>[Mann &amp; Moore 80]</marker>
<rawString>Mann, W.C. and Moore, J.A. 1980. Computer as Author: Results and Prospects. USC/Information Sciences Institute Research Report ISI/RR-79-82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>S A Thompson</author>
</authors>
<title>Rhetorical Structure Theory: Toward a Functional Theory of Text Organization.</title>
<date>1988</date>
<journal>Text</journal>
<volume>8</volume>
<issue>3</issue>
<pages>243--281</pages>
<note>Also available as USC/Information Sciences Institute Research Report RR-87-190.</note>
<marker>[Mann &amp; Thompson 88]</marker>
<rawString>Mann, W.C. and Thompson, S.A. 1988. Rhetorical Structure Theory: Toward a Functional Theory of Text Organization. Text 8(3) (243-281). Also available as USC/Information Sciences Institute Research Report RR-87-190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Martin</author>
</authors>
<date>1992</date>
<booktitle>English Text: System and Structure.</booktitle>
<publisher>Benjamins Press.</publisher>
<location>Amsterdam:</location>
<marker>[Martin 92]</marker>
<rawString>Martin, J.R. 1992. English Text: System and Structure. Amsterdam: Benjamins Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D V McDermott</author>
</authors>
<title>Artificial Intelligence Meets Natural Stupidity. In Mind Design,</title>
<date>1981</date>
<editor>J. Haugeland (ed),</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge:</location>
<marker>[McDermott 81]</marker>
<rawString>McDermott, D.V. 1981. Artificial Intelligence Meets Natural Stupidity. In Mind Design, J. Haugeland (ed), Cambridge: MIT Press, (143-160).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M W Meteer</author>
</authors>
<title>The &amp;quot;Generation Gap&amp;quot;: The Problem of Expressibility in Text Planning.</title>
<date>1990</date>
<pages>7347</pages>
<institution>University of Massachusetts at Amherst.</institution>
<note>Ph.D. dissertation,</note>
<marker>[Meteer 90]</marker>
<rawString>Meteer, M.W. 1990. The &amp;quot;Generation Gap&amp;quot;: The Problem of Expressibility in Text Planning. Ph.D. dissertation, University of Massachusetts at Amherst. Available as BBN Report No, 7347, February 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Moore</author>
</authors>
<title>A Reactive Approach to Explanation in Expert and Advice-Giving Systems.</title>
<date>1989</date>
<institution>University of California</institution>
<location>Los Angeles.</location>
<note>Ph.D. dissertation,</note>
<marker>[Moore 89]</marker>
<rawString>Moore, J.D. 1989. A Reactive Approach to Explanation in Expert and Advice-Giving Systems. Ph.D. dissertation, University of California in Los Angeles.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Moore</author>
<author>C L Paris</author>
</authors>
<title>Planning Text for Advisory Dialogues.</title>
<date>1989</date>
<booktitle>Proceedings of the 27th ACL Conference,</booktitle>
<location>Vancouver</location>
<marker>[Moore &amp; Paris 89]</marker>
<rawString>Moore, J.D. and Paris, C.L. 1989. Planning Text for Advisory Dialogues. Proceedings of the 27th ACL Conference, Vancouver (67-75).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Moore</author>
<author>M E Pollack</author>
</authors>
<title>A Problem for RST: The Need for Multi-Level Discourse Analysis.</title>
<date>1992</date>
<booktitle>Squib in Computational Linguistics 18(4).</booktitle>
<marker>[Moore &amp; Pollack 92]</marker>
<rawString>Moore, J.D. and Pollack, M.E. 1992. A Problem for RST: The Need for Multi-Level Discourse Analysis. Squib in Computational Linguistics 18(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Korelsky</author>
</authors>
<title>Applied Text Generation.</title>
<date>1992</date>
<booktitle>Proceedings of the Applied Natural Language Processing Conference,</booktitle>
<location>Trento, Italy.</location>
<marker>[Rainbow &amp; Korelsky 92]</marker>
<rawString>Rainbow, 0. and Korelsky, T. 1992. Applied Text Generation. Proceedings of the Applied Natural Language Processing Conference, Trento, Italy.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>