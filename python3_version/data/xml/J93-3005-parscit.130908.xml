<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002890">
<title confidence="0.886281">
Book Reviews
Ontologie und Axiomatik der Wissensbasis von LILOG
</title>
<author confidence="0.991477">
Gudrun Klose, Ewald Lang, and Thomas Pirlein, editors
</author>
<affiliation confidence="0.598709">
(Technische Universitat Berlin, Universitat Wuppertal, and IBM Deutschland GmbH)
</affiliation>
<bodyText confidence="0.72166975">
Berlin and Heidelberg: Springer-Verlag,
(Series Informatik Fachberichte 307,
edited by W. Brauer), 1992, x + 253 pp.
Paperbound, ISBN 0-387-55306-1
</bodyText>
<figure confidence="0.574485">
Reviewed by
John Bateman
GMD/Institut fiir integrierte Publikations- und Informationssysteme
and USC/Information Sciences Institute
</figure>
<bodyText confidence="0.994975821428572">
Running from 1985 to July 1990, IBM Germany&apos;s LILOG Project (LInguistic and LOG-
ical Methods and tools for the computational processing of German; Herzog and
Rollinger 1991) is one of the largest NLP projects carried out to date, involving exten-
sive (invited) cooperations between IBM and German universities (Hamburg, Stuttgart,
Osnabruck, Tubingen, SaarbrUcken, and Trier). The goal of the project was to produce
a system capable of &apos;understanding&apos; input texts and of demonstrating that under-
standing by answering questions. The selected domain of discourse was a tourist
information desk: the system was to accept as input texts concerning the center of
Dusseldorf and demonstrate its understanding of those texts by being able to answer
typical questions that visiting businesspeople might want to ask. A complete NLP sys-
tem such as this naturally involves practically every area of computational linguistics,
and the question of whether the project as a whole should be judged successful or not
is rather less interesting than the wealth and breadth of the issues addressed within
its subprojects. In particular, the book reviewed, Ontologie und Axiomatik der Wissens-
basis von LILOG (The Ontology and Axioms of the LILOG Knowledge Base), focuses
on two fundamental problems of NLP: the construction of knowledge bases for given
domains (termed &apos;knowledge engineering&apos;) and the establishment of principled con-
nections between such knowledge bases and language. The book is, therefore, very
timely. It relates directly to the concerns of the DARPA Knowledge Sharing Efforts
and to increasingly active discussions on general domain-independent &apos;ontologies&apos; for
organizing knowledge.
The book is a collection of 19 papers and commentaries (three in English, the
rest in German) on issues brought into focus during a LILOG-internal workshop on
ontology construction. The views presented are, accordingly, both historical—looking
back on the development of the knowledge base—and experimental—looking forward
to how the job could be done better. This is very valuable, escaping as it does from
the genre of &apos;result presentation&apos; where the major concern is to show how well a
particular project succeeded. Here we see behind the scenes a little, discovering how
the project developed, how decisions in different parts of the project had consequences
(often negative) for other parts of the project, and where different positions have been
taken by individuals and particular groups within the project as a whole. Thus, what
some might consider &apos;mistakes&apos; or &apos;failures&apos; are here often documented and openly
Computational Linguistics Volume 19, Number 3
discussed: a vital exercise for building on this work and for undertaking similar work
in the future. In many ways, what did not work proves itself to be more interesting
than the actual, often partial, solutions found (for example, under demo-stress!).
The contributions to the book are divided into four sections: aspects of knowledge
modeling in NLP systems; knowledge modeling and linguistic expression; knowledge
modeling and inference; and development and management of the knowledge base.
Appendices also contain the complete definition of the final ontology, the texts used
for bounding both the knowledge to be represented and the required linguistic com-
petence, and the syntax of the formalism used for representing the ontology, LLILOG.
Part 1 consists of papers by Klose and Pirlein, Lang (plus commentary from Sim-
mons), and von Luck. Klose and Pirlein give an overview of the modeling task under-
taken in LILOG, relating the task to the detailed scenario in which the resulting system
was to function. This scenario, together with the texts relevant for the scenario, per-
mits a broad classification of knowledge &apos;clusters&apos; that the knowledge representation
needs to cover: this includes space, objects, qualities, changes, energy and movement,
etc. An overview of the system architecture and a worked example of analysis show-
ing the use of the knowledge base is also presented. In its final state, the knowledge
base consisted of approximately 700 sort definitions plus 300 axioms allowing com-
plex inferences to be performed. The architecture as a whole then suggests three ways
in which the knowledge base can be evaluated: from the adequacy of the inferences
that the knowledge base axioms support, from the support for generation and analy-
sis that the knowledge base affords, and from its &apos;cognitive&apos; adequacy as a model of
possible cognitive representations. Each of these aspects is addressed by other papers
in the book. The paper by Lang is a very important paper for ontology design in
general; a shorter version of the paper appears (in English) in Lang&apos;s contribution to
the Herzog and Rollinger (1991) collection. Lang&apos;s basic point, building on a view of
semantics developed by Bierwisch and himself over many years, is that it is necessary
to maintain a sharp theoretical and practical distinction between linguistic knowl-
edge and conceptual knowledge; he also maintains that a genuine ontology should
be pitched at the conceptual, nonlinguistic level. He provides numerous examples of
how the final knowledge base of the LILOG system fails to separate these kinds of
knowledge, with the result that the sort hierarchy contains incompatible concept-types
that compromise inference capabilities and make a principled solution to the problem
of how to relate knowledge and language impossible. Whether one agrees with the
distinction that Lang argues for or not, any ontology constructed should be able to
meet his criticisms. Simmons&apos;s commentary on the paper further supports the lin-
guistic/nonlinguistic distinction with examples of the confusion that ensues when it
is not maintained. Von Luck&apos;s paper then attempts to demonstrate the value of em-
ploying &apos;naive theories&apos; of the commonsense world for both linguistic analysis (e.g.,
disambiguation) and for supporting inferencing in the domain.
Part 2 consists of papers by Maienborn (plus comments by Geurts, Gerstl, and
Lang), Novak, and Dobe. Maienborn&apos;s paper, although suggesting that it is concerned
with the &apos;cognitive&apos; adequacy of the knowledge representation, in fact presents more
linguistic evidence for the establishment of concepts in the ontology—in particular,
the distinction between &apos;states&apos; and &apos;events,&apos; the selection of thematic roles Agent and
Theme, and the use of a hierarchy of thematic roles. Contrasting the arguments given
here with those of Lang is interesting, since while both vigorously maintain that there
needs to be a sharp distinction between linguistic and nonlinguistic knowledge, the
motivations that Maienborn provides for ontological categories seem to me to fall
under what Lang would term linguistically motivated categories, which would not
then, by his definition, be judged ontological at all. Geurts then adds his voice to the
</bodyText>
<page confidence="0.973573">
540
</page>
<bodyText confidence="0.985830442307693">
Book Reviews
confusion by saying that he does not believe in the distinction between semantic and
conceptual information, although he is the only one in the book to take this position.
However, his reliance on the power of logical inference to handle the undifferentiated
mass of information that would result seems far removed from solving the everyday
problems of large-scale ontological engineering. Maienborn also complains about re-
strictions imposed on linguistic (cognitive?) theorizing by the computational properties
of the formalism available and Gerstl&apos;s commentary interprets this as symptomatic of
more-or-less fruitless discussions held between differing camps in AT in general and
LILOG in particular. Whereas the Lang/Bierwisch separation of linguistic and nonlin-
guistic information appears both linguistically important and practically useful, it also
provided a basis for the LILOG linguists and knowledge representation people not to
talk to one another. This is an especially unsatisfactory situation in an NLP system
where, as a number of papers in the book argue, the knowledge representation needs to
be &apos;linguistically responsible.&apos; The original specification of the LILOG project did not,
apparently, do enough to prevent this situation arising. The requirements of linguistic
responsibility are taken further in the papers of Novak and Dobe, who consider the
addition of text generation to LILOG&apos;s capabilities. This move was carried out rela-
tively late in the project as a whole, which created significant problems. Generation as
a task needs access to every type of information maintained in LILOG and makes its
own demands on that information. Novak points out that information concerning atti-
tudes and beliefs, rhetorical organization, hearer/reader models, etc., are lacking from
the knowledge base but are essential for generation. Moreover, the LILOG inference
engine and background knowledge can help in generation, but cannot solve questions
involving intentions, hearer models, and text structure. The ontology can also only
help if it encodes distinctions that are grammatically relevant, and the mixture of types
of concepts shown by Lang partly defeats this. Novak provides another perspective
on the mixture by mentioning the rather different expectations held by workers on
ontology depending on whether they are concerned with language or with knowledge
representation. The former expect a linguistically motivated classification; the latter a
theory of the commonsense world. These viewpoints only came to be combined late
in LILOG&apos;s development.
Part 3 contains papers by Simmons (in English) on modeling spatial knowledge,
Bollinger (plus comments by Rohrig and Neugebauer) on extensions to the formalism,
Lorenz on the temporal component of the ontology, and Ganger and Wachsmuth (plus
comments by Pirlein) on supporting inferences and flexible word choice by defining
appropriate axioms in the knowledge base. Simmons&apos;s paper is a very good short intro-
duction to the general theory of spatial representation presented in Lang, Carstensen,
and Simmons (1991), and also makes several important comments on ontology design.
The account will be of interest to anyone concerned with the representation of spatial
relationships and their linguistic expression. Lorenz uses the temporal component of
the ontology (which builds on accounts by Kamp, Allen, and Eberle) to illustrate some
practical problems in commonsense knowledge modeling. In particular, the conflation
of differing modeling strategies (e.g., shallow linguistically motivated categories and
deep semantic/logical modeling) inflates the number of concepts to the detriment of
the inferencing component. He shows that the very important work of consolidation
by which deeper modeling gradually weeds out previous less deep modeling is es-
sential; it is also generally disadvantageous to include too-shallow linguistically moti-
vated categories, since they prevent axioms being expressed with sufficient generality.
Ganger and Wachsmuth present a number of problems involved in modeling relations
between concepts that need to have connections between them to support the use of
related lexical items in question interpretation and answer generation. However, most
</bodyText>
<page confidence="0.990551">
541
</page>
<note confidence="0.658965">
Computational Linguistics Volume 19, Number 3
</note>
<bodyText confidence="0.999866960784314">
of the problems seem to arise from LILOG&apos;s methodology of separating the develop-
ment of the concept hierarchy and the inference rules; Pirlein&apos;s commentary shows
how adding to the concept hierarchy largely solves the problems discussed and thus
demonstrates that the concept hierarchy and the axioms should only be developed
together. He also describes this as another example of the desirability of taking the
linguistic capabilities required in a system seriously as constraints on what has to be
built in.
Part 4 contains papers by Gerstl (plus a commentary by Klose, Mezger, and Muller)
and Borkel. Gerstl describes problems that arise in developing and maintaining a
knowledge base when it grows to a significant size and undergoes modifications from
distributed working groups. He proposes that a project should have a manual for
knowledge engineering that sets out a protocol for making and commenting changes
that are made to the knowledge base, lays out standardized formats for information
display, etc. This is largely based on a systematization of the types of comments that
are usually made in any piece of software as it is developed. However, as Klose
et al. note in their commentary, the support that such a manual offers is quite weak,
and what is really necessary are support tools that allow high-level access to highly
interconnected data, with &apos;comments&apos; that are intended to be part of the discussion
of the development of the data automatically triggering electronic mail exchanges.
The state of knowledge-engineering support tools within LILOG only improved in
the latter half of the project with the move to more-graphical modes of interaction
and this alone, as Gerstl notes, already solved some of the development environment
problems. Finally, Borkel&apos;s paper shows something of the historical development of
proposed solutions to representational problems in LILOG, focusing on the influence
of the state of the implemented formalism and the modeling possibilities that that
state afforded. Also interesting here are the changes in status for various components
that he reports. For example, in the original LILOG plans the knowledge base had no
particular importance in its own right, compared to its role as a major component in
the second half of the project. Moreover, since the inference engine was not functional
in the early stages of the project, many of the concepts that were defined and their
related axioms could not be tested, often leaving them largely ad hoc. Partly as a
consequence of this, there was no re-use of the knowledge base from the first phase
of the project in the second phase.
The most important contribution of this book is to present a largely united front
concerning issues of design criteria for domain models and ontologies and issues of
the relationship between such bodies of knowledge and language. Based as it is on ex-
tensive practical efforts, the experiences reported here need to be seriously considered
by workers in this area. The papers by Lang and Simmons are particularly important
reading for ontology design and knowledge engineering. The book shows well that
mixing linguistic information with &apos;conceptual&apos; information leads to problems. Not so
clear is the precise nature of the levels of information required. But since this question
also lies at the center of all current discussions on ontology design, the book cannot be
faulted for failing to present a solution. There are also lessons to be drawn here for the
design of NLP systems in general. As made clear by the name of the LILOG project and
its original task specification, there was an emphasis at the outset on a rather narrow
kind of linguistics additionally subordinated to the task of extracting &apos;knowledge&apos; that
would support inferences. Thus there are extensive (and very valuable) treatments of
syntax and formalisms, a proposal for representing domain knowledge, and a rather
large gap in between. In relation to the state of knowledge today, as supported in this
book, we can see that there was an underestimation of the role of language in the
design of the system. There is no doubt still more organization to be imposed from
</bodyText>
<page confidence="0.986938">
542
</page>
<subsectionHeader confidence="0.754169">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.999505833333333">
language than has yet been teased out; for example, Novak&apos;s suggestion of construct-
ing an additional semantic &apos;ontology&apos; for the purposes of generation, in addition to
the conceptual ontology. The lack of less abstract linguistically motivated ontologies
that can mediate between the supposed cognitively relevant deep ontologies and sur-
face syntax is probably one source of continuing uncertainty over the levels required.
This makes it difficult to construct the required abstractions, as shown by the rather
small number of concepts (around 100) found in the final domain-independent part of
the knowledge base, the ontology proper. What is particularly valuable, however, is
the attempt to construct such representations on a realistic scale: this is a sure way to
lead us away from interminable discussions over theoretical possibilities and toward
genuine progress in both linguistic representations and domain modeling. As such,
the work reported in this book is to be highly commended.
</bodyText>
<reference confidence="0.702811363636364">
References G. (1991). Modeling Spatial Knowledge on a
Herzog, 0., and Rollinger, C.-R. (1991). Text Linguistic Basis: Theory—prototype—
Understanding in LILOG. (Lecture Notes in integration. (Lecture Notes in Artificial
Artificial Intelligence 546.) Springer-Verlag. Intelligence 481.) Springer-Verlag.
Lang, E., Carstensen, K.-U., and Simmons,
John Bateman completed his Ph.D. degree in Artificial Intelligence at the University of Edin-
burgh in 1985. He has since worked in all areas of text generation, including the construction
of linguistically motivated ontologies. He is currently project leader of the KOMET text gen-
eration project at IPSI, and is a project member on indefinite leave from the Penman project
at ISI. Bateman&apos;s address is: GMD/IPSI, Dolivostrasse 15, Darmstadt, Germany; e-mail: bate-
man@darmstadt.gmd.de.
</reference>
<page confidence="0.998661">
543
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.023794">
<note confidence="0.831558375">Ontologie und Axiomatik der Wissensbasis von LILOG Gudrun Klose, Ewald Lang, and Thomas Pirlein, editors (Technische Universitat Berlin, Universitat Wuppertal, and IBM Deutschland GmbH) Berlin and Heidelberg: Springer-Verlag, (Series Informatik Fachberichte 307, edited by W. Brauer), 1992, x + 253 pp. Paperbound, ISBN 0-387-55306-1 Reviewed by</note>
<author confidence="0.998274">John Bateman</author>
<abstract confidence="0.956845909090909">GMD/Institut fiir integrierte Publikationsund Informationssysteme and USC/Information Sciences Institute Running from 1985 to July 1990, IBM Germany&apos;s LILOG Project (LInguistic and LOGical Methods and tools for the computational processing of German; Herzog and Rollinger 1991) is one of the largest NLP projects carried out to date, involving extensive (invited) cooperations between IBM and German universities (Hamburg, Stuttgart, Osnabruck, Tubingen, SaarbrUcken, and Trier). The goal of the project was to produce a system capable of &apos;understanding&apos; input texts and of demonstrating that understanding by answering questions. The selected domain of discourse was a tourist information desk: the system was to accept as input texts concerning the center of Dusseldorf and demonstrate its understanding of those texts by being able to answer typical questions that visiting businesspeople might want to ask. A complete NLP system such as this naturally involves practically every area of computational linguistics, and the question of whether the project as a whole should be judged successful or not is rather less interesting than the wealth and breadth of the issues addressed within subprojects. In particular, the book reviewed, und Axiomatik der Wissensvon LILOG Ontology and Axioms of the LILOG Knowledge Base), focuses on two fundamental problems of NLP: the construction of knowledge bases for given domains (termed &apos;knowledge engineering&apos;) and the establishment of principled connections between such knowledge bases and language. The book is, therefore, very timely. It relates directly to the concerns of the DARPA Knowledge Sharing Efforts and to increasingly active discussions on general domain-independent &apos;ontologies&apos; for organizing knowledge. The book is a collection of 19 papers and commentaries (three in English, the rest in German) on issues brought into focus during a LILOG-internal workshop on ontology construction. The views presented are, accordingly, both historical—looking back on the development of the knowledge base—and experimental—looking forward to how the job could be done better. This is very valuable, escaping as it does from the genre of &apos;result presentation&apos; where the major concern is to show how well a particular project succeeded. Here we see behind the scenes a little, discovering how the project developed, how decisions in different parts of the project had consequences (often negative) for other parts of the project, and where different positions have been taken by individuals and particular groups within the project as a whole. Thus, what some might consider &apos;mistakes&apos; or &apos;failures&apos; are here often documented and openly Computational Linguistics Volume 19, Number 3 discussed: a vital exercise for building on this work and for undertaking similar work the future. In many ways, what proves itself to be more interesting than the actual, often partial, solutions found (for example, under demo-stress!). The contributions to the book are divided into four sections: aspects of knowledge modeling in NLP systems; knowledge modeling and linguistic expression; knowledge modeling and inference; and development and management of the knowledge base. Appendices also contain the complete definition of the final ontology, the texts used for bounding both the knowledge to be represented and the required linguistic comand the syntax of the formalism used for representing the LLILOG.</abstract>
<note confidence="0.642285">Part 1 consists of papers by Klose and Pirlein, Lang (plus commentary from Sim-</note>
<abstract confidence="0.992782280701754">mons), and von Luck. Klose and Pirlein give an overview of the modeling task undertaken in LILOG, relating the task to the detailed scenario in which the resulting system was to function. This scenario, together with the texts relevant for the scenario, permits a broad classification of knowledge &apos;clusters&apos; that the knowledge representation needs to cover: this includes space, objects, qualities, changes, energy and movement, etc. An overview of the system architecture and a worked example of analysis showing the use of the knowledge base is also presented. In its final state, the knowledge base consisted of approximately 700 sort definitions plus 300 axioms allowing complex inferences to be performed. The architecture as a whole then suggests three ways in which the knowledge base can be evaluated: from the adequacy of the inferences that the knowledge base axioms support, from the support for generation and analysis that the knowledge base affords, and from its &apos;cognitive&apos; adequacy as a model of possible cognitive representations. Each of these aspects is addressed by other papers in the book. The paper by Lang is a very important paper for ontology design in general; a shorter version of the paper appears (in English) in Lang&apos;s contribution to the Herzog and Rollinger (1991) collection. Lang&apos;s basic point, building on a view of Bierwisch and himself over many years, is that it is necessary to maintain a sharp theoretical and practical distinction between linguistic knowledge and conceptual knowledge; he also maintains that a genuine ontology should be pitched at the conceptual, nonlinguistic level. He provides numerous examples of how the final knowledge base of the LILOG system fails to separate these kinds of knowledge, with the result that the sort hierarchy contains incompatible concept-types that compromise inference capabilities and make a principled solution to the problem of how to relate knowledge and language impossible. Whether one agrees with the distinction that Lang argues for or not, any ontology constructed should be able to meet his criticisms. Simmons&apos;s commentary on the paper further supports the linguistic/nonlinguistic distinction with examples of the confusion that ensues when it is not maintained. Von Luck&apos;s paper then attempts to demonstrate the value of employing &apos;naive theories&apos; of the commonsense world for both linguistic analysis (e.g., disambiguation) and for supporting inferencing in the domain. Part 2 consists of papers by Maienborn (plus comments by Geurts, Gerstl, and Lang), Novak, and Dobe. Maienborn&apos;s paper, although suggesting that it is concerned with the &apos;cognitive&apos; adequacy of the knowledge representation, in fact presents more linguistic evidence for the establishment of concepts in the ontology—in particular, the distinction between &apos;states&apos; and &apos;events,&apos; the selection of thematic roles Agent and Theme, and the use of a hierarchy of thematic roles. Contrasting the arguments given here with those of Lang is interesting, since while both vigorously maintain that there needs to be a sharp distinction between linguistic and nonlinguistic knowledge, the motivations that Maienborn provides for ontological categories seem to me to fall under what Lang would term linguistically motivated categories, which would not then, by his definition, be judged ontological at all. Geurts then adds his voice to the 540 Book Reviews confusion by saying that he does not believe in the distinction between semantic and conceptual information, although he is the only one in the book to take this position. However, his reliance on the power of logical inference to handle the undifferentiated mass of information that would result seems far removed from solving the everyday problems of large-scale ontological engineering. Maienborn also complains about restrictions imposed on linguistic (cognitive?) theorizing by the computational properties of the formalism available and Gerstl&apos;s commentary interprets this as symptomatic of more-or-less fruitless discussions held between differing camps in AT in general and LILOG in particular. Whereas the Lang/Bierwisch separation of linguistic and nonlinguistic information appears both linguistically important and practically useful, it also provided a basis for the LILOG linguists and knowledge representation people not to talk to one another. This is an especially unsatisfactory situation in an NLP system where, as a number of papers in the book argue, the knowledge representation needs to be &apos;linguistically responsible.&apos; The original specification of the LILOG project did not, apparently, do enough to prevent this situation arising. The requirements of linguistic responsibility are taken further in the papers of Novak and Dobe, who consider the addition of text generation to LILOG&apos;s capabilities. This move was carried out relatively late in the project as a whole, which created significant problems. Generation as a task needs access to every type of information maintained in LILOG and makes its own demands on that information. Novak points out that information concerning attitudes and beliefs, rhetorical organization, hearer/reader models, etc., are lacking from the knowledge base but are essential for generation. Moreover, the LILOG inference engine and background knowledge can help in generation, but cannot solve questions involving intentions, hearer models, and text structure. The ontology can also only if it encodes distinctions that are and the mixture of types of concepts shown by Lang partly defeats this. Novak provides another perspective on the mixture by mentioning the rather different expectations held by workers on ontology depending on whether they are concerned with language or with knowledge representation. The former expect a linguistically motivated classification; the latter a theory of the commonsense world. These viewpoints only came to be combined late in LILOG&apos;s development. Part 3 contains papers by Simmons (in English) on modeling spatial knowledge, Bollinger (plus comments by Rohrig and Neugebauer) on extensions to the formalism, Lorenz on the temporal component of the ontology, and Ganger and Wachsmuth (plus comments by Pirlein) on supporting inferences and flexible word choice by defining appropriate axioms in the knowledge base. Simmons&apos;s paper is a very good short introduction to the general theory of spatial representation presented in Lang, Carstensen, and Simmons (1991), and also makes several important comments on ontology design. The account will be of interest to anyone concerned with the representation of spatial relationships and their linguistic expression. Lorenz uses the temporal component of the ontology (which builds on accounts by Kamp, Allen, and Eberle) to illustrate some practical problems in commonsense knowledge modeling. In particular, the conflation of differing modeling strategies (e.g., shallow linguistically motivated categories and deep semantic/logical modeling) inflates the number of concepts to the detriment of the inferencing component. He shows that the very important work of consolidation by which deeper modeling gradually weeds out previous less deep modeling is essential; it is also generally disadvantageous to include too-shallow linguistically motivated categories, since they prevent axioms being expressed with sufficient generality. Ganger and Wachsmuth present a number of problems involved in modeling relations between concepts that need to have connections between them to support the use of related lexical items in question interpretation and answer generation. However, most 541 Computational Linguistics Volume 19, Number 3 of the problems seem to arise from LILOG&apos;s methodology of separating the development of the concept hierarchy and the inference rules; Pirlein&apos;s commentary shows how adding to the concept hierarchy largely solves the problems discussed and thus demonstrates that the concept hierarchy and the axioms should only be developed together. He also describes this as another example of the desirability of taking the linguistic capabilities required in a system seriously as constraints on what has to be built in. Part 4 contains papers by Gerstl (plus a commentary by Klose, Mezger, and Muller) and Borkel. Gerstl describes problems that arise in developing and maintaining a knowledge base when it grows to a significant size and undergoes modifications from distributed working groups. He proposes that a project should have a manual for knowledge engineering that sets out a protocol for making and commenting changes that are made to the knowledge base, lays out standardized formats for information display, etc. This is largely based on a systematization of the types of comments that are usually made in any piece of software as it is developed. However, as Klose et al. note in their commentary, the support that such a manual offers is quite weak, and what is really necessary are support tools that allow high-level access to highly interconnected data, with &apos;comments&apos; that are intended to be part of the discussion of the development of the data automatically triggering electronic mail exchanges. The state of knowledge-engineering support tools within LILOG only improved in the latter half of the project with the move to more-graphical modes of interaction and this alone, as Gerstl notes, already solved some of the development environment problems. Finally, Borkel&apos;s paper shows something of the historical development of proposed solutions to representational problems in LILOG, focusing on the influence of the state of the implemented formalism and the modeling possibilities that that state afforded. Also interesting here are the changes in status for various components that he reports. For example, in the original LILOG plans the knowledge base had no particular importance in its own right, compared to its role as a major component in the second half of the project. Moreover, since the inference engine was not functional in the early stages of the project, many of the concepts that were defined and their related axioms could not be tested, often leaving them largely ad hoc. Partly as a consequence of this, there was no re-use of the knowledge base from the first phase of the project in the second phase. The most important contribution of this book is to present a largely united front concerning issues of design criteria for domain models and ontologies and issues of the relationship between such bodies of knowledge and language. Based as it is on extensive practical efforts, the experiences reported here need to be seriously considered by workers in this area. The papers by Lang and Simmons are particularly important reading for ontology design and knowledge engineering. The book shows well that mixing linguistic information with &apos;conceptual&apos; information leads to problems. Not so clear is the precise nature of the levels of information required. But since this question also lies at the center of all current discussions on ontology design, the book cannot be faulted for failing to present a solution. There are also lessons to be drawn here for the design of NLP systems in general. As made clear by the name of the LILOG project and its original task specification, there was an emphasis at the outset on a rather narrow kind of linguistics additionally subordinated to the task of extracting &apos;knowledge&apos; that would support inferences. Thus there are extensive (and very valuable) treatments of syntax and formalisms, a proposal for representing domain knowledge, and a rather large gap in between. In relation to the state of knowledge today, as supported in this book, we can see that there was an underestimation of the role of language in the design of the system. There is no doubt still more organization to be imposed from 542 Book Reviews language than has yet been teased out; for example, Novak&apos;s suggestion of constructing an additional semantic &apos;ontology&apos; for the purposes of generation, in addition to the conceptual ontology. The lack of less abstract linguistically motivated ontologies that can mediate between the supposed cognitively relevant deep ontologies and surface syntax is probably one source of continuing uncertainty over the levels required. This makes it difficult to construct the required abstractions, as shown by the rather number of concepts (around 100) found in the final of the knowledge base, the ontology proper. What is particularly valuable, however, is the attempt to construct such representations on a realistic scale: this is a sure way to lead us away from interminable discussions over theoretical possibilities and toward genuine progress in both linguistic representations and domain modeling. As such, the work reported in this book is to be highly commended. References (1991). Spatial Knowledge on a Linguistic Basis: Theory—prototype— Notes in Artificial Intelligence 481.) Springer-Verlag. 0., and Rollinger, C.-R. (1991). in LILOG. Notes in Artificial Intelligence 546.) Springer-Verlag. Lang, E., Carstensen, K.-U., and Simmons, Bateman his Ph.D. degree in Artificial Intelligence at the University of Edinburgh in 1985. He has since worked in all areas of text generation, including the construction of linguistically motivated ontologies. He is currently project leader of the KOMET text generation project at IPSI, and is a project member on indefinite leave from the Penman project at ISI. Bateman&apos;s address is: GMD/IPSI, Dolivostrasse 15, Darmstadt, Germany; e-mail: bateman@darmstadt.gmd.de.</abstract>
<intro confidence="0.785732">543</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C-R Rollinger</author>
</authors>
<title>Text Understanding in LILOG.</title>
<date>1991</date>
<journal>Lecture Notes in Artificial Intelligence</journal>
<volume>546</volume>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="651" citStr="Rollinger 1991" startWordPosition="85" endWordPosition="86"> der Wissensbasis von LILOG Gudrun Klose, Ewald Lang, and Thomas Pirlein, editors (Technische Universitat Berlin, Universitat Wuppertal, and IBM Deutschland GmbH) Berlin and Heidelberg: Springer-Verlag, (Series Informatik Fachberichte 307, edited by W. Brauer), 1992, x + 253 pp. Paperbound, ISBN 0-387-55306-1 Reviewed by John Bateman GMD/Institut fiir integrierte Publikations- und Informationssysteme and USC/Information Sciences Institute Running from 1985 to July 1990, IBM Germany&apos;s LILOG Project (LInguistic and LOGical Methods and tools for the computational processing of German; Herzog and Rollinger 1991) is one of the largest NLP projects carried out to date, involving extensive (invited) cooperations between IBM and German universities (Hamburg, Stuttgart, Osnabruck, Tubingen, SaarbrUcken, and Trier). The goal of the project was to produce a system capable of &apos;understanding&apos; input texts and of demonstrating that understanding by answering questions. The selected domain of discourse was a tourist information desk: the system was to accept as input texts concerning the center of Dusseldorf and demonstrate its understanding of those texts by being able to answer typical questions that visiting </context>
<context position="5252" citStr="Rollinger (1991)" startWordPosition="802" endWordPosition="803">x inferences to be performed. The architecture as a whole then suggests three ways in which the knowledge base can be evaluated: from the adequacy of the inferences that the knowledge base axioms support, from the support for generation and analysis that the knowledge base affords, and from its &apos;cognitive&apos; adequacy as a model of possible cognitive representations. Each of these aspects is addressed by other papers in the book. The paper by Lang is a very important paper for ontology design in general; a shorter version of the paper appears (in English) in Lang&apos;s contribution to the Herzog and Rollinger (1991) collection. Lang&apos;s basic point, building on a view of semantics developed by Bierwisch and himself over many years, is that it is necessary to maintain a sharp theoretical and practical distinction between linguistic knowledge and conceptual knowledge; he also maintains that a genuine ontology should be pitched at the conceptual, nonlinguistic level. He provides numerous examples of how the final knowledge base of the LILOG system fails to separate these kinds of knowledge, with the result that the sort hierarchy contains incompatible concept-types that compromise inference capabilities and m</context>
</contexts>
<marker>Rollinger, 1991</marker>
<rawString>References Herzog, 0., and Rollinger, C.-R. (1991). Text Understanding in LILOG. (Lecture Notes in Artificial Intelligence 546.) Springer-Verlag. Lang, E., Carstensen, K.-U., and Simmons, G. (1991). Modeling Spatial Knowledge on a Linguistic Basis: Theory—prototype— integration. (Lecture Notes in Artificial Intelligence 481.) Springer-Verlag.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>