<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.022861">
<title confidence="0.9979905">
Improving data-driven dependency parsing
using large-scale LFG grammars
</title>
<author confidence="0.999225">
Lilja Øvrelid, Jonas Kuhn and Kathrin Spreyer
</author>
<affiliation confidence="0.998072">
Department of Linguistics
University of Potsdam
</affiliation>
<email confidence="0.997987">
{lilja,kuhn,spreyer}@ling.uni-potsdam.de
</email>
<sectionHeader confidence="0.997377" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999982923076923">
This paper presents experiments which
combine a grammar-driven and a data-
driven parser. We show how the con-
version of LFG output to dependency
representation allows for a technique of
parser stacking, whereby the output of the
grammar-driven parser supplies features
for a data-driven dependency parser. We
evaluate on English and German and show
significant improvements stemming from
the proposed dependency structure as well
as various other, deep linguistic features
derived from the respective grammars.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999973857142857">
The divide between grammar-driven and data-
driven approaches to parsing has become less pro-
nounced in recent years due to extensive work on
robustness and efficiency for the grammar-driven
approaches (Riezler et al., 2002; Cahill et al.,
2008b). The linguistic generalizations captured in
such knowledge-based resources are thus increas-
ingly available for use in practical applications.
The NLP-community has in recent years wit-
nessed a surge of interest in dependency-based
approaches to syntactic parsing, spurred by the
CoNLL shared tasks of dependency parsing
(Buchholz and Marsi, 2006; Nivre et al., 2007).
Nivre and McDonald (2008) show how two differ-
ent approaches to dependency parsing, the graph-
based and transition-based approaches, may be
combined and subsequently learn to complement
each other to achieve improved parse results for a
range of different languages.
In this paper, we show how a data-driven depen-
dency parser may straightforwardly be modified to
learn directly from a grammar-driven parser. We
evaluate on English and German and show signifi-
cant improvements for both languages. Like Nivre
and McDonald (2008), we supply a data-driven
dependency parser with features from a different
parser to guide parsing. The additional parser em-
ployed in this work, is not however, a data-driven
parser trained on the same data set, but a grammar-
driven parser outputing a deep LFG analysis. We
furthermore show how a range of other features –
morphological, structural and semantic – from the
grammar-driven analysis may be employed dur-
ing data-driven parsing and lead to significant im-
provements.
</bodyText>
<sectionHeader confidence="0.848353" genericHeader="method">
2 Grammar-driven LFG-parsing
</sectionHeader>
<bodyText confidence="0.99995075">
The XLE system (Crouch et al., 2007) performs
unification-based parsing using hand-crafted LFG
grammars. It processes raw text and assigns to it
both a phrase-structural (‘c-structure’) and a fea-
ture structural, functional (‘f-structure’).
In the work described in this paper, we employ
the XLE platform using the grammars available
for English and German from the ParGram project
(Butt et al., 2002). In order to increase the cover-
age of the grammars, we employ the robustness
techniques of fragment parsing and ‘skimming’
available in XLE (Riezler et al., 2002).
</bodyText>
<sectionHeader confidence="0.9932855" genericHeader="method">
3 Dependency conversion and feature
extraction
</sectionHeader>
<bodyText confidence="0.999950833333333">
In extracting information from the output of the
deep grammars we wish to capture as much of the
precise, linguistic generalizations embodied in the
grammars as possible, whilst keeping with the re-
quirements posed by the dependency parser. The
process is illustrated in Figure 1.
</bodyText>
<subsectionHeader confidence="0.995224">
3.1 Data
</subsectionHeader>
<bodyText confidence="0.99994175">
The English data set consists of the Wall Street
Journal sections 2-24 of the Penn treebank (Mar-
cus et al., 1993), converted to dependency format.
The treebank data used for German is the Tiger
</bodyText>
<page confidence="0.996775">
37
</page>
<note confidence="0.9370545">
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 37–40,
Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP
</note>
<equation confidence="0.9487918125">
1
PRED ‘halte( . . . )’
VTYPE predicative
SUBJ “pro”
PRED ‘Verhalten’
CASE acc
OBJ SPEC f3( &amp;quot;das”
ADJUNCT { f4“damalige”}
f2 l
PRED ‘f¨ur( . . . �&apos;
PTYPE nosem
XCOMP-PRED IrPRED ‘richtig’�
OBJ [SUBJ J
f1
NK
SB
</equation>
<figureCaption confidence="0.998477">
Figure 1: Treebank enrichment with LFG output; German example: I consider the past behaviour cor-
</figureCaption>
<figure confidence="0.9642971875">
rect.
converted:
M
XCO
P-PRED
Ich halte das damalige Verhalten f¨ur richtig.
1sg pred. acc nosem
SUBJ
SPEC
ADJCT
SUBJ-OBJ
OBJ
OA
MO
NK
gold:
</figure>
<bodyText confidence="0.9898705">
treebank (Brants et al., 2004), where we employ
the version released with the CoNLL-X shared
task on dependency parsing (Buchholz and Marsi,
2006).
</bodyText>
<subsectionHeader confidence="0.997328">
3.2 LFG to dependency structure
</subsectionHeader>
<bodyText confidence="0.999988956521739">
We start out by converting the XLE output to a
dependency representation. This is quite straight-
forward since the f-structures produced by LFG
parsers can be interpreted as dependency struc-
tures. The conversion is performed by a set of
rewrite rules which are executed by XLE’s built-
in extraction engine. We employ two strategies for
the extraction of dependency structures from out-
put containing multiple heads. We attach the de-
pendent to the closest head and, i) label it with the
corresponding label (Single), ii) label it with the
complex label corresponding to the concatenation
of the labels from the multiple head attachments
(Complex). The converted dependency analysis in
Figure 1 shows the f-structure and the correspond-
ing converted dependency output of a German ex-
ample sentence, where a raised object Verhalten
receives the complex SUBJ-OBJ label. Following
the XLE-parsing of the treebanks and the ensu-
ing dependency conversion, we have agrammar-
based analysis for 95.2% of the English sentence,
45238 sentences altogether, and 96.5% of the Ger-
man sentences, 38189 sentences altogether.
</bodyText>
<subsectionHeader confidence="0.998111">
3.3 Deep linguistic features
</subsectionHeader>
<bodyText confidence="0.999841090909091">
The LFG grammars capture linguistic generaliza-
tions which may not be reduced to a dependency
representation. For instance, the grammars con-
tain information on morphosyntactic properties
such as case, gender and tense, as well as more se-
mantic properties detailing various types of adver-
bials, specifying semantic conceptual categories
such as human, time and location etc., see Fig-
ure 1. Table 1 presents the features extracted for
use during parsing from the German and English
XLE-parses.
</bodyText>
<sectionHeader confidence="0.986897" genericHeader="method">
4 Data-driven dependency parsing
</sectionHeader>
<bodyText confidence="0.999760222222222">
MaltParser (Nivre et al., 2006a) is a language-
independent system for data-driven dependency
parsing which is freely available.1 MaltParser is
based on a deterministic parsing strategy in com-
bination with treebank-induced classifiers for pre-
dicting parse transitions. MaltParser constructs
parsing as a set of transitions between parse con-
figurations. A parse configuration is a triple
(5, I, G), where 5 represents the parse stack, I is
the queue of remaining input tokens, and G repre-
sents the dependency graph defined thus far.
The feature model in MaltParser defines the rel-
evant attributes of tokens in a parse configuration.
Parse configurations are represented by a set of
features, which focus on attributes of the top of the
stack, the next input token and neighboring tokens
in the stack, input queue and dependency graph
under construction. Table 2 shows an example of
a feature model.2
For the training of baseline parsers we employ
feature models which make use of the word form
(FORM), part-of-speech (POS) and the dependency
relation (DEP) of a given token, exemplified in
Table 2. For the baseline parsers and all subse-
quent parsers we employ the arg-eager algorithm
in combination with SVM learners with a polyno-
mial kernel.3
</bodyText>
<note confidence="0.577339">
NK
</note>
<footnote confidence="0.998939272727273">
1http://maltparser.org
2Note that the feature model in Table 2 is an example fea-
ture model and not the actual model employed in the parse
experiments. The details or references for the English and
German models are provided below.
3For training of the baseline parsers we also em-
ploy some language-specific settings. For English we
use learner and parser settings, as well as feature model
from the English pretrained MaltParser-model available from
http://maltparser.org. For German, we use the learner and
parser settings from the parser employed in the CoNLL-X
</footnote>
<page confidence="0.991398">
38
</page>
<table confidence="0.999834">
POS XFeats
Verb CLAUSETYPE, GOVPREP, MOOD, PASSIVE, PERF,
TENSE, VTYPE
Noun CASE, COMMON, GOVPREP, LOCATIONTYPE, NUM,
NTYPE, PERS, PROPERTYPE
Pronoun CASE, GOVPREP, NUM, NTYPE, PERS
Prep PSEM, PTYPE
Conj COORD, COORD-FORM, COORD-LEVEL
Adv ADJUNCTTYPE, ADVTYPE
Adj ATYPE, DEGREE
English DEVERBAL, PROG, SUBCAT, GENDSEM, HUMAN,
German TIME
AUXSELECT, AUXFLIP, COHERENT, FUT, DEF, GEND,
GENITIVE, COUNT
</table>
<tableCaption confidence="0.9727075">
Table 1: Features from XLE output, common for
both languages and language-speciffic
</tableCaption>
<figure confidence="0.905371866666667">
FORM POS DEP XFEATS XDEP
S:top
I:next
I:next−1
G:head of top
G:leftmost dependent of top
InputArc(XHEAD)
+ + + + +
+ + + +
+ +
+ +
+ +
Table 2: Example feature model; S: stack, I: input,
G: graph; ±n = n positions to the left(−) or right
(+).
</figure>
<sectionHeader confidence="0.691043" genericHeader="method">
5 Parser stacking
</sectionHeader>
<bodyText confidence="0.9977792">
The procedure to enable the data-driven parser to
learn from the grammar-driven parser is quite sim-
ple. We parse a treebank with the XLE platform.
We then convert the LFG output to dependency
structures, so that we have two parallel versions
of the treebank – one gold standard and one with
LFG-annotation. We extend the gold standard
treebank with additional information from the cor-
responding LFG analysis, as illustrated by Figure
1 and train the data-driven dependency parser on
the enhanced data set.
We extend the feature model of the baseline
parsers in the same way as Nivre and McDon-
ald (2008). The example feature model in Table
2 shows how we add the proposed dependency
relation (XDEP) top and next as features for the
parser. We furthermore add a feature which looks
at whether there is an arc between these two tokens
in the dependency structure (InputArc(XHEAD)),
with three possible values: Left, Right, None. In
order to incorporate further information supplied
by the LFG grammars we extend the feature mod-
els with an additional, static attribute, XFEATS.
This is employed for the range of deep linguistic
features, detailed in section 3.3 above.
</bodyText>
<subsectionHeader confidence="0.992844">
5.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.993370714285714">
All parse experiments are performed using 10-fold
cross-validation for training and testing. Overall
parsing accuracy will be reported using the stan-
dard metrics of labeled attachment score (LAS)
and unlabeled attachment score (UAS).Statistical
significance is checked using Dan Bikel’s random-
ized parsing evaluation comparator.4
</bodyText>
<footnote confidence="0.950579">
shared task (Nivre et al., 2006b). For both languages, we em-
ploy so-called “relaxed” root handling.
4http://www.cis.upenn.edu/∼dbikel/software.html
</footnote>
<sectionHeader confidence="0.999586" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.968513594594595">
We experiment with the addition of two types of
features: i) the dependency structure proposed by
XLE for a given sentence ii) other morphosyntac-
tic, structural or lexical semantic features provided
by the XLE grammar. The results are presented in
Table 3.
For English, we find that the addition of pro-
posed dependency structure from the grammar-
driven parser causes a small, but significant im-
provement of results (p&lt;.0001). In terms of la-
beled accuracy the results improve with 0.15 per-
centage points, from 89.64 to 89.79. The introduc-
tion of complex dependency labels to account for
multiple heads in the LFG output causes a smaller
improvement of results than the single labeling
scheme. The corresponding results for German are
presented in Table 3. We find that the addition of
grammar-driven dependency structures with sin-
gle labels (Single) improves the parse results sig-
nificantly (p&lt;.0001), both in terms of unlabeled
and labeled accuracy. For labeled accuracy we ob-
serve an improvement of 1.45 percentage points,
from 85.97 to 87.42. For the German data, we
find that the addition of dependency structure with
complex labels (Complex) gives a further small,
but significant (p&lt;.03) improvement over the ex-
periment with single labels.
The results following the addition of the
grammar-extracted features in Table 1 (Feats) are
presented in Table 3.5 We observe significant im-
provements of overall parse results for both lan-
guages (p&lt;.0001).
5We experimented with several feature models for the in-
clusion of the additional information, however, found no sig-
nificant differences when performing a forward feature selec-
tion. The simple feature model simply adds the XFEATS of
the top and next tokens of the parse configuration.
</bodyText>
<page confidence="0.998341">
39
</page>
<table confidence="0.999365125">
English German
UAS LAS UAS LAS
Baseline 92.48 89.64 88.68 85.97
Single 92.61 89.79 89.72 87.42
Complex 92.58 89.74 89.76 87.46
Feats 92.55 89.77 89.63 87.30
Single+Feats 92.52 89.69 90.01 87.77
Complex+Feats 92.53 89.70 90.02 87.78
</table>
<tableCaption confidence="0.999595">
Table 3: Overall results in experiments expressed as unlabeled and labeled attachment scores.
</tableCaption>
<bodyText confidence="0.999947708333333">
We also investigated combinations of the dif-
ferent sources of information – dependency struc-
tures and deep features. These results are pre-
sented in the final lines of Table 3. We find
that for the English parser, the combination of
the features do not cause a further improve-
ment of results, compared to the individual ex-
periments. The combined experiments (Sin-
gle+Feats, Complex+Feats) for German, on the
other hand, differ significantly from the base-
line experiment, as well as the individual ex-
periments (Single,Complex,Feats) reported above
(p&lt;.0001). By combination of the grammar-
derived features we improve on the baseline by
1.81 percentage points.
A comparison with the German results obtained
using MaltParser with graph-based dependency
structures supplied by MSTParser (Nivre and Mc-
Donald, 2008) shows that our results using a
grammar-driven parser largely corroborate the ten-
dencies observed there. Our best results for Ger-
man, combining dependency structures and addi-
tional features, slightly improve on those reported
for MaltParser (by 0.11 percentage points).6
</bodyText>
<sectionHeader confidence="0.995738" genericHeader="conclusions">
7 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999982285714286">
This paper has presented experiments in the com-
bination of a grammar-driven LFG-parser and a
data-driven dependency parser. We have shown
how the use of converted dependency structures
in the training of a data-driven dependency parser,
MaltParser, causes significant improvements in
overall parse results for English and German. We
have furthermore presented a set of additional,
deep features which may straightforwardly be ex-
tracted from the grammar-based output and cause
individual improvements for both languages and a
combined effect for German.
In terms of future work, a more extensive er-
ror analysis will be performed to locate the pre-
</bodyText>
<footnote confidence="0.6847025">
6English was not among the languages investigated in-
Nivre and McDonald (2008).
</footnote>
<bodyText confidence="0.999682076923077">
cise benefits of the parser combination. We will
also investigate the application of the method di-
rectly to raw text and application to a task which
may benefit specifically from the combined anal-
yses, such as semantic role labeling or semantic
verb classification.
It has recently been shown that automatically
acquired LFG grammars may actually outperform
hand-crafted grammars in parsing (Cahill et al.,
2008a). These results add further to the relevance
of the results shown in this paper, bypassing the
bottleneck of grammar hand-crafting as a prereq-
uisite for the applicability of our results.
</bodyText>
<sectionHeader confidence="0.999457" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999774944444444">
Sabine Brants, Stefanie Dipper, Peter Eisenberg, Silvia Hansen-Schirra, Esther
Knig, Wolfgang Lezius, Christian Rohrer, George Smith, and Hans Uszko-
reit. 2004. Tiger: Linguistic interpretation of a German corpus. Research
on Language and Computation, 2:597–620.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilin-
gual dependency parsing. In Proceedings of CoNLL-X).
Miriam Butt, Helge Dyvik, Tracy Holloway King, Hiroshi Masuichi, and
Christian Rohrer. 2002. The Parallel Grammar Project. In Proceedings
of COLING-2002 Workshop on Grammar Engineering and Evaluation.
Aoife Cahill, Michael Burke, Ruth O’Donovan, Stefan Riezler, Josef van Gen-
abith, and Andy Way. 2008a. Wide-coverage deep statistical parsing using
automatic dependency structure annotation. Computational Linguistics.
Aoife Cahill, John T. Maxwell, Paul Meurer, Christian Rohrer, and Victoria
Rosen. 2008b. Speeding up LFG parsing using c-structure pruning. In
Proceedings of the Workshop on Grammar Engineering Across Frame-
works.
D. Crouch, M. Dalrymple, R. Kaplan, T. King, J. Maxwell, and P. Newman,
2007. XLE Documentation. http://www2.parc.com/isl/.
M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz. 1993. Building a large
annotated corpus for English: The Penn treebank. Computational Linguis-
tics, 19(2):313–330.
Joakim Nivre and Ryan McDonald. 2008. Integrating graph-based and
transition-based dependency parsers. In Proceedings ofACL-HLT 2008.
Joakim Nivre, Johan Hall, and Jens Nilsson. 2006a. Maltparser: A data-driven
parser-generator for dependency parsing. In Proceedings ofLREC.
Joakim Nivre, Jens Nilsson, Johan Hall, G¨uls¸en Eryiˇgit, and Svetoslav Mari-
nov. 2006b. Labeled pseudo-projective dependency parsing with Support
Vector Machines. In Proceedings of CoNLL.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Se-
bastian Riedel, and Deniz Yuret. 2007. CoNLL 2007 Shared Task on
Dependency Parsing. In Proceedings of the CoNLL Shared Task Session
ofEMNLP-CoNLL 2007, pages 915–932.
Stefan Riezler, Tracy King, Ronald Kaplan, Richard Crouch, John T. Maxwell,
and Mark Johnson. 2002. Parsing the Wall Street journal using a lexical-
functional grammar and discriminative estimation techniques. In Proceed-
ings ofACL.
</reference>
<page confidence="0.998636">
40
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.925424">
<title confidence="0.998248">Improving data-driven dependency parsing using large-scale LFG grammars</title>
<author confidence="0.998077">Lilja Øvrelid</author>
<author confidence="0.998077">Jonas Kuhn</author>
<author confidence="0.998077">Kathrin Spreyer</author>
<affiliation confidence="0.9992305">Department of Linguistics University of Potsdam</affiliation>
<abstract confidence="0.995068857142857">This paper presents experiments which combine a grammar-driven and a datadriven parser. We show how the conversion of LFG output to dependency representation allows for a technique of parser stacking, whereby the output of the grammar-driven parser supplies features for a data-driven dependency parser. We evaluate on English and German and show significant improvements stemming from the proposed dependency structure as well as various other, deep linguistic features derived from the respective grammars.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sabine Brants</author>
<author>Stefanie Dipper</author>
<author>Peter Eisenberg</author>
<author>Silvia Hansen-Schirra</author>
<author>Esther Knig</author>
<author>Wolfgang Lezius</author>
<author>Christian Rohrer</author>
<author>George Smith</author>
<author>Hans Uszkoreit</author>
</authors>
<title>Tiger: Linguistic interpretation of a German corpus.</title>
<date>2004</date>
<journal>Research on Language and Computation,</journal>
<pages>2--597</pages>
<contexts>
<context position="4086" citStr="Brants et al., 2004" startWordPosition="629" endWordPosition="632">the Tiger 37 Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 37–40, Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP 1 PRED ‘halte( . . . )’ VTYPE predicative SUBJ “pro” PRED ‘Verhalten’ CASE acc OBJ SPEC f3( &amp;quot;das” ADJUNCT { f4“damalige”} f2 l PRED ‘f¨ur( . . . �&apos; PTYPE nosem XCOMP-PRED IrPRED ‘richtig’� OBJ [SUBJ J f1 NK SB Figure 1: Treebank enrichment with LFG output; German example: I consider the past behaviour correct. converted: M XCO P-PRED Ich halte das damalige Verhalten f¨ur richtig. 1sg pred. acc nosem SUBJ SPEC ADJCT SUBJ-OBJ OBJ OA MO NK gold: treebank (Brants et al., 2004), where we employ the version released with the CoNLL-X shared task on dependency parsing (Buchholz and Marsi, 2006). 3.2 LFG to dependency structure We start out by converting the XLE output to a dependency representation. This is quite straightforward since the f-structures produced by LFG parsers can be interpreted as dependency structures. The conversion is performed by a set of rewrite rules which are executed by XLE’s builtin extraction engine. We employ two strategies for the extraction of dependency structures from output containing multiple heads. We attach the dependent to the closes</context>
</contexts>
<marker>Brants, Dipper, Eisenberg, Hansen-Schirra, Knig, Lezius, Rohrer, Smith, Uszkoreit, 2004</marker>
<rawString>Sabine Brants, Stefanie Dipper, Peter Eisenberg, Silvia Hansen-Schirra, Esther Knig, Wolfgang Lezius, Christian Rohrer, George Smith, and Hans Uszkoreit. 2004. Tiger: Linguistic interpretation of a German corpus. Research on Language and Computation, 2:597–620.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL-X).</booktitle>
<contexts>
<context position="1328" citStr="Buchholz and Marsi, 2006" startWordPosition="183" endWordPosition="186">respective grammars. 1 Introduction The divide between grammar-driven and datadriven approaches to parsing has become less pronounced in recent years due to extensive work on robustness and efficiency for the grammar-driven approaches (Riezler et al., 2002; Cahill et al., 2008b). The linguistic generalizations captured in such knowledge-based resources are thus increasingly available for use in practical applications. The NLP-community has in recent years witnessed a surge of interest in dependency-based approaches to syntactic parsing, spurred by the CoNLL shared tasks of dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). Nivre and McDonald (2008) show how two different approaches to dependency parsing, the graphbased and transition-based approaches, may be combined and subsequently learn to complement each other to achieve improved parse results for a range of different languages. In this paper, we show how a data-driven dependency parser may straightforwardly be modified to learn directly from a grammar-driven parser. We evaluate on English and German and show significant improvements for both languages. Like Nivre and McDonald (2008), we supply a data-driven dependency parser with feat</context>
<context position="4202" citStr="Buchholz and Marsi, 2006" startWordPosition="647" endWordPosition="650">st 2009. c�2009 ACL and AFNLP 1 PRED ‘halte( . . . )’ VTYPE predicative SUBJ “pro” PRED ‘Verhalten’ CASE acc OBJ SPEC f3( &amp;quot;das” ADJUNCT { f4“damalige”} f2 l PRED ‘f¨ur( . . . �&apos; PTYPE nosem XCOMP-PRED IrPRED ‘richtig’� OBJ [SUBJ J f1 NK SB Figure 1: Treebank enrichment with LFG output; German example: I consider the past behaviour correct. converted: M XCO P-PRED Ich halte das damalige Verhalten f¨ur richtig. 1sg pred. acc nosem SUBJ SPEC ADJCT SUBJ-OBJ OBJ OA MO NK gold: treebank (Brants et al., 2004), where we employ the version released with the CoNLL-X shared task on dependency parsing (Buchholz and Marsi, 2006). 3.2 LFG to dependency structure We start out by converting the XLE output to a dependency representation. This is quite straightforward since the f-structures produced by LFG parsers can be interpreted as dependency structures. The conversion is performed by a set of rewrite rules which are executed by XLE’s builtin extraction engine. We employ two strategies for the extraction of dependency structures from output containing multiple heads. We attach the dependent to the closest head and, i) label it with the corresponding label (Single), ii) label it with the complex label corresponding to </context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceedings of CoNLL-X).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
<author>Helge Dyvik</author>
<author>Tracy Holloway King</author>
<author>Hiroshi Masuichi</author>
<author>Christian Rohrer</author>
</authors>
<title>The Parallel Grammar Project.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING-2002 Workshop on Grammar Engineering and Evaluation.</booktitle>
<contexts>
<context position="2781" citStr="Butt et al., 2002" startWordPosition="409" endWordPosition="412">w how a range of other features – morphological, structural and semantic – from the grammar-driven analysis may be employed during data-driven parsing and lead to significant improvements. 2 Grammar-driven LFG-parsing The XLE system (Crouch et al., 2007) performs unification-based parsing using hand-crafted LFG grammars. It processes raw text and assigns to it both a phrase-structural (‘c-structure’) and a feature structural, functional (‘f-structure’). In the work described in this paper, we employ the XLE platform using the grammars available for English and German from the ParGram project (Butt et al., 2002). In order to increase the coverage of the grammars, we employ the robustness techniques of fragment parsing and ‘skimming’ available in XLE (Riezler et al., 2002). 3 Dependency conversion and feature extraction In extracting information from the output of the deep grammars we wish to capture as much of the precise, linguistic generalizations embodied in the grammars as possible, whilst keeping with the requirements posed by the dependency parser. The process is illustrated in Figure 1. 3.1 Data The English data set consists of the Wall Street Journal sections 2-24 of the Penn treebank (Marcus</context>
</contexts>
<marker>Butt, Dyvik, King, Masuichi, Rohrer, 2002</marker>
<rawString>Miriam Butt, Helge Dyvik, Tracy Holloway King, Hiroshi Masuichi, and Christian Rohrer. 2002. The Parallel Grammar Project. In Proceedings of COLING-2002 Workshop on Grammar Engineering and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aoife Cahill</author>
<author>Michael Burke</author>
<author>Ruth O’Donovan</author>
<author>Stefan Riezler</author>
<author>Josef van Genabith</author>
<author>Andy Way</author>
</authors>
<title>Wide-coverage deep statistical parsing using automatic dependency structure annotation. Computational Linguistics.</title>
<date>2008</date>
<marker>Cahill, Burke, O’Donovan, Riezler, van Genabith, Way, 2008</marker>
<rawString>Aoife Cahill, Michael Burke, Ruth O’Donovan, Stefan Riezler, Josef van Genabith, and Andy Way. 2008a. Wide-coverage deep statistical parsing using automatic dependency structure annotation. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aoife Cahill</author>
<author>John T Maxwell</author>
<author>Paul Meurer</author>
<author>Christian Rohrer</author>
<author>Victoria Rosen</author>
</authors>
<title>Speeding up LFG parsing using c-structure pruning.</title>
<date>2008</date>
<booktitle>In Proceedings of the Workshop on Grammar Engineering Across Frameworks.</booktitle>
<contexts>
<context position="981" citStr="Cahill et al., 2008" startWordPosition="134" endWordPosition="137">resentation allows for a technique of parser stacking, whereby the output of the grammar-driven parser supplies features for a data-driven dependency parser. We evaluate on English and German and show significant improvements stemming from the proposed dependency structure as well as various other, deep linguistic features derived from the respective grammars. 1 Introduction The divide between grammar-driven and datadriven approaches to parsing has become less pronounced in recent years due to extensive work on robustness and efficiency for the grammar-driven approaches (Riezler et al., 2002; Cahill et al., 2008b). The linguistic generalizations captured in such knowledge-based resources are thus increasingly available for use in practical applications. The NLP-community has in recent years witnessed a surge of interest in dependency-based approaches to syntactic parsing, spurred by the CoNLL shared tasks of dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). Nivre and McDonald (2008) show how two different approaches to dependency parsing, the graphbased and transition-based approaches, may be combined and subsequently learn to complement each other to achieve improved parse results f</context>
</contexts>
<marker>Cahill, Maxwell, Meurer, Rohrer, Rosen, 2008</marker>
<rawString>Aoife Cahill, John T. Maxwell, Paul Meurer, Christian Rohrer, and Victoria Rosen. 2008b. Speeding up LFG parsing using c-structure pruning. In Proceedings of the Workshop on Grammar Engineering Across Frameworks.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Crouch</author>
<author>M Dalrymple</author>
<author>R Kaplan</author>
<author>T King</author>
<author>J Maxwell</author>
<author>P Newman</author>
</authors>
<date>2007</date>
<note>XLE Documentation. http://www2.parc.com/isl/.</note>
<contexts>
<context position="2417" citStr="Crouch et al., 2007" startWordPosition="355" endWordPosition="358">ow significant improvements for both languages. Like Nivre and McDonald (2008), we supply a data-driven dependency parser with features from a different parser to guide parsing. The additional parser employed in this work, is not however, a data-driven parser trained on the same data set, but a grammardriven parser outputing a deep LFG analysis. We furthermore show how a range of other features – morphological, structural and semantic – from the grammar-driven analysis may be employed during data-driven parsing and lead to significant improvements. 2 Grammar-driven LFG-parsing The XLE system (Crouch et al., 2007) performs unification-based parsing using hand-crafted LFG grammars. It processes raw text and assigns to it both a phrase-structural (‘c-structure’) and a feature structural, functional (‘f-structure’). In the work described in this paper, we employ the XLE platform using the grammars available for English and German from the ParGram project (Butt et al., 2002). In order to increase the coverage of the grammars, we employ the robustness techniques of fragment parsing and ‘skimming’ available in XLE (Riezler et al., 2002). 3 Dependency conversion and feature extraction In extracting informatio</context>
</contexts>
<marker>Crouch, Dalrymple, Kaplan, King, Maxwell, Newman, 2007</marker>
<rawString>D. Crouch, M. Dalrymple, R. Kaplan, T. King, J. Maxwell, and P. Newman, 2007. XLE Documentation. http://www2.parc.com/isl/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus for English: The Penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="3395" citStr="Marcus et al., 1993" startWordPosition="509" endWordPosition="513"> 2002). In order to increase the coverage of the grammars, we employ the robustness techniques of fragment parsing and ‘skimming’ available in XLE (Riezler et al., 2002). 3 Dependency conversion and feature extraction In extracting information from the output of the deep grammars we wish to capture as much of the precise, linguistic generalizations embodied in the grammars as possible, whilst keeping with the requirements posed by the dependency parser. The process is illustrated in Figure 1. 3.1 Data The English data set consists of the Wall Street Journal sections 2-24 of the Penn treebank (Marcus et al., 1993), converted to dependency format. The treebank data used for German is the Tiger 37 Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 37–40, Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP 1 PRED ‘halte( . . . )’ VTYPE predicative SUBJ “pro” PRED ‘Verhalten’ CASE acc OBJ SPEC f3( &amp;quot;das” ADJUNCT { f4“damalige”} f2 l PRED ‘f¨ur( . . . �&apos; PTYPE nosem XCOMP-PRED IrPRED ‘richtig’� OBJ [SUBJ J f1 NK SB Figure 1: Treebank enrichment with LFG output; German example: I consider the past behaviour correct. converted: M XCO P-PRED Ich halte das damalige Verhalten f¨ur richtig. 1sg</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz. 1993. Building a large annotated corpus for English: The Penn treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Ryan McDonald</author>
</authors>
<title>Integrating graph-based and transition-based dependency parsers.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL-HLT</booktitle>
<contexts>
<context position="1376" citStr="Nivre and McDonald (2008)" startWordPosition="191" endWordPosition="194">between grammar-driven and datadriven approaches to parsing has become less pronounced in recent years due to extensive work on robustness and efficiency for the grammar-driven approaches (Riezler et al., 2002; Cahill et al., 2008b). The linguistic generalizations captured in such knowledge-based resources are thus increasingly available for use in practical applications. The NLP-community has in recent years witnessed a surge of interest in dependency-based approaches to syntactic parsing, spurred by the CoNLL shared tasks of dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). Nivre and McDonald (2008) show how two different approaches to dependency parsing, the graphbased and transition-based approaches, may be combined and subsequently learn to complement each other to achieve improved parse results for a range of different languages. In this paper, we show how a data-driven dependency parser may straightforwardly be modified to learn directly from a grammar-driven parser. We evaluate on English and German and show significant improvements for both languages. Like Nivre and McDonald (2008), we supply a data-driven dependency parser with features from a different parser to guide parsing. T</context>
<context position="9048" citStr="Nivre and McDonald (2008)" startWordPosition="1421" endWordPosition="1425">(+). 5 Parser stacking The procedure to enable the data-driven parser to learn from the grammar-driven parser is quite simple. We parse a treebank with the XLE platform. We then convert the LFG output to dependency structures, so that we have two parallel versions of the treebank – one gold standard and one with LFG-annotation. We extend the gold standard treebank with additional information from the corresponding LFG analysis, as illustrated by Figure 1 and train the data-driven dependency parser on the enhanced data set. We extend the feature model of the baseline parsers in the same way as Nivre and McDonald (2008). The example feature model in Table 2 shows how we add the proposed dependency relation (XDEP) top and next as features for the parser. We furthermore add a feature which looks at whether there is an arc between these two tokens in the dependency structure (InputArc(XHEAD)), with three possible values: Left, Right, None. In order to incorporate further information supplied by the LFG grammars we extend the feature models with an additional, static attribute, XFEATS. This is employed for the range of deep linguistic features, detailed in section 3.3 above. 5.1 Experimental setup All parse expe</context>
<context position="12991" citStr="Nivre and McDonald, 2008" startWordPosition="2029" endWordPosition="2033">nd that for the English parser, the combination of the features do not cause a further improvement of results, compared to the individual experiments. The combined experiments (Single+Feats, Complex+Feats) for German, on the other hand, differ significantly from the baseline experiment, as well as the individual experiments (Single,Complex,Feats) reported above (p&lt;.0001). By combination of the grammarderived features we improve on the baseline by 1.81 percentage points. A comparison with the German results obtained using MaltParser with graph-based dependency structures supplied by MSTParser (Nivre and McDonald, 2008) shows that our results using a grammar-driven parser largely corroborate the tendencies observed there. Our best results for German, combining dependency structures and additional features, slightly improve on those reported for MaltParser (by 0.11 percentage points).6 7 Conclusions and future work This paper has presented experiments in the combination of a grammar-driven LFG-parser and a data-driven dependency parser. We have shown how the use of converted dependency structures in the training of a data-driven dependency parser, MaltParser, causes significant improvements in overall parse r</context>
</contexts>
<marker>Nivre, McDonald, 2008</marker>
<rawString>Joakim Nivre and Ryan McDonald. 2008. Integrating graph-based and transition-based dependency parsers. In Proceedings ofACL-HLT 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Maltparser: A data-driven parser-generator for dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings ofLREC.</booktitle>
<contexts>
<context position="5919" citStr="Nivre et al., 2006" startWordPosition="914" endWordPosition="917">ences, 38189 sentences altogether. 3.3 Deep linguistic features The LFG grammars capture linguistic generalizations which may not be reduced to a dependency representation. For instance, the grammars contain information on morphosyntactic properties such as case, gender and tense, as well as more semantic properties detailing various types of adverbials, specifying semantic conceptual categories such as human, time and location etc., see Figure 1. Table 1 presents the features extracted for use during parsing from the German and English XLE-parses. 4 Data-driven dependency parsing MaltParser (Nivre et al., 2006a) is a languageindependent system for data-driven dependency parsing which is freely available.1 MaltParser is based on a deterministic parsing strategy in combination with treebank-induced classifiers for predicting parse transitions. MaltParser constructs parsing as a set of transitions between parse configurations. A parse configuration is a triple (5, I, G), where 5 represents the parse stack, I is the queue of remaining input tokens, and G represents the dependency graph defined thus far. The feature model in MaltParser defines the relevant attributes of tokens in a parse configuration. </context>
<context position="9995" citStr="Nivre et al., 2006" startWordPosition="1566" endWordPosition="1569">der to incorporate further information supplied by the LFG grammars we extend the feature models with an additional, static attribute, XFEATS. This is employed for the range of deep linguistic features, detailed in section 3.3 above. 5.1 Experimental setup All parse experiments are performed using 10-fold cross-validation for training and testing. Overall parsing accuracy will be reported using the standard metrics of labeled attachment score (LAS) and unlabeled attachment score (UAS).Statistical significance is checked using Dan Bikel’s randomized parsing evaluation comparator.4 shared task (Nivre et al., 2006b). For both languages, we employ so-called “relaxed” root handling. 4http://www.cis.upenn.edu/∼dbikel/software.html 6 Results We experiment with the addition of two types of features: i) the dependency structure proposed by XLE for a given sentence ii) other morphosyntactic, structural or lexical semantic features provided by the XLE grammar. The results are presented in Table 3. For English, we find that the addition of proposed dependency structure from the grammardriven parser causes a small, but significant improvement of results (p&lt;.0001). In terms of labeled accuracy the results improve</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2006</marker>
<rawString>Joakim Nivre, Johan Hall, and Jens Nilsson. 2006a. Maltparser: A data-driven parser-generator for dependency parsing. In Proceedings ofLREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
<author>Johan Hall</author>
<author>G¨uls¸en Eryiˇgit</author>
<author>Svetoslav Marinov</author>
</authors>
<title>Labeled pseudo-projective dependency parsing with Support Vector Machines.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL.</booktitle>
<marker>Nivre, Nilsson, Hall, Eryiˇgit, Marinov, 2006</marker>
<rawString>Joakim Nivre, Jens Nilsson, Johan Hall, G¨uls¸en Eryiˇgit, and Svetoslav Marinov. 2006b. Labeled pseudo-projective dependency parsing with Support Vector Machines. In Proceedings of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>Shared Task on Dependency Parsing.</title>
<date>2007</date>
<journal>CoNLL</journal>
<booktitle>In Proceedings of the CoNLL Shared Task Session ofEMNLP-CoNLL</booktitle>
<pages>915--932</pages>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. CoNLL 2007 Shared Task on Dependency Parsing. In Proceedings of the CoNLL Shared Task Session ofEMNLP-CoNLL 2007, pages 915–932.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Tracy King</author>
<author>Ronald Kaplan</author>
<author>Richard Crouch</author>
<author>John T Maxwell</author>
<author>Mark Johnson</author>
</authors>
<title>Parsing the Wall Street journal using a lexicalfunctional grammar and discriminative estimation techniques.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="960" citStr="Riezler et al., 2002" startWordPosition="130" endWordPosition="133">tput to dependency representation allows for a technique of parser stacking, whereby the output of the grammar-driven parser supplies features for a data-driven dependency parser. We evaluate on English and German and show significant improvements stemming from the proposed dependency structure as well as various other, deep linguistic features derived from the respective grammars. 1 Introduction The divide between grammar-driven and datadriven approaches to parsing has become less pronounced in recent years due to extensive work on robustness and efficiency for the grammar-driven approaches (Riezler et al., 2002; Cahill et al., 2008b). The linguistic generalizations captured in such knowledge-based resources are thus increasingly available for use in practical applications. The NLP-community has in recent years witnessed a surge of interest in dependency-based approaches to syntactic parsing, spurred by the CoNLL shared tasks of dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). Nivre and McDonald (2008) show how two different approaches to dependency parsing, the graphbased and transition-based approaches, may be combined and subsequently learn to complement each other to achieve imp</context>
<context position="2944" citStr="Riezler et al., 2002" startWordPosition="436" endWordPosition="439">to significant improvements. 2 Grammar-driven LFG-parsing The XLE system (Crouch et al., 2007) performs unification-based parsing using hand-crafted LFG grammars. It processes raw text and assigns to it both a phrase-structural (‘c-structure’) and a feature structural, functional (‘f-structure’). In the work described in this paper, we employ the XLE platform using the grammars available for English and German from the ParGram project (Butt et al., 2002). In order to increase the coverage of the grammars, we employ the robustness techniques of fragment parsing and ‘skimming’ available in XLE (Riezler et al., 2002). 3 Dependency conversion and feature extraction In extracting information from the output of the deep grammars we wish to capture as much of the precise, linguistic generalizations embodied in the grammars as possible, whilst keeping with the requirements posed by the dependency parser. The process is illustrated in Figure 1. 3.1 Data The English data set consists of the Wall Street Journal sections 2-24 of the Penn treebank (Marcus et al., 1993), converted to dependency format. The treebank data used for German is the Tiger 37 Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages</context>
</contexts>
<marker>Riezler, King, Kaplan, Crouch, Maxwell, Johnson, 2002</marker>
<rawString>Stefan Riezler, Tracy King, Ronald Kaplan, Richard Crouch, John T. Maxwell, and Mark Johnson. 2002. Parsing the Wall Street journal using a lexicalfunctional grammar and discriminative estimation techniques. In Proceedings ofACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>