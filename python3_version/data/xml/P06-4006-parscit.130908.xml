<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002816">
<title confidence="0.989276">
MIMA Search: A Structuring Knowledge System
towards Innovation for Engineering Education
</title>
<author confidence="0.993779">
Hideki Mima
</author>
<affiliation confidence="0.9828665">
School of Engineering
University of Tokyo
</affiliation>
<address confidence="0.890244">
Hongo 7-3-1, Bunkyo-ku, Tokyo 113-0033, Japan
</address>
<email confidence="0.954276">
mima@t-adm.t.u-tokyo.ac.jp
</email>
<sectionHeader confidence="0.992305" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999830761904762">
The main aim of the MIMA (Mining In-
formation for Management and Acquisi-
tion) Search System is to achieve ‘struc-
turing knowledge’ to accelerate knowl-
edge exploitation in the domains of sci-
ence and technology. This system inte-
grates natural language processing includ-
ing ontology development, information
retrieval, visualization, and database tech-
nology. The ‘structuring knowledge’ that
we define indicates 1) knowledge storage,
2) (hierarchical) classification of knowl-
edge, 3) analysis of knowledge, 4) visu-
alization of knowledge. We aim at inte-
grating different types of databases (pa-
pers and patents, technologies and innova-
tions) and knowledge domains, and simul-
taneously retrieving different types of
knowledge. Applications for the several
targets such as syllabus structuring will
also be mentioned.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999923939393939">
The growing number of electronically available
knowledge sources (KSs) emphasizes the impor-
tance of developing flexible and efficient tools for
automatic knowledge acquisition and structuring
in terms of knowledge integration. Different text
and literature mining techniques have been de-
veloped recently in order to facilitate efficient
discovery of knowledge contained in large textual
collections. The main goal of literature mining is
to retrieve knowledge that is “buried” in a text
and to present the distilled knowledge to users in
a concise form. Its advantage, compared to “man-
ual” knowledge discovery, is based on the as-
sumption that automatic methods are able to
process an enormous amount of text. It is doubt-
ful that any researcher could process such a huge
amount of information, especially if the knowl-
edge spans across domains. For these reasons,
literature mining aims at helping scientists in col-
lecting, maintaining, interpreting and curating
information.
In this paper, we introduce a knowledge struc-
turing system (KSS) we designed, in which ter-
minology-driven knowledge acquisition (KA),
knowledge retrieval (KR) and knowledge visuali-
zation (KV) are combined using automatic term
recognition, automatic term clustering and termi-
nology-based similarity calculation is explained.
The system incorporates our proposed automatic
term recognition / clustering and a visualization
of retrieved knowledge based on the terminology,
which allow users to access KSs visually though
sophisticated GUIs.
</bodyText>
<sectionHeader confidence="0.538718" genericHeader="method">
2 Overview of the system
</sectionHeader>
<bodyText confidence="0.9998662">
The main purpose of the knowledge structuring
system is 1) accumulating knowledge in order to
develop huge knowledge bases, 2) exploiting the
accumulated knowledge efficiently. Our approach
to structuring knowledge is based on:
</bodyText>
<listItem confidence="0.995154333333333">
• automatic term recognition (ATR)
• automatic term clustering (ATC) as an ontol-
ogy1 development
• ontology-based similarity calculation
• visualization of relationships among docu-
ments (KSs)
</listItem>
<bodyText confidence="0.992645545454546">
One of our definitions to structuring knowledge is
discovery of relevance between documents (KSs)
and its visualization. In order to achieve real time
processing for structuring knowledge, we adopt
terminology / ontology-based similarity calcula-
tion, because knowledge can also be represented
as textual documents or passages (e.g. sentences,
subsections) which are efficiently characterized
by sets of specialized (technical) terms. Further
details of our visualization scheme will be men-
tioned in Section 4.
</bodyText>
<footnote confidence="0.98928375">
1 Although, definition of ontology is domain-
specific, our definition of ontology is the collection
and classification of (technical) terms to recognize
their semantic relevance.
</footnote>
<page confidence="0.994005">
21
</page>
<bodyText confidence="0.369339">
Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, pages 21–24,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</bodyText>
<figure confidence="0.999214357142857">
B
r
o
w
s
e
r
G
U
I
Browser
Interface
Summarizer
Similarity
Graph
Visualizer
Document
Viewer
Similarity Processing Ontology Development
クラスタ
エンジンSimilarity
Calculation
Engine
Similarity
Manager
Knowledge
Retriever
Ontology Information
Database
Ontology Data
Manager
Knowledge Data
Manager
Ontology
Development
Engine
Database
Data Reader
PDF,
XML, CSV
Word, HTML,
KSs
</figure>
<figureCaption confidence="0.999998">
Figure 1: The system architecture
</figureCaption>
<bodyText confidence="0.982086259259259">
The system architecture is modular, and it inte-
grates the following components (Figure 1):
— Ontology Development Engine(s) (ODE) –
components that carry out the automatic ontol-
ogy development which includes recognition
and structuring of domain terminology;
— Knowledge Data Manager (KDM) – stores in-
dex of KSs and ontology in a ontology informa-
tion database (OID) and provides the corre-
sponding interface;
— Knowledge Retriever (KR) – retrieves KSs from
TID and calculates similarities between key-
words and KSs. Currently, we adopt tf*idf
based similarity calculation;
— Similarity Calculation Engine(s) (SCE) – calcu-
late similarities between KSs provided from KR
component using ontology developed by ODE
in order to show semantic similarities between
each KSs. We adopt Vector Space Model
(VSM) based similarity calculation and use
terms as features of VSM. Semantic clusters of
KSs are also provided.
— Graph Visualizer – visualizes knowledge struc-
tures based on graph expression in which rele-
vance links between provided keywords and
KSs, and relevance links between the KSs
themselves can be shown.
</bodyText>
<sectionHeader confidence="0.5916135" genericHeader="method">
3 Terminological processing as an ontol-
ogy development
</sectionHeader>
<bodyText confidence="0.999864346153846">
The lack of clear naming standards in a domain
(e.g. biomedicine) makes ATR a non-trivial prob-
lem (Fukuda et al., 1998). Also, it typically gives
rise to many-to-many relationships between terms
and concepts. In practice, two problems stem
from this fact: 1) there are terms that have multi-
ple meanings (term ambiguity), and, conversely,
2) there are terms that refer to the same concept
(term variation). Generally, term ambiguity has
negative effects on IE precision, while term varia-
tion decreases IE recall. These problems show the
difficulty of using simple keyword-based IE
techniques. Obviously, more sophisticated tech-
niques, identifying groups of different
terms referring to the same (or similar)
concept(s), and, therefore, could benefit
from relying on efficient and consistent
ATR/ATC and term variation manage-
ment methods are required. These meth-
ods are also important for organising do-
main specific knowledge, as terms should
not be treated isolated from other terms.
They should rather be related to one an-
other so that the relations existing between
the corresponding concepts are at least
partly reflected in a terminology.
</bodyText>
<subsectionHeader confidence="0.994337">
3.1 Term recognition
</subsectionHeader>
<bodyText confidence="0.999994583333333">
The ATR method used in the system is based on
the C / NC-value methods (Mima et al., 2001;
Mima and Ananiadou, 2001). The C-value
method recognizes terms by combining linguistic
knowledge and statistical analysis. The method
extracts multi-word terms2 and is not limited to a
specific class of concepts. It is implemented as a
two-step procedure. In the first step, term candi-
dates are extracted by using a set of linguistic fil-
ters which describe general term formation pat-
terns. In the second step, the term candidates are
assigned termhood scores (referred to as C-
values) according to a statistical measure. The
measure amalgamates four numerical corpus-
based characteristics of a candidate term, namely
the frequency of occurrence, the frequency of
occurrence as a substring of other candidate terms,
the number of candidate terms containing the
given candidate term as a substring, and the num-
ber of words contained in the candidate term.
The NC-value method further improves the C-
value results by taking into account the context of
candidate terms. The relevant context words are
extracted and assigned weights based on how fre-
quently they appear with top-ranked term candi-
dates extracted by the C-value method. Subse-
quently, context factors are assigned to candidate
terms according to their co-occurrence with top-
ranked context words. Finally, new termhood es-
timations, referred to as NC-values, are calculated
as a linear combination of the C-values and con-
text factors for the respective terms. Evaluation of
the C/NC-methods (Mima and Ananiadou, 2001)
has shown that contextual information improves
term distribution in the extracted list by placing
real terms closer to the top of the list.
</bodyText>
<footnote confidence="0.6699525">
2 More than 85% of domain-specific terms are multi-word
terms (Mima and Ananiadou, 2001).
</footnote>
<page confidence="0.996422">
22
</page>
<subsectionHeader confidence="0.94902">
3.2 Term variation management
</subsectionHeader>
<bodyText confidence="0.999881171428571">
Term variation and ambiguity are causing prob-
lems not only for ATR but for human experts as
well. Several methods for term variation man-
agement have been developed. For example, the
BLAST system Krauthammer et al., 2000) used
approximate text string matching techniques and
dictionaries to recognize spelling variations in
gene and protein names. FASTR (Jacquemin,
2001) handles morphological and syntactic varia-
tions by means of meta-rules used to describe
term normalization, while semantic variants are
handled via WordNet.
The basic C-value method has been enhanced
by term variation management (Mima and
Ananiadou, 2001). We consider a variety of
sources from which term variation problems
originate. In particular, we deal with orthographi-
cal, morphological, syntactic, lexico-semantic and
pragmatic phenomena. Our approach to term
variation management is based on term normali-
zation as an integral part of the ATR process.
Term variants (i.e. synonymous terms) are dealt
with in the initial phase of ATR when term can-
didates are singled out, as opposed to other ap-
proaches (e.g. FASTR handles variants subse-
quently by applying transformation rules to ex-
tracted terms). Each term variant is normalized
(see table 1 as an example) and term variants hav-
ing the same normalized form are then grouped
into classes in order to link each term candidate to
all of its variants. This way, a list of normalized
term candidate classes, rather than a list of single
terms is statistically processed. The termhood is
then calculated for a whole class of term variants,
not for each term variant separately.
</bodyText>
<tableCaption confidence="0.6682175">
Table 1: Automatic term normalization
Term variants Normalised term
</tableCaption>
<bodyText confidence="0.510927">
}→ human cancer
</bodyText>
<subsectionHeader confidence="0.997121">
3.3 Term clustering
</subsectionHeader>
<bodyText confidence="0.999939090909091">
Beside term recognition, term clustering is an
indispensable component of the literature mining
process. Since terminological opacity and
polysemy are very common in molecular biology
and biomedicine, term clustering is essential for
the semantic integration of terms, the construction
of domain ontologies and semantic tagging.
ATC in our system is performed using a hierar-
chical clustering method in which clusters are
merged based on average mutual information
measuring how strongly terms are related to one
</bodyText>
<figure confidence="0.940186">
Input documents
</figure>
<figureCaption confidence="0.999629">
Figure 2: Ontology development
</figureCaption>
<bodyText confidence="0.999721">
another (Ushioda, 1996). Terms automatically
recognized by the NC-value method and their co-
occurrences are used as input, and a dendrogram
of terms is produced as output. Parallel symmet-
ric processing is used for high-speed clustering.
The calculated term cluster information is en-
coded and used for calculating semantic similari-
ties in SCE component. More precisely, the simi-
larity between two individual terms is determined
according to their position in a dendrogram. Also
a commonality measure is defined as the number
of shared ancestors between two terms in the
dendrogram, and a positional measure as a sum of
their distances from the root. Similarity between
two terms corresponds to a ratio between com-
monality and positional measure.
Further details of the methods and their evalua-
tions can be referred in (Mima et al., 2001; Mima
and Ananiadou, 2001).
</bodyText>
<sectionHeader confidence="0.904422" genericHeader="method">
4 Structuring knowledge
</sectionHeader>
<bodyText confidence="0.999979888888889">
Structuring knowledge can be regarded as a
broader approach to IE/KA. IE and KA in our
system are implemented through the integration
of ATR, ATC, and ontology-based semantic simi-
larity calculation. Graph-based visualization for
globally structuring knowledge is also provided
to facilitate KR and KA from documents. Addi-
tionally, the system supports combining different
databases (papers and patents, technologies and
innovations) and retrieves different types of
knowledge simultaneously and crossly. This fea-
ture can accelerate knowledge discovery by com-
bining existing knowledge. For example, discov-
ering new knowledge on industrial innovation by
structuring knowledge of trendy scientific paper
database and past industrial innovation report da-
tabase can be expected. Figure 3 shows an exam-
ple of visualization of knowledge structures in the
</bodyText>
<figure confidence="0.997836052631579">
X M L documents including
te r m ta g s a n d te rm
v a ria tio n /c la ss information
Orthographic variants
Acronym recognition
M orphological variants
Syntactic variants
Term clustering
NC-value ATR
C-value ATR
POS tagger
Recognition
o f term s
Structuring
o f term s
human cancers
cancer in humans
human’s cancer
human carcinoma
</figure>
<page confidence="0.994934">
23
</page>
<bodyText confidence="0.999472714285714">
domain of engineering. In order to structure
knowledge, the system draws a graph in which
nodes indicate relevant KSs to keywords given
and each links between KSs indicates semantic
similarities dynamically calculated using ontol-
ogy information developed by our ATR / ATC
components.
</bodyText>
<figureCaption confidence="0.993945">
Figure 3: Visualization
</figureCaption>
<sectionHeader confidence="0.99834" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999911735294117">
In this paper, we presented a system for structur-
ing knowledge over large KSs. The system is a
terminology-based integrated KA system, in
which we have integrated ATR, ATC, IR, simi-
larity calculation, and visualization for structuring
knowledge. It allows users to search and combine
information from various sources. KA within the
system is terminology-driven, with terminology
information provided automatically. Similarity
based knowledge retrieval is implemented
through various semantic similarity calculations,
which, in combination with hierarchical, ontol-
ogy- based matching, offers powerful means for
KA through visualization-based literature mining.
We have applied the system to syllabus re-
trieval for The University of Tokyo`s Open
Course Ware (UT-OCW)3 site and syllabus struc-
turing (SS) site4 for school / department of engi-
neering at University of Tokyo, and they are both
available in public over the Internet. The UT-
OCW’s MIMA Search system is designed to
search the syllabuses of courses posted on the
UT-OCW site and the Massachusetts Institute of
Technology&apos;s OCW site (MIT-OCW). Also, the
SS site’s MIMA Search is designed to search the
syllabuses of lectures from more than 1,600 lec-
tures in school / department of engineering at
University of Tokyo. Both systems show search
results in terms of relations among the syllabuses
as a structural graphic (figure 3). Based on the
automatically extracted terms from the syllabuses
and similarities calculated using those terms,
MIMA Search displays the search results in a
network format, using dots and lines. Namely,
</bodyText>
<footnote confidence="0.970562">
3 http://ocw.u-tokyo.ac.jp/.
4 http://ciee.t.u-tokyo.ac.jp/.
</footnote>
<bodyText confidence="0.999755515151515">
MIMA Search extracts the contents from the
listed syllabuses, rearrange these syllabuses ac-
cording to semantic relations of the contents and
display the results graphically, whereas conven-
tional search engines simply list the syllabuses
that are related to the keywords. Thanks to this
process, we believe users are able to search for
key information and obtain results in minimal
time. In graphic displays, as already mentioned,
the searched syllabuses are shown in a structural
graphic with dots and lines. The stronger the se-
mantic relations of the syllabuses, the closer they
are placed on the graphic. This structure will help
users find a group of courses / lectures that are
closely related in contents, or take courses / lec-
tures in a logical order, for example, beginning
with fundamental mathematics and going on to
applied mathematics. Furthermore, because of the
structural graphic display, users will be able to
instinctively find the relations among syllabuses
of other universities.
Currently, we obtain more than 2,000 hits per
day in average from all over the world, and have
provided more then 50,000 page views during last
three months. On the other hand, we are in a
process of system evaluation using more than 40
students to evaluate usability as a next generation
information retrieval.
The other experiments we conducted also show
that the system’s knowledge structuring scheme
is an efficient methodology to facilitate KA and
new knowledge discovery in the field of genome
and nano-technology (Mima et al., 2001).
</bodyText>
<sectionHeader confidence="0.998627" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.986677909090909">
K. Fukuda, T. Tsunoda, A. Tamura, T. Takagi, 1998.
Toward information extraction: identifying protein
names from biological papers, Proc. of PSB-98,
Hawaii, pp. 3:705-716.
H. Mima, S. Ananiadou, G. Nenadic, 2001. ATRACT
workbench: an automatic term recognition and clus-
tering of terms, in: V. Matoušek, P. Mautner, R.
Mouček, K. Taušer (Eds.) Text, Speech and Dia-
logue, LNAI 2166, Springer Verlag, pp. 126-133.
H. Mima, S. Ananiadou, 2001. An application and
evaluation of the C/NC-value approach for the
automatic term recognition of multi-word units in
Japanese, Int. J. on Terminology 6/2, pp. 175-194.
M. Krauthammer, A. Rzhetsky, P. Morozov, C.
Friedman, 2000. Using BLAST for identifying gene
and protein names in journal articles, in: Gene 259,
pp. 245-252.
C. Jacquemin, 2001. Spotting and discovering terms
through NLP, MIT Press, Cambridge MA, p. 378.
A. Ushioda, 1996. Hierarchical clustering of words,
Proc. of COLING ’96, Copenhagen, Denmark, pp.
1159-1162.
</reference>
<page confidence="0.999178">
24
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.886189">
<title confidence="0.997462">MIMA Search: A Structuring Knowledge System towards Innovation for Engineering Education</title>
<author confidence="0.984693">Hideki Mima</author>
<affiliation confidence="0.9998085">School of Engineering University of Tokyo</affiliation>
<address confidence="0.944586">Hongo 7-3-1, Bunkyo-ku, Tokyo 113-0033, Japan</address>
<email confidence="0.977256">mima@t-adm.t.u-tokyo.ac.jp</email>
<abstract confidence="0.998740772727273">The main aim of the MIMA (Mining Information for Management and Acquisition) Search System is to achieve ‘structuring knowledge’ to accelerate knowledge exploitation in the domains of science and technology. This system integrates natural language processing including ontology development, information retrieval, visualization, and database technology. The ‘structuring knowledge’ that we define indicates 1) knowledge storage, 2) (hierarchical) classification of knowledge, 3) analysis of knowledge, 4) visualization of knowledge. We aim at integrating different types of databases (papers and patents, technologies and innovations) and knowledge domains, and simultaneously retrieving different types of knowledge. Applications for the several targets such as syllabus structuring will also be mentioned.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Fukuda</author>
<author>T Tsunoda</author>
<author>A Tamura</author>
<author>T Takagi</author>
</authors>
<title>Toward information extraction: identifying protein names from biological papers,</title>
<date>1998</date>
<booktitle>Proc. of PSB-98,</booktitle>
<pages>3--705</pages>
<location>Hawaii,</location>
<contexts>
<context position="5529" citStr="Fukuda et al., 1998" startWordPosition="803" endWordPosition="806">om KR component using ontology developed by ODE in order to show semantic similarities between each KSs. We adopt Vector Space Model (VSM) based similarity calculation and use terms as features of VSM. Semantic clusters of KSs are also provided. — Graph Visualizer – visualizes knowledge structures based on graph expression in which relevance links between provided keywords and KSs, and relevance links between the KSs themselves can be shown. 3 Terminological processing as an ontology development The lack of clear naming standards in a domain (e.g. biomedicine) makes ATR a non-trivial problem (Fukuda et al., 1998). Also, it typically gives rise to many-to-many relationships between terms and concepts. In practice, two problems stem from this fact: 1) there are terms that have multiple meanings (term ambiguity), and, conversely, 2) there are terms that refer to the same concept (term variation). Generally, term ambiguity has negative effects on IE precision, while term variation decreases IE recall. These problems show the difficulty of using simple keyword-based IE techniques. Obviously, more sophisticated techniques, identifying groups of different terms referring to the same (or similar) concept(s), </context>
</contexts>
<marker>Fukuda, Tsunoda, Tamura, Takagi, 1998</marker>
<rawString>K. Fukuda, T. Tsunoda, A. Tamura, T. Takagi, 1998. Toward information extraction: identifying protein names from biological papers, Proc. of PSB-98, Hawaii, pp. 3:705-716.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Mima</author>
<author>S Ananiadou</author>
<author>G Nenadic</author>
</authors>
<title>ATRACT workbench: an automatic term recognition and clustering of terms, in:</title>
<date>2001</date>
<pages>126--133</pages>
<publisher>Springer Verlag,</publisher>
<contexts>
<context position="6662" citStr="Mima et al., 2001" startWordPosition="981" endWordPosition="984">dentifying groups of different terms referring to the same (or similar) concept(s), and, therefore, could benefit from relying on efficient and consistent ATR/ATC and term variation management methods are required. These methods are also important for organising domain specific knowledge, as terms should not be treated isolated from other terms. They should rather be related to one another so that the relations existing between the corresponding concepts are at least partly reflected in a terminology. 3.1 Term recognition The ATR method used in the system is based on the C / NC-value methods (Mima et al., 2001; Mima and Ananiadou, 2001). The C-value method recognizes terms by combining linguistic knowledge and statistical analysis. The method extracts multi-word terms2 and is not limited to a specific class of concepts. It is implemented as a two-step procedure. In the first step, term candidates are extracted by using a set of linguistic filters which describe general term formation patterns. In the second step, the term candidates are assigned termhood scores (referred to as Cvalues) according to a statistical measure. The measure amalgamates four numerical corpusbased characteristics of a candid</context>
<context position="11496" citStr="Mima et al., 2001" startWordPosition="1738" endWordPosition="1741">-speed clustering. The calculated term cluster information is encoded and used for calculating semantic similarities in SCE component. More precisely, the similarity between two individual terms is determined according to their position in a dendrogram. Also a commonality measure is defined as the number of shared ancestors between two terms in the dendrogram, and a positional measure as a sum of their distances from the root. Similarity between two terms corresponds to a ratio between commonality and positional measure. Further details of the methods and their evaluations can be referred in (Mima et al., 2001; Mima and Ananiadou, 2001). 4 Structuring knowledge Structuring knowledge can be regarded as a broader approach to IE/KA. IE and KA in our system are implemented through the integration of ATR, ATC, and ontology-based semantic similarity calculation. Graph-based visualization for globally structuring knowledge is also provided to facilitate KR and KA from documents. Additionally, the system supports combining different databases (papers and patents, technologies and innovations) and retrieves different types of knowledge simultaneously and crossly. This feature can accelerate knowledge discov</context>
</contexts>
<marker>Mima, Ananiadou, Nenadic, 2001</marker>
<rawString>H. Mima, S. Ananiadou, G. Nenadic, 2001. ATRACT workbench: an automatic term recognition and clustering of terms, in: V. Matoušek, P. Mautner, R. Mouček, K. Taušer (Eds.) Text, Speech and Dialogue, LNAI 2166, Springer Verlag, pp. 126-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Mima</author>
<author>S Ananiadou</author>
</authors>
<title>An application and evaluation of the C/NC-value approach for the automatic term recognition of multi-word units in Japanese,</title>
<date>2001</date>
<journal>Int. J. on Terminology</journal>
<volume>6</volume>
<pages>175--194</pages>
<contexts>
<context position="6689" citStr="Mima and Ananiadou, 2001" startWordPosition="985" endWordPosition="988">f different terms referring to the same (or similar) concept(s), and, therefore, could benefit from relying on efficient and consistent ATR/ATC and term variation management methods are required. These methods are also important for organising domain specific knowledge, as terms should not be treated isolated from other terms. They should rather be related to one another so that the relations existing between the corresponding concepts are at least partly reflected in a terminology. 3.1 Term recognition The ATR method used in the system is based on the C / NC-value methods (Mima et al., 2001; Mima and Ananiadou, 2001). The C-value method recognizes terms by combining linguistic knowledge and statistical analysis. The method extracts multi-word terms2 and is not limited to a specific class of concepts. It is implemented as a two-step procedure. In the first step, term candidates are extracted by using a set of linguistic filters which describe general term formation patterns. In the second step, the term candidates are assigned termhood scores (referred to as Cvalues) according to a statistical measure. The measure amalgamates four numerical corpusbased characteristics of a candidate term, namely the freque</context>
<context position="8134" citStr="Mima and Ananiadou, 2001" startWordPosition="1212" endWordPosition="1215"> term. The NC-value method further improves the Cvalue results by taking into account the context of candidate terms. The relevant context words are extracted and assigned weights based on how frequently they appear with top-ranked term candidates extracted by the C-value method. Subsequently, context factors are assigned to candidate terms according to their co-occurrence with topranked context words. Finally, new termhood estimations, referred to as NC-values, are calculated as a linear combination of the C-values and context factors for the respective terms. Evaluation of the C/NC-methods (Mima and Ananiadou, 2001) has shown that contextual information improves term distribution in the extracted list by placing real terms closer to the top of the list. 2 More than 85% of domain-specific terms are multi-word terms (Mima and Ananiadou, 2001). 22 3.2 Term variation management Term variation and ambiguity are causing problems not only for ATR but for human experts as well. Several methods for term variation management have been developed. For example, the BLAST system Krauthammer et al., 2000) used approximate text string matching techniques and dictionaries to recognize spelling variations in gene and prot</context>
<context position="11523" citStr="Mima and Ananiadou, 2001" startWordPosition="1742" endWordPosition="1745">The calculated term cluster information is encoded and used for calculating semantic similarities in SCE component. More precisely, the similarity between two individual terms is determined according to their position in a dendrogram. Also a commonality measure is defined as the number of shared ancestors between two terms in the dendrogram, and a positional measure as a sum of their distances from the root. Similarity between two terms corresponds to a ratio between commonality and positional measure. Further details of the methods and their evaluations can be referred in (Mima et al., 2001; Mima and Ananiadou, 2001). 4 Structuring knowledge Structuring knowledge can be regarded as a broader approach to IE/KA. IE and KA in our system are implemented through the integration of ATR, ATC, and ontology-based semantic similarity calculation. Graph-based visualization for globally structuring knowledge is also provided to facilitate KR and KA from documents. Additionally, the system supports combining different databases (papers and patents, technologies and innovations) and retrieves different types of knowledge simultaneously and crossly. This feature can accelerate knowledge discovery by combining existing k</context>
</contexts>
<marker>Mima, Ananiadou, 2001</marker>
<rawString>H. Mima, S. Ananiadou, 2001. An application and evaluation of the C/NC-value approach for the automatic term recognition of multi-word units in Japanese, Int. J. on Terminology 6/2, pp. 175-194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Krauthammer</author>
<author>A Rzhetsky</author>
<author>P Morozov</author>
<author>C Friedman</author>
</authors>
<title>Using BLAST for identifying gene and protein names in journal articles, in: Gene 259,</title>
<date>2000</date>
<pages>245--252</pages>
<contexts>
<context position="8618" citStr="Krauthammer et al., 2000" startWordPosition="1291" endWordPosition="1294"> a linear combination of the C-values and context factors for the respective terms. Evaluation of the C/NC-methods (Mima and Ananiadou, 2001) has shown that contextual information improves term distribution in the extracted list by placing real terms closer to the top of the list. 2 More than 85% of domain-specific terms are multi-word terms (Mima and Ananiadou, 2001). 22 3.2 Term variation management Term variation and ambiguity are causing problems not only for ATR but for human experts as well. Several methods for term variation management have been developed. For example, the BLAST system Krauthammer et al., 2000) used approximate text string matching techniques and dictionaries to recognize spelling variations in gene and protein names. FASTR (Jacquemin, 2001) handles morphological and syntactic variations by means of meta-rules used to describe term normalization, while semantic variants are handled via WordNet. The basic C-value method has been enhanced by term variation management (Mima and Ananiadou, 2001). We consider a variety of sources from which term variation problems originate. In particular, we deal with orthographical, morphological, syntactic, lexico-semantic and pragmatic phenomena. Our</context>
</contexts>
<marker>Krauthammer, Rzhetsky, Morozov, Friedman, 2000</marker>
<rawString>M. Krauthammer, A. Rzhetsky, P. Morozov, C. Friedman, 2000. Using BLAST for identifying gene and protein names in journal articles, in: Gene 259, pp. 245-252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jacquemin</author>
</authors>
<title>Spotting and discovering terms through NLP,</title>
<date>2001</date>
<pages>378</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge MA,</location>
<contexts>
<context position="8768" citStr="Jacquemin, 2001" startWordPosition="1313" endWordPosition="1314">ntextual information improves term distribution in the extracted list by placing real terms closer to the top of the list. 2 More than 85% of domain-specific terms are multi-word terms (Mima and Ananiadou, 2001). 22 3.2 Term variation management Term variation and ambiguity are causing problems not only for ATR but for human experts as well. Several methods for term variation management have been developed. For example, the BLAST system Krauthammer et al., 2000) used approximate text string matching techniques and dictionaries to recognize spelling variations in gene and protein names. FASTR (Jacquemin, 2001) handles morphological and syntactic variations by means of meta-rules used to describe term normalization, while semantic variants are handled via WordNet. The basic C-value method has been enhanced by term variation management (Mima and Ananiadou, 2001). We consider a variety of sources from which term variation problems originate. In particular, we deal with orthographical, morphological, syntactic, lexico-semantic and pragmatic phenomena. Our approach to term variation management is based on term normalization as an integral part of the ATR process. Term variants (i.e. synonymous terms) ar</context>
</contexts>
<marker>Jacquemin, 2001</marker>
<rawString>C. Jacquemin, 2001. Spotting and discovering terms through NLP, MIT Press, Cambridge MA, p. 378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ushioda</author>
</authors>
<title>Hierarchical clustering of words,</title>
<date>1996</date>
<booktitle>Proc. of COLING ’96,</booktitle>
<pages>1159--1162</pages>
<location>Copenhagen,</location>
<contexts>
<context position="10685" citStr="Ushioda, 1996" startWordPosition="1609" endWordPosition="1610">uman cancer 3.3 Term clustering Beside term recognition, term clustering is an indispensable component of the literature mining process. Since terminological opacity and polysemy are very common in molecular biology and biomedicine, term clustering is essential for the semantic integration of terms, the construction of domain ontologies and semantic tagging. ATC in our system is performed using a hierarchical clustering method in which clusters are merged based on average mutual information measuring how strongly terms are related to one Input documents Figure 2: Ontology development another (Ushioda, 1996). Terms automatically recognized by the NC-value method and their cooccurrences are used as input, and a dendrogram of terms is produced as output. Parallel symmetric processing is used for high-speed clustering. The calculated term cluster information is encoded and used for calculating semantic similarities in SCE component. More precisely, the similarity between two individual terms is determined according to their position in a dendrogram. Also a commonality measure is defined as the number of shared ancestors between two terms in the dendrogram, and a positional measure as a sum of their </context>
</contexts>
<marker>Ushioda, 1996</marker>
<rawString>A. Ushioda, 1996. Hierarchical clustering of words, Proc. of COLING ’96, Copenhagen, Denmark, pp. 1159-1162.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>