<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000348">
<title confidence="0.9985275">
A Participant-based Approach for Event Summarization Using
Twitter Streams
</title>
<author confidence="0.999017">
Chao Shen&apos;, Fei Liu2, Fuliang Weng2, Tao Li&apos;
</author>
<affiliation confidence="0.98201">
&apos;School of Computing and Information Sciences, Florida International University
Miami, Florida 33199, USA
2Research and Technology Center, Robert Bosch LLC
</affiliation>
<address confidence="0.64158">
Palo Alto, California 94304, USA
</address>
<email confidence="0.9685875">
{cshen001, taoli}@cs.fiu.edu
{fei.liu, fuliang.weng}@us.bosch.com
</email>
<sectionHeader confidence="0.998587" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99995425">
Twitter offers an unprecedented advantage on
live reporting of the events happening around
the world. However, summarizing the Twit-
ter event has been a challenging task that was
not fully explored in the past. In this paper,
we propose a participant-based event summa-
rization approach that “zooms-in” the Twit-
ter event streams to the participant level, de-
tects the important sub-events associated with
each participant using a novel mixture model
that combines the “burstiness” and “cohesive-
ness” properties of the event tweets, and gen-
erates the event summaries progressively. We
evaluate the proposed approach on different
event types. Results show that the participant-
based approach can effectively capture the
sub-events that have otherwise been shadowed
by the long-tail of other dominant sub-events,
yielding summaries with considerably better
coverage than the state-of-the-art.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999987511627907">
Twitter has increasingly become a critical source of
information. People report the events they are ex-
periencing or publish comments on a wide variety
of events happening around the world, ranging from
the unexpected natural disasters, regional riots, to
many scheduled events, such as sports games, po-
litical debates, local festivals, and even academic
conferences. The Twitter data streams thus cover
a broad range of events and broadcast these in-
formation in a live manner. Event summarization
in this paper aims to generate a representative and
concise textual description of the scheduled events
that are being lively reported on Twitter, providing
people with an alternative means of observing the
world beyond the traditional journalism. Specifi-
cally, we investigate scheduled events of different
types, including six of the NBA (National Basket-
ball Association) sports games and a representative
conference event, namely the Apple CEO’s keynote
speech in the Apple Worldwide Developers Confer-
ence (WWDC 2012)1. All these events have excited
great discussion among the Twitter community.
Summarizing the Twitter event is a challenging
task that has yet been fully explored in the past.
Most previous summarization studies focus on the
well-formatted news documents, as driven by the
annual DUC2 and TAC3 evaluations. In contrast,
the Twitter messages (a.k.a., tweets) are very short
and noisy, containing nonstandard terms such as ab-
breviations, acronyms, emoticons, etc. (Liu et al.,
2011b; Liu et al., 2012; Eisenstein, 2013). The
noisy contents also cause great difficulties to the tra-
ditional NLP tools such as NER and dependency
parser (Ritter et al., 2011; Foster et al., 2011), lim-
iting the possibility of applying finer-grained event
analysis tools. In nature, the event tweets are closely
associated with the timeline and are drastically dif-
ferent from a static collection of news documents.
The tweets converge into text streams that pulse
along the timeline and cluster around the important
moments or sub-events. These “sub-events” are of
crucial importance since they represent a surge of in-
terest from the Twitter audience and the correspond-
</bodyText>
<footnote confidence="0.999950333333333">
1https://developer.apple.com/wwdc/
2http://duc.nist.gov/
3http://www.nist.gov/tac/
</footnote>
<page confidence="0.884483">
1152
</page>
<note confidence="0.6375955">
Proceedings of NAACL-HLT 2013, pages 1152–1162,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<figureCaption confidence="0.983915">
Figure 1: Example Twitter event stream (upper) and par-
ticipant stream (lower). Event stream contains tweets
related to an NBA basketball game (Spurs vs Thunder)
scheduled on May 31, 2012; participant stream contains
tweets corresponding to the player Russell Westbrook in
team Thunder. X-axis denotes the timeline and y-axis
represents the number of tweets per 10-second interval.
</figureCaption>
<bodyText confidence="0.999969276595745">
ing key information must be reflected in the event
summary. As such, event summarization research
has been focusing on developing accurate sub-event
detection systems and generating text descriptions
that can best summarize the sub-events in a progres-
sive manner (Chakrabarti and Punera, 2011; Nichols
et al., 2012; Zubiaga et al., 2012).
In Figure 1, we show an example Twitter event
stream and one of its “participant” streams. The
event stream contains all the tweets related to an
NBA basketball game Spurs vs Thunder; while
the participant stream contains only tweets corre-
sponding to the player Russell Westbrook in this
game. Previous research on event summarization
focuses on identifying the important moments from
the coarse-level event stream. This may yield sev-
eral side effects: first, the spike patterns are not
clearly identifiable from the overall event stream,
though they are more clearly seen if we “zoom-in” to
the participant level; second, it is arguable whether
the important sub-events can be accurately detected
based solely on the tweet volume change; third, a
popular participant or sub-event can elicit huge vol-
ume of tweets which dominant the event discussion
and shield less prominent sub-events. For example,
in the NBA games, discussions about the key players
(e.g., “LeBron James”, “Kobe Bryant”) can heavily
shadow other important participants or sub-events,
resulting in an event summary with repetitive de-
scriptions about the dominant players.
In this work, we propose a novel participant-
based event summarization approach, which dynam-
ically identifies the participants from data streams,
then “zooms-in” the event stream to participant
level, detects the important sub-events related to
each participant using a novel time-content mixture
model, and generates the event summary progres-
sively by concatenating the descriptions of the im-
portant sub-events. Results show that the mixture
model-based sub-event detection approach can effi-
ciently incorporate the “burstiness” and “cohesive-
ness” of the participant streams, and the participant-
based event summarization can effectively capture
the sub-events that have otherwise been shadowed
by the long-tail of other dominant sub-events, yield-
ing summaries with considerably better coverage
than the state-of-the-art approach.
</bodyText>
<sectionHeader confidence="0.999917" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999922344827586">
Mining Twitter for event information has received
increasing attention in recent years. Many research
studies focus on identifying the trending events from
Twitter and providing a concise and dynamic visual-
ization of the information. The identified events are
often represented using a set of keywords. (Petro-
vic et al., 2010) proposed an algorithm based on
locality-sensitive hashing for detecting new events
from a stream of Twitter posts. (O’Connor et al.,
2010; Becker et al., 2011b; Becker et al., 2011a;
Weng et al., 2011) proposed demo systems to dis-
play the event-related themes and popular tweets,
allowing the users to navigate through their topic
of interest. (Zhao et al., 2011) described an effort
to perform data collection and event recognition de-
spite various limits to the free access of Twitter data.
(Diao et al., 2012) integrated both temporal infor-
mation and users’ personal interests for bursty topic
detection from the microblogs. (Ritter et al., 2012)
described an open-domain event-extraction and cat-
egorization system, which extracts an open-domain
calendar of significant events from Twitter.
With the identified events of interest, there is an
ever-increasing demand for event summarization,
which distills the huge volume of Twitter discus-
sions into a concise and representative textual de-
scription of the events. Many studies start with
the text summarization approaches that have been
shown to perform well on the news documents and
</bodyText>
<page confidence="0.979407">
1153
</page>
<bodyText confidence="0.999962851851852">
develop adaptations to fit these methods to a col-
lection of event tweets. (Sharifi et al., 2010b) pro-
posed a graph-based phrase reinforcement algorithm
to build a one-sentence summary from a collection
of topic tweets. (Sharifi et al., 2010a; Inouye and
Kalita, 2011) presented a hybrid TF-IDF approach
to extract one- or multiple-sentence summary for
each topic. (Liu et al., 2011a) proposed to use
the concept-based ILP framework for summarizing
the Twitter trending topics, using both tweets and
the webpages linked from the tweets as input text
sources. (Harabagiu and Hickl, 2011) introduced a
generative framework that incorporates event struc-
ture and user behavior information in summarizing
multiple microblog posts related to the same topic.
Regarding summarizing the data streams, (Mar-
cus et al., 2011) introduced a “TwitInfo” system to
visually summarize and track the events on Twit-
ter. They proposed an automatic peak detection and
labeling algorithm for the social streams. (Taka-
mura et al., 2011) proposed a summarization model
based on the facility location problem, which gener-
ates summary for a stream of short documents along
the timeline. (Chakrabarti and Punera, 2011) pro-
posed an event summarization algorithm based on
learning an underlying hidden state representation
of the event via hidden Markov models. (Louis and
Newman, 2012) presented a method for summariz-
ing a collection of tweets related to a business. The
proposed procedure aggregates tweets into subtopic
clusters which are then ranked and summarized
by a few representative tweets from each cluster.
(Nichols et al., 2012; Zubiaga et al., 2012) focused
on real-time event summarization, which detects the
sub-events by identifying those moments where the
tweet volume has increases sharply, then uses var-
ious weighting schemes to perform tweet selection
and finally generates the event summary.
Our work is different from the above research
studies in three folds: first, we propose to “zoom-
in” the Twitter event streams to the participant
level, which allows us to clearly identify the im-
portant sub-events associated with each participant
and generate a balanced event summary with com-
prehensive coverage of all the important sub-events;
second, we propose a novel time-content mixture
model approach for sub-event detection, which ef-
fectively leverages the “burstiness” and “cohesive-
ness” of the event tweets and accurately detects
the participant-level sub-events. Third, we evalu-
ate the participant-based event summarization sys-
tem on different event types and demonstrate that the
proposed approach outperforms the state-of-the-art
method by a considerable margin.
</bodyText>
<sectionHeader confidence="0.964106" genericHeader="method">
3 Participant-based Event Summarization
</sectionHeader>
<bodyText confidence="0.99996175">
We propose a novel participant-centered event sum-
marization approach that consists of three key com-
ponents: (1) “Participant Detection” dynamically
identifies the event participants and divides the
entire event stream into a number of participant
streams (Section 3.1); (2) “Sub-event Detection” in-
troduces a novel time-content mixture model ap-
proach to identify the important sub-events associ-
ated with each participant; these “participant-level
sub-events” are then merged along the timeline to
form a set of “global sub-events”4, which capture
all the important moments in the event stream (Sec-
tion 3.2); (3) “Summary Tweet Extraction” extracts
the representative tweets from the global sub-events
and forms a comprehensive coverage of the event
progress (Section 3.3).
</bodyText>
<subsectionHeader confidence="0.9997">
3.1 Participant Detection
</subsectionHeader>
<bodyText confidence="0.987041956521739">
We define event participants as the entities that play
a significant role in shaping the event progress. “Par-
ticipant” is a general concept to denote the event
participating persons, organizations, product lines,
etc., each of which can be captured by a set of
correlated proper nouns. For example, the NBA
player “LeBron Raymone James” can be represented
by {LeBron James, LeBron, LBJ, King James, L.
James}, where each proper noun represents a unique
mention of the participant. In this work, we automat-
ically identify the proper nouns from tweet streams,
filter out the infrequent ones using a threshold 0,
and cluster them into individual event participants.
This process allows us to dynamically identify the
key participating entities and provide a full-coverage
for these participants in the event summary.
4We use “participant sub-events” and “global sub-events”
respectively to represent the important moments happened on
the participant-level and on the entire event-level. A “global
sub-event” may consist of one or more “participant sub-events”.
For example., the “steal” action in the basketball game typically
involves both the defensive and offensive players, and can be
generated by merging the two participant-level sub-events.
</bodyText>
<page confidence="0.974738">
1154
</page>
<bodyText confidence="0.999648272727273">
We formulate the participant detection in a hier-
archical agglomerative clustering framework. The
CMU TweetNLP tool (Gimpel et al., 2011) was used
for proper noun tagging. The proper nouns (a.k.a.,
mentions) are grouped into clusters in a bottom-up
fashion. Two mentions are considered similar if they
share (1) lexical resemblance, and (2) contextual
similarity. For example, in the following two tweets
“Gotta respect Anthony Davis, still rocking the uni-
brow”, “Anthony gotta do something about that uni-
brow”, the two mentions Anthony Davis and An-
thony are referring to the same participant and they
share both character overlap (“anthony”) and con-
text words (“unibrow”, “gotta”). We use sim(ci, cj)
to represent the similarity between two mentions ci
and cj, defined as:
sim(ci, cj) = lex sim(ci, cj)xcont sim(ci, cj)
where the lexical similarity (lex sim(·)) is defined
as a binary function representing whether a mention
ci is an abbreviation, acronym, or part of another
mention cj, or if the character edit distance between
the two mentions is less than a threshold θ5:
</bodyText>
<figureCaption confidence="0.993231">
Figure 2: Plate notation of the mixture model.
</figureCaption>
<bodyText confidence="0.999915666666667">
Similarity between two clusters of mentions are de-
fined as the maximum possible similarity between a
pair of mentions, each from one cluster:
</bodyText>
<equation confidence="0.865971">
sim(Ci, Cj) = max
ci∈Ci,cj∈Cj
</equation>
<bodyText confidence="0.999978142857143">
We perform bottom-up agglomerative clustering on
the mentions until a stopping threshold δ has been
reached for sim(Ci, Cj). The clustering approach
naturally groups the frequent proper nouns into par-
ticipants. The participant streams are then formed
by gathering the tweets that contain one or more
mentions in the participant cluster.
</bodyText>
<equation confidence="0.897800285714286">
π z
μ a B BI
K B
t w
W
|D|
sim(ci, cj)
</equation>
<bodyText confidence="0.999988642857143">
We define the context similarity (cont sim(·)) of
two mentions as the cosine similarity between their
context vectors ~vi and ~vj. Note that on the tweet
stream, two temporally distant tweets can be very
different even though they are lexically similar, e.g.,
two slam dunk shots performed by the same player
at different time points are different. We there-
fore restrain the context to a segment of the tweet
stream |Sk |and then take the weighted average of
the segment-based similarity as the final context
similarity. To build the context vector, we use term
frequency (TF) as the term weight and remove all the
stopwords. We use |D |to represent the total tweets
in the event stream.
</bodyText>
<equation confidence="0.987727">
cont sim|Sk|(ci, cj) = cos(~vi,~vj)
�cont sim(ci, cj) = |Sk|
k |D |x cont sim|Sk|(ci, cj)
</equation>
<bodyText confidence="0.641655">
50 was empirically set as 0.2 x min{|ci|, |cj|}
</bodyText>
<subsectionHeader confidence="0.999717">
3.2 Mixture Model-based Sub-event Detection
</subsectionHeader>
<bodyText confidence="0.999914">
A sub-event corresponds to a topic that emerges
from the data stream, being intensively discussed
during a short period, and then gradually fades away.
The tweets corresponding to a sub-event thus de-
mand not only “temporal burstiness” but also a cer-
tain degree of “lexical cohesiveness”. To incorporate
both the time and content aspects of the sub-events,
we propose a mixture model approach for sub-event
detection. Figure 2 shows the plate notation.
In the proposed model, each tweet d in the data
stream D is generated from a topic z, weighted by
πz. Each topic is characterized by both its content
and time aspects. The content aspect is captured by
a multinomial distribution over the words, param-
eterized by θ; while the time aspect is character-
ized by a Gaussian distribution, parameterized by µ
and σ, with µ represents the average time point that
the sub-event emerges and σ determines the duration
of the sub-event. These distributions bear similari-
ties with the previous work (Hofmann, 1999; Allan,
2002; Haghighi and Vanderwende, 2009). In addi-
tion, there are often background or “noise” topics
that are being constantly discussed over the entire
</bodyText>
<figure confidence="0.966033666666667">
lex sim(ci, cj)= { 1 ci(cj) is part of cj(ci)
1 EditDist(ci, cj) &lt; θ
0 Otherwise
</figure>
<page confidence="0.975433">
1155
</page>
<bodyText confidence="0.997422777777778">
event evolvement process and do not present the de-
sired “burstiness” property. We use a uniform dis-
tribution U(tb, te) to model the time aspect of these
“background” topics, with tb and te being the event
beginning and end time points. The content aspect
of a background topic is modeled by similar multi-
nomial distribution, parameterized by θ&apos;. We use the
maximum likelihood parameter estimation. The data
likelihood can be represented as:
</bodyText>
<equation confidence="0.947488">
L(D) = Y X lπzpz(td) Y pz(w)1
dED z wEd
</equation>
<bodyText confidence="0.999907">
where pz(td) models the timestamp of tweet d under
the topic z; pz(w) corresponds to the word distribu-
tion in topic z. They are defined as:
</bodyText>
<equation confidence="0.99712975">
� N(td; µz, σz) if z is a sub-event topic
pz(td) = U(tb, te) if z is background topic
� p(w; θz) if z is a sub-event topic
pz(w) = p(w; θ&apos;z) if z is background topic
</equation>
<bodyText confidence="0.917826333333333">
where both p(w; θz) and p(w; θ&apos;z) are multinomial
distributions over the words. Initially, we assume
there are K sub-event topics and B background top-
ics and use the EM algorithm for model fitting. The
EM equations are listed below:
E-step:
</bodyText>
<equation confidence="0.996539538461538">
p(zd = j) a
M-step:
Xπj a p(zd = j)
d
p(w; θj) a X p(zd = j) x c(w,d)
d
p(w; θ&apos; j) a X p(zd = j) x c(w,d)
d
= Pd p(zd = j) x td
µj K
Pj=1 Pd p(zd = j)
σ2j = Pd p(zd = j) x (td − µj)2
Pj= 1 Pd p(zd = j)
</equation>
<bodyText confidence="0.999979358974359">
To process the data stream D, we divide the data
into 10-second bins and process each bin at a time.
The peak time of a sub-event was determined as
the bin that has the most tweets related to this sub-
event. During EM initialization, the number of sub-
event topics K was empirically decided by scanning
through the data stream and examine tweets in ev-
ery 3-minute stream segment. If there was a spike6,
we add a new sub-event to the model and use the
tweets in this segment to initialize the value of µ,
σ, and θ. Initially, we use a fixed number of back-
ground topics with B = 4. A topic re-adjustment
was performed after the EM process. We merge two
sub-events in a data stream if they (1) locate closely
in the timeline, with peaks times within a 2-minute
window; and (2) share similar word distributions:
among the top-10 words with highest probability in
the word distributions, there are over 5 words over-
lap. We also convert the sub-event topics to back-
ground topics if their σ values are greater than a
threshold β7. We then re-run the EM to obtain the
updated parameters. The topic re-adjustment pro-
cess continues until the number of sub-events and
background topics do not change further.
We obtain the “participant sub-events” by ap-
plying this sub-event detection approach to each of
the participant streams. The “global sub-events”
are obtained by merging the participant sub-events
along the timeline. We merge two participant sub-
events into a global sub-event if (1) their peaks are
within a 2-minute window, and (2) the Jaccard simi-
larity (Lee, 1999) between their associated tweets is
greater than a threshold (set to 0.1 empirically). The
tweets associated with each global sub-event are the
ones with p(z|d) greater than a threshold γ, where z
is one of the participant sub-events and γ was set to
0.7 empirically. After the sub-event detection pro-
cess, we obtain a set of global sub-events and their
associated event tweets.8
</bodyText>
<subsectionHeader confidence="0.998295">
3.3 Summary Tweet Extraction
</subsectionHeader>
<bodyText confidence="0.9996985">
We extract a representative tweet from each of the
global sub-events and concatenate them to form an
informative event summary. Note that our goal in
this work is to identify all the important moments
</bodyText>
<footnote confidence="0.868274">
6We use the algorithm described in (Marcus et al., 2011) as
a baseline and ad hoc spike detection algorithm.
7,3 was set to 5 minutes in our experiments.
8We empirically set some threshold values in the topic re-
adjustment and sub-event merging process. In future, we would
like to explore more principled way of parameter selection.
</footnote>
<table confidence="0.92114825">
πjN(d;µj,σj) Q p(w; θj) if j &lt;= K
wEd
πjU(tb,te) Q p(w; θ&apos;j) else
wEd
⎧
⎨
⎩
1156
Event Date Duration #Tweets
Lakers vs Okc 05/19/2012 3h10m 218,313
N Celtics vs 76ers 05/23/2012 3h30m 245,734
B Celtics vs Heat 05/30/2012 3h30m 345,335
A Spurs vs Okc 05/31/2012 3h 254,670
Heat vs Okc (1) 06/12/2012 3h30m 331,498
Heat vs Okc (2) 06/21/2012 3h30m 332,223
Apple’s WWDC’12 Conf. 06/11/2012 3h30m 163,775
</table>
<tableCaption confidence="0.982409">
Table 1: Statistics of the data set, including six NBA bas-
ketball games and the WWDC 2012 conference event.
</tableCaption>
<bodyText confidence="0.999535357142857">
for event summarization, but not on proposing new
methods for tweet selection. We thus use the Hybrid
TF-IDF approach (Sharifi et al., 2010a; Liu et al.,
2011a) to extract the representative sentences from
a collection of tweets. In this approach, each tweet
was considered as a sentence. The sentences were
ranked according to the average TF-IDF score of the
consisting words; top weighted sentences were it-
eratively extracted, while excluding those that have
high cosine similarity with the existing summary
sentences. (Inouye and Kalita, 2011) showed the
Hybrid TF-IDF approach performs constantly better
than the phrase reinforcement algorithm and other
traditional summarization systems.
</bodyText>
<sectionHeader confidence="0.998428" genericHeader="method">
4 Data Corpus
</sectionHeader>
<bodyText confidence="0.999971">
We evaluate the proposed event summarization ap-
proach on six NBA basketball games and a repre-
sentative conference event, namely the Apple CEO’s
keynote speech in the Apple Worldwide Develop-
ers Conference (WWDC 2012)9. We use the het-
erogeneous event types to verify that the proposed
approach can robustly and efficiently produce sum-
maries on different event streams. The tweet streams
corresponding to these events are collected using
the Twitter Streaming API10 with pre-defined key-
word set. For NBA games, we use the team names,
first name and last name of the players and head
coaches as keywords for retrieving the event tweets;
for the WWDC conference, the keyword set contains
about 20 terms related to the Apple event, such as
“wwdc”, “apple”, “mac”, etc. We crawl the tweets
in real-time when these scheduled events are taking
place; nevertheless, certain non-event tweets could
be mis-included due to the broad coverage of the
used keywords. During preprocessing, we filter out
</bodyText>
<footnote confidence="0.998886">
9https://developer.apple.com/wwdc/
10https://dev.twitter.com/docs/streaming-apis
</footnote>
<table confidence="0.996898888888889">
Time Action (Sub-event) Score
9:22 Chris Bosh misses 10-foot two point shot 7-2
9:22 Serge Ibaka defensive rebound 7-2
9:11 Kevin Durant makes 15-foot two point shot 9-2
8:55 Serge Ibaka shooting foul (Shane Battier draws 9-2
the foul)
8:55 Shane Battier misses free throw 1 of 2 9-2
8:55 Miami offensive team rebound 9-2
8:55 Shane Battier makes free throw 2 of 2 9-3
</table>
<tableCaption confidence="0.608819">
Table 2: An example clip of the play-by-play live cov-
erage of an NBA game (Heat vs Okc). “Time” corre-
sponds to the minutes left in the current quarter of the
game; “Score” shows the score between the two teams.
</tableCaption>
<bodyText confidence="0.999960028571429">
the tweets containing URLs, non-English tweets,
and retweets since they are less likely containing
new information regarding the event progress. Ta-
ble 1 shows statistics of the event tweets after the
filtering process. In total, there are over 1.8 million
tweets used in the event summarization experiments.
We use the play-by-play live coverage collected
from the ESPN11 and MacRumors12 websites as ref-
erence, which provide detailed descriptions of the
NBA and WWDC events as they unfold. Table 2
shows an example clip of the play-by-play descrip-
tions of an NBA game. Ideally, each item in the live
coverage descriptions may correspond to a sub-event
in the tweet streams, but in reality, not all actions
would attract enough attention from the Twitter au-
dience. We use a human annotator to manually filter
out the actions that did not lead to any spike in the
corresponding participant stream. The rest items are
projected to the participant and event streams as the
goldstandard sub-events. The projection was man-
ually performed since the “game clock” associated
with the goldstandard (first column in Table 2) does
not align well with the “wall clock” due to the game
rules such as timeout and halftime rest. To evalu-
ate the participant detection performance, we ask the
annotator to manually group the proper noun men-
tions into clusters, each cluster corresponds to a par-
ticipant. The mentions that do not correspond to any
participant are discarded. The goldstandard event
summaries are generated by manually selecting one
representative tweet from each of the groundtruth
global sub-events. We choose not to use the play-
by-play descriptions as reference summaries since
their vocabulary is rather limited and do not overlap
with the tweet language.
</bodyText>
<footnote confidence="0.99483">
11http://espn.go.com/nba/scoreboard
12http://www.macrumorslive.com/archive/wwdc12/
</footnote>
<page confidence="0.975155">
1157
</page>
<table confidence="0.9975764">
Example Participants - NBA game
westbrook, russell westbrook
stephen jackson, steven jackson, jackson
james, james harden, harden
ibaka, serge ibaka
oklahoma city thunder, oklahoma
gregg popovich, greg popovich, popovich
kevin durant, kd, durant
thunder, okc, #okc, okc thunder, #thunder
Example Participants - WWDC Conference
macbooks, mbp, macbook pro, macbook air,...
google maps, google, apple maps
wwdc, apple wwdc, #wwdc
os, mountain, os x mountain, os x
iphone 4s, iphone 3gs, iphone
</table>
<tableCaption confidence="0.992275666666667">
Table 3: Example participants automatically detected
from the NBA game Spurs vs Okc (2012-5-31) and the
WWDC’12 conference.
</tableCaption>
<sectionHeader confidence="0.998168" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.999987333333333">
We evaluate the participant-based event summariza-
tion in a cascaded fashion and present results for
each of the three components, including the par-
ticipant detection (Section 5.1), sub-event detection
(Section 5.2), and quantitative and qualitative evalu-
ation of example event summaries (Section 5.3).
</bodyText>
<subsectionHeader confidence="0.990085">
5.1 Participant Detection Results
</subsectionHeader>
<bodyText confidence="0.9999455">
In Table 3, we show example participants that were
automatically detected by the proposed hierarchical
agglomerative clustering approach. We note that the
clusters include various mentions of the same event
participant, e.g., “gregg popovich”, “greg popovich”,
and “popovich” are both referring to the head coach
of the team Spurs; “macbooks”, “macbook pro”,
“mbp” are referring to a line of products from Apple.
Quantitatively, we evaluate the participant detection
results on both participant- and mention-level. As-
sume the system-detected and the goldstandard par-
ticipant clusters are T3 and Tg respectively. We de-
fine a correct participant as a system detected par-
ticipant with more than half of its associated men-
tions are included in a goldstandard participant (re-
ferred to as the hit participant). As a result, we
can define the participant-level precision and recall
as below:
</bodyText>
<equation confidence="0.571985">
participant-prec = #correct-participants/iT3I
participant-recall = #hit-participants/jTgj
</equation>
<bodyText confidence="0.947954">
Note that a correct participant may include incor-
rect mentions, and that more than one correct par-
</bodyText>
<figureCaption confidence="0.768991666666667">
Figure 3: Participant detection performance. The upper
figures represent the participant-level precision and re-
call scores; while the lower figures represent the mention-
</figureCaption>
<bodyText confidence="0.988613916666667">
level precision and recall. X-axis corresponds to the six
NBA games and the WWDC conference.
ticipants may correspond to the same hit participant,
both of which are undesired. In the latter case, we
use representative participant to refer to the cor-
rect participant which contains the most mentions
in the hit participant. In this way, we build a 1-
to-1 mapping from the detected participants to the
groundtruth participants. Next, we define correct
mentions as the union of the overlapping mentions
between all pairs of representative and hit partici-
pants. Then we calculate the mention-level precision
and recall as the number of correct mentions divided
by the total mentions in the system or goldstandard
participant clusters.
Figure 3 shows the participant- and mention-level
precision and recall scores. We experimented with
different similarity measures for the agglomerative
clustering approach13. The “global context” means
that the context vectors are created from the entire
data stream; this may not perform well since dif-
ferent participants can share similar global context.
E.g., the terms “shot”, “dunk”, “rebound” can ap-
pear in the context of any NBA players and are not
</bodyText>
<footnote confidence="0.592203">
13The stopping threshold S was set to 0.15, local context
length is 3 minutes, and frequency threshold 0 was set to 200.
</footnote>
<page confidence="0.961544">
1158
</page>
<table confidence="0.999930272727273">
Participant-level Sub-event Detection Global Sub-event Detection
Event #P #S Spike MM #S Spike Participant + Spike Participant + MM
R P F R P F R P F R P F R P F
Lakers vs Okc 9 65 0.75 0.31 0.44 0.71 0.39 0.50 48 0.67 0.38 0.48 0.94 0.19 0.32 0.88 0.40 0.55
Celtics vs 76ers 10 88 0.52 0.39 0.45 0.53 0.43 0.47 60 0.65 0.51 0.57 0.72 0.18 0.29 0.78 0.39 0.52
Celtics vs Heat 14 152 0.53 0.29 0.37 0.50 0.38 0.43 67 0.57 0.41 0.48 0.97 0.21 0.35 0.91 0.28 0.43
Spurs vs Okc 12 98 0.78 0.46 0.58 0.84 0.57 0.68 81 0.41 0.42 0.41 0.88 0.35 0.50 0.91 0.54 0.68
Heat vs Okc (1) 15 123 0.75 0.27 0.40 0.72 0.35 0.47 85 0.41 0.47 0.44 0.94 0.20 0.33 0.96 0.34 0.50
Heat vs okc (2) 13 153 0.74 0.36 0.48 0.76 0.43 0.55 92 0.41 0.33 0.37 0.88 0.21 0.34 0.87 0.38 0.53
WWDC’12 10 56 0.64 0.14 0.23 0.59 0.33 0.42 43 0.53 0.26 0.35 0.77 0.14 0.24 0.70 0.31 0.43
Average 12 105 0.67 0.32 0.42 0.66 0.41 0.50 68 0.52 0.40 0.44 0.87 0.21 0.34 0.86 0.38 0.52
</table>
<tableCaption confidence="0.990593666666667">
Table 4: Sub-event detection results on both participant and the event streams. “Spike” corresponds to the spike
detection algorithm proposed in (Marcus et al., 2011); “MM” represents our proposed time-content mixture model
approach. “#P” and “#S” list the number of participants and sub-events in each event stream.
</tableCaption>
<bodyText confidence="0.999872285714286">
discriminative enough. We found that adding the
lexical similarity measure greatly boosted the clus-
tering performance, especially on the mention-level,
and that combining the lexical similarity with the lo-
cal context is even more helpful for some events.
We notice that two events (celtics vs 76ers and
celtics vs heat) yield relatively low precision on both
participant- and mention-level. Taking a close look
at the data, we found that these two events acciden-
tally co-occurred with other popular events, namely
the TV program “American Idol” finale and the NBA
Draft. The keyword based data crawler thus includes
many noisy tweets in the event streams, leading to
some false participants being detected.
</bodyText>
<subsectionHeader confidence="0.999847">
5.2 Sub-event Detection Results
</subsectionHeader>
<bodyText confidence="0.999991785714286">
We compare our proposed time-content mixture
model (noted as “MM”) against the spike detection
algorithm proposed in (Marcus et al., 2011) (noted
as “Spike”) . The spike algorithm is based on the
tweet volume change. It uses 10 seconds as a time
unit, calculates the tweet arrival rate in each unit,
and identifies the rates that are significantly higher
than the mean tweet rate. For these rate spikes, the
algorithm finds the local maximum of tweet rate and
identify a window surrounding the local maximum.
We tune the parameter of the “Spike” approach (set
,r = 4) so that it yields similar recall values as the
mixture model approach. We then apply the “MM”
and “Spike” approaches to both the participant and
event streams and evaluate the sub-event detection
performance. Results are shown in Table 4. A sys-
tem detected sub-event is considered to match the
goldstandard sub-event if its peak time is within a
2-minute window of the goldstandard.
We first apply the “Spike” and “MM” approach to
the participant streams. The participant streams on
which we cannot detect any meaningful sub-events
have been excluded, the resulting number of partic-
ipants are listed in Table 4 and denoted as “#P”.
In general, we found the “MM” approach can per-
form better since it inherently incorporates both the
“burstiness” and “lexical cohesiveness” of the event
tweets, while the “Spike” approach relies solely on
the “burstiness” property. Note that although we di-
vide the entire event stream into participant streams,
some key participants still own huge amount of dis-
cussion and the spike patterns are not always clearly
identifiable. The time-content mixture model gains
advantages in these cases.
We apply three settings to detect global sub-
events on the data streams. “Spike” directly ap-
plies the spike algorithm on the entire event stream;
the “Participant + Spike” and “Participant + MM”
approaches first perform sub-event detection on the
participant streams and then merge the detected sub-
events along the timeline to generate global sub-
events. Note that there are fewer goldstandard
sub-events (“#S”) on the global streams since each
global sub-event may correspond to one or multiple
participant-level sub-events. Because of the averag-
ing effect, spike patterns on the entire event stream
is less obvious than those on the participant streams.
As a result, few spikes have been detected on the
event stream using the “Spike” algorithm, which
leads to low recall as compared to other participant-
based approaches. It also indicates that, by dividing
the entire event stream into participant streams, we
have a better chance of identifying the sub-events
that have otherwise been shadowed by the domi-
nant sub-events or participants. The two participant-
based methods yield similar recall but “Participant
</bodyText>
<page confidence="0.991718">
1159
</page>
<bodyText confidence="0.9995054">
+ Spike” yields slightly worse precision, since it is
very sensitive to the spikes on the participant-level,
leading to the rise of false alarms. The “Participant +
MM” approach is much better in precision, which is
consistent to our findings on the participant streams.
</bodyText>
<subsectionHeader confidence="0.999662">
5.3 Summarization Results
</subsectionHeader>
<bodyText confidence="0.999984086956522">
Summarization evaluation has been a longstanding
issue in the literature (Nenkova and Mckeown, 2011;
Liu and Liu, 2010). There are even less studies fo-
cusing on evaluating the event summaries generated
from data streams. Since the summary annotation
takes quite some effort, we sample a 10-minute seg-
ment from each of the seven event streams and ask
a human annotator to select representative tweets
for each segment. We then compare the system
summaries against the manual summaries using the
ROUGE-1 (Lin, 2004) metric. The quantitative re-
sults and qualitative analysis are presented in Table 5
and Table 6 respectively. Note that the ROUGE
scores are based solely on the n-gram overlap be-
tween the system and reference summaries, which
may not be the most appropriate measure for eval-
uating the Twitter event summaries. However, we
do notice that the accurate sub-event detection per-
formance can successfully translate into a gain of
the ROUGE scores. Qualitatively, the participant-
based event summarization approach focus more on
extracting tweets associated with the targeted partic-
ipants, which could lead to better text coherence.
</bodyText>
<sectionHeader confidence="0.99842" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9998996875">
In this work, we made an initial attempt to gen-
erate event summaries using Twitter data streams.
We proposed a participant-based event summariza-
tion approach which “zooms-in” the Twitter event
streams to the participant level, detects the impor-
tant sub-events associated with each participant us-
ing a novel mixture model that incorporates both the
“burstiness” and “cohesiveness” of tweets, and gen-
erates the event summaries progressively. Results
show that the proposed approach can effectively cap-
ture the sub-events that have otherwise been shad-
owed by the long-tail of other dominant sub-events,
yielding summaries with considerably better cover-
age. Without loss of generality, we report results
on the entire event streams, though the proposed ap-
proach can well be applied in an online fashion.
</bodyText>
<table confidence="0.999573285714286">
Event Method R(%) P(%) F(%)
Spike 14.73 23.24 16.87
NBA Average Participant + Spike 54.60 14.65 22.40
Participant + MM 54.36 23.06 31.53
Spike 26.58 39.62 31.82
WWDCConf. Participant + Spike 49.37 25.16 33.33
Participant + MM 42.77 31.73 36.07
</table>
<tableCaption confidence="0.871003">
Table 5: ROUGE-1 scores of summarization
</tableCaption>
<table confidence="0.999871538461539">
Method Summary
Manual Good drive for durant
Pretty shot by Duncan
Good 3 point tony parker
Nice move westbrook
Good shot Westbrook
Spike Game 3. Spurs vs. OKC
Okc and spurs game.
Participant OKLAHOMA CITY THUNDER vs san antonio
+ Spike spurs!! YA
I hope okc win the series. Ill hate too see the heat
play San Antonio
we aint in San Antonio anymore.
NBA: SA 0 OKC 8, 9:11 1st.#TeamOkc
San antonio spurs for 21 consecutive win? #nba
Somebody Should Stop Tim Duncan.
Pass the damn ball Westbrook
Good 3 pointer tony parker!
Participant Tim Duncan shot is so precise
+ MM Tim Duncan is gettin started
Good 3 pointer tony parker!
Sefalosa guarding tony parker. Good fucking move
coach brooks
Westbrook = 2 Fast 2 Furious
Niggas steady letting Tim Duncan shoot
Westbrook mid range shot is automatic
</table>
<tableCaption confidence="0.9853005">
Table 6: Example summaries for an event segment. Par-
ticipants are marked using italicized text.
</tableCaption>
<bodyText confidence="0.999946454545455">
There are many challenges left in this line of re-
search. Having a standardized evaluation metric for
event summaries is one of them. In the current work,
we employed ROUGE-1 for summary evaluation,
since it has been shown to correlate well with the hu-
man judgements on noisy text genres (Liu and Liu,
2010). We would like to explore other evaluation
metrics (e.g., ROUGE-2, -SU4, Pyramid (Nenkova
et al., 2007)) and the human evaluation in future.
We will also explore better ways of integrating the
sub-event detection and summarization approaches.
</bodyText>
<sectionHeader confidence="0.998814" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999097">
Part of this work was done during the first author’s
internship in Bosch Research and Technology Cen-
ter. The work is also partially supported by NSF
grants DMS-0915110 and HRD-0833093.
</bodyText>
<page confidence="0.989451">
1160
</page>
<sectionHeader confidence="0.996232" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999733509615385">
James Allan. 2002. Topic detection and tracking: Event-
based information organization. Kluwer Academic
Publishers Norwell, MA, USA.
Hila Becker, Feiyang Chen, Dan Iter, Mor Naaman, and
Luis Gravano. 2011a. Automatic identification and
presentation of twitter content for planned events. In
Proceedings of the Fifth International AAAI Confer-
ence on Weblogs and Social Media (ICWSM), pages
655–656.
Hila Becker, Mor Naaman, and Luis Gravano. 2011b.
Beyond trending topics: Real-world event identifica-
tion on twitter. In Proceedings of the Fifth Interna-
tional AAAI Conference on Weblogs and Social Media
(ICWSM), pages 438–441.
Deepayan Chakrabarti and Kunal Punera. 2011. Event
summarization using tweets. In Proceedings of the
Fifth International AAAI Conference on Weblogs and
Social Media (ICWSM), pages 66–73.
Qiming Diao, Jing Jiang, Feida Zhu, and Ee-Peng Lim.
2012. Finding bursty topics from microblogs. In Pro-
ceedings of the 50th Annual Meeting of the Association
for Computational Linguistics (ACL), pages 536–544.
Jacob Eisenstein. 2013. What to do about bad language
on the internet. In Proceedings of the 2013 Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics: Human Language
Technologies (NAACL/HLT).
Jennifer Foster, Ozlem Cetinoglu, Joachim Wagner,
Joseph Le Roux, Stephen Hogan, Joakim Nivre,
Deirdre Hogan, and Josef van Genabith. 2011. #hard-
toparse: POS tagging and parsing the twitterverse. In
Proceedings of the AAAI Workshop on Analyzing Mi-
crotext, pages 20–25.
Kevin Gimpel, Nathan Schneider, Brendan O’Connor,
Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael
Heilman, Dani Yogatama, Jeffrey Flanigan, and
Noah A. Smith. 2011. Part-of-speech tagging for twit-
ter: Annotation, features, and experiments. In Pro-
ceedings of the 49th Annual Meeting of the Associa-
tion for Computational Linguistics: Human Language
Technologies (ACL-HLT), pages 42–47.
Aria Haghighi and Lucy Vanderwende. 2009. Explor-
ing content models for multi-Document summariza-
tion. In Proceedings of Human Language Technolo-
gies: The 2009Annual Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics (NAACL), pages 362–370.
Sanda Harabagiu and Andrew Hickl. 2011. Relevance
modeling for microblog summarization. In Proceed-
ings of the Fifth International AAAI Conference on We-
blogs and Social Media (ICWSM), pages 514–517.
Thomas Hofmann. 1999. Probabilistic latent semantic
analysis. In Proceedings of Uncertainty in Artificial
Intelligence (UAI).
David Inouye and Jugal K. Kalita. 2011. Compar-
ing twitter summarization algorithms for multiple post
summaries. In Proceedings of 2011 IEEE Third Inter-
national Conference on Social Computing, pages 290–
306.
Lillian Lee. 1999. Measures of distributional similarity.
In Proceedings of the 37th Annual Meeting of the As-
sociation for Computational Linguistics (ACL), pages
25–32.
Chin-Yew Lin. 2004. ROUGE: A package for automatic
evaluation of summaries. In Workshop on Text Sum-
marization Branches Out.
Feifan Liu and Yang Liu. 2010. Exploring correlation
between ROUGE and human evaluation on meeting
summaries. IEEE Transactions on Audio, Speech, and
Language Processing, 18(1):187–196.
Fei Liu, Yang Liu, and Fuliang Weng. 2011a. Why is
”SXSW” trending? Exploring multiple text sources
for twitter topic summarization. In Proceedings of the
ACL Workshop on Language in Social Media (LSM),
pages 66–75.
Fei Liu, Fuliang Weng, Bingqing Wang, and Yang Liu.
2011b. Insertion, deletion, or substitution? Normal-
izing text messages without pre-categorization nor su-
pervision. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 71–76.
Fei Liu, Fuliang Weng, and Xiao Jiang. 2012. A broad-
coverage normalization system for social media lan-
guage. In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics (ACL),
pages 1035–1044.
Annie Louis and Todd Newman. 2012. Summarization
of business-related tweets: A concept-based approach.
In Proceedings of the 24th International Conference
on Computational Linguistics (COLING).
Adam Marcus, Michael S. Bernstein, Osama Badar,
David R. Karger, Samuel Madden, and Robert C.
Miller. 2011. Twitinfo: Aggregating and visualizing
microblogs for event exploration. In Proceedings of
the SIGCHI Conference on Human Factors in Com-
puting Systems, pages 227–236.
Ani Nenkova and Kathleen Mckeown. 2011. Automatic
summarization. Foundations and Trends in Informa-
tion Retrieval, 5(2–3):103–233.
Ani Nenkova, Rebecca Passonneau, and Kathleen Mcke-
own. 2007. The pyramid method: Incorporating hu-
man content selection variation in summarization eval-
uation. ACM Transactions on Speech and Language
Processing, 4(2).
</reference>
<page confidence="0.982525">
1161
</page>
<bodyText confidence="0.5983775">
ceedings of the 23rd ACM Conference on Hypertext
and Social Media, pages 319–320.
</bodyText>
<reference confidence="0.999794886792453">
Jeffrey Nichols, Jalal Mahmud, and Clemens Drews.
2012. Summarizing sporting events using twitter. In
Proceedings of the 2012 ACM Interntional Conference
on Intelligent User Interfaces (IUI), pages 189–198.
Brendan O’Connor, Michel Krieger, and David Ahn.
2010. TweetMotif: Exploratory search and topic sum-
marization for twitter. In Proceedings of the Fourth
International AAAI Conference on Weblogs and Social
Media (ICWSM), pages 384–385.
Sasa Petrovic, Miles Osborne, and Victor Lavrenko.
2010. Streaming first story detection with application
to twitter. In Proceedings of the 2010 Annual Con-
ference of the North American Chapter of the Associ-
ation for Computational Linguistics (NAACL), pages
181–189.
Alan Ritter, Sam Clark, Mausam, and Oren Etzioni.
2011. Named entity recognition in tweets: An exper-
imental study. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 1524–1534.
Alan Ritter, Mausam, Oren Etzioni, and Sam Clark.
2012. Open domain event extraction from twitter. In
Proceedings of the 18th ACM SIGKDD International
Conference on Knowledge Discovery and Data Min-
ing, pages 1104–1112.
Beaux Sharifi, Mark-Anthony Hutton, and Jugal K.
Kalita. 2010a. Experiments in microblog summariza-
tion. In Proceedings of the 2010 IEEE Second Interna-
tional Conference on Social Computing, pages 49–56.
Beaux Sharifi, Mark-Anthony Hutton, and Jugal K.
Kalita. 2010b. Summarizing microblogs automati-
cally. In Proceedings of the 2010 Annual Conference
of the North American Chapter of the Association for
Computational Linguistics (NAACL), pages 685–688.
Hiroya Takamura, Hikaru Yokono, and Manabu Oku-
mura. 2011. Summarizing a document stream. In
Proceedings of the 33rd European Conference on Ad-
vances in Information Retrieval (ECIR), pages 177–
188.
Jui-Yu Weng, Cheng-Lun Yang, Bo-Nian Chen, Yen-Kai
Wang, and Shou-De Lin. 2011. Imass: An intelli-
gent microblog analysis and summarization system. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies (ACL-HLT), pages 133–138.
Siqi Zhao, Lin Zhong, Jehan Wickramasuriya, and Venu
Vasudevan. 2011. Human as real-time sensors of so-
cial and physical events: A case study of twitter and
sports games. Technical Report TR0620-2011, Rice
University and Motorola Labs.
Arkaitz Zubiaga, Damiano Spina, Enrique Amig´o, and
Julio Gonzalo. 2012. Towards real-time summariza-
tion of scheduled events from twitter streams. In Pro-
</reference>
<page confidence="0.995707">
1162
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.642966">
<title confidence="0.9432245">A Participant-based Approach for Event Summarization Twitter Streams</title>
<author confidence="0.998956">Fei Fuliang Tao</author>
<affiliation confidence="0.997993">of Computing and Information Sciences, Florida International</affiliation>
<address confidence="0.911355">Miami, Florida 33199,</address>
<affiliation confidence="0.831464">and Technology Center, Robert Bosch</affiliation>
<address confidence="0.941445">Palo Alto, California 94304,</address>
<abstract confidence="0.999128666666667">Twitter offers an unprecedented advantage on live reporting of the events happening around the world. However, summarizing the Twitter event has been a challenging task that was not fully explored in the past. In this paper, we propose a participant-based event summarization approach that “zooms-in” the Twitter event streams to the participant level, detects the important sub-events associated with each participant using a novel mixture model that combines the “burstiness” and “cohesiveness” properties of the event tweets, and generates the event summaries progressively. We evaluate the proposed approach on different event types. Results show that the participantbased approach can effectively capture the sub-events that have otherwise been shadowed by the long-tail of other dominant sub-events, yielding summaries with considerably better coverage than the state-of-the-art.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allan</author>
</authors>
<title>Topic detection and tracking: Eventbased information organization.</title>
<date>2002</date>
<publisher>Kluwer Academic Publishers</publisher>
<location>Norwell, MA, USA.</location>
<contexts>
<context position="16143" citStr="Allan, 2002" startWordPosition="2460" endWordPosition="2461">nt detection. Figure 2 shows the plate notation. In the proposed model, each tweet d in the data stream D is generated from a topic z, weighted by πz. Each topic is characterized by both its content and time aspects. The content aspect is captured by a multinomial distribution over the words, parameterized by θ; while the time aspect is characterized by a Gaussian distribution, parameterized by µ and σ, with µ represents the average time point that the sub-event emerges and σ determines the duration of the sub-event. These distributions bear similarities with the previous work (Hofmann, 1999; Allan, 2002; Haghighi and Vanderwende, 2009). In addition, there are often background or “noise” topics that are being constantly discussed over the entire lex sim(ci, cj)= { 1 ci(cj) is part of cj(ci) 1 EditDist(ci, cj) &lt; θ 0 Otherwise 1155 event evolvement process and do not present the desired “burstiness” property. We use a uniform distribution U(tb, te) to model the time aspect of these “background” topics, with tb and te being the event beginning and end time points. The content aspect of a background topic is modeled by similar multinomial distribution, parameterized by θ&apos;. We use the maximum like</context>
</contexts>
<marker>Allan, 2002</marker>
<rawString>James Allan. 2002. Topic detection and tracking: Eventbased information organization. Kluwer Academic Publishers Norwell, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hila Becker</author>
<author>Feiyang Chen</author>
<author>Dan Iter</author>
<author>Mor Naaman</author>
<author>Luis Gravano</author>
</authors>
<title>Automatic identification and presentation of twitter content for planned events.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media (ICWSM),</booktitle>
<pages>655--656</pages>
<contexts>
<context position="6856" citStr="Becker et al., 2011" startWordPosition="1007" endWordPosition="1010">of other dominant sub-events, yielding summaries with considerably better coverage than the state-of-the-art approach. 2 Related Work Mining Twitter for event information has received increasing attention in recent years. Many research studies focus on identifying the trending events from Twitter and providing a concise and dynamic visualization of the information. The identified events are often represented using a set of keywords. (Petrovic et al., 2010) proposed an algorithm based on locality-sensitive hashing for detecting new events from a stream of Twitter posts. (O’Connor et al., 2010; Becker et al., 2011b; Becker et al., 2011a; Weng et al., 2011) proposed demo systems to display the event-related themes and popular tweets, allowing the users to navigate through their topic of interest. (Zhao et al., 2011) described an effort to perform data collection and event recognition despite various limits to the free access of Twitter data. (Diao et al., 2012) integrated both temporal information and users’ personal interests for bursty topic detection from the microblogs. (Ritter et al., 2012) described an open-domain event-extraction and categorization system, which extracts an open-domain calendar o</context>
</contexts>
<marker>Becker, Chen, Iter, Naaman, Gravano, 2011</marker>
<rawString>Hila Becker, Feiyang Chen, Dan Iter, Mor Naaman, and Luis Gravano. 2011a. Automatic identification and presentation of twitter content for planned events. In Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media (ICWSM), pages 655–656.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hila Becker</author>
<author>Mor Naaman</author>
<author>Luis Gravano</author>
</authors>
<title>Beyond trending topics: Real-world event identification on twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media (ICWSM),</booktitle>
<pages>438--441</pages>
<contexts>
<context position="6856" citStr="Becker et al., 2011" startWordPosition="1007" endWordPosition="1010">of other dominant sub-events, yielding summaries with considerably better coverage than the state-of-the-art approach. 2 Related Work Mining Twitter for event information has received increasing attention in recent years. Many research studies focus on identifying the trending events from Twitter and providing a concise and dynamic visualization of the information. The identified events are often represented using a set of keywords. (Petrovic et al., 2010) proposed an algorithm based on locality-sensitive hashing for detecting new events from a stream of Twitter posts. (O’Connor et al., 2010; Becker et al., 2011b; Becker et al., 2011a; Weng et al., 2011) proposed demo systems to display the event-related themes and popular tweets, allowing the users to navigate through their topic of interest. (Zhao et al., 2011) described an effort to perform data collection and event recognition despite various limits to the free access of Twitter data. (Diao et al., 2012) integrated both temporal information and users’ personal interests for bursty topic detection from the microblogs. (Ritter et al., 2012) described an open-domain event-extraction and categorization system, which extracts an open-domain calendar o</context>
</contexts>
<marker>Becker, Naaman, Gravano, 2011</marker>
<rawString>Hila Becker, Mor Naaman, and Luis Gravano. 2011b. Beyond trending topics: Real-world event identification on twitter. In Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media (ICWSM), pages 438–441.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deepayan Chakrabarti</author>
<author>Kunal Punera</author>
</authors>
<title>Event summarization using tweets.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media (ICWSM),</booktitle>
<pages>66--73</pages>
<contexts>
<context position="4339" citStr="Chakrabarti and Punera, 2011" startWordPosition="629" endWordPosition="632">) and participant stream (lower). Event stream contains tweets related to an NBA basketball game (Spurs vs Thunder) scheduled on May 31, 2012; participant stream contains tweets corresponding to the player Russell Westbrook in team Thunder. X-axis denotes the timeline and y-axis represents the number of tweets per 10-second interval. ing key information must be reflected in the event summary. As such, event summarization research has been focusing on developing accurate sub-event detection systems and generating text descriptions that can best summarize the sub-events in a progressive manner (Chakrabarti and Punera, 2011; Nichols et al., 2012; Zubiaga et al., 2012). In Figure 1, we show an example Twitter event stream and one of its “participant” streams. The event stream contains all the tweets related to an NBA basketball game Spurs vs Thunder; while the participant stream contains only tweets corresponding to the player Russell Westbrook in this game. Previous research on event summarization focuses on identifying the important moments from the coarse-level event stream. This may yield several side effects: first, the spike patterns are not clearly identifiable from the overall event stream, though they ar</context>
<context position="9029" citStr="Chakrabarti and Punera, 2011" startWordPosition="1343" endWordPosition="1346">arabagiu and Hickl, 2011) introduced a generative framework that incorporates event structure and user behavior information in summarizing multiple microblog posts related to the same topic. Regarding summarizing the data streams, (Marcus et al., 2011) introduced a “TwitInfo” system to visually summarize and track the events on Twitter. They proposed an automatic peak detection and labeling algorithm for the social streams. (Takamura et al., 2011) proposed a summarization model based on the facility location problem, which generates summary for a stream of short documents along the timeline. (Chakrabarti and Punera, 2011) proposed an event summarization algorithm based on learning an underlying hidden state representation of the event via hidden Markov models. (Louis and Newman, 2012) presented a method for summarizing a collection of tweets related to a business. The proposed procedure aggregates tweets into subtopic clusters which are then ranked and summarized by a few representative tweets from each cluster. (Nichols et al., 2012; Zubiaga et al., 2012) focused on real-time event summarization, which detects the sub-events by identifying those moments where the tweet volume has increases sharply, then uses </context>
</contexts>
<marker>Chakrabarti, Punera, 2011</marker>
<rawString>Deepayan Chakrabarti and Kunal Punera. 2011. Event summarization using tweets. In Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media (ICWSM), pages 66–73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiming Diao</author>
<author>Jing Jiang</author>
<author>Feida Zhu</author>
<author>Ee-Peng Lim</author>
</authors>
<title>Finding bursty topics from microblogs.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>536--544</pages>
<contexts>
<context position="7209" citStr="Diao et al., 2012" startWordPosition="1066" endWordPosition="1069"> information. The identified events are often represented using a set of keywords. (Petrovic et al., 2010) proposed an algorithm based on locality-sensitive hashing for detecting new events from a stream of Twitter posts. (O’Connor et al., 2010; Becker et al., 2011b; Becker et al., 2011a; Weng et al., 2011) proposed demo systems to display the event-related themes and popular tweets, allowing the users to navigate through their topic of interest. (Zhao et al., 2011) described an effort to perform data collection and event recognition despite various limits to the free access of Twitter data. (Diao et al., 2012) integrated both temporal information and users’ personal interests for bursty topic detection from the microblogs. (Ritter et al., 2012) described an open-domain event-extraction and categorization system, which extracts an open-domain calendar of significant events from Twitter. With the identified events of interest, there is an ever-increasing demand for event summarization, which distills the huge volume of Twitter discussions into a concise and representative textual description of the events. Many studies start with the text summarization approaches that have been shown to perform well </context>
</contexts>
<marker>Diao, Jiang, Zhu, Lim, 2012</marker>
<rawString>Qiming Diao, Jing Jiang, Feida Zhu, and Ee-Peng Lim. 2012. Finding bursty topics from microblogs. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL), pages 536–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
</authors>
<title>What to do about bad language on the internet.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL/HLT).</booktitle>
<contexts>
<context position="2819" citStr="Eisenstein, 2013" startWordPosition="411" endWordPosition="412">ent, namely the Apple CEO’s keynote speech in the Apple Worldwide Developers Conference (WWDC 2012)1. All these events have excited great discussion among the Twitter community. Summarizing the Twitter event is a challenging task that has yet been fully explored in the past. Most previous summarization studies focus on the well-formatted news documents, as driven by the annual DUC2 and TAC3 evaluations. In contrast, the Twitter messages (a.k.a., tweets) are very short and noisy, containing nonstandard terms such as abbreviations, acronyms, emoticons, etc. (Liu et al., 2011b; Liu et al., 2012; Eisenstein, 2013). The noisy contents also cause great difficulties to the traditional NLP tools such as NER and dependency parser (Ritter et al., 2011; Foster et al., 2011), limiting the possibility of applying finer-grained event analysis tools. In nature, the event tweets are closely associated with the timeline and are drastically different from a static collection of news documents. The tweets converge into text streams that pulse along the timeline and cluster around the important moments or sub-events. These “sub-events” are of crucial importance since they represent a surge of interest from the Twitter</context>
</contexts>
<marker>Eisenstein, 2013</marker>
<rawString>Jacob Eisenstein. 2013. What to do about bad language on the internet. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL/HLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Foster</author>
<author>Ozlem Cetinoglu</author>
<author>Joachim Wagner</author>
<author>Joseph Le Roux</author>
<author>Stephen Hogan</author>
<author>Joakim Nivre</author>
<author>Deirdre Hogan</author>
<author>Josef van Genabith</author>
</authors>
<title>hardtoparse: POS tagging and parsing the twitterverse.</title>
<date>2011</date>
<booktitle>In Proceedings of the AAAI Workshop on Analyzing Microtext,</booktitle>
<pages>20--25</pages>
<marker>Foster, Cetinoglu, Wagner, Le Roux, Hogan, Nivre, Hogan, van Genabith, 2011</marker>
<rawString>Jennifer Foster, Ozlem Cetinoglu, Joachim Wagner, Joseph Le Roux, Stephen Hogan, Joakim Nivre, Deirdre Hogan, and Josef van Genabith. 2011. #hardtoparse: POS tagging and parsing the twitterverse. In Proceedings of the AAAI Workshop on Analyzing Microtext, pages 20–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Brendan O’Connor</author>
<author>Dipanjan Das</author>
<author>Daniel Mills</author>
<author>Jacob Eisenstein</author>
<author>Michael Heilman</author>
<author>Dani Yogatama</author>
<author>Jeffrey Flanigan</author>
<author>Noah A Smith</author>
</authors>
<title>Part-of-speech tagging for twitter: Annotation, features, and experiments.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT),</booktitle>
<pages>42--47</pages>
<marker>Gimpel, Schneider, O’Connor, Das, Mills, Eisenstein, Heilman, Yogatama, Flanigan, Smith, 2011</marker>
<rawString>Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A. Smith. 2011. Part-of-speech tagging for twitter: Annotation, features, and experiments. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT), pages 42–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Lucy Vanderwende</author>
</authors>
<title>Exploring content models for multi-Document summarization.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<pages>362--370</pages>
<contexts>
<context position="16176" citStr="Haghighi and Vanderwende, 2009" startWordPosition="2462" endWordPosition="2465"> Figure 2 shows the plate notation. In the proposed model, each tweet d in the data stream D is generated from a topic z, weighted by πz. Each topic is characterized by both its content and time aspects. The content aspect is captured by a multinomial distribution over the words, parameterized by θ; while the time aspect is characterized by a Gaussian distribution, parameterized by µ and σ, with µ represents the average time point that the sub-event emerges and σ determines the duration of the sub-event. These distributions bear similarities with the previous work (Hofmann, 1999; Allan, 2002; Haghighi and Vanderwende, 2009). In addition, there are often background or “noise” topics that are being constantly discussed over the entire lex sim(ci, cj)= { 1 ci(cj) is part of cj(ci) 1 EditDist(ci, cj) &lt; θ 0 Otherwise 1155 event evolvement process and do not present the desired “burstiness” property. We use a uniform distribution U(tb, te) to model the time aspect of these “background” topics, with tb and te being the event beginning and end time points. The content aspect of a background topic is modeled by similar multinomial distribution, parameterized by θ&apos;. We use the maximum likelihood parameter estimation. The </context>
</contexts>
<marker>Haghighi, Vanderwende, 2009</marker>
<rawString>Aria Haghighi and Lucy Vanderwende. 2009. Exploring content models for multi-Document summarization. In Proceedings of Human Language Technologies: The 2009Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 362–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda Harabagiu</author>
<author>Andrew Hickl</author>
</authors>
<title>Relevance modeling for microblog summarization.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media (ICWSM),</booktitle>
<pages>514--517</pages>
<contexts>
<context position="8425" citStr="Harabagiu and Hickl, 2011" startWordPosition="1251" endWordPosition="1254">form well on the news documents and 1153 develop adaptations to fit these methods to a collection of event tweets. (Sharifi et al., 2010b) proposed a graph-based phrase reinforcement algorithm to build a one-sentence summary from a collection of topic tweets. (Sharifi et al., 2010a; Inouye and Kalita, 2011) presented a hybrid TF-IDF approach to extract one- or multiple-sentence summary for each topic. (Liu et al., 2011a) proposed to use the concept-based ILP framework for summarizing the Twitter trending topics, using both tweets and the webpages linked from the tweets as input text sources. (Harabagiu and Hickl, 2011) introduced a generative framework that incorporates event structure and user behavior information in summarizing multiple microblog posts related to the same topic. Regarding summarizing the data streams, (Marcus et al., 2011) introduced a “TwitInfo” system to visually summarize and track the events on Twitter. They proposed an automatic peak detection and labeling algorithm for the social streams. (Takamura et al., 2011) proposed a summarization model based on the facility location problem, which generates summary for a stream of short documents along the timeline. (Chakrabarti and Punera, 2</context>
</contexts>
<marker>Harabagiu, Hickl, 2011</marker>
<rawString>Sanda Harabagiu and Andrew Hickl. 2011. Relevance modeling for microblog summarization. In Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media (ICWSM), pages 514–517.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Probabilistic latent semantic analysis.</title>
<date>1999</date>
<booktitle>In Proceedings of Uncertainty in Artificial Intelligence (UAI).</booktitle>
<contexts>
<context position="16130" citStr="Hofmann, 1999" startWordPosition="2458" endWordPosition="2459">ach for sub-event detection. Figure 2 shows the plate notation. In the proposed model, each tweet d in the data stream D is generated from a topic z, weighted by πz. Each topic is characterized by both its content and time aspects. The content aspect is captured by a multinomial distribution over the words, parameterized by θ; while the time aspect is characterized by a Gaussian distribution, parameterized by µ and σ, with µ represents the average time point that the sub-event emerges and σ determines the duration of the sub-event. These distributions bear similarities with the previous work (Hofmann, 1999; Allan, 2002; Haghighi and Vanderwende, 2009). In addition, there are often background or “noise” topics that are being constantly discussed over the entire lex sim(ci, cj)= { 1 ci(cj) is part of cj(ci) 1 EditDist(ci, cj) &lt; θ 0 Otherwise 1155 event evolvement process and do not present the desired “burstiness” property. We use a uniform distribution U(tb, te) to model the time aspect of these “background” topics, with tb and te being the event beginning and end time points. The content aspect of a background topic is modeled by similar multinomial distribution, parameterized by θ&apos;. We use the</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann. 1999. Probabilistic latent semantic analysis. In Proceedings of Uncertainty in Artificial Intelligence (UAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Inouye</author>
<author>Jugal K Kalita</author>
</authors>
<title>Comparing twitter summarization algorithms for multiple post summaries.</title>
<date>2011</date>
<booktitle>In Proceedings of 2011 IEEE Third International Conference on Social Computing,</booktitle>
<pages>290--306</pages>
<contexts>
<context position="8107" citStr="Inouye and Kalita, 2011" startWordPosition="1202" endWordPosition="1205">witter. With the identified events of interest, there is an ever-increasing demand for event summarization, which distills the huge volume of Twitter discussions into a concise and representative textual description of the events. Many studies start with the text summarization approaches that have been shown to perform well on the news documents and 1153 develop adaptations to fit these methods to a collection of event tweets. (Sharifi et al., 2010b) proposed a graph-based phrase reinforcement algorithm to build a one-sentence summary from a collection of topic tweets. (Sharifi et al., 2010a; Inouye and Kalita, 2011) presented a hybrid TF-IDF approach to extract one- or multiple-sentence summary for each topic. (Liu et al., 2011a) proposed to use the concept-based ILP framework for summarizing the Twitter trending topics, using both tweets and the webpages linked from the tweets as input text sources. (Harabagiu and Hickl, 2011) introduced a generative framework that incorporates event structure and user behavior information in summarizing multiple microblog posts related to the same topic. Regarding summarizing the data streams, (Marcus et al., 2011) introduced a “TwitInfo” system to visually summarize a</context>
<context position="21164" citStr="Inouye and Kalita, 2011" startWordPosition="3351" endWordPosition="3354">a set, including six NBA basketball games and the WWDC 2012 conference event. for event summarization, but not on proposing new methods for tweet selection. We thus use the Hybrid TF-IDF approach (Sharifi et al., 2010a; Liu et al., 2011a) to extract the representative sentences from a collection of tweets. In this approach, each tweet was considered as a sentence. The sentences were ranked according to the average TF-IDF score of the consisting words; top weighted sentences were iteratively extracted, while excluding those that have high cosine similarity with the existing summary sentences. (Inouye and Kalita, 2011) showed the Hybrid TF-IDF approach performs constantly better than the phrase reinforcement algorithm and other traditional summarization systems. 4 Data Corpus We evaluate the proposed event summarization approach on six NBA basketball games and a representative conference event, namely the Apple CEO’s keynote speech in the Apple Worldwide Developers Conference (WWDC 2012)9. We use the heterogeneous event types to verify that the proposed approach can robustly and efficiently produce summaries on different event streams. The tweet streams corresponding to these events are collected using the </context>
</contexts>
<marker>Inouye, Kalita, 2011</marker>
<rawString>David Inouye and Jugal K. Kalita. 2011. Comparing twitter summarization algorithms for multiple post summaries. In Proceedings of 2011 IEEE Third International Conference on Social Computing, pages 290– 306.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lillian Lee</author>
</authors>
<title>Measures of distributional similarity.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>25--32</pages>
<contexts>
<context position="19166" citStr="Lee, 1999" startWordPosition="3022" endWordPosition="3023"> background topics if their σ values are greater than a threshold β7. We then re-run the EM to obtain the updated parameters. The topic re-adjustment process continues until the number of sub-events and background topics do not change further. We obtain the “participant sub-events” by applying this sub-event detection approach to each of the participant streams. The “global sub-events” are obtained by merging the participant sub-events along the timeline. We merge two participant subevents into a global sub-event if (1) their peaks are within a 2-minute window, and (2) the Jaccard similarity (Lee, 1999) between their associated tweets is greater than a threshold (set to 0.1 empirically). The tweets associated with each global sub-event are the ones with p(z|d) greater than a threshold γ, where z is one of the participant sub-events and γ was set to 0.7 empirically. After the sub-event detection process, we obtain a set of global sub-events and their associated event tweets.8 3.3 Summary Tweet Extraction We extract a representative tweet from each of the global sub-events and concatenate them to form an informative event summary. Note that our goal in this work is to identify all the importan</context>
</contexts>
<marker>Lee, 1999</marker>
<rawString>Lillian Lee. 1999. Measures of distributional similarity. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL), pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
</authors>
<title>ROUGE: A package for automatic evaluation of summaries.</title>
<date>2004</date>
<booktitle>In Workshop on Text Summarization Branches Out.</booktitle>
<contexts>
<context position="33967" citStr="Lin, 2004" startWordPosition="5400" endWordPosition="5401">ision, which is consistent to our findings on the participant streams. 5.3 Summarization Results Summarization evaluation has been a longstanding issue in the literature (Nenkova and Mckeown, 2011; Liu and Liu, 2010). There are even less studies focusing on evaluating the event summaries generated from data streams. Since the summary annotation takes quite some effort, we sample a 10-minute segment from each of the seven event streams and ask a human annotator to select representative tweets for each segment. We then compare the system summaries against the manual summaries using the ROUGE-1 (Lin, 2004) metric. The quantitative results and qualitative analysis are presented in Table 5 and Table 6 respectively. Note that the ROUGE scores are based solely on the n-gram overlap between the system and reference summaries, which may not be the most appropriate measure for evaluating the Twitter event summaries. However, we do notice that the accurate sub-event detection performance can successfully translate into a gain of the ROUGE scores. Qualitatively, the participantbased event summarization approach focus more on extracting tweets associated with the targeted participants, which could lead t</context>
</contexts>
<marker>Lin, 2004</marker>
<rawString>Chin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. In Workshop on Text Summarization Branches Out.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feifan Liu</author>
<author>Yang Liu</author>
</authors>
<title>Exploring correlation between ROUGE and human evaluation on meeting summaries.</title>
<date>2010</date>
<journal>IEEE Transactions on Audio, Speech, and Language Processing,</journal>
<volume>18</volume>
<issue>1</issue>
<contexts>
<context position="33573" citStr="Liu and Liu, 2010" startWordPosition="5334" endWordPosition="5337">e a better chance of identifying the sub-events that have otherwise been shadowed by the dominant sub-events or participants. The two participantbased methods yield similar recall but “Participant 1159 + Spike” yields slightly worse precision, since it is very sensitive to the spikes on the participant-level, leading to the rise of false alarms. The “Participant + MM” approach is much better in precision, which is consistent to our findings on the participant streams. 5.3 Summarization Results Summarization evaluation has been a longstanding issue in the literature (Nenkova and Mckeown, 2011; Liu and Liu, 2010). There are even less studies focusing on evaluating the event summaries generated from data streams. Since the summary annotation takes quite some effort, we sample a 10-minute segment from each of the seven event streams and ask a human annotator to select representative tweets for each segment. We then compare the system summaries against the manual summaries using the ROUGE-1 (Lin, 2004) metric. The quantitative results and qualitative analysis are presented in Table 5 and Table 6 respectively. Note that the ROUGE scores are based solely on the n-gram overlap between the system and referen</context>
</contexts>
<marker>Liu, Liu, 2010</marker>
<rawString>Feifan Liu and Yang Liu. 2010. Exploring correlation between ROUGE and human evaluation on meeting summaries. IEEE Transactions on Audio, Speech, and Language Processing, 18(1):187–196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Liu</author>
<author>Yang Liu</author>
<author>Fuliang Weng</author>
</authors>
<title>Why is ”SXSW” trending? Exploring multiple text sources for twitter topic summarization.</title>
<date>2011</date>
<booktitle>In Proceedings of the ACL Workshop on Language in Social Media (LSM),</booktitle>
<pages>66--75</pages>
<contexts>
<context position="2781" citStr="Liu et al., 2011" startWordPosition="403" endWordPosition="406">es and a representative conference event, namely the Apple CEO’s keynote speech in the Apple Worldwide Developers Conference (WWDC 2012)1. All these events have excited great discussion among the Twitter community. Summarizing the Twitter event is a challenging task that has yet been fully explored in the past. Most previous summarization studies focus on the well-formatted news documents, as driven by the annual DUC2 and TAC3 evaluations. In contrast, the Twitter messages (a.k.a., tweets) are very short and noisy, containing nonstandard terms such as abbreviations, acronyms, emoticons, etc. (Liu et al., 2011b; Liu et al., 2012; Eisenstein, 2013). The noisy contents also cause great difficulties to the traditional NLP tools such as NER and dependency parser (Ritter et al., 2011; Foster et al., 2011), limiting the possibility of applying finer-grained event analysis tools. In nature, the event tweets are closely associated with the timeline and are drastically different from a static collection of news documents. The tweets converge into text streams that pulse along the timeline and cluster around the important moments or sub-events. These “sub-events” are of crucial importance since they represen</context>
<context position="8221" citStr="Liu et al., 2011" startWordPosition="1220" endWordPosition="1223"> the huge volume of Twitter discussions into a concise and representative textual description of the events. Many studies start with the text summarization approaches that have been shown to perform well on the news documents and 1153 develop adaptations to fit these methods to a collection of event tweets. (Sharifi et al., 2010b) proposed a graph-based phrase reinforcement algorithm to build a one-sentence summary from a collection of topic tweets. (Sharifi et al., 2010a; Inouye and Kalita, 2011) presented a hybrid TF-IDF approach to extract one- or multiple-sentence summary for each topic. (Liu et al., 2011a) proposed to use the concept-based ILP framework for summarizing the Twitter trending topics, using both tweets and the webpages linked from the tweets as input text sources. (Harabagiu and Hickl, 2011) introduced a generative framework that incorporates event structure and user behavior information in summarizing multiple microblog posts related to the same topic. Regarding summarizing the data streams, (Marcus et al., 2011) introduced a “TwitInfo” system to visually summarize and track the events on Twitter. They proposed an automatic peak detection and labeling algorithm for the social st</context>
<context position="20776" citStr="Liu et al., 2011" startWordPosition="3293" endWordPosition="3296">p(w; θ&apos;j) else wEd ⎧ ⎨ ⎩ 1156 Event Date Duration #Tweets Lakers vs Okc 05/19/2012 3h10m 218,313 N Celtics vs 76ers 05/23/2012 3h30m 245,734 B Celtics vs Heat 05/30/2012 3h30m 345,335 A Spurs vs Okc 05/31/2012 3h 254,670 Heat vs Okc (1) 06/12/2012 3h30m 331,498 Heat vs Okc (2) 06/21/2012 3h30m 332,223 Apple’s WWDC’12 Conf. 06/11/2012 3h30m 163,775 Table 1: Statistics of the data set, including six NBA basketball games and the WWDC 2012 conference event. for event summarization, but not on proposing new methods for tweet selection. We thus use the Hybrid TF-IDF approach (Sharifi et al., 2010a; Liu et al., 2011a) to extract the representative sentences from a collection of tweets. In this approach, each tweet was considered as a sentence. The sentences were ranked according to the average TF-IDF score of the consisting words; top weighted sentences were iteratively extracted, while excluding those that have high cosine similarity with the existing summary sentences. (Inouye and Kalita, 2011) showed the Hybrid TF-IDF approach performs constantly better than the phrase reinforcement algorithm and other traditional summarization systems. 4 Data Corpus We evaluate the proposed event summarization approa</context>
</contexts>
<marker>Liu, Liu, Weng, 2011</marker>
<rawString>Fei Liu, Yang Liu, and Fuliang Weng. 2011a. Why is ”SXSW” trending? Exploring multiple text sources for twitter topic summarization. In Proceedings of the ACL Workshop on Language in Social Media (LSM), pages 66–75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Liu</author>
<author>Fuliang Weng</author>
<author>Bingqing Wang</author>
<author>Yang Liu</author>
</authors>
<title>Insertion, deletion, or substitution? Normalizing text messages without pre-categorization nor supervision.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>71--76</pages>
<contexts>
<context position="2781" citStr="Liu et al., 2011" startWordPosition="403" endWordPosition="406">es and a representative conference event, namely the Apple CEO’s keynote speech in the Apple Worldwide Developers Conference (WWDC 2012)1. All these events have excited great discussion among the Twitter community. Summarizing the Twitter event is a challenging task that has yet been fully explored in the past. Most previous summarization studies focus on the well-formatted news documents, as driven by the annual DUC2 and TAC3 evaluations. In contrast, the Twitter messages (a.k.a., tweets) are very short and noisy, containing nonstandard terms such as abbreviations, acronyms, emoticons, etc. (Liu et al., 2011b; Liu et al., 2012; Eisenstein, 2013). The noisy contents also cause great difficulties to the traditional NLP tools such as NER and dependency parser (Ritter et al., 2011; Foster et al., 2011), limiting the possibility of applying finer-grained event analysis tools. In nature, the event tweets are closely associated with the timeline and are drastically different from a static collection of news documents. The tweets converge into text streams that pulse along the timeline and cluster around the important moments or sub-events. These “sub-events” are of crucial importance since they represen</context>
<context position="8221" citStr="Liu et al., 2011" startWordPosition="1220" endWordPosition="1223"> the huge volume of Twitter discussions into a concise and representative textual description of the events. Many studies start with the text summarization approaches that have been shown to perform well on the news documents and 1153 develop adaptations to fit these methods to a collection of event tweets. (Sharifi et al., 2010b) proposed a graph-based phrase reinforcement algorithm to build a one-sentence summary from a collection of topic tweets. (Sharifi et al., 2010a; Inouye and Kalita, 2011) presented a hybrid TF-IDF approach to extract one- or multiple-sentence summary for each topic. (Liu et al., 2011a) proposed to use the concept-based ILP framework for summarizing the Twitter trending topics, using both tweets and the webpages linked from the tweets as input text sources. (Harabagiu and Hickl, 2011) introduced a generative framework that incorporates event structure and user behavior information in summarizing multiple microblog posts related to the same topic. Regarding summarizing the data streams, (Marcus et al., 2011) introduced a “TwitInfo” system to visually summarize and track the events on Twitter. They proposed an automatic peak detection and labeling algorithm for the social st</context>
<context position="20776" citStr="Liu et al., 2011" startWordPosition="3293" endWordPosition="3296">p(w; θ&apos;j) else wEd ⎧ ⎨ ⎩ 1156 Event Date Duration #Tweets Lakers vs Okc 05/19/2012 3h10m 218,313 N Celtics vs 76ers 05/23/2012 3h30m 245,734 B Celtics vs Heat 05/30/2012 3h30m 345,335 A Spurs vs Okc 05/31/2012 3h 254,670 Heat vs Okc (1) 06/12/2012 3h30m 331,498 Heat vs Okc (2) 06/21/2012 3h30m 332,223 Apple’s WWDC’12 Conf. 06/11/2012 3h30m 163,775 Table 1: Statistics of the data set, including six NBA basketball games and the WWDC 2012 conference event. for event summarization, but not on proposing new methods for tweet selection. We thus use the Hybrid TF-IDF approach (Sharifi et al., 2010a; Liu et al., 2011a) to extract the representative sentences from a collection of tweets. In this approach, each tweet was considered as a sentence. The sentences were ranked according to the average TF-IDF score of the consisting words; top weighted sentences were iteratively extracted, while excluding those that have high cosine similarity with the existing summary sentences. (Inouye and Kalita, 2011) showed the Hybrid TF-IDF approach performs constantly better than the phrase reinforcement algorithm and other traditional summarization systems. 4 Data Corpus We evaluate the proposed event summarization approa</context>
</contexts>
<marker>Liu, Weng, Wang, Liu, 2011</marker>
<rawString>Fei Liu, Fuliang Weng, Bingqing Wang, and Yang Liu. 2011b. Insertion, deletion, or substitution? Normalizing text messages without pre-categorization nor supervision. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL), pages 71–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Liu</author>
<author>Fuliang Weng</author>
<author>Xiao Jiang</author>
</authors>
<title>A broadcoverage normalization system for social media language.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>1035--1044</pages>
<contexts>
<context position="2800" citStr="Liu et al., 2012" startWordPosition="407" endWordPosition="410">tive conference event, namely the Apple CEO’s keynote speech in the Apple Worldwide Developers Conference (WWDC 2012)1. All these events have excited great discussion among the Twitter community. Summarizing the Twitter event is a challenging task that has yet been fully explored in the past. Most previous summarization studies focus on the well-formatted news documents, as driven by the annual DUC2 and TAC3 evaluations. In contrast, the Twitter messages (a.k.a., tweets) are very short and noisy, containing nonstandard terms such as abbreviations, acronyms, emoticons, etc. (Liu et al., 2011b; Liu et al., 2012; Eisenstein, 2013). The noisy contents also cause great difficulties to the traditional NLP tools such as NER and dependency parser (Ritter et al., 2011; Foster et al., 2011), limiting the possibility of applying finer-grained event analysis tools. In nature, the event tweets are closely associated with the timeline and are drastically different from a static collection of news documents. The tweets converge into text streams that pulse along the timeline and cluster around the important moments or sub-events. These “sub-events” are of crucial importance since they represent a surge of intere</context>
</contexts>
<marker>Liu, Weng, Jiang, 2012</marker>
<rawString>Fei Liu, Fuliang Weng, and Xiao Jiang. 2012. A broadcoverage normalization system for social media language. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL), pages 1035–1044.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annie Louis</author>
<author>Todd Newman</author>
</authors>
<title>Summarization of business-related tweets: A concept-based approach.</title>
<date>2012</date>
<booktitle>In Proceedings of the 24th International Conference on Computational Linguistics (COLING).</booktitle>
<contexts>
<context position="9195" citStr="Louis and Newman, 2012" startWordPosition="1368" endWordPosition="1371">to the same topic. Regarding summarizing the data streams, (Marcus et al., 2011) introduced a “TwitInfo” system to visually summarize and track the events on Twitter. They proposed an automatic peak detection and labeling algorithm for the social streams. (Takamura et al., 2011) proposed a summarization model based on the facility location problem, which generates summary for a stream of short documents along the timeline. (Chakrabarti and Punera, 2011) proposed an event summarization algorithm based on learning an underlying hidden state representation of the event via hidden Markov models. (Louis and Newman, 2012) presented a method for summarizing a collection of tweets related to a business. The proposed procedure aggregates tweets into subtopic clusters which are then ranked and summarized by a few representative tweets from each cluster. (Nichols et al., 2012; Zubiaga et al., 2012) focused on real-time event summarization, which detects the sub-events by identifying those moments where the tweet volume has increases sharply, then uses various weighting schemes to perform tweet selection and finally generates the event summary. Our work is different from the above research studies in three folds: fi</context>
</contexts>
<marker>Louis, Newman, 2012</marker>
<rawString>Annie Louis and Todd Newman. 2012. Summarization of business-related tweets: A concept-based approach. In Proceedings of the 24th International Conference on Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Marcus</author>
<author>Michael S Bernstein</author>
<author>Osama Badar</author>
<author>David R Karger</author>
<author>Samuel Madden</author>
<author>Robert C Miller</author>
</authors>
<title>Twitinfo: Aggregating and visualizing microblogs for event exploration.</title>
<date>2011</date>
<booktitle>In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,</booktitle>
<pages>227--236</pages>
<contexts>
<context position="8652" citStr="Marcus et al., 2011" startWordPosition="1283" endWordPosition="1287">ollection of topic tweets. (Sharifi et al., 2010a; Inouye and Kalita, 2011) presented a hybrid TF-IDF approach to extract one- or multiple-sentence summary for each topic. (Liu et al., 2011a) proposed to use the concept-based ILP framework for summarizing the Twitter trending topics, using both tweets and the webpages linked from the tweets as input text sources. (Harabagiu and Hickl, 2011) introduced a generative framework that incorporates event structure and user behavior information in summarizing multiple microblog posts related to the same topic. Regarding summarizing the data streams, (Marcus et al., 2011) introduced a “TwitInfo” system to visually summarize and track the events on Twitter. They proposed an automatic peak detection and labeling algorithm for the social streams. (Takamura et al., 2011) proposed a summarization model based on the facility location problem, which generates summary for a stream of short documents along the timeline. (Chakrabarti and Punera, 2011) proposed an event summarization algorithm based on learning an underlying hidden state representation of the event via hidden Markov models. (Louis and Newman, 2012) presented a method for summarizing a collection of tweet</context>
<context position="19832" citStr="Marcus et al., 2011" startWordPosition="3131" endWordPosition="3134">an a threshold (set to 0.1 empirically). The tweets associated with each global sub-event are the ones with p(z|d) greater than a threshold γ, where z is one of the participant sub-events and γ was set to 0.7 empirically. After the sub-event detection process, we obtain a set of global sub-events and their associated event tweets.8 3.3 Summary Tweet Extraction We extract a representative tweet from each of the global sub-events and concatenate them to form an informative event summary. Note that our goal in this work is to identify all the important moments 6We use the algorithm described in (Marcus et al., 2011) as a baseline and ad hoc spike detection algorithm. 7,3 was set to 5 minutes in our experiments. 8We empirically set some threshold values in the topic readjustment and sub-event merging process. In future, we would like to explore more principled way of parameter selection. πjN(d;µj,σj) Q p(w; θj) if j &lt;= K wEd πjU(tb,te) Q p(w; θ&apos;j) else wEd ⎧ ⎨ ⎩ 1156 Event Date Duration #Tweets Lakers vs Okc 05/19/2012 3h10m 218,313 N Celtics vs 76ers 05/23/2012 3h30m 245,734 B Celtics vs Heat 05/30/2012 3h30m 345,335 A Spurs vs Okc 05/31/2012 3h 254,670 Heat vs Okc (1) 06/12/2012 3h30m 331,498 Heat vs Ok</context>
<context position="29458" citStr="Marcus et al., 2011" startWordPosition="4679" endWordPosition="4682">.58 0.84 0.57 0.68 81 0.41 0.42 0.41 0.88 0.35 0.50 0.91 0.54 0.68 Heat vs Okc (1) 15 123 0.75 0.27 0.40 0.72 0.35 0.47 85 0.41 0.47 0.44 0.94 0.20 0.33 0.96 0.34 0.50 Heat vs okc (2) 13 153 0.74 0.36 0.48 0.76 0.43 0.55 92 0.41 0.33 0.37 0.88 0.21 0.34 0.87 0.38 0.53 WWDC’12 10 56 0.64 0.14 0.23 0.59 0.33 0.42 43 0.53 0.26 0.35 0.77 0.14 0.24 0.70 0.31 0.43 Average 12 105 0.67 0.32 0.42 0.66 0.41 0.50 68 0.52 0.40 0.44 0.87 0.21 0.34 0.86 0.38 0.52 Table 4: Sub-event detection results on both participant and the event streams. “Spike” corresponds to the spike detection algorithm proposed in (Marcus et al., 2011); “MM” represents our proposed time-content mixture model approach. “#P” and “#S” list the number of participants and sub-events in each event stream. discriminative enough. We found that adding the lexical similarity measure greatly boosted the clustering performance, especially on the mention-level, and that combining the lexical similarity with the local context is even more helpful for some events. We notice that two events (celtics vs 76ers and celtics vs heat) yield relatively low precision on both participant- and mention-level. Taking a close look at the data, we found that these two e</context>
</contexts>
<marker>Marcus, Bernstein, Badar, Karger, Madden, Miller, 2011</marker>
<rawString>Adam Marcus, Michael S. Bernstein, Osama Badar, David R. Karger, Samuel Madden, and Robert C. Miller. 2011. Twitinfo: Aggregating and visualizing microblogs for event exploration. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pages 227–236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ani Nenkova</author>
<author>Kathleen Mckeown</author>
</authors>
<date>2011</date>
<booktitle>Automatic summarization. Foundations and Trends in Information Retrieval,</booktitle>
<pages>5--2</pages>
<contexts>
<context position="33553" citStr="Nenkova and Mckeown, 2011" startWordPosition="5330" endWordPosition="5333">participant streams, we have a better chance of identifying the sub-events that have otherwise been shadowed by the dominant sub-events or participants. The two participantbased methods yield similar recall but “Participant 1159 + Spike” yields slightly worse precision, since it is very sensitive to the spikes on the participant-level, leading to the rise of false alarms. The “Participant + MM” approach is much better in precision, which is consistent to our findings on the participant streams. 5.3 Summarization Results Summarization evaluation has been a longstanding issue in the literature (Nenkova and Mckeown, 2011; Liu and Liu, 2010). There are even less studies focusing on evaluating the event summaries generated from data streams. Since the summary annotation takes quite some effort, we sample a 10-minute segment from each of the seven event streams and ask a human annotator to select representative tweets for each segment. We then compare the system summaries against the manual summaries using the ROUGE-1 (Lin, 2004) metric. The quantitative results and qualitative analysis are presented in Table 5 and Table 6 respectively. Note that the ROUGE scores are based solely on the n-gram overlap between th</context>
</contexts>
<marker>Nenkova, Mckeown, 2011</marker>
<rawString>Ani Nenkova and Kathleen Mckeown. 2011. Automatic summarization. Foundations and Trends in Information Retrieval, 5(2–3):103–233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ani Nenkova</author>
<author>Rebecca Passonneau</author>
<author>Kathleen Mckeown</author>
</authors>
<title>The pyramid method: Incorporating human content selection variation in summarization evaluation.</title>
<date>2007</date>
<journal>ACM Transactions on Speech and Language Processing,</journal>
<volume>4</volume>
<issue>2</issue>
<marker>Nenkova, Passonneau, Mckeown, 2007</marker>
<rawString>Ani Nenkova, Rebecca Passonneau, and Kathleen Mckeown. 2007. The pyramid method: Incorporating human content selection variation in summarization evaluation. ACM Transactions on Speech and Language Processing, 4(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Nichols</author>
<author>Jalal Mahmud</author>
<author>Clemens Drews</author>
</authors>
<title>Summarizing sporting events using twitter.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 ACM Interntional Conference on Intelligent User Interfaces (IUI),</booktitle>
<pages>189--198</pages>
<contexts>
<context position="4361" citStr="Nichols et al., 2012" startWordPosition="633" endWordPosition="636">r). Event stream contains tweets related to an NBA basketball game (Spurs vs Thunder) scheduled on May 31, 2012; participant stream contains tweets corresponding to the player Russell Westbrook in team Thunder. X-axis denotes the timeline and y-axis represents the number of tweets per 10-second interval. ing key information must be reflected in the event summary. As such, event summarization research has been focusing on developing accurate sub-event detection systems and generating text descriptions that can best summarize the sub-events in a progressive manner (Chakrabarti and Punera, 2011; Nichols et al., 2012; Zubiaga et al., 2012). In Figure 1, we show an example Twitter event stream and one of its “participant” streams. The event stream contains all the tweets related to an NBA basketball game Spurs vs Thunder; while the participant stream contains only tweets corresponding to the player Russell Westbrook in this game. Previous research on event summarization focuses on identifying the important moments from the coarse-level event stream. This may yield several side effects: first, the spike patterns are not clearly identifiable from the overall event stream, though they are more clearly seen if</context>
<context position="9449" citStr="Nichols et al., 2012" startWordPosition="1408" endWordPosition="1411">Takamura et al., 2011) proposed a summarization model based on the facility location problem, which generates summary for a stream of short documents along the timeline. (Chakrabarti and Punera, 2011) proposed an event summarization algorithm based on learning an underlying hidden state representation of the event via hidden Markov models. (Louis and Newman, 2012) presented a method for summarizing a collection of tweets related to a business. The proposed procedure aggregates tweets into subtopic clusters which are then ranked and summarized by a few representative tweets from each cluster. (Nichols et al., 2012; Zubiaga et al., 2012) focused on real-time event summarization, which detects the sub-events by identifying those moments where the tweet volume has increases sharply, then uses various weighting schemes to perform tweet selection and finally generates the event summary. Our work is different from the above research studies in three folds: first, we propose to “zoomin” the Twitter event streams to the participant level, which allows us to clearly identify the important sub-events associated with each participant and generate a balanced event summary with comprehensive coverage of all the imp</context>
</contexts>
<marker>Nichols, Mahmud, Drews, 2012</marker>
<rawString>Jeffrey Nichols, Jalal Mahmud, and Clemens Drews. 2012. Summarizing sporting events using twitter. In Proceedings of the 2012 ACM Interntional Conference on Intelligent User Interfaces (IUI), pages 189–198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brendan O’Connor</author>
<author>Michel Krieger</author>
<author>David Ahn</author>
</authors>
<title>TweetMotif: Exploratory search and topic summarization for twitter.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media (ICWSM),</booktitle>
<pages>384--385</pages>
<marker>O’Connor, Krieger, Ahn, 2010</marker>
<rawString>Brendan O’Connor, Michel Krieger, and David Ahn. 2010. TweetMotif: Exploratory search and topic summarization for twitter. In Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media (ICWSM), pages 384–385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sasa Petrovic</author>
<author>Miles Osborne</author>
<author>Victor Lavrenko</author>
</authors>
<title>Streaming first story detection with application to twitter.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<pages>181--189</pages>
<contexts>
<context position="6697" citStr="Petrovic et al., 2010" startWordPosition="981" endWordPosition="985">f the participant streams, and the participantbased event summarization can effectively capture the sub-events that have otherwise been shadowed by the long-tail of other dominant sub-events, yielding summaries with considerably better coverage than the state-of-the-art approach. 2 Related Work Mining Twitter for event information has received increasing attention in recent years. Many research studies focus on identifying the trending events from Twitter and providing a concise and dynamic visualization of the information. The identified events are often represented using a set of keywords. (Petrovic et al., 2010) proposed an algorithm based on locality-sensitive hashing for detecting new events from a stream of Twitter posts. (O’Connor et al., 2010; Becker et al., 2011b; Becker et al., 2011a; Weng et al., 2011) proposed demo systems to display the event-related themes and popular tweets, allowing the users to navigate through their topic of interest. (Zhao et al., 2011) described an effort to perform data collection and event recognition despite various limits to the free access of Twitter data. (Diao et al., 2012) integrated both temporal information and users’ personal interests for bursty topic det</context>
</contexts>
<marker>Petrovic, Osborne, Lavrenko, 2010</marker>
<rawString>Sasa Petrovic, Miles Osborne, and Victor Lavrenko. 2010. Streaming first story detection with application to twitter. In Proceedings of the 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 181–189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Sam Clark</author>
<author>Mausam</author>
<author>Oren Etzioni</author>
</authors>
<title>Named entity recognition in tweets: An experimental study.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1524--1534</pages>
<contexts>
<context position="2953" citStr="Ritter et al., 2011" startWordPosition="432" endWordPosition="435">great discussion among the Twitter community. Summarizing the Twitter event is a challenging task that has yet been fully explored in the past. Most previous summarization studies focus on the well-formatted news documents, as driven by the annual DUC2 and TAC3 evaluations. In contrast, the Twitter messages (a.k.a., tweets) are very short and noisy, containing nonstandard terms such as abbreviations, acronyms, emoticons, etc. (Liu et al., 2011b; Liu et al., 2012; Eisenstein, 2013). The noisy contents also cause great difficulties to the traditional NLP tools such as NER and dependency parser (Ritter et al., 2011; Foster et al., 2011), limiting the possibility of applying finer-grained event analysis tools. In nature, the event tweets are closely associated with the timeline and are drastically different from a static collection of news documents. The tweets converge into text streams that pulse along the timeline and cluster around the important moments or sub-events. These “sub-events” are of crucial importance since they represent a surge of interest from the Twitter audience and the correspond1https://developer.apple.com/wwdc/ 2http://duc.nist.gov/ 3http://www.nist.gov/tac/ 1152 Proceedings of NAA</context>
</contexts>
<marker>Ritter, Clark, Mausam, Etzioni, 2011</marker>
<rawString>Alan Ritter, Sam Clark, Mausam, and Oren Etzioni. 2011. Named entity recognition in tweets: An experimental study. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1524–1534.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Oren Etzioni Mausam</author>
<author>Sam Clark</author>
</authors>
<title>Open domain event extraction from twitter.</title>
<date>2012</date>
<booktitle>In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>1104--1112</pages>
<contexts>
<context position="7346" citStr="Ritter et al., 2012" startWordPosition="1086" endWordPosition="1089">on locality-sensitive hashing for detecting new events from a stream of Twitter posts. (O’Connor et al., 2010; Becker et al., 2011b; Becker et al., 2011a; Weng et al., 2011) proposed demo systems to display the event-related themes and popular tweets, allowing the users to navigate through their topic of interest. (Zhao et al., 2011) described an effort to perform data collection and event recognition despite various limits to the free access of Twitter data. (Diao et al., 2012) integrated both temporal information and users’ personal interests for bursty topic detection from the microblogs. (Ritter et al., 2012) described an open-domain event-extraction and categorization system, which extracts an open-domain calendar of significant events from Twitter. With the identified events of interest, there is an ever-increasing demand for event summarization, which distills the huge volume of Twitter discussions into a concise and representative textual description of the events. Many studies start with the text summarization approaches that have been shown to perform well on the news documents and 1153 develop adaptations to fit these methods to a collection of event tweets. (Sharifi et al., 2010b) proposed</context>
</contexts>
<marker>Ritter, Mausam, Clark, 2012</marker>
<rawString>Alan Ritter, Mausam, Oren Etzioni, and Sam Clark. 2012. Open domain event extraction from twitter. In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1104–1112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beaux Sharifi</author>
<author>Mark-Anthony Hutton</author>
<author>Jugal K Kalita</author>
</authors>
<title>Experiments in microblog summarization.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 IEEE Second International Conference on Social Computing,</booktitle>
<pages>49--56</pages>
<contexts>
<context position="7935" citStr="Sharifi et al., 2010" startWordPosition="1176" endWordPosition="1179">croblogs. (Ritter et al., 2012) described an open-domain event-extraction and categorization system, which extracts an open-domain calendar of significant events from Twitter. With the identified events of interest, there is an ever-increasing demand for event summarization, which distills the huge volume of Twitter discussions into a concise and representative textual description of the events. Many studies start with the text summarization approaches that have been shown to perform well on the news documents and 1153 develop adaptations to fit these methods to a collection of event tweets. (Sharifi et al., 2010b) proposed a graph-based phrase reinforcement algorithm to build a one-sentence summary from a collection of topic tweets. (Sharifi et al., 2010a; Inouye and Kalita, 2011) presented a hybrid TF-IDF approach to extract one- or multiple-sentence summary for each topic. (Liu et al., 2011a) proposed to use the concept-based ILP framework for summarizing the Twitter trending topics, using both tweets and the webpages linked from the tweets as input text sources. (Harabagiu and Hickl, 2011) introduced a generative framework that incorporates event structure and user behavior information in summariz</context>
<context position="20757" citStr="Sharifi et al., 2010" startWordPosition="3289" endWordPosition="3292"> &lt;= K wEd πjU(tb,te) Q p(w; θ&apos;j) else wEd ⎧ ⎨ ⎩ 1156 Event Date Duration #Tweets Lakers vs Okc 05/19/2012 3h10m 218,313 N Celtics vs 76ers 05/23/2012 3h30m 245,734 B Celtics vs Heat 05/30/2012 3h30m 345,335 A Spurs vs Okc 05/31/2012 3h 254,670 Heat vs Okc (1) 06/12/2012 3h30m 331,498 Heat vs Okc (2) 06/21/2012 3h30m 332,223 Apple’s WWDC’12 Conf. 06/11/2012 3h30m 163,775 Table 1: Statistics of the data set, including six NBA basketball games and the WWDC 2012 conference event. for event summarization, but not on proposing new methods for tweet selection. We thus use the Hybrid TF-IDF approach (Sharifi et al., 2010a; Liu et al., 2011a) to extract the representative sentences from a collection of tweets. In this approach, each tweet was considered as a sentence. The sentences were ranked according to the average TF-IDF score of the consisting words; top weighted sentences were iteratively extracted, while excluding those that have high cosine similarity with the existing summary sentences. (Inouye and Kalita, 2011) showed the Hybrid TF-IDF approach performs constantly better than the phrase reinforcement algorithm and other traditional summarization systems. 4 Data Corpus We evaluate the proposed event s</context>
</contexts>
<marker>Sharifi, Hutton, Kalita, 2010</marker>
<rawString>Beaux Sharifi, Mark-Anthony Hutton, and Jugal K. Kalita. 2010a. Experiments in microblog summarization. In Proceedings of the 2010 IEEE Second International Conference on Social Computing, pages 49–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beaux Sharifi</author>
<author>Mark-Anthony Hutton</author>
<author>Jugal K Kalita</author>
</authors>
<title>Summarizing microblogs automatically.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<pages>685--688</pages>
<contexts>
<context position="7935" citStr="Sharifi et al., 2010" startWordPosition="1176" endWordPosition="1179">croblogs. (Ritter et al., 2012) described an open-domain event-extraction and categorization system, which extracts an open-domain calendar of significant events from Twitter. With the identified events of interest, there is an ever-increasing demand for event summarization, which distills the huge volume of Twitter discussions into a concise and representative textual description of the events. Many studies start with the text summarization approaches that have been shown to perform well on the news documents and 1153 develop adaptations to fit these methods to a collection of event tweets. (Sharifi et al., 2010b) proposed a graph-based phrase reinforcement algorithm to build a one-sentence summary from a collection of topic tweets. (Sharifi et al., 2010a; Inouye and Kalita, 2011) presented a hybrid TF-IDF approach to extract one- or multiple-sentence summary for each topic. (Liu et al., 2011a) proposed to use the concept-based ILP framework for summarizing the Twitter trending topics, using both tweets and the webpages linked from the tweets as input text sources. (Harabagiu and Hickl, 2011) introduced a generative framework that incorporates event structure and user behavior information in summariz</context>
<context position="20757" citStr="Sharifi et al., 2010" startWordPosition="3289" endWordPosition="3292"> &lt;= K wEd πjU(tb,te) Q p(w; θ&apos;j) else wEd ⎧ ⎨ ⎩ 1156 Event Date Duration #Tweets Lakers vs Okc 05/19/2012 3h10m 218,313 N Celtics vs 76ers 05/23/2012 3h30m 245,734 B Celtics vs Heat 05/30/2012 3h30m 345,335 A Spurs vs Okc 05/31/2012 3h 254,670 Heat vs Okc (1) 06/12/2012 3h30m 331,498 Heat vs Okc (2) 06/21/2012 3h30m 332,223 Apple’s WWDC’12 Conf. 06/11/2012 3h30m 163,775 Table 1: Statistics of the data set, including six NBA basketball games and the WWDC 2012 conference event. for event summarization, but not on proposing new methods for tweet selection. We thus use the Hybrid TF-IDF approach (Sharifi et al., 2010a; Liu et al., 2011a) to extract the representative sentences from a collection of tweets. In this approach, each tweet was considered as a sentence. The sentences were ranked according to the average TF-IDF score of the consisting words; top weighted sentences were iteratively extracted, while excluding those that have high cosine similarity with the existing summary sentences. (Inouye and Kalita, 2011) showed the Hybrid TF-IDF approach performs constantly better than the phrase reinforcement algorithm and other traditional summarization systems. 4 Data Corpus We evaluate the proposed event s</context>
</contexts>
<marker>Sharifi, Hutton, Kalita, 2010</marker>
<rawString>Beaux Sharifi, Mark-Anthony Hutton, and Jugal K. Kalita. 2010b. Summarizing microblogs automatically. In Proceedings of the 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 685–688.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Hikaru Yokono</author>
<author>Manabu Okumura</author>
</authors>
<title>Summarizing a document stream.</title>
<date>2011</date>
<booktitle>In Proceedings of the 33rd European Conference on Advances in Information Retrieval (ECIR),</booktitle>
<pages>177--188</pages>
<contexts>
<context position="8851" citStr="Takamura et al., 2011" startWordPosition="1315" endWordPosition="1319">sed to use the concept-based ILP framework for summarizing the Twitter trending topics, using both tweets and the webpages linked from the tweets as input text sources. (Harabagiu and Hickl, 2011) introduced a generative framework that incorporates event structure and user behavior information in summarizing multiple microblog posts related to the same topic. Regarding summarizing the data streams, (Marcus et al., 2011) introduced a “TwitInfo” system to visually summarize and track the events on Twitter. They proposed an automatic peak detection and labeling algorithm for the social streams. (Takamura et al., 2011) proposed a summarization model based on the facility location problem, which generates summary for a stream of short documents along the timeline. (Chakrabarti and Punera, 2011) proposed an event summarization algorithm based on learning an underlying hidden state representation of the event via hidden Markov models. (Louis and Newman, 2012) presented a method for summarizing a collection of tweets related to a business. The proposed procedure aggregates tweets into subtopic clusters which are then ranked and summarized by a few representative tweets from each cluster. (Nichols et al., 2012; </context>
</contexts>
<marker>Takamura, Yokono, Okumura, 2011</marker>
<rawString>Hiroya Takamura, Hikaru Yokono, and Manabu Okumura. 2011. Summarizing a document stream. In Proceedings of the 33rd European Conference on Advances in Information Retrieval (ECIR), pages 177– 188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jui-Yu Weng</author>
<author>Cheng-Lun Yang</author>
<author>Bo-Nian Chen</author>
<author>Yen-Kai Wang</author>
<author>Shou-De Lin</author>
</authors>
<title>Imass: An intelligent microblog analysis and summarization system.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT),</booktitle>
<pages>133--138</pages>
<marker>Weng, Yang, Chen, Wang, Shou-De Lin, 2011</marker>
<rawString>Jui-Yu Weng, Cheng-Lun Yang, Bo-Nian Chen, Yen-Kai Wang, and Shou-De Lin. 2011. Imass: An intelligent microblog analysis and summarization system. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT), pages 133–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siqi Zhao</author>
<author>Lin Zhong</author>
<author>Jehan Wickramasuriya</author>
<author>Venu Vasudevan</author>
</authors>
<title>Human as real-time sensors of social and physical events: A case study of twitter and sports games.</title>
<date>2011</date>
<tech>Technical Report TR0620-2011,</tech>
<institution>Rice University and Motorola Labs.</institution>
<contexts>
<context position="7061" citStr="Zhao et al., 2011" startWordPosition="1041" endWordPosition="1044">n recent years. Many research studies focus on identifying the trending events from Twitter and providing a concise and dynamic visualization of the information. The identified events are often represented using a set of keywords. (Petrovic et al., 2010) proposed an algorithm based on locality-sensitive hashing for detecting new events from a stream of Twitter posts. (O’Connor et al., 2010; Becker et al., 2011b; Becker et al., 2011a; Weng et al., 2011) proposed demo systems to display the event-related themes and popular tweets, allowing the users to navigate through their topic of interest. (Zhao et al., 2011) described an effort to perform data collection and event recognition despite various limits to the free access of Twitter data. (Diao et al., 2012) integrated both temporal information and users’ personal interests for bursty topic detection from the microblogs. (Ritter et al., 2012) described an open-domain event-extraction and categorization system, which extracts an open-domain calendar of significant events from Twitter. With the identified events of interest, there is an ever-increasing demand for event summarization, which distills the huge volume of Twitter discussions into a concise a</context>
</contexts>
<marker>Zhao, Zhong, Wickramasuriya, Vasudevan, 2011</marker>
<rawString>Siqi Zhao, Lin Zhong, Jehan Wickramasuriya, and Venu Vasudevan. 2011. Human as real-time sensors of social and physical events: A case study of twitter and sports games. Technical Report TR0620-2011, Rice University and Motorola Labs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arkaitz Zubiaga</author>
<author>Damiano Spina</author>
<author>Enrique Amig´o</author>
<author>Julio Gonzalo</author>
</authors>
<title>Towards real-time summarization of scheduled events from twitter streams.</title>
<date>2012</date>
<booktitle>In Pro-</booktitle>
<marker>Zubiaga, Spina, Amig´o, Gonzalo, 2012</marker>
<rawString>Arkaitz Zubiaga, Damiano Spina, Enrique Amig´o, and Julio Gonzalo. 2012. Towards real-time summarization of scheduled events from twitter streams. In Pro-</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>