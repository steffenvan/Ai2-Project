<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000108">
<title confidence="0.984834">
Mining Bilingual Data from the Web with Adaptively Learnt Patterns
</title>
<author confidence="0.996769">
Long Jiang1, Shiquan Yang2, Ming Zhou1, Xiaohua Liu1, Qingsheng Zhu2
</author>
<affiliation confidence="0.964142">
1Microsoft Research Asia 2Chongqing University,
</affiliation>
<address confidence="0.864285">
Beijing, 100190, P.R.China Chongqing, 400044, P.R.China
</address>
<email confidence="0.998303">
{longj,mingzhou,xiaoliu}@microsoft.com shiquany@gmail.com,qszhu@cqu.edu.cn
</email>
<sectionHeader confidence="0.993883" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999442041666667">
Mining bilingual data (including bilingual sen-
tences and terms1) from the Web can benefit
many NLP applications, such as machine
translation and cross language information re-
trieval. In this paper, based on the observation
that bilingual data in many web pages appear
collectively following similar patterns, an
adaptive pattern-based bilingual data mining
method is proposed. Specifically, given a web
page, the method contains four steps: 1) pre-
processing: parse the web page into a DOM
tree and segment the inner text of each node
into snippets; 2) seed mining: identify poten-
tial translation pairs (seeds) using a word
based alignment model which takes both trans-
lation and transliteration into consideration; 3)
pattern learning: learn generalized patterns
with the identified seeds; 4) pattern based min-
ing: extract all bilingual data in the page using
the learned patterns. Our experiments on Chi-
nese web pages produced more than 7.5 mil-
lion pairs of bilingual sentences and more than
5 million pairs of bilingual terms, both with
over 80% accuracy.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999654888888889">
Bilingual data (including bilingual sentences and
bilingual terms) are critical resources for build-
ing many applications, such as machine transla-
tion (Brown, 1993) and cross language informa-
tion retrieval (Nie et al., 1999). However, most
existing bilingual data sets are (i) not adequate
for their intended uses, (ii) not up-to-date, (iii)
apply only to limited domains. Because it‟s very
hard and expensive to create a large scale bilin-
</bodyText>
<footnote confidence="0.857931">
1 In this paper terms refer to proper nouns, technical terms,
movie names, and so on. And bilingual terms/sentences
mean terms/sentences and their translations.
</footnote>
<bodyText confidence="0.999265575">
gual dataset with human effort, recently many
researchers have turned to automatically mining
them from the Web.
If the content of a web page is written in two
languages, we call the page a Bilingual Web
Page. Many such pages exist in non-English web
sites. Most of them have a primary language
(usually a non-English language) and a second-
ary language (usually English). The content in
the secondary language is often the translation of
some primary language text in the page.
Since bilingual web pages are very common in
non-English web sites, mining bilingual data
from them should be an important task. However,
as far as we know, there is no publication availa-
ble on mining bilingual sentences directly from
bilingual web pages. Most existing methods for
mining bilingual sentences from the Web, such
as (Nie et al., 1999; Resnik and Smith, 2003; Shi
et al., 2006), try to mine parallel web documents
within bilingual web sites first and then extract
bilingual sentences from mined parallel docu-
ments using sentence alignment methods.
As to mining term translations from bilingual
web pages, Cao et al. (2007) and Lin et al. (2008)
proposed two different methods to extract term
translations based on the observation that authors
of many bilingual web pages, especially those
whose primary language is Chinese, Japanese or
Korean, sometimes annotate terms with their
English translations inside a pair of parentheses,
like “c1c2...cn(e1 e2 ... em)” (c1c2...cn is a primary
language term and e1 e2 ... em is its English trans-
lation).
Actually, in addition to the parenthesis pattern,
there is another interesting phenomenon that in
many bilingual web pages bilingual data appear
collectively and follow similar surface patterns.
Figure 1 shows an excerpt of a page which intro-
duces different kinds of dogs2. The page provides
</bodyText>
<footnote confidence="0.961946">
2 http://www.chinapet.net
</footnote>
<page confidence="0.905133">
870
</page>
<note confidence="0.9996225">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 870–878,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.996478583333333">
a list of dog names in both English and Chinese.
Note that those bilingual names do not follow the
parenthesis pattern. However, most of them are
identically formatted as: “{Number}。{English
name}{Chinese name}{EndOfLine}”. One ex-
ceptional pair (“1.Alaskan Malamute 啊拉WiN
雪 橇犬 ”) differs only slightly. Furthermore,
there are also many pages containing consistently
formatted bilingual sentences (see Figure 2). The
page3 lists the (claimed) 200 most common oral
sentences in English and their Chinese transla-
tions to facilitate English learning.
</bodyText>
<figureCaption confidence="0.91944475">
Figure 1. Consistently formatted term translation
pairs
Figure 2. Consistently formatted sentence trans-
lation pairs
</figureCaption>
<bodyText confidence="0.999738933333333">
People create such web pages for various rea-
sons. Some online stores list their products in
two languages to make them understandable to
foreigners. Some pages aim to help readers with
foreign language learning. And in some pages
where foreign names or technical terms are men-
tioned, the authors provide the translations for
disambiguation. For easy reference, from now on
we will call pages which contain many consis-
tently formatted translation pairs Collective Bi-
lingual Pages.
According to our estimation, at least tens of
millions of collective bilingual pages exist in
Chinese web sites. Most importantly, each such
page usually contains a large amount of bilingual
</bodyText>
<footnote confidence="0.643532">
3 http://cul.beelink.com/20060205/2021119.shtml
</footnote>
<bodyText confidence="0.998891">
data. This shows the great potential of bilingual
data mining. However, the mining task is not
straightforward, for the following reasons:
</bodyText>
<listItem confidence="0.886261230769231">
1) The patterns vary in different pages, so
it‟s impossible to mine the translation
pairs using predefined templates;
2) Some pages contain consistently format-
ted texts in two languages but they are not
translation pairs;
3) Not all translations in a collective bilin-
gual page necessarily follow an exactly
consistent format. As shown in Figure 1,
the ten translation pairs are supposed to
follow the same pattern, however, due to
typos, the pattern of the first pair is
slightly different.
</listItem>
<bodyText confidence="0.9996775">
Because of these difficulties, simply using a
classifier to extract translation pairs from adja-
cent bilingual texts in a collective bilingual page
may not achieve satisfactory results. Therefore in
this paper, we propose a pattern-based approach:
learning patterns adaptively from collective bi-
lingual pages instead of using the parenthesis
pattern, then using the learned patterns to extract
translation pairs from corresponding web pages.
Specifically, our approach contains four steps:
</bodyText>
<listItem confidence="0.957790454545455">
1) Preprocessing: parse the web page into a
DOM tree and segment the inner text of
each node into snippets;
2) Seed mining: identify potential translation
pairs (seeds) using an alignment model
which takes both translation and translite-
ration into consideration;
3) Pattern learning: learn generalized pat-
terns with the identified seeds;
4) Pattern based mining: extract all bilingual
data in the page using the learnt patterns.
</listItem>
<bodyText confidence="0.9994683125">
Let us take mining bilingual data from the text
shown in Figure 1 as an example. Our method
identifies “Boxer 拳师” and “Eskimo Dog IWi
基摩犬” as two potential translation pairs based
on a dictionary and a transliteration model (Step
2 above). Then we learn a generalized pattern
that both pairs follow as “{BulletNumb-
er}{Punctuation}{English term}{Chinese
term}{EndOfLine}”, (Step 3 above). Finally, we
apply it to match in the entire text and get all
translation pairs following the pattern (Step 4
above).
The remainder of this paper is organized as
follows. In Section 2, we list some related work.
The overview of our mining approach is pre-
sented in Section 3. In Section 4, we give de-
</bodyText>
<page confidence="0.996471">
871
</page>
<bodyText confidence="0.999835636363636">
tailed introduction to each of the four modules in
our mining approach. The experimental results
are reported in Section 5 followed by our conclu-
sion and some future work in Section 6.
Please note that in this paper we describe our
method using example bilingual web pages in
English and Chinese, however, the method can
be applied to extract bilingual data from web
pages written in any other pair of languages,
such as Japanese and English, Korean and Eng-
lish etc.
</bodyText>
<sectionHeader confidence="0.999918" genericHeader="introduction">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.998488">
Mining Bilingual Data from the Web
</subsectionHeader>
<bodyText confidence="0.999985462686567">
As far as we know, there is no publication avail-
able on mining parallel sentences directly from
bilingual web pages. Most existing methods of
mining bilingual sentences from the Web, such
as (Nie et al., 1999; Resnik and Smith, 2003; Shi
et al., 2006), mine parallel web documents within
bilingual web sites first and then extract bilingual
sentences from mined parallel documents using
sentence alignment methods. However, since the
number of bilingual web sites is quite small,
these methods can not yield a large number of
bilingual sentences. (Shi et al., 2006), mined a
total of 1,069,423 pairs of English-Chinese paral-
lel sentences. In addition to mining from parallel
documents, (Munteanu and Marcu, 2005) pro-
posed a method for discovering bilingual sen-
tences in comparable corpora.
As to the term translation extraction from bi-
lingual web pages, (Cao et al., 2007) and (Lin et
al., 2008) proposed two different methods utiliz-
ing the parenthesis pattern. The primary insight
is that authors of many bilingual web pages, es-
pecially those whose primary language is Chi-
nese, Japanese or Korean sometimes annotate
terms with their English translations inside a pair
of parentheses. Their methods are tested on a
large set of web pages and achieve promising
results. However, since not all translations in
bilingual web pages follow the parenthesis pat-
tern, these methods may miss a lot of translations
appearing on the Web.
Apart from mining term translations directly
from bilingual web pages, more approaches have
been proposed to mine term translations from
text snippets returned by a web search engine
(Jiang et al., 2007; Zhang and Vines, 2004;
Cheng et al., 2004; Huang et al., 2005). In their
methods the source language term is usually giv-
en and the goal is to find the target language
translations from the Web. To obtain web pages
containing the target translations, they submit the
source term to the web search engine and collect
returned snippets. Various techniques have been
proposed to extract the target translations from
the snippets. Though these methods achieve high
accuracy, they are not suitable for compiling a
large-scale bilingual dictionary for the following
reasons: 1) they need a list of predefined source
terms which is not easy to obtain; 2) the relev-
ance ranking in web search engines is almost
entirely orthogonal to the intent of finding the
bilingual web pages containing the target transla-
tion, so many desired bilingual web pages may
never be returned; 3) most such methods rely
heavily on the frequency of the target translation
in the collected snippets which makes mining
low-frequency translations difficult.
Moreover, based on the assumption that anc-
hor texts in different languages referring to the
same web page are possibly translations of each
other, (Lu et al., 2004) propose a novel approach
to construct a multilingual lexicon by making use
of web anchor texts and their linking structure.
However, since only famous web pages may
have inner links from other pages in multiple
languages, the number of translations that can be
obtained with this method is limited.
</bodyText>
<subsectionHeader confidence="0.951434">
Pattern-based Relation Extraction
</subsectionHeader>
<bodyText confidence="0.999789727272727">
Pattern-based relation extraction has also been
studied for years. For instance, (Hearst, 1992;
Finkelstein-Landau and Morin, 1999) proposed
an iterative pattern learning method for extract-
ing semantic relationships between terms. (Brin,
1998) proposed a method called DIPRE (Dual
Iterative Pattern Relation Expansion) to extract a
relation of books (author, title) pairs from the
Web. Since translation can be regarded as a kind
of relation, those ideas can be leveraged for ex-
tracting translation pairs.
</bodyText>
<sectionHeader confidence="0.522447" genericHeader="method">
3 Overview of the Proposed Approach
</sectionHeader>
<figureCaption confidence="0.998456">
Figure 3. The framework of our approach
</figureCaption>
<figure confidence="0.989778588235294">
Pattern-based
mining
output
Translation
pairs
Preprocessing
input
Web
pages
depend
Seed mining
Transliteration
model depend
Bilingual
dictionary
Pattern
learning
</figure>
<page confidence="0.988121">
872
</page>
<bodyText confidence="0.999944555555555">
As illustrated in Figure 3, our mining system
consists of four main steps: preprocessing, seed
mining, pattern learning and pattern based min-
ing. The input is a set of web documents and the
output is mined bilingual data.
In the preprocessing step, the input web doc-
uments are parsed into DOM trees and the inner
text of each tree node is segment into snippets.
Then we select those tree nodes whose inner
texts are likely to contain translation pairs collec-
tively with a simple rule.
The seed mining module receives the inner
text of each selected tree node and uses a word-
based alignment model to identify potential
translation pairs. The alignment model can han-
dle both translation and transliteration in a uni-
fied framework.
The pattern learning module receives identi-
fied potential translation pairs from the seed min-
ing as input, and then extracts generalized pattern
candidates with the PAT tree algorithm. Then a
SVM classifier is trained to select good patterns
from all extracted pattern candidates.
In the pattern-based mining step, the selected
patterns were used to match within the whole
inner text to extract all translation pairs follow-
ing the patterns.
</bodyText>
<sectionHeader confidence="0.751037" genericHeader="method">
4 Adaptive Pattern-based Bilingual Da-
ta Mining
</sectionHeader>
<bodyText confidence="0.9997625">
In this section, we will present the details about
the four steps in the proposed approach.
</bodyText>
<subsectionHeader confidence="0.9445345">
4.1 Preprocessing
HTML Page Parsing
</subsectionHeader>
<bodyText confidence="0.9999709">
The Document Object Model (DOM) is an appli-
cation programming interface used for parsing
HTML documents. With DOM, an HTML doc-
ument is parsed into a tree structure, where each
node belongs to some predefined types (e.g. DIV,
TABLE, TEXT, COMMENT, etc.). We removed
nodes with types of “B”, “FONT”, “I” and so on,
because they are mainly used for controlling vis-
ual effect. After removal, their child nodes will
be directly connected to their parents.
</bodyText>
<subsectionHeader confidence="0.923957">
Text Segmentation
</subsectionHeader>
<bodyText confidence="0.997297727272727">
After an HTML document is parsed, the inner
text of each node in the DOM tree will be seg-
mented into a list of text snippets according to
their languages. That means each snippet will be
labeled as either an English snippet (E) or a Chi-
nese snippet (C).
The text segmentation was performed based
on the Unicode values of characters4 first and
then guided by the following rules to decide the
boundary of a snippet under some special situa-
tions:
</bodyText>
<listItem confidence="0.9963363">
1) Open punctuations (such as `(`) are pad-
ded into next snippet, and close punctua-
tions (such as `)&apos;) are padded into pre-
vious snippet; other punctuations (such as
`;`) are padded into previous snippet;
2) English snippets which contains only 1 or
2 ASCII letters are merged with previous
and next Chinese snippets (if exist). Since
sometimes Chinese sentences or terms al-
so contain some abbreviations in English.
</listItem>
<tableCaption confidence="0.763617">
Table 1 gives some examples of how the inner
texts are segmented.
</tableCaption>
<table confidence="0.999887333333333">
Inner text China Development Bank (中国) 国
家开发银行
Segmentation China Development Bank |( 中国)
国家开发银行
Inner text Windows XP 视窗操作系统 XP 版
Segmentation Windows XP |视窗操作系统 XP 版
</table>
<tableCaption confidence="0.962534">
Table 1. Example segmentations (`|&apos; indicates the
separator between adjacent snippets)
</tableCaption>
<bodyText confidence="0.997235153846154">
Since a node&apos;s inner text includes all inner
texts of its children, the segmentation to all texts
of a DOM tree has to be performed from the leaf
nodes up to the root in order to avoid repetitive
work. When segmenting a node&apos;s inner text, we
first segment the texts immediately dominated by
this node and then combine those results with its
children&apos;s segmented inner texts in sequence.
As a result of the segmentation, the inner text
of every node will look like “...ECECC 5EC...”.
Two adjacent snippets in different languages (in-
dicated as “EC” or “CE”) are considered a Bilin-
gual Snippet Pair (BSP).
</bodyText>
<subsectionHeader confidence="0.475372">
Collective Nodes Selection
</subsectionHeader>
<bodyText confidence="0.999887625">
Since our goal is to mine bilingual knowledge
from collective bilingual pages, we have to de-
cide if a page is really a collective bilingual page.
In this paper, the criterion is that a collective
page must contain at least one Collective Node
which is defined as a node whose inner text con-
tains no fewer than 10 non-overlapping bilingual
snippet pairs and which contains less than 10
</bodyText>
<footnote confidence="0.888179">
4 For languages with the same character zone, other tech-
niques are needed to segment the text.
5 Adjacent snippets in the same language only appear in the
inner texts of some non-leaf nodes.
</footnote>
<page confidence="0.997724">
873
</page>
<bodyText confidence="0.9738255">
percent of other snippets which do not belong to
any bilingual snippet pairs.
</bodyText>
<subsectionHeader confidence="0.988896">
4.2 Seed Mining
</subsectionHeader>
<bodyText confidence="0.999850388888889">
The input of this module is a collective node
whose inner text has been segmented into conti-
nuous text snippets, such
as ...EkChEk+1Ch+1Ch+2.... In this step, every ad-
jacent snippet pair in different languages will be
checked by an alignment model to see if it is a
potential translation pair. The alignment model
combines a translation and a transliteration mod-
el to compute the likelihood of a bilingual snip-
pet pair being a translation pair. If it is, we call
the snippet pair as a Translation Snippet Pair
(TSP). If both of two adjacent pairs, e.g. EkCh
and ChEk+1, are considered as TSPs, the one with
lower translation score will be regarded as a
NON-TSP.
Before computing the likelihood of a bilingual
snippet pair being a TSP, we preprocess it via the
following steps:
</bodyText>
<listItem confidence="0.880993347826087">
a) Isolating the English and Chinese con-
tents from their contexts in the bilingual
snippet pair. Here, we use a very simple
rule: in the English snippet, we regard all
characters within (and including) the first
and the last English letter in the snippet as
the English content; similarly, in the Chi-
nese snippet we regard all characters
within (and including) the first and the
last Chinese character in the snippet as
the Chinese content;
b) Word segmentation of the Chinese con-
tent. Here, the Forward Maximum Match-
ing algorithm (Chen and Liu, 1992) based
on a dictionary is adopted;
c) Stop words filtering. We compiled a
small list of stop words manually (for ex-
ample, “of”, “to”, “的”, etc.) and remove
them from the English and Chinese con-
tent;
d) Stemming of the English content. We use
an in-house stemming tool to get the un-
inflected form of all English words.
</listItem>
<bodyText confidence="0.999519533333333">
After preprocessing, all English words form a
collection E={e1,e2,...,em } and all Chinese
words constitute a collection C={c1,c2,...,cn},
where ei is an English word, and ci is a Chinese
word. We then use a linking algorithm which
takes both translation and transliteration into
consideration to link words across the two col-
lections.
In our linking algorithm, there are three situa-
tions in which two words will be linked. The first
is that the two words are considered translations
of each other by the translation dictionary. The
second is that the pronunciation similarity of the
two words is above a certain threshold so that
one can be considered the transliteration of the
other. The third is that the two words are identic-
al (this rule is especially designed for linking
numbers or English abbreviations in Chinese
snippets). The dictionary is an in-house dictio-
nary and the transliteration model is adapted
from (Jiang et al., 2007).
After the linking, a translation score over the
English and Chinese content is computed by cal-
culating the percentage of words which can be
linked in the two collections. For some pairs,
there are many conflicting links, for example,
some words have multiple senses in the dictio-
nary. Then we select the one with highest trans-
lation score.
For example, given the bilingual snippet pair
of “Little Smoky River” and “小斯莫基河”, its
English part is separated as “Little/Smoky/River”,
and its Chinese part is separated as “小/斯/莫/基/
河”. According to the dictionary, “Little” can be
linked with “小”, and “River” can be linked with
“河”. However, “Smoky” is translated as “冒烟
的” in the dictionary which does not match any
Chinese characters in the Chinese snippet. How-
ever the transliteration score (pronunciation simi-
larity) between “Smoky” (IPA: s.m.o.k.i) and
“斯/莫/基” (Pinyin: si mo ji) is higher than the
threshold, so the English word “Smoky” can be
linked to three Chinese characters “斯”, “莫” and
“基”. The result is a translation score of 1.0 for
the pair “Little Smoky River” and “小斯莫基河”.
</bodyText>
<subsectionHeader confidence="0.998499">
4.3 Pattern Learning
</subsectionHeader>
<bodyText confidence="0.999976571428571">
The pattern learning module is critical for mining
bilingual data from collective pages, because
many translation pairs whose translation scores
are not high enough may still be extracted by
pattern based mining methods.
In previous modules, the inner texts of all
nodes are segmented into continuous text snip-
pets, and translation snippet pairs (TSP) are iden-
tified in all bilingual snippet pairs. Next, in the
pattern learning module, those translation snippet
pairs are used to find candidate patterns and then
a SVM classifier is built to select the most useful
patterns shared by most translation pairs in the
whole text.
</bodyText>
<page confidence="0.997334">
874
</page>
<sectionHeader confidence="0.490523" genericHeader="method">
Candidate Pattern Extraction
</sectionHeader>
<bodyText confidence="0.999977535714286">
First, as in the seed mining module, we isolate
the English and Chinese contents from their con-
texts in a TSP and then replace the contents with
two placeholders “[E]” and “[C]” respectively.
Second, we merge the two snippets of a TSP
into a string and add a starting tag “[#]” and an
ending tag “[#]” to its start and end. Following
(Chang and Lui, 2001), all processed strings are
used to build a PAT tree, and we then extract all
substrings containing “E” and “C” as pattern
candidates from the PAT tree. However, pattern
candidates which start or end with “[E]” (or
“[C]”) will be removed, since they cannot speci-
fy unambiguous boundaries when being matched
in a string.
Web page authors commonly commit format-
ting errors when authoring the content into an
html page, as shown in Figure 1. There, the ten
bilingual terms should have been written in the
same pattern, however, because of the mistaken
use of “.” instead of “o”, the first translation
pair follows a slightly different pattern. Some
other typical errors may include varying length
or types of white space, adjacent punctuation
marks instead of one punctuation mark, and so
on. To make the patterns robust enough to handle
such variation, we generalized all pattern candi-
dates through the following two steps:
</bodyText>
<listItem confidence="0.994844428571429">
1) Replace characters in a pattern with their
classes. We define three classes of cha-
racters: Punctuation (P), Number (N), and
White Space (S). Table 2 lists the three
classes and the corresponding regular ex-
pressions in Microsoft .Net Framework6.
2) Merge identical adjacent classes.
</listItem>
<table confidence="0.99649825">
Class Corresponding regular expression
P [\p{P}]
N [\d]
S [\s]
</table>
<tableCaption confidence="0.999214">
Table 2. Character classes
</tableCaption>
<bodyText confidence="0.991609333333333">
For example, from the translation snippet pair
of “7. Don‟t worry.” and “别担心o”, we will
learn the following pattern candidates:
</bodyText>
<listItem confidence="0.9995614">
• “#[N][P][S][E][P][S][C][P]#”;
• “[N][P][S][E][P][S][C][P]#”;
• “[N][P][S][E][P][S][C][P]”;
• ...
• “[S][E][P][S][C][P]”;
</listItem>
<sectionHeader confidence="0.479336" genericHeader="method">
6 In System.Text.RegularExpressions namespace
</sectionHeader>
<subsectionHeader confidence="0.971278">
Pattern Selection
</subsectionHeader>
<bodyText confidence="0.9991205">
After all pattern candidates are extracted, a SVM
classifier is used to select the good ones:
where, is the feature vector of a pattern
candidate pi, and is the vector of weights.
(•;) stands for an inner product. f is the decision
function to decide which candidates are good.
In this SVM model, each pattern candidate pi
has the following four features:
</bodyText>
<listItem confidence="0.9836641875">
1) Generality: the percentage of those bi-
lingual snippet pairs which can match pi
in all bilingual snippet pairs. This feature
measures if the pattern is a common pat-
tern shared by many bilingual snippet
pairs;
2) Average translation score: the average
translation score of all bilingual snippet
pairs which can match pi. This feature
helps decide if those pairs sharing the
same pattern are really translations;
3) Length: the length of pi. In general, long-
er patterns are more specific and can pro-
duce more accurate translations, however,
they are likely to produce fewer matches;
4) Irregularity: the standard deviation of
</listItem>
<bodyText confidence="0.879798071428571">
the numbers of noisy snippets. Here noisy
snippets mean those snippets between any
two adjacent translation pairs which can
match pi. If the irregularity of a pattern is
low, we can be confident that pairs shar-
ing this pattern have a reliably similar in-
ner relationship with each other.
To estimate the weight vector, we extracted all
pattern candidates from 300 bilingual web pages
and asked 2 human annotators to label each of
the candidates as positive or negative. The anno-
tation took each of them about 20 hours. Then
with the labeled training examples, we use SVM
light7 to estimate the weights.
</bodyText>
<subsectionHeader confidence="0.991112">
4.4 Pattern-based Mining
</subsectionHeader>
<bodyText confidence="0.999897625">
After good patterns are selected, every two adja-
cent snippets in different languages in the inner
text will be merged as a target string. As we
mentioned previously, we add a starting tag “[#]”
and an ending tag “[#]” to the start and end of
every target string. Then we attempt to match
each of the selected patterns in each of the target
strings and extract translation pairs. If the target
</bodyText>
<footnote confidence="0.843805">
7 http://svmlight.joachims.org/
</footnote>
<page confidence="0.998061">
875
</page>
<bodyText confidence="0.999957833333333">
string was matched with more than one pattern,
the matched string with highest translation score
will be kept.
The matching process is actually quite simple,
since we transform the learnt patterns into stan-
dard regular expressions and then make use of
existing regular expression matching tools (e.g.,
Microsoft .Net Framework) to extract translation
pairs.
However, to make our patterns more robust,
when transforming the selected patterns into
standard regular expressions, we allow each cha-
racter class to match more than once. That means
“[N]”, “[P]” and “[S]” will be transformed into
“[\d]+”, “[\p{P}]+” and “[\s]+” respectively. And
“[E]” and “[C]” will be transformed into
“[^\u4e00-\u9fa5]+” (any character except Chi-
nese character) and “.+”, respectively.
</bodyText>
<sectionHeader confidence="0.994557" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.999924142857143">
In the following subsections, first, we will report
the results of our bilingual data mining on a large
set of Chinese web pages and compare them with
previous work. Second, we will report some ex-
perimental results on a manually constructed test
data set to analyze the impact of each part of our
method.
</bodyText>
<subsectionHeader confidence="0.994703">
5.1 Evaluation on a Large Set of Pages
</subsectionHeader>
<bodyText confidence="0.999992716981132">
With the proposed method, we performed bilin-
gual data extraction on about 3.5 billion web
pages crawled from Chinese web sites. Out of
them, about 20 million were determined to con-
tain bilingual collective nodes. From the inner
texts of those nodes, we extracted 12,610,626
unique translation pairs. If we consider those
pairs whose English parts contain more than 5
words as sentence translations and all others as
term translations, we get 7,522,803 sentence
translations and 5,087,823 term translations. We
evaluated the quality of these mined translations
by sampling 200 sentence translations and 200
term translations and presenting those to human
judges, with a resulting precision of 83.5% for
sentence translations and 80.5% for term transla-
tions.
As we mentioned in Section 2, (Shi et al.,
2006) reported that in total they mined 1,069,423
pairs of English-Chinese parallel sentences from
bilingual web sites. However, our method yields
about 7.5 million pairs, about seven times as
many.
We also re-implemented the extraction method
using the parenthesis pattern proposed by (Lin et
al., 2008) and were able to mine 6,538,164 bilin-
gual terms from the same web pages. A sample
of 200 terms was submitted for human judgment,
resulting in a precision of 78.5% which is a little
lower than that of our original result. Further
analysis showed that fewer than 20% of the bi-
lingual terms mined with our method overlap
with the data mined using the re-implemented
method proposed by (Lin et al., 2008). This indi-
cates that our method can find many translations
which are not covered by the parenthesis pattern
and therefore can be used together with the pa-
renthesis pattern based method to build a bilin-
gual lexicon.
Out of the term translations we mined, we
found many which co-occur with their source
terms only once in the Web. We check this by
searching in Google with a Boolean query made
of the term and its translation and then get the
number of pages containing the query. If one
attempts to extract this kind of low-frequency
translation using a search engine-based method,
the desired bilingual page which contains the
target translation is not likely to be returned in
the top n results when searching with the source
term as the query. Even if the desired page is
returned, the translation itself may be difficult to
extract due to its low frequency.
</bodyText>
<subsectionHeader confidence="0.8712025">
5.2 Evaluation on a Human Made Test Da-
ta Set
</subsectionHeader>
<bodyText confidence="0.9998474">
Besides the evaluation of our method on a huge
set of web pages, we also carried out some expe-
riments on a human-constructed test data set. We
randomly selected 500 collective nodes from the
huge set of Chinese web pages and asked two
annotators to label all bilingual data in their inner
texts. Half of the labeled data are then used as
the development data set and the rest as the test
data set to evaluate our systems with different
settings. Table 3 shows the evaluation results.
</bodyText>
<table confidence="0.999696222222222">
Setting Type Recall Precision F-Score
Without Exact 52.2 75.4 61.7
pattern
Fuzzy 56.3 79.3 65.8
Without Exact 69.2 78.6 73.6
PG
Fuzzy 74.3 82.9 78.4
With PG Exact 79.3 80.5 79.9
Fuzzy 86.7 87.9 87.3
</table>
<tableCaption confidence="0.999729">
Table 3. Performance of different settings
</tableCaption>
<bodyText confidence="0.9998706">
In Table 3, “Without pattern” means that we
simply treat those seed pairs found by the align-
ment model as final bilingual data. “Without PG”
and “With PG” mean not generalizing and gene-
ralizing the learnt patterns to class based form,
</bodyText>
<page confidence="0.994903">
876
</page>
<bodyText confidence="0.999822351851852">
respectively. Evaluation type “Exact” means the
mined bilingual data are considered correct only
if they are exactly same as the data labeled by
human, while “Fuzzy” means the mined bilin-
gual data are considered correct if they contain
the data labeled by the human.
As shown in Table 3, the system without pat-
tern-based extraction yields only 52.2% recall.
However, after adding pattern-based extraction,
recall is improved sharply, to 69.2% for “With-
out PG” and to 79.3% for “With PG”. Most of
the improvement comes from those translations
which have very low translation scores and
therefore are discarded by the seed mining mod-
ule, however, most of them are found with the
help of the learnt patterns.
From Table 3, we can also see that the system
“With PG” outperforms “Without PG” in terms
of both precision and recall. The reason may be
that web writers often make mistakes when writ-
ing on web pages, such as punctuation misuse,
punctuation loss, and extra spaces etc., so ex-
tracting with a strict surface pattern will often
miss those translations which follow slightly dif-
ferent patterns.
To find out the reasons why some non-
translation pairs are extracted, we checked 20
pairs which are not translations but extracted by
the system. Out of them, 5 are caused by wrong
segmentations. For example, “大提琴与小提琴
双重协奏曲 Double Concerto for Violin and
Cello D 大调第二交响曲 Symphony No.2 in D
Major” is segmented into “大提琴与小提琴双重
协奏曲”, “Double Concerto for Violin and Cello
D”, “大调第二交响曲”, and “Symphony No.2 in
D Major”. However, the ending letter „D‟ of the
second segment should have been padded into
the third segment. For 9 pairs, the Chinese parts
are explanative texts of corresponding English
texts, but not translations. Because they contain
the translations of the key words in the English
text, our seed mining module failed to identify
them as non-translation pairs. For 3 pairs, they
follow the same pattern with some genuine trans-
lation pairs and therefore were extracted by the
pattern based mining module. However, they are
not translation pairs. For the other 3 pairs, the
errors came from the pattern generalization.
To evaluate the contribution of each feature
used in the pattern selection module, we elimi-
nated one feature at a time in turn from the fea-
ture set to see how the performance changed in
the absence of any single feature. The results are
reported below.
</bodyText>
<table confidence="0.999258666666667">
Eliminated feature F-Score (Exact)
Null 79.9
Generality 72.3
Avg. translation score 74.3
Length 77.5
Irregularity 76.6
</table>
<tableCaption confidence="0.999739">
Table 4. Contribution of every feature
</tableCaption>
<bodyText confidence="0.9983865">
From the table above, we can see that every
feature contributes to the final performance and
that Generality is the most useful feature among
all four features.
</bodyText>
<sectionHeader confidence="0.999692" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.99999152173913">
Bilingual web pages have shown great potential
as a source of up-to-date bilingual
terms/sentences which cover many domains and
application types. Based on the observation that
many web pages contain bilingual data collec-
tions which follow a mostly consistent but possi-
bly somewhat variable pattern, we propose a uni-
fied approach for mining bilingual sentences and
terms from such pages. Our approach can adap-
tively learn translation patterns according to dif-
ferent formatting styles in various web pages and
then use the learnt patterns to extract more bilin-
gual data. The patterns are generalized to minim-
ize the impact of format variation and typos. Ac-
cording to experimental results on a large set of
web pages as well as on a manually made test
data set, our method is quite promising.
In the future, we would like to integrate the
text segmentation module with the seed mining
and pattern learning module to improve the accu-
racy of text segmentation. We also want to eva-
luate the usefulness of our mined data for ma-
chine translation or other applications.
</bodyText>
<sectionHeader confidence="0.999283" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998914909090909">
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra and
R. L. Mercer. 1993. The mathematics of statistical
machine translation: parameter estimation. Compu-
tational Linguistics, 19:2, 263-311.
Sergey Brin. 1998. Extracting patterns and relations
from the World Wide Web. In Proc. of the 1998 In-
ternational Workshop on the Web and Databases.
Pp: 172-183.
G.H. Cao, J.F. Gao and J.Y. Nie. 2007. A system to
mine large-scale bilingual dictionaries from mono-
lingual web pages. MT summit. Pp: 57-64.
</reference>
<page confidence="0.978611">
877
</page>
<reference confidence="0.999876815384615">
Chia-Hui Chang and Shao-Chen Lui. 2001. IEPAD:
Inform extract based on pattern discovery. In Proc.
of the 10th ACM WWW conference.
Keh-Jiann Chen, Shing-Huan Liu. 1992. Word Identi-
fication for Mandarin Chinese Sentences. In the
Proceedings of COLING 1992. Pp:101-107.
Cheng, P., Teng, J., Chen, R., Wang, J., Lu, W., and
Cheng, L. 2004. Translating Unknown Queries
with Web Corpora for Cross-Language Information
Retrieval. In the Proceedings of SIGIR 2004, pp
162-169.
Michal Finkelstein-Landau, Emmanuel Morin. 1999.
Extracting Semantic Relationships between Terms:
Supervised vs. Unsupervised Methods. In Proceed-
ings of International Workshop on Ontological En-
gineering on the Global Information Infrastructure.
Pp:71-80.
Marti A. Hearst. 1992. Automatic Acquisition of Hy-
ponyms from Large Text Corpora. In the Proceed-
ings of COLING-92. Pp: 539-545.
Huang, F., Zhang, Y., and Vogel, S. 2005. Mining
Key phrase Translations from Web Corpora. In the
Proceedings of HLT-EMNLP.
L. Jiang, M. Zhou, L.-F. Chien, C. Niu. 2007. Named
Entity Translation with Web Mining and Translite-
ration, Proceedings of the 20th IJCAI. Pp: 1629-
1634.
D. Lin, S. Zhao, B. Durme and M. Pasca. 2008. Min-
ing Parenthetical Translations from the Web by
Word Alignment. In ACL-08. pp 994-1002.
Lu, W. and Lee, H. 2004. Anchor text mining for
translation of Web queries: A transitive translation
approach. ACM transactions on Information Sys-
tems, Vol.22, April 2004, pages 242-269.
D. S. Munteanu, D. Marcu. Improving Machine
Translation Performance by Exploiting Non-
Parallel Corpora. 2005. Computational Linguistics.
31(4). Pp: 477-504.
J-Y Nie, M. Simard, P. Isabelle, and R. Durand. 1999.
Cross-Language Information Retrieval Based on
Parallel Texts and Automatic Mining of parallel
Text from the Web. In SIGIR 1999. Pp: 74-81.
Philip Resnik, Noah A. Smith. 2003. The Web as a
Parallel Corpus. Computational Linguistics. 29(3).
Pp: 349-380.
Li Shao and Hwee Tou Ng. 2004. Mining new word
translations from comparable corpora. In Proc. of
COLING 2004. Pp: 618–624.
Lei Shi, Cheng Niu, Ming Zhou, Jianfeng Gao. 2006.
A DOM Tree Alignment Model for Mining Paral-
lel Data from the Web. In ACL 2006.
Jung H. Shin, Young S. Han and Key-Sun Choi. 1996.
Bilingual knowledge acquisition from Korean-
English parallel corpus using alignment method:
Korean-English alignment at word and phrase level.
In Proceedings of the 16th conference on Computa-
tional linguistics, Copenhagen, Denmark.
J.C. Wu, T. Lin and J.S. Chang. 2005. Learning
Source-Target Surface Patterns for Web-based
Terminology Translation. ACL Interactive Poster
and Demonstration Sessions,. Pp 37-40, Ann Arbor.
Zhang, Y. and Vines, P.. 2004. Using the Web for
Automated Translation Extraction in Cross-
Language Information Retrieval. In the Proceed-
ings of SIGIR 2004. Pp: 162-169.
</reference>
<page confidence="0.997688">
878
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.673141">
<title confidence="0.999934">Mining Bilingual Data from the Web with Adaptively Learnt Patterns</title>
<author confidence="0.994319">Shiquan Ming Xiaohua Qingsheng</author>
<affiliation confidence="0.999817">Research Asia University,</affiliation>
<address confidence="0.995469">Beijing, 100190, P.R.China Chongqing, 400044, P.R.China</address>
<email confidence="0.691351">longj@microsoft.comshiquany@gmail.com,qszhu@cqu.edu.cn</email>
<email confidence="0.691351">mingzhou@microsoft.comshiquany@gmail.com,qszhu@cqu.edu.cn</email>
<email confidence="0.691351">xiaoliu@microsoft.comshiquany@gmail.com,qszhu@cqu.edu.cn</email>
<abstract confidence="0.99926572">Mining bilingual data (including bilingual senand from the Web can benefit many NLP applications, such as machine translation and cross language information retrieval. In this paper, based on the observation that bilingual data in many web pages appear collectively following similar patterns, an adaptive pattern-based bilingual data mining method is proposed. Specifically, given a web page, the method contains four steps: 1) preprocessing: parse the web page into a DOM tree and segment the inner text of each node into snippets; 2) seed mining: identify potential translation pairs (seeds) using a word based alignment model which takes both translation and transliteration into consideration; 3) pattern learning: learn generalized patterns with the identified seeds; 4) pattern based mining: extract all bilingual data in the page using the learned patterns. Our experiments on Chinese web pages produced more than 7.5 million pairs of bilingual sentences and more than 5 million pairs of bilingual terms, both with over 80% accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<pages>263--311</pages>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. F. Brown, S. A. Della Pietra, V. J. Della Pietra and R. L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19:2, 263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
</authors>
<title>Extracting patterns and relations from the World Wide Web.</title>
<date>1998</date>
<booktitle>In Proc. of the 1998 International Workshop on the Web and Databases. Pp:</booktitle>
<pages>172--183</pages>
<contexts>
<context position="11543" citStr="Brin, 1998" startWordPosition="1808" endWordPosition="1809">s of each other, (Lu et al., 2004) propose a novel approach to construct a multilingual lexicon by making use of web anchor texts and their linking structure. However, since only famous web pages may have inner links from other pages in multiple languages, the number of translations that can be obtained with this method is limited. Pattern-based Relation Extraction Pattern-based relation extraction has also been studied for years. For instance, (Hearst, 1992; Finkelstein-Landau and Morin, 1999) proposed an iterative pattern learning method for extracting semantic relationships between terms. (Brin, 1998) proposed a method called DIPRE (Dual Iterative Pattern Relation Expansion) to extract a relation of books (author, title) pairs from the Web. Since translation can be regarded as a kind of relation, those ideas can be leveraged for extracting translation pairs. 3 Overview of the Proposed Approach Figure 3. The framework of our approach Pattern-based mining output Translation pairs Preprocessing input Web pages depend Seed mining Transliteration model depend Bilingual dictionary Pattern learning 872 As illustrated in Figure 3, our mining system consists of four main steps: preprocessing, seed </context>
</contexts>
<marker>Brin, 1998</marker>
<rawString>Sergey Brin. 1998. Extracting patterns and relations from the World Wide Web. In Proc. of the 1998 International Workshop on the Web and Databases. Pp: 172-183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G H Cao</author>
<author>J F Gao</author>
<author>J Y Nie</author>
</authors>
<title>A system to mine large-scale bilingual dictionaries from monolingual web pages. MT summit.</title>
<date>2007</date>
<tech>Pp:</tech>
<pages>57--64</pages>
<contexts>
<context position="3109" citStr="Cao et al. (2007)" startWordPosition="476" endWordPosition="479"> pages are very common in non-English web sites, mining bilingual data from them should be an important task. However, as far as we know, there is no publication available on mining bilingual sentences directly from bilingual web pages. Most existing methods for mining bilingual sentences from the Web, such as (Nie et al., 1999; Resnik and Smith, 2003; Shi et al., 2006), try to mine parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment methods. As to mining term translations from bilingual web pages, Cao et al. (2007) and Lin et al. (2008) proposed two different methods to extract term translations based on the observation that authors of many bilingual web pages, especially those whose primary language is Chinese, Japanese or Korean, sometimes annotate terms with their English translations inside a pair of parentheses, like “c1c2...cn(e1 e2 ... em)” (c1c2...cn is a primary language term and e1 e2 ... em is its English translation). Actually, in addition to the parenthesis pattern, there is another interesting phenomenon that in many bilingual web pages bilingual data appear collectively and follow similar</context>
<context position="9019" citStr="Cao et al., 2007" startWordPosition="1406" endWordPosition="1409">ne parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment methods. However, since the number of bilingual web sites is quite small, these methods can not yield a large number of bilingual sentences. (Shi et al., 2006), mined a total of 1,069,423 pairs of English-Chinese parallel sentences. In addition to mining from parallel documents, (Munteanu and Marcu, 2005) proposed a method for discovering bilingual sentences in comparable corpora. As to the term translation extraction from bilingual web pages, (Cao et al., 2007) and (Lin et al., 2008) proposed two different methods utilizing the parenthesis pattern. The primary insight is that authors of many bilingual web pages, especially those whose primary language is Chinese, Japanese or Korean sometimes annotate terms with their English translations inside a pair of parentheses. Their methods are tested on a large set of web pages and achieve promising results. However, since not all translations in bilingual web pages follow the parenthesis pattern, these methods may miss a lot of translations appearing on the Web. Apart from mining term translations directly </context>
</contexts>
<marker>Cao, Gao, Nie, 2007</marker>
<rawString>G.H. Cao, J.F. Gao and J.Y. Nie. 2007. A system to mine large-scale bilingual dictionaries from monolingual web pages. MT summit. Pp: 57-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chia-Hui Chang</author>
<author>Shao-Chen Lui</author>
</authors>
<title>IEPAD: Inform extract based on pattern discovery.</title>
<date>2001</date>
<booktitle>In Proc. of the 10th ACM WWW conference.</booktitle>
<contexts>
<context position="21056" citStr="Chang and Lui, 2001" startWordPosition="3402" endWordPosition="3405">rs. Next, in the pattern learning module, those translation snippet pairs are used to find candidate patterns and then a SVM classifier is built to select the most useful patterns shared by most translation pairs in the whole text. 874 Candidate Pattern Extraction First, as in the seed mining module, we isolate the English and Chinese contents from their contexts in a TSP and then replace the contents with two placeholders “[E]” and “[C]” respectively. Second, we merge the two snippets of a TSP into a string and add a starting tag “[#]” and an ending tag “[#]” to its start and end. Following (Chang and Lui, 2001), all processed strings are used to build a PAT tree, and we then extract all substrings containing “E” and “C” as pattern candidates from the PAT tree. However, pattern candidates which start or end with “[E]” (or “[C]”) will be removed, since they cannot specify unambiguous boundaries when being matched in a string. Web page authors commonly commit formatting errors when authoring the content into an html page, as shown in Figure 1. There, the ten bilingual terms should have been written in the same pattern, however, because of the mistaken use of “.” instead of “o”, the first translation pa</context>
</contexts>
<marker>Chang, Lui, 2001</marker>
<rawString>Chia-Hui Chang and Shao-Chen Lui. 2001. IEPAD: Inform extract based on pattern discovery. In Proc. of the 10th ACM WWW conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keh-Jiann Chen</author>
<author>Shing-Huan Liu</author>
</authors>
<title>Word Identification for Mandarin Chinese Sentences.</title>
<date>1992</date>
<booktitle>In the Proceedings of COLING</booktitle>
<pages>101--107</pages>
<contexts>
<context position="17674" citStr="Chen and Liu, 1992" startWordPosition="2837" endWordPosition="2840">snippet pair being a TSP, we preprocess it via the following steps: a) Isolating the English and Chinese contents from their contexts in the bilingual snippet pair. Here, we use a very simple rule: in the English snippet, we regard all characters within (and including) the first and the last English letter in the snippet as the English content; similarly, in the Chinese snippet we regard all characters within (and including) the first and the last Chinese character in the snippet as the Chinese content; b) Word segmentation of the Chinese content. Here, the Forward Maximum Matching algorithm (Chen and Liu, 1992) based on a dictionary is adopted; c) Stop words filtering. We compiled a small list of stop words manually (for example, “of”, “to”, “的”, etc.) and remove them from the English and Chinese content; d) Stemming of the English content. We use an in-house stemming tool to get the uninflected form of all English words. After preprocessing, all English words form a collection E={e1,e2,...,em } and all Chinese words constitute a collection C={c1,c2,...,cn}, where ei is an English word, and ci is a Chinese word. We then use a linking algorithm which takes both translation and transliteration into co</context>
</contexts>
<marker>Chen, Liu, 1992</marker>
<rawString>Keh-Jiann Chen, Shing-Huan Liu. 1992. Word Identification for Mandarin Chinese Sentences. In the Proceedings of COLING 1992. Pp:101-107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cheng</author>
<author>J Teng</author>
<author>R Chen</author>
<author>J Wang</author>
<author>W Lu</author>
<author>L Cheng</author>
</authors>
<title>Translating Unknown Queries with Web Corpora for Cross-Language Information Retrieval.</title>
<date>2004</date>
<booktitle>In the Proceedings of SIGIR</booktitle>
<pages>162--169</pages>
<contexts>
<context position="9819" citStr="Cheng et al., 2004" startWordPosition="1536" endWordPosition="1539">ary language is Chinese, Japanese or Korean sometimes annotate terms with their English translations inside a pair of parentheses. Their methods are tested on a large set of web pages and achieve promising results. However, since not all translations in bilingual web pages follow the parenthesis pattern, these methods may miss a lot of translations appearing on the Web. Apart from mining term translations directly from bilingual web pages, more approaches have been proposed to mine term translations from text snippets returned by a web search engine (Jiang et al., 2007; Zhang and Vines, 2004; Cheng et al., 2004; Huang et al., 2005). In their methods the source language term is usually given and the goal is to find the target language translations from the Web. To obtain web pages containing the target translations, they submit the source term to the web search engine and collect returned snippets. Various techniques have been proposed to extract the target translations from the snippets. Though these methods achieve high accuracy, they are not suitable for compiling a large-scale bilingual dictionary for the following reasons: 1) they need a list of predefined source terms which is not easy to obtai</context>
</contexts>
<marker>Cheng, Teng, Chen, Wang, Lu, Cheng, 2004</marker>
<rawString>Cheng, P., Teng, J., Chen, R., Wang, J., Lu, W., and Cheng, L. 2004. Translating Unknown Queries with Web Corpora for Cross-Language Information Retrieval. In the Proceedings of SIGIR 2004, pp 162-169.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michal Finkelstein-Landau</author>
<author>Emmanuel Morin</author>
</authors>
<title>Extracting Semantic Relationships between Terms: Supervised vs. Unsupervised Methods.</title>
<date>1999</date>
<booktitle>In Proceedings of International Workshop on Ontological Engineering on the Global Information Infrastructure.</booktitle>
<pages>71--80</pages>
<contexts>
<context position="11431" citStr="Finkelstein-Landau and Morin, 1999" startWordPosition="1791" endWordPosition="1794">cult. Moreover, based on the assumption that anchor texts in different languages referring to the same web page are possibly translations of each other, (Lu et al., 2004) propose a novel approach to construct a multilingual lexicon by making use of web anchor texts and their linking structure. However, since only famous web pages may have inner links from other pages in multiple languages, the number of translations that can be obtained with this method is limited. Pattern-based Relation Extraction Pattern-based relation extraction has also been studied for years. For instance, (Hearst, 1992; Finkelstein-Landau and Morin, 1999) proposed an iterative pattern learning method for extracting semantic relationships between terms. (Brin, 1998) proposed a method called DIPRE (Dual Iterative Pattern Relation Expansion) to extract a relation of books (author, title) pairs from the Web. Since translation can be regarded as a kind of relation, those ideas can be leveraged for extracting translation pairs. 3 Overview of the Proposed Approach Figure 3. The framework of our approach Pattern-based mining output Translation pairs Preprocessing input Web pages depend Seed mining Transliteration model depend Bilingual dictionary Patt</context>
</contexts>
<marker>Finkelstein-Landau, Morin, 1999</marker>
<rawString>Michal Finkelstein-Landau, Emmanuel Morin. 1999. Extracting Semantic Relationships between Terms: Supervised vs. Unsupervised Methods. In Proceedings of International Workshop on Ontological Engineering on the Global Information Infrastructure. Pp:71-80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic Acquisition of Hyponyms from Large Text Corpora.</title>
<date>1992</date>
<booktitle>In the Proceedings of COLING-92. Pp:</booktitle>
<pages>539--545</pages>
<contexts>
<context position="11394" citStr="Hearst, 1992" startWordPosition="1789" endWordPosition="1790">slations difficult. Moreover, based on the assumption that anchor texts in different languages referring to the same web page are possibly translations of each other, (Lu et al., 2004) propose a novel approach to construct a multilingual lexicon by making use of web anchor texts and their linking structure. However, since only famous web pages may have inner links from other pages in multiple languages, the number of translations that can be obtained with this method is limited. Pattern-based Relation Extraction Pattern-based relation extraction has also been studied for years. For instance, (Hearst, 1992; Finkelstein-Landau and Morin, 1999) proposed an iterative pattern learning method for extracting semantic relationships between terms. (Brin, 1998) proposed a method called DIPRE (Dual Iterative Pattern Relation Expansion) to extract a relation of books (author, title) pairs from the Web. Since translation can be regarded as a kind of relation, those ideas can be leveraged for extracting translation pairs. 3 Overview of the Proposed Approach Figure 3. The framework of our approach Pattern-based mining output Translation pairs Preprocessing input Web pages depend Seed mining Transliteration m</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A. Hearst. 1992. Automatic Acquisition of Hyponyms from Large Text Corpora. In the Proceedings of COLING-92. Pp: 539-545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Huang</author>
<author>Y Zhang</author>
<author>S Vogel</author>
</authors>
<title>Mining Key phrase Translations from Web Corpora.</title>
<date>2005</date>
<booktitle>In the Proceedings of HLT-EMNLP.</booktitle>
<contexts>
<context position="9840" citStr="Huang et al., 2005" startWordPosition="1540" endWordPosition="1543">ese, Japanese or Korean sometimes annotate terms with their English translations inside a pair of parentheses. Their methods are tested on a large set of web pages and achieve promising results. However, since not all translations in bilingual web pages follow the parenthesis pattern, these methods may miss a lot of translations appearing on the Web. Apart from mining term translations directly from bilingual web pages, more approaches have been proposed to mine term translations from text snippets returned by a web search engine (Jiang et al., 2007; Zhang and Vines, 2004; Cheng et al., 2004; Huang et al., 2005). In their methods the source language term is usually given and the goal is to find the target language translations from the Web. To obtain web pages containing the target translations, they submit the source term to the web search engine and collect returned snippets. Various techniques have been proposed to extract the target translations from the snippets. Though these methods achieve high accuracy, they are not suitable for compiling a large-scale bilingual dictionary for the following reasons: 1) they need a list of predefined source terms which is not easy to obtain; 2) the relevance r</context>
</contexts>
<marker>Huang, Zhang, Vogel, 2005</marker>
<rawString>Huang, F., Zhang, Y., and Vogel, S. 2005. Mining Key phrase Translations from Web Corpora. In the Proceedings of HLT-EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Jiang</author>
<author>M Zhou</author>
<author>L-F Chien</author>
<author>C Niu</author>
</authors>
<title>Named Entity Translation with Web Mining and Transliteration,</title>
<date>2007</date>
<booktitle>Proceedings of the 20th IJCAI. Pp:</booktitle>
<pages>1629--1634</pages>
<contexts>
<context position="9776" citStr="Jiang et al., 2007" startWordPosition="1528" endWordPosition="1531">gual web pages, especially those whose primary language is Chinese, Japanese or Korean sometimes annotate terms with their English translations inside a pair of parentheses. Their methods are tested on a large set of web pages and achieve promising results. However, since not all translations in bilingual web pages follow the parenthesis pattern, these methods may miss a lot of translations appearing on the Web. Apart from mining term translations directly from bilingual web pages, more approaches have been proposed to mine term translations from text snippets returned by a web search engine (Jiang et al., 2007; Zhang and Vines, 2004; Cheng et al., 2004; Huang et al., 2005). In their methods the source language term is usually given and the goal is to find the target language translations from the Web. To obtain web pages containing the target translations, they submit the source term to the web search engine and collect returned snippets. Various techniques have been proposed to extract the target translations from the snippets. Though these methods achieve high accuracy, they are not suitable for compiling a large-scale bilingual dictionary for the following reasons: 1) they need a list of predefi</context>
<context position="18933" citStr="Jiang et al., 2007" startWordPosition="3049" endWordPosition="3052"> collections. In our linking algorithm, there are three situations in which two words will be linked. The first is that the two words are considered translations of each other by the translation dictionary. The second is that the pronunciation similarity of the two words is above a certain threshold so that one can be considered the transliteration of the other. The third is that the two words are identical (this rule is especially designed for linking numbers or English abbreviations in Chinese snippets). The dictionary is an in-house dictionary and the transliteration model is adapted from (Jiang et al., 2007). After the linking, a translation score over the English and Chinese content is computed by calculating the percentage of words which can be linked in the two collections. For some pairs, there are many conflicting links, for example, some words have multiple senses in the dictionary. Then we select the one with highest translation score. For example, given the bilingual snippet pair of “Little Smoky River” and “小斯莫基河”, its English part is separated as “Little/Smoky/River”, and its Chinese part is separated as “小/斯/莫/基/ 河”. According to the dictionary, “Little” can be linked with “小”, and “Ri</context>
</contexts>
<marker>Jiang, Zhou, Chien, Niu, 2007</marker>
<rawString>L. Jiang, M. Zhou, L.-F. Chien, C. Niu. 2007. Named Entity Translation with Web Mining and Transliteration, Proceedings of the 20th IJCAI. Pp: 1629-1634.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>S Zhao</author>
<author>B Durme</author>
<author>M Pasca</author>
</authors>
<title>Mining Parenthetical Translations from the Web by Word Alignment.</title>
<date>2008</date>
<booktitle>In ACL-08.</booktitle>
<pages>994--1002</pages>
<contexts>
<context position="3131" citStr="Lin et al. (2008)" startWordPosition="481" endWordPosition="484"> in non-English web sites, mining bilingual data from them should be an important task. However, as far as we know, there is no publication available on mining bilingual sentences directly from bilingual web pages. Most existing methods for mining bilingual sentences from the Web, such as (Nie et al., 1999; Resnik and Smith, 2003; Shi et al., 2006), try to mine parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment methods. As to mining term translations from bilingual web pages, Cao et al. (2007) and Lin et al. (2008) proposed two different methods to extract term translations based on the observation that authors of many bilingual web pages, especially those whose primary language is Chinese, Japanese or Korean, sometimes annotate terms with their English translations inside a pair of parentheses, like “c1c2...cn(e1 e2 ... em)” (c1c2...cn is a primary language term and e1 e2 ... em is its English translation). Actually, in addition to the parenthesis pattern, there is another interesting phenomenon that in many bilingual web pages bilingual data appear collectively and follow similar surface patterns. Fig</context>
<context position="9042" citStr="Lin et al., 2008" startWordPosition="1411" endWordPosition="1414">ts within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment methods. However, since the number of bilingual web sites is quite small, these methods can not yield a large number of bilingual sentences. (Shi et al., 2006), mined a total of 1,069,423 pairs of English-Chinese parallel sentences. In addition to mining from parallel documents, (Munteanu and Marcu, 2005) proposed a method for discovering bilingual sentences in comparable corpora. As to the term translation extraction from bilingual web pages, (Cao et al., 2007) and (Lin et al., 2008) proposed two different methods utilizing the parenthesis pattern. The primary insight is that authors of many bilingual web pages, especially those whose primary language is Chinese, Japanese or Korean sometimes annotate terms with their English translations inside a pair of parentheses. Their methods are tested on a large set of web pages and achieve promising results. However, since not all translations in bilingual web pages follow the parenthesis pattern, these methods may miss a lot of translations appearing on the Web. Apart from mining term translations directly from bilingual web page</context>
<context position="26943" citStr="Lin et al., 2008" startWordPosition="4345" endWordPosition="4348"> term translations. We evaluated the quality of these mined translations by sampling 200 sentence translations and 200 term translations and presenting those to human judges, with a resulting precision of 83.5% for sentence translations and 80.5% for term translations. As we mentioned in Section 2, (Shi et al., 2006) reported that in total they mined 1,069,423 pairs of English-Chinese parallel sentences from bilingual web sites. However, our method yields about 7.5 million pairs, about seven times as many. We also re-implemented the extraction method using the parenthesis pattern proposed by (Lin et al., 2008) and were able to mine 6,538,164 bilingual terms from the same web pages. A sample of 200 terms was submitted for human judgment, resulting in a precision of 78.5% which is a little lower than that of our original result. Further analysis showed that fewer than 20% of the bilingual terms mined with our method overlap with the data mined using the re-implemented method proposed by (Lin et al., 2008). This indicates that our method can find many translations which are not covered by the parenthesis pattern and therefore can be used together with the parenthesis pattern based method to build a bi</context>
</contexts>
<marker>Lin, Zhao, Durme, Pasca, 2008</marker>
<rawString>D. Lin, S. Zhao, B. Durme and M. Pasca. 2008. Mining Parenthetical Translations from the Web by Word Alignment. In ACL-08. pp 994-1002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Lu</author>
<author>H Lee</author>
</authors>
<title>Anchor text mining for translation of Web queries: A transitive translation approach.</title>
<date>2004</date>
<journal>ACM transactions on Information Systems,</journal>
<volume>22</volume>
<pages>242--269</pages>
<marker>Lu, Lee, 2004</marker>
<rawString>Lu, W. and Lee, H. 2004. Anchor text mining for translation of Web queries: A transitive translation approach. ACM transactions on Information Systems, Vol.22, April 2004, pages 242-269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D S Munteanu</author>
<author>D Marcu</author>
</authors>
<title>Improving Machine Translation Performance by Exploiting NonParallel Corpora.</title>
<date>2005</date>
<journal>Computational Linguistics.</journal>
<volume>31</volume>
<issue>4</issue>
<pages>477--504</pages>
<contexts>
<context position="8859" citStr="Munteanu and Marcu, 2005" startWordPosition="1379" endWordPosition="1382">tly from bilingual web pages. Most existing methods of mining bilingual sentences from the Web, such as (Nie et al., 1999; Resnik and Smith, 2003; Shi et al., 2006), mine parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment methods. However, since the number of bilingual web sites is quite small, these methods can not yield a large number of bilingual sentences. (Shi et al., 2006), mined a total of 1,069,423 pairs of English-Chinese parallel sentences. In addition to mining from parallel documents, (Munteanu and Marcu, 2005) proposed a method for discovering bilingual sentences in comparable corpora. As to the term translation extraction from bilingual web pages, (Cao et al., 2007) and (Lin et al., 2008) proposed two different methods utilizing the parenthesis pattern. The primary insight is that authors of many bilingual web pages, especially those whose primary language is Chinese, Japanese or Korean sometimes annotate terms with their English translations inside a pair of parentheses. Their methods are tested on a large set of web pages and achieve promising results. However, since not all translations in bili</context>
</contexts>
<marker>Munteanu, Marcu, 2005</marker>
<rawString>D. S. Munteanu, D. Marcu. Improving Machine Translation Performance by Exploiting NonParallel Corpora. 2005. Computational Linguistics. 31(4). Pp: 477-504.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-Y Nie</author>
<author>M Simard</author>
<author>P Isabelle</author>
<author>R Durand</author>
</authors>
<title>Cross-Language Information Retrieval Based on Parallel Texts and Automatic Mining of parallel Text from the Web. In SIGIR</title>
<date>1999</date>
<pages>74--81</pages>
<contexts>
<context position="1619" citStr="Nie et al., 1999" startWordPosition="232" endWordPosition="235">transliteration into consideration; 3) pattern learning: learn generalized patterns with the identified seeds; 4) pattern based mining: extract all bilingual data in the page using the learned patterns. Our experiments on Chinese web pages produced more than 7.5 million pairs of bilingual sentences and more than 5 million pairs of bilingual terms, both with over 80% accuracy. 1 Introduction Bilingual data (including bilingual sentences and bilingual terms) are critical resources for building many applications, such as machine translation (Brown, 1993) and cross language information retrieval (Nie et al., 1999). However, most existing bilingual data sets are (i) not adequate for their intended uses, (ii) not up-to-date, (iii) apply only to limited domains. Because it‟s very hard and expensive to create a large scale bilin1 In this paper terms refer to proper nouns, technical terms, movie names, and so on. And bilingual terms/sentences mean terms/sentences and their translations. gual dataset with human effort, recently many researchers have turned to automatically mining them from the Web. If the content of a web page is written in two languages, we call the page a Bilingual Web Page. Many such page</context>
<context position="8355" citStr="Nie et al., 1999" startWordPosition="1301" endWordPosition="1304"> in Section 5 followed by our conclusion and some future work in Section 6. Please note that in this paper we describe our method using example bilingual web pages in English and Chinese, however, the method can be applied to extract bilingual data from web pages written in any other pair of languages, such as Japanese and English, Korean and English etc. 2 Related Work Mining Bilingual Data from the Web As far as we know, there is no publication available on mining parallel sentences directly from bilingual web pages. Most existing methods of mining bilingual sentences from the Web, such as (Nie et al., 1999; Resnik and Smith, 2003; Shi et al., 2006), mine parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment methods. However, since the number of bilingual web sites is quite small, these methods can not yield a large number of bilingual sentences. (Shi et al., 2006), mined a total of 1,069,423 pairs of English-Chinese parallel sentences. In addition to mining from parallel documents, (Munteanu and Marcu, 2005) proposed a method for discovering bilingual sentences in comparable corpora. As to the term tra</context>
</contexts>
<marker>Nie, Simard, Isabelle, Durand, 1999</marker>
<rawString>J-Y Nie, M. Simard, P. Isabelle, and R. Durand. 1999. Cross-Language Information Retrieval Based on Parallel Texts and Automatic Mining of parallel Text from the Web. In SIGIR 1999. Pp: 74-81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Noah A Smith</author>
</authors>
<title>The Web as a Parallel Corpus.</title>
<date>2003</date>
<journal>Computational Linguistics.</journal>
<volume>29</volume>
<issue>3</issue>
<pages>349--380</pages>
<contexts>
<context position="2845" citStr="Resnik and Smith, 2003" startWordPosition="434" endWordPosition="437">ist in non-English web sites. Most of them have a primary language (usually a non-English language) and a secondary language (usually English). The content in the secondary language is often the translation of some primary language text in the page. Since bilingual web pages are very common in non-English web sites, mining bilingual data from them should be an important task. However, as far as we know, there is no publication available on mining bilingual sentences directly from bilingual web pages. Most existing methods for mining bilingual sentences from the Web, such as (Nie et al., 1999; Resnik and Smith, 2003; Shi et al., 2006), try to mine parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment methods. As to mining term translations from bilingual web pages, Cao et al. (2007) and Lin et al. (2008) proposed two different methods to extract term translations based on the observation that authors of many bilingual web pages, especially those whose primary language is Chinese, Japanese or Korean, sometimes annotate terms with their English translations inside a pair of parentheses, like “c1c2...cn(e1 e2 ... e</context>
<context position="8379" citStr="Resnik and Smith, 2003" startWordPosition="1305" endWordPosition="1308">owed by our conclusion and some future work in Section 6. Please note that in this paper we describe our method using example bilingual web pages in English and Chinese, however, the method can be applied to extract bilingual data from web pages written in any other pair of languages, such as Japanese and English, Korean and English etc. 2 Related Work Mining Bilingual Data from the Web As far as we know, there is no publication available on mining parallel sentences directly from bilingual web pages. Most existing methods of mining bilingual sentences from the Web, such as (Nie et al., 1999; Resnik and Smith, 2003; Shi et al., 2006), mine parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment methods. However, since the number of bilingual web sites is quite small, these methods can not yield a large number of bilingual sentences. (Shi et al., 2006), mined a total of 1,069,423 pairs of English-Chinese parallel sentences. In addition to mining from parallel documents, (Munteanu and Marcu, 2005) proposed a method for discovering bilingual sentences in comparable corpora. As to the term translation extraction from</context>
</contexts>
<marker>Resnik, Smith, 2003</marker>
<rawString>Philip Resnik, Noah A. Smith. 2003. The Web as a Parallel Corpus. Computational Linguistics. 29(3). Pp: 349-380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Shao</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Mining new word translations from comparable corpora.</title>
<date>2004</date>
<booktitle>In Proc. of COLING</booktitle>
<pages>618--624</pages>
<marker>Shao, Ng, 2004</marker>
<rawString>Li Shao and Hwee Tou Ng. 2004. Mining new word translations from comparable corpora. In Proc. of COLING 2004. Pp: 618–624.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Shi</author>
<author>Cheng Niu</author>
<author>Ming Zhou</author>
<author>Jianfeng Gao</author>
</authors>
<title>A DOM Tree Alignment Model for Mining Parallel Data from the Web. In</title>
<date>2006</date>
<booktitle>ACL</booktitle>
<contexts>
<context position="2864" citStr="Shi et al., 2006" startWordPosition="438" endWordPosition="441">ites. Most of them have a primary language (usually a non-English language) and a secondary language (usually English). The content in the secondary language is often the translation of some primary language text in the page. Since bilingual web pages are very common in non-English web sites, mining bilingual data from them should be an important task. However, as far as we know, there is no publication available on mining bilingual sentences directly from bilingual web pages. Most existing methods for mining bilingual sentences from the Web, such as (Nie et al., 1999; Resnik and Smith, 2003; Shi et al., 2006), try to mine parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment methods. As to mining term translations from bilingual web pages, Cao et al. (2007) and Lin et al. (2008) proposed two different methods to extract term translations based on the observation that authors of many bilingual web pages, especially those whose primary language is Chinese, Japanese or Korean, sometimes annotate terms with their English translations inside a pair of parentheses, like “c1c2...cn(e1 e2 ... em)” (c1c2...cn is a</context>
<context position="8398" citStr="Shi et al., 2006" startWordPosition="1309" endWordPosition="1312">nd some future work in Section 6. Please note that in this paper we describe our method using example bilingual web pages in English and Chinese, however, the method can be applied to extract bilingual data from web pages written in any other pair of languages, such as Japanese and English, Korean and English etc. 2 Related Work Mining Bilingual Data from the Web As far as we know, there is no publication available on mining parallel sentences directly from bilingual web pages. Most existing methods of mining bilingual sentences from the Web, such as (Nie et al., 1999; Resnik and Smith, 2003; Shi et al., 2006), mine parallel web documents within bilingual web sites first and then extract bilingual sentences from mined parallel documents using sentence alignment methods. However, since the number of bilingual web sites is quite small, these methods can not yield a large number of bilingual sentences. (Shi et al., 2006), mined a total of 1,069,423 pairs of English-Chinese parallel sentences. In addition to mining from parallel documents, (Munteanu and Marcu, 2005) proposed a method for discovering bilingual sentences in comparable corpora. As to the term translation extraction from bilingual web page</context>
<context position="26644" citStr="Shi et al., 2006" startWordPosition="4300" endWordPosition="4303">ingual collective nodes. From the inner texts of those nodes, we extracted 12,610,626 unique translation pairs. If we consider those pairs whose English parts contain more than 5 words as sentence translations and all others as term translations, we get 7,522,803 sentence translations and 5,087,823 term translations. We evaluated the quality of these mined translations by sampling 200 sentence translations and 200 term translations and presenting those to human judges, with a resulting precision of 83.5% for sentence translations and 80.5% for term translations. As we mentioned in Section 2, (Shi et al., 2006) reported that in total they mined 1,069,423 pairs of English-Chinese parallel sentences from bilingual web sites. However, our method yields about 7.5 million pairs, about seven times as many. We also re-implemented the extraction method using the parenthesis pattern proposed by (Lin et al., 2008) and were able to mine 6,538,164 bilingual terms from the same web pages. A sample of 200 terms was submitted for human judgment, resulting in a precision of 78.5% which is a little lower than that of our original result. Further analysis showed that fewer than 20% of the bilingual terms mined with o</context>
</contexts>
<marker>Shi, Niu, Zhou, Gao, 2006</marker>
<rawString>Lei Shi, Cheng Niu, Ming Zhou, Jianfeng Gao. 2006. A DOM Tree Alignment Model for Mining Parallel Data from the Web. In ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jung H Shin</author>
<author>Young S Han</author>
<author>Key-Sun Choi</author>
</authors>
<title>Bilingual knowledge acquisition from KoreanEnglish parallel corpus using alignment method: Korean-English alignment at word and phrase level.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th conference on Computational linguistics,</booktitle>
<location>Copenhagen, Denmark.</location>
<marker>Shin, Han, Choi, 1996</marker>
<rawString>Jung H. Shin, Young S. Han and Key-Sun Choi. 1996. Bilingual knowledge acquisition from KoreanEnglish parallel corpus using alignment method: Korean-English alignment at word and phrase level. In Proceedings of the 16th conference on Computational linguistics, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C Wu</author>
<author>T Lin</author>
<author>J S Chang</author>
</authors>
<title>Learning Source-Target Surface Patterns for Web-based Terminology Translation. ACL Interactive Poster and Demonstration Sessions,. Pp 37-40,</title>
<date>2005</date>
<location>Ann Arbor.</location>
<marker>Wu, Lin, Chang, 2005</marker>
<rawString>J.C. Wu, T. Lin and J.S. Chang. 2005. Learning Source-Target Surface Patterns for Web-based Terminology Translation. ACL Interactive Poster and Demonstration Sessions,. Pp 37-40, Ann Arbor.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>P Vines</author>
</authors>
<title>Using the Web for Automated Translation Extraction in CrossLanguage Information Retrieval.</title>
<date>2004</date>
<booktitle>In the Proceedings of SIGIR</booktitle>
<pages>162--169</pages>
<contexts>
<context position="9799" citStr="Zhang and Vines, 2004" startWordPosition="1532" endWordPosition="1535">cially those whose primary language is Chinese, Japanese or Korean sometimes annotate terms with their English translations inside a pair of parentheses. Their methods are tested on a large set of web pages and achieve promising results. However, since not all translations in bilingual web pages follow the parenthesis pattern, these methods may miss a lot of translations appearing on the Web. Apart from mining term translations directly from bilingual web pages, more approaches have been proposed to mine term translations from text snippets returned by a web search engine (Jiang et al., 2007; Zhang and Vines, 2004; Cheng et al., 2004; Huang et al., 2005). In their methods the source language term is usually given and the goal is to find the target language translations from the Web. To obtain web pages containing the target translations, they submit the source term to the web search engine and collect returned snippets. Various techniques have been proposed to extract the target translations from the snippets. Though these methods achieve high accuracy, they are not suitable for compiling a large-scale bilingual dictionary for the following reasons: 1) they need a list of predefined source terms which </context>
</contexts>
<marker>Zhang, Vines, 2004</marker>
<rawString>Zhang, Y. and Vines, P.. 2004. Using the Web for Automated Translation Extraction in CrossLanguage Information Retrieval. In the Proceedings of SIGIR 2004. Pp: 162-169.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>