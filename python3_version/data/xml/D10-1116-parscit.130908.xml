<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003681">
<title confidence="0.999102">
Practical Linguistic Steganography using Contextual Synonym Substitution
and Vertex Colour Coding
</title>
<author confidence="0.99744">
Ching-Yun Chang Stephen Clark
</author>
<affiliation confidence="0.990927">
University of Cambridge University of Cambridge
Computer Laboratory Computer Laboratory
</affiliation>
<email confidence="0.965825">
Ching-Yun.Chang@cl.cam.ac.uk Stephen.Clark@cl.cam.ac.uk
</email>
<sectionHeader confidence="0.99682" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99931488">
Linguistic Steganography is concerned with
hiding information in natural language text.
One of the major transformations used in Lin-
guistic Steganography is synonym substitu-
tion. However, few existing studies have stud-
ied the practical application of this approach.
In this paper we propose two improvements
to the use of synonym substitution for encod-
ing hidden bits of information. First, we use
the Web 1T Google n-gram corpus for check-
ing the applicability of a synonym in context,
and we evaluate this method using data from
the SemEval lexical substitution task. Second,
we address the problem that arises from words
with more than one sense, which creates a po-
tential ambiguity in terms of which bits are
encoded by a particular word. We develop a
novel method in which words are the vertices
in a graph, synonyms are linked by edges, and
the bits assigned to a word are determined by
a vertex colouring algorithm. This method
ensures that each word encodes a unique se-
quence of bits, without cutting out large num-
ber of synonyms, and thus maintaining a rea-
sonable embedding capacity.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999294">
Steganography is concerned with hiding informa-
tion in a cover medium, in order to facilitate covert
communication, such that the presence of the infor-
mation is imperceptible to a user (human or com-
puter). Much of the existing research in steganog-
raphy has used images as cover media; however,
given the ubiquitous nature of electronic text, inter-
est is growing in using natural language as the cover
medium. Linguistic Steganography—lying at the in-
tersection of Computational Linguistics and Com-
puter Security—is concerned with making changes
to a cover text in order to embed information, in such
a way that the changes do not result in ungrammati-
cal or unnatural text.
A related area is natural language watermarking,
in which changes are made to a text in order to iden-
tify it, for example for copyright purposes. An inter-
esting watermarking application is “traitor tracing”,
in which documents are changed in order to embed
individual watermarks. These marks can then be
used to later identify particular documents, for ex-
ample if a set of documents—identical except for
the changes used to embed the watermarks— have
been sent to a group of individuals, and one of the
documents has been leaked to a newspaper.
In terms of security, a linguistic stegosystem
should impose minimum embedding distortion to
the cover text so that the resulting stegotext in which
a message is camouflaged is inconspicuous, result-
ing in high imperceptibility. In addition, since
steganography aims at covert communication, a lin-
guistic stegosystem should allow sufficient embed-
ding capacity, known as the payload. There is a fun-
damental tradeoff between imperceptibility and pay-
load, since any attempt to embed more information
via changes to the cover text increases the chance
of introducing anomalies into the text and therefore
raising the suspicion of an observer.
A linguistic transformation is required to em-
bed information. Transformations studied in pre-
vious work include lexical substitution (Chapman
and Davida, 1997; Bolshakov, 2004; Taskiran et al.,
2006; Topkara et al., 2006b), phrase paraphrasing
(Chang and Clark, 2010), sentence structure manip-
ulations (Atallah et al., 2001a; Atallah et al., 2001b;
</bodyText>
<page confidence="0.958948">
1194
</page>
<note confidence="0.8395112">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1194–1203,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
Liu et al., 2005; Meral et al., 2007; Murphy, 2001;
Murphy and Vogel, 2007; Topkara et al., 2006a) and
semantic transformations (Atallah et al., 2002; Vy-
</note>
<bodyText confidence="0.975873857142857">
bornova and Macq, 2007). Many of these transfor-
mations require some sophisticated NLP tools; for
example, in order to perform semantic transforma-
tions on text, word sense disambiguation, seman-
tic role parsing and anaphora resolution tools may
be required. However, the current state-of-the-art in
language technology is arguably not good enough
for secure linguistic steganography based on sophis-
ticated semantic transformations, and the level of ro-
bustness required to perform practical experiments
has only just become available. Hence many exist-
ing linguistic stegosystems are proof-of-concept im-
plementations with little practical evaluation of the
imperceptibility or payload.
</bodyText>
<subsectionHeader confidence="0.992807">
1.1 Synonym substitution
</subsectionHeader>
<bodyText confidence="0.999923551724138">
Synonym substitution is a relatively straightforward
linguistic steganography method. It substitutes se-
lected words with the same part of speech (PoS) syn-
onyms, and does not involve operating on the sen-
tence structure so the modification can be guaran-
teed to be grammatical. Another advantage of this
method is that many languages are profuse in syn-
onyms, and so there is a rich source of information
carriers compared with other text transformations.
There are two practical difficulties associated with
hiding bits using synonym subsitution. The first is
that words can have more than one sense. In terms of
WordNet (Fellbaum, 1998), which is the electronic
dictionary we use, words can appear in more than
one synset. This is a problem because a word may be
assigned different bit strings in the different synsets,
and the receiver does not know which of the senses
to use, and hence does not know which hidden bit
string to recover. Our solution to this problem is a
novel vertex colouring method which ensures that
words are always assigned the same bit string, even
when they appear in different synsets.
The second problem is that many synonyms are
only applicable in certain contexts. For example, the
words in the WordNet synset {bridge, span} share
the meaning of “a structure that allows people or ve-
hicles to cross an obstacle such as a river or canal
or railway etc.”. However, bridge and span cannot
be substutited for each other in the sentence “sus-
</bodyText>
<figureCaption confidence="0.998717">
Figure 1: An example of the basic algorithm
</figureCaption>
<bodyText confidence="0.9940472">
pension bridges are typically ranked by the length
of their main span”, and doing so would likely raise
the suspicion of an observer due to the resulting
anomaly in the text.
Our solution to this problem is to perform a con-
textual check which utilises the Web 1T n-gram
Google n-gram corpus.1 We evaluate the method
using the data from the English Lexical Substitu-
tion task for SemEval-2007.2 The resulting preci-
sion of our lexical substitution system can be seen
as an indirect measure of the imperceptibility of the
stegosystem, whereas the recall can be seen as an
indirect measure of the payload.
The paper is organised so that the contextual
check is described first, and this is evaluated inde-
pendently of the steganographic application. Then
the vertex colouring method is presented, and finally
we show how the contextual check can be integrated
with the vertex colouring coding method to give a
complete stegsosystem. For readers unfamiliar with
linguistic steganogaphy, Section 2 has some exam-
ples of how bits can be hidden using textual trans-
formations. Also, Chang and Clark (2010) is a re-
cent NLP paper which describes the general linguis-
tic steganography framework.
</bodyText>
<sectionHeader confidence="0.99989" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999952375">
In the original work on linguistic steganography in
the late 1990s, Winstein proposed an information
hiding algorithm using a block coding method to en-
code synonyms, so that the selection of a word from
a synset directly associates with part of the secret
bitstring (Bergmair, 2007). Figure 1 illustrates the
embedding procedure of this approach. In this ex-
ample, the bitstring to be embedded is 010, which
</bodyText>
<footnote confidence="0.999943">
1www.ldc.upenn.edu/Catalog/docs/LDC2006T13/readme.txt
2http://www.dianamccarthy.co.uk/task10index.html
</footnote>
<page confidence="0.993175">
1195
</page>
<figureCaption confidence="0.969255">
Figure 2: An example of applying the basic algorithm to
overlapping synsets
</figureCaption>
<bodyText confidence="0.999977075757576">
can be divided into two codewords, 0 and 10, and the
information carriers in the cover text are the words
finished and project. According to the encoding dic-
tionary, complete represents 0, and task represents
10; hence these words are chosen and replace the
original words in the cover text (with suitable suffix-
ation). The stego sentence “He completed the task”
is then sent to the receiver. In order to recover the
message, the receiver only needs a copy of the en-
coding dictionary, and the decoding algorithm sim-
ply reverses the process used to encode the hidden
bits. Note that the receiver does not need the origi-
nal cover text to recover the information.
This algorithm requires synonym sets to be dis-
joint; i.e. no word may appear in more than one syn-
onym set, since overlapping synsets may cause am-
biguities during the decoding stage. Figure 2 shows
what happens when the basic algorithm is applied to
two overlapping synonym sets. As can be seen from
the example, composition is represented by two dif-
ferent codewords and thus the secret bitstring can-
not be reliably recovered, since the receiver does not
know the original cover word or the sense of the
word. In order to solve this problem, we propose
a novel coding method based on vertex colouring,
described in Section 4.
In addition to the basic algorithm, Winstein pro-
posed the T-Lex system using synonym substitution
as the text transformation. In order to solve the
problem of words appearing in more than one syn-
onym set, Winstein defines interchangeable words
as words that belong to the same synsets, and only
uses these words for substitution. Any words that are
not interchangeable are discarded and not available
for carrying information. The advantage in this ap-
proach is that interchangeable words always receive
the same codeword. The disadvantage is that many
synonyms need to be discarded in order to achieve
this property. Winstein calculates that only 30% of
WordNet can be used in such a system.
Another stegosystem based on synonym substi-
tution was proposed by Bolshakov (2004). In or-
der to ensure both sender and receiver use the
same synsets, Bolshakov applied transitive closure
to overlapping synsets to avoid the decoding ambi-
guity. Applying transitive closure leads to a merger
of all the overlapping synsets into one set which is
then seen as the synset of a target word. Consider
the overlapping synsets in Figure 2 as an example.
After applying transitive closure, the resulting set
is {‘authorship’, ‘composition’, ‘paper’, ‘penning’,
‘report’, ‘theme’, ‘writing’}.
Bolshakov (2004) also uses a method to deter-
mine whether a substitution is applicable in context,
using a collocation-based test. Finally, the colloca-
tionally verified synonyms are encoded by using the
block coding method. This is similar to our use of
the Google n-gram data to check for contextual ap-
plicability.
The disadvantage of Bolshakov’s system is that
all words in a synonym transitive closure chain need
to be considered, which can lead to very large sets
of synonyms, and many which are not synonymous
with the original target word. In contrast, our pro-
posed method operates on the original synonym sets
without extending them unnecessarily.
</bodyText>
<sectionHeader confidence="0.9085" genericHeader="method">
3 Proposed Method and Experiments
</sectionHeader>
<subsectionHeader confidence="0.991248">
3.1 Resources
</subsectionHeader>
<bodyText confidence="0.999987928571429">
We use WordNet (Fellbaum, 1998) to provide sets
of synonyms (synsets) for nouns, verbs, adjectives
and adverbs. Since the purpose of using WordNet is
to find possible substitutes for a target word, those
synsets containing only one entry are not useful and
are ignored by our stegosystem. In addition, our
stegosystem only takes single word substitution into
consideration in order to avoid the confusion of find-
ing information-carrying words during the decoding
phase. For example, if the cover word ‘complete’ is
replaced by ‘all over’, the receiver would not know
whether the secret message is embedded in the word
‘over’ or the phrase ‘all over’. Table 1 shows the
statistics of synsets used in our stegosystem.
</bodyText>
<page confidence="0.961952">
1196
</page>
<table confidence="0.9528408">
noun verb adj adv
# of synsets 16,079 4,529 6,655 964
# of entries 30,933 6,495 14,151 2,025
average set size 2.56 2.79 2.72 2.51
max set size 25 16 21 8
</table>
<tableCaption confidence="0.999733">
Table 1: Statistics of synsets used in our stegosystem
</tableCaption>
<bodyText confidence="0.999696916666667">
For the contextual check we use the Google Web
1T 5-gram Corpus (Brants and Franz, 2006) which
contains counts for n-grams from unigrams through
to five-grams obtained from over 1 trillion word to-
kens of English Web text. The corpus has been used
for many tasks such as spelling correction (Islam and
Inkpen, 2009; Carlson et al., 2008) and multi-word
expression classification (Kummerfeld and Curran,
2008). Moreover, for the SemEval-2007 English
Lexical Substitution Task, which is similar to our
substitution task, six out of ten participating teams
utilised the Web 1T corpus.
</bodyText>
<subsectionHeader confidence="0.999735">
3.2 Synonym Checking Method
</subsectionHeader>
<bodyText confidence="0.980296411764706">
In order to measure the degree of acceptability in a
substitution, the proposed filter calculates a substi-
tution score for a synonym by using the observed
frequency counts in the Web n-gram corpus. The
method first extracts contextual n-grams around the
synonym and queries the n-gram frequency counts
from the corpus. For each n, the total count fn is cal-
culated by summing up individual n-gram frequen-
cies, for every contextual n-gram containing the tar-
get word. We define a count function Count(w) =
E5n=2 log(fn) where log(0) is defined as zero. If
Count(w) = 0, we assume the word w is unrelated
to the context and therefore is eliminated from con-
sideration. We then find the maximum Count(w)
called max from the remaining words. The main
purpose of having max is to score each word rela-
tive to the most likely synonym in the group, so even
in less frequent contexts which lead to smaller fre-
quency counts, the score of each synonym can still
indicate the degree of feasibility. The substitution
score is defined as Score(w) = Count(w) - max.
The hypothesis is that a word with a high score is
more suitable for the context, and we apply a thresh-
old so that synonyms having a score lower than the
threshold are discarded.
Figure 3 demonstrates an example of calculat-
f2=525,856 high pole 3,544
pole . 522,312
f3=554 very high pole 84
high pole . 470
f4=72 a very high pole 72
very high pole . 0
f5=0 not a very high pole 0
a very high pole . 0
</bodyText>
<figure confidence="0.92722">
Count(‘pole’)=log(f2)+log(f3)+log(f4)+log(f5)=23
Score(‘pole’)=Count(‘pole’)/max=0.44&gt;0.37
</figure>
<figureCaption confidence="0.9882145">
Figure 3: An example of using the proposed synonym
checking method
</figureCaption>
<bodyText confidence="0.999384416666667">
ing the substitution score for the synonym ‘pole’
given the cover sentence “This is not a very high
bar.” First of all, various contextual n-grams are ex-
tracted from the sentence and the Web n-gram cor-
pus is consulted to obtain their frequency counts.
Count(‘pole’) is then calculated using the n-gram
frequencies. Suppose the threshold is 0.37, and the
max score is 52. Since Count(‘pole’) is greater
than zero and the substitution score Score(‘pole’)
is 0.44, the word ‘pole’ is determined as acceptable
for this context (even though it may not be, depend-
ing on the meaning of ‘bar’ in this case).
</bodyText>
<subsectionHeader confidence="0.997549">
3.3 Evaluation Data
</subsectionHeader>
<bodyText confidence="0.999975736842105">
In order to evaluate the proposed synonym check-
ing method, we need some data to test whether our
method can pick out acceptable substitutions. The
English Lexical Substitution task for SemEval-2007
has created human-annotated data for developing
systems that can automatically find feasible substi-
tutes given a target word in context. This data com-
prises 2010 sentences selected from the English In-
ternet Corpus3, and consists of 201 words: nouns,
verbs, adjectives and adverbs each with ten sen-
tences containing that word. The five annotators
were asked to provide up to three substitutes for a
target word in the context of a sentence, and were
permitted to consult a dictionary or thesaurus of
their choosing.
We use the sentences in this gold standard as the
cover text in our experiments so that the substi-
tutes provided by the annotators can be the positive
data for evaluating the proposed synonym check-
</bodyText>
<footnote confidence="0.948494">
3http://corpus.leeds.ac.uk/internet.html
</footnote>
<page confidence="0.89978">
1197
</page>
<table confidence="0.999207">
noun verb adj adv
# of target words 59 54 57 35
# of sentences 570 527 558 349
# of positives 2,343 2,371 2,708 1,269
# of negatives 1,914 1,715 1,868 884
</table>
<tableCaption confidence="0.999259">
Table 2: Statistics of experimental data
</tableCaption>
<bodyText confidence="0.999545625">
ing methods. Since we only take into considera-
tion the single word substitutions for the reason de-
scribed earlier, multi-word substitutes are removed
from the positive data. Moreover, we use Word-
Net as the source of providing candidate substitutes
in our stegosystem, so if a human-provided sub-
stitute does not appear in any synsets of its target
word in WordNet, there is no chance for our sys-
tem to replace the target word with the substitute and
therefore, the substitute can be eliminated. Table 2
presents the statistics of the positive data for our ex-
periments.
Apart from positive data, we also need some neg-
ative data to test whether our method has the ability
to filter out bad substitutions. Since the annotators
were allowed to refer to a dictionary or thesaurus,
we assume that annotators used WordNet as one of
the reference resources while generating candidates.
Hence we assume that, if a word in the correct synset
for a target word is not in the set produced by the hu-
man annotators, then it is inappropriate for that con-
text and a suitable negative example. This method is
appropriate because our steganography system has
to distinguish between good and bad synonyms from
WordNet, given a particular context.
For the above reasons, we extract the negative
data for our experiments by first matching positive
substitutes of a target word to all the synsets that
contain the target word in WordNet. The synset
that includes the most positive substitutes is used
to represent the meaning of the target word. If
there is more than one synset containing the high-
est number of positives, all the synsets are taken
into consideration. We then randomly select up to
six single-word synonyms other than positive substi-
tutes from the chosen synset(s) as negative instances
of the target word. Figure 4 shows an example of
automatically collected negative data from WordNet
given a target word and its positive substitutes. The
synset {‘remainder’, ‘balance’, ‘residual’, ‘residue’,
</bodyText>
<figureCaption confidence="0.99225">
Figure 4: An example of automatic negative data
</figureCaption>
<table confidence="0.998702666666667">
noun verb adj adv
# of true negatives 234 201 228 98
# of false negatives 9 20 28 16
</table>
<tableCaption confidence="0.999831">
Table 3: Annotation results for negative data
</tableCaption>
<bodyText confidence="0.999805379310345">
‘residuum’, ‘rest’} is selected for negative data col-
lection since it contains one of the positives while
the other synsets do not. We assume the selected
synset represents the meaning of the original word,
and those synonyms in the synset which are not an-
notated as positives must have a certain degree of
mismatch to the context. Therefore, from this exam-
ple, ‘balance’, ‘residue’, ‘residuum’ and ‘rest’ are
extracted as negatives to test whether our synonym
checking method can pick out bad substitutions from
a set of words sharing similar or the same meaning.
In order to examine whether the automatically
collected instances are true negatives and hence
form a useful test set, a sample of automatically gen-
erated negatives was selected for human evaluation.
For each PoS one sentence of each different target
word is selected, which results in roughly 13% of
the collected negative data, and every negative sub-
stitute of the selected sentences was judged by the
second author. As can be seen from the annota-
tion results shown in Table 3, most of the instances
are true negatives, and only a few cases are incor-
rectly chosen as false negatives. Since the main pur-
pose of the data set is to test whether the proposed
synonym checking method can guard against inap-
propriate synonym substitutions and be integrated
in the stegosystem, it is reasonable to have a few
false negatives in our experimental data. Also, it
is more harmless to rule out a permissible substitu-
</bodyText>
<page confidence="0.982267">
1198
</page>
<table confidence="0.9995516">
PoS Acc% P% R% F% Threshold
noun 70.2 70.0 80.2 74.7 0.58
verb 68.1 69.7 79.5 74.3 0.56
adj 72.5 72.7 85.7 78.7 0.48
adv 73.7 76.4 80.1 78.2 0.54
</table>
<tableCaption confidence="0.99987">
Table 4: Performance of the synonym checking method
</tableCaption>
<bodyText confidence="0.999847727272727">
tion than including an inappropriate replacement for
a stegosystem in terms of the security. Table 2 gives
the statistics of the automatically collected negative
data for our experiments.
Note that, although we use the data from the lex-
ical substitution task, our task is different: the pos-
sible substitutions for a target word need to be fixed
in advance for linguistic steganography (in order for
the receiver to be able to recover the hidden bits),
whereas for the lexical substitution task participants
were asked to discover possible replacements.
</bodyText>
<sectionHeader confidence="0.795933" genericHeader="method">
3.4 Results
</sectionHeader>
<bodyText confidence="0.999806333333333">
The performance of the proposed checking method
is evaluated in terms of accuracy, precision, recall
and balanced F-measure. Accuracy represents the
percentage of correct judgements over all accept-
able and unacceptable substitutions. Precision is the
percentage of substitutions judged acceptable by the
method which are determined to be suitable syn-
onyms by the human judges. Recall is the percent-
age of substitutions determined to be feasible by the
human annotators which are also judged acceptable
by the method. The interpretation of the measures
for a stegosystem is that a higher precision value im-
plies a better security level since good substitutions
are less likely to be seen as suspicious by the ob-
server; whereas a larger recall value means a greater
payload capacity since words are being substituted
where possible and therefore embedding as much in-
formation as possible.
In order to derive sensible threshold values for
each PoS, 5-fold cross-validation was implemented
to conduct the experiments. For each fold, 80% of
the data is used to find the threshold value which
maximises the accuracy, and that threshold is then
applied to the remaining 20% to get the final result.
Table 4 gives the results for the synonym checking
method and the average threshold values over the 5
folds. In addition, we are interested in the effect of
</bodyText>
<figureCaption confidence="0.998821">
Figure 5: System performance under various thresholds
</figureCaption>
<bodyText confidence="0.999960533333333">
various thresholds on the system performance. Fig-
ure 5 shows the precision and recall values with re-
spect to different thresholds for each PoS. From the
graphs we can clearly see the trade-off between pre-
cision and recall. Although a higher precision can
be achieved by using a higher threshold value, for
example noun’s substitutions almost reach 90% pre-
cision with threshold equal to 0.9, the large drop in
recall means many applicable synonyms are being
eliminated. In other words, the trade-off between
precision and recall implies the trade-off between
imperceptibility and payload capacity for linguistic
steganography. Therefore, the practical threshold
setting would depend on how steganography users
want to trade off imperceptibility for payload.
</bodyText>
<page confidence="0.998901">
1199
</page>
<figureCaption confidence="0.998701">
Figure 6: An example of coloured synonym graph
</figureCaption>
<sectionHeader confidence="0.993375" genericHeader="method">
4 Proposed Stegosystem
</sectionHeader>
<subsectionHeader confidence="0.999107">
4.1 The Vertex Coloring Coding Method
</subsectionHeader>
<bodyText confidence="0.999972971428571">
In this section, we propose a novel coding method
based on vertex colouring by which each synonym is
assigned a unique codeword so the usage of overlap-
ping synsets is not problematic for data embedding
and extracting. A vertex colouring is a labelling of
the graph’s vertices with colours subject to the con-
dition that no two adjacent vertices share the same
colour. The smallest number of colours required
to colour a graph G is called its chromatic num-
ber x(G), and a graph G having chromatic number
x(G) = k is called a k-chromatic graph. The main
idea of the proposed coding method is to represent
overlapping synsets as an undirected k-chromatic
graph called a synonym graph which has a vertex
for each word and an edge for every pair of words
that share the same meaning. A synonym is then
encoded by a codeword that represents the colour
assigned by the vertex colouring of the synonym
graph. Figure 6 shows the use of four different
colours, represented by ‘00’, ‘01’, ‘10’ and ‘11’, to
colour the 4-chromatic synonym graph of the two
overlapping synsets in Figure 2. Now, the over-
lapped word ‘composition’ receives a unique code-
word no matter which synset is considered, which
means the replacement of ‘paper’ to ‘composition’
in Figure 2 will not cause an ambiguity since the re-
ceiver can apply the same coding method to derive
identical codewords used by the sender.
99.6% of synsets in WordNet have size less than
8, which means most of the synsets cannot exhaust
more than a 2-bit coding space (i.e. we can only
encode at most 2 bits using a typical synset). There-
fore, we restrict the chromatic number of a synonym
graph G to 1 &lt; x(G) &lt; 4, which implies the max-
imum size of a synset is 4. When x(G) = 2, each
</bodyText>
<figureCaption confidence="0.999519">
Figure 7: Examples of 2,3,4-chromatic synonym graphs
</figureCaption>
<bodyText confidence="0.999928409090909">
vertex is assigned a single-bit codeword either ‘0’
or ‘1’ as shown in Figure 7(a). When x(G) = 3,
the overlapping set’s size is either 2 or 3, which can-
not exhaust the 2-bit coding space although code-
words ‘00’, ‘01’ and ‘10’ are initially assigned to
each vertex. Therefore, only the most significant
bits are used to represent the synonyms, which we
call codeword reduction. After the codeword reduc-
tion, if a vertex has the same codeword, say ‘0’, as
all of its neighbors, the vertex’s codeword must be
changed to ‘1’ so that the vertex would be able to ac-
commodate either secret bit ‘0’ or ‘1’, which we call
codeword correction. Figure 7(b) shows an example
of the process of codeword reduction and codeword
correction for x(G) = 3. For the case of x(G) = 4,
codeword reduction is applied to those vertices that
themselves or their neighboring vertices have no ac-
cess to all the codewords ‘00’, ‘01’, ‘10’ and ‘11’.
For example, vertices a, b, c, e and f in Figure 7(c)
meet the requirement of needing codeword reduc-
tion. The codeword correction process is then fur-
ther applied to vertex f to rectify its accessibility.
</bodyText>
<page confidence="0.967802">
1200
</page>
<bodyText confidence="0.99983645">
Figure 8 describes a greedy algorithm for con-
structing a coded synonym graph using at most
4 colours, given n synonyms w1, w2,... , wn in
the overlapping synsets. Let us define a function
E(wi7 wj) which returns an edge between wi and
wj if wi and wj are in the same synset; otherwise
returns false. Another function Qwi) returns the
colour of the synonym wi. The procedure loops
through all the input synonyms. For each iteration,
the procedure first finds available colours for the tar-
get synonym wi. If there is no colour available,
namely all the four colours have already been given
to wi’s neighbors, wi is randomly assigned one of
the four colours; otherwise, wi is assigned one of
the available colours. After adding wi to the graph
G, the procedure checks whether adding an edge of
wi to graph G would violate the vertex colouring.
After constructing the coloured graph, codeword re-
duction and codeword correction as previously de-
scribed are applied to revise improper codewords.
</bodyText>
<subsectionHeader confidence="0.998654">
4.2 Proposed Lexical Stegosystem
</subsectionHeader>
<bodyText confidence="0.9939528125">
Figure 9 illustrates the framework of our lexical
stegosystem. Note that we have preprocessed Word-
Net by excluding multi-word synonyms and single-
entry synsets. A possible information carrier is first
found in the cover sentence. We define a possi-
ble information carrier as a word in the cover sen-
tence that belongs to at least one synset in Word-
Net. The synsets containing the target word, and all
other synsets which can be reached via the synonym
relation, are then extracted from WordNet (i.e. we
build the connected component of WordNet which
contains the target word according to the synonym
relation). Words in these sets are then examined
by the Google n-gram contextual checking method
to eliminate inappropriate substitutions. If there is
more than one word left and if words which pass the
filter all belong to the same synset, the block cod-
ing method is used to encode the words; otherwise
the vertex colouring coding is applied. Finally, ac-
cording to the secret bitstring, the system selects the
synonym that shares an edge with the target word
and has as its codeword the longest potential match
with the secret bitstring.
We use the connected component of WordNet
containing the target word as a simple method to en-
sure that both sender and receiver colour-code the
INPUT: a synonym list w1, w2,... , wn and an
empty graph G
OUTPUT: a coded synonym graph G using at
most four colours
FOR every synonym wi in the input list
initialize four colours as available for wi
</bodyText>
<figure confidence="0.968172636363636">
FOR every wj in graph G
IF E(wi7 wj) THEN
set Qwj) as unavailable
END IF
END FOR
IF there is a colour available THEN
assign one of the available colours
to wi
ELSE
assign one of the four colours to wi
END IF
ADD wi to graph G
FOR every wj in graph G
IF E(wi7 wj) and Qwi) is not
equal to Qwj) THEN
ADD edge E(wi7 wj) to G
END IF
END FOR
END FOR
codeword reduction
codeword correction
OUTPUT graph G
</figure>
<figureCaption confidence="0.999784">
Figure 8: Constructing a coloured synonym graph
</figureCaption>
<bodyText confidence="0.9995445625">
same graph. It is important to note, however, that
the sender only considers the synonyms of the target
word as potential substitutes; the connected compo-
nent is only used to consistently assign the codes.
For the decoding process, the receiver does not
need the original text for extracting secret data. An
information carrier can be found in the stegotext by
referring to WordNet in which related synonyms are
extracted. Those words in the related sets undergo
the synonym checking method and then are encoded
by either block coding or vertex colouring coding
scheme depending on whether the remaining words
are in the same synset. Finally, the secret bitstring is
implicit in the codeword of the information carrier
and therefore can be extracted.
We demonstrate how to embed secret bit 1 in the
</bodyText>
<page confidence="0.990356">
1201
</page>
<figureCaption confidence="0.999851">
Figure 9: Framework of the proposed lexical stegosystem
</figureCaption>
<bodyText confidence="0.999955217391304">
sentence “it is a shame that we could not reach the
next stage.” A possible information carrier ‘shame’
is first found in the sentence. Table 5 lists the re-
lated synsets extracted from WordNet. The score
of each word calculated by the synonym checking
method using the Web 1T Corpus is given as a sub-
script. Assume the threshold score is 0.27. The out-
put of the synonym checking method is shown at the
right side of Table 5. Since the remaining words do
not belong to the same synset, the vertex colouring
coding method is then used to encode the words.
Figure 10(a) is the original synset graph in which
each vertex is assigned one of the four colours; Fig-
ure 10(b) is the graph after applying codeword re-
duction. Although both ‘disgrace’ and ‘pity’ are en-
coded by ‘1’, ‘pity’ is chosen to replace the cover
word since it has a higher score. Finally, the stego-
text is generated, “it is a pity that we could not reach
the next stage.”
As a rough guide to the potential payload with
this approach, we estimate that, with a threshold of
0.5 for the contextual check, the payload would be
slightly higher than 1 bit per newspaper sentence.
</bodyText>
<sectionHeader confidence="0.999688" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9997395">
One of the contributions of this paper is to develop a
novel lexical stegosystem based on vertex colouring
</bodyText>
<figure confidence="0.6172963125">
cover sentence:
It is a shame that we could not reach the next stage
original synsets retained synsets
{commiseration.28,
pity.97, ruth.13, pathos.31}
{pity.97, shame1}
{compassion.49, pity.97}
{commiseration}
{pathos, poignancy}
{pathos.31, poignancy.31}
{shame1, disgrace.84,
ignominy.24}
{compassion.49,
compassionateness0}
{poignance.12,
poignancy.31}
</figure>
<figureCaption confidence="0.608159333333333">
Table 5: Synsets of ‘shame’ before and after applying the
synonym checking method
Figure 10: Synonym graph of ‘shame’
</figureCaption>
<bodyText confidence="0.999776647058824">
coding which improves the data embedding capacity
compared to existing systems. The vertex colouring
coding method represents synonym substitution as a
synonym graph so the relations between words can
be clearly observed. In addition, an automatic sys-
tem for checking synonym acceptability in context is
integrated in our stegosystem to ensure information
security. For future work, we would like to explore
more linguistic transformations that can meet the re-
quirements of linguistic steganography — retaining
the meaning, grammaticality and style of the origi-
nal text. In addition, it is crucial to have a full eval-
uation of the linguistic stegosystem in terms of im-
perceptibility and payload capacity so we can know
how much data can be embedded before the cover
text reaches its maximum distortion which is toler-
ated by a human judge.
</bodyText>
<figure confidence="0.981362333333333">
{condolence.27,
commiseration.28}
{commiseration,
pity, pathos}
{pity, shame}
{compassion, pity}
{shame, disgrace}
{compassion}
{poignancy}
</figure>
<page confidence="0.993122">
1202
</page>
<sectionHeader confidence="0.995832" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999922676470588">
Mikhail J. Atallah, Craig J. McDonough, Victor Raskin,
and Sergei Nirenburg. 2001a. Natural language pro-
cessing for information assurance and security: an
overview and implementations. In Proceedings of the
2000 workshop on New security paradigms, pages 51–
65, Ballycotton, County Cork, Ireland.
Mikhail J. Atallah, Victor Raskin, Michael C. Crogan,
Christian Hempelmann, Florian Kerschbaum, Dina
Mohamed, and Sanket Naik. 2001b. Natural lan-
guage watermarking: design, analysis, and a proof-
of-concept implementation. In Proceedings of the 4th
International Information Hiding Workshop, volume
2137, pages 185–199, Pittsburgh, Pennsylvania.
Mikhail J. Atallah, Victor Raskin, Christian F. Hempel-
mann, Mercan Karahan, Umut Topkara, Katrina E.
Triezenberg, and Radu Sion. 2002. Natural language
watermarking and tamperproofing. In Proceedings of
the 5th International Information Hiding Workshop,
pages 196–212, Noordwijkerhout, The Netherlands.
Richard Bergmair. 2007. A comprehensive bibliogra-
phy of linguistic steganography. In Proceedings of the
SPIE Conference on Security, Steganography, and Wa-
termarking of Multimedia Contents, volume 6505.
Igor A. Bolshakov. 2004. A method of linguistic
steganography based on collocationally-verified syn-
onym. In Information Hiding: 6th International Work-
shop, volume 3200, pages 180–191, Toronto, Canada.
Thorsten Brants and Alex Franz. 2006. Web 1T 5-
gram corpus version 1.1. Technical report, Google Re-
search.
Andrew Carlson, Tom M. Mitchell, and Ian Fette. 2008.
Data analysis project: Leveraging massive textual cor-
pora using n-gram statistics. Technical report, School
of Computer Science, Carnegie Mellon University.
Ching-Yun Chang and Stephen Clark. 2010. Linguis-
tic steganography using automatically generated para-
phrases. In Human Language Technologies: The 2010
Annual Conference of the North American Chapter of
the Association for Computational Linguistics, pages
591–599, Los Angeles, California, June. Association
for Computational Linguistics.
Mark Chapman and George I. Davida. 1997. Hiding the
hidden: A software system for concealing ciphertext
as innocuous text. In Proceedings of the First Interna-
tional Conference on Information and Communication
Security, volume 1334, pages 335–345, Beijing.
Christiane Fellbaum. 1998. WordNet: An electronic lex-
ical database. MIT Press, first edition.
Aminul Islam and Diana Inkpen. 2009. Real-word
spelling correction using Google Web IT 3-grams. In
EMNLP ’09: Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Processing,
pages 1241–1249, Morristown, USA. Association for
Computational Linguistics.
Jonathan K Kummerfeld and James R Curran. 2008.
Classification of verb particle constructions with the
Google Web 1T Corpus. In Proceedings of the Aus-
tralasian Language Technology Association Workshop
2008, pages 55–63, Hobart, Australia, December.
Yuling Liu, Xingming Sun, and Yong Wu. 2005. A nat-
ural language watermarking based on Chinese syntax.
In Advances in Natural Computation, volume 3612,
pages 958–961, Changsha, China.
Diana McCarthy and Roberto Navigli. 2007. Semeval-
2007 task 10: English lexical substitution task. In Pro-
ceedings of the 4th International Workshop on Seman-
tic Evaluations, pages 48–53, Prague, Czech Republic.
Hasan M. Meral, Emre Sevinc, Ersin Unkar, Bulent
Sankur, A. Sumru Ozsoy, and Tunga Gungor. 2007.
Syntactic tools for text watermarking. In Proceed-
ings of the SPIE Conference on Security, Steganogra-
phy, and Watermarking of Multimedia Contents, vol-
ume 6505, San Jose, CA.
Brian Murphy and Carl Vogel. 2007. The syntax of con-
cealment: reliable methods for plain text information
hiding. In Proceedings of the SPIE Conference on Se-
curity, Steganography, and Watermarking of Multime-
dia Contents, volume 6505, San Jose, CA.
Brian Murphy. 2001. Syntactic information hiding in
plain text. Master’s thesis, Trinity College Dublin.
Cuneyt M. Taskiran, Mercan Topkara, and Edward J.
Delp. 2006. Attacks on linguistic steganography sys-
tems using text analysis. In Proceedings of the SPIE
Conference on Security, Steganography, and Water-
marking of Multimedia Contents, volume 6072, pages
97–105, San Jose, CA.
Mercan Topkara, Umut Topkara, and Mikhail J. Atallah.
2006a. Words are not enough: sentence level natural
language watermarking. In Proceedings of the ACM
Workshop on Content Protection and Security, pages
37–46, Santa Barbara, CA.
Umut Topkara, Mercan Topkara, and Mikhail J. Atal-
lah. 2006b. The hiding virtues of ambiguity: quan-
tifiably resilient watermarking of natural language text
through synonym substitutions. In Proceedings of the
8th Workshop on Multimedia and Security, pages 164–
174, Geneva, Switzerland.
M. Olga Vybornova and Benoit Macq. 2007. A
method of text watermarking using presuppositions.
In Proceedings of the SPIE Conference on Secu-
rity, Steganography, and Watermarking of Multimedia
Contents, volume 6505, San Jose, CA.
</reference>
<page confidence="0.969765">
1203
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.330666">
<title confidence="0.9975175">Practical Linguistic Steganography using Contextual Synonym Substitution and Vertex Colour Coding</title>
<author confidence="0.997501">Ching-Yun Chang Stephen Clark</author>
<affiliation confidence="0.710442666666667">University of Cambridge University of Cambridge Computer Laboratory Computer Ching-Yun.Chang@cl.cam.ac.uk Stephen.Clark@cl.cam.ac.uk</affiliation>
<abstract confidence="0.999033153846154">Linguistic Steganography is concerned with hiding information in natural language text. One of the major transformations used in Linguistic Steganography is synonym substitution. However, few existing studies have studied the practical application of this approach. In this paper we propose two improvements to the use of synonym substitution for encoding hidden bits of information. First, we use the Web 1T Google n-gram corpus for checking the applicability of a synonym in context, and we evaluate this method using data from the SemEval lexical substitution task. Second, we address the problem that arises from words with more than one sense, which creates a potential ambiguity in terms of which bits are encoded by a particular word. We develop a novel method in which words are the vertices in a graph, synonyms are linked by edges, and the bits assigned to a word are determined by a vertex colouring algorithm. This method ensures that each word encodes a unique sequence of bits, without cutting out large number of synonyms, and thus maintaining a reasonable embedding capacity.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mikhail J Atallah</author>
<author>Craig J McDonough</author>
<author>Victor Raskin</author>
<author>Sergei Nirenburg</author>
</authors>
<title>Natural language processing for information assurance and security: an overview and implementations.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2000 workshop on New security paradigms,</booktitle>
<pages>51--65</pages>
<location>Ballycotton, County Cork, Ireland.</location>
<contexts>
<context position="3564" citStr="Atallah et al., 2001" startWordPosition="554" endWordPosition="557">embedding capacity, known as the payload. There is a fundamental tradeoff between imperceptibility and payload, since any attempt to embed more information via changes to the cover text increases the chance of introducing anomalies into the text and therefore raising the suspicion of an observer. A linguistic transformation is required to embed information. Transformations studied in previous work include lexical substitution (Chapman and Davida, 1997; Bolshakov, 2004; Taskiran et al., 2006; Topkara et al., 2006b), phrase paraphrasing (Chang and Clark, 2010), sentence structure manipulations (Atallah et al., 2001a; Atallah et al., 2001b; 1194 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1194–1203, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics Liu et al., 2005; Meral et al., 2007; Murphy, 2001; Murphy and Vogel, 2007; Topkara et al., 2006a) and semantic transformations (Atallah et al., 2002; Vybornova and Macq, 2007). Many of these transformations require some sophisticated NLP tools; for example, in order to perform semantic transformations on text, word sense disambiguation, semantic role parsing and anaph</context>
</contexts>
<marker>Atallah, McDonough, Raskin, Nirenburg, 2001</marker>
<rawString>Mikhail J. Atallah, Craig J. McDonough, Victor Raskin, and Sergei Nirenburg. 2001a. Natural language processing for information assurance and security: an overview and implementations. In Proceedings of the 2000 workshop on New security paradigms, pages 51– 65, Ballycotton, County Cork, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikhail J Atallah</author>
<author>Victor Raskin</author>
<author>Michael C Crogan</author>
<author>Christian Hempelmann</author>
<author>Florian Kerschbaum</author>
<author>Dina Mohamed</author>
<author>Sanket Naik</author>
</authors>
<title>Natural language watermarking: design, analysis, and a proofof-concept implementation.</title>
<date>2001</date>
<booktitle>In Proceedings of the 4th International Information Hiding Workshop,</booktitle>
<volume>2137</volume>
<pages>185--199</pages>
<location>Pittsburgh, Pennsylvania.</location>
<contexts>
<context position="3564" citStr="Atallah et al., 2001" startWordPosition="554" endWordPosition="557">embedding capacity, known as the payload. There is a fundamental tradeoff between imperceptibility and payload, since any attempt to embed more information via changes to the cover text increases the chance of introducing anomalies into the text and therefore raising the suspicion of an observer. A linguistic transformation is required to embed information. Transformations studied in previous work include lexical substitution (Chapman and Davida, 1997; Bolshakov, 2004; Taskiran et al., 2006; Topkara et al., 2006b), phrase paraphrasing (Chang and Clark, 2010), sentence structure manipulations (Atallah et al., 2001a; Atallah et al., 2001b; 1194 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1194–1203, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics Liu et al., 2005; Meral et al., 2007; Murphy, 2001; Murphy and Vogel, 2007; Topkara et al., 2006a) and semantic transformations (Atallah et al., 2002; Vybornova and Macq, 2007). Many of these transformations require some sophisticated NLP tools; for example, in order to perform semantic transformations on text, word sense disambiguation, semantic role parsing and anaph</context>
</contexts>
<marker>Atallah, Raskin, Crogan, Hempelmann, Kerschbaum, Mohamed, Naik, 2001</marker>
<rawString>Mikhail J. Atallah, Victor Raskin, Michael C. Crogan, Christian Hempelmann, Florian Kerschbaum, Dina Mohamed, and Sanket Naik. 2001b. Natural language watermarking: design, analysis, and a proofof-concept implementation. In Proceedings of the 4th International Information Hiding Workshop, volume 2137, pages 185–199, Pittsburgh, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikhail J Atallah</author>
<author>Victor Raskin</author>
<author>Christian F Hempelmann</author>
<author>Mercan Karahan</author>
<author>Umut Topkara</author>
<author>Katrina E Triezenberg</author>
<author>Radu Sion</author>
</authors>
<title>Natural language watermarking and tamperproofing.</title>
<date>2002</date>
<booktitle>In Proceedings of the 5th International Information Hiding Workshop,</booktitle>
<pages>196--212</pages>
<location>Noordwijkerhout, The Netherlands.</location>
<contexts>
<context position="3942" citStr="Atallah et al., 2002" startWordPosition="609" endWordPosition="612">udied in previous work include lexical substitution (Chapman and Davida, 1997; Bolshakov, 2004; Taskiran et al., 2006; Topkara et al., 2006b), phrase paraphrasing (Chang and Clark, 2010), sentence structure manipulations (Atallah et al., 2001a; Atallah et al., 2001b; 1194 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1194–1203, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics Liu et al., 2005; Meral et al., 2007; Murphy, 2001; Murphy and Vogel, 2007; Topkara et al., 2006a) and semantic transformations (Atallah et al., 2002; Vybornova and Macq, 2007). Many of these transformations require some sophisticated NLP tools; for example, in order to perform semantic transformations on text, word sense disambiguation, semantic role parsing and anaphora resolution tools may be required. However, the current state-of-the-art in language technology is arguably not good enough for secure linguistic steganography based on sophisticated semantic transformations, and the level of robustness required to perform practical experiments has only just become available. Hence many existing linguistic stegosystems are proof-of-concept</context>
</contexts>
<marker>Atallah, Raskin, Hempelmann, Karahan, Topkara, Triezenberg, Sion, 2002</marker>
<rawString>Mikhail J. Atallah, Victor Raskin, Christian F. Hempelmann, Mercan Karahan, Umut Topkara, Katrina E. Triezenberg, and Radu Sion. 2002. Natural language watermarking and tamperproofing. In Proceedings of the 5th International Information Hiding Workshop, pages 196–212, Noordwijkerhout, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Bergmair</author>
</authors>
<title>A comprehensive bibliography of linguistic steganography.</title>
<date>2007</date>
<booktitle>In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,</booktitle>
<volume>volume</volume>
<pages>6505</pages>
<contexts>
<context position="7638" citStr="Bergmair, 2007" startWordPosition="1210" endWordPosition="1211"> vertex colouring coding method to give a complete stegsosystem. For readers unfamiliar with linguistic steganogaphy, Section 2 has some examples of how bits can be hidden using textual transformations. Also, Chang and Clark (2010) is a recent NLP paper which describes the general linguistic steganography framework. 2 Related Work In the original work on linguistic steganography in the late 1990s, Winstein proposed an information hiding algorithm using a block coding method to encode synonyms, so that the selection of a word from a synset directly associates with part of the secret bitstring (Bergmair, 2007). Figure 1 illustrates the embedding procedure of this approach. In this example, the bitstring to be embedded is 010, which 1www.ldc.upenn.edu/Catalog/docs/LDC2006T13/readme.txt 2http://www.dianamccarthy.co.uk/task10index.html 1195 Figure 2: An example of applying the basic algorithm to overlapping synsets can be divided into two codewords, 0 and 10, and the information carriers in the cover text are the words finished and project. According to the encoding dictionary, complete represents 0, and task represents 10; hence these words are chosen and replace the original words in the cover text </context>
</contexts>
<marker>Bergmair, 2007</marker>
<rawString>Richard Bergmair. 2007. A comprehensive bibliography of linguistic steganography. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 6505.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor A Bolshakov</author>
</authors>
<title>A method of linguistic steganography based on collocationally-verified synonym.</title>
<date>2004</date>
<booktitle>In Information Hiding: 6th International Workshop,</booktitle>
<volume>3200</volume>
<pages>180--191</pages>
<location>Toronto, Canada.</location>
<contexts>
<context position="3416" citStr="Bolshakov, 2004" startWordPosition="534" endWordPosition="535">ting in high imperceptibility. In addition, since steganography aims at covert communication, a linguistic stegosystem should allow sufficient embedding capacity, known as the payload. There is a fundamental tradeoff between imperceptibility and payload, since any attempt to embed more information via changes to the cover text increases the chance of introducing anomalies into the text and therefore raising the suspicion of an observer. A linguistic transformation is required to embed information. Transformations studied in previous work include lexical substitution (Chapman and Davida, 1997; Bolshakov, 2004; Taskiran et al., 2006; Topkara et al., 2006b), phrase paraphrasing (Chang and Clark, 2010), sentence structure manipulations (Atallah et al., 2001a; Atallah et al., 2001b; 1194 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1194–1203, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics Liu et al., 2005; Meral et al., 2007; Murphy, 2001; Murphy and Vogel, 2007; Topkara et al., 2006a) and semantic transformations (Atallah et al., 2002; Vybornova and Macq, 2007). Many of these transformations require some so</context>
<context position="10007" citStr="Bolshakov (2004)" startWordPosition="1595" endWordPosition="1596"> words appearing in more than one synonym set, Winstein defines interchangeable words as words that belong to the same synsets, and only uses these words for substitution. Any words that are not interchangeable are discarded and not available for carrying information. The advantage in this approach is that interchangeable words always receive the same codeword. The disadvantage is that many synonyms need to be discarded in order to achieve this property. Winstein calculates that only 30% of WordNet can be used in such a system. Another stegosystem based on synonym substitution was proposed by Bolshakov (2004). In order to ensure both sender and receiver use the same synsets, Bolshakov applied transitive closure to overlapping synsets to avoid the decoding ambiguity. Applying transitive closure leads to a merger of all the overlapping synsets into one set which is then seen as the synset of a target word. Consider the overlapping synsets in Figure 2 as an example. After applying transitive closure, the resulting set is {‘authorship’, ‘composition’, ‘paper’, ‘penning’, ‘report’, ‘theme’, ‘writing’}. Bolshakov (2004) also uses a method to determine whether a substitution is applicable in context, usi</context>
</contexts>
<marker>Bolshakov, 2004</marker>
<rawString>Igor A. Bolshakov. 2004. A method of linguistic steganography based on collocationally-verified synonym. In Information Hiding: 6th International Workshop, volume 3200, pages 180–191, Toronto, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<title>Web 1T 5-gram corpus version 1.1.</title>
<date>2006</date>
<tech>Technical report, Google Research.</tech>
<contexts>
<context position="12226" citStr="Brants and Franz, 2006" startWordPosition="1957" endWordPosition="1960">confusion of finding information-carrying words during the decoding phase. For example, if the cover word ‘complete’ is replaced by ‘all over’, the receiver would not know whether the secret message is embedded in the word ‘over’ or the phrase ‘all over’. Table 1 shows the statistics of synsets used in our stegosystem. 1196 noun verb adj adv # of synsets 16,079 4,529 6,655 964 # of entries 30,933 6,495 14,151 2,025 average set size 2.56 2.79 2.72 2.51 max set size 25 16 21 8 Table 1: Statistics of synsets used in our stegosystem For the contextual check we use the Google Web 1T 5-gram Corpus (Brants and Franz, 2006) which contains counts for n-grams from unigrams through to five-grams obtained from over 1 trillion word tokens of English Web text. The corpus has been used for many tasks such as spelling correction (Islam and Inkpen, 2009; Carlson et al., 2008) and multi-word expression classification (Kummerfeld and Curran, 2008). Moreover, for the SemEval-2007 English Lexical Substitution Task, which is similar to our substitution task, six out of ten participating teams utilised the Web 1T corpus. 3.2 Synonym Checking Method In order to measure the degree of acceptability in a substitution, the proposed</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram corpus version 1.1. Technical report, Google Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Tom M Mitchell</author>
<author>Ian Fette</author>
</authors>
<title>Data analysis project: Leveraging massive textual corpora using n-gram statistics.</title>
<date>2008</date>
<tech>Technical report,</tech>
<institution>School of Computer Science, Carnegie Mellon University.</institution>
<contexts>
<context position="12474" citStr="Carlson et al., 2008" startWordPosition="1999" endWordPosition="2002">ver’. Table 1 shows the statistics of synsets used in our stegosystem. 1196 noun verb adj adv # of synsets 16,079 4,529 6,655 964 # of entries 30,933 6,495 14,151 2,025 average set size 2.56 2.79 2.72 2.51 max set size 25 16 21 8 Table 1: Statistics of synsets used in our stegosystem For the contextual check we use the Google Web 1T 5-gram Corpus (Brants and Franz, 2006) which contains counts for n-grams from unigrams through to five-grams obtained from over 1 trillion word tokens of English Web text. The corpus has been used for many tasks such as spelling correction (Islam and Inkpen, 2009; Carlson et al., 2008) and multi-word expression classification (Kummerfeld and Curran, 2008). Moreover, for the SemEval-2007 English Lexical Substitution Task, which is similar to our substitution task, six out of ten participating teams utilised the Web 1T corpus. 3.2 Synonym Checking Method In order to measure the degree of acceptability in a substitution, the proposed filter calculates a substitution score for a synonym by using the observed frequency counts in the Web n-gram corpus. The method first extracts contextual n-grams around the synonym and queries the n-gram frequency counts from the corpus. For each</context>
</contexts>
<marker>Carlson, Mitchell, Fette, 2008</marker>
<rawString>Andrew Carlson, Tom M. Mitchell, and Ian Fette. 2008. Data analysis project: Leveraging massive textual corpora using n-gram statistics. Technical report, School of Computer Science, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ching-Yun Chang</author>
<author>Stephen Clark</author>
</authors>
<title>Linguistic steganography using automatically generated paraphrases.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>591--599</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Los Angeles, California,</location>
<contexts>
<context position="3508" citStr="Chang and Clark, 2010" startWordPosition="546" endWordPosition="549">ication, a linguistic stegosystem should allow sufficient embedding capacity, known as the payload. There is a fundamental tradeoff between imperceptibility and payload, since any attempt to embed more information via changes to the cover text increases the chance of introducing anomalies into the text and therefore raising the suspicion of an observer. A linguistic transformation is required to embed information. Transformations studied in previous work include lexical substitution (Chapman and Davida, 1997; Bolshakov, 2004; Taskiran et al., 2006; Topkara et al., 2006b), phrase paraphrasing (Chang and Clark, 2010), sentence structure manipulations (Atallah et al., 2001a; Atallah et al., 2001b; 1194 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1194–1203, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics Liu et al., 2005; Meral et al., 2007; Murphy, 2001; Murphy and Vogel, 2007; Topkara et al., 2006a) and semantic transformations (Atallah et al., 2002; Vybornova and Macq, 2007). Many of these transformations require some sophisticated NLP tools; for example, in order to perform semantic transformations on text, wo</context>
<context position="7254" citStr="Chang and Clark (2010)" startWordPosition="1145" endWordPosition="1148">ndirect measure of the imperceptibility of the stegosystem, whereas the recall can be seen as an indirect measure of the payload. The paper is organised so that the contextual check is described first, and this is evaluated independently of the steganographic application. Then the vertex colouring method is presented, and finally we show how the contextual check can be integrated with the vertex colouring coding method to give a complete stegsosystem. For readers unfamiliar with linguistic steganogaphy, Section 2 has some examples of how bits can be hidden using textual transformations. Also, Chang and Clark (2010) is a recent NLP paper which describes the general linguistic steganography framework. 2 Related Work In the original work on linguistic steganography in the late 1990s, Winstein proposed an information hiding algorithm using a block coding method to encode synonyms, so that the selection of a word from a synset directly associates with part of the secret bitstring (Bergmair, 2007). Figure 1 illustrates the embedding procedure of this approach. In this example, the bitstring to be embedded is 010, which 1www.ldc.upenn.edu/Catalog/docs/LDC2006T13/readme.txt 2http://www.dianamccarthy.co.uk/task1</context>
</contexts>
<marker>Chang, Clark, 2010</marker>
<rawString>Ching-Yun Chang and Stephen Clark. 2010. Linguistic steganography using automatically generated paraphrases. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 591–599, Los Angeles, California, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Chapman</author>
<author>George I Davida</author>
</authors>
<title>Hiding the hidden: A software system for concealing ciphertext as innocuous text.</title>
<date>1997</date>
<booktitle>In Proceedings of the First International Conference on Information and Communication Security,</booktitle>
<volume>1334</volume>
<pages>335--345</pages>
<location>Beijing.</location>
<contexts>
<context position="3399" citStr="Chapman and Davida, 1997" startWordPosition="530" endWordPosition="533">ed is inconspicuous, resulting in high imperceptibility. In addition, since steganography aims at covert communication, a linguistic stegosystem should allow sufficient embedding capacity, known as the payload. There is a fundamental tradeoff between imperceptibility and payload, since any attempt to embed more information via changes to the cover text increases the chance of introducing anomalies into the text and therefore raising the suspicion of an observer. A linguistic transformation is required to embed information. Transformations studied in previous work include lexical substitution (Chapman and Davida, 1997; Bolshakov, 2004; Taskiran et al., 2006; Topkara et al., 2006b), phrase paraphrasing (Chang and Clark, 2010), sentence structure manipulations (Atallah et al., 2001a; Atallah et al., 2001b; 1194 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1194–1203, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics Liu et al., 2005; Meral et al., 2007; Murphy, 2001; Murphy and Vogel, 2007; Topkara et al., 2006a) and semantic transformations (Atallah et al., 2002; Vybornova and Macq, 2007). Many of these transformation</context>
</contexts>
<marker>Chapman, Davida, 1997</marker>
<rawString>Mark Chapman and George I. Davida. 1997. Hiding the hidden: A software system for concealing ciphertext as innocuous text. In Proceedings of the First International Conference on Information and Communication Security, volume 1334, pages 335–345, Beijing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An electronic lexical database.</title>
<date>1998</date>
<publisher>MIT Press,</publisher>
<note>first edition.</note>
<contexts>
<context position="5287" citStr="Fellbaum, 1998" startWordPosition="812" endWordPosition="813">n is a relatively straightforward linguistic steganography method. It substitutes selected words with the same part of speech (PoS) synonyms, and does not involve operating on the sentence structure so the modification can be guaranteed to be grammatical. Another advantage of this method is that many languages are profuse in synonyms, and so there is a rich source of information carriers compared with other text transformations. There are two practical difficulties associated with hiding bits using synonym subsitution. The first is that words can have more than one sense. In terms of WordNet (Fellbaum, 1998), which is the electronic dictionary we use, words can appear in more than one synset. This is a problem because a word may be assigned different bit strings in the different synsets, and the receiver does not know which of the senses to use, and hence does not know which hidden bit string to recover. Our solution to this problem is a novel vertex colouring method which ensures that words are always assigned the same bit string, even when they appear in different synsets. The second problem is that many synonyms are only applicable in certain contexts. For example, the words in the WordNet syn</context>
<context position="11239" citStr="Fellbaum, 1998" startWordPosition="1790" endWordPosition="1791">based test. Finally, the collocationally verified synonyms are encoded by using the block coding method. This is similar to our use of the Google n-gram data to check for contextual applicability. The disadvantage of Bolshakov’s system is that all words in a synonym transitive closure chain need to be considered, which can lead to very large sets of synonyms, and many which are not synonymous with the original target word. In contrast, our proposed method operates on the original synonym sets without extending them unnecessarily. 3 Proposed Method and Experiments 3.1 Resources We use WordNet (Fellbaum, 1998) to provide sets of synonyms (synsets) for nouns, verbs, adjectives and adverbs. Since the purpose of using WordNet is to find possible substitutes for a target word, those synsets containing only one entry are not useful and are ignored by our stegosystem. In addition, our stegosystem only takes single word substitution into consideration in order to avoid the confusion of finding information-carrying words during the decoding phase. For example, if the cover word ‘complete’ is replaced by ‘all over’, the receiver would not know whether the secret message is embedded in the word ‘over’ or the</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An electronic lexical database. MIT Press, first edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aminul Islam</author>
<author>Diana Inkpen</author>
</authors>
<title>Real-word spelling correction using Google Web IT 3-grams.</title>
<date>2009</date>
<booktitle>In EMNLP ’09: Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1241--1249</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, USA.</location>
<contexts>
<context position="12451" citStr="Islam and Inkpen, 2009" startWordPosition="1995" endWordPosition="1998">er’ or the phrase ‘all over’. Table 1 shows the statistics of synsets used in our stegosystem. 1196 noun verb adj adv # of synsets 16,079 4,529 6,655 964 # of entries 30,933 6,495 14,151 2,025 average set size 2.56 2.79 2.72 2.51 max set size 25 16 21 8 Table 1: Statistics of synsets used in our stegosystem For the contextual check we use the Google Web 1T 5-gram Corpus (Brants and Franz, 2006) which contains counts for n-grams from unigrams through to five-grams obtained from over 1 trillion word tokens of English Web text. The corpus has been used for many tasks such as spelling correction (Islam and Inkpen, 2009; Carlson et al., 2008) and multi-word expression classification (Kummerfeld and Curran, 2008). Moreover, for the SemEval-2007 English Lexical Substitution Task, which is similar to our substitution task, six out of ten participating teams utilised the Web 1T corpus. 3.2 Synonym Checking Method In order to measure the degree of acceptability in a substitution, the proposed filter calculates a substitution score for a synonym by using the observed frequency counts in the Web n-gram corpus. The method first extracts contextual n-grams around the synonym and queries the n-gram frequency counts fr</context>
</contexts>
<marker>Islam, Inkpen, 2009</marker>
<rawString>Aminul Islam and Diana Inkpen. 2009. Real-word spelling correction using Google Web IT 3-grams. In EMNLP ’09: Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1241–1249, Morristown, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan K Kummerfeld</author>
<author>James R Curran</author>
</authors>
<title>Classification of verb particle constructions with the Google Web 1T Corpus.</title>
<date>2008</date>
<booktitle>In Proceedings of the Australasian Language Technology Association Workshop</booktitle>
<pages>55--63</pages>
<location>Hobart, Australia,</location>
<contexts>
<context position="12545" citStr="Kummerfeld and Curran, 2008" startWordPosition="2007" endWordPosition="2010">ystem. 1196 noun verb adj adv # of synsets 16,079 4,529 6,655 964 # of entries 30,933 6,495 14,151 2,025 average set size 2.56 2.79 2.72 2.51 max set size 25 16 21 8 Table 1: Statistics of synsets used in our stegosystem For the contextual check we use the Google Web 1T 5-gram Corpus (Brants and Franz, 2006) which contains counts for n-grams from unigrams through to five-grams obtained from over 1 trillion word tokens of English Web text. The corpus has been used for many tasks such as spelling correction (Islam and Inkpen, 2009; Carlson et al., 2008) and multi-word expression classification (Kummerfeld and Curran, 2008). Moreover, for the SemEval-2007 English Lexical Substitution Task, which is similar to our substitution task, six out of ten participating teams utilised the Web 1T corpus. 3.2 Synonym Checking Method In order to measure the degree of acceptability in a substitution, the proposed filter calculates a substitution score for a synonym by using the observed frequency counts in the Web n-gram corpus. The method first extracts contextual n-grams around the synonym and queries the n-gram frequency counts from the corpus. For each n, the total count fn is calculated by summing up individual n-gram fr</context>
</contexts>
<marker>Kummerfeld, Curran, 2008</marker>
<rawString>Jonathan K Kummerfeld and James R Curran. 2008. Classification of verb particle constructions with the Google Web 1T Corpus. In Proceedings of the Australasian Language Technology Association Workshop 2008, pages 55–63, Hobart, Australia, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuling Liu</author>
<author>Xingming Sun</author>
<author>Yong Wu</author>
</authors>
<title>A natural language watermarking based on Chinese syntax.</title>
<date>2005</date>
<booktitle>In Advances in Natural Computation,</booktitle>
<volume>3612</volume>
<pages>958--961</pages>
<location>Changsha, China.</location>
<contexts>
<context position="3809" citStr="Liu et al., 2005" startWordPosition="588" endWordPosition="591"> therefore raising the suspicion of an observer. A linguistic transformation is required to embed information. Transformations studied in previous work include lexical substitution (Chapman and Davida, 1997; Bolshakov, 2004; Taskiran et al., 2006; Topkara et al., 2006b), phrase paraphrasing (Chang and Clark, 2010), sentence structure manipulations (Atallah et al., 2001a; Atallah et al., 2001b; 1194 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1194–1203, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics Liu et al., 2005; Meral et al., 2007; Murphy, 2001; Murphy and Vogel, 2007; Topkara et al., 2006a) and semantic transformations (Atallah et al., 2002; Vybornova and Macq, 2007). Many of these transformations require some sophisticated NLP tools; for example, in order to perform semantic transformations on text, word sense disambiguation, semantic role parsing and anaphora resolution tools may be required. However, the current state-of-the-art in language technology is arguably not good enough for secure linguistic steganography based on sophisticated semantic transformations, and the level of robustness requi</context>
</contexts>
<marker>Liu, Sun, Wu, 2005</marker>
<rawString>Yuling Liu, Xingming Sun, and Yong Wu. 2005. A natural language watermarking based on Chinese syntax. In Advances in Natural Computation, volume 3612, pages 958–961, Changsha, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Roberto Navigli</author>
</authors>
<title>Semeval2007 task 10: English lexical substitution task.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>48--53</pages>
<location>Prague, Czech Republic.</location>
<marker>McCarthy, Navigli, 2007</marker>
<rawString>Diana McCarthy and Roberto Navigli. 2007. Semeval2007 task 10: English lexical substitution task. In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 48–53, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hasan M Meral</author>
<author>Emre Sevinc</author>
<author>Ersin Unkar</author>
<author>Bulent Sankur</author>
<author>A Sumru Ozsoy</author>
<author>Tunga Gungor</author>
</authors>
<title>Syntactic tools for text watermarking.</title>
<date>2007</date>
<booktitle>In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,</booktitle>
<volume>volume</volume>
<pages>6505</pages>
<location>San Jose, CA.</location>
<contexts>
<context position="3829" citStr="Meral et al., 2007" startWordPosition="592" endWordPosition="595"> the suspicion of an observer. A linguistic transformation is required to embed information. Transformations studied in previous work include lexical substitution (Chapman and Davida, 1997; Bolshakov, 2004; Taskiran et al., 2006; Topkara et al., 2006b), phrase paraphrasing (Chang and Clark, 2010), sentence structure manipulations (Atallah et al., 2001a; Atallah et al., 2001b; 1194 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1194–1203, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics Liu et al., 2005; Meral et al., 2007; Murphy, 2001; Murphy and Vogel, 2007; Topkara et al., 2006a) and semantic transformations (Atallah et al., 2002; Vybornova and Macq, 2007). Many of these transformations require some sophisticated NLP tools; for example, in order to perform semantic transformations on text, word sense disambiguation, semantic role parsing and anaphora resolution tools may be required. However, the current state-of-the-art in language technology is arguably not good enough for secure linguistic steganography based on sophisticated semantic transformations, and the level of robustness required to perform pract</context>
</contexts>
<marker>Meral, Sevinc, Unkar, Sankur, Ozsoy, Gungor, 2007</marker>
<rawString>Hasan M. Meral, Emre Sevinc, Ersin Unkar, Bulent Sankur, A. Sumru Ozsoy, and Tunga Gungor. 2007. Syntactic tools for text watermarking. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 6505, San Jose, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Murphy</author>
<author>Carl Vogel</author>
</authors>
<title>The syntax of concealment: reliable methods for plain text information hiding.</title>
<date>2007</date>
<booktitle>In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,</booktitle>
<volume>volume</volume>
<pages>6505</pages>
<location>San Jose, CA.</location>
<contexts>
<context position="3867" citStr="Murphy and Vogel, 2007" startWordPosition="598" endWordPosition="601">inguistic transformation is required to embed information. Transformations studied in previous work include lexical substitution (Chapman and Davida, 1997; Bolshakov, 2004; Taskiran et al., 2006; Topkara et al., 2006b), phrase paraphrasing (Chang and Clark, 2010), sentence structure manipulations (Atallah et al., 2001a; Atallah et al., 2001b; 1194 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1194–1203, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics Liu et al., 2005; Meral et al., 2007; Murphy, 2001; Murphy and Vogel, 2007; Topkara et al., 2006a) and semantic transformations (Atallah et al., 2002; Vybornova and Macq, 2007). Many of these transformations require some sophisticated NLP tools; for example, in order to perform semantic transformations on text, word sense disambiguation, semantic role parsing and anaphora resolution tools may be required. However, the current state-of-the-art in language technology is arguably not good enough for secure linguistic steganography based on sophisticated semantic transformations, and the level of robustness required to perform practical experiments has only just become </context>
</contexts>
<marker>Murphy, Vogel, 2007</marker>
<rawString>Brian Murphy and Carl Vogel. 2007. The syntax of concealment: reliable methods for plain text information hiding. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 6505, San Jose, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Murphy</author>
</authors>
<title>Syntactic information hiding in plain text. Master’s thesis,</title>
<date>2001</date>
<location>Trinity College Dublin.</location>
<contexts>
<context position="3843" citStr="Murphy, 2001" startWordPosition="596" endWordPosition="597"> observer. A linguistic transformation is required to embed information. Transformations studied in previous work include lexical substitution (Chapman and Davida, 1997; Bolshakov, 2004; Taskiran et al., 2006; Topkara et al., 2006b), phrase paraphrasing (Chang and Clark, 2010), sentence structure manipulations (Atallah et al., 2001a; Atallah et al., 2001b; 1194 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1194–1203, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics Liu et al., 2005; Meral et al., 2007; Murphy, 2001; Murphy and Vogel, 2007; Topkara et al., 2006a) and semantic transformations (Atallah et al., 2002; Vybornova and Macq, 2007). Many of these transformations require some sophisticated NLP tools; for example, in order to perform semantic transformations on text, word sense disambiguation, semantic role parsing and anaphora resolution tools may be required. However, the current state-of-the-art in language technology is arguably not good enough for secure linguistic steganography based on sophisticated semantic transformations, and the level of robustness required to perform practical experimen</context>
</contexts>
<marker>Murphy, 2001</marker>
<rawString>Brian Murphy. 2001. Syntactic information hiding in plain text. Master’s thesis, Trinity College Dublin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cuneyt M Taskiran</author>
<author>Mercan Topkara</author>
<author>Edward J Delp</author>
</authors>
<title>Attacks on linguistic steganography systems using text analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,</booktitle>
<volume>6072</volume>
<pages>97--105</pages>
<location>San Jose, CA.</location>
<contexts>
<context position="3439" citStr="Taskiran et al., 2006" startWordPosition="536" endWordPosition="539">rceptibility. In addition, since steganography aims at covert communication, a linguistic stegosystem should allow sufficient embedding capacity, known as the payload. There is a fundamental tradeoff between imperceptibility and payload, since any attempt to embed more information via changes to the cover text increases the chance of introducing anomalies into the text and therefore raising the suspicion of an observer. A linguistic transformation is required to embed information. Transformations studied in previous work include lexical substitution (Chapman and Davida, 1997; Bolshakov, 2004; Taskiran et al., 2006; Topkara et al., 2006b), phrase paraphrasing (Chang and Clark, 2010), sentence structure manipulations (Atallah et al., 2001a; Atallah et al., 2001b; 1194 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1194–1203, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics Liu et al., 2005; Meral et al., 2007; Murphy, 2001; Murphy and Vogel, 2007; Topkara et al., 2006a) and semantic transformations (Atallah et al., 2002; Vybornova and Macq, 2007). Many of these transformations require some sophisticated NLP tools; </context>
</contexts>
<marker>Taskiran, Topkara, Delp, 2006</marker>
<rawString>Cuneyt M. Taskiran, Mercan Topkara, and Edward J. Delp. 2006. Attacks on linguistic steganography systems using text analysis. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 6072, pages 97–105, San Jose, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mercan Topkara</author>
<author>Umut Topkara</author>
<author>Mikhail J Atallah</author>
</authors>
<title>Words are not enough: sentence level natural language watermarking.</title>
<date>2006</date>
<booktitle>In Proceedings of the ACM Workshop on Content Protection and Security,</booktitle>
<pages>37--46</pages>
<location>Santa Barbara, CA.</location>
<contexts>
<context position="3461" citStr="Topkara et al., 2006" startWordPosition="540" endWordPosition="543">on, since steganography aims at covert communication, a linguistic stegosystem should allow sufficient embedding capacity, known as the payload. There is a fundamental tradeoff between imperceptibility and payload, since any attempt to embed more information via changes to the cover text increases the chance of introducing anomalies into the text and therefore raising the suspicion of an observer. A linguistic transformation is required to embed information. Transformations studied in previous work include lexical substitution (Chapman and Davida, 1997; Bolshakov, 2004; Taskiran et al., 2006; Topkara et al., 2006b), phrase paraphrasing (Chang and Clark, 2010), sentence structure manipulations (Atallah et al., 2001a; Atallah et al., 2001b; 1194 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1194–1203, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics Liu et al., 2005; Meral et al., 2007; Murphy, 2001; Murphy and Vogel, 2007; Topkara et al., 2006a) and semantic transformations (Atallah et al., 2002; Vybornova and Macq, 2007). Many of these transformations require some sophisticated NLP tools; for example, in order </context>
</contexts>
<marker>Topkara, Topkara, Atallah, 2006</marker>
<rawString>Mercan Topkara, Umut Topkara, and Mikhail J. Atallah. 2006a. Words are not enough: sentence level natural language watermarking. In Proceedings of the ACM Workshop on Content Protection and Security, pages 37–46, Santa Barbara, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Umut Topkara</author>
<author>Mercan Topkara</author>
<author>Mikhail J Atallah</author>
</authors>
<title>The hiding virtues of ambiguity: quantifiably resilient watermarking of natural language text through synonym substitutions.</title>
<date>2006</date>
<booktitle>In Proceedings of the 8th Workshop on Multimedia and Security,</booktitle>
<pages>164--174</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="3461" citStr="Topkara et al., 2006" startWordPosition="540" endWordPosition="543">on, since steganography aims at covert communication, a linguistic stegosystem should allow sufficient embedding capacity, known as the payload. There is a fundamental tradeoff between imperceptibility and payload, since any attempt to embed more information via changes to the cover text increases the chance of introducing anomalies into the text and therefore raising the suspicion of an observer. A linguistic transformation is required to embed information. Transformations studied in previous work include lexical substitution (Chapman and Davida, 1997; Bolshakov, 2004; Taskiran et al., 2006; Topkara et al., 2006b), phrase paraphrasing (Chang and Clark, 2010), sentence structure manipulations (Atallah et al., 2001a; Atallah et al., 2001b; 1194 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1194–1203, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics Liu et al., 2005; Meral et al., 2007; Murphy, 2001; Murphy and Vogel, 2007; Topkara et al., 2006a) and semantic transformations (Atallah et al., 2002; Vybornova and Macq, 2007). Many of these transformations require some sophisticated NLP tools; for example, in order </context>
</contexts>
<marker>Topkara, Topkara, Atallah, 2006</marker>
<rawString>Umut Topkara, Mercan Topkara, and Mikhail J. Atallah. 2006b. The hiding virtues of ambiguity: quantifiably resilient watermarking of natural language text through synonym substitutions. In Proceedings of the 8th Workshop on Multimedia and Security, pages 164– 174, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Olga Vybornova</author>
<author>Benoit Macq</author>
</authors>
<title>A method of text watermarking using presuppositions.</title>
<date>2007</date>
<booktitle>In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents,</booktitle>
<volume>volume</volume>
<pages>6505</pages>
<location>San Jose, CA.</location>
<contexts>
<context position="3969" citStr="Vybornova and Macq, 2007" startWordPosition="613" endWordPosition="617"> include lexical substitution (Chapman and Davida, 1997; Bolshakov, 2004; Taskiran et al., 2006; Topkara et al., 2006b), phrase paraphrasing (Chang and Clark, 2010), sentence structure manipulations (Atallah et al., 2001a; Atallah et al., 2001b; 1194 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1194–1203, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics Liu et al., 2005; Meral et al., 2007; Murphy, 2001; Murphy and Vogel, 2007; Topkara et al., 2006a) and semantic transformations (Atallah et al., 2002; Vybornova and Macq, 2007). Many of these transformations require some sophisticated NLP tools; for example, in order to perform semantic transformations on text, word sense disambiguation, semantic role parsing and anaphora resolution tools may be required. However, the current state-of-the-art in language technology is arguably not good enough for secure linguistic steganography based on sophisticated semantic transformations, and the level of robustness required to perform practical experiments has only just become available. Hence many existing linguistic stegosystems are proof-of-concept implementations with littl</context>
</contexts>
<marker>Vybornova, Macq, 2007</marker>
<rawString>M. Olga Vybornova and Benoit Macq. 2007. A method of text watermarking using presuppositions. In Proceedings of the SPIE Conference on Security, Steganography, and Watermarking of Multimedia Contents, volume 6505, San Jose, CA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>