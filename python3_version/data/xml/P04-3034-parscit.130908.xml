<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005405">
<title confidence="0.978254">
Fragments and Text Categorization
</title>
<author confidence="0.972242">
Jan Blaˇtik and Eva Mrikoviand Luboˇs Popelinsk´y
</author>
<affiliation confidence="0.9698125">
Knowledge Discovery Lab
Faculty of Informatics, Masaryk University
</affiliation>
<address confidence="0.936776">
602 00 Brno,
Czech Republic
</address>
<email confidence="0.982679">
xblatak, glum, popel @fi.muni.cz
</email>
<sectionHeader confidence="0.997126" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999764">
We introduce two novel methods of text categoriza-
tion in which documents are split into fragments.
We conducted experiments on English, French and
Czech. In all cases, the problems referred to a bi-
nary document classification. We find that both
methods increase the accuracy of text categoriza-
tion. For the Naive Bayes classifier this increase is
significant.
</bodyText>
<sectionHeader confidence="0.991464" genericHeader="keywords">
1 Motivation
</sectionHeader>
<bodyText confidence="0.99998">
In the process of automatic classifying documents
into several predefined classes – text categorization
(Sebastiani, 2002) – text documents are usually seen
as sets or bags of all the words that have appeared
in a document, maybe after removing words in a
stop-list. In this paper we describe a novel approach
to text categorization in which each documents is
first split into subparts, called fragments. Each
fragment is consequently seen as a new document
which shares the same label with its source docu-
ment. We introduce two variants of this approach
– skip-tail and fragments. Both of these
methods are briefly described below. We demon-
strate the increased accuracy that we observed.
</bodyText>
<subsectionHeader confidence="0.998984">
1.1 Skipping the tail of a document
</subsectionHeader>
<bodyText confidence="0.997976909090909">
The first method uses only the first sentences
of a document and is henceforth referred to as
skip-tail. The idea behind this approach is that
the beginning of each document contains enough
information for the classification. In the process
of learning, each document is first replaced by its
initial part. The learning algorithm then uses only
these initial fragments as learning (test) examples.
We also sought the minimum length of initial frag-
ments that preserve the accuracy of the classifica-
tion.
</bodyText>
<subsectionHeader confidence="0.996908">
1.2 Splitting a document into fragments
</subsectionHeader>
<bodyText confidence="0.999694">
The second method splits the documents into frag-
ments which are classified independently of each
others. This method is henceforth referred to as
fragments. Initially, the classifier is used to gen-
erate a model from these fragments. Subsequently,
the model is utilized to classify unseen documents
(test set) which have also been split into fragments.
</bodyText>
<sectionHeader confidence="0.9957" genericHeader="introduction">
2 Data
</sectionHeader>
<bodyText confidence="0.976192142857143">
We conducted experiments using English, French
and Czech documents. In all cases, the problems
referred to a binary document classification. The
main characteristics of the data are in Table 1. Three
kinds of English documents were used:
20 Newsgroups1 (202 randomly chosen documents
from each class were used. The mail header was re-
moved so that the text contained only the body of
the message and in some cases, replies)
Reuters-21578, Distribution 1.02 (only documents
from money-fx, money-supply, trade clas-
sified into a single class were chosen). All
documents marked as BRIEF and UNPROC
were removed. The classification tasks in-
volved money-fx+money-supply vs. trade,
money-fx vs. money-supply, money-fx
vs. trade and money-supply vs. trade.
MEDLINE data3 (235 abstracts of medical papers
that concerned gynecology and assisted reproduc-
tion)
n docs ave sdev
</bodyText>
<table confidence="0.9720772">
20 Newsgroups 138 4040 15.79 5.99
Reuters-21578 4 1022 11.03 2.02
Medline 1 235 12.54 0.22
French cooking 36 1370 9.41 1.24
Czech newspaper 15 2545 22.04 4.22
</table>
<tableCaption confidence="0.994271">
Table 1: Data (n=number of classification tasks,
</tableCaption>
<bodyText confidence="0.627434">
docs=number of documents, ave =average number
of sentences per document, sdev =standard devia-
tion)
</bodyText>
<footnote confidence="0.99977225">
1http://www.ai.mit.edu/-jrennie/
20Newsgroups/
2http://www.research.att.com/-lewis
3http://www.fi.muni.cz/-zizka/medocs
</footnote>
<bodyText confidence="0.999933090909091">
The French documents contained French recipes.
Examples of the classification tasks are Accom-
pagnements vs. Cremes, Cremes vs. Pates-Pains-
Crepes, Desserts vs. Douceurs, Entrees vs. Plats-
Chauds and Pates-Pains-Crepes vs. Sauces, among
others.
We also used both methods for classifying Czech
documents. The data involved fifteen classification
tasks. The articles used had been taken from Czech
newspapers. Six tasks concerned authorship recog-
nition, the other seven to find a document source –
either a newspaper or a particular page (or column).
Topic recognition was the goal of two tasks.
The structure of the rest of this paper is as fol-
lows. The method for computing the classification
of the whole document from classifying fragments
(fragments method) is described in Section 3.
Experimental settings are introduced in Section 4.
Section 5 presents the main results. We conclude
with an overview of related works and with direc-
tions for potential future research in Sections 6 and
7.
</bodyText>
<sectionHeader confidence="0.765975" genericHeader="method">
3 Classification by means of
fragments of documents
</sectionHeader>
<bodyText confidence="0.998338230769231">
The class of the whole document is determined as
follows. Let us take a document which consists
of fragments , ... , such that and
. The value of depends
on the length of the document and on the number
of sentences in the fragments. Let ,
and denotes the set of possible classes. We than
use the learned model to assign a class to
each of the fragments . Let be the
confidence of the classification fragment into the
class . This confidence measure is computed as
an estimated probability of the predicted class. Then
for each fragment classified to the class
we define . The confi-
dence of the classification of the whole document
into is computed as follows
Finally, the class which is assigned to a docu-
ment is computed according to the following def-
inition:
In other words, a document is classified to a
, which was assigned to the most fragments
from (the most frequent class). If there are two
classes with the same cardinality, the confidence
measure is employed. We also tested an-
other method that exploited the confidence of clas-
sification but the results were not satisfactory.
</bodyText>
<sectionHeader confidence="0.999788" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999761842105263">
For feature (i.e. significant word) selection, we
tested four methods (Forman, 2002; Yang and Liu,
1999) – Chi-Squared (chi), Information Gain (ig),
F-measure (f1) and Probability Ratio (pr). Even-
tually, we chose ig because it yielded the best re-
sults. We utilized three learning algorithms from the
Weka4 system – the decision tree learner J48, the
Naive Bayes, the SVM Sequential Minimal Opti-
mization (SMO). All the algorithms were used with
default settings. The entire documents have been
split to fragments containing 1, 2, 3, 4, 5, 6, 7, 8,
9, 10, 11, 12, 13, 14, 15, 20, 25, 30, and 40 sen-
tences. For the skip-tail classification which
uses only the beginnings of documents we also em-
ployed these values.
As an evaluation criterion we used the accuracy
defined as the percentage of correctly classified doc-
uments from the test set. All the results have been
obtained by a 10-fold cross validation.
</bodyText>
<sectionHeader confidence="0.999968" genericHeader="evaluation">
5 Results
</sectionHeader>
<subsectionHeader confidence="0.753527">
5.1 General
</subsectionHeader>
<bodyText confidence="0.949868363636364">
We observed that for both skip-tail and
fragments there is always a consistent size of
fragments for which the accuracy increased. It is the
most important result. More details can be found in
the next two paragraphs.
Among the learning algorithms, the highest accu-
racy was achieved for all the three languages with
the Naive Bayes. It is surprising because for full
versions of documents it was the SMO algorithm
that was even slightly better than the Naive Bayes
in terms of accuracy. On the other hand, the highest
impact was observed for J48. Thus, for instance for
Czech, it was observed for fragments that the ac-
curacy was higher for 14 out of 15 tasks when J48
had been used, and for 12 out of 15 in the case of
the Naive Bayes and the Support Vector Machines.
However, the performance of J48 was far inferior to
that of the other algorithms. In only three tasks J48
for and
.
4http://www.cs.waikato.ac.nz/ml/weka
resulted in a higher accuracy than the Naive Bayes 92.5 skip-tail(fr)
and the Support Vector Machines. The similar situ- 92 full(fr)
ation appeared for English and French. 91.5 skip-tail(eng)
5.2 skip-tail 91 full(eng)
skip-tail method was successful for all the
three languages (see Table 2). It results in increased
accuracy even for a very small initial fragment. In
Figure 1 there are results for skip-tail and ini-
tial fragments of the length from 40% up to 100%
of the average length of documents in the learning
set.
accuracy.
</bodyText>
<table confidence="0.892368666666667">
40 50 60 70 80 90 100
lentgh of the fragment
n NB stail lngth incr
English 143 90.96 92.04 1.3 ++105
French 36 92.04 92.56 0.9 + 25
Czech 15 79.51 81.13 0.9 + 12
</table>
<tableCaption confidence="0.943779">
Table 2: Results for skip-tail and the
</tableCaption>
<bodyText confidence="0.990672684210526">
Naive Bayes (n=number of classification tasks,
NB=average of error rates for full documents,
stail=average of error rates for skip-tail,
lngth=optimal length of the fragment, incr=number
of tasks with the increase of accuracy: +, ++ means
significant on level 95% resp 99%, the sign test.)
For example, for English, taking only the first
40% of sentences in a document results in a slightly
increased accuracy. Figure 2 displays the relative
increase of accuracy for fragments of the length up
to 40 sentences for different learning algorithms for
English. It is important to stress that even for the
initial fragment of the length of 5 sentences, the ac-
curacy is the same as for full documents. When the
initial fragment is longer the classification accuracy
further increase until the length of 12 sentences.
We observed similar behaviour for skip-tail
when employed on other languages, and also for the
fragments method.
</bodyText>
<subsectionHeader confidence="0.982822">
5.3 fragments
</subsectionHeader>
<bodyText confidence="0.999665333333333">
This method was successful for classifying English
and Czech documents (significant on level 99% for
English and 95% for Czech). In the case of French
cooking recipes, a small, but not significant impact
has been observed, too. This may have been caused
by the special format of recipes.
</bodyText>
<table confidence="0.96585425">
n NB frag lngth incr
English 143 91.12 93.21 1.1 ++ 96
French 36 92.04 92.27 1.0 19
Czech 15 82.36 84.07 1.0 + 12
</table>
<tableCaption confidence="0.9328555">
Table 3: Results for fragments (for the descrip-
tion see Table 2)
</tableCaption>
<figureCaption confidence="0.767268666666667">
Figure 1: skip-tail, Naive Bayes. (lentgh of
the fragment = percentage of the average document
length)
</figureCaption>
<figure confidence="0.937999">
0 5 10 15 20 25 30 35 40
no. of senteces
</figure>
<figureCaption confidence="0.816881">
Figure 2: Relative increase of accuracy: English,
skip-tail
</figureCaption>
<subsectionHeader confidence="0.993166">
5.4 Optimal length of fragments
</subsectionHeader>
<bodyText confidence="0.999991636363636">
We also looked for the optimal length of fragments.
We found that for the lengths of fragments for the
range about the average document length (in the
learning set), the accuracy increased for the signifi-
cant number of the data sets (the sign test 95%). It
holds for skip-tail and for all languages. and
for English and Czech in the case of fragments.
However, an increase of accuracy is observed even
for 60% of the average length (see Fig. 1). More-
over, for the average length this increase is signifi-
cant for Czech at a level 95% (t-test).
</bodyText>
<sectionHeader confidence="0.993568" genericHeader="discussions">
6 Discussion and related work
</sectionHeader>
<bodyText confidence="0.99942275">
Two possible reasons may result in an accuracy in-
crease for skip-tail. As a rule, the beginning
of a document contains the most relevant informa-
tion. The concluding part, on the other hand, of-
ten includes the author’s interpretation and cross-
reference to other documents which can cause con-
fusion. However, these statements are yet to be ver-
ified.
</bodyText>
<figure confidence="0.991324538461539">
accuracy.
-10
-15
-20
-25
-30
-35
-5
5
0
NaiveBayes-bm
SMO-bm
J48-bm
</figure>
<bodyText confidence="0.999210708333333">
Additional information, namely lexical or syntac-
tic, may result in even higher accuracy of classifica-
tion. We performed several experiments for Czech.
We observed that adding noun, verb and preposi-
tional phrases led to a small increase in the accuracy
but that increase was not significant.
Other kinds of fragments should be checked,
for instance intersecting fragments or sliding frag-
ments. So far we have ignored the structure of the
documents (titles, splitting into paragraphs) and fo-
cused only on plain text. In the next stage, we will
apply these methods to classifying HTML and XML
documents.
Larkey (Larkey, 1999) employed a method sim-
ilar to skip-tail for classifying patent docu-
ments. He exploited the structure of documents –
the title, the abstract, and the first twenty lines of
the summary – assigning different weights to each
part. We showed that this approach can be used
even for non-structured texts like newspaper arti-
cles. Tombros et al. (Tombros et al., 2003) com-
bined text summarization when clustering so called
top-ranking sentences (TRS). It will be interesting
to check how fragments are related to the TRS.
</bodyText>
<sectionHeader confidence="0.999412" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9999845">
We have introduced two methods – skip-tail
and fragments – utilized for document catego-
rization which are based on splitting documents into
its subparts. We observed that both methods re-
sulted in significant increase of accuracy. We also
tested a method which exploited only the most con-
fident fragments. However, this did not result in any
accuracy increase. However, use of the most confi-
dent fragments for text summarization should also
be checked.
</bodyText>
<sectionHeader confidence="0.999" genericHeader="acknowledgments">
8 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999931">
We thank James Mayfield, James Thomas and Mar-
tin Dvoˇrik for their assistance. This work has been
partially supported by the Czech Ministry of Educa-
tion under the Grant No. 143300003.
</bodyText>
<sectionHeader confidence="0.999642" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99353276">
G. Forman. 2002. Choose your words carefully. In
T. Elomaa, H. Mannila, and H. Toivonen, editors,
Proceedings of the 6th Eur. Conf. on Principles
Data Mining and Knowledge Discovery (PKDD),
Helsinki, 2002, LNCS vol. 2431, pages 150–162.
Springer Verlag.
L. S. Larkey. 1999. A patent search and classifica-
tion system. In Proceedings of the fourth ACM
conference on Digital libraries, pages 179–187.
ACM Press.
F. Sebastiani. 2002. Machine learning in auto-
mated text categorization. ACM Comput. Surv.,
34(1):1–47.
A. Tombros, J. M. Jose, and I. Ruthven. 2003.
Clustering top-ranking sentences for information
access. In T. Koch and I. Sølvberg, editors,
Proceedings of the 7 European Conference on
Research and Advanced Technology for Digital
Libraries (ECDL), Trondheim 2003, LNCS vl.
2769, pages 523–528. Springer Verlag.
Y. Yang and X. Liu. 1999. A re-examination of
text categorization methods. In Proceedings of
the 22 annual international ACM SIGIR con-
ference on Research and development in informa-
tion retrieval, pages 42–49. ACM Press.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000476">
<title confidence="0.999654">Fragments and Text Categorization</title>
<author confidence="0.778621">Popelinsk´y</author>
<affiliation confidence="0.927697">Knowledge Discovery Lab Faculty of Informatics, Masaryk University</affiliation>
<address confidence="0.9886975">602 00 Brno, Czech Republic</address>
<email confidence="0.970054">xblatak,glum,popel@fi.muni.cz</email>
<abstract confidence="0.949886885017421">We introduce two novel methods of text categorization in which documents are split into fragments. We conducted experiments on English, French and Czech. In all cases, the problems referred to a binary document classification. We find that both methods increase the accuracy of text categorization. For the Naive Bayes classifier this increase is significant. 1 Motivation In the process of automatic classifying documents into several predefined classes – text categorization (Sebastiani, 2002) – text documents are usually seen as sets or bags of all the words that have appeared in a document, maybe after removing words in a stop-list. In this paper we describe a novel approach to text categorization in which each documents is split into subparts, called Each fragment is consequently seen as a new document which shares the same label with its source document. We introduce two variants of this approach Both of these methods are briefly described below. We demonstrate the increased accuracy that we observed. 1.1 Skipping the tail of a document The first method uses only the first sentences of a document and is henceforth referred to as The idea behind this approach is that the beginning of each document contains enough information for the classification. In the process of learning, each document is first replaced by its initial part. The learning algorithm then uses only these initial fragments as learning (test) examples. We also sought the minimum length of initial fragments that preserve the accuracy of the classification. 1.2 Splitting a document into fragments The second method splits the documents into fragments which are classified independently of each others. This method is henceforth referred to as Initially, the classifier is used to generate a model from these fragments. Subsequently, the model is utilized to classify unseen documents (test set) which have also been split into fragments. 2 Data We conducted experiments using English, French and Czech documents. In all cases, the problems referred to a binary document classification. The main characteristics of the data are in Table 1. Three kinds of English documents were used: (202 randomly chosen documents from each class were used. The mail header was removed so that the text contained only the body of the message and in some cases, replies) Distribution (only documents classified into a single class were chosen). All documents marked as BRIEF and UNPROC removed. The classification tasks (235 abstracts of medical papers that concerned gynecology and assisted reproduction) n docs ave sdev 20 Newsgroups 138 4040 15.79 5.99 Reuters-21578 4 1022 11.03 2.02 Medline 1 235 12.54 0.22 French cooking 36 1370 9.41 1.24 Czech newspaper 15 2545 22.04 4.22 Table 1: Data (n=number of classification tasks, docs=number of documents, ave =average number of sentences per document, sdev =standard deviation) 20Newsgroups/ French documents French recipes. Examples of the classification tasks are Accompagnements vs. Cremes, Cremes vs. Pates-Pains- Crepes, Desserts vs. Douceurs, Entrees vs. Plats- Chauds and Pates-Pains-Crepes vs. Sauces, among others. also used both methods for classifying The data involved fifteen classification tasks. The articles used had been taken from Czech newspapers. Six tasks concerned authorship recognition, the other seven to find a document source – either a newspaper or a particular page (or column). Topic recognition was the goal of two tasks. The structure of the rest of this paper is as follows. The method for computing the classification of the whole document from classifying fragments is described in Section 3. Experimental settings are introduced in Section 4. Section 5 presents the main results. We conclude with an overview of related works and with directions for potential future research in Sections 6 and 7. 3 Classification by means of fragments of documents The class of the whole document is determined as follows. Let us take a document which consists of fragments , ... , such that and . The value of depends on the length of the document and on the number of sentences in the fragments. Let , and denotes the set of possible classes. We than use the learned model to assign a class to each of the fragments . Let be the confidence of the classification fragment into the class . This confidence measure is computed as an estimated probability of the predicted class. Then for each fragment classified to the class define . The dence of the classification of the whole document into is computed as follows the class which is assigned to a document is computed according to the following definition: In other words, a document is classified to a , which was assigned to the most fragments from (the most frequent class). If there are two classes with the same cardinality, the confidence is employed. We also tested other method that exploited the confidence of classification but the results were not satisfactory. 4 Experiments For feature (i.e. significant word) selection, we tested four methods (Forman, 2002; Yang and Liu, – Chi-Squared Information Gain and Probability Ratio Evenwe chose it yielded the best results. We utilized three learning algorithms from the system – the decision tree learner J48, the Bayes, the SVM Minimal Opti- All the algorithms were used with default settings. The entire documents have been split to fragments containing 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 25, 30, and 40 sen- For the which uses only the beginnings of documents we also employed these values. As an evaluation criterion we used the accuracy defined as the percentage of correctly classified documents from the test set. All the results have been obtained by a 10-fold cross validation. 5 Results 5.1 General observed that for both is always a consistent size of fragments for which the accuracy increased. It is the most important result. More details can be found in the next two paragraphs. Among the learning algorithms, the highest accuracy was achieved for all the three languages with the Naive Bayes. It is surprising because for full versions of documents it was the SMO algorithm that was even slightly better than the Naive Bayes in terms of accuracy. On the other hand, the highest impact was observed for J48. Thus, for instance for it was observed for the accuracy was higher for 14 out of 15 tasks when J48 had been used, and for 12 out of 15 in the case of the Naive Bayes and the Support Vector Machines. However, the performance of J48 was far inferior to that of the other algorithms. In only three tasks J48 for and . resulted in a higher accuracy than the Naive Bayes and the Support Vector Machines. The similar situ-ation appeared for English and French. 92.5 skip-tail(fr) full(fr) skip-tail(eng) full(eng) 92 was successful for all the three languages (see Table 2). It results in increased accuracy even for a very small initial fragment. In 1 there are results for ini-tial fragments of the length from 40% up to 100% of the average length of documents in the learning set. 91.5 91 accuracy. 40 50 60 70 80 90 100 lentgh of the fragment n NB stail lngth incr English 143 90.96 92.04 1.3 French 36 92.04 92.56 0.9 Czech 15 79.51 81.13 0.9 2: Results for the Naive Bayes (n=number of classification tasks, NB=average of error rates for full documents, of error rates for lngth=optimal length of the fragment, incr=number tasks with the increase of accuracy: significant on level 95% resp 99%, the sign test.) For example, for English, taking only the first 40% of sentences in a document results in a slightly increased accuracy. Figure 2 displays the relative increase of accuracy for fragments of the length up to 40 sentences for different learning algorithms for English. It is important to stress that even for the initial fragment of the length of 5 sentences, the accuracy is the same as for full documents. When the initial fragment is longer the classification accuracy further increase until the length of 12 sentences. observed similar behaviour for when employed on other languages, and also for the This method was successful for classifying English and Czech documents (significant on level 99% for English and 95% for Czech). In the case of French cooking recipes, a small, but not significant impact has been observed, too. This may have been caused by the special format of recipes. n NB frag lngth incr English 143 91.12 93.21 1.1 French 36 92.04 92.27 1.0 19 Czech 15 82.36 84.07 1.0 3: Results for the description see Table 2) 1: Naive Bayes. (lentgh of the fragment = percentage of the average document length) 0 5 10 15 20 25 30 35 40 no. of senteces Figure 2: Relative increase of accuracy: English, skip-tail 5.4 Optimal length of fragments We also looked for the optimal length of fragments. We found that for the lengths of fragments for the range about the average document length (in the learning set), the accuracy increased for the significant number of the data sets (the sign test 95%). It for for all languages. and English and Czech in the case of However, an increase of accuracy is observed even for 60% of the average length (see Fig. 1). Moreover, for the average length this increase is significant for Czech at a level 95% (t-test). 6 Discussion and related work Two possible reasons may result in an accuracy infor As a rule, the beginning of a document contains the most relevant information. The concluding part, on the other hand, often includes the author’s interpretation and crossreference to other documents which can cause confusion. However, these statements are yet to be verified. accuracy. -10 -15 -20 -25 -30 -35 -5 5 0 NaiveBayes-bm SMO-bm J48-bm Additional information, namely lexical or syntactic, may result in even higher accuracy of classification. We performed several experiments for Czech. We observed that adding noun, verb and prepositional phrases led to a small increase in the accuracy but that increase was not significant. Other kinds of fragments should be checked, for instance intersecting fragments or sliding fragments. So far we have ignored the structure of the documents (titles, splitting into paragraphs) and focused only on plain text. In the next stage, we will apply these methods to classifying HTML and XML documents. Larkey (Larkey, 1999) employed a method simto classifying patent documents. He exploited the structure of documents – the title, the abstract, and the first twenty lines of the summary – assigning different weights to each part. We showed that this approach can be used even for non-structured texts like newspaper articles. Tombros et al. (Tombros et al., 2003) combined text summarization when clustering so called top-ranking sentences (TRS). It will be interesting to check how fragments are related to the TRS. 7 Conclusion have introduced two methods – utilized for document categorization which are based on splitting documents into its subparts. We observed that both methods resulted in significant increase of accuracy. We also tested a method which exploited only the most confident fragments. However, this did not result in any accuracy increase. However, use of the most confident fragments for text summarization should also be checked. 8 Acknowledgements We thank James Mayfield, James Thomas and Martin Dvoˇrik for their assistance. This work has been partially supported by the Czech Ministry of Education under the Grant No. 143300003.</abstract>
<note confidence="0.743723730769231">References G. Forman. 2002. Choose your words carefully. In T. Elomaa, H. Mannila, and H. Toivonen, editors, Proceedings of the 6th Eur. Conf. on Principles Data Mining and Knowledge Discovery (PKDD), 2431, pages 150–162. Springer Verlag. L. S. Larkey. 1999. A patent search and classificasystem. In of the fourth ACM on Digital pages 179–187. ACM Press. F. Sebastiani. 2002. Machine learning in autotext categorization. Comput. 34(1):1–47. A. Tombros, J. M. Jose, and I. Ruthven. 2003. Clustering top-ranking sentences for information access. In T. Koch and I. Sølvberg, editors, Proceedings of the 7 European Conference on Research and Advanced Technology for Digital (ECDL), Trondheim 2769, pages 523–528. Springer Verlag. Y. Yang and X. Liu. 1999. A re-examination of categorization methods. In of the 22 annual international ACM SIGIR conference on Research and development in informapages 42–49. ACM Press.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Forman</author>
</authors>
<title>Choose your words carefully. In</title>
<date>2002</date>
<booktitle>Proceedings of the 6th Eur. Conf. on Principles Data Mining and Knowledge Discovery (PKDD), Helsinki, 2002, LNCS</booktitle>
<volume>2431</volume>
<pages>150--162</pages>
<editor>T. Elomaa, H. Mannila, and H. Toivonen, editors,</editor>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="5738" citStr="Forman, 2002" startWordPosition="905" endWordPosition="906">The confidence of the classification of the whole document into is computed as follows Finally, the class which is assigned to a document is computed according to the following definition: In other words, a document is classified to a , which was assigned to the most fragments from (the most frequent class). If there are two classes with the same cardinality, the confidence measure is employed. We also tested another method that exploited the confidence of classification but the results were not satisfactory. 4 Experiments For feature (i.e. significant word) selection, we tested four methods (Forman, 2002; Yang and Liu, 1999) – Chi-Squared (chi), Information Gain (ig), F-measure (f1) and Probability Ratio (pr). Eventually, we chose ig because it yielded the best results. We utilized three learning algorithms from the Weka4 system – the decision tree learner J48, the Naive Bayes, the SVM Sequential Minimal Optimization (SMO). All the algorithms were used with default settings. The entire documents have been split to fragments containing 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 25, 30, and 40 sentences. For the skip-tail classification which uses only the beginnings of documents we</context>
</contexts>
<marker>Forman, 2002</marker>
<rawString>G. Forman. 2002. Choose your words carefully. In T. Elomaa, H. Mannila, and H. Toivonen, editors, Proceedings of the 6th Eur. Conf. on Principles Data Mining and Knowledge Discovery (PKDD), Helsinki, 2002, LNCS vol. 2431, pages 150–162. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L S Larkey</author>
</authors>
<title>A patent search and classification system.</title>
<date>1999</date>
<booktitle>In Proceedings of the fourth ACM conference on Digital libraries,</booktitle>
<pages>179--187</pages>
<publisher>ACM Press.</publisher>
<contexts>
<context position="11490" citStr="Larkey, 1999" startWordPosition="1894" endWordPosition="1895">l information, namely lexical or syntactic, may result in even higher accuracy of classification. We performed several experiments for Czech. We observed that adding noun, verb and prepositional phrases led to a small increase in the accuracy but that increase was not significant. Other kinds of fragments should be checked, for instance intersecting fragments or sliding fragments. So far we have ignored the structure of the documents (titles, splitting into paragraphs) and focused only on plain text. In the next stage, we will apply these methods to classifying HTML and XML documents. Larkey (Larkey, 1999) employed a method similar to skip-tail for classifying patent documents. He exploited the structure of documents – the title, the abstract, and the first twenty lines of the summary – assigning different weights to each part. We showed that this approach can be used even for non-structured texts like newspaper articles. Tombros et al. (Tombros et al., 2003) combined text summarization when clustering so called top-ranking sentences (TRS). It will be interesting to check how fragments are related to the TRS. 7 Conclusion We have introduced two methods – skip-tail and fragments – utilized for d</context>
</contexts>
<marker>Larkey, 1999</marker>
<rawString>L. S. Larkey. 1999. A patent search and classification system. In Proceedings of the fourth ACM conference on Digital libraries, pages 179–187. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sebastiani</author>
</authors>
<title>Machine learning in automated text categorization.</title>
<date>2002</date>
<journal>ACM Comput. Surv.,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="716" citStr="Sebastiani, 2002" startWordPosition="102" endWordPosition="103">very Lab Faculty of Informatics, Masaryk University 602 00 Brno, Czech Republic xblatak, glum, popel @fi.muni.cz Abstract We introduce two novel methods of text categorization in which documents are split into fragments. We conducted experiments on English, French and Czech. In all cases, the problems referred to a binary document classification. We find that both methods increase the accuracy of text categorization. For the Naive Bayes classifier this increase is significant. 1 Motivation In the process of automatic classifying documents into several predefined classes – text categorization (Sebastiani, 2002) – text documents are usually seen as sets or bags of all the words that have appeared in a document, maybe after removing words in a stop-list. In this paper we describe a novel approach to text categorization in which each documents is first split into subparts, called fragments. Each fragment is consequently seen as a new document which shares the same label with its source document. We introduce two variants of this approach – skip-tail and fragments. Both of these methods are briefly described below. We demonstrate the increased accuracy that we observed. 1.1 Skipping the tail of a docume</context>
</contexts>
<marker>Sebastiani, 2002</marker>
<rawString>F. Sebastiani. 2002. Machine learning in automated text categorization. ACM Comput. Surv., 34(1):1–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Tombros</author>
<author>J M Jose</author>
<author>I Ruthven</author>
</authors>
<title>Clustering top-ranking sentences for information access.</title>
<date>2003</date>
<booktitle>Proceedings of the 7 European Conference on Research and Advanced Technology for Digital Libraries (ECDL), Trondheim 2003, LNCS vl.</booktitle>
<pages>2769--523</pages>
<editor>In T. Koch and I. Sølvberg, editors,</editor>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="11850" citStr="Tombros et al., 2003" startWordPosition="1953" endWordPosition="1956">fragments or sliding fragments. So far we have ignored the structure of the documents (titles, splitting into paragraphs) and focused only on plain text. In the next stage, we will apply these methods to classifying HTML and XML documents. Larkey (Larkey, 1999) employed a method similar to skip-tail for classifying patent documents. He exploited the structure of documents – the title, the abstract, and the first twenty lines of the summary – assigning different weights to each part. We showed that this approach can be used even for non-structured texts like newspaper articles. Tombros et al. (Tombros et al., 2003) combined text summarization when clustering so called top-ranking sentences (TRS). It will be interesting to check how fragments are related to the TRS. 7 Conclusion We have introduced two methods – skip-tail and fragments – utilized for document categorization which are based on splitting documents into its subparts. We observed that both methods resulted in significant increase of accuracy. We also tested a method which exploited only the most confident fragments. However, this did not result in any accuracy increase. However, use of the most confident fragments for text summarization shoul</context>
</contexts>
<marker>Tombros, Jose, Ruthven, 2003</marker>
<rawString>A. Tombros, J. M. Jose, and I. Ruthven. 2003. Clustering top-ranking sentences for information access. In T. Koch and I. Sølvberg, editors, Proceedings of the 7 European Conference on Research and Advanced Technology for Digital Libraries (ECDL), Trondheim 2003, LNCS vl. 2769, pages 523–528. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Yang</author>
<author>X Liu</author>
</authors>
<title>A re-examination of text categorization methods.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22 annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>42--49</pages>
<publisher>ACM Press.</publisher>
<contexts>
<context position="5759" citStr="Yang and Liu, 1999" startWordPosition="907" endWordPosition="910"> of the classification of the whole document into is computed as follows Finally, the class which is assigned to a document is computed according to the following definition: In other words, a document is classified to a , which was assigned to the most fragments from (the most frequent class). If there are two classes with the same cardinality, the confidence measure is employed. We also tested another method that exploited the confidence of classification but the results were not satisfactory. 4 Experiments For feature (i.e. significant word) selection, we tested four methods (Forman, 2002; Yang and Liu, 1999) – Chi-Squared (chi), Information Gain (ig), F-measure (f1) and Probability Ratio (pr). Eventually, we chose ig because it yielded the best results. We utilized three learning algorithms from the Weka4 system – the decision tree learner J48, the Naive Bayes, the SVM Sequential Minimal Optimization (SMO). All the algorithms were used with default settings. The entire documents have been split to fragments containing 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 25, 30, and 40 sentences. For the skip-tail classification which uses only the beginnings of documents we also employed these </context>
</contexts>
<marker>Yang, Liu, 1999</marker>
<rawString>Y. Yang and X. Liu. 1999. A re-examination of text categorization methods. In Proceedings of the 22 annual international ACM SIGIR conference on Research and development in information retrieval, pages 42–49. ACM Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>