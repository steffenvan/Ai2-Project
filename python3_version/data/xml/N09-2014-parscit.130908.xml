<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.060339">
<title confidence="0.9980605">
Towards Natural Language Understanding of Partial Speech Recognition
Results in Dialogue Systems
</title>
<author confidence="0.958519">
Kenji Sagae and Gwen Christian and David DeVault and David R. Traum
</author>
<affiliation confidence="0.868807">
Institute for Creative Technologies, University of Southern California
13274 Fiji Way, Marina del Rey, CA 90292
</affiliation>
<email confidence="0.999482">
{sagae,gchristian,devault,traum}@ict.usc.edu
</email>
<sectionHeader confidence="0.997398" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99966375">
We investigate natural language understand-
ing of partial speech recognition results to
equip a dialogue system with incremental lan-
guage processing capabilities for more realis-
tic human-computer conversations. We show
that relatively high accuracy can be achieved
in understanding of spontaneous utterances
before utterances are completed.
</bodyText>
<sectionHeader confidence="0.999392" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999949208333334">
Most spoken dialogue systems wait until the user
stops speaking before trying to understand and re-
act to what the user is saying. In particular, in a
typical dialogue system pipeline, it is only once the
user’s spoken utterance is complete that the results
of automatic speech recognition (ASR) are sent on
to natural language understanding (NLU) and dia-
logue management, which then triggers generation
and synthesis of the next system prompt. While
this style of interaction is adequate for some appli-
cations, it enforces a rigid pacing that can be un-
natural and inefficient for mixed-initiative dialogue.
To achieve more flexible turn-taking with human
users, for whom turn-taking and feedback at the sub-
utterance level is natural and common, the system
needs to engage in incremental processing, in which
interpretation components are activated, and in some
cases decisions are made, before the user utterance
is complete.
There is a growing body of work on incremen-
tal processing in dialogue systems. Some of this
work has demonstrated overall improvements in sys-
tem responsiveness and user satisfaction; e.g. (Aist
et al., 2007; Skantze and Schlangen, 2009). Several
</bodyText>
<page confidence="0.980784">
53
</page>
<bodyText confidence="0.999929642857143">
research groups, inspired by psycholinguistic mod-
els of human processing, have also been exploring
technical frameworks that allow diverse contextual
information to be brought to bear during incremen-
tal processing; e.g. (Kruijff et al., 2007; Aist et al.,
2007).
While this work often assumes or suggests it is
possible for systems to understand partial user ut-
terances, this premise has generally not been given
detailed quantitative study. The contribution of this
paper is to demonstrate and explore quantitatively
the extent to which one specific dialogue system can
anticipate what an utterance means, on the basis of
partial ASR results, before the utterance is complete.
</bodyText>
<sectionHeader confidence="0.988967" genericHeader="method">
2 NLU for spontaneous spoken utterances
</sectionHeader>
<subsectionHeader confidence="0.757626">
in a dialogue system
</subsectionHeader>
<bodyText confidence="0.99997125">
For this initial effort, we chose to look at incremental
processing of natural language understanding in the
SASO-EN system (Traum et al., 2008), a complex
spoken dialog system for which we have a corpus
of user data that includes recorded speech files that
have been transcribed and annotated with a semantic
representation. The domain of this system is a nego-
tiation scenario involving the location of a medical
clinic in a foreign country. The system is intended as
a negotiation training tool, where users learn about
negotiation tactics in the context of the culture and
social norms of a particular community.
</bodyText>
<subsectionHeader confidence="0.986778">
2.1 The natural language understanding task
</subsectionHeader>
<bodyText confidence="0.999972">
The NLU module must take the output of ASR as
input, and produce domain-specific semantic frames
as output. These frames are intended to capture
much of the meaning of the utterance, although a
</bodyText>
<subsubsectionHeader confidence="0.834454">
Proceedings of NAACL HLT 2009: Short Papers, pages 53–56,
</subsubsectionHeader>
<bodyText confidence="0.971848928571428">
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
dialogue manager further enriches the frame rep-
resentations with pragmatic information (Traum,
2003). NLU output frames are attribute-value ma-
trices, where the attributes and values are linked to a
domain-specific ontology and task model.
Complicating the NLU task of is the relatively
high word error rate (0.54) in ASR of user speech
input, given conversational speech in a complex do-
main and an untrained broad user population.
The following example, where the user attempts
to address complaints about lack of power in the pro-
posed location for the clinic, illustrates an utterance-
frame pair.
</bodyText>
<listItem confidence="0.9982686">
• Utterance (speech): we are prepared to give
you guys generators for electricity downtown
• ASR (NLU input): we up apparently give you
guys generators for a letter city don town
• Frame (NLU output):
</listItem>
<bodyText confidence="0.89215052">
&lt;s&gt;.mood declarative
&lt;s&gt;.sem.agent kirk
&lt;s&gt;.sem.event deliver
&lt;s&gt;.sem.modal.possibility can
&lt;s&gt;.sem.speechact.type offer
&lt;s&gt;.sem.theme power-generator
&lt;s&gt;.sem.type event
The original NLU component for this system was
described in (Leuski and Traum, 2008). For the pur-
poses of this experiment, we have developed a new
NLU module and tested on several different data
sets as described in the next section. Our approach
is to use maximum entropy models (Berger et al.,
1996) to learn a suitable mapping from features de-
rived from the words in the ASR output to semantic
frames. Given a set of examples of semantic frames
with corresponding ASR output, a classifier should
learn, for example, that when “generators” appears
in the output of ASR, the value power-generators is
likely to be present in the output frame. The specific
features used by the classifier are: each word in the
input string (bag-of-words representation of the in-
put), each bigram (consecutive words), each pair of
any two words in the input, and the number of words
in the input string.
</bodyText>
<figureCaption confidence="0.998356">
Figure 1: Length of utterances in the development set.
</figureCaption>
<subsectionHeader confidence="0.986183">
2.2 Data
</subsectionHeader>
<bodyText confidence="0.999965266666667">
Our corpus consists of 4,500 user utterances spread
across a number of different dialogue sessions. Ut-
terances that were out-of-domain (13.7% of the cor-
pus) were assigned a “garbage” frame, with no se-
mantic content. Approximately 10% of the utter-
ances were set aside for final testing, and another
10% was designated the development corpus for the
NLU module. The development and test sets were
chosen so that all the utterances in a session were
kept in the same set, but sessions were chosen at ran-
dom for inclusion in the development and test sets.
The training set contains 136 distinct frames,
each of which is composed of several attribute-value
pairs, called frame elements. Figure 1 shows the ut-
terance length distribution in the development set.
</bodyText>
<subsectionHeader confidence="0.957874">
2.3 NLU results on complete ASR output
</subsectionHeader>
<bodyText confidence="0.9999281875">
To evaluate NLU results, we look at precision, re-
call and f-score of frame elements. When the NLU
module is trained on complete ASR utterances in
the training set, and tested on complete ASR utter-
ances in the development set, f-score of frame ele-
ments is 0.76, with precision at 0.78 and recall at
0.74. To gain insight on what the upperbound on
the accuracy of the NLU module might be, we also
trained the classifier using features extracted from
gold-standard manual transcription (instead of ASR
output), and tested the accuracy of analyses of gold-
standard transcriptions (which would not be avail-
able at run-time in the dialogue system). Under
these ideal conditions, NLU f-score is 0.87. Training
on gold-standard transcriptions and testing on ASR
output produces results with a lower f-score, 0.74.
</bodyText>
<figure confidence="0.99685425">
60
50
40
30
20
10
0
1 2 3 4
</figure>
<page confidence="0.969622">
54
</page>
<sectionHeader confidence="0.964961" genericHeader="method">
3 NLU on partial ASR results
</sectionHeader>
<bodyText confidence="0.999971090909091">
Roughly half of the utterances in our training data
contain six words or more, and the average utter-
ance length is 5.9 words. Since the ASR module is
capable of sending partial results to the NLU mod-
ule even before the user has finished an utterance, in
principle the dialogue system can start understand-
ing and even responding to user input as soon as
enough words have been uttered to give the system
some indication of what the user means, or even
what the user will have said once the utterance is
completed. To measure the extent to which our NLU
module can predict the frame for an input utterance
when it sees only a partial ASR result with the first
n words, we examine two aspects of NLU with par-
tial ASR results. The first is correctness of the NLU
output with partial ASR results of varying lengths, if
we take the gold-standard manual annotation for the
entire utterance as the correct frame for any of the
partial ASR results for that utterance. The second is
stability: how similar the NLU output with partial
ASR results of varying lengths is to what the NLU
result would have been for the entire utterance.
</bodyText>
<subsectionHeader confidence="0.960224">
3.1 Training the NLU module for analysis of
partial ASR results
</subsectionHeader>
<bodyText confidence="0.999994944444445">
The simplest way to perform NLU of partial ASR re-
sults is simply to process the partial utterances using
the NLU module trained on complete ASR output.
However, better results may be obtained by train-
ing separate NLU models for analysis of partial ut-
terances of different lengths. To train these sepa-
rate NLU models, we first ran the audio of the utter-
ances in the training data through our ASR module,
recording all partial results for each utterance. Then,
to train a model to analyze partial utterances con-
taining n words, we used only partial utterances in
the training set containing n words (unless the entire
utterance contained less than n words, in which case
we simply used the complete utterance). In some
cases, multiple partial ASR results for a single utter-
ance contained the same number of words, and we
used the last partial result with the appropriate num-
ber of words 1. We trained separate NLU models for
</bodyText>
<footnote confidence="0.943953">
1At run-time, this can be closely approximated by taking
the partial utterance immediately preceding the first partial ut-
terance of length n + 1.
</footnote>
<figure confidence="0.9849859">
80
70
60
50
40
30
20
10
0
1 2
</figure>
<figureCaption confidence="0.9865365">
Figure 2: Correctness for three NLU models on partial
ASR results up to n words.
</figureCaption>
<bodyText confidence="0.878955">
n varying from one to ten.
</bodyText>
<subsectionHeader confidence="0.811856">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.998656448275862">
Figure 2 shows the f-score for frames obtained by
processing partial ASR results up to length n using
three NLU models. The dashed line is our baseline
NLU model, trained on complete utterances only
(model 1). The solid line shows the results obtained
with length-specific NLU models (model 2), and the
dotted line shows results for length-specific models
that also use features that capture dialogue context
(model 3). Models 1 and 2 are described in the previ-
ous sections. The additional features used in model
3 are unigram and bigram word features extracted
from the most recent system utterance.
As seen in Figure 2, there is a clear benefit to
training NLU models specifically tailored for partial
ASR results. Training a model on partial utterances
with four or five words allows for relatively high f-
score of frame elements (0.67 and 0.71, respectively,
compared to 0.58 and 0.66 when the same partial
ASR results are analyzed using model 1). Consider-
ing that half of the utterances are expected to have
more than five words (based on the length of the ut-
terances in the training set), allowing the system to
start processing user input when four or five-word
partial ASR results are available provides interesting
opportunities. Targeting partial results with seven
words or more is less productive, since the time sav-
ings are reduced, and the gain in accuracy is modest.
The context features used in model 3 did not pro-
vide substantial benefits in NLU accuracy. It is pos-
</bodyText>
<page confidence="0.992375">
55
</page>
<figure confidence="0.998446666666667">
100
90
80
70
60
50
40
30
20
10
0
1
</figure>
<figureCaption confidence="0.9990555">
Figure 3: Stability of NLU results for partial ASR results
up to length n.
</figureCaption>
<bodyText confidence="0.999916259259259">
sible that other ways of representing context or di-
alogue state may be more effective. This is an area
we are currently investigating.
Finally, figure 3 shows the stability of NLU re-
sults produced by model 2 for partial ASR utter-
ances of varying lengths. This is intended to be an
indication of how much the frame assigned to a par-
tial utterance differs from the ultimate NLU output
for the entire utterance. This ultimate NLU output
is the frame assigned by model 1 for the complete
utterance. Stability is then measured as the F-score
between the output of model 2 for a particular partial
utterance, and the output of model 1 for the corre-
sponding complete utterance. A stability F-score of
1.0 would mean that the frame produced for the par-
tial utterance is identical to the frame produced for
the entire utterance. Lower values indicate that the
frame assigned to a partial utterance is revised sig-
nificantly when the entire input is available. As ex-
pected, the frames produced by model 2 for partial
utterances with at least eight words match closely
the frames produced by model 1 for the complete ut-
terances. Although the frames for partial utterances
of length six are almost as accurate as the frames for
the complete utterances (figure 2), figure 3 indicates
that these frames are still often revised once the en-
tire input utterance is available.
</bodyText>
<sectionHeader confidence="0.999667" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999994352941177">
We have presented experiments that show that it
is possible to obtain domain-specific semantic rep-
resentations of spontaneous speech utterances with
reasonable accuracy before automatic speech recog-
nition of the utterances is completed. This allows for
interesting opportunities in dialogue systems, such
as agents that can interrupt the user, or even finish
the user’s sentence. Having an estimate of the cor-
rectness and stability of NLU results obtained with
partial utterances allows the dialogue system to es-
timate how likely its initial interpretation of an user
utterance is to be correct, or at least agree with its
ultimate interpretation. We are currently working on
the extensions to the NLU model that will allow for
the use of different types of context features, and in-
vestigating interesting ways in which agents can take
advantage of early interpretations.
</bodyText>
<sectionHeader confidence="0.999506" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999609">
The work described here has been sponsored by the
U.S. Army Research, Development, and Engineer-
ing Command (RDECOM). Statements and opin-
ions expressed do not necessarily reflect the position
or the policy of the United States Government, and
no official endorsement should be inferred.
</bodyText>
<sectionHeader confidence="0.999435" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999790214285714">
G. Aist, J. Allen, E. Campana, C. G. Gallo, S. Stoness,
M. Swift, and M. K. Tanenhaus. 2007. Incremental
dialogue system faster than and preferred to its non-
incremental counterpart. In Proc. of the 29th Annual
Conference of the Cognitive Science Society.
A. L. Berger, S. A. Della Pietra, and V. J. Della Pietra.
1996. A maximum entropy approach to natural
language processing. Computational Linguistics,
22(1):39–71.
G. J. Kruijff, P. Lison, T. Benjamin, H. Jacobsson, and
N. Hawes. 2007. Incremental, multi-level processing
for comprehending situated dialogue in human-robot
interaction. In Language and Robots: Proc. from the
Symposium (LangRo’2007). University of Aveiro, 12.
A. Leuski and D. Traum. 2008. A statistical approach
for text processing in virtual humans. In 26th Army
Science Conference.
G. Skantze and D. Schlangen. 2009. Incremental dia-
logue processing in a micro-domain. In Proc. of the
12th Conference of the European Chapter of the ACL.
D. Traum, S. Marsella, J. Gratch, J. Lee, and A. Hartholt.
2008. Multi-party, multi-issue, multi-strategy negotia-
tion for multi-modal virtual agents. In Proc. of Intelli-
gent Virtual Agents Conference IVA-2008.
D. Traum. 2003. Semantics and pragmatics of ques-
tions and answers for dialogue agents. In Proc. of the
International Workshop on Computational Semantics,
pages 380–394, January.
</reference>
<page confidence="0.998422">
56
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.843994">
<title confidence="0.979952">Towards Natural Language Understanding of Partial Speech Results in Dialogue Systems</title>
<author confidence="0.85849">Sagae Christian DeVault R</author>
<affiliation confidence="0.999712">Institute for Creative Technologies, University of Southern</affiliation>
<address confidence="0.994909">13274 Fiji Way, Marina del Rey, CA</address>
<abstract confidence="0.999428111111111">We investigate natural language understanding of partial speech recognition results to equip a dialogue system with incremental language processing capabilities for more realistic human-computer conversations. We show that relatively high accuracy can be achieved in understanding of spontaneous utterances before utterances are completed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Aist</author>
<author>J Allen</author>
<author>E Campana</author>
<author>C G Gallo</author>
<author>S Stoness</author>
<author>M Swift</author>
<author>M K Tanenhaus</author>
</authors>
<title>Incremental dialogue system faster than and preferred to its nonincremental counterpart.</title>
<date>2007</date>
<booktitle>In Proc. of the 29th Annual Conference of the Cognitive Science Society.</booktitle>
<contexts>
<context position="1818" citStr="Aist et al., 2007" startWordPosition="267" endWordPosition="270">nforces a rigid pacing that can be unnatural and inefficient for mixed-initiative dialogue. To achieve more flexible turn-taking with human users, for whom turn-taking and feedback at the subutterance level is natural and common, the system needs to engage in incremental processing, in which interpretation components are activated, and in some cases decisions are made, before the user utterance is complete. There is a growing body of work on incremental processing in dialogue systems. Some of this work has demonstrated overall improvements in system responsiveness and user satisfaction; e.g. (Aist et al., 2007; Skantze and Schlangen, 2009). Several 53 research groups, inspired by psycholinguistic models of human processing, have also been exploring technical frameworks that allow diverse contextual information to be brought to bear during incremental processing; e.g. (Kruijff et al., 2007; Aist et al., 2007). While this work often assumes or suggests it is possible for systems to understand partial user utterances, this premise has generally not been given detailed quantitative study. The contribution of this paper is to demonstrate and explore quantitatively the extent to which one specific dialog</context>
</contexts>
<marker>Aist, Allen, Campana, Gallo, Stoness, Swift, Tanenhaus, 2007</marker>
<rawString>G. Aist, J. Allen, E. Campana, C. G. Gallo, S. Stoness, M. Swift, and M. K. Tanenhaus. 2007. Incremental dialogue system faster than and preferred to its nonincremental counterpart. In Proc. of the 29th Annual Conference of the Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Berger</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="4860" citStr="Berger et al., 1996" startWordPosition="741" endWordPosition="744">ys generators for electricity downtown • ASR (NLU input): we up apparently give you guys generators for a letter city don town • Frame (NLU output): &lt;s&gt;.mood declarative &lt;s&gt;.sem.agent kirk &lt;s&gt;.sem.event deliver &lt;s&gt;.sem.modal.possibility can &lt;s&gt;.sem.speechact.type offer &lt;s&gt;.sem.theme power-generator &lt;s&gt;.sem.type event The original NLU component for this system was described in (Leuski and Traum, 2008). For the purposes of this experiment, we have developed a new NLU module and tested on several different data sets as described in the next section. Our approach is to use maximum entropy models (Berger et al., 1996) to learn a suitable mapping from features derived from the words in the ASR output to semantic frames. Given a set of examples of semantic frames with corresponding ASR output, a classifier should learn, for example, that when “generators” appears in the output of ASR, the value power-generators is likely to be present in the output frame. The specific features used by the classifier are: each word in the input string (bag-of-words representation of the input), each bigram (consecutive words), each pair of any two words in the input, and the number of words in the input string. Figure 1: Leng</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>A. L. Berger, S. A. Della Pietra, and V. J. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G J Kruijff</author>
<author>P Lison</author>
<author>T Benjamin</author>
<author>H Jacobsson</author>
<author>N Hawes</author>
</authors>
<title>Incremental, multi-level processing for comprehending situated dialogue in human-robot interaction.</title>
<date>2007</date>
<booktitle>In Language and Robots: Proc. from the Symposium (LangRo’2007). University of Aveiro,</booktitle>
<pages>12</pages>
<contexts>
<context position="2102" citStr="Kruijff et al., 2007" startWordPosition="308" endWordPosition="311">g, in which interpretation components are activated, and in some cases decisions are made, before the user utterance is complete. There is a growing body of work on incremental processing in dialogue systems. Some of this work has demonstrated overall improvements in system responsiveness and user satisfaction; e.g. (Aist et al., 2007; Skantze and Schlangen, 2009). Several 53 research groups, inspired by psycholinguistic models of human processing, have also been exploring technical frameworks that allow diverse contextual information to be brought to bear during incremental processing; e.g. (Kruijff et al., 2007; Aist et al., 2007). While this work often assumes or suggests it is possible for systems to understand partial user utterances, this premise has generally not been given detailed quantitative study. The contribution of this paper is to demonstrate and explore quantitatively the extent to which one specific dialogue system can anticipate what an utterance means, on the basis of partial ASR results, before the utterance is complete. 2 NLU for spontaneous spoken utterances in a dialogue system For this initial effort, we chose to look at incremental processing of natural language understanding </context>
</contexts>
<marker>Kruijff, Lison, Benjamin, Jacobsson, Hawes, 2007</marker>
<rawString>G. J. Kruijff, P. Lison, T. Benjamin, H. Jacobsson, and N. Hawes. 2007. Incremental, multi-level processing for comprehending situated dialogue in human-robot interaction. In Language and Robots: Proc. from the Symposium (LangRo’2007). University of Aveiro, 12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Leuski</author>
<author>D Traum</author>
</authors>
<title>A statistical approach for text processing in virtual humans.</title>
<date>2008</date>
<booktitle>In 26th Army Science Conference.</booktitle>
<contexts>
<context position="4643" citStr="Leuski and Traum, 2008" startWordPosition="702" endWordPosition="705">. The following example, where the user attempts to address complaints about lack of power in the proposed location for the clinic, illustrates an utteranceframe pair. • Utterance (speech): we are prepared to give you guys generators for electricity downtown • ASR (NLU input): we up apparently give you guys generators for a letter city don town • Frame (NLU output): &lt;s&gt;.mood declarative &lt;s&gt;.sem.agent kirk &lt;s&gt;.sem.event deliver &lt;s&gt;.sem.modal.possibility can &lt;s&gt;.sem.speechact.type offer &lt;s&gt;.sem.theme power-generator &lt;s&gt;.sem.type event The original NLU component for this system was described in (Leuski and Traum, 2008). For the purposes of this experiment, we have developed a new NLU module and tested on several different data sets as described in the next section. Our approach is to use maximum entropy models (Berger et al., 1996) to learn a suitable mapping from features derived from the words in the ASR output to semantic frames. Given a set of examples of semantic frames with corresponding ASR output, a classifier should learn, for example, that when “generators” appears in the output of ASR, the value power-generators is likely to be present in the output frame. The specific features used by the classi</context>
</contexts>
<marker>Leuski, Traum, 2008</marker>
<rawString>A. Leuski and D. Traum. 2008. A statistical approach for text processing in virtual humans. In 26th Army Science Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Skantze</author>
<author>D Schlangen</author>
</authors>
<title>Incremental dialogue processing in a micro-domain.</title>
<date>2009</date>
<booktitle>In Proc. of the 12th Conference of the European Chapter of the ACL.</booktitle>
<contexts>
<context position="1848" citStr="Skantze and Schlangen, 2009" startWordPosition="271" endWordPosition="274">ing that can be unnatural and inefficient for mixed-initiative dialogue. To achieve more flexible turn-taking with human users, for whom turn-taking and feedback at the subutterance level is natural and common, the system needs to engage in incremental processing, in which interpretation components are activated, and in some cases decisions are made, before the user utterance is complete. There is a growing body of work on incremental processing in dialogue systems. Some of this work has demonstrated overall improvements in system responsiveness and user satisfaction; e.g. (Aist et al., 2007; Skantze and Schlangen, 2009). Several 53 research groups, inspired by psycholinguistic models of human processing, have also been exploring technical frameworks that allow diverse contextual information to be brought to bear during incremental processing; e.g. (Kruijff et al., 2007; Aist et al., 2007). While this work often assumes or suggests it is possible for systems to understand partial user utterances, this premise has generally not been given detailed quantitative study. The contribution of this paper is to demonstrate and explore quantitatively the extent to which one specific dialogue system can anticipate what </context>
</contexts>
<marker>Skantze, Schlangen, 2009</marker>
<rawString>G. Skantze and D. Schlangen. 2009. Incremental dialogue processing in a micro-domain. In Proc. of the 12th Conference of the European Chapter of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Traum</author>
<author>S Marsella</author>
<author>J Gratch</author>
<author>J Lee</author>
<author>A Hartholt</author>
</authors>
<title>Multi-party, multi-issue, multi-strategy negotiation for multi-modal virtual agents.</title>
<date>2008</date>
<booktitle>In Proc. of Intelligent Virtual Agents Conference IVA-2008.</booktitle>
<contexts>
<context position="2744" citStr="Traum et al., 2008" startWordPosition="410" endWordPosition="413">hile this work often assumes or suggests it is possible for systems to understand partial user utterances, this premise has generally not been given detailed quantitative study. The contribution of this paper is to demonstrate and explore quantitatively the extent to which one specific dialogue system can anticipate what an utterance means, on the basis of partial ASR results, before the utterance is complete. 2 NLU for spontaneous spoken utterances in a dialogue system For this initial effort, we chose to look at incremental processing of natural language understanding in the SASO-EN system (Traum et al., 2008), a complex spoken dialog system for which we have a corpus of user data that includes recorded speech files that have been transcribed and annotated with a semantic representation. The domain of this system is a negotiation scenario involving the location of a medical clinic in a foreign country. The system is intended as a negotiation training tool, where users learn about negotiation tactics in the context of the culture and social norms of a particular community. 2.1 The natural language understanding task The NLU module must take the output of ASR as input, and produce domain-specific sem</context>
</contexts>
<marker>Traum, Marsella, Gratch, Lee, Hartholt, 2008</marker>
<rawString>D. Traum, S. Marsella, J. Gratch, J. Lee, and A. Hartholt. 2008. Multi-party, multi-issue, multi-strategy negotiation for multi-modal virtual agents. In Proc. of Intelligent Virtual Agents Conference IVA-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Traum</author>
</authors>
<title>Semantics and pragmatics of questions and answers for dialogue agents.</title>
<date>2003</date>
<booktitle>In Proc. of the International Workshop on Computational Semantics,</booktitle>
<pages>380--394</pages>
<contexts>
<context position="3691" citStr="Traum, 2003" startWordPosition="560" endWordPosition="561">ion training tool, where users learn about negotiation tactics in the context of the culture and social norms of a particular community. 2.1 The natural language understanding task The NLU module must take the output of ASR as input, and produce domain-specific semantic frames as output. These frames are intended to capture much of the meaning of the utterance, although a Proceedings of NAACL HLT 2009: Short Papers, pages 53–56, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics dialogue manager further enriches the frame representations with pragmatic information (Traum, 2003). NLU output frames are attribute-value matrices, where the attributes and values are linked to a domain-specific ontology and task model. Complicating the NLU task of is the relatively high word error rate (0.54) in ASR of user speech input, given conversational speech in a complex domain and an untrained broad user population. The following example, where the user attempts to address complaints about lack of power in the proposed location for the clinic, illustrates an utteranceframe pair. • Utterance (speech): we are prepared to give you guys generators for electricity downtown • ASR (NLU i</context>
</contexts>
<marker>Traum, 2003</marker>
<rawString>D. Traum. 2003. Semantics and pragmatics of questions and answers for dialogue agents. In Proc. of the International Workshop on Computational Semantics, pages 380–394, January.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>