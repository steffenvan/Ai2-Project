<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.160169">
<title confidence="0.997831">
A Tool for Deep Semantic Encoding of Narrative Texts
</title>
<author confidence="0.996907">
David K. Elson
</author>
<affiliation confidence="0.996667">
Columbia University
</affiliation>
<address confidence="0.852889">
New York City
</address>
<email confidence="0.995137">
delson@cs.columbia.edu
</email>
<author confidence="0.991864">
Kathleen R. McKeown
</author>
<affiliation confidence="0.994519">
Columbia University
</affiliation>
<address confidence="0.85391">
New York City
</address>
<email confidence="0.997898">
kathy@cs.columbia.edu
</email>
<sectionHeader confidence="0.993874" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999988294117647">
We have developed a novel, publicly avail-
able annotation tool for the semantic en-
coding of texts, especially those in the
narrative domain. Users can create for-
mal propositions to represent spans of text,
as well as temporal relations and other
aspects of narrative. A built-in natural-
language generation component regener-
ates text from the formal structures, which
eases the annotation process. We have
run collection experiments with the tool
and shown that non-experts can easily cre-
ate semantic encodings of short fables.
We present this tool as a stand-alone, re-
usable resource for research in semantics
in which formal encoding of text, espe-
cially in a narrative form, is required.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999884105263158">
Research in language processing has benefited
greatly from the collection of large annotated
corpora such as Penn PropBank (Kingsbury and
Palmer, 2002) and Penn Treebank (Marcus et al.,
1993). Such projects typically involve a formal
model (such as a controlled vocabulary of thematic
roles) and a corpus of text that has been anno-
tated against the model. One persistent tradeoff in
building such resources, however, is that a model
with a wider scope is more challenging for anno-
tators. For example, part-of-speech tagging is an
easier task than PropBank annotation. We believe
that careful user interface design can alleviate dif-
ficulties in annotating texts against deep semantic
models. In this demonstration, we present a tool
we have developed, SCHEHERAZADE, for deep
annotation of text.1
We are using the tool to collect semantic rep-
resentations of narrative text. This domain occurs
</bodyText>
<footnote confidence="0.991288">
1Available at http://www.cs.columbia.edu/˜delson.
</footnote>
<bodyText confidence="0.999851146341463">
frequently, yet is rarely studied in computational
linguistics. Narrative occurs with every other dis-
course type, including dialogue, news, blogs and
multi-party interaction. Given the volume of nar-
rative prose on the Web, a system competent at un-
derstanding narrative structures would be instru-
mental in a range of text processing tasks, such
as summarization or the generation of biographies
for question answering.
In the pursuit of a complete and connected rep-
resentation of the underlying facts of a story, our
annotation process involves the labeling of verb
frames, thematic roles, temporal structure, modal-
ity, causality and other features. This type of anno-
tation allows for machine learning on the thematic
dimension of narrative – that is, the aspects that
unite a series of related facts into an engaging and
fulfilling experience for a reader. Our methodol-
ogy is novel in its synthesis of several annotation
goals and its focus on content rather than expres-
sion. We aim to separate the narrative’s fabula, the
content dimension of the story, from the rhetori-
cal presentation at the textual surface (sjuˇzet) (Bal,
1997). To this end, our model incorporates formal
elements found in other discourse-level annotation
projects such as Penn Discourse Treebank (Prasad
et al., 2008) and temporal markup languages such
as TimeML (Mani and Pustejovsky, 2004). We
call the representation a story graph, because these
elements are embodied by nodes and connected by
arcs that represent relationships such as temporal
order and motivation.
More specifically, our annotation process in-
volves the construction of propositions to best ap-
proximate each of the events described in the tex-
tual story. Every element of the representation
is formally defined from controlled vocabularies:
the verb frames, with their thematic roles, are
adapted from VerbNet (Kipper et al., 2006), the
largest verb lexicon available in English. When
the verb frames are filled in to construct action
</bodyText>
<page confidence="0.949778">
9
</page>
<note confidence="0.975937">
Proceedings of the ACL-IJCNLP 2009 Software Demonstrations, pages 9–12,
Suntec, Singapore, 3 August 2009. c�2009 ACL and AFNLP
</note>
<figureCaption confidence="0.992977">
Figure 1: Screenshot from our tool showing the process of creating a formal proposition. On the left, the
user is nesting three action propositions together; on the right, the user selects a particular frame from a
searchable list. The resulting propositions are regenerated in rectangular boxes.
</figureCaption>
<bodyText confidence="0.9996908125">
propositions, the arguments are either themselves
propositions or noun synsets from WordNet (the
largest available noun lexicon (Fellbaum, 1998)).
Annotators can also write stative propositions
and modifiers (with adjectives and adverbs culled
from WordNet), and distinguish between goals,
plans, beliefs and other “hypothetical” modalities.
The representation supports connectives including
causality and motivation between these elements.
Finally, and crucially, each proposition is bound
to a state (time slice) in the story’s main timeline
(a linear sequence of states). Additional timelines
can represent multi-state beliefs, goals or plans. In
the course of authoring actions and statives, an-
notators create a detailed temporal framework to
which they attach their propositions.
</bodyText>
<sectionHeader confidence="0.795176" genericHeader="method">
2 Description of Tool
</sectionHeader>
<bodyText confidence="0.999973166666667">
The collection process is amenable to community
and non-expert annotation by means of a graphical
encoding tool. We believe this resource can serve
a range of experiments in semantics and human
text comprehension.
As seen in Figure 1, the process of creating a
proposition with our tool involves selecting an ap-
propriate frame and filling the arguments indicated
by the thematic roles of the frame. Annotators are
guided through the process by a natural-language
generation component that is able to realize textual
equivalents of all possible propositions. A search
in the interface for “flatter,” for example, offers a
list of relevant frames such as &lt;A character&gt; flat-
ters &lt;a character&gt;. Upon selecting this frame, an
annotator is able to supply arguments by choosing
actors from a list of declared characters. “The fox
flatters the crow,” for one, would be internally rep-
resented with the proposition &lt;flatters&gt;([Foxi],
[Crowe]) where flatters, Fox and Crow are not
snippets of surface text, but rather selected Word-
Net and VerbNet records. (The subscript indi-
cates that the proposition is invoking a particular
[Fox] instance that was previously declared.) In
this manner an entire story can be encoded.
Figure 2 shows a screenshot from our interface
in which propositions are positioned on a timeline
to indicate temporal relationships. On the right
side of the screen are the original text (used for
reference) and the entire story as regenerated from
</bodyText>
<page confidence="0.98931">
10
</page>
<figureCaption confidence="0.9112855">
Figure 2: The main screen of our tool features a graphical timeline, as well as boxes for the reference
text and the story as regenerated by the system from the formal model.
</figureCaption>
<bodyText confidence="0.999352521739131">
the current state of the formal model. It is also pos-
sible from this screen to invoke modalities such
as goals, plans and beliefs, and to indicate links
between propositions. Annotators are instructed
to construct propositions until the resulting textual
story, as realized by the generation component, is
as close to their own understanding of the story as
permitted by the formal representation.
The tool includes annotation guidelines for con-
structing the best propositions to approximate the
content of the story. Depending on the intended
use of the data, annotators may be instructed to
model just the stated content in the text, or include
the implied content as well. (For example, causal
links between events are often not articulated in a
text.) The resulting story graph is a unified rep-
resentation of the entire fabula, without a story’s
beginning or end. In addition, the tool allows an-
notators to select spans of text and link them to
the corresponding proposition(s). By indicating
which propositions were stated in the original text,
and in what order, the content and presentation di-
mensions of a story are cross-indexed.
</bodyText>
<sectionHeader confidence="0.998824" genericHeader="method">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.999995588235294">
We have conducted several formative evaluations
and data collection experiments with this inter-
face. In one, four annotators each modeled four of
the fables attributed to Aesop. In another, two an-
notators each modeled twenty fables. We chose to
model stories from the Aesop corpus due to sev-
eral key advantages: the stories are mostly built
from simple declaratives, which are within the ex-
pressive range of our semantic model, yet are rich
in thematic targets for automatic learning (such as
dilemmas where characters must choose from be-
tween competing values).
In the latter collection, both annotators were un-
dergraduates in our engineering school and native
English speakers, with little background in lin-
guistics. For this experiment, we instructed them
to only model stated content (as opposed to includ-
ing inferences), and skip the linking to spans of
source text. On average, they required 35-45 min-
utes to encode a fable, though this decreased with
practice. The 40 encodings include 574 proposi-
tions, excluding those in hypothetical modalities.
The fables average 130 words in length (so the an-
notators created, on average, one proposition for
every nine words).
Both annotators became comfortable with the
tool after a period of training; in surveys that they
completed after each task, they gave Likert-scale
usability scores of 4.25 and 4.30 (averaged over
all 20 tasks, with a score of 5 representing “easiest
to use”). The most frequently cited deficiencies in
the model were abstract concepts such as fair (in
the sense of a community event), which we plan to
support in a future release.
</bodyText>
<sectionHeader confidence="0.999572" genericHeader="evaluation">
4 Results and Future Work
</sectionHeader>
<bodyText confidence="0.999954428571429">
The end result from a collection experiment is
a collection of story graphs which are suitable
for machine learning. An example story graph,
based on the state of the tool seen in Figure 2, is
shown in Figure 3. Nodes in the graph represent
states, declared objects and propositions (actions
and statives). Each of the predicates (e.g., &lt;lion&gt;,
</bodyText>
<page confidence="0.994801">
11
</page>
<figure confidence="0.9953614375">
Opening Assertions Time/ine
State 1 State 2
beginsAt
beginsAt
&lt;hungry&gt;(Lion1)
&lt;feed&gt;(Bull1, Meadow1)
&lt;watch&gt;(Lion1, Bull1)
Actions and statives
because
&lt;cunning&gt;(Lion1)
Bull1 = new &lt;bull&gt;
Field1 = new &lt;Field&gt;
Lion1= new &lt;lion&gt;
&lt;fat&gt; (Bull1)
&lt;horned&gt;(Bull1)
�
</figure>
<figureCaption confidence="0.999918">
Figure 3: A portion of a story graph representation as created by SCHEHERAZADE.
</figureCaption>
<bodyText confidence="0.9970299">
&lt;watch&gt;, &lt;cunning&gt;) are linked to their corre-
sponding VerbNet and WordNet records.
We are currently experimenting with ap-
proaches for data-driven analysis of narrative con-
tent along the “thematic” dimension as described
above. In particular, we are interested in the auto-
matic discovery of deep similarities between sto-
ries (such as analogous structures and prototypical
characters). We are also interested in investigat-
ing the selection and ordering of content in the
story’s telling (that is, which elements are stated
and which remain implied), especially as they per-
tain to the reader’s affectual responses. We plan
to make the annotated corpus publicly available in
addition to the tool.
Overall, while more work remains in expanding
the model as well as the graphical interface, we
believe we are providing to the community a valu-
able new tool for eliciting semantic encodings of
narrative texts for machine learning purposes.
</bodyText>
<sectionHeader confidence="0.991891" genericHeader="conclusions">
5 Script Outline
</sectionHeader>
<bodyText confidence="0.8516508">
Our demonstration involves a walk-through of the
SCHEHERAZADE tool. It includes:
1. An outline of the goals of the project and the
innovative aspects of our formal representa-
tion compared to other representations cur-
rently in the field.
2. A tour of the timeline screen (equivalent to
Figure 2) as configured for a particular Aesop
fable.
3. The procedure for reading a text for impor-
tant named entities, and formally declaring
these named entities for the story graph.
4. The process for constructing propositions in
order to encode actions and statives in the
text, as seen in Figure 1.
</bodyText>
<listItem confidence="0.901233">
5. Other features of the software package, such
as the setting of causal links and the ability to
undo/redo.
6. A review of the results of our formative eval-
uations and data collection experiments, in-
cluding surveys of user satisfaction.
</listItem>
<sectionHeader confidence="0.991882" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998733423076923">
Mieke Bal. 1997. Narratology: Introduction to the
Theory of Narrative. University of Toronto Press,
Toronto, second edition.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. MIT Press, Cambridge, MA.
Paul Kingsbury and Martha Palmer. 2002. From tree-
bank to propbank. In Proceedings of the Third In-
ternational Conference on Language Resources and
Evaluation (LREC-02), Canary Islands, Spain.
Karin Kipper, Anna Korhonen, Neville Ryant, and
Martha Palmer. 2006. Extensive classifications of
english verbs. In Proceedings of the 12th EURALEX
International Congress, Turin, Italy.
Inderjeet Mani and James Pustejovsky. 2004. Tem-
poral discourse models for narrative structure. In
Proceedings of the ACL Workshop on Discourse An-
notation, Barcelona, Spain.
Mitchell P. Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. Building a large anno-
tated corpus of english: The penn treebank. Compu-
tational Linguistics, 19.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie
Webber. 2008. The penn discourse treebank 2.0. In
Proceedings of the 6th International Conference on
Language Resources and Evaluation (LREC 2008).
</reference>
<page confidence="0.998434">
12
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.703039">
<title confidence="0.999966">A Tool for Deep Semantic Encoding of Narrative Texts</title>
<author confidence="0.999984">David K Elson</author>
<affiliation confidence="0.99991">Columbia University</affiliation>
<author confidence="0.887136">New York City</author>
<email confidence="0.996974">delson@cs.columbia.edu</email>
<author confidence="0.999964">Kathleen R McKeown</author>
<affiliation confidence="0.999917">Columbia University</affiliation>
<author confidence="0.88371">New York City</author>
<email confidence="0.999494">kathy@cs.columbia.edu</email>
<abstract confidence="0.994343555555555">We have developed a novel, publicly available annotation tool for the semantic encoding of texts, especially those in the narrative domain. Users can create formal propositions to represent spans of text, as well as temporal relations and other aspects of narrative. A built-in naturallanguage generation component regenerates text from the formal structures, which eases the annotation process. We have run collection experiments with the tool and shown that non-experts can easily create semantic encodings of short fables. We present this tool as a stand-alone, reusable resource for research in semantics in which formal encoding of text, especially in a narrative form, is required.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mieke Bal</author>
</authors>
<title>Narratology: Introduction to the Theory of Narrative.</title>
<date>1997</date>
<publisher>University of Toronto Press,</publisher>
<location>Toronto,</location>
<note>second edition.</note>
<contexts>
<context position="2986" citStr="Bal, 1997" startWordPosition="463" endWordPosition="464">tion process involves the labeling of verb frames, thematic roles, temporal structure, modality, causality and other features. This type of annotation allows for machine learning on the thematic dimension of narrative – that is, the aspects that unite a series of related facts into an engaging and fulfilling experience for a reader. Our methodology is novel in its synthesis of several annotation goals and its focus on content rather than expression. We aim to separate the narrative’s fabula, the content dimension of the story, from the rhetorical presentation at the textual surface (sjuˇzet) (Bal, 1997). To this end, our model incorporates formal elements found in other discourse-level annotation projects such as Penn Discourse Treebank (Prasad et al., 2008) and temporal markup languages such as TimeML (Mani and Pustejovsky, 2004). We call the representation a story graph, because these elements are embodied by nodes and connected by arcs that represent relationships such as temporal order and motivation. More specifically, our annotation process involves the construction of propositions to best approximate each of the events described in the textual story. Every element of the representatio</context>
</contexts>
<marker>Bal, 1997</marker>
<rawString>Mieke Bal. 1997. Narratology: Introduction to the Theory of Narrative. University of Toronto Press, Toronto, second edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="4402" citStr="Fellbaum, 1998" startWordPosition="676" endWordPosition="677">erb frames are filled in to construct action 9 Proceedings of the ACL-IJCNLP 2009 Software Demonstrations, pages 9–12, Suntec, Singapore, 3 August 2009. c�2009 ACL and AFNLP Figure 1: Screenshot from our tool showing the process of creating a formal proposition. On the left, the user is nesting three action propositions together; on the right, the user selects a particular frame from a searchable list. The resulting propositions are regenerated in rectangular boxes. propositions, the arguments are either themselves propositions or noun synsets from WordNet (the largest available noun lexicon (Fellbaum, 1998)). Annotators can also write stative propositions and modifiers (with adjectives and adverbs culled from WordNet), and distinguish between goals, plans, beliefs and other “hypothetical” modalities. The representation supports connectives including causality and motivation between these elements. Finally, and crucially, each proposition is bound to a state (time slice) in the story’s main timeline (a linear sequence of states). Additional timelines can represent multi-state beliefs, goals or plans. In the course of authoring actions and statives, annotators create a detailed temporal framework </context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Kingsbury</author>
<author>Martha Palmer</author>
</authors>
<title>From treebank to propbank.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC-02), Canary Islands,</booktitle>
<contexts>
<context position="1064" citStr="Kingsbury and Palmer, 2002" startWordPosition="159" endWordPosition="162">lations and other aspects of narrative. A built-in naturallanguage generation component regenerates text from the formal structures, which eases the annotation process. We have run collection experiments with the tool and shown that non-experts can easily create semantic encodings of short fables. We present this tool as a stand-alone, reusable resource for research in semantics in which formal encoding of text, especially in a narrative form, is required. 1 Introduction Research in language processing has benefited greatly from the collection of large annotated corpora such as Penn PropBank (Kingsbury and Palmer, 2002) and Penn Treebank (Marcus et al., 1993). Such projects typically involve a formal model (such as a controlled vocabulary of thematic roles) and a corpus of text that has been annotated against the model. One persistent tradeoff in building such resources, however, is that a model with a wider scope is more challenging for annotators. For example, part-of-speech tagging is an easier task than PropBank annotation. We believe that careful user interface design can alleviate difficulties in annotating texts against deep semantic models. In this demonstration, we present a tool we have developed, </context>
</contexts>
<marker>Kingsbury, Palmer, 2002</marker>
<rawString>Paul Kingsbury and Martha Palmer. 2002. From treebank to propbank. In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC-02), Canary Islands, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper</author>
<author>Anna Korhonen</author>
<author>Neville Ryant</author>
<author>Martha Palmer</author>
</authors>
<title>Extensive classifications of english verbs.</title>
<date>2006</date>
<booktitle>In Proceedings of the 12th EURALEX International Congress,</booktitle>
<location>Turin, Italy.</location>
<contexts>
<context position="3728" citStr="Kipper et al., 2006" startWordPosition="573" endWordPosition="576">ourse Treebank (Prasad et al., 2008) and temporal markup languages such as TimeML (Mani and Pustejovsky, 2004). We call the representation a story graph, because these elements are embodied by nodes and connected by arcs that represent relationships such as temporal order and motivation. More specifically, our annotation process involves the construction of propositions to best approximate each of the events described in the textual story. Every element of the representation is formally defined from controlled vocabularies: the verb frames, with their thematic roles, are adapted from VerbNet (Kipper et al., 2006), the largest verb lexicon available in English. When the verb frames are filled in to construct action 9 Proceedings of the ACL-IJCNLP 2009 Software Demonstrations, pages 9–12, Suntec, Singapore, 3 August 2009. c�2009 ACL and AFNLP Figure 1: Screenshot from our tool showing the process of creating a formal proposition. On the left, the user is nesting three action propositions together; on the right, the user selects a particular frame from a searchable list. The resulting propositions are regenerated in rectangular boxes. propositions, the arguments are either themselves propositions or noun</context>
</contexts>
<marker>Kipper, Korhonen, Ryant, Palmer, 2006</marker>
<rawString>Karin Kipper, Anna Korhonen, Neville Ryant, and Martha Palmer. 2006. Extensive classifications of english verbs. In Proceedings of the 12th EURALEX International Congress, Turin, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>James Pustejovsky</author>
</authors>
<title>Temporal discourse models for narrative structure.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL Workshop on Discourse Annotation,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="3218" citStr="Mani and Pustejovsky, 2004" startWordPosition="495" endWordPosition="498">ve – that is, the aspects that unite a series of related facts into an engaging and fulfilling experience for a reader. Our methodology is novel in its synthesis of several annotation goals and its focus on content rather than expression. We aim to separate the narrative’s fabula, the content dimension of the story, from the rhetorical presentation at the textual surface (sjuˇzet) (Bal, 1997). To this end, our model incorporates formal elements found in other discourse-level annotation projects such as Penn Discourse Treebank (Prasad et al., 2008) and temporal markup languages such as TimeML (Mani and Pustejovsky, 2004). We call the representation a story graph, because these elements are embodied by nodes and connected by arcs that represent relationships such as temporal order and motivation. More specifically, our annotation process involves the construction of propositions to best approximate each of the events described in the textual story. Every element of the representation is formally defined from controlled vocabularies: the verb frames, with their thematic roles, are adapted from VerbNet (Kipper et al., 2006), the largest verb lexicon available in English. When the verb frames are filled in to con</context>
</contexts>
<marker>Mani, Pustejovsky, 2004</marker>
<rawString>Inderjeet Mani and James Pustejovsky. 2004. Temporal discourse models for narrative structure. In Proceedings of the ACL Workshop on Discourse Annotation, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Beatrice Santorini</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<contexts>
<context position="1104" citStr="Marcus et al., 1993" startWordPosition="166" endWordPosition="169">-in naturallanguage generation component regenerates text from the formal structures, which eases the annotation process. We have run collection experiments with the tool and shown that non-experts can easily create semantic encodings of short fables. We present this tool as a stand-alone, reusable resource for research in semantics in which formal encoding of text, especially in a narrative form, is required. 1 Introduction Research in language processing has benefited greatly from the collection of large annotated corpora such as Penn PropBank (Kingsbury and Palmer, 2002) and Penn Treebank (Marcus et al., 1993). Such projects typically involve a formal model (such as a controlled vocabulary of thematic roles) and a corpus of text that has been annotated against the model. One persistent tradeoff in building such resources, however, is that a model with a wider scope is more challenging for annotators. For example, part-of-speech tagging is an easier task than PropBank annotation. We believe that careful user interface design can alleviate difficulties in annotating texts against deep semantic models. In this demonstration, we present a tool we have developed, SCHEHERAZADE, for deep annotation of tex</context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rashmi Prasad</author>
<author>Nikhil Dinesh</author>
<author>Alan Lee</author>
<author>Eleni Miltsakaki</author>
<author>Livio Robaldo</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<title>The penn discourse treebank 2.0.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC</booktitle>
<contexts>
<context position="3144" citStr="Prasad et al., 2008" startWordPosition="484" endWordPosition="487">on allows for machine learning on the thematic dimension of narrative – that is, the aspects that unite a series of related facts into an engaging and fulfilling experience for a reader. Our methodology is novel in its synthesis of several annotation goals and its focus on content rather than expression. We aim to separate the narrative’s fabula, the content dimension of the story, from the rhetorical presentation at the textual surface (sjuˇzet) (Bal, 1997). To this end, our model incorporates formal elements found in other discourse-level annotation projects such as Penn Discourse Treebank (Prasad et al., 2008) and temporal markup languages such as TimeML (Mani and Pustejovsky, 2004). We call the representation a story graph, because these elements are embodied by nodes and connected by arcs that represent relationships such as temporal order and motivation. More specifically, our annotation process involves the construction of propositions to best approximate each of the events described in the textual story. Every element of the representation is formally defined from controlled vocabularies: the verb frames, with their thematic roles, are adapted from VerbNet (Kipper et al., 2006), the largest ve</context>
</contexts>
<marker>Prasad, Dinesh, Lee, Miltsakaki, Robaldo, Joshi, Webber, 2008</marker>
<rawString>Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The penn discourse treebank 2.0. In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC 2008).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>