<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003952">
<title confidence="0.9982525">
Generating Expository Dialogue from Monologue:
Motivation, Corpus and Preliminary Rules
</title>
<author confidence="0.994919">
Paul Piwek
</author>
<affiliation confidence="0.811911666666667">
Centre for Research in Computing
The Open University
Walton Hall, Milton Keynes, UK
</affiliation>
<email confidence="0.99079">
p.piwek@open.ac.uk
</email>
<author confidence="0.935782">
Svetlana Stoyanchev
</author>
<affiliation confidence="0.656763">
Centre for Research in Computing
The Open University
Walton Hall, Milton Keynes, UK
</affiliation>
<email confidence="0.993544">
s.stoyanchev@open.ac.uk
</email>
<sectionHeader confidence="0.995583" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998645142857143">
Generating expository dialogue from mono-
logue is a task that poses an interesting and re-
warding challenge for Natural Language Pro-
cessing. This short paper has three aims:
firstly, to motivate the importance of this
task, both in terms of the benefits of ex-
pository dialogue as a way to present in-
formation and in terms of potential applica-
tions; secondly, to introduce a parallel cor-
pus of monologues and dialogues which en-
ables a data-driven approach to this challenge;
and, finally, to describe work-in-progress on
semi-automatic construction of Monologue-
to-Dialogue (M2D) generation rules.
</bodyText>
<sectionHeader confidence="0.998984" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999976918367347">
The tasks of text generation – e.g., Reiter et al.
(2005) and Demir et al. (2008) – and generation
in dialogue – e.g., Stent (2002) and DeVault et al.
(2008) – are central topics in Natural Language Gen-
eration (NLG). What sets the two tasks apart is the
interactive nature of dialogue, where participants
need to adapt their contributions to each other.
This paper introduces an NLG task, the genera-
tion of expository dialogue, to the Computational
Linguistics community which occupies the middle
ground between these two tasks. An expository di-
alogue is an authored conversation between two fic-
tive characters. It can be presented as text, audio or
film. Although there is no real-time interactivity, in
expository dialogue the contributions of the charac-
ters do need to mesh with each other. The main pur-
pose of expository dialogue is to present informa-
tion (a description, explanation or definition) to the
reader, hearer or viewer, in contrast with dramatic
dialogue, which tells a story.
The use of expository dialogue goes back as far as
Plato (c. 470-399 BC), who expressed his ideas as
dialogues between Socrates and his contemporaries.
Recently, a number of empirical studies show that
for some purposes expository dialogue has advan-
tages over monologue: for learners, dialogue can be
more memorable, stimulate them to formulate their
own questions (Craig et al., 2000), and get them to
talk with each other (Lee et al., 1998). Expository
dialogue has also been found to be more effective
for persuasion (Suzuki and Yamada, 2004).
Additionally, dialogue lends itself very well
for multimedia presentations by computer-animated
agents (Andr´e et al., 2000; van Deemter et al.,
2008). Potential application domains include ed-
ucation, (serious) games and E-Health. In educa-
tion, information from textbooks could be presented
in dialogue form, possibly using virtual reality plat-
forms such as Second Life. Automatically gener-
ating dialogue from text for non-player characters
could have a tremendous impact on the gaming in-
dustry; e.g., (IGDA Game Writers SIG, 2003) state
that the amount of dialogue script for a character-
driven computer game is usually many times that
for the average film. In connection with E-health,
consider patient information leaflets, which are of-
ten left unread; presenting them as movies between
a virtual pharmacist and client may help address this.
Thus instead of being presented with
</bodyText>
<listItem confidence="0.978792">
(1) a. You can take aspirin,
b. if you have a headache.
</listItem>
<page confidence="0.955343">
333
</page>
<affiliation confidence="0.1967455">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 333–336,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</affiliation>
<listItem confidence="0.885155571428571">
c. Though aspirin does have side effects:
d. it can harm circulation.
the patient could watch a movie on their mobile de-
vice of an exchange between a virtual client (lay-
man, L) and pharmacist (expert, E):
(2) L: What if I have a headache?
E: You can take aspirin
</listItem>
<bodyText confidence="0.975015619047619">
L: But does it have side effects?
E: Yes, it can harm circulation.
So far, research on generating expository dialogue
has been firmly rooted in classical AI approaches.
Work in this area starts from knowledge represen-
tations or databases (Andr´e et al., 2000), and even
research that does take text as input – e.g., Piwek
et al. (2007) describe a system for generating di-
alogues such as Example 2 – relies on handcrafted
rules. Two challenges present themselves for NLP
research: 1) generation of expository dialogue from
text, and 2) use of data-driven, rather than manually
authored, generation rules.
Apart from the cost of manually authoring gener-
ation rules, previous research has found that human-
authored rules can result in ‘too much information
[being] given too quickly’ (Williams et al., 2007),
which can be addressed by conversational padding.
We argue that rather than trying to invent padding
rules, the best strategy is to learn rules automatically
from professionally authored dialogues.
</bodyText>
<sectionHeader confidence="0.959894" genericHeader="method">
2 The CODA Corpus
</sectionHeader>
<bodyText confidence="0.999984">
To make inroads into data-driven dialogue genera-
tion, we first need to have the necessary resources.
We propose to view Monologue-to-Dialogue (M2D)
generation as analogous to machine translation; con-
sequently we need a parallel corpus for learning
mappings from the source (monologue) to the tar-
get (dialogue) texts. In the ongoing CODA1 project
we have created such a corpus. It consists of profes-
sionally authored dialogues2 that have been aligned
with monologues (written by ourselves) expressing
the same information. Since our ultimate aim is to
generate dialogues that resemble those written by
</bodyText>
<footnote confidence="0.998703">
1COherent Dialogue Automatically generated from text
2Most dialogues are from the Gutenberg library to facilitate
our planned release of the corpus to the research community.
</footnote>
<table confidence="0.99906">
Sp Dialog act Dialogue Turn Monologue
E: Complex When you have When you
Question a pain in your have a pain in
foot, how do your foot (i)
you know it? you know it
because you
L: Explain I feel it. can feel it. (ii)
E: Explain- But you do not But you do not
Contradict feel it until a feel it until a
nerve reports nerve reports
the hurt to the the hurt to the
brain. brain. (iii)
E: YN- Yet the brain is Yet the brain is
Question the seat of the the seat of the
mind, is it not? mind. (iv)
</table>
<tableCaption confidence="0.9592185">
Table 1: Parallel Monologue and Dialogue Example from
Mark Twain’s “What is Man?”
</tableCaption>
<bodyText confidence="0.999755923076923">
acclaimed authors, we started with professionally
authored dialogues and created the corresponding
monologues. From a practical point of view, it was
more feasible to use existing dialogue by acclaimed
authors than to hire professional authors to write di-
alogue based on monologues.
We have annotated both dialogues and mono-
logues: dialogue with dialogue acts and monologue
with discourse relations.3 We achieved 91% agree-
ment on segmentation and kappa=.82 for dialogue
act annotation on 11 dialogue act tags. We devel-
oped a D2MTranslation tool for monologue author-
ing, segmentation and dialogue annotation.
In January 2010, the corpus included 500 turns
from “What is man?”, a dialogue by Mark Twain,
and 88 turns from “Evolving Algebras”, an aca-
demic paper in the form of dialogue by Yuri Gure-
vich.4 Both of these expository dialogues present
conversation between an expert (Old Man in Twain
and Author in Gurevich) and a layman (Young Man
in Twain and Quisani in Gurevich). Table 1 shows
an example of a dialogue fragment, aligned mono-
logue and dialogue act annotations. The discourse
structure of the monologue is depicted in Figure 1.
Table 2 shows the distribution of the dialogue acts
between expert and layman. In both dialogues, the
</bodyText>
<footnote confidence="0.9948872">
3See (Stoyanchev and Piwek, 2010) for details.
4In addition to these dialogues we are working on a dialogue
by Berkeley (Three Dialogues between Hylas and Philonous)
and a selection of shorter fragments (for copyrights reasons) by
authors such as Douglas Hofstadter and Paul Feyerabend.
</footnote>
<page confidence="0.993856">
334
</page>
<figureCaption confidence="0.999779">
Figure 1: Discourse structure of the monologue in Table 1
</figureCaption>
<bodyText confidence="0.9992085">
most frequent dialogue act is Explain, where a char-
acter presents information (as a new idea or as a re-
sponse to another utterance). Also, in both dialogues
the layman asks more often for clarification than
the expert. The distribution over information re-
quests (yes/no, factoid, and complex questions) and
responses (yes, no, factoid) differs between the two
dialogues: in Twain’s dialogue, the expert mostly
requests information and the layman responds to re-
quests, whereas in Gurevich’s dialogue it is the other
way around.
The differences in style suggests that the M2D
mapping rules will be author or style-specific. By
applying M2D rules obtained from two different au-
thors (e.g., Twain and Gurevich) to the same text
(e.g., the aspirin example) we can generate two dif-
ferent dialogues. This will enable us to vary the pre-
sentation style of automatically generated dialogues.
</bodyText>
<table confidence="0.9986985">
Twain Gurevich
Tag Expert Layman Expert Layman
Explain 69 55 49 24
Clarify 1 15 0 6
Request 60 26 2 29
Response 14 43 9 0
</table>
<tableCaption confidence="0.955959666666667">
Table 2: Dialogue act tag frequencies for expert and lay-
man in a sample of 250 turns from Twain and 88 turns
from Gurevich dialogues.
</tableCaption>
<sectionHeader confidence="0.996476" genericHeader="method">
3 Rules
</sectionHeader>
<bodyText confidence="0.9999311">
We automatically derive M2D rules from the aligned
discourse relations and dialogue acts in our parallel
corpus of monologues and dialogues. Table 3 shows
three rules generated from the parallel dialogue–
monologue fragment in Table 1. The first rule, R1,
is based on the complete discourse structure of the
monologue (i–iv), whereas R2 and R3 are based on
only a part of it: R2 is based on i–iii, whereas R3 is
based on i and ii. By generating rules from subtrees
of a discourse structure, we obtain several rules from
</bodyText>
<figureCaption confidence="0.998732">
Figure 2: Discourse structures of the monologue in Ex-
ample 1. a-b and c-d indicate a concatenation of two
clauses.
</figureCaption>
<bodyText confidence="0.999970294117647">
Let us illustrate the use of such rules by applying
them to Example 1 about aspirin. The relations be-
tween the clauses of the example are depicted in Fig-
ure 2 (1). To generate a dialogue, we apply a match-
ing M2D rule. Alternatively, we can first simplify
the discourse structure of the monologue by remov-
ing relation nodes as illustrated in Figure 2 (2–4).
The simplified structure in Figure 2 (2) matches
rule R2 from Table 3. By applying R2 we gener-
ate the dialogue in Table 4: the expert asks a com-
plex question composed of clauses a and b, which
the layman answers with an explanation generated
from the same set of clauses. Then the expert offers
a contradicting explanation generated from c and d.
To generate dialogue sentences for a corresponding
discourse structure we are adapting the approach to
paraphrasing of Barzilay and McKeown (2001).
</bodyText>
<sectionHeader confidence="0.996563" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999241647058823">
This short paper presented three angles on the
Monologue-to-Dialogue (M2D) task. First, as an
opinion piece, it motivates the task of generating ex-
pository dialogue from monologue. We described
empirical research that provides evidence for the
effectiveness of expository dialogue and discussed
applications from education, gaming and E-health.
Second, we introduced the CODA corpus for ad-
dressing the task. Finally, we reported on work-
in-progress on semi-automatic construction of M2D
rules. Our implemented algorithm extracts several
M2D rules from the corpus that are applicable even
to a relatively simple input. Additionally, frequency
analysis of dialogue tags suggests that there is scope
for generating different dialogue styles.
The timeliness of this research is evidenced by the
emergence of a Question Generation (QG) commu-
</bodyText>
<figure confidence="0.999986842105263">
b a c d
a single dialogue fragment in the corpus.
Contrast
Condition Elaboration
(1)
(3)
Contrast
a − b
c
Elaboration
d
b a c d
c − d
Condition
Contrast
(4)
Condition Elaboration
(2)
b a
</figure>
<page confidence="0.993796">
335
</page>
<table confidence="0.9991947">
ID Dialogue Structure Monologue Structure
R1 E: Complex Question (i-ii) Contrast (Contrast (Condition(i,ii), iii, iv))
L: Explain (i-ii)
E: Explain-Contradict (iii)
E: YNQuestion (iv)
R2 E: Complex Question (i-ii) Contrast (Condition(i,ii), iii)
L: Explain(i-ii)
E: Explain-Contradict (iii)
R3 E: Complex Question (i-ii) Condition (i,ii)
L: Explain (i-ii)
</table>
<tableCaption confidence="0.987563">
Table 3: Monologue-to-Dialogue rules extracted from the parallel example in Table 1
</tableCaption>
<table confidence="0.999466714285714">
Sp Dialogue act Dialogue Turn
E: Complex Ques- If you have a headache, what
tion a-b do you do?
L: Explain a-b Take aspirin.
E: Explain- But aspirin does have side
Contradict effects: it can harm circula-
c-d tion
</table>
<tableCaption confidence="0.9905505">
Table 4: A dialogue generated from the monologue about
aspirin by applying the rule R2 (see Table 3)
</tableCaption>
<bodyText confidence="0.999554">
nity. QG is a subtask of M2D. The first QG work-
shop was held at the end of 2008, resulting in pro-
posals for a Shared Task and Evaluation Campaign
(Rus and Graesser, 2009) for 2010. The CODA cor-
pus should prove to be a useful resource not only for
M2D researchers, but also for the QG community.
</bodyText>
<sectionHeader confidence="0.997662" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.987847666666667">
The research reported in this paper was funded by
the UK Engineering and Physical Sciences Research
Council under grant EP/G/020981/1.
</bodyText>
<sectionHeader confidence="0.998627" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99994241509434">
E. Andr´e, T. Rist, S. van Mulken, M. Klesen, and
S. Baldes. 2000. The automated design of believable
dialogues for animated presentation teams. In Em-
bodied Conversational Agents, pages 220–255. MIT
Press, Cambridge, Mass.
R. Barzilay and K. McKeown. 2001. Extracting para-
phrases from a parallel corpus. In Proc. ofACL/EACL,
Toulouse.
S. Craig, B. Gholson, M. Ventura, A. Graesser, and the
Tutoring Research Group. 2000. Overhearing dia-
logues and monologues in virtual tutoring sessions.
International Journal of Artificial Intelligence in Ed-
ucation, 11:242–253.
S. Demir, S. Carberry, and K. McCoy. 2008. Generating
Textual Summaries of Bar Charts. In Procs of INLG
2008, Ohio, June.
D. DeVault, D. Traum, and R. Artstein. 2008. Making
Grammar-Based Generation Easier to Deploy in Dia-
logue Systems. In Procs SIGdial 2008, Ohio, June.
J. Lee, F. Dinneen, and J. McKendree. 1998. Supporting
student discussions: it isn’t just talk. Education and
Information Technologies, 3:217–229.
P. Piwek, H. Hernault, H. Prendinger, and M. Ishizuka.
2007. T2D: Generating Dialogues between Virtual
Agents Automatically from Text. In Intelligent Virtual
Agents, LNAI 4722, pages 161–174. Springer Verlag.
E. Reiter, S. Sripada, J. Hunter, J. Yu, and I. Davy. 2005.
Choosing Words in Computer-Generated Weather
Forecasts. Artificial Intelligence, 167:137–169.
V. Rus and A. Graesser, editors. 2009. The Ques-
tion Generation Shared Task and Evaluation Chal-
lenge. The University of Memphis. Available at:
http://www.questiongeneration.org/.
IGDA Game Writers SIG. 2003. International game
developers association’s (IGDA) guide to writing for
games. IGDA White Paper.
A. Stent. 2002. A conversation acts model for generating
spoken dialogue contributions. Computer Speech and
Language, 16(3-4):313–352.
S. Stoyanchev and P. Piwek. 2010. Constructing the
CODA corpus. In Procs of LREC 2010, Malta, May.
S. V. Suzuki and S. Yamada. 2004. Persuasion through
overheard communication by life-like agents. In Procs
of the 2004 IEEE/WIC/ACM International Conference
on Intelligent Agent Technology, Beijing, September.
K. van Deemter, B. Krenn, P. Piwek, M. Klesen,
M. Schr¨oder, and S. Baumann. 2008. Fully gener-
ated scripted dialogue for embodied agents. Artificial
Intelligence Journal, 172(10):1219–1244.
S. Williams, P. Piwek, and R. Power. 2007. Generat-
ing Monologue and Dialogue to Present Personalised
Medical Information to Patients. In Procs ENLG
2007, pages 167–170, Schloss Dagstuhl, Germany.
</reference>
<page confidence="0.999148">
336
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.174976">
<title confidence="0.9980895">Generating Expository Dialogue from Motivation, Corpus and Preliminary Rules</title>
<author confidence="0.984947">Paul</author>
<affiliation confidence="0.965387">Centre for Research in</affiliation>
<title confidence="0.687111">The Open</title>
<author confidence="0.911691">Walton Hall</author>
<author confidence="0.911691">Milton Keynes</author>
<email confidence="0.995747">p.piwek@open.ac.uk</email>
<title confidence="0.627660333333333">Svetlana Centre for Research in Computing The Open</title>
<author confidence="0.971698">Walton Hall</author>
<author confidence="0.971698">Milton Keynes</author>
<email confidence="0.998894">s.stoyanchev@open.ac.uk</email>
<abstract confidence="0.994610066666667">Generating expository dialogue from monologue is a task that poses an interesting and rewarding challenge for Natural Language Processing. This short paper has three aims: firstly, to motivate the importance of this task, both in terms of the benefits of expository dialogue as a way to present information and in terms of potential applications; secondly, to introduce a parallel corpus of monologues and dialogues which enables a data-driven approach to this challenge; and, finally, to describe work-in-progress on semi-automatic construction of Monologueto-Dialogue (M2D) generation rules.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Andr´e</author>
<author>T Rist</author>
<author>S van Mulken</author>
<author>M Klesen</author>
<author>S Baldes</author>
</authors>
<title>The automated design of believable dialogues for animated presentation teams.</title>
<date>2000</date>
<booktitle>In Embodied Conversational Agents,</booktitle>
<pages>220--255</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, Mass.</location>
<marker>Andr´e, Rist, van Mulken, Klesen, Baldes, 2000</marker>
<rawString>E. Andr´e, T. Rist, S. van Mulken, M. Klesen, and S. Baldes. 2000. The automated design of believable dialogues for animated presentation teams. In Embodied Conversational Agents, pages 220–255. MIT Press, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>K McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<booktitle>In Proc. ofACL/EACL,</booktitle>
<location>Toulouse.</location>
<contexts>
<context position="10481" citStr="Barzilay and McKeown (2001)" startWordPosition="1720" endWordPosition="1723">natively, we can first simplify the discourse structure of the monologue by removing relation nodes as illustrated in Figure 2 (2–4). The simplified structure in Figure 2 (2) matches rule R2 from Table 3. By applying R2 we generate the dialogue in Table 4: the expert asks a complex question composed of clauses a and b, which the layman answers with an explanation generated from the same set of clauses. Then the expert offers a contradicting explanation generated from c and d. To generate dialogue sentences for a corresponding discourse structure we are adapting the approach to paraphrasing of Barzilay and McKeown (2001). 4 Conclusion This short paper presented three angles on the Monologue-to-Dialogue (M2D) task. First, as an opinion piece, it motivates the task of generating expository dialogue from monologue. We described empirical research that provides evidence for the effectiveness of expository dialogue and discussed applications from education, gaming and E-health. Second, we introduced the CODA corpus for addressing the task. Finally, we reported on workin-progress on semi-automatic construction of M2D rules. Our implemented algorithm extracts several M2D rules from the corpus that are applicable eve</context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>R. Barzilay and K. McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proc. ofACL/EACL, Toulouse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Craig</author>
<author>B Gholson</author>
<author>M Ventura</author>
<author>A Graesser</author>
</authors>
<title>and the Tutoring Research Group.</title>
<date>2000</date>
<journal>International Journal of Artificial Intelligence in Education,</journal>
<pages>11--242</pages>
<contexts>
<context position="2326" citStr="Craig et al., 2000" startWordPosition="360" endWordPosition="363">s do need to mesh with each other. The main purpose of expository dialogue is to present information (a description, explanation or definition) to the reader, hearer or viewer, in contrast with dramatic dialogue, which tells a story. The use of expository dialogue goes back as far as Plato (c. 470-399 BC), who expressed his ideas as dialogues between Socrates and his contemporaries. Recently, a number of empirical studies show that for some purposes expository dialogue has advantages over monologue: for learners, dialogue can be more memorable, stimulate them to formulate their own questions (Craig et al., 2000), and get them to talk with each other (Lee et al., 1998). Expository dialogue has also been found to be more effective for persuasion (Suzuki and Yamada, 2004). Additionally, dialogue lends itself very well for multimedia presentations by computer-animated agents (Andr´e et al., 2000; van Deemter et al., 2008). Potential application domains include education, (serious) games and E-Health. In education, information from textbooks could be presented in dialogue form, possibly using virtual reality platforms such as Second Life. Automatically generating dialogue from text for non-player characte</context>
</contexts>
<marker>Craig, Gholson, Ventura, Graesser, 2000</marker>
<rawString>S. Craig, B. Gholson, M. Ventura, A. Graesser, and the Tutoring Research Group. 2000. Overhearing dialogues and monologues in virtual tutoring sessions. International Journal of Artificial Intelligence in Education, 11:242–253.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Demir</author>
<author>S Carberry</author>
<author>K McCoy</author>
</authors>
<title>Generating Textual Summaries of Bar Charts.</title>
<date>2008</date>
<booktitle>In Procs of INLG</booktitle>
<location>Ohio,</location>
<contexts>
<context position="1029" citStr="Demir et al. (2008)" startWordPosition="151" endWordPosition="154">nteresting and rewarding challenge for Natural Language Processing. This short paper has three aims: firstly, to motivate the importance of this task, both in terms of the benefits of expository dialogue as a way to present information and in terms of potential applications; secondly, to introduce a parallel corpus of monologues and dialogues which enables a data-driven approach to this challenge; and, finally, to describe work-in-progress on semi-automatic construction of Monologueto-Dialogue (M2D) generation rules. 1 Introduction The tasks of text generation – e.g., Reiter et al. (2005) and Demir et al. (2008) – and generation in dialogue – e.g., Stent (2002) and DeVault et al. (2008) – are central topics in Natural Language Generation (NLG). What sets the two tasks apart is the interactive nature of dialogue, where participants need to adapt their contributions to each other. This paper introduces an NLG task, the generation of expository dialogue, to the Computational Linguistics community which occupies the middle ground between these two tasks. An expository dialogue is an authored conversation between two fictive characters. It can be presented as text, audio or film. Although there is no real</context>
</contexts>
<marker>Demir, Carberry, McCoy, 2008</marker>
<rawString>S. Demir, S. Carberry, and K. McCoy. 2008. Generating Textual Summaries of Bar Charts. In Procs of INLG 2008, Ohio, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D DeVault</author>
<author>D Traum</author>
<author>R Artstein</author>
</authors>
<title>Making Grammar-Based Generation Easier to Deploy in Dialogue Systems.</title>
<date>2008</date>
<booktitle>In Procs SIGdial</booktitle>
<location>Ohio,</location>
<contexts>
<context position="1105" citStr="DeVault et al. (2008)" startWordPosition="165" endWordPosition="168">hort paper has three aims: firstly, to motivate the importance of this task, both in terms of the benefits of expository dialogue as a way to present information and in terms of potential applications; secondly, to introduce a parallel corpus of monologues and dialogues which enables a data-driven approach to this challenge; and, finally, to describe work-in-progress on semi-automatic construction of Monologueto-Dialogue (M2D) generation rules. 1 Introduction The tasks of text generation – e.g., Reiter et al. (2005) and Demir et al. (2008) – and generation in dialogue – e.g., Stent (2002) and DeVault et al. (2008) – are central topics in Natural Language Generation (NLG). What sets the two tasks apart is the interactive nature of dialogue, where participants need to adapt their contributions to each other. This paper introduces an NLG task, the generation of expository dialogue, to the Computational Linguistics community which occupies the middle ground between these two tasks. An expository dialogue is an authored conversation between two fictive characters. It can be presented as text, audio or film. Although there is no real-time interactivity, in expository dialogue the contributions of the charact</context>
</contexts>
<marker>DeVault, Traum, Artstein, 2008</marker>
<rawString>D. DeVault, D. Traum, and R. Artstein. 2008. Making Grammar-Based Generation Easier to Deploy in Dialogue Systems. In Procs SIGdial 2008, Ohio, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lee</author>
<author>F Dinneen</author>
<author>J McKendree</author>
</authors>
<title>Supporting student discussions: it isn’t just talk.</title>
<date>1998</date>
<booktitle>Education and Information Technologies,</booktitle>
<pages>3--217</pages>
<contexts>
<context position="2383" citStr="Lee et al., 1998" startWordPosition="372" endWordPosition="375">sitory dialogue is to present information (a description, explanation or definition) to the reader, hearer or viewer, in contrast with dramatic dialogue, which tells a story. The use of expository dialogue goes back as far as Plato (c. 470-399 BC), who expressed his ideas as dialogues between Socrates and his contemporaries. Recently, a number of empirical studies show that for some purposes expository dialogue has advantages over monologue: for learners, dialogue can be more memorable, stimulate them to formulate their own questions (Craig et al., 2000), and get them to talk with each other (Lee et al., 1998). Expository dialogue has also been found to be more effective for persuasion (Suzuki and Yamada, 2004). Additionally, dialogue lends itself very well for multimedia presentations by computer-animated agents (Andr´e et al., 2000; van Deemter et al., 2008). Potential application domains include education, (serious) games and E-Health. In education, information from textbooks could be presented in dialogue form, possibly using virtual reality platforms such as Second Life. Automatically generating dialogue from text for non-player characters could have a tremendous impact on the gaming industry;</context>
</contexts>
<marker>Lee, Dinneen, McKendree, 1998</marker>
<rawString>J. Lee, F. Dinneen, and J. McKendree. 1998. Supporting student discussions: it isn’t just talk. Education and Information Technologies, 3:217–229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Piwek</author>
<author>H Hernault</author>
<author>H Prendinger</author>
<author>M Ishizuka</author>
</authors>
<title>T2D: Generating Dialogues between Virtual Agents Automatically from Text.</title>
<date>2007</date>
<booktitle>In Intelligent Virtual Agents, LNAI 4722,</booktitle>
<pages>161--174</pages>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="4225" citStr="Piwek et al. (2007)" startWordPosition="670" endWordPosition="673">tational Linguistics c. Though aspirin does have side effects: d. it can harm circulation. the patient could watch a movie on their mobile device of an exchange between a virtual client (layman, L) and pharmacist (expert, E): (2) L: What if I have a headache? E: You can take aspirin L: But does it have side effects? E: Yes, it can harm circulation. So far, research on generating expository dialogue has been firmly rooted in classical AI approaches. Work in this area starts from knowledge representations or databases (Andr´e et al., 2000), and even research that does take text as input – e.g., Piwek et al. (2007) describe a system for generating dialogues such as Example 2 – relies on handcrafted rules. Two challenges present themselves for NLP research: 1) generation of expository dialogue from text, and 2) use of data-driven, rather than manually authored, generation rules. Apart from the cost of manually authoring generation rules, previous research has found that humanauthored rules can result in ‘too much information [being] given too quickly’ (Williams et al., 2007), which can be addressed by conversational padding. We argue that rather than trying to invent padding rules, the best strategy is t</context>
</contexts>
<marker>Piwek, Hernault, Prendinger, Ishizuka, 2007</marker>
<rawString>P. Piwek, H. Hernault, H. Prendinger, and M. Ishizuka. 2007. T2D: Generating Dialogues between Virtual Agents Automatically from Text. In Intelligent Virtual Agents, LNAI 4722, pages 161–174. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Reiter</author>
<author>S Sripada</author>
<author>J Hunter</author>
<author>J Yu</author>
<author>I Davy</author>
</authors>
<title>Choosing Words in Computer-Generated Weather Forecasts.</title>
<date>2005</date>
<journal>Artificial Intelligence,</journal>
<pages>167--137</pages>
<contexts>
<context position="1005" citStr="Reiter et al. (2005)" startWordPosition="146" endWordPosition="149">is a task that poses an interesting and rewarding challenge for Natural Language Processing. This short paper has three aims: firstly, to motivate the importance of this task, both in terms of the benefits of expository dialogue as a way to present information and in terms of potential applications; secondly, to introduce a parallel corpus of monologues and dialogues which enables a data-driven approach to this challenge; and, finally, to describe work-in-progress on semi-automatic construction of Monologueto-Dialogue (M2D) generation rules. 1 Introduction The tasks of text generation – e.g., Reiter et al. (2005) and Demir et al. (2008) – and generation in dialogue – e.g., Stent (2002) and DeVault et al. (2008) – are central topics in Natural Language Generation (NLG). What sets the two tasks apart is the interactive nature of dialogue, where participants need to adapt their contributions to each other. This paper introduces an NLG task, the generation of expository dialogue, to the Computational Linguistics community which occupies the middle ground between these two tasks. An expository dialogue is an authored conversation between two fictive characters. It can be presented as text, audio or film. A</context>
</contexts>
<marker>Reiter, Sripada, Hunter, Yu, Davy, 2005</marker>
<rawString>E. Reiter, S. Sripada, J. Hunter, J. Yu, and I. Davy. 2005. Choosing Words in Computer-Generated Weather Forecasts. Artificial Intelligence, 167:137–169.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Rus</author>
<author>A Graesser</author>
<author>editors</author>
</authors>
<title>The Question Generation Shared Task and Evaluation Challenge. The University of Memphis. Available at: http://www.questiongeneration.org/.</title>
<date>2009</date>
<marker>Rus, Graesser, editors, 2009</marker>
<rawString>V. Rus and A. Graesser, editors. 2009. The Question Generation Shared Task and Evaluation Challenge. The University of Memphis. Available at: http://www.questiongeneration.org/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>IGDA Game Writers SIG</author>
</authors>
<title>International game developers association’s (IGDA) guide to writing for games. IGDA White Paper.</title>
<date>2003</date>
<contexts>
<context position="3019" citStr="SIG, 2003" startWordPosition="468" endWordPosition="469">also been found to be more effective for persuasion (Suzuki and Yamada, 2004). Additionally, dialogue lends itself very well for multimedia presentations by computer-animated agents (Andr´e et al., 2000; van Deemter et al., 2008). Potential application domains include education, (serious) games and E-Health. In education, information from textbooks could be presented in dialogue form, possibly using virtual reality platforms such as Second Life. Automatically generating dialogue from text for non-player characters could have a tremendous impact on the gaming industry; e.g., (IGDA Game Writers SIG, 2003) state that the amount of dialogue script for a characterdriven computer game is usually many times that for the average film. In connection with E-health, consider patient information leaflets, which are often left unread; presenting them as movies between a virtual pharmacist and client may help address this. Thus instead of being presented with (1) a. You can take aspirin, b. if you have a headache. 333 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 333–336, Los Angeles, California, June 2010. c�2010 Association for Computational Ling</context>
</contexts>
<marker>SIG, 2003</marker>
<rawString>IGDA Game Writers SIG. 2003. International game developers association’s (IGDA) guide to writing for games. IGDA White Paper.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stent</author>
</authors>
<title>A conversation acts model for generating spoken dialogue contributions.</title>
<date>2002</date>
<journal>Computer Speech and Language,</journal>
<pages>16--3</pages>
<contexts>
<context position="1079" citStr="Stent (2002)" startWordPosition="162" endWordPosition="163">rocessing. This short paper has three aims: firstly, to motivate the importance of this task, both in terms of the benefits of expository dialogue as a way to present information and in terms of potential applications; secondly, to introduce a parallel corpus of monologues and dialogues which enables a data-driven approach to this challenge; and, finally, to describe work-in-progress on semi-automatic construction of Monologueto-Dialogue (M2D) generation rules. 1 Introduction The tasks of text generation – e.g., Reiter et al. (2005) and Demir et al. (2008) – and generation in dialogue – e.g., Stent (2002) and DeVault et al. (2008) – are central topics in Natural Language Generation (NLG). What sets the two tasks apart is the interactive nature of dialogue, where participants need to adapt their contributions to each other. This paper introduces an NLG task, the generation of expository dialogue, to the Computational Linguistics community which occupies the middle ground between these two tasks. An expository dialogue is an authored conversation between two fictive characters. It can be presented as text, audio or film. Although there is no real-time interactivity, in expository dialogue the co</context>
</contexts>
<marker>Stent, 2002</marker>
<rawString>A. Stent. 2002. A conversation acts model for generating spoken dialogue contributions. Computer Speech and Language, 16(3-4):313–352.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Stoyanchev</author>
<author>P Piwek</author>
</authors>
<title>Constructing the CODA corpus.</title>
<date>2010</date>
<booktitle>In Procs of LREC 2010,</booktitle>
<location>Malta,</location>
<contexts>
<context position="7534" citStr="Stoyanchev and Piwek, 2010" startWordPosition="1215" endWordPosition="1218"> turns from “What is man?”, a dialogue by Mark Twain, and 88 turns from “Evolving Algebras”, an academic paper in the form of dialogue by Yuri Gurevich.4 Both of these expository dialogues present conversation between an expert (Old Man in Twain and Author in Gurevich) and a layman (Young Man in Twain and Quisani in Gurevich). Table 1 shows an example of a dialogue fragment, aligned monologue and dialogue act annotations. The discourse structure of the monologue is depicted in Figure 1. Table 2 shows the distribution of the dialogue acts between expert and layman. In both dialogues, the 3See (Stoyanchev and Piwek, 2010) for details. 4In addition to these dialogues we are working on a dialogue by Berkeley (Three Dialogues between Hylas and Philonous) and a selection of shorter fragments (for copyrights reasons) by authors such as Douglas Hofstadter and Paul Feyerabend. 334 Figure 1: Discourse structure of the monologue in Table 1 most frequent dialogue act is Explain, where a character presents information (as a new idea or as a response to another utterance). Also, in both dialogues the layman asks more often for clarification than the expert. The distribution over information requests (yes/no, factoid, and </context>
</contexts>
<marker>Stoyanchev, Piwek, 2010</marker>
<rawString>S. Stoyanchev and P. Piwek. 2010. Constructing the CODA corpus. In Procs of LREC 2010, Malta, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S V Suzuki</author>
<author>S Yamada</author>
</authors>
<title>Persuasion through overheard communication by life-like agents.</title>
<date>2004</date>
<booktitle>In Procs of the 2004 IEEE/WIC/ACM International Conference on Intelligent Agent Technology,</booktitle>
<location>Beijing,</location>
<contexts>
<context position="2486" citStr="Suzuki and Yamada, 2004" startWordPosition="388" endWordPosition="391">er, hearer or viewer, in contrast with dramatic dialogue, which tells a story. The use of expository dialogue goes back as far as Plato (c. 470-399 BC), who expressed his ideas as dialogues between Socrates and his contemporaries. Recently, a number of empirical studies show that for some purposes expository dialogue has advantages over monologue: for learners, dialogue can be more memorable, stimulate them to formulate their own questions (Craig et al., 2000), and get them to talk with each other (Lee et al., 1998). Expository dialogue has also been found to be more effective for persuasion (Suzuki and Yamada, 2004). Additionally, dialogue lends itself very well for multimedia presentations by computer-animated agents (Andr´e et al., 2000; van Deemter et al., 2008). Potential application domains include education, (serious) games and E-Health. In education, information from textbooks could be presented in dialogue form, possibly using virtual reality platforms such as Second Life. Automatically generating dialogue from text for non-player characters could have a tremendous impact on the gaming industry; e.g., (IGDA Game Writers SIG, 2003) state that the amount of dialogue script for a characterdriven com</context>
</contexts>
<marker>Suzuki, Yamada, 2004</marker>
<rawString>S. V. Suzuki and S. Yamada. 2004. Persuasion through overheard communication by life-like agents. In Procs of the 2004 IEEE/WIC/ACM International Conference on Intelligent Agent Technology, Beijing, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K van Deemter</author>
<author>B Krenn</author>
<author>P Piwek</author>
<author>M Klesen</author>
<author>M Schr¨oder</author>
<author>S Baumann</author>
</authors>
<title>Fully generated scripted dialogue for embodied agents.</title>
<date>2008</date>
<journal>Artificial Intelligence Journal,</journal>
<volume>172</volume>
<issue>10</issue>
<marker>van Deemter, Krenn, Piwek, Klesen, Schr¨oder, Baumann, 2008</marker>
<rawString>K. van Deemter, B. Krenn, P. Piwek, M. Klesen, M. Schr¨oder, and S. Baumann. 2008. Fully generated scripted dialogue for embodied agents. Artificial Intelligence Journal, 172(10):1219–1244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Williams</author>
<author>P Piwek</author>
<author>R Power</author>
</authors>
<title>Generating Monologue and Dialogue to Present Personalised Medical Information to Patients.</title>
<date>2007</date>
<booktitle>In Procs ENLG</booktitle>
<pages>167--170</pages>
<location>Schloss Dagstuhl, Germany.</location>
<contexts>
<context position="4693" citStr="Williams et al., 2007" startWordPosition="743" endWordPosition="746"> area starts from knowledge representations or databases (Andr´e et al., 2000), and even research that does take text as input – e.g., Piwek et al. (2007) describe a system for generating dialogues such as Example 2 – relies on handcrafted rules. Two challenges present themselves for NLP research: 1) generation of expository dialogue from text, and 2) use of data-driven, rather than manually authored, generation rules. Apart from the cost of manually authoring generation rules, previous research has found that humanauthored rules can result in ‘too much information [being] given too quickly’ (Williams et al., 2007), which can be addressed by conversational padding. We argue that rather than trying to invent padding rules, the best strategy is to learn rules automatically from professionally authored dialogues. 2 The CODA Corpus To make inroads into data-driven dialogue generation, we first need to have the necessary resources. We propose to view Monologue-to-Dialogue (M2D) generation as analogous to machine translation; consequently we need a parallel corpus for learning mappings from the source (monologue) to the target (dialogue) texts. In the ongoing CODA1 project we have created such a corpus. It co</context>
</contexts>
<marker>Williams, Piwek, Power, 2007</marker>
<rawString>S. Williams, P. Piwek, and R. Power. 2007. Generating Monologue and Dialogue to Present Personalised Medical Information to Patients. In Procs ENLG 2007, pages 167–170, Schloss Dagstuhl, Germany.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>