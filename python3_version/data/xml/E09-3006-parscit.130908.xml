<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001239">
<title confidence="0.998284">
A Chain-starting Classifier of Definite NPs in Spanish
</title>
<author confidence="0.983737">
Marta Recasens
</author>
<affiliation confidence="0.992951">
CLiC - Centre de Llenguatge i Computaci´o
Department of Linguistics
University of Barcelona
</affiliation>
<address confidence="0.921902">
08007 Barcelona, Spain
</address>
<email confidence="0.999636">
mrecasens@ub.edu
</email>
<sectionHeader confidence="0.993918" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999874">
Given the great amount of definite noun
phrases that introduce an entity into the
text for the first time, this paper presents a
set of linguistic features that can be used
to detect this type of definites in Span-
ish. The efficiency of the different fea-
tures is tested by building a rule-based and
a learning-based chain-starting classifier.
Results suggest that the classifier, which
achieves high precision at the cost of re-
call, can be incorporated as either a filter
or an additional feature within a corefer-
ence resolution system to boost its perfor-
mance.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.973045964912281">
Although often treated together, anaphoric pro-
noun resolution differs from coreference resolu-
tion (van Deemter and Kibble, 2000). Whereas
the former attempts to find an antecedent for each
anaphoric pronoun in a discourse, the latter aims
to build full coreference chains, namely linking
all noun phrases (NPs) – whether pronominal or
with a nominal head – that point to the same en-
tity. The output of anaphora resolution1 are noun-
pronoun pairs (or pairs of a discourse segment and
a pronoun in some cases), whereas the output of
coreference resolution are chains containing a va-
riety of items: pronouns, full NPs, discourse seg-
ments... Thus, coreference resolution requires a
wider range of strategies in order to build the full
chains of coreferent mentions.2
1A different matter is the resolution of anaphoric full NPs,
i.e. those semantically dependent on a previous mention.
2We follow the ACE terminology (NIST, 2003) but in-
stead of talking of objects in the world we talk of objects in
the discourse model: we use entity for an object or set of ob-
jects in the discourse model, and mention for a reference to
an entity.
One of the problems specific to coreference res-
olution is determining, once a mention is encoun-
tered by the system, whether it refers to an entity
previously mentioned or it introduces a new entity
into the text. Many algorithms (Aone and Ben-
nett, 1996; Soon et al., 2001; Yang et al., 2003)
do not address this issue specifically, but implic-
itly assume all mentions to be potentially corefer-
ent and examine all possible combinations; only
if the system fails to link a mention with an al-
ready existing entity, it is considered to be chain
starting.3 However, such an approach is computa-
tionally expensive and prone to errors, since nat-
ural language is populated with a huge number of
entities that appear just once in the text. Even def-
inite NPs, which are traditionally believed to refer
to old entities, have been demonstrated to start a
coreference chain over 50% of the times (Fraurud,
1990; Poesio and Vieira, 1998).
An alternative line of research has considered
applying a filter prior to coreference resolution
that classifies mentions as either chain starting or
coreferent. Ng and Cardie (2002) and Poesio et al.
(2005) have tested the impact of such a detector
on the overall coreference resolution performance
with encouraging results. Our chain-starting clas-
sifier is comparable – despite some differences4
– to the detectors suggested by Ng and Cardie
(2002), Uryupina (2003), and Poesio et al. (2005)
for English, but not identical to strictly anaphoric
ones5 (Bean and Riloff, 1999; Uryupina, 2003),
since a non-anaphoric NP can corefer with a pre-
vious mention.
This paper presents a corpus-based study of def-
</bodyText>
<footnote confidence="0.9891995">
3By chain starting we refer to those mentions that are the
first element – and might be the only one – in a coreference
chain.
4Ng and Cardie (2002) and Uryupina (2003) do not limit
to definite NPs but deal with all types of NPs.
5Notice the confusing use of the term anaphoric in (Ng
and Cardie, 2002) for describing their chain-starting filtering
module.
</footnote>
<note confidence="0.969785">
Proceedings of the EACL 2009 Student Research Workshop, pages 46–53,
Athens, Greece, 2 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.999448">
46
</page>
<bodyText confidence="0.9997265625">
inite NPs in Spanish that results in a set of eight
features that can be used to identify chain-starting
definite NPs. The heuristics are tested by building
two different chain-starting classifiers for Spanish,
a rule-based and a learning-based one. The evalu-
ation gives priority to precision over recall in view
of the classifier’s efficiency as a filtering module.
The paper proceeds as follows. Section 2 pro-
vides a qualitative comparison with related work.
The corpus study and the empirically driven set of
heuristics for recognizing chain-starting definites
are described in Section 3. The chain-starting clas-
sifiers are built in Section 4. Section 5 reports on
the evaluation and discusses its implications. Fi-
nally, Section 6 summarizes the conclusions and
outlines future work.
</bodyText>
<sectionHeader confidence="0.999782" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999499534246575">
Some of the corpus-driven features here presented
have a precedent in earlier classifiers of this kind
for English while others are our own contribution.
In any case, they have been adapted and tested for
Spanish for the first time.
We build a list of storage units, which is in-
spired by research in the field of cognitive linguis-
tics. Bean and Riloff (1999) and Uryupina (2003)
have already employed a definite probability mea-
sure in a similar way, although the way the ratio
is computed is slightly different. The former use
it to make a “definite-only list” by ranking those
definites extracted from a corpus that were ob-
served at least five times and never in an indefi-
nite construction. In contrast, the latter computes
four definite probabilities – which are included
as features within a machine-learning classifier –
from the Web in an attempt to overcome Bean and
Riloff’s (1999) data sparseness problem. The defi-
nite probabilities in our approach are checked with
confidence intervals in order to guarantee the reli-
ability of the results, avoiding to draw any gener-
alization when the corpus does not contain a large
enough sample.
The heuristics concerning named entities and
storage-unit variants find an equivalent in the fea-
tures used in Ng and Cardie’s (2002) supervised
classifier that represent whether the mention is a
proper name (determined based on capitalization,
whereas our corpus includes both weak and strong
named entities) and whether a previous NP is an
alias of the current mention (on the basis of a rule-
based alias module that tries out different transfor-
mations). Uryupina (2003) and Vieira and Poesio
(2000) also take capital and low case letters into
account.
All four approaches exploit syntactic structural
cues of pre- and post- modification to detect com-
plex NPs, as they are considered to be unlikely to
have been previously mentioned in the discourse.
A more fine-grained distinction is made by Bean
and Riloff (1999) and Vieira and Poesio (2000)
to distinguish restrictive from non-restrictive post-
modification by ommitting those modifiers that
occur between commas, which should not be clas-
sified as chain starting. The latter also list a series
of “special predicates” including nouns like fact
or result, and adjectives such as first, best, only,
etc. A subset of the feature vectors used by Ng
and Cardie (2002) and Uryupina (2003) is meant
to code whether the NP is or not modified. In
this respect, our contribution lies in adapting these
ideas for the way modification occurs in Spanish
– where premodifiers are rare – and in introducing
a distinction between PP and AP modifiers, which
we correlate in turn with the heads of simple defi-
nites.
We borrow the idea of classifying definites oc-
curring in the first sentence as chain starting from
Bean and Riloff (1999).
The precision and recall results obtained by
these classifiers – tested on MUC corpora – are
around the eighties, and around the seventies in
the case of Vieira and Poesio (2000), who use the
Penn Treebank.
Luo et al. (2004) make use of both a linking
and a starting probability in their Bell tree algo-
rithm for coreference resolution, but the starting
probability happens to be the complementary of
the linking one. The chain-starting classifier we
build can be used to fine-tune the starting probabil-
ity used in the construction of coreference chains
in Luo et al.’s (2004) style.
</bodyText>
<sectionHeader confidence="0.991495" genericHeader="method">
3 Corpus-based Study
</sectionHeader>
<bodyText confidence="0.999995555555556">
As fully documented by Lyons (1999), definite-
ness varies cross-linguistically. In contrast with
English, for instance, Spanish adds the article be-
fore generic NPs (1), within some fixed phrases
(2), and in postmodifiers where English makes use
of bare nominal premodification (3). Altogether
results in a larger number of definite NPs in Span-
ish and, by extension, a larger number of chain-
starting definites (Recasens et al., 2009).
</bodyText>
<page confidence="0.99442">
47
</page>
<figure confidence="0.805055125">
(1) Tard´ıa incorporaci´on
Late incorporation
‘Late incorporation of 0 women into m work.’
(2) Villalobos dio
Villalobos gave
‘Villalobos gave m thanks to the militants.’
(3) El mercado internacional
The market international
</figure>
<subsectionHeader confidence="0.649277">
‘The international m coffee market.’
</subsectionHeader>
<bodyText confidence="0.999115058823529">
Long-held claims that equate the definite arti-
cle with a specific category of meaning cannot be
hold. The present-day definite article is a cate-
gory that, although it did originally have a seman-
tic meaning of “identifiability”, has increased its
range of contexts so that it is often a grammati-
cal rather than a semantic category (Lyons, 1999).
Definite NPs cannot be considered anaphoric by
default, but strategies need to be introduced in or-
der to classify a definite as either a chain-starting
or a coreferent mention. Given that the extent
of grammaticization6 varies from language to lan-
guage, we considered it appropriate to conduct a
corpus study oriented to Spanish: (i) to check the
extent to which strategies used in previous work
can be extended to Spanish, and (ii) to explore ad-
ditional linguistic cues.
</bodyText>
<subsectionHeader confidence="0.999258">
3.1 The corpus
</subsectionHeader>
<bodyText confidence="0.999990416666667">
The empirical data used in our corpus study come
from AnCora-Es, the Spanish corpus of AnCora
– Annotated Corpora for Spanish and Catalan
(Taule et al., 2008), developed at the University
of Barcelona and freely available from http:
//clic.ub.edu/ancora. AnCora-Es is a
half-million-word multilevel corpus consisting of
newspaper articles and annotated, among other
levels of information, with PoS tags, syntactic
constituents and functions, and named entities. A
subset of 320 000 tokens (72 500 full NPs7) was
used to draw linguistic features about definiteness.
</bodyText>
<subsectionHeader confidence="0.991194">
3.2 Features
</subsectionHeader>
<bodyText confidence="0.985107428571428">
As quantitatively supported by the figures in Ta-
ble 1, the split between simple (i.e. non-modified)
and complex NPs seems to be linguistically rele-
vant. We assume that the referential properties of
6Grammaticization, or grammaticalization, is a process
of linguistic change by which a content word becomes part
of the grammar by losing its lexical and phonological load.
7By full NPs we mean NPs with a nominal head, thus
omitting pronouns, NPs with an elliptical head as well as co-
ordinated NPs.
simple NPs differ from complex ones, and this dis-
tinction is kept when designing the eight heuristics
for recognizing chain-starting definites that we in-
troduce in this section.
</bodyText>
<listItem confidence="0.678563">
1. Head match. Ruling out those definites that
match an earlier noun in the text has proved
to be able to filter out a considerable num-
ber of coreferent mentions (Ng and Cardie,
2002; Poesio et al., 2005). We considered
</listItem>
<bodyText confidence="0.915251775510204">
both total and partial head match, but stuck
to the first as the second brought much noise.
On its own, namely if definite NPs are all
classified as chain starting only if no mention
has previously appeared with the same lexical
head, we obtain a precision (P) not less than
84.95% together with 89.68% recall (R). Our
purpose was to increase P as much as pos-
sible with the minimum loss in R: it is pre-
ferred not to classify a chain-starting instance
– which can still be detected by the corefer-
ence resolution module at a later stage – since
a wrong label might result in a missed coref-
erence link.
2. Storage units. A very grammaticized defi-
nite article accounts for the large number of
definite NPs attested in Spanish (column 2 in
Table 1): 46% of the total. In the light of
Bybee and Hopper’s (2001) claim that lan-
guage structure dynamically results from fre-
quency and repetition, we hypothesized that
specific simple definite NPs in which the ar-
ticle has fully grammaticized constitute what
Bybee and Hopper (2001) call storage units:
the more a specific chunk is used, the more
stored and automatized it becomes. These
article-noun storage units might well head a
coreference chain.
With a view to providing the chain-starting
classifier with a list of these article-noun
storage units, we extracted from AnCora-Es
all simple NPs preceded by a determiner8
(columns 2 and 3 in the second row of Table
1) and ranked them by their definite probabil-
ity, which we define as the number of simple
definite NPs with respect to the number of
simple determined NPs. Secondly, we set a
threshold of 0.7, considering as storage units
8Only noun types occurring a minimum of ten times were
included in this study. Singular and plural forms as well as
masculine and feminine were kept as distinct types.
de la mujer al trabajo.
of the woman to the work.
las gracias a los militantes.
the thanks to the militants.
del
of the
caf´e.
coffee.
</bodyText>
<page confidence="0.98737">
48
</page>
<table confidence="0.99938925">
Definite NPs Other det. NPs Bare NPs Total
Simple NPs 12 739 6 642 15 183 34564 (48%)
Complex NPs 20 447 9 545 8 068 38060 (52%)
Total 33186 (46%) 16187 (22%) 23 251 (32%) 72624 (100%)
</table>
<tableCaption confidence="0.999631">
Table 1: Overall distribution of full NPs in AnCora-Es (subset).
</tableCaption>
<bodyText confidence="0.998963857142857">
those definites above the threshold. In order
to avoid biased probabilities due to a small
number of observed examples in the corpus, a
95 percent confidence interval was computed.
The final list includes 191 storage units, such
as la UE ‘the EU’, el euro ‘the euro’, los con-
sumidores ‘the consumers’, etc.
</bodyText>
<listItem confidence="0.99459975">
3. Named entities (NEs). A closer look at the
list of storage units revealed that the higher
the definite probability, the more NE-like a
noun is. This led us to extrapolate that the
definite article has completely grammaticized
(i.e. lost its semantic load) before simple def-
inites which are NEs (e.g. los setenta ‘the
seventies’, el Congreso de Estados Unidos
‘the U.S. Congress’9), and so they are likely
to be chain-starting.
4. Storage-unit variants. The fact that some
of the extracted storage units were variants
of a same entity gave us an additional cue:
complementing the plain head_match feature
by adding a gazetteer with variants (e.g. la
Uni´on Europea ‘the European Union’ and la
UE ‘the EU’) stops the storage_unit heuris-
tic from classifying a simple definite as chain
starting if a previous equivalent unit has ap-
peared.
5. First sentence. Given that the probability
for any definite NP occurring in the first sen-
tence of a text to be chain starting is very
high, since there has not been time to intro-
duce many entities, all definites appearing in
the first sentence can be classified as chain
starting.
6. AP-preference nouns. Complex definites
represent 62% out of all definite NPs (Table
1). In order to assess to what extent the refer-
ential properties of a noun on its own depend
on its combinatorial potential to occur with
</listItem>
<footnote confidence="0.810291">
9The underscore represents multiword expressions.
</footnote>
<bodyText confidence="0.982107162790698">
either a prepositional phrase (PP) or an ad-
jectival phrase (AP), complex definites were
grouped into those containing a PP (49%) and
those containing an AP10 (27%). Next, the
probability for each noun to be modified by a
PP or an AP was computed. The results made
it possible to draw a distinction – and two re-
spective lists – between PP-preference nouns
(e.g. el inicio ‘the beginning’) and nouns that
prefer an AP modifier (e.g. las autoridades
‘the authorities’). Given that APs are not as
informative as PPs, they are more likely to
modify storage units than PPs. Nouns with
a preference for APs turned out to be storage
units or behave similarly. Thus, simple defi-
nites headed by such nouns are unlikely to be
coreferent.
7. PP-preference nouns. Nouns that prefer to
combine with a PP are those that depend on
an extra argument to become referential. This
argument, however, might not appear as a
nominal modifier but be recoverable from the
discourse context, either explicitly or implic-
itly. Therefore, a simple definite headed by
a PP-preference noun might be anaphoric but
not necessarily a coreferent mention. Thus,
grouping PP-preference nouns offers an em-
pirical way for capturing those nouns that are
bridging anaphors when they appear in a sim-
ple definite. For instance, it is not rare that,
once a specific company has been introduced
into the text, reference is made for the first
time to its director simply as el director ‘the
director’.
8. Neuter definites. Unlike English, the Span-
ish definite article is marked for grammati-
cal gender. Nouns might be either mascu-
line or feminine, but a third type of definite
article, the neuter one (lo), is used to nomi-
nalize adjectives and clauses, namely “to cre-
ate a referential entity” out of a non-nominal
10When a noun was followed by more than one modifier,
only the syntactic type of the first one was taken into account.
</bodyText>
<page confidence="0.999008">
49
</page>
<bodyText confidence="0.984119">
Given a definite mention m,
</bodyText>
<listItem confidence="0.973598666666667">
1. If m is introduced by a neuter definite article, classify
as chain starting.
2. If m appears in the first sentence of the document, clas-
sify as chain starting.
3. If m shares the same lexical head with a previous men-
tion or is a storage-unit variant of it, classify as coref-
erent.
4. If the head of m is PP-preference, classify as chain
starting.
5. If m is a simple definite,
(a) and the head of m appears in the list of storage
units, classify as chain starting.
(b) and the head of m is AP-preference, classify as
chain starting.
(c) and m is an NE, classify as chain starting.
(d) Otherwise, classify as coreferent.
6. Otherwise (i.e. m is a complex definite), classify as
chain starting.
</listItem>
<figureCaption confidence="0.999751">
Figure 1: Rule-based algorithm.
</figureCaption>
<bodyText confidence="0.997255333333333">
item. Since such neuters have a low corefer-
ential capacity, the classification of these NPs
as chain starting can favour recall.
</bodyText>
<sectionHeader confidence="0.9924" genericHeader="method">
4 Chain-starting Classifier
</sectionHeader>
<bodyText confidence="0.9999822">
In order to test the linguistic cues outlined above,
we build two different chain-starting classifiers: a
rule-based model and a learning-based one. Both
aim to detect those definite NPs for which there is
no need to look for a previous reference.
</bodyText>
<subsectionHeader confidence="0.993143">
4.1 Rule-based approach
</subsectionHeader>
<bodyText confidence="0.9999922">
The first way in which the linguistic findings in
Section 3.2 are tested is by building a rule-based
classifier. The heuristics are combined and or-
dered in the most efficient way, yielding the hand-
crafted algorithm shown in Figure 1. Two main
principles underlie the algorithm: (i) simple defi-
nites tend to be coreferent mentions, and (ii) com-
plex definites tend to be chain starting (if their
head has not previously appeared). Accordingly,
Step 5 in Figure 1 finishes by classifying simple
definites as coreferent, and Step 6 complex def-
inites as chain starting. Before these last steps,
however, a series of filters are applied correspond-
ing to the different heuristics. The performance is
presented in Table 2.
</bodyText>
<subsectionHeader confidence="0.998302">
4.2 Machine-learning approach
</subsectionHeader>
<bodyText confidence="0.999982714285714">
The second way in which the suggested linguistic
cues are tested is by constructing a learning-based
classifier. The Weka machine learning toolkit
(Witten and Frank, 2005) is used to train a J48
decision tree on a 10-fold cross-validation. A to-
tal of eight learning features are considered: (i)
head match, (ii) storage-unit variant, (iii) is a
neuter definite, (iv) is first sentence, (v) is a PP-
preference noun, (vi) is a storage unit, (vii) is
an AP-preference noun, (viii) is an NE. All fea-
tures are binary (either “yes” or “no”). We experi-
ment with different feature vectors, incrementally
adding one feature at a time. The performance is
presented in Table 3.
</bodyText>
<sectionHeader confidence="0.998654" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.99975495">
A subset of AnCora-CO-Es consisting of 60 Span-
ish newspaper articles (23 335 tokens, 5 747 full
NPs) is kept apart for the test corpus. AnCora-
CO-Es is the coreferentially annotated AnCora-Es
corpus, following the guidelines described in (Re-
casens et al., 2007). Coreference relations were
annotated manually with the aid of the PALinkA
(Orasan, 2003) and AnCoraPipe (Bertran et al.,
2008) tools. Interestingly enough, the test corpus
contains 2 575 definite NPs, out of which 1889 are
chain-starting (1401 chain-starting definite NPs
are actually isolated entities), namely 73% defi-
nites head a coreference chain, which implies that
a successful classifier has the potential to rule out
almost three quarters of all definite mentions.
Given that chain starting is the majority class
and following (Ng and Cardie, 2002), we took the
“one class” classification as a naive baseline: all
instances were classified as chain starting, giving
a precision of 71.95% (first row in Tables 2 and 3).
</bodyText>
<subsectionHeader confidence="0.991579">
5.1 Performance
</subsectionHeader>
<bodyText confidence="0.999768">
Tables 2 and 3 show the results in terms of preci-
sion (P), recall (R), and F0.5-measure (F0.5). F0.5-
measure,11 which weights P twice as much as R,
is chosen since this classifier is designed as a filter
for a coreference resolution module and hence we
want to make sure that the discarded cases can be
really discarded. P matters more than R.
Each row incrementally adds a new heuristic to
the previous ones. The score is cumulative. No-
tice that the order of the features in Table 2 does
</bodyText>
<footnote confidence="0.892812">
11F0.5 is computed as 1.5PR0.5P+R.
</footnote>
<page confidence="0.968074">
50
</page>
<table confidence="0.9999255">
Cumulative Features P (%) R (%) F0.5 (%)
Baseline 71.95 100.0 79.37
+Head match 84.95 89.68 86.47
+Storage-unit variant 85.02 89.58 86.49
+Neuter definite 85.08 90.05 86.68
+First sentence 85.12 90.32 86.79
+PP preference 85.12 90.32 86.79
+Storage unit 89.65** 71.54** 82.67
+AP preference 89.70** 71.96** 82.89
+Named entity 89.20* 78.22** 85.21
</table>
<tableCaption confidence="0.976285">
Table 2: Performance of the rule-based classifier.
</tableCaption>
<table confidence="0.9999616">
Cumulative Features P (%) R (%) F0.5 (%)
Baseline 71.95 100.0 79.37
+Head match 85.00 89.70 86.51
+Storage-unit variant 85.00 89.70 86.51
+Neuter definite 85.00 90.20 86.67
+First sentence 85.10 90.40 86.80
+PP preference 85.10 90.40 86.80
+Storage unit 83.80 93.50** 86.80
+AP preference 83.90 93.60** 86.90
+Named entity 83.90 93.60** 86.90
</table>
<tableCaption confidence="0.819646">
Table 3: Performance of the learning-based classi-
fier (J48 decision tree).
</tableCaption>
<bodyText confidence="0.999844615384615">
not directly map the order as presented in the algo-
rithm (Figure 1): the head_match heuristic and the
storage-unit_variant need to be applied first, since
the other heuristics function as filters that are ef-
fective only if head match between the mentions
has been first checked. Table 3 presents the incre-
mental performance of the learning-based classi-
fier for the different sets of features.
Diacritics ** (p&lt;.01) and * (p&lt;.05) indicate
whether differences in P and R between the re-
duced classifier (head_ match) and the extended
ones are significant (using a one-way ANOVA fol-
lowed by Tukey’s post-hoc test).
</bodyText>
<subsectionHeader confidence="0.99473">
5.2 Discussion
</subsectionHeader>
<bodyText confidence="0.999972486486486">
Although the central role played by the
head_match feature has been emphasized by
prior work, it is striking that such a simple heuris-
tic achieves results over 85%, raising P by 13
percentage points. All in all, these figures can only
be slightly improved by some of the additional
features. These features have a different effect
on each approach: whereas they improve P (and
decrease R) in the hand-crafted algorithm, they
improve R (and decrease P) in the decision tree.
In the first case, the highest R is achieved with
the first four features, and the last three features
obtain an increase in P statistically significant yet
accompanied by a decrease in R also statistically
significant. We expected that the second block of
features would favour P without such a significant
drop in R.
The drop in P in the decision tree is not statis-
tically significant as it is in the rule-based classi-
fier. Our goal, however, was to increase P as much
as possible, since false positive errors harm the
performance of the subsequent coreference resolu-
tion system much more than false negative errors,
which can still be detected at a later stage. The
very same attributes might prove more efficient if
used as additional learning features within the vec-
tor of a coreference resolution system rather than
as an independent pre-classifier.
From a linguistic perspective, the fact that the
linguistic heuristics increase P provides support
for the hypotheses about the grammaticized def-
inite article and the existence of storage units.
We carried out an error analysis to consider those
cases in which the features are misleading in terms
of precision errors. The first_sentence feature, for
instance, results in an error in (4), where the first
sentence includes a coreferent NP.
</bodyText>
<listItem confidence="0.499438">
(4) La expansi´on de la pirater´ıa en el Sudeste de Asia
</listItem>
<bodyText confidence="0.987199444444445">
puede destruir las econom´ıas de la regi´on.
‘The expansion of piracy in South-East Asia can de-
stroy the economies of the region.’
Classifying PP-preference nouns as chain starting
fails when a noun like el protagonista ‘the pro-
tagonist’, which could appear as the first mention
in a film critique, happens to be previously men-
tioned with a different head. Likewise, not using
the same head in cases such as la competici´on ‘the
competition’ and la Liga ‘the League’ accounts
for the failure of the storage_unit or named_entity
feature, which classify the second mention as
chain starting. On the other hand, some recall er-
rors are due to head_match, which might link two
NPs that despite sharing the same head point to a
different entity (e.g. el grupo Agnelli ‘the Agnelli
group’ and el grupo industrial Montedison ‘the in-
dustrial group Montedison’).
</bodyText>
<sectionHeader confidence="0.998962" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.9999966">
The paper presented a corpus-driven chain-
starting classifier of definite NPs for Spanish,
pointing out and empirically supporting a series
of linguistic features to be taken into account.
Given that definiteness is very much language de-
</bodyText>
<page confidence="0.994809">
51
</page>
<bodyText confidence="0.99997672881356">
pendent, the AnCora-Es corpus was mined to in-
fer some linguistic hypotheses that could help in
the automatic identification of chain-starting def-
inites. The information from different linguistic
levels (lexical, semantic, morphological, syntac-
tic, and pragmatic) in a computationally not ex-
pensive way casts light on potential features help-
ful for resolving coreference links. Each resulting
heuristic managed to improve precision although
at the cost of a drop in recall. The highest improve-
ment in precision (89.20%) with the lowest loss
in recall (78.22%) translates into an F0.5-measure
of 85.21%. Hence, the incorporation of linguistic
knowledge manages to outperform the baseline by
17 percentage points in precision.
Priority is given to precision, since we want to
assure that the filter prior to coreference resolu-
tion module does not label as chain starting def-
inite NPs that are coreferent. The classifier was
thus designed to minimize false positives. No less
than 73% of definite NPs in the data set are chain
starting, so detecting 78% of these definites with
almost 90% precision could have substantial sav-
ings. From a linguistic perspective, the improve-
ment in precision supports the linguistic hypothe-
ses, even if at the expense of recall. However, as
this classifier is not a final but a prior module, ei-
ther a filter within a rule-based system or one ad-
ditional feature within a larger learning-based sys-
tem, the shortage of recall can be compensated
at the coreference resolution stage by considering
other more sophisticated features.
The results here presented are not comparable
with other existing classifiers of this type for sev-
eral reasons. Our approach would perform differ-
ently for English, which has a lower number of
definite NPs. Secondly, our classifier has been
evaluated on a corpus much larger than prior ones
such as Uryupina’s (2003). Thirdly, some classi-
fiers aim at detecting non-anaphoric NPs, which
are not the same as chain-starting. Fourthly, we
have empirically explored the contribution of the
set of heuristics with respect to the head_match
feature. None of the existing approaches com-
pares its final performance in relation with this
simple but extremely powerful feature. Some of
our heuristics do draw on previous work, but we
have tuned them for Spanish and we have also con-
tributed with new ideas, such as the use of storage
units and the preference of some nouns for a spe-
cific syntactic type of modifier.
As future work, we will adapt this chain-starting
classifier for Catalan, fine-tune the set of heuris-
tics, and explore to what extent the inclusion of
such a classifier improves the overall performance
of a coreference resolution system for Spanish.
Alternatively, we will consider using the sug-
gested attributes as part of a larger set of learning
features for coreference resolution.
</bodyText>
<sectionHeader confidence="0.998278" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998642857142857">
We would like to thank the three anonymous
reviewers for their suggestions for improve-
ment. This paper has been supported by the
FPU Grant (AP2006-00994) from the Span-
ish Ministry of Education and Science, and
the Lang2World (TIN2006-15265-C06-06) and
Ancora-Nom (FFI2008-02691-E/FILO) projects.
</bodyText>
<sectionHeader confidence="0.999286" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99970903030303">
Chinatsu Aone and Scott W. Bennett. 1996. Ap-
plying machine learning to anaphora resolution.
In S. Wermter, E. Riloff and G. Scheler (eds.),
Connectionist, Statistical and Symbolic Approaches
to Learning for Natural Language Processing.
Springer Verlag, Berlin, 302-314.
David L. Bean and Ellen Riloff. 1999. Corpus-based
identification of non-anaphoric noun phrases. In
Proceedings of the ACL 1999, 373-380.
Manuel Bertran, Oriol Borrega, Marta Recasens, and
B`arbara Soriano. 2008. AnCoraPipe: A tool for
multilevel annotation. Procesamiento del Lenguaje
Natural, 41:291-292.
Joan Bybee and Paul Hopper. 2001. Introduction to
frequency and the emergence of linguistic structure.
In J. Bybee and P. Hopper (eds.), Frequency and the
Emergence of Linguistic Structure. John Benjamins,
Amsterdam, 1-24.
Kari Fraurud. 1990. Definiteness and the processing
of NPs in natural discourse. Journal of Semantics,
7:395-433.
Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, Nanda
Kambhatla, and Salim Roukos. 2004. A mention-
synchronous coreference resolution algorithm based
on the Bell tree. In Proceedings of ACL 2004.
Christopher Lyons. 1999. Definiteness. Cambridge
University Press, Cambridge.
Vincent Ng and Claire Cardie. 2002. Identifying
anaphoric and non-anaphoric noun phrases to im-
prove coreference resolution. In Proceedings of
COLING 2002.
NIST. 2003. ACE Entity detection and tracking.
V.2.5.1.
</reference>
<page confidence="0.973834">
52
</page>
<reference confidence="0.999603847826087">
Constantin Orasan. 2003. PALinkA: A highly cus-
tomisable tool for discourse annotation. In Proceed-
ings of the 4th SIGdial Workshop on Discourse and
Dialogue.
Massimo Poesio and Renata Vieira. 1998. A corpus-
based investigation of definite description use. Com-
putational Linguistics, 24(2):183-216.
Massimo Poesio, Mijail Alexandrov-Kabadjov, Renata
Vieira, Rodrigo Goulart, and Olga Uryupina. 2005.
Does discourse-new detection help definite descrip-
tion resolution? In Proceedings of IWCS 2005.
Marta Recasens, M. Ant`onia Mart´ı, and Mariona Taul´e.
2007. Where anaphora and coreference meet. An-
notation in the Spanish CESS-ECE corpus. In Pro-
ceedings of RANLP 2007. Borovets, Bulgaria.
Marta Recasens, M. Ant`onia Mart´ı, and Mariona Taul´e.
2009. First-mention definites: more than excep-
tional cases. In S. Featherston and S. Winkler (eds.),
The Fruits of Empirical Linguistics. Volume 2. De
Gruyter, Berlin.
Wee M. Soon, Hwee T. Ng, and Daniel C. Y. Lim.
2001. A machine learning approach to coreference
resolution of noun phrases. Computational Linguis-
tics, 27(4):521-544.
Mariona Taul´e, M. Ant`onia Mart´ı, and Marta Recasens.
2008. AnCora: Multilevel Annotated Corpora for
Catalan and Spanish. In Proceedings of the 6th In-
ternational Conference on Language Resources and
Evaluation (LREC 2008),
Olga Uryupina. 2003. High-precision identification
of discourse-new and unique noun phrases. In Pro-
ceedings of the ACL 2003 Student Workshop, 80-86.
Kees van Deemter and Rodger Kibble. 2000. Squibs
and Discussions: On coreferring: coreference in
MUC and related annotation schemes. Computa-
tional Linguistics, 26(4):629-637.
Renata Vieira and Massimo Poesio. 2000. An empir-
ically based system for processing definite descrip-
tions. Computational Linguistics, 26(4):539-593.
Ian Witten and Eibe Frank. 2005. Data Mining: Practi-
cal machine learning tools and techniques. Morgan
Kaufmann.
Xiaofeng Yang, Guodong Zhou, Jian Su, and Chew
L. Tan. 2003. Coreference resolution using com-
petition learning approach. In Proceedings of ACL
2003. 176-183.
</reference>
<page confidence="0.999351">
53
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.527903">
<title confidence="0.999395">A Chain-starting Classifier of Definite NPs in Spanish</title>
<author confidence="0.7759505">Centre de_Llenguatge i Computaci´o</author>
<affiliation confidence="0.9998025">Department of Linguistics University of Barcelona</affiliation>
<address confidence="0.998656">08007 Barcelona, Spain</address>
<email confidence="0.999831">mrecasens@ub.edu</email>
<abstract confidence="0.9966358">Given the great amount of definite noun phrases that introduce an entity into the text for the first time, this paper presents a set of linguistic features that can be used to detect this type of definites in Spanish. The efficiency of the different features is tested by building a rule-based and learning-based Results suggest that the classifier, which achieves high precision at the cost of recall, can be incorporated as either a filter or an additional feature within a coreference resolution system to boost its performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Chinatsu Aone</author>
<author>Scott W Bennett</author>
</authors>
<title>Applying machine learning to anaphora resolution.</title>
<date>1996</date>
<booktitle>Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing.</booktitle>
<pages>302--314</pages>
<editor>In S. Wermter, E. Riloff and G. Scheler (eds.),</editor>
<publisher>Springer Verlag,</publisher>
<location>Berlin,</location>
<contexts>
<context position="2165" citStr="Aone and Bennett, 1996" startWordPosition="353" endWordPosition="357">ons.2 1A different matter is the resolution of anaphoric full NPs, i.e. those semantically dependent on a previous mention. 2We follow the ACE terminology (NIST, 2003) but instead of talking of objects in the world we talk of objects in the discourse model: we use entity for an object or set of objects in the discourse model, and mention for a reference to an entity. One of the problems specific to coreference resolution is determining, once a mention is encountered by the system, whether it refers to an entity previously mentioned or it introduces a new entity into the text. Many algorithms (Aone and Bennett, 1996; Soon et al., 2001; Yang et al., 2003) do not address this issue specifically, but implicitly assume all mentions to be potentially coreferent and examine all possible combinations; only if the system fails to link a mention with an already existing entity, it is considered to be chain starting.3 However, such an approach is computationally expensive and prone to errors, since natural language is populated with a huge number of entities that appear just once in the text. Even definite NPs, which are traditionally believed to refer to old entities, have been demonstrated to start a coreference</context>
</contexts>
<marker>Aone, Bennett, 1996</marker>
<rawString>Chinatsu Aone and Scott W. Bennett. 1996. Applying machine learning to anaphora resolution. In S. Wermter, E. Riloff and G. Scheler (eds.), Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing. Springer Verlag, Berlin, 302-314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Bean</author>
<author>Ellen Riloff</author>
</authors>
<title>Corpus-based identification of non-anaphoric noun phrases.</title>
<date>1999</date>
<booktitle>In Proceedings of the ACL</booktitle>
<pages>373--380</pages>
<contexts>
<context position="3411" citStr="Bean and Riloff, 1999" startWordPosition="558" endWordPosition="561">mes (Fraurud, 1990; Poesio and Vieira, 1998). An alternative line of research has considered applying a filter prior to coreference resolution that classifies mentions as either chain starting or coreferent. Ng and Cardie (2002) and Poesio et al. (2005) have tested the impact of such a detector on the overall coreference resolution performance with encouraging results. Our chain-starting classifier is comparable – despite some differences4 – to the detectors suggested by Ng and Cardie (2002), Uryupina (2003), and Poesio et al. (2005) for English, but not identical to strictly anaphoric ones5 (Bean and Riloff, 1999; Uryupina, 2003), since a non-anaphoric NP can corefer with a previous mention. This paper presents a corpus-based study of def3By chain starting we refer to those mentions that are the first element – and might be the only one – in a coreference chain. 4Ng and Cardie (2002) and Uryupina (2003) do not limit to definite NPs but deal with all types of NPs. 5Notice the confusing use of the term anaphoric in (Ng and Cardie, 2002) for describing their chain-starting filtering module. Proceedings of the EACL 2009 Student Research Workshop, pages 46–53, Athens, Greece, 2 April 2009. c�2009 Associati</context>
<context position="5207" citStr="Bean and Riloff (1999)" startWordPosition="852" endWordPosition="855"> chain-starting definites are described in Section 3. The chain-starting classifiers are built in Section 4. Section 5 reports on the evaluation and discusses its implications. Finally, Section 6 summarizes the conclusions and outlines future work. 2 Related Work Some of the corpus-driven features here presented have a precedent in earlier classifiers of this kind for English while others are our own contribution. In any case, they have been adapted and tested for Spanish for the first time. We build a list of storage units, which is inspired by research in the field of cognitive linguistics. Bean and Riloff (1999) and Uryupina (2003) have already employed a definite probability measure in a similar way, although the way the ratio is computed is slightly different. The former use it to make a “definite-only list” by ranking those definites extracted from a corpus that were observed at least five times and never in an indefinite construction. In contrast, the latter computes four definite probabilities – which are included as features within a machine-learning classifier – from the Web in an attempt to overcome Bean and Riloff’s (1999) data sparseness problem. The definite probabilities in our approach a</context>
<context position="6806" citStr="Bean and Riloff (1999)" startWordPosition="1113" endWordPosition="1116"> proper name (determined based on capitalization, whereas our corpus includes both weak and strong named entities) and whether a previous NP is an alias of the current mention (on the basis of a rulebased alias module that tries out different transformations). Uryupina (2003) and Vieira and Poesio (2000) also take capital and low case letters into account. All four approaches exploit syntactic structural cues of pre- and post- modification to detect complex NPs, as they are considered to be unlikely to have been previously mentioned in the discourse. A more fine-grained distinction is made by Bean and Riloff (1999) and Vieira and Poesio (2000) to distinguish restrictive from non-restrictive postmodification by ommitting those modifiers that occur between commas, which should not be classified as chain starting. The latter also list a series of “special predicates” including nouns like fact or result, and adjectives such as first, best, only, etc. A subset of the feature vectors used by Ng and Cardie (2002) and Uryupina (2003) is meant to code whether the NP is or not modified. In this respect, our contribution lies in adapting these ideas for the way modification occurs in Spanish – where premodifiers a</context>
</contexts>
<marker>Bean, Riloff, 1999</marker>
<rawString>David L. Bean and Ellen Riloff. 1999. Corpus-based identification of non-anaphoric noun phrases. In Proceedings of the ACL 1999, 373-380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manuel Bertran</author>
<author>Oriol Borrega</author>
<author>Marta Recasens</author>
<author>B`arbara Soriano</author>
</authors>
<title>AnCoraPipe: A tool for multilevel annotation.</title>
<date>2008</date>
<booktitle>Procesamiento del Lenguaje Natural,</booktitle>
<pages>41--291</pages>
<contexts>
<context position="20046" citStr="Bertran et al., 2008" startWordPosition="3341" endWordPosition="3344"> an AP-preference noun, (viii) is an NE. All features are binary (either “yes” or “no”). We experiment with different feature vectors, incrementally adding one feature at a time. The performance is presented in Table 3. 5 Evaluation A subset of AnCora-CO-Es consisting of 60 Spanish newspaper articles (23 335 tokens, 5 747 full NPs) is kept apart for the test corpus. AnCoraCO-Es is the coreferentially annotated AnCora-Es corpus, following the guidelines described in (Recasens et al., 2007). Coreference relations were annotated manually with the aid of the PALinkA (Orasan, 2003) and AnCoraPipe (Bertran et al., 2008) tools. Interestingly enough, the test corpus contains 2 575 definite NPs, out of which 1889 are chain-starting (1401 chain-starting definite NPs are actually isolated entities), namely 73% definites head a coreference chain, which implies that a successful classifier has the potential to rule out almost three quarters of all definite mentions. Given that chain starting is the majority class and following (Ng and Cardie, 2002), we took the “one class” classification as a naive baseline: all instances were classified as chain starting, giving a precision of 71.95% (first row in Tables 2 and 3).</context>
</contexts>
<marker>Bertran, Borrega, Recasens, Soriano, 2008</marker>
<rawString>Manuel Bertran, Oriol Borrega, Marta Recasens, and B`arbara Soriano. 2008. AnCoraPipe: A tool for multilevel annotation. Procesamiento del Lenguaje Natural, 41:291-292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan Bybee</author>
<author>Paul Hopper</author>
</authors>
<title>Introduction to frequency and the emergence of linguistic structure.</title>
<date>2001</date>
<booktitle>Frequency and the Emergence of Linguistic Structure. John Benjamins,</booktitle>
<pages>1--24</pages>
<editor>In J. Bybee and P. Hopper (eds.),</editor>
<location>Amsterdam,</location>
<contexts>
<context position="12291" citStr="Bybee and Hopper (2001)" startWordPosition="2022" endWordPosition="2025">s preferred not to classify a chain-starting instance – which can still be detected by the coreference resolution module at a later stage – since a wrong label might result in a missed coreference link. 2. Storage units. A very grammaticized definite article accounts for the large number of definite NPs attested in Spanish (column 2 in Table 1): 46% of the total. In the light of Bybee and Hopper’s (2001) claim that language structure dynamically results from frequency and repetition, we hypothesized that specific simple definite NPs in which the article has fully grammaticized constitute what Bybee and Hopper (2001) call storage units: the more a specific chunk is used, the more stored and automatized it becomes. These article-noun storage units might well head a coreference chain. With a view to providing the chain-starting classifier with a list of these article-noun storage units, we extracted from AnCora-Es all simple NPs preceded by a determiner8 (columns 2 and 3 in the second row of Table 1) and ranked them by their definite probability, which we define as the number of simple definite NPs with respect to the number of simple determined NPs. Secondly, we set a threshold of 0.7, considering as stora</context>
</contexts>
<marker>Bybee, Hopper, 2001</marker>
<rawString>Joan Bybee and Paul Hopper. 2001. Introduction to frequency and the emergence of linguistic structure. In J. Bybee and P. Hopper (eds.), Frequency and the Emergence of Linguistic Structure. John Benjamins, Amsterdam, 1-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kari Fraurud</author>
</authors>
<title>Definiteness and the processing of NPs in natural discourse.</title>
<date>1990</date>
<journal>Journal of Semantics,</journal>
<pages>7--395</pages>
<contexts>
<context position="2808" citStr="Fraurud, 1990" startWordPosition="467" endWordPosition="468">l., 2003) do not address this issue specifically, but implicitly assume all mentions to be potentially coreferent and examine all possible combinations; only if the system fails to link a mention with an already existing entity, it is considered to be chain starting.3 However, such an approach is computationally expensive and prone to errors, since natural language is populated with a huge number of entities that appear just once in the text. Even definite NPs, which are traditionally believed to refer to old entities, have been demonstrated to start a coreference chain over 50% of the times (Fraurud, 1990; Poesio and Vieira, 1998). An alternative line of research has considered applying a filter prior to coreference resolution that classifies mentions as either chain starting or coreferent. Ng and Cardie (2002) and Poesio et al. (2005) have tested the impact of such a detector on the overall coreference resolution performance with encouraging results. Our chain-starting classifier is comparable – despite some differences4 – to the detectors suggested by Ng and Cardie (2002), Uryupina (2003), and Poesio et al. (2005) for English, but not identical to strictly anaphoric ones5 (Bean and Riloff, 1</context>
</contexts>
<marker>Fraurud, 1990</marker>
<rawString>Kari Fraurud. 1990. Definiteness and the processing of NPs in natural discourse. Journal of Semantics, 7:395-433.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoqiang Luo</author>
<author>Abe Ittycheriah</author>
<author>Hongyan Jing</author>
<author>Nanda Kambhatla</author>
<author>Salim Roukos</author>
</authors>
<title>A mentionsynchronous coreference resolution algorithm based on the Bell tree.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="7888" citStr="Luo et al. (2004)" startWordPosition="1297" endWordPosition="1300">ified. In this respect, our contribution lies in adapting these ideas for the way modification occurs in Spanish – where premodifiers are rare – and in introducing a distinction between PP and AP modifiers, which we correlate in turn with the heads of simple definites. We borrow the idea of classifying definites occurring in the first sentence as chain starting from Bean and Riloff (1999). The precision and recall results obtained by these classifiers – tested on MUC corpora – are around the eighties, and around the seventies in the case of Vieira and Poesio (2000), who use the Penn Treebank. Luo et al. (2004) make use of both a linking and a starting probability in their Bell tree algorithm for coreference resolution, but the starting probability happens to be the complementary of the linking one. The chain-starting classifier we build can be used to fine-tune the starting probability used in the construction of coreference chains in Luo et al.’s (2004) style. 3 Corpus-based Study As fully documented by Lyons (1999), definiteness varies cross-linguistically. In contrast with English, for instance, Spanish adds the article before generic NPs (1), within some fixed phrases (2), and in postmodifiers </context>
</contexts>
<marker>Luo, Ittycheriah, Jing, Kambhatla, Roukos, 2004</marker>
<rawString>Xiaoqiang Luo, Abe Ittycheriah, Hongyan Jing, Nanda Kambhatla, and Salim Roukos. 2004. A mentionsynchronous coreference resolution algorithm based on the Bell tree. In Proceedings of ACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Lyons</author>
</authors>
<title>Definiteness.</title>
<date>1999</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="8303" citStr="Lyons (1999)" startWordPosition="1367" endWordPosition="1368">sults obtained by these classifiers – tested on MUC corpora – are around the eighties, and around the seventies in the case of Vieira and Poesio (2000), who use the Penn Treebank. Luo et al. (2004) make use of both a linking and a starting probability in their Bell tree algorithm for coreference resolution, but the starting probability happens to be the complementary of the linking one. The chain-starting classifier we build can be used to fine-tune the starting probability used in the construction of coreference chains in Luo et al.’s (2004) style. 3 Corpus-based Study As fully documented by Lyons (1999), definiteness varies cross-linguistically. In contrast with English, for instance, Spanish adds the article before generic NPs (1), within some fixed phrases (2), and in postmodifiers where English makes use of bare nominal premodification (3). Altogether results in a larger number of definite NPs in Spanish and, by extension, a larger number of chainstarting definites (Recasens et al., 2009). 47 (1) Tard´ıa incorporaci´on Late incorporation ‘Late incorporation of 0 women into m work.’ (2) Villalobos dio Villalobos gave ‘Villalobos gave m thanks to the militants.’ (3) El mercado internacional</context>
</contexts>
<marker>Lyons, 1999</marker>
<rawString>Christopher Lyons. 1999. Definiteness. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
<author>Claire Cardie</author>
</authors>
<title>Identifying anaphoric and non-anaphoric noun phrases to improve coreference resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING</booktitle>
<contexts>
<context position="3018" citStr="Ng and Cardie (2002)" startWordPosition="496" endWordPosition="499"> already existing entity, it is considered to be chain starting.3 However, such an approach is computationally expensive and prone to errors, since natural language is populated with a huge number of entities that appear just once in the text. Even definite NPs, which are traditionally believed to refer to old entities, have been demonstrated to start a coreference chain over 50% of the times (Fraurud, 1990; Poesio and Vieira, 1998). An alternative line of research has considered applying a filter prior to coreference resolution that classifies mentions as either chain starting or coreferent. Ng and Cardie (2002) and Poesio et al. (2005) have tested the impact of such a detector on the overall coreference resolution performance with encouraging results. Our chain-starting classifier is comparable – despite some differences4 – to the detectors suggested by Ng and Cardie (2002), Uryupina (2003), and Poesio et al. (2005) for English, but not identical to strictly anaphoric ones5 (Bean and Riloff, 1999; Uryupina, 2003), since a non-anaphoric NP can corefer with a previous mention. This paper presents a corpus-based study of def3By chain starting we refer to those mentions that are the first element – and </context>
<context position="7205" citStr="Ng and Cardie (2002)" startWordPosition="1177" endWordPosition="1180">ctural cues of pre- and post- modification to detect complex NPs, as they are considered to be unlikely to have been previously mentioned in the discourse. A more fine-grained distinction is made by Bean and Riloff (1999) and Vieira and Poesio (2000) to distinguish restrictive from non-restrictive postmodification by ommitting those modifiers that occur between commas, which should not be classified as chain starting. The latter also list a series of “special predicates” including nouns like fact or result, and adjectives such as first, best, only, etc. A subset of the feature vectors used by Ng and Cardie (2002) and Uryupina (2003) is meant to code whether the NP is or not modified. In this respect, our contribution lies in adapting these ideas for the way modification occurs in Spanish – where premodifiers are rare – and in introducing a distinction between PP and AP modifiers, which we correlate in turn with the heads of simple definites. We borrow the idea of classifying definites occurring in the first sentence as chain starting from Bean and Riloff (1999). The precision and recall results obtained by these classifiers – tested on MUC corpora – are around the eighties, and around the seventies in</context>
<context position="11233" citStr="Ng and Cardie, 2002" startWordPosition="1834" endWordPosition="1837">, is a process of linguistic change by which a content word becomes part of the grammar by losing its lexical and phonological load. 7By full NPs we mean NPs with a nominal head, thus omitting pronouns, NPs with an elliptical head as well as coordinated NPs. simple NPs differ from complex ones, and this distinction is kept when designing the eight heuristics for recognizing chain-starting definites that we introduce in this section. 1. Head match. Ruling out those definites that match an earlier noun in the text has proved to be able to filter out a considerable number of coreferent mentions (Ng and Cardie, 2002; Poesio et al., 2005). We considered both total and partial head match, but stuck to the first as the second brought much noise. On its own, namely if definite NPs are all classified as chain starting only if no mention has previously appeared with the same lexical head, we obtain a precision (P) not less than 84.95% together with 89.68% recall (R). Our purpose was to increase P as much as possible with the minimum loss in R: it is preferred not to classify a chain-starting instance – which can still be detected by the coreference resolution module at a later stage – since a wrong label might</context>
<context position="20476" citStr="Ng and Cardie, 2002" startWordPosition="3407" endWordPosition="3410"> following the guidelines described in (Recasens et al., 2007). Coreference relations were annotated manually with the aid of the PALinkA (Orasan, 2003) and AnCoraPipe (Bertran et al., 2008) tools. Interestingly enough, the test corpus contains 2 575 definite NPs, out of which 1889 are chain-starting (1401 chain-starting definite NPs are actually isolated entities), namely 73% definites head a coreference chain, which implies that a successful classifier has the potential to rule out almost three quarters of all definite mentions. Given that chain starting is the majority class and following (Ng and Cardie, 2002), we took the “one class” classification as a naive baseline: all instances were classified as chain starting, giving a precision of 71.95% (first row in Tables 2 and 3). 5.1 Performance Tables 2 and 3 show the results in terms of precision (P), recall (R), and F0.5-measure (F0.5). F0.5- measure,11 which weights P twice as much as R, is chosen since this classifier is designed as a filter for a coreference resolution module and hence we want to make sure that the discarded cases can be really discarded. P matters more than R. Each row incrementally adds a new heuristic to the previous ones. Th</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Vincent Ng and Claire Cardie. 2002. Identifying anaphoric and non-anaphoric noun phrases to improve coreference resolution. In Proceedings of COLING 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST</author>
</authors>
<title>ACE Entity detection and tracking.</title>
<date>2003</date>
<pages>2--5</pages>
<contexts>
<context position="1710" citStr="NIST, 2003" startWordPosition="271" endWordPosition="272"> whether pronominal or with a nominal head – that point to the same entity. The output of anaphora resolution1 are nounpronoun pairs (or pairs of a discourse segment and a pronoun in some cases), whereas the output of coreference resolution are chains containing a variety of items: pronouns, full NPs, discourse segments... Thus, coreference resolution requires a wider range of strategies in order to build the full chains of coreferent mentions.2 1A different matter is the resolution of anaphoric full NPs, i.e. those semantically dependent on a previous mention. 2We follow the ACE terminology (NIST, 2003) but instead of talking of objects in the world we talk of objects in the discourse model: we use entity for an object or set of objects in the discourse model, and mention for a reference to an entity. One of the problems specific to coreference resolution is determining, once a mention is encountered by the system, whether it refers to an entity previously mentioned or it introduces a new entity into the text. Many algorithms (Aone and Bennett, 1996; Soon et al., 2001; Yang et al., 2003) do not address this issue specifically, but implicitly assume all mentions to be potentially coreferent a</context>
</contexts>
<marker>NIST, 2003</marker>
<rawString>NIST. 2003. ACE Entity detection and tracking. V.2.5.1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Constantin Orasan</author>
</authors>
<title>PALinkA: A highly customisable tool for discourse annotation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 4th SIGdial Workshop on Discourse and Dialogue.</booktitle>
<contexts>
<context position="20008" citStr="Orasan, 2003" startWordPosition="3337" endWordPosition="3338">i) is a storage unit, (vii) is an AP-preference noun, (viii) is an NE. All features are binary (either “yes” or “no”). We experiment with different feature vectors, incrementally adding one feature at a time. The performance is presented in Table 3. 5 Evaluation A subset of AnCora-CO-Es consisting of 60 Spanish newspaper articles (23 335 tokens, 5 747 full NPs) is kept apart for the test corpus. AnCoraCO-Es is the coreferentially annotated AnCora-Es corpus, following the guidelines described in (Recasens et al., 2007). Coreference relations were annotated manually with the aid of the PALinkA (Orasan, 2003) and AnCoraPipe (Bertran et al., 2008) tools. Interestingly enough, the test corpus contains 2 575 definite NPs, out of which 1889 are chain-starting (1401 chain-starting definite NPs are actually isolated entities), namely 73% definites head a coreference chain, which implies that a successful classifier has the potential to rule out almost three quarters of all definite mentions. Given that chain starting is the majority class and following (Ng and Cardie, 2002), we took the “one class” classification as a naive baseline: all instances were classified as chain starting, giving a precision of</context>
</contexts>
<marker>Orasan, 2003</marker>
<rawString>Constantin Orasan. 2003. PALinkA: A highly customisable tool for discourse annotation. In Proceedings of the 4th SIGdial Workshop on Discourse and Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Renata Vieira</author>
</authors>
<title>A corpusbased investigation of definite description use.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<pages>24--2</pages>
<contexts>
<context position="2834" citStr="Poesio and Vieira, 1998" startWordPosition="469" endWordPosition="472">t address this issue specifically, but implicitly assume all mentions to be potentially coreferent and examine all possible combinations; only if the system fails to link a mention with an already existing entity, it is considered to be chain starting.3 However, such an approach is computationally expensive and prone to errors, since natural language is populated with a huge number of entities that appear just once in the text. Even definite NPs, which are traditionally believed to refer to old entities, have been demonstrated to start a coreference chain over 50% of the times (Fraurud, 1990; Poesio and Vieira, 1998). An alternative line of research has considered applying a filter prior to coreference resolution that classifies mentions as either chain starting or coreferent. Ng and Cardie (2002) and Poesio et al. (2005) have tested the impact of such a detector on the overall coreference resolution performance with encouraging results. Our chain-starting classifier is comparable – despite some differences4 – to the detectors suggested by Ng and Cardie (2002), Uryupina (2003), and Poesio et al. (2005) for English, but not identical to strictly anaphoric ones5 (Bean and Riloff, 1999; Uryupina, 2003), sinc</context>
</contexts>
<marker>Poesio, Vieira, 1998</marker>
<rawString>Massimo Poesio and Renata Vieira. 1998. A corpusbased investigation of definite description use. Computational Linguistics, 24(2):183-216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Mijail Alexandrov-Kabadjov</author>
<author>Renata Vieira</author>
<author>Rodrigo Goulart</author>
<author>Olga Uryupina</author>
</authors>
<title>Does discourse-new detection help definite description resolution?</title>
<date>2005</date>
<booktitle>In Proceedings of IWCS</booktitle>
<contexts>
<context position="3043" citStr="Poesio et al. (2005)" startWordPosition="501" endWordPosition="504"> it is considered to be chain starting.3 However, such an approach is computationally expensive and prone to errors, since natural language is populated with a huge number of entities that appear just once in the text. Even definite NPs, which are traditionally believed to refer to old entities, have been demonstrated to start a coreference chain over 50% of the times (Fraurud, 1990; Poesio and Vieira, 1998). An alternative line of research has considered applying a filter prior to coreference resolution that classifies mentions as either chain starting or coreferent. Ng and Cardie (2002) and Poesio et al. (2005) have tested the impact of such a detector on the overall coreference resolution performance with encouraging results. Our chain-starting classifier is comparable – despite some differences4 – to the detectors suggested by Ng and Cardie (2002), Uryupina (2003), and Poesio et al. (2005) for English, but not identical to strictly anaphoric ones5 (Bean and Riloff, 1999; Uryupina, 2003), since a non-anaphoric NP can corefer with a previous mention. This paper presents a corpus-based study of def3By chain starting we refer to those mentions that are the first element – and might be the only one – i</context>
<context position="11255" citStr="Poesio et al., 2005" startWordPosition="1838" endWordPosition="1841">guistic change by which a content word becomes part of the grammar by losing its lexical and phonological load. 7By full NPs we mean NPs with a nominal head, thus omitting pronouns, NPs with an elliptical head as well as coordinated NPs. simple NPs differ from complex ones, and this distinction is kept when designing the eight heuristics for recognizing chain-starting definites that we introduce in this section. 1. Head match. Ruling out those definites that match an earlier noun in the text has proved to be able to filter out a considerable number of coreferent mentions (Ng and Cardie, 2002; Poesio et al., 2005). We considered both total and partial head match, but stuck to the first as the second brought much noise. On its own, namely if definite NPs are all classified as chain starting only if no mention has previously appeared with the same lexical head, we obtain a precision (P) not less than 84.95% together with 89.68% recall (R). Our purpose was to increase P as much as possible with the minimum loss in R: it is preferred not to classify a chain-starting instance – which can still be detected by the coreference resolution module at a later stage – since a wrong label might result in a missed co</context>
</contexts>
<marker>Poesio, Alexandrov-Kabadjov, Vieira, Goulart, Uryupina, 2005</marker>
<rawString>Massimo Poesio, Mijail Alexandrov-Kabadjov, Renata Vieira, Rodrigo Goulart, and Olga Uryupina. 2005. Does discourse-new detection help definite description resolution? In Proceedings of IWCS 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Recasens</author>
<author>M Ant`onia Mart´ı</author>
<author>Mariona Taul´e</author>
</authors>
<title>Where anaphora and coreference meet. Annotation in the Spanish CESS-ECE corpus.</title>
<date>2007</date>
<booktitle>In Proceedings of RANLP 2007. Borovets,</booktitle>
<marker>Recasens, Mart´ı, Taul´e, 2007</marker>
<rawString>Marta Recasens, M. Ant`onia Mart´ı, and Mariona Taul´e. 2007. Where anaphora and coreference meet. Annotation in the Spanish CESS-ECE corpus. In Proceedings of RANLP 2007. Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Recasens</author>
<author>M Ant`onia Mart´ı</author>
<author>Mariona Taul´e</author>
</authors>
<title>First-mention definites: more than exceptional cases.</title>
<date>2009</date>
<booktitle>The Fruits of Empirical Linguistics. Volume 2. De Gruyter,</booktitle>
<editor>In S. Featherston and S. Winkler (eds.),</editor>
<location>Berlin.</location>
<marker>Recasens, Mart´ı, Taul´e, 2009</marker>
<rawString>Marta Recasens, M. Ant`onia Mart´ı, and Mariona Taul´e. 2009. First-mention definites: more than exceptional cases. In S. Featherston and S. Winkler (eds.), The Fruits of Empirical Linguistics. Volume 2. De Gruyter, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee M Soon</author>
<author>Hwee T Ng</author>
<author>Daniel C Y Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<pages>27--4</pages>
<contexts>
<context position="2184" citStr="Soon et al., 2001" startWordPosition="358" endWordPosition="361">r is the resolution of anaphoric full NPs, i.e. those semantically dependent on a previous mention. 2We follow the ACE terminology (NIST, 2003) but instead of talking of objects in the world we talk of objects in the discourse model: we use entity for an object or set of objects in the discourse model, and mention for a reference to an entity. One of the problems specific to coreference resolution is determining, once a mention is encountered by the system, whether it refers to an entity previously mentioned or it introduces a new entity into the text. Many algorithms (Aone and Bennett, 1996; Soon et al., 2001; Yang et al., 2003) do not address this issue specifically, but implicitly assume all mentions to be potentially coreferent and examine all possible combinations; only if the system fails to link a mention with an already existing entity, it is considered to be chain starting.3 However, such an approach is computationally expensive and prone to errors, since natural language is populated with a huge number of entities that appear just once in the text. Even definite NPs, which are traditionally believed to refer to old entities, have been demonstrated to start a coreference chain over 50% of </context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Wee M. Soon, Hwee T. Ng, and Daniel C. Y. Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521-544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mariona Taul´e</author>
<author>M Ant`onia Mart´ı</author>
<author>Marta Recasens</author>
</authors>
<title>AnCora: Multilevel Annotated Corpora for Catalan and Spanish.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC</booktitle>
<marker>Taul´e, Mart´ı, Recasens, 2008</marker>
<rawString>Mariona Taul´e, M. Ant`onia Mart´ı, and Marta Recasens. 2008. AnCora: Multilevel Annotated Corpora for Catalan and Spanish. In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC 2008),</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olga Uryupina</author>
</authors>
<title>High-precision identification of discourse-new and unique noun phrases.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 Student Workshop,</booktitle>
<pages>80--86</pages>
<contexts>
<context position="3303" citStr="Uryupina (2003)" startWordPosition="542" endWordPosition="543">ieved to refer to old entities, have been demonstrated to start a coreference chain over 50% of the times (Fraurud, 1990; Poesio and Vieira, 1998). An alternative line of research has considered applying a filter prior to coreference resolution that classifies mentions as either chain starting or coreferent. Ng and Cardie (2002) and Poesio et al. (2005) have tested the impact of such a detector on the overall coreference resolution performance with encouraging results. Our chain-starting classifier is comparable – despite some differences4 – to the detectors suggested by Ng and Cardie (2002), Uryupina (2003), and Poesio et al. (2005) for English, but not identical to strictly anaphoric ones5 (Bean and Riloff, 1999; Uryupina, 2003), since a non-anaphoric NP can corefer with a previous mention. This paper presents a corpus-based study of def3By chain starting we refer to those mentions that are the first element – and might be the only one – in a coreference chain. 4Ng and Cardie (2002) and Uryupina (2003) do not limit to definite NPs but deal with all types of NPs. 5Notice the confusing use of the term anaphoric in (Ng and Cardie, 2002) for describing their chain-starting filtering module. Proceed</context>
<context position="5227" citStr="Uryupina (2003)" startWordPosition="857" endWordPosition="858">re described in Section 3. The chain-starting classifiers are built in Section 4. Section 5 reports on the evaluation and discusses its implications. Finally, Section 6 summarizes the conclusions and outlines future work. 2 Related Work Some of the corpus-driven features here presented have a precedent in earlier classifiers of this kind for English while others are our own contribution. In any case, they have been adapted and tested for Spanish for the first time. We build a list of storage units, which is inspired by research in the field of cognitive linguistics. Bean and Riloff (1999) and Uryupina (2003) have already employed a definite probability measure in a similar way, although the way the ratio is computed is slightly different. The former use it to make a “definite-only list” by ranking those definites extracted from a corpus that were observed at least five times and never in an indefinite construction. In contrast, the latter computes four definite probabilities – which are included as features within a machine-learning classifier – from the Web in an attempt to overcome Bean and Riloff’s (1999) data sparseness problem. The definite probabilities in our approach are checked with conf</context>
<context position="6460" citStr="Uryupina (2003)" startWordPosition="1058" endWordPosition="1059">n order to guarantee the reliability of the results, avoiding to draw any generalization when the corpus does not contain a large enough sample. The heuristics concerning named entities and storage-unit variants find an equivalent in the features used in Ng and Cardie’s (2002) supervised classifier that represent whether the mention is a proper name (determined based on capitalization, whereas our corpus includes both weak and strong named entities) and whether a previous NP is an alias of the current mention (on the basis of a rulebased alias module that tries out different transformations). Uryupina (2003) and Vieira and Poesio (2000) also take capital and low case letters into account. All four approaches exploit syntactic structural cues of pre- and post- modification to detect complex NPs, as they are considered to be unlikely to have been previously mentioned in the discourse. A more fine-grained distinction is made by Bean and Riloff (1999) and Vieira and Poesio (2000) to distinguish restrictive from non-restrictive postmodification by ommitting those modifiers that occur between commas, which should not be classified as chain starting. The latter also list a series of “special predicates”</context>
</contexts>
<marker>Uryupina, 2003</marker>
<rawString>Olga Uryupina. 2003. High-precision identification of discourse-new and unique noun phrases. In Proceedings of the ACL 2003 Student Workshop, 80-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kees van Deemter</author>
<author>Rodger Kibble</author>
</authors>
<title>Squibs and Discussions: On coreferring: coreference in MUC and related annotation schemes.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<pages>26--4</pages>
<marker>van Deemter, Kibble, 2000</marker>
<rawString>Kees van Deemter and Rodger Kibble. 2000. Squibs and Discussions: On coreferring: coreference in MUC and related annotation schemes. Computational Linguistics, 26(4):629-637.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Renata Vieira</author>
<author>Massimo Poesio</author>
</authors>
<title>An empirically based system for processing definite descriptions.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<pages>26--4</pages>
<contexts>
<context position="6489" citStr="Vieira and Poesio (2000)" startWordPosition="1061" endWordPosition="1064"> the reliability of the results, avoiding to draw any generalization when the corpus does not contain a large enough sample. The heuristics concerning named entities and storage-unit variants find an equivalent in the features used in Ng and Cardie’s (2002) supervised classifier that represent whether the mention is a proper name (determined based on capitalization, whereas our corpus includes both weak and strong named entities) and whether a previous NP is an alias of the current mention (on the basis of a rulebased alias module that tries out different transformations). Uryupina (2003) and Vieira and Poesio (2000) also take capital and low case letters into account. All four approaches exploit syntactic structural cues of pre- and post- modification to detect complex NPs, as they are considered to be unlikely to have been previously mentioned in the discourse. A more fine-grained distinction is made by Bean and Riloff (1999) and Vieira and Poesio (2000) to distinguish restrictive from non-restrictive postmodification by ommitting those modifiers that occur between commas, which should not be classified as chain starting. The latter also list a series of “special predicates” including nouns like fact or</context>
<context position="7842" citStr="Vieira and Poesio (2000)" startWordPosition="1288" endWordPosition="1291"> (2003) is meant to code whether the NP is or not modified. In this respect, our contribution lies in adapting these ideas for the way modification occurs in Spanish – where premodifiers are rare – and in introducing a distinction between PP and AP modifiers, which we correlate in turn with the heads of simple definites. We borrow the idea of classifying definites occurring in the first sentence as chain starting from Bean and Riloff (1999). The precision and recall results obtained by these classifiers – tested on MUC corpora – are around the eighties, and around the seventies in the case of Vieira and Poesio (2000), who use the Penn Treebank. Luo et al. (2004) make use of both a linking and a starting probability in their Bell tree algorithm for coreference resolution, but the starting probability happens to be the complementary of the linking one. The chain-starting classifier we build can be used to fine-tune the starting probability used in the construction of coreference chains in Luo et al.’s (2004) style. 3 Corpus-based Study As fully documented by Lyons (1999), definiteness varies cross-linguistically. In contrast with English, for instance, Spanish adds the article before generic NPs (1), within</context>
</contexts>
<marker>Vieira, Poesio, 2000</marker>
<rawString>Renata Vieira and Massimo Poesio. 2000. An empirically based system for processing definite descriptions. Computational Linguistics, 26(4):539-593.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Witten</author>
<author>Eibe Frank</author>
</authors>
<title>Data Mining: Practical machine learning tools and techniques.</title>
<date>2005</date>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="19150" citStr="Witten and Frank, 2005" startWordPosition="3191" endWordPosition="3194">nites tend to be coreferent mentions, and (ii) complex definites tend to be chain starting (if their head has not previously appeared). Accordingly, Step 5 in Figure 1 finishes by classifying simple definites as coreferent, and Step 6 complex definites as chain starting. Before these last steps, however, a series of filters are applied corresponding to the different heuristics. The performance is presented in Table 2. 4.2 Machine-learning approach The second way in which the suggested linguistic cues are tested is by constructing a learning-based classifier. The Weka machine learning toolkit (Witten and Frank, 2005) is used to train a J48 decision tree on a 10-fold cross-validation. A total of eight learning features are considered: (i) head match, (ii) storage-unit variant, (iii) is a neuter definite, (iv) is first sentence, (v) is a PPpreference noun, (vi) is a storage unit, (vii) is an AP-preference noun, (viii) is an NE. All features are binary (either “yes” or “no”). We experiment with different feature vectors, incrementally adding one feature at a time. The performance is presented in Table 3. 5 Evaluation A subset of AnCora-CO-Es consisting of 60 Spanish newspaper articles (23 335 tokens, 5 747 f</context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>Ian Witten and Eibe Frank. 2005. Data Mining: Practical machine learning tools and techniques. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaofeng Yang</author>
<author>Guodong Zhou</author>
<author>Jian Su</author>
<author>Chew L Tan</author>
</authors>
<title>Coreference resolution using competition learning approach.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL 2003.</booktitle>
<pages>176--183</pages>
<contexts>
<context position="2204" citStr="Yang et al., 2003" startWordPosition="362" endWordPosition="365"> of anaphoric full NPs, i.e. those semantically dependent on a previous mention. 2We follow the ACE terminology (NIST, 2003) but instead of talking of objects in the world we talk of objects in the discourse model: we use entity for an object or set of objects in the discourse model, and mention for a reference to an entity. One of the problems specific to coreference resolution is determining, once a mention is encountered by the system, whether it refers to an entity previously mentioned or it introduces a new entity into the text. Many algorithms (Aone and Bennett, 1996; Soon et al., 2001; Yang et al., 2003) do not address this issue specifically, but implicitly assume all mentions to be potentially coreferent and examine all possible combinations; only if the system fails to link a mention with an already existing entity, it is considered to be chain starting.3 However, such an approach is computationally expensive and prone to errors, since natural language is populated with a huge number of entities that appear just once in the text. Even definite NPs, which are traditionally believed to refer to old entities, have been demonstrated to start a coreference chain over 50% of the times (Fraurud, </context>
</contexts>
<marker>Yang, Zhou, Su, Tan, 2003</marker>
<rawString>Xiaofeng Yang, Guodong Zhou, Jian Su, and Chew L. Tan. 2003. Coreference resolution using competition learning approach. In Proceedings of ACL 2003. 176-183.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>