<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.050216">
<title confidence="0.931912">
UWN: A Large Multilingual Lexical Knowledge Base
</title>
<author confidence="0.76425">
Gerard de Melo
</author>
<affiliation confidence="0.658096">
ICSI Berkeley
</affiliation>
<email confidence="0.995688">
demelo@icsi.berkeley.edu
</email>
<author confidence="0.95648">
Gerhard Weikum
</author>
<affiliation confidence="0.91836">
Max Planck Institute for Informatics
</affiliation>
<email confidence="0.49819">
weikum@mpi-inf.mpg.de
</email>
<sectionHeader confidence="0.991146" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998570571428571">
We present UWN, a large multilingual lexi-
cal knowledge base that describes the mean-
ings and relationships of words in over 200
languages. This paper explains how link pre-
diction, information integration and taxonomy
induction methods have been used to build
UWN based on WordNet and extend it with
millions of named entities from Wikipedia.
We additionally introduce extensions to cover
lexical relationships, frame-semantic knowl-
edge, and language data. An online interface
provides human access to the data, while a
software API enables applications to look up
over 16 million words and names.
</bodyText>
<sectionHeader confidence="0.998987" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999881685714286">
Semantic knowledge about words and named enti-
ties is a fundamental building block both in vari-
ous forms of language technology as well as in end-
user applications. Examples of the latter include
word processor thesauri, online dictionaries, ques-
tion answering, and mobile services. Finding se-
mantically related words is vital for query expan-
sion in information retrieval (Gong et al., 2005),
database schema matching (Madhavan et al., 2001),
sentiment analysis (Godbole et al., 2007), and ontol-
ogy mapping (Jean-Mary and Kabuka, 2008). Fur-
ther uses of lexical knowledge include data cleaning
(Kedad and Métais, 2002), visual object recognition
(Marszałek and Schmid, 2007), and biomedical data
analysis (Rubin and others, 2006).
Many of these applications have used English-
language resources like WordNet (Fellbaum, 1998).
However, a more multilingual resource equipped
with an easy-to-use API would not only enable us to
perform all of the aforementioned tasks in additional
languages, but also to explore cross-lingual applica-
tions like cross-lingual IR (Etzioni et al., 2007) and
machine translation (Chatterjee et al., 2005).
This paper describes a new API that makes lexical
knowledge about millions of items in over 200 lan-
guages available to applications, and a correspond-
ing online user interface for users to explore the data.
We first describe link prediction techniques used to
create the multilingual core of the knowledge base
with word sense information (Section 2). We then
outline techniques used to incorporate named enti-
ties and specialized concepts (Section 3) and other
types of knowledge (Section 4). Finally, we describe
how the information is made accessible via a user in-
terface (Section 5) and a software API (Section 6).
</bodyText>
<sectionHeader confidence="0.965009" genericHeader="method">
2 The UWN Core
</sectionHeader>
<bodyText confidence="0.99967">
UWN (de Melo and Weikum, 2009) is based on
WordNet (Fellbaum, 1998), the most popular lexi-
cal knowledge base for the English language. Word-
Net enumerates the senses of a word, providing a
short description text (gloss) and synonyms for each
meaning. Additionally, it describes relationships be-
tween senses, e.g. via the hyponymy/hypernymy re-
lation that holds when one term like ‘publication’ is
a generalization of another term like ‘journal’.
This model can be generalized by allowing words
in multiple languages to be associated with a mean-
ing (without, of course, demanding every meaning
be lexicalized in every language). In order to ac-
complish this at a large scale, we automatically link
</bodyText>
<page confidence="0.979914">
151
</page>
<note confidence="0.684326">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 151–156,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.997388461538462">
terms in different languages to the meanings already
defined in WordNet. This transforms WordNet into
a multilingual lexical knowledge base that covers
not only English terms but hundreds of thousands
of terms from many different languages.
Unfortunately, a straightforward translation runs
into major difficulties because of homonyms and
synonyms. For example, a word like ‘bat’ has 10
senses in the English WordNet, but a German trans-
lation like ‘Fledermaus’ (the animal) only applies to
a small subset of those senses (cf. Figure 1). This
challenge can be approached by disambiguating us-
ing machine learning techniques.
</bodyText>
<figureCaption confidence="0.998594">
Figure 1: Word sense ambiguity
</figureCaption>
<bodyText confidence="0.998029653846154">
Knowledge Extraction An initial input knowl-
edge base graph G0 is constructed by ex-
tracting information from existing wordnets,
translation dictionaries including Wiktionary
(http://www.wiktionary.org), multilingual thesauri
and ontologies, and parallel corpora. Additional
heuristics are applied to increase the density of the
graph and merge near-duplicate statements.
Link Prediction A sequence of knowledge graphs
Gi are iteratively derived by assessing paths from
a new term x to an existing WordNet sense z via
some English translation y covered by WordNet. For
instance, the German ‘Fledermaus’ has ‘bat’ as a
translation and hence initially is tentatively linked to
all senses of ‘bat’ with a confidence of 0. In each
iteration, the confidence values are then updated to
reflect how likely it seems that those links are cor-
rect. The confidences are predicted using RBF-
kernel SVM models that are learnt from a training
set of labelled links between non-English words and
senses. The feature space is constructed using a se-
ries of graph-based statistical scores that represent
properties of the previous graph Gi_1 and addition-
ally make use of measures of semantic relatedness
and corpus frequencies. The most salient features
xi(x, z) are of the form:
</bodyText>
<equation confidence="0.999263">
O(x, y) sim*x(y, z) (1)
O(x, y) sim*x(y, z) (2)
simx*(y, z) + dissimx(y, z)
</equation>
<bodyText confidence="0.999958678571429">
The formulae consider the out-neighbourhood y E
r(x, Gi_1) of x, i.e. its translations, and then ob-
serve how strongly each y is tied to z. The function
sim* computes the maximal similarity between any
sense of y and the current sense z. The dissim func-
tion computes the sum of dissimilarities between
senses of y and z, essentially quantifying how many
alternatives there are to z. Additional weighting
functions O, -y are used to bias scores towards senses
that have an acceptable part-of-speech and senses
that are more frequent in the SemCor corpus.
Relying on multiple iterations allows us to draw
on multilingual evidence for greater precision and
recall. For instance, after linking the German ‘Fled-
ermaus’ to the animal sense of ‘bat’, we may be able
to infer the same for the Turkish translation ‘yarasa’.
Results We have successfully applied these tech-
niques to automatically create UWN, a large-scale
multilingual wordnet. Evaluating random samples
of term-sense links, we find (with Wilson-score in-
tervals at α = 0.05) that for French the preci-
sion is 89.2% f 3.4% (311 samples), for German
85.9% f 3.8% (321 samples), and for Mandarin
Chinese 90.5% f 3.3% (300 samples). The over-
all number of new term-sense links is 1,595,763, for
822,212 terms in over 200 languages. These figures
can be grown further if the input is extended by tap-
ping on additional sources of translations.
</bodyText>
<sectionHeader confidence="0.754005" genericHeader="method">
3 MENTA: Named Entities and
Specialized Concepts
</sectionHeader>
<bodyText confidence="0.99965125">
The UWN Core is extended by incorporating large
amounts of named entities and language- and
domain-specific concepts from Wikipedia (de Melo
and Weikum, 2010a). In the process, we also obtain
</bodyText>
<equation confidence="0.697364">
E
yEr(x,Gi−1)
E
yEr(x,Gi−1)
</equation>
<page confidence="0.983496">
152
</page>
<bodyText confidence="0.999954968085107">
human-readable glosses in many languages, links to
images, and other valuable information. These ad-
ditions are not simply added as a separate knowl-
edge base, but fully connected and integrated with
the core. In particular, we create a mapping between
Wikipedia and WordNet in order to merge equiva-
lent entries and we use taxonomy construction meth-
ods in order to attach all new named entities to their
most likely classes, e.g. ‘Haight-Ashbury’ is linked
to a WordNet sense of the word ‘neighborhood’.
Information Integration Supervised link predic-
tion, similar to the method presented in Section 2, is
used in order to attach Wikipedia articles to semanti-
cally equivalent WordNet entries, while also exploit-
ing gloss similarity as an additional feature. Addi-
tionally, we connect articles from different multilin-
gual Wikipedia editions via their cross-lingual inter-
wiki links, as well as categories with equivalent ar-
ticles and article redirects with redirect targets.
We then consider connected components of di-
rectly or transitively linked items. In the ideal case,
such a connected component consists of a number
of items all describing the same concept or entity, in-
cluding articles from different versions of Wikipedia
and perhaps also categories or WordNet senses.
Unfortunately, in many cases one obtains con-
nected components that are unlikely to be correct,
because multiple articles from the same Wikipedia
edition or multiple incompatible WordNet senses are
included in the same component. This can be due
to incorrect links produced by the supervised link
prediction, but often even the original links from
Wikipedia are not consistent.
In order to obtain more consistent connected com-
ponents, we use combinatorial optimization meth-
ods to delete certain links. In particular, for each
connected component to be analysed, an Integer
Linear Program formalizes the objective of mini-
mizing the costs for deleted edges and the costs for
ignoring soft constraints. The basic aim is that of
deleting as few edges as possible while simultane-
ously ensuring that the graph becomes as consistent
as possible. In some cases, there is overwhelming
evidence indicating that two slightly different arti-
cles should be grouped together, while in other cases
there might be little evidence for the correctness of
an edge and so it can easily be deleted with low cost.
While obtaining an exact solution is NP-hard and
APX-hard, we can solve the corresponding Linear
Program using a fast LP solver like CPLEX and sub-
sequently apply region growing techniques to obtain
a solution with a logarithmic approximation guaran-
tee (de Melo and Weikum, 2010b).
The clean connected components resulting from
this process can then be merged to form aggregate
entities. For instance, given WordNet’s standard
sense for ‘fog’, water vapor, we can check which
other items are in the connected component and
transfer all information to the WordNet entry. By
extracting snippets of text from the beginning of
Wikipedia articles, we can add new gloss descrip-
tions for fog in Arabic, Asturian, Bengali, and many
other languages. We can also attach pictures show-
ing fog to the WordNet word sense.
Taxonomy Induction The above process con-
nects articles to their counterparts in WordNet. In
the next step, we ensure that articles without any di-
rect counterpart are linked to WordNet as well, by
means of taxonomic hypernymy/instance links (de
Melo and Weikum, 2010a).
We generate individual hypotheses about likely
parents of entities. For instance, articles are con-
nected to their Wikipedia categories (if these are not
assessed to be mere topic descriptors) and categories
are linked to parent categories, etc. In order to link
categories to possible parent hypernyms in Word-
Net, we adapt the approach proposed for YAGO
(Suchanek et al., 2007) of determining the headword
of the category name and disambiguating it.
Since we are dealing with a multilingual scenario
that draws on articles from different multilingual
Wikipedia editions that all need to be connected to
WordNet, we apply an algorithm that jointly looks
at an entity and all of its parent candidates (not just
from an individual article, but all articles in the same
connected component) as well as superordinate par-
ent candidates (parents of parents, etc.), as depicted
in Figure 2. We then construct a Markov chain based
on this graph of parents that also incorporates the
possibility of random jumps from any parent back
to the current entity under consideration. The sta-
tionary probability of this Markov chain, which can
be obtained using random walk methods, provides
us a ranking of the most likely parents.
</bodyText>
<page confidence="0.999116">
153
</page>
<figureCaption confidence="0.99998">
Figure 2: Noisy initial edges (left) and cleaned, integrated output (right), shown in a simplified form
Figure 3: UWN with named entities
</figureCaption>
<bodyText confidence="0.993198">
Results Overall, we obtain a knowledge base with
5.4 million concepts or entities and 16.7 million
words or names associated with them from over
200 languages. Over 2 million named entities come
only from non-English Wikipedia editions, but their
taxonomic links to WordNet still have an accuracy
around 90%. An example excerpt is shown in Fig-
ure 3, with named entities connected to higher-level
classes in UWN, all with multilingual labels.
</bodyText>
<sectionHeader confidence="0.995851" genericHeader="method">
4 Other Extensions
</sectionHeader>
<bodyText confidence="0.998269225">
Word Relationships Another plugin provides
word relationships and properties mined from Wik-
tionary. These include derivational and etymologi-
cal word relationships (e.g. that ‘grotesque’ comes
from the Italian ‘grotta’: grotto, artificial cave), al-
ternative spellings (e.g. ‘encyclopcedia’ for ‘en-
cyclopedia’), common misspellings (e.g. ‘minis-
cule’ for ‘minuscule’), pronunciation information
(e.g. how to pronounce ‘nuclear’), and so on.
Frame-Semantic Knowledge Frame semantics is
a cognitively motivated theory that describes words
in terms of the cognitive frames or scenarios that
they evoke and the corresponding participants in-
volved in them. For a given frame, FrameNet
provides definitions, involved participants, associ-
ated words, and relationships. For instance, the
Commerce_goods-transfer frame normally
involves a seller and a buyer, among other things,
and different words like ‘buy’ and ‘sell’ can be cho-
sen to describe the same event.
Such detailed knowledge about scenarios is
largely complementary in nature to the sense re-
lationships that WordNet provides. For instance,
WordNet emphasizes the opposite meaning of the
words ‘happy’ and ‘unhappy’, while frame seman-
tics instead emphasizes the cognitive relatedness of
words like ‘happy’, ‘unhappy’, ‘astonished’, and
‘amusement’, and explains that typical participants
include an experiencer who experiences the emo-
tions and external stimuli that evoke them. There
have been individual systems that made use of both
forms of knowledge (Shi and Mihalcea, 2005; Cop-
pola and others, 2009), but due to their very different
nature, there is currently no simple way to accom-
plish this feat. Our system addresses this by seam-
lessly integrating frame semantic knowledge into the
system. We draw on FrameNet (Baker et al., 1998),
the most well-known computational instantiation of
frame semantics. While the FrameNet project is
generally well-known, its use in practical applica-
</bodyText>
<page confidence="0.99949">
154
</page>
<bodyText confidence="0.99997384">
tions has been limited due to the lack of easy-to-use
APIs and because FrameNet alone does not cover as
many words as WordNet. Our API simultaneously
provides access to both sources.
Language information For a given language, this
extension provides information such as relevant
writing systems, geographical regions, identifica-
tion codes, and names in many different languages.
These are all integrated into WordNet’s hypernym
hierarchy, i.e. from language families like the Sinitic
languages one may move down to macrolanguages
like Chinese, and then to more specific forms like
Mandarin Chinese, dialect groups like Ji-Lu Man-
darin, or even dialects of particular cities.
The information is obtained from ISO standards,
the Unicode CLDR as well as Wikipedia and then
integrated with WordNet using the information in-
tegration strategies described above (de Melo and
Weikum, 2008). Additionally, information about
writing systems is taken from the Unicode CLDR
and information about individual characters is ob-
tained from the Unicode, Unihan, and Hanzi Data
databases. For instance, the Chinese character ‘AN’
is connected to its radical component ‘k and to its
pronunciation component ‘fR.
</bodyText>
<sectionHeader confidence="0.990078" genericHeader="method">
5 Integrated Query Interface and Wiki
</sectionHeader>
<bodyText confidence="0.999791739130435">
We have developed an online interface that provides
access to our data to interested researchers (yago-
knowledge.org/uwn/), as shown in Figure 4.
Interactive online interfaces offer new ways of in-
teracting with lexical knowledge that are not possi-
ble with traditional print dictionaries. For example,
a user wishing to find a Spanish word for the concept
of persuading someone not to believe something
might look up the word ‘persuasion’ and then navi-
gate to its antonym ‘dissuasion’ to find the Spanish
translation. A non-native speaker of English looking
up the word ‘tercel’ might find it helpful to see pic-
tures available for the related terms ‘hawk’ or ‘fal-
con’ – a Google Image search for ‘tercel’ merely de-
livers images of Toyota Tercel cars.
While there have been other multilingual inter-
faces to WordNet-style lexical knowledge in the past
(Pianta et al., 2002; Atserias and others, 2004), these
provide less than 10 languages as of 2012. The most
similar resource is BabelNet (Navigli and Ponzetto,
2010), which contains multilingual synsets but does
not connect named entities from Wikipedia to them
in a multilingual taxonomy.
</bodyText>
<figureCaption confidence="0.995726">
Figure 4: Part of Online Interface
</figureCaption>
<sectionHeader confidence="0.996138" genericHeader="method">
6 Integrated API
</sectionHeader>
<bodyText confidence="0.99998752173913">
Our goal is to make the knowledge that we have de-
rived available for use in applications. To this end,
we have developed a fully downloadable API that
can easily be used in several different programming
languages. While there are many existing APIs for
WordNet and other lexical resources (e.g. (Judea et
al., 2011; Gurevych and others, 2012)), these don’t
provide a comparable degree of integrated multilin-
gual and taxonomic information.
Interface The API can be used by initializing an
accessor object and possibly specifying the list of
plugins to be loaded. Depending on the particular
application, one may choose only Princeton Word-
Net and the UWN Core, or one may want to in-
clude named entities from Wikipedia and frame-
semantic knowledge derived from FrameNet, for in-
stance. The accessor provides a simple graph-based
lookup API as well as some convenience methods
for common types of queries.
An additional higher-level API module imple-
ments several measures of semantic relatedness. It
also provides a simple word sense disambiguation
method that, given a tokenized text with part-of-
</bodyText>
<page confidence="0.997079">
155
</page>
<bodyText confidence="0.99980437037037">
speech and lemma annotations, selects likely word
senses by choosing the senses (with matching part-
of-speech) that are most similar to words in the con-
text. Note that these modules go beyond existing
APIs because they operate on words in many differ-
ent languages and semantic similarity can even be
assessed across languages.
Data Structures Under the hood, each plugin re-
lies on a disk-based associative array to store the
knowledge base as a labelled multi-graph. The out-
going labelled edges of an entity are saved on disk in
a serialized form, including relation names and rela-
tion weights. An index structure allows determining
the position of such records on disk.
Internally, this index structure is implemented as
a linearly-probed hash table that is also stored ex-
ternally. Note that such a structure is very efficient
in this scenario, because the index is used as a read-
only data store by the API. Once an index has been
created, write operations are no longer performed,
so B+ trees and similar disk-based balanced tree in-
dices commonly used in relational database manage-
ment systems are not needed. The advantage is that
this enables faster lookups, because retrieval opera-
tions normally require only two disk reads per plu-
gin, one to access a block in the index table, and
another to access a block of actual data.
</bodyText>
<sectionHeader confidence="0.998509" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999958125">
UWN is an important new multilingual lexical re-
source that is now freely available to the community.
It has been constructed using sophisticated knowl-
edge extraction, link prediction, information integra-
tion, and taxonomy induction methods. Apart from
an online querying and browsing interface, we have
also implemented an API that facilitates the use of
the knowledge base in applications.
</bodyText>
<sectionHeader confidence="0.998807" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999588688524591">
Jordi Atserias et al. 2004. The MEANING multilingual
central repository. In Proc. GWC 2004.
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet project. In Proc.
COLING-ACL 1998.
Niladri Chatterjee, Shailly Goyal, and Anjali Naithani.
2005. Resolving pattern ambiguity for English to
Hindi machine translation using WordNet. In Proc.
Workshop Translation Techn. at RANLP 2005.
Bonaventura Coppola et al. 2009. Frame detection over
the Semantic Web. In Proc. ESWC.
Gerard de Melo and Gerhard Weikum. 2008. Language
as a foundation of the Semantic Web. In Proc. ISWC.
Gerard de Melo and Gerhard Weikum. 2009. Towards
a universal wordnet by learning from combined evi-
dence. In Proc. CIKM 2009.
Gerard de Melo and Gerhard Weikum. 2010a. MENTA:
Inducing multilingual taxonomies from Wikipedia. In
Proc. CIKM 2010.
Gerard de Melo and Gerhard Weikum. 2010b. Untan-
gling the cross-lingual link structure of Wikipedia. In
Proc. ACL 2010.
Oren Etzioni, Kobi Reiter, Stephen Soderland, and Mar-
cus Sammer. 2007. Lexical translation with applica-
tion to image search on the Web. In Proc. MT Summit.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. The MIT Press.
Namrata Godbole, Manjunath Srinivasaiah, and Steven
Skiena. 2007. Large-scale sentiment analysis for news
and blogs. In Proc. ICWSM.
Zhiguo Gong, Chan Wa Cheang, and Leong Hou U.
2005. Web query expansion by WordNet. In Proc.
DEXA 2005.
Iryna Gurevych et al. 2012. Uby: A large-scale uni-
fied lexical-semantic resource based on LMF. In Proc.
EACL 2012.
Yves R. Jean-Mary and Mansur R. Kabuka. 2008. AS-
MOV: Results for OAEI 2008. In Proc. OM 2008.
Alex Judea, Vivi Nastase, and Michael Strube. 2011.
WikiNetTk – A tool kit for embedding world knowl-
edge in NLP applications. In Proc. IJCNLP 2011.
Zoubida Kedad and Elisabeth Métais. 2002. Ontology-
based data cleaning. In Proc. NLDB 2002.
Jayant Madhavan, P. Bernstein, and E. Rahm. 2001.
Generic schema matching with Cupid. In Proc. VLDB.
Marcin Marszałek and C. Schmid. 2007. Semantic hier-
archies for visual object recognition. In Proc. CVPR.
Roberto Navigli and Simone Paolo Ponzetto. 2010. Ba-
belNet: Building a very large multilingual semantic
network. In Proc. ACL 2010.
Emanuele Pianta, Luisa Bentivogli, and Christian Gi-
rardi. 2002. MultiWordNet: Developing an aligned
multilingual database. In Proc. GWC.
Daniel L. Rubin et al. 2006. National Center for Biomed-
ical Ontology. OMICS, 10(2):185–98.
Lei Shi and Rada Mihalcea. 2005. Putting the pieces to-
gether: Combining FrameNet, VerbNet, and WordNet
for robust semantic parsing. In Proc. CICLing.
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. YAGO: A core of semantic knowl-
edge. In Proc. WWW 2007.
</reference>
<page confidence="0.998791">
156
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.869844">
<title confidence="0.999439">UWN: A Large Multilingual Lexical Knowledge Base</title>
<author confidence="0.997757">Gerard de</author>
<affiliation confidence="0.908402">ICSI Berkeley</affiliation>
<email confidence="0.999642">demelo@icsi.berkeley.edu</email>
<author confidence="0.993207">Gerhard Weikum Max Planck Institute for Informatics</author>
<email confidence="0.993798">weikum@mpi-inf.mpg.de</email>
<abstract confidence="0.998461333333333">We present UWN, a large multilingual lexical knowledge base that describes the meanings and relationships of words in over 200 languages. This paper explains how link prediction, information integration and taxonomy induction methods have been used to build UWN based on WordNet and extend it with millions of named entities from Wikipedia. We additionally introduce extensions to cover lexical relationships, frame-semantic knowledge, and language data. An online interface provides human access to the data, while a software API enables applications to look up over 16 million words and names.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jordi Atserias</author>
</authors>
<title>The MEANING multilingual central repository.</title>
<date>2004</date>
<booktitle>In Proc. GWC</booktitle>
<marker>Atserias, 2004</marker>
<rawString>Jordi Atserias et al. 2004. The MEANING multilingual central repository. In Proc. GWC 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In Proc. COLING-ACL</booktitle>
<contexts>
<context position="14143" citStr="Baker et al., 1998" startWordPosition="2215" endWordPosition="2218">ile frame semantics instead emphasizes the cognitive relatedness of words like ‘happy’, ‘unhappy’, ‘astonished’, and ‘amusement’, and explains that typical participants include an experiencer who experiences the emotions and external stimuli that evoke them. There have been individual systems that made use of both forms of knowledge (Shi and Mihalcea, 2005; Coppola and others, 2009), but due to their very different nature, there is currently no simple way to accomplish this feat. Our system addresses this by seamlessly integrating frame semantic knowledge into the system. We draw on FrameNet (Baker et al., 1998), the most well-known computational instantiation of frame semantics. While the FrameNet project is generally well-known, its use in practical applica154 tions has been limited due to the lack of easy-to-use APIs and because FrameNet alone does not cover as many words as WordNet. Our API simultaneously provides access to both sources. Language information For a given language, this extension provides information such as relevant writing systems, geographical regions, identification codes, and names in many different languages. These are all integrated into WordNet’s hypernym hierarchy, i.e. fr</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet project. In Proc. COLING-ACL 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niladri Chatterjee</author>
<author>Shailly Goyal</author>
<author>Anjali Naithani</author>
</authors>
<title>Resolving pattern ambiguity for English to Hindi machine translation using WordNet. In</title>
<date>2005</date>
<booktitle>Proc. Workshop Translation Techn. at RANLP</booktitle>
<contexts>
<context position="1924" citStr="Chatterjee et al., 2005" startWordPosition="283" endWordPosition="286">g (Jean-Mary and Kabuka, 2008). Further uses of lexical knowledge include data cleaning (Kedad and Métais, 2002), visual object recognition (Marszałek and Schmid, 2007), and biomedical data analysis (Rubin and others, 2006). Many of these applications have used Englishlanguage resources like WordNet (Fellbaum, 1998). However, a more multilingual resource equipped with an easy-to-use API would not only enable us to perform all of the aforementioned tasks in additional languages, but also to explore cross-lingual applications like cross-lingual IR (Etzioni et al., 2007) and machine translation (Chatterjee et al., 2005). This paper describes a new API that makes lexical knowledge about millions of items in over 200 languages available to applications, and a corresponding online user interface for users to explore the data. We first describe link prediction techniques used to create the multilingual core of the knowledge base with word sense information (Section 2). We then outline techniques used to incorporate named entities and specialized concepts (Section 3) and other types of knowledge (Section 4). Finally, we describe how the information is made accessible via a user interface (Section 5) and a softwar</context>
</contexts>
<marker>Chatterjee, Goyal, Naithani, 2005</marker>
<rawString>Niladri Chatterjee, Shailly Goyal, and Anjali Naithani. 2005. Resolving pattern ambiguity for English to Hindi machine translation using WordNet. In Proc. Workshop Translation Techn. at RANLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonaventura Coppola</author>
</authors>
<title>Frame detection over the Semantic Web. In</title>
<date>2009</date>
<booktitle>Proc. ESWC.</booktitle>
<marker>Coppola, 2009</marker>
<rawString>Bonaventura Coppola et al. 2009. Frame detection over the Semantic Web. In Proc. ESWC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard de Melo</author>
<author>Gerhard Weikum</author>
</authors>
<title>Language as a foundation of the Semantic Web. In</title>
<date>2008</date>
<booktitle>Proc. ISWC.</booktitle>
<marker>de Melo, Weikum, 2008</marker>
<rawString>Gerard de Melo and Gerhard Weikum. 2008. Language as a foundation of the Semantic Web. In Proc. ISWC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard de Melo</author>
<author>Gerhard Weikum</author>
</authors>
<title>Towards a universal wordnet by learning from combined evidence.</title>
<date>2009</date>
<booktitle>In Proc. CIKM</booktitle>
<marker>de Melo, Weikum, 2009</marker>
<rawString>Gerard de Melo and Gerhard Weikum. 2009. Towards a universal wordnet by learning from combined evidence. In Proc. CIKM 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard de Melo</author>
<author>Gerhard Weikum</author>
</authors>
<title>MENTA: Inducing multilingual taxonomies from Wikipedia.</title>
<date>2010</date>
<booktitle>In Proc. CIKM</booktitle>
<marker>de Melo, Weikum, 2010</marker>
<rawString>Gerard de Melo and Gerhard Weikum. 2010a. MENTA: Inducing multilingual taxonomies from Wikipedia. In Proc. CIKM 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard de Melo</author>
<author>Gerhard Weikum</author>
</authors>
<title>Untangling the cross-lingual link structure of Wikipedia.</title>
<date>2010</date>
<booktitle>In Proc. ACL</booktitle>
<marker>de Melo, Weikum, 2010</marker>
<rawString>Gerard de Melo and Gerhard Weikum. 2010b. Untangling the cross-lingual link structure of Wikipedia. In Proc. ACL 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Kobi Reiter</author>
<author>Stephen Soderland</author>
<author>Marcus Sammer</author>
</authors>
<title>Lexical translation with application to image search on the Web. In</title>
<date>2007</date>
<booktitle>Proc. MT Summit.</booktitle>
<contexts>
<context position="1874" citStr="Etzioni et al., 2007" startWordPosition="276" endWordPosition="279">sis (Godbole et al., 2007), and ontology mapping (Jean-Mary and Kabuka, 2008). Further uses of lexical knowledge include data cleaning (Kedad and Métais, 2002), visual object recognition (Marszałek and Schmid, 2007), and biomedical data analysis (Rubin and others, 2006). Many of these applications have used Englishlanguage resources like WordNet (Fellbaum, 1998). However, a more multilingual resource equipped with an easy-to-use API would not only enable us to perform all of the aforementioned tasks in additional languages, but also to explore cross-lingual applications like cross-lingual IR (Etzioni et al., 2007) and machine translation (Chatterjee et al., 2005). This paper describes a new API that makes lexical knowledge about millions of items in over 200 languages available to applications, and a corresponding online user interface for users to explore the data. We first describe link prediction techniques used to create the multilingual core of the knowledge base with word sense information (Section 2). We then outline techniques used to incorporate named entities and specialized concepts (Section 3) and other types of knowledge (Section 4). Finally, we describe how the information is made accessi</context>
</contexts>
<marker>Etzioni, Reiter, Soderland, Sammer, 2007</marker>
<rawString>Oren Etzioni, Kobi Reiter, Stephen Soderland, and Marcus Sammer. 2007. Lexical translation with application to image search on the Web. In Proc. MT Summit.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>The MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Namrata Godbole</author>
<author>Manjunath Srinivasaiah</author>
<author>Steven Skiena</author>
</authors>
<title>Large-scale sentiment analysis for news and blogs.</title>
<date>2007</date>
<booktitle>In Proc. ICWSM.</booktitle>
<contexts>
<context position="1279" citStr="Godbole et al., 2007" startWordPosition="188" endWordPosition="191">ce provides human access to the data, while a software API enables applications to look up over 16 million words and names. 1 Introduction Semantic knowledge about words and named entities is a fundamental building block both in various forms of language technology as well as in enduser applications. Examples of the latter include word processor thesauri, online dictionaries, question answering, and mobile services. Finding semantically related words is vital for query expansion in information retrieval (Gong et al., 2005), database schema matching (Madhavan et al., 2001), sentiment analysis (Godbole et al., 2007), and ontology mapping (Jean-Mary and Kabuka, 2008). Further uses of lexical knowledge include data cleaning (Kedad and Métais, 2002), visual object recognition (Marszałek and Schmid, 2007), and biomedical data analysis (Rubin and others, 2006). Many of these applications have used Englishlanguage resources like WordNet (Fellbaum, 1998). However, a more multilingual resource equipped with an easy-to-use API would not only enable us to perform all of the aforementioned tasks in additional languages, but also to explore cross-lingual applications like cross-lingual IR (Etzioni et al., 2007) and </context>
</contexts>
<marker>Godbole, Srinivasaiah, Skiena, 2007</marker>
<rawString>Namrata Godbole, Manjunath Srinivasaiah, and Steven Skiena. 2007. Large-scale sentiment analysis for news and blogs. In Proc. ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiguo Gong</author>
<author>Chan Wa Cheang</author>
<author>Leong Hou U</author>
</authors>
<title>Web query expansion by WordNet.</title>
<date>2005</date>
<booktitle>In Proc. DEXA</booktitle>
<contexts>
<context position="1186" citStr="Gong et al., 2005" startWordPosition="175" endWordPosition="178">over lexical relationships, frame-semantic knowledge, and language data. An online interface provides human access to the data, while a software API enables applications to look up over 16 million words and names. 1 Introduction Semantic knowledge about words and named entities is a fundamental building block both in various forms of language technology as well as in enduser applications. Examples of the latter include word processor thesauri, online dictionaries, question answering, and mobile services. Finding semantically related words is vital for query expansion in information retrieval (Gong et al., 2005), database schema matching (Madhavan et al., 2001), sentiment analysis (Godbole et al., 2007), and ontology mapping (Jean-Mary and Kabuka, 2008). Further uses of lexical knowledge include data cleaning (Kedad and Métais, 2002), visual object recognition (Marszałek and Schmid, 2007), and biomedical data analysis (Rubin and others, 2006). Many of these applications have used Englishlanguage resources like WordNet (Fellbaum, 1998). However, a more multilingual resource equipped with an easy-to-use API would not only enable us to perform all of the aforementioned tasks in additional languages, but</context>
</contexts>
<marker>Gong, Cheang, U, 2005</marker>
<rawString>Zhiguo Gong, Chan Wa Cheang, and Leong Hou U. 2005. Web query expansion by WordNet. In Proc. DEXA 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
</authors>
<title>Uby: A large-scale unified lexical-semantic resource based on LMF.</title>
<date>2012</date>
<booktitle>In Proc. EACL</booktitle>
<marker>Gurevych, 2012</marker>
<rawString>Iryna Gurevych et al. 2012. Uby: A large-scale unified lexical-semantic resource based on LMF. In Proc. EACL 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves R Jean-Mary</author>
<author>Mansur R Kabuka</author>
</authors>
<title>ASMOV: Results for OAEI</title>
<date>2008</date>
<booktitle>In Proc. OM</booktitle>
<contexts>
<context position="1330" citStr="Jean-Mary and Kabuka, 2008" startWordPosition="196" endWordPosition="199"> software API enables applications to look up over 16 million words and names. 1 Introduction Semantic knowledge about words and named entities is a fundamental building block both in various forms of language technology as well as in enduser applications. Examples of the latter include word processor thesauri, online dictionaries, question answering, and mobile services. Finding semantically related words is vital for query expansion in information retrieval (Gong et al., 2005), database schema matching (Madhavan et al., 2001), sentiment analysis (Godbole et al., 2007), and ontology mapping (Jean-Mary and Kabuka, 2008). Further uses of lexical knowledge include data cleaning (Kedad and Métais, 2002), visual object recognition (Marszałek and Schmid, 2007), and biomedical data analysis (Rubin and others, 2006). Many of these applications have used Englishlanguage resources like WordNet (Fellbaum, 1998). However, a more multilingual resource equipped with an easy-to-use API would not only enable us to perform all of the aforementioned tasks in additional languages, but also to explore cross-lingual applications like cross-lingual IR (Etzioni et al., 2007) and machine translation (Chatterjee et al., 2005). This</context>
</contexts>
<marker>Jean-Mary, Kabuka, 2008</marker>
<rawString>Yves R. Jean-Mary and Mansur R. Kabuka. 2008. ASMOV: Results for OAEI 2008. In Proc. OM 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Judea</author>
<author>Vivi Nastase</author>
<author>Michael Strube</author>
</authors>
<title>WikiNetTk – A tool kit for embedding world knowledge in NLP applications.</title>
<date>2011</date>
<booktitle>In Proc. IJCNLP</booktitle>
<contexts>
<context position="17030" citStr="Judea et al., 2011" startWordPosition="2669" endWordPosition="2672">ers, 2004), these provide less than 10 languages as of 2012. The most similar resource is BabelNet (Navigli and Ponzetto, 2010), which contains multilingual synsets but does not connect named entities from Wikipedia to them in a multilingual taxonomy. Figure 4: Part of Online Interface 6 Integrated API Our goal is to make the knowledge that we have derived available for use in applications. To this end, we have developed a fully downloadable API that can easily be used in several different programming languages. While there are many existing APIs for WordNet and other lexical resources (e.g. (Judea et al., 2011; Gurevych and others, 2012)), these don’t provide a comparable degree of integrated multilingual and taxonomic information. Interface The API can be used by initializing an accessor object and possibly specifying the list of plugins to be loaded. Depending on the particular application, one may choose only Princeton WordNet and the UWN Core, or one may want to include named entities from Wikipedia and framesemantic knowledge derived from FrameNet, for instance. The accessor provides a simple graph-based lookup API as well as some convenience methods for common types of queries. An additional </context>
</contexts>
<marker>Judea, Nastase, Strube, 2011</marker>
<rawString>Alex Judea, Vivi Nastase, and Michael Strube. 2011. WikiNetTk – A tool kit for embedding world knowledge in NLP applications. In Proc. IJCNLP 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zoubida Kedad</author>
<author>Elisabeth Métais</author>
</authors>
<title>Ontologybased data cleaning.</title>
<date>2002</date>
<booktitle>In Proc. NLDB</booktitle>
<contexts>
<context position="1412" citStr="Kedad and Métais, 2002" startWordPosition="209" endWordPosition="212">duction Semantic knowledge about words and named entities is a fundamental building block both in various forms of language technology as well as in enduser applications. Examples of the latter include word processor thesauri, online dictionaries, question answering, and mobile services. Finding semantically related words is vital for query expansion in information retrieval (Gong et al., 2005), database schema matching (Madhavan et al., 2001), sentiment analysis (Godbole et al., 2007), and ontology mapping (Jean-Mary and Kabuka, 2008). Further uses of lexical knowledge include data cleaning (Kedad and Métais, 2002), visual object recognition (Marszałek and Schmid, 2007), and biomedical data analysis (Rubin and others, 2006). Many of these applications have used Englishlanguage resources like WordNet (Fellbaum, 1998). However, a more multilingual resource equipped with an easy-to-use API would not only enable us to perform all of the aforementioned tasks in additional languages, but also to explore cross-lingual applications like cross-lingual IR (Etzioni et al., 2007) and machine translation (Chatterjee et al., 2005). This paper describes a new API that makes lexical knowledge about millions of items in</context>
</contexts>
<marker>Kedad, Métais, 2002</marker>
<rawString>Zoubida Kedad and Elisabeth Métais. 2002. Ontologybased data cleaning. In Proc. NLDB 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jayant Madhavan</author>
<author>P Bernstein</author>
<author>E Rahm</author>
</authors>
<title>Generic schema matching with Cupid. In</title>
<date>2001</date>
<booktitle>Proc. VLDB.</booktitle>
<contexts>
<context position="1236" citStr="Madhavan et al., 2001" startWordPosition="182" endWordPosition="185">wledge, and language data. An online interface provides human access to the data, while a software API enables applications to look up over 16 million words and names. 1 Introduction Semantic knowledge about words and named entities is a fundamental building block both in various forms of language technology as well as in enduser applications. Examples of the latter include word processor thesauri, online dictionaries, question answering, and mobile services. Finding semantically related words is vital for query expansion in information retrieval (Gong et al., 2005), database schema matching (Madhavan et al., 2001), sentiment analysis (Godbole et al., 2007), and ontology mapping (Jean-Mary and Kabuka, 2008). Further uses of lexical knowledge include data cleaning (Kedad and Métais, 2002), visual object recognition (Marszałek and Schmid, 2007), and biomedical data analysis (Rubin and others, 2006). Many of these applications have used Englishlanguage resources like WordNet (Fellbaum, 1998). However, a more multilingual resource equipped with an easy-to-use API would not only enable us to perform all of the aforementioned tasks in additional languages, but also to explore cross-lingual applications like c</context>
</contexts>
<marker>Madhavan, Bernstein, Rahm, 2001</marker>
<rawString>Jayant Madhavan, P. Bernstein, and E. Rahm. 2001. Generic schema matching with Cupid. In Proc. VLDB.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcin Marszałek</author>
<author>C Schmid</author>
</authors>
<title>Semantic hierarchies for visual object recognition.</title>
<date>2007</date>
<booktitle>In Proc. CVPR.</booktitle>
<contexts>
<context position="1468" citStr="Marszałek and Schmid, 2007" startWordPosition="216" endWordPosition="219">ities is a fundamental building block both in various forms of language technology as well as in enduser applications. Examples of the latter include word processor thesauri, online dictionaries, question answering, and mobile services. Finding semantically related words is vital for query expansion in information retrieval (Gong et al., 2005), database schema matching (Madhavan et al., 2001), sentiment analysis (Godbole et al., 2007), and ontology mapping (Jean-Mary and Kabuka, 2008). Further uses of lexical knowledge include data cleaning (Kedad and Métais, 2002), visual object recognition (Marszałek and Schmid, 2007), and biomedical data analysis (Rubin and others, 2006). Many of these applications have used Englishlanguage resources like WordNet (Fellbaum, 1998). However, a more multilingual resource equipped with an easy-to-use API would not only enable us to perform all of the aforementioned tasks in additional languages, but also to explore cross-lingual applications like cross-lingual IR (Etzioni et al., 2007) and machine translation (Chatterjee et al., 2005). This paper describes a new API that makes lexical knowledge about millions of items in over 200 languages available to applications, and a cor</context>
</contexts>
<marker>Marszałek, Schmid, 2007</marker>
<rawString>Marcin Marszałek and C. Schmid. 2007. Semantic hierarchies for visual object recognition. In Proc. CVPR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>BabelNet: Building a very large multilingual semantic network. In</title>
<date>2010</date>
<booktitle>Proc. ACL</booktitle>
<contexts>
<context position="16539" citStr="Navigli and Ponzetto, 2010" startWordPosition="2588" endWordPosition="2591">ieve something might look up the word ‘persuasion’ and then navigate to its antonym ‘dissuasion’ to find the Spanish translation. A non-native speaker of English looking up the word ‘tercel’ might find it helpful to see pictures available for the related terms ‘hawk’ or ‘falcon’ – a Google Image search for ‘tercel’ merely delivers images of Toyota Tercel cars. While there have been other multilingual interfaces to WordNet-style lexical knowledge in the past (Pianta et al., 2002; Atserias and others, 2004), these provide less than 10 languages as of 2012. The most similar resource is BabelNet (Navigli and Ponzetto, 2010), which contains multilingual synsets but does not connect named entities from Wikipedia to them in a multilingual taxonomy. Figure 4: Part of Online Interface 6 Integrated API Our goal is to make the knowledge that we have derived available for use in applications. To this end, we have developed a fully downloadable API that can easily be used in several different programming languages. While there are many existing APIs for WordNet and other lexical resources (e.g. (Judea et al., 2011; Gurevych and others, 2012)), these don’t provide a comparable degree of integrated multilingual and taxonom</context>
</contexts>
<marker>Navigli, Ponzetto, 2010</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2010. BabelNet: Building a very large multilingual semantic network. In Proc. ACL 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emanuele Pianta</author>
<author>Luisa Bentivogli</author>
<author>Christian Girardi</author>
</authors>
<title>MultiWordNet: Developing an aligned multilingual database.</title>
<date>2002</date>
<booktitle>In Proc. GWC.</booktitle>
<contexts>
<context position="16394" citStr="Pianta et al., 2002" startWordPosition="2565" endWordPosition="2568"> with traditional print dictionaries. For example, a user wishing to find a Spanish word for the concept of persuading someone not to believe something might look up the word ‘persuasion’ and then navigate to its antonym ‘dissuasion’ to find the Spanish translation. A non-native speaker of English looking up the word ‘tercel’ might find it helpful to see pictures available for the related terms ‘hawk’ or ‘falcon’ – a Google Image search for ‘tercel’ merely delivers images of Toyota Tercel cars. While there have been other multilingual interfaces to WordNet-style lexical knowledge in the past (Pianta et al., 2002; Atserias and others, 2004), these provide less than 10 languages as of 2012. The most similar resource is BabelNet (Navigli and Ponzetto, 2010), which contains multilingual synsets but does not connect named entities from Wikipedia to them in a multilingual taxonomy. Figure 4: Part of Online Interface 6 Integrated API Our goal is to make the knowledge that we have derived available for use in applications. To this end, we have developed a fully downloadable API that can easily be used in several different programming languages. While there are many existing APIs for WordNet and other lexical</context>
</contexts>
<marker>Pianta, Bentivogli, Girardi, 2002</marker>
<rawString>Emanuele Pianta, Luisa Bentivogli, and Christian Girardi. 2002. MultiWordNet: Developing an aligned multilingual database. In Proc. GWC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel L Rubin</author>
</authors>
<date>2006</date>
<booktitle>National Center for Biomedical Ontology. OMICS,</booktitle>
<pages>10--2</pages>
<marker>Rubin, 2006</marker>
<rawString>Daniel L. Rubin et al. 2006. National Center for Biomedical Ontology. OMICS, 10(2):185–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Shi</author>
<author>Rada Mihalcea</author>
</authors>
<title>Putting the pieces together: Combining FrameNet, VerbNet, and WordNet for robust semantic parsing.</title>
<date>2005</date>
<booktitle>In Proc. CICLing.</booktitle>
<contexts>
<context position="13882" citStr="Shi and Mihalcea, 2005" startWordPosition="2170" endWordPosition="2173">ell’ can be chosen to describe the same event. Such detailed knowledge about scenarios is largely complementary in nature to the sense relationships that WordNet provides. For instance, WordNet emphasizes the opposite meaning of the words ‘happy’ and ‘unhappy’, while frame semantics instead emphasizes the cognitive relatedness of words like ‘happy’, ‘unhappy’, ‘astonished’, and ‘amusement’, and explains that typical participants include an experiencer who experiences the emotions and external stimuli that evoke them. There have been individual systems that made use of both forms of knowledge (Shi and Mihalcea, 2005; Coppola and others, 2009), but due to their very different nature, there is currently no simple way to accomplish this feat. Our system addresses this by seamlessly integrating frame semantic knowledge into the system. We draw on FrameNet (Baker et al., 1998), the most well-known computational instantiation of frame semantics. While the FrameNet project is generally well-known, its use in practical applica154 tions has been limited due to the lack of easy-to-use APIs and because FrameNet alone does not cover as many words as WordNet. Our API simultaneously provides access to both sources. La</context>
</contexts>
<marker>Shi, Mihalcea, 2005</marker>
<rawString>Lei Shi and Rada Mihalcea. 2005. Putting the pieces together: Combining FrameNet, VerbNet, and WordNet for robust semantic parsing. In Proc. CICLing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<title>YAGO: A core of semantic knowledge.</title>
<date>2007</date>
<booktitle>In Proc. WWW</booktitle>
<contexts>
<context position="10916" citStr="Suchanek et al., 2007" startWordPosition="1719" endWordPosition="1722">bove process connects articles to their counterparts in WordNet. In the next step, we ensure that articles without any direct counterpart are linked to WordNet as well, by means of taxonomic hypernymy/instance links (de Melo and Weikum, 2010a). We generate individual hypotheses about likely parents of entities. For instance, articles are connected to their Wikipedia categories (if these are not assessed to be mere topic descriptors) and categories are linked to parent categories, etc. In order to link categories to possible parent hypernyms in WordNet, we adapt the approach proposed for YAGO (Suchanek et al., 2007) of determining the headword of the category name and disambiguating it. Since we are dealing with a multilingual scenario that draws on articles from different multilingual Wikipedia editions that all need to be connected to WordNet, we apply an algorithm that jointly looks at an entity and all of its parent candidates (not just from an individual article, but all articles in the same connected component) as well as superordinate parent candidates (parents of parents, etc.), as depicted in Figure 2. We then construct a Markov chain based on this graph of parents that also incorporates the pos</context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. YAGO: A core of semantic knowledge. In Proc. WWW 2007.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>