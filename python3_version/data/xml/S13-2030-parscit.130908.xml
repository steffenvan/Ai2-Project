<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.088947">
<title confidence="0.995404">
XLING: Matching Query Sentences to a Parallel Corpus using
Topic Models for Word Sense Disambiguation
</title>
<author confidence="0.993864">
Liling Tan and Francis Bond
</author>
<affiliation confidence="0.994937">
Division of Linguistics and Multilingual Studies,
Nanyang Technological University
</affiliation>
<address confidence="0.5383">
14 Nanyang Drive, Singapore 637332
</address>
<email confidence="0.992351">
alvations@gmail.com, bond@ieee.org
</email>
<sectionHeader confidence="0.99734" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999222666666667">
This paper describes the XLING system partici-
pation in SemEval-2013 Crosslingual Word
Sense Disambiguation task. The XLING system
introduces a novel approach to skip the sense
disambiguation step by matching query sentenc-
es to sentences in a parallel corpus using topic
models; it returns the word alignments as the
translation for the target polysemous words.
Although, the topic-model base matching under-
performed, the matching approach showed po-
tential in the simple cosine-based surface simi-
larity matching.
</bodyText>
<sectionHeader confidence="0.999395" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999865625">
This paper describes the XLING system, an un-
supervised Cross-Lingual Word Sense Disam-
biguation (CLWSD) system based on matching
query sentence to parallel corpus using topic
models. CLWSD is the task of disambiguating a
word given a context by providing the most ap-
propriate translation in different languages
(Lefever and Hoste, 2013).
</bodyText>
<sectionHeader confidence="0.995965" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999918153846154">
Topic models assume that latent topics exist in
texts and each semantic topic can be represented
with a multinomial distribution of words and
each document can be classified into different
semantic topics (Hofmann, 1999). Blei et al.
(2003b) introduced a Bayesian version of topic
modeling using Dirichlet hyper-parameters, La-
tent Dirichlet Allocation (LDA). Using LDA, a
set of topics can be generated to classify docu-
ments within a corpus. Each topic will contain a
list of all the words in the vocabulary of the cor-
pus where each word is assigned a probability of
occurring given a particular topic.
</bodyText>
<sectionHeader confidence="0.998775" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.999973">
We hypothesized that sentences with different
senses of a polysemous word will be classified
into different topics during the LDA process. By
matching the query sentence to the training sen-
tences by LDA induced topics, the most appro-
priate translation for the polysemous word in the
query sentence should be equivalent to transla-
tion of word in the matched training sentence(s)
from a parallel corpus. By pursuing this ap-
proach, we escape the traditional mode of dis-
ambiguating a sense using a sense inventory.
</bodyText>
<sectionHeader confidence="0.993117" genericHeader="method">
4 System Description
</sectionHeader>
<bodyText confidence="0.999966666666667">
The XLING_TnT system attempts the matching
subtask in three steps (1) Topicalize: match-
ing the query sentence to the training sentences
by the most probable topic. (2) Rank: the
matching sentences were ranked according to
the cosine similarity between the query and
matching sentences. (3) Translate: provides
the translation of the polysemous word in the
matched sentence(s) from the parallel corpus.
</bodyText>
<subsectionHeader confidence="0.997289">
4.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999779555555556">
The Europarl version 7 corpus bitexts (English-
German, English-Spanish, English-French, Eng-
lish-Italian and English-Dutch) were aligned at
word-level with GIZA++ (Och and Ney, 2003).
The translation tables from the word-alignments
were used to provide the translation of the poly-
semous word in the Translate step.
The English sentences from the bitexts were
lemmatized using a dictionary-based lemmatiz-
</bodyText>
<page confidence="0.963105">
167
</page>
<bodyText confidence="0.91261528">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 167–170, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
er: xlemma1. After the lemmatization, English
stopwords2 were removed from the sentences.
The lemmatized and stop filtered sentences were
used as document inputs to train the LDA topic
model in the Topicalize step.
Previously, topic models had been incorpo-
rated as global context features into a modified
naive Bayes network with traditional WSD fea-
tures (Cai et al. 2007). We try a novel approach
of integrating local context (N-grams) by using
pseudo-word sentences as input for topic induc-
tion. Here we neither lemmatize or remove stops
words. For example:
Original Europarl sentence: “Education and
cultural policies are important tools for creating
these values”
Lemmatized and stopped: “education cultural
policy be important tool create these values”
Ngram pseudo-word: “education_and_cultural
and_cultural_policies cultural_policies_are
are_important_tools important_tools_for
tools_for_creating for_creating_these creat-
ing_these_values”
</bodyText>
<subsectionHeader confidence="0.992862">
4.2 Topicalize and Match
</subsectionHeader>
<bodyText confidence="0.999668">
The Topicalize step of the system first (i)
induced a list of topics and trained a topic model
for each polysemous word using LDA, then (ii)
allocated the topic with the highest probability
to each training sentence.
Finally, at evaluation, (iii) the query sentences
were assigned the most probable topic inferred
using the trained topic models. Then the training
sentences allocated with the same topic were
considered as matching sentences for the next
Rank step.
</bodyText>
<subsubsectionHeader confidence="0.883501">
4.2.1 Topic Induction
</subsubsectionHeader>
<bodyText confidence="0.9999698">
Topic models were trained using Europarl sen-
tences that contain the target polysemous words;
one model per target word. The topic models
were induced using LDA by setting the number
of topics (#topics) as 50, and the alpha and beta
</bodyText>
<footnote confidence="0.951135333333333">
1 http://code.google.com/p/xlemma/
2 Using the Page and Article Analyzer stopwords from
http://www.ranks.nl/resources/stopwords.html
</footnote>
<bodyText confidence="0.9992022">
hyper-parameters were symmetrically set at
1.0/#topics. Blei et al. (2003) had shown that the
perplexity plateaus when #topics ≥ 50; higher
perplexity means more computing time needed
to train the model.
</bodyText>
<subsubsectionHeader confidence="0.916544">
4.2.2 Topic Allocation
</subsubsectionHeader>
<bodyText confidence="0.986738">
Each sentence was allocated the most probable
topic induced by LDA. An induced topic con-
tained a ranked list of tuples where the 2nd ele-
ment in each tuple is a word that associated with
the topic, the 1st element is the probability that
the associated word will occur given the topic.
The probabilities are generatively output using
Variational Bayes algorithm as described in
Hoffman et al. (2010). For example:
[(0.0208, &apos;sport&apos;), (0.0172, &apos;however&apos;),
(0.0170, &apos;quite&apos;), (0.0166, &apos;maritime&apos;),
(0.0133, &apos;field&apos;), (0.0133, &apos;air-transport&apos;),
(0.0130, &apos;appear&apos;), (0.0117, &apos;arrangement&apos;),
(0.0117, &apos;pertain&apos;), (0.0111, &apos;supervision&apos;)]
</bodyText>
<subsubsectionHeader confidence="0.729624">
4.2.3 Topic Inference
</subsubsectionHeader>
<bodyText confidence="0.999940272727273">
With the trained LDA model, we inferred the
most probable topic of the query sentence. Then
we extracted the top-10 sentences from the train-
ing corpus that shared the same top ranking top-
ic.
The topic induction, allocation and inference
were done separately on the lemmatized and
stopped sentences and on the pseudo-word sen-
tence, resulting in two sets of matching sentenc-
es. Only the sentences that were in both sets of
matches are considered for the Rank step.
</bodyText>
<subsectionHeader confidence="0.993238">
4.3 Rank
</subsectionHeader>
<bodyText confidence="0.999889666666667">
Matched sentences from the Topicalize step
were converted into term vectors. The vectors
were reweighted using tf-idf and ranked accord-
ing to the cosine similarity with the query sen-
tences. The top five sentences were piped into
the Translate step.
</bodyText>
<subsectionHeader confidence="0.945187">
4.4 Translate
</subsectionHeader>
<bodyText confidence="0.99990925">
From the matching sentences, the Translate
step simply checks the GIZA++ word alignment
table and outputs the translation(s) of the target
polysemous word. Each matching sentence,
</bodyText>
<page confidence="0.993079">
168
</page>
<bodyText confidence="0.999929">
could output more than 1 translation depending
on the target word alignment. As a simple way
of filtering stop-words from target European
languages, translations with less than 4 charac-
ters were removed. This effectively distills misa-
ligned non-content words, such as articles, pro-
nouns, prepositions, etc. To simplify the lemma-
tization of Spanish and French plural noun suf-
fixes, the ‘-es’ and ‘-s’ are stemmed from the
translation outputs.
The XLING_TnT system outputs one transla-
tion for each query sentence for the best result
evaluation. It output the top 5 translations for the
out-of-five evaluation.
</bodyText>
<subsectionHeader confidence="0.885463">
4.5 Fallback
</subsectionHeader>
<bodyText confidence="0.999946777777778">
For the out-of-five evaluation, if the query re-
turned less than 5 answers, the first fallback3
appended the lemma of the Most Frequent Sense
(according to Wordnet) of the target polysemous
word in their respective language from the Open
Multilingual Wordnet.4 If the first fallback was
insufficient, the second fallback appended the
most frequent translation of the target polyse-
mous word to the queries’ responses.
</bodyText>
<subsectionHeader confidence="0.943779">
4.6 Baseline
</subsectionHeader>
<bodyText confidence="0.9989363">
We also constructed a baseline for matching sen-
tences by cosine similarity between the lemmas
of the query sentence and the lemmas of each
English sentence in the training corpus.5 The
baseline system is named XLING_SnT (Similar
and Translate). The cosine similarity is calculat-
ed from the division of the vector product of the
query and training sentence (i.e. numerator) by
the root product of the vector’s magnitude
squared.
</bodyText>
<sectionHeader confidence="0.999955" genericHeader="method">
5 Results
</sectionHeader>
<bodyText confidence="0.999726">
Tables 1 and 2 present the results for the XLING
system for best and out-of-five evaluation. Our
system did worse than the task’s baseline, i.e.
the Most Frequent Translation (MFT) of the tar-
get word for all languages. Moreover the topic
</bodyText>
<footnote confidence="0.9814014">
3 Code sample for the fallback can be found at
http://goo.gl/PbdK7
4 http://www.casta-net.jp/~kuribayashi/multi/
5 Code-snippet for the baseline can be found at
http://pythonfiddle.com/surface-cosine-similarity
</footnote>
<bodyText confidence="0.9977688">
model based matching did worse than the cosine
similarity matching baseline. The results show
that matching on topics did not help. However,
Li et al. (2010) and Anaya-Sanchez et al. (2007)
had shown that pure topic model based unsuper-
vised system for WSD should perform a little
better than Most Frequent Sense baseline in
coarse-grain English WSD. Hence it was neces-
sary to perform error analysis and tweaking to
improve the XLING system.
</bodyText>
<table confidence="0.998996857142857">
BEST German Spanish French Italian Dutch
SnT 8.13 19.59 17.33 12.74 9.89
(10.36) (24.31) (11.57) (11.27) (9.56)
TnT 5.28 18.60 16.48 10.70 7.40
(5.82) (24.31) (11.63) (7.54) (8.54)
MFT 17.43 23.23 25.74 20.21 20.66
(15.30) (27.48) (20.19) (19.88) (24.15)
</table>
<tableCaption confidence="0.998522">
Table 1: Precision and (Mood) for the best evaluation
</tableCaption>
<table confidence="0.999667857142857">
OOF German Spanish French Italian Dutch
SnT 23.71 44.83 38.44 32.38 27.11
(30.57) (50.04) (32.45) (29.17) (27.31)
TnT 19.13 39.52 35.3 33.28 23.27
(23.54) (44.96) (28.02) (29.61) (22.98)
MFT 38.86 53.07 51.36 42.63 43.59
(44.35) (57.35) (47.42) (41.69) (41.97)
</table>
<tableCaption confidence="0.998671">
Table 2: Precision and (Mood) for the oof evaluation
</tableCaption>
<sectionHeader confidence="0.979282" genericHeader="method">
6 Error Analysis and Modifications
</sectionHeader>
<bodyText confidence="0.9987024">
Statistically, we could improve the robustness of
the topic models in the Topicalize step by
(i) tweaking the Dirichlet hyper-parameters to
alpha = 50/#topics, beta = 0.01 as suggested by
Wang et al. (2009).
</bodyText>
<table confidence="0.999303857142857">
BEST Mood OOF Mood
Precision Precision
German 6.50 6.71 20.98 25.18
Spanish 14.77 19.43 40.22 45.67
French 10.79 7.95 31.26 23.37
Italian 13.10 10.95 36.56 31.94
Dutch 7.42 7.47 21.66 20.42
</table>
<tableCaption confidence="0.99991">
Table 3: Evaluations on Hyper-parameter tweaks
</tableCaption>
<bodyText confidence="0.9999502">
Although the hyperparameters tweaks improves
the scores for German and Dutch evaluations it
brings the overall precision and mood precision
of the other three languages down. Since the
documents from each language are parallel, this
</bodyText>
<page confidence="0.997453">
169
</page>
<bodyText confidence="0.999948529411765">
suggests that there is some language-dependency
for LDA’s hyperparameters.
By going through the individual queries and
responses, several issues in the translate
step need to be resolved to achieve higher preci-
sion; (i) German-English and Dutch-English
word alignments containing compound words
need to be segmented (e.g. kraftomnibusverkehr
kraft omnibus verkehr) and realigned such that
the target word coach only aligns to omnibus,
(ii) lemmatization of Italian, German and Dutch
is crucial is getting the gold answers of the task
(e.g. XLING answers omnibussen while the gold
answers allowed omnibus). The use of target
language lemmatizers, such as TreeTagger
(Schmid, 1995) would have benefited the sys-
tem.
</bodyText>
<sectionHeader confidence="0.999831" genericHeader="method">
7 Discussion
</sectionHeader>
<bodyText confidence="0.9999313">
The main advantage of statistical language inde-
pendent approaches is the ability to scale the
system in any possible language. However lan-
guage dependent processing remains crucial in
building an accurate system, especially lemmati-
zation in WSD tasks (e.g. kraftomnibusverkehr).
We also hypothesize that more context would
have improved the results of using topics: dis-
ambiguating senses solely from sentential con-
text is artificially hard.
</bodyText>
<sectionHeader confidence="0.99885" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999838842105263">
Our system has approached the CLWSD task in
an unconventional way of matching query sen-
tences to parallel corpus using topic models.
Given no improvement from hyper-parameter
tweaks, it reiterates Boyd-Graber, Blei and
Zhu’s (2007) assertion that while topic models
capture polysemous use of words, they do not
carry explicit notion of senses that is necessary
for WSD. Thus our approach to match query
sentences by topics did not perform beyond the
MFT baseline in the CLWSD evaluation.
However, the surface cosine baseline, with-
out any incorporation of any sense knowledge,
had surprisingly achieved performance closer to
MFT It provides a pilot platform for future work
to approach the CLWSD as a vector-based doc-
ument retrieval task on parallel corpora and
providing the translation from the word align-
ments.
</bodyText>
<sectionHeader confidence="0.996015" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99969244">
enry Anaya- anche , Aurora ons-Porrata, and
Rafael Berlanga-Llavori. 2007. Tkb-uo: Using
sense clustering for wsd. In Proceedings of the
Fourth International Workshop on Semantic Eval-
uations (SemEval-2007), pp. 322–325.
Jordan Boyd-Graber, David M. Blei, and Xiaojin
Zhu. 2007. A Topic Model for Word Sense Dis-
ambiguation. In Proc. of Empirical Methods in
Natural Language Processing( EMNLP).
David M. Blei, Andrew Y. Ng, and Michael L. Jor-
dan. 2003. Latent Dirichlet allocation. Journal of
Machine Learning Research, 3:993–1022.
Jun-Fu Cai, Wee-Sun Lee and Yee-Whye Teh. 2007.
Improving word sense disambiguation using topic
features. In Proceedings of the 2007 Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning (EMNLP-CoNLL), pp. 1015–1023.
Christiane Fellbaum. (ed.) (1998) WordNet: An Elec-
tronic Lexical Database, MIT Press
Thomas Hofmann. 1999. Probabilistic latent semantic
indexing. In Proceedings of SIGIR &apos;99, Berkeley,
CA, USA.
Matthew Hoffman, David Blei and Francis Bach.
2010. Online Learning for Latent Dirichlet Alloca-
tion. In Proceedings of NIPS 2010.
Els Lefever and Véronique Hoste. 2013. SemEval-
2013 Task 10: Cross-Lingual Word Sense Disam-
biguation, In Proceedings SemEval 2013, in con-
junction with *SEM 2013, Atlanta, USA.
Linlin Li, Benjamin Roth and Caroline Sporleder.
Topic Models for Word Sense Disambiguation and
Token-based Idiom Detection. In Proc. of The
48th Annual Meeting of the Association for Com-
putational Linguistics (ACL), 2010. Uppsala,
Sweden.
Franz Josef Och, Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment
Models. Computational Linguistics 29:1. pp. 19-
51.
Helmut Schmid. 1995. Improvements in Part-of-
Speech Tagging with an Application to German.
Proceedings of the ACL SIGDAT-Workshop. Dub-
lin, Ireland.
Yi Wang, Hongjie Bai, Matt Stanton, Wen-Yen
Chen, Edward Y. Chang. 2009. Plda: Parallel la-
tent dirichlet allocation for large-scale applica-
tions. In Proc. of 5th International Conference on
Algorithmic Aspects in Information and Manage-
ment.
</reference>
<page confidence="0.997387">
170
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.914851">
<title confidence="0.9997055">XLING: Matching Query Sentences to a Parallel Corpus using Topic Models for Word Sense Disambiguation</title>
<author confidence="0.995879">Tan</author>
<affiliation confidence="0.9897225">Division of Linguistics and Multilingual Nanyang Technological</affiliation>
<address confidence="0.999575">14 Nanyang Drive, Singapore</address>
<email confidence="0.996357">alvations@gmail.com,bond@ieee.org</email>
<abstract confidence="0.995445538461539">This paper describes the XLING system participation in SemEval-2013 Crosslingual Word Disambiguation task. The introduces a novel approach to skip the sense disambiguation step by matching query sentences to sentences in a parallel corpus using topic models; it returns the word alignments as the translation for the target polysemous words. Although, the topic-model base matching underperformed, the matching approach showed potential in the simple cosine-based surface similarity matching.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Aurora ons-Porrata</author>
<author>Rafael Berlanga-Llavori</author>
</authors>
<title>Tkb-uo: Using sense clustering for wsd.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<pages>322--325</pages>
<marker>ons-Porrata, Berlanga-Llavori, 2007</marker>
<rawString>enry Anaya- anche , Aurora ons-Porrata, and Rafael Berlanga-Llavori. 2007. Tkb-uo: Using sense clustering for wsd. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), pp. 322–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jordan Boyd-Graber</author>
<author>David M Blei</author>
<author>Xiaojin Zhu</author>
</authors>
<title>A Topic Model for Word Sense Disambiguation.</title>
<date>2007</date>
<booktitle>In Proc. of Empirical Methods in Natural Language Processing( EMNLP).</booktitle>
<marker>Boyd-Graber, Blei, Zhu, 2007</marker>
<rawString>Jordan Boyd-Graber, David M. Blei, and Xiaojin Zhu. 2007. A Topic Model for Word Sense Disambiguation. In Proc. of Empirical Methods in Natural Language Processing( EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael L Jordan</author>
</authors>
<title>Latent Dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="1408" citStr="Blei et al. (2003" startWordPosition="203" endWordPosition="206">ty matching. 1 Introduction This paper describes the XLING system, an unsupervised Cross-Lingual Word Sense Disambiguation (CLWSD) system based on matching query sentence to parallel corpus using topic models. CLWSD is the task of disambiguating a word given a context by providing the most appropriate translation in different languages (Lefever and Hoste, 2013). 2 Background Topic models assume that latent topics exist in texts and each semantic topic can be represented with a multinomial distribution of words and each document can be classified into different semantic topics (Hofmann, 1999). Blei et al. (2003b) introduced a Bayesian version of topic modeling using Dirichlet hyper-parameters, Latent Dirichlet Allocation (LDA). Using LDA, a set of topics can be generated to classify documents within a corpus. Each topic will contain a list of all the words in the vocabulary of the corpus where each word is assigned a probability of occurring given a particular topic. 3 Approach We hypothesized that sentences with different senses of a polysemous word will be classified into different topics during the LDA process. By matching the query sentence to the training sentences by LDA induced topics, the mo</context>
<context position="5289" citStr="Blei et al. (2003)" startWordPosition="775" endWordPosition="778">rred using the trained topic models. Then the training sentences allocated with the same topic were considered as matching sentences for the next Rank step. 4.2.1 Topic Induction Topic models were trained using Europarl sentences that contain the target polysemous words; one model per target word. The topic models were induced using LDA by setting the number of topics (#topics) as 50, and the alpha and beta 1 http://code.google.com/p/xlemma/ 2 Using the Page and Article Analyzer stopwords from http://www.ranks.nl/resources/stopwords.html hyper-parameters were symmetrically set at 1.0/#topics. Blei et al. (2003) had shown that the perplexity plateaus when #topics ≥ 50; higher perplexity means more computing time needed to train the model. 4.2.2 Topic Allocation Each sentence was allocated the most probable topic induced by LDA. An induced topic contained a ranked list of tuples where the 2nd element in each tuple is a word that associated with the topic, the 1st element is the probability that the associated word will occur given the topic. The probabilities are generatively output using Variational Bayes algorithm as described in Hoffman et al. (2010). For example: [(0.0208, &apos;sport&apos;), (0.0172, &apos;howe</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael L. Jordan. 2003. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun-Fu Cai</author>
<author>Wee-Sun Lee</author>
<author>Yee-Whye Teh</author>
</authors>
<title>Improving word sense disambiguation using topic features.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>1015--1023</pages>
<contexts>
<context position="3763" citStr="Cai et al. 2007" startWordPosition="564" endWordPosition="567">Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 167–170, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics er: xlemma1. After the lemmatization, English stopwords2 were removed from the sentences. The lemmatized and stop filtered sentences were used as document inputs to train the LDA topic model in the Topicalize step. Previously, topic models had been incorporated as global context features into a modified naive Bayes network with traditional WSD features (Cai et al. 2007). We try a novel approach of integrating local context (N-grams) by using pseudo-word sentences as input for topic induction. Here we neither lemmatize or remove stops words. For example: Original Europarl sentence: “Education and cultural policies are important tools for creating these values” Lemmatized and stopped: “education cultural policy be important tool create these values” Ngram pseudo-word: “education_and_cultural and_cultural_policies cultural_policies_are are_important_tools important_tools_for tools_for_creating for_creating_these creating_these_values” 4.2 Topicalize and Match T</context>
</contexts>
<marker>Cai, Lee, Teh, 2007</marker>
<rawString>Jun-Fu Cai, Wee-Sun Lee and Yee-Whye Teh. 2007. Improving word sense disambiguation using topic features. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pp. 1015–1023.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database,</title>
<date>1998</date>
<editor>Christiane Fellbaum. (ed.)</editor>
<publisher>MIT Press</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum. (ed.) (1998) WordNet: An Electronic Lexical Database, MIT Press</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Probabilistic latent semantic indexing.</title>
<date>1999</date>
<booktitle>In Proceedings of SIGIR &apos;99,</booktitle>
<location>Berkeley, CA, USA.</location>
<contexts>
<context position="1389" citStr="Hofmann, 1999" startWordPosition="201" endWordPosition="202">surface similarity matching. 1 Introduction This paper describes the XLING system, an unsupervised Cross-Lingual Word Sense Disambiguation (CLWSD) system based on matching query sentence to parallel corpus using topic models. CLWSD is the task of disambiguating a word given a context by providing the most appropriate translation in different languages (Lefever and Hoste, 2013). 2 Background Topic models assume that latent topics exist in texts and each semantic topic can be represented with a multinomial distribution of words and each document can be classified into different semantic topics (Hofmann, 1999). Blei et al. (2003b) introduced a Bayesian version of topic modeling using Dirichlet hyper-parameters, Latent Dirichlet Allocation (LDA). Using LDA, a set of topics can be generated to classify documents within a corpus. Each topic will contain a list of all the words in the vocabulary of the corpus where each word is assigned a probability of occurring given a particular topic. 3 Approach We hypothesized that sentences with different senses of a polysemous word will be classified into different topics during the LDA process. By matching the query sentence to the training sentences by LDA ind</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann. 1999. Probabilistic latent semantic indexing. In Proceedings of SIGIR &apos;99, Berkeley, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Hoffman</author>
<author>David Blei</author>
<author>Francis Bach</author>
</authors>
<title>Online Learning for Latent Dirichlet Allocation.</title>
<date>2010</date>
<booktitle>In Proceedings of NIPS</booktitle>
<contexts>
<context position="5840" citStr="Hoffman et al. (2010)" startWordPosition="867" endWordPosition="870">r-parameters were symmetrically set at 1.0/#topics. Blei et al. (2003) had shown that the perplexity plateaus when #topics ≥ 50; higher perplexity means more computing time needed to train the model. 4.2.2 Topic Allocation Each sentence was allocated the most probable topic induced by LDA. An induced topic contained a ranked list of tuples where the 2nd element in each tuple is a word that associated with the topic, the 1st element is the probability that the associated word will occur given the topic. The probabilities are generatively output using Variational Bayes algorithm as described in Hoffman et al. (2010). For example: [(0.0208, &apos;sport&apos;), (0.0172, &apos;however&apos;), (0.0170, &apos;quite&apos;), (0.0166, &apos;maritime&apos;), (0.0133, &apos;field&apos;), (0.0133, &apos;air-transport&apos;), (0.0130, &apos;appear&apos;), (0.0117, &apos;arrangement&apos;), (0.0117, &apos;pertain&apos;), (0.0111, &apos;supervision&apos;)] 4.2.3 Topic Inference With the trained LDA model, we inferred the most probable topic of the query sentence. Then we extracted the top-10 sentences from the training corpus that shared the same top ranking topic. The topic induction, allocation and inference were done separately on the lemmatized and stopped sentences and on the pseudo-word sentence, resulting in </context>
</contexts>
<marker>Hoffman, Blei, Bach, 2010</marker>
<rawString>Matthew Hoffman, David Blei and Francis Bach. 2010. Online Learning for Latent Dirichlet Allocation. In Proceedings of NIPS 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>Véronique Hoste</author>
</authors>
<title>SemEval2013 Task 10: Cross-Lingual Word Sense Disambiguation,</title>
<date>2013</date>
<booktitle>In Proceedings SemEval 2013, in conjunction with *SEM 2013,</booktitle>
<location>Atlanta, USA.</location>
<contexts>
<context position="1154" citStr="Lefever and Hoste, 2013" startWordPosition="163" endWordPosition="166">n a parallel corpus using topic models; it returns the word alignments as the translation for the target polysemous words. Although, the topic-model base matching underperformed, the matching approach showed potential in the simple cosine-based surface similarity matching. 1 Introduction This paper describes the XLING system, an unsupervised Cross-Lingual Word Sense Disambiguation (CLWSD) system based on matching query sentence to parallel corpus using topic models. CLWSD is the task of disambiguating a word given a context by providing the most appropriate translation in different languages (Lefever and Hoste, 2013). 2 Background Topic models assume that latent topics exist in texts and each semantic topic can be represented with a multinomial distribution of words and each document can be classified into different semantic topics (Hofmann, 1999). Blei et al. (2003b) introduced a Bayesian version of topic modeling using Dirichlet hyper-parameters, Latent Dirichlet Allocation (LDA). Using LDA, a set of topics can be generated to classify documents within a corpus. Each topic will contain a list of all the words in the vocabulary of the corpus where each word is assigned a probability of occurring given a </context>
</contexts>
<marker>Lefever, Hoste, 2013</marker>
<rawString>Els Lefever and Véronique Hoste. 2013. SemEval2013 Task 10: Cross-Lingual Word Sense Disambiguation, In Proceedings SemEval 2013, in conjunction with *SEM 2013, Atlanta, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linlin Li</author>
<author>Benjamin Roth</author>
<author>Caroline Sporleder</author>
</authors>
<title>Topic Models for Word Sense Disambiguation and Token-based Idiom Detection.</title>
<date>2010</date>
<booktitle>In Proc. of The 48th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<location>Uppsala,</location>
<contexts>
<context position="9109" citStr="Li et al. (2010)" startWordPosition="1367" endWordPosition="1370">5 Results Tables 1 and 2 present the results for the XLING system for best and out-of-five evaluation. Our system did worse than the task’s baseline, i.e. the Most Frequent Translation (MFT) of the target word for all languages. Moreover the topic 3 Code sample for the fallback can be found at http://goo.gl/PbdK7 4 http://www.casta-net.jp/~kuribayashi/multi/ 5 Code-snippet for the baseline can be found at http://pythonfiddle.com/surface-cosine-similarity model based matching did worse than the cosine similarity matching baseline. The results show that matching on topics did not help. However, Li et al. (2010) and Anaya-Sanchez et al. (2007) had shown that pure topic model based unsupervised system for WSD should perform a little better than Most Frequent Sense baseline in coarse-grain English WSD. Hence it was necessary to perform error analysis and tweaking to improve the XLING system. BEST German Spanish French Italian Dutch SnT 8.13 19.59 17.33 12.74 9.89 (10.36) (24.31) (11.57) (11.27) (9.56) TnT 5.28 18.60 16.48 10.70 7.40 (5.82) (24.31) (11.63) (7.54) (8.54) MFT 17.43 23.23 25.74 20.21 20.66 (15.30) (27.48) (20.19) (19.88) (24.15) Table 1: Precision and (Mood) for the best evaluation OOF Ger</context>
</contexts>
<marker>Li, Roth, Sporleder, 2010</marker>
<rawString>Linlin Li, Benjamin Roth and Caroline Sporleder. Topic Models for Word Sense Disambiguation and Token-based Idiom Detection. In Proc. of The 48th Annual Meeting of the Association for Computational Linguistics (ACL), 2010. Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational Linguistics</journal>
<volume>29</volume>
<pages>pp.</pages>
<contexts>
<context position="2915" citStr="Och and Ney, 2003" startWordPosition="440" endWordPosition="443">ystem Description The XLING_TnT system attempts the matching subtask in three steps (1) Topicalize: matching the query sentence to the training sentences by the most probable topic. (2) Rank: the matching sentences were ranked according to the cosine similarity between the query and matching sentences. (3) Translate: provides the translation of the polysemous word in the matched sentence(s) from the parallel corpus. 4.1 Preprocessing The Europarl version 7 corpus bitexts (EnglishGerman, English-Spanish, English-French, English-Italian and English-Dutch) were aligned at word-level with GIZA++ (Och and Ney, 2003). The translation tables from the word-alignments were used to provide the translation of the polysemous word in the Translate step. The English sentences from the bitexts were lemmatized using a dictionary-based lemmatiz167 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 167–170, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics er: xlemma1. After the lemmatization, English stopwords2 were removed from the sentences. The lemmatized and stop filtered s</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och, Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics 29:1. pp. 19-51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Improvements in Part-ofSpeech Tagging with an Application to German.</title>
<date>1995</date>
<booktitle>Proceedings of the ACL SIGDAT-Workshop.</booktitle>
<location>Dublin, Ireland.</location>
<contexts>
<context position="11413" citStr="Schmid, 1995" startWordPosition="1724" endWordPosition="1725">meters. By going through the individual queries and responses, several issues in the translate step need to be resolved to achieve higher precision; (i) German-English and Dutch-English word alignments containing compound words need to be segmented (e.g. kraftomnibusverkehr kraft omnibus verkehr) and realigned such that the target word coach only aligns to omnibus, (ii) lemmatization of Italian, German and Dutch is crucial is getting the gold answers of the task (e.g. XLING answers omnibussen while the gold answers allowed omnibus). The use of target language lemmatizers, such as TreeTagger (Schmid, 1995) would have benefited the system. 7 Discussion The main advantage of statistical language independent approaches is the ability to scale the system in any possible language. However language dependent processing remains crucial in building an accurate system, especially lemmatization in WSD tasks (e.g. kraftomnibusverkehr). We also hypothesize that more context would have improved the results of using topics: disambiguating senses solely from sentential context is artificially hard. 8 Conclusion Our system has approached the CLWSD task in an unconventional way of matching query sentences to pa</context>
</contexts>
<marker>Schmid, 1995</marker>
<rawString>Helmut Schmid. 1995. Improvements in Part-ofSpeech Tagging with an Application to German. Proceedings of the ACL SIGDAT-Workshop. Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Wang</author>
<author>Hongjie Bai</author>
<author>Matt Stanton</author>
<author>Wen-Yen Chen</author>
<author>Edward Y Chang</author>
</authors>
<title>Plda: Parallel latent dirichlet allocation for large-scale applications.</title>
<date>2009</date>
<booktitle>In Proc. of 5th International Conference on Algorithmic Aspects in Information and Management.</booktitle>
<contexts>
<context position="10257" citStr="Wang et al. (2009)" startWordPosition="1549" endWordPosition="1552"> (24.15) Table 1: Precision and (Mood) for the best evaluation OOF German Spanish French Italian Dutch SnT 23.71 44.83 38.44 32.38 27.11 (30.57) (50.04) (32.45) (29.17) (27.31) TnT 19.13 39.52 35.3 33.28 23.27 (23.54) (44.96) (28.02) (29.61) (22.98) MFT 38.86 53.07 51.36 42.63 43.59 (44.35) (57.35) (47.42) (41.69) (41.97) Table 2: Precision and (Mood) for the oof evaluation 6 Error Analysis and Modifications Statistically, we could improve the robustness of the topic models in the Topicalize step by (i) tweaking the Dirichlet hyper-parameters to alpha = 50/#topics, beta = 0.01 as suggested by Wang et al. (2009). BEST Mood OOF Mood Precision Precision German 6.50 6.71 20.98 25.18 Spanish 14.77 19.43 40.22 45.67 French 10.79 7.95 31.26 23.37 Italian 13.10 10.95 36.56 31.94 Dutch 7.42 7.47 21.66 20.42 Table 3: Evaluations on Hyper-parameter tweaks Although the hyperparameters tweaks improves the scores for German and Dutch evaluations it brings the overall precision and mood precision of the other three languages down. Since the documents from each language are parallel, this 169 suggests that there is some language-dependency for LDA’s hyperparameters. By going through the individual queries and respo</context>
</contexts>
<marker>Wang, Bai, Stanton, Chen, Chang, 2009</marker>
<rawString>Yi Wang, Hongjie Bai, Matt Stanton, Wen-Yen Chen, Edward Y. Chang. 2009. Plda: Parallel latent dirichlet allocation for large-scale applications. In Proc. of 5th International Conference on Algorithmic Aspects in Information and Management.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>