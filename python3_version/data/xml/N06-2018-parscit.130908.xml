<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002899">
<title confidence="0.9981715">
MMR-based Active Machine Learning
for Bio Named Entity Recognition
</title>
<author confidence="0.99692">
Seokhwan Kim1 Yu Song2 Kyungduk Kim1 Jeong-Won Cha3 Gary Geunbae Lee1
</author>
<affiliation confidence="0.986525">
1 Dept. of Computer Science and Engineering, POSTECH, Pohang, Korea
2 AIA Information Technology Co., Ltd. Beijing, China
3 Dept. of Computer Science, Changwon National University, Changwon, Korea
</affiliation>
<email confidence="0.9846495">
megaup@postech.ac.kr, Song-Y.Song@AIG.com, getta@postech.ac.kr
jcha@changwon.ac.kr, gblee@postech.ac.kr
</email>
<sectionHeader confidence="0.994718" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999898266666667">
This paper presents a new active learning
paradigm which considers not only the
uncertainty of the classifier but also the
diversity of the corpus. The two measures
for uncertainty and diversity were com-
bined using the MMR (Maximal Marginal
Relevance) method to give the sampling
scores in our active learning strategy. We
incorporated MMR-based active machine-
learning idea into the biomedical named-
entity recognition system. Our experimen-
tal results indicated that our strategies for
active-learning based sample selection
could significantly reduce the human ef-
fort.
</bodyText>
<sectionHeader confidence="0.998779" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999756509090909">
Named-entity recognition is one of the most ele-
mentary and core problems in biomedical text min-
ing. To achieve good recognition performance, we
use a supervised machine-learning based approach
which is a standard in the named-entity recognition
task. The obstacle of supervised machine-learning
methods is the lack of the annotated training data
which is essential for achieving good performance.
Building a training corpus manually is time con-
suming, labor intensive, and expensive. Creating
training corpora for the biomedical domain is par-
ticularly expensive as it requires domain specific
expert knowledge.
One way to solve this problem is through active
learning method to select the most informative
samples for training. Active selection of the train-
ing examples can significantly reduce the neces-
sary number of labeled training examples without
degrading the performance.
Existing work for active learning explores two
approaches: certainty or uncertainty-based methods
(Lewis and Gale 1994; Scheffer and Wrobel 2001;
Thompson et al. 1999) and committee-based
methods (Cohn et al. 1994; Dagan and Engelson
1995; Freund et al. 1997; Liere and Tadepalli
1997). Uncertainty-based systems begin with an
initial classifier and the systems assign some un-
certainty scores to the un-annotated examples. The
k examples with the highest scores will be anno-
tated by human experts and the classifier will be
retrained. In the committee-based systems, diverse
committees of classifiers were generated. Each
committee member will examine the un-annotated
examples. The degree of disagreement among the
committee members will be evaluated and the ex-
amples with the highest disagreement will be se-
lected for manual annotation.
Our efforts are different from the previous ac-
tive learning approaches and are devoted to two
aspects: we propose an entropy-based measure to
quantify the uncertainty that the current classifier
holds. The most uncertain samples are selected for
human annotation. However, we also assume that
the selected training samples should give the dif-
ferent aspects of learning features to the classifica-
tion system. So, we try to catch the most
representative sentences in each sampling. The
divergence measures of the two sentences are for
the novelty of the features and their representative
levels, and are described by the minimum similar-
ity among the examples. The two measures for un-
certainty and diversity will be combined using the
MMR (Maximal Marginal Relevance) method
(Carbonell and Goldstein 1998) to give the sam-
pling scores in our active learning strategy.
</bodyText>
<page confidence="0.991092">
69
</page>
<note confidence="0.876841">
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 69–72,
New York, June 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999228571428571">
We incorporate MMR-based active machine-
learning idea into the POSBIOTM/NER (Song et
al. 2005) system which is a trainable biomedical
named-entity recognition system using the Condi-
tional Random Fields (Lafferty et al. 2001) ma-
chine learning technique to automatically identify
different sets of biological entities in the text.
</bodyText>
<sectionHeader confidence="0.7847865" genericHeader="method">
2 MMR-based Active Learning for Bio-
medical Named-entity Recognition
</sectionHeader>
<subsectionHeader confidence="0.999339">
2.1 Active Learning
</subsectionHeader>
<bodyText confidence="0.999963823529412">
We integrate active learning methods into the
POSBIOTM/NER (Song et al. 2005) system by the
following procedure: Given an active learning
scoring strategy S and a threshold value th, at each
iteration t, the learner uses training corpus TMt to
train the NER module Mt. Each time a user wants
to annotate a set of un-labeled sentences U, the
system first tags the sentences using the current
NER module Mt. At the same time, each tagged
sentence is assigned with a score according to our
scoring strategy S. Sentences will be marked if its
score is larger than the threshold value th. The tag
result is presented to the user, and those marked
ones are rectified by the user and added to the
training corpus. Once the training data accumulates
to a certain amount, the NER module Mt will be
retrained.
</bodyText>
<subsectionHeader confidence="0.999498">
2.2 Uncertainty-based Sample Selection
</subsectionHeader>
<bodyText confidence="0.9955427">
We evaluate the uncertainty degree that the current
NER module holds for a given sentence in terms of
the entropy of the sentence. Given an input se-
quence o, the state sequence set S is a finite set.
And p∧ (s  |o), s ∈ S is the probability distribu-
tion over S. By using the equation for CRF
(Lafferty et al. 2001) module, we can calculate the
probability of any possible state sequence s given
an input sequence o. Then the entropy of
is defined to be:
</bodyText>
<equation confidence="0.8345075">
H = −∑ P∧ (s  |o) log2 [ P ( s  |o )]
∧
</equation>
<subsectionHeader confidence="0.713355">
s
</subsectionHeader>
<bodyText confidence="0.999981888888889">
The number of possible state sequences grows
exponentially as the sentence length increases. In
order to measure the uncertainty by entropy, it is
inconvenient and unnecessary to compute the
probability of all the possible state sequences. In-
stead we implement N-best Viterbi search to find
the N state sequences with the highest probabilities.
The entropy H(N) is defined as the entropy of the
distribution of the N-best state sequences:
</bodyText>
<equation confidence="0.9997363125">
N ⎡ ⎤
P ( )
s  |o P ( )
s  |o
∧
2
∑ = ∑ ∧ i i
log
=− ⎢ ⎥
N N
P ⎢ ∑ ⎥
i 1 = ∧ ( )
s  |o
i i ⎣ i = P ∧ ( )
s  |o
1 1 i ⎦
</equation>
<bodyText confidence="0.855662">
The range of the entropy H(N) is [0,
</bodyText>
<equation confidence="0.991185">
1
−log2 ] which varies according to different N.
N
</equation>
<bodyText confidence="0.632074">
We could use the equation (2) to normalize the
H(N) to [0, 1].
</bodyText>
<equation confidence="0.9914775">
H N
( )′ = 1
−
N
</equation>
<subsectionHeader confidence="0.990432">
2.3 Diversity-based Sample Selection
</subsectionHeader>
<bodyText confidence="0.999971083333333">
We measure the sentence structure similarity to
represent the diversity and catch the most represen-
tative ones in order to give more diverse features to
the machine learning-based classification systems.
We propose a three-level hierarchy to represent
the structure of a sentence. The first level is NP
chunk, the second level is Part-Of-Speech tag, and
the third level is the word itself. Each word is rep-
resented using this hierarchy structure. For exam-
ple in the sentence &amp;quot;I am a boy&amp;quot;, the word &amp;quot;boy&amp;quot; is
represented as wr =[NP, NN, boy]. The similarity
score of two words is defined as:
</bodyText>
<equation confidence="0.99849375">
r r
2 ∗ Depth w w
( , )
1
r r
Depth w Depth w
( ) + ( )
1 2
</equation>
<bodyText confidence="0.945312571428572">
Where Depth(wr1 , wr2) is defined from the top
level as the number of levels that the two words are
in common. Under our three-level hierarchy
scheme above, each word representation has depth
of 3.
The structure of a sentence S is represented as
the word representation vectors [w 1, w 2 , , r wN ]
</bodyText>
<equation confidence="0.767314">
r r K .
</equation>
<bodyText confidence="0.997885">
We measure the similarity of two sentences by the
standard cosine-similarity measure. The similarity
score of two sentences is defined as:
</bodyText>
<equation confidence="0.975538777777778">
similarity S S
( 1 , 2 ) =
S1 ⋅ S1
r r r r
S 1 S 2
⋅ = ∑∑ ⋅
sim ( w 1 i w 2 j )
)
(s  |o
p∧
N)
H(
. (1)
H(N)
. (2)
2
log
sim (rw2 )
w1 ⋅
r r r r
r r
S ⋅ S12
S2
⋅ S2
i
,
.
</equation>
<page confidence="0.990604">
70
</page>
<subsectionHeader confidence="0.924136">
2.4 MMR Combination for Sample Selection
</subsectionHeader>
<bodyText confidence="0.9996522">
We would like to score the sample sentences with
respect to both the uncertainty and the diversity.
The following MMR (Maximal Marginal Rele-
vance) (Carbonell and Goldstein 1998) formula is
used to calculate the active learning score:
</bodyText>
<equation confidence="0.98056475">
def
score(si ) = A, * Uncertainty(si,M) − (1− A,) (3)
* maxs jeTM Similarity
(si, s ) j
</equation>
<bodyText confidence="0.999987133333333">
where si is the sentence to be selected, Uncertainty
is the entropy of si given current NER module M,
and Similarity indicates the divergence degree be-
tween the si and the sentence sj in the training cor-
pus TM of M. The combination rule could be
interpreted as assigning a higher score to a sen-
tence of which the NER module is uncertain and
whose configuration differs from the sentences in
the existing training corpus. The value of parame-
ter A, coordinates those two different aspects of
the desirable sample sentences.
After initializing a NER module M and an ap-
propriate value of the parameter A, , we can assign
each candidate sentence a score under the control
of the uncertainty and the diversity.
</bodyText>
<sectionHeader confidence="0.989544" genericHeader="evaluation">
3 Experiment and Discussion
</sectionHeader>
<subsectionHeader confidence="0.991185">
3.1 Experiment Setup
</subsectionHeader>
<bodyText confidence="0.999970925925926">
We conducted our active learning experiments us-
ing pool-based sample selection (Lewis and Gale
1994). The pool-based sample selection, in which
the learner chooses the best instances for labeling
from a given pool of unlabelled examples, is the
most practical approach for problems in which
unlabelled data is relatively easily available.
For our empirical evaluation of the active learn-
ing methods, we used the training and test data
released by JNLPBA (Kim et al. 2004). The train-
ing corpus contains 2000 MEDLINE abstracts, and
the test data contains 404 abstracts from the
GENIA corpus. 100 abstracts were used to train
our initial NER module. The remaining training
data were taken as the pool. Each time, we chose k
examples from the given pool to train the new
NER module and the number k varied from 1000
to 17000 with a step size 1000.
We test 4 different active learning methods: Ran-
dom selection, Entropy-based uncertainty selection,
Entropy combined with Diversity, and Normalized
Entropy (equation (2)) combined with Diversity.
When we compute the active learning score using
the entropy based method and the combining
methods we set the values of parameter N (from
equation (1)) to 3 and A, (from equation (3)) to 0.8
empirically.
</bodyText>
<subsectionHeader confidence="0.722296">
Fig1. Comparison of active learning strategies with the ran-
dom selection
3.2 Results and Analyses
</subsectionHeader>
<bodyText confidence="0.99998925">
The initial NER module gets an F-score of 52.54,
while the F-score performance of the NER module
using the whole training data set is 67.19. We plot-
ted the learning curves for the different sample
selection strategies. The interval in the x-axis be-
tween the curves shows the number of examples
selected and the interval in the y-axis shows the
performance improved.
We compared the entropy, entropy combined
with sentence diversity, normalized entropy com-
bined with sentence diversity and random selection.
The curves in Figure 1 show the relative per-
formance. The F-score increases along with the
number of selected examples and receives the best
performance when all the examples in the pool are
selected. The results suggest that all three kinds of
active learning strategies consistently outperform
the random selection.
The entropy-based example selection has im-
proved performance compared with the random
selection. The entropy (N=3) curve approaches to
the random selection around 13000 sentences se-
lected, which is reasonable since all the methods
choose the examples from the same given pool. As
</bodyText>
<page confidence="0.995334">
71
</page>
<bodyText confidence="0.999585939393939">
the number of selected sentences approaches the
pool size, the performance difference among the
different methods gets small. The best performance
of the entropy strategy is 67.31 when 17000 exam-
s are selected.
Comparing with the entropy curve, the com-
bined strategy curve shows an interesting charac-
teristic. Up to 4000 sentences, the entropy strategy
and the combined strategy perform similarly. After
the 11000 sentence point, the combined strategy
surpasses the entropy strategy. It accords with our
belief that the diversity increases the classifier&apos;s
performance when the large amount of samples is
selected. The normalized combined strategy dif-
fers from the combined strategy. It exceeds the
other strategies from the beginning and maintains
the best performance up until 12000 sentence point.
The entropy strategy reaches 67.00 in F-score
when 11000 sentences are selected. The combined
strategy receives 67.17 in F-score while 13000 sen-
tences are selected, while the end performance is
67.19 using the whole training data. The combined
strategy reduces 24.64 % of training examples
compared with the random selection. The normal-
ized combined strategy achieves 67.17 in F-score
when 11000 sentences are selected, so 35.43% of
the training examples do not need to be labeled to
achieve almost the same performance as the end
performance. The normalized combined strategy&apos;s
performance becomes similar to the random selec-
tion strategy at around 13000 sentences, and after
14000 sentences the normalized combined strategy
behaves the worst.
</bodyText>
<sectionHeader confidence="0.999286" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999990444444445">
We incorporate active learning into the biomedical
named-entity recognition system to enhance the
system&apos;s performance with only small amount of
training data. We presented the entropy-based un-
certainty sample selection and combined selection
strategies using the corpus diversity. Experiments
indicate that our strategies for active-learning
based sample sele ction could significantly reduce
the human effort.
</bodyText>
<sectionHeader confidence="0.973459" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.783288">
This research was supported as a Brain Neuroin-
formatics Research Program sponsored by Minis-
try of Commerce, Industry and Energy.
</bodyText>
<sectionHeader confidence="0.980594" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99966475">
Carbonell J., &amp; Goldstein J. (1998). The Use of MMR,
Diversity-Based Reranking for Reordering Docu-
ments and Producing Summaries. In Proceedings of
the 21st Annual International ACM-SIGIR Confer-
ence on Research and Development in Information
Retrieval, pages 335-336.
Cohn, D. A., Atlas, L., &amp; Ladner, R. E. (1994). Improv-
ing generalization with active learning, Machine
Learning, 15(2), 201-221.
Dagan, I., &amp; Engelson S. (1995). Committee-based
sampling for training probabilistic classifiers. In Pro-
ceedings of the Twelfth International Conference on
Machine Learning, pages 150-157, San Francisco,
CA, Morgan Kaufman.
Freund Y., Seung H.S., Shamir E., &amp; Tishby N. (1997).
Selective sampling using the query by committee al-
gorithm, Machine Learning, 28, 133-168.
Kim JD., Ohta T., Tsuruoka Y., &amp; Tateisi Y. (2004).
Introduction to the Bio-Entity Recognition Task at
JNLPBA, Proceedings of the International Workshop
on Natural Language Processing in Biomedicine and
its Application (JNLPBA).
Lafferty, J., McCallum, A., &amp; Pereira, F. (2001). Condi-
tional random fields: Probabilistic models for seg-
menting and labeling sequence data. In Proc. of the
18th International Conf. on Machine Learning, pages
282-289, Williamstown, MA, Morgan Kaufmann.
Lewis D., &amp; Gale W. (1994). A Sequential Algorithm
for Training Text Classifiers, In: Proceedings of the
Seventeenth Annual International ACM-SIGIR Con-
ference on Research and Development in Information
Retrieval. pp. 3-12, Springer-Verlag.
Liere, R., &amp; Tadepalli, P. (1997). Active learning with
committees for text categorization, In proceedings of
the Fourteenth National Conference on Artificial In-
telligence, pp. 591-596 Providence, RI.
Scheffer T., &amp; Wrobel S. (2001). Active learning of
partially hidden markov models. In Proceedings of
the ECML/PKDD Workshop on Instance Selection.
Song Y., Kim E., Lee G.G., &amp; Yi B-k. (2005).
POSBIOTM-NER: a trainable biomedical named-
entity recognition system. Bioinformatics, 21 (11):
2794-2796.
Thompson C.A., Califf M.E., &amp; Mooney R.J. (1999).
Active Learning for Natural Language Parsing and
Information Extraction, In Proceedings of the Six-
teenth International Machine Learning Conference,
pp.406-414, Bled, Slovenia.
</reference>
<bodyText confidence="0.278298">
ple
</bodyText>
<page confidence="0.984822">
72
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.380051">
<title confidence="0.998162">MMR-based Active Machine for Bio Named Entity Recognition</title>
<author confidence="0.999835">Yu Kyungduk Jeong-Won Gary Geunbae</author>
<affiliation confidence="0.9597325">of Computer Science and Engineering, POSTECH, Pohang, Information Technology Co., Ltd. Beijing,</affiliation>
<address confidence="0.829083">of Computer Science, Changwon National University, Changwon, Korea</address>
<email confidence="0.78344">megaup@postech.ac.kr,Song-Y.Song@AIG.com,jcha@changwon.ac.kr,gblee@postech.ac.kr</email>
<abstract confidence="0.98580675">This paper presents a new active learning paradigm which considers not only the uncertainty of the classifier but also the diversity of the corpus. The two measures for uncertainty and diversity were combined using the MMR (Maximal Marginal Relevance) method to give the sampling scores in our active learning strategy. We incorporated MMR-based active machinelearning idea into the biomedical namedentity recognition system. Our experimental results indicated that our strategies for active-learning based sample selection could significantly reduce the human effort.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Carbonell</author>
<author>J Goldstein</author>
</authors>
<title>The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries.</title>
<date>1998</date>
<booktitle>In Proceedings of the 21st Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>335--336</pages>
<contexts>
<context position="3552" citStr="Carbonell and Goldstein 1998" startWordPosition="520" endWordPosition="523">he current classifier holds. The most uncertain samples are selected for human annotation. However, we also assume that the selected training samples should give the different aspects of learning features to the classification system. So, we try to catch the most representative sentences in each sampling. The divergence measures of the two sentences are for the novelty of the features and their representative levels, and are described by the minimum similarity among the examples. The two measures for uncertainty and diversity will be combined using the MMR (Maximal Marginal Relevance) method (Carbonell and Goldstein 1998) to give the sampling scores in our active learning strategy. 69 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 69–72, New York, June 2006. c�2006 Association for Computational Linguistics We incorporate MMR-based active machinelearning idea into the POSBIOTM/NER (Song et al. 2005) system which is a trainable biomedical named-entity recognition system using the Conditional Random Fields (Lafferty et al. 2001) machine learning technique to automatically identify different sets of biological entities in the text. 2 MMR-based Active Learnin</context>
<context position="7792" citStr="Carbonell and Goldstein 1998" startWordPosition="1338" endWordPosition="1341">ure of a sentence S is represented as the word representation vectors [w 1, w 2 , , r wN ] r r K . We measure the similarity of two sentences by the standard cosine-similarity measure. The similarity score of two sentences is defined as: similarity S S ( 1 , 2 ) = S1 ⋅ S1 r r r r S 1 S 2 ⋅ = ∑∑ ⋅ sim ( w 1 i w 2 j ) ) (s |o p∧ N) H( . (1) H(N) . (2) 2 log sim (rw2 ) w1 ⋅ r r r r r r S ⋅ S12 S2 ⋅ S2 i , . 70 2.4 MMR Combination for Sample Selection We would like to score the sample sentences with respect to both the uncertainty and the diversity. The following MMR (Maximal Marginal Relevance) (Carbonell and Goldstein 1998) formula is used to calculate the active learning score: def score(si ) = A, * Uncertainty(si,M) − (1− A,) (3) * maxs jeTM Similarity (si, s ) j where si is the sentence to be selected, Uncertainty is the entropy of si given current NER module M, and Similarity indicates the divergence degree between the si and the sentence sj in the training corpus TM of M. The combination rule could be interpreted as assigning a higher score to a sentence of which the NER module is uncertain and whose configuration differs from the sentences in the existing training corpus. The value of parameter A, coordina</context>
</contexts>
<marker>Carbonell, Goldstein, 1998</marker>
<rawString>Carbonell J., &amp; Goldstein J. (1998). The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries. In Proceedings of the 21st Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, pages 335-336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Cohn</author>
<author>L Atlas</author>
<author>R E Ladner</author>
</authors>
<title>Improving generalization with active learning,</title>
<date>1994</date>
<booktitle>Machine Learning,</booktitle>
<volume>15</volume>
<issue>2</issue>
<pages>201--221</pages>
<contexts>
<context position="2124" citStr="Cohn et al. 1994" startWordPosition="299" endWordPosition="302">nsive. Creating training corpora for the biomedical domain is particularly expensive as it requires domain specific expert knowledge. One way to solve this problem is through active learning method to select the most informative samples for training. Active selection of the training examples can significantly reduce the necessary number of labeled training examples without degrading the performance. Existing work for active learning explores two approaches: certainty or uncertainty-based methods (Lewis and Gale 1994; Scheffer and Wrobel 2001; Thompson et al. 1999) and committee-based methods (Cohn et al. 1994; Dagan and Engelson 1995; Freund et al. 1997; Liere and Tadepalli 1997). Uncertainty-based systems begin with an initial classifier and the systems assign some uncertainty scores to the un-annotated examples. The k examples with the highest scores will be annotated by human experts and the classifier will be retrained. In the committee-based systems, diverse committees of classifiers were generated. Each committee member will examine the un-annotated examples. The degree of disagreement among the committee members will be evaluated and the examples with the highest disagreement will be select</context>
</contexts>
<marker>Cohn, Atlas, Ladner, 1994</marker>
<rawString>Cohn, D. A., Atlas, L., &amp; Ladner, R. E. (1994). Improving generalization with active learning, Machine Learning, 15(2), 201-221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>S Engelson</author>
</authors>
<title>Committee-based sampling for training probabilistic classifiers.</title>
<date>1995</date>
<booktitle>In Proceedings of the Twelfth International Conference on Machine Learning,</booktitle>
<pages>150--157</pages>
<location>San Francisco, CA, Morgan Kaufman.</location>
<contexts>
<context position="2149" citStr="Dagan and Engelson 1995" startWordPosition="303" endWordPosition="306">aining corpora for the biomedical domain is particularly expensive as it requires domain specific expert knowledge. One way to solve this problem is through active learning method to select the most informative samples for training. Active selection of the training examples can significantly reduce the necessary number of labeled training examples without degrading the performance. Existing work for active learning explores two approaches: certainty or uncertainty-based methods (Lewis and Gale 1994; Scheffer and Wrobel 2001; Thompson et al. 1999) and committee-based methods (Cohn et al. 1994; Dagan and Engelson 1995; Freund et al. 1997; Liere and Tadepalli 1997). Uncertainty-based systems begin with an initial classifier and the systems assign some uncertainty scores to the un-annotated examples. The k examples with the highest scores will be annotated by human experts and the classifier will be retrained. In the committee-based systems, diverse committees of classifiers were generated. Each committee member will examine the un-annotated examples. The degree of disagreement among the committee members will be evaluated and the examples with the highest disagreement will be selected for manual annotation.</context>
</contexts>
<marker>Dagan, Engelson, 1995</marker>
<rawString>Dagan, I., &amp; Engelson S. (1995). Committee-based sampling for training probabilistic classifiers. In Proceedings of the Twelfth International Conference on Machine Learning, pages 150-157, San Francisco, CA, Morgan Kaufman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Freund</author>
<author>H S Seung</author>
<author>E Shamir</author>
<author>N Tishby</author>
</authors>
<title>Selective sampling using the query by committee algorithm,</title>
<date>1997</date>
<booktitle>Machine Learning,</booktitle>
<volume>28</volume>
<pages>133--168</pages>
<contexts>
<context position="2169" citStr="Freund et al. 1997" startWordPosition="307" endWordPosition="310">omedical domain is particularly expensive as it requires domain specific expert knowledge. One way to solve this problem is through active learning method to select the most informative samples for training. Active selection of the training examples can significantly reduce the necessary number of labeled training examples without degrading the performance. Existing work for active learning explores two approaches: certainty or uncertainty-based methods (Lewis and Gale 1994; Scheffer and Wrobel 2001; Thompson et al. 1999) and committee-based methods (Cohn et al. 1994; Dagan and Engelson 1995; Freund et al. 1997; Liere and Tadepalli 1997). Uncertainty-based systems begin with an initial classifier and the systems assign some uncertainty scores to the un-annotated examples. The k examples with the highest scores will be annotated by human experts and the classifier will be retrained. In the committee-based systems, diverse committees of classifiers were generated. Each committee member will examine the un-annotated examples. The degree of disagreement among the committee members will be evaluated and the examples with the highest disagreement will be selected for manual annotation. Our efforts are dif</context>
</contexts>
<marker>Freund, Seung, Shamir, Tishby, 1997</marker>
<rawString>Freund Y., Seung H.S., Shamir E., &amp; Tishby N. (1997). Selective sampling using the query by committee algorithm, Machine Learning, 28, 133-168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kim JD</author>
<author>T Ohta</author>
<author>Y Tsuruoka</author>
<author>Y Tateisi</author>
</authors>
<title>Introduction to the Bio-Entity Recognition Task at JNLPBA,</title>
<date>2004</date>
<booktitle>Proceedings of the International Workshop on Natural Language Processing in Biomedicine and its Application (JNLPBA).</booktitle>
<marker>JD, Ohta, Tsuruoka, Tateisi, 2004</marker>
<rawString>Kim JD., Ohta T., Tsuruoka Y., &amp; Tateisi Y. (2004). Introduction to the Bio-Entity Recognition Task at JNLPBA, Proceedings of the International Workshop on Natural Language Processing in Biomedicine and its Application (JNLPBA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proc. of the 18th International Conf. on Machine Learning,</booktitle>
<pages>282--289</pages>
<publisher>Morgan Kaufmann.</publisher>
<location>Williamstown, MA,</location>
<contexts>
<context position="4021" citStr="Lafferty et al. 2001" startWordPosition="591" endWordPosition="594">amples. The two measures for uncertainty and diversity will be combined using the MMR (Maximal Marginal Relevance) method (Carbonell and Goldstein 1998) to give the sampling scores in our active learning strategy. 69 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 69–72, New York, June 2006. c�2006 Association for Computational Linguistics We incorporate MMR-based active machinelearning idea into the POSBIOTM/NER (Song et al. 2005) system which is a trainable biomedical named-entity recognition system using the Conditional Random Fields (Lafferty et al. 2001) machine learning technique to automatically identify different sets of biological entities in the text. 2 MMR-based Active Learning for Biomedical Named-entity Recognition 2.1 Active Learning We integrate active learning methods into the POSBIOTM/NER (Song et al. 2005) system by the following procedure: Given an active learning scoring strategy S and a threshold value th, at each iteration t, the learner uses training corpus TMt to train the NER module Mt. Each time a user wants to annotate a set of un-labeled sentences U, the system first tags the sentences using the current NER module Mt. A</context>
<context position="5366" citStr="Lafferty et al. 2001" startWordPosition="825" endWordPosition="828"> if its score is larger than the threshold value th. The tag result is presented to the user, and those marked ones are rectified by the user and added to the training corpus. Once the training data accumulates to a certain amount, the NER module Mt will be retrained. 2.2 Uncertainty-based Sample Selection We evaluate the uncertainty degree that the current NER module holds for a given sentence in terms of the entropy of the sentence. Given an input sequence o, the state sequence set S is a finite set. And p∧ (s |o), s ∈ S is the probability distribution over S. By using the equation for CRF (Lafferty et al. 2001) module, we can calculate the probability of any possible state sequence s given an input sequence o. Then the entropy of is defined to be: H = −∑ P∧ (s |o) log2 [ P ( s |o )] ∧ s The number of possible state sequences grows exponentially as the sentence length increases. In order to measure the uncertainty by entropy, it is inconvenient and unnecessary to compute the probability of all the possible state sequences. Instead we implement N-best Viterbi search to find the N state sequences with the highest probabilities. The entropy H(N) is defined as the entropy of the distribution of the N-bes</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>Lafferty, J., McCallum, A., &amp; Pereira, F. (2001). Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proc. of the 18th International Conf. on Machine Learning, pages 282-289, Williamstown, MA, Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lewis</author>
<author>W Gale</author>
</authors>
<title>A Sequential Algorithm for Training Text Classifiers, In:</title>
<date>1994</date>
<booktitle>Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval.</booktitle>
<pages>3--12</pages>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="2029" citStr="Lewis and Gale 1994" startWordPosition="284" endWordPosition="287">good performance. Building a training corpus manually is time consuming, labor intensive, and expensive. Creating training corpora for the biomedical domain is particularly expensive as it requires domain specific expert knowledge. One way to solve this problem is through active learning method to select the most informative samples for training. Active selection of the training examples can significantly reduce the necessary number of labeled training examples without degrading the performance. Existing work for active learning explores two approaches: certainty or uncertainty-based methods (Lewis and Gale 1994; Scheffer and Wrobel 2001; Thompson et al. 1999) and committee-based methods (Cohn et al. 1994; Dagan and Engelson 1995; Freund et al. 1997; Liere and Tadepalli 1997). Uncertainty-based systems begin with an initial classifier and the systems assign some uncertainty scores to the un-annotated examples. The k examples with the highest scores will be annotated by human experts and the classifier will be retrained. In the committee-based systems, diverse committees of classifiers were generated. Each committee member will examine the un-annotated examples. The degree of disagreement among the co</context>
<context position="8791" citStr="Lewis and Gale 1994" startWordPosition="1512" endWordPosition="1515">le could be interpreted as assigning a higher score to a sentence of which the NER module is uncertain and whose configuration differs from the sentences in the existing training corpus. The value of parameter A, coordinates those two different aspects of the desirable sample sentences. After initializing a NER module M and an appropriate value of the parameter A, , we can assign each candidate sentence a score under the control of the uncertainty and the diversity. 3 Experiment and Discussion 3.1 Experiment Setup We conducted our active learning experiments using pool-based sample selection (Lewis and Gale 1994). The pool-based sample selection, in which the learner chooses the best instances for labeling from a given pool of unlabelled examples, is the most practical approach for problems in which unlabelled data is relatively easily available. For our empirical evaluation of the active learning methods, we used the training and test data released by JNLPBA (Kim et al. 2004). The training corpus contains 2000 MEDLINE abstracts, and the test data contains 404 abstracts from the GENIA corpus. 100 abstracts were used to train our initial NER module. The remaining training data were taken as the pool. E</context>
</contexts>
<marker>Lewis, Gale, 1994</marker>
<rawString>Lewis D., &amp; Gale W. (1994). A Sequential Algorithm for Training Text Classifiers, In: Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval. pp. 3-12, Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Liere</author>
<author>P Tadepalli</author>
</authors>
<title>Active learning with committees for text categorization,</title>
<date>1997</date>
<booktitle>In proceedings of the Fourteenth National Conference on Artificial Intelligence,</booktitle>
<pages>591--596</pages>
<location>Providence, RI.</location>
<contexts>
<context position="2196" citStr="Liere and Tadepalli 1997" startWordPosition="311" endWordPosition="314">articularly expensive as it requires domain specific expert knowledge. One way to solve this problem is through active learning method to select the most informative samples for training. Active selection of the training examples can significantly reduce the necessary number of labeled training examples without degrading the performance. Existing work for active learning explores two approaches: certainty or uncertainty-based methods (Lewis and Gale 1994; Scheffer and Wrobel 2001; Thompson et al. 1999) and committee-based methods (Cohn et al. 1994; Dagan and Engelson 1995; Freund et al. 1997; Liere and Tadepalli 1997). Uncertainty-based systems begin with an initial classifier and the systems assign some uncertainty scores to the un-annotated examples. The k examples with the highest scores will be annotated by human experts and the classifier will be retrained. In the committee-based systems, diverse committees of classifiers were generated. Each committee member will examine the un-annotated examples. The degree of disagreement among the committee members will be evaluated and the examples with the highest disagreement will be selected for manual annotation. Our efforts are different from the previous ac</context>
</contexts>
<marker>Liere, Tadepalli, 1997</marker>
<rawString>Liere, R., &amp; Tadepalli, P. (1997). Active learning with committees for text categorization, In proceedings of the Fourteenth National Conference on Artificial Intelligence, pp. 591-596 Providence, RI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Scheffer</author>
<author>S Wrobel</author>
</authors>
<title>Active learning of partially hidden markov models.</title>
<date>2001</date>
<booktitle>In Proceedings of the ECML/PKDD Workshop on Instance Selection.</booktitle>
<contexts>
<context position="2055" citStr="Scheffer and Wrobel 2001" startWordPosition="288" endWordPosition="291">lding a training corpus manually is time consuming, labor intensive, and expensive. Creating training corpora for the biomedical domain is particularly expensive as it requires domain specific expert knowledge. One way to solve this problem is through active learning method to select the most informative samples for training. Active selection of the training examples can significantly reduce the necessary number of labeled training examples without degrading the performance. Existing work for active learning explores two approaches: certainty or uncertainty-based methods (Lewis and Gale 1994; Scheffer and Wrobel 2001; Thompson et al. 1999) and committee-based methods (Cohn et al. 1994; Dagan and Engelson 1995; Freund et al. 1997; Liere and Tadepalli 1997). Uncertainty-based systems begin with an initial classifier and the systems assign some uncertainty scores to the un-annotated examples. The k examples with the highest scores will be annotated by human experts and the classifier will be retrained. In the committee-based systems, diverse committees of classifiers were generated. Each committee member will examine the un-annotated examples. The degree of disagreement among the committee members will be ev</context>
</contexts>
<marker>Scheffer, Wrobel, 2001</marker>
<rawString>Scheffer T., &amp; Wrobel S. (2001). Active learning of partially hidden markov models. In Proceedings of the ECML/PKDD Workshop on Instance Selection.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Song</author>
<author>E Kim</author>
<author>G G Lee</author>
<author>B-k Yi</author>
</authors>
<title>POSBIOTM-NER: a trainable biomedical namedentity recognition system.</title>
<date>2005</date>
<journal>Bioinformatics,</journal>
<volume>21</volume>
<issue>11</issue>
<pages>2794--2796</pages>
<contexts>
<context position="3891" citStr="Song et al. 2005" startWordPosition="572" endWordPosition="575"> are for the novelty of the features and their representative levels, and are described by the minimum similarity among the examples. The two measures for uncertainty and diversity will be combined using the MMR (Maximal Marginal Relevance) method (Carbonell and Goldstein 1998) to give the sampling scores in our active learning strategy. 69 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 69–72, New York, June 2006. c�2006 Association for Computational Linguistics We incorporate MMR-based active machinelearning idea into the POSBIOTM/NER (Song et al. 2005) system which is a trainable biomedical named-entity recognition system using the Conditional Random Fields (Lafferty et al. 2001) machine learning technique to automatically identify different sets of biological entities in the text. 2 MMR-based Active Learning for Biomedical Named-entity Recognition 2.1 Active Learning We integrate active learning methods into the POSBIOTM/NER (Song et al. 2005) system by the following procedure: Given an active learning scoring strategy S and a threshold value th, at each iteration t, the learner uses training corpus TMt to train the NER module Mt. Each tim</context>
</contexts>
<marker>Song, Kim, Lee, Yi, 2005</marker>
<rawString>Song Y., Kim E., Lee G.G., &amp; Yi B-k. (2005). POSBIOTM-NER: a trainable biomedical namedentity recognition system. Bioinformatics, 21 (11): 2794-2796.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C A Thompson</author>
<author>M E Califf</author>
<author>R J Mooney</author>
</authors>
<title>Active Learning for Natural Language Parsing and Information Extraction,</title>
<date>1999</date>
<booktitle>In Proceedings of the Sixteenth International Machine Learning Conference,</booktitle>
<pages>406--414</pages>
<location>Bled, Slovenia.</location>
<contexts>
<context position="2078" citStr="Thompson et al. 1999" startWordPosition="292" endWordPosition="295">nually is time consuming, labor intensive, and expensive. Creating training corpora for the biomedical domain is particularly expensive as it requires domain specific expert knowledge. One way to solve this problem is through active learning method to select the most informative samples for training. Active selection of the training examples can significantly reduce the necessary number of labeled training examples without degrading the performance. Existing work for active learning explores two approaches: certainty or uncertainty-based methods (Lewis and Gale 1994; Scheffer and Wrobel 2001; Thompson et al. 1999) and committee-based methods (Cohn et al. 1994; Dagan and Engelson 1995; Freund et al. 1997; Liere and Tadepalli 1997). Uncertainty-based systems begin with an initial classifier and the systems assign some uncertainty scores to the un-annotated examples. The k examples with the highest scores will be annotated by human experts and the classifier will be retrained. In the committee-based systems, diverse committees of classifiers were generated. Each committee member will examine the un-annotated examples. The degree of disagreement among the committee members will be evaluated and the example</context>
</contexts>
<marker>Thompson, Califf, Mooney, 1999</marker>
<rawString>Thompson C.A., Califf M.E., &amp; Mooney R.J. (1999). Active Learning for Natural Language Parsing and Information Extraction, In Proceedings of the Sixteenth International Machine Learning Conference, pp.406-414, Bled, Slovenia.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>