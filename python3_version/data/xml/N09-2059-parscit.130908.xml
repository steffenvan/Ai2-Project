<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.022947">
<title confidence="0.994632">
Estimating and Exploiting the Entropy of Sense Distributions
</title>
<author confidence="0.99917">
Peng Jin Diana McCarthy, Rob Koeling and John Carroll
</author>
<affiliation confidence="0.9985505">
Institute of Computational Linguistics University of Sussex
Peking University Falmer, East Sussex
</affiliation>
<address confidence="0.896299">
Beijing China BN1 9QJ, UK
</address>
<email confidence="0.997725">
jandp@pku.edu.cn {dianam,robk,johnca}@sussex.ac.uk
</email>
<sectionHeader confidence="0.995188" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.973634214285714">
Word sense distributions are usually skewed.
Predicting the extent of the skew can help a
word sense disambiguation (WSD) system de-
termine whether to consider evidence from the
local context or apply the simple yet effec-
tive heuristic of using the first (most frequent)
sense. In this paper, we propose a method to
estimate the entropy of a sense distribution to
boost the precision of a first sense heuristic by
restricting its application to words with lower
entropy. We show on two standard datasets
that automatic prediction of entropy can in-
crease the performance of an automatic first
sense heuristic.
</bodyText>
<sectionHeader confidence="0.998942" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999869">
Word sense distributions are typically skewed and
WSD systems do best when they exploit this ten-
dency. This is usually done by estimating the most
frequent sense (MFS) for each word from a training
corpus and using that sense as a back-off strategy for
a word when there is no convincing evidence from
the context. This is known as the MFS heuristic 1
and is very powerful since sense distributions are
usually skewed. The heuristic becomes particularly
hard to beat for words with highly skewed sense dis-
tributions (Yarowsky and Florian, 2002). Although
the MFS can be estimated from tagged corpora, there
are always cases where there is insufficient data, or
where the data is inappropriate, for example because
</bodyText>
<footnote confidence="0.948334">
1It is also referred to as the first sense heuristic in the WSD
literature and in this paper.
</footnote>
<bodyText confidence="0.999628428571429">
it comes from a very different domain. This has mo-
tivated some recent work attempting to estimate the
distributions automatically (McCarthy et al., 2004;
Lapata and Keller, 2007). This paper examines the
case for determining the skew of a word sense distri-
bution by estimating entropy and then using this to
increase the precision of an unsupervised first sense
heuristic by restricting application to those words
where the system can automatically detect that it has
the most chance. We use a method based on that
proposed by McCarthy et al. (2004) as this approach
does not require hand-labelled corpora. The method
could easily be adapted to other methods for predic-
ing predominant sense.
</bodyText>
<sectionHeader confidence="0.953077" genericHeader="introduction">
2 Method
</sectionHeader>
<bodyText confidence="0.999970944444444">
Given a listing of senses from an inventory, the
method proposed by McCarthy et al. (2004) pro-
vides a prevalence ranking score to produce a MFS
heuristic. We make a slight modification to Mc-
Carthy et al.’s prevalence score and use it to es-
timate the probability distribution over the senses
of a word. We use the same resources as Mc-
Carthy et al. (2004): a distributional similarity the-
saurus and a WordNet semantic similarity measure.
The thesaurus was produced using the metric de-
scribed by Lin (1998) with input from the gram-
matical relation data extracted using the 90 mil-
lion words of written English from the British Na-
tional Corpus (BNC) (Leech, 1992) using the RASP
parser (Briscoe and Carroll, 2002). The thesaurus
consists of entries for each word (w) with the top
50 “nearest neighbours” to w, where the neighbours
are words ranked by the distributional similarity that
</bodyText>
<page confidence="0.980734">
233
</page>
<note confidence="0.357209">
Proceedings of NAACL HLT 2009: Short Papers, pages 233–236,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999012166666667">
they share with w. The WordNet similarity score
is obtained with the jcn measure (Jiang and Con-
rath, 1997) using the WordNet Similarity Package
0.05 (Patwardhan and Pedersen, 2003) and WordNet
version 1.6. The jcn measure needs word frequency
information, which we obtained from the BNC.
</bodyText>
<subsectionHeader confidence="0.998817">
2.1 Estimates of Predominance, Probability
and Entropy
</subsectionHeader>
<bodyText confidence="0.990704846153846">
Following McCarthy et al. (2004), we calculate
prevalence of each sense of the word (w) using a
weighted sum of the distributional similarity scores
of the top 50 neighbours of w. The sense of w that
has the highest value is the automatically detected
MFS (predominant sense). The weights are deter-
mined by the WordNet similarity between the sense
in question and the neighbour. We make a modi-
fication to the original method by multiplying the
weight by the inverse rank of the neighbour from
the list of 50 neighbours. This modification magni-
fies the contribution to each sense depending on the
rank of the neighbour while still allowing a neigh-
bour to contribute to all senses that it relates too.
We verified the effect of this change compared to the
original ranking score by measuring cross-entropy. 2
Let Nw = n1,n2 ...nk denote the ordered set of the
top k = 50 neighbours of w according to the distri-
butional similarity thesaurus, senses(w) is the set of
senses of w and dss(w,nj) is the distributional sim-
ilarity score of a word w and its jth neighbour. Let
wsi be a sense of w then wnss(wsi,nj) is the maxi-
mum WordNet similarity score between wsi and the
WordNet sense of the neighbour (nj) that maximises
this score. The prevalence score is calculated as fol-
lows with 1 being our modification to McCarthy
</bodyText>
<equation confidence="0.945877666666667">
rankn j
et al.
Prevalence Score(wsi) = ∑nj∈Nw dss(w,nj)×
wnss(wsi,nj) 1 (1)
× ranknj
∑wsi0 ∈senses(w) wnss (wsi0, nj )
</equation>
<bodyText confidence="0.99941025">
To turn this score into a probability estimate we sum
the scores over all senses of a word and the proba-
bility for a sense is the original score divided by this
sum:
</bodyText>
<footnote confidence="0.827864">
2Our modified version of the score gave a lower cross-
entropy with SemCor compared to that in McCarthy et al. The
result was highly significant with p &lt; 0.01 on the t-test.
</footnote>
<equation confidence="0.9794015">
prevalence score(wsi)
ˆp(wsi) = ∑wsj∈w prevalence score(wsj) (2)
</equation>
<bodyText confidence="0.9997835">
To smooth the data, we evenly distribute 1/10 of the
smallest prevalence score to all senses with a unde-
fined prevalence score values. Entropy is measured
as:
</bodyText>
<equation confidence="0.9986405">
H(senses(w)) = −∑ p(wsi)log(p(wsi))
wsi∈senses(w)
</equation>
<bodyText confidence="0.9770985">
using our estimate ( ˆp) for the probability distribu-
tion p over the senses of w.
</bodyText>
<sectionHeader confidence="0.999795" genericHeader="background">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999994833333333">
We conducted two experiments to evaluate the ben-
efit of using our estimate of entropy to restrict appli-
cation of the MFS heuristic. The two experiments
are conducted on the polysemous nouns in SemCor
and the nouns in the SENSEVAL-2 English all words
task (we will refer to this as SE2-EAW).
</bodyText>
<subsectionHeader confidence="0.988425">
3.1 SemCor
</subsectionHeader>
<bodyText confidence="0.999902708333334">
For this experiment we used all the polysemous
nouns in Semcor 1.6 (excluding multiwords and
proper nouns). We depart slightly from (McCarthy
et al., 2004) in including all polysemous nouns
whereas they limited the experiment to those with
a frequency in SemCor of 3 or more and where there
is one sense with a higher frequency than the others.
Table 1 shows the precision of finding the predomi-
nant sense using equation 1 with respect to different
entropy thresholds. At each threshold, the MFS in
Semcor provides the upper-bound (UB). The random
baseline (RBL) is computed by selecting one of the
senses of the target word randomly as the predomi-
nant sense. As we hypothesized, precision is higher
when the entropy of the sense distribution is lower,
which is an encouraging result given that the entropy
is automatically estimated. The performance of the
random baseline is higher at lower entropy which
shows that the task is easier and involves a lower de-
gree of polysemy of the target words. However, the
gains over the random baseline are greater at lower
entropy levels indicating that the merits of detect-
ing the skew of the distribution cannot all be due to
lower polysemy levels.
</bodyText>
<page confidence="0.984085">
234
</page>
<table confidence="0.999989416666667">
H eq 1 precision UB #
(&lt;) RBL tokens
0.5 - - - 0
0.9 80.3 50.0 84.8 466
0.95 85.1 50.0 90.9 1360
1 68.5 50.0 87.4 9874
1.5 67.6 42.6 86.9 11287
2 58.0 36.7 79.5 25997
2.5 55.7 34.4 77.6 31599
3.0 50.2 30.6 73.4 41401
4.0 47.6 28.5 70.8 46987
5.0 (all) 47.3 27.3 70.5 47539
</table>
<tableCaption confidence="0.99421">
Table 1: First sense heuristic on SemCor
</tableCaption>
<table confidence="0.999763583333333">
Freq &lt; P #tokens
1 45.9 1132
5 50.1 5765
10 50.7 10736
100 49.4 39543
1000(all) 47.3 47539
#senses &lt; P #tokens
2 67.2 10736
5 55.4 31181
8 50.1 41393
12 47.8 46041
30(all) 47.3 47539
</table>
<tableCaption confidence="0.9626665">
Table 2: Precision (P) of equation 1 on SemCor with re-
spect to frequency and polysemy
</tableCaption>
<bodyText confidence="0.999984818181818">
We also conducted a frequency and polysemy
analysis shown in Table 2 to demonstrate that the
increase in precision is not all due to frequency or
polysemy. This is important, since both frequency
and polysemy level (assuming a predefined sense in-
ventory) could be obtained without the need for au-
tomatic estimation. As we can see, while precision
is higher for lower polysemy, the automatic estimate
of entropy can provide a greater increase in preci-
sion than polysemy, and frequency does not seem to
be strongly correlated with precision.
</bodyText>
<subsectionHeader confidence="0.999424">
3.2 SENSEVAL-2 English All Words Dataset
</subsectionHeader>
<bodyText confidence="0.99985825">
The SE2-EAW task provides a hand-tagged test suite
of 5,000 words of running text from three articles
from the Penn Treebank II (Palmer et al., 2001).
Again, we examine whether precision of the MFS
</bodyText>
<table confidence="0.999955416666667">
H eq 1 precision UB #
(&lt;) RBL SC tokens
0.5 - - - - 0
0.9 1 50.0 1 1 7
0.95 94.7 50.0 94.7 1 19
1 69.6 50.0 81.3 94.6 112
1.5 68.0 49.0 81.3 93.8 128
2 69.6 34.7 68.2 87.7 421
2.5 65.0 33.0 65.0 86.5 488
3.0 56.6 27.5 60.8 80.1 687
4.0 52.6 25.6 58.8 79.2 766
5.0 (all) 51.5 25.6 58.5 79.3 769
</table>
<tableCaption confidence="0.999825">
Table 3: First sense heuristic on SE2-EAW
</tableCaption>
<bodyText confidence="0.999228090909091">
heuristic can be increased by restricting application
depending on entropy. We use the same resources as
for the SemCor experiment. 3 Table 3 gives the re-
sults. The most frequent sense (MFS) from SE2-EAW
itself provides the upper-bound (UB). We also com-
pare performance with the Semcor MFS (SC). Per-
formance is close to the Semcor MFS while not re-
lying on any manual tagging. As before, precision
increases significantly for words with low estimated
entropy, and the gains over the random baseline are
higher compared to the gains including all words.
</bodyText>
<sectionHeader confidence="0.9999" genericHeader="related work">
4 Related Work
</sectionHeader>
<bodyText confidence="0.9997998">
There is promising related work on determining the
predominant sense for a MFS heuristic (Lapata and
Keller, 2007; Mohammad and Hirst, 2006) but our
work is the first to use the ranking score to estimate
entropy and apply it to determine the confidence in
the MFS heuristic. It is likely that these methods
would also have increased precision if the ranking
scores were used to estimate entropy. We leave such
investigations for further work.
Chan and Ng (2005) estimate word sense distri-
butions and demonstrate that sense distribution esti-
mation improves a supervised WSD classifier. They
use three sense distribution methods, including that
of McCarthy et al. (2004). While the other two
methods outperform the McCarthy et al. method,
</bodyText>
<footnote confidence="0.948906">
3We also used a tool for mapping from WordNet 1.7 to
WordNet 1.6 (Daud´e et al., 2000) to map the SE2-EAW noun
data (originally distributed with 1.7 sense numbers) to 1.6 sense
numbers.
</footnote>
<page confidence="0.997584">
235
</page>
<bodyText confidence="0.999935">
they rely on parallel training data and are not appli-
cable on 9.6% of the test data for which there are
no training examples. Our method does not require
parallel training data.
Agirre and Martfnez (2004) show that sense dis-
tribution estimation is very important for both super-
vised and unsupervised WSD. They acquire tagged
examples on a large scale by querying Google with
monosemous synonyms of the word senses in ques-
tion. They show that the method of McCarthy et
al. (2004) can be used to produce a better sampling
technique than relying on the bias from web data
or randomly selecting the same number of exam-
ples for each sense. Our work similarly shows that
the automatic MFS is an unsupervised alternative to
SemCor but our work does not focus on sampling
but on an estimation of confidence in an automatic
MFS heuristic.
</bodyText>
<sectionHeader confidence="0.999717" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999987947368421">
We demonstrate that our variation of the McCarthy
et al. (2004) method for finding a MFS heuristic can
be used for estimating the entropy of a sense dis-
tribution which can be exploited to boost precision.
Words which are estimated as having lower entropy
in general get higher precision. This suggests that
automatic estimation of entropy is a good criterion
for getting higher precision. This is in agreement
with Kilgarriff and Rosenzweig (2000) who demon-
strate that entropy is a good measure of the difficulty
of WSD tasks, though their measure of entropy was
taken from the gold-standard distribution itself.
As future work, we want to compare this approach
of estimating entropy with other methods for es-
timating sense distributions which do not require
hand-labelled data or parallel texts. Currently, we
disregard local context. We wish to couple the con-
fidence in the MFS with contextual evidence and in-
vestigate application on coarse-grained datasets.
</bodyText>
<sectionHeader confidence="0.997385" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<copyright confidence="0.326056333333333">
This work was funded by the China Scholarship Council,
the National Grant Fundamental Research 973 Program
of China: Grant No. 2004CB318102, the UK EPSRC
project EP/C537262 ‘Ranking Word Senses for Disam-
biguation’, and a UK Royal Society Dorothy Hodgkin
Fellowship to the second author.
</copyright>
<sectionHeader confidence="0.940539" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999243306122449">
E. Agirre and D. Martfnez. 2004. Unsupervised wsd
based on automatically retrieved examples: The im-
portance of bias. In Proceedings of EMNLP-2004,
pages 25–32, Barcelona, Spain.
E. Briscoe and J. Carroll. 2002. Robust accurate sta-
tistical annotation of general text. In Proceedings of
LREC-2002, pages 1499–1504, Las Palmas, Canary
Islands, Spain.
Y.S. Chan and H.T. Ng. 2005. Word sense disambigua-
tion with distribution estimation. In Proceedings of
IJCAI 2005, pages 1010–1015, Edinburgh, Scotland.
J. Daud´e, L. Padr´o, and G. Rigau. 2000. Mapping word-
nets using structural information. In Proceedings of
the 38th Annual Meeting of the Association for Com-
putational Linguistics, Hong Kong.
J. Jiang and D. Conrath. 1997. Semantic similarity based
on corpus statistics and lexical taxonomy. In Interna-
tional Conference on Research in Computational Lin-
guistics, Taiwan.
A. Kilgarriff and J. Rosenzweig. 2000. Framework and
results for english SENSEVAL. Computers and the
Humanities. Senseval Special Issue, 34(1–2):15–48.
M. Lapata and F. Keller. 2007. An information retrieval
approach to sense ranking. In Proceedings of NAACL-
2007, pages 348–355, Rochester.
G. Leech. 1992. 100 million words of English:
the British National Corpus. Language Research,
28(1):1–13.
D. Lin. 1998. Automatic retrieval and clustering of sim-
ilar words. In Proceedings of COLING-ACL 98, Mon-
treal, Canada.
D. McCarthy, R. Koeling, J. Weeds, and J. Carroll. 2004.
Finding predominant senses in untagged text. In Pro-
ceedings of ACL-2004, pages 280–287, Barcelona,
Spain.
S. Mohammad and G. Hirst. 2006. Determining word
sense dominance using a thesauru s. In Proceedings of
EACL-2006, pages 121–128, Trento, Italy.
M. Palmer, C. Fellbaum, S. Cotton, L. Delfs, and
H. Trang Dang. 2001. English tasks: All-words and
verb lexical sample. In Proceedings of the SENSEVAL-
2 workshop, pages 21–24.
S. Patwardhan and T. Pedersen. 2003. The
wordnet::similarity package. http://wn-
similarity.sourceforge.net/.
D. Yarowsky and R. Florian. 2002. Evaluating sense
disambiguation performance across diverse parame-
ter spaces. Natural Language Engineering, 8(4):293–
310.
</reference>
<page confidence="0.998537">
236
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.738674">
<title confidence="0.999189">Estimating and Exploiting the Entropy of Sense Distributions</title>
<author confidence="0.766348">Jin Diana McCarthy</author>
<author confidence="0.766348">Rob Koeling Carroll</author>
<affiliation confidence="0.996457">Institute of Computational Linguistics University of Sussex Peking University Falmer, East Sussex</affiliation>
<address confidence="0.986706">Beijing China BN1 9QJ, UK</address>
<abstract confidence="0.998921466666667">Word sense distributions are usually skewed. Predicting the extent of the skew can help a sense disambiguation system determine whether to consider evidence from the local context or apply the simple yet effective heuristic of using the first (most frequent) sense. In this paper, we propose a method to estimate the entropy of a sense distribution to boost the precision of a first sense heuristic by restricting its application to words with lower entropy. We show on two standard datasets that automatic prediction of entropy can increase the performance of an automatic first sense heuristic.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>D Martfnez</author>
</authors>
<title>Unsupervised wsd based on automatically retrieved examples: The importance of bias.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP-2004,</booktitle>
<pages>25--32</pages>
<location>Barcelona,</location>
<contexts>
<context position="10834" citStr="Agirre and Martfnez (2004)" startWordPosition="1853" endWordPosition="1856">strate that sense distribution estimation improves a supervised WSD classifier. They use three sense distribution methods, including that of McCarthy et al. (2004). While the other two methods outperform the McCarthy et al. method, 3We also used a tool for mapping from WordNet 1.7 to WordNet 1.6 (Daud´e et al., 2000) to map the SE2-EAW noun data (originally distributed with 1.7 sense numbers) to 1.6 sense numbers. 235 they rely on parallel training data and are not applicable on 9.6% of the test data for which there are no training examples. Our method does not require parallel training data. Agirre and Martfnez (2004) show that sense distribution estimation is very important for both supervised and unsupervised WSD. They acquire tagged examples on a large scale by querying Google with monosemous synonyms of the word senses in question. They show that the method of McCarthy et al. (2004) can be used to produce a better sampling technique than relying on the bias from web data or randomly selecting the same number of examples for each sense. Our work similarly shows that the automatic MFS is an unsupervised alternative to SemCor but our work does not focus on sampling but on an estimation of confidence in an</context>
</contexts>
<marker>Agirre, Martfnez, 2004</marker>
<rawString>E. Agirre and D. Martfnez. 2004. Unsupervised wsd based on automatically retrieved examples: The importance of bias. In Proceedings of EMNLP-2004, pages 25–32, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Briscoe</author>
<author>J Carroll</author>
</authors>
<title>Robust accurate statistical annotation of general text.</title>
<date>2002</date>
<booktitle>In Proceedings of LREC-2002,</booktitle>
<pages>1499--1504</pages>
<location>Las Palmas, Canary Islands,</location>
<contexts>
<context position="3139" citStr="Briscoe and Carroll, 2002" startWordPosition="510" endWordPosition="513">. (2004) provides a prevalence ranking score to produce a MFS heuristic. We make a slight modification to McCarthy et al.’s prevalence score and use it to estimate the probability distribution over the senses of a word. We use the same resources as McCarthy et al. (2004): a distributional similarity thesaurus and a WordNet semantic similarity measure. The thesaurus was produced using the metric described by Lin (1998) with input from the grammatical relation data extracted using the 90 million words of written English from the British National Corpus (BNC) (Leech, 1992) using the RASP parser (Briscoe and Carroll, 2002). The thesaurus consists of entries for each word (w) with the top 50 “nearest neighbours” to w, where the neighbours are words ranked by the distributional similarity that 233 Proceedings of NAACL HLT 2009: Short Papers, pages 233–236, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics they share with w. The WordNet similarity score is obtained with the jcn measure (Jiang and Conrath, 1997) using the WordNet Similarity Package 0.05 (Patwardhan and Pedersen, 2003) and WordNet version 1.6. The jcn measure needs word frequency information, which we obtained from the B</context>
</contexts>
<marker>Briscoe, Carroll, 2002</marker>
<rawString>E. Briscoe and J. Carroll. 2002. Robust accurate statistical annotation of general text. In Proceedings of LREC-2002, pages 1499–1504, Las Palmas, Canary Islands, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y S Chan</author>
<author>H T Ng</author>
</authors>
<title>Word sense disambiguation with distribution estimation.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCAI 2005,</booktitle>
<pages>1010--1015</pages>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="10164" citStr="Chan and Ng (2005)" startWordPosition="1742" endWordPosition="1745">nificantly for words with low estimated entropy, and the gains over the random baseline are higher compared to the gains including all words. 4 Related Work There is promising related work on determining the predominant sense for a MFS heuristic (Lapata and Keller, 2007; Mohammad and Hirst, 2006) but our work is the first to use the ranking score to estimate entropy and apply it to determine the confidence in the MFS heuristic. It is likely that these methods would also have increased precision if the ranking scores were used to estimate entropy. We leave such investigations for further work. Chan and Ng (2005) estimate word sense distributions and demonstrate that sense distribution estimation improves a supervised WSD classifier. They use three sense distribution methods, including that of McCarthy et al. (2004). While the other two methods outperform the McCarthy et al. method, 3We also used a tool for mapping from WordNet 1.7 to WordNet 1.6 (Daud´e et al., 2000) to map the SE2-EAW noun data (originally distributed with 1.7 sense numbers) to 1.6 sense numbers. 235 they rely on parallel training data and are not applicable on 9.6% of the test data for which there are no training examples. Our meth</context>
</contexts>
<marker>Chan, Ng, 2005</marker>
<rawString>Y.S. Chan and H.T. Ng. 2005. Word sense disambiguation with distribution estimation. In Proceedings of IJCAI 2005, pages 1010–1015, Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Daud´e</author>
<author>L Padr´o</author>
<author>G Rigau</author>
</authors>
<title>Mapping wordnets using structural information.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Hong Kong.</location>
<marker>Daud´e, Padr´o, Rigau, 2000</marker>
<rawString>J. Daud´e, L. Padr´o, and G. Rigau. 2000. Mapping wordnets using structural information. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jiang</author>
<author>D Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<booktitle>In International Conference on Research in Computational Linguistics,</booktitle>
<contexts>
<context position="3561" citStr="Jiang and Conrath, 1997" startWordPosition="575" endWordPosition="579">th input from the grammatical relation data extracted using the 90 million words of written English from the British National Corpus (BNC) (Leech, 1992) using the RASP parser (Briscoe and Carroll, 2002). The thesaurus consists of entries for each word (w) with the top 50 “nearest neighbours” to w, where the neighbours are words ranked by the distributional similarity that 233 Proceedings of NAACL HLT 2009: Short Papers, pages 233–236, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics they share with w. The WordNet similarity score is obtained with the jcn measure (Jiang and Conrath, 1997) using the WordNet Similarity Package 0.05 (Patwardhan and Pedersen, 2003) and WordNet version 1.6. The jcn measure needs word frequency information, which we obtained from the BNC. 2.1 Estimates of Predominance, Probability and Entropy Following McCarthy et al. (2004), we calculate prevalence of each sense of the word (w) using a weighted sum of the distributional similarity scores of the top 50 neighbours of w. The sense of w that has the highest value is the automatically detected MFS (predominant sense). The weights are determined by the WordNet similarity between the sense in question and</context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>J. Jiang and D. Conrath. 1997. Semantic similarity based on corpus statistics and lexical taxonomy. In International Conference on Research in Computational Linguistics, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
<author>J Rosenzweig</author>
</authors>
<title>Framework and results for english SENSEVAL. Computers and the Humanities. Senseval Special Issue,</title>
<date>2000</date>
<pages>34--1</pages>
<contexts>
<context position="11921" citStr="Kilgarriff and Rosenzweig (2000)" startWordPosition="2037" endWordPosition="2040"> that the automatic MFS is an unsupervised alternative to SemCor but our work does not focus on sampling but on an estimation of confidence in an automatic MFS heuristic. 5 Conclusions We demonstrate that our variation of the McCarthy et al. (2004) method for finding a MFS heuristic can be used for estimating the entropy of a sense distribution which can be exploited to boost precision. Words which are estimated as having lower entropy in general get higher precision. This suggests that automatic estimation of entropy is a good criterion for getting higher precision. This is in agreement with Kilgarriff and Rosenzweig (2000) who demonstrate that entropy is a good measure of the difficulty of WSD tasks, though their measure of entropy was taken from the gold-standard distribution itself. As future work, we want to compare this approach of estimating entropy with other methods for estimating sense distributions which do not require hand-labelled data or parallel texts. Currently, we disregard local context. We wish to couple the confidence in the MFS with contextual evidence and investigate application on coarse-grained datasets. Acknowledgements This work was funded by the China Scholarship Council, the National G</context>
</contexts>
<marker>Kilgarriff, Rosenzweig, 2000</marker>
<rawString>A. Kilgarriff and J. Rosenzweig. 2000. Framework and results for english SENSEVAL. Computers and the Humanities. Senseval Special Issue, 34(1–2):15–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lapata</author>
<author>F Keller</author>
</authors>
<title>An information retrieval approach to sense ranking.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL2007,</booktitle>
<pages>348--355</pages>
<location>Rochester.</location>
<contexts>
<context position="1908" citStr="Lapata and Keller, 2007" startWordPosition="300" endWordPosition="303">y powerful since sense distributions are usually skewed. The heuristic becomes particularly hard to beat for words with highly skewed sense distributions (Yarowsky and Florian, 2002). Although the MFS can be estimated from tagged corpora, there are always cases where there is insufficient data, or where the data is inappropriate, for example because 1It is also referred to as the first sense heuristic in the WSD literature and in this paper. it comes from a very different domain. This has motivated some recent work attempting to estimate the distributions automatically (McCarthy et al., 2004; Lapata and Keller, 2007). This paper examines the case for determining the skew of a word sense distribution by estimating entropy and then using this to increase the precision of an unsupervised first sense heuristic by restricting application to those words where the system can automatically detect that it has the most chance. We use a method based on that proposed by McCarthy et al. (2004) as this approach does not require hand-labelled corpora. The method could easily be adapted to other methods for predicing predominant sense. 2 Method Given a listing of senses from an inventory, the method proposed by McCarthy </context>
<context position="9816" citStr="Lapata and Keller, 2007" startWordPosition="1682" endWordPosition="1685">ending on entropy. We use the same resources as for the SemCor experiment. 3 Table 3 gives the results. The most frequent sense (MFS) from SE2-EAW itself provides the upper-bound (UB). We also compare performance with the Semcor MFS (SC). Performance is close to the Semcor MFS while not relying on any manual tagging. As before, precision increases significantly for words with low estimated entropy, and the gains over the random baseline are higher compared to the gains including all words. 4 Related Work There is promising related work on determining the predominant sense for a MFS heuristic (Lapata and Keller, 2007; Mohammad and Hirst, 2006) but our work is the first to use the ranking score to estimate entropy and apply it to determine the confidence in the MFS heuristic. It is likely that these methods would also have increased precision if the ranking scores were used to estimate entropy. We leave such investigations for further work. Chan and Ng (2005) estimate word sense distributions and demonstrate that sense distribution estimation improves a supervised WSD classifier. They use three sense distribution methods, including that of McCarthy et al. (2004). While the other two methods outperform the </context>
</contexts>
<marker>Lapata, Keller, 2007</marker>
<rawString>M. Lapata and F. Keller. 2007. An information retrieval approach to sense ranking. In Proceedings of NAACL2007, pages 348–355, Rochester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Leech</author>
</authors>
<title>100 million words of English:</title>
<date>1992</date>
<journal>the British National Corpus. Language Research,</journal>
<volume>28</volume>
<issue>1</issue>
<contexts>
<context position="3089" citStr="Leech, 1992" startWordPosition="504" endWordPosition="505">he method proposed by McCarthy et al. (2004) provides a prevalence ranking score to produce a MFS heuristic. We make a slight modification to McCarthy et al.’s prevalence score and use it to estimate the probability distribution over the senses of a word. We use the same resources as McCarthy et al. (2004): a distributional similarity thesaurus and a WordNet semantic similarity measure. The thesaurus was produced using the metric described by Lin (1998) with input from the grammatical relation data extracted using the 90 million words of written English from the British National Corpus (BNC) (Leech, 1992) using the RASP parser (Briscoe and Carroll, 2002). The thesaurus consists of entries for each word (w) with the top 50 “nearest neighbours” to w, where the neighbours are words ranked by the distributional similarity that 233 Proceedings of NAACL HLT 2009: Short Papers, pages 233–236, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics they share with w. The WordNet similarity score is obtained with the jcn measure (Jiang and Conrath, 1997) using the WordNet Similarity Package 0.05 (Patwardhan and Pedersen, 2003) and WordNet version 1.6. The jcn measure needs word f</context>
</contexts>
<marker>Leech, 1992</marker>
<rawString>G. Leech. 1992. 100 million words of English: the British National Corpus. Language Research, 28(1):1–13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL 98,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="2934" citStr="Lin (1998)" startWordPosition="477" endWordPosition="478">led corpora. The method could easily be adapted to other methods for predicing predominant sense. 2 Method Given a listing of senses from an inventory, the method proposed by McCarthy et al. (2004) provides a prevalence ranking score to produce a MFS heuristic. We make a slight modification to McCarthy et al.’s prevalence score and use it to estimate the probability distribution over the senses of a word. We use the same resources as McCarthy et al. (2004): a distributional similarity thesaurus and a WordNet semantic similarity measure. The thesaurus was produced using the metric described by Lin (1998) with input from the grammatical relation data extracted using the 90 million words of written English from the British National Corpus (BNC) (Leech, 1992) using the RASP parser (Briscoe and Carroll, 2002). The thesaurus consists of entries for each word (w) with the top 50 “nearest neighbours” to w, where the neighbours are words ranked by the distributional similarity that 233 Proceedings of NAACL HLT 2009: Short Papers, pages 233–236, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics they share with w. The WordNet similarity score is obtained with the jcn measur</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>D. Lin. 1998. Automatic retrieval and clustering of similar words. In Proceedings of COLING-ACL 98, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McCarthy</author>
<author>R Koeling</author>
<author>J Weeds</author>
<author>J Carroll</author>
</authors>
<title>Finding predominant senses in untagged text.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL-2004,</booktitle>
<pages>280--287</pages>
<location>Barcelona,</location>
<contexts>
<context position="1882" citStr="McCarthy et al., 2004" startWordPosition="296" endWordPosition="299"> heuristic 1 and is very powerful since sense distributions are usually skewed. The heuristic becomes particularly hard to beat for words with highly skewed sense distributions (Yarowsky and Florian, 2002). Although the MFS can be estimated from tagged corpora, there are always cases where there is insufficient data, or where the data is inappropriate, for example because 1It is also referred to as the first sense heuristic in the WSD literature and in this paper. it comes from a very different domain. This has motivated some recent work attempting to estimate the distributions automatically (McCarthy et al., 2004; Lapata and Keller, 2007). This paper examines the case for determining the skew of a word sense distribution by estimating entropy and then using this to increase the precision of an unsupervised first sense heuristic by restricting application to those words where the system can automatically detect that it has the most chance. We use a method based on that proposed by McCarthy et al. (2004) as this approach does not require hand-labelled corpora. The method could easily be adapted to other methods for predicing predominant sense. 2 Method Given a listing of senses from an inventory, the me</context>
<context position="3830" citStr="McCarthy et al. (2004)" startWordPosition="615" endWordPosition="618"> “nearest neighbours” to w, where the neighbours are words ranked by the distributional similarity that 233 Proceedings of NAACL HLT 2009: Short Papers, pages 233–236, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics they share with w. The WordNet similarity score is obtained with the jcn measure (Jiang and Conrath, 1997) using the WordNet Similarity Package 0.05 (Patwardhan and Pedersen, 2003) and WordNet version 1.6. The jcn measure needs word frequency information, which we obtained from the BNC. 2.1 Estimates of Predominance, Probability and Entropy Following McCarthy et al. (2004), we calculate prevalence of each sense of the word (w) using a weighted sum of the distributional similarity scores of the top 50 neighbours of w. The sense of w that has the highest value is the automatically detected MFS (predominant sense). The weights are determined by the WordNet similarity between the sense in question and the neighbour. We make a modification to the original method by multiplying the weight by the inverse rank of the neighbour from the list of 50 neighbours. This modification magnifies the contribution to each sense depending on the rank of the neighbour while still al</context>
<context position="6398" citStr="McCarthy et al., 2004" startWordPosition="1063" endWordPosition="1066">py is measured as: H(senses(w)) = −∑ p(wsi)log(p(wsi)) wsi∈senses(w) using our estimate ( ˆp) for the probability distribution p over the senses of w. 3 Experiments We conducted two experiments to evaluate the benefit of using our estimate of entropy to restrict application of the MFS heuristic. The two experiments are conducted on the polysemous nouns in SemCor and the nouns in the SENSEVAL-2 English all words task (we will refer to this as SE2-EAW). 3.1 SemCor For this experiment we used all the polysemous nouns in Semcor 1.6 (excluding multiwords and proper nouns). We depart slightly from (McCarthy et al., 2004) in including all polysemous nouns whereas they limited the experiment to those with a frequency in SemCor of 3 or more and where there is one sense with a higher frequency than the others. Table 1 shows the precision of finding the predominant sense using equation 1 with respect to different entropy thresholds. At each threshold, the MFS in Semcor provides the upper-bound (UB). The random baseline (RBL) is computed by selecting one of the senses of the target word randomly as the predominant sense. As we hypothesized, precision is higher when the entropy of the sense distribution is lower, wh</context>
<context position="10371" citStr="McCarthy et al. (2004)" startWordPosition="1772" endWordPosition="1775"> the predominant sense for a MFS heuristic (Lapata and Keller, 2007; Mohammad and Hirst, 2006) but our work is the first to use the ranking score to estimate entropy and apply it to determine the confidence in the MFS heuristic. It is likely that these methods would also have increased precision if the ranking scores were used to estimate entropy. We leave such investigations for further work. Chan and Ng (2005) estimate word sense distributions and demonstrate that sense distribution estimation improves a supervised WSD classifier. They use three sense distribution methods, including that of McCarthy et al. (2004). While the other two methods outperform the McCarthy et al. method, 3We also used a tool for mapping from WordNet 1.7 to WordNet 1.6 (Daud´e et al., 2000) to map the SE2-EAW noun data (originally distributed with 1.7 sense numbers) to 1.6 sense numbers. 235 they rely on parallel training data and are not applicable on 9.6% of the test data for which there are no training examples. Our method does not require parallel training data. Agirre and Martfnez (2004) show that sense distribution estimation is very important for both supervised and unsupervised WSD. They acquire tagged examples on a la</context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2004</marker>
<rawString>D. McCarthy, R. Koeling, J. Weeds, and J. Carroll. 2004. Finding predominant senses in untagged text. In Proceedings of ACL-2004, pages 280–287, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Mohammad</author>
<author>G Hirst</author>
</authors>
<title>Determining word sense dominance using a thesauru s.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL-2006,</booktitle>
<pages>121--128</pages>
<location>Trento, Italy.</location>
<contexts>
<context position="9843" citStr="Mohammad and Hirst, 2006" startWordPosition="1686" endWordPosition="1689"> the same resources as for the SemCor experiment. 3 Table 3 gives the results. The most frequent sense (MFS) from SE2-EAW itself provides the upper-bound (UB). We also compare performance with the Semcor MFS (SC). Performance is close to the Semcor MFS while not relying on any manual tagging. As before, precision increases significantly for words with low estimated entropy, and the gains over the random baseline are higher compared to the gains including all words. 4 Related Work There is promising related work on determining the predominant sense for a MFS heuristic (Lapata and Keller, 2007; Mohammad and Hirst, 2006) but our work is the first to use the ranking score to estimate entropy and apply it to determine the confidence in the MFS heuristic. It is likely that these methods would also have increased precision if the ranking scores were used to estimate entropy. We leave such investigations for further work. Chan and Ng (2005) estimate word sense distributions and demonstrate that sense distribution estimation improves a supervised WSD classifier. They use three sense distribution methods, including that of McCarthy et al. (2004). While the other two methods outperform the McCarthy et al. method, 3We</context>
</contexts>
<marker>Mohammad, Hirst, 2006</marker>
<rawString>S. Mohammad and G. Hirst. 2006. Determining word sense dominance using a thesauru s. In Proceedings of EACL-2006, pages 121–128, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>C Fellbaum</author>
<author>S Cotton</author>
<author>L Delfs</author>
<author>H Trang Dang</author>
</authors>
<title>English tasks: All-words and verb lexical sample.</title>
<date>2001</date>
<booktitle>In Proceedings of the SENSEVAL2 workshop,</booktitle>
<pages>21--24</pages>
<contexts>
<context position="8751" citStr="Palmer et al., 2001" startWordPosition="1483" endWordPosition="1486">sion is not all due to frequency or polysemy. This is important, since both frequency and polysemy level (assuming a predefined sense inventory) could be obtained without the need for automatic estimation. As we can see, while precision is higher for lower polysemy, the automatic estimate of entropy can provide a greater increase in precision than polysemy, and frequency does not seem to be strongly correlated with precision. 3.2 SENSEVAL-2 English All Words Dataset The SE2-EAW task provides a hand-tagged test suite of 5,000 words of running text from three articles from the Penn Treebank II (Palmer et al., 2001). Again, we examine whether precision of the MFS H eq 1 precision UB # (&lt;) RBL SC tokens 0.5 - - - - 0 0.9 1 50.0 1 1 7 0.95 94.7 50.0 94.7 1 19 1 69.6 50.0 81.3 94.6 112 1.5 68.0 49.0 81.3 93.8 128 2 69.6 34.7 68.2 87.7 421 2.5 65.0 33.0 65.0 86.5 488 3.0 56.6 27.5 60.8 80.1 687 4.0 52.6 25.6 58.8 79.2 766 5.0 (all) 51.5 25.6 58.5 79.3 769 Table 3: First sense heuristic on SE2-EAW heuristic can be increased by restricting application depending on entropy. We use the same resources as for the SemCor experiment. 3 Table 3 gives the results. The most frequent sense (MFS) from SE2-EAW itself prov</context>
</contexts>
<marker>Palmer, Fellbaum, Cotton, Delfs, Dang, 2001</marker>
<rawString>M. Palmer, C. Fellbaum, S. Cotton, L. Delfs, and H. Trang Dang. 2001. English tasks: All-words and verb lexical sample. In Proceedings of the SENSEVAL2 workshop, pages 21–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Patwardhan</author>
<author>T Pedersen</author>
</authors>
<date>2003</date>
<note>The wordnet::similarity package. http://wnsimilarity.sourceforge.net/.</note>
<contexts>
<context position="3635" citStr="Patwardhan and Pedersen, 2003" startWordPosition="586" endWordPosition="589">illion words of written English from the British National Corpus (BNC) (Leech, 1992) using the RASP parser (Briscoe and Carroll, 2002). The thesaurus consists of entries for each word (w) with the top 50 “nearest neighbours” to w, where the neighbours are words ranked by the distributional similarity that 233 Proceedings of NAACL HLT 2009: Short Papers, pages 233–236, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics they share with w. The WordNet similarity score is obtained with the jcn measure (Jiang and Conrath, 1997) using the WordNet Similarity Package 0.05 (Patwardhan and Pedersen, 2003) and WordNet version 1.6. The jcn measure needs word frequency information, which we obtained from the BNC. 2.1 Estimates of Predominance, Probability and Entropy Following McCarthy et al. (2004), we calculate prevalence of each sense of the word (w) using a weighted sum of the distributional similarity scores of the top 50 neighbours of w. The sense of w that has the highest value is the automatically detected MFS (predominant sense). The weights are determined by the WordNet similarity between the sense in question and the neighbour. We make a modification to the original method by multiplyi</context>
</contexts>
<marker>Patwardhan, Pedersen, 2003</marker>
<rawString>S. Patwardhan and T. Pedersen. 2003. The wordnet::similarity package. http://wnsimilarity.sourceforge.net/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>R Florian</author>
</authors>
<title>Evaluating sense disambiguation performance across diverse parameter spaces.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<volume>8</volume>
<issue>4</issue>
<pages>310</pages>
<contexts>
<context position="1466" citStr="Yarowsky and Florian, 2002" startWordPosition="227" endWordPosition="230">can increase the performance of an automatic first sense heuristic. 1 Introduction Word sense distributions are typically skewed and WSD systems do best when they exploit this tendency. This is usually done by estimating the most frequent sense (MFS) for each word from a training corpus and using that sense as a back-off strategy for a word when there is no convincing evidence from the context. This is known as the MFS heuristic 1 and is very powerful since sense distributions are usually skewed. The heuristic becomes particularly hard to beat for words with highly skewed sense distributions (Yarowsky and Florian, 2002). Although the MFS can be estimated from tagged corpora, there are always cases where there is insufficient data, or where the data is inappropriate, for example because 1It is also referred to as the first sense heuristic in the WSD literature and in this paper. it comes from a very different domain. This has motivated some recent work attempting to estimate the distributions automatically (McCarthy et al., 2004; Lapata and Keller, 2007). This paper examines the case for determining the skew of a word sense distribution by estimating entropy and then using this to increase the precision of an</context>
</contexts>
<marker>Yarowsky, Florian, 2002</marker>
<rawString>D. Yarowsky and R. Florian. 2002. Evaluating sense disambiguation performance across diverse parameter spaces. Natural Language Engineering, 8(4):293– 310.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>