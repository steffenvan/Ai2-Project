<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000545">
<title confidence="0.985624">
A Supervised Learning Approach to Automatic Synonym Identification
based on Distributional Features
</title>
<author confidence="0.991749">
Masato Hagiwara
</author>
<affiliation confidence="0.9976275">
Graduate School of Information Science
Nagoya University
</affiliation>
<address confidence="0.656476">
Furo-cho, Chikusa-ku, Nagoya 464-8603, JAPAN
</address>
<email confidence="0.997279">
hagiwara@kl.i.is.nagoya-u.ac.jp
</email>
<sectionHeader confidence="0.998584" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999309888888889">
Distributional similarity has been widely used
to capture the semantic relatedness of words in
many NLP tasks. However, various parame-
ters such as similarity measures must be hand-
tuned to make it work effectively. Instead, we
propose a novel approach to synonym iden-
tification based on supervised learning and
distributional features, which correspond to
the commonality of individual context types
shared by word pairs. Considering the inte-
gration with pattern-based features, we have
built and compared five synonym classifiers.
The evaluation experiment has shown a dra-
matic performance increase of over 120% on
the F-1 measure basis, compared to the con-
ventional similarity-based classification. On
the other hand, the pattern-based features have
appeared almost redundant.
</bodyText>
<sectionHeader confidence="0.999476" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999744787234042">
Semantic similarity of words is one of the most im-
portant lexical knowledge for NLP tasks including
word sense disambiguation and automatic thesaurus
construction. To measure the semantic relatedness
of words, a concept called distributional similarity
has been widely used. Distributional similarity rep-
resents the relatedness of two words by the common-
ality of contexts the words share, based on the distri-
butional hypothesis (Harris, 1985), which states that
semantically similar words share similar contexts.
A number of researches which utilized distri-
butional similarity have been conducted, including
(Hindle, 1990; Lin, 1998; Geffet and Dagan, 2004)
and many others. Although they have been success-
ful in acquiring related words, various parameters
such as similarity measures and weighting are in-
volved. As Weeds et al. (2004) pointed out, “it is
not at all obvious that one universally best measure
exists for all application,” thus they must be tuned by
hand in an ad-hoc manner. The fact that no theoretic
basis is given is making the matter more difficult.
On the other hand, if we pay attention to lexical
knowledge acquisition in general, a variety of sys-
tems which utilized syntactic patterns are found in
the literature. In her landmark paper in the field,
Hearst (1992) utilized syntactic patterns such as
“such X as Y” and “Y and other X,” and extracted
hypernym/hyponym relation of X and Y. Roark and
Charniak (1998) applied this idea to extraction of
words which belong to the same categories, utiliz-
ing syntactic relations such as conjunctions and ap-
positives. What is worth attention here is that super-
vised machine learning is easily incorporated with
syntactic patterns. For example, Snow et al. (2004)
further extended Hearst’s idea and built hypernym
classifiers based on machine learning and syntactic
pattern-based features, with a considerable success.
These two independent approaches, distributional
similarity and syntactic patterns, were finally inte-
grated by Mirkin et al. (2006). Although they re-
ported that their system successfully improved the
performance, it did not achieve a complete integra-
tion and was still relying on an independent mod-
ule to compute the similarity. This configuration in-
herits a large portion of drawbacks of the similarity-
based approach mentioned above. To achieve a full
integration of both approaches, we suppose that re-
</bodyText>
<page confidence="0.806408">
1
</page>
<bodyText confidence="0.980804896551724">
Proceedings of the ACL-08: HLT Student Research Workshop (Companion Volume), pages 1–6,
Columbus, June 2008. c�2008 Association for Computational Linguistics
formalization of similarity-based approach would
be essential, as pattern-based approach is enhanced
with the supervised machine learning.
In this paper, we propose a novel approach to
automatic synonym identification based on super-
vised learning technique. Firstly, we re-formalize
synonym acquisition as a classification problem:
one which classifies word pairs into synonym/non-
synonym classes, without depending on a single
value of distributional similarity. Instead, classi-
fication is done using a set of distributional fea-
tures, which correspond to the degree of common-
ality of individual context types shared by word
pairs. This formalization also enables to incorporate
pattern-based features, and we finally build five clas-
sifiers based on distributional and/or pattern-based
features. In the experiment, their performances are
compared in terms of synonym acquisition precision
and recall, and the differences of actually acquired
synonyms are to be clarified.
The rest of this paper is organized as follows: in
Sections 2 and 3, distributional and pattern-based
features are defined, along with the extraction meth-
ods. Using the features, in Section 4 we build five
types of synonym classifiers, and compare their per-
formances in Section 5. Section 6 concludes this
paper, mentioning the future direction of this study.
</bodyText>
<sectionHeader confidence="0.989948" genericHeader="method">
2 Distributional Features
</sectionHeader>
<bodyText confidence="0.999755333333333">
In this section, we firstly describe how we extract
contexts from corpora and then how distributional
features are constructed for word pairs.
</bodyText>
<subsectionHeader confidence="0.997046">
2.1 Context Extraction
</subsectionHeader>
<bodyText confidence="0.999386454545454">
We adopted dependency structure as the context of
words since it is the most widely used and well-
performing contextual information in the past stud-
ies (Ruge, 1997; Lin, 1998). In this paper the sophis-
ticated parser RASP Toolkit 2 (Briscoe et al., 2006)
was utilized to extract this kind of word relations.
We use the following example for illustration pur-
poses: The library has a large collection of classic
books by such authors as Herrick and Shakespeare.
RASP outputs the extracted dependency structure as
n-ary relations as follows:
</bodyText>
<footnote confidence="0.298905">
(ncsubj have library _)
(dobj have collection)
(det collection a)
</footnote>
<equation confidence="0.885982375">
(ncmod _ collection large)
(iobj collection of)
(dobj of book)
(ncmod _ book by)
(dobj by author)
(det author such)
(ncmod _ author as)
... ,
</equation>
<bodyText confidence="0.981274428571428">
whose graphical representation is shown in Figure 1.
While the RASP outputs are n-ary relations in
general, what we need here is co-occurrences of
words and contexts, so we extract the set of co-
occurrences of stemmed words and contexts by tak-
ing out the target word from the relation and replac-
ing the slot by an asterisk “*”:
</bodyText>
<equation confidence="0.967027833333333">
library - (ncsubj have * _)
library - (det * The)
collection - (dobj have *)
collection - (det * a)
collection - (ncmod _ * large)
collection - (iobj * of)
book - (dobj of *)
book - (ncmod _ * by)
book - (ncmod _ * classic)
author - (dobj by *)
author - (det * such)
...
</equation>
<bodyText confidence="0.9977172">
Summing all these up produces the raw co-
occurrence count N(w, c) of the word w and the
context c. In the following, the set of context types
co-occurring with the word w is denoted as C(w),
i.e., C(w) = {c|N(w, c) &gt; 01.
</bodyText>
<subsectionHeader confidence="0.996545">
2.2 Feature Construction
</subsectionHeader>
<bodyText confidence="0.999977285714286">
Using the co-occurrences extracted above, we define
distributional features fD j (w1, w2) for the word pair
(w1, w2). The feature value fD j is determined so that
it represents the degree of commonality of the con-
text cj shared by the word pair. We adopted point-
wise total correlation, one of the generalizations of
pointwise mutual information, as the feature value:
</bodyText>
<equation confidence="0.987476">
fDj (w1, w2) = log P (w1, w2, cj)
P(w1)P (w2)P (cj). (1)
</equation>
<bodyText confidence="0.999985">
The advantage of this feature construction is that,
given the independence assumption between the
words w1 and w2, the feature value is easily calcu-
lated as the simple sum of two corresponding point-
wise mutual information weights as:
</bodyText>
<equation confidence="0.579378">
fDj (w1, w2) = PMI(w1, cj) + PMI(w2, cj), (2)
</equation>
<page confidence="0.97836">
2
</page>
<figureCaption confidence="0.999732">
Figure 1: Dependency structure of the example sentence, along with conjunction shortcuts (dotted lines).
</figureCaption>
<figure confidence="0.997993176470588">
det
ncsubj
ncm.d
det
det
d.bj
i.bj
ncm.d
d.bj
ncm.d
d.bj
d.bj
ncm.d
The library has a large c.llecti.n .f classic b..ks by such auth.rs as Herrick and Shakespeare.
c.nj c.nj
(d.bj)
(d.bj)
</figure>
<bodyText confidence="0.990707">
where the value of PMI, which is also the weights
wgt(wi, cj) assigned for distributional similarity, is
calculated as:
</bodyText>
<equation confidence="0.996696">
P (wi, cj)
wgt(wi, cj) = PMI(wi, cj) = log P(wi)P (cj). (3)
</equation>
<bodyText confidence="0.999252545454545">
There are three things to note here: when
N(wi, cj) = 0 and PMI cannot be defined, then
we define wgt(wi, cj) = 0. Also, because it has
been shown (Curran and Moens, 2002) that negative
PMI values worsen the distributional similarity per-
formance, we bound PMI so that wgt(wi, cj) = 0
if PMI(wi, cj) &lt; 0. Finally, the feature value
fDj(w1, w2) is defined as shown in Equation (2) only
when the context cj co-occurs with both w1 and w2.
In other words, fD j (w1, w2) = 0 if PMI(w1, cj) =
0 and/or PMI(w2, cj) = 0.
</bodyText>
<sectionHeader confidence="0.999495" genericHeader="method">
3 Pattern-based Features
</sectionHeader>
<bodyText confidence="0.99995">
This section describes the other type of features, ex-
tracted from syntactic patterns in sentences.
</bodyText>
<subsectionHeader confidence="0.995507">
3.1 Syntactic Pattern Extraction
</subsectionHeader>
<bodyText confidence="0.999967655172414">
We define syntactic patterns based on dependency
structure of sentences. Following Snow et al.
(2004)’s definition, the syntactic pattern of words
w1, w2 is defined as the concatenation of the words
and relations which are on the dependency path from
w1 to w2, not including w1 and w2 themselves.
The syntactic pattern of word authors
and books in Figure 1 is, for example,
dobj:by:ncmod, while that of authors and Her-
rick is ncmod-of:as:dobj-of:and:conj-of.
Notice that, although not shown in the figure,
every relation has a reverse edge as its counterpart,
with the direction opposite and the postfix “-of”
attached to the label. This allows to follow the
relations in reverse, increasing the flexibility and
expressive power of patterns.
In the experiment, we limited the maximum
length of syntactic path to five, meaning that word
pairs having six or more relations in between were
disregarded. Also, we considered conjunction short-
cuts to capture the lexical relations more precisely,
following Snow et al. (2004). This modification cuts
short the conj edges when nouns are connected by
conjunctions such as and and or. After this shortcut,
the syntactic pattern between authors and Herrick is
ncmod-of:as:dobj-of, and that of Herrick and
Shakespeare is conj-and, which is a newly intro-
duced special symmetric relation, indicating that the
nouns are mutually conjunctional.
</bodyText>
<subsectionHeader confidence="0.995936">
3.2 Feature Construction
</subsectionHeader>
<bodyText confidence="0.999965333333333">
After the corpus is analyzed and patterns are ex-
tracted, the pattern based feature fPk (w1, w2), which
corresponds to the syntactic pattern Pk, is defined
as the conditional probability of observing Pk given
that the pair (w1, w2) is observed. This definition is
similar to (Mirkin et al., 2006) and is calculated as:
</bodyText>
<equation confidence="0.9974265">
fPk (w1, w2) = P(pk|w1, w2) = N(w1, w2, pk)
N(w1, w2) . (4)
</equation>
<sectionHeader confidence="0.996078" genericHeader="method">
4 Synonym Classifiers
</sectionHeader>
<bodyText confidence="0.9997967">
Now that we have all the features to consider, we
construct the following five classifiers. This section
gives the construction detail of the classifiers and
corresponding feature vectors.
Distributional Similarity (DSIM) DSIM classi-
fier is simple acquisition relying only on distribu-
tional similarity, not on supervised learning. Simi-
lar to conventional methods, distributional similar-
ity between words w1 and w2, sim(w1, w2), is cal-
culated for each word pair using Jaccard coefficient:
</bodyText>
<equation confidence="0.727052">
∑
cEC(w1)nC(w2) min(wg�rt(w1, c), wgt(w2, c))
∑cEC(w1)UC(w2) max(wgt(w1, c), wgt(w2, c)),
</equation>
<page confidence="0.95841">
3
</page>
<bodyText confidence="0.9989079">
considering the preliminary experimental result. A
threshold is set on the similarity and classification is
performed based on whether the similarity is above
or below of the given threshold. How to optimally
set this threshold is described later in Section 5.1.
Distributional Features (DFEAT) DFEAT clas-
sifier does not rely on the conventional distributional
similarity and instead uses the distributional features
described in Section 2. The feature vector v~ of a
word pair (w1, w2) is constructed as:
</bodyText>
<equation confidence="0.992109">
v~ = (fD , ..., f�M). (5)
</equation>
<bodyText confidence="0.97957275">
Pattern-based Features (PAT) This classifier
PAT uses only pattern-based features, essentially the
same as the classifier of Snow et al. (2004). The
feature vector is:
</bodyText>
<equation confidence="0.985041">
v~ = (f�1 , ..., f�K). (6)
</equation>
<bodyText confidence="0.9430315">
Distributional Similarity and Pattern-based Fea-
tures (DSIM-PAT) DSIM-PAT uses the distribu-
tional similarity of pairs as a feature, in addition
to pattern-based features. This classifier is essen-
tially the same as the integration method proposed
by Mirkin et al. (2006). Letting fS = sim(w1, w2),
the feature vector is:
v~= (fS, fi , ..., f�K). (7)
Distributional and Pattern-based Features
(DFEAT-PAT) The last classifier, DFEAT-PAT,
truly integrates both distributional and pattern-based
features. The feature vector is constructed by
replacing the fS component of DSIM-PAT with
distributional features fD , ..., fM as:
</bodyText>
<equation confidence="0.958963">
v~ = (fD , ..., fM, fP , ..., f�K). (8)
</equation>
<sectionHeader confidence="0.998932" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.9998405">
Finally, this section describes the experimental set-
ting and the comparison of synonym classifiers.
</bodyText>
<subsectionHeader confidence="0.965256">
5.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.891190333333333">
Corpus and Preprocessing As for the corpus,
New York Times section (1994) of English Giga-
word 1, consisting of approx. 46,000 documents,
</bodyText>
<footnote confidence="0.9313085">
1http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?
catalogId=LDC2003T05
</footnote>
<bodyText confidence="0.985113142857143">
922,000 sentences, and 30 million words, was an-
alyzed to obtain word-context co-occurrences.
This can yield 10,000 or more context types, thus
we applied feature selection and reduced the dimen-
sionality. Firstly, we simply applied frequency cut-
off to filter out any words and contexts with low
frequency. More specifically, any words w such
</bodyText>
<equation confidence="0.869585">
that ∑� N(w, c) &lt; θf and any contexts c such that
∑
</equation>
<bodyText confidence="0.990721864864865">
w N(w, c) &lt; θf, with θf = 5, were removed. DF
(document frequency) thresholding is then applied,
and context types with the lowest values of DF were
removed until 10% of the original contexts were left.
We verified through a preliminary experiment that
this feature selection keeps the performance loss at
minimum. As a result, this process left a total of
8,558 context types, or feature dimensionality.
The feature selection was also applied to pattern-
based features to avoid high sparseness — only syn-
tactic patterns which occurred more than or equal to
7 times were used. The number of syntactic pattern
types left after this process is 17,964.
Supervised Learning Training and test sets were
created as follows: firstly, the nouns listed in the
Longman Defining Vocabulary (LDV) 2 were cho-
sen as the target words of classification. Then, all
the LDV pairs which co-occur more than or equal
to 3 times with any of the syntactic patterns, i.e.,
{(w1, w2)jw1, w2 E LDV, ∑p N(w1, w2, p) &gt; 31
were classified into synonym/non-synonym classes
as mentioned in Section 5.2. All the positive-marked
pair, as well as randomly chosen 1 out of 5 negative-
marked pairs, were collected as the example set E.
This random selection is to avoid extreme bias to-
ward the negative examples. The example set E
ended up with 2,148 positive and 13,855 negative
examples, with their ratio being approx. 6.45.
The example set E was then divided into five par-
titions to conduct five-fold cross validation, of which
four partitions were used for learning and the one for
testing. SVM&amp;quot;-qht was adopted for machine learn-
ing, and RBF as the kernel. The parameters, i.e.,
the similarity threshold of DSIM classifier, gamma
parameter of RBF kernel, and the cost-factor j of
SVM, i.e., the ratio by which training errors on pos-
itive examples outweight errors on negative ones,
</bodyText>
<footnote confidence="0.9892685">
2http://www.cs.utexas.edu/users/kbarker/working notes/
ldoce-vocab.html
</footnote>
<page confidence="0.997955">
4
</page>
<tableCaption confidence="0.999761">
Table 1: Performance comparison of synonym classifiers
</tableCaption>
<table confidence="0.999776166666667">
Classifier Precision Recall F-1
DSIM 33.13% 49.71% 39.76%
DFEAT 95.25% 82.31% 88.30%
PAT 23.86% 45.17% 31.22%
DSIM-PAT 30.62% 51.34% 38.36%
DFEAT-PAT 95.37% 82.31% 88.36%
</table>
<bodyText confidence="0.9895655">
were optimized using one of the 5-fold cross valida-
tion train-test pair on the basis of F-1 measure. The
performance was evaluated for the other four train-
test pairs and the average values were recorded.
</bodyText>
<subsectionHeader confidence="0.992651">
5.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.999982636363636">
To test whether or not a given word pair (w1, w2)
is a synonym pair, three existing thesauri were con-
sulted: Roget’s Thesaurus (Roget, 1995), Collins
COBUILD Thesaurus (Collins, 2002), and WordNet
(Fellbaum, 1998). The union of synonyms obtained
when the head word is looked up as a noun is used
as the answer set, except for words marked as “id-
iom,” “informal,” “slang” and phrases comprised of
two or more words. The pair (w1, w2) is marked as
synonyms if and only if w2 is contained in the an-
swer set of w1, or w1 is contained in that of w2.
</bodyText>
<subsectionHeader confidence="0.998015">
5.3 Classifier Performance
</subsectionHeader>
<bodyText confidence="0.999988592592593">
The performances, i.e., precision, recall, and F-1
measure, of the five classifiers were evaluated and
shown in Table 1. First of all, we observed a drastic
improvement of DFEAT over DSIM — over 120%
increase of F-1 measure. When combined with
pattern-based features, DSIM-PAT showed a slight
recall increase compared to DSIM, partially recon-
firming the favorable integration result of (Mirkin et
al., 2006). However, the combination DFEAT-PAT
showed little change, meaning that the discrimina-
tive ability of DFEAT was so high that pattern-based
features were almost redundant. To note, the perfor-
mance of PAT was the lowest, reflecting the fact that
synonym pairs rarely occur in the same sentence,
making the identification using only syntactic pat-
tern clues even more difficult.
The reason of the drastic improvement is that, as
far as we speculate, the supervised learning may
have favorably worked to cause the same effect as
automatic feature selection technique. Features with
high discriminative power may have been automat-
ically promoted. In the distributional similarity set-
ting, in contrast, the contributions of context types
are uniformly fixed. In order to elucidate what is
happening in this situation, the investigations on ma-
chine learning settings, as well as algorithms other
than SVM should be conducted as the future work.
</bodyText>
<subsectionHeader confidence="0.998341">
5.4 Acquired Synonyms
</subsectionHeader>
<bodyText confidence="0.99999216">
In the second part of this experiment, we further in-
vestigated what kind of synonyms were actually ac-
quired by the classifiers. The targets are not LDV,
but all of 27,501 unique nouns appeared in the cor-
pus, because we cannot rule out the possibility that
the high performance seen in the previous exper-
iment was simply due to the rather limited target
word settings. The rest of the experimental setting
was almost the same as the previous one, except that
the construction of training set is rather artificial —
we used all of the 18,102 positive LDV pairs and
randomly chosen 20,000 negative LDV pairs.
Table 2 lists the acquired synonyms of video and
program. The results of DSIM and DFEAT are or-
dered by distributional similarity and the value of
decision function of SVM, respectively. Notice that
because neither word is included in LDV, all the
pairs of the query and the words listed in the table
are guaranteed to be excluded from the training set.
The result shows the superiority of DFEAT over
DSIM. The irrelevant words (marked by “*” by
human judgement) seen in the DSIM list are de-
moted and replaced with more relevant words in the
DFEAT list. We observed the same trend for lower
ranked words and other query words.
</bodyText>
<sectionHeader confidence="0.99826" genericHeader="conclusions">
6 Conclusion and Future Direction
</sectionHeader>
<bodyText confidence="0.999798363636364">
In this paper, we proposed a novel approach to au-
tomatic synonym identification based on supervised
machine learning and distributional features. For
this purpose, we re-formalized synonym acquisition
as a classification problem, and constructed the fea-
tures as the total correlation of pairs and contexts.
Since this formalization allows to integrate pattern-
based features in a seamless way, we built five clas-
sifiers based on distributional and/or pattern-based
features. The result was promising, achieving more
than 120% increase over conventional DSIM classi-
</bodyText>
<page confidence="0.995561">
5
</page>
<tableCaption confidence="0.98685">
Table 2: Acquired synonyms of video and program
</tableCaption>
<figure confidence="0.990460875">
For query word: video
DSIM DFEAT
computer computer
television television
3 movie multimedia
4 film communication
5 food* entertainment
6 multimedia advertisement
7 drug* food*
8 entertainment recording
9 music portrait
10 radio movie
For query word: program
Rank DSIM DFEAT
1 system project
2 plan system
3 project unit
4 service status
5 policy schedule
6 effort* organization*
7 bill* activity*
8 company* plan
9 operation scheme
10 organization* policy
</figure>
<bodyText confidence="0.993260238095238">
fier. Pattern-based features were partially effective
when combined with DSIM whereas with DFEAT
they were simply redundant.
The impact of this study is that it makes unneces-
sary to carefully choose similarity measures such as
Jaccard’s — instead, features can be directly input
to supervised learning right after their construction.
There are still a great deal of issues to address as the
current approach is only in its infancy. For example,
the formalization of distributional features requires
further investigation. Although we adopted total
correlation this time, there can be some other con-
struction methods which show higher performance.
Still, we believe that this is one of the best ac-
quisition performances achieved ever and will be an
important step to truly practical lexical knowledge
acquisition. Setting our future direction on the com-
pletely automatic construction of reliable thesaurus
or ontology, the approach proposed here is to be ap-
plied to and integrated with various kinds of lexical
knowledge acquisition methods in the future.
</bodyText>
<sectionHeader confidence="0.998645" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998099">
The author would like to thank Assoc. Prof. Katsu-
hiko Toyama and Assis. Prof. Yasuhiro Ogawa for
their kind supervision and advice.
</bodyText>
<sectionHeader confidence="0.998281" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999870914893617">
Ted Briscoe, John Carroll and Rebecca Watson. 2006.
The Second Release of the RASP System. Proc. of the
COLING/ACL 06 Interactive Presentation Sessions,
77–80.
Collins. 2002. Collins Cobuild Major New Edition CD-
ROM. HarperCollins Publishers.
James R. Curran and Marc Moens. 2002. Improve-
ments in automatic thesaurus extraction. In Workshop
on Unsupervised Lexical Acquisition. Proc. of ACL
SIGLEX, 231–238.
Christiane Fellbaum. 1998. WordNet: an electronic lexi-
cal database, MIT Press.
Maayan Geffet and Ido Dagan. 2004. Feature Vector
Quality and Distributional Similarity. Proc. of COL-
ING 04, 247–253.
Zellig Harris. 1985. Distributional Structure. Jerrold J.
Katz (ed.) The Philosophy ofLinguistics. Oxford Uni-
versity Press, 26–47.
Marti A. Hearst. 1992. Automatic Acquisition of Hy-
ponyms from Large Text Corpora. Proc. of COLING
92, 539–545.
Donald Hindle. 1990. Noun classification from
predicate-argument structures. Proc. ofACL 90, 268–
275.
Dekang Lin. 1998. Automatic retrieval and clustering of
similar words. Proc. of COLING/ACL 98, 786–774.
Shachar Mirkin, Ido Dagan, and Maayan Geffet. 2006.
Integrating pattern-based and distributional similarity
methods for lexical entailment acquisition. Proc. of
COLING/ACL 06, 579–586.
Brian Roark and Eugene Charniak. 1998. Noun
phrase cooccurrence statistics for semi-automatic lex-
icon construction. Proc. of COLING/ACL 98, 1110–
1116.
Roget. 1995. Roget’s II: The New Thesaurus, 3rd ed.
Houghton Mifflin.
Gerda Ruge. 1997. Automatic detection of thesaurus re-
lations for information retrieval applications. Founda-
tions of Computer Science: Potential - Theory - Cogni-
tion, LNCS, Volume 1337, 499–506, Springer Verlag.
Rion Snow, Daniel Jurafsly, and Andrew Y. Ng. 2004.
Learning syntactic patterns for automatic hypernym
discovery. Advances in Neural Information Process-
ing Systems (NIPS) 17.
Julie Weeds, David Weir and Diana McCarthy. 2004.
Characterising Measures of Lexical Distributional
Similarity. Proc. of COLING 04, 1015–1021.
</reference>
<figure confidence="0.901162">
Rank
1
2
</figure>
<page confidence="0.939266">
6
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.916403">
<title confidence="0.99908">A Supervised Learning Approach to Automatic Synonym Identification based on Distributional Features</title>
<author confidence="0.994139">Masato Hagiwara</author>
<affiliation confidence="0.9996345">Graduate School of Information Science Nagoya University</affiliation>
<address confidence="0.999524">Furo-cho, Chikusa-ku, Nagoya 464-8603, JAPAN</address>
<email confidence="0.966854">hagiwara@kl.i.is.nagoya-u.ac.jp</email>
<abstract confidence="0.996465526315789">Distributional similarity has been widely used to capture the semantic relatedness of words in many NLP tasks. However, various parameters such as similarity measures must be handtuned to make it work effectively. Instead, we propose a novel approach to synonym identification based on supervised learning and which correspond to the commonality of individual context types shared by word pairs. Considering the intewith we have built and compared five synonym classifiers. The evaluation experiment has shown a dramatic performance increase of over 120% on the F-1 measure basis, compared to the conventional similarity-based classification. On the other hand, the pattern-based features have appeared almost redundant.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Rebecca Watson</author>
</authors>
<date>2006</date>
<booktitle>The Second Release of the RASP System. Proc. of the COLING/ACL 06 Interactive Presentation Sessions,</booktitle>
<pages>77--80</pages>
<contexts>
<context position="5373" citStr="Briscoe et al., 2006" startWordPosition="804" endWordPosition="807">ection 4 we build five types of synonym classifiers, and compare their performances in Section 5. Section 6 concludes this paper, mentioning the future direction of this study. 2 Distributional Features In this section, we firstly describe how we extract contexts from corpora and then how distributional features are constructed for word pairs. 2.1 Context Extraction We adopted dependency structure as the context of words since it is the most widely used and wellperforming contextual information in the past studies (Ruge, 1997; Lin, 1998). In this paper the sophisticated parser RASP Toolkit 2 (Briscoe et al., 2006) was utilized to extract this kind of word relations. We use the following example for illustration purposes: The library has a large collection of classic books by such authors as Herrick and Shakespeare. RASP outputs the extracted dependency structure as n-ary relations as follows: (ncsubj have library _) (dobj have collection) (det collection a) (ncmod _ collection large) (iobj collection of) (dobj of book) (ncmod _ book by) (dobj by author) (det author such) (ncmod _ author as) ... , whose graphical representation is shown in Figure 1. While the RASP outputs are n-ary relations in general,</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Ted Briscoe, John Carroll and Rebecca Watson. 2006. The Second Release of the RASP System. Proc. of the COLING/ACL 06 Interactive Presentation Sessions, 77–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collins</author>
</authors>
<title>Collins Cobuild Major New Edition CDROM.</title>
<date>2002</date>
<publisher>HarperCollins Publishers.</publisher>
<contexts>
<context position="15624" citStr="Collins, 2002" startWordPosition="2499" endWordPosition="2500">rmance comparison of synonym classifiers Classifier Precision Recall F-1 DSIM 33.13% 49.71% 39.76% DFEAT 95.25% 82.31% 88.30% PAT 23.86% 45.17% 31.22% DSIM-PAT 30.62% 51.34% 38.36% DFEAT-PAT 95.37% 82.31% 88.36% were optimized using one of the 5-fold cross validation train-test pair on the basis of F-1 measure. The performance was evaluated for the other four traintest pairs and the average values were recorded. 5.2 Evaluation To test whether or not a given word pair (w1, w2) is a synonym pair, three existing thesauri were consulted: Roget’s Thesaurus (Roget, 1995), Collins COBUILD Thesaurus (Collins, 2002), and WordNet (Fellbaum, 1998). The union of synonyms obtained when the head word is looked up as a noun is used as the answer set, except for words marked as “idiom,” “informal,” “slang” and phrases comprised of two or more words. The pair (w1, w2) is marked as synonyms if and only if w2 is contained in the answer set of w1, or w1 is contained in that of w2. 5.3 Classifier Performance The performances, i.e., precision, recall, and F-1 measure, of the five classifiers were evaluated and shown in Table 1. First of all, we observed a drastic improvement of DFEAT over DSIM — over 120% increase of</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Collins. 2002. Collins Cobuild Major New Edition CDROM. HarperCollins Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Curran</author>
<author>Marc Moens</author>
</authors>
<title>Improvements in automatic thesaurus extraction.</title>
<date>2002</date>
<booktitle>In Workshop on Unsupervised Lexical Acquisition. Proc. of ACL SIGLEX,</booktitle>
<pages>231--238</pages>
<contexts>
<context position="8060" citStr="Curran and Moens, 2002" startWordPosition="1288" endWordPosition="1291">structure of the example sentence, along with conjunction shortcuts (dotted lines). det ncsubj ncm.d det det d.bj i.bj ncm.d d.bj ncm.d d.bj d.bj ncm.d The library has a large c.llecti.n .f classic b..ks by such auth.rs as Herrick and Shakespeare. c.nj c.nj (d.bj) (d.bj) where the value of PMI, which is also the weights wgt(wi, cj) assigned for distributional similarity, is calculated as: P (wi, cj) wgt(wi, cj) = PMI(wi, cj) = log P(wi)P (cj). (3) There are three things to note here: when N(wi, cj) = 0 and PMI cannot be defined, then we define wgt(wi, cj) = 0. Also, because it has been shown (Curran and Moens, 2002) that negative PMI values worsen the distributional similarity performance, we bound PMI so that wgt(wi, cj) = 0 if PMI(wi, cj) &lt; 0. Finally, the feature value fDj(w1, w2) is defined as shown in Equation (2) only when the context cj co-occurs with both w1 and w2. In other words, fD j (w1, w2) = 0 if PMI(w1, cj) = 0 and/or PMI(w2, cj) = 0. 3 Pattern-based Features This section describes the other type of features, extracted from syntactic patterns in sentences. 3.1 Syntactic Pattern Extraction We define syntactic patterns based on dependency structure of sentences. Following Snow et al. (2004)’</context>
</contexts>
<marker>Curran, Moens, 2002</marker>
<rawString>James R. Curran and Marc Moens. 2002. Improvements in automatic thesaurus extraction. In Workshop on Unsupervised Lexical Acquisition. Proc. of ACL SIGLEX, 231–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: an electronic lexical database,</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="15654" citStr="Fellbaum, 1998" startWordPosition="2503" endWordPosition="2504">classifiers Classifier Precision Recall F-1 DSIM 33.13% 49.71% 39.76% DFEAT 95.25% 82.31% 88.30% PAT 23.86% 45.17% 31.22% DSIM-PAT 30.62% 51.34% 38.36% DFEAT-PAT 95.37% 82.31% 88.36% were optimized using one of the 5-fold cross validation train-test pair on the basis of F-1 measure. The performance was evaluated for the other four traintest pairs and the average values were recorded. 5.2 Evaluation To test whether or not a given word pair (w1, w2) is a synonym pair, three existing thesauri were consulted: Roget’s Thesaurus (Roget, 1995), Collins COBUILD Thesaurus (Collins, 2002), and WordNet (Fellbaum, 1998). The union of synonyms obtained when the head word is looked up as a noun is used as the answer set, except for words marked as “idiom,” “informal,” “slang” and phrases comprised of two or more words. The pair (w1, w2) is marked as synonyms if and only if w2 is contained in the answer set of w1, or w1 is contained in that of w2. 5.3 Classifier Performance The performances, i.e., precision, recall, and F-1 measure, of the five classifiers were evaluated and shown in Table 1. First of all, we observed a drastic improvement of DFEAT over DSIM — over 120% increase of F-1 measure. When combined wi</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: an electronic lexical database, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maayan Geffet</author>
<author>Ido Dagan</author>
</authors>
<title>Feature Vector Quality and Distributional Similarity.</title>
<date>2004</date>
<booktitle>Proc. of COLING 04,</booktitle>
<pages>247--253</pages>
<contexts>
<context position="1709" citStr="Geffet and Dagan, 2004" startWordPosition="237" endWordPosition="240">e of the most important lexical knowledge for NLP tasks including word sense disambiguation and automatic thesaurus construction. To measure the semantic relatedness of words, a concept called distributional similarity has been widely used. Distributional similarity represents the relatedness of two words by the commonality of contexts the words share, based on the distributional hypothesis (Harris, 1985), which states that semantically similar words share similar contexts. A number of researches which utilized distributional similarity have been conducted, including (Hindle, 1990; Lin, 1998; Geffet and Dagan, 2004) and many others. Although they have been successful in acquiring related words, various parameters such as similarity measures and weighting are involved. As Weeds et al. (2004) pointed out, “it is not at all obvious that one universally best measure exists for all application,” thus they must be tuned by hand in an ad-hoc manner. The fact that no theoretic basis is given is making the matter more difficult. On the other hand, if we pay attention to lexical knowledge acquisition in general, a variety of systems which utilized syntactic patterns are found in the literature. In her landmark pap</context>
</contexts>
<marker>Geffet, Dagan, 2004</marker>
<rawString>Maayan Geffet and Ido Dagan. 2004. Feature Vector Quality and Distributional Similarity. Proc. of COLING 04, 247–253.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<title>The Philosophy ofLinguistics.</title>
<date>1985</date>
<pages>26--47</pages>
<editor>Distributional Structure. Jerrold J. Katz (ed.)</editor>
<publisher>Oxford University Press,</publisher>
<contexts>
<context position="1494" citStr="Harris, 1985" startWordPosition="209" endWordPosition="210"> measure basis, compared to the conventional similarity-based classification. On the other hand, the pattern-based features have appeared almost redundant. 1 Introduction Semantic similarity of words is one of the most important lexical knowledge for NLP tasks including word sense disambiguation and automatic thesaurus construction. To measure the semantic relatedness of words, a concept called distributional similarity has been widely used. Distributional similarity represents the relatedness of two words by the commonality of contexts the words share, based on the distributional hypothesis (Harris, 1985), which states that semantically similar words share similar contexts. A number of researches which utilized distributional similarity have been conducted, including (Hindle, 1990; Lin, 1998; Geffet and Dagan, 2004) and many others. Although they have been successful in acquiring related words, various parameters such as similarity measures and weighting are involved. As Weeds et al. (2004) pointed out, “it is not at all obvious that one universally best measure exists for all application,” thus they must be tuned by hand in an ad-hoc manner. The fact that no theoretic basis is given is making</context>
</contexts>
<marker>Harris, 1985</marker>
<rawString>Zellig Harris. 1985. Distributional Structure. Jerrold J. Katz (ed.) The Philosophy ofLinguistics. Oxford University Press, 26–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic Acquisition of Hyponyms from Large Text Corpora.</title>
<date>1992</date>
<booktitle>Proc. of COLING 92,</booktitle>
<pages>539--545</pages>
<contexts>
<context position="2339" citStr="Hearst (1992)" startWordPosition="347" endWordPosition="348"> Although they have been successful in acquiring related words, various parameters such as similarity measures and weighting are involved. As Weeds et al. (2004) pointed out, “it is not at all obvious that one universally best measure exists for all application,” thus they must be tuned by hand in an ad-hoc manner. The fact that no theoretic basis is given is making the matter more difficult. On the other hand, if we pay attention to lexical knowledge acquisition in general, a variety of systems which utilized syntactic patterns are found in the literature. In her landmark paper in the field, Hearst (1992) utilized syntactic patterns such as “such X as Y” and “Y and other X,” and extracted hypernym/hyponym relation of X and Y. Roark and Charniak (1998) applied this idea to extraction of words which belong to the same categories, utilizing syntactic relations such as conjunctions and appositives. What is worth attention here is that supervised machine learning is easily incorporated with syntactic patterns. For example, Snow et al. (2004) further extended Hearst’s idea and built hypernym classifiers based on machine learning and syntactic pattern-based features, with a considerable success. Thes</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A. Hearst. 1992. Automatic Acquisition of Hyponyms from Large Text Corpora. Proc. of COLING 92, 539–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>Noun classification from predicate-argument structures.</title>
<date>1990</date>
<booktitle>Proc. ofACL 90,</booktitle>
<pages>268--275</pages>
<contexts>
<context position="1673" citStr="Hindle, 1990" startWordPosition="233" endWordPosition="234">similarity of words is one of the most important lexical knowledge for NLP tasks including word sense disambiguation and automatic thesaurus construction. To measure the semantic relatedness of words, a concept called distributional similarity has been widely used. Distributional similarity represents the relatedness of two words by the commonality of contexts the words share, based on the distributional hypothesis (Harris, 1985), which states that semantically similar words share similar contexts. A number of researches which utilized distributional similarity have been conducted, including (Hindle, 1990; Lin, 1998; Geffet and Dagan, 2004) and many others. Although they have been successful in acquiring related words, various parameters such as similarity measures and weighting are involved. As Weeds et al. (2004) pointed out, “it is not at all obvious that one universally best measure exists for all application,” thus they must be tuned by hand in an ad-hoc manner. The fact that no theoretic basis is given is making the matter more difficult. On the other hand, if we pay attention to lexical knowledge acquisition in general, a variety of systems which utilized syntactic patterns are found in</context>
</contexts>
<marker>Hindle, 1990</marker>
<rawString>Donald Hindle. 1990. Noun classification from predicate-argument structures. Proc. ofACL 90, 268– 275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>Proc. of COLING/ACL 98,</booktitle>
<pages>786--774</pages>
<contexts>
<context position="1684" citStr="Lin, 1998" startWordPosition="235" endWordPosition="236">words is one of the most important lexical knowledge for NLP tasks including word sense disambiguation and automatic thesaurus construction. To measure the semantic relatedness of words, a concept called distributional similarity has been widely used. Distributional similarity represents the relatedness of two words by the commonality of contexts the words share, based on the distributional hypothesis (Harris, 1985), which states that semantically similar words share similar contexts. A number of researches which utilized distributional similarity have been conducted, including (Hindle, 1990; Lin, 1998; Geffet and Dagan, 2004) and many others. Although they have been successful in acquiring related words, various parameters such as similarity measures and weighting are involved. As Weeds et al. (2004) pointed out, “it is not at all obvious that one universally best measure exists for all application,” thus they must be tuned by hand in an ad-hoc manner. The fact that no theoretic basis is given is making the matter more difficult. On the other hand, if we pay attention to lexical knowledge acquisition in general, a variety of systems which utilized syntactic patterns are found in the litera</context>
<context position="5295" citStr="Lin, 1998" startWordPosition="792" endWordPosition="793">efined, along with the extraction methods. Using the features, in Section 4 we build five types of synonym classifiers, and compare their performances in Section 5. Section 6 concludes this paper, mentioning the future direction of this study. 2 Distributional Features In this section, we firstly describe how we extract contexts from corpora and then how distributional features are constructed for word pairs. 2.1 Context Extraction We adopted dependency structure as the context of words since it is the most widely used and wellperforming contextual information in the past studies (Ruge, 1997; Lin, 1998). In this paper the sophisticated parser RASP Toolkit 2 (Briscoe et al., 2006) was utilized to extract this kind of word relations. We use the following example for illustration purposes: The library has a large collection of classic books by such authors as Herrick and Shakespeare. RASP outputs the extracted dependency structure as n-ary relations as follows: (ncsubj have library _) (dobj have collection) (det collection a) (ncmod _ collection large) (iobj collection of) (dobj of book) (ncmod _ book by) (dobj by author) (det author such) (ncmod _ author as) ... , whose graphical representatio</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. Proc. of COLING/ACL 98, 786–774.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shachar Mirkin</author>
<author>Ido Dagan</author>
<author>Maayan Geffet</author>
</authors>
<title>Integrating pattern-based and distributional similarity methods for lexical entailment acquisition.</title>
<date>2006</date>
<booktitle>Proc. of COLING/ACL 06,</booktitle>
<pages>579--586</pages>
<contexts>
<context position="3066" citStr="Mirkin et al. (2006)" startWordPosition="455" endWordPosition="458">tion of X and Y. Roark and Charniak (1998) applied this idea to extraction of words which belong to the same categories, utilizing syntactic relations such as conjunctions and appositives. What is worth attention here is that supervised machine learning is easily incorporated with syntactic patterns. For example, Snow et al. (2004) further extended Hearst’s idea and built hypernym classifiers based on machine learning and syntactic pattern-based features, with a considerable success. These two independent approaches, distributional similarity and syntactic patterns, were finally integrated by Mirkin et al. (2006). Although they reported that their system successfully improved the performance, it did not achieve a complete integration and was still relying on an independent module to compute the similarity. This configuration inherits a large portion of drawbacks of the similaritybased approach mentioned above. To achieve a full integration of both approaches, we suppose that re1 Proceedings of the ACL-08: HLT Student Research Workshop (Companion Volume), pages 1–6, Columbus, June 2008. c�2008 Association for Computational Linguistics formalization of similarity-based approach would be essential, as pa</context>
<context position="10258" citStr="Mirkin et al., 2006" startWordPosition="1646" endWordPosition="1649">connected by conjunctions such as and and or. After this shortcut, the syntactic pattern between authors and Herrick is ncmod-of:as:dobj-of, and that of Herrick and Shakespeare is conj-and, which is a newly introduced special symmetric relation, indicating that the nouns are mutually conjunctional. 3.2 Feature Construction After the corpus is analyzed and patterns are extracted, the pattern based feature fPk (w1, w2), which corresponds to the syntactic pattern Pk, is defined as the conditional probability of observing Pk given that the pair (w1, w2) is observed. This definition is similar to (Mirkin et al., 2006) and is calculated as: fPk (w1, w2) = P(pk|w1, w2) = N(w1, w2, pk) N(w1, w2) . (4) 4 Synonym Classifiers Now that we have all the features to consider, we construct the following five classifiers. This section gives the construction detail of the classifiers and corresponding feature vectors. Distributional Similarity (DSIM) DSIM classifier is simple acquisition relying only on distributional similarity, not on supervised learning. Similar to conventional methods, distributional similarity between words w1 and w2, sim(w1, w2), is calculated for each word pair using Jaccard coefficient: ∑ cEC(w</context>
<context position="11938" citStr="Mirkin et al. (2006)" startWordPosition="1908" endWordPosition="1911"> instead uses the distributional features described in Section 2. The feature vector v~ of a word pair (w1, w2) is constructed as: v~ = (fD , ..., f�M). (5) Pattern-based Features (PAT) This classifier PAT uses only pattern-based features, essentially the same as the classifier of Snow et al. (2004). The feature vector is: v~ = (f�1 , ..., f�K). (6) Distributional Similarity and Pattern-based Features (DSIM-PAT) DSIM-PAT uses the distributional similarity of pairs as a feature, in addition to pattern-based features. This classifier is essentially the same as the integration method proposed by Mirkin et al. (2006). Letting fS = sim(w1, w2), the feature vector is: v~= (fS, fi , ..., f�K). (7) Distributional and Pattern-based Features (DFEAT-PAT) The last classifier, DFEAT-PAT, truly integrates both distributional and pattern-based features. The feature vector is constructed by replacing the fS component of DSIM-PAT with distributional features fD , ..., fM as: v~ = (fD , ..., fM, fP , ..., f�K). (8) 5 Experiments Finally, this section describes the experimental setting and the comparison of synonym classifiers. 5.1 Experimental Settings Corpus and Preprocessing As for the corpus, New York Times section </context>
<context position="16420" citStr="Mirkin et al., 2006" startWordPosition="2636" endWordPosition="2639">l,” “slang” and phrases comprised of two or more words. The pair (w1, w2) is marked as synonyms if and only if w2 is contained in the answer set of w1, or w1 is contained in that of w2. 5.3 Classifier Performance The performances, i.e., precision, recall, and F-1 measure, of the five classifiers were evaluated and shown in Table 1. First of all, we observed a drastic improvement of DFEAT over DSIM — over 120% increase of F-1 measure. When combined with pattern-based features, DSIM-PAT showed a slight recall increase compared to DSIM, partially reconfirming the favorable integration result of (Mirkin et al., 2006). However, the combination DFEAT-PAT showed little change, meaning that the discriminative ability of DFEAT was so high that pattern-based features were almost redundant. To note, the performance of PAT was the lowest, reflecting the fact that synonym pairs rarely occur in the same sentence, making the identification using only syntactic pattern clues even more difficult. The reason of the drastic improvement is that, as far as we speculate, the supervised learning may have favorably worked to cause the same effect as automatic feature selection technique. Features with high discriminative pow</context>
</contexts>
<marker>Mirkin, Dagan, Geffet, 2006</marker>
<rawString>Shachar Mirkin, Ido Dagan, and Maayan Geffet. 2006. Integrating pattern-based and distributional similarity methods for lexical entailment acquisition. Proc. of COLING/ACL 06, 579–586.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Eugene Charniak</author>
</authors>
<title>Noun phrase cooccurrence statistics for semi-automatic lexicon construction.</title>
<date>1998</date>
<booktitle>Proc. of COLING/ACL 98,</booktitle>
<pages>1110--1116</pages>
<contexts>
<context position="2488" citStr="Roark and Charniak (1998)" startWordPosition="371" endWordPosition="374">. As Weeds et al. (2004) pointed out, “it is not at all obvious that one universally best measure exists for all application,” thus they must be tuned by hand in an ad-hoc manner. The fact that no theoretic basis is given is making the matter more difficult. On the other hand, if we pay attention to lexical knowledge acquisition in general, a variety of systems which utilized syntactic patterns are found in the literature. In her landmark paper in the field, Hearst (1992) utilized syntactic patterns such as “such X as Y” and “Y and other X,” and extracted hypernym/hyponym relation of X and Y. Roark and Charniak (1998) applied this idea to extraction of words which belong to the same categories, utilizing syntactic relations such as conjunctions and appositives. What is worth attention here is that supervised machine learning is easily incorporated with syntactic patterns. For example, Snow et al. (2004) further extended Hearst’s idea and built hypernym classifiers based on machine learning and syntactic pattern-based features, with a considerable success. These two independent approaches, distributional similarity and syntactic patterns, were finally integrated by Mirkin et al. (2006). Although they report</context>
</contexts>
<marker>Roark, Charniak, 1998</marker>
<rawString>Brian Roark and Eugene Charniak. 1998. Noun phrase cooccurrence statistics for semi-automatic lexicon construction. Proc. of COLING/ACL 98, 1110– 1116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roget</author>
</authors>
<title>Roget’s II: The New Thesaurus, 3rd ed.</title>
<date>1995</date>
<publisher>Houghton Mifflin.</publisher>
<contexts>
<context position="15581" citStr="Roget, 1995" startWordPosition="2494" endWordPosition="2495"> notes/ ldoce-vocab.html 4 Table 1: Performance comparison of synonym classifiers Classifier Precision Recall F-1 DSIM 33.13% 49.71% 39.76% DFEAT 95.25% 82.31% 88.30% PAT 23.86% 45.17% 31.22% DSIM-PAT 30.62% 51.34% 38.36% DFEAT-PAT 95.37% 82.31% 88.36% were optimized using one of the 5-fold cross validation train-test pair on the basis of F-1 measure. The performance was evaluated for the other four traintest pairs and the average values were recorded. 5.2 Evaluation To test whether or not a given word pair (w1, w2) is a synonym pair, three existing thesauri were consulted: Roget’s Thesaurus (Roget, 1995), Collins COBUILD Thesaurus (Collins, 2002), and WordNet (Fellbaum, 1998). The union of synonyms obtained when the head word is looked up as a noun is used as the answer set, except for words marked as “idiom,” “informal,” “slang” and phrases comprised of two or more words. The pair (w1, w2) is marked as synonyms if and only if w2 is contained in the answer set of w1, or w1 is contained in that of w2. 5.3 Classifier Performance The performances, i.e., precision, recall, and F-1 measure, of the five classifiers were evaluated and shown in Table 1. First of all, we observed a drastic improvement</context>
</contexts>
<marker>Roget, 1995</marker>
<rawString>Roget. 1995. Roget’s II: The New Thesaurus, 3rd ed. Houghton Mifflin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerda Ruge</author>
</authors>
<title>Automatic detection of thesaurus relations for information retrieval applications.</title>
<date>1997</date>
<booktitle>Foundations of Computer Science: Potential - Theory - Cognition, LNCS,</booktitle>
<volume>1337</volume>
<pages>499--506</pages>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="5283" citStr="Ruge, 1997" startWordPosition="790" endWordPosition="791">atures are defined, along with the extraction methods. Using the features, in Section 4 we build five types of synonym classifiers, and compare their performances in Section 5. Section 6 concludes this paper, mentioning the future direction of this study. 2 Distributional Features In this section, we firstly describe how we extract contexts from corpora and then how distributional features are constructed for word pairs. 2.1 Context Extraction We adopted dependency structure as the context of words since it is the most widely used and wellperforming contextual information in the past studies (Ruge, 1997; Lin, 1998). In this paper the sophisticated parser RASP Toolkit 2 (Briscoe et al., 2006) was utilized to extract this kind of word relations. We use the following example for illustration purposes: The library has a large collection of classic books by such authors as Herrick and Shakespeare. RASP outputs the extracted dependency structure as n-ary relations as follows: (ncsubj have library _) (dobj have collection) (det collection a) (ncmod _ collection large) (iobj collection of) (dobj of book) (ncmod _ book by) (dobj by author) (det author such) (ncmod _ author as) ... , whose graphical r</context>
</contexts>
<marker>Ruge, 1997</marker>
<rawString>Gerda Ruge. 1997. Automatic detection of thesaurus relations for information retrieval applications. Foundations of Computer Science: Potential - Theory - Cognition, LNCS, Volume 1337, 499–506, Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Daniel Jurafsly</author>
<author>Andrew Y Ng</author>
</authors>
<title>Learning syntactic patterns for automatic hypernym discovery.</title>
<date>2004</date>
<booktitle>Advances in Neural Information Processing Systems (NIPS) 17.</booktitle>
<contexts>
<context position="2779" citStr="Snow et al. (2004)" startWordPosition="417" endWordPosition="420">to lexical knowledge acquisition in general, a variety of systems which utilized syntactic patterns are found in the literature. In her landmark paper in the field, Hearst (1992) utilized syntactic patterns such as “such X as Y” and “Y and other X,” and extracted hypernym/hyponym relation of X and Y. Roark and Charniak (1998) applied this idea to extraction of words which belong to the same categories, utilizing syntactic relations such as conjunctions and appositives. What is worth attention here is that supervised machine learning is easily incorporated with syntactic patterns. For example, Snow et al. (2004) further extended Hearst’s idea and built hypernym classifiers based on machine learning and syntactic pattern-based features, with a considerable success. These two independent approaches, distributional similarity and syntactic patterns, were finally integrated by Mirkin et al. (2006). Although they reported that their system successfully improved the performance, it did not achieve a complete integration and was still relying on an independent module to compute the similarity. This configuration inherits a large portion of drawbacks of the similaritybased approach mentioned above. To achiev</context>
<context position="8659" citStr="Snow et al. (2004)" startWordPosition="1392" endWordPosition="1395">an and Moens, 2002) that negative PMI values worsen the distributional similarity performance, we bound PMI so that wgt(wi, cj) = 0 if PMI(wi, cj) &lt; 0. Finally, the feature value fDj(w1, w2) is defined as shown in Equation (2) only when the context cj co-occurs with both w1 and w2. In other words, fD j (w1, w2) = 0 if PMI(w1, cj) = 0 and/or PMI(w2, cj) = 0. 3 Pattern-based Features This section describes the other type of features, extracted from syntactic patterns in sentences. 3.1 Syntactic Pattern Extraction We define syntactic patterns based on dependency structure of sentences. Following Snow et al. (2004)’s definition, the syntactic pattern of words w1, w2 is defined as the concatenation of the words and relations which are on the dependency path from w1 to w2, not including w1 and w2 themselves. The syntactic pattern of word authors and books in Figure 1 is, for example, dobj:by:ncmod, while that of authors and Herrick is ncmod-of:as:dobj-of:and:conj-of. Notice that, although not shown in the figure, every relation has a reverse edge as its counterpart, with the direction opposite and the postfix “-of” attached to the label. This allows to follow the relations in reverse, increasing the flexi</context>
<context position="11618" citStr="Snow et al. (2004)" startWordPosition="1857" endWordPosition="1860">old is set on the similarity and classification is performed based on whether the similarity is above or below of the given threshold. How to optimally set this threshold is described later in Section 5.1. Distributional Features (DFEAT) DFEAT classifier does not rely on the conventional distributional similarity and instead uses the distributional features described in Section 2. The feature vector v~ of a word pair (w1, w2) is constructed as: v~ = (fD , ..., f�M). (5) Pattern-based Features (PAT) This classifier PAT uses only pattern-based features, essentially the same as the classifier of Snow et al. (2004). The feature vector is: v~ = (f�1 , ..., f�K). (6) Distributional Similarity and Pattern-based Features (DSIM-PAT) DSIM-PAT uses the distributional similarity of pairs as a feature, in addition to pattern-based features. This classifier is essentially the same as the integration method proposed by Mirkin et al. (2006). Letting fS = sim(w1, w2), the feature vector is: v~= (fS, fi , ..., f�K). (7) Distributional and Pattern-based Features (DFEAT-PAT) The last classifier, DFEAT-PAT, truly integrates both distributional and pattern-based features. The feature vector is constructed by replacing th</context>
</contexts>
<marker>Snow, Jurafsly, Ng, 2004</marker>
<rawString>Rion Snow, Daniel Jurafsly, and Andrew Y. Ng. 2004. Learning syntactic patterns for automatic hypernym discovery. Advances in Neural Information Processing Systems (NIPS) 17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie Weeds</author>
<author>David Weir</author>
<author>Diana McCarthy</author>
</authors>
<date>2004</date>
<booktitle>Characterising Measures of Lexical Distributional Similarity. Proc. of COLING 04,</booktitle>
<pages>1015--1021</pages>
<contexts>
<context position="1887" citStr="Weeds et al. (2004)" startWordPosition="266" endWordPosition="269">ept called distributional similarity has been widely used. Distributional similarity represents the relatedness of two words by the commonality of contexts the words share, based on the distributional hypothesis (Harris, 1985), which states that semantically similar words share similar contexts. A number of researches which utilized distributional similarity have been conducted, including (Hindle, 1990; Lin, 1998; Geffet and Dagan, 2004) and many others. Although they have been successful in acquiring related words, various parameters such as similarity measures and weighting are involved. As Weeds et al. (2004) pointed out, “it is not at all obvious that one universally best measure exists for all application,” thus they must be tuned by hand in an ad-hoc manner. The fact that no theoretic basis is given is making the matter more difficult. On the other hand, if we pay attention to lexical knowledge acquisition in general, a variety of systems which utilized syntactic patterns are found in the literature. In her landmark paper in the field, Hearst (1992) utilized syntactic patterns such as “such X as Y” and “Y and other X,” and extracted hypernym/hyponym relation of X and Y. Roark and Charniak (1998</context>
</contexts>
<marker>Weeds, Weir, McCarthy, 2004</marker>
<rawString>Julie Weeds, David Weir and Diana McCarthy. 2004. Characterising Measures of Lexical Distributional Similarity. Proc. of COLING 04, 1015–1021.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>