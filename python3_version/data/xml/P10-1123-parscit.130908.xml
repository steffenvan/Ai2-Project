<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000019">
<title confidence="0.995522">
Assessing the Role of Discourse References in Entailment Inference
</title>
<author confidence="0.99821">
Shachar Mirkin, Ido Dagan Sebastian Pad´o
</author>
<affiliation confidence="0.999619">
Bar-Ilan University University of Stuttgart
</affiliation>
<address confidence="0.586641">
Ramat-Gan, Israel Stuttgart, Germany
</address>
<email confidence="0.99803">
{mirkins,dagan}@cs.biu.ac.il pado@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.99388" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999376363636364">
Discourse references, notably coreference
and bridging, play an important role in
many text understanding applications, but
their impact on textual entailment is yet to
be systematically understood. On the ba-
sis of an in-depth analysis of entailment
instances, we argue that discourse refer-
ences have the potential of substantially
improving textual entailment recognition,
and identify a number of research direc-
tions towards this goal.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9992942">
The detection and resolution of discourse refer-
ences such as coreference and bridging anaphora
play an important role in text understanding appli-
cations, like question answering and information
extraction. There, reference resolution is used for
the purpose of combining knowledge from multi-
ple sentences. Such knowledge is also important
for Textual Entailment (TE), a generic framework
for modeling semantic inference. TE reduces the
inference requirements of many text understand-
ing applications to the problem of determining
whether the meaning of a given textual assertion,
termed hypothesis (H), can be inferred from the
meaning of certain text (T) (Dagan et al., 2006).
Consider the following example:
</bodyText>
<listItem confidence="0.8461225">
(1) T: “Not only had he developed an aversion
to the Presidents and politics in general,
Oswald2 was also a failure with Marina, his
wife. [...] Their relationship was supposedly
responsible for why he2 killed Kennedys.”
H: “Oswald killed President Kennedy.”
</listItem>
<bodyText confidence="0.999956738095238">
The understanding that the second sentence of the
text entails the hypothesis draws on two corefer-
ence relationships, namely that he is Oswald, and
that the Kennedy in question is President Kennedy.
However, the utilization of discourse information
for such inferences has been so far limited mainly
to the substitution of nominal coreferents, while
many aspects of the interface between discourse
and semantic inference needs remain unexplored.
The recently held Fifth Recognizing Textual
Entailment (RTE-5) challenge (Bentivogli et al.,
2009a) has introduced a Search task, where the
text sentences are interpreted in the context of their
full discourse, as in Example 1 above. Accord-
ingly, TE constitutes an interesting framework –
and the Search task an adequate dataset – to study
the interrelation between discourse and inference.
The goal of this study is to analyze the roles
of discourse references for textual entailment in-
ference, to provide relevant findings and insights
to developers of both reference resolvers and en-
tailment systems and to highlight promising direc-
tions for the better incorporation of discourse phe-
nomena into inference. Our focus is on a manual,
in-depth assessment that results in a classification
and quantification of discourse reference phenom-
ena and their utilization for inference. On this ba-
sis, we develop an account of formal devices for
incorporating discourse references into the infer-
ence computation. An additional point of inter-
est is the interrelation between entailment knowl-
edge and coreference. E.g., in Example 1 above,
knowing that Kennedy was a president can alle-
viate the need for coreference resolution. Con-
versely, coreference resolution can often be used
to overcome gaps in entailment knowledge.
Structure of the paper. In Section 2, we pro-
vide background on the use of discourse refer-
ences in natural language processing (NLP) in
general and specifically in TE. Section 3 describes
the goals of this study, followed by our analy-
sis scheme (Section 4) and the required inference
</bodyText>
<page confidence="0.958035">
1209
</page>
<note confidence="0.9427035">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1209–1219,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.997989">
event coreference and bridging.1 Another reason
is uncertainty about their practical importance.
mechanisms (Section 5). Section 6 presents quan-
titative findings and further observations. Conclu-
sions are discussed in Section 7.
</bodyText>
<subsectionHeader confidence="0.43991">
2.2 Discourse in Textual Entailment
</subsectionHeader>
<sectionHeader confidence="0.908648" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.973473">
2.1 Discourse in NLP
</subsectionHeader>
<bodyText confidence="0.999890857142857">
Discourse information plays a role in a range
of NLP tasks. It is obviously central to dis-
course processing tasks such as text segmenta-
tion (Hearst, 1997). Reference information pro-
vided by discourse is also useful for text under-
standing tasks such as question answering (QA),
information extraction (IE) and information re-
trieval (IR) (Vicedo and Ferrndez, 2006; Zelenko
et al., 2004; Na and Ng, 2009), as well as for the
acquisition of lexical-semantic “narrative schema”
knowledge (Chambers and Jurafsky, 2009). Dis-
course references have been the subject of atten-
tion in both the Message Understanding Confer-
ence (Grishman and Sundheim, 1996) and the Au-
tomatic Content Extraction program (Strassel et
al., 2008).
The simplest form of information that discourse
provides is coreference, i.e., information that two
linguistic expressions refer to the same entity or
event. Coreference is particularly important for
processing pronouns and other anaphoric expres-
sions, such as he in Example 1. Ability to re-
solve this reference translates directly into, e.g., a
QA system’s ability to answer questions like Who
killed Kennedy?.
A second, more complex type of information
stems from bridging references, such as in the fol-
lowing discourse (Asher and Lascarides, 1998):
</bodyText>
<listItem confidence="0.530239">
(2) “I’ve just arrived. The camel is outside.”
</listItem>
<bodyText confidence="0.993589090909091">
While coreference indicates equivalence, bridging
points to the existence of a salient semantic rela-
tion between two distinct entities or events. Here,
it is (informally) ‘means of transport’, which
would make the discourse (2) relevant for a ques-
tion like How did I arrive here?. Other types of
bridging relations include set-membership, roles
in events and consequence (Clark, 1975).
Note, however, that text understanding systems
are generally limited to the resolution of entity (or
even just pronoun) coreference, e.g. (Li et al.,
2009; Dali et al., 2009). An important reason is the
unavailability of tools to resolve the more complex
(and difficult) forms of discourse reference such as
Textual Entailment has been introduced in Sec-
tion 1 as a common-sense notion of inference.
It has spawned interest in the computational lin-
guistics community as a common denominator of
many NLP tasks including IE, summarization and
tutoring (Romano et al., 2006; Harabagiu et al.,
2007; Nielsen et al., 2009).
Architectures for Textual Entailment. Over
the course of recent RTE challenges (Giampic-
colo et al., 2007; Giampiccolo et al., 2008), the
main benchmark for TE technology, two archi-
tectures for modeling TE have emerged as dom-
inant: transformations and alignment. The goal
of transformation-based TE models is to deter-
mine the entailment relation T ==&gt;. H by find-
ing a “proof”, i.e., a sequence of consequents,
(T, T1, ... , Tn), such that Tn=H (Bar-Haim et al.,
2008; Harmeling, 2009), and that in each trans-
formation, Ti —* Ti+1, the consequent Ti+1 is en-
tailed by Ti. These transformations commonly in-
clude lexical modifications and the generation of
syntactic alternatives. The second major approach
constructs an alignment between the linguistic en-
tities of the trees (or graphs) of T and H, which
can represent syntactic structure, semantic struc-
ture, or non-hierarchical phrases (Zanzotto et al.,
2009; Burchardt et al., 2009; MacCartney et al.,
2008). H is assumed to be entailed by T if its en-
tities are aligned “well” to corresponding entities
in T. Alignment quality is generally determined
based on features that assess the validity of the lo-
cal replacement of the T entity by the H entity.
While transformation- and alignment-based en-
tailment models look different at first glance, they
ultimately have the same goal, namely obtaining
a maximal coverage of H by T, i.e. to identify
matches of as many elements of H within T as
possible.2 To do so, both architectures typically
make use of inference rules such as ‘Y was pur-
chased by X —* X paid for Y’, either by directly ap-
plying them as transformations, or by using them
</bodyText>
<footnote confidence="0.999373285714286">
1Some studies, e.g. (Markert et al., 2003; Poesio et al.,
2004), address the resolution of a few specific kinds of bridg-
ing relations; yet, wide-scope systems for bridging resolution
are unavailable.
2Clearly, the details of how the final entailment decision
is made based on the attained coverage differ substantially
among models.
</footnote>
<page confidence="0.991499">
1210
</page>
<bodyText confidence="0.999496575">
to score alignments. Rules are generally drawn
from external knowledge resources, such as Word-
Net (Fellbaum, 1998) or DIRT (Lin and Pantel,
2001), although knowledge gaps remain a key ob-
stacle (Bos, 2005; Balahur et al., 2008; Bar-Haim
et al., 2008).
Discourse in previous RTE challenges. The
first two rounds of the RTE challenge used “self-
contained” texts and hypotheses, where discourse
considerations played virtually no role. A first step
towards a more comprehensive notion of entail-
ment was taken with RTE-3 (Giampiccolo et al.,
2007), when paragraph-length texts were first in-
cluded and constituted 17% of the texts in the test
set. Chambers et al. (2007) report that in a sample
of T − H pairs drawn from the development set,
25% involved discourse references.
Using the concepts introduced above, the im-
pact of discourse references can be generally de-
scribed as a coverage problem, independent of the
system’s architecture. In Example 1, the hypoth-
esis word Oswald cannot be safely linked to the
text pronoun he without further knowledge about
he; the same is true for ‘Kennedy —* President
Kennedy’ which involves a specialization that is
only warranted in the specific discourse.
A number of systems have tried to address the
question of coreference in RTE as a preprocessing
step prior to inference proper, with most systems
using off-the-shelf coreference resolvers such as
JavaRap (Qiu et al., 2004) or OpenNLP3. Gen-
erally, anaphoric expressions were textually re-
placed by their antecedents. Results were in-
conclusive, however, with several reports about
errors introduced by automatic coreference res-
olution (Agichtein et al., 2008; Adams et al.,
2007). Specific evaluations of the contribution
of coreference resolution yielded both small nega-
tive (Bar-Haim et al., 2008) and insignificant pos-
itive (Chambers et al., 2007) results.
</bodyText>
<sectionHeader confidence="0.958718" genericHeader="method">
3 Motivation and Goals
</sectionHeader>
<bodyText confidence="0.999927857142857">
The results of recent studies, as reported in Sec-
tion 2.2, seem to show that current resolution of
discourse references in RTE systems hardly af-
fects performance. However, our intuition is that
these results can be attributed to four major lim-
itations shared by these studies: (1) the datasets,
where discourse phenomena were not well repre-
</bodyText>
<footnote confidence="0.612755">
3http://opennlp.sourceforge.net
</footnote>
<bodyText confidence="0.993393836734694">
sented; (2) the off-the-shelf coreference resolution
systems which may have been not robust enough;
(3) the limitation to nominal coreference; and (4)
overly simple integration of reference information
into the inference engines.
The goal of this paper is to assess the impact of
discourse references on entailment with an anno-
tation study which removes these limitations. To
counteract (1), we use the recent RTE-5 Search
dataset (details below). To avoid (2), we perform
a manual analysis, assuming discourse references
as predicted by an oracle. With regards to (3), our
annotation scheme covers coreference and bridg-
ing relations of all syntactic categories and classi-
fies them. As for (4), we suggest several opera-
tions necessary to integrate the discourse informa-
tion into an entailment engine.
In contrast to the numerous existing datasets
annotated for discourse references (Hovy et al.,
2006; Strassel et al., 2008), we do not annotate ex-
haustively. Rather, we are interested specifically in
those references instances that impact inference.
Furthermore, we analyze each instance from an
entailment perspective, characterizing the relevant
factors that have an impact on inference. To our
knowledge, this is the first such in-depth study.4
The results of our study are of twofold interest.
First, they provide guidance for the developers of
reference resolvers who might prioritize the scope
of their systems to make them more valuable for
inference. Second, they point out potential direc-
tions for the developers of inference systems by
specifying what additional inference mechanisms
are needed to utilize discourse information.
The RTE-5 Search dataset. We base our anno-
tation on the Search task dataset, a new addition
to the recent Fifth RTE challenge (Bentivogli et
al., 2009a) that is motivated by the needs of NLP
applications and drawn from the TAC summariza-
tion track. In the Search task, TE systems are re-
quired to find all individual sentences in a given
corpus which entail the hypothesis – a setting that
is sensible not only for summarization, but also for
information access tasks like QA. Sentences are
judged individually, but “are to be interpreted in
the context of the corpus as they rely on explicit
and implicit references to entities, events, dates,
places, etc., mentioned elsewhere in the corpus”
(Bentivogli et al., 2009b).
</bodyText>
<footnote confidence="0.9959285">
4The guidelines and the dataset are available at
http://www.cs.biu.ac.il/˜nlp/downloads/
</footnote>
<page confidence="0.915622">
1211
</page>
<table confidence="0.9964518">
Text Hypothesis
i T0 Once the reform becomes law, Spain will join the Netherlands Massachusetts allows homosexual
and Belgium in allowing homosexual marriages. marriages
T Such unions are also legal in six Canadian provinces and the
northeastern US state of Massachusetts.
ii T0 The official name of 2003 UB313 has yet to be determined. 2003 UB313 is in the Kuiper Belt
T Brown said he expected to find a moon orbiting Xena because
many Kuiper Belt objects are paired with moons.
iii Ta All seven aboard the AS-28 submarine appeared to be in satis- The AS-28 mini submarine was trapped
factory condition, naval spokesman said. underwater
T 0 British crews were working with Russian naval authorities to ma-
t neuver the unmanned robotic vehicle and untangle the AS-28.
T The Russian military was racing against time early Friday to res-
cue a mini submarine trapped on the seabed.
iv T0 China seeks solutions to its coal mine safety. A mining accident in China has killed
several miners
T A recent accident has cost more than a dozen miners their lives.
v T00 A remote-controlled device was lowered to the stricken vessel to The AS-28 mini submarine was trapped
cut the cables in which the AS-28 vehicle is caught. underwater
T0 The mini submarine was resting on the seabed at a depth of about
200 meters.
T Specialists said it could have become tangled up with a metal
cable or in sunken nets from a fishing trawler.
vi T ... dried up lakes in Siberia, because the permafrost beneath The ice is melting in the Arctic
them has begun to thaw.
</table>
<tableCaption confidence="0.993445333333333">
Table 1: Examples for discourse-dependent entailment in the RTE-5 dataset, where the inference of H
depends on reference information from the discourse sentences T0 / T00. Referring terms (in T) and target
terms (in H) are shown in boldface.
</tableCaption>
<sectionHeader confidence="0.862906" genericHeader="method">
4 Analysis Scheme
</sectionHeader>
<bodyText confidence="0.992912">
For annotating the RTE-5 data, we operationalize
reference relations that are relevant for entailment
as those that improve coverage. Recall from Sec-
tion 2.2 that the concept of coverage is applicable
to both transformation and alignment models, all
of which aim at maximizing coverage of H by T.
We represent T and H as syntactic trees, as
common in the RTE literature (Zanzotto et al.,
2009; Agichtein et al., 2008). Specifically, we
assume MINIPAR-style (Lin, 1993) dependency
trees where nodes represent text expressions and
edges represent the syntactic relations between
them. We use “term” to refer to text expressions,
and “components” to refer to nodes, edges, and
subtrees. Dependency trees are a popular choice
in RTE since they offer a fairly semantics-oriented
account of the sentence structure that can still be
constructed robustly. In an ideal case of entail-
ment, all nodes and dependency edges of H are
covered by T.
For each T − H pair, we annotate all relevant
discourse references in terms of three items: the
target component in H, the focus term in T, and
the reference term which stands in a reference re-
lation to the focus term. By resolving this ref-
erence, the target component can usually be in-
ferred; sometimes, however, more than one ref-
erence term needs to be found. We now define
and illustrate these concepts on examples from
Table 1.5
The target component is a tree component in
H that cannot be covered by the “local” material
from T. An example for a tree component is Ex-
ample (v), where the target component AS-28 mini
submarine in H cannot be inferred from the pro-
noun it in T. Example (vi) demonstrates an edge
as target component. In this case, the edge in H
connecting melt with the modifier in the Arctic is
not found in T. Although each of the hypothesis’
nodes can be covered separately via knowledge-
based rules (e.g. ‘Siberia —* Arctic’, ‘permafrost
—* ice’, ‘thaw H melt’), the resulting fragments
in T are unconnected without the (intra-sentential)
coreference between them and lakes in Siberia.
For each target component, we identify its focus
term as the expression in T that does not cover the
target component itself but participates in a refer-
ence relation that can help covering it.
We follow the focus term’s reference chain to
a reference term which can, either separately or
in combination with the focus term, help covering
the target component. In Example (ii), where the
5In our annotation, we assume throughout that some
knowledge about basic admissible transformations is avail-
able, such as passive to active or derivational transformations;
for brevity, we ignore articles in the examples and treat named
entities as single nodes.
</bodyText>
<page confidence="0.96854">
1212
</page>
<bodyText confidence="0.99998150877193">
target component in H is 2003 UB313, Xena is the
focus term in T and the reference term is a men-
tion of 2003 UB313 in a previous sentence, T�. In
this case, the reference term covers the entire tar-
get component on its own.
An additional attribute that we record for each
instance is whether resolving the discourse refer-
ence is mandatory for determining entailment, or
optional. In Example (v), it is mandatory: the in-
ference cannot be completed without the knowl-
edge provided by the discourse. In contrast, in
Example (ii), inferring 2003 UB313 from Xena
is optional. It can be done either by identify-
ing their coreference relation, or by using back-
ground knowledge in the form of an entailment
rule, ‘Xena H 2003 UB313’, that is applicable
in the context of astronomy. Optional discourse
references represent instances where discourse in-
formation and TE knowledge are interchange-
able. As mentioned, knowledge gaps constitute
a major obstacle for TE systems, and we can-
not rely on the availability of any ceratin piece of
knowledge to the inference process. Thus, in our
scheme, mandatory references provide a “lower
bound” with regards to the necessity to resolve
discourse references, even in the presence of com-
plete knowledge; optional references, on the other
hand, set an “upper bound” for the contribution of
discourse resolution to inference, when no knowl-
edge is available. At the same time, this scheme
allows investigating how much TE knowledge can
be replaced by (perfect) discourse processing.
When choosing a reference term, we search the
reference chain of the focus term for the nearest
expression that is identical to the target component
or a subcomponent of it. If we find such an expres-
sion, covering the identical part of the target com-
ponent requires no entailment knowledge. If no
identical reference term exists, we choose the se-
mantically ‘closest’ term from the reference chain,
i.e. the term which requires the least knowledge to
infer the target component. For instance, we may
pick permafrost as the semantically closet term to
the target ice if the latter is not found in the focus
term’s reference chain.
Finally, for each reference relation that we an-
notate, we record four additional attributes which
we assumed to be informative in an evaluation.
First, the reference type: Is the relation a coref-
erence or a bridging reference? Second, the syn-
tactic type of the focus and reference terms. Third,
the focus/reference terms entailment status – does
some kind of entailment relation hold between the
two terms? Fourth, the operation that should be
performed on the focus and reference terms to ob-
tain coverage of the target component (as specified
in Section 5).
</bodyText>
<sectionHeader confidence="0.986511" genericHeader="method">
5 Integrating Discourse References into
</sectionHeader>
<subsectionHeader confidence="0.712477">
Entailment Recognition
</subsectionHeader>
<bodyText confidence="0.998319361111111">
In initial analysis we found that the standard sub-
stitution operation applied by virtually all previous
studies for integrating coreference into entailment
is insufficient. We identified three distinct cases
for the integration of discourse reference knowl-
edge in entailment, which correspond to different
relations between the target component, the fo-
cus term and the reference term. This section de-
scribes the three cases and characterizes them in
terms of tree transformations. An initial version of
these transformations is described in (Abad et al.,
2010). We assume a transformation-based entail-
ment architecture (cf. Section 2.2), although we
believe that the key points of our account are also
applicable to alignment-based architecture. Trans-
formations create revised trees that cover previ-
ously uncovered target components in H. The
output of each transformation, Ti, is comprised
of copies of the components used to construct it,
and is appended to the discourse forest, which in-
cludes the dependency trees of all sentences and
their generated consequents.
We assume that we have access to a dependency
tree for H, a dependency forest for T and its dis-
course context, as well as the output of a perfect
discourse processor, i.e., a complete set of both
coreference and bridging relations, including the
type of bridging relation (e.g. part-of, cause).
We use the following notation. We use x, y
for tree nodes, and 5x to denote a (sub-)tree with
root x. lab(x) is the label of the incoming edge
of x (i.e., its grammatical function). We write
Qx, y) for a coreference relation between 5x and
5y, the corresponding trees of the focus and refer-
ence terms, respectively. We write Br(x, y) for a
bridging relation, where r is its type.
</bodyText>
<listItem confidence="0.959809">
(1) Substitution: This is the most intuitive and
</listItem>
<bodyText confidence="0.9185958">
widely-used transformation, corresponding to the
treatment of discourse information in existing sys-
tems. It applies to coreference relations, when an
expression found elsewhere in the text (the refer-
ence term) can cover all missing information (the
</bodyText>
<page confidence="0.976154">
1213
</page>
<figureCaption confidence="0.697370333333333">
Figure 1: The Substitution transformation, demon-
strated on the relevant subtrees of Example (i).
The dashed line denotes a discourse reference.
</figureCaption>
<bodyText confidence="0.983577333333333">
target component) on its own. In such cases, the
reference term can replace the entire focus term.
Apparently (cf. Section 6), substitution applies
also to some types of bridging relations, such as
set-membership, when the member is sufficient for
representing the entire set for the necessary infer-
ence. For example, in “I met two people yesterday.
The woman told me a story.” (Clark, 1975), sub-
stituting two people with woman results in a text
which is entailed from the discourse, and which
allows inferring “I met a woman yesterday.”
In a parse tree representation, given a corefer-
ence relation Qx, y) (or Br(x, y)), the newly gen-
erated tree, Ti, consists of a copy of T, where the
entire tree Sx is replaced by a copy of Sy . In Fig-
ure 1, which shows Example (i) from Table 1, such
unions is substituted by homosexual marriages.
Head-substitution. Occasionally, substituting
only the head of the focus term is sufficient. In
such cases, only the root nodes x and y are sub-
stituted. This is the case, for example, with syn-
onymous verbs with identical subcategorization
frames (like melt and thaw). As verbs typically
constitute tree roots in dependency parses, sub-
stituting or merging (see below) their entire trees
might be inappropriate or wasteful. In such cases,
the simpler head-substitution may be applied.
(2) Merge: In contrast to substitution, where a
match for the entire target component is found
elsewhere in the text, this transformation is re-
quired when parts of the missing information are
scattered among multiple locations in the text.
We distinguish between two types of merge trans-
formations: (a) dependent-merge, and (b) head-
merge, depending on the syntactic roles of the
merged components.
(a) Dependent-Merge. This operation is ap-
plicable when the head of either the focus or ref-
erence terms (of both) matches the head node of
</bodyText>
<figureCaption confidence="0.9944165">
Figure 2: The dependent-merge (Ta) and head-
merge (Tb) transformations (Example (iii)).
</figureCaption>
<bodyText confidence="0.99687135">
the target component, but modifiers from both of
them are required to cover the target component’s
dependents. The modifiers are therefore merged
as dependents of a single head node, to create
a tree that covers the entire target component.
Dependent-merge is illustrated in Figure 2, using
Example (iii). The component we wish to cover in
H is the noun phrase AS-28 mini submarine. Un-
fortunately, the focus term in T, “mini submarine
trapped on the seabed”, covers only the modifier
mini, but not AS-28. This modifier can however be
provided by the coreferent term in Ta (left upper
corner). Once merged, the inference engine can,
e.g., employ the rule ‘on seabed —* underwater’
to cover H completely.
Formally, assume without loss of generality that
y, the reference term’s head, matches the root node
of the target component. Given Qx, y), we define
Ti as a copy of T, where (i) the subtree Sx is re-
placed by Sy, and (ii) for all children c of x, a copy
of S, is placed under the copy of y in Ti with its
original edge label, lab(c).
(b) Head-merge. An alternative way to recover
the missing information in Example (iii) is to find
a reference term whose head word itself (rather
than one of its modifiers) matches the target com-
ponent’s missing dependent, as with AS-28 in Fig-
ure 2 in the bottom left corner (Tb). In terms of
parse trees, we need to add one tree as a depen-
dent of the other. Formally, given Qx, y), simi-
larly to dependent-merge, Ti is created as a copy
of T where the subtree Sx is replaced by either Sx
or Sy, depending on whichever of x and y matches
the target component’s head. Assume it is x, for
example. Then, a copy of Sy is added as a new
child to x. In our sample, head-merge operations
correspond to internal coreferences within nomi-
nal target components (such as between AS-28 and
mini submarine in this case). The appropriate la-
bel, lab(y), in these cases is nn (nominal modi-
</bodyText>
<page confidence="0.996253">
1214
</page>
<figureCaption confidence="0.9961685">
Figure 3: The insertion transformation. Dotted
edges mark the newly inserted path (Ex. (iv)).
</figureCaption>
<bodyText confidence="0.975080666666667">
fier). Further analysis is required to specify what
other dependencies can hold between such core-
ferring heads.
</bodyText>
<listItem confidence="0.810933">
(3) Insertion: The last transformation, insertion,
</listItem>
<bodyText confidence="0.982261929824562">
is used when a relation that is realized in H is
missing from T and is only implied via a bridg-
ing relation. In Example (iv), the location that is
explicitly mentioned in H can only be covered by
T by resolving a bridging reference with China
in T&apos;. To connect the bridging referents, a new
tree component representing the bridging relation
is inserted into the consequent tree T1. In this ex-
ample, the component connects China and recent
accident via the in preposition. Formally, given
a bridging relation Br(x, y), we introduce a new
subtree Srz into T1, where z is a child of x and
lab(z) = labr. Srz must contain a variable node
that is instantiated with a copy of S(y).
This transformation stands out from the others
in that it introduces new material. For each bridg-
ing relation, it adds a specific subtrees Sr via an
edge labeled with labr. These two items form the
dependency representation of the bridging relation
Br and must be provided by the interface between
the discourse and the inference systems. Clearly,
their exact form depends on the set of bridging re-
lations provided by the discourse resolver as well
as the details of the dependency parses.
As shown in Figure 3, the bridging relation
located-in (r) is represented by inserting a subtree
Srz headed by in (z) into T1 and connecting it to
accident (x) as a modifier (labr). The subtree Srz
consists of a variable node which is connected to
in with a pcomp-n dependency (a nominal head of
a prepositional phrase), and which is instantiated
with the node China (y) when the transformation
is applied. Note that the structure of Sr z and the
way it is inserted into T1 are predefined by the
abovementioned interface; only the node to which
it is attached and the contents of the variable node
are determined at transformation-time.
As another example, consider the following
short text from (Clark, 1975): John was murdered
yesterday. The knife lay nearby. Here, the bridg-
ing relation between the murder event and the in-
strument, the knife (x), can be addressed by in-
serting under x a subtree for the clause with which
as Srz, with a variable which is instantiated by the
parse-tree (headed by murdered, y) of the entire
first sentence John was murdered yesterday.
Transformation chaining. Since our transfor-
mations are defined to be minimal, some cases re-
quire the application of multiple transformations
to achieve coverage. Consider Example (v), Ta-
ble 1. We wish to cover AS-28 mini submarine in
H from the coreferring it in T, mini submarine in
T&apos; and AS-28 vehicle in T&apos;&apos;. A substitution of it by
either coreference does not suffice, since none of
the antecedents contains all necessary modifiers. It
is therefore necessary to substitute it first by one of
the coreferences and then merge it with the other.
</bodyText>
<sectionHeader confidence="0.999936" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.99996176">
We analyzed 120 sentence-hypothesis pairs of the
RTE-5 development set (21 different hypotheses,
111 distinct sentences, 53 different documents).
Below, we summarize our findings, focusing on
the relation between our findings and the assump-
tions of previous studies as discussed in Section 3.
General statistics. We found that 44% of the
pairs contained reference relations whose resolu-
tion was mandatory for inference. In another 28%,
references could optionally support the inference
of the hypothesis. In the remaining 28%, refer-
ences did not contribute towards inference. The
total number of relevant references was 137, and
37 pairs (27%) contained multiple relevant refer-
ences. These numbers support our assumption that
discourse references play an important role in in-
ference.
Reference types. 73% of the identified refer-
ences are coreferences and 27% are bridging re-
lations. The most common bridging relation was
the location of events (e.g. Arctic in ice melting
events), generally assumed to be known through-
out the document. Other bridging relations we en-
countered include cause (e.g. between injured and
attack), event participants and set membership.
</bodyText>
<page confidence="0.981521">
1215
</page>
<table confidence="0.978650333333333">
(%) Pronoun NE NP VP
Focus term 9 19 49 23
Reference term - 43 43 14
</table>
<tableCaption confidence="0.856056">
Table 2: Syntactic types of discourse references
</tableCaption>
<table confidence="0.99396025">
(%) Sub. Merge Insertion
Coreference 62 38 -
Bridging 30 - 70
Total 54 28 18
</table>
<tableCaption confidence="0.99953">
Table 3: Distribution of transformation types
</tableCaption>
<bodyText confidence="0.999982945945946">
Syntactic types. Table 2 shows that 77% of all
focus terms and 86% of the reference terms were
nominal phrases, which justifies their prominent
position in work on anaphora and coreference res-
olution. However, almost a quarter of the focus
terms were verbal phrases. We found these focus
terms to be frequently crucial for entailment since
they included the main predicate of the hypothe-
sis.6 This calls for an increased focus on the reso-
lution of event references.
Transformations. Table 3 shows the relative
frequencies of all transformations. Again, we
found that the “default” transformation, substitu-
tion, is the most frequent one, and is helpful for
both coreference and bridging relations. Substitu-
tion is particularly useful for handling pronouns
(14% of all substitution instances), the replace-
ment of named entities by synonymous names
(32%), the replacement of other NPs (38%), and
the substitution of verbal head nodes in event
coreference (16%). Yet, in nearly half the cases,
a different transformation had to be applied. In-
sertion accounts for the majority of bridging cases.
Head-merge is necessary to integrate proper nouns
as modifiers of other head nouns. Dependent-
merge, responsible for 85% of the merge transfor-
mations, can be used to complete nominal focus
terms with missing modifiers (e.g., adjectives), as
well as for merging other dependencies between
coreferring predicates. This result indicates the
importance of incorporating other transformations
into inference systems.
Distance of reference terms. The distance be-
tween the focus and the reference terms varied
considerably, ranging from intra-sentential refer-
ence relations and up to several dozen sentences.
For more than a quarter of the focus terms, we
</bodyText>
<footnote confidence="0.905731666666667">
6The lower proportion of VPs among reference terms
stems from bridging relations between VPs and nominal de-
pendents, such as the abovementioned “location” relation.
</footnote>
<bodyText confidence="0.99903356097561">
had to go to other documents to find reference
terms that, possibly in conjunction with the focus
term, could cover the target components. Interest-
ingly, all such cases involved coreference (about
equally divided between the merge transforma-
tions and substitutions), while bridging was al-
ways “document-local”. This result reaffirms the
usefulness of cross-document coreference resolu-
tion for inference (Huang et al., 2009).
Discourse resolution as preprocessing? In ex-
isting RTE systems, discourse references are typ-
ically resolved as a preprocessing step. While
our annotation was manual and cannot yield di-
rect results about processing considerations, we
observed that discourse relations often hold be-
tween complex, and deeply embedded, expres-
sions, which makes their automatic resolution dif-
ficult. Of course, many RTE systems attempt to
normalize and simplify H and T, e.g., by split-
ting conjunctions or removing irrelevant clauses,
but these operations are usually considered a part
of the inference rather the preprocessing phase (cf.
e.g., Bar-Haim et al. (2007)). Since the resolu-
tion of discourse references is likely to profit from
these steps, it seems desirable to “postpone” it un-
til after simplification. In transformation-based
systems, it might be natural to add discourse-based
transformations to the set of inference operations,
while in alignment-based systems, discourse ref-
erences can be integrated into the computation of
alignment scores.
Discourse references vs. entailment knowledge.
We have stated before that even if a discourse ref-
erence is not strictly necessary for entailment, it
may be interesting because it represents an alter-
native to the use of knowledge rules to cover the
hypothesis. Sometimes, these rules are generally
applicable (e.g., ‘Alaska —* Arctic’). However, of-
ten they are context-specific. Consider the follow-
ing sentence as T for the hypothesis H: “The ice
is melting in the Arctic”:
</bodyText>
<listItem confidence="0.702075">
(3) T: “The scene at the receding edge of the Exit
</listItem>
<bodyText confidence="0.955134285714286">
Glacier was part festive gathering, part nature
tour with an apocalyptic edge.”
While it is possible to cover melting using a rule
‘melting H receding’, this rule is only valid under
quite specific conditions (e.g., for the subject ice).
Instead of determining the applicability of the rule,
a discourse-aware system can take the next sen-
</bodyText>
<page confidence="0.976731">
1216
</page>
<bodyText confidence="0.879621">
tence into account, which contains a coreferring
event to receding that can cover melting in H:
</bodyText>
<listItem confidence="0.995772666666667">
(4) T&apos;: “... people moved closer to the rope line
near the glacier as it shied away, practically
groaning and melting before their eyes.”
</listItem>
<bodyText confidence="0.577553">
Discourse relations can in fact encode arbitrar-
ily complex world knowledge, as in the following
pair:
</bodyText>
<listItem confidence="0.9435665">
(5) H: “The serial killer BTK was accused of at
least 7 killings starting in the 1970’s.”
</listItem>
<bodyText confidence="0.975942863636364">
T: “Police say BTK may have killed as many
as 10 people between 1974 and 1991.”
Here, the H modifier serial, which does not occur
in T, can be covered either by world knowledge
(a person who killed 10 people is a serial killer),
or by resolving the coreference of BTK to the term
the serial killer BTK which occurs in the discourse
around T. Our conclusion is that not only can
discourse references often replace world knowl-
edge in principle, in practice it often seems easier
to resolve discourse references than to determine
whether a rule is applicable in a given context or
to formalize complex world knowledge as infer-
ence rules. Our annotation provides further em-
pirical support to this claim: An entailment rela-
tion exists between the focus and reference terms
in 60% of the focus-reference term pairs, and in
many of the remainder, entailment holds between
the terms’ heads. Thus, discourse provides rela-
tions which are many times equivalent to entail-
ment knowledge rules and can therefore be uti-
lized in their stead.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999990431034483">
This work has presented an analysis of the relation
between discourse references and textual entail-
ment. We have identified a set of limitations com-
mon to the handling of discourse relations in vir-
tually all entailment systems. They include the use
of off-the-shelf resolvers that concentrate on nom-
inal coreference, the integration of reference in-
formation through substitution, and the RTE eval-
uation schemes, which played down the role of
discourse. Since in practical settings, discourse
plays an important role, our goal was to develop
an agenda for improving the handling of discourse
references in entailment-based inference.
Our manual analysis of the RTE-5 dataset
shows that while the majority of discourse refer-
ences that affect inference are nominal coreference
relations, another substantial part is made up by
verbal terms and bridging relations. Furthermore,
we have demonstrated that substitution alone is in-
sufficient to extract all relevant information from
the wide range of discourse references that are
frequently relevant for inference. We identified
three general cases, and suggested matching op-
erations to obtain the relevant inferences, formu-
lated as tree transformations. Furthermore, our ev-
idence suggests that for practical reasons, the res-
olution of discourse references should be tightly
integrated into entailment systems instead of treat-
ing it as a preprocessing step.
A particularly interesting result concerns the
interplay between discourse references and en-
tailment knowledge. While semantic knowledge
(e.g., from WordNet or Wikipedia) has been used
beneficially for coreference resolution (Soon et al.,
2001; Ponzetto and Strube, 2006), reference res-
olution has, to our knowledge, not yet been em-
ployed to validate entailment rules’ applicability.
Our analyses suggest that in the context of de-
ciding textual entailment, reference resolution and
entailment knowledge can be seen as complemen-
tary ways of achieving the same goal, namely en-
riching T with additional knowledge to allow the
inference of H. Given that both of the technolo-
gies are still imperfect, we envisage the way for-
ward as a joint strategy, where reference resolution
and entailment rules mutually fill each other’s gaps
(cf. Example 3).
In sum, our study shows that textual entailment
can profit substantially from better discourse han-
dling. The next challenge is to translate the the-
oretical gain into practical benefit. Our analy-
sis demonstrates that improvements are necessary
both on the side of discourse reference resolution
systems, which need to cover more types of refer-
ences, as well as a better integration of discourse
information in entailment systems, even for those
relations which are within the scope of available
resolvers.
</bodyText>
<sectionHeader confidence="0.996448" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.88101075">
This work was partially supported by the
PASCAL-2 Network of Excellence of the Eu-
ropean Community FP7-ICT-2007-1-216886 and
the Israel Science Foundation grant 1112/08.
</bodyText>
<page confidence="0.991875">
1217
</page>
<sectionHeader confidence="0.98936" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999441150943396">
Azad Abad, Luisa Bentivogli, Ido Dagan, Danilo Gi-
ampiccolo, Shachar Mirkin, Emanuele Pianta, and
Asher Stern. 2010. A resource for investigating the
impact of anaphora and coreference on inference. In
Proceedings of LREC.
Rod Adams, Gabriel Nicolae, Cristina Nicolae, and
Sanda Harabagiu. 2007. Textual entailment through
extended lexical overlap and lexico-semantic match-
ing. In Proceedings of the ACL-PASCAL Workshop
on Textual Entailment and Paraphrasing.
E. Agichtein, W. Askew, and Y. Liu. 2008. Combining
lexical, syntactic, and semantic evidence for textual
entailment classification. In Proceedings of TAC.
Nicholas Asher and Alex Lascarides. 1998. Bridging.
Journal of Semantics, 15(1):83–113.
Alexandra Balahur, Elena Lloret, ´Oscar Ferr´andez,
Andr´es Montoyo, Manuel Palomar, and Rafael
Mu˜noz. 2008. The DLSIUAES team’s participation
in the TAC 2008 tracks. In Proceedings of TAC.
Roy Bar-Haim, Ido Dagan, Iddo Greental, and Eyal
Shnarch. 2007. Semantic inference at the lexical-
syntactic level. In Proceedings of AAAI.
Roy Bar-Haim, Jonathan Berant, Ido Dagan, Iddo
Greental, Shachar Mirkin, and Eyal Shnarch amd
Idan Szpektor. 2008. Efficient semantic deduc-
tion and approximate matching over compact parse
forests. In Proceedings of TAC.
Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo
Giampiccolo, and Bernardo Magnini. 2009a. The
fifth pascal recognizing textual entailment chal-
lenge. In Proceedings of TAC.
Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo
Giampiccolo, Medea Lo Leggio, and Bernardo
Magnini. 2009b. Considering discourse references
in textual entailment annotation. In Proceedings of
the 5th International Conference on Generative Ap-
proaches to the Lexicon (GL2009).
Johan Bos. 2005. Recognising textual entailment with
logical inference. In Proceedings of EMNLP.
Aljoscha Burchardt, Marco Pennacchiotti, Stefan
Thater, and Manfred Pinkal. 2009. Assessing
the impact of frame semantics on textual entail-
ment. Journal of Natural Language Engineering,
15(4):527–550.
Nathanael Chambers and Dan Jurafsky. 2009. Unsu-
pervised learning of narrative schemas and their par-
ticipants. In Proceedings of ACL-IJCNLP.
Nathanael Chambers, Daniel Cer, Trond Grenager,
David Hall, Chloe Kiddon, Bill MacCartney, Marie-
Catherine de Marneffe, Daniel Ramage, Eric Yeh,
and Christopher D. Manning. 2007. Learning align-
ments and leveraging natural logic. In Proceedings
of the ACL-PASCAL Workshop on Textual Entail-
ment and Paraphrasing.
Herbert H. Clark. 1975. Bridging. In R. C. Schank
and B. L. Nash-Webber, editors, Theoretical issues
in natural language processing, pages 169–174. As-
sociation of Computing Machinery.
Ido Dagan, Oren Glickman, and Bernardo Magnini.
2006. The PASCAL recognising textual entailment
challenge. In Machine Learning Challenges, vol-
ume 3944 of Lecture Notes in Computer Science,
pages 177–190. Springer.
Lorand Dali, Delia Rusu, Blaz Fortuna, Dunja
Mladenic, and Marko Grobelnik. 2009. Ques-
tion answering based on semantic graphs. In Pro-
ceedings of the Workshop on Semantic Search (Sem-
Search 2009).
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database (Language, Speech, and
Communication). The MIT Press.
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan,
and Bill Dolan. 2007. The third pascal recogniz-
ing textual entailment challenge. In Proceedings of
the ACL-PASCAL Workshop on Textual Entailment
and Paraphrasing.
Danilo Giampiccolo, Hoa Trang Dang, Bernardo
Magnini, Ido Dagan, and Bill Dolan. 2008. The
fourth pascal recognizing textual entailment chal-
lenge. In Proceedings of TAC.
Ralph Grishman and Beth Sundheim. 1996. Mes-
sage Understanding Conference-6: a brief history.
In Proceedings of the 16th conference on Computa-
tional Linguistics.
Sanda Harabagiu, Andrew Hickl, and Finley Lacatusu.
2007. Satisfying information needs with multi-
document summaries. Information Processing &amp;
Management, 43:1619–1642.
Stefan Harmeling. 2009. Inferring textual entailment
with a probabilistically sound calculus. Journal of
Natural Language Engineering, pages 459–477.
Marti A. Hearst. 1997. Segmenting text into multi-
paragraph subtopic passages. Computational Lin-
guistics, 23(1):33–64.
Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance
Ramshaw, and Ralph Weischedel. 2006. Ontonotes:
The 90% solution. In Proceedings of HLT-NAACL.
Jian Huang, Sarah M. Taylor, Jonathan L. Smith, Kon-
stantinos A. Fotiadis, and C. Lee Giles. 2009. Pro-
file based cross-document coreference using kernel-
ized fuzzy relational clustering. In Proceedings of
ACL-IJCNLP.
Fangtao Li, Yang Tang, Minlie Huang, and Xiaoyan
Zhu. 2009. Answering opinion questions with
random walks on graphs. In Proceedings of ACL-
IJCNLP.
</reference>
<page confidence="0.947055">
1218
</page>
<bodyText confidence="0.582032857142857">
Dekang Lin and Patrick Pantel. 2001. Discovery of in-
ference rules for question answering. Natural Lan-
guage Engineering, 4(7):343–360.
Dmitry Zelenko, Chinatsu Aone, and Jason Tibbetts.
2004. Coreference resolution for information ex-
traction. In Proceedings of the ACL Workshop on
Reference Resolution and its Applications.
</bodyText>
<reference confidence="0.999766306122449">
Dekang Lin. 1993. Principle-based parsing without
overgeneration. In Proceedings ofACL.
Bill MacCartney, Michel Galley, and Christopher D.
Manning. 2008. A phrase-based alignment model
for natural language inference. In Proceedings of
EMNLP.
Katja Markert, Malvina Nissim, and Natalia N. Mod-
jeska. 2003. Using the web for nominal anaphora
resolution. In Proceedings of EACL Workshop on
the Computational Treatment of Anaphora.
Seung-Hoon Na and Hwee Tou Ng. 2009. A 2-poisson
model for probabilistic coreference of named enti-
ties for improved text retrieval. In Proceedings of
SIGIR.
Rodney D. Nielsen, Wayne Ward, and James H. Mar-
tin. 2009. Recognizing entailment in intelligent
tutoring systems. Natural Language Engineering,
15(4):479–501.
Massimo Poesio, Rahul Mehta, Axel Maroudas, and
Janet Hitzeman. 2004. Learning to resolve bridging
references. In Proceedings of ACL.
Simone Paolo Ponzetto and Michael Strube. 2006.
Exploiting semantic role labeling, WordNet and
Wikipedia for coreference resolution. In Proceed-
ings of HLT.
Long Qiu, Min-Yen Kan, and Tat-Seng Chua. 2004. A
public reference implementation of the rap anaphora
resolution algorithm. In Proceedings of LREC.
Lorenza Romano, Milen Kouylekov, Idan Szpektor,
Ido Dagan, and Alberto Lavelli. 2006. Investigat-
ing a generic paraphrase-based approach for relation
extraction. In Proceedings of EACL.
Wee Meng Soon, Hwee Tou Ng, and Daniel
Chung Yong Lim. 2001. A machine learning ap-
proach to coreference resolution of noun phrases.
Computational Linguistics, 27(4):521–544.
Stephanie Strassel, Mark Przybocki, Kay Peterson,
Zhiyi Song, and Kazuaki Maeda. 2008. Linguistic
resources and evaluation techniques for evaluation
of cross-document automatic content extraction. In
Proceedings of LREC.
Jose L. Vicedo and Antonio Ferrndez. 2006. Coref-
erence in Q&amp;A. In Tomek Strzalkowski and
Sanda M. Harabagiu, editors, Advances in Open Do-
main Question Answering, pages 71–96. Springer.
Fabio Massimo Zanzotto, Marco Pennacchiotti, and
Alessandro Moschitti. 2009. A machine learning
approach to textual entailment recognition. Journal
of Natural Language Engineering, 15(4):551–582.
</reference>
<page confidence="0.994948">
1219
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.946589">
<title confidence="0.999335">Assessing the Role of Discourse References in Entailment Inference</title>
<author confidence="0.997652">Shachar Mirkin</author>
<author confidence="0.997652">Ido Dagan Sebastian Pad´o</author>
<affiliation confidence="0.999313">Bar-Ilan University University of Stuttgart</affiliation>
<address confidence="0.993996">Ramat-Gan, Israel Stuttgart, Germany</address>
<email confidence="0.999145">pado@ims.uni-stuttgart.de</email>
<abstract confidence="0.99629775">Discourse references, notably coreference and bridging, play an important role in many text understanding applications, but their impact on textual entailment is yet to be systematically understood. On the basis of an in-depth analysis of entailment instances, we argue that discourse references have the potential of substantially improving textual entailment recognition, and identify a number of research directions towards this goal.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Azad Abad</author>
<author>Luisa Bentivogli</author>
<author>Ido Dagan</author>
<author>Danilo Giampiccolo</author>
<author>Shachar Mirkin</author>
<author>Emanuele Pianta</author>
<author>Asher Stern</author>
</authors>
<title>A resource for investigating the impact of anaphora and coreference on inference.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="21009" citStr="Abad et al., 2010" startWordPosition="3352" endWordPosition="3355">egrating Discourse References into Entailment Recognition In initial analysis we found that the standard substitution operation applied by virtually all previous studies for integrating coreference into entailment is insufficient. We identified three distinct cases for the integration of discourse reference knowledge in entailment, which correspond to different relations between the target component, the focus term and the reference term. This section describes the three cases and characterizes them in terms of tree transformations. An initial version of these transformations is described in (Abad et al., 2010). We assume a transformation-based entailment architecture (cf. Section 2.2), although we believe that the key points of our account are also applicable to alignment-based architecture. Transformations create revised trees that cover previously uncovered target components in H. The output of each transformation, Ti, is comprised of copies of the components used to construct it, and is appended to the discourse forest, which includes the dependency trees of all sentences and their generated consequents. We assume that we have access to a dependency tree for H, a dependency forest for T and its </context>
</contexts>
<marker>Abad, Bentivogli, Dagan, Giampiccolo, Mirkin, Pianta, Stern, 2010</marker>
<rawString>Azad Abad, Luisa Bentivogli, Ido Dagan, Danilo Giampiccolo, Shachar Mirkin, Emanuele Pianta, and Asher Stern. 2010. A resource for investigating the impact of anaphora and coreference on inference. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rod Adams</author>
<author>Gabriel Nicolae</author>
<author>Cristina Nicolae</author>
<author>Sanda Harabagiu</author>
</authors>
<title>Textual entailment through extended lexical overlap and lexico-semantic matching.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</booktitle>
<contexts>
<context position="10166" citStr="Adams et al., 2007" startWordPosition="1579" endWordPosition="1582">bout he; the same is true for ‘Kennedy —* President Kennedy’ which involves a specialization that is only warranted in the specific discourse. A number of systems have tried to address the question of coreference in RTE as a preprocessing step prior to inference proper, with most systems using off-the-shelf coreference resolvers such as JavaRap (Qiu et al., 2004) or OpenNLP3. Generally, anaphoric expressions were textually replaced by their antecedents. Results were inconclusive, however, with several reports about errors introduced by automatic coreference resolution (Agichtein et al., 2008; Adams et al., 2007). Specific evaluations of the contribution of coreference resolution yielded both small negative (Bar-Haim et al., 2008) and insignificant positive (Chambers et al., 2007) results. 3 Motivation and Goals The results of recent studies, as reported in Section 2.2, seem to show that current resolution of discourse references in RTE systems hardly affects performance. However, our intuition is that these results can be attributed to four major limitations shared by these studies: (1) the datasets, where discourse phenomena were not well repre3http://opennlp.sourceforge.net sented; (2) the off-the-</context>
</contexts>
<marker>Adams, Nicolae, Nicolae, Harabagiu, 2007</marker>
<rawString>Rod Adams, Gabriel Nicolae, Cristina Nicolae, and Sanda Harabagiu. 2007. Textual entailment through extended lexical overlap and lexico-semantic matching. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Agichtein</author>
<author>W Askew</author>
<author>Y Liu</author>
</authors>
<title>Combining lexical, syntactic, and semantic evidence for textual entailment classification.</title>
<date>2008</date>
<booktitle>In Proceedings of TAC.</booktitle>
<contexts>
<context position="10145" citStr="Agichtein et al., 2008" startWordPosition="1575" endWordPosition="1578">hout further knowledge about he; the same is true for ‘Kennedy —* President Kennedy’ which involves a specialization that is only warranted in the specific discourse. A number of systems have tried to address the question of coreference in RTE as a preprocessing step prior to inference proper, with most systems using off-the-shelf coreference resolvers such as JavaRap (Qiu et al., 2004) or OpenNLP3. Generally, anaphoric expressions were textually replaced by their antecedents. Results were inconclusive, however, with several reports about errors introduced by automatic coreference resolution (Agichtein et al., 2008; Adams et al., 2007). Specific evaluations of the contribution of coreference resolution yielded both small negative (Bar-Haim et al., 2008) and insignificant positive (Chambers et al., 2007) results. 3 Motivation and Goals The results of recent studies, as reported in Section 2.2, seem to show that current resolution of discourse references in RTE systems hardly affects performance. However, our intuition is that these results can be attributed to four major limitations shared by these studies: (1) the datasets, where discourse phenomena were not well repre3http://opennlp.sourceforge.net sen</context>
<context position="15411" citStr="Agichtein et al., 2008" startWordPosition="2429" endWordPosition="2432">n the RTE-5 dataset, where the inference of H depends on reference information from the discourse sentences T0 / T00. Referring terms (in T) and target terms (in H) are shown in boldface. 4 Analysis Scheme For annotating the RTE-5 data, we operationalize reference relations that are relevant for entailment as those that improve coverage. Recall from Section 2.2 that the concept of coverage is applicable to both transformation and alignment models, all of which aim at maximizing coverage of H by T. We represent T and H as syntactic trees, as common in the RTE literature (Zanzotto et al., 2009; Agichtein et al., 2008). Specifically, we assume MINIPAR-style (Lin, 1993) dependency trees where nodes represent text expressions and edges represent the syntactic relations between them. We use “term” to refer to text expressions, and “components” to refer to nodes, edges, and subtrees. Dependency trees are a popular choice in RTE since they offer a fairly semantics-oriented account of the sentence structure that can still be constructed robustly. In an ideal case of entailment, all nodes and dependency edges of H are covered by T. For each T − H pair, we annotate all relevant discourse references in terms of thre</context>
</contexts>
<marker>Agichtein, Askew, Liu, 2008</marker>
<rawString>E. Agichtein, W. Askew, and Y. Liu. 2008. Combining lexical, syntactic, and semantic evidence for textual entailment classification. In Proceedings of TAC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
<author>Alex Lascarides</author>
</authors>
<date>1998</date>
<journal>Bridging. Journal of Semantics,</journal>
<volume>15</volume>
<issue>1</issue>
<contexts>
<context position="5473" citStr="Asher and Lascarides, 1998" startWordPosition="818" endWordPosition="821"> 1996) and the Automatic Content Extraction program (Strassel et al., 2008). The simplest form of information that discourse provides is coreference, i.e., information that two linguistic expressions refer to the same entity or event. Coreference is particularly important for processing pronouns and other anaphoric expressions, such as he in Example 1. Ability to resolve this reference translates directly into, e.g., a QA system’s ability to answer questions like Who killed Kennedy?. A second, more complex type of information stems from bridging references, such as in the following discourse (Asher and Lascarides, 1998): (2) “I’ve just arrived. The camel is outside.” While coreference indicates equivalence, bridging points to the existence of a salient semantic relation between two distinct entities or events. Here, it is (informally) ‘means of transport’, which would make the discourse (2) relevant for a question like How did I arrive here?. Other types of bridging relations include set-membership, roles in events and consequence (Clark, 1975). Note, however, that text understanding systems are generally limited to the resolution of entity (or even just pronoun) coreference, e.g. (Li et al., 2009; Dali et a</context>
</contexts>
<marker>Asher, Lascarides, 1998</marker>
<rawString>Nicholas Asher and Alex Lascarides. 1998. Bridging. Journal of Semantics, 15(1):83–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Balahur</author>
<author>Elena Lloret</author>
<author>´Oscar Ferr´andez</author>
<author>Andr´es Montoyo</author>
<author>Manuel Palomar</author>
<author>Rafael Mu˜noz</author>
</authors>
<title>tracks.</title>
<date>2008</date>
<booktitle>The DLSIUAES team’s participation in the TAC</booktitle>
<marker>Balahur, Lloret, Ferr´andez, Montoyo, Palomar, Mu˜noz, 2008</marker>
<rawString>Alexandra Balahur, Elena Lloret, ´Oscar Ferr´andez, Andr´es Montoyo, Manuel Palomar, and Rafael Mu˜noz. 2008. The DLSIUAES team’s participation in the TAC 2008 tracks. In Proceedings of TAC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Bar-Haim</author>
</authors>
<title>Ido Dagan, Iddo Greental, and Eyal Shnarch.</title>
<date>2007</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<marker>Bar-Haim, 2007</marker>
<rawString>Roy Bar-Haim, Ido Dagan, Iddo Greental, and Eyal Shnarch. 2007. Semantic inference at the lexicalsyntactic level. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Bar-Haim</author>
<author>Jonathan Berant</author>
</authors>
<title>Ido Dagan, Iddo Greental, Shachar Mirkin, and Eyal Shnarch amd Idan Szpektor.</title>
<date>2008</date>
<booktitle>In Proceedings of TAC.</booktitle>
<marker>Bar-Haim, Berant, 2008</marker>
<rawString>Roy Bar-Haim, Jonathan Berant, Ido Dagan, Iddo Greental, Shachar Mirkin, and Eyal Shnarch amd Idan Szpektor. 2008. Efficient semantic deduction and approximate matching over compact parse forests. In Proceedings of TAC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luisa Bentivogli</author>
<author>Ido Dagan</author>
<author>Hoa Trang Dang</author>
<author>Danilo Giampiccolo</author>
<author>Bernardo Magnini</author>
</authors>
<title>The fifth pascal recognizing textual entailment challenge.</title>
<date>2009</date>
<booktitle>In Proceedings of TAC.</booktitle>
<contexts>
<context position="2218" citStr="Bentivogli et al., 2009" startWordPosition="315" endWordPosition="318">responsible for why he2 killed Kennedys.” H: “Oswald killed President Kennedy.” The understanding that the second sentence of the text entails the hypothesis draws on two coreference relationships, namely that he is Oswald, and that the Kennedy in question is President Kennedy. However, the utilization of discourse information for such inferences has been so far limited mainly to the substitution of nominal coreferents, while many aspects of the interface between discourse and semantic inference needs remain unexplored. The recently held Fifth Recognizing Textual Entailment (RTE-5) challenge (Bentivogli et al., 2009a) has introduced a Search task, where the text sentences are interpreted in the context of their full discourse, as in Example 1 above. Accordingly, TE constitutes an interesting framework – and the Search task an adequate dataset – to study the interrelation between discourse and inference. The goal of this study is to analyze the roles of discourse references for textual entailment inference, to provide relevant findings and insights to developers of both reference resolvers and entailment systems and to highlight promising directions for the better incorporation of discourse phenomena into</context>
<context position="12532" citStr="Bentivogli et al., 2009" startWordPosition="1942" endWordPosition="1945">an impact on inference. To our knowledge, this is the first such in-depth study.4 The results of our study are of twofold interest. First, they provide guidance for the developers of reference resolvers who might prioritize the scope of their systems to make them more valuable for inference. Second, they point out potential directions for the developers of inference systems by specifying what additional inference mechanisms are needed to utilize discourse information. The RTE-5 Search dataset. We base our annotation on the Search task dataset, a new addition to the recent Fifth RTE challenge (Bentivogli et al., 2009a) that is motivated by the needs of NLP applications and drawn from the TAC summarization track. In the Search task, TE systems are required to find all individual sentences in a given corpus which entail the hypothesis – a setting that is sensible not only for summarization, but also for information access tasks like QA. Sentences are judged individually, but “are to be interpreted in the context of the corpus as they rely on explicit and implicit references to entities, events, dates, places, etc., mentioned elsewhere in the corpus” (Bentivogli et al., 2009b). 4The guidelines and the datase</context>
</contexts>
<marker>Bentivogli, Dagan, Dang, Giampiccolo, Magnini, 2009</marker>
<rawString>Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo Giampiccolo, and Bernardo Magnini. 2009a. The fifth pascal recognizing textual entailment challenge. In Proceedings of TAC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luisa Bentivogli</author>
<author>Ido Dagan</author>
</authors>
<title>Hoa Trang Dang, Danilo Giampiccolo,</title>
<date>2009</date>
<booktitle>In Proceedings of the 5th International Conference on Generative Approaches to the Lexicon (GL2009).</booktitle>
<location>Medea</location>
<marker>Bentivogli, Dagan, 2009</marker>
<rawString>Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo Giampiccolo, Medea Lo Leggio, and Bernardo Magnini. 2009b. Considering discourse references in textual entailment annotation. In Proceedings of the 5th International Conference on Generative Approaches to the Lexicon (GL2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
</authors>
<title>Recognising textual entailment with logical inference.</title>
<date>2005</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="8701" citStr="Bos, 2005" startWordPosition="1347" endWordPosition="1348">ther by directly applying them as transformations, or by using them 1Some studies, e.g. (Markert et al., 2003; Poesio et al., 2004), address the resolution of a few specific kinds of bridging relations; yet, wide-scope systems for bridging resolution are unavailable. 2Clearly, the details of how the final entailment decision is made based on the attained coverage differ substantially among models. 1210 to score alignments. Rules are generally drawn from external knowledge resources, such as WordNet (Fellbaum, 1998) or DIRT (Lin and Pantel, 2001), although knowledge gaps remain a key obstacle (Bos, 2005; Balahur et al., 2008; Bar-Haim et al., 2008). Discourse in previous RTE challenges. The first two rounds of the RTE challenge used “selfcontained” texts and hypotheses, where discourse considerations played virtually no role. A first step towards a more comprehensive notion of entailment was taken with RTE-3 (Giampiccolo et al., 2007), when paragraph-length texts were first included and constituted 17% of the texts in the test set. Chambers et al. (2007) report that in a sample of T − H pairs drawn from the development set, 25% involved discourse references. Using the concepts introduced abo</context>
</contexts>
<marker>Bos, 2005</marker>
<rawString>Johan Bos. 2005. Recognising textual entailment with logical inference. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Marco Pennacchiotti</author>
<author>Stefan Thater</author>
<author>Manfred Pinkal</author>
</authors>
<title>Assessing the impact of frame semantics on textual entailment.</title>
<date>2009</date>
<journal>Journal of Natural Language Engineering,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="7456" citStr="Burchardt et al., 2009" startWordPosition="1134" endWordPosition="1137">to determine the entailment relation T ==&gt;. H by finding a “proof”, i.e., a sequence of consequents, (T, T1, ... , Tn), such that Tn=H (Bar-Haim et al., 2008; Harmeling, 2009), and that in each transformation, Ti —* Ti+1, the consequent Ti+1 is entailed by Ti. These transformations commonly include lexical modifications and the generation of syntactic alternatives. The second major approach constructs an alignment between the linguistic entities of the trees (or graphs) of T and H, which can represent syntactic structure, semantic structure, or non-hierarchical phrases (Zanzotto et al., 2009; Burchardt et al., 2009; MacCartney et al., 2008). H is assumed to be entailed by T if its entities are aligned “well” to corresponding entities in T. Alignment quality is generally determined based on features that assess the validity of the local replacement of the T entity by the H entity. While transformation- and alignment-based entailment models look different at first glance, they ultimately have the same goal, namely obtaining a maximal coverage of H by T, i.e. to identify matches of as many elements of H within T as possible.2 To do so, both architectures typically make use of inference rules such as ‘Y was</context>
</contexts>
<marker>Burchardt, Pennacchiotti, Thater, Pinkal, 2009</marker>
<rawString>Aljoscha Burchardt, Marco Pennacchiotti, Stefan Thater, and Manfred Pinkal. 2009. Assessing the impact of frame semantics on textual entailment. Journal of Natural Language Engineering, 15(4):527–550.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Unsupervised learning of narrative schemas and their participants.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP.</booktitle>
<contexts>
<context position="4720" citStr="Chambers and Jurafsky, 2009" startWordPosition="702" endWordPosition="705">ons. Conclusions are discussed in Section 7. 2.2 Discourse in Textual Entailment 2 Background 2.1 Discourse in NLP Discourse information plays a role in a range of NLP tasks. It is obviously central to discourse processing tasks such as text segmentation (Hearst, 1997). Reference information provided by discourse is also useful for text understanding tasks such as question answering (QA), information extraction (IE) and information retrieval (IR) (Vicedo and Ferrndez, 2006; Zelenko et al., 2004; Na and Ng, 2009), as well as for the acquisition of lexical-semantic “narrative schema” knowledge (Chambers and Jurafsky, 2009). Discourse references have been the subject of attention in both the Message Understanding Conference (Grishman and Sundheim, 1996) and the Automatic Content Extraction program (Strassel et al., 2008). The simplest form of information that discourse provides is coreference, i.e., information that two linguistic expressions refer to the same entity or event. Coreference is particularly important for processing pronouns and other anaphoric expressions, such as he in Example 1. Ability to resolve this reference translates directly into, e.g., a QA system’s ability to answer questions like Who ki</context>
</contexts>
<marker>Chambers, Jurafsky, 2009</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2009. Unsupervised learning of narrative schemas and their participants. In Proceedings of ACL-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Daniel Cer</author>
<author>Trond Grenager</author>
<author>David Hall</author>
<author>Chloe Kiddon</author>
<author>Bill MacCartney</author>
<author>MarieCatherine de Marneffe</author>
<author>Daniel Ramage</author>
<author>Eric Yeh</author>
<author>Christopher D Manning</author>
</authors>
<title>Learning alignments and leveraging natural logic.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</booktitle>
<marker>Chambers, Cer, Grenager, Hall, Kiddon, MacCartney, de Marneffe, Ramage, Yeh, Manning, 2007</marker>
<rawString>Nathanael Chambers, Daniel Cer, Trond Grenager, David Hall, Chloe Kiddon, Bill MacCartney, MarieCatherine de Marneffe, Daniel Ramage, Eric Yeh, and Christopher D. Manning. 2007. Learning alignments and leveraging natural logic. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
</authors>
<date>1975</date>
<journal>Association of Computing Machinery.</journal>
<booktitle>Theoretical issues in natural language processing,</booktitle>
<pages>169--174</pages>
<editor>Bridging. In R. C. Schank and B. L. Nash-Webber, editors,</editor>
<contexts>
<context position="5906" citStr="Clark, 1975" startWordPosition="887" endWordPosition="888">swer questions like Who killed Kennedy?. A second, more complex type of information stems from bridging references, such as in the following discourse (Asher and Lascarides, 1998): (2) “I’ve just arrived. The camel is outside.” While coreference indicates equivalence, bridging points to the existence of a salient semantic relation between two distinct entities or events. Here, it is (informally) ‘means of transport’, which would make the discourse (2) relevant for a question like How did I arrive here?. Other types of bridging relations include set-membership, roles in events and consequence (Clark, 1975). Note, however, that text understanding systems are generally limited to the resolution of entity (or even just pronoun) coreference, e.g. (Li et al., 2009; Dali et al., 2009). An important reason is the unavailability of tools to resolve the more complex (and difficult) forms of discourse reference such as Textual Entailment has been introduced in Section 1 as a common-sense notion of inference. It has spawned interest in the computational linguistics community as a common denominator of many NLP tasks including IE, summarization and tutoring (Romano et al., 2006; Harabagiu et al., 2007; Nie</context>
<context position="23030" citStr="Clark, 1975" startWordPosition="3683" endWordPosition="3684">in the text (the reference term) can cover all missing information (the 1213 Figure 1: The Substitution transformation, demonstrated on the relevant subtrees of Example (i). The dashed line denotes a discourse reference. target component) on its own. In such cases, the reference term can replace the entire focus term. Apparently (cf. Section 6), substitution applies also to some types of bridging relations, such as set-membership, when the member is sufficient for representing the entire set for the necessary inference. For example, in “I met two people yesterday. The woman told me a story.” (Clark, 1975), substituting two people with woman results in a text which is entailed from the discourse, and which allows inferring “I met a woman yesterday.” In a parse tree representation, given a coreference relation Qx, y) (or Br(x, y)), the newly generated tree, Ti, consists of a copy of T, where the entire tree Sx is replaced by a copy of Sy . In Figure 1, which shows Example (i) from Table 1, such unions is substituted by homosexual marriages. Head-substitution. Occasionally, substituting only the head of the focus term is sufficient. In such cases, only the root nodes x and y are substituted. This</context>
<context position="28625" citStr="Clark, 1975" startWordPosition="4653" endWordPosition="4654">Srz headed by in (z) into T1 and connecting it to accident (x) as a modifier (labr). The subtree Srz consists of a variable node which is connected to in with a pcomp-n dependency (a nominal head of a prepositional phrase), and which is instantiated with the node China (y) when the transformation is applied. Note that the structure of Sr z and the way it is inserted into T1 are predefined by the abovementioned interface; only the node to which it is attached and the contents of the variable node are determined at transformation-time. As another example, consider the following short text from (Clark, 1975): John was murdered yesterday. The knife lay nearby. Here, the bridging relation between the murder event and the instrument, the knife (x), can be addressed by inserting under x a subtree for the clause with which as Srz, with a variable which is instantiated by the parse-tree (headed by murdered, y) of the entire first sentence John was murdered yesterday. Transformation chaining. Since our transformations are defined to be minimal, some cases require the application of multiple transformations to achieve coverage. Consider Example (v), Table 1. We wish to cover AS-28 mini submarine in H fro</context>
</contexts>
<marker>Clark, 1975</marker>
<rawString>Herbert H. Clark. 1975. Bridging. In R. C. Schank and B. L. Nash-Webber, editors, Theoretical issues in natural language processing, pages 169–174. Association of Computing Machinery.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
<author>Bernardo Magnini</author>
</authors>
<title>The PASCAL recognising textual entailment challenge.</title>
<date>2006</date>
<booktitle>In Machine Learning Challenges,</booktitle>
<volume>3944</volume>
<pages>177--190</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1382" citStr="Dagan et al., 2006" startWordPosition="190" endWordPosition="193">h as coreference and bridging anaphora play an important role in text understanding applications, like question answering and information extraction. There, reference resolution is used for the purpose of combining knowledge from multiple sentences. Such knowledge is also important for Textual Entailment (TE), a generic framework for modeling semantic inference. TE reduces the inference requirements of many text understanding applications to the problem of determining whether the meaning of a given textual assertion, termed hypothesis (H), can be inferred from the meaning of certain text (T) (Dagan et al., 2006). Consider the following example: (1) T: “Not only had he developed an aversion to the Presidents and politics in general, Oswald2 was also a failure with Marina, his wife. [...] Their relationship was supposedly responsible for why he2 killed Kennedys.” H: “Oswald killed President Kennedy.” The understanding that the second sentence of the text entails the hypothesis draws on two coreference relationships, namely that he is Oswald, and that the Kennedy in question is President Kennedy. However, the utilization of discourse information for such inferences has been so far limited mainly to the </context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2006</marker>
<rawString>Ido Dagan, Oren Glickman, and Bernardo Magnini. 2006. The PASCAL recognising textual entailment challenge. In Machine Learning Challenges, volume 3944 of Lecture Notes in Computer Science, pages 177–190. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lorand Dali</author>
<author>Delia Rusu</author>
<author>Blaz Fortuna</author>
<author>Dunja Mladenic</author>
<author>Marko Grobelnik</author>
</authors>
<title>Question answering based on semantic graphs.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Semantic Search (SemSearch</booktitle>
<contexts>
<context position="6082" citStr="Dali et al., 2009" startWordPosition="913" endWordPosition="916">es, 1998): (2) “I’ve just arrived. The camel is outside.” While coreference indicates equivalence, bridging points to the existence of a salient semantic relation between two distinct entities or events. Here, it is (informally) ‘means of transport’, which would make the discourse (2) relevant for a question like How did I arrive here?. Other types of bridging relations include set-membership, roles in events and consequence (Clark, 1975). Note, however, that text understanding systems are generally limited to the resolution of entity (or even just pronoun) coreference, e.g. (Li et al., 2009; Dali et al., 2009). An important reason is the unavailability of tools to resolve the more complex (and difficult) forms of discourse reference such as Textual Entailment has been introduced in Section 1 as a common-sense notion of inference. It has spawned interest in the computational linguistics community as a common denominator of many NLP tasks including IE, summarization and tutoring (Romano et al., 2006; Harabagiu et al., 2007; Nielsen et al., 2009). Architectures for Textual Entailment. Over the course of recent RTE challenges (Giampiccolo et al., 2007; Giampiccolo et al., 2008), the main benchmark for </context>
</contexts>
<marker>Dali, Rusu, Fortuna, Mladenic, Grobelnik, 2009</marker>
<rawString>Lorand Dali, Delia Rusu, Blaz Fortuna, Dunja Mladenic, and Marko Grobelnik. 2009. Question answering based on semantic graphs. In Proceedings of the Workshop on Semantic Search (SemSearch 2009).</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database (Language, Speech, and Communication).</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>The MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database (Language, Speech, and Communication). The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Giampiccolo</author>
<author>Bernardo Magnini</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
</authors>
<title>The third pascal recognizing textual entailment challenge.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</booktitle>
<contexts>
<context position="6630" citStr="Giampiccolo et al., 2007" startWordPosition="999" endWordPosition="1003">or even just pronoun) coreference, e.g. (Li et al., 2009; Dali et al., 2009). An important reason is the unavailability of tools to resolve the more complex (and difficult) forms of discourse reference such as Textual Entailment has been introduced in Section 1 as a common-sense notion of inference. It has spawned interest in the computational linguistics community as a common denominator of many NLP tasks including IE, summarization and tutoring (Romano et al., 2006; Harabagiu et al., 2007; Nielsen et al., 2009). Architectures for Textual Entailment. Over the course of recent RTE challenges (Giampiccolo et al., 2007; Giampiccolo et al., 2008), the main benchmark for TE technology, two architectures for modeling TE have emerged as dominant: transformations and alignment. The goal of transformation-based TE models is to determine the entailment relation T ==&gt;. H by finding a “proof”, i.e., a sequence of consequents, (T, T1, ... , Tn), such that Tn=H (Bar-Haim et al., 2008; Harmeling, 2009), and that in each transformation, Ti —* Ti+1, the consequent Ti+1 is entailed by Ti. These transformations commonly include lexical modifications and the generation of syntactic alternatives. The second major approach co</context>
<context position="9039" citStr="Giampiccolo et al., 2007" startWordPosition="1398" endWordPosition="1401">sion is made based on the attained coverage differ substantially among models. 1210 to score alignments. Rules are generally drawn from external knowledge resources, such as WordNet (Fellbaum, 1998) or DIRT (Lin and Pantel, 2001), although knowledge gaps remain a key obstacle (Bos, 2005; Balahur et al., 2008; Bar-Haim et al., 2008). Discourse in previous RTE challenges. The first two rounds of the RTE challenge used “selfcontained” texts and hypotheses, where discourse considerations played virtually no role. A first step towards a more comprehensive notion of entailment was taken with RTE-3 (Giampiccolo et al., 2007), when paragraph-length texts were first included and constituted 17% of the texts in the test set. Chambers et al. (2007) report that in a sample of T − H pairs drawn from the development set, 25% involved discourse references. Using the concepts introduced above, the impact of discourse references can be generally described as a coverage problem, independent of the system’s architecture. In Example 1, the hypothesis word Oswald cannot be safely linked to the text pronoun he without further knowledge about he; the same is true for ‘Kennedy —* President Kennedy’ which involves a specialization</context>
</contexts>
<marker>Giampiccolo, Magnini, Dagan, Dolan, 2007</marker>
<rawString>Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. 2007. The third pascal recognizing textual entailment challenge. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Giampiccolo</author>
<author>Hoa Trang Dang</author>
<author>Bernardo Magnini</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
</authors>
<title>The fourth pascal recognizing textual entailment challenge.</title>
<date>2008</date>
<booktitle>In Proceedings of TAC.</booktitle>
<contexts>
<context position="6657" citStr="Giampiccolo et al., 2008" startWordPosition="1004" endWordPosition="1007">ference, e.g. (Li et al., 2009; Dali et al., 2009). An important reason is the unavailability of tools to resolve the more complex (and difficult) forms of discourse reference such as Textual Entailment has been introduced in Section 1 as a common-sense notion of inference. It has spawned interest in the computational linguistics community as a common denominator of many NLP tasks including IE, summarization and tutoring (Romano et al., 2006; Harabagiu et al., 2007; Nielsen et al., 2009). Architectures for Textual Entailment. Over the course of recent RTE challenges (Giampiccolo et al., 2007; Giampiccolo et al., 2008), the main benchmark for TE technology, two architectures for modeling TE have emerged as dominant: transformations and alignment. The goal of transformation-based TE models is to determine the entailment relation T ==&gt;. H by finding a “proof”, i.e., a sequence of consequents, (T, T1, ... , Tn), such that Tn=H (Bar-Haim et al., 2008; Harmeling, 2009), and that in each transformation, Ti —* Ti+1, the consequent Ti+1 is entailed by Ti. These transformations commonly include lexical modifications and the generation of syntactic alternatives. The second major approach constructs an alignment betwe</context>
</contexts>
<marker>Giampiccolo, Dang, Magnini, Dagan, Dolan, 2008</marker>
<rawString>Danilo Giampiccolo, Hoa Trang Dang, Bernardo Magnini, Ido Dagan, and Bill Dolan. 2008. The fourth pascal recognizing textual entailment challenge. In Proceedings of TAC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
<author>Beth Sundheim</author>
</authors>
<title>Message Understanding Conference-6: a brief history.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th conference on Computational Linguistics.</booktitle>
<contexts>
<context position="4852" citStr="Grishman and Sundheim, 1996" startWordPosition="723" endWordPosition="726">tion plays a role in a range of NLP tasks. It is obviously central to discourse processing tasks such as text segmentation (Hearst, 1997). Reference information provided by discourse is also useful for text understanding tasks such as question answering (QA), information extraction (IE) and information retrieval (IR) (Vicedo and Ferrndez, 2006; Zelenko et al., 2004; Na and Ng, 2009), as well as for the acquisition of lexical-semantic “narrative schema” knowledge (Chambers and Jurafsky, 2009). Discourse references have been the subject of attention in both the Message Understanding Conference (Grishman and Sundheim, 1996) and the Automatic Content Extraction program (Strassel et al., 2008). The simplest form of information that discourse provides is coreference, i.e., information that two linguistic expressions refer to the same entity or event. Coreference is particularly important for processing pronouns and other anaphoric expressions, such as he in Example 1. Ability to resolve this reference translates directly into, e.g., a QA system’s ability to answer questions like Who killed Kennedy?. A second, more complex type of information stems from bridging references, such as in the following discourse (Asher </context>
</contexts>
<marker>Grishman, Sundheim, 1996</marker>
<rawString>Ralph Grishman and Beth Sundheim. 1996. Message Understanding Conference-6: a brief history. In Proceedings of the 16th conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda Harabagiu</author>
<author>Andrew Hickl</author>
<author>Finley Lacatusu</author>
</authors>
<title>Satisfying information needs with multidocument summaries.</title>
<date>2007</date>
<booktitle>Information Processing &amp; Management,</booktitle>
<pages>43--1619</pages>
<contexts>
<context position="6501" citStr="Harabagiu et al., 2007" startWordPosition="980" endWordPosition="983">d consequence (Clark, 1975). Note, however, that text understanding systems are generally limited to the resolution of entity (or even just pronoun) coreference, e.g. (Li et al., 2009; Dali et al., 2009). An important reason is the unavailability of tools to resolve the more complex (and difficult) forms of discourse reference such as Textual Entailment has been introduced in Section 1 as a common-sense notion of inference. It has spawned interest in the computational linguistics community as a common denominator of many NLP tasks including IE, summarization and tutoring (Romano et al., 2006; Harabagiu et al., 2007; Nielsen et al., 2009). Architectures for Textual Entailment. Over the course of recent RTE challenges (Giampiccolo et al., 2007; Giampiccolo et al., 2008), the main benchmark for TE technology, two architectures for modeling TE have emerged as dominant: transformations and alignment. The goal of transformation-based TE models is to determine the entailment relation T ==&gt;. H by finding a “proof”, i.e., a sequence of consequents, (T, T1, ... , Tn), such that Tn=H (Bar-Haim et al., 2008; Harmeling, 2009), and that in each transformation, Ti —* Ti+1, the consequent Ti+1 is entailed by Ti. These </context>
</contexts>
<marker>Harabagiu, Hickl, Lacatusu, 2007</marker>
<rawString>Sanda Harabagiu, Andrew Hickl, and Finley Lacatusu. 2007. Satisfying information needs with multidocument summaries. Information Processing &amp; Management, 43:1619–1642.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Harmeling</author>
</authors>
<title>Inferring textual entailment with a probabilistically sound calculus.</title>
<date>2009</date>
<journal>Journal of Natural Language Engineering,</journal>
<pages>459--477</pages>
<contexts>
<context position="7009" citStr="Harmeling, 2009" startWordPosition="1066" endWordPosition="1067">ator of many NLP tasks including IE, summarization and tutoring (Romano et al., 2006; Harabagiu et al., 2007; Nielsen et al., 2009). Architectures for Textual Entailment. Over the course of recent RTE challenges (Giampiccolo et al., 2007; Giampiccolo et al., 2008), the main benchmark for TE technology, two architectures for modeling TE have emerged as dominant: transformations and alignment. The goal of transformation-based TE models is to determine the entailment relation T ==&gt;. H by finding a “proof”, i.e., a sequence of consequents, (T, T1, ... , Tn), such that Tn=H (Bar-Haim et al., 2008; Harmeling, 2009), and that in each transformation, Ti —* Ti+1, the consequent Ti+1 is entailed by Ti. These transformations commonly include lexical modifications and the generation of syntactic alternatives. The second major approach constructs an alignment between the linguistic entities of the trees (or graphs) of T and H, which can represent syntactic structure, semantic structure, or non-hierarchical phrases (Zanzotto et al., 2009; Burchardt et al., 2009; MacCartney et al., 2008). H is assumed to be entailed by T if its entities are aligned “well” to corresponding entities in T. Alignment quality is gene</context>
</contexts>
<marker>Harmeling, 2009</marker>
<rawString>Stefan Harmeling. 2009. Inferring textual entailment with a probabilistically sound calculus. Journal of Natural Language Engineering, pages 459–477.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Segmenting text into multiparagraph subtopic passages.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>1</issue>
<contexts>
<context position="4361" citStr="Hearst, 1997" startWordPosition="650" endWordPosition="651">al Meeting of the Association for Computational Linguistics, pages 1209–1219, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics event coreference and bridging.1 Another reason is uncertainty about their practical importance. mechanisms (Section 5). Section 6 presents quantitative findings and further observations. Conclusions are discussed in Section 7. 2.2 Discourse in Textual Entailment 2 Background 2.1 Discourse in NLP Discourse information plays a role in a range of NLP tasks. It is obviously central to discourse processing tasks such as text segmentation (Hearst, 1997). Reference information provided by discourse is also useful for text understanding tasks such as question answering (QA), information extraction (IE) and information retrieval (IR) (Vicedo and Ferrndez, 2006; Zelenko et al., 2004; Na and Ng, 2009), as well as for the acquisition of lexical-semantic “narrative schema” knowledge (Chambers and Jurafsky, 2009). Discourse references have been the subject of attention in both the Message Understanding Conference (Grishman and Sundheim, 1996) and the Automatic Content Extraction program (Strassel et al., 2008). The simplest form of information that </context>
</contexts>
<marker>Hearst, 1997</marker>
<rawString>Marti A. Hearst. 1997. Segmenting text into multiparagraph subtopic passages. Computational Linguistics, 23(1):33–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Lance Ramshaw</author>
<author>Ralph Weischedel</author>
</authors>
<title>Ontonotes: The 90% solution.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="11642" citStr="Hovy et al., 2006" startWordPosition="1805" endWordPosition="1808">course references on entailment with an annotation study which removes these limitations. To counteract (1), we use the recent RTE-5 Search dataset (details below). To avoid (2), we perform a manual analysis, assuming discourse references as predicted by an oracle. With regards to (3), our annotation scheme covers coreference and bridging relations of all syntactic categories and classifies them. As for (4), we suggest several operations necessary to integrate the discourse information into an entailment engine. In contrast to the numerous existing datasets annotated for discourse references (Hovy et al., 2006; Strassel et al., 2008), we do not annotate exhaustively. Rather, we are interested specifically in those references instances that impact inference. Furthermore, we analyze each instance from an entailment perspective, characterizing the relevant factors that have an impact on inference. To our knowledge, this is the first such in-depth study.4 The results of our study are of twofold interest. First, they provide guidance for the developers of reference resolvers who might prioritize the scope of their systems to make them more valuable for inference. Second, they point out potential directi</context>
</contexts>
<marker>Hovy, Marcus, Palmer, Ramshaw, Weischedel, 2006</marker>
<rawString>Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2006. Ontonotes: The 90% solution. In Proceedings of HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian Huang</author>
<author>Sarah M Taylor</author>
<author>Jonathan L Smith</author>
<author>Konstantinos A Fotiadis</author>
<author>C Lee Giles</author>
</authors>
<title>Profile based cross-document coreference using kernelized fuzzy relational clustering.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP.</booktitle>
<contexts>
<context position="33281" citStr="Huang et al., 2009" startWordPosition="5386" endWordPosition="5389">quarter of the focus terms, we 6The lower proportion of VPs among reference terms stems from bridging relations between VPs and nominal dependents, such as the abovementioned “location” relation. had to go to other documents to find reference terms that, possibly in conjunction with the focus term, could cover the target components. Interestingly, all such cases involved coreference (about equally divided between the merge transformations and substitutions), while bridging was always “document-local”. This result reaffirms the usefulness of cross-document coreference resolution for inference (Huang et al., 2009). Discourse resolution as preprocessing? In existing RTE systems, discourse references are typically resolved as a preprocessing step. While our annotation was manual and cannot yield direct results about processing considerations, we observed that discourse relations often hold between complex, and deeply embedded, expressions, which makes their automatic resolution difficult. Of course, many RTE systems attempt to normalize and simplify H and T, e.g., by splitting conjunctions or removing irrelevant clauses, but these operations are usually considered a part of the inference rather the prepr</context>
</contexts>
<marker>Huang, Taylor, Smith, Fotiadis, Giles, 2009</marker>
<rawString>Jian Huang, Sarah M. Taylor, Jonathan L. Smith, Konstantinos A. Fotiadis, and C. Lee Giles. 2009. Profile based cross-document coreference using kernelized fuzzy relational clustering. In Proceedings of ACL-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
<author>Yang Tang</author>
<author>Minlie Huang</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Answering opinion questions with random walks on graphs.</title>
<date>2009</date>
<booktitle>In Proceedings of ACLIJCNLP.</booktitle>
<contexts>
<context position="6062" citStr="Li et al., 2009" startWordPosition="909" endWordPosition="912">sher and Lascarides, 1998): (2) “I’ve just arrived. The camel is outside.” While coreference indicates equivalence, bridging points to the existence of a salient semantic relation between two distinct entities or events. Here, it is (informally) ‘means of transport’, which would make the discourse (2) relevant for a question like How did I arrive here?. Other types of bridging relations include set-membership, roles in events and consequence (Clark, 1975). Note, however, that text understanding systems are generally limited to the resolution of entity (or even just pronoun) coreference, e.g. (Li et al., 2009; Dali et al., 2009). An important reason is the unavailability of tools to resolve the more complex (and difficult) forms of discourse reference such as Textual Entailment has been introduced in Section 1 as a common-sense notion of inference. It has spawned interest in the computational linguistics community as a common denominator of many NLP tasks including IE, summarization and tutoring (Romano et al., 2006; Harabagiu et al., 2007; Nielsen et al., 2009). Architectures for Textual Entailment. Over the course of recent RTE challenges (Giampiccolo et al., 2007; Giampiccolo et al., 2008), the</context>
</contexts>
<marker>Li, Tang, Huang, Zhu, 2009</marker>
<rawString>Fangtao Li, Yang Tang, Minlie Huang, and Xiaoyan Zhu. 2009. Answering opinion questions with random walks on graphs. In Proceedings of ACLIJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Principle-based parsing without overgeneration.</title>
<date>1993</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="15462" citStr="Lin, 1993" startWordPosition="2437" endWordPosition="2438">ce information from the discourse sentences T0 / T00. Referring terms (in T) and target terms (in H) are shown in boldface. 4 Analysis Scheme For annotating the RTE-5 data, we operationalize reference relations that are relevant for entailment as those that improve coverage. Recall from Section 2.2 that the concept of coverage is applicable to both transformation and alignment models, all of which aim at maximizing coverage of H by T. We represent T and H as syntactic trees, as common in the RTE literature (Zanzotto et al., 2009; Agichtein et al., 2008). Specifically, we assume MINIPAR-style (Lin, 1993) dependency trees where nodes represent text expressions and edges represent the syntactic relations between them. We use “term” to refer to text expressions, and “components” to refer to nodes, edges, and subtrees. Dependency trees are a popular choice in RTE since they offer a fairly semantics-oriented account of the sentence structure that can still be constructed robustly. In an ideal case of entailment, all nodes and dependency edges of H are covered by T. For each T − H pair, we annotate all relevant discourse references in terms of three items: the target component in H, the focus term </context>
</contexts>
<marker>Lin, 1993</marker>
<rawString>Dekang Lin. 1993. Principle-based parsing without overgeneration. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill MacCartney</author>
<author>Michel Galley</author>
<author>Christopher D Manning</author>
</authors>
<title>A phrase-based alignment model for natural language inference.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="7482" citStr="MacCartney et al., 2008" startWordPosition="1138" endWordPosition="1141">ent relation T ==&gt;. H by finding a “proof”, i.e., a sequence of consequents, (T, T1, ... , Tn), such that Tn=H (Bar-Haim et al., 2008; Harmeling, 2009), and that in each transformation, Ti —* Ti+1, the consequent Ti+1 is entailed by Ti. These transformations commonly include lexical modifications and the generation of syntactic alternatives. The second major approach constructs an alignment between the linguistic entities of the trees (or graphs) of T and H, which can represent syntactic structure, semantic structure, or non-hierarchical phrases (Zanzotto et al., 2009; Burchardt et al., 2009; MacCartney et al., 2008). H is assumed to be entailed by T if its entities are aligned “well” to corresponding entities in T. Alignment quality is generally determined based on features that assess the validity of the local replacement of the T entity by the H entity. While transformation- and alignment-based entailment models look different at first glance, they ultimately have the same goal, namely obtaining a maximal coverage of H by T, i.e. to identify matches of as many elements of H within T as possible.2 To do so, both architectures typically make use of inference rules such as ‘Y was purchased by X —* X paid </context>
</contexts>
<marker>MacCartney, Galley, Manning, 2008</marker>
<rawString>Bill MacCartney, Michel Galley, and Christopher D. Manning. 2008. A phrase-based alignment model for natural language inference. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Markert</author>
<author>Malvina Nissim</author>
<author>Natalia N Modjeska</author>
</authors>
<title>Using the web for nominal anaphora resolution.</title>
<date>2003</date>
<booktitle>In Proceedings of EACL Workshop on the Computational Treatment of Anaphora.</booktitle>
<contexts>
<context position="8201" citStr="Markert et al., 2003" startWordPosition="1267" endWordPosition="1270">T. Alignment quality is generally determined based on features that assess the validity of the local replacement of the T entity by the H entity. While transformation- and alignment-based entailment models look different at first glance, they ultimately have the same goal, namely obtaining a maximal coverage of H by T, i.e. to identify matches of as many elements of H within T as possible.2 To do so, both architectures typically make use of inference rules such as ‘Y was purchased by X —* X paid for Y’, either by directly applying them as transformations, or by using them 1Some studies, e.g. (Markert et al., 2003; Poesio et al., 2004), address the resolution of a few specific kinds of bridging relations; yet, wide-scope systems for bridging resolution are unavailable. 2Clearly, the details of how the final entailment decision is made based on the attained coverage differ substantially among models. 1210 to score alignments. Rules are generally drawn from external knowledge resources, such as WordNet (Fellbaum, 1998) or DIRT (Lin and Pantel, 2001), although knowledge gaps remain a key obstacle (Bos, 2005; Balahur et al., 2008; Bar-Haim et al., 2008). Discourse in previous RTE challenges. The first two </context>
</contexts>
<marker>Markert, Nissim, Modjeska, 2003</marker>
<rawString>Katja Markert, Malvina Nissim, and Natalia N. Modjeska. 2003. Using the web for nominal anaphora resolution. In Proceedings of EACL Workshop on the Computational Treatment of Anaphora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seung-Hoon Na</author>
<author>Hwee Tou Ng</author>
</authors>
<title>A 2-poisson model for probabilistic coreference of named entities for improved text retrieval.</title>
<date>2009</date>
<booktitle>In Proceedings of SIGIR.</booktitle>
<contexts>
<context position="4609" citStr="Na and Ng, 2009" startWordPosition="687" endWordPosition="690"> importance. mechanisms (Section 5). Section 6 presents quantitative findings and further observations. Conclusions are discussed in Section 7. 2.2 Discourse in Textual Entailment 2 Background 2.1 Discourse in NLP Discourse information plays a role in a range of NLP tasks. It is obviously central to discourse processing tasks such as text segmentation (Hearst, 1997). Reference information provided by discourse is also useful for text understanding tasks such as question answering (QA), information extraction (IE) and information retrieval (IR) (Vicedo and Ferrndez, 2006; Zelenko et al., 2004; Na and Ng, 2009), as well as for the acquisition of lexical-semantic “narrative schema” knowledge (Chambers and Jurafsky, 2009). Discourse references have been the subject of attention in both the Message Understanding Conference (Grishman and Sundheim, 1996) and the Automatic Content Extraction program (Strassel et al., 2008). The simplest form of information that discourse provides is coreference, i.e., information that two linguistic expressions refer to the same entity or event. Coreference is particularly important for processing pronouns and other anaphoric expressions, such as he in Example 1. Ability </context>
</contexts>
<marker>Na, Ng, 2009</marker>
<rawString>Seung-Hoon Na and Hwee Tou Ng. 2009. A 2-poisson model for probabilistic coreference of named entities for improved text retrieval. In Proceedings of SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodney D Nielsen</author>
<author>Wayne Ward</author>
<author>James H Martin</author>
</authors>
<title>Recognizing entailment in intelligent tutoring systems.</title>
<date>2009</date>
<journal>Natural Language Engineering,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="6524" citStr="Nielsen et al., 2009" startWordPosition="984" endWordPosition="987">75). Note, however, that text understanding systems are generally limited to the resolution of entity (or even just pronoun) coreference, e.g. (Li et al., 2009; Dali et al., 2009). An important reason is the unavailability of tools to resolve the more complex (and difficult) forms of discourse reference such as Textual Entailment has been introduced in Section 1 as a common-sense notion of inference. It has spawned interest in the computational linguistics community as a common denominator of many NLP tasks including IE, summarization and tutoring (Romano et al., 2006; Harabagiu et al., 2007; Nielsen et al., 2009). Architectures for Textual Entailment. Over the course of recent RTE challenges (Giampiccolo et al., 2007; Giampiccolo et al., 2008), the main benchmark for TE technology, two architectures for modeling TE have emerged as dominant: transformations and alignment. The goal of transformation-based TE models is to determine the entailment relation T ==&gt;. H by finding a “proof”, i.e., a sequence of consequents, (T, T1, ... , Tn), such that Tn=H (Bar-Haim et al., 2008; Harmeling, 2009), and that in each transformation, Ti —* Ti+1, the consequent Ti+1 is entailed by Ti. These transformations commonl</context>
</contexts>
<marker>Nielsen, Ward, Martin, 2009</marker>
<rawString>Rodney D. Nielsen, Wayne Ward, and James H. Martin. 2009. Recognizing entailment in intelligent tutoring systems. Natural Language Engineering, 15(4):479–501.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Rahul Mehta</author>
<author>Axel Maroudas</author>
<author>Janet Hitzeman</author>
</authors>
<title>Learning to resolve bridging references.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="8223" citStr="Poesio et al., 2004" startWordPosition="1271" endWordPosition="1274">s generally determined based on features that assess the validity of the local replacement of the T entity by the H entity. While transformation- and alignment-based entailment models look different at first glance, they ultimately have the same goal, namely obtaining a maximal coverage of H by T, i.e. to identify matches of as many elements of H within T as possible.2 To do so, both architectures typically make use of inference rules such as ‘Y was purchased by X —* X paid for Y’, either by directly applying them as transformations, or by using them 1Some studies, e.g. (Markert et al., 2003; Poesio et al., 2004), address the resolution of a few specific kinds of bridging relations; yet, wide-scope systems for bridging resolution are unavailable. 2Clearly, the details of how the final entailment decision is made based on the attained coverage differ substantially among models. 1210 to score alignments. Rules are generally drawn from external knowledge resources, such as WordNet (Fellbaum, 1998) or DIRT (Lin and Pantel, 2001), although knowledge gaps remain a key obstacle (Bos, 2005; Balahur et al., 2008; Bar-Haim et al., 2008). Discourse in previous RTE challenges. The first two rounds of the RTE chal</context>
</contexts>
<marker>Poesio, Mehta, Maroudas, Hitzeman, 2004</marker>
<rawString>Massimo Poesio, Rahul Mehta, Axel Maroudas, and Janet Hitzeman. 2004. Learning to resolve bridging references. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Paolo Ponzetto</author>
<author>Michael Strube</author>
</authors>
<title>Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT.</booktitle>
<contexts>
<context position="38328" citStr="Ponzetto and Strube, 2006" startWordPosition="6184" endWordPosition="6187"> inference. We identified three general cases, and suggested matching operations to obtain the relevant inferences, formulated as tree transformations. Furthermore, our evidence suggests that for practical reasons, the resolution of discourse references should be tightly integrated into entailment systems instead of treating it as a preprocessing step. A particularly interesting result concerns the interplay between discourse references and entailment knowledge. While semantic knowledge (e.g., from WordNet or Wikipedia) has been used beneficially for coreference resolution (Soon et al., 2001; Ponzetto and Strube, 2006), reference resolution has, to our knowledge, not yet been employed to validate entailment rules’ applicability. Our analyses suggest that in the context of deciding textual entailment, reference resolution and entailment knowledge can be seen as complementary ways of achieving the same goal, namely enriching T with additional knowledge to allow the inference of H. Given that both of the technologies are still imperfect, we envisage the way forward as a joint strategy, where reference resolution and entailment rules mutually fill each other’s gaps (cf. Example 3). In sum, our study shows that </context>
</contexts>
<marker>Ponzetto, Strube, 2006</marker>
<rawString>Simone Paolo Ponzetto and Michael Strube. 2006. Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution. In Proceedings of HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Qiu</author>
<author>Min-Yen Kan</author>
<author>Tat-Seng Chua</author>
</authors>
<title>A public reference implementation of the rap anaphora resolution algorithm.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="9912" citStr="Qiu et al., 2004" startWordPosition="1542" endWordPosition="1545">ed above, the impact of discourse references can be generally described as a coverage problem, independent of the system’s architecture. In Example 1, the hypothesis word Oswald cannot be safely linked to the text pronoun he without further knowledge about he; the same is true for ‘Kennedy —* President Kennedy’ which involves a specialization that is only warranted in the specific discourse. A number of systems have tried to address the question of coreference in RTE as a preprocessing step prior to inference proper, with most systems using off-the-shelf coreference resolvers such as JavaRap (Qiu et al., 2004) or OpenNLP3. Generally, anaphoric expressions were textually replaced by their antecedents. Results were inconclusive, however, with several reports about errors introduced by automatic coreference resolution (Agichtein et al., 2008; Adams et al., 2007). Specific evaluations of the contribution of coreference resolution yielded both small negative (Bar-Haim et al., 2008) and insignificant positive (Chambers et al., 2007) results. 3 Motivation and Goals The results of recent studies, as reported in Section 2.2, seem to show that current resolution of discourse references in RTE systems hardly </context>
</contexts>
<marker>Qiu, Kan, Chua, 2004</marker>
<rawString>Long Qiu, Min-Yen Kan, and Tat-Seng Chua. 2004. A public reference implementation of the rap anaphora resolution algorithm. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lorenza Romano</author>
<author>Milen Kouylekov</author>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
<author>Alberto Lavelli</author>
</authors>
<title>Investigating a generic paraphrase-based approach for relation extraction.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL.</booktitle>
<contexts>
<context position="6477" citStr="Romano et al., 2006" startWordPosition="976" endWordPosition="979">p, roles in events and consequence (Clark, 1975). Note, however, that text understanding systems are generally limited to the resolution of entity (or even just pronoun) coreference, e.g. (Li et al., 2009; Dali et al., 2009). An important reason is the unavailability of tools to resolve the more complex (and difficult) forms of discourse reference such as Textual Entailment has been introduced in Section 1 as a common-sense notion of inference. It has spawned interest in the computational linguistics community as a common denominator of many NLP tasks including IE, summarization and tutoring (Romano et al., 2006; Harabagiu et al., 2007; Nielsen et al., 2009). Architectures for Textual Entailment. Over the course of recent RTE challenges (Giampiccolo et al., 2007; Giampiccolo et al., 2008), the main benchmark for TE technology, two architectures for modeling TE have emerged as dominant: transformations and alignment. The goal of transformation-based TE models is to determine the entailment relation T ==&gt;. H by finding a “proof”, i.e., a sequence of consequents, (T, T1, ... , Tn), such that Tn=H (Bar-Haim et al., 2008; Harmeling, 2009), and that in each transformation, Ti —* Ti+1, the consequent Ti+1 i</context>
</contexts>
<marker>Romano, Kouylekov, Szpektor, Dagan, Lavelli, 2006</marker>
<rawString>Lorenza Romano, Milen Kouylekov, Idan Szpektor, Ido Dagan, and Alberto Lavelli. 2006. Investigating a generic paraphrase-based approach for relation extraction. In Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Daniel Chung Yong Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="38300" citStr="Soon et al., 2001" startWordPosition="6180" endWordPosition="6183">uently relevant for inference. We identified three general cases, and suggested matching operations to obtain the relevant inferences, formulated as tree transformations. Furthermore, our evidence suggests that for practical reasons, the resolution of discourse references should be tightly integrated into entailment systems instead of treating it as a preprocessing step. A particularly interesting result concerns the interplay between discourse references and entailment knowledge. While semantic knowledge (e.g., from WordNet or Wikipedia) has been used beneficially for coreference resolution (Soon et al., 2001; Ponzetto and Strube, 2006), reference resolution has, to our knowledge, not yet been employed to validate entailment rules’ applicability. Our analyses suggest that in the context of deciding textual entailment, reference resolution and entailment knowledge can be seen as complementary ways of achieving the same goal, namely enriching T with additional knowledge to allow the inference of H. Given that both of the technologies are still imperfect, we envisage the way forward as a joint strategy, where reference resolution and entailment rules mutually fill each other’s gaps (cf. Example 3). I</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephanie Strassel</author>
<author>Mark Przybocki</author>
<author>Kay Peterson</author>
<author>Zhiyi Song</author>
<author>Kazuaki Maeda</author>
</authors>
<title>Linguistic resources and evaluation techniques for evaluation of cross-document automatic content extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="4921" citStr="Strassel et al., 2008" startWordPosition="734" endWordPosition="737">urse processing tasks such as text segmentation (Hearst, 1997). Reference information provided by discourse is also useful for text understanding tasks such as question answering (QA), information extraction (IE) and information retrieval (IR) (Vicedo and Ferrndez, 2006; Zelenko et al., 2004; Na and Ng, 2009), as well as for the acquisition of lexical-semantic “narrative schema” knowledge (Chambers and Jurafsky, 2009). Discourse references have been the subject of attention in both the Message Understanding Conference (Grishman and Sundheim, 1996) and the Automatic Content Extraction program (Strassel et al., 2008). The simplest form of information that discourse provides is coreference, i.e., information that two linguistic expressions refer to the same entity or event. Coreference is particularly important for processing pronouns and other anaphoric expressions, such as he in Example 1. Ability to resolve this reference translates directly into, e.g., a QA system’s ability to answer questions like Who killed Kennedy?. A second, more complex type of information stems from bridging references, such as in the following discourse (Asher and Lascarides, 1998): (2) “I’ve just arrived. The camel is outside.”</context>
<context position="11666" citStr="Strassel et al., 2008" startWordPosition="1809" endWordPosition="1812">n entailment with an annotation study which removes these limitations. To counteract (1), we use the recent RTE-5 Search dataset (details below). To avoid (2), we perform a manual analysis, assuming discourse references as predicted by an oracle. With regards to (3), our annotation scheme covers coreference and bridging relations of all syntactic categories and classifies them. As for (4), we suggest several operations necessary to integrate the discourse information into an entailment engine. In contrast to the numerous existing datasets annotated for discourse references (Hovy et al., 2006; Strassel et al., 2008), we do not annotate exhaustively. Rather, we are interested specifically in those references instances that impact inference. Furthermore, we analyze each instance from an entailment perspective, characterizing the relevant factors that have an impact on inference. To our knowledge, this is the first such in-depth study.4 The results of our study are of twofold interest. First, they provide guidance for the developers of reference resolvers who might prioritize the scope of their systems to make them more valuable for inference. Second, they point out potential directions for the developers o</context>
</contexts>
<marker>Strassel, Przybocki, Peterson, Song, Maeda, 2008</marker>
<rawString>Stephanie Strassel, Mark Przybocki, Kay Peterson, Zhiyi Song, and Kazuaki Maeda. 2008. Linguistic resources and evaluation techniques for evaluation of cross-document automatic content extraction. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Jose</author>
</authors>
<title>Vicedo and Antonio Ferrndez.</title>
<date>2006</date>
<booktitle>Advances in Open Domain Question Answering,</booktitle>
<pages>71--96</pages>
<editor>in Q&amp;A. In Tomek Strzalkowski and Sanda M. Harabagiu, editors,</editor>
<publisher>Springer.</publisher>
<marker>Jose, 2006</marker>
<rawString>Jose L. Vicedo and Antonio Ferrndez. 2006. Coreference in Q&amp;A. In Tomek Strzalkowski and Sanda M. Harabagiu, editors, Advances in Open Domain Question Answering, pages 71–96. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Massimo Zanzotto</author>
<author>Marco Pennacchiotti</author>
<author>Alessandro Moschitti</author>
</authors>
<title>A machine learning approach to textual entailment recognition.</title>
<date>2009</date>
<journal>Journal of Natural Language Engineering,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="7432" citStr="Zanzotto et al., 2009" startWordPosition="1130" endWordPosition="1133">ion-based TE models is to determine the entailment relation T ==&gt;. H by finding a “proof”, i.e., a sequence of consequents, (T, T1, ... , Tn), such that Tn=H (Bar-Haim et al., 2008; Harmeling, 2009), and that in each transformation, Ti —* Ti+1, the consequent Ti+1 is entailed by Ti. These transformations commonly include lexical modifications and the generation of syntactic alternatives. The second major approach constructs an alignment between the linguistic entities of the trees (or graphs) of T and H, which can represent syntactic structure, semantic structure, or non-hierarchical phrases (Zanzotto et al., 2009; Burchardt et al., 2009; MacCartney et al., 2008). H is assumed to be entailed by T if its entities are aligned “well” to corresponding entities in T. Alignment quality is generally determined based on features that assess the validity of the local replacement of the T entity by the H entity. While transformation- and alignment-based entailment models look different at first glance, they ultimately have the same goal, namely obtaining a maximal coverage of H by T, i.e. to identify matches of as many elements of H within T as possible.2 To do so, both architectures typically make use of infere</context>
<context position="15386" citStr="Zanzotto et al., 2009" startWordPosition="2425" endWordPosition="2428">-dependent entailment in the RTE-5 dataset, where the inference of H depends on reference information from the discourse sentences T0 / T00. Referring terms (in T) and target terms (in H) are shown in boldface. 4 Analysis Scheme For annotating the RTE-5 data, we operationalize reference relations that are relevant for entailment as those that improve coverage. Recall from Section 2.2 that the concept of coverage is applicable to both transformation and alignment models, all of which aim at maximizing coverage of H by T. We represent T and H as syntactic trees, as common in the RTE literature (Zanzotto et al., 2009; Agichtein et al., 2008). Specifically, we assume MINIPAR-style (Lin, 1993) dependency trees where nodes represent text expressions and edges represent the syntactic relations between them. We use “term” to refer to text expressions, and “components” to refer to nodes, edges, and subtrees. Dependency trees are a popular choice in RTE since they offer a fairly semantics-oriented account of the sentence structure that can still be constructed robustly. In an ideal case of entailment, all nodes and dependency edges of H are covered by T. For each T − H pair, we annotate all relevant discourse re</context>
</contexts>
<marker>Zanzotto, Pennacchiotti, Moschitti, 2009</marker>
<rawString>Fabio Massimo Zanzotto, Marco Pennacchiotti, and Alessandro Moschitti. 2009. A machine learning approach to textual entailment recognition. Journal of Natural Language Engineering, 15(4):551–582.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>