<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000054">
<title confidence="0.9993265">
Unsupervised Discovery of Discourse Relations for Eliminating
Intra-sentence Polarity Ambiguities
</title>
<author confidence="0.999578">
Lanjun Zhou, Binyang Li, Wei Gao, Zhongyu Wei, Kam-Fai Wong
</author>
<affiliation confidence="0.9186626">
Department of Systems Engineering and Engineering Management
The Chinese University of Hong Kong
Shatin, NT, Hong Kong, China
Key Laboratory of High Confidence Software Technologies
Ministry of Education, China
</affiliation>
<email confidence="0.980277">
{ljzhou, byli, wgao, zywei, kfwong}@se.cuhk.edu.hk
</email>
<sectionHeader confidence="0.995437" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996119782608696">
Polarity classification of opinionated sen-
tences with both positive and negative senti-
ments1 is a key challenge in sentiment anal-
ysis. This paper presents a novel unsuper-
vised method for discovering intra-sentence
level discourse relations for eliminating polar-
ity ambiguities. Firstly, a discourse scheme
with discourse constraints on polarity was de-
fined empirically based on Rhetorical Struc-
ture Theory (RST). Then, a small set of cue-
phrase-based patterns were utilized to collect
a large number of discourse instances which
were later converted to semantic sequential
representations (SSRs). Finally, an unsuper-
vised method was adopted to generate, weigh
and filter new SSRs without cue phrases for
recognizing discourse relations. Experimen-
tal results showed that the proposed methods
not only effectively recognized the defined
discourse relations but also achieved signifi-
cant improvement by integrating discourse in-
formation in sentence-level polarity classifica-
tion.
</bodyText>
<sectionHeader confidence="0.999135" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998847375">
As an important task of sentiment analysis, polar-
ity classification is critically affected by discourse
structure (Polanyi and Zaenen, 2006). Previous re-
search developed discourse schema (Asher et al.,
2008) (Somasundaran et al., 2008) and proved that
the utilization of discourse relations could improve
the performance of polarity classification on dia-
logues (Somasundaran et al., 2009). However, cur-
</bodyText>
<footnote confidence="0.912033">
1Defined as ambiguous sentences in this paper
</footnote>
<bodyText confidence="0.9501958125">
rent state-of-the-art methods for sentence-level po-
larity classification are facing difficulties in ascer-
taining the polarity of some sentences. For example:
(a) [Although Fujimori was criticized by the international
community],[he was loved by the domestic population],
[because people hated the corrupted ruling class]. (fitoft
國際間對藤森口誅筆伐,他在國內一直深受百姓愛
戴,原因是百姓對腐化的統治階級早就深惡痛絕。)
Example (a) is a positive sentence holding a Con-
trast relation between first two segments and a
Cause relation between last two segments. The po-
larity of &amp;quot;criticized&amp;quot;, &amp;quot;hated&amp;quot; and &amp;quot;corrupted&amp;quot; are rec-
ognized as negative expressions while &amp;quot;loved&amp;quot; is rec-
ognized as a positive expression. Example (a) is dif-
ficult for existing polarity classification methods for
two reasons: (1) the number of positive expressions
is less than negative expressions; (2) the importance
of each sentiment expression is unknown. However,
consider Figure 1, if we know that the polarity of
the first two segments holding a Contrast relation
is determined by the nucleus (Mann and Thompson,
1988) segment and the polarity of the last two seg-
ments holding a Cause relation is also determined by
the nucleus segment, the polarity of the sentence will
be determined by the polarity of &amp;quot;[he...population]&amp;quot;.
Thus, the polarity of Example (a) is positive.
Statistics showed that 43% of the opinionated
sentences in NTCIR2 MOAT (Multilingual Opinion
Analysis Task) Chinese corpus3 are ambiguous. Ex-
isting sentence-level polarity classification methods
ignoring discourse structure often give wrong results
for these sentences. We implemented state-of-the-
</bodyText>
<footnote confidence="0.963362333333333">
2http://research.nii.ac.jp/ntcir/
3Including simplified Chinese and traditional Chinese cor-
pus from NTCIR-6 MOAT and NTCIR-7 MOAT
</footnote>
<page confidence="0.889173">
162
</page>
<note confidence="0.9816845">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 162–171,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<figureCaption confidence="0.9869405">
Figure 1: Discourse relations for Example (a). (n and s
denote nucleus and satellite segment, respectively)
</figureCaption>
<bodyText confidence="0.999939966666667">
art method (Xu and Kit, 2010) in NTCIR-8 Chinese
MOAT as the baseline polarity classifier (BPC) in
this paper. Error analysis of BPC showed that 49%
errors came from ambiguous sentences.
In this paper, we focused on the automation of
recognizing intra-sentence level discourse relations
for polarity classification. Based on the previous
work of Rhetorical Structure Theory (RST) (Mann
and Thompson, 1988), a discourse scheme with dis-
course constraints on polarity was defined empiri-
cally (see Section 3). The scheme contains 5 rela-
tions: Contrast, Condition, Continuation, Cause and
Purpose. From a raw corpus, a small set of cue-
phrase-based patterns were used to collect discourse
instances. These instances were then converted to
semantic sequential representations (SSRs). Finally,
an unsupervised SSR learner was adopted to gener-
ate, weigh and filter high quality new SSRs with-
out cue phrases. Experimental results showed that
the proposed methods could effectively recognize
the defined discourse relations and achieve signifi-
cant improvement in sentence-level polarity classi-
fication comparing to BPC.
The remainder of this paper is organized as fol-
lows. Section 2 introduces the related work. Sec-
tion 3 presents the discourse scheme with discourse
constraints on polarity. Section 4 gives the detail of
proposed method. Experimental results are reported
and discussed in Section 5 and Section 6 concludes
this paper.
</bodyText>
<sectionHeader confidence="0.999803" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999913927272728">
Research on polarity classification were generally
conducted on 4 levels: document-level (Pang et al.,
2002), sentence-level (Riloff et al., 2003), phrase-
level (Wilson et al., 2009) and feature-level (Hu and
Liu, 2004; Xia et al., 2007).
There was little research focusing on the auto-
matic recognition of intra-sentence level discourse
relations for sentiment analysis in the literature.
Polanyi and Zaenen (2006) argued that valence cal-
culation is critically affected by discourse struc-
ture. Asher et al. (2008) proposed a shallow se-
mantic representation using a feature structure and
use five types of rhetorical relations to build a fine-
grained corpus for deep contextual sentiment anal-
ysis. Nevertheless, they did not propose a com-
putational model for their discourse scheme. Sny-
der and Barzilay (2007) combined an agreement
model based on contrastive RST relations with a lo-
cal aspect model to make a more informed over-
all decision for sentiment classification. Nonethe-
less, contrastive relations were only one type of dis-
course relations which may help polarity classifica-
tion. Sadamitsu et al. (2008) modeled polarity re-
versal using HCRFs integrated with inter-sentence
discourse structures. However, our work is on intra-
sentence level and our purpose is not to find polar-
ity reversals but trying to adapt general discourse
schemes (e.g., RST) to help determine the overall
polarity of ambiguous sentences.
The most closely related works were (Somasun-
daran et al., 2008) and (Somasundaran et al., 2009),
which proposed opinion frames as a representation
of discourse-level associations on dialogue and mod-
eled the scheme to improve opinion polarity clas-
sification. However, opinion frames was difficult
to be implemented because the recognition of opin-
ion target was very challenging in general text. Our
work differs from their approaches in two key as-
pects: (1) we distinguished nucleus and satellite in
discourse but opinion frames did not; (2) our method
for discourse discovery was unsupervised while their
method needed annotated data.
Most research works about discourse classifica-
tion were not related to sentiment analysis. Su-
pervised discourse classification methods (Soricut
and Marcu, 2003; Duverle and Prendinger, 2009)
needed manually annotated data. Marcu and Echi-
habi (2002) presented an unsupervised method to
recognize discourse relations held between arbitrary
spans of text. They showed that lexical pairs ex-
tracted from massive amount of data can have a
major impact on discourse classification. Blair-
Goldensohn et al. (2007) extended Marcu&apos;s work by
using parameter opitimization, topic segmentation
and syntactic parsing. However, syntactic parsers
</bodyText>
<page confidence="0.998376">
163
</page>
<bodyText confidence="0.999908428571428">
were usually costly and impractical when dealing
with large scale of text. Thus, in additional to lex-
ical features, we incorporated sequential and seman-
tic information in proposed method for discourse re-
lation classification. Moreover, our method kept the
characteristic of language independent, so it could be
applied to other languages.
</bodyText>
<sectionHeader confidence="0.939215" genericHeader="method">
3 Discourse Scheme for Eliminating
</sectionHeader>
<subsectionHeader confidence="0.603842">
Polarity Ambiguities
</subsectionHeader>
<bodyText confidence="0.992738333333334">
Since not all of the discourse relations in RST
would help eliminate polarity ambiguities, the dis-
course scheme defined in this paper was on a much
coarser level. In order to ascertain which relations
should be included in our scheme, 500 ambigu-
ous sentences were randomly chosen from NTCIR
MOAT Chinese corpus and the most common dis-
course relations for connecting independent clauses
in compound sentences were annotated. We found
that 13 relations from RST occupied about 70% of
the annotated discourse relations which may help
eliminate polarity ambiguities. Inspired by Marcu
and Echihabi (2002), to construct relatively low-
noise discourse instances for unsupervised methods
using cue phrases, we grouped the 13 relations into
the following 5 relations:
Contrast is a union of Antithesis, Concession, Oth-
erwise and Contrast from RST.
Condition is selected from RST.
Continuation is a union of Continuation, Parallel
from RST.
Cause is a union of Evidence, Volitional-Cause,
Nonvolitional-Cause, Volitional-result and
Nonvolitional-result from RST.
Purpose is selected from RST.
The discourse constraints on polarity presented
here were based on the observation of annotated dis-
course instances: (1) discourse instances holding
Contrast relation should contain two segments with
opposite polarities; (2) discourse instances hold-
ing Continuation relation should contain two seg-
ments with the same polarity; (3) the polarity of dis-
course instances holding Contrast, Condition, Cause
or Purpose was determined by the nucleus segment;
(4) the polarity of discourse instances holding Con-
tinuation was determined by either segment.
</bodyText>
<table confidence="0.9937803">
Relation Cue Phrases
(English Translation)
Contrast although1, but2, however2
Condition if1, (if1,then2)
Continuation and, further more,
(not only, but also)
Cause because1, thus2, accordingly2,
as a result2
Purpose in order to2, in order that2,
so that2
</table>
<tableCaption confidence="0.822479">
means CUE1 and 2 means CUE2
Table 1: Examples of cue phrases
</tableCaption>
<sectionHeader confidence="0.996787" genericHeader="method">
4 Methods
</sectionHeader>
<bodyText confidence="0.999971769230769">
The proposed methods were based on two as-
sumptions: (1) Cue-phrase-based patterns could be
used to find limited number of high quality discourse
instances; (2) discourse relations were determined
by lexical, structural and semantic information be-
tween two segments.
Cue-phrase-based patterns could find only lim-
ited number of discourse instances with high pre-
cision (Marcu and Echihabi, 2002). Therefore, we
could not rely on cue-phrase-based patterns alone.
Moreover, there was no annotated corpus similar to
Penn Discourse TreeBank (Miltsakaki et al., 2004)
in other languages such as Chinese. Thus, we pro-
posed a language independent unsupervised method
to identify discourse relations without cue phrases
while maintaining relatively high precision. For
each discourse relation, we started with several cue-
phrase-based patterns and collected a large number
of discourse instances from raw corpus. Then, dis-
course instances were converted to semantic sequen-
tial representations (SSRs). Finally, an unsupervised
method was adopted to generate, weigh and filter
common SSRs without cue phrases. The mined com-
mon SSRs could be directly used in our SSR-based
classifier in unsupervised manner or be employed as
effective features for supervised methods.
</bodyText>
<subsectionHeader confidence="0.9590895">
4.1 Gathering and representing discourse
instances
</subsectionHeader>
<bodyText confidence="0.9086855">
A discourse instance, denoted by DZ, consists of
two successive segments (DZ[j], DZ[2]) within a sen-
tence. For example:
D1: [Although Boris is very brilliant at math],, [he
</bodyText>
<page confidence="0.996183">
164
</page>
<construct confidence="0.562439">
BOS... ,[CUE2]...EOS
BOS [CUE1]... ,...EOS
BOS... ,[CUE1]...EOS
BOS [CUE1]... ,[CUE2]...EOS
</construct>
<tableCaption confidence="0.957489">
Table 2: Cue-phrase-based patterns. BOS and EOS de-
noted the beginning and end of two segments.
</tableCaption>
<bodyText confidence="0.984475967741936">
is a horrible teacher]n
D2: [John is good at basketball]s, [but he lacks team
spirit]n
In D1, &amp;quot;although&amp;quot; indicated the satellite section
while in D2, &amp;quot;but&amp;quot; indicated the nucleus section. Ac-
cordingly, different cue phrases may indicate differ-
ent segment type. Table 1 listed some examples of
cue phrases for each discourse relation. Some cue
phrases were singleton (e.g. &amp;quot;although&amp;quot; and &amp;quot;as a re-
sult&amp;quot;) and some were used as a pair (e.g. &amp;quot;not only,
but also&amp;quot;). &amp;quot;CUE1&amp;quot; indicated satellite segments and
&amp;quot;CUE2&amp;quot; indicated nucleus segments. Note that we
did not distinguish satellite from nucleus for Con-
tinuation in this paper because the polarity could be
determined by either segment.
Table 2 listed cue-phrase-based patterns for all re-
lations. To simplify the problem of discourse seg-
mentation, we split compound sentences into dis-
course segments using commas and semicolons. Al-
though we collected discourse instances from com-
pound sentences only, the number of instances for
each discourse relation was large enough for the pro-
posed unsupervised method. Note that we only col-
lected instances containing at least one sentiment
word in each segment.
In order to incorporate lexical and semantic infor-
mation in our method, we represented each word in
a discourse instance using a part-of-speech tag, a se-
mantic label and a sentiment tag. Then, all discourse
instances were converted to SSRs. The rules for con-
verting were as follows:
</bodyText>
<listItem confidence="0.998711333333333">
(1) Cue phrases and punctuations were ingored.
But the information of nucleus(n) and satellite(s)
was preserved.
(2) Adverbs(RB) appearing in sentiment lexicon,
verbs(V), adjectives(JJ) and nouns(NN) were repre-
sented by their part-of-speech (pos) tag with seman-
tic label (semlabel) if available.
(3) Named entities (NE; PER: person name; ORG:
organization), pronouns (PRP), and function words
</listItem>
<bodyText confidence="0.636009">
were represented by their corresponding named en-
tity tags and part-of-speech tags, respectively.
</bodyText>
<listItem confidence="0.8795415">
(4) Added sentiment tag (P: Positive; N: Nega-
tive) to all sentiment words.
</listItem>
<bodyText confidence="0.8946941875">
By applying above rules, the SSRs for D1 and D2
would be:
d1: [PER V|Ja01 RB|Ka01 JJ|Ee14|P IN NN|Dk03]s
, [PRP V|Ja01 DT JJ|Ga16|N NN|Ae13 ]n
d2: [PER V|Ja01 JJ|Ee14|P IN NN|Bp12]s, [PRP
V|He15|N NN|Di10 NN|Dd08 ]n
Refer to d1 and d2, &amp;quot;Boris&amp;quot; could match &amp;quot;John&amp;quot;
in SSRs because they were converted to &amp;quot;PER&amp;quot; and
they all appeared at the beginning of discourse in-
stances. &amp;quot;Ja01&amp;quot;, &amp;quot;Ee14&amp;quot; etc. were semantic labels
from Chinese synonym list extended version (Che et
al., 2010). There were similar resources in other lan-
guages such as Wordnet(Fellbaum,1998) in English.
The next problem became how to start from current
SSRs and generate new SSRs for recognizing dis-
course relations without cue phrases.
</bodyText>
<subsectionHeader confidence="0.99522">
4.2 Mining common SSRs
</subsectionHeader>
<bodyText confidence="0.981089818181818">
Recall assumption (2), in order to incorporate lex-
ical, structural and semantic information for the sim-
ilarity calculation of two SSRs holding the same
discourse relation, three types of matches were de-
fined for {(u, v)ju E di[k], v E dj[k], k = 1,2}:
(1)Full match: (i) u = v or (ii) u.pos = v.pos and
u.semlabel=v.semlabel or (iii) u.pos=v.pos and
u had a sentiment tag and v had a sentiment tag or
(iv) u.pos and v.posE{PRP, PER, ORG} (2) Partial
match: u.pos = v.pos but not Full match; (3) Mis-
match: u.pos =� v.pos.
</bodyText>
<subsectionHeader confidence="0.651816">
Generating common SSRs
</subsectionHeader>
<bodyText confidence="0.999856769230769">
Intuitively, a simple way of estimating the simi-
larity between two SSRs was using the number of
mismatches. Therefore, we utilized match(di,dj)
where i =� j, which integrated the three types of
matches defined above to calculate the number of
mismatches and generate common SSRs. Consider
Table 3, in common SSRs, full matches were pre-
served, partial matches were replaced by part of
speech tags and mismatches were replaced by &apos;*&apos;s.
The common SSRs generated during the calculation
of match(di, dj) consisted of two parts. The first
part was generated by di[1] and dj[1] and the second
part was generated by di[2] and dj[2]. We stipulated
</bodyText>
<page confidence="0.985771">
165
</page>
<table confidence="0.99949">
d1 d2 mis conf ssr
PER PER 0 0 PER
V|Ja01 V|Ja01 0 0 V|Ja01
RB|Ka01 +1 −0.298 *
JJ|Ee14|P JJ|Ee14|P 0 0 JJ|Ee14|P
IN IN 0 0 IN
NN|Dk03 NN|Bp12 0 −0.50 NN
conf(ssr[1]) = −0.798
PRP PRP 0 0 PRP
V|Ja01 V|He15|N 0 −0.50 V
DT +1 −0.184 *
JJ|Ga16|N +1 −1.0 *
NN|Ae13 NN|Di10 0 −0.50 NN
NN|Dd08 +1 −1.0 *
conf(ssr[2]) = −3.184
</table>
<tableCaption confidence="0.990401333333333">
Table 3: Calculation of match(d1, d2). ssr denoted
the common SSR between d1 and d2 , conf(ssr[1]) and
conf(ssr[2]) denoted the confidence of ssr.
</tableCaption>
<bodyText confidence="0.994309647058823">
that di and dj could generate a common SSR if and
only if the orders of nucleus segment and satellite
segment were the same.
In order to guarantee relatively high quality com-
mon SSRs, we empirically set the upper threshold
of the number of mismatches as 0.5 (i.e., &lt; 1/2 of
the number of words in the generated SSR). It&apos;s not
difficult to figure out that the number of mismatches
generated in Table 3 satisfied this requirement. As a
result, for each discourse relation rn, a correspond-
ing common SSR set Sn could be obtained by adopt-
ing match(di, dj) where i =� j for all discourse in-
stances. An advantage of match(d1, d2) was that
the generated common SSRs preserved the sequen-
tial structure of original discourse instances. And
common SSRs allows us to build high precision dis-
course classifiers (See Section 5).
Weighing and filtering common SSRs
A problem of match(di, dj) was that it ignored
some important information by treating different
mismatches equally. For example, the adverb &amp;quot;very&amp;quot;
in &amp;quot;very brilliant&amp;quot; of D1 was not important for dis-
course recognition. In other words, the number of
mismatches in match(di, dj) could not precisely re-
flect the confidence of the generated common SSRs.
Therefore, it was needed to weigh different mis-
matches for the confidence calculation of common
SSRs.
Intuitively, if a partial match or a mismatch (de-
noted by um) occurred very frequently in the gener-
ation of common SSRs, the importance of um tends
to diminish. Inspired by the tf-idf model, given
ssriESn, we utilized the following equation to esti-
mate the weight (denoted by wm) of um.
</bodyText>
<equation confidence="0.975296">
wm = −ufm · log(|Sn|/ssrfm )
</equation>
<bodyText confidence="0.99927882051282">
where ufm denoted the frequency of um during the
generation of ssri, |Sn |denoted the size of Sn and
ssrfm denoted the number of common SSRs in Sn
containing um . All weights were normalized to
[−1, 0).
Nouns (except for named entities) and verbs were
most representative words in discourse recognition
(Marcu and Echihabi, 2002). In addition, adjectives
and adverbs appearing in sentiment lexicons were
important for polarity classification. Therefore, for
these 4 kinds of words, we utilized −1.0 for a mis-
match and −0.50 for a partial match.
As we had got the weights for all partial matches
and mismatches, the confidence of ssriESn could be
calculated using the cumulation of weights of par-
tial matches and mismatches in ssri[1] and ssri[2].
Recall Table 3, conf(ssr[1]) and conf(ssr[2]) rep-
resented the confidence scores of match(di[1], dj[1])
and match(di[2],dj[2]), respectively. In order to
control the quantity and quality of mined SSRs, a
threshold minconf was introduced. ssri will be
preserved if and only if conf(ssri[1]) &gt; minconf
and conf(ssri[2]) &gt; minconf. The value of
minconf was tuned using the development data.
Finally, we combined adjacent &apos;*&apos;s and preserved
SSRs containing at least one notional word and at
least two words in each segment to meet the de-
mand of maintaining high precision (e.g., &amp;quot;[* DT
*]&amp;quot;, &amp;quot;[PER *]&amp;quot; will be dropped). Moreover, since
many of the SSRs were duplicated, we ranked all
the generated SSRs according to their occurrences
and dropped those appearing only once in order to
preserve common SSRs. At last, SSRs appearing in
more than one common SSR set were removed for
maintaining the uniqueness of each set. The com-
mon SSR set Sn for each discourse relation rn could
be directly used in SSR-based unsupervised classi-
fiers or be employed as effective features in super-
vised methods.
</bodyText>
<page confidence="0.996638">
166
</page>
<table confidence="0.999660142857143">
Relation Occurrence
Contrast 86 (8.2%)
Condition 27 (2.6%)
Continuation 445 (42.2%)
Cause 123 (11.7%)
Purpose 55 (5.2%)
Others 318 (30.2%)
</table>
<tableCaption confidence="0.995682333333333">
Table 4: Distribution of discourse relations on NTC-7.
Others represents discourse relations not included in our
discourse scheme.
</tableCaption>
<sectionHeader confidence="0.998829" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.995746">
5.1 Annotation work and Data
</subsectionHeader>
<bodyText confidence="0.999979944444444">
We extracted all compound sentences which may
contain the defined discourse relations from opinion-
ated sentences (neutral ones were dropped) of NT-
CIR7 MOAT simplified Chinese training data. 1,225
discourse instances were extracted and two annota-
tors were trained to annotate discourse relations ac-
cording to the discourse scheme defined in Section 3.
Note that we annotate both explicit and implicit dis-
course relations. The overall inter annotator agree-
ment was 86.05% and the Kappa-value was 0.8031.
Table 4 showed the distribution of annotated dis-
course relations based on the inter-annotator agree-
ment. The proportion of occurrences of each dis-
course relations varied greatly. For example, Con-
tinuation was the most common relation in anno-
tated corpus, but the occurrences of Condition rela-
tion were rare.
The experiments of this paper were performed us-
ing the following data sets:
NTC-7 contained manually annotated discourse
instances (shown in Table 4). The experiments of
discourse identification were performed on this data
set.
NTC-8 contained all opinionated sentences (neu-
tral ones were dropped) extracted from NTCIR8
MOAT simplified Chinese test data. The experi-
ments of polarity ambiguity elimination using the
identified discourse relations were performed on this
data set.
XINHUA contained simplified Chinese raw news
text from Xinhua.com (2002-2005). A word seg-
mentation tool, a part-of-speech tagging tool, a
named entity recognizer and a word sense disam-
biguation tool (Che et al., 2010) were adopted to all
sentences. The common SSRs were mined from this
data set.
</bodyText>
<subsectionHeader confidence="0.9151375">
5.2 Experimental Settings
Discourse relation identification
</subsectionHeader>
<bodyText confidence="0.998847142857143">
In order to systematically justify the effectiveness
of proposed unsupervised method, following exper-
iments were performed on NTC-7:
Baseline used only cue-phrase-based patterns.
M&amp;E proposed by Marcu and Echihabi (2002).
Given a discourse instance Di, the probabilities:
P(rk|(Di[1], Di[2])) for each relation rk were esti-
mated on all text from XINHUA. Then, the most
likely discourse relation was determined by taking
the maximum over argmaxk{P(rk|(Di[1], Di[2])}.
cSSR used both cue-phrase-based patterns to-
gether with common SSRs for recognizing discourse
relations. Common SSRs were mined from dis-
course instances extracted from XINHUA using cue-
phrase-based patterns. Development data were ran-
domly selected for tuning minconf.
SVM was trained utilizing cue phrases, probabil-
ities from M&amp;E, topic similarity, structure overlap,
polarity of segments and mined common SSRs (Op-
tional). The parameters of the SVM classifier were
set by a grid search on the training set. We performed
4-fold cross validation on NTC-7 to get an average
performance.
The purposes of introducing SVM in our experi-
ment were: (1) to compare the performance of cSSR
to supervised method; (2) to examine the effective-
ness of integrating common SSRs as features for su-
pervised methods.
</bodyText>
<subsectionHeader confidence="0.518405">
Polarity ambiguity elimination
</subsectionHeader>
<bodyText confidence="0.946172416666667">
BPC was trained mainly utilizing punctuation,
uni-gram, bi-gram features with confidence score
output. Discourse classifiers such as Baseline, cSSR
or SVM were adopted individually for the post-
processing of BPC. Given an ambiguous sentence
which contained more than one segment, an intuitive
three-step method was adopted to integrated a dis-
course classifier and discourse constraints on polar-
ity for the post-processing of BPC:
(1) Recognize all discourse relations together with
nucleus and satellite information using a discourse
classifier. The nucleus and satellite information is
</bodyText>
<page confidence="0.995975">
167
</page>
<figureCaption confidence="0.9993155">
Figure 2: Influences of different values of minconf to
the performance of cSSR
</figureCaption>
<bodyText confidence="0.8734059375">
acquired by cSSR if a segment pair could match a
cSSR. Otherwise, we use the annotated nucleus and
satellite information.
(2) Apply discourse constraints on polarity to
ascertain the polarity for each discourse instance.
There may be conflicts between polarities acquired
by BPC and discourse constraints on polarity (e.g.,
Two segments with the same polarity holding a Con-
trast relation). To handle this problem, we chose
the segment with higher polarity confidence and ad-
justed the polarity of the other segment using dis-
course constraints on polarity.
(3) If there was more than one discourse instance
in a single sentence, the overall polarity of the sen-
tence was determined by voting of polarities from
each discourse instance under the majority rule.
</bodyText>
<subsectionHeader confidence="0.997639">
5.3 Experimental Results
</subsectionHeader>
<bodyText confidence="0.998476733333333">
Refer to Figure 2, the performance of cSSR was
significantly affected by minconf. Note that we
performed the tuning process of minconf on differ-
ent development data (1/4 instances randomly se-
lected from NTC-7) and Figure 2 showed the av-
erage performance. cSSR became Baseline when
minconf =0. A significant drop of precision was
observed when minconf was less than −2.5. The
recall remained around 0.495 when minconf ≤
−4.0. The best performance was observed when
minconf =−3.5. As a result, −3.5 was utilized as
the threshold value for cSSR in the following exper-
iments.
Table 5 presented the experimental results for dis-
course relation classification. it showed that:
</bodyText>
<listItem confidence="0.7772785">
(1) Cue-phrase-based patterns could find only lim-
ited number of discourse relations (34.1% of average
</listItem>
<table confidence="0.9997726">
BPC Baseline cSSR SVM
+SSRs
Precision 0.7661 0.7982 0.8059 0.8113
Recall 0.7634 0.7957 0.8038 0.8091
F-score 0.7648 0.7970 0.8048 0.8102
</table>
<tableCaption confidence="0.97999325">
Table 6: Performance of integrating discourse classifiers
and constraints to polarity classification. Note that the
experiments were performed on NTC-8 which contained
only opinionated sentences.
</tableCaption>
<bodyText confidence="0.849747162162162">
recall) with a very high precision (96.17% of average
precision). This is a proof of assumption (1) given
in Section 4. On the other side, M&amp;E which only
considered word pairs between two segments of dis-
course instances got a higher recall with a large drop
of precision. The drop of precision may be caused
by the neglect of structural and semantic information
of discourse instances. However, M&amp;E still outper-
formed Baseline in average F-score.
(2) cSSR enhanced Baseline by increasing the av-
erage recall by about 15% with only a small drop of
precision. The performance of cSSR demonstrated
that our method could effectively discover high qual-
ity common SSRs. The most remarkable improve-
ment was observed on Continuation in which the re-
call increased by almost 20% with only a minor drop
of precision. Actually, cSSR outperformed Baseline
in all discourse relations except for Contrast. In Dis-
course Tree Bank (Carlson et al., 2001) only 26%
of Contrast relations were indicated by cue phrases
while in NTC-7 about 70% of Contrast were indi-
cated by cue phrases. A possible reason was that
we were dealing with Chinese news text which were
usually well written. Another important observation
was that the performance of cSSR was very close to
the result of SVM.
(3) SVM+SSRs achieved the best F-score on
Continuation and average performance. The integra-
tion of SSRs to the feature set of SVM contributed to
a remarkable increase in average F-score. The re-
sults of cSSR and SVM+SSRs demonstrated the ef-
fectiveness of common SSRs mined by the proposed
unsupervised method.
Table 6 presented the performance of integrat-
ing discourse classifiers to polarity classification.
For Baseline and cSSR, the information of nucleus
and satellite could be obtained directly from cue-
</bodyText>
<page confidence="0.993116">
168
</page>
<table confidence="0.9999739">
Relation Baseline M&amp;E cSSR SVM SVM
+SSRs
Contrast P 0.9375 0.4527 0.7531 0.9375 0.9375
R 0.6977 0.7791 0.7093 0.6977 0.6977
F 0.8000 0.5726 0.7305 0.8000 0.8000
Condition P 1.0000 0.4444 0.6774 1.0000 0.7083
R 0.5556 0.8889 0.7778 0.5185 0.6296
F 0.7143 0.5926 0.7241 0.6829 0.6667
Continuation P 0.9831 0.6028 0.9761 0.6507 0.7266
R 0.2607 0.5865 0.4584 0.6697 0.6629
F 0.4120 0.5945 0.6239 0.6600 0.6933
Cause P 1.0000 0.5542 0.9429 1.0000 0.9412
R 0.2114 0.3740 0.2683 0.2114 0.2602
F 0.3489 0.4466 0.4177 0.3489 0.4076
Purpose P 0.8947 0.3704 0.8163 0.9167 0.7193
R 0.6182 0.7273 0.7273 0.6000 0.7455
F 0.7312 0.4908 0.7692 0.7253 0.7321
Average P 0.9617 0.5302 0.8864 0.7207 0.7607
R 0.3410 0.5951 0.4878 0.5856 0.6046
F 0.5035 0.5608 0.6293 0.6461 0.6737
</table>
<tableCaption confidence="0.999842">
Table 5: Performance of recognizing discourse relations. (The evaluation criteria are Precision, Recall and F-score)
</tableCaption>
<bodyText confidence="0.999940416666667">
phrase-based patterns and SSRs, respectively. For
SVM+cSSR, the nucleus and satellite information
was acquired by cSSR if a segment pair could match
a cSSR. Otherwise, we used manually annotated nu-
cleus and satellite information. It&apos;s clear that the
performance of polarity classification was enhanced
with the improvement of discourse relation recogni-
tion. M&amp;E was not included in this experiment be-
cause the performance of polarity classification was
decreased by the mis-classified discourse relations.
SVM+SSRs achieved significant (p&lt;0.01) improve-
ment in polarity classification compared to BPC.
</bodyText>
<subsectionHeader confidence="0.9573675">
5.4 Discussion
Effect of weighing and filtering
</subsectionHeader>
<bodyText confidence="0.999904090909091">
To assess the contribution of weighing and filter-
ing in mining SSRs using a minimum confidence
threshold, i.e. minconf, we implemented cSSR’
without weighing and filtering on the same data set.
Consider Table 7, cSSR achieved obvious improve-
ment in Precision and F-score than cSSR’. More-
over, the total number of SSRs was greatly reduced
in cSSR with only a minor drop of recall. This was
because cSSR’ was affected by thousands of low
quality common SSRs which would be filtered in
cSSR. The result in Table 7 proved that weighing and
</bodyText>
<table confidence="0.9979144">
cSSR’ cSSR
Precision 0.6182 0.8864
Recall 0.5014 0.4878
F-score 0.5537 0.6293
NOS &gt; 1 million ≈ 0.12 million
</table>
<tableCaption confidence="0.9908455">
Table 7: Comparison of cSSR’ and cSSR. &amp;quot;NOS&amp;quot; denoted
the number of mined common SSRs.
</tableCaption>
<bodyText confidence="0.999769055555556">
filtering were essential in our proposed method.
We further analyzed how the improvement was
achieved in cSSR. In our experiment, the most com-
mon mismatches were auxiliary words, named enti-
ties, adjectives or adverbs without sentiments (e.g.,
&amp;quot;green&amp;quot;, &amp;quot;very&amp;quot;, etc.), prepositions, numbers and
quantifiers. It&apos;s straightforward that these words
were insignificant in discourse relation classification
purpose. Moreover, these words did not belong to
the 4 kinds of most representative words. In other
words, the weights of most mismatches were calcu-
lated using the equation presented in Section 4.2 in-
stead of utilizing a unified value, i.e. −1. Recall
Table 3, the weight of &amp;quot;RB|Ka01&amp;quot; (original: &amp;quot;very&amp;quot;)
was −0.298 and &amp;quot;DT&amp;quot; (original: &apos;a&apos;) was −0.184.
Comparing to the weights of mismatches for most
representative words (−1.0), the proposed method
successfully down weighed the words which were
</bodyText>
<page confidence="0.997539">
169
</page>
<figureCaption confidence="0.991777">
Figure 3: Improvement from individual discourse rela-
tions. N denoted the number of ambiguities eliminated.
</figureCaption>
<bodyText confidence="0.992682428571428">
not important for discourse identification. There-
fore, weighing and filtering were able to preserve
high quality SSRs while filter out low quality SSRs
by setting the confidence threshold, i.e. minconf.
Contribution of different discourse relations
We also analyzed the contribution of different dis-
course relations in eliminating polarity ambiguities.
Refer to Figure 3, the improvement of polarity classi-
fication mainly came from three discourse relations:
Contrast, Continuation and Cause. It was straight-
forward that Contrast relation could eliminate po-
larity ambiguities because it held between two seg-
ments with opposite polarities. The contribution of
Cause relation also result from two segments holding
different polarities such as example (a) in Section 1.
However, recall Table 4, although Cause occurred
more often than Contrast, only a part of discourse
instances holding Cause relation contained two seg-
ments with the opposite polarities. Another impor-
tant relation in eliminating ambiguity was Continu-
ation. We investigated sentences with polarities cor-
rected by Continuation relation. Most of them fell
into two categories: (1) sentences with mistakenly
classified sentiments by BPC; (2) sentences with im-
plicit sentiments. For example:
(b) [France and Germany have banned human cloning at
present],[on 20th, U.S. President George W. Bush called
for regulations of the same content to Congress] (R前,
法国和德国都禁止克隆人的胚胎,美国总统布什 20
日向国会提出,要求制定同样内容的法规。)
The first segment of example (b) was negative
(&amp;quot;banned&amp;quot; expressed a negative sentiment) and a
Continuation relation held between these two seg-
ments. Consequently, the polarity of the second seg-
ment should be negative.
</bodyText>
<sectionHeader confidence="0.996155" genericHeader="conclusions">
6 Conclusions and Future work
</sectionHeader>
<bodyText confidence="0.999983304347826">
This paper focused on unsupervised discovery
of intra-sentence discourse relations for sentence
level polarity classification. We firstly presented a
discourse scheme based on empirical observations.
Then, an unsupervised method was proposed start-
ing from a small set of cue-phrase-based patterns to
mine high quality common SSRs for each discourse
relation. The performance of discourse classification
was further improved by employing SSRs as features
in supervised methods. Experimental results showed
that our methods not only effectively recognized dis-
course relations but also achieved significant im-
provement (p&lt;0.01) in sentence level polarity clas-
sification. Although we were dealing with Chinese
text, the proposed unsupervised method could be
easily generalized to other languages.
The future work will be focused on (1) integrating
more semantic and syntactic information in proposed
unsupervised method; (2) extending our method to
inter-sentence level and then jointly modeling intra-
sentence level and inter-sentence level discourse
constraints on polarity to reach a global optimal in-
ference for polarity classification.
</bodyText>
<sectionHeader confidence="0.998227" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9817094">
This work is partially supported by National 863
program of China (Grant No. 2009AA01Z150),
the Innovation and Technology Fund of Hong Kong
SAR (Project No. GHP/036/09SZ) and 2010/11
CUHK Direct Grants (Project No. EE09743).
</bodyText>
<sectionHeader confidence="0.998942" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9989927">
N. Asher, F. Benamara, and Y.Y. Mathieu. 2008. Distill-
ing opinion in discourse: A preliminary study. Coling
2008: Companion volume: Posters and Demonstra-
tions, pages 5--8.
S. Blair-Goldensohn, K.R. McKeown, and O.C. Ram-
bow. 2007. Building and refining rhetorical-semantic
relation models. In Proceedings ofNAACL HLT, pages
428--435.
L. Carlson, D. Marcu, and M.E. Okurowski. 2001. Build-
ing a discourse-tagged corpus in the framework of
</reference>
<page confidence="0.969537">
170
</page>
<reference confidence="0.999724425287356">
rhetorical structure theory. In Proceedings of the Sec-
ond SIGdial Workshop on Discourse and Dialogue-
Volume 16, pages 1--10. Association for Computa-
tional Linguistics.
W. Che, Z. Li, and T. Liu. 2010. Ltp: A chinese language
technology platform. In Proceedings of the 23rd In-
ternational Conference on Computational Linguistics:
Demonstrations, pages 13--16. Association for Com-
putational Linguistics.
D.A. Duverle and H. Prendinger. 2009. A novel dis-
course parser based on support vector machine classi-
fication. In Proceedings of the Joint Conference of the
47th Annual Meeting of the ACL and the 4th Interna-
tional Joint Conference on Natural Language Process-
ing of the AFNLP: Volume 2, pages 665--673. Associ-
ation for Computational Linguistics.
C. Fellbaum. 1998. WordNet: An electronic lexical
database. The MIT press.
M. Hu and B. Liu. 2004. Mining and summarizing
customer reviews. In Proceedings of the tenth ACM
SIGKDD international conference on Knowledge dis-
covery and data mining, pages 168--177. ACM.
W.C. Mann and S.A. Thompson. 1988. Rhetorical struc-
ture theory: Toward a functional theory of text organi-
zation. Text-Interdisciplinary Journal for the Study of
Discourse, 8(3):243--281.
D. Marcu and A. Echihabi. 2002. An unsupervised ap-
proach to recognizing discourse relations. In Proceed-
ings of the 40th Annual Meeting on Association for
Computational Linguistics, pages 368--375. Associa-
tion for Computational Linguistics.
E. Miltsakaki, R. Prasad, A. Joshi, and B. Webber. 2004.
The penn discourse treebank. In Proceedings ofthe 4th
International Conference on Language Resources and
Evaluation. Citeseer.
B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs
up?: sentiment classification using machine learning
techniques. In Proceedings of the ACL-02 conference
on Empirical methods in natural language processing-
Volume 10, pages 79--86. Association for Computa-
tional Linguistics.
L. Polanyi and A. Zaenen. 2006. Contextual valence
shifters. Computing attitude and affect in text: The-
ory and applications, pages 1--10.
E. Riloff, J. Wiebe, and T. Wilson. 2003. Learning sub-
jective nouns using extraction pattern bootstrapping.
In Proceedings of the seventh conference on Natu-
ral language learning at HLT-NAACL 2003-Volume 4,
pages 25--32. Association for Computational Linguis-
tics.
K. Sadamitsu, S. Sekine, and M. Yamamoto. 2008. Sen-
timent analysis based on probabilistic models using
inter-sentence information.
B. Snyder and R. Barzilay. 2007. Multiple aspect rank-
ing using the good grief algorithm. In Proceedings of
NAACL HLT, pages 300--307.
S. Somasundaran, J. Wiebe, and J. Ruppenhofer. 2008.
Discourse level opinion interpretation. In Proceed-
ings of the 22nd International Conference on Compu-
tational Linguistics, pages 801--808. Association for
Computational Linguistics.
S. Somasundaran, G. Namata, J. Wiebe, and L. Getoor.
2009. Supervised and unsupervised methods in em-
ploying discourse relations for improving opinion po-
larity classification. In Proceedings of the 2009 Con-
ference on Empirical Methods in Natural Language
Processing, pages 170--179. Association for Compu-
tational Linguistics.
R. Soricut and D. Marcu. 2003. Sentence level dis-
course parsing using syntactic and lexical information.
In Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology,
pages 149--156. Association for Computational Lin-
guistics.
T. Wilson, J. Wiebe, and P. Hoffmann. 2009. Recogniz-
ing Contextual Polarity: an exploration of features for
phrase-level sentiment analysis. Computational Lin-
guistics, 35(3):399--433.
Y.Q. Xia, R.F. Xu, K.F. Wong, and F. Zheng. 2007. The
unified collocation framework for opinion mining. In
International Conference on Machine Learning and
Cybernetics, volume 2, pages 844--850. IEEE.
R. Xu and C. Kit. 2010. Incorporating feature-based and
similarity-based opinion mining--ctl in ntcir-8 moat.
In Proceedings ofthe 8th NTCIR Workshop, pages 276-
-281.
</reference>
<page confidence="0.998191">
171
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.567042">
<title confidence="0.999468">Unsupervised Discovery of Discourse Relations for Intra-sentence Polarity Ambiguities</title>
<author confidence="0.998005">Lanjun Zhou</author>
<author confidence="0.998005">Binyang Li</author>
<author confidence="0.998005">Wei Gao</author>
<author confidence="0.998005">Zhongyu Wei</author>
<author confidence="0.998005">Kam-Fai</author>
<affiliation confidence="0.9527068">Department of Systems Engineering and Engineering The Chinese University of Hong Shatin, NT, Hong Kong, Key Laboratory of High Confidence Software Ministry of Education,</affiliation>
<email confidence="0.84075">byli,wgao,zywei,</email>
<abstract confidence="0.993454958333333">Polarity classification of opinionated sentences with both positive and negative sentiis a key challenge in sentiment analysis. This paper presents a novel unsupervised method for discovering intra-sentence level discourse relations for eliminating polarity ambiguities. Firstly, a discourse scheme with discourse constraints on polarity was defined empirically based on Rhetorical Structure Theory (RST). Then, a small set of cuephrase-based patterns were utilized to collect a large number of discourse instances which were later converted to semantic sequential representations (SSRs). Finally, an unsupervised method was adopted to generate, weigh and filter new SSRs without cue phrases for recognizing discourse relations. Experimental results showed that the proposed methods not only effectively recognized the defined discourse relations but also achieved significant improvement by integrating discourse information in sentence-level polarity classification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>N Asher</author>
<author>F Benamara</author>
<author>Y Y Mathieu</author>
</authors>
<title>Distilling opinion in discourse: A preliminary study. Coling 2008: Companion volume: Posters and Demonstrations,</title>
<date>2008</date>
<pages>5--8</pages>
<contexts>
<context position="1627" citStr="Asher et al., 2008" startWordPosition="223" endWordPosition="226">ntations (SSRs). Finally, an unsupervised method was adopted to generate, weigh and filter new SSRs without cue phrases for recognizing discourse relations. Experimental results showed that the proposed methods not only effectively recognized the defined discourse relations but also achieved significant improvement by integrating discourse information in sentence-level polarity classification. 1 Introduction As an important task of sentiment analysis, polarity classification is critically affected by discourse structure (Polanyi and Zaenen, 2006). Previous research developed discourse schema (Asher et al., 2008) (Somasundaran et al., 2008) and proved that the utilization of discourse relations could improve the performance of polarity classification on dialogues (Somasundaran et al., 2009). However, cur1Defined as ambiguous sentences in this paper rent state-of-the-art methods for sentence-level polarity classification are facing difficulties in ascertaining the polarity of some sentences. For example: (a) [Although Fujimori was criticized by the international community],[he was loved by the domestic population], [because people hated the corrupted ruling class]. (fitoft 國際間對藤森口誅筆伐,他在國內一直深受百姓愛 戴,原因是百</context>
<context position="5856" citStr="Asher et al. (2008)" startWordPosition="844" endWordPosition="847">imental results are reported and discussed in Section 5 and Section 6 concludes this paper. 2 Related Work Research on polarity classification were generally conducted on 4 levels: document-level (Pang et al., 2002), sentence-level (Riloff et al., 2003), phraselevel (Wilson et al., 2009) and feature-level (Hu and Liu, 2004; Xia et al., 2007). There was little research focusing on the automatic recognition of intra-sentence level discourse relations for sentiment analysis in the literature. Polanyi and Zaenen (2006) argued that valence calculation is critically affected by discourse structure. Asher et al. (2008) proposed a shallow semantic representation using a feature structure and use five types of rhetorical relations to build a finegrained corpus for deep contextual sentiment analysis. Nevertheless, they did not propose a computational model for their discourse scheme. Snyder and Barzilay (2007) combined an agreement model based on contrastive RST relations with a local aspect model to make a more informed overall decision for sentiment classification. Nonetheless, contrastive relations were only one type of discourse relations which may help polarity classification. Sadamitsu et al. (2008) mode</context>
</contexts>
<marker>Asher, Benamara, Mathieu, 2008</marker>
<rawString>N. Asher, F. Benamara, and Y.Y. Mathieu. 2008. Distilling opinion in discourse: A preliminary study. Coling 2008: Companion volume: Posters and Demonstrations, pages 5--8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Blair-Goldensohn</author>
<author>K R McKeown</author>
<author>O C Rambow</author>
</authors>
<title>Building and refining rhetorical-semantic relation models.</title>
<date>2007</date>
<booktitle>In Proceedings ofNAACL HLT,</booktitle>
<pages>428--435</pages>
<marker>Blair-Goldensohn, McKeown, Rambow, 2007</marker>
<rawString>S. Blair-Goldensohn, K.R. McKeown, and O.C. Rambow. 2007. Building and refining rhetorical-semantic relation models. In Proceedings ofNAACL HLT, pages 428--435.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Carlson</author>
<author>D Marcu</author>
<author>M E Okurowski</author>
</authors>
<title>Building a discourse-tagged corpus in the framework of rhetorical structure theory.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second SIGdial Workshop on Discourse and DialogueVolume 16,</booktitle>
<pages>1--10</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="26615" citStr="Carlson et al., 2001" startWordPosition="4114" endWordPosition="4117"> neglect of structural and semantic information of discourse instances. However, M&amp;E still outperformed Baseline in average F-score. (2) cSSR enhanced Baseline by increasing the average recall by about 15% with only a small drop of precision. The performance of cSSR demonstrated that our method could effectively discover high quality common SSRs. The most remarkable improvement was observed on Continuation in which the recall increased by almost 20% with only a minor drop of precision. Actually, cSSR outperformed Baseline in all discourse relations except for Contrast. In Discourse Tree Bank (Carlson et al., 2001) only 26% of Contrast relations were indicated by cue phrases while in NTC-7 about 70% of Contrast were indicated by cue phrases. A possible reason was that we were dealing with Chinese news text which were usually well written. Another important observation was that the performance of cSSR was very close to the result of SVM. (3) SVM+SSRs achieved the best F-score on Continuation and average performance. The integration of SSRs to the feature set of SVM contributed to a remarkable increase in average F-score. The results of cSSR and SVM+SSRs demonstrated the effectiveness of common SSRs mined</context>
</contexts>
<marker>Carlson, Marcu, Okurowski, 2001</marker>
<rawString>L. Carlson, D. Marcu, and M.E. Okurowski. 2001. Building a discourse-tagged corpus in the framework of rhetorical structure theory. In Proceedings of the Second SIGdial Workshop on Discourse and DialogueVolume 16, pages 1--10. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Che</author>
<author>Z Li</author>
<author>T Liu</author>
</authors>
<title>Ltp: A chinese language technology platform.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Demonstrations,</booktitle>
<pages>13--16</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="14512" citStr="Che et al., 2010" startWordPosition="2162" endWordPosition="2165">rresponding named entity tags and part-of-speech tags, respectively. (4) Added sentiment tag (P: Positive; N: Negative) to all sentiment words. By applying above rules, the SSRs for D1 and D2 would be: d1: [PER V|Ja01 RB|Ka01 JJ|Ee14|P IN NN|Dk03]s , [PRP V|Ja01 DT JJ|Ga16|N NN|Ae13 ]n d2: [PER V|Ja01 JJ|Ee14|P IN NN|Bp12]s, [PRP V|He15|N NN|Di10 NN|Dd08 ]n Refer to d1 and d2, &amp;quot;Boris&amp;quot; could match &amp;quot;John&amp;quot; in SSRs because they were converted to &amp;quot;PER&amp;quot; and they all appeared at the beginning of discourse instances. &amp;quot;Ja01&amp;quot;, &amp;quot;Ee14&amp;quot; etc. were semantic labels from Chinese synonym list extended version (Che et al., 2010). There were similar resources in other languages such as Wordnet(Fellbaum,1998) in English. The next problem became how to start from current SSRs and generate new SSRs for recognizing discourse relations without cue phrases. 4.2 Mining common SSRs Recall assumption (2), in order to incorporate lexical, structural and semantic information for the similarity calculation of two SSRs holding the same discourse relation, three types of matches were defined for {(u, v)ju E di[k], v E dj[k], k = 1,2}: (1)Full match: (i) u = v or (ii) u.pos = v.pos and u.semlabel=v.semlabel or (iii) u.pos=v.pos and </context>
<context position="21692" citStr="Che et al., 2010" startWordPosition="3353" endWordPosition="3356">-7 contained manually annotated discourse instances (shown in Table 4). The experiments of discourse identification were performed on this data set. NTC-8 contained all opinionated sentences (neutral ones were dropped) extracted from NTCIR8 MOAT simplified Chinese test data. The experiments of polarity ambiguity elimination using the identified discourse relations were performed on this data set. XINHUA contained simplified Chinese raw news text from Xinhua.com (2002-2005). A word segmentation tool, a part-of-speech tagging tool, a named entity recognizer and a word sense disambiguation tool (Che et al., 2010) were adopted to all sentences. The common SSRs were mined from this data set. 5.2 Experimental Settings Discourse relation identification In order to systematically justify the effectiveness of proposed unsupervised method, following experiments were performed on NTC-7: Baseline used only cue-phrase-based patterns. M&amp;E proposed by Marcu and Echihabi (2002). Given a discourse instance Di, the probabilities: P(rk|(Di[1], Di[2])) for each relation rk were estimated on all text from XINHUA. Then, the most likely discourse relation was determined by taking the maximum over argmaxk{P(rk|(Di[1], Di[</context>
</contexts>
<marker>Che, Li, Liu, 2010</marker>
<rawString>W. Che, Z. Li, and T. Liu. 2010. Ltp: A chinese language technology platform. In Proceedings of the 23rd International Conference on Computational Linguistics: Demonstrations, pages 13--16. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Duverle</author>
<author>H Prendinger</author>
</authors>
<title>A novel discourse parser based on support vector machine classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP:</booktitle>
<volume>2</volume>
<pages>665--673</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7583" citStr="Duverle and Prendinger, 2009" startWordPosition="1110" endWordPosition="1113">odeled the scheme to improve opinion polarity classification. However, opinion frames was difficult to be implemented because the recognition of opinion target was very challenging in general text. Our work differs from their approaches in two key aspects: (1) we distinguished nucleus and satellite in discourse but opinion frames did not; (2) our method for discourse discovery was unsupervised while their method needed annotated data. Most research works about discourse classification were not related to sentiment analysis. Supervised discourse classification methods (Soricut and Marcu, 2003; Duverle and Prendinger, 2009) needed manually annotated data. Marcu and Echihabi (2002) presented an unsupervised method to recognize discourse relations held between arbitrary spans of text. They showed that lexical pairs extracted from massive amount of data can have a major impact on discourse classification. BlairGoldensohn et al. (2007) extended Marcu&apos;s work by using parameter opitimization, topic segmentation and syntactic parsing. However, syntactic parsers 163 were usually costly and impractical when dealing with large scale of text. Thus, in additional to lexical features, we incorporated sequential and semantic </context>
</contexts>
<marker>Duverle, Prendinger, 2009</marker>
<rawString>D.A. Duverle and H. Prendinger. 2009. A novel discourse parser based on support vector machine classification. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2, pages 665--673. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An electronic lexical database.</title>
<date>1998</date>
<publisher>The MIT press.</publisher>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet: An electronic lexical database. The MIT press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hu</author>
<author>B Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>168--177</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="5561" citStr="Hu and Liu, 2004" startWordPosition="799" endWordPosition="802">ovement in sentence-level polarity classification comparing to BPC. The remainder of this paper is organized as follows. Section 2 introduces the related work. Section 3 presents the discourse scheme with discourse constraints on polarity. Section 4 gives the detail of proposed method. Experimental results are reported and discussed in Section 5 and Section 6 concludes this paper. 2 Related Work Research on polarity classification were generally conducted on 4 levels: document-level (Pang et al., 2002), sentence-level (Riloff et al., 2003), phraselevel (Wilson et al., 2009) and feature-level (Hu and Liu, 2004; Xia et al., 2007). There was little research focusing on the automatic recognition of intra-sentence level discourse relations for sentiment analysis in the literature. Polanyi and Zaenen (2006) argued that valence calculation is critically affected by discourse structure. Asher et al. (2008) proposed a shallow semantic representation using a feature structure and use five types of rhetorical relations to build a finegrained corpus for deep contextual sentiment analysis. Nevertheless, they did not propose a computational model for their discourse scheme. Snyder and Barzilay (2007) combined a</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>M. Hu and B. Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 168--177. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>S A Thompson</author>
</authors>
<title>Rhetorical structure theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<journal>Text-Interdisciplinary Journal for the Study of Discourse,</journal>
<volume>8</volume>
<issue>3</issue>
<contexts>
<context position="2916" citStr="Mann and Thompson, 1988" startWordPosition="411" endWordPosition="414">ntrast relation between first two segments and a Cause relation between last two segments. The polarity of &amp;quot;criticized&amp;quot;, &amp;quot;hated&amp;quot; and &amp;quot;corrupted&amp;quot; are recognized as negative expressions while &amp;quot;loved&amp;quot; is recognized as a positive expression. Example (a) is difficult for existing polarity classification methods for two reasons: (1) the number of positive expressions is less than negative expressions; (2) the importance of each sentiment expression is unknown. However, consider Figure 1, if we know that the polarity of the first two segments holding a Contrast relation is determined by the nucleus (Mann and Thompson, 1988) segment and the polarity of the last two segments holding a Cause relation is also determined by the nucleus segment, the polarity of the sentence will be determined by the polarity of &amp;quot;[he...population]&amp;quot;. Thus, the polarity of Example (a) is positive. Statistics showed that 43% of the opinionated sentences in NTCIR2 MOAT (Multilingual Opinion Analysis Task) Chinese corpus3 are ambiguous. Existing sentence-level polarity classification methods ignoring discourse structure often give wrong results for these sentences. We implemented state-of-the2http://research.nii.ac.jp/ntcir/ 3Including simp</context>
<context position="4309" citStr="Mann and Thompson, 1988" startWordPosition="610" endWordPosition="613">ng, pages 162–171, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics Figure 1: Discourse relations for Example (a). (n and s denote nucleus and satellite segment, respectively) art method (Xu and Kit, 2010) in NTCIR-8 Chinese MOAT as the baseline polarity classifier (BPC) in this paper. Error analysis of BPC showed that 49% errors came from ambiguous sentences. In this paper, we focused on the automation of recognizing intra-sentence level discourse relations for polarity classification. Based on the previous work of Rhetorical Structure Theory (RST) (Mann and Thompson, 1988), a discourse scheme with discourse constraints on polarity was defined empirically (see Section 3). The scheme contains 5 relations: Contrast, Condition, Continuation, Cause and Purpose. From a raw corpus, a small set of cuephrase-based patterns were used to collect discourse instances. These instances were then converted to semantic sequential representations (SSRs). Finally, an unsupervised SSR learner was adopted to generate, weigh and filter high quality new SSRs without cue phrases. Experimental results showed that the proposed methods could effectively recognize the defined discourse re</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>W.C. Mann and S.A. Thompson. 1988. Rhetorical structure theory: Toward a functional theory of text organization. Text-Interdisciplinary Journal for the Study of Discourse, 8(3):243--281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marcu</author>
<author>A Echihabi</author>
</authors>
<title>An unsupervised approach to recognizing discourse relations.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>368--375</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7641" citStr="Marcu and Echihabi (2002)" startWordPosition="1118" endWordPosition="1122">However, opinion frames was difficult to be implemented because the recognition of opinion target was very challenging in general text. Our work differs from their approaches in two key aspects: (1) we distinguished nucleus and satellite in discourse but opinion frames did not; (2) our method for discourse discovery was unsupervised while their method needed annotated data. Most research works about discourse classification were not related to sentiment analysis. Supervised discourse classification methods (Soricut and Marcu, 2003; Duverle and Prendinger, 2009) needed manually annotated data. Marcu and Echihabi (2002) presented an unsupervised method to recognize discourse relations held between arbitrary spans of text. They showed that lexical pairs extracted from massive amount of data can have a major impact on discourse classification. BlairGoldensohn et al. (2007) extended Marcu&apos;s work by using parameter opitimization, topic segmentation and syntactic parsing. However, syntactic parsers 163 were usually costly and impractical when dealing with large scale of text. Thus, in additional to lexical features, we incorporated sequential and semantic information in proposed method for discourse relation clas</context>
<context position="9022" citStr="Marcu and Echihabi (2002)" startWordPosition="1327" endWordPosition="1330">ing Polarity Ambiguities Since not all of the discourse relations in RST would help eliminate polarity ambiguities, the discourse scheme defined in this paper was on a much coarser level. In order to ascertain which relations should be included in our scheme, 500 ambiguous sentences were randomly chosen from NTCIR MOAT Chinese corpus and the most common discourse relations for connecting independent clauses in compound sentences were annotated. We found that 13 relations from RST occupied about 70% of the annotated discourse relations which may help eliminate polarity ambiguities. Inspired by Marcu and Echihabi (2002), to construct relatively lownoise discourse instances for unsupervised methods using cue phrases, we grouped the 13 relations into the following 5 relations: Contrast is a union of Antithesis, Concession, Otherwise and Contrast from RST. Condition is selected from RST. Continuation is a union of Continuation, Parallel from RST. Cause is a union of Evidence, Volitional-Cause, Nonvolitional-Cause, Volitional-result and Nonvolitional-result from RST. Purpose is selected from RST. The discourse constraints on polarity presented here were based on the observation of annotated discourse instances: </context>
<context position="10770" citStr="Marcu and Echihabi, 2002" startWordPosition="1582" endWordPosition="1585">(if1,then2) Continuation and, further more, (not only, but also) Cause because1, thus2, accordingly2, as a result2 Purpose in order to2, in order that2, so that2 means CUE1 and 2 means CUE2 Table 1: Examples of cue phrases 4 Methods The proposed methods were based on two assumptions: (1) Cue-phrase-based patterns could be used to find limited number of high quality discourse instances; (2) discourse relations were determined by lexical, structural and semantic information between two segments. Cue-phrase-based patterns could find only limited number of discourse instances with high precision (Marcu and Echihabi, 2002). Therefore, we could not rely on cue-phrase-based patterns alone. Moreover, there was no annotated corpus similar to Penn Discourse TreeBank (Miltsakaki et al., 2004) in other languages such as Chinese. Thus, we proposed a language independent unsupervised method to identify discourse relations without cue phrases while maintaining relatively high precision. For each discourse relation, we started with several cuephrase-based patterns and collected a large number of discourse instances from raw corpus. Then, discourse instances were converted to semantic sequential representations (SSRs). Fin</context>
<context position="18364" citStr="Marcu and Echihabi, 2002" startWordPosition="2831" endWordPosition="2834">rtial match or a mismatch (denoted by um) occurred very frequently in the generation of common SSRs, the importance of um tends to diminish. Inspired by the tf-idf model, given ssriESn, we utilized the following equation to estimate the weight (denoted by wm) of um. wm = −ufm · log(|Sn|/ssrfm ) where ufm denoted the frequency of um during the generation of ssri, |Sn |denoted the size of Sn and ssrfm denoted the number of common SSRs in Sn containing um . All weights were normalized to [−1, 0). Nouns (except for named entities) and verbs were most representative words in discourse recognition (Marcu and Echihabi, 2002). In addition, adjectives and adverbs appearing in sentiment lexicons were important for polarity classification. Therefore, for these 4 kinds of words, we utilized −1.0 for a mismatch and −0.50 for a partial match. As we had got the weights for all partial matches and mismatches, the confidence of ssriESn could be calculated using the cumulation of weights of partial matches and mismatches in ssri[1] and ssri[2]. Recall Table 3, conf(ssr[1]) and conf(ssr[2]) represented the confidence scores of match(di[1], dj[1]) and match(di[2],dj[2]), respectively. In order to control the quantity and qual</context>
<context position="22051" citStr="Marcu and Echihabi (2002)" startWordPosition="3403" endWordPosition="3406">ourse relations were performed on this data set. XINHUA contained simplified Chinese raw news text from Xinhua.com (2002-2005). A word segmentation tool, a part-of-speech tagging tool, a named entity recognizer and a word sense disambiguation tool (Che et al., 2010) were adopted to all sentences. The common SSRs were mined from this data set. 5.2 Experimental Settings Discourse relation identification In order to systematically justify the effectiveness of proposed unsupervised method, following experiments were performed on NTC-7: Baseline used only cue-phrase-based patterns. M&amp;E proposed by Marcu and Echihabi (2002). Given a discourse instance Di, the probabilities: P(rk|(Di[1], Di[2])) for each relation rk were estimated on all text from XINHUA. Then, the most likely discourse relation was determined by taking the maximum over argmaxk{P(rk|(Di[1], Di[2])}. cSSR used both cue-phrase-based patterns together with common SSRs for recognizing discourse relations. Common SSRs were mined from discourse instances extracted from XINHUA using cuephrase-based patterns. Development data were randomly selected for tuning minconf. SVM was trained utilizing cue phrases, probabilities from M&amp;E, topic similarity, struct</context>
</contexts>
<marker>Marcu, Echihabi, 2002</marker>
<rawString>D. Marcu and A. Echihabi. 2002. An unsupervised approach to recognizing discourse relations. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 368--375. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Miltsakaki</author>
<author>R Prasad</author>
<author>A Joshi</author>
<author>B Webber</author>
</authors>
<title>The penn discourse treebank.</title>
<date>2004</date>
<booktitle>In Proceedings ofthe 4th International Conference on Language Resources and Evaluation. Citeseer.</booktitle>
<contexts>
<context position="10937" citStr="Miltsakaki et al., 2004" startWordPosition="1606" endWordPosition="1609">CUE1 and 2 means CUE2 Table 1: Examples of cue phrases 4 Methods The proposed methods were based on two assumptions: (1) Cue-phrase-based patterns could be used to find limited number of high quality discourse instances; (2) discourse relations were determined by lexical, structural and semantic information between two segments. Cue-phrase-based patterns could find only limited number of discourse instances with high precision (Marcu and Echihabi, 2002). Therefore, we could not rely on cue-phrase-based patterns alone. Moreover, there was no annotated corpus similar to Penn Discourse TreeBank (Miltsakaki et al., 2004) in other languages such as Chinese. Thus, we proposed a language independent unsupervised method to identify discourse relations without cue phrases while maintaining relatively high precision. For each discourse relation, we started with several cuephrase-based patterns and collected a large number of discourse instances from raw corpus. Then, discourse instances were converted to semantic sequential representations (SSRs). Finally, an unsupervised method was adopted to generate, weigh and filter common SSRs without cue phrases. The mined common SSRs could be directly used in our SSR-based c</context>
</contexts>
<marker>Miltsakaki, Prasad, Joshi, Webber, 2004</marker>
<rawString>E. Miltsakaki, R. Prasad, A. Joshi, and B. Webber. 2004. The penn discourse treebank. In Proceedings ofthe 4th International Conference on Language Resources and Evaluation. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
<author>S Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processingVolume 10,</booktitle>
<pages>79--86</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5452" citStr="Pang et al., 2002" startWordPosition="782" endWordPosition="785">t the proposed methods could effectively recognize the defined discourse relations and achieve significant improvement in sentence-level polarity classification comparing to BPC. The remainder of this paper is organized as follows. Section 2 introduces the related work. Section 3 presents the discourse scheme with discourse constraints on polarity. Section 4 gives the detail of proposed method. Experimental results are reported and discussed in Section 5 and Section 6 concludes this paper. 2 Related Work Research on polarity classification were generally conducted on 4 levels: document-level (Pang et al., 2002), sentence-level (Riloff et al., 2003), phraselevel (Wilson et al., 2009) and feature-level (Hu and Liu, 2004; Xia et al., 2007). There was little research focusing on the automatic recognition of intra-sentence level discourse relations for sentiment analysis in the literature. Polanyi and Zaenen (2006) argued that valence calculation is critically affected by discourse structure. Asher et al. (2008) proposed a shallow semantic representation using a feature structure and use five types of rhetorical relations to build a finegrained corpus for deep contextual sentiment analysis. Nevertheless,</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs up?: sentiment classification using machine learning techniques. In Proceedings of the ACL-02 conference on Empirical methods in natural language processingVolume 10, pages 79--86. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Polanyi</author>
<author>A Zaenen</author>
</authors>
<title>Contextual valence shifters. Computing attitude and affect in text: Theory and applications,</title>
<date>2006</date>
<pages>1--10</pages>
<contexts>
<context position="1560" citStr="Polanyi and Zaenen, 2006" startWordPosition="213" endWordPosition="216">ourse instances which were later converted to semantic sequential representations (SSRs). Finally, an unsupervised method was adopted to generate, weigh and filter new SSRs without cue phrases for recognizing discourse relations. Experimental results showed that the proposed methods not only effectively recognized the defined discourse relations but also achieved significant improvement by integrating discourse information in sentence-level polarity classification. 1 Introduction As an important task of sentiment analysis, polarity classification is critically affected by discourse structure (Polanyi and Zaenen, 2006). Previous research developed discourse schema (Asher et al., 2008) (Somasundaran et al., 2008) and proved that the utilization of discourse relations could improve the performance of polarity classification on dialogues (Somasundaran et al., 2009). However, cur1Defined as ambiguous sentences in this paper rent state-of-the-art methods for sentence-level polarity classification are facing difficulties in ascertaining the polarity of some sentences. For example: (a) [Although Fujimori was criticized by the international community],[he was loved by the domestic population], [because people hated</context>
<context position="5757" citStr="Polanyi and Zaenen (2006)" startWordPosition="828" endWordPosition="831">ourse scheme with discourse constraints on polarity. Section 4 gives the detail of proposed method. Experimental results are reported and discussed in Section 5 and Section 6 concludes this paper. 2 Related Work Research on polarity classification were generally conducted on 4 levels: document-level (Pang et al., 2002), sentence-level (Riloff et al., 2003), phraselevel (Wilson et al., 2009) and feature-level (Hu and Liu, 2004; Xia et al., 2007). There was little research focusing on the automatic recognition of intra-sentence level discourse relations for sentiment analysis in the literature. Polanyi and Zaenen (2006) argued that valence calculation is critically affected by discourse structure. Asher et al. (2008) proposed a shallow semantic representation using a feature structure and use five types of rhetorical relations to build a finegrained corpus for deep contextual sentiment analysis. Nevertheless, they did not propose a computational model for their discourse scheme. Snyder and Barzilay (2007) combined an agreement model based on contrastive RST relations with a local aspect model to make a more informed overall decision for sentiment classification. Nonetheless, contrastive relations were only o</context>
</contexts>
<marker>Polanyi, Zaenen, 2006</marker>
<rawString>L. Polanyi and A. Zaenen. 2006. Contextual valence shifters. Computing attitude and affect in text: Theory and applications, pages 1--10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>J Wiebe</author>
<author>T Wilson</author>
</authors>
<title>Learning subjective nouns using extraction pattern bootstrapping.</title>
<date>2003</date>
<booktitle>In Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003-Volume 4,</booktitle>
<pages>25--32</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5490" citStr="Riloff et al., 2003" startWordPosition="787" endWordPosition="790">vely recognize the defined discourse relations and achieve significant improvement in sentence-level polarity classification comparing to BPC. The remainder of this paper is organized as follows. Section 2 introduces the related work. Section 3 presents the discourse scheme with discourse constraints on polarity. Section 4 gives the detail of proposed method. Experimental results are reported and discussed in Section 5 and Section 6 concludes this paper. 2 Related Work Research on polarity classification were generally conducted on 4 levels: document-level (Pang et al., 2002), sentence-level (Riloff et al., 2003), phraselevel (Wilson et al., 2009) and feature-level (Hu and Liu, 2004; Xia et al., 2007). There was little research focusing on the automatic recognition of intra-sentence level discourse relations for sentiment analysis in the literature. Polanyi and Zaenen (2006) argued that valence calculation is critically affected by discourse structure. Asher et al. (2008) proposed a shallow semantic representation using a feature structure and use five types of rhetorical relations to build a finegrained corpus for deep contextual sentiment analysis. Nevertheless, they did not propose a computational </context>
</contexts>
<marker>Riloff, Wiebe, Wilson, 2003</marker>
<rawString>E. Riloff, J. Wiebe, and T. Wilson. 2003. Learning subjective nouns using extraction pattern bootstrapping. In Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003-Volume 4, pages 25--32. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sadamitsu</author>
<author>S Sekine</author>
<author>M Yamamoto</author>
</authors>
<title>Sentiment analysis based on probabilistic models using inter-sentence information.</title>
<date>2008</date>
<contexts>
<context position="6451" citStr="Sadamitsu et al. (2008)" startWordPosition="939" endWordPosition="942">ructure. Asher et al. (2008) proposed a shallow semantic representation using a feature structure and use five types of rhetorical relations to build a finegrained corpus for deep contextual sentiment analysis. Nevertheless, they did not propose a computational model for their discourse scheme. Snyder and Barzilay (2007) combined an agreement model based on contrastive RST relations with a local aspect model to make a more informed overall decision for sentiment classification. Nonetheless, contrastive relations were only one type of discourse relations which may help polarity classification. Sadamitsu et al. (2008) modeled polarity reversal using HCRFs integrated with inter-sentence discourse structures. However, our work is on intrasentence level and our purpose is not to find polarity reversals but trying to adapt general discourse schemes (e.g., RST) to help determine the overall polarity of ambiguous sentences. The most closely related works were (Somasundaran et al., 2008) and (Somasundaran et al., 2009), which proposed opinion frames as a representation of discourse-level associations on dialogue and modeled the scheme to improve opinion polarity classification. However, opinion frames was difficu</context>
</contexts>
<marker>Sadamitsu, Sekine, Yamamoto, 2008</marker>
<rawString>K. Sadamitsu, S. Sekine, and M. Yamamoto. 2008. Sentiment analysis based on probabilistic models using inter-sentence information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Snyder</author>
<author>R Barzilay</author>
</authors>
<title>Multiple aspect ranking using the good grief algorithm.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL HLT,</booktitle>
<pages>300--307</pages>
<contexts>
<context position="6150" citStr="Snyder and Barzilay (2007)" startWordPosition="890" endWordPosition="894">) and feature-level (Hu and Liu, 2004; Xia et al., 2007). There was little research focusing on the automatic recognition of intra-sentence level discourse relations for sentiment analysis in the literature. Polanyi and Zaenen (2006) argued that valence calculation is critically affected by discourse structure. Asher et al. (2008) proposed a shallow semantic representation using a feature structure and use five types of rhetorical relations to build a finegrained corpus for deep contextual sentiment analysis. Nevertheless, they did not propose a computational model for their discourse scheme. Snyder and Barzilay (2007) combined an agreement model based on contrastive RST relations with a local aspect model to make a more informed overall decision for sentiment classification. Nonetheless, contrastive relations were only one type of discourse relations which may help polarity classification. Sadamitsu et al. (2008) modeled polarity reversal using HCRFs integrated with inter-sentence discourse structures. However, our work is on intrasentence level and our purpose is not to find polarity reversals but trying to adapt general discourse schemes (e.g., RST) to help determine the overall polarity of ambiguous sen</context>
</contexts>
<marker>Snyder, Barzilay, 2007</marker>
<rawString>B. Snyder and R. Barzilay. 2007. Multiple aspect ranking using the good grief algorithm. In Proceedings of NAACL HLT, pages 300--307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Somasundaran</author>
<author>J Wiebe</author>
<author>J Ruppenhofer</author>
</authors>
<title>Discourse level opinion interpretation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics,</booktitle>
<pages>801--808</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="1655" citStr="Somasundaran et al., 2008" startWordPosition="227" endWordPosition="230">lly, an unsupervised method was adopted to generate, weigh and filter new SSRs without cue phrases for recognizing discourse relations. Experimental results showed that the proposed methods not only effectively recognized the defined discourse relations but also achieved significant improvement by integrating discourse information in sentence-level polarity classification. 1 Introduction As an important task of sentiment analysis, polarity classification is critically affected by discourse structure (Polanyi and Zaenen, 2006). Previous research developed discourse schema (Asher et al., 2008) (Somasundaran et al., 2008) and proved that the utilization of discourse relations could improve the performance of polarity classification on dialogues (Somasundaran et al., 2009). However, cur1Defined as ambiguous sentences in this paper rent state-of-the-art methods for sentence-level polarity classification are facing difficulties in ascertaining the polarity of some sentences. For example: (a) [Although Fujimori was criticized by the international community],[he was loved by the domestic population], [because people hated the corrupted ruling class]. (fitoft 國際間對藤森口誅筆伐,他在國內一直深受百姓愛 戴,原因是百姓對腐化的統治階級早就深惡痛絕。) Example (a</context>
<context position="6821" citStr="Somasundaran et al., 2008" startWordPosition="996" endWordPosition="1000">tive RST relations with a local aspect model to make a more informed overall decision for sentiment classification. Nonetheless, contrastive relations were only one type of discourse relations which may help polarity classification. Sadamitsu et al. (2008) modeled polarity reversal using HCRFs integrated with inter-sentence discourse structures. However, our work is on intrasentence level and our purpose is not to find polarity reversals but trying to adapt general discourse schemes (e.g., RST) to help determine the overall polarity of ambiguous sentences. The most closely related works were (Somasundaran et al., 2008) and (Somasundaran et al., 2009), which proposed opinion frames as a representation of discourse-level associations on dialogue and modeled the scheme to improve opinion polarity classification. However, opinion frames was difficult to be implemented because the recognition of opinion target was very challenging in general text. Our work differs from their approaches in two key aspects: (1) we distinguished nucleus and satellite in discourse but opinion frames did not; (2) our method for discourse discovery was unsupervised while their method needed annotated data. Most research works about di</context>
</contexts>
<marker>Somasundaran, Wiebe, Ruppenhofer, 2008</marker>
<rawString>S. Somasundaran, J. Wiebe, and J. Ruppenhofer. 2008. Discourse level opinion interpretation. In Proceedings of the 22nd International Conference on Computational Linguistics, pages 801--808. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Somasundaran</author>
<author>G Namata</author>
<author>J Wiebe</author>
<author>L Getoor</author>
</authors>
<title>Supervised and unsupervised methods in employing discourse relations for improving opinion polarity classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>170--179</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1808" citStr="Somasundaran et al., 2009" startWordPosition="249" endWordPosition="252">lts showed that the proposed methods not only effectively recognized the defined discourse relations but also achieved significant improvement by integrating discourse information in sentence-level polarity classification. 1 Introduction As an important task of sentiment analysis, polarity classification is critically affected by discourse structure (Polanyi and Zaenen, 2006). Previous research developed discourse schema (Asher et al., 2008) (Somasundaran et al., 2008) and proved that the utilization of discourse relations could improve the performance of polarity classification on dialogues (Somasundaran et al., 2009). However, cur1Defined as ambiguous sentences in this paper rent state-of-the-art methods for sentence-level polarity classification are facing difficulties in ascertaining the polarity of some sentences. For example: (a) [Although Fujimori was criticized by the international community],[he was loved by the domestic population], [because people hated the corrupted ruling class]. (fitoft 國際間對藤森口誅筆伐,他在國內一直深受百姓愛 戴,原因是百姓對腐化的統治階級早就深惡痛絕。) Example (a) is a positive sentence holding a Contrast relation between first two segments and a Cause relation between last two segments. The polarity of &amp;quot;criticiz</context>
<context position="6853" citStr="Somasundaran et al., 2009" startWordPosition="1002" endWordPosition="1005">aspect model to make a more informed overall decision for sentiment classification. Nonetheless, contrastive relations were only one type of discourse relations which may help polarity classification. Sadamitsu et al. (2008) modeled polarity reversal using HCRFs integrated with inter-sentence discourse structures. However, our work is on intrasentence level and our purpose is not to find polarity reversals but trying to adapt general discourse schemes (e.g., RST) to help determine the overall polarity of ambiguous sentences. The most closely related works were (Somasundaran et al., 2008) and (Somasundaran et al., 2009), which proposed opinion frames as a representation of discourse-level associations on dialogue and modeled the scheme to improve opinion polarity classification. However, opinion frames was difficult to be implemented because the recognition of opinion target was very challenging in general text. Our work differs from their approaches in two key aspects: (1) we distinguished nucleus and satellite in discourse but opinion frames did not; (2) our method for discourse discovery was unsupervised while their method needed annotated data. Most research works about discourse classification were not </context>
</contexts>
<marker>Somasundaran, Namata, Wiebe, Getoor, 2009</marker>
<rawString>S. Somasundaran, G. Namata, J. Wiebe, and L. Getoor. 2009. Supervised and unsupervised methods in employing discourse relations for improving opinion polarity classification. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170--179. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Soricut</author>
<author>D Marcu</author>
</authors>
<title>Sentence level discourse parsing using syntactic and lexical information.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,</booktitle>
<pages>149--156</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7552" citStr="Soricut and Marcu, 2003" startWordPosition="1106" endWordPosition="1109">iations on dialogue and modeled the scheme to improve opinion polarity classification. However, opinion frames was difficult to be implemented because the recognition of opinion target was very challenging in general text. Our work differs from their approaches in two key aspects: (1) we distinguished nucleus and satellite in discourse but opinion frames did not; (2) our method for discourse discovery was unsupervised while their method needed annotated data. Most research works about discourse classification were not related to sentiment analysis. Supervised discourse classification methods (Soricut and Marcu, 2003; Duverle and Prendinger, 2009) needed manually annotated data. Marcu and Echihabi (2002) presented an unsupervised method to recognize discourse relations held between arbitrary spans of text. They showed that lexical pairs extracted from massive amount of data can have a major impact on discourse classification. BlairGoldensohn et al. (2007) extended Marcu&apos;s work by using parameter opitimization, topic segmentation and syntactic parsing. However, syntactic parsers 163 were usually costly and impractical when dealing with large scale of text. Thus, in additional to lexical features, we incorp</context>
</contexts>
<marker>Soricut, Marcu, 2003</marker>
<rawString>R. Soricut and D. Marcu. 2003. Sentence level discourse parsing using syntactic and lexical information. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, pages 149--156. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>J Wiebe</author>
<author>P Hoffmann</author>
</authors>
<title>Recognizing Contextual Polarity: an exploration of features for phrase-level sentiment analysis.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>3</issue>
<contexts>
<context position="5525" citStr="Wilson et al., 2009" startWordPosition="793" endWordPosition="796">e relations and achieve significant improvement in sentence-level polarity classification comparing to BPC. The remainder of this paper is organized as follows. Section 2 introduces the related work. Section 3 presents the discourse scheme with discourse constraints on polarity. Section 4 gives the detail of proposed method. Experimental results are reported and discussed in Section 5 and Section 6 concludes this paper. 2 Related Work Research on polarity classification were generally conducted on 4 levels: document-level (Pang et al., 2002), sentence-level (Riloff et al., 2003), phraselevel (Wilson et al., 2009) and feature-level (Hu and Liu, 2004; Xia et al., 2007). There was little research focusing on the automatic recognition of intra-sentence level discourse relations for sentiment analysis in the literature. Polanyi and Zaenen (2006) argued that valence calculation is critically affected by discourse structure. Asher et al. (2008) proposed a shallow semantic representation using a feature structure and use five types of rhetorical relations to build a finegrained corpus for deep contextual sentiment analysis. Nevertheless, they did not propose a computational model for their discourse scheme. S</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2009</marker>
<rawString>T. Wilson, J. Wiebe, and P. Hoffmann. 2009. Recognizing Contextual Polarity: an exploration of features for phrase-level sentiment analysis. Computational Linguistics, 35(3):399--433.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Q Xia</author>
<author>R F Xu</author>
<author>K F Wong</author>
<author>F Zheng</author>
</authors>
<title>The unified collocation framework for opinion mining.</title>
<date>2007</date>
<booktitle>In International Conference on Machine Learning and Cybernetics,</booktitle>
<volume>2</volume>
<pages>844--850</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="5580" citStr="Xia et al., 2007" startWordPosition="803" endWordPosition="806">e-level polarity classification comparing to BPC. The remainder of this paper is organized as follows. Section 2 introduces the related work. Section 3 presents the discourse scheme with discourse constraints on polarity. Section 4 gives the detail of proposed method. Experimental results are reported and discussed in Section 5 and Section 6 concludes this paper. 2 Related Work Research on polarity classification were generally conducted on 4 levels: document-level (Pang et al., 2002), sentence-level (Riloff et al., 2003), phraselevel (Wilson et al., 2009) and feature-level (Hu and Liu, 2004; Xia et al., 2007). There was little research focusing on the automatic recognition of intra-sentence level discourse relations for sentiment analysis in the literature. Polanyi and Zaenen (2006) argued that valence calculation is critically affected by discourse structure. Asher et al. (2008) proposed a shallow semantic representation using a feature structure and use five types of rhetorical relations to build a finegrained corpus for deep contextual sentiment analysis. Nevertheless, they did not propose a computational model for their discourse scheme. Snyder and Barzilay (2007) combined an agreement model b</context>
</contexts>
<marker>Xia, Xu, Wong, Zheng, 2007</marker>
<rawString>Y.Q. Xia, R.F. Xu, K.F. Wong, and F. Zheng. 2007. The unified collocation framework for opinion mining. In International Conference on Machine Learning and Cybernetics, volume 2, pages 844--850. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Xu</author>
<author>C Kit</author>
</authors>
<title>Incorporating feature-based and similarity-based opinion mining--ctl in ntcir-8 moat.</title>
<date>2010</date>
<booktitle>In Proceedings ofthe 8th NTCIR Workshop,</booktitle>
<pages>276--281</pages>
<contexts>
<context position="3933" citStr="Xu and Kit, 2010" startWordPosition="554" endWordPosition="557">g sentence-level polarity classification methods ignoring discourse structure often give wrong results for these sentences. We implemented state-of-the2http://research.nii.ac.jp/ntcir/ 3Including simplified Chinese and traditional Chinese corpus from NTCIR-6 MOAT and NTCIR-7 MOAT 162 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 162–171, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics Figure 1: Discourse relations for Example (a). (n and s denote nucleus and satellite segment, respectively) art method (Xu and Kit, 2010) in NTCIR-8 Chinese MOAT as the baseline polarity classifier (BPC) in this paper. Error analysis of BPC showed that 49% errors came from ambiguous sentences. In this paper, we focused on the automation of recognizing intra-sentence level discourse relations for polarity classification. Based on the previous work of Rhetorical Structure Theory (RST) (Mann and Thompson, 1988), a discourse scheme with discourse constraints on polarity was defined empirically (see Section 3). The scheme contains 5 relations: Contrast, Condition, Continuation, Cause and Purpose. From a raw corpus, a small set of cu</context>
</contexts>
<marker>Xu, Kit, 2010</marker>
<rawString>R. Xu and C. Kit. 2010. Incorporating feature-based and similarity-based opinion mining--ctl in ntcir-8 moat. In Proceedings ofthe 8th NTCIR Workshop, pages 276--281.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>