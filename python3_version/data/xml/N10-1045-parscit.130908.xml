<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.029885">
<title confidence="0.976784">
Towards Cross-Lingual Textual Entailment
</title>
<author confidence="0.98856">
Yashar Mehdad&apos; 2, Matteo Negri&apos;, Marcello Federico&apos;
</author>
<affiliation confidence="0.994346">
FBK-Irst&apos;, University of Trento2
</affiliation>
<address confidence="0.602496">
Trento, Italy
</address>
<email confidence="0.999207">
{mehdad,negri,federico}@fbk.eu
</email>
<sectionHeader confidence="0.998601" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999766833333333">
This paper investigates cross-lingual textual
entailment as a semantic relation between two
text portions in different languages, and pro-
poses a prospective research direction. We
argue that cross-lingual textual entailment
(CLTE) can be a core technology for sev-
eral cross-lingual NLP applications and tasks.
Through preliminary experiments, we aim at
proving the feasibility of the task, and provid-
ing a reliable baseline. We also introduce new
applications for CLTE that will be explored in
future work.
</bodyText>
<sectionHeader confidence="0.999515" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99992905882353">
Textual Entailment (TE) (Dagan and Glickman,
2004) has been proposed as a generic framework for
modeling language variability. Given two texts T
and H, the task consists in deciding if the meaning
of H can be inferred from the meaning of T. So far,
TE has been only applied in a monolingual setting,
where both texts are assumed to be written in the
same language. In this work, we propose and inves-
tigate a cross-lingual extension of TE, where we as-
sume that T and H are written in different languages.
The great potential of integrating (monolingual)
TE recognition components into NLP architectures
has been reported in several works, such as ques-
tion answering (Harabagiu and Hickl, 2006), infor-
mation retrieval (Clinchant et al., 2006), informa-
tion extraction (Romano et al., 2006), and document
summarization (Lloret et al., 2008).
To the best of our knowledge, mainly due to
the absence of cross-lingual TE (CLTE) recognition
components, similar improvements have not been
achieved yet in any cross-lingual application. As
a matter of fact, despite the great deal of attention
that TE has received in recent years (also witnessed
by five editions of the Recognizing Textual Entail-
ment Challenge1), interest for cross-lingual exten-
sions has not been in the mainstream of TE research,
which until now has been mainly focused on the En-
glish language.
Nevertheless, the strong interest towards cross-
lingual NLP applications (both from the market and
research perspectives, as demonstrated by success-
ful evaluation campaigns such as CLEF2) is, to our
view, a good reason to start investigating CLTE, as
well. Along such direction, research can now ben-
efit from recent advances in other fields, especially
machine translation (MT), and the availability of: i)
large amounts of parallel and comparable corpora in
many languages, ii) open source software to com-
pute word-alignments from parallel corpora, and iii)
open source software to set-up strong MT baseline
systems. We strongly believe that all these resources
can potentially help in developing inference mecha-
nisms on multilingual data.
Building on these considerations, this paper aims
to put the basis for future research on the cross-
lingual Textual Entailment task, in order to allow
for semantic inference across languages in different
NLP tasks. Among these, as a long-term goal, we
plan to adopt CLTE to support the alignment of text
portions that express the same meaning in different
languages. As a possible application scenario, CLTE
</bodyText>
<footnote confidence="0.9999775">
1http://pascallin.ecs.soton.ac.uk/Challenges/RTE/
2www.clef-campaign.org/
</footnote>
<page confidence="0.942902">
321
</page>
<subsubsectionHeader confidence="0.558542">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 321–324,
</subsubsectionHeader>
<subsectionHeader confidence="0.269463">
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.999768">
can be used to address content merging tasks in tidy
multilingual environments, such as commercial Web
sites, digital libraries, or user generated content col-
lections. Within such framework, as it will be dis-
cussed in the last section of this paper, CLTE com-
ponents can be used for automatic content synchro-
nization in a concurrent, collaborative, and multilin-
gual editing setting, e.g. Wikipedia.
</bodyText>
<sectionHeader confidence="0.870827" genericHeader="method">
2 Cross Lingual Textual Entailment
</sectionHeader>
<bodyText confidence="0.999970691176471">
Adapting the definition of TE we define CLTE as
a relation between two natural language portions in
different languages, namely a text T (e.g. in En-
glish), and a hypothesis H (e.g. in French), that
holds if a human after reading T would infer that H
is most likely true, or otherwise stated, the meaning
of H can be entailed (inferred) from T.
We can see two main orthogonal directions for ap-
proaching CLTE: i) simply bring CLTE back to the
monolingual case by translating H into the language
of T, or vice-versa; ii) try to embed cross-lingual
processing techniques inside the TE recognition pro-
cess. In the following, we briefly overview and mo-
tivate each approach.
Basic approaches. The simplest approach is to
add a MT component to the front-end of an existing
TE engine. For instance, let the French hypothesis
H be translated into English and then run the TE en-
gine on T and the translation of H. There are sev-
eral good reasons to follow this divide-and-conquer
approach, as well as some drawbacks. Decoupling
the cross-lingual and the entailment components re-
sults in a simple and modular architecture that, ac-
cording to well known software engineering princi-
ples, results easier to develop, debug, and maintain.
Moreover, a decoupled CLTE architecture would al-
low for easy extensions to other languages as it just
requires extra MT systems. Along the same idea of
pivoting through English, in fact, the same TE sys-
tem can be employed to perform CLTE between any
language pair, once MT is available from each lan-
guage into English. A drawback of the decoupled
approach is that as MT is still far from being perfect,
translation errors are propagated to the TE engine
and might likely affect performance. To cope with
this issue, we explored the alternative approach of
applying TE on a list of n-best translations provided
by the MT engine, and take a final decision based on
some system combination criterion. This latter ap-
proach potentially reduces the impact of translation
errors, but might significantly increase the computa-
tional requirements of CLTE.
Advanced approaches. The idea is to move to-
wards a cross-lingual TE approach that takes advan-
tage of a tighter integration of MT and TE algo-
rithms and techniques. This could result in methods
for recognizing TE across languages without trans-
lating the texts and, in principle, with a lower com-
plexity. When dealing with phrase-based statistical
MT (Koehn et al., 2007), a possible approach is to
extract information from the phrase-table to enrich
the inference and entailment rules which could be
used in a distance based entailment system. As an
example the entailment relations between the French
phrase “ordinateur portable” and the English phrase
“laptop”, or between the German phrase “europaeis-
chen union” and the English word “Europe” could
be captured from parallel corpora through statistical
phrase-based MT approaches.
There are several implications that make this ap-
proach interesting. First of all, we believe that re-
search on CLTE can employ inference mechanisms
and semantic knowledge sources to augment exist-
ing MT methods, leading to improvements in the
translation quality (e.g. (Pad´o et al., 2009)). In
addition, the acquired rules could as well enrich
the available multilingual resources and dictionaries
such as MultiWordNet3.
</bodyText>
<sectionHeader confidence="0.991561" genericHeader="method">
3 Feasibility studies
</sectionHeader>
<bodyText confidence="0.999971">
The main purpose of our preliminary experiments is
to verify the feasibility of CLTE, as well as setting
baseline results to be further improved over time. To
this aim, we started by adopting the basic approach
previously discussed. In particular, starting from an
English/French corpus of T-H pairs, we automati-
cally translated each H fragment from French into
English.
Our decisions build on several motivations. First
of all, the reason for setting English and French
as a first language pair for experiments is to rely
on higher quality translation models, and larger
amounts of parallel data for future improvements.
</bodyText>
<footnote confidence="0.965943">
3http://multiwordnet.fbk.eu/
</footnote>
<page confidence="0.993903">
322
</page>
<bodyText confidence="0.999846511627907">
Second, the reason for translating the hypotheses is
that, according to the notion of TE, they are usually
shorter, less detailed, and barely complex in terms of
syntax and concepts with respect to the texts. This
makes them easier to translate preserving the origi-
nal meaning. Finally, from an application-oriented
perspective, working with English Ts seems more
promising due the richness of English data available
(e.g. in terms of language variability, and more de-
tailed elaboration of concepts). This increases the
probability to discover entailment relations with Hs
in other languages.
In order to create a realistic and standard setting,
we took advantage of the available RTE data, select-
ing the RTE3 development set and manually trans-
lating the hypotheses into French. Since the man-
ual translation requires trained translators, and due
to time and logistics constraints, we obtained 520
translated hypotheses (randomly selected from the
entire RTE3 development set) which built our bi-
lingual entailment corpus for evaluation.
In the initial step, following our basic approach,
we translated the French hypotheses to English us-
ing Google4 and Moses5. We trained a phrase-
base translation model using Europarl6 and News
Commentary parallel corpora in Moses, applying a
6-gram language model trained on the New York
Times portion of the English Gigaword corpus7.
As a TE engine , we used the EDITS8 package
(Edit Distance Textual Entailment Suite). This sys-
tem is an open source software package based on
edit distance algorithms, which computes the T-H
distance as the cost of the edit operations (i.e. in-
sertion, deletion and substitution) that are necessary
to transform T into H. By defining the edit distance
algorithm and a cost scheme (i.e. which defines the
costs of each edit operation), this package is able to
learn a distance model over a set of training pairs,
which is used to decide if an entailment relation
holds over each test pair.
In order to obtain a monolingual TE model, we
trained and tuned (Mehdad, 2009) our model on the
RTE3 test set, to reduce the overfitting bias, since
</bodyText>
<footnote confidence="0.9999522">
4http://translate.google.com
5http://www.statmt.org/moses/
6http://www.statmt.org/europarl/
7http://www.ldc.upenn.edu
8http://edits.fbk.eu/
</footnote>
<bodyText confidence="0.999863952380952">
our original data was created over the RTE3 devel-
opment set. Moreover, we used a set of lexical en-
tailment rules extracted from Wikipedia and Word-
Net, as described in (Mehdad et al., 2009). To be-
gin with, we used this model to classify the cre-
ated cross-lingual entailment corpus in three differ-
ent settings: 1) hypotheses translated by Google, 2)
hypotheses translated by Moses (1st best), and 3) the
original RTE3 monolingual English pairs.
Results reported in Table 1 show that using
Google as a translator, in comparison with the orig-
inal manually-created data, does not cause any drop
in performance. This confirms that merely trans-
lating the hypothesis using a very good translation
model (Google) is a feasible and promising direc-
tion for CLTE. Knowing that Google has one of the
best French-English translation models, the down-
trend of results using Moses translator, in contrast
with Google, is not out of our expectation. Trying
to bridge this gap brings us to the next round of
experiments, where we extracted the n-best trans-
</bodyText>
<table confidence="0.990208333333333">
Orig. Google Moses Moses Moses
1st best 30 best &gt; 0.4
Acc. 63.48 63.48 61.37 62.90 62.90
</table>
<tableCaption confidence="0.99992">
Table 1: Results comparison over 520 test pairs.
</tableCaption>
<bodyText confidence="0.999976333333333">
lations produced by Moses, to have a richer lexical
variability, beneficial for improving the TE recogni-
tion. The graph in Figure 1 shows an incremental
improvement when the n-best translated hypotheses
are used. Besides that, trying to reach a more mono-
tonic distribution of the results, we normalized the
ranking score (from 0 to 1) given by Moses, and in
each step we chose the first n results over a normal-
ized score. In this way, having the hypotheses with
the score of above 0.4, we achieved the highest accu-
racy of 62.9%. This is exactly equal to adopting the
30-best hypotheses translated by Moses. Using this
method, we could improve the performance up to
1.5% above the lst best results, achieving almost the
same level of performance obtained with Google.
</bodyText>
<sectionHeader confidence="0.950963" genericHeader="method">
4 A possible application scenario
</sectionHeader>
<bodyText confidence="0.99997825">
Among the many possible applications, the task of
managing textual information in multiple languages
represents an ideal application scenario for CLTE.
Along such direction, our long-term goal is to use
</bodyText>
<page confidence="0.998642">
323
</page>
<figureCaption confidence="0.999783">
Figure 1: Accuracy gained by n-best Moses translations.
</figureCaption>
<bodyText confidence="0.999894545454545">
CLTE components in the task of synchronizing the
content of documents about the same topic (e.g.
Wikipedia articles), written in different languages.
Currently, multilingual Wikis rely on users to manu-
ally translate different Wiki pages on the same sub-
ject. This is not only a time-consuming procedure
but also the source of many inconsistencies, as users
update the different language versions separately,
and every update would require translators to com-
pare the different language versions and synchronize
the updates. Our goal is to automate this process
by integrating MT and CLTE in a two-step process
where: i) CLTE is used to identify text portions that
should “migrate” from one page to the other, and ii)
MT is used to actually translate these portions in the
appropriate target language.
The adoption of entailment-based techniques to
address the multilingual content synchronization
task looks promising, as several issues inherent to
such task can be formalized as TE-related problems.
Given two pages (P1 and P2), these issues include
identifying (and then properly managing):
</bodyText>
<listItem confidence="0.946867769230769">
1. Text portions in P1 and P2 that express exactly
the same meaning (bi-directional entailment, or se-
mantic equivalence) and which should not migrate
across pages;
2. Text portions in P1 that are more specific than
portions of P2 (unidirectional entailment between
P2 and P1 or vice-versa) and should replace them;
3. Text portions in P1 describing facts that are not
present in P2, and which should be added in P2 or
vice-versa (the “unknown” cases in RTE parlance);
4. Meaning discrepancies between text portions
in P1 and text portions in P2 (“contradictions” in
RTE parlance).
</listItem>
<sectionHeader confidence="0.997855" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999955636363636">
This paper presented a preliminary investigation to-
wards cross-lingual Textual Entailment, focusing on
possible research directions and alternative method-
ologies. Baseline results have been provided to
demonstrate the potentialities of a simple approach
that integrates MT and monolingual TE compo-
nents. Overall, our work sets a novel framework
for further studies and experiments to improve cross-
lingual NLP tasks. In particular, CLTE can be scaled
to more complex problems, such as cross-lingual
content merging and synchronization.
</bodyText>
<sectionHeader confidence="0.999506" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999411">
This work has been partially supported by the EC-
funded project CoSyne (FP7-ICT-4-24853)
</bodyText>
<sectionHeader confidence="0.99943" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9994501">
S. Clinchant, C. Goutte, and E. Gaussier. 2006. Lex-
ical entailment for information retrieval. In Proc.
ECIR’06.
I. Dagan and O. Glickman. 2004. Probabilistic tex-
tual entailment: Generic applied modeling of language
variability. Proc. of the PASCAL Workshop of Learn-
ing Methods for Text Understanding and Mining.
S. Harabagiu and A. Hickl. 2006. Methods for using tex-
tual entailment in open-domain question answering.
In Proc. COLING/ACL 2006.
P. Koehn et al. 2007. Moses: Open source toolkit for
statistical machine translation. In Proc. ACL07 Demo
and Poster Sessions.
E. Lloret, ´O. Ferr´andez, R. Mu˜noz, and M. Palomar.
2008. A text summarization approach under the in-
fluence of textual entailment. In Proc. NLPCS 2008.
Y. Mehdad, M. Negri, E. Cabrio, M. Kouylekov, and
B. Magnini. 2009. Edits: An open source framework
for recognizing textual entailment. In Proc. TAC 2009.
To appear.
Yashar Mehdad. 2009. Automatic cost estimation for
tree edit distance using particle swarm optimization.
In Proc. ACL ’09.
S. Pad´o, M. Galley, D. Jurafsky, and C. D. Manning.
2009. Textual entailment features for machine trans-
lation evaluation. In Proc. StatMT ’09.
L. Romano, M. Kouylekov, I. Szpektor, I. Dagan, and
A. Lavelli. 2006. Investigating a generic paraphrase-
based approach for relation extraction. In Proc. EACL
2006.
</reference>
<page confidence="0.999023">
324
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.489901">
<title confidence="0.9996">Towards Cross-Lingual Textual Entailment</title>
<author confidence="0.999901">Matteo Marcello</author>
<affiliation confidence="0.999753">University of</affiliation>
<address confidence="0.512847">Trento,</address>
<abstract confidence="0.996524615384615">paper investigates textual a semantic relation between two text portions in different languages, and proposes a prospective research direction. We argue that cross-lingual textual entailment (CLTE) can be a core technology for several cross-lingual NLP applications and tasks. Through preliminary experiments, we aim at proving the feasibility of the task, and providing a reliable baseline. We also introduce new applications for CLTE that will be explored in future work.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Clinchant</author>
<author>C Goutte</author>
<author>E Gaussier</author>
</authors>
<title>Lexical entailment for information retrieval.</title>
<date>2006</date>
<booktitle>In Proc. ECIR’06.</booktitle>
<contexts>
<context position="1442" citStr="Clinchant et al., 2006" startWordPosition="218" endWordPosition="221">iability. Given two texts T and H, the task consists in deciding if the meaning of H can be inferred from the meaning of T. So far, TE has been only applied in a monolingual setting, where both texts are assumed to be written in the same language. In this work, we propose and investigate a cross-lingual extension of TE, where we assume that T and H are written in different languages. The great potential of integrating (monolingual) TE recognition components into NLP architectures has been reported in several works, such as question answering (Harabagiu and Hickl, 2006), information retrieval (Clinchant et al., 2006), information extraction (Romano et al., 2006), and document summarization (Lloret et al., 2008). To the best of our knowledge, mainly due to the absence of cross-lingual TE (CLTE) recognition components, similar improvements have not been achieved yet in any cross-lingual application. As a matter of fact, despite the great deal of attention that TE has received in recent years (also witnessed by five editions of the Recognizing Textual Entailment Challenge1), interest for cross-lingual extensions has not been in the mainstream of TE research, which until now has been mainly focused on the Eng</context>
</contexts>
<marker>Clinchant, Goutte, Gaussier, 2006</marker>
<rawString>S. Clinchant, C. Goutte, and E. Gaussier. 2006. Lexical entailment for information retrieval. In Proc. ECIR’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>O Glickman</author>
</authors>
<title>Probabilistic textual entailment: Generic applied modeling of language variability.</title>
<date>2004</date>
<booktitle>Proc. of the PASCAL Workshop of Learning Methods for Text Understanding and Mining.</booktitle>
<contexts>
<context position="752" citStr="Dagan and Glickman, 2004" startWordPosition="100" endWordPosition="103">rento, Italy {mehdad,negri,federico}@fbk.eu Abstract This paper investigates cross-lingual textual entailment as a semantic relation between two text portions in different languages, and proposes a prospective research direction. We argue that cross-lingual textual entailment (CLTE) can be a core technology for several cross-lingual NLP applications and tasks. Through preliminary experiments, we aim at proving the feasibility of the task, and providing a reliable baseline. We also introduce new applications for CLTE that will be explored in future work. 1 Introduction Textual Entailment (TE) (Dagan and Glickman, 2004) has been proposed as a generic framework for modeling language variability. Given two texts T and H, the task consists in deciding if the meaning of H can be inferred from the meaning of T. So far, TE has been only applied in a monolingual setting, where both texts are assumed to be written in the same language. In this work, we propose and investigate a cross-lingual extension of TE, where we assume that T and H are written in different languages. The great potential of integrating (monolingual) TE recognition components into NLP architectures has been reported in several works, such as ques</context>
</contexts>
<marker>Dagan, Glickman, 2004</marker>
<rawString>I. Dagan and O. Glickman. 2004. Probabilistic textual entailment: Generic applied modeling of language variability. Proc. of the PASCAL Workshop of Learning Methods for Text Understanding and Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Harabagiu</author>
<author>A Hickl</author>
</authors>
<title>Methods for using textual entailment in open-domain question answering.</title>
<date>2006</date>
<booktitle>In Proc. COLING/ACL</booktitle>
<contexts>
<context position="1394" citStr="Harabagiu and Hickl, 2006" startWordPosition="211" endWordPosition="214">ed as a generic framework for modeling language variability. Given two texts T and H, the task consists in deciding if the meaning of H can be inferred from the meaning of T. So far, TE has been only applied in a monolingual setting, where both texts are assumed to be written in the same language. In this work, we propose and investigate a cross-lingual extension of TE, where we assume that T and H are written in different languages. The great potential of integrating (monolingual) TE recognition components into NLP architectures has been reported in several works, such as question answering (Harabagiu and Hickl, 2006), information retrieval (Clinchant et al., 2006), information extraction (Romano et al., 2006), and document summarization (Lloret et al., 2008). To the best of our knowledge, mainly due to the absence of cross-lingual TE (CLTE) recognition components, similar improvements have not been achieved yet in any cross-lingual application. As a matter of fact, despite the great deal of attention that TE has received in recent years (also witnessed by five editions of the Recognizing Textual Entailment Challenge1), interest for cross-lingual extensions has not been in the mainstream of TE research, wh</context>
</contexts>
<marker>Harabagiu, Hickl, 2006</marker>
<rawString>S. Harabagiu and A. Hickl. 2006. Methods for using textual entailment in open-domain question answering. In Proc. COLING/ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. ACL07 Demo</booktitle>
<marker>Koehn, 2007</marker>
<rawString>P. Koehn et al. 2007. Moses: Open source toolkit for statistical machine translation. In Proc. ACL07 Demo and Poster Sessions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Lloret</author>
<author>´O Ferr´andez</author>
<author>R Mu˜noz</author>
<author>M Palomar</author>
</authors>
<title>A text summarization approach under the influence of textual entailment.</title>
<date>2008</date>
<booktitle>In Proc. NLPCS</booktitle>
<marker>Lloret, Ferr´andez, Mu˜noz, Palomar, 2008</marker>
<rawString>E. Lloret, ´O. Ferr´andez, R. Mu˜noz, and M. Palomar. 2008. A text summarization approach under the influence of textual entailment. In Proc. NLPCS 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mehdad</author>
<author>M Negri</author>
<author>E Cabrio</author>
<author>M Kouylekov</author>
<author>B Magnini</author>
</authors>
<title>Edits: An open source framework for recognizing textual entailment.</title>
<date>2009</date>
<booktitle>In Proc. TAC</booktitle>
<note>To appear.</note>
<contexts>
<context position="10341" citStr="Mehdad et al., 2009" startWordPosition="1621" endWordPosition="1624">e is able to learn a distance model over a set of training pairs, which is used to decide if an entailment relation holds over each test pair. In order to obtain a monolingual TE model, we trained and tuned (Mehdad, 2009) our model on the RTE3 test set, to reduce the overfitting bias, since 4http://translate.google.com 5http://www.statmt.org/moses/ 6http://www.statmt.org/europarl/ 7http://www.ldc.upenn.edu 8http://edits.fbk.eu/ our original data was created over the RTE3 development set. Moreover, we used a set of lexical entailment rules extracted from Wikipedia and WordNet, as described in (Mehdad et al., 2009). To begin with, we used this model to classify the created cross-lingual entailment corpus in three different settings: 1) hypotheses translated by Google, 2) hypotheses translated by Moses (1st best), and 3) the original RTE3 monolingual English pairs. Results reported in Table 1 show that using Google as a translator, in comparison with the original manually-created data, does not cause any drop in performance. This confirms that merely translating the hypothesis using a very good translation model (Google) is a feasible and promising direction for CLTE. Knowing that Google has one of the b</context>
</contexts>
<marker>Mehdad, Negri, Cabrio, Kouylekov, Magnini, 2009</marker>
<rawString>Y. Mehdad, M. Negri, E. Cabrio, M. Kouylekov, and B. Magnini. 2009. Edits: An open source framework for recognizing textual entailment. In Proc. TAC 2009. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
</authors>
<title>Automatic cost estimation for tree edit distance using particle swarm optimization.</title>
<date>2009</date>
<booktitle>In Proc. ACL ’09.</booktitle>
<contexts>
<context position="9942" citStr="Mehdad, 2009" startWordPosition="1571" endWordPosition="1572">tance Textual Entailment Suite). This system is an open source software package based on edit distance algorithms, which computes the T-H distance as the cost of the edit operations (i.e. insertion, deletion and substitution) that are necessary to transform T into H. By defining the edit distance algorithm and a cost scheme (i.e. which defines the costs of each edit operation), this package is able to learn a distance model over a set of training pairs, which is used to decide if an entailment relation holds over each test pair. In order to obtain a monolingual TE model, we trained and tuned (Mehdad, 2009) our model on the RTE3 test set, to reduce the overfitting bias, since 4http://translate.google.com 5http://www.statmt.org/moses/ 6http://www.statmt.org/europarl/ 7http://www.ldc.upenn.edu 8http://edits.fbk.eu/ our original data was created over the RTE3 development set. Moreover, we used a set of lexical entailment rules extracted from Wikipedia and WordNet, as described in (Mehdad et al., 2009). To begin with, we used this model to classify the created cross-lingual entailment corpus in three different settings: 1) hypotheses translated by Google, 2) hypotheses translated by Moses (1st best)</context>
</contexts>
<marker>Mehdad, 2009</marker>
<rawString>Yashar Mehdad. 2009. Automatic cost estimation for tree edit distance using particle swarm optimization. In Proc. ACL ’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pad´o</author>
<author>M Galley</author>
<author>D Jurafsky</author>
<author>C D Manning</author>
</authors>
<title>Textual entailment features for machine translation evaluation.</title>
<date>2009</date>
<booktitle>In Proc. StatMT ’09.</booktitle>
<marker>Pad´o, Galley, Jurafsky, Manning, 2009</marker>
<rawString>S. Pad´o, M. Galley, D. Jurafsky, and C. D. Manning. 2009. Textual entailment features for machine translation evaluation. In Proc. StatMT ’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Romano</author>
<author>M Kouylekov</author>
<author>I Szpektor</author>
<author>I Dagan</author>
<author>A Lavelli</author>
</authors>
<title>Investigating a generic paraphrasebased approach for relation extraction.</title>
<date>2006</date>
<booktitle>In Proc. EACL</booktitle>
<contexts>
<context position="1488" citStr="Romano et al., 2006" startWordPosition="225" endWordPosition="228">sts in deciding if the meaning of H can be inferred from the meaning of T. So far, TE has been only applied in a monolingual setting, where both texts are assumed to be written in the same language. In this work, we propose and investigate a cross-lingual extension of TE, where we assume that T and H are written in different languages. The great potential of integrating (monolingual) TE recognition components into NLP architectures has been reported in several works, such as question answering (Harabagiu and Hickl, 2006), information retrieval (Clinchant et al., 2006), information extraction (Romano et al., 2006), and document summarization (Lloret et al., 2008). To the best of our knowledge, mainly due to the absence of cross-lingual TE (CLTE) recognition components, similar improvements have not been achieved yet in any cross-lingual application. As a matter of fact, despite the great deal of attention that TE has received in recent years (also witnessed by five editions of the Recognizing Textual Entailment Challenge1), interest for cross-lingual extensions has not been in the mainstream of TE research, which until now has been mainly focused on the English language. Nevertheless, the strong intere</context>
</contexts>
<marker>Romano, Kouylekov, Szpektor, Dagan, Lavelli, 2006</marker>
<rawString>L. Romano, M. Kouylekov, I. Szpektor, I. Dagan, and A. Lavelli. 2006. Investigating a generic paraphrasebased approach for relation extraction. In Proc. EACL 2006.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>