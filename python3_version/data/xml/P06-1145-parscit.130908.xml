<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000031">
<title confidence="0.995519">
Time Period Identification of Events in Text
</title>
<author confidence="0.99738">
Taichi Noro† Takashi Inui†† Hiroya Takamura‡ Manabu Okumura‡
</author>
<affiliation confidence="0.955593">
†Interdisciplinary Graduate School of Science and Engineering
Tokyo Institute of Technology
4259 Nagatsuta-cho, Midori-ku, Yokohama, Kanagawa, Japan
††Japan Society for the Promotion of Science
‡Precision and Intelligence Laboratory, Tokyo Institute of Technology
</affiliation>
<email confidence="0.987742">
{norot, tinui}@lr.pi.titech.ac.jp,{takamura, oku}@pi.titech.ac.jp
</email>
<sectionHeader confidence="0.998598" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999939772727273">
This study aims at identifying when an
event written in text occurs. In particular,
we classify a sentence for an event into
four time-slots; morning, daytime, eve-
ning, and night. To realize our goal, we
focus on expressions associated with
time-slot (time-associated words). How-
ever, listing up all the time-associated
words is impractical, because there are
numerous time-associated expressions.
We therefore use a semi-supervised
learning method, the Naïve Bayes classi-
fier backed up with the Expectation
Maximization algorithm, in order to it-
eratively extract time-associated words
while improving the classifier. We also
propose to use Support Vector Machines
to filter out noisy instances that indicates
no specific time period. As a result of ex-
periments, the proposed method achieved
0.864 of accuracy and outperformed
other methods.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999916307692308">
In recent years, the spread of the internet has ac-
celerated. The documents on the internet have
increased their importance as targets of business
marketing. Such circumstances have evoked
many studies on information extraction from text
especially on the internet, such as sentiment
analysis and extraction of location information.
In this paper, we focus on the extraction of tem-
poral information. Many authors of documents
on the web often write about events in their daily
life. Identifying when the events occur provides
us valuable information. For example, we can
use temporal information as a new axis in the
information retrieval. From time-annotated text,
companies can figure out when customers use
their products. We can explore activities of users
for marketing researches, such as “What do
people eat in the morning?”, “What do people
spend money for in daytime?”
Most of previous work on temporal processing
of events in text dealt with only newswire text. In
those researches, it is assumed that temporal ex-
pressions indicating the time-period of events are
often explicitly written in text. Some examples of
explicit temporal expressions are as follows: “on
March 23”, “at 7 p.m.”.
However, other types of text including web
diaries and blogs contain few explicit temporal
expressions. Therefore one cannot acquire suffi-
cient temporal information using existing meth-
ods. Although dealing with such text as web dia-
ries and blogs is a hard problem, those types of
text are excellent information sources due to
their overwhelmingly huge amount.
In this paper, we propose a method for estimat-
ing occurrence time of events expressed in in-
formal text. In particular, we classify sentences
in text into one of four time-slots; morning, day-
time, evening, and night. To realize our goal, we
focus on expressions associated with time-slot
(hereafter, called time-associated words), such as
“commute (morning)”, “nap (daytime)” and
“cocktail (night)”. Explicit temporal expressions
have more certain information than the time-
associated words. However, these expressions
are rare in usual text. On the other hand, al-
though the time-associated words provide us
only indirect information for estimating occur-
rence time of events, these words frequently ap-
pear in usual text. Actually, Figure 2 (we will
discuss the graph in Section 5.2, again) shows
the number of sentences including explicit tem-
</bodyText>
<page confidence="0.870992">
1153
</page>
<note confidence="0.5221505">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1153–1160,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999900806451613">
poral expressions and time-associated words re-
spectively in text. The numbers are obtained
from a corpus we used in this paper. We can fig-
ure out that there are much more time-associated
words than explicit temporal expressions in blog
text. In other words, we can deal with wide cov-
erage of sentences in informal text by our
method with time-associated words.
However, listing up all the time-associated
words is impractical, because there are numerous
time-associated expressions. Therefore, we use a
semi-supervised method with a small amount of
labeled data and a large amount of unlabeled data,
because to prepare a large quantity of labeled
data is costly, while unlabeled data is easy to ob-
tain. Specifically, we adopt the Naïve Bayes
classifier backed up with the Expectation Maxi-
mization (EM) algorithm (Dempster et al., 1977)
for semi-supervised learning. In addition, we
propose to use Support Vector Machines to filter
out noisy sentences that degrade the performance
of the semi-supervised method.
In our experiments using blog data, we ob-
tained 0.864 of accuracy, and we have shown
effectiveness of the proposed method.
This paper is organized as follows. In Section
2 we briefly describe related work. In Section 3
we describe the details of our corpus. The pro-
posed method is presented in Section 4. In Sec-
tion 5, we describe experimental results and dis-
cussions. We conclude the paper in Section 6.
</bodyText>
<sectionHeader confidence="0.999893" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9999219">
The task of time period identification is new
and has not been explored much to date.
Setzer et al. (2001) and Mani et al. (2000)
aimed at annotating newswire text for analyzing
temporal information. However, these previous
work are different from ours, because these work
only dealt with newswire text including a lot of
explicit temporal expressions.
Tsuchiya et al. (2005) pursued a similar goal
as ours. They manually prepared a dictionary
with temporal information. They use the hand-
crafted dictionary and some inference rules to
determine the time periods of events. In contrast,
we do not resort to such a hand-crafted material,
which requires much labor and cost. Our method
automatically acquires temporal information
from actual data of people&apos;s activities (blog).
Henceforth, we can get temporal information
associated with your daily life that would be not
existed in a dictionary.
</bodyText>
<sectionHeader confidence="0.993486" genericHeader="method">
3 Corpus
</sectionHeader>
<bodyText confidence="0.9999666">
In this section, we describe a corpus made from
blog entries. The corpus is used for training and
test data of machine learning methods mentioned
in Section 4.
The blog entries we used are collected by the
method of Nanno et al. (2004). All the entries are
written in Japanese. All the entries are split into
sentences automatically by some heuristic rules.
In the next section, we are going to explain
“time-slot” tag added at every sentence.
</bodyText>
<subsectionHeader confidence="0.996723">
3.1 Time-Slot Tag
</subsectionHeader>
<bodyText confidence="0.967697413793103">
The “time-slot” tag represents when an event
occurs in five classes; “morning”, “daytime”,
“evening”, “night”, and “time-unknown”. “Time-
unknown” means that there is no temporal in-
formation. We set the criteria of time-slot tags as
follows.
Morning: 04:00--10:59
from early morning till before noon, breakfast
Daytime: 11:00--15:59
from noon till before dusk, lunch
Evening: 16:00--17:59
from dusk till before sunset
Night: 18:00--03:59
from sunset till dawn, dinner
Note that above criteria are just interpreted as
rough standards. We think time-slot recognized
by authors is more important. For example, in a
case of “about 3 o&apos;clock this morning” we judge
the case as “morning” (not “night”) with the ex-
pression written by the author “this morning”.
To annotate sentences in text, we used two dif-
ferent clues. One is the explicit temporal expres-
sions or time-associated words included in the
sentence to be judged. The other is contextual
information around the sentences to be judged.
The examples corresponding to the former case
are as follows:
Example 1
a. I went to post office by bicycle in the morning.
</bodyText>
<listItem confidence="0.5966685">
b. I had spaghetti at restaurant at noon.
c. I cooked stew as dinner on that day.
</listItem>
<bodyText confidence="0.999529625">
Suppose that the two sentences in Example 2
appear successively in a document. In this case,
we first judge the first sentence as morning. Next,
we judge the second sentence as morning by con-
textual information (i.e., the preceding sentence
is judged as morning), although we cannot know
the time period just from the content of the sec-
ond sentence itself.
</bodyText>
<page confidence="0.975493">
1154
</page>
<bodyText confidence="0.785115">
Example 2 4.2 Naïve Bayes Classifier
</bodyText>
<listItem confidence="0.5455375">
1. I went to X by bicycle in the morning. In this section, we describe multinomial model
2. I went to a shop on the way back from X. that is a kind of Naïve Bayes classifiers.
</listItem>
<bodyText confidence="0.945001">
A generative probability of example x given a
category c has the form:
</bodyText>
<equation confidence="0.99717">
x  |c,θ)= P(x)x!∏ P(w  |c)N(w,x) (1)
w N(w, x)
</equation>
<bodyText confidence="0.99983125">
where P(x ) denotes the probability that a sen-
tence of length x occurs, N(w,x) denotes the
number of occurrences of w in text x. The oc-
currence of a sentence is modeled as a set of tri-
als, in which a word is drawn from the whole
vocabulary.
In time-slot classification, the x is correspond
to each sentence, the c is correspond to one of
time-slots in {morning, daytime, evening, night}.
Features are words in the sentence. A detailed
description of features will be described in Sec-
tion 4.5.
</bodyText>
<subsectionHeader confidence="0.998415">
4.3 Incorporation of Unlabeled Data with
3.2 Corpus Statistics
</subsectionHeader>
<bodyText confidence="0.995924">
We manually annotated the corpus. The number
of the blog entries is 7,413. The number of sen-
tences is 70,775. Of 70,775, the number of sen-
tences representing any events1 is 14,220. The
frequency distribution of time-slot tags is shown
in Table 1. We can figure out that the number of
time-unknown sentences is much larger than the
other sentences from this table. This bias would
affect our classification process. Therefore, we
propose a method for tackling the problem.
</bodyText>
<figure confidence="0.983502857142857">
morning 711
daytime 599
evening 207
night 1,035
time-unknown 11,668
Total 14,220
P(
</figure>
<tableCaption confidence="0.989229">
Table 1: The numbers of time-slot tags.
</tableCaption>
<sectionHeader confidence="0.980674" genericHeader="method">
4 Proposed Method
</sectionHeader>
<subsectionHeader confidence="0.99583">
4.1 Basic Idea
</subsectionHeader>
<bodyText confidence="0.987851242424242">
Suppose, for example, “breakfast” is a strong
clue for the morning class, i.e. the word is a
time-associated word of morning. Thereby we
can classify the sentence “I have cereal for
breakfast.” into the morning class. Then “cereal”
will be a time-associated word of morning.
Therefore we can use “cereal” as a clue of time-
slot classification. By iterating this process, we
can obtain a lot of time-associated words with
bootstrapping method, improving sentence clas-
sification performance at the same time.
To realize the bootstrapping method, we use
the EM algorithm. This algorithm has a theoreti-
cal base of likelihood maximization of incom-
plete data and can enhance supervised learning
methods. We specifically adopted the combina-
tion of the Naïve Bayes classifier and the EM
algorithm. This combination has been proven to
be effective in the text classification (Nigam et
al., 2000).
1 The aim of this study is time-slot classification of
events. Therefore we treat only sentences expressing
an event.
the EM Algorithm
The EM algorithm (Dempster et al., 1977) is a
method to estimate a model that has the maximal
likelihood of the data when some variables can-
not be observed (these variables are called latent
variables). Nigam et al. (2000) proposed a com-
bination of the Naïve Bayes classifiers and the
EM algorithm.
Ignoring the unrelated factors of Eq. (1), we
obtain
</bodyText>
<equation confidence="0.98670025">
P(x  |c,θ)∝ ∏ P(w  |c)N(w,x), (2)
w
P(x |θ) ∝ ∑ P(cf j P(w  |c)N(w,x). (3)
c w
</equation>
<bodyText confidence="0.999519166666667">
We express model parameters as θ .
If we regard c as a latent variable and intro-
duce a Dirichlet distribution as the prior distribu-
tion for the parameters, the Q-function (i.e., the
expected log-likelihood) of this model is defined
as:
</bodyText>
<equation confidence="0.998632">
Q(θ |θ)= log(P(θ))+ ∑ ∑ P(x  |c, θ)×
xD c
∈ (4)
P(c)∏ P(w  |c)N(w,x)1
w ⎠,
</equation>
<bodyText confidence="0.9977608">
where P(θ)∝∏c(P (cY−1∏w( (w |c)α−1)) . α is a
user given parameter and D is the set of exam-
ples used for model estimation.
We obtain the next EM equation from this Q-
function:
</bodyText>
<equation confidence="0.632995333333333">
⎛ ⎜
⎝
log
</equation>
<page confidence="0.828432">
1155
</page>
<figureCaption confidence="0.999901">
Figure 1: The flow of 2-step classification.
</figureCaption>
<figure confidence="0.8345371">
time-slot = time-unknown
NB + EM
time-slot = morning, daytime, evening, night, time-unknown
Step 2
Time-Slot
Classifier
Step1
Time-Unknown
Filter
SVM
time-slot = morning, daytime, evening, night
time-slot = morning
time-slot = daytime
time-slot = night
time-slot = evening
⎞ ⎟
⎠
E-step: (5)
P(c  |x,θ)=∑c P((B +(xB)θ),
(7)
</figure>
<bodyText confidence="0.9983766">
where C denotes the number of categories, W
denotes the number of features variety. For la-
beled example x , Eq. (5) is not used. Instead,
P(c  |x, θ) is set as 1.0 if c is the category of x,
otherwise 0.
Instead of the usual EM algorithm, we use the
tempered EM algorithm (Hofmann, 2001). This
algorithm allows coordinating complexity of the
model. We can realize this algorithm by substi-
tuting the next equation for Eq. (5) at E-step:
</bodyText>
<equation confidence="0.9986825">
P(c  |x, θ)= {  |θHx  |c, θ)Y (8)
∑cHc  |θ)P(x  |c, θ)r
</equation>
<bodyText confidence="0.999697545454545">
where β denotes a hyper parameter for coordi-
nating complexity of the model, and it is positive
value. By decreasing this hyper-parameter β , we
can reduce the influence of intermediate classifi-
cation results if those results are unreliable.
Too much influence by unlabeled data some-
times deteriorates the model estimation. There-
fore, we introduce a new hyper-parameter
λ(0≤ λ≤ 1) which acts as weight on unlabeled
data. We exchange the second term in the right-
hand-side of Eq. (4) for the next equation:
</bodyText>
<equation confidence="0.990419">
∑ ∑ P(c  |x, θ)logP(c)∏ P(w  |c)N(w,x)
x∈Dl c w
+ λ ∑ ∑ P(c  |x, θ)log⎜ P(c)∏ P(w  |c)N(w,x) ⎟
x∈Du c ⎝ w ⎠
</equation>
<bodyText confidence="0.991606222222222">
where l
D denotes labeled data, u
D denotes
unlabeled data. We can reduce the influence of
unlabeled data by decreasing the value of λ .
We derived new update rules from this new Q-
function. The EM computation stops when the
difference in values of the Q-function is smaller
than a threshold.
</bodyText>
<subsectionHeader confidence="0.997026">
4.4 Class Imbalance Problem
</subsectionHeader>
<bodyText confidence="0.999970043478261">
We have two problems with respect to “time-
unknown” tag.
The first problem is the class imbalance prob-
lem (Japkowicz 2000). The number of time-
unknown time-slot sentences is much larger than
that of the other sentences as shown in Table 1.
There are more than ten times as many time-
unknown time-slot sentences as the other sen-
tences.
Second, there are no time-associated words in
the sentences categorized into “time-unknown”.
Thus the feature distribution of time-unknown
time-slot sentences is remarkably different from
the others. It would be expected that they ad-
versely affect proposed method.
There have been some methodologies in order
to solve the class imbalance problem, such as
Zhang and Mani (2003), Fan et al. (1999) and
Abe et al. (2004). However, in our case, we have
to resolve the latter problem in addition to the
class imbalance problem. To deal with two prob-
lems above simultaneously and precisely, we
develop a cascaded classification procedure.
</bodyText>
<equation confidence="0.999332714285714">
PH= (α −1)+∑ .DP(c  |x,θ)
(α−1)C+D
P(w  |c)
(α −1)+∑.D P(c  |x, θX(w, x)
= (α−1)W+∑w∑.D P(c |x,θN(w, x)
M-step:
, (6)
</equation>
<page confidence="0.983943">
1156
</page>
<subsectionHeader confidence="0.956692">
4.5 Time-Slot Classification Method
</subsectionHeader>
<bodyText confidence="0.99772526923077">
It’s desirable to treat only “time-known” sen-
tences at NB+EM process to avoid the above-
mentioned problems. We prepare another classi-
fier for filtering time-unknown sentences before
NB+EM process for that purpose. Thus, we pro-
pose a classification method in 2 steps (Method
A). The flow of the 2-step classification is shown
in Figure 1. In this figure, ovals represent classi-
fiers, and arrows represent flow of data.
The first classifier (hereafter, “time-unknown”
filter) classifies sentences into two classes;
“time-unknown” and “time-known”. The “time-
known” class is a coarse class consisting of four
time-slots (morning, daytime, evening, and
night). We use Support Vector Machines as a
classifier. The features we used are all words
included in the sentence to be classified.
The second classifier (time-slot classifier)
classifies “time-known” sentences into four
classes. We use Naïve Bayes classifier backed up
with the Expectation Maximization (EM) algo-
rithm mentioned in Section 4.3.
The features for the time-slot classifier are
words, whose part of speech is noun or verb. The
set of these features are called NORMAL in the
rest of this paper. In addition, we use information
from the previous and the following sentences in
the blog entry. The words included in such sen-
tences are also used as features. The set of these
features are called CONTEXT. The features in
CONTEXT would be effective for estimating
time-slot of the sentences as mentioned in Ex-
ample2 in Section 3.1.
We also use a simple classifier (Method B) for
comparison. The Method B classifies all time-
slots (morning — night, time-unknown) sentences
at just one step. We use Naïve Bayes classifier
backed up with the Expectation Maximization
(EM) algorithm at this learning. The features are
words (whose part-of-speech is noun or verb)
included in the sentence to be classified.
validation. We used TinySVM2 software pack-
age for implementation. The soft margin parame-
ter is automatically estimated by 10-fold cross
validation with training data. The result is shown
in Table 2.
Table 2 clarified that the “time-unknown” fil-
ter achieved good performance; F-measure of
0.899. In addition, since we obtained a high re-
call (0.969), many of the noisy sentences will be
filtered out at this step and the classifier of the
second step is likely to perform well.
</bodyText>
<table confidence="0.9903545">
Accuracy 0.878
Precision 0.838
Recall 0.969
F-measure 0.899
</table>
<tableCaption confidence="0.930888">
Table 2: Classification result of
the time-unknown filter.
</tableCaption>
<subsubsectionHeader confidence="0.923124">
5.1.2 Time-Slot Classification
</subsubsectionHeader>
<bodyText confidence="0.9998747">
In step 2, we used “time-known” sentences clas-
sified by the unknown filter as test data. We con-
ducted a classification experiment by Naïve
Bayes classifier + the EM algorithm with 10-fold
cross validation. For unlabeled data, we used
64,782 sentences, which have no intersection
with the labeled data. The parameters, λ and β ,
are automatically estimated by 10-fold cross
validation with training data. The result is shown
in Table 3.
</bodyText>
<table confidence="0.600276333333333">
Method Accuracy
NORMAL CONTEXT
Explicit 0.109
Baseline 0.406
NB 0.567 0.464
NB + EM 0.673 0.670
</table>
<tableCaption confidence="0.998182">
Table 3: The result of time-slot classifier.
</tableCaption>
<sectionHeader confidence="0.98884" genericHeader="evaluation">
5 Experimental Results and Discussion
</sectionHeader>
<subsectionHeader confidence="0.893946">
5.1 Time-Slot Classifier with Time-
Associated Words
5.1.1 Time-Unknown Filter
</subsectionHeader>
<bodyText confidence="0.99845025">
We used 11.668 positive (time-unknown) sam-
ples and 2,552 negative (morning — night) sam-
ples. We conducted a classification experiment
by Support Vector Machines with 10-fold cross
</bodyText>
<footnote confidence="0.966881">
2 http://www.chasen.org/—taku/software/TinySVM
</footnote>
<page confidence="0.964608">
1157
</page>
<table confidence="0.9999055">
output of time-slot classifier sum
morning daytime evening night time-unknown
time-slot tag morning 332 14 1 37 327 711
daytime 30 212 1 44 312 599
evening 4 5 70 18 110 207
night 21 19 4 382 609 1035
time-unknown 85 66 13 203 11301 11668
sum 472 316 89 684 12659 14220
</table>
<tableCaption confidence="0.997324">
Table 4: Confusion matrix of output.
</tableCaption>
<table confidence="0.999540636363636">
morning daytime evening night
rank word p(c|w) word p(c|w) word p(c|w) word p(c|w)
1 this morning 0.729 noon 0.728 evening 0.750 last night 0.702
2 morning 0.673 early after noon 0.674 sunset 0.557 night 0.689
3 breakfast 0.659 afternoon 0.667 academy 0.448 fireworks 0.688
4 early morning 0.656 daytime 0.655 dusk 0.430 dinner 0.684
5 before noon 0.617 lunch 0.653 Hills 0.429 go to bed 0.664
6 compacted snow 0.603 lunch 0.636 run on 0.429 night 0.641
7 commute 0.561 lunch break 0.629 directions 0.429 bow 0.634
8 --- 0.541 lunch 0.607 pinecone 0.429 overtime 0.606
9 parade 0.540 noon 0.567 priest 0.428 year-end party 0.603
10 wake up 0.520 butterfly 0.558 sand beach 0.428 dinner 0.574
11 leave harbor 0.504 Chinese food 0.554 --- 0.413 beach 0.572
12 rise late 0.504 forenoon 0.541 Omori 0.413 cocktail 0.570
13 cargo work 0.504 breast-feeding 0.536 fan 0.413 me 0.562
14 alarm clock 0.497 nap 0.521 Haneda 0.412 Tomoyuki 0.560
15 --- 0.494 diaper 0.511 preview 0.402 return home 0.557
16 sunglow 0.490 Japanese food 0.502 cloud 0.396 close 0.555
17 wheel 0.479 star festival 0.502 Dominus 0.392 stay up late 0.551
18 wake up 0.477 hot noodle 0.502 slip 0.392 tonight 0.549
19 perm 0.474 pharmacy 0.477 tasting 0.391 night 0.534
20 morning paper 0.470 noodle 0.476 nest 0.386 every night 0.521
</table>
<tableCaption confidence="0.99918">
Table 5: Time-associated words examples.
</tableCaption>
<bodyText confidence="0.8900790625">
In Table 3, “Explicit” indicates the result by a
simple classifier based on regular expressions3
including explicit temporal expressions. The
baseline method classifies all sentences into
night because the number of night sentences is
the largest. The “CONTEXT” column shows the
results obtained by classifiers learned with the
features in CONTEXT in addition to the features
3 For example, we classify sentences matching follow-
ing regular expressions into morning class:
[(gozen)(gozen-no)(asa) (asa-no)(am)(AM)(am-
no)(AM-no)][456789(10)] ji, [(04)(05)(06)(07)(08)
(09)]ji, [(04)(05)(06)(07) (08) (09)]:[0-9]{2,2},
[456789(10)][(am)(AM)].
(“gozen”, “gozen‐no” means before noon. “asa”,
“asa-no” means morning. “ji” means o’clock.)
in NORMAL. The accuracy of the Explicit
method is lower than the baseline. This means
existing methods based on explicit temporal ex-
pressions cannot work well in blog text. The ac-
curacy of the method &apos;NB&apos; exceeds that of the
baseline by 16%. Furthermore, the accuracy of
the proposed method &apos;NB+EM&apos; exceeds that of
the &apos;NB&apos; by 11%. Thus, we figure out that using
unlabeled data improves the performance of our
time-slot classification.
In this experiment, unfortunately, CONTEXT
only deteriorated the accuracy. The time-slot tags
of the sentences preceding or following the target
sentence may still provide information to im-
prove the accuracy. Thus, we tried a sequential
tagging method for sentences, in which tags are
</bodyText>
<page confidence="0.986057">
1158
</page>
<bodyText confidence="0.99994652173913">
predicted in the order of their occurrence. The
predicted tags are used as features in the predic-
tion of the next tag. This type of sequential tag-
ging method regard as a chunking procedure
(Kudo and Matsumoto, 2000) at sentence level.
We conducted time-slot (five classes) classifica-
tion experiment, and tried forward tagging and
backward tagging, with several window sizes.
We used YamCha4, the multi-purpose text chun-
ker using Support Vector Machines, as an ex-
perimental tool. However, any tagging direction
and window sizes did not improve the perform-
ance of classification. Although a chunking
method has possibility of correctly classifying a
sequence of text units, it can be adversely biased
by the preceding or the following tag. The sen-
tences in blog used in our experiments would not
have a very clear tendency in order of tags. This
is why the chunking-method failed to improve
the performance in this task. We would like to
try other bias-free methods such as Conditional
Random Fields (Lafferty et al., 2001) for future
work.
</bodyText>
<subsubsectionHeader confidence="0.890534">
5.1.3 2-step Classification
</subsubsectionHeader>
<bodyText confidence="0.988017105263158">
Finally, we show an accuracy of the 2-step clas-
sifier (Method A) and compare it with those of
other classifiers in Table 6. The accuracies are
calculated with the equation:
# sentences with a time-slot tag value
.
In Table 6, the baseline method classifies all
sentences into time-unknown because the num-
ber of time-unknown sentences is the largest.
Accuracy of Method A (proposed method) is
higher than that of Method B (4.1% over). These
results show that time-unknown sentences ad-
versely affect the classifier learning, and 2-step
classification is an effective method.
Table 4 shows the confusion matrix corre-
sponding to the Method A (NORMAL). From
this table, we can see Method A works well for
classification of morning, daytime, evening, and
night, but has some difficulty in
</bodyText>
<footnote confidence="0.889121">
4 http://www.chasen.org/~taku/software/YamCha
</footnote>
<table confidence="0.924632666666667">
Method Conclusive accuracy
Explicit 0.833
Baseline 0.821
Method A (NORMAL) 0.864
Method A (CONTEXT) 0.862
Method B 0.823
</table>
<tableCaption confidence="0.9632965">
Table 6: Comparison of the methods for five
class classification
</tableCaption>
<figure confidence="0.6731755">
1 10 20 30 40 50 60 70 80 90 100
# time-associated words (N-best)
</figure>
<figureCaption confidence="0.5955844">
Figure 2: Change of # sentences that have time-
associated words: “Explicit” indicates the num-
ber of sentences including explicit temporal ex-
pressions, “NE-TIME” indicates the number of
sentences including NE-TIME tag.
</figureCaption>
<bodyText confidence="0.982576538461538">
classification of time-unknown. The 11.7% of
samples were wrongly classified into “night” or
“unknown”.
We briefly describe an error analysis. We
found that our classifier tends to wrongly classify
samples in which two or more events are written
in a sentence. The followings are examples:
Example 3
a. I attended a party last night, and I got back
on the first train in this morning because the
party was running over.
b. I bought a cake this morning, and ate it after
the dinner.
</bodyText>
<subsectionHeader confidence="0.998983">
5.2 Examples of Time-Associated Words
</subsectionHeader>
<bodyText confidence="0.998761">
Table 5 shows some time-associated words ob-
tained by the proposed method. The words are
sorted in the descending order of the value of
P(c  |w). Although some consist of two or three
words, their original forms in Japanese consist of
one word. There are some expressions appearing
more than once, such as “dinner”. Actually these
expressions have different forms in Japanese.
Meaningless (non-word) strings caused by mor-
</bodyText>
<figure confidence="0.902065083333333">
Explicit
NE-TIME
# sentences including time- 4000
associated words 3000
2000
1000
0
5000
# time-unknown sentences correctly classi-
fied by the time-unknown filter
# known sentences correctly classi-
+ fied by the time-slot classifier
</figure>
<page confidence="0.959548">
1159
</page>
<bodyText confidence="0.99980012">
phological analysis error are presented as the
symbol “---”. We obtained a lot of interesting
time-associated words, such as “commute (morn-
ing)”, “fireworks (night)”, and “cocktail (night)”.
Most words obtained are significantly different
from explicit temporal expressions and NE-
TIME expressions.
Figure 2 shows the number of sentences in-
cluding time-associated words in blog text. The
horizontal axis represents the number of time-
associated words. We sort the words in the de-
scending order of P(c  |w) and selected the top N
words. The vertical axis represents the number of
sentences including any N-best time-associated
words. We also show the number of sentences
including explicit temporal expressions, and the
number of sentences including NE-TIME tag
(Sekine and Isahara, 1999) for comparison. The
set of explicit temporal expressions was ex-
tracted by the method described in Section 5.1.2.
We used a Japanese linguistic analyzer “Cabo-
Cha 5 ” to obtain NE-TIME information. From
this graph, we can confirm that the number of
target sentences of our proposed method is larger
than that of existing methods.
</bodyText>
<sectionHeader confidence="0.999669" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999993">
In our study, we proposed a method for identify-
ing when an event in text occurs. We succeeded
in using a semi-supervised method, the Naïve
Bayes Classifier enhanced by the EM algorithm,
with a small amount of labeled data and a large
amount of unlabeled data. In order to avoid the
class imbalance problem, we used a 2-step classi-
fier, which first filters out time-unknown sen-
tences and then classifies the remaining sen-
tences into one of 4 classes. The proposed
method outperformed the simple 1-step method.
We obtained 86.4% of accuracy that exceeds the
existing method and the baseline method.
</bodyText>
<sectionHeader confidence="0.999474" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999696981818182">
Naoki Abe, Bianca Zadrozny, John Langford. 2004.
An Iterative Method for Multi-class Cost-sensitive
Learning. In Proc. of the 10th. ACM SIGKDD,
pp.3–11.
Arthur P. Dempster, Nan M. laird, and Donald B.
Rubin. 1977. Maximum likelihood from incom-
plete data via the EM algorithm. Journal of the
Royal Statistical Society Series B, Vol. 39, No. 1,
pp.1–38.
Wei Fan, Salvatore J. Stolfo, Junxin Zhang, Philip K.
Chan. 1999. AdaCost: Misclassification Cost-
sensitive Boosting. In Proc. of ICML, pp.97–105.
Thomas Hofmann. 2001. Unsupervised learning by
probabilistic latent semantic analysis. Machine
Learning, 42:177–196.
Nathalie Japkowicz. 2000. Learning from Imbalanced
Data Sets: A Comparison of Various Strategies. In
Proc. of the AAAI Workshop on Learning from Im-
balanced Data Sets, pp.10 –15.
Taku Kudo, Yuji Matsumoto. 2000. Use of Support
Vector Learning for Chunking Identification, In
Proc of the 4th CoNLL, pp.142–144.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Probabil-
istic models for segmenting and labeling sequence
data, In Proc. of ICML, pp.282–289.
Inderjeet Mani, George Wilson 2000. Robust Tempo-
ral Processing of News. In Proc. of the 38th ACL,
pp.69–76.
Tomoyuki Nanno, Yasuhiro Suzuki, Toshiaki Fujiki,
Manabu Okumura. 2004. Automatically Collecting
and Monitoring Japanese Weblogs. Journal for
Japanese Society for Artificial Intelligence ,
Vol.19, No.6, pp.511–520. (in Japanese)
Kamal Nigam, Andrew McCallum, Sebastian Thrun,
and Tom Mitchell. 2000. Text classification from
labeled and unlabeled documents using EM. Ma-
chine Learning, Vol. 39, No.2/3, pp.103–134.
Satoshi Sekine, Hitoshi Isahara. 1999. IREX project
overview. Proceedings of the IREX Workshop.
Andrea Setzer, Robert Gaizauskas. 2001. A Pilot
Study on Annotating Temporal Relations in Text.
In Proc. of the ACL-2001 Workshop on Temporal
and Spatial Information Processing, Toulose,
France, July, pp.88–95.
Seiji Tsuchiya, Hirokazu Watabe, Tsukasa Kawaoka.
2005. Evaluation of a Time Judgement Technique
Based on an Association Mechanism. IPSG SIG
Technical Reports,2005-NL-168, pp.113–118. (in
Japanese)
Jianping Zhang, Inderjeet Mani. 2003. kNN Approach
to Unbalanced Data Distributions: A Case Study
involving Information Extraction. In Proc. of
ICML Workshop on Learning from Imbalanced
Datasets II., pp.42–48.
</reference>
<footnote confidence="0.611065">
5 http://chasen.org/~taku/software/cabocha/
</footnote>
<page confidence="0.985091">
1160
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.857958">
<title confidence="0.999771">Time Period Identification of Events in Text</title>
<author confidence="0.992468">Takashi Hiroya Manabu</author>
<affiliation confidence="0.996297">Graduate School of Science and Engineering Tokyo Institute of Technology</affiliation>
<address confidence="0.999025">4259 Nagatsuta-cho, Midori-ku, Yokohama, Kanagawa, Japan</address>
<affiliation confidence="0.99206">Society for the Promotion of Science and Intelligence Laboratory, Tokyo Institute of Technology</affiliation>
<email confidence="0.897972">norot@pi.titech.ac.jp</email>
<email confidence="0.897972">tinui}@lr.pi.titech.ac.jp@pi.titech.ac.jp</email>
<email confidence="0.897972">{takamura@pi.titech.ac.jp</email>
<email confidence="0.897972">oku@pi.titech.ac.jp</email>
<abstract confidence="0.999269521739131">This study aims at identifying when an event written in text occurs. In particular, we classify a sentence for an event into four time-slots; morning, daytime, evening, and night. To realize our goal, we focus on expressions associated with time-slot (time-associated words). However, listing up all the time-associated words is impractical, because there are numerous time-associated expressions. We therefore use a semi-supervised learning method, the Naïve Bayes classifier backed up with the Expectation Maximization algorithm, in order to iteratively extract time-associated words while improving the classifier. We also propose to use Support Vector Machines to filter out noisy instances that indicates no specific time period. As a result of experiments, the proposed method achieved 0.864 of accuracy and outperformed other methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Naoki Abe</author>
<author>Bianca Zadrozny</author>
<author>John Langford</author>
</authors>
<title>An Iterative Method for Multi-class Cost-sensitive Learning.</title>
<date>2004</date>
<booktitle>In Proc. of the 10th. ACM SIGKDD,</booktitle>
<pages>3--11</pages>
<contexts>
<context position="14249" citStr="Abe et al. (2004)" startWordPosition="2340" endWordPosition="2343">r of timeunknown time-slot sentences is much larger than that of the other sentences as shown in Table 1. There are more than ten times as many timeunknown time-slot sentences as the other sentences. Second, there are no time-associated words in the sentences categorized into “time-unknown”. Thus the feature distribution of time-unknown time-slot sentences is remarkably different from the others. It would be expected that they adversely affect proposed method. There have been some methodologies in order to solve the class imbalance problem, such as Zhang and Mani (2003), Fan et al. (1999) and Abe et al. (2004). However, in our case, we have to resolve the latter problem in addition to the class imbalance problem. To deal with two problems above simultaneously and precisely, we develop a cascaded classification procedure. PH= (α −1)+∑ .DP(c |x,θ) (α−1)C+D P(w |c) (α −1)+∑.D P(c |x, θX(w, x) = (α−1)W+∑w∑.D P(c |x,θN(w, x) M-step: , (6) 1156 4.5 Time-Slot Classification Method It’s desirable to treat only “time-known” sentences at NB+EM process to avoid the abovementioned problems. We prepare another classifier for filtering time-unknown sentences before NB+EM process for that purpose. Thus, we propos</context>
</contexts>
<marker>Abe, Zadrozny, Langford, 2004</marker>
<rawString>Naoki Abe, Bianca Zadrozny, John Langford. 2004. An Iterative Method for Multi-class Cost-sensitive Learning. In Proc. of the 10th. ACM SIGKDD, pp.3–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur P Dempster</author>
<author>Nan M laird</author>
<author>Donald B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society Series B,</journal>
<volume>39</volume>
<pages>1--38</pages>
<contexts>
<context position="4739" citStr="Dempster et al., 1977" startWordPosition="713" endWordPosition="716">al expressions in blog text. In other words, we can deal with wide coverage of sentences in informal text by our method with time-associated words. However, listing up all the time-associated words is impractical, because there are numerous time-associated expressions. Therefore, we use a semi-supervised method with a small amount of labeled data and a large amount of unlabeled data, because to prepare a large quantity of labeled data is costly, while unlabeled data is easy to obtain. Specifically, we adopt the Naïve Bayes classifier backed up with the Expectation Maximization (EM) algorithm (Dempster et al., 1977) for semi-supervised learning. In addition, we propose to use Support Vector Machines to filter out noisy sentences that degrade the performance of the semi-supervised method. In our experiments using blog data, we obtained 0.864 of accuracy, and we have shown effectiveness of the proposed method. This paper is organized as follows. In Section 2 we briefly describe related work. In Section 3 we describe the details of our corpus. The proposed method is presented in Section 4. In Section 5, we describe experimental results and discussions. We conclude the paper in Section 6. 2 Related Work The </context>
<context position="10832" citStr="Dempster et al., 1977" startWordPosition="1732" endWordPosition="1735">, improving sentence classification performance at the same time. To realize the bootstrapping method, we use the EM algorithm. This algorithm has a theoretical base of likelihood maximization of incomplete data and can enhance supervised learning methods. We specifically adopted the combination of the Naïve Bayes classifier and the EM algorithm. This combination has been proven to be effective in the text classification (Nigam et al., 2000). 1 The aim of this study is time-slot classification of events. Therefore we treat only sentences expressing an event. the EM Algorithm The EM algorithm (Dempster et al., 1977) is a method to estimate a model that has the maximal likelihood of the data when some variables cannot be observed (these variables are called latent variables). Nigam et al. (2000) proposed a combination of the Naïve Bayes classifiers and the EM algorithm. Ignoring the unrelated factors of Eq. (1), we obtain P(x |c,θ)∝ ∏ P(w |c)N(w,x), (2) w P(x |θ) ∝ ∑ P(cf j P(w |c)N(w,x). (3) c w We express model parameters as θ . If we regard c as a latent variable and introduce a Dirichlet distribution as the prior distribution for the parameters, the Q-function (i.e., the expected log-likelihood) of th</context>
</contexts>
<marker>Dempster, laird, Rubin, 1977</marker>
<rawString>Arthur P. Dempster, Nan M. laird, and Donald B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society Series B, Vol. 39, No. 1, pp.1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Fan</author>
<author>Salvatore J Stolfo</author>
<author>Junxin Zhang</author>
<author>Philip K Chan</author>
</authors>
<title>AdaCost: Misclassification Costsensitive Boosting.</title>
<date>1999</date>
<booktitle>In Proc. of ICML,</booktitle>
<pages>97--105</pages>
<contexts>
<context position="14227" citStr="Fan et al. (1999)" startWordPosition="2335" endWordPosition="2338">owicz 2000). The number of timeunknown time-slot sentences is much larger than that of the other sentences as shown in Table 1. There are more than ten times as many timeunknown time-slot sentences as the other sentences. Second, there are no time-associated words in the sentences categorized into “time-unknown”. Thus the feature distribution of time-unknown time-slot sentences is remarkably different from the others. It would be expected that they adversely affect proposed method. There have been some methodologies in order to solve the class imbalance problem, such as Zhang and Mani (2003), Fan et al. (1999) and Abe et al. (2004). However, in our case, we have to resolve the latter problem in addition to the class imbalance problem. To deal with two problems above simultaneously and precisely, we develop a cascaded classification procedure. PH= (α −1)+∑ .DP(c |x,θ) (α−1)C+D P(w |c) (α −1)+∑.D P(c |x, θX(w, x) = (α−1)W+∑w∑.D P(c |x,θN(w, x) M-step: , (6) 1156 4.5 Time-Slot Classification Method It’s desirable to treat only “time-known” sentences at NB+EM process to avoid the abovementioned problems. We prepare another classifier for filtering time-unknown sentences before NB+EM process for that pu</context>
</contexts>
<marker>Fan, Stolfo, Zhang, Chan, 1999</marker>
<rawString>Wei Fan, Salvatore J. Stolfo, Junxin Zhang, Philip K. Chan. 1999. AdaCost: Misclassification Costsensitive Boosting. In Proc. of ICML, pp.97–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Unsupervised learning by probabilistic latent semantic analysis.</title>
<date>2001</date>
<booktitle>Machine Learning,</booktitle>
<pages>42--177</pages>
<contexts>
<context position="12372" citStr="Hofmann, 2001" startWordPosition="2015" endWordPosition="2016">tion. time-slot = time-unknown NB + EM time-slot = morning, daytime, evening, night, time-unknown Step 2 Time-Slot Classifier Step1 Time-Unknown Filter SVM time-slot = morning, daytime, evening, night time-slot = morning time-slot = daytime time-slot = night time-slot = evening ⎞ ⎟ ⎠ E-step: (5) P(c |x,θ)=∑c P((B +(xB)θ), (7) where C denotes the number of categories, W denotes the number of features variety. For labeled example x , Eq. (5) is not used. Instead, P(c |x, θ) is set as 1.0 if c is the category of x, otherwise 0. Instead of the usual EM algorithm, we use the tempered EM algorithm (Hofmann, 2001). This algorithm allows coordinating complexity of the model. We can realize this algorithm by substituting the next equation for Eq. (5) at E-step: P(c |x, θ)= { |θHx |c, θ)Y (8) ∑cHc |θ)P(x |c, θ)r where β denotes a hyper parameter for coordinating complexity of the model, and it is positive value. By decreasing this hyper-parameter β , we can reduce the influence of intermediate classification results if those results are unreliable. Too much influence by unlabeled data sometimes deteriorates the model estimation. Therefore, we introduce a new hyper-parameter λ(0≤ λ≤ 1) which acts as weight</context>
</contexts>
<marker>Hofmann, 2001</marker>
<rawString>Thomas Hofmann. 2001. Unsupervised learning by probabilistic latent semantic analysis. Machine Learning, 42:177–196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathalie Japkowicz</author>
</authors>
<title>Learning from Imbalanced Data Sets: A Comparison of Various Strategies.</title>
<date>2000</date>
<booktitle>In Proc. of the AAAI Workshop on Learning from Imbalanced Data Sets,</booktitle>
<pages>10--15</pages>
<contexts>
<context position="13621" citStr="Japkowicz 2000" startWordPosition="2239" endWordPosition="2240">e second term in the righthand-side of Eq. (4) for the next equation: ∑ ∑ P(c |x, θ)logP(c)∏ P(w |c)N(w,x) x∈Dl c w + λ ∑ ∑ P(c |x, θ)log⎜ P(c)∏ P(w |c)N(w,x) ⎟ x∈Du c ⎝ w ⎠ where l D denotes labeled data, u D denotes unlabeled data. We can reduce the influence of unlabeled data by decreasing the value of λ . We derived new update rules from this new Qfunction. The EM computation stops when the difference in values of the Q-function is smaller than a threshold. 4.4 Class Imbalance Problem We have two problems with respect to “timeunknown” tag. The first problem is the class imbalance problem (Japkowicz 2000). The number of timeunknown time-slot sentences is much larger than that of the other sentences as shown in Table 1. There are more than ten times as many timeunknown time-slot sentences as the other sentences. Second, there are no time-associated words in the sentences categorized into “time-unknown”. Thus the feature distribution of time-unknown time-slot sentences is remarkably different from the others. It would be expected that they adversely affect proposed method. There have been some methodologies in order to solve the class imbalance problem, such as Zhang and Mani (2003), Fan et al. </context>
</contexts>
<marker>Japkowicz, 2000</marker>
<rawString>Nathalie Japkowicz. 2000. Learning from Imbalanced Data Sets: A Comparison of Various Strategies. In Proc. of the AAAI Workshop on Learning from Imbalanced Data Sets, pp.10 –15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Use of Support Vector Learning for Chunking Identification,</title>
<date>2000</date>
<booktitle>In Proc of the 4th CoNLL,</booktitle>
<pages>142--144</pages>
<contexts>
<context position="21375" citStr="Kudo and Matsumoto, 2000" startWordPosition="3468" endWordPosition="3471">he &apos;NB&apos; by 11%. Thus, we figure out that using unlabeled data improves the performance of our time-slot classification. In this experiment, unfortunately, CONTEXT only deteriorated the accuracy. The time-slot tags of the sentences preceding or following the target sentence may still provide information to improve the accuracy. Thus, we tried a sequential tagging method for sentences, in which tags are 1158 predicted in the order of their occurrence. The predicted tags are used as features in the prediction of the next tag. This type of sequential tagging method regard as a chunking procedure (Kudo and Matsumoto, 2000) at sentence level. We conducted time-slot (five classes) classification experiment, and tried forward tagging and backward tagging, with several window sizes. We used YamCha4, the multi-purpose text chunker using Support Vector Machines, as an experimental tool. However, any tagging direction and window sizes did not improve the performance of classification. Although a chunking method has possibility of correctly classifying a sequence of text units, it can be adversely biased by the preceding or the following tag. The sentences in blog used in our experiments would not have a very clear ten</context>
</contexts>
<marker>Kudo, Matsumoto, 2000</marker>
<rawString>Taku Kudo, Yuji Matsumoto. 2000. Use of Support Vector Learning for Chunking Identification, In Proc of the 4th CoNLL, pp.142–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data,</title>
<date>2001</date>
<booktitle>In Proc. of ICML,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="22181" citStr="Lafferty et al., 2001" startWordPosition="3598" endWordPosition="3601">ti-purpose text chunker using Support Vector Machines, as an experimental tool. However, any tagging direction and window sizes did not improve the performance of classification. Although a chunking method has possibility of correctly classifying a sequence of text units, it can be adversely biased by the preceding or the following tag. The sentences in blog used in our experiments would not have a very clear tendency in order of tags. This is why the chunking-method failed to improve the performance in this task. We would like to try other bias-free methods such as Conditional Random Fields (Lafferty et al., 2001) for future work. 5.1.3 2-step Classification Finally, we show an accuracy of the 2-step classifier (Method A) and compare it with those of other classifiers in Table 6. The accuracies are calculated with the equation: # sentences with a time-slot tag value . In Table 6, the baseline method classifies all sentences into time-unknown because the number of time-unknown sentences is the largest. Accuracy of Method A (proposed method) is higher than that of Method B (4.1% over). These results show that time-unknown sentences adversely affect the classifier learning, and 2-step classification is an</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data, In Proc. of ICML, pp.282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
</authors>
<title>Robust Temporal Processing of News.</title>
<date>2000</date>
<booktitle>In Proc. of the 38th ACL,</booktitle>
<pages>69--76</pages>
<location>George Wilson</location>
<marker>Mani, 2000</marker>
<rawString>Inderjeet Mani, George Wilson 2000. Robust Temporal Processing of News. In Proc. of the 38th ACL, pp.69–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomoyuki Nanno</author>
</authors>
<title>Yasuhiro Suzuki, Toshiaki Fujiki, Manabu Okumura.</title>
<date>2004</date>
<journal>Journal for Japanese Society for Artificial Intelligence ,</journal>
<volume>19</volume>
<pages>511--520</pages>
<note>(in Japanese)</note>
<marker>Nanno, 2004</marker>
<rawString>Tomoyuki Nanno, Yasuhiro Suzuki, Toshiaki Fujiki, Manabu Okumura. 2004. Automatically Collecting and Monitoring Japanese Weblogs. Journal for Japanese Society for Artificial Intelligence , Vol.19, No.6, pp.511–520. (in Japanese)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kamal Nigam</author>
<author>Andrew McCallum</author>
<author>Sebastian Thrun</author>
<author>Tom Mitchell</author>
</authors>
<title>Text classification from labeled and unlabeled documents using EM.</title>
<date>2000</date>
<booktitle>Machine Learning,</booktitle>
<volume>39</volume>
<pages>103--134</pages>
<contexts>
<context position="10655" citStr="Nigam et al., 2000" startWordPosition="1703" endWordPosition="1706">morning. Therefore we can use “cereal” as a clue of timeslot classification. By iterating this process, we can obtain a lot of time-associated words with bootstrapping method, improving sentence classification performance at the same time. To realize the bootstrapping method, we use the EM algorithm. This algorithm has a theoretical base of likelihood maximization of incomplete data and can enhance supervised learning methods. We specifically adopted the combination of the Naïve Bayes classifier and the EM algorithm. This combination has been proven to be effective in the text classification (Nigam et al., 2000). 1 The aim of this study is time-slot classification of events. Therefore we treat only sentences expressing an event. the EM Algorithm The EM algorithm (Dempster et al., 1977) is a method to estimate a model that has the maximal likelihood of the data when some variables cannot be observed (these variables are called latent variables). Nigam et al. (2000) proposed a combination of the Naïve Bayes classifiers and the EM algorithm. Ignoring the unrelated factors of Eq. (1), we obtain P(x |c,θ)∝ ∏ P(w |c)N(w,x), (2) w P(x |θ) ∝ ∑ P(cf j P(w |c)N(w,x). (3) c w We express model parameters as θ . </context>
</contexts>
<marker>Nigam, McCallum, Thrun, Mitchell, 2000</marker>
<rawString>Kamal Nigam, Andrew McCallum, Sebastian Thrun, and Tom Mitchell. 2000. Text classification from labeled and unlabeled documents using EM. Machine Learning, Vol. 39, No.2/3, pp.103–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
</authors>
<title>Hitoshi Isahara.</title>
<date>1999</date>
<booktitle>Proceedings of the IREX Workshop.</booktitle>
<marker>Sekine, 1999</marker>
<rawString>Satoshi Sekine, Hitoshi Isahara. 1999. IREX project overview. Proceedings of the IREX Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Setzer</author>
<author>Robert Gaizauskas</author>
</authors>
<title>A Pilot Study on Annotating Temporal Relations in Text.</title>
<date>2001</date>
<booktitle>In Proc. of the ACL-2001 Workshop on Temporal and Spatial Information Processing,</booktitle>
<location>Toulose, France,</location>
<marker>Setzer, Gaizauskas, 2001</marker>
<rawString>Andrea Setzer, Robert Gaizauskas. 2001. A Pilot Study on Annotating Temporal Relations in Text. In Proc. of the ACL-2001 Workshop on Temporal and Spatial Information Processing, Toulose, France, July, pp.88–95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seiji Tsuchiya</author>
</authors>
<title>Hirokazu Watabe, Tsukasa Kawaoka.</title>
<date>2005</date>
<tech>IPSG SIG Technical Reports,2005-NL-168,</tech>
<note>pp.113–118. (in Japanese)</note>
<marker>Tsuchiya, 2005</marker>
<rawString>Seiji Tsuchiya, Hirokazu Watabe, Tsukasa Kawaoka. 2005. Evaluation of a Time Judgement Technique Based on an Association Mechanism. IPSG SIG Technical Reports,2005-NL-168, pp.113–118. (in Japanese)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianping Zhang</author>
<author>Inderjeet Mani</author>
</authors>
<title>kNN Approach to Unbalanced Data Distributions: A Case Study involving Information Extraction.</title>
<date>2003</date>
<booktitle>In Proc. of ICML Workshop on Learning from Imbalanced Datasets II.,</booktitle>
<pages>42--48</pages>
<contexts>
<context position="14208" citStr="Zhang and Mani (2003)" startWordPosition="2331" endWordPosition="2334">imbalance problem (Japkowicz 2000). The number of timeunknown time-slot sentences is much larger than that of the other sentences as shown in Table 1. There are more than ten times as many timeunknown time-slot sentences as the other sentences. Second, there are no time-associated words in the sentences categorized into “time-unknown”. Thus the feature distribution of time-unknown time-slot sentences is remarkably different from the others. It would be expected that they adversely affect proposed method. There have been some methodologies in order to solve the class imbalance problem, such as Zhang and Mani (2003), Fan et al. (1999) and Abe et al. (2004). However, in our case, we have to resolve the latter problem in addition to the class imbalance problem. To deal with two problems above simultaneously and precisely, we develop a cascaded classification procedure. PH= (α −1)+∑ .DP(c |x,θ) (α−1)C+D P(w |c) (α −1)+∑.D P(c |x, θX(w, x) = (α−1)W+∑w∑.D P(c |x,θN(w, x) M-step: , (6) 1156 4.5 Time-Slot Classification Method It’s desirable to treat only “time-known” sentences at NB+EM process to avoid the abovementioned problems. We prepare another classifier for filtering time-unknown sentences before NB+EM </context>
</contexts>
<marker>Zhang, Mani, 2003</marker>
<rawString>Jianping Zhang, Inderjeet Mani. 2003. kNN Approach to Unbalanced Data Distributions: A Case Study involving Information Extraction. In Proc. of ICML Workshop on Learning from Imbalanced Datasets II., pp.42–48.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>