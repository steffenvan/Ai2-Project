<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000464">
<title confidence="0.854895">
Summarizing Multilingual Spoken Negotiation Dialogues
</title>
<author confidence="0.623389">
Norbert Reithinger and Michael Kipp and Ralf Engel and Jan Alexandersson*
</author>
<affiliation confidence="0.373957">
DFKI GmbH
</affiliation>
<address confidence="0.284944">
D-66123 Saarbriicken, Germany
</address>
<email confidence="0.984774">
fbert,kipp,rengel,janall@dfki.de
</email>
<sectionHeader confidence="0.995281" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999954">
We present the multilingual sum-
marization functionality for VERB-
MOBIL, a speech translation system.
We reuse resources of the system to
create a summary. After content ex-
traction, we interpret the results in
the dialog context. A summary gen-
erator provides the input to genera-
tion. A first evaluation indicates the
feasibility of the approach.
</bodyText>
<sectionHeader confidence="0.998524" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99996725">
In the last decade, automatic summarization
of textual (on-line) material was the main
goal of programs like TREC and TIPSTER
(see e.g. (Mani and Maybury, 1999)). These
projects dealt with the summarization of writ-
ten texts. With the availability of speech-
based dialogue systems, it is also possible to
produce summaries for spoken dialogue.
Within the speech-to-speech translation
system VERBMOBIL (Wahlster, 2000), a sys-
tem that translates negotiations in the do-
mains of scheduling, travel planning, and ho-
tel reservation between German and Japanese
or English, we developed summarization fa-
cilities that take knowledge sources already
present for translation purposes and use them
to generate a summary of the translated dia-
logue.
The rationale behind the summarization in
a translation system is to provide the users
</bodyText>
<footnote confidence="0.38305875">
This work was funded by the German Federal
Ministry for Education, Science, Research and Tech-
nology (BMBF) in the framework of the VERBMO-
BIL Project under Grant O1IV101K/1.
</footnote>
<bodyText confidence="0.999751457142857">
with notes about the dialogue in their native
language. They can be used, e.g., for insertion
in schedules, or to check whether the main
points of the conversation were correctly rec-
ognized and translated by the system.
Our view on summarization is tightly
linked to the underlying task of negotiation
where you are interested in those objects that
all speakers agreed on. In the course of a dia-
logue many suggestions are brought forward,
some are accepted, others rejected, some just
forgotten and never mentioned again. In a
word, the information is scattered across the
dialogue. For summarization, we try to bun-
dle singular data together to form suggestions
while keeping track of explicit and implicit
statements of acceptance and rejection. The
resulting items are presented in a fixed the-
matic order.
We start by first giving a rough sketch of
all modules involved. Then, we show how
we robustly extract a content description of
utterances from the speech recognizer&apos;s out-
put and build a core representation within
the dialogue memory. The dialogue proces-
sor extends this data and corrects implau-
sible input. We also show how we can use
these representations to produce an abstract
summary description that is converted by the
German language generation module into a
natural language summary. By utilizing the
transfer component we are able to produce
the summary in any language of the VERB-
MOBIL system. Finally, a first evaluation is
presented.
</bodyText>
<figure confidence="0.843023">
Generation
Summary Generation
Interpretation
Extraction
</figure>
<bodyText confidence="0.999613140625">
where the recognizer replaced &amp;quot;good so we
will&amp;quot; with &amp;quot;I would so we were&amp;quot;.
The aim is to get an abstract representation
of the content and the intention, irrespective
of recognition errors like these, as shown un-
der the sentence.
As target representation of the content we
use a formalism that comprises the dialogue
act which describes the speaker&apos;s intention
(in the example INFORM) and attribute-value
pairs for the content objects (see (Levin et al.,
1998) for a comparable approach in speech-to-
speech translation systems).
The dialogue act is computed statistically,
using language models (Reithinger and Kle-
sen, 1997; Tanaka and Yokoo, 1999). The di-
alogue act recognizer currently discriminates
19 different types of acts that cover, e.g., sug-
gestions, requests, accepts and rejects, dia-
logue opening and closing acts, and others.
The classifier is trained on a total number
of about 1,000 dialogues (consisting of Ger-
man, English, and Japanese dialogues) which
amount to 37,505 utterances. An evaluation
where each single dialogue was tested using
all the other dialogues as training set resulted
in an overall recall value of 72.48% and a pre-
cision of 69.90%. The dialogue act is used
later in the dialogue processor to trigger in-
ternal dialogue actions for the summarization
process, e.g., SUGGEST adds information, RE-
JECT discards information, utterances marked
with GIVE_REASON are ignored.
The second part of the expression de-
scribes the extracted content. We have chosen
nested attribute-value descriptions for this
task. 49 different classes of attribute-value
descriptions exist. The extracted information
doesn&apos;t describe exactly the utterance but is
restricted to the propositional content rele-
vant for the summarization process, like lo-
cations, dates, hotels, train information, or
moving direction (e.g., leaving vs. arriving).
The attribute-value descriptions are also spe-
cially designed to facilitate the task of com-
bining them in the dialogue processor.
To extract the information we use finite
state transducers (FSTs) (Appelt et al., 1993)
augmented with functions used, e.g., for scan-
ning input in advance or handling nested ob-
jects. The FSTs are hierarchically ordered
and grouped in three sequentially processed
layers (extracting temporal expressions, cre-
ating simple objects using keyword spotting,
combining these simple objects into complex
ones).
The construction of the FSTs is facilitated
by various tools, e.g., a graphical drawing tool
for FST development, a syntax checker and
several debugging tools. Currently, we have
defined 334 multi-language FSTs for the anal-
ysis of German, English and Japanese. The
FSTs were empirically derived from our sam-
ple corpus of about 30,000 utterances.
</bodyText>
<sectionHeader confidence="0.985175" genericHeader="introduction">
4 Interpretation
</sectionHeader>
<tableCaption confidence="0.9930805">
Table 1: The mapping from dialog act to negotiation
act and respective processing
</tableCaption>
<table confidence="0.983039615384615">
dialogue negotiation processing
act act
SUGGEST PROPOSE (1) complete object
INIT (2) compute relation
OFFER to focussed object
COMMIT (3) focus object
ACCEPT FEEDBACK annotate focussed
REJECT object with
acceptance/rejection
INFORM ELABORATE merge object with fo-
cussed object
REQUEST REQUEST store object in tempo-
rary memory
</table>
<bodyText confidence="0.9898498">
Internally, we model the negotiation in
terms of negotiation acts which tell us what
objects are part of a suggestion and signal
the speakers&apos; attitudes (accept/reject). Sug-
gestions are constantly completed (see com-
pletion arrow in Fig. 3) and related to previ-
ous suggestions by means of the more_specific
relation. This allows us to finally select the
summary items for generation: the most spe-
cific accepted suggestions. The whole process
is schematically depicted in Fig. 2 and 3
it will be explained in the rest of this section
starting with the introduction of topics.
Topic Topics partition our domain into four
areas: scheduling, traveling, accommodation
</bodyText>
<figure confidence="0.995841473684211">
GENERATION
EXTRACTION
PROCESSING
SUGGEST
ACCEPT
REJECT
SUGGEST
SUGGEST
ACCEPT
INFORM
PROPOSE
FEEDBACK
FEEDBACK
PROPOSE
PROPOSE
FEEDBACK
ELABORATE
sponsoring
completion
</figure>
<bodyText confidence="0.996041875">
der certain conditions relations can be special-
ized (e.g. has_time to has_departure_time).
Note that since N&apos; is already a completed ob-
ject, we obtain a complete object Nnen, with-
out further processing of other preceding ob-
jects.
Time expressions are completed by a sepa-
rate submodule (Kipp et al., 1999).
</bodyText>
<sectionHeader confidence="0.984598" genericHeader="method">
5 Summary Generation
</sectionHeader>
<bodyText confidence="0.991224342105263">
Responsible for the actual generation of the
summaries is the last processing block in
Fig. 1 — the summary generator (Alexander-
sson et al., 2000). On user request it con-
verts the most specific accepted NeOs into
sequences of high level German sentence de-
scriptions. These are converted into seman-
tic descriptions (VITs) and finally realized as
written text by the existing German generator
for presentation. For the generation of, e.g.,
English summaries, the VITs are sent through
the transfer component before realizing them
in the English generator.
We characterize the summary planning as
simplified text and sentence planning. The
summary generator uses an instance of the
plan processor described in (Alexandersson
and Reithinger, 1997) — for comparable ap-
proaches see (Moore, 1989) — which interprets
plan operators for traversing the NeOs and
partition/convert their content into abstract
sentence descriptions.
The information in VERBmoBIL&apos;s seman-
tic database (semdb) has been extended with
information about arguments and argument
types of the semantic entities for the planning
process. For the verbs, optionality of argu-
ments and adjuncts has been added. Verbs,
NPs and PPs are basic building blocks for
the sentences. The plan processor converts
the NeOs, depending on the number of rela-
tions and the depth of the content of the rela-
tions, to one of the basic building blocks NP,
PP and (sequences of) sentences. For simple
NeOs (e.g. transportation devices, time ex-
pressions) a NP/PP, and for complex NeOs
(e.g. move, appointment) sequences of sen-
tences are generated.
To demonstrate the generation in more de-
tail, consider Fig. 4 which is a Ne0 that re-
sults from a continuation of the dialogue ex-
cerpt shown in Fig. 3. Depending on topic
(traveling), class (journey) and the content of
the top object we select a set of possible verbs.
For each verb we recursively generate the con-
tent of their appropriate relations yielding a
set of NPs, PPs and, eventually, sentences.
According to the constraints of the verb (va-
lence roles, sortal constraints for arguments
and adjunct (s)) we try to link the NP/PPs to
the verb. For beginnen the compulsory argu-
ment — subject — has to carry the sort situa-
tion. In this case, we use the move which is
related to as move_there. This relation cor-
responds to Hinreise (Eng: trip there) which
is of sort move_sit. beginnen also allows for
one adjuncts of sort time_point and that the
source and target location can be linked to
the subject. During this process we maintain
a context, consisting of, e.g., focus and history
list, (cf. (Dale, 1995)) supporting the genera-
tion of, e.g., pronouns and demonstratives.
Theme: Appointment schedule with trip and
accommodation
Scheduling: Speaker B and speaker A will
meet in the train station on the 1. of
march 2000 at a quarter to 10 in the
morning.
Traveling: The trip there from Hamburg to
Hanover by train will start on the 2. of
march at 10 o&apos;clock in the morning. The
way back by train will start on the 2. of
march at half past 6 in the evening.
Accommodation: The hotel Luisenhof in
Hanover was agreed on. Speaker A is taking
care of the hotel reservation.
</bodyText>
<figureCaption confidence="0.992804">
Figure 5: An English dialogue summary
</figureCaption>
<bodyText confidence="0.99987825">
This process is iterated until all NeOs are
processed. To be robust, we finally use the
verb vereinbaren (Eng: agree) to realize the
relations which were not consumed. The re-
sulting sentence descriptions are passed to the
natural language generator which produces
the surface structure and provides an HTML-
formatted document (Fig. 5).
</bodyText>
<note confidence="0.349643">
move back transportation
</note>
<figureCaption confidence="0.998017">
Figure 4: Completed Ne0
</figureCaption>
<figure confidence="0.997650769230769">
departure time
source
time
{year:2000,month:mar,day:2,part:evening)
city
name.&apos;hamburg&apos;
ansportation
move_there
departure time
rail
time
{year:2000,month:mar,day:1,part:morning)
destination
</figure>
<sectionHeader confidence="0.52306" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.842018">
Evaluation is problematic in general, since it
is hard to find the ideal summary (Mani and
Maybury, 1999). In our case, things are fur-
ther complicated by the nature of speech-to-
speech translation. There are a lot of sys-
tem errors that can lead to a possible partial
breakdown of the dialogue and subsequent re-
pair dialogues. Using, for instance, the rec-
ognized and translated utterances as a basis
it is in many cases almost impossible, even
for a human, to judge what has actual been
agreed upon. Consider the excerpt from one
of our German-English evaluation dialogues
in Fig. 6, where for both participating speak-
ers and an observer it is difficult to grasp what
is going on in the dialogue.
Therefore, for a first evaluation we as-
sumed perfect recognition5 as a starting
point and evaluated four German-English dia-
logues which were mediated and translated by
the VERBMOBIL system. During the record-
ing of the dialogues the locutors had no visual
contact.
For each of the transcribed dialogues, a hu-
man marked the agreed on features, maxi-
mally 47 (e.g. location, date for a meeting,
speakers name and title, book agent). Each
dialogue only contains a subset of these fea-
tures. The dialogues were run through the
system, and the summary was generated. The
5Even using this strategy, it is, as a human, some-
times hard to understand the result of the negotiation.
T: okay then, that sounds fine, midday at twelve?
H: and sounds fine meet at twelve then
S: ja gut dann lass uns doch um zwolf Uhr treffen
Q: OK
T: aber an welchem Tag?
H: aber an welchem Tag
S: but that day suits me as well
Q: fail; transcripts&apos; translation: &amp;quot;But on which day&amp;quot;
T: which day did you want to leave? at midday.
H: weeks tight did you want to me at night out
S: wollten Sie fiir mich erkennen
</bodyText>
<figureCaption confidence="0.9186488">
Q: fail; translation of system&apos;s output:
&amp;quot;Would you recognize for me&amp;quot;
Figure 6: Excerpt from one of our evaluation dia-
logues. Each block shows Transcription, Hypothesis,
Systems&apos; Translation, and Translation Quality
</figureCaption>
<bodyText confidence="0.895012">
features in the summary were compared using
standard classifications as described in (Mani
and Maybury, 1999):
Corr The Feature approximately corresponds
to the human annotation. This means that
the feature is either (1) a 100% match, (2) it
was not enough specified or (3) too specific6.
Miss A feature is not included.
False A feature was erroneously included in
the summary, meaning that the feature was
not part of the dialogue or it received a wrong
value.
TN (True Negative) A feature was not part
of the dialogue, and not included in the sum-
mary.
6Example of (2) is when the correct date included
a time, which was not captured. Example of (3) is
when a date with time was annotated but the feature
contained just a date.
</bodyText>
<table confidence="0.999856777777778">
Dialogue 1 2 3 4 aver
Turns 33 33 31 32 32.25
Corr 6 13 9 11 9.75
Miss 6 3 5 4 4.5
False 3 3 3 0 2.25
TN 32 28 30 32 30.5
Recall 0.50 0.81 0.64 0.73 0.67
Prec. 0.67 0.81 0.75 1.0 0.81
Fallout 0.09 0.10 0.09 0.00 0.07
</table>
<figureCaption confidence="0.998909">
Figure 7: Evaluation Results
</figureCaption>
<bodyText confidence="0.999990125">
The results are shown in Fig. 7. As can
be seen our approach tries to be on the safe
side; the summary contains only those fea-
tures that the system thinks both partners
agreed on. The main reasons for not getting
higher numbers is due to the limited recogni-
tion of dialogue acts (70% recall) and errors
in the content extraction.
</bodyText>
<sectionHeader confidence="0.998413" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999972861111111">
We demonstrated how one can achieve a sum-
marization functionality of VERBMOBIL by
mostly utilizing and extending already exist-
ing components. This functionality is fully
integrated in the final version of the system.
We use standard methods from the area
of natural language processing and informa-
tion extraction for summarization: Statistical
methods are used to compute the intention of
an utterance and finite state technology to ex-
tract the domain relevant information. The
dialogue processor interprets and maintains
structures that mirror the negotiated objects
and their acceptance status. The summary
generator structures the finally agreed on ob-
jects partly according to the imposed topic
structure and divides the information within
each topic to abstract sentence descriptions.
These are verbalized and presented by VERB-
moBIL&apos;s natural language generator. By using
the transfer module we can produce multilin-
gual summaries. A first evaluation on a small
number of dialogue shows acceptable results
for the content contained in the summaries.
Finally, we consider scalability and how
to adapt to new domains/tasks and appli-
cations: If an already implemented domain
is extended, the algorithms can easily be
adapted. For new tasks (other than negoti-
ation) the discourse interpretation function-
ality must be rebuilt. Also, for extending
from two speakers to multi-party discussions,
a thorough re-structuring of the interpreta-
tion is required. In all cases, a corpus of dia-
logues must be available to be annotated for
training and test purposes.
</bodyText>
<sectionHeader confidence="0.999181" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999484434782609">
J. Alexandersson and N. Reithinger. 1997.
Learning Dialogue Structures from a Corpus.
In Proc. of EuroSpeech-97, pp. 2231-2235,
Rhodes.
J. Alexandersson, P. Poller, M. Kipp, and R. En-
gel. 2000. Multilingual Summary Generation
in a Speech-To-Speech Translation System for
Multilingual Dialogues. In Proc. of INLG-2000,
Mitzpe Ramon, Israel.
J. F. Allen. 1983. Maintaining Knowledge about
Temporal Intervals. Communications of the
ACM, 26(11):832-843, November.
D. E. Appelt, J. Hobbs, J. Bear, and M. Tyson.
1993. FASTUS: A finite-state processor for in-
formation extraction from real-world text. In
Proc. of IJCAI-93.
R. Dale. 1995. An Introduction to Natural Lan-
guage Generation. Tech. Report, Macquarie
University. Presented at ESSLLI-95.
M. Kipp, J. Alexandersson, and N. Reithinger.
1999. Understanding Spontaneous Negotiation
Dialogue. In Workshop Proc. &apos;Knowledge And
Reasoning in Practical Dialogue Systems&apos; of IJ-
CAI &apos;99, pages 57-64.
L. Levin, D. Gates, A. Lavie, and A. Waibel.
1998. An Interlingua Based on Domain Actions
for Machine Translation of Task-Oriented Dia-
logues. In Proc. of ICSLP &apos;98.
I. Mani and M. Maybury, eds. 1999. Advances in
Automatic Text Summarization. MIT Press.
J. D. Moore. 1989. A Reactive Approach to Ex-
planation in Expert and Advice-Giving Systems.
Ph.D. thesis, University of California, L.A.
N. Reithinger and M. Klesen. 1997. Dialogue Act
Classification Using Language Models. In Proc.
of EuroSpeech-97, pages 2235-2238, Rhodes.
N. Reithinger. 1999. Robust Information Extrac-
tion in a Speech Translation System. In Proc.
of EuroSpeech-99, pages 2427-2430.
H. Tanaka and A. Yokoo. 1999. An Efficient Sta-
tistical Speech Act Type Tagging System for a
Speech Translation System. In Proc. of ACL-
99, pages 381-388, Baltimore.
W. Wahlster, ed. 2000. VERBMOBIL:
Foundations of Speech-to-Speech Translation.
Springer.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.967006">
<title confidence="0.999845">Summarizing Multilingual Spoken Negotiation Dialogues</title>
<author confidence="0.983112">Reithinger Kipp Engel Alexandersson</author>
<affiliation confidence="0.998178">DFKI GmbH</affiliation>
<address confidence="0.998542">D-66123 Saarbriicken, Germany</address>
<email confidence="0.999743">fbert,kipp,rengel,janall@dfki.de</email>
<abstract confidence="0.998767090909091">We present the multilingual sumfor VERB- MOBIL, a speech translation system. We reuse resources of the system to create a summary. After content extraction, we interpret the results in the dialog context. A summary generator provides the input to generation. A first evaluation indicates the feasibility of the approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Alexandersson</author>
<author>N Reithinger</author>
</authors>
<date>1997</date>
<contexts>
<context position="8123" citStr="Alexandersson and Reithinger, 1997" startWordPosition="1243" endWordPosition="1246">generator (Alexandersson et al., 2000). On user request it converts the most specific accepted NeOs into sequences of high level German sentence descriptions. These are converted into semantic descriptions (VITs) and finally realized as written text by the existing German generator for presentation. For the generation of, e.g., English summaries, the VITs are sent through the transfer component before realizing them in the English generator. We characterize the summary planning as simplified text and sentence planning. The summary generator uses an instance of the plan processor described in (Alexandersson and Reithinger, 1997) — for comparable approaches see (Moore, 1989) — which interprets plan operators for traversing the NeOs and partition/convert their content into abstract sentence descriptions. The information in VERBmoBIL&apos;s semantic database (semdb) has been extended with information about arguments and argument types of the semantic entities for the planning process. For the verbs, optionality of arguments and adjuncts has been added. Verbs, NPs and PPs are basic building blocks for the sentences. The plan processor converts the NeOs, depending on the number of relations and the depth of the content of the </context>
</contexts>
<marker>Alexandersson, Reithinger, 1997</marker>
<rawString>J. Alexandersson and N. Reithinger. 1997.</rawString>
</citation>
<citation valid="false">
<title>Learning Dialogue Structures from a Corpus. In</title>
<booktitle>Proc. of EuroSpeech-97,</booktitle>
<pages>2231--2235</pages>
<location>Rhodes.</location>
<marker></marker>
<rawString>Learning Dialogue Structures from a Corpus. In Proc. of EuroSpeech-97, pp. 2231-2235, Rhodes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Alexandersson</author>
<author>P Poller</author>
<author>M Kipp</author>
<author>R Engel</author>
</authors>
<title>Multilingual Summary Generation in a Speech-To-Speech Translation System for Multilingual Dialogues.</title>
<date>2000</date>
<booktitle>In Proc. of INLG-2000,</booktitle>
<location>Mitzpe Ramon,</location>
<contexts>
<context position="7526" citStr="Alexandersson et al., 2000" startWordPosition="1152" endWordPosition="1156">RACTION PROCESSING SUGGEST ACCEPT REJECT SUGGEST SUGGEST ACCEPT INFORM PROPOSE FEEDBACK FEEDBACK PROPOSE PROPOSE FEEDBACK ELABORATE sponsoring completion der certain conditions relations can be specialized (e.g. has_time to has_departure_time). Note that since N&apos; is already a completed object, we obtain a complete object Nnen, without further processing of other preceding objects. Time expressions are completed by a separate submodule (Kipp et al., 1999). 5 Summary Generation Responsible for the actual generation of the summaries is the last processing block in Fig. 1 — the summary generator (Alexandersson et al., 2000). On user request it converts the most specific accepted NeOs into sequences of high level German sentence descriptions. These are converted into semantic descriptions (VITs) and finally realized as written text by the existing German generator for presentation. For the generation of, e.g., English summaries, the VITs are sent through the transfer component before realizing them in the English generator. We characterize the summary planning as simplified text and sentence planning. The summary generator uses an instance of the plan processor described in (Alexandersson and Reithinger, 1997) — </context>
</contexts>
<marker>Alexandersson, Poller, Kipp, Engel, 2000</marker>
<rawString>J. Alexandersson, P. Poller, M. Kipp, and R. Engel. 2000. Multilingual Summary Generation in a Speech-To-Speech Translation System for Multilingual Dialogues. In Proc. of INLG-2000, Mitzpe Ramon, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Allen</author>
</authors>
<title>Maintaining Knowledge about Temporal Intervals.</title>
<date>1983</date>
<journal>Communications of the ACM,</journal>
<pages>26--11</pages>
<marker>Allen, 1983</marker>
<rawString>J. F. Allen. 1983. Maintaining Knowledge about Temporal Intervals. Communications of the ACM, 26(11):832-843, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Appelt</author>
<author>J Hobbs</author>
<author>J Bear</author>
<author>M Tyson</author>
</authors>
<title>FASTUS: A finite-state processor for information extraction from real-world text.</title>
<date>1993</date>
<booktitle>In Proc. of IJCAI-93.</booktitle>
<contexts>
<context position="5137" citStr="Appelt et al., 1993" startWordPosition="790" endWordPosition="793">es the extracted content. We have chosen nested attribute-value descriptions for this task. 49 different classes of attribute-value descriptions exist. The extracted information doesn&apos;t describe exactly the utterance but is restricted to the propositional content relevant for the summarization process, like locations, dates, hotels, train information, or moving direction (e.g., leaving vs. arriving). The attribute-value descriptions are also specially designed to facilitate the task of combining them in the dialogue processor. To extract the information we use finite state transducers (FSTs) (Appelt et al., 1993) augmented with functions used, e.g., for scanning input in advance or handling nested objects. The FSTs are hierarchically ordered and grouped in three sequentially processed layers (extracting temporal expressions, creating simple objects using keyword spotting, combining these simple objects into complex ones). The construction of the FSTs is facilitated by various tools, e.g., a graphical drawing tool for FST development, a syntax checker and several debugging tools. Currently, we have defined 334 multi-language FSTs for the analysis of German, English and Japanese. The FSTs were empirical</context>
</contexts>
<marker>Appelt, Hobbs, Bear, Tyson, 1993</marker>
<rawString>D. E. Appelt, J. Hobbs, J. Bear, and M. Tyson. 1993. FASTUS: A finite-state processor for information extraction from real-world text. In Proc. of IJCAI-93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
</authors>
<title>An Introduction to Natural Language Generation.</title>
<date>1995</date>
<tech>Tech. Report,</tech>
<institution>Macquarie University.</institution>
<note>Presented at ESSLLI-95.</note>
<contexts>
<context position="9976" citStr="Dale, 1995" startWordPosition="1559" endWordPosition="1560">s. According to the constraints of the verb (valence roles, sortal constraints for arguments and adjunct (s)) we try to link the NP/PPs to the verb. For beginnen the compulsory argument — subject — has to carry the sort situation. In this case, we use the move which is related to as move_there. This relation corresponds to Hinreise (Eng: trip there) which is of sort move_sit. beginnen also allows for one adjuncts of sort time_point and that the source and target location can be linked to the subject. During this process we maintain a context, consisting of, e.g., focus and history list, (cf. (Dale, 1995)) supporting the generation of, e.g., pronouns and demonstratives. Theme: Appointment schedule with trip and accommodation Scheduling: Speaker B and speaker A will meet in the train station on the 1. of march 2000 at a quarter to 10 in the morning. Traveling: The trip there from Hamburg to Hanover by train will start on the 2. of march at 10 o&apos;clock in the morning. The way back by train will start on the 2. of march at half past 6 in the evening. Accommodation: The hotel Luisenhof in Hanover was agreed on. Speaker A is taking care of the hotel reservation. Figure 5: An English dialogue summary</context>
</contexts>
<marker>Dale, 1995</marker>
<rawString>R. Dale. 1995. An Introduction to Natural Language Generation. Tech. Report, Macquarie University. Presented at ESSLLI-95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kipp</author>
<author>J Alexandersson</author>
<author>N Reithinger</author>
</authors>
<title>Understanding Spontaneous Negotiation Dialogue.</title>
<date>1999</date>
<booktitle>In Workshop Proc. &apos;Knowledge And Reasoning in Practical Dialogue Systems&apos; of IJCAI &apos;99,</booktitle>
<pages>57--64</pages>
<contexts>
<context position="7357" citStr="Kipp et al., 1999" startWordPosition="1125" endWordPosition="1128">of this section starting with the introduction of topics. Topic Topics partition our domain into four areas: scheduling, traveling, accommodation GENERATION EXTRACTION PROCESSING SUGGEST ACCEPT REJECT SUGGEST SUGGEST ACCEPT INFORM PROPOSE FEEDBACK FEEDBACK PROPOSE PROPOSE FEEDBACK ELABORATE sponsoring completion der certain conditions relations can be specialized (e.g. has_time to has_departure_time). Note that since N&apos; is already a completed object, we obtain a complete object Nnen, without further processing of other preceding objects. Time expressions are completed by a separate submodule (Kipp et al., 1999). 5 Summary Generation Responsible for the actual generation of the summaries is the last processing block in Fig. 1 — the summary generator (Alexandersson et al., 2000). On user request it converts the most specific accepted NeOs into sequences of high level German sentence descriptions. These are converted into semantic descriptions (VITs) and finally realized as written text by the existing German generator for presentation. For the generation of, e.g., English summaries, the VITs are sent through the transfer component before realizing them in the English generator. We characterize the sum</context>
</contexts>
<marker>Kipp, Alexandersson, Reithinger, 1999</marker>
<rawString>M. Kipp, J. Alexandersson, and N. Reithinger. 1999. Understanding Spontaneous Negotiation Dialogue. In Workshop Proc. &apos;Knowledge And Reasoning in Practical Dialogue Systems&apos; of IJCAI &apos;99, pages 57-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Levin</author>
<author>D Gates</author>
<author>A Lavie</author>
<author>A Waibel</author>
</authors>
<title>An Interlingua Based on Domain Actions for Machine Translation of Task-Oriented Dialogues.</title>
<date>1998</date>
<booktitle>In Proc. of ICSLP &apos;98.</booktitle>
<contexts>
<context position="3534" citStr="Levin et al., 1998" startWordPosition="549" endWordPosition="552">produce the summary in any language of the VERBMOBIL system. Finally, a first evaluation is presented. Generation Summary Generation Interpretation Extraction where the recognizer replaced &amp;quot;good so we will&amp;quot; with &amp;quot;I would so we were&amp;quot;. The aim is to get an abstract representation of the content and the intention, irrespective of recognition errors like these, as shown under the sentence. As target representation of the content we use a formalism that comprises the dialogue act which describes the speaker&apos;s intention (in the example INFORM) and attribute-value pairs for the content objects (see (Levin et al., 1998) for a comparable approach in speech-tospeech translation systems). The dialogue act is computed statistically, using language models (Reithinger and Klesen, 1997; Tanaka and Yokoo, 1999). The dialogue act recognizer currently discriminates 19 different types of acts that cover, e.g., suggestions, requests, accepts and rejects, dialogue opening and closing acts, and others. The classifier is trained on a total number of about 1,000 dialogues (consisting of German, English, and Japanese dialogues) which amount to 37,505 utterances. An evaluation where each single dialogue was tested using all t</context>
</contexts>
<marker>Levin, Gates, Lavie, Waibel, 1998</marker>
<rawString>L. Levin, D. Gates, A. Lavie, and A. Waibel. 1998. An Interlingua Based on Domain Actions for Machine Translation of Task-Oriented Dialogues. In Proc. of ICSLP &apos;98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mani</author>
<author>M Maybury</author>
<author>eds</author>
</authors>
<date>1999</date>
<booktitle>Advances in Automatic Text Summarization.</booktitle>
<publisher>MIT Press.</publisher>
<marker>Mani, Maybury, eds, 1999</marker>
<rawString>I. Mani and M. Maybury, eds. 1999. Advances in Automatic Text Summarization. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Moore</author>
</authors>
<title>A Reactive Approach to Explanation in Expert and Advice-Giving Systems.</title>
<date>1989</date>
<tech>Ph.D. thesis,</tech>
<institution>University of California, L.A.</institution>
<contexts>
<context position="8169" citStr="Moore, 1989" startWordPosition="1253" endWordPosition="1254">he most specific accepted NeOs into sequences of high level German sentence descriptions. These are converted into semantic descriptions (VITs) and finally realized as written text by the existing German generator for presentation. For the generation of, e.g., English summaries, the VITs are sent through the transfer component before realizing them in the English generator. We characterize the summary planning as simplified text and sentence planning. The summary generator uses an instance of the plan processor described in (Alexandersson and Reithinger, 1997) — for comparable approaches see (Moore, 1989) — which interprets plan operators for traversing the NeOs and partition/convert their content into abstract sentence descriptions. The information in VERBmoBIL&apos;s semantic database (semdb) has been extended with information about arguments and argument types of the semantic entities for the planning process. For the verbs, optionality of arguments and adjuncts has been added. Verbs, NPs and PPs are basic building blocks for the sentences. The plan processor converts the NeOs, depending on the number of relations and the depth of the content of the relations, to one of the basic building blocks</context>
</contexts>
<marker>Moore, 1989</marker>
<rawString>J. D. Moore. 1989. A Reactive Approach to Explanation in Expert and Advice-Giving Systems. Ph.D. thesis, University of California, L.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Reithinger</author>
<author>M Klesen</author>
</authors>
<title>Dialogue Act Classification Using Language Models.</title>
<date>1997</date>
<booktitle>In Proc. of EuroSpeech-97,</booktitle>
<pages>2235--2238</pages>
<location>Rhodes.</location>
<contexts>
<context position="3696" citStr="Reithinger and Klesen, 1997" startWordPosition="571" endWordPosition="575">tion where the recognizer replaced &amp;quot;good so we will&amp;quot; with &amp;quot;I would so we were&amp;quot;. The aim is to get an abstract representation of the content and the intention, irrespective of recognition errors like these, as shown under the sentence. As target representation of the content we use a formalism that comprises the dialogue act which describes the speaker&apos;s intention (in the example INFORM) and attribute-value pairs for the content objects (see (Levin et al., 1998) for a comparable approach in speech-tospeech translation systems). The dialogue act is computed statistically, using language models (Reithinger and Klesen, 1997; Tanaka and Yokoo, 1999). The dialogue act recognizer currently discriminates 19 different types of acts that cover, e.g., suggestions, requests, accepts and rejects, dialogue opening and closing acts, and others. The classifier is trained on a total number of about 1,000 dialogues (consisting of German, English, and Japanese dialogues) which amount to 37,505 utterances. An evaluation where each single dialogue was tested using all the other dialogues as training set resulted in an overall recall value of 72.48% and a precision of 69.90%. The dialogue act is used later in the dialogue process</context>
</contexts>
<marker>Reithinger, Klesen, 1997</marker>
<rawString>N. Reithinger and M. Klesen. 1997. Dialogue Act Classification Using Language Models. In Proc. of EuroSpeech-97, pages 2235-2238, Rhodes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Reithinger</author>
</authors>
<title>Robust Information Extraction in a Speech Translation System. In</title>
<date>1999</date>
<booktitle>Proc. of EuroSpeech-99,</booktitle>
<pages>2427--2430</pages>
<marker>Reithinger, 1999</marker>
<rawString>N. Reithinger. 1999. Robust Information Extraction in a Speech Translation System. In Proc. of EuroSpeech-99, pages 2427-2430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Tanaka</author>
<author>A Yokoo</author>
</authors>
<title>An Efficient Statistical Speech Act Type Tagging System for a Speech Translation System. In</title>
<date>1999</date>
<booktitle>Proc. of ACL99,</booktitle>
<pages>381--388</pages>
<location>Baltimore.</location>
<contexts>
<context position="3721" citStr="Tanaka and Yokoo, 1999" startWordPosition="576" endWordPosition="579">laced &amp;quot;good so we will&amp;quot; with &amp;quot;I would so we were&amp;quot;. The aim is to get an abstract representation of the content and the intention, irrespective of recognition errors like these, as shown under the sentence. As target representation of the content we use a formalism that comprises the dialogue act which describes the speaker&apos;s intention (in the example INFORM) and attribute-value pairs for the content objects (see (Levin et al., 1998) for a comparable approach in speech-tospeech translation systems). The dialogue act is computed statistically, using language models (Reithinger and Klesen, 1997; Tanaka and Yokoo, 1999). The dialogue act recognizer currently discriminates 19 different types of acts that cover, e.g., suggestions, requests, accepts and rejects, dialogue opening and closing acts, and others. The classifier is trained on a total number of about 1,000 dialogues (consisting of German, English, and Japanese dialogues) which amount to 37,505 utterances. An evaluation where each single dialogue was tested using all the other dialogues as training set resulted in an overall recall value of 72.48% and a precision of 69.90%. The dialogue act is used later in the dialogue processor to trigger internal di</context>
</contexts>
<marker>Tanaka, Yokoo, 1999</marker>
<rawString>H. Tanaka and A. Yokoo. 1999. An Efficient Statistical Speech Act Type Tagging System for a Speech Translation System. In Proc. of ACL99, pages 381-388, Baltimore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wahlster</author>
<author>ed</author>
</authors>
<title>VERBMOBIL: Foundations of Speech-to-Speech Translation.</title>
<date>2000</date>
<publisher>Springer.</publisher>
<marker>Wahlster, ed, 2000</marker>
<rawString>W. Wahlster, ed. 2000. VERBMOBIL: Foundations of Speech-to-Speech Translation. Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>