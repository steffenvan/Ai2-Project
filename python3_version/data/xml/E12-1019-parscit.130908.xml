<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000066">
<title confidence="0.972603">
When Did that Happen? — Linking Events and Relations to Timestamps
</title>
<author confidence="0.94837">
Dirk Hovy*, James Fan, Alfio Gliozzo, Siddharth Patwardhan and Chris Welty
</author>
<note confidence="0.691266">
IBM T. J. Watson Research Center
19 Skyline Drive
</note>
<address confidence="0.714193">
Hawthorne, NY 10532
</address>
<email confidence="0.996749">
dirkh@isi.edu, {fanj,gliozzo,siddharth,welty}@us.ibm.com
</email>
<sectionHeader confidence="0.99561" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999618222222222">
We present work on linking events and flu-
ents (i.e., relations that hold for certain
periods of time) to temporal information
in text, which is an important enabler for
many applications such as timelines and
reasoning. Previous research has mainly
focused on temporal links for events, and
we extend that work to include fluents
as well, presenting a common methodol-
ogy for linking both events and relations
to timestamps within the same sentence.
Our approach combines tree kernels with
classical feature-based learning to exploit
context and achieves competitive F1-scores
on event-time linking, and comparable F1-
scores for fluents. Our best systems achieve
F1-scores of 0.76 on events and 0.72 on flu-
ents.
</bodyText>
<sectionHeader confidence="0.998995" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.977281056603774">
It is a long-standing goal of NLP to process natu-
ral language content in such a way that machines
can effectively reason over the entities, relations,
and events discussed within that content. The ap-
plications of such technology are numerous, in-
cluding intelligence gathering, business analytics,
healthcare, education, etc. Indeed, the promise
of machine reading is actively driving research in
this area (Etzioni et al., 2007; Barker et al., 2007;
Clark and Harrison, 2010; Strassel et al., 2010).
Temporal information is a crucial aspect of this
task. For a machine to successfully understand
natural language text, it must be able to associate
time points and temporal durations with relations
and events it discovers in text.
*The first author conducted this research during an in-
ternship at IBM Research.
In this paper we present methods to estab-
lish links between events (e.g. “bombing” or
“election”) or fluents (e.g. “spouseOf” or “em-
ployedBy”) and temporal expressions (e.g. “last
Tuesday” and “November 2008”). While previ-
ous research has mainly focused on temporal links
for events only, we deal with both events and flu-
ents with the same method. For example, consider
the sentence below
Before his death in October, Steve Jobs
led Apple for 15 years.
For a machine reading system processing this
sentence, we would expect it to link the fluent
CEO of(Steve Jobs, Apple) to time duration “15
years”. Similarly we expect it to link the event
“death” to the time expression “October”.
We do not take a strong “ontological” position
on what events and fluents are, as part of our
task these distinctions are made a priori. In other
words, events and fluents are input to our tempo-
ral linking framework. In the remainder of this pa-
per, we also do not make a strong distinction be-
tween relations in general and fluents in particu-
lar, and use them interchangeably, since our focus
is only on the specific types of relations that rep-
resent fluents. While we only use binary relations
in this work, there is nothing in the framework
that would prevent the use of n-ary relations. Our
work focuses on accurately identifying temporal
links for eventual use in a machine reading con-
text.
In this paper, we describe a single approach that
applies to both fluents and events, using feature
engineering as well as tree kernels. We show that
we can achieve good results for both events and
fluents using the same feature space, and advocate
</bodyText>
<page confidence="0.983539">
185
</page>
<note confidence="0.97691">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 185–193,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.99891196">
the versatility of our approach by achieving com-
petitive results on yet another similar task with a
different data set.
Our approach requires us to capture contextual
properties of text surrounding events, fluents and
time expressions that enable an automatic system
to detect temporal linking within our framework.
A common strategy for this is to follow standard
feature engineering methodology and manually
develop features for a machine learning model
from the lexical, syntactic and semantic analysis
of the text. A key contribution of our work in this
paper is to demonstrate a shallow tree-like repre-
sentation of the text that enables us to employ tree
kernel models, and more accurately detect tempo-
ral linking. The feature space represented by such
tree kernels is far larger than a manually engi-
neered feature space, and is capable of capturing
the contextual information required for temporal
linking.
The remainder of this paper goes into the de-
tails of our approach for temporal linking, and
presents empirical evidence for the effectiveness
of our approach. The contributions of this paper
can be summarized as follows:
</bodyText>
<listItem confidence="0.913878">
1. We define a common methodology to link
events and fluents to timestamps.
2. We use tree kernels in combination with clas-
sical feature-based approaches to obtain sig-
nificant gains by exploiting context.
3. Empirical evidence illustrates that our
framework for temporal linking is very ef-
fective for the task, achieving an F1-score of
0.76 on events and 0.72 on fluents/relations,
as well as 0.65 for TempEval2, approaching
state-of-the-art.
</listItem>
<sectionHeader confidence="0.999391" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999949421052632">
Most of the previous work on relation extraction
focuses on entity-entity relations, such as in the
ACE (Doddington et al., 2004) tasks. Temporal
relations are part of this, but to a lesser extent.
The primary research effort in event temporality
has gone into ordering events with respect to one
another (e.g., Chambers and Jurafsky (2008)), and
detecting their typical durations (e.g., Pan et al.
(2006)).
Recently, TempEval workshops have focused
on the temporal related issues in NLP. Some of
the TempEval tasks overlap with ours in many
ways. Our task is similar to task A and C of
TempEval-1 (Verhagen et al., 2007) in the sense
that we attempt to identify temporal relation be-
tween events and time expressions or document
dates. However, we do not use a restricted set of
events, but focus primarily on a single temporal
relation tlznk instead of named relations like BE-
FORE, AFTER or OVERLAP (although we show
that we can incorporate these as well). Part of our
task is similar to task C of TempEval-2 (Verha-
gen et al., 2010), determining the temporal rela-
tion between an event and a time expression in
the same sentence. In this paper, we do apply our
system to TempEval-2 data and compare our per-
formance to the participating systems.
Our work is similar to that of Boguraev and
Ando (2005), whose research only deals with
temporal links between events and time expres-
sions (and does not consider relations at all). They
employ a sequence tagging model with manual
feature engineering for the task and achieved
state-of-the-art results on Timebank (Pustejovsky
et al., 2003) data. Our task is slightly different be-
cause we include relations in the temporal linking,
and our use of tree kernels enables us to explore a
wider feature space very quickly.
Filatova and Hovy (2001) also explore tempo-
ral linking with events, but do not assume that
events and time stamps have been provided by an
external process. They used a heuristics-based ap-
proach to assign temporal expressions to events
(also relying on the proximity as a base case).
They report accuracy of the assignment for the
correctly classified events, the best being 82.29%.
Our best event system achieves an accuracy of
84.83%. These numbers are difficult to compare,
however, since accuracy does not efficiently cap-
ture the performance of a system on a task with so
many negative examples.
Mirroshandel et al. (2011) describe the use of
syntactic tree kernels for event-time links. Their
results on TempEval are comparable to ours. In
contrast to them, we found, though, that syntactic
tree kernels alone do not perform as well as using
several flat tree representations.
</bodyText>
<sectionHeader confidence="0.992535" genericHeader="method">
3 Problem Definition
</sectionHeader>
<bodyText confidence="0.998676666666667">
The task of linking events and relations to time
stamps can be defined as the following: given a set
of expressions denoting events or relation men-
</bodyText>
<page confidence="0.998172">
186
</page>
<bodyText confidence="0.994142857142857">
tions in a document, and a set of time expressions
in the same document, find all instances of the
tlink relation between elements of the two input
sets. The existence of a tlink(e, t) means that e,
which is an event or a relation mention, occurs
within the temporal context specified by the time
expression t.
Thus, our task can be cast as a binary rela-
tion classification task: for each possible pair
of (event/relation, time) in a document, decide
whether there exists a link between the two, and
if so, express it in the data.
In addition, we make these assumptions about
the data:
</bodyText>
<listItem confidence="0.995348">
1. There does not exist a timestamp for ev-
ery event/relation in a document. Although
events and relations typically have temporal
context, it may not be explicitly stated in a
document.
2. Every event/relation has at most one time ex-
</listItem>
<bodyText confidence="0.971040259259259">
pression associated with it. This is a simpli-
fying assumption, which in the case of rela-
tions we explore as future work.
3. Each temporal expression can be linked to
one or more events or relations. Since mul-
tiple events or relations may happen for a
given time, it is safe to assume that each tem-
poral expression can be linked to more than
one event/relation.
In general, the events/relations and their associ-
ated timestamps may occur within the same sen-
tence or may occur across different sentences. In
this paper, we focus on our effort and our evalua-
tion on the same sentence linking task.
In order to solve the problem of temporal link-
ing completely, however, it will be important to
also address the links that hold between entities
across sentences. We estimate, based on our data
set, that across sentence links account for 41% of
all correct event-time pairs in a document. For flu-
ents, the ratio is much higher, more than 80% of
the correct fluent-time links are across sentences.
One of the main obstacles for our approach in the
cross-sentence case is the very low ratio of posi-
tive to negative instances (3 : 100) in the set of all
pairs in a document. Most pairs are not linked to
one another.
</bodyText>
<sectionHeader confidence="0.976041" genericHeader="method">
4 Temporal Linking Framework
</sectionHeader>
<bodyText confidence="0.999992214285714">
As previously mentioned, we approach the tem-
poral linking problem as a classification task. In
the framework of classification, we refer to each
pair of (event/relation, temporal expression) oc-
curring within a sentence as an instance. The goal
is to devise a classifier that separates positive (i.e.,
linked) instances from negative ones, i.e., pairs
where there is no link between the event/relation
and the temporal expression in question. The lat-
ter case is far more frequent, so we have an inher-
ent bias toward negative examples in our data.1
Note that the basis of the positive and nega-
tive links is the context around the target terms.
It is impossible even for humans to determine the
existence of a link based only on the two terms
without their context. For instance, given just two
words (e.g., “said” and “yesterday”) there is no
way to tell if it is a positive or a negative example.
We need the context to decide.
Therefore, we base our classification models on
contextual features drawn from lexical and syn-
tactic analyses of the text surrounding the target
terms. For this, we first define a feature-based
approach, then we improve it by using tree ker-
nels. These two subsections, plus the treatment
of fluent relations, are the main contributions of
this paper. In all of this work, we employ SVM
classifiers (Vapnik, 1995) for machine learning.
</bodyText>
<subsectionHeader confidence="0.996933">
4.1 Feature Engineering
</subsectionHeader>
<bodyText confidence="0.98635105882353">
A manual analysis of development data provided
several intuitions about the kinds of features that
would be useful in this task. Based on this anal-
ysis and with inspiration from previous work (cf.
Boguraev and Ando (2005)) we established three
categories of features whose description follows.
Features describing events or relations. We
check whether the event or relation is phrasal, a
verb, or noun, whether it is present tense, past
tense, or progressive, the type assigned to the
event/relation by the UIMA type system used for
processing, and whether it includes certain trig-
ger words, such as reporting verbs (“said”, “re-
ported”, etc.).
1Initially, we employed an instance filtering method to
address this, which proved to be ineffective and was subse-
quently left out.
</bodyText>
<page confidence="0.990218">
187
</page>
<bodyText confidence="0.999415590909091">
Features describing temporal expressions.
We check for the presence of certain trigger words
(last, next, old, numbers, etc.) and the type of
the expression (DURATION, TIME, or DATE) as
specified by the UIMA type system.
Features describing context. We also in-
clude syntactic/structural features, such as testing
whether the relation/event dominates the temporal
expression, which one comes first in the sentence
order, and whether either of them is dominated
by a separate verb, preposition, “that” (which of-
ten indicates a subordinate sentence) or counter-
factual nouns or verbs (which would negate the
temporal link).
It is not surprising that some of the most in-
formative features (event comes before tempo-
ral expression, time is syntactic child of event)
are strongly correlated with the baselines. Less
salient features include the test for certain words
indicating the event is a noun, a verb, and if so
which tense it has and whether it is a reporting
verb.
</bodyText>
<subsectionHeader confidence="0.987306">
4.2 Tree Kernel Engineering
</subsectionHeader>
<bodyText confidence="0.993392878378379">
We expect that there exist certain patterns be-
tween the entities of a temporal link, which mani-
fest on several levels: some on the lexical level,
others expressed by certain sequences of POS
tags, NE labels, or other representations. Kernels
provide a principled way of expanding the number
of dimensions in which we search for a decision
boundary, and allow us to easily model local se-
quences and patterns in a natural way (Giuliano et
al., 2009). While it is possible to define a space
in which we find a decision boundary that sepa-
rates positive and negative instances with manu-
ally engineered features, these features can hardly
capture the notion of context as well as those ex-
plored by a tree kernel.
Tree Kernels are a family of kernel functions
developed to compute the similarity between tree
structures by counting the number of subtrees
they have in common. This generates a high-
dimensional feature space that can be handled ef-
ficiently using dynamic programming techniques
(Shawe-Taylor and Christianini, 2004). For our
purposes we used an implementation of the Sub-
tree and Subset Tree (SST) (Moschitti, 2006).
The advantages of using tree kernels are
two-fold: thanks to an existing implementation
(SVMUght with tree kernels, Moschitti (2004)), it
is faster and easier than traditional feature engi-
neering. The tree structure also allows us to use
different levels of representations (POS, lemma,
etc.) and combine their contributions, while at the
same time taking into account the ordering of la-
bels. We use POS, lemma, semantic type, and a
representation that replaces each word with a con-
catenation of its features (capitalization, count-
able, abstract/concrete noun, etc.).
We developed a shallow tree representation that
captures the context of the target terms, without
encoding too much structure (which may prevent
generalization). In essence, our tree structure in-
duces behavior somewhat similar to a string ker-
nel. In addition, we can model the tasks by pro-
viding specific markup on the generated tree. For
example, in our experiment we used the labels
EVENT (or equivalently RELATION) and TIME-
STAMP to mark our target terms. In order to re-
duce the complexity of this comparison, we focus
on the substring between event/relation and time
stamp and the rest of the tree structure is trun-
cated.
Figure 1 illustrates an example of the structure
described so far for both lemmas and POS tags
(note that the lowest level of the tree contains tok-
enized items, so their number can differ form the
actual words, as in “attorney general”). Similar
trees are produced for each level of representa-
tions used, and for each instance (i.e., pair of time
expressions and event/relation). If a sentence con-
tains more than one event/relation, we create sep-
arate trees for each of them, which differ in the po-
sition of the EVENT/RELATION marks (at level
1 of the tree).
The tree kernel implicitly expands this struc-
ture into a number of substructures allowing us
to capture sequential patterns in the data. As we
will see, this step provides significant boosts to
the task performance.
Curiously, using a full-parse syntactic tree as
input representation did not help performance.
This is in line with our finding that syntactic re-
lations are less important than sequential patterns
(see also Section 5.2). Therefore we adopted the
“string kernel like” representation illustrated in
Figure 1.
</bodyText>
<page confidence="0.922507">
188
</page>
<figure confidence="0.970991703703704">
Scores of supporters of detained Egyptian opposition leader Nur demonstrated outside the attorney general’s
office in Cairo last Saturday, demanding he be freed immediately.
BOW
TERM
TOK
outside
EVENT
TOK
demonstrate
TERM
TOK
attorney general
TERM
TOK
cairo
TERM
TOK
in
TOK
TOK
last
saturday
TERM
TOK
office
TIME
BOP
</figure>
<figureCaption confidence="0.996562">
Figure 1: Input Sentence and Tree Kernel Representations for Bag of Words (BOW) and POS tags (BOP)
</figureCaption>
<figure confidence="0.999369347826087">
EVENT
TOK
VBD
TERM
TOK
ADV
TIME
TOK
TERM
TOK
NNP
TERM
TOK
NN
TERM
TOK
IN
TERM
TOK
NNP
TOK
JJ
NNP
</figure>
<sectionHeader confidence="0.93148" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999968333333333">
We now apply our models to real world data, and
empirically demonstrate their effectiveness at the
task of temporal linking. In this section, we de-
scribe the data sets that were used for evaluation,
the baselines for comparison, parameter settings,
and the results of the experiments.
</bodyText>
<subsectionHeader confidence="0.986025">
5.1 Benchmark
</subsectionHeader>
<bodyText confidence="0.999958">
We evaluated our approach in 3 different tasks:
</bodyText>
<listItem confidence="0.9814185">
1. Linking Timestamps and Events in the IC
domain
2. Linking Timestamps and Relations in the IC
domain
3. Linking Events to Temporal Expressions
(TempEval-2, task C)
</listItem>
<bodyText confidence="0.99997096">
The first two data sets contained annotations
in the intelligence community (IC) domain, i.e.,
mainly news reports about terrorism. It com-
prised 169 documents. This dataset has been de-
veloped in the context of the machine reading pro-
gram (MRP) (Strassel et al., 2010). In both cases
our goal is to develop a binary classifier to judge
whether the event (or relation) overlaps with the
time interval denoted by the timestamp. Success
of this classification can be measured by precision
and recall on annotated data.
We originally considered using accuracy as a
measure of performance, but this does not cor-
rectly reflect the true performance of the system:
given the skewed nature of the data (much smaller
number of positive examples), we could achieve a
high accuracy simply by classifying all instances
as negative, i.e., not assigning a time stamp at all.
We thus decided to report precision, recall and F1.
Unless stated otherwise, results were achieved via
10-fold cross-validation (10-CV).
The number of instances (i.e., pairs of event
and temporal expression) for each of the differ-
ent cases listed above was (in brackets the ratio of
positive to negative instances).
</bodyText>
<listItem confidence="0.993336">
• events: 2046 (505 positive, 1541 negative)
• relations: 6526 (1847 positive, 4679 nega-
tive)
</listItem>
<bodyText confidence="0.998989117647059">
The size of the relation data set after filtering is
5511 (1847 positive, 3395 negative).
In order to increase the originally lower number
of event instances, we made use of the annotated
event-coreference as a sort of closure to add more
instances: if events A and B corefer, and there
is a link between A and time expression t, then
there is also a link between B and t. This was not
explicitly expressed in the data.
For the task at hand, we used gold standard
annotations for timestamps, events and relations.
The task was thus not the identification of these
objects (a necessary precursor and a difficult task
in itself), but the decision as to which events and
time expressions could and should be linked.
We also evaluated our system on TempEval-
2 (Verhagen et al., 2010) for better comparison
</bodyText>
<page confidence="0.998032">
189
</page>
<bodyText confidence="0.999908368421053">
to the state-of-the-art. TempEval-2 data included
the task of linking events to temporal expressions
(there called “task C”), using several link types
(OVERLAP, BEFORE, AFTER, BEFORE-OR-
OVERLAP, OVERLAP-OR-AFTER). This is a
bit different from our settings as it required the
implementation of a multi-class classifier. There-
fore we trained three different binary classifiers
(using the same feature set) for the first three of
those types (for which there was sufficient train-
ing data) and we used a one-versus-all strategy to
distinguish positive from negative examples. The
output of the system is the category with the high-
est SVM decision score. Since we only use three
labels, we incur an error every time the gold la-
bel is something else. Note that this is stricter
than the evaluation in the actual task, which left
contestants with the option of skipping examples
their systems could not classify.
</bodyText>
<subsectionHeader confidence="0.994516">
5.2 Baselines
</subsectionHeader>
<bodyText confidence="0.9993502">
Intuitively, one would expect temporal expres-
sions to be close to the event they denote, or even
syntactically related. In order to test this, we ap-
plied two baselines. In the first, each temporal ex-
pression was linked to the closest event (as mea-
sured in token distance). In the second, we at-
tached each temporal expression to its syntactic
head, if the head was an event. Results are re-
ported in Figure 2.
While these results are encouraging for our
task, it seems at first counter-intuitive that the
syntactic baseline does worse than the proximity-
based one. It does, however, reveal two facts:
events are not always synonymous with syntactic
units, and they are not always bound to tempo-
ral expressions through direct syntactic links. The
latter makes even more sense given that the links
can even occur across sentence boundaries. Pars-
ing quality could play a role, yet seems far fetched
to account for the difference.
More important than syntactic relations seem
to be sequential patterns on different levels, a fact
we exploit with the different tree representations
used (POS tags, NE types, etc.).
For relations, we only applied the closest-
relation baseline. Since relations consist of two or
more arguments that occur in different, often sep-
arated syntactic constituents, a syntactic approach
seems futile, especially given our experience with
events. Results are reported in Figure 3.
</bodyText>
<figure confidence="0.481182">
Precision Recall F1
metric
BL-parent BL-closest features +tree kernel
</figure>
<figureCaption confidence="0.572218">
Figure 2: Performance on events
</figureCaption>
<table confidence="0.999194">
System Accuracy
TRIOS 65%
this work 64.5%
JU-CSE, NCSU-indi all 63%
TRIPS, USFD2
</table>
<tableCaption confidence="0.999982">
Table 1: Comparison to Best Systems in TempEval-2
</tableCaption>
<subsectionHeader confidence="0.949199">
5.3 Events
</subsectionHeader>
<bodyText confidence="0.999928260869565">
Figure 2 shows the improvements of the feature-
based approach over the two baseline, and the ad-
ditional gain obtained by using the tree kernel.
Both the features and tree kernels mainly improve
precision, while the tree kernel adds a small boost
in recall. It is remarkable, though, that the closest-
event baseline has a very high recall value. This
suggests that most of the links actually do occur
between items that are close to one another. For a
possible explanation for the low precision value,
see the error analysis (Section 5.5).
Using a two-tailed t-test, we compute the sig-
nificance in the difference between the F1-scores.
Both the feature-based and the tree kernel ap-
proach improvements are statistically significant
at p &lt; 0.001 over the baseline scores.
Table 1 compares the performances of our sys-
tem to the state-of-the-art systems on TempEval-2
Data, task C, showing that our approach is very
competitive. The best systems there used sequen-
tial models. We attribute the competitive nature
of our results to the use of tree kernels, which en-
ables us to make use of contextual information.
</bodyText>
<subsectionHeader confidence="0.962493">
5.4 Relations
</subsectionHeader>
<bodyText confidence="0.999845666666667">
In general, performance for relations is not as high
as for events (see Figure 3). The reason here is
two-fold: relations consist of two (or more) ele-
ments, which can be in various positions with re-
spect to one another and the temporal expression,
and each relation can be expressed in a number of
</bodyText>
<figure confidence="0.98240145">
100
80
60
40
20
0
35.0
48.0
63.0
76.6
63.0
88.0
75.4
76.5 76.2
45.0
62.0
68.3
190
Precision Recall F1
metric
</figure>
<figureCaption confidence="0.996556">
Figure 3: Performance on relations/fluents
</figureCaption>
<figure confidence="0.781795">
% of data
</figure>
<figureCaption confidence="0.999518">
Figure 4: Learning curves for relation models
</figureCaption>
<bodyText confidence="0.938731130434783">
different ways.
Again, we perform significance tests on the dif-
ference in F1 scores and find that our improve-
ments over the baseline are statistically significant
e
at p &lt; 0.001. The improvement of the tree kernel
over the feature-based approach, however, are not
statistically significant at the same value.
The learning curve over parts of the training
data (exemplary shown here for relations, Figure
4)2 indicates that there is another advantage to us-
ing tree kernels: the approach can benefit from
more data. This is conceivably because it allows
the kernel to find more common subtrees in the
various representations the more examples it gets,
while the feature space rather finds more instances
that invalidate the expressiveness of features (i.e.,
it encounters positive and negative instances that
have very similar feature vectors). The curve sug-
gests that tree kernels could yield even better re-
sults with more data, while there is little to no ex-
pected gain using only features.
P
</bodyText>
<subsectionHeader confidence="0.927108">
5.5 Error Analysis
</subsectionHeader>
<bodyText confidence="0.973579666666667">
Examining the misclassified examples in our data,
we find that both feature-based and tree-kernel
approaches struggle to correctly classify exam-
</bodyText>
<footnote confidence="0.831154">
2The learning curve for events looks similar and is omit-
ted due to space constraints.
</footnote>
<bodyText confidence="0.99992725">
ples where time expression and event/relation are
immediately adjacent, but unrelated, as in “the
man arrested last Tuesday told the police ...”,
where last Tuesday modifies arrested. It limits
the amount of context that is available to the tree
kernels, since we truncate the tree representations
to the words between those two elements. This
case closely resembles the problem we see in the
closest-event/relation baseline, which, as we have
seen, does not perform too well. In this case, the
incorrect event (“told”) is as close to the time ex-
pression as the correct one (“arrested”), resulting
in a false positive that affects precision. Features
capturing the order of the elements do not seem
help here, since the elements can be arranged in
any order (i.e., temporal expression before or af-
ter the event/relation). The only way to solve this
problem would be to include additional informa-
tion about whether a time expression is already
attached to another event/relation.
</bodyText>
<subsectionHeader confidence="0.953919">
5.6 Ablations
</subsectionHeader>
<bodyText confidence="0.999956827586207">
To quantify the utility of each tree representation,
we also performed all-but-one ablation tests, i.e.,
left out each of the tree representations in turn, ran
10-fold cross-validation on the data and observed
the effect on F1. The larger the loss in F1, the
more informative the left-out-representation. We
performed ablations for both events and relations,
and found that the ranking of the representations
is the same for both.
In events and relations alike, leaving out POS
trees has the greatest effect on F1, followed by
the feature-bundle representation. Lemma and se-
mantic type representation have less of an impact.
We hypothesize that the former two capture un-
derlying regularities better by representing differ-
ent words with the same label. Lemmas in turn
are too numerous to form many recurring pat-
terns, and semantic type, while having a smaller
label alphabet, does not assign a label to every
word, thus creating a very sparse representation
that picks up more noise than signal.
In preliminary tests, we also used annotated
dependency trees as input to the tree kernel, but
found that performance improved when they were
left out. This is at odds with work that clearly
showed the value of syntactic tree kernels (Mir-
roshandel et al., 2011). We identify two poten-
tial causes—either our setup was not capable of
correctly capturing and exploiting the information
</bodyText>
<figure confidence="0.9987319375">
100
90
80
70
60
50
40
30
20
10
0
35.0
63.1
80.6
74.0
70.8 70.4 72.2
24.0
29.0
BL-closest features +tree kernel
0 10 20 30 40 50 60 70 80 90 100
F1 score
65
60
45
40
80
75
70
55
50
features w/ tree
kernel
</figure>
<page confidence="0.991146">
191
</page>
<bodyText confidence="0.999939">
from the dependency trees, or our formulation of
the task was not amenable to it. We did not inves-
tigate this further, but leave it to future work.
</bodyText>
<sectionHeader confidence="0.988894" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.998985">
We cast the problem of linking events and rela-
tions to temporal expressions as a classification
task using a combination of features and tree ker-
nels, with probabilistic type filtering. Our main
contributions are:
</bodyText>
<listItem confidence="0.640362090909091">
• We showed that within-sentence temporal
links for both events and relations can be ap-
proached with a common strategy.
• We developed flat tree representations and
showed that these produce considerable
gains, with significant improvements over
different baselines.
• We applied our technique without great ad-
justments to an existing data set and achieved
competitive results.
• Our best systems achieve F1 score of 0.76
</listItem>
<bodyText confidence="0.941858444444444">
on events and 0.72 on relations, and are ef-
fective at the task of temporal linking.
We developed the models as part of a machine
reading system and are currently evaluating it in
an end-to-end task.
Following tasks proposed in TempEval-2, we
plan to use our approach for across-sentence clas-
sification, as well as a similar model for linking
entities to the document creation date.
</bodyText>
<sectionHeader confidence="0.996547" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.990908166666667">
We would like to thank Alessandro Moschitti for
his help with the tree kernel setup, and the review-
ers who supplied us with very constructive feed-
back. Research supported in part by Air Force
Contract FA8750-09-C-0172 under the DARPA
Machine Reading Program.
</bodyText>
<sectionHeader confidence="0.99877" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999884984375">
Ken Barker, Bhalchandra Agashe, Shaw-Yi Chaw,
James Fan, Noah Friedland, Michael Glass, Jerry
Hobbs, Eduard Hovy, David Israel, Doo Soon Kim,
Rutu Mulkar-Mehta, Sourabh Patwardhan, Bruce
Porter, Dan Tecuci, and Peter Yeh. 2007. Learn-
ing by reading: A prototype system, performance
baseline and lessons learned. In Proceedings of
the 22nd National Conference for Artificial Intelli-
gence, Vancouver, Canada, July.
Branimir Boguraev and Rie Kubota Ando. 2005.
Timeml-compliant text analysis for temporal rea-
soning. In Proceedings of IJCAI, volume 5, pages
997–1003. IJCAI.
Nathanael Chambers and Dan Jurafsky. 2008. Unsu-
pervised learning of narrative event chains. pages
789–797. Association for Computational Linguis-
tics.
Peter Clark and Phil Harrison. 2010. Machine read-
ing as a process of partial question-answering. In
Proceedings of the NAACL HLT Workshop on For-
malisms and Methodology for Learning by Reading,
Los Angeles, CA, June.
George Doddington, Alexis Mitchell, Mark Przybocki,
Lance Ramshaw, Stephanie Strassel, and Ralph
Weischedel. 2004. The automatic content extrac-
tion program – tasks, data and evaluation. In Pro-
ceedings of the LREC Conference, Canary Islands,
Spain, July.
Oren Etzioni, Michele Banko, and Michael Cafarella.
2007. Machine reading. In Proceedings of the
AAAI Spring Symposium Series, Stanford, CA,
March.
Elena Filatova and Eduard Hovy. 2001. Assigning
time-stamps to event-clauses. In Proceedings of
the workshop on Temporal and spatial information
processing, volume 13, pages 1–8. Association for
Computational Linguistics.
Claudio Giuliano, Alfio Massimiliano Gliozzo, and
Carlo Strapparava. 2009. Kernel methods for min-
imally supervised wsd. Computational Linguistics,
35(4).
Seyed A. Mirroshandel, Mahdy Khayyamian, and
Gholamreza Ghassem-Sani. 2011. Syntactic tree
kernels for event-time temporal relation learning.
Human Language Technology. Challenges for Com-
puter Science and Linguistics, pages 213–223.
Alessandro Moschitti. 2004. A study on convolution
kernels for shallow semantic parsing. In Proceed-
ings of the 42nd Annual Meeting on Association for
Computational Linguistics, pages 335–es. Associa-
tion for Computational Linguistics.
Alessandro Moschitti. 2006. Making tree kernels
practical for natural language learning. In Proceed-
ings of EACL, volume 6.
Feng Pan, Rutu Mulkar, and Jerry R. Hobbs. 2006.
Learning event durations from event descriptions.
In Proceedings of the 21st International Conference
on Computational Linguistics and the 44th annual
meeting of the Association for Computational Lin-
guistics, pages 393–400. Association for Computa-
tional Linguistics.
James Pustejovsky, Patrick Hanks, Roser Saurı, An-
drew See, Robert Gaizauskas, Andrea Setzer,
Dragomir Radev, Beth Sundheim, David Day, Lisa
</reference>
<page confidence="0.977787">
192
</page>
<reference confidence="0.999709037037037">
Ferro, and Marcia Lazo. 2003. The TIMEBANK
Corpus. In Proceedings of Corpus Linguistics
2003, pages 647–656.
John Shawe-Taylor and Nello Christianini. 2004. Ker-
nel Methods for Pattern Analysis. Cambridge Uni-
versity Press.
Stephanie Strassel, Dan Adams, Henry Goldberg,
Jonathan Herr, Ron Keesing, Daniel Oblinger,
Heather Simpson, Robert Schrag, and Jonathan
Wright. 2010. The DARPA Machine Read-
ing Program-Encouraging Linguistic and Reason-
ing Research with a Series of Reading Tasks. In
Proceedings of LREC 2010.
Vladimir Vapnik. 1995. The Nature of Statistical
Learning Theory. Springer, New York, NY.
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Graham Katz, and James Puste-
jovsky. 2007. Semeval-2007 task 15: Tempeval
temporal relation identification. In Proceedings of
the 4th International Workshop on Semantic Evalu-
ations, pages 75–80. Association for Computational
Linguistics.
Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. Semeval-2010 task 13:
Tempeval-2. In Proceedings of the 5th Interna-
tional Workshop on Semantic Evaluation, pages 57–
62. Association for Computational Linguistics.
</reference>
<page confidence="0.999245">
193
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.406967">
<title confidence="0.990362">Did — Linking Events and Relations to Timestamps</title>
<author confidence="0.916793">James Fan Hovy</author>
<author confidence="0.916793">Alfio Gliozzo</author>
<author confidence="0.916793">Siddharth Patwardhan</author>
<affiliation confidence="0.900033">IBM T. J. Watson Research</affiliation>
<address confidence="0.745839">19 Skyline Hawthorne, NY</address>
<abstract confidence="0.987515842105263">We present work on linking events and fluents (i.e., relations that hold for certain periods of time) to temporal information in text, which is an important enabler for many applications such as timelines and reasoning. Previous research has mainly focused on temporal links for events, and we extend that work to include fluents as well, presenting a common methodology for linking both events and relations to timestamps within the same sentence. Our approach combines tree kernels with classical feature-based learning to exploit context and achieves competitive F1-scores on event-time linking, and comparable F1scores for fluents. Our best systems achieve of events and fluents.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Ken Barker</author>
<author>Bhalchandra Agashe</author>
<author>Shaw-Yi Chaw</author>
<author>James Fan</author>
<author>Noah Friedland</author>
<author>Michael Glass</author>
<author>Jerry Hobbs</author>
<author>Eduard Hovy</author>
<author>David Israel</author>
<author>Doo Soon Kim</author>
<author>Rutu Mulkar-Mehta</author>
<author>Sourabh Patwardhan</author>
<author>Bruce Porter</author>
<author>Dan Tecuci</author>
<author>Peter Yeh</author>
</authors>
<title>Learning by reading: A prototype system, performance baseline and lessons learned.</title>
<date>2007</date>
<booktitle>In Proceedings of the 22nd National Conference for Artificial Intelligence,</booktitle>
<location>Vancouver, Canada,</location>
<contexts>
<context position="1453" citStr="Barker et al., 2007" startWordPosition="217" endWordPosition="220">mpetitive F1-scores on event-time linking, and comparable F1- scores for fluents. Our best systems achieve F1-scores of 0.76 on events and 0.72 on fluents. 1 Introduction It is a long-standing goal of NLP to process natural language content in such a way that machines can effectively reason over the entities, relations, and events discussed within that content. The applications of such technology are numerous, including intelligence gathering, business analytics, healthcare, education, etc. Indeed, the promise of machine reading is actively driving research in this area (Etzioni et al., 2007; Barker et al., 2007; Clark and Harrison, 2010; Strassel et al., 2010). Temporal information is a crucial aspect of this task. For a machine to successfully understand natural language text, it must be able to associate time points and temporal durations with relations and events it discovers in text. *The first author conducted this research during an internship at IBM Research. In this paper we present methods to establish links between events (e.g. “bombing” or “election”) or fluents (e.g. “spouseOf” or “employedBy”) and temporal expressions (e.g. “last Tuesday” and “November 2008”). While previous research ha</context>
</contexts>
<marker>Barker, Agashe, Chaw, Fan, Friedland, Glass, Hobbs, Hovy, Israel, Kim, Mulkar-Mehta, Patwardhan, Porter, Tecuci, Yeh, 2007</marker>
<rawString>Ken Barker, Bhalchandra Agashe, Shaw-Yi Chaw, James Fan, Noah Friedland, Michael Glass, Jerry Hobbs, Eduard Hovy, David Israel, Doo Soon Kim, Rutu Mulkar-Mehta, Sourabh Patwardhan, Bruce Porter, Dan Tecuci, and Peter Yeh. 2007. Learning by reading: A prototype system, performance baseline and lessons learned. In Proceedings of the 22nd National Conference for Artificial Intelligence, Vancouver, Canada, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Branimir Boguraev</author>
<author>Rie Kubota Ando</author>
</authors>
<title>Timeml-compliant text analysis for temporal reasoning.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCAI,</booktitle>
<volume>5</volume>
<pages>997--1003</pages>
<publisher>IJCAI.</publisher>
<contexts>
<context position="6549" citStr="Boguraev and Ando (2005)" startWordPosition="1061" endWordPosition="1064">tion between events and time expressions or document dates. However, we do not use a restricted set of events, but focus primarily on a single temporal relation tlznk instead of named relations like BEFORE, AFTER or OVERLAP (although we show that we can incorporate these as well). Part of our task is similar to task C of TempEval-2 (Verhagen et al., 2010), determining the temporal relation between an event and a time expression in the same sentence. In this paper, we do apply our system to TempEval-2 data and compare our performance to the participating systems. Our work is similar to that of Boguraev and Ando (2005), whose research only deals with temporal links between events and time expressions (and does not consider relations at all). They employ a sequence tagging model with manual feature engineering for the task and achieved state-of-the-art results on Timebank (Pustejovsky et al., 2003) data. Our task is slightly different because we include relations in the temporal linking, and our use of tree kernels enables us to explore a wider feature space very quickly. Filatova and Hovy (2001) also explore temporal linking with events, but do not assume that events and time stamps have been provided by an</context>
<context position="11728" citStr="Boguraev and Ando (2005)" startWordPosition="1945" endWordPosition="1948">al features drawn from lexical and syntactic analyses of the text surrounding the target terms. For this, we first define a feature-based approach, then we improve it by using tree kernels. These two subsections, plus the treatment of fluent relations, are the main contributions of this paper. In all of this work, we employ SVM classifiers (Vapnik, 1995) for machine learning. 4.1 Feature Engineering A manual analysis of development data provided several intuitions about the kinds of features that would be useful in this task. Based on this analysis and with inspiration from previous work (cf. Boguraev and Ando (2005)) we established three categories of features whose description follows. Features describing events or relations. We check whether the event or relation is phrasal, a verb, or noun, whether it is present tense, past tense, or progressive, the type assigned to the event/relation by the UIMA type system used for processing, and whether it includes certain trigger words, such as reporting verbs (“said”, “reported”, etc.). 1Initially, we employed an instance filtering method to address this, which proved to be ineffective and was subsequently left out. 187 Features describing temporal expressions.</context>
</contexts>
<marker>Boguraev, Ando, 2005</marker>
<rawString>Branimir Boguraev and Rie Kubota Ando. 2005. Timeml-compliant text analysis for temporal reasoning. In Proceedings of IJCAI, volume 5, pages 997–1003. IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Unsupervised learning of narrative event chains.</title>
<date>2008</date>
<pages>789--797</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5589" citStr="Chambers and Jurafsky (2008)" startWordPosition="892" endWordPosition="895">icant gains by exploiting context. 3. Empirical evidence illustrates that our framework for temporal linking is very effective for the task, achieving an F1-score of 0.76 on events and 0.72 on fluents/relations, as well as 0.65 for TempEval2, approaching state-of-the-art. 2 Related Work Most of the previous work on relation extraction focuses on entity-entity relations, such as in the ACE (Doddington et al., 2004) tasks. Temporal relations are part of this, but to a lesser extent. The primary research effort in event temporality has gone into ordering events with respect to one another (e.g., Chambers and Jurafsky (2008)), and detecting their typical durations (e.g., Pan et al. (2006)). Recently, TempEval workshops have focused on the temporal related issues in NLP. Some of the TempEval tasks overlap with ours in many ways. Our task is similar to task A and C of TempEval-1 (Verhagen et al., 2007) in the sense that we attempt to identify temporal relation between events and time expressions or document dates. However, we do not use a restricted set of events, but focus primarily on a single temporal relation tlznk instead of named relations like BEFORE, AFTER or OVERLAP (although we show that we can incorporat</context>
</contexts>
<marker>Chambers, Jurafsky, 2008</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2008. Unsupervised learning of narrative event chains. pages 789–797. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Clark</author>
<author>Phil Harrison</author>
</authors>
<title>Machine reading as a process of partial question-answering.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT Workshop on Formalisms and Methodology for Learning by</booktitle>
<location>Reading, Los Angeles, CA,</location>
<contexts>
<context position="1479" citStr="Clark and Harrison, 2010" startWordPosition="221" endWordPosition="224">n event-time linking, and comparable F1- scores for fluents. Our best systems achieve F1-scores of 0.76 on events and 0.72 on fluents. 1 Introduction It is a long-standing goal of NLP to process natural language content in such a way that machines can effectively reason over the entities, relations, and events discussed within that content. The applications of such technology are numerous, including intelligence gathering, business analytics, healthcare, education, etc. Indeed, the promise of machine reading is actively driving research in this area (Etzioni et al., 2007; Barker et al., 2007; Clark and Harrison, 2010; Strassel et al., 2010). Temporal information is a crucial aspect of this task. For a machine to successfully understand natural language text, it must be able to associate time points and temporal durations with relations and events it discovers in text. *The first author conducted this research during an internship at IBM Research. In this paper we present methods to establish links between events (e.g. “bombing” or “election”) or fluents (e.g. “spouseOf” or “employedBy”) and temporal expressions (e.g. “last Tuesday” and “November 2008”). While previous research has mainly focused on tempor</context>
</contexts>
<marker>Clark, Harrison, 2010</marker>
<rawString>Peter Clark and Phil Harrison. 2010. Machine reading as a process of partial question-answering. In Proceedings of the NAACL HLT Workshop on Formalisms and Methodology for Learning by Reading, Los Angeles, CA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Doddington</author>
<author>Alexis Mitchell</author>
<author>Mark Przybocki</author>
<author>Lance Ramshaw</author>
<author>Stephanie Strassel</author>
<author>Ralph Weischedel</author>
</authors>
<title>The automatic content extraction program – tasks, data and evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of the LREC Conference, Canary Islands,</booktitle>
<location>Spain,</location>
<contexts>
<context position="5378" citStr="Doddington et al., 2004" startWordPosition="858" endWordPosition="861"> paper can be summarized as follows: 1. We define a common methodology to link events and fluents to timestamps. 2. We use tree kernels in combination with classical feature-based approaches to obtain significant gains by exploiting context. 3. Empirical evidence illustrates that our framework for temporal linking is very effective for the task, achieving an F1-score of 0.76 on events and 0.72 on fluents/relations, as well as 0.65 for TempEval2, approaching state-of-the-art. 2 Related Work Most of the previous work on relation extraction focuses on entity-entity relations, such as in the ACE (Doddington et al., 2004) tasks. Temporal relations are part of this, but to a lesser extent. The primary research effort in event temporality has gone into ordering events with respect to one another (e.g., Chambers and Jurafsky (2008)), and detecting their typical durations (e.g., Pan et al. (2006)). Recently, TempEval workshops have focused on the temporal related issues in NLP. Some of the TempEval tasks overlap with ours in many ways. Our task is similar to task A and C of TempEval-1 (Verhagen et al., 2007) in the sense that we attempt to identify temporal relation between events and time expressions or document </context>
</contexts>
<marker>Doddington, Mitchell, Przybocki, Ramshaw, Strassel, Weischedel, 2004</marker>
<rawString>George Doddington, Alexis Mitchell, Mark Przybocki, Lance Ramshaw, Stephanie Strassel, and Ralph Weischedel. 2004. The automatic content extraction program – tasks, data and evaluation. In Proceedings of the LREC Conference, Canary Islands, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Michele Banko</author>
<author>Michael Cafarella</author>
</authors>
<title>Machine reading.</title>
<date>2007</date>
<booktitle>In Proceedings of the AAAI Spring Symposium Series,</booktitle>
<location>Stanford, CA,</location>
<contexts>
<context position="1432" citStr="Etzioni et al., 2007" startWordPosition="213" endWordPosition="216">ontext and achieves competitive F1-scores on event-time linking, and comparable F1- scores for fluents. Our best systems achieve F1-scores of 0.76 on events and 0.72 on fluents. 1 Introduction It is a long-standing goal of NLP to process natural language content in such a way that machines can effectively reason over the entities, relations, and events discussed within that content. The applications of such technology are numerous, including intelligence gathering, business analytics, healthcare, education, etc. Indeed, the promise of machine reading is actively driving research in this area (Etzioni et al., 2007; Barker et al., 2007; Clark and Harrison, 2010; Strassel et al., 2010). Temporal information is a crucial aspect of this task. For a machine to successfully understand natural language text, it must be able to associate time points and temporal durations with relations and events it discovers in text. *The first author conducted this research during an internship at IBM Research. In this paper we present methods to establish links between events (e.g. “bombing” or “election”) or fluents (e.g. “spouseOf” or “employedBy”) and temporal expressions (e.g. “last Tuesday” and “November 2008”). While</context>
</contexts>
<marker>Etzioni, Banko, Cafarella, 2007</marker>
<rawString>Oren Etzioni, Michele Banko, and Michael Cafarella. 2007. Machine reading. In Proceedings of the AAAI Spring Symposium Series, Stanford, CA, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Filatova</author>
<author>Eduard Hovy</author>
</authors>
<title>Assigning time-stamps to event-clauses.</title>
<date>2001</date>
<booktitle>In Proceedings of the workshop on Temporal and spatial information processing,</booktitle>
<volume>13</volume>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7035" citStr="Filatova and Hovy (2001)" startWordPosition="1139" endWordPosition="1142">ystem to TempEval-2 data and compare our performance to the participating systems. Our work is similar to that of Boguraev and Ando (2005), whose research only deals with temporal links between events and time expressions (and does not consider relations at all). They employ a sequence tagging model with manual feature engineering for the task and achieved state-of-the-art results on Timebank (Pustejovsky et al., 2003) data. Our task is slightly different because we include relations in the temporal linking, and our use of tree kernels enables us to explore a wider feature space very quickly. Filatova and Hovy (2001) also explore temporal linking with events, but do not assume that events and time stamps have been provided by an external process. They used a heuristics-based approach to assign temporal expressions to events (also relying on the proximity as a base case). They report accuracy of the assignment for the correctly classified events, the best being 82.29%. Our best event system achieves an accuracy of 84.83%. These numbers are difficult to compare, however, since accuracy does not efficiently capture the performance of a system on a task with so many negative examples. Mirroshandel et al. (201</context>
</contexts>
<marker>Filatova, Hovy, 2001</marker>
<rawString>Elena Filatova and Eduard Hovy. 2001. Assigning time-stamps to event-clauses. In Proceedings of the workshop on Temporal and spatial information processing, volume 13, pages 1–8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudio Giuliano</author>
<author>Alfio Massimiliano Gliozzo</author>
<author>Carlo Strapparava</author>
</authors>
<title>Kernel methods for minimally supervised wsd.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>4</issue>
<contexts>
<context position="13727" citStr="Giuliano et al., 2009" startWordPosition="2269" endWordPosition="2272">atures include the test for certain words indicating the event is a noun, a verb, and if so which tense it has and whether it is a reporting verb. 4.2 Tree Kernel Engineering We expect that there exist certain patterns between the entities of a temporal link, which manifest on several levels: some on the lexical level, others expressed by certain sequences of POS tags, NE labels, or other representations. Kernels provide a principled way of expanding the number of dimensions in which we search for a decision boundary, and allow us to easily model local sequences and patterns in a natural way (Giuliano et al., 2009). While it is possible to define a space in which we find a decision boundary that separates positive and negative instances with manually engineered features, these features can hardly capture the notion of context as well as those explored by a tree kernel. Tree Kernels are a family of kernel functions developed to compute the similarity between tree structures by counting the number of subtrees they have in common. This generates a highdimensional feature space that can be handled efficiently using dynamic programming techniques (Shawe-Taylor and Christianini, 2004). For our purposes we use</context>
</contexts>
<marker>Giuliano, Gliozzo, Strapparava, 2009</marker>
<rawString>Claudio Giuliano, Alfio Massimiliano Gliozzo, and Carlo Strapparava. 2009. Kernel methods for minimally supervised wsd. Computational Linguistics, 35(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seyed A Mirroshandel</author>
<author>Mahdy Khayyamian</author>
<author>Gholamreza Ghassem-Sani</author>
</authors>
<title>Syntactic tree kernels for event-time temporal relation learning. Human Language Technology. Challenges for Computer Science and Linguistics,</title>
<date>2011</date>
<pages>213--223</pages>
<contexts>
<context position="7637" citStr="Mirroshandel et al. (2011)" startWordPosition="1238" endWordPosition="1241">Filatova and Hovy (2001) also explore temporal linking with events, but do not assume that events and time stamps have been provided by an external process. They used a heuristics-based approach to assign temporal expressions to events (also relying on the proximity as a base case). They report accuracy of the assignment for the correctly classified events, the best being 82.29%. Our best event system achieves an accuracy of 84.83%. These numbers are difficult to compare, however, since accuracy does not efficiently capture the performance of a system on a task with so many negative examples. Mirroshandel et al. (2011) describe the use of syntactic tree kernels for event-time links. Their results on TempEval are comparable to ours. In contrast to them, we found, though, that syntactic tree kernels alone do not perform as well as using several flat tree representations. 3 Problem Definition The task of linking events and relations to time stamps can be defined as the following: given a set of expressions denoting events or relation men186 tions in a document, and a set of time expressions in the same document, find all instances of the tlink relation between elements of the two input sets. The existence of a</context>
<context position="27469" citStr="Mirroshandel et al., 2011" startWordPosition="4531" endWordPosition="4535">pothesize that the former two capture underlying regularities better by representing different words with the same label. Lemmas in turn are too numerous to form many recurring patterns, and semantic type, while having a smaller label alphabet, does not assign a label to every word, thus creating a very sparse representation that picks up more noise than signal. In preliminary tests, we also used annotated dependency trees as input to the tree kernel, but found that performance improved when they were left out. This is at odds with work that clearly showed the value of syntactic tree kernels (Mirroshandel et al., 2011). We identify two potential causes—either our setup was not capable of correctly capturing and exploiting the information 100 90 80 70 60 50 40 30 20 10 0 35.0 63.1 80.6 74.0 70.8 70.4 72.2 24.0 29.0 BL-closest features +tree kernel 0 10 20 30 40 50 60 70 80 90 100 F1 score 65 60 45 40 80 75 70 55 50 features w/ tree kernel 191 from the dependency trees, or our formulation of the task was not amenable to it. We did not investigate this further, but leave it to future work. 6 Conclusion and Future Work We cast the problem of linking events and relations to temporal expressions as a classificati</context>
</contexts>
<marker>Mirroshandel, Khayyamian, Ghassem-Sani, 2011</marker>
<rawString>Seyed A. Mirroshandel, Mahdy Khayyamian, and Gholamreza Ghassem-Sani. 2011. Syntactic tree kernels for event-time temporal relation learning. Human Language Technology. Challenges for Computer Science and Linguistics, pages 213–223.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>A study on convolution kernels for shallow semantic parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>335</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="14535" citStr="Moschitti (2004)" startWordPosition="2400" endWordPosition="2401">e the notion of context as well as those explored by a tree kernel. Tree Kernels are a family of kernel functions developed to compute the similarity between tree structures by counting the number of subtrees they have in common. This generates a highdimensional feature space that can be handled efficiently using dynamic programming techniques (Shawe-Taylor and Christianini, 2004). For our purposes we used an implementation of the Subtree and Subset Tree (SST) (Moschitti, 2006). The advantages of using tree kernels are two-fold: thanks to an existing implementation (SVMUght with tree kernels, Moschitti (2004)), it is faster and easier than traditional feature engineering. The tree structure also allows us to use different levels of representations (POS, lemma, etc.) and combine their contributions, while at the same time taking into account the ordering of labels. We use POS, lemma, semantic type, and a representation that replaces each word with a concatenation of its features (capitalization, countable, abstract/concrete noun, etc.). We developed a shallow tree representation that captures the context of the target terms, without encoding too much structure (which may prevent generalization). In</context>
</contexts>
<marker>Moschitti, 2004</marker>
<rawString>Alessandro Moschitti. 2004. A study on convolution kernels for shallow semantic parsing. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, pages 335–es. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Making tree kernels practical for natural language learning.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL,</booktitle>
<volume>6</volume>
<contexts>
<context position="14401" citStr="Moschitti, 2006" startWordPosition="2381" endWordPosition="2382">a decision boundary that separates positive and negative instances with manually engineered features, these features can hardly capture the notion of context as well as those explored by a tree kernel. Tree Kernels are a family of kernel functions developed to compute the similarity between tree structures by counting the number of subtrees they have in common. This generates a highdimensional feature space that can be handled efficiently using dynamic programming techniques (Shawe-Taylor and Christianini, 2004). For our purposes we used an implementation of the Subtree and Subset Tree (SST) (Moschitti, 2006). The advantages of using tree kernels are two-fold: thanks to an existing implementation (SVMUght with tree kernels, Moschitti (2004)), it is faster and easier than traditional feature engineering. The tree structure also allows us to use different levels of representations (POS, lemma, etc.) and combine their contributions, while at the same time taking into account the ordering of labels. We use POS, lemma, semantic type, and a representation that replaces each word with a concatenation of its features (capitalization, countable, abstract/concrete noun, etc.). We developed a shallow tree re</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006. Making tree kernels practical for natural language learning. In Proceedings of EACL, volume 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feng Pan</author>
<author>Rutu Mulkar</author>
<author>Jerry R Hobbs</author>
</authors>
<title>Learning event durations from event descriptions.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>393--400</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5654" citStr="Pan et al. (2006)" startWordPosition="902" endWordPosition="905">r framework for temporal linking is very effective for the task, achieving an F1-score of 0.76 on events and 0.72 on fluents/relations, as well as 0.65 for TempEval2, approaching state-of-the-art. 2 Related Work Most of the previous work on relation extraction focuses on entity-entity relations, such as in the ACE (Doddington et al., 2004) tasks. Temporal relations are part of this, but to a lesser extent. The primary research effort in event temporality has gone into ordering events with respect to one another (e.g., Chambers and Jurafsky (2008)), and detecting their typical durations (e.g., Pan et al. (2006)). Recently, TempEval workshops have focused on the temporal related issues in NLP. Some of the TempEval tasks overlap with ours in many ways. Our task is similar to task A and C of TempEval-1 (Verhagen et al., 2007) in the sense that we attempt to identify temporal relation between events and time expressions or document dates. However, we do not use a restricted set of events, but focus primarily on a single temporal relation tlznk instead of named relations like BEFORE, AFTER or OVERLAP (although we show that we can incorporate these as well). Part of our task is similar to task C of TempEv</context>
</contexts>
<marker>Pan, Mulkar, Hobbs, 2006</marker>
<rawString>Feng Pan, Rutu Mulkar, and Jerry R. Hobbs. 2006. Learning event durations from event descriptions. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 393–400. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>James Pustejovsky</author>
<author>Patrick Hanks</author>
<author>Roser Saurı</author>
<author>Andrew See</author>
</authors>
<title>Robert Gaizauskas, Andrea Setzer, Dragomir Radev, Beth Sundheim,</title>
<location>David Day, Lisa</location>
<marker>Pustejovsky, Hanks, Saurı, See, </marker>
<rawString>James Pustejovsky, Patrick Hanks, Roser Saurı, Andrew See, Robert Gaizauskas, Andrea Setzer, Dragomir Radev, Beth Sundheim, David Day, Lisa</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ferro</author>
<author>Marcia Lazo</author>
</authors>
<title>The TIMEBANK Corpus.</title>
<date>2003</date>
<booktitle>In Proceedings of Corpus Linguistics</booktitle>
<pages>647--656</pages>
<marker>Ferro, Lazo, 2003</marker>
<rawString>Ferro, and Marcia Lazo. 2003. The TIMEBANK Corpus. In Proceedings of Corpus Linguistics 2003, pages 647–656.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Shawe-Taylor</author>
<author>Nello Christianini</author>
</authors>
<title>Kernel Methods for Pattern Analysis.</title>
<date>2004</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="14302" citStr="Shawe-Taylor and Christianini, 2004" startWordPosition="2362" endWordPosition="2365">quences and patterns in a natural way (Giuliano et al., 2009). While it is possible to define a space in which we find a decision boundary that separates positive and negative instances with manually engineered features, these features can hardly capture the notion of context as well as those explored by a tree kernel. Tree Kernels are a family of kernel functions developed to compute the similarity between tree structures by counting the number of subtrees they have in common. This generates a highdimensional feature space that can be handled efficiently using dynamic programming techniques (Shawe-Taylor and Christianini, 2004). For our purposes we used an implementation of the Subtree and Subset Tree (SST) (Moschitti, 2006). The advantages of using tree kernels are two-fold: thanks to an existing implementation (SVMUght with tree kernels, Moschitti (2004)), it is faster and easier than traditional feature engineering. The tree structure also allows us to use different levels of representations (POS, lemma, etc.) and combine their contributions, while at the same time taking into account the ordering of labels. We use POS, lemma, semantic type, and a representation that replaces each word with a concatenation of its</context>
</contexts>
<marker>Shawe-Taylor, Christianini, 2004</marker>
<rawString>John Shawe-Taylor and Nello Christianini. 2004. Kernel Methods for Pattern Analysis. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephanie Strassel</author>
<author>Dan Adams</author>
<author>Henry Goldberg</author>
<author>Jonathan Herr</author>
<author>Ron Keesing</author>
<author>Daniel Oblinger</author>
<author>Heather Simpson</author>
<author>Robert Schrag</author>
<author>Jonathan Wright</author>
</authors>
<title>The DARPA Machine Reading Program-Encouraging Linguistic and Reasoning Research with a Series of Reading Tasks.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC</booktitle>
<contexts>
<context position="1503" citStr="Strassel et al., 2010" startWordPosition="225" endWordPosition="228">comparable F1- scores for fluents. Our best systems achieve F1-scores of 0.76 on events and 0.72 on fluents. 1 Introduction It is a long-standing goal of NLP to process natural language content in such a way that machines can effectively reason over the entities, relations, and events discussed within that content. The applications of such technology are numerous, including intelligence gathering, business analytics, healthcare, education, etc. Indeed, the promise of machine reading is actively driving research in this area (Etzioni et al., 2007; Barker et al., 2007; Clark and Harrison, 2010; Strassel et al., 2010). Temporal information is a crucial aspect of this task. For a machine to successfully understand natural language text, it must be able to associate time points and temporal durations with relations and events it discovers in text. *The first author conducted this research during an internship at IBM Research. In this paper we present methods to establish links between events (e.g. “bombing” or “election”) or fluents (e.g. “spouseOf” or “employedBy”) and temporal expressions (e.g. “last Tuesday” and “November 2008”). While previous research has mainly focused on temporal links for events only</context>
<context position="17988" citStr="Strassel et al., 2010" startWordPosition="2970" endWordPosition="2973">data sets that were used for evaluation, the baselines for comparison, parameter settings, and the results of the experiments. 5.1 Benchmark We evaluated our approach in 3 different tasks: 1. Linking Timestamps and Events in the IC domain 2. Linking Timestamps and Relations in the IC domain 3. Linking Events to Temporal Expressions (TempEval-2, task C) The first two data sets contained annotations in the intelligence community (IC) domain, i.e., mainly news reports about terrorism. It comprised 169 documents. This dataset has been developed in the context of the machine reading program (MRP) (Strassel et al., 2010). In both cases our goal is to develop a binary classifier to judge whether the event (or relation) overlaps with the time interval denoted by the timestamp. Success of this classification can be measured by precision and recall on annotated data. We originally considered using accuracy as a measure of performance, but this does not correctly reflect the true performance of the system: given the skewed nature of the data (much smaller number of positive examples), we could achieve a high accuracy simply by classifying all instances as negative, i.e., not assigning a time stamp at all. We thus </context>
</contexts>
<marker>Strassel, Adams, Goldberg, Herr, Keesing, Oblinger, Simpson, Schrag, Wright, 2010</marker>
<rawString>Stephanie Strassel, Dan Adams, Henry Goldberg, Jonathan Herr, Ron Keesing, Daniel Oblinger, Heather Simpson, Robert Schrag, and Jonathan Wright. 2010. The DARPA Machine Reading Program-Encouraging Linguistic and Reasoning Research with a Series of Reading Tasks. In Proceedings of LREC 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer,</publisher>
<location>New York, NY.</location>
<contexts>
<context position="11460" citStr="Vapnik, 1995" startWordPosition="1904" endWordPosition="1905">the two terms without their context. For instance, given just two words (e.g., “said” and “yesterday”) there is no way to tell if it is a positive or a negative example. We need the context to decide. Therefore, we base our classification models on contextual features drawn from lexical and syntactic analyses of the text surrounding the target terms. For this, we first define a feature-based approach, then we improve it by using tree kernels. These two subsections, plus the treatment of fluent relations, are the main contributions of this paper. In all of this work, we employ SVM classifiers (Vapnik, 1995) for machine learning. 4.1 Feature Engineering A manual analysis of development data provided several intuitions about the kinds of features that would be useful in this task. Based on this analysis and with inspiration from previous work (cf. Boguraev and Ando (2005)) we established three categories of features whose description follows. Features describing events or relations. We check whether the event or relation is phrasal, a verb, or noun, whether it is present tense, past tense, or progressive, the type assigned to the event/relation by the UIMA type system used for processing, and whet</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vladimir Vapnik. 1995. The Nature of Statistical Learning Theory. Springer, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>Graham Katz</author>
<author>James Pustejovsky</author>
</authors>
<title>Semeval-2007 task 15: Tempeval temporal relation identification.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>75--80</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5870" citStr="Verhagen et al., 2007" startWordPosition="940" endWordPosition="943"> Most of the previous work on relation extraction focuses on entity-entity relations, such as in the ACE (Doddington et al., 2004) tasks. Temporal relations are part of this, but to a lesser extent. The primary research effort in event temporality has gone into ordering events with respect to one another (e.g., Chambers and Jurafsky (2008)), and detecting their typical durations (e.g., Pan et al. (2006)). Recently, TempEval workshops have focused on the temporal related issues in NLP. Some of the TempEval tasks overlap with ours in many ways. Our task is similar to task A and C of TempEval-1 (Verhagen et al., 2007) in the sense that we attempt to identify temporal relation between events and time expressions or document dates. However, we do not use a restricted set of events, but focus primarily on a single temporal relation tlznk instead of named relations like BEFORE, AFTER or OVERLAP (although we show that we can incorporate these as well). Part of our task is similar to task C of TempEval-2 (Verhagen et al., 2010), determining the temporal relation between an event and a time expression in the same sentence. In this paper, we do apply our system to TempEval-2 data and compare our performance to the</context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Katz, Pustejovsky, 2007</marker>
<rawString>Marc Verhagen, Robert Gaizauskas, Frank Schilder, Mark Hepple, Graham Katz, and James Pustejovsky. 2007. Semeval-2007 task 15: Tempeval temporal relation identification. In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 75–80. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Roser Sauri</author>
<author>Tommaso Caselli</author>
<author>James Pustejovsky</author>
</authors>
<title>57– 62. Association for Computational Linguistics.</title>
<date>2010</date>
<booktitle>Semeval-2010 task 13: Tempeval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>pages</pages>
<contexts>
<context position="6282" citStr="Verhagen et al., 2010" startWordPosition="1013" endWordPosition="1017">ently, TempEval workshops have focused on the temporal related issues in NLP. Some of the TempEval tasks overlap with ours in many ways. Our task is similar to task A and C of TempEval-1 (Verhagen et al., 2007) in the sense that we attempt to identify temporal relation between events and time expressions or document dates. However, we do not use a restricted set of events, but focus primarily on a single temporal relation tlznk instead of named relations like BEFORE, AFTER or OVERLAP (although we show that we can incorporate these as well). Part of our task is similar to task C of TempEval-2 (Verhagen et al., 2010), determining the temporal relation between an event and a time expression in the same sentence. In this paper, we do apply our system to TempEval-2 data and compare our performance to the participating systems. Our work is similar to that of Boguraev and Ando (2005), whose research only deals with temporal links between events and time expressions (and does not consider relations at all). They employ a sequence tagging model with manual feature engineering for the task and achieved state-of-the-art results on Timebank (Pustejovsky et al., 2003) data. Our task is slightly different because we </context>
<context position="19768" citStr="Verhagen et al., 2010" startWordPosition="3270" endWordPosition="3273">s, we made use of the annotated event-coreference as a sort of closure to add more instances: if events A and B corefer, and there is a link between A and time expression t, then there is also a link between B and t. This was not explicitly expressed in the data. For the task at hand, we used gold standard annotations for timestamps, events and relations. The task was thus not the identification of these objects (a necessary precursor and a difficult task in itself), but the decision as to which events and time expressions could and should be linked. We also evaluated our system on TempEval2 (Verhagen et al., 2010) for better comparison 189 to the state-of-the-art. TempEval-2 data included the task of linking events to temporal expressions (there called “task C”), using several link types (OVERLAP, BEFORE, AFTER, BEFORE-OROVERLAP, OVERLAP-OR-AFTER). This is a bit different from our settings as it required the implementation of a multi-class classifier. Therefore we trained three different binary classifiers (using the same feature set) for the first three of those types (for which there was sufficient training data) and we used a one-versus-all strategy to distinguish positive from negative examples. Th</context>
</contexts>
<marker>Verhagen, Sauri, Caselli, Pustejovsky, 2010</marker>
<rawString>Marc Verhagen, Roser Sauri, Tommaso Caselli, and James Pustejovsky. 2010. Semeval-2010 task 13: Tempeval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 57– 62. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>