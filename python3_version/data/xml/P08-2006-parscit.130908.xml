<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.136163">
<bodyText confidence="0.50134">
weights of the hybrid classifiers using a greedy strat-
egy to form the overall decision.
</bodyText>
<sectionHeader confidence="0.657797" genericHeader="method">
4 Baseline Acoustic Dialect Classification
</sectionHeader>
<bodyText confidence="0.87582475">
word match but they match the audio to an extent that
include what the speakers intended to say. The lan-
guage and Acoustic statistics of this database are de-
scribed in Sec 2.1, and 2.2.
</bodyText>
<subsectionHeader confidence="0.993115">
2.1 Language Statistics
</subsectionHeader>
<bodyText confidence="0.99818525">
Huang and Hansen observed that the best dialect
classification accuracy for N-gram classification re-
quires at least 300 text words to obtain reasonable
performance (Huang and Hansen, 2007). So, these
interviews are segmented into blocks of text with an
average text of 300 words. Table 1 summarizes the
text material for three family-tree branches of Eng-
lish, containing 474k words and 1325 documents.
</bodyText>
<table confidence="0.9986895">
Dialect No.of No. of Documents
words
Train Test
US English 200k 383 158
UK English 154k 288 122
AU English 120k 233 141
</table>
<tableCaption confidence="0.998463">
Table 1: Language Statistics
</tableCaption>
<subsectionHeader confidence="0.998004">
2.2 Acoustic Statistics
</subsectionHeader>
<bodyText confidence="0.999796416666667">
We note that the data collected from online podcasts
is not well structured. The audio data is segmented
into smaller audio segment files since we are inter-
ested in 300 word blocks. Since the collection of dia-
lect podcasts are collected from a wide range of
online sources, we assume that channel effects and
recording conditions are normalized across these
three dialects. We also note that there is no speaker
overlap between the test and train data. Therefore,
there are no additional acoustic clues other than dia-
lect. Table 2 summarizes the acoustic content of the
corpus with 231 speakers and 13.5 hrs of audio.
</bodyText>
<table confidence="0.9962702">
Dialect Males Females No. of Hours
Train Test
US English 48 37 3.2 1.7
UK English 40 32 2.3 1
AU English 36 38 3.3 2
</table>
<tableCaption confidence="0.995195">
Table 2: Acoustic Statistics
</tableCaption>
<sectionHeader confidence="0.974874" genericHeader="method">
3 System Architecture
</sectionHeader>
<bodyText confidence="0.99998036">
The system architecture is shown in Fig 1, which
consists of two main system phases for acoustic and
language classifiers. MFCC based classifiers are used
for acoustic modeling, while for language modeling,
we use a combination of n-gram language modes and
LSA classifiers. In the final phase, we combine the
acoustic and language classifiers into our final dialect
classifier. To construct the overall system, we first
train the individual classifiers, and then set the
GMM based acoustic classification is a popular
method for text-independent dialect classification
(Huang and Hansen, 2006) and therefore it is used as
a baseline for our system. Fig. 2 shows the block dia-
gram of the baseline gender-independent MFCC
based GMM training system with 600 mixtures for
each dialect. While testing, the incoming audio is
classified as a particular dialect based on the maxi-
mum posterior probability measure over all the Gaus-
sian Mixture Models. Mixture and frame selection
based techniques as well as SVM-GMM hybrid tech-
niques have been considered for dialect classification
(Chitturi and Hansen, 2007). In order to assess the
improvement by leveraging audio and text, we did
not include these audio classification improvements
in this study.
</bodyText>
<sectionHeader confidence="0.98907" genericHeader="method">
5 Dialect Classification using Language
</sectionHeader>
<bodyText confidence="0.99997">
As shown in Fig 1, the language based dialect classi-
fication module has two distinct classifiers. We de-
scribe in detail the n-gram and LSA based classifiers
in the sections 5.1 and 5.2
</bodyText>
<subsectionHeader confidence="0.996191">
5.1 N-gram based dialect classification
</subsectionHeader>
<bodyText confidence="0.997253636363636">
It is assumed that the text document is composed of
many sentences. Each sentence can be regarded as a
sequence of words W. The probability of generating
W is given by . Assum-
ing the probability depends on the previous n words
is where m is
the number of words in W, wi is the word and D-
{UK, US, AU) is the dialect specific language model.
The n-gram probabilities are calculated from occur-
rence counting. The final classification decision is
given by C= , where ϕ is a set of
sentences in a document and D - {UK, US, AU}. In this
study, we use the derivative measure of the cross en-
tropy known as the test set perplexity for dialect clas-
sification. If the word sequence is sufficiently long,
the cross entropy of the word sequence W is ap-
proximated as . The per-
plexity of the test word sequence W as it relates to
the language model D is
.The perplexity of the test word se-
quence is the generalization capability of the lan-
guage model. The smaller the perplexity, the better
</bodyText>
<page confidence="0.977137">
22
</page>
<bodyText confidence="0.97930075">
the language model generalizes to the test word se-
quence. The final classification decision is,
C= , where is the set of
sentences in a document, D - {UK, US, AU}.
</bodyText>
<figureCaption confidence="0.999819">
Figure 1: Proposed architecture
</figureCaption>
<subsectionHeader confidence="0.999729">
5.2 Latent Semantic Analysis for Dialect ID
</subsectionHeader>
<bodyText confidence="0.99898675">
One approach used to address topic classification
problems has been latent semantic analysis (LSA),
which was first explored for document indexing in
(Deerwester et al., 1990). This addresses the issues of
synonymy - many ways to refer to the same idea and
polysemy – words having more than one distinct
meaning. These two issues present problems for dia-
lect classification as two conversations about a topic
need not contain the same words and conversely two
conversations about different topics may contain the
same words but with different intended meanings. In
order to find a different feature space which avoids
these problems, singular value decomposition (SVD)
is performed to derive orthogonal vector representa-
tions of the documents. SVD uses eigen-analysis to
derive linearly independent directions of the original
term by document matrix A whose columns corre-
spond to the number of dialects, while the rows cor-
respond to the words/terms in the entire text database.
SVD decomposes this original term document matrix
A, into three other matrices: A=U*S*VT, where the
columns of U are the eigenvectors of AAT (left ei-
genvectors), S is a diagonal matrix, whose diagonal
elements are the singular values of A, and the col-
umns of V are the eigenvectors of ATA(called right
eigenvectors). The new dialect vector coordinates in
this reduced 3 dimensional space are the rows of V.
The coordinates of the test utterance is given by
q1=qT*U*S-1. The test utterance is then classified as
a particular dialect based on the scores, given by the
cosine similarity measure as
, where di is one of the three dialects.
</bodyText>
<sectionHeader confidence="0.999661" genericHeader="evaluation">
6 Results and Discussion
</sectionHeader>
<bodyText confidence="0.99984347368421">
All evaluations presented in this section were con-
ducted on the online podcast database described in
the section 2. The first row of Table 3 shows the per-
formance of the N-gram LM based dialect classifica-
tion (69.1% avg. performance). From this we observe
that this approach is good for US and UK, but not as
effective for AU family dialect classification, with
AU being confused with UK. The performance of the
LSA based dialect classification is shown in the sec-
ond row of Table 3. This classifier is consistent over
all the dialects with better performance than the N-
gram LM approach. There is more semantic similar-
ity of US with AU than UK (24% vs 5% - false posi-
tives), while UK has a balanced semantic error with
US and AU. This implies that there is more semantic
information in these dialects than text sequence struc-
ture.
Next, the N-gram and the LSA classifiers are com-
bined using optimal weights based on a greedy ap-
proach. Fig. 3 shows the performance of this hybrid
classifier with respect to the weights of the individual
classifiers (N-gram vs LSA: 04all N-gram, 5040.5
N-gram and 0.5 LSA, 1004 all LSA). After setting
the optimal weights 0.18 to LSA and 0.82 to N-gram
classifier, the hybrid classifier is seen to be consistent
and better than the individual classifiers (Table 3:
row 3 vs row2/row1). Performance of the hybrid
classifier is not as good as the LSA classifier for AU
classification, but significantly better for classifica-
tion of US and UK. The hybrid classifier is better in
all cases when compared to the N-gram classifier,
with an overall average improvement of 7.3% abso-
lute. The fourth row in Table 3 shows the perform-
ance of acoustic based dialect classification which is
as good as the language based dialect classification,
but it is noted that performance is poor for UK classi-
fication. It is expected that the type of errors made by
text (word selection), semantics and acoustic space
</bodyText>
<figure confidence="0.9997724">
MFCC based
Acoustic
GMM Classifier
Audio
Final Hybrid Acoustic &amp;
Language Classifier
Online
Podcasts
N-Gram
Classifier
Language
Classifier
Text
LSA
Classifier
</figure>
<figureCaption confidence="0.869252">
Figure 2: Baseline GMM based dialect classification
</figureCaption>
<figure confidence="0.99962075">
Silence
Remover
Feature
Extraction
Input
Audio
GMM1
GMM2
0
0
0
GMM n
0
Choose
Maximum
Likelihood
</figure>
<page confidence="0.99677">
23
</page>
<bodyText confidence="0.999951230769231">
will have differences and therefore we combine these
acoustical and language classifiers as shown in Fig1.
The overall performance of the proposed approach,
combining the acoustic and language information, is
better than the individual classifiers (Row 3 and Row
4 vs. Row 5 of Table 3). Even though the perform-
ance for US is reduced from 87.2% to 86.38%, the
classification of UK is improved significantly from
54% to 74%. This shows that this approach is more
consistent with accuracy that outperforms traditional
acoustic classifiers with a relative improvement of
30%. With respect to a language only classifier, this
hybrid classifier is better in all the cases.
</bodyText>
<sectionHeader confidence="0.999607" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.9998115">
In this study, we have developed a dialect classifica-
tion (DC) algorithm that addresses family branch DC
for English (US, UK, AU), by combining GMM
based acoustic, and text based N-gram LM and LSA
language information. In this paper, we employed
LSA in combination with N-gram language models
and GMM acoustic models to improve DC accuracy.
The performance of the individual classifiers were
shown to vary from 69.1%-72.4%. The final com-
bined system achieves a DC accuracy of 79.5% and
significantly outperformed the baseline acoustic clas-
sifier with a relative improvement of 30%, confirm-
ing that an integrated dialect classification system
employing GMM based acoustic and N-gram LM,
LSA based language information is effective for dia-
lect classification.
</bodyText>
<figureCaption confidence="0.987355">
Figure 3: Language classifier
</figureCaption>
<sectionHeader confidence="0.997572" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9773646">
Diakoloukas, V.; Neumeyer, L.; Kaja, J.; 1997. “Develop-
ment of dialect-specific speech recognizers using adap-
tation methods” IEEE- ICASSP
John Laver; 1994. “Principles of Phonetics”. Cambridge
University Press, Cambridge, UK.
</reference>
<figure confidence="0.597947">
F
</figure>
<figureCaption confidence="0.890135">
Figure 4: Acoustic + Language classifier
</figureCaption>
<table confidence="0.998539">
Accuracy→ US UK AU Overall
Methods↓
N-Gram LM 75.2% 71.2% 60.7% 69.1%
Classifier
Latent Semantic 70.2% 68.5% 78.7% 72.47%
(LSA) Classifier
N-Gram+ LSA 79.3% 74.6% 75.4% 76.4%
(Based on Text)
Acoustic GMM 87.2% 54.0% 73.3% 71.6%
Classifier
Acoustic GMM 86.4% 74.6% 77.0% 79.5%
+ N-gram+ LSA
</table>
<tableCaption confidence="0.999481">
Table 3: Performance of classifiers on Dialect-ID
</tableCaption>
<reference confidence="0.9963515">
Gray, S.; Hansen, J.H.L; 2005. “An integrated approach to
the detection and classification of /dialects for a spoken
document retrieval system” IEEE- ASRU
Huang R; Hansen J.H.L.; 2005. &amp;quot;Dialect/Accent Classifica-
tion via Boosted Word Modeling,&amp;quot; IEEE-ICASSP
Landauer,T.K., Foltz,P.W., &amp; Laham,D; 1998. &amp;quot; Introduc-
tion to Latent Semantic Analysis &amp;quot; Discourse Processes,
25, 259-284.
Huang R; Hansen J.H.L.2007 &amp;quot;Dialect Classification on
Printed Text using Perplexity Measure and Conditional
Random Fields,&amp;quot; IEEE- ICASSP
Hasegawa-Johnson M, Levinson S.E, 2006 &amp;quot;Extraction of
pragmatic and semantic salience from spontaneous
spoken English &amp;quot; Speech Comm. Vol. 48(3-4)
Antoine, J.-Y 1996 &amp;quot; Spontaneous speech and natural lan-
guage processing. ALPES: a robust semantic-led parser
&amp;quot; ICSLP
Deerwester.S. et al.1990.&amp;quot; Indexing by latent semantic
anlysis &amp;quot; Journal of American Society of Information
Science, 391–407.
Chitturi. R, Hansen J.H.L, 2007.&amp;quot; Multi stream based Dia-
lect classification using SVM-GMM hybrids&amp;quot; IEEE-
ASRU
Huang. R, Hansen J.L.H.; 2006. “Gaussian Mixture Selec-
tion and Data Selection for Unsupervised Spanish Dia-
lect Classification” ICSLP
Hansen J.H.L., Yapanel.U, Huang.R., Ikeno.A..; 2004.
“Dialect Anal&apos;ysis and Modeling for Automatic Classi-
fication” ICSLP
NIST- LRE 2005,” Language Recognition Evaluation”
</reference>
<page confidence="0.999153">
24
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000001">
<abstract confidence="0.9770985625">weights of the hybrid classifiers using a greedy strategy to form the overall decision. 4 Baseline Acoustic Dialect Classification word match but they match the audio to an extent that include what the speakers intended to say. The language and Acoustic statistics of this database are described in Sec 2.1, and 2.2. 2.1 Language Statistics Huang and Hansen observed that the best dialect classification accuracy for N-gram classification requires at least 300 text words to obtain reasonable performance (Huang and Hansen, 2007). So, these interviews are segmented into blocks of text with an average text of 300 words. Table 1 summarizes the text material for three family-tree branches of English, containing 474k words and 1325 documents.</abstract>
<title confidence="0.726841">Dialect No.of words No. of Documents</title>
<author confidence="0.758443">Train Test</author>
<note confidence="0.7468294">US English 200k 383 158 UK English 154k 288 122 AU English 120k 233 141 Table 1: Language Statistics 2.2 Acoustic Statistics</note>
<abstract confidence="0.98452182781457">We note that the data collected from online podcasts is not well structured. The audio data is segmented into smaller audio segment files since we are interested in 300 word blocks. Since the collection of dialect podcasts are collected from a wide range of online sources, we assume that channel effects and recording conditions are normalized across these three dialects. We also note that there is no speaker overlap between the test and train data. Therefore, there are no additional acoustic clues other than dialect. Table 2 summarizes the acoustic content of the corpus with 231 speakers and 13.5 hrs of audio. Dialect Males Females No. of Hours Train Test US English 48 37 3.2 1.7 UK English 40 32 2.3 1 AU English 36 38 3.3 2 Table 2: Acoustic Statistics 3 System Architecture The system architecture is shown in Fig 1, which consists of two main system phases for acoustic and language classifiers. MFCC based classifiers are used for acoustic modeling, while for language modeling, we use a combination of n-gram language modes and LSA classifiers. In the final phase, we combine the acoustic and language classifiers into our final dialect classifier. To construct the overall system, we first train the individual classifiers, and then set the GMM based acoustic classification is a popular method for text-independent dialect classification (Huang and Hansen, 2006) and therefore it is used as a baseline for our system. Fig. 2 shows the block diagram of the baseline gender-independent MFCC based GMM training system with 600 mixtures for each dialect. While testing, the incoming audio is classified as a particular dialect based on the maximum posterior probability measure over all the Gaussian Mixture Models. Mixture and frame selection based techniques as well as SVM-GMM hybrid techniques have been considered for dialect classification (Chitturi and Hansen, 2007). In order to assess the improvement by leveraging audio and text, we did not include these audio classification improvements in this study. 5 Dialect Classification using Language As shown in Fig 1, the language based dialect classification module has two distinct classifiers. We describe in detail the n-gram and LSA based classifiers in the sections 5.1 and 5.2 5.1 N-gram based dialect classification It is assumed that the text document is composed of many sentences. Each sentence can be regarded as a of words The probability of generating given by . ing the probability depends on the previous n words is where m is number of words in the word and US, AU) the dialect specific language model. The n-gram probabilities are calculated from occurrence counting. The final classification decision is by C= , where a set of in a document and US, In this study, we use the derivative measure of the cross entropy known as the test set perplexity for dialect classification. If the word sequence is sufficiently long, cross entropy of the word sequence apas . The perof the test word sequence it relates to the language model D is .The perplexity of the test word sequence is the generalization capability of the language model. The smaller the perplexity, the better 22 the language model generalizes to the test word sequence. The final classification decision is, C= , where is the set of in a document, D US, AU}. Figure 1: Proposed architecture 5.2 Latent Semantic Analysis for Dialect ID One approach used to address topic classification problems has been latent semantic analysis (LSA), which was first explored for document indexing in (Deerwester et al., 1990). This addresses the issues of synonymy many ways to refer to the same idea and polysemy – words having more than one distinct meaning. These two issues present problems for dialect classification as two conversations about a topic need not contain the same words and conversely two conversations about different topics may contain the same words but with different intended meanings. In order to find a different feature space which avoids these problems, singular value decomposition (SVD) is performed to derive orthogonal vector representations of the documents. SVD uses eigen-analysis to derive linearly independent directions of the original by document matrix columns correspond to the number of dialects, while the rows correspond to the words/terms in the entire text database. SVD decomposes this original term document matrix into three other matrices: where the of the eigenvectors of (left eia diagonal matrix, whose diagonal are the singular values of the colof the eigenvectors of right eigenvectors). The new dialect vector coordinates in reduced 3 dimensional space are the rows of The coordinates of the test utterance is given by test utterance is then classified as a particular dialect based on the scores, given by the cosine similarity measure as where one of the three dialects. 6 Results and Discussion All evaluations presented in this section were conducted on the online podcast database described in the section 2. The first row of Table 3 shows the performance of the N-gram LM based dialect classification (69.1% avg. performance). From this we observe that this approach is good for US and UK, but not as effective for AU family dialect classification, with AU being confused with UK. The performance of the LSA based dialect classification is shown in the second row of Table 3. This classifier is consistent over all the dialects with better performance than the Ngram LM approach. There is more semantic similarity of US with AU than UK (24% vs 5% false positives), while UK has a balanced semantic error with US and AU. This implies that there is more semantic information in these dialects than text sequence structure. Next, the N-gram and the LSA classifiers are combined using optimal weights based on a greedy approach. Fig. 3 shows the performance of this hybrid classifier with respect to the weights of the individual (N-gram vs LSA: N-gram, and 0.5 LSA, LSA). After setting the optimal weights 0.18 to LSA and 0.82 to N-gram classifier, the hybrid classifier is seen to be consistent and better than the individual classifiers (Table 3: row 3 vs row2/row1). Performance of the hybrid classifier is not as good as the LSA classifier for AU classification, but significantly better for classification of US and UK. The hybrid classifier is better in all cases when compared to the N-gram classifier, with an overall average improvement of 7.3% absolute. The fourth row in Table 3 shows the performance of acoustic based dialect classification which is as good as the language based dialect classification, but it is noted that performance is poor for UK classification. It is expected that the type of errors made by text (word selection), semantics and acoustic space MFCC based</abstract>
<title confidence="0.802270894736842">Acoustic GMM Classifier Audio Final Hybrid Acoustic &amp; Language Classifier Online Podcasts N-Gram Classifier Language Classifier Text LSA Classifier Figure 2: Baseline GMM based dialect classification Silence Remover Feature Extraction</title>
<note confidence="0.804898153846154">Input Audio GMM1 GMM2 0 0 0 GMM n 0 Choose Maximum Likelihood 23</note>
<abstract confidence="0.923373">will have differences and therefore we combine these acoustical and language classifiers as shown in Fig1. The overall performance of the proposed approach, combining the acoustic and language information, is better than the individual classifiers (Row 3 and Row 4 vs. Row 5 of Table 3). Even though the performance for US is reduced from 87.2% to 86.38%, the classification of UK is improved significantly from 54% to 74%. This shows that this approach is more consistent with accuracy that outperforms traditional acoustic classifiers with a relative improvement of 30%. With respect to a language only classifier, this hybrid classifier is better in all the cases. 7 Conclusions In this study, we have developed a dialect classification (DC) algorithm that addresses family branch DC for English (US, UK, AU), by combining GMM based acoustic, and text based N-gram LM and LSA language information. In this paper, we employed LSA in combination with N-gram language models and GMM acoustic models to improve DC accuracy. The performance of the individual classifiers were shown to vary from 69.1%-72.4%. The final combined system achieves a DC accuracy of 79.5% and significantly outperformed the baseline acoustic classifier with a relative improvement of 30%, confirming that an integrated dialect classification system employing GMM based acoustic and N-gram LM, LSA based language information is effective for dialect classification. Figure 3: Language classifier References V.; Neumeyer, L.; Kaja, J.; 1997. ment of dialect-specific speech recognizers using adapmethods” ICASSP</abstract>
<note confidence="0.764244">Laver; 1994. of Cambridge University Press, Cambridge, UK. F Figure 4: Acoustic + Language classifier US UK AU Overall N-Gram LM Classifier 75.2% 71.2% 60.7% 69.1% Latent Semantic (LSA) Classifier 70.2% 68.5% 78.7% 72.47% N-Gram+ LSA (Based on Text) 79.3% 74.6% 75.4% 76.4% Acoustic GMM Classifier 87.2% 54.0% 73.3% 71.6% Acoustic GMM + N-gram+ LSA 86.4% 74.6% 77.0% 79.5% Table 3: Performance of classifiers on Dialect-ID S.; Hansen, J.H.L; 2005. integrated approach to the detection and classification of /dialects for a spoken retrieval system” ASRU R; Hansen J.H.L.; 2005. Classificavia Boosted Word Modeling,&amp;quot; Foltz,P.W., &amp; Laham,D; 1998. Introducto Latent Semantic Analysis &amp;quot; Processes, 25, 259-284. R; Hansen J.H.L.2007 Classification on Printed Text using Perplexity Measure and Conditional Fields,&amp;quot; ICASSP M, Levinson S.E, 2006 of</note>
<abstract confidence="0.915280333333333">pragmatic and semantic salience from spontaneous English &amp;quot; Comm. Vol. 48(3-4) J.-Y 1996 Spontaneous speech and natural language processing. ALPES: a robust semantic-led parser et Indexing by latent semantic &amp;quot; of American Society of Information</abstract>
<note confidence="0.3136485">Science, 391–407. R, Hansen J.H.L, Multi stream based Diaclassification using SVM-GMM hybrids&amp;quot; IEEE- ASRU R, Hansen J.L.H.; 2006. Mixture Selection and Data Selection for Unsupervised Spanish Dia- Classification” Hansen J.H.L., Yapanel.U, Huang.R., Ikeno.A..; 2004.</note>
<title confidence="0.5139745">Dialect Anal&apos;ysis and Modeling for Automatic Classi- LRE Language Recognition Evaluation”</title>
<intro confidence="0.317209">24</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>V Diakoloukas</author>
<author>L Neumeyer</author>
<author>J Kaja</author>
</authors>
<title>Development of dialect-specific speech recognizers using adaptation methods”</title>
<date>1997</date>
<journal>IEEE- ICASSP</journal>
<marker>Diakoloukas, Neumeyer, Kaja, 1997</marker>
<rawString>Diakoloukas, V.; Neumeyer, L.; Kaja, J.; 1997. “Development of dialect-specific speech recognizers using adaptation methods” IEEE- ICASSP</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Laver</author>
</authors>
<title>Principles of Phonetics”.</title>
<date>1994</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<marker>Laver, 1994</marker>
<rawString>John Laver; 1994. “Principles of Phonetics”. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Gray</author>
<author>J H L Hansen</author>
</authors>
<title>An integrated approach to the detection and classification of /dialects for a spoken document retrieval system”</title>
<date>2005</date>
<journal>IEEE- ASRU</journal>
<marker>Gray, Hansen, 2005</marker>
<rawString>Gray, S.; Hansen, J.H.L; 2005. “An integrated approach to the detection and classification of /dialects for a spoken document retrieval system” IEEE- ASRU</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Huang</author>
<author>J H L Hansen</author>
</authors>
<title>Dialect/Accent Classification via Boosted Word Modeling,&amp;quot;</title>
<date>2005</date>
<journal>IEEE-ICASSP Landauer,T.K., Foltz,P.W., &amp; Laham,D;</journal>
<booktitle>Discourse Processes,</booktitle>
<volume>25</volume>
<pages>259--284</pages>
<marker>Huang, Hansen, 2005</marker>
<rawString>Huang R; Hansen J.H.L.; 2005. &amp;quot;Dialect/Accent Classification via Boosted Word Modeling,&amp;quot; IEEE-ICASSP Landauer,T.K., Foltz,P.W., &amp; Laham,D; 1998. &amp;quot; Introduction to Latent Semantic Analysis &amp;quot; Discourse Processes, 25, 259-284.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R Huang</author>
</authors>
<title>Hansen J.H.L.2007 &amp;quot;Dialect Classification on Printed Text using Perplexity Measure and Conditional Random Fields,&amp;quot;</title>
<journal>IEEE- ICASSP</journal>
<marker>Huang, </marker>
<rawString>Huang R; Hansen J.H.L.2007 &amp;quot;Dialect Classification on Printed Text using Perplexity Measure and Conditional Random Fields,&amp;quot; IEEE- ICASSP</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hasegawa-Johnson</author>
<author>S E Levinson</author>
</authors>
<title>Extraction of pragmatic and semantic salience from spontaneous spoken English &amp;quot;</title>
<date>2006</date>
<journal>Speech Comm.</journal>
<volume>Vol.</volume>
<pages>48--3</pages>
<marker>Hasegawa-Johnson, Levinson, 2006</marker>
<rawString>Hasegawa-Johnson M, Levinson S.E, 2006 &amp;quot;Extraction of pragmatic and semantic salience from spontaneous spoken English &amp;quot; Speech Comm. Vol. 48(3-4)</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-Y Antoine</author>
</authors>
<title>Spontaneous speech and natural language processing. ALPES: a robust semantic-led parser &amp;quot; ICSLP</title>
<date>1996</date>
<marker>Antoine, 1996</marker>
<rawString>Antoine, J.-Y 1996 &amp;quot; Spontaneous speech and natural language processing. ALPES: a robust semantic-led parser &amp;quot; ICSLP</rawString>
</citation>
<citation valid="false">
<authors>
<author>Deerwester S et</author>
</authors>
<title>al.1990.&amp;quot; Indexing by latent semantic anlysis &amp;quot;</title>
<journal>Journal of American Society of Information Science,</journal>
<pages>391--407</pages>
<marker>et, </marker>
<rawString>Deerwester.S. et al.1990.&amp;quot; Indexing by latent semantic anlysis &amp;quot; Journal of American Society of Information Science, 391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H L R Hansen</author>
</authors>
<title>Multi stream based Dialect classification using SVM-GMM hybrids&amp;quot;</title>
<date>2007</date>
<journal>IEEEASRU</journal>
<contexts>
<context position="2802" citStr="Hansen, 2007" startWordPosition="459" endWordPosition="460">ic classification is a popular method for text-independent dialect classification (Huang and Hansen, 2006) and therefore it is used as a baseline for our system. Fig. 2 shows the block diagram of the baseline gender-independent MFCC based GMM training system with 600 mixtures for each dialect. While testing, the incoming audio is classified as a particular dialect based on the maximum posterior probability measure over all the Gaussian Mixture Models. Mixture and frame selection based techniques as well as SVM-GMM hybrid techniques have been considered for dialect classification (Chitturi and Hansen, 2007). In order to assess the improvement by leveraging audio and text, we did not include these audio classification improvements in this study. 5 Dialect Classification using Language As shown in Fig 1, the language based dialect classification module has two distinct classifiers. We describe in detail the n-gram and LSA based classifiers in the sections 5.1 and 5.2 5.1 N-gram based dialect classification It is assumed that the text document is composed of many sentences. Each sentence can be regarded as a sequence of words W. The probability of generating W is given by . Assuming the probability</context>
</contexts>
<marker>Hansen, 2007</marker>
<rawString>Chitturi. R, Hansen J.H.L, 2007.&amp;quot; Multi stream based Dialect classification using SVM-GMM hybrids&amp;quot; IEEEASRU</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L H R Hansen</author>
</authors>
<title>Gaussian Mixture Selection and Data Selection for Unsupervised Spanish Dialect Classification”</title>
<date>2006</date>
<publisher>ICSLP</publisher>
<contexts>
<context position="2295" citStr="Hansen, 2006" startWordPosition="377" endWordPosition="378">System Architecture The system architecture is shown in Fig 1, which consists of two main system phases for acoustic and language classifiers. MFCC based classifiers are used for acoustic modeling, while for language modeling, we use a combination of n-gram language modes and LSA classifiers. In the final phase, we combine the acoustic and language classifiers into our final dialect classifier. To construct the overall system, we first train the individual classifiers, and then set the GMM based acoustic classification is a popular method for text-independent dialect classification (Huang and Hansen, 2006) and therefore it is used as a baseline for our system. Fig. 2 shows the block diagram of the baseline gender-independent MFCC based GMM training system with 600 mixtures for each dialect. While testing, the incoming audio is classified as a particular dialect based on the maximum posterior probability measure over all the Gaussian Mixture Models. Mixture and frame selection based techniques as well as SVM-GMM hybrid techniques have been considered for dialect classification (Chitturi and Hansen, 2007). In order to assess the improvement by leveraging audio and text, we did not include these a</context>
</contexts>
<marker>Hansen, 2006</marker>
<rawString>Huang. R, Hansen J.L.H.; 2006. “Gaussian Mixture Selection and Data Selection for Unsupervised Spanish Dialect Classification” ICSLP</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H L Hansen</author>
<author>Huang R Yapanel U</author>
<author>A Ikeno</author>
</authors>
<title>Dialect Anal&apos;ysis and Modeling for Automatic Classification” ICSLP</title>
<date>2004</date>
<marker>Hansen, U, Ikeno, 2004</marker>
<rawString>Hansen J.H.L., Yapanel.U, Huang.R., Ikeno.A..; 2004. “Dialect Anal&apos;ysis and Modeling for Automatic Classification” ICSLP</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST- LRE</author>
</authors>
<title>Language Recognition Evaluation”</title>
<date>2005</date>
<marker>LRE, 2005</marker>
<rawString>NIST- LRE 2005,” Language Recognition Evaluation”</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>