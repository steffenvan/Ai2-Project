<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000006">
<title confidence="0.9982315">
Improved Statistical Machine Translation
Using Monolingually-Derived Paraphrases
</title>
<author confidence="0.998865">
Yuval Marton,* Chris Callison-Burch,† and Philip Resnik*
</author>
<affiliation confidence="0.999605333333333">
*Department of Linguistics and the CLIP Lab
at the Institute for Advanced Computer Studies (UMIACS)
University of Maryland College Park, MD 20742-7505, USA
</affiliation>
<email confidence="0.886415">
{ymarton,resnik}@umiacs.umd.edu
</email>
<affiliation confidence="0.7999805">
†Computer Science Department, Johns Hopkins University
3400 N. Charles Street (CSEB 226-B) Baltimore, MD 21218
</affiliation>
<email confidence="0.998378">
ccb@cs.jhu.edu
</email>
<sectionHeader confidence="0.993894" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999978142857143">
Untranslated words still constitute a ma-
jor problem for Statistical Machine Trans-
lation (SMT), and current SMT systems
are limited by the quantity of parallel
training texts. Augmenting the training
data with paraphrases generated by pivot-
ing through other languages alleviates this
problem, especially for the so-called “low
density” languages. But pivoting requires
additional parallel texts. We address this
problem by deriving paraphrases monolin-
gually, using distributional semantic simi-
larity measures, thus providing access to
larger training resources, such as compa-
rable and unrelated monolingual corpora.
We present what is to our knowledge the
first successful integration of a colloca-
tional approach to untranslated words with
an end-to-end, state of the art SMT sys-
tem demonstrating significant translation
improvements in a low-resource setting.
</bodyText>
<sectionHeader confidence="0.999115" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999588961538462">
Phrase-based systems, flat and hierarchical alike
(Koehn et al., 2003; Koehn, 2004b; Koehn et al.,
2007; Chiang, 2005; Chiang, 2007), have achieved
a much better translation coverage than word-
based ones (Brown et al., 1993), but untranslated
words remain a major problem in SMT. For ex-
ample, according to Callison-Burch et al. (2006),
a SMT system with a training corpus of 10,000
words learned only 10% of the vocabulary; the
same system learned about 30% with a training
corpus of 100,000 words; and even with a large
training corpus of nearly 10,000,000 words it only
reached about 90% coverage of the source vocab-
ulary. Coverage of higher order n-gram levels is
even harder. This problem plays a major part in re-
ducing machine translation quality, as reflected by
both automatic measures such as BLEU (Papineni
et al., 2002) and human judgment tests. Improving
translation coverage accurately is therefore impor-
tant for SMT systems.
The first solution that might come to mind is
to use larger parallel training corpora. However,
current state-of-the-art SMT systems cannot learn
from non-aligned corpora, while sentence-aligned
parallel corpora (bitexts) are a limited resource
(See Section 2 for discussion of automatically-
compiled bitexts). Another direction might be
to make use of non-parallel corpora for training.
However, this requires developing techniques to
extract alignments or translations from them, and
in a sufficiently fast, memory-efficient, and scal-
able manner. One approach that can, in princi-
ple, better exploit both alignments from bitexts
and make use of non-parallel corpora is the dis-
tributional collocational approach, e.g., as used by
Fung and Yee (1998) and Rapp (1999). However,
the systems described there are not easily scalable,
and require pre-computation of a very large col-
location counts matrix. Related attempts propose
generating bitexts from comparable and “quasi-
comparable” bilingual texts by iteratively boot-
strapping documents, sentences, and words (Fung
and Cheung, 2004), or by using a maximum
entropy classifier (Munteanu and Marcu, 2005).
Alignment accuracy remains a challenge for them.
Recent work has proposed augmenting the
training data with paraphrases generated by pivot-
ing through other languages (Callison-Burch et al.,
2006; Madnani et al., 2007). This indeed allevi-
ates the vocabulary coverage problem, especially
for the so-called “low density” languages. How-
ever, these approaches still require bitexts where
</bodyText>
<page confidence="0.979301">
381
</page>
<note confidence="0.99661">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 381–390,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999878971428572">
one side contains the original source language.
The paradigm described in this paper involves
constructing monolingual distributional profiles
(DPs; a.k.a. word association profiles, or co-
occurrence vectors) of out-of-vocabulary words
and phrases in the source language; then, gener-
ating paraphrase candidates from phrases that co-
occur in similar contexts, and assigning them sim-
ilarity scores. The highest ranking paraphrases
are used to augment the translation phrase table.
The table augmentation idea is similar to Callison-
Burch et al.’s (Callison-Burch et al., 2006), but
our proposed paradigm does not require using a
limited resource such as parallel texts in order
to generate paraphrases. Moreover, our proposed
paradigm can, in principle, achieve large-scale ac-
quisition of paraphrases with high semantic simi-
larity. However, using parallel training texts in
pivoting techniques offers the potential advantage
of implicit translational knowledge, in the form
of sentence alignments, while our approach is un-
guided in this respect. Therefore, we conducted
experiments to find out how these relative advan-
tages play out. We present here, to our knowledge
for the first time, positive results of integrating dis-
tributional monolingually-derived paraphrases in
an end-to-end state-of-the-art SMT system.
In the rest of this paper we discuss related work
in Section 2, describe the distributional hypothesis
and distributional profiles in Section 3, and present
the monolingually-derived paraphrase generation
system in Section 4. We report our experiments
and results in Section 5, and conclude by dis-
cussing the implications and future research direc-
tions in Section 6.
</bodyText>
<sectionHeader confidence="0.999766" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999871184615385">
This is not the first to attempt to ameliorate the
out-of-vocabulary (OOV) words problem in sta-
tistical machine translation, and other natural lan-
guage processing tasks. This work is most closely
related to that of Callison-Burch et al. (2006),
who also translate source-side paraphrases of the
OOV phrases. There, paraphrases are generated
from bitexts of various language pairs, by “pivot-
ing”: translating the OOV phrases to an additional
language (or languages) and back to the source
language. The quality of these paraphrases is es-
timated by marginalizing translation probabilities
to and from the additional language side(s) e, as
follows: p(f2|f1) = &amp; p(e|f1)p(f2|e). A ma-
jor disadvantage of their approach is that it relies
on the availability of parallel corpora in other lan-
guages. While this works for English and many
European languages, it is far less likely to help
when translating from other source languages, for
which bitexts are scarce or non-existent. Also,
the pivoting approach is inherently noisy (in both
the paraphrase candidates’ correct sense, and their
translational likelihood), and it is likely to fare
poorly with out-of-domain translation. One ad-
vantage of the bitext-dependent pivoting approach
is the use of the additional human knowledge that
is encapsulated in the parallel sentence alignment.
However, we argue that the ability to use much
larger resources for paraphrasing should trump the
human knowledge advantage.
More recently, Callison-Burch (2008) has im-
proved performance of this pivoting technique by
imposing syntactic constraints on the paraphrases.
The limitation of such an approach is the reliance
on a good parser (in addition to reliance on bi-
texts), but a good parser is not available in all
languages, especially not in resource-poor lan-
guages. Another approach using a pivoting tech-
nique augments the human reference translation
with paraphrases, creating additional translation
“references” (Madnani et al., 2007). Both ap-
proaches have shown gains in BLEU score.
Barzilay and McKeown (2001) extract para-
phrases from a monolingual parallel corpus, con-
taining multiple translations of the same source.
In addition to the parallel corpus usage limitations
described above, this technique is further limited
by the small size of such materials, which are even
scarcer than the resources in the pivoting case.
Dolan et al. (2004) explore generating para-
phrases by edit-distance and headlines of time-
and topic-clustered news articles; they do not ad-
dress the OOV problem directly, as their focus
is sentence-level paraphrases; although they use
a standard SMT measure, alignment error rate
(AER), they only report results of the alignment
quality, and not of an end-to-end SMT system.
Much of the previous research largely focused on
morphological analysis in order to reduce type
sparseness; Callison-Burch et al. (2006) list some
of the influential work in that direction.
Work that relies on the distributional hypoth-
esis using bilingual comparable corpora (with-
out the need for bitexts), typically uses a seed
lexicon for “bridging” source language phrases
</bodyText>
<page confidence="0.997337">
382
</page>
<bodyText confidence="0.999939666666667">
with their target languages paraphrases (Fung and
Yee, 1998; Rapp, 1999; Diab and Finch, 2000).
This approach is sometimes viewed as, or com-
bined with, an information retrieval (IR) approach,
and normalizes strength-of-association measures
(see Section 3) with IR-related measures such as
TF/IDF (Fung and Yee, 1998). To date, reported
implementations suffer from scalability issues, as
they pre-compute and hold in memory a huge col-
location matrix; we know of no report of using this
approach in an end-to-end SMT system.
Another approach aiming to reduce OOV rate
concentrates on increasing parallel training set
size without using more dedicated human transla-
tion (Resnik and Smith, 2003; Oard et al., 2003).
</bodyText>
<sectionHeader confidence="0.997196" genericHeader="method">
3 Collocational Profiles
</sectionHeader>
<bodyText confidence="0.967734266666667">
The distributional hypothesis and distribu-
tional profiles. Natural language processing
(NLP) applications that assume the distributional
hypothesis (Harris, 1940; Firth, 1957) typically
keep track of word co-occurrences in distribu-
tional profiles (a.k.a. collocation vectors, or con-
text vectors). Each distributional profile DPu
(for some word u) keeps counts of co-occurrence
of u with all words within a usually fixed dis-
tance from each of its occurrences (a sliding win-
dow) in some training corpus. More advanced pro-
files keep “strength of association” (SoA) infor-
mation between u and each of the co-occurring
words, which is calculated from the counts of u,
the counts of the other word, their co-occurrence
count, and the count of all words in the corpus
(corpus size). The information on the other words
with respect to u is typically kept in a vector whose
dimensions correspond to all words in the training
corpus. This is described in Equation (1), where
V is the training corpus vocabulary:
DPu = {&lt; wz, SoA(u, wz) &gt; |u, wz E V } (1)
for all i s.t. 1 &lt; i &lt;  |V
Semantic similarity between words u and v can
be estimated by calculating the similarity (vector
distance) between their profiles. Slightly more for-
mally, the distributional hypothesis assumes that
if we had access to the hypothetical true (psycho-
linguistic) semantic similarity function over word
pairs, semsim(u, v), then
</bodyText>
<equation confidence="0.87387025">
Vu, v, w E V,
[semsim(u, v) &gt; semsim(u, w)] =�
[psim(DPu, DP„) &gt; psim(DPu, DPw)],
(2)
</equation>
<bodyText confidence="0.999803609756098">
where V is the language vocabulary, DPword is
the distributional profile of word, and psim() is
a 2-place vector similarity function (all further
described below). Paraphrasing and other NLP
applications that are based on the distributional
hypothesis assume entailment in the reverse di-
rection: the right-hand-side of Formula (2) (pro-
file/vector similarity) entails the left-hand-side
(semantic similarity).
The sliding window and word association (SoA)
measures. Some researchers count positional
collocations in a sliding window, i.e., the co-
counts and SoA measures are calculated per rel-
ative position (e.g., for some word/token u, po-
sition 1 is the token immediately after u; posi-
tion -2 is the token preceding the token that pre-
cedes u) (Rapp, 1999); other researchers use non-
positional (which we dub here flat) collocations,
meaning, they count all token occurrences within
the sliding window, regardless of their positions
in it relative to u (McDonald, 2000; Mohammad
and Hirst, 2006). We use here flat collocations
in a 6-token sliding window. Beside simple co-
occurrence counts within sliding windows, other
SoA measures include functions based on TF/IDF
(Fung and Yee, 1998), mutual information (PMI)
(Lin, 1998), conditional probabilities (Schuetze
and Pedersen, 1997), chi-square test, and the log-
likelihood ratio (Dunning, 1993).
Profile similarity measures. A profile similar-
ity function psim(DPu, DP„) is typically defined
as a two-place function, taking vectors as argu-
ments, each vector representing a distributional
profile of some word u and v, respectively, and
whose cells contain the SoA of u (or v) with each
word (“collocate”) in the known vocabulary. Sim-
ilarity can be (and have been) estimated in several
ways, e.g., the cosine coefficient, the Jaccard co-
efficient, the Dice coefficient, and the City-Block
measure. The formula for the cosine function for
similarity measure is given in Eq. (3):
</bodyText>
<page confidence="0.934384">
383
</page>
<equation confidence="0.9868835">
psim(DPu, DP„)
= cos(DPu, DP„)
E 5oA(u, wz)5oA(v, wz)
wi∈V
=
�5oA(u, wz)2 5oA(v, wz)2
wi∈V wi∈V
(3)
</equation>
<bodyText confidence="0.999555892857143">
In principle, any SoA can be used with any
profile similarity measure. However, in practice,
only some SoA/similarity measure combinations
do well, and finding the best combination is still
more art than science. Some successful combina-
tions are cosCP (Schuetze and Pedersen, 1997),
LinPmI (Lin, 1998), CityLL (Rapp, 1999), and
Jensen–Shannon divergence of conditional prob-
abilities (J5DCP). We use here cosine of log-
likelihood vectors (McDonald, 2000).
Phrasal distributional profiles. Word DPs can
be generalized to phrasal DPs, simply by count-
ing words that co-occur within a sliding window
around the target phrase’s occurrences (i.e., count-
ing occurrences of words up to 6 words before
or after the target phrase). For example, when
building a DP for the target phrase counting words
in the previous sentence, then simply is in rela-
tive position -2, and sliding is in relative posi-
tion 5. Searching for similar phrasal DPs poses
an additional challenge over the word DP case
(see Section 4), but there is no additional diffi-
culty in building the phrasal profile itself as de-
scribed above. In preliminary experiments we
found no gain in using phrasal collocates (i.e.,
count how many times a phrase of more than one
word co-occurs in a sliding window around the tar-
get word/phrase).
</bodyText>
<sectionHeader confidence="0.6715575" genericHeader="method">
4 Searching and Scoring Phrasal
Paraphrases
</sectionHeader>
<bodyText confidence="0.9962869">
The system design is as follows: upon receiv-
ing OOV phrase phr, build distributional profile
DPph,.. Next, gather contexts: for each occur-
rence of phr, keep surrounding (left and right)
context L__R. For each such context, gather para-
phrase candidates X which occur between L and
R in other locations in the training corpus, i.e.,
all X such that LXR occur in the corpus. Fi-
nally, rank all candidates X, by building distribu-
tional profile DPX and measuring profile similar-
ity between DPX and DPph,., for each X. Output
k-best candidates above a certain similarity score
threshold. The rest of this section describes this
system in more detail.
Build phrasal profile DPph,.. Build a profile of
all word collocates, as described in Section 3. Use
sliding window of size MaxPos = 6. If phr
is very frequent (above some threshold of t oc-
currences), uniformly sample only t occurrences,
multiplying the gathered co-counts by factor of
count(phr)/t. We set t = 10000.
Gather context. The challenge in choosing the
relevant context is this: if it is very short and/or
very frequent (e.g., “the __ is”), then it might not
be very informative, in the sense that many words
can appear in that context (in this example, practi-
cally any noun); however, if it is too long (too spe-
cific), then it might not occur enough times else-
where (or not at all) in the training corpus. There-
fore, to balance between these two extremes, we
use the following heuristics. Start small: Start
with setting the left part of the context L to be a
single word/token to the left of phrase phr. If it
is stoplisted, append the next word to the left (now
having a bigram left context instead of a unigram),
and repeat until the left context is not in the sto-
plist. Repeat similarly for R, the context to the
right of phr. Add the resulting L__R context to
a context list. We stoplist “promiscuous” words,
i.e., those that have more than 5toplistThreshold
collocates in the training corpus, using the above
MaxPos parameter value. We also stoplist bi-
grams which occur more than t times and com-
prise solely from stoplisted unigrams.
Gather candidates. For each gathered context
in the context list, gather all paraphrase candidate
phrases X that connect left hand side context L
with right hand side context R, i.e., gather all X
such that the sequence LXR occurs in the corpus.
In practice, to keep search complexity low, limit
X to be up to length MaxPhraseLen. Also, to
further speed up runtime, we uniformly sample the
context occurrences.
Rank candidates. For each candidate X,
build distributional profile DPX, and evaluate
psim(DPph,., DPX).
Output k-best candidates. Output k-best para-
phrase candidates for phrase phr, in descending
order of similarity. We set k = 20. Filter out para-
phrases with score less than min5core.
</bodyText>
<page confidence="0.997695">
384
</page>
<sectionHeader confidence="0.998597" genericHeader="evaluation">
5 Experiment
</sectionHeader>
<bodyText confidence="0.922746161290322">
We examined the application of the system’s para-
phrases to handling unknown phrases when trans-
lating from English into Chinese (E2C) and from
Spanish into English (S2E). For all baselines we
used the phrase-based statistical machine transla-
tion system Moses (Koehn et al., 2007), with the
default model features, weighted in a log-linear
framework (Och and Ney, 2002). Feature weights
were set with minimum error rate training (Och,
2003) on a development set using BLEU (Papineni
et al., 2002) as the objective function. Test re-
sults were evaluated using BLEU and TER (Snover
et al., 2005). The phrase translation probabili-
ties were determined using maximum likelihood
estimation over phrases induced from word-level
alignments produced by performing Giza++ train-
ing (Och and Ney, 2000) on both source and tar-
get sides of the parallel training sets. When the
baseline system encountered unknown words in
the test set, its behavior was simply to reproduce
the foreign word in the translated output.
The paraphrase-augmented systems were iden-
tical to the corresponding baseline system, with
the exception of additional (paraphrase-based)
translation rules, and additional feature(s). Simi-
larly to Callison-Burch et al. (2006), we added the
following feature:
I psim(DPf , DPf) If phrase table entry (e, f)
is generated from (e, f&apos;)
using monolingually-
derived paraphrases.
</bodyText>
<equation confidence="0.648793">
1 Otherwise,
(4)
</equation>
<bodyText confidence="0.99994024">
Note that it is possible to construct a new trans-
lation rule from f to e via more than one pair of
source-side phrase and its paraphrase; e.g., if f1
is a paraphrase of f, and so is f2, and both f1, f2
translate to the same e, then both lead to the con-
struction of the new rule translating f to e, but
with potentially different feature scores.
In order to eliminate this duplicity and lever-
age over these alternate paths which can be used
to increase our confidence level in the new rule,
we did the following: For each paraphrase f
of some source-side phrases fi, with respec-
tive similarity scores sim(fi, f), we calculated
an aggregate score asim with a “quasi-online-
updating” method as follows: asimi = (1 −
asimi−1)sim(fi, f), where asim0 = 0. The ag-
gregate score asim is updated in an “online” fash-
ion with each pair fi, f as they are processed, but
only the final asimk score is used, after all k pairs
have been processed. Simple arithmetics can show
that this method is insensitive to the order in which
the paraphrases are processed. We only augment
the phrase table with a single rule from f to e,
and in it are the feature values of the phrase fi for
which the score sim(fi, f) was the highest.
</bodyText>
<subsectionHeader confidence="0.876856">
5.1 English-to-Chinese Translation
</subsectionHeader>
<bodyText confidence="0.997501692307692">
For the English-Chinese (E2C) baseline system,
we trained on the LCD Sinorama and FBIS
tests (LCD2005T10 and LCD2003E14), and seg-
mented the Chinese side with the Stanford Seg-
menter (Tseng et al., 2005). After tokenization
and filtering, this bitext contained 231,586 lines
(6.4M + 5.1M tokens). We trained a trigram lan-
guage model on the Chinese side. We then split the
bitext to 32 even slices, and constructed a reduced
set of about 29,000 lines (sentences) by using only
every eighth slice. The purpose of creating this
subset model was to simulate a resource-poor lan-
guage. See Table 1.
</bodyText>
<table confidence="0.9997118">
Set # Tokens Source+Target
E2C 29K 0.8 + 0.6
E2C Full 6.4 + 5.1
bnc+apw 187
S2E 10K 0.3 + 0.3
S2E 20K 0.6 + 0.6
S2E 80K 2.3 + 2.3
wmt09 84
wmt09+acquis 139
wmt09+acquis+afp 402
</table>
<tableCaption confidence="0.999967">
Table 1: Training set sizes (million tokens).
</tableCaption>
<bodyText confidence="0.9997976">
For development, we used the Chinese-English
NIST MT 2005 evaluation set, taking one of the
English references as source, and the Chinese
source as a single reference translation. We tested
the system using the English-Chinese NIST MT
evaluation 2008 test set with its four reference
translations.
We augmented the E2C baseline models with
paraphrases generated as described above, train-
ing on the British National Corpus (BNC)
v3 (Burnard, 2000) and the first 3 million lines
of the English Gigaword v2 APW, totaling 187M
terms after tokenization, and number and punc-
tuation removal. We generated paraphrases for
phrases up to six tokens in length, and used an ar-
</bodyText>
<equation confidence="0.685589">
h(e, f) =
</equation>
<page confidence="0.9838">
385
</page>
<bodyText confidence="0.9999664375">
bitrary similarity threshold of minScore = 0.3.
We experimented with three variants: adding a
single additional feature for all paraphrases (1-
6grams); using only paraphrases of unigrams
(1grams); and adding two features, one only sen-
sitive to unigrams, and the other only to the rest
(1 + 2-6grams). All features had the same de-
sign as described in Section 5, each had an asso-
ciated weight (as all other features), and all fea-
ture weights in each system, including the base-
line, were tuned using a separate minimum error
rate training for each system.
Results are shown in Table 2. For the E2C sys-
tems, for which we had four reference translations
for the test set, we used shortest reference length,
and used the NIST-provided script to split the out-
put words to Chinese characters before evaluation.
Statistical significance for the BLEU results were
calculated using Koehn’s (Koehn, 2004) pair-wise
bootstrapping test with 95% confidence interval.
On the E2C 29,000-line subset, the augmented
system had a significant 1.7 BLEU points gain over
its baseline. On the full size model, results were
negative. Note that our E2C full size baseline
is reasonably strong: Its character-based BLEU
score is slightly higher than the JHU-UMD sys-
tem that participated in the NIST 2008 MT evalua-
tion (constrained training track), although we used
a subset of that system’s training materials, and
a smaller language model. Results there ranged
from 15.69 to 30.38 BLEU (ignoring a seeming
outlier of 3.93).
</bodyText>
<subsectionHeader confidence="0.99542">
5.2 Spanish-to-English Translation
</subsectionHeader>
<bodyText confidence="0.999953529411765">
In order to to permit a more direct comparison
with the pivoting technique, we also experimented
with Spanish to English (S2E) translation, fol-
lowing Callison-Burch et al. (2006). For base-
line we used the Spanish and English sides of
the Europarl multilingual parallel corpus (Koehn,
2005), with the standard training, development,
and test sets. We created training subset models
of 10,000, 20,000, and 80,000 aligned sentences,
as described in Callison-Burch et al. (2006). For
better comparison with their pivoting system, we
used the same 5-gram language model, develop-
ment and test sets: For development, we used the
Europarl dev2006 Spanish and English sides, and
for testing we used the Europarl 2006 test set.
We trained the Spanish paraphrase generation
system on the Spanish corpora available from
</bodyText>
<table confidence="0.999302666666667">
dataset E2C model BLEU TER
29k baseline 15.21 90.354
29k 1grams 16.87*** 90.370
29k 1-6grams 16.54*** 90.376
29k 1 + 2-6grams 16.88*** 90.349
Full baseline 22.17 90.398
Full 1grams 21.64*** 90.459
Full 1-6grams 21.75 90.421
Full 1 + 2-6grams 21.39*** 90.433
</table>
<tableCaption confidence="0.8130405">
Table 2: E2C Results: character-based BLEU and
TER scores. All models have one additional fea-
</tableCaption>
<bodyText confidence="0.973313">
ture over baseline, except for the &amp;quot;1 + 2-6&amp;quot; mod-
els that have one feature for unigrams and an-
other feature for bigrams to 6-grams. Paraphrases
with score &lt; .3 were filtered out. *** = sig-
nificance test over baseline with p &lt; 0.0001,
using Koehn’s (2004) pair-wise bootstrap resam-
pling test for BLEU with 95% confidence interval.
</bodyText>
<figure confidence="0.939058571428572">
Paraphrase Score
Source: deal
agreement 0.56
accord 0.53
talks 0.45
contract 0.42
peace deal 0.33
merger 0.32
agreement is 0.30
Source: fall
rise 0.87
slip 0.82
tumbled today 0.68
fell today 0.67
tumble 0.65
fall tokyo ap stock prices fell 0.56
are mixed 0.54
Source: to provide any other
to give any 0.74
to give further 0.70
to provide any 0.68
to give any other 0.62
to provide further 0.61
to provide other 0.53
to reveal any 0.52
to provide any further 0.48
to disclose any 0.47
to publicly discuss the 0.43
</figure>
<bodyText confidence="0.9122399">
Source: we have a situation that
uncontroversial question about our 0.66
obviously with the developments this morning 0.65
community staffing of community centres 0.64
perhaps we are getting rather impatient 0.63
er around the inner edge 0.60
interested in going to the topics 0.60
and that is the day that 0.60
as a as a final point 0.59
left which it may still have 0.56
</bodyText>
<tableCaption confidence="0.984756">
Table 3: English paraphrases from E2C 29K-
bitext systems.
</tableCaption>
<page confidence="0.998774">
386
</page>
<bodyText confidence="0.999958027027027">
the EACL 2009 Fourth Workshop on Statistical
Machine Translation:1 the Spanish side of the
Europarl-v4, news training 2008, and news com-
mentary 2009. We also re-trained adding the JRC-
Acquis-v3 corpus2 to the paraphrase training set,
and then adding also the LDC Spanish Gigaword
(LDC2006T12) and truncating the resulting cor-
pus after the first 150M lines. We lowercased
these training sets, tokenized and removed punc-
tuation marks and numbers, and this resulted in
training set sizes as detailed in Table 1. We gen-
erated paraphrases for phrases up to four tokens
in length, and used two arbitrary similarity thresh-
olds of minScore = 0.3 (as in the E2C experi-
ments), and 0.6, for enforcing only higher preci-
sion paraphrasing.
We experimented with these variants: a single
feature for all paraphrase (1-4grams); using only
paraphrases of unigrams (1grams); and using two
features: one only sensitive to unigrams and bi-
grams, and the other to the rest (1-2 + 3-4grams).
Results are shown in Table 4. We used BLEU
over lowercased outputs to evaluate all S2E sys-
tems, and Koehn’s significance test as above.
On the S2E 10,000-line subset, both the 1grams
and 1-4grams models achieved significant gains of
.4 BLEU points over the baseline. We concluded
from a manual evaluation of the 10,000-line mod-
els that the two major weaknesses of the baseline
system were (not surprisingly) number of untrans-
lated (OOV) words / phrases, followed by number
of superfluous words / phrases.
On the larger subset models, no system sig-
nificantly outperformed the baseline. Note that
our S2E baselines’ scores are higher than those
of Callison-Burch et al. (2006), since we evaluate
lowercased outputs, instead of recased ones.
</bodyText>
<sectionHeader confidence="0.99471" genericHeader="discussions">
6 Discussion and Future Work
</sectionHeader>
<bodyText confidence="0.9991859">
We have shown that monolingually-derived para-
phrases, based on distributional semantic similar-
ity measures over a source-language corpus, can
improve the performance of statistical machine
translation (SMT) systems. Our proposed method
has the advantage of not relying on bitexts in order
to generate the paraphrases, and therefore gives
access to large amounts of monolingual training
data, for which creating bitexts of equivalent size
is generally unfeasible. We haven’t trained our
</bodyText>
<footnote confidence="0.999323">
1http://www.statmt.org/wmt09
2http://wt.jrc.it/lt/Acquis
</footnote>
<bodyText confidence="0.999804960784314">
system on nearly as large a corpus as it can han-
dle, and indeed we see this as a natural next step.
Results support the assumption that a larger
monolingual paraphrase training set yields bet-
ter paraphrases: our S2E 1-4grams model per-
formed significantly better than baseline when us-
ing wmt09+aquis for paraphrasing, but when only
using wmt09, the model had a smaller advantage
that did not reach significance. However, for the
S2E 1grams model, there was a slight decrease in
performance when switching paraphrasing corpus
from wmt09+aquis to wmt09+aquis+afp. This ef-
fect might be due to the genre or unbalanced con-
tent of the additional corpus, or perhaps it is the
case that in this corpus size, paraphrases of higher-
level ngrams benefitted from the additional text
much more than paraphrases of unigrams did. The
two rightmost columns in Table 5 show that al-
though Spanish monolingual paraphrases for the
unigram baile improve when using the larger cor-
pus, (e.g., danza and un balie become the third and
fourth top candidates, pushing much worse candi-
dates far down the list), the two top paraphrase
candidates remained unchanged. However, for
the 4gram a favor del informe, antonymous can-
didates, which are bad and misleading for trans-
lation, are pushed down from the top first and
third spots by synonymous, better candidates. Ta-
ble 3 contains additional examples of good and
bad top paraphrase candidates, also in English.
Paraphrases of phrases seem to be of lower qual-
ity than those of unigrams, as can be seen at the
bottom of the table.
These results also show that our method is es-
pecially useful in settings involving low-density
languages or special domains: The smaller sub-
set models, emulating a resource-poor language
situation, show higher gains than larger models
(which are supersets of the smaller subset models),
when augmented with paraphrases derived from
the same paraphrase training set. This was vali-
dated in two very different language pairs: English
to Chinese, and Spanish to English. We believe
that larger monolingual training sets for paraphras-
ing can help languages with richer resources, and
we intend to explore this too.
Although the gains in the Spanish-English sub-
sets are somewhat smaller than the pivoting tech-
nique reported in Callison-Burch et al. (2006),
e.g., .7 BLEU for the 10k subset, we take these
results as a proof of concept that can yield better
</bodyText>
<page confidence="0.993742">
387
</page>
<table confidence="0.999830214285714">
bitext mono.corp. features minScore BLEU TER
10k (baseline) – – 23.78 62.382
10k wmt09 1-4grams .6 23.81
10k wmt09 1-2+3-4gr .6 23.92 62.202
10k wmt09+aquis 1-4grams .6 24.13*** 61.739
10k wmt09+aquis 1grams .6 24.11 61.979
20k (baseline) – – 24.68 62.333
20k wmt09+aquis 1-4grams .6 24.75 61.528
80k (baseline) – – 27.89 57.977
80k wmt09+aquis 1-4grams .6 27.82 57.906
10k wmt09+aquis 1grams .3 24.11 61.979
10k wmt09+aquis+afp 1grams .3 23.97 61.974
20k wmt09+aquis+afp 1grams .3 24.77 61.276
80k wmt09+aquis+afp 1grams .3 27.84*** 57.781
</table>
<tableCaption confidence="0.951913666666667">
Table 4: S2E Results: Lowercase BLEU and TER. Paraphrases with score &lt; minScore were filtered out.
*** = significance test over baseline with p &lt; 0.0001, using Koehn’s (2004) pair-wise bootstrap test for
BLEU with 95% confidence interval.
</tableCaption>
<figure confidence="0.435491375">
pivot wmt09+acquis wmt09+acquis+afp
Source: baile
danza el baile el baile
bailar baile y baile y
a de david palomar y la danza
dans viejo como quien se acomoda una un baile
empresa por julidn estrada el tercero de teatro
coro al baile a la baloncesto el cine
</figure>
<subsectionHeader confidence="0.669357">
Source: a favor del informe
</subsectionHeader>
<bodyText confidence="0.976377777777778">
a favor de este informe en contra del informe favor del informe
favor del informe a favor de este informe en contra del informe
el informe en contra de este informe a favor de este informe
a favor a favor de la resolución en contra de este informe
por el informe a favor de esta resolución en contra de la resolución
al informe a favor del informe del señor a favor del informe del sr.
su a favor del informe del sr. en contra del informe del sr.
del informe en contra de la propuesta a favor del excelente informe
de este informe contra el informe a favor del informe deprez
</bodyText>
<tableCaption confidence="0.9728425">
Table 5: Comparison of Spanish paraphrases: by pivoting, and by two monolingual corpora. Ordered
from best to worst score.
</tableCaption>
<subsectionHeader confidence="0.81764">
system example
</subsectionHeader>
<bodyText confidence="0.98295175">
source cuando escucho las distintas intervenciones , creo que quienes afirman que deberíamos analizar
nuestras prioridades y limitar el número de objetivos que queremos conseguir , estdn en lo cierto .
reference when i listen to the various comments made, i find myself agreeing with those who recommend
that we take a look at our priorities and then limit the number of aims we want to achieve
baseline escucho when the various speeches, i believe that those who afirman that we should our
environmental limitar priorities and the number of objectives we want to achieve, are in this way.
pivoting (MW) when i can hear the various speeches , i believe that those people that we should look at our
priorities and to limit the number of objectives we want to achieve , are in fact.
</bodyText>
<footnote confidence="0.5788295">
wmt09+acquis escucho when the various speeches, i believe that those who claiming that we should environmental
.1-4grams limitar our priorities and the number of objectives we want to achieve, are on the way.
wmt09+acquis escucho when the various speeches, i believe that those who considered that we should our
.1grams environmental priorities and reducing the number of objectives we want to achieve, are on the way.
wmt09+acquis+afp escucho when the various speeches, i believe that those who say that we should our environmental
.1grams priorities and reduce the number of objectives we want to achieve, are on the way.
</footnote>
<tableCaption confidence="0.947162">
Table 6: S2E translation examples on 10k-bitext systems. Some translation differences are in bold.
</tableCaption>
<page confidence="0.997569">
388
</page>
<bodyText confidence="0.999974410714286">
gains with larger monolingual training sets. Pivot-
ing techniques (translating back and forth) rely on
limited resources (bitexts), and are subject to shifts
in meaning due to their inherent double transla-
tion step. In contrast, large monolingual resources
are relatively easy to collect, and our system in-
volves only a single translation/paraphrasing step
per target phrase. Table 5 also shows an exemplar
comparison with the pivoting paraphrases used in
Callison-Burch et al. (2006). It seems that the piv-
oting paraphrases might suffer more from having
frequent function words as top candidates, which
might be a by-product of their alignment “promis-
cuity”. However, the top antonymous candidate
problem seems to mainly plague the monolin-
gual distributional paraphrases (but improves with
larger corpora). See also Table 6.
The paraphrase quality remains an issue with
this method (as with all other paraphrasing meth-
ods). Some possible ways of improving it, be-
sides using larger corpora, are: using syntactic in-
formation (Callison-Burch, 2008), using semantic
knowledge such as thesaurus or WordNet to per-
form word sense disambiguation (WSD) (Resnik,
1999; Mohammad and Hirst, 2006), improving
the similarity measure, and refining the similarity
threshold. We would like to explore ways of incor-
porating syntactic knowledge that do not sacrifice
coverage as much as in Callison-Burch (2008); in-
corporating semantic knowledge to disambiguate
phrasal senses; using context to help sense disam-
biguation (Erk and Padó, 2008); and optimizing
the similarity threshold for use in SMT, for exam-
ple on a held-out dataset: too high a threshold re-
duces coverage, while too low a threshold results
in bad paraphrases and translation.
The method presented here is quite general, and
therefore different similarity measures, including
other corpus-based ones, can be plugged in to gen-
erate paraphrases. We are looking into using DPs
with word-sense disambiguation: Since it has been
shown that similarity is often judged by the se-
mantic distance of the closest senses of the two
target words (Mohammad and Hirst, 2006), and
that paraphrases generated this way are likely to
be of higher quality (Marton et al., 2009), hence
it is also likely that the overall performance of an
SMT system using them will also improve further.
One potential advantage of using bitexts for
paraphrase generation is the usage of implicit hu-
man knowledge, i.e., sentence alignments. The
concern that not using this knowledge would turn
out detrimental to the performance of SMT sys-
tems augmented by paraphrases as described here
was largely put to rest, as our method improved
the tested subset SMT systems’ quality.
</bodyText>
<sectionHeader confidence="0.995494" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999844090909091">
Many thanks to Chris Dyer for his help with
the E2C set, and to Adam Lopez for his imple-
mentation of pattern matching with Suffix Ar-
ray. This research was partially supported by
the GALE program of the Defense Advanced Re-
search Projects Agency, Contract No. HR0011-
06-2-001 and NSF award 0838801, by the Euro-
MatrixPlus project funded by the European Com-
mission, and by the US National Science Foun-
dation under grant IIS-0713448. The views and
findings are the authors’ alone.
</bodyText>
<sectionHeader confidence="0.998827" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998456714285714">
Regina Barzilay and Kathleen McKeown. 2001. Ex-
tracting paraphrases from a parallel corpus. In Pro-
ceedings of ACL-2001.
P.F. Brown, S.A.D. Pietra, V.J.D. Pietra, and R.L. Mer-
cer. 1993. The mathematics of statistical machine
translation. Computational Linguistics, 19(2):263–
313.
Lou Burnard. 2000. Reference Guide for the British
National Corpus. Oxford University Computing
Services, Oxford, England, world edition edition.
Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved statistical machine trans-
lation using paraphrases. In Proceedings NAACL-
2006.
Chris Callison-Burch. 2008. Syntactic constraints on
paraphrases extracted from parallel corpora. In Pro-
ceedings of EMNLP 2008, Waikiki, Hawai’i.
David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of ACL-05, pages 263–270.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33(2):201–228.
Mona Diab and Steve Finch. 2000. A statistical word-
level translation model for comparable corpora. In
Proceedings of the Conference on Content-Based
Multimedia Information Access (RIAO).
B. Dolan, C. Quirk, and C. Brockett. 2004. Unsu-
pervised construction of large paraphrase corpora:
exploiting massively parallel news sources. In Pro-
ceedings of the 20th International Conference on
Computational Linguistics of the Association for
Computational Linguistics, Geneva, Switzerland.
T. Dunning. 1993. Accurate methods for the statistics
of surprise and coincidence. Computational Lin-
guistics, 19(1):61–74.
</reference>
<page confidence="0.988422">
389
</page>
<reference confidence="0.999765140350877">
Katrin Erk and Sebastian Padó. 2008. A struc-
tured vector space model for word meaning in con-
text. In Proceedings of the Conference on Empirical
Methods in Natural Language Processing (EMNLP-
2086), pages 897–906, Honolulu, HI.
John R. Firth. 1957. A synopsis of linguistic theory
1930 ˝U55. Studies in Linguistic Analysis, (special
volume of the Philological Society):1–32. Distribu-
tional Hypothesis.
Pascale Fung and Percy Cheung. 2004. Multi-
level bootstrapping for extracting parallel sentences
from a quasi-comparable corpus. In Proceedings of
the 20th international conference on Computational
Linguistics, page 1051, Geneva, Switzerland. Asso-
ciation for Computational Linguistics.
Pascale Fung and Lo Yuen Yee. 1998. An ir approach
for translating new words from nonparallel, com-
parable texts. In Proceedings of COLING-ACL98,
pages 414–420, Montreal, Canada.
Zellig S. Harris. 1940. Review of louis h. gray, foun-
dations of language (new york: Macmillan, 1939).
Language, 16(3):216 ˝U231.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of HLT-NAACL, pages 127–133.
Philipp Koehn, Hieu Hoang, Alexandra Birch,
Chris Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine
Moran Richard Zens, Chris Dyer, Ondrej Bojar,
Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open source toolkit for statistical machine
translation. In Annual Meeting of the Association
for Computational Linguistics (ACL), demonstration
session, Prague, Czech Republic.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proc. EMNLP.
Philipp Koehn. 2004b. Pharaoh: A beam search de-
coder for phrase-based statistical machine transla-
tion models. In Proceedings of AMTA.
Philipp Koehn. 2005. A parallel corpus for statistical
machine translation. In Proceedings of MT-Summit.
Dekang Lin. 1998. An information-theoretic defini-
tion of similarity. In Proceedings of the 15th In-
ternational Conference on Machine Learning, pages
296–304, San Francisco, CA.
Nitin Madnani, Necip Fazil Ayan, Philip Resnik, and
Bonnie Dorr. 2007. Using paraphrases for parame-
ter tuning in statistical machine translation. In Pro-
ceedings of the ACL Workshop on Statistical Ma-
chine Translation.
Yuval Marton, Saif Mohammad, and Philip Resnik.
2009. Estimating semantic distance using soft se-
mantic constraints in knowledge-source / corpus hy-
brid models. In Procedings of EMNLP, Singapore.
S. McDonald. 2000. Environmental determinants of
lexical processing effort. Ph.D. thesis, University of
Edinburgh.
Saif Mohammad and Graeme Hirst. 2006. Distribu-
tional measures of concept-distance: A task-oriented
evaluation. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP-2006), Sydney, Australia.
Dragos Stefan Munteanu and Daniel Marcu. 2005. Im-
proving machine translation performance by exploit-
ing non-parallel corpora. Computational Linguis-
tics, 31(4):477–504.
Doug Oard, David Doermann, Bonnie Dorr, Daqing
He, Phillip Resnik, William Byrne, Sanjeeve Khu-
danpur, David Yarowsky, Anton Leuski, Philipp
Koehn, and Kevin Knight. 2003. Desperately seek-
ing cebuano. In Proceedings of HLT-NAACL.
Franz Josef Och and Hermann Ney. 2000. Improved
statistical alignment models. In Proceedings of the
38th Annual Meeting of the ACL, pages 440–447.
Franz Josef Och and Hermann Ney. 2002. Discrimina-
tive training and maximum entropy models for sta-
tistical machine translation. In Proceedings of ACL.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting of the ACL, pages 160–167.
Kishore Papineni, Salim Roukos, Todd Ward, John
Henderson, and Florence Reeder. 2002. Corpus-
based comprehensive and diagnostic MT evaluation:
Initial Arabic, Chinese, French, and Spanish results.
In Proceedings of the ACL Human Language Tech-
nology Conference, pages 124–127, San Diego, CA.
Reinhard Rapp. 1999. Automatic identification of
word translations from unrelated english and german
corpora. In Proceedings of the 37th Annual Confer-
ence of the Association for Computational Linguis-
tics., pages 519–525.
Philip Resnik and Noah Smith. 2003. The web
as a parallel corpus. Computational Linguistics,
29(3):349–380.
Philip Resnik. 1999. Semantic similarity in a taxon-
omy: An information-based measure and its appli-
cation to problems of ambiguity in natural language.
Journal of Artificial Intelligence Research (JAIR),
11:95–130.
Hinrich Schuetze and Jan O. Pedersen. 1997. A
cooccurrence-based thesaurus and two applications
to information retreival. Information Processing
and Management, 33(3):307 ˝U318.
Matthew Snover, Bonnie J. Dorr, Richard Schwartz,
John Makhoul, Linnea Micciulla, and Ralph
Weischedel. 2005. A study of translation error rate
with targeted human annotation. Technical Report
LAMP-TR-126, CS-TR-4755, UMIACS-TR-2005-
58, University of Maryland, July, 2005.
Huihsin Tseng, Pichuan Chang, Galen Andrew, Daniel
Jurafsky, and Christopher Manning. 2005. A con-
ditional random field word segmenter. In Fourth
SIGHAN Workshop on Chinese Language Process-
ing.
</reference>
<page confidence="0.998248">
390
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.184381">
<title confidence="0.984686">Improved Statistical Machine Using Monolingually-Derived Paraphrases</title>
<author confidence="0.467179">Chris of Linguistics</author>
<author confidence="0.467179">the CLIP</author>
<affiliation confidence="0.704111">at the Institute for Advanced Computer Studies University of Maryland College Park, MD 20742-7505,</affiliation>
<email confidence="0.999147">ymarton@umiacs.umd.edu</email>
<email confidence="0.999147">resnik@umiacs.umd.edu</email>
<affiliation confidence="0.920605">Science Department, Johns Hopkins</affiliation>
<address confidence="0.995811">3400 N. Charles Street (CSEB 226-B) Baltimore, MD</address>
<email confidence="0.998966">ccb@cs.jhu.edu</email>
<abstract confidence="0.999520363636364">Untranslated words still constitute a major problem for Statistical Machine Translation (SMT), and current SMT systems are limited by the quantity of parallel training texts. Augmenting the training data with paraphrases generated by pivoting through other languages alleviates this problem, especially for the so-called “low density” languages. But pivoting requires additional parallel texts. We address this problem by deriving paraphrases monolingually, using distributional semantic similarity measures, thus providing access to larger training resources, such as comparable and unrelated monolingual corpora. We present what is to our knowledge the first successful integration of a collocational approach to untranslated words with an end-to-end, state of the art SMT system demonstrating significant translation improvements in a low-resource setting.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<booktitle>In Proceedings of ACL-2001.</booktitle>
<contexts>
<context position="7703" citStr="Barzilay and McKeown (2001)" startWordPosition="1138" endWordPosition="1141">ump the human knowledge advantage. More recently, Callison-Burch (2008) has improved performance of this pivoting technique by imposing syntactic constraints on the paraphrases. The limitation of such an approach is the reliance on a good parser (in addition to reliance on bitexts), but a good parser is not available in all languages, especially not in resource-poor languages. Another approach using a pivoting technique augments the human reference translation with paraphrases, creating additional translation “references” (Madnani et al., 2007). Both approaches have shown gains in BLEU score. Barzilay and McKeown (2001) extract paraphrases from a monolingual parallel corpus, containing multiple translations of the same source. In addition to the parallel corpus usage limitations described above, this technique is further limited by the small size of such materials, which are even scarcer than the resources in the pivoting case. Dolan et al. (2004) explore generating paraphrases by edit-distance and headlines of timeand topic-clustered news articles; they do not address the OOV problem directly, as their focus is sentence-level paraphrases; although they use a standard SMT measure, alignment error rate (AER),</context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>Regina Barzilay and Kathleen McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceedings of ACL-2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A D Pietra</author>
<author>V J D Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>313</pages>
<contexts>
<context position="1559" citStr="Brown et al., 1993" startWordPosition="211" endWordPosition="214">semantic similarity measures, thus providing access to larger training resources, such as comparable and unrelated monolingual corpora. We present what is to our knowledge the first successful integration of a collocational approach to untranslated words with an end-to-end, state of the art SMT system demonstrating significant translation improvements in a low-resource setting. 1 Introduction Phrase-based systems, flat and hierarchical alike (Koehn et al., 2003; Koehn, 2004b; Koehn et al., 2007; Chiang, 2005; Chiang, 2007), have achieved a much better translation coverage than wordbased ones (Brown et al., 1993), but untranslated words remain a major problem in SMT. For example, according to Callison-Burch et al. (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. Coverage of higher order n-gram levels is even harder. This problem plays a major part in reducing machine translation quality, as reflected by both automatic measures such as BLEU (Papineni et al., </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P.F. Brown, S.A.D. Pietra, V.J.D. Pietra, and R.L. Mercer. 1993. The mathematics of statistical machine translation. Computational Linguistics, 19(2):263– 313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lou Burnard</author>
</authors>
<title>Reference Guide for the British National Corpus.</title>
<date>2000</date>
<institution>Oxford University Computing Services,</institution>
<location>Oxford, England,</location>
<note>world edition edition.</note>
<contexts>
<context position="21048" citStr="Burnard, 2000" startWordPosition="3331" endWordPosition="3332">.4 + 5.1 bnc+apw 187 S2E 10K 0.3 + 0.3 S2E 20K 0.6 + 0.6 S2E 80K 2.3 + 2.3 wmt09 84 wmt09+acquis 139 wmt09+acquis+afp 402 Table 1: Training set sizes (million tokens). For development, we used the Chinese-English NIST MT 2005 evaluation set, taking one of the English references as source, and the Chinese source as a single reference translation. We tested the system using the English-Chinese NIST MT evaluation 2008 test set with its four reference translations. We augmented the E2C baseline models with paraphrases generated as described above, training on the British National Corpus (BNC) v3 (Burnard, 2000) and the first 3 million lines of the English Gigaword v2 APW, totaling 187M terms after tokenization, and number and punctuation removal. We generated paraphrases for phrases up to six tokens in length, and used an arh(e, f) = 385 bitrary similarity threshold of minScore = 0.3. We experimented with three variants: adding a single additional feature for all paraphrases (1- 6grams); using only paraphrases of unigrams (1grams); and adding two features, one only sensitive to unigrams, and the other only to the rest (1 + 2-6grams). All features had the same design as described in Section 5, each h</context>
</contexts>
<marker>Burnard, 2000</marker>
<rawString>Lou Burnard. 2000. Reference Guide for the British National Corpus. Oxford University Computing Services, Oxford, England, world edition edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Miles Osborne</author>
</authors>
<title>Improved statistical machine translation using paraphrases.</title>
<date>2006</date>
<booktitle>In Proceedings NAACL2006.</booktitle>
<contexts>
<context position="1669" citStr="Callison-Burch et al. (2006)" startWordPosition="229" endWordPosition="232">and unrelated monolingual corpora. We present what is to our knowledge the first successful integration of a collocational approach to untranslated words with an end-to-end, state of the art SMT system demonstrating significant translation improvements in a low-resource setting. 1 Introduction Phrase-based systems, flat and hierarchical alike (Koehn et al., 2003; Koehn, 2004b; Koehn et al., 2007; Chiang, 2005; Chiang, 2007), have achieved a much better translation coverage than wordbased ones (Brown et al., 1993), but untranslated words remain a major problem in SMT. For example, according to Callison-Burch et al. (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. Coverage of higher order n-gram levels is even harder. This problem plays a major part in reducing machine translation quality, as reflected by both automatic measures such as BLEU (Papineni et al., 2002) and human judgment tests. Improving translation coverage accurately is therefore important for SMT syste</context>
<context position="3619" citStr="Callison-Burch et al., 2006" startWordPosition="525" endWordPosition="528">s used by Fung and Yee (1998) and Rapp (1999). However, the systems described there are not easily scalable, and require pre-computation of a very large collocation counts matrix. Related attempts propose generating bitexts from comparable and “quasicomparable” bilingual texts by iteratively bootstrapping documents, sentences, and words (Fung and Cheung, 2004), or by using a maximum entropy classifier (Munteanu and Marcu, 2005). Alignment accuracy remains a challenge for them. Recent work has proposed augmenting the training data with paraphrases generated by pivoting through other languages (Callison-Burch et al., 2006; Madnani et al., 2007). This indeed alleviates the vocabulary coverage problem, especially for the so-called “low density” languages. However, these approaches still require bitexts where 381 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 381–390, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP one side contains the original source language. The paradigm described in this paper involves constructing monolingual distributional profiles (DPs; a.k.a. word association profiles, or cooccurrence vectors) of out-of-vocabulary words and phrases in the s</context>
<context position="5899" citStr="Callison-Burch et al. (2006)" startWordPosition="863" endWordPosition="866">m. In the rest of this paper we discuss related work in Section 2, describe the distributional hypothesis and distributional profiles in Section 3, and present the monolingually-derived paraphrase generation system in Section 4. We report our experiments and results in Section 5, and conclude by discussing the implications and future research directions in Section 6. 2 Related Work This is not the first to attempt to ameliorate the out-of-vocabulary (OOV) words problem in statistical machine translation, and other natural language processing tasks. This work is most closely related to that of Callison-Burch et al. (2006), who also translate source-side paraphrases of the OOV phrases. There, paraphrases are generated from bitexts of various language pairs, by “pivoting”: translating the OOV phrases to an additional language (or languages) and back to the source language. The quality of these paraphrases is estimated by marginalizing translation probabilities to and from the additional language side(s) e, as follows: p(f2|f1) = &amp; p(e|f1)p(f2|e). A major disadvantage of their approach is that it relies on the availability of parallel corpora in other languages. While this works for English and many European lang</context>
<context position="8528" citStr="Callison-Burch et al. (2006)" startWordPosition="1266" endWordPosition="1269"> further limited by the small size of such materials, which are even scarcer than the resources in the pivoting case. Dolan et al. (2004) explore generating paraphrases by edit-distance and headlines of timeand topic-clustered news articles; they do not address the OOV problem directly, as their focus is sentence-level paraphrases; although they use a standard SMT measure, alignment error rate (AER), they only report results of the alignment quality, and not of an end-to-end SMT system. Much of the previous research largely focused on morphological analysis in order to reduce type sparseness; Callison-Burch et al. (2006) list some of the influential work in that direction. Work that relies on the distributional hypothesis using bilingual comparable corpora (without the need for bitexts), typically uses a seed lexicon for “bridging” source language phrases 382 with their target languages paraphrases (Fung and Yee, 1998; Rapp, 1999; Diab and Finch, 2000). This approach is sometimes viewed as, or combined with, an information retrieval (IR) approach, and normalizes strength-of-association measures (see Section 3) with IR-related measures such as TF/IDF (Fung and Yee, 1998). To date, reported implementations suff</context>
<context position="18382" citStr="Callison-Burch et al. (2006)" startWordPosition="2861" endWordPosition="2864">phrase translation probabilities were determined using maximum likelihood estimation over phrases induced from word-level alignments produced by performing Giza++ training (Och and Ney, 2000) on both source and target sides of the parallel training sets. When the baseline system encountered unknown words in the test set, its behavior was simply to reproduce the foreign word in the translated output. The paraphrase-augmented systems were identical to the corresponding baseline system, with the exception of additional (paraphrase-based) translation rules, and additional feature(s). Similarly to Callison-Burch et al. (2006), we added the following feature: I psim(DPf , DPf) If phrase table entry (e, f) is generated from (e, f&apos;) using monolinguallyderived paraphrases. 1 Otherwise, (4) Note that it is possible to construct a new translation rule from f to e via more than one pair of source-side phrase and its paraphrase; e.g., if f1 is a paraphrase of f, and so is f2, and both f1, f2 translate to the same e, then both lead to the construction of the new rule translating f to e, but with potentially different feature scores. In order to eliminate this duplicity and leverage over these alternate paths which can be u</context>
<context position="22992" citStr="Callison-Burch et al. (2006)" startWordPosition="3647" endWordPosition="3650">l, results were negative. Note that our E2C full size baseline is reasonably strong: Its character-based BLEU score is slightly higher than the JHU-UMD system that participated in the NIST 2008 MT evaluation (constrained training track), although we used a subset of that system’s training materials, and a smaller language model. Results there ranged from 15.69 to 30.38 BLEU (ignoring a seeming outlier of 3.93). 5.2 Spanish-to-English Translation In order to to permit a more direct comparison with the pivoting technique, we also experimented with Spanish to English (S2E) translation, following Callison-Burch et al. (2006). For baseline we used the Spanish and English sides of the Europarl multilingual parallel corpus (Koehn, 2005), with the standard training, development, and test sets. We created training subset models of 10,000, 20,000, and 80,000 aligned sentences, as described in Callison-Burch et al. (2006). For better comparison with their pivoting system, we used the same 5-gram language model, development and test sets: For development, we used the Europarl dev2006 Spanish and English sides, and for testing we used the Europarl 2006 test set. We trained the Spanish paraphrase generation system on the S</context>
<context position="26890" citStr="Callison-Burch et al. (2006)" startWordPosition="4295" endWordPosition="4298">r lowercased outputs to evaluate all S2E systems, and Koehn’s significance test as above. On the S2E 10,000-line subset, both the 1grams and 1-4grams models achieved significant gains of .4 BLEU points over the baseline. We concluded from a manual evaluation of the 10,000-line models that the two major weaknesses of the baseline system were (not surprisingly) number of untranslated (OOV) words / phrases, followed by number of superfluous words / phrases. On the larger subset models, no system significantly outperformed the baseline. Note that our S2E baselines’ scores are higher than those of Callison-Burch et al. (2006), since we evaluate lowercased outputs, instead of recased ones. 6 Discussion and Future Work We have shown that monolingually-derived paraphrases, based on distributional semantic similarity measures over a source-language corpus, can improve the performance of statistical machine translation (SMT) systems. Our proposed method has the advantage of not relying on bitexts in order to generate the paraphrases, and therefore gives access to large amounts of monolingual training data, for which creating bitexts of equivalent size is generally unfeasible. We haven’t trained our 1http://www.statmt.o</context>
<context position="29824" citStr="Callison-Burch et al. (2006)" startWordPosition="4758" endWordPosition="4761">ns: The smaller subset models, emulating a resource-poor language situation, show higher gains than larger models (which are supersets of the smaller subset models), when augmented with paraphrases derived from the same paraphrase training set. This was validated in two very different language pairs: English to Chinese, and Spanish to English. We believe that larger monolingual training sets for paraphrasing can help languages with richer resources, and we intend to explore this too. Although the gains in the Spanish-English subsets are somewhat smaller than the pivoting technique reported in Callison-Burch et al. (2006), e.g., .7 BLEU for the 10k subset, we take these results as a proof of concept that can yield better 387 bitext mono.corp. features minScore BLEU TER 10k (baseline) – – 23.78 62.382 10k wmt09 1-4grams .6 23.81 10k wmt09 1-2+3-4gr .6 23.92 62.202 10k wmt09+aquis 1-4grams .6 24.13*** 61.739 10k wmt09+aquis 1grams .6 24.11 61.979 20k (baseline) – – 24.68 62.333 20k wmt09+aquis 1-4grams .6 24.75 61.528 80k (baseline) – – 27.89 57.977 80k wmt09+aquis 1-4grams .6 27.82 57.906 10k wmt09+aquis 1grams .3 24.11 61.979 10k wmt09+aquis+afp 1grams .3 23.97 61.974 20k wmt09+aquis+afp 1grams .3 24.77 61.276</context>
<context position="33702" citStr="Callison-Burch et al. (2006)" startWordPosition="5407" endWordPosition="5410">tives we want to achieve, are on the way. Table 6: S2E translation examples on 10k-bitext systems. Some translation differences are in bold. 388 gains with larger monolingual training sets. Pivoting techniques (translating back and forth) rely on limited resources (bitexts), and are subject to shifts in meaning due to their inherent double translation step. In contrast, large monolingual resources are relatively easy to collect, and our system involves only a single translation/paraphrasing step per target phrase. Table 5 also shows an exemplar comparison with the pivoting paraphrases used in Callison-Burch et al. (2006). It seems that the pivoting paraphrases might suffer more from having frequent function words as top candidates, which might be a by-product of their alignment “promiscuity”. However, the top antonymous candidate problem seems to mainly plague the monolingual distributional paraphrases (but improves with larger corpora). See also Table 6. The paraphrase quality remains an issue with this method (as with all other paraphrasing methods). Some possible ways of improving it, besides using larger corpora, are: using syntactic information (Callison-Burch, 2008), using semantic knowledge such as the</context>
</contexts>
<marker>Callison-Burch, Koehn, Osborne, 2006</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006. Improved statistical machine translation using paraphrases. In Proceedings NAACL2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
</authors>
<title>Syntactic constraints on paraphrases extracted from parallel corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<location>Waikiki, Hawai’i.</location>
<contexts>
<context position="7147" citStr="Callison-Burch (2008)" startWordPosition="1054" endWordPosition="1055">y to help when translating from other source languages, for which bitexts are scarce or non-existent. Also, the pivoting approach is inherently noisy (in both the paraphrase candidates’ correct sense, and their translational likelihood), and it is likely to fare poorly with out-of-domain translation. One advantage of the bitext-dependent pivoting approach is the use of the additional human knowledge that is encapsulated in the parallel sentence alignment. However, we argue that the ability to use much larger resources for paraphrasing should trump the human knowledge advantage. More recently, Callison-Burch (2008) has improved performance of this pivoting technique by imposing syntactic constraints on the paraphrases. The limitation of such an approach is the reliance on a good parser (in addition to reliance on bitexts), but a good parser is not available in all languages, especially not in resource-poor languages. Another approach using a pivoting technique augments the human reference translation with paraphrases, creating additional translation “references” (Madnani et al., 2007). Both approaches have shown gains in BLEU score. Barzilay and McKeown (2001) extract paraphrases from a monolingual para</context>
<context position="34264" citStr="Callison-Burch, 2008" startWordPosition="5495" endWordPosition="5496">e pivoting paraphrases used in Callison-Burch et al. (2006). It seems that the pivoting paraphrases might suffer more from having frequent function words as top candidates, which might be a by-product of their alignment “promiscuity”. However, the top antonymous candidate problem seems to mainly plague the monolingual distributional paraphrases (but improves with larger corpora). See also Table 6. The paraphrase quality remains an issue with this method (as with all other paraphrasing methods). Some possible ways of improving it, besides using larger corpora, are: using syntactic information (Callison-Burch, 2008), using semantic knowledge such as thesaurus or WordNet to perform word sense disambiguation (WSD) (Resnik, 1999; Mohammad and Hirst, 2006), improving the similarity measure, and refining the similarity threshold. We would like to explore ways of incorporating syntactic knowledge that do not sacrifice coverage as much as in Callison-Burch (2008); incorporating semantic knowledge to disambiguate phrasal senses; using context to help sense disambiguation (Erk and Padó, 2008); and optimizing the similarity threshold for use in SMT, for example on a held-out dataset: too high a threshold reduces c</context>
</contexts>
<marker>Callison-Burch, 2008</marker>
<rawString>Chris Callison-Burch. 2008. Syntactic constraints on paraphrases extracted from parallel corpora. In Proceedings of EMNLP 2008, Waikiki, Hawai’i.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-05,</booktitle>
<pages>263--270</pages>
<contexts>
<context position="1453" citStr="Chiang, 2005" startWordPosition="196" endWordPosition="197">arallel texts. We address this problem by deriving paraphrases monolingually, using distributional semantic similarity measures, thus providing access to larger training resources, such as comparable and unrelated monolingual corpora. We present what is to our knowledge the first successful integration of a collocational approach to untranslated words with an end-to-end, state of the art SMT system demonstrating significant translation improvements in a low-resource setting. 1 Introduction Phrase-based systems, flat and hierarchical alike (Koehn et al., 2003; Koehn, 2004b; Koehn et al., 2007; Chiang, 2005; Chiang, 2007), have achieved a much better translation coverage than wordbased ones (Brown et al., 1993), but untranslated words remain a major problem in SMT. For example, according to Callison-Burch et al. (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. Coverage of higher order n-gram levels is even harder. This problem plays a major part in red</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In Proceedings of ACL-05, pages 263–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="1468" citStr="Chiang, 2007" startWordPosition="198" endWordPosition="199"> We address this problem by deriving paraphrases monolingually, using distributional semantic similarity measures, thus providing access to larger training resources, such as comparable and unrelated monolingual corpora. We present what is to our knowledge the first successful integration of a collocational approach to untranslated words with an end-to-end, state of the art SMT system demonstrating significant translation improvements in a low-resource setting. 1 Introduction Phrase-based systems, flat and hierarchical alike (Koehn et al., 2003; Koehn, 2004b; Koehn et al., 2007; Chiang, 2005; Chiang, 2007), have achieved a much better translation coverage than wordbased ones (Brown et al., 1993), but untranslated words remain a major problem in SMT. For example, according to Callison-Burch et al. (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. Coverage of higher order n-gram levels is even harder. This problem plays a major part in reducing machine t</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Steve Finch</author>
</authors>
<title>A statistical wordlevel translation model for comparable corpora.</title>
<date>2000</date>
<booktitle>In Proceedings of the Conference on Content-Based Multimedia Information Access (RIAO).</booktitle>
<contexts>
<context position="8866" citStr="Diab and Finch, 2000" startWordPosition="1319" endWordPosition="1322">ey use a standard SMT measure, alignment error rate (AER), they only report results of the alignment quality, and not of an end-to-end SMT system. Much of the previous research largely focused on morphological analysis in order to reduce type sparseness; Callison-Burch et al. (2006) list some of the influential work in that direction. Work that relies on the distributional hypothesis using bilingual comparable corpora (without the need for bitexts), typically uses a seed lexicon for “bridging” source language phrases 382 with their target languages paraphrases (Fung and Yee, 1998; Rapp, 1999; Diab and Finch, 2000). This approach is sometimes viewed as, or combined with, an information retrieval (IR) approach, and normalizes strength-of-association measures (see Section 3) with IR-related measures such as TF/IDF (Fung and Yee, 1998). To date, reported implementations suffer from scalability issues, as they pre-compute and hold in memory a huge collocation matrix; we know of no report of using this approach in an end-to-end SMT system. Another approach aiming to reduce OOV rate concentrates on increasing parallel training set size without using more dedicated human translation (Resnik and Smith, 2003; Oa</context>
</contexts>
<marker>Diab, Finch, 2000</marker>
<rawString>Mona Diab and Steve Finch. 2000. A statistical wordlevel translation model for comparable corpora. In Proceedings of the Conference on Content-Based Multimedia Information Access (RIAO).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dolan</author>
<author>C Quirk</author>
<author>C Brockett</author>
</authors>
<title>Unsupervised construction of large paraphrase corpora: exploiting massively parallel news sources.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics of the Association for Computational Linguistics,</booktitle>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="8037" citStr="Dolan et al. (2004)" startWordPosition="1191" endWordPosition="1194">ially not in resource-poor languages. Another approach using a pivoting technique augments the human reference translation with paraphrases, creating additional translation “references” (Madnani et al., 2007). Both approaches have shown gains in BLEU score. Barzilay and McKeown (2001) extract paraphrases from a monolingual parallel corpus, containing multiple translations of the same source. In addition to the parallel corpus usage limitations described above, this technique is further limited by the small size of such materials, which are even scarcer than the resources in the pivoting case. Dolan et al. (2004) explore generating paraphrases by edit-distance and headlines of timeand topic-clustered news articles; they do not address the OOV problem directly, as their focus is sentence-level paraphrases; although they use a standard SMT measure, alignment error rate (AER), they only report results of the alignment quality, and not of an end-to-end SMT system. Much of the previous research largely focused on morphological analysis in order to reduce type sparseness; Callison-Burch et al. (2006) list some of the influential work in that direction. Work that relies on the distributional hypothesis using</context>
</contexts>
<marker>Dolan, Quirk, Brockett, 2004</marker>
<rawString>B. Dolan, C. Quirk, and C. Brockett. 2004. Unsupervised construction of large paraphrase corpora: exploiting massively parallel news sources. In Proceedings of the 20th International Conference on Computational Linguistics of the Association for Computational Linguistics, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="12331" citStr="Dunning, 1993" startWordPosition="1867" endWordPosition="1868">at precedes u) (Rapp, 1999); other researchers use nonpositional (which we dub here flat) collocations, meaning, they count all token occurrences within the sliding window, regardless of their positions in it relative to u (McDonald, 2000; Mohammad and Hirst, 2006). We use here flat collocations in a 6-token sliding window. Beside simple cooccurrence counts within sliding windows, other SoA measures include functions based on TF/IDF (Fung and Yee, 1998), mutual information (PMI) (Lin, 1998), conditional probabilities (Schuetze and Pedersen, 1997), chi-square test, and the loglikelihood ratio (Dunning, 1993). Profile similarity measures. A profile similarity function psim(DPu, DP„) is typically defined as a two-place function, taking vectors as arguments, each vector representing a distributional profile of some word u and v, respectively, and whose cells contain the SoA of u (or v) with each word (“collocate”) in the known vocabulary. Similarity can be (and have been) estimated in several ways, e.g., the cosine coefficient, the Jaccard coefficient, the Dice coefficient, and the City-Block measure. The formula for the cosine function for similarity measure is given in Eq. (3): 383 psim(DPu, DP„) </context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>T. Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Padó</author>
</authors>
<title>A structured vector space model for word meaning in context.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP2086),</booktitle>
<pages>897--906</pages>
<location>Honolulu, HI.</location>
<contexts>
<context position="34741" citStr="Erk and Padó, 2008" startWordPosition="5564" endWordPosition="5567">raphrasing methods). Some possible ways of improving it, besides using larger corpora, are: using syntactic information (Callison-Burch, 2008), using semantic knowledge such as thesaurus or WordNet to perform word sense disambiguation (WSD) (Resnik, 1999; Mohammad and Hirst, 2006), improving the similarity measure, and refining the similarity threshold. We would like to explore ways of incorporating syntactic knowledge that do not sacrifice coverage as much as in Callison-Burch (2008); incorporating semantic knowledge to disambiguate phrasal senses; using context to help sense disambiguation (Erk and Padó, 2008); and optimizing the similarity threshold for use in SMT, for example on a held-out dataset: too high a threshold reduces coverage, while too low a threshold results in bad paraphrases and translation. The method presented here is quite general, and therefore different similarity measures, including other corpus-based ones, can be plugged in to generate paraphrases. We are looking into using DPs with word-sense disambiguation: Since it has been shown that similarity is often judged by the semantic distance of the closest senses of the two target words (Mohammad and Hirst, 2006), and that parap</context>
</contexts>
<marker>Erk, Padó, 2008</marker>
<rawString>Katrin Erk and Sebastian Padó. 2008. A structured vector space model for word meaning in context. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP2086), pages 897–906, Honolulu, HI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John R Firth</author>
</authors>
<title>A synopsis of linguistic theory 1930 ˝U55. Studies in Linguistic Analysis, (special volume of the Philological Society):1–32. Distributional Hypothesis.</title>
<date>1957</date>
<contexts>
<context position="9684" citStr="Firth, 1957" startWordPosition="1440" endWordPosition="1441">g and Yee, 1998). To date, reported implementations suffer from scalability issues, as they pre-compute and hold in memory a huge collocation matrix; we know of no report of using this approach in an end-to-end SMT system. Another approach aiming to reduce OOV rate concentrates on increasing parallel training set size without using more dedicated human translation (Resnik and Smith, 2003; Oard et al., 2003). 3 Collocational Profiles The distributional hypothesis and distributional profiles. Natural language processing (NLP) applications that assume the distributional hypothesis (Harris, 1940; Firth, 1957) typically keep track of word co-occurrences in distributional profiles (a.k.a. collocation vectors, or context vectors). Each distributional profile DPu (for some word u) keeps counts of co-occurrence of u with all words within a usually fixed distance from each of its occurrences (a sliding window) in some training corpus. More advanced profiles keep “strength of association” (SoA) information between u and each of the co-occurring words, which is calculated from the counts of u, the counts of the other word, their co-occurrence count, and the count of all words in the corpus (corpus size). </context>
</contexts>
<marker>Firth, 1957</marker>
<rawString>John R. Firth. 1957. A synopsis of linguistic theory 1930 ˝U55. Studies in Linguistic Analysis, (special volume of the Philological Society):1–32. Distributional Hypothesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Percy Cheung</author>
</authors>
<title>Multilevel bootstrapping for extracting parallel sentences from a quasi-comparable corpus.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics,</booktitle>
<pages>1051</pages>
<institution>Geneva, Switzerland. Association for Computational Linguistics.</institution>
<contexts>
<context position="3354" citStr="Fung and Cheung, 2004" startWordPosition="486" endWordPosition="489">anslations from them, and in a sufficiently fast, memory-efficient, and scalable manner. One approach that can, in principle, better exploit both alignments from bitexts and make use of non-parallel corpora is the distributional collocational approach, e.g., as used by Fung and Yee (1998) and Rapp (1999). However, the systems described there are not easily scalable, and require pre-computation of a very large collocation counts matrix. Related attempts propose generating bitexts from comparable and “quasicomparable” bilingual texts by iteratively bootstrapping documents, sentences, and words (Fung and Cheung, 2004), or by using a maximum entropy classifier (Munteanu and Marcu, 2005). Alignment accuracy remains a challenge for them. Recent work has proposed augmenting the training data with paraphrases generated by pivoting through other languages (Callison-Burch et al., 2006; Madnani et al., 2007). This indeed alleviates the vocabulary coverage problem, especially for the so-called “low density” languages. However, these approaches still require bitexts where 381 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 381–390, Singapore, 6-7 August 2009. c�2009 ACL </context>
</contexts>
<marker>Fung, Cheung, 2004</marker>
<rawString>Pascale Fung and Percy Cheung. 2004. Multilevel bootstrapping for extracting parallel sentences from a quasi-comparable corpus. In Proceedings of the 20th international conference on Computational Linguistics, page 1051, Geneva, Switzerland. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Lo Yuen Yee</author>
</authors>
<title>An ir approach for translating new words from nonparallel, comparable texts.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL98,</booktitle>
<pages>414--420</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="3021" citStr="Fung and Yee (1998)" startWordPosition="439" endWordPosition="442">ems cannot learn from non-aligned corpora, while sentence-aligned parallel corpora (bitexts) are a limited resource (See Section 2 for discussion of automaticallycompiled bitexts). Another direction might be to make use of non-parallel corpora for training. However, this requires developing techniques to extract alignments or translations from them, and in a sufficiently fast, memory-efficient, and scalable manner. One approach that can, in principle, better exploit both alignments from bitexts and make use of non-parallel corpora is the distributional collocational approach, e.g., as used by Fung and Yee (1998) and Rapp (1999). However, the systems described there are not easily scalable, and require pre-computation of a very large collocation counts matrix. Related attempts propose generating bitexts from comparable and “quasicomparable” bilingual texts by iteratively bootstrapping documents, sentences, and words (Fung and Cheung, 2004), or by using a maximum entropy classifier (Munteanu and Marcu, 2005). Alignment accuracy remains a challenge for them. Recent work has proposed augmenting the training data with paraphrases generated by pivoting through other languages (Callison-Burch et al., 2006; </context>
<context position="8831" citStr="Fung and Yee, 1998" startWordPosition="1313" endWordPosition="1316">e-level paraphrases; although they use a standard SMT measure, alignment error rate (AER), they only report results of the alignment quality, and not of an end-to-end SMT system. Much of the previous research largely focused on morphological analysis in order to reduce type sparseness; Callison-Burch et al. (2006) list some of the influential work in that direction. Work that relies on the distributional hypothesis using bilingual comparable corpora (without the need for bitexts), typically uses a seed lexicon for “bridging” source language phrases 382 with their target languages paraphrases (Fung and Yee, 1998; Rapp, 1999; Diab and Finch, 2000). This approach is sometimes viewed as, or combined with, an information retrieval (IR) approach, and normalizes strength-of-association measures (see Section 3) with IR-related measures such as TF/IDF (Fung and Yee, 1998). To date, reported implementations suffer from scalability issues, as they pre-compute and hold in memory a huge collocation matrix; we know of no report of using this approach in an end-to-end SMT system. Another approach aiming to reduce OOV rate concentrates on increasing parallel training set size without using more dedicated human tran</context>
<context position="12174" citStr="Fung and Yee, 1998" startWordPosition="1845" endWordPosition="1848">es are calculated per relative position (e.g., for some word/token u, position 1 is the token immediately after u; position -2 is the token preceding the token that precedes u) (Rapp, 1999); other researchers use nonpositional (which we dub here flat) collocations, meaning, they count all token occurrences within the sliding window, regardless of their positions in it relative to u (McDonald, 2000; Mohammad and Hirst, 2006). We use here flat collocations in a 6-token sliding window. Beside simple cooccurrence counts within sliding windows, other SoA measures include functions based on TF/IDF (Fung and Yee, 1998), mutual information (PMI) (Lin, 1998), conditional probabilities (Schuetze and Pedersen, 1997), chi-square test, and the loglikelihood ratio (Dunning, 1993). Profile similarity measures. A profile similarity function psim(DPu, DP„) is typically defined as a two-place function, taking vectors as arguments, each vector representing a distributional profile of some word u and v, respectively, and whose cells contain the SoA of u (or v) with each word (“collocate”) in the known vocabulary. Similarity can be (and have been) estimated in several ways, e.g., the cosine coefficient, the Jaccard coeff</context>
</contexts>
<marker>Fung, Yee, 1998</marker>
<rawString>Pascale Fung and Lo Yuen Yee. 1998. An ir approach for translating new words from nonparallel, comparable texts. In Proceedings of COLING-ACL98, pages 414–420, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig S Harris</author>
</authors>
<title>Review of louis h. gray, foundations of language (new york:</title>
<date>1940</date>
<journal>Language,</journal>
<volume>16</volume>
<issue>3</issue>
<pages>231</pages>
<publisher>Macmillan,</publisher>
<contexts>
<context position="9670" citStr="Harris, 1940" startWordPosition="1438" endWordPosition="1439">as TF/IDF (Fung and Yee, 1998). To date, reported implementations suffer from scalability issues, as they pre-compute and hold in memory a huge collocation matrix; we know of no report of using this approach in an end-to-end SMT system. Another approach aiming to reduce OOV rate concentrates on increasing parallel training set size without using more dedicated human translation (Resnik and Smith, 2003; Oard et al., 2003). 3 Collocational Profiles The distributional hypothesis and distributional profiles. Natural language processing (NLP) applications that assume the distributional hypothesis (Harris, 1940; Firth, 1957) typically keep track of word co-occurrences in distributional profiles (a.k.a. collocation vectors, or context vectors). Each distributional profile DPu (for some word u) keeps counts of co-occurrence of u with all words within a usually fixed distance from each of its occurrences (a sliding window) in some training corpus. More advanced profiles keep “strength of association” (SoA) information between u and each of the co-occurring words, which is calculated from the counts of u, the counts of the other word, their co-occurrence count, and the count of all words in the corpus (</context>
</contexts>
<marker>Harris, 1940</marker>
<rawString>Zellig S. Harris. 1940. Review of louis h. gray, foundations of language (new york: Macmillan, 1939). Language, 16(3):216 ˝U231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>127--133</pages>
<contexts>
<context position="1405" citStr="Koehn et al., 2003" startWordPosition="186" endWordPosition="189">density” languages. But pivoting requires additional parallel texts. We address this problem by deriving paraphrases monolingually, using distributional semantic similarity measures, thus providing access to larger training resources, such as comparable and unrelated monolingual corpora. We present what is to our knowledge the first successful integration of a collocational approach to untranslated words with an end-to-end, state of the art SMT system demonstrating significant translation improvements in a low-resource setting. 1 Introduction Phrase-based systems, flat and hierarchical alike (Koehn et al., 2003; Koehn, 2004b; Koehn et al., 2007; Chiang, 2005; Chiang, 2007), have achieved a much better translation coverage than wordbased ones (Brown et al., 1993), but untranslated words remain a major problem in SMT. For example, according to Callison-Burch et al. (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. Coverage of higher order n-gram levels is eve</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of HLT-NAACL, pages 127–133.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<location>Christine Moran Richard Zens, Chris Dyer, Ondrej Bojar,</location>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, </marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran Richard Zens, Chris Dyer, Ondrej Bojar,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session,</booktitle>
<location>Prague, Czech Republic.</location>
<marker>Constantin, Herbst, 2007</marker>
<rawString>Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Proc. EMNLP.</booktitle>
<contexts>
<context position="1418" citStr="Koehn, 2004" startWordPosition="190" endWordPosition="191">But pivoting requires additional parallel texts. We address this problem by deriving paraphrases monolingually, using distributional semantic similarity measures, thus providing access to larger training resources, such as comparable and unrelated monolingual corpora. We present what is to our knowledge the first successful integration of a collocational approach to untranslated words with an end-to-end, state of the art SMT system demonstrating significant translation improvements in a low-resource setting. 1 Introduction Phrase-based systems, flat and hierarchical alike (Koehn et al., 2003; Koehn, 2004b; Koehn et al., 2007; Chiang, 2005; Chiang, 2007), have achieved a much better translation coverage than wordbased ones (Brown et al., 1993), but untranslated words remain a major problem in SMT. For example, according to Callison-Burch et al. (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. Coverage of higher order n-gram levels is even harder. Thi</context>
<context position="22173" citStr="Koehn, 2004" startWordPosition="3522" endWordPosition="3523">rest (1 + 2-6grams). All features had the same design as described in Section 5, each had an associated weight (as all other features), and all feature weights in each system, including the baseline, were tuned using a separate minimum error rate training for each system. Results are shown in Table 2. For the E2C systems, for which we had four reference translations for the test set, we used shortest reference length, and used the NIST-provided script to split the output words to Chinese characters before evaluation. Statistical significance for the BLEU results were calculated using Koehn’s (Koehn, 2004) pair-wise bootstrapping test with 95% confidence interval. On the E2C 29,000-line subset, the augmented system had a significant 1.7 BLEU points gain over its baseline. On the full size model, results were negative. Note that our E2C full size baseline is reasonably strong: Its character-based BLEU score is slightly higher than the JHU-UMD system that participated in the NIST 2008 MT evaluation (constrained training track), although we used a subset of that system’s training materials, and a smaller language model. Results there ranged from 15.69 to 30.38 BLEU (ignoring a seeming outlier of 3</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical significance tests for machine translation evaluation. In Proc. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Pharaoh: A beam search decoder for phrase-based statistical machine translation models.</title>
<date>2004</date>
<booktitle>In Proceedings of AMTA.</booktitle>
<contexts>
<context position="1418" citStr="Koehn, 2004" startWordPosition="190" endWordPosition="191">But pivoting requires additional parallel texts. We address this problem by deriving paraphrases monolingually, using distributional semantic similarity measures, thus providing access to larger training resources, such as comparable and unrelated monolingual corpora. We present what is to our knowledge the first successful integration of a collocational approach to untranslated words with an end-to-end, state of the art SMT system demonstrating significant translation improvements in a low-resource setting. 1 Introduction Phrase-based systems, flat and hierarchical alike (Koehn et al., 2003; Koehn, 2004b; Koehn et al., 2007; Chiang, 2005; Chiang, 2007), have achieved a much better translation coverage than wordbased ones (Brown et al., 1993), but untranslated words remain a major problem in SMT. For example, according to Callison-Burch et al. (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. Coverage of higher order n-gram levels is even harder. Thi</context>
<context position="22173" citStr="Koehn, 2004" startWordPosition="3522" endWordPosition="3523">rest (1 + 2-6grams). All features had the same design as described in Section 5, each had an associated weight (as all other features), and all feature weights in each system, including the baseline, were tuned using a separate minimum error rate training for each system. Results are shown in Table 2. For the E2C systems, for which we had four reference translations for the test set, we used shortest reference length, and used the NIST-provided script to split the output words to Chinese characters before evaluation. Statistical significance for the BLEU results were calculated using Koehn’s (Koehn, 2004) pair-wise bootstrapping test with 95% confidence interval. On the E2C 29,000-line subset, the augmented system had a significant 1.7 BLEU points gain over its baseline. On the full size model, results were negative. Note that our E2C full size baseline is reasonably strong: Its character-based BLEU score is slightly higher than the JHU-UMD system that participated in the NIST 2008 MT evaluation (constrained training track), although we used a subset of that system’s training materials, and a smaller language model. Results there ranged from 15.69 to 30.38 BLEU (ignoring a seeming outlier of 3</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004b. Pharaoh: A beam search decoder for phrase-based statistical machine translation models. In Proceedings of AMTA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of MT-Summit.</booktitle>
<contexts>
<context position="23103" citStr="Koehn, 2005" startWordPosition="3667" endWordPosition="3668"> higher than the JHU-UMD system that participated in the NIST 2008 MT evaluation (constrained training track), although we used a subset of that system’s training materials, and a smaller language model. Results there ranged from 15.69 to 30.38 BLEU (ignoring a seeming outlier of 3.93). 5.2 Spanish-to-English Translation In order to to permit a more direct comparison with the pivoting technique, we also experimented with Spanish to English (S2E) translation, following Callison-Burch et al. (2006). For baseline we used the Spanish and English sides of the Europarl multilingual parallel corpus (Koehn, 2005), with the standard training, development, and test sets. We created training subset models of 10,000, 20,000, and 80,000 aligned sentences, as described in Callison-Burch et al. (2006). For better comparison with their pivoting system, we used the same 5-gram language model, development and test sets: For development, we used the Europarl dev2006 Spanish and English sides, and for testing we used the Europarl 2006 test set. We trained the Spanish paraphrase generation system on the Spanish corpora available from dataset E2C model BLEU TER 29k baseline 15.21 90.354 29k 1grams 16.87*** 90.370 2</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. A parallel corpus for statistical machine translation. In Proceedings of MT-Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>An information-theoretic definition of similarity.</title>
<date>1998</date>
<booktitle>In Proceedings of the 15th International Conference on Machine Learning,</booktitle>
<pages>296--304</pages>
<location>San Francisco, CA.</location>
<contexts>
<context position="12212" citStr="Lin, 1998" startWordPosition="1852" endWordPosition="1853">for some word/token u, position 1 is the token immediately after u; position -2 is the token preceding the token that precedes u) (Rapp, 1999); other researchers use nonpositional (which we dub here flat) collocations, meaning, they count all token occurrences within the sliding window, regardless of their positions in it relative to u (McDonald, 2000; Mohammad and Hirst, 2006). We use here flat collocations in a 6-token sliding window. Beside simple cooccurrence counts within sliding windows, other SoA measures include functions based on TF/IDF (Fung and Yee, 1998), mutual information (PMI) (Lin, 1998), conditional probabilities (Schuetze and Pedersen, 1997), chi-square test, and the loglikelihood ratio (Dunning, 1993). Profile similarity measures. A profile similarity function psim(DPu, DP„) is typically defined as a two-place function, taking vectors as arguments, each vector representing a distributional profile of some word u and v, respectively, and whose cells contain the SoA of u (or v) with each word (“collocate”) in the known vocabulary. Similarity can be (and have been) estimated in several ways, e.g., the cosine coefficient, the Jaccard coefficient, the Dice coefficient, and the </context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. An information-theoretic definition of similarity. In Proceedings of the 15th International Conference on Machine Learning, pages 296–304, San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Madnani</author>
<author>Necip Fazil Ayan</author>
<author>Philip Resnik</author>
<author>Bonnie Dorr</author>
</authors>
<title>Using paraphrases for parameter tuning in statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL Workshop on Statistical Machine Translation.</booktitle>
<contexts>
<context position="3642" citStr="Madnani et al., 2007" startWordPosition="529" endWordPosition="532"> and Rapp (1999). However, the systems described there are not easily scalable, and require pre-computation of a very large collocation counts matrix. Related attempts propose generating bitexts from comparable and “quasicomparable” bilingual texts by iteratively bootstrapping documents, sentences, and words (Fung and Cheung, 2004), or by using a maximum entropy classifier (Munteanu and Marcu, 2005). Alignment accuracy remains a challenge for them. Recent work has proposed augmenting the training data with paraphrases generated by pivoting through other languages (Callison-Burch et al., 2006; Madnani et al., 2007). This indeed alleviates the vocabulary coverage problem, especially for the so-called “low density” languages. However, these approaches still require bitexts where 381 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 381–390, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP one side contains the original source language. The paradigm described in this paper involves constructing monolingual distributional profiles (DPs; a.k.a. word association profiles, or cooccurrence vectors) of out-of-vocabulary words and phrases in the source language; then, g</context>
<context position="7626" citStr="Madnani et al., 2007" startWordPosition="1125" endWordPosition="1128">hat the ability to use much larger resources for paraphrasing should trump the human knowledge advantage. More recently, Callison-Burch (2008) has improved performance of this pivoting technique by imposing syntactic constraints on the paraphrases. The limitation of such an approach is the reliance on a good parser (in addition to reliance on bitexts), but a good parser is not available in all languages, especially not in resource-poor languages. Another approach using a pivoting technique augments the human reference translation with paraphrases, creating additional translation “references” (Madnani et al., 2007). Both approaches have shown gains in BLEU score. Barzilay and McKeown (2001) extract paraphrases from a monolingual parallel corpus, containing multiple translations of the same source. In addition to the parallel corpus usage limitations described above, this technique is further limited by the small size of such materials, which are even scarcer than the resources in the pivoting case. Dolan et al. (2004) explore generating paraphrases by edit-distance and headlines of timeand topic-clustered news articles; they do not address the OOV problem directly, as their focus is sentence-level parap</context>
</contexts>
<marker>Madnani, Ayan, Resnik, Dorr, 2007</marker>
<rawString>Nitin Madnani, Necip Fazil Ayan, Philip Resnik, and Bonnie Dorr. 2007. Using paraphrases for parameter tuning in statistical machine translation. In Proceedings of the ACL Workshop on Statistical Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Marton</author>
<author>Saif Mohammad</author>
<author>Philip Resnik</author>
</authors>
<title>Estimating semantic distance using soft semantic constraints in knowledge-source / corpus hybrid models.</title>
<date>2009</date>
<booktitle>In Procedings of EMNLP,</booktitle>
<contexts>
<context position="35423" citStr="Marton et al., 2009" startWordPosition="5676" endWordPosition="5679">example on a held-out dataset: too high a threshold reduces coverage, while too low a threshold results in bad paraphrases and translation. The method presented here is quite general, and therefore different similarity measures, including other corpus-based ones, can be plugged in to generate paraphrases. We are looking into using DPs with word-sense disambiguation: Since it has been shown that similarity is often judged by the semantic distance of the closest senses of the two target words (Mohammad and Hirst, 2006), and that paraphrases generated this way are likely to be of higher quality (Marton et al., 2009), hence it is also likely that the overall performance of an SMT system using them will also improve further. One potential advantage of using bitexts for paraphrase generation is the usage of implicit human knowledge, i.e., sentence alignments. The concern that not using this knowledge would turn out detrimental to the performance of SMT systems augmented by paraphrases as described here was largely put to rest, as our method improved the tested subset SMT systems’ quality. Acknowledgments Many thanks to Chris Dyer for his help with the E2C set, and to Adam Lopez for his implementation of pat</context>
</contexts>
<marker>Marton, Mohammad, Resnik, 2009</marker>
<rawString>Yuval Marton, Saif Mohammad, and Philip Resnik. 2009. Estimating semantic distance using soft semantic constraints in knowledge-source / corpus hybrid models. In Procedings of EMNLP, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S McDonald</author>
</authors>
<title>Environmental determinants of lexical processing effort.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="11955" citStr="McDonald, 2000" startWordPosition="1813" endWordPosition="1814">arity) entails the left-hand-side (semantic similarity). The sliding window and word association (SoA) measures. Some researchers count positional collocations in a sliding window, i.e., the cocounts and SoA measures are calculated per relative position (e.g., for some word/token u, position 1 is the token immediately after u; position -2 is the token preceding the token that precedes u) (Rapp, 1999); other researchers use nonpositional (which we dub here flat) collocations, meaning, they count all token occurrences within the sliding window, regardless of their positions in it relative to u (McDonald, 2000; Mohammad and Hirst, 2006). We use here flat collocations in a 6-token sliding window. Beside simple cooccurrence counts within sliding windows, other SoA measures include functions based on TF/IDF (Fung and Yee, 1998), mutual information (PMI) (Lin, 1998), conditional probabilities (Schuetze and Pedersen, 1997), chi-square test, and the loglikelihood ratio (Dunning, 1993). Profile similarity measures. A profile similarity function psim(DPu, DP„) is typically defined as a two-place function, taking vectors as arguments, each vector representing a distributional profile of some word u and v, r</context>
<context position="13468" citStr="McDonald, 2000" startWordPosition="2046" endWordPosition="2047">osine function for similarity measure is given in Eq. (3): 383 psim(DPu, DP„) = cos(DPu, DP„) E 5oA(u, wz)5oA(v, wz) wi∈V = �5oA(u, wz)2 5oA(v, wz)2 wi∈V wi∈V (3) In principle, any SoA can be used with any profile similarity measure. However, in practice, only some SoA/similarity measure combinations do well, and finding the best combination is still more art than science. Some successful combinations are cosCP (Schuetze and Pedersen, 1997), LinPmI (Lin, 1998), CityLL (Rapp, 1999), and Jensen–Shannon divergence of conditional probabilities (J5DCP). We use here cosine of loglikelihood vectors (McDonald, 2000). Phrasal distributional profiles. Word DPs can be generalized to phrasal DPs, simply by counting words that co-occur within a sliding window around the target phrase’s occurrences (i.e., counting occurrences of words up to 6 words before or after the target phrase). For example, when building a DP for the target phrase counting words in the previous sentence, then simply is in relative position -2, and sliding is in relative position 5. Searching for similar phrasal DPs poses an additional challenge over the word DP case (see Section 4), but there is no additional difficulty in building the p</context>
</contexts>
<marker>McDonald, 2000</marker>
<rawString>S. McDonald. 2000. Environmental determinants of lexical processing effort. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Graeme Hirst</author>
</authors>
<title>Distributional measures of concept-distance: A task-oriented evaluation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2006),</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="11982" citStr="Mohammad and Hirst, 2006" startWordPosition="1815" endWordPosition="1818">he left-hand-side (semantic similarity). The sliding window and word association (SoA) measures. Some researchers count positional collocations in a sliding window, i.e., the cocounts and SoA measures are calculated per relative position (e.g., for some word/token u, position 1 is the token immediately after u; position -2 is the token preceding the token that precedes u) (Rapp, 1999); other researchers use nonpositional (which we dub here flat) collocations, meaning, they count all token occurrences within the sliding window, regardless of their positions in it relative to u (McDonald, 2000; Mohammad and Hirst, 2006). We use here flat collocations in a 6-token sliding window. Beside simple cooccurrence counts within sliding windows, other SoA measures include functions based on TF/IDF (Fung and Yee, 1998), mutual information (PMI) (Lin, 1998), conditional probabilities (Schuetze and Pedersen, 1997), chi-square test, and the loglikelihood ratio (Dunning, 1993). Profile similarity measures. A profile similarity function psim(DPu, DP„) is typically defined as a two-place function, taking vectors as arguments, each vector representing a distributional profile of some word u and v, respectively, and whose cell</context>
<context position="34403" citStr="Mohammad and Hirst, 2006" startWordPosition="5514" endWordPosition="5517">ent function words as top candidates, which might be a by-product of their alignment “promiscuity”. However, the top antonymous candidate problem seems to mainly plague the monolingual distributional paraphrases (but improves with larger corpora). See also Table 6. The paraphrase quality remains an issue with this method (as with all other paraphrasing methods). Some possible ways of improving it, besides using larger corpora, are: using syntactic information (Callison-Burch, 2008), using semantic knowledge such as thesaurus or WordNet to perform word sense disambiguation (WSD) (Resnik, 1999; Mohammad and Hirst, 2006), improving the similarity measure, and refining the similarity threshold. We would like to explore ways of incorporating syntactic knowledge that do not sacrifice coverage as much as in Callison-Burch (2008); incorporating semantic knowledge to disambiguate phrasal senses; using context to help sense disambiguation (Erk and Padó, 2008); and optimizing the similarity threshold for use in SMT, for example on a held-out dataset: too high a threshold reduces coverage, while too low a threshold results in bad paraphrases and translation. The method presented here is quite general, and therefore di</context>
</contexts>
<marker>Mohammad, Hirst, 2006</marker>
<rawString>Saif Mohammad and Graeme Hirst. 2006. Distributional measures of concept-distance: A task-oriented evaluation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2006), Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragos Stefan Munteanu</author>
<author>Daniel Marcu</author>
</authors>
<title>Improving machine translation performance by exploiting non-parallel corpora.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>4</issue>
<contexts>
<context position="3423" citStr="Munteanu and Marcu, 2005" startWordPosition="497" endWordPosition="500">, and scalable manner. One approach that can, in principle, better exploit both alignments from bitexts and make use of non-parallel corpora is the distributional collocational approach, e.g., as used by Fung and Yee (1998) and Rapp (1999). However, the systems described there are not easily scalable, and require pre-computation of a very large collocation counts matrix. Related attempts propose generating bitexts from comparable and “quasicomparable” bilingual texts by iteratively bootstrapping documents, sentences, and words (Fung and Cheung, 2004), or by using a maximum entropy classifier (Munteanu and Marcu, 2005). Alignment accuracy remains a challenge for them. Recent work has proposed augmenting the training data with paraphrases generated by pivoting through other languages (Callison-Burch et al., 2006; Madnani et al., 2007). This indeed alleviates the vocabulary coverage problem, especially for the so-called “low density” languages. However, these approaches still require bitexts where 381 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 381–390, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP one side contains the original source language. The paradig</context>
</contexts>
<marker>Munteanu, Marcu, 2005</marker>
<rawString>Dragos Stefan Munteanu and Daniel Marcu. 2005. Improving machine translation performance by exploiting non-parallel corpora. Computational Linguistics, 31(4):477–504.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doug Oard</author>
<author>David Doermann</author>
<author>Bonnie Dorr</author>
<author>Daqing He</author>
<author>Phillip Resnik</author>
<author>William Byrne</author>
<author>Sanjeeve Khudanpur</author>
<author>David Yarowsky</author>
<author>Anton Leuski</author>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Desperately seeking cebuano.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="9482" citStr="Oard et al., 2003" startWordPosition="1414" endWordPosition="1417">0). This approach is sometimes viewed as, or combined with, an information retrieval (IR) approach, and normalizes strength-of-association measures (see Section 3) with IR-related measures such as TF/IDF (Fung and Yee, 1998). To date, reported implementations suffer from scalability issues, as they pre-compute and hold in memory a huge collocation matrix; we know of no report of using this approach in an end-to-end SMT system. Another approach aiming to reduce OOV rate concentrates on increasing parallel training set size without using more dedicated human translation (Resnik and Smith, 2003; Oard et al., 2003). 3 Collocational Profiles The distributional hypothesis and distributional profiles. Natural language processing (NLP) applications that assume the distributional hypothesis (Harris, 1940; Firth, 1957) typically keep track of word co-occurrences in distributional profiles (a.k.a. collocation vectors, or context vectors). Each distributional profile DPu (for some word u) keeps counts of co-occurrence of u with all words within a usually fixed distance from each of its occurrences (a sliding window) in some training corpus. More advanced profiles keep “strength of association” (SoA) information</context>
</contexts>
<marker>Oard, Doermann, Dorr, He, Resnik, Byrne, Khudanpur, Yarowsky, Leuski, Koehn, Knight, 2003</marker>
<rawString>Doug Oard, David Doermann, Bonnie Dorr, Daqing He, Phillip Resnik, William Byrne, Sanjeeve Khudanpur, David Yarowsky, Anton Leuski, Philipp Koehn, and Kevin Knight. 2003. Desperately seeking cebuano. In Proceedings of HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the ACL,</booktitle>
<pages>440--447</pages>
<contexts>
<context position="17945" citStr="Och and Ney, 2000" startWordPosition="2796" endWordPosition="2799"> For all baselines we used the phrase-based statistical machine translation system Moses (Koehn et al., 2007), with the default model features, weighted in a log-linear framework (Och and Ney, 2002). Feature weights were set with minimum error rate training (Och, 2003) on a development set using BLEU (Papineni et al., 2002) as the objective function. Test results were evaluated using BLEU and TER (Snover et al., 2005). The phrase translation probabilities were determined using maximum likelihood estimation over phrases induced from word-level alignments produced by performing Giza++ training (Och and Ney, 2000) on both source and target sides of the parallel training sets. When the baseline system encountered unknown words in the test set, its behavior was simply to reproduce the foreign word in the translated output. The paraphrase-augmented systems were identical to the corresponding baseline system, with the exception of additional (paraphrase-based) translation rules, and additional feature(s). Similarly to Callison-Burch et al. (2006), we added the following feature: I psim(DPf , DPf) If phrase table entry (e, f) is generated from (e, f&apos;) using monolinguallyderived paraphrases. 1 Otherwise, (4)</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz Josef Och and Hermann Ney. 2000. Improved statistical alignment models. In Proceedings of the 38th Annual Meeting of the ACL, pages 440–447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="17525" citStr="Och and Ney, 2002" startWordPosition="2731" endWordPosition="2734">tional profile DPX, and evaluate psim(DPph,., DPX). Output k-best candidates. Output k-best paraphrase candidates for phrase phr, in descending order of similarity. We set k = 20. Filter out paraphrases with score less than min5core. 384 5 Experiment We examined the application of the system’s paraphrases to handling unknown phrases when translating from English into Chinese (E2C) and from Spanish into English (S2E). For all baselines we used the phrase-based statistical machine translation system Moses (Koehn et al., 2007), with the default model features, weighted in a log-linear framework (Och and Ney, 2002). Feature weights were set with minimum error rate training (Och, 2003) on a development set using BLEU (Papineni et al., 2002) as the objective function. Test results were evaluated using BLEU and TER (Snover et al., 2005). The phrase translation probabilities were determined using maximum likelihood estimation over phrases induced from word-level alignments produced by performing Giza++ training (Och and Ney, 2000) on both source and target sides of the parallel training sets. When the baseline system encountered unknown words in the test set, its behavior was simply to reproduce the foreign</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>Franz Josef Och and Hermann Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the ACL,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="17596" citStr="Och, 2003" startWordPosition="2744" endWordPosition="2745">utput k-best paraphrase candidates for phrase phr, in descending order of similarity. We set k = 20. Filter out paraphrases with score less than min5core. 384 5 Experiment We examined the application of the system’s paraphrases to handling unknown phrases when translating from English into Chinese (E2C) and from Spanish into English (S2E). For all baselines we used the phrase-based statistical machine translation system Moses (Koehn et al., 2007), with the default model features, weighted in a log-linear framework (Och and Ney, 2002). Feature weights were set with minimum error rate training (Och, 2003) on a development set using BLEU (Papineni et al., 2002) as the objective function. Test results were evaluated using BLEU and TER (Snover et al., 2005). The phrase translation probabilities were determined using maximum likelihood estimation over phrases induced from word-level alignments produced by performing Giza++ training (Och and Ney, 2000) on both source and target sides of the parallel training sets. When the baseline system encountered unknown words in the test set, its behavior was simply to reproduce the foreign word in the translated output. The paraphrase-augmented systems were i</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting of the ACL, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>John Henderson</author>
<author>Florence Reeder</author>
</authors>
<title>Corpusbased comprehensive and diagnostic MT evaluation: Initial Arabic, Chinese, French, and Spanish results.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL Human Language Technology Conference,</booktitle>
<pages>124--127</pages>
<location>San Diego, CA.</location>
<contexts>
<context position="2164" citStr="Papineni et al., 2002" startWordPosition="314" endWordPosition="317">own et al., 1993), but untranslated words remain a major problem in SMT. For example, according to Callison-Burch et al. (2006), a SMT system with a training corpus of 10,000 words learned only 10% of the vocabulary; the same system learned about 30% with a training corpus of 100,000 words; and even with a large training corpus of nearly 10,000,000 words it only reached about 90% coverage of the source vocabulary. Coverage of higher order n-gram levels is even harder. This problem plays a major part in reducing machine translation quality, as reflected by both automatic measures such as BLEU (Papineni et al., 2002) and human judgment tests. Improving translation coverage accurately is therefore important for SMT systems. The first solution that might come to mind is to use larger parallel training corpora. However, current state-of-the-art SMT systems cannot learn from non-aligned corpora, while sentence-aligned parallel corpora (bitexts) are a limited resource (See Section 2 for discussion of automaticallycompiled bitexts). Another direction might be to make use of non-parallel corpora for training. However, this requires developing techniques to extract alignments or translations from them, and in a s</context>
<context position="17652" citStr="Papineni et al., 2002" startWordPosition="2752" endWordPosition="2755">e phr, in descending order of similarity. We set k = 20. Filter out paraphrases with score less than min5core. 384 5 Experiment We examined the application of the system’s paraphrases to handling unknown phrases when translating from English into Chinese (E2C) and from Spanish into English (S2E). For all baselines we used the phrase-based statistical machine translation system Moses (Koehn et al., 2007), with the default model features, weighted in a log-linear framework (Och and Ney, 2002). Feature weights were set with minimum error rate training (Och, 2003) on a development set using BLEU (Papineni et al., 2002) as the objective function. Test results were evaluated using BLEU and TER (Snover et al., 2005). The phrase translation probabilities were determined using maximum likelihood estimation over phrases induced from word-level alignments produced by performing Giza++ training (Och and Ney, 2000) on both source and target sides of the parallel training sets. When the baseline system encountered unknown words in the test set, its behavior was simply to reproduce the foreign word in the translated output. The paraphrase-augmented systems were identical to the corresponding baseline system, with the </context>
</contexts>
<marker>Papineni, Roukos, Ward, Henderson, Reeder, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, John Henderson, and Florence Reeder. 2002. Corpusbased comprehensive and diagnostic MT evaluation: Initial Arabic, Chinese, French, and Spanish results. In Proceedings of the ACL Human Language Technology Conference, pages 124–127, San Diego, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated english and german corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Conference of the Association for Computational Linguistics.,</booktitle>
<pages>519--525</pages>
<contexts>
<context position="3037" citStr="Rapp (1999)" startWordPosition="444" endWordPosition="445">n-aligned corpora, while sentence-aligned parallel corpora (bitexts) are a limited resource (See Section 2 for discussion of automaticallycompiled bitexts). Another direction might be to make use of non-parallel corpora for training. However, this requires developing techniques to extract alignments or translations from them, and in a sufficiently fast, memory-efficient, and scalable manner. One approach that can, in principle, better exploit both alignments from bitexts and make use of non-parallel corpora is the distributional collocational approach, e.g., as used by Fung and Yee (1998) and Rapp (1999). However, the systems described there are not easily scalable, and require pre-computation of a very large collocation counts matrix. Related attempts propose generating bitexts from comparable and “quasicomparable” bilingual texts by iteratively bootstrapping documents, sentences, and words (Fung and Cheung, 2004), or by using a maximum entropy classifier (Munteanu and Marcu, 2005). Alignment accuracy remains a challenge for them. Recent work has proposed augmenting the training data with paraphrases generated by pivoting through other languages (Callison-Burch et al., 2006; Madnani et al., </context>
<context position="8843" citStr="Rapp, 1999" startWordPosition="1317" endWordPosition="1318"> although they use a standard SMT measure, alignment error rate (AER), they only report results of the alignment quality, and not of an end-to-end SMT system. Much of the previous research largely focused on morphological analysis in order to reduce type sparseness; Callison-Burch et al. (2006) list some of the influential work in that direction. Work that relies on the distributional hypothesis using bilingual comparable corpora (without the need for bitexts), typically uses a seed lexicon for “bridging” source language phrases 382 with their target languages paraphrases (Fung and Yee, 1998; Rapp, 1999; Diab and Finch, 2000). This approach is sometimes viewed as, or combined with, an information retrieval (IR) approach, and normalizes strength-of-association measures (see Section 3) with IR-related measures such as TF/IDF (Fung and Yee, 1998). To date, reported implementations suffer from scalability issues, as they pre-compute and hold in memory a huge collocation matrix; we know of no report of using this approach in an end-to-end SMT system. Another approach aiming to reduce OOV rate concentrates on increasing parallel training set size without using more dedicated human translation (Res</context>
<context position="11744" citStr="Rapp, 1999" startWordPosition="1781" endWordPosition="1782">r described below). Paraphrasing and other NLP applications that are based on the distributional hypothesis assume entailment in the reverse direction: the right-hand-side of Formula (2) (profile/vector similarity) entails the left-hand-side (semantic similarity). The sliding window and word association (SoA) measures. Some researchers count positional collocations in a sliding window, i.e., the cocounts and SoA measures are calculated per relative position (e.g., for some word/token u, position 1 is the token immediately after u; position -2 is the token preceding the token that precedes u) (Rapp, 1999); other researchers use nonpositional (which we dub here flat) collocations, meaning, they count all token occurrences within the sliding window, regardless of their positions in it relative to u (McDonald, 2000; Mohammad and Hirst, 2006). We use here flat collocations in a 6-token sliding window. Beside simple cooccurrence counts within sliding windows, other SoA measures include functions based on TF/IDF (Fung and Yee, 1998), mutual information (PMI) (Lin, 1998), conditional probabilities (Schuetze and Pedersen, 1997), chi-square test, and the loglikelihood ratio (Dunning, 1993). Profile sim</context>
<context position="13338" citStr="Rapp, 1999" startWordPosition="2028" endWordPosition="2029">e.g., the cosine coefficient, the Jaccard coefficient, the Dice coefficient, and the City-Block measure. The formula for the cosine function for similarity measure is given in Eq. (3): 383 psim(DPu, DP„) = cos(DPu, DP„) E 5oA(u, wz)5oA(v, wz) wi∈V = �5oA(u, wz)2 5oA(v, wz)2 wi∈V wi∈V (3) In principle, any SoA can be used with any profile similarity measure. However, in practice, only some SoA/similarity measure combinations do well, and finding the best combination is still more art than science. Some successful combinations are cosCP (Schuetze and Pedersen, 1997), LinPmI (Lin, 1998), CityLL (Rapp, 1999), and Jensen–Shannon divergence of conditional probabilities (J5DCP). We use here cosine of loglikelihood vectors (McDonald, 2000). Phrasal distributional profiles. Word DPs can be generalized to phrasal DPs, simply by counting words that co-occur within a sliding window around the target phrase’s occurrences (i.e., counting occurrences of words up to 6 words before or after the target phrase). For example, when building a DP for the target phrase counting words in the previous sentence, then simply is in relative position -2, and sliding is in relative position 5. Searching for similar phrasa</context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>Reinhard Rapp. 1999. Automatic identification of word translations from unrelated english and german corpora. In Proceedings of the 37th Annual Conference of the Association for Computational Linguistics., pages 519–525.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Noah Smith</author>
</authors>
<title>The web as a parallel corpus.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="9462" citStr="Resnik and Smith, 2003" startWordPosition="1410" endWordPosition="1413">999; Diab and Finch, 2000). This approach is sometimes viewed as, or combined with, an information retrieval (IR) approach, and normalizes strength-of-association measures (see Section 3) with IR-related measures such as TF/IDF (Fung and Yee, 1998). To date, reported implementations suffer from scalability issues, as they pre-compute and hold in memory a huge collocation matrix; we know of no report of using this approach in an end-to-end SMT system. Another approach aiming to reduce OOV rate concentrates on increasing parallel training set size without using more dedicated human translation (Resnik and Smith, 2003; Oard et al., 2003). 3 Collocational Profiles The distributional hypothesis and distributional profiles. Natural language processing (NLP) applications that assume the distributional hypothesis (Harris, 1940; Firth, 1957) typically keep track of word co-occurrences in distributional profiles (a.k.a. collocation vectors, or context vectors). Each distributional profile DPu (for some word u) keeps counts of co-occurrence of u with all words within a usually fixed distance from each of its occurrences (a sliding window) in some training corpus. More advanced profiles keep “strength of associatio</context>
</contexts>
<marker>Resnik, Smith, 2003</marker>
<rawString>Philip Resnik and Noah Smith. 2003. The web as a parallel corpus. Computational Linguistics, 29(3):349–380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language.</title>
<date>1999</date>
<journal>Journal of Artificial Intelligence Research (JAIR),</journal>
<pages>11--95</pages>
<contexts>
<context position="34376" citStr="Resnik, 1999" startWordPosition="5512" endWordPosition="5513">m having frequent function words as top candidates, which might be a by-product of their alignment “promiscuity”. However, the top antonymous candidate problem seems to mainly plague the monolingual distributional paraphrases (but improves with larger corpora). See also Table 6. The paraphrase quality remains an issue with this method (as with all other paraphrasing methods). Some possible ways of improving it, besides using larger corpora, are: using syntactic information (Callison-Burch, 2008), using semantic knowledge such as thesaurus or WordNet to perform word sense disambiguation (WSD) (Resnik, 1999; Mohammad and Hirst, 2006), improving the similarity measure, and refining the similarity threshold. We would like to explore ways of incorporating syntactic knowledge that do not sacrifice coverage as much as in Callison-Burch (2008); incorporating semantic knowledge to disambiguate phrasal senses; using context to help sense disambiguation (Erk and Padó, 2008); and optimizing the similarity threshold for use in SMT, for example on a held-out dataset: too high a threshold reduces coverage, while too low a threshold results in bad paraphrases and translation. The method presented here is quit</context>
</contexts>
<marker>Resnik, 1999</marker>
<rawString>Philip Resnik. 1999. Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language. Journal of Artificial Intelligence Research (JAIR), 11:95–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Schuetze</author>
<author>Jan O Pedersen</author>
</authors>
<title>A cooccurrence-based thesaurus and two applications to information retreival.</title>
<date>1997</date>
<booktitle>Information Processing and Management,</booktitle>
<volume>33</volume>
<issue>3</issue>
<pages>318</pages>
<contexts>
<context position="12269" citStr="Schuetze and Pedersen, 1997" startWordPosition="1856" endWordPosition="1859">e token immediately after u; position -2 is the token preceding the token that precedes u) (Rapp, 1999); other researchers use nonpositional (which we dub here flat) collocations, meaning, they count all token occurrences within the sliding window, regardless of their positions in it relative to u (McDonald, 2000; Mohammad and Hirst, 2006). We use here flat collocations in a 6-token sliding window. Beside simple cooccurrence counts within sliding windows, other SoA measures include functions based on TF/IDF (Fung and Yee, 1998), mutual information (PMI) (Lin, 1998), conditional probabilities (Schuetze and Pedersen, 1997), chi-square test, and the loglikelihood ratio (Dunning, 1993). Profile similarity measures. A profile similarity function psim(DPu, DP„) is typically defined as a two-place function, taking vectors as arguments, each vector representing a distributional profile of some word u and v, respectively, and whose cells contain the SoA of u (or v) with each word (“collocate”) in the known vocabulary. Similarity can be (and have been) estimated in several ways, e.g., the cosine coefficient, the Jaccard coefficient, the Dice coefficient, and the City-Block measure. The formula for the cosine function f</context>
</contexts>
<marker>Schuetze, Pedersen, 1997</marker>
<rawString>Hinrich Schuetze and Jan O. Pedersen. 1997. A cooccurrence-based thesaurus and two applications to information retreival. Information Processing and Management, 33(3):307 ˝U318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie J Dorr</author>
<author>Richard Schwartz</author>
<author>John Makhoul</author>
<author>Linnea Micciulla</author>
<author>Ralph Weischedel</author>
</authors>
<title>A study of translation error rate with targeted human annotation.</title>
<date>2005</date>
<tech>Technical Report LAMP-TR-126, CS-TR-4755, UMIACS-TR-2005-58,</tech>
<institution>University of Maryland,</institution>
<contexts>
<context position="17748" citStr="Snover et al., 2005" startWordPosition="2769" endWordPosition="2772">an min5core. 384 5 Experiment We examined the application of the system’s paraphrases to handling unknown phrases when translating from English into Chinese (E2C) and from Spanish into English (S2E). For all baselines we used the phrase-based statistical machine translation system Moses (Koehn et al., 2007), with the default model features, weighted in a log-linear framework (Och and Ney, 2002). Feature weights were set with minimum error rate training (Och, 2003) on a development set using BLEU (Papineni et al., 2002) as the objective function. Test results were evaluated using BLEU and TER (Snover et al., 2005). The phrase translation probabilities were determined using maximum likelihood estimation over phrases induced from word-level alignments produced by performing Giza++ training (Och and Ney, 2000) on both source and target sides of the parallel training sets. When the baseline system encountered unknown words in the test set, its behavior was simply to reproduce the foreign word in the translated output. The paraphrase-augmented systems were identical to the corresponding baseline system, with the exception of additional (paraphrase-based) translation rules, and additional feature(s). Similar</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Makhoul, Micciulla, Weischedel, 2005</marker>
<rawString>Matthew Snover, Bonnie J. Dorr, Richard Schwartz, John Makhoul, Linnea Micciulla, and Ralph Weischedel. 2005. A study of translation error rate with targeted human annotation. Technical Report LAMP-TR-126, CS-TR-4755, UMIACS-TR-2005-58, University of Maryland, July, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huihsin Tseng</author>
<author>Pichuan Chang</author>
<author>Galen Andrew</author>
<author>Daniel Jurafsky</author>
<author>Christopher Manning</author>
</authors>
<title>A conditional random field word segmenter.</title>
<date>2005</date>
<booktitle>In Fourth SIGHAN Workshop on Chinese Language Processing.</booktitle>
<contexts>
<context position="19989" citStr="Tseng et al., 2005" startWordPosition="3150" endWordPosition="3153">i, f as they are processed, but only the final asimk score is used, after all k pairs have been processed. Simple arithmetics can show that this method is insensitive to the order in which the paraphrases are processed. We only augment the phrase table with a single rule from f to e, and in it are the feature values of the phrase fi for which the score sim(fi, f) was the highest. 5.1 English-to-Chinese Translation For the English-Chinese (E2C) baseline system, we trained on the LCD Sinorama and FBIS tests (LCD2005T10 and LCD2003E14), and segmented the Chinese side with the Stanford Segmenter (Tseng et al., 2005). After tokenization and filtering, this bitext contained 231,586 lines (6.4M + 5.1M tokens). We trained a trigram language model on the Chinese side. We then split the bitext to 32 even slices, and constructed a reduced set of about 29,000 lines (sentences) by using only every eighth slice. The purpose of creating this subset model was to simulate a resource-poor language. See Table 1. Set # Tokens Source+Target E2C 29K 0.8 + 0.6 E2C Full 6.4 + 5.1 bnc+apw 187 S2E 10K 0.3 + 0.3 S2E 20K 0.6 + 0.6 S2E 80K 2.3 + 2.3 wmt09 84 wmt09+acquis 139 wmt09+acquis+afp 402 Table 1: Training set sizes (mill</context>
</contexts>
<marker>Tseng, Chang, Andrew, Jurafsky, Manning, 2005</marker>
<rawString>Huihsin Tseng, Pichuan Chang, Galen Andrew, Daniel Jurafsky, and Christopher Manning. 2005. A conditional random field word segmenter. In Fourth SIGHAN Workshop on Chinese Language Processing.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>