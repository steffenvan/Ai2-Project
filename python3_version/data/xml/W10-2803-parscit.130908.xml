<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004171">
<title confidence="0.9955935">
What Is Word Meaning, Really?
(And How Can Distributional Models Help Us Describe It?)
</title>
<author confidence="0.997098">
Katrin Erk
</author>
<affiliation confidence="0.997958">
Department of Linguistics
University of Texas at Austin
</affiliation>
<email confidence="0.998422">
katrin.erk@mail.utexas.edu
</email>
<sectionHeader confidence="0.993888" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999906105263158">
In this paper, we argue in favor of re-
considering models for word meaning, us-
ing as a basis results from cognitive sci-
ence on human concept representation.
More specifically, we argue for a more
flexible representation of word meaning
than the assignment of a single best-fitting
dictionary sense to each occurrence: Ei-
ther use dictionary senses, but view them
as having fuzzy boundaries, and assume
that an occurrence can activate multiple
senses to different degrees. Or move away
from dictionary senses completely, and
only model similarities between individ-
ual word usages. We argue that distri-
butional models provide a flexible frame-
work for experimenting with alternative
models of word meanings, and discuss ex-
ample models.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999893508474577">
Word sense disambiguation (WSD) is one of
the oldest problems in computational linguis-
tics (Weaver, 1949) and still remains challeng-
ing today. State-of-the-art performance on WSD
for WordNet senses is at only around 70-80%
accuracy (Edmonds and Cotton, 2001; Mihalcea
et al., 2004). The use of coarse-grained sense
groups (Palmer et al., 2007) has led to consider-
able advances in WSD performance, with accura-
cies of around 90% (Pradhan et al., 2007). But
this figure averages over lemmas, and the problem
remains that while WSD works well for some lem-
mas, others continue to be tough.
In WSD, polysemy is typically modeled
through a list of dictionary senses thought to be
mutually disjoint, such that each occurrence of
a word is characterized through one best-fitting
dictionary sense. Accordingly, WSD is typically
framed as a classification task. Interestingly, the
task of assigning a single best word sense is very
hard for human annotators, not just machines (Kil-
garriff and Rosenzweig, 2000).
In this paper we advocate the exploration of
alternative computational models of word mean-
ing. After all, one possible reason for the con-
tinuing difficulty of (manual as well as automatic)
word sense assignment is that the prevailing model
might be suboptimal. We explore three main hy-
potheses. The first builds on research on the hu-
man concept representation that has shown that
concepts in the human mind do not work like
sets with clear-cut boundaries; they show graded
membership, and there are typical members as
well as borderline cases (Rosch, 1975; Hamp-
ton, 2007). Accordingly, (A) we will suggest
that word meaning may be better modeled us-
ing a graded notion of sense membership than
through concepts with hard boundaries. Second,
even if senses have soft boundaries, the question
remains of whether they are disjoint. (B) We
will argue in favor of a framework where multi-
ple senses may apply to a single occurrence, to
different degrees. This can be viewed as a dy-
namical grouping of senses for each occurrence,
in contrast to static sense groups as in Palmer et
al. (2007). The first two hypotheses still rely on
an existing sense list. However, there is no univer-
sal agreement across dictionaries and across tasks
on the number of senses that words have (Hanks,
2000). Kilgarriff (1997) even argues that general,
task-independent word senses do not exist. (C) By
focusing on individual occurrences (usages) of
a lemma and their degree of similarity, we can
model word meaning without recourse to dic-
tionary senses.
In this paper, we are going to argue in favor of
the use of vector space as a basis for alternative
models of word meaning. Vector space models
have been used widely to model word sense (Lund
</bodyText>
<page confidence="0.991878">
17
</page>
<note confidence="0.9793735">
Proceedings of the 2010 Workshop on GEometrical Models of Natural Language Semantics, ACL 2010, pages 17–26,
Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999699368421053">
and Burgess, 1996; Deerwester et al., 1990; Lan-
dauer and Dumais, 1997; Sahlgren and Karlgren,
2005; Pad´o and Lapata, 2007), their central prop-
erty being that proximity in space can be used to
predict semantic similarity. By viewing word oc-
currences as points in vector space, we can model
word meaning without recourse to senses. An ad-
ditional advantage of vector space models is that
they are also widely used in human concept rep-
resentation models, yielding many modeling ideas
that can be exploited for computational models.
In Section 2 we review the evidence that word
sense is a tough phenomenon to model, and we lay
out findings that support hypotheses (A)-(C). Sec-
tion 4 considers distributional models that repre-
sent word meaning without recourse to dictionary
senses, following (C). In Section 5 we discuss pos-
sibilities for embedding dictionary senses in vec-
tor space in a way that respects points (A) and (B).
</bodyText>
<sectionHeader confidence="0.511575" genericHeader="introduction">
2 Computational and cognitive models of
word meaning
</sectionHeader>
<bodyText confidence="0.988686794520548">
In this section, we review the problems of (manual
and automatic) sense assignment, and we discuss
discusses cognitive models of concept representa-
tion and polysemy, following the three hypotheses
laid out in the introduction.
Word sense assignment. In computational lin-
guistics, the problem of polysemy is typically
phrased as one of choosing one best-fitting sense
for the given occurrence out of a dictionary-
defined sense list. However, this is a hard task
both for humans and for machines. With Word-
Net (Fellbaum, 1998), the electronic lexicon re-
source that is currently most widely used in com-
putational linguistics, inter-annotator agreement
(ITA) lies in the range of 67% to 78% (Landes
et al., 1998; Snyder and Palmer, 2004; Mihal-
cea et al., 2004), and state-of-the-art WSD sys-
tems achieve accuracy scores of 73% to 77% (Ed-
monds and Cotton, 2001; Mihalcea et al., 2004).
This problem is not specific to WordNet: Anal-
yses with the HECTOR dictionary led to simi-
lar numbers (Kilgarriff and Rosenzweig, 2000).
Sense granularity has been suggested as a reason
for the difficulty of the task (Palmer et al., 2007).
And in fact, the use of more coarse-grained senses
leads to greatly ITA as well as WSD accuracy,
with about a 10% improvement for either mea-
sure (Palmer et al., 2007; Pradhan et al., 2007). In
OntoNotes (Hovy et al., 2006), an ITA of 90% is
used as the criterion for the construction of coarse-
grained sense distinctions. However, intriguingly,
for some high-frequency lemmas such as leave
this ITA threshold is not reached even after mul-
tiple re-partitionings of the semantic space (Chen
and Palmer, 2009) – indicating that the meaning of
these words may not be separable into senses dis-
tinct enough for consistent annotation. A recent
analysis of factors influencing ITA differences be-
tween lemmas (Passonneau et al., 2010) found
three main factors: sense concreteness, specificity
of the context in which a target word occurs, and
similarity between senses. It is interesting to note
that only one of those factors, the third, can be ad-
dressed through a change of dictionary.
More radical solutions than sense grouping that
have been proposed are to restrict the task to deter-
mining predominant sense in a given domain (Mc-
Carthy et al., 2004), or to work directly with para-
phrases (McCarthy and Navigli, 2009).
(A) Graded sense membership. Research on
the human concept representation (Murphy, 2002;
Hampton, 2007) shows that categories in the
human mind are not simply sets with clear-cut
boundaries. Some items are perceived as more
typical than others (Rosch, 1975; Rosch and
Mervis, 1975). Also, some items are clear mem-
bers, others are rated as borderline (Hampton,
1979). On borderline items, people are more likely
to change their mind about category member-
ship (McCloskey and Glucksberg, 1978). How-
ever, these results concern mental concepts, which
raises the question of the relation between mental
concepts and word senses. This relation is dis-
cussed in most depth by Murphy (1991; 2002),
who argues that while not every human concept
is associated with a word, word meanings show
many of the same phenomena as concepts in gen-
eral; word meaning is “made up of pieces of con-
ceptual structure”. In cognitive linguistics there
has been much work on word meaning based on
models with graded membership and typically ef-
fects (Coleman and Kay, 1981; Lakoff, 1987;
Cruse, 1986; Taylor, 1989).
</bodyText>
<listItem confidence="0.805891833333333">
(B) Multiple senses per occurrence. While
most manual word sense annotation efforts al-
low annotators to assign more than one dictionary
sense to an occurrence, this is typically phrased
as an exception rather than the default. In the re-
cent WSsim annotation study (Erk et al., 2009),
</listItem>
<page confidence="0.998358">
18
</page>
<table confidence="0.996279166666667">
Senses
Sentence 1 2 3 4 5 6 7 Annotator
This question provoked arguments in America about the 1 4 4 2 1 1 3 Ann. 1
Norton Anthology of Literature by Women, some of the 4 5 4 2 1 1 4 Ann. 2
contents of which were said to have had little value as 1 4 5 1 1 1 1 Ann. 3
literature.
</table>
<tableCaption confidence="0.9099885">
Table 1: From (Erk et al., 2009): A sample annotation from the WSsim dataset. The senses are: 1:state-
ment, 2:controversy, 3:debate, 4:literary argument, 5:parameter, 6:variable, 7:line of reasoning
</tableCaption>
<bodyText confidence="0.997940488372093">
we asked three human annotators to judge the ap-
plicability of WordNet senses on a graded scale of
1 (completely different) to 5 (identical) and giv-
ing a rating for each sense rather than picking one.
Table 1 shows an example sentence with annota-
tor ratings for the senses of the target argument.
For this sentence, the annotators agree that senses
2 and 3 are highly applicable, but there also indi-
vidual differences in the perceived meaning: Only
annotator 2 views sense 1 as applying to a high
degree. In an annotation setting with graded judg-
ments, it does not make sense to measure exact
agreement on judgments. We instead evaluated
ITA using Spearman’s rho, a nonparametric corre-
lation test, finding highly significant correlations
(p « 0.001) between each pair of annotators, as
well as highly significant correlations with the re-
sults of a previous, traditional word sense annota-
tion of the same dataset. The annotators made use
of the complete scale (1-5), often opting for inter-
mediate values of sense applicability. In addition,
we tested whether there were groups of senses
that always got the same ratings on any given sen-
tence (which would mean that the annotators im-
plicitly used more coarse-grained senses). What
we found instead is that the annotators seemed to
have mixed and matched senses for the individual
occurrences in a dynamic fashion.
(C) Describing word meaning without dictio-
nary senses. In lexicography, Kilgarriff (1997)
and Hanks (2000) cast doubt on the existence
of task-independent, distinct senses. In cogni-
tive science, Kintsch (2007) calls word meaning
“fluid and flexible”. And some researchers in lex-
ical semantics have suggested that word mean-
ings lie on a continuum between clear cut cases
of ambiguity on the one hand, and on the other
hand vagueness where clear cut boundaries do not
hold (Tuggy, 1993). There are some psycholog-
ical studies on whether different senses of a pol-
ysemous word are represented separately in the
mind or whether there is some joint representa-
tion. However, so far the evidence is inconclusive
</bodyText>
<figure confidence="0.6163085">
1) We study the methods and concepts that each writer uses to
defend the cogency of legal, deliberative, or more generally
political prudence against explicit or implicit charges that
practical thinking is merely a knack or form of cleverness.
2) Eleven CIRA members have been convicted of criminal
charges and others are awaiting trial.
</figure>
<figureCaption confidence="0.886414666666667">
Figure 1: From (Erk et al., 2009): A sense pair
from the USim dataset, for the target charge.n.
Annotator judgments: 2,3,4
</figureCaption>
<bodyText confidence="0.999971931034483">
and varies strongly with the experimental setting.
Some studies found evidence for a separate rep-
resentation (Klein and Murphy, 2001; Pylkkanen
et al., 2006). Brown (2008) finds a linear change
in semantic similarity effects with sense distance,
which could possibly point to a continuous rep-
resentation of word meaning without clear sense
boundaries. But while there is no definitive answer
yet on the question of the mental representation
of polysemy, a computational model that does not
rely on distinct senses has the advantage of making
fewer assumptions. It also avoids the tough lexi-
cographic problem mentioned above, of deciding
on a best set of senses for a given domain.
In the recent USim annotation study (Erk et al.,
2009), we tested whether human annotators could
reliably and consistently provide word meaning
judgments without the use of dictionary senses.
Three annotators rated the similarity of pairs of oc-
currences (usages) of a common target word, again
on a scale of 1-5. Figure 1 shows an example,
with the corresponding annotator judgments. The
results on this task were encouraging: Again us-
ing correlation to measure ITA, we found a highly
significant correlation (p « 0.001) between the
judgments of each pair of annotators. Further-
more, there was a strong correlation on judgments
given with and without the use of dictionary senses
(USim versus WSsim) for the same data.
</bodyText>
<page confidence="0.996472">
19
</page>
<bodyText confidence="0.983493377777778">
3 Vector space models of word meaning
in isolation
This section gives a brief overview of the use of
vector spaces to model concepts and word mean-
ing in cognition and computational linguistics.
In two of the current main theories of concept
representation, feature vectors play a prominent
role. Prototype theory (Hampton, 1979; Smith and
Medin, 1981) models degree of category member-
ship through similarity to a single prototype. Ex-
emplar models (Medin and Schaffer, 1978; Nosof-
sky, 1992; Nosofsky and Palmeri, 1997) represent
a concept as a collection of all previously seen ex-
emplars and compute degree of category member-
ship as similarity to stored exemplars. Both pro-
totypes and exemplars are typically represented as
feature vectors. Many models represent a concept
as a region rather than a point in space, often char-
acterized by a feature vector plus a separate di-
mension weight vector (Smith et al., 1988; Hamp-
ton, 1991; G¨ardenfors, 2004). The features are
individually meaningful and interpretable and in-
clude sensory and motor features as well as func-
tion and taxonomic features. There are several
datasets with features elicited from human sub-
jects (McRae et al., 2005; Vigliocco et al., 2004).
In computational linguistics, distributional
models represent the meaning of a word as a vec-
tor in a high-dimensional space whose dimensions
characterize the contexts in which the word typi-
cally occurs (Lund and Burgess, 1996; Landauer
and Dumais, 1997; Sahlgren and Karlgren, 2005;
Pad´o and Lapata, 2007). In the simplest case,
the dimensions are context words, and the values
are co-occurrence counts. In contrast to spaces
used in cognitive science, the dimensions in dis-
tributional models are typically not interpretable
(though see Almuhareb and Poesio (2005), Baroni
et al. (2010)). A central property of distributional
models is that proximity in vector space is a pre-
dictor of semantic similarity. These models have
been used successfully in NLP (Deerwester et al.,
1990; Manning et al., 2008), as well as in psy-
chology (Landauer and Dumais, 1997; Lowe and
McDonald, 2000; McDonald and Ramscar, 2001).
</bodyText>
<sectionHeader confidence="0.5499905" genericHeader="method">
4 Vector space models of word meaning
in context
</sectionHeader>
<bodyText confidence="0.999994018518519">
If we want to represent word meaning through
individual usages and their similarity only, with-
out the use of dictionary senses (along hypothesis
(C)), distributional models are an obvious choice,
if we can just represent each individual usage as
a point in space. However, vector space models
have mostly been used to represent the meaning of
a word in isolation: The vector for a word is com-
puted by summing over all its corpus occurrences,
thereby summing over all its meanings. There are
a few vector space models of meaning in context,
though they differ in what it is that they model.
One group of models computes a single vector for
a whole sentence, encoding both the words and the
syntactic structure (Smolensky, 1990; B. Coecke
and Clark, 2010). In this case, the dimensionality
of the vectors varies with the syntactic complexity
of the sentence in question. A second group also
computes a single vector for a whole expression,
but the vector for a larger expression is a combi-
nation of the word vectors for the words occurring
in the expression (Landauer and Dumais, 1997;
Mitchell and Lapata, 2008). Syntactic structure
is not encoded. The resulting vector, of the same
dimensionality as the word vectors, is then a com-
bination of the contexts in which the words of the
sentence occur. A third group of approaches de-
rives a separate vector for each word in a given
sentence (Erk and Pad´o, 2008; Thater et al., 2009;
Erk and Pad´o, 2010). While an approach of the
second type would derive a single, joint vector for,
say, the expression catch a ball, an approach from
the third group would derive two vectors, one for
the word catch in the context of ball, and one for
the word ball in the context of catch. In this third
group, the dimensionality of a vector for a word in
context is the same as for a word in isolation.
In this paper, we focus on the third type of ap-
proaches. Our aim is to study alternatives to dic-
tionary senses for characterizing word meaning.
So we need a meaning characterization for each
individual word in a given sentence context, rather
than a single vector for a larger expression.
We can also classify distributional approaches
to word meaning in context into prototype- and
exemplar-based approaches. Prototype-based ap-
proaches first compute a (prototype) vector for
each word in isolation, then modify this vec-
tor according to the context in a given occur-
rence (Landauer and Dumais, 1997; Mitchell
and Lapata, 2008; Erk and Pad´o, 2008; Thater
et al., 2009). Typical methods for combining
prototype vectors are addition, component-wise
multiplication (introduced by Mitchell and Lap-
</bodyText>
<page confidence="0.963898">
20
</page>
<figureCaption confidence="0.992167333333333">
Figure 2: From (Erk and Pad´o, 2008): Left: Vector representations for verb catch and noun ball. Lexical
information plus selectional preferences. Right: Computing context-specific meaning by combining
predicate and argument via selectional preference vectors
</figureCaption>
<figure confidence="0.993320976744186">
accuse
say
claim
obj
cold
baseball
drift
red
golf
elegant
...
...
...
comp-1
subj
catch
cold
baseball
drift
obj
throw
catch
organise
obj-1 subj-1
ball
mod
...
whirl
fly
provide
subj-1
throw
catch
organise
obj-1
ball
mod
comp-1
catch
subj
he
fielder
dog
</figure>
<bodyText confidence="0.999684222222222">
ata (2008)), and component-wise minimum. Then
there are multiple prototype approaches that stat-
ically cluster synonyms or occurrences to induce
word senses(Sch¨utze, 1998; Pantel and Lin, 2002;
Reisinger and Mooney, 2010). Exemplar-based
approaches represent a word in isolation as a col-
lection of its occurrences or paraphrases, then se-
lect only the contextually appropriate exemplars
for a given occurrence context (Kintsch, 2001; Erk
and Pad´o, 2010). In this paper we focus on the first
and third group of approaches, as they do not rely
on knowledge of how many word senses (clusters)
there should be.
A structured vector space model for word
meaning in context. In Erk and Pad´o (2008), we
proposed the structured vector space model (SVS),
which relies solely on syntactic context for com-
puting a context-specific vector. It is a prototype-
based model, , and called structured because it ex-
plicitly represents argument structure, using multi-
ple vectors to represent each word. Figure 2 (left)
illustrates the representation. A word, for exam-
ple catch, has one vector describing the meaning
of the word itself, the lexical vector ~catch. It is
a vector for the word in isolation, as is usual for
prototype-based models. In addition, the represen-
tation for catch contains further vectors describing
the selectional preferences for each argument po-
sition. The obj preference vector of catch is com-
puted from the lexical vectors of all words that
have been observed as direct objects of catch in
some syntactically parsed corpus. In the example
in Figure 2, we have observed the direct objects
cold, baseball, and drift. In the simplest case,
the obj preference vector of catch is then com-
puted as the (weighted) sum of the three vectors
</bodyText>
<equation confidence="0.84967">
� � �
</equation>
<bodyText confidence="0.981524047619048">
cold, baseball and drift. Likewise, ball is repre-
sented by one vector for ball itself, one for ball’s
preferences for its modifiers (mod), one vector for
the verbs of which it is a subject (subj−1), and one
for the verbs of which is an object (obj−1).
The vector for catch in a given context, say in
the context catch ball, is then computed as illus-
trated on the right side of Figure 2: The lexical
vector ~catch is combined with the obj−1 vector of
�
ball, modifying the vector catch in the direction of
verbs that typically take ball as an object. For the
vector combination, any of the usual operations
can be used: addition, component-wise multipli-
cation, or minimum. Likewise, the lexical vector
�
ball is combined with the obj preference vector of
catch to compute the meaning of ball in the con-
text catch ball.
The standard evaluation for vector models of
meaning in context is to predict paraphrase appro-
priateness. Paraphrases always apply to a word
meaning, not a word. For example, contract is
an appropriate paraphrase for catch in the context
John caught the flu, but it is not an appropriate
paraphrase in the context John caught a butterfly.
A vector space model can predict paraphrase ap-
propriateness as the similarity (measured, for ex-
ample, using Cosine) of the context-specific vec-
tor of catch with the lexical vector of contract:
The more similar the vectors, the higher the pre-
dicted appropriateness of the paraphrase. We eval-
uated SVS on two datasets. The first is a tightly
controlled psycholinguistic dataset of subject/verb
pairs with paraphrases for the verbs only (Mitchell
and Lapata, 2008). The other is the Lexical Sub-
stitution dataset, which has annotator-generated
paraphrases for target words in a larger senten-
tial context and which is thus closer to typical
NLP application scenarios (McCarthy and Nav-
igli, 2009). SVS showed comparable performance
to the model by Mitchell and Lapata (2008) on the
</bodyText>
<page confidence="0.998063">
21
</page>
<bodyText confidence="0.9998608">
former dataset, and outperformed the Mitchell and
Lapata model on the latter.
One obvious extension is to use all available
syntactic context, instead of focusing on a sin-
gle syntactic neighbor. We found no improve-
ment on SVS in a straightforward extension to
additional syntactic context items (Erk and Pad´o,
2009). However, Thater et al. (2009) did achieve
better performance with a different model that
used all syntactic context.
Taking larger context into account in an
exemplar-based model. But even if we take the
complete local syntactic context into account, we
are missing some evidence, in particular non-local
information. The word ball is interpreted differ-
ently in sentences (1a) and (1b) 1 even though its
predicate ran has more or less the same meaning in
both sentences. What is different is the subject of
ran, player versus debutante, which is not a direct
syntactic neighbor of the ambiguous word ball.
</bodyText>
<listItem confidence="0.9486905">
(1) (a) the player ran to the ball
(b) the debutante ran to the ball
</listItem>
<bodyText confidence="0.999980304347826">
Even though we are not using dictionary senses,
the types of evidence that should be useful for
computing occurrence-specific vectors should be
the same as for traditional WSD; and one of the
main type of features used there is bag-of-words
context. In (Erk and Pad´o, 2010), we proposed an
exemplar-based model of word meaning in con-
text that relied on bag-of-words context informa-
tion from the whole sentence, but did not use syn-
tactic information. The model assumes that each
target lemma is represented by a set of exemplars,
where an exemplar is a sentence in which the tar-
get lemma occurs. Polysemy is then modeled by
activating (selecting) relevant exemplars of a tar-
get lemma in a given occurrence s.2 Both the ex-
emplars and the occurrence s are modeled as vec-
tors. We simply use first-order vectors that re-
flect the number of times each word occurs in a
given sentence. The activated exemplars are then
simply the ones whose vectors are most similar
to the vector of s. The results that we achieved
with the exemplar-based model on the Lexical
Substitution dataset were considerably better than
</bodyText>
<footnote confidence="0.974454">
1These two examples are due to Ray Mooney.
2Instead of the binary selection of each exemplar that this
model uses, it would also be possible to assign each exemplar
a weight, making it partially selected.
</footnote>
<bodyText confidence="0.998983214285714">
those achieved with any of the syntax-based ap-
proaches (Erk and Pad´o, 2008; Erk and Pad´o,
2009; Thater et al., 2009).
While prototype models compute a vector by
first summing over all observed occurrences and
then having to suppress dimensions that are not
contextually appropriate, exemplar models only
take contextually appropriate exemplars into ac-
count in the first place, which is conceptually
simpler and thus more attractive. But there are
still many open questions, in particular the best
combination of bag-of-words context and syntac-
tic context as evidence for computing occurrence-
specific vector representations.
</bodyText>
<sectionHeader confidence="0.86075" genericHeader="method">
5 The role of dictionary senses
</sectionHeader>
<bodyText confidence="0.999885628571428">
Word meaning models that rely only on individual
word usages and their similarities are more flex-
ible than dictionary-based models and make less
assumptions. On the other hand, dictionaries offer
not just sense lists but also a wealth of information
that can be used for inferences. WordNet (Fell-
baum, 1998) has relations between words and be-
tween synsets, most importantly synonymy and
hyponymy. VerbNet (Kipper et al., 2000) specifies
semantic properties of a predicate’s arguments, as
well as relations between the arguments.
In this section we discuss approaches for em-
bedding dictionary senses in a distributional model
in a way that supports hypotheses (A) and (B)
(graded sense membership, and description of an
occurrence through multiple senses) and that sup-
ports testing the applicability of dictionary-based
inference rules.
Mapping dictionary senses to points in vec-
tor space. Dictionary senses can be mapped to
points in vector space very straightforwardly if we
have sense-annotated corpus data. In that case,
we can compute a (prototype) vector for a sense
from all corpus occurrences annotated with that
sense. We used this simple model (Erk and Mc-
Carthy, 2009) to predict the graded sense appli-
cability judgments from the WSsim dataset. (See
Section 2 for more information on this dataset.)
The predictions of the vector space model sig-
nificantly correlate with annotator judgments. In
comparison with an approach that uses the con-
fidence levels of a standard WSD model as pre-
dictions, the vector space model shows higher re-
call but lower precision – for definitions of preci-
sion and recall that are adapted to the graded case.
</bodyText>
<page confidence="0.991335">
22
</page>
<bodyText confidence="0.999669857142857">
Another way of putting the findings is to say that
the WSD confidence levels tend to under-estimate
sense applicability, while the vector space model
tends to over-estimate it.
Attachment sites for inference rules. As dis-
cussed above, vector space models for word mean-
ing in context are typically evaluated on para-
phrase applicability tasks (Mitchell and Lapata,
2008; Erk and Pad´o, 2008; Erk and Pad´o, 2009;
Thater et al., 2009). They predict the applicabil-
ity of a paraphrase like (2) based on the similarity
between a context-specific vector for the lemma
(here, catch) and a context-independent vector for
the paraphrase. (in this case, contract).
</bodyText>
<equation confidence="0.945001">
X catch Y —* X contract Y (2)
</equation>
<bodyText confidence="0.999952823529411">
Another way of looking at this is to consider the
inference rule (2) to be attached to a point in
space, namely the vector for contract, and to trig-
ger the inference rule for an occurrence of catch if
it is close enough to the attachment site. If we
know the WordNet sense of contract for which
rule (2) holds – it happens to be sense 4 –, we can
attach the rule to a vector for sense 4 of contract,
rather than a vector computed from all occurrences
of the lemma. Note that when we use dictionar-
ies as a source for inference rules, for example
by creating an inference rule like (2) for each two
words that share a synset and for each direct hy-
ponym/hypernym pair, we do know the WordNet
sense to which each inference rule attaches.
Mapping dictionary senses to regions in vector
space. In Erk (2009) we expand on the idea of
tying inference rules to attachment sites by repre-
senting a word sense not as a point but as a region
in vector space. The extent of the regions is esti-
mated through the use of both positive exemplars
(occurrences of the word sense in question), and
negative exemplars (occurrences of other words).
The computational models we use are inspired by
cognitive models of concept representation that
represent concepts as regions (Smith et al., 1988;
Hampton, 1991), in particular adopting Shepard’s
law (Shepard, 1987), which states that perceived
similarity to an exemplar decreases exponentially
with distance from its vector.
In the longer term, the goal for the association
of inference rules with attachment sites is to obtain
a principled framework for reasoning with par-
tially applicable inference rules in vector space.
</bodyText>
<sectionHeader confidence="0.897716" genericHeader="conclusions">
6 Conclusion and outlook
</sectionHeader>
<bodyText confidence="0.99997392">
In this paper, we have argued that it may be time
to consider alternative computational models of
word meaning, given that word sense disambigua-
tion, after all this time, is still a tough problem for
humans as well as machines. We have followed
three hypotheses. The first two involve dictionary
senses, suggesting that (A) senses may best be
viewed as applying to a certain degree, rather than
in a binary fashion, and (B) that it may make sense
to describe an occurrence through multiple senses
as a default rather than an exception. The third
hypothesis then departs from dictionary senses,
suggesting (C) focusing on individual word us-
ages and their similarities instead. We have argued
that distributional models are a good match for
word meaning models following hypotheses (A)-
(C): They can represent individual word usages as
points in vector space, and they can also represent
dictionary senses in a way that allows for graded
membership and overlapping senses, and we have
discussed some existing models, both prototype-
based and exemplar-based.
One big question is, of course, about the us-
ability of these alternative models of word mean-
ing in NLP applications. Will they do better than
dictionary-based models? The current evaluations,
testing paraphrase applicability in context, are a
step in the right direction, but more task-oriented
evaluation schemes have to follow.
We have argued that it makes sense to look to
cognitive models of mental concept representa-
tion. They are often based on feature vectors, and
there are many interesting ideas in these models
that have not yet been used (much) in computa-
tional models of word meaning. One of the most
exciting ones, perhaps, is that cognitive models of-
ten have interpretable dimensions. While dimen-
sions of distributional models are usually not in-
dividually interpretable, there are some first mod-
els (Almuhareb and Poesio, 2005; Baroni et al.,
2010) that use patterns to extract meaningful di-
mensions from corpus data. This offers many new
perspectives: For which tasks can we improve per-
formance by selecting dimensions that are mean-
ingful specifically for that task (as in Mitchell et
al. (2008))? Can interpretable dimensions be used
for inferences? And, when we are computing vec-
tor space representations for word meaning in con-
text, is it possible to select meaningful dimensions
that are appropriate for a given context?
</bodyText>
<page confidence="0.993022">
23
</page>
<bodyText confidence="0.952382444444445">
Acknowledgements. This work was supported
in part by National Science Foundation grant IIS-
0845925, and by a Morris Memorial Grant from
the New York Community Trust.
K. Erk, D. McCarthy, and N. Gaylord. 2009. Inves-
tigations on word senses and word usages. In Pro-
ceedings of ACL, Singapore.
Katrin Erk. 2009. Representing words as regions in
vector space. In Proceedings of CoNLL.
</bodyText>
<sectionHeader confidence="0.985122" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999408978021978">
A. Almuhareb and M. Poesio. 2005. Finding concept
attributes in the web. In Proceedings of the Corpus
Linguistics Conference, Birmingham.
M. Sadrzadeh B. Coecke and S. Clark. 2010. Mathe-
matical foundations for a compositional distributed
model of meaning. Lambek Festschrift, Linguistic
Analysis, 36.
M. Baroni, B. Murphy, E. Barbu, and M. Poesio. 2010.
Strudel: A corpus-based semantic model based on
properties and types. Cognitive Science, 34(2):222–
254.
S. W. Brown. 2008. Choosing sense distinctions for
WSD: Psycholinguistic evidence. In Proceedings of
ACL/HLT, Columbus, OH.
J. Chen and M. Palmer. 2009. Improving English
verb sense disambiguation performance with lin-
guistically motivated features and clear sense dis-
tinction boundaries. Journal of Language Resources
and Evaluation, Special Issue on SemEval-2007,
43:181–208.
L. Coleman and P. Kay. 1981. The English word “lie”.
Linguistics, 57.
D. A. Cruse. 1986. Lexical Semantics. Cambridge
University Press.
S. Deerwester, S. T. Dumais, T. K. Landauer, G. W.
Furnaas, and R. A. Harshman. 1990. Indexing by
latent semantic analysis. Journal of the Society for
Information Science, 41(6):391–407.
P. Edmonds and S. Cotton, editors. 2001. Proceed-
ings of the SensEval-2 Workshop, Toulouse, France.
ACL. Seehttp://www.sle.sharp.co.uk/
senseval.
K. Erk and D. McCarthy. 2009. Graded word sense
assignment. In Proceedings of EMNLP, Singapore.
K. Erk and S. Pad´o. 2008. A structured vector space
model for word meaning in context. In Proceedings
of EMNLP, Honolulu, HI.
K. Erk and S. Pad´o. 2009. Paraphrase assessment in
structured vector space: Exploring parameters and
datasets. In Proceedings of the EACL Workshop on
Geometrical Methods for Natural Language Seman-
tics (GEMS).
K. Erk and S. Pad´o. 2010. Exemplar-based models
for word meaning in context. In Proceedings of the
ACL, Uppsala.
C. Fellbaum, editor. 1998. WordNet: An electronic
lexical database. MIT Press, Cambridge, MA.
P. G¨ardenfors. 2004. Conceptual spaces. MIT press,
Cambridge, MA.
J. A. Hampton. 1979. Polymorphous concepts in se-
mantic memory. Journal of Verbal Learning and
Verbal Behavior, 18:441–461.
J. A. Hampton. 1991. The combination of prototype
concepts. In P. Schwanenflugel, editor, The psy-
chology of word meanings. Lawrence Erlbaum As-
sociates.
J. A. Hampton. 2007. Typicality, graded membership,
and vagueness. Cognitive Science, 31:355–384.
P. Hanks. 2000. Do word meanings exist? Computers
and the Humanities, 34(1-2):205–215(11).
E. H. Hovy, M. Marcus, M. Palmer, S. Pradhan,
L. Ramshaw, and R. Weischedel. 2006. OntoNotes:
The 90% solution. In Proceedings of HLT-NAACL,
pages 57–60, New York.
A. Kilgarriff and J. Rosenzweig. 2000. Framework
and results for English Senseval. Computers and the
Humanities, 34(1-2):15–48.
A. Kilgarriff. 1997. I don’t believe in word senses.
Computers and the Humanities, 31(2):91–113.
W. Kintsch. 2001. Predication. Cognitive Science,
25:173–202.
W. Kintsch. 2007. Meaning in context. In T.K. Lan-
dauer, D. McNamara, S. Dennis, and W. Kintsch, ed-
itors, Handbook of Latent Semantic Analysis, pages
89–105. Erlbaum, Mahwah, NJ.
K. Kipper, H.T. Dang, and M. Palmer. 2000. Class-
based construction of a verb lexicon. In Proceedings
ofAAAI/IAAI.
D.E. Klein and G.L. Murphy. 2001. The representa-
tion of polysemous words. Journal of Memory and
Language, 45:259–282.
G. Lakoff. 1987. Women, fire, and dangerous things.
The University of Chicago Press.
T. Landauer and S. Dumais. 1997. A solution to Platos
problem: the latent semantic analysis theory of ac-
quisition, induction, and representation of knowl-
edge. Psychological Review, 104(2):211–240.
S. Landes, C. Leacock, and R. Tengi. 1998. Build-
ing semantic concordances. In C. Fellbaum, editor,
WordNet: An Electronic Lexical Database. The MIT
Press, Cambridge, MA.
</reference>
<page confidence="0.990581">
24
</page>
<reference confidence="0.997909425742574">
W. Lowe and S. McDonald. 2000. The direct route:
Mediated priming in semantic space. In Proceed-
ings of the Cognitive Science Society, pages 675–
680.
K. Lund and C. Burgess. 1996. Producing
high-dimensional semantic spaces from lexical co-
occurrence. Behavior Research Methods, Instru-
ments, and Computers, 28:203—208.
C. D. Manning, P. Raghavan, and H. Sch¨utze. 2008.
Introduction to Information Retrieval. Cambridge
University Press.
D. McCarthy and R. Navigli. 2009. The English lexi-
cal substitution task. Language Resources and Eval-
uation, 43(2):139–159. Special Issue on Compu-
tational Semantic Analysis of Language: SemEval-
2007 and Beyond.
D. McCarthy, R. Koeling, J. Weeds, and J. Carroll.
2004. Finding predominant senses in untagged text.
In Proceedings of ACL, Barcelona.
M. McCloskey and S. Glucksberg. 1978. Natural cat-
egories: Well defined or fuzzy sets? Memory &amp;
Cognition, 6:462–472.
S. McDonald and M. Ramscar. 2001. Testing the dis-
tributional hypothesis: The influence of context on
judgements of semantic similarity. In Proceedings
of the Cognitive Science Society, pages 611–616.
K. McRae, G. S. Cree, M. S. Seidenberg, and C. Mc-
Norgan. 2005. Semantic feature production norms
for a large set of living and nonliving things. Behav-
ior Research Methods, 37(4):547–559.
D. L. Medin and M. M. Schaffer. 1978. Context the-
ory of classification learning. Psychological Review,
85:207–238.
R. Mihalcea, T. Chklovski, and A. Kilgariff. 2004. The
Senseval-3 English lexical sample task. In Proceed-
ings of SensEval-3, Barcelona.
J. Mitchell and M. Lapata. 2008. Vector-based models
of semantic composition. In Proceedings of ACL,
Columbus, OH.
T. Mitchell, S. Shinkareva, A. Carlson, K. Chang,
V.Malave, R. Mason, and M. Just. 2008. Predicting
human brain activity associated with the meanings
of nouns. Science, 320(5880):1191–1195.
G. L. Murphy. 1991. Meaning and concepts. In
P. Schwanenflugel, editor, The psychology of word
meanings. Lawrence Erlbaum Associates.
G. L. Murphy. 2002. The Big Book of Concepts. MIT
Press.
R. M. Nosofsky and T. J. Palmeri. 1997. An exemplar-
based random walk model of speeded classification.
Psychological Review, 104(2):266–300.
R. M. Nosofsky. 1992. Exemplars, prototypes, and
similarity rules. In A. Healy, S. Kosslyn, and
R. Shiffrin, editors, From learning theory to connec-
tionist theory: essays in honor of W.K. Estes, vol-
ume 1, pages 149–168. Erlbaum, Hillsdale, NJ.
S. Pad´o and M. Lapata. 2007. Dependency-based con-
struction of semantic space models. Computational
Linguistics, 33(2):161–199.
M. Palmer, H. Trang Dang, and C. Fellbaum. 2007.
Making fine-grained and coarse-grained sense dis-
tinctions, both manually and automatically. Natural
Language Engineering, 13:137–163.
P. Pantel and D. Lin. 2002. Discovering word senses
from text. In Proceedings of KDD, Edmonton,
Canada.
R. Passonneau, A. Salleb-Aouissi, V. Bhardwaj, and
N. Ide. 2010. Word sense annotation of polyse-
mous words by multiple annotators. In Proceedings
of LREC-7, Valleta, Malta.
S. Pradhan, E. Loper, D. Dligach, and M. Palmer.
2007. Semeval-2007 task 17: English lexical sam-
ple, SRL and all words. In Proceedings of Se-
mEval¡, Prague, Czech Republic.
L. Pylkkanen, R. Llinas, and G.L. Murphy. 2006. The
representation of polysemy: MEG evidence. Jour-
nal of Cognitive Neuroscience, 18:97–109.
J. Reisinger and R.J. Mooney. 2010. Multi-prototype
vector-space models of word meaning. In Proceed-
ing of NAACL.
E. Rosch and C. B. Mervis. 1975. Family resem-
blance: Studies in the internal structure of cate-
gories. Cognitive Psychology, 7:573–605.
E. Rosch. 1975. Cognitive representations of seman-
tic categories. Journal of Experimental Psychology:
General, 104:192–233.
M. Sahlgren and J. Karlgren. 2005. Automatic bilin-
gual lexicon acquisition using random indexing of
parallel corpora. Journal of Natural Language En-
gineering, Special Issue on Parallel Texts, 11(3).
H. Sch¨utze. 1998. Automatic word sense discrimina-
tion. Computational Linguistics, 24(1).
R. Shepard. 1987. Towards a universal law of
generalization for psychological science. Science,
237(4820):1317–1323.
E. E. Smith and D. L. Medin. 1981. Categories and
Concepts. Harvard University Press, Cambridge,
MA.
E. E. Smith, D. Osherson, L. J. Rips, and M. Keane.
1988. Combining prototypes: A selective modifica-
tion model. Cognitive Science, 12(4):485–527.
</reference>
<page confidence="0.964555">
25
</page>
<reference confidence="0.99921124">
P. Smolensky. 1990. Tensor product variable binding
and the representation of symbolic structures in con-
nectionist systems. Artificial Intelligence, 46:159–
216.
B. Snyder and M. Palmer. 2004. The English all-words
task. In 3rd International Workshop on Semantic
Evaluations (SensEval-3) at ACL-2004, Barcelona,
Spain.
J. Taylor. 1989. Linguistic Categorization: Prototypes
in Linguistic Theory. Oxford Textbooks in Linguis-
tics.
S. Thater, G. Dinu, and M. Pinkal. 2009. Ranking
paraphrases in context. In Proceedings of the ACL
Workshop on Applied Textual Inference, Singapore.
D. H. Tuggy. 1993. Ambiguity, polysemy and vague-
ness. Cognitive linguistics, 4(2):273–290.
G. Vigliocco, D. P. Vinson, W. Lewis, and M. F. Gar-
rett. 2004. Representing the meanings of object
and action words: The featural and unitary semantic
space hypothesis. Cognitive Psychology, 48:422–
488.
W. Weaver. 1949. Translation. In W.N. Locke and
A.D. Booth, editors, Machine Translation of Lan-
guages: Fourteen Essays. MIT Press, Cambridge,
MA.
</reference>
<page confidence="0.998006">
26
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.813866">
<title confidence="0.9578825">What Is Word Meaning, Really? (And How Can Distributional Models Help Us Describe It?)</title>
<author confidence="0.88274">Katrin</author>
<affiliation confidence="0.9972585">Department of University of Texas at</affiliation>
<email confidence="0.998098">katrin.erk@mail.utexas.edu</email>
<abstract confidence="0.99822945">In this paper, we argue in favor of reconsidering models for word meaning, using as a basis results from cognitive science on human concept representation. More specifically, we argue for a more flexible representation of word meaning than the assignment of a single best-fitting dictionary sense to each occurrence: Either use dictionary senses, but view them as having fuzzy boundaries, and assume that an occurrence can activate multiple senses to different degrees. Or move away from dictionary senses completely, and only model similarities between individual word usages. We argue that distributional models provide a flexible framework for experimenting with alternative models of word meanings, and discuss example models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Almuhareb</author>
<author>M Poesio</author>
</authors>
<title>Finding concept attributes in the web.</title>
<date>2005</date>
<booktitle>In Proceedings of the Corpus Linguistics Conference,</booktitle>
<location>Birmingham.</location>
<contexts>
<context position="14703" citStr="Almuhareb and Poesio (2005)" startWordPosition="2411" endWordPosition="2414"> human subjects (McRae et al., 2005; Vigliocco et al., 2004). In computational linguistics, distributional models represent the meaning of a word as a vector in a high-dimensional space whose dimensions characterize the contexts in which the word typically occurs (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007). In the simplest case, the dimensions are context words, and the values are co-occurrence counts. In contrast to spaces used in cognitive science, the dimensions in distributional models are typically not interpretable (though see Almuhareb and Poesio (2005), Baroni et al. (2010)). A central property of distributional models is that proximity in vector space is a predictor of semantic similarity. These models have been used successfully in NLP (Deerwester et al., 1990; Manning et al., 2008), as well as in psychology (Landauer and Dumais, 1997; Lowe and McDonald, 2000; McDonald and Ramscar, 2001). 4 Vector space models of word meaning in context If we want to represent word meaning through individual usages and their similarity only, without the use of dictionary senses (along hypothesis (C)), distributional models are an obvious choice, if we can</context>
<context position="30785" citStr="Almuhareb and Poesio, 2005" startWordPosition="5082" endWordPosition="5085">licability in context, are a step in the right direction, but more task-oriented evaluation schemes have to follow. We have argued that it makes sense to look to cognitive models of mental concept representation. They are often based on feature vectors, and there are many interesting ideas in these models that have not yet been used (much) in computational models of word meaning. One of the most exciting ones, perhaps, is that cognitive models often have interpretable dimensions. While dimensions of distributional models are usually not individually interpretable, there are some first models (Almuhareb and Poesio, 2005; Baroni et al., 2010) that use patterns to extract meaningful dimensions from corpus data. This offers many new perspectives: For which tasks can we improve performance by selecting dimensions that are meaningful specifically for that task (as in Mitchell et al. (2008))? Can interpretable dimensions be used for inferences? And, when we are computing vector space representations for word meaning in context, is it possible to select meaningful dimensions that are appropriate for a given context? 23 Acknowledgements. This work was supported in part by National Science Foundation grant IIS0845925</context>
</contexts>
<marker>Almuhareb, Poesio, 2005</marker>
<rawString>A. Almuhareb and M. Poesio. 2005. Finding concept attributes in the web. In Proceedings of the Corpus Linguistics Conference, Birmingham.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sadrzadeh B Coecke</author>
<author>S Clark</author>
</authors>
<title>Mathematical foundations for a compositional distributed model of meaning. Lambek Festschrift, Linguistic Analysis,</title>
<date>2010</date>
<contexts>
<context position="15851" citStr="Coecke and Clark, 2010" startWordPosition="2606" endWordPosition="2609">ong hypothesis (C)), distributional models are an obvious choice, if we can just represent each individual usage as a point in space. However, vector space models have mostly been used to represent the meaning of a word in isolation: The vector for a word is computed by summing over all its corpus occurrences, thereby summing over all its meanings. There are a few vector space models of meaning in context, though they differ in what it is that they model. One group of models computes a single vector for a whole sentence, encoding both the words and the syntactic structure (Smolensky, 1990; B. Coecke and Clark, 2010). In this case, the dimensionality of the vectors varies with the syntactic complexity of the sentence in question. A second group also computes a single vector for a whole expression, but the vector for a larger expression is a combination of the word vectors for the words occurring in the expression (Landauer and Dumais, 1997; Mitchell and Lapata, 2008). Syntactic structure is not encoded. The resulting vector, of the same dimensionality as the word vectors, is then a combination of the contexts in which the words of the sentence occur. A third group of approaches derives a separate vector f</context>
</contexts>
<marker>Coecke, Clark, 2010</marker>
<rawString>M. Sadrzadeh B. Coecke and S. Clark. 2010. Mathematical foundations for a compositional distributed model of meaning. Lambek Festschrift, Linguistic Analysis, 36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Baroni</author>
<author>B Murphy</author>
<author>E Barbu</author>
<author>M Poesio</author>
</authors>
<title>Strudel: A corpus-based semantic model based on properties and types.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>2</issue>
<pages>254</pages>
<contexts>
<context position="14725" citStr="Baroni et al. (2010)" startWordPosition="2415" endWordPosition="2418">, 2005; Vigliocco et al., 2004). In computational linguistics, distributional models represent the meaning of a word as a vector in a high-dimensional space whose dimensions characterize the contexts in which the word typically occurs (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007). In the simplest case, the dimensions are context words, and the values are co-occurrence counts. In contrast to spaces used in cognitive science, the dimensions in distributional models are typically not interpretable (though see Almuhareb and Poesio (2005), Baroni et al. (2010)). A central property of distributional models is that proximity in vector space is a predictor of semantic similarity. These models have been used successfully in NLP (Deerwester et al., 1990; Manning et al., 2008), as well as in psychology (Landauer and Dumais, 1997; Lowe and McDonald, 2000; McDonald and Ramscar, 2001). 4 Vector space models of word meaning in context If we want to represent word meaning through individual usages and their similarity only, without the use of dictionary senses (along hypothesis (C)), distributional models are an obvious choice, if we can just represent each i</context>
<context position="30807" citStr="Baroni et al., 2010" startWordPosition="5086" endWordPosition="5089"> step in the right direction, but more task-oriented evaluation schemes have to follow. We have argued that it makes sense to look to cognitive models of mental concept representation. They are often based on feature vectors, and there are many interesting ideas in these models that have not yet been used (much) in computational models of word meaning. One of the most exciting ones, perhaps, is that cognitive models often have interpretable dimensions. While dimensions of distributional models are usually not individually interpretable, there are some first models (Almuhareb and Poesio, 2005; Baroni et al., 2010) that use patterns to extract meaningful dimensions from corpus data. This offers many new perspectives: For which tasks can we improve performance by selecting dimensions that are meaningful specifically for that task (as in Mitchell et al. (2008))? Can interpretable dimensions be used for inferences? And, when we are computing vector space representations for word meaning in context, is it possible to select meaningful dimensions that are appropriate for a given context? 23 Acknowledgements. This work was supported in part by National Science Foundation grant IIS0845925, and by a Morris Memo</context>
</contexts>
<marker>Baroni, Murphy, Barbu, Poesio, 2010</marker>
<rawString>M. Baroni, B. Murphy, E. Barbu, and M. Poesio. 2010. Strudel: A corpus-based semantic model based on properties and types. Cognitive Science, 34(2):222– 254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S W Brown</author>
</authors>
<title>Choosing sense distinctions for WSD: Psycholinguistic evidence.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL/HLT,</booktitle>
<location>Columbus, OH.</location>
<contexts>
<context position="11698" citStr="Brown (2008)" startWordPosition="1930" endWordPosition="1931">ods and concepts that each writer uses to defend the cogency of legal, deliberative, or more generally political prudence against explicit or implicit charges that practical thinking is merely a knack or form of cleverness. 2) Eleven CIRA members have been convicted of criminal charges and others are awaiting trial. Figure 1: From (Erk et al., 2009): A sense pair from the USim dataset, for the target charge.n. Annotator judgments: 2,3,4 and varies strongly with the experimental setting. Some studies found evidence for a separate representation (Klein and Murphy, 2001; Pylkkanen et al., 2006). Brown (2008) finds a linear change in semantic similarity effects with sense distance, which could possibly point to a continuous representation of word meaning without clear sense boundaries. But while there is no definitive answer yet on the question of the mental representation of polysemy, a computational model that does not rely on distinct senses has the advantage of making fewer assumptions. It also avoids the tough lexicographic problem mentioned above, of deciding on a best set of senses for a given domain. In the recent USim annotation study (Erk et al., 2009), we tested whether human annotators</context>
</contexts>
<marker>Brown, 2008</marker>
<rawString>S. W. Brown. 2008. Choosing sense distinctions for WSD: Psycholinguistic evidence. In Proceedings of ACL/HLT, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chen</author>
<author>M Palmer</author>
</authors>
<title>Improving English verb sense disambiguation performance with linguistically motivated features and clear sense distinction boundaries.</title>
<date>2009</date>
<journal>Journal of Language Resources and Evaluation, Special Issue on SemEval-2007,</journal>
<pages>43--181</pages>
<contexts>
<context position="6446" citStr="Chen and Palmer, 2009" startWordPosition="1050" endWordPosition="1053">zweig, 2000). Sense granularity has been suggested as a reason for the difficulty of the task (Palmer et al., 2007). And in fact, the use of more coarse-grained senses leads to greatly ITA as well as WSD accuracy, with about a 10% improvement for either measure (Palmer et al., 2007; Pradhan et al., 2007). In OntoNotes (Hovy et al., 2006), an ITA of 90% is used as the criterion for the construction of coarsegrained sense distinctions. However, intriguingly, for some high-frequency lemmas such as leave this ITA threshold is not reached even after multiple re-partitionings of the semantic space (Chen and Palmer, 2009) – indicating that the meaning of these words may not be separable into senses distinct enough for consistent annotation. A recent analysis of factors influencing ITA differences between lemmas (Passonneau et al., 2010) found three main factors: sense concreteness, specificity of the context in which a target word occurs, and similarity between senses. It is interesting to note that only one of those factors, the third, can be addressed through a change of dictionary. More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in</context>
</contexts>
<marker>Chen, Palmer, 2009</marker>
<rawString>J. Chen and M. Palmer. 2009. Improving English verb sense disambiguation performance with linguistically motivated features and clear sense distinction boundaries. Journal of Language Resources and Evaluation, Special Issue on SemEval-2007, 43:181–208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Coleman</author>
<author>P Kay</author>
</authors>
<title>The English word “lie”.</title>
<date>1981</date>
<journal>Linguistics,</journal>
<volume>57</volume>
<contexts>
<context position="8195" citStr="Coleman and Kay, 1981" startWordPosition="1337" endWordPosition="1340"> their mind about category membership (McCloskey and Glucksberg, 1978). However, these results concern mental concepts, which raises the question of the relation between mental concepts and word senses. This relation is discussed in most depth by Murphy (1991; 2002), who argues that while not every human concept is associated with a word, word meanings show many of the same phenomena as concepts in general; word meaning is “made up of pieces of conceptual structure”. In cognitive linguistics there has been much work on word meaning based on models with graded membership and typically effects (Coleman and Kay, 1981; Lakoff, 1987; Cruse, 1986; Taylor, 1989). (B) Multiple senses per occurrence. While most manual word sense annotation efforts allow annotators to assign more than one dictionary sense to an occurrence, this is typically phrased as an exception rather than the default. In the recent WSsim annotation study (Erk et al., 2009), 18 Senses Sentence 1 2 3 4 5 6 7 Annotator This question provoked arguments in America about the 1 4 4 2 1 1 3 Ann. 1 Norton Anthology of Literature by Women, some of the 4 5 4 2 1 1 4 Ann. 2 contents of which were said to have had little value as 1 4 5 1 1 1 1 Ann. 3 lit</context>
</contexts>
<marker>Coleman, Kay, 1981</marker>
<rawString>L. Coleman and P. Kay. 1981. The English word “lie”. Linguistics, 57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Cruse</author>
</authors>
<title>Lexical Semantics.</title>
<date>1986</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="8222" citStr="Cruse, 1986" startWordPosition="1343" endWordPosition="1344"> (McCloskey and Glucksberg, 1978). However, these results concern mental concepts, which raises the question of the relation between mental concepts and word senses. This relation is discussed in most depth by Murphy (1991; 2002), who argues that while not every human concept is associated with a word, word meanings show many of the same phenomena as concepts in general; word meaning is “made up of pieces of conceptual structure”. In cognitive linguistics there has been much work on word meaning based on models with graded membership and typically effects (Coleman and Kay, 1981; Lakoff, 1987; Cruse, 1986; Taylor, 1989). (B) Multiple senses per occurrence. While most manual word sense annotation efforts allow annotators to assign more than one dictionary sense to an occurrence, this is typically phrased as an exception rather than the default. In the recent WSsim annotation study (Erk et al., 2009), 18 Senses Sentence 1 2 3 4 5 6 7 Annotator This question provoked arguments in America about the 1 4 4 2 1 1 3 Ann. 1 Norton Anthology of Literature by Women, some of the 4 5 4 2 1 1 4 Ann. 2 contents of which were said to have had little value as 1 4 5 1 1 1 1 Ann. 3 literature. Table 1: From (Erk</context>
</contexts>
<marker>Cruse, 1986</marker>
<rawString>D. A. Cruse. 1986. Lexical Semantics. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Deerwester</author>
<author>S T Dumais</author>
<author>T K Landauer</author>
<author>G W Furnaas</author>
<author>R A Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the Society for Information Science,</journal>
<volume>41</volume>
<issue>6</issue>
<contexts>
<context position="3890" citStr="Deerwester et al., 1990" startWordPosition="626" endWordPosition="629">independent word senses do not exist. (C) By focusing on individual occurrences (usages) of a lemma and their degree of similarity, we can model word meaning without recourse to dictionary senses. In this paper, we are going to argue in favor of the use of vector space as a basis for alternative models of word meaning. Vector space models have been used widely to model word sense (Lund 17 Proceedings of the 2010 Workshop on GEometrical Models of Natural Language Semantics, ACL 2010, pages 17–26, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics and Burgess, 1996; Deerwester et al., 1990; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007), their central property being that proximity in space can be used to predict semantic similarity. By viewing word occurrences as points in vector space, we can model word meaning without recourse to senses. An additional advantage of vector space models is that they are also widely used in human concept representation models, yielding many modeling ideas that can be exploited for computational models. In Section 2 we review the evidence that word sense is a tough phenomenon to model, and we lay out findings that </context>
<context position="14917" citStr="Deerwester et al., 1990" startWordPosition="2446" endWordPosition="2449">e contexts in which the word typically occurs (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007). In the simplest case, the dimensions are context words, and the values are co-occurrence counts. In contrast to spaces used in cognitive science, the dimensions in distributional models are typically not interpretable (though see Almuhareb and Poesio (2005), Baroni et al. (2010)). A central property of distributional models is that proximity in vector space is a predictor of semantic similarity. These models have been used successfully in NLP (Deerwester et al., 1990; Manning et al., 2008), as well as in psychology (Landauer and Dumais, 1997; Lowe and McDonald, 2000; McDonald and Ramscar, 2001). 4 Vector space models of word meaning in context If we want to represent word meaning through individual usages and their similarity only, without the use of dictionary senses (along hypothesis (C)), distributional models are an obvious choice, if we can just represent each individual usage as a point in space. However, vector space models have mostly been used to represent the meaning of a word in isolation: The vector for a word is computed by summing over all i</context>
</contexts>
<marker>Deerwester, Dumais, Landauer, Furnaas, Harshman, 1990</marker>
<rawString>S. Deerwester, S. T. Dumais, T. K. Landauer, G. W. Furnaas, and R. A. Harshman. 1990. Indexing by latent semantic analysis. Journal of the Society for Information Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Edmonds</author>
<author>S Cotton</author>
<author>editors</author>
</authors>
<date>2001</date>
<booktitle>Proceedings of the SensEval-2 Workshop,</booktitle>
<location>Toulouse, France. ACL.</location>
<note>Seehttp://www.sle.sharp.co.uk/ senseval.</note>
<marker>Edmonds, Cotton, editors, 2001</marker>
<rawString>P. Edmonds and S. Cotton, editors. 2001. Proceedings of the SensEval-2 Workshop, Toulouse, France. ACL. Seehttp://www.sle.sharp.co.uk/ senseval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Erk</author>
<author>D McCarthy</author>
</authors>
<title>Graded word sense assignment.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<contexts>
<context position="26058" citStr="Erk and McCarthy, 2009" startWordPosition="4290" endWordPosition="4294">s approaches for embedding dictionary senses in a distributional model in a way that supports hypotheses (A) and (B) (graded sense membership, and description of an occurrence through multiple senses) and that supports testing the applicability of dictionary-based inference rules. Mapping dictionary senses to points in vector space. Dictionary senses can be mapped to points in vector space very straightforwardly if we have sense-annotated corpus data. In that case, we can compute a (prototype) vector for a sense from all corpus occurrences annotated with that sense. We used this simple model (Erk and McCarthy, 2009) to predict the graded sense applicability judgments from the WSsim dataset. (See Section 2 for more information on this dataset.) The predictions of the vector space model significantly correlate with annotator judgments. In comparison with an approach that uses the confidence levels of a standard WSD model as predictions, the vector space model shows higher recall but lower precision – for definitions of precision and recall that are adapted to the graded case. 22 Another way of putting the findings is to say that the WSD confidence levels tend to under-estimate sense applicability, while th</context>
</contexts>
<marker>Erk, McCarthy, 2009</marker>
<rawString>K. Erk and D. McCarthy. 2009. Graded word sense assignment. In Proceedings of EMNLP, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Erk</author>
<author>S Pad´o</author>
</authors>
<title>A structured vector space model for word meaning in context.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<location>Honolulu, HI.</location>
<marker>Erk, Pad´o, 2008</marker>
<rawString>K. Erk and S. Pad´o. 2008. A structured vector space model for word meaning in context. In Proceedings of EMNLP, Honolulu, HI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Erk</author>
<author>S Pad´o</author>
</authors>
<title>Paraphrase assessment in structured vector space: Exploring parameters and datasets.</title>
<date>2009</date>
<booktitle>In Proceedings of the EACL Workshop on Geometrical Methods for Natural Language Semantics (GEMS).</booktitle>
<marker>Erk, Pad´o, 2009</marker>
<rawString>K. Erk and S. Pad´o. 2009. Paraphrase assessment in structured vector space: Exploring parameters and datasets. In Proceedings of the EACL Workshop on Geometrical Methods for Natural Language Semantics (GEMS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Erk</author>
<author>S Pad´o</author>
</authors>
<title>Exemplar-based models for word meaning in context.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<location>Uppsala.</location>
<marker>Erk, Pad´o, 2010</marker>
<rawString>K. Erk and S. Pad´o. 2010. Exemplar-based models for word meaning in context. In Proceedings of the ACL, Uppsala.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An electronic lexical database.</title>
<date>1998</date>
<editor>C. Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1998</marker>
<rawString>C. Fellbaum, editor. 1998. WordNet: An electronic lexical database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P G¨ardenfors</author>
</authors>
<title>Conceptual spaces.</title>
<date>2004</date>
<publisher>MIT press,</publisher>
<location>Cambridge, MA.</location>
<marker>G¨ardenfors, 2004</marker>
<rawString>P. G¨ardenfors. 2004. Conceptual spaces. MIT press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Hampton</author>
</authors>
<title>Polymorphous concepts in semantic memory.</title>
<date>1979</date>
<journal>Journal of Verbal Learning and Verbal Behavior,</journal>
<pages>18--441</pages>
<contexts>
<context position="7519" citStr="Hampton, 1979" startWordPosition="1226" endWordPosition="1227">f dictionary. More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al., 2004), or to work directly with paraphrases (McCarthy and Navigli, 2009). (A) Graded sense membership. Research on the human concept representation (Murphy, 2002; Hampton, 2007) shows that categories in the human mind are not simply sets with clear-cut boundaries. Some items are perceived as more typical than others (Rosch, 1975; Rosch and Mervis, 1975). Also, some items are clear members, others are rated as borderline (Hampton, 1979). On borderline items, people are more likely to change their mind about category membership (McCloskey and Glucksberg, 1978). However, these results concern mental concepts, which raises the question of the relation between mental concepts and word senses. This relation is discussed in most depth by Murphy (1991; 2002), who argues that while not every human concept is associated with a word, word meanings show many of the same phenomena as concepts in general; word meaning is “made up of pieces of conceptual structure”. In cognitive linguistics there has been much work on word meaning based o</context>
<context position="13257" citStr="Hampton, 1979" startWordPosition="2184" endWordPosition="2185">ng correlation to measure ITA, we found a highly significant correlation (p « 0.001) between the judgments of each pair of annotators. Furthermore, there was a strong correlation on judgments given with and without the use of dictionary senses (USim versus WSsim) for the same data. 19 3 Vector space models of word meaning in isolation This section gives a brief overview of the use of vector spaces to model concepts and word meaning in cognition and computational linguistics. In two of the current main theories of concept representation, feature vectors play a prominent role. Prototype theory (Hampton, 1979; Smith and Medin, 1981) models degree of category membership through similarity to a single prototype. Exemplar models (Medin and Schaffer, 1978; Nosofsky, 1992; Nosofsky and Palmeri, 1997) represent a concept as a collection of all previously seen exemplars and compute degree of category membership as similarity to stored exemplars. Both prototypes and exemplars are typically represented as feature vectors. Many models represent a concept as a region rather than a point in space, often characterized by a feature vector plus a separate dimension weight vector (Smith et al., 1988; Hampton, 199</context>
</contexts>
<marker>Hampton, 1979</marker>
<rawString>J. A. Hampton. 1979. Polymorphous concepts in semantic memory. Journal of Verbal Learning and Verbal Behavior, 18:441–461.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Hampton</author>
</authors>
<title>The combination of prototype concepts.</title>
<date>1991</date>
<editor>In P. Schwanenflugel, editor,</editor>
<contexts>
<context position="13858" citStr="Hampton, 1991" startWordPosition="2283" endWordPosition="2285">ampton, 1979; Smith and Medin, 1981) models degree of category membership through similarity to a single prototype. Exemplar models (Medin and Schaffer, 1978; Nosofsky, 1992; Nosofsky and Palmeri, 1997) represent a concept as a collection of all previously seen exemplars and compute degree of category membership as similarity to stored exemplars. Both prototypes and exemplars are typically represented as feature vectors. Many models represent a concept as a region rather than a point in space, often characterized by a feature vector plus a separate dimension weight vector (Smith et al., 1988; Hampton, 1991; G¨ardenfors, 2004). The features are individually meaningful and interpretable and include sensory and motor features as well as function and taxonomic features. There are several datasets with features elicited from human subjects (McRae et al., 2005; Vigliocco et al., 2004). In computational linguistics, distributional models represent the meaning of a word as a vector in a high-dimensional space whose dimensions characterize the contexts in which the word typically occurs (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007). In the simpl</context>
<context position="28500" citStr="Hampton, 1991" startWordPosition="4719" endWordPosition="4720">now the WordNet sense to which each inference rule attaches. Mapping dictionary senses to regions in vector space. In Erk (2009) we expand on the idea of tying inference rules to attachment sites by representing a word sense not as a point but as a region in vector space. The extent of the regions is estimated through the use of both positive exemplars (occurrences of the word sense in question), and negative exemplars (occurrences of other words). The computational models we use are inspired by cognitive models of concept representation that represent concepts as regions (Smith et al., 1988; Hampton, 1991), in particular adopting Shepard’s law (Shepard, 1987), which states that perceived similarity to an exemplar decreases exponentially with distance from its vector. In the longer term, the goal for the association of inference rules with attachment sites is to obtain a principled framework for reasoning with partially applicable inference rules in vector space. 6 Conclusion and outlook In this paper, we have argued that it may be time to consider alternative computational models of word meaning, given that word sense disambiguation, after all this time, is still a tough problem for humans as w</context>
</contexts>
<marker>Hampton, 1991</marker>
<rawString>J. A. Hampton. 1991. The combination of prototype concepts. In P. Schwanenflugel, editor, The psychology of word meanings. Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Hampton</author>
</authors>
<title>Typicality, graded membership, and vagueness.</title>
<date>2007</date>
<journal>Cognitive Science,</journal>
<pages>31--355</pages>
<contexts>
<context position="2508" citStr="Hampton, 2007" startWordPosition="396" endWordPosition="398">achines (Kilgarriff and Rosenzweig, 2000). In this paper we advocate the exploration of alternative computational models of word meaning. After all, one possible reason for the continuing difficulty of (manual as well as automatic) word sense assignment is that the prevailing model might be suboptimal. We explore three main hypotheses. The first builds on research on the human concept representation that has shown that concepts in the human mind do not work like sets with clear-cut boundaries; they show graded membership, and there are typical members as well as borderline cases (Rosch, 1975; Hampton, 2007). Accordingly, (A) we will suggest that word meaning may be better modeled using a graded notion of sense membership than through concepts with hard boundaries. Second, even if senses have soft boundaries, the question remains of whether they are disjoint. (B) We will argue in favor of a framework where multiple senses may apply to a single occurrence, to different degrees. This can be viewed as a dynamical grouping of senses for each occurrence, in contrast to static sense groups as in Palmer et al. (2007). The first two hypotheses still rely on an existing sense list. However, there is no un</context>
<context position="7257" citStr="Hampton, 2007" startWordPosition="1183" endWordPosition="1184">ssonneau et al., 2010) found three main factors: sense concreteness, specificity of the context in which a target word occurs, and similarity between senses. It is interesting to note that only one of those factors, the third, can be addressed through a change of dictionary. More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al., 2004), or to work directly with paraphrases (McCarthy and Navigli, 2009). (A) Graded sense membership. Research on the human concept representation (Murphy, 2002; Hampton, 2007) shows that categories in the human mind are not simply sets with clear-cut boundaries. Some items are perceived as more typical than others (Rosch, 1975; Rosch and Mervis, 1975). Also, some items are clear members, others are rated as borderline (Hampton, 1979). On borderline items, people are more likely to change their mind about category membership (McCloskey and Glucksberg, 1978). However, these results concern mental concepts, which raises the question of the relation between mental concepts and word senses. This relation is discussed in most depth by Murphy (1991; 2002), who argues that</context>
</contexts>
<marker>Hampton, 2007</marker>
<rawString>J. A. Hampton. 2007. Typicality, graded membership, and vagueness. Cognitive Science, 31:355–384.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Hanks</author>
</authors>
<date>2000</date>
<booktitle>Do word meanings exist? Computers and the Humanities,</booktitle>
<pages>34--1</pages>
<contexts>
<context position="3216" citStr="Hanks, 2000" startWordPosition="519" endWordPosition="520"> of sense membership than through concepts with hard boundaries. Second, even if senses have soft boundaries, the question remains of whether they are disjoint. (B) We will argue in favor of a framework where multiple senses may apply to a single occurrence, to different degrees. This can be viewed as a dynamical grouping of senses for each occurrence, in contrast to static sense groups as in Palmer et al. (2007). The first two hypotheses still rely on an existing sense list. However, there is no universal agreement across dictionaries and across tasks on the number of senses that words have (Hanks, 2000). Kilgarriff (1997) even argues that general, task-independent word senses do not exist. (C) By focusing on individual occurrences (usages) of a lemma and their degree of similarity, we can model word meaning without recourse to dictionary senses. In this paper, we are going to argue in favor of the use of vector space as a basis for alternative models of word meaning. Vector space models have been used widely to model word sense (Lund 17 Proceedings of the 2010 Workshop on GEometrical Models of Natural Language Semantics, ACL 2010, pages 17–26, Uppsala, Sweden, 16 July 2010. c�2010 Associatio</context>
<context position="10469" citStr="Hanks (2000)" startWordPosition="1730" endWordPosition="1731">, traditional word sense annotation of the same dataset. The annotators made use of the complete scale (1-5), often opting for intermediate values of sense applicability. In addition, we tested whether there were groups of senses that always got the same ratings on any given sentence (which would mean that the annotators implicitly used more coarse-grained senses). What we found instead is that the annotators seemed to have mixed and matched senses for the individual occurrences in a dynamic fashion. (C) Describing word meaning without dictionary senses. In lexicography, Kilgarriff (1997) and Hanks (2000) cast doubt on the existence of task-independent, distinct senses. In cognitive science, Kintsch (2007) calls word meaning “fluid and flexible”. And some researchers in lexical semantics have suggested that word meanings lie on a continuum between clear cut cases of ambiguity on the one hand, and on the other hand vagueness where clear cut boundaries do not hold (Tuggy, 1993). There are some psychological studies on whether different senses of a polysemous word are represented separately in the mind or whether there is some joint representation. However, so far the evidence is inconclusive 1) </context>
</contexts>
<marker>Hanks, 2000</marker>
<rawString>P. Hanks. 2000. Do word meanings exist? Computers and the Humanities, 34(1-2):205–215(11).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Hovy</author>
<author>M Marcus</author>
<author>M Palmer</author>
<author>S Pradhan</author>
<author>L Ramshaw</author>
<author>R Weischedel</author>
</authors>
<title>OntoNotes: The 90% solution.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>57--60</pages>
<location>New York.</location>
<contexts>
<context position="6163" citStr="Hovy et al., 2006" startWordPosition="1005" endWordPosition="1008">lmer, 2004; Mihalcea et al., 2004), and state-of-the-art WSD systems achieve accuracy scores of 73% to 77% (Edmonds and Cotton, 2001; Mihalcea et al., 2004). This problem is not specific to WordNet: Analyses with the HECTOR dictionary led to similar numbers (Kilgarriff and Rosenzweig, 2000). Sense granularity has been suggested as a reason for the difficulty of the task (Palmer et al., 2007). And in fact, the use of more coarse-grained senses leads to greatly ITA as well as WSD accuracy, with about a 10% improvement for either measure (Palmer et al., 2007; Pradhan et al., 2007). In OntoNotes (Hovy et al., 2006), an ITA of 90% is used as the criterion for the construction of coarsegrained sense distinctions. However, intriguingly, for some high-frequency lemmas such as leave this ITA threshold is not reached even after multiple re-partitionings of the semantic space (Chen and Palmer, 2009) – indicating that the meaning of these words may not be separable into senses distinct enough for consistent annotation. A recent analysis of factors influencing ITA differences between lemmas (Passonneau et al., 2010) found three main factors: sense concreteness, specificity of the context in which a target word o</context>
</contexts>
<marker>Hovy, Marcus, Palmer, Pradhan, Ramshaw, Weischedel, 2006</marker>
<rawString>E. H. Hovy, M. Marcus, M. Palmer, S. Pradhan, L. Ramshaw, and R. Weischedel. 2006. OntoNotes: The 90% solution. In Proceedings of HLT-NAACL, pages 57–60, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
<author>J Rosenzweig</author>
</authors>
<title>Framework and results for English Senseval. Computers and the Humanities,</title>
<date>2000</date>
<pages>34--1</pages>
<contexts>
<context position="1935" citStr="Kilgarriff and Rosenzweig, 2000" startWordPosition="299" endWordPosition="303"> advances in WSD performance, with accuracies of around 90% (Pradhan et al., 2007). But this figure averages over lemmas, and the problem remains that while WSD works well for some lemmas, others continue to be tough. In WSD, polysemy is typically modeled through a list of dictionary senses thought to be mutually disjoint, such that each occurrence of a word is characterized through one best-fitting dictionary sense. Accordingly, WSD is typically framed as a classification task. Interestingly, the task of assigning a single best word sense is very hard for human annotators, not just machines (Kilgarriff and Rosenzweig, 2000). In this paper we advocate the exploration of alternative computational models of word meaning. After all, one possible reason for the continuing difficulty of (manual as well as automatic) word sense assignment is that the prevailing model might be suboptimal. We explore three main hypotheses. The first builds on research on the human concept representation that has shown that concepts in the human mind do not work like sets with clear-cut boundaries; they show graded membership, and there are typical members as well as borderline cases (Rosch, 1975; Hampton, 2007). Accordingly, (A) we will </context>
<context position="5836" citStr="Kilgarriff and Rosenzweig, 2000" startWordPosition="946" endWordPosition="949"> occurrence out of a dictionarydefined sense list. However, this is a hard task both for humans and for machines. With WordNet (Fellbaum, 1998), the electronic lexicon resource that is currently most widely used in computational linguistics, inter-annotator agreement (ITA) lies in the range of 67% to 78% (Landes et al., 1998; Snyder and Palmer, 2004; Mihalcea et al., 2004), and state-of-the-art WSD systems achieve accuracy scores of 73% to 77% (Edmonds and Cotton, 2001; Mihalcea et al., 2004). This problem is not specific to WordNet: Analyses with the HECTOR dictionary led to similar numbers (Kilgarriff and Rosenzweig, 2000). Sense granularity has been suggested as a reason for the difficulty of the task (Palmer et al., 2007). And in fact, the use of more coarse-grained senses leads to greatly ITA as well as WSD accuracy, with about a 10% improvement for either measure (Palmer et al., 2007; Pradhan et al., 2007). In OntoNotes (Hovy et al., 2006), an ITA of 90% is used as the criterion for the construction of coarsegrained sense distinctions. However, intriguingly, for some high-frequency lemmas such as leave this ITA threshold is not reached even after multiple re-partitionings of the semantic space (Chen and Pal</context>
</contexts>
<marker>Kilgarriff, Rosenzweig, 2000</marker>
<rawString>A. Kilgarriff and J. Rosenzweig. 2000. Framework and results for English Senseval. Computers and the Humanities, 34(1-2):15–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
</authors>
<title>I don’t believe in word senses.</title>
<date>1997</date>
<journal>Computers and the Humanities,</journal>
<volume>31</volume>
<issue>2</issue>
<contexts>
<context position="3235" citStr="Kilgarriff (1997)" startWordPosition="521" endWordPosition="522">ership than through concepts with hard boundaries. Second, even if senses have soft boundaries, the question remains of whether they are disjoint. (B) We will argue in favor of a framework where multiple senses may apply to a single occurrence, to different degrees. This can be viewed as a dynamical grouping of senses for each occurrence, in contrast to static sense groups as in Palmer et al. (2007). The first two hypotheses still rely on an existing sense list. However, there is no universal agreement across dictionaries and across tasks on the number of senses that words have (Hanks, 2000). Kilgarriff (1997) even argues that general, task-independent word senses do not exist. (C) By focusing on individual occurrences (usages) of a lemma and their degree of similarity, we can model word meaning without recourse to dictionary senses. In this paper, we are going to argue in favor of the use of vector space as a basis for alternative models of word meaning. Vector space models have been used widely to model word sense (Lund 17 Proceedings of the 2010 Workshop on GEometrical Models of Natural Language Semantics, ACL 2010, pages 17–26, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational</context>
<context position="10452" citStr="Kilgarriff (1997)" startWordPosition="1727" endWordPosition="1728"> results of a previous, traditional word sense annotation of the same dataset. The annotators made use of the complete scale (1-5), often opting for intermediate values of sense applicability. In addition, we tested whether there were groups of senses that always got the same ratings on any given sentence (which would mean that the annotators implicitly used more coarse-grained senses). What we found instead is that the annotators seemed to have mixed and matched senses for the individual occurrences in a dynamic fashion. (C) Describing word meaning without dictionary senses. In lexicography, Kilgarriff (1997) and Hanks (2000) cast doubt on the existence of task-independent, distinct senses. In cognitive science, Kintsch (2007) calls word meaning “fluid and flexible”. And some researchers in lexical semantics have suggested that word meanings lie on a continuum between clear cut cases of ambiguity on the one hand, and on the other hand vagueness where clear cut boundaries do not hold (Tuggy, 1993). There are some psychological studies on whether different senses of a polysemous word are represented separately in the mind or whether there is some joint representation. However, so far the evidence is</context>
</contexts>
<marker>Kilgarriff, 1997</marker>
<rawString>A. Kilgarriff. 1997. I don’t believe in word senses. Computers and the Humanities, 31(2):91–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Kintsch</author>
</authors>
<date>2001</date>
<journal>Predication. Cognitive Science,</journal>
<pages>25--173</pages>
<contexts>
<context position="18671" citStr="Kintsch, 2001" startWordPosition="3068" endWordPosition="3069">omp-1 subj catch cold baseball drift obj throw catch organise obj-1 subj-1 ball mod ... whirl fly provide subj-1 throw catch organise obj-1 ball mod comp-1 catch subj he fielder dog ata (2008)), and component-wise minimum. Then there are multiple prototype approaches that statically cluster synonyms or occurrences to induce word senses(Sch¨utze, 1998; Pantel and Lin, 2002; Reisinger and Mooney, 2010). Exemplar-based approaches represent a word in isolation as a collection of its occurrences or paraphrases, then select only the contextually appropriate exemplars for a given occurrence context (Kintsch, 2001; Erk and Pad´o, 2010). In this paper we focus on the first and third group of approaches, as they do not rely on knowledge of how many word senses (clusters) there should be. A structured vector space model for word meaning in context. In Erk and Pad´o (2008), we proposed the structured vector space model (SVS), which relies solely on syntactic context for computing a context-specific vector. It is a prototypebased model, , and called structured because it explicitly represents argument structure, using multiple vectors to represent each word. Figure 2 (left) illustrates the representation. A</context>
</contexts>
<marker>Kintsch, 2001</marker>
<rawString>W. Kintsch. 2001. Predication. Cognitive Science, 25:173–202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Kintsch</author>
</authors>
<title>Meaning in context. In</title>
<date>2007</date>
<booktitle>Handbook of Latent Semantic Analysis,</booktitle>
<pages>89--105</pages>
<editor>T.K. Landauer, D. McNamara, S. Dennis, and W. Kintsch, editors,</editor>
<publisher>Erlbaum,</publisher>
<location>Mahwah, NJ.</location>
<contexts>
<context position="10572" citStr="Kintsch (2007)" startWordPosition="1745" endWordPosition="1746">e (1-5), often opting for intermediate values of sense applicability. In addition, we tested whether there were groups of senses that always got the same ratings on any given sentence (which would mean that the annotators implicitly used more coarse-grained senses). What we found instead is that the annotators seemed to have mixed and matched senses for the individual occurrences in a dynamic fashion. (C) Describing word meaning without dictionary senses. In lexicography, Kilgarriff (1997) and Hanks (2000) cast doubt on the existence of task-independent, distinct senses. In cognitive science, Kintsch (2007) calls word meaning “fluid and flexible”. And some researchers in lexical semantics have suggested that word meanings lie on a continuum between clear cut cases of ambiguity on the one hand, and on the other hand vagueness where clear cut boundaries do not hold (Tuggy, 1993). There are some psychological studies on whether different senses of a polysemous word are represented separately in the mind or whether there is some joint representation. However, so far the evidence is inconclusive 1) We study the methods and concepts that each writer uses to defend the cogency of legal, deliberative, o</context>
</contexts>
<marker>Kintsch, 2007</marker>
<rawString>W. Kintsch. 2007. Meaning in context. In T.K. Landauer, D. McNamara, S. Dennis, and W. Kintsch, editors, Handbook of Latent Semantic Analysis, pages 89–105. Erlbaum, Mahwah, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kipper</author>
<author>H T Dang</author>
<author>M Palmer</author>
</authors>
<title>Classbased construction of a verb lexicon.</title>
<date>2000</date>
<booktitle>In Proceedings ofAAAI/IAAI.</booktitle>
<contexts>
<context position="25307" citStr="Kipper et al., 2000" startWordPosition="4174" endWordPosition="4177"> questions, in particular the best combination of bag-of-words context and syntactic context as evidence for computing occurrencespecific vector representations. 5 The role of dictionary senses Word meaning models that rely only on individual word usages and their similarities are more flexible than dictionary-based models and make less assumptions. On the other hand, dictionaries offer not just sense lists but also a wealth of information that can be used for inferences. WordNet (Fellbaum, 1998) has relations between words and between synsets, most importantly synonymy and hyponymy. VerbNet (Kipper et al., 2000) specifies semantic properties of a predicate’s arguments, as well as relations between the arguments. In this section we discuss approaches for embedding dictionary senses in a distributional model in a way that supports hypotheses (A) and (B) (graded sense membership, and description of an occurrence through multiple senses) and that supports testing the applicability of dictionary-based inference rules. Mapping dictionary senses to points in vector space. Dictionary senses can be mapped to points in vector space very straightforwardly if we have sense-annotated corpus data. In that case, we</context>
</contexts>
<marker>Kipper, Dang, Palmer, 2000</marker>
<rawString>K. Kipper, H.T. Dang, and M. Palmer. 2000. Classbased construction of a verb lexicon. In Proceedings ofAAAI/IAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Klein</author>
<author>G L Murphy</author>
</authors>
<title>The representation of polysemous words.</title>
<date>2001</date>
<journal>Journal of Memory and Language,</journal>
<pages>45--259</pages>
<contexts>
<context position="11659" citStr="Klein and Murphy, 2001" startWordPosition="1922" endWordPosition="1925">the evidence is inconclusive 1) We study the methods and concepts that each writer uses to defend the cogency of legal, deliberative, or more generally political prudence against explicit or implicit charges that practical thinking is merely a knack or form of cleverness. 2) Eleven CIRA members have been convicted of criminal charges and others are awaiting trial. Figure 1: From (Erk et al., 2009): A sense pair from the USim dataset, for the target charge.n. Annotator judgments: 2,3,4 and varies strongly with the experimental setting. Some studies found evidence for a separate representation (Klein and Murphy, 2001; Pylkkanen et al., 2006). Brown (2008) finds a linear change in semantic similarity effects with sense distance, which could possibly point to a continuous representation of word meaning without clear sense boundaries. But while there is no definitive answer yet on the question of the mental representation of polysemy, a computational model that does not rely on distinct senses has the advantage of making fewer assumptions. It also avoids the tough lexicographic problem mentioned above, of deciding on a best set of senses for a given domain. In the recent USim annotation study (Erk et al., 20</context>
</contexts>
<marker>Klein, Murphy, 2001</marker>
<rawString>D.E. Klein and G.L. Murphy. 2001. The representation of polysemous words. Journal of Memory and Language, 45:259–282.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Lakoff</author>
</authors>
<title>Women, fire, and dangerous things.</title>
<date>1987</date>
<publisher>The University of Chicago Press.</publisher>
<contexts>
<context position="8209" citStr="Lakoff, 1987" startWordPosition="1341" endWordPosition="1342">ory membership (McCloskey and Glucksberg, 1978). However, these results concern mental concepts, which raises the question of the relation between mental concepts and word senses. This relation is discussed in most depth by Murphy (1991; 2002), who argues that while not every human concept is associated with a word, word meanings show many of the same phenomena as concepts in general; word meaning is “made up of pieces of conceptual structure”. In cognitive linguistics there has been much work on word meaning based on models with graded membership and typically effects (Coleman and Kay, 1981; Lakoff, 1987; Cruse, 1986; Taylor, 1989). (B) Multiple senses per occurrence. While most manual word sense annotation efforts allow annotators to assign more than one dictionary sense to an occurrence, this is typically phrased as an exception rather than the default. In the recent WSsim annotation study (Erk et al., 2009), 18 Senses Sentence 1 2 3 4 5 6 7 Annotator This question provoked arguments in America about the 1 4 4 2 1 1 3 Ann. 1 Norton Anthology of Literature by Women, some of the 4 5 4 2 1 1 4 Ann. 2 contents of which were said to have had little value as 1 4 5 1 1 1 1 Ann. 3 literature. Table</context>
</contexts>
<marker>Lakoff, 1987</marker>
<rawString>G. Lakoff. 1987. Women, fire, and dangerous things. The University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Landauer</author>
<author>S Dumais</author>
</authors>
<title>A solution to Platos problem: the latent semantic analysis theory of acquisition, induction, and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<volume>104</volume>
<issue>2</issue>
<contexts>
<context position="3917" citStr="Landauer and Dumais, 1997" startWordPosition="630" endWordPosition="634">o not exist. (C) By focusing on individual occurrences (usages) of a lemma and their degree of similarity, we can model word meaning without recourse to dictionary senses. In this paper, we are going to argue in favor of the use of vector space as a basis for alternative models of word meaning. Vector space models have been used widely to model word sense (Lund 17 Proceedings of the 2010 Workshop on GEometrical Models of Natural Language Semantics, ACL 2010, pages 17–26, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics and Burgess, 1996; Deerwester et al., 1990; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007), their central property being that proximity in space can be used to predict semantic similarity. By viewing word occurrences as points in vector space, we can model word meaning without recourse to senses. An additional advantage of vector space models is that they are also widely used in human concept representation models, yielding many modeling ideas that can be exploited for computational models. In Section 2 we review the evidence that word sense is a tough phenomenon to model, and we lay out findings that support hypotheses (A)-(C).</context>
<context position="14390" citStr="Landauer and Dumais, 1997" startWordPosition="2364" endWordPosition="2367">y a feature vector plus a separate dimension weight vector (Smith et al., 1988; Hampton, 1991; G¨ardenfors, 2004). The features are individually meaningful and interpretable and include sensory and motor features as well as function and taxonomic features. There are several datasets with features elicited from human subjects (McRae et al., 2005; Vigliocco et al., 2004). In computational linguistics, distributional models represent the meaning of a word as a vector in a high-dimensional space whose dimensions characterize the contexts in which the word typically occurs (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007). In the simplest case, the dimensions are context words, and the values are co-occurrence counts. In contrast to spaces used in cognitive science, the dimensions in distributional models are typically not interpretable (though see Almuhareb and Poesio (2005), Baroni et al. (2010)). A central property of distributional models is that proximity in vector space is a predictor of semantic similarity. These models have been used successfully in NLP (Deerwester et al., 1990; Manning et al., 2008), as well as in psychology (Landauer and Dumais, 1</context>
<context position="16180" citStr="Landauer and Dumais, 1997" startWordPosition="2662" endWordPosition="2665"> over all its meanings. There are a few vector space models of meaning in context, though they differ in what it is that they model. One group of models computes a single vector for a whole sentence, encoding both the words and the syntactic structure (Smolensky, 1990; B. Coecke and Clark, 2010). In this case, the dimensionality of the vectors varies with the syntactic complexity of the sentence in question. A second group also computes a single vector for a whole expression, but the vector for a larger expression is a combination of the word vectors for the words occurring in the expression (Landauer and Dumais, 1997; Mitchell and Lapata, 2008). Syntactic structure is not encoded. The resulting vector, of the same dimensionality as the word vectors, is then a combination of the contexts in which the words of the sentence occur. A third group of approaches derives a separate vector for each word in a given sentence (Erk and Pad´o, 2008; Thater et al., 2009; Erk and Pad´o, 2010). While an approach of the second type would derive a single, joint vector for, say, the expression catch a ball, an approach from the third group would derive two vectors, one for the word catch in the context of ball, and one for t</context>
<context position="17529" citStr="Landauer and Dumais, 1997" startWordPosition="2898" endWordPosition="2901">as for a word in isolation. In this paper, we focus on the third type of approaches. Our aim is to study alternatives to dictionary senses for characterizing word meaning. So we need a meaning characterization for each individual word in a given sentence context, rather than a single vector for a larger expression. We can also classify distributional approaches to word meaning in context into prototype- and exemplar-based approaches. Prototype-based approaches first compute a (prototype) vector for each word in isolation, then modify this vector according to the context in a given occurrence (Landauer and Dumais, 1997; Mitchell and Lapata, 2008; Erk and Pad´o, 2008; Thater et al., 2009). Typical methods for combining prototype vectors are addition, component-wise multiplication (introduced by Mitchell and Lap20 Figure 2: From (Erk and Pad´o, 2008): Left: Vector representations for verb catch and noun ball. Lexical information plus selectional preferences. Right: Computing context-specific meaning by combining predicate and argument via selectional preference vectors accuse say claim obj cold baseball drift red golf elegant ... ... ... comp-1 subj catch cold baseball drift obj throw catch organise obj-1 sub</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>T. Landauer and S. Dumais. 1997. A solution to Platos problem: the latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological Review, 104(2):211–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Landes</author>
<author>C Leacock</author>
<author>R Tengi</author>
</authors>
<title>Building semantic concordances.</title>
<date>1998</date>
<booktitle>WordNet: An Electronic Lexical Database. The</booktitle>
<editor>In C. Fellbaum, editor,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="5530" citStr="Landes et al., 1998" startWordPosition="894" endWordPosition="897"> we discuss discusses cognitive models of concept representation and polysemy, following the three hypotheses laid out in the introduction. Word sense assignment. In computational linguistics, the problem of polysemy is typically phrased as one of choosing one best-fitting sense for the given occurrence out of a dictionarydefined sense list. However, this is a hard task both for humans and for machines. With WordNet (Fellbaum, 1998), the electronic lexicon resource that is currently most widely used in computational linguistics, inter-annotator agreement (ITA) lies in the range of 67% to 78% (Landes et al., 1998; Snyder and Palmer, 2004; Mihalcea et al., 2004), and state-of-the-art WSD systems achieve accuracy scores of 73% to 77% (Edmonds and Cotton, 2001; Mihalcea et al., 2004). This problem is not specific to WordNet: Analyses with the HECTOR dictionary led to similar numbers (Kilgarriff and Rosenzweig, 2000). Sense granularity has been suggested as a reason for the difficulty of the task (Palmer et al., 2007). And in fact, the use of more coarse-grained senses leads to greatly ITA as well as WSD accuracy, with about a 10% improvement for either measure (Palmer et al., 2007; Pradhan et al., 2007).</context>
</contexts>
<marker>Landes, Leacock, Tengi, 1998</marker>
<rawString>S. Landes, C. Leacock, and R. Tengi. 1998. Building semantic concordances. In C. Fellbaum, editor, WordNet: An Electronic Lexical Database. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Lowe</author>
<author>S McDonald</author>
</authors>
<title>The direct route: Mediated priming in semantic space.</title>
<date>2000</date>
<booktitle>In Proceedings of the Cognitive Science Society,</booktitle>
<pages>675--680</pages>
<contexts>
<context position="15018" citStr="Lowe and McDonald, 2000" startWordPosition="2464" endWordPosition="2467">lgren and Karlgren, 2005; Pad´o and Lapata, 2007). In the simplest case, the dimensions are context words, and the values are co-occurrence counts. In contrast to spaces used in cognitive science, the dimensions in distributional models are typically not interpretable (though see Almuhareb and Poesio (2005), Baroni et al. (2010)). A central property of distributional models is that proximity in vector space is a predictor of semantic similarity. These models have been used successfully in NLP (Deerwester et al., 1990; Manning et al., 2008), as well as in psychology (Landauer and Dumais, 1997; Lowe and McDonald, 2000; McDonald and Ramscar, 2001). 4 Vector space models of word meaning in context If we want to represent word meaning through individual usages and their similarity only, without the use of dictionary senses (along hypothesis (C)), distributional models are an obvious choice, if we can just represent each individual usage as a point in space. However, vector space models have mostly been used to represent the meaning of a word in isolation: The vector for a word is computed by summing over all its corpus occurrences, thereby summing over all its meanings. There are a few vector space models of </context>
</contexts>
<marker>Lowe, McDonald, 2000</marker>
<rawString>W. Lowe and S. McDonald. 2000. The direct route: Mediated priming in semantic space. In Proceedings of the Cognitive Science Society, pages 675– 680.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Lund</author>
<author>C Burgess</author>
</authors>
<title>Producing high-dimensional semantic spaces from lexical cooccurrence.</title>
<date>1996</date>
<journal>Behavior Research Methods, Instruments, and Computers,</journal>
<pages>28--203</pages>
<contexts>
<context position="14363" citStr="Lund and Burgess, 1996" startWordPosition="2360" endWordPosition="2363">e, often characterized by a feature vector plus a separate dimension weight vector (Smith et al., 1988; Hampton, 1991; G¨ardenfors, 2004). The features are individually meaningful and interpretable and include sensory and motor features as well as function and taxonomic features. There are several datasets with features elicited from human subjects (McRae et al., 2005; Vigliocco et al., 2004). In computational linguistics, distributional models represent the meaning of a word as a vector in a high-dimensional space whose dimensions characterize the contexts in which the word typically occurs (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007). In the simplest case, the dimensions are context words, and the values are co-occurrence counts. In contrast to spaces used in cognitive science, the dimensions in distributional models are typically not interpretable (though see Almuhareb and Poesio (2005), Baroni et al. (2010)). A central property of distributional models is that proximity in vector space is a predictor of semantic similarity. These models have been used successfully in NLP (Deerwester et al., 1990; Manning et al., 2008), as well as in psychol</context>
</contexts>
<marker>Lund, Burgess, 1996</marker>
<rawString>K. Lund and C. Burgess. 1996. Producing high-dimensional semantic spaces from lexical cooccurrence. Behavior Research Methods, Instruments, and Computers, 28:203—208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>P Raghavan</author>
<author>H Sch¨utze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press.</publisher>
<marker>Manning, Raghavan, Sch¨utze, 2008</marker>
<rawString>C. D. Manning, P. Raghavan, and H. Sch¨utze. 2008. Introduction to Information Retrieval. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McCarthy</author>
<author>R Navigli</author>
</authors>
<title>The English lexical substitution task.</title>
<date>2009</date>
<journal>Language Resources and Evaluation,</journal>
<booktitle>Special Issue on Computational Semantic Analysis of Language: SemEval2007 and Beyond.</booktitle>
<volume>43</volume>
<issue>2</issue>
<contexts>
<context position="7152" citStr="McCarthy and Navigli, 2009" startWordPosition="1167" endWordPosition="1170">distinct enough for consistent annotation. A recent analysis of factors influencing ITA differences between lemmas (Passonneau et al., 2010) found three main factors: sense concreteness, specificity of the context in which a target word occurs, and similarity between senses. It is interesting to note that only one of those factors, the third, can be addressed through a change of dictionary. More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al., 2004), or to work directly with paraphrases (McCarthy and Navigli, 2009). (A) Graded sense membership. Research on the human concept representation (Murphy, 2002; Hampton, 2007) shows that categories in the human mind are not simply sets with clear-cut boundaries. Some items are perceived as more typical than others (Rosch, 1975; Rosch and Mervis, 1975). Also, some items are clear members, others are rated as borderline (Hampton, 1979). On borderline items, people are more likely to change their mind about category membership (McCloskey and Glucksberg, 1978). However, these results concern mental concepts, which raises the question of the relation between mental c</context>
<context position="21832" citStr="McCarthy and Navigli, 2009" startWordPosition="3601" endWordPosition="3605">the similarity (measured, for example, using Cosine) of the context-specific vector of catch with the lexical vector of contract: The more similar the vectors, the higher the predicted appropriateness of the paraphrase. We evaluated SVS on two datasets. The first is a tightly controlled psycholinguistic dataset of subject/verb pairs with paraphrases for the verbs only (Mitchell and Lapata, 2008). The other is the Lexical Substitution dataset, which has annotator-generated paraphrases for target words in a larger sentential context and which is thus closer to typical NLP application scenarios (McCarthy and Navigli, 2009). SVS showed comparable performance to the model by Mitchell and Lapata (2008) on the 21 former dataset, and outperformed the Mitchell and Lapata model on the latter. One obvious extension is to use all available syntactic context, instead of focusing on a single syntactic neighbor. We found no improvement on SVS in a straightforward extension to additional syntactic context items (Erk and Pad´o, 2009). However, Thater et al. (2009) did achieve better performance with a different model that used all syntactic context. Taking larger context into account in an exemplar-based model. But even if w</context>
</contexts>
<marker>McCarthy, Navigli, 2009</marker>
<rawString>D. McCarthy and R. Navigli. 2009. The English lexical substitution task. Language Resources and Evaluation, 43(2):139–159. Special Issue on Computational Semantic Analysis of Language: SemEval2007 and Beyond.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McCarthy</author>
<author>R Koeling</author>
<author>J Weeds</author>
<author>J Carroll</author>
</authors>
<title>Finding predominant senses in untagged text.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Barcelona.</location>
<contexts>
<context position="7085" citStr="McCarthy et al., 2004" startWordPosition="1155" endWordPosition="1159">t the meaning of these words may not be separable into senses distinct enough for consistent annotation. A recent analysis of factors influencing ITA differences between lemmas (Passonneau et al., 2010) found three main factors: sense concreteness, specificity of the context in which a target word occurs, and similarity between senses. It is interesting to note that only one of those factors, the third, can be addressed through a change of dictionary. More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al., 2004), or to work directly with paraphrases (McCarthy and Navigli, 2009). (A) Graded sense membership. Research on the human concept representation (Murphy, 2002; Hampton, 2007) shows that categories in the human mind are not simply sets with clear-cut boundaries. Some items are perceived as more typical than others (Rosch, 1975; Rosch and Mervis, 1975). Also, some items are clear members, others are rated as borderline (Hampton, 1979). On borderline items, people are more likely to change their mind about category membership (McCloskey and Glucksberg, 1978). However, these results concern mental c</context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2004</marker>
<rawString>D. McCarthy, R. Koeling, J. Weeds, and J. Carroll. 2004. Finding predominant senses in untagged text. In Proceedings of ACL, Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M McCloskey</author>
<author>S Glucksberg</author>
</authors>
<title>Natural categories: Well defined or fuzzy sets?</title>
<date>1978</date>
<journal>Memory &amp; Cognition,</journal>
<pages>6--462</pages>
<contexts>
<context position="7644" citStr="McCloskey and Glucksberg, 1978" startWordPosition="1243" endWordPosition="1246"> determining predominant sense in a given domain (McCarthy et al., 2004), or to work directly with paraphrases (McCarthy and Navigli, 2009). (A) Graded sense membership. Research on the human concept representation (Murphy, 2002; Hampton, 2007) shows that categories in the human mind are not simply sets with clear-cut boundaries. Some items are perceived as more typical than others (Rosch, 1975; Rosch and Mervis, 1975). Also, some items are clear members, others are rated as borderline (Hampton, 1979). On borderline items, people are more likely to change their mind about category membership (McCloskey and Glucksberg, 1978). However, these results concern mental concepts, which raises the question of the relation between mental concepts and word senses. This relation is discussed in most depth by Murphy (1991; 2002), who argues that while not every human concept is associated with a word, word meanings show many of the same phenomena as concepts in general; word meaning is “made up of pieces of conceptual structure”. In cognitive linguistics there has been much work on word meaning based on models with graded membership and typically effects (Coleman and Kay, 1981; Lakoff, 1987; Cruse, 1986; Taylor, 1989). (B) M</context>
</contexts>
<marker>McCloskey, Glucksberg, 1978</marker>
<rawString>M. McCloskey and S. Glucksberg. 1978. Natural categories: Well defined or fuzzy sets? Memory &amp; Cognition, 6:462–472.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S McDonald</author>
<author>M Ramscar</author>
</authors>
<title>Testing the distributional hypothesis: The influence of context on judgements of semantic similarity.</title>
<date>2001</date>
<booktitle>In Proceedings of the Cognitive Science Society,</booktitle>
<pages>611--616</pages>
<contexts>
<context position="15047" citStr="McDonald and Ramscar, 2001" startWordPosition="2468" endWordPosition="2471"> Pad´o and Lapata, 2007). In the simplest case, the dimensions are context words, and the values are co-occurrence counts. In contrast to spaces used in cognitive science, the dimensions in distributional models are typically not interpretable (though see Almuhareb and Poesio (2005), Baroni et al. (2010)). A central property of distributional models is that proximity in vector space is a predictor of semantic similarity. These models have been used successfully in NLP (Deerwester et al., 1990; Manning et al., 2008), as well as in psychology (Landauer and Dumais, 1997; Lowe and McDonald, 2000; McDonald and Ramscar, 2001). 4 Vector space models of word meaning in context If we want to represent word meaning through individual usages and their similarity only, without the use of dictionary senses (along hypothesis (C)), distributional models are an obvious choice, if we can just represent each individual usage as a point in space. However, vector space models have mostly been used to represent the meaning of a word in isolation: The vector for a word is computed by summing over all its corpus occurrences, thereby summing over all its meanings. There are a few vector space models of meaning in context, though th</context>
</contexts>
<marker>McDonald, Ramscar, 2001</marker>
<rawString>S. McDonald and M. Ramscar. 2001. Testing the distributional hypothesis: The influence of context on judgements of semantic similarity. In Proceedings of the Cognitive Science Society, pages 611–616.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K McRae</author>
<author>G S Cree</author>
<author>M S Seidenberg</author>
<author>C McNorgan</author>
</authors>
<title>Semantic feature production norms for a large set of living and nonliving things.</title>
<date>2005</date>
<journal>Behavior Research Methods,</journal>
<volume>37</volume>
<issue>4</issue>
<contexts>
<context position="14111" citStr="McRae et al., 2005" startWordPosition="2321" endWordPosition="2324">eviously seen exemplars and compute degree of category membership as similarity to stored exemplars. Both prototypes and exemplars are typically represented as feature vectors. Many models represent a concept as a region rather than a point in space, often characterized by a feature vector plus a separate dimension weight vector (Smith et al., 1988; Hampton, 1991; G¨ardenfors, 2004). The features are individually meaningful and interpretable and include sensory and motor features as well as function and taxonomic features. There are several datasets with features elicited from human subjects (McRae et al., 2005; Vigliocco et al., 2004). In computational linguistics, distributional models represent the meaning of a word as a vector in a high-dimensional space whose dimensions characterize the contexts in which the word typically occurs (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007). In the simplest case, the dimensions are context words, and the values are co-occurrence counts. In contrast to spaces used in cognitive science, the dimensions in distributional models are typically not interpretable (though see Almuhareb and Poesio (2005), Baroni</context>
</contexts>
<marker>McRae, Cree, Seidenberg, McNorgan, 2005</marker>
<rawString>K. McRae, G. S. Cree, M. S. Seidenberg, and C. McNorgan. 2005. Semantic feature production norms for a large set of living and nonliving things. Behavior Research Methods, 37(4):547–559.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L Medin</author>
<author>M M Schaffer</author>
</authors>
<title>Context theory of classification learning.</title>
<date>1978</date>
<journal>Psychological Review,</journal>
<pages>85--207</pages>
<contexts>
<context position="13402" citStr="Medin and Schaffer, 1978" startWordPosition="2205" endWordPosition="2208"> Furthermore, there was a strong correlation on judgments given with and without the use of dictionary senses (USim versus WSsim) for the same data. 19 3 Vector space models of word meaning in isolation This section gives a brief overview of the use of vector spaces to model concepts and word meaning in cognition and computational linguistics. In two of the current main theories of concept representation, feature vectors play a prominent role. Prototype theory (Hampton, 1979; Smith and Medin, 1981) models degree of category membership through similarity to a single prototype. Exemplar models (Medin and Schaffer, 1978; Nosofsky, 1992; Nosofsky and Palmeri, 1997) represent a concept as a collection of all previously seen exemplars and compute degree of category membership as similarity to stored exemplars. Both prototypes and exemplars are typically represented as feature vectors. Many models represent a concept as a region rather than a point in space, often characterized by a feature vector plus a separate dimension weight vector (Smith et al., 1988; Hampton, 1991; G¨ardenfors, 2004). The features are individually meaningful and interpretable and include sensory and motor features as well as function and </context>
</contexts>
<marker>Medin, Schaffer, 1978</marker>
<rawString>D. L. Medin and M. M. Schaffer. 1978. Context theory of classification learning. Psychological Review, 85:207–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>T Chklovski</author>
<author>A Kilgariff</author>
</authors>
<title>The Senseval-3 English lexical sample task.</title>
<date>2004</date>
<booktitle>In Proceedings of SensEval-3,</booktitle>
<location>Barcelona.</location>
<contexts>
<context position="1217" citStr="Mihalcea et al., 2004" startWordPosition="183" endWordPosition="186">an occurrence can activate multiple senses to different degrees. Or move away from dictionary senses completely, and only model similarities between individual word usages. We argue that distributional models provide a flexible framework for experimenting with alternative models of word meanings, and discuss example models. 1 Introduction Word sense disambiguation (WSD) is one of the oldest problems in computational linguistics (Weaver, 1949) and still remains challenging today. State-of-the-art performance on WSD for WordNet senses is at only around 70-80% accuracy (Edmonds and Cotton, 2001; Mihalcea et al., 2004). The use of coarse-grained sense groups (Palmer et al., 2007) has led to considerable advances in WSD performance, with accuracies of around 90% (Pradhan et al., 2007). But this figure averages over lemmas, and the problem remains that while WSD works well for some lemmas, others continue to be tough. In WSD, polysemy is typically modeled through a list of dictionary senses thought to be mutually disjoint, such that each occurrence of a word is characterized through one best-fitting dictionary sense. Accordingly, WSD is typically framed as a classification task. Interestingly, the task of ass</context>
<context position="5579" citStr="Mihalcea et al., 2004" startWordPosition="902" endWordPosition="906">ept representation and polysemy, following the three hypotheses laid out in the introduction. Word sense assignment. In computational linguistics, the problem of polysemy is typically phrased as one of choosing one best-fitting sense for the given occurrence out of a dictionarydefined sense list. However, this is a hard task both for humans and for machines. With WordNet (Fellbaum, 1998), the electronic lexicon resource that is currently most widely used in computational linguistics, inter-annotator agreement (ITA) lies in the range of 67% to 78% (Landes et al., 1998; Snyder and Palmer, 2004; Mihalcea et al., 2004), and state-of-the-art WSD systems achieve accuracy scores of 73% to 77% (Edmonds and Cotton, 2001; Mihalcea et al., 2004). This problem is not specific to WordNet: Analyses with the HECTOR dictionary led to similar numbers (Kilgarriff and Rosenzweig, 2000). Sense granularity has been suggested as a reason for the difficulty of the task (Palmer et al., 2007). And in fact, the use of more coarse-grained senses leads to greatly ITA as well as WSD accuracy, with about a 10% improvement for either measure (Palmer et al., 2007; Pradhan et al., 2007). In OntoNotes (Hovy et al., 2006), an ITA of 90% </context>
</contexts>
<marker>Mihalcea, Chklovski, Kilgariff, 2004</marker>
<rawString>R. Mihalcea, T. Chklovski, and A. Kilgariff. 2004. The Senseval-3 English lexical sample task. In Proceedings of SensEval-3, Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Mitchell</author>
<author>M Lapata</author>
</authors>
<title>Vector-based models of semantic composition.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Columbus, OH.</location>
<contexts>
<context position="16208" citStr="Mitchell and Lapata, 2008" startWordPosition="2666" endWordPosition="2669">re are a few vector space models of meaning in context, though they differ in what it is that they model. One group of models computes a single vector for a whole sentence, encoding both the words and the syntactic structure (Smolensky, 1990; B. Coecke and Clark, 2010). In this case, the dimensionality of the vectors varies with the syntactic complexity of the sentence in question. A second group also computes a single vector for a whole expression, but the vector for a larger expression is a combination of the word vectors for the words occurring in the expression (Landauer and Dumais, 1997; Mitchell and Lapata, 2008). Syntactic structure is not encoded. The resulting vector, of the same dimensionality as the word vectors, is then a combination of the contexts in which the words of the sentence occur. A third group of approaches derives a separate vector for each word in a given sentence (Erk and Pad´o, 2008; Thater et al., 2009; Erk and Pad´o, 2010). While an approach of the second type would derive a single, joint vector for, say, the expression catch a ball, an approach from the third group would derive two vectors, one for the word catch in the context of ball, and one for the word ball in the context </context>
<context position="17556" citStr="Mitchell and Lapata, 2008" startWordPosition="2902" endWordPosition="2905"> In this paper, we focus on the third type of approaches. Our aim is to study alternatives to dictionary senses for characterizing word meaning. So we need a meaning characterization for each individual word in a given sentence context, rather than a single vector for a larger expression. We can also classify distributional approaches to word meaning in context into prototype- and exemplar-based approaches. Prototype-based approaches first compute a (prototype) vector for each word in isolation, then modify this vector according to the context in a given occurrence (Landauer and Dumais, 1997; Mitchell and Lapata, 2008; Erk and Pad´o, 2008; Thater et al., 2009). Typical methods for combining prototype vectors are addition, component-wise multiplication (introduced by Mitchell and Lap20 Figure 2: From (Erk and Pad´o, 2008): Left: Vector representations for verb catch and noun ball. Lexical information plus selectional preferences. Right: Computing context-specific meaning by combining predicate and argument via selectional preference vectors accuse say claim obj cold baseball drift red golf elegant ... ... ... comp-1 subj catch cold baseball drift obj throw catch organise obj-1 subj-1 ball mod ... whirl fly </context>
<context position="21603" citStr="Mitchell and Lapata, 2008" startWordPosition="3566" endWordPosition="3569"> contract is an appropriate paraphrase for catch in the context John caught the flu, but it is not an appropriate paraphrase in the context John caught a butterfly. A vector space model can predict paraphrase appropriateness as the similarity (measured, for example, using Cosine) of the context-specific vector of catch with the lexical vector of contract: The more similar the vectors, the higher the predicted appropriateness of the paraphrase. We evaluated SVS on two datasets. The first is a tightly controlled psycholinguistic dataset of subject/verb pairs with paraphrases for the verbs only (Mitchell and Lapata, 2008). The other is the Lexical Substitution dataset, which has annotator-generated paraphrases for target words in a larger sentential context and which is thus closer to typical NLP application scenarios (McCarthy and Navigli, 2009). SVS showed comparable performance to the model by Mitchell and Lapata (2008) on the 21 former dataset, and outperformed the Mitchell and Lapata model on the latter. One obvious extension is to use all available syntactic context, instead of focusing on a single syntactic neighbor. We found no improvement on SVS in a straightforward extension to additional syntactic c</context>
<context position="26896" citStr="Mitchell and Lapata, 2008" startWordPosition="4429" endWordPosition="4432">udgments. In comparison with an approach that uses the confidence levels of a standard WSD model as predictions, the vector space model shows higher recall but lower precision – for definitions of precision and recall that are adapted to the graded case. 22 Another way of putting the findings is to say that the WSD confidence levels tend to under-estimate sense applicability, while the vector space model tends to over-estimate it. Attachment sites for inference rules. As discussed above, vector space models for word meaning in context are typically evaluated on paraphrase applicability tasks (Mitchell and Lapata, 2008; Erk and Pad´o, 2008; Erk and Pad´o, 2009; Thater et al., 2009). They predict the applicability of a paraphrase like (2) based on the similarity between a context-specific vector for the lemma (here, catch) and a context-independent vector for the paraphrase. (in this case, contract). X catch Y —* X contract Y (2) Another way of looking at this is to consider the inference rule (2) to be attached to a point in space, namely the vector for contract, and to trigger the inference rule for an occurrence of catch if it is close enough to the attachment site. If we know the WordNet sense of contrac</context>
</contexts>
<marker>Mitchell, Lapata, 2008</marker>
<rawString>J. Mitchell and M. Lapata. 2008. Vector-based models of semantic composition. In Proceedings of ACL, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mitchell</author>
<author>S Shinkareva</author>
<author>A Carlson</author>
<author>K Chang</author>
<author>R Mason V Malave</author>
<author>M Just</author>
</authors>
<title>Predicting human brain activity associated with the meanings of nouns.</title>
<date>2008</date>
<journal>Science,</journal>
<volume>320</volume>
<issue>5880</issue>
<contexts>
<context position="31055" citStr="Mitchell et al. (2008)" startWordPosition="5127" endWordPosition="5130">nteresting ideas in these models that have not yet been used (much) in computational models of word meaning. One of the most exciting ones, perhaps, is that cognitive models often have interpretable dimensions. While dimensions of distributional models are usually not individually interpretable, there are some first models (Almuhareb and Poesio, 2005; Baroni et al., 2010) that use patterns to extract meaningful dimensions from corpus data. This offers many new perspectives: For which tasks can we improve performance by selecting dimensions that are meaningful specifically for that task (as in Mitchell et al. (2008))? Can interpretable dimensions be used for inferences? And, when we are computing vector space representations for word meaning in context, is it possible to select meaningful dimensions that are appropriate for a given context? 23 Acknowledgements. This work was supported in part by National Science Foundation grant IIS0845925, and by a Morris Memorial Grant from the New York Community Trust. K. Erk, D. McCarthy, and N. Gaylord. 2009. Investigations on word senses and word usages. In Proceedings of ACL, Singapore. Katrin Erk. 2009. Representing words as regions in vector space. In Proceeding</context>
</contexts>
<marker>Mitchell, Shinkareva, Carlson, Chang, Malave, Just, 2008</marker>
<rawString>T. Mitchell, S. Shinkareva, A. Carlson, K. Chang, V.Malave, R. Mason, and M. Just. 2008. Predicting human brain activity associated with the meanings of nouns. Science, 320(5880):1191–1195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G L Murphy</author>
</authors>
<title>Meaning and concepts.</title>
<date>1991</date>
<editor>In P. Schwanenflugel, editor,</editor>
<contexts>
<context position="7833" citStr="Murphy (1991" startWordPosition="1276" endWordPosition="1277">tation (Murphy, 2002; Hampton, 2007) shows that categories in the human mind are not simply sets with clear-cut boundaries. Some items are perceived as more typical than others (Rosch, 1975; Rosch and Mervis, 1975). Also, some items are clear members, others are rated as borderline (Hampton, 1979). On borderline items, people are more likely to change their mind about category membership (McCloskey and Glucksberg, 1978). However, these results concern mental concepts, which raises the question of the relation between mental concepts and word senses. This relation is discussed in most depth by Murphy (1991; 2002), who argues that while not every human concept is associated with a word, word meanings show many of the same phenomena as concepts in general; word meaning is “made up of pieces of conceptual structure”. In cognitive linguistics there has been much work on word meaning based on models with graded membership and typically effects (Coleman and Kay, 1981; Lakoff, 1987; Cruse, 1986; Taylor, 1989). (B) Multiple senses per occurrence. While most manual word sense annotation efforts allow annotators to assign more than one dictionary sense to an occurrence, this is typically phrased as an ex</context>
</contexts>
<marker>Murphy, 1991</marker>
<rawString>G. L. Murphy. 1991. Meaning and concepts. In P. Schwanenflugel, editor, The psychology of word meanings. Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G L Murphy</author>
</authors>
<title>The Big Book of Concepts.</title>
<date>2002</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7241" citStr="Murphy, 2002" startWordPosition="1181" endWordPosition="1182">een lemmas (Passonneau et al., 2010) found three main factors: sense concreteness, specificity of the context in which a target word occurs, and similarity between senses. It is interesting to note that only one of those factors, the third, can be addressed through a change of dictionary. More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al., 2004), or to work directly with paraphrases (McCarthy and Navigli, 2009). (A) Graded sense membership. Research on the human concept representation (Murphy, 2002; Hampton, 2007) shows that categories in the human mind are not simply sets with clear-cut boundaries. Some items are perceived as more typical than others (Rosch, 1975; Rosch and Mervis, 1975). Also, some items are clear members, others are rated as borderline (Hampton, 1979). On borderline items, people are more likely to change their mind about category membership (McCloskey and Glucksberg, 1978). However, these results concern mental concepts, which raises the question of the relation between mental concepts and word senses. This relation is discussed in most depth by Murphy (1991; 2002),</context>
</contexts>
<marker>Murphy, 2002</marker>
<rawString>G. L. Murphy. 2002. The Big Book of Concepts. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Nosofsky</author>
<author>T J Palmeri</author>
</authors>
<title>An exemplarbased random walk model of speeded classification.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<volume>104</volume>
<issue>2</issue>
<contexts>
<context position="13447" citStr="Nosofsky and Palmeri, 1997" startWordPosition="2212" endWordPosition="2215">on on judgments given with and without the use of dictionary senses (USim versus WSsim) for the same data. 19 3 Vector space models of word meaning in isolation This section gives a brief overview of the use of vector spaces to model concepts and word meaning in cognition and computational linguistics. In two of the current main theories of concept representation, feature vectors play a prominent role. Prototype theory (Hampton, 1979; Smith and Medin, 1981) models degree of category membership through similarity to a single prototype. Exemplar models (Medin and Schaffer, 1978; Nosofsky, 1992; Nosofsky and Palmeri, 1997) represent a concept as a collection of all previously seen exemplars and compute degree of category membership as similarity to stored exemplars. Both prototypes and exemplars are typically represented as feature vectors. Many models represent a concept as a region rather than a point in space, often characterized by a feature vector plus a separate dimension weight vector (Smith et al., 1988; Hampton, 1991; G¨ardenfors, 2004). The features are individually meaningful and interpretable and include sensory and motor features as well as function and taxonomic features. There are several dataset</context>
</contexts>
<marker>Nosofsky, Palmeri, 1997</marker>
<rawString>R. M. Nosofsky and T. J. Palmeri. 1997. An exemplarbased random walk model of speeded classification. Psychological Review, 104(2):266–300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Nosofsky</author>
</authors>
<title>Exemplars, prototypes, and similarity rules. In</title>
<date>1992</date>
<booktitle>From learning theory to connectionist theory: essays in honor of W.K. Estes,</booktitle>
<volume>1</volume>
<pages>149--168</pages>
<editor>A. Healy, S. Kosslyn, and R. Shiffrin, editors,</editor>
<publisher>Erlbaum,</publisher>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="13418" citStr="Nosofsky, 1992" startWordPosition="2209" endWordPosition="2211">strong correlation on judgments given with and without the use of dictionary senses (USim versus WSsim) for the same data. 19 3 Vector space models of word meaning in isolation This section gives a brief overview of the use of vector spaces to model concepts and word meaning in cognition and computational linguistics. In two of the current main theories of concept representation, feature vectors play a prominent role. Prototype theory (Hampton, 1979; Smith and Medin, 1981) models degree of category membership through similarity to a single prototype. Exemplar models (Medin and Schaffer, 1978; Nosofsky, 1992; Nosofsky and Palmeri, 1997) represent a concept as a collection of all previously seen exemplars and compute degree of category membership as similarity to stored exemplars. Both prototypes and exemplars are typically represented as feature vectors. Many models represent a concept as a region rather than a point in space, often characterized by a feature vector plus a separate dimension weight vector (Smith et al., 1988; Hampton, 1991; G¨ardenfors, 2004). The features are individually meaningful and interpretable and include sensory and motor features as well as function and taxonomic featur</context>
</contexts>
<marker>Nosofsky, 1992</marker>
<rawString>R. M. Nosofsky. 1992. Exemplars, prototypes, and similarity rules. In A. Healy, S. Kosslyn, and R. Shiffrin, editors, From learning theory to connectionist theory: essays in honor of W.K. Estes, volume 1, pages 149–168. Erlbaum, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pad´o</author>
<author>M Lapata</author>
</authors>
<title>Dependency-based construction of semantic space models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<marker>Pad´o, Lapata, 2007</marker>
<rawString>S. Pad´o and M. Lapata. 2007. Dependency-based construction of semantic space models. Computational Linguistics, 33(2):161–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>H Trang Dang</author>
<author>C Fellbaum</author>
</authors>
<title>Making fine-grained and coarse-grained sense distinctions, both manually and automatically.</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<pages>13--137</pages>
<contexts>
<context position="1279" citStr="Palmer et al., 2007" startWordPosition="193" endWordPosition="196"> Or move away from dictionary senses completely, and only model similarities between individual word usages. We argue that distributional models provide a flexible framework for experimenting with alternative models of word meanings, and discuss example models. 1 Introduction Word sense disambiguation (WSD) is one of the oldest problems in computational linguistics (Weaver, 1949) and still remains challenging today. State-of-the-art performance on WSD for WordNet senses is at only around 70-80% accuracy (Edmonds and Cotton, 2001; Mihalcea et al., 2004). The use of coarse-grained sense groups (Palmer et al., 2007) has led to considerable advances in WSD performance, with accuracies of around 90% (Pradhan et al., 2007). But this figure averages over lemmas, and the problem remains that while WSD works well for some lemmas, others continue to be tough. In WSD, polysemy is typically modeled through a list of dictionary senses thought to be mutually disjoint, such that each occurrence of a word is characterized through one best-fitting dictionary sense. Accordingly, WSD is typically framed as a classification task. Interestingly, the task of assigning a single best word sense is very hard for human annotat</context>
<context position="3020" citStr="Palmer et al. (2007)" startWordPosition="484" endWordPosition="487">ow graded membership, and there are typical members as well as borderline cases (Rosch, 1975; Hampton, 2007). Accordingly, (A) we will suggest that word meaning may be better modeled using a graded notion of sense membership than through concepts with hard boundaries. Second, even if senses have soft boundaries, the question remains of whether they are disjoint. (B) We will argue in favor of a framework where multiple senses may apply to a single occurrence, to different degrees. This can be viewed as a dynamical grouping of senses for each occurrence, in contrast to static sense groups as in Palmer et al. (2007). The first two hypotheses still rely on an existing sense list. However, there is no universal agreement across dictionaries and across tasks on the number of senses that words have (Hanks, 2000). Kilgarriff (1997) even argues that general, task-independent word senses do not exist. (C) By focusing on individual occurrences (usages) of a lemma and their degree of similarity, we can model word meaning without recourse to dictionary senses. In this paper, we are going to argue in favor of the use of vector space as a basis for alternative models of word meaning. Vector space models have been us</context>
<context position="5939" citStr="Palmer et al., 2007" startWordPosition="964" endWordPosition="967">ith WordNet (Fellbaum, 1998), the electronic lexicon resource that is currently most widely used in computational linguistics, inter-annotator agreement (ITA) lies in the range of 67% to 78% (Landes et al., 1998; Snyder and Palmer, 2004; Mihalcea et al., 2004), and state-of-the-art WSD systems achieve accuracy scores of 73% to 77% (Edmonds and Cotton, 2001; Mihalcea et al., 2004). This problem is not specific to WordNet: Analyses with the HECTOR dictionary led to similar numbers (Kilgarriff and Rosenzweig, 2000). Sense granularity has been suggested as a reason for the difficulty of the task (Palmer et al., 2007). And in fact, the use of more coarse-grained senses leads to greatly ITA as well as WSD accuracy, with about a 10% improvement for either measure (Palmer et al., 2007; Pradhan et al., 2007). In OntoNotes (Hovy et al., 2006), an ITA of 90% is used as the criterion for the construction of coarsegrained sense distinctions. However, intriguingly, for some high-frequency lemmas such as leave this ITA threshold is not reached even after multiple re-partitionings of the semantic space (Chen and Palmer, 2009) – indicating that the meaning of these words may not be separable into senses distinct enoug</context>
</contexts>
<marker>Palmer, Dang, Fellbaum, 2007</marker>
<rawString>M. Palmer, H. Trang Dang, and C. Fellbaum. 2007. Making fine-grained and coarse-grained sense distinctions, both manually and automatically. Natural Language Engineering, 13:137–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
<author>D Lin</author>
</authors>
<title>Discovering word senses from text.</title>
<date>2002</date>
<booktitle>In Proceedings of KDD,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="18432" citStr="Pantel and Lin, 2002" startWordPosition="3031" endWordPosition="3034"> noun ball. Lexical information plus selectional preferences. Right: Computing context-specific meaning by combining predicate and argument via selectional preference vectors accuse say claim obj cold baseball drift red golf elegant ... ... ... comp-1 subj catch cold baseball drift obj throw catch organise obj-1 subj-1 ball mod ... whirl fly provide subj-1 throw catch organise obj-1 ball mod comp-1 catch subj he fielder dog ata (2008)), and component-wise minimum. Then there are multiple prototype approaches that statically cluster synonyms or occurrences to induce word senses(Sch¨utze, 1998; Pantel and Lin, 2002; Reisinger and Mooney, 2010). Exemplar-based approaches represent a word in isolation as a collection of its occurrences or paraphrases, then select only the contextually appropriate exemplars for a given occurrence context (Kintsch, 2001; Erk and Pad´o, 2010). In this paper we focus on the first and third group of approaches, as they do not rely on knowledge of how many word senses (clusters) there should be. A structured vector space model for word meaning in context. In Erk and Pad´o (2008), we proposed the structured vector space model (SVS), which relies solely on syntactic context for c</context>
</contexts>
<marker>Pantel, Lin, 2002</marker>
<rawString>P. Pantel and D. Lin. 2002. Discovering word senses from text. In Proceedings of KDD, Edmonton, Canada.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R Passonneau</author>
<author>A Salleb-Aouissi</author>
<author>V Bhardwaj</author>
</authors>
<location>and</location>
<marker>Passonneau, Salleb-Aouissi, Bhardwaj, </marker>
<rawString>R. Passonneau, A. Salleb-Aouissi, V. Bhardwaj, and</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
</authors>
<title>Word sense annotation of polysemous words by multiple annotators.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC-7,</booktitle>
<location>Valleta,</location>
<marker>Ide, 2010</marker>
<rawString>N. Ide. 2010. Word sense annotation of polysemous words by multiple annotators. In Proceedings of LREC-7, Valleta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pradhan</author>
<author>E Loper</author>
<author>D Dligach</author>
<author>M Palmer</author>
</authors>
<title>Semeval-2007 task 17: English lexical sample, SRL and all words.</title>
<date>2007</date>
<booktitle>In Proceedings of SemEval¡,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="1385" citStr="Pradhan et al., 2007" startWordPosition="212" endWordPosition="215">es. We argue that distributional models provide a flexible framework for experimenting with alternative models of word meanings, and discuss example models. 1 Introduction Word sense disambiguation (WSD) is one of the oldest problems in computational linguistics (Weaver, 1949) and still remains challenging today. State-of-the-art performance on WSD for WordNet senses is at only around 70-80% accuracy (Edmonds and Cotton, 2001; Mihalcea et al., 2004). The use of coarse-grained sense groups (Palmer et al., 2007) has led to considerable advances in WSD performance, with accuracies of around 90% (Pradhan et al., 2007). But this figure averages over lemmas, and the problem remains that while WSD works well for some lemmas, others continue to be tough. In WSD, polysemy is typically modeled through a list of dictionary senses thought to be mutually disjoint, such that each occurrence of a word is characterized through one best-fitting dictionary sense. Accordingly, WSD is typically framed as a classification task. Interestingly, the task of assigning a single best word sense is very hard for human annotators, not just machines (Kilgarriff and Rosenzweig, 2000). In this paper we advocate the exploration of alt</context>
<context position="6129" citStr="Pradhan et al., 2007" startWordPosition="999" endWordPosition="1002">% (Landes et al., 1998; Snyder and Palmer, 2004; Mihalcea et al., 2004), and state-of-the-art WSD systems achieve accuracy scores of 73% to 77% (Edmonds and Cotton, 2001; Mihalcea et al., 2004). This problem is not specific to WordNet: Analyses with the HECTOR dictionary led to similar numbers (Kilgarriff and Rosenzweig, 2000). Sense granularity has been suggested as a reason for the difficulty of the task (Palmer et al., 2007). And in fact, the use of more coarse-grained senses leads to greatly ITA as well as WSD accuracy, with about a 10% improvement for either measure (Palmer et al., 2007; Pradhan et al., 2007). In OntoNotes (Hovy et al., 2006), an ITA of 90% is used as the criterion for the construction of coarsegrained sense distinctions. However, intriguingly, for some high-frequency lemmas such as leave this ITA threshold is not reached even after multiple re-partitionings of the semantic space (Chen and Palmer, 2009) – indicating that the meaning of these words may not be separable into senses distinct enough for consistent annotation. A recent analysis of factors influencing ITA differences between lemmas (Passonneau et al., 2010) found three main factors: sense concreteness, specificity of th</context>
</contexts>
<marker>Pradhan, Loper, Dligach, Palmer, 2007</marker>
<rawString>S. Pradhan, E. Loper, D. Dligach, and M. Palmer. 2007. Semeval-2007 task 17: English lexical sample, SRL and all words. In Proceedings of SemEval¡, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Pylkkanen</author>
<author>R Llinas</author>
<author>G L Murphy</author>
</authors>
<title>The representation of polysemy: MEG evidence.</title>
<date>2006</date>
<journal>Journal of Cognitive Neuroscience,</journal>
<pages>18--97</pages>
<contexts>
<context position="11684" citStr="Pylkkanen et al., 2006" startWordPosition="1926" endWordPosition="1929">sive 1) We study the methods and concepts that each writer uses to defend the cogency of legal, deliberative, or more generally political prudence against explicit or implicit charges that practical thinking is merely a knack or form of cleverness. 2) Eleven CIRA members have been convicted of criminal charges and others are awaiting trial. Figure 1: From (Erk et al., 2009): A sense pair from the USim dataset, for the target charge.n. Annotator judgments: 2,3,4 and varies strongly with the experimental setting. Some studies found evidence for a separate representation (Klein and Murphy, 2001; Pylkkanen et al., 2006). Brown (2008) finds a linear change in semantic similarity effects with sense distance, which could possibly point to a continuous representation of word meaning without clear sense boundaries. But while there is no definitive answer yet on the question of the mental representation of polysemy, a computational model that does not rely on distinct senses has the advantage of making fewer assumptions. It also avoids the tough lexicographic problem mentioned above, of deciding on a best set of senses for a given domain. In the recent USim annotation study (Erk et al., 2009), we tested whether hu</context>
</contexts>
<marker>Pylkkanen, Llinas, Murphy, 2006</marker>
<rawString>L. Pylkkanen, R. Llinas, and G.L. Murphy. 2006. The representation of polysemy: MEG evidence. Journal of Cognitive Neuroscience, 18:97–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Reisinger</author>
<author>R J Mooney</author>
</authors>
<title>Multi-prototype vector-space models of word meaning.</title>
<date>2010</date>
<booktitle>In Proceeding of NAACL.</booktitle>
<contexts>
<context position="18461" citStr="Reisinger and Mooney, 2010" startWordPosition="3035" endWordPosition="3038">formation plus selectional preferences. Right: Computing context-specific meaning by combining predicate and argument via selectional preference vectors accuse say claim obj cold baseball drift red golf elegant ... ... ... comp-1 subj catch cold baseball drift obj throw catch organise obj-1 subj-1 ball mod ... whirl fly provide subj-1 throw catch organise obj-1 ball mod comp-1 catch subj he fielder dog ata (2008)), and component-wise minimum. Then there are multiple prototype approaches that statically cluster synonyms or occurrences to induce word senses(Sch¨utze, 1998; Pantel and Lin, 2002; Reisinger and Mooney, 2010). Exemplar-based approaches represent a word in isolation as a collection of its occurrences or paraphrases, then select only the contextually appropriate exemplars for a given occurrence context (Kintsch, 2001; Erk and Pad´o, 2010). In this paper we focus on the first and third group of approaches, as they do not rely on knowledge of how many word senses (clusters) there should be. A structured vector space model for word meaning in context. In Erk and Pad´o (2008), we proposed the structured vector space model (SVS), which relies solely on syntactic context for computing a context-specific v</context>
</contexts>
<marker>Reisinger, Mooney, 2010</marker>
<rawString>J. Reisinger and R.J. Mooney. 2010. Multi-prototype vector-space models of word meaning. In Proceeding of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Rosch</author>
<author>C B Mervis</author>
</authors>
<title>Family resemblance: Studies in the internal structure of categories.</title>
<date>1975</date>
<journal>Cognitive Psychology,</journal>
<pages>7--573</pages>
<contexts>
<context position="7435" citStr="Rosch and Mervis, 1975" startWordPosition="1210" endWordPosition="1213">esting to note that only one of those factors, the third, can be addressed through a change of dictionary. More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al., 2004), or to work directly with paraphrases (McCarthy and Navigli, 2009). (A) Graded sense membership. Research on the human concept representation (Murphy, 2002; Hampton, 2007) shows that categories in the human mind are not simply sets with clear-cut boundaries. Some items are perceived as more typical than others (Rosch, 1975; Rosch and Mervis, 1975). Also, some items are clear members, others are rated as borderline (Hampton, 1979). On borderline items, people are more likely to change their mind about category membership (McCloskey and Glucksberg, 1978). However, these results concern mental concepts, which raises the question of the relation between mental concepts and word senses. This relation is discussed in most depth by Murphy (1991; 2002), who argues that while not every human concept is associated with a word, word meanings show many of the same phenomena as concepts in general; word meaning is “made up of pieces of conceptual s</context>
</contexts>
<marker>Rosch, Mervis, 1975</marker>
<rawString>E. Rosch and C. B. Mervis. 1975. Family resemblance: Studies in the internal structure of categories. Cognitive Psychology, 7:573–605.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Rosch</author>
</authors>
<title>Cognitive representations of semantic categories.</title>
<date>1975</date>
<journal>Journal of Experimental Psychology: General,</journal>
<pages>104--192</pages>
<contexts>
<context position="2492" citStr="Rosch, 1975" startWordPosition="394" endWordPosition="395">s, not just machines (Kilgarriff and Rosenzweig, 2000). In this paper we advocate the exploration of alternative computational models of word meaning. After all, one possible reason for the continuing difficulty of (manual as well as automatic) word sense assignment is that the prevailing model might be suboptimal. We explore three main hypotheses. The first builds on research on the human concept representation that has shown that concepts in the human mind do not work like sets with clear-cut boundaries; they show graded membership, and there are typical members as well as borderline cases (Rosch, 1975; Hampton, 2007). Accordingly, (A) we will suggest that word meaning may be better modeled using a graded notion of sense membership than through concepts with hard boundaries. Second, even if senses have soft boundaries, the question remains of whether they are disjoint. (B) We will argue in favor of a framework where multiple senses may apply to a single occurrence, to different degrees. This can be viewed as a dynamical grouping of senses for each occurrence, in contrast to static sense groups as in Palmer et al. (2007). The first two hypotheses still rely on an existing sense list. However</context>
<context position="7410" citStr="Rosch, 1975" startWordPosition="1208" endWordPosition="1209">. It is interesting to note that only one of those factors, the third, can be addressed through a change of dictionary. More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al., 2004), or to work directly with paraphrases (McCarthy and Navigli, 2009). (A) Graded sense membership. Research on the human concept representation (Murphy, 2002; Hampton, 2007) shows that categories in the human mind are not simply sets with clear-cut boundaries. Some items are perceived as more typical than others (Rosch, 1975; Rosch and Mervis, 1975). Also, some items are clear members, others are rated as borderline (Hampton, 1979). On borderline items, people are more likely to change their mind about category membership (McCloskey and Glucksberg, 1978). However, these results concern mental concepts, which raises the question of the relation between mental concepts and word senses. This relation is discussed in most depth by Murphy (1991; 2002), who argues that while not every human concept is associated with a word, word meanings show many of the same phenomena as concepts in general; word meaning is “made up </context>
</contexts>
<marker>Rosch, 1975</marker>
<rawString>E. Rosch. 1975. Cognitive representations of semantic categories. Journal of Experimental Psychology: General, 104:192–233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sahlgren</author>
<author>J Karlgren</author>
</authors>
<title>Automatic bilingual lexicon acquisition using random indexing of parallel corpora.</title>
<date>2005</date>
<journal>Journal of Natural Language Engineering, Special Issue on Parallel Texts,</journal>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="3946" citStr="Sahlgren and Karlgren, 2005" startWordPosition="635" endWordPosition="638">g on individual occurrences (usages) of a lemma and their degree of similarity, we can model word meaning without recourse to dictionary senses. In this paper, we are going to argue in favor of the use of vector space as a basis for alternative models of word meaning. Vector space models have been used widely to model word sense (Lund 17 Proceedings of the 2010 Workshop on GEometrical Models of Natural Language Semantics, ACL 2010, pages 17–26, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics and Burgess, 1996; Deerwester et al., 1990; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007), their central property being that proximity in space can be used to predict semantic similarity. By viewing word occurrences as points in vector space, we can model word meaning without recourse to senses. An additional advantage of vector space models is that they are also widely used in human concept representation models, yielding many modeling ideas that can be exploited for computational models. In Section 2 we review the evidence that word sense is a tough phenomenon to model, and we lay out findings that support hypotheses (A)-(C). Section 4 considers distribu</context>
<context position="14419" citStr="Sahlgren and Karlgren, 2005" startWordPosition="2368" endWordPosition="2371">eparate dimension weight vector (Smith et al., 1988; Hampton, 1991; G¨ardenfors, 2004). The features are individually meaningful and interpretable and include sensory and motor features as well as function and taxonomic features. There are several datasets with features elicited from human subjects (McRae et al., 2005; Vigliocco et al., 2004). In computational linguistics, distributional models represent the meaning of a word as a vector in a high-dimensional space whose dimensions characterize the contexts in which the word typically occurs (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007). In the simplest case, the dimensions are context words, and the values are co-occurrence counts. In contrast to spaces used in cognitive science, the dimensions in distributional models are typically not interpretable (though see Almuhareb and Poesio (2005), Baroni et al. (2010)). A central property of distributional models is that proximity in vector space is a predictor of semantic similarity. These models have been used successfully in NLP (Deerwester et al., 1990; Manning et al., 2008), as well as in psychology (Landauer and Dumais, 1997; Lowe and McDonald, 2000;</context>
</contexts>
<marker>Sahlgren, Karlgren, 2005</marker>
<rawString>M. Sahlgren and J. Karlgren. 2005. Automatic bilingual lexicon acquisition using random indexing of parallel corpora. Journal of Natural Language Engineering, Special Issue on Parallel Texts, 11(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sch¨utze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Sch¨utze, 1998</marker>
<rawString>H. Sch¨utze. 1998. Automatic word sense discrimination. Computational Linguistics, 24(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Shepard</author>
</authors>
<title>Towards a universal law of generalization for psychological science.</title>
<date>1987</date>
<journal>Science,</journal>
<volume>237</volume>
<issue>4820</issue>
<contexts>
<context position="28554" citStr="Shepard, 1987" startWordPosition="4726" endWordPosition="4727">aches. Mapping dictionary senses to regions in vector space. In Erk (2009) we expand on the idea of tying inference rules to attachment sites by representing a word sense not as a point but as a region in vector space. The extent of the regions is estimated through the use of both positive exemplars (occurrences of the word sense in question), and negative exemplars (occurrences of other words). The computational models we use are inspired by cognitive models of concept representation that represent concepts as regions (Smith et al., 1988; Hampton, 1991), in particular adopting Shepard’s law (Shepard, 1987), which states that perceived similarity to an exemplar decreases exponentially with distance from its vector. In the longer term, the goal for the association of inference rules with attachment sites is to obtain a principled framework for reasoning with partially applicable inference rules in vector space. 6 Conclusion and outlook In this paper, we have argued that it may be time to consider alternative computational models of word meaning, given that word sense disambiguation, after all this time, is still a tough problem for humans as well as machines. We have followed three hypotheses. Th</context>
</contexts>
<marker>Shepard, 1987</marker>
<rawString>R. Shepard. 1987. Towards a universal law of generalization for psychological science. Science, 237(4820):1317–1323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E E Smith</author>
<author>D L Medin</author>
</authors>
<title>Categories and Concepts.</title>
<date>1981</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="13281" citStr="Smith and Medin, 1981" startWordPosition="2186" endWordPosition="2189">to measure ITA, we found a highly significant correlation (p « 0.001) between the judgments of each pair of annotators. Furthermore, there was a strong correlation on judgments given with and without the use of dictionary senses (USim versus WSsim) for the same data. 19 3 Vector space models of word meaning in isolation This section gives a brief overview of the use of vector spaces to model concepts and word meaning in cognition and computational linguistics. In two of the current main theories of concept representation, feature vectors play a prominent role. Prototype theory (Hampton, 1979; Smith and Medin, 1981) models degree of category membership through similarity to a single prototype. Exemplar models (Medin and Schaffer, 1978; Nosofsky, 1992; Nosofsky and Palmeri, 1997) represent a concept as a collection of all previously seen exemplars and compute degree of category membership as similarity to stored exemplars. Both prototypes and exemplars are typically represented as feature vectors. Many models represent a concept as a region rather than a point in space, often characterized by a feature vector plus a separate dimension weight vector (Smith et al., 1988; Hampton, 1991; G¨ardenfors, 2004). T</context>
</contexts>
<marker>Smith, Medin, 1981</marker>
<rawString>E. E. Smith and D. L. Medin. 1981. Categories and Concepts. Harvard University Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E E Smith</author>
<author>D Osherson</author>
<author>L J Rips</author>
<author>M Keane</author>
</authors>
<title>Combining prototypes: A selective modification model.</title>
<date>1988</date>
<journal>Cognitive Science,</journal>
<volume>12</volume>
<issue>4</issue>
<contexts>
<context position="13843" citStr="Smith et al., 1988" startWordPosition="2279" endWordPosition="2282"> Prototype theory (Hampton, 1979; Smith and Medin, 1981) models degree of category membership through similarity to a single prototype. Exemplar models (Medin and Schaffer, 1978; Nosofsky, 1992; Nosofsky and Palmeri, 1997) represent a concept as a collection of all previously seen exemplars and compute degree of category membership as similarity to stored exemplars. Both prototypes and exemplars are typically represented as feature vectors. Many models represent a concept as a region rather than a point in space, often characterized by a feature vector plus a separate dimension weight vector (Smith et al., 1988; Hampton, 1991; G¨ardenfors, 2004). The features are individually meaningful and interpretable and include sensory and motor features as well as function and taxonomic features. There are several datasets with features elicited from human subjects (McRae et al., 2005; Vigliocco et al., 2004). In computational linguistics, distributional models represent the meaning of a word as a vector in a high-dimensional space whose dimensions characterize the contexts in which the word typically occurs (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007</context>
<context position="28484" citStr="Smith et al., 1988" startWordPosition="4715" endWordPosition="4718">pernym pair, we do know the WordNet sense to which each inference rule attaches. Mapping dictionary senses to regions in vector space. In Erk (2009) we expand on the idea of tying inference rules to attachment sites by representing a word sense not as a point but as a region in vector space. The extent of the regions is estimated through the use of both positive exemplars (occurrences of the word sense in question), and negative exemplars (occurrences of other words). The computational models we use are inspired by cognitive models of concept representation that represent concepts as regions (Smith et al., 1988; Hampton, 1991), in particular adopting Shepard’s law (Shepard, 1987), which states that perceived similarity to an exemplar decreases exponentially with distance from its vector. In the longer term, the goal for the association of inference rules with attachment sites is to obtain a principled framework for reasoning with partially applicable inference rules in vector space. 6 Conclusion and outlook In this paper, we have argued that it may be time to consider alternative computational models of word meaning, given that word sense disambiguation, after all this time, is still a tough problem</context>
</contexts>
<marker>Smith, Osherson, Rips, Keane, 1988</marker>
<rawString>E. E. Smith, D. Osherson, L. J. Rips, and M. Keane. 1988. Combining prototypes: A selective modification model. Cognitive Science, 12(4):485–527.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Smolensky</author>
</authors>
<title>Tensor product variable binding and the representation of symbolic structures in connectionist systems.</title>
<date>1990</date>
<journal>Artificial Intelligence,</journal>
<volume>46</volume>
<pages>216</pages>
<contexts>
<context position="15823" citStr="Smolensky, 1990" startWordPosition="2603" endWordPosition="2604">ictionary senses (along hypothesis (C)), distributional models are an obvious choice, if we can just represent each individual usage as a point in space. However, vector space models have mostly been used to represent the meaning of a word in isolation: The vector for a word is computed by summing over all its corpus occurrences, thereby summing over all its meanings. There are a few vector space models of meaning in context, though they differ in what it is that they model. One group of models computes a single vector for a whole sentence, encoding both the words and the syntactic structure (Smolensky, 1990; B. Coecke and Clark, 2010). In this case, the dimensionality of the vectors varies with the syntactic complexity of the sentence in question. A second group also computes a single vector for a whole expression, but the vector for a larger expression is a combination of the word vectors for the words occurring in the expression (Landauer and Dumais, 1997; Mitchell and Lapata, 2008). Syntactic structure is not encoded. The resulting vector, of the same dimensionality as the word vectors, is then a combination of the contexts in which the words of the sentence occur. A third group of approaches</context>
</contexts>
<marker>Smolensky, 1990</marker>
<rawString>P. Smolensky. 1990. Tensor product variable binding and the representation of symbolic structures in connectionist systems. Artificial Intelligence, 46:159– 216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Snyder</author>
<author>M Palmer</author>
</authors>
<title>The English all-words task.</title>
<date>2004</date>
<booktitle>In 3rd International Workshop on Semantic Evaluations (SensEval-3) at ACL-2004,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="5555" citStr="Snyder and Palmer, 2004" startWordPosition="898" endWordPosition="901"> cognitive models of concept representation and polysemy, following the three hypotheses laid out in the introduction. Word sense assignment. In computational linguistics, the problem of polysemy is typically phrased as one of choosing one best-fitting sense for the given occurrence out of a dictionarydefined sense list. However, this is a hard task both for humans and for machines. With WordNet (Fellbaum, 1998), the electronic lexicon resource that is currently most widely used in computational linguistics, inter-annotator agreement (ITA) lies in the range of 67% to 78% (Landes et al., 1998; Snyder and Palmer, 2004; Mihalcea et al., 2004), and state-of-the-art WSD systems achieve accuracy scores of 73% to 77% (Edmonds and Cotton, 2001; Mihalcea et al., 2004). This problem is not specific to WordNet: Analyses with the HECTOR dictionary led to similar numbers (Kilgarriff and Rosenzweig, 2000). Sense granularity has been suggested as a reason for the difficulty of the task (Palmer et al., 2007). And in fact, the use of more coarse-grained senses leads to greatly ITA as well as WSD accuracy, with about a 10% improvement for either measure (Palmer et al., 2007; Pradhan et al., 2007). In OntoNotes (Hovy et al</context>
</contexts>
<marker>Snyder, Palmer, 2004</marker>
<rawString>B. Snyder and M. Palmer. 2004. The English all-words task. In 3rd International Workshop on Semantic Evaluations (SensEval-3) at ACL-2004, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Taylor</author>
</authors>
<title>Linguistic Categorization: Prototypes in Linguistic Theory. Oxford Textbooks in Linguistics.</title>
<date>1989</date>
<contexts>
<context position="8237" citStr="Taylor, 1989" startWordPosition="1345" endWordPosition="1346">nd Glucksberg, 1978). However, these results concern mental concepts, which raises the question of the relation between mental concepts and word senses. This relation is discussed in most depth by Murphy (1991; 2002), who argues that while not every human concept is associated with a word, word meanings show many of the same phenomena as concepts in general; word meaning is “made up of pieces of conceptual structure”. In cognitive linguistics there has been much work on word meaning based on models with graded membership and typically effects (Coleman and Kay, 1981; Lakoff, 1987; Cruse, 1986; Taylor, 1989). (B) Multiple senses per occurrence. While most manual word sense annotation efforts allow annotators to assign more than one dictionary sense to an occurrence, this is typically phrased as an exception rather than the default. In the recent WSsim annotation study (Erk et al., 2009), 18 Senses Sentence 1 2 3 4 5 6 7 Annotator This question provoked arguments in America about the 1 4 4 2 1 1 3 Ann. 1 Norton Anthology of Literature by Women, some of the 4 5 4 2 1 1 4 Ann. 2 contents of which were said to have had little value as 1 4 5 1 1 1 1 Ann. 3 literature. Table 1: From (Erk et al., 2009):</context>
</contexts>
<marker>Taylor, 1989</marker>
<rawString>J. Taylor. 1989. Linguistic Categorization: Prototypes in Linguistic Theory. Oxford Textbooks in Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Thater</author>
<author>G Dinu</author>
<author>M Pinkal</author>
</authors>
<title>Ranking paraphrases in context.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL Workshop on Applied Textual Inference,</booktitle>
<contexts>
<context position="16525" citStr="Thater et al., 2009" startWordPosition="2723" endWordPosition="2726">s with the syntactic complexity of the sentence in question. A second group also computes a single vector for a whole expression, but the vector for a larger expression is a combination of the word vectors for the words occurring in the expression (Landauer and Dumais, 1997; Mitchell and Lapata, 2008). Syntactic structure is not encoded. The resulting vector, of the same dimensionality as the word vectors, is then a combination of the contexts in which the words of the sentence occur. A third group of approaches derives a separate vector for each word in a given sentence (Erk and Pad´o, 2008; Thater et al., 2009; Erk and Pad´o, 2010). While an approach of the second type would derive a single, joint vector for, say, the expression catch a ball, an approach from the third group would derive two vectors, one for the word catch in the context of ball, and one for the word ball in the context of catch. In this third group, the dimensionality of a vector for a word in context is the same as for a word in isolation. In this paper, we focus on the third type of approaches. Our aim is to study alternatives to dictionary senses for characterizing word meaning. So we need a meaning characterization for each in</context>
<context position="22268" citStr="Thater et al. (2009)" startWordPosition="3673" endWordPosition="3676">et, which has annotator-generated paraphrases for target words in a larger sentential context and which is thus closer to typical NLP application scenarios (McCarthy and Navigli, 2009). SVS showed comparable performance to the model by Mitchell and Lapata (2008) on the 21 former dataset, and outperformed the Mitchell and Lapata model on the latter. One obvious extension is to use all available syntactic context, instead of focusing on a single syntactic neighbor. We found no improvement on SVS in a straightforward extension to additional syntactic context items (Erk and Pad´o, 2009). However, Thater et al. (2009) did achieve better performance with a different model that used all syntactic context. Taking larger context into account in an exemplar-based model. But even if we take the complete local syntactic context into account, we are missing some evidence, in particular non-local information. The word ball is interpreted differently in sentences (1a) and (1b) 1 even though its predicate ran has more or less the same meaning in both sentences. What is different is the subject of ran, player versus debutante, which is not a direct syntactic neighbor of the ambiguous word ball. (1) (a) the player ran </context>
<context position="24341" citStr="Thater et al., 2009" startWordPosition="4027" endWordPosition="4030"> that reflect the number of times each word occurs in a given sentence. The activated exemplars are then simply the ones whose vectors are most similar to the vector of s. The results that we achieved with the exemplar-based model on the Lexical Substitution dataset were considerably better than 1These two examples are due to Ray Mooney. 2Instead of the binary selection of each exemplar that this model uses, it would also be possible to assign each exemplar a weight, making it partially selected. those achieved with any of the syntax-based approaches (Erk and Pad´o, 2008; Erk and Pad´o, 2009; Thater et al., 2009). While prototype models compute a vector by first summing over all observed occurrences and then having to suppress dimensions that are not contextually appropriate, exemplar models only take contextually appropriate exemplars into account in the first place, which is conceptually simpler and thus more attractive. But there are still many open questions, in particular the best combination of bag-of-words context and syntactic context as evidence for computing occurrencespecific vector representations. 5 The role of dictionary senses Word meaning models that rely only on individual word usages</context>
<context position="26960" citStr="Thater et al., 2009" startWordPosition="4441" endWordPosition="4444">els of a standard WSD model as predictions, the vector space model shows higher recall but lower precision – for definitions of precision and recall that are adapted to the graded case. 22 Another way of putting the findings is to say that the WSD confidence levels tend to under-estimate sense applicability, while the vector space model tends to over-estimate it. Attachment sites for inference rules. As discussed above, vector space models for word meaning in context are typically evaluated on paraphrase applicability tasks (Mitchell and Lapata, 2008; Erk and Pad´o, 2008; Erk and Pad´o, 2009; Thater et al., 2009). They predict the applicability of a paraphrase like (2) based on the similarity between a context-specific vector for the lemma (here, catch) and a context-independent vector for the paraphrase. (in this case, contract). X catch Y —* X contract Y (2) Another way of looking at this is to consider the inference rule (2) to be attached to a point in space, namely the vector for contract, and to trigger the inference rule for an occurrence of catch if it is close enough to the attachment site. If we know the WordNet sense of contract for which rule (2) holds – it happens to be sense 4 –, we can </context>
</contexts>
<marker>Thater, Dinu, Pinkal, 2009</marker>
<rawString>S. Thater, G. Dinu, and M. Pinkal. 2009. Ranking paraphrases in context. In Proceedings of the ACL Workshop on Applied Textual Inference, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D H Tuggy</author>
</authors>
<title>Ambiguity, polysemy and vagueness.</title>
<date>1993</date>
<booktitle>Cognitive linguistics,</booktitle>
<pages>4--2</pages>
<contexts>
<context position="10847" citStr="Tuggy, 1993" startWordPosition="1793" endWordPosition="1794">und instead is that the annotators seemed to have mixed and matched senses for the individual occurrences in a dynamic fashion. (C) Describing word meaning without dictionary senses. In lexicography, Kilgarriff (1997) and Hanks (2000) cast doubt on the existence of task-independent, distinct senses. In cognitive science, Kintsch (2007) calls word meaning “fluid and flexible”. And some researchers in lexical semantics have suggested that word meanings lie on a continuum between clear cut cases of ambiguity on the one hand, and on the other hand vagueness where clear cut boundaries do not hold (Tuggy, 1993). There are some psychological studies on whether different senses of a polysemous word are represented separately in the mind or whether there is some joint representation. However, so far the evidence is inconclusive 1) We study the methods and concepts that each writer uses to defend the cogency of legal, deliberative, or more generally political prudence against explicit or implicit charges that practical thinking is merely a knack or form of cleverness. 2) Eleven CIRA members have been convicted of criminal charges and others are awaiting trial. Figure 1: From (Erk et al., 2009): A sense </context>
</contexts>
<marker>Tuggy, 1993</marker>
<rawString>D. H. Tuggy. 1993. Ambiguity, polysemy and vagueness. Cognitive linguistics, 4(2):273–290.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Vigliocco</author>
<author>D P Vinson</author>
<author>W Lewis</author>
<author>M F Garrett</author>
</authors>
<title>Representing the meanings of object and action words: The featural and unitary semantic space hypothesis. Cognitive Psychology,</title>
<date>2004</date>
<pages>48--422</pages>
<contexts>
<context position="14136" citStr="Vigliocco et al., 2004" startWordPosition="2325" endWordPosition="2328">ars and compute degree of category membership as similarity to stored exemplars. Both prototypes and exemplars are typically represented as feature vectors. Many models represent a concept as a region rather than a point in space, often characterized by a feature vector plus a separate dimension weight vector (Smith et al., 1988; Hampton, 1991; G¨ardenfors, 2004). The features are individually meaningful and interpretable and include sensory and motor features as well as function and taxonomic features. There are several datasets with features elicited from human subjects (McRae et al., 2005; Vigliocco et al., 2004). In computational linguistics, distributional models represent the meaning of a word as a vector in a high-dimensional space whose dimensions characterize the contexts in which the word typically occurs (Lund and Burgess, 1996; Landauer and Dumais, 1997; Sahlgren and Karlgren, 2005; Pad´o and Lapata, 2007). In the simplest case, the dimensions are context words, and the values are co-occurrence counts. In contrast to spaces used in cognitive science, the dimensions in distributional models are typically not interpretable (though see Almuhareb and Poesio (2005), Baroni et al. (2010)). A centra</context>
</contexts>
<marker>Vigliocco, Vinson, Lewis, Garrett, 2004</marker>
<rawString>G. Vigliocco, D. P. Vinson, W. Lewis, and M. F. Garrett. 2004. Representing the meanings of object and action words: The featural and unitary semantic space hypothesis. Cognitive Psychology, 48:422– 488.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Weaver</author>
</authors>
<date>1949</date>
<booktitle>Machine Translation of Languages: Fourteen Essays.</booktitle>
<editor>Translation. In W.N. Locke and A.D. Booth, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1041" citStr="Weaver, 1949" startWordPosition="158" endWordPosition="159">n the assignment of a single best-fitting dictionary sense to each occurrence: Either use dictionary senses, but view them as having fuzzy boundaries, and assume that an occurrence can activate multiple senses to different degrees. Or move away from dictionary senses completely, and only model similarities between individual word usages. We argue that distributional models provide a flexible framework for experimenting with alternative models of word meanings, and discuss example models. 1 Introduction Word sense disambiguation (WSD) is one of the oldest problems in computational linguistics (Weaver, 1949) and still remains challenging today. State-of-the-art performance on WSD for WordNet senses is at only around 70-80% accuracy (Edmonds and Cotton, 2001; Mihalcea et al., 2004). The use of coarse-grained sense groups (Palmer et al., 2007) has led to considerable advances in WSD performance, with accuracies of around 90% (Pradhan et al., 2007). But this figure averages over lemmas, and the problem remains that while WSD works well for some lemmas, others continue to be tough. In WSD, polysemy is typically modeled through a list of dictionary senses thought to be mutually disjoint, such that eac</context>
</contexts>
<marker>Weaver, 1949</marker>
<rawString>W. Weaver. 1949. Translation. In W.N. Locke and A.D. Booth, editors, Machine Translation of Languages: Fourteen Essays. MIT Press, Cambridge, MA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>