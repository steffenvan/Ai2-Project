<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004537">
<title confidence="0.981625">
Simple, readable sub-sentences
</title>
<author confidence="0.994904">
Sigrid Klerke
</author>
<affiliation confidence="0.997828">
Centre for Language Technology
University of Copenhagen
</affiliation>
<email confidence="0.981772">
sigridklerke@gmail.com
</email>
<author confidence="0.991206">
Anders Søgaard
</author>
<affiliation confidence="0.9977385">
Centre for Language Technology
University of Copenhagen
</affiliation>
<email confidence="0.987894">
soegaard@hum.ku.dk
</email>
<sectionHeader confidence="0.993646" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999940866666667">
We present experiments using a new unsu-
pervised approach to automatic text sim-
plification, which builds on sampling and
ranking via a loss function informed by
readability research. The main idea is
that a loss function can distinguish good
simplification candidates among randomly
sampled sub-sentences of the input sen-
tence. Our approach is rated as equally
grammatical and beginner reader appro-
priate as a supervised SMT-based baseline
system by native speakers, but our setup
performs more radical changes that better
resembles the variation observed in human
generated simplifications.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999978863636364">
As a field of research in NLP, text simplification
(TS) has gained increasing attention recently, pri-
marily for English text, but also for Brazilian Por-
tuguese (Specia, 2010; Aluísio et al., 2008), Dutch
(Daelemans et al., 2004), Spanish (Drndarevic
and Saggion, 2012), Danish (Klerke and Søgaard,
2012), French (Seretan, 2012) and Swedish (Ry-
bing and Smith, 2009; Decker, 2003). Our experi-
ments use Danish text which is similar to English
in that it has a deep orthography making it hard
to map between letters and sounds. Danish has a
relatively free word order and sparse morfology.
TS can help readers with below average reading
skills access information and may supply relevant
training material, which is crucial for developing
reading skills. However, manual TS is as expen-
sive as translation, which is a key limiting factor
on the availability of easy-to-read material. One of
the persistent chalenges of TS is that different in-
terventions are called for depending on the target
reader population. Automatic TS is an effective
way to counter these limitations.
</bodyText>
<sectionHeader confidence="0.992789" genericHeader="introduction">
2 Approach
</sectionHeader>
<bodyText confidence="0.9988992">
Definitions of TS typically reflect varying target
reader populations and the methods studied. For
our purposes we define TS to include any oper-
ation on the linguistic structure and content of a
text, intended to produce new text, which
</bodyText>
<listItem confidence="0.9920054">
1. has semantic content similar to (a part of) the
original text
2. requires less cognitive effort to decode and
understand by a target reader, compared to
the original text.
</listItem>
<bodyText confidence="0.985533962962963">
Operations on linguistic content may include
deletion, reordering and insertion of content,
paraphrasing concepts, resolving references, etc.,
while typography and layout are excluded as non-
linguistic properties.
We cast the problem of generating a more read-
able sentence from an input as a problem of choos-
ing a reasonable sub-sentence from the words
present in the original. The corpus-example below
illustrates how a simplified sentence can be em-
bedded as scattered parts of a non-simplified sen-
tence. The words in bold are the common parts
which make up almost the entire human generated
simplification and constitutes a suitable simplifi-
cation on its own.
Original: Der er målt hvad der bliver betegnet som abnormt store
mængder af radioaktivt materiale i havvand nær det jordskælvsramte
atomkraftværk i Japan .
What has been termed an abnormally large amount of radioactivity
has been measured in sea water near the nuclear power plant that
was hit by earthquakes in Japan
Simplified: Der er målt en stor mængde radioaktivt materiale i havet
nær atom-kraftværket Fukushima i Japan.
A large amount of radioactivity has been measured in the sea near
the nuclear power plant Fukushima in Japan
To generate candidate sub-sentences we use a
random deletion procedure in combination with
</bodyText>
<page confidence="0.962451">
142
</page>
<note confidence="0.653847">
Proceedings of the ACL Student Research Workshop, pages 142–149,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999949125">
general dependency-based heuristics for conserv-
ing main sentence constituents, and then introduce
a loss-function for choosing between candidates.
Since we avoid relying on a specialized parallel
corpus or a simplification grammar, which can be
expensive to create, the method is especially rel-
evant for under-resourced languages and organi-
zations. Although we limit rewriting to deletions,
the space of possible candidates grows exponen-
tially with the length of the input sentence, pro-
hibiting exhaustive candidate generation, which is
why we chose to sample the deletions randomly.
However, to increase the chance of sampling good
candidates, we restrict the search space under
the assumption that some general patterns apply,
namely, that the main verb and subject should al-
ways be kept, negations should be kept and that if
something is kept that originally had objects, those
objects should also be kept. Another way in which
we restrict the candidate space is by splitting long
sentences. Some clauses are simple to identify
and extract, like relative clauses, and doing so can
dramatically reduce sentence length. Both sim-
ple deletions and extraction of clauses can be ob-
served in professionally simplified text. (Medero,
2011; Klerke, 2012)
The next section positions this research in the
context of related work. Section 4 presents the ex-
perimental setup including generation and evalu-
ation. In Section 5, the results are presented and
discussed and, finally, concluding remarks and fu-
ture perspectives are presented in the last section.
</bodyText>
<sectionHeader confidence="0.999875" genericHeader="method">
3 Related work
</sectionHeader>
<bodyText confidence="0.97626105882353">
Approaches for automatic TS traditionally focus
on lexical substitution (De Belder and Moens,
2012; Specia et al., 2012; Yatskar et al., 2010), on
identifying re-write rules at sentence level either
manually (Chandrasekar et al., 1996; Carroll et al.,
1999; Canning et al., 2000; Siddharthan, 2010;
Siddharthan, 2011; Seretan, 2012) or automati-
cally from parallel corpora (Woodsend and Lap-
ata, 2011; Coster and Kauchak, 2011; Zhu et al.,
2010) and possibly learning cues for when to ap-
ply such changes (Petersen and Ostendorf, 2007;
Medero, 2011; Bott et al., 2012).
Chandrasekar et al. (1996) propose a structural
approach, which uses syntactic cues to recover rel-
ative clauses and appositives. Sentence level syn-
tactic re-writing has since seen a variety of man-
ually constructed general sentence splitting rules,
designed to operate both on dependencies and
phrase structure trees, and typically including lex-
ical cues (Siddharthan, 2011; Heilman and Smith,
2010; Canning et al., 2000). Similar rules have
been created from direct inspection of simplifica-
tion corpora (Decker, 2003; Seretan, 2012) and
discovered automatically from large scale aligned
corpora (Woodsend and Lapata, 2011; Zhu et al.,
2010).
In our experiment we apply few basic sentence
splitting rules as a pre-processing technique be-
fore using an over-generating random deletion ap-
proach.
Carroll et al. (1999) perform lexical substitution
from frequency counts and eliminate anaphora by
resolving and replacing the referring expressions
with the entity referred to. Their system further
include compound sentence splitting and rewrit-
ing of passive sentences to active ones (Canning
et al., 2000). Research into lexical simplification
remains an active topic. De Belder and Moens
(2012; Specia et al. (2012) are both recent pub-
lications of new resources for evaluating lexical
simplification in English consisting of lists of syn-
onyms ranked by human judges. Another type
of resource is graded word-lists as described in
Brooke et al. (2012). Annotator agreement and
comparisons so far shows that it is easy to over-
fit to reflect individual annotator and domain dif-
ferences that are not of relevance to generalized
systems.
In a minimally supervised setup, our TS ap-
proach can be modified to include lexical simpli-
fications as part of the random generation process.
This would require a broad coverage list of words
and simpler synonyms, which could for instance
be extracted from a parallel corpus like the DSim
corpus.
For the majority of research in automatic TS
the question of what constitutes cognitive load is
not discussed. An exception is Siddharthan and
Katsos (2012), who seek to isolate the psycho-
linguistically motivated notions of sentence com-
prehension from sentence acceptability by actually
measuring the effect of TS on cognition on a small
scale.
Readability research is a line of research that is
more directly concerned with the nature of cogni-
tive load in reading building on insights from psy-
cholinguistics. One goal is to develop techniques
and metrics for assessing the readability of unseen
</bodyText>
<page confidence="0.998507">
143
</page>
<bodyText confidence="0.99965575">
text. Such metrics are used as a tool for teachers
and publishers, but existing standard metrics (like
Flesch-Kincaid (Flesch, 1948) and LIX (Bjorns-
son, 1983)) were designed and optimized for easy
manual application to human written text, requir-
ing thehuman reader to assess that the text is
congruent and coherent. More recent methods
promise to be applicable to unassessed text. Lan-
guage modeling in particular has shown to be a
robust and informative component of systems for
assessing text readability (Schwarm and Osten-
dorf, 2005; Vajjala and Meurers, 2012) as it is bet-
ter suited to evaluate grammaticality than standard
metrics. We use language modeling alongside tra-
ditional metrics for selecting good simplification
candidates.
</bodyText>
<sectionHeader confidence="0.999871" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999199">
4.1 Baseline Systems
</subsectionHeader>
<bodyText confidence="0.9997496">
We used the original input text and the human sim-
plified text from the sentence aligned DSim corpus
which consist of 48k original and manually sim-
plified sentences of Danish news wire text (Klerke
and Søgaard, 2012) as reference in the evaluations.
In addition we trained a statistical machine trans-
lation (SMT) simplification system, in effect trans-
lating from normal news wire text to simplified
news. To train an SMT system, a large resource
of aligned parallel text and a language model of
the target language are needed. We combined the
25 million words Danish Korpus 20001 with the
entire 1.75 million words unaligned DSim cor-
pus (Klerke and Søgaard, 2012) to build the lan-
guage model2. Including both corpora gives bet-
ter coverage and assigns lower average ppl and a
simlar difference in average ppl between the two
sides of a held out part of the DSim corpus com-
pared to using only the simplified part of DSim
for the language model. Following Coster and
Kauchak (2011), we used the phrase-based SMT
Moses (Koehn et al., 2007), with GIZA++ word-
alignment (Och and Ney, 2000) and phrase tables
learned from the sentence aligned portion of the
DSim corpus.
</bodyText>
<footnote confidence="0.9899555">
1http://korpus.dsl.dk/korpus2000/
engelsk_hovedside
2The LM was a 5-gram Knesser-Ney smoothed lowercase
model, built using IRSTLM (Federico et al., 2008)
</footnote>
<subsectionHeader confidence="0.983394">
4.2 Experimental setup
</subsectionHeader>
<bodyText confidence="0.998728857142857">
Three system variants were set up to generate
simplified output from the original news wire of
the development and test partitions of the DSim
corpus. The texts were dependency-parsed us-
ing Bohnet’s parser (Bohnet, 2010) trained on the
Danish Treebank3 (Kromann, 2003) with default
settings4.
</bodyText>
<listItem confidence="0.950836444444444">
1. Split only performed simple sentence split-
ting.
2. Sample over-generated candidates by sam-
pling the heuristically restricted space of ran-
dom lexical deletions and ranking candidates
with a loss function.
3. Combined is a combination of the two, ap-
plying the sampling procedure of Sample to
the split sentences from Split.
</listItem>
<bodyText confidence="0.999678076923077">
Sentence Splitting We implemented sentence
splitting to extract relative clauses, as marked by
the dependency relation rel, coordinated clauses,
coord, and conjuncts, conj, when at least a verb
and a noun is left in each part of the split. Only
splits resulting in sentences of more than three
words were considered. Where applicable, re-
ferred entities were included in the extracted sen-
tence by using the dependency analysis to extract
the subtree of the former head of the new sen-
tence5. In case of more than one possibility, the
split resulting in the most balanced division of the
sentence was chosen and the rules were re-applied
if a new sentence was still longer than ten tokens.
Structural Heuristics To preserve nodes from
later deletion we applied heuristics using simple
structural cues from the dependency structures.
We favored nodes headed by a subject relation,
subj, and object relations, *obj, and negating
modifiers (the Danish word ikke) under the as-
sumption that these were most likely to be impor-
tant for preserving semantics and generating well-
formed candidates under the sampling procedure
described below. The heuristics were applied both
to trees, acting by preserving entire subtrees and
applied to words, only preserving single tokens.
</bodyText>
<footnote confidence="0.866614666666667">
3http://ilk.uvt.nl/conll/post_task_
data.html
4Performance of the parser on the treebank test set La-
beled attatchment score (LAS) = 85.65 and Unlabeled at-
tatchment score (UAS) = 90.29
5For a formal description see (Klerke, 2012)
</footnote>
<page confidence="0.997451">
144
</page>
<bodyText confidence="0.9997329">
This serves as a way of avoiding relying heavily
on possibly faulty dependency analyses and also
avoid the risk of insisting on keeping long, com-
plex or superfluous modifiers.
Sampling Candidates for scoring were over-
generated by randomly selecting parts of a (pos-
sibly split) input sentence. Either the selected
nodes with their full sub-tree or the single tokens
from the flat list of tokens were eliminated, unless
they were previously selected for preservation by
a heuristic. Some additional interaction between
heuristics and sampling happened when the dele-
tions were performed on trees: deletion of subtrees
allow non-continuous deletions when the parses
are non-projective, and nodes that were otherwise
selected for keeping may nevertheless be removed
if they are part of a subtree of a node selected for
deletion. After pruning, all nodes that used to have
outgoing obj-relations had the first child node of
these relations restored.
</bodyText>
<subsectionHeader confidence="0.997772">
4.3 Scoring
</subsectionHeader>
<bodyText confidence="0.999814545454545">
We rank candidates according to a loss function
incorporating both readability score (the lower,
the more readable) and language model perplexity
(the lower, the less perplexing) as described below.
The loss function assigns values to the candidates
such that the best simplification candidate receives
the lowest score.
The loss function is a weighted combination of
three scores: perplexity (PPL), LIX and word-
class distribution (WCD). The PPL scores were
obtained from a 5-gram language model of Dan-
ish6 We used the standard readability metric for
Danish, LIX (Bjornsson, 1983)7. Finally, the
WCD measured the variation in universal pos-
tag-distribution 8 compared to the observed tag-
variation in the entire simplified corpus. For PPL
and LIX we calculated the difference between the
score of the input sentence and the candidate.
Development data was used for tuning the
weights of the loss function. Because the
candidate-generation is free to produce extremely
short candidates, we have to deal with candidates
</bodyText>
<footnote confidence="0.998766111111111">
6The LM was Knesser-Ney smoothed, using the same cor-
pora as the baseline system, without punctuation and built us-
ing SRILM (Stolcke, 2002).
7LIX is similar to the English Flesch-Kincaid grade level
in favoring short sentences with short words. The formula
is LIX = average sentence length + % long words, with
long words being of more than 6 characters. (Anderson,
1983) calculated a conversion from LIX to grade levels.
8suggested by(Petrov et al., 2011)
</footnote>
<bodyText confidence="0.983924772727273">
receiving extremely low scores. Those scores
never arise in the professionally simplified text,
so we eliminate extreme candidates by introduc-
ing filters on all scores. The lower limit was tuned
experimentally and fixed approximately two times
below the average difference observed between
the two parts of the aligned DSim corpus, thus lim-
iting the reduction in PPL and LIX to 60% of the
input’s PPL and LIX. The upper limit was fixed
at the input-level plus 20% to allow more varied
candidates through the filters. The WCD-filter ac-
cepted all candidates with a tag-variance that fell
below the 75-percentile observed variance in the
simplified training part of the DSim corpus. The
resulting loss was calculated as the sum of three
weighted scores.
Below is the loss function we minimized over
the filtered candidates t ∈ Ts for each input sen-
tence, s. The notation var() denotes the range al-
lowed through a hard filter. Using development
data we set the values of the term weights to
α = 1, β = 6 and γ = 2.
</bodyText>
<equation confidence="0.999702">
t∗ = argmin loss(s,t)
t∈Ts
loss(s, t) = ALIX (s, t) + β APPL(s, t)
avar(LIX(s)) var(PPL(s))
+ ry AWCD(.75, t)
WCD(.75)
</equation>
<bodyText confidence="0.9994845">
If no candidates passed through the filters, the
input sentence was kept.
</bodyText>
<subsectionHeader confidence="0.958719">
4.4 Evaluation
</subsectionHeader>
<bodyText confidence="0.999989722222222">
Evaluation was performed by a group of proficient
Danish speaking volunteers who received written
instructions and responded anonymously via an
online form. 240 sentences were evaluated: six
versions of each of 40 test set sentences. 48
sentences were evaluated by four judges, and
the remaining by one judge each. The judges
were asked to rate each sentence in terms of
grammaticality and in terms of perceived beginner
reader appropriateness, both on a 5-point scale,
with one signifying very good and five signifying
very bad. The evaluators had to rate six versions
of each sentence: original news wire, a human
simplified version, the baseline system, a split
sentence version (Split), a sampled only version
(Sample), and a version combining the Split and
Sample techniques (Combined). The presentation
was randomized. Below are example outputs
</bodyText>
<page confidence="0.995481">
145
</page>
<bodyText confidence="0.818368090909091">
for the baseline and the other three automatic
systems:
BL: Der er hvad der bliver betegnet som abnormt store mængder
radioaktivt materiale i havvand nær frygter atomkraftværk .
Split: Der er målt hvad. Hvad bliver betegnet som abnormt
store mængder af radioaktivt materiale i havvand nær det
jordskælvsramte atomkraftværk i Japan .
Sample: Der er målt hvad der bliver betegnet som store mængder
af radioaktivt materiale i havvand japan .
Comb.: Der er målt hvad. Hvad bliver betegnet som store mængder
af radioaktivt materiale det atomkraftværk i japan .
</bodyText>
<sectionHeader confidence="0.999793" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999880902439025">
The ranking of the systems in terms of begin-
ner reader appropriateness and grammaticality, are
shown in Figure 1. From the test set of the DSim
corpus, 15 news wire texts were arbitrarily se-
lected for evaluation. For these texts we calcu-
lated median LIX and PPL. The results are shown
in Table 1. The sentences for human evaluation
were drawn arbitrarily from this collection. As
expected, the filtering of candidates and the loss
function force the systems Sample and Combined
to choose simplifications with LIX and PPL scores
close to the ones observed in the human simpli-
fied version. Split sentences only reduce LIX as
a result of shorter sentences, however PPL is the
highest, indicating a loss of grammaticality. Most
often this was caused by tagger and parser errors.
The baseline reduces PPL slightly, while LIX is
unchanged. This reflects the importance of the
language model in the SMT system.
In the analyses below, the rating were collapsed
to three levels. For texts ranked by more than
one judge, we calculated agreement as Krippen-
dorff’s α. The results are shown in Table 2. In
addition to sentence-wise agreement, the system-
wise evaluation agreement was calculated as all
judges were evaluating the same 6 systems 8 times
each. We calculated α of the most frequent score
(mode) assigned by each judge to each system.
As shown in Table 2 this system score agreement
was only about half of the single sentence agree-
ment, which reflect a notable instability in output
quality of all computer generated systems. The
same tendency is visible in both histograms in Fig-
ure 1a and 1b. While grammaticality is mostly
agreed upon when the scores are collapsed into
three bins (α = 0.650), proficient speakers do not
agree to the same extent on what constitutes be-
ginner reader appropriate text (α = 0.338). The
average, mean and most frequent assigned ranks
are recorded in Table 3. Significant differences at
p &lt; 0.05 are reported in Table 4.
</bodyText>
<figure confidence="0.963865">
Beginning reader appropriateness
votes for each system
(a) Sentence – Beginner
Grammaticality
votes for each system
(b) Sentence – Grammar.
</figure>
<figureCaption confidence="0.994323">
Figure 1: Distribution of all rankings on systems
before collapsing rankings.
</figureCaption>
<table confidence="0.987482666666667">
Orig. Simpl. Base Split Sample Comb.
PPL 222 174 214 234 164 177
LIX 45 (10) 39 (8) 45 (10) 41(9) 36 (8) 32 (7)
</table>
<tableCaption confidence="0.99447">
Table 1: LIX and PPL scores for reference texts
</tableCaption>
<bodyText confidence="0.966223090909091">
and system generated output. Medians are re-
ported, because distributions are very skewed,
which makes the mean a bad estimator of central
tendency. LIX grade levels in parenthesis.
Reflecting the fair agreement on grammatical-
ity, all comparisons come out significant except
the human generated versions that are judged as
equally grammatical and the Combined and Base-
line systems that are indistinguishable in gram-
maticality. Beginner reader appropriateness is sig-
nificantly better in the human simplified version
</bodyText>
<figure confidence="0.992031392857143">
40
60
70
50
30
20
10
0
Original
Simplified
Baseline
Split
Sample
Combined
40
60
70
50
30
20
10
0
Original
Simplified
Baseline
Split
Sample
Combined
</figure>
<page confidence="0.992585">
146
</page>
<table confidence="0.996927666666667">
Systems Sentences
Beginner reader 0.168 0.338
Grammaticality 0.354 0.650
</table>
<tableCaption confidence="0.972323">
Table 2: Krippendorff’s α agreement for full-text
</tableCaption>
<bodyText confidence="0.998798666666667">
and sentence evaluation. Agreement on system
ranks was calculated from the most frequent score
per judge per system.
compared to all other versions, and the original
version is significantly better than the Sample and
Split systems. The remaining observed differences
are not significant due to the great variation in
quality as expressed in Figure 1a.
We found that our Combined system produced
sentences that were as grammatical as the base-
line and also frequently judged to be appropriate
for beginner readers. The main source of error
affecting both Combined and Split is faulty sen-
tence splitting as a result of errors in tagging and
parsing. One way to avoid this in future develop-
ment is to propagate several split variants to the
final sampling and scoring. In addition, the sys-
tems Combined and Sample are prone to omitting
important information that is perceived as missing
when compared directly to the original, although
those two systems are the ones that score the clos-
est to the human generated simplifications. As can
be expected in a system operating exclusively at
sentence level, coherence across sentence bound-
aries remains a weak point.
Another important point is that while the base-
line system performs well in the evaluation, this
is likely due to its conservativeness: choosing
simplifications resembling the original input very
closely. This is evident both in our automatic mea-
sures (see Table 1) and from manual inspection.
Our systems Sample and Combine, on the other
hand, have been tuned to perform much more radi-
cal changes and in this respect more closely model
the changes we see in the human simplification.
Combined is thus evaluated to be at level with
the baseline in grammaticality and beginner reader
appropriateness, despite the fact that the baseline
system is supervised.
</bodyText>
<sectionHeader confidence="0.667826" genericHeader="conclusions">
Conclusion and perspectives
</sectionHeader>
<bodyText confidence="0.999589">
We have shown promising results for simplifica-
tion of Danish sentences. We have also shown
that using restricted over-generation and scoring
can be a feasible way for simplifying text with-
out relying directly on large scale parallel corpora,
</bodyText>
<table confidence="0.997881125">
Sent. – Beginner Sent. – Grammar
x¯ x˜ mode x¯ x˜ mode
Human Simp. 1.44 1 1 1.29 1 1
Orig. 2.14 1 1 1.32 1 1
Base 2.58 3 1 1.88 2 1
Split 3.31 3 5 2.44 3 3
Sample 3.22 3 5 2.39 3 3
Comb. 2.72 1 1 1.93 2 1
</table>
<tableCaption confidence="0.998748">
Table 3: Human evaluation. Mean (¯x), median (˜x)
</tableCaption>
<bodyText confidence="0.783548">
and most frequent (mode) of assigned ranks by be-
ginner reader appropriateness and grammaticality
as assessed by proficient Danish speakers.
</bodyText>
<table confidence="0.991216333333333">
Comb. Sample Split Base Orig.
Human Simp. b, g b, g b, g b, g b
Orig. g b, g b, g g
Base g g g
Split g
Sample
</table>
<tableCaption confidence="0.98688">
Table 4: Significant differences between systems
</tableCaption>
<bodyText confidence="0.948103076923077">
in experiment b: Beginner reader appropriate-
ness and g: Grammaticality. Bonferroni-corrected
Mann-Whitney’s U for 15 comparisons, two-tailed
test. A letter indicate significant difference at cor-
rected p &lt; 0.05 level.
which for many languages do not exist. To inte-
grate language modeling and readability metrics in
scoring is a first step towards applying results from
readability research to the simplification frame-
work. Our error analysis showed that many errors
come from pre-processing and thus more robust
NLP-tools for Danish are needed. Future perspec-
tives include combining supervised and unsuper-
vised methods to exploit the radical unsupervised
deletion approach and the knowledge obtainable
from observable structural changes and potential
lexical simplifications. We plan to focus on refin-
ing the reliability of sentence splitting in the pres-
ence of parser errors as well as on developing a
loss function that incorporates more of the insights
from readability research, and to apply machine
learning techniques to the weighting of features.
Specifically we would like to investigate the use-
fulness of discourse features and transition proba-
bilities (Pitler and Nenkova, 2008) for performing
and evaluating full-text simplifications.
</bodyText>
<sectionHeader confidence="0.980169" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99946925">
Thanks to Mirella Lapata and Kristian Woodsend
for their feedback and comments early in the pro-
cess of this work and to the Emnlp@Cph group
and reviewers for their helpful comments.
</bodyText>
<page confidence="0.997361">
147
</page>
<sectionHeader confidence="0.987516" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999466132075472">
S.M. Aluísio, Lucia Specia, T.A.S. Pardo, E.G.
Maziero, H.M. Caseli, and R.P.M. Fortes. 2008. A
corpus analysis of simple account texts and the pro-
posal of simplification strategies: first steps towards
text simplification systems. In Proceedings of the
26th annual ACM international conference on De-
sign of communication, pages 15–22. ACM.
Jonathan Anderson. 1983. LIX and RIX: Variations on
a little-known readability index. Journal of Reading,
26(6):490–496.
C. H. Bjornsson. 1983. Readability of Newspapers
in 11 Languages. Reading Research Quarterly,
18(4):480–497.
B Bohnet. 2010. Very high accuracy and fast depen-
dency parsing is not a contradiction. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics, pages 89–97. Association for
Computational Linguistics.
S. Bott, H. Saggion, and D. Figueroa. 2012. A hy-
brid system for spanish text simplification. In Third
Workshop on Speech and Language Processing for
Assistive Technologies (SLPAT), Montreal, Canada.
Julian Brooke, Vivian Tsang, David Jacob, Fraser
Shein, and Graeme Hirst. 2012. Building Read-
ability Lexicons with Unannotated Corpora. In Pro-
ceedings of the First Workshop on Predicting and
Improving Text Readability for target reader popula-
tions, pages 33–39, Montr{é}al, Canada, June. As-
sociation for Computational Linguistics.
Y. Canning, J. Tait, J. Archibald, and R. Crawley.
2000. Cohesive generation of syntactically simpli-
fied newspaper text. Springer.
John Carroll, G. Minnen, D. Pearce, Yvonne Canning,
S. Devlin, and J. Tait. 1999. Simplifying text
for language-impaired readers. In Proceedings of
EACL, volume 99, pages 269–270. Citeseer.
R. Chandrasekar, Christine Doran, and B Srinivas.
1996. Motivations and methods for text simplifica-
tion. In Proceedings of the 16th conference on Com-
putational linguistics-Volume 2, pages 1041–1044.
Association for Computational Linguistics.
William Coster and David Kauchak. 2011. Simple En-
glish Wikipedia: a new text simplification task. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies: short papers-Volume 2, vol-
ume 2, pages 665–669. Association for Computa-
tional Linguistics.
W. Daelemans, A. Höthker, and E.T.K. Sang. 2004.
Automatic sentence simplification for subtitling in
dutch and english. In Proceedings of the 4th In-
ternational Conference on Language Resources and
Evaluation, pages 1045–1048.
A. Davison and R.N. Kantor. 1982. On the failure of
readability formulas to define readable texts: A case
study from adaptations. Reading Research Quar-
terly, pages 187–209.
J. De Belder and M.F. Moens. 2012. A dataset for the
evaluation of lexical simplification. Computational
Linguistics and Intelligent Text Processing, pages
426–437.
Anna Decker. 2003. Towards automatic grammati-
cal simplification of Swedish text. Master’s thesis,
Stockholm University.
Biljana Drndarevic and Horacio Saggion. 2012. To-
wards Automatic Lexical Simplification in Spanish:
An Empirical Study. In Proceedings of the First
Workshop on Predicting and Improving Text Read-
ability for target reader populations, pages 8–16,
Montr{é}al, Canada, June. Association for Compu-
tational Linguistics.
M Federico, N Bertoldi, and M Cettolo. 2008.
IRSTLM: an open source toolkit for handling large
scale language models. In Ninth Annual Conference
of the International Speech Communication Associ-
ation.
Rudolph Flesch. 1948. A new readability yardstick.
Journal of applied psychology, 32(3):221.
Michael Heilman and Noah A Smith. 2010. Extract-
ing simplified statements for factual question gen-
eration. In Proceedings of the Third Workshop on
Question Generation.
Sigrid Klerke and Anders Søgaard. 2012. DSim , a
Danish Parallel Corpus for Text Simplification. In
Proceedings of Language Resources and Evaluation
(LREC 2012), pages 4015–4018.
Sigrid Klerke. 2012. Automatic text simplification in
danish. sampling a restricted space of rewrites to op-
timize readability using lexical substitutions and de-
pendency analyses. Master’s thesis, University of
Copenhagen.
P Koehn, H Hoang, A Birch, C Callison-Burch, M Fed-
erico, N Bertoldi, B Cowan, W Shen, C Moran,
R Zens, and Others. 2007. Moses: Open source
toolkit for statistical machine translation. In Pro-
ceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
pages 177–180. Association for Computational Lin-
guistics.
M T Kromann. 2003. The Danish Dependency Tree-
bank and the DTAG treebank tool. In Proceedings
of the Second Workshop on Treebanks and Linguistic
Theories (TLT), page 217.
Julie Medero. 2011. Identifying Targets for Syntactic
Simplification. In Proceedings of Speech and Lan-
guage Technology in Education.
</reference>
<page confidence="0.979646">
148
</page>
<reference confidence="0.999636988095238">
F.J. Och and H. Ney. 2000. A comparison of alignment
models for statistical machine translation. In Pro-
ceedings of the 18th conference on Computational
linguistics-Volume 2, pages 1086–1090. Association
for Computational Linguistics.
S.E. E Petersen and Mari Ostendorf. 2007. Text sim-
plification for language learners: a corpus analy-
sis. In the Proceedings of the Speech and Language
Technology for Education Workshop, pages 69–72.
Citeseer.
S. Petrov, D. Das, and R. McDonald. 2011. A
universal part-of-speech tagset. Arxiv preprint
ArXiv:1104.2086.
Emily Pitler and Ani Nenkova. 2008. Revisiting
readability: A unified framework for predicting text
quality. Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing.
Jonas Rybing and Christian Smith. 2009. CogFLUX
Grunden till ett automatiskt textförenklingssystem
för svenska. Master’s thesis, Linköpings Univer-
sitet.
Sarah E Schwarm and Mari Ostendorf. 2005. Reading
Level Assessment Using Support Vector Machines
and Statistical Language Models. In Proceedings
of the 43rd Annual Meeting of the ACL, pages 523–
530.
V. Seretan. 2012. Acquisition of syntactic simplifica-
tion rules for french. In Proceedings of Language
Resources and Evaluation (LREC 2012).
Advaith Siddharthan and Napoleon Katsos. 2012.
Offline Sentence Processing Measures for testing
Readability with Users. In Proceedings of the First
Workshop on Predicting and Improving Text Read-
ability for target reader populations, pages 17–24,
Montr{é}al, Canada, June. Association for Compu-
tational Linguistics.
Advaith Siddharthan. 2010. Complex lexico-syntactic
reformulation of sentences using typed dependency
representations. Proceedings of the 6th Interna-
tional Natural Language Generation Conference.
Advaith Siddharthan. 2011. Text Simplification us-
ing Typed Dependencies: A Comparison of the Ro-
bustness of Different Generation Strategies. In Pro-
ceedings of the 13th European Workshop on Natural
Language Generation, pages 2–11.
L. Specia, S.K. Jauhar, and R. Mihalcea. 2012.
Semeval-2012 task 1: English lexical simplification.
In Proceedings of the 6th International Workshop on
Semantic Evaluation (SemEval 2012), pages 347–
355.
L. Specia. 2010. Translating from complex to simpli-
fied sentences. In Proceedings of the 9th interna-
tional conference on Computational Processing of
the Portuguese Language, pages 30–39.
Andreas Stolcke. 2002. SRILM – an extensible lan-
guage modeling toolkit. In Proceedings of the Sev-
enth International Conference on Spoken Language
Processing.
S. Vajjala and D. Meurers. 2012. On improving the
accuracy of readability classification using insights
from second language acquisition. In Proceedings
of the 7th Workshop on Innovative Use of NLP for
Building Educational Applications (BEA7), pages
163–173.
Kristian Woodsend and Mirella Lapata. 2011. Learn-
ing to Simplify Sentences with Quasi-Synchronous
Grammar and Integer Programming. In Proceed-
ings of the 2011 Conference on Empirical Methods
in Natural Language Processing (2011), pages 409–
420.
Mark Yatskar, Bo Pang, C. Danescu-Niculescu-Mizil,
and Lillian Lee. 2010. For the sake of simplic-
ity: Unsupervised extraction of lexical simplifica-
tions from Wikipedia. In Human Language Tech-
nologies: The 2010 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 365–368. Association for
Computational Linguistics.
Zhemin Zhu, Delphine Bernhard, and I. Gurevych.
2010. A monolingual tree-based translation model
for sentence simplification. In Proceedings of The
23rd International Conference on Computational
Linguistics, pages 1353–1361. Association for Com-
putational Linguistics.
</reference>
<page confidence="0.998973">
149
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.717083">
<title confidence="0.99701">Simple, readable sub-sentences</title>
<author confidence="0.980929">Sigrid</author>
<affiliation confidence="0.997815">Centre for Language University of</affiliation>
<email confidence="0.994964">sigridklerke@gmail.com</email>
<author confidence="0.805424">Anders</author>
<affiliation confidence="0.9987565">Centre for Language University of</affiliation>
<email confidence="0.939944">soegaard@hum.ku.dk</email>
<abstract confidence="0.998456375">We present experiments using a new unsupervised approach to automatic text simplification, which builds on sampling and ranking via a loss function informed by readability research. The main idea is that a loss function can distinguish good simplification candidates among randomly sampled sub-sentences of the input sentence. Our approach is rated as equally grammatical and beginner reader appropriate as a supervised SMT-based baseline system by native speakers, but our setup performs more radical changes that better resembles the variation observed in human generated simplifications.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S M Aluísio</author>
<author>Lucia Specia</author>
<author>T A S Pardo</author>
<author>E G Maziero</author>
<author>H M Caseli</author>
<author>R P M Fortes</author>
</authors>
<title>A corpus analysis of simple account texts and the proposal of simplification strategies: first steps towards text simplification systems.</title>
<date>2008</date>
<booktitle>In Proceedings of the 26th annual ACM international conference on Design of communication,</booktitle>
<pages>15--22</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1025" citStr="Aluísio et al., 2008" startWordPosition="142" endWordPosition="145"> The main idea is that a loss function can distinguish good simplification candidates among randomly sampled sub-sentences of the input sentence. Our approach is rated as equally grammatical and beginner reader appropriate as a supervised SMT-based baseline system by native speakers, but our setup performs more radical changes that better resembles the variation observed in human generated simplifications. 1 Introduction As a field of research in NLP, text simplification (TS) has gained increasing attention recently, primarily for English text, but also for Brazilian Portuguese (Specia, 2010; Aluísio et al., 2008), Dutch (Daelemans et al., 2004), Spanish (Drndarevic and Saggion, 2012), Danish (Klerke and Søgaard, 2012), French (Seretan, 2012) and Swedish (Rybing and Smith, 2009; Decker, 2003). Our experiments use Danish text which is similar to English in that it has a deep orthography making it hard to map between letters and sounds. Danish has a relatively free word order and sparse morfology. TS can help readers with below average reading skills access information and may supply relevant training material, which is crucial for developing reading skills. However, manual TS is as expensive as translat</context>
</contexts>
<marker>Aluísio, Specia, Pardo, Maziero, Caseli, Fortes, 2008</marker>
<rawString>S.M. Aluísio, Lucia Specia, T.A.S. Pardo, E.G. Maziero, H.M. Caseli, and R.P.M. Fortes. 2008. A corpus analysis of simple account texts and the proposal of simplification strategies: first steps towards text simplification systems. In Proceedings of the 26th annual ACM international conference on Design of communication, pages 15–22. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Anderson</author>
</authors>
<title>LIX and RIX: Variations on a little-known readability index.</title>
<date>1983</date>
<journal>Journal of Reading,</journal>
<volume>26</volume>
<issue>6</issue>
<contexts>
<context position="14981" citStr="Anderson, 1983" startWordPosition="2344" endWordPosition="2345">ce between the score of the input sentence and the candidate. Development data was used for tuning the weights of the loss function. Because the candidate-generation is free to produce extremely short candidates, we have to deal with candidates 6The LM was Knesser-Ney smoothed, using the same corpora as the baseline system, without punctuation and built using SRILM (Stolcke, 2002). 7LIX is similar to the English Flesch-Kincaid grade level in favoring short sentences with short words. The formula is LIX = average sentence length + % long words, with long words being of more than 6 characters. (Anderson, 1983) calculated a conversion from LIX to grade levels. 8suggested by(Petrov et al., 2011) receiving extremely low scores. Those scores never arise in the professionally simplified text, so we eliminate extreme candidates by introducing filters on all scores. The lower limit was tuned experimentally and fixed approximately two times below the average difference observed between the two parts of the aligned DSim corpus, thus limiting the reduction in PPL and LIX to 60% of the input’s PPL and LIX. The upper limit was fixed at the input-level plus 20% to allow more varied candidates through the filter</context>
</contexts>
<marker>Anderson, 1983</marker>
<rawString>Jonathan Anderson. 1983. LIX and RIX: Variations on a little-known readability index. Journal of Reading, 26(6):490–496.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Bjornsson</author>
</authors>
<date>1983</date>
<journal>Readability of Newspapers in 11 Languages. Reading Research Quarterly,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="8572" citStr="Bjornsson, 1983" startWordPosition="1327" endWordPosition="1329"> Katsos (2012), who seek to isolate the psycholinguistically motivated notions of sentence comprehension from sentence acceptability by actually measuring the effect of TS on cognition on a small scale. Readability research is a line of research that is more directly concerned with the nature of cognitive load in reading building on insights from psycholinguistics. One goal is to develop techniques and metrics for assessing the readability of unseen 143 text. Such metrics are used as a tool for teachers and publishers, but existing standard metrics (like Flesch-Kincaid (Flesch, 1948) and LIX (Bjornsson, 1983)) were designed and optimized for easy manual application to human written text, requiring thehuman reader to assess that the text is congruent and coherent. More recent methods promise to be applicable to unassessed text. Language modeling in particular has shown to be a robust and informative component of systems for assessing text readability (Schwarm and Ostendorf, 2005; Vajjala and Meurers, 2012) as it is better suited to evaluate grammaticality than standard metrics. We use language modeling alongside traditional metrics for selecting good simplification candidates. 4 Experiments 4.1 Bas</context>
<context position="14175" citStr="Bjornsson, 1983" startWordPosition="2214" endWordPosition="2215">ese relations restored. 4.3 Scoring We rank candidates according to a loss function incorporating both readability score (the lower, the more readable) and language model perplexity (the lower, the less perplexing) as described below. The loss function assigns values to the candidates such that the best simplification candidate receives the lowest score. The loss function is a weighted combination of three scores: perplexity (PPL), LIX and wordclass distribution (WCD). The PPL scores were obtained from a 5-gram language model of Danish6 We used the standard readability metric for Danish, LIX (Bjornsson, 1983)7. Finally, the WCD measured the variation in universal postag-distribution 8 compared to the observed tagvariation in the entire simplified corpus. For PPL and LIX we calculated the difference between the score of the input sentence and the candidate. Development data was used for tuning the weights of the loss function. Because the candidate-generation is free to produce extremely short candidates, we have to deal with candidates 6The LM was Knesser-Ney smoothed, using the same corpora as the baseline system, without punctuation and built using SRILM (Stolcke, 2002). 7LIX is similar to the E</context>
</contexts>
<marker>Bjornsson, 1983</marker>
<rawString>C. H. Bjornsson. 1983. Readability of Newspapers in 11 Languages. Reading Research Quarterly, 18(4):480–497.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Bohnet</author>
</authors>
<title>Very high accuracy and fast dependency parsing is not a contradiction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>89--97</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10745" citStr="Bohnet, 2010" startWordPosition="1677" endWordPosition="1678">owing Coster and Kauchak (2011), we used the phrase-based SMT Moses (Koehn et al., 2007), with GIZA++ wordalignment (Och and Ney, 2000) and phrase tables learned from the sentence aligned portion of the DSim corpus. 1http://korpus.dsl.dk/korpus2000/ engelsk_hovedside 2The LM was a 5-gram Knesser-Ney smoothed lowercase model, built using IRSTLM (Federico et al., 2008) 4.2 Experimental setup Three system variants were set up to generate simplified output from the original news wire of the development and test partitions of the DSim corpus. The texts were dependency-parsed using Bohnet’s parser (Bohnet, 2010) trained on the Danish Treebank3 (Kromann, 2003) with default settings4. 1. Split only performed simple sentence splitting. 2. Sample over-generated candidates by sampling the heuristically restricted space of random lexical deletions and ranking candidates with a loss function. 3. Combined is a combination of the two, applying the sampling procedure of Sample to the split sentences from Split. Sentence Splitting We implemented sentence splitting to extract relative clauses, as marked by the dependency relation rel, coordinated clauses, coord, and conjuncts, conj, when at least a verb and a no</context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>B Bohnet. 2010. Very high accuracy and fast dependency parsing is not a contradiction. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 89–97. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bott</author>
<author>H Saggion</author>
<author>D Figueroa</author>
</authors>
<title>A hybrid system for spanish text simplification.</title>
<date>2012</date>
<booktitle>In Third Workshop on Speech and Language Processing for Assistive Technologies (SLPAT),</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="5888" citStr="Bott et al., 2012" startWordPosition="907" endWordPosition="910">es are presented in the last section. 3 Related work Approaches for automatic TS traditionally focus on lexical substitution (De Belder and Moens, 2012; Specia et al., 2012; Yatskar et al., 2010), on identifying re-write rules at sentence level either manually (Chandrasekar et al., 1996; Carroll et al., 1999; Canning et al., 2000; Siddharthan, 2010; Siddharthan, 2011; Seretan, 2012) or automatically from parallel corpora (Woodsend and Lapata, 2011; Coster and Kauchak, 2011; Zhu et al., 2010) and possibly learning cues for when to apply such changes (Petersen and Ostendorf, 2007; Medero, 2011; Bott et al., 2012). Chandrasekar et al. (1996) propose a structural approach, which uses syntactic cues to recover relative clauses and appositives. Sentence level syntactic re-writing has since seen a variety of manually constructed general sentence splitting rules, designed to operate both on dependencies and phrase structure trees, and typically including lexical cues (Siddharthan, 2011; Heilman and Smith, 2010; Canning et al., 2000). Similar rules have been created from direct inspection of simplification corpora (Decker, 2003; Seretan, 2012) and discovered automatically from large scale aligned corpora (Wo</context>
</contexts>
<marker>Bott, Saggion, Figueroa, 2012</marker>
<rawString>S. Bott, H. Saggion, and D. Figueroa. 2012. A hybrid system for spanish text simplification. In Third Workshop on Speech and Language Processing for Assistive Technologies (SLPAT), Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julian Brooke</author>
<author>Vivian Tsang</author>
<author>David Jacob</author>
<author>Fraser Shein</author>
<author>Graeme Hirst</author>
</authors>
<title>Building Readability Lexicons with Unannotated Corpora.</title>
<date>2012</date>
<booktitle>In Proceedings of the First Workshop on Predicting and Improving Text Readability for target reader populations,</booktitle>
<pages>33--39</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr{é}al, Canada,</location>
<contexts>
<context position="7334" citStr="Brooke et al. (2012)" startWordPosition="1125" endWordPosition="1128">xical substitution from frequency counts and eliminate anaphora by resolving and replacing the referring expressions with the entity referred to. Their system further include compound sentence splitting and rewriting of passive sentences to active ones (Canning et al., 2000). Research into lexical simplification remains an active topic. De Belder and Moens (2012; Specia et al. (2012) are both recent publications of new resources for evaluating lexical simplification in English consisting of lists of synonyms ranked by human judges. Another type of resource is graded word-lists as described in Brooke et al. (2012). Annotator agreement and comparisons so far shows that it is easy to overfit to reflect individual annotator and domain differences that are not of relevance to generalized systems. In a minimally supervised setup, our TS approach can be modified to include lexical simplifications as part of the random generation process. This would require a broad coverage list of words and simpler synonyms, which could for instance be extracted from a parallel corpus like the DSim corpus. For the majority of research in automatic TS the question of what constitutes cognitive load is not discussed. An except</context>
</contexts>
<marker>Brooke, Tsang, Jacob, Shein, Hirst, 2012</marker>
<rawString>Julian Brooke, Vivian Tsang, David Jacob, Fraser Shein, and Graeme Hirst. 2012. Building Readability Lexicons with Unannotated Corpora. In Proceedings of the First Workshop on Predicting and Improving Text Readability for target reader populations, pages 33–39, Montr{é}al, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Canning</author>
<author>J Tait</author>
<author>J Archibald</author>
<author>R Crawley</author>
</authors>
<title>Cohesive generation of syntactically simplified newspaper text.</title>
<date>2000</date>
<publisher>Springer.</publisher>
<contexts>
<context position="5601" citStr="Canning et al., 2000" startWordPosition="861" endWordPosition="864">(Medero, 2011; Klerke, 2012) The next section positions this research in the context of related work. Section 4 presents the experimental setup including generation and evaluation. In Section 5, the results are presented and discussed and, finally, concluding remarks and future perspectives are presented in the last section. 3 Related work Approaches for automatic TS traditionally focus on lexical substitution (De Belder and Moens, 2012; Specia et al., 2012; Yatskar et al., 2010), on identifying re-write rules at sentence level either manually (Chandrasekar et al., 1996; Carroll et al., 1999; Canning et al., 2000; Siddharthan, 2010; Siddharthan, 2011; Seretan, 2012) or automatically from parallel corpora (Woodsend and Lapata, 2011; Coster and Kauchak, 2011; Zhu et al., 2010) and possibly learning cues for when to apply such changes (Petersen and Ostendorf, 2007; Medero, 2011; Bott et al., 2012). Chandrasekar et al. (1996) propose a structural approach, which uses syntactic cues to recover relative clauses and appositives. Sentence level syntactic re-writing has since seen a variety of manually constructed general sentence splitting rules, designed to operate both on dependencies and phrase structure t</context>
<context position="6989" citStr="Canning et al., 2000" startWordPosition="1070" endWordPosition="1073">f simplification corpora (Decker, 2003; Seretan, 2012) and discovered automatically from large scale aligned corpora (Woodsend and Lapata, 2011; Zhu et al., 2010). In our experiment we apply few basic sentence splitting rules as a pre-processing technique before using an over-generating random deletion approach. Carroll et al. (1999) perform lexical substitution from frequency counts and eliminate anaphora by resolving and replacing the referring expressions with the entity referred to. Their system further include compound sentence splitting and rewriting of passive sentences to active ones (Canning et al., 2000). Research into lexical simplification remains an active topic. De Belder and Moens (2012; Specia et al. (2012) are both recent publications of new resources for evaluating lexical simplification in English consisting of lists of synonyms ranked by human judges. Another type of resource is graded word-lists as described in Brooke et al. (2012). Annotator agreement and comparisons so far shows that it is easy to overfit to reflect individual annotator and domain differences that are not of relevance to generalized systems. In a minimally supervised setup, our TS approach can be modified to incl</context>
</contexts>
<marker>Canning, Tait, Archibald, Crawley, 2000</marker>
<rawString>Y. Canning, J. Tait, J. Archibald, and R. Crawley. 2000. Cohesive generation of syntactically simplified newspaper text. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>G Minnen</author>
<author>D Pearce</author>
<author>Yvonne Canning</author>
<author>S Devlin</author>
<author>J Tait</author>
</authors>
<title>Simplifying text for language-impaired readers.</title>
<date>1999</date>
<booktitle>In Proceedings of EACL,</booktitle>
<volume>99</volume>
<pages>269--270</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="5579" citStr="Carroll et al., 1999" startWordPosition="857" endWordPosition="860">ally simplified text. (Medero, 2011; Klerke, 2012) The next section positions this research in the context of related work. Section 4 presents the experimental setup including generation and evaluation. In Section 5, the results are presented and discussed and, finally, concluding remarks and future perspectives are presented in the last section. 3 Related work Approaches for automatic TS traditionally focus on lexical substitution (De Belder and Moens, 2012; Specia et al., 2012; Yatskar et al., 2010), on identifying re-write rules at sentence level either manually (Chandrasekar et al., 1996; Carroll et al., 1999; Canning et al., 2000; Siddharthan, 2010; Siddharthan, 2011; Seretan, 2012) or automatically from parallel corpora (Woodsend and Lapata, 2011; Coster and Kauchak, 2011; Zhu et al., 2010) and possibly learning cues for when to apply such changes (Petersen and Ostendorf, 2007; Medero, 2011; Bott et al., 2012). Chandrasekar et al. (1996) propose a structural approach, which uses syntactic cues to recover relative clauses and appositives. Sentence level syntactic re-writing has since seen a variety of manually constructed general sentence splitting rules, designed to operate both on dependencies </context>
</contexts>
<marker>Carroll, Minnen, Pearce, Canning, Devlin, Tait, 1999</marker>
<rawString>John Carroll, G. Minnen, D. Pearce, Yvonne Canning, S. Devlin, and J. Tait. 1999. Simplifying text for language-impaired readers. In Proceedings of EACL, volume 99, pages 269–270. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Chandrasekar</author>
<author>Christine Doran</author>
<author>B Srinivas</author>
</authors>
<title>Motivations and methods for text simplification.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th conference on Computational linguistics-Volume 2,</booktitle>
<pages>1041--1044</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5557" citStr="Chandrasekar et al., 1996" startWordPosition="853" endWordPosition="856">n be observed in professionally simplified text. (Medero, 2011; Klerke, 2012) The next section positions this research in the context of related work. Section 4 presents the experimental setup including generation and evaluation. In Section 5, the results are presented and discussed and, finally, concluding remarks and future perspectives are presented in the last section. 3 Related work Approaches for automatic TS traditionally focus on lexical substitution (De Belder and Moens, 2012; Specia et al., 2012; Yatskar et al., 2010), on identifying re-write rules at sentence level either manually (Chandrasekar et al., 1996; Carroll et al., 1999; Canning et al., 2000; Siddharthan, 2010; Siddharthan, 2011; Seretan, 2012) or automatically from parallel corpora (Woodsend and Lapata, 2011; Coster and Kauchak, 2011; Zhu et al., 2010) and possibly learning cues for when to apply such changes (Petersen and Ostendorf, 2007; Medero, 2011; Bott et al., 2012). Chandrasekar et al. (1996) propose a structural approach, which uses syntactic cues to recover relative clauses and appositives. Sentence level syntactic re-writing has since seen a variety of manually constructed general sentence splitting rules, designed to operate</context>
</contexts>
<marker>Chandrasekar, Doran, Srinivas, 1996</marker>
<rawString>R. Chandrasekar, Christine Doran, and B Srinivas. 1996. Motivations and methods for text simplification. In Proceedings of the 16th conference on Computational linguistics-Volume 2, pages 1041–1044. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Coster</author>
<author>David Kauchak</author>
</authors>
<title>Simple English Wikipedia: a new text simplification task.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short</booktitle>
<volume>2</volume>
<pages>665--669</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5747" citStr="Coster and Kauchak, 2011" startWordPosition="882" endWordPosition="885">p including generation and evaluation. In Section 5, the results are presented and discussed and, finally, concluding remarks and future perspectives are presented in the last section. 3 Related work Approaches for automatic TS traditionally focus on lexical substitution (De Belder and Moens, 2012; Specia et al., 2012; Yatskar et al., 2010), on identifying re-write rules at sentence level either manually (Chandrasekar et al., 1996; Carroll et al., 1999; Canning et al., 2000; Siddharthan, 2010; Siddharthan, 2011; Seretan, 2012) or automatically from parallel corpora (Woodsend and Lapata, 2011; Coster and Kauchak, 2011; Zhu et al., 2010) and possibly learning cues for when to apply such changes (Petersen and Ostendorf, 2007; Medero, 2011; Bott et al., 2012). Chandrasekar et al. (1996) propose a structural approach, which uses syntactic cues to recover relative clauses and appositives. Sentence level syntactic re-writing has since seen a variety of manually constructed general sentence splitting rules, designed to operate both on dependencies and phrase structure trees, and typically including lexical cues (Siddharthan, 2011; Heilman and Smith, 2010; Canning et al., 2000). Similar rules have been created fro</context>
<context position="10163" citStr="Coster and Kauchak (2011)" startWordPosition="1588" endWordPosition="1591">ting from normal news wire text to simplified news. To train an SMT system, a large resource of aligned parallel text and a language model of the target language are needed. We combined the 25 million words Danish Korpus 20001 with the entire 1.75 million words unaligned DSim corpus (Klerke and Søgaard, 2012) to build the language model2. Including both corpora gives better coverage and assigns lower average ppl and a simlar difference in average ppl between the two sides of a held out part of the DSim corpus compared to using only the simplified part of DSim for the language model. Following Coster and Kauchak (2011), we used the phrase-based SMT Moses (Koehn et al., 2007), with GIZA++ wordalignment (Och and Ney, 2000) and phrase tables learned from the sentence aligned portion of the DSim corpus. 1http://korpus.dsl.dk/korpus2000/ engelsk_hovedside 2The LM was a 5-gram Knesser-Ney smoothed lowercase model, built using IRSTLM (Federico et al., 2008) 4.2 Experimental setup Three system variants were set up to generate simplified output from the original news wire of the development and test partitions of the DSim corpus. The texts were dependency-parsed using Bohnet’s parser (Bohnet, 2010) trained on the Da</context>
</contexts>
<marker>Coster, Kauchak, 2011</marker>
<rawString>William Coster and David Kauchak. 2011. Simple English Wikipedia: a new text simplification task. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2, volume 2, pages 665–669. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>A Höthker</author>
<author>E T K Sang</author>
</authors>
<title>Automatic sentence simplification for subtitling in dutch and english.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation,</booktitle>
<pages>1045--1048</pages>
<contexts>
<context position="1057" citStr="Daelemans et al., 2004" startWordPosition="147" endWordPosition="150">function can distinguish good simplification candidates among randomly sampled sub-sentences of the input sentence. Our approach is rated as equally grammatical and beginner reader appropriate as a supervised SMT-based baseline system by native speakers, but our setup performs more radical changes that better resembles the variation observed in human generated simplifications. 1 Introduction As a field of research in NLP, text simplification (TS) has gained increasing attention recently, primarily for English text, but also for Brazilian Portuguese (Specia, 2010; Aluísio et al., 2008), Dutch (Daelemans et al., 2004), Spanish (Drndarevic and Saggion, 2012), Danish (Klerke and Søgaard, 2012), French (Seretan, 2012) and Swedish (Rybing and Smith, 2009; Decker, 2003). Our experiments use Danish text which is similar to English in that it has a deep orthography making it hard to map between letters and sounds. Danish has a relatively free word order and sparse morfology. TS can help readers with below average reading skills access information and may supply relevant training material, which is crucial for developing reading skills. However, manual TS is as expensive as translation, which is a key limiting fac</context>
</contexts>
<marker>Daelemans, Höthker, Sang, 2004</marker>
<rawString>W. Daelemans, A. Höthker, and E.T.K. Sang. 2004. Automatic sentence simplification for subtitling in dutch and english. In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 1045–1048.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Davison</author>
<author>R N Kantor</author>
</authors>
<title>On the failure of readability formulas to define readable texts: A case study from adaptations. Reading Research Quarterly,</title>
<date>1982</date>
<pages>187--209</pages>
<marker>Davison, Kantor, 1982</marker>
<rawString>A. Davison and R.N. Kantor. 1982. On the failure of readability formulas to define readable texts: A case study from adaptations. Reading Research Quarterly, pages 187–209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J De Belder</author>
<author>M F Moens</author>
</authors>
<title>A dataset for the evaluation of lexical simplification.</title>
<date>2012</date>
<booktitle>Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>426--437</pages>
<marker>De Belder, Moens, 2012</marker>
<rawString>J. De Belder and M.F. Moens. 2012. A dataset for the evaluation of lexical simplification. Computational Linguistics and Intelligent Text Processing, pages 426–437.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Decker</author>
</authors>
<title>Towards automatic grammatical simplification of Swedish text. Master’s thesis,</title>
<date>2003</date>
<institution>Stockholm University.</institution>
<contexts>
<context position="1207" citStr="Decker, 2003" startWordPosition="171" endWordPosition="172"> and beginner reader appropriate as a supervised SMT-based baseline system by native speakers, but our setup performs more radical changes that better resembles the variation observed in human generated simplifications. 1 Introduction As a field of research in NLP, text simplification (TS) has gained increasing attention recently, primarily for English text, but also for Brazilian Portuguese (Specia, 2010; Aluísio et al., 2008), Dutch (Daelemans et al., 2004), Spanish (Drndarevic and Saggion, 2012), Danish (Klerke and Søgaard, 2012), French (Seretan, 2012) and Swedish (Rybing and Smith, 2009; Decker, 2003). Our experiments use Danish text which is similar to English in that it has a deep orthography making it hard to map between letters and sounds. Danish has a relatively free word order and sparse morfology. TS can help readers with below average reading skills access information and may supply relevant training material, which is crucial for developing reading skills. However, manual TS is as expensive as translation, which is a key limiting factor on the availability of easy-to-read material. One of the persistent chalenges of TS is that different interventions are called for depending on th</context>
<context position="6406" citStr="Decker, 2003" startWordPosition="986" endWordPosition="987">for when to apply such changes (Petersen and Ostendorf, 2007; Medero, 2011; Bott et al., 2012). Chandrasekar et al. (1996) propose a structural approach, which uses syntactic cues to recover relative clauses and appositives. Sentence level syntactic re-writing has since seen a variety of manually constructed general sentence splitting rules, designed to operate both on dependencies and phrase structure trees, and typically including lexical cues (Siddharthan, 2011; Heilman and Smith, 2010; Canning et al., 2000). Similar rules have been created from direct inspection of simplification corpora (Decker, 2003; Seretan, 2012) and discovered automatically from large scale aligned corpora (Woodsend and Lapata, 2011; Zhu et al., 2010). In our experiment we apply few basic sentence splitting rules as a pre-processing technique before using an over-generating random deletion approach. Carroll et al. (1999) perform lexical substitution from frequency counts and eliminate anaphora by resolving and replacing the referring expressions with the entity referred to. Their system further include compound sentence splitting and rewriting of passive sentences to active ones (Canning et al., 2000). Research into l</context>
</contexts>
<marker>Decker, 2003</marker>
<rawString>Anna Decker. 2003. Towards automatic grammatical simplification of Swedish text. Master’s thesis, Stockholm University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Biljana Drndarevic</author>
<author>Horacio Saggion</author>
</authors>
<title>Towards Automatic Lexical Simplification in Spanish: An Empirical Study.</title>
<date>2012</date>
<booktitle>In Proceedings of the First Workshop on Predicting and Improving Text Readability for target reader populations,</booktitle>
<pages>8--16</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr{é}al, Canada,</location>
<contexts>
<context position="1097" citStr="Drndarevic and Saggion, 2012" startWordPosition="152" endWordPosition="155">lification candidates among randomly sampled sub-sentences of the input sentence. Our approach is rated as equally grammatical and beginner reader appropriate as a supervised SMT-based baseline system by native speakers, but our setup performs more radical changes that better resembles the variation observed in human generated simplifications. 1 Introduction As a field of research in NLP, text simplification (TS) has gained increasing attention recently, primarily for English text, but also for Brazilian Portuguese (Specia, 2010; Aluísio et al., 2008), Dutch (Daelemans et al., 2004), Spanish (Drndarevic and Saggion, 2012), Danish (Klerke and Søgaard, 2012), French (Seretan, 2012) and Swedish (Rybing and Smith, 2009; Decker, 2003). Our experiments use Danish text which is similar to English in that it has a deep orthography making it hard to map between letters and sounds. Danish has a relatively free word order and sparse morfology. TS can help readers with below average reading skills access information and may supply relevant training material, which is crucial for developing reading skills. However, manual TS is as expensive as translation, which is a key limiting factor on the availability of easy-to-read </context>
</contexts>
<marker>Drndarevic, Saggion, 2012</marker>
<rawString>Biljana Drndarevic and Horacio Saggion. 2012. Towards Automatic Lexical Simplification in Spanish: An Empirical Study. In Proceedings of the First Workshop on Predicting and Improving Text Readability for target reader populations, pages 8–16, Montr{é}al, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>M Cettolo</author>
</authors>
<title>IRSTLM: an open source toolkit for handling large scale language models.</title>
<date>2008</date>
<booktitle>In Ninth Annual Conference of the International Speech Communication Association.</booktitle>
<contexts>
<context position="10501" citStr="Federico et al., 2008" startWordPosition="1637" endWordPosition="1640">Including both corpora gives better coverage and assigns lower average ppl and a simlar difference in average ppl between the two sides of a held out part of the DSim corpus compared to using only the simplified part of DSim for the language model. Following Coster and Kauchak (2011), we used the phrase-based SMT Moses (Koehn et al., 2007), with GIZA++ wordalignment (Och and Ney, 2000) and phrase tables learned from the sentence aligned portion of the DSim corpus. 1http://korpus.dsl.dk/korpus2000/ engelsk_hovedside 2The LM was a 5-gram Knesser-Ney smoothed lowercase model, built using IRSTLM (Federico et al., 2008) 4.2 Experimental setup Three system variants were set up to generate simplified output from the original news wire of the development and test partitions of the DSim corpus. The texts were dependency-parsed using Bohnet’s parser (Bohnet, 2010) trained on the Danish Treebank3 (Kromann, 2003) with default settings4. 1. Split only performed simple sentence splitting. 2. Sample over-generated candidates by sampling the heuristically restricted space of random lexical deletions and ranking candidates with a loss function. 3. Combined is a combination of the two, applying the sampling procedure of </context>
</contexts>
<marker>Federico, Bertoldi, Cettolo, 2008</marker>
<rawString>M Federico, N Bertoldi, and M Cettolo. 2008. IRSTLM: an open source toolkit for handling large scale language models. In Ninth Annual Conference of the International Speech Communication Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rudolph Flesch</author>
</authors>
<title>A new readability yardstick.</title>
<date>1948</date>
<journal>Journal of applied psychology,</journal>
<volume>32</volume>
<issue>3</issue>
<contexts>
<context position="8546" citStr="Flesch, 1948" startWordPosition="1323" endWordPosition="1324">tion is Siddharthan and Katsos (2012), who seek to isolate the psycholinguistically motivated notions of sentence comprehension from sentence acceptability by actually measuring the effect of TS on cognition on a small scale. Readability research is a line of research that is more directly concerned with the nature of cognitive load in reading building on insights from psycholinguistics. One goal is to develop techniques and metrics for assessing the readability of unseen 143 text. Such metrics are used as a tool for teachers and publishers, but existing standard metrics (like Flesch-Kincaid (Flesch, 1948) and LIX (Bjornsson, 1983)) were designed and optimized for easy manual application to human written text, requiring thehuman reader to assess that the text is congruent and coherent. More recent methods promise to be applicable to unassessed text. Language modeling in particular has shown to be a robust and informative component of systems for assessing text readability (Schwarm and Ostendorf, 2005; Vajjala and Meurers, 2012) as it is better suited to evaluate grammaticality than standard metrics. We use language modeling alongside traditional metrics for selecting good simplification candida</context>
</contexts>
<marker>Flesch, 1948</marker>
<rawString>Rudolph Flesch. 1948. A new readability yardstick. Journal of applied psychology, 32(3):221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Heilman</author>
<author>Noah A Smith</author>
</authors>
<title>Extracting simplified statements for factual question generation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Third Workshop on Question Generation.</booktitle>
<contexts>
<context position="6287" citStr="Heilman and Smith, 2010" startWordPosition="966" endWordPosition="969">atically from parallel corpora (Woodsend and Lapata, 2011; Coster and Kauchak, 2011; Zhu et al., 2010) and possibly learning cues for when to apply such changes (Petersen and Ostendorf, 2007; Medero, 2011; Bott et al., 2012). Chandrasekar et al. (1996) propose a structural approach, which uses syntactic cues to recover relative clauses and appositives. Sentence level syntactic re-writing has since seen a variety of manually constructed general sentence splitting rules, designed to operate both on dependencies and phrase structure trees, and typically including lexical cues (Siddharthan, 2011; Heilman and Smith, 2010; Canning et al., 2000). Similar rules have been created from direct inspection of simplification corpora (Decker, 2003; Seretan, 2012) and discovered automatically from large scale aligned corpora (Woodsend and Lapata, 2011; Zhu et al., 2010). In our experiment we apply few basic sentence splitting rules as a pre-processing technique before using an over-generating random deletion approach. Carroll et al. (1999) perform lexical substitution from frequency counts and eliminate anaphora by resolving and replacing the referring expressions with the entity referred to. Their system further includ</context>
</contexts>
<marker>Heilman, Smith, 2010</marker>
<rawString>Michael Heilman and Noah A Smith. 2010. Extracting simplified statements for factual question generation. In Proceedings of the Third Workshop on Question Generation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sigrid Klerke</author>
<author>Anders Søgaard</author>
</authors>
<title>DSim , a Danish Parallel Corpus for Text Simplification.</title>
<date>2012</date>
<booktitle>In Proceedings of Language Resources and Evaluation (LREC</booktitle>
<pages>4015--4018</pages>
<contexts>
<context position="1132" citStr="Klerke and Søgaard, 2012" startWordPosition="157" endWordPosition="160">mpled sub-sentences of the input sentence. Our approach is rated as equally grammatical and beginner reader appropriate as a supervised SMT-based baseline system by native speakers, but our setup performs more radical changes that better resembles the variation observed in human generated simplifications. 1 Introduction As a field of research in NLP, text simplification (TS) has gained increasing attention recently, primarily for English text, but also for Brazilian Portuguese (Specia, 2010; Aluísio et al., 2008), Dutch (Daelemans et al., 2004), Spanish (Drndarevic and Saggion, 2012), Danish (Klerke and Søgaard, 2012), French (Seretan, 2012) and Swedish (Rybing and Smith, 2009; Decker, 2003). Our experiments use Danish text which is similar to English in that it has a deep orthography making it hard to map between letters and sounds. Danish has a relatively free word order and sparse morfology. TS can help readers with below average reading skills access information and may supply relevant training material, which is crucial for developing reading skills. However, manual TS is as expensive as translation, which is a key limiting factor on the availability of easy-to-read material. One of the persistent cha</context>
<context position="9401" citStr="Klerke and Søgaard, 2012" startWordPosition="1457" endWordPosition="1460">o unassessed text. Language modeling in particular has shown to be a robust and informative component of systems for assessing text readability (Schwarm and Ostendorf, 2005; Vajjala and Meurers, 2012) as it is better suited to evaluate grammaticality than standard metrics. We use language modeling alongside traditional metrics for selecting good simplification candidates. 4 Experiments 4.1 Baseline Systems We used the original input text and the human simplified text from the sentence aligned DSim corpus which consist of 48k original and manually simplified sentences of Danish news wire text (Klerke and Søgaard, 2012) as reference in the evaluations. In addition we trained a statistical machine translation (SMT) simplification system, in effect translating from normal news wire text to simplified news. To train an SMT system, a large resource of aligned parallel text and a language model of the target language are needed. We combined the 25 million words Danish Korpus 20001 with the entire 1.75 million words unaligned DSim corpus (Klerke and Søgaard, 2012) to build the language model2. Including both corpora gives better coverage and assigns lower average ppl and a simlar difference in average ppl between </context>
</contexts>
<marker>Klerke, Søgaard, 2012</marker>
<rawString>Sigrid Klerke and Anders Søgaard. 2012. DSim , a Danish Parallel Corpus for Text Simplification. In Proceedings of Language Resources and Evaluation (LREC 2012), pages 4015–4018.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sigrid Klerke</author>
</authors>
<title>Automatic text simplification in danish. sampling a restricted space of rewrites to optimize readability using lexical substitutions and dependency analyses. Master’s thesis,</title>
<date>2012</date>
<institution>University of Copenhagen.</institution>
<contexts>
<context position="5009" citStr="Klerke, 2012" startWordPosition="770" endWordPosition="771">ndidates, we restrict the search space under the assumption that some general patterns apply, namely, that the main verb and subject should always be kept, negations should be kept and that if something is kept that originally had objects, those objects should also be kept. Another way in which we restrict the candidate space is by splitting long sentences. Some clauses are simple to identify and extract, like relative clauses, and doing so can dramatically reduce sentence length. Both simple deletions and extraction of clauses can be observed in professionally simplified text. (Medero, 2011; Klerke, 2012) The next section positions this research in the context of related work. Section 4 presents the experimental setup including generation and evaluation. In Section 5, the results are presented and discussed and, finally, concluding remarks and future perspectives are presented in the last section. 3 Related work Approaches for automatic TS traditionally focus on lexical substitution (De Belder and Moens, 2012; Specia et al., 2012; Yatskar et al., 2010), on identifying re-write rules at sentence level either manually (Chandrasekar et al., 1996; Carroll et al., 1999; Canning et al., 2000; Siddha</context>
<context position="12634" citStr="Klerke, 2012" startWordPosition="1974" endWordPosition="1975">ubj, and object relations, *obj, and negating modifiers (the Danish word ikke) under the assumption that these were most likely to be important for preserving semantics and generating wellformed candidates under the sampling procedure described below. The heuristics were applied both to trees, acting by preserving entire subtrees and applied to words, only preserving single tokens. 3http://ilk.uvt.nl/conll/post_task_ data.html 4Performance of the parser on the treebank test set Labeled attatchment score (LAS) = 85.65 and Unlabeled attatchment score (UAS) = 90.29 5For a formal description see (Klerke, 2012) 144 This serves as a way of avoiding relying heavily on possibly faulty dependency analyses and also avoid the risk of insisting on keeping long, complex or superfluous modifiers. Sampling Candidates for scoring were overgenerated by randomly selecting parts of a (possibly split) input sentence. Either the selected nodes with their full sub-tree or the single tokens from the flat list of tokens were eliminated, unless they were previously selected for preservation by a heuristic. Some additional interaction between heuristics and sampling happened when the deletions were performed on trees: d</context>
</contexts>
<marker>Klerke, 2012</marker>
<rawString>Sigrid Klerke. 2012. Automatic text simplification in danish. sampling a restricted space of rewrites to optimize readability using lexical substitutions and dependency analyses. Master’s thesis, University of Copenhagen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>Others</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10220" citStr="Koehn et al., 2007" startWordPosition="1598" endWordPosition="1601"> SMT system, a large resource of aligned parallel text and a language model of the target language are needed. We combined the 25 million words Danish Korpus 20001 with the entire 1.75 million words unaligned DSim corpus (Klerke and Søgaard, 2012) to build the language model2. Including both corpora gives better coverage and assigns lower average ppl and a simlar difference in average ppl between the two sides of a held out part of the DSim corpus compared to using only the simplified part of DSim for the language model. Following Coster and Kauchak (2011), we used the phrase-based SMT Moses (Koehn et al., 2007), with GIZA++ wordalignment (Och and Ney, 2000) and phrase tables learned from the sentence aligned portion of the DSim corpus. 1http://korpus.dsl.dk/korpus2000/ engelsk_hovedside 2The LM was a 5-gram Knesser-Ney smoothed lowercase model, built using IRSTLM (Federico et al., 2008) 4.2 Experimental setup Three system variants were set up to generate simplified output from the original news wire of the development and test partitions of the DSim corpus. The texts were dependency-parsed using Bohnet’s parser (Bohnet, 2010) trained on the Danish Treebank3 (Kromann, 2003) with default settings4. 1.</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Others, 2007</marker>
<rawString>P Koehn, H Hoang, A Birch, C Callison-Burch, M Federico, N Bertoldi, B Cowan, W Shen, C Moran, R Zens, and Others. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, pages 177–180. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M T Kromann</author>
</authors>
<title>The Danish Dependency Treebank and the DTAG treebank tool.</title>
<date>2003</date>
<booktitle>In Proceedings of the Second Workshop on Treebanks and Linguistic Theories (TLT),</booktitle>
<pages>217</pages>
<contexts>
<context position="10793" citStr="Kromann, 2003" startWordPosition="1684" endWordPosition="1685">rase-based SMT Moses (Koehn et al., 2007), with GIZA++ wordalignment (Och and Ney, 2000) and phrase tables learned from the sentence aligned portion of the DSim corpus. 1http://korpus.dsl.dk/korpus2000/ engelsk_hovedside 2The LM was a 5-gram Knesser-Ney smoothed lowercase model, built using IRSTLM (Federico et al., 2008) 4.2 Experimental setup Three system variants were set up to generate simplified output from the original news wire of the development and test partitions of the DSim corpus. The texts were dependency-parsed using Bohnet’s parser (Bohnet, 2010) trained on the Danish Treebank3 (Kromann, 2003) with default settings4. 1. Split only performed simple sentence splitting. 2. Sample over-generated candidates by sampling the heuristically restricted space of random lexical deletions and ranking candidates with a loss function. 3. Combined is a combination of the two, applying the sampling procedure of Sample to the split sentences from Split. Sentence Splitting We implemented sentence splitting to extract relative clauses, as marked by the dependency relation rel, coordinated clauses, coord, and conjuncts, conj, when at least a verb and a noun is left in each part of the split. Only split</context>
</contexts>
<marker>Kromann, 2003</marker>
<rawString>M T Kromann. 2003. The Danish Dependency Treebank and the DTAG treebank tool. In Proceedings of the Second Workshop on Treebanks and Linguistic Theories (TLT), page 217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie Medero</author>
</authors>
<title>Identifying Targets for Syntactic Simplification.</title>
<date>2011</date>
<booktitle>In Proceedings of Speech and Language Technology in Education.</booktitle>
<contexts>
<context position="4994" citStr="Medero, 2011" startWordPosition="768" endWordPosition="769">mpling good candidates, we restrict the search space under the assumption that some general patterns apply, namely, that the main verb and subject should always be kept, negations should be kept and that if something is kept that originally had objects, those objects should also be kept. Another way in which we restrict the candidate space is by splitting long sentences. Some clauses are simple to identify and extract, like relative clauses, and doing so can dramatically reduce sentence length. Both simple deletions and extraction of clauses can be observed in professionally simplified text. (Medero, 2011; Klerke, 2012) The next section positions this research in the context of related work. Section 4 presents the experimental setup including generation and evaluation. In Section 5, the results are presented and discussed and, finally, concluding remarks and future perspectives are presented in the last section. 3 Related work Approaches for automatic TS traditionally focus on lexical substitution (De Belder and Moens, 2012; Specia et al., 2012; Yatskar et al., 2010), on identifying re-write rules at sentence level either manually (Chandrasekar et al., 1996; Carroll et al., 1999; Canning et al</context>
</contexts>
<marker>Medero, 2011</marker>
<rawString>Julie Medero. 2011. Identifying Targets for Syntactic Simplification. In Proceedings of Speech and Language Technology in Education.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A comparison of alignment models for statistical machine translation.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th conference on Computational linguistics-Volume 2,</booktitle>
<pages>1086--1090</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10267" citStr="Och and Ney, 2000" startWordPosition="1606" endWordPosition="1609">l text and a language model of the target language are needed. We combined the 25 million words Danish Korpus 20001 with the entire 1.75 million words unaligned DSim corpus (Klerke and Søgaard, 2012) to build the language model2. Including both corpora gives better coverage and assigns lower average ppl and a simlar difference in average ppl between the two sides of a held out part of the DSim corpus compared to using only the simplified part of DSim for the language model. Following Coster and Kauchak (2011), we used the phrase-based SMT Moses (Koehn et al., 2007), with GIZA++ wordalignment (Och and Ney, 2000) and phrase tables learned from the sentence aligned portion of the DSim corpus. 1http://korpus.dsl.dk/korpus2000/ engelsk_hovedside 2The LM was a 5-gram Knesser-Ney smoothed lowercase model, built using IRSTLM (Federico et al., 2008) 4.2 Experimental setup Three system variants were set up to generate simplified output from the original news wire of the development and test partitions of the DSim corpus. The texts were dependency-parsed using Bohnet’s parser (Bohnet, 2010) trained on the Danish Treebank3 (Kromann, 2003) with default settings4. 1. Split only performed simple sentence splitting</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F.J. Och and H. Ney. 2000. A comparison of alignment models for statistical machine translation. In Proceedings of the 18th conference on Computational linguistics-Volume 2, pages 1086–1090. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S E E Petersen</author>
<author>Mari Ostendorf</author>
</authors>
<title>Text simplification for language learners: a corpus analysis.</title>
<date>2007</date>
<booktitle>In the Proceedings of the Speech and Language Technology for Education Workshop,</booktitle>
<pages>69--72</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="5854" citStr="Petersen and Ostendorf, 2007" startWordPosition="901" endWordPosition="904">ly, concluding remarks and future perspectives are presented in the last section. 3 Related work Approaches for automatic TS traditionally focus on lexical substitution (De Belder and Moens, 2012; Specia et al., 2012; Yatskar et al., 2010), on identifying re-write rules at sentence level either manually (Chandrasekar et al., 1996; Carroll et al., 1999; Canning et al., 2000; Siddharthan, 2010; Siddharthan, 2011; Seretan, 2012) or automatically from parallel corpora (Woodsend and Lapata, 2011; Coster and Kauchak, 2011; Zhu et al., 2010) and possibly learning cues for when to apply such changes (Petersen and Ostendorf, 2007; Medero, 2011; Bott et al., 2012). Chandrasekar et al. (1996) propose a structural approach, which uses syntactic cues to recover relative clauses and appositives. Sentence level syntactic re-writing has since seen a variety of manually constructed general sentence splitting rules, designed to operate both on dependencies and phrase structure trees, and typically including lexical cues (Siddharthan, 2011; Heilman and Smith, 2010; Canning et al., 2000). Similar rules have been created from direct inspection of simplification corpora (Decker, 2003; Seretan, 2012) and discovered automatically fr</context>
</contexts>
<marker>Petersen, Ostendorf, 2007</marker>
<rawString>S.E. E Petersen and Mari Ostendorf. 2007. Text simplification for language learners: a corpus analysis. In the Proceedings of the Speech and Language Technology for Education Workshop, pages 69–72. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>D Das</author>
<author>R McDonald</author>
</authors>
<title>A universal part-of-speech tagset. Arxiv preprint ArXiv:1104.2086.</title>
<date>2011</date>
<contexts>
<context position="15066" citStr="Petrov et al., 2011" startWordPosition="2355" endWordPosition="2358">as used for tuning the weights of the loss function. Because the candidate-generation is free to produce extremely short candidates, we have to deal with candidates 6The LM was Knesser-Ney smoothed, using the same corpora as the baseline system, without punctuation and built using SRILM (Stolcke, 2002). 7LIX is similar to the English Flesch-Kincaid grade level in favoring short sentences with short words. The formula is LIX = average sentence length + % long words, with long words being of more than 6 characters. (Anderson, 1983) calculated a conversion from LIX to grade levels. 8suggested by(Petrov et al., 2011) receiving extremely low scores. Those scores never arise in the professionally simplified text, so we eliminate extreme candidates by introducing filters on all scores. The lower limit was tuned experimentally and fixed approximately two times below the average difference observed between the two parts of the aligned DSim corpus, thus limiting the reduction in PPL and LIX to 60% of the input’s PPL and LIX. The upper limit was fixed at the input-level plus 20% to allow more varied candidates through the filters. The WCD-filter accepted all candidates with a tag-variance that fell below the 75-</context>
</contexts>
<marker>Petrov, Das, McDonald, 2011</marker>
<rawString>S. Petrov, D. Das, and R. McDonald. 2011. A universal part-of-speech tagset. Arxiv preprint ArXiv:1104.2086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
<author>Ani Nenkova</author>
</authors>
<title>Revisiting readability: A unified framework for predicting text quality.</title>
<date>2008</date>
<booktitle>Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<marker>Pitler, Nenkova, 2008</marker>
<rawString>Emily Pitler and Ani Nenkova. 2008. Revisiting readability: A unified framework for predicting text quality. Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonas Rybing</author>
<author>Christian Smith</author>
</authors>
<title>CogFLUX Grunden till ett automatiskt textförenklingssystem för svenska. Master’s thesis,</title>
<date>2009</date>
<institution>Linköpings Universitet.</institution>
<contexts>
<context position="1192" citStr="Rybing and Smith, 2009" startWordPosition="166" endWordPosition="170">d as equally grammatical and beginner reader appropriate as a supervised SMT-based baseline system by native speakers, but our setup performs more radical changes that better resembles the variation observed in human generated simplifications. 1 Introduction As a field of research in NLP, text simplification (TS) has gained increasing attention recently, primarily for English text, but also for Brazilian Portuguese (Specia, 2010; Aluísio et al., 2008), Dutch (Daelemans et al., 2004), Spanish (Drndarevic and Saggion, 2012), Danish (Klerke and Søgaard, 2012), French (Seretan, 2012) and Swedish (Rybing and Smith, 2009; Decker, 2003). Our experiments use Danish text which is similar to English in that it has a deep orthography making it hard to map between letters and sounds. Danish has a relatively free word order and sparse morfology. TS can help readers with below average reading skills access information and may supply relevant training material, which is crucial for developing reading skills. However, manual TS is as expensive as translation, which is a key limiting factor on the availability of easy-to-read material. One of the persistent chalenges of TS is that different interventions are called for </context>
</contexts>
<marker>Rybing, Smith, 2009</marker>
<rawString>Jonas Rybing and Christian Smith. 2009. CogFLUX Grunden till ett automatiskt textförenklingssystem för svenska. Master’s thesis, Linköpings Universitet.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarah E Schwarm</author>
<author>Mari Ostendorf</author>
</authors>
<title>Reading Level Assessment Using Support Vector Machines and Statistical Language Models.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the ACL,</booktitle>
<pages>523--530</pages>
<contexts>
<context position="8948" citStr="Schwarm and Ostendorf, 2005" startWordPosition="1385" endWordPosition="1389">s. One goal is to develop techniques and metrics for assessing the readability of unseen 143 text. Such metrics are used as a tool for teachers and publishers, but existing standard metrics (like Flesch-Kincaid (Flesch, 1948) and LIX (Bjornsson, 1983)) were designed and optimized for easy manual application to human written text, requiring thehuman reader to assess that the text is congruent and coherent. More recent methods promise to be applicable to unassessed text. Language modeling in particular has shown to be a robust and informative component of systems for assessing text readability (Schwarm and Ostendorf, 2005; Vajjala and Meurers, 2012) as it is better suited to evaluate grammaticality than standard metrics. We use language modeling alongside traditional metrics for selecting good simplification candidates. 4 Experiments 4.1 Baseline Systems We used the original input text and the human simplified text from the sentence aligned DSim corpus which consist of 48k original and manually simplified sentences of Danish news wire text (Klerke and Søgaard, 2012) as reference in the evaluations. In addition we trained a statistical machine translation (SMT) simplification system, in effect translating from </context>
</contexts>
<marker>Schwarm, Ostendorf, 2005</marker>
<rawString>Sarah E Schwarm and Mari Ostendorf. 2005. Reading Level Assessment Using Support Vector Machines and Statistical Language Models. In Proceedings of the 43rd Annual Meeting of the ACL, pages 523– 530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Seretan</author>
</authors>
<title>Acquisition of syntactic simplification rules for french.</title>
<date>2012</date>
<booktitle>In Proceedings of Language Resources and Evaluation (LREC</booktitle>
<contexts>
<context position="1156" citStr="Seretan, 2012" startWordPosition="162" endWordPosition="163">ntence. Our approach is rated as equally grammatical and beginner reader appropriate as a supervised SMT-based baseline system by native speakers, but our setup performs more radical changes that better resembles the variation observed in human generated simplifications. 1 Introduction As a field of research in NLP, text simplification (TS) has gained increasing attention recently, primarily for English text, but also for Brazilian Portuguese (Specia, 2010; Aluísio et al., 2008), Dutch (Daelemans et al., 2004), Spanish (Drndarevic and Saggion, 2012), Danish (Klerke and Søgaard, 2012), French (Seretan, 2012) and Swedish (Rybing and Smith, 2009; Decker, 2003). Our experiments use Danish text which is similar to English in that it has a deep orthography making it hard to map between letters and sounds. Danish has a relatively free word order and sparse morfology. TS can help readers with below average reading skills access information and may supply relevant training material, which is crucial for developing reading skills. However, manual TS is as expensive as translation, which is a key limiting factor on the availability of easy-to-read material. One of the persistent chalenges of TS is that dif</context>
<context position="5655" citStr="Seretan, 2012" startWordPosition="869" endWordPosition="870"> research in the context of related work. Section 4 presents the experimental setup including generation and evaluation. In Section 5, the results are presented and discussed and, finally, concluding remarks and future perspectives are presented in the last section. 3 Related work Approaches for automatic TS traditionally focus on lexical substitution (De Belder and Moens, 2012; Specia et al., 2012; Yatskar et al., 2010), on identifying re-write rules at sentence level either manually (Chandrasekar et al., 1996; Carroll et al., 1999; Canning et al., 2000; Siddharthan, 2010; Siddharthan, 2011; Seretan, 2012) or automatically from parallel corpora (Woodsend and Lapata, 2011; Coster and Kauchak, 2011; Zhu et al., 2010) and possibly learning cues for when to apply such changes (Petersen and Ostendorf, 2007; Medero, 2011; Bott et al., 2012). Chandrasekar et al. (1996) propose a structural approach, which uses syntactic cues to recover relative clauses and appositives. Sentence level syntactic re-writing has since seen a variety of manually constructed general sentence splitting rules, designed to operate both on dependencies and phrase structure trees, and typically including lexical cues (Siddhartha</context>
</contexts>
<marker>Seretan, 2012</marker>
<rawString>V. Seretan. 2012. Acquisition of syntactic simplification rules for french. In Proceedings of Language Resources and Evaluation (LREC 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Advaith Siddharthan</author>
<author>Napoleon Katsos</author>
</authors>
<title>Offline Sentence Processing Measures for testing Readability with Users.</title>
<date>2012</date>
<booktitle>In Proceedings of the First Workshop on Predicting and Improving Text Readability for target reader populations,</booktitle>
<pages>17--24</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr{é}al, Canada,</location>
<contexts>
<context position="7970" citStr="Siddharthan and Katsos (2012)" startWordPosition="1230" endWordPosition="1233">ator agreement and comparisons so far shows that it is easy to overfit to reflect individual annotator and domain differences that are not of relevance to generalized systems. In a minimally supervised setup, our TS approach can be modified to include lexical simplifications as part of the random generation process. This would require a broad coverage list of words and simpler synonyms, which could for instance be extracted from a parallel corpus like the DSim corpus. For the majority of research in automatic TS the question of what constitutes cognitive load is not discussed. An exception is Siddharthan and Katsos (2012), who seek to isolate the psycholinguistically motivated notions of sentence comprehension from sentence acceptability by actually measuring the effect of TS on cognition on a small scale. Readability research is a line of research that is more directly concerned with the nature of cognitive load in reading building on insights from psycholinguistics. One goal is to develop techniques and metrics for assessing the readability of unseen 143 text. Such metrics are used as a tool for teachers and publishers, but existing standard metrics (like Flesch-Kincaid (Flesch, 1948) and LIX (Bjornsson, 198</context>
</contexts>
<marker>Siddharthan, Katsos, 2012</marker>
<rawString>Advaith Siddharthan and Napoleon Katsos. 2012. Offline Sentence Processing Measures for testing Readability with Users. In Proceedings of the First Workshop on Predicting and Improving Text Readability for target reader populations, pages 17–24, Montr{é}al, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Advaith Siddharthan</author>
</authors>
<title>Complex lexico-syntactic reformulation of sentences using typed dependency representations.</title>
<date>2010</date>
<booktitle>Proceedings of the 6th International Natural Language Generation Conference.</booktitle>
<contexts>
<context position="5620" citStr="Siddharthan, 2010" startWordPosition="865" endWordPosition="866"> 2012) The next section positions this research in the context of related work. Section 4 presents the experimental setup including generation and evaluation. In Section 5, the results are presented and discussed and, finally, concluding remarks and future perspectives are presented in the last section. 3 Related work Approaches for automatic TS traditionally focus on lexical substitution (De Belder and Moens, 2012; Specia et al., 2012; Yatskar et al., 2010), on identifying re-write rules at sentence level either manually (Chandrasekar et al., 1996; Carroll et al., 1999; Canning et al., 2000; Siddharthan, 2010; Siddharthan, 2011; Seretan, 2012) or automatically from parallel corpora (Woodsend and Lapata, 2011; Coster and Kauchak, 2011; Zhu et al., 2010) and possibly learning cues for when to apply such changes (Petersen and Ostendorf, 2007; Medero, 2011; Bott et al., 2012). Chandrasekar et al. (1996) propose a structural approach, which uses syntactic cues to recover relative clauses and appositives. Sentence level syntactic re-writing has since seen a variety of manually constructed general sentence splitting rules, designed to operate both on dependencies and phrase structure trees, and typically</context>
</contexts>
<marker>Siddharthan, 2010</marker>
<rawString>Advaith Siddharthan. 2010. Complex lexico-syntactic reformulation of sentences using typed dependency representations. Proceedings of the 6th International Natural Language Generation Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Advaith Siddharthan</author>
</authors>
<title>Text Simplification using Typed Dependencies: A Comparison of the Robustness of Different Generation Strategies.</title>
<date>2011</date>
<booktitle>In Proceedings of the 13th European Workshop on Natural Language Generation,</booktitle>
<pages>2--11</pages>
<contexts>
<context position="5639" citStr="Siddharthan, 2011" startWordPosition="867" endWordPosition="868">tion positions this research in the context of related work. Section 4 presents the experimental setup including generation and evaluation. In Section 5, the results are presented and discussed and, finally, concluding remarks and future perspectives are presented in the last section. 3 Related work Approaches for automatic TS traditionally focus on lexical substitution (De Belder and Moens, 2012; Specia et al., 2012; Yatskar et al., 2010), on identifying re-write rules at sentence level either manually (Chandrasekar et al., 1996; Carroll et al., 1999; Canning et al., 2000; Siddharthan, 2010; Siddharthan, 2011; Seretan, 2012) or automatically from parallel corpora (Woodsend and Lapata, 2011; Coster and Kauchak, 2011; Zhu et al., 2010) and possibly learning cues for when to apply such changes (Petersen and Ostendorf, 2007; Medero, 2011; Bott et al., 2012). Chandrasekar et al. (1996) propose a structural approach, which uses syntactic cues to recover relative clauses and appositives. Sentence level syntactic re-writing has since seen a variety of manually constructed general sentence splitting rules, designed to operate both on dependencies and phrase structure trees, and typically including lexical </context>
</contexts>
<marker>Siddharthan, 2011</marker>
<rawString>Advaith Siddharthan. 2011. Text Simplification using Typed Dependencies: A Comparison of the Robustness of Different Generation Strategies. In Proceedings of the 13th European Workshop on Natural Language Generation, pages 2–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Specia</author>
<author>S K Jauhar</author>
<author>R Mihalcea</author>
</authors>
<title>Semeval-2012 task 1: English lexical simplification.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>347--355</pages>
<contexts>
<context position="5442" citStr="Specia et al., 2012" startWordPosition="836" endWordPosition="839">ses, and doing so can dramatically reduce sentence length. Both simple deletions and extraction of clauses can be observed in professionally simplified text. (Medero, 2011; Klerke, 2012) The next section positions this research in the context of related work. Section 4 presents the experimental setup including generation and evaluation. In Section 5, the results are presented and discussed and, finally, concluding remarks and future perspectives are presented in the last section. 3 Related work Approaches for automatic TS traditionally focus on lexical substitution (De Belder and Moens, 2012; Specia et al., 2012; Yatskar et al., 2010), on identifying re-write rules at sentence level either manually (Chandrasekar et al., 1996; Carroll et al., 1999; Canning et al., 2000; Siddharthan, 2010; Siddharthan, 2011; Seretan, 2012) or automatically from parallel corpora (Woodsend and Lapata, 2011; Coster and Kauchak, 2011; Zhu et al., 2010) and possibly learning cues for when to apply such changes (Petersen and Ostendorf, 2007; Medero, 2011; Bott et al., 2012). Chandrasekar et al. (1996) propose a structural approach, which uses syntactic cues to recover relative clauses and appositives. Sentence level syntacti</context>
<context position="7100" citStr="Specia et al. (2012)" startWordPosition="1087" endWordPosition="1090">pora (Woodsend and Lapata, 2011; Zhu et al., 2010). In our experiment we apply few basic sentence splitting rules as a pre-processing technique before using an over-generating random deletion approach. Carroll et al. (1999) perform lexical substitution from frequency counts and eliminate anaphora by resolving and replacing the referring expressions with the entity referred to. Their system further include compound sentence splitting and rewriting of passive sentences to active ones (Canning et al., 2000). Research into lexical simplification remains an active topic. De Belder and Moens (2012; Specia et al. (2012) are both recent publications of new resources for evaluating lexical simplification in English consisting of lists of synonyms ranked by human judges. Another type of resource is graded word-lists as described in Brooke et al. (2012). Annotator agreement and comparisons so far shows that it is easy to overfit to reflect individual annotator and domain differences that are not of relevance to generalized systems. In a minimally supervised setup, our TS approach can be modified to include lexical simplifications as part of the random generation process. This would require a broad coverage list </context>
</contexts>
<marker>Specia, Jauhar, Mihalcea, 2012</marker>
<rawString>L. Specia, S.K. Jauhar, and R. Mihalcea. 2012. Semeval-2012 task 1: English lexical simplification. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012), pages 347– 355.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Specia</author>
</authors>
<title>Translating from complex to simplified sentences.</title>
<date>2010</date>
<booktitle>In Proceedings of the 9th international conference on Computational Processing of the Portuguese Language,</booktitle>
<pages>30--39</pages>
<contexts>
<context position="1002" citStr="Specia, 2010" startWordPosition="140" endWordPosition="141">lity research. The main idea is that a loss function can distinguish good simplification candidates among randomly sampled sub-sentences of the input sentence. Our approach is rated as equally grammatical and beginner reader appropriate as a supervised SMT-based baseline system by native speakers, but our setup performs more radical changes that better resembles the variation observed in human generated simplifications. 1 Introduction As a field of research in NLP, text simplification (TS) has gained increasing attention recently, primarily for English text, but also for Brazilian Portuguese (Specia, 2010; Aluísio et al., 2008), Dutch (Daelemans et al., 2004), Spanish (Drndarevic and Saggion, 2012), Danish (Klerke and Søgaard, 2012), French (Seretan, 2012) and Swedish (Rybing and Smith, 2009; Decker, 2003). Our experiments use Danish text which is similar to English in that it has a deep orthography making it hard to map between letters and sounds. Danish has a relatively free word order and sparse morfology. TS can help readers with below average reading skills access information and may supply relevant training material, which is crucial for developing reading skills. However, manual TS is a</context>
</contexts>
<marker>Specia, 2010</marker>
<rawString>L. Specia. 2010. Translating from complex to simplified sentences. In Proceedings of the 9th international conference on Computational Processing of the Portuguese Language, pages 30–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM – an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the Seventh International Conference on Spoken Language Processing.</booktitle>
<contexts>
<context position="14749" citStr="Stolcke, 2002" startWordPosition="2305" endWordPosition="2306">metric for Danish, LIX (Bjornsson, 1983)7. Finally, the WCD measured the variation in universal postag-distribution 8 compared to the observed tagvariation in the entire simplified corpus. For PPL and LIX we calculated the difference between the score of the input sentence and the candidate. Development data was used for tuning the weights of the loss function. Because the candidate-generation is free to produce extremely short candidates, we have to deal with candidates 6The LM was Knesser-Ney smoothed, using the same corpora as the baseline system, without punctuation and built using SRILM (Stolcke, 2002). 7LIX is similar to the English Flesch-Kincaid grade level in favoring short sentences with short words. The formula is LIX = average sentence length + % long words, with long words being of more than 6 characters. (Anderson, 1983) calculated a conversion from LIX to grade levels. 8suggested by(Petrov et al., 2011) receiving extremely low scores. Those scores never arise in the professionally simplified text, so we eliminate extreme candidates by introducing filters on all scores. The lower limit was tuned experimentally and fixed approximately two times below the average difference observed </context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM – an extensible language modeling toolkit. In Proceedings of the Seventh International Conference on Spoken Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vajjala</author>
<author>D Meurers</author>
</authors>
<title>On improving the accuracy of readability classification using insights from second language acquisition.</title>
<date>2012</date>
<booktitle>In Proceedings of the 7th Workshop on Innovative Use of NLP for Building Educational Applications (BEA7),</booktitle>
<pages>163--173</pages>
<contexts>
<context position="8976" citStr="Vajjala and Meurers, 2012" startWordPosition="1390" endWordPosition="1393">hniques and metrics for assessing the readability of unseen 143 text. Such metrics are used as a tool for teachers and publishers, but existing standard metrics (like Flesch-Kincaid (Flesch, 1948) and LIX (Bjornsson, 1983)) were designed and optimized for easy manual application to human written text, requiring thehuman reader to assess that the text is congruent and coherent. More recent methods promise to be applicable to unassessed text. Language modeling in particular has shown to be a robust and informative component of systems for assessing text readability (Schwarm and Ostendorf, 2005; Vajjala and Meurers, 2012) as it is better suited to evaluate grammaticality than standard metrics. We use language modeling alongside traditional metrics for selecting good simplification candidates. 4 Experiments 4.1 Baseline Systems We used the original input text and the human simplified text from the sentence aligned DSim corpus which consist of 48k original and manually simplified sentences of Danish news wire text (Klerke and Søgaard, 2012) as reference in the evaluations. In addition we trained a statistical machine translation (SMT) simplification system, in effect translating from normal news wire text to sim</context>
</contexts>
<marker>Vajjala, Meurers, 2012</marker>
<rawString>S. Vajjala and D. Meurers. 2012. On improving the accuracy of readability classification using insights from second language acquisition. In Proceedings of the 7th Workshop on Innovative Use of NLP for Building Educational Applications (BEA7), pages 163–173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristian Woodsend</author>
<author>Mirella Lapata</author>
</authors>
<title>Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</booktitle>
<pages>409--420</pages>
<contexts>
<context position="5721" citStr="Woodsend and Lapata, 2011" startWordPosition="877" endWordPosition="881">sents the experimental setup including generation and evaluation. In Section 5, the results are presented and discussed and, finally, concluding remarks and future perspectives are presented in the last section. 3 Related work Approaches for automatic TS traditionally focus on lexical substitution (De Belder and Moens, 2012; Specia et al., 2012; Yatskar et al., 2010), on identifying re-write rules at sentence level either manually (Chandrasekar et al., 1996; Carroll et al., 1999; Canning et al., 2000; Siddharthan, 2010; Siddharthan, 2011; Seretan, 2012) or automatically from parallel corpora (Woodsend and Lapata, 2011; Coster and Kauchak, 2011; Zhu et al., 2010) and possibly learning cues for when to apply such changes (Petersen and Ostendorf, 2007; Medero, 2011; Bott et al., 2012). Chandrasekar et al. (1996) propose a structural approach, which uses syntactic cues to recover relative clauses and appositives. Sentence level syntactic re-writing has since seen a variety of manually constructed general sentence splitting rules, designed to operate both on dependencies and phrase structure trees, and typically including lexical cues (Siddharthan, 2011; Heilman and Smith, 2010; Canning et al., 2000). Similar r</context>
</contexts>
<marker>Woodsend, Lapata, 2011</marker>
<rawString>Kristian Woodsend and Mirella Lapata. 2011. Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (2011), pages 409– 420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Yatskar</author>
<author>Bo Pang</author>
<author>C Danescu-Niculescu-Mizil</author>
<author>Lillian Lee</author>
</authors>
<title>For the sake of simplicity: Unsupervised extraction of lexical simplifications from Wikipedia.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>365--368</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5465" citStr="Yatskar et al., 2010" startWordPosition="840" endWordPosition="843"> dramatically reduce sentence length. Both simple deletions and extraction of clauses can be observed in professionally simplified text. (Medero, 2011; Klerke, 2012) The next section positions this research in the context of related work. Section 4 presents the experimental setup including generation and evaluation. In Section 5, the results are presented and discussed and, finally, concluding remarks and future perspectives are presented in the last section. 3 Related work Approaches for automatic TS traditionally focus on lexical substitution (De Belder and Moens, 2012; Specia et al., 2012; Yatskar et al., 2010), on identifying re-write rules at sentence level either manually (Chandrasekar et al., 1996; Carroll et al., 1999; Canning et al., 2000; Siddharthan, 2010; Siddharthan, 2011; Seretan, 2012) or automatically from parallel corpora (Woodsend and Lapata, 2011; Coster and Kauchak, 2011; Zhu et al., 2010) and possibly learning cues for when to apply such changes (Petersen and Ostendorf, 2007; Medero, 2011; Bott et al., 2012). Chandrasekar et al. (1996) propose a structural approach, which uses syntactic cues to recover relative clauses and appositives. Sentence level syntactic re-writing has since </context>
</contexts>
<marker>Yatskar, Pang, Danescu-Niculescu-Mizil, Lee, 2010</marker>
<rawString>Mark Yatskar, Bo Pang, C. Danescu-Niculescu-Mizil, and Lillian Lee. 2010. For the sake of simplicity: Unsupervised extraction of lexical simplifications from Wikipedia. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 365–368. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhemin Zhu</author>
<author>Delphine Bernhard</author>
<author>I Gurevych</author>
</authors>
<title>A monolingual tree-based translation model for sentence simplification.</title>
<date>2010</date>
<booktitle>In Proceedings of The 23rd International Conference on Computational Linguistics,</booktitle>
<pages>1353--1361</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5766" citStr="Zhu et al., 2010" startWordPosition="886" endWordPosition="889"> evaluation. In Section 5, the results are presented and discussed and, finally, concluding remarks and future perspectives are presented in the last section. 3 Related work Approaches for automatic TS traditionally focus on lexical substitution (De Belder and Moens, 2012; Specia et al., 2012; Yatskar et al., 2010), on identifying re-write rules at sentence level either manually (Chandrasekar et al., 1996; Carroll et al., 1999; Canning et al., 2000; Siddharthan, 2010; Siddharthan, 2011; Seretan, 2012) or automatically from parallel corpora (Woodsend and Lapata, 2011; Coster and Kauchak, 2011; Zhu et al., 2010) and possibly learning cues for when to apply such changes (Petersen and Ostendorf, 2007; Medero, 2011; Bott et al., 2012). Chandrasekar et al. (1996) propose a structural approach, which uses syntactic cues to recover relative clauses and appositives. Sentence level syntactic re-writing has since seen a variety of manually constructed general sentence splitting rules, designed to operate both on dependencies and phrase structure trees, and typically including lexical cues (Siddharthan, 2011; Heilman and Smith, 2010; Canning et al., 2000). Similar rules have been created from direct inspection</context>
</contexts>
<marker>Zhu, Bernhard, Gurevych, 2010</marker>
<rawString>Zhemin Zhu, Delphine Bernhard, and I. Gurevych. 2010. A monolingual tree-based translation model for sentence simplification. In Proceedings of The 23rd International Conference on Computational Linguistics, pages 1353–1361. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>