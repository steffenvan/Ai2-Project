<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004581">
<title confidence="0.998208">
Broadly Improving User Classification via
Communication-Based Name and Location Clustering on Twitter
</title>
<author confidence="0.999853">
Shane Bergsma, Mark Dredze, Benjamin Van Durme, Theresa Wilson, David Yarowsky
</author>
<affiliation confidence="0.924038">
Department of Computer Science and Human Language Technology Center of Excellence
Johns Hopkins University
</affiliation>
<address confidence="0.846949">
Baltimore, MD 21218, USA
</address>
<email confidence="0.990306">
shane.a.bergsma@gmail.com, mdredze@cs.jhu.edu, vandurme@cs.jhu.edu, taw@jhu.edu, yarowsky@cs.jhu.edu
</email>
<sectionHeader confidence="0.995576" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999883458333333">
Hidden properties of social media users, such
as their ethnicity, gender, and location, are of-
ten reflected in their observed attributes, such
as their first and last names. Furthermore,
users who communicate with each other of-
ten have similar hidden properties. We pro-
pose an algorithm that exploits these insights
to cluster the observed attributes of hundreds
of millions of Twitter users. Attributes such
as user names are grouped together if users
with those names communicate with other
similar users. We separately cluster millions
of unique first names, last names, and user-
provided locations. The efficacy of these clus-
ters is then evaluated on a diverse set of clas-
sification tasks that predict hidden users prop-
erties such as ethnicity, geographic location,
gender, language, and race, using only pro-
file names and locations when appropriate.
Our readily-replicable approach and publicly-
released clusters are shown to be remarkably
effective and versatile, substantially outper-
forming state-of-the-art approaches and hu-
man accuracy on each of the tasks studied.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999979619047619">
There is growing interest in automatically classify-
ing users in social media by various hidden prop-
erties, such as their gender, location, and language
(e.g. Rao et al. (2010), Cheng et al. (2010), Bergsma
et al. (2012)). Predicting these and other proper-
ties for users can enable better advertising and per-
sonalization, as well as a finer-grained analysis of
user opinions (O’Connor et al., 2010), health (Paul
and Dredze, 2011), and sociolinguistic phenomena
(Eisenstein et al., 2011). Classifiers for user prop-
erties often rely on information from a user’s social
network (Jernigan and Mistree, 2009; Sadilek et al.,
2012) or the textual content they generate (Pennac-
chiotti and Popescu, 2011; Burger et al., 2011).
Here, we propose and evaluate classifiers that bet-
ter exploit the attributes that users explicitly provide
in their user profiles, such as names (e.g., first names
like Mary, last names like Smith) and locations (e.g.,
Brasil). Such attributes have previously been used as
“profile features” in supervised user classifiers (Pen-
nacchiotti and Popescu, 2011; Burger et al., 2011;
Bergsma et al., 2012). There are several motivations
for exploiting these data. Often the only informa-
tion available for a user is a name or location (e.g.
for a new user account). Profiles also provide an
orthogonal or complementary source of information
to a user’s social network and textual content; gains
based on profiles alone should therefore add to gains
based on other data. The decisions of profile-based
classifiers could also be used to bootstrap training
data for other classifiers that use complementary fea-
tures.
Prior work has encoded profile attributes via lex-
ical or character-based features (e.g. Pennacchiotti
and Popescu (2011), Burger et al. (2011), Bergsma
et al. (2012)). Unfortunately, due to the long-tailed
distribution of user attributes, a profile-based classi-
fier will encounter many examples at test time that
were not observed during training. For example,
suppose a user wassim hassan gives their location as
tanger. If the attribute tokens wassim, hassan, and
tanger do not occur in training (nor indicative sub-
</bodyText>
<page confidence="0.937214">
1010
</page>
<note confidence="0.4694665">
Proceedings of NAACL-HLT 2013, pages 1010–1019,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.969980387755102">
strings), then a classifier can only guess at the user’s First names: maria, david, ana, daniel, michael, john,
ethnicity and location. In social media, the preva- alex, jessica, carlos, jose, chris, sarah, laura, juan
lence of fake names and large variations in spelling,
slang, and language make matters worse.
Our innovation is to enhance attribute-based clas-
sifiers with new data, derived from the communica-
tions of Twitter users with those attributes. Users
with the name tokens wassim and hassan often talk
to users with Arab names like abdul and hussein.
Users listing their location as tanger often talk to
users from morocco. Since users who communicate
often share properties such as ethnicity and location
(§8), the user wassim hassan might be an Arab who
uses the French spelling of the city Tangier.
Our challenge is to encode these data in a form
readily usable by a classifier. Our approach is to
represent each unique profile attribute (e.g. tanger
or hassan) as a vector that encodes the communi-
cation pattern of users with that attribute (e.g. how
often they talk to users from morocco, etc.); we then
cluster the vectors to discover latent groupings of
similar attributes. Based on transitive (third party)
connections, tanger and tangier can appear in the
same cluster, even if no two users from these loca-
tions talk directly. To use the clusters in an attribute-
based classifier, we add new features that indicate
the cluster memberships of the attributes. Clustering
thus lets us convert a high-dimensional space of all
attribute pairs to a low-dimensional space of cluster
memberships. This makes it easier to share our data,
yields fewer parameters for learning, and creates at-
tribute groups that are interpretable to humans.
We cluster names and locations in a very large
corpus of 168 million Twitter users (§2) and use a
distributed clustering algorithm to separately clus-
ter millions of first names, last names, and user-
provided locations (§3). We evaluate the use of our
cluster data as a novel feature in supervised classi-
fiers, and compare our result to standard classifiers
using character and token-level features (§4). The
cluster data enables significantly improved perfor-
mance in predicting the gender, location, and lan-
guage of social media users, exceeding both ex-
isting state-of-the-art machine and human perfor-
mance (§6). Our cluster data can likewise im-
prove performance in other domains, on both es-
tablished and new NLP tasks as further evaluated
in this paper (§6). We also propose a way to
1011
Last names: silva, santos, smith, garcia, oliveira, ro-
driguez, jones, williams, johnson, brown, gonzalez
Locations: brasil, indonesia, philippines, london,
jakarta, são paulo, rio de janeiro, venezuela, brazil
Table 1: Most frequent profile attributes for our collection
of 168 million Twitter users, in descending order
enhance a geolocation system by using commu-
nication patterns, and show strong improvements
over a hand-engineered baseline (§7). We share
our clusters with the community to use with other
tasks. The clusters, and other experimental data, are
available for download from www.clsp.jhu.edu/
-sbergsma/TwitterClusters/.
2 Attribute Associations on Twitter
Data and Processing Our raw Twitter data com-
prises the union of 2.2 billion tweets from 05/2009
to 10/2010 (O’Connor et al., 2010), 1.8 billion
tweets collected from 07/2011 to 08/2012, and 80
million tweets collected from followers of 10 thou-
sand location and language-specific Twitter feeds.
We implemented each stage of processing using
MapReduce (Dean and Ghemawat, 2008). The total
computation (from extracting profiles to clustering
attributes) was 1300 days of wall-clock CPU time.
Attribute Extraction Tweets provide the name
and self-reported location of the tweeter. We find
126M unique users with these attributes in our data.
When tweets mention other users via an @user con-
struction, Twitter also includes the profile name of
the mentioned user; we obtain a further 42M users
from these cases. We then normalize the extracted
attributes by converting to lower-case, deleting sym-
bols, numbers, and punctuation, and removing com-
mon honorifics and suffixes like mr/mrs and jr/sr.
Common prefixes like van and de la are joined to
the last-name token.1 This processing yields 8.3M
1www.clsp.jhu.edu/-sbergsma/TwitterClusters/
also provides our scripts for normalizing attributes. The scripts
can be used to ensure consistency/compatibility between
arbitrary datasets and our shared cluster data. Note we use no
special processing for the companies, organizations, and spam-
mers among our users, nor for names arising from different
conventions (e.g. 1-word names, reversed first/last names).
henrik: fredrik 5.87, henrik 5.82, anders 5.73, johan
5.69, andreas 5.59, martin 5.54, magnus 5.41
courtney: taylor 8.03, ashley 7.92, courtney 7.92,
emily 7.91, lauren 7.82, katie 7.72, brittany 7.69
ilya: sergey 5.85, alexey 5.62, alexander 5.59, dmitry
5.51, A.nexcaaRp 5.46, anton 5.44, andrey 5.40
</bodyText>
<tableCaption confidence="0.992791">
Table 2: Top associates and PMIs for three first names.
</tableCaption>
<bodyText confidence="0.99976475">
unique locations, 7.4M unique last names, and 5.5M
unique first names. These three sets provide the tar-
get attributes that we cluster in §3. Table 1 shows
the most frequent names in each of these three sets.
User-User Links We extract each user mention as
an undirected communication link between the user
tweeting and the mentioned user (including self-
mentions but not retweets). We consider each user-
user link as a single event; we count it once no mat-
ter how often two specific users interact. We extract
436M user-user links in total.
Attribute-Attribute Pairs We use our profile data
to map each user-user link to an attribute-attribute
pair; we separately count each pair of first names,
last names, and locations. For example, the first-
name pair (henrik, fredrik) occurs 181 times. Rather
than using the raw count, we calculate the associa-
tion between attributes a1 and a2 via their pointwise
mutual information (PMI), following prior work in
distributional clustering (Lin and Wu, 2009):
</bodyText>
<equation confidence="0.998522">
P(a1, a2)
PMI(a1, a2) = log
P(a1)P(a2)
</equation>
<bodyText confidence="0.999684923076923">
PMI essentially normalizes the co-occurrence by
what we would expect if the attributes were indepen-
dently distributed. We smooth the PMI by adding a
count of 0.5 to all co-occurrence events.
The most highly-associated name attributes re-
flect similarities in ethnicity and gender (Table 2).
The most highly-ranked associates for locations are
often nicknames and alternate/misspellings of those
locations. For example, the locations charm city,
bmore, balto, westbaltimore, b a l t i m o r e, bal-
timoreee, and balitmore each have the U.S. city of
baltimore as their highest-PMI associate. We show
how this can be used to help geolocate users (§7).
</bodyText>
<sectionHeader confidence="0.972517" genericHeader="method">
3 Attribute Clustering
</sectionHeader>
<bodyText confidence="0.999901739130435">
Representation We first represent each target at-
tribute as a feature vector, where each feature corre-
sponds to another attribute of the same type as the
target and each value gives the PMI between this at-
tribute and the target (as in Table 2).2 To help cluster
the long-tail of infrequent attributes, we also include
orthographic features. For first and last names, we
have binary features for the last 2 characters in the
string. For locations, we have binary features for
(a) any ideographic characters in the string and (b)
each token (with diacritics removed) in the string.
We normalize the feature vectors to unit length.
Distributed K-Means Clustering Our approach
to clustering follows Lin and Wu (2009) who used k-
means to cluster tens of millions of phrases. We also
use cosine similarity to compute the closest centroid
(i.e., we use the spherical k-means clustering algo-
rithm (Dhillon and Modha, 2001)). We keep track
of the average cosine similarity between each vector
and its nearest centroid; this average is guaranteed
to increase at each iteration.
Like Lin and Wu (2009), we parallelize the al-
gorithm using MapReduce. Each mapper finds the
nearest centroids for a portion of the vectors, while
also computing the partial sums of the vectors as-
signed to each centroid. The mappers emit the cen-
troid IDs as keys and the partial sums as values.
The Reducer aggregates the partial sums from each
partition and re-normalizes each sum vector to unit
length to obtain the new centroids. We also use an
inverted index at each iteration that, for each input
feature, lists which centroids each feature belongs
to. Using this index greatly speeds up the centroid
similarity computations.
Clustering Details We cluster with nine separate
configurations: over first names, last names, and lo-
cations, and each with 50, 200, and 1000 cluster
centroids (denoted C50, C200, and C1000). Since k-
2We decided to restrict the features for a target to be at-
tributes of the same type (e.g., we did not use last name as-
sociations for a first name target) because each attribute type
conveys distinct information. For example, first names convey
gender and age more than last names. By separately cluster-
ing representations using first names, last names, and locations,
each clustering can capture its own distinct latent-class associa-
tions.
</bodyText>
<page confidence="0.983441">
1012
</page>
<bodyText confidence="0.7757021875">
Cluster 463 (Serbian): pavlovi´c, jovanovic, jo-
vanovi´c, stankovi´c, srbija, markovi´c, petrovi´c,
radovic, nenad, milenkovic, nikolic, sekulic, todor-
ovic, stojanovic, petrovic, aleksic, ilic, markovic
Cluster 544 (Black South African): ngcobo, nkosi,
dlamini, ndlovu, mkhize, mtshali, sithole, mathebula,
mthembu, khumalo, ngwenya, shabangu, nxumalo,
buthelezi, radebe, mabena, zwane, mbatha, sibiya
Cluster 449 (Turkish): ¸sahin, çelik, öztürk, koç, çakır,
karata¸s, akta¸s, güngör, özkan, balcı, gümü¸s, akkaya,
genç, sarı, yüksel, güne¸s, yi˘git, yalçın, orhan, sa˘glam,
güler, demirci, küçük, yavuz, bayrak, özcan, altun
Cluster 656 (Indonesian): utari, oktaviana, apriani,
mustika, septiana, febrianti, kurniawati, indriani, nur-
janah, septian, cahya, anggara, yuliani, purnamasari,
sukma, wijayanti, pramesti, ningrum, yanti, wulansari
</bodyText>
<tableCaption confidence="0.995876">
Table 3: Example C1000 last-name clusters
</tableCaption>
<bodyText confidence="0.994629384615385">
Cluster 56 [sim=0.497]: gregg, bryn, bret, stewart,
lyndsay, howie, elyse, jacqui, becki, rhett, meaghan,
kirstie, russ, jaclyn, zak, katey, seamus, brennan,
fraser, kristie, stu, jaimie, kerri, heath, carley, griffin
Cluster 104 [sim=0.442]: stephon, devonte, deion,
demarcus, janae, tyree, jarvis, donte, dewayne, javon,
destinee, tray, janay, tyrell, jamar, iesha, chyna,
jaylen, darion, lamont, marquise, domonique, alexus
Cluster 132 [sim=0.292]: moustafa, omnya, menna-
tallah, rxt_j, shorouk, ragab, S� il, radwa, moemen,
mohab, hazem, yehia, ._1�, �I1.I, mennah, S� 1��.,
abdelrahman, ��ila.e., y am, 1.L, nermeen, hebatallah
...
</bodyText>
<tableCaption confidence="0.990241">
Table 4: C200 soft clustering for first name yasmeen
</tableCaption>
<bodyText confidence="0.999907838709677">
means is not guaranteed to reach a global optimum,
we use ten different random initializations for each
configuration, and select the one with the highest av-
erage similarity after 20 iterations. We run this one
for an additional 30 iterations and take the output as
our final set of centroids for that configuration.
The resulting clusters provide data that could help
classify hidden properties of social media users. For
example, Table 3 shows that last names often clus-
ter by ethnicity, even at the sub-national level (e.g.
Zulu tribe surnames nkosi, dlamini, mathebula, etc.).
Note the Serbian names include two entries that are
not last names: srbija, the Serbian word for Serbia,
and nenad, a common Serbian first name.
Soft Clustering Rather than assigning each at-
tribute to its single highest-similarity cluster, we can
assign each vector to its N most similar clusters.
These soft-cluster assignments often reflect different
social groups where a name or location is used. For
example, the name yasmeen is similar to both com-
mon American names (Cluster 56), African Ameri-
can names (Cluster 104), and Arabic names (Clus-
ter 132) (Table 4). As another example, the C1000
assignments for the location trujillo comprise sep-
arate clusters containing towns and cities in Peru,
Venezuela, Colombia, etc., reflecting the various
places in the Latin world with this name. In general,
the soft cluster assignment is a low-dimensional rep-
resentation of each of our attributes. Although it can
be interpretable to humans, it need not be in order to
be useful to a classifier.
</bodyText>
<sectionHeader confidence="0.950469" genericHeader="method">
4 Classification with Cluster Features
</sectionHeader>
<bodyText confidence="0.981685444444445">
Our motivating problem is to classify users for hid-
den properties such as their gender, location, race,
ethnicity, and language. We adopt a discriminative
solution. We encode the relevant data for each in-
stance in a feature vector and train a (linear) support
vector machine classifier (Cortes and Vapnik, 1995).
SVMs represent the state-of-the-art on many NLP
classification tasks, but other classifiers could also
be used. For multi-class classification, we use a one-
versus-all strategy, a competitive approach on most
multi-class problems (Rifkin and Klautau, 2004).
The input to our system is one or more observed
user attributes (e.g. name and location fields from
a user profile). We now describe how features are
created from these attributes in both state-of-the-art
systems and via our new cluster data.
Token Features (Tok) are binary features that in-
dicate the presence of a specific attribute (e.g., first-
name=bob). Burger et al. (2011) and Bergsma et al.
(2012) used Tok features to encode user profile fea-
tures. For multi-token fields (e.g. location), our Tok
features also indicate the specific position of each
token (e.g., loc1=são, loc2=paulo, locN=brasil).
Character N-gram Features (Ngm) give the
count of all character n-grams of length 1-to-4 in the
input. Ngm features have been used in user classifi-
cation (Burger et al., 2011) and represent the state-
</bodyText>
<page confidence="0.960813">
1013
</page>
<bodyText confidence="0.9999775625">
of-the-art in detecting name ethnicity (Bhargava and
Kondrak, 2010). We add special begin/end charac-
ters to the attributes to mark the prefix and suffix po-
sitions. We also use a smoothed log-count; we found
this to be most effective in preliminary work.
Cluster Features (Clus) indicate the soft-cluster
memberships of the attributes. We have features for
the top-2, 5, and 20 most similar clusters in the C50,
C200, and C1000 clusterings, respectively. Like Lin
and Wu (2009), we “side-step the matter of choos-
ing the optimal value k in k-means” by using fea-
tures from clusterings at different granularities. Our
feature dimensions correspond to cluster IDs; fea-
ture values give the similarity to the cluster centroid.
Other strategies (e.g. hard clustering, binary fea-
tures) were less effective in preliminary work.
</bodyText>
<sectionHeader confidence="0.996361" genericHeader="method">
5 Classification Experiments
</sectionHeader>
<subsectionHeader confidence="0.817467">
5.1 Methodology
</subsectionHeader>
<bodyText confidence="0.999941037037037">
Our main objective is to assess the value of us-
ing cluster features (Clus). We add these features
to classifiers using Tok+Ngm features, which repre-
sents the current state-of-the-art. We compare these
feature settings on both Twitter tasks (§5.2) and
tasks not related to social-media (§5.3). For each
task, we randomly divide the gold standard data into
50% train, 25% development and 25% test, unless
otherwise noted. As noted above, the gold-standard
datasets for all of our experiments are available for
download. We train our SVM classifiers using the
LIBLINEAR package (Fan et al., 2008). We optimize
the classifier’s regularization parameter on develop-
ment data, and report our final results on the held-
out test examples. We report accuracy: the propor-
tion of test examples classified correctly. For com-
parison, we report the accuracy of a majority-class
baseline on each task (Base).
Classifying hidden properties of social media
users is challenging (Table 5). Pennacchiotti and
Popescu (2011) even conclude that “profile fields do
not contain enough good-quality information to be
directly used for user classification.” To provide in-
sight into the difficulty of the tasks, we had two hu-
mans annotate 120 examples from each of the test
sets, and we average their results to give a “Human”
performance number. The two humans are experts in
</bodyText>
<table confidence="0.981377625">
Country: 53 possible countries
United States courtland dante cali baby
United States tinas twin on the court
Brazil thamires gomez macapá ap
Denmark marte clason NONE
Lang. ID: 9 confusable languages
Bulgarian valentina getova NONE
Russian borisenko yana edinburgh
Bulgarian NONE blagoevgrad
Ukrainian andriy kupyna ternopil
Farsi kambiz barahouei NONE
Urdu musadiq sanwal jammu
Ethnicity: 13 European ethnicities
German dennis hustadt
Dutch bernhard hofstede
French david coste
Swedish mattias bjarsmyr
Portuguese helder costa
Race: black or white
black kerry swain
black darrell foskey
white ty j larocca
black james n jones
white sean p farrell
</table>
<tableCaption confidence="0.992919">
Table 5: Examples of class (left) and input (names, loca-
tions) for some of our evaluation tasks.
</tableCaption>
<bodyText confidence="0.767981">
this domain and have very wide knowledge of global
names and locations.
</bodyText>
<subsectionHeader confidence="0.986143">
5.2 Twitter Applications
</subsectionHeader>
<bodyText confidence="0.995591333333333">
Country A number of recent papers have consid-
ered the task of predicting the geolocation of users,
using both user content (Cheng et al., 2010; Eisen-
stein et al., 2010; Hecht et al., 2011; Wing and
Baldridge, 2011; Roller et al., 2012) and social net-
work (Backstrom et al., 2010; Sadilek et al., 2012).
Here, we first predict user location at the level of
the user’s location country. To our knowledge, we
are the first to exploit user locations and names for
this prediction. For this task, we obtain gold data
from the portion of Twitter users who have GPS en-
abled (geocoded tweets). We were able to obtain a
very large number of gold instances for this task, so
selected only 10K for testing, 10K for development,
and retained the remaining 782K for training.
Language ID Identifying the language of users
is an important prerequisite for building language-
specific social media resources (Tromp and Pech-
</bodyText>
<page confidence="0.982516">
1014
</page>
<bodyText confidence="0.999605578947368">
enizkiy, 2011; Carter et al., 2013). Bergsma et al.
(2012) recently released a corpus of tweets marked
for one of nine languages grouped into three confus-
able character sets: Arabic, Farsi, and Urdu tweets
written in Arabic characters; Hindi, Nepali, and
Marathi written in Devanagari, and Russian, Bulgar-
ian, and Ukrainian written in Cyrillic. The tweets
were marked for language by native speakers via
Amazon Mechanical Turk. We again discard the
tweet content and extract each user’s first name, last
name, and user location as our input data, while tak-
ing the annotated language as the class label.
Gender We predict whether a Twitter user is male
or female using data from Burger et al. (2011). This
data was created by linking Twitter users to struc-
tured profile pages on other websites where users
must select their gender. Unlike prior systems using
this data (Burger et al., 2011; Van Durme, 2012), we
make the predictions using only user names.
</bodyText>
<subsectionHeader confidence="0.989389">
5.3 Other Applications
</subsectionHeader>
<bodyText confidence="0.999881034482759">
Origin Knowing the origin of a name can improve
its automatic pronunciation (Llitjos and Black,
2001) and transliteration (Bhargava and Kondrak,
2010). We evaluate our cluster data on name-origin
prediction using a corpus of names marked as ei-
ther Indian or non-Indian by Bhargava and Kondrak
(2010). Since names in this corpus are not marked
for entity type, we include separate cluster features
from both our first and last name clusters.
Ethnicity We also evaluate on name-origin data
from Konstantopoulos (2007). This data derives
from lists of football players on European national
teams; it marks each name (with diacritics removed)
as arising from one of 13 European languages. Fol-
lowing prior work, we test in two settings: (1) using
last names only, and (2) using first and last names.
Race We also evaluate our ability to identify eth-
nic groups at a sub-national level. To obtain data
for this task, we mined the publicly-available arrest
records on mugshots.com for the U.S. state of New
Jersey (a small but diverse and densely-populated
area). Over 99% of users were listed as either black
or white, and we structure the task as a binary clas-
sification problem between these two classes. We
predict the race of each person based purely on their
name; this contrasts with prior work in social media
which looked at identifying African Americans on
the basis of their Twitter content (Eisenstein et al.,
2011; Pennacchiotti and Popescu, 2011).
</bodyText>
<sectionHeader confidence="0.984786" genericHeader="method">
6 Classification Results
</sectionHeader>
<bodyText confidence="0.999944083333333">
Table 6 gives the results on each task. The system in-
corporating our novel Clus features consistently im-
proves over the Ngm+Tok system; all differences be-
tween All and Ngm+Tok are significant (McNemar’s,
p&lt;0.01). The relative reduction in error from adding
Clus features ranges between 7% and 51%. The All
system including Clus features also exceeds human
performance on all studied tasks.
On Country, the U.S. is the majority class, oc-
curring in 42.5% of cases.3 It is impressive that
All so significantly exceeds Tok+Ngm (86.7% vs.
84.8%); with 782K training examples, we did not
expect such room for improvement. Both names and
locations play an important role: All achieves 66%
using names alone and 70% with only location. On
the subset of data where all three attributes are non-
empty, the full system achieves 93% accuracy.
Both feature classes are likewise important for
Lang. ID; All achieves 67% with only first+last
names, 72% with just locations, but 83% with both.
Our smallest improvement is on Gender. This
task is easier (with higher human/system accuracy)
and has plenty of training data (more data per class
than any other task); there is thus less room to im-
prove. Looking at the feature weights, the strongest-
weighted female cluster apparently captures a sub-
community of Justin Bieber fans (showing loyalty
with “first names” jbieber, belieb, biebz, beliebing,
jbiebs, etc.). Just because a first name like madison
has a high similarity to this cluster does not imply
girls named Madison are Justin Bieber fans; it sim-
ply means that Madisons have similar names to the
friends of Justin Bieber fans (who tend to be girls).
Also, note that while the majority of the 34K users in
our training data are assigned this cluster somewhere
in their soft clustering, only 6 would be assigned this
</bodyText>
<footnote confidence="0.988861166666667">
3We tried other baselines: e.g., we predict countries if they
are substrings of the location (otherwise predicting U.S.); and
we predict countries if they often occur as a string following
the given location in our profile data (e.g., we predict Spain for
Madrid since Madrid, Spain is common). Variations on these
approaches consistently performed between 48% and 56%.
</footnote>
<page confidence="0.953019">
1015
</page>
<table confidence="0.989675411764706">
Num. Num. Base Human Tok Ngm Clus Tok+ All A
Train Class Ngm
781920 53 42.5 71.7 83.0 84.5 80.2 84.8 86.7 12.5
2492 9 27.0 74.2 74.6 80.6 71.1 80.4 82.7 11.7
33805 2 52.4 88.3 85.3 88.6 79.5 89.5 90.2 6.7
500 2 52.4 80.4 - 75.6 81.2 75.6 88.0 50.8
6026 13 20.8 47.9 - 54.6 48.5 54.6 62.4 17.2
7457 13 21.2 53.3 67.6 77.5 73.6 78.4 81.3 13.4
7977 2 54.7 71.4 80.4 81.6 84.6 82.4 84.6 12.5
Task Input
Country first+last+loc
Lang. ID first+last+loc
Gender first+last
Origin entity name
Ethnicity last
Ethnicity first+last
Race first+last
</table>
<tableCaption confidence="0.989028">
Table 6: Task details and accuracy (%) for attribute-based classification tasks. A = relative error reduction (%) of All
(Tok+Ngm+Clus) over Ngm+Tok. All always exceeds both Tok+Ngm and the human performance.
</tableCaption>
<bodyText confidence="0.999533242424243">
cluster in a hard clustering. This clearly illustrates
the value of the soft clustering representation.
Note the All system performed between 83% and
90% on each Twitter task. This level of performance
strongly refutes the prevailing notion that Twitter
profile information is useless in general (Pennac-
chiotti and Popescu, 2011) and especially for geolo-
cation (Cheng et al., 2010; Hecht et al., 2011).
We now move to applications beyond social me-
dia. Bhargava and Kondrak (2010) have the current
state-of-the-art on Origin and Ethnicity based on an
SVM using character-n-gram features; we reimple-
mented this as Ngm. We obtain a huge improvement
over their work using Clus, especially on Origin
where we reduce error by &gt;50%.4 This improve-
ment can partly be attributed to the small amount of
training data; with fewer parameters to learn, Clus
learns more from limited data than Ngm. We like-
wise see large improvements over the state-of-the-
art on Ethnicity, on both last name and full name
settings.
Finally, Clus features also significantly improve
accuracy on the new Race task. Our cluster data can
therefore help to classify names into sub-national
groups, and could potentially be used to infer other
interesting communities such as castes in India and
religious divisions in many countries.
In general, the relative value of our cluster models
varies with the amount of training data; we see huge
gains on the smaller Origin data but smaller gains
on the large Gender set. Figure 1 shows how per-
formance of Clus and Ngm varies with training data
on Race. Again, Clus is especially helpful with less
</bodyText>
<footnote confidence="0.994677">
4Note Tok is not used here because the input is a single token
and training and test splits have distinct instances.
</footnote>
<figure confidence="0.9640075">
10 100 1000 10000
Number of training examples
</figure>
<figureCaption confidence="0.993968">
Figure 1: Learning curve on Race: Clus perform as well
with 30 training examples as Ngm features do with 1000.
</figureCaption>
<bodyText confidence="0.998073">
data; thousands of training examples are needed for
Ngm to rival the performance of Clus using only a
handful. Since labeled data is generally expensive
to obtain or in short supply, our method for exploit-
ing unlabeled Twitter data can both save money and
improve top-end performance.
</bodyText>
<sectionHeader confidence="0.776279" genericHeader="method">
7 Geolocation by Association
</sectionHeader>
<bodyText confidence="0.999939181818182">
There is a tradition in computational linguistics of
grouping words both by the similarity of their con-
text vectors (Hindle, 1990; Pereira et al., 1993; Lin,
1998) and directly by their statistical association in
text (Church and Hanks, 1990; Brown et al., 1992).
While the previous sections explored clusters built
by vector similarity, we now explore a direct appli-
cation of our attribute association data (§2).
We wish to use this data to improve an existing
Twitter geolocation system based on user profile lo-
cations. The system operates as follows: 1) normal-
</bodyText>
<figure confidence="0.993665">
Accuracy
85
80
75
70
65
60
Clus
Ngm
</figure>
<page confidence="0.992347">
1016
</page>
<bodyText confidence="0.9831465">
ize user-provided locations using a set of regular ex-
pressions (e.g. remove extra spacing, punctuation);
</bodyText>
<listItem confidence="0.83121275">
2) look up the normalized location in an alias list;
3) if found, map the alias to a unique string (target
location), corresponding to a structured location ob-
ject that includes geo-coordinates.
</listItem>
<bodyText confidence="0.999370596153846">
The alias list we are currently using is based on
extensive work in hand-writing aliases for the most
popular Twitter locations. For example, the current
aliases for Nashville, Tennessee include nashville,
nashville tn, music city, etc. Our objective is to im-
prove on this human-designed list by automatically
generating aliases using our association data.
Aliases by Association For each target, we pro-
pose new aliases from the target’s top-PMI asso-
ciates (§2). To become an alias, the PMI between
the alias and target must be above a threshold,
the alias must occur more than a fixed number of
times in our profile data, the alias must be within
the top-N1 associates of the target, and the target
must be within the top-N2 associates of the alias.
We merge our automatic aliases with the manually-
written aliases. The new aliases for Nashville, Ten-
nessee include east nashville, nashville tenn, music
city usa, nashvegas, cashville tn, etc.
Experiments To evaluate the geolocation system,
we use tweets from users with GPS enabled (§5.2).
For each tweet, we resolve the location using the
system and compare to the gold coordinates. The
system can skip a location if it does not match the
alias list; more than half of the locations are skipped,
which is consistent with prior work (Hecht et al.,
2011). We evaluate the alias lists using two mea-
sures: (1) its coverage: the percentage of locations it
resolves, and (2) its precision: of the ones resolved,
the percentage that are correct. We define a correct
resolution to be one where the resolved coordinates
are within 50 miles of the gold coordinates.
We use 56K gold tweets to tune the parameters of
our automatic alias-generator, trading off coverage
and precision. We tune such that the system using
these aliases obtains the highest possible coverage,
while being at least as precise as the baseline system.
We then evaluate both the baseline set of aliases and
our new set on 56K held-out examples.
Results On held-out test data, the geolocation sys-
tem using baseline aliases has a coverage of 38.7%
and a precision of 59.5%. Meanwhile, the system
using the new aliases has a coverage of 44.6% and
a precision of 59.4%. With virtually the same pre-
cision, the new aliases are thus able to resolve 15%
more users. This provides an immediate benefit to
our existing Twitter research efforts.
Note that our alias lists can be viewed as clus-
ters of locations. In ongoing work, we are exploring
techniques based on discriminative learning to infer
alias lists using not only Clus information but also
Ngm and Tok features as in the previous sections.
</bodyText>
<sectionHeader confidence="0.999745" genericHeader="related work">
8 Related Work
</sectionHeader>
<bodyText confidence="0.99991778125">
In both real-world and online social networks, “peo-
ple socialize with people who are like them in terms
of gender, sexual orientation, age, race, education,
and religion” (Jernigan and Mistree, 2009). So-
cial media research has exploited this for two main
purposes: (1) to predict friendships based on user
properties, and (2) to predict user properties based
on friendships. Friendship prediction systems (e.g.
Facebook’s friend suggestion tool) use features such
as whether both people are computer science ma-
jors (Taskar et al., 2003) or whether both are at the
same location (Crandall et al., 2010; Sadilek et al.,
2012). The inverse problem has been explored in the
prediction of a user’s location given the location of
their peers (Backstrom et al., 2010; Cho et al., 2011;
Sadilek et al., 2012). Jernigan and Mistree (2009)
predict a user’s sexuality based on the sexuality of
their Facebook friends, while Garera and Yarowsky
(2009) predict a user’s gender partly based on the
gender of their conversational partner. Jha and El-
hadad (2010) predict the cancer stage of users of
an online cancer discussion board; they derive com-
plementary information for prediction from both the
text a user generates and the cancer stage of the peo-
ple that a user interacts with.
The idea of clustering data in order to provide fea-
tures for supervised systems has been successfully
explored in a range of NLP tasks, including named-
entity-recognition (Miller et al., 2004; Lin and Wu,
2009; Ratinov and Roth, 2009), syntactic chunking
(Turian et al., 2010), and dependency parsing (Koo
et al., 2008; Täckström et al., 2012). In each case,
</bodyText>
<page confidence="0.986672">
1017
</page>
<bodyText confidence="0.999911666666667">
the clusters are derived from the distribution of the
words or phrases in text, not from their communica-
tion pattern. It would be interesting to see whether
prior distributional clusters can be combined with
our communication-based clusters to achieve even
better performance. Indeed, there is evidence that
features derived from text can improve the predic-
tion of name ethnicity (Pervouchine et al., 2010).
There has been an explosion of work in recent
years in predicting user properties in social net-
works. Aside from the work mentioned above that
analyzes a user’s social network, a large amount
of work has focused on inferring user properties
based on the content they generate (e.g. Burger
and Henderson (2006), Schler et al. (2006), Rao
et al. (2010), Mukherjee and Liu (2010), Pennac-
chiotti and Popescu (2011), Burger et al. (2011), Van
Durme (2012)).
</bodyText>
<sectionHeader confidence="0.986469" genericHeader="conclusions">
9 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999984857142857">
We presented a highly effective and readily repli-
cable algorithm for generating language resources
from Twitter communication patterns. We clustered
user attributes based on both the communication of
users with those attributes as well as substring sim-
ilarity. Systems using our clusters significantly out-
perform state-of-the-art algorithms on each of the
tasks investigated, and exceed human performance
on each task as well. The power and versatility of
our clusters is exemplified by the fact we reduce er-
ror by a larger margin on each of the non-Twitter
tasks than on any Twitter task itself.
Twitter provides a remarkably large sample and
effectively a partial census of much of the world’s
population, with associated metadata, descriptive
content and sentiment information. Our ability to
accurately assign numerous often unspecified prop-
erties such as race, gender, language and ethnicity to
such a large user sample substantially increases the
sociological insights and correlations one can derive
from such data.
</bodyText>
<sectionHeader confidence="0.998863" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99931325">
Lars Backstrom, Eric Sun, and Cameron Marlow. 2010.
Find me if you can: improving geographical predic-
tion with social and spatial proximity. In Proc. WWW,
pages 61–70.
Shane Bergsma, Paul McNamee, Mossaab Bagdouri,
Clayton Fink, and Theresa Wilson. 2012. Language
identification for creating language-specific Twitter
collections. In Proceedings of the Second Workshop
on Language in Social Media, pages 65–74.
Aditya Bhargava and Grzegorz Kondrak. 2010. Lan-
guage identification of names with SVMs. In Proc.
HLT-NAACL, pages 693–696.
Peter F. Brown, Vincent J. Della Pietra, Peter V. de Souza,
Jennifer C. Lai, and Robert L. Mercer. 1992. Class-
based n-gram models of natural language. Computa-
tional Linguistics, 18(4):467–479.
John D. Burger and John C. Henderson. 2006. An ex-
ploration of observable features related to blogger age.
In Proc. AAAI Spring Symposium: Computational Ap-
proaches to Analyzing Weblogs, pages 15–20.
John D. Burger, John Henderson, George Kim, and Guido
Zarrella. 2011. Discriminating gender on Twitter. In
Proc. EMNLP, pages 1301–1309.
Simon Carter, Wouter Weerkamp, and Manos Tsagkias.
2013. Microblog Language Identification: Overcom-
ing the Limitations of Short, Unedited and Idiomatic
Text. Language Resources and Evaluation Journal.
(forthcoming).
Zhiyuan Cheng, James Caverlee, and Kyumin Lee. 2010.
You are where you tweet: a content-based approach
to geo-locating Twitter users. In Proc. CIKM, pages
759–768.
Eunjoon Cho, Seth A. Myers, and Jure Leskovec. 2011.
Friendship and mobility: user movement in location-
based social networks. In Proc. KDD, pages 1082–
1090.
Kenneth W. Church and Patrick Hanks. 1990. Word as-
sociation norms, mutual information, and lexicogra-
phy. Computational Linguistics, 16(1):22–29.
Corinna Cortes and Vladimir Vapnik. 1995. Support-
vector networks. Mach. Learn., 20(3):273–297.
David J. Crandall, Lars Backstrom, Dan Cosley, Sid-
dharth Suri, Daniel Huttenlocher, and Jon Kleinberg.
2010. Inferring social ties from geographic coinci-
dences. Proceedings of the National Academy of Sci-
ences, 107(52):22436–22441.
Jeffrey Dean and Sanjay Ghemawat. 2008. MapReduce:
simplified data processing on large clusters. Commun.
ACM, 51(1):107–113.
Inderjit S. Dhillon and Dharmendra S. Modha. 2001.
Concept decompositions for large sparse text data us-
ing clustering. Mach. Learn., 42(1-2):143–175.
Jacob Eisenstein, Brendan O’Connor, Noah A. Smith,
and Eric P. Xing. 2010. A latent variable model for
geographic lexical variation. In Proc. EMNLP, pages
1277–1287.
</reference>
<page confidence="0.78541">
1018
</page>
<reference confidence="0.999895358490566">
Jacob Eisenstein, Noah A. Smith, and Eric P. Xing. 2011.
Discovering sociolinguistic associations with struc-
tured sparsity. In Proc. ACL, pages 1365–1374.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui
Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A li-
brary for large linear classification. J. Mach. Learn.
Res., 9:1871–1874.
Nikesh Garera and David Yarowsky. 2009. Modeling la-
tent biographic attributes in conversational genres. In
Proc. ACL-IJCNLP, pages 710–718.
Brent Hecht, Lichan Hong, Bongwon Suh, and Ed H. Chi.
2011. Tweets from Justin Bieber’s heart: the dynamics
of the location field in user profiles. In Proc. CHI,
pages 237–246.
Donald Hindle. 1990. Noun classification from
predicate-argument structures. In Proc. ACL, pages
268–275.
Carter Jernigan and Behram F. T. Mistree. 2009. Gaydar:
Facebook friendships expose sexual orientation. First
Monday, 14(10). [Online].
Mukund Jha and Noemie Elhadad. 2010. Cancer stage
prediction based on patient online discourse. In Proc.
2010 Workshop on Biomedical Natural Language Pro-
cessing, pages 64–71.
Stasinos Konstantopoulos. 2007. What’s in a name? In
Proc. Computational Phonology Workshop, RANLP.
Terry Koo, Xavier Carreras, and Michael Collins. 2008.
Simple semi-supervised dependency parsing. In Proc.
ACL-08: HLT, pages 595–603.
Dekang Lin and Xiaoyun Wu. 2009. Phrase clustering
for discriminative learning. In Proc. ACL-IJCNLP,
pages 1030––1038.
Dekang Lin. 1998. Automatic retrieval and clustering of
similar words. In Proc. Coling-ACL, pages 768–774.
Ariadna Font Llitjos and Alan W. Black. 2001. Knowl-
edge of language origin improves pronunciation accu-
racy of proper names. In Proceedings of EuroSpeech-
01, pages 1919–1922.
Scott Miller, Jethran Guinness, and Alex Zamanian.
2004. Name tagging with word clusters and discrimi-
native training. In Proc. HLT-NAACL, pages 337–342.
Arjun Mukherjee and Bing Liu. 2010. Improving gender
classification of blog authors. In Proc. EMNLP, pages
207–217.
Brendan O’Connor, Ramnath Balasubramanyan,
Bryan R. Routledge, and Noah A. Smith. 2010.
From tweets to polls: Linking text sentiment to public
opinion time series. In Proc. ICWSM, pages 122–129.
Michael Paul and Mark Dredze. 2011. You are what you
tweet: Analyzing Twitter for public health. In Proc.
ICWSM, pages 265–272.
Marco Pennacchiotti and Ana-Maria Popescu. 2011. A
machine learning approach to Twitter user classifica-
tion. In Proc. ICWSM, pages 281–288.
Fernando Pereira, Naftali Tishby, and Lillian Lee. 1993.
Distributional clustering of English words. In Proc.
ACL, pages 183–190.
Vladimir Pervouchine, Min Zhang, Ming Liu, and
Haizhou Li. 2010. Improving name origin recogni-
tion with context features and unlabelled data. In Col-
ing 2010: Posters, pages 972–978.
Delip Rao, David Yarowsky, Abhishek Shreevats, and
Manaswi Gupta. 2010. Classifying latent user at-
tributes in Twitter. In Proc. International Workshop on
Search and Mining User-Generated Contents, pages
37–44.
Lev Ratinov and Dan Roth. 2009. Design challenges and
misconceptions in named entity recognition. In Proc.
CoNLL, pages 147–155.
Ryan Rifkin and Aldebaro Klautau. 2004. In defense of
one-vs-all classification. J. Mach. Learn. Res., 5:101–
141.
Stephen Roller, Michael Speriosu, Sarat Rallapalli, Ben-
jamin Wing, and Jason Baldridge. 2012. Supervised
text-based geolocation using language models on an
adaptive grid. In Proc. EMNLP-CoNLL, pages 1500–
1510.
Adam Sadilek, Henry Kautz, and Jeffrey P. Bigham.
2012. Finding your friends and following them to
where you are. In Proc. WSDM, pages 723–732.
Jonathan Schler, Moshe Koppel, Shlomo Argamon, and
James W. Pennebaker. 2006. Effects of age and
gender on blogging. In Proc. AAAI Spring Sympo-
sium: Computational Approaches to Analyzing We-
blogs, pages 199–205.
Oscar Täckström, Ryan McDonald, and Jakob Uszkoreit.
2012. Cross-lingual word clusters for direct transfer
of linguistic structure. In Proc. NAACL-HLT, pages
477–487.
Ben Taskar, Ming-Fai Wong, Pieter Abbeel, and Daphne
Koller. 2003. Link prediction in relational data. In
Proc. NIPS, volume 15.
Erik Tromp and Mykola Pechenizkiy. 2011. Graph-
based n-gram language identication on short texts. In
Proc. 20th Machine Learning conference of Belgium
and The Netherlands, pages 27–34.
Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: A simple and general method
for semi-supervised learning. In Proc. ACL, pages
384–394.
Benjamin Van Durme. 2012. Streaming analysis of dis-
course participants. In Proc. EMNLP-CoNLL, pages
48–58.
Benjamin Wing and Jason Baldridge. 2011. Simple su-
pervised document geolocation with geodesic grids.
In Proc. ACL, pages 955–964.
</reference>
<page confidence="0.996065">
1019
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.695498">
<title confidence="0.9904235">Broadly Improving User Classification Communication-Based Name and Location Clustering on Twitter</title>
<author confidence="0.999288">Shane Bergsma</author>
<author confidence="0.999288">Mark Dredze</author>
<author confidence="0.999288">Benjamin Van_Durme</author>
<author confidence="0.999288">Theresa Wilson</author>
<author confidence="0.999288">David</author>
<affiliation confidence="0.8683085">Department of Computer Science and Human Language Technology Center of Johns Hopkins</affiliation>
<address confidence="0.999878">Baltimore, MD 21218, USA</address>
<email confidence="0.999874">shane.a.bergsma@gmail.com,mdredze@cs.jhu.edu,vandurme@cs.jhu.edu,taw@jhu.edu,yarowsky@cs.jhu.edu</email>
<abstract confidence="0.99848308">Hidden properties of social media users, such as their ethnicity, gender, and location, are often reflected in their observed attributes, such as their first and last names. Furthermore, users who communicate with each other often have similar hidden properties. We propose an algorithm that exploits these insights to cluster the observed attributes of hundreds of millions of Twitter users. Attributes such as user names are grouped together if users with those names communicate with other similar users. We separately cluster millions of unique first names, last names, and userprovided locations. The efficacy of these clusters is then evaluated on a diverse set of classification tasks that predict hidden users properties such as ethnicity, geographic location, gender, language, and race, using only profile names and locations when appropriate. Our readily-replicable approach and publiclyreleased clusters are shown to be remarkably effective and versatile, substantially outperforming state-of-the-art approaches and human accuracy on each of the tasks studied.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lars Backstrom</author>
<author>Eric Sun</author>
<author>Cameron Marlow</author>
</authors>
<title>Find me if you can: improving geographical prediction with social and spatial proximity.</title>
<date>2010</date>
<booktitle>In Proc. WWW,</booktitle>
<pages>61--70</pages>
<contexts>
<context position="20800" citStr="Backstrom et al., 2010" startWordPosition="3222" endWordPosition="3225">rsmyr Portuguese helder costa Race: black or white black kerry swain black darrell foskey white ty j larocca black james n jones white sean p farrell Table 5: Examples of class (left) and input (names, locations) for some of our evaluation tasks. this domain and have very wide knowledge of global names and locations. 5.2 Twitter Applications Country A number of recent papers have considered the task of predicting the geolocation of users, using both user content (Cheng et al., 2010; Eisenstein et al., 2010; Hecht et al., 2011; Wing and Baldridge, 2011; Roller et al., 2012) and social network (Backstrom et al., 2010; Sadilek et al., 2012). Here, we first predict user location at the level of the user’s location country. To our knowledge, we are the first to exploit user locations and names for this prediction. For this task, we obtain gold data from the portion of Twitter users who have GPS enabled (geocoded tweets). We were able to obtain a very large number of gold instances for this task, so selected only 10K for testing, 10K for development, and retained the remaining 782K for training. Language ID Identifying the language of users is an important prerequisite for building languagespecific social med</context>
<context position="33292" citStr="Backstrom et al., 2010" startWordPosition="5302" endWordPosition="5305">e, race, education, and religion” (Jernigan and Mistree, 2009). Social media research has exploited this for two main purposes: (1) to predict friendships based on user properties, and (2) to predict user properties based on friendships. Friendship prediction systems (e.g. Facebook’s friend suggestion tool) use features such as whether both people are computer science majors (Taskar et al., 2003) or whether both are at the same location (Crandall et al., 2010; Sadilek et al., 2012). The inverse problem has been explored in the prediction of a user’s location given the location of their peers (Backstrom et al., 2010; Cho et al., 2011; Sadilek et al., 2012). Jernigan and Mistree (2009) predict a user’s sexuality based on the sexuality of their Facebook friends, while Garera and Yarowsky (2009) predict a user’s gender partly based on the gender of their conversational partner. Jha and Elhadad (2010) predict the cancer stage of users of an online cancer discussion board; they derive complementary information for prediction from both the text a user generates and the cancer stage of the people that a user interacts with. The idea of clustering data in order to provide features for supervised systems has been</context>
</contexts>
<marker>Backstrom, Sun, Marlow, 2010</marker>
<rawString>Lars Backstrom, Eric Sun, and Cameron Marlow. 2010. Find me if you can: improving geographical prediction with social and spatial proximity. In Proc. WWW, pages 61–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Paul McNamee</author>
<author>Mossaab Bagdouri</author>
<author>Clayton Fink</author>
<author>Theresa Wilson</author>
</authors>
<title>Language identification for creating language-specific Twitter collections.</title>
<date>2012</date>
<booktitle>In Proceedings of the Second Workshop on Language in Social Media,</booktitle>
<pages>65--74</pages>
<contexts>
<context position="1730" citStr="Bergsma et al. (2012)" startWordPosition="247" endWordPosition="250">tasks that predict hidden users properties such as ethnicity, geographic location, gender, language, and race, using only profile names and locations when appropriate. Our readily-replicable approach and publiclyreleased clusters are shown to be remarkably effective and versatile, substantially outperforming state-of-the-art approaches and human accuracy on each of the tasks studied. 1 Introduction There is growing interest in automatically classifying users in social media by various hidden properties, such as their gender, location, and language (e.g. Rao et al. (2010), Cheng et al. (2010), Bergsma et al. (2012)). Predicting these and other properties for users can enable better advertising and personalization, as well as a finer-grained analysis of user opinions (O’Connor et al., 2010), health (Paul and Dredze, 2011), and sociolinguistic phenomena (Eisenstein et al., 2011). Classifiers for user properties often rely on information from a user’s social network (Jernigan and Mistree, 2009; Sadilek et al., 2012) or the textual content they generate (Pennacchiotti and Popescu, 2011; Burger et al., 2011). Here, we propose and evaluate classifiers that better exploit the attributes that users explicitly p</context>
<context position="3302" citStr="Bergsma et al. (2012)" startWordPosition="492" endWordPosition="495"> data. Often the only information available for a user is a name or location (e.g. for a new user account). Profiles also provide an orthogonal or complementary source of information to a user’s social network and textual content; gains based on profiles alone should therefore add to gains based on other data. The decisions of profile-based classifiers could also be used to bootstrap training data for other classifiers that use complementary features. Prior work has encoded profile attributes via lexical or character-based features (e.g. Pennacchiotti and Popescu (2011), Burger et al. (2011), Bergsma et al. (2012)). Unfortunately, due to the long-tailed distribution of user attributes, a profile-based classifier will encounter many examples at test time that were not observed during training. For example, suppose a user wassim hassan gives their location as tanger. If the attribute tokens wassim, hassan, and tanger do not occur in training (nor indicative sub1010 Proceedings of NAACL-HLT 2013, pages 1010–1019, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics strings), then a classifier can only guess at the user’s First names: maria, david, ana, daniel, michael, john, </context>
<context position="17062" citStr="Bergsma et al. (2012)" startWordPosition="2630" endWordPosition="2633">any NLP classification tasks, but other classifiers could also be used. For multi-class classification, we use a oneversus-all strategy, a competitive approach on most multi-class problems (Rifkin and Klautau, 2004). The input to our system is one or more observed user attributes (e.g. name and location fields from a user profile). We now describe how features are created from these attributes in both state-of-the-art systems and via our new cluster data. Token Features (Tok) are binary features that indicate the presence of a specific attribute (e.g., firstname=bob). Burger et al. (2011) and Bergsma et al. (2012) used Tok features to encode user profile features. For multi-token fields (e.g. location), our Tok features also indicate the specific position of each token (e.g., loc1=são, loc2=paulo, locN=brasil). Character N-gram Features (Ngm) give the count of all character n-grams of length 1-to-4 in the input. Ngm features have been used in user classification (Burger et al., 2011) and represent the state1013 of-the-art in detecting name ethnicity (Bhargava and Kondrak, 2010). We add special begin/end characters to the attributes to mark the prefix and suffix positions. We also use a smoothed log-cou</context>
<context position="21491" citStr="Bergsma et al. (2012)" startWordPosition="3339" endWordPosition="3342">evel of the user’s location country. To our knowledge, we are the first to exploit user locations and names for this prediction. For this task, we obtain gold data from the portion of Twitter users who have GPS enabled (geocoded tweets). We were able to obtain a very large number of gold instances for this task, so selected only 10K for testing, 10K for development, and retained the remaining 782K for training. Language ID Identifying the language of users is an important prerequisite for building languagespecific social media resources (Tromp and Pech1014 enizkiy, 2011; Carter et al., 2013). Bergsma et al. (2012) recently released a corpus of tweets marked for one of nine languages grouped into three confusable character sets: Arabic, Farsi, and Urdu tweets written in Arabic characters; Hindi, Nepali, and Marathi written in Devanagari, and Russian, Bulgarian, and Ukrainian written in Cyrillic. The tweets were marked for language by native speakers via Amazon Mechanical Turk. We again discard the tweet content and extract each user’s first name, last name, and user location as our input data, while taking the annotated language as the class label. Gender We predict whether a Twitter user is male or fem</context>
</contexts>
<marker>Bergsma, McNamee, Bagdouri, Fink, Wilson, 2012</marker>
<rawString>Shane Bergsma, Paul McNamee, Mossaab Bagdouri, Clayton Fink, and Theresa Wilson. 2012. Language identification for creating language-specific Twitter collections. In Proceedings of the Second Workshop on Language in Social Media, pages 65–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aditya Bhargava</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Language identification of names with SVMs.</title>
<date>2010</date>
<booktitle>In Proc. HLT-NAACL,</booktitle>
<pages>693--696</pages>
<contexts>
<context position="17535" citStr="Bhargava and Kondrak, 2010" startWordPosition="2703" endWordPosition="2706">eatures (Tok) are binary features that indicate the presence of a specific attribute (e.g., firstname=bob). Burger et al. (2011) and Bergsma et al. (2012) used Tok features to encode user profile features. For multi-token fields (e.g. location), our Tok features also indicate the specific position of each token (e.g., loc1=são, loc2=paulo, locN=brasil). Character N-gram Features (Ngm) give the count of all character n-grams of length 1-to-4 in the input. Ngm features have been used in user classification (Burger et al., 2011) and represent the state1013 of-the-art in detecting name ethnicity (Bhargava and Kondrak, 2010). We add special begin/end characters to the attributes to mark the prefix and suffix positions. We also use a smoothed log-count; we found this to be most effective in preliminary work. Cluster Features (Clus) indicate the soft-cluster memberships of the attributes. We have features for the top-2, 5, and 20 most similar clusters in the C50, C200, and C1000 clusterings, respectively. Like Lin and Wu (2009), we “side-step the matter of choosing the optimal value k in k-means” by using features from clusterings at different granularities. Our feature dimensions correspond to cluster IDs; feature</context>
<context position="22561" citStr="Bhargava and Kondrak, 2010" startWordPosition="3513" endWordPosition="3516">st name, and user location as our input data, while taking the annotated language as the class label. Gender We predict whether a Twitter user is male or female using data from Burger et al. (2011). This data was created by linking Twitter users to structured profile pages on other websites where users must select their gender. Unlike prior systems using this data (Burger et al., 2011; Van Durme, 2012), we make the predictions using only user names. 5.3 Other Applications Origin Knowing the origin of a name can improve its automatic pronunciation (Llitjos and Black, 2001) and transliteration (Bhargava and Kondrak, 2010). We evaluate our cluster data on name-origin prediction using a corpus of names marked as either Indian or non-Indian by Bhargava and Kondrak (2010). Since names in this corpus are not marked for entity type, we include separate cluster features from both our first and last name clusters. Ethnicity We also evaluate on name-origin data from Konstantopoulos (2007). This data derives from lists of football players on European national teams; it marks each name (with diacritics removed) as arising from one of 13 European languages. Following prior work, we test in two settings: (1) using last nam</context>
<context position="27294" citStr="Bhargava and Kondrak (2010)" startWordPosition="4301" endWordPosition="4304">assification tasks. A = relative error reduction (%) of All (Tok+Ngm+Clus) over Ngm+Tok. All always exceeds both Tok+Ngm and the human performance. cluster in a hard clustering. This clearly illustrates the value of the soft clustering representation. Note the All system performed between 83% and 90% on each Twitter task. This level of performance strongly refutes the prevailing notion that Twitter profile information is useless in general (Pennacchiotti and Popescu, 2011) and especially for geolocation (Cheng et al., 2010; Hecht et al., 2011). We now move to applications beyond social media. Bhargava and Kondrak (2010) have the current state-of-the-art on Origin and Ethnicity based on an SVM using character-n-gram features; we reimplemented this as Ngm. We obtain a huge improvement over their work using Clus, especially on Origin where we reduce error by &gt;50%.4 This improvement can partly be attributed to the small amount of training data; with fewer parameters to learn, Clus learns more from limited data than Ngm. We likewise see large improvements over the state-of-theart on Ethnicity, on both last name and full name settings. Finally, Clus features also significantly improve accuracy on the new Race task</context>
</contexts>
<marker>Bhargava, Kondrak, 2010</marker>
<rawString>Aditya Bhargava and Grzegorz Kondrak. 2010. Language identification of names with SVMs. In Proc. HLT-NAACL, pages 693–696.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Peter V de Souza</author>
<author>Jennifer C Lai</author>
<author>Robert L Mercer</author>
</authors>
<title>Classbased n-gram models of natural language.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<issue>4</issue>
<marker>Brown, Pietra, de Souza, Lai, Mercer, 1992</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Peter V. de Souza, Jennifer C. Lai, and Robert L. Mercer. 1992. Classbased n-gram models of natural language. Computational Linguistics, 18(4):467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Burger</author>
<author>John C Henderson</author>
</authors>
<title>An exploration of observable features related to blogger age.</title>
<date>2006</date>
<booktitle>In Proc. AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs,</booktitle>
<pages>15--20</pages>
<contexts>
<context position="34884" citStr="Burger and Henderson (2006)" startWordPosition="5563" endWordPosition="5566">heir communication pattern. It would be interesting to see whether prior distributional clusters can be combined with our communication-based clusters to achieve even better performance. Indeed, there is evidence that features derived from text can improve the prediction of name ethnicity (Pervouchine et al., 2010). There has been an explosion of work in recent years in predicting user properties in social networks. Aside from the work mentioned above that analyzes a user’s social network, a large amount of work has focused on inferring user properties based on the content they generate (e.g. Burger and Henderson (2006), Schler et al. (2006), Rao et al. (2010), Mukherjee and Liu (2010), Pennacchiotti and Popescu (2011), Burger et al. (2011), Van Durme (2012)). 9 Conclusion and Future Work We presented a highly effective and readily replicable algorithm for generating language resources from Twitter communication patterns. We clustered user attributes based on both the communication of users with those attributes as well as substring similarity. Systems using our clusters significantly outperform state-of-the-art algorithms on each of the tasks investigated, and exceed human performance on each task as well. </context>
</contexts>
<marker>Burger, Henderson, 2006</marker>
<rawString>John D. Burger and John C. Henderson. 2006. An exploration of observable features related to blogger age. In Proc. AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs, pages 15–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Burger</author>
<author>John Henderson</author>
<author>George Kim</author>
<author>Guido Zarrella</author>
</authors>
<title>Discriminating gender on Twitter.</title>
<date>2011</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>1301--1309</pages>
<contexts>
<context position="2228" citStr="Burger et al., 2011" startWordPosition="324" endWordPosition="327">operties, such as their gender, location, and language (e.g. Rao et al. (2010), Cheng et al. (2010), Bergsma et al. (2012)). Predicting these and other properties for users can enable better advertising and personalization, as well as a finer-grained analysis of user opinions (O’Connor et al., 2010), health (Paul and Dredze, 2011), and sociolinguistic phenomena (Eisenstein et al., 2011). Classifiers for user properties often rely on information from a user’s social network (Jernigan and Mistree, 2009; Sadilek et al., 2012) or the textual content they generate (Pennacchiotti and Popescu, 2011; Burger et al., 2011). Here, we propose and evaluate classifiers that better exploit the attributes that users explicitly provide in their user profiles, such as names (e.g., first names like Mary, last names like Smith) and locations (e.g., Brasil). Such attributes have previously been used as “profile features” in supervised user classifiers (Pennacchiotti and Popescu, 2011; Burger et al., 2011; Bergsma et al., 2012). There are several motivations for exploiting these data. Often the only information available for a user is a name or location (e.g. for a new user account). Profiles also provide an orthogonal or </context>
<context position="17036" citStr="Burger et al. (2011)" startWordPosition="2625" endWordPosition="2628">the state-of-the-art on many NLP classification tasks, but other classifiers could also be used. For multi-class classification, we use a oneversus-all strategy, a competitive approach on most multi-class problems (Rifkin and Klautau, 2004). The input to our system is one or more observed user attributes (e.g. name and location fields from a user profile). We now describe how features are created from these attributes in both state-of-the-art systems and via our new cluster data. Token Features (Tok) are binary features that indicate the presence of a specific attribute (e.g., firstname=bob). Burger et al. (2011) and Bergsma et al. (2012) used Tok features to encode user profile features. For multi-token fields (e.g. location), our Tok features also indicate the specific position of each token (e.g., loc1=são, loc2=paulo, locN=brasil). Character N-gram Features (Ngm) give the count of all character n-grams of length 1-to-4 in the input. Ngm features have been used in user classification (Burger et al., 2011) and represent the state1013 of-the-art in detecting name ethnicity (Bhargava and Kondrak, 2010). We add special begin/end characters to the attributes to mark the prefix and suffix positions. We a</context>
<context position="22131" citStr="Burger et al. (2011)" startWordPosition="3445" endWordPosition="3448"> corpus of tweets marked for one of nine languages grouped into three confusable character sets: Arabic, Farsi, and Urdu tweets written in Arabic characters; Hindi, Nepali, and Marathi written in Devanagari, and Russian, Bulgarian, and Ukrainian written in Cyrillic. The tweets were marked for language by native speakers via Amazon Mechanical Turk. We again discard the tweet content and extract each user’s first name, last name, and user location as our input data, while taking the annotated language as the class label. Gender We predict whether a Twitter user is male or female using data from Burger et al. (2011). This data was created by linking Twitter users to structured profile pages on other websites where users must select their gender. Unlike prior systems using this data (Burger et al., 2011; Van Durme, 2012), we make the predictions using only user names. 5.3 Other Applications Origin Knowing the origin of a name can improve its automatic pronunciation (Llitjos and Black, 2001) and transliteration (Bhargava and Kondrak, 2010). We evaluate our cluster data on name-origin prediction using a corpus of names marked as either Indian or non-Indian by Bhargava and Kondrak (2010). Since names in this</context>
<context position="35007" citStr="Burger et al. (2011)" startWordPosition="5584" endWordPosition="5587">ation-based clusters to achieve even better performance. Indeed, there is evidence that features derived from text can improve the prediction of name ethnicity (Pervouchine et al., 2010). There has been an explosion of work in recent years in predicting user properties in social networks. Aside from the work mentioned above that analyzes a user’s social network, a large amount of work has focused on inferring user properties based on the content they generate (e.g. Burger and Henderson (2006), Schler et al. (2006), Rao et al. (2010), Mukherjee and Liu (2010), Pennacchiotti and Popescu (2011), Burger et al. (2011), Van Durme (2012)). 9 Conclusion and Future Work We presented a highly effective and readily replicable algorithm for generating language resources from Twitter communication patterns. We clustered user attributes based on both the communication of users with those attributes as well as substring similarity. Systems using our clusters significantly outperform state-of-the-art algorithms on each of the tasks investigated, and exceed human performance on each task as well. The power and versatility of our clusters is exemplified by the fact we reduce error by a larger margin on each of the non-</context>
</contexts>
<marker>Burger, Henderson, Kim, Zarrella, 2011</marker>
<rawString>John D. Burger, John Henderson, George Kim, and Guido Zarrella. 2011. Discriminating gender on Twitter. In Proc. EMNLP, pages 1301–1309.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Carter</author>
<author>Wouter Weerkamp</author>
<author>Manos Tsagkias</author>
</authors>
<title>Microblog Language Identification: Overcoming the Limitations of Short, Unedited and Idiomatic Text. Language Resources and Evaluation Journal.</title>
<date>2013</date>
<tech>(forthcoming).</tech>
<contexts>
<context position="21468" citStr="Carter et al., 2013" startWordPosition="3335" endWordPosition="3338">user location at the level of the user’s location country. To our knowledge, we are the first to exploit user locations and names for this prediction. For this task, we obtain gold data from the portion of Twitter users who have GPS enabled (geocoded tweets). We were able to obtain a very large number of gold instances for this task, so selected only 10K for testing, 10K for development, and retained the remaining 782K for training. Language ID Identifying the language of users is an important prerequisite for building languagespecific social media resources (Tromp and Pech1014 enizkiy, 2011; Carter et al., 2013). Bergsma et al. (2012) recently released a corpus of tweets marked for one of nine languages grouped into three confusable character sets: Arabic, Farsi, and Urdu tweets written in Arabic characters; Hindi, Nepali, and Marathi written in Devanagari, and Russian, Bulgarian, and Ukrainian written in Cyrillic. The tweets were marked for language by native speakers via Amazon Mechanical Turk. We again discard the tweet content and extract each user’s first name, last name, and user location as our input data, while taking the annotated language as the class label. Gender We predict whether a Twit</context>
</contexts>
<marker>Carter, Weerkamp, Tsagkias, 2013</marker>
<rawString>Simon Carter, Wouter Weerkamp, and Manos Tsagkias. 2013. Microblog Language Identification: Overcoming the Limitations of Short, Unedited and Idiomatic Text. Language Resources and Evaluation Journal. (forthcoming).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiyuan Cheng</author>
<author>James Caverlee</author>
<author>Kyumin Lee</author>
</authors>
<title>You are where you tweet: a content-based approach to geo-locating Twitter users.</title>
<date>2010</date>
<booktitle>In Proc. CIKM,</booktitle>
<pages>759--768</pages>
<contexts>
<context position="1707" citStr="Cheng et al. (2010)" startWordPosition="243" endWordPosition="246">et of classification tasks that predict hidden users properties such as ethnicity, geographic location, gender, language, and race, using only profile names and locations when appropriate. Our readily-replicable approach and publiclyreleased clusters are shown to be remarkably effective and versatile, substantially outperforming state-of-the-art approaches and human accuracy on each of the tasks studied. 1 Introduction There is growing interest in automatically classifying users in social media by various hidden properties, such as their gender, location, and language (e.g. Rao et al. (2010), Cheng et al. (2010), Bergsma et al. (2012)). Predicting these and other properties for users can enable better advertising and personalization, as well as a finer-grained analysis of user opinions (O’Connor et al., 2010), health (Paul and Dredze, 2011), and sociolinguistic phenomena (Eisenstein et al., 2011). Classifiers for user properties often rely on information from a user’s social network (Jernigan and Mistree, 2009; Sadilek et al., 2012) or the textual content they generate (Pennacchiotti and Popescu, 2011; Burger et al., 2011). Here, we propose and evaluate classifiers that better exploit the attributes </context>
<context position="20664" citStr="Cheng et al., 2010" startWordPosition="3197" endWordPosition="3200">sanwal jammu Ethnicity: 13 European ethnicities German dennis hustadt Dutch bernhard hofstede French david coste Swedish mattias bjarsmyr Portuguese helder costa Race: black or white black kerry swain black darrell foskey white ty j larocca black james n jones white sean p farrell Table 5: Examples of class (left) and input (names, locations) for some of our evaluation tasks. this domain and have very wide knowledge of global names and locations. 5.2 Twitter Applications Country A number of recent papers have considered the task of predicting the geolocation of users, using both user content (Cheng et al., 2010; Eisenstein et al., 2010; Hecht et al., 2011; Wing and Baldridge, 2011; Roller et al., 2012) and social network (Backstrom et al., 2010; Sadilek et al., 2012). Here, we first predict user location at the level of the user’s location country. To our knowledge, we are the first to exploit user locations and names for this prediction. For this task, we obtain gold data from the portion of Twitter users who have GPS enabled (geocoded tweets). We were able to obtain a very large number of gold instances for this task, so selected only 10K for testing, 10K for development, and retained the remainin</context>
<context position="27195" citStr="Cheng et al., 2010" startWordPosition="4284" endWordPosition="4287">y first+last Race first+last Table 6: Task details and accuracy (%) for attribute-based classification tasks. A = relative error reduction (%) of All (Tok+Ngm+Clus) over Ngm+Tok. All always exceeds both Tok+Ngm and the human performance. cluster in a hard clustering. This clearly illustrates the value of the soft clustering representation. Note the All system performed between 83% and 90% on each Twitter task. This level of performance strongly refutes the prevailing notion that Twitter profile information is useless in general (Pennacchiotti and Popescu, 2011) and especially for geolocation (Cheng et al., 2010; Hecht et al., 2011). We now move to applications beyond social media. Bhargava and Kondrak (2010) have the current state-of-the-art on Origin and Ethnicity based on an SVM using character-n-gram features; we reimplemented this as Ngm. We obtain a huge improvement over their work using Clus, especially on Origin where we reduce error by &gt;50%.4 This improvement can partly be attributed to the small amount of training data; with fewer parameters to learn, Clus learns more from limited data than Ngm. We likewise see large improvements over the state-of-theart on Ethnicity, on both last name and </context>
</contexts>
<marker>Cheng, Caverlee, Lee, 2010</marker>
<rawString>Zhiyuan Cheng, James Caverlee, and Kyumin Lee. 2010. You are where you tweet: a content-based approach to geo-locating Twitter users. In Proc. CIKM, pages 759–768.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eunjoon Cho</author>
<author>Seth A Myers</author>
<author>Jure Leskovec</author>
</authors>
<title>Friendship and mobility: user movement in locationbased social networks.</title>
<date>2011</date>
<booktitle>In Proc. KDD,</booktitle>
<pages>1082--1090</pages>
<contexts>
<context position="33310" citStr="Cho et al., 2011" startWordPosition="5306" endWordPosition="5309">religion” (Jernigan and Mistree, 2009). Social media research has exploited this for two main purposes: (1) to predict friendships based on user properties, and (2) to predict user properties based on friendships. Friendship prediction systems (e.g. Facebook’s friend suggestion tool) use features such as whether both people are computer science majors (Taskar et al., 2003) or whether both are at the same location (Crandall et al., 2010; Sadilek et al., 2012). The inverse problem has been explored in the prediction of a user’s location given the location of their peers (Backstrom et al., 2010; Cho et al., 2011; Sadilek et al., 2012). Jernigan and Mistree (2009) predict a user’s sexuality based on the sexuality of their Facebook friends, while Garera and Yarowsky (2009) predict a user’s gender partly based on the gender of their conversational partner. Jha and Elhadad (2010) predict the cancer stage of users of an online cancer discussion board; they derive complementary information for prediction from both the text a user generates and the cancer stage of the people that a user interacts with. The idea of clustering data in order to provide features for supervised systems has been successfully expl</context>
</contexts>
<marker>Cho, Myers, Leskovec, 2011</marker>
<rawString>Eunjoon Cho, Seth A. Myers, and Jure Leskovec. 2011. Friendship and mobility: user movement in locationbased social networks. In Proc. KDD, pages 1082– 1090.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="29249" citStr="Church and Hanks, 1990" startWordPosition="4628" endWordPosition="4631">rm as well with 30 training examples as Ngm features do with 1000. data; thousands of training examples are needed for Ngm to rival the performance of Clus using only a handful. Since labeled data is generally expensive to obtain or in short supply, our method for exploiting unlabeled Twitter data can both save money and improve top-end performance. 7 Geolocation by Association There is a tradition in computational linguistics of grouping words both by the similarity of their context vectors (Hindle, 1990; Pereira et al., 1993; Lin, 1998) and directly by their statistical association in text (Church and Hanks, 1990; Brown et al., 1992). While the previous sections explored clusters built by vector similarity, we now explore a direct application of our attribute association data (§2). We wish to use this data to improve an existing Twitter geolocation system based on user profile locations. The system operates as follows: 1) normalAccuracy 85 80 75 70 65 60 Clus Ngm 1016 ize user-provided locations using a set of regular expressions (e.g. remove extra spacing, punctuation); 2) look up the normalized location in an alias list; 3) if found, map the alias to a unique string (target location), corresponding </context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth W. Church and Patrick Hanks. 1990. Word association norms, mutual information, and lexicography. Computational Linguistics, 16(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Corinna Cortes</author>
<author>Vladimir Vapnik</author>
</authors>
<title>Supportvector networks.</title>
<date>1995</date>
<location>Mach. Learn.,</location>
<contexts>
<context position="16399" citStr="Cortes and Vapnik, 1995" startWordPosition="2526" endWordPosition="2529">, etc., reflecting the various places in the Latin world with this name. In general, the soft cluster assignment is a low-dimensional representation of each of our attributes. Although it can be interpretable to humans, it need not be in order to be useful to a classifier. 4 Classification with Cluster Features Our motivating problem is to classify users for hidden properties such as their gender, location, race, ethnicity, and language. We adopt a discriminative solution. We encode the relevant data for each instance in a feature vector and train a (linear) support vector machine classifier (Cortes and Vapnik, 1995). SVMs represent the state-of-the-art on many NLP classification tasks, but other classifiers could also be used. For multi-class classification, we use a oneversus-all strategy, a competitive approach on most multi-class problems (Rifkin and Klautau, 2004). The input to our system is one or more observed user attributes (e.g. name and location fields from a user profile). We now describe how features are created from these attributes in both state-of-the-art systems and via our new cluster data. Token Features (Tok) are binary features that indicate the presence of a specific attribute (e.g.,</context>
</contexts>
<marker>Cortes, Vapnik, 1995</marker>
<rawString>Corinna Cortes and Vladimir Vapnik. 1995. Supportvector networks. Mach. Learn., 20(3):273–297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David J Crandall</author>
<author>Lars Backstrom</author>
<author>Dan Cosley</author>
<author>Siddharth Suri</author>
<author>Daniel Huttenlocher</author>
<author>Jon Kleinberg</author>
</authors>
<title>Inferring social ties from geographic coincidences.</title>
<date>2010</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>107</volume>
<issue>52</issue>
<contexts>
<context position="33133" citStr="Crandall et al., 2010" startWordPosition="5275" endWordPosition="5278">ions. 8 Related Work In both real-world and online social networks, “people socialize with people who are like them in terms of gender, sexual orientation, age, race, education, and religion” (Jernigan and Mistree, 2009). Social media research has exploited this for two main purposes: (1) to predict friendships based on user properties, and (2) to predict user properties based on friendships. Friendship prediction systems (e.g. Facebook’s friend suggestion tool) use features such as whether both people are computer science majors (Taskar et al., 2003) or whether both are at the same location (Crandall et al., 2010; Sadilek et al., 2012). The inverse problem has been explored in the prediction of a user’s location given the location of their peers (Backstrom et al., 2010; Cho et al., 2011; Sadilek et al., 2012). Jernigan and Mistree (2009) predict a user’s sexuality based on the sexuality of their Facebook friends, while Garera and Yarowsky (2009) predict a user’s gender partly based on the gender of their conversational partner. Jha and Elhadad (2010) predict the cancer stage of users of an online cancer discussion board; they derive complementary information for prediction from both the text a user ge</context>
</contexts>
<marker>Crandall, Backstrom, Cosley, Suri, Huttenlocher, Kleinberg, 2010</marker>
<rawString>David J. Crandall, Lars Backstrom, Dan Cosley, Siddharth Suri, Daniel Huttenlocher, and Jon Kleinberg. 2010. Inferring social ties from geographic coincidences. Proceedings of the National Academy of Sciences, 107(52):22436–22441.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Dean</author>
<author>Sanjay Ghemawat</author>
</authors>
<title>MapReduce: simplified data processing on large clusters.</title>
<date>2008</date>
<journal>Commun. ACM,</journal>
<volume>51</volume>
<issue>1</issue>
<contexts>
<context position="7376" citStr="Dean and Ghemawat, 2008" startWordPosition="1129" endWordPosition="1132">engineered baseline (§7). We share our clusters with the community to use with other tasks. The clusters, and other experimental data, are available for download from www.clsp.jhu.edu/ -sbergsma/TwitterClusters/. 2 Attribute Associations on Twitter Data and Processing Our raw Twitter data comprises the union of 2.2 billion tweets from 05/2009 to 10/2010 (O’Connor et al., 2010), 1.8 billion tweets collected from 07/2011 to 08/2012, and 80 million tweets collected from followers of 10 thousand location and language-specific Twitter feeds. We implemented each stage of processing using MapReduce (Dean and Ghemawat, 2008). The total computation (from extracting profiles to clustering attributes) was 1300 days of wall-clock CPU time. Attribute Extraction Tweets provide the name and self-reported location of the tweeter. We find 126M unique users with these attributes in our data. When tweets mention other users via an @user construction, Twitter also includes the profile name of the mentioned user; we obtain a further 42M users from these cases. We then normalize the extracted attributes by converting to lower-case, deleting symbols, numbers, and punctuation, and removing common honorifics and suffixes like mr/</context>
</contexts>
<marker>Dean, Ghemawat, 2008</marker>
<rawString>Jeffrey Dean and Sanjay Ghemawat. 2008. MapReduce: simplified data processing on large clusters. Commun. ACM, 51(1):107–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjit S Dhillon</author>
<author>Dharmendra S Modha</author>
</authors>
<title>Concept decompositions for large sparse text data using clustering.</title>
<date>2001</date>
<pages>42--1</pages>
<location>Mach. Learn.,</location>
<contexts>
<context position="11476" citStr="Dhillon and Modha, 2001" startWordPosition="1779" endWordPosition="1782"> attributes, we also include orthographic features. For first and last names, we have binary features for the last 2 characters in the string. For locations, we have binary features for (a) any ideographic characters in the string and (b) each token (with diacritics removed) in the string. We normalize the feature vectors to unit length. Distributed K-Means Clustering Our approach to clustering follows Lin and Wu (2009) who used kmeans to cluster tens of millions of phrases. We also use cosine similarity to compute the closest centroid (i.e., we use the spherical k-means clustering algorithm (Dhillon and Modha, 2001)). We keep track of the average cosine similarity between each vector and its nearest centroid; this average is guaranteed to increase at each iteration. Like Lin and Wu (2009), we parallelize the algorithm using MapReduce. Each mapper finds the nearest centroids for a portion of the vectors, while also computing the partial sums of the vectors assigned to each centroid. The mappers emit the centroid IDs as keys and the partial sums as values. The Reducer aggregates the partial sums from each partition and re-normalizes each sum vector to unit length to obtain the new centroids. We also use an</context>
</contexts>
<marker>Dhillon, Modha, 2001</marker>
<rawString>Inderjit S. Dhillon and Dharmendra S. Modha. 2001. Concept decompositions for large sparse text data using clustering. Mach. Learn., 42(1-2):143–175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
<author>Brendan O’Connor</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>A latent variable model for geographic lexical variation.</title>
<date>2010</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>1277--1287</pages>
<marker>Eisenstein, O’Connor, Smith, Xing, 2010</marker>
<rawString>Jacob Eisenstein, Brendan O’Connor, Noah A. Smith, and Eric P. Xing. 2010. A latent variable model for geographic lexical variation. In Proc. EMNLP, pages 1277–1287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>Discovering sociolinguistic associations with structured sparsity.</title>
<date>2011</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>1365--1374</pages>
<contexts>
<context position="1997" citStr="Eisenstein et al., 2011" startWordPosition="287" endWordPosition="290">ve and versatile, substantially outperforming state-of-the-art approaches and human accuracy on each of the tasks studied. 1 Introduction There is growing interest in automatically classifying users in social media by various hidden properties, such as their gender, location, and language (e.g. Rao et al. (2010), Cheng et al. (2010), Bergsma et al. (2012)). Predicting these and other properties for users can enable better advertising and personalization, as well as a finer-grained analysis of user opinions (O’Connor et al., 2010), health (Paul and Dredze, 2011), and sociolinguistic phenomena (Eisenstein et al., 2011). Classifiers for user properties often rely on information from a user’s social network (Jernigan and Mistree, 2009; Sadilek et al., 2012) or the textual content they generate (Pennacchiotti and Popescu, 2011; Burger et al., 2011). Here, we propose and evaluate classifiers that better exploit the attributes that users explicitly provide in their user profiles, such as names (e.g., first names like Mary, last names like Smith) and locations (e.g., Brasil). Such attributes have previously been used as “profile features” in supervised user classifiers (Pennacchiotti and Popescu, 2011; Burger et </context>
<context position="23829" citStr="Eisenstein et al., 2011" startWordPosition="3726" endWordPosition="3729">Race We also evaluate our ability to identify ethnic groups at a sub-national level. To obtain data for this task, we mined the publicly-available arrest records on mugshots.com for the U.S. state of New Jersey (a small but diverse and densely-populated area). Over 99% of users were listed as either black or white, and we structure the task as a binary classification problem between these two classes. We predict the race of each person based purely on their name; this contrasts with prior work in social media which looked at identifying African Americans on the basis of their Twitter content (Eisenstein et al., 2011; Pennacchiotti and Popescu, 2011). 6 Classification Results Table 6 gives the results on each task. The system incorporating our novel Clus features consistently improves over the Ngm+Tok system; all differences between All and Ngm+Tok are significant (McNemar’s, p&lt;0.01). The relative reduction in error from adding Clus features ranges between 7% and 51%. The All system including Clus features also exceeds human performance on all studied tasks. On Country, the U.S. is the majority class, occurring in 42.5% of cases.3 It is impressive that All so significantly exceeds Tok+Ngm (86.7% vs. 84.8%</context>
</contexts>
<marker>Eisenstein, Smith, Xing, 2011</marker>
<rawString>Jacob Eisenstein, Noah A. Smith, and Eric P. Xing. 2011. Discovering sociolinguistic associations with structured sparsity. In Proc. ACL, pages 1365–1374.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>Xiang-Rui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBLINEAR: A library for large linear classification.</title>
<date>2008</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>9--1871</pages>
<contexts>
<context position="18924" citStr="Fan et al., 2008" startWordPosition="2924" endWordPosition="2927">riments 5.1 Methodology Our main objective is to assess the value of using cluster features (Clus). We add these features to classifiers using Tok+Ngm features, which represents the current state-of-the-art. We compare these feature settings on both Twitter tasks (§5.2) and tasks not related to social-media (§5.3). For each task, we randomly divide the gold standard data into 50% train, 25% development and 25% test, unless otherwise noted. As noted above, the gold-standard datasets for all of our experiments are available for download. We train our SVM classifiers using the LIBLINEAR package (Fan et al., 2008). We optimize the classifier’s regularization parameter on development data, and report our final results on the heldout test examples. We report accuracy: the proportion of test examples classified correctly. For comparison, we report the accuracy of a majority-class baseline on each task (Base). Classifying hidden properties of social media users is challenging (Table 5). Pennacchiotti and Popescu (2011) even conclude that “profile fields do not contain enough good-quality information to be directly used for user classification.” To provide insight into the difficulty of the tasks, we had tw</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library for large linear classification. J. Mach. Learn. Res., 9:1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikesh Garera</author>
<author>David Yarowsky</author>
</authors>
<title>Modeling latent biographic attributes in conversational genres.</title>
<date>2009</date>
<booktitle>In Proc. ACL-IJCNLP,</booktitle>
<pages>710--718</pages>
<contexts>
<context position="33472" citStr="Garera and Yarowsky (2009)" startWordPosition="5331" endWordPosition="5334">ies, and (2) to predict user properties based on friendships. Friendship prediction systems (e.g. Facebook’s friend suggestion tool) use features such as whether both people are computer science majors (Taskar et al., 2003) or whether both are at the same location (Crandall et al., 2010; Sadilek et al., 2012). The inverse problem has been explored in the prediction of a user’s location given the location of their peers (Backstrom et al., 2010; Cho et al., 2011; Sadilek et al., 2012). Jernigan and Mistree (2009) predict a user’s sexuality based on the sexuality of their Facebook friends, while Garera and Yarowsky (2009) predict a user’s gender partly based on the gender of their conversational partner. Jha and Elhadad (2010) predict the cancer stage of users of an online cancer discussion board; they derive complementary information for prediction from both the text a user generates and the cancer stage of the people that a user interacts with. The idea of clustering data in order to provide features for supervised systems has been successfully explored in a range of NLP tasks, including namedentity-recognition (Miller et al., 2004; Lin and Wu, 2009; Ratinov and Roth, 2009), syntactic chunking (Turian et al.</context>
</contexts>
<marker>Garera, Yarowsky, 2009</marker>
<rawString>Nikesh Garera and David Yarowsky. 2009. Modeling latent biographic attributes in conversational genres. In Proc. ACL-IJCNLP, pages 710–718.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brent Hecht</author>
<author>Lichan Hong</author>
<author>Bongwon Suh</author>
<author>Ed H Chi</author>
</authors>
<title>Tweets from Justin Bieber’s heart: the dynamics of the location field in user profiles.</title>
<date>2011</date>
<booktitle>In Proc. CHI,</booktitle>
<pages>237--246</pages>
<contexts>
<context position="20709" citStr="Hecht et al., 2011" startWordPosition="3206" endWordPosition="3209">es German dennis hustadt Dutch bernhard hofstede French david coste Swedish mattias bjarsmyr Portuguese helder costa Race: black or white black kerry swain black darrell foskey white ty j larocca black james n jones white sean p farrell Table 5: Examples of class (left) and input (names, locations) for some of our evaluation tasks. this domain and have very wide knowledge of global names and locations. 5.2 Twitter Applications Country A number of recent papers have considered the task of predicting the geolocation of users, using both user content (Cheng et al., 2010; Eisenstein et al., 2010; Hecht et al., 2011; Wing and Baldridge, 2011; Roller et al., 2012) and social network (Backstrom et al., 2010; Sadilek et al., 2012). Here, we first predict user location at the level of the user’s location country. To our knowledge, we are the first to exploit user locations and names for this prediction. For this task, we obtain gold data from the portion of Twitter users who have GPS enabled (geocoded tweets). We were able to obtain a very large number of gold instances for this task, so selected only 10K for testing, 10K for development, and retained the remaining 782K for training. Language ID Identifying </context>
<context position="27216" citStr="Hecht et al., 2011" startWordPosition="4288" endWordPosition="4291">rst+last Table 6: Task details and accuracy (%) for attribute-based classification tasks. A = relative error reduction (%) of All (Tok+Ngm+Clus) over Ngm+Tok. All always exceeds both Tok+Ngm and the human performance. cluster in a hard clustering. This clearly illustrates the value of the soft clustering representation. Note the All system performed between 83% and 90% on each Twitter task. This level of performance strongly refutes the prevailing notion that Twitter profile information is useless in general (Pennacchiotti and Popescu, 2011) and especially for geolocation (Cheng et al., 2010; Hecht et al., 2011). We now move to applications beyond social media. Bhargava and Kondrak (2010) have the current state-of-the-art on Origin and Ethnicity based on an SVM using character-n-gram features; we reimplemented this as Ngm. We obtain a huge improvement over their work using Clus, especially on Origin where we reduce error by &gt;50%.4 This improvement can partly be attributed to the small amount of training data; with fewer parameters to learn, Clus learns more from limited data than Ngm. We likewise see large improvements over the state-of-theart on Ethnicity, on both last name and full name settings. F</context>
<context position="31216" citStr="Hecht et al., 2011" startWordPosition="4956" endWordPosition="4959">and the target must be within the top-N2 associates of the alias. We merge our automatic aliases with the manuallywritten aliases. The new aliases for Nashville, Tennessee include east nashville, nashville tenn, music city usa, nashvegas, cashville tn, etc. Experiments To evaluate the geolocation system, we use tweets from users with GPS enabled (§5.2). For each tweet, we resolve the location using the system and compare to the gold coordinates. The system can skip a location if it does not match the alias list; more than half of the locations are skipped, which is consistent with prior work (Hecht et al., 2011). We evaluate the alias lists using two measures: (1) its coverage: the percentage of locations it resolves, and (2) its precision: of the ones resolved, the percentage that are correct. We define a correct resolution to be one where the resolved coordinates are within 50 miles of the gold coordinates. We use 56K gold tweets to tune the parameters of our automatic alias-generator, trading off coverage and precision. We tune such that the system using these aliases obtains the highest possible coverage, while being at least as precise as the baseline system. We then evaluate both the baseline s</context>
</contexts>
<marker>Hecht, Hong, Suh, Chi, 2011</marker>
<rawString>Brent Hecht, Lichan Hong, Bongwon Suh, and Ed H. Chi. 2011. Tweets from Justin Bieber’s heart: the dynamics of the location field in user profiles. In Proc. CHI, pages 237–246.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>Noun classification from predicate-argument structures.</title>
<date>1990</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>268--275</pages>
<contexts>
<context position="29137" citStr="Hindle, 1990" startWordPosition="4612" endWordPosition="4613"> instances. 10 100 1000 10000 Number of training examples Figure 1: Learning curve on Race: Clus perform as well with 30 training examples as Ngm features do with 1000. data; thousands of training examples are needed for Ngm to rival the performance of Clus using only a handful. Since labeled data is generally expensive to obtain or in short supply, our method for exploiting unlabeled Twitter data can both save money and improve top-end performance. 7 Geolocation by Association There is a tradition in computational linguistics of grouping words both by the similarity of their context vectors (Hindle, 1990; Pereira et al., 1993; Lin, 1998) and directly by their statistical association in text (Church and Hanks, 1990; Brown et al., 1992). While the previous sections explored clusters built by vector similarity, we now explore a direct application of our attribute association data (§2). We wish to use this data to improve an existing Twitter geolocation system based on user profile locations. The system operates as follows: 1) normalAccuracy 85 80 75 70 65 60 Clus Ngm 1016 ize user-provided locations using a set of regular expressions (e.g. remove extra spacing, punctuation); 2) look up the norma</context>
</contexts>
<marker>Hindle, 1990</marker>
<rawString>Donald Hindle. 1990. Noun classification from predicate-argument structures. In Proc. ACL, pages 268–275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carter Jernigan</author>
<author>Behram F T Mistree</author>
</authors>
<title>Gaydar: Facebook friendships expose sexual orientation.</title>
<date>2009</date>
<journal>First Monday,</journal>
<volume>14</volume>
<issue>10</issue>
<publisher>[Online].</publisher>
<contexts>
<context position="2113" citStr="Jernigan and Mistree, 2009" startWordPosition="305" endWordPosition="308">studied. 1 Introduction There is growing interest in automatically classifying users in social media by various hidden properties, such as their gender, location, and language (e.g. Rao et al. (2010), Cheng et al. (2010), Bergsma et al. (2012)). Predicting these and other properties for users can enable better advertising and personalization, as well as a finer-grained analysis of user opinions (O’Connor et al., 2010), health (Paul and Dredze, 2011), and sociolinguistic phenomena (Eisenstein et al., 2011). Classifiers for user properties often rely on information from a user’s social network (Jernigan and Mistree, 2009; Sadilek et al., 2012) or the textual content they generate (Pennacchiotti and Popescu, 2011; Burger et al., 2011). Here, we propose and evaluate classifiers that better exploit the attributes that users explicitly provide in their user profiles, such as names (e.g., first names like Mary, last names like Smith) and locations (e.g., Brasil). Such attributes have previously been used as “profile features” in supervised user classifiers (Pennacchiotti and Popescu, 2011; Burger et al., 2011; Bergsma et al., 2012). There are several motivations for exploiting these data. Often the only informatio</context>
<context position="32732" citStr="Jernigan and Mistree, 2009" startWordPosition="5211" endWordPosition="5214">ly the same precision, the new aliases are thus able to resolve 15% more users. This provides an immediate benefit to our existing Twitter research efforts. Note that our alias lists can be viewed as clusters of locations. In ongoing work, we are exploring techniques based on discriminative learning to infer alias lists using not only Clus information but also Ngm and Tok features as in the previous sections. 8 Related Work In both real-world and online social networks, “people socialize with people who are like them in terms of gender, sexual orientation, age, race, education, and religion” (Jernigan and Mistree, 2009). Social media research has exploited this for two main purposes: (1) to predict friendships based on user properties, and (2) to predict user properties based on friendships. Friendship prediction systems (e.g. Facebook’s friend suggestion tool) use features such as whether both people are computer science majors (Taskar et al., 2003) or whether both are at the same location (Crandall et al., 2010; Sadilek et al., 2012). The inverse problem has been explored in the prediction of a user’s location given the location of their peers (Backstrom et al., 2010; Cho et al., 2011; Sadilek et al., 2012</context>
</contexts>
<marker>Jernigan, Mistree, 2009</marker>
<rawString>Carter Jernigan and Behram F. T. Mistree. 2009. Gaydar: Facebook friendships expose sexual orientation. First Monday, 14(10). [Online].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mukund Jha</author>
<author>Noemie Elhadad</author>
</authors>
<title>Cancer stage prediction based on patient online discourse.</title>
<date>2010</date>
<booktitle>In Proc. 2010 Workshop on Biomedical Natural Language Processing,</booktitle>
<pages>64--71</pages>
<contexts>
<context position="33579" citStr="Jha and Elhadad (2010)" startWordPosition="5348" endWordPosition="5352">iend suggestion tool) use features such as whether both people are computer science majors (Taskar et al., 2003) or whether both are at the same location (Crandall et al., 2010; Sadilek et al., 2012). The inverse problem has been explored in the prediction of a user’s location given the location of their peers (Backstrom et al., 2010; Cho et al., 2011; Sadilek et al., 2012). Jernigan and Mistree (2009) predict a user’s sexuality based on the sexuality of their Facebook friends, while Garera and Yarowsky (2009) predict a user’s gender partly based on the gender of their conversational partner. Jha and Elhadad (2010) predict the cancer stage of users of an online cancer discussion board; they derive complementary information for prediction from both the text a user generates and the cancer stage of the people that a user interacts with. The idea of clustering data in order to provide features for supervised systems has been successfully explored in a range of NLP tasks, including namedentity-recognition (Miller et al., 2004; Lin and Wu, 2009; Ratinov and Roth, 2009), syntactic chunking (Turian et al., 2010), and dependency parsing (Koo et al., 2008; Täckström et al., 2012). In each case, 1017 the clusters</context>
</contexts>
<marker>Jha, Elhadad, 2010</marker>
<rawString>Mukund Jha and Noemie Elhadad. 2010. Cancer stage prediction based on patient online discourse. In Proc. 2010 Workshop on Biomedical Natural Language Processing, pages 64–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stasinos Konstantopoulos</author>
</authors>
<title>What’s in a name?</title>
<date>2007</date>
<booktitle>In Proc. Computational Phonology Workshop,</booktitle>
<location>RANLP.</location>
<contexts>
<context position="22926" citStr="Konstantopoulos (2007)" startWordPosition="3574" endWordPosition="3575">rger et al., 2011; Van Durme, 2012), we make the predictions using only user names. 5.3 Other Applications Origin Knowing the origin of a name can improve its automatic pronunciation (Llitjos and Black, 2001) and transliteration (Bhargava and Kondrak, 2010). We evaluate our cluster data on name-origin prediction using a corpus of names marked as either Indian or non-Indian by Bhargava and Kondrak (2010). Since names in this corpus are not marked for entity type, we include separate cluster features from both our first and last name clusters. Ethnicity We also evaluate on name-origin data from Konstantopoulos (2007). This data derives from lists of football players on European national teams; it marks each name (with diacritics removed) as arising from one of 13 European languages. Following prior work, we test in two settings: (1) using last names only, and (2) using first and last names. Race We also evaluate our ability to identify ethnic groups at a sub-national level. To obtain data for this task, we mined the publicly-available arrest records on mugshots.com for the U.S. state of New Jersey (a small but diverse and densely-populated area). Over 99% of users were listed as either black or white, and</context>
</contexts>
<marker>Konstantopoulos, 2007</marker>
<rawString>Stasinos Konstantopoulos. 2007. What’s in a name? In Proc. Computational Phonology Workshop, RANLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Xavier Carreras</author>
<author>Michael Collins</author>
</authors>
<title>Simple semi-supervised dependency parsing.</title>
<date>2008</date>
<booktitle>In Proc. ACL-08: HLT,</booktitle>
<pages>595--603</pages>
<contexts>
<context position="34121" citStr="Koo et al., 2008" startWordPosition="5440" endWordPosition="5443">ased on the gender of their conversational partner. Jha and Elhadad (2010) predict the cancer stage of users of an online cancer discussion board; they derive complementary information for prediction from both the text a user generates and the cancer stage of the people that a user interacts with. The idea of clustering data in order to provide features for supervised systems has been successfully explored in a range of NLP tasks, including namedentity-recognition (Miller et al., 2004; Lin and Wu, 2009; Ratinov and Roth, 2009), syntactic chunking (Turian et al., 2010), and dependency parsing (Koo et al., 2008; Täckström et al., 2012). In each case, 1017 the clusters are derived from the distribution of the words or phrases in text, not from their communication pattern. It would be interesting to see whether prior distributional clusters can be combined with our communication-based clusters to achieve even better performance. Indeed, there is evidence that features derived from text can improve the prediction of name ethnicity (Pervouchine et al., 2010). There has been an explosion of work in recent years in predicting user properties in social networks. Aside from the work mentioned above that ana</context>
</contexts>
<marker>Koo, Carreras, Collins, 2008</marker>
<rawString>Terry Koo, Xavier Carreras, and Michael Collins. 2008. Simple semi-supervised dependency parsing. In Proc. ACL-08: HLT, pages 595–603.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Xiaoyun Wu</author>
</authors>
<title>Phrase clustering for discriminative learning.</title>
<date>2009</date>
<booktitle>In Proc. ACL-IJCNLP,</booktitle>
<pages>1030--1038</pages>
<contexts>
<context position="9853" citStr="Lin and Wu, 2009" startWordPosition="1513" endWordPosition="1516">s). We consider each useruser link as a single event; we count it once no matter how often two specific users interact. We extract 436M user-user links in total. Attribute-Attribute Pairs We use our profile data to map each user-user link to an attribute-attribute pair; we separately count each pair of first names, last names, and locations. For example, the firstname pair (henrik, fredrik) occurs 181 times. Rather than using the raw count, we calculate the association between attributes a1 and a2 via their pointwise mutual information (PMI), following prior work in distributional clustering (Lin and Wu, 2009): P(a1, a2) PMI(a1, a2) = log P(a1)P(a2) PMI essentially normalizes the co-occurrence by what we would expect if the attributes were independently distributed. We smooth the PMI by adding a count of 0.5 to all co-occurrence events. The most highly-associated name attributes reflect similarities in ethnicity and gender (Table 2). The most highly-ranked associates for locations are often nicknames and alternate/misspellings of those locations. For example, the locations charm city, bmore, balto, westbaltimore, b a l t i m o r e, baltimoreee, and balitmore each have the U.S. city of baltimore as </context>
<context position="11275" citStr="Lin and Wu (2009)" startWordPosition="1745" endWordPosition="1748">e corresponds to another attribute of the same type as the target and each value gives the PMI between this attribute and the target (as in Table 2).2 To help cluster the long-tail of infrequent attributes, we also include orthographic features. For first and last names, we have binary features for the last 2 characters in the string. For locations, we have binary features for (a) any ideographic characters in the string and (b) each token (with diacritics removed) in the string. We normalize the feature vectors to unit length. Distributed K-Means Clustering Our approach to clustering follows Lin and Wu (2009) who used kmeans to cluster tens of millions of phrases. We also use cosine similarity to compute the closest centroid (i.e., we use the spherical k-means clustering algorithm (Dhillon and Modha, 2001)). We keep track of the average cosine similarity between each vector and its nearest centroid; this average is guaranteed to increase at each iteration. Like Lin and Wu (2009), we parallelize the algorithm using MapReduce. Each mapper finds the nearest centroids for a portion of the vectors, while also computing the partial sums of the vectors assigned to each centroid. The mappers emit the cent</context>
<context position="17944" citStr="Lin and Wu (2009)" startWordPosition="2771" endWordPosition="2774"> n-grams of length 1-to-4 in the input. Ngm features have been used in user classification (Burger et al., 2011) and represent the state1013 of-the-art in detecting name ethnicity (Bhargava and Kondrak, 2010). We add special begin/end characters to the attributes to mark the prefix and suffix positions. We also use a smoothed log-count; we found this to be most effective in preliminary work. Cluster Features (Clus) indicate the soft-cluster memberships of the attributes. We have features for the top-2, 5, and 20 most similar clusters in the C50, C200, and C1000 clusterings, respectively. Like Lin and Wu (2009), we “side-step the matter of choosing the optimal value k in k-means” by using features from clusterings at different granularities. Our feature dimensions correspond to cluster IDs; feature values give the similarity to the cluster centroid. Other strategies (e.g. hard clustering, binary features) were less effective in preliminary work. 5 Classification Experiments 5.1 Methodology Our main objective is to assess the value of using cluster features (Clus). We add these features to classifiers using Tok+Ngm features, which represents the current state-of-the-art. We compare these feature sett</context>
<context position="34012" citStr="Lin and Wu, 2009" startWordPosition="5423" endWordPosition="5426">on the sexuality of their Facebook friends, while Garera and Yarowsky (2009) predict a user’s gender partly based on the gender of their conversational partner. Jha and Elhadad (2010) predict the cancer stage of users of an online cancer discussion board; they derive complementary information for prediction from both the text a user generates and the cancer stage of the people that a user interacts with. The idea of clustering data in order to provide features for supervised systems has been successfully explored in a range of NLP tasks, including namedentity-recognition (Miller et al., 2004; Lin and Wu, 2009; Ratinov and Roth, 2009), syntactic chunking (Turian et al., 2010), and dependency parsing (Koo et al., 2008; Täckström et al., 2012). In each case, 1017 the clusters are derived from the distribution of the words or phrases in text, not from their communication pattern. It would be interesting to see whether prior distributional clusters can be combined with our communication-based clusters to achieve even better performance. Indeed, there is evidence that features derived from text can improve the prediction of name ethnicity (Pervouchine et al., 2010). There has been an explosion of work i</context>
</contexts>
<marker>Lin, Wu, 2009</marker>
<rawString>Dekang Lin and Xiaoyun Wu. 2009. Phrase clustering for discriminative learning. In Proc. ACL-IJCNLP, pages 1030––1038.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proc. Coling-ACL,</booktitle>
<pages>768--774</pages>
<contexts>
<context position="29171" citStr="Lin, 1998" startWordPosition="4618" endWordPosition="4619"> of training examples Figure 1: Learning curve on Race: Clus perform as well with 30 training examples as Ngm features do with 1000. data; thousands of training examples are needed for Ngm to rival the performance of Clus using only a handful. Since labeled data is generally expensive to obtain or in short supply, our method for exploiting unlabeled Twitter data can both save money and improve top-end performance. 7 Geolocation by Association There is a tradition in computational linguistics of grouping words both by the similarity of their context vectors (Hindle, 1990; Pereira et al., 1993; Lin, 1998) and directly by their statistical association in text (Church and Hanks, 1990; Brown et al., 1992). While the previous sections explored clusters built by vector similarity, we now explore a direct application of our attribute association data (§2). We wish to use this data to improve an existing Twitter geolocation system based on user profile locations. The system operates as follows: 1) normalAccuracy 85 80 75 70 65 60 Clus Ngm 1016 ize user-provided locations using a set of regular expressions (e.g. remove extra spacing, punctuation); 2) look up the normalized location in an alias list; 3</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In Proc. Coling-ACL, pages 768–774.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ariadna Font Llitjos</author>
<author>Alan W Black</author>
</authors>
<title>Knowledge of language origin improves pronunciation accuracy of proper names.</title>
<date>2001</date>
<booktitle>In Proceedings of EuroSpeech01,</booktitle>
<pages>1919--1922</pages>
<contexts>
<context position="22512" citStr="Llitjos and Black, 2001" startWordPosition="3507" endWordPosition="3510">content and extract each user’s first name, last name, and user location as our input data, while taking the annotated language as the class label. Gender We predict whether a Twitter user is male or female using data from Burger et al. (2011). This data was created by linking Twitter users to structured profile pages on other websites where users must select their gender. Unlike prior systems using this data (Burger et al., 2011; Van Durme, 2012), we make the predictions using only user names. 5.3 Other Applications Origin Knowing the origin of a name can improve its automatic pronunciation (Llitjos and Black, 2001) and transliteration (Bhargava and Kondrak, 2010). We evaluate our cluster data on name-origin prediction using a corpus of names marked as either Indian or non-Indian by Bhargava and Kondrak (2010). Since names in this corpus are not marked for entity type, we include separate cluster features from both our first and last name clusters. Ethnicity We also evaluate on name-origin data from Konstantopoulos (2007). This data derives from lists of football players on European national teams; it marks each name (with diacritics removed) as arising from one of 13 European languages. Following prior </context>
</contexts>
<marker>Llitjos, Black, 2001</marker>
<rawString>Ariadna Font Llitjos and Alan W. Black. 2001. Knowledge of language origin improves pronunciation accuracy of proper names. In Proceedings of EuroSpeech01, pages 1919–1922.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Miller</author>
<author>Jethran Guinness</author>
<author>Alex Zamanian</author>
</authors>
<title>Name tagging with word clusters and discriminative training.</title>
<date>2004</date>
<booktitle>In Proc. HLT-NAACL,</booktitle>
<pages>337--342</pages>
<contexts>
<context position="33994" citStr="Miller et al., 2004" startWordPosition="5419" endWordPosition="5422">er’s sexuality based on the sexuality of their Facebook friends, while Garera and Yarowsky (2009) predict a user’s gender partly based on the gender of their conversational partner. Jha and Elhadad (2010) predict the cancer stage of users of an online cancer discussion board; they derive complementary information for prediction from both the text a user generates and the cancer stage of the people that a user interacts with. The idea of clustering data in order to provide features for supervised systems has been successfully explored in a range of NLP tasks, including namedentity-recognition (Miller et al., 2004; Lin and Wu, 2009; Ratinov and Roth, 2009), syntactic chunking (Turian et al., 2010), and dependency parsing (Koo et al., 2008; Täckström et al., 2012). In each case, 1017 the clusters are derived from the distribution of the words or phrases in text, not from their communication pattern. It would be interesting to see whether prior distributional clusters can be combined with our communication-based clusters to achieve even better performance. Indeed, there is evidence that features derived from text can improve the prediction of name ethnicity (Pervouchine et al., 2010). There has been an e</context>
</contexts>
<marker>Miller, Guinness, Zamanian, 2004</marker>
<rawString>Scott Miller, Jethran Guinness, and Alex Zamanian. 2004. Name tagging with word clusters and discriminative training. In Proc. HLT-NAACL, pages 337–342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
</authors>
<title>Improving gender classification of blog authors.</title>
<date>2010</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>207--217</pages>
<contexts>
<context position="34951" citStr="Mukherjee and Liu (2010)" startWordPosition="5575" endWordPosition="5578">or distributional clusters can be combined with our communication-based clusters to achieve even better performance. Indeed, there is evidence that features derived from text can improve the prediction of name ethnicity (Pervouchine et al., 2010). There has been an explosion of work in recent years in predicting user properties in social networks. Aside from the work mentioned above that analyzes a user’s social network, a large amount of work has focused on inferring user properties based on the content they generate (e.g. Burger and Henderson (2006), Schler et al. (2006), Rao et al. (2010), Mukherjee and Liu (2010), Pennacchiotti and Popescu (2011), Burger et al. (2011), Van Durme (2012)). 9 Conclusion and Future Work We presented a highly effective and readily replicable algorithm for generating language resources from Twitter communication patterns. We clustered user attributes based on both the communication of users with those attributes as well as substring similarity. Systems using our clusters significantly outperform state-of-the-art algorithms on each of the tasks investigated, and exceed human performance on each task as well. The power and versatility of our clusters is exemplified by the fac</context>
</contexts>
<marker>Mukherjee, Liu, 2010</marker>
<rawString>Arjun Mukherjee and Bing Liu. 2010. Improving gender classification of blog authors. In Proc. EMNLP, pages 207–217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brendan O’Connor</author>
<author>Ramnath Balasubramanyan</author>
<author>Bryan R Routledge</author>
<author>Noah A Smith</author>
</authors>
<title>From tweets to polls: Linking text sentiment to public opinion time series.</title>
<date>2010</date>
<booktitle>In Proc. ICWSM,</booktitle>
<pages>122--129</pages>
<marker>O’Connor, Balasubramanyan, Routledge, Smith, 2010</marker>
<rawString>Brendan O’Connor, Ramnath Balasubramanyan, Bryan R. Routledge, and Noah A. Smith. 2010. From tweets to polls: Linking text sentiment to public opinion time series. In Proc. ICWSM, pages 122–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Paul</author>
<author>Mark Dredze</author>
</authors>
<title>You are what you tweet: Analyzing Twitter for public health.</title>
<date>2011</date>
<booktitle>In Proc. ICWSM,</booktitle>
<pages>265--272</pages>
<contexts>
<context position="1940" citStr="Paul and Dredze, 2011" startWordPosition="280" endWordPosition="283">clyreleased clusters are shown to be remarkably effective and versatile, substantially outperforming state-of-the-art approaches and human accuracy on each of the tasks studied. 1 Introduction There is growing interest in automatically classifying users in social media by various hidden properties, such as their gender, location, and language (e.g. Rao et al. (2010), Cheng et al. (2010), Bergsma et al. (2012)). Predicting these and other properties for users can enable better advertising and personalization, as well as a finer-grained analysis of user opinions (O’Connor et al., 2010), health (Paul and Dredze, 2011), and sociolinguistic phenomena (Eisenstein et al., 2011). Classifiers for user properties often rely on information from a user’s social network (Jernigan and Mistree, 2009; Sadilek et al., 2012) or the textual content they generate (Pennacchiotti and Popescu, 2011; Burger et al., 2011). Here, we propose and evaluate classifiers that better exploit the attributes that users explicitly provide in their user profiles, such as names (e.g., first names like Mary, last names like Smith) and locations (e.g., Brasil). Such attributes have previously been used as “profile features” in supervised user</context>
</contexts>
<marker>Paul, Dredze, 2011</marker>
<rawString>Michael Paul and Mark Dredze. 2011. You are what you tweet: Analyzing Twitter for public health. In Proc. ICWSM, pages 265–272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Pennacchiotti</author>
<author>Ana-Maria Popescu</author>
</authors>
<title>A machine learning approach to Twitter user classification.</title>
<date>2011</date>
<booktitle>In Proc. ICWSM,</booktitle>
<pages>281--288</pages>
<contexts>
<context position="2206" citStr="Pennacchiotti and Popescu, 2011" startWordPosition="319" endWordPosition="323">social media by various hidden properties, such as their gender, location, and language (e.g. Rao et al. (2010), Cheng et al. (2010), Bergsma et al. (2012)). Predicting these and other properties for users can enable better advertising and personalization, as well as a finer-grained analysis of user opinions (O’Connor et al., 2010), health (Paul and Dredze, 2011), and sociolinguistic phenomena (Eisenstein et al., 2011). Classifiers for user properties often rely on information from a user’s social network (Jernigan and Mistree, 2009; Sadilek et al., 2012) or the textual content they generate (Pennacchiotti and Popescu, 2011; Burger et al., 2011). Here, we propose and evaluate classifiers that better exploit the attributes that users explicitly provide in their user profiles, such as names (e.g., first names like Mary, last names like Smith) and locations (e.g., Brasil). Such attributes have previously been used as “profile features” in supervised user classifiers (Pennacchiotti and Popescu, 2011; Burger et al., 2011; Bergsma et al., 2012). There are several motivations for exploiting these data. Often the only information available for a user is a name or location (e.g. for a new user account). Profiles also pro</context>
<context position="19333" citStr="Pennacchiotti and Popescu (2011)" startWordPosition="2986" endWordPosition="2989">development and 25% test, unless otherwise noted. As noted above, the gold-standard datasets for all of our experiments are available for download. We train our SVM classifiers using the LIBLINEAR package (Fan et al., 2008). We optimize the classifier’s regularization parameter on development data, and report our final results on the heldout test examples. We report accuracy: the proportion of test examples classified correctly. For comparison, we report the accuracy of a majority-class baseline on each task (Base). Classifying hidden properties of social media users is challenging (Table 5). Pennacchiotti and Popescu (2011) even conclude that “profile fields do not contain enough good-quality information to be directly used for user classification.” To provide insight into the difficulty of the tasks, we had two humans annotate 120 examples from each of the test sets, and we average their results to give a “Human” performance number. The two humans are experts in Country: 53 possible countries United States courtland dante cali baby United States tinas twin on the court Brazil thamires gomez macapá ap Denmark marte clason NONE Lang. ID: 9 confusable languages Bulgarian valentina getova NONE Russian borisenko yan</context>
<context position="23863" citStr="Pennacchiotti and Popescu, 2011" startWordPosition="3730" endWordPosition="3733"> ability to identify ethnic groups at a sub-national level. To obtain data for this task, we mined the publicly-available arrest records on mugshots.com for the U.S. state of New Jersey (a small but diverse and densely-populated area). Over 99% of users were listed as either black or white, and we structure the task as a binary classification problem between these two classes. We predict the race of each person based purely on their name; this contrasts with prior work in social media which looked at identifying African Americans on the basis of their Twitter content (Eisenstein et al., 2011; Pennacchiotti and Popescu, 2011). 6 Classification Results Table 6 gives the results on each task. The system incorporating our novel Clus features consistently improves over the Ngm+Tok system; all differences between All and Ngm+Tok are significant (McNemar’s, p&lt;0.01). The relative reduction in error from adding Clus features ranges between 7% and 51%. The All system including Clus features also exceeds human performance on all studied tasks. On Country, the U.S. is the majority class, occurring in 42.5% of cases.3 It is impressive that All so significantly exceeds Tok+Ngm (86.7% vs. 84.8%); with 782K training examples, we</context>
<context position="27144" citStr="Pennacchiotti and Popescu, 2011" startWordPosition="4274" endWordPosition="4278">+loc Gender first+last Origin entity name Ethnicity last Ethnicity first+last Race first+last Table 6: Task details and accuracy (%) for attribute-based classification tasks. A = relative error reduction (%) of All (Tok+Ngm+Clus) over Ngm+Tok. All always exceeds both Tok+Ngm and the human performance. cluster in a hard clustering. This clearly illustrates the value of the soft clustering representation. Note the All system performed between 83% and 90% on each Twitter task. This level of performance strongly refutes the prevailing notion that Twitter profile information is useless in general (Pennacchiotti and Popescu, 2011) and especially for geolocation (Cheng et al., 2010; Hecht et al., 2011). We now move to applications beyond social media. Bhargava and Kondrak (2010) have the current state-of-the-art on Origin and Ethnicity based on an SVM using character-n-gram features; we reimplemented this as Ngm. We obtain a huge improvement over their work using Clus, especially on Origin where we reduce error by &gt;50%.4 This improvement can partly be attributed to the small amount of training data; with fewer parameters to learn, Clus learns more from limited data than Ngm. We likewise see large improvements over the s</context>
<context position="34985" citStr="Pennacchiotti and Popescu (2011)" startWordPosition="5579" endWordPosition="5583"> can be combined with our communication-based clusters to achieve even better performance. Indeed, there is evidence that features derived from text can improve the prediction of name ethnicity (Pervouchine et al., 2010). There has been an explosion of work in recent years in predicting user properties in social networks. Aside from the work mentioned above that analyzes a user’s social network, a large amount of work has focused on inferring user properties based on the content they generate (e.g. Burger and Henderson (2006), Schler et al. (2006), Rao et al. (2010), Mukherjee and Liu (2010), Pennacchiotti and Popescu (2011), Burger et al. (2011), Van Durme (2012)). 9 Conclusion and Future Work We presented a highly effective and readily replicable algorithm for generating language resources from Twitter communication patterns. We clustered user attributes based on both the communication of users with those attributes as well as substring similarity. Systems using our clusters significantly outperform state-of-the-art algorithms on each of the tasks investigated, and exceed human performance on each task as well. The power and versatility of our clusters is exemplified by the fact we reduce error by a larger marg</context>
</contexts>
<marker>Pennacchiotti, Popescu, 2011</marker>
<rawString>Marco Pennacchiotti and Ana-Maria Popescu. 2011. A machine learning approach to Twitter user classification. In Proc. ICWSM, pages 281–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Naftali Tishby</author>
<author>Lillian Lee</author>
</authors>
<title>Distributional clustering of English words.</title>
<date>1993</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>183--190</pages>
<contexts>
<context position="29159" citStr="Pereira et al., 1993" startWordPosition="4614" endWordPosition="4617"> 100 1000 10000 Number of training examples Figure 1: Learning curve on Race: Clus perform as well with 30 training examples as Ngm features do with 1000. data; thousands of training examples are needed for Ngm to rival the performance of Clus using only a handful. Since labeled data is generally expensive to obtain or in short supply, our method for exploiting unlabeled Twitter data can both save money and improve top-end performance. 7 Geolocation by Association There is a tradition in computational linguistics of grouping words both by the similarity of their context vectors (Hindle, 1990; Pereira et al., 1993; Lin, 1998) and directly by their statistical association in text (Church and Hanks, 1990; Brown et al., 1992). While the previous sections explored clusters built by vector similarity, we now explore a direct application of our attribute association data (§2). We wish to use this data to improve an existing Twitter geolocation system based on user profile locations. The system operates as follows: 1) normalAccuracy 85 80 75 70 65 60 Clus Ngm 1016 ize user-provided locations using a set of regular expressions (e.g. remove extra spacing, punctuation); 2) look up the normalized location in an a</context>
</contexts>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Fernando Pereira, Naftali Tishby, and Lillian Lee. 1993. Distributional clustering of English words. In Proc. ACL, pages 183–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Pervouchine</author>
<author>Min Zhang</author>
<author>Ming Liu</author>
<author>Haizhou Li</author>
</authors>
<title>Improving name origin recognition with context features and unlabelled data. In Coling 2010: Posters,</title>
<date>2010</date>
<pages>972--978</pages>
<contexts>
<context position="34573" citStr="Pervouchine et al., 2010" startWordPosition="5511" endWordPosition="5514">g namedentity-recognition (Miller et al., 2004; Lin and Wu, 2009; Ratinov and Roth, 2009), syntactic chunking (Turian et al., 2010), and dependency parsing (Koo et al., 2008; Täckström et al., 2012). In each case, 1017 the clusters are derived from the distribution of the words or phrases in text, not from their communication pattern. It would be interesting to see whether prior distributional clusters can be combined with our communication-based clusters to achieve even better performance. Indeed, there is evidence that features derived from text can improve the prediction of name ethnicity (Pervouchine et al., 2010). There has been an explosion of work in recent years in predicting user properties in social networks. Aside from the work mentioned above that analyzes a user’s social network, a large amount of work has focused on inferring user properties based on the content they generate (e.g. Burger and Henderson (2006), Schler et al. (2006), Rao et al. (2010), Mukherjee and Liu (2010), Pennacchiotti and Popescu (2011), Burger et al. (2011), Van Durme (2012)). 9 Conclusion and Future Work We presented a highly effective and readily replicable algorithm for generating language resources from Twitter comm</context>
</contexts>
<marker>Pervouchine, Zhang, Liu, Li, 2010</marker>
<rawString>Vladimir Pervouchine, Min Zhang, Ming Liu, and Haizhou Li. 2010. Improving name origin recognition with context features and unlabelled data. In Coling 2010: Posters, pages 972–978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>David Yarowsky</author>
<author>Abhishek Shreevats</author>
<author>Manaswi Gupta</author>
</authors>
<title>Classifying latent user attributes in Twitter.</title>
<date>2010</date>
<booktitle>In Proc. International Workshop on Search and Mining User-Generated Contents,</booktitle>
<pages>37--44</pages>
<contexts>
<context position="1686" citStr="Rao et al. (2010)" startWordPosition="239" endWordPosition="242">ated on a diverse set of classification tasks that predict hidden users properties such as ethnicity, geographic location, gender, language, and race, using only profile names and locations when appropriate. Our readily-replicable approach and publiclyreleased clusters are shown to be remarkably effective and versatile, substantially outperforming state-of-the-art approaches and human accuracy on each of the tasks studied. 1 Introduction There is growing interest in automatically classifying users in social media by various hidden properties, such as their gender, location, and language (e.g. Rao et al. (2010), Cheng et al. (2010), Bergsma et al. (2012)). Predicting these and other properties for users can enable better advertising and personalization, as well as a finer-grained analysis of user opinions (O’Connor et al., 2010), health (Paul and Dredze, 2011), and sociolinguistic phenomena (Eisenstein et al., 2011). Classifiers for user properties often rely on information from a user’s social network (Jernigan and Mistree, 2009; Sadilek et al., 2012) or the textual content they generate (Pennacchiotti and Popescu, 2011; Burger et al., 2011). Here, we propose and evaluate classifiers that better ex</context>
<context position="34925" citStr="Rao et al. (2010)" startWordPosition="5571" endWordPosition="5574"> to see whether prior distributional clusters can be combined with our communication-based clusters to achieve even better performance. Indeed, there is evidence that features derived from text can improve the prediction of name ethnicity (Pervouchine et al., 2010). There has been an explosion of work in recent years in predicting user properties in social networks. Aside from the work mentioned above that analyzes a user’s social network, a large amount of work has focused on inferring user properties based on the content they generate (e.g. Burger and Henderson (2006), Schler et al. (2006), Rao et al. (2010), Mukherjee and Liu (2010), Pennacchiotti and Popescu (2011), Burger et al. (2011), Van Durme (2012)). 9 Conclusion and Future Work We presented a highly effective and readily replicable algorithm for generating language resources from Twitter communication patterns. We clustered user attributes based on both the communication of users with those attributes as well as substring similarity. Systems using our clusters significantly outperform state-of-the-art algorithms on each of the tasks investigated, and exceed human performance on each task as well. The power and versatility of our clusters</context>
</contexts>
<marker>Rao, Yarowsky, Shreevats, Gupta, 2010</marker>
<rawString>Delip Rao, David Yarowsky, Abhishek Shreevats, and Manaswi Gupta. 2010. Classifying latent user attributes in Twitter. In Proc. International Workshop on Search and Mining User-Generated Contents, pages 37–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
</authors>
<title>Design challenges and misconceptions in named entity recognition.</title>
<date>2009</date>
<booktitle>In Proc. CoNLL,</booktitle>
<pages>147--155</pages>
<contexts>
<context position="34037" citStr="Ratinov and Roth, 2009" startWordPosition="5427" endWordPosition="5430">f their Facebook friends, while Garera and Yarowsky (2009) predict a user’s gender partly based on the gender of their conversational partner. Jha and Elhadad (2010) predict the cancer stage of users of an online cancer discussion board; they derive complementary information for prediction from both the text a user generates and the cancer stage of the people that a user interacts with. The idea of clustering data in order to provide features for supervised systems has been successfully explored in a range of NLP tasks, including namedentity-recognition (Miller et al., 2004; Lin and Wu, 2009; Ratinov and Roth, 2009), syntactic chunking (Turian et al., 2010), and dependency parsing (Koo et al., 2008; Täckström et al., 2012). In each case, 1017 the clusters are derived from the distribution of the words or phrases in text, not from their communication pattern. It would be interesting to see whether prior distributional clusters can be combined with our communication-based clusters to achieve even better performance. Indeed, there is evidence that features derived from text can improve the prediction of name ethnicity (Pervouchine et al., 2010). There has been an explosion of work in recent years in predict</context>
</contexts>
<marker>Ratinov, Roth, 2009</marker>
<rawString>Lev Ratinov and Dan Roth. 2009. Design challenges and misconceptions in named entity recognition. In Proc. CoNLL, pages 147–155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Rifkin</author>
<author>Aldebaro Klautau</author>
</authors>
<title>In defense of one-vs-all classification.</title>
<date>2004</date>
<journal>J. Mach. Learn. Res.,</journal>
<volume>5</volume>
<pages>141</pages>
<contexts>
<context position="16656" citStr="Rifkin and Klautau, 2004" startWordPosition="2562" endWordPosition="2565"> to a classifier. 4 Classification with Cluster Features Our motivating problem is to classify users for hidden properties such as their gender, location, race, ethnicity, and language. We adopt a discriminative solution. We encode the relevant data for each instance in a feature vector and train a (linear) support vector machine classifier (Cortes and Vapnik, 1995). SVMs represent the state-of-the-art on many NLP classification tasks, but other classifiers could also be used. For multi-class classification, we use a oneversus-all strategy, a competitive approach on most multi-class problems (Rifkin and Klautau, 2004). The input to our system is one or more observed user attributes (e.g. name and location fields from a user profile). We now describe how features are created from these attributes in both state-of-the-art systems and via our new cluster data. Token Features (Tok) are binary features that indicate the presence of a specific attribute (e.g., firstname=bob). Burger et al. (2011) and Bergsma et al. (2012) used Tok features to encode user profile features. For multi-token fields (e.g. location), our Tok features also indicate the specific position of each token (e.g., loc1=são, loc2=paulo, locN=b</context>
</contexts>
<marker>Rifkin, Klautau, 2004</marker>
<rawString>Ryan Rifkin and Aldebaro Klautau. 2004. In defense of one-vs-all classification. J. Mach. Learn. Res., 5:101– 141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Roller</author>
<author>Michael Speriosu</author>
<author>Sarat Rallapalli</author>
<author>Benjamin Wing</author>
<author>Jason Baldridge</author>
</authors>
<title>Supervised text-based geolocation using language models on an adaptive grid.</title>
<date>2012</date>
<booktitle>In Proc. EMNLP-CoNLL,</booktitle>
<pages>1500--1510</pages>
<contexts>
<context position="20757" citStr="Roller et al., 2012" startWordPosition="3214" endWordPosition="3217">de French david coste Swedish mattias bjarsmyr Portuguese helder costa Race: black or white black kerry swain black darrell foskey white ty j larocca black james n jones white sean p farrell Table 5: Examples of class (left) and input (names, locations) for some of our evaluation tasks. this domain and have very wide knowledge of global names and locations. 5.2 Twitter Applications Country A number of recent papers have considered the task of predicting the geolocation of users, using both user content (Cheng et al., 2010; Eisenstein et al., 2010; Hecht et al., 2011; Wing and Baldridge, 2011; Roller et al., 2012) and social network (Backstrom et al., 2010; Sadilek et al., 2012). Here, we first predict user location at the level of the user’s location country. To our knowledge, we are the first to exploit user locations and names for this prediction. For this task, we obtain gold data from the portion of Twitter users who have GPS enabled (geocoded tweets). We were able to obtain a very large number of gold instances for this task, so selected only 10K for testing, 10K for development, and retained the remaining 782K for training. Language ID Identifying the language of users is an important prerequisi</context>
</contexts>
<marker>Roller, Speriosu, Rallapalli, Wing, Baldridge, 2012</marker>
<rawString>Stephen Roller, Michael Speriosu, Sarat Rallapalli, Benjamin Wing, and Jason Baldridge. 2012. Supervised text-based geolocation using language models on an adaptive grid. In Proc. EMNLP-CoNLL, pages 1500– 1510.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Sadilek</author>
<author>Henry Kautz</author>
<author>Jeffrey P Bigham</author>
</authors>
<title>Finding your friends and following them to where you are.</title>
<date>2012</date>
<booktitle>In Proc. WSDM,</booktitle>
<pages>723--732</pages>
<contexts>
<context position="2136" citStr="Sadilek et al., 2012" startWordPosition="309" endWordPosition="312">e is growing interest in automatically classifying users in social media by various hidden properties, such as their gender, location, and language (e.g. Rao et al. (2010), Cheng et al. (2010), Bergsma et al. (2012)). Predicting these and other properties for users can enable better advertising and personalization, as well as a finer-grained analysis of user opinions (O’Connor et al., 2010), health (Paul and Dredze, 2011), and sociolinguistic phenomena (Eisenstein et al., 2011). Classifiers for user properties often rely on information from a user’s social network (Jernigan and Mistree, 2009; Sadilek et al., 2012) or the textual content they generate (Pennacchiotti and Popescu, 2011; Burger et al., 2011). Here, we propose and evaluate classifiers that better exploit the attributes that users explicitly provide in their user profiles, such as names (e.g., first names like Mary, last names like Smith) and locations (e.g., Brasil). Such attributes have previously been used as “profile features” in supervised user classifiers (Pennacchiotti and Popescu, 2011; Burger et al., 2011; Bergsma et al., 2012). There are several motivations for exploiting these data. Often the only information available for a user </context>
<context position="20823" citStr="Sadilek et al., 2012" startWordPosition="3226" endWordPosition="3229">costa Race: black or white black kerry swain black darrell foskey white ty j larocca black james n jones white sean p farrell Table 5: Examples of class (left) and input (names, locations) for some of our evaluation tasks. this domain and have very wide knowledge of global names and locations. 5.2 Twitter Applications Country A number of recent papers have considered the task of predicting the geolocation of users, using both user content (Cheng et al., 2010; Eisenstein et al., 2010; Hecht et al., 2011; Wing and Baldridge, 2011; Roller et al., 2012) and social network (Backstrom et al., 2010; Sadilek et al., 2012). Here, we first predict user location at the level of the user’s location country. To our knowledge, we are the first to exploit user locations and names for this prediction. For this task, we obtain gold data from the portion of Twitter users who have GPS enabled (geocoded tweets). We were able to obtain a very large number of gold instances for this task, so selected only 10K for testing, 10K for development, and retained the remaining 782K for training. Language ID Identifying the language of users is an important prerequisite for building languagespecific social media resources (Tromp and</context>
<context position="33156" citStr="Sadilek et al., 2012" startWordPosition="5279" endWordPosition="5282"> both real-world and online social networks, “people socialize with people who are like them in terms of gender, sexual orientation, age, race, education, and religion” (Jernigan and Mistree, 2009). Social media research has exploited this for two main purposes: (1) to predict friendships based on user properties, and (2) to predict user properties based on friendships. Friendship prediction systems (e.g. Facebook’s friend suggestion tool) use features such as whether both people are computer science majors (Taskar et al., 2003) or whether both are at the same location (Crandall et al., 2010; Sadilek et al., 2012). The inverse problem has been explored in the prediction of a user’s location given the location of their peers (Backstrom et al., 2010; Cho et al., 2011; Sadilek et al., 2012). Jernigan and Mistree (2009) predict a user’s sexuality based on the sexuality of their Facebook friends, while Garera and Yarowsky (2009) predict a user’s gender partly based on the gender of their conversational partner. Jha and Elhadad (2010) predict the cancer stage of users of an online cancer discussion board; they derive complementary information for prediction from both the text a user generates and the cancer </context>
</contexts>
<marker>Sadilek, Kautz, Bigham, 2012</marker>
<rawString>Adam Sadilek, Henry Kautz, and Jeffrey P. Bigham. 2012. Finding your friends and following them to where you are. In Proc. WSDM, pages 723–732.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Schler</author>
<author>Moshe Koppel</author>
<author>Shlomo Argamon</author>
<author>James W Pennebaker</author>
</authors>
<title>Effects of age and gender on blogging.</title>
<date>2006</date>
<booktitle>In Proc. AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs,</booktitle>
<pages>199--205</pages>
<contexts>
<context position="34906" citStr="Schler et al. (2006)" startWordPosition="5567" endWordPosition="5570">t would be interesting to see whether prior distributional clusters can be combined with our communication-based clusters to achieve even better performance. Indeed, there is evidence that features derived from text can improve the prediction of name ethnicity (Pervouchine et al., 2010). There has been an explosion of work in recent years in predicting user properties in social networks. Aside from the work mentioned above that analyzes a user’s social network, a large amount of work has focused on inferring user properties based on the content they generate (e.g. Burger and Henderson (2006), Schler et al. (2006), Rao et al. (2010), Mukherjee and Liu (2010), Pennacchiotti and Popescu (2011), Burger et al. (2011), Van Durme (2012)). 9 Conclusion and Future Work We presented a highly effective and readily replicable algorithm for generating language resources from Twitter communication patterns. We clustered user attributes based on both the communication of users with those attributes as well as substring similarity. Systems using our clusters significantly outperform state-of-the-art algorithms on each of the tasks investigated, and exceed human performance on each task as well. The power and versatil</context>
</contexts>
<marker>Schler, Koppel, Argamon, Pennebaker, 2006</marker>
<rawString>Jonathan Schler, Moshe Koppel, Shlomo Argamon, and James W. Pennebaker. 2006. Effects of age and gender on blogging. In Proc. AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs, pages 199–205.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar Täckström</author>
<author>Ryan McDonald</author>
<author>Jakob Uszkoreit</author>
</authors>
<title>Cross-lingual word clusters for direct transfer of linguistic structure.</title>
<date>2012</date>
<booktitle>In Proc. NAACL-HLT,</booktitle>
<pages>477--487</pages>
<contexts>
<context position="34146" citStr="Täckström et al., 2012" startWordPosition="5444" endWordPosition="5447"> of their conversational partner. Jha and Elhadad (2010) predict the cancer stage of users of an online cancer discussion board; they derive complementary information for prediction from both the text a user generates and the cancer stage of the people that a user interacts with. The idea of clustering data in order to provide features for supervised systems has been successfully explored in a range of NLP tasks, including namedentity-recognition (Miller et al., 2004; Lin and Wu, 2009; Ratinov and Roth, 2009), syntactic chunking (Turian et al., 2010), and dependency parsing (Koo et al., 2008; Täckström et al., 2012). In each case, 1017 the clusters are derived from the distribution of the words or phrases in text, not from their communication pattern. It would be interesting to see whether prior distributional clusters can be combined with our communication-based clusters to achieve even better performance. Indeed, there is evidence that features derived from text can improve the prediction of name ethnicity (Pervouchine et al., 2010). There has been an explosion of work in recent years in predicting user properties in social networks. Aside from the work mentioned above that analyzes a user’s social net</context>
</contexts>
<marker>Täckström, McDonald, Uszkoreit, 2012</marker>
<rawString>Oscar Täckström, Ryan McDonald, and Jakob Uszkoreit. 2012. Cross-lingual word clusters for direct transfer of linguistic structure. In Proc. NAACL-HLT, pages 477–487.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Taskar</author>
<author>Ming-Fai Wong</author>
<author>Pieter Abbeel</author>
<author>Daphne Koller</author>
</authors>
<title>Link prediction in relational data.</title>
<date>2003</date>
<booktitle>In Proc. NIPS,</booktitle>
<volume>15</volume>
<contexts>
<context position="33069" citStr="Taskar et al., 2003" startWordPosition="5263" endWordPosition="5266">formation but also Ngm and Tok features as in the previous sections. 8 Related Work In both real-world and online social networks, “people socialize with people who are like them in terms of gender, sexual orientation, age, race, education, and religion” (Jernigan and Mistree, 2009). Social media research has exploited this for two main purposes: (1) to predict friendships based on user properties, and (2) to predict user properties based on friendships. Friendship prediction systems (e.g. Facebook’s friend suggestion tool) use features such as whether both people are computer science majors (Taskar et al., 2003) or whether both are at the same location (Crandall et al., 2010; Sadilek et al., 2012). The inverse problem has been explored in the prediction of a user’s location given the location of their peers (Backstrom et al., 2010; Cho et al., 2011; Sadilek et al., 2012). Jernigan and Mistree (2009) predict a user’s sexuality based on the sexuality of their Facebook friends, while Garera and Yarowsky (2009) predict a user’s gender partly based on the gender of their conversational partner. Jha and Elhadad (2010) predict the cancer stage of users of an online cancer discussion board; they derive compl</context>
</contexts>
<marker>Taskar, Wong, Abbeel, Koller, 2003</marker>
<rawString>Ben Taskar, Ming-Fai Wong, Pieter Abbeel, and Daphne Koller. 2003. Link prediction in relational data. In Proc. NIPS, volume 15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Tromp</author>
<author>Mykola Pechenizkiy</author>
</authors>
<title>Graphbased n-gram language identication on short texts.</title>
<date>2011</date>
<booktitle>In Proc. 20th Machine Learning conference of Belgium and The Netherlands,</booktitle>
<pages>27--34</pages>
<marker>Tromp, Pechenizkiy, 2011</marker>
<rawString>Erik Tromp and Mykola Pechenizkiy. 2011. Graphbased n-gram language identication on short texts. In Proc. 20th Machine Learning conference of Belgium and The Netherlands, pages 27–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: A simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>384--394</pages>
<contexts>
<context position="34079" citStr="Turian et al., 2010" startWordPosition="5433" endWordPosition="5436">rowsky (2009) predict a user’s gender partly based on the gender of their conversational partner. Jha and Elhadad (2010) predict the cancer stage of users of an online cancer discussion board; they derive complementary information for prediction from both the text a user generates and the cancer stage of the people that a user interacts with. The idea of clustering data in order to provide features for supervised systems has been successfully explored in a range of NLP tasks, including namedentity-recognition (Miller et al., 2004; Lin and Wu, 2009; Ratinov and Roth, 2009), syntactic chunking (Turian et al., 2010), and dependency parsing (Koo et al., 2008; Täckström et al., 2012). In each case, 1017 the clusters are derived from the distribution of the words or phrases in text, not from their communication pattern. It would be interesting to see whether prior distributional clusters can be combined with our communication-based clusters to achieve even better performance. Indeed, there is evidence that features derived from text can improve the prediction of name ethnicity (Pervouchine et al., 2010). There has been an explosion of work in recent years in predicting user properties in social networks. As</context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. Word representations: A simple and general method for semi-supervised learning. In Proc. ACL, pages 384–394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Van Durme</author>
</authors>
<title>Streaming analysis of discourse participants.</title>
<date>2012</date>
<booktitle>In Proc. EMNLP-CoNLL,</booktitle>
<pages>48--58</pages>
<marker>Van Durme, 2012</marker>
<rawString>Benjamin Van Durme. 2012. Streaming analysis of discourse participants. In Proc. EMNLP-CoNLL, pages 48–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Wing</author>
<author>Jason Baldridge</author>
</authors>
<title>Simple supervised document geolocation with geodesic grids.</title>
<date>2011</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>955--964</pages>
<contexts>
<context position="20735" citStr="Wing and Baldridge, 2011" startWordPosition="3210" endWordPosition="3213">tadt Dutch bernhard hofstede French david coste Swedish mattias bjarsmyr Portuguese helder costa Race: black or white black kerry swain black darrell foskey white ty j larocca black james n jones white sean p farrell Table 5: Examples of class (left) and input (names, locations) for some of our evaluation tasks. this domain and have very wide knowledge of global names and locations. 5.2 Twitter Applications Country A number of recent papers have considered the task of predicting the geolocation of users, using both user content (Cheng et al., 2010; Eisenstein et al., 2010; Hecht et al., 2011; Wing and Baldridge, 2011; Roller et al., 2012) and social network (Backstrom et al., 2010; Sadilek et al., 2012). Here, we first predict user location at the level of the user’s location country. To our knowledge, we are the first to exploit user locations and names for this prediction. For this task, we obtain gold data from the portion of Twitter users who have GPS enabled (geocoded tweets). We were able to obtain a very large number of gold instances for this task, so selected only 10K for testing, 10K for development, and retained the remaining 782K for training. Language ID Identifying the language of users is a</context>
</contexts>
<marker>Wing, Baldridge, 2011</marker>
<rawString>Benjamin Wing and Jason Baldridge. 2011. Simple supervised document geolocation with geodesic grids. In Proc. ACL, pages 955–964.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>