<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000113">
<title confidence="0.933403">
SPred: Large-scale Harvesting of Semantic Predicates
</title>
<author confidence="0.508005">
Tiziano Flati and Roberto Navigli
</author>
<affiliation confidence="0.312062">
Dipartimento di Informatica
</affiliation>
<address confidence="0.259722">
Sapienza Universit`a di Roma
</address>
<email confidence="0.933557">
{flati,navigli}@di.uniroma1.it
</email>
<sectionHeader confidence="0.991956" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999319375">
We present SPred, a novel method for the
creation of large repositories of semantic
predicates. We start from existing colloca-
tions to form lexical predicates (e.g., break
*) and learn the semantic classes that best
fit the * argument. To do this, we extract
all the occurrences in Wikipedia which
match the predicate and abstract its argu-
ments to general semantic classes (e.g.,
break BODY PART, break AGREEMENT,
etc.). Our experiments show that we are
able to create a large collection of seman-
tic predicates from the Oxford Advanced
Learner’s Dictionary with high precision
and recall, and perform well against the
most similar approach.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999874106060606">
Acquiring semantic knowledge from text automat-
ically is a long-standing issue in Computational
Linguistics and Artificial Intelligence. Over the
last decade or so the enormous abundance of in-
formation and data that has become available has
made it possible to extract huge amounts of pat-
terns and named entities (Etzioni et al., 2005), se-
mantic lexicons for categories of interest (Thelen
and Riloff, 2002; Igo and Riloff, 2009), large do-
main glossaries (De Benedictis et al., 2013) and
lists of concepts (Katz et al., 2003). Recently,
the availability of Wikipedia and other collabora-
tive resources has considerably boosted research
on several aspects of knowledge acquisition (Hovy
et al., 2013), leading to the creation of several
large-scale knowledge resources, such as DBPe-
dia (Bizer et al., 2009), BabelNet (Navigli and
Ponzetto, 2012), YAGO (Hoffart et al., 2013),
MENTA (de Melo and Weikum, 2010), to name
but a few. This wealth of acquired knowledge
is known to have a positive impact on important
fields such as Information Retrieval (Chu-Carroll
and Prager, 2007), Information Extraction (Krause
et al., 2012), Question Answering (Ferrucci et al.,
2010) and Textual Entailment (Berant et al., 2012;
Stern and Dagan, 2012).
Not only are these knowledge resources ob-
tained by acquiring concepts and named entities,
but they also provide semantic relations between
them. These relations are extracted from unstruc-
tured or semi-structured text using ontology learn-
ing from scratch (Velardi et al., 2013) and Open
Information Extraction techniques (Etzioni et al.,
2005; Yates et al., 2007; Wu and Weld, 2010;
Fader et al., 2011; Moro and Navigli, 2013) which
mainly stem from seminal work on is-a relation
acquisition (Hearst, 1992) and subsequent devel-
opments (Girju et al., 2003; Pasca, 2004; Snow et
al., 2004, among others).
However, these knowledge resources still lack
semantic information about language units such
as phrases and collocations. For instance, which
semantic classes are expected as a direct object
of the verb break? What kinds of noun does the
adjective amazing collocate with? Recognition of
the need for systems that are aware of the selec-
tional restrictions of verbs and, more in general, of
textual expressions, dates back to several decades
(Wilks, 1975), but today it is more relevant than
ever, as is testified by the current interest in se-
mantic class learning (Kozareva et al., 2008) and
supertype acquisition (Kozareva and Hovy, 2010).
These approaches leverage lexico-syntactic pat-
terns and input seeds to recursively learn the se-
mantic classes of relation arguments. However,
they require the manual selection of one or more
seeds for each pattern of interest, and this selec-
tion influences the amount and kind of semantic
classes to be learned. Furthermore, the learned
classes are not directly linked to existing resources
such as WordNet (Fellbaum, 1998) or Wikipedia.
The goal of our research is to create a large-
scale repository of semantic predicates whose lex-
ical arguments are replaced by their semantic
classes. For example, given the textual expres-
sion break a toe we want to create the correspond-
</bodyText>
<page confidence="0.935913">
1222
</page>
<note confidence="0.8313294">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1222–1232,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
ing semantic predicate break a BODY PART, where
BODY PART is a class comprising several lexical
realizations, such as leg, arm, foot, etc.
</note>
<bodyText confidence="0.927167">
This paper provides three main contributions:
predicate, such as cup of COUNTRY, referring to
cup as a prize instead of cup as a container.
</bodyText>
<note confidence="0.706453">
3 Large-Scale Harvesting of Semantic
Predicates
</note>
<listItem confidence="0.9564041">
• We propose SPred, a novel approach which
harvests predicates from Wikipedia and gen-
eralizes them by leveraging core concepts
from WordNet.
• We create a large-scale resource made up of
semantic predicates.
• We demonstrate the high quality of our se-
mantic predicates, as well as the generality
of our approach, also in comparison with our
closest competitor.
</listItem>
<sectionHeader confidence="0.975717" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<bodyText confidence="0.989555705882353">
We introduce two preliminary definitions which
we use in our approach.
Definition 1(lexical predicate). A lexical pred-
icate w1 w2 ... wz * wz+1 ... wn is a regular
expression, where wj are tokens (j = 1, ... , n), *
matches any sequence of one or more tokens, and
i E 10, ... , n}. We call the token sequence which
matches * the filling argument of the predicate.
For example, a * of milk matches occurrences
such as a full bottle of milk, a glass of milk, a car-
ton of milk, etc. While in principle * could match
any sequence of words, since we aim at general-
izing nouns, in what follows we allow * to match
only noun phrases (e.g., glass, hot cup, very big
bottle, etc.).
Definition 2 (semantic predicate). A semantic
predicate is a sequence w1 w2 ... wz c wz+1
... wn, where wj are tokens (j = 1, ... , n),
c E C is a semantic class selected from a fixed
set C of classes, and i E 10,... , n}.
As an example, consider the semantic predicate
cup of BEVERAGE,1 where BEVERAGE is a se-
mantic class representing beverages. This pred-
icate matches phrases like cup of coffee, cup of
tea, etc., but not cup of sky. Other examples in-
clude: MUSICAL INSTRUMENT is played by, a
CONTAINER of milk, break AGREEMENT, etc.
Semantic predicates mix the lexical information
of a given lexical predicate with the explicit se-
mantic modeling of its argument. Importantly, the
same lexical predicate can have different classes as
its argument, like cup of FOOD vs. cup of BEVER-
AGE. Note, however, that different classes might
convey different semantics for the same lexical
</bodyText>
<footnote confidence="0.9703795">
1In what follows we denote the SEMANTIC CLASS in
small capitals and the lexical predicate in italics.
</footnote>
<bodyText confidence="0.99947575">
The goal of this paper is to provide a fully auto-
matic approach for the creation of a large repos-
itory of semantic predicates in three phases. For
each lexical predicate of interest (e.g., break *):
</bodyText>
<listItem confidence="0.978177545454545">
1. We extract all its possible filling arguments
from Wikipedia, e.g., lease, contract, leg,
arm, etc. (Section 3.1).
2. We disambiguate as many filling arguments
as possible using Wikipedia, obtaining a
set of corresponding Wikipedia pages, e.g.,
Lease, Contract, etc. (Section 3.2).
3. We create the semantic predicates by general-
izing the Wikipedia pages to their most suit-
able semantic classes, e.g., break AGREE-
MENT, break LIMB, etc. (Section 3.3).
</listItem>
<bodyText confidence="0.99462375">
We can then exploit the learned semantic predi-
cates to assign the most suitable semantic class to
new filling arguments for the given lexical predi-
cate (Section 3.4).
</bodyText>
<subsectionHeader confidence="0.999902">
3.1 Extraction of Filling Arguments
</subsectionHeader>
<bodyText confidence="0.999893818181818">
Let 7r be an input lexical predicate (e.g., break *).
We search the English Wikipedia for all the to-
ken sequences which match 7r, resulting in a list
of noun phrases filling the * argument. We show
an excerpt of the output obtained when searching
Wikipedia for the arguments of the lexical predi-
cate a * of milk in Table 1. As can be seen, a wide
range of noun phrases are extracted, from quanti-
ties such as glass and cup to other aspects, such as
brand and constituent.
The output of this first step is a set Lπ of triples
(a, s, l) of filling arguments a matching the lexi-
cal predicate 7r in a sentence s of the Wikipedia
corpus, with a potentially linked to a page l (e.g.,
see the top 3 rows in Table 1; l = c if no link is
provided, see bottom rows of the Table).2 Note
that Wikipedia is the only possible corpus that can
be used here for at least two reasons: first, in or-
der to extract relevant arguments, we need a large
corpus of a definitional nature; second, we need
wide-coverage semantic annotations of filling ar-
guments.
</bodyText>
<subsectionHeader confidence="0.999916">
3.2 Disambiguation of Filling Arguments
</subsectionHeader>
<bodyText confidence="0.979549">
The objective of the second step is to disambiguate
as many arguments in Lπ as possible for the lex-
</bodyText>
<footnote confidence="0.987075">
2We will also refer to l as the sense of a in sentence s.
</footnote>
<page confidence="0.977366">
1223
</page>
<tableCaption confidence="0.919085">
a full [[bottle]] of milk
a nice hot [[cup]] of milk
a cold [[glass]] of milk
a very big bottle of milk
a brand of milk
a constituent of milk
Table 1: An excerpt of the token sequences
</tableCaption>
<bodyText confidence="0.996697">
which match the lexical predicate a * of milk in
Wikipedia (filling argument shown in the second
column; following the Wikipedia convention we
provide links in double square brackets).
ical predicate π. We denote Dπ = {(a, s, l) :
l =6 c} ⊆ Lπ as the set of those arguments origi-
nally linked to the corresponding Wikipedia page
(like the top three linked arguments in Table 1).
Therefore, in the rest of this section we will focus
only on the remaining triples (a, s, c) ∈ Uπ, where
Uπ = Lπ \Dπ, i.e., those triples whose arguments
are not semantically annotated. Our goal is to re-
place c with an appropriate sense, i.e., page, for a.
For each such triple (a, s, c) ∈ Uπ, we apply the
following disambiguation heuristics:
</bodyText>
<listItem confidence="0.969820612903226">
• One sense per page: if another occurrence
of a in the same Wikipedia page (indepen-
dent of the lexical predicate) is linked to a
page l, then remove (a, s, c) from Uπ and add
(a, s, l) to Dπ. In other words, we propa-
gate an existing annotation of a in the same
Wikipedia page and apply it to our ambigu-
ous item. For instance, cup of coffee appears
in the Wikipedia page Energy drink in the
sentence “[... ] energy drinks contain more
caffeine than a strong cup of coffee”, but this
occurrence of coffee is not linked. How-
ever the second paragraph contains the sen-
tence “[[Coffee]], tea and other naturally caf-
feinated beverages are usually not considered
energy drinks”, where coffee is linked to the
Coffee page. This heuristic naturally reflects
the broadly known assumption about lexi-
cal ambiguity presented in (Yarowsky, 1995),
namely the one-sense-per-discourse heuris-
tic.
• One sense per lexical predicate: if
∃(a, s&apos;, l) ∈ Dπ, then remove (a, s, c) from
Uπ and add (a, s, l) to Dπ. If multiple senses
of a are available, choose the most frequent
one in Dπ. For example, in the page Singa-
porean cuisine the occurrence of coffee in the
sentence “[... ] combined with a cup of cof-
fee and a half-boiled egg” is not linked, but
we have collected many other occurrences,
all linked to the Coffee page, so this link
</listItem>
<bodyText confidence="0.9965575">
gets propagated to our ambiguous item as
well. This heuristic mimes the one-sense-per-
collocation heuristic presented in (Yarowsky,
1995).
</bodyText>
<listItem confidence="0.93326">
• Trust the inventory: if Wikipedia provides
only one sense for a, i.e., only one page title
whose lemma is a, link a to that page. Con-
sider the instance “At that point, Smith threw
down a cup of Gatorade” in page Jimmy
Clausen; there is only one sense for Gatorade
in Wikipedia, so we link the unannotated oc-
currence to it.
</listItem>
<bodyText confidence="0.999805090909091">
As a result, the initial set of disambiguated ar-
guments in Dπ is augmented with all those triples
for which any of the above three heuristics apply.
Note that Dπ might contain the same argument
several times, occurring in different sentences and
linked many times to the same page or to differ-
ent pages. Notably, the discovery of new links is
made through one scan of Wikipedia per heuristic.
The three disambiguation strategies, applied in the
same order as presented above, contribute to pro-
moting the most relevant sense for a given word.
</bodyText>
<listItem confidence="0.7778486">
Finally, let A be the set of arguments in Dπ,
i.e., A := {a : ∃(a, s, l) ∈ Dπ}. For each argu-
ment a ∈ A we select the majority sense sense(a)
of a and collect the corresponding set of sen-
tences sent(a) marked with that sense. Formally,
</listItem>
<equation confidence="0.773916666666667">
sense(a) := arg maxl|{(x, y, z) ∈ Dπ : x =
a∧z = l} |and sent(a) := {s : (a, s, sense(a)) ∈
Dπ}.
</equation>
<subsectionHeader confidence="0.998305">
3.3 Generalization to Semantic Classes
</subsectionHeader>
<bodyText confidence="0.999953888888889">
Our final objective is to generalize the annotated
arguments to semantic classes picked out from a
fixed set C of classes. As explained below, we as-
sume the set C to be made up of representative
synsets from WordNet. We perform this in two
substeps: we first link all our disambiguated argu-
ments to WordNet (Section 3.3.1) and then lever-
age the WordNet taxonomy to populate the seman-
tic classes in C (Section 3.3.2).
</bodyText>
<subsectionHeader confidence="0.99485">
3.3.1 Linking to WordNet
</subsectionHeader>
<bodyText confidence="0.9999745">
So far the arguments in Dπ have been semanti-
cally annotated with the Wikipedia pages they re-
fer to. However, using Wikipedia as our sense in-
ventory is not desirable; in fact, contrarily to other
commonly used lexical-semantic networks such
as WordNet, Wikipedia is not formally organized
in a structured, taxonomic hierarchy. While it is
true that attached to each Wikipedia page there are
one or more categories, these categories just pro-
vide shallow information about the class the page
</bodyText>
<page confidence="0.966527">
1224
</page>
<bodyText confidence="0.999952638297873">
belongs to. Indeed, categories are not ideal for
representing the semantic classes of a Wikipedia
page for at least three reasons: i) many cate-
gories do not express taxonomic information (e.g.,
the English page Albert Einstein provides cate-
gories such as DEATHS FROM ABDOMINAL AOR-
TIC ANEURYSM and INSTITUTE FOR ADVANCED
STUDY FACULTY); ii) categories are mostly struc-
tured in a directed acyclic graph with multiple
parents per category (even worse, cycles are pos-
sible in principle); iii) there is no clear way of
identifying core semantic classes from the large
set of available categories. Although efforts to-
wards the automatic taxonomization of Wikipedia
categories do exist in the literature (Ponzetto and
Strube, 2011; Nastase and Strube, 2013), the re-
sults are of a lower quality than a hand-built lexical
resource. Therefore, as was done in previous work
(Mihalcea and Moldovan, ; Ciaramita and Altun,
2006; Izquierdo et al., 2009; Erk and McCarthy,
2009; Huang and Riloff, 2010), we pick out our
semantic classes C from WordNet and leverage its
manually-curated taxonomy to associate our argu-
ments with the most suitable class. This way we
avoid building a new taxonomy and shift the prob-
lem to that of projecting the Wikipedia pages –
associated with annotated filling arguments – to
synsets in WordNet. We address this problem in
two steps:
Wikipedia-WordNet mapping. We exploit an
existing mapping implemented in BabelNet (Nav-
igli and Ponzetto, 2012), a wide-coverage
multilingual semantic network that integrates
Wikipedia and WordNet.3 Based on a disam-
biguation algorithm, BabelNet establishes a map-
ping µ : Wikipages -+ Synsets which links
about 50,000 pages to their most suitable Word-
Net senses.4
Mapping extension. Nevertheless, BabelNet is
able to solve the problem only partially, because it
still leaves the vast majority of the 4 million En-
glish Wikipedia pages unmapped. This is mainly
due to the encyclopedic nature of most pages,
which do not have a counterpart in the WordNet
dictionary. To address this issue, for each un-
mapped Wikipedia page p we obtain its textual
definition as the first sentence of the page.5 Next,
</bodyText>
<footnote confidence="0.974898">
3http://babelnet.org
4We follow (Navigli, 2009) and denote with w&apos; the i-th
sense of w in WordNet with part of speech p.
5According to the Wikipedia guidelines, “The article
should begin with a short declarative sentence, answer-
ing two questions for the nonspecialist reader: What (or
who) is the subject? and Why is this subject notable?”,
extracted from http://en.wikipedia.org/wiki/
</footnote>
<bodyText confidence="0.999916631578948">
we extract the hypernym from the textual defini-
tion of p by applying Word-Class Lattices (Navigli
and Velardi, 2010, WCL6), a domain-independent
hypernym extraction system successfully applied
to taxonomy learning from scratch (Velardi et al.,
2013) and freely available online (Faralli and Nav-
igli, 2013). If a hypernym h is successfully ex-
tracted and h is linked to a Wikipedia page p&apos;
for which µ(p&apos;) is defined, then we extend the
mapping by setting µ(p) := µ(p&apos;). For instance,
the mapping provided by BabelNet does not pro-
vide any link for the page Peter Spence; thanks to
WCL, though, we are able to set the page Jour-
nalist as its hypernym, and link it to the WordNet
synset journalists.
This way our mapping extension now covers
539,954 pages, i.e., more than an order of mag-
nitude greater than the number of pages originally
covered by the BabelNet mapping.
</bodyText>
<subsectionHeader confidence="0.98753">
3.3.2 Populating the Semantic Classes
</subsectionHeader>
<bodyText confidence="0.999351833333333">
We now proceed to populating the semantic
classes in C with the annotated arguments ob-
tained for the lexical predicate π.
Definition 3 (semantic class of a synset). The
semantic class for a WordNet synset S is the class
c among those in C which is the most specific hy-
pernym of S according to the WordNet taxonomy.
For instance, given the synset tap waters, its se-
mantic class is waters (while the other more gen-
eral subsumers in C are not considered, e.g., com-
pounds, chemicals, liquids, etc).
For each argument a E A for which a
Wikipedia-to-WordNet mapping µ(sense(a))
could be established as a result of the linking
procedure described above, we associate a with
the semantic class of µ(sense(a)). For example,
consider the case in which a is equal to tap water
and sense(a) is equal to the Wikipedia page Tap
water, in turn mapped to tap waters via µ; we
thus associate tap water with its semantic class
waters. If more than one class can be found we
add a to each of them.7
Ultimately, for each class c E C, we obtain
a set support(c) made up of all the arguments
a E A associated with c. For instance, sup-
port(beverages) = { chinese tea, 3.2% beer, hot
cocoa, cider, ... , orange juice }. Note that, thanks
to our extended mapping (cf. Section 3.3.1), the
support of a class can also contain arguments not
covered in WordNet (e.g., hot cocoa and tejuino).
</bodyText>
<footnote confidence="0.9731955">
Wikipedia:Writing—better—articles.
6http://lcl.uniroma1.it/wcl
7This can rarely happen due to multiple hypernyms avail-
able in WordNet for the same synset.
</footnote>
<page confidence="0.92624">
1225
</page>
<table confidence="0.990446466666667">
Pclass(c|π) c support(c)
0.1896 wine� wine, sack, white wine, red wine, wine in china, madeira wine, claret, kosher wine
0.1805 � turkish coffee, drip coffee, espresso, coffee, cappucino, caff`e latte, decaffeinated coffee, latte
0.1143 coffee�� green tea, indian tea, black tea, orange pekoe tea, tea
0.1104 herb� water, seawater
0.0532 � chinese tea, 3.2% beer, orange soda, boiled water, hot chocolate, hot cocoa, tejuino, cider,
0.0403 water� beverage, cocoa, coffee milk, lemonade, orange juice
0.0351 � skim milk, milk, cultured buttermilk, whole milk
0.0273 beverage�� 3.2% beer, beer
0.0182 milk� mead, umeshu, kava, rice wine, j¨agermeister, kvass, sake, gin, rum
� poison
beer�
�
alcohol��
poison��
</table>
<tableCaption confidence="0.9956075">
Table 2: Highest-probability semantic classes for the lexical predicate π = cup of *, according to our set
C of semantic classes.
</tableCaption>
<bodyText confidence="0.9964132">
Since not all classes are equally relevant to the
lexical predicate π, we estimate the conditional
probability of each class c E C given π on the
basis of the number of sentences which contain an
argument in that class. Formally:
</bodyText>
<equation confidence="0.998932">
Pclass(c|π) = EaEsupport(c) |sent(a) |, (1)
Z
</equation>
<bodyText confidence="0.795163">
where
</bodyText>
<equation confidence="0.6825415">
�Z` is a normalization factor calculated as
Z = F-c�EC EaEsupport(c )  |sent(a) |. As an ex-
</equation>
<bodyText confidence="0.997933333333333">
ample, in Table 2 we show the highest-probability
classes for the lexical predicate cup of *.
As a result of the probabilistic association of
each semantic class c with a target lexical predi-
cate w1 w2 ... wi * wi+1 ... wn, we obtain a
semantic predicate w1 w2 ... wi c wi+1 ... wn.
</bodyText>
<subsectionHeader confidence="0.997808">
3.4 Classification of new arguments
</subsectionHeader>
<bodyText confidence="0.982520428571428">
Once the semantic predicates for the input lexical
predicate π have been learned, we can classify a
new filling argument a of π. However, the class
probabilities calculated with Formula 1 might not
provide reliable scores for several classes, includ-
ing unseen ones whose probability would be 0.
To enable wide coverage we estimate a second
conditional probability based on the distributional
semantic profile of each class. To do this, we per-
form three steps:
1. For each WordNet synset S we create a dis-
tributional vector S~ summing the noun occur-
rences within all the Wikipedia pages p such
that µ(p) = S. Next, we create a distribu-
tional vector for each class c E C as follows:
c~= ESEdesc(c) ~S,
where desc(c) is the set of all synsets
which are descendants of the semantic class
c in WordNet. As a result we obtain a
predicate-independent distributional descrip-
tion for each semantic class in C.
</bodyText>
<listItem confidence="0.900010230769231">
2. Now, given an argument a of a lexical predi-
cate π, we create a distributional vector a~ by
summing the noun occurrences of all the sen-
tences s such that (a, s, l) E Lπ (cf. Section
3.1).
3. Let Ca be the set of candidate semantic
classes for argument a, i.e., Ca contains the
semantic classes for the WordNet synsets of
a as well as the semantic classes associated
with µ(p) for all Wikipedia pages p whose
lemma is a. For each candidate class c E Ca,
we determine the cosine similarity between
the distributional vectors c~ and a~ as follows:
</listItem>
<equation confidence="0.967775">
sim(~c,~a) =
</equation>
<bodyText confidence="0.999428">
Then, we determine the most suitable seman-
tic class c E Ca of argument a as the class
with the highest distributional probability, es-
timated as:
</bodyText>
<equation confidence="0.978664">
sim(~c,~a)
Pdistr(c|π, a) = Ec ECa sim(~c &amp;quot;~a). (2)
</equation>
<bodyText confidence="0.999916">
We can now choose the most suitable class c E
Ca for argument a which maximizes the proba-
bility mixture of the distributional probability in
Formula 2 and the class probability in Formula 1:
</bodyText>
<equation confidence="0.9902895">
P(c|π, a) = αPdistr(c|π, a)+(1−α)Pclass(c|π),
(3)
</equation>
<bodyText confidence="0.995603555555555">
where α E [0, 1] is an interpolation factor.
We now illustrate the entire process of our al-
gorithm on a real example. Given a textual ex-
pression such as virus replicate, we: (i) extract
all the filling arguments of the lexical predicate
* replicate; (ii) link and disambiguate the ex-
tracted filling arguments; (iii) query our system for
the available virus semantic classes (i.e., {virus1n,
virus3n}); (iv) build the distributional vectors for
</bodyText>
<equation confidence="0.869037">
c~ - a~
||~c  |~a||.
</equation>
<page confidence="0.887429">
1226
</page>
<bodyText confidence="0.999395142857143">
the candidate semantic classes and the given in-
put argument; (v) calculate the probability mix-
ture. As a result we obtain the following rank-
ing, virus1n:0.250, virusn:0.000894, so that the first
sense of virus in WordNet 3.0 is preferred, being
an “ultramicroscopic infectious agent that repli-
cates itself only within cells of living hosts”.
</bodyText>
<sectionHeader confidence="0.9260395" genericHeader="method">
4 Experiment 1: Oxford Lexical
Predicates
</sectionHeader>
<bodyText confidence="0.999885666666667">
We evaluate on the two forms of output produced
by SPred: (i) the top-ranking semantic classes of a
lexical predicate, as obtained with Formula 1, and
(ii) the classification of a lexical predicate’s argu-
ment with the most suitable semantic class, as pro-
duced using Formula 3. For both evaluations, we
use a lexical predicate dataset built from the Ox-
ford Advanced Learner’s Dictionary (Crowther,
1998).
</bodyText>
<subsectionHeader confidence="0.999618">
4.1 Set of Semantic Classes
</subsectionHeader>
<bodyText confidence="0.9999796">
The selection of which semantic classes to include
in the set C is of great importance. In fact, hav-
ing too many classes will end up in an overly fine-
grained inventory of meanings, whereas an exces-
sively small number of classes will provide lit-
tle discriminatory power. As our set C of seman-
tic classes we selected the standard set of 3,299
core nominal synsets available in WordNet.8 How-
ever, our approach is flexible and can be used with
classes of an arbitrary level of granularity.
</bodyText>
<subsectionHeader confidence="0.875256">
4.2 Datasets
</subsectionHeader>
<bodyText confidence="0.99984">
The Oxford Advanced Learner’s Dictionary pro-
vides usage notes that contain typical predicates in
various semantic domains in English, e.g., Travel-
ing.9 Each predicate is made up of a fixed part
(e.g., a verb) and a generalizable part which con-
tains one or more nouns.
Examples include fix an election/the vote, bac-
teria/microbes/viruses spread, spend money/sav-
ings/a fortune. In the case that more than one
noun was provided, we split the textual expres-
sion into as many items as the number of nouns.
For instance, from spend money/savings/a fortune
we created three items in our dataset, i.e., spend
money, spend savings, spend a fortune. The split-
ting procedure generated 6,220 instantiated lexical
predicate items overall.
</bodyText>
<footnote confidence="0.98436775">
8http://wordnetcode.princeton.edu/
standoff-files/core-wordnet.txt
9http://oald8.oxfordlearnersdictionaries.
com/usage_notes/unbox_colloc/
</footnote>
<table confidence="0.999983428571429">
k Prec@k Correct Total
1 0.94 46 49
2 0.87 85 98
3 0.86 124 145
4 0.83 160 192
5 0.82 194 237
6 0.81 228 282
7 0.80 261 326
8 0.78 288 370
9 0.77 318 414
10 0.76 349 458
11 0.75 379 502
12 0.75 411 546
13 0.75 445 590
14 0.76 479 634
15 0.75 510 678
16 0.75 544 721
17 0.76 577 763
18 0.76 612 806
19 0.76 643 849
20 0.75 671 892
</table>
<tableCaption confidence="0.978625">
Table 3: Precision@k for ranking the semantic
classes of lexical predicates.
</tableCaption>
<subsectionHeader confidence="0.99896">
4.3 Evaluating the Semantic Class Ranking
</subsectionHeader>
<bodyText confidence="0.999997037037037">
Dataset. Given the above dataset, we general-
ized each item by pairing its fixed verb part with *
(i.e., we keep “verb predicates” only, since they
are more informative). For instance, the three
items bacteria/microbes/viruses spread were gen-
eralized into the lexical predicate * spread. The to-
tal number of different lexical predicates obtained
was 1,446, totaling 1,429 distinct verbs (note that
the dataset might contain the lexical predicate *
spread as well as spread *).10
Methodology. For each lexical predicate we cal-
culated the conditional probability of each seman-
tic class using Formula 1, resulting in a ranking
of semantic classes. To evaluate the top ranking
classes, we calculated precision@k, with k rang-
ing from 1 to 20, by counting all applicable classes
as correct, e.g., location1n is a valid semantic class
for travel to * while emotion1n is not.
Results. We show in Table 3 the precision@k
calculated over a random sample of 50 lexical
predicates.11 As can be seen, while the classes
quality is pretty high with low values of k, per-
formance gradually degrades as we let k increase.
This is mostly due to the highly polysemous nature
of the predicates selected (e.g., occupy *, leave *,
help *, attain *, live *, etc.). We note that high per-
formance, attaining above 80%, can be achieved
</bodyText>
<footnote confidence="0.99674625">
10The low number of items per predicate is due to the orig-
inal Oxford resource.
11One lexical predicate did not have any semantic class
ranking.
</footnote>
<page confidence="0.995459">
1227
</page>
<bodyText confidence="0.996775">
by focusing up to the first 7 classes output by our
system, with a 94% precision@1.
</bodyText>
<subsectionHeader confidence="0.997541">
4.4 Evaluating Classification Performance
</subsectionHeader>
<bodyText confidence="0.999964791666667">
Dataset. Starting from the lexical predicate
items obtained as described in Section 4.2, we se-
lected those items belonging to a random sample
of 20 usage notes among those provided by the
Oxford dictionary, totaling 3,245 items. We then
manually tagged each item’s argument (e.g., virus
in viruses spread) with the most suitable seman-
tic class (e.g., virusn), obtaining a gold standard
dataset for the evaluation of our argument classifi-
cation algorithm (cf. Section 3.4).
Methodology. In this second evaluation we
measure the accuracy of our method at assigning
the most suitable semantic class to the argument
of a lexical predicate item in our gold standard.
We use three customary measures to determine the
quality of the acquired semantic classes, i.e., pre-
cision, recall and F1. Precision is the number of
items which are assigned the correct class (as eval-
uated by a human) over the number of items which
are assigned a class by the system. Recall is the
number of items which are assigned the correct
class over the number of items to be classified. F1
is the harmonic mean of precision and recall.
Tuning. The only parameter to be tuned is the
factor α that we use to mix the two probabilities
in Formula 3 (cf. Section 3.4). For tuning α we
used a held-out set of 8 verbs, randomly sampled
from the lexical predicates not used in the dataset.
We created a tuning set using the annotated argu-
ments in Wikipedia for these verbs: we trained the
model on 80% of the annotated lexical predicate
arguments (i.e., the class probability estimates in
Formula 1) and then applied the probability mix-
ture (i.e., Formula 3) for classifying the remain-
ing 20% of arguments. Finally, we calculated the
performance in terms of precision, recall and F1
with 11 different values of α E {0, 0.1, ... ,1.0},
achieving optimal performance with α = 0.2.
Results. Table 4 shows the results on the seman-
tic class assignments. Our system shows very high
precision, above 85%, while at the same time at-
taining an adequate 68% recall. We also compared
against a random baseline that randomly selects
one out of all the candidate semantic classes for
each item, achieving only moderate results. A sub-
sequent error analysis revealed the common types
of error produced by our system: terms for which
we could not provide (1) any WordNet concept
</bodyText>
<table confidence="0.990986">
Method Precision Recall F1
SPred 85.61 68.01 75.80
Random 40.96 40.96 40.96
</table>
<tableCaption confidence="0.89731075">
Table 4: Performance on semantic class assign-
ment.
(e.g., political corruption) or (2) any candidate se-
mantic class (e.g., immune system).
</tableCaption>
<subsectionHeader confidence="0.987102">
4.5 Disambiguation heuristics impact
</subsectionHeader>
<bodyText confidence="0.999973260869565">
As a follow-up analysis, for each dataset we con-
sidered the impact of each disambiguation heuris-
tic described in Section 3.2 according to how many
times it was triggered. Starting from the entire set
of 1,446 lexical predicates from the Oxford dictio-
nary (see Section 4.3), we counted the number of
argument triples (a, s, l) already disambiguated in
Wikipedia (i.e., l =� E) and those disambiguated
thanks to our disambiguation strategies. Table
5 shows the statistics. We note that, while the
amount of originally linked arguments is very low
(about 2.5% of total), our strategies are able to
considerably increase the size of the initial set of
linked instances. The most effective strategies ap-
pear to be the One sense per page and the Trust the
inventory, which contribute 26.16% and 31.33%
of the total links, respectively.
Even though most of the triples (i.e., 68 out of
almost 74 million) remain unlinked, the ratio of
distinct arguments which we linked to WordNet
is considerably higher, calculated as 3,723,979
linked arguments over 12,431,564 distinct argu-
ments, i.e., about 30%.
</bodyText>
<sectionHeader confidence="0.835759" genericHeader="method">
5 Experiment 2: Comparison with
Kozareva &amp; Hovy (2010)
</sectionHeader>
<bodyText confidence="0.99828925">
Due to the novelty of the task carried out by SPred,
the resulting output may be compared with only a
limited number of existing approaches. The most
similar approach is that of Kozareva and Hovy
(2010, K&amp;H) who assign supertypes to the argu-
ments of arbitrary relations, a task which resem-
bles our semantic predicate ranking. We therefore
performed a comparison on the quality of the most
highly-ranked supertypes (i.e., semantic classes)
using their dataset of 24 relation patterns (i.e., lex-
ical predicates).
Dataset. The dataset contained 14 lexical pred-
icates (e.g., work for * or *fly to), 10 of which
were expanded in order to semantify their left- and
right-side arguments (e.g., * work for and work
for *); for the remaining 4 predicates just a single
</bodyText>
<page confidence="0.97252">
1228
</page>
<table confidence="0.991012333333333">
Total Linked in One sense One sense per Trust the Not
triples Wikipedia per page lexical predicate inventory linked
73,843,415 1,795,608 1,433,634 533,946 1,716,813 68,363,414
</table>
<tableCaption confidence="0.992523">
Table 5: Statistics on argument triple linking for all the lexical predicates in the Oxford dataset.
</tableCaption>
<table confidence="0.999961333333333">
k Prec@k Correct Total
1 0.88 21 24
2 0.90 43 48
3 0.88 63 72
4 0.89 85 96
5 0.91 109 120
6 0.91 131 144
7 0.92 154 168
8 0.91 175 192
9 0.92 198 216
10 0.92 221 240
11 0.92 242 264
12 0.92 264 288
13 0.91 284 312
14 0.90 304 336
15 0.91 327 360
16 0.91 348 384
17 0.90 367 408
18 0.89 386 432
19 0.89 407 456
20 0.89 429 480
</table>
<tableCaption confidence="0.869669">
Table 6: Precision@k for the semantic classes of
the relations of Kozareva and Hovy (2010).
</tableCaption>
<bodyText confidence="0.996344730769231">
side was generalized (e.g., * dress). While most of
the relations apply to persons as a supertype, our
method could find arguments for each of them.
Methodology. We carried out the same evalua-
tion as in Section 4.3. We calculated precision@k
of the semantic classes obtained for each relation
in the dataset of K&amp;H. Because the set of appli-
cable classes was potentially unbounded, we were
not able to report recall directly.
Results. K&amp;H reported an overall accuracy of
the top-20 supertypes of 92%. As can be seen in
Table 6 we exhibit very good performance with in-
creasing values of k. A comparison of Table 3 with
Table 6 shows considerable differences in perfor-
mance between the two datasets. We attribute this
difference to the higher average WordNet poly-
semy of the verbal component of the Oxford pred-
icates (on average 2.64 senses for K&amp;H against
6.52 for the Oxford dataset).
Although we cannot report recall, we list the
number of Wikipedia arguments and associated
classes in Table 7, which provides an estimate of
the extraction capability of SPred. The large num-
ber of classes found for the arguments demon-
strates the ability of our method to generalize to
a variety of semantic classes.
</bodyText>
<table confidence="0.998721153846154">
Predicate Number of args Number of classes
cause * 181,401 1,339
live in * 143,628 600
go to * 134,712 867
* cause 92,160 1,244
work in * 79,444 770
* go to 71,794 746
* live in 61,074 541
work on * 58,760 840
work for * 58,332 681
work at * 31,904 511
* work in 24,933 528
* celebrate 23,333 408
</table>
<tableCaption confidence="0.6436775">
Table 7: Number of arguments and associated
classes for the 12 most frequent lexical predicates
of Kozareva and Hovy (2010) extracted by SPred
from Wikipedia.
</tableCaption>
<sectionHeader confidence="0.999545" genericHeader="method">
6 Related work
</sectionHeader>
<bodyText confidence="0.9998779">
The availability of Web-scale corpora has led to
the production of large resources of relations (Et-
zioni et al., 2005; Yates et al., 2007; Wu and Weld,
2010; Carlson et al., 2010; Fader et al., 2011).
However, these resources often operate purely at
the lexical level, providing no information on the
semantics of their arguments or relations. Several
studies have examined adding semantics through
grouping relations into sets (Yates and Etzioni,
2009), ontologizing the arguments (Chklovski and
Pantel, 2004), or ontologizing the relations them-
selves (Moro and Navigli, 2013). However, analy-
sis has largely been either limited to ontologizing
a small number of relation types with a fixed in-
ventory, which potentially limits coverage, or has
used implicit definitions of semantic categories
(e.g., clusters of arguments), which limits inter-
pretability. For example, Mohamed et al. (2011)
use the semantic categories of the NELL system
(Carlson et al., 2010) to learn roughly 400 valid
ontologized relations from over 200M web pages,
whereas WiSeNet (Moro and Navigli, 2012) lever-
ages Wikipedia to acquire relation synsets for an
open set of relations. Despite these efforts, no
large-scale resource has existed to date that con-
tains ontologized lexical predicates. In contrast,
the present work provides a high-coverage method
for learning argument supertypes from a broad-
coverage ontology (WordNet), which can poten-
tially be leveraged in relation extraction to ontolo-
</bodyText>
<page confidence="0.988948">
1229
</page>
<bodyText confidence="0.999430568965517">
gize relation arguments.
Our method for identifying the different seman-
tic classes of predicate arguments is closely related
to the task of identifying selectional preferences.
The most similar approaches to it are taxonomy-
based ones, which leverage the semantic types
of the relations arguments (Resnik, 1996; Li and
Abe, 1998; Clark and Weir, 2002; Pennacchiotti
and Pantel, 2006). Nevertheless, despite their high
quality sense-tagged data, these methods have of-
ten suffered from lack of coverage. As a result,
alternative approaches have been proposed that es-
chew taxonomies in favor of rating the quality of
potential relation arguments (Erk, 2007; Cham-
bers and Jurafsky, 2010) or generating probabil-
ity distributions over the arguments (Rooth et al.,
1999; Pantel et al., 2007; Bergsma et al., 2008;
Ritter et al., 2010; S´eaghdha, 2010; Bouma, 2010;
Jang and Mostow, 2012) in order to obtain higher
coverage of preferences.
In contrast, we overcome the data sparsity of
class-based models by leveraging the large quan-
tity of collaboratively-annotated Wikipedia text in
order to connect predicate arguments with their
semantic class in WordNet using BabelNet (Nav-
igli and Ponzetto, 2012); because we map directly
to WordNet synsets, we provide a more readily-
interpretable collocation preference model than
most similarity-based or probabilistic models.
Verb frame extraction (Green et al., 2004) and
predicate-argument structure analysis (Surdeanu
et al., 2003; Yakushiji et al., 2006) are two areas
that are also related to our work. But their gener-
ality goes beyond our intentions, as we focus on
semantic predicates, which is much simpler and
free from syntactic parsing.
Another closely related work is that of Hanks
(2013) concerning the Theory of Norms and Ex-
ploitations, where norms (exploitations) represent
expected (unexpected) classes for a given lexical
predicate. Although our semantified predicates do,
indeed, provide explicit evidence of norms ob-
tained from collective intelligence and would pro-
vide support for this theory, exploitations present
a more difficult task, different from the one ad-
dressed here, due to its focus on identifying prop-
erty transfer between the semantic class and the
exploited instance.
The closest technical approach to ours is that
of Kozareva and Hovy (2010), who use recursive
patterns to induce semantic classes for the argu-
ments of relational patterns. Whereas their ap-
proach requires both a relation pattern and one
or more seeds, which bias the types of semantic
classes that are learned, our proposed method re-
quires only the pattern itself, and as a result is ca-
pable of learning an unbounded number of differ-
ent semantic classes.
</bodyText>
<sectionHeader confidence="0.992274" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999743205128205">
In this paper we present SPred, a novel approach
to large-scale harvesting of semantic predicates.
In order to semantify lexical predicates we ex-
ploit the wide coverage of Wikipedia to extract
and disambiguate lexical predicate occurrences,
and leverage WordNet to populate the semantic
classes with suitable predicate arguments. As a re-
sult, we are able to ontologize lexical predicate in-
stances like those available in existing dictionaries
(e.g., break a toe) into semantic predicates (such
as break a BODY PART).
For each lexical predicate (such as break ∗),
our method produces a probability distribution
over the set of semantic classes (thus covering the
different expected meanings for the filling argu-
ments) and is able to classify new instances with
the most suitable class. Our experiments show
generally high performance, also in comparison
with previous work on argument supertyping.
We hope that our semantic predicates will en-
able progress in different Natural Language Pro-
cessing tasks such as Word Sense Disambigua-
tion (Navigli, 2009), Semantic Role Labeling
(F¨urstenau and Lapata, 2012) or even Textual En-
tailment (Stern and Dagan, 2012) – each of which
is in urgent need of reliable semantics. While we
focused on semantifying lexical predicates, as fu-
ture work we will apply our method to the ontol-
ogization of large amounts of sequences of words,
such as phrases or textual relations (e.g., consid-
ering Google n-grams appearing in Wikipedia).
Notably, our method should, in principle, gener-
alize to any semantically-annotated corpus (e.g.,
Wikipedias in other languages), provided lexical
predicates can be extracted with associated seman-
tic classes.
In order to support future efforts we are releas-
ing our semantic predicates as a freely available
resource.12
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999718666666667">
The authors gratefully acknowledge
the support of the ERC Starting
Grant MultiJEDI No. 259234.
Thanks go to David A. Jurgens, Silvia Necs¸ulescu,
Stefano Faralli and Moreno De Vincenzi for their
help.
</bodyText>
<footnote confidence="0.86878">
12http://lcl.uniroma1.it/spred
</footnote>
<page confidence="0.989231">
1230
</page>
<sectionHeader confidence="0.989623" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99966347107438">
Jonathan Berant, Ido Dagan, and Jacob Goldberger.
2012. Learning entailment relations by global graph
structure optimization. Computational Linguistics,
38(1):73–111.
Shane Bergsma, Dekang Lin, and Randy Goebel.
2008. Discriminative learning of selectional prefer-
ence from unlabeled text. In Proc. of EMNLP, pages
59–68, Stroudsburg, PA, USA.
Christian Bizer, Jens Lehmann, Georgi Kobilarov,
S¨oren Auer, Christian Becker, Richard Cyganiak,
and Sebastian Hellmann. 2009. DBpedia - a crystal-
lization point for the Web of Data. Web Semantics,
7(3):154–165.
Gerlof Bouma. 2010. Collocation Extraction beyond
the Independence Assumption. In Proc. of ACL,
Short Papers, pages 109–114, Uppsala, Sweden.
Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr
Settles, Estevam R. Hruschka, and Tom M. Mitchell.
2010. Toward an architecture for never-ending lan-
guage learning. In Proc. ofAAAI, pages 1306–1313,
Atlanta, Georgia.
Nathanael Chambers and Dan Jurafsky. 2010. Improv-
ing the use of pseudo-words for evaluating selec-
tional preferences. In Proc. of ACL, pages 445–453,
Stroudsburg, PA, USA.
Tim Chklovski and Patrick Pantel. 2004. VerbOcean:
Mining the Web for fine-grained semantic verb rela-
tions. In Proc. of EMNLP, pages 33–40, Barcelona,
Spain.
Jennifer Chu-Carroll and John Prager. 2007. An exper-
imental study of the impact of information extraction
accuracy on semantic search performance. In Proc.
of CIKM, pages 505–514, Lisbon, Portugal.
Massimiliano Ciaramita and Yasemin Altun. 2006.
Broad-Coverage Sense Disambiguation and Infor-
mation Extraction with a Supersense Sequence Tag-
ger. In Proc. of EMNLP, pages 594–602, Sydney,
Australia.
Stephen Clark and David Weir. 2002. Class-based
probability estimation using a semantic hierarchy.
Computational Linguistics, 28(2):187–206.
Jonathan Crowther, editor. 1998. Oxford Advanced
Learner’s Dictionary. Cornelsen &amp; Oxford, 5th edi-
tion.
Flavio De Benedictis, Stefano Faralli, and Roberto
Navigli. 2013. GlossBoot: Bootstrapping multilin-
gual domain glossaries from the Web. In Proc. of
ACL, Sofia, Bulgaria.
Gerard de Melo and Gerhard Weikum. 2010. MENTA:
Inducing Multilingual Taxonomies from Wikipedia.
In Proc. of CIKM, pages 1099–1108, New York, NY,
USA.
Katrin Erk and Diana McCarthy. 2009. Graded word
sense assignment. In Proc. of EMNLP, pages 440–
449, Stroudsburg, PA, USA.
Katrin Erk. 2007. A Simple, Similarity-based Model
for Selectional Preferences. In Proc. of ACL, pages
216–223, Prague, Czech Republic.
Oren Etzioni, Michael Cafarella, Doug Downey, Ana-
Maria Popescu, Tal Shaked, Stephen Soderland,
Daniel S. Weld, and Alexander Yates. 2005. Un-
supervised named-entity extraction from the web:
an experimental study. Artificial Intelligence,
165(1):91–134.
Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying Relations for Open Information
Extraction. In Proc. of EMNLP, pages 1535–1545,
Edinburgh, UK.
Stefano Faralli and Roberto Navigli. 2013. A Java
framework for multilingual definition and hypernym
extraction. In Proc. of ACL, Comp. Volume, Sofia,
Bulgaria.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Database. MIT Press, Cambridge, MA.
David A. Ferrucci, Eric W. Brown, Jennifer Chu-
Carroll, James Fan, David Gondek, Aditya Kalyan-
pur, Adam Lally, J. William Murdock, Eric Nyberg,
John M. Prager, Nico Schlaefer, and Christopher A.
Welty. 2010. Building Watson: an overview of the
DeepQA project. AI Magazine, 31(3):59–79.
Hagen F¨urstenau and Mirella Lapata. 2012. Semi-
supervised semantic role labeling via structural
alignment. Computational Linguistics, 38(1):135–
171.
Roxana Girju, Adriana Badulescu, and Dan Moldovan.
2003. Learning semantic constraints for the auto-
matic discovery of part-whole relations. In Proc. of
HLT-NAACL, pages 1–8, Edmonton, Canada.
Rebecca Green, Bonnie J. Dorr, and Philip Resnik.
2004. Inducing Frame Semantic Verb Classes from
WordNet and LDOCE. In Proc. of ACL, pages 375–
382, Barcelona, Spain.
Patrick Hanks. 2013. Lexical Analysis: Norms and
Exploitations. University Press Group Limited.
Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proc. of COL-
ING, pages 539–545, Nantes, France.
Johannes Hoffart, Fabian M. Suchanek, Klaus
Berberich, and Gerhard Weikum. 2013. Yago2: A
spatially and temporally enhanced knowledge base
from wikipedia. Artificial Intelligence, 194:28–61.
Eduard H. Hovy, Roberto Navigli, and Simone Paolo
Ponzetto. 2013. Collaboratively built semi-
structured content and artificial intelligence: The
story so far. Artificial Intelligence, 194:2–27.
Ruihong Huang and Ellen Riloff. 2010. Inducing
Domain-Specific Semantic Class Taggers from (Al-
most) Nothing. In Proc. of ACL, pages 275–285,
Uppsala, Sweden.
Sean P. Igo and Ellen Riloff. 2009. Corpus-based se-
mantic lexicon induction with Web-based corrobo-
ration. In Proc. of UMSLLS, pages 18–26, Strouds-
burg, PA, USA.
Rub´en Izquierdo, Armando Su´arez, and German Rigau.
2009. An Empirical Study on Class-Based Word
Sense Disambiguation. In Proc. of EACL, pages
389–397, Athens, Greece.
Hyeju Jang and Jack Mostow. 2012. Inferring se-
lectional preferences from part-of-speech n-grams.
In Proc. of EACL, pages 377–386, Stroudsburg, PA,
USA.
</reference>
<page confidence="0.781788">
1231
</page>
<reference confidence="0.999893515873017">
Boris Katz, Jimmy J. Lin, Daniel Loreto, Wesley Hilde-
brandt, Matthew W. Bilotti, Sue Felshin, Aaron
Fernandes, Gregory Marton, and Federico Mora.
2003. Integrating Web-based and Corpus-based
Techniques for Question Answering. In Proc. of
TREC, pages 426–435, Gaithersburg, Maryland.
Zornitsa Kozareva and Eduard Hovy. 2010. Learning
Arguments and Supertypes of Semantic Relations
Using Recursive Patterns. In Proc. of ACL, pages
1482–1491, Uppsala, Sweden.
Zornitsa Kozareva, Ellen Riloff, and Eduard H. Hovy.
2008. Semantic Class Learning from the Web
with Hyponym Pattern Linkage Graphs. In Proc.
ACL/HLT, pages 1048–1056, Columbus, Ohio.
Sebastian Krause, Hong Li, Hans Uszkoreit, and Feiyu
Xu. 2012. Large-scale learning of relation-
extraction rules with distant supervision from the
web. In Proc. of ISWC 2012, Part I, pages 263–278,
Boston, MA.
Hang Li and Naoki Abe. 1998. Generalizing case
frames using a thesaurus and the MDL principle.
Computational Linguistics, 24(2):217–244.
Rada Mihalcea and Dan Moldovan. eXtended Word-
Net: Progress report. In Proceedings of the NAACL-
01 Workshop on WordNet and Other Lexical Re-
sources, Pittsburgh, Penn.
Thahir Mohamed, Estevam Hruschka, and Tom
Mitchell. 2011. Discovering Relations between
Noun Categories. In Proc. of EMNLP, pages 1447–
1455, Edinburgh, Scotland, UK.
Andrea Moro and Roberto Navigli. 2012. WiSeNet:
Building a Wikipedia-based semantic network with
ontologized relations. In Proc. of CIKM, pages
1672–1676, Maui, HI, USA.
Andrea Moro and Roberto Navigli. 2013. Integrating
Syntactic and Semantic Analysis into the Open In-
formation Extraction Paradigm. In Proc. of IJCAI,
Beijing, China.
Vivi Nastase and Michael Strube. 2013. Transform-
ing wikipedia into a large scale multilingual concept
network. Artificial Intelligence, 194:62–85.
Roberto Navigli and Simone Paolo Ponzetto. 2012.
BabelNet: The automatic construction, evaluation
and application of a wide-coverage multilingual se-
mantic network. Artificial Intelligence, 193:217–
250.
Roberto Navigli and Paola Velardi. 2010. Learning
Word-Class Lattices for Definition and Hypernym
Extraction. In Proc. of ACL, pages 1318–1327, Up-
psala, Sweden.
Roberto Navigli. 2009. Word Sense Disambiguation:
A survey. ACM Computing Surveys, 41(2):1–69.
Patrick Pantel, Rahul Bhagat, Timothy Chklovski, and
Eduard Hovy. 2007. ISP: learning inferential selec-
tional preferences. In Proc. of NAACL, pages 564–
571, Rochester, NY.
Marius Pasca. 2004. Acquisition of categorized named
entities for web search. In Proc. of CIKM, pages
137–145, New York, NY, USA.
Marco Pennacchiotti and Patrick Pantel. 2006. On-
tologizing semantic relations. In Proc. of COLING,
pages 793–800, Sydney, Australia.
Simone Paolo Ponzetto and Michael Strube. 2011.
Taxonomy induction based on a collaboratively built
knowledge repository. Artificial Intelligence, 175(9-
10):1737–1756.
Philip Resnik. 1996. Selectional constraints: An
information-theoretic model and its computational
realization. Cognition, 61(1):127–159.
Alan Ritter, Mausam, and Oren Etzioni. 2010. A la-
tent dirichlet allocation method for selectional pref-
erences. In Proc. of ACL, pages 424–434, Uppsala,
Sweden. ACL.
Mats Rooth, Stefan Riezler, Detlef Prescher, Glenn
Carroll, and Franz Beil. 1999. Inducing a seman-
tically annotated lexicon via EM-based clustering.
In Proc. of ACL, pages 104–111, Stroudsburg, PA,
USA.
Diarmuid O S´eaghdha. 2010. Latent variable models
of selectional preference. In Proc. of ACL, pages
435–444, Uppsala, Sweden.
Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2004.
Learning Syntactic Patterns for Automatic Hyper-
nym Discovery. In NIPS, pages 1297–1304, Cam-
bridge, Mass.
Asher Stern and Ido Dagan. 2012. Biutee: A mod-
ular open-source system for recognizing textual en-
tailment. In Proc. of ACL 2012, System Demonstra-
tions, pages 73–78, Jeju Island, Korea.
Mihai Surdeanu, Sanda Harabagiu, John Williams, and
Paul Aarseth. 2003. Using predicate-argument
structures for information extraction. In Proc. ACL,
pages 8–15, Stroudsburg, PA, USA.
M. Thelen and E. Riloff. 2002. A Bootstrapping
Method for Learning Semantic Lexicons using Ex-
traction Pattern Contexts. In Proc. of EMNLP, pages
214–221, Salt Lake City, UT, USA.
Paola Velardi, Stefano Faralli, and Roberto Navigli.
2013. OntoLearn Reloaded: A graph-based algo-
rithm for taxonomy induction. Computational Lin-
guistics, 39(3).
Yorick Wilks. 1975. A preferential, pattern-seeking,
semantics for natural language inference. Artificial
Intelligence, 6(1):53–74.
Fei Wu and Daniel S. Weld. 2010. Open Information
Extraction Using Wikipedia. In Proc. ofACL, pages
118–127, Uppsala, Sweden.
Akane Yakushiji, Yusuke Miyao, Tomoko Ohta, Yuka
Tateisi, and Jun’ichi Tsujii. 2006. Automatic con-
struction of predicate-argument structure patterns
for biomedical information extraction. In Proc. of
EMNLP, pages 284–292, Stroudsburg, PA, USA.
David Yarowsky. 1995. Unsupervised Word Sense
Disambiguation Rivaling Supervised Methods. In
Proc. of ACL, pages 189–196, Cambridge, MA,
USA.
Alexander Yates and Oren Etzioni. 2009. Unsuper-
vised methods for determining object and relation
synonyms on the web. Journal of Artificial Intelli-
gence Research, 34(1):255.
Alexander Yates, Michael Cafarella, Michele Banko,
Oren Etzioni, Matthew Broadhead, and Stephen
Soderland. 2007. TextRunner: open informa-
tion extraction on the web. In Proc. of NAACL-
Demonstrations, pages 25–26, Stroudsburg, PA,
USA.
</reference>
<page confidence="0.993186">
1232
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.530098">
<title confidence="0.8488725">SPred: Large-scale Harvesting of Semantic Predicates Flati</title>
<author confidence="0.798767">Dipartimento di_Sapienza Universit`a di</author>
<abstract confidence="0.9992425">We present SPred, a novel method for the creation of large repositories of semantic predicates. We start from existing collocato form lexical predicates (e.g., and learn the semantic classes that best the To do this, we extract all the occurrences in Wikipedia which match the predicate and abstract its arguments to general semantic classes (e.g., etc.). Our experiments show that we are able to create a large collection of semantic predicates from the Oxford Advanced Learner’s Dictionary with high precision and recall, and perform well against the most similar approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Ido Dagan</author>
<author>Jacob Goldberger</author>
</authors>
<title>Learning entailment relations by global graph structure optimization.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<volume>38</volume>
<issue>1</issue>
<contexts>
<context position="2049" citStr="Berant et al., 2012" startWordPosition="311" endWordPosition="314">resources has considerably boosted research on several aspects of knowledge acquisition (Hovy et al., 2013), leading to the creation of several large-scale knowledge resources, such as DBPedia (Bizer et al., 2009), BabelNet (Navigli and Ponzetto, 2012), YAGO (Hoffart et al., 2013), MENTA (de Melo and Weikum, 2010), to name but a few. This wealth of acquired knowledge is known to have a positive impact on important fields such as Information Retrieval (Chu-Carroll and Prager, 2007), Information Extraction (Krause et al., 2012), Question Answering (Ferrucci et al., 2010) and Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-structured text using ontology learning from scratch (Velardi et al., 2013) and Open Information Extraction techniques (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Fader et al., 2011; Moro and Navigli, 2013) which mainly stem from seminal work on is-a relation acquisition (Hearst, 1992) and subsequent developments (Girju et al., 2003; Pasca, 2004; Snow e</context>
</contexts>
<marker>Berant, Dagan, Goldberger, 2012</marker>
<rawString>Jonathan Berant, Ido Dagan, and Jacob Goldberger. 2012. Learning entailment relations by global graph structure optimization. Computational Linguistics, 38(1):73–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Dekang Lin</author>
<author>Randy Goebel</author>
</authors>
<title>Discriminative learning of selectional preference from unlabeled text.</title>
<date>2008</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>59--68</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="35379" citStr="Bergsma et al., 2008" startWordPosition="5999" endWordPosition="6002">t similar approaches to it are taxonomybased ones, which leverage the semantic types of the relations arguments (Resnik, 1996; Li and Abe, 1998; Clark and Weir, 2002; Pennacchiotti and Pantel, 2006). Nevertheless, despite their high quality sense-tagged data, these methods have often suffered from lack of coverage. As a result, alternative approaches have been proposed that eschew taxonomies in favor of rating the quality of potential relation arguments (Erk, 2007; Chambers and Jurafsky, 2010) or generating probability distributions over the arguments (Rooth et al., 1999; Pantel et al., 2007; Bergsma et al., 2008; Ritter et al., 2010; S´eaghdha, 2010; Bouma, 2010; Jang and Mostow, 2012) in order to obtain higher coverage of preferences. In contrast, we overcome the data sparsity of class-based models by leveraging the large quantity of collaboratively-annotated Wikipedia text in order to connect predicate arguments with their semantic class in WordNet using BabelNet (Navigli and Ponzetto, 2012); because we map directly to WordNet synsets, we provide a more readilyinterpretable collocation preference model than most similarity-based or probabilistic models. Verb frame extraction (Green et al., 2004) an</context>
</contexts>
<marker>Bergsma, Lin, Goebel, 2008</marker>
<rawString>Shane Bergsma, Dekang Lin, and Randy Goebel. 2008. Discriminative learning of selectional preference from unlabeled text. In Proc. of EMNLP, pages 59–68, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Bizer</author>
<author>Jens Lehmann</author>
<author>Georgi Kobilarov</author>
<author>S¨oren Auer</author>
<author>Christian Becker</author>
<author>Richard Cyganiak</author>
<author>Sebastian Hellmann</author>
</authors>
<title>DBpedia - a crystallization point for the Web of Data.</title>
<date>2009</date>
<journal>Web Semantics,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="1643" citStr="Bizer et al., 2009" startWordPosition="248" endWordPosition="251">e of information and data that has become available has made it possible to extract huge amounts of patterns and named entities (Etzioni et al., 2005), semantic lexicons for categories of interest (Thelen and Riloff, 2002; Igo and Riloff, 2009), large domain glossaries (De Benedictis et al., 2013) and lists of concepts (Katz et al., 2003). Recently, the availability of Wikipedia and other collaborative resources has considerably boosted research on several aspects of knowledge acquisition (Hovy et al., 2013), leading to the creation of several large-scale knowledge resources, such as DBPedia (Bizer et al., 2009), BabelNet (Navigli and Ponzetto, 2012), YAGO (Hoffart et al., 2013), MENTA (de Melo and Weikum, 2010), to name but a few. This wealth of acquired knowledge is known to have a positive impact on important fields such as Information Retrieval (Chu-Carroll and Prager, 2007), Information Extraction (Krause et al., 2012), Question Answering (Ferrucci et al., 2010) and Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are ext</context>
</contexts>
<marker>Bizer, Lehmann, Kobilarov, Auer, Becker, Cyganiak, Hellmann, 2009</marker>
<rawString>Christian Bizer, Jens Lehmann, Georgi Kobilarov, S¨oren Auer, Christian Becker, Richard Cyganiak, and Sebastian Hellmann. 2009. DBpedia - a crystallization point for the Web of Data. Web Semantics, 7(3):154–165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerlof Bouma</author>
</authors>
<title>Collocation Extraction beyond the Independence Assumption.</title>
<date>2010</date>
<booktitle>In Proc. of ACL, Short Papers,</booktitle>
<pages>109--114</pages>
<location>Uppsala,</location>
<contexts>
<context position="35430" citStr="Bouma, 2010" startWordPosition="6009" endWordPosition="6010">erage the semantic types of the relations arguments (Resnik, 1996; Li and Abe, 1998; Clark and Weir, 2002; Pennacchiotti and Pantel, 2006). Nevertheless, despite their high quality sense-tagged data, these methods have often suffered from lack of coverage. As a result, alternative approaches have been proposed that eschew taxonomies in favor of rating the quality of potential relation arguments (Erk, 2007; Chambers and Jurafsky, 2010) or generating probability distributions over the arguments (Rooth et al., 1999; Pantel et al., 2007; Bergsma et al., 2008; Ritter et al., 2010; S´eaghdha, 2010; Bouma, 2010; Jang and Mostow, 2012) in order to obtain higher coverage of preferences. In contrast, we overcome the data sparsity of class-based models by leveraging the large quantity of collaboratively-annotated Wikipedia text in order to connect predicate arguments with their semantic class in WordNet using BabelNet (Navigli and Ponzetto, 2012); because we map directly to WordNet synsets, we provide a more readilyinterpretable collocation preference model than most similarity-based or probabilistic models. Verb frame extraction (Green et al., 2004) and predicate-argument structure analysis (Surdeanu e</context>
</contexts>
<marker>Bouma, 2010</marker>
<rawString>Gerlof Bouma. 2010. Collocation Extraction beyond the Independence Assumption. In Proc. of ACL, Short Papers, pages 109–114, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Justin Betteridge</author>
<author>Bryan Kisiel</author>
<author>Burr Settles</author>
<author>Estevam R Hruschka</author>
<author>Tom M Mitchell</author>
</authors>
<title>Toward an architecture for never-ending language learning.</title>
<date>2010</date>
<booktitle>In Proc. ofAAAI,</booktitle>
<pages>1306--1313</pages>
<location>Atlanta,</location>
<contexts>
<context position="33278" citStr="Carlson et al., 2010" startWordPosition="5681" endWordPosition="5684">er of classes cause * 181,401 1,339 live in * 143,628 600 go to * 134,712 867 * cause 92,160 1,244 work in * 79,444 770 * go to 71,794 746 * live in 61,074 541 work on * 58,760 840 work for * 58,332 681 work at * 31,904 511 * work in 24,933 528 * celebrate 23,333 408 Table 7: Number of arguments and associated classes for the 12 most frequent lexical predicates of Kozareva and Hovy (2010) extracted by SPred from Wikipedia. 6 Related work The availability of Web-scale corpora has led to the production of large resources of relations (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Carlson et al., 2010; Fader et al., 2011). However, these resources often operate purely at the lexical level, providing no information on the semantics of their arguments or relations. Several studies have examined adding semantics through grouping relations into sets (Yates and Etzioni, 2009), ontologizing the arguments (Chklovski and Pantel, 2004), or ontologizing the relations themselves (Moro and Navigli, 2013). However, analysis has largely been either limited to ontologizing a small number of relation types with a fixed inventory, which potentially limits coverage, or has used implicit definitions of seman</context>
</contexts>
<marker>Carlson, Betteridge, Kisiel, Settles, Hruschka, Mitchell, 2010</marker>
<rawString>Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R. Hruschka, and Tom M. Mitchell. 2010. Toward an architecture for never-ending language learning. In Proc. ofAAAI, pages 1306–1313, Atlanta, Georgia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Improving the use of pseudo-words for evaluating selectional preferences.</title>
<date>2010</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>445--453</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="35257" citStr="Chambers and Jurafsky, 2010" startWordPosition="5978" endWordPosition="5982">e different semantic classes of predicate arguments is closely related to the task of identifying selectional preferences. The most similar approaches to it are taxonomybased ones, which leverage the semantic types of the relations arguments (Resnik, 1996; Li and Abe, 1998; Clark and Weir, 2002; Pennacchiotti and Pantel, 2006). Nevertheless, despite their high quality sense-tagged data, these methods have often suffered from lack of coverage. As a result, alternative approaches have been proposed that eschew taxonomies in favor of rating the quality of potential relation arguments (Erk, 2007; Chambers and Jurafsky, 2010) or generating probability distributions over the arguments (Rooth et al., 1999; Pantel et al., 2007; Bergsma et al., 2008; Ritter et al., 2010; S´eaghdha, 2010; Bouma, 2010; Jang and Mostow, 2012) in order to obtain higher coverage of preferences. In contrast, we overcome the data sparsity of class-based models by leveraging the large quantity of collaboratively-annotated Wikipedia text in order to connect predicate arguments with their semantic class in WordNet using BabelNet (Navigli and Ponzetto, 2012); because we map directly to WordNet synsets, we provide a more readilyinterpretable coll</context>
</contexts>
<marker>Chambers, Jurafsky, 2010</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2010. Improving the use of pseudo-words for evaluating selectional preferences. In Proc. of ACL, pages 445–453, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Chklovski</author>
<author>Patrick Pantel</author>
</authors>
<title>VerbOcean: Mining the Web for fine-grained semantic verb relations.</title>
<date>2004</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>33--40</pages>
<location>Barcelona,</location>
<contexts>
<context position="33610" citStr="Chklovski and Pantel, 2004" startWordPosition="5728" endWordPosition="5731">he 12 most frequent lexical predicates of Kozareva and Hovy (2010) extracted by SPred from Wikipedia. 6 Related work The availability of Web-scale corpora has led to the production of large resources of relations (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Carlson et al., 2010; Fader et al., 2011). However, these resources often operate purely at the lexical level, providing no information on the semantics of their arguments or relations. Several studies have examined adding semantics through grouping relations into sets (Yates and Etzioni, 2009), ontologizing the arguments (Chklovski and Pantel, 2004), or ontologizing the relations themselves (Moro and Navigli, 2013). However, analysis has largely been either limited to ontologizing a small number of relation types with a fixed inventory, which potentially limits coverage, or has used implicit definitions of semantic categories (e.g., clusters of arguments), which limits interpretability. For example, Mohamed et al. (2011) use the semantic categories of the NELL system (Carlson et al., 2010) to learn roughly 400 valid ontologized relations from over 200M web pages, whereas WiSeNet (Moro and Navigli, 2012) leverages Wikipedia to acquire rel</context>
</contexts>
<marker>Chklovski, Pantel, 2004</marker>
<rawString>Tim Chklovski and Patrick Pantel. 2004. VerbOcean: Mining the Web for fine-grained semantic verb relations. In Proc. of EMNLP, pages 33–40, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Chu-Carroll</author>
<author>John Prager</author>
</authors>
<title>An experimental study of the impact of information extraction accuracy on semantic search performance.</title>
<date>2007</date>
<booktitle>In Proc. of CIKM,</booktitle>
<pages>505--514</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="1915" citStr="Chu-Carroll and Prager, 2007" startWordPosition="292" endWordPosition="295">ssaries (De Benedictis et al., 2013) and lists of concepts (Katz et al., 2003). Recently, the availability of Wikipedia and other collaborative resources has considerably boosted research on several aspects of knowledge acquisition (Hovy et al., 2013), leading to the creation of several large-scale knowledge resources, such as DBPedia (Bizer et al., 2009), BabelNet (Navigli and Ponzetto, 2012), YAGO (Hoffart et al., 2013), MENTA (de Melo and Weikum, 2010), to name but a few. This wealth of acquired knowledge is known to have a positive impact on important fields such as Information Retrieval (Chu-Carroll and Prager, 2007), Information Extraction (Krause et al., 2012), Question Answering (Ferrucci et al., 2010) and Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-structured text using ontology learning from scratch (Velardi et al., 2013) and Open Information Extraction techniques (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Fader et al., 2011; Moro and Navigli, 2013) which mainly s</context>
</contexts>
<marker>Chu-Carroll, Prager, 2007</marker>
<rawString>Jennifer Chu-Carroll and John Prager. 2007. An experimental study of the impact of information extraction accuracy on semantic search performance. In Proc. of CIKM, pages 505–514, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimiliano Ciaramita</author>
<author>Yasemin Altun</author>
</authors>
<title>Broad-Coverage Sense Disambiguation and Information Extraction with a Supersense Sequence Tagger.</title>
<date>2006</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>594--602</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="14087" citStr="Ciaramita and Altun, 2006" startWordPosition="2407" endWordPosition="2410">YSM and INSTITUTE FOR ADVANCED STUDY FACULTY); ii) categories are mostly structured in a directed acyclic graph with multiple parents per category (even worse, cycles are possible in principle); iii) there is no clear way of identifying core semantic classes from the large set of available categories. Although efforts towards the automatic taxonomization of Wikipedia categories do exist in the literature (Ponzetto and Strube, 2011; Nastase and Strube, 2013), the results are of a lower quality than a hand-built lexical resource. Therefore, as was done in previous work (Mihalcea and Moldovan, ; Ciaramita and Altun, 2006; Izquierdo et al., 2009; Erk and McCarthy, 2009; Huang and Riloff, 2010), we pick out our semantic classes C from WordNet and leverage its manually-curated taxonomy to associate our arguments with the most suitable class. This way we avoid building a new taxonomy and shift the problem to that of projecting the Wikipedia pages – associated with annotated filling arguments – to synsets in WordNet. We address this problem in two steps: Wikipedia-WordNet mapping. We exploit an existing mapping implemented in BabelNet (Navigli and Ponzetto, 2012), a wide-coverage multilingual semantic network that</context>
</contexts>
<marker>Ciaramita, Altun, 2006</marker>
<rawString>Massimiliano Ciaramita and Yasemin Altun. 2006. Broad-Coverage Sense Disambiguation and Information Extraction with a Supersense Sequence Tagger. In Proc. of EMNLP, pages 594–602, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>David Weir</author>
</authors>
<title>Class-based probability estimation using a semantic hierarchy.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>2</issue>
<contexts>
<context position="34924" citStr="Clark and Weir, 2002" startWordPosition="5929" endWordPosition="5932"> existed to date that contains ontologized lexical predicates. In contrast, the present work provides a high-coverage method for learning argument supertypes from a broadcoverage ontology (WordNet), which can potentially be leveraged in relation extraction to ontolo1229 gize relation arguments. Our method for identifying the different semantic classes of predicate arguments is closely related to the task of identifying selectional preferences. The most similar approaches to it are taxonomybased ones, which leverage the semantic types of the relations arguments (Resnik, 1996; Li and Abe, 1998; Clark and Weir, 2002; Pennacchiotti and Pantel, 2006). Nevertheless, despite their high quality sense-tagged data, these methods have often suffered from lack of coverage. As a result, alternative approaches have been proposed that eschew taxonomies in favor of rating the quality of potential relation arguments (Erk, 2007; Chambers and Jurafsky, 2010) or generating probability distributions over the arguments (Rooth et al., 1999; Pantel et al., 2007; Bergsma et al., 2008; Ritter et al., 2010; S´eaghdha, 2010; Bouma, 2010; Jang and Mostow, 2012) in order to obtain higher coverage of preferences. In contrast, we ov</context>
</contexts>
<marker>Clark, Weir, 2002</marker>
<rawString>Stephen Clark and David Weir. 2002. Class-based probability estimation using a semantic hierarchy. Computational Linguistics, 28(2):187–206.</rawString>
</citation>
<citation valid="true">
<date>1998</date>
<booktitle>Oxford Advanced Learner’s Dictionary. Cornelsen &amp; Oxford, 5th edition.</booktitle>
<editor>Jonathan Crowther, editor.</editor>
<marker>1998</marker>
<rawString>Jonathan Crowther, editor. 1998. Oxford Advanced Learner’s Dictionary. Cornelsen &amp; Oxford, 5th edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Flavio De Benedictis</author>
<author>Stefano Faralli</author>
<author>Roberto Navigli</author>
</authors>
<title>GlossBoot: Bootstrapping multilingual domain glossaries from the Web. In</title>
<date>2013</date>
<booktitle>Proc. of ACL,</booktitle>
<location>Sofia, Bulgaria.</location>
<marker>De Benedictis, Faralli, Navigli, 2013</marker>
<rawString>Flavio De Benedictis, Stefano Faralli, and Roberto Navigli. 2013. GlossBoot: Bootstrapping multilingual domain glossaries from the Web. In Proc. of ACL, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard de Melo</author>
<author>Gerhard Weikum</author>
</authors>
<title>MENTA: Inducing Multilingual Taxonomies from Wikipedia.</title>
<date>2010</date>
<booktitle>In Proc. of CIKM,</booktitle>
<pages>1099--1108</pages>
<location>New York, NY, USA.</location>
<marker>de Melo, Weikum, 2010</marker>
<rawString>Gerard de Melo and Gerhard Weikum. 2010. MENTA: Inducing Multilingual Taxonomies from Wikipedia. In Proc. of CIKM, pages 1099–1108, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Diana McCarthy</author>
</authors>
<title>Graded word sense assignment.</title>
<date>2009</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>440--449</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="14135" citStr="Erk and McCarthy, 2009" startWordPosition="2415" endWordPosition="2418">categories are mostly structured in a directed acyclic graph with multiple parents per category (even worse, cycles are possible in principle); iii) there is no clear way of identifying core semantic classes from the large set of available categories. Although efforts towards the automatic taxonomization of Wikipedia categories do exist in the literature (Ponzetto and Strube, 2011; Nastase and Strube, 2013), the results are of a lower quality than a hand-built lexical resource. Therefore, as was done in previous work (Mihalcea and Moldovan, ; Ciaramita and Altun, 2006; Izquierdo et al., 2009; Erk and McCarthy, 2009; Huang and Riloff, 2010), we pick out our semantic classes C from WordNet and leverage its manually-curated taxonomy to associate our arguments with the most suitable class. This way we avoid building a new taxonomy and shift the problem to that of projecting the Wikipedia pages – associated with annotated filling arguments – to synsets in WordNet. We address this problem in two steps: Wikipedia-WordNet mapping. We exploit an existing mapping implemented in BabelNet (Navigli and Ponzetto, 2012), a wide-coverage multilingual semantic network that integrates Wikipedia and WordNet.3 Based on a d</context>
</contexts>
<marker>Erk, McCarthy, 2009</marker>
<rawString>Katrin Erk and Diana McCarthy. 2009. Graded word sense assignment. In Proc. of EMNLP, pages 440– 449, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
</authors>
<title>A Simple, Similarity-based Model for Selectional Preferences.</title>
<date>2007</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>216--223</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="35227" citStr="Erk, 2007" startWordPosition="5976" endWordPosition="5977">ntifying the different semantic classes of predicate arguments is closely related to the task of identifying selectional preferences. The most similar approaches to it are taxonomybased ones, which leverage the semantic types of the relations arguments (Resnik, 1996; Li and Abe, 1998; Clark and Weir, 2002; Pennacchiotti and Pantel, 2006). Nevertheless, despite their high quality sense-tagged data, these methods have often suffered from lack of coverage. As a result, alternative approaches have been proposed that eschew taxonomies in favor of rating the quality of potential relation arguments (Erk, 2007; Chambers and Jurafsky, 2010) or generating probability distributions over the arguments (Rooth et al., 1999; Pantel et al., 2007; Bergsma et al., 2008; Ritter et al., 2010; S´eaghdha, 2010; Bouma, 2010; Jang and Mostow, 2012) in order to obtain higher coverage of preferences. In contrast, we overcome the data sparsity of class-based models by leveraging the large quantity of collaboratively-annotated Wikipedia text in order to connect predicate arguments with their semantic class in WordNet using BabelNet (Navigli and Ponzetto, 2012); because we map directly to WordNet synsets, we provide a </context>
</contexts>
<marker>Erk, 2007</marker>
<rawString>Katrin Erk. 2007. A Simple, Similarity-based Model for Selectional Preferences. In Proc. of ACL, pages 216–223, Prague, Czech Republic.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Oren Etzioni</author>
<author>Michael Cafarella</author>
<author>Doug Downey</author>
</authors>
<title>AnaMaria Popescu, Tal Shaked,</title>
<location>Stephen Soderland,</location>
<marker>Etzioni, Cafarella, Downey, </marker>
<rawString>Oren Etzioni, Michael Cafarella, Doug Downey, AnaMaria Popescu, Tal Shaked, Stephen Soderland,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel S Weld</author>
<author>Alexander Yates</author>
</authors>
<title>Unsupervised named-entity extraction from the web: an experimental study.</title>
<date>2005</date>
<journal>Artificial Intelligence,</journal>
<volume>165</volume>
<issue>1</issue>
<marker>Weld, Yates, 2005</marker>
<rawString>Daniel S. Weld, and Alexander Yates. 2005. Unsupervised named-entity extraction from the web: an experimental study. Artificial Intelligence, 165(1):91–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Identifying Relations for Open Information Extraction.</title>
<date>2011</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>1535--1545</pages>
<location>Edinburgh, UK.</location>
<contexts>
<context position="2475" citStr="Fader et al., 2011" startWordPosition="378" endWordPosition="381">ch as Information Retrieval (Chu-Carroll and Prager, 2007), Information Extraction (Krause et al., 2012), Question Answering (Ferrucci et al., 2010) and Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-structured text using ontology learning from scratch (Velardi et al., 2013) and Open Information Extraction techniques (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Fader et al., 2011; Moro and Navigli, 2013) which mainly stem from seminal work on is-a relation acquisition (Hearst, 1992) and subsequent developments (Girju et al., 2003; Pasca, 2004; Snow et al., 2004, among others). However, these knowledge resources still lack semantic information about language units such as phrases and collocations. For instance, which semantic classes are expected as a direct object of the verb break? What kinds of noun does the adjective amazing collocate with? Recognition of the need for systems that are aware of the selectional restrictions of verbs and, more in general, of textual e</context>
<context position="33299" citStr="Fader et al., 2011" startWordPosition="5685" endWordPosition="5688">181,401 1,339 live in * 143,628 600 go to * 134,712 867 * cause 92,160 1,244 work in * 79,444 770 * go to 71,794 746 * live in 61,074 541 work on * 58,760 840 work for * 58,332 681 work at * 31,904 511 * work in 24,933 528 * celebrate 23,333 408 Table 7: Number of arguments and associated classes for the 12 most frequent lexical predicates of Kozareva and Hovy (2010) extracted by SPred from Wikipedia. 6 Related work The availability of Web-scale corpora has led to the production of large resources of relations (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Carlson et al., 2010; Fader et al., 2011). However, these resources often operate purely at the lexical level, providing no information on the semantics of their arguments or relations. Several studies have examined adding semantics through grouping relations into sets (Yates and Etzioni, 2009), ontologizing the arguments (Chklovski and Pantel, 2004), or ontologizing the relations themselves (Moro and Navigli, 2013). However, analysis has largely been either limited to ontologizing a small number of relation types with a fixed inventory, which potentially limits coverage, or has used implicit definitions of semantic categories (e.g.,</context>
</contexts>
<marker>Fader, Soderland, Etzioni, 2011</marker>
<rawString>Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying Relations for Open Information Extraction. In Proc. of EMNLP, pages 1535–1545, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefano Faralli</author>
<author>Roberto Navigli</author>
</authors>
<title>A Java framework for multilingual definition and hypernym extraction.</title>
<date>2013</date>
<booktitle>In Proc. of ACL, Comp.</booktitle>
<location>Volume, Sofia, Bulgaria.</location>
<contexts>
<context position="16011" citStr="Faralli and Navigli, 2013" startWordPosition="2709" endWordPosition="2713">&apos; the i-th sense of w in WordNet with part of speech p. 5According to the Wikipedia guidelines, “The article should begin with a short declarative sentence, answering two questions for the nonspecialist reader: What (or who) is the subject? and Why is this subject notable?”, extracted from http://en.wikipedia.org/wiki/ we extract the hypernym from the textual definition of p by applying Word-Class Lattices (Navigli and Velardi, 2010, WCL6), a domain-independent hypernym extraction system successfully applied to taxonomy learning from scratch (Velardi et al., 2013) and freely available online (Faralli and Navigli, 2013). If a hypernym h is successfully extracted and h is linked to a Wikipedia page p&apos; for which µ(p&apos;) is defined, then we extend the mapping by setting µ(p) := µ(p&apos;). For instance, the mapping provided by BabelNet does not provide any link for the page Peter Spence; thanks to WCL, though, we are able to set the page Journalist as its hypernym, and link it to the WordNet synset journalists. This way our mapping extension now covers 539,954 pages, i.e., more than an order of magnitude greater than the number of pages originally covered by the BabelNet mapping. 3.3.2 Populating the Semantic Classes </context>
</contexts>
<marker>Faralli, Navigli, 2013</marker>
<rawString>Stefano Faralli and Roberto Navigli. 2013. A Java framework for multilingual definition and hypernym extraction. In Proc. of ACL, Comp. Volume, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Ferrucci</author>
<author>Eric W Brown</author>
<author>Jennifer ChuCarroll</author>
<author>James Fan</author>
<author>David Gondek</author>
<author>Aditya Kalyanpur</author>
<author>Adam Lally</author>
<author>J William Murdock</author>
<author>Eric Nyberg</author>
<author>John M Prager</author>
<author>Nico Schlaefer</author>
<author>Christopher A Welty</author>
</authors>
<title>Building Watson: an overview of the DeepQA project.</title>
<date>2010</date>
<journal>AI Magazine,</journal>
<volume>31</volume>
<issue>3</issue>
<contexts>
<context position="2005" citStr="Ferrucci et al., 2010" startWordPosition="304" endWordPosition="307">ilability of Wikipedia and other collaborative resources has considerably boosted research on several aspects of knowledge acquisition (Hovy et al., 2013), leading to the creation of several large-scale knowledge resources, such as DBPedia (Bizer et al., 2009), BabelNet (Navigli and Ponzetto, 2012), YAGO (Hoffart et al., 2013), MENTA (de Melo and Weikum, 2010), to name but a few. This wealth of acquired knowledge is known to have a positive impact on important fields such as Information Retrieval (Chu-Carroll and Prager, 2007), Information Extraction (Krause et al., 2012), Question Answering (Ferrucci et al., 2010) and Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-structured text using ontology learning from scratch (Velardi et al., 2013) and Open Information Extraction techniques (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Fader et al., 2011; Moro and Navigli, 2013) which mainly stem from seminal work on is-a relation acquisition (Hearst, 1992) and subsequent developme</context>
</contexts>
<marker>Ferrucci, Brown, ChuCarroll, Fan, Gondek, Kalyanpur, Lally, Murdock, Nyberg, Prager, Schlaefer, Welty, 2010</marker>
<rawString>David A. Ferrucci, Eric W. Brown, Jennifer ChuCarroll, James Fan, David Gondek, Aditya Kalyanpur, Adam Lally, J. William Murdock, Eric Nyberg, John M. Prager, Nico Schlaefer, and Christopher A. Welty. 2010. Building Watson: an overview of the DeepQA project. AI Magazine, 31(3):59–79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hagen F¨urstenau</author>
<author>Mirella Lapata</author>
</authors>
<title>Semisupervised semantic role labeling via structural alignment.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<volume>38</volume>
<issue>1</issue>
<pages>171</pages>
<marker>F¨urstenau, Lapata, 2012</marker>
<rawString>Hagen F¨urstenau and Mirella Lapata. 2012. Semisupervised semantic role labeling via structural alignment. Computational Linguistics, 38(1):135– 171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roxana Girju</author>
<author>Adriana Badulescu</author>
<author>Dan Moldovan</author>
</authors>
<title>Learning semantic constraints for the automatic discovery of part-whole relations.</title>
<date>2003</date>
<booktitle>In Proc. of HLT-NAACL,</booktitle>
<pages>1--8</pages>
<location>Edmonton, Canada.</location>
<contexts>
<context position="2628" citStr="Girju et al., 2003" startWordPosition="402" endWordPosition="405">Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-structured text using ontology learning from scratch (Velardi et al., 2013) and Open Information Extraction techniques (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Fader et al., 2011; Moro and Navigli, 2013) which mainly stem from seminal work on is-a relation acquisition (Hearst, 1992) and subsequent developments (Girju et al., 2003; Pasca, 2004; Snow et al., 2004, among others). However, these knowledge resources still lack semantic information about language units such as phrases and collocations. For instance, which semantic classes are expected as a direct object of the verb break? What kinds of noun does the adjective amazing collocate with? Recognition of the need for systems that are aware of the selectional restrictions of verbs and, more in general, of textual expressions, dates back to several decades (Wilks, 1975), but today it is more relevant than ever, as is testified by the current interest in semantic cla</context>
</contexts>
<marker>Girju, Badulescu, Moldovan, 2003</marker>
<rawString>Roxana Girju, Adriana Badulescu, and Dan Moldovan. 2003. Learning semantic constraints for the automatic discovery of part-whole relations. In Proc. of HLT-NAACL, pages 1–8, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Green</author>
<author>Bonnie J Dorr</author>
<author>Philip Resnik</author>
</authors>
<title>Inducing Frame Semantic Verb Classes from WordNet and LDOCE.</title>
<date>2004</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>375--382</pages>
<location>Barcelona,</location>
<contexts>
<context position="35976" citStr="Green et al., 2004" startWordPosition="6087" endWordPosition="6090">; Bergsma et al., 2008; Ritter et al., 2010; S´eaghdha, 2010; Bouma, 2010; Jang and Mostow, 2012) in order to obtain higher coverage of preferences. In contrast, we overcome the data sparsity of class-based models by leveraging the large quantity of collaboratively-annotated Wikipedia text in order to connect predicate arguments with their semantic class in WordNet using BabelNet (Navigli and Ponzetto, 2012); because we map directly to WordNet synsets, we provide a more readilyinterpretable collocation preference model than most similarity-based or probabilistic models. Verb frame extraction (Green et al., 2004) and predicate-argument structure analysis (Surdeanu et al., 2003; Yakushiji et al., 2006) are two areas that are also related to our work. But their generality goes beyond our intentions, as we focus on semantic predicates, which is much simpler and free from syntactic parsing. Another closely related work is that of Hanks (2013) concerning the Theory of Norms and Exploitations, where norms (exploitations) represent expected (unexpected) classes for a given lexical predicate. Although our semantified predicates do, indeed, provide explicit evidence of norms obtained from collective intelligen</context>
</contexts>
<marker>Green, Dorr, Resnik, 2004</marker>
<rawString>Rebecca Green, Bonnie J. Dorr, and Philip Resnik. 2004. Inducing Frame Semantic Verb Classes from WordNet and LDOCE. In Proc. of ACL, pages 375– 382, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Hanks</author>
</authors>
<title>Lexical Analysis: Norms and Exploitations.</title>
<date>2013</date>
<publisher>University Press Group Limited.</publisher>
<contexts>
<context position="36308" citStr="Hanks (2013)" startWordPosition="6143" endWordPosition="6144">ir semantic class in WordNet using BabelNet (Navigli and Ponzetto, 2012); because we map directly to WordNet synsets, we provide a more readilyinterpretable collocation preference model than most similarity-based or probabilistic models. Verb frame extraction (Green et al., 2004) and predicate-argument structure analysis (Surdeanu et al., 2003; Yakushiji et al., 2006) are two areas that are also related to our work. But their generality goes beyond our intentions, as we focus on semantic predicates, which is much simpler and free from syntactic parsing. Another closely related work is that of Hanks (2013) concerning the Theory of Norms and Exploitations, where norms (exploitations) represent expected (unexpected) classes for a given lexical predicate. Although our semantified predicates do, indeed, provide explicit evidence of norms obtained from collective intelligence and would provide support for this theory, exploitations present a more difficult task, different from the one addressed here, due to its focus on identifying property transfer between the semantic class and the exploited instance. The closest technical approach to ours is that of Kozareva and Hovy (2010), who use recursive pat</context>
</contexts>
<marker>Hanks, 2013</marker>
<rawString>Patrick Hanks. 2013. Lexical Analysis: Norms and Exploitations. University Press Group Limited.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proc. of COLING,</booktitle>
<pages>539--545</pages>
<location>Nantes, France.</location>
<contexts>
<context position="2580" citStr="Hearst, 1992" startWordPosition="396" endWordPosition="397">tion Answering (Ferrucci et al., 2010) and Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-structured text using ontology learning from scratch (Velardi et al., 2013) and Open Information Extraction techniques (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Fader et al., 2011; Moro and Navigli, 2013) which mainly stem from seminal work on is-a relation acquisition (Hearst, 1992) and subsequent developments (Girju et al., 2003; Pasca, 2004; Snow et al., 2004, among others). However, these knowledge resources still lack semantic information about language units such as phrases and collocations. For instance, which semantic classes are expected as a direct object of the verb break? What kinds of noun does the adjective amazing collocate with? Recognition of the need for systems that are aware of the selectional restrictions of verbs and, more in general, of textual expressions, dates back to several decades (Wilks, 1975), but today it is more relevant than ever, as is t</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proc. of COLING, pages 539–545, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Hoffart</author>
<author>Fabian M Suchanek</author>
<author>Klaus Berberich</author>
<author>Gerhard Weikum</author>
</authors>
<title>Yago2: A spatially and temporally enhanced knowledge base from wikipedia.</title>
<date>2013</date>
<journal>Artificial Intelligence,</journal>
<pages>194--28</pages>
<contexts>
<context position="1711" citStr="Hoffart et al., 2013" startWordPosition="258" endWordPosition="261">ssible to extract huge amounts of patterns and named entities (Etzioni et al., 2005), semantic lexicons for categories of interest (Thelen and Riloff, 2002; Igo and Riloff, 2009), large domain glossaries (De Benedictis et al., 2013) and lists of concepts (Katz et al., 2003). Recently, the availability of Wikipedia and other collaborative resources has considerably boosted research on several aspects of knowledge acquisition (Hovy et al., 2013), leading to the creation of several large-scale knowledge resources, such as DBPedia (Bizer et al., 2009), BabelNet (Navigli and Ponzetto, 2012), YAGO (Hoffart et al., 2013), MENTA (de Melo and Weikum, 2010), to name but a few. This wealth of acquired knowledge is known to have a positive impact on important fields such as Information Retrieval (Chu-Carroll and Prager, 2007), Information Extraction (Krause et al., 2012), Question Answering (Ferrucci et al., 2010) and Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-structured text using ontology lear</context>
</contexts>
<marker>Hoffart, Suchanek, Berberich, Weikum, 2013</marker>
<rawString>Johannes Hoffart, Fabian M. Suchanek, Klaus Berberich, and Gerhard Weikum. 2013. Yago2: A spatially and temporally enhanced knowledge base from wikipedia. Artificial Intelligence, 194:28–61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard H Hovy</author>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>Collaboratively built semistructured content and artificial intelligence: The story so far.</title>
<date>2013</date>
<journal>Artificial Intelligence,</journal>
<pages>194--2</pages>
<contexts>
<context position="1537" citStr="Hovy et al., 2013" startWordPosition="231" endWordPosition="234">n Computational Linguistics and Artificial Intelligence. Over the last decade or so the enormous abundance of information and data that has become available has made it possible to extract huge amounts of patterns and named entities (Etzioni et al., 2005), semantic lexicons for categories of interest (Thelen and Riloff, 2002; Igo and Riloff, 2009), large domain glossaries (De Benedictis et al., 2013) and lists of concepts (Katz et al., 2003). Recently, the availability of Wikipedia and other collaborative resources has considerably boosted research on several aspects of knowledge acquisition (Hovy et al., 2013), leading to the creation of several large-scale knowledge resources, such as DBPedia (Bizer et al., 2009), BabelNet (Navigli and Ponzetto, 2012), YAGO (Hoffart et al., 2013), MENTA (de Melo and Weikum, 2010), to name but a few. This wealth of acquired knowledge is known to have a positive impact on important fields such as Information Retrieval (Chu-Carroll and Prager, 2007), Information Extraction (Krause et al., 2012), Question Answering (Ferrucci et al., 2010) and Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring c</context>
</contexts>
<marker>Hovy, Navigli, Ponzetto, 2013</marker>
<rawString>Eduard H. Hovy, Roberto Navigli, and Simone Paolo Ponzetto. 2013. Collaboratively built semistructured content and artificial intelligence: The story so far. Artificial Intelligence, 194:2–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruihong Huang</author>
<author>Ellen Riloff</author>
</authors>
<title>Inducing Domain-Specific Semantic Class Taggers from (Almost) Nothing.</title>
<date>2010</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>275--285</pages>
<location>Uppsala,</location>
<contexts>
<context position="14160" citStr="Huang and Riloff, 2010" startWordPosition="2419" endWordPosition="2422">ructured in a directed acyclic graph with multiple parents per category (even worse, cycles are possible in principle); iii) there is no clear way of identifying core semantic classes from the large set of available categories. Although efforts towards the automatic taxonomization of Wikipedia categories do exist in the literature (Ponzetto and Strube, 2011; Nastase and Strube, 2013), the results are of a lower quality than a hand-built lexical resource. Therefore, as was done in previous work (Mihalcea and Moldovan, ; Ciaramita and Altun, 2006; Izquierdo et al., 2009; Erk and McCarthy, 2009; Huang and Riloff, 2010), we pick out our semantic classes C from WordNet and leverage its manually-curated taxonomy to associate our arguments with the most suitable class. This way we avoid building a new taxonomy and shift the problem to that of projecting the Wikipedia pages – associated with annotated filling arguments – to synsets in WordNet. We address this problem in two steps: Wikipedia-WordNet mapping. We exploit an existing mapping implemented in BabelNet (Navigli and Ponzetto, 2012), a wide-coverage multilingual semantic network that integrates Wikipedia and WordNet.3 Based on a disambiguation algorithm, </context>
</contexts>
<marker>Huang, Riloff, 2010</marker>
<rawString>Ruihong Huang and Ellen Riloff. 2010. Inducing Domain-Specific Semantic Class Taggers from (Almost) Nothing. In Proc. of ACL, pages 275–285, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sean P Igo</author>
<author>Ellen Riloff</author>
</authors>
<title>Corpus-based semantic lexicon induction with Web-based corroboration.</title>
<date>2009</date>
<booktitle>In Proc. of UMSLLS,</booktitle>
<pages>18--26</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1268" citStr="Igo and Riloff, 2009" startWordPosition="190" endWordPosition="193">reate a large collection of semantic predicates from the Oxford Advanced Learner’s Dictionary with high precision and recall, and perform well against the most similar approach. 1 Introduction Acquiring semantic knowledge from text automatically is a long-standing issue in Computational Linguistics and Artificial Intelligence. Over the last decade or so the enormous abundance of information and data that has become available has made it possible to extract huge amounts of patterns and named entities (Etzioni et al., 2005), semantic lexicons for categories of interest (Thelen and Riloff, 2002; Igo and Riloff, 2009), large domain glossaries (De Benedictis et al., 2013) and lists of concepts (Katz et al., 2003). Recently, the availability of Wikipedia and other collaborative resources has considerably boosted research on several aspects of knowledge acquisition (Hovy et al., 2013), leading to the creation of several large-scale knowledge resources, such as DBPedia (Bizer et al., 2009), BabelNet (Navigli and Ponzetto, 2012), YAGO (Hoffart et al., 2013), MENTA (de Melo and Weikum, 2010), to name but a few. This wealth of acquired knowledge is known to have a positive impact on important fields such as Infor</context>
</contexts>
<marker>Igo, Riloff, 2009</marker>
<rawString>Sean P. Igo and Ellen Riloff. 2009. Corpus-based semantic lexicon induction with Web-based corroboration. In Proc. of UMSLLS, pages 18–26, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rub´en Izquierdo</author>
<author>Armando Su´arez</author>
<author>German Rigau</author>
</authors>
<title>An Empirical Study on Class-Based Word Sense Disambiguation.</title>
<date>2009</date>
<booktitle>In Proc. of EACL,</booktitle>
<pages>389--397</pages>
<location>Athens, Greece.</location>
<marker>Izquierdo, Su´arez, Rigau, 2009</marker>
<rawString>Rub´en Izquierdo, Armando Su´arez, and German Rigau. 2009. An Empirical Study on Class-Based Word Sense Disambiguation. In Proc. of EACL, pages 389–397, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hyeju Jang</author>
<author>Jack Mostow</author>
</authors>
<title>Inferring selectional preferences from part-of-speech n-grams.</title>
<date>2012</date>
<booktitle>In Proc. of EACL,</booktitle>
<pages>377--386</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="35454" citStr="Jang and Mostow, 2012" startWordPosition="6011" endWordPosition="6014">antic types of the relations arguments (Resnik, 1996; Li and Abe, 1998; Clark and Weir, 2002; Pennacchiotti and Pantel, 2006). Nevertheless, despite their high quality sense-tagged data, these methods have often suffered from lack of coverage. As a result, alternative approaches have been proposed that eschew taxonomies in favor of rating the quality of potential relation arguments (Erk, 2007; Chambers and Jurafsky, 2010) or generating probability distributions over the arguments (Rooth et al., 1999; Pantel et al., 2007; Bergsma et al., 2008; Ritter et al., 2010; S´eaghdha, 2010; Bouma, 2010; Jang and Mostow, 2012) in order to obtain higher coverage of preferences. In contrast, we overcome the data sparsity of class-based models by leveraging the large quantity of collaboratively-annotated Wikipedia text in order to connect predicate arguments with their semantic class in WordNet using BabelNet (Navigli and Ponzetto, 2012); because we map directly to WordNet synsets, we provide a more readilyinterpretable collocation preference model than most similarity-based or probabilistic models. Verb frame extraction (Green et al., 2004) and predicate-argument structure analysis (Surdeanu et al., 2003; Yakushiji e</context>
</contexts>
<marker>Jang, Mostow, 2012</marker>
<rawString>Hyeju Jang and Jack Mostow. 2012. Inferring selectional preferences from part-of-speech n-grams. In Proc. of EACL, pages 377–386, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Boris Katz</author>
<author>Jimmy J Lin</author>
<author>Daniel Loreto</author>
<author>Wesley Hildebrandt</author>
<author>Matthew W Bilotti</author>
</authors>
<location>Sue Felshin, Aaron</location>
<marker>Katz, Lin, Loreto, Hildebrandt, Bilotti, </marker>
<rawString>Boris Katz, Jimmy J. Lin, Daniel Loreto, Wesley Hildebrandt, Matthew W. Bilotti, Sue Felshin, Aaron</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Marton Fernandes</author>
<author>Federico Mora</author>
</authors>
<title>Integrating Web-based and Corpus-based Techniques for Question Answering.</title>
<date>2003</date>
<booktitle>In Proc. of TREC,</booktitle>
<pages>426--435</pages>
<location>Gaithersburg, Maryland.</location>
<marker>Fernandes, Mora, 2003</marker>
<rawString>Fernandes, Gregory Marton, and Federico Mora. 2003. Integrating Web-based and Corpus-based Techniques for Question Answering. In Proc. of TREC, pages 426–435, Gaithersburg, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Eduard Hovy</author>
</authors>
<title>Learning Arguments and Supertypes of Semantic Relations Using Recursive Patterns.</title>
<date>2010</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>1482--1491</pages>
<location>Uppsala,</location>
<contexts>
<context position="3315" citStr="Kozareva and Hovy, 2010" startWordPosition="512" endWordPosition="515"> knowledge resources still lack semantic information about language units such as phrases and collocations. For instance, which semantic classes are expected as a direct object of the verb break? What kinds of noun does the adjective amazing collocate with? Recognition of the need for systems that are aware of the selectional restrictions of verbs and, more in general, of textual expressions, dates back to several decades (Wilks, 1975), but today it is more relevant than ever, as is testified by the current interest in semantic class learning (Kozareva et al., 2008) and supertype acquisition (Kozareva and Hovy, 2010). These approaches leverage lexico-syntactic patterns and input seeds to recursively learn the semantic classes of relation arguments. However, they require the manual selection of one or more seeds for each pattern of interest, and this selection influences the amount and kind of semantic classes to be learned. Furthermore, the learned classes are not directly linked to existing resources such as WordNet (Fellbaum, 1998) or Wikipedia. The goal of our research is to create a largescale repository of semantic predicates whose lexical arguments are replaced by their semantic classes. For example</context>
<context position="30170" citStr="Kozareva and Hovy (2010" startWordPosition="5119" endWordPosition="5122">r page and the Trust the inventory, which contribute 26.16% and 31.33% of the total links, respectively. Even though most of the triples (i.e., 68 out of almost 74 million) remain unlinked, the ratio of distinct arguments which we linked to WordNet is considerably higher, calculated as 3,723,979 linked arguments over 12,431,564 distinct arguments, i.e., about 30%. 5 Experiment 2: Comparison with Kozareva &amp; Hovy (2010) Due to the novelty of the task carried out by SPred, the resulting output may be compared with only a limited number of existing approaches. The most similar approach is that of Kozareva and Hovy (2010, K&amp;H) who assign supertypes to the arguments of arbitrary relations, a task which resembles our semantic predicate ranking. We therefore performed a comparison on the quality of the most highly-ranked supertypes (i.e., semantic classes) using their dataset of 24 relation patterns (i.e., lexical predicates). Dataset. The dataset contained 14 lexical predicates (e.g., work for * or *fly to), 10 of which were expanded in order to semantify their left- and right-side arguments (e.g., * work for and work for *); for the remaining 4 predicates just a single 1228 Total Linked in One sense One sense </context>
<context position="31427" citStr="Kozareva and Hovy (2010)" startWordPosition="5352" endWordPosition="5355">ia per page lexical predicate inventory linked 73,843,415 1,795,608 1,433,634 533,946 1,716,813 68,363,414 Table 5: Statistics on argument triple linking for all the lexical predicates in the Oxford dataset. k Prec@k Correct Total 1 0.88 21 24 2 0.90 43 48 3 0.88 63 72 4 0.89 85 96 5 0.91 109 120 6 0.91 131 144 7 0.92 154 168 8 0.91 175 192 9 0.92 198 216 10 0.92 221 240 11 0.92 242 264 12 0.92 264 288 13 0.91 284 312 14 0.90 304 336 15 0.91 327 360 16 0.91 348 384 17 0.90 367 408 18 0.89 386 432 19 0.89 407 456 20 0.89 429 480 Table 6: Precision@k for the semantic classes of the relations of Kozareva and Hovy (2010). side was generalized (e.g., * dress). While most of the relations apply to persons as a supertype, our method could find arguments for each of them. Methodology. We carried out the same evaluation as in Section 4.3. We calculated precision@k of the semantic classes obtained for each relation in the dataset of K&amp;H. Because the set of applicable classes was potentially unbounded, we were not able to report recall directly. Results. K&amp;H reported an overall accuracy of the top-20 supertypes of 92%. As can be seen in Table 6 we exhibit very good performance with increasing values of k. A comparis</context>
<context position="33049" citStr="Kozareva and Hovy (2010)" startWordPosition="5641" endWordPosition="5644">hich provides an estimate of the extraction capability of SPred. The large number of classes found for the arguments demonstrates the ability of our method to generalize to a variety of semantic classes. Predicate Number of args Number of classes cause * 181,401 1,339 live in * 143,628 600 go to * 134,712 867 * cause 92,160 1,244 work in * 79,444 770 * go to 71,794 746 * live in 61,074 541 work on * 58,760 840 work for * 58,332 681 work at * 31,904 511 * work in 24,933 528 * celebrate 23,333 408 Table 7: Number of arguments and associated classes for the 12 most frequent lexical predicates of Kozareva and Hovy (2010) extracted by SPred from Wikipedia. 6 Related work The availability of Web-scale corpora has led to the production of large resources of relations (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Carlson et al., 2010; Fader et al., 2011). However, these resources often operate purely at the lexical level, providing no information on the semantics of their arguments or relations. Several studies have examined adding semantics through grouping relations into sets (Yates and Etzioni, 2009), ontologizing the arguments (Chklovski and Pantel, 2004), or ontologizing the relations themsel</context>
<context position="36885" citStr="Kozareva and Hovy (2010)" startWordPosition="6228" endWordPosition="6231">er closely related work is that of Hanks (2013) concerning the Theory of Norms and Exploitations, where norms (exploitations) represent expected (unexpected) classes for a given lexical predicate. Although our semantified predicates do, indeed, provide explicit evidence of norms obtained from collective intelligence and would provide support for this theory, exploitations present a more difficult task, different from the one addressed here, due to its focus on identifying property transfer between the semantic class and the exploited instance. The closest technical approach to ours is that of Kozareva and Hovy (2010), who use recursive patterns to induce semantic classes for the arguments of relational patterns. Whereas their approach requires both a relation pattern and one or more seeds, which bias the types of semantic classes that are learned, our proposed method requires only the pattern itself, and as a result is capable of learning an unbounded number of different semantic classes. 7 Conclusions In this paper we present SPred, a novel approach to large-scale harvesting of semantic predicates. In order to semantify lexical predicates we exploit the wide coverage of Wikipedia to extract and disambigu</context>
<context position="29968" citStr="Kozareva &amp; Hovy (2010)" startWordPosition="5083" endWordPosition="5086">rguments is very low (about 2.5% of total), our strategies are able to considerably increase the size of the initial set of linked instances. The most effective strategies appear to be the One sense per page and the Trust the inventory, which contribute 26.16% and 31.33% of the total links, respectively. Even though most of the triples (i.e., 68 out of almost 74 million) remain unlinked, the ratio of distinct arguments which we linked to WordNet is considerably higher, calculated as 3,723,979 linked arguments over 12,431,564 distinct arguments, i.e., about 30%. 5 Experiment 2: Comparison with Kozareva &amp; Hovy (2010) Due to the novelty of the task carried out by SPred, the resulting output may be compared with only a limited number of existing approaches. The most similar approach is that of Kozareva and Hovy (2010, K&amp;H) who assign supertypes to the arguments of arbitrary relations, a task which resembles our semantic predicate ranking. We therefore performed a comparison on the quality of the most highly-ranked supertypes (i.e., semantic classes) using their dataset of 24 relation patterns (i.e., lexical predicates). Dataset. The dataset contained 14 lexical predicates (e.g., work for * or *fly to), 10 o</context>
</contexts>
<marker>Kozareva, Hovy, 2010</marker>
<rawString>Zornitsa Kozareva and Eduard Hovy. 2010. Learning Arguments and Supertypes of Semantic Relations Using Recursive Patterns. In Proc. of ACL, pages 1482–1491, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Ellen Riloff</author>
<author>Eduard H Hovy</author>
</authors>
<title>Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs.</title>
<date>2008</date>
<booktitle>In Proc. ACL/HLT,</booktitle>
<pages>1048--1056</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="3263" citStr="Kozareva et al., 2008" startWordPosition="505" endWordPosition="508">; Snow et al., 2004, among others). However, these knowledge resources still lack semantic information about language units such as phrases and collocations. For instance, which semantic classes are expected as a direct object of the verb break? What kinds of noun does the adjective amazing collocate with? Recognition of the need for systems that are aware of the selectional restrictions of verbs and, more in general, of textual expressions, dates back to several decades (Wilks, 1975), but today it is more relevant than ever, as is testified by the current interest in semantic class learning (Kozareva et al., 2008) and supertype acquisition (Kozareva and Hovy, 2010). These approaches leverage lexico-syntactic patterns and input seeds to recursively learn the semantic classes of relation arguments. However, they require the manual selection of one or more seeds for each pattern of interest, and this selection influences the amount and kind of semantic classes to be learned. Furthermore, the learned classes are not directly linked to existing resources such as WordNet (Fellbaum, 1998) or Wikipedia. The goal of our research is to create a largescale repository of semantic predicates whose lexical arguments</context>
</contexts>
<marker>Kozareva, Riloff, Hovy, 2008</marker>
<rawString>Zornitsa Kozareva, Ellen Riloff, and Eduard H. Hovy. 2008. Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs. In Proc. ACL/HLT, pages 1048–1056, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Krause</author>
<author>Hong Li</author>
<author>Hans Uszkoreit</author>
<author>Feiyu Xu</author>
</authors>
<title>Large-scale learning of relationextraction rules with distant supervision from the web. In</title>
<date>2012</date>
<booktitle>Proc. of ISWC 2012, Part I,</booktitle>
<pages>263--278</pages>
<location>Boston, MA.</location>
<contexts>
<context position="1961" citStr="Krause et al., 2012" startWordPosition="298" endWordPosition="301">pts (Katz et al., 2003). Recently, the availability of Wikipedia and other collaborative resources has considerably boosted research on several aspects of knowledge acquisition (Hovy et al., 2013), leading to the creation of several large-scale knowledge resources, such as DBPedia (Bizer et al., 2009), BabelNet (Navigli and Ponzetto, 2012), YAGO (Hoffart et al., 2013), MENTA (de Melo and Weikum, 2010), to name but a few. This wealth of acquired knowledge is known to have a positive impact on important fields such as Information Retrieval (Chu-Carroll and Prager, 2007), Information Extraction (Krause et al., 2012), Question Answering (Ferrucci et al., 2010) and Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-structured text using ontology learning from scratch (Velardi et al., 2013) and Open Information Extraction techniques (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Fader et al., 2011; Moro and Navigli, 2013) which mainly stem from seminal work on is-a relation acquisi</context>
</contexts>
<marker>Krause, Li, Uszkoreit, Xu, 2012</marker>
<rawString>Sebastian Krause, Hong Li, Hans Uszkoreit, and Feiyu Xu. 2012. Large-scale learning of relationextraction rules with distant supervision from the web. In Proc. of ISWC 2012, Part I, pages 263–278, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Li</author>
<author>Naoki Abe</author>
</authors>
<title>Generalizing case frames using a thesaurus and the MDL principle.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>2</issue>
<contexts>
<context position="34902" citStr="Li and Abe, 1998" startWordPosition="5925" endWordPosition="5928">scale resource has existed to date that contains ontologized lexical predicates. In contrast, the present work provides a high-coverage method for learning argument supertypes from a broadcoverage ontology (WordNet), which can potentially be leveraged in relation extraction to ontolo1229 gize relation arguments. Our method for identifying the different semantic classes of predicate arguments is closely related to the task of identifying selectional preferences. The most similar approaches to it are taxonomybased ones, which leverage the semantic types of the relations arguments (Resnik, 1996; Li and Abe, 1998; Clark and Weir, 2002; Pennacchiotti and Pantel, 2006). Nevertheless, despite their high quality sense-tagged data, these methods have often suffered from lack of coverage. As a result, alternative approaches have been proposed that eschew taxonomies in favor of rating the quality of potential relation arguments (Erk, 2007; Chambers and Jurafsky, 2010) or generating probability distributions over the arguments (Rooth et al., 1999; Pantel et al., 2007; Bergsma et al., 2008; Ritter et al., 2010; S´eaghdha, 2010; Bouma, 2010; Jang and Mostow, 2012) in order to obtain higher coverage of preferenc</context>
</contexts>
<marker>Li, Abe, 1998</marker>
<rawString>Hang Li and Naoki Abe. 1998. Generalizing case frames using a thesaurus and the MDL principle. Computational Linguistics, 24(2):217–244.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Rada Mihalcea</author>
<author>Dan Moldovan</author>
</authors>
<title>eXtended WordNet: Progress report.</title>
<booktitle>In Proceedings of the NAACL01 Workshop on WordNet and Other Lexical Resources,</booktitle>
<location>Pittsburgh, Penn.</location>
<marker>Mihalcea, Moldovan, </marker>
<rawString>Rada Mihalcea and Dan Moldovan. eXtended WordNet: Progress report. In Proceedings of the NAACL01 Workshop on WordNet and Other Lexical Resources, Pittsburgh, Penn.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thahir Mohamed</author>
<author>Estevam Hruschka</author>
<author>Tom Mitchell</author>
</authors>
<title>Discovering Relations between Noun Categories.</title>
<date>2011</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>1447--1455</pages>
<location>Edinburgh, Scotland, UK.</location>
<contexts>
<context position="33989" citStr="Mohamed et al. (2011)" startWordPosition="5785" endWordPosition="5788"> providing no information on the semantics of their arguments or relations. Several studies have examined adding semantics through grouping relations into sets (Yates and Etzioni, 2009), ontologizing the arguments (Chklovski and Pantel, 2004), or ontologizing the relations themselves (Moro and Navigli, 2013). However, analysis has largely been either limited to ontologizing a small number of relation types with a fixed inventory, which potentially limits coverage, or has used implicit definitions of semantic categories (e.g., clusters of arguments), which limits interpretability. For example, Mohamed et al. (2011) use the semantic categories of the NELL system (Carlson et al., 2010) to learn roughly 400 valid ontologized relations from over 200M web pages, whereas WiSeNet (Moro and Navigli, 2012) leverages Wikipedia to acquire relation synsets for an open set of relations. Despite these efforts, no large-scale resource has existed to date that contains ontologized lexical predicates. In contrast, the present work provides a high-coverage method for learning argument supertypes from a broadcoverage ontology (WordNet), which can potentially be leveraged in relation extraction to ontolo1229 gize relation </context>
</contexts>
<marker>Mohamed, Hruschka, Mitchell, 2011</marker>
<rawString>Thahir Mohamed, Estevam Hruschka, and Tom Mitchell. 2011. Discovering Relations between Noun Categories. In Proc. of EMNLP, pages 1447– 1455, Edinburgh, Scotland, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Moro</author>
<author>Roberto Navigli</author>
</authors>
<title>WiSeNet: Building a Wikipedia-based semantic network with ontologized relations.</title>
<date>2012</date>
<booktitle>In Proc. of CIKM,</booktitle>
<pages>1672--1676</pages>
<location>Maui, HI, USA.</location>
<contexts>
<context position="34175" citStr="Moro and Navigli, 2012" startWordPosition="5815" endWordPosition="5818">), ontologizing the arguments (Chklovski and Pantel, 2004), or ontologizing the relations themselves (Moro and Navigli, 2013). However, analysis has largely been either limited to ontologizing a small number of relation types with a fixed inventory, which potentially limits coverage, or has used implicit definitions of semantic categories (e.g., clusters of arguments), which limits interpretability. For example, Mohamed et al. (2011) use the semantic categories of the NELL system (Carlson et al., 2010) to learn roughly 400 valid ontologized relations from over 200M web pages, whereas WiSeNet (Moro and Navigli, 2012) leverages Wikipedia to acquire relation synsets for an open set of relations. Despite these efforts, no large-scale resource has existed to date that contains ontologized lexical predicates. In contrast, the present work provides a high-coverage method for learning argument supertypes from a broadcoverage ontology (WordNet), which can potentially be leveraged in relation extraction to ontolo1229 gize relation arguments. Our method for identifying the different semantic classes of predicate arguments is closely related to the task of identifying selectional preferences. The most similar approa</context>
</contexts>
<marker>Moro, Navigli, 2012</marker>
<rawString>Andrea Moro and Roberto Navigli. 2012. WiSeNet: Building a Wikipedia-based semantic network with ontologized relations. In Proc. of CIKM, pages 1672–1676, Maui, HI, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Moro</author>
<author>Roberto Navigli</author>
</authors>
<title>Integrating Syntactic and Semantic Analysis into the Open Information Extraction Paradigm.</title>
<date>2013</date>
<booktitle>In Proc. of IJCAI,</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="2500" citStr="Moro and Navigli, 2013" startWordPosition="382" endWordPosition="385">trieval (Chu-Carroll and Prager, 2007), Information Extraction (Krause et al., 2012), Question Answering (Ferrucci et al., 2010) and Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-structured text using ontology learning from scratch (Velardi et al., 2013) and Open Information Extraction techniques (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Fader et al., 2011; Moro and Navigli, 2013) which mainly stem from seminal work on is-a relation acquisition (Hearst, 1992) and subsequent developments (Girju et al., 2003; Pasca, 2004; Snow et al., 2004, among others). However, these knowledge resources still lack semantic information about language units such as phrases and collocations. For instance, which semantic classes are expected as a direct object of the verb break? What kinds of noun does the adjective amazing collocate with? Recognition of the need for systems that are aware of the selectional restrictions of verbs and, more in general, of textual expressions, dates back to</context>
<context position="33677" citStr="Moro and Navigli, 2013" startWordPosition="5738" endWordPosition="5741">acted by SPred from Wikipedia. 6 Related work The availability of Web-scale corpora has led to the production of large resources of relations (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Carlson et al., 2010; Fader et al., 2011). However, these resources often operate purely at the lexical level, providing no information on the semantics of their arguments or relations. Several studies have examined adding semantics through grouping relations into sets (Yates and Etzioni, 2009), ontologizing the arguments (Chklovski and Pantel, 2004), or ontologizing the relations themselves (Moro and Navigli, 2013). However, analysis has largely been either limited to ontologizing a small number of relation types with a fixed inventory, which potentially limits coverage, or has used implicit definitions of semantic categories (e.g., clusters of arguments), which limits interpretability. For example, Mohamed et al. (2011) use the semantic categories of the NELL system (Carlson et al., 2010) to learn roughly 400 valid ontologized relations from over 200M web pages, whereas WiSeNet (Moro and Navigli, 2012) leverages Wikipedia to acquire relation synsets for an open set of relations. Despite these efforts, </context>
</contexts>
<marker>Moro, Navigli, 2013</marker>
<rawString>Andrea Moro and Roberto Navigli. 2013. Integrating Syntactic and Semantic Analysis into the Open Information Extraction Paradigm. In Proc. of IJCAI, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivi Nastase</author>
<author>Michael Strube</author>
</authors>
<title>Transforming wikipedia into a large scale multilingual concept network.</title>
<date>2013</date>
<journal>Artificial Intelligence,</journal>
<pages>194--62</pages>
<contexts>
<context position="13923" citStr="Nastase and Strube, 2013" startWordPosition="2379" endWordPosition="2382">sons: i) many categories do not express taxonomic information (e.g., the English page Albert Einstein provides categories such as DEATHS FROM ABDOMINAL AORTIC ANEURYSM and INSTITUTE FOR ADVANCED STUDY FACULTY); ii) categories are mostly structured in a directed acyclic graph with multiple parents per category (even worse, cycles are possible in principle); iii) there is no clear way of identifying core semantic classes from the large set of available categories. Although efforts towards the automatic taxonomization of Wikipedia categories do exist in the literature (Ponzetto and Strube, 2011; Nastase and Strube, 2013), the results are of a lower quality than a hand-built lexical resource. Therefore, as was done in previous work (Mihalcea and Moldovan, ; Ciaramita and Altun, 2006; Izquierdo et al., 2009; Erk and McCarthy, 2009; Huang and Riloff, 2010), we pick out our semantic classes C from WordNet and leverage its manually-curated taxonomy to associate our arguments with the most suitable class. This way we avoid building a new taxonomy and shift the problem to that of projecting the Wikipedia pages – associated with annotated filling arguments – to synsets in WordNet. We address this problem in two steps</context>
</contexts>
<marker>Nastase, Strube, 2013</marker>
<rawString>Vivi Nastase and Michael Strube. 2013. Transforming wikipedia into a large scale multilingual concept network. Artificial Intelligence, 194:62–85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network.</title>
<date>2012</date>
<journal>Artificial Intelligence,</journal>
<volume>193</volume>
<pages>250</pages>
<contexts>
<context position="1682" citStr="Navigli and Ponzetto, 2012" startWordPosition="253" endWordPosition="256">has become available has made it possible to extract huge amounts of patterns and named entities (Etzioni et al., 2005), semantic lexicons for categories of interest (Thelen and Riloff, 2002; Igo and Riloff, 2009), large domain glossaries (De Benedictis et al., 2013) and lists of concepts (Katz et al., 2003). Recently, the availability of Wikipedia and other collaborative resources has considerably boosted research on several aspects of knowledge acquisition (Hovy et al., 2013), leading to the creation of several large-scale knowledge resources, such as DBPedia (Bizer et al., 2009), BabelNet (Navigli and Ponzetto, 2012), YAGO (Hoffart et al., 2013), MENTA (de Melo and Weikum, 2010), to name but a few. This wealth of acquired knowledge is known to have a positive impact on important fields such as Information Retrieval (Chu-Carroll and Prager, 2007), Information Extraction (Krause et al., 2012), Question Answering (Ferrucci et al., 2010) and Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-struct</context>
<context position="14635" citStr="Navigli and Ponzetto, 2012" startWordPosition="2495" endWordPosition="2499">s was done in previous work (Mihalcea and Moldovan, ; Ciaramita and Altun, 2006; Izquierdo et al., 2009; Erk and McCarthy, 2009; Huang and Riloff, 2010), we pick out our semantic classes C from WordNet and leverage its manually-curated taxonomy to associate our arguments with the most suitable class. This way we avoid building a new taxonomy and shift the problem to that of projecting the Wikipedia pages – associated with annotated filling arguments – to synsets in WordNet. We address this problem in two steps: Wikipedia-WordNet mapping. We exploit an existing mapping implemented in BabelNet (Navigli and Ponzetto, 2012), a wide-coverage multilingual semantic network that integrates Wikipedia and WordNet.3 Based on a disambiguation algorithm, BabelNet establishes a mapping µ : Wikipages -+ Synsets which links about 50,000 pages to their most suitable WordNet senses.4 Mapping extension. Nevertheless, BabelNet is able to solve the problem only partially, because it still leaves the vast majority of the 4 million English Wikipedia pages unmapped. This is mainly due to the encyclopedic nature of most pages, which do not have a counterpart in the WordNet dictionary. To address this issue, for each unmapped Wikiped</context>
<context position="35768" citStr="Navigli and Ponzetto, 2012" startWordPosition="6057" endWordPosition="6061">w taxonomies in favor of rating the quality of potential relation arguments (Erk, 2007; Chambers and Jurafsky, 2010) or generating probability distributions over the arguments (Rooth et al., 1999; Pantel et al., 2007; Bergsma et al., 2008; Ritter et al., 2010; S´eaghdha, 2010; Bouma, 2010; Jang and Mostow, 2012) in order to obtain higher coverage of preferences. In contrast, we overcome the data sparsity of class-based models by leveraging the large quantity of collaboratively-annotated Wikipedia text in order to connect predicate arguments with their semantic class in WordNet using BabelNet (Navigli and Ponzetto, 2012); because we map directly to WordNet synsets, we provide a more readilyinterpretable collocation preference model than most similarity-based or probabilistic models. Verb frame extraction (Green et al., 2004) and predicate-argument structure analysis (Surdeanu et al., 2003; Yakushiji et al., 2006) are two areas that are also related to our work. But their generality goes beyond our intentions, as we focus on semantic predicates, which is much simpler and free from syntactic parsing. Another closely related work is that of Hanks (2013) concerning the Theory of Norms and Exploitations, where nor</context>
</contexts>
<marker>Navigli, Ponzetto, 2012</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012. BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network. Artificial Intelligence, 193:217– 250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Paola Velardi</author>
</authors>
<title>Learning Word-Class Lattices for Definition and Hypernym Extraction.</title>
<date>2010</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>1318--1327</pages>
<location>Uppsala,</location>
<contexts>
<context position="15821" citStr="Navigli and Velardi, 2010" startWordPosition="2684" endWordPosition="2687">s this issue, for each unmapped Wikipedia page p we obtain its textual definition as the first sentence of the page.5 Next, 3http://babelnet.org 4We follow (Navigli, 2009) and denote with w&apos; the i-th sense of w in WordNet with part of speech p. 5According to the Wikipedia guidelines, “The article should begin with a short declarative sentence, answering two questions for the nonspecialist reader: What (or who) is the subject? and Why is this subject notable?”, extracted from http://en.wikipedia.org/wiki/ we extract the hypernym from the textual definition of p by applying Word-Class Lattices (Navigli and Velardi, 2010, WCL6), a domain-independent hypernym extraction system successfully applied to taxonomy learning from scratch (Velardi et al., 2013) and freely available online (Faralli and Navigli, 2013). If a hypernym h is successfully extracted and h is linked to a Wikipedia page p&apos; for which µ(p&apos;) is defined, then we extend the mapping by setting µ(p) := µ(p&apos;). For instance, the mapping provided by BabelNet does not provide any link for the page Peter Spence; thanks to WCL, though, we are able to set the page Journalist as its hypernym, and link it to the WordNet synset journalists. This way our mapping</context>
</contexts>
<marker>Navigli, Velardi, 2010</marker>
<rawString>Roberto Navigli and Paola Velardi. 2010. Learning Word-Class Lattices for Definition and Hypernym Extraction. In Proc. of ACL, pages 1318–1327, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word Sense Disambiguation: A survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="15367" citStr="Navigli, 2009" startWordPosition="2614" endWordPosition="2615">rithm, BabelNet establishes a mapping µ : Wikipages -+ Synsets which links about 50,000 pages to their most suitable WordNet senses.4 Mapping extension. Nevertheless, BabelNet is able to solve the problem only partially, because it still leaves the vast majority of the 4 million English Wikipedia pages unmapped. This is mainly due to the encyclopedic nature of most pages, which do not have a counterpart in the WordNet dictionary. To address this issue, for each unmapped Wikipedia page p we obtain its textual definition as the first sentence of the page.5 Next, 3http://babelnet.org 4We follow (Navigli, 2009) and denote with w&apos; the i-th sense of w in WordNet with part of speech p. 5According to the Wikipedia guidelines, “The article should begin with a short declarative sentence, answering two questions for the nonspecialist reader: What (or who) is the subject? and Why is this subject notable?”, extracted from http://en.wikipedia.org/wiki/ we extract the hypernym from the textual definition of p by applying Word-Class Lattices (Navigli and Velardi, 2010, WCL6), a domain-independent hypernym extraction system successfully applied to taxonomy learning from scratch (Velardi et al., 2013) and freely </context>
<context position="38330" citStr="Navigli, 2009" startWordPosition="6460" endWordPosition="6461">aries (e.g., break a toe) into semantic predicates (such as break a BODY PART). For each lexical predicate (such as break ∗), our method produces a probability distribution over the set of semantic classes (thus covering the different expected meanings for the filling arguments) and is able to classify new instances with the most suitable class. Our experiments show generally high performance, also in comparison with previous work on argument supertyping. We hope that our semantic predicates will enable progress in different Natural Language Processing tasks such as Word Sense Disambiguation (Navigli, 2009), Semantic Role Labeling (F¨urstenau and Lapata, 2012) or even Textual Entailment (Stern and Dagan, 2012) – each of which is in urgent need of reliable semantics. While we focused on semantifying lexical predicates, as future work we will apply our method to the ontologization of large amounts of sequences of words, such as phrases or textual relations (e.g., considering Google n-grams appearing in Wikipedia). Notably, our method should, in principle, generalize to any semantically-annotated corpus (e.g., Wikipedias in other languages), provided lexical predicates can be extracted with associa</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word Sense Disambiguation: A survey. ACM Computing Surveys, 41(2):1–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Rahul Bhagat</author>
<author>Timothy Chklovski</author>
<author>Eduard Hovy</author>
</authors>
<title>ISP: learning inferential selectional preferences.</title>
<date>2007</date>
<booktitle>In Proc. of NAACL,</booktitle>
<pages>564--571</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="35357" citStr="Pantel et al., 2007" startWordPosition="5995" endWordPosition="5998"> preferences. The most similar approaches to it are taxonomybased ones, which leverage the semantic types of the relations arguments (Resnik, 1996; Li and Abe, 1998; Clark and Weir, 2002; Pennacchiotti and Pantel, 2006). Nevertheless, despite their high quality sense-tagged data, these methods have often suffered from lack of coverage. As a result, alternative approaches have been proposed that eschew taxonomies in favor of rating the quality of potential relation arguments (Erk, 2007; Chambers and Jurafsky, 2010) or generating probability distributions over the arguments (Rooth et al., 1999; Pantel et al., 2007; Bergsma et al., 2008; Ritter et al., 2010; S´eaghdha, 2010; Bouma, 2010; Jang and Mostow, 2012) in order to obtain higher coverage of preferences. In contrast, we overcome the data sparsity of class-based models by leveraging the large quantity of collaboratively-annotated Wikipedia text in order to connect predicate arguments with their semantic class in WordNet using BabelNet (Navigli and Ponzetto, 2012); because we map directly to WordNet synsets, we provide a more readilyinterpretable collocation preference model than most similarity-based or probabilistic models. Verb frame extraction (</context>
</contexts>
<marker>Pantel, Bhagat, Chklovski, Hovy, 2007</marker>
<rawString>Patrick Pantel, Rahul Bhagat, Timothy Chklovski, and Eduard Hovy. 2007. ISP: learning inferential selectional preferences. In Proc. of NAACL, pages 564– 571, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pasca</author>
</authors>
<title>Acquisition of categorized named entities for web search.</title>
<date>2004</date>
<booktitle>In Proc. of CIKM,</booktitle>
<pages>137--145</pages>
<location>New York, NY, USA.</location>
<contexts>
<context position="2641" citStr="Pasca, 2004" startWordPosition="406" endWordPosition="407">Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-structured text using ontology learning from scratch (Velardi et al., 2013) and Open Information Extraction techniques (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Fader et al., 2011; Moro and Navigli, 2013) which mainly stem from seminal work on is-a relation acquisition (Hearst, 1992) and subsequent developments (Girju et al., 2003; Pasca, 2004; Snow et al., 2004, among others). However, these knowledge resources still lack semantic information about language units such as phrases and collocations. For instance, which semantic classes are expected as a direct object of the verb break? What kinds of noun does the adjective amazing collocate with? Recognition of the need for systems that are aware of the selectional restrictions of verbs and, more in general, of textual expressions, dates back to several decades (Wilks, 1975), but today it is more relevant than ever, as is testified by the current interest in semantic class learning (</context>
</contexts>
<marker>Pasca, 2004</marker>
<rawString>Marius Pasca. 2004. Acquisition of categorized named entities for web search. In Proc. of CIKM, pages 137–145, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Pennacchiotti</author>
<author>Patrick Pantel</author>
</authors>
<title>Ontologizing semantic relations.</title>
<date>2006</date>
<booktitle>In Proc. of COLING,</booktitle>
<pages>793--800</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="34957" citStr="Pennacchiotti and Pantel, 2006" startWordPosition="5933" endWordPosition="5936">contains ontologized lexical predicates. In contrast, the present work provides a high-coverage method for learning argument supertypes from a broadcoverage ontology (WordNet), which can potentially be leveraged in relation extraction to ontolo1229 gize relation arguments. Our method for identifying the different semantic classes of predicate arguments is closely related to the task of identifying selectional preferences. The most similar approaches to it are taxonomybased ones, which leverage the semantic types of the relations arguments (Resnik, 1996; Li and Abe, 1998; Clark and Weir, 2002; Pennacchiotti and Pantel, 2006). Nevertheless, despite their high quality sense-tagged data, these methods have often suffered from lack of coverage. As a result, alternative approaches have been proposed that eschew taxonomies in favor of rating the quality of potential relation arguments (Erk, 2007; Chambers and Jurafsky, 2010) or generating probability distributions over the arguments (Rooth et al., 1999; Pantel et al., 2007; Bergsma et al., 2008; Ritter et al., 2010; S´eaghdha, 2010; Bouma, 2010; Jang and Mostow, 2012) in order to obtain higher coverage of preferences. In contrast, we overcome the data sparsity of class</context>
</contexts>
<marker>Pennacchiotti, Pantel, 2006</marker>
<rawString>Marco Pennacchiotti and Patrick Pantel. 2006. Ontologizing semantic relations. In Proc. of COLING, pages 793–800, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Paolo Ponzetto</author>
<author>Michael Strube</author>
</authors>
<title>Taxonomy induction based on a collaboratively built knowledge repository.</title>
<date>2011</date>
<journal>Artificial Intelligence,</journal>
<pages>175--9</pages>
<contexts>
<context position="13896" citStr="Ponzetto and Strube, 2011" startWordPosition="2375" endWordPosition="2378">page for at least three reasons: i) many categories do not express taxonomic information (e.g., the English page Albert Einstein provides categories such as DEATHS FROM ABDOMINAL AORTIC ANEURYSM and INSTITUTE FOR ADVANCED STUDY FACULTY); ii) categories are mostly structured in a directed acyclic graph with multiple parents per category (even worse, cycles are possible in principle); iii) there is no clear way of identifying core semantic classes from the large set of available categories. Although efforts towards the automatic taxonomization of Wikipedia categories do exist in the literature (Ponzetto and Strube, 2011; Nastase and Strube, 2013), the results are of a lower quality than a hand-built lexical resource. Therefore, as was done in previous work (Mihalcea and Moldovan, ; Ciaramita and Altun, 2006; Izquierdo et al., 2009; Erk and McCarthy, 2009; Huang and Riloff, 2010), we pick out our semantic classes C from WordNet and leverage its manually-curated taxonomy to associate our arguments with the most suitable class. This way we avoid building a new taxonomy and shift the problem to that of projecting the Wikipedia pages – associated with annotated filling arguments – to synsets in WordNet. We addres</context>
</contexts>
<marker>Ponzetto, Strube, 2011</marker>
<rawString>Simone Paolo Ponzetto and Michael Strube. 2011. Taxonomy induction based on a collaboratively built knowledge repository. Artificial Intelligence, 175(9-10):1737–1756.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selectional constraints: An information-theoretic model and its computational realization.</title>
<date>1996</date>
<journal>Cognition,</journal>
<volume>61</volume>
<issue>1</issue>
<contexts>
<context position="34884" citStr="Resnik, 1996" startWordPosition="5923" endWordPosition="5924">rts, no large-scale resource has existed to date that contains ontologized lexical predicates. In contrast, the present work provides a high-coverage method for learning argument supertypes from a broadcoverage ontology (WordNet), which can potentially be leveraged in relation extraction to ontolo1229 gize relation arguments. Our method for identifying the different semantic classes of predicate arguments is closely related to the task of identifying selectional preferences. The most similar approaches to it are taxonomybased ones, which leverage the semantic types of the relations arguments (Resnik, 1996; Li and Abe, 1998; Clark and Weir, 2002; Pennacchiotti and Pantel, 2006). Nevertheless, despite their high quality sense-tagged data, these methods have often suffered from lack of coverage. As a result, alternative approaches have been proposed that eschew taxonomies in favor of rating the quality of potential relation arguments (Erk, 2007; Chambers and Jurafsky, 2010) or generating probability distributions over the arguments (Rooth et al., 1999; Pantel et al., 2007; Bergsma et al., 2008; Ritter et al., 2010; S´eaghdha, 2010; Bouma, 2010; Jang and Mostow, 2012) in order to obtain higher cov</context>
</contexts>
<marker>Resnik, 1996</marker>
<rawString>Philip Resnik. 1996. Selectional constraints: An information-theoretic model and its computational realization. Cognition, 61(1):127–159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Mausam</author>
<author>Oren Etzioni</author>
</authors>
<title>A latent dirichlet allocation method for selectional preferences.</title>
<date>2010</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>424--434</pages>
<publisher>ACL.</publisher>
<location>Uppsala,</location>
<contexts>
<context position="35400" citStr="Ritter et al., 2010" startWordPosition="6003" endWordPosition="6006">o it are taxonomybased ones, which leverage the semantic types of the relations arguments (Resnik, 1996; Li and Abe, 1998; Clark and Weir, 2002; Pennacchiotti and Pantel, 2006). Nevertheless, despite their high quality sense-tagged data, these methods have often suffered from lack of coverage. As a result, alternative approaches have been proposed that eschew taxonomies in favor of rating the quality of potential relation arguments (Erk, 2007; Chambers and Jurafsky, 2010) or generating probability distributions over the arguments (Rooth et al., 1999; Pantel et al., 2007; Bergsma et al., 2008; Ritter et al., 2010; S´eaghdha, 2010; Bouma, 2010; Jang and Mostow, 2012) in order to obtain higher coverage of preferences. In contrast, we overcome the data sparsity of class-based models by leveraging the large quantity of collaboratively-annotated Wikipedia text in order to connect predicate arguments with their semantic class in WordNet using BabelNet (Navigli and Ponzetto, 2012); because we map directly to WordNet synsets, we provide a more readilyinterpretable collocation preference model than most similarity-based or probabilistic models. Verb frame extraction (Green et al., 2004) and predicate-argument </context>
</contexts>
<marker>Ritter, Mausam, Etzioni, 2010</marker>
<rawString>Alan Ritter, Mausam, and Oren Etzioni. 2010. A latent dirichlet allocation method for selectional preferences. In Proc. of ACL, pages 424–434, Uppsala, Sweden. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Rooth</author>
<author>Stefan Riezler</author>
<author>Detlef Prescher</author>
<author>Glenn Carroll</author>
<author>Franz Beil</author>
</authors>
<title>Inducing a semantically annotated lexicon via EM-based clustering.</title>
<date>1999</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>104--111</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="35336" citStr="Rooth et al., 1999" startWordPosition="5991" endWordPosition="5994">ntifying selectional preferences. The most similar approaches to it are taxonomybased ones, which leverage the semantic types of the relations arguments (Resnik, 1996; Li and Abe, 1998; Clark and Weir, 2002; Pennacchiotti and Pantel, 2006). Nevertheless, despite their high quality sense-tagged data, these methods have often suffered from lack of coverage. As a result, alternative approaches have been proposed that eschew taxonomies in favor of rating the quality of potential relation arguments (Erk, 2007; Chambers and Jurafsky, 2010) or generating probability distributions over the arguments (Rooth et al., 1999; Pantel et al., 2007; Bergsma et al., 2008; Ritter et al., 2010; S´eaghdha, 2010; Bouma, 2010; Jang and Mostow, 2012) in order to obtain higher coverage of preferences. In contrast, we overcome the data sparsity of class-based models by leveraging the large quantity of collaboratively-annotated Wikipedia text in order to connect predicate arguments with their semantic class in WordNet using BabelNet (Navigli and Ponzetto, 2012); because we map directly to WordNet synsets, we provide a more readilyinterpretable collocation preference model than most similarity-based or probabilistic models. Ve</context>
</contexts>
<marker>Rooth, Riezler, Prescher, Carroll, Beil, 1999</marker>
<rawString>Mats Rooth, Stefan Riezler, Detlef Prescher, Glenn Carroll, and Franz Beil. 1999. Inducing a semantically annotated lexicon via EM-based clustering. In Proc. of ACL, pages 104–111, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diarmuid O S´eaghdha</author>
</authors>
<title>Latent variable models of selectional preference.</title>
<date>2010</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>435--444</pages>
<location>Uppsala,</location>
<marker>S´eaghdha, 2010</marker>
<rawString>Diarmuid O S´eaghdha. 2010. Latent variable models of selectional preference. In Proc. of ACL, pages 435–444, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Learning Syntactic Patterns for Automatic Hypernym Discovery. In</title>
<date>2004</date>
<booktitle>NIPS,</booktitle>
<pages>1297--1304</pages>
<location>Cambridge, Mass.</location>
<contexts>
<context position="2660" citStr="Snow et al., 2004" startWordPosition="408" endWordPosition="411">, 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-structured text using ontology learning from scratch (Velardi et al., 2013) and Open Information Extraction techniques (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Fader et al., 2011; Moro and Navigli, 2013) which mainly stem from seminal work on is-a relation acquisition (Hearst, 1992) and subsequent developments (Girju et al., 2003; Pasca, 2004; Snow et al., 2004, among others). However, these knowledge resources still lack semantic information about language units such as phrases and collocations. For instance, which semantic classes are expected as a direct object of the verb break? What kinds of noun does the adjective amazing collocate with? Recognition of the need for systems that are aware of the selectional restrictions of verbs and, more in general, of textual expressions, dates back to several decades (Wilks, 1975), but today it is more relevant than ever, as is testified by the current interest in semantic class learning (Kozareva et al., 20</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2004</marker>
<rawString>Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2004. Learning Syntactic Patterns for Automatic Hypernym Discovery. In NIPS, pages 1297–1304, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asher Stern</author>
<author>Ido Dagan</author>
</authors>
<title>Biutee: A modular open-source system for recognizing textual entailment.</title>
<date>2012</date>
<booktitle>In Proc. of ACL 2012, System Demonstrations,</booktitle>
<pages>73--78</pages>
<location>Jeju Island,</location>
<contexts>
<context position="2073" citStr="Stern and Dagan, 2012" startWordPosition="315" endWordPosition="318">rably boosted research on several aspects of knowledge acquisition (Hovy et al., 2013), leading to the creation of several large-scale knowledge resources, such as DBPedia (Bizer et al., 2009), BabelNet (Navigli and Ponzetto, 2012), YAGO (Hoffart et al., 2013), MENTA (de Melo and Weikum, 2010), to name but a few. This wealth of acquired knowledge is known to have a positive impact on important fields such as Information Retrieval (Chu-Carroll and Prager, 2007), Information Extraction (Krause et al., 2012), Question Answering (Ferrucci et al., 2010) and Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-structured text using ontology learning from scratch (Velardi et al., 2013) and Open Information Extraction techniques (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Fader et al., 2011; Moro and Navigli, 2013) which mainly stem from seminal work on is-a relation acquisition (Hearst, 1992) and subsequent developments (Girju et al., 2003; Pasca, 2004; Snow et al., 2004, among other</context>
<context position="38435" citStr="Stern and Dagan, 2012" startWordPosition="6474" endWordPosition="6477">predicate (such as break ∗), our method produces a probability distribution over the set of semantic classes (thus covering the different expected meanings for the filling arguments) and is able to classify new instances with the most suitable class. Our experiments show generally high performance, also in comparison with previous work on argument supertyping. We hope that our semantic predicates will enable progress in different Natural Language Processing tasks such as Word Sense Disambiguation (Navigli, 2009), Semantic Role Labeling (F¨urstenau and Lapata, 2012) or even Textual Entailment (Stern and Dagan, 2012) – each of which is in urgent need of reliable semantics. While we focused on semantifying lexical predicates, as future work we will apply our method to the ontologization of large amounts of sequences of words, such as phrases or textual relations (e.g., considering Google n-grams appearing in Wikipedia). Notably, our method should, in principle, generalize to any semantically-annotated corpus (e.g., Wikipedias in other languages), provided lexical predicates can be extracted with associated semantic classes. In order to support future efforts we are releasing our semantic predicates as a fr</context>
</contexts>
<marker>Stern, Dagan, 2012</marker>
<rawString>Asher Stern and Ido Dagan. 2012. Biutee: A modular open-source system for recognizing textual entailment. In Proc. of ACL 2012, System Demonstrations, pages 73–78, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Sanda Harabagiu</author>
<author>John Williams</author>
<author>Paul Aarseth</author>
</authors>
<title>Using predicate-argument structures for information extraction.</title>
<date>2003</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>8--15</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="36041" citStr="Surdeanu et al., 2003" startWordPosition="6095" endWordPosition="6098">ouma, 2010; Jang and Mostow, 2012) in order to obtain higher coverage of preferences. In contrast, we overcome the data sparsity of class-based models by leveraging the large quantity of collaboratively-annotated Wikipedia text in order to connect predicate arguments with their semantic class in WordNet using BabelNet (Navigli and Ponzetto, 2012); because we map directly to WordNet synsets, we provide a more readilyinterpretable collocation preference model than most similarity-based or probabilistic models. Verb frame extraction (Green et al., 2004) and predicate-argument structure analysis (Surdeanu et al., 2003; Yakushiji et al., 2006) are two areas that are also related to our work. But their generality goes beyond our intentions, as we focus on semantic predicates, which is much simpler and free from syntactic parsing. Another closely related work is that of Hanks (2013) concerning the Theory of Norms and Exploitations, where norms (exploitations) represent expected (unexpected) classes for a given lexical predicate. Although our semantified predicates do, indeed, provide explicit evidence of norms obtained from collective intelligence and would provide support for this theory, exploitations prese</context>
</contexts>
<marker>Surdeanu, Harabagiu, Williams, Aarseth, 2003</marker>
<rawString>Mihai Surdeanu, Sanda Harabagiu, John Williams, and Paul Aarseth. 2003. Using predicate-argument structures for information extraction. In Proc. ACL, pages 8–15, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Thelen</author>
<author>E Riloff</author>
</authors>
<title>A Bootstrapping Method for Learning Semantic Lexicons using Extraction Pattern Contexts.</title>
<date>2002</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>214--221</pages>
<location>Salt Lake City, UT, USA.</location>
<contexts>
<context position="1245" citStr="Thelen and Riloff, 2002" startWordPosition="186" endWordPosition="189">how that we are able to create a large collection of semantic predicates from the Oxford Advanced Learner’s Dictionary with high precision and recall, and perform well against the most similar approach. 1 Introduction Acquiring semantic knowledge from text automatically is a long-standing issue in Computational Linguistics and Artificial Intelligence. Over the last decade or so the enormous abundance of information and data that has become available has made it possible to extract huge amounts of patterns and named entities (Etzioni et al., 2005), semantic lexicons for categories of interest (Thelen and Riloff, 2002; Igo and Riloff, 2009), large domain glossaries (De Benedictis et al., 2013) and lists of concepts (Katz et al., 2003). Recently, the availability of Wikipedia and other collaborative resources has considerably boosted research on several aspects of knowledge acquisition (Hovy et al., 2013), leading to the creation of several large-scale knowledge resources, such as DBPedia (Bizer et al., 2009), BabelNet (Navigli and Ponzetto, 2012), YAGO (Hoffart et al., 2013), MENTA (de Melo and Weikum, 2010), to name but a few. This wealth of acquired knowledge is known to have a positive impact on importa</context>
</contexts>
<marker>Thelen, Riloff, 2002</marker>
<rawString>M. Thelen and E. Riloff. 2002. A Bootstrapping Method for Learning Semantic Lexicons using Extraction Pattern Contexts. In Proc. of EMNLP, pages 214–221, Salt Lake City, UT, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Velardi</author>
<author>Stefano Faralli</author>
<author>Roberto Navigli</author>
</authors>
<title>OntoLearn Reloaded: A graph-based algorithm for taxonomy induction.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>3</issue>
<contexts>
<context position="2351" citStr="Velardi et al., 2013" startWordPosition="357" endWordPosition="360">d Weikum, 2010), to name but a few. This wealth of acquired knowledge is known to have a positive impact on important fields such as Information Retrieval (Chu-Carroll and Prager, 2007), Information Extraction (Krause et al., 2012), Question Answering (Ferrucci et al., 2010) and Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-structured text using ontology learning from scratch (Velardi et al., 2013) and Open Information Extraction techniques (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Fader et al., 2011; Moro and Navigli, 2013) which mainly stem from seminal work on is-a relation acquisition (Hearst, 1992) and subsequent developments (Girju et al., 2003; Pasca, 2004; Snow et al., 2004, among others). However, these knowledge resources still lack semantic information about language units such as phrases and collocations. For instance, which semantic classes are expected as a direct object of the verb break? What kinds of noun does the adjective amazing collocate with? Re</context>
<context position="15955" citStr="Velardi et al., 2013" startWordPosition="2701" endWordPosition="2704">et.org 4We follow (Navigli, 2009) and denote with w&apos; the i-th sense of w in WordNet with part of speech p. 5According to the Wikipedia guidelines, “The article should begin with a short declarative sentence, answering two questions for the nonspecialist reader: What (or who) is the subject? and Why is this subject notable?”, extracted from http://en.wikipedia.org/wiki/ we extract the hypernym from the textual definition of p by applying Word-Class Lattices (Navigli and Velardi, 2010, WCL6), a domain-independent hypernym extraction system successfully applied to taxonomy learning from scratch (Velardi et al., 2013) and freely available online (Faralli and Navigli, 2013). If a hypernym h is successfully extracted and h is linked to a Wikipedia page p&apos; for which µ(p&apos;) is defined, then we extend the mapping by setting µ(p) := µ(p&apos;). For instance, the mapping provided by BabelNet does not provide any link for the page Peter Spence; thanks to WCL, though, we are able to set the page Journalist as its hypernym, and link it to the WordNet synset journalists. This way our mapping extension now covers 539,954 pages, i.e., more than an order of magnitude greater than the number of pages originally covered by the </context>
</contexts>
<marker>Velardi, Faralli, Navigli, 2013</marker>
<rawString>Paola Velardi, Stefano Faralli, and Roberto Navigli. 2013. OntoLearn Reloaded: A graph-based algorithm for taxonomy induction. Computational Linguistics, 39(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick Wilks</author>
</authors>
<title>A preferential, pattern-seeking, semantics for natural language inference.</title>
<date>1975</date>
<journal>Artificial Intelligence,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="3130" citStr="Wilks, 1975" startWordPosition="483" endWordPosition="484"> from seminal work on is-a relation acquisition (Hearst, 1992) and subsequent developments (Girju et al., 2003; Pasca, 2004; Snow et al., 2004, among others). However, these knowledge resources still lack semantic information about language units such as phrases and collocations. For instance, which semantic classes are expected as a direct object of the verb break? What kinds of noun does the adjective amazing collocate with? Recognition of the need for systems that are aware of the selectional restrictions of verbs and, more in general, of textual expressions, dates back to several decades (Wilks, 1975), but today it is more relevant than ever, as is testified by the current interest in semantic class learning (Kozareva et al., 2008) and supertype acquisition (Kozareva and Hovy, 2010). These approaches leverage lexico-syntactic patterns and input seeds to recursively learn the semantic classes of relation arguments. However, they require the manual selection of one or more seeds for each pattern of interest, and this selection influences the amount and kind of semantic classes to be learned. Furthermore, the learned classes are not directly linked to existing resources such as WordNet (Fellb</context>
</contexts>
<marker>Wilks, 1975</marker>
<rawString>Yorick Wilks. 1975. A preferential, pattern-seeking, semantics for natural language inference. Artificial Intelligence, 6(1):53–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Daniel S Weld</author>
</authors>
<title>Open Information Extraction Using Wikipedia. In</title>
<date>2010</date>
<booktitle>Proc. ofACL,</booktitle>
<pages>118--127</pages>
<location>Uppsala,</location>
<contexts>
<context position="2455" citStr="Wu and Weld, 2010" startWordPosition="374" endWordPosition="377">important fields such as Information Retrieval (Chu-Carroll and Prager, 2007), Information Extraction (Krause et al., 2012), Question Answering (Ferrucci et al., 2010) and Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-structured text using ontology learning from scratch (Velardi et al., 2013) and Open Information Extraction techniques (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Fader et al., 2011; Moro and Navigli, 2013) which mainly stem from seminal work on is-a relation acquisition (Hearst, 1992) and subsequent developments (Girju et al., 2003; Pasca, 2004; Snow et al., 2004, among others). However, these knowledge resources still lack semantic information about language units such as phrases and collocations. For instance, which semantic classes are expected as a direct object of the verb break? What kinds of noun does the adjective amazing collocate with? Recognition of the need for systems that are aware of the selectional restrictions of verbs and, more in g</context>
<context position="33256" citStr="Wu and Weld, 2010" startWordPosition="5677" endWordPosition="5680">Number of args Number of classes cause * 181,401 1,339 live in * 143,628 600 go to * 134,712 867 * cause 92,160 1,244 work in * 79,444 770 * go to 71,794 746 * live in 61,074 541 work on * 58,760 840 work for * 58,332 681 work at * 31,904 511 * work in 24,933 528 * celebrate 23,333 408 Table 7: Number of arguments and associated classes for the 12 most frequent lexical predicates of Kozareva and Hovy (2010) extracted by SPred from Wikipedia. 6 Related work The availability of Web-scale corpora has led to the production of large resources of relations (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Carlson et al., 2010; Fader et al., 2011). However, these resources often operate purely at the lexical level, providing no information on the semantics of their arguments or relations. Several studies have examined adding semantics through grouping relations into sets (Yates and Etzioni, 2009), ontologizing the arguments (Chklovski and Pantel, 2004), or ontologizing the relations themselves (Moro and Navigli, 2013). However, analysis has largely been either limited to ontologizing a small number of relation types with a fixed inventory, which potentially limits coverage, or has used implici</context>
</contexts>
<marker>Wu, Weld, 2010</marker>
<rawString>Fei Wu and Daniel S. Weld. 2010. Open Information Extraction Using Wikipedia. In Proc. ofACL, pages 118–127, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akane Yakushiji</author>
<author>Yusuke Miyao</author>
<author>Tomoko Ohta</author>
<author>Yuka Tateisi</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Automatic construction of predicate-argument structure patterns for biomedical information extraction.</title>
<date>2006</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>284--292</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="36066" citStr="Yakushiji et al., 2006" startWordPosition="6099" endWordPosition="6102">stow, 2012) in order to obtain higher coverage of preferences. In contrast, we overcome the data sparsity of class-based models by leveraging the large quantity of collaboratively-annotated Wikipedia text in order to connect predicate arguments with their semantic class in WordNet using BabelNet (Navigli and Ponzetto, 2012); because we map directly to WordNet synsets, we provide a more readilyinterpretable collocation preference model than most similarity-based or probabilistic models. Verb frame extraction (Green et al., 2004) and predicate-argument structure analysis (Surdeanu et al., 2003; Yakushiji et al., 2006) are two areas that are also related to our work. But their generality goes beyond our intentions, as we focus on semantic predicates, which is much simpler and free from syntactic parsing. Another closely related work is that of Hanks (2013) concerning the Theory of Norms and Exploitations, where norms (exploitations) represent expected (unexpected) classes for a given lexical predicate. Although our semantified predicates do, indeed, provide explicit evidence of norms obtained from collective intelligence and would provide support for this theory, exploitations present a more difficult task,</context>
</contexts>
<marker>Yakushiji, Miyao, Ohta, Tateisi, Tsujii, 2006</marker>
<rawString>Akane Yakushiji, Yusuke Miyao, Tomoko Ohta, Yuka Tateisi, and Jun’ichi Tsujii. 2006. Automatic construction of predicate-argument structure patterns for biomedical information extraction. In Proc. of EMNLP, pages 284–292, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised Word Sense Disambiguation Rivaling Supervised Methods.</title>
<date>1995</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>189--196</pages>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="10374" citStr="Yarowsky, 1995" startWordPosition="1760" endWordPosition="1761">agate an existing annotation of a in the same Wikipedia page and apply it to our ambiguous item. For instance, cup of coffee appears in the Wikipedia page Energy drink in the sentence “[... ] energy drinks contain more caffeine than a strong cup of coffee”, but this occurrence of coffee is not linked. However the second paragraph contains the sentence “[[Coffee]], tea and other naturally caffeinated beverages are usually not considered energy drinks”, where coffee is linked to the Coffee page. This heuristic naturally reflects the broadly known assumption about lexical ambiguity presented in (Yarowsky, 1995), namely the one-sense-per-discourse heuristic. • One sense per lexical predicate: if ∃(a, s&apos;, l) ∈ Dπ, then remove (a, s, c) from Uπ and add (a, s, l) to Dπ. If multiple senses of a are available, choose the most frequent one in Dπ. For example, in the page Singaporean cuisine the occurrence of coffee in the sentence “[... ] combined with a cup of coffee and a half-boiled egg” is not linked, but we have collected many other occurrences, all linked to the Coffee page, so this link gets propagated to our ambiguous item as well. This heuristic mimes the one-sense-percollocation heuristic present</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>David Yarowsky. 1995. Unsupervised Word Sense Disambiguation Rivaling Supervised Methods. In Proc. of ACL, pages 189–196, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yates</author>
<author>Oren Etzioni</author>
</authors>
<title>Unsupervised methods for determining object and relation synonyms on the web.</title>
<date>2009</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="33553" citStr="Yates and Etzioni, 2009" startWordPosition="5721" endWordPosition="5724">le 7: Number of arguments and associated classes for the 12 most frequent lexical predicates of Kozareva and Hovy (2010) extracted by SPred from Wikipedia. 6 Related work The availability of Web-scale corpora has led to the production of large resources of relations (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Carlson et al., 2010; Fader et al., 2011). However, these resources often operate purely at the lexical level, providing no information on the semantics of their arguments or relations. Several studies have examined adding semantics through grouping relations into sets (Yates and Etzioni, 2009), ontologizing the arguments (Chklovski and Pantel, 2004), or ontologizing the relations themselves (Moro and Navigli, 2013). However, analysis has largely been either limited to ontologizing a small number of relation types with a fixed inventory, which potentially limits coverage, or has used implicit definitions of semantic categories (e.g., clusters of arguments), which limits interpretability. For example, Mohamed et al. (2011) use the semantic categories of the NELL system (Carlson et al., 2010) to learn roughly 400 valid ontologized relations from over 200M web pages, whereas WiSeNet (M</context>
</contexts>
<marker>Yates, Etzioni, 2009</marker>
<rawString>Alexander Yates and Oren Etzioni. 2009. Unsupervised methods for determining object and relation synonyms on the web. Journal of Artificial Intelligence Research, 34(1):255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yates</author>
<author>Michael Cafarella</author>
<author>Michele Banko</author>
<author>Oren Etzioni</author>
<author>Matthew Broadhead</author>
<author>Stephen Soderland</author>
</authors>
<title>TextRunner: open information extraction on the web.</title>
<date>2007</date>
<booktitle>In Proc. of NAACLDemonstrations,</booktitle>
<pages>25--26</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2436" citStr="Yates et al., 2007" startWordPosition="370" endWordPosition="373"> positive impact on important fields such as Information Retrieval (Chu-Carroll and Prager, 2007), Information Extraction (Krause et al., 2012), Question Answering (Ferrucci et al., 2010) and Textual Entailment (Berant et al., 2012; Stern and Dagan, 2012). Not only are these knowledge resources obtained by acquiring concepts and named entities, but they also provide semantic relations between them. These relations are extracted from unstructured or semi-structured text using ontology learning from scratch (Velardi et al., 2013) and Open Information Extraction techniques (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Fader et al., 2011; Moro and Navigli, 2013) which mainly stem from seminal work on is-a relation acquisition (Hearst, 1992) and subsequent developments (Girju et al., 2003; Pasca, 2004; Snow et al., 2004, among others). However, these knowledge resources still lack semantic information about language units such as phrases and collocations. For instance, which semantic classes are expected as a direct object of the verb break? What kinds of noun does the adjective amazing collocate with? Recognition of the need for systems that are aware of the selectional restrictions of v</context>
<context position="33237" citStr="Yates et al., 2007" startWordPosition="5673" endWordPosition="5676"> classes. Predicate Number of args Number of classes cause * 181,401 1,339 live in * 143,628 600 go to * 134,712 867 * cause 92,160 1,244 work in * 79,444 770 * go to 71,794 746 * live in 61,074 541 work on * 58,760 840 work for * 58,332 681 work at * 31,904 511 * work in 24,933 528 * celebrate 23,333 408 Table 7: Number of arguments and associated classes for the 12 most frequent lexical predicates of Kozareva and Hovy (2010) extracted by SPred from Wikipedia. 6 Related work The availability of Web-scale corpora has led to the production of large resources of relations (Etzioni et al., 2005; Yates et al., 2007; Wu and Weld, 2010; Carlson et al., 2010; Fader et al., 2011). However, these resources often operate purely at the lexical level, providing no information on the semantics of their arguments or relations. Several studies have examined adding semantics through grouping relations into sets (Yates and Etzioni, 2009), ontologizing the arguments (Chklovski and Pantel, 2004), or ontologizing the relations themselves (Moro and Navigli, 2013). However, analysis has largely been either limited to ontologizing a small number of relation types with a fixed inventory, which potentially limits coverage, </context>
</contexts>
<marker>Yates, Cafarella, Banko, Etzioni, Broadhead, Soderland, 2007</marker>
<rawString>Alexander Yates, Michael Cafarella, Michele Banko, Oren Etzioni, Matthew Broadhead, and Stephen Soderland. 2007. TextRunner: open information extraction on the web. In Proc. of NAACLDemonstrations, pages 25–26, Stroudsburg, PA, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>