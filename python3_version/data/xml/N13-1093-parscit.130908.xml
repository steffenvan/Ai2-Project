<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000936">
<title confidence="0.998832">
Exploiting the Scope of Negations and Heterogeneous Features
for Relation Extraction: A Case Study for Drug-Drug Interaction Extraction
</title>
<author confidence="0.705927">
Md. Faisal Mahbub Chowdhury t t and Alberto Lavelli �
</author>
<affiliation confidence="0.8150945">
� Fondazione Bruno Kessler (FBK-irst), Italy
t University of Trento, Italy
</affiliation>
<email confidence="0.9966">
fmchowdhury@gmail.com, lavelli@fbk.eu
</email>
<sectionHeader confidence="0.995617" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998361">
This paper presents an approach that exploits
the scope of negation cues for relation extrac-
tion (RE) without the need of using any specif-
ically annotated dataset for building a separate
negation scope detection classifier. New fea-
tures are proposed which are used in two dif-
ferent stages. These also include non-target
entity specific features. The proposed RE ap-
proach outperforms the previous state of the
art for drug-drug interaction (DDI) extraction.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999939571428571">
Negation is a linguistic phenomenon where a nega-
tion cue (e.g. not) can alter the meaning of a partic-
ular text segment or of a fact. This text segment (or
fact) is said to be inside the scope of that negation
(cue). In the context of RE, there is not much work
that aims to exploit the scope of negations.1 The
only work on RE that we are aware of is Sanchez-
Graillet and Poesio (2007) where they used various
heuristics to extract negative protein interaction.
Despite the recent interest on automatically de-
tecting the scope of negation2 till now there seems
to be no empirical evidence supporting its exploita-
tion for the purpose of RE. Even if we could man-
age to obtain highly accurate automatically detected
</bodyText>
<footnote confidence="0.99258025">
1In the context of event extraction (a closely related task of
RE), there have been efforts in BioNLP shared tasks of 2009 and
2011 for (non-mandatory sub-task of) event negation detection
(3 participants in 2009; 2 in 2011) (Kim et al., 2009; Kim et al.,
2011). The participants approached the sub-task using either
pre-defined patterns or some heuristics.
2This task is popularized by various recently held shared
tasks (Farkas et al., 2010; Morante and Blanco, 2012).
</footnote>
<bodyText confidence="0.999837583333334">
negation scopes, it is not clear how to feed this infor-
mation inside the RE approach. Simply considering
whether a pair of candidate mentions falls under the
scope of a negation cue might not be helpful.
In this paper, we propose that the scope of nega-
tions can be exploited at two different levels. Firstly,
the system would check whether all the target en-
tity3 mentions inside a sentence along with possible
relation clues (or trigger words), if any, fall (directly
or indirectly) under the scope of a negation cue. If
such a sentence is found, then it should be discarded
(i.e. candidate mention pairs4 inside that sentence
would not be considered). Secondly, for each of the
remaining pairs of candidate mentions, the system
should exploit features related to the scope of nega-
tion (rather than simply adding a feature for negation
cue, approach adopted in various RE systems) that
can provide indication (if any such evidence exists)
that the corresponding relation of interest actually
does not hold in that particular context.
In the subsequent sections, we describe our ap-
proach. The RE task considered is drug-drug in-
teraction (DDI) extraction. The task has signifi-
cant importance for public health safety.5 We used
</bodyText>
<footnote confidence="0.98343325">
3The target entities, for example, for DDI extraction and for
EMP-ORG relation extraction would be {DRUG} and {PER,
GPE, ORG} respectively. Any entity other than the target enti-
ties (w.r.t. the particular RE task) belongs to non-target entities.
4Candidate mention pairs for RE are taken from target entity
mentions.
5After the death of pop star Michael Jackson, allegedly due
to DDI, it was reported that about 2.2 million people in USA,
age 57 to 85, were taking potentially dangerous combinations of
drugs (Landau, 2009). An earlier report mentioned that deaths
from accidental drug interactions rose 68 percent between 1999
and 2004 (Payne, 2007).
</footnote>
<page confidence="0.984652">
765
</page>
<subsectionHeader confidence="0.291271">
Proceedings of NAACL-HLT 2013, pages 765–771,
</subsectionHeader>
<bodyText confidence="0.939494333333333">
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
the DDIExtraction-2011 challenge corpus (Segura-
Bedmar et al., 2011). The official training and test
data of the corpus contain 4,267 and 1,539 sen-
tences, and 2,402 and 755 DDI annotations respec-
tively.
</bodyText>
<sectionHeader confidence="0.970896" genericHeader="method">
2 Proposed Approach
</sectionHeader>
<subsectionHeader confidence="0.929782">
2.1 Stage 1: Exploiting scope of negation to
filter out sentences
</subsectionHeader>
<bodyText confidence="0.9993164">
We propose a two stage RE approach. In the first
stage, our goal is to exploit the scope of negations
to reduce the number of candidate mention pairs by
discarding sentences. For this purpose, we propose
the following features to train a binary classifier:
</bodyText>
<listItem confidence="0.999516085714286">
• has2TM: If the sentence has exactly 2 target entity
mentions (i.e. drug mentions for DDI extraction).
• has3OrMoreTM: Whether the sentence has more
than 2 target entity mentions.
• allTMonRight: Whether all target entity mentions
inside the sentence appear after the negation cue.
• neitherAllTMonLeftOrRight: Whether some but not
all target entity mentions appear after the negation
cue.
• negCue: The negation cue itself.
• immediateGovernor: The word on which the cue is
directly syntactically dependent.
• nearestVerbGovernor: The nearest verb in the de-
pendency graph on which the cue is syntactically
dependent.
• isVerbGovernorRoot: Whether the nearestVerb-
Governor is root of the dependency graph of the
sentence.
• allTMdependentOnNVG: Whether all target en-
tity mentions are syntactically dependent (di-
rectly/indirectly) on the nearestVerbGovernor.
• allButOneTMdependentOnNVG: Whether all but
one target entity mentions are syntactically depen-
dent on the nearestVerbGovernor.
• although*PrecedeCue: Whether the syntactic
clause containing the negation cue begins with “al-
though / though / despite / in spite”.
• commaBeforeNextTM: Whether there is a comma in
the text between the negation cue and the next target
entity mention after the cue.
• commaAfterPrevTM: Whether there is a comma in
the text between the previous target entity mention
before the negation cue and the cue itself.
• sentHasBut: Whether the sentence contains the
word “but”.
</listItem>
<bodyText confidence="0.999554888888889">
The objective of the classifier is to decide whether
all of the target entity mentions (i.e. drugs) as well as
any possible evidence of the relation of interest (for
which we assume the immediate and the nearest verb
governors of the negation cue would be good candi-
dates) inside the corresponding sentence fall under
the scope of a negation cue in such a way that the
sentence is unlikely to contain a DDI.
At present, we limit our focus only on the first
occurrence of the following negation cues: “no”,
“n’t” or “not”.6 In the Stage 1, any sentence that
contains at least one DDI is considered by the clas-
sifier as a positive (training/test) instance. Other sen-
tences are considered as negative instances. We rule
out any sentence (i.e. we do not consider as train-
ing/test instance for the classifier that filters less in-
formative sentences) during both training and testing
if any of the following conditions holds:
</bodyText>
<listItem confidence="0.999004625">
• The sentence contains less than two target entity
mentions (such sentence would not contain the re-
lation of interest anyway).
• It has any of the following phrases – “not recom-
mended”, “should not be” or “must not be”.7
• There is no “no”, “n’t” or “not” in the sentence.
• No target entity mention appears in the sentence af-
ter “no”, “n’t” or “not”.
</listItem>
<bodyText confidence="0.997035333333333">
To assess the effectiveness of the proposed Stage
1 classifier, we defined a baseline classifier that fil-
ters any sentence that contains “no”, “n’t” or “not”.
</bodyText>
<subsectionHeader confidence="0.995599">
2.2 Stage 2
</subsectionHeader>
<bodyText confidence="0.999973333333333">
Once the sentences which are likely to have no DDI
are identified and removed, the next step is to ap-
ply a state-of-the-art RE approach on the remaining
sentences. In this section, we propose a new hybrid
kernel, KHybrid, for this purpose. It is defined as
follows:
</bodyText>
<equation confidence="0.9806175">
KHybrid (R1, R2) = KHF (R1, R2) + KSL
(R1, R2) + w * KPET (R1, R2)
</equation>
<footnote confidence="0.978832">
6These cues usually occur more frequently and generally
have larger negation scope than other negation cues.
7These expressions often provide clues that one of the bio-
entity mentions negatively influences the level of activity of the
other.
</footnote>
<page confidence="0.996439">
766
</page>
<bodyText confidence="0.999966875">
Here, KHF stands for a new feature based kernel
(proposed in this paper) that uses a heterogeneous
set of features. KSL stands for the Shallow Linguis-
tic (SL) kernel proposed by Giuliano et al. (2006).
KPET stands for the Path-enclosed Tree (PET) ker-
nel (Moschitti, 2004). w is a multiplicative constant
used for the PET kernel. It allows the hybrid kernel
to assign more (or less) weight to the information
obtained using tree structures depending on the cor-
pus.
The proposed kernel composition is valid accord-
ing to the closure properties of kernels. We ex-
ploit the SVM-Light-TK toolkit (Moschitti, 2006;
Joachims, 1999) for kernel computation. In Stage
2, each candidate drug mention pair represents an
instance.
</bodyText>
<subsubsectionHeader confidence="0.916619">
2.2.1 Proposed KHF kernel
</subsubsectionHeader>
<bodyText confidence="0.999864428571429">
As mentioned earlier, this proposed kernel uses
heterogeneous features. The first version of the het-
erogeneous feature set (henceforth, HF v1) com-
bines features proposed by two previous RE works.
The former is Zhou et al. (2005), which uses 51 dif-
ferent features. We select the following 27 of their
features for our feature set:
</bodyText>
<construct confidence="0.9993085">
WBNULL, WBFL, WBF, WBL, WBO,
BM1F, BM1L, AM2F, AM2L, #MB, #WB,
CPHBNULL, CPHBFL, CPHBF, CPHBL,
CPHBO, CPHBM1F, CPHBM1L, CPHAM2F,
CPHAM2F, CPP, CPPH, ET12SameNP,
ET12SamePP, ET12SameVP, PTP, PTPH
</construct>
<bodyText confidence="0.746383">
The latter is the TPWF kernel (Chowdhury and
Lavelli, 2012a) from which we use following fea-
tures:
</bodyText>
<construct confidence="0.7111355">
HasTriggerWord, Trigger-X, DepPattern-i, e-
walk, v-walk
</construct>
<bodyText confidence="0.999968956521739">
The TPWF kernel extracts the HasTriggerWord,
Trigger-X and DepPattern-i features from a sub-
graph called reduced graph. We also follow this ap-
proach with one minor difference. Unlike Chowd-
hury and Lavelli (2012a), we look for trigger words
in the whole reduced graph instead of using only the
root of the sub-graph.
Due to space limitation we refer the readers to
the corresponding papers for the description of the
above mentioned features and the definition of re-
duced graph.
In addition, HF v1 also includes surrounding to-
kens within the window of {-2,+2} for each candi-
date mention. We are unaware of any available list
of trigger words for drug-drug interaction. So, we
created such a list.$
We extend the heterogeneous feature set by
adding features related to the scope of negation
(henceforth, HF v2). We use a list of 13 negation
cues9 to search inside the reduced graph of a candi-
date pair. If the reduced graph contains any of the
negation cues or their morphological variants then
we add the following features:
</bodyText>
<listItem confidence="0.892867">
• negCue: The corresponding negation cue.
• immediateNegatedWord: If the word following the
negation cue is neither a preposition nor a “be verb”,
then that word, otherwise the word after the next
word.10
</listItem>
<bodyText confidence="0.991997">
Furthermore, if the corresponding matched nega-
tion cue is either “no”, “n’t” or “not”, then we add
additional features related to negation scope:
</bodyText>
<listItem confidence="0.9905592">
• bothEntDependOnImmediateGovernor: Whether
the immediate governor (if any) of the negation cue
is also governor of a dependency sub-tree (of the de-
pendency graph of the corresponding sentence) that
includes both of the candidate mentions.
• immediateGovernorIsVerbGovernor: Whether the
immediate governor of the negation cue is a verb.
• nearestVerbGovernor: The closest verb governor
(i.e. parent or grandparent inside the dependency
graph), if any, of the negation cue.
</listItem>
<bodyText confidence="0.9999701">
We further extend the heterogeneous feature set
by adding features related to relevant non-target en-
tities (with respect to the relation of interest; hence-
forth, HF v3). For the purpose of DDI extrac-
tion, we deem the presence of DISEASE mentions
(which might result as a consequence of a DDI)
can provide some clues. So, we use a publicly
available state-of-the-art disease NER system called
BioEnEx (Chowdhury and Lavelli, 2010) to anno-
tate the DDIExtraction-2011 challenge corpus. For
</bodyText>
<tableCaption confidence="0.369180285714286">
$The RE system developed for this work and the cre-
ated list of trigger words for DDI can be downloaded from
https://github.com/fmchowdhury/HyREX .
9No, not, neither, without, lack, fail, unable, abrogate, ab-
sence, prevent, unlikely, unchanged, rarely.
10For example, “interested” from “... not interested ...”, and
“confused” from “... not to be confused ...”.
</tableCaption>
<page confidence="0.983967">
767
</page>
<bodyText confidence="0.8345305">
each candidate (drug) mention pair, we add the fol-
lowing features in HF v3:
</bodyText>
<listItem confidence="0.968375">
• NTEMinsideSentence: Whether the corresponding
sentence contains important non-target entity men-
tion(s) (e.g. disease for DDI).
• immediateGovernorIsVerbGovernorOfNTEM: The
immediate governor (if any) of the non-target entity
mention, only if such governor is also governing a
dependency sub-tree that includes both of the target
candidate entity mentions.
• nearestVerbGovernorOfNTEM: The closest verb
governor (if any) of the non-target entity mention,
only if it also governs the candidate entity mentions.
• immediateGovernorIsVerbGovernorOfNTEM:
Whether the immediate governor is a verb.
</listItem>
<sectionHeader confidence="0.99896" genericHeader="evaluation">
3 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999926673076923">
We train a linear SVM classifier in Stage 1 and
tune the hyper-parameters (by doing 5-fold cross-
validation) for obtaining maximum possible recall.
In this way we minimize the number of false neg-
atives (i.e. sentences that contain DDIs but are
wrongly identified as not having any).
During the cross-validation experiments on the
training data, 334 sentences (7.83% of the total sen-
tences) containing at least 2 drug mentions were
identified by our proposed classifier (in Section 2.1)
as unlikely to have any DDI and hence are candi-
dates for discarding. Only 19 of these sentences
were incorrectly identified. When we trained on
the training data and tested on the official test data
of DDIExtraction-2011 challenge corpus, 121 sen-
tences (7.86% of the total test sentences) were iden-
tified by the classifier as candidates for discarding.
Only 5 of them were incorrectly identified.
Unlike Stage 1, in Stage 2 where we train the hy-
brid kernel based RE classifier and use it for RE (i.e.
DDI extraction) from the test data, sentences are not
the RE training/test instances. Instead, a RE instance
corresponds to a candidate mention pair.
All the DDIs (i.e. positive RE instances) of the
incorrectly identified sentences in Stage 1 (i.e. the
sentences which are incorrectly labelled as not hav-
ing any DDI and filtered) are automatically consid-
ered as false negatives during the calculation of DDI
extraction results in Stage 2.
To verify whether our proposed hybrid kernel
achieves state-of-the-art results without taking ben-
efits of the output of Stage 1, we did some experi-
ments without discarding any sentence. These ex-
periments are done using Zhou et al. (2005), TPWF
kernel, SL kernel, different versions of proposed
KHF kernel and KHybrid kernel. Table 1 shows
the results of 5-fold cross-validation experiments
(hyper-parameters are tuned for obtaining maximum
F-score). As the results show, there is a gain +0.9
points in F-score (mainly due to the boost in re-
call) after the addition of features related to negation
scope. There is also some minor improvement due
to the proposed non-target entity specific features.
We also performed (5-fold cross validation) ex-
periments by combining the Stage 1 classifier with
each of the Zhou et al. (2005), TPWF kernel, SL
kernel, PET kernel, KHF kernel and KHybrid kernel
separately (only the results of KHybrid are reported
in Table 1 due to space limitation). In each case,
there were improvements in precision, recall and F-
score. The gain in F-score ranged from 1.0 to 1.4
points.
</bodyText>
<table confidence="0.997077545454545">
P / R / F-score
Using SL kernel (Giuliano et al., 2006) 51.3 / 64.7 / 57.3
Using (Zhou et al., 2005) 58.7 / 37.1 / 45.5
Using PET kernel (Moschitti, 2004) 46.8 / 602 / 52.7
TPWF (Chowdhury and Lavelli, 2012a) 43.7 / 60.7 / 50.8
Proposed approaches
Proposed KHF v1 53.4 / 51.5 / 52.4
KHF v2 (i.e. + neg scope feat.) 53.9 / 52.6 / 53.3 (+0.9)
KHF v3 (i.e. + non-target entity feat.) 53.6 / 53.5 / 53.6 (+0.3)
Proposed KHybrid 56.3 / 68.5 / 61.8
Proposed KHybrid with Stage 1 57.3 / 69.4 / 62.8 (+1.0)
</table>
<tableCaption confidence="0.999947">
Table 1: 5-fold cross-validation results on training data.
</tableCaption>
<bodyText confidence="0.972369777777778">
Table 2 reports the results of the previously pub-
lished studies that used the same corpus. Our pro-
posed KHybrid kernel obtains an F-score that is
higher than that of the previous state of the art.
When the Stage 1 classifier (based on negation
scope features) is exploited before using the KHybrid
kernel, the F-score reaches up to 67.4. This is
+1.0 points higher than without exploiting the Stage
1 classifier and +1.7 higher than previous state of
</bodyText>
<page confidence="0.993591">
768
</page>
<bodyText confidence="0.9999667">
the art. We did separate experiments (also reported
in Table 2) to assess the performance improvement
when the output of Stage 1 is used to filter sentences
from either training or test data only. The results
remain the same when only training sentences are
filtered; while there are some improvements when
only test sentences are filtered. Filtering both train-
ing and test sentences provides the larger gain which
is statistically significant.
Usually, the number of negative instances in a
corpus is much higher than that of the positive in-
stances. In a recent work, Chowdhury and Lavelli
(2012b) showed that by removing less informative
(negative) instances (henceforth, LIIs), not only the
skewness in instance distribution could be reduced
but it also leads to a better result. The proposed
Stage 1 classifier, presented in this work, also re-
duces skewness in instance distribution. This is be-
cause we are only removing those sentences that are
unlikely to contain any positive instance. So, in prin-
ciple, the Stage 1 classifier is focused on removing
only negative instances (although the classifier mis-
takenly discards few positive instances, too).
We wanted to study how the Stage 1 classifier
would contribute if we use it on top of the tech-
niques that were proposed in Chowdhury and Lavelli
(2012b) to remove LIIs. As Table 2 shows, by using
the Stage 1 classifier along with LLI filtering, we
could further improve the results (+3.2 points differ-
ence in F-score with the previous state of the art).
</bodyText>
<sectionHeader confidence="0.996536" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999886625">
A major flexibility in the proposed approach is that
it does not require a separate dataset (which needs
to match the genre of the text to be used for RE)
annotated with negation scopes. Instead, the pro-
posed Stage 1 classifier uses the RE training data
(which do not have negation scope annotations) to
self-supervise itself. Various new features have been
exploited (both in stages 1 and 2) that can provide
strong indications of the scope of negation cues with
respect to the relation to be extracted. The only thing
needed is the list of possible negation cues (Morante
(2010) includes such a comprehensive list).
Our proposed kernel, which has a component that
exploits a heterogeneous set of features including
negation scope and presence of non-target entities,
already obtains better results than previous studies.
</bodyText>
<table confidence="0.9787914375">
P R F-score
(Thomas et al., 2011) 60.5 71.9 65.7
(Chowdhury et al., 2011) 58.6 70.5 64.0
(Chowdhury and Lavelli, 2011) 58.4 70.1 63.7
(Bjorne et al., 2011) 58.0 68.9 63.0
Proposed KHybrid 60.0 74.3 66.4
KHybrid + Stage 1 baseline 61.8 68.9 65.1
KHybrid + proposed Stage 1 60.0 74.2 66.4
(only training sentences are filtered)
KHybrid + proposed Stage 1 61.4 73.8 67.0
(only test sentences are filtered)
KHybrid + proposed Stage 1 62.1 73.8 67.4 stat. sig.
(both training and test sentences are filtered)
Proposed KHybrid + LII filtering 61.1 75.1 67.4 stat. sig.
Proposed KHybrid + LII filtering 63.5 75.2 68.9 stat. sig.
+ proposed Stage 1
</table>
<tableCaption confidence="0.839614333333333">
Table 2: Results obtained on the official test set of the
2011 DDI Extraction challenge. LII filtering refers to the
techniques proposed in Chowdhury and Lavelli (2012b)
</tableCaption>
<bodyText confidence="0.988080642857143">
for reducing skewness in RE data distribution. stat. sig. in-
dicates that the improvement of F-score, due to usage of
Stage 1 classifier, is statistically significant (verified using
Approximate Randomization Procedure (Noreen, 1989);
number of iterations = 1,000, confidence level = 0.01).
The results considerably improve when possible ir-
relevant sentences from both training and test data
are filtered by exploiting features related to the scope
of negations.
In future, we would like to exploit the scope of
more negation cues, apart from the three cues that
are used in this study. We believe our approach
would help to improve RE in other genres of text
(such as newspaper) as well.
</bodyText>
<sectionHeader confidence="0.953284" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.993428666666667">
This work was carried out in the context of the
project “eOnco - Pervasive knowledge and data
management in cancer care”.
</bodyText>
<sectionHeader confidence="0.998953" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9957948">
J Bjorne, A Airola, T Pahikkala, and T Salakoski. 2011.
Drug-drug interaction extraction with RLS and SVM
classifiers. In Proceedings of the 1st Challenge task
on Drug-Drug Interaction Extraction (DDIExtraction
2011), pages 35–42, Huelva, Spain, September.
</reference>
<page confidence="0.991667">
769
</page>
<reference confidence="0.997046579439252">
MFM Chowdhury and A Lavelli. 2010. Disease mention
recognition with specific features. In Proceedings of
the 2010 Workshop on Biomedical Natural Language
Processing, pages 83–90, Uppsala, Sweden, July. As-
sociation for Computational Linguistics.
MFM Chowdhury and A Lavelli. 2011. Drug-drug inter-
action extraction using composite kernels. In Proceed-
ings of the 1st Challenge task on Drug-Drug Interac-
tion Extraction (DDIExtraction 2011), pages 27–33,
Huelva, Spain, September.
MFM Chowdhury and A Lavelli. 2012a. Combining tree
structures, flat features and patterns for biomedical re-
lation extraction. In Proceedings of the 13th Confer-
ence of the European Chapter of the Association for
Computational Linguistics (EACL 2012), pages 420–
429, Avignon, France, April. Association for Compu-
tational Linguistics.
MFM Chowdhury and A Lavelli. 2012b. Impact of Less
Skewed Distributions on Efficiency and Effectiveness
of Biomedical Relation Extraction. In Proceedings of
the 24th International Conference on Computational
Linguistics (COLING 2012) : Posters, pages 205–216,
Mumbai, India, December.
MFM Chowdhury, AB Abacha, A Lavelli, and
P Zweigenbaum. 2011. Two different machine learn-
ing techniques for drug-drug interaction extraction. In
Proceedings of the 1st Challenge task on Drug-Drug
Interaction Extraction (DDIExtraction 2011), pages
19–26, Huelva, Spain, September.
R Farkas, V Vincze, G M´ora, J Csirik, and G Szarvas.
2010. The CoNLL-2010 shared task: Learning to de-
tect hedges and their scope in natural language text.
In Proceedings of the Fourteenth Conference on Com-
putational Natural Language Learning, pages 1–12,
Uppsala, Sweden, July. Association for Computational
Linguistics.
C Giuliano, A Lavelli, and L Romano. 2006. Exploit-
ing shallow linguistic information for relation extrac-
tion from biomedical literature. In Proceedings of the
11th Conference of the European Chapter of the As-
sociation for Computational Linguistics (EACL 2006),
pages 401–408.
T Joachims. 1999. Making large-scale support vec-
tor machine learning practical. In Advances in ker-
nel methods: support vector learning, pages 169–184.
MIT Press, Cambridge, MA, USA.
JD Kim, T Ohta, S Pyysalo, Y Kano, and J Tsujii. 2009.
Overview of BioNLP’09 shared task on event extrac-
tion. In Proceedings of the BioNLP 2009 Workshop
Companion Volume for Shared Task, pages 1–9, Boul-
der, Colorado, June. Association for Computational
Linguistics.
JD Kim, Y Wang, T Takagi, and A Yonezawa. 2011.
Overview of Genia event task in BioNLP shared task
2011. In Proceedings of BioNLP Shared Task 2011
Workshop, pages 7–15, Portland, Oregon, USA, June.
Association for Computational Linguistics.
E Landau. 2009. Jackson’s death raises questions about
drug interactions [Published in CNN; June 26, 2009].
http://articles.cnn.com/2009-06-
26/health/jackson.drug.interaction.
caution_1_drug-interactions-heart-
rhythms-antidepressants?_s=PM:
HEALTH.
R Morante and E Blanco. 2012. *SEM 2012 shared task:
Resolving the scope and focus of negation. In *SEM
2012: The First Joint Conference on Lexical and Com-
putational Semantics – Volume 1: Proceedings of the
main conference and the shared task, and Volume 2:
Proceedings of the Sixth International Workshop on
Semantic Evaluation (SemEval 2012), pages 265–274,
Montr´eal, Canada, 7-8 June. Association for Compu-
tational Linguistics.
R Morante. 2010. Descriptive Analysis of Negation
Cue in Biomedical Texts. In Proceedings of the 7th
International Conference on Language Resources and
Evaluation (LREC 2010), Malta.
A Moschitti. 2004. A study on convolution kernels for
shallow semantic parsing. In Proceedings of the 42nd
Annual Meeting of the Association for Computational
Linguistics (ACL 2004), Barcelona, Spain.
A Moschitti. 2006. Making Tree Kernels Practical
for Natural Language Learning. In Proceedings of
11th Conference of the European Chapter of the As-
sociation for computational Linguistics (EACL 2006),
Trento, Italy.
EW Noreen. 1989. Computer-Intensive Methods
for Testing Hypotheses : An Introduction. Wiley-
Interscience, April.
JW Payne. 2007. A Dangerous Mix [Published
in The Washington Post; February 27, 2007].
http://www.washingtonpost.com/wp-
dyn/content/article/2007/02/23/
AR2007022301780.html.
O Sanchez-Graillet and M Poesio. 2007. Negation of
protein-protein interactions: analysis and extraction.
Bioinformatics, 23(13):i424–i432.
I Segura-Bedmar, P Martinez, and CD Pablo-S´anchez.
2011. The 1st DDIExtraction-2011 challenge task:
Extraction of Drug-Drug Interactions from biomedi-
cal texts. In Proceedings of the 1st Challenge task
on Drug-Drug Interaction Extraction (DDIExtraction
2011), pages 1–9, Huelva, Spain, September.
P Thomas, M Neves, I Solt, D Tikk, and U Leser.
2011. Relation extraction for drug-drug interactions
using ensemble learning. In Proceedings of the 1st
Challenge task on Drug-Drug Interaction Extraction
</reference>
<page confidence="0.961985">
770
</page>
<reference confidence="0.997800285714286">
(DDIExtraction 2011), pages 11–18, Huelva, Spain,
September.
GD Zhou, J Su, J Zhang, and M Zhang. 2005. Ex-
ploring various knowledge in relation extraction. In
Proceedings of the 43rd Annual Meeting on Associa-
tion for Computational Linguistics (ACL 2005), pages
427–434, Ann Arbor, Michigan, USA.
</reference>
<page confidence="0.997951">
771
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.788635">
<title confidence="0.9998845">Exploiting the Scope of Negations and Heterogeneous for Relation Extraction: A Case Study for Drug-Drug Interaction Extraction</title>
<author confidence="0.9095945">Faisal Mahbub Chowdhury t Alberto Lavelli Bruno Kessler</author>
<affiliation confidence="0.982205">of Trento,</affiliation>
<email confidence="0.997897">fmchowdhury@gmail.com,lavelli@fbk.eu</email>
<abstract confidence="0.998164181818182">This paper presents an approach that exploits the scope of negation cues for relation extraction (RE) without the need of using any specifically annotated dataset for building a separate negation scope detection classifier. New features are proposed which are used in two different stages. These also include non-target entity specific features. The proposed RE approach outperforms the previous state of the art for drug-drug interaction (DDI) extraction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Bjorne</author>
<author>A Airola</author>
<author>T Pahikkala</author>
<author>T Salakoski</author>
</authors>
<title>Drug-drug interaction extraction with RLS and SVM classifiers.</title>
<date>2011</date>
<booktitle>In Proceedings of the 1st Challenge task on Drug-Drug Interaction Extraction (DDIExtraction 2011),</booktitle>
<pages>35--42</pages>
<location>Huelva, Spain,</location>
<contexts>
<context position="18860" citStr="Bjorne et al., 2011" startWordPosition="3074" endWordPosition="3077">exploited (both in stages 1 and 2) that can provide strong indications of the scope of negation cues with respect to the relation to be extracted. The only thing needed is the list of possible negation cues (Morante (2010) includes such a comprehensive list). Our proposed kernel, which has a component that exploits a heterogeneous set of features including negation scope and presence of non-target entities, already obtains better results than previous studies. P R F-score (Thomas et al., 2011) 60.5 71.9 65.7 (Chowdhury et al., 2011) 58.6 70.5 64.0 (Chowdhury and Lavelli, 2011) 58.4 70.1 63.7 (Bjorne et al., 2011) 58.0 68.9 63.0 Proposed KHybrid 60.0 74.3 66.4 KHybrid + Stage 1 baseline 61.8 68.9 65.1 KHybrid + proposed Stage 1 60.0 74.2 66.4 (only training sentences are filtered) KHybrid + proposed Stage 1 61.4 73.8 67.0 (only test sentences are filtered) KHybrid + proposed Stage 1 62.1 73.8 67.4 stat. sig. (both training and test sentences are filtered) Proposed KHybrid + LII filtering 61.1 75.1 67.4 stat. sig. Proposed KHybrid + LII filtering 63.5 75.2 68.9 stat. sig. + proposed Stage 1 Table 2: Results obtained on the official test set of the 2011 DDI Extraction challenge. LII filtering refers to t</context>
</contexts>
<marker>Bjorne, Airola, Pahikkala, Salakoski, 2011</marker>
<rawString>J Bjorne, A Airola, T Pahikkala, and T Salakoski. 2011. Drug-drug interaction extraction with RLS and SVM classifiers. In Proceedings of the 1st Challenge task on Drug-Drug Interaction Extraction (DDIExtraction 2011), pages 35–42, Huelva, Spain, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MFM Chowdhury</author>
<author>A Lavelli</author>
</authors>
<title>Disease mention recognition with specific features.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Workshop on Biomedical Natural Language Processing,</booktitle>
<pages>83--90</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="11698" citStr="Chowdhury and Lavelli, 2010" startWordPosition="1897" endWordPosition="1900"> Whether the immediate governor of the negation cue is a verb. • nearestVerbGovernor: The closest verb governor (i.e. parent or grandparent inside the dependency graph), if any, of the negation cue. We further extend the heterogeneous feature set by adding features related to relevant non-target entities (with respect to the relation of interest; henceforth, HF v3). For the purpose of DDI extraction, we deem the presence of DISEASE mentions (which might result as a consequence of a DDI) can provide some clues. So, we use a publicly available state-of-the-art disease NER system called BioEnEx (Chowdhury and Lavelli, 2010) to annotate the DDIExtraction-2011 challenge corpus. For $The RE system developed for this work and the created list of trigger words for DDI can be downloaded from https://github.com/fmchowdhury/HyREX . 9No, not, neither, without, lack, fail, unable, abrogate, absence, prevent, unlikely, unchanged, rarely. 10For example, “interested” from “... not interested ...”, and “confused” from “... not to be confused ...”. 767 each candidate (drug) mention pair, we add the following features in HF v3: • NTEMinsideSentence: Whether the corresponding sentence contains important non-target entity mention</context>
</contexts>
<marker>Chowdhury, Lavelli, 2010</marker>
<rawString>MFM Chowdhury and A Lavelli. 2010. Disease mention recognition with specific features. In Proceedings of the 2010 Workshop on Biomedical Natural Language Processing, pages 83–90, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MFM Chowdhury</author>
<author>A Lavelli</author>
</authors>
<title>Drug-drug interaction extraction using composite kernels.</title>
<date>2011</date>
<booktitle>In Proceedings of the 1st Challenge task on Drug-Drug Interaction Extraction (DDIExtraction 2011),</booktitle>
<pages>27--33</pages>
<location>Huelva, Spain,</location>
<contexts>
<context position="18823" citStr="Chowdhury and Lavelli, 2011" startWordPosition="3067" endWordPosition="3070">rvise itself. Various new features have been exploited (both in stages 1 and 2) that can provide strong indications of the scope of negation cues with respect to the relation to be extracted. The only thing needed is the list of possible negation cues (Morante (2010) includes such a comprehensive list). Our proposed kernel, which has a component that exploits a heterogeneous set of features including negation scope and presence of non-target entities, already obtains better results than previous studies. P R F-score (Thomas et al., 2011) 60.5 71.9 65.7 (Chowdhury et al., 2011) 58.6 70.5 64.0 (Chowdhury and Lavelli, 2011) 58.4 70.1 63.7 (Bjorne et al., 2011) 58.0 68.9 63.0 Proposed KHybrid 60.0 74.3 66.4 KHybrid + Stage 1 baseline 61.8 68.9 65.1 KHybrid + proposed Stage 1 60.0 74.2 66.4 (only training sentences are filtered) KHybrid + proposed Stage 1 61.4 73.8 67.0 (only test sentences are filtered) KHybrid + proposed Stage 1 62.1 73.8 67.4 stat. sig. (both training and test sentences are filtered) Proposed KHybrid + LII filtering 61.1 75.1 67.4 stat. sig. Proposed KHybrid + LII filtering 63.5 75.2 68.9 stat. sig. + proposed Stage 1 Table 2: Results obtained on the official test set of the 2011 DDI Extraction</context>
</contexts>
<marker>Chowdhury, Lavelli, 2011</marker>
<rawString>MFM Chowdhury and A Lavelli. 2011. Drug-drug interaction extraction using composite kernels. In Proceedings of the 1st Challenge task on Drug-Drug Interaction Extraction (DDIExtraction 2011), pages 27–33, Huelva, Spain, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MFM Chowdhury</author>
<author>A Lavelli</author>
</authors>
<title>Combining tree structures, flat features and patterns for biomedical relation extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2012),</booktitle>
<pages>420--429</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Avignon, France,</location>
<contexts>
<context position="9326" citStr="Chowdhury and Lavelli, 2012" startWordPosition="1516" endWordPosition="1519">ents an instance. 2.2.1 Proposed KHF kernel As mentioned earlier, this proposed kernel uses heterogeneous features. The first version of the heterogeneous feature set (henceforth, HF v1) combines features proposed by two previous RE works. The former is Zhou et al. (2005), which uses 51 different features. We select the following 27 of their features for our feature set: WBNULL, WBFL, WBF, WBL, WBO, BM1F, BM1L, AM2F, AM2L, #MB, #WB, CPHBNULL, CPHBFL, CPHBF, CPHBL, CPHBO, CPHBM1F, CPHBM1L, CPHAM2F, CPHAM2F, CPP, CPPH, ET12SameNP, ET12SamePP, ET12SameVP, PTP, PTPH The latter is the TPWF kernel (Chowdhury and Lavelli, 2012a) from which we use following features: HasTriggerWord, Trigger-X, DepPattern-i, ewalk, v-walk The TPWF kernel extracts the HasTriggerWord, Trigger-X and DepPattern-i features from a subgraph called reduced graph. We also follow this approach with one minor difference. Unlike Chowdhury and Lavelli (2012a), we look for trigger words in the whole reduced graph instead of using only the root of the sub-graph. Due to space limitation we refer the readers to the corresponding papers for the description of the above mentioned features and the definition of reduced graph. In addition, HF v1 also inc</context>
<context position="15552" citStr="Chowdhury and Lavelli, 2012" startWordPosition="2514" endWordPosition="2517">fic features. We also performed (5-fold cross validation) experiments by combining the Stage 1 classifier with each of the Zhou et al. (2005), TPWF kernel, SL kernel, PET kernel, KHF kernel and KHybrid kernel separately (only the results of KHybrid are reported in Table 1 due to space limitation). In each case, there were improvements in precision, recall and Fscore. The gain in F-score ranged from 1.0 to 1.4 points. P / R / F-score Using SL kernel (Giuliano et al., 2006) 51.3 / 64.7 / 57.3 Using (Zhou et al., 2005) 58.7 / 37.1 / 45.5 Using PET kernel (Moschitti, 2004) 46.8 / 602 / 52.7 TPWF (Chowdhury and Lavelli, 2012a) 43.7 / 60.7 / 50.8 Proposed approaches Proposed KHF v1 53.4 / 51.5 / 52.4 KHF v2 (i.e. + neg scope feat.) 53.9 / 52.6 / 53.3 (+0.9) KHF v3 (i.e. + non-target entity feat.) 53.6 / 53.5 / 53.6 (+0.3) Proposed KHybrid 56.3 / 68.5 / 61.8 Proposed KHybrid with Stage 1 57.3 / 69.4 / 62.8 (+1.0) Table 1: 5-fold cross-validation results on training data. Table 2 reports the results of the previously published studies that used the same corpus. Our proposed KHybrid kernel obtains an F-score that is higher than that of the previous state of the art. When the Stage 1 classifier (based on negation scop</context>
<context position="16955" citStr="Chowdhury and Lavelli (2012" startWordPosition="2758" endWordPosition="2761">her than previous state of 768 the art. We did separate experiments (also reported in Table 2) to assess the performance improvement when the output of Stage 1 is used to filter sentences from either training or test data only. The results remain the same when only training sentences are filtered; while there are some improvements when only test sentences are filtered. Filtering both training and test sentences provides the larger gain which is statistically significant. Usually, the number of negative instances in a corpus is much higher than that of the positive instances. In a recent work, Chowdhury and Lavelli (2012b) showed that by removing less informative (negative) instances (henceforth, LIIs), not only the skewness in instance distribution could be reduced but it also leads to a better result. The proposed Stage 1 classifier, presented in this work, also reduces skewness in instance distribution. This is because we are only removing those sentences that are unlikely to contain any positive instance. So, in principle, the Stage 1 classifier is focused on removing only negative instances (although the classifier mistakenly discards few positive instances, too). We wanted to study how the Stage 1 class</context>
<context position="19513" citStr="Chowdhury and Lavelli (2012" startWordPosition="3184" endWordPosition="3187">Hybrid 60.0 74.3 66.4 KHybrid + Stage 1 baseline 61.8 68.9 65.1 KHybrid + proposed Stage 1 60.0 74.2 66.4 (only training sentences are filtered) KHybrid + proposed Stage 1 61.4 73.8 67.0 (only test sentences are filtered) KHybrid + proposed Stage 1 62.1 73.8 67.4 stat. sig. (both training and test sentences are filtered) Proposed KHybrid + LII filtering 61.1 75.1 67.4 stat. sig. Proposed KHybrid + LII filtering 63.5 75.2 68.9 stat. sig. + proposed Stage 1 Table 2: Results obtained on the official test set of the 2011 DDI Extraction challenge. LII filtering refers to the techniques proposed in Chowdhury and Lavelli (2012b) for reducing skewness in RE data distribution. stat. sig. indicates that the improvement of F-score, due to usage of Stage 1 classifier, is statistically significant (verified using Approximate Randomization Procedure (Noreen, 1989); number of iterations = 1,000, confidence level = 0.01). The results considerably improve when possible irrelevant sentences from both training and test data are filtered by exploiting features related to the scope of negations. In future, we would like to exploit the scope of more negation cues, apart from the three cues that are used in this study. We believe </context>
</contexts>
<marker>Chowdhury, Lavelli, 2012</marker>
<rawString>MFM Chowdhury and A Lavelli. 2012a. Combining tree structures, flat features and patterns for biomedical relation extraction. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2012), pages 420– 429, Avignon, France, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MFM Chowdhury</author>
<author>A Lavelli</author>
</authors>
<title>Impact of Less Skewed Distributions on Efficiency and Effectiveness of Biomedical Relation Extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 24th International Conference on Computational Linguistics (COLING 2012) : Posters,</booktitle>
<pages>205--216</pages>
<location>Mumbai, India,</location>
<contexts>
<context position="9326" citStr="Chowdhury and Lavelli, 2012" startWordPosition="1516" endWordPosition="1519">ents an instance. 2.2.1 Proposed KHF kernel As mentioned earlier, this proposed kernel uses heterogeneous features. The first version of the heterogeneous feature set (henceforth, HF v1) combines features proposed by two previous RE works. The former is Zhou et al. (2005), which uses 51 different features. We select the following 27 of their features for our feature set: WBNULL, WBFL, WBF, WBL, WBO, BM1F, BM1L, AM2F, AM2L, #MB, #WB, CPHBNULL, CPHBFL, CPHBF, CPHBL, CPHBO, CPHBM1F, CPHBM1L, CPHAM2F, CPHAM2F, CPP, CPPH, ET12SameNP, ET12SamePP, ET12SameVP, PTP, PTPH The latter is the TPWF kernel (Chowdhury and Lavelli, 2012a) from which we use following features: HasTriggerWord, Trigger-X, DepPattern-i, ewalk, v-walk The TPWF kernel extracts the HasTriggerWord, Trigger-X and DepPattern-i features from a subgraph called reduced graph. We also follow this approach with one minor difference. Unlike Chowdhury and Lavelli (2012a), we look for trigger words in the whole reduced graph instead of using only the root of the sub-graph. Due to space limitation we refer the readers to the corresponding papers for the description of the above mentioned features and the definition of reduced graph. In addition, HF v1 also inc</context>
<context position="15552" citStr="Chowdhury and Lavelli, 2012" startWordPosition="2514" endWordPosition="2517">fic features. We also performed (5-fold cross validation) experiments by combining the Stage 1 classifier with each of the Zhou et al. (2005), TPWF kernel, SL kernel, PET kernel, KHF kernel and KHybrid kernel separately (only the results of KHybrid are reported in Table 1 due to space limitation). In each case, there were improvements in precision, recall and Fscore. The gain in F-score ranged from 1.0 to 1.4 points. P / R / F-score Using SL kernel (Giuliano et al., 2006) 51.3 / 64.7 / 57.3 Using (Zhou et al., 2005) 58.7 / 37.1 / 45.5 Using PET kernel (Moschitti, 2004) 46.8 / 602 / 52.7 TPWF (Chowdhury and Lavelli, 2012a) 43.7 / 60.7 / 50.8 Proposed approaches Proposed KHF v1 53.4 / 51.5 / 52.4 KHF v2 (i.e. + neg scope feat.) 53.9 / 52.6 / 53.3 (+0.9) KHF v3 (i.e. + non-target entity feat.) 53.6 / 53.5 / 53.6 (+0.3) Proposed KHybrid 56.3 / 68.5 / 61.8 Proposed KHybrid with Stage 1 57.3 / 69.4 / 62.8 (+1.0) Table 1: 5-fold cross-validation results on training data. Table 2 reports the results of the previously published studies that used the same corpus. Our proposed KHybrid kernel obtains an F-score that is higher than that of the previous state of the art. When the Stage 1 classifier (based on negation scop</context>
<context position="16955" citStr="Chowdhury and Lavelli (2012" startWordPosition="2758" endWordPosition="2761">her than previous state of 768 the art. We did separate experiments (also reported in Table 2) to assess the performance improvement when the output of Stage 1 is used to filter sentences from either training or test data only. The results remain the same when only training sentences are filtered; while there are some improvements when only test sentences are filtered. Filtering both training and test sentences provides the larger gain which is statistically significant. Usually, the number of negative instances in a corpus is much higher than that of the positive instances. In a recent work, Chowdhury and Lavelli (2012b) showed that by removing less informative (negative) instances (henceforth, LIIs), not only the skewness in instance distribution could be reduced but it also leads to a better result. The proposed Stage 1 classifier, presented in this work, also reduces skewness in instance distribution. This is because we are only removing those sentences that are unlikely to contain any positive instance. So, in principle, the Stage 1 classifier is focused on removing only negative instances (although the classifier mistakenly discards few positive instances, too). We wanted to study how the Stage 1 class</context>
<context position="19513" citStr="Chowdhury and Lavelli (2012" startWordPosition="3184" endWordPosition="3187">Hybrid 60.0 74.3 66.4 KHybrid + Stage 1 baseline 61.8 68.9 65.1 KHybrid + proposed Stage 1 60.0 74.2 66.4 (only training sentences are filtered) KHybrid + proposed Stage 1 61.4 73.8 67.0 (only test sentences are filtered) KHybrid + proposed Stage 1 62.1 73.8 67.4 stat. sig. (both training and test sentences are filtered) Proposed KHybrid + LII filtering 61.1 75.1 67.4 stat. sig. Proposed KHybrid + LII filtering 63.5 75.2 68.9 stat. sig. + proposed Stage 1 Table 2: Results obtained on the official test set of the 2011 DDI Extraction challenge. LII filtering refers to the techniques proposed in Chowdhury and Lavelli (2012b) for reducing skewness in RE data distribution. stat. sig. indicates that the improvement of F-score, due to usage of Stage 1 classifier, is statistically significant (verified using Approximate Randomization Procedure (Noreen, 1989); number of iterations = 1,000, confidence level = 0.01). The results considerably improve when possible irrelevant sentences from both training and test data are filtered by exploiting features related to the scope of negations. In future, we would like to exploit the scope of more negation cues, apart from the three cues that are used in this study. We believe </context>
</contexts>
<marker>Chowdhury, Lavelli, 2012</marker>
<rawString>MFM Chowdhury and A Lavelli. 2012b. Impact of Less Skewed Distributions on Efficiency and Effectiveness of Biomedical Relation Extraction. In Proceedings of the 24th International Conference on Computational Linguistics (COLING 2012) : Posters, pages 205–216, Mumbai, India, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MFM Chowdhury</author>
<author>AB Abacha</author>
<author>A Lavelli</author>
<author>P Zweigenbaum</author>
</authors>
<title>Two different machine learning techniques for drug-drug interaction extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the 1st Challenge task on Drug-Drug Interaction Extraction (DDIExtraction 2011),</booktitle>
<pages>pages</pages>
<location>Huelva, Spain,</location>
<contexts>
<context position="18778" citStr="Chowdhury et al., 2011" startWordPosition="3060" endWordPosition="3063">negation scope annotations) to self-supervise itself. Various new features have been exploited (both in stages 1 and 2) that can provide strong indications of the scope of negation cues with respect to the relation to be extracted. The only thing needed is the list of possible negation cues (Morante (2010) includes such a comprehensive list). Our proposed kernel, which has a component that exploits a heterogeneous set of features including negation scope and presence of non-target entities, already obtains better results than previous studies. P R F-score (Thomas et al., 2011) 60.5 71.9 65.7 (Chowdhury et al., 2011) 58.6 70.5 64.0 (Chowdhury and Lavelli, 2011) 58.4 70.1 63.7 (Bjorne et al., 2011) 58.0 68.9 63.0 Proposed KHybrid 60.0 74.3 66.4 KHybrid + Stage 1 baseline 61.8 68.9 65.1 KHybrid + proposed Stage 1 60.0 74.2 66.4 (only training sentences are filtered) KHybrid + proposed Stage 1 61.4 73.8 67.0 (only test sentences are filtered) KHybrid + proposed Stage 1 62.1 73.8 67.4 stat. sig. (both training and test sentences are filtered) Proposed KHybrid + LII filtering 61.1 75.1 67.4 stat. sig. Proposed KHybrid + LII filtering 63.5 75.2 68.9 stat. sig. + proposed Stage 1 Table 2: Results obtained on the</context>
</contexts>
<marker>Chowdhury, Abacha, Lavelli, Zweigenbaum, 2011</marker>
<rawString>MFM Chowdhury, AB Abacha, A Lavelli, and P Zweigenbaum. 2011. Two different machine learning techniques for drug-drug interaction extraction. In Proceedings of the 1st Challenge task on Drug-Drug Interaction Extraction (DDIExtraction 2011), pages 19–26, Huelva, Spain, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Farkas</author>
<author>V Vincze</author>
<author>G M´ora</author>
<author>J Csirik</author>
<author>G Szarvas</author>
</authors>
<title>The CoNLL-2010 shared task: Learning to detect hedges and their scope in natural language text.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>1--12</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<marker>Farkas, Vincze, M´ora, Csirik, Szarvas, 2010</marker>
<rawString>R Farkas, V Vincze, G M´ora, J Csirik, and G Szarvas. 2010. The CoNLL-2010 shared task: Learning to detect hedges and their scope in natural language text. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 1–12, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Giuliano</author>
<author>A Lavelli</author>
<author>L Romano</author>
</authors>
<title>Exploiting shallow linguistic information for relation extraction from biomedical literature.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL</booktitle>
<pages>401--408</pages>
<contexts>
<context position="8201" citStr="Giuliano et al. (2006)" startWordPosition="1338" endWordPosition="1341">tences. In this section, we propose a new hybrid kernel, KHybrid, for this purpose. It is defined as follows: KHybrid (R1, R2) = KHF (R1, R2) + KSL (R1, R2) + w * KPET (R1, R2) 6These cues usually occur more frequently and generally have larger negation scope than other negation cues. 7These expressions often provide clues that one of the bioentity mentions negatively influences the level of activity of the other. 766 Here, KHF stands for a new feature based kernel (proposed in this paper) that uses a heterogeneous set of features. KSL stands for the Shallow Linguistic (SL) kernel proposed by Giuliano et al. (2006). KPET stands for the Path-enclosed Tree (PET) kernel (Moschitti, 2004). w is a multiplicative constant used for the PET kernel. It allows the hybrid kernel to assign more (or less) weight to the information obtained using tree structures depending on the corpus. The proposed kernel composition is valid according to the closure properties of kernels. We exploit the SVM-Light-TK toolkit (Moschitti, 2006; Joachims, 1999) for kernel computation. In Stage 2, each candidate drug mention pair represents an instance. 2.2.1 Proposed KHF kernel As mentioned earlier, this proposed kernel uses heterogene</context>
<context position="15401" citStr="Giuliano et al., 2006" startWordPosition="2484" endWordPosition="2487">recall) after the addition of features related to negation scope. There is also some minor improvement due to the proposed non-target entity specific features. We also performed (5-fold cross validation) experiments by combining the Stage 1 classifier with each of the Zhou et al. (2005), TPWF kernel, SL kernel, PET kernel, KHF kernel and KHybrid kernel separately (only the results of KHybrid are reported in Table 1 due to space limitation). In each case, there were improvements in precision, recall and Fscore. The gain in F-score ranged from 1.0 to 1.4 points. P / R / F-score Using SL kernel (Giuliano et al., 2006) 51.3 / 64.7 / 57.3 Using (Zhou et al., 2005) 58.7 / 37.1 / 45.5 Using PET kernel (Moschitti, 2004) 46.8 / 602 / 52.7 TPWF (Chowdhury and Lavelli, 2012a) 43.7 / 60.7 / 50.8 Proposed approaches Proposed KHF v1 53.4 / 51.5 / 52.4 KHF v2 (i.e. + neg scope feat.) 53.9 / 52.6 / 53.3 (+0.9) KHF v3 (i.e. + non-target entity feat.) 53.6 / 53.5 / 53.6 (+0.3) Proposed KHybrid 56.3 / 68.5 / 61.8 Proposed KHybrid with Stage 1 57.3 / 69.4 / 62.8 (+1.0) Table 1: 5-fold cross-validation results on training data. Table 2 reports the results of the previously published studies that used the same corpus. Our pr</context>
</contexts>
<marker>Giuliano, Lavelli, Romano, 2006</marker>
<rawString>C Giuliano, A Lavelli, and L Romano. 2006. Exploiting shallow linguistic information for relation extraction from biomedical literature. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2006), pages 401–408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Making large-scale support vector machine learning practical.</title>
<date>1999</date>
<booktitle>In Advances in kernel methods: support vector learning,</booktitle>
<pages>169--184</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="8623" citStr="Joachims, 1999" startWordPosition="1408" endWordPosition="1409">HF stands for a new feature based kernel (proposed in this paper) that uses a heterogeneous set of features. KSL stands for the Shallow Linguistic (SL) kernel proposed by Giuliano et al. (2006). KPET stands for the Path-enclosed Tree (PET) kernel (Moschitti, 2004). w is a multiplicative constant used for the PET kernel. It allows the hybrid kernel to assign more (or less) weight to the information obtained using tree structures depending on the corpus. The proposed kernel composition is valid according to the closure properties of kernels. We exploit the SVM-Light-TK toolkit (Moschitti, 2006; Joachims, 1999) for kernel computation. In Stage 2, each candidate drug mention pair represents an instance. 2.2.1 Proposed KHF kernel As mentioned earlier, this proposed kernel uses heterogeneous features. The first version of the heterogeneous feature set (henceforth, HF v1) combines features proposed by two previous RE works. The former is Zhou et al. (2005), which uses 51 different features. We select the following 27 of their features for our feature set: WBNULL, WBFL, WBF, WBL, WBO, BM1F, BM1L, AM2F, AM2L, #MB, #WB, CPHBNULL, CPHBFL, CPHBF, CPHBL, CPHBO, CPHBM1F, CPHBM1L, CPHAM2F, CPHAM2F, CPP, CPPH, E</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>T Joachims. 1999. Making large-scale support vector machine learning practical. In Advances in kernel methods: support vector learning, pages 169–184. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JD Kim</author>
<author>T Ohta</author>
<author>S Pyysalo</author>
<author>Y Kano</author>
<author>J Tsujii</author>
</authors>
<title>Overview of BioNLP’09 shared task on event extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task,</booktitle>
<pages>1--9</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado,</location>
<contexts>
<context position="1738" citStr="Kim et al., 2009" startWordPosition="282" endWordPosition="285"> aware of is SanchezGraillet and Poesio (2007) where they used various heuristics to extract negative protein interaction. Despite the recent interest on automatically detecting the scope of negation2 till now there seems to be no empirical evidence supporting its exploitation for the purpose of RE. Even if we could manage to obtain highly accurate automatically detected 1In the context of event extraction (a closely related task of RE), there have been efforts in BioNLP shared tasks of 2009 and 2011 for (non-mandatory sub-task of) event negation detection (3 participants in 2009; 2 in 2011) (Kim et al., 2009; Kim et al., 2011). The participants approached the sub-task using either pre-defined patterns or some heuristics. 2This task is popularized by various recently held shared tasks (Farkas et al., 2010; Morante and Blanco, 2012). negation scopes, it is not clear how to feed this information inside the RE approach. Simply considering whether a pair of candidate mentions falls under the scope of a negation cue might not be helpful. In this paper, we propose that the scope of negations can be exploited at two different levels. Firstly, the system would check whether all the target entity3 mentions</context>
</contexts>
<marker>Kim, Ohta, Pyysalo, Kano, Tsujii, 2009</marker>
<rawString>JD Kim, T Ohta, S Pyysalo, Y Kano, and J Tsujii. 2009. Overview of BioNLP’09 shared task on event extraction. In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task, pages 1–9, Boulder, Colorado, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JD Kim</author>
<author>Y Wang</author>
<author>T Takagi</author>
<author>A Yonezawa</author>
</authors>
<title>Overview of Genia event task in BioNLP shared task 2011.</title>
<date>2011</date>
<booktitle>In Proceedings of BioNLP Shared Task 2011 Workshop,</booktitle>
<pages>7--15</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="1757" citStr="Kim et al., 2011" startWordPosition="286" endWordPosition="289">ezGraillet and Poesio (2007) where they used various heuristics to extract negative protein interaction. Despite the recent interest on automatically detecting the scope of negation2 till now there seems to be no empirical evidence supporting its exploitation for the purpose of RE. Even if we could manage to obtain highly accurate automatically detected 1In the context of event extraction (a closely related task of RE), there have been efforts in BioNLP shared tasks of 2009 and 2011 for (non-mandatory sub-task of) event negation detection (3 participants in 2009; 2 in 2011) (Kim et al., 2009; Kim et al., 2011). The participants approached the sub-task using either pre-defined patterns or some heuristics. 2This task is popularized by various recently held shared tasks (Farkas et al., 2010; Morante and Blanco, 2012). negation scopes, it is not clear how to feed this information inside the RE approach. Simply considering whether a pair of candidate mentions falls under the scope of a negation cue might not be helpful. In this paper, we propose that the scope of negations can be exploited at two different levels. Firstly, the system would check whether all the target entity3 mentions inside a sentence </context>
</contexts>
<marker>Kim, Wang, Takagi, Yonezawa, 2011</marker>
<rawString>JD Kim, Y Wang, T Takagi, and A Yonezawa. 2011. Overview of Genia event task in BioNLP shared task 2011. In Proceedings of BioNLP Shared Task 2011 Workshop, pages 7–15, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Landau</author>
</authors>
<title>Jackson’s death raises questions about drug interactions [Published in CNN;</title>
<date>2009</date>
<publisher>HEALTH.</publisher>
<note>http://articles.cnn.com/2009-06-26/health/jackson.drug.interaction. rhythms-antidepressants?_s=PM:</note>
<contexts>
<context position="3715" citStr="Landau, 2009" startWordPosition="605" endWordPosition="606"> (DDI) extraction. The task has significant importance for public health safety.5 We used 3The target entities, for example, for DDI extraction and for EMP-ORG relation extraction would be {DRUG} and {PER, GPE, ORG} respectively. Any entity other than the target entities (w.r.t. the particular RE task) belongs to non-target entities. 4Candidate mention pairs for RE are taken from target entity mentions. 5After the death of pop star Michael Jackson, allegedly due to DDI, it was reported that about 2.2 million people in USA, age 57 to 85, were taking potentially dangerous combinations of drugs (Landau, 2009). An earlier report mentioned that deaths from accidental drug interactions rose 68 percent between 1999 and 2004 (Payne, 2007). 765 Proceedings of NAACL-HLT 2013, pages 765–771, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics the DDIExtraction-2011 challenge corpus (SeguraBedmar et al., 2011). The official training and test data of the corpus contain 4,267 and 1,539 sentences, and 2,402 and 755 DDI annotations respectively. 2 Proposed Approach 2.1 Stage 1: Exploiting scope of negation to filter out sentences We propose a two stage RE approach. In the first s</context>
</contexts>
<marker>Landau, 2009</marker>
<rawString>E Landau. 2009. Jackson’s death raises questions about drug interactions [Published in CNN; June 26, 2009]. http://articles.cnn.com/2009-06-26/health/jackson.drug.interaction. rhythms-antidepressants?_s=PM: HEALTH.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R Morante</author>
<author>E Blanco</author>
</authors>
<title>SEM 2012 shared task: Resolving the scope and focus of negation.</title>
<date>2012</date>
<booktitle>In *SEM 2012: The First Joint Conference on Lexical and Computational Semantics – Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>265--274</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal,</location>
<contexts>
<context position="1965" citStr="Morante and Blanco, 2012" startWordPosition="316" endWordPosition="319">ems to be no empirical evidence supporting its exploitation for the purpose of RE. Even if we could manage to obtain highly accurate automatically detected 1In the context of event extraction (a closely related task of RE), there have been efforts in BioNLP shared tasks of 2009 and 2011 for (non-mandatory sub-task of) event negation detection (3 participants in 2009; 2 in 2011) (Kim et al., 2009; Kim et al., 2011). The participants approached the sub-task using either pre-defined patterns or some heuristics. 2This task is popularized by various recently held shared tasks (Farkas et al., 2010; Morante and Blanco, 2012). negation scopes, it is not clear how to feed this information inside the RE approach. Simply considering whether a pair of candidate mentions falls under the scope of a negation cue might not be helpful. In this paper, we propose that the scope of negations can be exploited at two different levels. Firstly, the system would check whether all the target entity3 mentions inside a sentence along with possible relation clues (or trigger words), if any, fall (directly or indirectly) under the scope of a negation cue. If such a sentence is found, then it should be discarded (i.e. candidate mention</context>
</contexts>
<marker>Morante, Blanco, 2012</marker>
<rawString>R Morante and E Blanco. 2012. *SEM 2012 shared task: Resolving the scope and focus of negation. In *SEM 2012: The First Joint Conference on Lexical and Computational Semantics – Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval 2012), pages 265–274, Montr´eal, Canada, 7-8 June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Morante</author>
</authors>
<title>Descriptive Analysis of Negation Cue in Biomedical Texts.</title>
<date>2010</date>
<booktitle>In Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC</booktitle>
<contexts>
<context position="18462" citStr="Morante (2010)" startWordPosition="3014" endWordPosition="3015">s state of the art). 4 Conclusion A major flexibility in the proposed approach is that it does not require a separate dataset (which needs to match the genre of the text to be used for RE) annotated with negation scopes. Instead, the proposed Stage 1 classifier uses the RE training data (which do not have negation scope annotations) to self-supervise itself. Various new features have been exploited (both in stages 1 and 2) that can provide strong indications of the scope of negation cues with respect to the relation to be extracted. The only thing needed is the list of possible negation cues (Morante (2010) includes such a comprehensive list). Our proposed kernel, which has a component that exploits a heterogeneous set of features including negation scope and presence of non-target entities, already obtains better results than previous studies. P R F-score (Thomas et al., 2011) 60.5 71.9 65.7 (Chowdhury et al., 2011) 58.6 70.5 64.0 (Chowdhury and Lavelli, 2011) 58.4 70.1 63.7 (Bjorne et al., 2011) 58.0 68.9 63.0 Proposed KHybrid 60.0 74.3 66.4 KHybrid + Stage 1 baseline 61.8 68.9 65.1 KHybrid + proposed Stage 1 60.0 74.2 66.4 (only training sentences are filtered) KHybrid + proposed Stage 1 61.4</context>
</contexts>
<marker>Morante, 2010</marker>
<rawString>R Morante. 2010. Descriptive Analysis of Negation Cue in Biomedical Texts. In Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC 2010), Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Moschitti</author>
</authors>
<title>A study on convolution kernels for shallow semantic parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL 2004),</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="8272" citStr="Moschitti, 2004" startWordPosition="1351" endWordPosition="1352">rpose. It is defined as follows: KHybrid (R1, R2) = KHF (R1, R2) + KSL (R1, R2) + w * KPET (R1, R2) 6These cues usually occur more frequently and generally have larger negation scope than other negation cues. 7These expressions often provide clues that one of the bioentity mentions negatively influences the level of activity of the other. 766 Here, KHF stands for a new feature based kernel (proposed in this paper) that uses a heterogeneous set of features. KSL stands for the Shallow Linguistic (SL) kernel proposed by Giuliano et al. (2006). KPET stands for the Path-enclosed Tree (PET) kernel (Moschitti, 2004). w is a multiplicative constant used for the PET kernel. It allows the hybrid kernel to assign more (or less) weight to the information obtained using tree structures depending on the corpus. The proposed kernel composition is valid according to the closure properties of kernels. We exploit the SVM-Light-TK toolkit (Moschitti, 2006; Joachims, 1999) for kernel computation. In Stage 2, each candidate drug mention pair represents an instance. 2.2.1 Proposed KHF kernel As mentioned earlier, this proposed kernel uses heterogeneous features. The first version of the heterogeneous feature set (hence</context>
<context position="15500" citStr="Moschitti, 2004" startWordPosition="2506" endWordPosition="2507">e to the proposed non-target entity specific features. We also performed (5-fold cross validation) experiments by combining the Stage 1 classifier with each of the Zhou et al. (2005), TPWF kernel, SL kernel, PET kernel, KHF kernel and KHybrid kernel separately (only the results of KHybrid are reported in Table 1 due to space limitation). In each case, there were improvements in precision, recall and Fscore. The gain in F-score ranged from 1.0 to 1.4 points. P / R / F-score Using SL kernel (Giuliano et al., 2006) 51.3 / 64.7 / 57.3 Using (Zhou et al., 2005) 58.7 / 37.1 / 45.5 Using PET kernel (Moschitti, 2004) 46.8 / 602 / 52.7 TPWF (Chowdhury and Lavelli, 2012a) 43.7 / 60.7 / 50.8 Proposed approaches Proposed KHF v1 53.4 / 51.5 / 52.4 KHF v2 (i.e. + neg scope feat.) 53.9 / 52.6 / 53.3 (+0.9) KHF v3 (i.e. + non-target entity feat.) 53.6 / 53.5 / 53.6 (+0.3) Proposed KHybrid 56.3 / 68.5 / 61.8 Proposed KHybrid with Stage 1 57.3 / 69.4 / 62.8 (+1.0) Table 1: 5-fold cross-validation results on training data. Table 2 reports the results of the previously published studies that used the same corpus. Our proposed KHybrid kernel obtains an F-score that is higher than that of the previous state of the art.</context>
</contexts>
<marker>Moschitti, 2004</marker>
<rawString>A Moschitti. 2004. A study on convolution kernels for shallow semantic parsing. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL 2004), Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Moschitti</author>
</authors>
<title>Making Tree Kernels Practical for Natural Language Learning.</title>
<date>2006</date>
<booktitle>In Proceedings of 11th Conference of the European Chapter of the Association for computational Linguistics (EACL</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="8606" citStr="Moschitti, 2006" startWordPosition="1406" endWordPosition="1407">ther. 766 Here, KHF stands for a new feature based kernel (proposed in this paper) that uses a heterogeneous set of features. KSL stands for the Shallow Linguistic (SL) kernel proposed by Giuliano et al. (2006). KPET stands for the Path-enclosed Tree (PET) kernel (Moschitti, 2004). w is a multiplicative constant used for the PET kernel. It allows the hybrid kernel to assign more (or less) weight to the information obtained using tree structures depending on the corpus. The proposed kernel composition is valid according to the closure properties of kernels. We exploit the SVM-Light-TK toolkit (Moschitti, 2006; Joachims, 1999) for kernel computation. In Stage 2, each candidate drug mention pair represents an instance. 2.2.1 Proposed KHF kernel As mentioned earlier, this proposed kernel uses heterogeneous features. The first version of the heterogeneous feature set (henceforth, HF v1) combines features proposed by two previous RE works. The former is Zhou et al. (2005), which uses 51 different features. We select the following 27 of their features for our feature set: WBNULL, WBFL, WBF, WBL, WBO, BM1F, BM1L, AM2F, AM2L, #MB, #WB, CPHBNULL, CPHBFL, CPHBF, CPHBL, CPHBO, CPHBM1F, CPHBM1L, CPHAM2F, CPHA</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>A Moschitti. 2006. Making Tree Kernels Practical for Natural Language Learning. In Proceedings of 11th Conference of the European Chapter of the Association for computational Linguistics (EACL 2006), Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>EW Noreen</author>
</authors>
<title>Computer-Intensive Methods for Testing Hypotheses : An Introduction.</title>
<date>1989</date>
<location>WileyInterscience,</location>
<contexts>
<context position="19748" citStr="Noreen, 1989" startWordPosition="3219" endWordPosition="3220">62.1 73.8 67.4 stat. sig. (both training and test sentences are filtered) Proposed KHybrid + LII filtering 61.1 75.1 67.4 stat. sig. Proposed KHybrid + LII filtering 63.5 75.2 68.9 stat. sig. + proposed Stage 1 Table 2: Results obtained on the official test set of the 2011 DDI Extraction challenge. LII filtering refers to the techniques proposed in Chowdhury and Lavelli (2012b) for reducing skewness in RE data distribution. stat. sig. indicates that the improvement of F-score, due to usage of Stage 1 classifier, is statistically significant (verified using Approximate Randomization Procedure (Noreen, 1989); number of iterations = 1,000, confidence level = 0.01). The results considerably improve when possible irrelevant sentences from both training and test data are filtered by exploiting features related to the scope of negations. In future, we would like to exploit the scope of more negation cues, apart from the three cues that are used in this study. We believe our approach would help to improve RE in other genres of text (such as newspaper) as well. Acknowledgement This work was carried out in the context of the project “eOnco - Pervasive knowledge and data management in cancer care”. Refere</context>
</contexts>
<marker>Noreen, 1989</marker>
<rawString>EW Noreen. 1989. Computer-Intensive Methods for Testing Hypotheses : An Introduction. WileyInterscience, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JW Payne</author>
</authors>
<title>A Dangerous Mix [Published in The Washington Post;</title>
<date>2007</date>
<note>http://www.washingtonpost.com/wpdyn/content/article/2007/02/23/ AR2007022301780.html.</note>
<contexts>
<context position="3842" citStr="Payne, 2007" startWordPosition="624" endWordPosition="625"> DDI extraction and for EMP-ORG relation extraction would be {DRUG} and {PER, GPE, ORG} respectively. Any entity other than the target entities (w.r.t. the particular RE task) belongs to non-target entities. 4Candidate mention pairs for RE are taken from target entity mentions. 5After the death of pop star Michael Jackson, allegedly due to DDI, it was reported that about 2.2 million people in USA, age 57 to 85, were taking potentially dangerous combinations of drugs (Landau, 2009). An earlier report mentioned that deaths from accidental drug interactions rose 68 percent between 1999 and 2004 (Payne, 2007). 765 Proceedings of NAACL-HLT 2013, pages 765–771, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics the DDIExtraction-2011 challenge corpus (SeguraBedmar et al., 2011). The official training and test data of the corpus contain 4,267 and 1,539 sentences, and 2,402 and 755 DDI annotations respectively. 2 Proposed Approach 2.1 Stage 1: Exploiting scope of negation to filter out sentences We propose a two stage RE approach. In the first stage, our goal is to exploit the scope of negations to reduce the number of candidate mention pairs by discarding sentences. Fo</context>
</contexts>
<marker>Payne, 2007</marker>
<rawString>JW Payne. 2007. A Dangerous Mix [Published in The Washington Post; February 27, 2007]. http://www.washingtonpost.com/wpdyn/content/article/2007/02/23/ AR2007022301780.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Sanchez-Graillet</author>
<author>M Poesio</author>
</authors>
<title>Negation of protein-protein interactions: analysis and extraction.</title>
<date>2007</date>
<journal>Bioinformatics,</journal>
<volume>23</volume>
<issue>13</issue>
<marker>Sanchez-Graillet, Poesio, 2007</marker>
<rawString>O Sanchez-Graillet and M Poesio. 2007. Negation of protein-protein interactions: analysis and extraction. Bioinformatics, 23(13):i424–i432.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Segura-Bedmar</author>
<author>P Martinez</author>
<author>CD Pablo-S´anchez</author>
</authors>
<title>The 1st DDIExtraction-2011 challenge task: Extraction of Drug-Drug Interactions from biomedical texts.</title>
<date>2011</date>
<booktitle>In Proceedings of the 1st Challenge task on Drug-Drug Interaction Extraction (DDIExtraction</booktitle>
<pages>1--9</pages>
<location>Huelva, Spain,</location>
<marker>Segura-Bedmar, Martinez, Pablo-S´anchez, 2011</marker>
<rawString>I Segura-Bedmar, P Martinez, and CD Pablo-S´anchez. 2011. The 1st DDIExtraction-2011 challenge task: Extraction of Drug-Drug Interactions from biomedical texts. In Proceedings of the 1st Challenge task on Drug-Drug Interaction Extraction (DDIExtraction 2011), pages 1–9, Huelva, Spain, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Thomas</author>
<author>M Neves</author>
<author>I Solt</author>
<author>D Tikk</author>
<author>U Leser</author>
</authors>
<title>Relation extraction for drug-drug interactions using ensemble learning.</title>
<date>2011</date>
<booktitle>In Proceedings of the 1st Challenge task on Drug-Drug Interaction Extraction (DDIExtraction 2011),</booktitle>
<pages>11--18</pages>
<location>Huelva, Spain,</location>
<contexts>
<context position="18738" citStr="Thomas et al., 2011" startWordPosition="3053" endWordPosition="3056"> RE training data (which do not have negation scope annotations) to self-supervise itself. Various new features have been exploited (both in stages 1 and 2) that can provide strong indications of the scope of negation cues with respect to the relation to be extracted. The only thing needed is the list of possible negation cues (Morante (2010) includes such a comprehensive list). Our proposed kernel, which has a component that exploits a heterogeneous set of features including negation scope and presence of non-target entities, already obtains better results than previous studies. P R F-score (Thomas et al., 2011) 60.5 71.9 65.7 (Chowdhury et al., 2011) 58.6 70.5 64.0 (Chowdhury and Lavelli, 2011) 58.4 70.1 63.7 (Bjorne et al., 2011) 58.0 68.9 63.0 Proposed KHybrid 60.0 74.3 66.4 KHybrid + Stage 1 baseline 61.8 68.9 65.1 KHybrid + proposed Stage 1 60.0 74.2 66.4 (only training sentences are filtered) KHybrid + proposed Stage 1 61.4 73.8 67.0 (only test sentences are filtered) KHybrid + proposed Stage 1 62.1 73.8 67.4 stat. sig. (both training and test sentences are filtered) Proposed KHybrid + LII filtering 61.1 75.1 67.4 stat. sig. Proposed KHybrid + LII filtering 63.5 75.2 68.9 stat. sig. + proposed </context>
</contexts>
<marker>Thomas, Neves, Solt, Tikk, Leser, 2011</marker>
<rawString>P Thomas, M Neves, I Solt, D Tikk, and U Leser. 2011. Relation extraction for drug-drug interactions using ensemble learning. In Proceedings of the 1st Challenge task on Drug-Drug Interaction Extraction (DDIExtraction 2011), pages 11–18, Huelva, Spain, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GD Zhou</author>
<author>J Su</author>
<author>J Zhang</author>
<author>M Zhang</author>
</authors>
<title>Exploring various knowledge in relation extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics (ACL</booktitle>
<pages>427--434</pages>
<location>Ann Arbor, Michigan, USA.</location>
<contexts>
<context position="8971" citStr="Zhou et al. (2005)" startWordPosition="1461" endWordPosition="1464">rnel to assign more (or less) weight to the information obtained using tree structures depending on the corpus. The proposed kernel composition is valid according to the closure properties of kernels. We exploit the SVM-Light-TK toolkit (Moschitti, 2006; Joachims, 1999) for kernel computation. In Stage 2, each candidate drug mention pair represents an instance. 2.2.1 Proposed KHF kernel As mentioned earlier, this proposed kernel uses heterogeneous features. The first version of the heterogeneous feature set (henceforth, HF v1) combines features proposed by two previous RE works. The former is Zhou et al. (2005), which uses 51 different features. We select the following 27 of their features for our feature set: WBNULL, WBFL, WBF, WBL, WBO, BM1F, BM1L, AM2F, AM2L, #MB, #WB, CPHBNULL, CPHBFL, CPHBF, CPHBL, CPHBO, CPHBM1F, CPHBM1L, CPHAM2F, CPHAM2F, CPP, CPPH, ET12SameNP, ET12SamePP, ET12SameVP, PTP, PTPH The latter is the TPWF kernel (Chowdhury and Lavelli, 2012a) from which we use following features: HasTriggerWord, Trigger-X, DepPattern-i, ewalk, v-walk The TPWF kernel extracts the HasTriggerWord, Trigger-X and DepPattern-i features from a subgraph called reduced graph. We also follow this approach w</context>
<context position="14478" citStr="Zhou et al. (2005)" startWordPosition="2330" endWordPosition="2333">RE training/test instances. Instead, a RE instance corresponds to a candidate mention pair. All the DDIs (i.e. positive RE instances) of the incorrectly identified sentences in Stage 1 (i.e. the sentences which are incorrectly labelled as not having any DDI and filtered) are automatically considered as false negatives during the calculation of DDI extraction results in Stage 2. To verify whether our proposed hybrid kernel achieves state-of-the-art results without taking benefits of the output of Stage 1, we did some experiments without discarding any sentence. These experiments are done using Zhou et al. (2005), TPWF kernel, SL kernel, different versions of proposed KHF kernel and KHybrid kernel. Table 1 shows the results of 5-fold cross-validation experiments (hyper-parameters are tuned for obtaining maximum F-score). As the results show, there is a gain +0.9 points in F-score (mainly due to the boost in recall) after the addition of features related to negation scope. There is also some minor improvement due to the proposed non-target entity specific features. We also performed (5-fold cross validation) experiments by combining the Stage 1 classifier with each of the Zhou et al. (2005), TPWF kerne</context>
</contexts>
<marker>Zhou, Su, Zhang, Zhang, 2005</marker>
<rawString>GD Zhou, J Su, J Zhang, and M Zhang. 2005. Exploring various knowledge in relation extraction. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics (ACL 2005), pages 427–434, Ann Arbor, Michigan, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>