<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.025124">
<title confidence="0.996662">
Detecting Semantic Equivalence and Information Disparity
in Cross-lingual Documents
</title>
<author confidence="0.974016">
Yashar Mehdad Matteo Negri Marcello Federico
</author>
<affiliation confidence="0.750299">
Fondazione Bruno Kessler, FBK-irst
</affiliation>
<address confidence="0.594037">
Trento , Italy
</address>
<email confidence="0.998974">
{mehdad|negri|federico}@fbk.eu
</email>
<sectionHeader confidence="0.998601" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999836357142857">
We address a core aspect of the multilingual
content synchronization task: the identifica-
tion of novel, more informative or semanti-
cally equivalent pieces of information in two
documents about the same topic. This can be
seen as an application-oriented variant of tex-
tual entailment recognition where: i) T and
H are in different languages, and ii) entail-
ment relations between T and H have to be
checked in both directions. Using a combi-
nation of lexical, syntactic, and semantic fea-
tures to train a cross-lingual textual entailment
system, we report promising results on differ-
ent datasets.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.985686097560976">
Given two documents about the same topic writ-
ten in different languages (e.g. Wiki pages), con-
tent synchronization deals with the problem of au-
tomatically detecting and resolving differences in
the information they provide, in order to produce
aligned, mutually enriched versions. A roadmap to-
wards the solution of this problem has to take into
account, among the many sub-tasks, the identifica-
tion of information in one page that is semantically
equivalent, novel, or more informative with respect
to the content of the other page. In this paper we
set such problem as an application-oriented, cross-
lingual variant of the Textual Entailment (TE) recog-
nition task (Dagan and Glickman, 2004). Along this
direction, we make two main contributions:
(a) Experiments with multi-directional cross-
lingual textual entailment. So far, cross-lingual
textual entailment (CLTE) has been only applied
to: i) available TE datasets (uni-directional rela-
tions between monolingual pairs) transformed into
their cross-lingual counterpart by translating the hy-
potheses into other languages (Negri and Mehdad,
2010), and ii) machine translation (MT) evaluation
datasets (Mehdad et al., 2012). Instead, we ex-
periment with the only corpus representative of the
multilingual content synchronization scenario, and
the richer inventory of phenomena arising from it
(multi-directional entailment relations).
(b) Improvement of current CLTE methods. The
CLTE methods proposed so far adopt either a “piv-
oting approach” based on the translation of the two
input texts into the same language (Mehdad et al.,
2010), or an “integrated solution” that exploits bilin-
gual phrase tables to capture lexical relations and
contextual information (Mehdad et al., 2011). The
promising results achieved with the integrated ap-
proach, however, still rely on phrasal matching tech-
niques that disregard relevant semantic aspects of
the problem. By filling this gap integrating linguis-
tically motivated features, we propose a novel ap-
proach that improves the state-of-the-art in CLTE.
</bodyText>
<sectionHeader confidence="0.904848" genericHeader="method">
2 CLTE-based content synchronization
</sectionHeader>
<bodyText confidence="0.999160625">
CLTE has been proposed by (Mehdad et al., 2010) as
an extension of textual entailment which consists of
deciding, given a text T and an hypothesis H in dif-
ferent languages, if the meaning of H can be inferred
from the meaning of T. The adoption of entailment-
based techniques to address content synchronization
looks promising, as several issues inherent to such
task can be formalized as entailment-related prob-
</bodyText>
<page confidence="0.943288">
120
</page>
<note confidence="0.680729">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 120–124,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.992737">
lems. Given two pages (P1 and P2), these issues
include identifying, and properly managing:
</bodyText>
<listItem confidence="0.982626789473684">
(1) Text portions in P1 and P2 that express the same
meaning (bi-directional entailment). In such cases
no information has to migrate across P1 and P2, and
the two text portions will remain the same;
(2) Text portions in P1 that are more informa-
tive than portions in P2 (forward entailment). In
such cases, the entailing (more informative) portions
from P1 have to be translated and migrated to P2 in
order to replace or complement the entailed (less in-
formative) fragments;
(3) Text portions in P2 that are more informa-
tive than portions in P1 (backward entailment), and
should be translated to replace or complement them;
(4) Text portions in P1 describing facts that are not
present in P2, and vice-versa (the “unknown” cases
in RTE parlance). In such cases, the novel infor-
mation from both sides has to be translated and mi-
grated in order to mutually enrich the two pages;
(5) Meaning discrepancies between text portions in
</listItem>
<bodyText confidence="0.989447954545455">
the two pages (“contradictions” in RTE parlance).
CLTE has been previously modeled as a phrase
matching problem that exploits dictionaries and
phrase tables extracted from bilingual parallel cor-
pora to determine the number of word sequences in
H that can be mapped to word sequences in T. In
this way a semantic judgement about entailment is
made exclusively on the basis of lexical evidence.
When only unidirectional entailment relations from
T to H have to be determined (RTE-like setting), the
full mapping of the hypothesis into the text usually
provides enough evidence for a positive entailment
judgement. Unfortunately, when dealing with multi-
directional entailment, the correlation between the
proportion of matching terms and the correct entail-
ment decisions is less strong. In such framework, for
instance, the full mapping of the hypothesis into the
text is per se not sufficient to discriminate between
forward entailment and semantic equivalence. To
cope with these issues, we explore the contribution
of syntactic and semantic features as a complement
to lexical ones in a supervised learning framework.
</bodyText>
<sectionHeader confidence="0.982029" genericHeader="method">
3 Beyond lexical CLTE
</sectionHeader>
<bodyText confidence="0.999973404255319">
In order to enrich the feature space beyond pure lex-
ical match through phrase table entries, our model
builds on two additional feature sets, derived from i)
semantic phrase tables, and ii) dependency relations.
Semantic Phrase Table (SPT) matching repre-
sents a novel way to leverage the integration of se-
mantics and MT-derived techniques. SPT matching
extends CLTE methods based on pure lexical match
by means of “generalized” phrase tables annotated
with shallow semantic labels. SPTs, with entries in
the form “[LABEL] word,...word,,, [LABEL]”, are
used as a recall-oriented complement to the phrase
tables used in MT. A motivation for this augmenta-
tion is that semantic tags allow to match tokens that
do not occur in the original bilingual parallel cor-
pora used for phrase table extraction. Our hypothe-
sis is that the increase in recall obtained from relaxed
matches through semantic tags in place of “out of
vocabulary” terms (e.g. unseen person names) is an
effective way to improve CLTE performance, even
at the cost of some loss in precision.
Like lexical phrase tables, SPTs are extracted
from parallel corpora. As a first step we annotate
the parallel corpora with named-entity taggers for
the source and target languages, replacing named
entities with general semantic labels chosen from
a coarse-grained taxonomy (person, location, orga-
nization, date and numeric expression). Then, we
combine the sequences of unique labels into one sin-
gle token of the same label, and we run Giza++ (Och
and Ney, 2000) to align the resulting semantically
augmented corpora. Finally, we extract the seman-
tic phrase table from the augmented aligned corpora
using the Moses toolkit (Koehn et al., 2007). For
the matching phase, we first annotate T and H in the
same way we labeled our parallel corpora. Then, for
each n-gram order (n=1 to 5) we use the SPT to cal-
culate a matching score as the number of n-grams in
H that match with phrases in T divided by the num-
ber of n-grams in H.1
Dependency Relation (DR) matching targets the
increase of CLTE precision. Adding syntactic con-
straints to the matching process, DR features aim to
reduce the amount of wrong matches often occur-
ring with bag-of-words methods (both at the lexi-
cal level and with recall-oriented SPTs). For in-
stance, the contradiction between “Yahoo acquired
</bodyText>
<footnote confidence="0.9909065">
1When checking for entailment from H to T, the normaliza-
tion is carried out dividing by the number of n-grams in T.
</footnote>
<page confidence="0.994741">
121
</page>
<bodyText confidence="0.999939470588236">
Overture” and “Overture compr´o Yahoo”, which is
evident when syntax is taken into account, can not
be caught by shallow methods. We define a de-
pendency relation as a triple that connects pairs of
words through a grammatical relation. DR matching
captures similarities between dependency relations,
combining the syntactic and lexical level. In a valid
match, while the relation has to be the same, the con-
nected words can be either the same, or semantically
equivalent terms in the two languages (e.g. accord-
ing to a bilingual dictionary). Given the dependency
tree representations of T and H, for each grammati-
cal relation (r) we calculate a DR matching score as
the number of matching occurrences of r in T and
H, divided by the number of occurrences of r in H.
Separate DR matching scores are calculated for each
relation r appearing both in T and H.
</bodyText>
<sectionHeader confidence="0.999613" genericHeader="evaluation">
4 Experiments and results
</sectionHeader>
<subsectionHeader confidence="0.999222">
4.1 Content synchronization scenario
</subsectionHeader>
<bodyText confidence="0.985714307692308">
In our first experiment we used the English-German
portion of the CLTE corpus described in (Negri et
al., 2011), consisting of 500 multi-directional entail-
ment pairs which we equally divided into training
and test sets. Each pair in the dataset is annotated
with “Bidirectional”, “Forward”, or “Backward” en-
tailment judgements. Although highly relevant for
the content synchronization task, “Contradiction”
and “Unknown” cases (i.e. “NO” entailment in both
directions) are not present in the annotation. How-
ever, this is the only available dataset suitable to
gather insights about the viability of our approach to
multi-directional CLTE recognition.2 We chose the
ENG-GER portion of the dataset since for such lan-
guage pair MT systems performance is often lower,
making the adoption of simpler solutions based on
pivoting more vulnerable.
To build the English-German phrase tables we
combined the Europarl, News Commentary and “de-
news”3 parallel corpora. After tokenization, Giza++
and Moses were respectively used to align the cor-
pora and extract a lexical phrase table (PT). Simi-
larly, the semantic phrase table (SPT) has been ex-
2Recently, a new dataset including “Unknown” pairs has
been used in the “Cross-Lingual Textual Entailment for Content
Synchronization” task at SemEval-2012 (Negri et al., 2012).
</bodyText>
<footnote confidence="0.654776">
3http://homepages.inf.ed.ac.uk/pkoehn/
</footnote>
<bodyText confidence="0.999969956521739">
tracted from the same corpora annotated with the
Stanford NE tagger (Faruqui and Pad´o, 2010; Finkel
et al., 2005). Dependency relations (DR) have been
extracted running the Stanford parser (Rafferty and
Manning, 2008; De Marneffe et al., 2006). The dic-
tionary created during the alignment of the parallel
corpora provided the lexical knowledge to perform
matches when the connected words are different, but
semantically equivalent in the two languages. To
combine and weight features at different levels we
used SVMlight (Joachims, 1999) with default pa-
rameters.
In order to experiment under testing conditions
of increasing complexity, we set the CLTE problem
both as a two-way and as a three-way classification
task. Two-way classification casts multi-directional
entailment as a unidirectional problem, where each
pair is analyzed checking for entailment both from
left to right and from right to left. In this condi-
tion, each original test example is correctly clas-
sified if both pairs originated from it are correctly
judged (“YES-YES” for bidirectional, “YES-NO”
for forward, and “NO-YES” for backward entail-
ment). Two-way classification represents an intu-
itive solution to capture multidirectional entailment
relations but, at the same time, a suboptimal ap-
proach in terms of efficiency since two checks are
performed for each pair. Three-way classification is
more efficient, but at the same time more challeng-
ing due to the higher difficulty of multiclass learn-
ing, especially with small datasets.
Results are compared with two pivoting ap-
proaches, checking for entailment between the orig-
inal English texts and the translated German hy-
potheses.4 The first (Pivot-EDITS), uses an op-
timized distance-based model implemented in the
open source RTE system EDITS (Kouylekov and
Negri, 2010; Kouylekov et al., 2011). The second
(Pivot-PPT) exploits paraphrase tables for phrase
matching, and represents the best monolingual
model presented in (Mehdad et al., 2011). Table
1 demonstrates the success of our results in prov-
ing the two main claims of this paper. (a) In both
settings all the feature sets used outperform the ap-
proaches taken as terms of comparison. The 61.6%
accuracy achieved in the most challenging setting
</bodyText>
<footnote confidence="0.876411">
4Using Google Translate.
</footnote>
<page confidence="0.982799">
122
</page>
<table confidence="0.9986898">
PT PT+DR PT+SPT PT+SPT+DR Pivot-EDITS Pivot-PPT
Cont. Synch. (2-way) 57.8 58.6 62.4 63.3 27.4 57.0
Cont. Synch. (3-way) 57.4 57.8 58.7 61.6 25.3 56.1
RTE-3 AVG Pivot PPT
RTE3-derived 62.6 63.6 63.5 64.5 62.4 63.5
</table>
<tableCaption confidence="0.999901">
Table 1: CLTE accuracy results over content synchronization and RTE3-derived datasets.
</tableCaption>
<bodyText confidence="0.998721761904762">
(3-way) demonstrates the effectiveness of our ap-
proach to capture meaning equivalence and informa-
tion disparity in cross-lingual texts.
(b) In both settings the combination of lexical, syn-
tactic and semantic features (PT+SPT+DR) signif-
icantly improves5 the state-of-the-art CLTE model
(PT). Such improvement is motivated by the joint
contribution of SPTs (matching more and longer n-
grams, with a consequent recall improvement), and
DR matching (adding constraints, with a consequent
gain in precision). However, the performance in-
crease brought by DR features over PT is mini-
mal. This might be due to the fact that both PT and
DR features are precision-oriented, and their effec-
tiveness becomes evident only in combination with
recall-oriented features (SPT).
Cross-lingual models also significantly outper-
form pivoting methods. This suggests that the noise
introduced by incorrect translations makes the pivot-
ing approach less attractive in comparison with the
more robust cross-lingual models.
</bodyText>
<subsectionHeader confidence="0.990175">
4.2 RTE-like CLTE scenario
</subsectionHeader>
<bodyText confidence="0.999843">
Our second experiment aims at verifying the effec-
tiveness of the improved model over RTE-derived
CLTE data. To this aim, we compare the results ob-
tained by the new CLTE model with those reported
in (Mehdad et al., 2011), calculated over an English-
Spanish entailment corpus derived from the RTE-3
dataset (Negri and Mehdad, 2010).
In order to build the English-Spanish lexical
phrase table (PT), we used the Europarl, News Com-
mentary and United Nations parallel corpora. The
semantic phrase table (SPT) was extracted from the
same corpora annotated with FreeLing (Carreras et
al., 2004). Dependency relations (DR) have been ex-
tracted parsing English texts and Spanish hypotheses
with DepPattern (Gamallo and Gonzalez, 2011).
</bodyText>
<footnote confidence="0.882091">
5p &lt; 0.05, calculated using the approximate randomization
test implemented in (Pad´o, 2006).
</footnote>
<bodyText confidence="0.999433842105263">
Accuracy results have been calculated over 800
test pairs of the CLTE corpus, after training the SVM
binary classifier over the 800 development pairs.
Our new features have been compared with: i) the
state-of-the-art CLTE model (PT), ii) the best mono-
lingual model (Pivot-PPT) presented in (Mehdad et
al., 2011), and iii) the average result achieved by
participants in the monolingual English RTE-3 eval-
uation campaign (RTE-3 AVG). As shown in Ta-
ble 1, the combined feature set (PT+SPT+DR) sig-
nificantly5 outperforms the lexical model (64.5%
vs 62.6%), while SPT and DR features separately
added to PT (PT+SPT, and PT+DR) lead to marginal
improvements over the results achieved by the PT
model alone (about 1%). This confirms the con-
clusions drawn from the previous experiment, that
precision-oriented and recall-oriented features lead
to a larger improvement when they are used in com-
bination.
</bodyText>
<sectionHeader confidence="0.999448" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999921307692308">
We addressed the identification of semantic equiv-
alence and information disparity in two documents
about the same topic, written in different languages.
This is a core aspect of the multilingual content syn-
chronization task, which represents a challenging
application scenario for a variety of NLP technolo-
gies, and a shared research framework for the inte-
gration of semantics and MT technology. Casting
the problem as a CLTE task, we extended previous
lexical models with syntactic and semantic features.
Our results in different cross-lingual settings prove
the feasibility of the approach, with significant state-
of-the-art improvements also on RTE-derived data.
</bodyText>
<sectionHeader confidence="0.998813" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9979905">
This work has been partially supported by the EU-
funded project CoSyne (FP7-ICT-4-248531).
</bodyText>
<page confidence="0.998548">
123
</page>
<sectionHeader confidence="0.996415" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999365159090909">
X. Carreras, I. Chao, L. Padr´o, and M. Padr´o. 2004.
FreeLing: An Open-Source Suite of Language Ana-
lyzers. In Proceedings of the 4th Language Resources
and Evaluation Conference (LREC 2004), volume 4.
I. Dagan and O. Glickman. 2004. Probabilistic Textual
Entailment: Generic Applied Modeling of Language
Variability. In Proceedings of the PASCAL Workshop
of Learning Methods for Text Understanding and Min-
ing.
M.C. De Marneffe, B. MacCartney, and C.D. Man-
ning. 2006. Generating Typed Dependency Parses
from Phrase Structure Parses. In Proceedings of the
5th Language Resources and Evaluation Conference
(LREC 2006), volume 6, pages 449–454.
M. Faruqui and S. Pad´o. 2010. Training and Evaluat-
ing a German Named Entity Recognizer with Seman-
tic Generalization. In Proceedings of the 10th Con-
ference on Natural Language Processing (KONVENS
2010), Saarbr¨ucken, Germany.
J.R. Finkel, T. Grenager, and C. Manning. 2005. Incor-
porating Non-local Information into Information Ex-
traction Systems by Gibbs Sampling. In Proceedings
of the 43rd Annual Meeting on Association for Com-
putational Linguistics (ACL 2005).
P. Gamallo and I. Gonzalez. 2011. A grammatical for-
malism based on patterns of part of speech tags. Inter-
national Journal of Corpus Linguistics, 16(1):45–71.
T. Joachims. 1999. Advances in kernel methods. chap-
ter Making large-scale support vector machine learn-
ing practical, pages 169–184. MIT Press, Cambridge,
MA, USA.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open Source Toolkit
for Statistical Machine Translation. In Proceedings of
the 45th Annual Meeting on Association for Computa-
tional Linguistics, Demonstration Session (ACL 2007).
M. Kouylekov and M. Negri. 2010. An Open-Source
Package for Recognizing Textual Entailment. In Pro-
ceedings of the 48th Annual Meeting of the Association
for Computational Linguistics, system demonstrations
(ACL 2010).
M. Kouylekov, Y. Mehdad, and M. Negri. 2011. Is it
Worth Submitting this Run? Assess your RTE Sys-
tem with a Good Sparring Partner. Proceedings of the
EMNLP TextInfer 2011 Workshop on Textual Entail-
ment.
Y. Mehdad, M. Negri, and M. Federico. 2010. Towards
Cross-Lingual Textual Entailment. In Proceedings of
the 11th Annual Conference of the North American
Chapter of the Association for Computational Linguis-
tics (NAACL HLT 2010).
Y. Mehdad, M. Negri, and M. Federico. 2011. Using
Bilingual Parallel Corpora for Cross-Lingual Textual
Entailment. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics:
Human Language Technologies (ACL HLT 2011).
Y. Mehdad, M. Negri, and M. Federico. 2012. Match
without a Referee: Evaluating MT Adequacy without
Reference Translations. In Proceedings of the Ma-
chine Translation Workshop (WMT2012).
M. Negri and Y. Mehdad. 2010. Creating a Bi-lingual
Entailment Corpus through Translations with Mechan-
ical Turk: $100 for a 10-day Rush. In Proceedings of
the NAACL HLT 2010 Workshop on Creating Speech
and Language Data with Amazon´s Mechanical Turk.
M. Negri, L. Bentivogli, Y. Mehdad, D. Giampiccolo, and
A. Marchetti. 2011. Divide and Conquer: Crowd-
sourcing the Creation of Cross-Lingual Textual Entail-
ment Corpora. Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Processing
(EMNLP 2011).
M. Negri, A. Marchetti, Y. Mehdad, L. Bentivogli, and
D. Giampiccolo. 2012. Semeval-2012 Task 8: Cross-
lingual Textual Entailment for Content Synchroniza-
tion. In Proceedings of the 6th International Workshop
on Semantic Evaluation (SemEval 2012).
F.J. Och and H. Ney. 2000. Improved Statistical Align-
ment Models. In Proceedings of the 38th Annual
Meeting of the Association for Computational Linguis-
tics (ACL 2000).
S. Pad´o, 2006. User’s guide to sigf: Significance test-
ing by approximate randomisation.
A.N. Rafferty and C.D. Manning. 2008. Parsing Three
German Treebanks: Lexicalized and Unlexicalized
Baselines. In In Proceedings of the ACL 2008 Work-
shop on Parsing German.
</reference>
<page confidence="0.998317">
124
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.363540">
<title confidence="0.9996865">Detecting Semantic Equivalence and Information in Cross-lingual Documents</title>
<author confidence="0.770961666666667">Yashar Mehdad Matteo Negri Marcello Federico Fondazione Bruno Kessler</author>
<author confidence="0.770961666666667">Trento</author>
<abstract confidence="0.994213066666667">We address a core aspect of the multilingual content synchronization task: the identification of novel, more informative or semantically equivalent pieces of information in two documents about the same topic. This can be seen as an application-oriented variant of texentailment recognition where: and are in different languages, and entailment relations between T and H have to be checked in both directions. Using a combination of lexical, syntactic, and semantic features to train a cross-lingual textual entailment system, we report promising results on different datasets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>I Chao</author>
<author>L Padr´o</author>
<author>M Padr´o</author>
</authors>
<title>FreeLing: An Open-Source Suite of Language Analyzers.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th Language Resources and Evaluation Conference (LREC</booktitle>
<volume>4</volume>
<marker>Carreras, Chao, Padr´o, Padr´o, 2004</marker>
<rawString>X. Carreras, I. Chao, L. Padr´o, and M. Padr´o. 2004. FreeLing: An Open-Source Suite of Language Analyzers. In Proceedings of the 4th Language Resources and Evaluation Conference (LREC 2004), volume 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>O Glickman</author>
</authors>
<title>Probabilistic Textual Entailment: Generic Applied Modeling of Language Variability.</title>
<date>2004</date>
<booktitle>In Proceedings of the PASCAL Workshop of Learning Methods for Text Understanding and Mining.</booktitle>
<contexts>
<context position="1517" citStr="Dagan and Glickman, 2004" startWordPosition="228" endWordPosition="231">guages (e.g. Wiki pages), content synchronization deals with the problem of automatically detecting and resolving differences in the information they provide, in order to produce aligned, mutually enriched versions. A roadmap towards the solution of this problem has to take into account, among the many sub-tasks, the identification of information in one page that is semantically equivalent, novel, or more informative with respect to the content of the other page. In this paper we set such problem as an application-oriented, crosslingual variant of the Textual Entailment (TE) recognition task (Dagan and Glickman, 2004). Along this direction, we make two main contributions: (a) Experiments with multi-directional crosslingual textual entailment. So far, cross-lingual textual entailment (CLTE) has been only applied to: i) available TE datasets (uni-directional relations between monolingual pairs) transformed into their cross-lingual counterpart by translating the hypotheses into other languages (Negri and Mehdad, 2010), and ii) machine translation (MT) evaluation datasets (Mehdad et al., 2012). Instead, we experiment with the only corpus representative of the multilingual content synchronization scenario, and </context>
</contexts>
<marker>Dagan, Glickman, 2004</marker>
<rawString>I. Dagan and O. Glickman. 2004. Probabilistic Textual Entailment: Generic Applied Modeling of Language Variability. In Proceedings of the PASCAL Workshop of Learning Methods for Text Understanding and Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M C De Marneffe</author>
<author>B MacCartney</author>
<author>C D Manning</author>
</authors>
<title>Generating Typed Dependency Parses from Phrase Structure Parses.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th Language Resources and Evaluation Conference (LREC</booktitle>
<volume>6</volume>
<pages>449--454</pages>
<marker>De Marneffe, MacCartney, Manning, 2006</marker>
<rawString>M.C. De Marneffe, B. MacCartney, and C.D. Manning. 2006. Generating Typed Dependency Parses from Phrase Structure Parses. In Proceedings of the 5th Language Resources and Evaluation Conference (LREC 2006), volume 6, pages 449–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Faruqui</author>
<author>S Pad´o</author>
</authors>
<title>Training and Evaluating a German Named Entity Recognizer with Semantic Generalization.</title>
<date>2010</date>
<booktitle>In Proceedings of the 10th Conference on Natural Language Processing (KONVENS</booktitle>
<location>Saarbr¨ucken, Germany.</location>
<marker>Faruqui, Pad´o, 2010</marker>
<rawString>M. Faruqui and S. Pad´o. 2010. Training and Evaluating a German Named Entity Recognizer with Semantic Generalization. In Proceedings of the 10th Conference on Natural Language Processing (KONVENS 2010), Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Finkel</author>
<author>T Grenager</author>
<author>C Manning</author>
</authors>
<title>Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics (ACL</booktitle>
<contexts>
<context position="10491" citStr="Finkel et al., 2005" startWordPosition="1652" endWordPosition="1655">build the English-German phrase tables we combined the Europarl, News Commentary and “denews”3 parallel corpora. After tokenization, Giza++ and Moses were respectively used to align the corpora and extract a lexical phrase table (PT). Similarly, the semantic phrase table (SPT) has been ex2Recently, a new dataset including “Unknown” pairs has been used in the “Cross-Lingual Textual Entailment for Content Synchronization” task at SemEval-2012 (Negri et al., 2012). 3http://homepages.inf.ed.ac.uk/pkoehn/ tracted from the same corpora annotated with the Stanford NE tagger (Faruqui and Pad´o, 2010; Finkel et al., 2005). Dependency relations (DR) have been extracted running the Stanford parser (Rafferty and Manning, 2008; De Marneffe et al., 2006). The dictionary created during the alignment of the parallel corpora provided the lexical knowledge to perform matches when the connected words are different, but semantically equivalent in the two languages. To combine and weight features at different levels we used SVMlight (Joachims, 1999) with default parameters. In order to experiment under testing conditions of increasing complexity, we set the CLTE problem both as a two-way and as a three-way classification </context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>J.R. Finkel, T. Grenager, and C. Manning. 2005. Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics (ACL 2005).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Gamallo</author>
<author>I Gonzalez</author>
</authors>
<title>A grammatical formalism based on patterns of part of speech tags.</title>
<date>2011</date>
<journal>International Journal of Corpus Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="14679" citStr="Gamallo and Gonzalez, 2011" startWordPosition="2292" endWordPosition="2295">d CLTE data. To this aim, we compare the results obtained by the new CLTE model with those reported in (Mehdad et al., 2011), calculated over an EnglishSpanish entailment corpus derived from the RTE-3 dataset (Negri and Mehdad, 2010). In order to build the English-Spanish lexical phrase table (PT), we used the Europarl, News Commentary and United Nations parallel corpora. The semantic phrase table (SPT) was extracted from the same corpora annotated with FreeLing (Carreras et al., 2004). Dependency relations (DR) have been extracted parsing English texts and Spanish hypotheses with DepPattern (Gamallo and Gonzalez, 2011). 5p &lt; 0.05, calculated using the approximate randomization test implemented in (Pad´o, 2006). Accuracy results have been calculated over 800 test pairs of the CLTE corpus, after training the SVM binary classifier over the 800 development pairs. Our new features have been compared with: i) the state-of-the-art CLTE model (PT), ii) the best monolingual model (Pivot-PPT) presented in (Mehdad et al., 2011), and iii) the average result achieved by participants in the monolingual English RTE-3 evaluation campaign (RTE-3 AVG). As shown in Table 1, the combined feature set (PT+SPT+DR) significantly5 </context>
</contexts>
<marker>Gamallo, Gonzalez, 2011</marker>
<rawString>P. Gamallo and I. Gonzalez. 2011. A grammatical formalism based on patterns of part of speech tags. International Journal of Corpus Linguistics, 16(1):45–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Advances in kernel methods. chapter Making large-scale support vector machine learning practical,</title>
<date>1999</date>
<pages>169--184</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="10915" citStr="Joachims, 1999" startWordPosition="1717" endWordPosition="1718">at SemEval-2012 (Negri et al., 2012). 3http://homepages.inf.ed.ac.uk/pkoehn/ tracted from the same corpora annotated with the Stanford NE tagger (Faruqui and Pad´o, 2010; Finkel et al., 2005). Dependency relations (DR) have been extracted running the Stanford parser (Rafferty and Manning, 2008; De Marneffe et al., 2006). The dictionary created during the alignment of the parallel corpora provided the lexical knowledge to perform matches when the connected words are different, but semantically equivalent in the two languages. To combine and weight features at different levels we used SVMlight (Joachims, 1999) with default parameters. In order to experiment under testing conditions of increasing complexity, we set the CLTE problem both as a two-way and as a three-way classification task. Two-way classification casts multi-directional entailment as a unidirectional problem, where each pair is analyzed checking for entailment both from left to right and from right to left. In this condition, each original test example is correctly classified if both pairs originated from it are correctly judged (“YES-YES” for bidirectional, “YES-NO” for forward, and “NO-YES” for backward entailment). Two-way classifi</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>T. Joachims. 1999. Advances in kernel methods. chapter Making large-scale support vector machine learning practical, pages 169–184. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting on Association for Computational Linguistics, Demonstration Session (ACL</booktitle>
<contexts>
<context position="7367" citStr="Koehn et al., 2007" startWordPosition="1144" endWordPosition="1147">s, SPTs are extracted from parallel corpora. As a first step we annotate the parallel corpora with named-entity taggers for the source and target languages, replacing named entities with general semantic labels chosen from a coarse-grained taxonomy (person, location, organization, date and numeric expression). Then, we combine the sequences of unique labels into one single token of the same label, and we run Giza++ (Och and Ney, 2000) to align the resulting semantically augmented corpora. Finally, we extract the semantic phrase table from the augmented aligned corpora using the Moses toolkit (Koehn et al., 2007). For the matching phase, we first annotate T and H in the same way we labeled our parallel corpora. Then, for each n-gram order (n=1 to 5) we use the SPT to calculate a matching score as the number of n-grams in H that match with phrases in T divided by the number of n-grams in H.1 Dependency Relation (DR) matching targets the increase of CLTE precision. Adding syntactic constraints to the matching process, DR features aim to reduce the amount of wrong matches often occurring with bag-of-words methods (both at the lexical level and with recall-oriented SPTs). For instance, the contradiction b</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of the 45th Annual Meeting on Association for Computational Linguistics, Demonstration Session (ACL 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kouylekov</author>
<author>M Negri</author>
</authors>
<title>An Open-Source Package for Recognizing Textual Entailment.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, system demonstrations (ACL</booktitle>
<contexts>
<context position="12172" citStr="Kouylekov and Negri, 2010" startWordPosition="1907" endWordPosition="1910">olution to capture multidirectional entailment relations but, at the same time, a suboptimal approach in terms of efficiency since two checks are performed for each pair. Three-way classification is more efficient, but at the same time more challenging due to the higher difficulty of multiclass learning, especially with small datasets. Results are compared with two pivoting approaches, checking for entailment between the original English texts and the translated German hypotheses.4 The first (Pivot-EDITS), uses an optimized distance-based model implemented in the open source RTE system EDITS (Kouylekov and Negri, 2010; Kouylekov et al., 2011). The second (Pivot-PPT) exploits paraphrase tables for phrase matching, and represents the best monolingual model presented in (Mehdad et al., 2011). Table 1 demonstrates the success of our results in proving the two main claims of this paper. (a) In both settings all the feature sets used outperform the approaches taken as terms of comparison. The 61.6% accuracy achieved in the most challenging setting 4Using Google Translate. 122 PT PT+DR PT+SPT PT+SPT+DR Pivot-EDITS Pivot-PPT Cont. Synch. (2-way) 57.8 58.6 62.4 63.3 27.4 57.0 Cont. Synch. (3-way) 57.4 57.8 58.7 61.</context>
</contexts>
<marker>Kouylekov, Negri, 2010</marker>
<rawString>M. Kouylekov and M. Negri. 2010. An Open-Source Package for Recognizing Textual Entailment. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, system demonstrations (ACL 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kouylekov</author>
<author>Y Mehdad</author>
<author>M Negri</author>
</authors>
<title>Is it Worth Submitting this Run? Assess your RTE System with a Good Sparring Partner.</title>
<date>2011</date>
<booktitle>Proceedings of the EMNLP TextInfer 2011 Workshop on Textual Entailment.</booktitle>
<contexts>
<context position="12197" citStr="Kouylekov et al., 2011" startWordPosition="1911" endWordPosition="1914">ectional entailment relations but, at the same time, a suboptimal approach in terms of efficiency since two checks are performed for each pair. Three-way classification is more efficient, but at the same time more challenging due to the higher difficulty of multiclass learning, especially with small datasets. Results are compared with two pivoting approaches, checking for entailment between the original English texts and the translated German hypotheses.4 The first (Pivot-EDITS), uses an optimized distance-based model implemented in the open source RTE system EDITS (Kouylekov and Negri, 2010; Kouylekov et al., 2011). The second (Pivot-PPT) exploits paraphrase tables for phrase matching, and represents the best monolingual model presented in (Mehdad et al., 2011). Table 1 demonstrates the success of our results in proving the two main claims of this paper. (a) In both settings all the feature sets used outperform the approaches taken as terms of comparison. The 61.6% accuracy achieved in the most challenging setting 4Using Google Translate. 122 PT PT+DR PT+SPT PT+SPT+DR Pivot-EDITS Pivot-PPT Cont. Synch. (2-way) 57.8 58.6 62.4 63.3 27.4 57.0 Cont. Synch. (3-way) 57.4 57.8 58.7 61.6 25.3 56.1 RTE-3 AVG Piv</context>
</contexts>
<marker>Kouylekov, Mehdad, Negri, 2011</marker>
<rawString>M. Kouylekov, Y. Mehdad, and M. Negri. 2011. Is it Worth Submitting this Run? Assess your RTE System with a Good Sparring Partner. Proceedings of the EMNLP TextInfer 2011 Workshop on Textual Entailment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mehdad</author>
<author>M Negri</author>
<author>M Federico</author>
</authors>
<title>Towards Cross-Lingual Textual Entailment.</title>
<date>2010</date>
<booktitle>In Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT</booktitle>
<contexts>
<context position="2410" citStr="Mehdad et al., 2010" startWordPosition="355" endWordPosition="358"> pairs) transformed into their cross-lingual counterpart by translating the hypotheses into other languages (Negri and Mehdad, 2010), and ii) machine translation (MT) evaluation datasets (Mehdad et al., 2012). Instead, we experiment with the only corpus representative of the multilingual content synchronization scenario, and the richer inventory of phenomena arising from it (multi-directional entailment relations). (b) Improvement of current CLTE methods. The CLTE methods proposed so far adopt either a “pivoting approach” based on the translation of the two input texts into the same language (Mehdad et al., 2010), or an “integrated solution” that exploits bilingual phrase tables to capture lexical relations and contextual information (Mehdad et al., 2011). The promising results achieved with the integrated approach, however, still rely on phrasal matching techniques that disregard relevant semantic aspects of the problem. By filling this gap integrating linguistically motivated features, we propose a novel approach that improves the state-of-the-art in CLTE. 2 CLTE-based content synchronization CLTE has been proposed by (Mehdad et al., 2010) as an extension of textual entailment which consists of deci</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2010</marker>
<rawString>Y. Mehdad, M. Negri, and M. Federico. 2010. Towards Cross-Lingual Textual Entailment. In Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mehdad</author>
<author>M Negri</author>
<author>M Federico</author>
</authors>
<title>Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL HLT</booktitle>
<contexts>
<context position="2555" citStr="Mehdad et al., 2011" startWordPosition="376" endWordPosition="379">hine translation (MT) evaluation datasets (Mehdad et al., 2012). Instead, we experiment with the only corpus representative of the multilingual content synchronization scenario, and the richer inventory of phenomena arising from it (multi-directional entailment relations). (b) Improvement of current CLTE methods. The CLTE methods proposed so far adopt either a “pivoting approach” based on the translation of the two input texts into the same language (Mehdad et al., 2010), or an “integrated solution” that exploits bilingual phrase tables to capture lexical relations and contextual information (Mehdad et al., 2011). The promising results achieved with the integrated approach, however, still rely on phrasal matching techniques that disregard relevant semantic aspects of the problem. By filling this gap integrating linguistically motivated features, we propose a novel approach that improves the state-of-the-art in CLTE. 2 CLTE-based content synchronization CLTE has been proposed by (Mehdad et al., 2010) as an extension of textual entailment which consists of deciding, given a text T and an hypothesis H in different languages, if the meaning of H can be inferred from the meaning of T. The adoption of entai</context>
<context position="12346" citStr="Mehdad et al., 2011" startWordPosition="1932" endWordPosition="1935">y classification is more efficient, but at the same time more challenging due to the higher difficulty of multiclass learning, especially with small datasets. Results are compared with two pivoting approaches, checking for entailment between the original English texts and the translated German hypotheses.4 The first (Pivot-EDITS), uses an optimized distance-based model implemented in the open source RTE system EDITS (Kouylekov and Negri, 2010; Kouylekov et al., 2011). The second (Pivot-PPT) exploits paraphrase tables for phrase matching, and represents the best monolingual model presented in (Mehdad et al., 2011). Table 1 demonstrates the success of our results in proving the two main claims of this paper. (a) In both settings all the feature sets used outperform the approaches taken as terms of comparison. The 61.6% accuracy achieved in the most challenging setting 4Using Google Translate. 122 PT PT+DR PT+SPT PT+SPT+DR Pivot-EDITS Pivot-PPT Cont. Synch. (2-way) 57.8 58.6 62.4 63.3 27.4 57.0 Cont. Synch. (3-way) 57.4 57.8 58.7 61.6 25.3 56.1 RTE-3 AVG Pivot PPT RTE3-derived 62.6 63.6 63.5 64.5 62.4 63.5 Table 1: CLTE accuracy results over content synchronization and RTE3-derived datasets. (3-way) demo</context>
<context position="14176" citStr="Mehdad et al., 2011" startWordPosition="2217" endWordPosition="2220"> and DR features are precision-oriented, and their effectiveness becomes evident only in combination with recall-oriented features (SPT). Cross-lingual models also significantly outperform pivoting methods. This suggests that the noise introduced by incorrect translations makes the pivoting approach less attractive in comparison with the more robust cross-lingual models. 4.2 RTE-like CLTE scenario Our second experiment aims at verifying the effectiveness of the improved model over RTE-derived CLTE data. To this aim, we compare the results obtained by the new CLTE model with those reported in (Mehdad et al., 2011), calculated over an EnglishSpanish entailment corpus derived from the RTE-3 dataset (Negri and Mehdad, 2010). In order to build the English-Spanish lexical phrase table (PT), we used the Europarl, News Commentary and United Nations parallel corpora. The semantic phrase table (SPT) was extracted from the same corpora annotated with FreeLing (Carreras et al., 2004). Dependency relations (DR) have been extracted parsing English texts and Spanish hypotheses with DepPattern (Gamallo and Gonzalez, 2011). 5p &lt; 0.05, calculated using the approximate randomization test implemented in (Pad´o, 2006). Ac</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2011</marker>
<rawString>Y. Mehdad, M. Negri, and M. Federico. 2011. Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL HLT 2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mehdad</author>
<author>M Negri</author>
<author>M Federico</author>
</authors>
<title>Match without a Referee: Evaluating MT Adequacy without Reference Translations.</title>
<date>2012</date>
<booktitle>In Proceedings of the Machine Translation Workshop (WMT2012).</booktitle>
<contexts>
<context position="1998" citStr="Mehdad et al., 2012" startWordPosition="293" endWordPosition="296">et such problem as an application-oriented, crosslingual variant of the Textual Entailment (TE) recognition task (Dagan and Glickman, 2004). Along this direction, we make two main contributions: (a) Experiments with multi-directional crosslingual textual entailment. So far, cross-lingual textual entailment (CLTE) has been only applied to: i) available TE datasets (uni-directional relations between monolingual pairs) transformed into their cross-lingual counterpart by translating the hypotheses into other languages (Negri and Mehdad, 2010), and ii) machine translation (MT) evaluation datasets (Mehdad et al., 2012). Instead, we experiment with the only corpus representative of the multilingual content synchronization scenario, and the richer inventory of phenomena arising from it (multi-directional entailment relations). (b) Improvement of current CLTE methods. The CLTE methods proposed so far adopt either a “pivoting approach” based on the translation of the two input texts into the same language (Mehdad et al., 2010), or an “integrated solution” that exploits bilingual phrase tables to capture lexical relations and contextual information (Mehdad et al., 2011). The promising results achieved with the i</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2012</marker>
<rawString>Y. Mehdad, M. Negri, and M. Federico. 2012. Match without a Referee: Evaluating MT Adequacy without Reference Translations. In Proceedings of the Machine Translation Workshop (WMT2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Negri</author>
<author>Y Mehdad</author>
</authors>
<title>Creating a Bi-lingual Entailment Corpus through Translations with Mechanical Turk: $100 for a 10-day Rush.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon´s Mechanical Turk.</booktitle>
<contexts>
<context position="1922" citStr="Negri and Mehdad, 2010" startWordPosition="282" endWordPosition="285">e informative with respect to the content of the other page. In this paper we set such problem as an application-oriented, crosslingual variant of the Textual Entailment (TE) recognition task (Dagan and Glickman, 2004). Along this direction, we make two main contributions: (a) Experiments with multi-directional crosslingual textual entailment. So far, cross-lingual textual entailment (CLTE) has been only applied to: i) available TE datasets (uni-directional relations between monolingual pairs) transformed into their cross-lingual counterpart by translating the hypotheses into other languages (Negri and Mehdad, 2010), and ii) machine translation (MT) evaluation datasets (Mehdad et al., 2012). Instead, we experiment with the only corpus representative of the multilingual content synchronization scenario, and the richer inventory of phenomena arising from it (multi-directional entailment relations). (b) Improvement of current CLTE methods. The CLTE methods proposed so far adopt either a “pivoting approach” based on the translation of the two input texts into the same language (Mehdad et al., 2010), or an “integrated solution” that exploits bilingual phrase tables to capture lexical relations and contextual </context>
<context position="14285" citStr="Negri and Mehdad, 2010" startWordPosition="2233" endWordPosition="2236">recall-oriented features (SPT). Cross-lingual models also significantly outperform pivoting methods. This suggests that the noise introduced by incorrect translations makes the pivoting approach less attractive in comparison with the more robust cross-lingual models. 4.2 RTE-like CLTE scenario Our second experiment aims at verifying the effectiveness of the improved model over RTE-derived CLTE data. To this aim, we compare the results obtained by the new CLTE model with those reported in (Mehdad et al., 2011), calculated over an EnglishSpanish entailment corpus derived from the RTE-3 dataset (Negri and Mehdad, 2010). In order to build the English-Spanish lexical phrase table (PT), we used the Europarl, News Commentary and United Nations parallel corpora. The semantic phrase table (SPT) was extracted from the same corpora annotated with FreeLing (Carreras et al., 2004). Dependency relations (DR) have been extracted parsing English texts and Spanish hypotheses with DepPattern (Gamallo and Gonzalez, 2011). 5p &lt; 0.05, calculated using the approximate randomization test implemented in (Pad´o, 2006). Accuracy results have been calculated over 800 test pairs of the CLTE corpus, after training the SVM binary cla</context>
</contexts>
<marker>Negri, Mehdad, 2010</marker>
<rawString>M. Negri and Y. Mehdad. 2010. Creating a Bi-lingual Entailment Corpus through Translations with Mechanical Turk: $100 for a 10-day Rush. In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon´s Mechanical Turk.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Negri</author>
<author>L Bentivogli</author>
<author>Y Mehdad</author>
<author>D Giampiccolo</author>
<author>A Marchetti</author>
</authors>
<title>Divide and Conquer: Crowdsourcing the Creation of Cross-Lingual Textual Entailment Corpora.</title>
<date>2011</date>
<booktitle>Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<contexts>
<context position="9139" citStr="Negri et al., 2011" startWordPosition="1452" endWordPosition="1455">ed words can be either the same, or semantically equivalent terms in the two languages (e.g. according to a bilingual dictionary). Given the dependency tree representations of T and H, for each grammatical relation (r) we calculate a DR matching score as the number of matching occurrences of r in T and H, divided by the number of occurrences of r in H. Separate DR matching scores are calculated for each relation r appearing both in T and H. 4 Experiments and results 4.1 Content synchronization scenario In our first experiment we used the English-German portion of the CLTE corpus described in (Negri et al., 2011), consisting of 500 multi-directional entailment pairs which we equally divided into training and test sets. Each pair in the dataset is annotated with “Bidirectional”, “Forward”, or “Backward” entailment judgements. Although highly relevant for the content synchronization task, “Contradiction” and “Unknown” cases (i.e. “NO” entailment in both directions) are not present in the annotation. However, this is the only available dataset suitable to gather insights about the viability of our approach to multi-directional CLTE recognition.2 We chose the ENG-GER portion of the dataset since for such </context>
</contexts>
<marker>Negri, Bentivogli, Mehdad, Giampiccolo, Marchetti, 2011</marker>
<rawString>M. Negri, L. Bentivogli, Y. Mehdad, D. Giampiccolo, and A. Marchetti. 2011. Divide and Conquer: Crowdsourcing the Creation of Cross-Lingual Textual Entailment Corpora. Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP 2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Negri</author>
<author>A Marchetti</author>
<author>Y Mehdad</author>
<author>L Bentivogli</author>
<author>D Giampiccolo</author>
</authors>
<title>Semeval-2012 Task 8: Crosslingual Textual Entailment for Content Synchronization.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="10336" citStr="Negri et al., 2012" startWordPosition="1632" endWordPosition="1635">ataset since for such language pair MT systems performance is often lower, making the adoption of simpler solutions based on pivoting more vulnerable. To build the English-German phrase tables we combined the Europarl, News Commentary and “denews”3 parallel corpora. After tokenization, Giza++ and Moses were respectively used to align the corpora and extract a lexical phrase table (PT). Similarly, the semantic phrase table (SPT) has been ex2Recently, a new dataset including “Unknown” pairs has been used in the “Cross-Lingual Textual Entailment for Content Synchronization” task at SemEval-2012 (Negri et al., 2012). 3http://homepages.inf.ed.ac.uk/pkoehn/ tracted from the same corpora annotated with the Stanford NE tagger (Faruqui and Pad´o, 2010; Finkel et al., 2005). Dependency relations (DR) have been extracted running the Stanford parser (Rafferty and Manning, 2008; De Marneffe et al., 2006). The dictionary created during the alignment of the parallel corpora provided the lexical knowledge to perform matches when the connected words are different, but semantically equivalent in the two languages. To combine and weight features at different levels we used SVMlight (Joachims, 1999) with default paramet</context>
</contexts>
<marker>Negri, Marchetti, Mehdad, Bentivogli, Giampiccolo, 2012</marker>
<rawString>M. Negri, A. Marchetti, Y. Mehdad, L. Bentivogli, and D. Giampiccolo. 2012. Semeval-2012 Task 8: Crosslingual Textual Entailment for Content Synchronization. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improved Statistical Alignment Models.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<contexts>
<context position="7186" citStr="Och and Ney, 2000" startWordPosition="1116" endWordPosition="1119">place of “out of vocabulary” terms (e.g. unseen person names) is an effective way to improve CLTE performance, even at the cost of some loss in precision. Like lexical phrase tables, SPTs are extracted from parallel corpora. As a first step we annotate the parallel corpora with named-entity taggers for the source and target languages, replacing named entities with general semantic labels chosen from a coarse-grained taxonomy (person, location, organization, date and numeric expression). Then, we combine the sequences of unique labels into one single token of the same label, and we run Giza++ (Och and Ney, 2000) to align the resulting semantically augmented corpora. Finally, we extract the semantic phrase table from the augmented aligned corpora using the Moses toolkit (Koehn et al., 2007). For the matching phase, we first annotate T and H in the same way we labeled our parallel corpora. Then, for each n-gram order (n=1 to 5) we use the SPT to calculate a matching score as the number of n-grams in H that match with phrases in T divided by the number of n-grams in H.1 Dependency Relation (DR) matching targets the increase of CLTE precision. Adding syntactic constraints to the matching process, DR feat</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F.J. Och and H. Ney. 2000. Improved Statistical Alignment Models. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL 2000).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pad´o</author>
</authors>
<title>User’s guide to sigf: Significance testing by approximate randomisation.</title>
<date>2006</date>
<marker>Pad´o, 2006</marker>
<rawString>S. Pad´o, 2006. User’s guide to sigf: Significance testing by approximate randomisation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A N Rafferty</author>
<author>C D Manning</author>
</authors>
<title>Parsing Three German Treebanks: Lexicalized and Unlexicalized Baselines. In</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL 2008 Workshop on Parsing German.</booktitle>
<contexts>
<context position="10594" citStr="Rafferty and Manning, 2008" startWordPosition="1666" endWordPosition="1669">rallel corpora. After tokenization, Giza++ and Moses were respectively used to align the corpora and extract a lexical phrase table (PT). Similarly, the semantic phrase table (SPT) has been ex2Recently, a new dataset including “Unknown” pairs has been used in the “Cross-Lingual Textual Entailment for Content Synchronization” task at SemEval-2012 (Negri et al., 2012). 3http://homepages.inf.ed.ac.uk/pkoehn/ tracted from the same corpora annotated with the Stanford NE tagger (Faruqui and Pad´o, 2010; Finkel et al., 2005). Dependency relations (DR) have been extracted running the Stanford parser (Rafferty and Manning, 2008; De Marneffe et al., 2006). The dictionary created during the alignment of the parallel corpora provided the lexical knowledge to perform matches when the connected words are different, but semantically equivalent in the two languages. To combine and weight features at different levels we used SVMlight (Joachims, 1999) with default parameters. In order to experiment under testing conditions of increasing complexity, we set the CLTE problem both as a two-way and as a three-way classification task. Two-way classification casts multi-directional entailment as a unidirectional problem, where each</context>
</contexts>
<marker>Rafferty, Manning, 2008</marker>
<rawString>A.N. Rafferty and C.D. Manning. 2008. Parsing Three German Treebanks: Lexicalized and Unlexicalized Baselines. In In Proceedings of the ACL 2008 Workshop on Parsing German.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>