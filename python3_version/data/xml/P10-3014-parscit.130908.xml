<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002270">
<title confidence="0.961276">
Edit Tree Distance alignments for Semantic Role Labelling
</title>
<author confidence="0.986555">
Hector-Hugo Franco-Penya
</author>
<affiliation confidence="0.986619">
Trinity College Dublin
</affiliation>
<address confidence="0.834859">
Dublin, Ireland.
</address>
<email confidence="0.977336">
francoph@cs.tcd.ie
</email>
<sectionHeader confidence="0.993217" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9991034">
&amp;quot;Tree SRL system&amp;quot; is a Semantic Role Label-
ling supervised system based on a tree-distance
algorithm and a simple k-NN implementation.
The novelty of the system lies in comparing the
sentences as tree structures with multiple rela-
tions instead of extracting vectors of features
for each relation and classifying them. The sys-
tem was tested with the English CoNLL-2009
shared task data set where 79% accuracy was
obtained.
</bodyText>
<sectionHeader confidence="0.999262" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9990084">
Semantic Role Labelling (SRL) is a natural lan-
guage processing task which deals with semantic
analysis at sentence-level. SRL is the task of
identifying arguments for a certain predicate and
labelling them. The predicates are usually verbs.
They establish &amp;quot;what happened&amp;quot;. The arguments
determine events such as &amp;quot;who&amp;quot;, &amp;quot;whom&amp;quot;,
&amp;quot;where&amp;quot;, etc, with reference to one predicate.
The possible semantic roles are pre-defined for
each predicate. The set of roles depends on the
corpora.
SRL is becoming an important tool for infor-
mation extraction, text summarization, machine
translation and question answering (Màrquez, et
al, 2008).
</bodyText>
<sectionHeader confidence="0.933043" genericHeader="introduction">
2 The data
</sectionHeader>
<bodyText confidence="0.996133166666667">
The data set I used is taken from the CoNLL-
2009 shared task (Hajič et al., 2009) and is part
of Propbank. Propbank (Palmer et al, 2005) is a
hand-annotated corpus. It transforms sentences
into propositions. It adds a semantic layer to the
Penn TreeBank (Marcus et al, 1994) and defines
a set of semantic roles for each predicate.
It is difficult to define universal semantic roles
for all predicates. That is why PropBank defines
a set of semantic roles for each possible sense of
each predicate (frame) [See a sample of the
frame &amp;quot;raise&amp;quot; on the Figure 1 caption].
</bodyText>
<table confidence="0.988315">
Sentences predicates arguments Predicates per arguments File size in
sentence per sub-tree Mb
Tra 39279 179014 393699 4.55 2.20 56.2
Dev 1334 6390 13865 4.79 2.17 1.97
Evl 2399 10498 23286 4.38 2.22 3.41
</table>
<tableCaption confidence="0.999701">
Table 1: The data
</tableCaption>
<bodyText confidence="0.999804695652174">
The data set is divided into three files: training
(Tra), development (Dev) and evaluation (Evl).
The following table describes the number of
sentences, sub-trees and labels contained in
them, and the ratios of sub-trees per sentences
and relations per sub-tree.
The core arguments are labelled by numbers.
Adjuncts, which are common to all predicates,
have their own labels, like: AM-LOC, TMP,
NEG, etc. The four most frequent labels in the
data set are: A1:35%, A0:20.86%, A2:7.88% and
AM-TMP: 7.72%
Propbank was originally built using constitu-
ent tree structures, but here only the dependency
tree structure version was used. Note that de-
pendency tree structures have labels on the ar-
rows. The tree distance algorithm cannot work
with these labelled arrows and so they are moved
to the child node as an extra label.
The task performed by the Tree SRL system
consists of labelling the relations (predicate ar-
guments) which are assumed to be already iden-
tified.
</bodyText>
<sectionHeader confidence="0.993214" genericHeader="method">
3 Tree Distance
</sectionHeader>
<bodyText confidence="0.995222545454545">
The tree distance algorithm has already been ap-
plied to text entailment (Kouylekov &amp; Magnini,
2005) and question answering (Punyakanok et al,
2004; Emms, 2006) with positive results.
The main contribution of this piece of work to
the SRL field is the inclusion of the tree distance
algorithm into an SRL system, working with tree
structures in contrast to the classical &amp;quot;feature ex-
traction&amp;quot; and &amp;quot;classification&amp;quot;. Kim et al (2009)
developed a similar system for Information Ex-
traction.
</bodyText>
<page confidence="0.989041">
79
</page>
<note confidence="0.8850955">
Proceedings of the ACL 2010 Student Research Workshop, pages 79–84,
Uppsala, Sweden, 13 July 2010. c�2010 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999808">
Figure 1: Alignment sample
</figureCaption>
<bodyText confidence="0.999403045454546">
A two sentence sample, in a dependency tree representation. In each node, the word form and the
position of the word in the sentence are shown. Straight arrows represent syntactic dependencies. The
label of the dependency is not shown. The square node represent the predicate that is going to be ana-
lyzed, (there can be multiple predicates in a single sentence). Semi-dotted arrows between a square
node and an ellipse node represent a semantic relation. This arrow has a semantic tag (A1, A2, A3
and A4).
The grey shadow contains all the nodes of the sub tree for the &amp;quot;rose&amp;quot; predicate.
The dotted double arrows between the nodes of both sentences represent the tree distance alignment
for both sub-trees. In this particular case every single node is matched.
Both predicate nodes are samples of the frame &amp;quot;raise&amp;quot; sense 01 (which means &amp;quot;go up quantifiably&amp;quot;)
where the core arguments are:
A0: Agent, causer of motion A1: Logical subject, patient, thing rising
A2: EXT, amount raised A3: Start point A4: End point AM: Medium
Tai (1979) introduced a criterion for matching
nodes between tree representations (or convert-
ing one tree into another one) and (Shasha &amp;
Zhang, 1990; Zhang &amp; Shasha, 1989) developed
an algorithm that finds an optimal matching tree
solution for any given pair of trees. The advan-
tage of this algorithm is that its computational
cost is low. The optimal matching depends on
the defined atomic cost of matching two nodes.
</bodyText>
<sectionHeader confidence="0.992983" genericHeader="method">
4 Tree SRL system architecture
</sectionHeader>
<bodyText confidence="0.999731428571429">
For the training and testing data set, all possible
sub-trees were extracted. Figure 3 and Figure 5
describe the process. Then, using the tree dis-
tance algorithm, the test sub-trees are labelled
using the training ones. Finally, the predicted
labels get assembled on the original sentence
where the test sub-tree came from. Figure 2 de-
scribes the process.
A sub-tree extracted from a sentence, contains
a predicate node, all its argument nodes and all
the ancestors up to the first common ancestor of
all nodes. (Figure 1 shows two samples of sub-
tree extraction. Figure 3 describes how sub trees
are obtained)
</bodyText>
<page confidence="0.99438">
80
</page>
<bodyText confidence="0.9842815">
Input: training data set (labelled)
Input: testing data set (unlabelled)
Output: testing data set (labelled)
Load training and testing data;
Adapt the trees for the tree distance algorithm;
foreach sentence (training &amp; testing data) do
obtain each minimal sub-tree for each pre-
dicate;
</bodyText>
<subsectionHeader confidence="0.77845">
end
</subsectionHeader>
<bodyText confidence="0.859231">
foreach sub-tree T from the testing data do
calculate the distance and the alignment
from T to each training sub-tree;
sort the list of alignments by ascending
tree distance;
use the list to label the sub-tree T;
Assemble T labels on the original sentence
End
</bodyText>
<figureCaption confidence="0.999523">
Figure 2: Tree SRL system pseudo code
Figure 3: Sub-tree extraction sample.
</figureCaption>
<bodyText confidence="0.999808416666666">
Assuming that &amp;quot;p&amp;quot; (the square node) is a pre-
dicate node and the nodes &amp;quot;a1&amp;quot; and &amp;quot;a2&amp;quot; are
its arguments (the arguments are defined by
the semantic relations. In this case, the semi-
doted arrows.), the sub-tree extracted from the
above sentence will contain the nodes: &amp;quot;a1&amp;quot;,
&amp;quot;a2&amp;quot;, &amp;quot;p&amp;quot;, all ancestors of &amp;quot;a1&amp;quot;,&amp;quot;a2&amp;quot; and &amp;quot;p&amp;quot;
up to the first common one, in this case node
&amp;quot;u&amp;quot;, which is also included in the sub-tree.
All of the white nodes are not included in the
sub-tree. The straight lines represent syntactic
dependency relations.
</bodyText>
<sectionHeader confidence="0.986789" genericHeader="method">
5 Labelling
</sectionHeader>
<bodyText confidence="0.91376325">
Suppose that in Figure 1, the bottom sentence is
the query, where the grey shadow contains the
sub-tree to be labelled and the top sentence con-
tains the sub-tree sample chosen to label the
query. Then, an alignment between the sample
sub-tree and the query sub-tree suggests labelling
the query sub-tree with A1, A2 and A3, where
the first two labels are right but the last label, A4,
is predicted as A3, so it is wrong.
Input: A sub-tree to be labelled
Input: list of alignments sorted by ascending
tree distance
Output: labelled sub-tree
foreach argument(a) in T do
foreach alignment (ali) in the sorted list do
if there is a semantic relation
</bodyText>
<equation confidence="0.487884714285714">
(ali.function(p),ali.function(a))
Then break loop;
end
end
label relation p-a with the label of the
relation (ali.function(p),ali.function(a));
end
</equation>
<bodyText confidence="0.743784833333333">
p is the node predicate.
a is a node argument.
ali is an alignment between the sub-tree that
has to be labelled and a sub-tree in the train-
ing dataset.
The method function is explained in Figure 3.
</bodyText>
<figureCaption confidence="0.877327">
Figure 4: Labelling a relation. (approach
</figureCaption>
<figure confidence="0.892498470588235">
A)
Input: T: tree structure labelled in post order
traversal
Input: L: list of nodes to be on the sub-tree in
post order traversal
Output: T: Sub-Tree
foreach node x in the list do
mark x as part of the sub-tree;
end
while L contains more than 2 unique values do
[minValue , position]=min(L);
Value = parent(minValue);
Mark value as part of the sub-tree;
L[position] = value;
end
Remove all nodes that are not marked as part
of the sub-tree;
</figure>
<figureCaption confidence="0.999539">
Figure 5: Sub-tree extraction
</figureCaption>
<bodyText confidence="0.999841636363636">
It is not necessary to label a whole sub-tree
(query) using just a single sub-tree sample. How-
ever, if the whole query is labelled using a single
answer sample, the prediction is guaranteed to be
consistent (no repeated argument labels).
Some possible ways to label the semantic rela-
tion using a sorted list of alignments (with each
sub-tree of the training data set) is discussed
ahead. Each sub-tree contains one predicate and
several semantic relations, one for each argument
node.
</bodyText>
<subsectionHeader confidence="0.994123">
5.1 Treating relations independently
</subsectionHeader>
<bodyText confidence="0.9968835">
In this sub-section, the neighbouring sub-trees
for one relation of a sub-tree T refers to the near-
</bodyText>
<page confidence="0.993492">
81
</page>
<bodyText confidence="0.999833047619048">
est sub-trees with which the match with T pro-
duces a match between two predicate nodes and
two argument nodes. A label from the nearest
neighbour(s) can be transferred to T for labelling
the relation.
The current implementation (Approach A),
described in more detail in Figure 4, labels a re-
lation using the first nearest neighbour from a list
ordered by ascending tree distance. If there are
several nearest neighbours, the first one on the
list is used. This is a naive implementation of the
k-NN algorithm where in case of multiple near-
est neighbours only one is used and the others
get ignored.
A negative aspect of this strategy is that it can
select a different sub-tree based on the input or-
der. This makes the algorithm indeterministic. A
way to make it deterministic can be by extending
the parameter &amp;quot;k&amp;quot; in case of multiple cases at the
same distance or a tie in the voting (Approach
B).
</bodyText>
<subsectionHeader confidence="0.997392">
5.2 Treating relations dependently
</subsectionHeader>
<bodyText confidence="0.999941722222222">
In this section, a sample refers to a sub-tree con-
taining all arguments and its labels. The argu-
ments for a certain predicate are related.
Some strategies can lead to non-consistent
structures (core argument labels cannot appear
twice in the same sub-tree). Approach B treats
the relations independently. It does not have any
mechanism to keep the consistency of the whole
predicate structure.
Another way is to find a sample that contains
enough information to label the whole sub-tree
(Approach C). This approach always generates
consistent structures. The limitation of this
model is that the required sample may not exist
or the tree distance may be very high, making
those samples poor predictors. The implemented
method (Approach A) indirectly attempts to find
a training sample sub-tree which contains labels
for all the arguments of the predicate.
It is expected for tree distances to be smaller
than other sub-trees that do not have information
to label all the desired relations.
The system tries to get a consistent structure
using a simple algorithm. Only in the case when
using the nearest tree does not lead to labelling
the whole structure, labels are predicted using
multiple samples, thereby, risking the structure
consistency.
Future implementations will rank possible
candidate labels for each relation (probably using
multiple samples).
A &amp;quot;joint scoring algorithm&amp;quot;, which is com-
monly used (Marquez et al, 2008), can be applied
for consistency checking after finding the rank
probability for all the argument labels for the
same predicate (Approach D).
</bodyText>
<sectionHeader confidence="0.984003" genericHeader="method">
6 Experiments: the matching cost
</sectionHeader>
<bodyText confidence="0.9997705">
The cost of matching two nodes is crucial to the
performance of the system. Different atomic
measures (ways to measure the cost of matching
two nodes) that were tested are explained ahead.
Results for experiments using these atomic
measures are given in Table 2.
</bodyText>
<subsectionHeader confidence="0.999588">
6.1 Binary system
</subsectionHeader>
<bodyText confidence="0.999827571428571">
For Binary system, the atomic cost of matching
two nodes is one if label POS or dependency re-
lations are different, otherwise the cost is zero.
The atomic cost of inserting or deleting a node is
always one. Note that the measure is totally
based on the syntactic structure (words are not
used).
</bodyText>
<subsectionHeader confidence="0.999439">
6.2 Ternary system
</subsectionHeader>
<bodyText confidence="0.999993857142857">
The next intuitive measure is how the system
would perform in case of a ternary cost (ternary
system). The atomic cost is half if POS or de-
pendency relation is different, one if POS and
dependency relation are different or zero in all
other case. For this system, Table 2 shows a very
similar accuracy to the binary one.
</bodyText>
<subsectionHeader confidence="0.999859">
6.3 Hamming system
</subsectionHeader>
<bodyText confidence="0.999989">
The atomic cost of matching two nodes is the
sum of the following sub costs:
</bodyText>
<equation confidence="0.847861666666667">
0.25 if POS is different.
0.25 if dependency relation is different.
0.25 if Lemma is different.
</equation>
<bodyText confidence="0.991598666666667">
0.25 if one node is a predicate but the other is
not or if both nodes are predicates but with
different lemma.
The cost to create or delete nodes is one.
Note that the sum of all costs cannot be
greater than one.
</bodyText>
<subsectionHeader confidence="0.997705">
6.4 Predicate match system
</subsectionHeader>
<bodyText confidence="0.998978142857143">
The analysis of results for the previous systems
shows that the accuracy is higher for the sub-
trees that are labelled using sub-trees with the
same predicate node. Consequently, this strategy
attempts to force the predicate to be the same.
In this system, the atomic cost of matching two
nodes is the sum of the following sub costs:
</bodyText>
<page confidence="0.983641">
82
</page>
<bodyText confidence="0.824690166666667">
0.3 if POS is different.
0.3 if dependency relation is different.
1 if one is a predicate and the other node
is not or both nodes are predicates but
with different lemma.
The cost to create or delete nodes is one.
</bodyText>
<subsectionHeader confidence="0.99906">
6.5 Complex system
</subsectionHeader>
<bodyText confidence="0.999033947368421">
This strategy attempts to improve the accuracy
by adding an extra label to the argument nodes
and using it.
The atomic cost of matching two nodes is the
sum of the following sub costs:
0.1 for each different label (dependency rela-
tion or POS or lemma).
0.1 for each pair of different labels (depend-
ency relation or POS or lemma).
0.4 if one node is a predicate and the other is
not.
0.4 if both nodes are predicates and lemma is
different.
2 if one node is marked as an argument and
the other is not or one node is marked as a
predicate and the other is not.
The atomic cost of deleting or inserting a node
is: two if the node is an argument or predicate
node and one in any other case.
</bodyText>
<sectionHeader confidence="0.999719" genericHeader="evaluation">
7 Results
</sectionHeader>
<bodyText confidence="0.9993208">
Table 2 shows the accuracy of all the systems.
The validation data set is added to the training
data set when the system is labelling the evalua-
tion data set. This is a common methodology
followed in CoNLL2009 (Li et al, 2009).
</bodyText>
<table confidence="0.998243">
System Evaluation Development
Binary 64.36% 61.12%
Ternary 64.88% 61.28%
Hamming 78.01%
Predicate 76.98%
Match
Complex 78.98%
</table>
<tableCaption confidence="0.997477">
Table 2: System accuracy
</tableCaption>
<bodyText confidence="0.9955248">
Accuracy is measured as the percentage of se-
mantic labels correctly predicted.
The implementation of the Tree SRL system
takes several days to run a single experiment. It
makes non viable the idea of using the develop-
ment data set for adjusting parameters and that is
why, for the last three systems (Hamming, Predi-
cate Match and Complex), the accuracy over the
development data set is not measured. The same
reason supports adding the development data set
to the training data set without over fitting the
system, because the development data set is not
really used for adjusting parameters.
However, the observations of the system on the
development data set shows:
</bodyText>
<listItem confidence="0.971627058823529">
1. If the complexity gets increased (Ternary),
the number of cases having the multiple
nearest sub-trees gets reduced.
2. The output of the system only contains five
per cent of inconsistent structures (Binary
and Ternary), which is lower than expected.
0.5% of inconsistent sub-trees were de-
tected in the training data-set.
3. Higher accuracy for the relations where a
sub-tree is labelled using a sub-tree sample
which has the same predicate node. This has
led to the design of the &amp;quot;predicate match&amp;quot;
and the &amp;quot;complex&amp;quot; systems.
4. Some sub-trees are very small (just one
node). This resulted in low accuracy for
they predicted labels due to multiple nearest
neighbours.
</listItem>
<bodyText confidence="0.988957454545455">
It is surprising that the hamming measure
reaches higher accuracy than the &amp;quot;predicate
match&amp;quot;, which uses more information, and is also
surprising that the accuracies for &amp;quot;Hamming&amp;quot;,
&amp;quot;Predicate Match&amp;quot; and &amp;quot;Complex&amp;quot; systems are
very similar.
The CoNLL-2009 SRL shared task was evalu-
ated on multiple languages: Catalan, Chinese,
Czech, English, German, Japanese and Spanish.
Some results for those languages using &amp;quot;Tree
SRL System Binary&amp;quot; are shown in Table 3.
</bodyText>
<table confidence="0.996660461538462">
Language Accuracy on Training data
evaluation set size in Mb
English 64.36% 56
Spanish 57.86% 46
Catalan 58.49% 43
Japanese 50.71% 8
German These languages had been ex-
cluded from the experiments be-
cause some of the sentences did
not follow a dependency tree struc-
ture.
Czech
Chinese
</table>
<tableCaption confidence="0.997533">
Table 3: Accuracy for other languages
</tableCaption>
<bodyText confidence="0.9740157">
(Binary system)
The accuracy results for multiple languages
suggest that the size of the corpora has a strong
influence on the results of the system perform-
ance.
The results are not comparable with the rest of
the CoNLL-2009 systems because the task is
different. This system does not identify argu-
ments and does not perform predicate sense dis-
ambiguation.
</bodyText>
<page confidence="0.998508">
83
</page>
<sectionHeader confidence="0.996706" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999918642857143">
The tree distance algorithm has been applied
successfully to build a SRL system. Future work
will focus on improving the performance of the
system by: a) trying to extend the sub-trees
which will contain more contextual information,
b) using different approaches to label semantic
relations discussed in Section 5. Also, the system
will be expanded to identify arguments using a
tree distance algorithm.
Evaluating the task of identifying the argu-
ments and labelling the relations separately will
assist in determining which systems to combine
to create an hybrid system with better perform-
ance.
</bodyText>
<sectionHeader confidence="0.99837" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.992667">
This research is supported by the Science Foun-
dation Ireland (Grant 07/CE/I1142) as part of the
Centre for Next Generation Localisation
(www.cngl.ie) at Trinity College Dublin.
Thanks are due to Dr Martin Emms for his sup-
port on the development of this project.
</bodyText>
<sectionHeader confidence="0.998181" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999316515151515">
Martin Emms. 2006. Variants of Tree Similarity in
a Question Answering Task. In Proceedings of
the Workshop on Linguistic Distances, held in
conjunction with COLING 2006, 100—108, Syd-
ney, Australia, Asociation for Computational Lin-
guistics.
Jan Hajič, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Ka-wahara, Maria Antonia Martí,
Luis Màrquez, Adam Meyers, Joakim Nivre, Se-
bastian Padó, Jan gtěpánek, Pavel Stravnák, Mihai
Surdeanu, Nianwen Xue and Yi Zhang. 2009. The
CoNLL-2009 shared task: syntactic and se-
mantic dependencies in multiple languages. In
CoNLL &apos;09: Proceedings of the Thirteenth Confe-
rence on Computational Natural Language Learn-
ing (pp. 1-18). Morristown, NJ, USA: Association
for Computational Linguistics.
Seokhwan Kim, Minwoo Jeong and Gary Geunbae
Lee. 2009. A Local Tree Alignment-based Soft
Pattern Matching Approach for Information
Extraction. Proceedings of NAAACL HLT, 169-
172. Boulder, Colorado, June 2009
Milen Kouylekov and Bernardo Magnini. 2005. Re-
cognizing textual entailment with tree edit
distance algorithms. In Recognizing Textual En-
tailment (pp. 17-20). Southampton, U.K.
Baoli Li, Martin Emms, Saturnino Luz and Carl Vo-
gel. 2009. Exploring multilingual semantic role
labeling. In CoNLL &apos;09: Proceedings of the Thir-
teenth Conference on Computational Natural Lan-
guage Learning (pp. 73-78). Morristown, NJ,
USA: Association for Computational Linguistics.
Mitchell Marcus, Beatrice Santorini and Mary Ann
Marcinkiewicz. 1994. Building a large anno-
tated corpus of Eng-lish: The Penn Treebank.
Computational linguistics, 19(2), 313–330.
Alessandro Moschitti, Daniele Pighin and Roberto
Basili. 2008. Tree kernels for semantic role
labeling. Computational Linguistics, 34(2), 193-
224. Cambridge, MA, USA: MIT Press.
Lluis Màrquez, Xavier Carreras, Kenneth. C.
Litkowski and Suzanne Stevenson. 2008. Seman-
tic Role Labeling: An Introduction to the Spe-
cial Issue. Computational Linguistics, 34(2), 145-
159.
Martha Palmer, Paul Kingsbury and Daniel Gildea.
2005. The Proposition Bank: An Annotated
Corpus of Semantic Roles. Computational Lin-
guistics, 31(1), 71-106.
Vasin Punyakanok, Dan Roth and Wen-tau Yih. 2004.
Mapping dependencies trees: An application
to question answering. In Proceedings of
AI\&amp;Math 2004 (pp. 1-10). Ford.
Dennis Shasha and Kaizhong Zhang. 1990. Fast al-
gorithms for the unit cost editing distance be-
tween trees. J. Algorithms, 11(4), 581-621. Du-
luth, MN, USA: Academic Press, Inc.
Kuo-Chung Tai. 1979. The Tree-to-Tree Correc-
tion Problem. J. ACM, 26(3), 422-433. New
York, NY, USA: ACM.
Kaizhong Zhang and Dennis Shasha. 1989. Simple
fast algorithms for the editing distance be-
tween trees and related problems. SIAM J.
Comput., 18(6), 1245-1262. Philadelphia, PA,
USA: Society for Industrial and Applied Mathe-
matics.
</reference>
<page confidence="0.999236">
84
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.667979">
<title confidence="0.999169">Edit Tree Distance alignments for Semantic Role Labelling</title>
<author confidence="0.955195">Hector-Hugo Franco-Penya</author>
<affiliation confidence="0.997671">Trinity College Dublin</affiliation>
<address confidence="0.946171">Dublin, Ireland.</address>
<email confidence="0.998631">francoph@cs.tcd.ie</email>
<abstract confidence="0.942582272727273">SRL system&amp;quot; is a Role Labelling supervised system based on a tree-distance algorithm and a simple k-NN implementation. The novelty of the system lies in comparing the sentences as tree structures with multiple relations instead of extracting vectors of features for each relation and classifying them. The system was tested with the English CoNLL-2009 shared task data set where 79% accuracy was obtained.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Martin Emms</author>
</authors>
<title>Variants of Tree Similarity in a Question Answering Task.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Linguistic Distances, held in conjunction with COLING 2006, 100—108,</booktitle>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia, Asociation</location>
<contexts>
<context position="3151" citStr="Emms, 2006" startWordPosition="505" endWordPosition="506">uilt using constituent tree structures, but here only the dependency tree structure version was used. Note that dependency tree structures have labels on the arrows. The tree distance algorithm cannot work with these labelled arrows and so they are moved to the child node as an extra label. The task performed by the Tree SRL system consists of labelling the relations (predicate arguments) which are assumed to be already identified. 3 Tree Distance The tree distance algorithm has already been applied to text entailment (Kouylekov &amp; Magnini, 2005) and question answering (Punyakanok et al, 2004; Emms, 2006) with positive results. The main contribution of this piece of work to the SRL field is the inclusion of the tree distance algorithm into an SRL system, working with tree structures in contrast to the classical &amp;quot;feature extraction&amp;quot; and &amp;quot;classification&amp;quot;. Kim et al (2009) developed a similar system for Information Extraction. 79 Proceedings of the ACL 2010 Student Research Workshop, pages 79–84, Uppsala, Sweden, 13 July 2010. c�2010 Association for Computational Linguistics Figure 1: Alignment sample A two sentence sample, in a dependency tree representation. In each node, the word form and the </context>
</contexts>
<marker>Emms, 2006</marker>
<rawString>Martin Emms. 2006. Variants of Tree Similarity in a Question Answering Task. In Proceedings of the Workshop on Linguistic Distances, held in conjunction with COLING 2006, 100—108, Sydney, Australia, Asociation for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jan Hajič</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Ka-wahara</author>
<author>Maria Antonia Martí</author>
<author>Luis Màrquez</author>
<author>Adam Meyers</author>
<author>Joakim Nivre</author>
<author>Sebastian Padó</author>
</authors>
<title>gtěpánek, Pavel Stravnák, Mihai Surdeanu, Nianwen Xue and Yi Zhang.</title>
<date></date>
<booktitle>In CoNLL &apos;09: Proceedings of the Thirteenth Conference on Computational Natural Language Learning</booktitle>
<pages>1--18</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA:</location>
<marker>Hajič, Ciaramita, Johansson, Ka-wahara, Martí, Màrquez, Meyers, Nivre, Padó, </marker>
<rawString>Jan Hajič, Massimiliano Ciaramita, Richard Johansson, Daisuke Ka-wahara, Maria Antonia Martí, Luis Màrquez, Adam Meyers, Joakim Nivre, Sebastian Padó, Jan gtěpánek, Pavel Stravnák, Mihai Surdeanu, Nianwen Xue and Yi Zhang. 2009. The CoNLL-2009 shared task: syntactic and semantic dependencies in multiple languages. In CoNLL &apos;09: Proceedings of the Thirteenth Conference on Computational Natural Language Learning (pp. 1-18). Morristown, NJ, USA: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seokhwan Kim</author>
<author>Minwoo Jeong</author>
<author>Gary Geunbae Lee</author>
</authors>
<title>A Local Tree Alignment-based Soft Pattern Matching Approach for Information Extraction.</title>
<date>2009</date>
<booktitle>Proceedings of NAAACL HLT,</booktitle>
<pages>169--172</pages>
<location>Boulder, Colorado,</location>
<contexts>
<context position="3421" citStr="Kim et al (2009)" startWordPosition="548" endWordPosition="551">ld node as an extra label. The task performed by the Tree SRL system consists of labelling the relations (predicate arguments) which are assumed to be already identified. 3 Tree Distance The tree distance algorithm has already been applied to text entailment (Kouylekov &amp; Magnini, 2005) and question answering (Punyakanok et al, 2004; Emms, 2006) with positive results. The main contribution of this piece of work to the SRL field is the inclusion of the tree distance algorithm into an SRL system, working with tree structures in contrast to the classical &amp;quot;feature extraction&amp;quot; and &amp;quot;classification&amp;quot;. Kim et al (2009) developed a similar system for Information Extraction. 79 Proceedings of the ACL 2010 Student Research Workshop, pages 79–84, Uppsala, Sweden, 13 July 2010. c�2010 Association for Computational Linguistics Figure 1: Alignment sample A two sentence sample, in a dependency tree representation. In each node, the word form and the position of the word in the sentence are shown. Straight arrows represent syntactic dependencies. The label of the dependency is not shown. The square node represent the predicate that is going to be analyzed, (there can be multiple predicates in a single sentence). Sem</context>
</contexts>
<marker>Kim, Jeong, Lee, 2009</marker>
<rawString>Seokhwan Kim, Minwoo Jeong and Gary Geunbae Lee. 2009. A Local Tree Alignment-based Soft Pattern Matching Approach for Information Extraction. Proceedings of NAAACL HLT, 169-172. Boulder, Colorado, June 2009</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milen Kouylekov</author>
<author>Bernardo Magnini</author>
</authors>
<title>Recognizing textual entailment with tree edit distance algorithms.</title>
<date>2005</date>
<booktitle>In Recognizing Textual Entailment</booktitle>
<pages>17--20</pages>
<location>Southampton, U.K.</location>
<contexts>
<context position="3091" citStr="Kouylekov &amp; Magnini, 2005" startWordPosition="494" endWordPosition="497">re: A1:35%, A0:20.86%, A2:7.88% and AM-TMP: 7.72% Propbank was originally built using constituent tree structures, but here only the dependency tree structure version was used. Note that dependency tree structures have labels on the arrows. The tree distance algorithm cannot work with these labelled arrows and so they are moved to the child node as an extra label. The task performed by the Tree SRL system consists of labelling the relations (predicate arguments) which are assumed to be already identified. 3 Tree Distance The tree distance algorithm has already been applied to text entailment (Kouylekov &amp; Magnini, 2005) and question answering (Punyakanok et al, 2004; Emms, 2006) with positive results. The main contribution of this piece of work to the SRL field is the inclusion of the tree distance algorithm into an SRL system, working with tree structures in contrast to the classical &amp;quot;feature extraction&amp;quot; and &amp;quot;classification&amp;quot;. Kim et al (2009) developed a similar system for Information Extraction. 79 Proceedings of the ACL 2010 Student Research Workshop, pages 79–84, Uppsala, Sweden, 13 July 2010. c�2010 Association for Computational Linguistics Figure 1: Alignment sample A two sentence sample, in a dependen</context>
</contexts>
<marker>Kouylekov, Magnini, 2005</marker>
<rawString>Milen Kouylekov and Bernardo Magnini. 2005. Recognizing textual entailment with tree edit distance algorithms. In Recognizing Textual Entailment (pp. 17-20). Southampton, U.K.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Baoli Li</author>
<author>Martin Emms</author>
<author>Saturnino Luz</author>
<author>Carl Vogel</author>
</authors>
<title>Exploring multilingual semantic role labeling.</title>
<date>2009</date>
<booktitle>In CoNLL &apos;09: Proceedings of the Thirteenth Conference on Computational Natural Language Learning</booktitle>
<pages>73--78</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA:</location>
<contexts>
<context position="14413" citStr="Li et al, 2009" startWordPosition="2426" endWordPosition="2429">ion or POS or lemma). 0.4 if one node is a predicate and the other is not. 0.4 if both nodes are predicates and lemma is different. 2 if one node is marked as an argument and the other is not or one node is marked as a predicate and the other is not. The atomic cost of deleting or inserting a node is: two if the node is an argument or predicate node and one in any other case. 7 Results Table 2 shows the accuracy of all the systems. The validation data set is added to the training data set when the system is labelling the evaluation data set. This is a common methodology followed in CoNLL2009 (Li et al, 2009). System Evaluation Development Binary 64.36% 61.12% Ternary 64.88% 61.28% Hamming 78.01% Predicate 76.98% Match Complex 78.98% Table 2: System accuracy Accuracy is measured as the percentage of semantic labels correctly predicted. The implementation of the Tree SRL system takes several days to run a single experiment. It makes non viable the idea of using the development data set for adjusting parameters and that is why, for the last three systems (Hamming, Predicate Match and Complex), the accuracy over the development data set is not measured. The same reason supports adding the development</context>
</contexts>
<marker>Li, Emms, Luz, Vogel, 2009</marker>
<rawString>Baoli Li, Martin Emms, Saturnino Luz and Carl Vogel. 2009. Exploring multilingual semantic role labeling. In CoNLL &apos;09: Proceedings of the Thirteenth Conference on Computational Natural Language Learning (pp. 73-78). Morristown, NJ, USA: Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of Eng-lish: The Penn Treebank.</title>
<date>1994</date>
<journal>Computational linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>313--330</pages>
<contexts>
<context position="1499" citStr="Marcus et al, 1994" startWordPosition="229" endWordPosition="232">ine events such as &amp;quot;who&amp;quot;, &amp;quot;whom&amp;quot;, &amp;quot;where&amp;quot;, etc, with reference to one predicate. The possible semantic roles are pre-defined for each predicate. The set of roles depends on the corpora. SRL is becoming an important tool for information extraction, text summarization, machine translation and question answering (Màrquez, et al, 2008). 2 The data The data set I used is taken from the CoNLL2009 shared task (Hajič et al., 2009) and is part of Propbank. Propbank (Palmer et al, 2005) is a hand-annotated corpus. It transforms sentences into propositions. It adds a semantic layer to the Penn TreeBank (Marcus et al, 1994) and defines a set of semantic roles for each predicate. It is difficult to define universal semantic roles for all predicates. That is why PropBank defines a set of semantic roles for each possible sense of each predicate (frame) [See a sample of the frame &amp;quot;raise&amp;quot; on the Figure 1 caption]. Sentences predicates arguments Predicates per arguments File size in sentence per sub-tree Mb Tra 39279 179014 393699 4.55 2.20 56.2 Dev 1334 6390 13865 4.79 2.17 1.97 Evl 2399 10498 23286 4.38 2.22 3.41 Table 1: The data The data set is divided into three files: training (Tra), development (Dev) and evalua</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1994</marker>
<rawString>Mitchell Marcus, Beatrice Santorini and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of Eng-lish: The Penn Treebank. Computational linguistics, 19(2), 313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Daniele Pighin</author>
<author>Roberto Basili</author>
</authors>
<title>Tree kernels for semantic role labeling.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<pages>193--224</pages>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA, USA:</location>
<marker>Moschitti, Pighin, Basili, 2008</marker>
<rawString>Alessandro Moschitti, Daniele Pighin and Roberto Basili. 2008. Tree kernels for semantic role labeling. Computational Linguistics, 34(2), 193-224. Cambridge, MA, USA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Litkowski</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Semantic Role Labeling: An Introduction to the Special Issue.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<pages>145--159</pages>
<marker>Litkowski, Stevenson, 2008</marker>
<rawString>Lluis Màrquez, Xavier Carreras, Kenneth. C. Litkowski and Suzanne Stevenson. 2008. Semantic Role Labeling: An Introduction to the Special Issue. Computational Linguistics, 34(2), 145-159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Paul Kingsbury</author>
<author>Daniel Gildea</author>
</authors>
<title>The Proposition Bank: An Annotated Corpus of Semantic Roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<pages>71--106</pages>
<contexts>
<context position="1361" citStr="Palmer et al, 2005" startWordPosition="207" endWordPosition="210">guments for a certain predicate and labelling them. The predicates are usually verbs. They establish &amp;quot;what happened&amp;quot;. The arguments determine events such as &amp;quot;who&amp;quot;, &amp;quot;whom&amp;quot;, &amp;quot;where&amp;quot;, etc, with reference to one predicate. The possible semantic roles are pre-defined for each predicate. The set of roles depends on the corpora. SRL is becoming an important tool for information extraction, text summarization, machine translation and question answering (Màrquez, et al, 2008). 2 The data The data set I used is taken from the CoNLL2009 shared task (Hajič et al., 2009) and is part of Propbank. Propbank (Palmer et al, 2005) is a hand-annotated corpus. It transforms sentences into propositions. It adds a semantic layer to the Penn TreeBank (Marcus et al, 1994) and defines a set of semantic roles for each predicate. It is difficult to define universal semantic roles for all predicates. That is why PropBank defines a set of semantic roles for each possible sense of each predicate (frame) [See a sample of the frame &amp;quot;raise&amp;quot; on the Figure 1 caption]. Sentences predicates arguments Predicates per arguments File size in sentence per sub-tree Mb Tra 39279 179014 393699 4.55 2.20 56.2 Dev 1334 6390 13865 4.79 2.17 1.97 Ev</context>
</contexts>
<marker>Palmer, Kingsbury, Gildea, 2005</marker>
<rawString>Martha Palmer, Paul Kingsbury and Daniel Gildea. 2005. The Proposition Bank: An Annotated Corpus of Semantic Roles. Computational Linguistics, 31(1), 71-106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>Mapping dependencies trees: An application to question answering.</title>
<date>2004</date>
<booktitle>In Proceedings of AI\&amp;Math</booktitle>
<pages>1--10</pages>
<contexts>
<context position="3138" citStr="Punyakanok et al, 2004" startWordPosition="501" endWordPosition="504">ropbank was originally built using constituent tree structures, but here only the dependency tree structure version was used. Note that dependency tree structures have labels on the arrows. The tree distance algorithm cannot work with these labelled arrows and so they are moved to the child node as an extra label. The task performed by the Tree SRL system consists of labelling the relations (predicate arguments) which are assumed to be already identified. 3 Tree Distance The tree distance algorithm has already been applied to text entailment (Kouylekov &amp; Magnini, 2005) and question answering (Punyakanok et al, 2004; Emms, 2006) with positive results. The main contribution of this piece of work to the SRL field is the inclusion of the tree distance algorithm into an SRL system, working with tree structures in contrast to the classical &amp;quot;feature extraction&amp;quot; and &amp;quot;classification&amp;quot;. Kim et al (2009) developed a similar system for Information Extraction. 79 Proceedings of the ACL 2010 Student Research Workshop, pages 79–84, Uppsala, Sweden, 13 July 2010. c�2010 Association for Computational Linguistics Figure 1: Alignment sample A two sentence sample, in a dependency tree representation. In each node, the word </context>
</contexts>
<marker>Punyakanok, Roth, Yih, 2004</marker>
<rawString>Vasin Punyakanok, Dan Roth and Wen-tau Yih. 2004. Mapping dependencies trees: An application to question answering. In Proceedings of AI\&amp;Math 2004 (pp. 1-10). Ford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dennis Shasha</author>
<author>Kaizhong Zhang</author>
</authors>
<title>Fast algorithms for the unit cost editing distance between trees.</title>
<date>1990</date>
<journal>J. Algorithms,</journal>
<volume>11</volume>
<issue>4</issue>
<pages>581--621</pages>
<publisher>Academic Press, Inc.</publisher>
<location>Duluth, MN, USA:</location>
<contexts>
<context position="4827" citStr="Shasha &amp; Zhang, 1990" startWordPosition="777" endWordPosition="780">sub tree for the &amp;quot;rose&amp;quot; predicate. The dotted double arrows between the nodes of both sentences represent the tree distance alignment for both sub-trees. In this particular case every single node is matched. Both predicate nodes are samples of the frame &amp;quot;raise&amp;quot; sense 01 (which means &amp;quot;go up quantifiably&amp;quot;) where the core arguments are: A0: Agent, causer of motion A1: Logical subject, patient, thing rising A2: EXT, amount raised A3: Start point A4: End point AM: Medium Tai (1979) introduced a criterion for matching nodes between tree representations (or converting one tree into another one) and (Shasha &amp; Zhang, 1990; Zhang &amp; Shasha, 1989) developed an algorithm that finds an optimal matching tree solution for any given pair of trees. The advantage of this algorithm is that its computational cost is low. The optimal matching depends on the defined atomic cost of matching two nodes. 4 Tree SRL system architecture For the training and testing data set, all possible sub-trees were extracted. Figure 3 and Figure 5 describe the process. Then, using the tree distance algorithm, the test sub-trees are labelled using the training ones. Finally, the predicted labels get assembled on the original sentence where the</context>
</contexts>
<marker>Shasha, Zhang, 1990</marker>
<rawString>Dennis Shasha and Kaizhong Zhang. 1990. Fast algorithms for the unit cost editing distance between trees. J. Algorithms, 11(4), 581-621. Duluth, MN, USA: Academic Press, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuo-Chung Tai</author>
</authors>
<title>The Tree-to-Tree Correction Problem.</title>
<date>1979</date>
<journal>J. ACM,</journal>
<volume>26</volume>
<issue>3</issue>
<pages>422--433</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA:</location>
<contexts>
<context position="4688" citStr="Tai (1979)" startWordPosition="757" endWordPosition="758"> represent a semantic relation. This arrow has a semantic tag (A1, A2, A3 and A4). The grey shadow contains all the nodes of the sub tree for the &amp;quot;rose&amp;quot; predicate. The dotted double arrows between the nodes of both sentences represent the tree distance alignment for both sub-trees. In this particular case every single node is matched. Both predicate nodes are samples of the frame &amp;quot;raise&amp;quot; sense 01 (which means &amp;quot;go up quantifiably&amp;quot;) where the core arguments are: A0: Agent, causer of motion A1: Logical subject, patient, thing rising A2: EXT, amount raised A3: Start point A4: End point AM: Medium Tai (1979) introduced a criterion for matching nodes between tree representations (or converting one tree into another one) and (Shasha &amp; Zhang, 1990; Zhang &amp; Shasha, 1989) developed an algorithm that finds an optimal matching tree solution for any given pair of trees. The advantage of this algorithm is that its computational cost is low. The optimal matching depends on the defined atomic cost of matching two nodes. 4 Tree SRL system architecture For the training and testing data set, all possible sub-trees were extracted. Figure 3 and Figure 5 describe the process. Then, using the tree distance algorit</context>
</contexts>
<marker>Tai, 1979</marker>
<rawString>Kuo-Chung Tai. 1979. The Tree-to-Tree Correction Problem. J. ACM, 26(3), 422-433. New York, NY, USA: ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kaizhong Zhang</author>
<author>Dennis Shasha</author>
</authors>
<title>Simple fast algorithms for the editing distance between trees and related problems.</title>
<date>1989</date>
<journal>SIAM J. Comput.,</journal>
<volume>18</volume>
<issue>6</issue>
<pages>1245--1262</pages>
<location>Philadelphia, PA, USA:</location>
<contexts>
<context position="4850" citStr="Zhang &amp; Shasha, 1989" startWordPosition="781" endWordPosition="784">&amp;quot; predicate. The dotted double arrows between the nodes of both sentences represent the tree distance alignment for both sub-trees. In this particular case every single node is matched. Both predicate nodes are samples of the frame &amp;quot;raise&amp;quot; sense 01 (which means &amp;quot;go up quantifiably&amp;quot;) where the core arguments are: A0: Agent, causer of motion A1: Logical subject, patient, thing rising A2: EXT, amount raised A3: Start point A4: End point AM: Medium Tai (1979) introduced a criterion for matching nodes between tree representations (or converting one tree into another one) and (Shasha &amp; Zhang, 1990; Zhang &amp; Shasha, 1989) developed an algorithm that finds an optimal matching tree solution for any given pair of trees. The advantage of this algorithm is that its computational cost is low. The optimal matching depends on the defined atomic cost of matching two nodes. 4 Tree SRL system architecture For the training and testing data set, all possible sub-trees were extracted. Figure 3 and Figure 5 describe the process. Then, using the tree distance algorithm, the test sub-trees are labelled using the training ones. Finally, the predicted labels get assembled on the original sentence where the test sub-tree came fro</context>
</contexts>
<marker>Zhang, Shasha, 1989</marker>
<rawString>Kaizhong Zhang and Dennis Shasha. 1989. Simple fast algorithms for the editing distance between trees and related problems. SIAM J. Comput., 18(6), 1245-1262. Philadelphia, PA, USA: Society for Industrial and Applied Mathematics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>