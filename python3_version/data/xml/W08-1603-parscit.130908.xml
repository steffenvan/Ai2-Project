<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.996876">
Know-Why Extraction from Textual Data for Supporting What
Question
</title>
<author confidence="0.939402">
Chaveevan Pechsiri
</author>
<affiliation confidence="0.6666305">
Dept. of Information
Technology,
DhurakijPundit University,
Bangkok, Thailand
</affiliation>
<email confidence="0.991315">
itdpu@hotmail.com
</email>
<author confidence="0.765128">
Phunthara Sroison
</author>
<affiliation confidence="0.55188525">
Dept. of Information
Technology,
DhurakijPundit University,
Bangkok, Thailand
</affiliation>
<email confidence="0.995856">
phunthara@it.dpu.ac.th
</email>
<author confidence="0.92883">
U. Janviriyasopak
</author>
<affiliation confidence="0.8975645">
Eastern Industry Co.ltd.
Bangkok, Thailand
</affiliation>
<email confidence="0.995513">
uraiwanjan@hotmail.com
</email>
<sectionHeader confidence="0.995598" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999873944444445">
This research aims to automatically ex-
tract Know-Why from documents on the
website to contribute knowledge sources
to support the question-answering sys-
tem, especially What-Question, for dis-
ease treatment. This paper is concerned
about extracting Know-Why based on
multiple EDUs (Elementary Discourse
Units). There are two problems in ex-
tracting Know-Why: an identification
problem and an effect boundary determi-
nation problem. We propose using Naïve
Bayes with three verb features, a causa-
tive-verb-phrase concept set, a supporting
causative verb set, and the effect-verb-
phrase concept set. The Know-Why ex-
traction results show the success rate of
85.5% precision and 79.8% recall.
</bodyText>
<sectionHeader confidence="0.998966" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999100230769231">
Automatically Know -Why extraction is essential
for providing the rational knowledge source, to
the society through question answering system,
especially in herbal medicines when assisting the
locals to understand more about herbs.
According to Jana Trnkova and Wolfgang
Theilmann (2004) Know-Why is the knowing of
the reason of why something is the way it is.
Therefore, Know-Why has to involve the causal
relation which is “an irreflexive, transitive and
asymmetrical” relation that contains the
properties of “productivity (effect is ‘produced’
by the cause) and locality (it obeys the markov
</bodyText>
<footnote confidence="0.9517505">
© 2008. Licensed under the Creative Commons Attri-
bution-Noncommercial-Share Alike 3.0 Unported
license (http://creativecommons.org/licenses/by-nc-
sa/3.0/). Some rights reserved.
</footnote>
<bodyText confidence="0.996541925">
condition, for model A4 B 4 C, if there is no
B, then A does not cause C)”( Lemeire J. et al.
(2004)). Wolff P. (2007) stated that the causal
relation can be decomposed into 2 major
approaches, the dependency model and the
physicalist models. The dependency model can
be represented by using statistical dependency
model whereas in recent physicalist models are
based on the concepts of force dynamic models
consisting of 2 force entities in certain events;
the agonist and the antagonist (Talmy, 2000).
Later, the agonist form (Wolff P., 2007) can be
viewed as the ‘effect’ and the antagonist as the
‘cause’. According to Talmy (2000), if there is a
situation where the antagonist is stronger, which
can be expressed as ‘event X happens because of
event Y’(Y contains the antagonist.), it is a form
of causation. Moreover, the causal relation can
pivot on the distinction between causality and
causation (Lehmann J. et al, 2004) whereas
causality is ‘a law-like relation between cause
events and effect events’ and causation is ‘the
actual causal relation that holds between
individual events’. For example:
“Because a bird sings a song at a window, The
rock is thrown at the window.”
Causality: “An object vibrates. An object
moves.”
Causation: “A bird sings. The rock is thrown”
This research focuses only on ‘causal relation’ to
provide both ‘causality’ for extracting Know-
Why from the herbal medicine domain and
‘causation’ for answering What-question, since
what questions contain ambiguities (Girju R. and
Moldovan D., 2002) for example:
Know-Why: “7ummmiNrAguen vnv un®EOuY unshotvioc /A
basil leaf is used as a medicine releasing gas.
[The leaf] stops nausea. [The leaf] stops paining
the abdomen.” (where the [..] symbol means
ellipsis.)
</bodyText>
<page confidence="0.988987">
17
</page>
<reference confidence="0.3478875">
Coling 2008: Proceedings of the workshop on Knowledge and Reasoning for Answering Questions, pages 17–24
Manchester, August 2008
</reference>
<bodyText confidence="0.990512564516129">
Know-Why concept: “A herb organ is used as
being a carminative drug. [The organ] is anti
nausea, [The organ] is anti stomachache.”
Question: “�������������������������/What herb is used
for stopping nausea?” From this example, ‘A
basil leaf is used as a medicine releasing gas’ is
the causation and the concept is the causality.
There are various forms of causal-
relation expression such as in the form of intra-
NP, inter-NP, and inter-sentence (Chang and
Choi,2004). According to our research, we
separated this relation into 2 main forms based
on the elementary discourse unit (EDU) as
defined by (Carlson et al., 2003) as a simple
sentence or clause. We defined the intra-causal
EDU as an expression within one simple EDU
being equivalent to either the intra-NP form or
the inter-NP form (Chang and Choi,2004). The
inter-causal EDU is defined as an expression
within more than one simple EDU which is
equivalent to the inter-sentences of Chang and
Choi (2004). However, this paper works on only
the inter-causal EDU extraction because some
cause-effect relation from the herbal web sites
are expressed in the form of the EDU containing
an EDU-like name entity with the causative
action followed by some effect EDUs.
Several techniques (Marcu and Echihabi,2002;
Torisawa 2003; Inui and et al.,2004; Pechsiri
and Kawtrakul, 2007) have been used to extract
cause-effect knowledge varying from two
adjacent sentences to multiple sentences. Our
work aimed at mining and extracting Know-Why
from Thai documents of herbal medicines. Thai
has several specific characteristics, such as the
existence of sentence-like name entity, zero
anaphora or the implicit noun phrase. All of
these characteristics are involved in the two main
problems of Know-Why extraction: the first
problem is how to identify the interesting
causality events expressed by an EDU- like name
entity from documents, and the second one is
how to identify the effect boundary, where The
problem of implicit delimiter of the boundary is
involved. From all of these problems, we needed
to develop a framework which combineed
Language Processing and the machine learning
technique as Naïve Bayes to learn features of
three verb sets, a causative concept verb set, a
supporting causative verb set, and an effect
concept verb set, for solving those problems.
In conclusion, unlike other methods (Marcu
and Echihabi ,2002; Torisawa 2003; Inui and et
al.,2004) where the emphasis is based on two
adjacent sentences, this paper is based on
multiple EDU extraction. Our research was
separated into 5 sections. In section 2, related
work was summarized. Problems in causality
mining from Thai documents will be described in
section 3 and in section 4 our framework for
causality extraction was explained. In section 5,
we evaluated and concluded our proposed model.
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999978155555556">
Several strategies such as those done by Marcu
and Echihabi ,2002, Torisawa( 2003), Inui and et
al.(2004), and Pechsiri and Kawtrakul (2007)
have been proposed to extract and discover
knowledge from the textual data.
Marcu and Echihabi (2002) presented the
unsupervised approach to recognize the discourse
relations by using word pair probabilities
between two adjacent sentences for classifying
the rhetorical relations, such as Contrast, Cause-
Explanation, Condition, and Elaboration,
between two adjacent sentences by using Naïve
Bayes classifier to the BLIPP corpus (Charniak,
2000). They determined the word pairs in the
cartesian product from the sentence pairs
connected with or without discourse marker or
connective marker , i.e. ‘because’ ‘but’ ‘then’, to
classify the causal relation from other rhetorical
relations. The result showed an accuracy of 75%
of inter-sentence causality extraction from the
corpus size of more than a million sentences for
learning whereas our corpus size is 3000
sentences for learning. Therefore, our approach
is the supervised approach with the statistical
method because our corpus size is small.
Inui’s work (Inui and et al.,2004) proposed a
method of extraction and classification of causal
knowledge. The method of extraction was
accomplished under two adjacent sentences by
using explicit connective markers; e.g. “because”
“since” “if..then” “as the result” etc.. SVM was
used for the classification process in (Inui and et
al.,2004). Four types of causal relations are
studied, including the following: cause,
precondition, mean, effect relations. Inui’s
work’s precision is high: 90% but the recall is
low: 30%, because of unresolved anaphora.
However, in our work, we extract multiple EDUs
with some implicit discourse markers.
Torisawa( 2003)’ s work in extracting the verb
phrase pair from the news corpus worked on the
assumption that if two events share a common
participant (is specified by a noun) then the two
events are likely to have a logical relation as
causal relation. For example “A man drank
</bodyText>
<page confidence="0.995202">
18
</page>
<bodyText confidence="0.987076279069767">
liquor and was intoxicated by the liquor.”(a
common participant is ‘liquor’). However, this
assumption can not be applied in our research
because most of our causality expression does
not share a common participant; e. g. “;A419uen
medicine. [The ginger] stops constipation.
Pechsiri and Kawtrakul (2007), proposed
verb-pair rules learned by two different machine
learning techniques (NB and SVM) to extract
causality with multiple EDUs of a causative unit
and multiple EDUs of an effect unit with the
problems of the discourse marker ambiguity and
the implicit discourse marker. This verb-pair
rule has been represented by the following equa-
tion (1) (Pechsiri and Kawtrakul, 2007) where Vc
is the causative verb concept set, Ve is the effect
verb concept set , C is the Boolean variables of
causality and non-causality, and a causative verb
concept (vc , where vcEVj and an effect verb
concept (ve , where veEVe) are referred to Word-
Net (http://wordnet.princeton.edu/) and the pre-
defined plant disease information from Depart-
ment of Agriculture (http://www.doa.go.th/).
CausalityFunction: Vc A Ve 4 C (1)
They also proposed using Vc and Ve to solve
the boundary of the causative unit and using the
Centering theory along with Ve to solve the
boundary of the effect unit. The outcomes of
their research were the verb-pair rule, Vc, Ve, and
the multiple EDUs of causality (extracted from
textual data) was at their highest precision of
89% and their highest recall of 76%. The cor-
rectness of the causality-boundary determination
is 88% on average. However, our causative unit
consisted of only one EDU containing an EDU-
like name entity as a cause, and this EDU was
followed by several effect EDUs.
In our current work, we aimed at extracting
the Know-Why in Natural Language description
instead of visualizing only associations of
concepts, by applying both language processing
and learning technique by Naïve Bayes to
identify the causality expression.
</bodyText>
<sectionHeader confidence="0.903253" genericHeader="method">
3 Problem of Know-Why Extraction
</sectionHeader>
<bodyText confidence="0.999940285714286">
To extract the cause-effect expressions, there
are two main problems that must be solved. The
first problem is how to identify interesting cause-
effect relations from the documents. The second
problem is how to determine the effect boundary.
There is also the problem of implicit noun
phrase.
</bodyText>
<subsectionHeader confidence="0.999364">
3.1 Causality Identification
</subsectionHeader>
<bodyText confidence="0.964854071428571">
The problem involves the word level and the sen-
tence level. For the word level, the medicinal
name entity may express in the form of a sen-
tence like name entity or an EDU- like name en-
tity which explains the medicinal action as the
causative action of medicine, and medical char-
acteristic. The problem of this level is how to
identify the causative name entity. For example:
a) “lvnTwnTv/A basil leaf 71YOu#is used as av
medicine vv#releases nag#gas”
where ‘a medicine releases gas’ is an EDU-
like name entity with the causative action,
‘release’.
b) “ggflunywi%:d# Nicolson stem 1ti &amp;~#is used for
making a„#medicine oov#soaks in g&apos;dv
liquor”
where ‘a medicine soaks in liquor’ is an
EDU-like name entity with the characteristic
of medicine being preserved in the alcohol.
The above examples, a) and b), contain an
EDU-like name entity which is a cause in a) and
a non cause in b).
For the sentence level, the EDU containing an
EDU-like name entity with the causative action
may be followed by an effect EDU(s) to form the
cause-effect or causality relation between the
EDU like name entity and that following
EDU(s). For example:
</bodyText>
<sectionHeader confidence="0.629821" genericHeader="method">
Causality
</sectionHeader>
<bodyText confidence="0.960384">
EDU1 “(Ans&apos;mi/Lemon grass Iva &amp;quot;s used as
a„#medicine 9wontracts ,agp)nn#a uterus”
(where ‘a medicine contracts a uterus.’ is the
EDU-like name entity with concept of ‘the
medicine causes uterus to contract’.)
EDU2 “[The plant ] vv/discharges i_1=%&amp;~~&amp;&apos;w
period.” (=The plant discharges period.)
</bodyText>
<subsectionHeader confidence="0.980897">
Non causality
</subsectionHeader>
<bodyText confidence="0.999394">
EDU1 “lvnTvnTv/A basil leaf MOu#is used as
a„#medicine vv#releases na#gas.” (where ‘a
medicine releases gas’ is the causative EDU-
like name entity.)
</bodyText>
<equation confidence="0.7629135">
����!&amp;quot;�/Ginger is used as being laxative
����� ���
</equation>
<page confidence="0.733213">
19
</page>
<bodyText confidence="0.7645964">
EDU2 “[the basil leaf]sr*vrelieves u!�#ulcer
lu#innydarndoi&apos;iy#stomach.”(= [The basil leaf re-
lives ulcer in a stomach. )
Where in this example, EDU 1 is the cause
and EDU2 is the effect
</bodyText>
<subsectionHeader confidence="0.999136">
3.2 Effect Boundary Determination
</subsectionHeader>
<bodyText confidence="0.999862">
There are two problems of an implicit effect
boundary cue and the effect EDU containing in-
terrupts.
</bodyText>
<subsubsectionHeader confidence="0.993631">
3.2.1 Implicit Effect Boundary Cue
</subsubsectionHeader>
<bodyText confidence="0.917813705882353">
Some cause-effect relations from the herbal web
sites are expressed in the form of the EDU con-
taining an EDU like name entity with the causa-
tive action followed by some effect EDUs with-
out any cue of ending effect boundary, e.g. “unvi
and”. For example:
EDU1 “hinninT A basil leaf 1%0&amp;quot;s used as Fav
medicine vt,#releases oaa#gas” (=A basil leaf is
used as a medicine releasing gas.)
EDU2 “[The basil leaf ] un&apos;Istops oIUMI nau-
seate.” (=The basil leaf stop being nausea.)
EDU3 “[And the leaf ] un&apos;Istops 91ao/pain rioa#
abdomen.” (= [And the leaf] stops paining
abdomen.)
Where in this example, EDU 1 is the cause
and EDU 2 &amp; EDU3 are the effects. EDU 2
and EDU3 help us to determine the boundary.
</bodyText>
<subsubsectionHeader confidence="0.990531">
3.2.2 Effect EDU Containing Interrupts
</subsubsectionHeader>
<bodyText confidence="0.9693949">
There are some effect EDUs containing inter-
rupts as shown in the following example:
EDU1 “&apos;oijupw#A red onion fads used as ov
medicine +$�n /be laxztive” (=A red onion is
used as a laxative medicine.)
EDU2 “[And the red onion ] un&apos;Istops rioa!&amp;quot;n#
being constipation” (= [And the red onion]
stops being constipation.)
EDU3 “[The red onion ] Udischarges it�trn:d
/urine.” (= [The red onion] discharges urine.)
</bodyText>
<subsubsectionHeader confidence="0.479847">
EDU4 “[The red onion makes a patient] a%F-
</subsubsectionHeader>
<bodyText confidence="0.998137428571429">
mu/be appetite.” (= [The red onion] makes a
patient] be appetite. )
Where the EDU-like name entity in EDU1 is a
cause with EDU2 and EDU4 as its effects. The
EDU3 is an interrupt. Although EDU3 is the ef-
fect of red onions, but EDU 3 is not the effect of
laxatives.
</bodyText>
<sectionHeader confidence="0.918755" genericHeader="method">
4 A Framework for Know-Why Extrac-
tion
</sectionHeader>
<figureCaption confidence="0.998877">
Figure 1. System Overview
</figureCaption>
<bodyText confidence="0.99983575">
There are three steps in our framework. First is
the corpus preparation step followed by causality
learning, and causality recognition steps (as
shown in figure 1).
</bodyText>
<subsectionHeader confidence="0.990581">
4.1 Corpus Preparation
</subsectionHeader>
<bodyText confidence="0.986362173913044">
There are two steps of pre-annotation and Cau-
sality annotation.
4.1.1 Pre-annotation
This step is the preparation of the corpus in the
form of EDU from the text. The step involves
using Thai word segmentation tools to solve a
boundary of a Thai word and tagging its part of
speech (Sudprasert and Kawtrakul, 2003). This
process includes Name entity (Chanlekha and
Kawtrakul, 2004), and word-formation recogni-
tion (Pengphom, et al 2002) to solve the bound-
ary of Thai Name entity and Noun phrase.
After the word segmentation is achieved, EDU
segmentation is dealt with. According to Charo-
ensuk et al. (2005), this process segments plain
text into units of EDUs by using the rule based
and the machine learning technique of C4.5
(Mitchell T.M., 1997). These generated EDUs
will be kept as an EDU corpus. This corpus will
contain 4500 EDUs and will be separated into 2
parts, one part is 3500 EDUs for causality learn-
ing and the other part of 1000 EDUs for causality
recognition and extraction.
</bodyText>
<subsubsectionHeader confidence="0.966829">
4.1.2 Causality Annotation
</subsubsectionHeader>
<bodyText confidence="0.9979908">
Due to the problems in the causality identifica-
tion, verbs from three EDUs (with one EDU as
an EDU-like name entity) in the EDU corpus are
used in this process to learn for extracting causal-
ity. Word ambiguity will be solved through the
</bodyText>
<figure confidence="0.999243">
Causality learning
Word net
Causality
identification
Causality model
Causality recognition
Effect bound-
ary det.
Causality
relation
Know-Why
Corpus prepa-
ration
Text
</figure>
<page confidence="0.930927">
20
</page>
<bodyText confidence="0.99972905">
finding of word concepts from Wordnet. Since
Thai Wordnet does not exist, we need to translate
from Thai to English, using Lexitron (the Thai-
English dictionary)( http://lexitron.nectec.or.th/),
before using Wordnet(http://wordnet.princeton.
edu/obtain). In this process, we manually anno-
tate the causality EDUs by annotating the EDU
containing the causative EDU-like name entity as
the causative EDU. We annotate a verb phrase
in the causative EDU-like name entity to be a
causative-verb-phrase concept (referred to
Wordnet). The verb from EDU which contains
the causative EDU-like name entity is annotated
with a concept and we call this verb as ‘support-
ing causative verb’. We also annotate the effect-
verb-phrase concept(referred to Wordnet and
http://www.ars-grin.gov/duke/ethnobot.html)
from effect EDUs following the EDU containing
the causative EDU-like name, as shown in Figure
2)
</bodyText>
<subsectionHeader confidence="0.994387">
4.2 Causality Learning
</subsectionHeader>
<bodyText confidence="0.999972666666667">
The aim of this step was to learn cause-effect
relation between causative events and effect
events from annotating an EDU corpus.
</bodyText>
<subsubsectionHeader confidence="0.810693">
4.2.1 Feature Extraction
</subsubsectionHeader>
<bodyText confidence="0.9999146">
All annotated verb features from the previous
step are extracted into database table (in Table 1)
including surface forms of verb features along
with their concepts used for probability determi-
nation in the next step.
</bodyText>
<figure confidence="0.922865074074074">
&lt;C id=1&gt;
&lt;EDU type =cause&gt;
&lt;NP1 concept=a herb organ&gt;latasc.A basil leaf&lt;/NP1&gt;
&lt;VS concept=use#1&gt;lI71�u�is used as&lt;/VS&gt;
&lt;EDU-Like-NE &gt;
&lt;NP2 concept=drug&gt;a,enedicine&lt;/NP2&gt;
&lt;CVC concept= be carminative/ eliminate gas from a body&gt;
,tuMeases aw gas
&lt;/CVC&gt;
&lt;/EDU-Like-NE&gt;
&lt;/EDU&gt;
&lt;/C&gt;
&lt;R id=1&gt;
&lt;EDU type=effect&gt;
&lt;EVC concept= stop nausea/ be anti nausea&gt;arvstops a°uldi nauseate.
&lt;/EVC&gt;
&lt;/EDU&gt;
&lt;EDU type=effect&gt;
&lt;EVC concept=stop paining an abdomen/ relieve abdominal pain&gt; u&amp;
stops 71in/pain naai abdomen
&lt;/EVC&gt;
&lt;/EDU&gt;
&lt;/R&gt;
EDU= EDU, EDU-Like-NE= EDU-like name entity tag,
C=cause tag, R=result or effect tag, VS= supporting verb tag ,
CVC=causative verb concept tag, EVC=effect verb concept tag
NP1 NP2= noun phrase tag
</figure>
<figureCaption confidence="0.999593">
Figure 2. Causality Annotation Tag
</figureCaption>
<table confidence="0.992402857142857">
NP1 NP1 Vs Vs Concept VPc VPc VPe VPe Concept Class
Concept concept
nruas/ herb IMU use as O�ulnw/ be- u�iil�a relieve muscle n
Naringi cure antipyretic ������ pain
crenulata poison
������ herb leaf IMU use as �� topi cally fnmuwa heal wound y
Asiatic napplyn/
Pennyworth externally
BUIIa!/ herb ���� is &amp;quot;#��� be-lexative ������!�$� stop being y
red onion excrete constipation
BUIIa!/ herb ���� is &amp;quot;#��� be-lexative %�� discharge urine n
red onion excrete �&amp;&apos;&apos;���
BUIIa!/ herb ���� is &amp;quot;#��� be-lexative ����( be appetite y
red onion excrete 111 ,17
%��)����� herb ���� is *#����)�� be-antiseptic ����� cure skin y
curcumin antiseptic +�, disease
g.) lr!
�����!� herb �-����� make as ���)-�.�� balance ~~ /~ stop coughing n
Soianum �������� blood sugar
indicum reduce level
Linn blood
sugar
������� � herb leaf ������� use as %�ua71/ be ~~ ,~~~~&apos; relieve nausea y
Basil release carminative
gas
������� � herb leaf ������� use as %����� be ~~ ~~~ stop paining y
Basil release carminative ~ ~! an abdomen
gas
%�! / ginger herb IMU use as %����� be ~~ ,~~~~&apos; relieve nausea y
release carminative
gas
71�fJa / herb leaf IMU use as %�11a3j/ be ~~ ,~~~~&apos; relieve nausea y
bergamot release carminative
leaf gas
... ... ... ... ... ... ... ... ...
</table>
<tableCaption confidence="0.99997">
Table 1. The extracted features from the annotated corpus
</tableCaption>
<page confidence="0.960933">
21
</page>
<table confidence="0.99995475">
Vs concept causality non
causality
Z,i0Lflu/use as 0.27619 0.290323
Be 0.561905 0.612903
vi-10LUu/make as 0.009524 0.032258
1,80v1&apos;10Lflu/use for making as 0.066667 0.053763
... ... ...
VPc concept causality non
causality
‘%�U+03i/release-gas’ 0.371901 0.192661
‘LL&amp;/a/anti coughing’ 0.024793 0.045872
‘V1&apos;1/apply’ 0.140496 0.009174
‘%u/be-bitter’ 0.041322 0.009174
‘%�v+37&apos;&apos;� /discharge-urine’ 0.057851 0.06422
‘%�u+L&apos;3j .,/be expectorant’ 0.041322 0.06422
‘flv+unQn/contract 0.041322 0.027523
uterus/oxytocic’
‘fmri+Lu- nu/be antidiabetic’ 0.008264 0.027523
... ... ...
VPe concept causality non
causality
‘~~ +~~~+~ ~!/stop- 0.035714 0.007813
stomachach/relieve abdominal
pain’
‘LL&amp;,gul&apos;�/stop-naucea/be anti 0.035714 0.007813
nausea’
‘���+���!������!�23�/stop- 0.15 0.007813
flatulence/relieve indigestion’
‘0+03J&apos;Alt/stop-rash/ be antiurti- 0.035714 0.023438
caria’
‘sffi/% /reduce-fever’ 0.021429 0.039063
‘%~~+m/eliminate-placenta’ 0.007143 0.054688
‘ 0.092857 0.007813
3(+a-l n1/increase appetite’
‘%�U+L !~~~/release-sweat/be dia- 0.007143 0.070313
phoretic’
</table>
<tableCaption confidence="0.9947065">
Table 2. Show probability of Vs concept, VPc
concept and VPe concept
</tableCaption>
<subsubsectionHeader confidence="0.928657">
4.2.2 Probability Determination
</subsubsectionHeader>
<bodyText confidence="0.999887428571429">
After we had obtained the extracted verb features,
we then determined the probability of causal and
non causal from the occurrences of the cartesian
products of three verb feature concepts , shown
in Table2, by using Weka which is a software
tool for machine learning (http://www.cs. wai-
kato.ac.nz/ml/weka/ ).
</bodyText>
<subsectionHeader confidence="0.999861">
4.3 Causality Recognition and Extraction
</subsectionHeader>
<bodyText confidence="0.992717125">
The objective of this step was to recognize and
extract the cause-effect relation from the testing
EDU corpus. In order to start the causality rec-
ognition process, Naïve Bayes Classifer shown in
equation (2) is applied with the feature probabili-
ties in Table 2, where EDUs class is determined
by class1 (causality EDUs) and class0 (non cau-
sality EDUs).
</bodyText>
<figure confidence="0.989658833333333">
EDUclass=argmax P(class|v„vp ,vp )
class Class
e
Causative Verbconcept set
VerbPhrase conceptset
a Effect VerbPhrase concept set
</figure>
<bodyText confidence="0.431824">
Therefore, Causality Recognition can be sepa-
rated into 2 steps: causality identification and
effect boundary determination.
</bodyText>
<subsubsectionHeader confidence="0.839746">
4.3.1 Causality Identification
</subsubsectionHeader>
<bodyText confidence="0.999979666666667">
This step was to determine the interesting loca-
tions that are cause-effect relations by searching
any EDU which consists of a verb matching to a
verb in the supporting causative concept set, Vs,
and an EDU-like name entity containing a causa-
tive-verb-phrase concept as vpc (where vpceVPc).
</bodyText>
<subsubsectionHeader confidence="0.993433">
4.3.2 Effect Boundary Determination
</subsubsectionHeader>
<bodyText confidence="0.999460736842105">
The effect EDU and the effect boundary were
determined at the same time by checking all se-
quence EDUs right after the EDU containing vpc
in the EDU-like name entity. If a verb phrase
from the sequence of checked EDUs is not in
VPe, the possible effect boundary is end. Af-
ter the possible boundary is determined, vs_inEDU1,
vpc_inEDU1 and vpe_inEDU2..vpe_inEDUn (where n&gt;2)
will be used to determine the causality class from
the Naïve Bayes Classifier equation (2) as shown
in Figure 3. The actual effect boundary is deter-
mined from the last class1 in the sequence of
EDU2.. EDUn.
Furthermore, where the implicit noun phrase
occurs as the subject of the current EDU, this has
to be solved in this step by using the heuristic
rule which is that the noun phrase as a subject of
the previous EDU will be the subject of the cur-
rent EDU.
</bodyText>
<figure confidence="0.97413012">
argmax P(vs |class)P(vpc |class)P(vp |class)P(class)
classe
Class
(2)
vs e V where V is aSupporting
s s
vp VP where VP is a Causative
ce c c
vpe eVP where VP is
e e
22
Assume that each EDU is represented by (np vp)
L is a list of EDU
VPC is a causative-verb-phrase concept set, VPE /VPe is a effect-
verb-phrase concept set
VS is a supporting causative verb concept set
CAUSALITY_EXTRACTION ( L, VC, VE, Vs )
1 i F 1, RF O
2 while i !9 length[L] do
3 begin_while1
4 CA F O, EC F O
5 if (vpi a VS) n (vpi_in_NE a VPC) then
6 begin_if
CA F CA v {i}, i F i + 1 /*CA is causa
tive EDU
</figure>
<bodyText confidence="0.980116727272727">
tribute the causality knowledge for supporting
What-question with the concept of causal rela-
tion from a web page by inference method of
backward chaining, for example:
Extracted causality: “1v.&apos;sd1N71gl11�1ta71141flt1 !/f1Flfl
1[1 l/fl
slaFlViac /A basil leaf is used for a gas released
medicine. [The leaf] stops nausea. [The leaf]
stop stomachache.” ................
The above extracted causality can be repre-
sented by the following predication.
</bodyText>
<figure confidence="0.98899525">
EDU
12 i F i + 1
13 end_while2
14 endif
15 if res = yes n CA &lt;&gt;O then
16 R = R v { (CA,EC) }
17 end_while1
18 return R
</figure>
<figureCaption confidence="0.874621">
Figure3. Show Causality Extraction algorithm for
</figureCaption>
<bodyText confidence="0.992572">
the EDU containing the causative EDU-like name
entity, and followed by multiple effect EDUs .
</bodyText>
<sectionHeader confidence="0.990759" genericHeader="evaluation">
5 Evaluation and Conclusion
</sectionHeader>
<bodyText confidence="0.999926571428571">
The Thai corpora used to evaluate the proposed
causality extraction algorithm consist of about
1,000 EDUs collected from several herbal web
sites. The evaluation of the causality extraction
performance of this research methodology is ex-
pressed in terms of the precision and the recall
as shown below, where R is the causality relation:
</bodyText>
<figure confidence="0.89287625">
a) Vx be_herb(x) ^ be_herb_medicine(y) ^
be_carminative (y) ^ use_as(x,y)4 stop(x, z) ^
be_nausea(z)
b) Vx be_herb(x) ^ be_herb_medicine(y) ^
be_carminative (y) ^use_as(x,y)4 stop(x, z) ^
be_abdominal pain(z)
Where x a X,{‘lum.-imn/basil leaf’ ‘~~/ginger’
‘minlmdblack pepper’ ‘luinniw/bergamot leaf’..},
</figure>
<bodyText confidence="0.9665411875">
and X is the extracted NP1 set from EDUs con-
taining the causative EDU-like name entities
and being followed by the effect EDUs , e.g.
(stop(x, z) ^ be_nausea(z)), (stop(x, z) ^ be_stomach
ache(z)).
Question: “lv# use rryuN5, # herb adls # what utl # stop
t&apos; 7d# nausea (What kind of herb is used for stop
nausea?)
The backward chaining from the above question
and the extracted causality in a) is shown in the
following
stop(x, z) ^ be_nausea(z) 4be_herb(x) ^
be_herb_medicine(y) ^ be_carminative (y) ^
use_as(x,y)
where x is ‘lum.-imn/basil leaf’, ‘~~/ginger’,
‘minIma/black pepper’, or ‘1vu-.nidbergamot leaf’
</bodyText>
<figure confidence="0.979061769230769">
7 while (vpi a VPE) do
8 begin_while2
9 res F
max P vs c P vpc c P vpe c P c
(  |) (  |) (  |) ( )
ca yes no )
( ,
10 if res=yes
11 EC F EC v {i}, /*EC is effect
arg
Precision � #of samples correctly extracted as R (3) References
#of all samples output asbeing R
#of samples correctly extracted as R (4)
</figure>
<figureCaption confidence="0.350189">
#of all samples holding thetarget relation R
</figureCaption>
<bodyText confidence="0.99947025">
The results of precision and recall are evalu-
ated by three expert judgments with max win
voting. The precision of the extracted causality
85.5% with 79.8% recall. The correctness of our
effect boundary determination by these expert
judgments is 86%. These research results can be
increased if we use a larger corpus. However,
our methodology will be very beneficial for con-
</bodyText>
<reference confidence="0.999409909090909">
Carlson L., Marcu D., and Okurowski M. E. 2003.
Building a Discourse-Tagged Corpus in the
Framework of Rhetorical Structure Theory. In Cur-
rent Directions in Discourse and Dialogue. pp.85-
112.
Chanlekha H. and Kawtrakul A. 2004. Thai Named
Entity Extraction by incorporating Maximum En-
tropy Model with Simple Heuristic Information.
IJCNLP’ 2004.
Chareonsuk J ., Sukvakree T., and Kawtrakul A.
2005. Elementary Discourse unit Segmentation for
</reference>
<figure confidence="0.879932">
�
Recall
</figure>
<page confidence="0.987534">
23
</page>
<reference confidence="0.99962682">
Thai using Discourse Cue and Syntactic Informa-
tion. NCSEC 2005.
Chang D.S. and Choi K.S. 2004. Causal Relation Ex-
traction Using Cue Phrase and Lexical Pair Prob-
abilities. IJCNLP. pp. 61 – 70.
Charniak, E. 2000. A maximum-entropy-inspired
parser. Proc. of NAACL, pp.132-130.
Girju R. and Moldovan D. 2002. Mining answers for
causation questions. AAAI Symposium on Mining
Answers from Texts and Knowledge Bases.
Inui T., Inui K., and Matsumoto Y. 2004. Acquiring
causal knowledge from text using the connective
markers. Journal of the information processing so-
ciety of Japan 45(3), pp. 919-993.
Lemeire, J., S. Maes and E. Dirkx. 2004. Causal
Models for Parallel Performance Analysis. Fourth
PA3CT-Symposium, Edegem, Belgium, Septem-
ber.
Marcu D. and Echihabi A. 2002. An Unsupervised
Approach to Recognizing Discourse Relations. in
Proceedings of the 40th Annual Meeting of the As-
sociation for Computational Linguistics Confer-
ence. pp. 368 – 375.
Pechsiri C., Kawtrakul A. and Piriyakul R. 2005.
Mining Causality Knowledge From Text for Ques-
tion Answering System. IEICE Transactions on In-
formation and Systems, Vol.E90-D, No.10 :1523-
1533.
Pengphon N., Kawtrakul A., and Suktarachan M.
2002. Word Formation Approach to Noun Phrase
Analysis for Thai. SNLP.
Mitchell T.M. 1997. Machine Learning. The
McGraw-Hill Companies Inc. and MIT Press, Sin-
gapore.
Sudprasert S. and Kawtrakul A. 2003. Thai Word
Segmentation based on Global and Local Unsuper-
vised Learning. NCSEC’2003.
Talmy, L. 2000. Toward a Cognitive Semantics Con-
cept Structuring Systems – Vol. 1. The MIT Press.
Torisawa K. 2003. Automatic Extraction of Common-
sense Inference Rules from Corpora. In Proc. Of
The 9th Annual Meeting of The Association for
Natural Language Proceeding. pp. 318-321.
Trnkova, Jana, Wolfgang Theilmann. 2004. Author-
ing processes for Advanced Learning Strategies.
Telecooperation Research Group,TU Darmstadt,
and SAP Research, CEC Karlsruhe. Germany.
Wolff, P. 2007. Representing Causation. Journal of
experimental psychology: General 2007 Vol. 136
No.1 82-111. USA.
</reference>
<page confidence="0.999177">
24
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.182362">
<title confidence="0.9983425">Know-Why Extraction from Textual Data for Supporting What Question</title>
<author confidence="0.864255">Chaveevan</author>
<affiliation confidence="0.9300485">Dept. of DhurakijPundit</affiliation>
<address confidence="0.942587">Bangkok, Thailand</address>
<email confidence="0.999653">itdpu@hotmail.com</email>
<author confidence="0.657909">Phunthara</author>
<affiliation confidence="0.936179">Dept. of DhurakijPundit</affiliation>
<address confidence="0.978045">Bangkok, Thailand</address>
<email confidence="0.948496">phunthara@it.dpu.ac.th</email>
<affiliation confidence="0.8396325">U. Eastern Industry</affiliation>
<address confidence="0.606834">Bangkok,</address>
<email confidence="0.9999">uraiwanjan@hotmail.com</email>
<abstract confidence="0.998418052631579">This research aims to automatically extract Know-Why from documents on the website to contribute knowledge sources to support the question-answering system, especially What-Question, for disease treatment. This paper is concerned about extracting Know-Why based on multiple EDUs (Elementary Discourse Units). There are two problems in extracting Know-Why: an identification problem and an effect boundary determination problem. We propose using Naïve Bayes with three verb features, a causative-verb-phrase concept set, a supporting causative verb set, and the effect-verbphrase concept set. The Know-Why extraction results show the success rate of 85.5% precision and 79.8% recall.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>Coling 2008: Proceedings of the workshop on Knowledge and Reasoning for Answering Questions,</booktitle>
<pages>17--24</pages>
<marker></marker>
<rawString>Coling 2008: Proceedings of the workshop on Knowledge and Reasoning for Answering Questions, pages 17–24</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manchester</author>
</authors>
<title>Building a Discourse-Tagged Corpus in the Framework of Rhetorical Structure Theory.</title>
<date>2008</date>
<booktitle>In Current Directions in Discourse and Dialogue.</booktitle>
<pages>85--112</pages>
<marker>Manchester, 2008</marker>
<rawString>Manchester, August 2008 Building a Discourse-Tagged Corpus in the Framework of Rhetorical Structure Theory. In Current Directions in Discourse and Dialogue. pp.85-112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Chanlekha</author>
<author>A Kawtrakul</author>
</authors>
<title>Thai Named Entity Extraction by incorporating Maximum Entropy Model with Simple Heuristic Information. IJCNLP’</title>
<date>2004</date>
<marker>Chanlekha, Kawtrakul, 2004</marker>
<rawString>Chanlekha H. and Kawtrakul A. 2004. Thai Named Entity Extraction by incorporating Maximum Entropy Model with Simple Heuristic Information. IJCNLP’ 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Sukvakree</author>
<author>A Kawtrakul</author>
</authors>
<date>2005</date>
<booktitle>Elementary Discourse unit Segmentation for � tion. NCSEC</booktitle>
<marker>Sukvakree, Kawtrakul, 2005</marker>
<rawString>Chareonsuk J ., Sukvakree T., and Kawtrakul A. 2005. Elementary Discourse unit Segmentation for � tion. NCSEC 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D S Chang</author>
<author>K S Choi</author>
</authors>
<title>Causal Relation Extraction Using Cue</title>
<date>2004</date>
<booktitle>Phrase and Lexical Pair Probabilities. IJCNLP.</booktitle>
<pages>61--70</pages>
<marker>Chang, Choi, 2004</marker>
<rawString>Chang D.S. and Choi K.S. 2004. Causal Relation Extraction Using Cue Phrase and Lexical Pair Probabilities. IJCNLP. pp. 61 – 70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>Proc. of NAACL,</booktitle>
<pages>132--130</pages>
<marker>Charniak, 2000</marker>
<rawString>Charniak, E. 2000. A maximum-entropy-inspired parser. Proc. of NAACL, pp.132-130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Girju</author>
<author>D Moldovan</author>
</authors>
<title>Mining answers for causation questions. AAAI</title>
<date>2002</date>
<booktitle>Symposium on Mining Answers from Texts and Knowledge Bases.</booktitle>
<marker>Girju, Moldovan, 2002</marker>
<rawString>Girju R. and Moldovan D. 2002. Mining answers for causation questions. AAAI Symposium on Mining Answers from Texts and Knowledge Bases.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Inui</author>
<author>K Inui</author>
<author>Y Matsumoto</author>
</authors>
<title>Acquiring causal knowledge from text using the connective markers.</title>
<date>2004</date>
<journal>Journal of the information processing society of Japan</journal>
<volume>45</volume>
<issue>3</issue>
<pages>919--993</pages>
<marker>Inui, Inui, Matsumoto, 2004</marker>
<rawString>Inui T., Inui K., and Matsumoto Y. 2004. Acquiring causal knowledge from text using the connective markers. Journal of the information processing society of Japan 45(3), pp. 919-993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lemeire</author>
<author>S Maes</author>
<author>E Dirkx</author>
</authors>
<title>Causal Models for Parallel Performance Analysis. Fourth PA3CT-Symposium,</title>
<date>2004</date>
<location>Edegem, Belgium,</location>
<marker>Lemeire, Maes, Dirkx, 2004</marker>
<rawString>Lemeire, J., S. Maes and E. Dirkx. 2004. Causal Models for Parallel Performance Analysis. Fourth PA3CT-Symposium, Edegem, Belgium, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marcu</author>
<author>A Echihabi</author>
</authors>
<title>An Unsupervised Approach to Recognizing Discourse Relations.</title>
<date>2002</date>
<booktitle>in Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics Conference.</booktitle>
<pages>368--375</pages>
<marker>Marcu, Echihabi, 2002</marker>
<rawString>Marcu D. and Echihabi A. 2002. An Unsupervised Approach to Recognizing Discourse Relations. in Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics Conference. pp. 368 – 375.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pechsiri</author>
<author>A Kawtrakul</author>
<author>R Piriyakul</author>
</authors>
<title>Mining Causality Knowledge From Text for Question Answering System.</title>
<date>2005</date>
<journal>IEICE Transactions on Information and Systems,</journal>
<volume>90</volume>
<pages>1523--1533</pages>
<marker>Pechsiri, Kawtrakul, Piriyakul, 2005</marker>
<rawString>Pechsiri C., Kawtrakul A. and Piriyakul R. 2005. Mining Causality Knowledge From Text for Question Answering System. IEICE Transactions on Information and Systems, Vol.E90-D, No.10 :1523-1533.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Pengphon</author>
<author>A Kawtrakul</author>
<author>M Suktarachan</author>
</authors>
<title>Word Formation Approach to Noun Phrase Analysis for Thai.</title>
<date>2002</date>
<publisher>SNLP.</publisher>
<marker>Pengphon, Kawtrakul, Suktarachan, 2002</marker>
<rawString>Pengphon N., Kawtrakul A., and Suktarachan M. 2002. Word Formation Approach to Noun Phrase Analysis for Thai. SNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T M Mitchell</author>
</authors>
<date>1997</date>
<booktitle>Machine Learning. The McGraw-Hill Companies Inc. and</booktitle>
<publisher>MIT Press,</publisher>
<marker>Mitchell, 1997</marker>
<rawString>Mitchell T.M. 1997. Machine Learning. The McGraw-Hill Companies Inc. and MIT Press, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sudprasert</author>
<author>A Kawtrakul</author>
</authors>
<title>Thai Word Segmentation based on Global and Local Unsupervised Learning.</title>
<date>2003</date>
<tech>NCSEC’2003.</tech>
<marker>Sudprasert, Kawtrakul, 2003</marker>
<rawString>Sudprasert S. and Kawtrakul A. 2003. Thai Word Segmentation based on Global and Local Unsupervised Learning. NCSEC’2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Talmy</author>
</authors>
<title>Toward a Cognitive Semantics Concept Structuring Systems</title>
<date>2000</date>
<journal></journal>
<volume>1</volume>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="2367" citStr="Talmy, 2000" startWordPosition="333" endWordPosition="334">al-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-ncsa/3.0/). Some rights reserved. condition, for model A4 B 4 C, if there is no B, then A does not cause C)”( Lemeire J. et al. (2004)). Wolff P. (2007) stated that the causal relation can be decomposed into 2 major approaches, the dependency model and the physicalist models. The dependency model can be represented by using statistical dependency model whereas in recent physicalist models are based on the concepts of force dynamic models consisting of 2 force entities in certain events; the agonist and the antagonist (Talmy, 2000). Later, the agonist form (Wolff P., 2007) can be viewed as the ‘effect’ and the antagonist as the ‘cause’. According to Talmy (2000), if there is a situation where the antagonist is stronger, which can be expressed as ‘event X happens because of event Y’(Y contains the antagonist.), it is a form of causation. Moreover, the causal relation can pivot on the distinction between causality and causation (Lehmann J. et al, 2004) whereas causality is ‘a law-like relation between cause events and effect events’ and causation is ‘the actual causal relation that holds between individual events’. For ex</context>
</contexts>
<marker>Talmy, 2000</marker>
<rawString>Talmy, L. 2000. Toward a Cognitive Semantics Concept Structuring Systems – Vol. 1. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Torisawa</author>
</authors>
<title>Automatic Extraction of Commonsense Inference Rules from Corpora.</title>
<date>2003</date>
<booktitle>In Proc. Of The 9th Annual Meeting of The Association for Natural Language Proceeding.</booktitle>
<pages>318--321</pages>
<marker>Torisawa, 2003</marker>
<rawString>Torisawa K. 2003. Automatic Extraction of Commonsense Inference Rules from Corpora. In Proc. Of The 9th Annual Meeting of The Association for Natural Language Proceeding. pp. 318-321.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jana Trnkova</author>
<author>Wolfgang Theilmann</author>
</authors>
<title>Authoring processes for Advanced Learning Strategies.</title>
<date>2004</date>
<journal>Telecooperation Research Group,TU Darmstadt, and SAP Research, CEC</journal>
<location>Karlsruhe. Germany.</location>
<marker>Trnkova, Theilmann, 2004</marker>
<rawString>Trnkova, Jana, Wolfgang Theilmann. 2004. Authoring processes for Advanced Learning Strategies. Telecooperation Research Group,TU Darmstadt, and SAP Research, CEC Karlsruhe. Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Wolff</author>
</authors>
<title>Representing Causation.</title>
<date>2007</date>
<journal>Journal of experimental psychology: General</journal>
<volume>136</volume>
<pages>82--111</pages>
<publisher>USA.</publisher>
<marker>Wolff, 2007</marker>
<rawString>Wolff, P. 2007. Representing Causation. Journal of experimental psychology: General 2007 Vol. 136 No.1 82-111. USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>