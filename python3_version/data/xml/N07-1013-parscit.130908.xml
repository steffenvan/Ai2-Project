<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008626">
<title confidence="0.99732">
Improving Diversity in Ranking using Absorbing Random Walks
</title>
<author confidence="0.998224">
Xiaojin Zhu Andrew B. Goldberg Jurgen Van Gael David Andrzejewski
</author>
<affiliation confidence="0.9977745">
Department of Computer Sciences
University of Wisconsin, Madison
</affiliation>
<address confidence="0.770974">
Madison, WI 53705
</address>
<email confidence="0.981849">
{jerryzhu, goldberg, jvangael, andrzeje}@cs.wisc.edu
</email>
<sectionHeader confidence="0.998533" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999909421052632">
We introduce a novel ranking algorithm
called GRASSHOPPER, which ranks items
with an emphasis on diversity. That is, the
top items should be different from each
other in order to have a broad coverage
of the whole item set. Many natural lan-
guage processing tasks can benefit from
such diversity ranking. Our algorithm is
based on random walks in an absorbing
Markov chain. We turn ranked items into
absorbing states, which effectively pre-
vents redundant items from receiving a
high rank. We demonstrate GRASSHOP-
PER’s effectiveness on extractive text sum-
marization: our algorithm ranks between
the 1st and 2nd systems on DUC 2004
Task 2; and on a social network analy-
sis task that identifies movie stars of the
world.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999909">
Many natural language processing tasks involve
ranking a set of items. Sometimes we want the top
items to be not only good individually but also di-
verse collectively. For example, extractive text sum-
marization generates a summary by selecting a few
good sentences from one or more articles on the
same topic (Goldstein et al., 2000). This can be for-
mulated as ranking all the sentences, and taking the
top ones. A good sentence is one that is represen-
tative, i.e., similar to many other sentences, so that
</bodyText>
<page confidence="0.993601">
97
</page>
<bodyText confidence="0.999937088235294">
it likely conveys the central meaning of the articles.
On the other hand, we do not want multiple near-
identical sentences. The top sentences should be di-
verse.
As another example, in information retrieval on
news events, an article is often published by multi-
ple newspapers with only minor changes. It is unde-
sirable to rank all copies of the same article highly,
even though it may be the most relevant. Instead,
the top results should be different and complemen-
tary. In other words, one wants ‘subtopic diversity’
in retrieval results (Zhai et al., 2003).
The need for diversity in ranking is not unique to
natural language processing. In social network anal-
ysis, people are connected by their interactions, e.g.,
phone calls. Active groups of people have strong in-
teractions among them, but many groups may exist
with fewer interactions. If we want a list of people
that represent various groups, it is important to con-
sider both activity and diversity, and not to fill the
list with people from the same active groups.
Given the importance of diversity in ranking,
there has been significant research in this area. Per-
haps the most well-known method is maximum
marginal relevance (MMR) (Carbonell and Gold-
stein, 1998), as well as cross-sentence informational
subsumption (Radev, 2000), mixture models (Zhang
et al., 2002), subtopic diversity (Zhai et al., 2003),
diversity penalty (Zhang et al., 2005), and others.
The basic idea is to penalize redundancy by lowering
an item’s rank if it is similar to items already ranked.
However, these methods often treat centrality rank-
ing and diversity ranking separately, sometimes with
heuristic procedures.
</bodyText>
<note confidence="0.8294005">
Proceedings of NAACL HLT 2007, pages 97–104,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999903625">
We propose GRASSHOPPER (Graph Random-walk
with Absorbing StateS that HOPs among PEaks
for Ranking), a novel ranking algorithm that en-
courages diversity. GRASSHOPPER is an alternative
to MMR and variants, with a principled mathemat-
ical model and strong empirical performance. It
ranks a set of items such that: 1. A highly ranked
item is representative of a local group in the set,
i.e., it is similar to many other items (centrality);
2. The top items cover as many distinct groups as
possible (diversity); 3. It incorporates an arbitrary
pre-specified ranking as prior knowledge (prior).
Importantly GRASSHOPPER achieves these in a uni-
fied framework of absorbing Markov chain random
walks. The key idea is the following: We define
a random walk on a graph over the items. Items
which have been ranked so far become absorbing
states. These absorbing states ‘drag down’ the im-
portance of similar unranked states, thus encourag-
ing diversity. Our model naturally balances central-
ity, diversity, and prior. We discuss the algorithm
in Section 2. We present GRASSHOPPER’s empiri-
cal results on text summarization and social network
analysis in Section 3.
</bodyText>
<sectionHeader confidence="0.949293" genericHeader="method">
2 The GRASSHOPPER Algorithm
</sectionHeader>
<subsectionHeader confidence="0.961925">
2.1 The Input
</subsectionHeader>
<bodyText confidence="0.986570512820512">
GRASSHOPPER requires three inputs: a graph W, a
probability distribution r that encodes the prior rank-
ing, and a weight A E [0, 1] that balances the two.
The user needs to supply a graph with n nodes,
one for each item. The graph is represented by an
n x n weight matrix W, where wig is the weight on
the edge from i to j. It can be either directed or undi-
rected. W is symmetric for undirected graphs. The
weights are non-negative. The graph does not need
to be fully connected: if there is no edge from item
i to j, then wig = 0. Self-edges are allowed. For ex-
ample, in text summarization one can create an undi-
rected, fully connected graph on the sentences. The
edge between sentences i, j has weight wig, their co-
sine similarity. In social network analysis one can
create a directed graph with wig being the number
of phone calls i made to j. The graph should be
constructed carefully to reflect domain knowledge.
For examples, see (Erkan and Radev, 2004; Mihal-
cea and Tarau, 2004; Pang and Lee, 2004).
The user can optionally supply an arbitrary rank-
ing on the items as prior knowledge. In this
case GRASSHOPPER can be viewed as a re-ranking
method. For example, in information retrieval,
the prior ranking can be the ranking by relevance
scores. In text summarization, it can be the po-
sition of sentences in the original article. (There
is evidence that the first few sentences in an ar-
ticle are likely good summaries.) Somewhat un-
conventionally, the prior ranking is represented as
a probability distribution r = (r1, · · · , rn)T such
that ri &gt; 0, En i�1 ri = 1. The highest-ranked item
has the largest probability, the next item has smaller
probability, and so on. A distribution gives the user
more control. For example ra = (0.1, 0.7, 0.2)T
and rb = (0.3, 0.37, 0.33)T both represent the same
ranking of items 2, 3, 1, but with different strengths.
When there is no prior ranking, one can let r =
(1/n, · · · ,1/n)T, the uniform distribution.
</bodyText>
<subsectionHeader confidence="0.998726">
2.2 Finding the First Item
</subsectionHeader>
<bodyText confidence="0.9999814">
We find the first item in GRASSHOPPER ranking by
teleporting random walks. Imagine a random walker
on the graph. At each step, the walker may do one of
two things: with probability A, she moves to a neigh-
bor state1 according to the edge weights; otherwise
she is teleported to a random state according to the
distribution r. Under mild conditions (which are sat-
isfied in our setting, see below), the stationary distri-
bution of the random walk defines the visiting prob-
abilities of the nodes. The states with large probabil-
ities can be regarded as central items, an idea used
in Google PageRank (Page et al., 1998) and other in-
formation retrieval systems (Kurland and Lee, 2005;
Zhang et al., 2005), text summarization (Erkan and
Radev, 2004), keyword extraction (Mihalcea and Ta-
rau, 2004) and so on. Depending on A, items high on
the user-supplied prior ranking r may also have large
stationary probabilities, which is a way to incorpo-
rate the prior ranking.
As an example, we created a toy data set with 300
points in Figure 1(a). There are roughly three groups
with different densities. We created a fully con-
nected graph on the data, with larger edge weights
if points are closer2. Figure 1(b) shows the station-
ary distribution of the random walk on the graph.
</bodyText>
<footnote confidence="0.9984725">
1We use state, node and item interchangeably.
2We use wij = exp(−�xi − xj112/0.16), A = 1.
</footnote>
<page confidence="0.998524">
98
</page>
<figure confidence="0.999255481481482">
00 5 10
91
5 0 0 5 10
92
5 0 0 5 10
93
5 0 0 5 10
0
10
0
10
4
2
6
0.5
1.5
0
10
1
0.015
0.01
0.005
8
6
4
2
(a) (b) (c) (d)
</figure>
<figureCaption confidence="0.88452125">
Figure 1: (a) A toy data set. (b) The stationary distribution π reflects centrality. The item with the largest
probability is selected as the first item g1. (c) The expected number of visits v to each node after g1 becomes
an absorbing state. (d) After both g1 and g2 become absorbing states. Note the diversity in g1, g2, g3 as they
come from different groups.
</figureCaption>
<bodyText confidence="0.973450375">
Items at group centers have higher probabilities, and
tighter groups have overall higher probabilities.
However, the stationary distribution does not ad-
dress diversity at all. If we were to rank the items
by their stationary distribution, the top list would be
dominated by items from the center group in Fig-
ure 1(b). Therefore we only use the stationary dis-
tribution to find the first item, and use a method
described in the next section to rank the remaining
items.
Formally we first define an n × n raw transition
Aj =
wij/En k�1 wik, so that �Pij is the probability that the
walker moves to j from i. We then make the walk
a teleporting random walk P by interpolating each
row with the user-supplied initial distribution r:
</bodyText>
<equation confidence="0.998921">
P = λ P� + (1 − λ)1r⊤, (1)
</equation>
<bodyText confidence="0.998909166666667">
where 1 is an all-1 vector, and 1r⊤ is the outer prod-
uct. If λ &lt; 1 and r does not have zero elements,
our teleporting random walk P is irreducible (possi-
ble to go to any state from any state by teleporting),
aperiodic (the walk can return to a state after any
number of steps), all states are positive recurrent (the
expected return time to any state is finite) and thus
ergodic (Grimmett and Stirzaker, 2001). Therefore
P has a unique stationary distribution π = P⊤π.
We take the state with the largest stationary proba-
bility to be the first item g1 in GRASSHOPPER rank-
ing: g1 = argmaxni�1 πi.
</bodyText>
<subsectionHeader confidence="0.999129">
2.3 Ranking the Remaining Items
</subsectionHeader>
<bodyText confidence="0.99910509375">
As mentioned early, the key idea of GRASSHOPPER
is to turn ranked items into absorbing states. We
first turn g1 into an absorbing state. Once the ran-
dom walk reaches an absorbing state, the walk is ab-
sorbed and stays there. It is no longer informative to
compute the stationary distribution of an absorbing
Markov chain, because the walk will eventually be
absorbed. Nonetheless, it is useful to compute the
expected number of visits to each node before ab-
sorption. Intuitively, those nodes strongly connected
to g1 will have many fewer visits by the random
walk, because the walk tends to be absorbed soon
after visiting them. In contrast, groups of nodes far
away from g1 still allow the random walk to linger
among them, and thus have more visits. In Fig-
ure 1(c), once g1 becomes an absorbing node (rep-
resented by a circle ‘on the floor’), the center group
is no longer the most prominent: nodes in this group
have fewer visits than the left group. Note now the
y-axis is the number of visits instead of probability.
GRASSHOPPER selects the second item g2 with the
largest expected number of visits in this absorbing
Markov chain. This naturally inhibits items similar
to g1 and encourages diversity. In Figure 1(c), the
item near the center of the left group is selected as
g2. Once g2 is selected, it is converted into an ab-
sorbing state, too. This is shown in Figure 1(d). The
right group now becomes the most prominent, since
both the left and center groups contain an absorbing
state. The next item g3 in ranking will come from the
right group. Also note the range of y-axis is smaller:
matrix P by normalizing the rows of W:
</bodyText>
<page confidence="0.94141">
99
</page>
<bodyText confidence="0.999704428571429">
with more absorbing states, the random walk will be
absorbed sooner. The procedure is repeated until all
items are ranked. The name GRASSHOPPER reflects
the ‘hopping’ behavior on the peaks.
It is therefore important to compute the expected
number of visits in an absorbing Markov chain. Let
G be the set of items ranked so far. We turn the states
g E G into absorbing states by setting Pgg = 1 and
Pgi = 0, Vi =� g. If we arrange items so that ranked
ones are listed before unranked ones, we can write
P as
Here IG is the identity matrix on G. Submatrices R
and Q correspond to rows of unranked items, those
from (1). It is known that the fundamental matrix
</bodyText>
<equation confidence="0.998252">
N = (I − Q)—1 (3)
</equation>
<bodyText confidence="0.999797166666667">
gives the expected number of visits in the absorbing
random walk (Doyle and Snell, 1984). In particular
Nij is the expected number of visits to state j be-
fore absorption, if the random walk started at state i.
We then average over all starting states to obtain vj,
the expected number of visits to state j. In matrix
</bodyText>
<equation confidence="0.915734666666667">
notation,
T
_ N 1 ( )
</equation>
<bodyText confidence="0.87981475">
v n − |G |, 4
where |G |is the size of G. We select the state with
the largest expected number of visits as the next item
g|G|+1 in GRASSHOPPER ranking:
</bodyText>
<equation confidence="0.999038">
g|G|+1 = argmaxni=|G|+1 vi. (5)
</equation>
<bodyText confidence="0.9981845">
The complete GRASSHOPPER algorithm is summa-
rized in Figure 2.
</bodyText>
<subsectionHeader confidence="0.993499">
2.4 Some Discussions
</subsectionHeader>
<bodyText confidence="0.9984335">
To see how A controls the tradeoff, note when A = 1
we ignore the user-supplied prior ranking r, while
when A = 0 one can show that GRASSHOPPER re-
turns the ranking specified by r.
Our data in Figure 1(a) has a cluster struc-
ture. Many methods have exploited such structure,
e.g., (Hearst and Pedersen, 1996; Leuski, 2001; Liu
and Croft, 2004). In fact, a heuristic algorithm is
to first cluster the items, then pick the central items
from each cluster in turn. But it can be difficult to
</bodyText>
<figureCaption confidence="0.999043">
Figure 2: The GRASSHOPPER algorithm
</figureCaption>
<bodyText confidence="0.999720052631579">
determine the appropriate number and control the
shape of clusters. In contrast, GRASSHOPPER does
not involve clustering. However it is still able to
automatically take advantage of cluster structures in
the data.
In each iteration we need to compute the fun-
damental matrix (3). This involves inverting an
(n − |G|) x (n − |G|) matrix, which is expensive.
However the Q matrix is reduced by one row and
one column in every iteration, but is otherwise un-
changed. This allows us to apply the matrix in-
version lemma (Sherman-Morrison-Woodbury for-
mula) (Press et al., 1992). Then we only need to
invert the matrix once in the first iteration, but not in
subsequent iterations. Space precludes a full discus-
sion, but we point out that it presents a significant
speed up. A Matlab implementation can be found
athttp://www.cs.wisc.edu/—jerryzhu/
pub/grasshopper.m.
</bodyText>
<sectionHeader confidence="0.999962" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999256">
3.1 Text Summarization
</subsectionHeader>
<bodyText confidence="0.999046875">
Multi-document extractive text summarization is a
prime application for GRASSHOPPER. In this task, we
must select and rank sentences originating from a
set of documents about a particular topic or event.
The goal is to produce a summary that includes all
the relevant facts, yet avoids repetition that may
result from using similar sentences from multiple
documents. In this section, we demonstrate that
</bodyText>
<figure confidence="0.963898428571429">
�IG 0 .(2)
R Q
P=
Input: W, r, A
1. Create the initial Markov chain P from
W,r,A (1).
2. Compute P’s stationary distribution 7r. Pick the
first item g1 = argmaxi 7ri.
3. Repeat until all items are ranked:
(a) Turn ranked items into absorbing
states (2).
(b) Compute the expected number of visits v
for all remaining items (4). Pick the next
item g|G|+1 = argmaxi vi
</figure>
<page confidence="0.892832">
100
</page>
<bodyText confidence="0.999818369565218">
GRASSHOPPER’s balance of centrality and diversity
makes it successful at this task. We present em-
pirical evidence that GRASSHOPPER achieves results
competitive with the top text summarizers in the
2004 Document Understanding Conference (http:
//duc.nist.gov). DUC is a yearly text summa-
rization community evaluation, with several tasks in
recent years concentrating on multi-document sum-
marization (described in more detail below).
Many successful text summarization systems
achieve a balance between sentence centrality and
diversity in a two-step process. Here we review the
LexRank system (Erkan and Radev, 2004), which
is most similar to our current approach. LexRank
works by placing sentences in a graph, with edges
based on the lexical similarity between the sentences
(as determined by a cosine measure). Each sen-
tence is then assigned a centrality score by finding
its probability under the stationary distribution of
a random walk on this graph. Unlike the similar
PageRank algorithm (Page et al., 1998), LexRank
uses an undirected graph of sentences rather than
Web pages, and the edge weights are either cosine
values or 0/1 with thresholding. The LexRank cen-
trality can be combined with other centrality mea-
sures, as well as sentence position information. Af-
ter this first step of computing centrality, a sec-
ond step performs re-ranking to avoid redundancy
in the highly ranked sentences. LexRank uses cross-
sentence informational subsumption (Radev, 2000)
to this end, but MMR (Carbonell and Goldstein,
1998) has also been widely used in the text sum-
marization community. These methods essentially
disqualify sentences that are too lexically similar to
sentences ranked higher by centrality. In short, sim-
ilar graph-based approaches to text summarization
rely on two distinct processes to measure each sen-
tence’s importance and ensure some degree of diver-
sity. GRASSHOPPER, on the other hand, achieves the
same goal in a unified procedure.
We apply GRASSHOPPER to text summarization in
the following manner. Our graph contains nodes
for all the sentences in a document set. We
used the Clair Library (http://tangra.si.
umich.edu/clair/clairlib) to split docu-
ments into sentences, apply stemming, and create
a cosine matrix for the stemmed sentences. Cosine
values are computed using TF-IDF vectors. As in
LexRank, edges in the graph correspond to text sim-
ilarity. To create a sparse graph, we use the cosine
threshold value of 0.1 obtained in (Erkan and Radev,
2004). Specifically, the edge weight between sen-
tence vectors si and sj is defined as
The second input for GRASSHOPPER is an initial
ranking distribution, which we derive from the po-
sition of each sentence in its originating document.
Position forms the basis for lead-based summaries
(i.e., using the first N sentences as the summary)
and leads to very competitive summaries (Brandow
et al., 1995). We form an initial ranking for each
sentence by computing p−α, where p is the position
of the sentence in its document, and α is a posi-
tive parameter trained on a development dataset. We
then normalize over all sentences in all documents
to form a valid distribution r ∝ p−α that gives high
probability to sentences closer to the beginning of
documents. With a larger α, the probability assigned
to later sentences decays more rapidly.
To evaluate GRASSHOPPER, we experimented with
DUC datasets. We train our parameters (α and A)
using the DUC 2003 Task 2 data. This dataset con-
tains 30 document sets, each with an average of 10
documents about a news event. We test GRASSHOP-
PER’s performance on the DUC 2004 Task 2, Tasks
4a and 4b data. DUC 2004 Task 2 has 50 document
sets of 10 documents each. Tasks 4a and 4b explored
cross-lingual summarization. These datasets consist
of Arabic-to-English translations of news stories.
The documents in Task 4a are machine-translated,
while Task 4b’s are manually-translated. Note that
we handle the translated documents in exactly the
same manner as the English documents.
We evaluate our results using the standard text
summarization metric ROUGE (http://www.
isi.edu/∼cyl/ROUGE/). This is a recall-based
measure of text co-occurrence between a machine-
generated summary and model summaries manually
created by judges. ROUGE metrics exist based on
bigram, trigram, and 4-gram overlap, but ROUGE-1
(based on unigram matching) has been found to cor-
relate best with human judgments (Lin and Hovy,
2003).
</bodyText>
<figure confidence="0.9944675">
� 1 if k 3k·k3 k &gt; 0.1
s
.
si
;
(6)
0 otherwise
wij _
</figure>
<page confidence="0.994176">
101
</page>
<bodyText confidence="0.999952965517241">
Using the DUC 2003 training data, we tuned α
and A on a small grid (α E 10.125,0.25,0.5, 1.0};
A E 10.0, 0.0625, 0.125, 0.25, 0.5, 0.95}). Specifi-
cally, for each of the 30 DUC 2003 Task 2 document
sets, we computed ROUGE-1 scores comparing our
generated summary to 4 model summaries. We av-
eraged the resulting ROUGE-1 scores across all 30
sets to produce a single average ROUGE-1 score to
assess a particular parameter configuration. After
examining the results for all 24 configurations, we
selected the best one: α = 0.25 and A = 0.5.
Table 1 presents our results using these parame-
ter values to generate summaries for the three DUC
2004 datasets. Note that the averages listed are ac-
tually averages over 4 model summaries per set, and
over all the sets. Following the standard DUC pro-
tocol, we list the confidence intervals calculated by
ROUGE using a bootstrapping technique. The fi-
nal column compares our results to the official sys-
tems that participated in the DUC 2004 evaluation.
GRASSHOPPER is highly competitive in these text
summarization tasks: in particular it ranks between
the 1st and 2nd automatic systems on 2004 Task 2.
The lower performance in Task 4a is potentially due
to the documents being machine-translated. If they
contain poorly translated sentences, graph edges
based on cosine similarity could be less meaning-
ful. For such a task, more advanced text processing
is probably required.
</bodyText>
<subsectionHeader confidence="0.997489">
3.2 Social Network Analysis
</subsectionHeader>
<bodyText confidence="0.999974630769231">
As another application of GRASSHOPPER, we iden-
tify the nodes in a social network that are the most
prominent, and at the same time maximally cover
the network. A node’s prominence comes from its
intrinsic stature, as well as the prominence of the
nodes it touches. However, to ensure that the top-
ranked nodes are representative of the larger graph
structure, it is important to make sure the results are
not dominated by a small group of highly prominent
nodes who are closely linked to one another. This re-
quirement makes GRASSHOPPER a useful algorithm
for this task.
We created a dataset from the Internet Movie
Database (IMDb) that consists of all comedy movies
produced between 2000 and 2006, and have received
more than 500 votes by IMDb users. This results in
1027 movies. We form a social network of actors by
co-star relationship. Not surprisingly, actors from
the United States dominate our dataset, although a
total of 30 distinct countries are represented. We
seek an actor ranking such that the top actors are
prominent. However, we also want the top actors to
be diverse, so they represent comedians from around
the world.
This problem is framed as a GRASSHOPPER rank-
ing problem. For each movie, we considered only
the main stars, i.e., the first five cast members, who
tend to be the most important. The resulting list con-
tains 3452 unique actors. We formed a social net-
work where the nodes are the actors, and undirected
weighted edges connect actors who have appeared in
a movie together. The edge weights are equal to the
number of movies from our dataset in which both
actors were main stars. Actors are also given a self-
edge with weight 1. The co-star graph is given to
GRASSHOPPER as an input. For the prior actor rank-
ing, we simply let r be proportional to the number
of movies in our dataset in which an actor has ap-
peared. We set the weight A = 0.95. It is important
to note that no country information is ever given to
GRASSHOPPER.
We use two measurements, ‘country coverage’
and ‘movie coverage’, to study the diversity and
prominence of the ranking produced by GRASSHOP-
PER. We compare GRASSHOPPER to two baselines:
ranking based solely on the number of movies an ac-
tor has appeared in, MOVIECOUNT, and a randomly
generated ranking, RANDOM.
First, we calculate ‘country coverage’ as the num-
ber of different countries represented by the top k ac-
tors, for all k values. Each actor represents a single
country—the country that the actor has appeared in
the most. We hypothesize that actors are more likely
to have co-star connections to actors within the same
country, so our social network may have, to some
extent, a clustering structure by country. ‘Country
coverage’ approximates the number of clusters rep-
resented at different ranks.
Figure 3(a) shows that country coverage grows
much more rapidly for GRASSHOPPER than for
MOVIECOUNT. That is, we see more comedians from
around the world ranked highly by GRASSHOPPER.
In contrast, the top ranks of MOVIECOUNT are dom-
inated by US actors, due to the relative abundance
of US movies on IMDb. Many other countries are
</bodyText>
<page confidence="0.993022">
102
</page>
<table confidence="0.986913">
Number of Average GRASSHOPPER
Dataset Doc. Sets ROUGE-1 95% C.I. Unofficial Rank
DUC 2004 Task 2 50 0.3755 [0.3622, 0.3888] Between 1 &amp; 2 of 34
DUC 2004 Task 4a 24 0.3785 [0.3613, 0.3958] Between 5 &amp; 6 of 11
DUC 2004 Task 4b 24 0.4067 [0.3883, 0.4251] Between 2 &amp; 3 of 11
</table>
<tableCaption confidence="0.998494">
Table 1: Text summarization results on DUC 2004 datasets. GRASSHOPPER was configured using parameters
</tableCaption>
<bodyText confidence="0.992417870967742">
tuned on the DUC 2003 Task 2 dataset. The rightmost column lists what our rank would have been if we
had participated in the DUC 2004 evaluation.
not represented until further down in the ranked
list. This demonstrates that GRASSHOPPER ranking is
successful in returning a more diverse ranking. Be-
cause of the absorbing states in GRASSHOPPER, the
first few highly ranked US actors encourage the se-
lection of actors from other regions of the co-star
graph, which roughly correspond to different coun-
tries. RANDOM achieves even higher country cover-
age initially, but is quickly surpassed by GRASSHOP-
PER. The initial high coverage comes from the ran-
dom selection of actors. However these randomly
selected actors are often not prominent, as we show
next.
Second, we calculate ‘movie coverage’ as the to-
tal number of unique movies the top k actors are
in. We expect that actors who have been in more
movies are more prominent. This is reasonable be-
cause we count an actor in a movie only if the actor
is among the top five actors from that movie. Our
counts thus exclude actors who had only small roles
in numerous movies. Therefore high movie cov-
erage roughly corresponds to ranking more promi-
nent actors highly. It is worth noting that this mea-
sure also partially accounts for diversity, since an
actor whose movies completely overlap with those
of higher-ranked actors contributes nothing to movie
coverage (i.e., his/her movies are already covered by
higher-ranked actors).
Figure 3(b) shows that the movie cover-
age of GRASSHOPPER grows more rapidly than
MOVIECOUNT, and much more rapidly than RAN-
DOM. The results show that, while the RANDOM
ranking is diverse, it is not of high quality be-
cause it fails to include many prominent actors in
its high ranks. This is to be expected of a ran-
dom ranking. Since the vast majority of the ac-
tors appear in only one movie, the movie cover-
age curve is roughly linear in the number of ac-
tors. By ranking more prominent actors highly, the
GRASSHOPPER and MOVIECOUNT movie coverage
curves grow faster. Many of the US actors highly
ranked by MOVIECOUNT are co-stars of one an-
other, so GRASSHOPPER outperforms MOVIECOUNT
in terms of movie coverage too.
We inspect the GRASSHOPPER ranking, and find
the top 5 actors to be Ben Stiller, Anthony Anderson,
Johnny Knoxville, Eddie Murphy and Adam San-
dler. GRASSHOPPER also brings many countries, and
major stars from those countries, into the high ranks.
Examples include Mads Mikkelsen (“synonym to
the great success the Danish film industry has had”),
Cem Yilmaz (“famous Turkish comedy actor, cari-
caturist and scenarist”), Jun Ji-Hyun (“face of South
Korean cinema”), Tadanobu Asano (“Japan’s an-
swer to Johnny Depp”), Aamir Khan (“prominent
Bollywood film actor”), and so on3. These actors
are ranked significantly lower by MOVIECOUNT.
These results indicate that GRASSHOPPER
achieves both prominence and diversity in ranking
actors in the IMDb co-star graph.
</bodyText>
<sectionHeader confidence="0.999635" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999933">
GRASSHOPPER ranking provides a unified approach
for achieving both diversity and centrality. We have
shown its effectiveness in text summarization and
social network analysis. As future work, one direc-
tion is “partial absorption,” where at each absorbing
state the random walk has an escape probability to
continue the random walk instead of being absorbed.
Tuning the escape probability creates a continuum
between PageRank (if the walk always escapes) and
GRASSHOPPER (if always absorbed). In addition, we
will explore the issue of parameter learning, and
</bodyText>
<note confidence="0.614507">
3Quotes from IMDb and Wikipedia.
</note>
<page confidence="0.996118">
103
</page>
<figure confidence="0.993677">
(a) Country coverage (b) Movie coverage
</figure>
<figureCaption confidence="0.987551">
Figure 3: (a) Country coverage at ranks up to 500, showing that GRASSHOPPER and RANDOM rankings are
more diverse than MOVIECOUNT. (b) Movie coverage at ranks up to 500, showing that GRASSHOPPER and
MOVIECOUNT have more prominent actors than RANDOM. Overall, GRASSHOPPER is the best.
</figureCaption>
<figure confidence="0.99124225">
30
1000
k (number of actors)
k (number of actors)
900
800
700
600
500
400
300
GRASSHOPPER
MOVIECOUNT
RANDOM
100 200 300 400 500
0
0
Number of movies covered
200
GRASSHOPPER
MOVIECOUNT
RANDOM
100
100 200 300 400 500
0
0
Number of countries covered
20
15
10
5
25
</figure>
<bodyText confidence="0.995309076923077">
user feedback (e.g., “This item should be ranked
higher.”). We also plan to apply GRASSHOPPER to a
variety of tasks, including information retrieval (for
example ranking news articles on the same event as
in Google News, where many newspapers might use
the same report and thus result in a lack of diversity),
image collection summarization, and social network
analysis for national security and business intelli-
gence.
Acknowledgment We thank Mark Craven and the anony-
mous reviewers for helpful comments. This work is supported
in part by Wisconsin Alumni Research Foundation (WARF) and
NLM training grant 5T15LM07359.
</bodyText>
<sectionHeader confidence="0.99955" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999705218181818">
R. Brandow, K. Mitze, and Lisa F. Rau. 1995. Automatic con-
densation of electronic publications by sentence selection.
Inf. Process. Manage., 31(5):675–685.
Jaime Carbonell and Jade Goldstein. 1998. The use of MMR,
diversity-based reranking for reordering documents and pro-
ducing summaries. In SIGIR’98.
P.G. Doyle and J.L. Snell. 1984. Random Walks and Electric
Networks. Mathematical Assoc. of America.
G¨unes¸ Erkan and Dragomir R. Radev. 2004. LexRank: Graph-
based centrality as salience in text summarization. Journal
ofArti�cial Intelligence Research.
Jade Goldstein, Vibhu Mittal, Jaime Carbonell, and Mark
Kantrowitz. 2000. Multi-document summarization by sen-
tence extraction. In NAACL-ANLP 2000 Workshop on Auto-
matic summarization, pages 40–48.
Geoffrey R. Grimmett and David R. Stirzaker. 2001. Proba-
bility and Random Processes. Oxford Science Publications,
third edition.
Marti A. Hearst and Jan O. Pedersen. 1996. Reexamining
the cluster hypothesis: Scatter/gather on retrieval results. In
SIGIR-96.
Oren Kurland and Lillian Lee. 2005. PageRank without hyper-
links: Structural re-ranking using links induced by language
models. In SIGIR’05.
Anton Leuski. 2001. Evaluating document clustering for inter-
active information retrieval. In CIKM’01.
Chin-Yew Lin and Eduard Hovy. 2003. Automatic evalua-
tion of summaries using n-gram co-occurrence statistics. In
NAACL’03, pages 71–78.
Xiaoyong Liu and W. Bruce Croft. 2004. Cluster-based re-
trieval using language models. In SIGIR’04.
Rada Mihalcea and Paul Tarau. 2004. TextRank: Bringing
order into texts. In EMNLP’04.
Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Wino-
grad. 1998. The PageRank citation ranking: Bringing order
to the web. Technical report, Stanford Digital Library Tech-
nologies Project.
Bo Pang and Lillian Lee. 2004. A sentimental education: Sen-
timent analysis using subjectivity summarization based on
minimum cuts. In ACL, pages 271–278.
W.H. Press, S.A. Teukolsky, W.T. Vetterling, and B.P. Flannery.
1992. Numerical recipes in C: the art of scienti�c comput-
ing. Cambridge University Press New York, NY, USA.
Dragomir Radev. 2000. A common theory of information fu-
sion from multiple text sources, step one: Cross-document
structure. In Proceedings of the 1st ACL SIGDIAL Workshop
on Discourse and Dialogue.
ChengXiang Zhai, William W. Cohen, and John Lafferty. 2003.
Beyond independent relevance: Methods and evaluation
metrics for subtopic retrieval. In SIGIR’03.
Yi Zhang, Jamie Callan, and Thomas Minka. 2002. Novelty
and redundancy detection in adaptive filtering. In SIGIR’02.
Benyu Zhang, Hua Li, Yi Liu, Lei Ji, Wensi Xi, Weiguo Fan,
Zheng Chen, and Wei-Ying Ma. 2005. Improving web
search results using affinity graph. In SIGIR’05.
</reference>
<page confidence="0.998772">
104
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.888578">
<title confidence="0.999717">Improving Diversity in Ranking using Absorbing Random Walks</title>
<author confidence="0.99914">Xiaojin Zhu Andrew B Goldberg Jurgen Van_Gael David</author>
<affiliation confidence="0.999989">Department of Computer University of Wisconsin,</affiliation>
<address confidence="0.999542">Madison, WI</address>
<email confidence="0.942479">goldberg,jvangael,</email>
<abstract confidence="0.99655095">We introduce a novel ranking algorithm which ranks items with an emphasis on diversity. That is, the top items should be different from each other in order to have a broad coverage of the whole item set. Many natural language processing tasks can benefit from such diversity ranking. Our algorithm is based on random walks in an absorbing Markov chain. We turn ranked items into absorbing states, which effectively prevents redundant items from receiving a rank. We demonstrate GRASSHOPeffectiveness on extractive text summarization: our algorithm ranks between the 1st and 2nd systems on DUC 2004 Task 2; and on a social network analysis task that identifies movie stars of the world.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Brandow</author>
<author>K Mitze</author>
<author>Lisa F Rau</author>
</authors>
<title>Automatic condensation of electronic publications by sentence selection.</title>
<date>1995</date>
<journal>Inf. Process. Manage.,</journal>
<volume>31</volume>
<issue>5</issue>
<contexts>
<context position="17666" citStr="Brandow et al., 1995" startWordPosition="3038" endWordPosition="3041"> sentences. Cosine values are computed using TF-IDF vectors. As in LexRank, edges in the graph correspond to text similarity. To create a sparse graph, we use the cosine threshold value of 0.1 obtained in (Erkan and Radev, 2004). Specifically, the edge weight between sentence vectors si and sj is defined as The second input for GRASSHOPPER is an initial ranking distribution, which we derive from the position of each sentence in its originating document. Position forms the basis for lead-based summaries (i.e., using the first N sentences as the summary) and leads to very competitive summaries (Brandow et al., 1995). We form an initial ranking for each sentence by computing p−α, where p is the position of the sentence in its document, and α is a positive parameter trained on a development dataset. We then normalize over all sentences in all documents to form a valid distribution r ∝ p−α that gives high probability to sentences closer to the beginning of documents. With a larger α, the probability assigned to later sentences decays more rapidly. To evaluate GRASSHOPPER, we experimented with DUC datasets. We train our parameters (α and A) using the DUC 2003 Task 2 data. This dataset contains 30 document se</context>
</contexts>
<marker>Brandow, Mitze, Rau, 1995</marker>
<rawString>R. Brandow, K. Mitze, and Lisa F. Rau. 1995. Automatic condensation of electronic publications by sentence selection. Inf. Process. Manage., 31(5):675–685.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime Carbonell</author>
<author>Jade Goldstein</author>
</authors>
<title>The use of MMR, diversity-based reranking for reordering documents and producing summaries.</title>
<date>1998</date>
<booktitle>In SIGIR’98.</booktitle>
<contexts>
<context position="2733" citStr="Carbonell and Goldstein, 1998" startWordPosition="445" endWordPosition="449"> is not unique to natural language processing. In social network analysis, people are connected by their interactions, e.g., phone calls. Active groups of people have strong interactions among them, but many groups may exist with fewer interactions. If we want a list of people that represent various groups, it is important to consider both activity and diversity, and not to fill the list with people from the same active groups. Given the importance of diversity in ranking, there has been significant research in this area. Perhaps the most well-known method is maximum marginal relevance (MMR) (Carbonell and Goldstein, 1998), as well as cross-sentence informational subsumption (Radev, 2000), mixture models (Zhang et al., 2002), subtopic diversity (Zhai et al., 2003), diversity penalty (Zhang et al., 2005), and others. The basic idea is to penalize redundancy by lowering an item’s rank if it is similar to items already ranked. However, these methods often treat centrality ranking and diversity ranking separately, sometimes with heuristic procedures. Proceedings of NAACL HLT 2007, pages 97–104, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics We propose GRASSHOPPER (Graph Random-walk with</context>
<context position="16315" citStr="Carbonell and Goldstein, 1998" startWordPosition="2823" endWordPosition="2826">nder the stationary distribution of a random walk on this graph. Unlike the similar PageRank algorithm (Page et al., 1998), LexRank uses an undirected graph of sentences rather than Web pages, and the edge weights are either cosine values or 0/1 with thresholding. The LexRank centrality can be combined with other centrality measures, as well as sentence position information. After this first step of computing centrality, a second step performs re-ranking to avoid redundancy in the highly ranked sentences. LexRank uses crosssentence informational subsumption (Radev, 2000) to this end, but MMR (Carbonell and Goldstein, 1998) has also been widely used in the text summarization community. These methods essentially disqualify sentences that are too lexically similar to sentences ranked higher by centrality. In short, similar graph-based approaches to text summarization rely on two distinct processes to measure each sentence’s importance and ensure some degree of diversity. GRASSHOPPER, on the other hand, achieves the same goal in a unified procedure. We apply GRASSHOPPER to text summarization in the following manner. Our graph contains nodes for all the sentences in a document set. We used the Clair Library (http://</context>
</contexts>
<marker>Carbonell, Goldstein, 1998</marker>
<rawString>Jaime Carbonell and Jade Goldstein. 1998. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In SIGIR’98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P G Doyle</author>
<author>J L Snell</author>
</authors>
<title>Random Walks and Electric Networks. Mathematical Assoc.</title>
<date>1984</date>
<publisher>of America.</publisher>
<contexts>
<context position="12083" citStr="Doyle and Snell, 1984" startWordPosition="2118" endWordPosition="2121">R reflects the ‘hopping’ behavior on the peaks. It is therefore important to compute the expected number of visits in an absorbing Markov chain. Let G be the set of items ranked so far. We turn the states g E G into absorbing states by setting Pgg = 1 and Pgi = 0, Vi =� g. If we arrange items so that ranked ones are listed before unranked ones, we can write P as Here IG is the identity matrix on G. Submatrices R and Q correspond to rows of unranked items, those from (1). It is known that the fundamental matrix N = (I − Q)—1 (3) gives the expected number of visits in the absorbing random walk (Doyle and Snell, 1984). In particular Nij is the expected number of visits to state j before absorption, if the random walk started at state i. We then average over all starting states to obtain vj, the expected number of visits to state j. In matrix notation, T _ N 1 ( ) v n − |G |, 4 where |G |is the size of G. We select the state with the largest expected number of visits as the next item g|G|+1 in GRASSHOPPER ranking: g|G|+1 = argmaxni=|G|+1 vi. (5) The complete GRASSHOPPER algorithm is summarized in Figure 2. 2.4 Some Discussions To see how A controls the tradeoff, note when A = 1 we ignore the user-supplied p</context>
</contexts>
<marker>Doyle, Snell, 1984</marker>
<rawString>P.G. Doyle and J.L. Snell. 1984. Random Walks and Electric Networks. Mathematical Assoc. of America.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨unes¸ Erkan</author>
<author>Dragomir R Radev</author>
</authors>
<title>LexRank: Graphbased centrality as salience in text summarization.</title>
<date>2004</date>
<journal>Journal ofArti�cial Intelligence Research.</journal>
<contexts>
<context position="5435" citStr="Erkan and Radev, 2004" startWordPosition="897" endWordPosition="900">her directed or undirected. W is symmetric for undirected graphs. The weights are non-negative. The graph does not need to be fully connected: if there is no edge from item i to j, then wig = 0. Self-edges are allowed. For example, in text summarization one can create an undirected, fully connected graph on the sentences. The edge between sentences i, j has weight wig, their cosine similarity. In social network analysis one can create a directed graph with wig being the number of phone calls i made to j. The graph should be constructed carefully to reflect domain knowledge. For examples, see (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Pang and Lee, 2004). The user can optionally supply an arbitrary ranking on the items as prior knowledge. In this case GRASSHOPPER can be viewed as a re-ranking method. For example, in information retrieval, the prior ranking can be the ranking by relevance scores. In text summarization, it can be the position of sentences in the original article. (There is evidence that the first few sentences in an article are likely good summaries.) Somewhat unconventionally, the prior ranking is represented as a probability distribution r = (r1, · · · , rn)T such that ri &gt; 0, En</context>
<context position="7199" citStr="Erkan and Radev, 2004" startWordPosition="1210" endWordPosition="1213">h step, the walker may do one of two things: with probability A, she moves to a neighbor state1 according to the edge weights; otherwise she is teleported to a random state according to the distribution r. Under mild conditions (which are satisfied in our setting, see below), the stationary distribution of the random walk defines the visiting probabilities of the nodes. The states with large probabilities can be regarded as central items, an idea used in Google PageRank (Page et al., 1998) and other information retrieval systems (Kurland and Lee, 2005; Zhang et al., 2005), text summarization (Erkan and Radev, 2004), keyword extraction (Mihalcea and Tarau, 2004) and so on. Depending on A, items high on the user-supplied prior ranking r may also have large stationary probabilities, which is a way to incorporate the prior ranking. As an example, we created a toy data set with 300 points in Figure 1(a). There are roughly three groups with different densities. We created a fully connected graph on the data, with larger edge weights if points are closer2. Figure 1(b) shows the stationary distribution of the random walk on the graph. 1We use state, node and item interchangeably. 2We use wij = exp(−�xi − xj112/</context>
<context position="15409" citStr="Erkan and Radev, 2004" startWordPosition="2678" endWordPosition="2681">vi 100 GRASSHOPPER’s balance of centrality and diversity makes it successful at this task. We present empirical evidence that GRASSHOPPER achieves results competitive with the top text summarizers in the 2004 Document Understanding Conference (http: //duc.nist.gov). DUC is a yearly text summarization community evaluation, with several tasks in recent years concentrating on multi-document summarization (described in more detail below). Many successful text summarization systems achieve a balance between sentence centrality and diversity in a two-step process. Here we review the LexRank system (Erkan and Radev, 2004), which is most similar to our current approach. LexRank works by placing sentences in a graph, with edges based on the lexical similarity between the sentences (as determined by a cosine measure). Each sentence is then assigned a centrality score by finding its probability under the stationary distribution of a random walk on this graph. Unlike the similar PageRank algorithm (Page et al., 1998), LexRank uses an undirected graph of sentences rather than Web pages, and the edge weights are either cosine values or 0/1 with thresholding. The LexRank centrality can be combined with other centralit</context>
<context position="17273" citStr="Erkan and Radev, 2004" startWordPosition="2974" endWordPosition="2977">ee of diversity. GRASSHOPPER, on the other hand, achieves the same goal in a unified procedure. We apply GRASSHOPPER to text summarization in the following manner. Our graph contains nodes for all the sentences in a document set. We used the Clair Library (http://tangra.si. umich.edu/clair/clairlib) to split documents into sentences, apply stemming, and create a cosine matrix for the stemmed sentences. Cosine values are computed using TF-IDF vectors. As in LexRank, edges in the graph correspond to text similarity. To create a sparse graph, we use the cosine threshold value of 0.1 obtained in (Erkan and Radev, 2004). Specifically, the edge weight between sentence vectors si and sj is defined as The second input for GRASSHOPPER is an initial ranking distribution, which we derive from the position of each sentence in its originating document. Position forms the basis for lead-based summaries (i.e., using the first N sentences as the summary) and leads to very competitive summaries (Brandow et al., 1995). We form an initial ranking for each sentence by computing p−α, where p is the position of the sentence in its document, and α is a positive parameter trained on a development dataset. We then normalize ove</context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>G¨unes¸ Erkan and Dragomir R. Radev. 2004. LexRank: Graphbased centrality as salience in text summarization. Journal ofArti�cial Intelligence Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jade Goldstein</author>
<author>Vibhu Mittal</author>
<author>Jaime Carbonell</author>
<author>Mark Kantrowitz</author>
</authors>
<title>Multi-document summarization by sentence extraction.</title>
<date>2000</date>
<booktitle>In NAACL-ANLP 2000 Workshop on Automatic summarization,</booktitle>
<pages>40--48</pages>
<contexts>
<context position="1335" citStr="Goldstein et al., 2000" startWordPosition="208" endWordPosition="211">ts redundant items from receiving a high rank. We demonstrate GRASSHOPPER’s effectiveness on extractive text summarization: our algorithm ranks between the 1st and 2nd systems on DUC 2004 Task 2; and on a social network analysis task that identifies movie stars of the world. 1 Introduction Many natural language processing tasks involve ranking a set of items. Sometimes we want the top items to be not only good individually but also diverse collectively. For example, extractive text summarization generates a summary by selecting a few good sentences from one or more articles on the same topic (Goldstein et al., 2000). This can be formulated as ranking all the sentences, and taking the top ones. A good sentence is one that is representative, i.e., similar to many other sentences, so that 97 it likely conveys the central meaning of the articles. On the other hand, we do not want multiple nearidentical sentences. The top sentences should be diverse. As another example, in information retrieval on news events, an article is often published by multiple newspapers with only minor changes. It is undesirable to rank all copies of the same article highly, even though it may be the most relevant. Instead, the top r</context>
</contexts>
<marker>Goldstein, Mittal, Carbonell, Kantrowitz, 2000</marker>
<rawString>Jade Goldstein, Vibhu Mittal, Jaime Carbonell, and Mark Kantrowitz. 2000. Multi-document summarization by sentence extraction. In NAACL-ANLP 2000 Workshop on Automatic summarization, pages 40–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey R Grimmett</author>
<author>David R Stirzaker</author>
</authors>
<date>2001</date>
<booktitle>Probability and Random Processes. Oxford Science Publications, third edition.</booktitle>
<contexts>
<context position="9464" citStr="Grimmett and Stirzaker, 2001" startWordPosition="1643" endWordPosition="1646">k, so that �Pij is the probability that the walker moves to j from i. We then make the walk a teleporting random walk P by interpolating each row with the user-supplied initial distribution r: P = λ P� + (1 − λ)1r⊤, (1) where 1 is an all-1 vector, and 1r⊤ is the outer product. If λ &lt; 1 and r does not have zero elements, our teleporting random walk P is irreducible (possible to go to any state from any state by teleporting), aperiodic (the walk can return to a state after any number of steps), all states are positive recurrent (the expected return time to any state is finite) and thus ergodic (Grimmett and Stirzaker, 2001). Therefore P has a unique stationary distribution π = P⊤π. We take the state with the largest stationary probability to be the first item g1 in GRASSHOPPER ranking: g1 = argmaxni�1 πi. 2.3 Ranking the Remaining Items As mentioned early, the key idea of GRASSHOPPER is to turn ranked items into absorbing states. We first turn g1 into an absorbing state. Once the random walk reaches an absorbing state, the walk is absorbed and stays there. It is no longer informative to compute the stationary distribution of an absorbing Markov chain, because the walk will eventually be absorbed. Nonetheless, it</context>
</contexts>
<marker>Grimmett, Stirzaker, 2001</marker>
<rawString>Geoffrey R. Grimmett and David R. Stirzaker. 2001. Probability and Random Processes. Oxford Science Publications, third edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
<author>Jan O Pedersen</author>
</authors>
<title>Reexamining the cluster hypothesis: Scatter/gather on retrieval results.</title>
<date>1996</date>
<booktitle>In SIGIR-96.</booktitle>
<contexts>
<context position="12907" citStr="Hearst and Pedersen, 1996" startWordPosition="2275" endWordPosition="2278"> visits to state j. In matrix notation, T _ N 1 ( ) v n − |G |, 4 where |G |is the size of G. We select the state with the largest expected number of visits as the next item g|G|+1 in GRASSHOPPER ranking: g|G|+1 = argmaxni=|G|+1 vi. (5) The complete GRASSHOPPER algorithm is summarized in Figure 2. 2.4 Some Discussions To see how A controls the tradeoff, note when A = 1 we ignore the user-supplied prior ranking r, while when A = 0 one can show that GRASSHOPPER returns the ranking specified by r. Our data in Figure 1(a) has a cluster structure. Many methods have exploited such structure, e.g., (Hearst and Pedersen, 1996; Leuski, 2001; Liu and Croft, 2004). In fact, a heuristic algorithm is to first cluster the items, then pick the central items from each cluster in turn. But it can be difficult to Figure 2: The GRASSHOPPER algorithm determine the appropriate number and control the shape of clusters. In contrast, GRASSHOPPER does not involve clustering. However it is still able to automatically take advantage of cluster structures in the data. In each iteration we need to compute the fundamental matrix (3). This involves inverting an (n − |G|) x (n − |G|) matrix, which is expensive. However the Q matrix is re</context>
</contexts>
<marker>Hearst, Pedersen, 1996</marker>
<rawString>Marti A. Hearst and Jan O. Pedersen. 1996. Reexamining the cluster hypothesis: Scatter/gather on retrieval results. In SIGIR-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Kurland</author>
<author>Lillian Lee</author>
</authors>
<title>PageRank without hyperlinks: Structural re-ranking using links induced by language models.</title>
<date>2005</date>
<booktitle>In SIGIR’05.</booktitle>
<contexts>
<context position="7134" citStr="Kurland and Lee, 2005" startWordPosition="1200" endWordPosition="1203">rting random walks. Imagine a random walker on the graph. At each step, the walker may do one of two things: with probability A, she moves to a neighbor state1 according to the edge weights; otherwise she is teleported to a random state according to the distribution r. Under mild conditions (which are satisfied in our setting, see below), the stationary distribution of the random walk defines the visiting probabilities of the nodes. The states with large probabilities can be regarded as central items, an idea used in Google PageRank (Page et al., 1998) and other information retrieval systems (Kurland and Lee, 2005; Zhang et al., 2005), text summarization (Erkan and Radev, 2004), keyword extraction (Mihalcea and Tarau, 2004) and so on. Depending on A, items high on the user-supplied prior ranking r may also have large stationary probabilities, which is a way to incorporate the prior ranking. As an example, we created a toy data set with 300 points in Figure 1(a). There are roughly three groups with different densities. We created a fully connected graph on the data, with larger edge weights if points are closer2. Figure 1(b) shows the stationary distribution of the random walk on the graph. 1We use stat</context>
</contexts>
<marker>Kurland, Lee, 2005</marker>
<rawString>Oren Kurland and Lillian Lee. 2005. PageRank without hyperlinks: Structural re-ranking using links induced by language models. In SIGIR’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anton Leuski</author>
</authors>
<title>Evaluating document clustering for interactive information retrieval.</title>
<date>2001</date>
<booktitle>In CIKM’01.</booktitle>
<contexts>
<context position="12921" citStr="Leuski, 2001" startWordPosition="2279" endWordPosition="2280">ix notation, T _ N 1 ( ) v n − |G |, 4 where |G |is the size of G. We select the state with the largest expected number of visits as the next item g|G|+1 in GRASSHOPPER ranking: g|G|+1 = argmaxni=|G|+1 vi. (5) The complete GRASSHOPPER algorithm is summarized in Figure 2. 2.4 Some Discussions To see how A controls the tradeoff, note when A = 1 we ignore the user-supplied prior ranking r, while when A = 0 one can show that GRASSHOPPER returns the ranking specified by r. Our data in Figure 1(a) has a cluster structure. Many methods have exploited such structure, e.g., (Hearst and Pedersen, 1996; Leuski, 2001; Liu and Croft, 2004). In fact, a heuristic algorithm is to first cluster the items, then pick the central items from each cluster in turn. But it can be difficult to Figure 2: The GRASSHOPPER algorithm determine the appropriate number and control the shape of clusters. In contrast, GRASSHOPPER does not involve clustering. However it is still able to automatically take advantage of cluster structures in the data. In each iteration we need to compute the fundamental matrix (3). This involves inverting an (n − |G|) x (n − |G|) matrix, which is expensive. However the Q matrix is reduced by one r</context>
</contexts>
<marker>Leuski, 2001</marker>
<rawString>Anton Leuski. 2001. Evaluating document clustering for interactive information retrieval. In CIKM’01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
<author>Eduard Hovy</author>
</authors>
<title>Automatic evaluation of summaries using n-gram co-occurrence statistics.</title>
<date>2003</date>
<booktitle>In NAACL’03,</booktitle>
<pages>71--78</pages>
<contexts>
<context position="19208" citStr="Lin and Hovy, 2003" startWordPosition="3289" endWordPosition="3292">ies. The documents in Task 4a are machine-translated, while Task 4b’s are manually-translated. Note that we handle the translated documents in exactly the same manner as the English documents. We evaluate our results using the standard text summarization metric ROUGE (http://www. isi.edu/∼cyl/ROUGE/). This is a recall-based measure of text co-occurrence between a machinegenerated summary and model summaries manually created by judges. ROUGE metrics exist based on bigram, trigram, and 4-gram overlap, but ROUGE-1 (based on unigram matching) has been found to correlate best with human judgments (Lin and Hovy, 2003). � 1 if k 3k·k3 k &gt; 0.1 s . si ; (6) 0 otherwise wij _ 101 Using the DUC 2003 training data, we tuned α and A on a small grid (α E 10.125,0.25,0.5, 1.0}; A E 10.0, 0.0625, 0.125, 0.25, 0.5, 0.95}). Specifically, for each of the 30 DUC 2003 Task 2 document sets, we computed ROUGE-1 scores comparing our generated summary to 4 model summaries. We averaged the resulting ROUGE-1 scores across all 30 sets to produce a single average ROUGE-1 score to assess a particular parameter configuration. After examining the results for all 24 configurations, we selected the best one: α = 0.25 and A = 0.5. Tab</context>
</contexts>
<marker>Lin, Hovy, 2003</marker>
<rawString>Chin-Yew Lin and Eduard Hovy. 2003. Automatic evaluation of summaries using n-gram co-occurrence statistics. In NAACL’03, pages 71–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoyong Liu</author>
<author>W Bruce Croft</author>
</authors>
<title>Cluster-based retrieval using language models.</title>
<date>2004</date>
<booktitle>In SIGIR’04.</booktitle>
<contexts>
<context position="12943" citStr="Liu and Croft, 2004" startWordPosition="2281" endWordPosition="2284"> _ N 1 ( ) v n − |G |, 4 where |G |is the size of G. We select the state with the largest expected number of visits as the next item g|G|+1 in GRASSHOPPER ranking: g|G|+1 = argmaxni=|G|+1 vi. (5) The complete GRASSHOPPER algorithm is summarized in Figure 2. 2.4 Some Discussions To see how A controls the tradeoff, note when A = 1 we ignore the user-supplied prior ranking r, while when A = 0 one can show that GRASSHOPPER returns the ranking specified by r. Our data in Figure 1(a) has a cluster structure. Many methods have exploited such structure, e.g., (Hearst and Pedersen, 1996; Leuski, 2001; Liu and Croft, 2004). In fact, a heuristic algorithm is to first cluster the items, then pick the central items from each cluster in turn. But it can be difficult to Figure 2: The GRASSHOPPER algorithm determine the appropriate number and control the shape of clusters. In contrast, GRASSHOPPER does not involve clustering. However it is still able to automatically take advantage of cluster structures in the data. In each iteration we need to compute the fundamental matrix (3). This involves inverting an (n − |G|) x (n − |G|) matrix, which is expensive. However the Q matrix is reduced by one row and one column in e</context>
</contexts>
<marker>Liu, Croft, 2004</marker>
<rawString>Xiaoyong Liu and W. Bruce Croft. 2004. Cluster-based retrieval using language models. In SIGIR’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
</authors>
<title>TextRank: Bringing order into texts.</title>
<date>2004</date>
<booktitle>In EMNLP’04.</booktitle>
<contexts>
<context position="5461" citStr="Mihalcea and Tarau, 2004" startWordPosition="901" endWordPosition="905">ted. W is symmetric for undirected graphs. The weights are non-negative. The graph does not need to be fully connected: if there is no edge from item i to j, then wig = 0. Self-edges are allowed. For example, in text summarization one can create an undirected, fully connected graph on the sentences. The edge between sentences i, j has weight wig, their cosine similarity. In social network analysis one can create a directed graph with wig being the number of phone calls i made to j. The graph should be constructed carefully to reflect domain knowledge. For examples, see (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Pang and Lee, 2004). The user can optionally supply an arbitrary ranking on the items as prior knowledge. In this case GRASSHOPPER can be viewed as a re-ranking method. For example, in information retrieval, the prior ranking can be the ranking by relevance scores. In text summarization, it can be the position of sentences in the original article. (There is evidence that the first few sentences in an article are likely good summaries.) Somewhat unconventionally, the prior ranking is represented as a probability distribution r = (r1, · · · , rn)T such that ri &gt; 0, En i�1 ri = 1. The highest-r</context>
<context position="7246" citStr="Mihalcea and Tarau, 2004" startWordPosition="1216" endWordPosition="1220"> with probability A, she moves to a neighbor state1 according to the edge weights; otherwise she is teleported to a random state according to the distribution r. Under mild conditions (which are satisfied in our setting, see below), the stationary distribution of the random walk defines the visiting probabilities of the nodes. The states with large probabilities can be regarded as central items, an idea used in Google PageRank (Page et al., 1998) and other information retrieval systems (Kurland and Lee, 2005; Zhang et al., 2005), text summarization (Erkan and Radev, 2004), keyword extraction (Mihalcea and Tarau, 2004) and so on. Depending on A, items high on the user-supplied prior ranking r may also have large stationary probabilities, which is a way to incorporate the prior ranking. As an example, we created a toy data set with 300 points in Figure 1(a). There are roughly three groups with different densities. We created a fully connected graph on the data, with larger edge weights if points are closer2. Figure 1(b) shows the stationary distribution of the random walk on the graph. 1We use state, node and item interchangeably. 2We use wij = exp(−�xi − xj112/0.16), A = 1. 98 00 5 10 91 5 0 0 5 10 92 5 0 0</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>Rada Mihalcea and Paul Tarau. 2004. TextRank: Bringing order into texts. In EMNLP’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Page</author>
<author>Sergey Brin</author>
<author>Rajeev Motwani</author>
<author>Terry Winograd</author>
</authors>
<title>The PageRank citation ranking: Bringing order to the web.</title>
<date>1998</date>
<tech>Technical report,</tech>
<institution>Stanford Digital Library Technologies Project.</institution>
<contexts>
<context position="7071" citStr="Page et al., 1998" startWordPosition="1190" endWordPosition="1193">Item We find the first item in GRASSHOPPER ranking by teleporting random walks. Imagine a random walker on the graph. At each step, the walker may do one of two things: with probability A, she moves to a neighbor state1 according to the edge weights; otherwise she is teleported to a random state according to the distribution r. Under mild conditions (which are satisfied in our setting, see below), the stationary distribution of the random walk defines the visiting probabilities of the nodes. The states with large probabilities can be regarded as central items, an idea used in Google PageRank (Page et al., 1998) and other information retrieval systems (Kurland and Lee, 2005; Zhang et al., 2005), text summarization (Erkan and Radev, 2004), keyword extraction (Mihalcea and Tarau, 2004) and so on. Depending on A, items high on the user-supplied prior ranking r may also have large stationary probabilities, which is a way to incorporate the prior ranking. As an example, we created a toy data set with 300 points in Figure 1(a). There are roughly three groups with different densities. We created a fully connected graph on the data, with larger edge weights if points are closer2. Figure 1(b) shows the statio</context>
<context position="15807" citStr="Page et al., 1998" startWordPosition="2743" endWordPosition="2746">on (described in more detail below). Many successful text summarization systems achieve a balance between sentence centrality and diversity in a two-step process. Here we review the LexRank system (Erkan and Radev, 2004), which is most similar to our current approach. LexRank works by placing sentences in a graph, with edges based on the lexical similarity between the sentences (as determined by a cosine measure). Each sentence is then assigned a centrality score by finding its probability under the stationary distribution of a random walk on this graph. Unlike the similar PageRank algorithm (Page et al., 1998), LexRank uses an undirected graph of sentences rather than Web pages, and the edge weights are either cosine values or 0/1 with thresholding. The LexRank centrality can be combined with other centrality measures, as well as sentence position information. After this first step of computing centrality, a second step performs re-ranking to avoid redundancy in the highly ranked sentences. LexRank uses crosssentence informational subsumption (Radev, 2000) to this end, but MMR (Carbonell and Goldstein, 1998) has also been widely used in the text summarization community. These methods essentially di</context>
</contexts>
<marker>Page, Brin, Motwani, Winograd, 1998</marker>
<rawString>Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1998. The PageRank citation ranking: Bringing order to the web. Technical report, Stanford Digital Library Technologies Project.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In ACL,</booktitle>
<pages>271--278</pages>
<contexts>
<context position="5482" citStr="Pang and Lee, 2004" startWordPosition="906" endWordPosition="909">directed graphs. The weights are non-negative. The graph does not need to be fully connected: if there is no edge from item i to j, then wig = 0. Self-edges are allowed. For example, in text summarization one can create an undirected, fully connected graph on the sentences. The edge between sentences i, j has weight wig, their cosine similarity. In social network analysis one can create a directed graph with wig being the number of phone calls i made to j. The graph should be constructed carefully to reflect domain knowledge. For examples, see (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Pang and Lee, 2004). The user can optionally supply an arbitrary ranking on the items as prior knowledge. In this case GRASSHOPPER can be viewed as a re-ranking method. For example, in information retrieval, the prior ranking can be the ranking by relevance scores. In text summarization, it can be the position of sentences in the original article. (There is evidence that the first few sentences in an article are likely good summaries.) Somewhat unconventionally, the prior ranking is represented as a probability distribution r = (r1, · · · , rn)T such that ri &gt; 0, En i�1 ri = 1. The highest-ranked item has the la</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In ACL, pages 271–278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W H Press</author>
<author>S A Teukolsky</author>
<author>W T Vetterling</author>
<author>B P Flannery</author>
</authors>
<title>Numerical recipes in C: the art of scienti�c computing.</title>
<date>1992</date>
<publisher>Cambridge University Press</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="13694" citStr="Press et al., 1992" startWordPosition="2409" endWordPosition="2412"> difficult to Figure 2: The GRASSHOPPER algorithm determine the appropriate number and control the shape of clusters. In contrast, GRASSHOPPER does not involve clustering. However it is still able to automatically take advantage of cluster structures in the data. In each iteration we need to compute the fundamental matrix (3). This involves inverting an (n − |G|) x (n − |G|) matrix, which is expensive. However the Q matrix is reduced by one row and one column in every iteration, but is otherwise unchanged. This allows us to apply the matrix inversion lemma (Sherman-Morrison-Woodbury formula) (Press et al., 1992). Then we only need to invert the matrix once in the first iteration, but not in subsequent iterations. Space precludes a full discussion, but we point out that it presents a significant speed up. A Matlab implementation can be found athttp://www.cs.wisc.edu/—jerryzhu/ pub/grasshopper.m. 3 Experiments 3.1 Text Summarization Multi-document extractive text summarization is a prime application for GRASSHOPPER. In this task, we must select and rank sentences originating from a set of documents about a particular topic or event. The goal is to produce a summary that includes all the relevant facts,</context>
</contexts>
<marker>Press, Teukolsky, Vetterling, Flannery, 1992</marker>
<rawString>W.H. Press, S.A. Teukolsky, W.T. Vetterling, and B.P. Flannery. 1992. Numerical recipes in C: the art of scienti�c computing. Cambridge University Press New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir Radev</author>
</authors>
<title>A common theory of information fusion from multiple text sources, step one: Cross-document structure.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st ACL SIGDIAL Workshop on Discourse and Dialogue.</booktitle>
<contexts>
<context position="2800" citStr="Radev, 2000" startWordPosition="456" endWordPosition="457"> connected by their interactions, e.g., phone calls. Active groups of people have strong interactions among them, but many groups may exist with fewer interactions. If we want a list of people that represent various groups, it is important to consider both activity and diversity, and not to fill the list with people from the same active groups. Given the importance of diversity in ranking, there has been significant research in this area. Perhaps the most well-known method is maximum marginal relevance (MMR) (Carbonell and Goldstein, 1998), as well as cross-sentence informational subsumption (Radev, 2000), mixture models (Zhang et al., 2002), subtopic diversity (Zhai et al., 2003), diversity penalty (Zhang et al., 2005), and others. The basic idea is to penalize redundancy by lowering an item’s rank if it is similar to items already ranked. However, these methods often treat centrality ranking and diversity ranking separately, sometimes with heuristic procedures. Proceedings of NAACL HLT 2007, pages 97–104, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics We propose GRASSHOPPER (Graph Random-walk with Absorbing StateS that HOPs among PEaks for Ranking), a novel ranki</context>
<context position="16262" citStr="Radev, 2000" startWordPosition="2816" endWordPosition="2817"> score by finding its probability under the stationary distribution of a random walk on this graph. Unlike the similar PageRank algorithm (Page et al., 1998), LexRank uses an undirected graph of sentences rather than Web pages, and the edge weights are either cosine values or 0/1 with thresholding. The LexRank centrality can be combined with other centrality measures, as well as sentence position information. After this first step of computing centrality, a second step performs re-ranking to avoid redundancy in the highly ranked sentences. LexRank uses crosssentence informational subsumption (Radev, 2000) to this end, but MMR (Carbonell and Goldstein, 1998) has also been widely used in the text summarization community. These methods essentially disqualify sentences that are too lexically similar to sentences ranked higher by centrality. In short, similar graph-based approaches to text summarization rely on two distinct processes to measure each sentence’s importance and ensure some degree of diversity. GRASSHOPPER, on the other hand, achieves the same goal in a unified procedure. We apply GRASSHOPPER to text summarization in the following manner. Our graph contains nodes for all the sentences </context>
</contexts>
<marker>Radev, 2000</marker>
<rawString>Dragomir Radev. 2000. A common theory of information fusion from multiple text sources, step one: Cross-document structure. In Proceedings of the 1st ACL SIGDIAL Workshop on Discourse and Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ChengXiang Zhai</author>
<author>William W Cohen</author>
<author>John Lafferty</author>
</authors>
<title>Beyond independent relevance: Methods and evaluation metrics for subtopic retrieval.</title>
<date>2003</date>
<booktitle>In SIGIR’03.</booktitle>
<contexts>
<context position="2068" citStr="Zhai et al., 2003" startWordPosition="336" endWordPosition="339">esentative, i.e., similar to many other sentences, so that 97 it likely conveys the central meaning of the articles. On the other hand, we do not want multiple nearidentical sentences. The top sentences should be diverse. As another example, in information retrieval on news events, an article is often published by multiple newspapers with only minor changes. It is undesirable to rank all copies of the same article highly, even though it may be the most relevant. Instead, the top results should be different and complementary. In other words, one wants ‘subtopic diversity’ in retrieval results (Zhai et al., 2003). The need for diversity in ranking is not unique to natural language processing. In social network analysis, people are connected by their interactions, e.g., phone calls. Active groups of people have strong interactions among them, but many groups may exist with fewer interactions. If we want a list of people that represent various groups, it is important to consider both activity and diversity, and not to fill the list with people from the same active groups. Given the importance of diversity in ranking, there has been significant research in this area. Perhaps the most well-known method is</context>
</contexts>
<marker>Zhai, Cohen, Lafferty, 2003</marker>
<rawString>ChengXiang Zhai, William W. Cohen, and John Lafferty. 2003. Beyond independent relevance: Methods and evaluation metrics for subtopic retrieval. In SIGIR’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Zhang</author>
<author>Jamie Callan</author>
<author>Thomas Minka</author>
</authors>
<title>Novelty and redundancy detection in adaptive filtering.</title>
<date>2002</date>
<booktitle>In SIGIR’02.</booktitle>
<contexts>
<context position="2837" citStr="Zhang et al., 2002" startWordPosition="460" endWordPosition="463">ns, e.g., phone calls. Active groups of people have strong interactions among them, but many groups may exist with fewer interactions. If we want a list of people that represent various groups, it is important to consider both activity and diversity, and not to fill the list with people from the same active groups. Given the importance of diversity in ranking, there has been significant research in this area. Perhaps the most well-known method is maximum marginal relevance (MMR) (Carbonell and Goldstein, 1998), as well as cross-sentence informational subsumption (Radev, 2000), mixture models (Zhang et al., 2002), subtopic diversity (Zhai et al., 2003), diversity penalty (Zhang et al., 2005), and others. The basic idea is to penalize redundancy by lowering an item’s rank if it is similar to items already ranked. However, these methods often treat centrality ranking and diversity ranking separately, sometimes with heuristic procedures. Proceedings of NAACL HLT 2007, pages 97–104, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics We propose GRASSHOPPER (Graph Random-walk with Absorbing StateS that HOPs among PEaks for Ranking), a novel ranking algorithm that encourages diversit</context>
</contexts>
<marker>Zhang, Callan, Minka, 2002</marker>
<rawString>Yi Zhang, Jamie Callan, and Thomas Minka. 2002. Novelty and redundancy detection in adaptive filtering. In SIGIR’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benyu Zhang</author>
<author>Hua Li</author>
<author>Yi Liu</author>
<author>Lei Ji</author>
<author>Wensi Xi</author>
<author>Weiguo Fan</author>
<author>Zheng Chen</author>
<author>Wei-Ying Ma</author>
</authors>
<title>Improving web search results using affinity graph.</title>
<date>2005</date>
<booktitle>In SIGIR’05.</booktitle>
<contexts>
<context position="2917" citStr="Zhang et al., 2005" startWordPosition="472" endWordPosition="475">em, but many groups may exist with fewer interactions. If we want a list of people that represent various groups, it is important to consider both activity and diversity, and not to fill the list with people from the same active groups. Given the importance of diversity in ranking, there has been significant research in this area. Perhaps the most well-known method is maximum marginal relevance (MMR) (Carbonell and Goldstein, 1998), as well as cross-sentence informational subsumption (Radev, 2000), mixture models (Zhang et al., 2002), subtopic diversity (Zhai et al., 2003), diversity penalty (Zhang et al., 2005), and others. The basic idea is to penalize redundancy by lowering an item’s rank if it is similar to items already ranked. However, these methods often treat centrality ranking and diversity ranking separately, sometimes with heuristic procedures. Proceedings of NAACL HLT 2007, pages 97–104, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics We propose GRASSHOPPER (Graph Random-walk with Absorbing StateS that HOPs among PEaks for Ranking), a novel ranking algorithm that encourages diversity. GRASSHOPPER is an alternative to MMR and variants, with a principled mathemat</context>
<context position="7155" citStr="Zhang et al., 2005" startWordPosition="1204" endWordPosition="1207">gine a random walker on the graph. At each step, the walker may do one of two things: with probability A, she moves to a neighbor state1 according to the edge weights; otherwise she is teleported to a random state according to the distribution r. Under mild conditions (which are satisfied in our setting, see below), the stationary distribution of the random walk defines the visiting probabilities of the nodes. The states with large probabilities can be regarded as central items, an idea used in Google PageRank (Page et al., 1998) and other information retrieval systems (Kurland and Lee, 2005; Zhang et al., 2005), text summarization (Erkan and Radev, 2004), keyword extraction (Mihalcea and Tarau, 2004) and so on. Depending on A, items high on the user-supplied prior ranking r may also have large stationary probabilities, which is a way to incorporate the prior ranking. As an example, we created a toy data set with 300 points in Figure 1(a). There are roughly three groups with different densities. We created a fully connected graph on the data, with larger edge weights if points are closer2. Figure 1(b) shows the stationary distribution of the random walk on the graph. 1We use state, node and item inte</context>
</contexts>
<marker>Zhang, Li, Liu, Ji, Xi, Fan, Chen, Ma, 2005</marker>
<rawString>Benyu Zhang, Hua Li, Yi Liu, Lei Ji, Wensi Xi, Weiguo Fan, Zheng Chen, and Wei-Ying Ma. 2005. Improving web search results using affinity graph. In SIGIR’05.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>