<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000011">
<title confidence="0.939607">
Graph-based Learning for Statistical Machine Translation
</title>
<author confidence="0.991732">
Andrei Alexandrescu
</author>
<affiliation confidence="0.9979545">
Dept. of Comp. Sci. Eng.
University of Washington
</affiliation>
<address confidence="0.7835">
Seattle, WA 98195, USA
</address>
<email confidence="0.999184">
andrei@cs.washington.edu
</email>
<author confidence="0.990109">
Katrin Kirchhoff
</author>
<affiliation confidence="0.998216">
Dept. of Electrical Eng.
University of Washington
</affiliation>
<address confidence="0.618177">
Seattle, WA 98195, USA
</address>
<email confidence="0.998227">
katrin@ee.washington.edu
</email>
<sectionHeader confidence="0.996655" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999443647058823">
Current phrase-based statistical machine
translation systems process each test sentence
in isolation and do not enforce global consis-
tency constraints, even though the test data
is often internally consistent with respect to
topic or style. We propose a new consistency
model for machine translation in the form
of a graph-based semi-supervised learning
algorithm that exploits similarities between
training and test data and also similarities
between different test sentences. The algo-
rithm learns a regression function jointly over
training and test data and uses the resulting
scores to rerank translation hypotheses. Eval-
uation on two travel expression translation
tasks demonstrates improvements of up to 2.6
BLEU points absolute and 2.8% in PER.
</bodyText>
<sectionHeader confidence="0.998882" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999951">
Current phrase-based statistical machine translation
(SMT) systems commonly operate at the sentence
level—each sentence is translated in isolation, even
when the test data consists of internally coherent
paragraphs or stories, such as news articles. For
each sentence, SMT systems choose the translation
hypothesis that maximizes a combined log-linear
model score, which is computed independently of
all other sentences, using globally optimized com-
bination weights. Thus, similar input strings may
be translated in very different ways, depending on
which component model happens to dominate the
combined score for that sentence. This is illustrated
by the following example (from the IWSLT 2007
</bodyText>
<page confidence="0.993572">
119
</page>
<tableCaption confidence="0.872140545454545">
Arabic-English translation task):
Source 1: Asf lA ymknk *lk hnAk klfp HwAly vmAnyn
dwlAr lAlsAEp AlwAHdp
Ref: sorry you can’t there is a cost the charge is eighty
dollars per hour
1-best: i’m sorry you can’t there in the cost about eighty
dollars for a one o’clock
Source 2: E*rA lA ymknk t$gyl AltlfAz HtY tqlE
AlTA}rp
Ref: sorry you cannot turn the tv on until the plane has
taken off
</tableCaption>
<bodyText confidence="0.977504909090909">
1-best: excuse me i you turn tv until the plane departs
The phrase lA ymknk (you may not/you cannot)
is translated differently (and wrongly in the sec-
ond case) due to different segmentations and phrase
translations chosen by the decoder. Though differ-
ent choices may be sometimes appropriate, the lack
of constraints enforcing translation consistency of-
ten leads to suboptimal translation performance. It
would be desirable to counter this effect by encour-
aging similar outputs for similar inputs (under a suit-
ably defined notion of similarity, which may include
e.g. a context specification for the phrase/sentence).
In machine learning, the idea of forcing the out-
puts of a statistical learner to vary smoothly with the
underlying structure of the inputs has been formal-
ized in the graph-based learning (GBL) framework.
In GBL, both labeled (train) and unlabeled (test)
data samples are jointly represented as vertices in a
graph whose edges encode pairwise similarities be-
tween samples. Various learning algorithms can be
applied to assign labels to the test samples while en-
suring that the classification output varies smoothly
</bodyText>
<note confidence="0.8062">
Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 119–127,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999953">
along the manifold defined by the graph. GBL has
been successfully applied to a range of problems in
computer vision, computational biology, and natu-
ral language processing. However, in most cases,
the learning tasks consisted of unstructured classi-
fication, where the input was represented by fixed-
length feature vectors and the output was one of a
finite set of discrete labels. In machine translation,
by contrast, both inputs and outputs consist of word
strings of variable length, and the number of possi-
ble outputs is not fixed and practically unlimited.
In this paper we propose a new graph-based learn-
ing algorithm with structured inputs and outputs to
improve consistency in phrase-based statistical ma-
chine translation. We define a joint similarity graph
over training and test data and use an iterative label
propagation procedure to regress a scoring function
over the graph. The resulting scores for unlabeled
samples (translation hypotheses) are then combined
with standard model scores in a log-linear transla-
tion model for the purpose of reranking. Our con-
tributions are twofold. First, from a machine trans-
lation perspective, we design and evaluate a global
consistency model enforcing that similar inputs re-
ceive similar translations. Second, from a machine
learning perspective, we apply graph-based learning
to a task with structured inputs and outputs, which
is a novel contribution in itself since previous ap-
plications of GBL have focused on predicting cat-
egorical labels. We evaluate our approach on two
machine translation tasks, the IWSLT 2007 Italian-
to-English and Arabic-to-English tasks, and demon-
strate significant improvements over the baseline.
</bodyText>
<sectionHeader confidence="0.990535" genericHeader="method">
2 Graph-Based Learning
</sectionHeader>
<bodyText confidence="0.99943876">
GBL algorithms rely on a similarity graph consisting
of a set of nodes representing data samples xi (where
i ranges over 1, ... , l labeled points and l + 1, ... , n
unlabeled points), and a set of weighted edges en-
coding pairwise similarities between samples. The
graph is characterized by a weight matrix W whose
elements Wij ≥ 0 are the similarity values for edges
between vertices xi and xj, and by its label vector
Y = (y1,... yl), yi E {1, ... , C} that defines la-
bels for the first l points. If there is no edge linking
nodes xi and xj, then Wij = 0. There is consider-
able freedom in choosing the weights. The similar-
ity measure used to compute the edge weights de-
termines the graph structure and is the most impor-
tant factor in successfully applying GBL. In most
applications of GBL, data samples are represented
by fixed-length feature vectors, and cosine similar-
ity or Euclidean distance-based measures are used
for edge weights.
Learning algorithms on similarity graphs include
e.g. min-cut (Blum and Chawla, 2001), spectral
graph transducer (Joachims, 2003), random walk-
based approaches (Szummer and Jaakkola, 2001),
and label propagation (Zhu and Ghahramani, 2002).
The algorithm proposed herein is based on the latter.
</bodyText>
<subsectionHeader confidence="0.975888">
2.1 Label Propagation
</subsectionHeader>
<bodyText confidence="0.999567">
Given a graph defined by a weight matrix W and
a label set Y , the basic label propagation algorithm
proceeds as follows:
</bodyText>
<listItem confidence="0.999550071428571">
1. Initialize the matrix P as P = Wij−Wii
2� Ej Wij−Wii
2. Initialize a n x C matrix f with binary vectors
encoding the known labels for the first l rows:
fi = δC(yi) ∀i E {1, 2, ... ,l}, where δC(yi) is
the Kronecker vector of length C with 1 in po-
sition yi and 0 elsewhere. The remaining rows
of f can be zero.
3. f′ ← P x f
4. Clamp already-labeled data rows: f′ i = δC(yi)
∀i E {1,2,...,l}
5. If f′ ∼= f, stop.
6. f ← f′
7. Repeat from step 3.
</listItem>
<bodyText confidence="0.921599666666667">
After convergence, f contains the solution in rows
l + 1 to n in the form of unnormalized label proba-
bility distributions. Hard labels can be obtained by
</bodyText>
<equation confidence="0.9969175">
ˆyi = arg max fij ∀i E {l + 1, ... , n} (1)
jE{1,...,C}
</equation>
<bodyText confidence="0.538486">
The algorithm minimizes the following cost func-
tion (Zhu, 2005):
</bodyText>
<equation confidence="0.996592333333333">
C
S = � Wij(fik − fjk)2 (2)
k=1 i&gt;l V j&gt;l
</equation>
<footnote confidence="0.5281455">
S measures the smoothness of the learned function,
i.e., the extent to which the labeling allows large-
weight edges to link nodes of different labels. By
minimizing S, label propagation finds a labeling
</footnote>
<page confidence="0.99355">
120
</page>
<bodyText confidence="0.999845285714286">
that, to the extent possible, assigns similar soft labels
(identical hard labels) to nodes linked by edges with
large weights (i.e., highly similar samples). The
labeling decision takes into account not only sim-
ilarities between labeled and unlabeled nodes (as
in nearest-neighbor approaches) but also similarities
among unlabeled nodes. Label propagation has been
used successfully for various classification tasks,
e.g. image classification and handwriting recogni-
tion (Zhu, 2005). In natural language processing, la-
bel propagation has been used for document classifi-
cation (Zhu, 2005), word sense disambiguation (Niu
et al., 2005; Alexandrescu and Kirchhoff, 2007), and
sentiment categorization (Goldberg and Zhu, 2006).
</bodyText>
<sectionHeader confidence="0.985038" genericHeader="method">
3 Graph-Based Learning for Machine
Translation
</sectionHeader>
<bodyText confidence="0.999293583333333">
Our goal is to exploit graph-based learning for im-
proving consistency in statistical phrase-based ma-
chine translation. Intuitively, a set of similar source
sentences should receive similar target-language
translations. This means that similarities between
training and test sentences should be taken into ac-
count, but also similarities between different test
sentences, which is a source of information currently
not exploited by standard SMT systems. To this
end we define a graph over the training and test sets
with edges between test and training sentences as
well as between different test sentences. In cases
where a test sentence does not have any connections
to training sentences but is connected to other test
sentences, helpful information about preferred trans-
lations can be propagated via these edges.
As mentioned above, the problem of machine
translation does not neatly fit into the standard
GBL framework. Given that our samples consist
of variable-length word strings instead of feature
vectors, the standard cosine or Euclidean-distance
based similarity measures cannot be used mean-
ingfully, and the number of possible “labels”—
correct translations—is unbounded and practically
very large. We thus need to modify both the graph
construction and the label propagation algorithms.
First, we handle the problem of unlimited out-
puts by applying GBL to rescoring only. In most
SMT systems, an N-best list (generated by a first de-
coding pass) approximates the search space of good
hypotheses reasonably well, provided N is large
enough. For all hypotheses of all sentences in the
test set (set we denote with H), the system learns a
ranking function r : H —* [0, 1]. Larger values of r
indicate better hypotheses. The corresponding loss
functional is
</bodyText>
<equation confidence="0.951179">
L(r) = � Wij [r(xi) − r(xj)]2 (3)
i,j
</equation>
<bodyText confidence="0.999891222222222">
L(r) measures the smoothness of r over the graph
by penalizing highly similar clusters of nodes that
have a high variance of r (in other words, simi-
lar input sentences that have very different transla-
tions). The smaller L(r), the “smoother” r is over
the graph. Thus, instead of directly learning a clas-
sification function, we learn a regression function—
similar to (Goldberg and Zhu, 2006)—that is then
used for ranking the hypotheses.
</bodyText>
<subsectionHeader confidence="0.998167">
3.1 Graph Construction
</subsectionHeader>
<bodyText confidence="0.999968444444444">
Each graph node represents a sentence pair (consist-
ing of source and target strings), and edge weights
represent the combined similarity scores computed
from comparing both the source sides and target
sides of a pair of nodes. Given a training set
with l source and target language sentence pairs
(s1, t1), ... , (sl, tl) and a test set with l + 1, ..., n
source sentences, sl+1, ... , sn, the construction of
the similarity graph proceeds as follows:
</bodyText>
<listItem confidence="0.9347695">
1. For each test sentence si, i = l + 1, ... , n,
find a set Straini of similar training source
sentences and a set Stesti of similar test sen-
tences (excluding si and sentences identical to
it) by applying a string similarity function σ to
the source sides only and retaining sentences
whose similarity exceeds a threshold θ. Dif-
ferent θ’s can be used for training vs. test sen-
tences; we use the same θ for both sets.
2. For each hypothesis hsi generated for si by a
baseline system, compute its similarity to the
target sides of all sentences in Straini. The
overall similarity is then defined by the com-
bined score
</listItem>
<equation confidence="0.746139">
αij = κ (σ(si, sj), σ(hsi, tj)) (4)
</equation>
<bodyText confidence="0.907068">
where i = l + 1,... n, j = 1, ... , |Straini |and
κ : R+ x R+ —* R+ is an averaging function.
</bodyText>
<page confidence="0.979489">
121
</page>
<bodyText confidence="0.859911428571429">
If αij &gt; 0, establish graph nodes for hsi and tj
and link them with an edge of weight αij.
3. For each hypothesis hsi and each hypothe-
sis generated for each of the sentences sk E
Σtesti, compute similarity on the target side and
use the combined similarity score as the edge
weight between nodes for hsi and hsk.
</bodyText>
<listItem confidence="0.82989">
4. Finally,for each node xt representing a train-
ing sentence, assign r(xt) = 1 and also de-
fine its synthetic counterpart: a vertex x′t with
r(x′t) = 0. For each edge incident to xt of
weight Wth, define a corresponding edge of
weight 1 − Wt′h.
</listItem>
<bodyText confidence="0.999943171875">
The synthetic nodes and edges need to be added
to prevent the label propagation algorithm from con-
verging to the trivial solution that assigns r = 1 to
all points in the graph. This choice is theoretically
motivated—a similarity graph for regression should
have not only “sources” (good nodes with high value
of r) but also “sinks” (counterparts for the sources).
Figure 1 illustrates the connections of a test node.
Similarity Measure The similarity measure used
for comparing source and target sides is of prime
importance, as it determines the structure of the
graph. This has consequences for both computa-
tional efficiency (denser graphs require more com-
putation and memory) and the accuracy of the out-
come. A low similarity threshold results in a rich
graph with a large number of edges but possibly in-
troduces noise. A higher threshold leads to a small
graph emphasizing highly similar samples but with
too many disconnected components. The similarity
measure is also the means by which domain knowl-
edge can be incorporated into the graph construc-
tion process. Similarity may be defined at the level
of surface word strings, but may also include lin-
guistic information such as morphological features,
part-of-speech tags, or syntactic structures. Here,
we compare two similarity measures: the famil-
iar BLEU score (Papineni et al., 2002) and a score
based on string kernels. In using BLEU we treat
each sentence as a complete document. BLEU is not
symmetric—when comparing two sentences, differ-
ent results are obtained depending on which one is
considered the reference and which one is the hy-
pothesis. For computing similarities between train
and test translations, we use the train translation as
the reference. For computing similarity between two
test hypotheses, we compute BLEU in both direc-
tions and take the average. We note that more ap-
propriate distance measures are certainly possible.
Many previous studies, such as (Callison-Burch et
al., 2006), have pointed out drawbacks of BLEU,
and any other similarity measure could be utilized
instead. In particular, similarity measures that model
aspects of sentences that are ill handled by standard
phrase-based decoders (such as syntactic structure
or semantic information) could be useful here.
A more general way of computing similarity be-
tween strings is provided by string kernels (Lodhi et
al., 2002; Rousu and Shawe-Taylor, 2005), which
have been extensively used in bioinformatics and
email spam detection. String kernels map strings
into a feature space defined by all possible sub-
strings of the string up a fixed length k, and com-
puting the dot product between the resulting feature
vectors. Several variants of basic string kernels ex-
ist, notably those allowing gaps or mismatches, and
efficient implementations have been devised even
for large scale applications. Formally, we define a
sentence s as a concatenation of symbols from a fi-
nite alphabet Σ (the vocabulary of the language) and
an embedding function from strings to feature vec-
tors, φ : Σ∗ —* X A kernel function 1C(s, t) com-
putes the distance between the resulting vectors for
two sentences s and t. In our case, the embedding
function is defined as
</bodyText>
<equation confidence="0.996526">
�φku(s) := λ|i |u E Σk (5)
isu=s(i)
</equation>
<bodyText confidence="0.998998">
where k is the maximum length of substrings, |i |is
the length of i, and λ is a penalty parameter for each
gap encountered in the substring. 1C is defined as
</bodyText>
<equation confidence="0.949568">
1C(s, t) = � (φu(s), φu(t))wu (6)
u
</equation>
<bodyText confidence="0.8797667">
where w is a weight dependent on the length of the
substring u. Finally, the kernel score is normalized
V/
by 1C(s, s) · 1C(t, t) to discourage long sentences
from being favored. Thus, our similarity measure is
a gapped, normalized string kernel, which is a more
general measure than BLEU in that is considers non-
contiguous substrings. We use a dynamic program-
ming implementation of string kernels (Rousu and
Shawe-Taylor, 2005).
</bodyText>
<page confidence="0.99022">
122
</page>
<bodyText confidence="0.999864744680851">
For the combination of source-side and target-
side similarity scores (the function we denoted as κ)
we test two simple schemes, using either the ge-
ometric or the arithmetic mean of the individual
scores. In the first case, large edge weights only re-
sult when both source and target are close to each
other; the latter may produce high edge weights
when only one of them (typically the source score)
is high. More sophisticated combination schemes,
using e.g. weighted combination, could be used but
were not investigated in this study.
Scalability Poor scalability is often mentioned as
a drawback of graph-based learning. Straightfor-
ward implementations of GBL algorithms often rep-
resent the joint training and test data in working
memory and therefore do not scale well to large
data sets. However, we have developed several tech-
niques to improve scalability without impeding ac-
curacy. First, we construct separate graphs for each
test sentence without losing global connectivity in-
formation. The graph for a test sentence is com-
puted as the transitive closure of the edge set E over
the nodes containing all hypotheses for that test sen-
tence. This smaller graph does not affect the out-
come of the learning process for the chosen sentence
because in label propagation the learned value r(xi)
can be influenced by that of another node xj if and
only if xj is reachable from xi. In the worst the-
oretical case, the transitive closure could compre-
hend the entire graph, but in practice the edge set is
never that dense and can be easily pruned based on
the heuristic that faraway nodes connected through
low-weight edges have less influence on the result.
We use a simple embodiment of this heuristic in a
work-list approach: starting from the nodes of inter-
est (hypotheses for the focal sentence), we expand
the closure starting with the direct neighbors, which
have the largest influence; then add their neighbors,
which have less influence, and so forth. A thresh-
old on the number of added vertices limits undue
expansion while capturing either the entire closure
or a good approximation of it. Another practical
computational advantage of portioning work is that
graphs for different hypothesis sets can be trivially
created and used in parallel, whereas distributing
large matrix-vector multiplication is much more dif-
ficult (Choi, 1998). The disadvantage is that overall
</bodyText>
<figureCaption confidence="0.9934975">
Figure 1: Connections for hypothesis node xh. Similar-
ity edges with weights Wth link the node with train sen-
tences xt, for which r(xt) = 1. For each of these edges
we define a dissimilarity edge of weight 1− Wth, linking
the node with node x′t for which r(x′t) = 0. The vertex is
also connected to other test vertices (the dotted edges).
</figureCaption>
<bodyText confidence="0.9994595">
redundant computations are being made: incomplete
estimates of r are computed for the ancillary nodes
in the transitive closure and then discarded.
Second, we obtain a reduction in graph size of or-
ders of magnitude by collapsing all training vertices
of the same r that are connected to the same test
vertex into one and sum the edge weights. This is
equivalent to the full graph for learning purposes.
</bodyText>
<subsectionHeader confidence="0.997697">
3.2 Propagation
</subsectionHeader>
<bodyText confidence="0.990706">
Label propagation proceeds as follows:
</bodyText>
<listItem confidence="0.90371664">
1. Compute the transitive closure over the edges
starting from all hypothesis nodes of a given
sentence.
2. On the resulting graph, collapse all test-train
similarities for each test node by summing edge
weights. Obtain accumulated similarities in
row and column 1 of the similarity matrix W.
3. Normalize test-to-train weights such that
Ej W1j = Ej Wj1 = 1.
4. Initialize the matrix P as P Wij
Z� — — 1−Wi1+Pj Wij .
(The quantity 1−W1i in the denominator is the
weight of the dissimilarity edge.)
5. Initialize a column vector f of height n with
f1 = 1 (corresponding to node x1) and 0 in the
remaining positions.
6. f′ +— P x f
7. Clamp f′1: f′1 = 1
8. If f′ f, continue with step 11.
9. f +— f′
10. Repeat from step 6.
11. The result r is in the slots of f that correspond
to the hypotheses of interest. Normalize per
sentence if needed, and rank in decreasing or-
der of r.
</listItem>
<equation confidence="0.907101">
. . . . . .
1 W1h 1 − W1h 0
1 0
</equation>
<page confidence="0.993104">
123
</page>
<bodyText confidence="0.920547666666667">
Convergence Our algorithm’s convergence proof
is similar to that for standard label propagation (Zhu,
2005, p. 6). We split P as follows:
</bodyText>
<equation confidence="0.9856395">
L0 PLU J (7)
PUL PUU
</equation>
<bodyText confidence="0.999420833333333">
where PUL is a column vector holding global simi-
larities of test hypotheses with train sentences, PLU
is a horizontal vector holding the same similarities
(though PLU =� PTUL due to normalization), and
PUU holds the normalized similarities between pairs
of test hypotheses. We also separate f:
</bodyText>
<equation confidence="0.88869">
f =IfU1 (8)
</equation>
<bodyText confidence="0.999952333333333">
where we distinguish the first entry because it repre-
sents the training part of the data. With these nota-
tions, the iteration formula becomes:
</bodyText>
<equation confidence="0.992408666666667">
f′U = PUUfU + PUL (9)
Unrolling the iteration yields:
&amp;quot; ! #
Xn
fU = lim (PUU)nf0 U + (PUU)i−1 PUL
n→∞i=1
</equation>
<bodyText confidence="0.9930685">
It can be easily shown that the first term converges
to zero because of normalization in step 4 (Zhu,
2005). The sum in the second term converges to
(I − PUU)−1, so the unique fixed point is:
</bodyText>
<equation confidence="0.99732">
fU = (I − PUU)−1PUL (10)
</equation>
<bodyText confidence="0.999724333333333">
Our system uses the iterative form. On the data sets
used, convergence took 61.07 steps on average.
At the end of the label propagation algorithm, nor-
malized scores are obtained for each N-best list (sen-
tences without any connections whatsoever are as-
signed zero scores). These are then used together
with the other component models in log-linear com-
bination. Combination weights are optimized on a
held-out data set.
</bodyText>
<sectionHeader confidence="0.968303" genericHeader="method">
4 Data and System
</sectionHeader>
<bodyText confidence="0.999593095238095">
We evaluate our approach on the IWSLT 2007
Italian-to-English (IE) and Arabic-to-English (AE)
travel tasks. The first is a challenge task, where the
training set consists of read sentences but the de-
velopment and test data consist of spontaneous di-
alogues. The second is a standard travel expres-
sion translation task consisting entirely of read in-
put. For our experiments we chose the text input
(correct transcription) condition only. The data set
sizes are shown in Table 1. We split the IE develop-
ment set into two subsets of 500 and 496 sentences
each. The first set (dev-1) is used to train the system
parameters of the baseline system and as a training
set for GBL. The second is used to tune the GBL pa-
rameters. For each language pair, the baseline sys-
tem was trained with additional out-of-domain text
data: the Italian-English Europarl corpus (Koehn,
2005) in the case of the IE system, and 5.5M words
of newswire data (LDC Arabic Newswire, Multiple-
Translation Corpus and ISI automatically extracted
parallel data) in the case of the AE system.
</bodyText>
<table confidence="0.983755888888889">
Set #sent pairs #words #refs
IE train 26.5K 160K 1
IE dev-1 500 4308 1
IE dev-2 496 4204 1
IE eval 724 6481 4
AE train 23K 160K 1
AE dev4 489 5392 7
AE dev5 500 5981 7
AE eval 489 2893 6
</table>
<tableCaption confidence="0.999456">
Table 1: Data set sizes and reference translations count.
</tableCaption>
<bodyText confidence="0.999919823529412">
Our baseline is a standard phrase-based SMT
system based on alog-linear model with the fol-
lowing feature functions: two phrase-based trans-
lation scores, two lexical translation scores, word
count and phrase count penalty, distortion score,
and language model score. We use the Moses de-
coder (Koehn et al., 2007) with a reordering limit of
4 for both languages, which generates N-best lists
of up to 2000 hypotheses per sentence in a first pass.
The second pass uses apart-of-speech (POS) based
trigram model, trained on POS sequences generated
by a MaxEnt tagger (Ratnaparkhi, 1996). The lan-
guage models are trained on the English side using
SRILM (Stolcke, 2002) and modified Kneser-Ney
discounting for the first-pass models and Witten-
Bell discounting for the POS models. The baseline
system yields state-of-the-art performance.
</bodyText>
<equation confidence="0.39598">
P=
</equation>
<page confidence="0.980374">
124
</page>
<table confidence="0.999490875">
Weighting dev-2 eval
none (baseline) 22.3/53.3 29.6/45.5
23.4/51.5 30.7/44.1
23.5/51.6 30.6/44.3
23.2/51.8 30.0/44.6
System dev-2 eval
Baseline 22.3/53.3 29.6/45.5
GBL 24.3/51.0 32.2/42.7
</table>
<tableCaption confidence="0.9811158">
Table 3: GBL results (%BLEU/PER) on IE tasks with
string-kernel based similarity measure.
Table 2: GBL results (%BLEU/PER) on IE task
for different weightings of labeled-labeled vs. labeled-
unlabeled graph edges (BLEU-based similarity measure).
</tableCaption>
<sectionHeader confidence="0.983758" genericHeader="evaluation">
5 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999944339622642">
We started with the IE system and initially inves-
tigated the effect of only including edges between
labeled and unlabeled samples in the graph. This
is equivalent to using a weighted k-nearest neighbor
reranker that, for each hypothesis, computes average
similarity with its neighborhood of labeled points,
and uses the resulting score for reranking.
Starting with the IE task and the BLEU-based
similarity metric, we ran optimization experiments
that varied the similarity threshold and compared
sum vs. product combination of source and target
similarity scores, settling for 0 = 0.7 and prod-
uct combination. We experimented with three dif-
ferent ways of weighting the contributions from
labeled-unlabeled vs. unlabeled-unlabeled edges:
(a) no weighting, (b) labeled-to-unlabeled edges
were weighted 4 times stronger than unlabeled-
unlabeled ones; and (c) labeled-to-unlabeled edges
were weighted 2 times stronger. The weighting
schemes do not lead to significantly different results.
The best result obtained shows a gain of 1.2 BLEU
points on the dev set and 1 point on the eval set, re-
flecting PER gains of 2% and 1.2%, respectively.
We next tested the string kernel based similarity
measure. The parameter values were 0.5 for the gap
penalty, a maximum substring length of k = 4, and
weights of 0, 0.1, 0.2, 0.7. These values were chosen
heuristically and were not tuned extensively due to
time constraints. Results (Table 3) show significant
improvements in PER and BLEU.
In the context of the BTEC challenge task it is
interesting to compare this approach to adding the
development set directly to the training set. Part of
the improvements may be due to utilizing kNN in-
formation from a data set that is matched to the test
set in terms of style. If this data were also used for
training the initial phrase table, the improvements
might disappear. We first optimized the log-linear
model combination weights on the entire dev07 set
(dev-1 and dev-2 in Table 1) before retraining the
phrase table using the combined train and dev07
data. The new baseline performance (shown in Ta-
ble 4) is much better than before, due to the im-
proved training data. We then added GBL to this
system by keeping the model combination weights
trained for the previous system, using the N-best
lists generated by the new system, and using the
combined train+dev07 set as a train set for select-
ing similar sentences. We used the GBL parameters
that yielded the best performance in the experiments
described above. As can be seen from Table 4, GBL
again yields an improvement of up to 1.2% absolute
in both BLEU and PER.
</bodyText>
<table confidence="0.757813666666667">
System BLEU (%) PER
Baseline 37.9 38.4
GBL 39.2 37.2
</table>
<tableCaption confidence="0.9980015">
Table 4: Effect of GBL on IE system trained with
matched data (eval set).
</tableCaption>
<bodyText confidence="0.999920071428572">
For the AE task we used 0 = 0.5; however, this
threshold was not tuned extensively. Results using
BLEU similarity are shown in Table 5. The best
result on the eval set yields an improvement of 1.2
BLEU points though only 0.2% reduction in PER.
Overall, results seem to vary with parameter settings
and nature of the test set (e.g. on dev5, used as a test
set, not for optimization, a surprisingly larger im-
provement in BLEU of 2.7 points is obtained!).
Overall, sentence similarities were observed to be
lower for this task. One reason may be that the AE
system includes statistical tokenization of the source
side, which is itself error-prone in that it can split the
same word in different ways depending on the con-
</bodyText>
<page confidence="0.993072">
125
</page>
<table confidence="0.999569">
Method dev4 dev5 eval
Baseline 30.2/43.5 21.9/48.4 37.8/41.8
GBL 30.3/42.5 24.6/48.1 39.0/41.6
</table>
<tableCaption confidence="0.997653">
Table 5: AE results (%BLEU/PER, θ = 0.5)
</tableCaption>
<bodyText confidence="0.995939846153846">
text. Since our similarity measure is word-based,
this may cause similar sentences to fall below the
threshold. The string kernel does not yield any im-
provement over the BLEU-based similarity measure
on this task. One possible improvement would be to
use an extended string kernel that can take morpho-
logical similarity into account.
Example Below we give an actual example of a
translation improvement, showing the source sen-
tence, the 1-best hypotheses of the baseline system
and GBL system, respectively, the references, and
the translations of similar sentences in the graph
neighborhood of the current sentence.
</bodyText>
<table confidence="0.73173525">
Source: Al+ mE*rp Aymknk {ltqAT Swrp lnA
Baseline: i’m sorry could picture for us
GBL: excuse me could you take a picture of the us
Refs:
</table>
<tableCaption confidence="0.712612333333333">
excuse me can you take a picture of us
excuse me could you take a photo of us
pardon would you mind taking a photo of us
pardon me could you take our picture
pardon me would you take a picture of us
excuse me could you take a picture of u
</tableCaption>
<subsectionHeader confidence="0.893514">
Similar sentences:
</subsectionHeader>
<bodyText confidence="0.986239">
could you get two tickets for us
please take a picture for me
could you please take a picture of us
</bodyText>
<sectionHeader confidence="0.99997" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999963970588235">
GBL is an instance of semi-supervised learning,
specifically transductive learning. A different form
of semi-supervised learning (self-training) has been
applied to MT by (Ueffing et al., 2007). Ours is
the first study to explore a graph-based learning ap-
proach. In the machine learning community, work
on applying GBL to structured outputs is beginning
to emerge. Transductive graph-based regularization
has been applied to large-margin learning on struc-
tured data (Altun et al., 2005). However, scalability
quickly becomes a problem with these approaches;
we solve that issue by working on transitive closures
as opposed to entire graphs. String kernel represen-
tations have been used in MT (Szedmak, 2007) in
a kernel regression based framework, which, how-
ever, was an entirely supervised framework. Finally,
our approach can be likened to a probabilistic imple-
mentation of translation memories (Maruyana and
Watanabe, 1992; Veale and Way, 1997). Translation
memories are (usually commercial) databases of
segment translations extracted from a large database
of translation examples. They are typically used by
human translators to retrieve translation candidates
for subsequences of a new input text. Matches can
be exact or fuzzy; the latter is similar to the iden-
tification of graph neighborhoods in our approach.
However, our GBL scheme propagates similarity
scores not just from known to unknown sentences
but also indirectly, via connections through other un-
known sentences. The combination of a translation
memory and statistical translation was reported in
(Marcu, 2001); however, this is a combination of
word-based and phrase-based translation predating
the current phrase-based approach to SMT.
</bodyText>
<sectionHeader confidence="0.998205" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999877291666667">
We have presented a graph-based learning scheme
to implement a consistency model for SMT that
encourages similar inputs to receive similar out-
puts. Evaluation on two small-scale translation tasks
showed significant improvements of up to 2.6 points
in BLEU and 2.8% PER. Future work will include
testing different graph construction schemes, in par-
ticular better parameter optimization approaches and
better string similarity measures. More gains can
be expected when using better domain knowledge
in constructing the string kernels. This may include
e.g. similarity measures that accommodate POS tags
or morphological features, or comparisons of the
syntax trees of parsed sentence. The latter could be
quite easily incorporated into a string kernel or the
related tree kernel similarity measure. Additionally,
we will investigate the effectiveness of this approach
on larger translation tasks.
Acknowledgments This work was funded by
NSF grant IIS-032676 and DARPA under Contract
No. HR0011-06-C-0023. Any opinions, findings
and conclusions or recommendations expressed in
this material are those of the author(s) and do not
necessarily reflect the views of these agencies.
</bodyText>
<page confidence="0.998088">
126
</page>
<sectionHeader confidence="0.993875" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999912544303798">
A. Alexandrescu and K. Kirchhoff. 2007. Data-Driven
Graph Construction for Semi-Supervised Graph-
Based Learning in NLP. In HLT.
Y. Altun, D. McAllester, and M. Belkin. 2005. Max-
imum margin semi-supervised learning for structured
variables. In Proceedings ofNIPS 18.
A. Blum and S. Chawla. 2001. Learning from labeled
and unlabeled data using graph mincuts. Proc. 18th
International Conf. on Machine Learning, pages 19–
26.
C. Callison-Burch, M. Osborne, and P. Koehn. 2006. Re-
evaluating the role of BLEU in machine translation re-
search. In Proceedings of EACL.
Jaeyoung Choi. 1998. A new parallel matrix multi-
plication algorithm on distributed-memory concurrent
computers. Concurrency: Practice and Experience,
10(8):655–670.
A. Goldberg and J. Zhu. 2006. Seeing stars when
there aren’t many stars: Graph-based semi-supervised
learning for sentiment categorization. In HLT-NAACL
Workshop on Graph-based Algorithms for Natural
Language Processing.
T. Joachims. 2003. Transductive learning via spectral
graph partitioning. In Proceedings ofICML.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In ACL.
P. Koehn. 2005. Europarl: A parallel corpus for sta-
tistical machine translation. In Machine Translation
Summit X, pages 79–86, Phuket, Thailand.
H. Lodhi, J. Shawe-taylor, and N. Cristianini. 2002. Text
classification using string kernels. In Proceedings of
NIPS.
D. Marcu. 2001. Towards a unified approach to memory-
and statistical-based machine translation. In Proceed-
ings ofACL.
H. Maruyana and H. Watanabe. 1992. Tree cover search
algorithm for example-based translation. In Proceed-
ings of TMI, pages 173–184.
Zheng-Yu Niu, Dong-Hong Ji, and Chew Lim Tan. 2005.
Word sense disambiguation using label propagation
based semi-supervised learning method. In Proceed-
ings ofACL, pages 395–402.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
Bleu: a method for automatic evaluation of machine
translation. In Proceedings ofACL.
A. Ratnaparkhi. 1996. A maximum entropy part-of-
speech tagger. In Proc.of (EMNLP).
J. Rousu and J. Shawe-Taylor. 2005. Efficient computa-
tion of gap-weighted string kernels on large alphabets.
Journal ofMachine Learning Research, 6:1323–1344.
A. Stolcke. 2002. SRILM—an extensible language mod-
eling toolkit. In ICSLP, pages 901–904.
Zhuoran Wang;John Shawe-Taylor;Sandor Szedmak.
2007. Kernel regression based machine translation. In
Proceedings of NAACL/HLT, pages 185–188. Associ-
ation for Computational Linguistics.
Martin Szummer and Tommi Jaakkola. 2001. Partially
labeled classification with markov random walks. In
Advances in Neural Information Processing Systems,
volume 14. http://ai.mit.edu/people/
szummer/.
N. Ueffing, G. Haffari, and A. Sarkar. 2007. Trans-
ductive learning for statistical machine translation. In
Proceedings of the ACL Workshop on Statistical Ma-
chine Translation.
T. Veale and A. Way. 1997. Gaijin: a template-
based bootstrapping approach to example-based ma-
chine translation. In Proceedings of News Methods in
Natural Language Processing.
X. Zhu and Z. Ghahramani. 2002. Learning from labeled
and unlabeled data with label propagation. Technical
report, CMU-CALD-02.
Xiaojin Zhu. 2005. Semi-Supervised Learning with
Graphs. Ph.D. thesis, Carnegie Mellon University.
CMU-LTI-05-192.
</reference>
<page confidence="0.997309">
127
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.351953">
<title confidence="0.999759">Graph-based Learning for Statistical Machine Translation</title>
<author confidence="0.999527">Andrei Alexandrescu</author>
<affiliation confidence="0.999931">Dept. of Comp. Sci. Eng. University of Washington</affiliation>
<address confidence="0.999922">Seattle, WA 98195, USA</address>
<email confidence="0.998938">andrei@cs.washington.edu</email>
<author confidence="0.433514">Katrin</author>
<affiliation confidence="0.9994935">Dept. of Electrical University of</affiliation>
<address confidence="0.998651">Seattle, WA 98195,</address>
<email confidence="0.999805">katrin@ee.washington.edu</email>
<abstract confidence="0.986946111111111">Current phrase-based statistical machine translation systems process each test sentence in isolation and do not enforce global consistency constraints, even though the test data is often internally consistent with respect to topic or style. We propose a new consistency model for machine translation in the form of a graph-based semi-supervised learning algorithm that exploits similarities between training and test data and also similarities between different test sentences. The algorithm learns a regression function jointly over training and test data and uses the resulting scores to rerank translation hypotheses. Evaluation on two travel expression translation tasks demonstrates improvements of up to 2.6 BLEU points absolute and 2.8% in PER.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Alexandrescu</author>
<author>K Kirchhoff</author>
</authors>
<title>Data-Driven Graph Construction for Semi-Supervised GraphBased Learning in NLP.</title>
<date>2007</date>
<booktitle>In HLT.</booktitle>
<contexts>
<context position="8193" citStr="Alexandrescu and Kirchhoff, 2007" startWordPosition="1315" endWordPosition="1318">gns similar soft labels (identical hard labels) to nodes linked by edges with large weights (i.e., highly similar samples). The labeling decision takes into account not only similarities between labeled and unlabeled nodes (as in nearest-neighbor approaches) but also similarities among unlabeled nodes. Label propagation has been used successfully for various classification tasks, e.g. image classification and handwriting recognition (Zhu, 2005). In natural language processing, label propagation has been used for document classification (Zhu, 2005), word sense disambiguation (Niu et al., 2005; Alexandrescu and Kirchhoff, 2007), and sentiment categorization (Goldberg and Zhu, 2006). 3 Graph-Based Learning for Machine Translation Our goal is to exploit graph-based learning for improving consistency in statistical phrase-based machine translation. Intuitively, a set of similar source sentences should receive similar target-language translations. This means that similarities between training and test sentences should be taken into account, but also similarities between different test sentences, which is a source of information currently not exploited by standard SMT systems. To this end we define a graph over the train</context>
</contexts>
<marker>Alexandrescu, Kirchhoff, 2007</marker>
<rawString>A. Alexandrescu and K. Kirchhoff. 2007. Data-Driven Graph Construction for Semi-Supervised GraphBased Learning in NLP. In HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Altun</author>
<author>D McAllester</author>
<author>M Belkin</author>
</authors>
<title>Maximum margin semi-supervised learning for structured variables.</title>
<date>2005</date>
<booktitle>In Proceedings ofNIPS 18.</booktitle>
<contexts>
<context position="29414" citStr="Altun et al., 2005" startWordPosition="4913" endWordPosition="4916">imilar sentences: could you get two tickets for us please take a picture for me could you please take a picture of us 6 Related Work GBL is an instance of semi-supervised learning, specifically transductive learning. A different form of semi-supervised learning (self-training) has been applied to MT by (Ueffing et al., 2007). Ours is the first study to explore a graph-based learning approach. In the machine learning community, work on applying GBL to structured outputs is beginning to emerge. Transductive graph-based regularization has been applied to large-margin learning on structured data (Altun et al., 2005). However, scalability quickly becomes a problem with these approaches; we solve that issue by working on transitive closures as opposed to entire graphs. String kernel representations have been used in MT (Szedmak, 2007) in a kernel regression based framework, which, however, was an entirely supervised framework. Finally, our approach can be likened to a probabilistic implementation of translation memories (Maruyana and Watanabe, 1992; Veale and Way, 1997). Translation memories are (usually commercial) databases of segment translations extracted from a large database of translation examples. </context>
</contexts>
<marker>Altun, McAllester, Belkin, 2005</marker>
<rawString>Y. Altun, D. McAllester, and M. Belkin. 2005. Maximum margin semi-supervised learning for structured variables. In Proceedings ofNIPS 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Blum</author>
<author>S Chawla</author>
</authors>
<title>Learning from labeled and unlabeled data using graph mincuts.</title>
<date>2001</date>
<booktitle>Proc. 18th International Conf. on Machine Learning,</booktitle>
<pages>19--26</pages>
<contexts>
<context position="6203" citStr="Blum and Chawla, 2001" startWordPosition="966" endWordPosition="969">its label vector Y = (y1,... yl), yi E {1, ... , C} that defines labels for the first l points. If there is no edge linking nodes xi and xj, then Wij = 0. There is considerable freedom in choosing the weights. The similarity measure used to compute the edge weights determines the graph structure and is the most important factor in successfully applying GBL. In most applications of GBL, data samples are represented by fixed-length feature vectors, and cosine similarity or Euclidean distance-based measures are used for edge weights. Learning algorithms on similarity graphs include e.g. min-cut (Blum and Chawla, 2001), spectral graph transducer (Joachims, 2003), random walkbased approaches (Szummer and Jaakkola, 2001), and label propagation (Zhu and Ghahramani, 2002). The algorithm proposed herein is based on the latter. 2.1 Label Propagation Given a graph defined by a weight matrix W and a label set Y , the basic label propagation algorithm proceeds as follows: 1. Initialize the matrix P as P = Wij−Wii 2� Ej Wij−Wii 2. Initialize a n x C matrix f with binary vectors encoding the known labels for the first l rows: fi = δC(yi) ∀i E {1, 2, ... ,l}, where δC(yi) is the Kronecker vector of length C with 1 in p</context>
</contexts>
<marker>Blum, Chawla, 2001</marker>
<rawString>A. Blum and S. Chawla. 2001. Learning from labeled and unlabeled data using graph mincuts. Proc. 18th International Conf. on Machine Learning, pages 19– 26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Callison-Burch</author>
<author>M Osborne</author>
<author>P Koehn</author>
</authors>
<title>Reevaluating the role of BLEU in machine translation research.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL.</booktitle>
<contexts>
<context position="14283" citStr="Callison-Burch et al., 2006" startWordPosition="2341" endWordPosition="2344">., 2002) and a score based on string kernels. In using BLEU we treat each sentence as a complete document. BLEU is not symmetric—when comparing two sentences, different results are obtained depending on which one is considered the reference and which one is the hypothesis. For computing similarities between train and test translations, we use the train translation as the reference. For computing similarity between two test hypotheses, we compute BLEU in both directions and take the average. We note that more appropriate distance measures are certainly possible. Many previous studies, such as (Callison-Burch et al., 2006), have pointed out drawbacks of BLEU, and any other similarity measure could be utilized instead. In particular, similarity measures that model aspects of sentences that are ill handled by standard phrase-based decoders (such as syntactic structure or semantic information) could be useful here. A more general way of computing similarity between strings is provided by string kernels (Lodhi et al., 2002; Rousu and Shawe-Taylor, 2005), which have been extensively used in bioinformatics and email spam detection. String kernels map strings into a feature space defined by all possible substrings of </context>
</contexts>
<marker>Callison-Burch, Osborne, Koehn, 2006</marker>
<rawString>C. Callison-Burch, M. Osborne, and P. Koehn. 2006. Reevaluating the role of BLEU in machine translation research. In Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaeyoung Choi</author>
</authors>
<title>A new parallel matrix multiplication algorithm on distributed-memory concurrent computers.</title>
<date>1998</date>
<journal>Concurrency: Practice and Experience,</journal>
<volume>10</volume>
<issue>8</issue>
<contexts>
<context position="18509" citStr="Choi, 1998" startWordPosition="3048" endWordPosition="3049">ing from the nodes of interest (hypotheses for the focal sentence), we expand the closure starting with the direct neighbors, which have the largest influence; then add their neighbors, which have less influence, and so forth. A threshold on the number of added vertices limits undue expansion while capturing either the entire closure or a good approximation of it. Another practical computational advantage of portioning work is that graphs for different hypothesis sets can be trivially created and used in parallel, whereas distributing large matrix-vector multiplication is much more difficult (Choi, 1998). The disadvantage is that overall Figure 1: Connections for hypothesis node xh. Similarity edges with weights Wth link the node with train sentences xt, for which r(xt) = 1. For each of these edges we define a dissimilarity edge of weight 1− Wth, linking the node with node x′t for which r(x′t) = 0. The vertex is also connected to other test vertices (the dotted edges). redundant computations are being made: incomplete estimates of r are computed for the ancillary nodes in the transitive closure and then discarded. Second, we obtain a reduction in graph size of orders of magnitude by collapsin</context>
</contexts>
<marker>Choi, 1998</marker>
<rawString>Jaeyoung Choi. 1998. A new parallel matrix multiplication algorithm on distributed-memory concurrent computers. Concurrency: Practice and Experience, 10(8):655–670.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Goldberg</author>
<author>J Zhu</author>
</authors>
<title>Seeing stars when there aren’t many stars: Graph-based semi-supervised learning for sentiment categorization.</title>
<date>2006</date>
<booktitle>In HLT-NAACL Workshop on Graph-based Algorithms for Natural Language Processing.</booktitle>
<contexts>
<context position="8248" citStr="Goldberg and Zhu, 2006" startWordPosition="1322" endWordPosition="1325">y edges with large weights (i.e., highly similar samples). The labeling decision takes into account not only similarities between labeled and unlabeled nodes (as in nearest-neighbor approaches) but also similarities among unlabeled nodes. Label propagation has been used successfully for various classification tasks, e.g. image classification and handwriting recognition (Zhu, 2005). In natural language processing, label propagation has been used for document classification (Zhu, 2005), word sense disambiguation (Niu et al., 2005; Alexandrescu and Kirchhoff, 2007), and sentiment categorization (Goldberg and Zhu, 2006). 3 Graph-Based Learning for Machine Translation Our goal is to exploit graph-based learning for improving consistency in statistical phrase-based machine translation. Intuitively, a set of similar source sentences should receive similar target-language translations. This means that similarities between training and test sentences should be taken into account, but also similarities between different test sentences, which is a source of information currently not exploited by standard SMT systems. To this end we define a graph over the training and test sets with edges between test and training </context>
<context position="10491" citStr="Goldberg and Zhu, 2006" startWordPosition="1679" endWordPosition="1682">f all sentences in the test set (set we denote with H), the system learns a ranking function r : H —* [0, 1]. Larger values of r indicate better hypotheses. The corresponding loss functional is L(r) = � Wij [r(xi) − r(xj)]2 (3) i,j L(r) measures the smoothness of r over the graph by penalizing highly similar clusters of nodes that have a high variance of r (in other words, similar input sentences that have very different translations). The smaller L(r), the “smoother” r is over the graph. Thus, instead of directly learning a classification function, we learn a regression function— similar to (Goldberg and Zhu, 2006)—that is then used for ranking the hypotheses. 3.1 Graph Construction Each graph node represents a sentence pair (consisting of source and target strings), and edge weights represent the combined similarity scores computed from comparing both the source sides and target sides of a pair of nodes. Given a training set with l source and target language sentence pairs (s1, t1), ... , (sl, tl) and a test set with l + 1, ..., n source sentences, sl+1, ... , sn, the construction of the similarity graph proceeds as follows: 1. For each test sentence si, i = l + 1, ... , n, find a set Straini of simila</context>
</contexts>
<marker>Goldberg, Zhu, 2006</marker>
<rawString>A. Goldberg and J. Zhu. 2006. Seeing stars when there aren’t many stars: Graph-based semi-supervised learning for sentiment categorization. In HLT-NAACL Workshop on Graph-based Algorithms for Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Transductive learning via spectral graph partitioning.</title>
<date>2003</date>
<booktitle>In Proceedings ofICML.</booktitle>
<contexts>
<context position="6247" citStr="Joachims, 2003" startWordPosition="973" endWordPosition="974"> that defines labels for the first l points. If there is no edge linking nodes xi and xj, then Wij = 0. There is considerable freedom in choosing the weights. The similarity measure used to compute the edge weights determines the graph structure and is the most important factor in successfully applying GBL. In most applications of GBL, data samples are represented by fixed-length feature vectors, and cosine similarity or Euclidean distance-based measures are used for edge weights. Learning algorithms on similarity graphs include e.g. min-cut (Blum and Chawla, 2001), spectral graph transducer (Joachims, 2003), random walkbased approaches (Szummer and Jaakkola, 2001), and label propagation (Zhu and Ghahramani, 2002). The algorithm proposed herein is based on the latter. 2.1 Label Propagation Given a graph defined by a weight matrix W and a label set Y , the basic label propagation algorithm proceeds as follows: 1. Initialize the matrix P as P = Wij−Wii 2� Ej Wij−Wii 2. Initialize a n x C matrix f with binary vectors encoding the known labels for the first l rows: fi = δC(yi) ∀i E {1, 2, ... ,l}, where δC(yi) is the Kronecker vector of length C with 1 in position yi and 0 elsewhere. The remaining ro</context>
</contexts>
<marker>Joachims, 2003</marker>
<rawString>T. Joachims. 2003. Transductive learning via spectral graph partitioning. In Proceedings ofICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="23228" citStr="Koehn et al., 2007" startWordPosition="3896" endWordPosition="3899">tically extracted parallel data) in the case of the AE system. Set #sent pairs #words #refs IE train 26.5K 160K 1 IE dev-1 500 4308 1 IE dev-2 496 4204 1 IE eval 724 6481 4 AE train 23K 160K 1 AE dev4 489 5392 7 AE dev5 500 5981 7 AE eval 489 2893 6 Table 1: Data set sizes and reference translations count. Our baseline is a standard phrase-based SMT system based on alog-linear model with the following feature functions: two phrase-based translation scores, two lexical translation scores, word count and phrase count penalty, distortion score, and language model score. We use the Moses decoder (Koehn et al., 2007) with a reordering limit of 4 for both languages, which generates N-best lists of up to 2000 hypotheses per sentence in a first pass. The second pass uses apart-of-speech (POS) based trigram model, trained on POS sequences generated by a MaxEnt tagger (Ratnaparkhi, 1996). The language models are trained on the English side using SRILM (Stolcke, 2002) and modified Kneser-Ney discounting for the first-pass models and WittenBell discounting for the POS models. The baseline system yields state-of-the-art performance. P= 124 Weighting dev-2 eval none (baseline) 22.3/53.3 29.6/45.5 23.4/51.5 30.7/44</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Machine Translation Summit X,</booktitle>
<pages>79--86</pages>
<location>Phuket, Thailand.</location>
<contexts>
<context position="22483" citStr="Koehn, 2005" startWordPosition="3763" endWordPosition="3764">es. The second is a standard travel expression translation task consisting entirely of read input. For our experiments we chose the text input (correct transcription) condition only. The data set sizes are shown in Table 1. We split the IE development set into two subsets of 500 and 496 sentences each. The first set (dev-1) is used to train the system parameters of the baseline system and as a training set for GBL. The second is used to tune the GBL parameters. For each language pair, the baseline system was trained with additional out-of-domain text data: the Italian-English Europarl corpus (Koehn, 2005) in the case of the IE system, and 5.5M words of newswire data (LDC Arabic Newswire, MultipleTranslation Corpus and ISI automatically extracted parallel data) in the case of the AE system. Set #sent pairs #words #refs IE train 26.5K 160K 1 IE dev-1 500 4308 1 IE dev-2 496 4204 1 IE eval 724 6481 4 AE train 23K 160K 1 AE dev4 489 5392 7 AE dev5 500 5981 7 AE eval 489 2893 6 Table 1: Data set sizes and reference translations count. Our baseline is a standard phrase-based SMT system based on alog-linear model with the following feature functions: two phrase-based translation scores, two lexical t</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>P. Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In Machine Translation Summit X, pages 79–86, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Lodhi</author>
<author>J Shawe-taylor</author>
<author>N Cristianini</author>
</authors>
<title>Text classification using string kernels.</title>
<date>2002</date>
<booktitle>In Proceedings of NIPS.</booktitle>
<contexts>
<context position="14687" citStr="Lodhi et al., 2002" startWordPosition="2403" endWordPosition="2406">een two test hypotheses, we compute BLEU in both directions and take the average. We note that more appropriate distance measures are certainly possible. Many previous studies, such as (Callison-Burch et al., 2006), have pointed out drawbacks of BLEU, and any other similarity measure could be utilized instead. In particular, similarity measures that model aspects of sentences that are ill handled by standard phrase-based decoders (such as syntactic structure or semantic information) could be useful here. A more general way of computing similarity between strings is provided by string kernels (Lodhi et al., 2002; Rousu and Shawe-Taylor, 2005), which have been extensively used in bioinformatics and email spam detection. String kernels map strings into a feature space defined by all possible substrings of the string up a fixed length k, and computing the dot product between the resulting feature vectors. Several variants of basic string kernels exist, notably those allowing gaps or mismatches, and efficient implementations have been devised even for large scale applications. Formally, we define a sentence s as a concatenation of symbols from a finite alphabet Σ (the vocabulary of the language) and an e</context>
</contexts>
<marker>Lodhi, Shawe-taylor, Cristianini, 2002</marker>
<rawString>H. Lodhi, J. Shawe-taylor, and N. Cristianini. 2002. Text classification using string kernels. In Proceedings of NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marcu</author>
</authors>
<title>Towards a unified approach to memoryand statistical-based machine translation.</title>
<date>2001</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="30508" citStr="Marcu, 2001" startWordPosition="5078" endWordPosition="5079">s are (usually commercial) databases of segment translations extracted from a large database of translation examples. They are typically used by human translators to retrieve translation candidates for subsequences of a new input text. Matches can be exact or fuzzy; the latter is similar to the identification of graph neighborhoods in our approach. However, our GBL scheme propagates similarity scores not just from known to unknown sentences but also indirectly, via connections through other unknown sentences. The combination of a translation memory and statistical translation was reported in (Marcu, 2001); however, this is a combination of word-based and phrase-based translation predating the current phrase-based approach to SMT. 7 Conclusion We have presented a graph-based learning scheme to implement a consistency model for SMT that encourages similar inputs to receive similar outputs. Evaluation on two small-scale translation tasks showed significant improvements of up to 2.6 points in BLEU and 2.8% PER. Future work will include testing different graph construction schemes, in particular better parameter optimization approaches and better string similarity measures. More gains can be expect</context>
</contexts>
<marker>Marcu, 2001</marker>
<rawString>D. Marcu. 2001. Towards a unified approach to memoryand statistical-based machine translation. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Maruyana</author>
<author>H Watanabe</author>
</authors>
<title>Tree cover search algorithm for example-based translation.</title>
<date>1992</date>
<booktitle>In Proceedings of TMI,</booktitle>
<pages>173--184</pages>
<contexts>
<context position="29853" citStr="Maruyana and Watanabe, 1992" startWordPosition="4979" endWordPosition="4982">work on applying GBL to structured outputs is beginning to emerge. Transductive graph-based regularization has been applied to large-margin learning on structured data (Altun et al., 2005). However, scalability quickly becomes a problem with these approaches; we solve that issue by working on transitive closures as opposed to entire graphs. String kernel representations have been used in MT (Szedmak, 2007) in a kernel regression based framework, which, however, was an entirely supervised framework. Finally, our approach can be likened to a probabilistic implementation of translation memories (Maruyana and Watanabe, 1992; Veale and Way, 1997). Translation memories are (usually commercial) databases of segment translations extracted from a large database of translation examples. They are typically used by human translators to retrieve translation candidates for subsequences of a new input text. Matches can be exact or fuzzy; the latter is similar to the identification of graph neighborhoods in our approach. However, our GBL scheme propagates similarity scores not just from known to unknown sentences but also indirectly, via connections through other unknown sentences. The combination of a translation memory an</context>
</contexts>
<marker>Maruyana, Watanabe, 1992</marker>
<rawString>H. Maruyana and H. Watanabe. 1992. Tree cover search algorithm for example-based translation. In Proceedings of TMI, pages 173–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng-Yu Niu</author>
<author>Dong-Hong Ji</author>
<author>Chew Lim Tan</author>
</authors>
<title>Word sense disambiguation using label propagation based semi-supervised learning method.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>395--402</pages>
<contexts>
<context position="8158" citStr="Niu et al., 2005" startWordPosition="1311" endWordPosition="1314">ent possible, assigns similar soft labels (identical hard labels) to nodes linked by edges with large weights (i.e., highly similar samples). The labeling decision takes into account not only similarities between labeled and unlabeled nodes (as in nearest-neighbor approaches) but also similarities among unlabeled nodes. Label propagation has been used successfully for various classification tasks, e.g. image classification and handwriting recognition (Zhu, 2005). In natural language processing, label propagation has been used for document classification (Zhu, 2005), word sense disambiguation (Niu et al., 2005; Alexandrescu and Kirchhoff, 2007), and sentiment categorization (Goldberg and Zhu, 2006). 3 Graph-Based Learning for Machine Translation Our goal is to exploit graph-based learning for improving consistency in statistical phrase-based machine translation. Intuitively, a set of similar source sentences should receive similar target-language translations. This means that similarities between training and test sentences should be taken into account, but also similarities between different test sentences, which is a source of information currently not exploited by standard SMT systems. To this e</context>
</contexts>
<marker>Niu, Ji, Tan, 2005</marker>
<rawString>Zheng-Yu Niu, Dong-Hong Ji, and Chew Lim Tan. 2005. Word sense disambiguation using label propagation based semi-supervised learning method. In Proceedings ofACL, pages 395–402.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="13663" citStr="Papineni et al., 2002" startWordPosition="2242" endWordPosition="2245">milarity threshold results in a rich graph with a large number of edges but possibly introduces noise. A higher threshold leads to a small graph emphasizing highly similar samples but with too many disconnected components. The similarity measure is also the means by which domain knowledge can be incorporated into the graph construction process. Similarity may be defined at the level of surface word strings, but may also include linguistic information such as morphological features, part-of-speech tags, or syntactic structures. Here, we compare two similarity measures: the familiar BLEU score (Papineni et al., 2002) and a score based on string kernels. In using BLEU we treat each sentence as a complete document. BLEU is not symmetric—when comparing two sentences, different results are obtained depending on which one is considered the reference and which one is the hypothesis. For computing similarities between train and test translations, we use the train translation as the reference. For computing similarity between two test hypotheses, we compute BLEU in both directions and take the average. We note that more appropriate distance measures are certainly possible. Many previous studies, such as (Callison</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A maximum entropy part-ofspeech tagger.</title>
<date>1996</date>
<booktitle>In Proc.of (EMNLP).</booktitle>
<contexts>
<context position="23499" citStr="Ratnaparkhi, 1996" startWordPosition="3942" endWordPosition="3943">s and reference translations count. Our baseline is a standard phrase-based SMT system based on alog-linear model with the following feature functions: two phrase-based translation scores, two lexical translation scores, word count and phrase count penalty, distortion score, and language model score. We use the Moses decoder (Koehn et al., 2007) with a reordering limit of 4 for both languages, which generates N-best lists of up to 2000 hypotheses per sentence in a first pass. The second pass uses apart-of-speech (POS) based trigram model, trained on POS sequences generated by a MaxEnt tagger (Ratnaparkhi, 1996). The language models are trained on the English side using SRILM (Stolcke, 2002) and modified Kneser-Ney discounting for the first-pass models and WittenBell discounting for the POS models. The baseline system yields state-of-the-art performance. P= 124 Weighting dev-2 eval none (baseline) 22.3/53.3 29.6/45.5 23.4/51.5 30.7/44.1 23.5/51.6 30.6/44.3 23.2/51.8 30.0/44.6 System dev-2 eval Baseline 22.3/53.3 29.6/45.5 GBL 24.3/51.0 32.2/42.7 Table 3: GBL results (%BLEU/PER) on IE tasks with string-kernel based similarity measure. Table 2: GBL results (%BLEU/PER) on IE task for different weighting</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>A. Ratnaparkhi. 1996. A maximum entropy part-ofspeech tagger. In Proc.of (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Rousu</author>
<author>J Shawe-Taylor</author>
</authors>
<title>Efficient computation of gap-weighted string kernels on large alphabets.</title>
<date>2005</date>
<journal>Journal ofMachine Learning Research,</journal>
<pages>6--1323</pages>
<contexts>
<context position="14718" citStr="Rousu and Shawe-Taylor, 2005" startWordPosition="2407" endWordPosition="2410">ses, we compute BLEU in both directions and take the average. We note that more appropriate distance measures are certainly possible. Many previous studies, such as (Callison-Burch et al., 2006), have pointed out drawbacks of BLEU, and any other similarity measure could be utilized instead. In particular, similarity measures that model aspects of sentences that are ill handled by standard phrase-based decoders (such as syntactic structure or semantic information) could be useful here. A more general way of computing similarity between strings is provided by string kernels (Lodhi et al., 2002; Rousu and Shawe-Taylor, 2005), which have been extensively used in bioinformatics and email spam detection. String kernels map strings into a feature space defined by all possible substrings of the string up a fixed length k, and computing the dot product between the resulting feature vectors. Several variants of basic string kernels exist, notably those allowing gaps or mismatches, and efficient implementations have been devised even for large scale applications. Formally, we define a sentence s as a concatenation of symbols from a finite alphabet Σ (the vocabulary of the language) and an embedding function from strings </context>
<context position="16164" citStr="Rousu and Shawe-Taylor, 2005" startWordPosition="2660" endWordPosition="2663">u=s(i) where k is the maximum length of substrings, |i |is the length of i, and λ is a penalty parameter for each gap encountered in the substring. 1C is defined as 1C(s, t) = � (φu(s), φu(t))wu (6) u where w is a weight dependent on the length of the substring u. Finally, the kernel score is normalized V/ by 1C(s, s) · 1C(t, t) to discourage long sentences from being favored. Thus, our similarity measure is a gapped, normalized string kernel, which is a more general measure than BLEU in that is considers noncontiguous substrings. We use a dynamic programming implementation of string kernels (Rousu and Shawe-Taylor, 2005). 122 For the combination of source-side and targetside similarity scores (the function we denoted as κ) we test two simple schemes, using either the geometric or the arithmetic mean of the individual scores. In the first case, large edge weights only result when both source and target are close to each other; the latter may produce high edge weights when only one of them (typically the source score) is high. More sophisticated combination schemes, using e.g. weighted combination, could be used but were not investigated in this study. Scalability Poor scalability is often mentioned as a drawba</context>
</contexts>
<marker>Rousu, Shawe-Taylor, 2005</marker>
<rawString>J. Rousu and J. Shawe-Taylor. 2005. Efficient computation of gap-weighted string kernels on large alphabets. Journal ofMachine Learning Research, 6:1323–1344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILM—an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In ICSLP,</booktitle>
<pages>901--904</pages>
<contexts>
<context position="23580" citStr="Stolcke, 2002" startWordPosition="3956" endWordPosition="3957">m based on alog-linear model with the following feature functions: two phrase-based translation scores, two lexical translation scores, word count and phrase count penalty, distortion score, and language model score. We use the Moses decoder (Koehn et al., 2007) with a reordering limit of 4 for both languages, which generates N-best lists of up to 2000 hypotheses per sentence in a first pass. The second pass uses apart-of-speech (POS) based trigram model, trained on POS sequences generated by a MaxEnt tagger (Ratnaparkhi, 1996). The language models are trained on the English side using SRILM (Stolcke, 2002) and modified Kneser-Ney discounting for the first-pass models and WittenBell discounting for the POS models. The baseline system yields state-of-the-art performance. P= 124 Weighting dev-2 eval none (baseline) 22.3/53.3 29.6/45.5 23.4/51.5 30.7/44.1 23.5/51.6 30.6/44.3 23.2/51.8 30.0/44.6 System dev-2 eval Baseline 22.3/53.3 29.6/45.5 GBL 24.3/51.0 32.2/42.7 Table 3: GBL results (%BLEU/PER) on IE tasks with string-kernel based similarity measure. Table 2: GBL results (%BLEU/PER) on IE task for different weightings of labeled-labeled vs. labeledunlabeled graph edges (BLEU-based similarity meas</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. SRILM—an extensible language modeling toolkit. In ICSLP, pages 901–904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhuoran Wang</author>
<author>John Shawe-Taylor</author>
<author>Sandor Szedmak</author>
</authors>
<title>Kernel regression based machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL/HLT,</booktitle>
<pages>185--188</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Wang, Shawe-Taylor, Szedmak, 2007</marker>
<rawString>Zhuoran Wang;John Shawe-Taylor;Sandor Szedmak. 2007. Kernel regression based machine translation. In Proceedings of NAACL/HLT, pages 185–188. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Szummer</author>
<author>Tommi Jaakkola</author>
</authors>
<title>Partially labeled classification with markov random walks.</title>
<date>2001</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<volume>14</volume>
<note>http://ai.mit.edu/people/ szummer/.</note>
<contexts>
<context position="6305" citStr="Szummer and Jaakkola, 2001" startWordPosition="979" endWordPosition="982">f there is no edge linking nodes xi and xj, then Wij = 0. There is considerable freedom in choosing the weights. The similarity measure used to compute the edge weights determines the graph structure and is the most important factor in successfully applying GBL. In most applications of GBL, data samples are represented by fixed-length feature vectors, and cosine similarity or Euclidean distance-based measures are used for edge weights. Learning algorithms on similarity graphs include e.g. min-cut (Blum and Chawla, 2001), spectral graph transducer (Joachims, 2003), random walkbased approaches (Szummer and Jaakkola, 2001), and label propagation (Zhu and Ghahramani, 2002). The algorithm proposed herein is based on the latter. 2.1 Label Propagation Given a graph defined by a weight matrix W and a label set Y , the basic label propagation algorithm proceeds as follows: 1. Initialize the matrix P as P = Wij−Wii 2� Ej Wij−Wii 2. Initialize a n x C matrix f with binary vectors encoding the known labels for the first l rows: fi = δC(yi) ∀i E {1, 2, ... ,l}, where δC(yi) is the Kronecker vector of length C with 1 in position yi and 0 elsewhere. The remaining rows of f can be zero. 3. f′ ← P x f 4. Clamp already-labele</context>
</contexts>
<marker>Szummer, Jaakkola, 2001</marker>
<rawString>Martin Szummer and Tommi Jaakkola. 2001. Partially labeled classification with markov random walks. In Advances in Neural Information Processing Systems, volume 14. http://ai.mit.edu/people/ szummer/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ueffing</author>
<author>G Haffari</author>
<author>A Sarkar</author>
</authors>
<title>Transductive learning for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL Workshop on Statistical Machine Translation.</booktitle>
<contexts>
<context position="29121" citStr="Ueffing et al., 2007" startWordPosition="4868" endWordPosition="4871">BL: excuse me could you take a picture of the us Refs: excuse me can you take a picture of us excuse me could you take a photo of us pardon would you mind taking a photo of us pardon me could you take our picture pardon me would you take a picture of us excuse me could you take a picture of u Similar sentences: could you get two tickets for us please take a picture for me could you please take a picture of us 6 Related Work GBL is an instance of semi-supervised learning, specifically transductive learning. A different form of semi-supervised learning (self-training) has been applied to MT by (Ueffing et al., 2007). Ours is the first study to explore a graph-based learning approach. In the machine learning community, work on applying GBL to structured outputs is beginning to emerge. Transductive graph-based regularization has been applied to large-margin learning on structured data (Altun et al., 2005). However, scalability quickly becomes a problem with these approaches; we solve that issue by working on transitive closures as opposed to entire graphs. String kernel representations have been used in MT (Szedmak, 2007) in a kernel regression based framework, which, however, was an entirely supervised fr</context>
</contexts>
<marker>Ueffing, Haffari, Sarkar, 2007</marker>
<rawString>N. Ueffing, G. Haffari, and A. Sarkar. 2007. Transductive learning for statistical machine translation. In Proceedings of the ACL Workshop on Statistical Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Veale</author>
<author>A Way</author>
</authors>
<title>Gaijin: a templatebased bootstrapping approach to example-based machine translation.</title>
<date>1997</date>
<booktitle>In Proceedings of News Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="29875" citStr="Veale and Way, 1997" startWordPosition="4983" endWordPosition="4986">tured outputs is beginning to emerge. Transductive graph-based regularization has been applied to large-margin learning on structured data (Altun et al., 2005). However, scalability quickly becomes a problem with these approaches; we solve that issue by working on transitive closures as opposed to entire graphs. String kernel representations have been used in MT (Szedmak, 2007) in a kernel regression based framework, which, however, was an entirely supervised framework. Finally, our approach can be likened to a probabilistic implementation of translation memories (Maruyana and Watanabe, 1992; Veale and Way, 1997). Translation memories are (usually commercial) databases of segment translations extracted from a large database of translation examples. They are typically used by human translators to retrieve translation candidates for subsequences of a new input text. Matches can be exact or fuzzy; the latter is similar to the identification of graph neighborhoods in our approach. However, our GBL scheme propagates similarity scores not just from known to unknown sentences but also indirectly, via connections through other unknown sentences. The combination of a translation memory and statistical translat</context>
</contexts>
<marker>Veale, Way, 1997</marker>
<rawString>T. Veale and A. Way. 1997. Gaijin: a templatebased bootstrapping approach to example-based machine translation. In Proceedings of News Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhu</author>
<author>Z Ghahramani</author>
</authors>
<title>Learning from labeled and unlabeled data with label propagation.</title>
<date>2002</date>
<tech>Technical report, CMU-CALD-02.</tech>
<contexts>
<context position="6355" citStr="Zhu and Ghahramani, 2002" startWordPosition="986" endWordPosition="989"> = 0. There is considerable freedom in choosing the weights. The similarity measure used to compute the edge weights determines the graph structure and is the most important factor in successfully applying GBL. In most applications of GBL, data samples are represented by fixed-length feature vectors, and cosine similarity or Euclidean distance-based measures are used for edge weights. Learning algorithms on similarity graphs include e.g. min-cut (Blum and Chawla, 2001), spectral graph transducer (Joachims, 2003), random walkbased approaches (Szummer and Jaakkola, 2001), and label propagation (Zhu and Ghahramani, 2002). The algorithm proposed herein is based on the latter. 2.1 Label Propagation Given a graph defined by a weight matrix W and a label set Y , the basic label propagation algorithm proceeds as follows: 1. Initialize the matrix P as P = Wij−Wii 2� Ej Wij−Wii 2. Initialize a n x C matrix f with binary vectors encoding the known labels for the first l rows: fi = δC(yi) ∀i E {1, 2, ... ,l}, where δC(yi) is the Kronecker vector of length C with 1 in position yi and 0 elsewhere. The remaining rows of f can be zero. 3. f′ ← P x f 4. Clamp already-labeled data rows: f′ i = δC(yi) ∀i E {1,2,...,l} 5. If </context>
</contexts>
<marker>Zhu, Ghahramani, 2002</marker>
<rawString>X. Zhu and Z. Ghahramani. 2002. Learning from labeled and unlabeled data with label propagation. Technical report, CMU-CALD-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojin Zhu</author>
</authors>
<title>Semi-Supervised Learning with Graphs.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<pages>05--192</pages>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="7276" citStr="Zhu, 2005" startWordPosition="1176" endWordPosition="1177">ding the known labels for the first l rows: fi = δC(yi) ∀i E {1, 2, ... ,l}, where δC(yi) is the Kronecker vector of length C with 1 in position yi and 0 elsewhere. The remaining rows of f can be zero. 3. f′ ← P x f 4. Clamp already-labeled data rows: f′ i = δC(yi) ∀i E {1,2,...,l} 5. If f′ ∼= f, stop. 6. f ← f′ 7. Repeat from step 3. After convergence, f contains the solution in rows l + 1 to n in the form of unnormalized label probability distributions. Hard labels can be obtained by ˆyi = arg max fij ∀i E {l + 1, ... , n} (1) jE{1,...,C} The algorithm minimizes the following cost function (Zhu, 2005): C S = � Wij(fik − fjk)2 (2) k=1 i&gt;l V j&gt;l S measures the smoothness of the learned function, i.e., the extent to which the labeling allows largeweight edges to link nodes of different labels. By minimizing S, label propagation finds a labeling 120 that, to the extent possible, assigns similar soft labels (identical hard labels) to nodes linked by edges with large weights (i.e., highly similar samples). The labeling decision takes into account not only similarities between labeled and unlabeled nodes (as in nearest-neighbor approaches) but also similarities among unlabeled nodes. Label propag</context>
<context position="20358" citStr="Zhu, 2005" startWordPosition="3391" endWordPosition="3392">j Wij . (The quantity 1−W1i in the denominator is the weight of the dissimilarity edge.) 5. Initialize a column vector f of height n with f1 = 1 (corresponding to node x1) and 0 in the remaining positions. 6. f′ +— P x f 7. Clamp f′1: f′1 = 1 8. If f′ f, continue with step 11. 9. f +— f′ 10. Repeat from step 6. 11. The result r is in the slots of f that correspond to the hypotheses of interest. Normalize per sentence if needed, and rank in decreasing order of r. . . . . . . 1 W1h 1 − W1h 0 1 0 123 Convergence Our algorithm’s convergence proof is similar to that for standard label propagation (Zhu, 2005, p. 6). We split P as follows: L0 PLU J (7) PUL PUU where PUL is a column vector holding global similarities of test hypotheses with train sentences, PLU is a horizontal vector holding the same similarities (though PLU =� PTUL due to normalization), and PUU holds the normalized similarities between pairs of test hypotheses. We also separate f: f =IfU1 (8) where we distinguish the first entry because it represents the training part of the data. With these notations, the iteration formula becomes: f′U = PUUfU + PUL (9) Unrolling the iteration yields: &amp;quot; ! # Xn fU = lim (PUU)nf0 U + (PUU)i−1 PUL </context>
</contexts>
<marker>Zhu, 2005</marker>
<rawString>Xiaojin Zhu. 2005. Semi-Supervised Learning with Graphs. Ph.D. thesis, Carnegie Mellon University. CMU-LTI-05-192.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>