<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.858077">
Computational Aspects of M-grammars
Joep Rous
Philips Research Laboratories, P.O. Box 80.000
5600 JA Eindhoven, The Netherlands
</note>
<email confidence="0.994599">
E-mail: rous@rosetta.prl.philips.n1 (uucp)
</email>
<sectionHeader confidence="0.991231" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.994919376623377">
In this paper M-grammars that are used in the Rosetta
translation system will be looked at as the specifica-
tion of attribute grammars. We will show that the
attribute evaluation order is such that instead of the
special-purpose parsing and generation algorithms in-
troduced for M-grammars in Appelo et al.(1987), also
Earley-like context-free parsing and ordinary generation
strategies can be used. Furthermore, it is illustrated
that the attribute grammar approach gives an insight
into the weak generative capacity of M-grammars and
into the computational complexity of the parsing and
generation process. Finally, the attribute grammar ap-
proach will be used to reformulate the concept of iso-
morphic grammars.
1\4-grammars
In this section we will introduce, very globally, the gram-
mars that are used in the Rosetta machine translation
system which is being developed at Philips Research
Laboratories in Eindhoven. The original Rosetta gram-
mar formalism, called M-grammars, was a computa-
tional variant of Montague grammar. The formalism
was introduced in Landsbergen(1981). Whereas rules
in Montague grammar operate on strings, M-grammar
rules (M-rules) operate on labelled ordered trees, called
S-trees. The nodes of S-trees are labelled with syntac-
tic categories and attribute-value pairs. Because of the
reversibility of M-rules, it is possible to define two al-
gorithms: M-Parser and M-Generator . The M-Parser
algorithm starts with a surface structure in the form
of an S-tree and breaks it down into basic expressions
by recursive application of reversed M-rules. The result
of the M-Parser algorithm is a syntactic derivation tree
which reflects the history of the analysis process. The
leaves of the derivation tree are names of basic expres-
sions. The M-Generator algorithm generates a set of
S-trees by bottom-up application of M-rules, the names
of which are mentioned in a syntactic derivation tree.
Analogous to Montague Grammar, with each M-rule a
rule is associated which expresses its meaning. This al-
lows for the transformation of a syntactic derivation tree
into a semantic derivation tree by replacing the name of
each M-rule by the name of the corresponding mean-
ing rule. In Landsbergen (1982) it was shown that the
formalism is very well fit to be nsed in an interlingual
machine translation system in which semantic derivation
trees make up the interlingua. In the analysis part of
the translation system an S-tree of the source language
is mapped onto a set of semantic derivation trees. Next,
each semantic derivation tree is mapped onto a set of
S-trees of the target language. In order to guarantee
that for a sentence which can be analysed by means of
the source language grammar a translation can always
be generated using the target language grammar, source
and target grammars in the Rosetta system are attuned.
Grammars, attuned in the way described in Landsber-
gen (1982), are called isomorphic.
Appelo et al.(1987) introduces some extensions of the
formalism, which make it possible to assign more struc-
ture to an M-grammar. The new formalism was called
controlled M-grammars. In this new approach a gram-
mar consists of a set of subgrammars. Each of the sub-
grammars contains a set of M-rules and a regular ex-
pression over the alphabet of rule names. The set of
M-rules is subdivided into meaningful rules and trans-
formations. Transformations have no semantic relevance
and will therefore not occur in a derivation tree. The
regular expression can be looked at as a prescription of
the order in which the rules of the subgrammar have to
be applied. Because of these changes in the formalism,
new versions of the M-Parser and M-Generator algo-
rithm were introduced which were able to deal with sub-
grammars. These algorithms, however, are complex and
result in a rather cumbersome implementation. In this
paper we will show that they can be replaced by normal
context-free parse and generation algorithms if we inter-
pret an M-grammar as the specification of an attribute
grammar (Knuth (1968), Deransart et al.(1988)).
</bodyText>
<subsectionHeader confidence="0.874941">
M-grarnmars as attribute grammars
</subsectionHeader>
<bodyText confidence="0.999724375">
The control expression which is used in the definition of
a Rosetta subgrammar specifies a regular language over
the alphabet of rule names. Another way to define such
a language is by means of a regular grammar. Let con-
trol expression ce, of subgrammar i define the regular
language C(i). Then we can construct a minimal regu-
lar grammar rg, which defines the same language. The
grammar rgi will have the following form:
</bodyText>
<listItem confidence="0.8132152">
• A set of non-terminals N, = {I? , ,
• A set of terminals E. E, is the smallest set such
that there is a terminal f E E, for each M-rule r .
• Start symbol I?
- 210 •
• A set of production rules P, containing the follow-
ing type of rules:
— f/t, where f E Ei
— /i7 —■
— If --• e.
</listItem>
<bodyText confidence="0.998961125">
We will use the regular grammar defined above as a
starting point for the construction of an attributed sub-
grammar. An elegant view of attribute grammars can be
found in Hemerik (1984). Hemerik defines an attribute
grammar as a context free grammar with parametrized
non-terminals and production rules. In general, non,
terminals may have a number of parameters - attributes
- associated with them. Production rules of an attribute
grammar are pairs (rule form, rule condition). From a
rule form, production rules can be obtained by means
of substitution of values for the attribute variables that
satisfy the rule condition. In the grammars presented
in this paper, non-terminals have only one attribute of
type S-tree. The attribute grammar rules that are used
throughout this paper also have a very restricted form.
A typical attribute grammar rule r with context free
</bodyText>
<equation confidence="0.801748333333333">
[skeleton A BC will look like:
A&lt;o&gt;—+B&lt;p&gt;C&lt;q&gt;
(o,(p,q)) E R
</equation>
<bodyText confidence="0.998412846153846">
Here, A&lt;o&gt;--■ B&lt;p&gt; C&lt;q&gt; is the rule form,
o, p, q are the attributes and (o, (p, g)) E /1 is the rule
condition. R defines a relation between the attributes at
the left-hand side and the attributes at the right-hand
side of the rule form.
For each subgrammar rg,, (1 &lt; i &lt; M) we will con-
struct an attributed subgrammar 091. Each constructed
attributed subgrammar ag; will have a start symbol J.
First, however, we define two new attributed subgram-
mars that have no direct relation with a subgrammar
of a given M-grammar: the start subgrammar and the
terminal subgrammar. The terminal subgrammar agi
with start symbol n contains a rule of the form
</bodyText>
<equation confidence="0.73683">
{
&lt;0 &gt;--,
o = x
</equation>
<bodyText confidence="0.943407333333333">
for each basic expression x of the M-grammar. The start
subgrammar ago with start symbol S contains a rule of
the form
</bodyText>
<equation confidence="0.9752405">
[S &lt; o &gt;—■ .4) &lt; p &gt;
o = p A cat(p) E exportcats(i)
</equation>
<bodyText confidence="0.99706725">
for the start symbol of each attributed subgrammar.
The attribute condition in this rule means that S-trees
that are exported by subgrammar i have a syntactic cat-
egory which is in the set exportcats(i).
</bodyText>
<subsectionHeader confidence="0.5103875">
For each subgrammar rg, specified by the M-grammar
we can construct an attributed subgrammar ag; being
</subsectionHeader>
<bodyText confidence="0.8840275">
the 5-tuple (1 ,U (S), (t&gt;, Un. , , (T, Fi)) as fol-
lows:
</bodyText>
<listItem confidence="0.982007666666667">
• ag, has &apos;domain&apos; (T, 11), where T is the set of possi-
ble S-trees and Fi is a collection of relations of type
Tin x T, m&gt; 0. F1 contains all relations defined by
the M-rules of subgrammar i.
• The set of production rules of ag, can be con-
structed as follows:
</listItem>
<bodyText confidence="0.932984815789474">
— If rgi contains a rule of the form If --. flt,
where f corresponds with an n-ary meaning-
ful M-rule r, ag, contains the following at-
tribute grammar rule:
if &lt; 0 &gt;•-• 9i?&apos; &lt; pi &gt; S &lt; p2 &gt; ...
[
(0, (Pi , ..., Pn)) E Rr
Here, If and r are non-terminals of the at-
tributed sugrarnmar ag,, S is the start sym-
bol of the complete grammar, the terminal 9
is the name of the M-rule and ft,. is the binary
relation between S-trees and tuples of S-trees
which is defined by M-rule r. The terminal
symbol t&gt; marks the end of the scope of the
production rule in the strings generated by
the grammar. The variables o, pi ... p,, are
the attributes of the rule. All attributes are
of type S-tree.
One possible interpretation of the attribute
grammar rule is that the S-tree o is received
from non-terminal If of the current subgram-
mar. According to the relation defined by M-
rule r, the S-tree o corresponds to the S-trees
P1, ...,p.. S-tree pi is passed to another non-
terminal of the current subgrammar, whereas
P2, ...,p. are offered to the start symbol of the
attribute grammar.
— If rgi contains a rule of the form If --+ ilt
where 9 corresponds with unary transforma-
tion r, ag; contains the following attribute
grammar rule:
[ 1 (10, pre &gt;1 : It &lt; p &gt;
Notice that an attribute rule corresponding
with a transformation r does not produce the
terminal 9.
— If rgi contains a rule of the form /I --■ Ip, the
ag, contains the following attribute grammar
rule:
</bodyText>
<figure confidence="0.450776142857143">
[
&lt;o &lt; p &gt;
o = p
— If rgi contains a rule of the form If c then
091 contains the following rule:
[1 &lt;0 OS &lt; p &gt;
0 =p A cat(p) E headcats(i)
</figure>
<subsectionHeader confidence="0.961556">
Rules Of this form mark the beginning of a
</subsectionHeader>
<bodyText confidence="0.990700166666667">
subgrammar. The terminal symbol 0 is used
for this purpose. The attribute relation is
a restriction on the kind of S-trees that is
allowed to enter the subgrammar. Only S-
trees with a syntactic category in the set
headcats(i) are accepted.
</bodyText>
<page confidence="0.68998">
-211 -
</page>
<bodyText confidence="0.995481">
The set of all attributed subgrammars can be joined
to one single attribute grammar (N, E, P, S, (T, F)) as
follows:
</bodyText>
<listItem confidence="0.923501444444444">
• The non-terminal set of the attribute grammar is
the union of all non-terminals of all subgrammars,
i.e. N = A.
,=o
• The terminal set E of the attribute grammar is the
union of all terminals of all subgrammars (including
the terminal subgrammar): E = { t, D} UU14.-.0 ti.
• The set of production rules is the union of all pro-
duction rules of the subgrammars, P = Ui.o P.
• The startsymbol of the composed grammar is iden-
tical to the the startsymbol S of the start subgram-
mar. The attribute of the start symbol of an at-
tribute grammar is called the designated attribute
(Engelfriet (1986)) of the attribute grammar. The
output set of an attribute grammar is the set of all
possible values of its designated attribute.
• The composed grammar has domain (T, F) where
F = Ur=0 Fi and T is the set of all possible S-trees.
</listItem>
<bodyText confidence="0.994172">
In the rest of the paper we call an attribute grammar
which has been derived from an M-grammar in this way
an attributed M-grammar or amg.
</bodyText>
<subsectionHeader confidence="0.925086">
Computational Aspects
</subsectionHeader>
<bodyText confidence="0.999893454545455">
Because each meaningful attributed rule r produces the
terminal symbol f and because each terminal rule x pro-
duces terminal symbol t, the strings of C(X), the lan-
guage defined by an amg X, will contain the deriva-
tional history of the string itself. The history is partial,
because the grammar rules for transformations do not
produce a terminal. Moreover, the form of the grammar
rules is such that each string is a prefix representation
of its own derivational history.
Given an amg X, with a set of terminals E, a recognition
function of type E(X) --. 2T can be defined as:
</bodyText>
<equation confidence="0.711469">
MGen(d) =de It I S&lt;t&gt;,÷d Ad E
</equation>
<bodyText confidence="0.859722875">
The reverse of MGen is the generation function of type
T 24x), which can be defined as:
MPars(t)=d {d I S&lt;t&gt;,÷dAdE E*}
These functions can of course be defined for each at-
tribute grammar in this form. However, in the case of
amg&apos;s the MPars and MGen functions are both com-
putable because each M-rule r defines both a computable
function and its reverse:
</bodyText>
<equation confidence="0.973724">
(o,(p,...,p))E11
0 E fr(P1,•••,Pn)
(P1, •..,Pn) E f,71(o)
</equation>
<listItem confidence="0.75439725">
Because of this property of the M-rules the grammar has
two possible interpretations:
• one for recognition purposes with only synthesized
attributes, in which the rules can be written as:
</listItem>
<equation confidence="0.8378585">
[I! &lt;1. 0 &gt;--• W1. &lt; Pi &gt; S &lt;I p2 &gt; ...
0 E fr(Pi,...,Pn)
</equation>
<bodyText confidence="0.699344">
This interpretation is to be used by MGen in the
generation phase of the Rosetta system.
</bodyText>
<listItem confidence="0.9694155">
• one for generation purposes with only inherited at-
tributes containing the following type of rules:
</listItem>
<equation confidence="0.699728333333333">
[It &lt;1 o &gt;—+ fl? &lt;1 pi &gt; S &lt;1, p2 &gt; ...
(P1,...,Pn) E f,71(o)
The generative interpretation of the rules will be
</equation>
<bodyText confidence="0.931480789473684">
used by MPars in the analysis phase of the Rosetta
translation system.
From the definitions of MPars and MGen the reversibil-
ity property of the grammar follows immediately:
d E MPars(t) t E MGen(d)
The reversibility property which has always been one of
the tenets of the Rosetta system (Landsbergen (1982))
has recently received the appreciation of other re-
searchers in the field of M.T. as well (Isabelle (1989),
Rohrer (1989), van Noord (1990)).
In order to give the M-grammar formalism a place in
the list of other linguistic formalisms like LFG, FUG,
TG, TAG and GPSG 1, we will investigate some com-
putational aspects of amg&apos;s in this section. Given an
amg grammar X, we can calculate the value of the des-
ignated attribute for an element of ,C(X). For this cal-
culation an ordinary context free recognition algorithm
(Earley(1970), Leermakers(1991)) can be used. Because
the grammar may contain cycles of the form
</bodyText>
<equation confidence="0.910223">
[&lt;o &gt;--+ .17 &lt; p &gt;
(o,p) E
</equation>
<bodyText confidence="0.971386214953272">
its context-free backbone is not finitely ambiguous.
Hence, an amg is not necessarily off-line parsable (
Pereira and Warren (1983), Haas (1989)). The term
off-line parsable is somewhat misleading because a two-
stage parse process for grammars which are infinitely
ambiguous is very well feasible. In the first stage of
the parse process, in which the context free backbone is
used, a finite representation of the infinitely many parse
trees, e.g. in the form of a parse matrix, is determined.
Next, in the second stage, the attributes are calculated.
However, measure conditions on the attributes are nec-
essary to guarantee termination of the parse process.
These measure conditions are constraints on the size
(according to a certain measure) of the attribute val-
ues that occur in each cycle of the underlying context
free grammar.
The generative interpretation of amg X can be used in a
straight-forward language generator which generates all
corresponding elements of E(X) for a given value of the
designated attribute. Obviously, it can only be guaran-
teed that the generation process will always terminate if
lcf. Perrault (1984) for a comparison of the mathematical
properties of these formalisms.
- 212 -
the grammar satisfies some restrictions. Suggestions for
grammar constraints in the form of termination condi-
tions for parsing and generation are given in Appelo et
al.(1987).
For an insight into the weak generative capacity of the
formalism we have to examine the set of yields of the
S-trees in the output set of an amg. Let us call this
set the output language defined by an amg. It is not
possible to characterize exactly the set of output lan-
guages that can be defined by an amg without defining
what the termination conditions are. The precise form
of the termination conditions, however, is not imposed
by the M-grammar formalism. The formalism merely
demands that some measure on the attribute values is
defined which garantuees termination of the recognition
and generation process. In order to get an idea of the
weak generative capacity of the formalism, we assume,
for the moment, the weakest condition that guarantees
termination. It can be shown that each deterministic
Turing Machine can be implemented by means of an
amg such that the language defined by the TM is the
output language of that amg. Not all grammars that
can be constructed in this way satify the termination
condition, however. The termination condition is only
satisfied by Turing Machines that halt on all inputs,
which is exactly the class of machines that define the
set of all recursive languages. Consequently, the output
languages that can be defined by amg&apos;s or M-grammars,
in principle, are the languages that can be recognized by
deterministic Turing Machines in finite time.
At this point it is appropriate to mention the bifurca-
tion of grammatical formalisms into two classes: the
formalisms designed as linguistic tools (e.g. PATR-H,
FUG, DCG) and those intended to be linguistic theories
(e.g. LFG, GPSG, GB) (cf. Shieber (1987) for a motiva-
tion of this bifurcation). The goals of these formalisms
with respect to expressive power are, in general, at odds
with each other. While great expressive power is consid-
ered to be an advantage of tool-oriented formalisms, it is
considered to be an undesirable property of formalisms
of the theory type. The M-grammar formalism clearly
belongs to the category of linguistic tools.
By strengthening the termination conditions it is pos-
sible to restrict the class of output languages that can
be defined by an amg. For instance, the class of out-
put languages can be restricted to the languages that
are recognizable by a deterministic TM in 2&amp;quot; time 2 if
we assume that the termination conditions imposed on
an amg are the weakest conditions that satisfy the con-
straints formulated in Rounds (1973). A reformulation
of these constraints for amg&apos;s is as follows:
• The time needed by an attribute evaluating func-
tion is proportional to some polynomial in the sum
of the size of its arguments.,
• There is a positive constant A such that in each
fully attributed derivation tree, the size of each at-
tribute value is less than or equal to the size of
the constant A times the size of the value of the
designated attribute.
Rounds used these conditions to show that the languages
recognizable in exponential time make up exactly the
set which is characterized by transformational gram-
mars (as presented in Chomsky (1965)) satisfying the
terminal-length non-decreasing condition.
TIr power of the formalism with respect to generative
capacity has of course its consequences for the compu-
tational complexity of the generation and recognition
process, Here too, the exact form of the termination
condition is important. Obeying the termination condi-
tions that we adhere to in the current Rosetta system,
it can be proved that the recognition and the generation
problems are NP-hard, which makes them computation-
ally intractable. In comparison with other formalisms,
M-grammars are no exception with respect to the com-
plexity of these issues. LFG recognition and FUG gener-
ation have both been proved to be NP-hard in Barton et
al, (1987) and Ritchie (1986) respectively. Recognition
in GPBG has even been proved to be EXP-POLY-hard
(Barton et al. 1987). We should keep in mind, however,
that the computational complexity analysis is a worst-
case analysis. The average-case behaviour of the parse
and generation algorithm that we experience in the daily
use of the Rosetta system is certainly not exponential.
</bodyText>
<subsectionHeader confidence="0.792518">
Isomorphic Grammars
</subsectionHeader>
<bodyText confidence="0.9978432">
The decidability of the question whether two M-
grammoo are isomorphic is another computational as-
pect related to M-grammars. Although this mathemati-
cal issue appears not to be very relevant from a practical
point of view, it enables us to show what grammar iso-
morphy means in the context of amg&apos;s.
According to the Rosetta Compositionality Principle
(Landsbergen(1987)) to each meaningful M-rule r a
meaning rule mr corresponds which expresses the se-
mantics of r. Furthermore, there is a set of basic mean-
ings for each basic expression of an M-grammar. We
can easily express this relation of M-grammar rules and
basic expressions with their semantic counterparts in an
amg, Instead of incorporating the M-rule name e in
the attributed production rule as we did in the previous
sections, we now include the name of the corresponding
meaning rule Til r as follows:
[II &lt; 0 &gt;-. fizr.t?&apos; &lt;pi &gt; S &lt; p2 &gt; . . . S &lt;p,i &gt; t&gt;
(o, (pi , ..., P.)) E R,
The terminal subgramrnar must be adapted in order to
generate basic meanings instead of basic expressions. If
a basic expression x corresponds with the basic mean-
ings mix,...,mi,..., mxn then we replace the original
rule in the terminal subgrammar for x by n rules of
the form:
</bodyText>
<equation confidence="0.651006">
t 0. x
</equation>
<bodyText confidence="0.977263627906976">
2This includes all context sensitive languages (Cook We will call a grammar that has been derived in this way
(1971)). from an amg a semantic amg, or samg. The strings
- 213
of the language defined by an samg are prefix repre-
sentations of semantic derivation trees. The language
defined by an samg is called the set of strings which are
well-formed with respect to X.
Let us repeat here what it means for two M-grammars
to be isomorphic:
&amp;quot;...Two grammars are isomorphic if each semantic
derivation tree which is well-formed with respect to one
grammar is also well-formed with respect to the other
grammar...&amp;quot; (Landsbergen (1987)). We can reformulate
the original definition of isomorphic M-grammars in a
very elegant way for samg&apos;s:
Definition: Two samg&apos;s X1 and X2 are isomorphic if
they are equivalent, that is if cpci) = c(x2)
This definition says that writing isomorphic grammars
comes down to writing two attribute grammars which
define the same language. From formal language the-
ory (e.g. Hoperoft and Ullman (1979)) we know that
there is no algorithm that can test an arbitrary pair of
context-free grammars G1 and G2 to determine whether
L(G1) = L(G2). It can also be shown that samg&apos;s can
define any recursive language. Consequently, checking
the equivalence of two arbitrary samg&apos;s will be an un-
decidable problem. Rosetta grammars that are used for
translation purposes, however, are not arbitrary samg&apos;s:
they are not created completely independently. The
strategy followed in Rosetta to accomplish the defini-
tion of equivalent grammars, that is, grammars that de-
fine identical languages, is to attune two samg&apos;s to each
other. This grammar attuning strategy is extensively de-
scribed in Appelo et al.(1987), Landsbergen (1982) and
Landsbergen (1987) for ordinary M-grammars. Here,
we will show what the attuning strategy means in the
context of samg&apos;s, together with a few extensions.
The attuning measures below must not be looked at as
the weakest possible conditions that guarantee isomor-
phy. The list merely is an enumeration of conditions
which together should help to establish isomorphy. If
two samg&apos;s XI and X2 have to be isomorphic, the fol-
lowing measures are proposed:
</bodyText>
<listItem confidence="0.910199">
• The production rules of both samg &apos;s must be con-
sistent.
</listItem>
<bodyText confidence="0.938758">
If both grammars have a production rule in which
the name of the meaning rule m appears, then the
right-hand side of the rules should contain the same
number of non terminals, since m is a function with
a fixed number of arguments, independent of the
grammar it is used in.
• The terminal sets of both samg &apos;s should be equaP.
In the context of the ordinary M-grammar formal-
ism this condition is formulated as:
- for each basic expression in one M-grammar there
has to be at least one basic expression in the other
M-grammar with the same meaning (which comes
</bodyText>
<note confidence="0.609563">
3This condition is equivalent to the attuning measures de-
scribed in Appelo et al. (1987), Landsbergen (1982) and
Landsbergen(1987).
</note>
<bodyText confidence="0.9961066">
down to the condition that the terminal set of the
terminal subgrammars should be identical)
- for each meaningful rule in one M-grammar there
has to be at least one meaningful rule in the other
M-grammar which has the same meaning.
</bodyText>
<listItem confidence="0.6771775">
• The underlying context free grammars of both
samg &apos;s should be equivalent.
</listItem>
<bodyText confidence="0.97896816">
Equivalence of the underlying context free gram-
mars can be established by putting an equivalence
condition on the underlying grammar of corre-
sponding subgrammars of the samg&apos;s in question.
Suppose that for each subgrammar of an smug
X1 a subgrammar of another samg X2 would ex-
ist that performs the same linguistic task and vice
versa. Such an ideal situation could be expressed
by a relation 72 on the sets of subgrammars of both
samg&apos;s. Let i and j be subgrammars of the samg&apos;s
Xi and X2 respectively, such that (i, E R, then
the underlying grammars* B, and B, have to be
constructed in such a way that they define the same
language. ( Notice that B, and B, are regular
grammars.) More formally:
V(i, j) E R: L(B,) = L(B,). 5
The three attuning conditions above guarantee that
the underlying context free grammars of two attuned
samg&apos;s are equivalent. However, the language defined
by an samg is a subset of the language defined by its un-
derlying grammar. The rule conditions determine which
elements are in the subset and which are not. Because
of the great expressive power of M-rules, the attuning
measures place no effective restrictions on the kind of
languages an samg can define. Hence, it can be proved
that:
Theorem: The question whether two attuned samg&apos;s
are isomorphic is undecidable.
Because of the equivalence between samg&apos;s and M-
grammars this also applies to arbitrary attuned M-
grammars. Future research is needed to find extensions
for the attuning measures in a way that guarantees iso-
morphy if grammar writers adhere to the attuning con-
ditions. The extensions will probably include restric-
tions on the form of the underlying grammar and on
the expressive power of M-rules. Also formal attuning
measures between M-rules or sets of M-rules of different
grammars are conceivable.
*Because we are dealing with a subgrarnmar, the non-
terminal S is discarded from the production rules of the un-
derlying grammar.
5This attuning measure sketches an ideal situation. In
practice for each subgramrnar of an samg there is not a cor-
responding fully isomorphic subgrammar but only a partially
isomorphic subgrammar of the other samg. However, the re-
quirement of fully isomorphic subgranunars is not the weak-
est attuning condition that guarantees the equivalence of the
underlying context free grammars. Equivalence can also be
guaranteed if X1 and X2 satisfy the following condition which
expresses partial isomorphy between subgrarturnars:
</bodyText>
<subsubsectionHeader confidence="0.748038">
Ueexi &apos;CPO =Uiex3 £(B,)
</subsubsectionHeader>
<bodyText confidence="0.9759395">
- 214 -
The current Rosetta grammars obey the three previ-
ously mentioned attuning measures. In practice these
measures provide a good basis to work with. Therefore,
the undecidability of the isomorphy question is not an
urgent topic at the moment.
</bodyText>
<sectionHeader confidence="0.536255" genericHeader="conclusions">
Conclusions
</sectionHeader>
<bodyText confidence="0.998791666666667">
In this paper we presented the interpretation of an M-
grammar as a specification of an attribute grammar.
We showed that the resulting attribute grammar is re-
versible and that it can be used in ordinary context
free recognition and generation algorithms. The gen-
eration algorithm is to be used in the analysis phase of
Rosetta, whereas the recognition algorithm should be
used in the generation phase. With respect to the weak
generative capacity it has been concluded that the set
of languages that can be generated and recognized de-
pends on the termination conditions that are imposed
on the grammar. If the weakest termination condition
is assumed, the set of languages that can be defined by
an M-grammar is equivalent to the set of languages that
can be recognized by a deterministic Turing Machine
in finite time. Using more realistic termination condi-
tions, the computational complexity of the recognition
and generation problem can still be classified as NP-
hard and, consequently, as computationally intractable.
Finally, it was concluded that the question whether two
attuned M-grammars are isomorphic, is undecidable.
</bodyText>
<sectionHeader confidence="0.994588" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999845">
The author wishes to thank Jan Landsbergen, Jan
Odijk, André Schenk and Petra de Wit for their helpful
comments on earlier versions of the paper. The author
is also indebted to Lisette Appelo for encouraging him
to write the paper and to Rene L-eermakers with whom
he had many fruitful discussions on the subject.
</bodyText>
<sectionHeader confidence="0.998986" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996132831168831">
Appelo, L. , C. Fellinger and J. Landsbergen (1987),
`Subgrammars, Rule Classes and Control in the
Rosetta Translation System&apos;, Philips Research
M.S. 14.131, Proceedings of 3rd ACL Conference
, European Chapter, pp. 118-133.
Barton, G., R. Berwick and E. Ristad (1987), Com-
putational Complexity and Natural Language, MIT
Press, Cambridge, Mass.
Chomsky, N. (1965), Aspects of the Theory of Syntax,
MIT Press, Cambridge, Mass.
Cook, S. A. (1971), Characterizations of Pushdown
Machines in Terms of Time-bounded Computers,
Journal of the Association for Computing Machin-
ery 18, 1, pp. 4-18.
Deransart, P., M. Jourdan, B. Lorho (1988), &apos;Attribute
Grammars&apos;, Lecture Notes in Computer Science
323, Springer-Verlag, Berlin.
Earley, J. (1970), &apos;An efficient context-free parsing al-
gorithm&apos;, Commun. ACM 13 (1970), pp. 94-102.
Engelfriet, J. (1986), &apos;The Complexity of Languages
Generated by Attribute Grammars&apos;, SIAM Journal
on Computing 15, 1, pp. 70-86.
Haas, A. (1989), &apos;A Generalization of the Offline
Parsable Grammars&apos;, Proceedings of the 27th An-
nual Meeting of the Association for Computational
Linguistics, pp. 237-242.
Hemerik, C. (1984), &apos;Formal definitions of program-
ming languages as a basis for compiler construc-
tion&apos;, Ph.D. th., University of Eindhoven.
Hoperoft, J.E. and J.D. Ullman (1979), &apos;Introduction
to Automata Theory, Languages and Computa-
tion&apos;, Addison Wesley Publishing Company, Read-
ing, Mass.
Isabelle, P. (1989), &apos;Towards Reversible M.T. Systems&apos;,
MT Summit&apos;!!, pp. 67-68.
Knuth, D.E. (1968), &apos;Semantics of Context-Free Lan-
guages&apos;, Math. Systems Theory 2, 2, pp. 127-145
(June 1968).
Landsbergen, J. (1981), &apos;Adaptation of Montague
grammar to the requirements of parsing&apos;, in: For-
mal Methods in the Study of Language Part 2, MC
Tract 136, Mathematical Centre, Amsterdam.
Landsbergen, J. (1982), &apos;Machine Translation based on
logically isomorphic Montague grammars&apos;, Coling
82, North-Holland, Amsterdam, pp. 175-181.
Landsbergen, J. (1987), &apos;Isomorphic grammars and
their use in the Rosetta Translation system&apos;, Ma-
chine TVanslation, the State of the Art, M. King
(ed.), Edinburg University Press.
Leermakers, R (1991), &apos;Non-deterministic recursive as-
cent parsing&apos;, Proceedings of the 5th ACL Confer-
ence, European Chapter, forthcoming.
Noord, van G. (1990), &apos;Reversible Unification Based
Machine Translation&apos;, in Proceedings of the 13th In-
ternational Conference on Computational Linguis-
tics, Helsinki.
Pereira, F., D. Warren (1983), &apos;Parsing as deduction&apos;,
Proceedings of the 21th Annual Meeting of the As-
sociation for Computational Linguistics, pp. 137-
144.
Perrault, C.R. (1984), &apos;On the Mathematical Proper-
ties of Linguistic Theories&apos;, Computational Linguis-
tics 10, pp. 165-176.
Ritchie, G. (1986), &apos;The computational complexity of
sentence derivation in functional unification gram-
mar&apos;, Proceedings of Coling&apos;86, pp. 584-586.
Rohrer, C. (1989), &apos;New directions in MT systems&apos;,
MT Summit II, pp. 120-122.
Rounds, W. (1975), &apos;A grammatical characterization
of the exponential languages&apos;, Proceedings of the
16th Annual Symposium on Switching Theory and
Automata, IEEE Computer Society, New York, pp.
135-143.
Shieber, S. M. (1987), &apos;Separating Linguistic Analyses
from Linguistic Theories&apos;, in Linguistic Theory and
Computer Applications, Academic Press.
- 215 -
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.108451">
<title confidence="0.988332">Computational Aspects of M-grammars</title>
<author confidence="0.765444">Joep Rous</author>
<address confidence="0.950909">Philips Research Laboratories, P.O. Box 80.000 5600 JA Eindhoven, The Netherlands</address>
<email confidence="0.884371">E-mail:rous@rosetta.prl.philips.n1(uucp)</email>
<abstract confidence="0.997758107583775">In this paper M-grammars that are used in the Rosetta translation system will be looked at as the specification of attribute grammars. We will show that the attribute evaluation order is such that instead of the special-purpose parsing and generation algorithms introduced for M-grammars in Appelo et al.(1987), also Earley-like context-free parsing and ordinary generation strategies can be used. Furthermore, it is illustrated that the attribute grammar approach gives an insight into the weak generative capacity of M-grammars and into the computational complexity of the parsing and generation process. Finally, the attribute grammar approach will be used to reformulate the concept of isomorphic grammars. 1\4-grammars In this section we will introduce, very globally, the grammars that are used in the Rosetta machine translation system which is being developed at Philips Research Laboratories in Eindhoven. The original Rosetta gramformalism, called was a computational variant of Montague grammar. The formalism was introduced in Landsbergen(1981). Whereas rules in Montague grammar operate on strings, M-grammar rules (M-rules) operate on labelled ordered trees, called S-trees. The nodes of S-trees are labelled with syntactic categories and attribute-value pairs. Because of the reversibility of M-rules, it is possible to define two algorithms: M-Parser and M-Generator . The M-Parser algorithm starts with a surface structure in the form of an S-tree and breaks it down into basic expressions by recursive application of reversed M-rules. The result of the M-Parser algorithm is a syntactic derivation tree which reflects the history of the analysis process. The leaves of the derivation tree are names of basic expressions. The M-Generator algorithm generates a set of S-trees by bottom-up application of M-rules, the names of which are mentioned in a syntactic derivation tree. Analogous to Montague Grammar, with each M-rule a rule is associated which expresses its meaning. This allows for the transformation of a syntactic derivation tree into a semantic derivation tree by replacing the name of each M-rule by the name of the corresponding meaning rule. In Landsbergen (1982) it was shown that the formalism is very well fit to be nsed in an interlingual machine translation system in which semantic derivation trees make up the interlingua. In the analysis part of the translation system an S-tree of the source language is mapped onto a set of semantic derivation trees. Next, each semantic derivation tree is mapped onto a set of S-trees of the target language. In order to guarantee that for a sentence which can be analysed by means of the source language grammar a translation can always be generated using the target language grammar, source target grammars in the Rosetta system are Grammars, attuned in the way described in Landsber- (1982), are called Appelo et al.(1987) introduces some extensions of the formalism, which make it possible to assign more structure to an M-grammar. The new formalism was called In this new approach a grammar consists of a set of subgrammars. Each of the subgrammars contains a set of M-rules and a regular expression over the alphabet of rule names. The set of M-rules is subdivided into meaningful rules and transformations. Transformations have no semantic relevance and will therefore not occur in a derivation tree. The regular expression can be looked at as a prescription of the order in which the rules of the subgrammar have to be applied. Because of these changes in the formalism, new versions of the M-Parser and M-Generator algorithm were introduced which were able to deal with subgrammars. These algorithms, however, are complex and result in a rather cumbersome implementation. In this paper we will show that they can be replaced by normal context-free parse and generation algorithms if we interpret an M-grammar as the specification of an attribute grammar (Knuth (1968), Deransart et al.(1988)). M-grarnmars as attribute grammars The control expression which is used in the definition of a Rosetta subgrammar specifies a regular language over the alphabet of rule names. Another way to define such a language is by means of a regular grammar. Let conexpression subgrammar i define the regular language C(i). Then we can construct a minimal regular grammar rg, which defines the same language. The grammar rgi will have the following form: A set of non-terminals = {I? , , • A set of terminals E. E, is the smallest set such there is a terminal E, for each M-rule r . • Start symbol I? - 210 • • A set of production rules P, containing the following type of rules: f E —■ If --• We will use the regular grammar defined above as a starting point for the construction of an attributed subgrammar. An elegant view of attribute grammars can be found in Hemerik (1984). Hemerik defines an attribute grammar as a context free grammar with parametrized non-terminals and production rules. In general, non, terminals may have a number of parameters attributes associated with them. Production rules of an attribute grammar are pairs (rule form, rule condition). From a rule form, production rules can be obtained by means of substitution of values for the attribute variables that satisfy the rule condition. In the grammars presented in this paper, non-terminals have only one attribute of type S-tree. The attribute grammar rules that are used throughout this paper also have a very restricted form. A typical attribute grammar rule r with context free BC will like: A&lt;o&gt;—+B&lt;p&gt;C&lt;q&gt; R B&lt;p&gt; C&lt;q&gt; the rule form, p, q are attributes and /1 the rule condition. R defines a relation between the attributes at the left-hand side and the attributes at the right-hand side of the rule form. each subgrammar rg,, (1 &lt; i &lt; will construct an attributed subgrammar 091. Each constructed subgrammar have a start symbol First, however, we define two new attributed subgrammars that have no direct relation with a subgrammar of a given M-grammar: the start subgrammar and the The agi start symbol a rule of the form { o = x for each basic expression x of the M-grammar. The start ago with start symbol a rule of the form &lt; p &gt; = E exportcats(i) the start symbol of attributed subgrammar. The attribute condition in this rule means that S-trees that are exported by subgrammar i have a syntactic catwhich is in the set For each subgrammar rg, specified by the M-grammar can construct an attributed subgrammar ,U (S), (t&gt;, , as lows: ag, has &apos;domain&apos; 11), where T the set of possi- S-trees and is collection of relations of type m&gt; all relations defined by M-rules of subgrammar • The set of production rules of ag, can be constructed as follows: If rgi contains a rule of the form --. with an n-ary meaningful M-rule r, ag, contains the following attribute grammar rule: pi &gt; p2 &gt; ... [ , ..., Pn)) Rr If and r are non-terminals of the atsugrarnmar ag,, the start symof the complete grammar, the terminal the name of the M-rule and the binary relation between S-trees and tuples of S-trees which is defined by M-rule r. The terminal symbol t&gt; marks the end of the scope of the production rule in the strings generated by grammar. The variables ... p,, are the attributes of the rule. All attributes are of type S-tree. One possible interpretation of the attribute rule is that the S-tree received from non-terminal If of the current subgrammar. According to the relation defined by Mr, the S-tree to the S-trees P1, ...,p.. S-tree pi is passed to another nonterminal of the current subgrammar, whereas P2, ...,p. are offered to the start symbol of the attribute grammar. If rgi contains a rule of the form --+ ilt 9 corresponds with unary transformathe following attribute grammar rule: 1 : It&lt; p&gt; that attribute rule corresponding with a transformation r does not produce the terminal 9. If a rule of the form /I --■ Ip, the the following attribute grammar rule: [ p &gt; o = p If a rule of the form c then 091 contains the following rule: [1 &lt; p &gt; Rules Of this form mark the beginning of a subgrammar. The terminal symbol 0 is used for this purpose. The attribute relation is a restriction on the kind of S-trees that is to enter the subgrammar. Only Swith syntactic category in the set headcats(i) are accepted. -211 - The set of all attributed subgrammars can be joined one single attribute grammar S, (T, F)) follows: • The non-terminal set of the attribute grammar is the union of all non-terminals of all subgrammars, N = ,=o • The terminal set E of the attribute grammar is the union of all terminals of all subgrammars (including terminal subgrammar): E = { t, D} ti. • The set of production rules is the union of all prorules of the subgrammars, • The startsymbol of the composed grammar is idento the the startsymbol the start subgrammar. The attribute of the start symbol of an atgrammar is called the (Engelfriet (1986)) of the attribute grammar. The set an attribute grammar is the set of all possible values of its designated attribute. The composed grammar has domain F) = Fi and the set of all possible S-trees. In the rest of the paper we call an attribute grammar which has been derived from an M-grammar in this way M-grammar Computational Aspects Because each meaningful attributed rule r produces the symbol f and because each terminal rule proterminal symbol t, the strings of landefined by an contain the derivational history of the string itself. The history is partial, because the grammar rules for transformations do not produce a terminal. Moreover, the form of the grammar rules is such that each string is a prefix representation of its own derivational history. an a set of terminals E, a of type --. can be defined as: It S&lt;t&gt;,÷d Ad reverse of MGen is the of type which can be defined as: I These functions can of course be defined for each attribute grammar in this form. However, in the case of MPars and MGen functions are both comeach M-rule r defines both a computable function and its reverse: fr(P1,•••,Pn) •..,Pn) Because of this property of the M-rules the grammar has two possible interpretations: • one for recognition purposes with only synthesized in which the rules can be written 0&gt;--• &lt; Pi &gt; p2 &gt; ... fr(Pi,...,Pn) This interpretation is to be used by MGen in the generation phase of the Rosetta system. • one for generation purposes with only inherited attributes containing the following type of rules: &lt;1 fl? &lt;1 &gt; p2 &gt; ... E The generative interpretation of the rules will be used by MPars in the analysis phase of the Rosetta translation system. the definitions of MPars and MGen the reversibilproperty the grammar follows immediately: E t E MGen(d) The reversibility property which has always been one of tenets of the Rosetta system (Landsbergen has recently received the appreciation of other researchers in the field of M.T. as well (Isabelle (1989), Rohrer (1989), van Noord (1990)). In order to give the M-grammar formalism a place in the list of other linguistic formalisms like LFG, FUG, TAG and GPSG we will investigate some comaspects of this section. Given an can calculate the value of the desattribute for an element of this calculation an ordinary context free recognition algorithm (Earley(1970), Leermakers(1991)) can be used. Because the grammar may contain cycles of the form .17 &lt; p &gt; its context-free backbone is not finitely ambiguous. an not necessarily parsable ( and Warren (1983), Haas (1989)). The parsable somewhat misleading because a twostage parse process for grammars which are infinitely ambiguous is very well feasible. In the first stage of the parse process, in which the context free backbone is used, a finite representation of the infinitely many parse trees, e.g. in the form of a parse matrix, is determined. Next, in the second stage, the attributes are calculated. However, measure conditions on the attributes are necessary to guarantee termination of the parse process. These measure conditions are constraints on the size (according to a certain measure) of the attribute values that occur in each cycle of the underlying context free grammar. generative interpretation of be used in a straight-forward language generator which generates all elements of a given value of the designated attribute. Obviously, it can only be guaranteed that the generation process will always terminate if lcf. Perrault (1984) for a comparison of the mathematical properties of these formalisms. - 212 the grammar satisfies some restrictions. Suggestions for grammar constraints in the form of termination conditions for parsing and generation are given in Appelo et al.(1987). For an insight into the weak generative capacity of the formalism we have to examine the set of yields of the S-trees in the output set of an amg. Let us call this the language by an amg. It is not possible to characterize exactly the set of output languages that can be defined by an amg without defining what the termination conditions are. The precise form of the termination conditions, however, is not imposed by the M-grammar formalism. The formalism merely demands that some measure on the attribute values is defined which garantuees termination of the recognition and generation process. In order to get an idea of the weak generative capacity of the formalism, we assume, for the moment, the weakest condition that guarantees termination. It can be shown that each deterministic Turing Machine can be implemented by means of an amg such that the language defined by the TM is the output language of that amg. Not all grammars that can be constructed in this way satify the termination condition, however. The termination condition is only satisfied by Turing Machines that halt on all inputs, which is exactly the class of machines that define the set of all recursive languages. Consequently, the output that can by amg&apos;s or M-grammars, in principle, are the languages that can be recognized by deterministic Turing Machines in finite time. At this point it is appropriate to mention the bifurcation of grammatical formalisms into two classes: the designed as linguistic PATR-H, DCG) and those intended to be linguistic (e.g. LFG, GPSG, GB) (cf. Shieber (1987) for a motivation of this bifurcation). The goals of these formalisms with respect to expressive power are, in general, at odds with each other. While great expressive power is considered to be an advantage of tool-oriented formalisms, it is considered to be an undesirable property of formalisms of the theory type. The M-grammar formalism clearly belongs to the category of linguistic tools. By strengthening the termination conditions it is possible to restrict the class of output languages that can be defined by an amg. For instance, the class of output languages can be restricted to the languages that recognizable by a deterministic TM in 2&amp;quot; time 2if we assume that the termination conditions imposed on an amg are the weakest conditions that satisfy the constraints formulated in Rounds (1973). A reformulation of these constraints for amg&apos;s is as follows: • The time needed by an attribute evaluating function is proportional to some polynomial in the sum of the size of its arguments., • There is a positive constant A such that in each fully attributed derivation tree, the size of each attribute value is less than or equal to the size of constant times the of the value of the designated attribute. Rounds used these conditions to show that the languages recognizable in exponential time make up exactly the set which is characterized by transformational grammars (as presented in Chomsky (1965)) satisfying the terminal-length non-decreasing condition. the formalism with respect to generative capacity has of course its consequences for the computational complexity of the generation and recognition process, Here too, the exact form of the termination condition is important. Obeying the termination conditions that we adhere to in the current Rosetta system, it can be proved that the recognition and the generation are NP-hard, which makes them computationintractable. In with other formalisms, M-grammars are no exception with respect to the complexity of these issues. LFG recognition and FUG generation have both been proved to be NP-hard in Barton et al, (1987) and Ritchie (1986) respectively. Recognition in GPBG has even been proved to be EXP-POLY-hard (Barton et al. 1987). We should keep in mind, however, the computational complexity analysis is a worst- The average-case behaviour of the parse and generation algorithm that we experience in the daily use of the Rosetta system is certainly not exponential. Isomorphic Grammars decidability of the question whether two Misomorphic is another computational aspect related to M-grammars. Although this mathematical issue appears not to be very relevant from a practical point of view, it enables us to show what grammar isomorphy means in the context of amg&apos;s. According to the Rosetta Compositionality Principle (Landsbergen(1987)) to each meaningful M-rule r a rule corresponds which expresses the semantics of r. Furthermore, there is a set of basic meanings for each basic expression of an M-grammar. We can easily express this relation of M-grammar rules and basic expressions with their semantic counterparts in an of incorporating the M-rule name the attributed production rule as we did in the previous sections, we now include the name of the corresponding rule r follows: &lt; 0 &gt;-. fizr.t?&apos; &lt;pi p2 &gt; . . . &gt; t&gt; (pi , ..., R, subgramrnar must be adapted in order to generate basic meanings instead of basic expressions. If basic expression with the basic meanthen we replace the original rule in the terminal subgrammar for x by n rules of the form: 0. includes all context sensitive languages (Cook We call a grammar that has been derived in this way from amg or samg. The strings - 213 the language defined by samg are representations of semantic derivation trees. The language defined by an samg is called the set of strings which are respect to Let us repeat here what it means for two M-grammars to be isomorphic: &amp;quot;...Two grammars are isomorphic if each semantic derivation tree which is well-formed with respect to one grammar is also well-formed with respect to the other grammar...&amp;quot; (Landsbergen (1987)). We can reformulate the original definition of isomorphic M-grammars in a elegant way for Two samg&apos;s and isomorphic if are is if = This definition says that writing isomorphic grammars comes down to writing two attribute grammars which define the same language. From formal language theory (e.g. Hoperoft and Ullman (1979)) we know that there is no algorithm that can test an arbitrary pair of grammars and to determine whether = L(G2). can also be shown samg&apos;s define any recursive language. Consequently, checking equivalence of two arbitrary be an un- Rosetta grammars that are used for translation purposes, however, are not arbitrary samg&apos;s: they are not created completely independently. The strategy followed in Rosetta to accomplish the definition of equivalent grammars, that is, grammars that define identical languages, is to attune two samg&apos;s to each other. This grammar attuning strategy is extensively described in Appelo et al.(1987), Landsbergen (1982) and Landsbergen (1987) for ordinary M-grammars. Here, we will show what the attuning strategy means in the samg&apos;s, together with a extensions. The attuning measures below must not be looked at as the weakest possible conditions that guarantee isomorphy. The list merely is an enumeration of conditions which together should help to establish isomorphy. If and to be isomorphic, the following measures are proposed: The production rules of both must be consistent. both grammars have a production rule the name of the meaning rule m appears, then the right-hand side of the rules should contain the same number of non terminals, since m is a function with a fixed number of arguments, independent of the grammar it is used in. The terminal sets of both should be equaP. In the context of the ordinary M-grammar formalism this condition is formulated as: for each basic expression in one M-grammar there has to be at least one basic expression in the other M-grammar with the same meaning (which comes condition is equivalent to the attuning measures described in Appelo et al. (1987), Landsbergen (1982) and Landsbergen(1987). down to the condition that the terminal set of the terminal subgrammars should be identical) for each meaningful rule in one M-grammar there has to be at least one meaningful rule in the other M-grammar which has the same meaning. • The underlying context free grammars of both should be equivalent. Equivalence of the underlying context free grammars can be established by putting an equivalence condition on the underlying grammar of corresponding subgrammars of the samg&apos;s in question. that for each subgrammar of smug a subgrammar of another X2 exist that performs the same linguistic task and vice versa. Such an ideal situation could be expressed a relation 72 on the sets of subgrammars of Let i and subgrammars of the and such that (i, then underlying grammars* to be constructed in such a way that they define the same ( Notice that regular grammars.) More formally: = L(B,). 5 The three attuning conditions above guarantee that underlying context free grammars of two samg&apos;s are equivalent. However, the language defined by an samg is a subset of the language defined by its underlying grammar. The rule conditions determine which elements are in the subset and which are not. Because of the great expressive power of M-rules, the attuning measures place no effective restrictions on the kind of an samg define. Hence, it can be proved that: Theorem: The question whether two attuned samg&apos;s is undecidable. of the equivalence samg&apos;s and Mgrammars this also applies to arbitrary attuned Mgrammars. Future research is needed to find extensions for the attuning measures in a way that guarantees isomorphy if grammar writers adhere to the attuning conditions. The extensions will probably include restrictions on the form of the underlying grammar and on the expressive power of M-rules. Also formal attuning measures between M-rules or sets of M-rules of different grammars are conceivable. we are dealing a subgrarnmar, the nonterminal S is discarded from the production rules of the unattuning measure an ideal situation. In practice for each subgramrnar of an samg there is not a corresponding fully isomorphic subgrammar but only a partially isomorphic subgrammar of the other samg. However, the requirement of fully isomorphic subgranunars is not the weakest attuning condition that guarantees the equivalence of the underlying context free grammars. Equivalence can also be if X1 and satisfy the following condition which expresses partial isomorphy between subgrarturnars: =Uiex3 £(B,) - 214 - The current Rosetta grammars obey the three previously mentioned attuning measures. In practice these measures provide a good basis to work with. Therefore, the undecidability of the isomorphy question is not an urgent topic at the moment. Conclusions In this paper we presented the interpretation of an Mspecification of an attribute grammar. We showed that the resulting attribute grammar is reversible and that it can be used in ordinary context and generation algorithms. The generation algorithm is to be used in the analysis phase of Rosetta, whereas the recognition algorithm should be used in the generation phase. With respect to the weak generative capacity it has been concluded that the set of languages that can be generated and recognized depends on the termination conditions that are imposed on the grammar. If the weakest termination condition is assumed, the set of languages that can be defined by an M-grammar is equivalent to the set of languages that can be recognized by a deterministic Turing Machine in finite time. Using more realistic termination conditions, the computational complexity of the recognition and generation problem can still be classified as NPhard and, consequently, as computationally intractable. it that the question whether two attuned M-grammars are isomorphic, is undecidable. The author wishes to thank Jan Landsbergen, Jan Odijk, André Schenk and Petra de Wit for their helpful comments on earlier versions of the paper. The author is also indebted to Lisette Appelo for encouraging him to write the paper and to Rene L-eermakers with whom he had many fruitful discussions on the subject.</abstract>
<note confidence="0.9391889">References Appelo, L. , C. Fellinger and J. Landsbergen (1987), `Subgrammars, Rule Classes and Control in the Rosetta Translation System&apos;, Philips Research 14.131, of 3rd ACL Conference , European Chapter, pp. 118-133. G., R. Berwick and E. Ristad (1987), Com- Complexity and Natural Language, Press, Cambridge, Mass. N. (1965), of the Theory of Syntax, MIT Press, Cambridge, Mass. Cook, S. A. (1971), Characterizations of Pushdown Machines in Terms of Time-bounded Computers, Journal of the Association for Computing Machin- 18, pp. 4-18. Deransart, P., M. Jourdan, B. Lorho (1988), &apos;Attribute Notes Science 323, Springer-Verlag, Berlin. Earley, J. (1970), &apos;An efficient context-free parsing al- Commun. 13 pp. 94-102. Engelfriet, J. (1986), &apos;The Complexity of Languages by Attribute Grammars&apos;, Journal Computing 1, pp. 70-86. Haas, A. (1989), &apos;A Generalization of the Offline Grammars&apos;, of the 27th Anof the Association for Computational 237-242. Hemerik, C. (1984), &apos;Formal definitions of programming languages as a basis for compiler construction&apos;, Ph.D. th., University of Eindhoven.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Fellinger</author>
<author>J Landsbergen</author>
</authors>
<title>Subgrammars, Rule Classes and Control in the Rosetta Translation System&apos;,</title>
<date>1987</date>
<booktitle>Philips Research M.S. 14.131, Proceedings of 3rd ACL Conference , European Chapter,</booktitle>
<pages>118--133</pages>
<marker>Fellinger, Landsbergen, 1987</marker>
<rawString>Appelo, L. , C. Fellinger and J. Landsbergen (1987), `Subgrammars, Rule Classes and Control in the Rosetta Translation System&apos;, Philips Research M.S. 14.131, Proceedings of 3rd ACL Conference , European Chapter, pp. 118-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Barton</author>
<author>R Berwick</author>
<author>E Ristad</author>
</authors>
<date>1987</date>
<booktitle>Computational Complexity and Natural Language,</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, Mass.</location>
<contexts>
<context position="18010" citStr="Barton et al, (1987)" startWordPosition="3104" endWordPosition="3107">spect to generative capacity has of course its consequences for the computational complexity of the generation and recognition process, Here too, the exact form of the termination condition is important. Obeying the termination conditions that we adhere to in the current Rosetta system, it can be proved that the recognition and the generation problems are NP-hard, which makes them computationally intractable. In comparison with other formalisms, M-grammars are no exception with respect to the complexity of these issues. LFG recognition and FUG generation have both been proved to be NP-hard in Barton et al, (1987) and Ritchie (1986) respectively. Recognition in GPBG has even been proved to be EXP-POLY-hard (Barton et al. 1987). We should keep in mind, however, that the computational complexity analysis is a worstcase analysis. The average-case behaviour of the parse and generation algorithm that we experience in the daily use of the Rosetta system is certainly not exponential. Isomorphic Grammars The decidability of the question whether two Mgrammoo are isomorphic is another computational aspect related to M-grammars. Although this mathematical issue appears not to be very relevant from a practical poi</context>
</contexts>
<marker>Barton, Berwick, Ristad, 1987</marker>
<rawString>Barton, G., R. Berwick and E. Ristad (1987), Computational Complexity and Natural Language, MIT Press, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<title>Aspects of the Theory of Syntax,</title>
<date>1965</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Mass.</location>
<contexts>
<context position="17297" citStr="Chomsky (1965)" startWordPosition="2995" endWordPosition="2996">reformulation of these constraints for amg&apos;s is as follows: • The time needed by an attribute evaluating function is proportional to some polynomial in the sum of the size of its arguments., • There is a positive constant A such that in each fully attributed derivation tree, the size of each attribute value is less than or equal to the size of the constant A times the size of the value of the designated attribute. Rounds used these conditions to show that the languages recognizable in exponential time make up exactly the set which is characterized by transformational grammars (as presented in Chomsky (1965)) satisfying the terminal-length non-decreasing condition. TIr power of the formalism with respect to generative capacity has of course its consequences for the computational complexity of the generation and recognition process, Here too, the exact form of the termination condition is important. Obeying the termination conditions that we adhere to in the current Rosetta system, it can be proved that the recognition and the generation problems are NP-hard, which makes them computationally intractable. In comparison with other formalisms, M-grammars are no exception with respect to the complexit</context>
</contexts>
<marker>Chomsky, 1965</marker>
<rawString>Chomsky, N. (1965), Aspects of the Theory of Syntax, MIT Press, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S A Cook</author>
</authors>
<title>Characterizations of Pushdown Machines in Terms of Time-bounded Computers,</title>
<date>1971</date>
<journal>Journal of the Association for Computing Machinery</journal>
<volume>18</volume>
<pages>4--18</pages>
<marker>Cook, 1971</marker>
<rawString>Cook, S. A. (1971), Characterizations of Pushdown Machines in Terms of Time-bounded Computers, Journal of the Association for Computing Machinery 18, 1, pp. 4-18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Deransart</author>
<author>M Jourdan</author>
<author>B Lorho</author>
</authors>
<title>Attribute Grammars&apos;,</title>
<date>1988</date>
<booktitle>Lecture Notes in Computer Science 323,</booktitle>
<publisher>Springer-Verlag,</publisher>
<location>Berlin.</location>
<marker>Deransart, Jourdan, Lorho, 1988</marker>
<rawString>Deransart, P., M. Jourdan, B. Lorho (1988), &apos;Attribute Grammars&apos;, Lecture Notes in Computer Science 323, Springer-Verlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Earley</author>
</authors>
<title>An efficient context-free parsing algorithm&apos;,</title>
<date>1970</date>
<journal>Commun. ACM</journal>
<volume>13</volume>
<pages>94--102</pages>
<marker>Earley, 1970</marker>
<rawString>Earley, J. (1970), &apos;An efficient context-free parsing algorithm&apos;, Commun. ACM 13 (1970), pp. 94-102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Engelfriet</author>
</authors>
<title>The Complexity of Languages Generated by Attribute Grammars&apos;,</title>
<date>1986</date>
<journal>SIAM Journal on Computing</journal>
<volume>15</volume>
<pages>70--86</pages>
<contexts>
<context position="9931" citStr="Engelfriet (1986)" startWordPosition="1739" endWordPosition="1740"> P, S, (T, F)) as follows: • The non-terminal set of the attribute grammar is the union of all non-terminals of all subgrammars, i.e. N = A. ,=o • The terminal set E of the attribute grammar is the union of all terminals of all subgrammars (including the terminal subgrammar): E = { t, D} UU14.-.0 ti. • The set of production rules is the union of all production rules of the subgrammars, P = Ui.o P. • The startsymbol of the composed grammar is identical to the the startsymbol S of the start subgrammar. The attribute of the start symbol of an attribute grammar is called the designated attribute (Engelfriet (1986)) of the attribute grammar. The output set of an attribute grammar is the set of all possible values of its designated attribute. • The composed grammar has domain (T, F) where F = Ur=0 Fi and T is the set of all possible S-trees. In the rest of the paper we call an attribute grammar which has been derived from an M-grammar in this way an attributed M-grammar or amg. Computational Aspects Because each meaningful attributed rule r produces the terminal symbol f and because each terminal rule x produces terminal symbol t, the strings of C(X), the language defined by an amg X, will contain the de</context>
</contexts>
<marker>Engelfriet, 1986</marker>
<rawString>Engelfriet, J. (1986), &apos;The Complexity of Languages Generated by Attribute Grammars&apos;, SIAM Journal on Computing 15, 1, pp. 70-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Haas</author>
</authors>
<title>A Generalization of the Offline Parsable Grammars&apos;,</title>
<date>1989</date>
<booktitle>Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>237--242</pages>
<contexts>
<context position="12980" citStr="Haas (1989)" startWordPosition="2278" endWordPosition="2279">r formalism a place in the list of other linguistic formalisms like LFG, FUG, TG, TAG and GPSG 1, we will investigate some computational aspects of amg&apos;s in this section. Given an amg grammar X, we can calculate the value of the designated attribute for an element of ,C(X). For this calculation an ordinary context free recognition algorithm (Earley(1970), Leermakers(1991)) can be used. Because the grammar may contain cycles of the form [&lt;o &gt;--+ .17 &lt; p &gt; (o,p) E its context-free backbone is not finitely ambiguous. Hence, an amg is not necessarily off-line parsable ( Pereira and Warren (1983), Haas (1989)). The term off-line parsable is somewhat misleading because a twostage parse process for grammars which are infinitely ambiguous is very well feasible. In the first stage of the parse process, in which the context free backbone is used, a finite representation of the infinitely many parse trees, e.g. in the form of a parse matrix, is determined. Next, in the second stage, the attributes are calculated. However, measure conditions on the attributes are necessary to guarantee termination of the parse process. These measure conditions are constraints on the size (according to a certain measure) </context>
</contexts>
<marker>Haas, 1989</marker>
<rawString>Haas, A. (1989), &apos;A Generalization of the Offline Parsable Grammars&apos;, Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics, pp. 237-242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Hemerik</author>
</authors>
<title>Formal definitions of programming languages as a basis for compiler construction&apos;, Ph.D. th.,</title>
<date>1984</date>
<institution>University of Eindhoven.</institution>
<contexts>
<context position="5144" citStr="Hemerik (1984)" startWordPosition="845" endWordPosition="846">lar language C(i). Then we can construct a minimal regular grammar rg, which defines the same language. The grammar rgi will have the following form: • A set of non-terminals N, = {I? , , • A set of terminals E. E, is the smallest set such that there is a terminal f E E, for each M-rule r . • Start symbol I? - 210 • • A set of production rules P, containing the following type of rules: — f/t, where f E Ei — /i7 —■ — If --• e. We will use the regular grammar defined above as a starting point for the construction of an attributed subgrammar. An elegant view of attribute grammars can be found in Hemerik (1984). Hemerik defines an attribute grammar as a context free grammar with parametrized non-terminals and production rules. In general, non, terminals may have a number of parameters - attributes - associated with them. Production rules of an attribute grammar are pairs (rule form, rule condition). From a rule form, production rules can be obtained by means of substitution of values for the attribute variables that satisfy the rule condition. In the grammars presented in this paper, non-terminals have only one attribute of type S-tree. The attribute grammar rules that are used throughout this paper</context>
</contexts>
<marker>Hemerik, 1984</marker>
<rawString>Hemerik, C. (1984), &apos;Formal definitions of programming languages as a basis for compiler construction&apos;, Ph.D. th., University of Eindhoven.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Hoperoft</author>
<author>J D Ullman</author>
</authors>
<title>Introduction to Automata Theory, Languages and Computation&apos;,</title>
<date>1979</date>
<publisher>Addison Wesley Publishing Company,</publisher>
<location>Reading, Mass.</location>
<contexts>
<context position="20649" citStr="Hoperoft and Ullman (1979)" startWordPosition="3552" endWordPosition="3555">eans for two M-grammars to be isomorphic: &amp;quot;...Two grammars are isomorphic if each semantic derivation tree which is well-formed with respect to one grammar is also well-formed with respect to the other grammar...&amp;quot; (Landsbergen (1987)). We can reformulate the original definition of isomorphic M-grammars in a very elegant way for samg&apos;s: Definition: Two samg&apos;s X1 and X2 are isomorphic if they are equivalent, that is if cpci) = c(x2) This definition says that writing isomorphic grammars comes down to writing two attribute grammars which define the same language. From formal language theory (e.g. Hoperoft and Ullman (1979)) we know that there is no algorithm that can test an arbitrary pair of context-free grammars G1 and G2 to determine whether L(G1) = L(G2). It can also be shown that samg&apos;s can define any recursive language. Consequently, checking the equivalence of two arbitrary samg&apos;s will be an undecidable problem. Rosetta grammars that are used for translation purposes, however, are not arbitrary samg&apos;s: they are not created completely independently. The strategy followed in Rosetta to accomplish the definition of equivalent grammars, that is, grammars that define identical languages, is to attune two samg</context>
</contexts>
<marker>Hoperoft, Ullman, 1979</marker>
<rawString>Hoperoft, J.E. and J.D. Ullman (1979), &apos;Introduction to Automata Theory, Languages and Computation&apos;, Addison Wesley Publishing Company, Reading, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Isabelle</author>
</authors>
<title>Towards Reversible M.T.</title>
<date>1989</date>
<journal>Systems&apos;, MT Summit&apos;!!,</journal>
<pages>67--68</pages>
<contexts>
<context position="12304" citStr="Isabelle (1989)" startWordPosition="2163" endWordPosition="2164">neration purposes with only inherited attributes containing the following type of rules: [It &lt;1 o &gt;—+ fl? &lt;1 pi &gt; S &lt;1, p2 &gt; ... (P1,...,Pn) E f,71(o) The generative interpretation of the rules will be used by MPars in the analysis phase of the Rosetta translation system. From the definitions of MPars and MGen the reversibility property of the grammar follows immediately: d E MPars(t) t E MGen(d) The reversibility property which has always been one of the tenets of the Rosetta system (Landsbergen (1982)) has recently received the appreciation of other researchers in the field of M.T. as well (Isabelle (1989), Rohrer (1989), van Noord (1990)). In order to give the M-grammar formalism a place in the list of other linguistic formalisms like LFG, FUG, TG, TAG and GPSG 1, we will investigate some computational aspects of amg&apos;s in this section. Given an amg grammar X, we can calculate the value of the designated attribute for an element of ,C(X). For this calculation an ordinary context free recognition algorithm (Earley(1970), Leermakers(1991)) can be used. Because the grammar may contain cycles of the form [&lt;o &gt;--+ .17 &lt; p &gt; (o,p) E its context-free backbone is not finitely ambiguous. Hence, an amg i</context>
</contexts>
<marker>Isabelle, 1989</marker>
<rawString>Isabelle, P. (1989), &apos;Towards Reversible M.T. Systems&apos;, MT Summit&apos;!!, pp. 67-68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Knuth</author>
</authors>
<title>Semantics of Context-Free Languages&apos;,</title>
<date>1968</date>
<journal>Math. Systems Theory</journal>
<volume>2</volume>
<pages>127--145</pages>
<contexts>
<context position="4198" citStr="Knuth (1968)" startWordPosition="664" endWordPosition="665">l therefore not occur in a derivation tree. The regular expression can be looked at as a prescription of the order in which the rules of the subgrammar have to be applied. Because of these changes in the formalism, new versions of the M-Parser and M-Generator algorithm were introduced which were able to deal with subgrammars. These algorithms, however, are complex and result in a rather cumbersome implementation. In this paper we will show that they can be replaced by normal context-free parse and generation algorithms if we interpret an M-grammar as the specification of an attribute grammar (Knuth (1968), Deransart et al.(1988)). M-grarnmars as attribute grammars The control expression which is used in the definition of a Rosetta subgrammar specifies a regular language over the alphabet of rule names. Another way to define such a language is by means of a regular grammar. Let control expression ce, of subgrammar i define the regular language C(i). Then we can construct a minimal regular grammar rg, which defines the same language. The grammar rgi will have the following form: • A set of non-terminals N, = {I? , , • A set of terminals E. E, is the smallest set such that there is a terminal f E</context>
</contexts>
<marker>Knuth, 1968</marker>
<rawString>Knuth, D.E. (1968), &apos;Semantics of Context-Free Languages&apos;, Math. Systems Theory 2, 2, pp. 127-145 (June 1968).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Landsbergen</author>
</authors>
<title>Adaptation of Montague grammar to the requirements of parsing&apos;, in:</title>
<date>1981</date>
<booktitle>Formal Methods in the Study of Language Part 2, MC Tract 136, Mathematical Centre,</booktitle>
<location>Amsterdam.</location>
<marker>Landsbergen, 1981</marker>
<rawString>Landsbergen, J. (1981), &apos;Adaptation of Montague grammar to the requirements of parsing&apos;, in: Formal Methods in the Study of Language Part 2, MC Tract 136, Mathematical Centre, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Landsbergen</author>
</authors>
<title>Machine Translation based on logically isomorphic Montague grammars&apos;,</title>
<date>1982</date>
<booktitle>Coling 82,</booktitle>
<pages>175--181</pages>
<location>North-Holland, Amsterdam,</location>
<contexts>
<context position="2391" citStr="Landsbergen (1982)" startWordPosition="361" endWordPosition="362">er algorithm is a syntactic derivation tree which reflects the history of the analysis process. The leaves of the derivation tree are names of basic expressions. The M-Generator algorithm generates a set of S-trees by bottom-up application of M-rules, the names of which are mentioned in a syntactic derivation tree. Analogous to Montague Grammar, with each M-rule a rule is associated which expresses its meaning. This allows for the transformation of a syntactic derivation tree into a semantic derivation tree by replacing the name of each M-rule by the name of the corresponding meaning rule. In Landsbergen (1982) it was shown that the formalism is very well fit to be nsed in an interlingual machine translation system in which semantic derivation trees make up the interlingua. In the analysis part of the translation system an S-tree of the source language is mapped onto a set of semantic derivation trees. Next, each semantic derivation tree is mapped onto a set of S-trees of the target language. In order to guarantee that for a sentence which can be analysed by means of the source language grammar a translation can always be generated using the target language grammar, source and target grammars in the</context>
<context position="12197" citStr="Landsbergen (1982)" startWordPosition="2145" endWordPosition="2146">,...,Pn) This interpretation is to be used by MGen in the generation phase of the Rosetta system. • one for generation purposes with only inherited attributes containing the following type of rules: [It &lt;1 o &gt;—+ fl? &lt;1 pi &gt; S &lt;1, p2 &gt; ... (P1,...,Pn) E f,71(o) The generative interpretation of the rules will be used by MPars in the analysis phase of the Rosetta translation system. From the definitions of MPars and MGen the reversibility property of the grammar follows immediately: d E MPars(t) t E MGen(d) The reversibility property which has always been one of the tenets of the Rosetta system (Landsbergen (1982)) has recently received the appreciation of other researchers in the field of M.T. as well (Isabelle (1989), Rohrer (1989), van Noord (1990)). In order to give the M-grammar formalism a place in the list of other linguistic formalisms like LFG, FUG, TG, TAG and GPSG 1, we will investigate some computational aspects of amg&apos;s in this section. Given an amg grammar X, we can calculate the value of the designated attribute for an element of ,C(X). For this calculation an ordinary context free recognition algorithm (Earley(1970), Leermakers(1991)) can be used. Because the grammar may contain cycles </context>
<context position="21365" citStr="Landsbergen (1982)" startWordPosition="3667" endWordPosition="3668">nd G2 to determine whether L(G1) = L(G2). It can also be shown that samg&apos;s can define any recursive language. Consequently, checking the equivalence of two arbitrary samg&apos;s will be an undecidable problem. Rosetta grammars that are used for translation purposes, however, are not arbitrary samg&apos;s: they are not created completely independently. The strategy followed in Rosetta to accomplish the definition of equivalent grammars, that is, grammars that define identical languages, is to attune two samg&apos;s to each other. This grammar attuning strategy is extensively described in Appelo et al.(1987), Landsbergen (1982) and Landsbergen (1987) for ordinary M-grammars. Here, we will show what the attuning strategy means in the context of samg&apos;s, together with a few extensions. The attuning measures below must not be looked at as the weakest possible conditions that guarantee isomorphy. The list merely is an enumeration of conditions which together should help to establish isomorphy. If two samg&apos;s XI and X2 have to be isomorphic, the following measures are proposed: • The production rules of both samg &apos;s must be consistent. If both grammars have a production rule in which the name of the meaning rule m appears,</context>
</contexts>
<marker>Landsbergen, 1982</marker>
<rawString>Landsbergen, J. (1982), &apos;Machine Translation based on logically isomorphic Montague grammars&apos;, Coling 82, North-Holland, Amsterdam, pp. 175-181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Landsbergen</author>
</authors>
<title>Isomorphic grammars and their use in the Rosetta Translation system&apos;,</title>
<date>1987</date>
<booktitle>Machine TVanslation, the State of the</booktitle>
<editor>Art, M. King (ed.),</editor>
<publisher>Edinburg University Press.</publisher>
<contexts>
<context position="20256" citStr="Landsbergen (1987)" startWordPosition="3491" endWordPosition="3492">des all context sensitive languages (Cook We will call a grammar that has been derived in this way (1971)). from an amg a semantic amg, or samg. The strings - 213 of the language defined by an samg are prefix representations of semantic derivation trees. The language defined by an samg is called the set of strings which are well-formed with respect to X. Let us repeat here what it means for two M-grammars to be isomorphic: &amp;quot;...Two grammars are isomorphic if each semantic derivation tree which is well-formed with respect to one grammar is also well-formed with respect to the other grammar...&amp;quot; (Landsbergen (1987)). We can reformulate the original definition of isomorphic M-grammars in a very elegant way for samg&apos;s: Definition: Two samg&apos;s X1 and X2 are isomorphic if they are equivalent, that is if cpci) = c(x2) This definition says that writing isomorphic grammars comes down to writing two attribute grammars which define the same language. From formal language theory (e.g. Hoperoft and Ullman (1979)) we know that there is no algorithm that can test an arbitrary pair of context-free grammars G1 and G2 to determine whether L(G1) = L(G2). It can also be shown that samg&apos;s can define any recursive language.</context>
</contexts>
<marker>Landsbergen, 1987</marker>
<rawString>Landsbergen, J. (1987), &apos;Isomorphic grammars and their use in the Rosetta Translation system&apos;, Machine TVanslation, the State of the Art, M. King (ed.), Edinburg University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Leermakers</author>
</authors>
<title>Non-deterministic recursive ascent parsing&apos;,</title>
<date>1991</date>
<booktitle>Proceedings of the 5th ACL Conference, European Chapter, forthcoming.</booktitle>
<marker>Leermakers, 1991</marker>
<rawString>Leermakers, R (1991), &apos;Non-deterministic recursive ascent parsing&apos;, Proceedings of the 5th ACL Conference, European Chapter, forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>van G Noord</author>
</authors>
<title>Reversible Unification Based Machine Translation&apos;,</title>
<date>1990</date>
<booktitle>in Proceedings of the 13th International Conference on Computational Linguistics,</booktitle>
<location>Helsinki.</location>
<contexts>
<context position="12337" citStr="Noord (1990)" startWordPosition="2168" endWordPosition="2169">d attributes containing the following type of rules: [It &lt;1 o &gt;—+ fl? &lt;1 pi &gt; S &lt;1, p2 &gt; ... (P1,...,Pn) E f,71(o) The generative interpretation of the rules will be used by MPars in the analysis phase of the Rosetta translation system. From the definitions of MPars and MGen the reversibility property of the grammar follows immediately: d E MPars(t) t E MGen(d) The reversibility property which has always been one of the tenets of the Rosetta system (Landsbergen (1982)) has recently received the appreciation of other researchers in the field of M.T. as well (Isabelle (1989), Rohrer (1989), van Noord (1990)). In order to give the M-grammar formalism a place in the list of other linguistic formalisms like LFG, FUG, TG, TAG and GPSG 1, we will investigate some computational aspects of amg&apos;s in this section. Given an amg grammar X, we can calculate the value of the designated attribute for an element of ,C(X). For this calculation an ordinary context free recognition algorithm (Earley(1970), Leermakers(1991)) can be used. Because the grammar may contain cycles of the form [&lt;o &gt;--+ .17 &lt; p &gt; (o,p) E its context-free backbone is not finitely ambiguous. Hence, an amg is not necessarily off-line parsab</context>
</contexts>
<marker>Noord, 1990</marker>
<rawString>Noord, van G. (1990), &apos;Reversible Unification Based Machine Translation&apos;, in Proceedings of the 13th International Conference on Computational Linguistics, Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pereira</author>
<author>D Warren</author>
</authors>
<title>Parsing as deduction&apos;,</title>
<date>1983</date>
<booktitle>Proceedings of the 21th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>137--144</pages>
<contexts>
<context position="12967" citStr="Pereira and Warren (1983)" startWordPosition="2274" endWordPosition="2277"> order to give the M-grammar formalism a place in the list of other linguistic formalisms like LFG, FUG, TG, TAG and GPSG 1, we will investigate some computational aspects of amg&apos;s in this section. Given an amg grammar X, we can calculate the value of the designated attribute for an element of ,C(X). For this calculation an ordinary context free recognition algorithm (Earley(1970), Leermakers(1991)) can be used. Because the grammar may contain cycles of the form [&lt;o &gt;--+ .17 &lt; p &gt; (o,p) E its context-free backbone is not finitely ambiguous. Hence, an amg is not necessarily off-line parsable ( Pereira and Warren (1983), Haas (1989)). The term off-line parsable is somewhat misleading because a twostage parse process for grammars which are infinitely ambiguous is very well feasible. In the first stage of the parse process, in which the context free backbone is used, a finite representation of the infinitely many parse trees, e.g. in the form of a parse matrix, is determined. Next, in the second stage, the attributes are calculated. However, measure conditions on the attributes are necessary to guarantee termination of the parse process. These measure conditions are constraints on the size (according to a cert</context>
</contexts>
<marker>Pereira, Warren, 1983</marker>
<rawString>Pereira, F., D. Warren (1983), &apos;Parsing as deduction&apos;, Proceedings of the 21th Annual Meeting of the Association for Computational Linguistics, pp. 137-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C R Perrault</author>
</authors>
<title>On the Mathematical Properties of Linguistic Theories&apos;,</title>
<date>1984</date>
<journal>Computational Linguistics</journal>
<volume>10</volume>
<pages>165--176</pages>
<contexts>
<context position="13969" citStr="Perrault (1984)" startWordPosition="2437" endWordPosition="2438">, the attributes are calculated. However, measure conditions on the attributes are necessary to guarantee termination of the parse process. These measure conditions are constraints on the size (according to a certain measure) of the attribute values that occur in each cycle of the underlying context free grammar. The generative interpretation of amg X can be used in a straight-forward language generator which generates all corresponding elements of E(X) for a given value of the designated attribute. Obviously, it can only be guaranteed that the generation process will always terminate if lcf. Perrault (1984) for a comparison of the mathematical properties of these formalisms. - 212 - the grammar satisfies some restrictions. Suggestions for grammar constraints in the form of termination conditions for parsing and generation are given in Appelo et al.(1987). For an insight into the weak generative capacity of the formalism we have to examine the set of yields of the S-trees in the output set of an amg. Let us call this set the output language defined by an amg. It is not possible to characterize exactly the set of output languages that can be defined by an amg without defining what the termination </context>
</contexts>
<marker>Perrault, 1984</marker>
<rawString>Perrault, C.R. (1984), &apos;On the Mathematical Properties of Linguistic Theories&apos;, Computational Linguistics 10, pp. 165-176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ritchie</author>
</authors>
<title>The computational complexity of sentence derivation in functional unification grammar&apos;,</title>
<date>1986</date>
<booktitle>Proceedings of Coling&apos;86,</booktitle>
<pages>584--586</pages>
<contexts>
<context position="18029" citStr="Ritchie (1986)" startWordPosition="3109" endWordPosition="3110">ity has of course its consequences for the computational complexity of the generation and recognition process, Here too, the exact form of the termination condition is important. Obeying the termination conditions that we adhere to in the current Rosetta system, it can be proved that the recognition and the generation problems are NP-hard, which makes them computationally intractable. In comparison with other formalisms, M-grammars are no exception with respect to the complexity of these issues. LFG recognition and FUG generation have both been proved to be NP-hard in Barton et al, (1987) and Ritchie (1986) respectively. Recognition in GPBG has even been proved to be EXP-POLY-hard (Barton et al. 1987). We should keep in mind, however, that the computational complexity analysis is a worstcase analysis. The average-case behaviour of the parse and generation algorithm that we experience in the daily use of the Rosetta system is certainly not exponential. Isomorphic Grammars The decidability of the question whether two Mgrammoo are isomorphic is another computational aspect related to M-grammars. Although this mathematical issue appears not to be very relevant from a practical point of view, it enab</context>
</contexts>
<marker>Ritchie, 1986</marker>
<rawString>Ritchie, G. (1986), &apos;The computational complexity of sentence derivation in functional unification grammar&apos;, Proceedings of Coling&apos;86, pp. 584-586.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Rohrer</author>
</authors>
<title>New directions in MT systems&apos;,</title>
<date>1989</date>
<booktitle>MT Summit II,</booktitle>
<pages>120--122</pages>
<contexts>
<context position="12319" citStr="Rohrer (1989)" startWordPosition="2165" endWordPosition="2166"> with only inherited attributes containing the following type of rules: [It &lt;1 o &gt;—+ fl? &lt;1 pi &gt; S &lt;1, p2 &gt; ... (P1,...,Pn) E f,71(o) The generative interpretation of the rules will be used by MPars in the analysis phase of the Rosetta translation system. From the definitions of MPars and MGen the reversibility property of the grammar follows immediately: d E MPars(t) t E MGen(d) The reversibility property which has always been one of the tenets of the Rosetta system (Landsbergen (1982)) has recently received the appreciation of other researchers in the field of M.T. as well (Isabelle (1989), Rohrer (1989), van Noord (1990)). In order to give the M-grammar formalism a place in the list of other linguistic formalisms like LFG, FUG, TG, TAG and GPSG 1, we will investigate some computational aspects of amg&apos;s in this section. Given an amg grammar X, we can calculate the value of the designated attribute for an element of ,C(X). For this calculation an ordinary context free recognition algorithm (Earley(1970), Leermakers(1991)) can be used. Because the grammar may contain cycles of the form [&lt;o &gt;--+ .17 &lt; p &gt; (o,p) E its context-free backbone is not finitely ambiguous. Hence, an amg is not necessari</context>
</contexts>
<marker>Rohrer, 1989</marker>
<rawString>Rohrer, C. (1989), &apos;New directions in MT systems&apos;, MT Summit II, pp. 120-122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Rounds</author>
</authors>
<title>A grammatical characterization of the exponential languages&apos;,</title>
<date>1975</date>
<booktitle>Proceedings of the 16th Annual Symposium on Switching Theory and Automata, IEEE Computer Society,</booktitle>
<pages>135--143</pages>
<location>New York,</location>
<marker>Rounds, 1975</marker>
<rawString>Rounds, W. (1975), &apos;A grammatical characterization of the exponential languages&apos;, Proceedings of the 16th Annual Symposium on Switching Theory and Automata, IEEE Computer Society, New York, pp. 135-143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>Separating Linguistic Analyses from Linguistic Theories&apos;,</title>
<date>1987</date>
<booktitle>in Linguistic Theory and Computer Applications,</booktitle>
<publisher>Academic Press.</publisher>
<contexts>
<context position="15871" citStr="Shieber (1987)" startWordPosition="2751" endWordPosition="2752">The termination condition is only satisfied by Turing Machines that halt on all inputs, which is exactly the class of machines that define the set of all recursive languages. Consequently, the output languages that can be defined by amg&apos;s or M-grammars, in principle, are the languages that can be recognized by deterministic Turing Machines in finite time. At this point it is appropriate to mention the bifurcation of grammatical formalisms into two classes: the formalisms designed as linguistic tools (e.g. PATR-H, FUG, DCG) and those intended to be linguistic theories (e.g. LFG, GPSG, GB) (cf. Shieber (1987) for a motivation of this bifurcation). The goals of these formalisms with respect to expressive power are, in general, at odds with each other. While great expressive power is considered to be an advantage of tool-oriented formalisms, it is considered to be an undesirable property of formalisms of the theory type. The M-grammar formalism clearly belongs to the category of linguistic tools. By strengthening the termination conditions it is possible to restrict the class of output languages that can be defined by an amg. For instance, the class of output languages can be restricted to the langu</context>
</contexts>
<marker>Shieber, 1987</marker>
<rawString>Shieber, S. M. (1987), &apos;Separating Linguistic Analyses from Linguistic Theories&apos;, in Linguistic Theory and Computer Applications, Academic Press.</rawString>
</citation>
<citation valid="false">
<pages>215</pages>
<marker></marker>
<rawString>- 215 -</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>