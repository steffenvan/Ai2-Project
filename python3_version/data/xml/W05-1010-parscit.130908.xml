<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9957855">
Automatic Acquisition of Bilingual Rules for Extraction of
Bilingual Word Pairs from Parallel Corpora
</title>
<author confidence="0.941218">
Hiroshi Echizen-ya
</author>
<affiliation confidence="0.9251895">
Dept. of Electronics and Information
Hokkai-Gakuen University
</affiliation>
<address confidence="0.8063825">
S26-Jo W11-Chome, Chuo-ku
Sapporo, 064-0926 Japan
</address>
<email confidence="0.902051">
echiOeli.hokkai-s-u.ac.jp
</email>
<note confidence="0.9047345">
Kenji Araki
Graduate School of Information Science
and Technology, Hokkaido University
N14-Jo W9-Chome, Kita-ku
</note>
<address confidence="0.44569">
Sapporo, 060-0814 Japan
</address>
<email confidence="0.679301">
arakiOmedia.eng.hokudai.ac.jp
</email>
<author confidence="0.91041">
Yoshio Momouchi
</author>
<affiliation confidence="0.9943625">
Dept. of Electronics and Information
Hokkai-Gakuen University
</affiliation>
<address confidence="0.6599535">
S26-Jo W11-Chome, Chuo-ku
Sapporo, 064-0926 Japan
</address>
<email confidence="0.688951">
momouchiOeli.hokkai-s-u.ac.jp
</email>
<sectionHeader confidence="0.97583" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999809666666667">
In this paper, we propose a new
learning method to solve the sparse
data problem in automatic extraction
of bilingual word pairs from paral-
lel corpora with various languages.
Our learning method automatically ac-
quires rules, which are effective to solve
the sparse data problem, only from
parallel corpora without any bilingual
resource (e.g., a bilingual dictionary,
machine translation systems) before-
hand. We call this method Inductive
Chain Learning (ICL). The ICL can
limit the search scope for the deci-
sion of equivalents. Using ICL, the
recall in three systems based on sim-
ilarity measures improved respectively
8.0, 6.1 and 6.0 percentage points. In
addition, the recall value of GIZA++
improved 6.6 percentage points using
ICL.
</bodyText>
<sectionHeader confidence="0.997146" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.973073133333333">
1.1 Sparse data problems in extraction
of bilingual word pairs
Many studies of automatic extraction of bilin-
gual word pairs have been reported. Most stud-
ies have used similarity measures (Manning and
Schiitze, 1999; Sadat et al., 2002) because they
are language-independent. However, these stud-
ies are insufficient because of the sparse data
problem. For example, we would like to ob-
tain (book; * [hard]) as the bilingual word pair
from (Your book is on the table.; 5- —7)1//24::
A tSti:10)11K1b1 IA0 [teburu ni anata
no hon ga an masud) using the Dice coefficient
(Smadja et al., 1996) automatically. The Dice
coefficient is defined as
</bodyText>
<note confidence="0.274934">
2a (1)
Dice(Ws, WT) =(a ± + (a + e)
</note>
<bodyText confidence="0.99997">
In that equation, &apos;a&apos; is the number of pieces
in which both the Source Language (SL) word
Ws and Target Language (TL) word WT were
found; &apos;b&apos; is the number of pieces in which only
Ws was found; and &apos;c&apos; is the number of pieces
in which only WT was found.
In the case of using the Dice coefficient,
the system cannot extract only (book; * [hon])
when the respective frequencies of &amp;quot;book&amp;quot;,
&amp;quot;AK [hou]&amp;quot; and &amp;quot;5- —1 [teburu]&amp;quot; are 1. That
is, the similarity value between &amp;quot;book&amp;quot; and &amp;quot;AK
</bodyText>
<sectionHeader confidence="0.440273" genericHeader="introduction">
21+x N
</sectionHeader>
<bodyText confidence="0.961685">
[hour becomes 1.0(= ); the similarity value
between &amp;quot;book&amp;quot; and &amp;quot;-7)L[teburu]&amp;quot; also be-
</bodyText>
<footnote confidence="0.655235666666667">
&apos;Italics means Japanese pronunciation.
27&apos; in Japanese sentences are inserted after each mor-
pheme because Japanese is an agglutinative language.
</footnote>
<page confidence="0.995252">
87
</page>
<note confidence="0.87008475">
2 x
comes 1.0(= 1) This obstacle is common
D.
among methods based on similarity measures.
</note>
<bodyText confidence="0.963383">
cate the information to cope with the dif-
ference word orders of SL and TL.
1.2 Basic idea for solution of the sparse
data problem
We propose a new learning method to solve
this sparse data problem. We call this method
Inductive Chain Learning (ICL). For example,
in (Your book is on the table.; 5- —7)L//
A tS ti:10)/*/b1/A 9/t. [teburu ni anata
no hon ga an masud), a system using ICL
uses the information that &amp;quot;your&amp;quot; corresponds
to &amp;quot;A tS [anata no].&amp;quot; Moreover, it uses the
information that equivalents of words that ad-
join the right side of &amp;quot;your&amp;quot; exist on the right
side of &amp;quot;A tS [anata nor in TL sentences.
Using such bilingual rules, the system can ex-
tract only (book; * [hon]). This fact indicates
that the system limits the search scope for the
decision of equivalents in TL sentences. Conse-
quently, ICL is effective to solve the sparse data
problem. In this study, bilingual rules are ac-
quired automatically only from parallel corpora
by view of learning (Echizen-ya et al., 2002).
The system using ICL extracts bilingual word
pairs by applying the acquired bilingual rules
to bilingual sentence pairs in parallel corpora.
Therefore, the system using ICL causes a chain
reaction in the acquisition of bilingual rules and
the extraction of bilingual word pairs. The main
advantages of ICL are the following three:
</bodyText>
<listItem confidence="0.997023142857143">
(1) The system using ICL requires no bilin-
gual resource (e.g., a bilingual dictionary,
machine translation systems) beforehand.
All bilingual rules are acquired automati-
cally solely from the parallel corpora. More-
over, the system using ICL extracts bilin-
gual word pairs using only acquired bilin-
gual rules to solve the sparse data problem.
(2) The system using ICL is effective for paral-
lel corpora with various languages for which
the grammatical structures of SL differ from
the grammatical structures of TL (i.e., En-
glish – Japanese, not English – French, En-
glish – German) through the use of acquired
bilingual rules. The bilingual rules can lo-
(3) The system using ICL can extract bilin-
gual word pairs even when the frequencies
of the pairs of the co-occurrence words and
the bilingual word pairs are only 1 in a par-
allel corpus. For example, when the bilin-
gual rule (your A; A tS tz.10)10[anata no
@]) exists, the system using ICL can extract
(book; * [hon]) even when the frequency
of the pairs of &amp;quot;your&amp;quot; and &amp;quot;book&amp;quot; is only
1. This fact indicates that the system us-
ing ICL can extract not only high-frequency
bilingual word pairs, but also low-frequency
bilingual word pairs.
</listItem>
<bodyText confidence="0.999782157894737">
We applied this ICL to three systems based
on the Dice coefficient, Yates&apos; x2 (Hisamitsu
and Niwa, 1996), and Akaike&apos;s Information
Criterion (AIC) (Akaike, 1974). For evaluation
experiments, five kinds of parallel corpora: En-
glish – Japanese, French – Japanese, German
– Japanese, Shanghai-Chinese – Japanese and
Ainu3 – Japanese parallel corpora were used as
evaluation data. Evaluation experiments indi-
cated that, using ICL in the systems based on
the Dice coefficient, Yates&apos; x2 and AIC, the re-
spective recall values improved 8.0, 6.1 and 6.0
percentage points. In addition, using ICL, the
recall of the statistical word-alignment model
GIZA++ (Och, 2003) improved 6.6 percentage
points. Therefore, we confirmed that ICL is ef-
fective to solve the sparse data problem in the
extraction of bilingual word pairs from parallel
corpora with various languages.
</bodyText>
<subsectionHeader confidence="0.631056">
1.3 Related works
</subsectionHeader>
<bodyText confidence="0.999129">
Several methods based on the co-occurrence of
words have been proposed. (Fung, 1995) pro-
posed a method that specifically examines con-
text heterogeneity, which indicates the num-
ber of kinds of words that adjoin SL words.
(Rapp, 1999) proposed a method that uses co-
occurrence vectors based on the two words that
</bodyText>
<footnote confidence="0.999446">
3The Ainu language is spoken by some members of the
Ainu ethnic group of northern Japan and Sakhalin. Ainu
language is independent from, but similar to, Japanese
and Korean.
</footnote>
<page confidence="0.999516">
88
</page>
<bodyText confidence="0.999875934782609">
adjoin SL words on the right side and left
side. Moreover, (Fung, 1998; Kaji and Aizono,
1996) proposed methods that uses co-occurrence
vectors based on all words that exist in the
existing bilingual dictionary, among sentences.
(Tanaka and Iwasaki, 1996) presented a trans-
lation matrix that provides co-occurring infor-
mation translated from the source into the tar-
get, and obtains bilingual word pairs by deter-
mining the best translation matrix. Ultimately,
these methods depend on the existing bilingual
dictionary. Therefore, it is difficult to extract
bilingual word pairs from parallel corpora with
various languages when a sufficient bilingual dic-
tionary does not exist. In contrast, the system
using ICL automatically can extract bilingual
word pairs without an existing bilingual dictio-
nary as a bilingual resource.
Regarding methods for acquisition translation
templates, (McTait, 1997; Giivenir and Cicekli,
1998) proposed methods that acquires bilin-
gual templates using common parts and differ-
ent parts. However, such methods require many
similar bilingual sentence pairs to extract suf-
ficient translation templates. Moreover, K-vec
(Fung and Church, 1994) is unable to extract
low-frequency bilingual word pairs. The algo-
rithm is applicable only to bilingual word pairs
that occur with a frequency greater than three.
In addition, statistical word-alignment meth-
ods (Brown et al., 1993; Melamed, 2000; Och
and Ney, 2003; Niei3en and Ney, 2004) have been
proposed, but they are also insufficient. That
is, the statistical word-alignment methods can-
not extract bilingual word pairs efficiently when
the frequencies of many bilingual word pairs are
low. (Watanabe and Sumita, 2003) proposed a
method by which the decoder uses some transla-
tion examples whose source part is similar to the
input. However, numerous translation examples
are necessary as a bilingual resource. That is,
it is difficult to deal with languages for which
translation examples are not sufficiently obtain-
able. In contrast, ICL can extract bilingual rules
and bilingual word pairs efficiently, even from a
small parallel corpus.
</bodyText>
<sectionHeader confidence="0.993371" genericHeader="method">
2 Outline
</sectionHeader>
<bodyText confidence="0.9994076">
Figure 1 shows an outline of a system using
ICL. The ICL corresponds to three processes: a
method based on bilingual rules, a method based
on two bilingual sentence pairs, and the decision
process of bilingual word pairs.
</bodyText>
<figureCaption confidence="0.999123">
Figure 1: Process flow.
</figureCaption>
<bodyText confidence="0.999106590909091">
First, the user inputs the SL words of bilingual
word pairs. In methods based on bilingual rules,
the system extracts bilingual word pairs using
the acquired bilingual rules in the dictionary for
bilingual rules. In this paper, the bilingual rules
are the rules for extracting new bilingual word
pairs. In all extracted bilingual word pairs, sim-
ilarity values between SL words and TL words
are assigned using similarity measure. In the
method based on two bilingual sentence pairs,
the system obtains bilingual word pairs and new
bilingual rules using the bilingual sentence pairs
that SL words exist and other bilingual sentence
pairs. Moreover, in the decision process of bilin-
gual word pairs, the system chooses the most
suitable bilingual word pairs using their simi-
larity values when several bilingual word pairs
candidates exist. The system compares the sim-
ilarity values of chosen bilingual word pairs with
a threshold value. Consequently, the system reg-
isters the chosen bilingual word pairs to the dic-
tionary for bilingual word pairs when their re-
</bodyText>
<figure confidence="0.917820034482759">
Parallel corpus
Bilingual sentence
pair 1
Bilingual sentence
pair 2
•
SL Word
Method based on
sbilingual rules
\ (-Method based on
two bilingual
sentence pairs
C.
Dictionary for
bilingual rules
Decision process of
sbilingual word pairs j
&apos;Method based on
• Reference similarity measure
-* Registration
Dictionary for
bilingual word
pairs
89
1: Input: TL sentence of bilingual sentence pair that SL word exists
2: m = 1
3: if TLDPm exists on the left side of TLCP, then
4: If TLDP„,, corresponds to word then
5 Extraction of TLDP„,, (i.e., the part from word at the beginning
:
of TL sentence to word that adjoins the left side of TLCP,)
6: end
7: m = m + 1
8: end
9: if NTLCP 2 then
10: n = 1
11: while n &lt; NT„pC,
12: s = n + 1
13: while s NTLcpC,
14: if TLDPm corresponds to word then
15 Extraction of TLDP. (i.e., the part between TLCPu
:
and TLCPs)
16: end
17: s = s + 1
18: m = m + 1
19: end
20: n = n + 1
21: end
22: end
23: if TLDP„,, exists on the right side of TLCPNT„p then
24: if TLDP„,, corresponds to word then
Extraction of TLDP„,, (i.e., the part from word that adjoins the
right side of TLCPNT„p to word at the end of TL sentence)
26: end
27: end
28: Output: TLDPs that correspond to words
25:
</figure>
<figureCaption confidence="0.999967">
Figure 2: The algorithm of method based on two bilingual sentence pairs.
</figureCaption>
<bodyText confidence="0.9981494">
spective similarity values are greater than the
threshold value.
In the method based on similarity measure,
the system extracts bilingual word pairs using
only one similarity measure (i.e., the Dice coef-
ficient, Yates&apos; )(2, AIC) from bilingual sentence
pairs that SL words exist without ICL. It does
so when their similarity values are not greater
than the threshold or when no bilingual word
pairs are extracted in the ICL process.
</bodyText>
<sectionHeader confidence="0.997392" genericHeader="method">
3 Process
</sectionHeader>
<subsectionHeader confidence="0.9827485">
3.1 Method based on two bilingual
sentence pairs
</subsectionHeader>
<bodyText confidence="0.999842787878788">
In the method based on two bilingual sentence
pairs, the system acquires bilingual rules using
the bilingual sentence pairs that SL words exist
and other bilingual sentence pairs. The bilin-
gual word pairs for SL words are also extracted.
The system obtains bilingual rules using com-
mon parts between two bilingual sentence pairs.
That is, the word strings for which the frequen-
cies are very low are used as bilingual rules. Us-
ing such low-frequency word strings, the bilin-
gual rules are acquired easily only from paral-
lel corpus. In this paper, the respective com-
mon parts between SL sentences of two bilin-
gual sentence pairs are called SLCPi_1,...,NSLCP;
the respective common parts between TL sen-
tences of two bilingual sentence pairs are called
TLCPi_1,...,NTLCP; the respective different parts
between TL sentences of two bilingual sentence
pairs are called TLDP„,_1,2,3,.... In addition, the
number of SLCPs is called NSLCP; the number
of TLCPs is called NTLCP. The details of the
process based on two bilingual sentence pairs are
the following:
P1-(1) The system selects bilingual sentence
pairs for which SL words exist from a
parallel corpus. Moreover, the system
chooses the bilingual sentence pairs that
have SLCPs and TLCPs as the bilingual
sentence pairs with SL words. In that case,
SLCPs must adjoin SL words in SL sen-
tences.
P1-(2) The system extracts TLDPs that corre-
spond to nouns, verbs, adjectives, adverbs,
</bodyText>
<page confidence="0.990499">
90
</page>
<bodyText confidence="0.961938588235294">
or conjunctions from TL sentences of bilin-
gual sentence pairs for which SL words ex-
ist. Figure 2 shows the algorithm of this
process. In lines 11 and 13 of Fig. 2,
NTLCP C2 indicates 2, ( NNTTLLccr 2)! That is,
it means the number of combinations based
on two TLCPs.
P1-(3) The system obtains bilingual word pairs
by combining SL words and extracted TL-
CPs.
P1-(4) The system acquires bilingual rules us-
ing the extracted TLDPs. The details of
this process are the following:
(i) The system replaces SL words and the
extracted TLDPs with variables in the
bilingual sentence pairs for which SL
words exist.
</bodyText>
<listItem confidence="0.686157111111111">
(ii) The system extracts all pairs of each
SLCP and variable, and all pairs of
each TLCP and variable from bilingual
sentence pairs with variables obtained
by process (i) of P1-(4).
(iii) The system generates bilingual rules
using all combinations of the pairs of
SLCPs and variables, and the pairs of
TLCPs and variables.
</listItem>
<bodyText confidence="0.892071052631579">
(iv) The system calculates the similarity
values between SLCPs and TLCPs in
the acquired bilingual rules using the
Dice coefficient function (1); it regis-
ters the bilingual rules to the dictio-
nary for bilingual rules.
Figure 3 shows an acquisition example of
bilingual rules using two English — Japanese
bilingual sentence pairs. The system selects
bilingual sentence pair 1, for which &amp;quot;house&amp;quot; ex-
ists. Furthermore, the system chooses the bilin-
gual sentence pair 2 that have SLCP and TLCPs
as the bilingual sentence pairs with SL words by
process P1-(1). In Fig. 3, &amp;quot;this&amp;quot; is SLCP in
SL sentences of bilingual sentence pairs 1 and
2; it adjoins an SL word &amp;quot;house&amp;quot; in SL sen-
tence of bilingual sentence pair 1. First, the
system determines the TLDP that adjoins the
left side of TLCP1 by processes of lines 3 to 8
</bodyText>
<table confidence="0.56311947368421">
SL word: house
Bilingual sentence pair 1 :
(Please keep it until you leave this house.
SLCP
TLDP 1°
./rC14-3/-C/1..V-C/Tt LN•i
TLCP, TLCP2
[kono ie wo deru made mat te i te kudasail)
Bilingual sentence pair 2 :
(I&apos;d like to send this letter.:
SLCP TLCP, TLCP2
[kono tegami wo okuri tai no desul)
Extracted parts:
SL word &lt;4, TLDP, : house &lt;4, Cie] 0 Noun bilingual word pair
(Please keep it until you leave[this
[kono @wo deru made motte i te kudasail)
SL: this @; TL: LOW@ [kono 01, @/- [0 wo]
Bilingual rules and (this @; zo)/g [kono g1) : 0.4
similarity values: (this @;@/- [0 wo]) :0.1
</table>
<figureCaption confidence="0.9732115">
Figure 3: An acquisition example of bilingual
rules using two bilingual sentence pairs.
</figureCaption>
<bodyText confidence="0.99010659375">
in Fig. 2. However, in TL sentences of bilingual
sentence pair 1, the word that adjoins the left
side of TLCP1 (&amp;quot;L [kono]&amp;quot;) does not exist.
Therefore, TLDP is not extracted by this pro-
cess. The system then determines TLDPs using
the parts exist between two TLCPs by the pro-
cesses of lines 9 to 22 in Fig. 2. In TL sentences
of bilingual sentence pair 1, one TLDP exists
because the number of combinations based on
two TLCPs is by NTLCP:2 C2 = 2,(22! 2), = 1.
That is, &amp;quot;* [ie]&amp;quot; that exists between TLCP1
(&amp;quot;L [kono]&amp;quot;) and TLCP2 [wo]&amp;quot;) is deter-
mined as TLDP1. Moreover, the system deter-
mines the TLDP that adjoins the right side of
TLCPNTLcP:2 by the processes of lines 23 to 27
in Fig. 2. In TL sentences of bilingual sen-
tence pair 1, &amp;quot;M6[iT/4-9/T/I/N/T/TI/N
[deru made mot te i te kudasai]&amp;quot; is determined
as TLDP2 because it is the part from the word
that adjoins the right side of TLCP2 [wo]&amp;quot;)
to the word at the end of TL sentence. Among
two extracted TLDPs, the TLDP that corre-
sponds to word of noun, verb, adjective, ad-
verb, or conjunction is TLDP1 (&amp;quot;* [id&amp;quot;) that
is noun word. TLDP2 (&amp;quot;M
C/11&apos; [deru made mot te i te kudasai]&amp;quot;) is
0: words of nouns, verbs,
adjectives, adverbs and
conjunctions
x: not words of nouns,
verbs, adjectives,
adverbs and conjunctions
</bodyText>
<equation confidence="0.976641">
TLDP2 : x
</equation>
<page confidence="0.827661">
91
13:
</page>
<listItem confidence="0.917110545454546">
1: Input: SL word
while Selection of bilingual sentence pair that SL word exist, and selection of ICL
2: rule that has SLCP and TLCP to the selected bilingual sentence pair
3: if Variable exists on the right side of TLCP in TL part of ICL rule then
4: i = 0
5: while i &lt; NTLCP
6: Extraction of TL word (i.e., word of noun, verb, adjective, adverb
and conjunction) that adjoins the right side of TLCP in TL sentence
7: i = i + 1
8: end
9: end
</listItem>
<figure confidence="0.837054692307692">
10: if Variable exists on the left side of TLCP in TL part of ICL rule then
11: i = 0
12: while i &lt; NTLCP
Extraction of TL word (i.e., word of noun, verb, adjective, adverb
and conjunction) that adjoins the left side of TLCP in TL sentence
14: i = i + 1
15: end
16: end
17: end
18: Calculation of similarity value between SL word and each extracted TL word using
the cosine function (1)
19: Extraction of bilingual word pair by combining SL word and each TL word
20: Output: Bilingual word pairs
</figure>
<figureCaption confidence="0.999796">
Figure 4: The extraction algorithm of bilingual word pairs based on bilingual rules.
</figureCaption>
<bodyText confidence="0.998064333333334">
verb phrase, not word. Therefore, only (house;
[ie]) is obtained by combining the SL word
(&amp;quot;house&amp;quot;) and the extracted TLDP (&amp;quot;* [id&amp;quot;)
by process P1-(3). In addition, the system re-
places &amp;quot;house&amp;quot; and &amp;quot;* [ie]&amp;quot; with variable &amp;quot;A&amp;quot;
by process (i) of P1-(4). As a result, (this A;
IO[kono @]), (this 0;0/&apos;[ wo]) are ac-
quired as bilingual rules by process (ii) and (iii)
of P1-(4). Similarity values in the acquired bilin-
gual rules (this A; L I O[kono @]) and (this
0;0/ wo]) are calculated using Dice coeffi-
cient function (I) by process (iv) of P1-(4). The
similarity value of (this A; L I O[kono @]) is
higher than that of (this 0;0/ wo]) because
(this A; L I O[kono @]) is the correct bilingual
rule; and (this 0;0/ wo]) is the erroneous
bilingual rule. That is, &amp;quot;this&amp;quot; corresponds to &amp;quot;L
0) [kono]&amp;quot; , not [wo]&amp;quot; in Japanese. In this pa-
per, the parts extracted from SL sentences are
called SL parts; the parts extracted from TL
sentences are called TL parts.
</bodyText>
<subsectionHeader confidence="0.999755">
3.2 Method based on bilingual rules
</subsectionHeader>
<bodyText confidence="0.9902935">
In the method based on bilingual rules, the sys-
tem extracts bilingual word pairs using the bilin-
gual rules acquired by the method based on two
bilingual sentence pairs. The system can limit
the search scope for the decision of equivalents
in the TL sentences by the use of bilingual rules.
Figure 4 gives the extraction algorithm of bilin-
gual word pairs based on bilingual rules.
</bodyText>
<table confidence="0.6968626">
Extraction example 1
SL word 1: parcel
Bilingual rule 1 (this @;.707/@ [kono OP
Bilingual sentence pair 1
(And what about this parc)-lay-sea mail?
SLCP
; /.70,//iltilt/MIE/Tilt/E5/-Ct/tN?
TLCP
[soshite , kono kotsuzumi wa senbin de wa dou desu ka?])
Noun bilingual word pair
and similarity value: (parcel; /.1vg [kotsuzurm])
Extraction example 2
SL word 2: eat
Bilingual rule 2 (to @;@//10 rA)
Bilingual sentence pair 2 SLCP
</table>
<equation confidence="0.442039166666667">
(After the test, we all went out forlsomethingto eat.
SLCP
; Utik/0/1k/7/, /ailut.i./-C/A,‘//zi± tN11-/t.://v/7.t.
TLCP
[shiken no ato de, minna de tabe ni dekake ta n desul)
(eat ; [tabe])
</equation>
<figureCaption confidence="0.998044">
Figure 5: Examples of extraction of bilingual
word pairs based on bilingual rules.
</figureCaption>
<bodyText confidence="0.6743108">
Figure 5 shows examples of extraction of bilin-
gual word pairs from English-Japanese bilingual
sentence pairs in the method based on bilingual
Verb bilingual word pair
and similarity value:
</bodyText>
<page confidence="0.941902">
92
</page>
<bodyText confidence="0.998092291666667">
rules. In example 1 of Fig. 5, (parcel; dva [kot-
suzurni]) is extracted as the noun bilingual word
pair using (this A; IO[kono @]) acquired in
Fig. 3. First, the system selects bilingual sen-
tence pair 1 that SL word 1 &amp;quot;parcel&amp;quot; exists from
a parallel corpus. Moreover, the system selects
bilingual rule 1 (this A; 0) I O[kono @]) from
the dictionary for bilingual rules because the
variable &amp;quot;A&amp;quot; exists on the right side of SLCP
(&amp;quot;this&amp;quot;) in the SL part of bilingual rule 1, and
SL word 1 &amp;quot;parcel&amp;quot; also exists on the right side
of SLCP (&amp;quot;this&amp;quot;) in the SL sentence of bilin-
gual sentence pair 1. The system then extracts
TL words that adjoin the right side of TLCP be-
cause the variable &amp;quot;A&amp;quot; exists on the right side of
TLCP (&amp;quot;L kono&amp;quot;) in the TL part of bilingual
rule 1. Using bilingual rule 1, noun word &amp;quot;1:1\
[kotsuzurni]&amp;quot; , which exists on the right side of
TLCP (&amp;quot;L kono&amp;quot;) is extracted from TL sen-
tence of bilingual sentence pair 1. As a result,
the system can obtain (parcel; dva [kotsuzurni])
as the noun bilingual word pair.
In example 2 of Fig. 5, (eat; [tabe]) is
extracted as the verb bilingual word pair using
bilingual rule 2 (to A;A/ 4:1[ ni]). The sys-
tem selects bilingual sentence pair 2, in which
SL word 2 &amp;quot;eat&amp;quot; exists from a parallel corpus.
Moreover, the system selects bilingual rule 2 (to
A;A/ 4:1[ ni]) from the dictionary for bilingual
rules because the variable &amp;quot;A&amp;quot; exists on the right
side of SLCP (&amp;quot;to&amp;quot;) in the SL part of bilingual
rule 2, and SL word 2 &amp;quot;eat&amp;quot; also exists on the
right side of SLCP (&amp;quot;to&amp;quot;) in SL sentence of bilin-
gual sentence pair 2. The system then extracts
TL words that adjoin the left side of TLCP be-
cause the variable &amp;quot;A&amp;quot; exists on the left side
of TLCP (&amp;quot;4:: [ni]&amp;quot; ) in the TL part of bilingual
rule 2. Using bilingual rule 2, verb word
[tabe]&amp;quot; , which adjoins the left side of TLCP (&amp;quot;4::
[ni]&amp;quot;) is extracted from the TL sentence of bilin-
gual sentence pair 2. The system calculates the
similarity value between &amp;quot;eat&amp;quot; and &amp;quot;-ft, [tabe]&amp;quot;
using the Dice coefficient function (1), and reg-
istered (eat; [tabe]) into the dictionary of
bilingual word pairs. The system determines
the most suitable bilingual word pairs according
to their similarity values when several bilingual
word pairs have been extracted as described in
section 3.3.
Using the bilingual rules, the system can de-
crease the number of candidates of equivalents
for SL words. In example 2 of Fig. 5, the sys-
tem could decrease the number of candidates of
equivalents for &amp;quot;eat&amp;quot; using the bilingual rule (to
A;A/ 4:1[ ni]). All words of nouns, or verbs
&amp;quot;MA [shiken]&amp;quot; , &amp;quot;]&amp; [ato]&amp;quot; , &amp;quot;(7-).1-1, [minna]&amp;quot;,
[tabe]&amp;quot; , &amp;quot;fflAt [dekake]&amp;quot; , and &amp;quot;A, [n]&amp;quot; be-
come candidates of equivalents for &amp;quot;eat&amp;quot; when
ICL is not used. In contrast, only &amp;quot;-ft, [tabe]&amp;quot;
becomes candidates of equivalents for &amp;quot;eat&amp;quot; us-
ing ICL. This fact indicates that ICL is effec-
tive to solve the sparse data problem. Moreover,
the system can extract bilingual word pairs from
parallel corpora of various languages for which
the grammatical structure of SL differs from the
structure of TL. For example, in the bilingual
rule 2 (to A;A/ 4:1[ ni]), the variable &amp;quot;A&amp;quot; ex-
ists on the right side of &amp;quot;to.&amp;quot; In contrast, in the
TL part, the variable &amp;quot;A&amp;quot; exists on the left side
of &amp;quot;4:1 [ni].&amp;quot; Therefore, bilingual rules have the
knowledge to cope with the different word order
between SL and TL.
</bodyText>
<subsectionHeader confidence="0.693161">
3.3 Decision process of bilingual word
pair
</subsectionHeader>
<bodyText confidence="0.999247777777778">
The system determines the most suitable bilin-
gual word pairs according to their similarity val-
ues when several bilingual word pairs have been
extracted. The details of this process are the
following:
P2-(1) The system selects the bilingual word
pairs that have the highest similarity val-
ues.
P2-(2) When several bilingual word pairs with
identical similarity values exist, the system
selects the bilingual word pairs that used
bilingual rules with the highest similarity
values.
P2-(3) The system selects the bilingual word
pairs that appear in a parallel corpus for
the first time when it cannot choose only
one bilingual word pair by processes P2-(1)
and P2-(2).
</bodyText>
<page confidence="0.999126">
93
</page>
<tableCaption confidence="0.999885">
Table 1: Results of evaluation experiments.
</tableCaption>
<table confidence="0.99954425">
SL Dice Dice , Yates AIC AIC Number of
coefficient +ICL Yates&apos; x` +ICL +ICL bilingual word pairs
English 49.7% 58.0% 53.8% 59.8% 53.3% 58.6% 169
French 47.9% 56.7% 55.4% 60.4% 55.4% 60.4% 240
German 53.3% 61.0% 53.3% 58.5% 53.8% 59.0% 195
Sh.-Chinese 54.9% 62.9% 57.6% 62.5% 58.3% 62.9% 264
Ainu 54.0% 61.5% 52.1% 62.0% 52.6% 62.4% 213
Total 52.1% 60.1% 54.7% 60.8% 54.9% 60.9% 1,081
</table>
<subsectionHeader confidence="0.7330675">
3.4 Method based on similarity
measure
</subsectionHeader>
<bodyText confidence="0.9998851">
In the method based on similarity measures, the
system extracts bilingual word pairs using only
one similarity measure (i.e., the Dice coefficient,
Yates&apos; X2, AIC) without using ICL when the
similarity values are not greater than the thresh-
old value or when no bilingual word pairs are ex-
tracted. Moreover, the system chooses the bilin-
gual word pairs that appear in the parallel cor-
pus at the first time when several candidates of
bilingual word pairs are obtained.
</bodyText>
<sectionHeader confidence="0.99481" genericHeader="evaluation">
4 Performance Evaluation
</sectionHeader>
<subsectionHeader confidence="0.9980675">
4.1 Experimental Procedure and
Evaluation Standard
</subsectionHeader>
<bodyText confidence="0.999975617647059">
Five kinds of parallel corpora were used in
this paper as experimental data. These paral-
lel corpora are for English - Japanese, French
- Japanese, German - Japanese, Shanghai-
Chinese - Japanese and Ainu - Japanese.
They were taken from textbooks(Harukawa
and Snelling, 1998; Chikushi, 2001; Oshio,
2004; Emoto and Han, 2004; Nakagawa and
Nakamoto, 2004). The number of bilingual sen-
tence pairs was 1,794; the average numbers of
words in SL and TL sentences were 6.8 and 8.8,
respectively. We inputted all 1,081 SL words
of nouns, verbs, adjectives, adverbs, and con-
junctions in five parallel corpora to six systems:
a system based on the Dice coefficient; a sys-
tem based on the Dice coefficient in which AIL
is applied (herein, we call it the system based
on Dice+ICL); a system based on Yates&apos; X2; a
system based on Yates&apos; X2 in which ICL is ap-
plied (herein, the system based on Yates+ICL);
a system based on AIC; and a system based on
AIC in which ICL is applied (herein, the system
based on AIC+ICL). Initially, the dictionary for
bilingual word pairs and the bilingual rule dic-
tionary are empty. Moreover, the system uses
0.5 as its best threshold4. We repeated the ex-
periments for each parallel corpus using respec-
tive systems.
We evaluated whether or not correct bilingual
word pairs exist in the dictionary. Moreover, we
calculated the recall. The recall is the rate for
the number of correct bilingual word pairs to the
number of all bilingual word pairs in the parallel
corpora (i.e., 1,081).
</bodyText>
<subsectionHeader confidence="0.847717">
4.2 Experiments and Discussion
</subsectionHeader>
<bodyText confidence="0.999987692307692">
Table 1 shows the results of the experiments.
The respective recall values of the systems based
on Dice+ICL, Yates+ICL, and AIC+ICL were
more than 8.0, 6.1, and 6.0 percentage points
higher than those of the systems based on the
Dice coefficient, Yates&apos; X2, and AIC. These re-
sults indicate that ICL is effective for various
similarity measures. Particularly, the recall val-
ues of the bilingual word pairs for which the
frequencies are 1 improved to 11.0, 9.7 and 9.9
percentage points using ICL. In systems with-
out ICL, many bilingual word pairs for which
the frequencies are 1 were erroneous bilingual
</bodyText>
<footnote confidence="0.9139545">
4This value was obtained through preliminary exper-
iments. Some correct bilingual word pairs are evaluated
as erroneous bilingual word pairs when the system using
ICL uses a high value as a threshold. In contrast, some
erroneous bilingual word pairs are evaluated as correct
bilingual word pairs when the system using ICL uses a
low value as threshold. Therefore, 0.5, the middle value,
became a most suitable threshold.
</footnote>
<page confidence="0.998914">
94
</page>
<tableCaption confidence="0.998174">
Table 2: Examples of bilingual word pairs extracted by ICL.
</tableCaption>
<table confidence="0.999172333333333">
SL Correct bilingual word pairs Erroneous bilingual word pairs
Bilingual word pairs Equivalents
E nglish (cereal; ..:&gt; ) 7)0 1.0 0 curtains
(boarding house; -FM) 1.0 (curtains; *1-1 [new]) 0.67 interesting
(interesting; M- [outside]) 0.67
French (monuments;Et-is/sem) 1.0 (surtout; RI% [relation]) 1.0 specially
(cherche; al&amp;quot; [search]) 0.67 (petit; W [place]) 0.67 small
German (namlich; &apos;i 0 [after all]) 0.67 (Wege; 6 [bridge]) 1.0 lane
(das Foto; 4A [photograph]) 1.0 (Neues; *1111 [newspaper]) 0.67 new event
Sh.-Chinese (Thli ; 3A40/ L. [leave office] ) 1.0 (IIIPR; ,:-- tigl/ Li [treat] ) 1.0 lunch
(triM; _hit /1J-1 (aPR; # -E. [service]) 0.67 dinner
[Shanghai crab]) 1.0
Ainu (ekupa; &lt;b k [take something (apto; a -9 [fall]) 1.0 rain
in one&apos;s mouth]) 1.0 (tunasno; E‘8- [get up]) 0.67 early
(set ; IbF [bed]) 1.0
</table>
<bodyText confidence="0.994432310344828">
word pairs created by data sparseness problems,
as described in section 1.1. Therefore, improve-
ment of the recall values of bilingual word pairs
for which the frequencies are 1 indicates that
ICL is effective to solve the sparse data prob-
lem. On the other hand, the precision values -
the rates of the number of correct bilingual word
pairs to the number of all extracted bilingual
word pairs - are all equal to the recall values.
Among all 1,081 SL words, the correct bilin-
gual word pairs or erroneous bilingual word pairs
were obtained by the method based on similar-
ity measure when the ICL process extracted no
bilingual word pairs. Consequently, the numbers
of all bilingual word pairs in the parallel corpora
and of all extracted bilingual word pairs became
1,081. That is, the precision values are identical
to the recall values. Table 2 shows examples of
bilingual word pairs extracted by ICL and their
similarity values. Table 2 indicates that ICL can
extract not only bilingual word pairs that the
number of words is 1, but also bilingual word
pairs that the number of words is over 1.
Furthermore, we applied ICL to GIZA++.
Table 3 shows those experimental results. The
total recall of GIZA++ +ICL was more than 6.6
percentage points higher than that of GIZA++.
Table 3 indicates that ICL is very effective for
parallel corpora between languages for which the
</bodyText>
<tableCaption confidence="0.99722">
Table 3: Experimental results in GIZA++.
</tableCaption>
<table confidence="0.998966857142857">
SL GIZA++ GIZA++ +ICL
English 47.3% 54.4%
French 39.6% 54.2%
German 37.4% 61.5%
Sh.-Chinese 62.5% 60.6%
Ainu 66.6% 58.2%
Total 51.3% 57.9%
</table>
<bodyText confidence="0.999403">
grammatical structure of SL differs from the
grammar structure of TL. Grammatical struc-
tures of English, French, and German are SVO,
whereas the Japanese grammatical structure is
SOV. Using ICL, the recall improved 15.3 per-
centage points on average in English - Japanese,
French - Japanese, and German - Japanese par-
allel corpora.
</bodyText>
<sectionHeader confidence="0.99941" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999538375">
This paper presented Inductive Chain Learning
(ICL) as a new learning method to solve the
sparse data problem in extraction of bilingual
word pairs among various languages. From ex-
perimental results, we confirmed that ICL is ef-
fective to solve the sparse data problem in ex-
traction of bilingual word pairs from parallel cor-
pora with various languages.
</bodyText>
<page confidence="0.995642">
95
</page>
<bodyText confidence="0.99966725">
Future studies will solve the problem of word-
ambiguity. Moreover, we apply our method to a
multilingual machine translation system and an
cross-language information retrieval system.
</bodyText>
<sectionHeader confidence="0.998387" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.99913925">
This work was partially supported by Grants
from the High-Tech Research Center of Hokkai-
Gakuen University, and an academic research
grant of Hokkai-Gakuen University.
</bodyText>
<sectionHeader confidence="0.999149" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999922419753087">
Manning, C. D. and Schiitze, H. 1999. Foundations
of Statistical Natural Language Processing. The
MIT Press.
Sadat, F., Dejean, H. and Gaussier, E. 2002. A com-
bination of models for bilingual lexicon extraction
from comparable corpora. In Proceedings of Pa-
pilion&apos;02, pp.16-21.
Smadja, F., McKeown, K. R. and Hatzivassiloglou,
V. 1996. Translating Collocations for Bilingual
Lexicons: A Statistical Approach. Computational
Linguistics, vol.22, no.1, pp.1-38.
Echizen-ya, H., Araki, K. Momouchi, Y., and Tochi-
nai, K. 2002. Study of Practical Effectiveness for
Machine Translation Using Recursive Chain-link-
type Learning. In Proceedings of COLING &apos;02,
pp.246-252.
Hisamitsu, T. and Niwa, Y. 2001. Topic-Word Se-
lection Based on Combinatorial Probability. In
NLPRS&apos;01, pp.289-296.
Akaike, H. 1974. A New Look at the Statistical
Model Identification. IEEE Transactions on Au-
tomatic Control, AC-19(6), pp.716-723.
Och, F. J. 2003. GIZA++: Training of statisti-
cal translation models. Available at http://www-
16.informatik.rwth-aachen.de/Colleagues/och/
software/GIZA++.html
Fung, P. 1995. Compiling bilingual lexicon en-
tries from a non-parallel English-Chinese corpus.
Workshop on very large corpora, pp.173-183.
Rapp, R. 1999. Automatic identification of word
translations from unrelated English and German
corpora. In Proceedings of ACL&apos;99, pp.519-526.
Fung, P. 1998. A statistical view on bilingual lexicon
extraction: from parallel corpora to non-parallel
corpora, LNAL Springer Publishing, vol.1529,
pp.1-17.
Kaji, H. and Aizono, T. 1996. Extracting Word
Correspondences from Bilingual Corpora Based on
Word Co-occurrence Information. In Proc. Col-
ing &apos;96, pp.23-28.
Tanaka, K. and Iwasaki, H. 1996. Extraction of Lex-
ical Translation from Non-Aligned Corpora. In
Proc. Coling &apos;96, pp.580-585.
McTait, K. 1997. Linguistic knowledge and com-
plexity in an EBMT system based on translation
patterns. In Proceedings Workshop on EBMT,
MT Summit VIII.
Giivenir, H. A. and Cicekli, I. 1998. Learning trans-
lation templates from examples. Information Sys-
tems, vol. 23, no.6, pp.353-363.
Fung, P. and Church, K. 1994. K-vec: A new ap-
proach for alignment parallel texts. In Proc. Col-
pp.1096-1102.
Brown, P. F., Della Pietra, S. A., Della Pietra, V.
J., and Mercer, R. L. 1993. The mathematics
of statistical machine translation: Parameter es-
timation. Computational linguistics, vol.19, no.2,
pp.263-311.
Melamed, I. D. 2000. Models of translation equiv-
alence among words. Computational Linguistics,
vol.26, no.2, pp.221-249.
Och, F. J. and Ney, H. 2003. A systematic compari-
son of various statistical alignment models. Com-
putational Linguistics, vol.29, no.1, pp.19-51.
Nie/3en, S. and Ney, H. 2004. Statistical machine
translation with scarce resources using morpho-
syntactic information. Computational Linguistics,
vol.30, no.2, pp.181-204.
Watanabe, Y. and Sumita, E. 2003. Example-based
decoding for statistical machine translation. In
Proceedings of MT summit IX, pp.410-417.
Harukawa, Y. and Snelling, J. 1998. Express: En-
glish. Hakusui-sha (in Japanese).
Chikushi, F. 2001. Express: French. Hakusui-sha
(in Japanese).
Oshio, T. 2004. Express: German. Hakusui-sha (in
Japanese).
Emoto, H. and Han, G. 2004. Express: Shanghai.
Hakusui-sha (in Japanese).
Nakagawa, H. and Nakamoto, M. 2004. Express:
Ainu. Hakusui-sha (in Japanese).
</reference>
<page confidence="0.998461">
96
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.018431">
<title confidence="0.911212">Automatic Acquisition of Bilingual Rules for Extraction Bilingual Word Pairs from Parallel Corpora</title>
<author confidence="0.815597">Hiroshi</author>
<affiliation confidence="0.8024905">Dept. of Electronics and Hokkai-Gakuen</affiliation>
<address confidence="0.6658115">S26-Jo W11-Chome, Sapporo, 064-0926</address>
<email confidence="0.796477">Kenji</email>
<affiliation confidence="0.995001">Graduate School of Information and Technology, Hokkaido</affiliation>
<address confidence="0.8578105">N14-Jo W9-Chome, Sapporo, 060-0814</address>
<email confidence="0.970587">arakiOmedia.eng.hokudai.ac.jp</email>
<author confidence="0.499408">Yoshio</author>
<affiliation confidence="0.769717">Dept. of Electronics and Hokkai-Gakuen</affiliation>
<address confidence="0.6419685">S26-Jo W11-Chome, Sapporo, 064-0926</address>
<email confidence="0.974138">momouchiOeli.hokkai-s-u.ac.jp</email>
<abstract confidence="0.9894645">In this paper, we propose a new learning method to solve the sparse data problem in automatic extraction of bilingual word pairs from parallel corpora with various languages. Our learning method automatically acquires rules, which are effective to solve the sparse data problem, only from parallel corpora without any bilingual resource (e.g., a bilingual dictionary, machine translation systems) beforehand. We call this method Inductive Chain Learning (ICL). The ICL can limit the search scope for the decision of equivalents. Using ICL, the recall in three systems based on similarity measures improved respectively 8.0, 6.1 and 6.0 percentage points. In addition, the recall value of GIZA++ improved 6.6 percentage points using ICL.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>H Schiitze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="1558" citStr="Manning and Schiitze, 1999" startWordPosition="213" endWordPosition="216">g., a bilingual dictionary, machine translation systems) beforehand. We call this method Inductive Chain Learning (ICL). The ICL can limit the search scope for the decision of equivalents. Using ICL, the recall in three systems based on similarity measures improved respectively 8.0, 6.1 and 6.0 percentage points. In addition, the recall value of GIZA++ improved 6.6 percentage points using ICL. 1 Introduction 1.1 Sparse data problems in extraction of bilingual word pairs Many studies of automatic extraction of bilingual word pairs have been reported. Most studies have used similarity measures (Manning and Schiitze, 1999; Sadat et al., 2002) because they are language-independent. However, these studies are insufficient because of the sparse data problem. For example, we would like to obtain (book; * [hard]) as the bilingual word pair from (Your book is on the table.; 5- —7)1//24:: A tSti:10)11K1b1 IA0 [teburu ni anata no hon ga an masud) using the Dice coefficient (Smadja et al., 1996) automatically. The Dice coefficient is defined as 2a (1) Dice(Ws, WT) =(a ± + (a + e) In that equation, &apos;a&apos; is the number of pieces in which both the Source Language (SL) word Ws and Target Language (TL) word WT were found; &apos;b&apos;</context>
</contexts>
<marker>Manning, Schiitze, 1999</marker>
<rawString>Manning, C. D. and Schiitze, H. 1999. Foundations of Statistical Natural Language Processing. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sadat</author>
<author>H Dejean</author>
<author>E Gaussier</author>
</authors>
<title>A combination of models for bilingual lexicon extraction from comparable corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of Papilion&apos;02,</booktitle>
<pages>16--21</pages>
<contexts>
<context position="1579" citStr="Sadat et al., 2002" startWordPosition="217" endWordPosition="220">machine translation systems) beforehand. We call this method Inductive Chain Learning (ICL). The ICL can limit the search scope for the decision of equivalents. Using ICL, the recall in three systems based on similarity measures improved respectively 8.0, 6.1 and 6.0 percentage points. In addition, the recall value of GIZA++ improved 6.6 percentage points using ICL. 1 Introduction 1.1 Sparse data problems in extraction of bilingual word pairs Many studies of automatic extraction of bilingual word pairs have been reported. Most studies have used similarity measures (Manning and Schiitze, 1999; Sadat et al., 2002) because they are language-independent. However, these studies are insufficient because of the sparse data problem. For example, we would like to obtain (book; * [hard]) as the bilingual word pair from (Your book is on the table.; 5- —7)1//24:: A tSti:10)11K1b1 IA0 [teburu ni anata no hon ga an masud) using the Dice coefficient (Smadja et al., 1996) automatically. The Dice coefficient is defined as 2a (1) Dice(Ws, WT) =(a ± + (a + e) In that equation, &apos;a&apos; is the number of pieces in which both the Source Language (SL) word Ws and Target Language (TL) word WT were found; &apos;b&apos; is the number of pie</context>
</contexts>
<marker>Sadat, Dejean, Gaussier, 2002</marker>
<rawString>Sadat, F., Dejean, H. and Gaussier, E. 2002. A combination of models for bilingual lexicon extraction from comparable corpora. In Proceedings of Papilion&apos;02, pp.16-21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Smadja</author>
<author>K R McKeown</author>
<author>V Hatzivassiloglou</author>
</authors>
<title>Translating Collocations for Bilingual Lexicons: A Statistical Approach.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<pages>1--38</pages>
<contexts>
<context position="1930" citStr="Smadja et al., 1996" startWordPosition="277" endWordPosition="280"> points using ICL. 1 Introduction 1.1 Sparse data problems in extraction of bilingual word pairs Many studies of automatic extraction of bilingual word pairs have been reported. Most studies have used similarity measures (Manning and Schiitze, 1999; Sadat et al., 2002) because they are language-independent. However, these studies are insufficient because of the sparse data problem. For example, we would like to obtain (book; * [hard]) as the bilingual word pair from (Your book is on the table.; 5- —7)1//24:: A tSti:10)11K1b1 IA0 [teburu ni anata no hon ga an masud) using the Dice coefficient (Smadja et al., 1996) automatically. The Dice coefficient is defined as 2a (1) Dice(Ws, WT) =(a ± + (a + e) In that equation, &apos;a&apos; is the number of pieces in which both the Source Language (SL) word Ws and Target Language (TL) word WT were found; &apos;b&apos; is the number of pieces in which only Ws was found; and &apos;c&apos; is the number of pieces in which only WT was found. In the case of using the Dice coefficient, the system cannot extract only (book; * [hon]) when the respective frequencies of &amp;quot;book&amp;quot;, &amp;quot;AK [hou]&amp;quot; and &amp;quot;5- —1 [teburu]&amp;quot; are 1. That is, the similarity value between &amp;quot;book&amp;quot; and &amp;quot;AK 21+x N [hour becomes 1.0(= ); the </context>
</contexts>
<marker>Smadja, McKeown, Hatzivassiloglou, 1996</marker>
<rawString>Smadja, F., McKeown, K. R. and Hatzivassiloglou, V. 1996. Translating Collocations for Bilingual Lexicons: A Statistical Approach. Computational Linguistics, vol.22, no.1, pp.1-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Echizen-ya</author>
<author>K Momouchi Araki</author>
<author>Y</author>
<author>K Tochinai</author>
</authors>
<title>Study of Practical Effectiveness for Machine Translation Using Recursive Chain-linktype Learning.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING &apos;02,</booktitle>
<pages>246--252</pages>
<contexts>
<context position="3814" citStr="Echizen-ya et al., 2002" startWordPosition="612" endWordPosition="615">), a system using ICL uses the information that &amp;quot;your&amp;quot; corresponds to &amp;quot;A tS [anata no].&amp;quot; Moreover, it uses the information that equivalents of words that adjoin the right side of &amp;quot;your&amp;quot; exist on the right side of &amp;quot;A tS [anata nor in TL sentences. Using such bilingual rules, the system can extract only (book; * [hon]). This fact indicates that the system limits the search scope for the decision of equivalents in TL sentences. Consequently, ICL is effective to solve the sparse data problem. In this study, bilingual rules are acquired automatically only from parallel corpora by view of learning (Echizen-ya et al., 2002). The system using ICL extracts bilingual word pairs by applying the acquired bilingual rules to bilingual sentence pairs in parallel corpora. Therefore, the system using ICL causes a chain reaction in the acquisition of bilingual rules and the extraction of bilingual word pairs. The main advantages of ICL are the following three: (1) The system using ICL requires no bilingual resource (e.g., a bilingual dictionary, machine translation systems) beforehand. All bilingual rules are acquired automatically solely from the parallel corpora. Moreover, the system using ICL extracts bilingual word pai</context>
</contexts>
<marker>Echizen-ya, Araki, Y, Tochinai, 2002</marker>
<rawString>Echizen-ya, H., Araki, K. Momouchi, Y., and Tochinai, K. 2002. Study of Practical Effectiveness for Machine Translation Using Recursive Chain-linktype Learning. In Proceedings of COLING &apos;02, pp.246-252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hisamitsu</author>
<author>Y Niwa</author>
</authors>
<title>Topic-Word Selection Based on Combinatorial Probability.</title>
<date>2001</date>
<booktitle>In NLPRS&apos;01,</booktitle>
<pages>289--296</pages>
<marker>Hisamitsu, Niwa, 2001</marker>
<rawString>Hisamitsu, T. and Niwa, Y. 2001. Topic-Word Selection Based on Combinatorial Probability. In NLPRS&apos;01, pp.289-296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Akaike</author>
</authors>
<title>A New Look at the Statistical Model Identification.</title>
<date>1974</date>
<journal>IEEE Transactions on Automatic Control,</journal>
<volume>19</volume>
<issue>6</issue>
<pages>716--723</pages>
<contexts>
<context position="5490" citStr="Akaike, 1974" startWordPosition="893" endWordPosition="894">s of the pairs of the co-occurrence words and the bilingual word pairs are only 1 in a parallel corpus. For example, when the bilingual rule (your A; A tS tz.10)10[anata no @]) exists, the system using ICL can extract (book; * [hon]) even when the frequency of the pairs of &amp;quot;your&amp;quot; and &amp;quot;book&amp;quot; is only 1. This fact indicates that the system using ICL can extract not only high-frequency bilingual word pairs, but also low-frequency bilingual word pairs. We applied this ICL to three systems based on the Dice coefficient, Yates&apos; x2 (Hisamitsu and Niwa, 1996), and Akaike&apos;s Information Criterion (AIC) (Akaike, 1974). For evaluation experiments, five kinds of parallel corpora: English – Japanese, French – Japanese, German – Japanese, Shanghai-Chinese – Japanese and Ainu3 – Japanese parallel corpora were used as evaluation data. Evaluation experiments indicated that, using ICL in the systems based on the Dice coefficient, Yates&apos; x2 and AIC, the respective recall values improved 8.0, 6.1 and 6.0 percentage points. In addition, using ICL, the recall of the statistical word-alignment model GIZA++ (Och, 2003) improved 6.6 percentage points. Therefore, we confirmed that ICL is effective to solve the sparse data</context>
</contexts>
<marker>Akaike, 1974</marker>
<rawString>Akaike, H. 1974. A New Look at the Statistical Model Identification. IEEE Transactions on Automatic Control, AC-19(6), pp.716-723.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>GIZA++: Training of statistical translation models.</title>
<date>2003</date>
<note>Available at http://www16.informatik.rwth-aachen.de/Colleagues/och/ software/GIZA++.html</note>
<contexts>
<context position="5987" citStr="Och, 2003" startWordPosition="970" endWordPosition="971">e Dice coefficient, Yates&apos; x2 (Hisamitsu and Niwa, 1996), and Akaike&apos;s Information Criterion (AIC) (Akaike, 1974). For evaluation experiments, five kinds of parallel corpora: English – Japanese, French – Japanese, German – Japanese, Shanghai-Chinese – Japanese and Ainu3 – Japanese parallel corpora were used as evaluation data. Evaluation experiments indicated that, using ICL in the systems based on the Dice coefficient, Yates&apos; x2 and AIC, the respective recall values improved 8.0, 6.1 and 6.0 percentage points. In addition, using ICL, the recall of the statistical word-alignment model GIZA++ (Och, 2003) improved 6.6 percentage points. Therefore, we confirmed that ICL is effective to solve the sparse data problem in the extraction of bilingual word pairs from parallel corpora with various languages. 1.3 Related works Several methods based on the co-occurrence of words have been proposed. (Fung, 1995) proposed a method that specifically examines context heterogeneity, which indicates the number of kinds of words that adjoin SL words. (Rapp, 1999) proposed a method that uses cooccurrence vectors based on the two words that 3The Ainu language is spoken by some members of the Ainu ethnic group of</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Och, F. J. 2003. GIZA++: Training of statistical translation models. Available at http://www16.informatik.rwth-aachen.de/Colleagues/och/ software/GIZA++.html</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fung</author>
</authors>
<title>Compiling bilingual lexicon entries from a non-parallel English-Chinese corpus. Workshop on very large corpora,</title>
<date>1995</date>
<pages>173--183</pages>
<contexts>
<context position="6289" citStr="Fung, 1995" startWordPosition="1017" endWordPosition="1018">re used as evaluation data. Evaluation experiments indicated that, using ICL in the systems based on the Dice coefficient, Yates&apos; x2 and AIC, the respective recall values improved 8.0, 6.1 and 6.0 percentage points. In addition, using ICL, the recall of the statistical word-alignment model GIZA++ (Och, 2003) improved 6.6 percentage points. Therefore, we confirmed that ICL is effective to solve the sparse data problem in the extraction of bilingual word pairs from parallel corpora with various languages. 1.3 Related works Several methods based on the co-occurrence of words have been proposed. (Fung, 1995) proposed a method that specifically examines context heterogeneity, which indicates the number of kinds of words that adjoin SL words. (Rapp, 1999) proposed a method that uses cooccurrence vectors based on the two words that 3The Ainu language is spoken by some members of the Ainu ethnic group of northern Japan and Sakhalin. Ainu language is independent from, but similar to, Japanese and Korean. 88 adjoin SL words on the right side and left side. Moreover, (Fung, 1998; Kaji and Aizono, 1996) proposed methods that uses co-occurrence vectors based on all words that exist in the existing bilingu</context>
</contexts>
<marker>Fung, 1995</marker>
<rawString>Fung, P. 1995. Compiling bilingual lexicon entries from a non-parallel English-Chinese corpus. Workshop on very large corpora, pp.173-183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated English and German corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of ACL&apos;99,</booktitle>
<pages>519--526</pages>
<contexts>
<context position="6437" citStr="Rapp, 1999" startWordPosition="1042" endWordPosition="1043">spective recall values improved 8.0, 6.1 and 6.0 percentage points. In addition, using ICL, the recall of the statistical word-alignment model GIZA++ (Och, 2003) improved 6.6 percentage points. Therefore, we confirmed that ICL is effective to solve the sparse data problem in the extraction of bilingual word pairs from parallel corpora with various languages. 1.3 Related works Several methods based on the co-occurrence of words have been proposed. (Fung, 1995) proposed a method that specifically examines context heterogeneity, which indicates the number of kinds of words that adjoin SL words. (Rapp, 1999) proposed a method that uses cooccurrence vectors based on the two words that 3The Ainu language is spoken by some members of the Ainu ethnic group of northern Japan and Sakhalin. Ainu language is independent from, but similar to, Japanese and Korean. 88 adjoin SL words on the right side and left side. Moreover, (Fung, 1998; Kaji and Aizono, 1996) proposed methods that uses co-occurrence vectors based on all words that exist in the existing bilingual dictionary, among sentences. (Tanaka and Iwasaki, 1996) presented a translation matrix that provides co-occurring information translated from the</context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>Rapp, R. 1999. Automatic identification of word translations from unrelated English and German corpora. In Proceedings of ACL&apos;99, pp.519-526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fung</author>
</authors>
<title>A statistical view on bilingual lexicon extraction: from parallel corpora to non-parallel corpora,</title>
<date>1998</date>
<volume>1529</volume>
<pages>1--17</pages>
<publisher>LNAL Springer Publishing,</publisher>
<contexts>
<context position="6762" citStr="Fung, 1998" startWordPosition="1099" endWordPosition="1100">el corpora with various languages. 1.3 Related works Several methods based on the co-occurrence of words have been proposed. (Fung, 1995) proposed a method that specifically examines context heterogeneity, which indicates the number of kinds of words that adjoin SL words. (Rapp, 1999) proposed a method that uses cooccurrence vectors based on the two words that 3The Ainu language is spoken by some members of the Ainu ethnic group of northern Japan and Sakhalin. Ainu language is independent from, but similar to, Japanese and Korean. 88 adjoin SL words on the right side and left side. Moreover, (Fung, 1998; Kaji and Aizono, 1996) proposed methods that uses co-occurrence vectors based on all words that exist in the existing bilingual dictionary, among sentences. (Tanaka and Iwasaki, 1996) presented a translation matrix that provides co-occurring information translated from the source into the target, and obtains bilingual word pairs by determining the best translation matrix. Ultimately, these methods depend on the existing bilingual dictionary. Therefore, it is difficult to extract bilingual word pairs from parallel corpora with various languages when a sufficient bilingual dictionary does not </context>
</contexts>
<marker>Fung, 1998</marker>
<rawString>Fung, P. 1998. A statistical view on bilingual lexicon extraction: from parallel corpora to non-parallel corpora, LNAL Springer Publishing, vol.1529, pp.1-17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kaji</author>
<author>T Aizono</author>
</authors>
<title>Extracting Word Correspondences from Bilingual Corpora Based on Word Co-occurrence Information.</title>
<date>1996</date>
<booktitle>In Proc. Coling &apos;96,</booktitle>
<pages>23--28</pages>
<contexts>
<context position="6786" citStr="Kaji and Aizono, 1996" startWordPosition="1101" endWordPosition="1104">ith various languages. 1.3 Related works Several methods based on the co-occurrence of words have been proposed. (Fung, 1995) proposed a method that specifically examines context heterogeneity, which indicates the number of kinds of words that adjoin SL words. (Rapp, 1999) proposed a method that uses cooccurrence vectors based on the two words that 3The Ainu language is spoken by some members of the Ainu ethnic group of northern Japan and Sakhalin. Ainu language is independent from, but similar to, Japanese and Korean. 88 adjoin SL words on the right side and left side. Moreover, (Fung, 1998; Kaji and Aizono, 1996) proposed methods that uses co-occurrence vectors based on all words that exist in the existing bilingual dictionary, among sentences. (Tanaka and Iwasaki, 1996) presented a translation matrix that provides co-occurring information translated from the source into the target, and obtains bilingual word pairs by determining the best translation matrix. Ultimately, these methods depend on the existing bilingual dictionary. Therefore, it is difficult to extract bilingual word pairs from parallel corpora with various languages when a sufficient bilingual dictionary does not exist. In contrast, the </context>
</contexts>
<marker>Kaji, Aizono, 1996</marker>
<rawString>Kaji, H. and Aizono, T. 1996. Extracting Word Correspondences from Bilingual Corpora Based on Word Co-occurrence Information. In Proc. Coling &apos;96, pp.23-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Tanaka</author>
<author>H Iwasaki</author>
</authors>
<title>Extraction of Lexical Translation from Non-Aligned Corpora.</title>
<date>1996</date>
<booktitle>In Proc. Coling &apos;96,</booktitle>
<pages>580--585</pages>
<contexts>
<context position="6947" citStr="Tanaka and Iwasaki, 1996" startWordPosition="1124" endWordPosition="1127">lly examines context heterogeneity, which indicates the number of kinds of words that adjoin SL words. (Rapp, 1999) proposed a method that uses cooccurrence vectors based on the two words that 3The Ainu language is spoken by some members of the Ainu ethnic group of northern Japan and Sakhalin. Ainu language is independent from, but similar to, Japanese and Korean. 88 adjoin SL words on the right side and left side. Moreover, (Fung, 1998; Kaji and Aizono, 1996) proposed methods that uses co-occurrence vectors based on all words that exist in the existing bilingual dictionary, among sentences. (Tanaka and Iwasaki, 1996) presented a translation matrix that provides co-occurring information translated from the source into the target, and obtains bilingual word pairs by determining the best translation matrix. Ultimately, these methods depend on the existing bilingual dictionary. Therefore, it is difficult to extract bilingual word pairs from parallel corpora with various languages when a sufficient bilingual dictionary does not exist. In contrast, the system using ICL automatically can extract bilingual word pairs without an existing bilingual dictionary as a bilingual resource. Regarding methods for acquisiti</context>
</contexts>
<marker>Tanaka, Iwasaki, 1996</marker>
<rawString>Tanaka, K. and Iwasaki, H. 1996. Extraction of Lexical Translation from Non-Aligned Corpora. In Proc. Coling &apos;96, pp.580-585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K McTait</author>
</authors>
<title>Linguistic knowledge and complexity in an EBMT system based on translation patterns.</title>
<date>1997</date>
<booktitle>In Proceedings Workshop on EBMT, MT Summit VIII.</booktitle>
<contexts>
<context position="7586" citStr="McTait, 1997" startWordPosition="1219" endWordPosition="1220">trix that provides co-occurring information translated from the source into the target, and obtains bilingual word pairs by determining the best translation matrix. Ultimately, these methods depend on the existing bilingual dictionary. Therefore, it is difficult to extract bilingual word pairs from parallel corpora with various languages when a sufficient bilingual dictionary does not exist. In contrast, the system using ICL automatically can extract bilingual word pairs without an existing bilingual dictionary as a bilingual resource. Regarding methods for acquisition translation templates, (McTait, 1997; Giivenir and Cicekli, 1998) proposed methods that acquires bilingual templates using common parts and different parts. However, such methods require many similar bilingual sentence pairs to extract sufficient translation templates. Moreover, K-vec (Fung and Church, 1994) is unable to extract low-frequency bilingual word pairs. The algorithm is applicable only to bilingual word pairs that occur with a frequency greater than three. In addition, statistical word-alignment methods (Brown et al., 1993; Melamed, 2000; Och and Ney, 2003; Niei3en and Ney, 2004) have been proposed, but they are also </context>
</contexts>
<marker>McTait, 1997</marker>
<rawString>McTait, K. 1997. Linguistic knowledge and complexity in an EBMT system based on translation patterns. In Proceedings Workshop on EBMT, MT Summit VIII.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H A Giivenir</author>
<author>I Cicekli</author>
</authors>
<title>Learning translation templates from examples.</title>
<date>1998</date>
<journal>Information Systems,</journal>
<volume>23</volume>
<pages>353--363</pages>
<contexts>
<context position="7615" citStr="Giivenir and Cicekli, 1998" startWordPosition="1221" endWordPosition="1224">ides co-occurring information translated from the source into the target, and obtains bilingual word pairs by determining the best translation matrix. Ultimately, these methods depend on the existing bilingual dictionary. Therefore, it is difficult to extract bilingual word pairs from parallel corpora with various languages when a sufficient bilingual dictionary does not exist. In contrast, the system using ICL automatically can extract bilingual word pairs without an existing bilingual dictionary as a bilingual resource. Regarding methods for acquisition translation templates, (McTait, 1997; Giivenir and Cicekli, 1998) proposed methods that acquires bilingual templates using common parts and different parts. However, such methods require many similar bilingual sentence pairs to extract sufficient translation templates. Moreover, K-vec (Fung and Church, 1994) is unable to extract low-frequency bilingual word pairs. The algorithm is applicable only to bilingual word pairs that occur with a frequency greater than three. In addition, statistical word-alignment methods (Brown et al., 1993; Melamed, 2000; Och and Ney, 2003; Niei3en and Ney, 2004) have been proposed, but they are also insufficient. That is, the st</context>
</contexts>
<marker>Giivenir, Cicekli, 1998</marker>
<rawString>Giivenir, H. A. and Cicekli, I. 1998. Learning translation templates from examples. Information Systems, vol. 23, no.6, pp.353-363.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fung</author>
<author>K Church</author>
</authors>
<title>K-vec: A new approach for alignment parallel texts.</title>
<date>1994</date>
<booktitle>In Proc. Colpp.1096-1102.</booktitle>
<contexts>
<context position="7859" citStr="Fung and Church, 1994" startWordPosition="1256" endWordPosition="1259">to extract bilingual word pairs from parallel corpora with various languages when a sufficient bilingual dictionary does not exist. In contrast, the system using ICL automatically can extract bilingual word pairs without an existing bilingual dictionary as a bilingual resource. Regarding methods for acquisition translation templates, (McTait, 1997; Giivenir and Cicekli, 1998) proposed methods that acquires bilingual templates using common parts and different parts. However, such methods require many similar bilingual sentence pairs to extract sufficient translation templates. Moreover, K-vec (Fung and Church, 1994) is unable to extract low-frequency bilingual word pairs. The algorithm is applicable only to bilingual word pairs that occur with a frequency greater than three. In addition, statistical word-alignment methods (Brown et al., 1993; Melamed, 2000; Och and Ney, 2003; Niei3en and Ney, 2004) have been proposed, but they are also insufficient. That is, the statistical word-alignment methods cannot extract bilingual word pairs efficiently when the frequencies of many bilingual word pairs are low. (Watanabe and Sumita, 2003) proposed a method by which the decoder uses some translation examples whose </context>
</contexts>
<marker>Fung, Church, 1994</marker>
<rawString>Fung, P. and Church, K. 1994. K-vec: A new approach for alignment parallel texts. In Proc. Colpp.1096-1102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>Della Pietra</author>
<author>S A</author>
<author>Della Pietra</author>
<author>V J</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational linguistics,</journal>
<volume>19</volume>
<pages>263--311</pages>
<contexts>
<context position="8089" citStr="Brown et al., 1993" startWordPosition="1292" endWordPosition="1295">ilingual dictionary as a bilingual resource. Regarding methods for acquisition translation templates, (McTait, 1997; Giivenir and Cicekli, 1998) proposed methods that acquires bilingual templates using common parts and different parts. However, such methods require many similar bilingual sentence pairs to extract sufficient translation templates. Moreover, K-vec (Fung and Church, 1994) is unable to extract low-frequency bilingual word pairs. The algorithm is applicable only to bilingual word pairs that occur with a frequency greater than three. In addition, statistical word-alignment methods (Brown et al., 1993; Melamed, 2000; Och and Ney, 2003; Niei3en and Ney, 2004) have been proposed, but they are also insufficient. That is, the statistical word-alignment methods cannot extract bilingual word pairs efficiently when the frequencies of many bilingual word pairs are low. (Watanabe and Sumita, 2003) proposed a method by which the decoder uses some translation examples whose source part is similar to the input. However, numerous translation examples are necessary as a bilingual resource. That is, it is difficult to deal with languages for which translation examples are not sufficiently obtainable. In </context>
</contexts>
<marker>Brown, Pietra, A, Pietra, J, Mercer, 1993</marker>
<rawString>Brown, P. F., Della Pietra, S. A., Della Pietra, V. J., and Mercer, R. L. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational linguistics, vol.19, no.2, pp.263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I D Melamed</author>
</authors>
<title>Models of translation equivalence among words.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<pages>221--249</pages>
<contexts>
<context position="8104" citStr="Melamed, 2000" startWordPosition="1296" endWordPosition="1297">as a bilingual resource. Regarding methods for acquisition translation templates, (McTait, 1997; Giivenir and Cicekli, 1998) proposed methods that acquires bilingual templates using common parts and different parts. However, such methods require many similar bilingual sentence pairs to extract sufficient translation templates. Moreover, K-vec (Fung and Church, 1994) is unable to extract low-frequency bilingual word pairs. The algorithm is applicable only to bilingual word pairs that occur with a frequency greater than three. In addition, statistical word-alignment methods (Brown et al., 1993; Melamed, 2000; Och and Ney, 2003; Niei3en and Ney, 2004) have been proposed, but they are also insufficient. That is, the statistical word-alignment methods cannot extract bilingual word pairs efficiently when the frequencies of many bilingual word pairs are low. (Watanabe and Sumita, 2003) proposed a method by which the decoder uses some translation examples whose source part is similar to the input. However, numerous translation examples are necessary as a bilingual resource. That is, it is difficult to deal with languages for which translation examples are not sufficiently obtainable. In contrast, ICL c</context>
</contexts>
<marker>Melamed, 2000</marker>
<rawString>Melamed, I. D. 2000. Models of translation equivalence among words. Computational Linguistics, vol.26, no.2, pp.221-249.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<pages>19--51</pages>
<contexts>
<context position="8123" citStr="Och and Ney, 2003" startWordPosition="1298" endWordPosition="1301">resource. Regarding methods for acquisition translation templates, (McTait, 1997; Giivenir and Cicekli, 1998) proposed methods that acquires bilingual templates using common parts and different parts. However, such methods require many similar bilingual sentence pairs to extract sufficient translation templates. Moreover, K-vec (Fung and Church, 1994) is unable to extract low-frequency bilingual word pairs. The algorithm is applicable only to bilingual word pairs that occur with a frequency greater than three. In addition, statistical word-alignment methods (Brown et al., 1993; Melamed, 2000; Och and Ney, 2003; Niei3en and Ney, 2004) have been proposed, but they are also insufficient. That is, the statistical word-alignment methods cannot extract bilingual word pairs efficiently when the frequencies of many bilingual word pairs are low. (Watanabe and Sumita, 2003) proposed a method by which the decoder uses some translation examples whose source part is similar to the input. However, numerous translation examples are necessary as a bilingual resource. That is, it is difficult to deal with languages for which translation examples are not sufficiently obtainable. In contrast, ICL can extract bilingua</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Och, F. J. and Ney, H. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, vol.29, no.1, pp.19-51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Nie3en</author>
<author>H Ney</author>
</authors>
<title>Statistical machine translation with scarce resources using morphosyntactic information.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<pages>181--204</pages>
<marker>Nie3en, Ney, 2004</marker>
<rawString>Nie/3en, S. and Ney, H. 2004. Statistical machine translation with scarce resources using morphosyntactic information. Computational Linguistics, vol.30, no.2, pp.181-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Watanabe</author>
<author>E Sumita</author>
</authors>
<title>Example-based decoding for statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of MT summit IX,</booktitle>
<pages>410--417</pages>
<contexts>
<context position="8382" citStr="Watanabe and Sumita, 2003" startWordPosition="1337" endWordPosition="1340">ual sentence pairs to extract sufficient translation templates. Moreover, K-vec (Fung and Church, 1994) is unable to extract low-frequency bilingual word pairs. The algorithm is applicable only to bilingual word pairs that occur with a frequency greater than three. In addition, statistical word-alignment methods (Brown et al., 1993; Melamed, 2000; Och and Ney, 2003; Niei3en and Ney, 2004) have been proposed, but they are also insufficient. That is, the statistical word-alignment methods cannot extract bilingual word pairs efficiently when the frequencies of many bilingual word pairs are low. (Watanabe and Sumita, 2003) proposed a method by which the decoder uses some translation examples whose source part is similar to the input. However, numerous translation examples are necessary as a bilingual resource. That is, it is difficult to deal with languages for which translation examples are not sufficiently obtainable. In contrast, ICL can extract bilingual rules and bilingual word pairs efficiently, even from a small parallel corpus. 2 Outline Figure 1 shows an outline of a system using ICL. The ICL corresponds to three processes: a method based on bilingual rules, a method based on two bilingual sentence pai</context>
</contexts>
<marker>Watanabe, Sumita, 2003</marker>
<rawString>Watanabe, Y. and Sumita, E. 2003. Example-based decoding for statistical machine translation. In Proceedings of MT summit IX, pp.410-417.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Harukawa</author>
<author>J Snelling</author>
</authors>
<date>1998</date>
<note>Express: English. Hakusui-sha (in Japanese).</note>
<contexts>
<context position="25629" citStr="Harukawa and Snelling, 1998" startWordPosition="4365" endWordPosition="4368">the similarity values are not greater than the threshold value or when no bilingual word pairs are extracted. Moreover, the system chooses the bilingual word pairs that appear in the parallel corpus at the first time when several candidates of bilingual word pairs are obtained. 4 Performance Evaluation 4.1 Experimental Procedure and Evaluation Standard Five kinds of parallel corpora were used in this paper as experimental data. These parallel corpora are for English - Japanese, French - Japanese, German - Japanese, ShanghaiChinese - Japanese and Ainu - Japanese. They were taken from textbooks(Harukawa and Snelling, 1998; Chikushi, 2001; Oshio, 2004; Emoto and Han, 2004; Nakagawa and Nakamoto, 2004). The number of bilingual sentence pairs was 1,794; the average numbers of words in SL and TL sentences were 6.8 and 8.8, respectively. We inputted all 1,081 SL words of nouns, verbs, adjectives, adverbs, and conjunctions in five parallel corpora to six systems: a system based on the Dice coefficient; a system based on the Dice coefficient in which AIL is applied (herein, we call it the system based on Dice+ICL); a system based on Yates&apos; X2; a system based on Yates&apos; X2 in which ICL is applied (herein, the system ba</context>
</contexts>
<marker>Harukawa, Snelling, 1998</marker>
<rawString>Harukawa, Y. and Snelling, J. 1998. Express: English. Hakusui-sha (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Chikushi</author>
</authors>
<date>2001</date>
<note>Express: French. Hakusui-sha (in Japanese).</note>
<contexts>
<context position="25645" citStr="Chikushi, 2001" startWordPosition="4369" endWordPosition="4370"> greater than the threshold value or when no bilingual word pairs are extracted. Moreover, the system chooses the bilingual word pairs that appear in the parallel corpus at the first time when several candidates of bilingual word pairs are obtained. 4 Performance Evaluation 4.1 Experimental Procedure and Evaluation Standard Five kinds of parallel corpora were used in this paper as experimental data. These parallel corpora are for English - Japanese, French - Japanese, German - Japanese, ShanghaiChinese - Japanese and Ainu - Japanese. They were taken from textbooks(Harukawa and Snelling, 1998; Chikushi, 2001; Oshio, 2004; Emoto and Han, 2004; Nakagawa and Nakamoto, 2004). The number of bilingual sentence pairs was 1,794; the average numbers of words in SL and TL sentences were 6.8 and 8.8, respectively. We inputted all 1,081 SL words of nouns, verbs, adjectives, adverbs, and conjunctions in five parallel corpora to six systems: a system based on the Dice coefficient; a system based on the Dice coefficient in which AIL is applied (herein, we call it the system based on Dice+ICL); a system based on Yates&apos; X2; a system based on Yates&apos; X2 in which ICL is applied (herein, the system based on Yates+ICL</context>
</contexts>
<marker>Chikushi, 2001</marker>
<rawString>Chikushi, F. 2001. Express: French. Hakusui-sha (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Oshio</author>
</authors>
<date>2004</date>
<note>Express: German. Hakusui-sha (in Japanese).</note>
<contexts>
<context position="25658" citStr="Oshio, 2004" startWordPosition="4371" endWordPosition="4372">e threshold value or when no bilingual word pairs are extracted. Moreover, the system chooses the bilingual word pairs that appear in the parallel corpus at the first time when several candidates of bilingual word pairs are obtained. 4 Performance Evaluation 4.1 Experimental Procedure and Evaluation Standard Five kinds of parallel corpora were used in this paper as experimental data. These parallel corpora are for English - Japanese, French - Japanese, German - Japanese, ShanghaiChinese - Japanese and Ainu - Japanese. They were taken from textbooks(Harukawa and Snelling, 1998; Chikushi, 2001; Oshio, 2004; Emoto and Han, 2004; Nakagawa and Nakamoto, 2004). The number of bilingual sentence pairs was 1,794; the average numbers of words in SL and TL sentences were 6.8 and 8.8, respectively. We inputted all 1,081 SL words of nouns, verbs, adjectives, adverbs, and conjunctions in five parallel corpora to six systems: a system based on the Dice coefficient; a system based on the Dice coefficient in which AIL is applied (herein, we call it the system based on Dice+ICL); a system based on Yates&apos; X2; a system based on Yates&apos; X2 in which ICL is applied (herein, the system based on Yates+ICL); a system b</context>
</contexts>
<marker>Oshio, 2004</marker>
<rawString>Oshio, T. 2004. Express: German. Hakusui-sha (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Emoto</author>
<author>G Han</author>
</authors>
<title>Express: Shanghai. Hakusui-sha</title>
<date>2004</date>
<note>(in Japanese).</note>
<contexts>
<context position="25679" citStr="Emoto and Han, 2004" startWordPosition="4373" endWordPosition="4376">alue or when no bilingual word pairs are extracted. Moreover, the system chooses the bilingual word pairs that appear in the parallel corpus at the first time when several candidates of bilingual word pairs are obtained. 4 Performance Evaluation 4.1 Experimental Procedure and Evaluation Standard Five kinds of parallel corpora were used in this paper as experimental data. These parallel corpora are for English - Japanese, French - Japanese, German - Japanese, ShanghaiChinese - Japanese and Ainu - Japanese. They were taken from textbooks(Harukawa and Snelling, 1998; Chikushi, 2001; Oshio, 2004; Emoto and Han, 2004; Nakagawa and Nakamoto, 2004). The number of bilingual sentence pairs was 1,794; the average numbers of words in SL and TL sentences were 6.8 and 8.8, respectively. We inputted all 1,081 SL words of nouns, verbs, adjectives, adverbs, and conjunctions in five parallel corpora to six systems: a system based on the Dice coefficient; a system based on the Dice coefficient in which AIL is applied (herein, we call it the system based on Dice+ICL); a system based on Yates&apos; X2; a system based on Yates&apos; X2 in which ICL is applied (herein, the system based on Yates+ICL); a system based on AIC; and a sy</context>
</contexts>
<marker>Emoto, Han, 2004</marker>
<rawString>Emoto, H. and Han, G. 2004. Express: Shanghai. Hakusui-sha (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Nakagawa</author>
<author>M Nakamoto</author>
</authors>
<date>2004</date>
<note>Express: Ainu. Hakusui-sha (in Japanese).</note>
<contexts>
<context position="25709" citStr="Nakagawa and Nakamoto, 2004" startWordPosition="4377" endWordPosition="4380">gual word pairs are extracted. Moreover, the system chooses the bilingual word pairs that appear in the parallel corpus at the first time when several candidates of bilingual word pairs are obtained. 4 Performance Evaluation 4.1 Experimental Procedure and Evaluation Standard Five kinds of parallel corpora were used in this paper as experimental data. These parallel corpora are for English - Japanese, French - Japanese, German - Japanese, ShanghaiChinese - Japanese and Ainu - Japanese. They were taken from textbooks(Harukawa and Snelling, 1998; Chikushi, 2001; Oshio, 2004; Emoto and Han, 2004; Nakagawa and Nakamoto, 2004). The number of bilingual sentence pairs was 1,794; the average numbers of words in SL and TL sentences were 6.8 and 8.8, respectively. We inputted all 1,081 SL words of nouns, verbs, adjectives, adverbs, and conjunctions in five parallel corpora to six systems: a system based on the Dice coefficient; a system based on the Dice coefficient in which AIL is applied (herein, we call it the system based on Dice+ICL); a system based on Yates&apos; X2; a system based on Yates&apos; X2 in which ICL is applied (herein, the system based on Yates+ICL); a system based on AIC; and a system based on AIC in which ICL</context>
</contexts>
<marker>Nakagawa, Nakamoto, 2004</marker>
<rawString>Nakagawa, H. and Nakamoto, M. 2004. Express: Ainu. Hakusui-sha (in Japanese).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>