<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000299">
<title confidence="0.996669">
Active Learning for Post-Editing Based Incrementally Retrained MT
</title>
<author confidence="0.98026">
Aswarth Dara Josef van Genabith Qun Liu John Judge Antonio Toral
</author>
<affiliation confidence="0.9884035">
School of Computing
Dublin City University
</affiliation>
<address confidence="0.664528">
Dublin, Ireland
</address>
<email confidence="0.995397">
{adara,josef,qliu,jjudge,atoral}@computing.dcu.ie
</email>
<sectionHeader confidence="0.99735" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999576793103448">
Machine translation, in particular statis-
tical machine translation (SMT), is mak-
ing big inroads into the localisation and
translation industry. In typical work-
flows (S)MT output is checked and (where
required) manually post-edited by hu-
man translators. Recently, a significant
amount of research has concentrated on
capturing human post-editing outputs as
early as possible to incrementally up-
date/modify SMT models to avoid repeat
mistakes. Typically in these approaches,
MT and post-edits happen sequentially
and chronologically, following the way
unseen data (the translation job) is pre-
sented. In this paper, we add to the ex-
isting literature addressing the question
whether and if so, to what extent, this
process can be improved upon by Active
Learning, where input is not presented
chronologically but dynamically selected
according to criteria that maximise perfor-
mance with respect to (whatever is) the re-
maining data. We explore novel (source
side-only) selection criteria and show per-
formance increases of 0.67-2.65 points
TER absolute on average on typical indus-
try data sets compared to sequential PE-
based incrementally retrained SMT.
</bodyText>
<sectionHeader confidence="0.994066" genericHeader="keywords">
1 Introduction and Related Research
</sectionHeader>
<bodyText confidence="0.999852842105263">
Machine Translation (MT) has evolved dramati-
cally over the last two decades, especially since
the appearance of statistical approaches (Brown et
al., 1993). In fact, MT is nowadays succesfully
used in the localisation and translation industry,
as for many relevant domains such as technical
documentation, post-editing (PE) of MT output by
human translators (compared to human translation
from scratch) results in notable productivity gains,
as a number of industry studies have shown con-
vincingly, e.g. (Plitt and Masselot, 2010). Fur-
thermore, incremental retraining and update tech-
niques (Bertoldi et al., 2013; Levenberg et al.,
2010; Mathur et al., 2013; Simard and Foster,
2013) allow these PEs to be fed back into the MT
model, resulting in an MT system that is contin-
uously updated to perform better on forthcoming
sentences, which should lead to a further increase
in productivity.
Typically, post-editors are presented with MT
output units (sentences) in the order in which input
sentences appear one after the other in the trans-
lation job. Because of this, incremental MT re-
training and update models based on PE outputs
also proceed in the same chronological order de-
termined by the input data. This may be sub-
optimal. In this paper we study the application of
Active Learning (AL) to the scenario of PE MT
and subsequent PE-based incremental retraining.
AL selects data (here translation inputs and their
MT outputs for PE) according to criteria that max-
imise performance with respect to the remaining
data and may diverge from processing data items
in chronological order. This may allow incremen-
tally PE-based retrained MT to (i) improve more
rapidly than chronologically PE-based retrained
MT and (ii) result in overall productivity gains.
The main contributions of this paper include:
</bodyText>
<listItem confidence="0.995590529411765">
• Previous work (Haffari et al., 2009; Blood-
good and Callison-Burch, 2010) shows that,
given a (static) training set, AL can im-
prove the quality of MT. By contrast, here
we show that AL-based data selection for hu-
man PE improves incrementally and dynami-
cally retrained MT, reducing overall PE time
of translation jobs in the localisation industry
application scenarios.
• We propose novel selection criteria for AL-
based PE: we adapt cross-entropy difference
(Moore and Lewis, 2010; Axelrod et al.,
2011), originally used for domain adaptation,
and propose an extension to cross entropy
difference with a vocabulary saturation filter
(Lewis and Eetemadi, 2013).
• While much of previous work concentrates
</listItem>
<bodyText confidence="0.5971045">
on research datasets (e.g. Europarl, News
Commentary), we use industry data (techni-
</bodyText>
<page confidence="0.983898">
185
</page>
<note confidence="0.6926925">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 185–189,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.9778648">
cal manuals). (Bertoldi et al., 2013) shows
that the repetition rate of news is consider-
ably lower than that of technical documenta-
tion, which impacts on the results obtained
with incremental retraining.
</bodyText>
<listItem confidence="0.998232142857143">
• Unlike in previous research, our AL-based
selection criteria take into account only the
source side of the data. This supports se-
lection before translation, keeping costs to a
minimum, a priority in commercial PE MT
applications.
• Our experiments show that AL-based selec-
</listItem>
<bodyText confidence="0.9524934">
tion works for PE-based incrementally re-
trained MT with overall performance gains
around 0.67 to 2.65 TER absolute on average.
AL has been successfully applied to many tasks
in natural language processing, including pars-
ing (Tang et al., 2002), named entity recogni-
tion (Miller et al., 2004), to mention just a few. See
(Olsson, 2009) for a comprehensie overview of
the application of AL to natural language process-
ing. (Haffari et al., 2009; Bloodgood and Callison-
Burch, 2010) apply AL to MT where the aim is to
build an optimal MT model from a given, static
dataset. To the best of our knowledge, the most
relevant previous research is (Gonz´alez-Rubio et
al., 2012), which applies AL to interactive MT. In
addition to differences in the AL selection criteria
and data sets, our goals are fundamentally differ-
ent: while the previous work aimed at reducing
human effort in interactive MT, we aim at reduc-
ing the overall PE time in PE-based incremental
MT update applications in the localisation indus-
try.
In our experiments reported in Section 3 below
we want to explore a space consisting of a con-
siderable number of selection strategies and incre-
mental retraining batch sizes. In order to be able to
do this, we use the target side of our industry trans-
lation memory data to approximate human PE out-
put and automatic TER (Snover et al., 2006) scores
as a proxy for human PE times (O’Brien, 2011).
</bodyText>
<sectionHeader confidence="0.994816" genericHeader="introduction">
2 Methodology
</sectionHeader>
<bodyText confidence="0.895251615384615">
Given a translation job, our goal is to reduce the
overall PE time. At each stage, we select sen-
tences that are given to the post editor in such a
way that uncertain sentences (with respect to the
MT system at hand)1 are post-edited first. We then
translate the n top-ranked sentences using the MT
system and use the human PEs of the MT outputs
to retrain the system. Algorithm 1 describes our
1The uncertainty of a sentence with respect to the model
can be measured according to different criteria, e.g. percent-
age of unknown n-grams, perplexity etc.
method, where s and t stand for source and target,
respectively.
</bodyText>
<figure confidence="0.589508">
Algorithm 1 Sentence Selection Algorithm
Input:
L ←− Initial training data
M ←− Initial MT model
for C ∈ (Random,Sequential,Ngram,CED,CEDN) do
</figure>
<equation confidence="0.975253375">
U ←− Translation job
while size(U) &gt; 0 do
U1.s ←− SelectTopSentences(C, U.s)
U11.t ←− Translate(M, U1.s)
U1.t ←− PostEdit(U11.t)
U ←− U - U1
L ←− L ∪ U1
M ←− TrainModel (L)
</equation>
<subsectionHeader confidence="0.8189515">
end while
end for
</subsectionHeader>
<bodyText confidence="0.999865285714286">
We use two baselines, i.e. random and sequen-
tial. In the random baseline, the batch of sentences
at each iteration are selected randomly. In the se-
quential baseline, the batches of sentences follow
the same order as the data.
Aside from the Random and Sequential base-
lines we use the following selection criteria:
</bodyText>
<listItem confidence="0.993355214285714">
• N-gram Overlap. An SMT system will en-
counter problems translating sentences con-
taining n-grams not seen in the training data.
Thus, PEs of sentences with high number of
unseen n-grams are considered to be more in-
formative for updating the current MT sys-
tem. However, for the MT system to trans-
late unseen n-grams accurately, they need to
be seen a minimum number V times.2 We
use an n-gram overlap function similar to
the one described in (Gonz´alez-Rubio et al.,
2012) given in Equation 1 where N(T(i)) and
N(S(i)) return i-grams in training data and
the sentence S, respectively.
</listItem>
<equation confidence="0.98408425">
n
unseen(S) = i=1 {|N(T (i)) ∩ N(S(i))|&gt;V }
N(S(i))
(1)
</equation>
<listItem confidence="0.979140142857143">
• Cross Entropy Difference (CED). This met-
ric is originally used in data selection (Moore
and Lewis, 2010; Axelrod et al., 2011).
Given an in-domain corpus I and a general
corpus O, language models are built from
both,3 and each sentence in O is scored ac-
cording to the entropy H difference (Equation
</listItem>
<footnote confidence="0.935111166666667">
2Following (Gonz´alez-Rubio et al., 2012) we use V =
10.
3In order to make the LMs comparable they have the same
size. As commonly the size of O is considerable bigger than
I, this means that the LM for O is built from a subset of the
same size as I.
</footnote>
<equation confidence="0.912574">
n
i=1
</equation>
<page confidence="0.97614">
186
</page>
<bodyText confidence="0.999541666666667">
2). The lower the score given to a sentence,
the more useful it is to train a system for the
specific domain I.
</bodyText>
<equation confidence="0.999576">
score(s) = HI(s) − HO(s) (2)
</equation>
<bodyText confidence="0.999195545454545">
In our AL scenario, we have the current train-
ing corpus L and an untranslated corpus U.
CED is applied to select sentences from U
that are (i) different from L (as we would like
to add sentences that add new information to
the model) and (ii) similar to the overall cor-
pus U (as we would like to add sentences that
are common in the untranslated data). Hence
we apply CED and select sentences from U
that have high entropy with respect to L and
low entropy with respect to U (Equation 3).
</bodyText>
<equation confidence="0.997596">
score(s) = HU(s) − HL(s) (3)
</equation>
<listItem confidence="0.707421785714286">
• CED + n-gram (CEDN). This is an exten-
sion of the CED criterion inspired by the con-
cept of the vocabulary saturation filter (Lewis
and Eetemadi, 2013). CED may select many
very similar sentences, and thus it may be the
case that some of them are redundant. By
post-processing the selection made by CED
with vocabulary saturation we aim to spot
and remove redudant sentences. This works
in two steps. In the first step, all the sentences
from U are scored using the CED metric. In
the second step, we down-rank sentences that
are considered redundant. The top sentence is
selected, and its n-grams are stored in local-
</listItem>
<bodyText confidence="0.930413333333333">
ngrams. For the remaining sentences, one by
one, their n-grams are matched against local-
ngrams. If the intersection between them is
lower than a predefined threshold, the current
sentence is added and localngrams is updated
with the n-grams from the current sentence.
Otherwise the sentence is down-ranked to the
bottom. In our experiments, the value n = 1
produces best results.
</bodyText>
<sectionHeader confidence="0.998882" genericHeader="related work">
3 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999931551020408">
We use technical documentation data taken from
Symantec translation memories for the English–
French (EN–FR) and English–German (EN–DE)
language pairs (both directions) for our experi-
ments. The statistics of the data (training and in-
cremental splits) are shown in Table 1.
All the systems are trained using the
Moses (Koehn et al., 2007) phrase-based sta-
tistical MT system, with IRSTLM (Federico et
al., 2008) for language modelling (n-grams up
to order five) and with the alignment heuristic
grow-diag-final-and.
For the experiments, we considered two settings
for each language pair in each direction. In the
first setting, the initial MT system is trained using
the training set (39,679 and 54,907 sentence pairs
for EN–FR and EN–DE, respectively). Then, a
batch of 500 source sentences is selected from the
incremental dataset according to each of the se-
lection criteria, and translations are obtained with
the initial MT system. These translations are post-
edited and the corrected translations are added to
the training data.4 We then train a new MT sys-
tem using the updated training data (initial training
data plus PEs of the first batch of sentences). The
updated model will be used to translate the next
batch. The same process is repeated until the in-
cremental dataset is finished (16 and 20 iterations
for English–French and English–German, respec-
tively). For each batch we compute the TER score
between the MT output and the refererence trans-
lations for the sentences of that batch. We then
compute the average TER score for all the batches.
These average scores, for each selection criterion,
are reported in Table 2.
In the second setting, instead of using the whole
training data, we used a subset of (randomly se-
lected) 5,000 sentence pairs for training the initial
MT system and a subset of 20,000 sentences from
the remaining data as the incremental dataset.
Here we take batches of 1,000 sentences (thus 20
batches). The results are shown in Table 3.
The first setting aims to reflect the situation
where a translation job is to be completed for a do-
main for which we have a considerable amount of
data available. Conversely, the second setting re-
flects the situation where a translation job is to be
carried out for a domain with little (if any) avail-
able data.
</bodyText>
<table confidence="0.9997038">
Dir Random Seq. Ngram CED CEDN
EN-*FR 29.64 29.81 28.97 29.25 29.05
FR-*EN 27.08 27.04 26.15 26.63 26.39
EN-*DE 24.00 24.08 22.34 22.60 22.32
DE-*EN 19.36 19.34 17.70 17.97 17.48
</table>
<tableCaption confidence="0.972128">
Table 2: TER average scores for Setting 1
</tableCaption>
<table confidence="0.9999058">
Dir Random Seq. Ngram CED CEDN
EN-*FR 36.23 36.26 35.20 35.48 35.17
FR-*EN 33.26 33.34 32.26 32.69 32.17
EN-*DE 32.23 32.19 30.58 31.96 29.98
DE-*EN 27.24 27.29 26.10 26.73 24.94
</table>
<tableCaption confidence="0.99971">
Table 3: TER average scores for Setting 2
</tableCaption>
<bodyText confidence="0.990036333333333">
For Setting 1 (Table 2), the best result is ob-
tained by the CEDN criterion for two out of the
four directions. For EN→FR, n-gram overlap
</bodyText>
<footnote confidence="0.982763">
4As this study simulates the post-editing, we use the ref-
erences of the translated segments instead of the PEs.
</footnote>
<page confidence="0.988597">
187
</page>
<table confidence="0.99844525">
Type EN–FR EN–DE
Sentences Avg. EN SL Avg. FR SL Sentences Avg. EN SL Avg. DE SL
Training 39,679 13.55 15.28 54,907 12.66 12.90
Incremental 8,000 13.74 15.50 10,000 12.38 12.61
</table>
<tableCaption confidence="0.9957345">
Table 1: Data Statistics for English–French and English–German Symantec Translation Memory Data.
SL stands for sentence length, EN stands for English, FR stands for French and DE stands for German
</tableCaption>
<bodyText confidence="0.999893066666667">
performs slightly better than CEDN (0.08 points
lower) with a decrease of 0.67 and 0.84 points
when compared to the baselines (random and se-
quential, respectively). For FR→EN, n-gram
overlap results in a decrease of 0.93 and 0.89
points compared to the baselines. The decrease in
average TER score is higher for the EN→DE and
for DE→EN directions, i.e. 1.68 and 1.88 points
respectively for CEDN compared to the random
baseline.
In the scenario with limited data available be-
forehand (Table 3), CEDN is the best performing
criterion for all the language directions. For the
EN–FR and FR–EN language pairs, CEDN results
in a decrease of 1.06 and 1.09 points compared to
the random baseline. Again, the decrease is higher
for the EN–DE and DE–EN language pairs, i.e.
2.25 and 2.30 absolute points on average.
Figure 1 shows the TER scores per iteration for
each of the criteria, for the scenario DE→EN Set-
ting 2 (the trends are similar for the other scenar-
ios). The two baselines exhibit slight improve-
ment over the iterations, both starting at around
.35 TER points and finishing at around .25 points.
Conversely, all the three criteria start at very high
scores (in the range [.5,.6]) and then improve con-
siderably to arrive at scores below .1 for the last
iterations. Compared to Ngram and CED, CEDN
reaches better scores earlier on, being the criterion
with the lowest score up to iteration 13.
</bodyText>
<figure confidence="0.846237">
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
Iteration
</figure>
<figureCaption confidence="0.999808">
Figure 1: Results per iteration, DE→EN Setting 2
</figureCaption>
<bodyText confidence="0.9759673">
Figure 1 together with Tables 2 and 3 show
that AL for PE-based incremental MT retrain-
ing really works: all AL based methods (Ngram,
CED, CEDN) show strong improvements over
both baselines after the initial 8-9 iterations (Fig-
ure 1) and best performance on the complete incre-
mental data sets, resulting in a noticeable decrease
of the overall TER score (Tables 2 and 3). In six
out of eight scenarios, our novel metric CEDN ob-
tains the best result.
</bodyText>
<sectionHeader confidence="0.993694" genericHeader="conclusions">
4 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999977525">
This paper has presented an application of AL to
MT for dynamically selecting automatic transla-
tions of sentences for human PE, with the aim of
reducing overall PE time in a PE-based incremen-
tal MT retraining scenario in a typical industrial
localisation workflow that aims to capitalise on
human PE as early as possible to avoid repeat mis-
takes.
Our approach makes use of source side informa-
tion only, uses two novel selection criteria based
on cross entropy difference and is tested on indus-
trial data for two language pairs. Our best per-
forming criteria allow the incrementally retrained
MT systems to improve their performance earlier
and reduce the overall TER score by around one
and two absolute points for English–French and
English–German, respectively.
In order to be able to explore a space of selec-
tion criteria and batch sizes, our experiments sim-
ulate PE, in the sense that we use the target ref-
erence (instead of PEs) and approximate PE time
with TER. Given that TER correlates well with PE
time (O’Brien, 2011), we expect AL-based selec-
tion of sentences for human PE to lead to overall
reduction of PE time. In the future work, we plan
to do the experiments using PEs to retrain the sys-
tem and measuring PE time.
In this work, we have taken batches of sentences
(size 500 to 1,000) and do full retraining. As fu-
ture work, we plan to use fully incremental retrain-
ing and perform the selection on a sentence-by-
sentence basis (instead of taking batches).
Finally and importantly, a potential drawback of
our approach is that by dynamically selecting in-
dividual sentences for PE, the human post-editor
looses context, which they may use if processing
sentences sequentially. We will explore the trade
off between the context lost and the productivity
gain achieved, and ways of supplying context (e.g.
previous and following sentence) for real PE.
</bodyText>
<figure confidence="0.998283928571428">
TER score
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
Random
Seq
Ngram
CED
CEDN
</figure>
<page confidence="0.98509">
188
</page>
<sectionHeader confidence="0.998332" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999505">
This work is supported by Science Foundation
Ireland (Grants 12/TIDA/I2438, 07/CE/I1142 and
12/CE/I2267) as part of the Centre for Next Gen-
eration Localisation (www.cngl.ie) at Dublin City
University. We would like to thank Symantec for
the provision of data sets used in our experiments.
</bodyText>
<sectionHeader confidence="0.998954" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999876912621359">
Amittai Axelrod, Xiaodong He, and Jianfeng Gao.
2011. Domain adaptation via pseudo in-domain
data selection. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing, EMNLP ’11, pages 355–362, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Nicola Bertoldi, Mauro Cettolo, and Marcello Fed-
erico. 2013. Cache-based online adaptation for ma-
chine translation enhanced computer assisted trans-
lation. In Proceedings of the XIV Machine Transla-
tion Summit, pages 35–42, Nice, France.
Michael Bloodgood and Chris Callison-Burch. 2010.
Bucking the trend: Large-scale cost-focused active
learning for statistical machine translation. In Jan
Hajic, Sandra Carberry, and Stephen Clark, editors,
ACL, pages 854–864. The Association for Computer
Linguistics.
Peter F. Brown, Vincent J. Della Pietra, Stephen
A. Della Pietra, and Robert L. Mercer. 1993. The
mathematics of statistical machine translation: Pa-
rameter estimation. Comput. Linguist., 19(2):263–
311, June.
Marcello Federico, Nicola Bertoldi, and Mauro Cet-
tolo. 2008. IRSTLM: an open source toolkit for
handling large scale language models. In INTER-
SPEECH, pages 1618–1621. ISCA.
Jes´us Gonz´alez-Rubio, Daniel Ortiz-Martinez, and
Francisco Casacuberta. 2012. Active learning for
interactive machine translation. In Proceedings of
the 13th Conference of the European Chapter of the
Association for Computational Linguistics, EACL
’12, pages 245–254, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Gholamreza Haffari, Maxim Roy, and Anoop Sarkar.
2009. Active learning for statistical phrase-based
machine translation. In HLT-NAACL, pages 415–
423. The Association for Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
ACL 2007, pages 177–180, Prague, Czech Repub-
lic. Association for Computational Linguistics.
Abby Levenberg, Chris Callison-Burch, and Miles Os-
borne. 2010. Stream-based translation models
for statistical machine translation. In Human Lan-
guage Technologies: The 2010 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics, HLT ’10, pages 394–
402, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
William Lewis and Sauleh Eetemadi. 2013. Dramati-
cally reducing training data size through vocabulary
saturation. In Proceedings of the Eighth Workshop
on Statistical Machine Translation, pages 281–291,
Sofia, Bulgaria, August. Association for Computa-
tional Linguistics.
Prashant Mathur, Mauro Cettolo, and Marcello Fed-
erico. 2013. Online learning approaches in com-
puter assisted translation. In Proceedings of the
Eighth Workshop on Statistical Machine Transla-
tion, ACL, pages 301–308, Sofia, Bulgaria.
Scott Miller, Jethran Guinness, and Alex Zamanian.
2004. Name tagging with word clusters and dis-
criminative training. In Proceedings of HLT, pages
337–342.
Robert C. Moore and William Lewis. 2010. Intelli-
gent selection of language model training data. In
Proceedings of the ACL 2010 Conference Short Pa-
pers, ACLShort ’10, pages 220–224, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
Sharon O’Brien. 2011. Towards predicting
post-editing productivity. Machine Translation,
25(3):197–215, September.
Fredrik Olsson. 2009. A literature survey of active
machine learning in the context of natural language
processing. Technical Report T2009:06.
Mirko Plitt and Franc¸ois Masselot. 2010. A productiv-
ity test of statistical machine translation post-editing
in a typical localisation context. Prague Bull. Math.
Linguistics, 93:7–16.
Michel Simard and George Foster. 2013. Pepr: Post-
edit propagation using phrase-based statistical ma-
chine translation. In Proceedings of the XIV Ma-
chine Translation Summit, pages 191–198, Nice,
France.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A study of
translation edit rate with targeted human annotation.
In Proceedings of Association for Machine Trans-
lation in the Americas, pages 223–231, Cambridge,
MA.
Min Tang, Xiaoqiang Luo, and Salim Roukos. 2002.
Active learning for statistical natural language pars-
ing. In Proceedings of the 40th Annual Meeting
on Association for Computational Linguistics, ACL
’02, pages 120–127, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
</reference>
<page confidence="0.998929">
189
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.621025">
<title confidence="0.998012">Active Learning for Post-Editing Based Incrementally Retrained MT</title>
<author confidence="0.995469">Aswarth Dara Josef van_Genabith Qun Liu John Judge Antonio</author>
<affiliation confidence="0.997675">School of Dublin City</affiliation>
<address confidence="0.666506">Dublin,</address>
<abstract confidence="0.998020866666667">Machine translation, in particular statistical machine translation (SMT), is making big inroads into the localisation and translation industry. In typical workflows (S)MT output is checked and (where required) manually post-edited by human translators. Recently, a significant amount of research has concentrated on capturing human post-editing outputs as early as possible to incrementally update/modify SMT models to avoid repeat mistakes. Typically in these approaches, MT and post-edits happen sequentially and chronologically, following the way unseen data (the translation job) is presented. In this paper, we add to the existing literature addressing the question whether and if so, to what extent, this process can be improved upon by Active Learning, where input is not presented chronologically but dynamically selected according to criteria that maximise performance with respect to (whatever is) the remaining data. We explore novel (source side-only) selection criteria and show performance increases of 0.67-2.65 points TER absolute on average on typical industry data sets compared to sequential PEbased incrementally retrained SMT.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amittai Axelrod</author>
<author>Xiaodong He</author>
<author>Jianfeng Gao</author>
</authors>
<title>Domain adaptation via pseudo in-domain data selection.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>355--362</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="3737" citStr="Axelrod et al., 2011" startWordPosition="571" endWordPosition="574">ly PE-based retrained MT and (ii) result in overall productivity gains. The main contributions of this paper include: • Previous work (Haffari et al., 2009; Bloodgood and Callison-Burch, 2010) shows that, given a (static) training set, AL can improve the quality of MT. By contrast, here we show that AL-based data selection for human PE improves incrementally and dynamically retrained MT, reducing overall PE time of translation jobs in the localisation industry application scenarios. • We propose novel selection criteria for ALbased PE: we adapt cross-entropy difference (Moore and Lewis, 2010; Axelrod et al., 2011), originally used for domain adaptation, and propose an extension to cross entropy difference with a vocabulary saturation filter (Lewis and Eetemadi, 2013). • While much of previous work concentrates on research datasets (e.g. Europarl, News Commentary), we use industry data (techni185 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 185–189, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics cal manuals). (Bertoldi et al., 2013) shows that the repetition rate of news is considerably lower th</context>
<context position="8161" citStr="Axelrod et al., 2011" startWordPosition="1313" endWordPosition="1316">ces with high number of unseen n-grams are considered to be more informative for updating the current MT system. However, for the MT system to translate unseen n-grams accurately, they need to be seen a minimum number V times.2 We use an n-gram overlap function similar to the one described in (Gonz´alez-Rubio et al., 2012) given in Equation 1 where N(T(i)) and N(S(i)) return i-grams in training data and the sentence S, respectively. n unseen(S) = i=1 {|N(T (i)) ∩ N(S(i))|&gt;V } N(S(i)) (1) • Cross Entropy Difference (CED). This metric is originally used in data selection (Moore and Lewis, 2010; Axelrod et al., 2011). Given an in-domain corpus I and a general corpus O, language models are built from both,3 and each sentence in O is scored according to the entropy H difference (Equation 2Following (Gonz´alez-Rubio et al., 2012) we use V = 10. 3In order to make the LMs comparable they have the same size. As commonly the size of O is considerable bigger than I, this means that the LM for O is built from a subset of the same size as I. n i=1 186 2). The lower the score given to a sentence, the more useful it is to train a system for the specific domain I. score(s) = HI(s) − HO(s) (2) In our AL scenario, we ha</context>
</contexts>
<marker>Axelrod, He, Gao, 2011</marker>
<rawString>Amittai Axelrod, Xiaodong He, and Jianfeng Gao. 2011. Domain adaptation via pseudo in-domain data selection. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 355–362, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Bertoldi</author>
<author>Mauro Cettolo</author>
<author>Marcello Federico</author>
</authors>
<title>Cache-based online adaptation for machine translation enhanced computer assisted translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the XIV Machine Translation Summit,</booktitle>
<pages>35--42</pages>
<location>Nice, France.</location>
<contexts>
<context position="2045" citStr="Bertoldi et al., 2013" startWordPosition="294" endWordPosition="297">Research Machine Translation (MT) has evolved dramatically over the last two decades, especially since the appearance of statistical approaches (Brown et al., 1993). In fact, MT is nowadays succesfully used in the localisation and translation industry, as for many relevant domains such as technical documentation, post-editing (PE) of MT output by human translators (compared to human translation from scratch) results in notable productivity gains, as a number of industry studies have shown convincingly, e.g. (Plitt and Masselot, 2010). Furthermore, incremental retraining and update techniques (Bertoldi et al., 2013; Levenberg et al., 2010; Mathur et al., 2013; Simard and Foster, 2013) allow these PEs to be fed back into the MT model, resulting in an MT system that is continuously updated to perform better on forthcoming sentences, which should lead to a further increase in productivity. Typically, post-editors are presented with MT output units (sentences) in the order in which input sentences appear one after the other in the translation job. Because of this, incremental MT retraining and update models based on PE outputs also proceed in the same chronological order determined by the input data. This m</context>
<context position="4273" citStr="Bertoldi et al., 2013" startWordPosition="646" endWordPosition="649">ed PE: we adapt cross-entropy difference (Moore and Lewis, 2010; Axelrod et al., 2011), originally used for domain adaptation, and propose an extension to cross entropy difference with a vocabulary saturation filter (Lewis and Eetemadi, 2013). • While much of previous work concentrates on research datasets (e.g. Europarl, News Commentary), we use industry data (techni185 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 185–189, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics cal manuals). (Bertoldi et al., 2013) shows that the repetition rate of news is considerably lower than that of technical documentation, which impacts on the results obtained with incremental retraining. • Unlike in previous research, our AL-based selection criteria take into account only the source side of the data. This supports selection before translation, keeping costs to a minimum, a priority in commercial PE MT applications. • Our experiments show that AL-based selection works for PE-based incrementally retrained MT with overall performance gains around 0.67 to 2.65 TER absolute on average. AL has been successfully applied</context>
</contexts>
<marker>Bertoldi, Cettolo, Federico, 2013</marker>
<rawString>Nicola Bertoldi, Mauro Cettolo, and Marcello Federico. 2013. Cache-based online adaptation for machine translation enhanced computer assisted translation. In Proceedings of the XIV Machine Translation Summit, pages 35–42, Nice, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Bloodgood</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Bucking the trend: Large-scale cost-focused active learning for statistical machine translation.</title>
<date>2010</date>
<pages>854--864</pages>
<editor>In Jan Hajic, Sandra Carberry, and Stephen Clark, editors, ACL,</editor>
<publisher>The Association for Computer Linguistics.</publisher>
<contexts>
<context position="3308" citStr="Bloodgood and Callison-Burch, 2010" startWordPosition="500" endWordPosition="504">per we study the application of Active Learning (AL) to the scenario of PE MT and subsequent PE-based incremental retraining. AL selects data (here translation inputs and their MT outputs for PE) according to criteria that maximise performance with respect to the remaining data and may diverge from processing data items in chronological order. This may allow incrementally PE-based retrained MT to (i) improve more rapidly than chronologically PE-based retrained MT and (ii) result in overall productivity gains. The main contributions of this paper include: • Previous work (Haffari et al., 2009; Bloodgood and Callison-Burch, 2010) shows that, given a (static) training set, AL can improve the quality of MT. By contrast, here we show that AL-based data selection for human PE improves incrementally and dynamically retrained MT, reducing overall PE time of translation jobs in the localisation industry application scenarios. • We propose novel selection criteria for ALbased PE: we adapt cross-entropy difference (Moore and Lewis, 2010; Axelrod et al., 2011), originally used for domain adaptation, and propose an extension to cross entropy difference with a vocabulary saturation filter (Lewis and Eetemadi, 2013). • While much </context>
</contexts>
<marker>Bloodgood, Callison-Burch, 2010</marker>
<rawString>Michael Bloodgood and Chris Callison-Burch. 2010. Bucking the trend: Large-scale cost-focused active learning for statistical machine translation. In Jan Hajic, Sandra Carberry, and Stephen Clark, editors, ACL, pages 854–864. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Comput. Linguist.,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>311</pages>
<contexts>
<context position="1588" citStr="Brown et al., 1993" startWordPosition="226" endWordPosition="229">an be improved upon by Active Learning, where input is not presented chronologically but dynamically selected according to criteria that maximise performance with respect to (whatever is) the remaining data. We explore novel (source side-only) selection criteria and show performance increases of 0.67-2.65 points TER absolute on average on typical industry data sets compared to sequential PEbased incrementally retrained SMT. 1 Introduction and Related Research Machine Translation (MT) has evolved dramatically over the last two decades, especially since the appearance of statistical approaches (Brown et al., 1993). In fact, MT is nowadays succesfully used in the localisation and translation industry, as for many relevant domains such as technical documentation, post-editing (PE) of MT output by human translators (compared to human translation from scratch) results in notable productivity gains, as a number of industry studies have shown convincingly, e.g. (Plitt and Masselot, 2010). Furthermore, incremental retraining and update techniques (Bertoldi et al., 2013; Levenberg et al., 2010; Mathur et al., 2013; Simard and Foster, 2013) allow these PEs to be fed back into the MT model, resulting in an MT sy</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Comput. Linguist., 19(2):263– 311, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Mauro Cettolo</author>
</authors>
<title>IRSTLM: an open source toolkit for handling large scale language models.</title>
<date>2008</date>
<booktitle>In INTERSPEECH,</booktitle>
<pages>1618--1621</pages>
<publisher>ISCA.</publisher>
<contexts>
<context position="10686" citStr="Federico et al., 2008" startWordPosition="1765" endWordPosition="1768">ded and localngrams is updated with the n-grams from the current sentence. Otherwise the sentence is down-ranked to the bottom. In our experiments, the value n = 1 produces best results. 3 Experiments and Results We use technical documentation data taken from Symantec translation memories for the English– French (EN–FR) and English–German (EN–DE) language pairs (both directions) for our experiments. The statistics of the data (training and incremental splits) are shown in Table 1. All the systems are trained using the Moses (Koehn et al., 2007) phrase-based statistical MT system, with IRSTLM (Federico et al., 2008) for language modelling (n-grams up to order five) and with the alignment heuristic grow-diag-final-and. For the experiments, we considered two settings for each language pair in each direction. In the first setting, the initial MT system is trained using the training set (39,679 and 54,907 sentence pairs for EN–FR and EN–DE, respectively). Then, a batch of 500 source sentences is selected from the incremental dataset according to each of the selection criteria, and translations are obtained with the initial MT system. These translations are postedited and the corrected translations are added </context>
</contexts>
<marker>Federico, Bertoldi, Cettolo, 2008</marker>
<rawString>Marcello Federico, Nicola Bertoldi, and Mauro Cettolo. 2008. IRSTLM: an open source toolkit for handling large scale language models. In INTERSPEECH, pages 1618–1621. ISCA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jes´us Gonz´alez-Rubio</author>
<author>Daniel Ortiz-Martinez</author>
<author>Francisco Casacuberta</author>
</authors>
<title>Active learning for interactive machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’12,</booktitle>
<pages>245--254</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Gonz´alez-Rubio, Ortiz-Martinez, Casacuberta, 2012</marker>
<rawString>Jes´us Gonz´alez-Rubio, Daniel Ortiz-Martinez, and Francisco Casacuberta. 2012. Active learning for interactive machine translation. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’12, pages 245–254, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gholamreza Haffari</author>
<author>Maxim Roy</author>
<author>Anoop Sarkar</author>
</authors>
<title>Active learning for statistical phrase-based machine translation.</title>
<date>2009</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>415--423</pages>
<contexts>
<context position="3271" citStr="Haffari et al., 2009" startWordPosition="496" endWordPosition="499">suboptimal. In this paper we study the application of Active Learning (AL) to the scenario of PE MT and subsequent PE-based incremental retraining. AL selects data (here translation inputs and their MT outputs for PE) according to criteria that maximise performance with respect to the remaining data and may diverge from processing data items in chronological order. This may allow incrementally PE-based retrained MT to (i) improve more rapidly than chronologically PE-based retrained MT and (ii) result in overall productivity gains. The main contributions of this paper include: • Previous work (Haffari et al., 2009; Bloodgood and Callison-Burch, 2010) shows that, given a (static) training set, AL can improve the quality of MT. By contrast, here we show that AL-based data selection for human PE improves incrementally and dynamically retrained MT, reducing overall PE time of translation jobs in the localisation industry application scenarios. • We propose novel selection criteria for ALbased PE: we adapt cross-entropy difference (Moore and Lewis, 2010; Axelrod et al., 2011), originally used for domain adaptation, and propose an extension to cross entropy difference with a vocabulary saturation filter (Lew</context>
<context position="5155" citStr="Haffari et al., 2009" startWordPosition="789" endWordPosition="792">e side of the data. This supports selection before translation, keeping costs to a minimum, a priority in commercial PE MT applications. • Our experiments show that AL-based selection works for PE-based incrementally retrained MT with overall performance gains around 0.67 to 2.65 TER absolute on average. AL has been successfully applied to many tasks in natural language processing, including parsing (Tang et al., 2002), named entity recognition (Miller et al., 2004), to mention just a few. See (Olsson, 2009) for a comprehensie overview of the application of AL to natural language processing. (Haffari et al., 2009; Bloodgood and CallisonBurch, 2010) apply AL to MT where the aim is to build an optimal MT model from a given, static dataset. To the best of our knowledge, the most relevant previous research is (Gonz´alez-Rubio et al., 2012), which applies AL to interactive MT. In addition to differences in the AL selection criteria and data sets, our goals are fundamentally different: while the previous work aimed at reducing human effort in interactive MT, we aim at reducing the overall PE time in PE-based incremental MT update applications in the localisation industry. In our experiments reported in Sect</context>
</contexts>
<marker>Haffari, Roy, Sarkar, 2009</marker>
<rawString>Gholamreza Haffari, Maxim Roy, and Anoop Sarkar. 2009. Active learning for statistical phrase-based machine translation. In HLT-NAACL, pages 415– 423. The Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondˇrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="10614" citStr="Koehn et al., 2007" startWordPosition="1754" endWordPosition="1757">them is lower than a predefined threshold, the current sentence is added and localngrams is updated with the n-grams from the current sentence. Otherwise the sentence is down-ranked to the bottom. In our experiments, the value n = 1 produces best results. 3 Experiments and Results We use technical documentation data taken from Symantec translation memories for the English– French (EN–FR) and English–German (EN–DE) language pairs (both directions) for our experiments. The statistics of the data (training and incremental splits) are shown in Table 1. All the systems are trained using the Moses (Koehn et al., 2007) phrase-based statistical MT system, with IRSTLM (Federico et al., 2008) for language modelling (n-grams up to order five) and with the alignment heuristic grow-diag-final-and. For the experiments, we considered two settings for each language pair in each direction. In the first setting, the initial MT system is trained using the training set (39,679 and 54,907 sentence pairs for EN–FR and EN–DE, respectively). Then, a batch of 500 source sentences is selected from the incremental dataset according to each of the selection criteria, and translations are obtained with the initial MT system. The</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL 2007, pages 177–180, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abby Levenberg</author>
<author>Chris Callison-Burch</author>
<author>Miles Osborne</author>
</authors>
<title>Stream-based translation models for statistical machine translation.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10,</booktitle>
<pages>394--402</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2069" citStr="Levenberg et al., 2010" startWordPosition="298" endWordPosition="301">ation (MT) has evolved dramatically over the last two decades, especially since the appearance of statistical approaches (Brown et al., 1993). In fact, MT is nowadays succesfully used in the localisation and translation industry, as for many relevant domains such as technical documentation, post-editing (PE) of MT output by human translators (compared to human translation from scratch) results in notable productivity gains, as a number of industry studies have shown convincingly, e.g. (Plitt and Masselot, 2010). Furthermore, incremental retraining and update techniques (Bertoldi et al., 2013; Levenberg et al., 2010; Mathur et al., 2013; Simard and Foster, 2013) allow these PEs to be fed back into the MT model, resulting in an MT system that is continuously updated to perform better on forthcoming sentences, which should lead to a further increase in productivity. Typically, post-editors are presented with MT output units (sentences) in the order in which input sentences appear one after the other in the translation job. Because of this, incremental MT retraining and update models based on PE outputs also proceed in the same chronological order determined by the input data. This may be suboptimal. In thi</context>
</contexts>
<marker>Levenberg, Callison-Burch, Osborne, 2010</marker>
<rawString>Abby Levenberg, Chris Callison-Burch, and Miles Osborne. 2010. Stream-based translation models for statistical machine translation. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10, pages 394– 402, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Lewis</author>
<author>Sauleh Eetemadi</author>
</authors>
<title>Dramatically reducing training data size through vocabulary saturation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Eighth Workshop on Statistical Machine Translation,</booktitle>
<pages>281--291</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="3893" citStr="Lewis and Eetemadi, 2013" startWordPosition="593" endWordPosition="596">009; Bloodgood and Callison-Burch, 2010) shows that, given a (static) training set, AL can improve the quality of MT. By contrast, here we show that AL-based data selection for human PE improves incrementally and dynamically retrained MT, reducing overall PE time of translation jobs in the localisation industry application scenarios. • We propose novel selection criteria for ALbased PE: we adapt cross-entropy difference (Moore and Lewis, 2010; Axelrod et al., 2011), originally used for domain adaptation, and propose an extension to cross entropy difference with a vocabulary saturation filter (Lewis and Eetemadi, 2013). • While much of previous work concentrates on research datasets (e.g. Europarl, News Commentary), we use industry data (techni185 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 185–189, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics cal manuals). (Bertoldi et al., 2013) shows that the repetition rate of news is considerably lower than that of technical documentation, which impacts on the results obtained with incremental retraining. • Unlike in previous research, our AL-based selection</context>
<context position="9405" citStr="Lewis and Eetemadi, 2013" startWordPosition="1555" endWordPosition="1558">ning corpus L and an untranslated corpus U. CED is applied to select sentences from U that are (i) different from L (as we would like to add sentences that add new information to the model) and (ii) similar to the overall corpus U (as we would like to add sentences that are common in the untranslated data). Hence we apply CED and select sentences from U that have high entropy with respect to L and low entropy with respect to U (Equation 3). score(s) = HU(s) − HL(s) (3) • CED + n-gram (CEDN). This is an extension of the CED criterion inspired by the concept of the vocabulary saturation filter (Lewis and Eetemadi, 2013). CED may select many very similar sentences, and thus it may be the case that some of them are redundant. By post-processing the selection made by CED with vocabulary saturation we aim to spot and remove redudant sentences. This works in two steps. In the first step, all the sentences from U are scored using the CED metric. In the second step, we down-rank sentences that are considered redundant. The top sentence is selected, and its n-grams are stored in localngrams. For the remaining sentences, one by one, their n-grams are matched against localngrams. If the intersection between them is lo</context>
</contexts>
<marker>Lewis, Eetemadi, 2013</marker>
<rawString>William Lewis and Sauleh Eetemadi. 2013. Dramatically reducing training data size through vocabulary saturation. In Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 281–291, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prashant Mathur</author>
<author>Mauro Cettolo</author>
<author>Marcello Federico</author>
</authors>
<title>Online learning approaches in computer assisted translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Eighth Workshop on Statistical Machine Translation, ACL,</booktitle>
<pages>301--308</pages>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="2090" citStr="Mathur et al., 2013" startWordPosition="302" endWordPosition="305">ramatically over the last two decades, especially since the appearance of statistical approaches (Brown et al., 1993). In fact, MT is nowadays succesfully used in the localisation and translation industry, as for many relevant domains such as technical documentation, post-editing (PE) of MT output by human translators (compared to human translation from scratch) results in notable productivity gains, as a number of industry studies have shown convincingly, e.g. (Plitt and Masselot, 2010). Furthermore, incremental retraining and update techniques (Bertoldi et al., 2013; Levenberg et al., 2010; Mathur et al., 2013; Simard and Foster, 2013) allow these PEs to be fed back into the MT model, resulting in an MT system that is continuously updated to perform better on forthcoming sentences, which should lead to a further increase in productivity. Typically, post-editors are presented with MT output units (sentences) in the order in which input sentences appear one after the other in the translation job. Because of this, incremental MT retraining and update models based on PE outputs also proceed in the same chronological order determined by the input data. This may be suboptimal. In this paper we study the </context>
</contexts>
<marker>Mathur, Cettolo, Federico, 2013</marker>
<rawString>Prashant Mathur, Mauro Cettolo, and Marcello Federico. 2013. Online learning approaches in computer assisted translation. In Proceedings of the Eighth Workshop on Statistical Machine Translation, ACL, pages 301–308, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Miller</author>
<author>Jethran Guinness</author>
<author>Alex Zamanian</author>
</authors>
<title>Name tagging with word clusters and discriminative training.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT,</booktitle>
<pages>337--342</pages>
<contexts>
<context position="5005" citStr="Miller et al., 2004" startWordPosition="763" endWordPosition="766">s on the results obtained with incremental retraining. • Unlike in previous research, our AL-based selection criteria take into account only the source side of the data. This supports selection before translation, keeping costs to a minimum, a priority in commercial PE MT applications. • Our experiments show that AL-based selection works for PE-based incrementally retrained MT with overall performance gains around 0.67 to 2.65 TER absolute on average. AL has been successfully applied to many tasks in natural language processing, including parsing (Tang et al., 2002), named entity recognition (Miller et al., 2004), to mention just a few. See (Olsson, 2009) for a comprehensie overview of the application of AL to natural language processing. (Haffari et al., 2009; Bloodgood and CallisonBurch, 2010) apply AL to MT where the aim is to build an optimal MT model from a given, static dataset. To the best of our knowledge, the most relevant previous research is (Gonz´alez-Rubio et al., 2012), which applies AL to interactive MT. In addition to differences in the AL selection criteria and data sets, our goals are fundamentally different: while the previous work aimed at reducing human effort in interactive MT, w</context>
</contexts>
<marker>Miller, Guinness, Zamanian, 2004</marker>
<rawString>Scott Miller, Jethran Guinness, and Alex Zamanian. 2004. Name tagging with word clusters and discriminative training. In Proceedings of HLT, pages 337–342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
<author>William Lewis</author>
</authors>
<title>Intelligent selection of language model training data.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 Conference Short Papers, ACLShort ’10,</booktitle>
<pages>220--224</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="3714" citStr="Moore and Lewis, 2010" startWordPosition="567" endWordPosition="570">idly than chronologically PE-based retrained MT and (ii) result in overall productivity gains. The main contributions of this paper include: • Previous work (Haffari et al., 2009; Bloodgood and Callison-Burch, 2010) shows that, given a (static) training set, AL can improve the quality of MT. By contrast, here we show that AL-based data selection for human PE improves incrementally and dynamically retrained MT, reducing overall PE time of translation jobs in the localisation industry application scenarios. • We propose novel selection criteria for ALbased PE: we adapt cross-entropy difference (Moore and Lewis, 2010; Axelrod et al., 2011), originally used for domain adaptation, and propose an extension to cross entropy difference with a vocabulary saturation filter (Lewis and Eetemadi, 2013). • While much of previous work concentrates on research datasets (e.g. Europarl, News Commentary), we use industry data (techni185 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 185–189, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics cal manuals). (Bertoldi et al., 2013) shows that the repetition rate of news i</context>
<context position="8138" citStr="Moore and Lewis, 2010" startWordPosition="1309" endWordPosition="1312">ta. Thus, PEs of sentences with high number of unseen n-grams are considered to be more informative for updating the current MT system. However, for the MT system to translate unseen n-grams accurately, they need to be seen a minimum number V times.2 We use an n-gram overlap function similar to the one described in (Gonz´alez-Rubio et al., 2012) given in Equation 1 where N(T(i)) and N(S(i)) return i-grams in training data and the sentence S, respectively. n unseen(S) = i=1 {|N(T (i)) ∩ N(S(i))|&gt;V } N(S(i)) (1) • Cross Entropy Difference (CED). This metric is originally used in data selection (Moore and Lewis, 2010; Axelrod et al., 2011). Given an in-domain corpus I and a general corpus O, language models are built from both,3 and each sentence in O is scored according to the entropy H difference (Equation 2Following (Gonz´alez-Rubio et al., 2012) we use V = 10. 3In order to make the LMs comparable they have the same size. As commonly the size of O is considerable bigger than I, this means that the LM for O is built from a subset of the same size as I. n i=1 186 2). The lower the score given to a sentence, the more useful it is to train a system for the specific domain I. score(s) = HI(s) − HO(s) (2) In</context>
</contexts>
<marker>Moore, Lewis, 2010</marker>
<rawString>Robert C. Moore and William Lewis. 2010. Intelligent selection of language model training data. In Proceedings of the ACL 2010 Conference Short Papers, ACLShort ’10, pages 220–224, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon O’Brien</author>
</authors>
<title>Towards predicting post-editing productivity.</title>
<date>2011</date>
<journal>Machine Translation,</journal>
<volume>25</volume>
<issue>3</issue>
<marker>O’Brien, 2011</marker>
<rawString>Sharon O’Brien. 2011. Towards predicting post-editing productivity. Machine Translation, 25(3):197–215, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fredrik Olsson</author>
</authors>
<title>A literature survey of active machine learning in the context of natural language processing.</title>
<date>2009</date>
<tech>Technical Report T2009:06.</tech>
<contexts>
<context position="5048" citStr="Olsson, 2009" startWordPosition="773" endWordPosition="774">ing. • Unlike in previous research, our AL-based selection criteria take into account only the source side of the data. This supports selection before translation, keeping costs to a minimum, a priority in commercial PE MT applications. • Our experiments show that AL-based selection works for PE-based incrementally retrained MT with overall performance gains around 0.67 to 2.65 TER absolute on average. AL has been successfully applied to many tasks in natural language processing, including parsing (Tang et al., 2002), named entity recognition (Miller et al., 2004), to mention just a few. See (Olsson, 2009) for a comprehensie overview of the application of AL to natural language processing. (Haffari et al., 2009; Bloodgood and CallisonBurch, 2010) apply AL to MT where the aim is to build an optimal MT model from a given, static dataset. To the best of our knowledge, the most relevant previous research is (Gonz´alez-Rubio et al., 2012), which applies AL to interactive MT. In addition to differences in the AL selection criteria and data sets, our goals are fundamentally different: while the previous work aimed at reducing human effort in interactive MT, we aim at reducing the overall PE time in PE</context>
</contexts>
<marker>Olsson, 2009</marker>
<rawString>Fredrik Olsson. 2009. A literature survey of active machine learning in the context of natural language processing. Technical Report T2009:06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirko Plitt</author>
<author>Franc¸ois Masselot</author>
</authors>
<title>A productivity test of statistical machine translation post-editing in a typical localisation context.</title>
<date>2010</date>
<journal>Prague Bull. Math. Linguistics,</journal>
<pages>93--7</pages>
<contexts>
<context position="1963" citStr="Plitt and Masselot, 2010" startWordPosition="282" endWordPosition="285">ompared to sequential PEbased incrementally retrained SMT. 1 Introduction and Related Research Machine Translation (MT) has evolved dramatically over the last two decades, especially since the appearance of statistical approaches (Brown et al., 1993). In fact, MT is nowadays succesfully used in the localisation and translation industry, as for many relevant domains such as technical documentation, post-editing (PE) of MT output by human translators (compared to human translation from scratch) results in notable productivity gains, as a number of industry studies have shown convincingly, e.g. (Plitt and Masselot, 2010). Furthermore, incremental retraining and update techniques (Bertoldi et al., 2013; Levenberg et al., 2010; Mathur et al., 2013; Simard and Foster, 2013) allow these PEs to be fed back into the MT model, resulting in an MT system that is continuously updated to perform better on forthcoming sentences, which should lead to a further increase in productivity. Typically, post-editors are presented with MT output units (sentences) in the order in which input sentences appear one after the other in the translation job. Because of this, incremental MT retraining and update models based on PE outputs</context>
</contexts>
<marker>Plitt, Masselot, 2010</marker>
<rawString>Mirko Plitt and Franc¸ois Masselot. 2010. A productivity test of statistical machine translation post-editing in a typical localisation context. Prague Bull. Math. Linguistics, 93:7–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Simard</author>
<author>George Foster</author>
</authors>
<title>Pepr: Postedit propagation using phrase-based statistical machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the XIV Machine Translation Summit,</booktitle>
<pages>191--198</pages>
<location>Nice, France.</location>
<contexts>
<context position="2116" citStr="Simard and Foster, 2013" startWordPosition="306" endWordPosition="309">last two decades, especially since the appearance of statistical approaches (Brown et al., 1993). In fact, MT is nowadays succesfully used in the localisation and translation industry, as for many relevant domains such as technical documentation, post-editing (PE) of MT output by human translators (compared to human translation from scratch) results in notable productivity gains, as a number of industry studies have shown convincingly, e.g. (Plitt and Masselot, 2010). Furthermore, incremental retraining and update techniques (Bertoldi et al., 2013; Levenberg et al., 2010; Mathur et al., 2013; Simard and Foster, 2013) allow these PEs to be fed back into the MT model, resulting in an MT system that is continuously updated to perform better on forthcoming sentences, which should lead to a further increase in productivity. Typically, post-editors are presented with MT output units (sentences) in the order in which input sentences appear one after the other in the translation job. Because of this, incremental MT retraining and update models based on PE outputs also proceed in the same chronological order determined by the input data. This may be suboptimal. In this paper we study the application of Active Lear</context>
</contexts>
<marker>Simard, Foster, 2013</marker>
<rawString>Michel Simard and George Foster. 2013. Pepr: Postedit propagation using phrase-based statistical machine translation. In Proceedings of the XIV Machine Translation Summit, pages 191–198, Nice, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of Association for Machine Translation in the Americas,</booktitle>
<pages>223--231</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="6059" citStr="Snover et al., 2006" startWordPosition="947" endWordPosition="950">erences in the AL selection criteria and data sets, our goals are fundamentally different: while the previous work aimed at reducing human effort in interactive MT, we aim at reducing the overall PE time in PE-based incremental MT update applications in the localisation industry. In our experiments reported in Section 3 below we want to explore a space consisting of a considerable number of selection strategies and incremental retraining batch sizes. In order to be able to do this, we use the target side of our industry translation memory data to approximate human PE output and automatic TER (Snover et al., 2006) scores as a proxy for human PE times (O’Brien, 2011). 2 Methodology Given a translation job, our goal is to reduce the overall PE time. At each stage, we select sentences that are given to the post editor in such a way that uncertain sentences (with respect to the MT system at hand)1 are post-edited first. We then translate the n top-ranked sentences using the MT system and use the human PEs of the MT outputs to retrain the system. Algorithm 1 describes our 1The uncertainty of a sentence with respect to the model can be measured according to different criteria, e.g. percentage of unknown n-gr</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings of Association for Machine Translation in the Americas, pages 223–231, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Tang</author>
<author>Xiaoqiang Luo</author>
<author>Salim Roukos</author>
</authors>
<title>Active learning for statistical natural language parsing.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>120--127</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4957" citStr="Tang et al., 2002" startWordPosition="755" endWordPosition="758"> that of technical documentation, which impacts on the results obtained with incremental retraining. • Unlike in previous research, our AL-based selection criteria take into account only the source side of the data. This supports selection before translation, keeping costs to a minimum, a priority in commercial PE MT applications. • Our experiments show that AL-based selection works for PE-based incrementally retrained MT with overall performance gains around 0.67 to 2.65 TER absolute on average. AL has been successfully applied to many tasks in natural language processing, including parsing (Tang et al., 2002), named entity recognition (Miller et al., 2004), to mention just a few. See (Olsson, 2009) for a comprehensie overview of the application of AL to natural language processing. (Haffari et al., 2009; Bloodgood and CallisonBurch, 2010) apply AL to MT where the aim is to build an optimal MT model from a given, static dataset. To the best of our knowledge, the most relevant previous research is (Gonz´alez-Rubio et al., 2012), which applies AL to interactive MT. In addition to differences in the AL selection criteria and data sets, our goals are fundamentally different: while the previous work aim</context>
</contexts>
<marker>Tang, Luo, Roukos, 2002</marker>
<rawString>Min Tang, Xiaoqiang Luo, and Salim Roukos. 2002. Active learning for statistical natural language parsing. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 120–127, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>