<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.020829">
<title confidence="0.989618">
Unsupervised discovery of negative categories in lexicon bootstrapping
</title>
<author confidence="0.981867">
Tara McIntosh
</author>
<affiliation confidence="0.981374">
NICTA Victoria Research Lab
Dept of Computer Science and Software Engineering
University of Melbourne
</affiliation>
<email confidence="0.994212">
nlp@taramcintosh.org
</email>
<sectionHeader confidence="0.993413" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.92833395">
Multi-category bootstrapping algorithms were
developed to reduce semantic drift. By ex-
tracting multiple semantic lexicons simultane-
ously, a category’s search space may be re-
stricted. The best results have been achieved
through reliance on manually crafted negative
categories. Unfortunately, identifying these
categories is non-trivial, and their use shifts
the unsupervised bootstrapping paradigm to-
wards a supervised framework.
We present NEG-FINDER, the first approach
for discovering negative categories automat-
ically. NEG-FINDER exploits unsupervised
term clustering to generate multiple nega-
tive categories during bootstrapping. Our al-
gorithm effectively removes the necessity of
manual intervention and formulation of nega-
tive categories, with performance closely ap-
proaching that obtained using negative cate-
gories defined by a domain expert.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999545217391304">
Automatically acquiring semantic lexicons from text
is essential for overcoming the knowledge bottle-
neck in many NLP tasks, e.g. question answer-
ing (Ravichandran and Hovy, 2002). Many of the
successful methods follow the unsupervised itera-
tive bootstrapping framework (Riloff and Shepherd,
1997). Bootstrapping has since been effectively ap-
plied to extracting general semantic lexicons (Riloff
and Jones, 1999), biomedical entities (Yu and
Agichtein, 2003) and facts (Carlson et al., 2010).
Bootstrapping is often considered to be minimally
supervised, as it is initialised with a small set of seed
terms of the target category to extract. These seeds
are used to identify patterns that can match the tar-
get category, which in turn can extract new lexicon
terms (Riloff and Jones, 1999). Unfortunately, se-
mantic drift often occurs when ambiguous or erro-
neous terms and/or patterns are introduced into the
iterative process (Curran et al., 2007).
In multi-category bootstrapping, semantic drift is
often reduced when the target categories compete
with each other for terms and/or patterns (Yangarber
et al., 2002). This process is most effective when
the categories bound each other’s search space. To
ensure this, manually crafted negative categories are
introduced (Lin et al., 2003; Curran et al., 2007).
Unfortunately, this makes these algorithms substan-
tially more supervised.
The design of negative categories is a very time
consuming task. It typically requires a domain ex-
pert to identify the semantic drift and its cause, fol-
lowed by a significant amount of trial and error in or-
der to select the most suitable combination of nega-
tive categories. This introduces a substantial amount
of supervised information into what was an unsuper-
vised framework, and in turn negates one of the main
advantages of bootstrapping — the quick construc-
tion of accurate semantic lexicons.
We show that although excellent performance is
achieved using negative categories, it varies greatly
depending on the negative categories selected. This
highlights the difficulty of crafting negative cate-
gories and thus the necessity for tools that can au-
tomatically identify them.
Our second contribution is the first fully unsu-
pervised approach, NEG-FINDER, for discovering
</bodyText>
<page confidence="0.980791">
356
</page>
<note confidence="0.817812">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 356–365,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999671388888889">
negative categories automatically. During boot-
strapping, efficient clustering techniques are applied
to sets of drifted candidate terms to generate new
negative categories. Once a negative category is
identified it is incorporated into the subsequent it-
erations whereby it provides the necessary semantic
boundaries for the target categories.
We demonstrate the effectiveness of our ap-
proach for extracting biomedical semantic lexicons
by incorporating NEG-FINDER within the WMEB-
DRIFT bootstrapping algorithm (McIntosh and Cur-
ran, 2009). NEG-FINDER significantly outperforms
bootstrapping prior to the domain expert’s negative
categories. We show that by using our discovered
categories we can reach near expert-guided perfor-
mance. Our methods effectively remove the neces-
sity of manual intervention and formulation of neg-
ative categories in semantic lexicon bootstrapping.
</bodyText>
<sectionHeader confidence="0.987665" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999807444444445">
Various automated pattern-based bootstrapping al-
gorithms have been proposed to iteratively build se-
mantic lexicons. In multi-level bootstrapping, a lex-
icon is iteratively expanded from a small sample of
seed terms (Riloff and Jones, 1999). The seed terms
are used to identify contextual patterns they appear
in, which in turn may be used to extract new lexi-
con entries. This process is repeated with the new
expanded lexicon identifying new patterns.
When bootstrapping semantic lexicons, polyse-
mous or erroneous terms and/or patterns that weakly
constrain the semantic class are eventually extracted.
This often causes semantic drift — when a lexicon’s
intended meaning shifts into another category dur-
ing bootstrapping (Curran et al., 2007). For exam-
ple, female names may drift into gemstones when
the terms Ruby and Pearl are extracted.
Multi-category bootstrapping algorithms, such as
BASILISK (Thelen and Riloff, 2002), NOMEN (Yan-
garber et al., 2002), and WMEB (McIntosh and
Curran, 2008), aim to reduce semantic drift by
extracting multiple semantic categories simultane-
ously. These algorithms utilise information about
other semantic categories in order to reduce the cate-
gories from drifting towards each other. This frame-
work has recently been extended to extract different
relations from text (Carlson et al., 2010).
</bodyText>
<subsectionHeader confidence="0.953133">
2.1 Weighted MEB
</subsectionHeader>
<bodyText confidence="0.999979763157895">
In Weighted Mutual Exclusion Bootstrapping
(WMEB, McIntosh and Curran, 2008), multiple se-
mantic categories iterate simultaneously between
the term and pattern extraction phases, competing
with each other for terms and patterns. Semantic
drift is reduced by forcing the categories to be mu-
tually exclusive. That is, candidate terms can only
be extracted by a single category and patterns can
only extract terms for a single category.
In WMEB, multiple bootstrapping instances are
initiated for each competing target category. Each
category’s seed set forms its initial lexicon. For
each term in the category lexicon, WMEB identifies
all candidate contextual patterns that can match the
term in the text. To ensure mutual exclusion between
the categories, candidate patterns that are identified
by multiple categories in an iteration are excluded.
The remaining patterns are then ranked according to
the reliability measure and relevance weight.
The reliability of a pattern for a given category
is the number of extracted terms in the category’s
lexicon that match the pattern. A pattern’s relevance
weight is defined as the sum of the x-squared values
between the pattern (p) and each of the lexicon terms
(t): weight(p) _ EtET x2(p, t). These metrics are
symmetrical for both candidate terms and patterns.
The top-m patterns are then added to the pool of
extracting patterns. If each of the top-m patterns al-
ready exists in the pool, the next unseen pattern is
added to the pool. This ensures at least one new pat-
tern is added to the pool in each iteration.
In the term selection phase, all patterns within the
pattern pool are used to identify candidate terms.
Like the candidate patterns, terms that are extracted
by multiple categories in the same iteration are also
excluded. The remaining candidate terms are ranked
with respect to their reliability and relevance weight,
and the top-n terms are added to the lexicon.
</bodyText>
<subsectionHeader confidence="0.999676">
2.2 Detecting semantic drift in WMEB
</subsectionHeader>
<bodyText confidence="0.9996975">
In McIntosh and Curran (2009), we showed that
multi-category bootstrappers are still prone to se-
mantic drift in the later iterations. We proposed a
drift detection metric based on our hypothesis that
semantic drift occurs when a candidate term is more
similar to the recently added terms than to the seed
</bodyText>
<page confidence="0.996897">
357
</page>
<bodyText confidence="0.999862555555556">
and high precision terms extracted in the earlier
iterations. Our metric is based on distributional sim-
ilarity measurements and can be directly incorpo-
rated into WMEB’s term selection phase to prevent
drifting terms from being extracted (WMEB-DRIFT).
The drift metric is defined as the ratio of the aver-
age distributional similarity of the candidate term to
the first n terms extracted into the lexicon L, and to
the last m terms extracted in the previous iterations:
</bodyText>
<equation confidence="0.99827475">
avgsim(L1...n, term)
drift(term, n, m) =
avgsim(L(N_.+1)...N, term)
(1)
</equation>
<subsectionHeader confidence="0.985662">
2.3 Negative categories
</subsectionHeader>
<bodyText confidence="0.999868727272727">
In multi-category bootstrapping, improvements in
precision arise when semantic boundaries between
multiple target categories are established. Thus, it is
beneficial to bootstrap categories that share similar
semantic spaces, such as female names and flowers.
Unfortunately, it is difficult to predict if a tar-
get category will suffer from semantic drift and/or
whether it will naturally compete with the other tar-
get categories. Once a domain expert establishes
semantic drift and its possible cause, a set of neg-
ative/stop categories that may be of no direct inter-
est are manually crafted to prevent semantic drift.
These additional categories are then exploited dur-
ing another round of bootstrapping to provide fur-
ther competition for the target categories (Lin et al.,
2003; Curran et al., 2007).
Lin et al. (2003) improved NOMEN’s perfor-
mance for extracting diseases and locations from
the ProMED corpus by incorporating negative cat-
egories into the bootstrapping process. They first
used one general negative category, seeded with the
10 most frequent nouns in the corpus that were un-
related to the target categories. This single nega-
tive category resulted in substantial improvements in
precision. In their final experiment, six negative cat-
egories that were notable sources of semantic drift
were identified, and the inclusion of these lead to
further performance improvements (-20%).
In similar experiments, both Curran et al. (2007)
and McIntosh (2010) manually crafted negative
categories that were necessary to prevent semantic
drift. In particular, in McIntosh (2010), a biomedical
expert spent considerable time (—15 days) and effort
</bodyText>
<figureCaption confidence="0.998119">
Figure 1: NEG-FINDER: Local negative discovery
</figureCaption>
<bodyText confidence="0.999474692307692">
identifying potential negative categories and subse-
quently optimising their associated seeds in trial and
error bootstrapping runs.
By introducing manually crafted negative cate-
gories, a significant amount of expert domain knowl-
edge is introduced. The use of this expert knowl-
edge undermines the principle advantages of un-
supervised bootstrapping, by making it difficult to
bootstrap lexicons for a large number of categories
across diverse domains or languages. In this pa-
per, we aim to push multi-category bootstrapping
back into its original minimally-supervised frame-
work, with as little performance loss as possible.
</bodyText>
<sectionHeader confidence="0.984688" genericHeader="method">
3 NEG-FINDER
</sectionHeader>
<bodyText confidence="0.999874333333333">
Our approach, Negative Category Finder for Boot-
strapping (NEG-FINDER), can be easily incorporated
into bootstrapping algorithms that exclude candidate
terms or facts based on a selection criteria, includ-
ing WMEB-DRIFT and Pas¸ca et al.’s (2006) large-
scale fact extraction system. For simplicity, we de-
scribe our approach within the WMEB-DRIFT boot-
strapping algorithm. Figure 1 shows the framework
of our approach.
To discover negative categories during bootstrap-
ping, NEG-FINDER must identify a representative
cluster of the drifted terms. In this section, we
present the two types of clustering used (maximum
and outlier), and our three different levels of nega-
tive discovery (local, global and mixture).
</bodyText>
<subsectionHeader confidence="0.999886">
3.1 Discovering negative categories
</subsectionHeader>
<bodyText confidence="0.9999575">
We have observed that semantic drift begins to dom-
inate when clusters of incorrect terms with similar
</bodyText>
<figure confidence="0.9167545">
Initial Lexicon Clustered Terms Negative Lexicon
Drift Cache
</figure>
<page confidence="0.987145">
358
</page>
<bodyText confidence="0.999935742857143">
meanings are extracted. In the term selection phase
of WMEB-DRIFT, the top-n candidate terms that sat-
isfy the drift detection threshold are added to the ex-
panding lexicon. Those terms which are considered
but do not meet the threshold are excluded.
In NEG-FINDER, these drifted terms are cached as
they may provide adequate seed terms for new neg-
ative categories. However, the drifted terms can also
include scattered polysemous or correct terms that
share little similarity with the other drifted terms.
Therefore, simply using the first set of drifted terms
to establish a negative category is likely to introduce
noise rather than a cohesive competing category.
To discover negative categories, we exploit hi-
erarchical clustering to group similar terms within
the cache of drifted terms. In agglomerative hi-
erarchical clustering, a single term is assigned to
an individual cluster, and these clusters are itera-
tively merged until a final cluster is formed contain-
ing all terms (Kaufmann and Rousseeuw, 1990). In
our approach, the similarity between two clusters is
computed as the average distributional similarity be-
tween all pairs of terms across the clusters (average-
link clustering).
For calculating the similarity between two terms
we use the distributional similarity approach de-
scribed in Curran (2004). We extracted window-
based features from the set of candidate patterns to
form context vectors for each term. We use the
standard t-test weight and weighted Jaccard measure
functions (Curran, 2004).
To ensure adequate coverage of the possible drift-
ing topics, negative discovery and hence clustering
is only performed when the drift cache consists of at
least 20 terms.
</bodyText>
<subsectionHeader confidence="0.999549">
3.2 Maximum and outlier clustering
</subsectionHeader>
<bodyText confidence="0.999985277777778">
Although hierarchical clustering is quadratic, we can
efficiently exploit the agglomerative process as the
most similar terms will merge into clusters first.
Therefore, to identify the k most similar terms, we
can exit the clustering process as soon as a cluster
of size k is established. We refer to this approach as
maximum clustering.
In our next clustering method, we aim to form a
negative category with as little similarity to the tar-
get seeds. We use an outlier clustering strategy, in
which the drifted term t with the least average distri-
butional similarity to the first n terms in the lexicon
must be contained in the cluster of seeds. We use
average similarity to the first n terms, as it is already
pre-computed for the drift detection metric. As with
maximum clustering, once a cluster of size k con-
taining the term t is formed, the clustering process
can be terminated.
</bodyText>
<subsectionHeader confidence="0.998954">
3.3 Incorporating the negative category
</subsectionHeader>
<bodyText confidence="0.999980045454545">
After a cluster of negative seed terms is established,
the drift cache is cleared, and a new negative cate-
gory is created and introduced into the iterative boot-
strapping process in the next iteration. This means
that the negative category can only influence the
subsequent iterations of bootstrapping. The nega-
tive categories can compete with all other categories,
including any previously introduced negative cate-
gories, however the negative categories do not con-
tribute to the drift caches.
Before the new category is introduced, its first
set of extracting patterns must be identified. For
this, the complete set of extracting patterns match-
ing any of the negative seeds are considered and
ranked with respect to the seeds. The top scoring
patterns are considered sequentially until m patterns
are assigned to the new negative category. To ensure
mutual exclusion between the new category and the
target categories, a candidate pattern that has previ-
ously been selected by a target category cannot be
used to extract terms for either category in the sub-
sequent iterations.
</bodyText>
<subsectionHeader confidence="0.99943">
3.4 Levels of negative discovery
</subsectionHeader>
<bodyText confidence="0.999988866666667">
Negative category discovery can be performed at a
local or global level, or as a mixture of both. In local
discovery, each target category has its own drifted
term cache and can generate negative categories ir-
respective of the other target categories. This is
shown in Figure 1. The drifted terms (shaded) are
extracted away from the lexicon into the local drift
cache, which is then clustered. A cluster is then used
to initiate a negative category’s lexicon. Target cate-
gories can also generate multiple negative categories
across different iterations.
In global discovery, all drifted terms are pooled
into a global cache, from which a single negative
category can be identified in an iteration. This is
based on our intuition that multiple target categories
</bodyText>
<page confidence="0.988727">
359
</page>
<table confidence="0.999446">
TYPE MEDLINE
No. Terms 1347 002
No. Patterns 4 090 412
No. 5-grams 72 796 760
No. Unfiltered tokens 6 642 802 776
</table>
<tableCaption confidence="0.999734">
Table 1: Filtered 5-gram dataset statistics.
</tableCaption>
<bodyText confidence="0.999625307692308">
may be drifting into similar semantic categories, and
enables these otherwise missed negative categories
to be established.
In the mixture discovery method, both global and
local negative categories can be formed. A cate-
gory’s drifted terms are collected into its local cache
as well as the global cache. Negative discovery is
then performed on each cache when they contain at
least 20 terms. Once a local negative category is
formed, the terms within the local cache are cleared
and also removed from the global cache. This pre-
vents multiple negative categories being instantiated
with overlapping seed terms.
</bodyText>
<sectionHeader confidence="0.998761" genericHeader="method">
4 Experimental setup
</sectionHeader>
<bodyText confidence="0.999911333333333">
To compare the effectiveness of our negative discov-
ery approaches we consider the task of extracting
biomedical semantic lexicons from raw text.
</bodyText>
<subsectionHeader confidence="0.967685">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.999969555555556">
The algorithms take as input a set of candidate terms
to be extracted into semantic lexicons. The source
text collection consists of 5-grams (t1, t2, t3, t4, t5)
from approximately 16 million MEDLINE abstracts.1
The set of possible candidate terms correspond to
the middle tokens (t3), and the possible patterns are
formed from the surrounding tokens (t1, t2, t4, t5).
We do not use syntactic knowledge, as we did not
wish to rely on any tools that require supervised
training, to ensure our technique is as domain and
language independent as possible.
Limited preprocessing was required to extract the
5-grams from MEDLINE. The XML markup was
removed, and the collection was tokenised and split
into sentences using bio-specific NLP tools (Grover
et al., 2006). Filtering was applied to remove infre-
quent patterns and terms – patterns appearing with
less than 7 different terms, and terms only appearing
</bodyText>
<footnote confidence="0.873988">
1The set contains all MEDLINE titles and abstracts available
up to Oct 2007.
</footnote>
<tableCaption confidence="0.995031">
Table 2: The MEDLINE semantic categories
</tableCaption>
<bodyText confidence="0.991463">
with those patterns were removed. The statistics of
the resulting dataset are shown in Table 1.
</bodyText>
<subsectionHeader confidence="0.993438">
4.2 Semantic categories
</subsectionHeader>
<bodyText confidence="0.999977285714286">
The semantic categories we extract from MEDLINE
were inspired by the TREC Genomics entities (Hersh
et al., 2007) and are described in detail in McIntosh
(2010). The hand-picked seeds selected by a domain
expert for each category are shown in italics in Table
2. These were carefully chosen to be as unambigu-
ous as possible with respect to the other categories.
</bodyText>
<subsectionHeader confidence="0.995532">
4.3 Negative categories
</subsectionHeader>
<bodyText confidence="0.999631666666667">
In our experiments, we use two different sets of neg-
ative categories. These are shown in Table 3. The
first set corresponds to those used in McIntosh and
Curran (2008), and were identified by a domain ex-
pert as common sources of semantic drift in prelimi-
nary experiments with MEB and WMEB. The AMINO
ACID category was created in order to filter common
MUTN errors. The ANIMAL and BODY PART cate-
gories were formed with the intention of preventing
drift in the CELL, DISE and SIGN categories. The
ORGANISM category was then created to reduce the
new drift forming in the DISE category after the first
set of negative categories were introduced.
The second set of negative categories was identi-
fied by an independent domain expert with limited
</bodyText>
<table confidence="0.718816140350877">
CAT
DESCRIPTION
Antibodies: MAb IgG IgM rituximab infiiximab
(κ1:0.89, κ2:1.0)
Cells: RBC HUVEC BAEC VSMC SMC (κ1:0.91,
κ2:1.0)
Cell lines: PC12 CHO HeLa Jurkat COS (κ1:0.93,
κ2: 1.0)
Diseases: asthma hepatitis tuberculosis HIV malaria
(κ1:0.98, κ2:1.0)
Drugs: acetylcholine carbachol heparin penicillin
tetracyclin (κ1:0.86, κ2:0.99)
Molecular functions and processes: kinase ligase
acetyltransferase helicase binding (κ1:0.87, κ2:0.99)
Protein and gene mutations: Leiden C677T C282Y
35delG null (κ1:0.89, κ2:1.0)
Proteins and genes: p53 actin collagen albumin IL-6
(κ1:0.99, κ2:1.0)
Signs and symptoms: anemia fever hypertension
hyperglycemia cough (κ1:0.96, κ2:0.99)
Tumors: lymphoma sarcoma melanoma osteosarcoma
neuroblastoma (κ1:0.89, κ2:0.95)
ANTI
CELL
CLNE
DISE
DRUG
FUNC
MUTN
PROT
SIGN
TUMR
360
CATEGORY SEED TERMS
1 AMINO ACID arginine cysteine glycine glutamate histamine
insect mammal mice mouse rats
breast eye liver muscle spleen
Bartonella Borrelia Cryptosporidium
Salmonella toxoplasma
2 AMINO ACID Asn Gly His Leu Valine
1-500 1-1000
WMEB-DRIFT 74.3 68.6
+negative 1 87.7 82.8
+negative 2 83.8 77.8
Table 4: Influence of negative categories
ANIMAL
BODY PART
ORGANISM
ANIMAL
animals dogs larvae rabbits rodents
Canidia Shigella Scedosporium Salmonella
Yersinia
decrease effects events increase response
acute deep intrauterine postoperative
secondary
children females men subjects women
biopsies CFU sample specimens tissues
</table>
<tableCaption confidence="0.999746">
Table 3: Manually crafted negative categories
</tableCaption>
<bodyText confidence="0.99868825">
knowledge of NLP and bootstrapping. This expert
identified three similar categories to the first expert,
however their seeds are very different. They also
identified three more categories than the first.
</bodyText>
<subsectionHeader confidence="0.99858">
4.4 Lexicon evaluation
</subsectionHeader>
<bodyText confidence="0.978971846153846">
Our evaluation process follows that of McIntosh
and Curran (2009) and involved manually inspect-
ing each extracted term and judging whether it was
a member of the semantic class. This manual eval-
uation was performed by two domain experts and is
necessary due to the limited coverage of biomedical
resources. Inter-annotator agreement scores are pro-
vided in Table 2.2 To make later evaluations more
efficient, all evaluators’ decisions for each category
are cached.
Unfamiliar terms were checked using online re-
sources including MEDLINE, MeSH, and Wikipedia.
Each ambiguous term was counted as correct if it
was classified into one of its correct categories, such
as lymphoma, which is a TUMR and DISE. If a term
was unambiguously part of a multi-word term we
considered it correct. Abbreviations, acronyms, and
obvious misspelled words were included.
For comparing the performance of the algorithms,
the average precision for the top-1000 terms over the
10 target categories is measured. To identify when
semantic drift has a significant impact, we report the
precision of specific sections of the lexicon, e.g. the
801-1000 sample corresponds to the last 200 terms.
2All disagreements were discussed, and the kappa scores r1
and r12 are those before and after the discussions, respectively.
</bodyText>
<subsectionHeader confidence="0.993709">
4.5 System settings
</subsectionHeader>
<bodyText confidence="0.999992277777778">
All experiments were performed using the 10 tar-
get categories as input. Unless otherwise stated, no
hand-picked negative categories are used.
Each target category is initialised with the 5 hand-
picked seed terms (Table 2). In each iteration a max-
imum of 5 lexicon terms and 5 new patterns can
be extracted by a category. The bootstrapping al-
gorithms are run for 200 iterations.
The drift detection metric is calculated over the
first 100 terms and previous 5 terms extracted into
the lexicon, and the filter threshold is set to 0.2, as
in McIntosh and Curran (2009). To ensure infre-
quent terms are not used to seed negative categories,
drifted terms must occur at least 50 times to be re-
tained in the drift cache. Negative category discov-
ery is only initiated when the drifted cache contains
at least 20 terms, and a minimum of 5 terms are used
to seed a negative category.
</bodyText>
<subsectionHeader confidence="0.987839">
4.6 Random seed experiments
</subsectionHeader>
<bodyText confidence="0.9999131">
Both McIntosh and Curran (2009) and Pantel et
al. (2009) have shown that a bootstrapper’s per-
formance can vary greatly depending on the input
seeds. To ensure our methods are compared reliably,
we also report the average precision of randomised
seed experiments. Each algorithm is instantiated 10
times with different random gold seeds for each tar-
get category. These gold seeds are randomly sam-
pled from the evaluation cache formed in McIntosh
and Curran (2009).
</bodyText>
<sectionHeader confidence="0.999984" genericHeader="evaluation">
5 Results
</sectionHeader>
<subsectionHeader confidence="0.998866">
5.1 Influence of negative categories
</subsectionHeader>
<bodyText confidence="0.999991">
In our first experiments, we investigate the per-
formance variations and improvements gained us-
ing negative categories selected by two indepen-
dent domain experts. Table 4 shows WMEB-DRIFT’s
average precision over the 10 target categories with
and without the two negative category sets. Both
</bodyText>
<figure confidence="0.9929592">
ORGANISM
GENERIC
MODIFIERS
PEOPLE
SAMPLE
</figure>
<page confidence="0.983334">
361
</page>
<table confidence="0.998608692307692">
1-200 201-400 401-600 601-800 801-1000 1-1000
WMEB-DRIFT 79.5 74.8 64.7 61.9 62.1 68.6
NEG-FINDER
First discovered 79.5 74.3 64.8 67.8 66.6 70.7
Local discovery 79.5 74.8 67.3 69.3 70.5 72.2
+maximum
+outlier 79.5 73.9 64.8 67.8 71.0 71.5
Global discovery
+maximum 79.5 73.9 65.7 73.2 72.7 73.4
+outlier 79.5 74.7 65.6 71.4 68.2 72.1
Mixture discovery 79.5 74.7 69.3 73.3 72.8 74.0
+maximum
+outlier 79.5 75.2 69.7 72.0 69.4 73.2
</table>
<tableCaption confidence="0.999795">
Table 5: Performance comparison of WMEB-DRIFT and NEG-FINDER
</tableCaption>
<bodyText confidence="0.999367833333333">
sets significantly improve WMEB-DRIFT, however
there is a significant performance difference be-
tween them. This demonstrates the difficulty of se-
lecting appropriate negative categories and seeds for
the task, and in turn the necessity for tools to dis-
cover them automatically.
</bodyText>
<subsectionHeader confidence="0.998039">
5.2 Negative category discovery
</subsectionHeader>
<bodyText confidence="0.999937739130435">
Table 5 compares the performance of NEG-FINDER
incorporated with WMEB-DRIFT. Each method has
equal average precision over the first 200 terms, as
semantic drift does not typically occur in the early
iterations. Each discovery method significantly out-
performs WMEB-DRIFT in the later stages, and over
the top 1000 terms.3
The first discovery approach corresponds to the
naive NEG-FINDER system that generates local neg-
ative categories from the first five drifted terms. Al-
though it outperforms WMEB-DRIFT, its advantage
is smaller than the clustering methods.
The outlier clustering approach, which we pre-
dicted to be the most effective, was surprisingly less
accurate than the maximum approach for selecting
negative seeds. This is because the seed cluster
formed around the outlier term is not guaranteed to
have high pair-wise similarity and thus it may repre-
sent multiple semantic categories.
Local discovery was the least effective discov-
ery approach. Compared to local discovery, global
discovery is capable of detecting new negative cate-
gories earlier, and the categories it detects are more
</bodyText>
<footnote confidence="0.956114">
3Statistical significance was tested using computationally-
intensive randomisation tests (Cohen, 1995).
</footnote>
<table confidence="0.9595069">
CATEGORY NEGATIVE SEEDS
CELL-NEG animals After Lambs Pigs Rabbits
TUMR-NEG inoperable multinodular nonresectable
operated unruptured
GLOBAL days Hz mM post Torr
GLOBAL aortas eyes legs mucosa retinas
GLOBAL men offspring parents persons relatives
GLOBAL Australian Belgian Dutch European Italian
GLOBAL Amblyospora Branhamella Phormodium
Pseudanabaena Rhodotorula
</table>
<tableCaption confidence="0.998411">
Table 6: Negative categories from mixture discovery
</tableCaption>
<bodyText confidence="0.998656588235294">
likely to compete with multiple target categories.
The NEG-FINDER mixture approach, which ben-
efits from both local and global discovery, identi-
fies the most useful negative categories. Table 6
shows the seven discovered categories — two lo-
cal negative categories from CELL and TUMOUR,
and five global categories were formed. Many of
these categories are similar to those identified by
the domain experts. For example, clear categories
for ANIMAL, BODY PART, PEOPLE and ORGANISM
are created. By identifying and then including these
negative categories, NEG-FINDER significantly out-
performs WMEB-DRIFT by 5.4% over the top-1000
terms and by 10.7% over the last 200 terms, where
semantic drift is prominent. These results demon-
strate that suitable negative categories can be identi-
fied and exploited during bootstrapping.
</bodyText>
<subsectionHeader confidence="0.999583">
5.3 Boosting hand-picked negative categories
</subsectionHeader>
<bodyText confidence="0.99993925">
In our next set of experiments, we investigate
whether NEG-FINDER can improve state-of-the-
art performance by identifying new negative cate-
gories in addition to the manually selected negative
</bodyText>
<page confidence="0.993523">
362
</page>
<table confidence="0.99913125">
1-200 201-400 401-600 601-800 801-1000 1-1000
WMEB-DRIFT 90.5 87.3 82.0 74.6 79.8 82.8
+negative 1
+negative 2 87.8 82.2 78.7 76.1 63.3 77.8
WMEB-DRIFT 85.5 82.6 76.5 75.7 68.5 78.4
+restart +local
+restart +global 84.0 83.8 79.1 74.8 69.5 79.7
+restart +mixture 85.2 85.0 82.3 72.5 72.7 81.4
</table>
<tableCaption confidence="0.991004">
Table 7: Performance of WMEB-DRIFT using negative categories discovered by NEG-FINDER
</tableCaption>
<table confidence="0.999457">
601-800 801-1000 1-1000
WMEB-DRIFT
+negative 1 74.6 79.8 82.8
NEG-FINDER 76.4 80.1 83.2
+negative 1 +local
+negative 1 +global 77.5 76.0 82.7
+negative 1 +mixture 76.7 79.9 83.2
</table>
<tableCaption confidence="0.993669">
Table 8: Performance of NEG-FINDER with manually
crafted negative categories
</tableCaption>
<bodyText confidence="0.9992634">
categories. Both NEG-FINDER and WMEB-DRIFT
are initialised with the 10 target categories and the
first set of negative categories.
Table 8 compares our best performing systems
(NEG-FINDER maximum clustering) with standard
WMEB-DRIFT, over the last 400 terms where seman-
tic drift dominates. NEG-FINDER effectively dis-
covers additional categories and significantly out-
performs WMEB-DRIFT. This further demonstrates
the utility of our approach.
</bodyText>
<subsectionHeader confidence="0.999398">
5.4 Restarting with new negative categories
</subsectionHeader>
<bodyText confidence="0.9998571">
The performance improvements so far using NEG-
FINDER have been limited by the time at which new
negative categories are discovered and incorporated
into the bootstrapping process. That is, system im-
provements can only be gained from the negative
categories after they are generated. For example,
in Local NEG-FINDER, five negative categories are
discovered in iterations 83, 85, 126, 130 and 150.
On the other hand, in the WMEB-DRIFT +negative
experiments (Table 8 row 2), the hand-picked neg-
ative categories can start competing with the target
categories in the very first iteration of bootstrapping.
To test the full utility of NEG-FINDER, we use the
set of discovered categories as competing input for
WMEB-DRIFT. Table 7 shows the average precision
of WMEB-DRIFT over the 10 target categories when
it is restarted with the new negative categories dis-
covered from our three approaches (using maximum
clustering). Over the first 200 terms, significant im-
provements are gained using the new negative cate-
gories (+6%). However, the manually selected cat-
egories are far superior in preventing drift (+11%).
This may be attributed by the target categories not
strongly drifting into the new negative categories un-
til the later stages, whereas the hand-picked cate-
gories were selected on the basis of observed drift
in the early stages (over the first 500 terms).
Each NEG-FINDER approach significantly outper-
forms WMEB-DRIFT with no negative categories.
For example, using the NEG-FINDER mixture cat-
egories increases precision by 12.8%. These ap-
proaches also outperform their corresponding inline
discovery methods (e.g. +7.4% with mixture discov-
ery – Table 5).
Table 7 shows that each of the discovered neg-
ative sets can significantly outperform the negative
categories selected by a domain expert (negative set
2) (+0.6 – 3.9%). Our best system’s performance
(mixture: 81.4%) closely approaches that of the su-
perior negative set, trailing by only 1.4%.
</bodyText>
<subsectionHeader confidence="0.882358">
5.5 Individual categories
</subsectionHeader>
<bodyText confidence="0.999131583333333">
In this section, we analyse the effect of NEG-FINDER
on the individual target categories. Table 9 shows
the average precision of the lexicons for some tar-
get categories. All categories, except TUMOUR, im-
prove significantly with the inclusion of the discov-
ered negative categories. In particular, the CELL
and SIGN categories, which are affected severely by
semantic drift, increase by up to 33.3% and 45.2%,
respectively. The discovered negative categories
are more effective than the manually crafted sets in
reducing semantic drift in the ANTIBODY, CELL and
DISEASE lexicons.
</bodyText>
<page confidence="0.99676">
363
</page>
<table confidence="0.999427636363636">
ANTI CELL DISE SIGN TUMR
WMEB-DRIFT 92.9 47.8 49.3 27.9 39.5
+negative 1 91.6 73.1 87.8 76.5 48.7
+negative 2 85.8 68.0 84.2 71.3 16.3
NEG-FINDER
+mixture 94.9 73.9 56.0 41.0 42.2
+mixture +negative 1 90.8 77.2 87.8 78.2 48.2
WMEB-DRIFT
+restart +local 89.9 78.8 71.6 73.1 32.2
+restart +global 94.6 79.0 81.9 62.6 35.2
+restart +mixture 92.6 81.1 91.1 63.6 47.5
</table>
<tableCaption confidence="0.998776">
Table 9: Individual category results (1-1000 terms)
</tableCaption>
<subsectionHeader confidence="0.931965">
5.6 Random seed experiments
</subsectionHeader>
<bodyText confidence="0.999992">
In Table 10, we report the results of our randomised
experiments. Over the last 200 terms, WMEB-DRIFT
with the first set of negative categories (row 2) is out-
performed by NEG-FINDER (row 4). NEG-FINDER
also significantly boosts the performance of the orig-
inal negative categories by identifying additional
negative categories (row 5). Our final experiment,
where WMEB-DRIFT is re-initialised with the nega-
tive categories discovered by NEG-FINDER, further
demonstrates the utility of our method. On average,
the discovered negative categories significantly out-
perform the manually crafted negative categories.
</bodyText>
<sectionHeader confidence="0.999358" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.997773947368421">
In this paper, we have proposed the first completely
unsupervised approach to identifying the negative
categories that are necessary for bootstrapping large
yet precise semantic lexicons. Prior to this work,
negative categories were manually crafted by a do-
main expert, undermining the advantages of an un-
supervised bootstrapping paradigm.
There are numerous avenues for further examina-
tion. We intend to use sophisticated clustering meth-
ods, such as CBC (Pantel, 2003), to identify multiple
negative categories across the target categories in a
single iteration. We would also like to explore the
suitability of NEG-FINDER for relation extraction.
Our initial analysis demonstrated that although
excellent performance is achieved using negative
categories, large performance variations occur when
using categories crafted by different domain experts.
In NEG-FINDER, unsupervised clustering ap-
proaches are exploited to automatically discover
</bodyText>
<table confidence="0.996659625">
401-600 801-1000
WMEB-DRIFT 66.9 58.5
+negative 1 73.1 61.7
NEG-FINDER
+mixture 71.9 64.2
+mixture +negative 1 76.1 66.7
WMEB-DRIFT
+restart +mixture 78.0 70.8
</table>
<tableCaption confidence="0.999561">
Table 10: Random seed results
</tableCaption>
<bodyText confidence="0.999102238095238">
negative categories during bootstrapping. NEG-
FINDER identifies cohesive negative categories and
many of these are semantically similar to those iden-
tified by domain experts.
NEG-FINDER significantly outperforms the state-
of-the-art algorithm WMEB-DRIFT, before negative
categories are crafted, by up to 5.4% over the top-
1000 terms; and by 10.7% over the last 200 terms ex-
tracted, where semantic drift is extensive. The new
discovered categories can also be fully exploited in
bootstrapping, where they successfully outperform
a domain expert’s negative categories and approach
that of another expert.
The result is an effective approach that can be in-
corporated within any bootstrapper. NEG-FINDER
successfully removes the necessity of including
manually crafted supervised knowledge to boost a
bootstrapper’s performance. In doing so, we revert
the multi-category bootstrapping framework back to
its originally intended minimally supervised frame-
work, with little performance trade-off.
</bodyText>
<sectionHeader confidence="0.996006" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999967857142857">
We would like to thank Dr Cassie Thornley, our
second evaluator; and the anonymous reviewers for
their helpful feedback. NICTA is funded by the Aus-
tralian Government as represented by the Depart-
ment of Broadband, Communications and the Dig-
ital Economy and the Australian Research Council
through the ICT Centre of Excellence program.
</bodyText>
<sectionHeader confidence="0.999474" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998871333333333">
Andrew Carlson, Justin Betteridge, Richard C. Wang, Jr.
Estevam R. Hruschka, and Tom M. Mitchell. 2010.
Coupled semi-supervised learning for information ex-
traction. In Proceedings of the third ACM interna-
tional conference on Web search and data mining,
pages 101–110, New York, NY, USA.
</reference>
<page confidence="0.987585">
364
</page>
<reference confidence="0.99992">
Paul R. Cohen. 1995. Empirical Methods for Artificial
Intelligence. MIT Press, Cambridge, MA, USA.
James R. Curran, Tara Murphy, and Bernhard Scholz.
2007. Minimising semantic drift with mutual exclu-
sion bootstrapping. In Proceedings of the 10th Con-
ference of the Pacific Association for Computational
Linguistics, pages 172–180, Melbourne, Australia.
James R. Curran. 2004. From Distributional to Seman-
tic Similarity. Ph.D. thesis, University of Edinburgh,
Edinburgh, UK.
Claire Grover, Michael Matthews, and Richard Tobin.
2006. Tools to address the interdependence between
tokenisation and standoff annotation. In Proceed-
ings of the 5th Workshop on NLP and XML: Multi-
Dimensional Markup in Natural Language Process-
ing, pages 19–26, Trento, Italy.
William Hersh, Aaron M. Cohen, Lynn Ruslen, and
Phoebe M. Roberts. 2007. TREC 2007 Genomics
track overview. In Proceedings of the 16th Text RE-
trieval Conference, Gaithersburg, MD, USA.
Leonard Kaufmann and Peter J. Rousseeuw. 1990. Find-
ing Groups in Data: an Introdution to Cluster Analy-
sis. John Wiley and Sons.
Winston Lin, Roman Yangarber, and Ralph Grishman.
2003. Bootstrapped learning of semantic classes from
positive and negative examples. In Proceedings of
the ICML-2003 Workshop on The Continuum from La-
beled to Unlabeled Data, pages 103–111, Washington,
DC, USA.
Tara McIntosh and James R. Curran. 2008. Weighted
mutual exclusion bootstrapping for domain indepen-
dent lexicon and template acquisition. In Proceedings
of the Australasian Language Technology Association
Workshop, pages 97–105, Hobart, Australia.
Tara McIntosh and James R. Curran. 2009. Reducing
semantic drift with bagging and distributional similar-
ity. In Proceedings of the 47th Annual Meeting of the
Association for Computational Linguistics and the 4th
International Conference on Natural Language Pro-
cessing of the Asian Federation of Natural Language
Processing, pages 396–404, Suntec, Singapore.
Tara McIntosh. 2010. Reducing Semantic Drift in
Biomedical Lexicon Bootstrapping. Ph.D. thesis, Uni-
versity of Sydney.
Marius Pas¸ca, Dekang Lin, Jeffrey Bigham, Andrei Lif-
chits, and Alpa Jain. 2006. Names and similarities on
the web: Fact extraction in the fast lane. In Proceed-
ings of the 21st International Conference on Compu-
tational Linguistics and the 44th Annual Meeting of
the Association for Computational Linguistics, pages
809–816, Sydney, Australia.
Patrick Pantel, Eric Crestan, Arkady Borkovsky, Ana-
Maria Popescu, and Vishnu Vyas. 2009. Web-scale
distributional similarity and entity set expansion. In
Proceedings of the Conference on Empirical Methods
in Natural Language Processing, pages 238–247, Sin-
gapore, Singapore.
Patrick Pantel. 2003. Clustering by Committee. Ph.D.
thesis, University of Alberta.
Deepak Ravichandran and Eduard Hovy. 2002. Learning
surface text patterns for a question answering system.
In Proceedings of the 40th Annual Meeting of the As-
sociation for Computational Linguistics, pages 41–47,
Philadelphia, PA, USA.
Ellen Riloff and Rosie Jones. 1999. Learning dictionar-
ies for information extraction by multi-level bootstrap-
ping. In Proceedings of the 16th National Conference
on Artificial Intelligence and the 11th Innovative Ap-
plications of Artificial Intelligence Conference, pages
474–479, Orlando, FL, USA.
Ellen Riloff and Jessica Shepherd. 1997. A corpus-based
approach for building semantic lexicons. In Proceed-
ings of the Second Conference on Empirical Meth-
ods in Natural Language Processing, pages 117–124,
Providence, RI, USA.
Michael Thelen and Ellen Riloff. 2002. A bootstrapping
method for learning semantic lexicons using extraction
pattern contexts. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing,
pages 214–221, Philadelphia, PA, USA.
Roman Yangarber, Winston Lin, and Ralph Grishman.
2002. Unsupervised learning of generalized names. In
Proceedings of the 19th International Conference on
Computational Linguistics (COLING), pages 1135–
1141, San Francisco, CA, USA.
Hong Yu and Eugene Agichtein. 2003. Extracting syn-
onymous gene and protein terms from biological liter-
ature. Bioinformatics, 19(1):i340–i349.
</reference>
<page confidence="0.999097">
365
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.732382">
<title confidence="0.99515">Unsupervised discovery of negative categories in lexicon bootstrapping</title>
<author confidence="0.968916">Tara</author>
<affiliation confidence="0.952625">NICTA Victoria Research Dept of Computer Science and Software University of</affiliation>
<email confidence="0.924771">nlp@taramcintosh.org</email>
<abstract confidence="0.997175190476191">Multi-category bootstrapping algorithms were developed to reduce semantic drift. By extracting multiple semantic lexicons simultaneously, a category’s search space may be restricted. The best results have been achieved through reliance on manually crafted negative categories. Unfortunately, identifying these categories is non-trivial, and their use shifts the unsupervised bootstrapping paradigm towards a supervised framework. present the first approach for discovering negative categories automatunsupervised term clustering to generate multiple negative categories during bootstrapping. Our algorithm effectively removes the necessity of manual intervention and formulation of negative categories, with performance closely approaching that obtained using negative categories defined by a domain expert.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Estevam R Hruschka</author>
<author>Tom M Mitchell</author>
</authors>
<title>Coupled semi-supervised learning for information extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the third ACM international conference on Web search and data mining,</booktitle>
<pages>101--110</pages>
<location>New York, NY, USA.</location>
<marker>Hruschka, Mitchell, 2010</marker>
<rawString>Andrew Carlson, Justin Betteridge, Richard C. Wang, Jr. Estevam R. Hruschka, and Tom M. Mitchell. 2010. Coupled semi-supervised learning for information extraction. In Proceedings of the third ACM international conference on Web search and data mining, pages 101–110, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul R Cohen</author>
</authors>
<title>Empirical Methods for Artificial Intelligence.</title>
<date>1995</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="26343" citStr="Cohen, 1995" startWordPosition="4066" endWordPosition="4067">ach, which we predicted to be the most effective, was surprisingly less accurate than the maximum approach for selecting negative seeds. This is because the seed cluster formed around the outlier term is not guaranteed to have high pair-wise similarity and thus it may represent multiple semantic categories. Local discovery was the least effective discovery approach. Compared to local discovery, global discovery is capable of detecting new negative categories earlier, and the categories it detects are more 3Statistical significance was tested using computationallyintensive randomisation tests (Cohen, 1995). CATEGORY NEGATIVE SEEDS CELL-NEG animals After Lambs Pigs Rabbits TUMR-NEG inoperable multinodular nonresectable operated unruptured GLOBAL days Hz mM post Torr GLOBAL aortas eyes legs mucosa retinas GLOBAL men offspring parents persons relatives GLOBAL Australian Belgian Dutch European Italian GLOBAL Amblyospora Branhamella Phormodium Pseudanabaena Rhodotorula Table 6: Negative categories from mixture discovery likely to compete with multiple target categories. The NEG-FINDER mixture approach, which benefits from both local and global discovery, identifies the most useful negative categorie</context>
</contexts>
<marker>Cohen, 1995</marker>
<rawString>Paul R. Cohen. 1995. Empirical Methods for Artificial Intelligence. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Curran</author>
<author>Tara Murphy</author>
<author>Bernhard Scholz</author>
</authors>
<title>Minimising semantic drift with mutual exclusion bootstrapping.</title>
<date>2007</date>
<booktitle>In Proceedings of the 10th Conference of the Pacific Association for Computational Linguistics,</booktitle>
<pages>172--180</pages>
<location>Melbourne, Australia.</location>
<contexts>
<context position="2027" citStr="Curran et al., 2007" startWordPosition="283" endWordPosition="286">n effectively applied to extracting general semantic lexicons (Riloff and Jones, 1999), biomedical entities (Yu and Agichtein, 2003) and facts (Carlson et al., 2010). Bootstrapping is often considered to be minimally supervised, as it is initialised with a small set of seed terms of the target category to extract. These seeds are used to identify patterns that can match the target category, which in turn can extract new lexicon terms (Riloff and Jones, 1999). Unfortunately, semantic drift often occurs when ambiguous or erroneous terms and/or patterns are introduced into the iterative process (Curran et al., 2007). In multi-category bootstrapping, semantic drift is often reduced when the target categories compete with each other for terms and/or patterns (Yangarber et al., 2002). This process is most effective when the categories bound each other’s search space. To ensure this, manually crafted negative categories are introduced (Lin et al., 2003; Curran et al., 2007). Unfortunately, this makes these algorithms substantially more supervised. The design of negative categories is a very time consuming task. It typically requires a domain expert to identify the semantic drift and its cause, followed by a </context>
<context position="5167" citStr="Curran et al., 2007" startWordPosition="745" endWordPosition="748">ti-level bootstrapping, a lexicon is iteratively expanded from a small sample of seed terms (Riloff and Jones, 1999). The seed terms are used to identify contextual patterns they appear in, which in turn may be used to extract new lexicon entries. This process is repeated with the new expanded lexicon identifying new patterns. When bootstrapping semantic lexicons, polysemous or erroneous terms and/or patterns that weakly constrain the semantic class are eventually extracted. This often causes semantic drift — when a lexicon’s intended meaning shifts into another category during bootstrapping (Curran et al., 2007). For example, female names may drift into gemstones when the terms Ruby and Pearl are extracted. Multi-category bootstrapping algorithms, such as BASILISK (Thelen and Riloff, 2002), NOMEN (Yangarber et al., 2002), and WMEB (McIntosh and Curran, 2008), aim to reduce semantic drift by extracting multiple semantic categories simultaneously. These algorithms utilise information about other semantic categories in order to reduce the categories from drifting towards each other. This framework has recently been extended to extract different relations from text (Carlson et al., 2010). 2.1 Weighted ME</context>
<context position="9401" citStr="Curran et al., 2007" startWordPosition="1415" endWordPosition="1418">categories that share similar semantic spaces, such as female names and flowers. Unfortunately, it is difficult to predict if a target category will suffer from semantic drift and/or whether it will naturally compete with the other target categories. Once a domain expert establishes semantic drift and its possible cause, a set of negative/stop categories that may be of no direct interest are manually crafted to prevent semantic drift. These additional categories are then exploited during another round of bootstrapping to provide further competition for the target categories (Lin et al., 2003; Curran et al., 2007). Lin et al. (2003) improved NOMEN’s performance for extracting diseases and locations from the ProMED corpus by incorporating negative categories into the bootstrapping process. They first used one general negative category, seeded with the 10 most frequent nouns in the corpus that were unrelated to the target categories. This single negative category resulted in substantial improvements in precision. In their final experiment, six negative categories that were notable sources of semantic drift were identified, and the inclusion of these lead to further performance improvements (-20%). In sim</context>
</contexts>
<marker>Curran, Murphy, Scholz, 2007</marker>
<rawString>James R. Curran, Tara Murphy, and Bernhard Scholz. 2007. Minimising semantic drift with mutual exclusion bootstrapping. In Proceedings of the 10th Conference of the Pacific Association for Computational Linguistics, pages 172–180, Melbourne, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Curran</author>
</authors>
<title>From Distributional to Semantic Similarity.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh,</institution>
<location>Edinburgh, UK.</location>
<contexts>
<context position="13153" citStr="Curran (2004)" startWordPosition="1983" endWordPosition="1984">e exploit hierarchical clustering to group similar terms within the cache of drifted terms. In agglomerative hierarchical clustering, a single term is assigned to an individual cluster, and these clusters are iteratively merged until a final cluster is formed containing all terms (Kaufmann and Rousseeuw, 1990). In our approach, the similarity between two clusters is computed as the average distributional similarity between all pairs of terms across the clusters (averagelink clustering). For calculating the similarity between two terms we use the distributional similarity approach described in Curran (2004). We extracted windowbased features from the set of candidate patterns to form context vectors for each term. We use the standard t-test weight and weighted Jaccard measure functions (Curran, 2004). To ensure adequate coverage of the possible drifting topics, negative discovery and hence clustering is only performed when the drift cache consists of at least 20 terms. 3.2 Maximum and outlier clustering Although hierarchical clustering is quadratic, we can efficiently exploit the agglomerative process as the most similar terms will merge into clusters first. Therefore, to identify the k most sim</context>
</contexts>
<marker>Curran, 2004</marker>
<rawString>James R. Curran. 2004. From Distributional to Semantic Similarity. Ph.D. thesis, University of Edinburgh, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Grover</author>
<author>Michael Matthews</author>
<author>Richard Tobin</author>
</authors>
<title>Tools to address the interdependence between tokenisation and standoff annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th Workshop on NLP and XML: MultiDimensional Markup in Natural Language Processing,</booktitle>
<pages>pages</pages>
<location>Trento, Italy.</location>
<contexts>
<context position="18063" citStr="Grover et al., 2006" startWordPosition="2781" endWordPosition="2784">(t1, t2, t3, t4, t5) from approximately 16 million MEDLINE abstracts.1 The set of possible candidate terms correspond to the middle tokens (t3), and the possible patterns are formed from the surrounding tokens (t1, t2, t4, t5). We do not use syntactic knowledge, as we did not wish to rely on any tools that require supervised training, to ensure our technique is as domain and language independent as possible. Limited preprocessing was required to extract the 5-grams from MEDLINE. The XML markup was removed, and the collection was tokenised and split into sentences using bio-specific NLP tools (Grover et al., 2006). Filtering was applied to remove infrequent patterns and terms – patterns appearing with less than 7 different terms, and terms only appearing 1The set contains all MEDLINE titles and abstracts available up to Oct 2007. Table 2: The MEDLINE semantic categories with those patterns were removed. The statistics of the resulting dataset are shown in Table 1. 4.2 Semantic categories The semantic categories we extract from MEDLINE were inspired by the TREC Genomics entities (Hersh et al., 2007) and are described in detail in McIntosh (2010). The hand-picked seeds selected by a domain expert for eac</context>
</contexts>
<marker>Grover, Matthews, Tobin, 2006</marker>
<rawString>Claire Grover, Michael Matthews, and Richard Tobin. 2006. Tools to address the interdependence between tokenisation and standoff annotation. In Proceedings of the 5th Workshop on NLP and XML: MultiDimensional Markup in Natural Language Processing, pages 19–26, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Hersh</author>
<author>Aaron M Cohen</author>
<author>Lynn Ruslen</author>
<author>Phoebe M Roberts</author>
</authors>
<title>TREC</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th Text REtrieval Conference,</booktitle>
<location>Gaithersburg, MD, USA.</location>
<contexts>
<context position="18557" citStr="Hersh et al., 2007" startWordPosition="2860" endWordPosition="2863">kup was removed, and the collection was tokenised and split into sentences using bio-specific NLP tools (Grover et al., 2006). Filtering was applied to remove infrequent patterns and terms – patterns appearing with less than 7 different terms, and terms only appearing 1The set contains all MEDLINE titles and abstracts available up to Oct 2007. Table 2: The MEDLINE semantic categories with those patterns were removed. The statistics of the resulting dataset are shown in Table 1. 4.2 Semantic categories The semantic categories we extract from MEDLINE were inspired by the TREC Genomics entities (Hersh et al., 2007) and are described in detail in McIntosh (2010). The hand-picked seeds selected by a domain expert for each category are shown in italics in Table 2. These were carefully chosen to be as unambiguous as possible with respect to the other categories. 4.3 Negative categories In our experiments, we use two different sets of negative categories. These are shown in Table 3. The first set corresponds to those used in McIntosh and Curran (2008), and were identified by a domain expert as common sources of semantic drift in preliminary experiments with MEB and WMEB. The AMINO ACID category was created i</context>
</contexts>
<marker>Hersh, Cohen, Ruslen, Roberts, 2007</marker>
<rawString>William Hersh, Aaron M. Cohen, Lynn Ruslen, and Phoebe M. Roberts. 2007. TREC 2007 Genomics track overview. In Proceedings of the 16th Text REtrieval Conference, Gaithersburg, MD, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Kaufmann</author>
<author>Peter J Rousseeuw</author>
</authors>
<title>Finding Groups in Data: an Introdution to Cluster Analysis.</title>
<date>1990</date>
<publisher>John Wiley and Sons.</publisher>
<contexts>
<context position="12851" citStr="Kaufmann and Rousseeuw, 1990" startWordPosition="1936" endWordPosition="1939">ted terms can also include scattered polysemous or correct terms that share little similarity with the other drifted terms. Therefore, simply using the first set of drifted terms to establish a negative category is likely to introduce noise rather than a cohesive competing category. To discover negative categories, we exploit hierarchical clustering to group similar terms within the cache of drifted terms. In agglomerative hierarchical clustering, a single term is assigned to an individual cluster, and these clusters are iteratively merged until a final cluster is formed containing all terms (Kaufmann and Rousseeuw, 1990). In our approach, the similarity between two clusters is computed as the average distributional similarity between all pairs of terms across the clusters (averagelink clustering). For calculating the similarity between two terms we use the distributional similarity approach described in Curran (2004). We extracted windowbased features from the set of candidate patterns to form context vectors for each term. We use the standard t-test weight and weighted Jaccard measure functions (Curran, 2004). To ensure adequate coverage of the possible drifting topics, negative discovery and hence clusterin</context>
</contexts>
<marker>Kaufmann, Rousseeuw, 1990</marker>
<rawString>Leonard Kaufmann and Peter J. Rousseeuw. 1990. Finding Groups in Data: an Introdution to Cluster Analysis. John Wiley and Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Winston Lin</author>
<author>Roman Yangarber</author>
<author>Ralph Grishman</author>
</authors>
<title>Bootstrapped learning of semantic classes from positive and negative examples.</title>
<date>2003</date>
<booktitle>In Proceedings of the ICML-2003 Workshop on The Continuum from Labeled to Unlabeled Data,</booktitle>
<pages>103--111</pages>
<location>Washington, DC, USA.</location>
<contexts>
<context position="2366" citStr="Lin et al., 2003" startWordPosition="333" endWordPosition="336">ntify patterns that can match the target category, which in turn can extract new lexicon terms (Riloff and Jones, 1999). Unfortunately, semantic drift often occurs when ambiguous or erroneous terms and/or patterns are introduced into the iterative process (Curran et al., 2007). In multi-category bootstrapping, semantic drift is often reduced when the target categories compete with each other for terms and/or patterns (Yangarber et al., 2002). This process is most effective when the categories bound each other’s search space. To ensure this, manually crafted negative categories are introduced (Lin et al., 2003; Curran et al., 2007). Unfortunately, this makes these algorithms substantially more supervised. The design of negative categories is a very time consuming task. It typically requires a domain expert to identify the semantic drift and its cause, followed by a significant amount of trial and error in order to select the most suitable combination of negative categories. This introduces a substantial amount of supervised information into what was an unsupervised framework, and in turn negates one of the main advantages of bootstrapping — the quick construction of accurate semantic lexicons. We s</context>
<context position="9379" citStr="Lin et al., 2003" startWordPosition="1411" endWordPosition="1414">cial to bootstrap categories that share similar semantic spaces, such as female names and flowers. Unfortunately, it is difficult to predict if a target category will suffer from semantic drift and/or whether it will naturally compete with the other target categories. Once a domain expert establishes semantic drift and its possible cause, a set of negative/stop categories that may be of no direct interest are manually crafted to prevent semantic drift. These additional categories are then exploited during another round of bootstrapping to provide further competition for the target categories (Lin et al., 2003; Curran et al., 2007). Lin et al. (2003) improved NOMEN’s performance for extracting diseases and locations from the ProMED corpus by incorporating negative categories into the bootstrapping process. They first used one general negative category, seeded with the 10 most frequent nouns in the corpus that were unrelated to the target categories. This single negative category resulted in substantial improvements in precision. In their final experiment, six negative categories that were notable sources of semantic drift were identified, and the inclusion of these lead to further performance impro</context>
</contexts>
<marker>Lin, Yangarber, Grishman, 2003</marker>
<rawString>Winston Lin, Roman Yangarber, and Ralph Grishman. 2003. Bootstrapped learning of semantic classes from positive and negative examples. In Proceedings of the ICML-2003 Workshop on The Continuum from Labeled to Unlabeled Data, pages 103–111, Washington, DC, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tara McIntosh</author>
<author>James R Curran</author>
</authors>
<title>Weighted mutual exclusion bootstrapping for domain independent lexicon and template acquisition.</title>
<date>2008</date>
<booktitle>In Proceedings of the Australasian Language Technology Association Workshop,</booktitle>
<pages>97--105</pages>
<location>Hobart, Australia.</location>
<contexts>
<context position="5418" citStr="McIntosh and Curran, 2008" startWordPosition="784" endWordPosition="787">s. This process is repeated with the new expanded lexicon identifying new patterns. When bootstrapping semantic lexicons, polysemous or erroneous terms and/or patterns that weakly constrain the semantic class are eventually extracted. This often causes semantic drift — when a lexicon’s intended meaning shifts into another category during bootstrapping (Curran et al., 2007). For example, female names may drift into gemstones when the terms Ruby and Pearl are extracted. Multi-category bootstrapping algorithms, such as BASILISK (Thelen and Riloff, 2002), NOMEN (Yangarber et al., 2002), and WMEB (McIntosh and Curran, 2008), aim to reduce semantic drift by extracting multiple semantic categories simultaneously. These algorithms utilise information about other semantic categories in order to reduce the categories from drifting towards each other. This framework has recently been extended to extract different relations from text (Carlson et al., 2010). 2.1 Weighted MEB In Weighted Mutual Exclusion Bootstrapping (WMEB, McIntosh and Curran, 2008), multiple semantic categories iterate simultaneously between the term and pattern extraction phases, competing with each other for terms and patterns. Semantic drift is red</context>
<context position="18997" citStr="McIntosh and Curran (2008)" startWordPosition="2936" endWordPosition="2939">cs of the resulting dataset are shown in Table 1. 4.2 Semantic categories The semantic categories we extract from MEDLINE were inspired by the TREC Genomics entities (Hersh et al., 2007) and are described in detail in McIntosh (2010). The hand-picked seeds selected by a domain expert for each category are shown in italics in Table 2. These were carefully chosen to be as unambiguous as possible with respect to the other categories. 4.3 Negative categories In our experiments, we use two different sets of negative categories. These are shown in Table 3. The first set corresponds to those used in McIntosh and Curran (2008), and were identified by a domain expert as common sources of semantic drift in preliminary experiments with MEB and WMEB. The AMINO ACID category was created in order to filter common MUTN errors. The ANIMAL and BODY PART categories were formed with the intention of preventing drift in the CELL, DISE and SIGN categories. The ORGANISM category was then created to reduce the new drift forming in the DISE category after the first set of negative categories were introduced. The second set of negative categories was identified by an independent domain expert with limited CAT DESCRIPTION Antibodies</context>
</contexts>
<marker>McIntosh, Curran, 2008</marker>
<rawString>Tara McIntosh and James R. Curran. 2008. Weighted mutual exclusion bootstrapping for domain independent lexicon and template acquisition. In Proceedings of the Australasian Language Technology Association Workshop, pages 97–105, Hobart, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tara McIntosh</author>
<author>James R Curran</author>
</authors>
<title>Reducing semantic drift with bagging and distributional similarity.</title>
<date>2009</date>
<booktitle>In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Conference on Natural Language Processing of the Asian Federation of Natural Language Processing,</booktitle>
<pages>396--404</pages>
<location>Suntec, Singapore.</location>
<contexts>
<context position="4074" citStr="McIntosh and Curran, 2009" startWordPosition="583" endWordPosition="587">, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics negative categories automatically. During bootstrapping, efficient clustering techniques are applied to sets of drifted candidate terms to generate new negative categories. Once a negative category is identified it is incorporated into the subsequent iterations whereby it provides the necessary semantic boundaries for the target categories. We demonstrate the effectiveness of our approach for extracting biomedical semantic lexicons by incorporating NEG-FINDER within the WMEBDRIFT bootstrapping algorithm (McIntosh and Curran, 2009). NEG-FINDER significantly outperforms bootstrapping prior to the domain expert’s negative categories. We show that by using our discovered categories we can reach near expert-guided performance. Our methods effectively remove the necessity of manual intervention and formulation of negative categories in semantic lexicon bootstrapping. 2 Background Various automated pattern-based bootstrapping algorithms have been proposed to iteratively build semantic lexicons. In multi-level bootstrapping, a lexicon is iteratively expanded from a small sample of seed terms (Riloff and Jones, 1999). The seed </context>
<context position="7759" citStr="McIntosh and Curran (2009)" startWordPosition="1157" endWordPosition="1160">ng patterns. If each of the top-m patterns already exists in the pool, the next unseen pattern is added to the pool. This ensures at least one new pattern is added to the pool in each iteration. In the term selection phase, all patterns within the pattern pool are used to identify candidate terms. Like the candidate patterns, terms that are extracted by multiple categories in the same iteration are also excluded. The remaining candidate terms are ranked with respect to their reliability and relevance weight, and the top-n terms are added to the lexicon. 2.2 Detecting semantic drift in WMEB In McIntosh and Curran (2009), we showed that multi-category bootstrappers are still prone to semantic drift in the later iterations. We proposed a drift detection metric based on our hypothesis that semantic drift occurs when a candidate term is more similar to the recently added terms than to the seed 357 and high precision terms extracted in the earlier iterations. Our metric is based on distributional similarity measurements and can be directly incorporated into WMEB’s term selection phase to prevent drifting terms from being extracted (WMEB-DRIFT). The drift metric is defined as the ratio of the average distributiona</context>
<context position="21350" citStr="McIntosh and Curran (2009)" startWordPosition="3276" endWordPosition="3279">ries ANIMAL BODY PART ORGANISM ANIMAL animals dogs larvae rabbits rodents Canidia Shigella Scedosporium Salmonella Yersinia decrease effects events increase response acute deep intrauterine postoperative secondary children females men subjects women biopsies CFU sample specimens tissues Table 3: Manually crafted negative categories knowledge of NLP and bootstrapping. This expert identified three similar categories to the first expert, however their seeds are very different. They also identified three more categories than the first. 4.4 Lexicon evaluation Our evaluation process follows that of McIntosh and Curran (2009) and involved manually inspecting each extracted term and judging whether it was a member of the semantic class. This manual evaluation was performed by two domain experts and is necessary due to the limited coverage of biomedical resources. Inter-annotator agreement scores are provided in Table 2.2 To make later evaluations more efficient, all evaluators’ decisions for each category are cached. Unfamiliar terms were checked using online resources including MEDLINE, MeSH, and Wikipedia. Each ambiguous term was counted as correct if it was classified into one of its correct categories, such as </context>
<context position="23160" citStr="McIntosh and Curran (2009)" startWordPosition="3569" endWordPosition="3572"> and after the discussions, respectively. 4.5 System settings All experiments were performed using the 10 target categories as input. Unless otherwise stated, no hand-picked negative categories are used. Each target category is initialised with the 5 handpicked seed terms (Table 2). In each iteration a maximum of 5 lexicon terms and 5 new patterns can be extracted by a category. The bootstrapping algorithms are run for 200 iterations. The drift detection metric is calculated over the first 100 terms and previous 5 terms extracted into the lexicon, and the filter threshold is set to 0.2, as in McIntosh and Curran (2009). To ensure infrequent terms are not used to seed negative categories, drifted terms must occur at least 50 times to be retained in the drift cache. Negative category discovery is only initiated when the drifted cache contains at least 20 terms, and a minimum of 5 terms are used to seed a negative category. 4.6 Random seed experiments Both McIntosh and Curran (2009) and Pantel et al. (2009) have shown that a bootstrapper’s performance can vary greatly depending on the input seeds. To ensure our methods are compared reliably, we also report the average precision of randomised seed experiments. </context>
</contexts>
<marker>McIntosh, Curran, 2009</marker>
<rawString>Tara McIntosh and James R. Curran. 2009. Reducing semantic drift with bagging and distributional similarity. In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, pages 396–404, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tara McIntosh</author>
</authors>
<title>Reducing Semantic Drift in Biomedical Lexicon Bootstrapping.</title>
<date>2010</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Sydney.</institution>
<contexts>
<context position="10064" citStr="McIntosh (2010)" startWordPosition="1518" endWordPosition="1519"> for extracting diseases and locations from the ProMED corpus by incorporating negative categories into the bootstrapping process. They first used one general negative category, seeded with the 10 most frequent nouns in the corpus that were unrelated to the target categories. This single negative category resulted in substantial improvements in precision. In their final experiment, six negative categories that were notable sources of semantic drift were identified, and the inclusion of these lead to further performance improvements (-20%). In similar experiments, both Curran et al. (2007) and McIntosh (2010) manually crafted negative categories that were necessary to prevent semantic drift. In particular, in McIntosh (2010), a biomedical expert spent considerable time (—15 days) and effort Figure 1: NEG-FINDER: Local negative discovery identifying potential negative categories and subsequently optimising their associated seeds in trial and error bootstrapping runs. By introducing manually crafted negative categories, a significant amount of expert domain knowledge is introduced. The use of this expert knowledge undermines the principle advantages of unsupervised bootstrapping, by making it diffic</context>
<context position="18604" citStr="McIntosh (2010)" startWordPosition="2870" endWordPosition="2871">nd split into sentences using bio-specific NLP tools (Grover et al., 2006). Filtering was applied to remove infrequent patterns and terms – patterns appearing with less than 7 different terms, and terms only appearing 1The set contains all MEDLINE titles and abstracts available up to Oct 2007. Table 2: The MEDLINE semantic categories with those patterns were removed. The statistics of the resulting dataset are shown in Table 1. 4.2 Semantic categories The semantic categories we extract from MEDLINE were inspired by the TREC Genomics entities (Hersh et al., 2007) and are described in detail in McIntosh (2010). The hand-picked seeds selected by a domain expert for each category are shown in italics in Table 2. These were carefully chosen to be as unambiguous as possible with respect to the other categories. 4.3 Negative categories In our experiments, we use two different sets of negative categories. These are shown in Table 3. The first set corresponds to those used in McIntosh and Curran (2008), and were identified by a domain expert as common sources of semantic drift in preliminary experiments with MEB and WMEB. The AMINO ACID category was created in order to filter common MUTN errors. The ANIMA</context>
</contexts>
<marker>McIntosh, 2010</marker>
<rawString>Tara McIntosh. 2010. Reducing Semantic Drift in Biomedical Lexicon Bootstrapping. Ph.D. thesis, University of Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pas¸ca</author>
<author>Dekang Lin</author>
<author>Jeffrey Bigham</author>
<author>Andrei Lifchits</author>
<author>Alpa Jain</author>
</authors>
<title>Names and similarities on the web: Fact extraction in the fast lane.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>809--816</pages>
<location>Sydney, Australia.</location>
<marker>Pas¸ca, Lin, Bigham, Lifchits, Jain, 2006</marker>
<rawString>Marius Pas¸ca, Dekang Lin, Jeffrey Bigham, Andrei Lifchits, and Alpa Jain. 2006. Names and similarities on the web: Fact extraction in the fast lane. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, pages 809–816, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
</authors>
<title>Eric Crestan, Arkady Borkovsky, AnaMaria Popescu, and Vishnu Vyas.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>238--247</pages>
<marker>Pantel, 2009</marker>
<rawString>Patrick Pantel, Eric Crestan, Arkady Borkovsky, AnaMaria Popescu, and Vishnu Vyas. 2009. Web-scale distributional similarity and entity set expansion. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 238–247, Singapore, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
</authors>
<title>Clustering by Committee.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Alberta.</institution>
<contexts>
<context position="33034" citStr="Pantel, 2003" startWordPosition="5072" endWordPosition="5073">y of our method. On average, the discovered negative categories significantly outperform the manually crafted negative categories. 6 Conclusion In this paper, we have proposed the first completely unsupervised approach to identifying the negative categories that are necessary for bootstrapping large yet precise semantic lexicons. Prior to this work, negative categories were manually crafted by a domain expert, undermining the advantages of an unsupervised bootstrapping paradigm. There are numerous avenues for further examination. We intend to use sophisticated clustering methods, such as CBC (Pantel, 2003), to identify multiple negative categories across the target categories in a single iteration. We would also like to explore the suitability of NEG-FINDER for relation extraction. Our initial analysis demonstrated that although excellent performance is achieved using negative categories, large performance variations occur when using categories crafted by different domain experts. In NEG-FINDER, unsupervised clustering approaches are exploited to automatically discover 401-600 801-1000 WMEB-DRIFT 66.9 58.5 +negative 1 73.1 61.7 NEG-FINDER +mixture 71.9 64.2 +mixture +negative 1 76.1 66.7 WMEB-D</context>
</contexts>
<marker>Pantel, 2003</marker>
<rawString>Patrick Pantel. 2003. Clustering by Committee. Ph.D. thesis, University of Alberta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deepak Ravichandran</author>
<author>Eduard Hovy</author>
</authors>
<title>Learning surface text patterns for a question answering system.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>41--47</pages>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="1260" citStr="Ravichandran and Hovy, 2002" startWordPosition="164" endWordPosition="167">sed framework. We present NEG-FINDER, the first approach for discovering negative categories automatically. NEG-FINDER exploits unsupervised term clustering to generate multiple negative categories during bootstrapping. Our algorithm effectively removes the necessity of manual intervention and formulation of negative categories, with performance closely approaching that obtained using negative categories defined by a domain expert. 1 Introduction Automatically acquiring semantic lexicons from text is essential for overcoming the knowledge bottleneck in many NLP tasks, e.g. question answering (Ravichandran and Hovy, 2002). Many of the successful methods follow the unsupervised iterative bootstrapping framework (Riloff and Shepherd, 1997). Bootstrapping has since been effectively applied to extracting general semantic lexicons (Riloff and Jones, 1999), biomedical entities (Yu and Agichtein, 2003) and facts (Carlson et al., 2010). Bootstrapping is often considered to be minimally supervised, as it is initialised with a small set of seed terms of the target category to extract. These seeds are used to identify patterns that can match the target category, which in turn can extract new lexicon terms (Riloff and Jon</context>
</contexts>
<marker>Ravichandran, Hovy, 2002</marker>
<rawString>Deepak Ravichandran and Eduard Hovy. 2002. Learning surface text patterns for a question answering system. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 41–47, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Rosie Jones</author>
</authors>
<title>Learning dictionaries for information extraction by multi-level bootstrapping.</title>
<date>1999</date>
<booktitle>In Proceedings of the 16th National Conference on Artificial Intelligence and the 11th Innovative Applications of Artificial Intelligence Conference,</booktitle>
<pages>474--479</pages>
<location>Orlando, FL, USA.</location>
<contexts>
<context position="1493" citStr="Riloff and Jones, 1999" startWordPosition="196" endWordPosition="199">ctively removes the necessity of manual intervention and formulation of negative categories, with performance closely approaching that obtained using negative categories defined by a domain expert. 1 Introduction Automatically acquiring semantic lexicons from text is essential for overcoming the knowledge bottleneck in many NLP tasks, e.g. question answering (Ravichandran and Hovy, 2002). Many of the successful methods follow the unsupervised iterative bootstrapping framework (Riloff and Shepherd, 1997). Bootstrapping has since been effectively applied to extracting general semantic lexicons (Riloff and Jones, 1999), biomedical entities (Yu and Agichtein, 2003) and facts (Carlson et al., 2010). Bootstrapping is often considered to be minimally supervised, as it is initialised with a small set of seed terms of the target category to extract. These seeds are used to identify patterns that can match the target category, which in turn can extract new lexicon terms (Riloff and Jones, 1999). Unfortunately, semantic drift often occurs when ambiguous or erroneous terms and/or patterns are introduced into the iterative process (Curran et al., 2007). In multi-category bootstrapping, semantic drift is often reduced</context>
<context position="4663" citStr="Riloff and Jones, 1999" startWordPosition="667" endWordPosition="670">orithm (McIntosh and Curran, 2009). NEG-FINDER significantly outperforms bootstrapping prior to the domain expert’s negative categories. We show that by using our discovered categories we can reach near expert-guided performance. Our methods effectively remove the necessity of manual intervention and formulation of negative categories in semantic lexicon bootstrapping. 2 Background Various automated pattern-based bootstrapping algorithms have been proposed to iteratively build semantic lexicons. In multi-level bootstrapping, a lexicon is iteratively expanded from a small sample of seed terms (Riloff and Jones, 1999). The seed terms are used to identify contextual patterns they appear in, which in turn may be used to extract new lexicon entries. This process is repeated with the new expanded lexicon identifying new patterns. When bootstrapping semantic lexicons, polysemous or erroneous terms and/or patterns that weakly constrain the semantic class are eventually extracted. This often causes semantic drift — when a lexicon’s intended meaning shifts into another category during bootstrapping (Curran et al., 2007). For example, female names may drift into gemstones when the terms Ruby and Pearl are extracted</context>
</contexts>
<marker>Riloff, Jones, 1999</marker>
<rawString>Ellen Riloff and Rosie Jones. 1999. Learning dictionaries for information extraction by multi-level bootstrapping. In Proceedings of the 16th National Conference on Artificial Intelligence and the 11th Innovative Applications of Artificial Intelligence Conference, pages 474–479, Orlando, FL, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Jessica Shepherd</author>
</authors>
<title>A corpus-based approach for building semantic lexicons.</title>
<date>1997</date>
<booktitle>In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>117--124</pages>
<location>Providence, RI, USA.</location>
<contexts>
<context position="1378" citStr="Riloff and Shepherd, 1997" startWordPosition="180" endWordPosition="183">xploits unsupervised term clustering to generate multiple negative categories during bootstrapping. Our algorithm effectively removes the necessity of manual intervention and formulation of negative categories, with performance closely approaching that obtained using negative categories defined by a domain expert. 1 Introduction Automatically acquiring semantic lexicons from text is essential for overcoming the knowledge bottleneck in many NLP tasks, e.g. question answering (Ravichandran and Hovy, 2002). Many of the successful methods follow the unsupervised iterative bootstrapping framework (Riloff and Shepherd, 1997). Bootstrapping has since been effectively applied to extracting general semantic lexicons (Riloff and Jones, 1999), biomedical entities (Yu and Agichtein, 2003) and facts (Carlson et al., 2010). Bootstrapping is often considered to be minimally supervised, as it is initialised with a small set of seed terms of the target category to extract. These seeds are used to identify patterns that can match the target category, which in turn can extract new lexicon terms (Riloff and Jones, 1999). Unfortunately, semantic drift often occurs when ambiguous or erroneous terms and/or patterns are introduced</context>
</contexts>
<marker>Riloff, Shepherd, 1997</marker>
<rawString>Ellen Riloff and Jessica Shepherd. 1997. A corpus-based approach for building semantic lexicons. In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing, pages 117–124, Providence, RI, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Thelen</author>
<author>Ellen Riloff</author>
</authors>
<title>A bootstrapping method for learning semantic lexicons using extraction pattern contexts.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>214--221</pages>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="5348" citStr="Thelen and Riloff, 2002" startWordPosition="772" endWordPosition="775">y appear in, which in turn may be used to extract new lexicon entries. This process is repeated with the new expanded lexicon identifying new patterns. When bootstrapping semantic lexicons, polysemous or erroneous terms and/or patterns that weakly constrain the semantic class are eventually extracted. This often causes semantic drift — when a lexicon’s intended meaning shifts into another category during bootstrapping (Curran et al., 2007). For example, female names may drift into gemstones when the terms Ruby and Pearl are extracted. Multi-category bootstrapping algorithms, such as BASILISK (Thelen and Riloff, 2002), NOMEN (Yangarber et al., 2002), and WMEB (McIntosh and Curran, 2008), aim to reduce semantic drift by extracting multiple semantic categories simultaneously. These algorithms utilise information about other semantic categories in order to reduce the categories from drifting towards each other. This framework has recently been extended to extract different relations from text (Carlson et al., 2010). 2.1 Weighted MEB In Weighted Mutual Exclusion Bootstrapping (WMEB, McIntosh and Curran, 2008), multiple semantic categories iterate simultaneously between the term and pattern extraction phases, c</context>
</contexts>
<marker>Thelen, Riloff, 2002</marker>
<rawString>Michael Thelen and Ellen Riloff. 2002. A bootstrapping method for learning semantic lexicons using extraction pattern contexts. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 214–221, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roman Yangarber</author>
<author>Winston Lin</author>
<author>Ralph Grishman</author>
</authors>
<title>Unsupervised learning of generalized names.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>1135--1141</pages>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="2195" citStr="Yangarber et al., 2002" startWordPosition="307" endWordPosition="310">. Bootstrapping is often considered to be minimally supervised, as it is initialised with a small set of seed terms of the target category to extract. These seeds are used to identify patterns that can match the target category, which in turn can extract new lexicon terms (Riloff and Jones, 1999). Unfortunately, semantic drift often occurs when ambiguous or erroneous terms and/or patterns are introduced into the iterative process (Curran et al., 2007). In multi-category bootstrapping, semantic drift is often reduced when the target categories compete with each other for terms and/or patterns (Yangarber et al., 2002). This process is most effective when the categories bound each other’s search space. To ensure this, manually crafted negative categories are introduced (Lin et al., 2003; Curran et al., 2007). Unfortunately, this makes these algorithms substantially more supervised. The design of negative categories is a very time consuming task. It typically requires a domain expert to identify the semantic drift and its cause, followed by a significant amount of trial and error in order to select the most suitable combination of negative categories. This introduces a substantial amount of supervised inform</context>
<context position="5380" citStr="Yangarber et al., 2002" startWordPosition="777" endWordPosition="781"> used to extract new lexicon entries. This process is repeated with the new expanded lexicon identifying new patterns. When bootstrapping semantic lexicons, polysemous or erroneous terms and/or patterns that weakly constrain the semantic class are eventually extracted. This often causes semantic drift — when a lexicon’s intended meaning shifts into another category during bootstrapping (Curran et al., 2007). For example, female names may drift into gemstones when the terms Ruby and Pearl are extracted. Multi-category bootstrapping algorithms, such as BASILISK (Thelen and Riloff, 2002), NOMEN (Yangarber et al., 2002), and WMEB (McIntosh and Curran, 2008), aim to reduce semantic drift by extracting multiple semantic categories simultaneously. These algorithms utilise information about other semantic categories in order to reduce the categories from drifting towards each other. This framework has recently been extended to extract different relations from text (Carlson et al., 2010). 2.1 Weighted MEB In Weighted Mutual Exclusion Bootstrapping (WMEB, McIntosh and Curran, 2008), multiple semantic categories iterate simultaneously between the term and pattern extraction phases, competing with each other for ter</context>
</contexts>
<marker>Yangarber, Lin, Grishman, 2002</marker>
<rawString>Roman Yangarber, Winston Lin, and Ralph Grishman. 2002. Unsupervised learning of generalized names. In Proceedings of the 19th International Conference on Computational Linguistics (COLING), pages 1135– 1141, San Francisco, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Eugene Agichtein</author>
</authors>
<title>Extracting synonymous gene and protein terms from biological literature.</title>
<date>2003</date>
<journal>Bioinformatics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="1539" citStr="Yu and Agichtein, 2003" startWordPosition="202" endWordPosition="205">ention and formulation of negative categories, with performance closely approaching that obtained using negative categories defined by a domain expert. 1 Introduction Automatically acquiring semantic lexicons from text is essential for overcoming the knowledge bottleneck in many NLP tasks, e.g. question answering (Ravichandran and Hovy, 2002). Many of the successful methods follow the unsupervised iterative bootstrapping framework (Riloff and Shepherd, 1997). Bootstrapping has since been effectively applied to extracting general semantic lexicons (Riloff and Jones, 1999), biomedical entities (Yu and Agichtein, 2003) and facts (Carlson et al., 2010). Bootstrapping is often considered to be minimally supervised, as it is initialised with a small set of seed terms of the target category to extract. These seeds are used to identify patterns that can match the target category, which in turn can extract new lexicon terms (Riloff and Jones, 1999). Unfortunately, semantic drift often occurs when ambiguous or erroneous terms and/or patterns are introduced into the iterative process (Curran et al., 2007). In multi-category bootstrapping, semantic drift is often reduced when the target categories compete with each </context>
</contexts>
<marker>Yu, Agichtein, 2003</marker>
<rawString>Hong Yu and Eugene Agichtein. 2003. Extracting synonymous gene and protein terms from biological literature. Bioinformatics, 19(1):i340–i349.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>