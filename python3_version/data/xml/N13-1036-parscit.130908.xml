<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004109">
<title confidence="0.9981845">
Dialectal Arabic to English Machine Translation:
Pivoting through Modern Standard Arabic
</title>
<author confidence="0.987174">
Wael Salloum and Nizar Habash
</author>
<affiliation confidence="0.9962005">
Center for Computational Learning Systems
Columbia University
</affiliation>
<email confidence="0.998824">
{wael,habash}@ccls.columbia.edu
</email>
<sectionHeader confidence="0.993678" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99664455">
Modern Standard Arabic (MSA) has a wealth
of natural language processing (NLP) tools
and resources. In comparison, resources for
dialectal Arabic (DA), the unstandardized spo-
ken varieties of Arabic, are still lacking. We
present ELISSA, a machine translation (MT)
system for DA to MSA. ELISSA employs a
rule-based approach that relies on morpho-
logical analysis, transfer rules and dictionar-
ies in addition to language models to produce
MSA paraphrases of DA sentences. ELISSA
can be employed as a general preprocessor for
DA when using MSA NLP tools. A man-
ual error analysis of ELISSA’s output shows
that it produces correct MSA translations over
93% of the time. Using ELISSA to produce
MSA versions of DA sentences as part of
an MSA-pivoting DA-to-English MT solution,
improves BLEU scores on multiple blind test
sets between 0.6% and 1.4%.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999617128205128">
Much work has been done on Modern Standard Ara-
bic (MSA) natural language processing (NLP) and
machine translation (MT), especially Statistical MT
(SMT). MSA has a wealth of resources in terms of
morphological analyzers, disambiguation systems,
and parallel corpora. In comparison, research on di-
alectal Arabic (DA), the unstandardized spoken vari-
eties of Arabic, is still lacking in NLP in general and
MT in particular. In this paper we present ELISSA,
our DA-to-MSA MT system, and show how it can
help improve the translation of highly dialectal Ara-
bic text into English by pivoting on MSA.
The ELISSA approach can be summarized as fol-
lows. First, ELISSA uses different techniques to
identify dialectal words and multi-word construc-
tions (phrases) in a source sentence. Then, ELISSA
produces MSA paraphrases for the selected words
and phrase using a rule-based component that de-
pends on the existence of a dialectal morphologi-
cal analyzer, a list of morphosyntactic transfer rules,
and DA-MSA dictionaries. The resulting MSA is in
a lattice form that we pass to a language model for n-
best decoding. The output of ELISSA, whether a top-
1 choice sentence or n-best sentences, is passed to an
MSA-English SMT system to produce the English
translation sentence. ELISSA-based MSA-pivoting
for DA-to-English SMT improves BLEU scores (Pa-
pineni et al., 2002) on three blind test sets between
0.6% and 1.4%. A manual error analysis of trans-
lated words shows that ELISSA produces correct
MSA translations over 93% of the time.
The rest of this paper is structured as follows:
Section 2 motivates the use of ELISSA to improve
DA-English SMT with an example. Section 3 dis-
cusses some of the challenges associated with pro-
cessing Arabic and its dialects. Section 4 presents
related work. Section 5 details ELISSA and its
approach and Section 6 presents results evaluating
ELISSA under a variety of conditions.
</bodyText>
<sectionHeader confidence="0.934336" genericHeader="introduction">
2 Motivating Example
</sectionHeader>
<bodyText confidence="0.99988">
Table 1 shows a motivating example of how pivot-
ing on MSA can dramatically improve the transla-
tion quality of a statistical MT system that is trained
on mostly MSA-to-English parallel corpora. In this
example, we use Google Translate’s online Arabic-
English SMT system.1 The table is divided into two
parts. The top part shows a dialectal (Levantine)
sentence, its reference translation to English, and
its Google Translate translation. The Google Trans-
late translation clearly struggles with most of the DA
words, which were probably unseen in the training
data (i.e., out-of-vocabulary – OOV) and were con-
</bodyText>
<footnote confidence="0.985014">
1The system was used on February 21, 2013.
</footnote>
<page confidence="0.917238">
348
</page>
<table confidence="0.708793695652174">
Proceedings of NAACL-HLT 2013, pages 348–358,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
DA source �
hPA�JÖß�@ �àñëQ�. �gAÓ ñ�KB �HA�J��J�Óñ» �áÊ�JªJ.K� èAK� �àYK. Bð ñªJ.�K �éJ�’ j ~‚Ë@ éj�®’Ë@ ¡J�j« ñËñJ.�JºJ�k AÓ ø
Aë �éËAmÌ AîE.
.YÊJ.ËA« hðQK�
bhAlHAlh hAy mA Hyktbwlw SHyT AlSfHh AlšxSyh tbSw wlA bdn yAh ybStln kwmyntAt lÂnw mAxbrhwn AymtA
rH yrwH SAlbld.
Human In this case, they will not write on his profile wall and they do not want him to send them comments because he
Reference did not tell them when he will go to the country.
Google Bhalhalh Hi Hictpoulo Ahat Profile Tbau not hull Weah Abatln Comintat Anu Mabarhun Oamta welcomed calls
Translate them Aalbuld.
Human ��@ é;ðYK�QK
DA-to-MSA Bð Z’j�°‚Ë@ é�Jja“ ¡iAg úÎ« éË @ñJ.:ºK
j�éËAmÌ @ è �Yë ú
~m~ B �HA�®J�Êª�K ÑêË ÉƒQK� à
úæÓ ÑëQ�. �� ÕË é�K¯�
.YÊJ.Ë@ úÍ@ I. ë YJ
ƒ
fy h6h AlHAlh ln yktbwA lh Slý HAˆyT SfHth AlšxSyh wlA yrydwnh Ân yrsl lhm tSlyqAt lÂnh lm yxbrhm mtý sy6hb
ˇAlý Albld.
Google In this case it would not write to him on the wall of his own and do not want to send their comments because he
Translate did not tell them when going to the country.
</table>
<tableCaption confidence="0.997043">
Table 1: A motivating example for DA-to-English MT by pivoting (bridging) on MSA. The top half of the table
displays a DA sentence, its human reference translation and the output of Google Translate. The bottom half of the
table shows the result of human translation into MSA of the DA sentence before sending it to Google Translate.
</tableCaption>
<bodyText confidence="0.997778181818182">
sidered proper nouns (transliterated and capitalized).
The lack of DA-English parallel corpora suggests
pivoting on MSA can improve the translation qual-
ity. In the bottom part of the table, we show a hu-
man MSA translation of the DA sentence above and
its Google translation. We see that the results are
quite promising. The goal of ELISSA is to model this
DA-MSA translation automatically. In Section 5.4,
we revisit this example to discuss ELISSA’s perfor-
mance on it. We show its output and its correspond-
ing Google translation in Table 3.
</bodyText>
<sectionHeader confidence="0.9891635" genericHeader="method">
3 Challenges for Processing Arabic and its
Dialects
</sectionHeader>
<bodyText confidence="0.995903666666667">
Contemporary Arabic is in fact a collection of vari-
eties: MSA, the official language of the Arab World,
which has a standard orthography and is used in
formal settings; and DAs, the commonly used in-
formal native varieties, which have no standard or-
thographies but have an increasing presence on the
web. Arabic, in general, is a morphologically com-
plex language which has rich inflectional morphol-
ogy, expressed both templatically and affixationally,
and several classes of attachable clitics. For exam-
ple, the Arabic word Aî�EñJ.�JºJ
ƒð w+s+y-ktb-wn+hA2
‘and they will write it’ has two proclitics (+ð w+
‘and’ and +€ s+ ‘will’), one prefix -ø
y- ‘3rd
</bodyText>
<footnote confidence="0.862484">
2Arabic transliteration throughout the paper is presented in
the Habash-Soudi-Buckwalter scheme (Habash et al., 2007): (in
alphabetical order) AbtOjHxd6rzsšSDT ˇDS-yfqklmnhwy and the
</footnote>
<construct confidence="0.321963">
additional symbols: ’ Z, Â �@, Aˇ @�, A¯ �@, wˆ j , yˆ Zø , h o, ý ø.
</construct>
<bodyText confidence="0.998714806451613">
person’, one suffix vð- -wn ‘masculine plural’ and
one pronominal enclitic Aë+ +hA ‘it/her’. DAs dif-
fer from MSA phonologically, morphologically and
to a lesser degree syntactically. The morpholog-
ical differences are most noticeably expressed in
the use of clitics and affixes that do not exist in
MSA. For instance, the Levantine Arabic equivalent
of the MSA example above is AëñJ.-.ºJ�kð w+H+y-
ktb-w+hA ‘and they will write it’. The optionality
of vocalic diacritics helps hide some of the differ-
ences resulting from vowel changes; compare the
diacritized forms: Levantine wHayikitbuwhA and
MSA wasayaktubuwnahA.
All of the NLP challenges of MSA (e.g., optional
diacritics and spelling inconsistency) are shared by
DA. However, the lack of standard orthographies for
the dialects and their numerous varieties pose new
challenges. Additionally, DAs are rather impover-
ished in terms of available tools and resources com-
pared to MSA, e.g., there is very little parallel DA-
English corpora and almost no MSA-DA parallel
corpora. The number and sophistication of morpho-
logical analysis and disambiguation tools in DA is
very limited in comparison to MSA (Duh and Kirch-
hoff, 2005; Habash and Rambow, 2006; Abo Bakr et
al., 2008; Habash, 2010; Salloum and Habash, 2011;
Habash et al., 2012; Habash et al., 2013). MSA
tools cannot be effectively used to handle DA, e.g.,
Habash and Rambow (2006) report that over one-
third of Levantine verbs cannot be analyzed using
an MSA morphological analyzer.
</bodyText>
<page confidence="0.999461">
349
</page>
<sectionHeader confidence="0.99991" genericHeader="method">
4 Related Work
</sectionHeader>
<bodyText confidence="0.998800842105264">
Dialectal Arabic NLP. Several researchers have
explored the idea of exploiting existing MSA rich
resources to build tools for DA NLP (Chiang et al.,
2006). Such approaches typically expect the pres-
ence of tools/resources to relate DA words to their
MSA variants or translations. Given that DA and
MSA do not have much in terms of parallel cor-
pora, rule-based methods to translate DA-to-MSA
or other methods to collect word-pair lists have been
explored. For example, Abo Bakr et al. (2008) intro-
duced a hybrid approach to transfer a sentence from
Egyptian Arabic into MSA. This hybrid system con-
sisted of a statistical system for tokenizing and tag-
ging, and a rule-based system for constructing dia-
critized MSA sentences. Moreover, Al-Sabbagh and
Girju (2010) described an approach of mining the
web to build a DA-to-MSA lexicon. In the context
of DA-to-English SMT, Riesa and Yarowsky (2006)
presented a supervised algorithm for online mor-
pheme segmentation on DA that cut the OOV words
by half.
Machine Translation for Closely Related Lan-
guages. Using closely related languages has been
shown to improve MT quality when resources are
limited. Hajiˇc et al. (2000) argued that for very
close languages, e.g., Czech and Slovak, it is pos-
sible to obtain a better translation quality by using
simple methods such as morphological disambigua-
tion, transfer-based MT and word-for-word MT.
Zhang (1998) introduced a Cantonese-Mandarin MT
that uses transformational grammar rules. In the
context of Arabic dialect translation, Sawaf (2010)
built a hybrid MT system that uses both statistical
and rule-based approaches for DA-to-English MT.
In his approach, DA is normalized into MSA us-
ing a dialectal morphological analyzer. In previ-
ous work, we presented a rule-based DA-MSA sys-
tem to improve DA-to-English MT (Salloum and
Habash, 2011; Salloum and Habash, 2012). Our ap-
proach used a DA morphological analyzer (ADAM)
and a list of hand-written morphosyntactic transfer
rules. This use of “resource-rich” related languages
is a specific variant of the more general approach
of using pivot/bridge languages (Utiyama and Isa-
hara, 2007; Kumar et al., 2007). In the case of
MSA and DA variants, it is plausible to consider
the MSA variants of a DA phrase as monolingual
paraphrases (Callison-Burch et al., 2006; Du et al.,
2010). Also related is the work by Nakov and Ng
(2011), who use morphological knowledge to gener-
ate paraphrases for a morphologically rich language,
Malay, to extend the phrase table in a Malay-to-
English SMT system.
Pivoting on MSA or acquiring more DA-English
data? Zbib et al. (2012) demonstrated an approach
to cheaply obtaining DA-English data. They used
Amazon’s Mechanical Turk (MTurk) to create a DA-
English parallel corpus of 1.5M words and added it
to a 150M MSA-English parallel corpus to create the
training corpus of their SMT system. They also used
MTurk to translate their dialectal test set to MSA
in order to compare the MSA-pivoting approach to
the direct translation from DA to English approach.
They showed that even though pivoting on MSA
(produced by Human translators in an oracle experi-
ment) can reduce OOV rate to 0.98% from 2.27% for
direct translation (without pivoting), it improves by
4.91% BLEU while direct translation improves by
6.81% BLEU over their 12.29% BLEU baseline (di-
rect translation using the 150M MSA system). They
concluded that simple vocabulary coverage is not
sufficient and the domain mismatch is a more im-
portant problem. The approach we take in this paper
is orthogonal to such efforts to build parallel data.
We plan to study interactions between the two types
of solutions in the future.
Our work is most similar to Sawaf (2010)’s MSA-
pivoting approach. In his approach, DA is normal-
ized into MSA using character-based DA normal-
ization rules, a DA morphological analyzer, a DA
normalization decoder that relies on language mod-
els, and a lexicon. Similarly, we use some char-
acter normalization rules, a DA morphological an-
alyzer, and DA-MSA dictionaries. In contrast, we
use hand-written morphosyntactic transfer rules that
focus on translating DA morphemes and lemmas to
their MSA equivalents.
In our previous work (Salloum and Habash, 2011;
Salloum and Habash, 2012), we applied our ap-
proach to tokenized Arabic and our DA-MSA trans-
fer component used feature transfer rules only. We
did not use a language model to pick the best path;
instead we kept the ambiguity in the lattice and
passed it to our SMT system. In contrast, in this pa-
per, we run ELISSA on untokenized Arabic, we use
</bodyText>
<page confidence="0.980363">
350
</page>
<bodyText confidence="0.999912625">
feature, lemma, and surface form transfer rules, and
we pick the best path of the generated MSA lattice
through a language model.
Certain aspects of our approach are similar to
Riesa and Yarowsky (2006)’s, in that we use mor-
phological analysis for DA to help DA-English MT;
but unlike them, we use a rule-based approach to
model DA morphology.
</bodyText>
<sectionHeader confidence="0.994391" genericHeader="method">
5 ELISSA
</sectionHeader>
<bodyText confidence="0.99981537037037">
ELISSA is a DA-to-MSA MT System. ELISSA uses
a rule-based approach (with some statistical compo-
nents) that relies on the existence of a DA morpho-
logical analyzer, a list of hand-written transfer rules,
and DA-MSA dictionaries to create a mapping of
DA to MSA words and construct a lattice of pos-
sible sentences. ELISSA uses a language model to
rank and select the generated sentences.
ELISSA supports untokenized (raw) input only.
ELISSA supports three types of output: top-1 choice,
an n-best list or a map file that maps source
words/phrases to target phrases. The top-1 and n-
best lists are determined using an untokenized MSA
language model to rank the paths in the MSA trans-
lation output lattice. This variety of output types
makes it easy to plug ELISSA with other systems and
to use it as a DA preprocessing tool for other MSA
systems, e.g., MADA (Habash and Rambow, 2005)
or AMIRA (Diab et al., 2007).
ELISSA’s approach consists of three major steps
preceded by a preprocessing and normalization step,
that prepares the input text to be handled (e.g., UTF-
8 cleaning, Alif/Ya normalization, word-lengthening
normalization), and followed by a post-processing
step, that produces the output in the desired form
(e.g., encoding choice). The three major steps are
Selection, Translation, and Language Modeling.
</bodyText>
<subsectionHeader confidence="0.998255">
5.1 Selection
</subsectionHeader>
<bodyText confidence="0.998779">
In the first step, ELISSA identifies which words or
phrases to paraphrase and which words or phrases
to leave as is. ELISSA provides different methods
(techniques) for selection, and can be configured to
use different subsets of them. In Section 6 we use the
term &amp;quot;selection mode&amp;quot; to denote a subset of selec-
tion methods. Selection methods are classified into
Word-based selection and Phrase-based selection.
Word-based selection. Methods of this type fall
in the following categories:
</bodyText>
<listItem confidence="0.986470294117647">
a. User token-based selection: The user can mark
specific words for selection using the tag ‘/DIA’
(stands for ‘dialect’) after each word to select.
b. User type-based selection: The user can specify
a list of words to select from, e.g., OOVs. Also
the user can provide a list of words and their
frequencies and specify a cut-off threshold to
prevent selecting a frequent word.
c. Morphology-based word selection: ELISSA
uses ADAM (Salloum and Habash, 2011)
to select words that have DA analyses only
(DIAONLY) or DA/MSA analyses (DIAMSA).
d. Dictionary-based selection: ELISSA selects
words based on their existence in the DA side
of our DA-MSA dictionaries.
e. All: ELISSA selects every word in an input sen-
tence.
</listItem>
<bodyText confidence="0.986539083333334">
Phrase-based selection. This selection type uses
hand-written rules to identify dialectal multi-word
constructions that are mappable to single or multi-
word MSA constructions. The current count of these
rules is 25. Table 2 presents some rule categories
and related examples.
In the current version of ELISSA, words can
be selected using either the phrase-based selection
method or a word-based selection method, but not
both. Phrase-based selection has precedence. We
evaluate different settings for selection step in Sec-
tion 6.
</bodyText>
<subsectionHeader confidence="0.997774">
5.2 Translation
</subsectionHeader>
<bodyText confidence="0.999686538461538">
In this step, ELISSA translates the selected words
and phrases to their MSA equivalent paraphrases.
The specific type of selection determines the type of
the translation, e.g., phrase-based selected words are
translated using phrase-based translation rules. The
MSA paraphrases are then used to form an MSA lat-
tice.
Word-based translation. This category has two
types of translation techniques: surface transla-
tion that uses DA-to-MSA surface-to-surface (S2S)
transfer rules (TRs) and deep (morphological) trans-
lation that uses the classic rule-based machine trans-
lation flow: analysis, transfer and generation. The
</bodyText>
<page confidence="0.991944">
351
</page>
<table confidence="0.99978">
Rule Category Selection Examples Translation Examples
Dialectal Idafa A�J«A�JK. ú��æ£ñË@ LA_i�m.Ì @ Aljyš AlwTny btASnA ú��æ£ñË@ A�J :‚��k. jyšnA AlwTny
‘the-army the-national ours’ ‘our-army the-national’
Verb + �,ëAK� AêËQå�”k HDrlhA yAhn AêË ÑëQå;”k HDrhm lhA
flipped direct and indirect objects ‘he-prepared-for-her them’ ‘he-prepared-them for-her’
Special dialectal expressions AëAK�@ ðYK. bdw AyAhA AëYK�QK� yrydhA
‘his-desire her’ ‘he-desires-her’
Negation +verb ñËñJ.�JºJ éË @ñJ.:ºK� uËð wln yktbwA lh
k AÓð wmA Hyktbwlw ‘and-will-not they-write to-him’
‘and-not they-will-write-to-him’
Negation + agent noun &lt;J&amp;quot;¯B � fmš lAqyh Ys CU flA tjd
‘so-not finding’ ‘so-not she-finds’
Negation + closed-class words Õ»Y« AÓ mA Sdkm ÕºK�YË •�»Ë lys ldykm
‘not with-you’ ‘not with-you’
</table>
<tableCaption confidence="0.969143">
Table 2: Examples of some types of phrase-based selection and translation rules.
</tableCaption>
<table confidence="0.99986225">
DA Phrase Bñk@P AÓð wmA rAHwlA ‘And they did not go to her’
Analysis Word 1 Word 2
Proclitics [Lemma &amp; Features] [Lemma &amp; Features] [Lemma &amp; Features] Enclitic
w+ mA rAHw +l +A
conj+ [neg] [rAH PV subj:3MP] +prep +pron3FS
and+ not they go +to +her
Transfer Word 1 Word 2 Word 3
Proclitics [Lemma &amp; Features] [Lemma &amp; Features] [Lemma &amp; Features] Enclitic
conj+ [ lam ] [ðahab IV subj:3MP] [ Alý ] +pron3FS
and+ did not they go to +her
Generation w+ lm yðhbwA Aly +hA
MSA Phrase AîD�Ë@� @ñJ.ë .E ÕËð wlm yðhbwA ˇAlyhA ‘And they did not go to her’
</table>
<figureCaption confidence="0.9960885">
Figure 1: An example illustrating the analysis-transfer-generation steps to translate a dialectal multi-word expression
into its MSA equivalent phrase.
</figureCaption>
<bodyText confidence="0.999450551724138">
dialectal morphological analysis step uses ADAM
(Salloum and Habash, 2011) to get a list of di-
alectal analyses. The morphosyntactic transfer
step uses lemma-to-lemma (L2L) and features-to-
features (F2F) transfer rules to change lemmas, cl-
itics or features, and even split up the dialectal word
into multiple MSA word analyses (such as splitting
negation words and indirect objects). The MSA
morphological generation step uses the general to-
kenizer/generator TOKAN (Habash, 2007) to gen-
erate untokenized surface form words. For more de-
tails, see Salloum and Habash (2011).
Phrase-based translation. Unlike the word-
based translation techniques which map single DA
words to single or multi-word MSA sequences, this
technique uses hand-written multi-word transfer
rules that map multi-word DA constructions to
single or multi-word MSA constructions. In the
current system, there are 47 phrase-based transfer
rules. Many of the word-based morphosyntactic
transfer rules are re-used for phrase-based transla-
tion. Figure 1 shows an example of a phrase-based
morphological translation of the two-word DA
sequence Bñk@P AÓð wmA rAHwlA ‘And they did
not go to her’. If these two words were spelled as a
single word, Bñk@PAÓð wmArAHwlA, we would still
get the same result using the word-based translation
technique only. Table 2 shows some rule categories
along with selection and translation examples.
</bodyText>
<subsectionHeader confidence="0.993685">
5.3 Language Modeling
</subsectionHeader>
<bodyText confidence="0.99990375">
The language model (LM) component uses the
SRILM lattice-tool for weight assignment and n-
best decoding (Stolcke, 2002). ELISSA comes with
a default 5-gram LM file trained on —200M unto-
</bodyText>
<page confidence="0.981357">
352
</page>
<table confidence="0.999983666666667">
DA source 7 �HA�J��J�Óñ» 6 �áÊ�JªJ.K� 5 (èAK� �àYK.) Bð 4 (ñªJ.�K �éJ�’ j ~‚Ë@ éj�®’Ë@) 3 ¡J�j« 2 (ñËñJ.�JºJ�k AÓ) 1 (ø
Aë �éËAmÌ AîE.)
�
.12 YÊJ.ËA« 11 (hðQK� hP)10 A:Öß�@ 9 JñëQ{.�AÓ 8 ñ KB
(bhAlHAlh hAy)1 (mA Hyktbwlw)2 ςHyT3 (AlSfHh AlšxSyh tbςw)4 wlA (bdn yAh)5 ybςtln6 kwmyntAt7 lÂnw8
mAxbrhwn9 AymtA10 (rH yrwH)11 ςAlbld12.
Human Ref- In this case, they will not write on his profile wall and they do not want him to send them comments because he did
erence not tell them when he will go to the country.
Google Bhalhalh Hi Hictpoulo Ahat Profile Tbau not hull Weah Abatln Comintat Anu Mabarhun Oamta welcomed calls
Translate them Aalbuld.
ELISSA 6 (ÑîD�Ë@ ÉƒQK�) 5 ( à@ é�KðYK�QK�) Bð 4 (�éJ�’ j ~‚Ë@ é�Jj�®“) 3 (¡~Ag ú
DA-to-MSA Î«) 2 (éË @ñJ.�JºK� áË) 1 (�éËAmÌ @ è �Yë ú
�¯)
. 12 (YÊJ.Ë@ ú
Í@) 11 I. ë YJ
ƒ 10 ú
~æÓ 9 (ÑëQ�.�m� � ÕË) 8 é�KB 7 �HA�®J�Êª�K
(fy hðh AlHAlh)1 (ln yktbwA lh)2 (ςly HAˆyT)3 (SfHth AlšxSyh)4 wlA (yrydwnh An)5 (yrsl Alyhm)6 tςlyqAt7 lAnh8
(lm yxbrhm)9 mty10 syðhb11 (Aly Albld)12.
Google In this case it would not write to him on the wall of his own and do not want to send them comments that he did not
Translate tell them when going to the country.
</table>
<tableCaption confidence="0.997432">
Table 3: Revisiting our motivating example, but with ELISSA-based DA-to-MSA middle step. ELISSA’s output is
Alif/Ya normalized. Parentheses are added for illustrative reasons to highlight how multi-word DA constructions are
selected and translated. Superscript indices link the selected words and phrases with their MSA translations.
</tableCaption>
<bodyText confidence="0.9953962">
kenized Arabic words of Arabic Gigaword (Parker
et al., 2009). Users can specify their own LM file
and/or interpolate it with our default LM. This is
useful for adapting ELISSA’s output to the Arabic
side of the training data.
</bodyText>
<subsectionHeader confidence="0.995523">
5.4 Revisiting our Motivating Example
</subsectionHeader>
<bodyText confidence="0.999930111111111">
We revisit our motivating example in Section 2 and
show automatic MSA-pivoting through ELISSA. Ta-
ble 3 is divided into two parts. The first part is
copied from Table 1 for convenience. The second
part shows ELISSA’s output on the dialectal sentence
and its Google Translate translation. The produced
MSA is not perfect, but is clearly an improvement
over doing nothing as far as usability for MT into
English.
</bodyText>
<sectionHeader confidence="0.999125" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.9999174">
In this section, we present two evaluations of
ELISSA. The first is an extrinsic evaluation of
ELISSA as part of MSA-pivoting for DA-to-English
SMT. And the second is an intrinsic evaluation of
the quality of ELISSA’s MSA output.
</bodyText>
<subsectionHeader confidence="0.9055305">
6.1 DA-English MT Evaluation
6.1.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999983027777778">
We use the open-source Moses toolkit (Koehn
et al., 2007) to build a phrase-based SMT system
trained on mostly MSA data (64M words on the
Arabic side) obtained from several LDC corpora in-
cluding some limited DA data. Our system uses
a standard phrase-based architecture. The paral-
lel corpus is word-aligned using GIZA++ (Och and
Ney, 2003). Phrase translations of up to 10 words
are extracted in the Moses phrase table. The lan-
guage model for our system is trained on the En-
glish side of the bitext augmented with English Gi-
gaword (Graff and Cieri, 2003). We use a 5-gram
language model with modified Kneser-Ney smooth-
ing. Feature weights are tuned to maximize BLEU
on the NIST MTEval 2006 test set using Minimum
Error Rate Training (Och, 2003). This is only done
on the baseline systems. The English data is tok-
enized using simple punctuation-based rules. The
Arabic side is segmented according to the Arabic
Treebank (ATB) tokenization scheme (Maamouri et
al., 2004) using the MADA+TOKAN morphologi-
cal analyzer and tokenizer v3.1 (Habash and Ram-
bow, 2005; Roth et al., 2008). The Arabic text is
also Alif/Ya normalized. MADA-produced Arabic
lemmas are used for word alignment.
We use the same development (dev) and test sets
used by Salloum and Habash (2011) (we will call
them speech-dev and speech-test, respectively) and
we compare to them in the next sections. We also
evaluate on two web-crawled blind test sets: the
Levantine test set presented in Zbib et al. (2012) (we
will call it web-lev-test) and the Egyptian Dev-MT-
v2 development data of the DARPA BOLT program
(we will call it web-egy-test). The speech-dev set
has 1,496 sentences with 32,047 untokenized Arabic
words. The speech-test set has 1,568 sentences with
</bodyText>
<page confidence="0.998407">
353
</page>
<bodyText confidence="0.998328692307692">
32,492 untokenized Arabic words. The web-lev-
test set has 2,728 sentences with 21,179 untokenized
Arabic words. The web-egy-test set has 1,553 sen-
tences with 21,495 untokenized Arabic words. The
two speech test sets contain multi-dialect (e.g., Iraqi,
Levantine, Gulf, and Egyptian) broadcast conver-
sational (BC) segments (with three reference trans-
lations), and broadcast news (BN) segments (with
only one reference, replicated three times). The
web-egy-test has two references while the web-lev-
test has only one reference. Results are presented in
terms of BLEU (Papineni et al., 2002). All evalua-
tion results are case insensitive.
</bodyText>
<subsubsectionHeader confidence="0.732047">
6.1.2 Results on the Development Set
</subsubsectionHeader>
<bodyText confidence="0.999902390243902">
We experimented with different method combi-
nations in the selection and translation components
in ELISSA. We use the term selection mode and
translation mode to denote a certain combination
of methods in selection or translation, respectively.
Due to limited space, we only present the best se-
lection mode variation experiments. Other selection
modes were tried but they proved to be consistently
lower than the rest. The ‘F2F+L2L; S2S’ word-
based translation mode (using morphological trans-
fer of features and lemmas along with surface form
transfer) showed to be consistently better than other
method combinations across all selection modes. In
this paper we only use ‘F2F+L2L; S2S’ word-based
translation mode. Phrase-based translation mode is
used when phrase-based selection mode is used.
To rank paraphrases in the generated MSA lattice,
we combine two 5-gram untokenized Arabic lan-
guage models: one is trained on Arabic Gigaword
data and the other is trained the Arabic side of our
SMT training data. The use of the latter LM gave
frequent dialectal phrases a higher chance to appear
in ELISSA’s output; thus, making the output &amp;quot;more
dialectal&amp;quot; but adapting it to our SMT input. Exper-
iments showed that using both LMs is better than
using each one alone.
In all the experiments, we run the DA sentence
through ELISSA to generate a top-1 MSA transla-
tion, which we then tokenize through MADA be-
fore sending to the MSA-English SMT system. Our
baseline is to not run ELISSA at all; instead, we send
the DA sentence through MADA before applying
the MSA-English MT system.
Table 4 summarizes the experiments and results
on the dev set. The rows of the table are the dif-
ferent systems (baseline and ELISSA’s experiments).
All differences in BLEU scores from the baseline
are statistically significant above the 95% level. Sta-
tistical significance is computed using paired boot-
strap re-sampling (Koehn, 2004). The name of the
system in ELISSA’s experiments denotes the com-
bination of selection method. ELISSA’s experi-
ments are grouped into three groups: simple selec-
tion, frequency-based selection, and phrase-based
selection. Simple selection group consists of five
systems: OOV, ADAM, OOV U ADAM, DICT,
and OOV U ADAM U DICT. The OOV selection
mode identifies the untokenized OOV words. In
the ADAM selection mode, or the morphological
selection mode, we use ADAM to identify dialec-
tal words. Experiments showed that ADAM’s DI-
AMSA mode (selecting words that have at least one
dialectal analysis) is slightly better than ADAM’s
DIAONLY mode (selecting words that have only di-
alectal analyses and no MSA ones). The OOV U
ADAM selection mode is the union of the OOVs
and ADAM selection modes. In DICT selection
mode, we select dialectal words that exist in our DA-
MSA dictionaries. The OOV U ADAM U DICT
selection mode is the union of the OOVs, ADAM,
and DICT selection modes. The results show that
combining the output of OOV selection method and
ADAM selection method is the best. DICT selec-
tion method hurts the performance of the system
when used because dictionaries usually have fre-
quent dialectal words that the SMT system already
knows how to handle.
In the frequency-based selection group, we ex-
clude from word selection all words with number of
occurrences in the training data that is above a cer-
tain threshold. This threshold was determined em-
pirically to be 50. The string ‘- (Freq &gt;= 50)’ means
that all words with frequencies of 50 or more should
not be selected. The results show that excluding fre-
quent dialectal words improves the best simple se-
lection system. It also shows that using DICT selec-
tion improves the best system if frequent words are
excluded.
In the last system group, phrase+word-based se-
lection, phrase-based selection is used to select
phrases and add them on top of the best perform-
ers of the previous two groups. Phrase-based trans-
</bodyText>
<page confidence="0.99654">
354
</page>
<table confidence="0.999849769230769">
Test Set speech-dev
BLEU Diff.
Baseline 37.20 0.00
Select: OOV 37.75 0.55
Select: ADAM 37.88 0.68
Select: OOV U ADAM 37.89 0.69
Select: DICT 37.06 -0.14
Select: OOV U ADAM U DICT 37.53 0.33
Select: (OOV U ADAM) - (Freq &gt;= 50) 37.96 0.76
Select: (OOV U ADAM U DICT) - (Freq &gt;= 50) 38.00 0.80
Select: Phrase; (OOV U ADAM) 37.99 0.79
Select: Phrase; ((OOV U ADAM) - (Freq &gt;= 50)) 38.05 0.85
Select: Phrase; ((OOV U ADAM U DICT) - (Freq &gt;= 50)) 38.10 0.90
</table>
<tableCaption confidence="0.967108">
Table 4: Results for the speech-dev set in terms of BLEU. The ‘Diff.’ column shows result differences from the
baseline. The rows of the table are the different systems (baseline and ELISSA’s experiments). The name of the
system in ELISSA’s experiments denotes the combination of selection method. In all ELISSA’s experiments, all word-
based translation methods are tried. Phrase-based translation methods are used when phrase-based selection is used
(i.e., the last three rows). The best system is in bold.
</tableCaption>
<bodyText confidence="0.999617642857143">
lation is also added to word-based translation. Re-
sults show that selecting and translating phrases im-
prove the three best performers of word-based se-
lection. The best performer, shown in the last raw,
suggests using phrase-based selection and restricted
word-based selection. The restriction is to include
OOV words and selected low frequency words that
have at least one dialectal analysis or appear in our
dialectal dictionaries. Comparing the best performer
to the OOV selection mode system shows that trans-
lating low frequency in-vocabulary dialectal words
and phrases to their MSA paraphrases can improve
the English translation. This is a similar conclusion
to our previous work in Salloum and Habash (2011).
</bodyText>
<subsectionHeader confidence="0.506285">
6.1.3 Results on the Blind Test Sets
</subsectionHeader>
<bodyText confidence="0.999975117647059">
We run the system settings that performed best on
the dev set along with the OOV selection mode sys-
tem on the three blind test set. Results and their dif-
ferences from the baseline are reported in Table 5.
We see that OOV selection mode system always im-
proves over the baseline for all test sets. Also, the
best performer on the dev is the best performer for
all test sets. The improvements of the best per-
former over the OOV selection mode system on all
test sets confirm that translating low frequency in-
vocabulary dialectal words and phrases to their MSA
paraphrases can improve the English translation. Its
improvements over the baseline for the three test sets
are: 0.95% absolute BLEU (or 2.5% relative) for the
speech-test, 1.41% absolute BLEU (or 15.4% rela-
tive) for the web-lev-test, and 0.61% absolute BLEU
(or 3.2% relative) for the web-egy-test.
</bodyText>
<subsectionHeader confidence="0.929155">
6.1.4 A Case Study
</subsectionHeader>
<bodyText confidence="0.999101538461539">
We next examine an example in some detail.
Table 6 shows a dialectal sentence along with its
ELISSA’s translation, English references, the output
of the baseline system and the output of our best
system. The example shows a dialectal word 61lm
hAlmblγ ‘this-amount/sum’, which is not translated
by the baseline (although it appears in the training
data, but quite infrequently such that all of its phrase
table occurrences have restricted contexts, mak-
ing it effectively an OOV). The dialectal proclitic
+Jlm hAl+ ‘this-’ comes sometimes in the dialec-
tal construction: ‘hAl+NOUN DEM’ (as in this ex-
ample: IIA �Jlm hAlmblγ h6A ‘this-amount/sum
this’). ELISSA’s selection component captures this
multi-word expression and its translation component
produces the following paraphrases: tLdI IAA h6A
Almblγ ‘this amount/sum’ (h6A is used with mas-
culine singular nouns), tLdI o !A h6h Almblγ ‘this
amount/sum’ (h6h is used with feminine singular
or irrational plural nouns), and tLjI -ygm hwlA’
Almblγ ‘these amount/sum’ (hwlA’ is used with
rational plural nouns). ELISSA’s language mod-
eling component picks the first MSA paraphrase,
which perfectly fits the context and satisfies the
gender/number/rationality agreement (note that the
word Almblγ is an irrational masculine singular
</bodyText>
<page confidence="0.99577">
355
</page>
<table confidence="0.9998376">
Test Set speech-test web-lev-test web-egy-test
BLEU Diff. BLEU Diff. BLEU Diff.
Baseline 38.18 0.00 9.13 0.00 18.98 0.00
Select:OOV 38.76 0.58 9.65 0.62 19.19 0.21
Select: Phrase; ((OOV U ADAM U DICT) - (Freq &gt;= 50)) 39.13 0.95 10.54 1.41 19.59 0.61
</table>
<tableCaption confidence="0.990172">
Table 5: Results for the three blind test sets (table columns) in terms of BLEU. The ‘Diff.’ columns show result
differences from the baselines. The rows of the table are the different systems (baselines and ELISSA’s experiments).
The best systems are in bold.
</tableCaption>
<bodyText confidence="0.9992612">
noun). For more on Arabic morpho-syntactic agree-
ment patterns, see Alkuhlani and Habash (2011).
Finally, the best system translation for the selected
phrase is ‘this sum’. We can see how both the accu-
racy and fluency of the sentence have improved.
</bodyText>
<table confidence="0.988513857142857">
DA sentence fmA mA AtSwr hAlmbl-y hðA ySny.
ELISSA’s output fmA mA AtSwr hðA Almbl-y ySny.
References I don’t think this amount is I mean.
So I do not I do not think this cost I mean.
So I do not imagine this sum I mean
Baseline So i don’t think hAlmblg this means.
Best system So i don’t think this sum i mean.
</table>
<tableCaption confidence="0.976424">
Table 6: An example of handling dialectal words/phrases
using ELISSA and its effect on the accuracy and fluency
of the English translation. Words of interest are bolded.
</tableCaption>
<subsectionHeader confidence="0.998408">
6.2 DA-to-MSA Translation Quality
</subsectionHeader>
<bodyText confidence="0.999979214285714">
We conducted a manual error analysis comparing
ELISSA’s input (the original dev set) to its output
using our best system settings from the experiments
above. Out of 708 affected sentences, we randomly
selected 300 sentences (42%). Out of the 482 han-
dled tokens, 449 (93.15%) tokens have good MSA
translations, and 33 (6.85%) tokens have wrong
MSA translations. Most of the wrong translations
are due to spelling errors, proper nouns, and weak
input sentence fluency (especially due to speech ef-
fect). This analysis clearly validates ELISSA’s MSA
output. Of course, a correct MSA output can still be
mistranslated by the MT system we used above if it
is not in the vocabulary of the MT system.
</bodyText>
<sectionHeader confidence="0.99281" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999993828571428">
We presented ELISSA, a tool for DA-MSA transla-
tion. ELISSA employs a rule-based MT approach
that relies on morphological analysis, transfer rules
and dictionaries in addition to language models to
produce MSA paraphrases of dialectal sentences.
Using ELISSA to produce MSA versions of dialec-
tal sentences as part of an MSA-pivoting DA-to-
English MT solution, improves BLEU scores on
three blind test sets by: 0.95% absolute BLEU
(or 2.5% relative) for a speech multi-dialect (Iraqi,
Levantine, Gulf, Egyptian) test set, 1.41% absolute
BLEU (or 15.4% relative) for a web-crawled Levan-
tine test set, and 0.61% absolute BLEU (or 3.2% rel-
ative) for a web-crawled Egyptian test set. A man-
ual error analysis of translated selected words shows
that our system produces correct MSA translations
over 93% of the time.
In the future, we plan to extend ELISSA’s cover-
age of phenomena in the handled dialects and to new
dialects. We also plan to automatically learn addi-
tional rules from limited available data (DA-MSA
or DA-English). We also would like to do additional
MT experiments where we use ELISSA to prepro-
cess the training data, comparable to experiments
done by Sawaf (2010). We are interested in studying
how our approach can be combined with solutions
that simply add more dialectal training data since
the two directions are complementary in that they
address linguistic normalization and domain cov-
erage. Finally, we look forward to experimenting
with ELISSA as a preprocessing system for a variety
of dialect NLP applications similar to Chiang et al.
(2006)’s work on dialect parsing, for example.
ELISSA will be publicly available. Please contact
the authors for more information.
</bodyText>
<sectionHeader confidence="0.959274" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.998940571428571">
This paper is based upon work supported by
the Defense Advanced Research Projects Agency
(DARPA) under Contract No. HR0011-12-C-0014.
Any opinions, findings and conclusions or recom-
mendations expressed in this paper are those of the
authors and do not necessarily reflect the views of
DARPA.
</bodyText>
<page confidence="0.998081">
356
</page>
<sectionHeader confidence="0.990023" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999524981132075">
Hitham Abo Bakr, Khaled Shaalan, and Ibrahim Ziedan.
2008. A Hybrid Approach for Converting Written
Egyptian Colloquial Dialect into Diacritized Arabic.
In The 6th International Conference on Informatics
and Systems, INFOS2008. Cairo University.
Rania Al-Sabbagh and Roxana Girju. 2010. Mining the
Web for the Induction of a Dialectical Arabic Lexicon.
In Nicoletta Calzolari, Khalid Choukri, Bente Mae-
gaard, Joseph Mariani, Jan Odijk, Stelios Piperidis,
Mike Rosner, and Daniel Tapias, editors, LREC. Eu-
ropean Language Resources Association.
Sarah Alkuhlani and Nizar Habash. 2011. A Corpus
for Modeling Morpho-Syntactic Agreement in Ara-
bic: Gender, Number and Rationality. In Proceed-
ings of the 49th Annual Meeting of the Association for
Computational Linguistics (ACL’11), Portland, Ore-
gon, USA.
Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved statistical machine transla-
tion using paraphrases. In Proceedings of the Human
Language Technology Conference of the NAACL, Main
Conference, pages 17–24.
David Chiang, Mona Diab, Nizar Habash, Owen Ram-
bow, and Safiullah Shareef. 2006. Parsing Arabic
Dialects. In Proceedings of the European Chapter of
ACL (EACL).
Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2007.
Automated Methods for Processing Arabic Text: From
Tokenization to Base Phrase Chunking. In Antal
van den Bosch and Abdelhadi Soudi, editors, Arabic
Computational Morphology: Knowledge-based and
Empirical Methods. Kluwer/Springer.
Jinhua Du, Jie Jiang, and Andy Way. 2010. Facil-
itating translation using source language paraphrase
lattices. In Proceedings of the 2010 Conference
on Empirical Methods in Natural Language Process-
ing, EMNLP’10, pages 420–429, Cambridge, Mas-
sachusetts.
Kevin Duh and Katrin Kirchhoff. 2005. POS tagging of
dialectal Arabic: a minimally supervised approach. In
Proceedings of the ACL Workshop on Computational
Approaches to Semitic Languages, Semitic ’05, pages
55–62, Ann Arbor, Michigan.
David Graff and Christopher Cieri. 2003. English Gi-
gaword, LDC Catalog No.: LDC2003T05. Linguistic
Data Consortium, University of Pennsylvania.
Nizar Habash and Owen Rambow. 2005. Arabic Tok-
enization, Part-of-Speech Tagging and Morphological
Disambiguation in One Fell Swoop. In Proceedings of
the 43rd Annual Meeting of the Association for Com-
putational Linguistics (ACL’05), pages 573–580, Ann
Arbor, Michigan.
Nizar Habash and Owen Rambow. 2006. MAGEAD:
A Morphological Analyzer and Generator for the Ara-
bic Dialects. In Proceedings of the 21st International
Conference on Computational Linguistics and 44th
Annual Meeting of the Association for Computational
Linguistics, pages 681–688, Sydney, Australia.
Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.
2007. On Arabic Transliteration. In A. van den Bosch
and A. Soudi, editors, Arabic Computational Mor-
phology: Knowledge-based and Empirical Methods.
Springer.
Nizar Habash, Ramy Eskander, and Abdelati Hawwari.
2012. A Morphological Analyzer for Egyptian Ara-
bic. In Proceedings of the Twelfth Meeting of the Spe-
cial Interest Group on Computational Morphology and
Phonology, pages 1–9, Montréal, Canada.
Nizar Habash, Ryan Roth, Owen Rambow, Ramy Eskan-
der, and Nadi Tomeh. 2013. Morphological Analysis
and Disambiguation for Dialectal Arabic. In Proceed-
ings of the 2013 Conference of the North American
Chapter of the Association for Computational Linguis-
tics: Human Language Technologies (NAACL-HLT),
Atlanta, GA.
Nizar Habash. 2007. Arabic Morphological Representa-
tions for Machine Translation. In A. van den Bosch
and A. Soudi, editors, Arabic Computational Mor-
phology: Knowledge-based and Empirical Methods.
Springer.
Nizar Habash. 2010. Introduction to Arabic Natural
Language Processing. Morgan &amp; Claypool Publish-
ers.
Jan Hajiˇc, Jan Hric, and Vladislav Kubon. 2000. Ma-
chine Translation of Very Close Languages. In Pro-
ceedings of the 6th Applied Natural Language Pro-
cessing Conference (ANLP’2000), pages 7–12, Seat-
tle.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Christo-
pher Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine
Moran, Richard Zens, Christopher Dyer, Ondrej Bo-
jar, Alexandra Constantin, and Evan Herbst. 2007.
Moses: open source toolkit for statistical machine
translation. In Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguistics
Companion Volume Proceedings of the Demo and
Poster Sessions, pages 177–180, Prague, Czech Re-
public.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of
EMNLP 2004, pages 388–395, Barcelona, Spain, July.
Association for Computational Linguistics.
Shankar Kumar, Franz J. Och, and Wolfgang Macherey.
2007. Improving word alignment with bridge lan-
guages. In Proceedings of the 2007 Joint Conference
</reference>
<page confidence="0.976967">
357
</page>
<reference confidence="0.9998913625">
on Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL), pages 42–50, Prague, Czech Re-
public.
Mohamed Maamouri, Ann Bies, Tim Buckwalter, and
Wigdan Mekki. 2004. The Penn Arabic Treebank:
Building a Large-Scale Annotated Arabic Corpus. In
NEMLAR Conference on Arabic Language Resources
and Tools, pages 102–109, Cairo, Egypt.
Preslav Nakov and Hwee Tou Ng. 2011. Translat-
ing from Morphologically Complex Languages: A
Paraphrase-Based Approach. In Proceedings of the
Meeting of the Association for Computational Linguis-
tics (ACL’2011), Portland, Oregon, USA.
F. J. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational
Linguistics, 29(1):19–51.
Franz Josef Och. 2003. Minimum Error Rate Training
for Statistical Machine Translation. In Proceedings
of the 41st Annual Conference of the Association for
Computational Linguistics, pages 160–167, Sapporo,
Japan.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic Eval-
uation of Machine Translation. In Proceedings of the
40th Annual Meeting of the Association for Computa-
tional Linguistics, pages 311–318, Philadelphia, PA.
Robert Parker, David Graff, Ke Chen, Junbo Kong, and
Kazuaki Maeda. 2009. Arabic Gigaword Fourth Edi-
tion. LDC catalog number No. LDC2009T30, ISBN
1-58563-532-4.
Jason Riesa and David Yarowsky. 2006. Minimally Su-
pervised Morphological Segmentation with Applica-
tions to Machine Translation. In Proceedings of the
7th Conference of the Association for Machine Trans-
lation in the Americas (AMTA06), pages 185–192,
Cambridge,MA.
Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab,
and Cynthia Rudin. 2008. Arabic Morphological Tag-
ging, Diacritization, and Lemmatization Using Lex-
eme Models and Feature Ranking. In Proceedings of
ACL-08: HLT, Short Papers, pages 117–120, Colum-
bus, Ohio.
Wael Salloum and Nizar Habash. 2011. Dialectal
to Standard Arabic Paraphrasing to Improve Arabic-
English Statistical Machine Translation. In Proceed-
ings of the First Workshop on Algorithms and Re-
sources for Modelling of Dialects and Language Va-
rieties, pages 10–21, Edinburgh, Scotland.
Wael Salloum and Nizar Habash. 2012. Elissa: A Di-
alectal to Standard Arabic Machine Translation Sys-
tem. In Proceedings of the 24th International Confer-
ence on Computational Linguistics (COLING 2012):
Demonstration Papers, pages 385–392, Mumbai, In-
dia.
Hassan Sawaf. 2010. Arabic dialect handling in hybrid
machine translation. In Proceedings of the Confer-
ence of the Association for Machine Translation in the
Americas (AMTA), Denver, Colorado.
Andreas Stolcke. 2002. SRILM an Extensible Language
Modeling Toolkit. In Proceedings of the International
Conference on Spoken Language Processing.
Masao Utiyama and Hitoshi Isahara. 2007. A compar-
ison of pivot methods for phrase-based statistical ma-
chine translation. In HLT-NAACL, pages 484–491.
Rabih Zbib, Erika Malchiodi, Jacob Devlin, David
Stallard, Spyros Matsoukas, Richard Schwartz, John
Makhoul, Omar F. Zaidan, and Chris Callison-Burch.
2012. Machine Translation of Arabic Dialects. In Pro-
ceedings of the 2012 Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, pages 49–
59, Montréal, Canada, June. Association for Compu-
tational Linguistics.
Xiaoheng Zhang. 1998. Dialect MT: a case study be-
tween Cantonese and Mandarin. In Proceedings of the
36th Annual Meeting of the Association for Computa-
tional Linguistics and 17th International Conference
on Computational Linguistics, ACL ’98, pages 1460–
1464, Montreal, Canada.
</reference>
<page confidence="0.997929">
358
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.551301">
<title confidence="0.9808775">Dialectal Arabic to English Machine Pivoting through Modern Standard Arabic</title>
<author confidence="0.928763">Salloum</author>
<affiliation confidence="0.8127955">Center for Computational Learning Columbia</affiliation>
<email confidence="0.999833">wael@ccls.columbia.edu</email>
<email confidence="0.999833">habash@ccls.columbia.edu</email>
<abstract confidence="0.998758142857143">Modern Standard Arabic (MSA) has a wealth of natural language processing (NLP) tools and resources. In comparison, resources for dialectal Arabic (DA), the unstandardized spoken varieties of Arabic, are still lacking. We a machine translation (MT) for DA to MSA. a rule-based approach that relies on morphological analysis, transfer rules and dictionaries in addition to language models to produce paraphrases of DA sentences. can be employed as a general preprocessor for DA when using MSA NLP tools. A manerror analysis of output shows that it produces correct MSA translations over of the time. Using produce MSA versions of DA sentences as part of an MSA-pivoting DA-to-English MT solution, improves BLEU scores on multiple blind test sets between 0.6% and 1.4%.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hitham Abo Bakr</author>
<author>Khaled Shaalan</author>
<author>Ibrahim Ziedan</author>
</authors>
<title>A Hybrid Approach for Converting Written Egyptian Colloquial Dialect into Diacritized Arabic.</title>
<date>2008</date>
<booktitle>In The 6th International Conference on Informatics and Systems, INFOS2008.</booktitle>
<institution>Cairo University.</institution>
<contexts>
<context position="7874" citStr="Bakr et al., 2008" startWordPosition="1283" endWordPosition="1286">ubuwnahA. All of the NLP challenges of MSA (e.g., optional diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DAEnglish corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 349 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have </context>
</contexts>
<marker>Bakr, Shaalan, Ziedan, 2008</marker>
<rawString>Hitham Abo Bakr, Khaled Shaalan, and Ibrahim Ziedan. 2008. A Hybrid Approach for Converting Written Egyptian Colloquial Dialect into Diacritized Arabic. In The 6th International Conference on Informatics and Systems, INFOS2008. Cairo University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rania Al-Sabbagh</author>
<author>Roxana Girju</author>
</authors>
<title>Mining the Web for the Induction of a Dialectical Arabic Lexicon.</title>
<date>2010</date>
<editor>In Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel Tapias, editors, LREC. European</editor>
<contexts>
<context position="8920" citStr="Al-Sabbagh and Girju (2010)" startWordPosition="1455" endWordPosition="1458"> (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translate DA-to-MSA or other methods to collect word-pair lists have been explored. For example, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. This hybrid system consisted of a statistical system for tokenizing and tagging, and a rule-based system for constructing diacritized MSA sentences. Moreover, Al-Sabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. In the context of DA-to-English SMT, Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut the OOV words by half. Machine Translation for Closely Related Languages. Using closely related languages has been shown to improve MT quality when resources are limited. Hajiˇc et al. (2000) argued that for very close languages, e.g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based </context>
</contexts>
<marker>Al-Sabbagh, Girju, 2010</marker>
<rawString>Rania Al-Sabbagh and Roxana Girju. 2010. Mining the Web for the Induction of a Dialectical Arabic Lexicon. In Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel Tapias, editors, LREC. European Language Resources Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarah Alkuhlani</author>
<author>Nizar Habash</author>
</authors>
<title>A Corpus for Modeling Morpho-Syntactic Agreement in Arabic: Gender, Number and Rationality.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL’11),</booktitle>
<location>Portland, Oregon, USA.</location>
<contexts>
<context position="33162" citStr="Alkuhlani and Habash (2011)" startWordPosition="5389" endWordPosition="5392">asculine singular 355 Test Set speech-test web-lev-test web-egy-test BLEU Diff. BLEU Diff. BLEU Diff. Baseline 38.18 0.00 9.13 0.00 18.98 0.00 Select:OOV 38.76 0.58 9.65 0.62 19.19 0.21 Select: Phrase; ((OOV U ADAM U DICT) - (Freq &gt;= 50)) 39.13 0.95 10.54 1.41 19.59 0.61 Table 5: Results for the three blind test sets (table columns) in terms of BLEU. The ‘Diff.’ columns show result differences from the baselines. The rows of the table are the different systems (baselines and ELISSA’s experiments). The best systems are in bold. noun). For more on Arabic morpho-syntactic agreement patterns, see Alkuhlani and Habash (2011). Finally, the best system translation for the selected phrase is ‘this sum’. We can see how both the accuracy and fluency of the sentence have improved. DA sentence fmA mA AtSwr hAlmbl-y hðA ySny. ELISSA’s output fmA mA AtSwr hðA Almbl-y ySny. References I don’t think this amount is I mean. So I do not I do not think this cost I mean. So I do not imagine this sum I mean Baseline So i don’t think hAlmblg this means. Best system So i don’t think this sum i mean. Table 6: An example of handling dialectal words/phrases using ELISSA and its effect on the accuracy and fluency of the English transla</context>
</contexts>
<marker>Alkuhlani, Habash, 2011</marker>
<rawString>Sarah Alkuhlani and Nizar Habash. 2011. A Corpus for Modeling Morpho-Syntactic Agreement in Arabic: Gender, Number and Rationality. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL’11), Portland, Oregon, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Miles Osborne</author>
</authors>
<title>Improved statistical machine translation using paraphrases.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,</booktitle>
<pages>17--24</pages>
<contexts>
<context position="10460" citStr="Callison-Burch et al., 2006" startWordPosition="1699" endWordPosition="1702">MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich language, Malay, to extend the phrase table in a Malay-toEnglish SMT system. Pivoting on MSA or acquiring more DA-English data? Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data. They used Amazon’s Mechanical Turk (MTurk) to create a DAEnglish parallel corpus of 1.5M words and added it to a 150M MSA-English parallel corpus to create the training corpus of their SMT system. They also used MTurk to translate their d</context>
</contexts>
<marker>Callison-Burch, Koehn, Osborne, 2006</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006. Improved statistical machine translation using paraphrases. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 17–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Mona Diab</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Safiullah Shareef</author>
</authors>
<title>Parsing Arabic Dialects.</title>
<date>2006</date>
<booktitle>In Proceedings of the European Chapter of ACL (EACL).</booktitle>
<contexts>
<context position="8315" citStr="Chiang et al., 2006" startWordPosition="1356" endWordPosition="1359">phistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 349 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translate DA-to-MSA or other methods to collect word-pair lists have been explored. For example, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. This hybrid system consisted of a statistical system for tokenizing and tagging, and a rule-based system for constructing diacritized MSA sentences. Moreover, Al-Sabbagh and Girju (</context>
</contexts>
<marker>Chiang, Diab, Habash, Rambow, Shareef, 2006</marker>
<rawString>David Chiang, Mona Diab, Nizar Habash, Owen Rambow, and Safiullah Shareef. 2006. Parsing Arabic Dialects. In Proceedings of the European Chapter of ACL (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Kadri Hacioglu</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automated Methods for Processing Arabic Text: From Tokenization to Base Phrase Chunking.</title>
<date>2007</date>
<booktitle>In Antal van den Bosch and Abdelhadi Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Methods.</booktitle>
<publisher>Kluwer/Springer.</publisher>
<contexts>
<context position="13972" citStr="Diab et al., 2007" startWordPosition="2294" endWordPosition="2297">of possible sentences. ELISSA uses a language model to rank and select the generated sentences. ELISSA supports untokenized (raw) input only. ELISSA supports three types of output: top-1 choice, an n-best list or a map file that maps source words/phrases to target phrases. The top-1 and nbest lists are determined using an untokenized MSA language model to rank the paths in the MSA translation output lattice. This variety of output types makes it easy to plug ELISSA with other systems and to use it as a DA preprocessing tool for other MSA systems, e.g., MADA (Habash and Rambow, 2005) or AMIRA (Diab et al., 2007). ELISSA’s approach consists of three major steps preceded by a preprocessing and normalization step, that prepares the input text to be handled (e.g., UTF8 cleaning, Alif/Ya normalization, word-lengthening normalization), and followed by a post-processing step, that produces the output in the desired form (e.g., encoding choice). The three major steps are Selection, Translation, and Language Modeling. 5.1 Selection In the first step, ELISSA identifies which words or phrases to paraphrase and which words or phrases to leave as is. ELISSA provides different methods (techniques) for selection, a</context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2007</marker>
<rawString>Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2007. Automated Methods for Processing Arabic Text: From Tokenization to Base Phrase Chunking. In Antal van den Bosch and Abdelhadi Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Methods. Kluwer/Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinhua Du</author>
<author>Jie Jiang</author>
<author>Andy Way</author>
</authors>
<title>Facilitating translation using source language paraphrase lattices.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP’10,</booktitle>
<pages>420--429</pages>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="10478" citStr="Du et al., 2010" startWordPosition="1703" endWordPosition="1706">ogical analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich language, Malay, to extend the phrase table in a Malay-toEnglish SMT system. Pivoting on MSA or acquiring more DA-English data? Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data. They used Amazon’s Mechanical Turk (MTurk) to create a DAEnglish parallel corpus of 1.5M words and added it to a 150M MSA-English parallel corpus to create the training corpus of their SMT system. They also used MTurk to translate their dialectal test set </context>
</contexts>
<marker>Du, Jiang, Way, 2010</marker>
<rawString>Jinhua Du, Jie Jiang, and Andy Way. 2010. Facilitating translation using source language paraphrase lattices. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP’10, pages 420–429, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Duh</author>
<author>Katrin Kirchhoff</author>
</authors>
<title>POS tagging of dialectal Arabic: a minimally supervised approach.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages, Semitic ’05,</booktitle>
<pages>55--62</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="7826" citStr="Duh and Kirchhoff, 2005" startWordPosition="1273" endWordPosition="1277">itized forms: Levantine wHayikitbuwhA and MSA wasayaktubuwnahA. All of the NLP challenges of MSA (e.g., optional diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DAEnglish corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 349 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or </context>
</contexts>
<marker>Duh, Kirchhoff, 2005</marker>
<rawString>Kevin Duh and Katrin Kirchhoff. 2005. POS tagging of dialectal Arabic: a minimally supervised approach. In Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages, Semitic ’05, pages 55–62, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Graff</author>
<author>Christopher Cieri</author>
</authors>
<date>2003</date>
<booktitle>English Gigaword, LDC Catalog No.: LDC2003T05. Linguistic Data</booktitle>
<institution>Consortium, University of Pennsylvania.</institution>
<contexts>
<context position="22969" citStr="Graff and Cieri, 2003" startWordPosition="3728" endWordPosition="3731">s MSA output. 6.1 DA-English MT Evaluation 6.1.1 Experimental Setup We use the open-source Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system trained on mostly MSA data (64M words on the Arabic side) obtained from several LDC corpora including some limited DA data. Our system uses a standard phrase-based architecture. The parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003). Phrase translations of up to 10 words are extracted in the Moses phrase table. The language model for our system is trained on the English side of the bitext augmented with English Gigaword (Graff and Cieri, 2003). We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. The English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Habash and Rambow, 2005; Roth et al., 2008). The Arabic text is also Alif/Ya normalized. MADA-produced Arabic lemmas are </context>
</contexts>
<marker>Graff, Cieri, 2003</marker>
<rawString>David Graff and Christopher Cieri. 2003. English Gigaword, LDC Catalog No.: LDC2003T05. Linguistic Data Consortium, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>573--580</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="13943" citStr="Habash and Rambow, 2005" startWordPosition="2288" endWordPosition="2291"> MSA words and construct a lattice of possible sentences. ELISSA uses a language model to rank and select the generated sentences. ELISSA supports untokenized (raw) input only. ELISSA supports three types of output: top-1 choice, an n-best list or a map file that maps source words/phrases to target phrases. The top-1 and nbest lists are determined using an untokenized MSA language model to rank the paths in the MSA translation output lattice. This variety of output types makes it easy to plug ELISSA with other systems and to use it as a DA preprocessing tool for other MSA systems, e.g., MADA (Habash and Rambow, 2005) or AMIRA (Diab et al., 2007). ELISSA’s approach consists of three major steps preceded by a preprocessing and normalization step, that prepares the input text to be handled (e.g., UTF8 cleaning, Alif/Ya normalization, word-lengthening normalization), and followed by a post-processing step, that produces the output in the desired form (e.g., encoding choice). The three major steps are Selection, Translation, and Language Modeling. 5.1 Selection In the first step, ELISSA identifies which words or phrases to paraphrase and which words or phrases to leave as is. ELISSA provides different methods </context>
<context position="23471" citStr="Habash and Rambow, 2005" startWordPosition="3808" endWordPosition="3812">model for our system is trained on the English side of the bitext augmented with English Gigaword (Graff and Cieri, 2003). We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. The English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Habash and Rambow, 2005; Roth et al., 2008). The Arabic text is also Alif/Ya normalized. MADA-produced Arabic lemmas are used for word alignment. We use the same development (dev) and test sets used by Salloum and Habash (2011) (we will call them speech-dev and speech-test, respectively) and we compare to them in the next sections. We also evaluate on two web-crawled blind test sets: the Levantine test set presented in Zbib et al. (2012) (we will call it web-lev-test) and the Egyptian Dev-MTv2 development data of the DARPA BOLT program (we will call it web-egy-test). The speech-dev set has 1,496 sentences with 32,04</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 573–580, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>MAGEAD: A Morphological Analyzer and Generator for the Arabic Dialects.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>681--688</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="7851" citStr="Habash and Rambow, 2006" startWordPosition="1278" endWordPosition="1281">HayikitbuwhA and MSA wasayaktubuwnahA. All of the NLP challenges of MSA (e.g., optional diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DAEnglish corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 349 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that </context>
</contexts>
<marker>Habash, Rambow, 2006</marker>
<rawString>Nizar Habash and Owen Rambow. 2006. MAGEAD: A Morphological Analyzer and Generator for the Arabic Dialects. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 681–688, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Abdelhadi Soudi</author>
<author>Tim Buckwalter</author>
</authors>
<title>On Arabic Transliteration.</title>
<date>2007</date>
<booktitle>Arabic Computational Morphology: Knowledge-based and Empirical Methods.</booktitle>
<editor>In A. van den Bosch and A. Soudi, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="6517" citStr="Habash et al., 2007" startWordPosition="1064" endWordPosition="1067">n formal settings; and DAs, the commonly used informal native varieties, which have no standard orthographies but have an increasing presence on the web. Arabic, in general, is a morphologically complex language which has rich inflectional morphology, expressed both templatically and affixationally, and several classes of attachable clitics. For example, the Arabic word Aî�EñJ.�JºJ ƒð w+s+y-ktb-wn+hA2 ‘and they will write it’ has two proclitics (+ð w+ ‘and’ and +€ s+ ‘will’), one prefix -ø y- ‘3rd 2Arabic transliteration throughout the paper is presented in the Habash-Soudi-Buckwalter scheme (Habash et al., 2007): (in alphabetical order) AbtOjHxd6rzsšSDT ˇDS-yfqklmnhwy and the additional symbols: ’ Z, Â �@, Aˇ @�, A¯ �@, wˆ j , yˆ Zø , h o, ý ø. person’, one suffix vð- -wn ‘masculine plural’ and one pronominal enclitic Aë+ +hA ‘it/her’. DAs differ from MSA phonologically, morphologically and to a lesser degree syntactically. The morphological differences are most noticeably expressed in the use of clitics and affixes that do not exist in MSA. For instance, the Levantine Arabic equivalent of the MSA example above is AëñJ.-.ºJ�kð w+H+yktb-w+hA ‘and they will write it’. The optionality of vocalic diacrit</context>
</contexts>
<marker>Habash, Soudi, Buckwalter, 2007</marker>
<rawString>Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter. 2007. On Arabic Transliteration. In A. van den Bosch and A. Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Methods. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ramy Eskander</author>
<author>Abdelati Hawwari</author>
</authors>
<title>A Morphological Analyzer for Egyptian Arabic.</title>
<date>2012</date>
<booktitle>In Proceedings of the Twelfth Meeting of the Special Interest Group on Computational Morphology and Phonology,</booktitle>
<pages>1--9</pages>
<location>Montréal, Canada.</location>
<contexts>
<context position="7935" citStr="Habash et al., 2012" startWordPosition="1293" endWordPosition="1296">diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DAEnglish corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 349 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to tran</context>
</contexts>
<marker>Habash, Eskander, Hawwari, 2012</marker>
<rawString>Nizar Habash, Ramy Eskander, and Abdelati Hawwari. 2012. A Morphological Analyzer for Egyptian Arabic. In Proceedings of the Twelfth Meeting of the Special Interest Group on Computational Morphology and Phonology, pages 1–9, Montréal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ryan Roth</author>
<author>Owen Rambow</author>
<author>Ramy Eskander</author>
<author>Nadi Tomeh</author>
</authors>
<title>Morphological Analysis and Disambiguation for Dialectal Arabic.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<location>Atlanta, GA.</location>
<contexts>
<context position="7957" citStr="Habash et al., 2013" startWordPosition="1297" endWordPosition="1300">ng inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DAEnglish corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 349 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translate DA-to-MSA or oth</context>
</contexts>
<marker>Habash, Roth, Rambow, Eskander, Tomeh, 2013</marker>
<rawString>Nizar Habash, Ryan Roth, Owen Rambow, Ramy Eskander, and Nadi Tomeh. 2013. Morphological Analysis and Disambiguation for Dialectal Arabic. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), Atlanta, GA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Arabic Morphological Representations for Machine Translation.</title>
<date>2007</date>
<booktitle>Arabic Computational Morphology: Knowledge-based and Empirical Methods.</booktitle>
<editor>In A. van den Bosch and A. Soudi, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="18798" citStr="Habash, 2007" startWordPosition="3031" endWordPosition="3032">mple illustrating the analysis-transfer-generation steps to translate a dialectal multi-word expression into its MSA equivalent phrase. dialectal morphological analysis step uses ADAM (Salloum and Habash, 2011) to get a list of dialectal analyses. The morphosyntactic transfer step uses lemma-to-lemma (L2L) and features-tofeatures (F2F) transfer rules to change lemmas, clitics or features, and even split up the dialectal word into multiple MSA word analyses (such as splitting negation words and indirect objects). The MSA morphological generation step uses the general tokenizer/generator TOKAN (Habash, 2007) to generate untokenized surface form words. For more details, see Salloum and Habash (2011). Phrase-based translation. Unlike the wordbased translation techniques which map single DA words to single or multi-word MSA sequences, this technique uses hand-written multi-word transfer rules that map multi-word DA constructions to single or multi-word MSA constructions. In the current system, there are 47 phrase-based transfer rules. Many of the word-based morphosyntactic transfer rules are re-used for phrase-based translation. Figure 1 shows an example of a phrase-based morphological translation o</context>
</contexts>
<marker>Habash, 2007</marker>
<rawString>Nizar Habash. 2007. Arabic Morphological Representations for Machine Translation. In A. van den Bosch and A. Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Methods. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Introduction to Arabic Natural Language Processing.</title>
<date>2010</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="7888" citStr="Habash, 2010" startWordPosition="1287" endWordPosition="1288">e NLP challenges of MSA (e.g., optional diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DAEnglish corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 349 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms </context>
</contexts>
<marker>Habash, 2010</marker>
<rawString>Nizar Habash. 2010. Introduction to Arabic Natural Language Processing. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Jan Hric</author>
<author>Vladislav Kubon</author>
</authors>
<title>Machine Translation of Very Close Languages.</title>
<date>2000</date>
<booktitle>In Proceedings of the 6th Applied Natural Language Processing Conference (ANLP’2000),</booktitle>
<pages>7--12</pages>
<location>Seattle.</location>
<marker>Hajiˇc, Hric, Kubon, 2000</marker>
<rawString>Jan Hajiˇc, Jan Hric, and Vladislav Kubon. 2000. Machine Translation of Very Close Languages. In Proceedings of the 6th Applied Natural Language Processing Conference (ANLP’2000), pages 7–12, Seattle.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Christopher Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Christopher Dyer</author>
<author>Ondrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="22472" citStr="Koehn et al., 2007" startWordPosition="3641" endWordPosition="3644">is copied from Table 1 for convenience. The second part shows ELISSA’s output on the dialectal sentence and its Google Translate translation. The produced MSA is not perfect, but is clearly an improvement over doing nothing as far as usability for MT into English. 6 Evaluation In this section, we present two evaluations of ELISSA. The first is an extrinsic evaluation of ELISSA as part of MSA-pivoting for DA-to-English SMT. And the second is an intrinsic evaluation of the quality of ELISSA’s MSA output. 6.1 DA-English MT Evaluation 6.1.1 Experimental Setup We use the open-source Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system trained on mostly MSA data (64M words on the Arabic side) obtained from several LDC corpora including some limited DA data. Our system uses a standard phrase-based architecture. The parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003). Phrase translations of up to 10 words are extracted in the Moses phrase table. The language model for our system is trained on the English side of the bitext augmented with English Gigaword (Graff and Cieri, 2003). We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maxim</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Christopher Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Christopher Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177–180, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP 2004,</booktitle>
<pages>388--395</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="26724" citStr="Koehn, 2004" startWordPosition="4331" endWordPosition="4332">e DA sentence through ELISSA to generate a top-1 MSA translation, which we then tokenize through MADA before sending to the MSA-English SMT system. Our baseline is to not run ELISSA at all; instead, we send the DA sentence through MADA before applying the MSA-English MT system. Table 4 summarizes the experiments and results on the dev set. The rows of the table are the different systems (baseline and ELISSA’s experiments). All differences in BLEU scores from the baseline are statistically significant above the 95% level. Statistical significance is computed using paired bootstrap re-sampling (Koehn, 2004). The name of the system in ELISSA’s experiments denotes the combination of selection method. ELISSA’s experiments are grouped into three groups: simple selection, frequency-based selection, and phrase-based selection. Simple selection group consists of five systems: OOV, ADAM, OOV U ADAM, DICT, and OOV U ADAM U DICT. The OOV selection mode identifies the untokenized OOV words. In the ADAM selection mode, or the morphological selection mode, we use ADAM to identify dialectal words. Experiments showed that ADAM’s DIAMSA mode (selecting words that have at least one dialectal analysis) is slightl</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical significance tests for machine translation evaluation. In Proceedings of EMNLP 2004, pages 388–395, Barcelona, Spain, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
<author>Franz J Och</author>
<author>Wolfgang Macherey</author>
</authors>
<title>Improving word alignment with bridge languages.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>42--50</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="10307" citStr="Kumar et al., 2007" startWordPosition="1672" endWordPosition="1675">2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich language, Malay, to extend the phrase table in a Malay-toEnglish SMT system. Pivoting on MSA or acquiring more DA-English data? Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data. They used Amazon’s Mechanical Turk (MTurk) to create a DAEnglish parallel corpus of 1</context>
</contexts>
<marker>Kumar, Och, Macherey, 2007</marker>
<rawString>Shankar Kumar, Franz J. Och, and Wolfgang Macherey. 2007. Improving word alignment with bridge languages. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 42–50, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Tim Buckwalter</author>
<author>Wigdan Mekki</author>
</authors>
<title>The Penn Arabic Treebank: Building a Large-Scale Annotated Arabic Corpus.</title>
<date>2004</date>
<booktitle>In NEMLAR Conference on Arabic Language Resources and Tools,</booktitle>
<pages>102--109</pages>
<location>Cairo, Egypt.</location>
<contexts>
<context position="23383" citStr="Maamouri et al., 2004" startWordPosition="3795" endWordPosition="3798">e translations of up to 10 words are extracted in the Moses phrase table. The language model for our system is trained on the English side of the bitext augmented with English Gigaword (Graff and Cieri, 2003). We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. The English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Habash and Rambow, 2005; Roth et al., 2008). The Arabic text is also Alif/Ya normalized. MADA-produced Arabic lemmas are used for word alignment. We use the same development (dev) and test sets used by Salloum and Habash (2011) (we will call them speech-dev and speech-test, respectively) and we compare to them in the next sections. We also evaluate on two web-crawled blind test sets: the Levantine test set presented in Zbib et al. (2012) (we will call it web-lev-test) and the Egyptian Dev-MTv2 development data of the DARPA BOLT p</context>
</contexts>
<marker>Maamouri, Bies, Buckwalter, Mekki, 2004</marker>
<rawString>Mohamed Maamouri, Ann Bies, Tim Buckwalter, and Wigdan Mekki. 2004. The Penn Arabic Treebank: Building a Large-Scale Annotated Arabic Corpus. In NEMLAR Conference on Arabic Language Resources and Tools, pages 102–109, Cairo, Egypt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Translating from Morphologically Complex Languages: A Paraphrase-Based Approach.</title>
<date>2011</date>
<booktitle>In Proceedings of the Meeting of the Association for Computational Linguistics (ACL’2011),</booktitle>
<location>Portland, Oregon, USA.</location>
<contexts>
<context position="10527" citStr="Nakov and Ng (2011)" startWordPosition="1713" endWordPosition="1716">d a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich language, Malay, to extend the phrase table in a Malay-toEnglish SMT system. Pivoting on MSA or acquiring more DA-English data? Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data. They used Amazon’s Mechanical Turk (MTurk) to create a DAEnglish parallel corpus of 1.5M words and added it to a 150M MSA-English parallel corpus to create the training corpus of their SMT system. They also used MTurk to translate their dialectal test set to MSA in order to compare the MSA-pivoting appro</context>
</contexts>
<marker>Nakov, Ng, 2011</marker>
<rawString>Preslav Nakov and Hwee Tou Ng. 2011. Translating from Morphologically Complex Languages: A Paraphrase-Based Approach. In Proceedings of the Meeting of the Association for Computational Linguistics (ACL’2011), Portland, Oregon, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="22754" citStr="Och and Ney, 2003" startWordPosition="3688" endWordPosition="3691">is section, we present two evaluations of ELISSA. The first is an extrinsic evaluation of ELISSA as part of MSA-pivoting for DA-to-English SMT. And the second is an intrinsic evaluation of the quality of ELISSA’s MSA output. 6.1 DA-English MT Evaluation 6.1.1 Experimental Setup We use the open-source Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system trained on mostly MSA data (64M words on the Arabic side) obtained from several LDC corpora including some limited DA data. Our system uses a standard phrase-based architecture. The parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003). Phrase translations of up to 10 words are extracted in the Moses phrase table. The language model for our system is trained on the English side of the bitext augmented with English Gigaword (Graff and Cieri, 2003). We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. The English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization s</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum Error Rate Training for Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Conference of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="23159" citStr="Och, 2003" startWordPosition="3762" endWordPosition="3763">the Arabic side) obtained from several LDC corpora including some limited DA data. Our system uses a standard phrase-based architecture. The parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003). Phrase translations of up to 10 words are extracted in the Moses phrase table. The language model for our system is trained on the English side of the bitext augmented with English Gigaword (Graff and Cieri, 2003). We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. The English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Habash and Rambow, 2005; Roth et al., 2008). The Arabic text is also Alif/Ya normalized. MADA-produced Arabic lemmas are used for word alignment. We use the same development (dev) and test sets used by Salloum and Habash (2011) (we will call them speech-dev and speech-test, respectively) and we compare to them</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum Error Rate Training for Statistical Machine Translation. In Proceedings of the 41st Annual Conference of the Association for Computational Linguistics, pages 160–167, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="2430" citStr="Papineni et al., 2002" startWordPosition="375" endWordPosition="379">structions (phrases) in a source sentence. Then, ELISSA produces MSA paraphrases for the selected words and phrase using a rule-based component that depends on the existence of a dialectal morphological analyzer, a list of morphosyntactic transfer rules, and DA-MSA dictionaries. The resulting MSA is in a lattice form that we pass to a language model for nbest decoding. The output of ELISSA, whether a top1 choice sentence or n-best sentences, is passed to an MSA-English SMT system to produce the English translation sentence. ELISSA-based MSA-pivoting for DA-to-English SMT improves BLEU scores (Papineni et al., 2002) on three blind test sets between 0.6% and 1.4%. A manual error analysis of translated words shows that ELISSA produces correct MSA translations over 93% of the time. The rest of this paper is structured as follows: Section 2 motivates the use of ELISSA to improve DA-English SMT with an example. Section 3 discusses some of the challenges associated with processing Arabic and its dialects. Section 4 presents related work. Section 5 details ELISSA and its approach and Section 6 presents results evaluating ELISSA under a variety of conditions. 2 Motivating Example Table 1 shows a motivating examp</context>
<context position="24734" citStr="Papineni et al., 2002" startWordPosition="4007" endWordPosition="4010">st set has 1,568 sentences with 353 32,492 untokenized Arabic words. The web-levtest set has 2,728 sentences with 21,179 untokenized Arabic words. The web-egy-test set has 1,553 sentences with 21,495 untokenized Arabic words. The two speech test sets contain multi-dialect (e.g., Iraqi, Levantine, Gulf, and Egyptian) broadcast conversational (BC) segments (with three reference translations), and broadcast news (BN) segments (with only one reference, replicated three times). The web-egy-test has two references while the web-levtest has only one reference. Results are presented in terms of BLEU (Papineni et al., 2002). All evaluation results are case insensitive. 6.1.2 Results on the Development Set We experimented with different method combinations in the selection and translation components in ELISSA. We use the term selection mode and translation mode to denote a certain combination of methods in selection or translation, respectively. Due to limited space, we only present the best selection mode variation experiments. Other selection modes were tried but they proved to be consistently lower than the rest. The ‘F2F+L2L; S2S’ wordbased translation mode (using morphological transfer of features and lemmas</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Parker</author>
<author>David Graff</author>
<author>Ke Chen</author>
<author>Junbo Kong</author>
<author>Kazuaki Maeda</author>
</authors>
<date>2009</date>
<booktitle>Arabic Gigaword Fourth Edition. LDC catalog number No. LDC2009T30, ISBN</booktitle>
<pages>1--58563</pages>
<contexts>
<context position="21504" citStr="Parker et al., 2009" startWordPosition="3481" endWordPosition="3484">lyqAt7 lAnh8 (lm yxbrhm)9 mty10 syðhb11 (Aly Albld)12. Google In this case it would not write to him on the wall of his own and do not want to send them comments that he did not Translate tell them when going to the country. Table 3: Revisiting our motivating example, but with ELISSA-based DA-to-MSA middle step. ELISSA’s output is Alif/Ya normalized. Parentheses are added for illustrative reasons to highlight how multi-word DA constructions are selected and translated. Superscript indices link the selected words and phrases with their MSA translations. kenized Arabic words of Arabic Gigaword (Parker et al., 2009). Users can specify their own LM file and/or interpolate it with our default LM. This is useful for adapting ELISSA’s output to the Arabic side of the training data. 5.4 Revisiting our Motivating Example We revisit our motivating example in Section 2 and show automatic MSA-pivoting through ELISSA. Table 3 is divided into two parts. The first part is copied from Table 1 for convenience. The second part shows ELISSA’s output on the dialectal sentence and its Google Translate translation. The produced MSA is not perfect, but is clearly an improvement over doing nothing as far as usability for MT </context>
</contexts>
<marker>Parker, Graff, Chen, Kong, Maeda, 2009</marker>
<rawString>Robert Parker, David Graff, Ke Chen, Junbo Kong, and Kazuaki Maeda. 2009. Arabic Gigaword Fourth Edition. LDC catalog number No. LDC2009T30, ISBN 1-58563-532-4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Riesa</author>
<author>David Yarowsky</author>
</authors>
<title>Minimally Supervised Morphological Segmentation with Applications to Machine Translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas (AMTA06),</booktitle>
<pages>185--192</pages>
<location>Cambridge,MA.</location>
<contexts>
<context position="9053" citStr="Riesa and Yarowsky (2006)" startWordPosition="1477" endWordPosition="1480">anslations. Given that DA and MSA do not have much in terms of parallel corpora, rule-based methods to translate DA-to-MSA or other methods to collect word-pair lists have been explored. For example, Abo Bakr et al. (2008) introduced a hybrid approach to transfer a sentence from Egyptian Arabic into MSA. This hybrid system consisted of a statistical system for tokenizing and tagging, and a rule-based system for constructing diacritized MSA sentences. Moreover, Al-Sabbagh and Girju (2010) described an approach of mining the web to build a DA-to-MSA lexicon. In the context of DA-to-English SMT, Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut the OOV words by half. Machine Translation for Closely Related Languages. Using closely related languages has been shown to improve MT quality when resources are limited. Hajiˇc et al. (2000) argued that for very close languages, e.g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of </context>
<context position="12914" citStr="Riesa and Yarowsky (2006)" startWordPosition="2110" endWordPosition="2113"> to their MSA equivalents. In our previous work (Salloum and Habash, 2011; Salloum and Habash, 2012), we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only. We did not use a language model to pick the best path; instead we kept the ambiguity in the lattice and passed it to our SMT system. In contrast, in this paper, we run ELISSA on untokenized Arabic, we use 350 feature, lemma, and surface form transfer rules, and we pick the best path of the generated MSA lattice through a language model. Certain aspects of our approach are similar to Riesa and Yarowsky (2006)’s, in that we use morphological analysis for DA to help DA-English MT; but unlike them, we use a rule-based approach to model DA morphology. 5 ELISSA ELISSA is a DA-to-MSA MT System. ELISSA uses a rule-based approach (with some statistical components) that relies on the existence of a DA morphological analyzer, a list of hand-written transfer rules, and DA-MSA dictionaries to create a mapping of DA to MSA words and construct a lattice of possible sentences. ELISSA uses a language model to rank and select the generated sentences. ELISSA supports untokenized (raw) input only. ELISSA supports th</context>
</contexts>
<marker>Riesa, Yarowsky, 2006</marker>
<rawString>Jason Riesa and David Yarowsky. 2006. Minimally Supervised Morphological Segmentation with Applications to Machine Translation. In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas (AMTA06), pages 185–192, Cambridge,MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Roth</author>
<author>Owen Rambow</author>
<author>Nizar Habash</author>
<author>Mona Diab</author>
<author>Cynthia Rudin</author>
</authors>
<title>Arabic Morphological Tagging, Diacritization, and Lemmatization Using Lexeme Models and Feature Ranking.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT, Short Papers,</booktitle>
<pages>117--120</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="23491" citStr="Roth et al., 2008" startWordPosition="3813" endWordPosition="3816">rained on the English side of the bitext augmented with English Gigaword (Graff and Cieri, 2003). We use a 5-gram language model with modified Kneser-Ney smoothing. Feature weights are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. The English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Habash and Rambow, 2005; Roth et al., 2008). The Arabic text is also Alif/Ya normalized. MADA-produced Arabic lemmas are used for word alignment. We use the same development (dev) and test sets used by Salloum and Habash (2011) (we will call them speech-dev and speech-test, respectively) and we compare to them in the next sections. We also evaluate on two web-crawled blind test sets: the Levantine test set presented in Zbib et al. (2012) (we will call it web-lev-test) and the Egyptian Dev-MTv2 development data of the DARPA BOLT program (we will call it web-egy-test). The speech-dev set has 1,496 sentences with 32,047 untokenized Arabic</context>
</contexts>
<marker>Roth, Rambow, Habash, Diab, Rudin, 2008</marker>
<rawString>Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab, and Cynthia Rudin. 2008. Arabic Morphological Tagging, Diacritization, and Lemmatization Using Lexeme Models and Feature Ranking. In Proceedings of ACL-08: HLT, Short Papers, pages 117–120, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wael Salloum</author>
<author>Nizar Habash</author>
</authors>
<title>Dialectal to Standard Arabic Paraphrasing to Improve ArabicEnglish Statistical Machine Translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties,</booktitle>
<pages>10--21</pages>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="7914" citStr="Salloum and Habash, 2011" startWordPosition="1289" endWordPosition="1292">es of MSA (e.g., optional diacritics and spelling inconsistency) are shared by DA. However, the lack of standard orthographies for the dialects and their numerous varieties pose new challenges. Additionally, DAs are rather impoverished in terms of available tools and resources compared to MSA, e.g., there is very little parallel DAEnglish corpora and almost no MSA-DA parallel corpora. The number and sophistication of morphological analysis and disambiguation tools in DA is very limited in comparison to MSA (Duh and Kirchhoff, 2005; Habash and Rambow, 2006; Abo Bakr et al., 2008; Habash, 2010; Salloum and Habash, 2011; Habash et al., 2012; Habash et al., 2013). MSA tools cannot be effectively used to handle DA, e.g., Habash and Rambow (2006) report that over onethird of Levantine verbs cannot be analyzed using an MSA morphological analyzer. 349 4 Related Work Dialectal Arabic NLP. Several researchers have explored the idea of exploiting existing MSA rich resources to build tools for DA NLP (Chiang et al., 2006). Such approaches typically expect the presence of tools/resources to relate DA words to their MSA variants or translations. Given that DA and MSA do not have much in terms of parallel corpora, rule-</context>
<context position="9990" citStr="Salloum and Habash, 2011" startWordPosition="1623" endWordPosition="1626">.g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a</context>
<context position="12362" citStr="Salloum and Habash, 2011" startWordPosition="2011" endWordPosition="2014"> to study interactions between the two types of solutions in the future. Our work is most similar to Sawaf (2010)’s MSApivoting approach. In his approach, DA is normalized into MSA using character-based DA normalization rules, a DA morphological analyzer, a DA normalization decoder that relies on language models, and a lexicon. Similarly, we use some character normalization rules, a DA morphological analyzer, and DA-MSA dictionaries. In contrast, we use hand-written morphosyntactic transfer rules that focus on translating DA morphemes and lemmas to their MSA equivalents. In our previous work (Salloum and Habash, 2011; Salloum and Habash, 2012), we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only. We did not use a language model to pick the best path; instead we kept the ambiguity in the lattice and passed it to our SMT system. In contrast, in this paper, we run ELISSA on untokenized Arabic, we use 350 feature, lemma, and surface form transfer rules, and we pick the best path of the generated MSA lattice through a language model. Certain aspects of our approach are similar to Riesa and Yarowsky (2006)’s, in that we use morphological analysis for DA</context>
<context position="15335" citStr="Salloum and Habash, 2011" startWordPosition="2504" endWordPosition="2507">ds. Selection methods are classified into Word-based selection and Phrase-based selection. Word-based selection. Methods of this type fall in the following categories: a. User token-based selection: The user can mark specific words for selection using the tag ‘/DIA’ (stands for ‘dialect’) after each word to select. b. User type-based selection: The user can specify a list of words to select from, e.g., OOVs. Also the user can provide a list of words and their frequencies and specify a cut-off threshold to prevent selecting a frequent word. c. Morphology-based word selection: ELISSA uses ADAM (Salloum and Habash, 2011) to select words that have DA analyses only (DIAONLY) or DA/MSA analyses (DIAMSA). d. Dictionary-based selection: ELISSA selects words based on their existence in the DA side of our DA-MSA dictionaries. e. All: ELISSA selects every word in an input sentence. Phrase-based selection. This selection type uses hand-written rules to identify dialectal multi-word constructions that are mappable to single or multiword MSA constructions. The current count of these rules is 25. Table 2 presents some rule categories and related examples. In the current version of ELISSA, words can be selected using eith</context>
<context position="18395" citStr="Salloum and Habash, 2011" startWordPosition="2968" endWordPosition="2971">es] Enclitic w+ mA rAHw +l +A conj+ [neg] [rAH PV subj:3MP] +prep +pron3FS and+ not they go +to +her Transfer Word 1 Word 2 Word 3 Proclitics [Lemma &amp; Features] [Lemma &amp; Features] [Lemma &amp; Features] Enclitic conj+ [ lam ] [ðahab IV subj:3MP] [ Alý ] +pron3FS and+ did not they go to +her Generation w+ lm yðhbwA Aly +hA MSA Phrase AîD�Ë@� @ñJ.ë .E ÕËð wlm yðhbwA ˇAlyhA ‘And they did not go to her’ Figure 1: An example illustrating the analysis-transfer-generation steps to translate a dialectal multi-word expression into its MSA equivalent phrase. dialectal morphological analysis step uses ADAM (Salloum and Habash, 2011) to get a list of dialectal analyses. The morphosyntactic transfer step uses lemma-to-lemma (L2L) and features-tofeatures (F2F) transfer rules to change lemmas, clitics or features, and even split up the dialectal word into multiple MSA word analyses (such as splitting negation words and indirect objects). The MSA morphological generation step uses the general tokenizer/generator TOKAN (Habash, 2007) to generate untokenized surface form words. For more details, see Salloum and Habash (2011). Phrase-based translation. Unlike the wordbased translation techniques which map single DA words to sing</context>
<context position="23675" citStr="Salloum and Habash (2011)" startWordPosition="3843" endWordPosition="3846">hts are tuned to maximize BLEU on the NIST MTEval 2006 test set using Minimum Error Rate Training (Och, 2003). This is only done on the baseline systems. The English data is tokenized using simple punctuation-based rules. The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Habash and Rambow, 2005; Roth et al., 2008). The Arabic text is also Alif/Ya normalized. MADA-produced Arabic lemmas are used for word alignment. We use the same development (dev) and test sets used by Salloum and Habash (2011) (we will call them speech-dev and speech-test, respectively) and we compare to them in the next sections. We also evaluate on two web-crawled blind test sets: the Levantine test set presented in Zbib et al. (2012) (we will call it web-lev-test) and the Egyptian Dev-MTv2 development data of the DARPA BOLT program (we will call it web-egy-test). The speech-dev set has 1,496 sentences with 32,047 untokenized Arabic words. The speech-test set has 1,568 sentences with 353 32,492 untokenized Arabic words. The web-levtest set has 2,728 sentences with 21,179 untokenized Arabic words. The web-egy-test</context>
<context position="30360" citStr="Salloum and Habash (2011)" startWordPosition="4937" endWordPosition="4940">ng phrases improve the three best performers of word-based selection. The best performer, shown in the last raw, suggests using phrase-based selection and restricted word-based selection. The restriction is to include OOV words and selected low frequency words that have at least one dialectal analysis or appear in our dialectal dictionaries. Comparing the best performer to the OOV selection mode system shows that translating low frequency in-vocabulary dialectal words and phrases to their MSA paraphrases can improve the English translation. This is a similar conclusion to our previous work in Salloum and Habash (2011). 6.1.3 Results on the Blind Test Sets We run the system settings that performed best on the dev set along with the OOV selection mode system on the three blind test set. Results and their differences from the baseline are reported in Table 5. We see that OOV selection mode system always improves over the baseline for all test sets. Also, the best performer on the dev is the best performer for all test sets. The improvements of the best performer over the OOV selection mode system on all test sets confirm that translating low frequency invocabulary dialectal words and phrases to their MSA para</context>
</contexts>
<marker>Salloum, Habash, 2011</marker>
<rawString>Wael Salloum and Nizar Habash. 2011. Dialectal to Standard Arabic Paraphrasing to Improve ArabicEnglish Statistical Machine Translation. In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties, pages 10–21, Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wael Salloum</author>
<author>Nizar Habash</author>
</authors>
<title>Elissa: A Dialectal to Standard Arabic Machine Translation System.</title>
<date>2012</date>
<booktitle>In Proceedings of the 24th International Conference on Computational Linguistics (COLING 2012): Demonstration Papers,</booktitle>
<pages>385--392</pages>
<location>Mumbai, India.</location>
<contexts>
<context position="10017" citStr="Salloum and Habash, 2012" startWordPosition="1627" endWordPosition="1630">is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich langu</context>
<context position="12389" citStr="Salloum and Habash, 2012" startWordPosition="2015" endWordPosition="2018">ween the two types of solutions in the future. Our work is most similar to Sawaf (2010)’s MSApivoting approach. In his approach, DA is normalized into MSA using character-based DA normalization rules, a DA morphological analyzer, a DA normalization decoder that relies on language models, and a lexicon. Similarly, we use some character normalization rules, a DA morphological analyzer, and DA-MSA dictionaries. In contrast, we use hand-written morphosyntactic transfer rules that focus on translating DA morphemes and lemmas to their MSA equivalents. In our previous work (Salloum and Habash, 2011; Salloum and Habash, 2012), we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only. We did not use a language model to pick the best path; instead we kept the ambiguity in the lattice and passed it to our SMT system. In contrast, in this paper, we run ELISSA on untokenized Arabic, we use 350 feature, lemma, and surface form transfer rules, and we pick the best path of the generated MSA lattice through a language model. Certain aspects of our approach are similar to Riesa and Yarowsky (2006)’s, in that we use morphological analysis for DA to help DA-English MT; but</context>
</contexts>
<marker>Salloum, Habash, 2012</marker>
<rawString>Wael Salloum and Nizar Habash. 2012. Elissa: A Dialectal to Standard Arabic Machine Translation System. In Proceedings of the 24th International Conference on Computational Linguistics (COLING 2012): Demonstration Papers, pages 385–392, Mumbai, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Sawaf</author>
</authors>
<title>Arabic dialect handling in hybrid machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference of the Association for Machine Translation in the Americas (AMTA),</booktitle>
<location>Denver, Colorado.</location>
<contexts>
<context position="9693" citStr="Sawaf (2010)" startWordPosition="1577" endWordPosition="1578">rithm for online morpheme segmentation on DA that cut the OOV words by half. Machine Translation for Closely Related Languages. Using closely related languages has been shown to improve MT quality when resources are limited. Hajiˇc et al. (2000) argued that for very close languages, e.g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar</context>
<context position="11851" citStr="Sawaf (2010)" startWordPosition="1934" endWordPosition="1935">d by Human translators in an oracle experiment) can reduce OOV rate to 0.98% from 2.27% for direct translation (without pivoting), it improves by 4.91% BLEU while direct translation improves by 6.81% BLEU over their 12.29% BLEU baseline (direct translation using the 150M MSA system). They concluded that simple vocabulary coverage is not sufficient and the domain mismatch is a more important problem. The approach we take in this paper is orthogonal to such efforts to build parallel data. We plan to study interactions between the two types of solutions in the future. Our work is most similar to Sawaf (2010)’s MSApivoting approach. In his approach, DA is normalized into MSA using character-based DA normalization rules, a DA morphological analyzer, a DA normalization decoder that relies on language models, and a lexicon. Similarly, we use some character normalization rules, a DA morphological analyzer, and DA-MSA dictionaries. In contrast, we use hand-written morphosyntactic transfer rules that focus on translating DA morphemes and lemmas to their MSA equivalents. In our previous work (Salloum and Habash, 2011; Salloum and Habash, 2012), we applied our approach to tokenized Arabic and our DA-MSA t</context>
<context position="35726" citStr="Sawaf (2010)" startWordPosition="5825" endWordPosition="5826">or a web-crawled Levantine test set, and 0.61% absolute BLEU (or 3.2% relative) for a web-crawled Egyptian test set. A manual error analysis of translated selected words shows that our system produces correct MSA translations over 93% of the time. In the future, we plan to extend ELISSA’s coverage of phenomena in the handled dialects and to new dialects. We also plan to automatically learn additional rules from limited available data (DA-MSA or DA-English). We also would like to do additional MT experiments where we use ELISSA to preprocess the training data, comparable to experiments done by Sawaf (2010). We are interested in studying how our approach can be combined with solutions that simply add more dialectal training data since the two directions are complementary in that they address linguistic normalization and domain coverage. Finally, we look forward to experimenting with ELISSA as a preprocessing system for a variety of dialect NLP applications similar to Chiang et al. (2006)’s work on dialect parsing, for example. ELISSA will be publicly available. Please contact the authors for more information. Acknowledgment This paper is based upon work supported by the Defense Advanced Research</context>
</contexts>
<marker>Sawaf, 2010</marker>
<rawString>Hassan Sawaf. 2010. Arabic dialect handling in hybrid machine translation. In Proceedings of the Conference of the Association for Machine Translation in the Americas (AMTA), Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM an Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing.</booktitle>
<contexts>
<context position="19852" citStr="Stolcke, 2002" startWordPosition="3191" endWordPosition="3192"> the word-based morphosyntactic transfer rules are re-used for phrase-based translation. Figure 1 shows an example of a phrase-based morphological translation of the two-word DA sequence Bñk@P AÓð wmA rAHwlA ‘And they did not go to her’. If these two words were spelled as a single word, Bñk@PAÓð wmArAHwlA, we would still get the same result using the word-based translation technique only. Table 2 shows some rule categories along with selection and translation examples. 5.3 Language Modeling The language model (LM) component uses the SRILM lattice-tool for weight assignment and nbest decoding (Stolcke, 2002). ELISSA comes with a default 5-gram LM file trained on —200M unto352 DA source 7 �HA�J��J�Óñ» 6 �áÊ�JªJ.K� 5 (èAK� �àYK.) Bð 4 (ñªJ.�K �éJ�’ j ~‚Ë@ éj�®’Ë@) 3 ¡J�j« 2 (ñËñJ.�JºJ�k AÓ) 1 (ø Aë �éËAmÌ AîE.) � .12 YÊJ.ËA« 11 (hðQK� hP)10 A:Öß�@ 9 JñëQ{.�AÓ 8 ñ KB (bhAlHAlh hAy)1 (mA Hyktbwlw)2 ςHyT3 (AlSfHh AlšxSyh tbςw)4 wlA (bdn yAh)5 ybςtln6 kwmyntAt7 lÂnw8 mAxbrhwn9 AymtA10 (rH yrwH)11 ςAlbld12. Human Ref- In this case, they will not write on his profile wall and they do not want him to send them comments because he did erence not tell them when he will go to the country. Google Bhalhalh Hi </context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM an Extensible Language Modeling Toolkit. In Proceedings of the International Conference on Spoken Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masao Utiyama</author>
<author>Hitoshi Isahara</author>
</authors>
<title>A comparison of pivot methods for phrase-based statistical machine translation.</title>
<date>2007</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>484--491</pages>
<contexts>
<context position="10286" citStr="Utiyama and Isahara, 2007" startWordPosition="1667" endWordPosition="1671">ialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich language, Malay, to extend the phrase table in a Malay-toEnglish SMT system. Pivoting on MSA or acquiring more DA-English data? Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data. They used Amazon’s Mechanical Turk (MTurk) to create a DAEnglish</context>
</contexts>
<marker>Utiyama, Isahara, 2007</marker>
<rawString>Masao Utiyama and Hitoshi Isahara. 2007. A comparison of pivot methods for phrase-based statistical machine translation. In HLT-NAACL, pages 484–491.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Rabih Zbib</author>
<author>Erika Malchiodi</author>
<author>Jacob Devlin</author>
<author>David Stallard</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
<author>John Makhoul</author>
<author>Omar F Zaidan</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Machine Translation of Arabic Dialects.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>49--59</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montréal, Canada,</location>
<contexts>
<context position="10758" citStr="Zbib et al. (2012)" startWordPosition="1750" endWordPosition="1753">of “resource-rich” related languages is a specific variant of the more general approach of using pivot/bridge languages (Utiyama and Isahara, 2007; Kumar et al., 2007). In the case of MSA and DA variants, it is plausible to consider the MSA variants of a DA phrase as monolingual paraphrases (Callison-Burch et al., 2006; Du et al., 2010). Also related is the work by Nakov and Ng (2011), who use morphological knowledge to generate paraphrases for a morphologically rich language, Malay, to extend the phrase table in a Malay-toEnglish SMT system. Pivoting on MSA or acquiring more DA-English data? Zbib et al. (2012) demonstrated an approach to cheaply obtaining DA-English data. They used Amazon’s Mechanical Turk (MTurk) to create a DAEnglish parallel corpus of 1.5M words and added it to a 150M MSA-English parallel corpus to create the training corpus of their SMT system. They also used MTurk to translate their dialectal test set to MSA in order to compare the MSA-pivoting approach to the direct translation from DA to English approach. They showed that even though pivoting on MSA (produced by Human translators in an oracle experiment) can reduce OOV rate to 0.98% from 2.27% for direct translation (without</context>
<context position="23889" citStr="Zbib et al. (2012)" startWordPosition="3879" endWordPosition="3882"> The Arabic side is segmented according to the Arabic Treebank (ATB) tokenization scheme (Maamouri et al., 2004) using the MADA+TOKAN morphological analyzer and tokenizer v3.1 (Habash and Rambow, 2005; Roth et al., 2008). The Arabic text is also Alif/Ya normalized. MADA-produced Arabic lemmas are used for word alignment. We use the same development (dev) and test sets used by Salloum and Habash (2011) (we will call them speech-dev and speech-test, respectively) and we compare to them in the next sections. We also evaluate on two web-crawled blind test sets: the Levantine test set presented in Zbib et al. (2012) (we will call it web-lev-test) and the Egyptian Dev-MTv2 development data of the DARPA BOLT program (we will call it web-egy-test). The speech-dev set has 1,496 sentences with 32,047 untokenized Arabic words. The speech-test set has 1,568 sentences with 353 32,492 untokenized Arabic words. The web-levtest set has 2,728 sentences with 21,179 untokenized Arabic words. The web-egy-test set has 1,553 sentences with 21,495 untokenized Arabic words. The two speech test sets contain multi-dialect (e.g., Iraqi, Levantine, Gulf, and Egyptian) broadcast conversational (BC) segments (with three referenc</context>
</contexts>
<marker>Zbib, Malchiodi, Devlin, Stallard, Matsoukas, Schwartz, Makhoul, Zaidan, Callison-Burch, 2012</marker>
<rawString>Rabih Zbib, Erika Malchiodi, Jacob Devlin, David Stallard, Spyros Matsoukas, Richard Schwartz, John Makhoul, Omar F. Zaidan, and Chris Callison-Burch. 2012. Machine Translation of Arabic Dialects. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 49– 59, Montréal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoheng Zhang</author>
</authors>
<title>Dialect MT: a case study between Cantonese and Mandarin.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, ACL ’98,</booktitle>
<pages>1460--1464</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="9557" citStr="Zhang (1998)" startWordPosition="1559" endWordPosition="1560"> mining the web to build a DA-to-MSA lexicon. In the context of DA-to-English SMT, Riesa and Yarowsky (2006) presented a supervised algorithm for online morpheme segmentation on DA that cut the OOV words by half. Machine Translation for Closely Related Languages. Using closely related languages has been shown to improve MT quality when resources are limited. Hajiˇc et al. (2000) argued that for very close languages, e.g., Czech and Slovak, it is possible to obtain a better translation quality by using simple methods such as morphological disambiguation, transfer-based MT and word-for-word MT. Zhang (1998) introduced a Cantonese-Mandarin MT that uses transformational grammar rules. In the context of Arabic dialect translation, Sawaf (2010) built a hybrid MT system that uses both statistical and rule-based approaches for DA-to-English MT. In his approach, DA is normalized into MSA using a dialectal morphological analyzer. In previous work, we presented a rule-based DA-MSA system to improve DA-to-English MT (Salloum and Habash, 2011; Salloum and Habash, 2012). Our approach used a DA morphological analyzer (ADAM) and a list of hand-written morphosyntactic transfer rules. This use of “resource-rich</context>
</contexts>
<marker>Zhang, 1998</marker>
<rawString>Xiaoheng Zhang. 1998. Dialect MT: a case study between Cantonese and Mandarin. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, ACL ’98, pages 1460– 1464, Montreal, Canada.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>