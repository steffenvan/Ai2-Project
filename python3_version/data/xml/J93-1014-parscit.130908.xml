<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.015413">
<title confidence="0.968114">
Corpus Linguistics and the Automatic Analysis of English
</title>
<author confidence="0.901021">
Nelleke Oostdijk
</author>
<affiliation confidence="0.7138335">
(University of Nijmegen)
Amsterdam: Editions Rodopi
</affiliation>
<bodyText confidence="0.602359166666667">
(Language and Computers: Studies in
Practical Linguistics 6, edited by Jan
Aarts and Willem Meijs), 1991,
xii + 267 pp.
Paperbound, ISBN 90-5183-281-8,
$40.00, Dfl 80.00
</bodyText>
<figure confidence="0.640846">
Reviewed by
Ted Briscoe
</figure>
<affiliation confidence="0.478069">
University of Cambridge
</affiliation>
<bodyText confidence="0.999952176470588">
In a recent paper advocating a corpus-based and probabilistic approach to grammar
development, Black, Lafferty, and Roukos (1992) argue that &amp;quot;the current state of the
art is far from being able to produce a robust parser of general English&amp;quot; and advo-
cate &amp;quot;steady and quantifiable,&amp;quot; empirically corpus-driven grammar development and
testing. Black et al. are addressing a community in which armchair introspection has
been and still is the dominant methodology in many quarters, but in some parts of
Europe, corpus linguistics never died. For nearly two decades, the Nijmegen group
led by Jan Aarts have been undertaking corpus analyses that, although motivated pri-
marily by the desire to study language variation using corpus data, are particularly
relevant to the issue of broad-coverage grammar development. In distinction to other
groups undertaking corpus-based work (e.g., Garside, Leech, and Sampson 1987), the
Nijmegen group has consistently adopted the position that it is possible and desirable
to develop a formal, generative grammar that characterizes the syntactic properties of
a given corpus and can be used to assign appropriate analyses to each of its sentences.
Nelleke Oostdijk&apos;s book provides a detailed description of the cumulative devel-
opment of a grammar capable of analyzing a one million—word corpus of English
written texts, drawn from a wide but balanced variety of sources. This task forms
a significant component of the wider Tools for Syntactic Corpus Analysis (TOSCA)
project being undertaken at Nijmegen. Oostdijk&apos;s work provides an excellent example
of the strengths and weaknesses of the approach advocated by Black et al. In addition,
she discusses issues such as sampling and tokenization of corpus material, as well as
the exploitation of the analyzed corpus in studies of language variation. However, in
this review I will concentrate on the central core of her book: the development of the
grammar and performance of the associated parser, since this is the part that is most
relevant to computational linguistics.
Oostdijk begins by locating her work and the TOSCA project within the field of
computational linguistics (arguing that it is distinguished by &amp;quot;an interest in language
itself as it is actually produced&amp;quot; (p. 2)) and contrasting it to the LSP system (Sager
1981) and Parsifal (Marcus 1980). The comparison is brief and the choice odd since
more general broad-coverage grammars, such as DIAGRAM (Robinson 1982), PEG
(Jensen et al. 1986) and ANLT (Grover et al. 1989), and more corpus-oriented parsing
systems, such as FIDDITCH (Hindle 1983, 1993) or MITFP (de Marcken 1990), have
been developed within the field, but are not discussed anywhere. A similar suspicion
of isolationism recurs in the sections dealing with the grammatical formalism used;
</bodyText>
<page confidence="0.996319">
210
</page>
<subsectionHeader confidence="0.949304">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.999974921568628">
this is based on (extended) affix grammar (Koster 1971) and, although only described
informally, the variant of affix grammar adopted is probably similar in generative and
expressive capacity to unification-based formalisms, such as PATR-II (Shieber 1986) or
the ANLT formalism (Briscoe et al. 1987), with some interesting extensions making
it more adequate to phenomena such as agreement in coordinate structures. Unfor-
tunately, no comparison is offered. More discussion is devoted to comparison with
the approach to corpus analysis taken by the Lancaster group (Garside et al. 1987);
Oostdijk argues that because their espousal of probabilistic methods and rejection of
a rule-based generative approach is not founded on sound empirical evidence, it is
impossible to develop a comprehensive generative grammar for a corpus. While I am
sympathetic to Oostdijk&apos;s position and think that the grammar she goes on to present
is impressive enough to bias us towards the opposite conclusion, it is a mistake to ac-
cept the assumption that the two approaches are incompatible, as much recent work
(including that of Black et al. 1992) has demonstrated the usefulness of combining
statistical techniques with rule-based systems.
The core of the book is a description of the grammar developed and analy-
ses adopted for notoriously difficult phenomena, such as nonconstituent coordina-
tion, gapping, apposition, partitives, other noun phrase premodifier syntax, and so
forth. The grammatical framework adopted is based on a conventional notion of con-
stituency, with nodes assigned categorial labels augmented with functional categories
encoding mostly familiar grammatical relations. The commitment to nonelliptical ac-
counts of the full range of coordinate and gapped constructions that occur in the cor-
pus leads to adoption of linguistically nonstandard analyses; for example, grouping
noun phrase complements of ditransitive verbs into single constituents. Once again,
no reference is made to recent theoretical work addressing similar problems, such as
extended categorial or combinatory grammar (e.g., Steedman 1985). Nevertheless, the
coverage of the resultant grammar is impressive, and the (computational) linguist who
has not developed a substantial grammar from natural data will find enough inter-
esting insights, analyses, and detailed discussion of constructions sometimes ignored
in the more mainstream generative literature to be convinced, I hope, of the value of
corpus-based grammar development. There are, however, dangers, as well as strengths
in this approach; for instance, the commitment to assign an analysis to each sentence
of the corpus can easily lead to reification of undesirable decisions in the grammar
and consequent propagation throughout the analyzed corpus: a case in point might
be the use of ditransitive complement constituents introduced to deal with gapped
examples.
Corpus-based development and testing of a grammar requires computational sup-
port to be practical and, given the goal of the TOSCA project, a method is needed to
select the semantically and pragmatically appropriate analysis from the set licensed
by the grammar for each sentence in the corpus. A separate system is used to assign
each word of the input sentence an unambiguous and correct lexical category com-
patible with the grammar developed. This system and the lexical categories are not
described in the book but appear to be more fine-grained than the categories assigned
by tagging programs (e.g., CLAWS2, Garside et al. 1987), incorporating subcategoriza-
tion information concerning complementation, for instance. The parsing system then
assigns analyses to this unambiguous sequence of lexical categories. Oostdijk does
not describe the parser-generator or parser developed for the affix grammar formal-
ism used, but instead concentrates on the issues of parse selection and performance
both in terms of coverage and efficiency. Parse selection is done interactively by guid-
ing the parser manually; Oostdijk justifies this approach by arguing that it ensures a
high level of accuracy and guarantees parsing efficiency by pre-empting unnecessary
</bodyText>
<page confidence="0.986101">
211
</page>
<note confidence="0.556064">
Computational Linguistics Volume 19, Number 1
</note>
<bodyText confidence="0.999586363636364">
search. An approach in which intervention is limited to selection between predefined
legitimate analyses is an improvement on one in which the analyst is able to create
new descriptions at will (e.g., Leech and Garside 1991) in that the resulting database
of analyses will be consistent and intervention will be simpler and faster. However,
other approaches are possible, such as the use of probabilities to guide parse selec-
tion, if not grammar induction (e.g., Black et al. 1992). Oostdijk does not consider this
possibility, presumably because of her acceptance of the incompatibility of rule-based
and statistical techniques. The decision to manually select parses, coupled with the
fact that the TOSCA parser (on the hardware available) is not always able to compute
all the possible analyses, even starting from unambiguous lexical categories, has the
unfortunate side effect that a significant effort has been devoted to removing linguis-
tically motivated ambiguity from the grammar. Earlier, Oostdijk argues for the strict
separation of grammatical formalism and parsing algorithm on familiar grounds, but
the same arguments tell against the decision, for instance, to stipulate that coordina-
tion occurs at specific nodes in case of ambiguity (p. 133), since such distinctions often
correlate with differences of semantic scope.
Despite these criticisms—and in a practical project of this type some compromises
are inevitable--Oostdijk&apos;s achievement is impressive; her book is well written and
easy to read, and she manages the difficult task of striking the right level between
an exhaustive and exhausting documentation of a substantial grammar and a super-
ficial overview. There are very few typographical errors and the book has been well
produced.
</bodyText>
<sectionHeader confidence="0.910412" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.990068258064516">
Black, Ezra; Lafferty, John; and Roukos,
Salim (1992). &amp;quot;Development and
evaluation of a broad-coverage
probabilistic grammar of English-language
computer manuals.&amp;quot; Proceedings, 30th
Annual Meeting of the Association for
Computational Linguistics, Newark, DE,
185-192.
Briscoe, Ted; Grover, Claire; Boguraev, Bran;
and Carroll, John (1987). &amp;quot;A formalism
and environment for the development of a
large grammar of English.&amp;quot; Proceedings,
10th International Joint Conference on
Artificial Intelligence, Milan, 703-708.
De Marcken, Carl G. (1990). &amp;quot;Parsing the
LOB Corpus.&amp;quot; Proceedings, 28th Annual
Meeting of the Association for Computational
Linguistics, Pittsburgh, 243-251.
Garside, Roger; Leech, Geoffrey; and
Sampson, Geoffrey (1987). The
Computational Analysis of English: A
Corpus-Based Approach. Longman.
Grover, Claire; Briscoe, Ted; Carroll, John;
and Boguraev, Bran (1989). &amp;quot;The Alvey
natural language tools grammar (second
release).&amp;quot; Technical Report 162, University
of Cambridge, Computer Laboratory.
Hindle, Donald (1983). &amp;quot;User manual for
Fidditch, a deterministic parser.&amp;quot; Technical
Memorandum 7590-142, Naval Research
Laboratory.
Hindle, Donald (1993). &amp;quot;A parser for text
corpora.&amp;quot; In Computational Approaches to
the Lexicon, edited by B. T. S. Atkins and
A. Zampolli, Oxford University Press. In
press.
Jensen, Karen; Heidorn, George;
Richardson, Stephen; and Haas, Norman
(1986). &amp;quot;PLNLP, PEG and CRITIQUE:
Three contributions to computing in the
humanities.&amp;quot; Report RC-11841, IBM
Thomas J. Watson Research Center.
Koster, C. (1971). &amp;quot;Affix grammars.&amp;quot; In
ALGOL 68 Implementation, edited by John
Peck, North-Holland.
Leech, Geoffrey, and Garside, Roger (1991).
&amp;quot;Running a grammar factory: The
production of syntactically analysed
corpora or &apos;treebanks&apos;.&amp;quot; In English
Computer Corpora: Selected Papers and
Bibliography, edited by Stig Johansson and
A. Stenstrom, Mouton de Gruyter.
Marcus, Mitchell P. (1980). A Theory of
Syntactic Recognition for Natural Language.
The MIT Press.
Robinson, Joan (1982). &amp;quot;DIAGRAM: A
grammar for dialogues.&amp;quot; Communications
of the ACM. 25(1), 27-47.
Sager, Naomi (1981). Natural Language
Information Processing: A Computer
Grammar of English and Its Applications.
Addison-Wesley.
</reference>
<page confidence="0.976751">
212
</page>
<reference confidence="0.996444416666667">
Book Reviews
Shieber, Stuart (1986). Introduction to
Unification-Based Approaches to Grammar.
Stanford, CA: Center for the Study of
Language and Information.
Steedman, Mark (1985). &amp;quot;Dependency and
coordination in the grammar of Dutch
and English.&amp;quot; Language, 62, 523-568.
Ted Briscoe is a SERC Advanced Research Fellow at the Computer Laboratory, University of
Cambridge. His current research interests include robust parsing of naturally occurring natural
language. His address is: Computer Laboratory, University of Cambridge, Pembroke Street,
Cambridge CB1 3AZ, UK; e-mail: ejb@cl.cam.ac.uk
</reference>
<page confidence="0.999395">
213
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000114">
<title confidence="0.942699">Corpus Linguistics and the Automatic Analysis of English</title>
<author confidence="0.845359">Nelleke Oostdijk</author>
<affiliation confidence="0.932989">(University of Nijmegen)</affiliation>
<address confidence="0.571628">Amsterdam: Editions Rodopi</address>
<note confidence="0.909671571428571">(Language and Computers: Studies in Practical Linguistics 6, edited by Jan Aarts and Willem Meijs), 1991, xii + 267 pp. Paperbound, ISBN 90-5183-281-8, $40.00, Dfl 80.00 Reviewed by</note>
<author confidence="0.998797">Ted Briscoe</author>
<affiliation confidence="0.995281">University of Cambridge</affiliation>
<abstract confidence="0.977173725806451">In a recent paper advocating a corpus-based and probabilistic approach to grammar development, Black, Lafferty, and Roukos (1992) argue that &amp;quot;the current state of the art is far from being able to produce a robust parser of general English&amp;quot; and advocate &amp;quot;steady and quantifiable,&amp;quot; empirically corpus-driven grammar development and testing. Black et al. are addressing a community in which armchair introspection has been and still is the dominant methodology in many quarters, but in some parts of Europe, corpus linguistics never died. For nearly two decades, the Nijmegen group led by Jan Aarts have been undertaking corpus analyses that, although motivated primarily by the desire to study language variation using corpus data, are particularly relevant to the issue of broad-coverage grammar development. In distinction to other groups undertaking corpus-based work (e.g., Garside, Leech, and Sampson 1987), the Nijmegen group has consistently adopted the position that it is possible and desirable to develop a formal, generative grammar that characterizes the syntactic properties of a given corpus and can be used to assign appropriate analyses to each of its sentences. Nelleke Oostdijk&apos;s book provides a detailed description of the cumulative development of a grammar capable of analyzing a one million—word corpus of English written texts, drawn from a wide but balanced variety of sources. This task forms a significant component of the wider Tools for Syntactic Corpus Analysis (TOSCA) project being undertaken at Nijmegen. Oostdijk&apos;s work provides an excellent example of the strengths and weaknesses of the approach advocated by Black et al. In addition, she discusses issues such as sampling and tokenization of corpus material, as well as the exploitation of the analyzed corpus in studies of language variation. However, in this review I will concentrate on the central core of her book: the development of the grammar and performance of the associated parser, since this is the part that is most relevant to computational linguistics. Oostdijk begins by locating her work and the TOSCA project within the field of computational linguistics (arguing that it is distinguished by &amp;quot;an interest in language itself as it is actually produced&amp;quot; (p. 2)) and contrasting it to the LSP system (Sager 1981) and Parsifal (Marcus 1980). The comparison is brief and the choice odd since more general broad-coverage grammars, such as DIAGRAM (Robinson 1982), PEG (Jensen et al. 1986) and ANLT (Grover et al. 1989), and more corpus-oriented parsing systems, such as FIDDITCH (Hindle 1983, 1993) or MITFP (de Marcken 1990), have been developed within the field, but are not discussed anywhere. A similar suspicion of isolationism recurs in the sections dealing with the grammatical formalism used; 210 Book Reviews this is based on (extended) affix grammar (Koster 1971) and, although only described informally, the variant of affix grammar adopted is probably similar in generative and expressive capacity to unification-based formalisms, such as PATR-II (Shieber 1986) or the ANLT formalism (Briscoe et al. 1987), with some interesting extensions making it more adequate to phenomena such as agreement in coordinate structures. Unfortunately, no comparison is offered. More discussion is devoted to comparison with the approach to corpus analysis taken by the Lancaster group (Garside et al. 1987); Oostdijk argues that because their espousal of probabilistic methods and rejection of a rule-based generative approach is not founded on sound empirical evidence, it is impossible to develop a comprehensive generative grammar for a corpus. While I am sympathetic to Oostdijk&apos;s position and think that the grammar she goes on to present is impressive enough to bias us towards the opposite conclusion, it is a mistake to accept the assumption that the two approaches are incompatible, as much recent work (including that of Black et al. 1992) has demonstrated the usefulness of combining statistical techniques with rule-based systems. The core of the book is a description of the grammar developed and analyses adopted for notoriously difficult phenomena, such as nonconstituent coordination, gapping, apposition, partitives, other noun phrase premodifier syntax, and so forth. The grammatical framework adopted is based on a conventional notion of constituency, with nodes assigned categorial labels augmented with functional categories encoding mostly familiar grammatical relations. The commitment to nonelliptical accounts of the full range of coordinate and gapped constructions that occur in the corpus leads to adoption of linguistically nonstandard analyses; for example, grouping phrase complements of verbs into single Once again, no reference is made to recent theoretical work addressing similar problems, such as extended categorial or combinatory grammar (e.g., Steedman 1985). Nevertheless, the coverage of the resultant grammar is impressive, and the (computational) linguist who has not developed a substantial grammar from natural data will find enough interesting insights, analyses, and detailed discussion of constructions sometimes ignored in the more mainstream generative literature to be convinced, I hope, of the value of corpus-based grammar development. There are, however, dangers, as well as strengths in this approach; for instance, the commitment to assign an analysis to each sentence of the corpus can easily lead to reification of undesirable decisions in the grammar and consequent propagation throughout the analyzed corpus: a case in point might be the use of ditransitive complement constituents introduced to deal with gapped examples. Corpus-based development and testing of a grammar requires computational support to be practical and, given the goal of the TOSCA project, a method is needed to select the semantically and pragmatically appropriate analysis from the set licensed by the grammar for each sentence in the corpus. A separate system is used to assign each word of the input sentence an unambiguous and correct lexical category compatible with the grammar developed. This system and the lexical categories are not described in the book but appear to be more fine-grained than the categories assigned by tagging programs (e.g., CLAWS2, Garside et al. 1987), incorporating subcategorization information concerning complementation, for instance. The parsing system then assigns analyses to this unambiguous sequence of lexical categories. Oostdijk does not describe the parser-generator or parser developed for the affix grammar formalism used, but instead concentrates on the issues of parse selection and performance both in terms of coverage and efficiency. Parse selection is done interactively by guiding the parser manually; Oostdijk justifies this approach by arguing that it ensures a high level of accuracy and guarantees parsing efficiency by pre-empting unnecessary 211 Computational Linguistics Volume 19, Number 1 search. An approach in which intervention is limited to selection between predefined legitimate analyses is an improvement on one in which the analyst is able to create new descriptions at will (e.g., Leech and Garside 1991) in that the resulting database of analyses will be consistent and intervention will be simpler and faster. However, other approaches are possible, such as the use of probabilities to guide parse selection, if not grammar induction (e.g., Black et al. 1992). Oostdijk does not consider this possibility, presumably because of her acceptance of the incompatibility of rule-based and statistical techniques. The decision to manually select parses, coupled with the fact that the TOSCA parser (on the hardware available) is not always able to compute all the possible analyses, even starting from unambiguous lexical categories, has the unfortunate side effect that a significant effort has been devoted to removing linguistically motivated ambiguity from the grammar. Earlier, Oostdijk argues for the strict separation of grammatical formalism and parsing algorithm on familiar grounds, but the same arguments tell against the decision, for instance, to stipulate that coordination occurs at specific nodes in case of ambiguity (p. 133), since such distinctions often correlate with differences of semantic scope. Despite these criticisms—and in a practical project of this type some compromises are inevitable--Oostdijk&apos;s achievement is impressive; her book is well written and easy to read, and she manages the difficult task of striking the right level between an exhaustive and exhausting documentation of a substantial grammar and a superficial overview. There are very few typographical errors and the book has been well produced. References Black, Ezra; Lafferty, John; and Roukos, Salim (1992). &amp;quot;Development and evaluation of a broad-coverage probabilistic grammar of English-language manuals.&amp;quot; 30th Annual Meeting of the Association for Linguistics, DE, 185-192. Briscoe, Ted; Grover, Claire; Boguraev, Bran; and Carroll, John (1987). &amp;quot;A formalism and environment for the development of a grammar of English.&amp;quot;</abstract>
<note confidence="0.77127285483871">10th International Joint Conference on Intelligence, 703-708. De Marcken, Carl G. (1990). &amp;quot;Parsing the Corpus.&amp;quot; 28th Annual Meeting of the Association for Computational 243-251. Garside, Roger; Leech, Geoffrey; and Geoffrey (1987). Computational Analysis of English: A Approach. Grover, Claire; Briscoe, Ted; Carroll, John; and Boguraev, Bran (1989). &amp;quot;The Alvey natural language tools grammar (second release).&amp;quot; Technical Report 162, University of Cambridge, Computer Laboratory. Hindle, Donald (1983). &amp;quot;User manual for Fidditch, a deterministic parser.&amp;quot; Technical Memorandum 7590-142, Naval Research Laboratory. Hindle, Donald (1993). &amp;quot;A parser for text In Approaches to Lexicon, by B. T. S. Atkins and A. Zampolli, Oxford University Press. In press. Jensen, Karen; Heidorn, George; Richardson, Stephen; and Haas, Norman (1986). &amp;quot;PLNLP, PEG and CRITIQUE: Three contributions to computing in the humanities.&amp;quot; Report RC-11841, IBM Thomas J. Watson Research Center. Koster, C. (1971). &amp;quot;Affix grammars.&amp;quot; In 68 Implementation, by John Peck, North-Holland. Leech, Geoffrey, and Garside, Roger (1991). &amp;quot;Running a grammar factory: The production of syntactically analysed or &apos;treebanks&apos;.&amp;quot; In Computer Corpora: Selected Papers and by Stig Johansson and A. Stenstrom, Mouton de Gruyter. Mitchell P. (1980). Theory of Syntactic Recognition for Natural Language. The MIT Press. Robinson, Joan (1982). &amp;quot;DIAGRAM: A for dialogues.&amp;quot; the ACM. Naomi (1981). Language Information Processing: A Computer Grammar of English and Its Applications. Addison-Wesley. 212 Book Reviews Stuart (1986). to Unification-Based Approaches to Grammar. Stanford, CA: Center for the Study of Language and Information. Steedman, Mark (1985). &amp;quot;Dependency and coordination in the grammar of Dutch English.&amp;quot; Briscoe a SERC Advanced Research Fellow at the Computer Laboratory, University of Cambridge. His current research interests include robust parsing of naturally occurring natural language. His address is: Computer Laboratory, University of Cambridge, Pembroke Street,</note>
<address confidence="0.7756685">Cambridge CB1 3AZ, UK; e-mail: ejb@cl.cam.ac.uk 213</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ezra Black</author>
<author>John Lafferty</author>
<author>Salim Roukos</author>
</authors>
<title>Development and evaluation of a broad-coverage probabilistic grammar of English-language computer manuals.&amp;quot;</title>
<date>1992</date>
<booktitle>Proceedings, 30th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>185--192</pages>
<location>Newark, DE,</location>
<contexts>
<context position="4286" citStr="Black et al. 1992" startWordPosition="659" endWordPosition="662">roach to corpus analysis taken by the Lancaster group (Garside et al. 1987); Oostdijk argues that because their espousal of probabilistic methods and rejection of a rule-based generative approach is not founded on sound empirical evidence, it is impossible to develop a comprehensive generative grammar for a corpus. While I am sympathetic to Oostdijk&apos;s position and think that the grammar she goes on to present is impressive enough to bias us towards the opposite conclusion, it is a mistake to accept the assumption that the two approaches are incompatible, as much recent work (including that of Black et al. 1992) has demonstrated the usefulness of combining statistical techniques with rule-based systems. The core of the book is a description of the grammar developed and analyses adopted for notoriously difficult phenomena, such as nonconstituent coordination, gapping, apposition, partitives, other noun phrase premodifier syntax, and so forth. The grammatical framework adopted is based on a conventional notion of constituency, with nodes assigned categorial labels augmented with functional categories encoding mostly familiar grammatical relations. The commitment to nonelliptical accounts of the full ra</context>
<context position="7836" citStr="Black et al. 1992" startWordPosition="1187" endWordPosition="1190"> a high level of accuracy and guarantees parsing efficiency by pre-empting unnecessary 211 Computational Linguistics Volume 19, Number 1 search. An approach in which intervention is limited to selection between predefined legitimate analyses is an improvement on one in which the analyst is able to create new descriptions at will (e.g., Leech and Garside 1991) in that the resulting database of analyses will be consistent and intervention will be simpler and faster. However, other approaches are possible, such as the use of probabilities to guide parse selection, if not grammar induction (e.g., Black et al. 1992). Oostdijk does not consider this possibility, presumably because of her acceptance of the incompatibility of rule-based and statistical techniques. The decision to manually select parses, coupled with the fact that the TOSCA parser (on the hardware available) is not always able to compute all the possible analyses, even starting from unambiguous lexical categories, has the unfortunate side effect that a significant effort has been devoted to removing linguistically motivated ambiguity from the grammar. Earlier, Oostdijk argues for the strict separation of grammatical formalism and parsing alg</context>
</contexts>
<marker>Black, Lafferty, Roukos, 1992</marker>
<rawString>Black, Ezra; Lafferty, John; and Roukos, Salim (1992). &amp;quot;Development and evaluation of a broad-coverage probabilistic grammar of English-language computer manuals.&amp;quot; Proceedings, 30th Annual Meeting of the Association for Computational Linguistics, Newark, DE, 185-192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>Claire Grover</author>
<author>Bran Boguraev</author>
<author>John Carroll</author>
</authors>
<title>A formalism and environment for the development of a large grammar of English.&amp;quot;</title>
<date>1987</date>
<booktitle>Proceedings, 10th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>703--708</pages>
<location>Milan,</location>
<contexts>
<context position="3458" citStr="Briscoe et al. 1987" startWordPosition="528" endWordPosition="531"> (Grover et al. 1989), and more corpus-oriented parsing systems, such as FIDDITCH (Hindle 1983, 1993) or MITFP (de Marcken 1990), have been developed within the field, but are not discussed anywhere. A similar suspicion of isolationism recurs in the sections dealing with the grammatical formalism used; 210 Book Reviews this is based on (extended) affix grammar (Koster 1971) and, although only described informally, the variant of affix grammar adopted is probably similar in generative and expressive capacity to unification-based formalisms, such as PATR-II (Shieber 1986) or the ANLT formalism (Briscoe et al. 1987), with some interesting extensions making it more adequate to phenomena such as agreement in coordinate structures. Unfortunately, no comparison is offered. More discussion is devoted to comparison with the approach to corpus analysis taken by the Lancaster group (Garside et al. 1987); Oostdijk argues that because their espousal of probabilistic methods and rejection of a rule-based generative approach is not founded on sound empirical evidence, it is impossible to develop a comprehensive generative grammar for a corpus. While I am sympathetic to Oostdijk&apos;s position and think that the grammar </context>
</contexts>
<marker>Briscoe, Grover, Boguraev, Carroll, 1987</marker>
<rawString>Briscoe, Ted; Grover, Claire; Boguraev, Bran; and Carroll, John (1987). &amp;quot;A formalism and environment for the development of a large grammar of English.&amp;quot; Proceedings, 10th International Joint Conference on Artificial Intelligence, Milan, 703-708.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl G De Marcken</author>
</authors>
<title>Parsing the LOB Corpus.&amp;quot;</title>
<date>1990</date>
<booktitle>Proceedings, 28th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>243--251</pages>
<location>Pittsburgh,</location>
<marker>De Marcken, 1990</marker>
<rawString>De Marcken, Carl G. (1990). &amp;quot;Parsing the LOB Corpus.&amp;quot; Proceedings, 28th Annual Meeting of the Association for Computational Linguistics, Pittsburgh, 243-251.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Garside</author>
<author>Geoffrey Leech</author>
<author>Geoffrey Sampson</author>
</authors>
<title>The Computational Analysis of English: A Corpus-Based Approach.</title>
<date>1987</date>
<publisher>Longman.</publisher>
<contexts>
<context position="3743" citStr="Garside et al. 1987" startWordPosition="571" endWordPosition="574">al formalism used; 210 Book Reviews this is based on (extended) affix grammar (Koster 1971) and, although only described informally, the variant of affix grammar adopted is probably similar in generative and expressive capacity to unification-based formalisms, such as PATR-II (Shieber 1986) or the ANLT formalism (Briscoe et al. 1987), with some interesting extensions making it more adequate to phenomena such as agreement in coordinate structures. Unfortunately, no comparison is offered. More discussion is devoted to comparison with the approach to corpus analysis taken by the Lancaster group (Garside et al. 1987); Oostdijk argues that because their espousal of probabilistic methods and rejection of a rule-based generative approach is not founded on sound empirical evidence, it is impossible to develop a comprehensive generative grammar for a corpus. While I am sympathetic to Oostdijk&apos;s position and think that the grammar she goes on to present is impressive enough to bias us towards the opposite conclusion, it is a mistake to accept the assumption that the two approaches are incompatible, as much recent work (including that of Black et al. 1992) has demonstrated the usefulness of combining statistical</context>
<context position="6686" citStr="Garside et al. 1987" startWordPosition="1015" endWordPosition="1018">development and testing of a grammar requires computational support to be practical and, given the goal of the TOSCA project, a method is needed to select the semantically and pragmatically appropriate analysis from the set licensed by the grammar for each sentence in the corpus. A separate system is used to assign each word of the input sentence an unambiguous and correct lexical category compatible with the grammar developed. This system and the lexical categories are not described in the book but appear to be more fine-grained than the categories assigned by tagging programs (e.g., CLAWS2, Garside et al. 1987), incorporating subcategorization information concerning complementation, for instance. The parsing system then assigns analyses to this unambiguous sequence of lexical categories. Oostdijk does not describe the parser-generator or parser developed for the affix grammar formalism used, but instead concentrates on the issues of parse selection and performance both in terms of coverage and efficiency. Parse selection is done interactively by guiding the parser manually; Oostdijk justifies this approach by arguing that it ensures a high level of accuracy and guarantees parsing efficiency by pre-e</context>
</contexts>
<marker>Garside, Leech, Sampson, 1987</marker>
<rawString>Garside, Roger; Leech, Geoffrey; and Sampson, Geoffrey (1987). The Computational Analysis of English: A Corpus-Based Approach. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Grover</author>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Bran Boguraev</author>
</authors>
<title>The Alvey natural language tools grammar (second release).&amp;quot;</title>
<date>1989</date>
<tech>Technical Report 162,</tech>
<institution>University of Cambridge, Computer Laboratory.</institution>
<contexts>
<context position="2859" citStr="Grover et al. 1989" startWordPosition="439" endWordPosition="442">er book: the development of the grammar and performance of the associated parser, since this is the part that is most relevant to computational linguistics. Oostdijk begins by locating her work and the TOSCA project within the field of computational linguistics (arguing that it is distinguished by &amp;quot;an interest in language itself as it is actually produced&amp;quot; (p. 2)) and contrasting it to the LSP system (Sager 1981) and Parsifal (Marcus 1980). The comparison is brief and the choice odd since more general broad-coverage grammars, such as DIAGRAM (Robinson 1982), PEG (Jensen et al. 1986) and ANLT (Grover et al. 1989), and more corpus-oriented parsing systems, such as FIDDITCH (Hindle 1983, 1993) or MITFP (de Marcken 1990), have been developed within the field, but are not discussed anywhere. A similar suspicion of isolationism recurs in the sections dealing with the grammatical formalism used; 210 Book Reviews this is based on (extended) affix grammar (Koster 1971) and, although only described informally, the variant of affix grammar adopted is probably similar in generative and expressive capacity to unification-based formalisms, such as PATR-II (Shieber 1986) or the ANLT formalism (Briscoe et al. 1987),</context>
</contexts>
<marker>Grover, Briscoe, Carroll, Boguraev, 1989</marker>
<rawString>Grover, Claire; Briscoe, Ted; Carroll, John; and Boguraev, Bran (1989). &amp;quot;The Alvey natural language tools grammar (second release).&amp;quot; Technical Report 162, University of Cambridge, Computer Laboratory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>User manual for Fidditch, a deterministic parser.&amp;quot;</title>
<date>1983</date>
<tech>Technical Memorandum 7590-142,</tech>
<institution>Naval Research Laboratory.</institution>
<contexts>
<context position="2932" citStr="Hindle 1983" startWordPosition="451" endWordPosition="452"> since this is the part that is most relevant to computational linguistics. Oostdijk begins by locating her work and the TOSCA project within the field of computational linguistics (arguing that it is distinguished by &amp;quot;an interest in language itself as it is actually produced&amp;quot; (p. 2)) and contrasting it to the LSP system (Sager 1981) and Parsifal (Marcus 1980). The comparison is brief and the choice odd since more general broad-coverage grammars, such as DIAGRAM (Robinson 1982), PEG (Jensen et al. 1986) and ANLT (Grover et al. 1989), and more corpus-oriented parsing systems, such as FIDDITCH (Hindle 1983, 1993) or MITFP (de Marcken 1990), have been developed within the field, but are not discussed anywhere. A similar suspicion of isolationism recurs in the sections dealing with the grammatical formalism used; 210 Book Reviews this is based on (extended) affix grammar (Koster 1971) and, although only described informally, the variant of affix grammar adopted is probably similar in generative and expressive capacity to unification-based formalisms, such as PATR-II (Shieber 1986) or the ANLT formalism (Briscoe et al. 1987), with some interesting extensions making it more adequate to phenomena su</context>
</contexts>
<marker>Hindle, 1983</marker>
<rawString>Hindle, Donald (1983). &amp;quot;User manual for Fidditch, a deterministic parser.&amp;quot; Technical Memorandum 7590-142, Naval Research Laboratory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>A parser for text corpora.&amp;quot; In Computational Approaches to the Lexicon, edited by</title>
<date>1993</date>
<publisher>University Press. In press.</publisher>
<location>Oxford</location>
<marker>Hindle, 1993</marker>
<rawString>Hindle, Donald (1993). &amp;quot;A parser for text corpora.&amp;quot; In Computational Approaches to the Lexicon, edited by B. T. S. Atkins and A. Zampolli, Oxford University Press. In press.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jensen</author>
</authors>
<location>Karen; Heidorn, George;</location>
<marker>Jensen, </marker>
<rawString>Jensen, Karen; Heidorn, George;</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Richardson</author>
<author>Norman Haas</author>
</authors>
<title>PLNLP, PEG and CRITIQUE: Three contributions to computing in the humanities.&amp;quot; Report RC-11841,</title>
<date>1986</date>
<journal>IBM Thomas J. Watson Research Center.</journal>
<marker>Richardson, Haas, 1986</marker>
<rawString>Richardson, Stephen; and Haas, Norman (1986). &amp;quot;PLNLP, PEG and CRITIQUE: Three contributions to computing in the humanities.&amp;quot; Report RC-11841, IBM Thomas J. Watson Research Center.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Koster</author>
</authors>
<title>Affix grammars.&amp;quot;</title>
<date>1971</date>
<booktitle>In ALGOL 68 Implementation,</booktitle>
<note>edited by John Peck, North-Holland.</note>
<contexts>
<context position="3214" citStr="Koster 1971" startWordPosition="495" endWordPosition="496"> 2)) and contrasting it to the LSP system (Sager 1981) and Parsifal (Marcus 1980). The comparison is brief and the choice odd since more general broad-coverage grammars, such as DIAGRAM (Robinson 1982), PEG (Jensen et al. 1986) and ANLT (Grover et al. 1989), and more corpus-oriented parsing systems, such as FIDDITCH (Hindle 1983, 1993) or MITFP (de Marcken 1990), have been developed within the field, but are not discussed anywhere. A similar suspicion of isolationism recurs in the sections dealing with the grammatical formalism used; 210 Book Reviews this is based on (extended) affix grammar (Koster 1971) and, although only described informally, the variant of affix grammar adopted is probably similar in generative and expressive capacity to unification-based formalisms, such as PATR-II (Shieber 1986) or the ANLT formalism (Briscoe et al. 1987), with some interesting extensions making it more adequate to phenomena such as agreement in coordinate structures. Unfortunately, no comparison is offered. More discussion is devoted to comparison with the approach to corpus analysis taken by the Lancaster group (Garside et al. 1987); Oostdijk argues that because their espousal of probabilistic methods </context>
</contexts>
<marker>Koster, 1971</marker>
<rawString>Koster, C. (1971). &amp;quot;Affix grammars.&amp;quot; In ALGOL 68 Implementation, edited by John Peck, North-Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Leech</author>
<author>Roger Garside</author>
</authors>
<title>Running a grammar factory: The production of syntactically analysed corpora or &apos;treebanks&apos;.&amp;quot; In English Computer Corpora: Selected Papers and Bibliography, edited by Stig Johansson</title>
<date>1991</date>
<contexts>
<context position="7579" citStr="Leech and Garside 1991" startWordPosition="1145" endWordPosition="1148"> formalism used, but instead concentrates on the issues of parse selection and performance both in terms of coverage and efficiency. Parse selection is done interactively by guiding the parser manually; Oostdijk justifies this approach by arguing that it ensures a high level of accuracy and guarantees parsing efficiency by pre-empting unnecessary 211 Computational Linguistics Volume 19, Number 1 search. An approach in which intervention is limited to selection between predefined legitimate analyses is an improvement on one in which the analyst is able to create new descriptions at will (e.g., Leech and Garside 1991) in that the resulting database of analyses will be consistent and intervention will be simpler and faster. However, other approaches are possible, such as the use of probabilities to guide parse selection, if not grammar induction (e.g., Black et al. 1992). Oostdijk does not consider this possibility, presumably because of her acceptance of the incompatibility of rule-based and statistical techniques. The decision to manually select parses, coupled with the fact that the TOSCA parser (on the hardware available) is not always able to compute all the possible analyses, even starting from unambi</context>
</contexts>
<marker>Leech, Garside, 1991</marker>
<rawString>Leech, Geoffrey, and Garside, Roger (1991). &amp;quot;Running a grammar factory: The production of syntactically analysed corpora or &apos;treebanks&apos;.&amp;quot; In English Computer Corpora: Selected Papers and Bibliography, edited by Stig Johansson and A. Stenstrom, Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
</authors>
<title>A Theory of Syntactic Recognition for Natural Language.</title>
<date>1980</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="2683" citStr="Marcus 1980" startWordPosition="412" endWordPosition="413">corpus material, as well as the exploitation of the analyzed corpus in studies of language variation. However, in this review I will concentrate on the central core of her book: the development of the grammar and performance of the associated parser, since this is the part that is most relevant to computational linguistics. Oostdijk begins by locating her work and the TOSCA project within the field of computational linguistics (arguing that it is distinguished by &amp;quot;an interest in language itself as it is actually produced&amp;quot; (p. 2)) and contrasting it to the LSP system (Sager 1981) and Parsifal (Marcus 1980). The comparison is brief and the choice odd since more general broad-coverage grammars, such as DIAGRAM (Robinson 1982), PEG (Jensen et al. 1986) and ANLT (Grover et al. 1989), and more corpus-oriented parsing systems, such as FIDDITCH (Hindle 1983, 1993) or MITFP (de Marcken 1990), have been developed within the field, but are not discussed anywhere. A similar suspicion of isolationism recurs in the sections dealing with the grammatical formalism used; 210 Book Reviews this is based on (extended) affix grammar (Koster 1971) and, although only described informally, the variant of affix gramma</context>
</contexts>
<marker>Marcus, 1980</marker>
<rawString>Marcus, Mitchell P. (1980). A Theory of Syntactic Recognition for Natural Language. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan Robinson</author>
</authors>
<title>DIAGRAM: A grammar for dialogues.&amp;quot;</title>
<date>1982</date>
<journal>Communications of the ACM.</journal>
<volume>25</volume>
<issue>1</issue>
<pages>27--47</pages>
<contexts>
<context position="2803" citStr="Robinson 1982" startWordPosition="430" endWordPosition="431"> review I will concentrate on the central core of her book: the development of the grammar and performance of the associated parser, since this is the part that is most relevant to computational linguistics. Oostdijk begins by locating her work and the TOSCA project within the field of computational linguistics (arguing that it is distinguished by &amp;quot;an interest in language itself as it is actually produced&amp;quot; (p. 2)) and contrasting it to the LSP system (Sager 1981) and Parsifal (Marcus 1980). The comparison is brief and the choice odd since more general broad-coverage grammars, such as DIAGRAM (Robinson 1982), PEG (Jensen et al. 1986) and ANLT (Grover et al. 1989), and more corpus-oriented parsing systems, such as FIDDITCH (Hindle 1983, 1993) or MITFP (de Marcken 1990), have been developed within the field, but are not discussed anywhere. A similar suspicion of isolationism recurs in the sections dealing with the grammatical formalism used; 210 Book Reviews this is based on (extended) affix grammar (Koster 1971) and, although only described informally, the variant of affix grammar adopted is probably similar in generative and expressive capacity to unification-based formalisms, such as PATR-II (Sh</context>
</contexts>
<marker>Robinson, 1982</marker>
<rawString>Robinson, Joan (1982). &amp;quot;DIAGRAM: A grammar for dialogues.&amp;quot; Communications of the ACM. 25(1), 27-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naomi Sager</author>
</authors>
<title>Natural Language Information Processing: A Computer Grammar of English and Its Applications.</title>
<date>1981</date>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="2656" citStr="Sager 1981" startWordPosition="408" endWordPosition="409">pling and tokenization of corpus material, as well as the exploitation of the analyzed corpus in studies of language variation. However, in this review I will concentrate on the central core of her book: the development of the grammar and performance of the associated parser, since this is the part that is most relevant to computational linguistics. Oostdijk begins by locating her work and the TOSCA project within the field of computational linguistics (arguing that it is distinguished by &amp;quot;an interest in language itself as it is actually produced&amp;quot; (p. 2)) and contrasting it to the LSP system (Sager 1981) and Parsifal (Marcus 1980). The comparison is brief and the choice odd since more general broad-coverage grammars, such as DIAGRAM (Robinson 1982), PEG (Jensen et al. 1986) and ANLT (Grover et al. 1989), and more corpus-oriented parsing systems, such as FIDDITCH (Hindle 1983, 1993) or MITFP (de Marcken 1990), have been developed within the field, but are not discussed anywhere. A similar suspicion of isolationism recurs in the sections dealing with the grammatical formalism used; 210 Book Reviews this is based on (extended) affix grammar (Koster 1971) and, although only described informally, </context>
</contexts>
<marker>Sager, 1981</marker>
<rawString>Sager, Naomi (1981). Natural Language Information Processing: A Computer Grammar of English and Its Applications. Addison-Wesley.</rawString>
</citation>
<citation valid="false">
<institution>Book Reviews</institution>
<marker></marker>
<rawString>Book Reviews</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
</authors>
<title>Introduction to Unification-Based Approaches to Grammar. Stanford, CA: Center for the Study of Language and Information.</title>
<date>1986</date>
<contexts>
<context position="3414" citStr="Shieber 1986" startWordPosition="522" endWordPosition="523">2), PEG (Jensen et al. 1986) and ANLT (Grover et al. 1989), and more corpus-oriented parsing systems, such as FIDDITCH (Hindle 1983, 1993) or MITFP (de Marcken 1990), have been developed within the field, but are not discussed anywhere. A similar suspicion of isolationism recurs in the sections dealing with the grammatical formalism used; 210 Book Reviews this is based on (extended) affix grammar (Koster 1971) and, although only described informally, the variant of affix grammar adopted is probably similar in generative and expressive capacity to unification-based formalisms, such as PATR-II (Shieber 1986) or the ANLT formalism (Briscoe et al. 1987), with some interesting extensions making it more adequate to phenomena such as agreement in coordinate structures. Unfortunately, no comparison is offered. More discussion is devoted to comparison with the approach to corpus analysis taken by the Lancaster group (Garside et al. 1987); Oostdijk argues that because their espousal of probabilistic methods and rejection of a rule-based generative approach is not founded on sound empirical evidence, it is impossible to develop a comprehensive generative grammar for a corpus. While I am sympathetic to Oos</context>
</contexts>
<marker>Shieber, 1986</marker>
<rawString>Shieber, Stuart (1986). Introduction to Unification-Based Approaches to Grammar. Stanford, CA: Center for the Study of Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Dependency and coordination in the grammar of Dutch and English.&amp;quot;</title>
<date>1985</date>
<journal>Language,</journal>
<volume>62</volume>
<pages>523--568</pages>
<contexts>
<context position="5267" citStr="Steedman 1985" startWordPosition="798" endWordPosition="799">ted is based on a conventional notion of constituency, with nodes assigned categorial labels augmented with functional categories encoding mostly familiar grammatical relations. The commitment to nonelliptical accounts of the full range of coordinate and gapped constructions that occur in the corpus leads to adoption of linguistically nonstandard analyses; for example, grouping noun phrase complements of ditransitive verbs into single constituents. Once again, no reference is made to recent theoretical work addressing similar problems, such as extended categorial or combinatory grammar (e.g., Steedman 1985). Nevertheless, the coverage of the resultant grammar is impressive, and the (computational) linguist who has not developed a substantial grammar from natural data will find enough interesting insights, analyses, and detailed discussion of constructions sometimes ignored in the more mainstream generative literature to be convinced, I hope, of the value of corpus-based grammar development. There are, however, dangers, as well as strengths in this approach; for instance, the commitment to assign an analysis to each sentence of the corpus can easily lead to reification of undesirable decisions in</context>
</contexts>
<marker>Steedman, 1985</marker>
<rawString>Steedman, Mark (1985). &amp;quot;Dependency and coordination in the grammar of Dutch and English.&amp;quot; Language, 62, 523-568.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ted</author>
</authors>
<title>Briscoe is a SERC Advanced Research Fellow at the Computer Laboratory, University of Cambridge. His current research interests include robust parsing of naturally occurring natural language. His address is:</title>
<institution>Computer Laboratory, University of Cambridge, Pembroke Street, Cambridge</institution>
<note>CB1 3AZ, UK; e-mail: ejb@cl.cam.ac.uk</note>
<marker>Ted, </marker>
<rawString>Ted Briscoe is a SERC Advanced Research Fellow at the Computer Laboratory, University of Cambridge. His current research interests include robust parsing of naturally occurring natural language. His address is: Computer Laboratory, University of Cambridge, Pembroke Street, Cambridge CB1 3AZ, UK; e-mail: ejb@cl.cam.ac.uk</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>