<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001960">
<note confidence="0.547218">
Book Reviews Machine Translation: Past, Present, Future
</note>
<bodyText confidence="0.999931837837838">
presented as the only significant computational contri-
butions. There is no discussion of processing as it is
defined computationally. There is no mention of proc-
essing concerns that require integration of some of the
issues raised in other chapters (Chapters 2, 4, and 5),
such as the knowledge base necessary for natural lan-
guage processing and the fact that one must consider
what control structures or procedures must be in place
to process language. These issues are never related to
language as a process.
The emphasis is on more psycholinguistically moti-
vated approaches and perhaps that is why the compu-
tational aspects included are biased to only include
those which emphasize meaning representations as
scripts and schemas while ignoring all other computa-
tional approaches. Computational language processing
approaches that are omitted range from the ATN work
of Woods (1970) to the ARPA projects of the mid-&apos;70s
(HWIM, Woods et al. 1976, HEARSAY-II, Erman et al.
1980). These are the biggest omissions and limit the use
of this text to introduce natural language processing or
to form a basis for a computational linguistics course.
However, one can supplement this by using the discus-
sion of language processing in a suitable introductory Al
text such as Barr and Feigenbaum (1981).
In conclusion, this book is an excellent attempt to
present aspects of cognitive science from within disci-
plines that are each approaching its study. For introduc-
tory NLP or computational linguistic study, I would use
this at least as a supplementary text. I know of no other
equally broad and comprehensive source of material
that is relevant to language study from so many per-
spectives. Given the above-stated problems, I would
also be prepared to supplement the book in ways
previously discussed. This is especially critical to the
issues of natural language processing and to integrating
viewpoints of the same problem across the discussion.
</bodyText>
<sectionHeader confidence="0.993607" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.813373666666667">
Anderson, J.R. 1983 The Architecture of Cognition, Harvard Univer-
sity Press, Cambridge, MA.
Barr, A. and Feigenbaum, E.A. 1981 The Handbook of Artificial
Intelligence 1, William Kaufmann, Inc.
Collins, A.M. and Loftus, E.F. 1975 A Spreading Activation Theory
of Semantic Processing. Psychological Review 82(6): 407-428.
</reference>
<tableCaption confidence="0.297585678571429">
Erman, L.D., Hayes-Roth, F., Lesser, V.R., and Reddy, D.R. 1980
The HEARSAY-II speech-understanding system: Integrating
knowledge to resolve uncertainty. Computing Surveys 12: 213-
253.
Goodglass, H. and Kaplan, E. 1983 The Assessment of Aphasia and
Related Disorders (2nd ed.). Lea and Febiger.
Kertesz, A. 1979 Aphasia and Associated Disorders: Taxonomy,
Localization, and Recovery. Grune and Stratton.
Newell, A. and Simon, H.A. 1972 Human problem solving. Prentice-
Hall, Englewood Cliffs, NJ.
Quillian, M.R. 1968 Semantic Memory. In M. Minsky (ed.), Semantic
Information Processing. MIT Press, Cambridge, MA.
Winograd, T. 1972 Understanding Natural Language. Academic
Press, New York, NY.
Woods, W.A. 1970 Transition Network Grammars for Natural Lan-
guage Analysis. Communications of the ACM 13(10): 591-606.
Woods, W. A.; Bates, M.; Brown, G.; Bruce, B.; Cook, C.; Klovstad,
J.; Maldoul, J.; Nash-Webber, B.; Schwartz, R.; Wolf, J.; and
Zue, V. 1976 Speech Understanding Systems—Final Report.
Technicd Report 3438, Volume 4, Bolt Beranek and Newman,
Inc.
Helen Gigley&apos; s areas of interest include computational linguis-
tics and neurolinguistics, artificial intelligence and neurophy-
siology, and neural-based cognitive modeling. She received a
Ph.D. in computer science in 1982 from the University of
Massachusetts, Amherst. Gigley&apos;s address is National Sci-
ence Foundation, 1800 G St., NW, Rm. 304, Washington, DC
20550. E-mail: hgigley@note.nsf.gov
</tableCaption>
<figure confidence="0.814632636363636">
MACHINE TRANSLATION: PAST, PRESENT, FUTURE.
William John Hutchins
University of East Anglia)
(Ellis Horwood Series in Computers and their
Applications)
Ellis Horwood: Chichester, 1986, 382 pp.
ISBN 0-85312-788-3, $49.95 (hb)
Reviewed by
Richard Kittredge
Universite de Montreal and Odyssey Research Asso-
ciates
</figure>
<bodyText confidence="0.9991589">
Most computational linguists are probably aware that
machine translation (MT) has provided the impetus for
a number of important advances in linguistics and
computing over the past 40 years. But even those who
have worked on MT could not have fully appreciated
the breadth, depth and impact of MT activity around the
globe before reading Hutchins&apos;s book Machine Trans-
lation: Past, Present, Future. For most of us, I think, its
publication has come as a very pleasant and welcome
surprise for a number of reasons. First, the recent
reawakening of interest in MT worldwide calls for a
balanced historical overview of the approaches used
and the experience gained to date. Hutchins&apos;s volume
helps satisfy this need for a critical collective conscious-
ness, and sets a high standard for future works of this
nature.
Second, Hutchins&apos;s thorough treatment of the his-
tory of MT is interspersed with short summaries of the
technical problems and approaches in linguistic analysis
and natural language processing as they have related to
MT. The result is a very readable and even entertaining
book, which can serve as an introduction to the field for
a wide audience including not only translators, linguists,
and computer scientists, but also the general (techni-
cally literate) public. The students in my graduate MT
seminar, for example, have found it the most useful
single book on the subject.
Third, it satisfies the long-standing need for a good
single-volume reference on MT. Its detailed and cross-
referenced description of virtually all known MT
</bodyText>
<page confidence="0.906776">
118 Computational Linguistics, Volume 14, Number 3, September 1988
</page>
<note confidence="0.649751">
Book Reviews Machine Translation: Past, Present, Future
</note>
<bodyText confidence="0.992673751515152">
projects (to 1985), including a chronological table of
main projects and systems, its 33-page bibliography,
and its index all contribute to make it the definitive
reference work on MT today. Whatever shortcomings
may be found in this book (see below) are relatively
minor when compared to Hutchins&apos;s impressive
achievement.
Working largely on the basis of published documents
and technical reports augmented by personal correspon-
dence, Hutchins has pieced together a remarkable his-
torical overview of the approaches and accomplish-
ments of some 70 different MT projects and systems.
Here one can find, for example, a whole chapter de-
voted to &amp;quot;Groups and projects in the Soviet Union and
Eastern Europe (1955-1967)&amp;quot; as well as an account of
the story behind the ALPAC report, notes on the origin
of purported MT &amp;quot;howlers&amp;quot; (such as &amp;quot;out of sight, out
of mind&amp;quot; translated as &amp;quot;invisible lunatic&amp;quot;) and other
lore.
Machine Translation deals primarily with the well-
established past. It is, in Hutchins&apos;s words &amp;quot;a history
and assessment of efforts to mechanise processes of
translating from one natural language into another.&amp;quot;
The final chapter, on &amp;quot;present developments and future
prospects&amp;quot;, highlights artificial intelligence approaches
and increasing commercial activity, including work on
translators&apos; aids. The main thrust, however, is histori-
cal, with nearly half the book detailing the widespread
activity that preceded the publication of the ALPAC
report in 1966.
Hutchins has done a historian&apos;s work. He traces
MT&apos;s intellectual origins from 17th-century notions of a
universal language. We hear about two 1933 patents for
translation machines by French and Russian inventors,
and are treated to a fascinating account of the early
post-war period. A substantial chapter on &amp;quot;problems,
methods and strategies&amp;quot; then outlines the background
issues in semantics, syntax, and morphology and intro-
duces the basic design options for MT systems. The
remaining chapters are organized roughly according to
decades. A 50-page chapter covers the U.S. scene
through 1966, when dozens of American MT projects
sprouted like mushrooms, only to wither away in dis-
appointment or digress into linguistic theory or the
computational prerequisites of sentence parsing. Chap-
ters 5-7 recount the parallel activities in Western Eu-
rope, Eastern Europe, and the Orient (plus Mexico)
during the decade ending in 1966. Chapter 8 details the
stocktaking of the mid-1960s culminating in the devas-
tating ALPAC report.
The ALPAC watershed is also reflected in the book&apos;s
structure. Chapter 9 sets the stage for the post-ALPAC
era by surveying the strategies and methods introduced
after 1966. Chapters 10 and 11 deal with interlingual
systems and other indirect systems between 1965 and
1975, including the early work at Grenoble and Texas
and on Mere&apos;uk&apos;s Meaning-Text Model. The operational
systems of Systran, Logos, and the Pan American
Health Organization are treated together in a chapter on
direct translation models. Another substantial chapter
on transfer systems contains the main presentation of
the TAUM, SUSY, GETA, and METAL project achieve-
ments. Chapter 14 is devoted to the use of Systran by
the Commission of the European Communities, and to
the growth of the Eurotra project. Chapter 15 covers the
birth of &amp;quot;artificial intelligence systems&amp;quot; starting with
Wilks at Stanford, and including the experiments of
Schank and his students at Yale, and Nirenburg when at
Colgate. The following chapter on recent interlingual
projects introduces DLT and its use of Esperanto.
Chapter 17, on interactive and human-aided systems,
presents, among others, the Brigham Young University
approach and its two commercial implementations at
ALPS and WCC (Weidner). The penultimate chapter is
devoted to work in the USSR and Japan since 1974. The
fact that a mere eight pages here serve to cover a decade
of Japanese effort is due more to the relative scarcity of
Japanese tech reports in English in 1985 than to the state
of the art in Japan at that time.
I found Machine Translation to be quite fair and
accurate, on the whole, in historical details that I have
been able to verify. Hutchins has been careful to use
original quotations from published material where
claims might be open to debate. But the necessity of
relying on printed sources can give an incomplete
perspective on some projects. In the case of the Mon-
treal TAUM project, for example, the documents avail-
able to Hutchins did not reveal the importance of the
linguistic inspiration for the systems coming from the
University of Pennsylvania school of distributional
analysis and surface structure transformationalism (Z.
Harris et al.). Although the implemented models for
TAUM73, TAUM-METEO, and AVIATION were the-
oretically eclectic (borrowing insights from Fillmore&apos;s
case grammar, as well as from Chomsky and Tesniere),
there was a strong link between the Pennsylvania-
trained linguists at TAUM and the NYU practitioners of
string grammar and sublanguage analysis (Sager et al.),
who had also come from the Pennsylvania school. The
influence of the Grenoble CETA/GETA group on
TAUM, cited by Hutchins, was therefore limited mostly
to broad questions of MT strategy during the years
1965-68, after which the two projects developed along
independent lines, albeit in close communication.
Some current MT researchers may feel that Hutchins
places too much emphasis on the more distant past.
(For example, fully half of the bibliographical refer-
ences are to work published before 1968.) To some
extent this is simply a function of the quantity of early
work published. But it is also indicative of the quality of
work by scores of talented people on MT in the 1950s
and 1960s and of the rapid evolution taking place in
linguistics and computer science.
Hutchins reminds us of the distinguished linguists
who cut their analytical teeth on MT problems, or in
MT-funded laboratories: Noam Chomsky, Charles Fill-
Computational Linguistics, Volume 14, Number 3, September 1988 119
Book Reviews Machine Translation: Past, Present, Future
more, Joseph Grimes, M.A.K. Halliday, Susumo Kuno,
Sidney Lamb, John Lyons, James McCawley, and Igor
Mel&apos;euk, to name but a few. Some of the advances in
computing which resulted largely from work in MT
laboratories include the foundations of formal language
theory (Chomsky at MIT), ATN parsers (Woods at
Harvard), and Prolog (from Colmerauer&apos;s Q-systems at
Montreal).
Purists might object to the condensed treatment that
Hutchins (necessarily) gives to topics in linguistics and
computing. In general, I found these summaries quite
fitting and accurate, given the context. Only on a few
occasions, such as on page 48, where Hutchins seems,
by implication, to equate phrase structure grammars
with finite state grammars, would I have liked to see the
passage extended or reformulated.
Another possible criticism might arise in the qualita-
tive selection of references. Hutchins has apparently
made an effort not to slight any significant contributor
to the field, particularly where a new project or ap-
proach is involved. At the same time, those who have
argued against MT in favor of machine aids for transla-
tors are not cited, presumably because Hutchins states
at the outset that machine-aided human translation is
outside the scope of Machine Translation. Still, a
reference to Martin Kay&apos;s numerous and persuasive
suggestions over the years regarding the translator-
machine interface would have been appropriate, given
the present trends towards interactive systems and
translator workstations. Another minor gap is the lack
of any reference to COLING conferences or COLING
proceedings before 1982, when in fact COLING has
been the major forum for MT discussion and the con-
ference proceedings still are a primary source of MT
project information.
Despite minor drawbacks of the kind mentioned
above, Hutchins&apos;s book stands as a major achievement.
It is generally balanced and objective, as complete as
one could want, and throughly informative and read-
able. It should enjoy wide readership, particularly if it
can be brought out in a less expensive student&apos;s edition.
Even at the hardcover price, anyone seriously inter-
ested in MT cannot afford to be without this book.
Richard Kittredge was one of the principals of the TAUM
machine translation project. His address is: Departement de
Linguistique, Universitd de Montréal, C.P. 6128, Succ. A,
Montréal, Québec, Canada H3C 3J7.
</bodyText>
<page confidence="0.927882">
120 Computational Linguistics, Volume 14, Number 3, September 1988
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.006969">
<title confidence="0.50832">Book Reviews Machine Translation: Past, Present, Future</title>
<abstract confidence="0.988767945945946">presented as the only significant computational contributions. There is no discussion of processing as it is defined computationally. There is no mention of processing concerns that require integration of some of the issues raised in other chapters (Chapters 2, 4, and 5), such as the knowledge base necessary for natural language processing and the fact that one must consider what control structures or procedures must be in place language. These issues are never related to language as a process. The emphasis is on more psycholinguistically motivated approaches and perhaps that is why the computational aspects included are biased to only include those which emphasize meaning representations as scripts and schemas while ignoring all other computational approaches. Computational language processing approaches that are omitted range from the ATN work of Woods (1970) to the ARPA projects of the mid-&apos;70s (HWIM, Woods et al. 1976, HEARSAY-II, Erman et al. 1980). These are the biggest omissions and limit the use of this text to introduce natural language processing or to form a basis for a computational linguistics course. However, one can supplement this by using the discussion of language processing in a suitable introductory Al text such as Barr and Feigenbaum (1981). In conclusion, this book is an excellent attempt to present aspects of cognitive science from within disciplines that are each approaching its study. For introductory NLP or computational linguistic study, I would use at least as a supplementary text. of no other equally broad and comprehensive source of material that is relevant to language study from so many perspectives. Given the above-stated problems, I would also be prepared to supplement the book in ways previously discussed. This is especially critical to the issues of natural language processing and to integrating viewpoints of the same problem across the discussion.</abstract>
<note confidence="0.889571027777778">REFERENCES J.R. 1983 Architecture of Cognition, University Press, Cambridge, MA. A. and Feigenbaum, E.A. 1981 Handbook of Artificial 1, Kaufmann, Inc. Collins, A.M. and Loftus, E.F. 1975 A Spreading Activation Theory Semantic Processing. Review 407-428. Erman, L.D., Hayes-Roth, F., Lesser, V.R., and Reddy, D.R. 1980 The HEARSAY-II speech-understanding system: Integrating to resolve uncertainty. Surveys 213- 253. H. and Kaplan, E. 1983 Assessment of Aphasia and Disorders ed.). Lea and Febiger. A. 1979 and Associated Disorders: Taxonomy, and Recovery. and Stratton. A. and Simon, H.A. 1972 problem solving. Prentice- Hall, Englewood Cliffs, NJ. M.R. 1968 Semantic Memory. In M. Minsky (ed.), Processing. Press, Cambridge, MA. T. 1972 Natural Language. Press, New York, NY. Woods, W.A. 1970 Transition Network Grammars for Natural Lan- Analysis. of the ACM 591-606. Woods, W. A.; Bates, M.; Brown, G.; Bruce, B.; Cook, C.; Klovstad, J.; Maldoul, J.; Nash-Webber, B.; Schwartz, R.; Wolf, J.; and Zue, V. 1976 Speech Understanding Systems—Final Report. Technicd Report 3438, Volume 4, Bolt Beranek and Newman, Inc. Gigley&apos; s of interest include computational linguistics and neurolinguistics, artificial intelligence and neurophysiology, and neural-based cognitive modeling. She received a Ph.D. in computer science in 1982 from the University of Massachusetts, Amherst. Gigley&apos;s address is National Science Foundation, 1800 G St., NW, Rm. 304, Washington, DC 20550. E-mail: hgigley@note.nsf.gov MACHINE TRANSLATION: PAST, PRESENT, FUTURE.</note>
<author confidence="0.895121">William John Hutchins</author>
<affiliation confidence="0.882828">University of East Anglia</affiliation>
<note confidence="0.9053196">(Ellis Horwood Series in Computers and their Applications) Ellis Horwood: Chichester, 1986, 382 pp. ISBN 0-85312-788-3, $49.95 (hb) Reviewed by</note>
<author confidence="0.99543">Richard Kittredge</author>
<affiliation confidence="0.968326">Universite de Montreal and Odyssey Research Asso-</affiliation>
<email confidence="0.574404">ciates</email>
<abstract confidence="0.982772904761905">Most computational linguists are probably aware that machine translation (MT) has provided the impetus for a number of important advances in linguistics and computing over the past 40 years. But even those who have worked on MT could not have fully appreciated breadth, depth and of MT activity around the before reading Hutchins&apos;s book Trans- Past, Present, Future. most of us, its publication has come as a very pleasant and welcome surprise for a number of reasons. First, the recent reawakening of interest in MT worldwide calls for a balanced historical overview of the approaches used and the experience gained to date. Hutchins&apos;s volume helps satisfy this need for a critical collective consciousness, and sets a high standard for future works of this nature. Second, Hutchins&apos;s thorough treatment of the history of MT is interspersed with short summaries of the technical problems and approaches in linguistic analysis and natural language processing as they have related to MT. The result is a very readable and even entertaining</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J R Anderson</author>
</authors>
<title>The Architecture of Cognition,</title>
<date>1983</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Anderson, 1983</marker>
<rawString>Anderson, J.R. 1983 The Architecture of Cognition, Harvard University Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Barr</author>
<author>E A Feigenbaum</author>
</authors>
<date>1981</date>
<booktitle>The Handbook of Artificial Intelligence 1,</booktitle>
<publisher>Kaufmann, Inc.</publisher>
<location>William</location>
<contexts>
<context position="1348" citStr="Barr and Feigenbaum (1981)" startWordPosition="211" endWordPosition="214">se which emphasize meaning representations as scripts and schemas while ignoring all other computational approaches. Computational language processing approaches that are omitted range from the ATN work of Woods (1970) to the ARPA projects of the mid-&apos;70s (HWIM, Woods et al. 1976, HEARSAY-II, Erman et al. 1980). These are the biggest omissions and limit the use of this text to introduce natural language processing or to form a basis for a computational linguistics course. However, one can supplement this by using the discussion of language processing in a suitable introductory Al text such as Barr and Feigenbaum (1981). In conclusion, this book is an excellent attempt to present aspects of cognitive science from within disciplines that are each approaching its study. For introductory NLP or computational linguistic study, I would use this at least as a supplementary text. I know of no other equally broad and comprehensive source of material that is relevant to language study from so many perspectives. Given the above-stated problems, I would also be prepared to supplement the book in ways previously discussed. This is especially critical to the issues of natural language processing and to integrating viewpo</context>
</contexts>
<marker>Barr, Feigenbaum, 1981</marker>
<rawString>Barr, A. and Feigenbaum, E.A. 1981 The Handbook of Artificial Intelligence 1, William Kaufmann, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Collins</author>
<author>E F Loftus</author>
</authors>
<title>A Spreading Activation Theory of Semantic Processing.</title>
<date>1975</date>
<journal>Psychological Review</journal>
<volume>82</volume>
<issue>6</issue>
<pages>407--428</pages>
<marker>Collins, Loftus, 1975</marker>
<rawString>Collins, A.M. and Loftus, E.F. 1975 A Spreading Activation Theory of Semantic Processing. Psychological Review 82(6): 407-428.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>