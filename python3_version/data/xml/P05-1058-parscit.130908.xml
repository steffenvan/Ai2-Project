<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.993744">
Alignment Model Adaptation for Domain-Specific Word Alignment
</title>
<author confidence="0.992233">
WU Hua, WANG Haifeng, LIU Zhanyi
</author>
<affiliation confidence="0.983961">
Toshiba (China) Research and Development Center
</affiliation>
<address confidence="0.973402333333333">
5/F., Tower W2, Oriental Plaza
No.1, East Chang An Ave., Dong Cheng District
Beijing, 100738, China
</address>
<email confidence="0.970082">
{wuhua, wanghaifeng, liuzhanyi}@rdc.toshiba.com.cn
</email>
<sectionHeader confidence="0.993764" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999957722222222">
This paper proposes an alignment
adaptation approach to improve
domain-specific (in-domain) word
alignment. The basic idea of alignment
adaptation is to use out-of-domain corpus
to improve in-domain word alignment
results. In this paper, we first train two
statistical word alignment models with the
large-scale out-of-domain corpus and the
small-scale in-domain corpus respectively,
and then interpolate these two models to
improve the domain-specific word
alignment. Experimental results show that
our approach improves domain-specific
word alignment in terms of both precision
and recall, achieving a relative error rate
reduction of 6.56% as compared with the
state-of-the-art technologies.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999935553571429">
Word alignment was first proposed as an
intermediate result of statistical machine
translation (Brown et al., 1993). In recent years,
many researchers have employed statistical models
(Wu, 1997; Och and Ney, 2003; Cherry and Lin,
2003) or association measures (Smadja et al.,
1996; Ahrenberg et al., 1998; Tufis and Barbu,
2002) to build alignment links. In order to achieve
satisfactory results, all of these methods require a
large-scale bilingual corpus for training. When the
large-scale bilingual corpus is not available, some
researchers use existing dictionaries to improve
word alignment (Ker and Chang, 1997). However,
only a few studies (Wu and Wang, 2004) directly
address the problem of domain-specific word
alignment when neither the large-scale
domain-specific bilingual corpus nor the
domain-specific translation dictionary is available.
In this paper, we address the problem of word
alignment in a specific domain, in which only a
small-scale corpus is available. In the
domain-specific (in-domain) corpus, there are two
kinds of words: general words, which also
frequently occur in the out-of-domain corpus, and
domain-specific words, which only occur in the
specific domain. Thus, we can use the
out-of-domain bilingual corpus to improve the
alignment for general words and use the in-domain
bilingual corpus for domain-specific words. We
implement this by using alignment model
adaptation.
Although the adaptation technology is widely
used for other tasks such as language modeling
(Iyer et al., 1997), only a few studies, to the best of
our knowledge, directly address word alignment
adaptation. Wu and Wang (2004) adapted the
alignment results obtained with the out-of-domain
corpus to the results obtained with the in-domain
corpus. This method first trained two models and
two translation dictionaries with the in-domain
corpus and the out-of-domain corpus, respectively.
Then these two models were applied to the
in-domain corpus to get different results. The
trained translation dictionaries were used to select
alignment links from these different results. Thus,
this method performed adaptation through result
combination. The experimental results showed a
significant error rate reduction as compared with
the method directly combining the two corpora as
training data.
In this paper, we improve domain-specific word
alignment through statistical alignment model
adaptation instead of result adaptation. Our method
includes the following steps: (1) two word
alignment models are trained using a small-scale
in-domain bilingual corpus and a large-scale
</bodyText>
<page confidence="0.988467">
467
</page>
<note confidence="0.9914705">
Proceedings of the 43rd Annual Meeting of the ACL, pages 467–474,
Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<bodyText confidence="0.8123504">
i
c
(2)
l,m are the lengths of the target sentence and the
source sentence respectively.
j is the position index of the source word.
a j is the position of the target word aligned to
the jth source word.
φi is the fertility of ei .
p1 is the fertility probability for e , and
</bodyText>
<equation confidence="0.846480285714286">
0
p 0 + p 1 = 1.
t(f j  |eaj is the word translation probability.
)
n(φi  |ei) is the fertility probability.
d j − cρ is the distortion probability for the
1 ( a j )
</equation>
<bodyText confidence="0.918926">
head of each cept1.
d&gt;1 (j − p(j)) is the distortion probability for the
remaining words of the cept.
</bodyText>
<equation confidence="0.9702746">
h i =
( ) min{ :
k i = a is the head of cept i.
k }
k
p j = k &lt; j k a =a
( ) max{ : j k
ρi is the first word before with non-zero
ei
fertility. If  |{i&apos; : i&apos; &gt; 0 &lt; i &apos; &lt;i}|&gt;0
φ 0 ∧
,
0 0 &apos;
∧ &lt;i &lt;i}; else ρi = 0.
∑j[aj =i]⋅ j
</equation>
<bodyText confidence="0.996819347826087">
= is the center of cept i.
φi
During the training process, IBM model 3 is
first trained, and then the parameters in model 3
are employed to train model 4. During the testing
process, the trained model 3 is also used to get an
initial alignment result, and then the trained model
4 is employed to improve this alignment result. For
convenience, we describe model 3 in Equation (3).
The main difference between model 3 and model 4
lies in the calculation of distortion probability.
out-of-domain bilingual corpus, respectively. (2) A
new alignment model is built by interpolating the
two trained models. (3) A translation dictionary is
also built by interpolating the two dictionaries that
are trained from the two training corpora. (4) The
new alignment model and the translation dictionary
are employed to improve domain-specific word
alignment results. Experimental results show that
our approach improves domain-specific word
alignment in terms of both precision and recall,
achieving a relative error rate reduction of 6.56%
as compared with the state-of-the-art technologies.
</bodyText>
<figureCaption confidence="0.818361666666667">
The remainder of the paper is organized as
follows. Section 2 introduces the statistical word
alignment model. Section 3 describes our
alignment model adaptation method. Section 4
describes the method used to build the translation
dictionary. Section 5 describes the model
adaptation algorithm. Section 6 presents the
evaluation results. The last section concludes our
approach.
</figureCaption>
<sectionHeader confidence="0.720762" genericHeader="method">
2 Statistical Word Alignment
</sectionHeader>
<bodyText confidence="0.931939333333333">
According to the IBM models (Brown et al., 1993),
the statistical word alignment model can be
generally represented as in Equation (1).
</bodyText>
<figure confidence="0.9523135625">
f e
, ) =
|
a
&apos;
 |e)
∑ p(a&apos; ,  |)
f e (1)
,
a
(
f
p
(
a
p
</figure>
<bodyText confidence="0.6775712">
In this paper, we use a simplified IBM model 4
(Al-Onaizan et al., 1999), which is shown in
Equation (2). This simplified version does not take
word classes into account as described in (Brown
et al., 1993).
</bodyText>
<equation confidence="0.948578679245282">
p(a,  |e) = ∑ Pr( ,  |)
f ( , ) τ π e
τ π
l m
,
,
1
j
=
j : 0
a j ≠
∏
n(φi  |ei )⋅ ∏φi
i
=1 i=1
m
m
e)
m
0
l l
|
π
,
∑
e)Pr(= τ
p(a, |
f
( , )
τ π


m−
φ0
=
φ0
  p

⋅
2φ0
φ0
p1
⋅
!
)⋅ ∏ d j a
( |
j
t
(fj
∏
 |e j
a
(3)
1 A cept is defined as the set of target words connected to a source word
(Brown et al., 1993).
)
) ( |
⋅ ∏ t f e
j a j
i
1, 0
aj≠
=
l
m
∏
)
⋅
n(φi  |e
=
1
=
i
j
1
m
j
j=
1, 0
a j ≠
m
0
( ([ ( )] (
j h a d j c
= ⋅ − ))
j 1 ρaj
m
([ ( )] ( ( ))))
j h a d j p j
≠ ⋅ −
j &gt; 1
∏
∏
+
φ0
=
  p

 m−
φ0
⋅
2φ φ
0 0
p1
}
ρi = max{i &apos;: φi&apos; &gt;
</equation>
<page confidence="0.986092">
468
</page>
<bodyText confidence="0.973727294117647">
However, both model 3 and model 4 do not
take the multiword cept into account. Only
one-to-one and many-to-one word alignments are
considered. Thus, some multi-word units in the
domain-specific corpus cannot be correctly aligned.
In order to deal with this problem, we perform
word alignment in two directions (source to target,
and target to source) as described in (Och and Ney,
2000). The GIZA++ toolkit2 is used to perform
statistical word alignment.
We use SG1 and to represent the
SG2
bi-directional alignment sets, which are shown in
Equation (4) and (5). For alignment in both sets,
we use j for source words and i for target words. If
a target word in position i is connected to source
words in positions and , then
</bodyText>
<equation confidence="0.983952">
j1 j2 Ai = {j 1 , j2} .
</equation>
<bodyText confidence="0.916082">
We call an element in the alignment set an
alignment link.
</bodyText>
<equation confidence="0.988705333333333">
SG A i i A i j a j i a j
1 {( , )  |{  |, 0} }
= = = ≥ (4)
SG j Aj Aj i i aj a j
2 {( , )  |{  |, 0} }
= = = ≥ (5)
</equation>
<sectionHeader confidence="0.993047" genericHeader="method">
3 Word Alignment Model Adaptation
</sectionHeader>
<bodyText confidence="0.9999677">
In this paper, we first train two models using the
out-of-domain training data and the in-domain
training data, and then build a new alignment
model through linear interpolation of the two
trained models. In other words, we make use of the
out-of-domain training data and the in-domain
training data by interpolating the trained alignment
models. One method to perform model adaptation
is to directly interpolate the alignment models as
shown in Equation (6).
</bodyText>
<equation confidence="0.996909">
p(a|f,e)=λ⋅pI(a|f,e)+(1−λ)⋅pO(a|f,e) (6)
</equation>
<bodyText confidence="0.963054833333333">
p I (a  |f, e) and pO (a  |f, e) are the alignment
model trained using the in-domain corpus and the
out-of-domain corpus, respectively. λ is an
interpolation weight. It can be a constant or a
function of f and e.
However, in both model 3 and model 4, there
are mainly three kinds of parameters: translation
probability, fertility probability and distortion
probability. These three kinds of parameters have
their own interpretation in these two models. In
order to obtain fine-grained interpolation models,
we separate the alignment model interpolation into
</bodyText>
<footnote confidence="0.808045">
2 It is located at http://www.fjoch.com/GIZA++.html.
</footnote>
<bodyText confidence="0.996168076923077">
three parts: translation probability interpolation,
fertility probability interpolation and distortion
probability interpolation. For these probabilities,
we use different interpolation methods to calculate
the interpolation weights. After interpolation, we
replace the corresponding parameters in equation
(2) and (3) with the interpolated probabilities to get
new alignment models.
In the following subsections, we will perform
linear interpolation for word alignment in the
source to target direction. For the word alignment
in the target to source direction, we use the same
interpolation method.
</bodyText>
<subsectionHeader confidence="0.998952">
3.1 Translation Probability Interpolation
</subsectionHeader>
<bodyText confidence="0.998086142857143">
The word translation probability t(fj  |eaj ) is
very important in translation models. The same
word may have different distributions in the
in-domain corpus and the out-of-domain corpus.
Thus, the interpolation weight for the translation
probability is taken as a variant. The interpolation
model for t(f j  |eaj ) is described in Equation (7).
</bodyText>
<equation confidence="0.962214081081081">
t(fj  |ea ) = λt (eaj)⋅tI (fj  |eaj ) +
(eaj ))⋅tO (f j  |eaj ) (7)
The interpolation weight
λt(eaj) in (7) is a
function of . It is calculated as shown in
eaj
Equation (8).
p e
I a
( )
j

λ e =
t a
( )
j  ( ) ( )
+ p e
j j
 p e
I a O a
and
are the relative
pI(eaj)
pO(eaj)
equencies of in the in-domain corpus and in
eaj
the out-of-domain corpus, respectively.
α
 (8)


fr
is an
α
adaptation coefficient, such that
0.
Equation (8) indicates that if a word occurs
</equation>
<bodyText confidence="0.65639425">
more frequently in a specific domain than in the
general domain, it can usually be considered as a
domain-specific word
et al., 2001). For
</bodyText>
<equation confidence="0.742771666666667">
example, if
is much larger than
,
</equation>
<bodyText confidence="0.966871">
the word
interpolation weight approaches to 1. In this case,
we trust more on the translation probability
obtained from the in-domain corpus than that
obtained fr
</bodyText>
<equation confidence="0.8790959">
α≥
(Peñas
pI(eaj)
pO(eaj)
is a domain-specific word and the
eaj
om the out-of-domain corpus.
−
(1
λt
</equation>
<page confidence="0.9979">
469
</page>
<subsectionHeader confidence="0.99376">
3.2 Fertility Probability Interpolation
</subsectionHeader>
<bodyText confidence="0.999108">
The fertility probability n(φi  |ei) describes the
distribution of the number of words that is
</bodyText>
<equation confidence="0.652933">
ei
aligned to. The interpolation model is shown in (9).
n(φi  |ei) = λn ⋅ n I (φi  |ei) + (1− λ )⋅ nO (φi  |ei) (9)
</equation>
<bodyText confidence="0.969389888888889">
Where, is a constant. This constant is obtained
λn
using a manually annotated held-out data set. In
fact, we can also set the interpolation weight to be
a function of the word . From the word
ei
alignment results on the held-out set, we conclude
that these two weighting schemes do not perform
quite differently.
</bodyText>
<subsectionHeader confidence="0.993795">
3.3 Distortion Probability Interpolation
</subsectionHeader>
<bodyText confidence="0.9564605">
The distortion probability describes the distribution
of alignment positions. We separate it into two
parts: one is the distortion probability in model 3,
and the other is the distortion probability in model
4. The interpolation model for the distortion
probability in model 3 is shown in (10). Since the
distortion probability is irrelevant with any specific
source or target words, we take as a constant.
λd
This constant is obtained using the held-out set.
out-of-domain corpus, we build a translation
dictionary filtered with a threshold . Based
D1 δ1
on the alignment results on a small-scale
in-domain corpus, we build another translation
dictionary filtered with a threshold .
</bodyText>
<equation confidence="0.869472">
D2 δ2
</equation>
<bodyText confidence="0.999444125">
After obtaining the two dictionaries, we
combine two dictionaries through linearly
interpolating the translation probabilities in the two
dictionaries, which is shown in (11). The symbols f
and e represent a single word or a phrase in the
source and target languages. This differs from the
translation probability in Equation (7), where these
two symbols only represent single words.
</bodyText>
<equation confidence="0.8819136">
p f e
(  |) = λ(e)⋅ pI(f  |e)+(1−λ(e))⋅ pO(f  |e) (11)
The interpolation weight is also a function of e. It
is calculated as shown in (12)3.
p e
I ( )
λ=
( )
e (12)
pI (e) + pO (e)
</equation>
<bodyText confidence="0.511572">
pI (e) and pO (e) represent the relative
frequencies of e in the in-domain corpus and
out-of-domain corpus, respectively.
</bodyText>
<sectionHeader confidence="0.797259" genericHeader="method">
5 Adaptation Algorithm
</sectionHeader>
<equation confidence="0.74238825">
aj,l,m)=λd⋅dI(j |aj
d ( |
j
l m ) +
, ,
(10)
j , , )
l m
</equation>
<bodyText confidence="0.999795">
For the distortion probability in model 4, we
use the same interpolation method and take the
interpolation weight as a constant.
</bodyText>
<sectionHeader confidence="0.990998" genericHeader="method">
4 Translation Dictionary Acquisition
</sectionHeader>
<bodyText confidence="0.991955294117647">
We use the translation dictionary trained from the
training data to further improve the alignment
results. When we train the bi-directional statistical
word alignment models with the training data, we
get two word alignment results for the training data.
By taking the intersection of the two word
alignment results, we build a new alignment set.
The alignment links in this intersection set are
extended by iteratively adding word alignment
links into it as described in (Och and Ney, 2000).
Based on the extended alignment links, we build a
translation dictionary. In order to filter the noise
caused by the error alignment links, we only retain
those translation pairs whose log-likelihood ratio
scores (Dunning, 1993) are above a threshold.
Based on the alignment results on the
d one-to-many alignments.
</bodyText>
<sectionHeader confidence="0.998837" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.9955985">
The first method is descri
ed in (Wu and Wang,
2004). We call it “Result Adaptation (ResAdapt)”.
The adaptation algorithms include two parts: a
training algorithm and a testing algorithm. The
training algorithm is shown in Figure 1.
After getting the two adaptation models and the
translation dictionary, we apply them to the
in-domain corpus to perform word alignment. Here
we call it testing algorithm. The detailed algorithm
is shown in Figure 2. For each sentence pair, there
are two different word alignment results, from
which the final alignment links are selected
according to their translation probabilities in the
dictionary D. The selection order is similar to that
in the competitive linking algorithm (Melamed,
1997). The difference is that we allow many-to-one
an
We compare our method with four other methods.
We also tried an adaptation coefficient to calculate the
interpolation weight as in (8). However, the alignment results
are not improved by using this coefficient for the dictionary
</bodyText>
<page confidence="0.969607">
3
</page>
<figure confidence="0.872136538461539">
.
a
−
(1
λd
)⋅ dO (j |
470
Input: In-domain training data
Out-of-domain training data
Output: Alignment models st
M and ts
M
Translation dictionary D
</figure>
<figureCaption confidence="0.999832">
Figure 1. Training Algorithm
</figureCaption>
<bodyText confidence="0.791194">
Input: Alignment models st
</bodyText>
<equation confidence="0.9017975">
M and ts
M ,
</equation>
<bodyText confidence="0.996794">
translation dictionary D , and testing
data
</bodyText>
<listItem confidence="0.926694777777778">
(1) Apply the adaptation model st
M and
M to the testing data to get two
ts
different alignment results.
(2) Select the alignment links with higher
translation probability in the translation
dictionary D .
Output: Alignment results on the testing data
</listItem>
<figureCaption confidence="0.999463">
Figure 2. Testing Algorithm
</figureCaption>
<bodyText confidence="0.999958">
The second method “Gen+Spec” directly combines
the out-of-domain corpus and the in-domain corpus
as training data. The third method “Gen” only uses
the out-of-domain corpus as training data. The
fourth method “Spec” only uses the in-domain
corpus as training data. For each of the last three
methods, we first train bi-directional alignment
models using the training data. Then we build a
translation dictionary based on the alignment
results on the training data and filter it using
log-likelihood ratio as described in section 4.
</bodyText>
<subsectionHeader confidence="0.993569">
6.1 Training and Testing Data
</subsectionHeader>
<bodyText confidence="0.999946571428572">
In this paper, we take English-Chinese word
alignment as a case study. We use a sentence-
aligned out-of-domain English-Chinese bilingual
corpus, which includes 320,000 bilingual sentence
pairs. The average length of the English sentences
is 13.6 words while the average length of the
Chinese sentences is 14.2 words.
We also use a sentence-aligned in-domain
English-Chinese bilingual corpus (operation
manuals for diagnostic ultrasound systems), which
includes 5,862 bilingual sentence pairs. The
average length of the English sentences is 12.8
words while the average length of the Chinese
sentences is 11.8 words. From this domain-specific
corpus, we randomly select 416 pairs as testing
data. We also select 400 pairs to be manually
annotated as held-out set (development set) to
adjust parameters. The remained 5,046 pairs are
used as domain-specific training data.
The Chinese sentences in both the training set
and the testing set are automatically segmented
into words. In order to exclude the effect of the
segmentation errors on our alignment results, the
segmentation errors in our testing set are
post-corrected. The alignments in the testing set
are manually annotated, which includes 3,166
alignment links. Among them, 504 alignment links
include multiword units.
</bodyText>
<subsectionHeader confidence="0.999135">
6.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.890247692307692">
We use the same evaluation metrics as described in
(Wu and Wang, 2004). If we use to represent
SG
the set of alignment links identified by the
proposed methods and to denote the reference
SC
alignment set, the methods to calculate the
precision, recall, f-measure, and alignment error
rate (AER) are shown in Equation (13), (14), (15),
and (16). It can be seen that the higher the
f-measure is, the lower the alignment error rate is.
Thus, we will only show precision, recall and AER
scores in the evaluation results.
</bodyText>
<figure confidence="0.976159777777778">
(1) Train two alignment models M st
I
(source to target) and (target to
MI ts
source) using the in-domain corpus.
(2) Train the other two alignment models
st and using the out-of-domain
MO ts
MO
corpus.
(3) Build an adaptation model st
M based on
MIst st
and MO , and build the other
adaptation model M based on
ts
and using the interpolation methods
MO ts
described in section 3.
(4) Train a dictionary D1 using the
alignment results on the in-domain
training data.
(5) Train another dictionary using the
D2
alignment results on the out-of-domain
training data.
(6) Build an adaptation dictionary D based
on and using the interpolation
D1 D2
method described in section 4.
Mts
I
precision =  |S S |
G ∩ C
 |S  |(13)
G
</figure>
<page confidence="0.992342">
471
</page>
<subsectionHeader confidence="0.998494">
6.3 Evaluation Results
</subsectionHeader>
<bodyText confidence="0.988301111111111">
We use the held-out set described in section 6.1 to
set the interpolation weights. The coefficient α in
Equation (8) is set to 0.8, the interpolation weight
λn in Equation (9) is set to 0.1, the interpolation
weight in model 3 in Equation (10) is set to
λd0.1, and the interpolation weight in model 4 is
λd
set to 1. In addition, log-likelihood ratio score
thresholds are set to δ1 = 30 and δ2 = 25. With
these parameters, we get the lowest alignment error
rate on the held-out set.
Using these parameters, we build two
adaptation models and a translation dictionary on
the training data, which are applied to the testing
set. The evaluation results on our testing set are
shown in Table 1. From the results, it can be seen
that our approach performs the best among all of
the methods, achieving the lowest alignment error
rate. Compared with the method “ResAdapt”, our
method achieves a higher precision without loss of
recall, resulting in an error rate reduction of 6.56%.
Compared with the method “Gen+Spec”, our
method gets a higher recall, resulting in an error
rate reduction of 17.43%. This indicates that our
model adaptation method is very effective to
alleviate the data-sparseness problem of
domain-specific word alignment.
</bodyText>
<table confidence="0.999415">
Method Precision Recall AER
Ours 0.8490 0.7599 0.1980
ResAdapt 0.8198 0.7587 0.2119
Gen+Spec 0.8456 0.6905 0.2398
Gen 0.8589 0.6576 0.2551
Spec 0.8386 0.6731 0.2532
</table>
<tableCaption confidence="0.999892">
Table 1. Word Alignment Adaptation Results
</tableCaption>
<bodyText confidence="0.997549375">
The method that only uses the large-scale
out-of-domain corpus as training data does not
produce good result. The alignment error rate is
almost the same as that of the method only using
the in-domain corpus. In order to further analyze
the result, we classify the alignment links into two
classes: single word alignment links (SWA) and
multiword alignment links (MWA). Single word
alignment links only include one-to-one
alignments. The multiword alignment links include
those links in which there are multiword units in
the source language or/and the target language.
The results are shown in Table 2. From the results,
it can be seen that the method “Spec” produces
better results for multiword alignment while the
method “Gen” produces better results for single
word alignment. This indicates that the multiword
alignment links mainly include the domain-specific
words. Among the 504 multiword alignment links,
about 60% of the links include domain-specific
words. In Table 2, we also present the results of
our method. Our method achieves the lowest error
rate results on both single word alignment and
multiword alignment.
</bodyText>
<table confidence="0.999722285714286">
Method Precision Recall AER
Ours (SWA) 0.8703 0.8621 0.1338
Ours (MWA) 0.5635 0.2202 0.6833
Gen (SWA) 0.8816 0.7694 0.1783
Gen (MWA) 0.3366 0.0675 0.8876
Spec (SWA) 0.8710 0.7633 0.1864
Spec (MWA) 0.4760 0.1964 0.7219
</table>
<tableCaption confidence="0.99926">
Table 2. Single Word and Multiword Alignment
</tableCaption>
<sectionHeader confidence="0.963461" genericHeader="evaluation">
Results
</sectionHeader>
<bodyText confidence="0.999757222222222">
In order to further compare our method with the
method described in (Wu and Wang, 2004). We do
another experiment using almost the same-scale
in-domain training corpus as described in (Wu and
Wang, 2004). From the in-domain training corpus,
we randomly select about 500 sentence pairs to
build the smaller training set. The testing data is
the same as shown in section 6.1. The evaluation
results are shown in Table 3.
</bodyText>
<table confidence="0.99685675">
Method Precision Recall AER
Ours 0.8424 0.7378 0.2134
ResAdapt 0.8027 0.7262 0.2375
Gen+Spec 0.8041 0.6857 0.2598
</table>
<tableCaption confidence="0.8663095">
Table 3. Alignment Adaptation Results Using a
Smaller In-Domain Corpus
</tableCaption>
<bodyText confidence="0.914646">
Compared with the method “Gen+Spec”, our
method achieves an error rate reduction of 17.86%
</bodyText>
<figure confidence="0.996571294117647">
|
SG  |+|SC
AER =1−2× |SG ∩ SC  |=1
|
|
|S S
G ∩ C
=
recall
|
|S C
2×|SG∩SC|
=
fmeasure
|
|SG|+|SC
fmeasure
</figure>
<page confidence="0.99629">
472
</page>
<bodyText confidence="0.99983572">
while the method “ResAdapt” described in (Wu
and Wang, 2004) only achieves an error rate
reduction of 8.59%. Compared with the method
“ResAdapt”, our method achieves an error rate
reduction of 10.15%.
This result is different from that in (Wu and
Wang, 2004), where their method achieved an
error rate reduction of 21.96% as compared with
the method “Gen+Spec”. The main reason is that
the in-domain training corpus and testing corpus in
this paper are different from those in (Wu and
Wang, 2004). The training data and the testing data
described in (Wu and Wang, 2004) are from a
single manual. The data in our corpus are from
several manuals describing how to use the
diagnostic ultrasound systems.
In addition to the above evaluations, we also
evaluate our model adaptation method using the
&amp;quot;refined&amp;quot; combination in Och and Ney (2000)
instead of the translation dictionary. Using the
&amp;quot;refined&amp;quot; method to select the alignments produced
by our model adaptation method (AER: 0.2371)
still yields better result than directly combining
out-of-domain and in-domain corpora as training
data of the &amp;quot;refined&amp;quot; method (AER: 0.2290).
</bodyText>
<subsectionHeader confidence="0.975667">
6.4 The Effect of In-Domain Corpus
</subsectionHeader>
<bodyText confidence="0.999973923076923">
In general, it is difficult to obtain large-scale
in-domain bilingual corpus. For some domains,
only a very small-scale bilingual sentence pairs are
available. Thus, in order to analyze the effect of the
size of in-domain corpus, we randomly select
sentence pairs from the in-domain training corpus
to generate five training sets. The numbers of
sentence pairs in these five sets are 1,010, 2,020,
3,030, 4,040 and 5,046. For each training set, we
use model 4 in section 2 to train an in-domain
model. The out-of-domain corpus for the
adaptation experiments and the testing set are the
same as described in section 6.1.
</bodyText>
<table confidence="0.999317285714286">
# Sentence Precision Recall AER
Pairs
1010 0.8385 0.7394 0.2142
2020 0.8388 0.7514 0.2073
3030 0.8474 0.7558 0.2010
4040 0.8482 0.7555 0.2008
5046 0.8490 0.7599 0.1980
</table>
<tableCaption confidence="0.9943365">
Table 4. Alignment Adaptation Results Using
In-Domain Corpora of Different Sizes
</tableCaption>
<table confidence="0.999971571428572">
# Sentence Precision Recall AER
Pairs
1010 0.8737 0.6642 0.2453
2020 0.8502 0.6804 0.2442
3030 0.8473 0.6874 0.2410
4040 0.8430 0.6917 0.2401
5046 0.8456 0.6905 0.2398
</table>
<tableCaption confidence="0.9817705">
Table 5. Alignment Results Directly Combining
Out-of-Domain and In-Domain Corpora
</tableCaption>
<bodyText confidence="0.999889">
The results are shown in Table 4 and Table 5.
Table 4 describes the alignment adaptation results
using in-domain corpora of different sizes. Table 5
describes the alignment results by directly
combining the out-of-domain corpus and the
in-domain corpus of different sizes. From the
results, it can be seen that the larger the size of
in-domain corpus is, the smaller the alignment
error rate is. However, when the number of the
sentence pairs increase from 3030 to 5046, the
error rate reduction in Table 4 is very small. This is
because the contents in the specific domain are
highly replicated. This also shows that increasing
the domain-specific corpus does not obtain great
improvement on the word alignment results.
Comparing the results in Table 4 and Table 5, we
find out that our adaptation method reduces the
alignment error rate on all of the in-domain
corpora of different sizes.
</bodyText>
<subsectionHeader confidence="0.915945">
6.5 The Effect of Out-of-Domain Corpus
</subsectionHeader>
<bodyText confidence="0.999836888888889">
In order to further analyze the effect of the
out-of-domain corpus on the adaptation results, we
randomly select sentence pairs from the
out-of-domain corpus to generate five sets. The
numbers of sentence pairs in these five sets are
65,000, 130,000, 195,000, 260,000, and 320,000
(the entire out-of-domain corpus). In the adaptation
experiments, we use the entire in-domain corpus
(5046 sentence pairs). The adaptation results are
shown in Table 6.
From the results in Table 6, it can be seen that
the larger the size of out-of-domain corpus is, the
smaller the alignment error rate is. However, when
the number of the sentence pairs is more than
130,000, the error rate reduction is very small. This
indicates that we do not need a very large bilingual
out-of-domain corpus to improve domain-specific
word alignment results.
</bodyText>
<page confidence="0.998718">
473
</page>
<table confidence="0.999825714285714">
# Sentence Precision Recall AER
Pairs (k)
65 0.8441 0.7284 0.2180
130 0.8479 0.7413 0.2090
195 0.8454 0.7461 0.2073
260 0.8426 0.7508 0.2059
320 0.8490 0.7599 0.1980
</table>
<tableCaption confidence="0.9869065">
Table 6. Adaptation Alignment Results Using
Out-of-Domain Corpora of Different Sizes
</tableCaption>
<sectionHeader confidence="0.996362" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999990457142857">
This paper proposes an approach to improve
domain-specific word alignment through alignment
model adaptation. Our approach first trains two
alignment models with a large-scale out-of-domain
corpus and a small-scale domain-specific corpus.
Second, we build a new adaptation model by
linearly interpolating these two models. Third, we
apply the new model to the domain-specific corpus
and improve the word alignment results. In
addition, with the training data, an interpolated
translation dictionary is built to select the word
alignment links from different alignment results.
Experimental results indicate that our approach
achieves a precision of 84.90% and a recall of
75.99% for word alignment in a specific domain.
Our method achieves a relative error rate reduction
of 17.43% as compared with the method directly
combining the out-of-domain corpus and the
in-domain corpus as training data. It also
achieves a relative error rate reduction of 6.56% as
compared with the previous work in (Wu and
Wang, 2004). In addition, when we train the model
with a smaller-scale in-domain corpus as described
in (Wu and Wang, 2004), our method achieves an
error rate reduction of 10.15% as compared with
the method in (Wu and Wang, 2004).
We also use in-domain corpora and
out-of-domain corpora of different sizes to perform
adaptation experiments. The experimental results
show that our model adaptation method improves
alignment results on in-domain corpora of different
sizes. The experimental results also show that
even a not very large out-of-domain corpus can
help to improve the domain-specific word
alignment through alignment model adaptation.
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99986022">
L. Ahrenberg, M. Merkel, M. Andersson. 1998. A
Simple Hybrid Aligner for Generating Lexical
Correspondences in Parallel Tests. In Proc. of
ACL/COLING-1998, pp. 29-35.
Y. Al-Onaizan, J. Curin, M. Jahr, K. Knight, J. Lafferty,
D. Melamed, F. J. Och, D. Purdy, N. A. Smith, D.
Yarowsky. 1999. Statistical Machine Translation
Final Report. Johns Hopkins University Workshop.
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, R.
Mercer. 1993. The Mathematics of Statistical
Machine Translation: Parameter Estimation.
Computational Linguistics, 19(2): 263-311.
C. Cherry and D. Lin. 2003. A Probability Model to
Improve Word Alignment. In Proc. of ACL-2003, pp.
88-95.
T. Dunning. 1993. Accurate Methods for the Statistics of
Surprise and Coincidence. Computational Linguistics,
19(1): 61-74.
R. Iyer, M. Ostendorf, H. Gish. 1997. Using
Out-of-Domain Data to Improve In-Domain
Language Models. IEEE Signal Processing Letters,
221-223.
S. J. Ker and J. S. Chang. 1997. A Class-based
Approach to Word Alignment. Computational
Linguistics, 23(2): 313-343.
I. D. Melamed. 1997. A Word-to-Word Model of
Translational Equivalence. In Proc. of ACL 1997, pp.
490-497.
F. J. Och and H. Ney. 2000. Improved Statistical
Alignment Models. In Proc. of ACL-2000, pp.
440-447.
A. Peñas, F. Verdejo, J. Gonzalo. 2001. Corpus-based
Terminology Extraction Applied to Information
Access. In Proc. of the Corpus Linguistics 2001, vol.
13.
F. Smadja, K. R. McKeown, V. Hatzivassiloglou. 1996.
Translating Collocations for Bilingual Lexicons: a
Statistical Approach. Computational Linguistics,
22(1): 1-38.
D. Tufis and A. M. Barbu. 2002. Lexical Token
Alignment: Experiments, Results and Application. In
Proc. of LREC-2002, pp. 458-465.
D. Wu. 1997. Stochastic Inversion Transduction
Grammars and Bilingual Parsing of Parallel
Corpora. Computational Linguistics, 23(3): 377-403.
H. Wu and H. Wang. 2004. Improving Domain-Specific
Word Alignment with a General Bilingual Corpus. In
R. E. Frederking and K. B. Taylor (Eds.), Machine
Translation: From Real Users to Research: 6th
conference of AMTA-2004, pp. 262-271.
</reference>
<page confidence="0.998986">
474
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.922497">
<title confidence="0.995341">Alignment Model Adaptation for Domain-Specific Word Alignment</title>
<author confidence="0.977991">WU Hua</author>
<author confidence="0.977991">WANG Haifeng</author>
<author confidence="0.977991">LIU Zhanyi</author>
<affiliation confidence="0.981704">Toshiba (China) Research and Development Center</affiliation>
<address confidence="0.989058666666667">5/F., Tower W2, Oriental Plaza No.1, East Chang An Ave., Dong Cheng District Beijing, 100738, China</address>
<email confidence="0.994054">wuhua@rdc.toshiba.com.cn</email>
<email confidence="0.994054">wanghaifeng@rdc.toshiba.com.cn</email>
<email confidence="0.994054">liuzhanyi@rdc.toshiba.com.cn</email>
<abstract confidence="0.999701684210526">This paper proposes an alignment adaptation approach to improve domain-specific (in-domain) word alignment. The basic idea of alignment adaptation is to use out-of-domain corpus to improve in-domain word alignment results. In this paper, we first train two statistical word alignment models with the large-scale out-of-domain corpus and the small-scale in-domain corpus respectively, and then interpolate these two models to improve the domain-specific word alignment. Experimental results show that our approach improves domain-specific word alignment in terms of both precision and recall, achieving a relative error rate reduction of 6.56% as compared with the state-of-the-art technologies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Ahrenberg</author>
<author>M Merkel</author>
<author>M Andersson</author>
</authors>
<title>A Simple Hybrid Aligner for Generating Lexical Correspondences in Parallel Tests.</title>
<date>1998</date>
<booktitle>In Proc. of ACL/COLING-1998,</booktitle>
<pages>29--35</pages>
<contexts>
<context position="1317" citStr="Ahrenberg et al., 1998" startWordPosition="179" endWordPosition="182"> interpolate these two models to improve the domain-specific word alignment. Experimental results show that our approach improves domain-specific word alignment in terms of both precision and recall, achieving a relative error rate reduction of 6.56% as compared with the state-of-the-art technologies. 1 Introduction Word alignment was first proposed as an intermediate result of statistical machine translation (Brown et al., 1993). In recent years, many researchers have employed statistical models (Wu, 1997; Och and Ney, 2003; Cherry and Lin, 2003) or association measures (Smadja et al., 1996; Ahrenberg et al., 1998; Tufis and Barbu, 2002) to build alignment links. In order to achieve satisfactory results, all of these methods require a large-scale bilingual corpus for training. When the large-scale bilingual corpus is not available, some researchers use existing dictionaries to improve word alignment (Ker and Chang, 1997). However, only a few studies (Wu and Wang, 2004) directly address the problem of domain-specific word alignment when neither the large-scale domain-specific bilingual corpus nor the domain-specific translation dictionary is available. In this paper, we address the problem of word align</context>
</contexts>
<marker>Ahrenberg, Merkel, Andersson, 1998</marker>
<rawString>L. Ahrenberg, M. Merkel, M. Andersson. 1998. A Simple Hybrid Aligner for Generating Lexical Correspondences in Parallel Tests. In Proc. of ACL/COLING-1998, pp. 29-35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Al-Onaizan</author>
<author>J Curin</author>
<author>M Jahr</author>
<author>K Knight</author>
<author>J Lafferty</author>
<author>D Melamed</author>
<author>F J Och</author>
<author>D Purdy</author>
<author>N A Smith</author>
<author>D Yarowsky</author>
</authors>
<title>Statistical Machine Translation Final Report.</title>
<date>1999</date>
<institution>Johns Hopkins University Workshop.</institution>
<contexts>
<context position="6252" citStr="Al-Onaizan et al., 1999" startWordPosition="1007" endWordPosition="1010">ws. Section 2 introduces the statistical word alignment model. Section 3 describes our alignment model adaptation method. Section 4 describes the method used to build the translation dictionary. Section 5 describes the model adaptation algorithm. Section 6 presents the evaluation results. The last section concludes our approach. 2 Statistical Word Alignment According to the IBM models (Brown et al., 1993), the statistical word alignment model can be generally represented as in Equation (1). f e , ) = | a &apos; |e) ∑ p(a&apos; , |) f e (1) , a ( f p ( a p In this paper, we use a simplified IBM model 4 (Al-Onaizan et al., 1999), which is shown in Equation (2). This simplified version does not take word classes into account as described in (Brown et al., 1993). p(a, |e) = ∑ Pr( , |) f ( , ) τ π e τ π l m , , 1 j = j : 0 a j ≠ ∏ n(φi |ei )⋅ ∏φi i =1 i=1 m m e) m 0 l l | π , ∑ e)Pr(= τ p(a, | f ( , ) τ π   m− φ0 = φ0   p  ⋅ 2φ0 φ0 p1 ⋅ ! )⋅ ∏ d j a ( | j t (fj ∏ |e j a (3) 1 A cept is defined as the set of target words connected to a source word (Brown et al., 1993). ) ) ( | ⋅ ∏ t f e j a j i 1, 0 aj≠ = l m ∏ ) ⋅ n(φi |e = 1 = i j 1 m j j= 1, 0 a j ≠ m 0 ( ([ ( )] ( j h a d j c = ⋅ − )) j 1 ρaj m ([ ( )] ( ( ))))</context>
</contexts>
<marker>Al-Onaizan, Curin, Jahr, Knight, Lafferty, Melamed, Och, Purdy, Smith, Yarowsky, 1999</marker>
<rawString>Y. Al-Onaizan, J. Curin, M. Jahr, K. Knight, J. Lafferty, D. Melamed, F. J. Och, D. Purdy, N. A. Smith, D. Yarowsky. 1999. Statistical Machine Translation Final Report. Johns Hopkins University Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R Mercer</author>
</authors>
<date>1993</date>
<journal>The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>263--311</pages>
<contexts>
<context position="1128" citStr="Brown et al., 1993" startWordPosition="149" endWordPosition="152">ignment results. In this paper, we first train two statistical word alignment models with the large-scale out-of-domain corpus and the small-scale in-domain corpus respectively, and then interpolate these two models to improve the domain-specific word alignment. Experimental results show that our approach improves domain-specific word alignment in terms of both precision and recall, achieving a relative error rate reduction of 6.56% as compared with the state-of-the-art technologies. 1 Introduction Word alignment was first proposed as an intermediate result of statistical machine translation (Brown et al., 1993). In recent years, many researchers have employed statistical models (Wu, 1997; Och and Ney, 2003; Cherry and Lin, 2003) or association measures (Smadja et al., 1996; Ahrenberg et al., 1998; Tufis and Barbu, 2002) to build alignment links. In order to achieve satisfactory results, all of these methods require a large-scale bilingual corpus for training. When the large-scale bilingual corpus is not available, some researchers use existing dictionaries to improve word alignment (Ker and Chang, 1997). However, only a few studies (Wu and Wang, 2004) directly address the problem of domain-specific </context>
<context position="6036" citStr="Brown et al., 1993" startWordPosition="956" endWordPosition="959">cific word alignment in terms of both precision and recall, achieving a relative error rate reduction of 6.56% as compared with the state-of-the-art technologies. The remainder of the paper is organized as follows. Section 2 introduces the statistical word alignment model. Section 3 describes our alignment model adaptation method. Section 4 describes the method used to build the translation dictionary. Section 5 describes the model adaptation algorithm. Section 6 presents the evaluation results. The last section concludes our approach. 2 Statistical Word Alignment According to the IBM models (Brown et al., 1993), the statistical word alignment model can be generally represented as in Equation (1). f e , ) = | a &apos; |e) ∑ p(a&apos; , |) f e (1) , a ( f p ( a p In this paper, we use a simplified IBM model 4 (Al-Onaizan et al., 1999), which is shown in Equation (2). This simplified version does not take word classes into account as described in (Brown et al., 1993). p(a, |e) = ∑ Pr( , |) f ( , ) τ π e τ π l m , , 1 j = j : 0 a j ≠ ∏ n(φi |ei )⋅ ∏φi i =1 i=1 m m e) m 0 l l | π , ∑ e)Pr(= τ p(a, | f ( , ) τ π   m− φ0 = φ0   p  ⋅ 2φ0 φ0 p1 ⋅ ! )⋅ ∏ d j a ( | j t (fj ∏ |e j a (3) 1 A cept is defined as the s</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, R. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19(2): 263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cherry</author>
<author>D Lin</author>
</authors>
<title>A Probability Model to Improve Word Alignment.</title>
<date>2003</date>
<booktitle>In Proc. of ACL-2003,</booktitle>
<pages>88--95</pages>
<contexts>
<context position="1248" citStr="Cherry and Lin, 2003" startWordPosition="168" endWordPosition="171">n corpus and the small-scale in-domain corpus respectively, and then interpolate these two models to improve the domain-specific word alignment. Experimental results show that our approach improves domain-specific word alignment in terms of both precision and recall, achieving a relative error rate reduction of 6.56% as compared with the state-of-the-art technologies. 1 Introduction Word alignment was first proposed as an intermediate result of statistical machine translation (Brown et al., 1993). In recent years, many researchers have employed statistical models (Wu, 1997; Och and Ney, 2003; Cherry and Lin, 2003) or association measures (Smadja et al., 1996; Ahrenberg et al., 1998; Tufis and Barbu, 2002) to build alignment links. In order to achieve satisfactory results, all of these methods require a large-scale bilingual corpus for training. When the large-scale bilingual corpus is not available, some researchers use existing dictionaries to improve word alignment (Ker and Chang, 1997). However, only a few studies (Wu and Wang, 2004) directly address the problem of domain-specific word alignment when neither the large-scale domain-specific bilingual corpus nor the domain-specific translation diction</context>
</contexts>
<marker>Cherry, Lin, 2003</marker>
<rawString>C. Cherry and D. Lin. 2003. A Probability Model to Improve Word Alignment. In Proc. of ACL-2003, pp. 88-95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Accurate Methods for the Statistics of Surprise and Coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<pages>61--74</pages>
<contexts>
<context position="13848" citStr="Dunning, 1993" startWordPosition="2435" endWordPosition="2436">When we train the bi-directional statistical word alignment models with the training data, we get two word alignment results for the training data. By taking the intersection of the two word alignment results, we build a new alignment set. The alignment links in this intersection set are extended by iteratively adding word alignment links into it as described in (Och and Ney, 2000). Based on the extended alignment links, we build a translation dictionary. In order to filter the noise caused by the error alignment links, we only retain those translation pairs whose log-likelihood ratio scores (Dunning, 1993) are above a threshold. Based on the alignment results on the d one-to-many alignments. 6 Evaluation The first method is descri ed in (Wu and Wang, 2004). We call it “Result Adaptation (ResAdapt)”. The adaptation algorithms include two parts: a training algorithm and a testing algorithm. The training algorithm is shown in Figure 1. After getting the two adaptation models and the translation dictionary, we apply them to the in-domain corpus to perform word alignment. Here we call it testing algorithm. The detailed algorithm is shown in Figure 2. For each sentence pair, there are two different w</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>T. Dunning. 1993. Accurate Methods for the Statistics of Surprise and Coincidence. Computational Linguistics, 19(1): 61-74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Iyer</author>
<author>M Ostendorf</author>
<author>H Gish</author>
</authors>
<title>Using Out-of-Domain Data to Improve In-Domain Language Models.</title>
<date>1997</date>
<journal>IEEE Signal Processing Letters,</journal>
<pages>221--223</pages>
<contexts>
<context position="2533" citStr="Iyer et al., 1997" startWordPosition="359" endWordPosition="362">gnment in a specific domain, in which only a small-scale corpus is available. In the domain-specific (in-domain) corpus, there are two kinds of words: general words, which also frequently occur in the out-of-domain corpus, and domain-specific words, which only occur in the specific domain. Thus, we can use the out-of-domain bilingual corpus to improve the alignment for general words and use the in-domain bilingual corpus for domain-specific words. We implement this by using alignment model adaptation. Although the adaptation technology is widely used for other tasks such as language modeling (Iyer et al., 1997), only a few studies, to the best of our knowledge, directly address word alignment adaptation. Wu and Wang (2004) adapted the alignment results obtained with the out-of-domain corpus to the results obtained with the in-domain corpus. This method first trained two models and two translation dictionaries with the in-domain corpus and the out-of-domain corpus, respectively. Then these two models were applied to the in-domain corpus to get different results. The trained translation dictionaries were used to select alignment links from these different results. Thus, this method performed adaptatio</context>
</contexts>
<marker>Iyer, Ostendorf, Gish, 1997</marker>
<rawString>R. Iyer, M. Ostendorf, H. Gish. 1997. Using Out-of-Domain Data to Improve In-Domain Language Models. IEEE Signal Processing Letters, 221-223.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S J Ker</author>
<author>J S Chang</author>
</authors>
<title>A Class-based Approach to Word Alignment.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>2</issue>
<pages>313--343</pages>
<contexts>
<context position="1630" citStr="Ker and Chang, 1997" startWordPosition="225" endWordPosition="228">on Word alignment was first proposed as an intermediate result of statistical machine translation (Brown et al., 1993). In recent years, many researchers have employed statistical models (Wu, 1997; Och and Ney, 2003; Cherry and Lin, 2003) or association measures (Smadja et al., 1996; Ahrenberg et al., 1998; Tufis and Barbu, 2002) to build alignment links. In order to achieve satisfactory results, all of these methods require a large-scale bilingual corpus for training. When the large-scale bilingual corpus is not available, some researchers use existing dictionaries to improve word alignment (Ker and Chang, 1997). However, only a few studies (Wu and Wang, 2004) directly address the problem of domain-specific word alignment when neither the large-scale domain-specific bilingual corpus nor the domain-specific translation dictionary is available. In this paper, we address the problem of word alignment in a specific domain, in which only a small-scale corpus is available. In the domain-specific (in-domain) corpus, there are two kinds of words: general words, which also frequently occur in the out-of-domain corpus, and domain-specific words, which only occur in the specific domain. Thus, we can use the out</context>
</contexts>
<marker>Ker, Chang, 1997</marker>
<rawString>S. J. Ker and J. S. Chang. 1997. A Class-based Approach to Word Alignment. Computational Linguistics, 23(2): 313-343.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I D Melamed</author>
</authors>
<title>A Word-to-Word Model of Translational Equivalence.</title>
<date>1997</date>
<booktitle>In Proc. of ACL</booktitle>
<pages>490--497</pages>
<contexts>
<context position="14678" citStr="Melamed, 1997" startWordPosition="2566" endWordPosition="2567">orithms include two parts: a training algorithm and a testing algorithm. The training algorithm is shown in Figure 1. After getting the two adaptation models and the translation dictionary, we apply them to the in-domain corpus to perform word alignment. Here we call it testing algorithm. The detailed algorithm is shown in Figure 2. For each sentence pair, there are two different word alignment results, from which the final alignment links are selected according to their translation probabilities in the dictionary D. The selection order is similar to that in the competitive linking algorithm (Melamed, 1997). The difference is that we allow many-to-one an We compare our method with four other methods. We also tried an adaptation coefficient to calculate the interpolation weight as in (8). However, the alignment results are not improved by using this coefficient for the dictionary 3 . a − (1 λd )⋅ dO (j | 470 Input: In-domain training data Out-of-domain training data Output: Alignment models st M and ts M Translation dictionary D Figure 1. Training Algorithm Input: Alignment models st M and ts M , translation dictionary D , and testing data (1) Apply the adaptation model st M and M to the testing </context>
</contexts>
<marker>Melamed, 1997</marker>
<rawString>I. D. Melamed. 1997. A Word-to-Word Model of Translational Equivalence. In Proc. of ACL 1997, pp. 490-497.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improved Statistical Alignment Models.</title>
<date>2000</date>
<booktitle>In Proc. of ACL-2000,</booktitle>
<pages>440--447</pages>
<contexts>
<context position="7332" citStr="Och and Ney, 2000" startWordPosition="1306" endWordPosition="1309">∏ t f e j a j i 1, 0 aj≠ = l m ∏ ) ⋅ n(φi |e = 1 = i j 1 m j j= 1, 0 a j ≠ m 0 ( ([ ( )] ( j h a d j c = ⋅ − )) j 1 ρaj m ([ ( )] ( ( )))) j h a d j p j ≠ ⋅ − j &gt; 1 ∏ ∏ + φ0 =   p   m− φ0 ⋅ 2φ φ 0 0 p1 } ρi = max{i &apos;: φi&apos; &gt; 468 However, both model 3 and model 4 do not take the multiword cept into account. Only one-to-one and many-to-one word alignments are considered. Thus, some multi-word units in the domain-specific corpus cannot be correctly aligned. In order to deal with this problem, we perform word alignment in two directions (source to target, and target to source) as described in (Och and Ney, 2000). The GIZA++ toolkit2 is used to perform statistical word alignment. We use SG1 and to represent the SG2 bi-directional alignment sets, which are shown in Equation (4) and (5). For alignment in both sets, we use j for source words and i for target words. If a target word in position i is connected to source words in positions and , then j1 j2 Ai = {j 1 , j2} . We call an element in the alignment set an alignment link. SG A i i A i j a j i a j 1 {( , ) |{ |, 0} } = = = ≥ (4) SG j Aj Aj i i aj a j 2 {( , ) |{ |, 0} } = = = ≥ (5) 3 Word Alignment Model Adaptation In this paper, we first train two</context>
<context position="13618" citStr="Och and Ney, 2000" startWordPosition="2398" endWordPosition="2401"> 4, we use the same interpolation method and take the interpolation weight as a constant. 4 Translation Dictionary Acquisition We use the translation dictionary trained from the training data to further improve the alignment results. When we train the bi-directional statistical word alignment models with the training data, we get two word alignment results for the training data. By taking the intersection of the two word alignment results, we build a new alignment set. The alignment links in this intersection set are extended by iteratively adding word alignment links into it as described in (Och and Ney, 2000). Based on the extended alignment links, we build a translation dictionary. In order to filter the noise caused by the error alignment links, we only retain those translation pairs whose log-likelihood ratio scores (Dunning, 1993) are above a threshold. Based on the alignment results on the d one-to-many alignments. 6 Evaluation The first method is descri ed in (Wu and Wang, 2004). We call it “Result Adaptation (ResAdapt)”. The adaptation algorithms include two parts: a training algorithm and a testing algorithm. The training algorithm is shown in Figure 1. After getting the two adaptation mod</context>
<context position="23109" citStr="Och and Ney (2000)" startWordPosition="3949" endWordPosition="3952">ferent from that in (Wu and Wang, 2004), where their method achieved an error rate reduction of 21.96% as compared with the method “Gen+Spec”. The main reason is that the in-domain training corpus and testing corpus in this paper are different from those in (Wu and Wang, 2004). The training data and the testing data described in (Wu and Wang, 2004) are from a single manual. The data in our corpus are from several manuals describing how to use the diagnostic ultrasound systems. In addition to the above evaluations, we also evaluate our model adaptation method using the &amp;quot;refined&amp;quot; combination in Och and Ney (2000) instead of the translation dictionary. Using the &amp;quot;refined&amp;quot; method to select the alignments produced by our model adaptation method (AER: 0.2371) still yields better result than directly combining out-of-domain and in-domain corpora as training data of the &amp;quot;refined&amp;quot; method (AER: 0.2290). 6.4 The Effect of In-Domain Corpus In general, it is difficult to obtain large-scale in-domain bilingual corpus. For some domains, only a very small-scale bilingual sentence pairs are available. Thus, in order to analyze the effect of the size of in-domain corpus, we randomly select sentence pairs from the in-</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F. J. Och and H. Ney. 2000. Improved Statistical Alignment Models. In Proc. of ACL-2000, pp. 440-447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Peñas</author>
<author>F Verdejo</author>
<author>J Gonzalo</author>
</authors>
<title>Corpus-based Terminology Extraction Applied to Information Access.</title>
<date>2001</date>
<booktitle>In Proc. of the Corpus Linguistics</booktitle>
<volume>13</volume>
<marker>Peñas, Verdejo, Gonzalo, 2001</marker>
<rawString>A. Peñas, F. Verdejo, J. Gonzalo. 2001. Corpus-based Terminology Extraction Applied to Information Access. In Proc. of the Corpus Linguistics 2001, vol. 13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Smadja</author>
<author>K R McKeown</author>
<author>V Hatzivassiloglou</author>
</authors>
<title>Translating Collocations for Bilingual Lexicons: a Statistical Approach.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<pages>1--38</pages>
<contexts>
<context position="1293" citStr="Smadja et al., 1996" startWordPosition="175" endWordPosition="178">espectively, and then interpolate these two models to improve the domain-specific word alignment. Experimental results show that our approach improves domain-specific word alignment in terms of both precision and recall, achieving a relative error rate reduction of 6.56% as compared with the state-of-the-art technologies. 1 Introduction Word alignment was first proposed as an intermediate result of statistical machine translation (Brown et al., 1993). In recent years, many researchers have employed statistical models (Wu, 1997; Och and Ney, 2003; Cherry and Lin, 2003) or association measures (Smadja et al., 1996; Ahrenberg et al., 1998; Tufis and Barbu, 2002) to build alignment links. In order to achieve satisfactory results, all of these methods require a large-scale bilingual corpus for training. When the large-scale bilingual corpus is not available, some researchers use existing dictionaries to improve word alignment (Ker and Chang, 1997). However, only a few studies (Wu and Wang, 2004) directly address the problem of domain-specific word alignment when neither the large-scale domain-specific bilingual corpus nor the domain-specific translation dictionary is available. In this paper, we address t</context>
</contexts>
<marker>Smadja, McKeown, Hatzivassiloglou, 1996</marker>
<rawString>F. Smadja, K. R. McKeown, V. Hatzivassiloglou. 1996. Translating Collocations for Bilingual Lexicons: a Statistical Approach. Computational Linguistics, 22(1): 1-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Tufis</author>
<author>A M Barbu</author>
</authors>
<title>Lexical Token Alignment: Experiments, Results and Application.</title>
<date>2002</date>
<booktitle>In Proc. of LREC-2002,</booktitle>
<pages>458--465</pages>
<contexts>
<context position="1341" citStr="Tufis and Barbu, 2002" startWordPosition="183" endWordPosition="186">odels to improve the domain-specific word alignment. Experimental results show that our approach improves domain-specific word alignment in terms of both precision and recall, achieving a relative error rate reduction of 6.56% as compared with the state-of-the-art technologies. 1 Introduction Word alignment was first proposed as an intermediate result of statistical machine translation (Brown et al., 1993). In recent years, many researchers have employed statistical models (Wu, 1997; Och and Ney, 2003; Cherry and Lin, 2003) or association measures (Smadja et al., 1996; Ahrenberg et al., 1998; Tufis and Barbu, 2002) to build alignment links. In order to achieve satisfactory results, all of these methods require a large-scale bilingual corpus for training. When the large-scale bilingual corpus is not available, some researchers use existing dictionaries to improve word alignment (Ker and Chang, 1997). However, only a few studies (Wu and Wang, 2004) directly address the problem of domain-specific word alignment when neither the large-scale domain-specific bilingual corpus nor the domain-specific translation dictionary is available. In this paper, we address the problem of word alignment in a specific domai</context>
</contexts>
<marker>Tufis, Barbu, 2002</marker>
<rawString>D. Tufis and A. M. Barbu. 2002. Lexical Token Alignment: Experiments, Results and Application. In Proc. of LREC-2002, pp. 458-465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
</authors>
<title>Stochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<pages>377--403</pages>
<contexts>
<context position="1206" citStr="Wu, 1997" startWordPosition="162" endWordPosition="163"> the large-scale out-of-domain corpus and the small-scale in-domain corpus respectively, and then interpolate these two models to improve the domain-specific word alignment. Experimental results show that our approach improves domain-specific word alignment in terms of both precision and recall, achieving a relative error rate reduction of 6.56% as compared with the state-of-the-art technologies. 1 Introduction Word alignment was first proposed as an intermediate result of statistical machine translation (Brown et al., 1993). In recent years, many researchers have employed statistical models (Wu, 1997; Och and Ney, 2003; Cherry and Lin, 2003) or association measures (Smadja et al., 1996; Ahrenberg et al., 1998; Tufis and Barbu, 2002) to build alignment links. In order to achieve satisfactory results, all of these methods require a large-scale bilingual corpus for training. When the large-scale bilingual corpus is not available, some researchers use existing dictionaries to improve word alignment (Ker and Chang, 1997). However, only a few studies (Wu and Wang, 2004) directly address the problem of domain-specific word alignment when neither the large-scale domain-specific bilingual corpus n</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>D. Wu. 1997. Stochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora. Computational Linguistics, 23(3): 377-403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Wu</author>
<author>H Wang</author>
</authors>
<title>Improving Domain-Specific Word Alignment with a General Bilingual Corpus. In</title>
<date>2004</date>
<booktitle>Machine Translation: From Real Users to Research: 6th conference of AMTA-2004,</booktitle>
<pages>262--271</pages>
<editor>Taylor (Eds.),</editor>
<contexts>
<context position="1679" citStr="Wu and Wang, 2004" startWordPosition="234" endWordPosition="237">iate result of statistical machine translation (Brown et al., 1993). In recent years, many researchers have employed statistical models (Wu, 1997; Och and Ney, 2003; Cherry and Lin, 2003) or association measures (Smadja et al., 1996; Ahrenberg et al., 1998; Tufis and Barbu, 2002) to build alignment links. In order to achieve satisfactory results, all of these methods require a large-scale bilingual corpus for training. When the large-scale bilingual corpus is not available, some researchers use existing dictionaries to improve word alignment (Ker and Chang, 1997). However, only a few studies (Wu and Wang, 2004) directly address the problem of domain-specific word alignment when neither the large-scale domain-specific bilingual corpus nor the domain-specific translation dictionary is available. In this paper, we address the problem of word alignment in a specific domain, in which only a small-scale corpus is available. In the domain-specific (in-domain) corpus, there are two kinds of words: general words, which also frequently occur in the out-of-domain corpus, and domain-specific words, which only occur in the specific domain. Thus, we can use the out-of-domain bilingual corpus to improve the alignm</context>
<context position="14001" citStr="Wu and Wang, 2004" startWordPosition="2460" endWordPosition="2463">y taking the intersection of the two word alignment results, we build a new alignment set. The alignment links in this intersection set are extended by iteratively adding word alignment links into it as described in (Och and Ney, 2000). Based on the extended alignment links, we build a translation dictionary. In order to filter the noise caused by the error alignment links, we only retain those translation pairs whose log-likelihood ratio scores (Dunning, 1993) are above a threshold. Based on the alignment results on the d one-to-many alignments. 6 Evaluation The first method is descri ed in (Wu and Wang, 2004). We call it “Result Adaptation (ResAdapt)”. The adaptation algorithms include two parts: a training algorithm and a testing algorithm. The training algorithm is shown in Figure 1. After getting the two adaptation models and the translation dictionary, we apply them to the in-domain corpus to perform word alignment. Here we call it testing algorithm. The detailed algorithm is shown in Figure 2. For each sentence pair, there are two different word alignment results, from which the final alignment links are selected according to their translation probabilities in the dictionary D. The selection </context>
<context position="17432" citStr="Wu and Wang, 2004" startWordPosition="2998" endWordPosition="3001">d-out set (development set) to adjust parameters. The remained 5,046 pairs are used as domain-specific training data. The Chinese sentences in both the training set and the testing set are automatically segmented into words. In order to exclude the effect of the segmentation errors on our alignment results, the segmentation errors in our testing set are post-corrected. The alignments in the testing set are manually annotated, which includes 3,166 alignment links. Among them, 504 alignment links include multiword units. 6.2 Evaluation Metrics We use the same evaluation metrics as described in (Wu and Wang, 2004). If we use to represent SG the set of alignment links identified by the proposed methods and to denote the reference SC alignment set, the methods to calculate the precision, recall, f-measure, and alignment error rate (AER) are shown in Equation (13), (14), (15), and (16). It can be seen that the higher the f-measure is, the lower the alignment error rate is. Thus, we will only show precision, recall and AER scores in the evaluation results. (1) Train two alignment models M st I (source to target) and (target to MI ts source) using the in-domain corpus. (2) Train the other two alignment mode</context>
<context position="21554" citStr="Wu and Wang, 2004" startWordPosition="3686" endWordPosition="3689">rds. Among the 504 multiword alignment links, about 60% of the links include domain-specific words. In Table 2, we also present the results of our method. Our method achieves the lowest error rate results on both single word alignment and multiword alignment. Method Precision Recall AER Ours (SWA) 0.8703 0.8621 0.1338 Ours (MWA) 0.5635 0.2202 0.6833 Gen (SWA) 0.8816 0.7694 0.1783 Gen (MWA) 0.3366 0.0675 0.8876 Spec (SWA) 0.8710 0.7633 0.1864 Spec (MWA) 0.4760 0.1964 0.7219 Table 2. Single Word and Multiword Alignment Results In order to further compare our method with the method described in (Wu and Wang, 2004). We do another experiment using almost the same-scale in-domain training corpus as described in (Wu and Wang, 2004). From the in-domain training corpus, we randomly select about 500 sentence pairs to build the smaller training set. The testing data is the same as shown in section 6.1. The evaluation results are shown in Table 3. Method Precision Recall AER Ours 0.8424 0.7378 0.2134 ResAdapt 0.8027 0.7262 0.2375 Gen+Spec 0.8041 0.6857 0.2598 Table 3. Alignment Adaptation Results Using a Smaller In-Domain Corpus Compared with the method “Gen+Spec”, our method achieves an error rate reduction of</context>
<context position="22841" citStr="Wu and Wang, 2004" startWordPosition="3905" endWordPosition="3908">S C 2×|SG∩SC| = fmeasure | |SG|+|SC fmeasure 472 while the method “ResAdapt” described in (Wu and Wang, 2004) only achieves an error rate reduction of 8.59%. Compared with the method “ResAdapt”, our method achieves an error rate reduction of 10.15%. This result is different from that in (Wu and Wang, 2004), where their method achieved an error rate reduction of 21.96% as compared with the method “Gen+Spec”. The main reason is that the in-domain training corpus and testing corpus in this paper are different from those in (Wu and Wang, 2004). The training data and the testing data described in (Wu and Wang, 2004) are from a single manual. The data in our corpus are from several manuals describing how to use the diagnostic ultrasound systems. In addition to the above evaluations, we also evaluate our model adaptation method using the &amp;quot;refined&amp;quot; combination in Och and Ney (2000) instead of the translation dictionary. Using the &amp;quot;refined&amp;quot; method to select the alignments produced by our model adaptation method (AER: 0.2371) still yields better result than directly combining out-of-domain and in-domain corpora as training data of the &amp;quot;refined&amp;quot; method (AER: 0.2290). 6.4 The Effect of In-Domain Corpus In gener</context>
<context position="27589" citStr="Wu and Wang, 2004" startWordPosition="4652" endWordPosition="4655"> the word alignment results. In addition, with the training data, an interpolated translation dictionary is built to select the word alignment links from different alignment results. Experimental results indicate that our approach achieves a precision of 84.90% and a recall of 75.99% for word alignment in a specific domain. Our method achieves a relative error rate reduction of 17.43% as compared with the method directly combining the out-of-domain corpus and the in-domain corpus as training data. It also achieves a relative error rate reduction of 6.56% as compared with the previous work in (Wu and Wang, 2004). In addition, when we train the model with a smaller-scale in-domain corpus as described in (Wu and Wang, 2004), our method achieves an error rate reduction of 10.15% as compared with the method in (Wu and Wang, 2004). We also use in-domain corpora and out-of-domain corpora of different sizes to perform adaptation experiments. The experimental results show that our model adaptation method improves alignment results on in-domain corpora of different sizes. The experimental results also show that even a not very large out-of-domain corpus can help to improve the domain-specific word alignment t</context>
</contexts>
<marker>Wu, Wang, 2004</marker>
<rawString>H. Wu and H. Wang. 2004. Improving Domain-Specific Word Alignment with a General Bilingual Corpus. In R. E. Frederking and K. B. Taylor (Eds.), Machine Translation: From Real Users to Research: 6th conference of AMTA-2004, pp. 262-271.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>