<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005028">
<title confidence="0.995712">
A Pattern-based Machine Translation System Extended by
Example-based Processing
</title>
<author confidence="0.906303">
Hideo Watanabe and Koichi Takeda
</author>
<affiliation confidence="0.879865">
IBM Research, Tokyo Research Laboratory
</affiliation>
<address confidence="0.680927">
1623-14 Shimotsuruma, Yamato, Kanagawa 242-8502, Japan
</address>
<email confidence="0.996885">
{watanabe,takeda}@trLibm.co.jp
</email>
<sectionHeader confidence="0.997369" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999954">
In this paper, we describe a machine translation
system called PalmTree which uses the &amp;quot;pattern-
based&amp;quot; approach as a fundamental framework. The
pure pattern-based translation framework has sev-
eral issues. One is the performance due to using
many rules in the parsing stage, and the other is
inefficiency of usage of translation patterns due to
the exact-matching. To overcome these problems,
we describe several methods; pruning techniques
for the former, and introduction of example-based
processing for the latter.
</bodyText>
<sectionHeader confidence="0.99939" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.984210657142857">
While the World-Wide Web (WWW) has quickly
turned the Internet into a treasury of information
for every netizen, non-native English speakers now
face a serious problem that textual data are more
often than not written in a foreign language. This
has led to an explosive popularity of machine trans-
lation (MT) tools in the world.
Under these circumstances, we developed a ma-
chine translation system called PalmTreel which
uses the pattern-based translation [6, 7] formalism.
The key ideas of the pattern-based MT is to em-
ploy a massive collection of diverse transfer knowl-
edge, and to select the best translation among the
translation candidates (ambiguities). This is a nat-
ural extension of the example-based MT in the sense
that we incorporate not only sentential correspon-
dences (bilingual corpora) but every other level of
linguistic (lexical, phrasal, and collocational) ex-
pressions into the transfer knowledge. It is also a
rule-based counterpart to the word n-grams of the
stochastic MT since our patterns intuitively cap-
tures the frequent collocations.
Although the pattern-based MT framework is
promising, there are some drawbacks. One is the
speed, since it uses many rules when parsing. The
other is inefficiency of usage of translation patterns,
&apos;Using this system, IBM Japan releases a MT product
called &amp;quot;Internet King of Translation&amp;quot; which can translate an
English Web pages into Japanese.
since it uses the exact-match when matching trans-
lation patterns with the input. We will describe
several methods for accelerating the system perfor-
mance for the former, and describe the extension
by using the example-based processing [4, 8] for the
latter.
</bodyText>
<sectionHeader confidence="0.998929" genericHeader="method">
2 Pattern-based Translation
</sectionHeader>
<bodyText confidence="0.9992936">
Here, we briefly describe how the pattern-based
translation works. (See [6, 7] for details.) A trans-
lation pattern is a pair of source CFG-rule and its
corresponding target CFG-rule. The followings are
examples of translation patterns.
</bodyText>
<equation confidence="0.985122">
(p1) take:VERB:1 a look at NP:2 VP:1
VP:1 NP:2 wo(dobj) miru(see):VERB:1
(p2) NP:1 VP:2 = S:2 S:2 NP:1 ha VP:2
(p3) PRON:1 NP:1 NP:1 = PRON:1
</equation>
<bodyText confidence="0.982261227272727">
The (p1) is a translation pattern of an English
colloquial phrase &amp;quot;take a look at,&amp;quot; and (p2) and
(p3) are general syntactic translation patterns. In
the above patterns, a left-half part (like &amp;quot;A B C
D&amp;quot;) of a pattern is a source CFG-rule, the right-
half part (like &amp;quot;A B C D&amp;quot;) is a target CFG-rule,
and an index number represents correspondence of
terms in the source and target sides and is also used
to indicate a head term (which is a term having the
same index as the left-hand side2 of a CFG-rule).
Further, some features can be attached as matching
conditions for each term.
The pattern-based MT engine performs a CFG-
parsing for an input sentence with using source
sides of translation patterns. This is done by us-
ing chart-type CFG-parser. The target structure is
constructed by the synchronous derivation which
generates a target structure by combining target
sides of translation patterns which are used to make
a parse.
Figure 2 shows how an English sentence &amp;quot;She
takes a look at him&amp;quot; is translated into Japanese.
</bodyText>
<footnote confidence="0.998793666666667">
2we call the destination of an arrow of a CFG rule de-
scription the left-hand side or LHS, on the other hand, we
call the source side of an arrow the right-hand side or RHS.
</footnote>
<page confidence="0.993413">
1369
</page>
<figure confidence="0.782454">
(she) (subj) (he) (dobj) (see)
</figure>
<figureCaption confidence="0.999711">
Figure 1: Translation Example by Pattern-based MT
</figureCaption>
<figure confidence="0.995870103448276">
VP
................................
NP ---------- .
(p3) I
pron verb det noun prep pron
NP-* NP
.-
.................... .. (P3) I
pron
She take a look at him
.......
............................. .......
.....
.............................
(13) I
NP
cm pron
ha
:
:
...... ............
........................... .......... ............ ..........
...
Y
(p2)
VP
kanojo ha kare wo miru
cm verb
wo miru
</figure>
<bodyText confidence="0.997392166666667">
In this figure, a dotted line represents the corre-
spondence of terms in the source side and the tar-
get side. The source part of (p3) matches &amp;quot;She&amp;quot;
and &amp;quot;him,&amp;quot; the source part of (pl) matches a seg-
ment consisting &amp;quot;take a look at&amp;quot; and a NP( &amp;quot;him&amp;quot;)
made from (p3), and finally the source part of (p2)
matches a whole sentence. A target structure is
constructed by combining target sides of (pl), (p2),
and (p3). Several terms without lexical forms are
instantiated with translation words, and finally a
translated Japanese sentence &amp;quot;kanojo(she) ha(subj)
kare(he) wo(dobj) miru(see)&amp;quot; will be generated.
</bodyText>
<sectionHeader confidence="0.895081" genericHeader="method">
3 Pruning Techniques
</sectionHeader>
<bodyText confidence="0.999921428571429">
As mentioned earlier, our basic principle is to
use many lexical translation patterns for produc-
ing natural translation. Therefore, we use more
CFG rules than usual systems. This causes the
slow-down of the parsing process. We introduced
the following pruning techniques for improving the
performance.
</bodyText>
<subsectionHeader confidence="0.999773">
3.1 Lexical Rule Preference Principle
</subsectionHeader>
<bodyText confidence="0.999001461538462">
We call a CFG rule which has lexical terms in
the right-hand side (RHS) a lexical ride, otherwise
a normal rule. The lexical rule preference principle
(or LRPP) invalidates arcs made from normal rules
in a span in which there are arcs made from both
normal rules and lexical rules.
Further, lexical rules are assigned cost so that
lexical rules which has more lexical terms are pre-
ferred.
For instance, for the span [take, map] of the fol-
lowing input sentence,
He takes a look at a map.
if the following rules are matched,
</bodyText>
<listItem confidence="0.89805925">
(rl) take:verb a look at NP
(r2) take:verb a NP at NP
(r3) take:verb NP at NP
(r4) VERB NP PREP NP
</listItem>
<bodyText confidence="0.8845045">
then, (r4) is invalidated, and (r1),(r2), and (r3) are
preferred in this order.
</bodyText>
<subsectionHeader confidence="0.999864">
3.2 Left-Bound Fixed Exclusive Rule
</subsectionHeader>
<bodyText confidence="0.999928285714286">
We generally use an exclusive title which invali-
dates competitive arcs made from general rules for
a very special expression. This is, however, limited
in terms of the matching ability since it is usually
implemented as both ends of rules are lexical items.
There are many expression such that left-end part
is fixed but right-end is open, but these expressions
cannot be expressed as exclusive rules. Therefore,
we introduce here a left-bound fixed exclusive (or
LBFE) rule which can deal with right-end open
expressions.
Given a span [x y] for which an LBFE rule matched,
in a span [ii] such that i&lt;x and x&lt;j &lt;y, and in all
sub-spans inside [x 37],
</bodyText>
<page confidence="0.983285">
1370
</page>
<figureCaption confidence="0.998927">
Figure 2: The Effect of an LBFE Rule
</figureCaption>
<listItem confidence="0.997061">
• Rules other than exclusive rules are not ap-
plied, and
• Arcs made from non-exclusive rules are inval-
idated.
</listItem>
<bodyText confidence="0.935176888888889">
Fig.2 shows that an LBFE rule &amp;quot;VP VERB
NP&amp;quot;3 matches an input. In spans of (a),(b), and
(c), arcs made from non-exclusive rules are inval-
idated, and the application of non-exclusive rules
are inhibited.
Examples of LBFE rules are as follows:
NP DET own NP
NOUN 4— as many as NP
NP 4-- most of NP
</bodyText>
<subsectionHeader confidence="0.998223">
3.3 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999936636363636">
Preprocessing includes local bracketing of proper
nouns, monetary expressions, quoted expressions,
Internet addresses, and so on. Conversion of nu-
meric expressions and units, and decomposition of
unknown hyphenated words are also included in the
preprocessing. A bracketed span works like an ex-
clusive rule, that is, we can ignore arcs crossing a
bracketed span. Thus, accurate preprocessing not
only improved the translation accuracy, but it vis-
ibly improved the translation speed for longer sen-
tences.
</bodyText>
<subsectionHeader confidence="0.677518">
3.4 Experiments
</subsectionHeader>
<bodyText confidence="0.9999556">
To evaluate the above pruning techniques, we
have tested the speed and the translation quality
for three documents. Table 1 shows the speed to
translate documents with and without the above
pruning techniques.4 The fourth row shows the
</bodyText>
<footnote confidence="0.99033525">
3This is not an LBFE rule in practice.
4Please note that the time shown in this table was
recorded about two years ago and the latest version is much
faster.
</footnote>
<bodyText confidence="0.999812625">
number of sentences tested with pruning which be-
come worse than sentences without pruning and
sentences with pruning which become better than
without pruning.
This shows the speed with pruning is about 2
times faster than one without pruning at the same
time the translation quality with pruning is kept in
the almost same level as one without pruning..
</bodyText>
<sectionHeader confidence="0.9319635" genericHeader="method">
4 Extension by Example-based Pro-
cessing
</sectionHeader>
<bodyText confidence="0.999982272727273">
One drawback of our pattern-based formalism is
to have to use many rules in the parsing process.
One of reasons to use such many rules is that the
matching of rules and the input is performed by the
exact-matching. It is a straightforward idea to ex-
tend this exact-matching to fuzzy-matching so that
we can reduce the number of translation patterns
by merging some patterns identical in terms of the
fuzzy-matching. We made the following extensions
to the pattern-based MT to achieve this example-
based processing.
</bodyText>
<subsectionHeader confidence="0.969625">
4.1 Example-based Parsing
</subsectionHeader>
<bodyText confidence="0.9999834">
If a term in a RHS of source part of a pattern has
a lexical-form and a corresponding term in the tar-
get part, then it is called a fuzzy-match term, oth-
erwise an exact-match term. A pattern writer can
intentionally designate if a term is a fuzzy-match
term or an exact-match term by using a double-
quoted string (for fuzzy-match) or a single-quoted
string (for exact-match).
For instance, in the following example, a word
make is usually a fuzzy-match term since it has a
corresponding term in the target side (ketsudan-
suru), but it is a single-quoted string, so it is an
exact-match term. Words a and decision are exact-
match terms since they has no corresponding terms
in the target side.
</bodyText>
<equation confidence="0.7911075">
&apos;make&apos;:VERB:1 a decision = VP:1
VP:1 4= ketsudan-suru:1
</equation>
<bodyText confidence="0.9860962">
Thus, the example-based parsing extends the
term matching mechanism of a normal parsing as
follows: A term TB matches another matched-term
TA (Lex A,PosB)5 if one of the following conditions
holds.
</bodyText>
<listItem confidence="0.570032666666667">
(1) When a term TB has both LexB and PosB,
(1-1) LexB is the same as LexA, and PosB is
the same as PosA.
</listItem>
<footnote confidence="0.9706675">
5A matched-term inherits a lexical-form of a term it
matches.
</footnote>
<page confidence="0.949106">
1371
</page>
<table confidence="0.998114166666667">
Sample 1 Sample 2 Sample 3
Num of Sentences 13 41 50
Time with Pruning (sec.) 16 23 44
Time without Pruning (sec.) - 48 67
20
Num of Changed Sentences (Worse/Better) 1/2 5/4 4/6
</table>
<tableCaption confidence="0.999562">
Table 1: Result of peformance experiment of pruning techniques
</tableCaption>
<listItem confidence="0.994634181818182">
(1-2) TB is a fuzzy-match term, the semantic
distance of LexB and LexA is smaller
than a criterion, and PosB is the same
as Po8A•
(2) When a term TB has only LexB,
(2-1) LexB is the same as LexA •
(2-2) LexB is a fuzzy-match term, the seman-
tic distance of LexB and LexA is smaller
than a criterion.
(3) When TB has only PosB, then PosB is the
same as PosA.
</listItem>
<subsectionHeader confidence="0.999864">
4.2 Prioritization of Rules
</subsectionHeader>
<bodyText confidence="0.999934142857143">
Many ambiguous results are given in the pars-
ing, and the preference of these results are usually
determined by the cost value calculated as the sum
of costs of used rules. This example-based process-
ing adds fuzzy-matching cost to this base cost. The
fuzzy-matching cost is determined to keep the fol-
lowing order.
</bodyText>
<equation confidence="0.93845">
(1-1) &lt; (1-2),(2-1) &lt; (2-2) &lt; (3)
</equation>
<bodyText confidence="0.99995525">
The costs of (1-2) and (2-1) are determined by
the fuzzy-match criterion value, since we cannot
determine which one of (1-2) and (2-1) is preferable
in general.
</bodyText>
<subsectionHeader confidence="0.99998">
4.3 Modification of Target Side of Rules
</subsectionHeader>
<bodyText confidence="0.974789636363636">
Lexical-forms written in the target side may be
different from translation words of matched input
word, since the fuzzy-matching is used. Therefore,
we must modify the target side before constructing
a target structure.
Suppose that a RHS term tt in the target side
of a pattern has a lexical-form wt, tt has a corre-
sponding term ts in the source side, and ts matches
an input word wi. If wt is not a translation word
of w2, then wt is replaced with translation words of
Wi
</bodyText>
<subsectionHeader confidence="0.998542">
4.4 Translation Example
</subsectionHeader>
<bodyText confidence="0.99943">
Figure 3 shows a translation example by using
example-based processing described above.
In this example, the following translation pat-
terns are used.
</bodyText>
<equation confidence="0.988357">
(p2) NP:1 VP:2 5:2 5:2 NP:1 ha VP:2
(p3) PRON:1 = NP:1 NP:1 PRON:1
(p4) take:VERB:1 a bus:2 =&gt; VP:1
VP:1 basu:2 ni noru:VERB:1
</equation>
<bodyText confidence="0.998188181818182">
The pattern (p4) matches a phrase &amp;quot;take a taxi,&amp;quot;
since &amp;quot;taxi&amp;quot; and &amp;quot;bus&amp;quot; are semantically similar. By
combining target parts of these translation pat-
terns, a translation &amp;quot;PRON ha basu ni noru&amp;quot; is
generated. In this translation, since &amp;quot;basu(bus)&amp;quot; is
not a correct translation of a corresponding source
word &amp;quot;taxi,&amp;quot; it is changed to a correct translation
word &amp;quot;takusi(taxi).&amp;quot; Further, PRON is instanti-
ated by &amp;quot;watashi&amp;quot; which is a translation of &amp;quot;I.&amp;quot;
Then a correct translation &amp;quot;watashi ha takusi ni
noru&amp;quot; is generated.
</bodyText>
<sectionHeader confidence="0.995406" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999975333333333">
Unlike most of existing MT approaches that con-
sist of three major components[1, 2] - analysis,
transfer, and generation - the pattern-based MT
is based on a synchronous model[5, 3] of transla-
tion. That is, the analysis of a source sentence
is directly connected to the generation of a target
sentence through the translation knowledge (i.e.,
patterns). This simple architecture makes it much
easier to customize a system for improving trans-
lation quality than the conventional MT, since the
management of the ambiguities in 3-component ar-
chitecture has to tackle the exponential combina-
tion of overall ambiguities. In this simple model,
we can concentrate on a single module (a parser
with synchronous derivation), and manage most of
translation knowledge in a uniform way as transla-
tion patterns.
Although it is easier to add translation patterns
in our system than previous systems, it is difficult
for non-experts to specify detailed matching condi-
tions (or features). Therefore, we made a pattern
compiler which interprets a simple pattern which a
non-expert writes and converts it into the full-scale
patterns including necessary matching conditions,
</bodyText>
<page confidence="0.980585">
1372
</page>
<figure confidence="0.999170777777778">
(p2) S
••&amp;quot; &apos;&apos;
/VP
34)
pron verb det noun
I take a taxi
.-•
NP
(0) I
cm noun cm verb
ha basu ni noru
(bus)
: .-•
........
........... t ............
71
watasi ha takusi
(I) (subj) (taxi)
</figure>
<figureCaption confidence="0.997086">
Figure 3: Translation Example by Example-based Processing
</figureCaption>
<figure confidence="0.9628545">
pron
....
. ... .....................
...............
1
1 1
ni noru
(ride)
etc. For instance, the following E-to-J simple pat-
tern (a) is converted into a full-scale pattern (b) by
the pattern compiler.6
(a) [VP] hit a big shot = subarasii shotto wo utu
(b) hit:verb:1 a big shot VP:1
VP:1 = subarsii shotto wo utu:verb:1
</figure>
<bodyText confidence="0.9999660625">
Shown in the above example, it is very easy for non-
experts to write these simple patterns. Thus, this
pattern compiler enable non-experts to customize a
system. In conventional MT systems, an expert is
usually needed for each component (analysis, trans-
fer, and generation).
These advantages can reduce the cost of develop-
ment and customization of a MT system, and can
largely contribute to rapidly improve the transla-
tion quality in a short time.
Further, we have shown the way to integrate
example-based processing and pattern-based MT.
In addition to reduce the total number of transla-
tion patterns, this combination enables us to make
a more robust and human-like MT system thanks
to the easy addition of translation pattern.
</bodyText>
<sectionHeader confidence="0.999601" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.997233461538462">
In this paper, we have described a pattern-based
MT system called PalmTree. This system can break
6Practically, some conditional features are attached into
verb terms.
the current ceiling of MT technologies, and at the
same time satisfy three essential requirements of
the current market: efficiency, scalability, and ease-
of-use.
We have described several pruning techniques
for gaining better performance. Further we de-
scribed the integration of example-based processing
and pattern-based MT, which enables us to make
more robust and human-like translation system.
</bodyText>
<sectionHeader confidence="0.99926" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999970954545454">
[1] Nagao, M., Tsujii, J., and Nakamura, J., &amp;quot;The Japanese
Government Project of Machine Translation,&amp;quot; Compu-
tational Linguistics, 11(2-3):91-110, 1985.
[2] Nirenberg, S. editor: Machine Translation - Theoretical
and Methodological Issues, Cambridge University Press,
Cambridge, 1987.
[3] Rambow, 0., and Satta, S., &amp;quot;Synchronous Models of
Language,&amp;quot; Proc. of the 34th of ACL, pp. 116-123,
June 1996.
[4] Sato, S., and Nagao, M. &amp;quot;Toward Memory-based Trans-
lation,&amp;quot; Proc. of 13th COLING, August 1990.
[5) Shieber, S. M., and Schabes Y., &amp;quot;Synchronous Tree-
Adjoining Grammars,&amp;quot; Proc. of the 13th COLING, pp.
253-258, August 1990.
[6] Takeda, K., &amp;quot;Pattern-Based Context-Free Grammars
for Machine Translation,&amp;quot; Proc. of 34th ACL, pp. 144-
151, June 1996.
[7] Takeda, K., &amp;quot;Pattern-Based Machine Translation,&amp;quot;
Proc. of 16th COLING, Vol. 2, pp. 1155-1158, August
1996.
[8] Watanabe, H. &amp;quot;A Similarity-Driven Transfer System,&amp;quot;
Proc. of the 14th COLING, Vol. 2, pp. 770-776, 1992.
</reference>
<page confidence="0.984754">
1373
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.613742">
<title confidence="0.9934165">A Pattern-based Machine Translation System Extended by Example-based Processing</title>
<author confidence="0.990609">Hideo Watanabe</author>
<author confidence="0.990609">Koichi Takeda</author>
<affiliation confidence="0.999998">IBM Research, Tokyo Research Laboratory</affiliation>
<address confidence="0.998093">1623-14 Shimotsuruma, Yamato, Kanagawa 242-8502, Japan</address>
<email confidence="0.984868">watanabe@trLibm.co.jp</email>
<email confidence="0.984868">takeda@trLibm.co.jp</email>
<abstract confidence="0.9637564">In this paper, we describe a machine translation system called PalmTree which uses the &amp;quot;patternbased&amp;quot; approach as a fundamental framework. The pure pattern-based translation framework has several issues. One is the performance due to using many rules in the parsing stage, and the other is inefficiency of usage of translation patterns due to the exact-matching. To overcome these problems, we describe several methods; pruning techniques</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Nagao</author>
<author>J Tsujii</author>
<author>J Nakamura</author>
</authors>
<title>The Japanese Government Project of Machine Translation,&amp;quot;</title>
<date>1985</date>
<journal>Computational Linguistics,</journal>
<pages>11--2</pages>
<contexts>
<context position="12864" citStr="[1, 2]" startWordPosition="2148" endWordPosition="2149">attern (p4) matches a phrase &amp;quot;take a taxi,&amp;quot; since &amp;quot;taxi&amp;quot; and &amp;quot;bus&amp;quot; are semantically similar. By combining target parts of these translation patterns, a translation &amp;quot;PRON ha basu ni noru&amp;quot; is generated. In this translation, since &amp;quot;basu(bus)&amp;quot; is not a correct translation of a corresponding source word &amp;quot;taxi,&amp;quot; it is changed to a correct translation word &amp;quot;takusi(taxi).&amp;quot; Further, PRON is instantiated by &amp;quot;watashi&amp;quot; which is a translation of &amp;quot;I.&amp;quot; Then a correct translation &amp;quot;watashi ha takusi ni noru&amp;quot; is generated. 5 Discussion Unlike most of existing MT approaches that consist of three major components[1, 2] - analysis, transfer, and generation - the pattern-based MT is based on a synchronous model[5, 3] of translation. That is, the analysis of a source sentence is directly connected to the generation of a target sentence through the translation knowledge (i.e., patterns). This simple architecture makes it much easier to customize a system for improving translation quality than the conventional MT, since the management of the ambiguities in 3-component architecture has to tackle the exponential combination of overall ambiguities. In this simple model, we can concentrate on a single module (a pars</context>
</contexts>
<marker>[1]</marker>
<rawString>Nagao, M., Tsujii, J., and Nakamura, J., &amp;quot;The Japanese Government Project of Machine Translation,&amp;quot; Computational Linguistics, 11(2-3):91-110, 1985.</rawString>
</citation>
<citation valid="true">
<date>1987</date>
<booktitle>Machine Translation - Theoretical and Methodological Issues,</booktitle>
<editor>Nirenberg, S. editor:</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge,</location>
<contexts>
<context position="12864" citStr="[1, 2]" startWordPosition="2148" endWordPosition="2149">attern (p4) matches a phrase &amp;quot;take a taxi,&amp;quot; since &amp;quot;taxi&amp;quot; and &amp;quot;bus&amp;quot; are semantically similar. By combining target parts of these translation patterns, a translation &amp;quot;PRON ha basu ni noru&amp;quot; is generated. In this translation, since &amp;quot;basu(bus)&amp;quot; is not a correct translation of a corresponding source word &amp;quot;taxi,&amp;quot; it is changed to a correct translation word &amp;quot;takusi(taxi).&amp;quot; Further, PRON is instantiated by &amp;quot;watashi&amp;quot; which is a translation of &amp;quot;I.&amp;quot; Then a correct translation &amp;quot;watashi ha takusi ni noru&amp;quot; is generated. 5 Discussion Unlike most of existing MT approaches that consist of three major components[1, 2] - analysis, transfer, and generation - the pattern-based MT is based on a synchronous model[5, 3] of translation. That is, the analysis of a source sentence is directly connected to the generation of a target sentence through the translation knowledge (i.e., patterns). This simple architecture makes it much easier to customize a system for improving translation quality than the conventional MT, since the management of the ambiguities in 3-component architecture has to tackle the exponential combination of overall ambiguities. In this simple model, we can concentrate on a single module (a pars</context>
</contexts>
<marker>[2]</marker>
<rawString>Nirenberg, S. editor: Machine Translation - Theoretical and Methodological Issues, Cambridge University Press, Cambridge, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Satta</author>
</authors>
<title>Synchronous Models of Language,&amp;quot;</title>
<date>1996</date>
<booktitle>Proc. of the 34th of ACL,</booktitle>
<pages>116--123</pages>
<contexts>
<context position="12962" citStr="[5, 3]" startWordPosition="2164" endWordPosition="2165">mbining target parts of these translation patterns, a translation &amp;quot;PRON ha basu ni noru&amp;quot; is generated. In this translation, since &amp;quot;basu(bus)&amp;quot; is not a correct translation of a corresponding source word &amp;quot;taxi,&amp;quot; it is changed to a correct translation word &amp;quot;takusi(taxi).&amp;quot; Further, PRON is instantiated by &amp;quot;watashi&amp;quot; which is a translation of &amp;quot;I.&amp;quot; Then a correct translation &amp;quot;watashi ha takusi ni noru&amp;quot; is generated. 5 Discussion Unlike most of existing MT approaches that consist of three major components[1, 2] - analysis, transfer, and generation - the pattern-based MT is based on a synchronous model[5, 3] of translation. That is, the analysis of a source sentence is directly connected to the generation of a target sentence through the translation knowledge (i.e., patterns). This simple architecture makes it much easier to customize a system for improving translation quality than the conventional MT, since the management of the ambiguities in 3-component architecture has to tackle the exponential combination of overall ambiguities. In this simple model, we can concentrate on a single module (a parser with synchronous derivation), and manage most of translation knowledge in a uniform way as tran</context>
</contexts>
<marker>[3]</marker>
<rawString>Rambow, 0., and Satta, S., &amp;quot;Synchronous Models of Language,&amp;quot; Proc. of the 34th of ACL, pp. 116-123, June 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sato</author>
<author>M Nagao</author>
</authors>
<title>Toward Memory-based Translation,&amp;quot;</title>
<date>1990</date>
<booktitle>Proc. of 13th COLING,</booktitle>
<volume>5</volume>
<pages>253--258</pages>
<contexts>
<context position="2423" citStr="[4, 8]" startWordPosition="364" endWordPosition="365">requent collocations. Although the pattern-based MT framework is promising, there are some drawbacks. One is the speed, since it uses many rules when parsing. The other is inefficiency of usage of translation patterns, &apos;Using this system, IBM Japan releases a MT product called &amp;quot;Internet King of Translation&amp;quot; which can translate an English Web pages into Japanese. since it uses the exact-match when matching translation patterns with the input. We will describe several methods for accelerating the system performance for the former, and describe the extension by using the example-based processing [4, 8] for the latter. 2 Pattern-based Translation Here, we briefly describe how the pattern-based translation works. (See [6, 7] for details.) A translation pattern is a pair of source CFG-rule and its corresponding target CFG-rule. The followings are examples of translation patterns. (p1) take:VERB:1 a look at NP:2 VP:1 VP:1 NP:2 wo(dobj) miru(see):VERB:1 (p2) NP:1 VP:2 = S:2 S:2 NP:1 ha VP:2 (p3) PRON:1 NP:1 NP:1 = PRON:1 The (p1) is a translation pattern of an English colloquial phrase &amp;quot;take a look at,&amp;quot; and (p2) and (p3) are general syntactic translation patterns. In the above patterns, a left-h</context>
</contexts>
<marker>[4]</marker>
<rawString>Sato, S., and Nagao, M. &amp;quot;Toward Memory-based Translation,&amp;quot; Proc. of 13th COLING, August 1990. [5) Shieber, S. M., and Schabes Y., &amp;quot;Synchronous TreeAdjoining Grammars,&amp;quot; Proc. of the 13th COLING, pp. 253-258, August 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Takeda</author>
</authors>
<title>Pattern-Based Context-Free Grammars for Machine Translation,&amp;quot;</title>
<date>1996</date>
<booktitle>Proc. of 34th ACL,</booktitle>
<pages>144--151</pages>
<contexts>
<context position="1241" citStr="[6, 7]" startWordPosition="179" endWordPosition="180">ms, we describe several methods; pruning techniques for the former, and introduction of example-based processing for the latter. 1 Introduction While the World-Wide Web (WWW) has quickly turned the Internet into a treasury of information for every netizen, non-native English speakers now face a serious problem that textual data are more often than not written in a foreign language. This has led to an explosive popularity of machine translation (MT) tools in the world. Under these circumstances, we developed a machine translation system called PalmTreel which uses the pattern-based translation [6, 7] formalism. The key ideas of the pattern-based MT is to employ a massive collection of diverse transfer knowledge, and to select the best translation among the translation candidates (ambiguities). This is a natural extension of the example-based MT in the sense that we incorporate not only sentential correspondences (bilingual corpora) but every other level of linguistic (lexical, phrasal, and collocational) expressions into the transfer knowledge. It is also a rule-based counterpart to the word n-grams of the stochastic MT since our patterns intuitively captures the frequent collocations. Al</context>
<context position="2546" citStr="[6, 7]" startWordPosition="382" endWordPosition="383">ce it uses many rules when parsing. The other is inefficiency of usage of translation patterns, &apos;Using this system, IBM Japan releases a MT product called &amp;quot;Internet King of Translation&amp;quot; which can translate an English Web pages into Japanese. since it uses the exact-match when matching translation patterns with the input. We will describe several methods for accelerating the system performance for the former, and describe the extension by using the example-based processing [4, 8] for the latter. 2 Pattern-based Translation Here, we briefly describe how the pattern-based translation works. (See [6, 7] for details.) A translation pattern is a pair of source CFG-rule and its corresponding target CFG-rule. The followings are examples of translation patterns. (p1) take:VERB:1 a look at NP:2 VP:1 VP:1 NP:2 wo(dobj) miru(see):VERB:1 (p2) NP:1 VP:2 = S:2 S:2 NP:1 ha VP:2 (p3) PRON:1 NP:1 NP:1 = PRON:1 The (p1) is a translation pattern of an English colloquial phrase &amp;quot;take a look at,&amp;quot; and (p2) and (p3) are general syntactic translation patterns. In the above patterns, a left-half part (like &amp;quot;A B C D&amp;quot;) of a pattern is a source CFG-rule, the righthalf part (like &amp;quot;A B C D&amp;quot;) is a target CFG-rule, and </context>
</contexts>
<marker>[6]</marker>
<rawString>Takeda, K., &amp;quot;Pattern-Based Context-Free Grammars for Machine Translation,&amp;quot; Proc. of 34th ACL, pp. 144-151, June 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Takeda</author>
</authors>
<title>Pattern-Based Machine Translation,&amp;quot;</title>
<date>1996</date>
<booktitle>Proc. of 16th COLING,</booktitle>
<volume>2</volume>
<pages>1155--1158</pages>
<contexts>
<context position="1241" citStr="[6, 7]" startWordPosition="179" endWordPosition="180">ms, we describe several methods; pruning techniques for the former, and introduction of example-based processing for the latter. 1 Introduction While the World-Wide Web (WWW) has quickly turned the Internet into a treasury of information for every netizen, non-native English speakers now face a serious problem that textual data are more often than not written in a foreign language. This has led to an explosive popularity of machine translation (MT) tools in the world. Under these circumstances, we developed a machine translation system called PalmTreel which uses the pattern-based translation [6, 7] formalism. The key ideas of the pattern-based MT is to employ a massive collection of diverse transfer knowledge, and to select the best translation among the translation candidates (ambiguities). This is a natural extension of the example-based MT in the sense that we incorporate not only sentential correspondences (bilingual corpora) but every other level of linguistic (lexical, phrasal, and collocational) expressions into the transfer knowledge. It is also a rule-based counterpart to the word n-grams of the stochastic MT since our patterns intuitively captures the frequent collocations. Al</context>
<context position="2546" citStr="[6, 7]" startWordPosition="382" endWordPosition="383">ce it uses many rules when parsing. The other is inefficiency of usage of translation patterns, &apos;Using this system, IBM Japan releases a MT product called &amp;quot;Internet King of Translation&amp;quot; which can translate an English Web pages into Japanese. since it uses the exact-match when matching translation patterns with the input. We will describe several methods for accelerating the system performance for the former, and describe the extension by using the example-based processing [4, 8] for the latter. 2 Pattern-based Translation Here, we briefly describe how the pattern-based translation works. (See [6, 7] for details.) A translation pattern is a pair of source CFG-rule and its corresponding target CFG-rule. The followings are examples of translation patterns. (p1) take:VERB:1 a look at NP:2 VP:1 VP:1 NP:2 wo(dobj) miru(see):VERB:1 (p2) NP:1 VP:2 = S:2 S:2 NP:1 ha VP:2 (p3) PRON:1 NP:1 NP:1 = PRON:1 The (p1) is a translation pattern of an English colloquial phrase &amp;quot;take a look at,&amp;quot; and (p2) and (p3) are general syntactic translation patterns. In the above patterns, a left-half part (like &amp;quot;A B C D&amp;quot;) of a pattern is a source CFG-rule, the righthalf part (like &amp;quot;A B C D&amp;quot;) is a target CFG-rule, and </context>
</contexts>
<marker>[7]</marker>
<rawString>Takeda, K., &amp;quot;Pattern-Based Machine Translation,&amp;quot; Proc. of 16th COLING, Vol. 2, pp. 1155-1158, August 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Watanabe</author>
</authors>
<title>A Similarity-Driven Transfer System,&amp;quot;</title>
<date>1992</date>
<booktitle>Proc. of the 14th COLING,</booktitle>
<volume>2</volume>
<pages>770--776</pages>
<contexts>
<context position="2423" citStr="[4, 8]" startWordPosition="364" endWordPosition="365">requent collocations. Although the pattern-based MT framework is promising, there are some drawbacks. One is the speed, since it uses many rules when parsing. The other is inefficiency of usage of translation patterns, &apos;Using this system, IBM Japan releases a MT product called &amp;quot;Internet King of Translation&amp;quot; which can translate an English Web pages into Japanese. since it uses the exact-match when matching translation patterns with the input. We will describe several methods for accelerating the system performance for the former, and describe the extension by using the example-based processing [4, 8] for the latter. 2 Pattern-based Translation Here, we briefly describe how the pattern-based translation works. (See [6, 7] for details.) A translation pattern is a pair of source CFG-rule and its corresponding target CFG-rule. The followings are examples of translation patterns. (p1) take:VERB:1 a look at NP:2 VP:1 VP:1 NP:2 wo(dobj) miru(see):VERB:1 (p2) NP:1 VP:2 = S:2 S:2 NP:1 ha VP:2 (p3) PRON:1 NP:1 NP:1 = PRON:1 The (p1) is a translation pattern of an English colloquial phrase &amp;quot;take a look at,&amp;quot; and (p2) and (p3) are general syntactic translation patterns. In the above patterns, a left-h</context>
</contexts>
<marker>[8]</marker>
<rawString>Watanabe, H. &amp;quot;A Similarity-Driven Transfer System,&amp;quot; Proc. of the 14th COLING, Vol. 2, pp. 770-776, 1992.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>