<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002772">
<note confidence="0.764561">
Computational Linguistics Volume 27, Number 4
</note>
<title confidence="0.888331">
Parallel Text Processing: Alignment and Use of Translation Corpora
</title>
<author confidence="0.631516">
Jean Veronis (editor)
</author>
<affiliation confidence="0.5537775">
(Universit6 de Provence)
Dordrecht: Kluwer Academic
</affiliation>
<bodyText confidence="0.304731833333333">
Publishers (Text, speech and language
technology series, edited by Nancy Ide
and Jean Wronis, volume 13), 2000,
xxiii+402 pp; hardbound, ISBN
0-7923-6546-1, $160.00, £99.00,
Dfl 300.00
</bodyText>
<note confidence="0.087648">
Reviewed by
</note>
<author confidence="0.464983">
Philip Resnik
</author>
<affiliation confidence="0.969814">
University of Maryland
</affiliation>
<sectionHeader confidence="0.989974" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999882225806452">
One can&apos;t help but be fascinated by two sentences in parallel translation, the selfsame
meaning diffused, distributed, diverging across alternative expressions. In his Le Ton
beau de Marot: In Praise of the Music of Language, Douglas Hofstadter goes to the extreme
of inventing or examining dozens upon dozens of alternative English translations of
a single 18-line French poem, reveling in the nuances of content and form. Articles
on machine translation technology in the popular press place the obligatory man-
gled proverb, obtained by automatic translation and then automatic back-translation,
against its original. Closer to home, students of syntactic theory examine word-by-
word glosses of sentences in unfamiliar languages in order to see uncovered there
the building blocks—morpheme, inflectional marking—that recombine into a fluid
expression using familiar words.
By all rights, Parallel Text Processing should be merely a technical volume, and this
should be merely a technical review. But editor Wronis has chosen to leave until the
end the technical inspiration for the book, namely, the ARCADE evaluation exercise
for sentence- and word-level alignment systems. At the start of the book, instead, he
places a tiny gem of a preface written by Martin Kay. In this preface, Kay makes
two significant observations about corpora. First, he notes that what makes current
statistical methods tick is that they use knowledge about language as a proxy for
world knowledge; second, he argues that aligned texts are a rich source of knowledge
about language, knowledge placed there by human translators.
To be sure, Kay expresses doubt about the adequacy of corpora to serve in place
of world knowledge where the tough problems are concerned: &amp;quot;More substantial suc-
cesses in these enterprises [such as high-quality automatic translation] will require a
sharper image of the world than any that can be made out simply from the statistics
of language use&amp;quot; (page xvii). I myself am more optimistic, because as our field moves
from its statistical renaissance into the next phase, I think we are seeing a return to
semantic issues that may help provide the &amp;quot;sharper image of the world&amp;quot; Kay believes
necessary. I do not mean by this a renewed focus on semantic theory per se, but rather
a return to questions of meaning and world knowledge accompanied by the insights of
quantitative, corpus-based approaches. To take a few examples, stochastic parsing has
moved beyond constituency analyses to syntactic dependencies, which are closer to
</bodyText>
<page confidence="0.995229">
592
</page>
<subsectionHeader confidence="0.949339">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.999822">
underlying thematic relationships (Haji e et al. 1998); large-scale lexical resources are be-
ing built with more elaborated semantic underpinnings (Fillmore, Wooters, and Baker
2001; Vossen 1998), and the productive annotate-train-evaluate paradigm is finding
application in meaning-oriented tasks ranging from named entity identification and
coreference (Harman and Chinchor 2001) to word sense disambiguation (Cotton et al.
2001).
</bodyText>
<sectionHeader confidence="0.982765" genericHeader="categories and subject descriptors">
2. Individual Contributions
</sectionHeader>
<bodyText confidence="0.99998569047619">
Whether or not one shares my optimism for the long-term future of semantic depth
in corpus-based approaches, it is clear that, as Kay puts it, &amp;quot;The unparalleled richness
of aligned texts for a great number of purposes is clear for anyone to see&amp;quot; (page xvii).
Veronis begins the collection with &amp;quot;From the Rosetta stone to the information society:
A survey of parallel text processing,&amp;quot; a very nice survey of how parallel texts are
processed and used, laying out clearly the book&apos;s organization into major sections
on techniques for alignment, applications of parallel texts, and corpus resources and
evaluation. Starting in this first chapter by Wronis, points of consensus quickly emerge
in alignment methodology, notably principles of lexical anchoring (e.g., dictionary-
based word pairs or cognate pairs) and of length correlation (taking advantage of
the tendency of short units to translate into short, medium into medium, long into
long), with these two principles serving individually or in combination as the basis
for establishing correspondences.
The first five methodology chapters lay out alternative approaches taking advan-
tage of multiple sources of information within various levels of analysis. Melamed&apos;s
chapter, &amp;quot;Pattern recognition for mapping bitext correspondence,&amp;quot; lays out a powerful
and general geometric approach to identifying token-level correspondences that takes
advantage of both the general length correlation and a general matching predicate
that can exploit dictionary- or cognate-based lexical anchors as available. Simard, in
&amp;quot;Multilingual text alignment: Aligning three or more versions of a text,&amp;quot; focuses on
sentence-level alignment, adapting techniques from molecular biology. A key innova-
tion here is the exploration of how transitivity of word-level translations in multilingual
parallel texts can help identify correspondences missed in the component bilingual
corpora. Ahrenberg, Andersson, and Merkel, in &amp;quot;A knowledge-lite approach to word
alignment,&amp;quot; emphasize a modular combination of resources, with the ultimate aim of
obtaining a nonprobabilistic translation lexicon from parallel corpus links; the chapter
demonstrates portability from English-Swedish to English-French language pairs. The
chapter by Choueka, Conley, and Dagan, &amp;quot;A comprehensive bilingual word alignment
system—application to disparate languages: Hebrew and English,&amp;quot; is distinguished by
its focus on relevant properties of the languages, notably issues of morphology and
lemmatization in a Semitic language. The chapter is likely to be of interest to the grow-
ing segment of the community looking at the English-Arabic language pair. Piperidis,
Papageorgiou, and Boutsis, in &amp;quot;From sentences to words and clauses,&amp;quot; look at multiple
levels of alignment—words, noun phrases, clauses, and sentences—with a focus on
machine-assisted translation of English-Greek.
The remaining four alignment methodology chapters explore radically different
visions of what it means for two texts to be aligned. Wu, in &amp;quot;Bracketing and aligning
words and constituents in parallel text using Stochastic Inversion Transduction Gram-
mars,&amp;quot; presents a stochastic grammar formalism that characterizes sentence pairs, and
associated algorithms, making it possible to take a generative or language-modeling
view of parallel texts. The chapter offers a clear exposition covering bracketing, phrasal
alignment, and word alignment. Fluhr, Bisson, and Elkateb, in &amp;quot;Parallel text alignment
</bodyText>
<page confidence="0.992802">
593
</page>
<note confidence="0.634548">
Computational Linguistics Volume 27, Number 4
</note>
<bodyText confidence="0.999919117647059">
using crosslingual information retrieval techniques,&amp;quot; view the sentence alignment pro-
cess as one in which the goal is to match sentences with their translations, much as
queries are matched with relevant documents in many retrieval systems based on a
vector space notion of semantic proximity. The resulting technique is naturally quite
robust in the face of gaps or order variations. In &amp;quot;Parallel alignment of structured doc-
uments,&amp;quot; Romary and Bonhomme view documents as multilevel structures and take
advantage of structure information in alignment. The chapter includes an interesting
description of relevant aspects of the Text Encoding Initiative (TEI) guidelines for anno-
tating document structure. Although the chapter by Santos, &amp;quot;The translation network:
A model for a fine-grained description of translations,&amp;quot; accompanies in this section
other chapters concerning alignment methods, the main emphasis of the chapter is a
detailed corpus study rather than alignment techniques. The empirical evidence leads
Santos to challenge standard assumptions about parallel texts and alignment and to
propose an alternative conception of translation inspired by the monolingual notion
of aspectual coercion.
The five chapters on applications of parallel text and alignment illustrate signifi-
cant diversity, and at the same time they all draw attention to fundamental problems
concerning the matching of units of meaning at the right granularity. Fung, in &amp;quot;A
statistical view on bilingual lexicon extraction: From parallel corpora to non-parallel
corpora,&amp;quot; raises the question of how to deal with bilingual corpora containing noise,
as might be the case when sentence-level units are not cleanly aligned. In order to
handle corpora containing comparable documents rather than parallel translations,
Fung suggests a vector space approach similar to that of Fluhr, Bisson, and Elkateb
but at the level of word contexts rather than sentences. Blank&apos;s chapter, &amp;quot;Terminol-
ogy extraction from parallel technical texts,&amp;quot; differs from some of the preceding work
in its focus on a particular domain (patent documentation) and technical terminol-
ogy. Monolingual terminology identification is combined with semiautomatic tools
for matching terms; French and German illustrate problems encountered when try-
ing to match multiword versus compounded terms. Gaussier, Hull, and Aft-Molchtar,
in &amp;quot;Term alignment in use: Machine-aided human translation,&amp;quot; present methods for
term extraction and alignment as well as innovative translation memory techniques
that permit multilevel matching. Brown, Carbonell, and Yang, in &amp;quot;Automatic dictio-
nary extraction for cross-language information retrieval,&amp;quot; extract a bilingual dictionary
using a simple technique based on co-occurrence frequency, use the resulting entries
to improve alignments, then extract an improved dictionary; they present comparative
results in cross-language retrieval experiments. Nerbonne&apos;s chapter, &amp;quot;Parallel texts in
computer-assisted language learning,&amp;quot; provides background on language learning and
presents a tool to assist Dutch students of French. The tool approximates automatic
glossing of French sentences in Dutch and permits ready access to parallel examples,
relying heavily on the ability to treat morphological variants as equivalents.
The final section of the book concerns efforts to support the community by means
of parallel corpora, resource sharing, and common evaluation. Isahara and Haruno&apos;s
chapter, &amp;quot;Japanese—English aligned bilingual corpora,&amp;quot; is really a combination of a
proposed alignment technique and a corpus-building project. The chapter makes clear
how difficult it can be, owing to availability, quality, and copyright issues, to produce
a parallel corpus of reasonable size, even for better-studied languages such as English
and Japanese. Singh, McEnery, and Baker&apos;s chapter, &amp;quot;Building a parallel corpus of
English/Panjabi,&amp;quot; strongly reinforces the message of the previous chapter. For modern
Panjabi, a representative of Indic languages, the authors after a great deal of work
found a collection of children&apos;s bedtime stories with English translations, tracked down
the author for permission, and ultimately typed the Panjabi text in by hand because
</bodyText>
<page confidence="0.995264">
594
</page>
<subsectionHeader confidence="0.92797">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.999882125">
it was unavailable as electronic text. In the chapter by Melby, &amp;quot;Sharing of translation
memory databases derived from aligned parallel text,&amp;quot; the author describes in detail
the translation memory exchange (TMX) format, developed by a standards group in
order to facilitate the sharing of translation memory databases. Veronis and Langlais,
in &amp;quot;Evaluation of parallel text alignment systems: The ARCADE project,&amp;quot; describe
the common evaluation of parallel text alignment systems. They report greater than
98% sentence alignment accuracy for systems on &amp;quot;normal&amp;quot; texts; word alignment was
evaluated nonexhaustively and yielded accuracy estimates in the vicinity of 75%.
</bodyText>
<sectionHeader confidence="0.860512" genericHeader="conclusions">
3. Conclusion
</sectionHeader>
<bodyText confidence="0.998450533333333">
Parallel Text Processing succeeds admirably at its goals and will be of use to a wide range
of people. One of the book&apos;s primary goals is to address a wide range of topics and to
cut across communities, and it does a surprisingly good job of balancing introductory
and historical material with technical substance. The overall coherent organization is
supported further by the abstracts and keywords at the front of each chapter. I can
easily imagine using this book both to introduce ideas in a graduate seminar and as
a reference for research.
The book should be quite accessible to graduate students and researchers in com-
putational linguistics and to computer scientists. Linguists, translators, or those with
less mathematical background might want to brush up on their understanding of basic
probability theory and to perhaps get a brief tutorial on dynamic programming from
a friendly computer scientist. Even skimming the more technical sections, however,
they are likely to be rewarded by interesting material. All readers will be grateful that
the editor chose to include separate and fairly thorough indexes for terms, authors,
and languages and writing systems.
</bodyText>
<sectionHeader confidence="0.97425" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.948422">
Cotton, Scott, Phil Edmonds, Adam
Kilgarriff, and Martha Palmer, editors.
2001. SENSEVAL-2: Second International
Workshop on Evaluating Word Sense
Disambiguation Systems, Toulouse, France,
July. ACL SIGLEX.
http://www.sle.sharp.co.uk/senseval2/.
Fillmore, Charles J., Charles Wooters, and
Collin F. Baker. 2001. Building a large
lexical databank which provides deep
semantics. In Proceedings of the Pacific Asian
Conference on Language, Information and
Computation, Hong Kong.
Haji, Jan, Eric Brill, Michael Collins,
Barbora Hladkd, Douglas Jones, Cynthia
Kuo, Lance Ramshaw, Oren Schwartz,
Christoph Tillmann, and Daniel Zeman.
1998. Core natural language processing
technology applicable to multiple
languages: Final report. Technical Report,
Center for Language and Speech
Processing, Johns Hopkins University,
Baltimore.
http://www.clsp.jhu.edu/ws98/projects
/n1p/report/.
Harman, Donna and Nancy Chinchor. 2001.
Message understanding conference
proceedings.
http://www.itl.nist.gov/iaui/894.02/
related_projects/muc/ proceedings/
proceedings_index.html
Hofstadter, Douglas R. 1997. Le Ton beau de
Marot: In Praise of the Music of Language.
Basic Books.
Vossen, Piek. 1998. EuroWordNet: A
Multilingual Database with Lexical Semantic
Networks. Kluwer Academic Publishers,
Dordrecht.
Philip Resnik is an assistant professor at the University of Maryland in the Department of Linguis-
tics and the Institute for Advanced Computer Studies (UMIACS). He has developed STRAND,
a system for automatically finding parallel texts on the Web, and is working on linguistically
informed statistical methods for machine translation. Resnik&apos;s address is: Department of Lin-
guistics, 1401 Marie Mount Hall, University of Maryland, College Park, MD 20742; e-mail:
resnik@umiacs.umd.edu.
</reference>
<page confidence="0.996837">
595
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.255841">
<note confidence="0.609845416666667">Computational Linguistics Volume 27, Number 4 Parallel Text Processing: Alignment and Use of Translation Corpora Jean Veronis (editor) (Universit6 de Provence) Dordrecht: Kluwer Academic Publishers (Text, speech and language technology series, edited by Nancy Ide and Jean Wronis, volume 13), 2000, xxiii+402 pp; hardbound, ISBN 0-7923-6546-1, $160.00, £99.00, Dfl 300.00 Reviewed by</note>
<author confidence="0.99971">Philip Resnik</author>
<affiliation confidence="0.998875">University of Maryland</affiliation>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<date>2001</date>
<booktitle>SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguation Systems,</booktitle>
<editor>Cotton, Scott, Phil Edmonds, Adam Kilgarriff, and Martha Palmer, editors.</editor>
<location>Toulouse, France,</location>
<marker>2001</marker>
<rawString>Cotton, Scott, Phil Edmonds, Adam Kilgarriff, and Martha Palmer, editors. 2001. SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguation Systems, Toulouse, France, July. ACL SIGLEX. http://www.sle.sharp.co.uk/senseval2/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
<author>Charles Wooters</author>
<author>Collin F Baker</author>
</authors>
<title>Building a large lexical databank which provides deep semantics.</title>
<date>2001</date>
<booktitle>In Proceedings of the Pacific Asian Conference on Language, Information and Computation,</booktitle>
<location>Hong Kong.</location>
<marker>Fillmore, Wooters, Baker, 2001</marker>
<rawString>Fillmore, Charles J., Charles Wooters, and Collin F. Baker. 2001. Building a large lexical databank which provides deep semantics. In Proceedings of the Pacific Asian Conference on Language, Information and Computation, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Haji</author>
<author>Eric Brill</author>
<author>Michael Collins</author>
<author>Barbora Hladkd</author>
<author>Douglas Jones</author>
<author>Cynthia Kuo</author>
<author>Lance Ramshaw</author>
<author>Oren Schwartz</author>
<author>Christoph Tillmann</author>
<author>Daniel Zeman</author>
</authors>
<title>Core natural language processing technology applicable to multiple languages: Final report.</title>
<date>1998</date>
<tech>Technical Report,</tech>
<institution>Center for Language and Speech Processing, Johns Hopkins University,</institution>
<location>Baltimore.</location>
<marker>Haji, Brill, Collins, Hladkd, Jones, Kuo, Ramshaw, Schwartz, Tillmann, Zeman, 1998</marker>
<rawString>Haji, Jan, Eric Brill, Michael Collins, Barbora Hladkd, Douglas Jones, Cynthia Kuo, Lance Ramshaw, Oren Schwartz, Christoph Tillmann, and Daniel Zeman. 1998. Core natural language processing technology applicable to multiple languages: Final report. Technical Report, Center for Language and Speech Processing, Johns Hopkins University, Baltimore. /n1p/report/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donna Harman</author>
<author>Nancy Chinchor</author>
</authors>
<title>Message understanding conference proceedings. related_projects/muc/</title>
<date>2001</date>
<note>proceedings/ proceedings_index.html</note>
<contexts>
<context position="3369" citStr="Harman and Chinchor 2001" startWordPosition="506" endWordPosition="509"> meaning and world knowledge accompanied by the insights of quantitative, corpus-based approaches. To take a few examples, stochastic parsing has moved beyond constituency analyses to syntactic dependencies, which are closer to 592 Book Reviews underlying thematic relationships (Haji e et al. 1998); large-scale lexical resources are being built with more elaborated semantic underpinnings (Fillmore, Wooters, and Baker 2001; Vossen 1998), and the productive annotate-train-evaluate paradigm is finding application in meaning-oriented tasks ranging from named entity identification and coreference (Harman and Chinchor 2001) to word sense disambiguation (Cotton et al. 2001). 2. Individual Contributions Whether or not one shares my optimism for the long-term future of semantic depth in corpus-based approaches, it is clear that, as Kay puts it, &amp;quot;The unparalleled richness of aligned texts for a great number of purposes is clear for anyone to see&amp;quot; (page xvii). Veronis begins the collection with &amp;quot;From the Rosetta stone to the information society: A survey of parallel text processing,&amp;quot; a very nice survey of how parallel texts are processed and used, laying out clearly the book&apos;s organization into major sections on tech</context>
</contexts>
<marker>Harman, Chinchor, 2001</marker>
<rawString>Harman, Donna and Nancy Chinchor. 2001. Message understanding conference proceedings. related_projects/muc/ proceedings/ proceedings_index.html</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas R Hofstadter</author>
</authors>
<title>Le Ton beau de Marot:</title>
<date>1997</date>
<booktitle>In Praise of the Music of Language.</booktitle>
<publisher>Basic Books.</publisher>
<marker>Hofstadter, 1997</marker>
<rawString>Hofstadter, Douglas R. 1997. Le Ton beau de Marot: In Praise of the Music of Language. Basic Books.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Piek Vossen</author>
</authors>
<title>EuroWordNet: A Multilingual Database with Lexical Semantic Networks.</title>
<date>1998</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="3183" citStr="Vossen 1998" startWordPosition="486" endWordPosition="487">ay help provide the &amp;quot;sharper image of the world&amp;quot; Kay believes necessary. I do not mean by this a renewed focus on semantic theory per se, but rather a return to questions of meaning and world knowledge accompanied by the insights of quantitative, corpus-based approaches. To take a few examples, stochastic parsing has moved beyond constituency analyses to syntactic dependencies, which are closer to 592 Book Reviews underlying thematic relationships (Haji e et al. 1998); large-scale lexical resources are being built with more elaborated semantic underpinnings (Fillmore, Wooters, and Baker 2001; Vossen 1998), and the productive annotate-train-evaluate paradigm is finding application in meaning-oriented tasks ranging from named entity identification and coreference (Harman and Chinchor 2001) to word sense disambiguation (Cotton et al. 2001). 2. Individual Contributions Whether or not one shares my optimism for the long-term future of semantic depth in corpus-based approaches, it is clear that, as Kay puts it, &amp;quot;The unparalleled richness of aligned texts for a great number of purposes is clear for anyone to see&amp;quot; (page xvii). Veronis begins the collection with &amp;quot;From the Rosetta stone to the informati</context>
</contexts>
<marker>Vossen, 1998</marker>
<rawString>Vossen, Piek. 1998. EuroWordNet: A Multilingual Database with Lexical Semantic Networks. Kluwer Academic Publishers, Dordrecht.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philip</author>
</authors>
<title>Resnik is an assistant professor at the University of Maryland in the Department of Linguistics and the Institute for Advanced Computer Studies (UMIACS). He has developed STRAND, a system for automatically finding parallel texts on the Web, and is working on linguistically informed statistical methods for machine translation. Resnik&apos;s address is:</title>
<institution>Department of Linguistics, 1401 Marie Mount Hall, University of Maryland, College Park, MD</institution>
<note>20742; e-mail: resnik@umiacs.umd.edu.</note>
<marker>Philip, </marker>
<rawString>Philip Resnik is an assistant professor at the University of Maryland in the Department of Linguistics and the Institute for Advanced Computer Studies (UMIACS). He has developed STRAND, a system for automatically finding parallel texts on the Web, and is working on linguistically informed statistical methods for machine translation. Resnik&apos;s address is: Department of Linguistics, 1401 Marie Mount Hall, University of Maryland, College Park, MD 20742; e-mail: resnik@umiacs.umd.edu.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>