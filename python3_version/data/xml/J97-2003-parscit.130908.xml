<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.996265">
Finite-State Transducers in Language and
Speech Processing
</title>
<author confidence="0.824347">
Mehryar Mohri*
</author>
<affiliation confidence="0.267498">
AT&amp;T Labs-Research
</affiliation>
<bodyText confidence="0.99532775">
Finite-state machines have been used in various domains of natural language processing. We
consider here the use of a type of transducer that supports very efficient programs: sequential
transducers. We recall classical theorems and give new ones characterizing sequential string-to-
string transducers. Transducers that output weights also play an important role in language and
speech processing. We give a specific study of string-to-weight transducers, including algorithms
for determinizing and minimizing these transducers very efficiently, and characterizations of the
transducers admitting determinization and the corresponding algorithms. Some applications of
these algorithms in speech recognition are described and illustrated.
</bodyText>
<sectionHeader confidence="0.994129" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999548807692308">
Finite-state machines have been used in many areas of computational linguistics. Their
use can be justified by both linguistic and computational arguments. Linguistically,
finite automata are convenient since they allow one to describe easily most of the
relevant local phenomena encountered in the empirical study of language. They often
lead to a compact representation of lexical rules, or idioms and clichés, that appears
natural to linguists (Gross 1989). Graphic tools also allow one to visualize and modify
automata, which helps in correcting and completing a grammar. Other more general
phenomena, such as parsing context-free grammars, can also be dealt with using finite-
state machines such as RTN&apos;s (Woods 1970). Moreover, the underlying mechanisms in
most of the methods used in parsing are related to automata.
From the computational point of view, the use of finite-state machines is mainly
motivated by considerations of time and space efficiency. Time efficiency is usually
achieved using deterministic automata. The output of deterministic machines depends,
in general linearly, only on the input size and can therefore be considered optimal from
this point of view. Space efficiency is achieved with classical minimization algorithms
(Aho, Hoperoft, and Ullman 1974) for deterministic automata. Applications such as
compiler construction have shown deterministic finite automata to be very efficient
in practice (Aho, Sethi, and Ullman 1986). Finite automata now also constitute a rich
chapter of theoretical computer science (Perrin 1990).
Their recent applications in natural language processing, which range from the
construction of lexical analyzers (Silverztein 1993) and the compilation of morpho-
logical and phonological rules (Kaplan and Kay 1994; Karttunen, Kaplan and Zaenen
1992) to speech processing (Mohri, Pereira, and Riley 1996) show the usefulness of
finite-state machines in many areas. In this paper, we provide theoretical and algo-
rithmic bases for the use and application of the devices that support very efficient
programs: sequential transducers.
</bodyText>
<note confidence="0.86365">
* 600 Mountain Avenue, Murray Hill, NJ 07974, USA.
C) 1997 Association for Computational Linguistics
Computational Linguistics Volume 23, Number 2
</note>
<bodyText confidence="0.999986595238096">
We extend the idea of deterministic automata to transducers with deterministic
input, that is, machines that produce output strings or weights in addition to (deter-
ministically) accepting input. Thus, we describe methods consistent with the initial
reasons for using finite-state machines, in particular the time efficiency of determinis-
tic machines, and the space efficiency achievable with new minimization algorithms
for sequential transducers.
Both time and space concerns are important when dealing with language. Indeed,
one of the recent trends in language studies is a large increase in the size of data sets.
Lexical approaches have been shown to be the most appropriate in many areas of
computational linguistics ranging from large-scale dictionaries in morphology to large
lexical grammars in syntax. The effect of the size increase on time and space efficiency
is probably the main computational problem of language processing.
The use of finite-state machines in natural language processing is certainly not
new. The limitations of the corresponding techniques, however, are pointed out more
often than their advantages, probably because recent work in this field is not yet
described in computer science textbooks. Sequential finite-state transducers are now
used in all areas of computational linguistics.
In the following sections, we give an extended description of these devices. We
first consider string-to-string transducers, which have been successfully used in the
representation of large-scale dictionaries, computational morphology, and local gram-
mars and syntax, and describe the theoretical bases for their use. In particular, we
recall classical theorems and provide some new ones characterizing these transducers.
We then consider the case of sequential string-to-weight transducers. Language
models, phone lattices, and word lattices are among the objects that can be represented
by these transducers, making them very interesting from the point of view of speech
processing. We give new theorems extending the known characterizations of string-
to-string transducers to these transducers. We define an algorithm for determinizing
string-to-weight transducers, characterize the unambiguous transducers admitting de-
terminization, and describe an algorithm to test determinizability. We also give an
algorithm to minimize sequential transducers that has a complexity equivalent to that
of classical automata minimization and that is very efficient in practice. Under cer-
tain restrictions, the minimization of sequential string-to-weight transducers can also
be performed using the determinization algorithm. We describe the corresponding
algorithm and give the proof of its correctness in the appendix.
We have used most of these algorithms in speech processing. In the last section, we
describe some applications of determinization and minimization of string-to-weight
transducers in speech recognition, illustrating them with several results that show
them to be very efficient. Our implementation of the determinization is such that it
can be used on the fly: only the necessary part of the transducer needs to be expanded.
This plays an important role in the space and time efficiency of speech recognition.
The reduction in the size of word lattices that these algorithms provide sheds new
light on the complexity of the networks involved in speech processing.
</bodyText>
<sectionHeader confidence="0.950488" genericHeader="keywords">
2. Sequential String-to-String Transducers
</sectionHeader>
<bodyText confidence="0.998858333333333">
Sequential string-to-string transducers are used in various areas of natural language
processing. Both determinization (Mohri 1994c) and minimization algorithms (Mohri
1994b) have been defined for the class of p-subsequential transducers, which includes
sequential string-to-string transducers. In this section, the theoretical basis of the use
of sequential transducers is described. Classical and new theorems help to indicate
the usefulness of these devices as well as their characterization.
</bodyText>
<page confidence="0.988128">
270
</page>
<note confidence="0.4832975">
Mohri Transducers in Language and Speech
b:E
</note>
<figureCaption confidence="0.965963">
Figure 1
</figureCaption>
<subsectionHeader confidence="0.7214365">
Example of a sequential transducer.
2.1 Sequential Transducers
</subsectionHeader>
<bodyText confidence="0.999966153846154">
We consider here sequential transducers, namely, transducers with a deterministic
input. At any state of such transducers, at most one outgoing arc is labeled with a
given element of the alphabet. Figure 1 gives an example of a sequential transducer.
Notice that output labels might be strings, including the empty string E. The empty
string is not allowed on input, however. The output of a sequential transducer is not
necessarily deterministic. The one in Figure 1 is not since, for instance, two distinct
arcs with output labels b leave the state 0.
Sequential transducers are computationally interesting because their use with a
given input does not depend on the size of the transducer but only on the size of the
input. Since using a sequential transducer with a given input consists of following the
only path corresponding to the input string and in writing consecutive output labels
along this path, the total computational time is linear in the size of the input, if we
consider that the cost of copying out each output label does not depend on its length.
</bodyText>
<sectionHeader confidence="0.720501" genericHeader="introduction">
Definition
</sectionHeader>
<bodyText confidence="0.84134">
More formally, a sequential string-to-string transducer T is a 7-tuple (Q, i, F, E, A, 6 &apos;, a),
with:
</bodyText>
<listItem confidence="0.999754714285714">
• Q the set of states,
• i E Q the initial state,
• F C Q the set of final states,
• E and A finite sets corresponding respectively to the input and output
alphabets of the transducer,
• 6 the state transition function, which maps Q x E to Q,
• a the output function, which maps Q x E to A*.
</listItem>
<bodyText confidence="0.99970625">
The functions 6 and o- are generally partial functions: a state q E Q does not
necessarily admit outgoing transitions labeled on the input side with all elements
of the alphabet. These functions can be extended to mappings from Q x E* by the
following classical recurrence relations:
</bodyText>
<construct confidence="0.449919">
Vs E Q, VW E E*, Va E E, 6(s, E) = s, 6(s, wa) -=-- 6(6(s, w), a);
o-(s, f) = E, a (s, wa) = o-(s, w)o- (6 (s , w), a).
</construct>
<page confidence="0.993726">
271
</page>
<note confidence="0.633924">
Computational Linguistics Volume 23, Number 2
</note>
<figureCaption confidence="0.945457">
Figure 2
</figureCaption>
<subsectionHeader confidence="0.440566">
Example of a 2-subsequential transducer
</subsectionHeader>
<bodyText confidence="0.9838365">
Thus, a string W E E* is accepted by T iff 6(i, w) E F, and in that case the output of
the transducer is cr(i, w).
</bodyText>
<subsectionHeader confidence="0.986276">
2.2 Subsequential and p-Subsequential Transducers
</subsectionHeader>
<bodyText confidence="0.999956918918919">
Sequential transducers can be generalized by introducing the possibility of generating
an additional output string at final states (Schiitzenberger 1977). The application of the
transducer to a string can then possibly finish with the concatenation of such an out-
put string to the usual output. Such transducers are called subsequential transducers.
Language processing often requires a more general extension. Indeed, the ambigui-
ties encountered in language—ambiguity of grammars, of morphological analyzers,
or that of pronunciation dictionaries, for instance—cannot be taken into account when
using sequential or subsequential transducers. These devices associate at most a sin-
gle output to a given input. In order to deal with ambiguities, one can introduce
p-subsequential transducers (Mohri 1994a), namely transducers provided with at most
p final output strings at each final state. Figure 2 gives an example of a 2-subsequential
transducer. Here, the input string w = aa gives two distinct outputs aaa and aab. Since
one cannot find any reasonable case in language in which the number of ambiguities
would be infinite, p-subsequential transducers seem to be sufficient for describing lin-
guistic ambiguities. However, the number of ambiguities could be very large in some
cases. Notice that 1-subsequential transducers are exactly the subsequential transduc-
ers.
Transducers can be considered to represent mappings from strings to strings. As
such, they admit the composition operation defined for mappings, a useful operation
that allows the construction of more complex transducers from simpler ones. The
result of the application of T2 o Ti to a string s can be computed by first considering
all output strings associated with the input s in the transducer Ti, then applying T2
to all of these strings. The output strings obtained after this application represent the
result (T2 0 Ti) (s). In fact, instead of waiting for the result of the application of Ti to
be completely given, one can gradually apply T2 to the output strings of Ti yet to
be completed. This is the basic idea of the composition algorithm, which allows the
transducer T2 0 Ti to be directly constructed given Ti and T2
We define sequential (resp. p-subsequential) functions to be those functions that
can be represented by sequential (resp. p-subsequential) transducers. We noted previ-
ously that the result of the composition of two transducers is a transducer that can
be directly constructed. There exists an efficient algorithm for the general case of the
composition of transducers (transducers subsequential or not, having &amp;transitions or
not, and with outputs in E*, or in E* U fool x R-F U fool) (Mohri, Pereira, and Riley
1996).
The following theorem gives a more specific result for the case of subsequential
and p-subsequential functions, which expresses their closure under composition. We
use the expression p-subsequential in two ways here. One means that a finite number of
</bodyText>
<page confidence="0.986365">
272
</page>
<note confidence="0.582464">
Mohri Transducers in Language and Speech
</note>
<figureCaption confidence="0.597286">
Figure 3
</figureCaption>
<bodyText confidence="0.434215333333333">
Example of a subsequential transducer 72.
ambiguities is admitted (the closure under composition matches this case), the second
indicates that this number equals exactly p.
</bodyText>
<subsectionHeader confidence="0.516718">
Theorem 1
</subsectionHeader>
<bodyText confidence="0.98627">
Let f: E* —&gt; A* be a sequential (resp. p-subsequential) and g: A* -- 9* be a sequential
(resp. q-subsequential) function, then g of is sequential (resp. pq-subsequential).
</bodyText>
<subsectionHeader confidence="0.728602">
Proof
</subsectionHeader>
<bodyText confidence="0.944747555555556">
We prove the theorem in the general case of p-subsequential transducers. The case
of sequential transducers, first proved by Choffrut (1978), can be derived from the
general case in a trivial way. Let T1 be a p-subsequential transducer representing f,
Ti = (Qi,ii,h, E, A, 61, cri, pi), and T2 = (Q2/ i2/ F2, A, C/, 6&apos;2, 0-2, P2) a q-subsequential
transducer representing g. pi and p2 denote the final output functions of T1 and 72,
which map Fi to (A*)P and F2 to (S2* )q, respectively. pi (r) represents, for instance, the
set of final output strings at a final state r. Define the pq-subsequential transducer T -=
(Q, i, F, E, ft 6,a, P) by Q = Qi X Q2/ i = (i1/ i2). F = {(qi,q2) E Q: qi E Fi, 82(q2, pi(qi)) n
F2 01, with the following transition and output functions:
</bodyText>
<equation confidence="0.9532545">
Va E E, V(q1,q2) E Q, b((qi, q2), a) = (51(qi, a), 62(q2, ai(qi, a)))
a((qi,q2),a) = 0-2(q2,a1(91,a))
</equation>
<bodyText confidence="0.937342684210526">
and with the final output function defined by:
V(qi,q2) E F, p((qi, q2)) = 0-2 (q2, pi (qi ))p2(.5(q2, pi (qi )))
Clearly, according to the definition of composition, the transducer r realizes g of. The
definition of p shows that it admits at most pq distinct output strings for a given input
one. This ends the proof of the theorem. 0
Figure 3 gives an example of a 1-subsequential or subsequential transducer T2. The
result of the composition of the transducers Ti and 12 is shown in Figure 4. States in
the transducer T3 correspond to pairs of states of Ti and T2. The composition consists
essentially of making the intersection of the outputs of Ti with the inputs of 72.
Transducers admit another useful operation: union. Given an input string w, a
transducer union of T1 and T2 gives the set union of the strings obtained by application
of Ti to w and 12 to w. We denote by Tl + T2 the union of TI and T2. The following
theorem specifies the type of the transducer TI +7-2, implying in particular the closure
under union of p-subsequential transducers. It can be proved in a way similar to the
composition theorem.
Theorem 2
Let f: E* —&gt; A* be a sequential (resp. p-subsequential) and g: E* --&gt; A* be a se-
quential (resp. q-subsequential) function, then g + f is 2-subsequential (resp. (p + q)-
subsequential).
</bodyText>
<page confidence="0.997043">
273
</page>
<note confidence="0.645283">
Computational Linguistics Volume 23, Number 2
</note>
<figureCaption confidence="0.989605">
Figure 4
</figureCaption>
<bodyText confidence="0.995459545454545">
2-subsequential transducer 73, obtained by composition of 71 and 12.
The union transducer Ti + T2 can be constructed from Ti and 7-2 in a way close
to the union of automata. One can indeed introduce a new initial state connected to
the old initial states of Ti and T2 by transitions labeled with the empty string both on
input and output. But the transducer obtained using this construction is not sequential,
since it contains c-transitions on the input side. There exists, however, an algorithm
to construct the union of p-subsequential and q-subsequential transducers directly as
a p + q-subsequential transducer.
The direct construction consists of considering pairs of states (qi, q), qi being a
state of Ti or an additional state that we denote by an underscore, q2 a state of 7-2 or
an additional state that we denote by an underscore. The transitions leaving (qi, q2)
are obtained by taking the union of the transitions leaving qi and q2, or by keeping
only those of qi if q2 is the underscore state, similarly by keeping only those of q2 if qi
is the underscore state. The union of the transitions is performed in such a way that
if qi and q2 both have transitions labeled with the same input label a, then only one
transition labeled with a is associated to (qi, q2). The output label of that transition is
the longest common prefix of the output transitions labeled with a leaving qi and q2.
See Mohri (1996b) for a full description of this algorithm.
Figure 5 shows the 2-subsequential transducer obtained by constructing the union
of the transducers 7-1 and T2 this way. Notice that according to the theorem the result
could be a priori 3-subsequential, but these two transducers share no common accepted
string. In such cases, the resulting transducer is max(p, q)-subsequential.
</bodyText>
<subsectionHeader confidence="0.999894">
2.3 Characterization and Extensions
</subsectionHeader>
<bodyText confidence="0.962386333333333">
The linear complexity of their use makes sequential or p-subsequential transducers
both mathematically and computationally of particular interest. However, not all trans-
ducers, even when they realize functions (rational functions), admit an equivalent
sequential or subsequential transducer.
Consider, for instance, the function f associated with the classical transducer rep-
resented in Figure 6; f can be defined by:1
VW E {X}-1-, f (w) = aim&apos; if I w I is even,
= Owl otherwise
This function is not sequential, that is, it cannot be realized by any sequential trans-
ducer. Indeed, in order to start writing the output associated to an input string w
a or b according to whether n is even or odd, one needs to finish reading the whole in-
put string w, which can be arbitrarily long. Sequential functions, namely functions that
</bodyText>
<equation confidence="0.600441">
1 We denote by I wl the length of a string w.
(1)
</equation>
<page confidence="0.941177">
274
</page>
<figure confidence="0.612261333333333">
Mohri Transducers in Language and Speech
Figure 5
2-subsequential transducer 14, union of T1 and r2.
</figure>
<figureCaption confidence="0.874306">
Figure 6
</figureCaption>
<subsectionHeader confidence="0.467749">
Transducer T with no equivalent sequential representation.
</subsectionHeader>
<bodyText confidence="0.999758666666667">
can be represented by sequential transducers do not allow such unbounded delays.
More generally, sequential functions can be characterized among rational functions by
the following theorem:
</bodyText>
<subsectionHeader confidence="0.686244">
Theorem 3 (Ginsburg and Rose 1966)
</subsectionHeader>
<bodyText confidence="0.9567505">
Let f be a rational function mapping E* to L. f is sequential iff there exists a positive
integer K such that:
</bodyText>
<footnote confidence="0.4104424">
WI E E*, Va E E, 3w E A*, I wl &lt;K: f(ua) = f(u)w (2)
In other words, for any string u and any element of the alphabet a, f (ua) is equal
to f (u) concatenated with some bounded string. Notice that this implies that f(u) is
always a prefix of f (ua), and more generally that if f is sequential then it preserves
prefixes.
</footnote>
<page confidence="0.994312">
275
</page>
<figure confidence="0.808546">
Computational Linguistics Volume 23, Number 2
</figure>
<figureCaption confidence="0.947423">
Figure 7
</figureCaption>
<figure confidence="0.8864605">
Left-to-right sequential transducer L.
xl:a
</figure>
<figureCaption confidence="0.942822">
Figure 8
</figureCaption>
<subsectionHeader confidence="0.437117">
Right-to-left sequential transducer R.
</subsectionHeader>
<bodyText confidence="0.993156833333333">
The fact that not all rational functions are sequential could reduce the interest
of sequential transducers. The following theorem, due to Elgot and Mezei (1965),
shows, however, that transducers are exactly compositions of left and right sequential
transducers.
Theorem 4 (Elgot and Mezei 1965)
Let f be a partial function mapping E* to A*. f is rational iff there exists a left sequential
function 1: E* —&gt; S2* and a right sequential function r: S-2* —&gt; A* such that f =-- r 0 1.
Left sequential functions or transducers are those we previously defined. Their
application to a string proceeds from left to right. Right sequential functions apply
to strings from right to left. According to the theorem, considering a new sufficiently
large alphabet SZ allows one to define two sequential functions 1 and r that decompose
a rational function f. This result considerably increases the importance of sequential
functions in the theory of finite-state machines as well as in the practical use of trans-
ducers.
Berstel (1979) gives a constructive proof of this theorem. Given a finite-state trans-
ducer T, one can easily construct a left sequential transducer L and a right sequential
transducer R such that R o L = T. Intuitively, the extended alphabet Si keeps track of
the local ambiguities encountered when applying the transducer from left to right. A
distinct element of the alphabet is assigned to each of these ambiguities. The right
sequential transducer can be constructed in such a way that these ambiguities can
then be resolved from right to left. Figures 7 and 8 give a decomposition of the non-
sequential transducer T of Figure 6. The symbols of the alphabet Q = {xl, x2} store
information about the size of the input string w. The output of L ends with x1 iff I wl
is odd. The right sequential function R is then easy to construct.
</bodyText>
<page confidence="0.976511">
276
</page>
<bodyText confidence="0.938033333333333">
Mohri Transducers in Language and Speech
Sequential transducers offer other theoretical advantages. In particular, while sev-
eral important tests, such as equivalence, are undecidable with general transducers,
sequential transducers have the following decidability property
Theorem 5
Let T be a transducer mapping E* to A*. It is decidable whether T is sequential.
A constructive proof of this theorem was given by Choffrut (1978). An efficient
polynomial algorithm for testing the sequentiability of transducers based on this proof
was given by Weber and Klemm (1995).
Choffrut also gave a characterization of subsequential functions based on the def-
inition of a metric on E*. Denote by u A v the longest common prefix of two strings u
and v in E*. It is easy to verify that the following defines a metric on E*:
</bodyText>
<equation confidence="0.997279">
d(u,v) = lul + Iv&apos; - 2lu A vl (3)
</equation>
<bodyText confidence="0.725892666666667">
The following theorem describes this characterization of subsequential functions.
Theorem 6
Let f be a partial function mapping E* to A*. f is subsequential iff:
</bodyText>
<listItem confidence="0.998467">
1. f has bounded variation (according to the metric defined above).
2. for any rational subset Y of A*, f-1(Y) is rational.
</listItem>
<bodyText confidence="0.9709715">
The notion of bounded variation can be roughly understood here as follows: if
d(x,y) is small enough, namely if the prefix that x and y share is sufficiently long
compared to their lengths, then the same is true of their images by f, f(x) and f(y).
This theorem can be extended to describe the case of p-subsequential functions by
defining a metric do° on (A*)P. For any u = , up) and v(vi,.. , vp) E (A*)P,
we define:
</bodyText>
<equation confidence="0.989664">
doo(u,v) = max d(u,,v,) (4)
i&lt;i&lt;p
Theorem 7
</equation>
<listItem confidence="0.7987845">
Let f =([i,.. Jp) be a partial function mapping Dom(f) c E* to (A*)P. f is p-
subsequential iff:
1. f has bounded variation (using the metric d on E* and doo on (A*)P).
2. for all i (1 &lt; &lt; p) and any rational subset Y of A*, (Y) is rational.
</listItem>
<subsectionHeader confidence="0.72094">
Proof
</subsectionHeader>
<bodyText confidence="0.9938839">
Assume f p-subsequential, and let T be a p-subsequential transducer realizing f. A
transducer Ti, 1 &lt; i &lt; p, realizing a component fi off can be obtained from T simply
by keeping only one of the p outputs at each final state of T. T, is subsequential
by construction, hence the component fi is subsequential. Then the previous theorem
implies that each component fi has bounded variation, and by definition of do°, f has
also bounded variation.
Conversely, if the first condition holds, a fortiori eachfi has bounded variation. This
combined with the second condition implies that eachfi is subsequential. A transducer
T realizing f can be obtained by taking the union of p subsequential transducers
realizing each component j. Thus, in view of the theorem 2,f is p-subsequential.
</bodyText>
<page confidence="0.98679">
277
</page>
<note confidence="0.442126">
Computational Linguistics Volume 23, Number 2
</note>
<bodyText confidence="0.9827085">
One can also give a characterization of p-subsequential transducers irrespective of
the choice of their components. Let dp be the semimetric defined by:
</bodyText>
<equation confidence="0.7093845">
V (u, v) E [(*)P]2, dp&apos; (u, v) = max d(ui, vi)
i&lt;i,i&lt;p (5)
The following theorem that follows then gives that characterization.
Theorem 8
</equation>
<bodyText confidence="0.997866">
Let f be a rational function mapping E* to (6,*)P.f is p-subsequential iff it has bounded
variation (using the semimetric dip on (A*)P).
</bodyText>
<subsectionHeader confidence="0.525411">
Proof
</subsectionHeader>
<bodyText confidence="0.973406">
According to the previous theorem the condition is sufficient since:
</bodyText>
<equation confidence="0.881529">
V(U, V) E (E*)2,d(u,v) dp&apos; (u, v)
</equation>
<bodyText confidence="0.939536333333333">
Conversely if f is p-subsequential, let T = (Q, i, F, E, L, 6, a, p) be a p-subsequential
transducer representing f , where p = (p1,. , pp) is the output function mapping Q to
(A*)P. Let N and M be defined by:
</bodyText>
<equation confidence="0.993676">
N = max I pi(q)I and M = max I o-(q, a) I (6)
qEF,1&lt;i,j&lt;p aEE,qEQ
</equation>
<bodyText confidence="0.857096">
We denote by Dom(T) the set of strings accepted by T. Let k &gt; 0 and (ui, u2) E
[Dom(T)12 such that d(ui, u2) &lt;k. Then, there exists u E E* such that:
</bodyText>
<equation confidence="0.995129571428572">
= UV1, 142 = uv2, and lvii + 1v21 &lt;k (7)
Hence,
f (ui) = {a- (i, u)cr (6(i, u), vi)pi (S(i, 140): 1 j &lt; (8)
f (u2) = {o-(i, u)o- (6(i, u), v2)p1(8(i, u2)): 1 &lt;j
Let K = kM + 2N. We have:
crp(f (141),f (u2)) &lt; May 11 + k21) c(P(6(i, al)), PO(i,u2)))
&lt; kM + 2N = K
</equation>
<bodyText confidence="0.984355">
Thus, f has bounded variation using dip. This ends the proof of the theorem.
</bodyText>
<subsectionHeader confidence="0.998473">
2.4 Application to Language Processing
</subsectionHeader>
<bodyText confidence="0.997371285714286">
We briefly mentioned several theoretical and computational properties of sequential
and p-subsequential transducers. These devices are used in many areas of compu-
tational linguistics. In all those areas, the determinization algorithm can be used to
obtain a p-subsequential transducer (Mohri 1996b), and the minimization algorithm to
reduce the size of the p-subsequential transducer used (Mohri 1994b). The composi-
tion, union, and equivalence algorithms for subsequential transducers are also useful
in many applications.
</bodyText>
<page confidence="0.971754">
278
</page>
<bodyText confidence="0.947636909090909">
Mohri Transducers in Language and Speech
2.4.1 Representation of Dictionaries. Very large-scale dictionaries can be represented
by p-subsequential dictionaries because the number of entries and that of the ambigu-
ities they contain are finite. The corresponding representation offers fast look-up since
the recognition does not depend on the size of the dictionary but only on that of the in-
put string considered. The minimization algorithm for sequential and p-subsequential
transducers allows the size of these devices to be reduced to the minimum. Exper-
iments have shown that these compact and fast look-up representations for large
natural language dictionaries can be efficiently obtained. As an example, a French
morphological dictionary of about 21.2 Mb can be compiled into a p-subsequential
transducer of 1.3 Mb, in a few minutes (Mohri 1996b).
</bodyText>
<listItem confidence="0.907657444444445">
2.4.2 Compilation of Morphological and Phonological Rules. Similarly, context-depen-
dent phonological and morphological rules can be represented by finite-state transduc-
ers (Kaplan and Kay 1994). Most phonological and morphological rules correspond to
p-subsequential functions. The result of the computation described by Kaplan and Kay
(1994) is not necessarily a p-subsequential transducer. But, it can often be determinized
using the determinization algorithm for p-subsequentiable transducers. This consid-
erably increases the time efficiency of the transducer. It can be further minimized to
reduce its size. These observations can be extended to the case of weighted rewrite
rules (Mohri and Sproat 1996).
</listItem>
<bodyText confidence="0.943755">
2.4.3 Syntax. Finite-state machines are also currently used to represent local syn-
tactic constraints (Silberztein 1993; Roche 1993; Karlsson et al. 1995; Mohri 1994d).
Linguists can conveniently introduce local grammar transducers that can be used to
disambiguate sentences. The number of local grammars for a given language and
even for a specific domain can be large. The local grammar transducers are mostly
p-subsequential. Determinization and minimization can then be used to make the
use of local grammar transducers more time efficient and to reduce their size. Since
p-subsequential transducers are closed under composition, the result of the composi-
tion of all local grammar transducers is a p-subsequential transducer. The equivalence
of local grammars can also be tested using the equivalence algorithm for sequential
transducers.
For a more detailed overview of the applications of sequential string to string
transducers to language processing, see Mohri (1996a).
Because they are so time and space efficient, sequential transducers will likely be
used increasingly often in natural language processing as well as in other connected
fields. In the following, we consider the case of string-to-weight transducers, which
are also used in many areas of computational linguistics.
</bodyText>
<subsectionHeader confidence="0.378011">
3. Power Series and Subsequential String-to-Weight Transducers
</subsectionHeader>
<bodyText confidence="0.9999364">
We consider string-to-weight transducers, namely transducers with input strings and
output weights. These transducers are used in various domains, such as language
modeling, representation of word or phonetic lattices, etc., in the following way: one
reads and follows a path corresponding to a given input string and outputs a number
obtained by combining the weights along this path. In most applications to natural
language processing, the weights are simply added along the path, since they are
interpreted as (negative) logarithms of probabilities. In case the transducer is not se-
quential, that is, when it does not have a deterministic input, one proceeds in the same
way for all the paths corresponding to the input string. In natural language processing,
specifically in speech processing, one keeps the minimum of the weights associated to
</bodyText>
<page confidence="0.994597">
279
</page>
<figure confidence="0.751346">
Computational Linguistics &amp;quot;Volume 23, Number 2
</figure>
<figureCaption confidence="0.968232">
Figure 9
</figureCaption>
<subsectionHeader confidence="0.618086">
Example of a string-to-weight transducer.
</subsectionHeader>
<bodyText confidence="0.997749666666667">
these paths. This corresponds to the Viterbi approximation in speech recognition or in
other related areas for which hidden Markov models (HMM&apos;s) are used. In all such
applications, one looks for the best path, i.e., the path with the minimum weight.
</bodyText>
<subsectionHeader confidence="0.990992">
3.1 Definitions
</subsectionHeader>
<bodyText confidence="0.99552">
In this section, we give the definition of string-to-weight transducers and other defi-
nitions useful for the presentation of the theorems of the following sections.
In addition to the output weights of the transitions, string-to-weight transducers
are provided with initial and output weights. For instance, when used with the input
string ab, the transducer in Figure 9 outputs: 5 + 1 + 2 + 3 = 11, 5 being the initial and
3 the final weight.
</bodyText>
<subsectionHeader confidence="0.469857">
Definition
</subsectionHeader>
<bodyText confidence="0.899787">
More formally, a string-to-weight transducer T is defined by T = (Q, E, I, F, E, A, p)
with:
</bodyText>
<listItem confidence="0.999492428571429">
• Q a finite set of states,
• E the input alphabet,
• I c Q the set of initial states,
• F C Q the set of final states,
• Ec QxEx R+ x Q a finite set of transitions,
• A the initial weight function mapping Ito R+,
• p the final weight function mapping F to R.
</listItem>
<bodyText confidence="0.993288">
One can define for T a transition (partial) function S mapping Q x E to 2Q by:
V (q, a) E Q x E, (q , a) = fq&apos; I 3x E (q, a, x, q&apos;) e El
and an output function a mapping E to R. by:
</bodyText>
<equation confidence="0.587126">
Vt = (p, a, x, q) E E, o- (t) = x
</equation>
<bodyText confidence="0.948972333333333">
A path 7 in T from q E Q to q&apos; c Q is a set of successive transitions from q to q&apos;:
7r = ((q0,ao,x0, qi), • • • , (qm—i,am_i, xm_i, qm)), with Vi E [0, M — 11, q,±1 E 6(q11at). We can
extend the definition of a to paths by: a(x) = xoxi • x-i.
We denote by 7r e q q&apos; the set of paths from q to q&apos; labeled with the input string
w. The definition of S can be extended to Q x E* by:
V(q, EQ x E*,(5(q,w) = {q&apos;: path 7r in T,7r E q q&apos;}
</bodyText>
<page confidence="0.685314">
280
</page>
<bodyText confidence="0.7183975">
Mohri Transducers in Language and Speech
and to 2(2 x E*, by:
</bodyText>
<equation confidence="0.8585605">
VR c Q, Vw E E*,O(R,w) = U o(q,w)
qER
</equation>
<bodyText confidence="0.938799">
For (q, w, q&apos;) E QxExQ such that there exists a path from q to q&apos; labeled with
w, we define 9(q, w, q&apos;) as the minimum of the outputs of all paths from q to q&apos; with
input w:
</bodyText>
<equation confidence="0.9535355">
0(q,w,q1) = min a(r)
irEct;&apos;
</equation>
<bodyText confidence="0.99993725">
A successful path in T is a path from an initial state to a final state. A string w E E*
is accepted by T if there exists a successful path labeled with w: w E S(I,w) n F. The
output corresponding to an accepted string w is then obtained by taking the minimum
of the outputs of all successful paths with input label w:
</bodyText>
<equation confidence="0.9906915">
min (A(i) + 0(i, w,f) + p(f))
(if)ElxF: fE6(i,w)
</equation>
<bodyText confidence="0.997269">
A transducer T is said to be trim if all states of T belong to a successful path. String-to-
weight transducers clearly realize functions mapping E* to 12.±. Since the operations
we need to consider are addition and min, and since (74 U { oo }, min, +, oo, 0) is a
semiring, we call these functions formal power series.&apos; We adopt the terminology
and notation used in formal language theory (Berstel and Reutenauer 1988; Kuich and
Salomaa 1986; Salomaa and Soittola 1978):
</bodyText>
<listItem confidence="0.997739333333333">
• the image by a formal power series S of a string w is denoted by (S, w)
and called the coefficient of w in S.
• the notation S E. (S,w)w is then used to define a power series by
its coefficients,
• the support of S is the language defined by:
supp(S) = fw E E*: (S, w) oo }
</listItem>
<bodyText confidence="0.9969507">
The fundamental theorem of Schutzenberger (1961), analogous to Kleene&apos;s the-
orem for formal languages, states that a formal power series S is rational iff it is
recognizable, that is, realizable by a string-to-weight transducer. The semiring (R.+ U
{ °e}, min, +, 00, 0) used in many optimization problems is called the tropical semiring.3
So, the functions we consider here are more precisely rational power series over the
tropical semiring.
A string-to-weight transducer T is said to be unambiguous if for any given string
w there exists at most one successful path labeled with w.
In the following, we examine, more specifically, efficient string-to-weight transduc-
ers: subsequential transducers. A transducer is said to be subsequential if its input is
</bodyText>
<footnote confidence="0.708227666666667">
2 Recall that a semiring is essentially a ring that may lack negation, namely in which the first operation
does not necessarily admit inversion. (R., +, 0,1), where 0 and 1 are, respectively, the identity
elements for + and or, for any non-empty set E, (2E, U, n, 0,E), where 0 and E are, respectively, the
identity elements for U and n, are other examples of semirings.
3 This terminology is often used more specifically when the set is restricted to natural integers
(JV U { oo }, min, +, oo, 0).
</footnote>
<page confidence="0.983333">
281
</page>
<note confidence="0.433964">
Computational Linguistics Volume 23, Number 2
</note>
<bodyText confidence="0.999721714285714">
deterministic, that is if at any state there exists at most one outgoing transition labeled
with a given element of the input alphabet E. Subsequential string-to-weight transduc-
ers are sometimes called weighted automata, or weighted acceptors, or probabilistic
automata, or distance automata. Our terminology is meant to favor the functional view
of these devices, which is the view that we consider here. Not all string-to-weight trans-
ducers are subsequential but we define an algorithm to determinize nonsubsequential
transducers when possible.
</bodyText>
<subsectionHeader confidence="0.497375">
Definition
</subsectionHeader>
<bodyText confidence="0.9976575">
More formally a string-to-weight subsequential transducer T = (Q, i, F, E, (5, a, A, p) is
an 8-tuple, with:
</bodyText>
<listItem confidence="0.9998487">
• Q the set of its states,
• i E Q its initial state,
• F c Q the set of final states,
• E the input alphabet,
• (5 the transition function mapping Q x E to Q, (5 can be extended as in
the string case to map Q x E* to Q,
• a the output function, which maps Q x E to 14, a can also be extended
to Q x E*,
• A e 74 the initial weight,
• p the final weight function mapping F to R.
</listItem>
<bodyText confidence="0.99928275">
A string w E E* is accepted by a subsequential transducer T if there exists f E F
such that (5(i, w) = f . The output associated to w is then: A + cr(i, w) + p(f).
We will use the following definition for characterizing the transducers that admit
determinization.
</bodyText>
<subsectionHeader confidence="0.500358">
Definition
</subsectionHeader>
<bodyText confidence="0.9980235">
Two states q and q&apos; of a string-to-weight transducer T = (Q, I, F, E, 6, a, A, p), not nec-
essarily subsequential, are said to be twins if:
</bodyText>
<equation confidence="0.944132">
V(u, V) E (E*)2, (fq , q&apos;l C 6(1, u), q E 6 (q, v), q&apos; E (5(q&apos; ,v)) =- 0(q, v, q) = 0 (q&apos; ,v, q&apos;) (9)
</equation>
<bodyText confidence="0.999939363636364">
In other words, q and q&apos; are twins if, when they can be reached from the initial
state by the same string u, the minimum outputs of loops at q and q&apos; labeled with any
string v are identical. We say that T has the twins property when any two states q and
q&apos; of T are twins. Notice that according to the definition, two states that do not have
cycles with the same string v are twins. In particular, two states that do not belong to
any cycle are necessarily twins. Thus, an acyclic transducer has the twins property
In the following section, we consider subsequential power series in the tropi-
cal semiring, that is, functions that can be realized by subsequential string-to-weight
transducers. Many rational power series defined on the tropical semiring considered
in practice are subsequential, in particular, acyclic transducers represent subsequential
power series.
</bodyText>
<page confidence="0.868786">
282
</page>
<bodyText confidence="0.980714733333333">
Mohri Transducers in Language and Speech
We introduce a theorem giving an intrinsic characterization of subsequential power
series irrespective of the transducer realizing them. We then present an algorithm
that allows one to determinize some string-to-weight transducers. We give a general
presentation of the algorithm since it can be used with many other semirings, in
particular, with string-to-string transducers and with transducers whose output labels
are pairs of strings and weights.
We then use the twins property to define a set of transducers to which the deter-
minization algorithm applies. We give a characterization of unambiguous transducers
admitting determinization, and then use this characterization to define an algorithm
to test if a given transducer can be determinized.
We also present a very efficient minimization algorithm that applies to subse-
quential string-to-weight transducers. In many cases, the determinization algorithm
can also be used to minimize a subsequential transducer; we describe this use of the
algorithm and give the related proofs in the appendix.
</bodyText>
<subsectionHeader confidence="0.999406">
3.2 Characterization of Subsequential Power Series
</subsectionHeader>
<bodyText confidence="0.876072">
Recall that one can define a metric on E* by:
</bodyText>
<equation confidence="0.615159">
d(u, v) = jui + jvi — 2ju A &apos;V (10)
</equation>
<bodyText confidence="0.935873">
where we denote by u A v the longest common prefix of two strings u and v in E*.
The definition we gave for subsequential power series depends on the transducers
representing them. The theorem that follows gives an intrinsic characterization of
subsequential power series.&apos;
Theorem 9
Let S be a rational power series defined on the tropical semiring. S is subsequential
iff it has bounded variation.
Proof
Assume that S is subsequential. Let T = (Q, i, F, E, 6,0•, A, p) be a subsequential trans-
ducer. 8 denotes the transition function associated with 7-, a its output function, and
A and p the initial and final weight functions. Let L be the maximum of the lengths of
all output labels of T:
</bodyText>
<equation confidence="0.9975155">
L= max la (q , a)I (11)
(q,a)E(2xE
</equation>
<bodyText confidence="0.958531">
and R the upper bound of all output differences at final states:
</bodyText>
<equation confidence="0.997196">
R= max p(q) — p(q1) I (12)
(q,q9EF2
</equation>
<bodyText confidence="0.9490855">
and define M as M -= L + R. Let (ui, u2) be in (E*)2. By definition of d, there exists
U E E* such that:
</bodyText>
<equation confidence="0.738549666666667">
-+- UV 1, U = uv2, and lvii + Iv21 = d(ui, u2) (13)
Hence, = (i, u) + a- (6 (i, u), vi)
= a- (i, u) + cr (S(i, u), v2)
</equation>
<footnote confidence="0.915844">
4 This is an extension of the characterization theorem of Choffrut (1978) for string-to-string functions.
The extension is not straightforward because the length of an output string is a natural integer. Here
we deal with real numbers.
</footnote>
<page confidence="0.992051">
283
</page>
<figure confidence="0.431515">
Computational Linguistics Volume 23, Number 2
Since
</figure>
<equation confidence="0.931177555555556">
I u(6(i, u), Vi) — 0(6(i, u), v2)I &lt; L • (IVi I 1V21) = L d(ui, u2)
and
II* (04)) P(O(i,u2))I R
we have
+ cr(i, + P(6(i, 140) — A ± o-(i, u2) P(6(i, u2))1 L d(ui,u2) +R
Notice that if u1 u2, R &lt;R • d(ui, u2). Thus
l A + (7(i, ui) + (i, ui)) — A + cr(i, u2) + p(6(i, u2))I (L + d(ui, 142)
Therefore:
V(Ui, U2) E (E*)2, I5(ui) — S(U2)I &lt; M • C1(1-11,142) (14)
</equation>
<bodyText confidence="0.997578083333333">
This proves that S is M-Lipschitzian5 and a fortiori that it has bounded variation.
Conversely, suppose that S has bounded variation. Since S is rational, according
to the theorem of Schtitzenberger (1961) it is recognizable and therefore there exists
a string-to-weight transducer 7- = (Q, I, F, E, 6, a, p) realizing S. As in the case of
string-to-string transducers, one can show that any transducer admits an equivalent
trim unambiguous transducer. So, without loss of generality we can assume T trim
and unambiguous.
Furthermore, we describe in the next sections a determinization algorithm. We
show that this algorithm applies to any transducer that has the twins property Thus,
in order to show that S is subsequentiable, it is sufficient to show that T has the twins
property
Consider two states q and q&apos; of T and let (u, v) E (E* )2 be such that:
</bodyText>
<equation confidence="0.970071">
C (I, u), q E 6 (q, v), E 6(qc v)
</equation>
<bodyText confidence="0.5735905">
Since T is trim there exists (w, w&apos;) E (E*)2 such that 6(q, w) n F 0 and 6 (q, w&apos;) n F 0.
Notice that
Vk &gt; 0, d(uvkw, uvkw&apos;) d(w, w1)
Thus, since S has bounded variation
</bodyText>
<equation confidence="0.9320888">
3K&gt; 0, Vk &gt; 0, IS(uvkw) — S(uvkw&apos;)1 &lt;K
Since 7- is unambiguous, there is only one path from I to F corresponding to uvkw
(resp. uvkw&apos;). We have:
S(uvkw) = 0 (I, uw, F) + (q, v, q)
S(uvk w&apos;) uw&apos; ,F) + (q&apos;, v, q&apos;)
</equation>
<footnote confidence="0.899333">
5 This implies in particular that the subsequential power series over the tropical semiring define
continuous functions for the topology induced by the metric d on E*. Also this shows that in the
theorem one can replace has bounded variation by is Lipschitzian.
</footnote>
<page confidence="0.989341">
284
</page>
<table confidence="0.8817975">
Mohri Transducers in Language and Speech
Power Series Determinization(r1, r2)
1 F2
2 A2 &lt;— ED Al (i)
</table>
<figure confidence="0.814816">
IEIi
3 i2 Lif(i,)V Al(i))/
jEJi
4 Q {i2}
5 while Q 0
6 do q2 4- head[Q]
7 if (there exists (q, x) E q2 such that q E Fi)
8 then F2 4- F2 U {q2}
9 P2 (q2) (130 x pi(q)
qEF1,(q,x)Eq2
10 for each a such that r(q21 a) 0
11 do a2(q2, a) 4-- [x o( t)]
(q,x)Er (q2,a) t=(q,a,cr (t) (t)) EE1
12 62(q2, a) 4-- U {(qC ED [0-2(q2,a)]-1 x al (t)}
q&apos;Ev(q2,a) (q,x,t)Ery(q2,a),ni(t)=q&apos;
13 if (62(q2, a) is a new state)
14 then ENQuEuE(Q, 62(q2, a))
15 DEQuEuE(Q)
</figure>
<figureCaption confidence="0.882446">
Figure 10
</figureCaption>
<bodyText confidence="0.845006">
Algorithm for the determinization of a transducer Ti representing a power series defined on
the semiring (S, G, 6, 1) .
Hence
</bodyText>
<equation confidence="0.514065333333333">
3K &gt; 0, Vk &gt; 0, I (0(/, uw,F) — 0 (I, uw&apos; , F)) + k(0(q, v, q) — 61(qc v, q&apos;))I 5 K
0 (q , v, q) — 0 (q&apos; ,v, q&apos;) = 0
Thus r has the twins property This ends the proof of the theorem. 0
</equation>
<subsectionHeader confidence="0.999849">
3.3 General Determinization Algorithm for Power Series
</subsectionHeader>
<bodyText confidence="0.999919545454545">
We describe in this section an algorithm for constructing a subsequential transducer
72 = (Q2, 2,F2, E, 62, 0-2, A2,192) equivalent to a given nonsubsequential one TI
E, I, F1, Ei, A1, P1). The algorithm extends our determinization algorithm for string-
to-string transducers representing p-subsequential functions to the case of transducers
outputting weights (Mohri 1994c).
Figure 10 gives the pseudocode of the algorithm. We present the algorithm in the
general case of a semiring (S, ED, 0, 0, 1) on which the transducer Ti is defined. Indeed,
the algorithm we are describing here applies as well to transducers representing power
series defined on many other semirings.6 We describe the algorithm in the case of the
tropical semiring. For the tropical semiring, one can replace ED by min and 0 by + in
the pseudocode of Figure 10.7
</bodyText>
<footnote confidence="0.9757105">
6 In particular, the algorithm also applies to string subsequentiable transducers and to transducers that
output pairs of strings and weights. We will come back to this point later.
</footnote>
<page confidence="0.8517125">
7 Similarly, Ai-1 should be interpreted as —A, and [a2(q2,a)] —1 as —c72(q2,a).
285
</page>
<note confidence="0.434116">
Computational Linguistics Volume 23, Number 2
</note>
<bodyText confidence="0.999338964285714">
The algorithm is similar to the powerset construction used for the determinization
of automata. However, since the outputs of two transitions bearing the same input
label might differ, one can only output the minimum of these outputs in the result-
ing transducer, therefore one needs to keep track of the residual weights. Hence, the
subsets q2 that we consider here are made of pairs (q, x) of states and weights.
The initial weight A2 Of 72 is the minimum of all the initial weights of TI (line
2). The initial state i2 is a subset made of pairs (i, x), where i is an initial state of
and x = A1 (i) — A2 (line 3). We use a queue Q to maintain the set of subsets q2 yet to
be examined, as in the classical powerset construction.&apos; Initially, Q contains only the
subset i2. The subsets q2 are the states of the resulting transducer. q2 is a final state of
7-2 iff it contains at least one pair (q, x), with q a final state of ri (lines 7-8). The final
output associated to q2 is then the minimum of the final outputs of all the final states
in q2 combined with their respective residual weight (line 9).
For each input label a such that there exists at least one state q of the subset
q2 admitting an outgoing transition labeled with a, one outgoing transition leaving q2
with the input label a is constructed (lines 10-14). The output 0-2(q2, a) of this transition
is the minimum of the outputs of all the transitions with input label a that leave a
state in the subset q2, when combined with the residual weight associated to that state
(line 11).
The destination state 62(q2, a) of the transition leaving q2 is a subset made of pairs
(q&apos;, x&apos;), where q&apos; is a state of Ti that can be reached by a transition labeled with a, and
x&apos; the corresponding residual weight (line 12). x&apos; is computed by taking the minimum
of all the transitions with input label a that leave a state q of q2 and reach q&apos;, when
combined with the residual weight of q minus the output weight C72 (q2, a). Finally,
62(q2, a) is enqueued in Q iff it is a new subset.
We denote by n1 (t) the destination state of a transition t E Ei. Hence n1 (t) q&apos; ,
if t = (q, a, x, q&apos;) E Ei. The sets r(q2, a), of(q2, a), and v(q2, a) used in the algorithm are
defined by:
</bodyText>
<listItem confidence="0.998987666666667">
• r(q2,a) = {(q, x) E q2: 3t = (q, a, cri(t), ni(t)) E Ell
• 1, (q2, a) = {(q, x, t) E q2 x Ei: t (q, a, o-i(t), ni(t)) E Ell
• v(112, a) = {q&apos;: ](q, x) E q2, 3t = (q, a, 0-1(t), q&apos;) E El}
</listItem>
<bodyText confidence="0.999639133333333">
(q2, a) denotes the set of pairs (q, x), elements of the subset q2, having transitions
labeled with the input a. 7(q2, a) denotes the set of triples (q, x, t) where (q, x) is a pair
in q2 such that q admits a transition with input label a. v(q2, a) is the set of states q&apos;
that can be reached by transitions labeled with a from the states of the subset q2.
The algorithm is illustrated in Figures 11 and 12. Notice that the input ab admits
several outputs in pi: {1 + 1 = 2,1 + 3 = 4,3 + 3 = 6,3 + 5 -= 8}. Only one of these
outputs (2, the smallest) is kept in the determinized transducer /12, since in the tropical
semiring one is only interested in the minimum outputs for any given string.
Notice that several transitions might reach the same state with a priori differ-
ent residual weights. Since one is only interested in the best path, namely the path
corresponding to the minimum weight, one can keep the minimum of these weights
for a given state element of a subset (line 11 of the algorithm of Figure 10). In the
next section, we give a set of transducers TI for which the determinization algorithm
terminates. The following theorem shows the correctness of the algorithm when it
terminates.
</bodyText>
<page confidence="0.6991015">
8 The algorithm works with any queue discipline chosen for Q.
286
</page>
<figure confidence="0.463664333333333">
Mohri Transducers in Language and Speech
Figure 11
Transducer pi representing a power series defined on (RH_ u foo}, min, +).
</figure>
<figureCaption confidence="0.839545">
Figure 12
</figureCaption>
<bodyText confidence="0.778504">
Transducer it2 obtained by power series determinization of
Theorem 10
Assume that the determinization algorithm terminates, then the resulting transducer
72 is equivalent to r1.
</bodyText>
<subsectionHeader confidence="0.430847">
Proof
</subsectionHeader>
<bodyText confidence="0.9995915">
We denote by Oi(q,w, q&apos;) the minimum of the outputs of all paths from q to q&apos;. By
construction we have:
</bodyText>
<equation confidence="0.939416">
A2 -= mm(il)
</equation>
<bodyText confidence="0.96950575">
We define the residual output associated to q in the subset 62(i2, w) as the weight
c(q, w) associated to the pair containing q in 82 (i2, w). It is not hard to show by induction
on I wl that the subsets constructed by the algorithm are the sets 62 (i2, W E E*, such
that:
</bodyText>
<equation confidence="0.977986">
Vw E E*, 62(i2, w) =U {(q&apos; c(q&apos; w)} (15)
qE(51. (11,w)
c(q, w) = min(Ai(ii) + w, q)) — w) — A2
Eh
0-2(l2,W) =
qE61(11,w)
Min (Ai (il ) 01 (il, q)) — A2
</equation>
<page confidence="0.980074">
287
</page>
<note confidence="0.635436">
Computational Linguistics Volume 23, Number 2
</note>
<bodyText confidence="0.9994757">
Notice that the size of a subset never exceeds I Qi I: card(62(i2, w)) &lt; I Qi. A state
q belongs at most to one pair of a subset, since for all paths reaching q, only the
minimum of the residual outputs is kept. Notice also that, by definition of mm, in any
subset there exists at least one state q with a residual output c(q, w) equal to 0.
A string w is accepted by Ti iff there exists q E F1 such that q E 61(Ii,w). Using
equations 15, it is accepted if 62(i2, w) contains a pair (q,c(q,w)) with q E Fi. This is
exactly the definition of the final states F2 (line 7). So 7-1 and T2 accept the same set of
strings.
Let w E E* be a string accepted by ri and T2. The definition of p2 in the algorithm
of figure 10, line 9, gives:
</bodyText>
<equation confidence="0.9971646">
p2(62(i2, w)) = min pi (q) + min(Ai(ii) + w, q)) - (i2, w) - A2 (16)
qE.51(11,w)nFi iiEli
Thus, if we denote by S the power series realized by Ti, we have:
P2(62(i2, w)) = (S, w) — a2(i2, w) — A2 (17)
Hence: A2 + 0-2(i2,W) P2(62 (i2, W)) = (S, W). 0
</equation>
<bodyText confidence="0.999118346153846">
The power series determinization algorithm is equivalent to the usual determiniza-
tion of automata when the initial weight, the final weights, and all output labels are
equal to 0. The subsets considered in the algorithm are then exactly those obtained in
the powerset determinization of automata, all residual outputs c(q, w) being equal to
0.
Both space and time complexity of the determinization algorithm for automata
are exponential. There are minimal deterministic automata with exponential size with
respect to an equivalent nondeterministic one. A fortiori the complexity of the de-
terminization algorithm in the weighted case we just described is also exponential.
However, in some cases in which the degree of nondeterminism of the initial trans-
ducer is high, the determinization algorithm turns out to be fast and the resulting
transducer has fewer states than the initial one. We present examples of such cases,
which appear in speech recognition, in the last section. We also present a minimization
algorithm that allows the size of subsequential transducers representing power series
to be reduced.
The complexity of the application of subsequential transducers is linear in the
size of the string to which it applies. This property makes it worthwhile to use the
power series determinization to speed up the application of transducers. Not all trans-
ducers can be determinized using the power series determinization. In the following
section, we define a set of transducers that admit determinization, and characterize
unambiguous transducers that admit the application of the algorithm.
Since determinization does not apply to all transducers, it is important to be able to
test the determinizability of a transducer. We present, in the next section, an algorithm
to test this property in the case of unambiguous trim transducers.
The proofs of some of the theorems in the next two sections are complex; they can
be skipped on first reading.
</bodyText>
<subsectionHeader confidence="0.930195">
3.4 Determinizable Transducers
</subsectionHeader>
<bodyText confidence="0.999884333333333">
There are transducers with which determinization does not halt, but rather generates
an infinite number of subsets. We define determinizable transducers as those transduc-
ers with which the algorithm terminates. We first show that a large set of transducers
</bodyText>
<page confidence="0.939035">
288
</page>
<bodyText confidence="0.905608777777778">
Mohri Transducers in Language and Speech
admit determinization, then give a characterization of unambiguous transducers ad-
mitting determinization. In what follows, the states of the transducers considered will
be assumed to be accessible from the initial one.
The following lemma will be useful in the proof of the theorems.
Lemma 1
Let T = (Q, E, I, F, E, A, p) be a string-to-weight transducer, 7r E p q a path in T from
the state p E Q to q E Q, and 7r&apos; E p&apos; q&apos; a path from p&apos; E Q to q&apos; E Q both labeled
with the input string w E E*. Assume that the lengths of it and 7r&apos; are greater than
</bodyText>
<equation confidence="0.87007975">
IQI2 - 1, then there exist strings 141, u2, u3 in E*, and states pi, 192, and p&apos;2 such that
u2 &gt; 0, u1u2u3 = w and such that it and 7r&apos; be factored in the following way:
U2 143
irE/7&amp;quot;- p1
It E p&apos; ti› -1:3+
Proof
The proof is based on the use of a cross product of two transducers. Given two
transducers T1 = (Q1, E, Ei, Ai, pi) and T2 = (22, E, 12, F2, E2, A2, P2), we define
the cross product of T1 and T2 as the transducer:
T1 X T2 = (Q1 x Q2,E,11 x 12,F1 x F2, E, p)
with outputs in R.+ x &apos;R+ such that t = ((qi, q2), a, (xi, x2), (q&apos;i, I/12)) E Qi x E x &apos;R+ x x
Q2 is a transition of T1 x T2, namely t E E, iff (qi, a, xi, E Ei and (q2, a, x2, q&apos;2) E E2.
</equation>
<bodyText confidence="0.9983175">
We also define A and p by: V(ii, t2) E h x A(ii, i2) = A2(i2)), V(fj,,,f2) E Fi x
F2, P(fi,f2) -= (Pi(fi ), P2(f2)).
Consider the cross product of T with itself, T x T. Let it and 713 be two paths in T
with lengths greater than 1Q12 - 1, (m&gt; 1Q12 - 1):
</bodyText>
<equation confidence="0.99836925">
it = ((p = qo, ao, xo, qi.), • • • , (qm-i, am_i, xm-i, = q))
it = ((p&apos; = q1 0,a0, qi), • • • , (q&amp;quot;, am_i, q&apos;m = q&apos;))
then:
LI = (((q0, q&apos;o), ao, (xo, x&apos;0), qi)), , ((qm_i, (xm-1,4_1), (qm,q&amp;quot;„)))
</equation>
<bodyText confidence="0.972995">
is a path in T x T with length greater than 1Q12 - 1. Since T x T has exactly 1Q12 states,
H admits at least one cycle at some state (p1,p&apos;i) labeled with a non-empty input string
u2. This shows the existence of the factorization above and proves the lemma. 0
</bodyText>
<subsectionHeader confidence="0.332089">
Theorem 11
</subsectionHeader>
<bodyText confidence="0.910433166666667">
Let TI = (Q1, E, 111F1, Ei, Ai, p1) be a string-to-weight transducer defined on the tropical
semirirtg. If 7-1 has the twins property then it is determinizable.
Proof
Assume that 7- has the twins property. If the determinization algorithm does not halt,
there exists at least one subset of 2, {q0, , q„,}, such that the algorithm generates
an infinite number of distinct weighted subsets {(qo, c0), • • (q„„ .
</bodyText>
<page confidence="0.987545">
289
</page>
<note confidence="0.639793">
Computational Linguistics Volume 23, Number 2
</note>
<bodyText confidence="0.993974625">
Then we have necessarily m &gt; 1. Indeed, we mentioned previously that in any
subset there exists at least one state qi with a residual output c, = 0. If the subset
contains only one state go, then co = 0. So there cannot be an infinite number of
distinct subsets { (go, co )} •
Let A C E* be the set of strings w such that the states of 62(i2, w) be Iqo, • • • , 1. We
have: Vw E A, 62(i2,w) = {(q0, c(qo,w)), • • • , (qm, c(q,n,w))1 . Since A is infinite, and since
in each weighted subset there exists a null residual output, there exist io, 0 &lt; io &lt;m,
such that c(q,,„w) = 0 for an infinite number of strings w E A. Without loss of generality
we can assume that io =- 0.
Let B C A be the infinite set of strings w for which c(q0,w) = 0. Since the number
of subsets {(go, c(go, w)), • • • (qm, c(gm, w))}, w E B, is infinite, there exists], 0 &lt;j &lt; m,
such that c(qj,w) be distinct for an infinite number of strings w E B. Without loss of
generality we can assume j = 1.
Let C C B be an infinite set of strings w with c(qi,w) all distinct. Define R(qo, qi)
to be the finite set of differences of the weights of paths leading to go and gi labeled
with the same string w, &lt; IwIIQiI2-1:
</bodyText>
<equation confidence="0.9842055">
R(go,gi) = {(A(ii) + cr(7r1)) — (A(io) (7(70): 7ro E io &amp;quot;-v&gt; (10,7ri E ii-14v
io EI,ii EI,IwI &lt; IQ112
</equation>
<bodyText confidence="0.927823625">
We will show that {c(gi, w): w E C} C R(q0, qi). This will yield a contradiction with
the infinity of C, and will therefore prove that the algorithm terminates.
Let w E C, and consider a shortest path 7ro from a state 10 E I to qo labeled with
the input string w and with total cost cr(7r0). Similarly consider a shortest path in from
E Ito gi labeled with the input string w and with total cost cr(n-i). By definition of
the subset construction we have: (A(i1) + cr(71-1)) — (A(io) cr(71-0)) = c(qi,w). Assume
that w I &gt; 112112 — 1. Using the lemma 1, there exists a factorization of 7r0 and iti of the
type:
</bodyText>
<equation confidence="0.9773736">
Ui U2 U3
7ro E o &apos;&amp;quot;4 po po qo
• Ul U2 U3
7ri E qi
with 1u21 &gt; 0. Since po and pi are twins, Oi (po, u2, po) = (pi, u2,pi). Define 711) and RI
by:
• Ui U3
7ro E io Po&amp;quot;-, qo
• Ul U3
E 11 piqi
</equation>
<bodyText confidence="0.9993667">
Since in and 7T/ are shortest paths, we have: O(7n0) = o-(71-) + 01(Po, u2,po) and 0*(70 =
c(lri)±01 (pi, u2, pi). Hence: (A(ii)+0(7r)) — (.\(io)±(7(4)) = c(qi,w). By induction on
170, we can therefore find shortest paths Ho and 1-11 from 10 to qo (resp. ii to gi) with
length less or equal to l(2112 —1 and such that (A(ii)+a(111)) — (A(io)+0-(11o)) = c(ql, w).
Since c(I11) — cr(II0) E R(q0, qi), c(qi,w) E R(q0, qi) and C is finite. This ends the proof
of the theorem. 0
There are transducers that do not have the twins property and that are still de-
terminizable. To characterize such transducers, more complex conditions that we will
not describe here are required. However, in the case of trim unambiguous transducers,
the twins property provides a characterization of determinizable transducers.
</bodyText>
<page confidence="0.919903">
290
</page>
<equation confidence="0.1790715">
Mohri Transducers in Language and Speech
Theorem 12
</equation>
<bodyText confidence="0.967566357142857">
Let Ti = (Q1, E, /1, F1, Ei, Ai, Pi) be a trim unambiguous string-to-weight transducer
defined on the tropical semiring. Then Ti is determirtizable iff it has the twins property.
Proof
According to the previous theorem, if T.1 has the twins property, then it is deter-
minizable. Assume now that T does not have the twins property, then there exist at
least two states q and q&apos; in Q that are not twins. There exists (u, v) E E* such that:
({q, q&apos;} c SW, u), q E 61(q,v),q&apos; E 81(qcv)) and 01(q, v, q) 01(q&apos; ,v, q&apos;). Consider the
weighted subsets 52(i2, UVk), with k E Ai, constructed by the determinization algorithm.
A subset 62(i2, uv&amp;quot;) contains the pairs (q, c(q, uvk)) and (q&apos;, c(q&apos;, uvk)). We will show that
these subsets are all distinct. This will prove that the determinization algorithm does
not terminate if Ti does not have the twins property.
Since ri is a trim unambiguous transducer, there exits only one path in Ti from
I to q or to q&apos; with input string u. Similarly, the cycles at q and q&apos; labeled with v are
unique. Thus, there exist i E I and i&apos; E I such that:
</bodyText>
<equation confidence="0.991352571428571">
Vk E , c(q, uvk) = (i) + 01(i, u, q) + k0i(q, v, q) — uv&apos;) — A2 (18)
Vk E c(q&apos;, uv&apos;) = A1 (i&apos;) + Oi (1&apos;, u, q&apos;) + koi(q&apos; , v, q&apos;) — uv&apos;) — A2
Let A and 0 be defined by:
A = (Ai (i&apos;) — Ai (i)) + (01 (i&apos;, u, q&apos;) — u, q)) (19)
= 01(qc v, q&apos;) — 01(q, v, q)
We have:
Vk E A 1, c(q&apos;, uv&apos;) — c(q, uvk) = A + k0 (20)
</equation>
<bodyText confidence="0.991715">
Since 0 0 0, equation 20 shows that the subsets 62(i2, uv&apos;) are all distinct. 0
</bodyText>
<subsectionHeader confidence="0.99829">
3.5 Test of Determinizability
</subsectionHeader>
<bodyText confidence="0.946548714285714">
The characterization of determinizable transducers provided by theorem 12 leads to
the definition of an algorithm for testing the determinizability of trim unambiguous
transducers. Before describing the algorithm, we introduce a lemma that shows that
it suffices to examine a finite number of paths to test the twins property.
Lemma 2
Let Ti = (Qi, E, Ii, Fi, Ei, Ai, Pi) be a trim unambiguous string-to-weight transducer
defined on the tropical serniring. Ti has the twins property iff V(u, V) E (E*)2,1UVI &lt;
</bodyText>
<equation confidence="0.747370666666667">
21(2112 - 1,
({q, q&apos;} c Si (I, u), q E oi(q, v), q&apos; c Si (q&apos; , v)) 01(q, v, q) = 01(q&apos; , v, q&apos;) (21)
Proof
</equation>
<bodyText confidence="0.976784666666667">
Clearly if Ti has the twins property, then (21) holds. Conversely, we prove that if (21)
holds, then it also holds for any (u, v) E (E* )2, by induction on I uv. Our proof is
similar to that of Berstel (1979) for string-to-string transducers. Consider (u, v) E (E*)2
and (q, q&apos;) E l(2112 such that: {q, q&apos;} c I (I, u), q c 61(q, v), q&apos; E (q&apos; , v). Assume that
luvl &gt; 21(2112 — 1 with Ivl &gt; 0. Then either lul &gt;
Assume that I u I &gt; 1(21 12 - 1. Since Ti is a trim unambiguous transducer there exists
1(2112 — 1 or Iv&apos;
a unique path 7r in Ti from i E Ito q labeled with the input string u, and a unique path
&gt; 1Q112 — 1.
</bodyText>
<page confidence="0.991489">
291
</page>
<note confidence="0.64924">
Computational Linguistics Volume 23, Number 2
</note>
<bodyText confidence="0.997593">
7r&apos; from i&apos; E Ito q&apos;. In view of lemma 2, there exist strings 141, u2, u3 in E*, and states
pi, p2, p, and p12 such that I u2I &gt; 0, u1u2u3 = u and such that ir and ir&apos; be factored in
the following way:
</bodyText>
<equation confidence="0.833015666666667">
.U1 U2 7r E pi pi &amp;quot;3&gt; 9
E 4.,41+ ,t2.&gt; pfi 34 q/
Since I ui u3vI &lt; I uvl, by induction (q, v, q) = 01(q&apos; , v, g&apos;).
</equation>
<bodyText confidence="0.996831333333333">
Next, assume that lvi &gt; 1Q112 -1. Then according to lemma 1, there exist strings
v1, v2, V3 in E*, and states qi, q2, q&apos;y and q&apos;2 such that Iv2I &gt; 0, v1v2v3 = v and such that
Ir and 71-&apos; be factored in the following way:
</bodyText>
<equation confidence="0.987532888888889">
VI, V2 V3
E V qi q
7r, E ql tl* q/1 Z„,!3&gt; q/1 q/
Since iuvi v3 I uv, by induction, 01 (q, v1v3,q) = 01(q&apos;,v1v3, q&apos;). Similarly, since luv1v2I &lt;
uvl, 01(qi, v2, qi) =- (q&apos;i, v2, q&apos;i). 71 is a trim unambiguous transducer, so:
01(q, v, q) = 01(q, viv3, q) + 01(qi, v2, qi)
01(q&apos; , v, q&apos;) = 01(q&apos; , viv3, q&apos;) + 01(qi, v2, qi)
Thus, 01 (q, v, q) = 01(q&apos; , v, q&apos;). This completes the proof of the lemma. 0
Theorem 13
</equation>
<bodyText confidence="0.9391987">
Let T1 -= E1, A1,101) be a trim unambiguous string-to-weight transducer
defined on the tropical semiring. There exists an algorithm to test the determinizability
of Ti.
Proof
According to theorem 12, testing the determinizability of TI is equivalent to testing for
the twins property We define an algorithm to test this property Our algorithm is close
to that of Weber and Klemm (1995) for testing the sequentiability of string-to-string
transducers. It is based on the construction of an automaton A = (Q, I, F, E) similar to
the cross product of Ti with itself.
Let K C 7?, be the finite set of real numbers defined by:
</bodyText>
<listItem confidence="0.944529333333333">
K {E(o(t) - a(t)): 1 &lt;k &lt; 21(2112 - 1,Vi &lt; k (ti„t) E
We define A by the following:
• The set of states of A is defined by Q = xQ1 x K,
• The set of initial states by I -= Ii x Ii x {0},
• The set of final states by F = F1 x F1 x K,
• The set of transitions by:
</listItem>
<equation confidence="0.942872">
E = {((q1,q2, c), a, (qii, q&apos;2, c&apos; )) EQx E x Q:
</equation>
<page confidence="0.716567">
3 (qi, a, x, q2) E Ei, (qi, a, x&apos; (I) E Ei, - c = - XI.
292
</page>
<bodyText confidence="0.9480695">
Mohri Transducers in Language and Speech
By construction, two states qi and q2 of Q can be reached by the same string u, lul &lt;
21(2112 — 1, if there exists c E K such that (qi, q2, c) can be reached from / in A. The set
of such (qi, q2, c) is exactly the transitive closure of I in A. The transitive closure of I
can be determined in time linear in the size of A, 0(1(21 + I E I).
Two such states qi and q2 are not twins if there exists a path in A from (eh, q2, 0) to
(qi, q2, c), with c 0. Indeed, this is exactly equivalent to the existence of cycles at qi
and q2 with the same input label and distinct output weights. According to lemma 2,
it suffices to test the twins property for strings of length less than 21(2112 — 1. So the
following gives an algorithm to test the twins property of a transducer
</bodyText>
<listItem confidence="0.99272425">
1. Compute the transitive closure of I: T(I).
2. Determine the set of pairs (qi, q2) of T(I) with distinct states qi q2.
3. For each such { qi, q2}, compute the transitive closure of (qi, q2, 0) in A. If
it contains (qi, q2, c) with c 0, then Ti does not have the twins property
</listItem>
<bodyText confidence="0.996281411764706">
The operations used in the algorithm (computation of the transitive closure, determi-
nation of the set of states) can all be done in polynomial time with respect to the size
of A, using classical algorithms (Aho, Hoperoft, and Ullman 1974). 0
This provides an algorithm for testing the twins property of an unambiguous trim
transducer T. It is very useful when T is known to be unambiguous.
In many practical cases, the transducer one wishes to determinize is ambiguous.
It is always possible to construct an unambiguous transducer T&apos; from T (Eilenberg
1974-1976). The complexity of such a construction is exponential in the worst case.
Thus the overall complexity of the test of determinizability is also exponential in the
worst case.
Notice that if one wishes to construct the result of the determinization of T for a
given input string w, one does not need to expand the whole result of the determiniza-
tion, but only the necessary part of the determinized transducer. When restricted to
a finite set the function realized by any transducer is subsequentiable, since it has
bounded variation.&apos; Acyclic transducers have the twins property, so they are deter-
minizable. Therefore, it is always possible to expand the result of the determinization
algorithm for a finite set of input strings, even if T is not determinizable.
</bodyText>
<subsectionHeader confidence="0.991408">
3.6 Determinization in Other Semirings
</subsectionHeader>
<bodyText confidence="0.999754">
The determinization algorithm that we previously presented applies as well to trans-
ducers mapping strings to other semirings. We gave the pseudocode of the algorithm
in the general case. The algorithm applies for instance to the real semiring (R,,+,., 0,1).
One can also verify that (E*Uf oo}, A, oo, f), where A denotes the longest common
prefix operation and • concatenation, oo a new element such that for any string w E
(E*U fool), WA oo = co A w = w and w oo oo • w = oo, defines a left semiring.&apos; We
call this semiring the string semiring. The algorithm of Figure 10 used with the string
semiring is exactly the determinization algorithm for subsequentiable string-to-string
transducers, as defined by Mohri (1994c). The cross product of two semirings defines
a semiring. The algorithm also applies when the semiring is the cross product of
</bodyText>
<footnote confidence="0.950786">
9 Using the proof of the theorem of the previous section, it is easy to convince oneself that this assertion
can be generalized to any rational subset Y of E* such that the restriction of S, the function T realizes,
to Y has bounded variation.
</footnote>
<page confidence="0.95041">
10 A left semiring is a semiring that may lack right distributivity.
293
</page>
<figure confidence="0.83283975">
Computational Linguistics Volume 23, Number 2
a:b/3
Figure 13
Transducer Ti with outputs in E* x R.
</figure>
<figureCaption confidence="0.932314">
Figure 14
</figureCaption>
<bodyText confidence="0.892521">
Sequential transducer 72 with outputs in E* x R obtained from (31 by determinization.
(E* U fool, A, oo, €) and (R+ U { oo }, min, +, 00, 0), which allows transducers outputting
pairs of strings and weights to be determined. The determirtization algorithm for such
transducers is illustrated in Figures 13 and 14. Subsets in this algorithm are made of
triples (q, w, x) E Q x E* U { oo} x R. U foo}, where q is a state of the initial transducer,
w a residual string, and x a residual output weight.
</bodyText>
<subsectionHeader confidence="0.983214">
3.7 Minimization
</subsectionHeader>
<bodyText confidence="0.90742025">
We here define a minimization algorithm for subsequential power series defined on
the tropical semiring, which extends the algorithm defined by Mohri (1994b) in the
case of string-to-string transducers. For any subset L of E* and any string u we define
it-lL by:
</bodyText>
<equation confidence="0.981777833333333">
uL = {W: uW E Ll (22)
Recall that L is a regular language if there exists a finite number of distinct tt-
Nerode (1958). In a similar way, given a power series S we define a new power series
14-1S by:11
u-is = E (s,uw)w (23)
wEE.
</equation>
<bodyText confidence="0.459462333333333">
11 One can prove that S. a power series defined on a field, is rational if it admits a finite number of
independent u-1S (Carlyle and Paz 1971). This is the equivalent, for power series, of Nerode&apos;s theorem
for regular languages.
</bodyText>
<page confidence="0.982633">
294
</page>
<bodyText confidence="0.675932">
Mohri Transducers in Language and Speech
For any subsequential power series S we can now define the following relation on E*:
</bodyText>
<equation confidence="0.9782705">
`Au, V) E E*, u Rs v &lt; &gt; k E 7Z, (u-1 supp(S) = v-1 supp(S)) and
au-1 S - V-1 Si /u—tsupp(S) = k) (24)
</equation>
<bodyText confidence="0.998794666666667">
It is easy to show that Rs is an equivalence relation. (u-1 supp(S) = supp(S)) defines
the equivalence relation for regular languages. Rs is a finer relation. The additional
condition in the definition of Rs is that the restriction of the power series [14-1S - v-1S]
to u-1 supp(S) = supp(S) is constant. The following lemma shows that if there exists
a subsequential transducer T computing S with a number of states equal to the number
of equivalence classes of Rs, then T is a minimal transducer computing f.
</bodyText>
<subsectionHeader confidence="0.500599">
Lemma 3
</subsectionHeader>
<bodyText confidence="0.972760666666666">
If S is a subsequential power series defined on the tropical semiring, Rs has a finite
number of equivalence classes. This number is bounded by the number of states of
any subsequential transducer realizing S.
</bodyText>
<equation confidence="0.853896714285714">
Proof
Let T = (Q, i, F, E, 6,0, A, p) be a subsequential transducer realizing S. Clearly,
V(u, v) E (E*)2, 6(i, u) = (5(i, v) = Vw E supp(S), S(i, uw) E F &lt;#. vw) E F
.#&gt; u- supp(S) = v- supp(S)
Also, if u-1 supp(S) = supp(S), V (u, v) E (E*)2,
6(i, u) = 6(i, v) = Vw E u-1 supp(S), (S, uw) - (S, vw) = o-(i, u) - a (i, v)
&lt;=&gt; [u-1S - v-1 S] iu-isupp(s) = a (i, u) - a (i, v)
</equation>
<bodyText confidence="0.977924666666667">
So V(u, v) E (E*)2, 6(i, u) = 6(i, v) = (uRsv). This proves the lemma. 0
The following theorem proves the existence of a minimal subsequential transducer
representing S.
</bodyText>
<subsectionHeader confidence="0.903124">
Theorem 14
</subsectionHeader>
<bodyText confidence="0.9980845">
For any subsequential function S, there exists a minimal subsequential transducer
computing it. Its number of states is equal to the index of R.
</bodyText>
<subsectionHeader confidence="0.898397">
Proof
</subsectionHeader>
<bodyText confidence="0.978239">
Given a subsequential power series S, we define a power series f by:
</bodyText>
<equation confidence="0.866966">
Vu E E*: u-1 supp(S) = 0, (f, u) =
Vu E E*: u-1 supp(S) 0, (f, u) = min (S, uw)
wEu—lsupp(S)
</equation>
<bodyText confidence="0.993443">
We then define a subsequential transducer T = (Q, i, F, E, 6,a, A, p) by:12
</bodyText>
<listItem confidence="0.988477">
• Q = {u: u E E*};
</listItem>
<footnote confidence="0.322282">
12 We denote by ü the equivalence class of u E E*.
</footnote>
<page confidence="0.989008">
295
</page>
<note confidence="0.440684">
Computational Linguistics Volume 23, Number 2
</note>
<listItem confidence="0.9935925">
• i=;
• F =_ {u: U E E* n supp(s)};
• Vu E E*, Va E E, 6(ii, a) = iia;
• Vu E Va E E, cr(ii, a) = (f , ua) - (f ,u);
•
• V q E Q, p(q) = O.
</listItem>
<bodyText confidence="0.7668252">
Since the index of Rs is finite, Q and F are well-defined. The definition of 6 does
not depend on the choice of the element u in U, since for any a E E, u Rs v implies
(ua) Rs (va). The definition of a is also independent of this choice, since by definition
of Rs, if uRsv, then (ua) Rs (va) and there exists k E R. such that Vw E E*, (S, uaw) -
(S. yaw) = (S, uw) - (S, vw) = k. Notice that the definition of a implies that:
</bodyText>
<equation confidence="0.997436125">
VW E E*, o-(i, w) = (f ,w) -(f, e) (25)
So:
VW E supp(S), A + cr(i,w) + p(q) = (f ,w) = min (S, ww1)
w,Ew-lsupp(S)
S is subsequential, hence: VW/ E w-lsupp(S), (S, ww&apos;) &lt; (S. w). Since VW E supp(S), E E
w-1 supp (S), we have:
min (S, ww&apos;) = (S, W)
w&apos;Ew—lsupp(S)
</equation>
<bodyText confidence="0.942374">
T realizes S. This ends the proof of the theorem. 0
Given a subsequential transducer T = (Q, i,F , E, 6, a, A, p), we can define for each
state q E Q, d(q) by:
</bodyText>
<equation confidence="0.765359666666667">
d(q) = min (o-(q,w) + p(6(q,w))) (26)
b(q,w)EF
Definition
</equation>
<bodyText confidence="0.99951825">
We define a new operation of pushing, which applies to any transducer T. In partic-
ular, if T is subsequential the result of the application of pushing to T is a new
subsequential transducer T&apos; = (Q, i,F , E, 6, , A&apos;, p&apos;) that only differs from T by its
output weights in the following way:
</bodyText>
<listItem confidence="0.999816333333333">
• A&apos; = A + d(i);
• V (q, a) E Q x E, (q, a) = o-(q , a) + d(6(q, a)) - d(q);
• V q E Q, (q) = O.
</listItem>
<bodyText confidence="0.635904">
According to the definition of d, we have:
</bodyText>
<equation confidence="0.831011">
Vw E E*: 6(q, aw) E F , d(q) &lt; o-(q, a) + c r (6 (q, a), w) + p(6(6(q, a), w))
This implies that:
d(q) &lt; (q, a) + d(6(q, a))
So, a&apos; is well-defined:
V (q , a) E Q x E, (q, a) ? 0
</equation>
<page confidence="0.858887">
296
</page>
<bodyText confidence="0.7226335">
Mohri Transducers in Language and Speech
Lemma 4
Let T&apos; be the transducer obtained from T by pushing. T&apos; is a subsequential transducer
which realizes the same function as T.
</bodyText>
<equation confidence="0.9903376">
Proof
That T&apos; is subsequential follows immediately its definition. Also,
VW E E*,q E Q, (q, w) = a(q,w) + d(o(q,w)) —d(q)
Since 6(i, w) E F = d(S(i,w)) = p(S(i,w)), we have:
A&apos; + (i, w) + (6(i, w)) = A + d(i) + a(q, w) + p(o(i,w)) — d(i) + 0
</equation>
<bodyText confidence="0.9975085">
This proves the lemma. 0
The following theorem defines the minimization algorithm.
</bodyText>
<subsectionHeader confidence="0.467415">
Theorem 15
</subsectionHeader>
<bodyText confidence="0.999373">
Let T be a subsequential transducer realizing a power series on the tropical semiring.
Then applying the following two operations:
</bodyText>
<listItem confidence="0.9946305">
1. pushing
2. automata minimization
</listItem>
<bodyText confidence="0.998432476190476">
leads to a minimal transducer. This minimal transducer is exactly the one defined in
the proof of theorem 14.
The automata minimization step in the theorem consists of considering pairs of
input labels and associated weights as a single label and of applying classical mini-
mization algorithms for automata (Aho, Hoperoft, and Ullman 1974). We do not give
the proof of the theorem; it can be proved in a way similar to what is indicated in
Mohri (1994b).
In general, there are several distinct minimal subsequential transducers realizing
the same function. Pushing introduces an equivalence relation on minimal transduc-
ers: T Rp T&apos; if p(T) -= p(T&apos;), where p(T) (resp. p(T&apos;)) denotes the transducer obtained
from T (resp. T&apos;) by pushing. Indeed, if T and T&apos; are minimal transducers realizing
the same function, then p(T) and p(T&apos;) are both equal to the unique minimal trans-
ducer equivalent to T and T&apos; as defined in theorem 14. So, two equivalent minimal
transducers only differ by their output labels, they have the same topology. They only
differ by the way the output weights are spread along the paths.
Notice that if we introduce a new super final state 43 to which each final state q
is connected by a transition of weight p(q), then d(q) in the definition of T&apos; is exactly
the length of a shortest path from .11 to q. Thus, T&apos; can be obtained from T using
the classical single-source shortest paths algorithms such as that of Dijkstra (Cormen,
Leiserson, and Rivest 1992).13 lit case the transducer is acyclic, a classical linear time
algorithm based on a topological sort of the graph allows one to obtain d.
</bodyText>
<footnote confidence="0.8463495">
13 This algorithm can be extended to the case where weights are negative. If there is no negative cycle the
Bellman-Ford algorithm can be used.
</footnote>
<page confidence="0.985831">
297
</page>
<figure confidence="0.592246">
Computational Linguistics Volume 23, Number 2
</figure>
<figureCaption confidence="0.945525333333333">
Figure 15
Transducer ,31.
Figure 16
</figureCaption>
<subsectionHeader confidence="0.38133">
Transducer yi obtained from by pushing.
</subsectionHeader>
<bodyText confidence="0.982885894736842">
Once the function d is defined, the transformation of T into T&apos; can be done in linear
time, namely 0(1(21+IED, if we denote by E the set of transitions of T. The complexity of
pushing is therefore linear (0(1Q1+1E1)) if the transducer is acyclic. In the general case,
the complexity of pushing is 0(1Ellog IQ&apos;) if we use classical heaps, 0(1E1 + IQ&apos; log 1 (21 )
if we use Fibonacci heaps, and 0(1Ellog log IQ) if we use the efficient implementation
of priority queues by Thorup (1996). In case the maximum output weight W is small,
we can use the algorithm of Ahuja et al. (1988); the complexity of pushing is then
0(1E1+ 1(21-0w1).
In case the transducer is acyclic, we can use a specific automata minimization
algorithm (Revuz 1992) with linear time complexity, 0(1(21 + 1E1). In the general case,
an efficient implementation of Hoperoft&apos;s algorithm (Aho, Hoperoft, and Ullman 1974)
leads to 0(1ElloglQ1).
Thus, the overall complexity of the minimization of subsequential transducers is
always as good as that of classical automata minimization: 0(1(21 + 1El) in the acyclic
case, and 0(1Ellog1Q1) in the general case.
Figures 15 to 17 illustrate the minimization algorithm. 31 (Figure 15) represents a
subsequential string-to-weight transducer. Notice that the size of )31 cannot be reduced
using the automata minimization. represents the transducer obtained by pushing,
and Si a minimal transducer realizing the same function as 31 in the tropical semiring.
</bodyText>
<page confidence="0.989299">
298
</page>
<figure confidence="0.417809">
Mohri Transducers in Language and Speech
d/O
</figure>
<figureCaption confidence="0.884206">
Figure 17
</figureCaption>
<bodyText confidence="0.935540111111111">
Minimal transducer 61 obtained from 71 by automata minimization.
The transducer obtained by this algorithm is the one defined in the proof of the-
orem 14 and has the minimal number of states. This raises the question of whether
there exists a subsequential transducer with the minimal number of transitions and
computing the same function as a given subsequential transducer T. The following
corollary offers an answer.
Corollary 1
A minimal subsequential transducer has also the minimal number of transitions among
all subsequential transducers realizing the same function.
</bodyText>
<subsectionHeader confidence="0.585373">
Proof
</subsectionHeader>
<bodyText confidence="0.954489538461539">
This generalizes the analogous theorem that holds in the case of automata. The proof
is similar. Let T be a subsequential transducer with a minimal number of transitions.
Clearly, pushing does not change the number of transitions of T and automatan mini-
mization, which consists of merging equivalent states, reduces or does not change this
number. Thus, the number of transitions of the minimal transducer equivalent to T
as previously defined is less or equal to that of T. This proves the corollary since, as
previously pointed out, equivalent minimal transducers all have the same topology:
in particular, they have the same number of states and transitions.
Given two subsequential transducers, one might wish to test their equivalence.
The importance of this problem was pointed out by Hoperoft and Ullman (1979, 284).
The following corollary addresses this question.
Corollary 2
There exists an algorithm to determine if two subsequential transducers are equivalent.
</bodyText>
<subsectionHeader confidence="0.63715">
Proof
</subsectionHeader>
<bodyText confidence="0.998380285714286">
The algorithm of theorem 15 associates a unique minimal transducer to each sub-
sequential transducer T. More precisely, this minimal transducer is unique up to a
renumbering of the states. The identity of two subsequential transducers with differ-
ent numbering of states can be tested in the same way as that of two deterministic
automata; for instance, by testing the equivalence of the automata and the equality
of their number of states. An efficient algorithm for testing the equivalence of two
deterministic automata is given in Aho, Hoperoft, and Ullman (1974).14 Since the min-
</bodyText>
<footnote confidence="0.675285">
14 The automata minimization step can in fact be omitted if this equivalence algorithm is used, since it
does not affect the equivalence of the two subsequential transducers, considered as automata.
</footnote>
<page confidence="0.99157">
299
</page>
<note confidence="0.732483">
Computational Linguistics Volume 23, Number 2
</note>
<bodyText confidence="0.998126142857143">
imization of subsequential transducers was also shown to be efficient, this proves the
corollary and also the efficiency of the test of equivalence. 0
Schiitzenberger (1961) gave an algorithm for minimizing the representation of
power series, but this algorithm can only be used when the semiring considered is a
field. In particular, it cannot be used with the tropical semiring or the string semir-
ing used in language and speech processing, since none of these semirings is a field.
More precisely, a recent result of Krob (1994) states that such a minimization cannot
be defined for transducers defined on the tropical semiring. Furthermore, we imple-
mented the algorithm of Schatzenberger (1961) and used it in the case of the semiring
(R., +, 0,1). It has two important disadvantages in practice: it creates many transi-
tions, and it can generate transitions with negative weights, even if the initial machine
has none. The negative weights cannot be interpreted in terms of probability.
In the next section, we describe some of the applications to speech recognition of
the algorithms we presented above.
</bodyText>
<sectionHeader confidence="0.797794" genericHeader="method">
4. Application to Speech Recognition
</sectionHeader>
<bodyText confidence="0.99996">
In previous sections, we gave a theoretical description of the determinization and
minimization algorithms for string-to-weight transducers. Here we indicate their use
in practice. These algorithms have interesting applications in speech recognition, some
of which we briefly point out below.
</bodyText>
<subsectionHeader confidence="0.995317">
4.1 Speech Recognition with Finite-State Transducers
</subsectionHeader>
<bodyText confidence="0.99679668">
String-to-weight transducers are found at several stages of speech recognition. Phone
lattices, language models, and word lattices are typically represented by such trans-
ducers. Weights in these graphs correspond to negative logarithms of probabilities.
They are added along a path. For a given string, there might be many different paths
in a transducer. Only the minimum of the total weights of these paths is considered
relevant. Thus, the main operations involved in the interpretation of these transducers
are addition and min, namely those of the tropical semiring. Thus, the algorithms we
defined in the previous sections apply to speech recognition.
The domain of the speech recognition systems above signal processing can be
represented by a composition of finite-state transducers outputting weights, or both
strings and weights (Pereira and Riley 1996; Mohri, Pereira, and Riley 1996):
GoL 0 Co A 0
where 0 represents the acoustic observations, A the acoustic model mapping sequences
of acoustic observations to context-dependent phones, C the context-dependency model
mapping sequences of context-dependent phones to (context-independent) phones, L
a pronunciation dictionary mapping sequences of phones to words, and G a language
model or grammar mapping sequences of words to sentences.
In general, this cascade of compositions cannot be explicitly expanded, because of
the large size of the compositions; an approximation method is required to search it.
Often, a beam pruning is used: only paths with weights within the beam (the differ-
ence of the weights from the minimum weight so far is less than a certain predefined
threshold) are kept during the expansion of the cascade of composition. Furthermore,
only the best path or a set of paths of the cascade of transducers with the lowest
weights is of interest.
A set of paths with the lowest weights can be represented by an acyclic string-to-
</bodyText>
<page confidence="0.969587">
300
</page>
<note confidence="0.413464">
Mohri Transducers in Language and Speech
</note>
<bodyText confidence="0.99973275">
weight transducer, each path of which corresponds to a sentence. The weight of the
path can be interpreted as a negative log of the probability of that sentence given the
sequence of acoustic observations (utterance). Such acyclic string-to-weight transduc-
ers are called word lattices.
</bodyText>
<subsectionHeader confidence="0.999864">
4.2 Word Lattices
</subsectionHeader>
<bodyText confidence="0.999868">
For a given utterance, the word lattice obtained in such a way contains many paths
labeled with the possible sentences and their associated weights. A word lattice often
contains a lot of redundancy: many paths correspond to the same sentence but with
different weights.
Word lattices can be directly searched to find the most probable sentences, those
which correspond to the best paths, the paths with the smallest weights.
Figure 18 shows a word lattice obtained in speech recognition for the 2,000-word
ARPA ATIS Task. It corresponds to the following utterance: Which flights leave Detroit
and arrive at Saint Petersburg around nine am? Clearly the lattice is complex; it contains
about 83 million paths.
Usually, it is not enough to consider the best path of a word lattice. It is also
necessary to correct the best path approximation by considering the n best paths,
where the value of n depends on the task considered. Notice that in case n is very
large, one would need to consider, for the lattice in Figure 18, all 83 million paths. The
transducer contains 106 states and 359 transitions.
Determinization applies to this lattice. The resulting transducer W2 (Figure 19) is
sparser. Recall that it is equivalent to W1, realizing exactly the same function mapping
strings to weights. For a given sentence s recognized by WI, there are many different
paths with different total weights. W2 contains a path labeled with s and with a total
weight equal to the minimum of the weights of the paths of W1. Let us insist on the
fact that no pruning, heuristic, or approximation has been used here. The lattice W2
only contains 18 paths. Obviously, the search stage in speech recognition is greatly
simplified when applied to W2 rather than Wi. W2 admits 38 states and 51 transitions.
The transducer W2 can still be minimized. The minimization algorithm described
in the previous section leads to the transducer W3 shown in Figure 20. It contains 25
states and 33 transitions and of course the same number of paths as W2, 18. The effect of
minimization appears to be less important. This is because, in this case, determinization
includes a large part of the minimization by reducing the size of the first lattice. This
can be explained by the degree of nondeterminism of word lattices such as WI.&apos; Many
states can be reached by the same set of strings. These states are grouped into a single
subset during determinization.
Also, the complexity of determinization is exponential in general, but in the case
of the lattices considered in speech recognition, it is not.16 Since they contain a lot
of redundancy, the resulting lattice is smaller than the initial one. In fact, the time
complexity of determinization can be expressed in terms of the initial and resulting
lattices, W1 and W2, by 0(1E I log II(1W1I1W21)2), where I Wi I and 114,721 denote the sizes
of W1 and W2. Clearly if we restrict determinization to the cases where 1W2 I I W1 its
complexity is polynomial in terms of the size of the initial transducer I Wi I. This also
</bodyText>
<footnote confidence="0.9950845">
15 The notion of ambiguity of a finite automaton can be formalized conveniently using the tropical
semiring. Many important studies of the degree of ambiguity of automata have been done in
connection with the study of the properties of this semiring (Simon 1987).
16 A more specific determinization can be used in the cases often encountered in natural language
processing where the graph admits a loop at the initial state over the elements of the alphabet (Mohri
1995).
</footnote>
<page confidence="0.991852">
301
</page>
<figure confidence="0.6728725">
Computational Linguistics Volume 23, Number 2
411.11111111&amp;quot;0-`0
</figure>
<footnote confidence="0.578743333333333">
Figure 18
Word lattice W1, ATIS task, for the utterance Which flights leave Detroit and arrive at Saint
Petersburg around nine a.m.?
</footnote>
<page confidence="0.987406">
302
</page>
<figure confidence="0.7658115">
Mohri Transducers in Language and Speech
Figure 19
Equivalent word lattice W2 obtained by detenninization of W1.
Figure 20
Equivalent word lattice W3 obtained by minimization from W2.
rescoring
</figure>
<figureCaption confidence="0.843809">
Figure 21
Rescoring.
</figureCaption>
<bodyText confidence="0.998048578947369">
applies to the space complexity of the algorithm. In practice, the algorithm appears to
be very efficient. As an example, it took about 0.02s on a Silicon Graphics (Indy 100
MHZ Processor, 64 Mb RAM) to determinize the transducer of Figure 18.1&apos;
Determinization makes the use of lattices much faster. Since at any state there
exists at most one transition labeled with the word considered, finding the weight
associated with a sentence does not depend on the size of the lattice. The time and
space complexity of such an operation is simply linear in the size of the sentence.
When dealing with large tasks, most speech recognition systems use a rescoring
method (Figure 21). This consists of first using a simple acoustic and grammar model
to produce a word lattice, and then to reevaluate this word lattice with a more sophis-
ticated model.
The size of the word lattice is then a critical parameter in the time and space
efficiency of the system. The determinization and minimization algorithms we pre-
sented allow the size of such word lattices to be considerably reduced, as seen in the
examples.
We experimented with both determinization and minimization algorithms in the
ATIS task. Table 1 illustrates these results. It shows these algorithms to be very effective
in reducing the redundancy of speech networks in this task. The reduction is also
illustrated by an example in the ATIS task.
</bodyText>
<page confidence="0.555686">
17 Part of this time corresponds to I/O&apos;s and is therefore independent of the algorithm.
</page>
<figure confidence="0.997075625">
_10... approximate
lattice
--------A
detailed
models
-1 cheap
models
—OD-
</figure>
<page confidence="0.939623">
303
</page>
<note confidence="0.560844">
Computational Linguistics Volume 23, Number 2
</note>
<tableCaption confidence="0.988532">
Table 1
</tableCaption>
<table confidence="0.978454333333333">
Word lattices in the AT1S task.
Determinization Determinization + Minimization
Objects reduction factor reduction factor
States
Transitions Re, 9 :Re, 17
Paths &gt; 232 &gt; 232
</table>
<tableCaption confidence="0.992396">
Table 2
</tableCaption>
<table confidence="0.9374216">
Subsequential word lattices in the NAB task.
Minimization results
Objects reduction factor
States 4
Transitions --ze, 3
Example 1
Example of a word lattice in the ATIS task.
States: 187 -4 37
Transitions: 993 59
Paths: &gt; 232 6,993
</table>
<bodyText confidence="0.9993326">
The number of paths of the word lattice before determinization was larger than that
of the largest integer representable with 32 bit machines. We also experimented with
the minimization algorithm by applying it to several word lattices obtained in the
60,000-word ARPA North American Business News task (NAB).
These lattices were already determinized. Table 2 shows the average reduction fac-
tors we obtained when using the minimization algorithms with several subsequential
lattices obtained for utterances of the NAB task. The reduction factors help to mea-
sure the gain of minimization alone, since the lattices are already subsequential. The
numbers in example 2, an example of reduction we obtained, correspond to a typical
case.
</bodyText>
<table confidence="0.81176825">
Example 2
Example of a word lattice in NAB task.
Transitions: 10,8211 —&gt; 37,563
States: 10,407 -4 2,553
</table>
<subsectionHeader confidence="0.991087">
4.3 On-the-fly Implementation of Determinization
</subsectionHeader>
<bodyText confidence="0.9999505">
An important characteristic of the determinization algorithm is that it can be used
on-the-fly. Indeed, the determinization algorithm is such that given a subset repre-
senting a state of the resulting transducer, the definition of the transitions leaving that
state depends only on that state or, equivalently, on the states of that subset, and on
the transducer to determinize. In particular, the definition and construction of these
transitions do not depend directly on the previous subsets constructed.
We have produced an implementation of the determinization that allows one both
to completely expand the result or to expand it on demand. Arcs leaving a state of
</bodyText>
<page confidence="0.988555">
304
</page>
<bodyText confidence="0.958826384615385">
Mohri Transducers in Language and Speech
the determinized transducer are expanded only if necessary This characteristic of the
implementation is important. It can then be used, for instance, at any step in an on-
the-fly cascade of composition of transducers in speech recognition to expand only
the necessary part of a lattice or transducer (Pereira and Riley 1996; Mohri, Pereira,
and Riley 1996). One of the essential implications of the implementation is that it
contributes to saving space during the search stage. It is also very useful in speeding
up the n-best decoder in speech recognition.&apos;
The determinization and minimization algorithms for string-to-weight transducers
seem to have other applications in speech processing. Many new experiments can be
done using these algorithms at different stages of speech recognition, which might
lead to the reshaping of some of the methods used in this field and create a renewed
interest in the theory of automata and transducers.
</bodyText>
<sectionHeader confidence="0.998196" genericHeader="method">
5. Conclusion
</sectionHeader>
<bodyText confidence="0.999976909090909">
We have briefly presented the theoretical bases, algorithmic tools, and practical use of
a set of devices that seem to fit the complexity of language and provide efficiency in
space and time. From the theoretical point of view, the understanding of these objects
is crucial. It helps to describe the possibilities they offer and to guide algorithmic
choices. Many new theoretical issues arise when more precision is sought.
The notion of determinization can be generalized to that of E-determinization for
instance (Salomaa and Soittola 1978, chapter 3, exercise) requiring more general al-
gorithms. It can also be extended to local determinization: determinization at only
those states of a transducer that admit a predefined property, such as that of having
a large number of outgoing transitions. An important advantage of local determiniza-
tion is that it can be applied to any transducer without restriction. Furthermore, local
determinization also admits an on-the-fly implementation. New characterizations of
rational functions shed new light on some aspects of the theory of finite-state trans-
ducers (Reutenauer and Schiitzenberger 1995). We have also offered a generalization of
the operations we use based on the notions of semiring and power series, which help
to simplify problems and algorithms used in various cases. In particular, the string
semirirtg that we introduced makes it conceptually easier to describe many algorithms
and properties.
Subsequential transducers admit very efficient algorithms. The determinization
and minimization algorithms in the case of string-to-weight transducers presented
here complete a large series of algorithms that have been shown to give remarkable
results in natural language processing. Sequential machines lead to useful algorithms
in many other areas of computational linguistics. In particular, subsequential power
series allow for efficient results in indexation of natural language texts (Crochemore
1986; Mohri 1996b).
We briefly illustrated the application of these algorithms to speech recognition.
More precision in acoustic modeling, finer language models, large lexicon grammars,
and a larger vocabulary will lead, in the near future, to networks of much larger sizes
in speech recognition. The determinization and minimization algorithms might help
to limit the size of these networks while maintaining their time efficiency.
These algorithms can also be used in text-to-speech synthesis. In fact, the same
operations of composition of transducers (Sproat 1995) and perhaps more important
size issues can be found in this field.
</bodyText>
<page confidence="0.679484">
18 We describe this application of determinization elsewhere.
305
</page>
<figure confidence="0.643935">
Computational Linguistics Volume 23, Number 2
</figure>
<figureCaption confidence="0.877375">
Figure 22
</figureCaption>
<bodyText confidence="0.749416">
Subsequential power series S nonbisubsequential.
</bodyText>
<sectionHeader confidence="0.987146" genericHeader="conclusions">
Appendix
</sectionHeader>
<bodyText confidence="0.965069857142857">
The determinization algorithm for power series can also be used to minimize trans-
ducers in many cases. Let us first consider the case of automata. Brzozowski (1962)
showed that determinization can be used to minimize automata. This nice result has
also been proved more recently in elegant papers by Bauer (1988) and Urbanek (1989).
These authors refine the method to obtain better complexities.19
Theorem 16 (Brzozowski 1962)
Let A be a nondeterministic automaton. Then the automaton A&apos; = (Q&apos;, i&apos;,F&apos;,E,6&apos;) ob-
tained by reversing A, applying determinization, rereversing the obtained automaton
and determiruizing it is the minimal deterministic automaton equivalent to A.
We generalize this theorem to the case of string-to-weight transducers. We say that
a rational power series S is bisubsequential when S is subsequential and the power
series SR = EwEE. (5, wR)w is also subsequential.&apos; Not all subsequential transducers
are bisubsequential. Figure 22 shows a transducer representing a power series S that
is not bisubsequential. S is such that:
</bodyText>
<equation confidence="0.987447">
Vn E JV, (S , ban) = n +1 (27)
Vn E Ar, (s,can) = 0
</equation>
<bodyText confidence="0.998315">
The transducer of Figure 22 is subsequential so S is subsequential. But the reverse SR
is not, because it does not have bounded variation. Indeed, since:
</bodyText>
<equation confidence="0.7504415">
Vn Ef , (SR , an b) = n + 1 (28)
Vn E (SR, anC) = 0
</equation>
<bodyText confidence="0.3758025">
We have:
Vn E AT , l(SR , a&amp;quot; b) — (SR , an c)I = n +1
</bodyText>
<note confidence="0.392074666666667">
19 See Watson (1993) for a taxonomy of minimization algorithms for automata; see also Courcelle,
Niwinsld, and Podelski 1991.
20 For any string w E E*, we denote by wR its reverse.
</note>
<page confidence="0.994078">
306
</page>
<bodyText confidence="0.923049857142857">
Mohri Transducers in Language and Speech
A characterization similar to that of string-to-string transducers (Choffrut 1978) is
possible for bisubsequential power series defined on the tropical semiring. In particu-
lar, the theorem of the previous sections shows that S is bisubsequential if S and SR
have bounded variation.
We similarly define bideterminizable transducers as the transducers T defined on
the tropical semiring admitting two applications of determinization, as follows:
</bodyText>
<listItem confidence="0.7914225">
1. The reverse of T, TR can be determinized. We denote by det(TR) the
resulting transducer.
2. The reverse of det(TR), [det(TR)]R can also be determinized. We denote by
det(Pet(TR)JR) the resulting transducer.
</listItem>
<bodyText confidence="0.889519">
In this definition, we assume that the reverse operation is performed simply by
reversing the direction of the transitions and exchanging initial and final states. Given
this definition, we can present the extension of the theorem of Brzozowski (1962) to
bideterminizable transducers.21
Theorem 17
Let T be a bideterminizable transducer defined on the tropical semiring. Then the trans-
ducer det(klet(TR)r) obtained by reversing T, applying determinization, rereversing
the obtained transducer and determinizing it is a minimal subsequential transducer
equivalent to T.
Proof
We denote by:
</bodyText>
<listItem confidence="0.98013775">
• T1 = E, cri, Ai, det(TR),
• T&apos; = (Q&apos;,i&apos; ,F&apos;, E, , a&apos;, A&apos;, p&apos;) detUdet(TR)1R)
• T&amp;quot; = (Q&amp;quot;,i&amp;quot;,F&amp;quot;, E, 6&amp;quot;, a&amp;quot;, A&amp;quot;, p&amp;quot;) the transducer obtained from T by
pushing.
</listItem>
<bodyText confidence="0.989331411764706">
The double reverse and determinization algorithms clearly do not change the function
that T realizes. So T&apos; is a subsequential transducer equivalent to T. We only need to
prove that T&apos; is minimal. This is equivalent to showing that T&amp;quot; is minimal, since T&apos;
and T&amp;quot; have the same number of states. Ti is the result of a determinization, hence
it is a trim subsequential transducer. We show that T&apos; det(n) is minimal if Ti is
a trim subsequential transducer. Notice that the theorem does not require that T be
subsequential.
Let Si and 52 be two states of T&amp;quot; equivalent in the sense of automata. We prove
that Si = Sz, namely that no two distinct states of T&amp;quot; can be merged. This will prove
that T&amp;quot; is minimal. Since pushing only affects the output labels, T&apos; and T&amp;quot; have the
same set of states: Q&apos; = Q&amp;quot;. Hence Si and S2 are also states of T&apos;. The states of T&apos;
can be viewed as weighted subsets whose state elements belong to T,, because T&apos; is
obtained by determinization of T.
Let (q, c) E Qi X R. be a pair of the subset Si. Since Ti is trim there exists w E E*
such that Si (ii, w) = q, so Si(Si, w) E F&apos;. Since Si and S2 are equivalent, we also have:
21 The theorem also holds in the case of string-to-string bideterminizable transducers. We give the proof
in the more complex case of string-to-weight transducers.
</bodyText>
<page confidence="0.97778">
307
</page>
<figure confidence="0.940717571428571">
Computational Linguistics Volume 23, Number 2
Figure 23
Transducer 02 obtained by reversing 01.
a/0
Figure 24
Transducer 03 obtained by determinization of 02.
d/0
</figure>
<figureCaption confidence="0.989624">
Figure 25
</figureCaption>
<bodyText confidence="0.9221655">
Minimal transducer 04 obtained by reversing 03 and applying determinization.
6&apos;(S2, 7.1)) E F&apos;. Since T1 is subsequential, there exists only one state of Tf admitting a
path labeled with w to ii; that state is q. Thus, q E S2. Therefore any state q member
of a pair of Si is also member of a pair of S2. By symmetry the reverse is also true.
Thus exactly the same states are members of the pairs of Si and S2. There exists k &gt; 0
such that:
</bodyText>
<equation confidence="0.995926">
Si = {(q0, c10), cii), • • • , (qk, clic)} (29)
S2 = {(qo, c20), (qi, c21), • • • (qk, c2k)1
</equation>
<bodyText confidence="0.9985455">
We prove that weights are also the same in Si and 52. Let Hy, (0 &gt; j &gt; k), be the
set of strings labeling the paths from i3 to qi in T1. cffi(ii, w) is the weight output
corresponding to a string w E R. Consider the accumulated weights c11, 1 &lt; i &lt; 2,
0 &lt;j &lt; k, in determinization of T. Each cl; for instance corresponds to the weight not
yet output in the paths reaching Si. It needs to be added to the weights of any path
from qj E S1 to a final state in rev(Ti). In other terms, the determinization algorithm
will assign the weight c + w) + Ai to a path labeled with wR reaching a final
state of T&apos; from Si. T&amp;quot; is obtained by pushing from T&apos;. Therefore the weight of such
</bodyText>
<page confidence="0.985522">
308
</page>
<figure confidence="0.4600304">
Mohri Transducers in Language and Speech
a path in T&amp;quot; is:
cli + w) + A1 — min {c11 + cri + Ail
0&lt;j&lt;k,wElli
Similarly, the weight of a path labeled with the same string considered from S2 is:
c21 + w) + A1 — min {C21 + al (ilf W) + A1}
0&lt;j&lt;k,wElli
Since S1 and S2 are equivalent in T&amp;quot; the weights of the paths from S1 or S2 to F&apos; are
equal. Thus, Vw E 11, Vi E [0, k],
+ Gri (ii, W) — min + W)/ = C21 0-1(i1. W) — min 1E[0, {c21 + cri (ii, wil
11,tvErb
Hence:
Vj E [0,/C], — min {cii = c2] — min {CA
!EPA] lE[01c
,]
</figure>
<bodyText confidence="0.959241307692308">
We noticed in the proof of the determinization theorem that the minimum weight of
the pairs of any subset is 0.
Therefore: Vj E [O. k], C11 = C21
and S2 =- S1. This ends the proof of the theorem. 0
Figures 23-25 illustrate the minimization of string-to-weight transducers using
the determinization algorithm. The transducer 02 of Figure 23 is obtained from that
of Figure 15, IA, by reversing it. The application of determinization to 02 results in
03 (Figure 24). Notice that since 01 is subsequential, according to the theorem the
transducer 03 is minimal too. 03 is then reversed and determinized (Figure 25). The
resulting transducer 04 is minimal and equivalent to 01. Comparing the transducer 04
to the transducer of Figure 17, Si, we note that both are minimal and realize the same
function. Si provides output weights as soon as possible; it can be obtained from 04
by pushing.
</bodyText>
<sectionHeader confidence="0.942172" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.942068555555556">
I thank Michael Riley, and also CL
reviewers, for their comments on earlier
versions of this paper, Fernando Pereira and
Michael Riley for discussions, Andrej Ljolje
for providing the word lattices cited herein,
Phil Terscaphen for useful advice, and
Dominique Perrin for his help in finding
references relating to the minimization of
automata by determinization.
</bodyText>
<sectionHeader confidence="0.897397" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999193321428571">
Aho, Alfred V., John E. Hoperoft, and
Jeffrey D. Ullman. 1974. The Design and
Analysis of Computer Algorithms. Addison
Wesley, Reading, MA.
Aho, Alfred V., Ravi Sethi, and Jeffrey D.
Ullman. 1986. Compilers, Principles,
Techniques and Tools. Addison Wesley,
Reading, MA.
Ahuja, Ravindra K., Kurt Mehlhorn,
James B. Orlin, and Robert Taman. 1988.
Faster algorithms for the shortest path
problem. Technical Report 193, MIT
Operations Research Center.
Bauer, W. 1988. On minimizing finite
automata. EATCS Bulletin, 35.
Berstel, Jean. 1979. Transductions and
Context-Free Languages. Teubner
Studienbucher, Stuttgart.
Berstel, Jean and Christophe Reutenauer.
1988. Rational Series and Their Languages.
Springer-Verlag, Berlin and New York.
Brzozowski, J. A. 1962. Canonical regular
expressions and minimal state graphs for
definite events. Mathematical Theory of
Automata, 12:529-561.
Carlyle, J. W. and A. Paz. 1971. Realizations
by stochastic finite automaton. Journal of
Computer and System Sciences, 5:26-40.
</reference>
<page confidence="0.980804">
309
</page>
<note confidence="0.364224">
Computational Linguistics Volume 23, Number 2
</note>
<reference confidence="0.999235627118644">
Choffrut, Christian. 1978. Contributions a
l&apos;etude de quelques families remarquables de
fonctions rationnelles. Ph.D. thesis, (these
de doctorat d&apos;Etat), Universite Paris 7,
LITP, Paris.
Cormen, T., C. Leiserson, and R. Rivest.
1992. Introduction to Algorithms. The MIT
Press, Cambridge, MA.
Courcelle, Bruno, Damian Niwinski, and
Andreas Podelsld. 1991. A geometrical
view of the determinization and
minimization of finite-state automata.
Mathematical Systems Theory, 24:117-146.
Crochemore, Maxirne. 1986. Transducers
and repetitions. Theoretical Computer
Science, 45.
Eilenberg, Samuel. 1974-1976. Automata,
Languages and Machines, volume A-B.
Academic Press.
Elgot, C. C. and J. E. Mezei. 1965. On
relations defined by generalized finite
automata. IBM Journal of Research and
Development, 9.
Ginsburg, S. and G. F. Rose. 1966. A
characterization of machine mappings.
Canadian Journal of Mathematics, 18.
Gross, Maurice. 1989. The use of finite
automata in the lexical representation of
natural language. Lecture Notes in
Computer Science, 377.
Hoperoft, John E. and Jeffrey D. Ullman.
1979. Introduction to Automata Theory,
Languages, and Computation. Addison
Wesley, Reading, MA.
Kaplan, Ronald M. and Martin Kay. 1994.
Regular models of phonological rule
systems. Computational Linguistics, 20(3).
Karlsson, Fred, Afro Voutilainen, Juha
Heikkila, and Atro Anttila. 1995.
Constraint Grammar, A Language-
Independent System for Parsing Unrestricted
Text. Mouton de Gruyter.
Karttunen, Lauri, Ronald M. Kaplan, and
Annie Zaenen. 1992. Two-level
morphology with composition. In
Proceedings of the Fifteenth International
Conference on Computational Linguistics
(COLING-92), Nantes, France. COLING.
Krob, Daniel. 1994. The equality problem
for rational series with multiplicities in
the tropical semiring is undecidable.
Journal of Algebra and Computation, 4.
Kuich, Werner and Arto Salomaa. 1986.
Semirings, Automata, Languages. EATCS
Monographs on Theoretical Computer
Science, Number 5. Springer-Verlag,
Berlin.
Mohri, Mehryar. 1994a. Compact
representations by finite-state transducers.
In Proceedings of the 32nd Annual Meeting,
Las Cruces, New Mexico. Association for
Computational Linguistics.
Mohri, Mehryar. 1994b. Minimization of
sequential transducers. Lecture Notes in
Computer Science, 807.
Mohri, Mehryar. 1994c. On some
applications of finite-state automata
theory to natural language processing:
Representation of morphological
dictionaries, compaction, and indexation.
Technical Report IGM 94-22, Institut
Gaspard Monge, Noisy-le-Grand.
Mohri, Mehryar. 1994d. Syntactic analysis
by local grammars automata: An efficient
algorithm. In Proceedings of the International
Conference on Computational Lexicography
(COMPLEX 94). Linguistic Institute,
Hungarian Academy of Science,
Budapest, Hungary.
Mohri, Mehryar. 1995. Matching patterns of
an automaton. Lecture Notes in Computer
Science, 937.
Mohri, Mehryar, 1996a. On The Use of
Sequential Transducers in Natural
Language Processing. In Yves Shabes,
editor, Finite State Devices in Natural
Language Processing. MIT Press,
Cambridge, MA. To appear.
Mohri, Mehryar. 1996b. On some
applications of finite-state automata
theory to natural language processing.
Journal of Natural Language Engineering,
2:1-20.
Mohri, Mehryar, Fernando C. N. Pereira,
and Michael Riley. 1996. Weighted
automata in text and speech processing.
In ECAI-96 Workshop, Budapest, Hungary.
ECAI.
Mohri, Mehryar and Richard Sproat. 1996.
An efficient compiler for weighted rewrite
rules. In Proceedings of the 34th Annual
Meeting, Santa Cruz, California.
Association for Computational
Linguistics.
Nerode, Anil. 1958. Linear automaton
transformations. In Proceedings of AMS,
volume 9.
Pereira, Fernando C. N. and Michael Riley,
1996. Weighted Rational Transductions
and their Application to Human
Language Processing. In Yves Shabes,
editor, Finite State Devices in Natural
Language Processing. MIT Press,
Cambridge, MA. To appear.
Perrin, Dominique. 1990. Finite automata. In
J. Van Leuwen, editor, Handbook of
Theoretical Computer Science, Volume B:
Formal Models and Semantics. Elsevier,
</reference>
<page confidence="0.951264">
310
</page>
<reference confidence="0.990125516666667">
Mohri Transducers in Language and Speech
Amsterdam, pages 1-57.
Reutenauer, Christophe and Marcel Paul
Schutzenberger. 1995. Varidt6s et
fonctions rationnelles. Theoretical Computer
Science, 145.
Revuz, Dominique. 1992. Minimisation of
acyclic deterministic automata in linear
time. Theoretical Computer Science,
92:181-189.
Roche, Emmanuel. 1993. Analyse syntaxique
transformationnelle du francais par
transducteurs et lexique-grammaire. Ph.D.
thesis, Universite Paris 7, Paris.
Salomaa, Arto and Matti Soittola. 1978.
Automata-Theoretic Aspects of Formal Power
Series. Springer-Verlag, New York.
Schiitzenberger, Marcel Paul. 1961. On the
definition of a family of automata.
Information and Control, 4.
Schiitzenberger, Marcel Paul. 1977. Sur une
variante des fonctions s6quentielles.
Theoretical Computer Science.
Schiitzenberger, Marcel Paul. 1987.
Polynomial decomposition of rational
functions. In Lecture Notes in Computer
Science, volume 386. Springer-Verlag,
Berlin, Heidelberg, and New York.
Silberztein, Max. 1993. Dictionnaires
elect roniques et analyse automatique de textes:
le systeme INTEX. Masson, Paris.
Simon, Imre. 1987. The nondeterministic
complexity of finite automata. Technical
Report RT-MAP-8073, Instituto de
Matemdtica e Estatistica da Universidade
de Sao Paulo.
Sproat, Richard. 1995. A finite-state
architecture for tokenization and
grapheme-to-phoneme conversion in
multilingual text analysis. In Proceedings of
the ACL SIGDAT Workshop, Dublin,
Ireland. ACL.
Thorup, Mikkel. 1996. On ram priority
queues. In Proceedings of SODA&apos;96,
Atlanta, Georgia. ACM, SIAM, New York.
Urbanek, F. 1989. On minimizing finite
automata. EATCS Bulletin, 39.
Watson, Bruce W. 1993. A taxonomy of
finite automata minimization algorithms.
Technical Report 93/44, Eindhoven
University of Technology, The
Netherlands.
Weber, Andreas and Reinhard Klemm. 1995.
Economy of description for single-valued
transducers. Information and Computation,
119.
Woods, W.A. 1970. Transition network
grammars for natural language analysis.
Communications of the Association for the
Computational Machinery, 13(10).
</reference>
<page confidence="0.999014">
311
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.822868">
<title confidence="0.997427">Finite-State Transducers in Language and Speech Processing</title>
<author confidence="0.844489">Mehryar Mohri</author>
<affiliation confidence="0.981021">AT&amp;T Labs-Research</affiliation>
<abstract confidence="0.9975095">Finite-state machines have been used in various domains of natural language processing. We consider here the use of a type of transducer that supports very efficient programs: sequential transducers. We recall classical theorems and give new ones characterizing sequential string-tostring transducers. Transducers that output weights also play an important role in language and speech processing. We give a specific study of string-to-weight transducers, including algorithms for determinizing and minimizing these transducers very efficiently, and characterizations of the transducers admitting determinization and the corresponding algorithms. Some applications of these algorithms in speech recognition are described and illustrated.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alfred V Aho</author>
<author>John E Hoperoft</author>
<author>Jeffrey D Ullman</author>
</authors>
<title>The Design and Analysis of Computer Algorithms.</title>
<date>1974</date>
<publisher>Addison Wesley,</publisher>
<location>Reading, MA.</location>
<marker>Aho, Hoperoft, Ullman, 1974</marker>
<rawString>Aho, Alfred V., John E. Hoperoft, and Jeffrey D. Ullman. 1974. The Design and Analysis of Computer Algorithms. Addison Wesley, Reading, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alfred V Aho</author>
<author>Ravi Sethi</author>
<author>Jeffrey D Ullman</author>
</authors>
<date>1986</date>
<booktitle>Compilers, Principles, Techniques and Tools.</booktitle>
<publisher>Addison Wesley,</publisher>
<location>Reading, MA.</location>
<marker>Aho, Sethi, Ullman, 1986</marker>
<rawString>Aho, Alfred V., Ravi Sethi, and Jeffrey D. Ullman. 1986. Compilers, Principles, Techniques and Tools. Addison Wesley, Reading, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ravindra K Ahuja</author>
<author>Kurt Mehlhorn</author>
<author>James B Orlin</author>
<author>Robert Taman</author>
</authors>
<title>Faster algorithms for the shortest path problem.</title>
<date>1988</date>
<tech>Technical Report 193,</tech>
<institution>MIT Operations Research Center.</institution>
<contexts>
<context position="71984" citStr="Ahuja et al. (1988)" startWordPosition="12971" endWordPosition="12974">Transducer yi obtained from by pushing. Once the function d is defined, the transformation of T into T&apos; can be done in linear time, namely 0(1(21+IED, if we denote by E the set of transitions of T. The complexity of pushing is therefore linear (0(1Q1+1E1)) if the transducer is acyclic. In the general case, the complexity of pushing is 0(1Ellog IQ&apos;) if we use classical heaps, 0(1E1 + IQ&apos; log 1 (21 ) if we use Fibonacci heaps, and 0(1Ellog log IQ) if we use the efficient implementation of priority queues by Thorup (1996). In case the maximum output weight W is small, we can use the algorithm of Ahuja et al. (1988); the complexity of pushing is then 0(1E1+ 1(21-0w1). In case the transducer is acyclic, we can use a specific automata minimization algorithm (Revuz 1992) with linear time complexity, 0(1(21 + 1E1). In the general case, an efficient implementation of Hoperoft&apos;s algorithm (Aho, Hoperoft, and Ullman 1974) leads to 0(1ElloglQ1). Thus, the overall complexity of the minimization of subsequential transducers is always as good as that of classical automata minimization: 0(1(21 + 1El) in the acyclic case, and 0(1Ellog1Q1) in the general case. Figures 15 to 17 illustrate the minimization algorithm. 31</context>
</contexts>
<marker>Ahuja, Mehlhorn, Orlin, Taman, 1988</marker>
<rawString>Ahuja, Ravindra K., Kurt Mehlhorn, James B. Orlin, and Robert Taman. 1988. Faster algorithms for the shortest path problem. Technical Report 193, MIT Operations Research Center.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Bauer</author>
</authors>
<title>On minimizing finite automata.</title>
<date>1988</date>
<journal>EATCS Bulletin,</journal>
<volume>35</volume>
<contexts>
<context position="90662" citStr="Bauer (1988)" startWordPosition="15922" endWordPosition="15923">erations of composition of transducers (Sproat 1995) and perhaps more important size issues can be found in this field. 18 We describe this application of determinization elsewhere. 305 Computational Linguistics Volume 23, Number 2 Figure 22 Subsequential power series S nonbisubsequential. Appendix The determinization algorithm for power series can also be used to minimize transducers in many cases. Let us first consider the case of automata. Brzozowski (1962) showed that determinization can be used to minimize automata. This nice result has also been proved more recently in elegant papers by Bauer (1988) and Urbanek (1989). These authors refine the method to obtain better complexities.19 Theorem 16 (Brzozowski 1962) Let A be a nondeterministic automaton. Then the automaton A&apos; = (Q&apos;, i&apos;,F&apos;,E,6&apos;) obtained by reversing A, applying determinization, rereversing the obtained automaton and determiruizing it is the minimal deterministic automaton equivalent to A. We generalize this theorem to the case of string-to-weight transducers. We say that a rational power series S is bisubsequential when S is subsequential and the power series SR = EwEE. (5, wR)w is also subsequential.&apos; Not all subsequential t</context>
</contexts>
<marker>Bauer, 1988</marker>
<rawString>Bauer, W. 1988. On minimizing finite automata. EATCS Bulletin, 35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Berstel</author>
</authors>
<title>Transductions and Context-Free Languages. Teubner Studienbucher,</title>
<date>1979</date>
<location>Stuttgart.</location>
<contexts>
<context position="19612" citStr="Berstel (1979)" startWordPosition="3146" endWordPosition="3147">&gt; S2* and a right sequential function r: S-2* —&gt; A* such that f =-- r 0 1. Left sequential functions or transducers are those we previously defined. Their application to a string proceeds from left to right. Right sequential functions apply to strings from right to left. According to the theorem, considering a new sufficiently large alphabet SZ allows one to define two sequential functions 1 and r that decompose a rational function f. This result considerably increases the importance of sequential functions in the theory of finite-state machines as well as in the practical use of transducers. Berstel (1979) gives a constructive proof of this theorem. Given a finite-state transducer T, one can easily construct a left sequential transducer L and a right sequential transducer R such that R o L = T. Intuitively, the extended alphabet Si keeps track of the local ambiguities encountered when applying the transducer from left to right. A distinct element of the alphabet is assigned to each of these ambiguities. The right sequential transducer can be constructed in such a way that these ambiguities can then be resolved from right to left. Figures 7 and 8 give a decomposition of the nonsequential transdu</context>
<context position="57792" citStr="Berstel (1979)" startWordPosition="10203" endWordPosition="10204">m, we introduce a lemma that shows that it suffices to examine a finite number of paths to test the twins property. Lemma 2 Let Ti = (Qi, E, Ii, Fi, Ei, Ai, Pi) be a trim unambiguous string-to-weight transducer defined on the tropical serniring. Ti has the twins property iff V(u, V) E (E*)2,1UVI &lt; 21(2112 - 1, ({q, q&apos;} c Si (I, u), q E oi(q, v), q&apos; c Si (q&apos; , v)) 01(q, v, q) = 01(q&apos; , v, q&apos;) (21) Proof Clearly if Ti has the twins property, then (21) holds. Conversely, we prove that if (21) holds, then it also holds for any (u, v) E (E* )2, by induction on I uv. Our proof is similar to that of Berstel (1979) for string-to-string transducers. Consider (u, v) E (E*)2 and (q, q&apos;) E l(2112 such that: {q, q&apos;} c I (I, u), q c 61(q, v), q&apos; E (q&apos; , v). Assume that luvl &gt; 21(2112 — 1 with Ivl &gt; 0. Then either lul &gt; Assume that I u I &gt; 1(21 12 - 1. Since Ti is a trim unambiguous transducer there exists 1(2112 — 1 or Iv&apos; a unique path 7r in Ti from i E Ito q labeled with the input string u, and a unique path &gt; 1Q112 — 1. 291 Computational Linguistics Volume 23, Number 2 7r&apos; from i&apos; E Ito q&apos;. In view of lemma 2, there exist strings 141, u2, u3 in E*, and states pi, p2, p, and p12 such that I u2I &gt; 0, u1u2u3 </context>
</contexts>
<marker>Berstel, 1979</marker>
<rawString>Berstel, Jean. 1979. Transductions and Context-Free Languages. Teubner Studienbucher, Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Berstel</author>
<author>Christophe Reutenauer</author>
</authors>
<title>Rational Series and Their Languages.</title>
<date>1988</date>
<publisher>Springer-Verlag,</publisher>
<location>Berlin and New York.</location>
<contexts>
<context position="31660" citStr="Berstel and Reutenauer 1988" startWordPosition="5248" endWordPosition="5251"> E S(I,w) n F. The output corresponding to an accepted string w is then obtained by taking the minimum of the outputs of all successful paths with input label w: min (A(i) + 0(i, w,f) + p(f)) (if)ElxF: fE6(i,w) A transducer T is said to be trim if all states of T belong to a successful path. String-toweight transducers clearly realize functions mapping E* to 12.±. Since the operations we need to consider are addition and min, and since (74 U { oo }, min, +, oo, 0) is a semiring, we call these functions formal power series.&apos; We adopt the terminology and notation used in formal language theory (Berstel and Reutenauer 1988; Kuich and Salomaa 1986; Salomaa and Soittola 1978): • the image by a formal power series S of a string w is denoted by (S, w) and called the coefficient of w in S. • the notation S E. (S,w)w is then used to define a power series by its coefficients, • the support of S is the language defined by: supp(S) = fw E E*: (S, w) oo } The fundamental theorem of Schutzenberger (1961), analogous to Kleene&apos;s theorem for formal languages, states that a formal power series S is rational iff it is recognizable, that is, realizable by a string-to-weight transducer. The semiring (R.+ U { °e}, min, +, 00, 0) </context>
</contexts>
<marker>Berstel, Reutenauer, 1988</marker>
<rawString>Berstel, Jean and Christophe Reutenauer. 1988. Rational Series and Their Languages. Springer-Verlag, Berlin and New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Brzozowski</author>
</authors>
<title>Canonical regular expressions and minimal state graphs for definite events. Mathematical Theory of Automata,</title>
<date>1962</date>
<pages>12--529</pages>
<contexts>
<context position="90514" citStr="Brzozowski (1962)" startWordPosition="15898" endWordPosition="15899">t the size of these networks while maintaining their time efficiency. These algorithms can also be used in text-to-speech synthesis. In fact, the same operations of composition of transducers (Sproat 1995) and perhaps more important size issues can be found in this field. 18 We describe this application of determinization elsewhere. 305 Computational Linguistics Volume 23, Number 2 Figure 22 Subsequential power series S nonbisubsequential. Appendix The determinization algorithm for power series can also be used to minimize transducers in many cases. Let us first consider the case of automata. Brzozowski (1962) showed that determinization can be used to minimize automata. This nice result has also been proved more recently in elegant papers by Bauer (1988) and Urbanek (1989). These authors refine the method to obtain better complexities.19 Theorem 16 (Brzozowski 1962) Let A be a nondeterministic automaton. Then the automaton A&apos; = (Q&apos;, i&apos;,F&apos;,E,6&apos;) obtained by reversing A, applying determinization, rereversing the obtained automaton and determiruizing it is the minimal deterministic automaton equivalent to A. We generalize this theorem to the case of string-to-weight transducers. We say that a rationa</context>
<context position="92841" citStr="Brzozowski (1962)" startWordPosition="16285" endWordPosition="16286">ilarly define bideterminizable transducers as the transducers T defined on the tropical semiring admitting two applications of determinization, as follows: 1. The reverse of T, TR can be determinized. We denote by det(TR) the resulting transducer. 2. The reverse of det(TR), [det(TR)]R can also be determinized. We denote by det(Pet(TR)JR) the resulting transducer. In this definition, we assume that the reverse operation is performed simply by reversing the direction of the transitions and exchanging initial and final states. Given this definition, we can present the extension of the theorem of Brzozowski (1962) to bideterminizable transducers.21 Theorem 17 Let T be a bideterminizable transducer defined on the tropical semiring. Then the transducer det(klet(TR)r) obtained by reversing T, applying determinization, rereversing the obtained transducer and determinizing it is a minimal subsequential transducer equivalent to T. Proof We denote by: • T1 = E, cri, Ai, det(TR), • T&apos; = (Q&apos;,i&apos; ,F&apos;, E, , a&apos;, A&apos;, p&apos;) detUdet(TR)1R) • T&amp;quot; = (Q&amp;quot;,i&amp;quot;,F&amp;quot;, E, 6&amp;quot;, a&amp;quot;, A&amp;quot;, p&amp;quot;) the transducer obtained from T by pushing. The double reverse and determinization algorithms clearly do not change the function that T realizes. S</context>
</contexts>
<marker>Brzozowski, 1962</marker>
<rawString>Brzozowski, J. A. 1962. Canonical regular expressions and minimal state graphs for definite events. Mathematical Theory of Automata, 12:529-561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J W Carlyle</author>
<author>A Paz</author>
</authors>
<title>Realizations by stochastic finite automaton.</title>
<date>1971</date>
<journal>Journal of Computer and System Sciences,</journal>
<pages>5--26</pages>
<contexts>
<context position="65069" citStr="Carlyle and Paz 1971" startWordPosition="11614" endWordPosition="11617">e a minimization algorithm for subsequential power series defined on the tropical semiring, which extends the algorithm defined by Mohri (1994b) in the case of string-to-string transducers. For any subset L of E* and any string u we define it-lL by: uL = {W: uW E Ll (22) Recall that L is a regular language if there exists a finite number of distinct ttNerode (1958). In a similar way, given a power series S we define a new power series 14-1S by:11 u-is = E (s,uw)w (23) wEE. 11 One can prove that S. a power series defined on a field, is rational if it admits a finite number of independent u-1S (Carlyle and Paz 1971). This is the equivalent, for power series, of Nerode&apos;s theorem for regular languages. 294 Mohri Transducers in Language and Speech For any subsequential power series S we can now define the following relation on E*: `Au, V) E E*, u Rs v &lt; &gt; k E 7Z, (u-1 supp(S) = v-1 supp(S)) and au-1 S - V-1 Si /u—tsupp(S) = k) (24) It is easy to show that Rs is an equivalence relation. (u-1 supp(S) = supp(S)) defines the equivalence relation for regular languages. Rs is a finer relation. The additional condition in the definition of Rs is that the restriction of the power series [14-1S - v-1S] to u-1 supp(S</context>
</contexts>
<marker>Carlyle, Paz, 1971</marker>
<rawString>Carlyle, J. W. and A. Paz. 1971. Realizations by stochastic finite automaton. Journal of Computer and System Sciences, 5:26-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Choffrut</author>
</authors>
<title>Contributions a l&apos;etude de quelques families remarquables de fonctions rationnelles.</title>
<date>1978</date>
<booktitle>Ph.D. thesis, (these de doctorat d&apos;Etat), Universite Paris 7, LITP,</booktitle>
<location>Paris.</location>
<contexts>
<context position="12794" citStr="Choffrut (1978)" startWordPosition="1961" endWordPosition="1962">uential in two ways here. One means that a finite number of 272 Mohri Transducers in Language and Speech Figure 3 Example of a subsequential transducer 72. ambiguities is admitted (the closure under composition matches this case), the second indicates that this number equals exactly p. Theorem 1 Let f: E* —&gt; A* be a sequential (resp. p-subsequential) and g: A* -- 9* be a sequential (resp. q-subsequential) function, then g of is sequential (resp. pq-subsequential). Proof We prove the theorem in the general case of p-subsequential transducers. The case of sequential transducers, first proved by Choffrut (1978), can be derived from the general case in a trivial way. Let T1 be a p-subsequential transducer representing f, Ti = (Qi,ii,h, E, A, 61, cri, pi), and T2 = (Q2/ i2/ F2, A, C/, 6&apos;2, 0-2, P2) a q-subsequential transducer representing g. pi and p2 denote the final output functions of T1 and 72, which map Fi to (A*)P and F2 to (S2* )q, respectively. pi (r) represents, for instance, the set of final output strings at a final state r. Define the pq-subsequential transducer T -= (Q, i, F, E, ft 6,a, P) by Q = Qi X Q2/ i = (i1/ i2). F = {(qi,q2) E Q: qi E Fi, 82(q2, pi(qi)) n F2 01, with the following</context>
<context position="20866" citStr="Choffrut (1978)" startWordPosition="3357" endWordPosition="3358">lphabet Q = {xl, x2} store information about the size of the input string w. The output of L ends with x1 iff I wl is odd. The right sequential function R is then easy to construct. 276 Mohri Transducers in Language and Speech Sequential transducers offer other theoretical advantages. In particular, while several important tests, such as equivalence, are undecidable with general transducers, sequential transducers have the following decidability property Theorem 5 Let T be a transducer mapping E* to A*. It is decidable whether T is sequential. A constructive proof of this theorem was given by Choffrut (1978). An efficient polynomial algorithm for testing the sequentiability of transducers based on this proof was given by Weber and Klemm (1995). Choffrut also gave a characterization of subsequential functions based on the definition of a metric on E*. Denote by u A v the longest common prefix of two strings u and v in E*. It is easy to verify that the following defines a metric on E*: d(u,v) = lul + Iv&apos; - 2lu A vl (3) The following theorem describes this characterization of subsequential functions. Theorem 6 Let f be a partial function mapping E* to A*. f is subsequential iff: 1. f has bounded var</context>
<context position="38084" citStr="Choffrut (1978)" startWordPosition="6402" endWordPosition="6403">the transition function associated with 7-, a its output function, and A and p the initial and final weight functions. Let L be the maximum of the lengths of all output labels of T: L= max la (q , a)I (11) (q,a)E(2xE and R the upper bound of all output differences at final states: R= max p(q) — p(q1) I (12) (q,q9EF2 and define M as M -= L + R. Let (ui, u2) be in (E*)2. By definition of d, there exists U E E* such that: -+- UV 1, U = uv2, and lvii + Iv21 = d(ui, u2) (13) Hence, = (i, u) + a- (6 (i, u), vi) = a- (i, u) + cr (S(i, u), v2) 4 This is an extension of the characterization theorem of Choffrut (1978) for string-to-string functions. The extension is not straightforward because the length of an output string is a natural integer. Here we deal with real numbers. 283 Computational Linguistics Volume 23, Number 2 Since I u(6(i, u), Vi) — 0(6(i, u), v2)I &lt; L • (IVi I 1V21) = L d(ui, u2) and II* (04)) P(O(i,u2))I R we have + cr(i, + P(6(i, 140) — A ± o-(i, u2) P(6(i, u2))1 L d(ui,u2) +R Notice that if u1 u2, R &lt;R • d(ui, u2). Thus l A + (7(i, ui) + (i, ui)) — A + cr(i, u2) + p(6(i, u2))I (L + d(ui, 142) Therefore: V(Ui, U2) E (E*)2, I5(ui) — S(U2)I &lt; M • C1(1-11,142) (14) This proves that S is M</context>
<context position="92018" citStr="Choffrut 1978" startWordPosition="16160" endWordPosition="16161">V, (S , ban) = n +1 (27) Vn E Ar, (s,can) = 0 The transducer of Figure 22 is subsequential so S is subsequential. But the reverse SR is not, because it does not have bounded variation. Indeed, since: Vn Ef , (SR , an b) = n + 1 (28) Vn E (SR, anC) = 0 We have: Vn E AT , l(SR , a&amp;quot; b) — (SR , an c)I = n +1 19 See Watson (1993) for a taxonomy of minimization algorithms for automata; see also Courcelle, Niwinsld, and Podelski 1991. 20 For any string w E E*, we denote by wR its reverse. 306 Mohri Transducers in Language and Speech A characterization similar to that of string-to-string transducers (Choffrut 1978) is possible for bisubsequential power series defined on the tropical semiring. In particular, the theorem of the previous sections shows that S is bisubsequential if S and SR have bounded variation. We similarly define bideterminizable transducers as the transducers T defined on the tropical semiring admitting two applications of determinization, as follows: 1. The reverse of T, TR can be determinized. We denote by det(TR) the resulting transducer. 2. The reverse of det(TR), [det(TR)]R can also be determinized. We denote by det(Pet(TR)JR) the resulting transducer. In this definition, we assum</context>
</contexts>
<marker>Choffrut, 1978</marker>
<rawString>Choffrut, Christian. 1978. Contributions a l&apos;etude de quelques families remarquables de fonctions rationnelles. Ph.D. thesis, (these de doctorat d&apos;Etat), Universite Paris 7, LITP, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Cormen</author>
<author>C Leiserson</author>
<author>R Rivest</author>
</authors>
<title>Introduction to Algorithms.</title>
<date>1992</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Cormen, Leiserson, Rivest, 1992</marker>
<rawString>Cormen, T., C. Leiserson, and R. Rivest. 1992. Introduction to Algorithms. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruno Courcelle</author>
<author>Damian Niwinski</author>
<author>Andreas Podelsld</author>
</authors>
<title>A geometrical view of the determinization and minimization of finite-state automata.</title>
<date>1991</date>
<booktitle>Mathematical Systems Theory,</booktitle>
<pages>24--117</pages>
<marker>Courcelle, Niwinski, Podelsld, 1991</marker>
<rawString>Courcelle, Bruno, Damian Niwinski, and Andreas Podelsld. 1991. A geometrical view of the determinization and minimization of finite-state automata. Mathematical Systems Theory, 24:117-146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maxirne Crochemore</author>
</authors>
<title>Transducers and repetitions.</title>
<date>1986</date>
<journal>Theoretical Computer Science,</journal>
<volume>45</volume>
<contexts>
<context position="89538" citStr="Crochemore 1986" startWordPosition="15754" endWordPosition="15755">string semirirtg that we introduced makes it conceptually easier to describe many algorithms and properties. Subsequential transducers admit very efficient algorithms. The determinization and minimization algorithms in the case of string-to-weight transducers presented here complete a large series of algorithms that have been shown to give remarkable results in natural language processing. Sequential machines lead to useful algorithms in many other areas of computational linguistics. In particular, subsequential power series allow for efficient results in indexation of natural language texts (Crochemore 1986; Mohri 1996b). We briefly illustrated the application of these algorithms to speech recognition. More precision in acoustic modeling, finer language models, large lexicon grammars, and a larger vocabulary will lead, in the near future, to networks of much larger sizes in speech recognition. The determinization and minimization algorithms might help to limit the size of these networks while maintaining their time efficiency. These algorithms can also be used in text-to-speech synthesis. In fact, the same operations of composition of transducers (Sproat 1995) and perhaps more important size iss</context>
</contexts>
<marker>Crochemore, 1986</marker>
<rawString>Crochemore, Maxirne. 1986. Transducers and repetitions. Theoretical Computer Science, 45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Eilenberg</author>
</authors>
<date>1974</date>
<journal>Automata, Languages and Machines,</journal>
<volume>volume</volume>
<publisher>A-B. Academic Press.</publisher>
<contexts>
<context position="61838" citStr="Eilenberg 1974" startWordPosition="11045" endWordPosition="11046">q2, c) with c 0, then Ti does not have the twins property The operations used in the algorithm (computation of the transitive closure, determination of the set of states) can all be done in polynomial time with respect to the size of A, using classical algorithms (Aho, Hoperoft, and Ullman 1974). 0 This provides an algorithm for testing the twins property of an unambiguous trim transducer T. It is very useful when T is known to be unambiguous. In many practical cases, the transducer one wishes to determinize is ambiguous. It is always possible to construct an unambiguous transducer T&apos; from T (Eilenberg 1974-1976). The complexity of such a construction is exponential in the worst case. Thus the overall complexity of the test of determinizability is also exponential in the worst case. Notice that if one wishes to construct the result of the determinization of T for a given input string w, one does not need to expand the whole result of the determinization, but only the necessary part of the determinized transducer. When restricted to a finite set the function realized by any transducer is subsequentiable, since it has bounded variation.&apos; Acyclic transducers have the twins property, so they are det</context>
</contexts>
<marker>Eilenberg, 1974</marker>
<rawString>Eilenberg, Samuel. 1974-1976. Automata, Languages and Machines, volume A-B. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C C Elgot</author>
<author>J E Mezei</author>
</authors>
<title>On relations defined by generalized finite automata.</title>
<date>1965</date>
<journal>IBM Journal of Research and Development,</journal>
<volume>9</volume>
<contexts>
<context position="18752" citStr="Elgot and Mezei (1965)" startWordPosition="3001" endWordPosition="3004"> E E, 3w E A*, I wl &lt;K: f(ua) = f(u)w (2) In other words, for any string u and any element of the alphabet a, f (ua) is equal to f (u) concatenated with some bounded string. Notice that this implies that f(u) is always a prefix of f (ua), and more generally that if f is sequential then it preserves prefixes. 275 Computational Linguistics Volume 23, Number 2 Figure 7 Left-to-right sequential transducer L. xl:a Figure 8 Right-to-left sequential transducer R. The fact that not all rational functions are sequential could reduce the interest of sequential transducers. The following theorem, due to Elgot and Mezei (1965), shows, however, that transducers are exactly compositions of left and right sequential transducers. Theorem 4 (Elgot and Mezei 1965) Let f be a partial function mapping E* to A*. f is rational iff there exists a left sequential function 1: E* —&gt; S2* and a right sequential function r: S-2* —&gt; A* such that f =-- r 0 1. Left sequential functions or transducers are those we previously defined. Their application to a string proceeds from left to right. Right sequential functions apply to strings from right to left. According to the theorem, considering a new sufficiently large alphabet SZ allows </context>
</contexts>
<marker>Elgot, Mezei, 1965</marker>
<rawString>Elgot, C. C. and J. E. Mezei. 1965. On relations defined by generalized finite automata. IBM Journal of Research and Development, 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ginsburg</author>
<author>G F Rose</author>
</authors>
<title>A characterization of machine mappings.</title>
<date>1966</date>
<journal>Canadian Journal of Mathematics,</journal>
<volume>18</volume>
<contexts>
<context position="18007" citStr="Ginsburg and Rose 1966" startWordPosition="2867" endWordPosition="2870"> a or b according to whether n is even or odd, one needs to finish reading the whole input string w, which can be arbitrarily long. Sequential functions, namely functions that 1 We denote by I wl the length of a string w. (1) 274 Mohri Transducers in Language and Speech Figure 5 2-subsequential transducer 14, union of T1 and r2. Figure 6 Transducer T with no equivalent sequential representation. can be represented by sequential transducers do not allow such unbounded delays. More generally, sequential functions can be characterized among rational functions by the following theorem: Theorem 3 (Ginsburg and Rose 1966) Let f be a rational function mapping E* to L. f is sequential iff there exists a positive integer K such that: WI E E*, Va E E, 3w E A*, I wl &lt;K: f(ua) = f(u)w (2) In other words, for any string u and any element of the alphabet a, f (ua) is equal to f (u) concatenated with some bounded string. Notice that this implies that f(u) is always a prefix of f (ua), and more generally that if f is sequential then it preserves prefixes. 275 Computational Linguistics Volume 23, Number 2 Figure 7 Left-to-right sequential transducer L. xl:a Figure 8 Right-to-left sequential transducer R. The fact that no</context>
</contexts>
<marker>Ginsburg, Rose, 1966</marker>
<rawString>Ginsburg, S. and G. F. Rose. 1966. A characterization of machine mappings. Canadian Journal of Mathematics, 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maurice Gross</author>
</authors>
<title>The use of finite automata in the lexical representation of natural language.</title>
<date>1989</date>
<journal>Lecture Notes in Computer Science,</journal>
<volume>377</volume>
<contexts>
<context position="1305" citStr="Gross 1989" startWordPosition="176" endWordPosition="177">minization and the corresponding algorithms. Some applications of these algorithms in speech recognition are described and illustrated. 1. Introduction Finite-state machines have been used in many areas of computational linguistics. Their use can be justified by both linguistic and computational arguments. Linguistically, finite automata are convenient since they allow one to describe easily most of the relevant local phenomena encountered in the empirical study of language. They often lead to a compact representation of lexical rules, or idioms and clichés, that appears natural to linguists (Gross 1989). Graphic tools also allow one to visualize and modify automata, which helps in correcting and completing a grammar. Other more general phenomena, such as parsing context-free grammars, can also be dealt with using finitestate machines such as RTN&apos;s (Woods 1970). Moreover, the underlying mechanisms in most of the methods used in parsing are related to automata. From the computational point of view, the use of finite-state machines is mainly motivated by considerations of time and space efficiency. Time efficiency is usually achieved using deterministic automata. The output of deterministic mac</context>
</contexts>
<marker>Gross, 1989</marker>
<rawString>Gross, Maurice. 1989. The use of finite automata in the lexical representation of natural language. Lecture Notes in Computer Science, 377.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John E Hoperoft</author>
<author>Jeffrey D Ullman</author>
</authors>
<title>Introduction to Automata Theory, Languages, and Computation.</title>
<date>1979</date>
<publisher>Addison Wesley,</publisher>
<location>Reading, MA.</location>
<contexts>
<context position="74322" citStr="Hoperoft and Ullman (1979" startWordPosition="13333" endWordPosition="13336">s not change the number of transitions of T and automatan minimization, which consists of merging equivalent states, reduces or does not change this number. Thus, the number of transitions of the minimal transducer equivalent to T as previously defined is less or equal to that of T. This proves the corollary since, as previously pointed out, equivalent minimal transducers all have the same topology: in particular, they have the same number of states and transitions. Given two subsequential transducers, one might wish to test their equivalence. The importance of this problem was pointed out by Hoperoft and Ullman (1979, 284). The following corollary addresses this question. Corollary 2 There exists an algorithm to determine if two subsequential transducers are equivalent. Proof The algorithm of theorem 15 associates a unique minimal transducer to each subsequential transducer T. More precisely, this minimal transducer is unique up to a renumbering of the states. The identity of two subsequential transducers with different numbering of states can be tested in the same way as that of two deterministic automata; for instance, by testing the equivalence of the automata and the equality of their number of states</context>
</contexts>
<marker>Hoperoft, Ullman, 1979</marker>
<rawString>Hoperoft, John E. and Jeffrey D. Ullman. 1979. Introduction to Automata Theory, Languages, and Computation. Addison Wesley, Reading, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>Martin Kay</author>
</authors>
<title>Regular models of phonological rule systems.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>3</issue>
<contexts>
<context position="2616" citStr="Kaplan and Kay 1994" startWordPosition="366" endWordPosition="369">ptimal from this point of view. Space efficiency is achieved with classical minimization algorithms (Aho, Hoperoft, and Ullman 1974) for deterministic automata. Applications such as compiler construction have shown deterministic finite automata to be very efficient in practice (Aho, Sethi, and Ullman 1986). Finite automata now also constitute a rich chapter of theoretical computer science (Perrin 1990). Their recent applications in natural language processing, which range from the construction of lexical analyzers (Silverztein 1993) and the compilation of morphological and phonological rules (Kaplan and Kay 1994; Karttunen, Kaplan and Zaenen 1992) to speech processing (Mohri, Pereira, and Riley 1996) show the usefulness of finite-state machines in many areas. In this paper, we provide theoretical and algorithmic bases for the use and application of the devices that support very efficient programs: sequential transducers. * 600 Mountain Avenue, Murray Hill, NJ 07974, USA. C) 1997 Association for Computational Linguistics Computational Linguistics Volume 23, Number 2 We extend the idea of deterministic automata to transducers with deterministic input, that is, machines that produce output strings or we</context>
<context position="26025" citStr="Kaplan and Kay 1994" startWordPosition="4249" endWordPosition="4252">ion algorithm for sequential and p-subsequential transducers allows the size of these devices to be reduced to the minimum. Experiments have shown that these compact and fast look-up representations for large natural language dictionaries can be efficiently obtained. As an example, a French morphological dictionary of about 21.2 Mb can be compiled into a p-subsequential transducer of 1.3 Mb, in a few minutes (Mohri 1996b). 2.4.2 Compilation of Morphological and Phonological Rules. Similarly, context-dependent phonological and morphological rules can be represented by finite-state transducers (Kaplan and Kay 1994). Most phonological and morphological rules correspond to p-subsequential functions. The result of the computation described by Kaplan and Kay (1994) is not necessarily a p-subsequential transducer. But, it can often be determinized using the determinization algorithm for p-subsequentiable transducers. This considerably increases the time efficiency of the transducer. It can be further minimized to reduce its size. These observations can be extended to the case of weighted rewrite rules (Mohri and Sproat 1996). 2.4.3 Syntax. Finite-state machines are also currently used to represent local synt</context>
</contexts>
<marker>Kaplan, Kay, 1994</marker>
<rawString>Kaplan, Ronald M. and Martin Kay. 1994. Regular models of phonological rule systems. Computational Linguistics, 20(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred Karlsson</author>
<author>Afro Voutilainen</author>
<author>Juha Heikkila</author>
<author>Atro Anttila</author>
</authors>
<title>Constraint Grammar, A LanguageIndependent System for Parsing Unrestricted Text. Mouton de Gruyter.</title>
<date>1995</date>
<contexts>
<context position="26694" citStr="Karlsson et al. 1995" startWordPosition="4345" endWordPosition="4348">spond to p-subsequential functions. The result of the computation described by Kaplan and Kay (1994) is not necessarily a p-subsequential transducer. But, it can often be determinized using the determinization algorithm for p-subsequentiable transducers. This considerably increases the time efficiency of the transducer. It can be further minimized to reduce its size. These observations can be extended to the case of weighted rewrite rules (Mohri and Sproat 1996). 2.4.3 Syntax. Finite-state machines are also currently used to represent local syntactic constraints (Silberztein 1993; Roche 1993; Karlsson et al. 1995; Mohri 1994d). Linguists can conveniently introduce local grammar transducers that can be used to disambiguate sentences. The number of local grammars for a given language and even for a specific domain can be large. The local grammar transducers are mostly p-subsequential. Determinization and minimization can then be used to make the use of local grammar transducers more time efficient and to reduce their size. Since p-subsequential transducers are closed under composition, the result of the composition of all local grammar transducers is a p-subsequential transducer. The equivalence of loca</context>
</contexts>
<marker>Karlsson, Voutilainen, Heikkila, Anttila, 1995</marker>
<rawString>Karlsson, Fred, Afro Voutilainen, Juha Heikkila, and Atro Anttila. 1995. Constraint Grammar, A LanguageIndependent System for Parsing Unrestricted Text. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
<author>Ronald M Kaplan</author>
<author>Annie Zaenen</author>
</authors>
<title>Two-level morphology with composition.</title>
<date>1992</date>
<booktitle>In Proceedings of the Fifteenth International Conference on Computational Linguistics (COLING-92),</booktitle>
<location>Nantes, France. COLING.</location>
<marker>Karttunen, Kaplan, Zaenen, 1992</marker>
<rawString>Karttunen, Lauri, Ronald M. Kaplan, and Annie Zaenen. 1992. Two-level morphology with composition. In Proceedings of the Fifteenth International Conference on Computational Linguistics (COLING-92), Nantes, France. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Krob</author>
</authors>
<title>The equality problem for rational series with multiplicities in the tropical semiring is undecidable.</title>
<date>1994</date>
<journal>Journal of Algebra and Computation,</journal>
<volume>4</volume>
<contexts>
<context position="75846" citStr="Krob (1994)" startWordPosition="13576" endWordPosition="13577">cers, considered as automata. 299 Computational Linguistics Volume 23, Number 2 imization of subsequential transducers was also shown to be efficient, this proves the corollary and also the efficiency of the test of equivalence. 0 Schiitzenberger (1961) gave an algorithm for minimizing the representation of power series, but this algorithm can only be used when the semiring considered is a field. In particular, it cannot be used with the tropical semiring or the string semiring used in language and speech processing, since none of these semirings is a field. More precisely, a recent result of Krob (1994) states that such a minimization cannot be defined for transducers defined on the tropical semiring. Furthermore, we implemented the algorithm of Schatzenberger (1961) and used it in the case of the semiring (R., +, 0,1). It has two important disadvantages in practice: it creates many transitions, and it can generate transitions with negative weights, even if the initial machine has none. The negative weights cannot be interpreted in terms of probability. In the next section, we describe some of the applications to speech recognition of the algorithms we presented above. 4. Application to Spee</context>
</contexts>
<marker>Krob, 1994</marker>
<rawString>Krob, Daniel. 1994. The equality problem for rational series with multiplicities in the tropical semiring is undecidable. Journal of Algebra and Computation, 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Werner Kuich</author>
<author>Arto Salomaa</author>
</authors>
<date>1986</date>
<journal>Semirings, Automata, Languages. EATCS Monographs on Theoretical Computer Science, Number</journal>
<volume>5</volume>
<publisher>Springer-Verlag,</publisher>
<location>Berlin.</location>
<contexts>
<context position="31684" citStr="Kuich and Salomaa 1986" startWordPosition="5252" endWordPosition="5255">responding to an accepted string w is then obtained by taking the minimum of the outputs of all successful paths with input label w: min (A(i) + 0(i, w,f) + p(f)) (if)ElxF: fE6(i,w) A transducer T is said to be trim if all states of T belong to a successful path. String-toweight transducers clearly realize functions mapping E* to 12.±. Since the operations we need to consider are addition and min, and since (74 U { oo }, min, +, oo, 0) is a semiring, we call these functions formal power series.&apos; We adopt the terminology and notation used in formal language theory (Berstel and Reutenauer 1988; Kuich and Salomaa 1986; Salomaa and Soittola 1978): • the image by a formal power series S of a string w is denoted by (S, w) and called the coefficient of w in S. • the notation S E. (S,w)w is then used to define a power series by its coefficients, • the support of S is the language defined by: supp(S) = fw E E*: (S, w) oo } The fundamental theorem of Schutzenberger (1961), analogous to Kleene&apos;s theorem for formal languages, states that a formal power series S is rational iff it is recognizable, that is, realizable by a string-to-weight transducer. The semiring (R.+ U { °e}, min, +, 00, 0) used in many optimizatio</context>
</contexts>
<marker>Kuich, Salomaa, 1986</marker>
<rawString>Kuich, Werner and Arto Salomaa. 1986. Semirings, Automata, Languages. EATCS Monographs on Theoretical Computer Science, Number 5. Springer-Verlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
</authors>
<title>Compact representations by finite-state transducers.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd Annual Meeting,</booktitle>
<institution>Mexico. Association for Computational Linguistics.</institution>
<location>Las Cruces, New</location>
<contexts>
<context position="6643" citStr="Mohri 1994" startWordPosition="950" endWordPosition="951">everal results that show them to be very efficient. Our implementation of the determinization is such that it can be used on the fly: only the necessary part of the transducer needs to be expanded. This plays an important role in the space and time efficiency of speech recognition. The reduction in the size of word lattices that these algorithms provide sheds new light on the complexity of the networks involved in speech processing. 2. Sequential String-to-String Transducers Sequential string-to-string transducers are used in various areas of natural language processing. Both determinization (Mohri 1994c) and minimization algorithms (Mohri 1994b) have been defined for the class of p-subsequential transducers, which includes sequential string-to-string transducers. In this section, the theoretical basis of the use of sequential transducers is described. Classical and new theorems help to indicate the usefulness of these devices as well as their characterization. 270 Mohri Transducers in Language and Speech b:E Figure 1 Example of a sequential transducer. 2.1 Sequential Transducers We consider here sequential transducers, namely, transducers with a deterministic input. At any state of such tra</context>
<context position="10072" citStr="Mohri 1994" startWordPosition="1524" endWordPosition="1525"> a string can then possibly finish with the concatenation of such an output string to the usual output. Such transducers are called subsequential transducers. Language processing often requires a more general extension. Indeed, the ambiguities encountered in language—ambiguity of grammars, of morphological analyzers, or that of pronunciation dictionaries, for instance—cannot be taken into account when using sequential or subsequential transducers. These devices associate at most a single output to a given input. In order to deal with ambiguities, one can introduce p-subsequential transducers (Mohri 1994a), namely transducers provided with at most p final output strings at each final state. Figure 2 gives an example of a 2-subsequential transducer. Here, the input string w = aa gives two distinct outputs aaa and aab. Since one cannot find any reasonable case in language in which the number of ambiguities would be infinite, p-subsequential transducers seem to be sufficient for describing linguistic ambiguities. However, the number of ambiguities could be very large in some cases. Notice that 1-subsequential transducers are exactly the subsequential transducers. Transducers can be considered to</context>
<context position="24852" citStr="Mohri 1994" startWordPosition="4080" endWordPosition="4081">kM + 2N. We have: crp(f (141),f (u2)) &lt; May 11 + k21) c(P(6(i, al)), PO(i,u2))) &lt; kM + 2N = K Thus, f has bounded variation using dip. This ends the proof of the theorem. 2.4 Application to Language Processing We briefly mentioned several theoretical and computational properties of sequential and p-subsequential transducers. These devices are used in many areas of computational linguistics. In all those areas, the determinization algorithm can be used to obtain a p-subsequential transducer (Mohri 1996b), and the minimization algorithm to reduce the size of the p-subsequential transducer used (Mohri 1994b). The composition, union, and equivalence algorithms for subsequential transducers are also useful in many applications. 278 Mohri Transducers in Language and Speech 2.4.1 Representation of Dictionaries. Very large-scale dictionaries can be represented by p-subsequential dictionaries because the number of entries and that of the ambiguities they contain are finite. The corresponding representation offers fast look-up since the recognition does not depend on the size of the dictionary but only on that of the input string considered. The minimization algorithm for sequential and p-subsequentia</context>
<context position="26706" citStr="Mohri 1994" startWordPosition="4349" endWordPosition="4350">al functions. The result of the computation described by Kaplan and Kay (1994) is not necessarily a p-subsequential transducer. But, it can often be determinized using the determinization algorithm for p-subsequentiable transducers. This considerably increases the time efficiency of the transducer. It can be further minimized to reduce its size. These observations can be extended to the case of weighted rewrite rules (Mohri and Sproat 1996). 2.4.3 Syntax. Finite-state machines are also currently used to represent local syntactic constraints (Silberztein 1993; Roche 1993; Karlsson et al. 1995; Mohri 1994d). Linguists can conveniently introduce local grammar transducers that can be used to disambiguate sentences. The number of local grammars for a given language and even for a specific domain can be large. The local grammar transducers are mostly p-subsequential. Determinization and minimization can then be used to make the use of local grammar transducers more time efficient and to reduce their size. Since p-subsequential transducers are closed under composition, the result of the composition of all local grammar transducers is a p-subsequential transducer. The equivalence of local grammars c</context>
<context position="41495" citStr="Mohri 1994" startWordPosition="7057" endWordPosition="7058">3K &gt; 0, Vk &gt; 0, I (0(/, uw,F) — 0 (I, uw&apos; , F)) + k(0(q, v, q) — 61(qc v, q&apos;))I 5 K 0 (q , v, q) — 0 (q&apos; ,v, q&apos;) = 0 Thus r has the twins property This ends the proof of the theorem. 0 3.3 General Determinization Algorithm for Power Series We describe in this section an algorithm for constructing a subsequential transducer 72 = (Q2, 2,F2, E, 62, 0-2, A2,192) equivalent to a given nonsubsequential one TI E, I, F1, Ei, A1, P1). The algorithm extends our determinization algorithm for stringto-string transducers representing p-subsequential functions to the case of transducers outputting weights (Mohri 1994c). Figure 10 gives the pseudocode of the algorithm. We present the algorithm in the general case of a semiring (S, ED, 0, 0, 1) on which the transducer Ti is defined. Indeed, the algorithm we are describing here applies as well to transducers representing power series defined on many other semirings.6 We describe the algorithm in the case of the tropical semiring. For the tropical semiring, one can replace ED by min and 0 by + in the pseudocode of Figure 10.7 6 In particular, the algorithm also applies to string subsequentiable transducers and to transducers that output pairs of strings and w</context>
<context position="63364" citStr="Mohri (1994" startWordPosition="11301" endWordPosition="11302"> other semirings. We gave the pseudocode of the algorithm in the general case. The algorithm applies for instance to the real semiring (R,,+,., 0,1). One can also verify that (E*Uf oo}, A, oo, f), where A denotes the longest common prefix operation and • concatenation, oo a new element such that for any string w E (E*U fool), WA oo = co A w = w and w oo oo • w = oo, defines a left semiring.&apos; We call this semiring the string semiring. The algorithm of Figure 10 used with the string semiring is exactly the determinization algorithm for subsequentiable string-to-string transducers, as defined by Mohri (1994c). The cross product of two semirings defines a semiring. The algorithm also applies when the semiring is the cross product of 9 Using the proof of the theorem of the previous section, it is easy to convince oneself that this assertion can be generalized to any rational subset Y of E* such that the restriction of S, the function T realizes, to Y has bounded variation. 10 A left semiring is a semiring that may lack right distributivity. 293 Computational Linguistics Volume 23, Number 2 a:b/3 Figure 13 Transducer Ti with outputs in E* x R. Figure 14 Sequential transducer 72 with outputs in E* x</context>
<context position="64590" citStr="Mohri (1994" startWordPosition="11520" endWordPosition="11521">m (31 by determinization. (E* U fool, A, oo, €) and (R+ U { oo }, min, +, 00, 0), which allows transducers outputting pairs of strings and weights to be determined. The determirtization algorithm for such transducers is illustrated in Figures 13 and 14. Subsets in this algorithm are made of triples (q, w, x) E Q x E* U { oo} x R. U foo}, where q is a state of the initial transducer, w a residual string, and x a residual output weight. 3.7 Minimization We here define a minimization algorithm for subsequential power series defined on the tropical semiring, which extends the algorithm defined by Mohri (1994b) in the case of string-to-string transducers. For any subset L of E* and any string u we define it-lL by: uL = {W: uW E Ll (22) Recall that L is a regular language if there exists a finite number of distinct ttNerode (1958). In a similar way, given a power series S we define a new power series 14-1S by:11 u-is = E (s,uw)w (23) wEE. 11 One can prove that S. a power series defined on a field, is rational if it admits a finite number of independent u-1S (Carlyle and Paz 1971). This is the equivalent, for power series, of Nerode&apos;s theorem for regular languages. 294 Mohri Transducers in Language </context>
<context position="69970" citStr="Mohri (1994" startWordPosition="12622" endWordPosition="12623">be a subsequential transducer realizing a power series on the tropical semiring. Then applying the following two operations: 1. pushing 2. automata minimization leads to a minimal transducer. This minimal transducer is exactly the one defined in the proof of theorem 14. The automata minimization step in the theorem consists of considering pairs of input labels and associated weights as a single label and of applying classical minimization algorithms for automata (Aho, Hoperoft, and Ullman 1974). We do not give the proof of the theorem; it can be proved in a way similar to what is indicated in Mohri (1994b). In general, there are several distinct minimal subsequential transducers realizing the same function. Pushing introduces an equivalence relation on minimal transducers: T Rp T&apos; if p(T) -= p(T&apos;), where p(T) (resp. p(T&apos;)) denotes the transducer obtained from T (resp. T&apos;) by pushing. Indeed, if T and T&apos; are minimal transducers realizing the same function, then p(T) and p(T&apos;) are both equal to the unique minimal transducer equivalent to T and T&apos; as defined in theorem 14. So, two equivalent minimal transducers only differ by their output labels, they have the same topology. They only differ by </context>
</contexts>
<marker>Mohri, 1994</marker>
<rawString>Mohri, Mehryar. 1994a. Compact representations by finite-state transducers. In Proceedings of the 32nd Annual Meeting, Las Cruces, New Mexico. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
</authors>
<title>Minimization of sequential transducers.</title>
<date>1994</date>
<journal>Lecture Notes in Computer Science,</journal>
<volume>807</volume>
<contexts>
<context position="6643" citStr="Mohri 1994" startWordPosition="950" endWordPosition="951">everal results that show them to be very efficient. Our implementation of the determinization is such that it can be used on the fly: only the necessary part of the transducer needs to be expanded. This plays an important role in the space and time efficiency of speech recognition. The reduction in the size of word lattices that these algorithms provide sheds new light on the complexity of the networks involved in speech processing. 2. Sequential String-to-String Transducers Sequential string-to-string transducers are used in various areas of natural language processing. Both determinization (Mohri 1994c) and minimization algorithms (Mohri 1994b) have been defined for the class of p-subsequential transducers, which includes sequential string-to-string transducers. In this section, the theoretical basis of the use of sequential transducers is described. Classical and new theorems help to indicate the usefulness of these devices as well as their characterization. 270 Mohri Transducers in Language and Speech b:E Figure 1 Example of a sequential transducer. 2.1 Sequential Transducers We consider here sequential transducers, namely, transducers with a deterministic input. At any state of such tra</context>
<context position="10072" citStr="Mohri 1994" startWordPosition="1524" endWordPosition="1525"> a string can then possibly finish with the concatenation of such an output string to the usual output. Such transducers are called subsequential transducers. Language processing often requires a more general extension. Indeed, the ambiguities encountered in language—ambiguity of grammars, of morphological analyzers, or that of pronunciation dictionaries, for instance—cannot be taken into account when using sequential or subsequential transducers. These devices associate at most a single output to a given input. In order to deal with ambiguities, one can introduce p-subsequential transducers (Mohri 1994a), namely transducers provided with at most p final output strings at each final state. Figure 2 gives an example of a 2-subsequential transducer. Here, the input string w = aa gives two distinct outputs aaa and aab. Since one cannot find any reasonable case in language in which the number of ambiguities would be infinite, p-subsequential transducers seem to be sufficient for describing linguistic ambiguities. However, the number of ambiguities could be very large in some cases. Notice that 1-subsequential transducers are exactly the subsequential transducers. Transducers can be considered to</context>
<context position="24852" citStr="Mohri 1994" startWordPosition="4080" endWordPosition="4081">kM + 2N. We have: crp(f (141),f (u2)) &lt; May 11 + k21) c(P(6(i, al)), PO(i,u2))) &lt; kM + 2N = K Thus, f has bounded variation using dip. This ends the proof of the theorem. 2.4 Application to Language Processing We briefly mentioned several theoretical and computational properties of sequential and p-subsequential transducers. These devices are used in many areas of computational linguistics. In all those areas, the determinization algorithm can be used to obtain a p-subsequential transducer (Mohri 1996b), and the minimization algorithm to reduce the size of the p-subsequential transducer used (Mohri 1994b). The composition, union, and equivalence algorithms for subsequential transducers are also useful in many applications. 278 Mohri Transducers in Language and Speech 2.4.1 Representation of Dictionaries. Very large-scale dictionaries can be represented by p-subsequential dictionaries because the number of entries and that of the ambiguities they contain are finite. The corresponding representation offers fast look-up since the recognition does not depend on the size of the dictionary but only on that of the input string considered. The minimization algorithm for sequential and p-subsequentia</context>
<context position="26706" citStr="Mohri 1994" startWordPosition="4349" endWordPosition="4350">al functions. The result of the computation described by Kaplan and Kay (1994) is not necessarily a p-subsequential transducer. But, it can often be determinized using the determinization algorithm for p-subsequentiable transducers. This considerably increases the time efficiency of the transducer. It can be further minimized to reduce its size. These observations can be extended to the case of weighted rewrite rules (Mohri and Sproat 1996). 2.4.3 Syntax. Finite-state machines are also currently used to represent local syntactic constraints (Silberztein 1993; Roche 1993; Karlsson et al. 1995; Mohri 1994d). Linguists can conveniently introduce local grammar transducers that can be used to disambiguate sentences. The number of local grammars for a given language and even for a specific domain can be large. The local grammar transducers are mostly p-subsequential. Determinization and minimization can then be used to make the use of local grammar transducers more time efficient and to reduce their size. Since p-subsequential transducers are closed under composition, the result of the composition of all local grammar transducers is a p-subsequential transducer. The equivalence of local grammars c</context>
<context position="41495" citStr="Mohri 1994" startWordPosition="7057" endWordPosition="7058">3K &gt; 0, Vk &gt; 0, I (0(/, uw,F) — 0 (I, uw&apos; , F)) + k(0(q, v, q) — 61(qc v, q&apos;))I 5 K 0 (q , v, q) — 0 (q&apos; ,v, q&apos;) = 0 Thus r has the twins property This ends the proof of the theorem. 0 3.3 General Determinization Algorithm for Power Series We describe in this section an algorithm for constructing a subsequential transducer 72 = (Q2, 2,F2, E, 62, 0-2, A2,192) equivalent to a given nonsubsequential one TI E, I, F1, Ei, A1, P1). The algorithm extends our determinization algorithm for stringto-string transducers representing p-subsequential functions to the case of transducers outputting weights (Mohri 1994c). Figure 10 gives the pseudocode of the algorithm. We present the algorithm in the general case of a semiring (S, ED, 0, 0, 1) on which the transducer Ti is defined. Indeed, the algorithm we are describing here applies as well to transducers representing power series defined on many other semirings.6 We describe the algorithm in the case of the tropical semiring. For the tropical semiring, one can replace ED by min and 0 by + in the pseudocode of Figure 10.7 6 In particular, the algorithm also applies to string subsequentiable transducers and to transducers that output pairs of strings and w</context>
<context position="63364" citStr="Mohri (1994" startWordPosition="11301" endWordPosition="11302"> other semirings. We gave the pseudocode of the algorithm in the general case. The algorithm applies for instance to the real semiring (R,,+,., 0,1). One can also verify that (E*Uf oo}, A, oo, f), where A denotes the longest common prefix operation and • concatenation, oo a new element such that for any string w E (E*U fool), WA oo = co A w = w and w oo oo • w = oo, defines a left semiring.&apos; We call this semiring the string semiring. The algorithm of Figure 10 used with the string semiring is exactly the determinization algorithm for subsequentiable string-to-string transducers, as defined by Mohri (1994c). The cross product of two semirings defines a semiring. The algorithm also applies when the semiring is the cross product of 9 Using the proof of the theorem of the previous section, it is easy to convince oneself that this assertion can be generalized to any rational subset Y of E* such that the restriction of S, the function T realizes, to Y has bounded variation. 10 A left semiring is a semiring that may lack right distributivity. 293 Computational Linguistics Volume 23, Number 2 a:b/3 Figure 13 Transducer Ti with outputs in E* x R. Figure 14 Sequential transducer 72 with outputs in E* x</context>
<context position="64590" citStr="Mohri (1994" startWordPosition="11520" endWordPosition="11521">m (31 by determinization. (E* U fool, A, oo, €) and (R+ U { oo }, min, +, 00, 0), which allows transducers outputting pairs of strings and weights to be determined. The determirtization algorithm for such transducers is illustrated in Figures 13 and 14. Subsets in this algorithm are made of triples (q, w, x) E Q x E* U { oo} x R. U foo}, where q is a state of the initial transducer, w a residual string, and x a residual output weight. 3.7 Minimization We here define a minimization algorithm for subsequential power series defined on the tropical semiring, which extends the algorithm defined by Mohri (1994b) in the case of string-to-string transducers. For any subset L of E* and any string u we define it-lL by: uL = {W: uW E Ll (22) Recall that L is a regular language if there exists a finite number of distinct ttNerode (1958). In a similar way, given a power series S we define a new power series 14-1S by:11 u-is = E (s,uw)w (23) wEE. 11 One can prove that S. a power series defined on a field, is rational if it admits a finite number of independent u-1S (Carlyle and Paz 1971). This is the equivalent, for power series, of Nerode&apos;s theorem for regular languages. 294 Mohri Transducers in Language </context>
<context position="69970" citStr="Mohri (1994" startWordPosition="12622" endWordPosition="12623">be a subsequential transducer realizing a power series on the tropical semiring. Then applying the following two operations: 1. pushing 2. automata minimization leads to a minimal transducer. This minimal transducer is exactly the one defined in the proof of theorem 14. The automata minimization step in the theorem consists of considering pairs of input labels and associated weights as a single label and of applying classical minimization algorithms for automata (Aho, Hoperoft, and Ullman 1974). We do not give the proof of the theorem; it can be proved in a way similar to what is indicated in Mohri (1994b). In general, there are several distinct minimal subsequential transducers realizing the same function. Pushing introduces an equivalence relation on minimal transducers: T Rp T&apos; if p(T) -= p(T&apos;), where p(T) (resp. p(T&apos;)) denotes the transducer obtained from T (resp. T&apos;) by pushing. Indeed, if T and T&apos; are minimal transducers realizing the same function, then p(T) and p(T&apos;) are both equal to the unique minimal transducer equivalent to T and T&apos; as defined in theorem 14. So, two equivalent minimal transducers only differ by their output labels, they have the same topology. They only differ by </context>
</contexts>
<marker>Mohri, 1994</marker>
<rawString>Mohri, Mehryar. 1994b. Minimization of sequential transducers. Lecture Notes in Computer Science, 807.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
</authors>
<title>On some applications of finite-state automata theory to natural language processing: Representation of morphological dictionaries, compaction, and indexation.</title>
<date>1994</date>
<tech>Technical Report IGM 94-22,</tech>
<institution>Institut Gaspard Monge, Noisy-le-Grand.</institution>
<contexts>
<context position="6643" citStr="Mohri 1994" startWordPosition="950" endWordPosition="951">everal results that show them to be very efficient. Our implementation of the determinization is such that it can be used on the fly: only the necessary part of the transducer needs to be expanded. This plays an important role in the space and time efficiency of speech recognition. The reduction in the size of word lattices that these algorithms provide sheds new light on the complexity of the networks involved in speech processing. 2. Sequential String-to-String Transducers Sequential string-to-string transducers are used in various areas of natural language processing. Both determinization (Mohri 1994c) and minimization algorithms (Mohri 1994b) have been defined for the class of p-subsequential transducers, which includes sequential string-to-string transducers. In this section, the theoretical basis of the use of sequential transducers is described. Classical and new theorems help to indicate the usefulness of these devices as well as their characterization. 270 Mohri Transducers in Language and Speech b:E Figure 1 Example of a sequential transducer. 2.1 Sequential Transducers We consider here sequential transducers, namely, transducers with a deterministic input. At any state of such tra</context>
<context position="10072" citStr="Mohri 1994" startWordPosition="1524" endWordPosition="1525"> a string can then possibly finish with the concatenation of such an output string to the usual output. Such transducers are called subsequential transducers. Language processing often requires a more general extension. Indeed, the ambiguities encountered in language—ambiguity of grammars, of morphological analyzers, or that of pronunciation dictionaries, for instance—cannot be taken into account when using sequential or subsequential transducers. These devices associate at most a single output to a given input. In order to deal with ambiguities, one can introduce p-subsequential transducers (Mohri 1994a), namely transducers provided with at most p final output strings at each final state. Figure 2 gives an example of a 2-subsequential transducer. Here, the input string w = aa gives two distinct outputs aaa and aab. Since one cannot find any reasonable case in language in which the number of ambiguities would be infinite, p-subsequential transducers seem to be sufficient for describing linguistic ambiguities. However, the number of ambiguities could be very large in some cases. Notice that 1-subsequential transducers are exactly the subsequential transducers. Transducers can be considered to</context>
<context position="24852" citStr="Mohri 1994" startWordPosition="4080" endWordPosition="4081">kM + 2N. We have: crp(f (141),f (u2)) &lt; May 11 + k21) c(P(6(i, al)), PO(i,u2))) &lt; kM + 2N = K Thus, f has bounded variation using dip. This ends the proof of the theorem. 2.4 Application to Language Processing We briefly mentioned several theoretical and computational properties of sequential and p-subsequential transducers. These devices are used in many areas of computational linguistics. In all those areas, the determinization algorithm can be used to obtain a p-subsequential transducer (Mohri 1996b), and the minimization algorithm to reduce the size of the p-subsequential transducer used (Mohri 1994b). The composition, union, and equivalence algorithms for subsequential transducers are also useful in many applications. 278 Mohri Transducers in Language and Speech 2.4.1 Representation of Dictionaries. Very large-scale dictionaries can be represented by p-subsequential dictionaries because the number of entries and that of the ambiguities they contain are finite. The corresponding representation offers fast look-up since the recognition does not depend on the size of the dictionary but only on that of the input string considered. The minimization algorithm for sequential and p-subsequentia</context>
<context position="26706" citStr="Mohri 1994" startWordPosition="4349" endWordPosition="4350">al functions. The result of the computation described by Kaplan and Kay (1994) is not necessarily a p-subsequential transducer. But, it can often be determinized using the determinization algorithm for p-subsequentiable transducers. This considerably increases the time efficiency of the transducer. It can be further minimized to reduce its size. These observations can be extended to the case of weighted rewrite rules (Mohri and Sproat 1996). 2.4.3 Syntax. Finite-state machines are also currently used to represent local syntactic constraints (Silberztein 1993; Roche 1993; Karlsson et al. 1995; Mohri 1994d). Linguists can conveniently introduce local grammar transducers that can be used to disambiguate sentences. The number of local grammars for a given language and even for a specific domain can be large. The local grammar transducers are mostly p-subsequential. Determinization and minimization can then be used to make the use of local grammar transducers more time efficient and to reduce their size. Since p-subsequential transducers are closed under composition, the result of the composition of all local grammar transducers is a p-subsequential transducer. The equivalence of local grammars c</context>
<context position="41495" citStr="Mohri 1994" startWordPosition="7057" endWordPosition="7058">3K &gt; 0, Vk &gt; 0, I (0(/, uw,F) — 0 (I, uw&apos; , F)) + k(0(q, v, q) — 61(qc v, q&apos;))I 5 K 0 (q , v, q) — 0 (q&apos; ,v, q&apos;) = 0 Thus r has the twins property This ends the proof of the theorem. 0 3.3 General Determinization Algorithm for Power Series We describe in this section an algorithm for constructing a subsequential transducer 72 = (Q2, 2,F2, E, 62, 0-2, A2,192) equivalent to a given nonsubsequential one TI E, I, F1, Ei, A1, P1). The algorithm extends our determinization algorithm for stringto-string transducers representing p-subsequential functions to the case of transducers outputting weights (Mohri 1994c). Figure 10 gives the pseudocode of the algorithm. We present the algorithm in the general case of a semiring (S, ED, 0, 0, 1) on which the transducer Ti is defined. Indeed, the algorithm we are describing here applies as well to transducers representing power series defined on many other semirings.6 We describe the algorithm in the case of the tropical semiring. For the tropical semiring, one can replace ED by min and 0 by + in the pseudocode of Figure 10.7 6 In particular, the algorithm also applies to string subsequentiable transducers and to transducers that output pairs of strings and w</context>
<context position="63364" citStr="Mohri (1994" startWordPosition="11301" endWordPosition="11302"> other semirings. We gave the pseudocode of the algorithm in the general case. The algorithm applies for instance to the real semiring (R,,+,., 0,1). One can also verify that (E*Uf oo}, A, oo, f), where A denotes the longest common prefix operation and • concatenation, oo a new element such that for any string w E (E*U fool), WA oo = co A w = w and w oo oo • w = oo, defines a left semiring.&apos; We call this semiring the string semiring. The algorithm of Figure 10 used with the string semiring is exactly the determinization algorithm for subsequentiable string-to-string transducers, as defined by Mohri (1994c). The cross product of two semirings defines a semiring. The algorithm also applies when the semiring is the cross product of 9 Using the proof of the theorem of the previous section, it is easy to convince oneself that this assertion can be generalized to any rational subset Y of E* such that the restriction of S, the function T realizes, to Y has bounded variation. 10 A left semiring is a semiring that may lack right distributivity. 293 Computational Linguistics Volume 23, Number 2 a:b/3 Figure 13 Transducer Ti with outputs in E* x R. Figure 14 Sequential transducer 72 with outputs in E* x</context>
<context position="64590" citStr="Mohri (1994" startWordPosition="11520" endWordPosition="11521">m (31 by determinization. (E* U fool, A, oo, €) and (R+ U { oo }, min, +, 00, 0), which allows transducers outputting pairs of strings and weights to be determined. The determirtization algorithm for such transducers is illustrated in Figures 13 and 14. Subsets in this algorithm are made of triples (q, w, x) E Q x E* U { oo} x R. U foo}, where q is a state of the initial transducer, w a residual string, and x a residual output weight. 3.7 Minimization We here define a minimization algorithm for subsequential power series defined on the tropical semiring, which extends the algorithm defined by Mohri (1994b) in the case of string-to-string transducers. For any subset L of E* and any string u we define it-lL by: uL = {W: uW E Ll (22) Recall that L is a regular language if there exists a finite number of distinct ttNerode (1958). In a similar way, given a power series S we define a new power series 14-1S by:11 u-is = E (s,uw)w (23) wEE. 11 One can prove that S. a power series defined on a field, is rational if it admits a finite number of independent u-1S (Carlyle and Paz 1971). This is the equivalent, for power series, of Nerode&apos;s theorem for regular languages. 294 Mohri Transducers in Language </context>
<context position="69970" citStr="Mohri (1994" startWordPosition="12622" endWordPosition="12623">be a subsequential transducer realizing a power series on the tropical semiring. Then applying the following two operations: 1. pushing 2. automata minimization leads to a minimal transducer. This minimal transducer is exactly the one defined in the proof of theorem 14. The automata minimization step in the theorem consists of considering pairs of input labels and associated weights as a single label and of applying classical minimization algorithms for automata (Aho, Hoperoft, and Ullman 1974). We do not give the proof of the theorem; it can be proved in a way similar to what is indicated in Mohri (1994b). In general, there are several distinct minimal subsequential transducers realizing the same function. Pushing introduces an equivalence relation on minimal transducers: T Rp T&apos; if p(T) -= p(T&apos;), where p(T) (resp. p(T&apos;)) denotes the transducer obtained from T (resp. T&apos;) by pushing. Indeed, if T and T&apos; are minimal transducers realizing the same function, then p(T) and p(T&apos;) are both equal to the unique minimal transducer equivalent to T and T&apos; as defined in theorem 14. So, two equivalent minimal transducers only differ by their output labels, they have the same topology. They only differ by </context>
</contexts>
<marker>Mohri, 1994</marker>
<rawString>Mohri, Mehryar. 1994c. On some applications of finite-state automata theory to natural language processing: Representation of morphological dictionaries, compaction, and indexation. Technical Report IGM 94-22, Institut Gaspard Monge, Noisy-le-Grand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
</authors>
<title>Syntactic analysis by local grammars automata: An efficient algorithm.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Conference on Computational Lexicography (COMPLEX 94). Linguistic Institute, Hungarian Academy of Science,</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="6643" citStr="Mohri 1994" startWordPosition="950" endWordPosition="951">everal results that show them to be very efficient. Our implementation of the determinization is such that it can be used on the fly: only the necessary part of the transducer needs to be expanded. This plays an important role in the space and time efficiency of speech recognition. The reduction in the size of word lattices that these algorithms provide sheds new light on the complexity of the networks involved in speech processing. 2. Sequential String-to-String Transducers Sequential string-to-string transducers are used in various areas of natural language processing. Both determinization (Mohri 1994c) and minimization algorithms (Mohri 1994b) have been defined for the class of p-subsequential transducers, which includes sequential string-to-string transducers. In this section, the theoretical basis of the use of sequential transducers is described. Classical and new theorems help to indicate the usefulness of these devices as well as their characterization. 270 Mohri Transducers in Language and Speech b:E Figure 1 Example of a sequential transducer. 2.1 Sequential Transducers We consider here sequential transducers, namely, transducers with a deterministic input. At any state of such tra</context>
<context position="10072" citStr="Mohri 1994" startWordPosition="1524" endWordPosition="1525"> a string can then possibly finish with the concatenation of such an output string to the usual output. Such transducers are called subsequential transducers. Language processing often requires a more general extension. Indeed, the ambiguities encountered in language—ambiguity of grammars, of morphological analyzers, or that of pronunciation dictionaries, for instance—cannot be taken into account when using sequential or subsequential transducers. These devices associate at most a single output to a given input. In order to deal with ambiguities, one can introduce p-subsequential transducers (Mohri 1994a), namely transducers provided with at most p final output strings at each final state. Figure 2 gives an example of a 2-subsequential transducer. Here, the input string w = aa gives two distinct outputs aaa and aab. Since one cannot find any reasonable case in language in which the number of ambiguities would be infinite, p-subsequential transducers seem to be sufficient for describing linguistic ambiguities. However, the number of ambiguities could be very large in some cases. Notice that 1-subsequential transducers are exactly the subsequential transducers. Transducers can be considered to</context>
<context position="24852" citStr="Mohri 1994" startWordPosition="4080" endWordPosition="4081">kM + 2N. We have: crp(f (141),f (u2)) &lt; May 11 + k21) c(P(6(i, al)), PO(i,u2))) &lt; kM + 2N = K Thus, f has bounded variation using dip. This ends the proof of the theorem. 2.4 Application to Language Processing We briefly mentioned several theoretical and computational properties of sequential and p-subsequential transducers. These devices are used in many areas of computational linguistics. In all those areas, the determinization algorithm can be used to obtain a p-subsequential transducer (Mohri 1996b), and the minimization algorithm to reduce the size of the p-subsequential transducer used (Mohri 1994b). The composition, union, and equivalence algorithms for subsequential transducers are also useful in many applications. 278 Mohri Transducers in Language and Speech 2.4.1 Representation of Dictionaries. Very large-scale dictionaries can be represented by p-subsequential dictionaries because the number of entries and that of the ambiguities they contain are finite. The corresponding representation offers fast look-up since the recognition does not depend on the size of the dictionary but only on that of the input string considered. The minimization algorithm for sequential and p-subsequentia</context>
<context position="26706" citStr="Mohri 1994" startWordPosition="4349" endWordPosition="4350">al functions. The result of the computation described by Kaplan and Kay (1994) is not necessarily a p-subsequential transducer. But, it can often be determinized using the determinization algorithm for p-subsequentiable transducers. This considerably increases the time efficiency of the transducer. It can be further minimized to reduce its size. These observations can be extended to the case of weighted rewrite rules (Mohri and Sproat 1996). 2.4.3 Syntax. Finite-state machines are also currently used to represent local syntactic constraints (Silberztein 1993; Roche 1993; Karlsson et al. 1995; Mohri 1994d). Linguists can conveniently introduce local grammar transducers that can be used to disambiguate sentences. The number of local grammars for a given language and even for a specific domain can be large. The local grammar transducers are mostly p-subsequential. Determinization and minimization can then be used to make the use of local grammar transducers more time efficient and to reduce their size. Since p-subsequential transducers are closed under composition, the result of the composition of all local grammar transducers is a p-subsequential transducer. The equivalence of local grammars c</context>
<context position="41495" citStr="Mohri 1994" startWordPosition="7057" endWordPosition="7058">3K &gt; 0, Vk &gt; 0, I (0(/, uw,F) — 0 (I, uw&apos; , F)) + k(0(q, v, q) — 61(qc v, q&apos;))I 5 K 0 (q , v, q) — 0 (q&apos; ,v, q&apos;) = 0 Thus r has the twins property This ends the proof of the theorem. 0 3.3 General Determinization Algorithm for Power Series We describe in this section an algorithm for constructing a subsequential transducer 72 = (Q2, 2,F2, E, 62, 0-2, A2,192) equivalent to a given nonsubsequential one TI E, I, F1, Ei, A1, P1). The algorithm extends our determinization algorithm for stringto-string transducers representing p-subsequential functions to the case of transducers outputting weights (Mohri 1994c). Figure 10 gives the pseudocode of the algorithm. We present the algorithm in the general case of a semiring (S, ED, 0, 0, 1) on which the transducer Ti is defined. Indeed, the algorithm we are describing here applies as well to transducers representing power series defined on many other semirings.6 We describe the algorithm in the case of the tropical semiring. For the tropical semiring, one can replace ED by min and 0 by + in the pseudocode of Figure 10.7 6 In particular, the algorithm also applies to string subsequentiable transducers and to transducers that output pairs of strings and w</context>
<context position="63364" citStr="Mohri (1994" startWordPosition="11301" endWordPosition="11302"> other semirings. We gave the pseudocode of the algorithm in the general case. The algorithm applies for instance to the real semiring (R,,+,., 0,1). One can also verify that (E*Uf oo}, A, oo, f), where A denotes the longest common prefix operation and • concatenation, oo a new element such that for any string w E (E*U fool), WA oo = co A w = w and w oo oo • w = oo, defines a left semiring.&apos; We call this semiring the string semiring. The algorithm of Figure 10 used with the string semiring is exactly the determinization algorithm for subsequentiable string-to-string transducers, as defined by Mohri (1994c). The cross product of two semirings defines a semiring. The algorithm also applies when the semiring is the cross product of 9 Using the proof of the theorem of the previous section, it is easy to convince oneself that this assertion can be generalized to any rational subset Y of E* such that the restriction of S, the function T realizes, to Y has bounded variation. 10 A left semiring is a semiring that may lack right distributivity. 293 Computational Linguistics Volume 23, Number 2 a:b/3 Figure 13 Transducer Ti with outputs in E* x R. Figure 14 Sequential transducer 72 with outputs in E* x</context>
<context position="64590" citStr="Mohri (1994" startWordPosition="11520" endWordPosition="11521">m (31 by determinization. (E* U fool, A, oo, €) and (R+ U { oo }, min, +, 00, 0), which allows transducers outputting pairs of strings and weights to be determined. The determirtization algorithm for such transducers is illustrated in Figures 13 and 14. Subsets in this algorithm are made of triples (q, w, x) E Q x E* U { oo} x R. U foo}, where q is a state of the initial transducer, w a residual string, and x a residual output weight. 3.7 Minimization We here define a minimization algorithm for subsequential power series defined on the tropical semiring, which extends the algorithm defined by Mohri (1994b) in the case of string-to-string transducers. For any subset L of E* and any string u we define it-lL by: uL = {W: uW E Ll (22) Recall that L is a regular language if there exists a finite number of distinct ttNerode (1958). In a similar way, given a power series S we define a new power series 14-1S by:11 u-is = E (s,uw)w (23) wEE. 11 One can prove that S. a power series defined on a field, is rational if it admits a finite number of independent u-1S (Carlyle and Paz 1971). This is the equivalent, for power series, of Nerode&apos;s theorem for regular languages. 294 Mohri Transducers in Language </context>
<context position="69970" citStr="Mohri (1994" startWordPosition="12622" endWordPosition="12623">be a subsequential transducer realizing a power series on the tropical semiring. Then applying the following two operations: 1. pushing 2. automata minimization leads to a minimal transducer. This minimal transducer is exactly the one defined in the proof of theorem 14. The automata minimization step in the theorem consists of considering pairs of input labels and associated weights as a single label and of applying classical minimization algorithms for automata (Aho, Hoperoft, and Ullman 1974). We do not give the proof of the theorem; it can be proved in a way similar to what is indicated in Mohri (1994b). In general, there are several distinct minimal subsequential transducers realizing the same function. Pushing introduces an equivalence relation on minimal transducers: T Rp T&apos; if p(T) -= p(T&apos;), where p(T) (resp. p(T&apos;)) denotes the transducer obtained from T (resp. T&apos;) by pushing. Indeed, if T and T&apos; are minimal transducers realizing the same function, then p(T) and p(T&apos;) are both equal to the unique minimal transducer equivalent to T and T&apos; as defined in theorem 14. So, two equivalent minimal transducers only differ by their output labels, they have the same topology. They only differ by </context>
</contexts>
<marker>Mohri, 1994</marker>
<rawString>Mohri, Mehryar. 1994d. Syntactic analysis by local grammars automata: An efficient algorithm. In Proceedings of the International Conference on Computational Lexicography (COMPLEX 94). Linguistic Institute, Hungarian Academy of Science, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
</authors>
<title>Matching patterns of an automaton.</title>
<date>1995</date>
<journal>Lecture Notes in Computer Science,</journal>
<pages>937</pages>
<contexts>
<context position="82574" citStr="Mohri 1995" startWordPosition="14669" endWordPosition="14670"> determinization to the cases where 1W2 I I W1 its complexity is polynomial in terms of the size of the initial transducer I Wi I. This also 15 The notion of ambiguity of a finite automaton can be formalized conveniently using the tropical semiring. Many important studies of the degree of ambiguity of automata have been done in connection with the study of the properties of this semiring (Simon 1987). 16 A more specific determinization can be used in the cases often encountered in natural language processing where the graph admits a loop at the initial state over the elements of the alphabet (Mohri 1995). 301 Computational Linguistics Volume 23, Number 2 411.11111111&amp;quot;0-`0 Figure 18 Word lattice W1, ATIS task, for the utterance Which flights leave Detroit and arrive at Saint Petersburg around nine a.m.? 302 Mohri Transducers in Language and Speech Figure 19 Equivalent word lattice W2 obtained by detenninization of W1. Figure 20 Equivalent word lattice W3 obtained by minimization from W2. rescoring Figure 21 Rescoring. applies to the space complexity of the algorithm. In practice, the algorithm appears to be very efficient. As an example, it took about 0.02s on a Silicon Graphics (Indy 100 MHZ </context>
</contexts>
<marker>Mohri, 1995</marker>
<rawString>Mohri, Mehryar. 1995. Matching patterns of an automaton. Lecture Notes in Computer Science, 937.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
</authors>
<title>On The Use of Sequential Transducers</title>
<date>1996</date>
<booktitle>in Natural Language Processing. In Yves Shabes, editor, Finite State Devices in Natural Language Processing.</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<note>To appear.</note>
<contexts>
<context position="16323" citStr="Mohri (1996" startWordPosition="2601" endWordPosition="2602">te that we denote by an underscore. The transitions leaving (qi, q2) are obtained by taking the union of the transitions leaving qi and q2, or by keeping only those of qi if q2 is the underscore state, similarly by keeping only those of q2 if qi is the underscore state. The union of the transitions is performed in such a way that if qi and q2 both have transitions labeled with the same input label a, then only one transition labeled with a is associated to (qi, q2). The output label of that transition is the longest common prefix of the output transitions labeled with a leaving qi and q2. See Mohri (1996b) for a full description of this algorithm. Figure 5 shows the 2-subsequential transducer obtained by constructing the union of the transducers 7-1 and T2 this way. Notice that according to the theorem the result could be a priori 3-subsequential, but these two transducers share no common accepted string. In such cases, the resulting transducer is max(p, q)-subsequential. 2.3 Characterization and Extensions The linear complexity of their use makes sequential or p-subsequential transducers both mathematically and computationally of particular interest. However, not all transducers, even when t</context>
<context position="24748" citStr="Mohri 1996" startWordPosition="4065" endWordPosition="4066">u)cr (6(i, u), vi)pi (S(i, 140): 1 j &lt; (8) f (u2) = {o-(i, u)o- (6(i, u), v2)p1(8(i, u2)): 1 &lt;j Let K = kM + 2N. We have: crp(f (141),f (u2)) &lt; May 11 + k21) c(P(6(i, al)), PO(i,u2))) &lt; kM + 2N = K Thus, f has bounded variation using dip. This ends the proof of the theorem. 2.4 Application to Language Processing We briefly mentioned several theoretical and computational properties of sequential and p-subsequential transducers. These devices are used in many areas of computational linguistics. In all those areas, the determinization algorithm can be used to obtain a p-subsequential transducer (Mohri 1996b), and the minimization algorithm to reduce the size of the p-subsequential transducer used (Mohri 1994b). The composition, union, and equivalence algorithms for subsequential transducers are also useful in many applications. 278 Mohri Transducers in Language and Speech 2.4.1 Representation of Dictionaries. Very large-scale dictionaries can be represented by p-subsequential dictionaries because the number of entries and that of the ambiguities they contain are finite. The corresponding representation offers fast look-up since the recognition does not depend on the size of the dictionary but o</context>
<context position="27515" citStr="Mohri (1996" startWordPosition="4469" endWordPosition="4470"> large. The local grammar transducers are mostly p-subsequential. Determinization and minimization can then be used to make the use of local grammar transducers more time efficient and to reduce their size. Since p-subsequential transducers are closed under composition, the result of the composition of all local grammar transducers is a p-subsequential transducer. The equivalence of local grammars can also be tested using the equivalence algorithm for sequential transducers. For a more detailed overview of the applications of sequential string to string transducers to language processing, see Mohri (1996a). Because they are so time and space efficient, sequential transducers will likely be used increasingly often in natural language processing as well as in other connected fields. In the following, we consider the case of string-to-weight transducers, which are also used in many areas of computational linguistics. 3. Power Series and Subsequential String-to-Weight Transducers We consider string-to-weight transducers, namely transducers with input strings and output weights. These transducers are used in various domains, such as language modeling, representation of word or phonetic lattices, e</context>
<context position="89550" citStr="Mohri 1996" startWordPosition="15756" endWordPosition="15757">that we introduced makes it conceptually easier to describe many algorithms and properties. Subsequential transducers admit very efficient algorithms. The determinization and minimization algorithms in the case of string-to-weight transducers presented here complete a large series of algorithms that have been shown to give remarkable results in natural language processing. Sequential machines lead to useful algorithms in many other areas of computational linguistics. In particular, subsequential power series allow for efficient results in indexation of natural language texts (Crochemore 1986; Mohri 1996b). We briefly illustrated the application of these algorithms to speech recognition. More precision in acoustic modeling, finer language models, large lexicon grammars, and a larger vocabulary will lead, in the near future, to networks of much larger sizes in speech recognition. The determinization and minimization algorithms might help to limit the size of these networks while maintaining their time efficiency. These algorithms can also be used in text-to-speech synthesis. In fact, the same operations of composition of transducers (Sproat 1995) and perhaps more important size issues can be f</context>
</contexts>
<marker>Mohri, 1996</marker>
<rawString>Mohri, Mehryar, 1996a. On The Use of Sequential Transducers in Natural Language Processing. In Yves Shabes, editor, Finite State Devices in Natural Language Processing. MIT Press, Cambridge, MA. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
</authors>
<title>On some applications of finite-state automata theory to natural language processing.</title>
<date>1996</date>
<journal>Journal of Natural Language Engineering,</journal>
<pages>2--1</pages>
<contexts>
<context position="16323" citStr="Mohri (1996" startWordPosition="2601" endWordPosition="2602">te that we denote by an underscore. The transitions leaving (qi, q2) are obtained by taking the union of the transitions leaving qi and q2, or by keeping only those of qi if q2 is the underscore state, similarly by keeping only those of q2 if qi is the underscore state. The union of the transitions is performed in such a way that if qi and q2 both have transitions labeled with the same input label a, then only one transition labeled with a is associated to (qi, q2). The output label of that transition is the longest common prefix of the output transitions labeled with a leaving qi and q2. See Mohri (1996b) for a full description of this algorithm. Figure 5 shows the 2-subsequential transducer obtained by constructing the union of the transducers 7-1 and T2 this way. Notice that according to the theorem the result could be a priori 3-subsequential, but these two transducers share no common accepted string. In such cases, the resulting transducer is max(p, q)-subsequential. 2.3 Characterization and Extensions The linear complexity of their use makes sequential or p-subsequential transducers both mathematically and computationally of particular interest. However, not all transducers, even when t</context>
<context position="24748" citStr="Mohri 1996" startWordPosition="4065" endWordPosition="4066">u)cr (6(i, u), vi)pi (S(i, 140): 1 j &lt; (8) f (u2) = {o-(i, u)o- (6(i, u), v2)p1(8(i, u2)): 1 &lt;j Let K = kM + 2N. We have: crp(f (141),f (u2)) &lt; May 11 + k21) c(P(6(i, al)), PO(i,u2))) &lt; kM + 2N = K Thus, f has bounded variation using dip. This ends the proof of the theorem. 2.4 Application to Language Processing We briefly mentioned several theoretical and computational properties of sequential and p-subsequential transducers. These devices are used in many areas of computational linguistics. In all those areas, the determinization algorithm can be used to obtain a p-subsequential transducer (Mohri 1996b), and the minimization algorithm to reduce the size of the p-subsequential transducer used (Mohri 1994b). The composition, union, and equivalence algorithms for subsequential transducers are also useful in many applications. 278 Mohri Transducers in Language and Speech 2.4.1 Representation of Dictionaries. Very large-scale dictionaries can be represented by p-subsequential dictionaries because the number of entries and that of the ambiguities they contain are finite. The corresponding representation offers fast look-up since the recognition does not depend on the size of the dictionary but o</context>
<context position="27515" citStr="Mohri (1996" startWordPosition="4469" endWordPosition="4470"> large. The local grammar transducers are mostly p-subsequential. Determinization and minimization can then be used to make the use of local grammar transducers more time efficient and to reduce their size. Since p-subsequential transducers are closed under composition, the result of the composition of all local grammar transducers is a p-subsequential transducer. The equivalence of local grammars can also be tested using the equivalence algorithm for sequential transducers. For a more detailed overview of the applications of sequential string to string transducers to language processing, see Mohri (1996a). Because they are so time and space efficient, sequential transducers will likely be used increasingly often in natural language processing as well as in other connected fields. In the following, we consider the case of string-to-weight transducers, which are also used in many areas of computational linguistics. 3. Power Series and Subsequential String-to-Weight Transducers We consider string-to-weight transducers, namely transducers with input strings and output weights. These transducers are used in various domains, such as language modeling, representation of word or phonetic lattices, e</context>
<context position="89550" citStr="Mohri 1996" startWordPosition="15756" endWordPosition="15757">that we introduced makes it conceptually easier to describe many algorithms and properties. Subsequential transducers admit very efficient algorithms. The determinization and minimization algorithms in the case of string-to-weight transducers presented here complete a large series of algorithms that have been shown to give remarkable results in natural language processing. Sequential machines lead to useful algorithms in many other areas of computational linguistics. In particular, subsequential power series allow for efficient results in indexation of natural language texts (Crochemore 1986; Mohri 1996b). We briefly illustrated the application of these algorithms to speech recognition. More precision in acoustic modeling, finer language models, large lexicon grammars, and a larger vocabulary will lead, in the near future, to networks of much larger sizes in speech recognition. The determinization and minimization algorithms might help to limit the size of these networks while maintaining their time efficiency. These algorithms can also be used in text-to-speech synthesis. In fact, the same operations of composition of transducers (Sproat 1995) and perhaps more important size issues can be f</context>
</contexts>
<marker>Mohri, 1996</marker>
<rawString>Mohri, Mehryar. 1996b. On some applications of finite-state automata theory to natural language processing. Journal of Natural Language Engineering, 2:1-20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Fernando C N Pereira</author>
<author>Michael Riley</author>
</authors>
<title>Weighted automata in text and speech processing.</title>
<date>1996</date>
<booktitle>In ECAI-96 Workshop,</booktitle>
<publisher>ECAI.</publisher>
<location>Budapest, Hungary.</location>
<marker>Mohri, Pereira, Riley, 1996</marker>
<rawString>Mohri, Mehryar, Fernando C. N. Pereira, and Michael Riley. 1996. Weighted automata in text and speech processing. In ECAI-96 Workshop, Budapest, Hungary. ECAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Richard Sproat</author>
</authors>
<title>An efficient compiler for weighted rewrite rules.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Santa Cruz, California.</location>
<contexts>
<context position="26540" citStr="Mohri and Sproat 1996" startWordPosition="4323" endWordPosition="4326">t phonological and morphological rules can be represented by finite-state transducers (Kaplan and Kay 1994). Most phonological and morphological rules correspond to p-subsequential functions. The result of the computation described by Kaplan and Kay (1994) is not necessarily a p-subsequential transducer. But, it can often be determinized using the determinization algorithm for p-subsequentiable transducers. This considerably increases the time efficiency of the transducer. It can be further minimized to reduce its size. These observations can be extended to the case of weighted rewrite rules (Mohri and Sproat 1996). 2.4.3 Syntax. Finite-state machines are also currently used to represent local syntactic constraints (Silberztein 1993; Roche 1993; Karlsson et al. 1995; Mohri 1994d). Linguists can conveniently introduce local grammar transducers that can be used to disambiguate sentences. The number of local grammars for a given language and even for a specific domain can be large. The local grammar transducers are mostly p-subsequential. Determinization and minimization can then be used to make the use of local grammar transducers more time efficient and to reduce their size. Since p-subsequential transdu</context>
</contexts>
<marker>Mohri, Sproat, 1996</marker>
<rawString>Mohri, Mehryar and Richard Sproat. 1996. An efficient compiler for weighted rewrite rules. In Proceedings of the 34th Annual Meeting, Santa Cruz, California. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anil Nerode</author>
</authors>
<title>Linear automaton transformations.</title>
<date>1958</date>
<booktitle>In Proceedings of AMS,</booktitle>
<volume>9</volume>
<contexts>
<context position="64815" citStr="Nerode (1958)" startWordPosition="11564" endWordPosition="11566">ustrated in Figures 13 and 14. Subsets in this algorithm are made of triples (q, w, x) E Q x E* U { oo} x R. U foo}, where q is a state of the initial transducer, w a residual string, and x a residual output weight. 3.7 Minimization We here define a minimization algorithm for subsequential power series defined on the tropical semiring, which extends the algorithm defined by Mohri (1994b) in the case of string-to-string transducers. For any subset L of E* and any string u we define it-lL by: uL = {W: uW E Ll (22) Recall that L is a regular language if there exists a finite number of distinct ttNerode (1958). In a similar way, given a power series S we define a new power series 14-1S by:11 u-is = E (s,uw)w (23) wEE. 11 One can prove that S. a power series defined on a field, is rational if it admits a finite number of independent u-1S (Carlyle and Paz 1971). This is the equivalent, for power series, of Nerode&apos;s theorem for regular languages. 294 Mohri Transducers in Language and Speech For any subsequential power series S we can now define the following relation on E*: `Au, V) E E*, u Rs v &lt; &gt; k E 7Z, (u-1 supp(S) = v-1 supp(S)) and au-1 S - V-1 Si /u—tsupp(S) = k) (24) It is easy to show that Rs</context>
</contexts>
<marker>Nerode, 1958</marker>
<rawString>Nerode, Anil. 1958. Linear automaton transformations. In Proceedings of AMS, volume 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>Michael Riley</author>
</authors>
<title>Weighted Rational Transductions and their Application to Human Language Processing.</title>
<date>1996</date>
<booktitle>Finite State Devices in Natural Language Processing.</booktitle>
<editor>In Yves Shabes, editor,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<note>To appear.</note>
<contexts>
<context position="77669" citStr="Pereira and Riley 1996" startWordPosition="13847" endWordPosition="13850">robabilities. They are added along a path. For a given string, there might be many different paths in a transducer. Only the minimum of the total weights of these paths is considered relevant. Thus, the main operations involved in the interpretation of these transducers are addition and min, namely those of the tropical semiring. Thus, the algorithms we defined in the previous sections apply to speech recognition. The domain of the speech recognition systems above signal processing can be represented by a composition of finite-state transducers outputting weights, or both strings and weights (Pereira and Riley 1996; Mohri, Pereira, and Riley 1996): GoL 0 Co A 0 where 0 represents the acoustic observations, A the acoustic model mapping sequences of acoustic observations to context-dependent phones, C the context-dependency model mapping sequences of context-dependent phones to (context-independent) phones, L a pronunciation dictionary mapping sequences of phones to words, and G a language model or grammar mapping sequences of words to sentences. In general, this cascade of compositions cannot be explicitly expanded, because of the large size of the compositions; an approximation method is required to sea</context>
<context position="86942" citStr="Pereira and Riley 1996" startWordPosition="15365" endWordPosition="15368">onstruction of these transitions do not depend directly on the previous subsets constructed. We have produced an implementation of the determinization that allows one both to completely expand the result or to expand it on demand. Arcs leaving a state of 304 Mohri Transducers in Language and Speech the determinized transducer are expanded only if necessary This characteristic of the implementation is important. It can then be used, for instance, at any step in an onthe-fly cascade of composition of transducers in speech recognition to expand only the necessary part of a lattice or transducer (Pereira and Riley 1996; Mohri, Pereira, and Riley 1996). One of the essential implications of the implementation is that it contributes to saving space during the search stage. It is also very useful in speeding up the n-best decoder in speech recognition.&apos; The determinization and minimization algorithms for string-to-weight transducers seem to have other applications in speech processing. Many new experiments can be done using these algorithms at different stages of speech recognition, which might lead to the reshaping of some of the methods used in this field and create a renewed interest in the theory of automat</context>
</contexts>
<marker>Pereira, Riley, 1996</marker>
<rawString>Pereira, Fernando C. N. and Michael Riley, 1996. Weighted Rational Transductions and their Application to Human Language Processing. In Yves Shabes, editor, Finite State Devices in Natural Language Processing. MIT Press, Cambridge, MA. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominique Perrin</author>
</authors>
<title>Finite automata.</title>
<date>1990</date>
<booktitle>Handbook of Theoretical Computer Science, Volume B: Formal Models and Semantics. Elsevier, Mohri Transducers in Language and Speech Amsterdam,</booktitle>
<pages>1--57</pages>
<editor>In J. Van Leuwen, editor,</editor>
<contexts>
<context position="2402" citStr="Perrin 1990" startWordPosition="338" endWordPosition="339">space efficiency. Time efficiency is usually achieved using deterministic automata. The output of deterministic machines depends, in general linearly, only on the input size and can therefore be considered optimal from this point of view. Space efficiency is achieved with classical minimization algorithms (Aho, Hoperoft, and Ullman 1974) for deterministic automata. Applications such as compiler construction have shown deterministic finite automata to be very efficient in practice (Aho, Sethi, and Ullman 1986). Finite automata now also constitute a rich chapter of theoretical computer science (Perrin 1990). Their recent applications in natural language processing, which range from the construction of lexical analyzers (Silverztein 1993) and the compilation of morphological and phonological rules (Kaplan and Kay 1994; Karttunen, Kaplan and Zaenen 1992) to speech processing (Mohri, Pereira, and Riley 1996) show the usefulness of finite-state machines in many areas. In this paper, we provide theoretical and algorithmic bases for the use and application of the devices that support very efficient programs: sequential transducers. * 600 Mountain Avenue, Murray Hill, NJ 07974, USA. C) 1997 Association</context>
</contexts>
<marker>Perrin, 1990</marker>
<rawString>Perrin, Dominique. 1990. Finite automata. In J. Van Leuwen, editor, Handbook of Theoretical Computer Science, Volume B: Formal Models and Semantics. Elsevier, Mohri Transducers in Language and Speech Amsterdam, pages 1-57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christophe Reutenauer</author>
<author>Marcel Paul Schutzenberger</author>
</authors>
<title>Varidt6s et fonctions rationnelles.</title>
<date>1995</date>
<journal>Theoretical Computer Science,</journal>
<volume>145</volume>
<marker>Reutenauer, Schutzenberger, 1995</marker>
<rawString>Reutenauer, Christophe and Marcel Paul Schutzenberger. 1995. Varidt6s et fonctions rationnelles. Theoretical Computer Science, 145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominique Revuz</author>
</authors>
<title>Minimisation of acyclic deterministic automata in linear time.</title>
<date>1992</date>
<journal>Theoretical Computer Science,</journal>
<pages>92--181</pages>
<contexts>
<context position="72139" citStr="Revuz 1992" startWordPosition="12997" endWordPosition="12998"> by E the set of transitions of T. The complexity of pushing is therefore linear (0(1Q1+1E1)) if the transducer is acyclic. In the general case, the complexity of pushing is 0(1Ellog IQ&apos;) if we use classical heaps, 0(1E1 + IQ&apos; log 1 (21 ) if we use Fibonacci heaps, and 0(1Ellog log IQ) if we use the efficient implementation of priority queues by Thorup (1996). In case the maximum output weight W is small, we can use the algorithm of Ahuja et al. (1988); the complexity of pushing is then 0(1E1+ 1(21-0w1). In case the transducer is acyclic, we can use a specific automata minimization algorithm (Revuz 1992) with linear time complexity, 0(1(21 + 1E1). In the general case, an efficient implementation of Hoperoft&apos;s algorithm (Aho, Hoperoft, and Ullman 1974) leads to 0(1ElloglQ1). Thus, the overall complexity of the minimization of subsequential transducers is always as good as that of classical automata minimization: 0(1(21 + 1El) in the acyclic case, and 0(1Ellog1Q1) in the general case. Figures 15 to 17 illustrate the minimization algorithm. 31 (Figure 15) represents a subsequential string-to-weight transducer. Notice that the size of )31 cannot be reduced using the automata minimization. represe</context>
</contexts>
<marker>Revuz, 1992</marker>
<rawString>Revuz, Dominique. 1992. Minimisation of acyclic deterministic automata in linear time. Theoretical Computer Science, 92:181-189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmanuel Roche</author>
</authors>
<title>Analyse syntaxique transformationnelle du francais par transducteurs et lexique-grammaire.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<institution>Universite Paris 7,</institution>
<location>Paris.</location>
<contexts>
<context position="26672" citStr="Roche 1993" startWordPosition="4343" endWordPosition="4344"> rules correspond to p-subsequential functions. The result of the computation described by Kaplan and Kay (1994) is not necessarily a p-subsequential transducer. But, it can often be determinized using the determinization algorithm for p-subsequentiable transducers. This considerably increases the time efficiency of the transducer. It can be further minimized to reduce its size. These observations can be extended to the case of weighted rewrite rules (Mohri and Sproat 1996). 2.4.3 Syntax. Finite-state machines are also currently used to represent local syntactic constraints (Silberztein 1993; Roche 1993; Karlsson et al. 1995; Mohri 1994d). Linguists can conveniently introduce local grammar transducers that can be used to disambiguate sentences. The number of local grammars for a given language and even for a specific domain can be large. The local grammar transducers are mostly p-subsequential. Determinization and minimization can then be used to make the use of local grammar transducers more time efficient and to reduce their size. Since p-subsequential transducers are closed under composition, the result of the composition of all local grammar transducers is a p-subsequential transducer. T</context>
</contexts>
<marker>Roche, 1993</marker>
<rawString>Roche, Emmanuel. 1993. Analyse syntaxique transformationnelle du francais par transducteurs et lexique-grammaire. Ph.D. thesis, Universite Paris 7, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arto Salomaa</author>
<author>Matti Soittola</author>
</authors>
<title>Automata-Theoretic Aspects of Formal Power Series.</title>
<date>1978</date>
<publisher>Springer-Verlag,</publisher>
<location>New York.</location>
<contexts>
<context position="31712" citStr="Salomaa and Soittola 1978" startWordPosition="5256" endWordPosition="5259">d string w is then obtained by taking the minimum of the outputs of all successful paths with input label w: min (A(i) + 0(i, w,f) + p(f)) (if)ElxF: fE6(i,w) A transducer T is said to be trim if all states of T belong to a successful path. String-toweight transducers clearly realize functions mapping E* to 12.±. Since the operations we need to consider are addition and min, and since (74 U { oo }, min, +, oo, 0) is a semiring, we call these functions formal power series.&apos; We adopt the terminology and notation used in formal language theory (Berstel and Reutenauer 1988; Kuich and Salomaa 1986; Salomaa and Soittola 1978): • the image by a formal power series S of a string w is denoted by (S, w) and called the coefficient of w in S. • the notation S E. (S,w)w is then used to define a power series by its coefficients, • the support of S is the language defined by: supp(S) = fw E E*: (S, w) oo } The fundamental theorem of Schutzenberger (1961), analogous to Kleene&apos;s theorem for formal languages, states that a formal power series S is rational iff it is recognizable, that is, realizable by a string-to-weight transducer. The semiring (R.+ U { °e}, min, +, 00, 0) used in many optimization problems is called the tro</context>
<context position="88116" citStr="Salomaa and Soittola 1978" startWordPosition="15548" endWordPosition="15551"> create a renewed interest in the theory of automata and transducers. 5. Conclusion We have briefly presented the theoretical bases, algorithmic tools, and practical use of a set of devices that seem to fit the complexity of language and provide efficiency in space and time. From the theoretical point of view, the understanding of these objects is crucial. It helps to describe the possibilities they offer and to guide algorithmic choices. Many new theoretical issues arise when more precision is sought. The notion of determinization can be generalized to that of E-determinization for instance (Salomaa and Soittola 1978, chapter 3, exercise) requiring more general algorithms. It can also be extended to local determinization: determinization at only those states of a transducer that admit a predefined property, such as that of having a large number of outgoing transitions. An important advantage of local determinization is that it can be applied to any transducer without restriction. Furthermore, local determinization also admits an on-the-fly implementation. New characterizations of rational functions shed new light on some aspects of the theory of finite-state transducers (Reutenauer and Schiitzenberger 199</context>
</contexts>
<marker>Salomaa, Soittola, 1978</marker>
<rawString>Salomaa, Arto and Matti Soittola. 1978. Automata-Theoretic Aspects of Formal Power Series. Springer-Verlag, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcel Paul Schiitzenberger</author>
</authors>
<title>On the definition of a family of automata.</title>
<date>1961</date>
<journal>Information and Control,</journal>
<volume>4</volume>
<contexts>
<context position="75488" citStr="Schiitzenberger (1961)" startWordPosition="13515" endWordPosition="13516"> the automata and the equality of their number of states. An efficient algorithm for testing the equivalence of two deterministic automata is given in Aho, Hoperoft, and Ullman (1974).14 Since the min14 The automata minimization step can in fact be omitted if this equivalence algorithm is used, since it does not affect the equivalence of the two subsequential transducers, considered as automata. 299 Computational Linguistics Volume 23, Number 2 imization of subsequential transducers was also shown to be efficient, this proves the corollary and also the efficiency of the test of equivalence. 0 Schiitzenberger (1961) gave an algorithm for minimizing the representation of power series, but this algorithm can only be used when the semiring considered is a field. In particular, it cannot be used with the tropical semiring or the string semiring used in language and speech processing, since none of these semirings is a field. More precisely, a recent result of Krob (1994) states that such a minimization cannot be defined for transducers defined on the tropical semiring. Furthermore, we implemented the algorithm of Schatzenberger (1961) and used it in the case of the semiring (R., +, 0,1). It has two important</context>
</contexts>
<marker>Schiitzenberger, 1961</marker>
<rawString>Schiitzenberger, Marcel Paul. 1961. On the definition of a family of automata. Information and Control, 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcel Paul Schiitzenberger</author>
</authors>
<title>Sur une variante des fonctions s6quentielles. Theoretical Computer Science.</title>
<date>1977</date>
<contexts>
<context position="9424" citStr="Schiitzenberger 1977" startWordPosition="1430" endWordPosition="1431">e extended to mappings from Q x E* by the following classical recurrence relations: Vs E Q, VW E E*, Va E E, 6(s, E) = s, 6(s, wa) -=-- 6(6(s, w), a); o-(s, f) = E, a (s, wa) = o-(s, w)o- (6 (s , w), a). 271 Computational Linguistics Volume 23, Number 2 Figure 2 Example of a 2-subsequential transducer Thus, a string W E E* is accepted by T iff 6(i, w) E F, and in that case the output of the transducer is cr(i, w). 2.2 Subsequential and p-Subsequential Transducers Sequential transducers can be generalized by introducing the possibility of generating an additional output string at final states (Schiitzenberger 1977). The application of the transducer to a string can then possibly finish with the concatenation of such an output string to the usual output. Such transducers are called subsequential transducers. Language processing often requires a more general extension. Indeed, the ambiguities encountered in language—ambiguity of grammars, of morphological analyzers, or that of pronunciation dictionaries, for instance—cannot be taken into account when using sequential or subsequential transducers. These devices associate at most a single output to a given input. In order to deal with ambiguities, one can i</context>
</contexts>
<marker>Schiitzenberger, 1977</marker>
<rawString>Schiitzenberger, Marcel Paul. 1977. Sur une variante des fonctions s6quentielles. Theoretical Computer Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcel Paul Schiitzenberger</author>
</authors>
<title>Polynomial decomposition of rational functions.</title>
<date>1987</date>
<booktitle>In Lecture Notes in Computer Science,</booktitle>
<volume>386</volume>
<publisher>Springer-Verlag,</publisher>
<location>Berlin, Heidelberg, and New York.</location>
<marker>Schiitzenberger, 1987</marker>
<rawString>Schiitzenberger, Marcel Paul. 1987. Polynomial decomposition of rational functions. In Lecture Notes in Computer Science, volume 386. Springer-Verlag, Berlin, Heidelberg, and New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Silberztein</author>
</authors>
<title>Dictionnaires elect roniques et analyse automatique de textes: le systeme INTEX.</title>
<date>1993</date>
<location>Masson, Paris.</location>
<contexts>
<context position="26660" citStr="Silberztein 1993" startWordPosition="4341" endWordPosition="4342"> and morphological rules correspond to p-subsequential functions. The result of the computation described by Kaplan and Kay (1994) is not necessarily a p-subsequential transducer. But, it can often be determinized using the determinization algorithm for p-subsequentiable transducers. This considerably increases the time efficiency of the transducer. It can be further minimized to reduce its size. These observations can be extended to the case of weighted rewrite rules (Mohri and Sproat 1996). 2.4.3 Syntax. Finite-state machines are also currently used to represent local syntactic constraints (Silberztein 1993; Roche 1993; Karlsson et al. 1995; Mohri 1994d). Linguists can conveniently introduce local grammar transducers that can be used to disambiguate sentences. The number of local grammars for a given language and even for a specific domain can be large. The local grammar transducers are mostly p-subsequential. Determinization and minimization can then be used to make the use of local grammar transducers more time efficient and to reduce their size. Since p-subsequential transducers are closed under composition, the result of the composition of all local grammar transducers is a p-subsequential t</context>
</contexts>
<marker>Silberztein, 1993</marker>
<rawString>Silberztein, Max. 1993. Dictionnaires elect roniques et analyse automatique de textes: le systeme INTEX. Masson, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Imre Simon</author>
</authors>
<title>The nondeterministic complexity of finite automata.</title>
<date>1987</date>
<booktitle>Instituto de Matemdtica e Estatistica da Universidade de Sao Paulo.</booktitle>
<tech>Technical Report RT-MAP-8073,</tech>
<contexts>
<context position="82366" citStr="Simon 1987" startWordPosition="14634" endWordPosition="14635">xity of determinization can be expressed in terms of the initial and resulting lattices, W1 and W2, by 0(1E I log II(1W1I1W21)2), where I Wi I and 114,721 denote the sizes of W1 and W2. Clearly if we restrict determinization to the cases where 1W2 I I W1 its complexity is polynomial in terms of the size of the initial transducer I Wi I. This also 15 The notion of ambiguity of a finite automaton can be formalized conveniently using the tropical semiring. Many important studies of the degree of ambiguity of automata have been done in connection with the study of the properties of this semiring (Simon 1987). 16 A more specific determinization can be used in the cases often encountered in natural language processing where the graph admits a loop at the initial state over the elements of the alphabet (Mohri 1995). 301 Computational Linguistics Volume 23, Number 2 411.11111111&amp;quot;0-`0 Figure 18 Word lattice W1, ATIS task, for the utterance Which flights leave Detroit and arrive at Saint Petersburg around nine a.m.? 302 Mohri Transducers in Language and Speech Figure 19 Equivalent word lattice W2 obtained by detenninization of W1. Figure 20 Equivalent word lattice W3 obtained by minimization from W2. r</context>
</contexts>
<marker>Simon, 1987</marker>
<rawString>Simon, Imre. 1987. The nondeterministic complexity of finite automata. Technical Report RT-MAP-8073, Instituto de Matemdtica e Estatistica da Universidade de Sao Paulo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sproat</author>
</authors>
<title>A finite-state architecture for tokenization and grapheme-to-phoneme conversion in multilingual text analysis.</title>
<date>1995</date>
<booktitle>In Proceedings of the ACL SIGDAT Workshop,</booktitle>
<publisher>ACL.</publisher>
<location>Dublin, Ireland.</location>
<contexts>
<context position="90102" citStr="Sproat 1995" startWordPosition="15836" endWordPosition="15837">ation of natural language texts (Crochemore 1986; Mohri 1996b). We briefly illustrated the application of these algorithms to speech recognition. More precision in acoustic modeling, finer language models, large lexicon grammars, and a larger vocabulary will lead, in the near future, to networks of much larger sizes in speech recognition. The determinization and minimization algorithms might help to limit the size of these networks while maintaining their time efficiency. These algorithms can also be used in text-to-speech synthesis. In fact, the same operations of composition of transducers (Sproat 1995) and perhaps more important size issues can be found in this field. 18 We describe this application of determinization elsewhere. 305 Computational Linguistics Volume 23, Number 2 Figure 22 Subsequential power series S nonbisubsequential. Appendix The determinization algorithm for power series can also be used to minimize transducers in many cases. Let us first consider the case of automata. Brzozowski (1962) showed that determinization can be used to minimize automata. This nice result has also been proved more recently in elegant papers by Bauer (1988) and Urbanek (1989). These authors refin</context>
</contexts>
<marker>Sproat, 1995</marker>
<rawString>Sproat, Richard. 1995. A finite-state architecture for tokenization and grapheme-to-phoneme conversion in multilingual text analysis. In Proceedings of the ACL SIGDAT Workshop, Dublin, Ireland. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikkel Thorup</author>
</authors>
<title>On ram priority queues.</title>
<date>1996</date>
<booktitle>In Proceedings of SODA&apos;96,</booktitle>
<publisher>ACM, SIAM,</publisher>
<location>Atlanta,</location>
<contexts>
<context position="71889" citStr="Thorup (1996)" startWordPosition="12954" endWordPosition="12955">d. 297 Computational Linguistics Volume 23, Number 2 Figure 15 Transducer ,31. Figure 16 Transducer yi obtained from by pushing. Once the function d is defined, the transformation of T into T&apos; can be done in linear time, namely 0(1(21+IED, if we denote by E the set of transitions of T. The complexity of pushing is therefore linear (0(1Q1+1E1)) if the transducer is acyclic. In the general case, the complexity of pushing is 0(1Ellog IQ&apos;) if we use classical heaps, 0(1E1 + IQ&apos; log 1 (21 ) if we use Fibonacci heaps, and 0(1Ellog log IQ) if we use the efficient implementation of priority queues by Thorup (1996). In case the maximum output weight W is small, we can use the algorithm of Ahuja et al. (1988); the complexity of pushing is then 0(1E1+ 1(21-0w1). In case the transducer is acyclic, we can use a specific automata minimization algorithm (Revuz 1992) with linear time complexity, 0(1(21 + 1E1). In the general case, an efficient implementation of Hoperoft&apos;s algorithm (Aho, Hoperoft, and Ullman 1974) leads to 0(1ElloglQ1). Thus, the overall complexity of the minimization of subsequential transducers is always as good as that of classical automata minimization: 0(1(21 + 1El) in the acyclic case, a</context>
</contexts>
<marker>Thorup, 1996</marker>
<rawString>Thorup, Mikkel. 1996. On ram priority queues. In Proceedings of SODA&apos;96, Atlanta, Georgia. ACM, SIAM, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Urbanek</author>
</authors>
<title>On minimizing finite automata.</title>
<date>1989</date>
<journal>EATCS Bulletin,</journal>
<volume>39</volume>
<contexts>
<context position="90681" citStr="Urbanek (1989)" startWordPosition="15925" endWordPosition="15926">sition of transducers (Sproat 1995) and perhaps more important size issues can be found in this field. 18 We describe this application of determinization elsewhere. 305 Computational Linguistics Volume 23, Number 2 Figure 22 Subsequential power series S nonbisubsequential. Appendix The determinization algorithm for power series can also be used to minimize transducers in many cases. Let us first consider the case of automata. Brzozowski (1962) showed that determinization can be used to minimize automata. This nice result has also been proved more recently in elegant papers by Bauer (1988) and Urbanek (1989). These authors refine the method to obtain better complexities.19 Theorem 16 (Brzozowski 1962) Let A be a nondeterministic automaton. Then the automaton A&apos; = (Q&apos;, i&apos;,F&apos;,E,6&apos;) obtained by reversing A, applying determinization, rereversing the obtained automaton and determiruizing it is the minimal deterministic automaton equivalent to A. We generalize this theorem to the case of string-to-weight transducers. We say that a rational power series S is bisubsequential when S is subsequential and the power series SR = EwEE. (5, wR)w is also subsequential.&apos; Not all subsequential transducers are bisu</context>
</contexts>
<marker>Urbanek, 1989</marker>
<rawString>Urbanek, F. 1989. On minimizing finite automata. EATCS Bulletin, 39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce W Watson</author>
</authors>
<title>A taxonomy of finite automata minimization algorithms.</title>
<date>1993</date>
<tech>Technical Report 93/44,</tech>
<institution>Eindhoven University of Technology, The Netherlands.</institution>
<contexts>
<context position="91730" citStr="Watson (1993)" startWordPosition="16115" endWordPosition="16116">ower series S is bisubsequential when S is subsequential and the power series SR = EwEE. (5, wR)w is also subsequential.&apos; Not all subsequential transducers are bisubsequential. Figure 22 shows a transducer representing a power series S that is not bisubsequential. S is such that: Vn E JV, (S , ban) = n +1 (27) Vn E Ar, (s,can) = 0 The transducer of Figure 22 is subsequential so S is subsequential. But the reverse SR is not, because it does not have bounded variation. Indeed, since: Vn Ef , (SR , an b) = n + 1 (28) Vn E (SR, anC) = 0 We have: Vn E AT , l(SR , a&amp;quot; b) — (SR , an c)I = n +1 19 See Watson (1993) for a taxonomy of minimization algorithms for automata; see also Courcelle, Niwinsld, and Podelski 1991. 20 For any string w E E*, we denote by wR its reverse. 306 Mohri Transducers in Language and Speech A characterization similar to that of string-to-string transducers (Choffrut 1978) is possible for bisubsequential power series defined on the tropical semiring. In particular, the theorem of the previous sections shows that S is bisubsequential if S and SR have bounded variation. We similarly define bideterminizable transducers as the transducers T defined on the tropical semiring admitting</context>
</contexts>
<marker>Watson, 1993</marker>
<rawString>Watson, Bruce W. 1993. A taxonomy of finite automata minimization algorithms. Technical Report 93/44, Eindhoven University of Technology, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Weber</author>
<author>Reinhard Klemm</author>
</authors>
<title>Economy of description for single-valued transducers.</title>
<date>1995</date>
<journal>Information and Computation,</journal>
<volume>119</volume>
<contexts>
<context position="21004" citStr="Weber and Klemm (1995)" startWordPosition="3376" endWordPosition="3379">t sequential function R is then easy to construct. 276 Mohri Transducers in Language and Speech Sequential transducers offer other theoretical advantages. In particular, while several important tests, such as equivalence, are undecidable with general transducers, sequential transducers have the following decidability property Theorem 5 Let T be a transducer mapping E* to A*. It is decidable whether T is sequential. A constructive proof of this theorem was given by Choffrut (1978). An efficient polynomial algorithm for testing the sequentiability of transducers based on this proof was given by Weber and Klemm (1995). Choffrut also gave a characterization of subsequential functions based on the definition of a metric on E*. Denote by u A v the longest common prefix of two strings u and v in E*. It is easy to verify that the following defines a metric on E*: d(u,v) = lul + Iv&apos; - 2lu A vl (3) The following theorem describes this characterization of subsequential functions. Theorem 6 Let f be a partial function mapping E* to A*. f is subsequential iff: 1. f has bounded variation (according to the metric defined above). 2. for any rational subset Y of A*, f-1(Y) is rational. The notion of bounded variation ca</context>
<context position="59588" citStr="Weber and Klemm (1995)" startWordPosition="10581" endWordPosition="10584">2, q&apos;i). 71 is a trim unambiguous transducer, so: 01(q, v, q) = 01(q, viv3, q) + 01(qi, v2, qi) 01(q&apos; , v, q&apos;) = 01(q&apos; , viv3, q&apos;) + 01(qi, v2, qi) Thus, 01 (q, v, q) = 01(q&apos; , v, q&apos;). This completes the proof of the lemma. 0 Theorem 13 Let T1 -= E1, A1,101) be a trim unambiguous string-to-weight transducer defined on the tropical semiring. There exists an algorithm to test the determinizability of Ti. Proof According to theorem 12, testing the determinizability of TI is equivalent to testing for the twins property We define an algorithm to test this property Our algorithm is close to that of Weber and Klemm (1995) for testing the sequentiability of string-to-string transducers. It is based on the construction of an automaton A = (Q, I, F, E) similar to the cross product of Ti with itself. Let K C 7?, be the finite set of real numbers defined by: K {E(o(t) - a(t)): 1 &lt;k &lt; 21(2112 - 1,Vi &lt; k (ti„t) E We define A by the following: • The set of states of A is defined by Q = xQ1 x K, • The set of initial states by I -= Ii x Ii x {0}, • The set of final states by F = F1 x F1 x K, • The set of transitions by: E = {((q1,q2, c), a, (qii, q&apos;2, c&apos; )) EQx E x Q: 3 (qi, a, x, q2) E Ei, (qi, a, x&apos; (I) E Ei, - c = - </context>
</contexts>
<marker>Weber, Klemm, 1995</marker>
<rawString>Weber, Andreas and Reinhard Klemm. 1995. Economy of description for single-valued transducers. Information and Computation, 119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>Transition network grammars for natural language analysis.</title>
<date>1970</date>
<journal>Communications of the Association for the Computational Machinery,</journal>
<volume>13</volume>
<issue>10</issue>
<contexts>
<context position="1567" citStr="Woods 1970" startWordPosition="217" endWordPosition="218"> both linguistic and computational arguments. Linguistically, finite automata are convenient since they allow one to describe easily most of the relevant local phenomena encountered in the empirical study of language. They often lead to a compact representation of lexical rules, or idioms and clichés, that appears natural to linguists (Gross 1989). Graphic tools also allow one to visualize and modify automata, which helps in correcting and completing a grammar. Other more general phenomena, such as parsing context-free grammars, can also be dealt with using finitestate machines such as RTN&apos;s (Woods 1970). Moreover, the underlying mechanisms in most of the methods used in parsing are related to automata. From the computational point of view, the use of finite-state machines is mainly motivated by considerations of time and space efficiency. Time efficiency is usually achieved using deterministic automata. The output of deterministic machines depends, in general linearly, only on the input size and can therefore be considered optimal from this point of view. Space efficiency is achieved with classical minimization algorithms (Aho, Hoperoft, and Ullman 1974) for deterministic automata. Applicati</context>
</contexts>
<marker>Woods, 1970</marker>
<rawString>Woods, W.A. 1970. Transition network grammars for natural language analysis. Communications of the Association for the Computational Machinery, 13(10).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>