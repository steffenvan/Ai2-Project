<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000100">
<author confidence="0.24677">
Book Reviews Machine Translation Today: The State of the Art (Proceedings of the Third Lugano Tutorial, April 1984)
</author>
<bodyText confidence="0.999289578947369">
It may seem obvious that one understands the utterance
of a novel sentence because one knows the meanings of
the words contained in it and, in some sense, knows a rule
for determining the meaning of the sentence on the basis
of its syntax and the meanings of its words. (p. 179)
Nevertheless, he argues that the evidence for a compo-
sitional truth-theoretic semantics is pretty glib, because
one can give a correct model of language understanding
and productivity without assuming a compositional
truth-theoretic semantics.
In the seventh chapter of the book he suggests a
counterexample to the compositional view about lan-
guage understanding. He describes a possible world in
which a human computer, Harvey, understands a lan-
guage E, as complex as English. The author analyzes
Harvey&apos;s comprehension of some sentences and he
draws a picture in which heuristic tools, such as the
&apos;conceptual roles&apos; of some expressions of Harvey&apos;s
neural language of thought, allow him to show that
&amp;quot;there could be a correct psychological model of a
person&apos;s language processing that does not presuppose
a compositional semantics for the mastered language&amp;quot;
(p. 205).
But one might object that if compositional semantics
is not needed in order to account for language under-
standing, it is needed in order to explain what Schiffer
calls &amp;quot;the platitude&amp;quot;, i.e., the idea that the meanings of
sentences are determined by their syntax and the mean-
ings of their words. In Chapter 8, Schiffer argues against
this objection by introducing other heuristic notions,
such as the &amp;quot;saying-potential&amp;quot; and the &amp;quot;processing
role&amp;quot; of linguistic expression. In the sentence &amp;quot;Michel
believes that his car was stolen&amp;quot;, the word &amp;quot;believes&amp;quot;
has a processing role that determines its saying potential
each time the word is used. &amp;quot;Believes&amp;quot; is a semantic
primitive, &amp;quot;but it is not a semantic primitive in any
sense appropriate to a compositional semantics, for no
base axiom, no satisfaction clause, can be written for
&apos;believes&apos; that could take its place in a true truth theory
for English&amp;quot; (p. 216).
Schiffer does not want to deny all the aspects of
semantic compositionality, nor that natural languages
contain truth-affecting iterative devices (p. 208). What
he denies is the relevance of truth-theoretic semantics
to an account of language understanding and productiv-
ity. He denies that something like analytic philosophy is
possible, but in the meantime he suggests that the
compositionality of natural language should be ex-
plained via cognitive models of linguistic behaviour. At
the very end of his book, he seems to set up an alliance
with cognitive science in order to explain facts about
language which do need explanation. They are facts
about language comprehension, about the ways in
which we store, represent, and process information.
But, Schiffer says, these &amp;quot;are not philosophical ques-
tions (although the skills of the philosopher would be
relevant to answering them)&amp;quot; (p. 271).
</bodyText>
<sectionHeader confidence="0.897074" genericHeader="references">
REFERENCES
</sectionHeader>
<bodyText confidence="0.483137">
Hirst, Graeme 1987 Semantic Interpretation and the Resolution of
Ambiguity, Cambridge University Press, Cambridge, England.
Rorty, R. 1979 Philosophy and the Mirror of Nature, Princeton
</bodyText>
<subsectionHeader confidence="0.195385">
University Press, Princeton, NJ.
</subsectionHeader>
<bodyText confidence="0.866008375">
Wittgenstein, L. 1953 Philosophische Untersuchungen [Philosophical
Investigations], Basil Blackwell, Oxford, England.
Morena Danieli&apos;s thesis was on the semantics of proper
names. Her present interests concern the integration of syntax
and semantics in natural languages. At Olivetti, her research
concerns the development of syntactic tools for language
analysis. Danieli&apos;s address is: Speech and Language Labora-
tory, Olivetti, c.so Svizzera 185, 10149 Torino, Italy.
</bodyText>
<sectionHeader confidence="0.996193666666667" genericHeader="method">
MACHINE TRANSLATION TODAY: THE STATE OF THE
ART (PROCEEDINGS OF THE THIRD LUGANO
TUTORIAL, APRIL 1984)
</sectionHeader>
<subsectionHeader confidence="0.937727">
Margaret King (ed.)
</subsectionHeader>
<affiliation confidence="0.86253275">
(Institute for Semantic and Cognitive Studies,
University of Geneva, Switzerland)
Edinburgh University Press, 1987, xii + 447 pp.
(Edinburgh Information Technology Series 2)
</affiliation>
<figure confidence="0.87630625">
ISBN 0-85224-519-X, £45.00 (hb)
Reviewed by
John Hutchins
University of East Anglia
</figure>
<bodyText confidence="0.993295743243244">
It is always regrettable when the proceedings of confer-
ences appear a long time after they were held, in this
case nearly four years, but it is even more so in a rapidly
changing field such as machine translation (MT). Devel-
opments since this MT tutorial was organized by the
Dalle Molle Institute for Semantic and Cognitive Stud-
ies (ISSCO) in early 1984 mean that many of the
contributions have now predominantly historical inter-
est. They are, however, no less valuable since many are
accounts of MT systems which have not been bettered
in comprehensiveness before or since. In keeping with
its historical character and its originally-intended role as
a general introduction to the state of the art in MT, the
volume contains a mixture of historical surveys, discus-
sions of linguistic and computational problems, and
detailed descriptions of major systems. It does not
include papers on practical implementations of MT
systems, on comparative evaluations of MT output, or
on the impact of MT on the translation industry. Some
readers may regret their absence but the value of the
collection lies precisely in its emphasis on the linguistic
features of MT systems, and on the more theoretical
aspects of MT research. Contributions have been di-
vided into three sections: Part 1, containing essentially
background papers; Part 2, devoted mainly to software;
and Part 3, to accounts of particular MT systems.
Part 1 opens with two general historical overviews by
Beat Buchmann covering MT history until the notorious
ALPAC report in 1966, and by Susan Warwick on
developments since 1966. Although necessarily brief,
Computational Linguistics, Volume 15, Number 2, June 1989 117
Book Reviews Machine Translation Today: The State of the Art (Proceedings of the Third Lugano Tutorial, April 1984)
both are reasonably balanced surveys summarizing
what is now becoming fairly familiar ternitory for most
MT researchers (but which may well not be for others).
Buchmann describes the pioneer efforts of Troyanskii,
Booth, Weaver, Reifler, and Bar-Hillel, the 1952 con-
ference (raising issues that are &amp;quot;still important&amp;quot;), and
evaluates the Georgetown-IBM 1954 experiment, Bar-
Hillel&apos;s influential 1960 survey (seen in hindsight as
&amp;quot;realistic&amp;quot; rather than wholly destructive), the growing
disillusion with &apos;brute-force&apos; methods and with early
theory-oriented projects, and the ALPAC report itself;
there are some minor inaccuracies and omissions (e.g.,
the Cambridge Language Research Unit and important
Russian projects), but overall this is a sound survey of
the early period. Warwick covers reactions to ALPAC,
the development of the Systran and Logos systems
(describing Logos incorrectly as a Vietnamese-to-En-
glish system), the university-based projects GETA,
TAUM, METAL, etc., the emergence of the transfer
design as an accepted standard (which seemed more
true in 1984 than today), and the appearance of re-
stricted systems (METEO, TITUS), interactive sys-
tems, and AI approaches.
The next four papers are concerned with the role of
linguistic theory and artificial intelligence in MT re-
search. On this issue there have been basically two
views: on the one hand, that MT research pays insuffi-
cient attention to advances in linguistics and Al and its
failures are attributable to this neglect; and on the other,
that MT research needs to develop its own independent
theory or theories, in which the proper application of
linguistics, Al, computation theories, etc., can be
judged and evaluated. The first view is coupled gener-
ally with advocacy of one particular theory; the second
view is accompanied generally by an eclectic pragmatic
approach to MT system design.
The early (pre-1966) debate is presented by Anne De
Roeck in a paper that complements Buchmann&apos;s general
historical survey examining the linguistic theories un-
derlying MT projects in this period. However, she limits
her discussion by excluding all direct systems (&amp;quot;unless
an MT system incorporates at some stage a static
representation which describes the text being translated
it is difficult to assess what linguistic information has
been used . . .&amp;quot;), all non-generative models (only gen-
erative grammars are held to be theoretically well
founded), all &amp;quot;MT systems not explicitly concerned
with syntax&amp;quot;, and all pre-1955 activity (on the justifiable
grounds that many MT pioneers were either ignorant of
or antagonistic to current linguistics). After a brief
account of the influence of information theory on
Weaver and Yngve and of structural linguistics on the
empiricist approaches of the RAND project, she con-
centrates on the influence of generative ideas: Bar-
Hillel&apos;s early work on categorial grammar and Chom-
sky&apos;s transformational grammar. It is admitted that the
influence of Chomsky was indirect (even at MIT the MT
researchers were very critical of many aspects of TG
theory), and that the contribution of other theories—
dependency and stratificational, in particular—was
greater. There is a good outline of the linguistic frame-
work of the CETA approach (at Grenoble), described as
&amp;quot;generative in spirit&amp;quot;. The conclusion, however, is that
linguistic work in MT went on quite independently of
linguistics, that MT research was often &amp;quot;violently
opposed&amp;quot; to current theories, and that &amp;quot;in the period
. . . the possible advantages to be gained for MT by
reference to theories in linguistics ha[d] not really been
exploited&amp;quot;.
Eric Wehrli repeats this common criticism by lin-
guists, viz., that MT fails to pay sufficient attention to
developments in linguistic theory. He then proceeds to
outline government-binding theory as a framework for
MT systems. Whatever the merits of this or any other
contemporary theory, MT researchers have to live with
the long-term effects of commitments to particular
linguistic theories—practically useful MT systems re-
quire many years of development, and researchers are
naturally reluctant to implement theories that have yet
to be fully tested and evaluated. There is a similar
dilemma with advances in Al techniques. Patrick Shann
illustrates the problems in a paper discussing the imple-
mentation of Al models and techniques in MT. There is
a detailed and positive description of Wilks&apos;s preference
semantics, an evaluation of Schank&apos;s use of scripts and
MOPs and the problems of going beyond limited do-
mains, and a description of experimental systems
(SALAT and CON3TRA) using world-knowledge
sources and inferential semantics. Shann concludes,
however, that &amp;quot;existing Al techniques are not ready for
large-scale MT systems&amp;quot;, and that MT systems should
apply Al methods as adjuncts to rather than replace-
ments of existing techniques.
Geoffrey Sampson presents what he considers a
&amp;quot;nonconformist&amp;quot; view, arguing that MT research has
adopted a mistaken conception of the &amp;quot;problem of
translation&amp;quot;: it is aiming for &amp;quot;100% fidelity&amp;quot; and &amp;quot;per-
fectionism&amp;quot; when there can be no such thing in trans-
lation (it is an open-ended problem-solving task with no
&apos;correct&apos; solutions); hence, MT should be looking for
techniques that give good results, not perfect ones.
However, Sampson&apos;s criticism is misdirected: theoret-
ical linguists and some researchers in Al and computa-
tional linguistics may well be seeking &apos;complete&apos; solu-
tions, but even a cursory examination of current MT
efforts (including systems described in this volume)
demonstrates that the perfectionist goal has long been
abandoned in MT research; &amp;quot;interesting minor prob-
lems&amp;quot; are not the focus of MT research, but methods
giving good results in the majority of cases. Sampson&apos;s
own inclination is in the direction of statistical and
probabilistic methods. Many MT researchers would
probably agree that these have a place—however, not
instead of, but alongside linguistic and AI techniques of
various kinds.
The second part of the collection is devoted to MT
</bodyText>
<page confidence="0.859901">
118 Computational Linguistics, Volume 15, Number 2, June 1989
</page>
<note confidence="0.248694">
Book Reviews Machine Translation Today: The State of the Art (Proceedings of the Third Lugano Tutorial, April 1984)
</note>
<bodyText confidence="0.987853494318183">
software needs. As in the first part, it is a mixture of
background papers and discussions of major issues.
Dominique Petitpierre defines some basic terminology,
Jean-Luc Cochard outlines software architecture and
chart parsing, and Alan Melby describes his now-
familiar ideas about translation workstations. Christian
Boitet then gives one of his usual masterly expositions
of the research framework of GETA (Grenoble Univer-
sity), covering the aims and design of the multilingual
ARIANE-78 system, the distinction between implicit
(linguistic) and explicit (knowledge base) information,
the advantages of multilevel interfaces, the develop-
ment of &amp;quot;lingware&amp;quot; tools, workstations for linguist
researchers, and the VISULEX tool for dictionary
consultation and editing, the GETA contribution to the
French National MT project, and the overall objectives
of research at Grenoble: an &amp;quot;expert system for transla-
tion&amp;quot;, not perfectionist, but concentrating on frequent
&apos;damaging&apos; errors of translation. (Boitet describes ARI-
ANE-78 in this paper; although the basic philosophy
remains, it should be noted that the latest version,
ARIANE-85, incorporates a number of changes and
modifications in both design and software.)
The final paper in Part 2 is by Rod Johnson and
Michael Rosner on the objectives of MT software
design. They argue convincingly that the aim should be
the development of software tools enabling linguists
(and others) to work on problems within relatively
familiar, well-defined (theoretical) frameworks. But the
difficulty is, as they point out, that MT is not a well-
defined problem—in other words, MT lacks an indepen-
dent theoretical framework.
The third part of the book, in size over half the total,
comprises descriptions of current operational and ex-
perimental MT systems. In many respects it contains
the most valuable contributions in this volume, because
although many of the details may now have only histor-
ical interest, these descriptions are among the most
comprehensive accounts of MT systems to be found
anywhere. The richness of the contents of many of the
descriptions can only be alluded to in this review—all
will repay close reading by anyone at all interested in
the problems and development of MT.
The first paper by Sophie Ananiadou is a survey of
systems that are not treated in depth in the following
chapters. Succinct and essentially accurate accounts
are given of CULT, ALPS, Weidner, LOGOS, and
TITUS. Next, Peter Wheeler provides what is probably
the most definitive and detailed description of the
linguistic foundations of Systran (still undoubtedly the
most successful operational MT system), concentrating
on the implementation in the European communities
and particularly on the English-French and French-
English versions (and saying nothing about the Russian-
English system at USAF). It is followed by Heinz-
Dieter Maas&apos;s equally detailed and equally definitive
description of the influential SUSY system at Saar-
briicken, which admirably illustrates the immense
(sometimes seemingly intractable) complexities of lin-
guistic analysis and synthesis in MT systems.
The following contribution by Pierre Isabelle is a
comprehensive history of the TAUM English-French
project at Montreal, including the development of Q-
systems, the successful design of the METEO system
for the restricted domain of weather reports, and the
AVIATION project for translating hydraulic mainte-
nance manuals for aircraft (which failed ultimately
because the system was too restrictive in range, but
which did produce sophisticated methods for evaluating
MT systems in general). Isabelle concludes his clear and
honest account of this influential project with a valuable
summary of the strengths and weaknesses of &apos;second-
generation&apos; MT systems (of which TAUM is an ac-
knowledged exemplar) and of the continuing impor-
tance of the sublanguage approach.
In a paper complementing Boitet&apos;s general descrip-
tion of the GETA approach, Jean-Philippe Guilbaud
details the design and development of an experimental
German-French version of ARIANE-78. The paper is
valuable as almost the only detailed account of this
particular project. Most attention was devoted to Ger-
man morphology and syntax, since French generation
was based on an adaptation of programs for the existing
GETA Russian-French system. It is followed by
Jonathan Slocum&apos;s account of the development of the
METAL system at the Linguistics Research Center
(LRC) of the University of Texas. After stressing the
importance of software tools (for dictionary updating,
text formating and reformating, editing, etc.), Slocum
defends the LRC adoption of phrase structure (LFG-
like) grammar and a minimal use of semantic analysis
(primarily to deal with prepositions during transfer)
against semantics-based and understanding approaches,
claiming that good results have been achieved without
semantic features and that it is just not feasible to
undertake detailed semantic analyses of the vocabulary
of 100,000-page technical texts. He justifies the empha-
sis (as in most MT projects aiming for operational
implementation) on effective &apos;shallow&apos; analysis, on
plausibility screening of multiple parsings, and on pro-
ducing some kind of output—when dealing with thou-
sands of pages, no practical system can &amp;quot;indulge in the
luxury of simply replying with an error message stating
that the sentence cannot be interpreted&amp;quot;. Slocum is
convinced that there is &amp;quot;no evidence that today&apos;s
advanced but experimental NLP techniques will soon
(in this decade or even century) be able to supplant the
more primitive techniques that are currently effective in
a large-scale application such as ours&amp;quot;.
The most experimental and innovative system de-
scribed is the Rosetta project at Philips (Eindhoven).
Jan Landsbergen&apos;s paper provides a definitive account
of the theoretical foundations of the system. It is based
on Montague semantics and the notion of isomorphic
grammars, i.e., the &apos;attuning&apos; of source and target
language grammars to each other, so that for each
Computational Linguistics, Volume 15, Number 2, June 1989 119
Book Reviews Advances in Natural Language Generation: An Interdisciplinary Perspective
expression or syntactic rule in one there is a corre-
sponding expression or syntactic rule in the other with
the same meaning. Rosetta differs from the strict Mon-
tague model in making no use of intensional logic or of
categorial grammar, but it adheres to the composition-
ality principle (in relating syntactic rules and semantic
structures). The paper includes many formal proofs and
only trivial sentence examples—which might well not
impress those skeptical of the value of a project whose
influence on MT theorists has been considerable in
recent years. It is followed by a description of another
experimental system (albeit less radically innovative in
linguistic conception), an account by Margaret King and
Sergei Perschke of the Eurotra project of the European
Communities. After outlining the historical background
(the need for a decentralized multilingual project capa-
ble of stimulating MT and computational linguistic
research in each of the participating countries), the
basic features are described: a linguistics-based transfer
model, modular and robust, no interactive facilities,
multilevel tree-structure interfaces, a controlled pro-
duction system operating on series of well-defined
grammars, etc. Eurotra is admitted to be relatively
traditional in its linguistics, but it is claimed to be more
advanced in its computational design and to have been
successful in promoting the study of languages not
previously the subject of MT or detailed linguistic
research.
This book represents a primary source of information
for some of the most significant and influential MT
projects in the last decade. It is greatly enhanced by a
substantial bibliography, which includes not only all
references by the contributors, but also many other
items covering the historical development of MT, the
current (1984) state of research, and related topics in
computational linguistics and artificial intelligence. The
publication delay has not diminished the value of the
contributions: many papers provide the most detailed
and comprehensive accounts of individual MT systems.
Only in the cases of Rosetta, GETA, and Eurotra can it
be said that there have been substantial changes in the
years since the Lugano tutorial. There are some omis-
sions in the historical surveys as already noted, and
readers should also be made aware that a number of
systems current at the time are not mentioned at all,
e.g., the DLT system in Utrecht, the PAHO system in
Washington, many of the largely AI-inspired projects in
the United States, the systems in the Soviet Union, and
the activity in Japan (e.g., the influential Kyoto
research). These are minor points. This is a publication
that will remain for many years an invaluable source on
MT research and it deserves to find a place on the
shelves of anyone seriously interested in computational
linguistics and in machine translation.
John Hutchins is the author of Machine translation: Past,
present, and future (published by Ellis Horwood). His address
is The Library, University of East Anglia, University Plain,
Norwich NR4 7TJ, England. E-mail: L101@uea.cpc865
</bodyText>
<sectionHeader confidence="0.9909585" genericHeader="method">
ADVANCES IN NATURAL LANGUAGE GENERATION:
AN INTERDISCIPLINARY PERSPECTIVE
</sectionHeader>
<reference confidence="0.913723">
Michael Zock and Gerard Sabah (eds.)
(LIMSI, Orsay)
London: Pinter Publishers and Norwood, NJ: Ablex
Publishing, 1987, 2 vols., xix +200 pp., xviii+ 176
pp.
(Communication in Artificial Intelligence Series)
ISBN 0-86187-965-1 and -995-5, £27.50 per volume
(hb); ISBN 0-89391-527-0 and -537-8, $45.00 per
volume (corporate), $27.00 per volume (personal)
Reviewed by
Marie Meteer
</reference>
<subsubsectionHeader confidence="0.492588">
BBN Systems and Technologies Corporation
</subsubsectionHeader>
<bodyText confidence="0.995055195121951">
Advances in Natural Language Generation is the pro-
ceedings of the European Workshop on Natural Lan-
guage Generation held in January 1988 at the Abbey de
Royaumont, France. As such, it gives a fairly broad
snapshot of the work in this area going on in Europe
(with a few notable omissions, such as Wahlster, Rei-
thinger, and Danlos). The introduction by editors Zock
and Sabah, and the foreword by David McDonald
emphasize the youth of natural language generation
(NLG) as a field and the importance of workshops such
as this one in bringing together researchers from diverse
areas, such as psychology, linguistics, and artificial
intelligence, to contribute to this growing field.
Perhaps due to the youth of the field or perhaps due
to a lack of rigor on the part of the workshop organizers
and editors, the book lacks unity. The papers them-
selves vary a great deal in quality and in audience, some
presenting an introduction to some aspect of the field
and others assuming the reader knows the particular
details of a linguistic framework. Some address them-
selves directly to the problems of NLG, while others
report on just their own work and leave the connections
to NLG to the reader.
The first paper in the book, &amp;quot;Language Generation
and Explanation&amp;quot; by McKeown and Swartout, is aimed
at a wide audience and presents issues and approaches
rather than particular advances in the field. It is not a
paper from the workshop itself, but rather a reprint from
the Annual Review of Computer Science, and as such is
a very good general overview of previous work, partic-
ularly in text planning and explanation. Unfortunately,
it does not provide adequate background for the papers
in this collection; in particular, it does not supply any
introduction to the different kinds of grammars in use,
such as LFG, SFG, and FUG.
As the title of the book suggests, many of the papers
are reports on work that has in some way furthered the
state of the art in NLG. These papers are aimed at those
who already know the field, at least to some degree, and
who know some of the background behind the problems
being addressed. The best of the papers were those that
</bodyText>
<page confidence="0.928734">
120 Computational Linguistics, Volume 15, Number 2, June 1989
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.028555">
<note confidence="0.937787">Book Reviews Machine Translation Today: The State of the Art (Proceedings of the Third Lugano Tutorial, April 1984)</note>
<abstract confidence="0.995009894736842">It may seem obvious that one understands the utterance of a novel sentence because one knows the meanings of the words contained in it and, in some sense, knows a rule for determining the meaning of the sentence on the basis of its syntax and the meanings of its words. (p. 179) Nevertheless, he argues that the evidence for a compositional truth-theoretic semantics is pretty glib, because one can give a correct model of language understanding and productivity without assuming a compositional truth-theoretic semantics. In the seventh chapter of the book he suggests a to the compositional view about language understanding. He describes a possible world in which a human computer, Harvey, understands a lancomplex as English. The author analyzes Harvey&apos;s comprehension of some sentences and he draws a picture in which heuristic tools, such as the &apos;conceptual roles&apos; of some expressions of Harvey&apos;s neural language of thought, allow him to show that &amp;quot;there could be a correct psychological model of a person&apos;s language processing that does not presuppose a compositional semantics for the mastered language&amp;quot; (p. 205). But one might object that if compositional semantics is not needed in order to account for language understanding, it is needed in order to explain what Schiffer calls &amp;quot;the platitude&amp;quot;, i.e., the idea that the meanings of sentences are determined by their syntax and the meanings of their words. In Chapter 8, Schiffer argues against this objection by introducing other heuristic notions, such as the &amp;quot;saying-potential&amp;quot; and the &amp;quot;processing role&amp;quot; of linguistic expression. In the sentence &amp;quot;Michel believes that his car was stolen&amp;quot;, the word &amp;quot;believes&amp;quot; has a processing role that determines its saying potential each time the word is used. &amp;quot;Believes&amp;quot; is a semantic primitive, &amp;quot;but it is not a semantic primitive in any sense appropriate to a compositional semantics, for no base axiom, no satisfaction clause, can be written for &apos;believes&apos; that could take its place in a true truth theory for English&amp;quot; (p. 216). Schiffer does not want to deny all the aspects of semantic compositionality, nor that natural languages contain truth-affecting iterative devices (p. 208). What he denies is the relevance of truth-theoretic semantics to an account of language understanding and productivity. He denies that something like analytic philosophy is possible, but in the meantime he suggests that the compositionality of natural language should be explained via cognitive models of linguistic behaviour. At the very end of his book, he seems to set up an alliance with cognitive science in order to explain facts about language which do need explanation. They are facts about language comprehension, about the ways in which we store, represent, and process information. But, Schiffer says, these &amp;quot;are not philosophical questions (although the skills of the philosopher would be relevant to answering them)&amp;quot; (p. 271).</abstract>
<note confidence="0.916086375">REFERENCES Graeme 1987 Interpretation and the Resolution of University Press, Cambridge, R. 1979 and the Mirror of Nature, University Press, Princeton, NJ. L. 1953 Untersuchungen [Philosophical Blackwell, Oxford, England. Danieli&apos;s was on the semantics of proper</note>
<abstract confidence="0.99020075">names. Her present interests concern the integration of syntax and semantics in natural languages. At Olivetti, her research concerns the development of syntactic tools for language analysis. Danieli&apos;s address is: Speech and Language Labora-</abstract>
<address confidence="0.78043">tory, Olivetti, c.so Svizzera 185, 10149 Torino, Italy.</address>
<title confidence="0.587577">MACHINE TRANSLATION TODAY: THE STATE OF THE</title>
<author confidence="0.679683333333333">ART</author>
<affiliation confidence="0.841035666666667">(Institute for Semantic and Cognitive Studies, University of Geneva, Switzerland) Edinburgh University Press, 1987, xii + 447 pp.</affiliation>
<note confidence="0.985021">(Edinburgh Information Technology Series 2) ISBN 0-85224-519-X, £45.00 (hb) Reviewed by</note>
<author confidence="0.994661">John Hutchins</author>
<affiliation confidence="0.976188">University of East Anglia</affiliation>
<abstract confidence="0.98722525">It is always regrettable when the proceedings of conferences appear a long time after they were held, in this case nearly four years, but it is even more so in a rapidly changing field such as machine translation (MT). Developments since this MT tutorial was organized by the Dalle Molle Institute for Semantic and Cognitive Studies (ISSCO) in early 1984 mean that many of the contributions have now predominantly historical interest. They are, however, no less valuable since many are accounts of MT systems which have not been bettered in comprehensiveness before or since. In keeping with its historical character and its originally-intended role as</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<editor>Michael Zock and Gerard Sabah (eds.) (LIMSI,</editor>
<location>Orsay</location>
<marker></marker>
<rawString>Michael Zock and Gerard Sabah (eds.) (LIMSI, Orsay)</rawString>
</citation>
<citation valid="true">
<authors>
<author>London Pinter Publishers</author>
<author>NJ Norwood</author>
</authors>
<date>1987</date>
<volume>2</volume>
<pages>176</pages>
<publisher>Ablex Publishing,</publisher>
<marker>Publishers, Norwood, 1987</marker>
<rawString>London: Pinter Publishers and Norwood, NJ: Ablex Publishing, 1987, 2 vols., xix +200 pp., xviii+ 176 pp.</rawString>
</citation>
<citation valid="false">
<title>(Communication in Artificial Intelligence Series) ISBN 0-86187-965-1 and -995-5, £27.50 per volume (hb); ISBN 0-89391-527-0 and -537-8, $45.00 per volume (corporate), $27.00 per volume (personal) Reviewed by Marie Meteer</title>
<marker></marker>
<rawString>(Communication in Artificial Intelligence Series) ISBN 0-86187-965-1 and -995-5, £27.50 per volume (hb); ISBN 0-89391-527-0 and -537-8, $45.00 per volume (corporate), $27.00 per volume (personal) Reviewed by Marie Meteer</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>