<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000009">
<note confidence="0.825311">
AN ENGLISH GENERATOR FOR A CASE-LABELLED DEPEND&amp;NCY REPRESENTATION
</note>
<author confidence="0.244464833333333">
John Irving Tait
Acorn Computers Ltd.
Fulbourn Road
Cherry Hinton
Cambridge CB]. 4JN
U. K.
</author>
<sectionHeader confidence="0.839215" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99986308">
The paper describes a program which has been
constructed to produce English strings from a
case-label lea dependency representation. The
program uses an especially simple and uniform
control structure with a well defined separation
of the different knowledge sources used during
generation. Furthermore, the majority of the
system&apos;s knowledge is expressed in a declarative
form, so in priciple the generator&apos;s knowledge
bases could be used for purposes other than
generation. The generator uses a two-pass control
structure, the first translating from the
semantically orientated case-labelled dependency
structures into surface syntactic trees and the
second translating from these trees into English
strings.
The generator is very flexible: it can be run in
such a way as to produce all the possible
syntactically legitimate variations on a given
utterance, and has built in facilities to do some
synonym substitution. It has been used in a
number of application domains: notably as a part of
a free text retrieval system and as part of a
natural language front end to a relational database
system.
</bodyText>
<sectionHeader confidence="0.975783" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.99992116">
This paper describes a program which has been
constructed to translate from Boguraev&apos;s
case-labelled dependency representations (Boguraev,
1979: see also Boguraev and Sparck Jones, 1982) to
English strings. Although the principles on which
the program has been constructed are primarily a
new Mix of established ideas, the generator
incorporates a number of novel features. In
particular, it combines an especially simple and
uniform control structure with a well defined
separation of the different knowledge sources used
during generation. It operates in two passes, the
first translating from the semantically orientated
case-labelled dependency structures into surface
syntactic trees and the second translating from
these trees into English strings.
The translation from dependency structures to
surface syntactic trees is the more complex of the
two passes undertaken by the generator and will be
described here. The other, translation from
instantiated surface trees to text strings is
relatively straightforward and will not be dealt
with in this paper. It is fundamentally a tree
flattening process, and is described in detail in
Tait and Sparck Jones (1983).
</bodyText>
<sectionHeader confidence="0.938747" genericHeader="method">
2. The Generator&apos;s Knowledge Structures
</sectionHeader>
<bodyText confidence="0.784947416666667">
The generator&apos;s knowledge is separated into four
sections, as follows.
1) a set of bare templates of phrasal and
clausal structures which restrict the
surface trees other parts of the system may
produce by defining the branching factor at
a given node type. For example, the patterns
record that English has intransitive,
transitive and ditransitive, but not
tritransitive, verb phrases. The bare
template for noun phrases is illustrated in
Figure 1.
</bodyText>
<listItem confidence="0.998503636363636">
2) a lexicon and an associated morphological
processor.
3) a set of production rules which fill out
partially instantiated syntactic trees
produced from the phrasal and clausal
patterns. These rules contain most of the
systen&apos;s knowledge about the relationship
between the constructs of Boguraev&apos;s
representation language and English forms.
4) another set of production rules which convert
filled out surface trees to English strings.
</listItem>
<figure confidence="0.868391625">
/-Quantifier
-Determiner
-Ordinal
Noun Phrase == -Number
-Adjective-list
-Nominal-modifier-list
-Head
\-Post-modifers
</figure>
<figureCaption confidence="0.888426">
Figure 1
</figureCaption>
<bodyText confidence="0.887993">
Template for Noun Phrase
These four knowledge sources represent the
generator&apos;s entire knowledge of both English and
Boguraev &apos;s representation language. Although they
are obviously interrelated, each is distinct and
separate. This well defined separation greatly
</bodyText>
<page confidence="0.998144">
194
</page>
<bodyText confidence="0.999057">
Each ra:IP-associated production rule takes four
inputs, as follows:
increases the extensability and maintainability of
the system.
As noted in the previous section the application of
the rules of section 4 will not be discussed in
this paper. The remainder of the paper discusses
the use made of the first three knowledge sources.
</bodyText>
<listItem confidence="0.7555745">
3. Translation from Dependency Structures to
Surface Syntactic Trees
</listItem>
<bodyText confidence="0.914637933333333">
The primary work of conversion from the dependency
representations to the surface syntactic trees is
umiertaken by a set of production rules, each rule
being associated with one of the case labels used
in Boguraev&apos;s representation scheme. These rules
are applied by a suite of programs which exploit
information about the structure of Boguraev&apos;s
dependency structures. For example they know where
in a nominal aependency structure to find the word
sense name of the head noun (&apos;oscillatorl&apos; in
Figure 2) and where to find its case list (to
which the production rules should be applied).
(n (oscillatorl THING
(@@ det (the]. ONE))
(## nmod
</bodyText>
<figure confidence="0.771874111111111">
((((trace (clause v agent))
(clause
(v (be2 BE
(@@ agent
(n (frequencyl SIGN)))
(@@ state
(St (n (nameless NIL))
(val (high3 KIN)))))
))) ))) )))
</figure>
<figureCaption confidence="0.649165666666667">
Figure 2
Boguraev Representation used for
&amp;quot;the high frequency oscillator&amp;quot;
</figureCaption>
<bodyText confidence="0.992077428571428">
It must be emphasized that Boguraev&apos;s use of the
term case is much wider than is cannon in
linguistics. Not only is it used to cover
prepositional attachment to nouns as well as
verbs; it is also used to cover some other forms
of attachment to, and modification of, nouns, for
example by determiners (like &amp;quot;a&amp;quot;) and even for
plural or singular number. In the phrase &amp;quot;the high
frequency oscillator&amp;quot;, whose representation is
illustrated by Figure 2, the link between
&apos;oscillatorl&apos; (standing for &amp;quot;oscillator&amp;quot;), and the
determiner (&apos;(thel ONE)&apos;, representing &amp;quot;the&amp;quot;) is
the so-called case-label det. Similarly the
prenominal modifier &amp;quot;high frequency&amp;quot; (represented
by the complex structure to the lower right of the
figure) is linked to &apos;oscillatorl&apos; by nmod.
1) the dependent item attached to the case link,
for example &apos;(the]. ONE)&apos; in the case of det
given below;
2) an environment which is used to pass
information from the processing of higher
levels of the representation down to lower
levels: for example tense from the
sentential level into an embedded relative
clause; the environment is also used to allow
various kinds of control over the generation
process: for example to determine how many
paraphrases of a sentence are produced;
</bodyText>
<listItem confidence="0.677521285714286">
3) a partially instantiated phrase or clause
template, which will ultimately form part of
the surface syntactic tree output by the
first pass of the generator;
4) the dictionary entry for the dominant item of
the current case list: in Figure 2 this is
the entry for &apos;oscillator&apos;&apos;, presented in
</listItem>
<figureCaption confidence="0.823365">
Figure 3.
</figureCaption>
<figure confidence="0.75418325">
(oscillator&apos;
(oscillatorl-#1
(root oscillator)
(syntax-patterns Noun-phrase-pattern)))
</figure>
<figureCaption confidence="0.676714">
Figure 3
</figureCaption>
<bodyText confidence="0.97596295">
Dictionary entry for &apos;oscillatorl&apos;
The rules vary greatly in canplexity: the structure
illustrated in Figure 2 requires the use of both
the simplest and most complex form of rule.
The det production rule may be described in
pseudo-English as:
If the partially instantiated template is for
a noun phrase then look up the lexical items
(potentially synonyms) associated with the
word sense name &apos;the].&apos;, and insert each in
the determiner slot in a new copy of the
syntactic node.
(Of course for English there is only one lexical
item associated with &apos;the].&apos;: &amp;quot;the&amp;quot;.) At the other
extreme is the production rule for the nmod case.
The nmod case in Boguraev&apos;s dependency structures
is used to associate the pre-nominal modifiers in
a compound nominal with the head noun. The
pre-nominal modifiers are represented as a list of
simple naninal representations.
</bodyText>
<figure confidence="0.88987225">
(Noun-Phrase (NIL the NIL NIL NIL
((Noun-Phrase NIL NIL NIL NIL
(high) NIL frequency NIL))
oscillator NIL))
</figure>
<figureCaption confidence="0.983919">
Figure 4
</figureCaption>
<bodyText confidence="0.862659333333333">
Surface Structure Tree for
&amp;quot;the high frequency oscillator&amp;quot;
In English the mood production rule might be
</bodyText>
<page confidence="0.995063">
195
</page>
<bodyText confidence="0.992548262626263">
expressed as:
If the partially instantiated template is for
a noun phrase, apply the processor which,
given an existing nominal representation,
instantiates a corresponding phrasal
template, to each nominal representation in
the dependent item list: form the results
into a set of lists, one for each
combination of possible results for
expressing each nominal: insert each result
list into a copy of the partially
instantiated template originally passed to
the rule.
The surface structure tree produced after these
rules have been applied to the representation of
Figure 2 is given in Figure 4. Note that the tree
contains syntactic category names, and that
unfilled slots in the tree are filled with NIL.
Thus if the phrase to be generated was &amp;quot;all the
high frequency oscillators&amp;quot;, the first NIL in the
surface syntactic tree (representing the unfilled
quantifier slot of the dominant noun phrase node)
would be replaced by &amp;quot;all&amp;quot;. The order of the words
in the surface syntactic tree represents the order
in which they will be produced in the output
sentence.
These two production rules, for the det and nmod
case labels, are fairly typical of those used
elsewhere in the system. There is, however, an
important feature they fail to illustrate. In
contrast with more conventional cases, nmod and
det do not require the identification of a lexical
item associated with the case-label itself. This is
of course necessary when expressing prepositional
phrases
4. Distinctive Features of this Translation Process
The two most noteworthy features of the generation
phase which produces surface structure trees are
the control structure employed and distribution of
the systems language knowledge between its
different components.
No mention of the system&apos;s control structure was
made in the previous section. The structure used
is sufficiently powerful and elegant that it could
be ignored entirely when building up the systems
knowledge of Boguraev&apos;s representation language
and of English. However, the efficiency of the
generator described here is largely a result of the
control structure used. It is rare for this system
to take more than a few fractions of a second to
generate a sentence: a sharp contrast with
approaches based on unification, like Appelt&apos;s
(1983) TELFgRAM.
First the current representational structure is
classified as clausal, simple nominal, or complex
(typically relativised) nominal. Second, a suitable
structure dismantling function is applied to the
structure which identifies the head lexical token
from the structure and separates out its case-list.
Third the dictionary entry for the head lexical
item is obtained, and, after checkina the
syntactic markers in the dictionary entry and
phrasal or clause templates suitable for the
environment are identified. Fourth, appropriate
production rules are applied to each element of the
structure&apos;s case list in order to instantiate the
templates. Frequently this whole process is applied
recursively to some dependent representation level.
So, for example, the representation for &amp;quot;high
frequency&amp;quot; is processed by a second call of the
noun phrase processor from within the call dealing
with the dominant nominal, &apos;oscillatorl&apos;. When the
case list has been completely processed, the
dismantling function applies any necessary
morphological processing to the head lexical item
(for example to reflect subject/verb and
person/number agreement).
This simple framework covers all the processing
done by the generator.
The split between the syntactic knowledge
represented in the phrasal and clausal templates
and in the production rules is also unusual. The
templates define the shape of the surface
syntactic trees which the system can produce. It
places no restrictions on the form of the fillers
for any slot in a grammar node. The production
rules enforce categorial and ordering
restrictions. So, for example, the templates
reflect the fact that English possesses
intransitive, transitive and ditransitive verbs,
whilst the production rules ensure that the
subject of a clause is of a suitable syntactic
category, and that the subject precedes the verb
in simple declarative sentences.
The surface structure trees produced contain all
the words in the sentence to be produced in the
order and form in which they are to be output. Thus
it is a straightforward matter to generate English
strings from them.
</bodyText>
<sectionHeader confidence="0.912701" genericHeader="method">
5. Conclusion
</sectionHeader>
<bodyText confidence="0.999651909090909">
The generator presented here is in essence a
development of the Micro-Mumble generator
described in Meehan (1981). But in the process of
extending Meehan &apos;s framework for a wide coverage
system, his original design has been radically
transformed. Most notably, the system described
here has its syntactic knowledge largely separated
from its knowledge of the input representation
language. It has, however, retained the elegant
control structure of Meehan &apos;s original. This
distinguishes it from the early generators in the
same style, like Goldman&apos;s (1975) BABEL.
At the same time the generator described here is
very flexible: it can be run in such a way as to
produce all the possible syntactically legitimate
variations on a given utterance, and has built in
facilities to do some synonym substitution. The
environment mechanism is very (perhaps too)
powerful, and could be used to dynamically select
possible ways of expressing a given structure in
almost any way required.
The system&apos;s knowledge of natural language and of
</bodyText>
<page confidence="0.997802">
196
</page>
<bodyText confidence="0.999986877192983">
the representation language is expressed in a
fundamentally rule-like way, most notably without
the use of an assignment mechanism. In principle
such rules could be used backwards, that is they
could be used to parse incoming English. However no
work has been done to develop a parser which uses
the generators rules, so this possibility remains
pure speculation at present.
The generator described here, it must be
emphasized, covers only part of the task of
generation. Unlike, for example, McKeown&apos;s (1981))
system, it deals not with what to say, but only
with how to say it. Boguraev&apos;s representation
identifies sentence boundaries and the majority of
content words to be used in the utterance being
produced (see Figure 1), making the task of the
generator relatively straightforward. However, the
techniques used could deal with a representation
which was much Less closely related to the surface
text provided this representation retained a
fairly straightforward relationship between
propositional units of the meaning representation
and the clausal structure of the language. For
example, a representation language which
represented only states and times, but not the
events which linked different states and times
would probably require a more powerful framework
than that provided by the generator described
here. However, another case-labelled dependency
language, like Schenk &apos;s (1975) Conceptual
Dependency (CD) Representation, could be handled
by providing the generator with a new set of
syntactico-semantic production rules, a new lexicon
and the replacement of the functions for
dismantling Boguraev &apos;s dependency representation
with functions for dismantling CD structures. &apos;
The framework of the generator has been completely
implemented and tested with a lexicon of a few
hundred words and a grammar covering much of the
English noun phrase and a number of the more
straightforward sentence types. It has been used
in a number of applications, most notably document
retrieval (Sparck Jones and Teit, 1984a and 1984b)
and relational database access (Boguraev and
Sparck Jones, 1983).
The program described here is efficient (rarely
taking more than a few fractions of second to
generate a sentence) in contrast with approaches
based on complex pattern matching (like Appelt
(1983), and Jacobs (1983)). On the other hand, the
essential simplicity and uniformity of the approach
adopted here has meant that the generator is no
more difficult to maintain and extend than more
linguistically motivated approaches, for example
Appelt&apos; s. Thus it has demonstrated its usefulness
as a practical tool for computational linguistic
research.
</bodyText>
<sectionHeader confidence="0.469385" genericHeader="method">
FCENCNLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.991214666666667">
This work was supported by the British Library
Research and Development Department and was
undertaken in the University of Cambridge Computer
Laboratory. I would like to thank Bran Boguraev,
Ted Briscoe and Karen Sparck Jones for the helpful
comments they made on the first draft of this
paper. I would also like to thank my anonymous
referees for the very helpful comments they made on
the an earlier draft of the paper.
</bodyText>
<sectionHeader confidence="0.998191" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999810577777778">
Appelt, D.E. (1983) TELEGRAM: A Grammar Formalism
for Language Planning. Proceedings of the
Eighth International Joint Conference on
Artificial Intelligence. Karlsruhe.
Boguraev, B. K. (1979) Automatic Resolution of
Linguistic Ambiguities. Technical Report No. 11,
University of Cambridge Canputer Laboratory.
Boguraev, B.K. and K. Sparck Jones (1982) A natural
language analyser for database access. In
Information Technology: Research and
Development; vol. 1.
Boguraev, B.K. and K. Sparck Jones (1983) A natural
language front end to data bases with
evaluative feedback. In New Applications of
Databases (Ed. Garadin and Gelenbe), Academic
Press, London.
Goldman, N. (1975) Conceptual Generation. In
Conceptual Information Processing, R.C.
Schenk, North Holland, Amsterdmn.
Jacobs, P. S. (1983) Generation in a Natural
Language Interface. Proceedings of the Eighth
International Joint Conference on Artificial
Intelligence. Karlsruhe.
McKeown, K.R. (1980), Generating Relevant
Explanations: Natural Language Responses to
Questions about Database Structure. Proceedings
of the First Annual National Conference on
Artificial Intelligence, Stanford, Ca.
Meehan, J. (198i) Micro-TALE-SPIN. In Inside
Computer Understanding, R. C. Schank and C.K.
Riesbeck, Lawrence Erlbaum Associates,
Hillsdale, New Jersey.
Schenk, R. C. (1975) Conceptual Information
Processing, North Holland, Amsterdam.
Sparck Jones K. and J. I. Tait (1984a), Automatic
Search Term Variant Generation. Journal of
Documentation, Vol 40, No. 1.
Sparck Jones, K. and J. I. Tait (1984b),
Linguistically Motivated Descriptive Term
Selection. Proceedings of COLING 84, Association
for Computational Linguistics, Stanford.
Tait, J.I. and K. Sparck Jones (1983), Automatic
Search Term Variant Generation for Document
Retrieval; British Library R&amp;D Report 5793,
Cambridge.
</reference>
<page confidence="0.998188">
197
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.256443">
<title confidence="0.995141">AN ENGLISH GENERATOR FOR A CASE-LABELLED DEPEND&amp;NCY REPRESENTATION</title>
<author confidence="0.99039">John Irving Tait</author>
<affiliation confidence="0.953594">Acorn Computers Ltd.</affiliation>
<title confidence="0.751904">Fulbourn Road</title>
<author confidence="0.809027">Cherry Hinton</author>
<address confidence="0.911876">Cambridge CB]. 4JN</address>
<author confidence="0.442826">U K</author>
<abstract confidence="0.998886269230769">The paper describes a program which has been constructed to produce English strings from a case-label lea dependency representation. The program uses an especially simple and uniform control structure with a well defined separation of the different knowledge sources used during generation. Furthermore, the majority of the system&apos;s knowledge is expressed in a declarative form, so in priciple the generator&apos;s knowledge bases could be used for purposes other than generation. The generator uses a two-pass control structure, the first translating from the semantically orientated case-labelled dependency structures into surface syntactic trees and the second translating from these trees into English strings. The generator is very flexible: it can be run in such a way as to produce all the possible syntactically legitimate variations on a given utterance, and has built in facilities to do some synonym substitution. It has been used in a number of application domains: notably as a part of a free text retrieval system and as part of a natural language front end to a relational database system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D E Appelt</author>
</authors>
<title>TELEGRAM: A Grammar Formalism for Language Planning.</title>
<date>1983</date>
<booktitle>Proceedings of the Eighth International Joint Conference on Artificial Intelligence.</booktitle>
<location>Karlsruhe.</location>
<contexts>
<context position="15476" citStr="Appelt (1983)" startWordPosition="2390" endWordPosition="2391">ures. &apos; The framework of the generator has been completely implemented and tested with a lexicon of a few hundred words and a grammar covering much of the English noun phrase and a number of the more straightforward sentence types. It has been used in a number of applications, most notably document retrieval (Sparck Jones and Teit, 1984a and 1984b) and relational database access (Boguraev and Sparck Jones, 1983). The program described here is efficient (rarely taking more than a few fractions of second to generate a sentence) in contrast with approaches based on complex pattern matching (like Appelt (1983), and Jacobs (1983)). On the other hand, the essential simplicity and uniformity of the approach adopted here has meant that the generator is no more difficult to maintain and extend than more linguistically motivated approaches, for example Appelt&apos; s. Thus it has demonstrated its usefulness as a practical tool for computational linguistic research. FCENCNLEDGEMENTS This work was supported by the British Library Research and Development Department and was undertaken in the University of Cambridge Computer Laboratory. I would like to thank Bran Boguraev, Ted Briscoe and Karen Sparck Jones for t</context>
</contexts>
<marker>Appelt, 1983</marker>
<rawString>Appelt, D.E. (1983) TELEGRAM: A Grammar Formalism for Language Planning. Proceedings of the Eighth International Joint Conference on Artificial Intelligence. Karlsruhe.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B K Boguraev</author>
</authors>
<title>Automatic Resolution of Linguistic Ambiguities.</title>
<date>1979</date>
<tech>Technical Report No. 11,</tech>
<institution>University of Cambridge Canputer Laboratory.</institution>
<contexts>
<context position="1427" citStr="Boguraev, 1979" startWordPosition="213" endWordPosition="214">nd the second translating from these trees into English strings. The generator is very flexible: it can be run in such a way as to produce all the possible syntactically legitimate variations on a given utterance, and has built in facilities to do some synonym substitution. It has been used in a number of application domains: notably as a part of a free text retrieval system and as part of a natural language front end to a relational database system. 1. Introduction This paper describes a program which has been constructed to translate from Boguraev&apos;s case-labelled dependency representations (Boguraev, 1979: see also Boguraev and Sparck Jones, 1982) to English strings. Although the principles on which the program has been constructed are primarily a new Mix of established ideas, the generator incorporates a number of novel features. In particular, it combines an especially simple and uniform control structure with a well defined separation of the different knowledge sources used during generation. It operates in two passes, the first translating from the semantically orientated case-labelled dependency structures into surface syntactic trees and the second translating from these trees into Engli</context>
</contexts>
<marker>Boguraev, 1979</marker>
<rawString>Boguraev, B. K. (1979) Automatic Resolution of Linguistic Ambiguities. Technical Report No. 11, University of Cambridge Canputer Laboratory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B K Boguraev</author>
<author>K Sparck Jones</author>
</authors>
<title>A natural language analyser for database access.</title>
<date>1982</date>
<booktitle>In Information Technology: Research and Development;</booktitle>
<volume>1</volume>
<marker>Boguraev, Jones, 1982</marker>
<rawString>Boguraev, B.K. and K. Sparck Jones (1982) A natural language analyser for database access. In Information Technology: Research and Development; vol. 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B K Boguraev</author>
<author>K Sparck Jones</author>
</authors>
<title>A natural language front end to data bases with evaluative feedback.</title>
<date>1983</date>
<booktitle>In New Applications of Databases (Ed. Garadin and Gelenbe),</booktitle>
<publisher>Academic Press,</publisher>
<location>London.</location>
<marker>Boguraev, Jones, 1983</marker>
<rawString>Boguraev, B.K. and K. Sparck Jones (1983) A natural language front end to data bases with evaluative feedback. In New Applications of Databases (Ed. Garadin and Gelenbe), Academic Press, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Goldman</author>
</authors>
<title>Conceptual Generation.</title>
<date>1975</date>
<booktitle>In Conceptual Information Processing,</booktitle>
<location>R.C. Schenk, North Holland, Amsterdmn.</location>
<marker>Goldman, 1975</marker>
<rawString>Goldman, N. (1975) Conceptual Generation. In Conceptual Information Processing, R.C. Schenk, North Holland, Amsterdmn.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P S Jacobs</author>
</authors>
<title>Generation in a Natural Language Interface.</title>
<date>1983</date>
<booktitle>Proceedings of the Eighth International Joint Conference on Artificial Intelligence.</booktitle>
<location>Karlsruhe.</location>
<contexts>
<context position="15495" citStr="Jacobs (1983)" startWordPosition="2393" endWordPosition="2394">rk of the generator has been completely implemented and tested with a lexicon of a few hundred words and a grammar covering much of the English noun phrase and a number of the more straightforward sentence types. It has been used in a number of applications, most notably document retrieval (Sparck Jones and Teit, 1984a and 1984b) and relational database access (Boguraev and Sparck Jones, 1983). The program described here is efficient (rarely taking more than a few fractions of second to generate a sentence) in contrast with approaches based on complex pattern matching (like Appelt (1983), and Jacobs (1983)). On the other hand, the essential simplicity and uniformity of the approach adopted here has meant that the generator is no more difficult to maintain and extend than more linguistically motivated approaches, for example Appelt&apos; s. Thus it has demonstrated its usefulness as a practical tool for computational linguistic research. FCENCNLEDGEMENTS This work was supported by the British Library Research and Development Department and was undertaken in the University of Cambridge Computer Laboratory. I would like to thank Bran Boguraev, Ted Briscoe and Karen Sparck Jones for the helpful comments</context>
</contexts>
<marker>Jacobs, 1983</marker>
<rawString>Jacobs, P. S. (1983) Generation in a Natural Language Interface. Proceedings of the Eighth International Joint Conference on Artificial Intelligence. Karlsruhe.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K R McKeown</author>
</authors>
<title>Generating Relevant Explanations: Natural Language Responses to Questions about Database Structure.</title>
<date>1980</date>
<booktitle>Proceedings of the First Annual National Conference on Artificial Intelligence,</booktitle>
<location>Stanford, Ca.</location>
<marker>McKeown, 1980</marker>
<rawString>McKeown, K.R. (1980), Generating Relevant Explanations: Natural Language Responses to Questions about Database Structure. Proceedings of the First Annual National Conference on Artificial Intelligence, Stanford, Ca.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Meehan</author>
</authors>
<title>Micro-TALE-SPIN. In Inside Computer Understanding,</title>
<date></date>
<location>Hillsdale, New Jersey.</location>
<marker>Meehan, </marker>
<rawString>Meehan, J. (198i) Micro-TALE-SPIN. In Inside Computer Understanding, R. C. Schank and C.K. Riesbeck, Lawrence Erlbaum Associates, Hillsdale, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Schenk</author>
</authors>
<title>Conceptual Information Processing,</title>
<date>1975</date>
<publisher>North</publisher>
<location>Holland, Amsterdam.</location>
<marker>Schenk, 1975</marker>
<rawString>Schenk, R. C. (1975) Conceptual Information Processing, North Holland, Amsterdam.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sparck Jones K</author>
<author>J I</author>
</authors>
<title>Tait (1984a), Automatic Search Term Variant Generation.</title>
<journal>Journal of Documentation, Vol</journal>
<volume>40</volume>
<marker>K, I, </marker>
<rawString>Sparck Jones K. and J. I. Tait (1984a), Automatic Search Term Variant Generation. Journal of Documentation, Vol 40, No. 1.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sparck Jones</author>
<author>K</author>
<author>J I</author>
</authors>
<title>Tait (1984b), Linguistically Motivated Descriptive Term Selection.</title>
<booktitle>Proceedings of COLING 84, Association for Computational Linguistics,</booktitle>
<location>Stanford.</location>
<marker>Jones, K, I, </marker>
<rawString>Sparck Jones, K. and J. I. Tait (1984b), Linguistically Motivated Descriptive Term Selection. Proceedings of COLING 84, Association for Computational Linguistics, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J I Tait</author>
<author>K</author>
</authors>
<title>Sparck Jones</title>
<date>1983</date>
<location>Cambridge.</location>
<marker>Tait, K, 1983</marker>
<rawString>Tait, J.I. and K. Sparck Jones (1983), Automatic Search Term Variant Generation for Document Retrieval; British Library R&amp;D Report 5793, Cambridge.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>