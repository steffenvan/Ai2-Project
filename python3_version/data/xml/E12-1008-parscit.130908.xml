<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000007">
<title confidence="0.995732">
Dependency Parsing with Undirected Graphs
</title>
<author confidence="0.963852">
Carlos G´omez-Rodriguez
</author>
<affiliation confidence="0.8367745">
Departamento de Computaci´on
Universidade da Coru˜na
</affiliation>
<address confidence="0.906123">
Campus de Elvi˜na, 15071
A Coru˜na, Spain
</address>
<email confidence="0.997184">
carlos.gomez@udc.es
</email>
<author confidence="0.860447">
Daniel Fern´andez-Gonz´alez
</author>
<affiliation confidence="0.7802365">
Departamento de Inform´atica
Universidade de Vigo
</affiliation>
<address confidence="0.941719">
Campus As Lagoas, 32004
Ourense, Spain
</address>
<email confidence="0.998589">
danifg@uvigo.es
</email>
<sectionHeader confidence="0.994778" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999944105263158">
We introduce a new approach to transition-
based dependency parsing in which the
parser does not directly construct a depen-
dency structure, but rather an undirected
graph, which is then converted into a di-
rected dependency tree in a post-processing
step. This alleviates error propagation,
since undirected parsers do not need to ob-
serve the single-head constraint.
Undirected parsers can be obtained by sim-
plifying existing transition-based parsers
satisfying certain conditions. We apply this
approach to obtain undirected variants of
the planar and 2-planar parsers and of Cov-
ington’s non-projective parser. We perform
experiments on several datasets from the
CoNLL-X shared task, showing that these
variants outperform the original directed al-
gorithms in most of the cases.
</bodyText>
<sectionHeader confidence="0.998782" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999764352941176">
Dependency parsing has proven to be very use-
ful for natural language processing tasks. Data-
driven dependency parsers such as those by Nivre
et al. (2004), McDonald et al. (2005), Titov and
Henderson (2007), Martins et al. (2009) or Huang
and Sagae (2010) are accurate and efficient, they
can be trained from annotated data without the
need for a grammar, and they provide a simple
representation of syntax that maps to predicate-
argument structure in a straightforward way.
In particular, transition-based dependency
parsers (Nivre, 2008) are a type of dependency
parsing algorithms which use a model that scores
transitions between parser states. Greedy deter-
ministic search can be used to select the transition
to be taken at each state, thus achieving linear or
quadratic time complexity.
</bodyText>
<figureCaption confidence="0.991557">
Figure 1: An example dependency structure where
transition-based parsers enforcing the single-head con-
straint will incur in error propagation if they mistak-
enly build a dependency link 1 → 2 instead of 2 → 1
(dependency links are represented as arrows going
from head to dependent).
</figureCaption>
<bodyText confidence="0.99997276">
It has been shown by McDonald and Nivre
(2007) that such parsers suffer from error prop-
agation: an early erroneous choice can place the
parser in an incorrect state that will in turn lead to
more errors. For instance, suppose that a sentence
whose correct analysis is the dependency graph
in Figure 1 is analyzed by any bottom-up or left-
to-right transition-based parser that outputs de-
pendency trees, therefore obeying the single-head
constraint (only one incoming arc is allowed per
node). If the parser chooses an erroneous transi-
tion that leads it to build a dependency link from
1 to 2 instead of the correct link from 2 to 1, this
will lead it to a state where the single-head con-
straint makes it illegal to create the link from 3 to
2. Therefore, a single erroneous choice will cause
two attachment errors in the output tree.
With the goal of minimizing these sources of
errors, we obtain novel undirected variants of
several parsers; namely, of the planar and 2-
planar parsers by G´omez-Rodr´ıguez and Nivre
(2010) and the non-projective list-based parser
described by Nivre (2008), which is based on
Covington’s algorithm (Covington, 2001). These
variants work by collapsing the LEFT-ARC and
</bodyText>
<equation confidence="0.528609">
0 1 2 3
</equation>
<page confidence="0.829577">
66
</page>
<note confidence="0.9732665">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 66–76,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999053029411765">
RIGHT-ARC transitions in the original parsers,
which create right-to-left and left-to-right depen-
dency links, into a single ARC transition creating
an undirected link. This has the advantage that
the single-head constraint need not be observed
during the parsing process, since the directed no-
tions of head and dependent are lost in undirected
graphs. This gives the parser more freedom and
can prevent situations where enforcing the con-
straint leads to error propagation, as in Figure 1.
On the other hand, these new algorithms have
the disadvantage that their output is an undirected
graph, which has to be post-processed to recover
the direction of the dependency links and generate
a valid dependency tree. Thus, some complexity
is moved from the parsing process to this post-
processing step; and each undirected parser will
outperform the directed version only if the simpli-
fication of the parsing phase is able to avoid more
errors than are generated by the post-processing.
As will be seen in latter sections, experimental re-
sults indicate that this is in fact the case.
The rest of this paper is organized as follows:
Section 2 introduces some notation and concepts
that we will use throughout the paper. In Sec-
tion 3, we present the undirected versions of the
parsers by G´omez-Rodr´ıguez and Nivre (2010)
and Nivre (2008), as well as some considerations
about the feature models suitable to train them. In
Section 4, we discuss post-processing techniques
that can be used to recover dependency trees from
undirected graphs. Section 5 presents an empir-
ical study of the performance obtained by these
parsers, and Section 6 contains a final discussion.
</bodyText>
<sectionHeader confidence="0.997252" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<subsectionHeader confidence="0.999013">
2.1 Dependency Graphs
</subsectionHeader>
<bodyText confidence="0.998412444444444">
Let w = wi ... wn be an input string. A de-
pendency graph for w is a directed graph G =
(Vw, E), where Vw = 10, ... , n} is the set of
nodes, and E C Vw x Vw is the set of directed
arcs. Each node in Vw encodes the position of
a token in w, and each arc in E encodes a de-
pendency relation between two tokens. We write
i --+ j to denote a directed arc (i, j), which will
also be called a dependency link from i to j.1 We
</bodyText>
<footnote confidence="0.9662654">
1In practice, dependency links are usually labeled, but
to simplify the presentation we will ignore labels throughout
most of the paper. However, all the results and algorithms
presented can be applied to labeled dependency graphs and
will be so applied in the experimental evaluation.
</footnote>
<bodyText confidence="0.998568642857143">
say that i is the head of j and, conversely, that j
is a syntactic dependent of i.
Given a dependency graph G = (Vw, E), we
write i --+? j E E if there is a (possibly empty)
directed path from i to j; and i H? j E E if
there is a (possibly empty) path between i and j in
the undirected graph underlying G (omitting the
references to E when clear from the context).
Most dependency-based representations of syn-
tax do not allow arbitrary dependency graphs, in-
stead, they are restricted to acyclic graphs that
have at most one head per node. Dependency
graphs satisfying these constraints are called de-
pendency forests.
</bodyText>
<listItem confidence="0.8245345">
Definition 1 A dependency graph G is said to be
a forest iff it satisfies:
1. Acyclicity constraint: if i --+? j, then not
j --+ i.
2. Single-head constraint: if j i, then there
is no k =� j such that k --+ i.
</listItem>
<bodyText confidence="0.9558992">
A node that has no head in a dependency for-
est is called a root. Some dependency frame-
works add the additional constraint that depen-
dency forests have only one root (or, equivalently,
that they are connected). Such a forest is called a
dependency tree. A dependency tree can be ob-
tained from any dependency forest by linking all
of its root nodes as dependents of a dummy root
node, conventionally located in position 0 of the
input.
</bodyText>
<subsectionHeader confidence="0.999366">
2.2 Transition Systems
</subsectionHeader>
<bodyText confidence="0.999421">
In the framework of Nivre (2008), transition-
based parsers are described by means of a non-
deterministic state machine called a transition
system.
</bodyText>
<listItem confidence="0.897988666666667">
Definition 2 A transition system for dependency
parsing is a tuple S = (C, T, cs, Ct), where
1. C is a set ofpossible parser configurations,
2. T is a finite set of transitions, which are par-
tial functions t : C --+ C,
3. cs is a total initialization function mapping
each input string to a unique initial configu-
ration, and
4. Ct C C is a set of terminal configurations.
</listItem>
<bodyText confidence="0.998823333333334">
To obtain a deterministic parser from a non-
deterministic transition system, an oracle is used
to deterministically select a single transition at
</bodyText>
<page confidence="0.998986">
67
</page>
<bodyText confidence="0.9991038">
each configuration. An oracle for a transition sys-
tem 5 = (C, T, cs, Ct) is a function o : C —* T.
Suitable oracles can be obtained in practice by
training classifiers on treebank data (Nivre et al.,
2004).
</bodyText>
<subsectionHeader confidence="0.9994135">
2.3 The Planar, 2-Planar and Covington
Transition Systems
</subsectionHeader>
<bodyText confidence="0.999888428571429">
Our undirected dependency parsers are based
on the planar and 2-planar transition systems
by G´omez-Rodr´ıguez and Nivre (2010) and the
version of the Covington (2001) non-projective
parser defined by Nivre (2008). We now outline
these directed parsers briefly, a more detailed de-
scription can be found in the above references.
</bodyText>
<subsectionHeader confidence="0.644867">
2.3.1 Planar
</subsectionHeader>
<bodyText confidence="0.999292870967742">
The planar transition system by G´omez-
Rodr´ıguez and Nivre (2010) is a linear-time
transition-based parser for planar dependency
forests, i.e., forests whose dependency arcs do not
cross when drawn above the words. The set of
planar dependency structures is a very mild ex-
tension of that of projective structures (Kuhlmann
and Nivre, 2006).
Configurations in this system are of the form
c = (E, B, A) where E and B are disjoint lists of
nodes from V,,, (for some input w), and A is a set
of dependency links over V,,,. The list B, called
the buffer, holds the input words that are still to
be read. The list E, called the stack, is initially
empty and is used to hold words that have depen-
dency links pending to be created. The system
is shown at the top in Figure 2, where the nota-
tion E  |i is used for a stack with top i and tail E,
and we invert the notation for the buffer for clarity
(i.e., i  |B as a buffer with top i and tail B).
The system reads the input sentence and creates
links in a left-to-right order by executing its four
transitions, until it gets to a terminal configura-
tion. A SHIFT transition moves the first (leftmost)
node in the buffer to the top of the stack. Transi-
tions LEFT-ARC and RIGHT-ARC create leftward
or rightward link, respectively, involving the first
node in the buffer and the topmost node in the
stack. Finally, REDUCE transition is used to pop
the top word from the stack when we have fin-
ished building arcs to or from it.
</bodyText>
<subsectionHeader confidence="0.769415">
2.3.2 2-Planar
</subsectionHeader>
<bodyText confidence="0.999878736842105">
The 2-planar transition system by G´omez-
Rodr´ıguez and Nivre (2010) is an extension of
the planar system that uses two stacks, allowing
it to recognize 2-planar structures, a larger set
of dependency structures that has been shown to
cover the vast majority of non-projective struc-
tures in a number of treebanks (G´omez-Rodriguez
and Nivre, 2010).
This transition system, shown in Figure 2, has
configurations of the form c = (E0, E1, B, A) ,
where we call E0 the active stack and E1 the in-
active stack. Its SHIFT, LEFT-ARC, RIGHT-ARC
and REDUCE transitions work similarly to those
in the planar parser, but while SHIFT pushes the
first word in the buffer to both stacks; the other
three transitions only work with the top of the ac-
tive stack, ignoring the inactive one. Finally, a
SWITCH transition is added that makes the active
stack inactive and vice versa.
</bodyText>
<subsubsectionHeader confidence="0.605703">
2.3.3 Covington Non-Projective
</subsubsectionHeader>
<bodyText confidence="0.99993046875">
Covington (2001) proposes several incremen-
tal parsing strategies for dependency representa-
tions and one of them can recover non-projective
dependency graphs. Nivre (2008) implements a
variant of this strategy as a transition system with
configurations of the form c = (A1, A2, B, A),
where A1 and A2 are lists containing partially pro-
cessed words and B is the buffer list of unpro-
cessed words.
The Covington non-projective transition sys-
tem is shown at the bottom in Figure 2. At each
configuration c = (A1, A2, B, A), the parser has
to consider whether any dependency arc should
be created involving the top of the buffer and the
words in A1. A LEFT-ARC transition adds a link
from the first node j in the buffer to the node in the
head of the list A1, which is moved to the list A2
to signify that we have finished considering it as a
possible head or dependent of j. The RIGHT-ARC
transition does the same manipulation, but creat-
ing the symmetric link. A NO-ARC transition re-
moves the head of the list A1 and inserts it at the
head of the list A2 without creating any arcs: this
transition is to be used where there is no depen-
dency relation between the top node in the buffer
and the head of A1, but we still may want to cre-
ate an arc involving the top of the buffer and other
nodes in A1. Finally, if we do not want to create
any such arcs at all, we can execute a SHIFT tran-
sition, which advances the parsing process by re-
moving the first node in the buffer B and inserting
it at the head of a list obtained by concatenating
</bodyText>
<page confidence="0.996492">
68
</page>
<bodyText confidence="0.9618582">
A1 and A2. This list becomes the new A1, whereas
A2 is empty in the resulting configuration.
Note that the Covington parser has quadratic
complexity with respect to input length, while the
planar and 2-planar parsers run in linear time.
</bodyText>
<sectionHeader confidence="0.940036" genericHeader="method">
3 The Undirected Parsers
</sectionHeader>
<bodyText confidence="0.999059142857143">
The transition systems defined in Section 2.3
share the common property that their LEFT-ARC
and RIGHT-ARC have exactly the same effects ex-
cept for the direction of the links that they create.
We can take advantage of this property to define
undirected versions of these transition systems, by
transforming them as follows:
</bodyText>
<listItem confidence="0.9884874">
• Configurations are changed so that the arc set
A is a set of undirected arcs, instead of di-
rected arcs.
• The LEFT-ARC and RIGHT-ARC transitions
in each parser are collapsed into a single ARC
transition that creates an undirected arc.
• The preconditions of transitions that guaran-
tee the single-head constraint are removed,
since the notions of head and dependent are
lost in undirected graphs.
</listItem>
<bodyText confidence="0.999627076923077">
By performing these transformations and leaving
the systems otherwise unchanged, we obtain the
undirected variants of the planar, 2-planar and
Covington algorithms that are shown in Figure 3.
Note that the transformation can be applied
to any transition system having LEFT-ARC and
RIGHT-ARC transitions that are equal except for
the direction of the created link, and thus col-
lapsable into one. The above three transition sys-
tems fulfill this property, but not every transition
system does. For example, the well-known arc-
eager parser of Nivre (2003) pops a node from the
stack when creating left arcs, and pushes a node
to the stack when creating right arcs, so the trans-
formation cannot be applied to it.2
2One might think that the arc-eager algorithm could still
be transformed by converting each of its arc transitions into
an undirected transition, without collapsing them into one.
However, this would result into a parser that violates the
acyclicity constraint, since the algorithm is designed in such
a way that acyclicity is only guaranteed if the single-head
constraint is kept. It is easy to see that this problem cannot
happen in parsers where LEFT-ARC and RIGHT-ARC transi-
tions have the same effect: in these, if a directed graph is not
parsable in the original algorithm, its underlying undirected
graph cannot not be parsable in the undirected variant.
</bodyText>
<subsectionHeader confidence="0.999311">
3.1 Feature models
</subsectionHeader>
<bodyText confidence="0.999980133333333">
Some of the features that are typically used to
train transition-based dependency parsers depend
on the direction of the arcs that have been built up
to a certain point. For example, two such features
for the planar parser could be the POS tag associ-
ated with the head of the topmost stack node, or
the label of the arc going from the first node in the
buffer to its leftmost dependent.3
As the notion of head and dependent is lost in
undirected graphs, this kind of features cannot be
used to train undirected parsers. Instead, we use
features based on undirected relations between
nodes. We found that the following kinds of fea-
tures worked well in practice as a replacement for
features depending on arc direction:
</bodyText>
<listItem confidence="0.998586111111111">
• Information about the ith node linked to a
given node (topmost stack node, topmost
buffer node, etc.) on the left or on the right,
and about the associated undirected arc, typi-
cally for i = 1, 2, 3,
• Information about whether two nodes are
linked or not in the undirected graph, and
about the label of the arc between them,
• Information about the first left and right
</listItem>
<bodyText confidence="0.624978777777778">
“undirected siblings” of a given node, i.e., the
first node q located to the left of the given node
p such that p and q are linked to some common
node r located to the right of both, and vice
versa. Note that this notion of undirected sib-
lings does not correspond exclusively to sib-
lings in the directed graph, since it can also
capture other second-order interactions, such
as grandparents.
</bodyText>
<sectionHeader confidence="0.980492" genericHeader="method">
4 Reconstructing the dependency forest
</sectionHeader>
<bodyText confidence="0.999976818181818">
The modified transition systems presented in the
previous section generate undirected graphs. To
obtain complete dependency parsers that are able
to produce directed dependency forests, we will
need a reconstruction step that will assign a direc-
tion to the arcs in such a way that the single-head
constraint is obeyed. This reconstruction step can
be implemented by building a directed graph with
weighted arcs corresponding to both possible di-
rections of each undirected edge, and then finding
an optimum branching to reduce it to a directed
</bodyText>
<footnote confidence="0.990723">
3These example features are taken from the default model
for the planar parser in version 1.5 of MaltParser (Nivre et
al., 2006).
</footnote>
<page confidence="0.993798">
69
</page>
<table confidence="0.73184725">
Planar initial/terminal configurations: cs(w1 ... wn) = h[], [1... n], ∅i, Cf = {hΣ, [], Ai ∈ C}
Transitions: SHIFT hΣ, i|B, Ai ⇒ hΣ|i, B, Ai
REDUCE hΣ|i, B, Ai ⇒ hΣ, B, Ai
LEFT-ARC hΣ|i, j|B, Ai ⇒ hΣ|i, j|B, A ∪ {(j, i)}i
</table>
<equation confidence="0.711880058823529">
only if �k  |(k, i) ∈ A (single-head) and i ↔* j ∈6 A (acyclicity).
RIGHT-ARC hΣ|i, j|B,Ai ⇒ hΣ|i, j|B,A ∪ {(i, j)}i
only if �k  |(k, j) ∈ A (single-head) and i ↔* j ∈6 A (acyclicity).
2-Planar initial/terminal configurations: cs(w1 ... wn) = h[], [], [1... n], ∅i, Cf = {hΣ0, Σ1, [], Ai ∈ C}
Transitions: SHIFT hΣ0, Σ1, i|B, Ai ⇒ hΣ0|i, Σ1|i, B, Ai
REDUCE hΣ0|i, Σ1, B, Ai ⇒ hΣ0, Σ1, B, Ai
LEFT-ARC hΣ0|i,Σ1, j|B, Ai ⇒ hΣ0|i,Σ1, j|B,A ∪ {j,i)}i
only if �k  |(k, i) ∈ A (single-head) and i ↔* j ∈6 A (acyclicity).
RIGHT-ARC hΣ0|i, Σ1, j|B, Ai ⇒ hΣ0|i, Σ1, j|B, A ∪ {(i, j)}i
only if �k  |(k, j) ∈ A (single-head) and i ↔* j ∈6 A (acyclicity).
SWITCH hΣ0, Σ1, B, Ai ⇒ hΣ1, Σ0, B, Ai
Covington initial/term. configurations: cs(w1 ... wn) = h[], [], [1... n], ∅i, Cf = {hA1, A2, [], Ai ∈ C}
Transitions: SHIFT hA1, A2, i|B, Ai ⇒ hA1 · A2|i, [], B, Ai
NO-ARC hA1|i, A2, B, Ai ⇒ hA1, i|A2, B, Ai
LEFT-ARC hA1|i,A2,j|B,Ai ⇒ hA1,i|A2,j|B,A ∪ {(j,i)}i
only if �k  |(k, i) ∈ A (single-head) and i ↔* j ∈6 A (acyclicity).
RIGHT-ARC hA1|i, A2, j|B, Ai ⇒ hA1, i|A2, j|B, A ∪ {(i, j)}i
</equation>
<figureCaption confidence="0.768697">
only if �k  |(k, j) ∈ A (single-head) and i ↔* j ∈6 A (acyclicity).
Figure 2: Transition systems for planar, 2-planar and Covington non-projective dependency parsing.
</figureCaption>
<table confidence="0.9629522">
Undirected Planar initial/term. conf.: cs(w1 ... wn) = h[], [1... n], ∅i, Cf = {hΣ, [], Ai ∈ C}
Transitions: SHIFT hΣ, i|B, Ai ⇒ hΣ|i, B, Ai
REDUCE hΣ|i, B, Ai ⇒ hΣ, B, Ai
ARC hΣ|i, j|B,Ai ⇒ hΣ|i, j|B,A ∪ {{i, j}}i
only if i ↔* j ∈6 A (acyclicity).
Undirected 2-Planar initial/term. conf.: cs(w1 ... wn) = h[], [], [1... n], ∅i, Cf = {hΣ0, Σ1, [], Ai ∈ C}
Transitions: SHIFT hΣ0, Σ1, i|B, Ai ⇒ hΣ0|i, Σ1|i, B, Ai
REDUCE hΣ0|i, Σ1, B, Ai ⇒ hΣ0, Σ1, B, Ai
ARC hΣ0|i, Σ1, j|B,Ai ⇒ hΣ0|i,Σ1, j|B,A ∪ {{i, j}}i
only if i ↔* j ∈6 A (acyclicity).
SWITCH hΣ0, Σ1, B, Ai ⇒ hΣ1, Σ0, B, Ai
Undirected Covington init./term. conf.: cs(w1 ... wn) = h[], [], [1... n], ∅i, Cf = {hA1, A2, [], Ai ∈ C}
Transitions: SHIFT hA1, A2, i|B, Ai ⇒ hA1 · A2|i, [], B, Ai
NO-ARC hA1|i, A2, B, Ai ⇒ hA1, i|A2, B, Ai
ARC hA1|i,A2, j|B, Ai ⇒ hA1,i|A2, j|B,A ∪ {{i, j}}i
</table>
<figureCaption confidence="0.649939">
only if i ↔* j ∈6 A (acyclicity).
Figure 3: Transition systems for undirected planar, 2-planar and Covington non-projective dependency parsing.
</figureCaption>
<page confidence="0.987184">
70
</page>
<bodyText confidence="0.99989425">
tree. Different criteria for assigning weights to
arcs provide different variants of the reconstruc-
tion technique.
To describe these variants, we first introduce
preliminary definitions. Let U = (Vw, E) be
an undirected graph produced by an undirected
parser for some string w. We define the follow-
ing sets of arcs:
</bodyText>
<equation confidence="0.999893">
A1(U) = {(i, j() I j 7 f0 ∧ {i, j} E E},
A2(U) = {(0,i) I i E Vw}.
</equation>
<bodyText confidence="0.999930571428571">
Note that A1(U) represents the set of arcs ob-
tained from assigning an orientation to an edge
in U, except arcs whose dependent is the dummy
root, which are disallowed. On the other hand,
A2(U) contains all the possible arcs originating
from the dummy root node, regardless of whether
their underlying undirected edges are in U or not;
this is so that reconstructions are allowed to link
unattached tokens to the dummy root.
The reconstruction process consists of finding
a minimum branching (i.e. a directed minimum
spanning tree) for a weighted directed graph ob-
tained from assigning a cost c(i, j) to each arc
(i, j) of the following directed graph:
</bodyText>
<equation confidence="0.930728">
D(U) = {Vw, A(U) = A1(U) U A2(U)}.
</equation>
<bodyText confidence="0.99924165">
That is, we will find a dependency tree T =
(Vw, AT C A(U)) such that the sum of costs of
the arcs in AT is minimal. In general, such a min-
imum branching can be calculated with the Chu-
Liu-Edmonds algorithm (Chu and Liu, 1965; Ed-
monds, 1967). Since the graph D(U) has O(n)
nodes and O(n) arcs for a string of length n, this
can be done in O(n log n) if implemented as de-
scribed by Tarjan (1977).
However, applying these generic techniques is
not necessary in this case: since our graph U is
acyclic, the problem of reconstructing the forest
can be reduced to choosing a root word for each
connected component in the graph, linking it as
a dependent of the dummy root and directing the
other arcs in the component in the (unique) way
that makes them point away from the root.
It remains to see how to assign the costs c(i, j)
to the arcs of D(U): different criteria for assign-
ing scores will lead to different reconstructions.
</bodyText>
<subsectionHeader confidence="0.982041">
4.1 Naive reconstruction
</subsectionHeader>
<bodyText confidence="0.9998395">
A first, very simple reconstruction technique can
be obtained by assigning arc costs to the arcs in
</bodyText>
<equation confidence="0.911284666666667">
A(U) as follows:
{ 1 if (i, j) E A1(U),
c(i, j) 2 if (i, j) E A2(U) ∧ (i, j) E� A1(U).
</equation>
<bodyText confidence="0.999952178571428">
This approach gives the same cost to all arcs
obtained from the undirected graph U, while also
allowing (at a higher cost) to attach any node to
the dummy root. To obtain satisfactory results
with this technique, we must train our parser to
explicitly build undirected arcs from the dummy
root node to the root word(s) of each sentence us-
ing arc transitions (note that this implies that we
need to represent forests as trees, in the manner
described at the end of Section 2.1). Under this
assumption, it is easy to see that we can obtain the
correct directed tree T for a sentence if it is pro-
vided with its underlying undirected tree U: the
tree is obtained in O(n) as the unique orientation
of U that makes each of its edges point away from
the dummy root.
This approach to reconstruction has the advan-
tage of being very simple and not adding any com-
plications to the parsing process, while guarantee-
ing that the correct directed tree will be recovered
if the undirected tree for a sentence is generated
correctly. However, it is not very robust, since the
direction of all the arcs in the output depends on
which node is chosen as sentence head and linked
to the dummy root. Therefore, a parsing error af-
fecting the undirected edge involving the dummy
root may result in many dependency links being
erroneous.
</bodyText>
<subsectionHeader confidence="0.978226">
4.2 Label-based reconstruction
</subsectionHeader>
<bodyText confidence="0.9995470625">
To achieve a more robust reconstruction, we use
labels to encode a preferred direction for depen-
dency arcs. To do so, for each pre-existing label
X in the training set, we create two labels Xl and
Xr. The parser is then trained on a modified ver-
sion of the training set where leftward links orig-
inally labelled X are labelled Xl, and rightward
links originally labelled X are labelled Xr. Thus,
the output of the parser on a new sentence will be
an undirected graph where each edge has a label
with an annotation indicating whether the recon-
struction process should prefer to link the pair of
nodes with a leftward or a rightward arc. We can
then assign costs to our minimum branching algo-
rithm so that it will return a tree agreeing with as
many such annotations as possible.
</bodyText>
<page confidence="0.997074">
71
</page>
<bodyText confidence="0.999335">
To do this, we call A1+(U) C_ A1(U) the set
of arcs in A1(U) that agree with the annotations,
i.e., arcs (i, j) E A1(U) where either i &lt; j and
i, j is labelled Xr in U, or i &gt; j and i, j is labelled
Xl in U. We call A1−(U) the set of arcs in A1(U)
that disagree with the annotations, i.e., A1−(U) =
A1(U)\A1+(U). And we assign costs as follows:
</bodyText>
<equation confidence="0.879237333333333">
c(i, j) { 1 if (i, j) E A1+(U),
2 if (i, j) E A1−(U),
2n if (i, j) E A2(U) n (i, j) E� A1(U).
</equation>
<bodyText confidence="0.986970638888889">
where n is the length of the string.
With these costs, the minimum branching algo-
rithm will find a tree which agrees with as many
annotations as possible. Additional arcs from the
root not corresponding to any edge in the output
of the parser (i.e. arcs in A2(U) but not in A1(U))
will be used only if strictly necessary to guarantee
connectedness, this is implemented by the high
cost for these arcs.
While this may be the simplest cost assignment
to implement label-based reconstruction, we have
found that better empirical results are obtained if
we give the algorithm more freedom to create new
arcs from the root, as follows:
c(i, j)
While the cost of arcs from the dummy root is
still 2n, this is now so even for arcs that are in the
output of the undirected parser, which had cost 1
before. Informally, this means that with this con-
figuration the postprocessor does not “trust” the
links from the dummy root created by the parser,
and may choose to change them if it is conve-
nient to get a better agreement with label anno-
tations (see Figure 4 for an example of the dif-
ference between both cost assignments). We be-
lieve that the better accuracy obtained with this
criterion probably stems from the fact that it is bi-
ased towards changing links from the root, which
tend to be more problematic for transition-based
parsers, while respecting the parser output for
links located deeper in the dependency structure,
for which transition-based parsers tend to be more
accurate (McDonald and Nivre, 2007).
Note that both variants of label-based recon-
struction have the property that, if the undirected
parser produces the correct edges and labels for a
</bodyText>
<figure confidence="0.965638666666667">
0 1 2 3 4 5
0 1 2 3 4 5
0 1 2 3 4 5
</figure>
<figureCaption confidence="0.9027504">
Figure 4: a) An undirected graph obtained by the
parser with the label-based transformation, b) and c)
The dependency graph obtained by each of the variants
of the label-based reconstruction (note how the second
variant moves an arc from the root).
</figureCaption>
<bodyText confidence="0.999935">
given sentence, then the obtained directed tree is
guaranteed to be correct (as it will simply be the
tree obtained by decoding the label annotations).
</bodyText>
<sectionHeader confidence="0.998197" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999814384615384">
In this section, we evaluate the performance of the
undirected planar, 2-planar and Covington parsers
on eight datasets from the CoNLL-X shared task
(Buchholz and Marsi, 2006).
Tables 1, 2 and 3 compare the accuracy of the
undirected versions with naive and label-based re-
construction to that of the directed versions of
the planar, 2-planar and Covington parsers, re-
spectively. In addition, we provide a comparison
to well-known state-of-the-art projective and non-
projective parsers: the planar parsers are com-
pared to the arc-eager projective parser by Nivre
(2003), which is also restricted to planar struc-
tures; and the 2-planar parsers are compared with
the arc-eager parser with pseudo-projective trans-
formation of Nivre and Nilsson (2005), capable of
handling non-planar dependencies.
We use SVM classifiers from the LIBSVM
package (Chang and Lin, 2001) for all the lan-
guages except Chinese, Czech and German. In
these, we use the LIBLINEAR package (Fan et
al., 2008) for classification, which reduces train-
ing time for these larger datasets; and feature
models adapted to this system which, in the case
of German, result in higher accuracy than pub-
lished results using LIBSVM.
</bodyText>
<equation confidence="0.9374892">
R
R L L L
{ 1 if (i, j) E A1+(U) n (i, j) E� A2(U),
2 if (i, j) E A1−(U) n (i, j) E� A2(U),
2n if (i, j) E A2(U).
</equation>
<page confidence="0.973792">
72
</page>
<bodyText confidence="0.999961685714286">
The LIBSVM feature models for the arc-eager
projective and pseudo-projective parsers are the
same used by these parsers in the CoNLL-X
shared task, where the pseudo-projective version
of MaltParser was one of the two top performing
systems (Buchholz and Marsi, 2006). For the 2-
planar parser, we took the feature models from
G´omez-Rodr´ıguez and Nivre (2010) for the lan-
guages included in that paper. For all the algo-
rithms and datasets, the feature models used for
the undirected parsers were adapted from those of
the directed parsers as described in Section 3.1.4
The results show that the use of undirected
parsing with label-based reconstruction clearly
improves the performance in the vast majority of
the datasets for the planar and Covington algo-
rithms, where in many cases it also improves upon
the corresponding projective and non-projective
state-of-the-art parsers provided for comparison.
In the case of the 2-planar parser the results are
less conclusive, with improvements over the di-
rected versions in five out of the eight languages.
The improvements in LAS obtained with label-
based reconstruction over directed parsing are sta-
tistically significant at the .05 level5 for Danish,
German and Portuguese in the case of the pla-
nar parser; and Czech, Danish and Turkish for
Covington’s parser. No statistically significant de-
crease in accuracy was detected in any of the al-
gorithm/dataset combinations.
As expected, the good results obtained by the
undirected parsers with label-based reconstruc-
tion contrast with those obtained by the variants
with root-based reconstruction, which performed
worse in all the experiments.
</bodyText>
<sectionHeader confidence="0.997934" genericHeader="conclusions">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999977111111111">
We have presented novel variants of the planar
and 2-planar transition-based parsers by G´omez-
Rodr´ıguez and Nivre (2010) and of Covington’s
non-projective parser (Covington, 2001; Nivre,
2008) which ignore the direction of dependency
links, and reconstruction techniques that can be
used to recover the direction of the arcs thus pro-
duced. The results obtained show that this idea
of undirected parsing, together with the label-
</bodyText>
<footnote confidence="0.9841795">
4All the experimental settings and feature models used
are included in the supplementary material and also available
athttp://www.grupolys.org/-cgomezr/exp/.
5Statistical significance was assessed using Dan Bikel’s
randomized comparator: http://www.cis.upenn.
edu/-dbikel/software.html
</footnote>
<bodyText confidence="0.999973547619048">
based reconstruction technique of Section 4.2, im-
proves parsing accuracy on most of the tested
dataset/algorithm combinations, and it can out-
perform state-of-the-art transition-based parsers.
The accuracy improvements achieved by re-
laxing the single-head constraint to mitigate er-
ror propagation were able to overcome the er-
rors generated in the reconstruction phase, which
were few: we observed empirically that the dif-
ferences between the undirected LAS obtained
from the undirected graph before the reconstruc-
tion and the final directed LAS are typically be-
low 0.20%. This is true both for the naive and
label-based transformations, indicating that both
techniques are able to recover arc directions accu-
rately, and the accuracy differences between them
come mainly from the differences in training (e.g.
having tentative arc direction as part of feature
information in the label-based reconstruction and
not in the naive one) rather than from the differ-
ences in the reconstruction methods themselves.
The reason why we can apply the undirected
simplification to the three parsers that we have
used in this paper is that their LEFT-ARC and
RIGHT-ARC transitions have the same effect ex-
cept for the direction of the links they create.
The same transformation and reconstruction tech-
niques could be applied to any other transition-
based dependency parsers sharing this property.
The reconstruction techniques alone could po-
tentially be applied to any dependency parser
(transition-based or not) as long as it can be some-
how converted to output undirected graphs.
The idea of parsing with undirected relations
between words has been applied before in the
work on Link Grammar (Sleator and Temperley,
1991), but in that case the formalism itself works
with undirected graphs, which are the final out-
put of the parser. To our knowledge, the idea of
using an undirected graph as an intermediate step
towards obtaining a dependency structure has not
been explored before.
</bodyText>
<sectionHeader confidence="0.998044" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.988677333333333">
This research has been partially funded by the Spanish
Ministry of Economy and Competitiveness and FEDER
(projects TIN2010-18552-C03-01 and TIN2010-18552-
C03-02), Ministry of Education (FPU Grant Program) and
Xunta de Galicia (Rede Galega de Recursos Ling¨uisticos
para unha Soc. do Co˜nec.). The experiments were conducted
with the help of computing resources provided by the Su-
percomputing Center of Galicia (CESGA). We thank Joakim
Nivre for helpful input in the early stages of this work.
</bodyText>
<page confidence="0.995329">
73
</page>
<table confidence="0.9998591">
Planar UPlanarN UPlanarL MaltP
Lang. LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p)
Arabic 66.93 (67.34) 77.56 (77.22) 65.91 (66.33) 77.03 (76.75) 66.75 (67.19) 77.45 (77.22) 66.43 (66.74) 77.19 (76.83)
Chinese 84.23 (84.20) 88.37 (88.33) 83.14 (83.10) 87.00 (86.95) 84.51* (84.50*) 88.37 (88.35*) 86.42 (86.39) 90.06 (90.02)
Czech 77.24 (77.70) 83.46 (83.24) 75.08 (75.60) 81.14 (81.14) 77.60* (77.93*) 83.56* (83.41*) 77.24 (77.57) 83.40 (83.19)
Danish 83.31 (82.60) 88.02 (86.64) 82.65 (82.45) 87.58 (86.67*) 83.87* (83.83*) 88.94* (88.17*) 83.31 (82.64) 88.30 (86.91)
German 84.66 (83.60) 87.02 (85.67) 83.33 (82.77) 85.78 (84.93) 86.32* (85.67*) 88.62* (87.69*) 86.12 (85.48) 88.52 (87.58)
Portug. 86.22 (83.82) 89.80 (86.88) 85.89 (83.82) 89.68 (87.06*) 86.52* (84.83*) 90.28* (88.03*) 86.60 (84.66) 90.20 (87.73)
Swedish 83.01 (82.44) 88.53 (87.36) 81.20 (81.10) 86.50 (85.86) 82.95 (82.66*) 88.29 (87.45*) 82.89 (82.44) 88.61 (87.55)
Turkish 62.70 (71.27) 73.67 (78.57) 59.83 (68.31) 70.15 (75.17) 63.27* (71.63*) 73.93* (78.72*) 62.58 (70.96) 73.09 (77.95)
</table>
<tableCaption confidence="0.84755675">
Table 1: Parsing accuracy of the undirected planar parser with naive (UPlanarN) and label-based (UPlanarL)
postprocessing in comparison to the directed planar (Planar) and the MaltParser arc-eager projective (MaltP)
algorithms, on eight datasets from the CoNLL-X shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al.,
2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et
al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003;
Atalay et al., 2003). We show labelled (LAS) and unlabelled (UAS) attachment score excluding and including
punctuation tokens in the scoring (the latter in brackets). Best results for each language are shown in boldface,
and results where the undirected parser outperforms the directed version are marked with an asterisk.
</tableCaption>
<table confidence="0.9997902">
2Planar U2PlanarN U2PlanarL MaltPP
Lang. LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p)
Arabic 66.73 (67.19) 77.33 (77.11) 66.37 (66.93) 77.15 (77.09) 66.13 (66.52) 76.97 (76.70) 65.93 (66.02) 76.79 (76.14)
Chinese 84.35 (84.32) 88.31 (88.27) 83.02 (82.98) 86.86 (86.81) 84.45* (84.42*) 88.29 (88.25) 86.42 (86.39) 90.06 (90.02)
Czech 77.72 (77.91) 83.76 (83.32) 74.44 (75.19) 80.68 (80.80) 78.00* (78.59*) 84.22* (84.21*) 78.86 (78.47) 84.54 (83.89)
Danish 83.81 (83.61) 88.50 (87.63) 82.00 (81.63) 86.87 (85.80) 83.75 (83.65*) 88.62* (87.82*) 83.67 (83.54) 88.52 (87.70)
German 86.28 (85.76) 88.68 (87.86) 82.93 (82.53) 85.52 (84.81) 86.52* (85.99*) 88.72* (87.92*) 86.94 (86.62) 89.30 (88.69)
Portug. 87.04 (84.92) 90.82 (88.14) 85.61 (83.45) 89.36 (86.65) 86.70 (84.75) 90.38 (87.88) 87.08 (84.90) 90.66 (87.95)
Swedish 83.13 (82.71) 88.57 (87.59) 81.00 (80.71) 86.54 (85.68) 82.59 (82.25) 88.19 (87.29) 83.39 (82.67) 88.59 (87.38)
Turkish 61.80 (70.09) 72.75 (77.39) 58.10 (67.44) 68.03 (74.06) 61.92* (70.64*) 72.18 (77.46*) 62.80 (71.33) 73.49 (78.44)
</table>
<tableCaption confidence="0.992710333333333">
Table 2: Parsing accuracy of the undirected 2-planar parser with naive (U2PlanarN) and label-based (U2PlanarL)
postprocessing in comparison to the directed 2-planar (2Planar) and MaltParser arc-eager pseudo-projective
(MaltPP) algorithms. The meaning of the scores shown is as in Table 1.
</tableCaption>
<table confidence="0.9998171">
Covington UCovingtonN UCovingtonL
Lang. LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p)
Arabic 65.17 (65.49) 75.99 (75.69) 63.49 (63.93) 74.41 (74.20) 65.61* (65.81*) 76.11* (75.66)
Chinese 85.61 (85.61) 89.64 (89.62) 84.12 (84.02) 87.85 (87.73) 86.28* (86.17*) 90.16* (90.04*)
Czech 78.26 (77.43) 84.04 (83.15) 74.02 (74.78) 79.80 (79.92) 78.42* (78.69*) 84.50* (84.16*)
Danish 83.63 (82.89) 88.50 (87.06) 82.00 (81.61) 86.55 (85.51) 84.27* (83.85*) 88.82* (87.75*)
German 86.70 (85.69) 89.08 (87.78) 84.03 (83.51) 86.16 (85.39) 86.50 (85.90*) 88.84 (87.95*)
Portug. 84.73 (82.56) 89.10 (86.30) 83.83 (81.71) 87.88 (85.17) 84.95* (82.70*) 89.18* (86.31*)
Swedish 83.53 (82.76) 88.91 (87.61) 81.78 (81.47) 86.78 (85.96) 83.09 (82.73) 88.11 (87.23)
Turkish 64.25 (72.70) 74.85 (79.75) 63.51 (72.08) 74.07 (79.10) 64.91* (73.38*) 75.46* (80.40*)
</table>
<tableCaption confidence="0.971674666666667">
Table 3: Parsing accuracy of the undirected Covington non-projective parser with naive (UCovingtonN) and
label-based (UCovingtonL) postprocessing in comparison to the directed algorithm (Covington). The meaning
of the scores shown is as in Table 1.
</tableCaption>
<page confidence="0.998353">
74
</page>
<sectionHeader confidence="0.983229" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999784504424779">
Susana Afonso, Eckhard Bick, Renato Haber, and Di-
ana Santos. 2002. “Floresta sint´a(c)tica”: a tree-
bank for Portuguese. In Proceedings of the 3rd In-
ternational Conference on Language Resources and
Evaluation (LREC 2002), pages 1968–1703, Paris,
France. ELRA.
Nart B. Atalay, Kemal Oflazer, and Bilge Say. 2003.
The annotation process in the Turkish treebank.
In Proceedings of EACL Workshop on Linguisti-
cally Interpreted Corpora (LINC-03), pages 243–
246, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolf-
gang Lezius, and George Smith. 2002. The tiger
treebank. In Proceedings of the Workshop on Tree-
banks and Linguistic Theories, September 20-21,
Sozopol, Bulgaria.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proceedings of the 10th Conference on Computa-
tional Natural Language Learning (CoNLL), pages
149–164.
Chih-Chung Chang and Chih-Jen Lin, 2001.
LIBSVM: A Library for Support Vec-
tor Machines. Software available at
http://www.csie.ntu.edu.tw/∼cjlin/libsvm.
K. Chen, C. Luo, M. Chang, F. Chen, C. Chen,
C. Huang, and Z. Gao. 2003. Sinica treebank: De-
sign criteria, representational issues and implemen-
tation. In Anne Abeill´e, editor, Treebanks: Building
and Using Parsed Corpora, chapter 13, pages 231–
248. Kluwer.
Y. J. Chu and T. H. Liu. 1965. On the shortest arbores-
cence of a directed graph. Science Sinica, 14:1396–
1400.
Michael A. Covington. 2001. A fundamental algo-
rithm for dependency parsing. In Proceedings of
the 39th Annual ACM Southeast Conference, pages
95–102.
Jack Edmonds. 1967. Optimum branchings. Journal
of Research of the National Bureau of Standards,
71B:233–240.
R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and
C.-J. Lin. 2008. LIBLINEAR: A library for large
linear classification. Journal of Machine Learning
Research, 9:1871–1874.
Carlos G´omez-Rodriguez and Joakim Nivre. 2010.
A transition-based parser for 2-planar dependency
structures. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguis-
tics, ACL ’10, pages 1492–1501, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Jan Hajiˇc, Otakar Smrˇz, Petr Zem´anek, Jan ˇSnaidauf,
and Emanuel Beˇska. 2004. Prague Arabic Depen-
dency Treebank: Development in data and tools. In
Proceedings of the NEMLAR International Confer-
ence on Arabic Language Resources and Tools.
Jan Hajiˇc, Jarmila Panevov´a, Eva Hajiˇcov´a, Jarmila
Panevov´a, Petr Sgall, Petr Pajas, Jan ˇStˇep´anek,
JiˇriHavelka, and Marie Mikulov´a. 2006.
Prague Dependency Treebank 2.0. CDROM CAT:
LDC2006T01, ISBN 1-58563-370-4. Linguistic
Data Consortium.
Liang Huang and Kenji Sagae. 2010. Dynamic pro-
gramming for linear-time incremental parsing. In
Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics, ACL ’10,
pages 1077–1086, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
Matthias T. Kromann. 2003. The Danish dependency
treebank and the underlying linguistic theory. In
Proceedings of the 2nd Workshop on Treebanks and
Linguistic Theories (TLT), pages 217–220, V¨axj¨o,
Sweden. V¨axj¨o University Press.
Marco Kuhlmann and Joakim Nivre. 2006. Mildly
non-projective dependency structures. In Proceed-
ings of the COLING/ACL 2006 Main Conference
Poster Sessions, pages 507–514.
Andre Martins, Noah Smith, and Eric Xing. 2009.
Concise integer linear programming formulations
for dependency parsing. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP (ACL-
IJCNLP), pages 342–350.
Ryan McDonald and Joakim Nivre. 2007. Character-
izing the errors of data-driven dependency parsing
models. In Proceedings of the 2007 Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning (EMNLP-CoNLL), pages 122–131.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajiˇc. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings
of the Human Language Technology Conference
and the Conference on Empirical Methods in Nat-
ural Language Processing (HLT/EMNLP), pages
523–530.
Jens Nilsson, Johan Hall, and Joakim Nivre. 2005.
MAMBA meets TIGER: Reconstructing a Swedish
treebank from Antiquity. In Peter Juel Henrichsen,
editor, Proceedings of the NODALIDA Special Ses-
sion on Treebanks.
Joakim Nivre and Jens Nilsson. 2005. Pseudo-
projective dependency parsing. In Proceedings of
the 43rd Annual Meeting of the Association for
Computational Linguistics (ACL), pages 99–106.
Joakim Nivre, Johan Hall, and Jens Nilsson. 2004.
Memory-based dependency parsing. In Proceed-
ings of the 8th Conference on Computational Nat-
ural Language Learning (CoNLL-2004), pages 49–
56, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
</reference>
<page confidence="0.979381">
75
</page>
<reference confidence="0.997779444444444">
Joakim Nivre, Johan Hall, and Jens Nilsson. 2006.
MaltParser: A data-driven parser-generator for de-
pendency parsing. In Proceedings of the 5th In-
ternational Conference on Language Resources and
Evaluation (LREC), pages 2216–2219.
Joakim Nivre. 2003. An efficient algorithm for pro-
jective dependency parsing. In Proceedings of the
8th International Workshop on Parsing Technolo-
gies (IWPT), pages 149–160.
Joakim Nivre. 2008. Algorithms for Deterministic
Incremental Dependency Parsing. Computational
Linguistics, 34(4):513–553.
Kemal Oflazer, Bilge Say, Dilek Zeynep Hakkani-T¨ur,
and G¨okhan T¨ur. 2003. Building a Turkish tree-
bank. In Anne Abeill´e, editor, Treebanks: Build-
ing and Using Parsed Corpora, pages 261–277.
Kluwer.
Daniel Sleator and Davy Temperley. 1991. Pars-
ing English with a link grammar. Technical Re-
port CMU-CS-91-196, Carnegie Mellon University,
Computer Science.
R. E. Tarjan. 1977. Finding optimum branchings.
Networks, 7:25–35.
Ivan Titov and James Henderson. 2007. A latent vari-
able model for generative dependency parsing. In
Proceedings of the 10th International Conference
on Parsing Technologies (IWPT), pages 144–155.
</reference>
<page confidence="0.991289">
76
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.083050">
<title confidence="0.999453">Dependency Parsing with Undirected Graphs</title>
<author confidence="0.612807">Carlos</author>
<abstract confidence="0.570313">Departamento de da de carlos.gomez@udc.es</abstract>
<author confidence="0.861685">Daniel</author>
<affiliation confidence="0.914719666666667">Departamento de Universidade de Campus As Lagoas,</affiliation>
<address confidence="0.978032">Ourense,</address>
<email confidence="0.997545">danifg@uvigo.es</email>
<abstract confidence="0.9955631">We introduce a new approach to transitionbased dependency parsing in which the parser does not directly construct a dependency structure, but rather an undirected graph, which is then converted into a directed dependency tree in a post-processing step. This alleviates error propagation, since undirected parsers do not need to observe the single-head constraint. Undirected parsers can be obtained by simplifying existing transition-based parsers satisfying certain conditions. We apply this approach to obtain undirected variants of the planar and 2-planar parsers and of Covington’s non-projective parser. We perform experiments on several datasets from the CoNLL-X shared task, showing that these variants outperform the original directed algorithms in most of the cases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Susana Afonso</author>
<author>Eckhard Bick</author>
<author>Renato Haber</author>
<author>Diana Santos</author>
</authors>
<title>Floresta sint´a(c)tica”: a treebank for Portuguese.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>1968--1703</pages>
<location>Paris, France. ELRA.</location>
<contexts>
<context position="34057" citStr="Afonso et al., 2002" startWordPosition="5847" endWordPosition="5850">.44) 88.61 (87.55) Turkish 62.70 (71.27) 73.67 (78.57) 59.83 (68.31) 70.15 (75.17) 63.27* (71.63*) 73.93* (78.72*) 62.58 (70.96) 73.09 (77.95) Table 1: Parsing accuracy of the undirected planar parser with naive (UPlanarN) and label-based (UPlanarL) postprocessing in comparison to the directed planar (Planar) and the MaltParser arc-eager projective (MaltP) algorithms, on eight datasets from the CoNLL-X shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al., 2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). We show labelled (LAS) and unlabelled (UAS) attachment score excluding and including punctuation tokens in the scoring (the latter in brackets). Best results for each language are shown in boldface, and results where the undirected parser outperforms the directed version are marked with an asterisk. 2Planar U2PlanarN U2PlanarL MaltPP Lang. LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p) Arabic 66.73 (67.19) 77.33 (77.11) 66.37 (66.93) 77.15 (77.09) 66.13 (66.52) 76.97 (76.70) 65.93 (66.02) 76.79 (</context>
</contexts>
<marker>Afonso, Bick, Haber, Santos, 2002</marker>
<rawString>Susana Afonso, Eckhard Bick, Renato Haber, and Diana Santos. 2002. “Floresta sint´a(c)tica”: a treebank for Portuguese. In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC 2002), pages 1968–1703, Paris, France. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nart B Atalay</author>
<author>Kemal Oflazer</author>
<author>Bilge Say</author>
</authors>
<title>The annotation process in the Turkish treebank.</title>
<date>2003</date>
<booktitle>In Proceedings of EACL Workshop on Linguistically Interpreted Corpora (LINC-03),</booktitle>
<pages>243--246</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="34145" citStr="Atalay et al., 2003" startWordPosition="5862" endWordPosition="5865">* (71.63*) 73.93* (78.72*) 62.58 (70.96) 73.09 (77.95) Table 1: Parsing accuracy of the undirected planar parser with naive (UPlanarN) and label-based (UPlanarL) postprocessing in comparison to the directed planar (Planar) and the MaltParser arc-eager projective (MaltP) algorithms, on eight datasets from the CoNLL-X shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al., 2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). We show labelled (LAS) and unlabelled (UAS) attachment score excluding and including punctuation tokens in the scoring (the latter in brackets). Best results for each language are shown in boldface, and results where the undirected parser outperforms the directed version are marked with an asterisk. 2Planar U2PlanarN U2PlanarL MaltPP Lang. LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p) Arabic 66.73 (67.19) 77.33 (77.11) 66.37 (66.93) 77.15 (77.09) 66.13 (66.52) 76.97 (76.70) 65.93 (66.02) 76.79 (76.14) Chinese 84.35 (84.32) 88.31 (88.27) 83.02 (82.98) 86.86 (86.81) 84.45* (84.42*) 8</context>
</contexts>
<marker>Atalay, Oflazer, Say, 2003</marker>
<rawString>Nart B. Atalay, Kemal Oflazer, and Bilge Say. 2003. The annotation process in the Turkish treebank. In Proceedings of EACL Workshop on Linguistically Interpreted Corpora (LINC-03), pages 243– 246, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Brants</author>
<author>Stefanie Dipper</author>
<author>Silvia Hansen</author>
<author>Wolfgang Lezius</author>
<author>George Smith</author>
</authors>
<title>The tiger treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Treebanks and Linguistic Theories,</booktitle>
<location>Sozopol, Bulgaria.</location>
<contexts>
<context position="34023" citStr="Brants et al., 2002" startWordPosition="5842" endWordPosition="5845"> (82.66*) 88.29 (87.45*) 82.89 (82.44) 88.61 (87.55) Turkish 62.70 (71.27) 73.67 (78.57) 59.83 (68.31) 70.15 (75.17) 63.27* (71.63*) 73.93* (78.72*) 62.58 (70.96) 73.09 (77.95) Table 1: Parsing accuracy of the undirected planar parser with naive (UPlanarN) and label-based (UPlanarL) postprocessing in comparison to the directed planar (Planar) and the MaltParser arc-eager projective (MaltP) algorithms, on eight datasets from the CoNLL-X shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al., 2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). We show labelled (LAS) and unlabelled (UAS) attachment score excluding and including punctuation tokens in the scoring (the latter in brackets). Best results for each language are shown in boldface, and results where the undirected parser outperforms the directed version are marked with an asterisk. 2Planar U2PlanarN U2PlanarL MaltPP Lang. LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p) Arabic 66.73 (67.19) 77.33 (77.11) 66.37 (66.93) 77.15 (77.09) 66.13 (66.52) 7</context>
</contexts>
<marker>Brants, Dipper, Hansen, Lezius, Smith, 2002</marker>
<rawString>Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang Lezius, and George Smith. 2002. The tiger treebank. In Proceedings of the Workshop on Treebanks and Linguistic Theories, September 20-21, Sozopol, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>149--164</pages>
<contexts>
<context position="26533" citStr="Buchholz and Marsi, 2006" startWordPosition="4699" endWordPosition="4702"> 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 Figure 4: a) An undirected graph obtained by the parser with the label-based transformation, b) and c) The dependency graph obtained by each of the variants of the label-based reconstruction (note how the second variant moves an arc from the root). given sentence, then the obtained directed tree is guaranteed to be correct (as it will simply be the tree obtained by decoding the label annotations). 5 Experiments In this section, we evaluate the performance of the undirected planar, 2-planar and Covington parsers on eight datasets from the CoNLL-X shared task (Buchholz and Marsi, 2006). Tables 1, 2 and 3 compare the accuracy of the undirected versions with naive and label-based reconstruction to that of the directed versions of the planar, 2-planar and Covington parsers, respectively. In addition, we provide a comparison to well-known state-of-the-art projective and nonprojective parsers: the planar parsers are compared to the arc-eager projective parser by Nivre (2003), which is also restricted to planar structures; and the 2-planar parsers are compared with the arc-eager parser with pseudo-projective transformation of Nivre and Nilsson (2005), capable of handling non-plan</context>
<context position="27926" citStr="Buchholz and Marsi, 2006" startWordPosition="4935" endWordPosition="4938">NEAR package (Fan et al., 2008) for classification, which reduces training time for these larger datasets; and feature models adapted to this system which, in the case of German, result in higher accuracy than published results using LIBSVM. R R L L L { 1 if (i, j) E A1+(U) n (i, j) E� A2(U), 2 if (i, j) E A1−(U) n (i, j) E� A2(U), 2n if (i, j) E A2(U). 72 The LIBSVM feature models for the arc-eager projective and pseudo-projective parsers are the same used by these parsers in the CoNLL-X shared task, where the pseudo-projective version of MaltParser was one of the two top performing systems (Buchholz and Marsi, 2006). For the 2- planar parser, we took the feature models from G´omez-Rodr´ıguez and Nivre (2010) for the languages included in that paper. For all the algorithms and datasets, the feature models used for the undirected parsers were adapted from those of the directed parsers as described in Section 3.1.4 The results show that the use of undirected parsing with label-based reconstruction clearly improves the performance in the vast majority of the datasets for the planar and Covington algorithms, where in many cases it also improves upon the corresponding projective and non-projective state-of-the</context>
<context position="33881" citStr="Buchholz and Marsi, 2006" startWordPosition="5819" endWordPosition="5822">2) 89.68 (87.06*) 86.52* (84.83*) 90.28* (88.03*) 86.60 (84.66) 90.20 (87.73) Swedish 83.01 (82.44) 88.53 (87.36) 81.20 (81.10) 86.50 (85.86) 82.95 (82.66*) 88.29 (87.45*) 82.89 (82.44) 88.61 (87.55) Turkish 62.70 (71.27) 73.67 (78.57) 59.83 (68.31) 70.15 (75.17) 63.27* (71.63*) 73.93* (78.72*) 62.58 (70.96) 73.09 (77.95) Table 1: Parsing accuracy of the undirected planar parser with naive (UPlanarN) and label-based (UPlanarL) postprocessing in comparison to the directed planar (Planar) and the MaltParser arc-eager projective (MaltP) algorithms, on eight datasets from the CoNLL-X shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al., 2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). We show labelled (LAS) and unlabelled (UAS) attachment score excluding and including punctuation tokens in the scoring (the latter in brackets). Best results for each language are shown in boldface, and results where the undirected parser outperforms the directed version are marked with an asterisk. 2Planar U2PlanarN U2PlanarL MaltP</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL), pages 149–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A Library for Support Vector Machines. Software available at http://www.csie.ntu.edu.tw/∼cjlin/libsvm.</title>
<date>2001</date>
<contexts>
<context position="27218" citStr="Chang and Lin, 2001" startWordPosition="4804" endWordPosition="4807">ns with naive and label-based reconstruction to that of the directed versions of the planar, 2-planar and Covington parsers, respectively. In addition, we provide a comparison to well-known state-of-the-art projective and nonprojective parsers: the planar parsers are compared to the arc-eager projective parser by Nivre (2003), which is also restricted to planar structures; and the 2-planar parsers are compared with the arc-eager parser with pseudo-projective transformation of Nivre and Nilsson (2005), capable of handling non-planar dependencies. We use SVM classifiers from the LIBSVM package (Chang and Lin, 2001) for all the languages except Chinese, Czech and German. In these, we use the LIBLINEAR package (Fan et al., 2008) for classification, which reduces training time for these larger datasets; and feature models adapted to this system which, in the case of German, result in higher accuracy than published results using LIBSVM. R R L L L { 1 if (i, j) E A1+(U) n (i, j) E� A2(U), 2 if (i, j) E A1−(U) n (i, j) E� A2(U), 2n if (i, j) E A2(U). 72 The LIBSVM feature models for the arc-eager projective and pseudo-projective parsers are the same used by these parsers in the CoNLL-X shared task, where the </context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin, 2001. LIBSVM: A Library for Support Vector Machines. Software available at http://www.csie.ntu.edu.tw/∼cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Chen</author>
<author>C Luo</author>
<author>M Chang</author>
<author>F Chen</author>
<author>C Chen</author>
<author>C Huang</author>
<author>Z Gao</author>
</authors>
<title>Sinica treebank: Design criteria, representational issues and implementation.</title>
<date>2003</date>
<booktitle>Treebanks: Building and Using Parsed Corpora, chapter 13,</booktitle>
<pages>231--248</pages>
<editor>In Anne Abeill´e, editor,</editor>
<publisher>Kluwer.</publisher>
<contexts>
<context position="33940" citStr="Chen et al., 2003" startWordPosition="5829" endWordPosition="5832">.20 (87.73) Swedish 83.01 (82.44) 88.53 (87.36) 81.20 (81.10) 86.50 (85.86) 82.95 (82.66*) 88.29 (87.45*) 82.89 (82.44) 88.61 (87.55) Turkish 62.70 (71.27) 73.67 (78.57) 59.83 (68.31) 70.15 (75.17) 63.27* (71.63*) 73.93* (78.72*) 62.58 (70.96) 73.09 (77.95) Table 1: Parsing accuracy of the undirected planar parser with naive (UPlanarN) and label-based (UPlanarL) postprocessing in comparison to the directed planar (Planar) and the MaltParser arc-eager projective (MaltP) algorithms, on eight datasets from the CoNLL-X shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al., 2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). We show labelled (LAS) and unlabelled (UAS) attachment score excluding and including punctuation tokens in the scoring (the latter in brackets). Best results for each language are shown in boldface, and results where the undirected parser outperforms the directed version are marked with an asterisk. 2Planar U2PlanarN U2PlanarL MaltPP Lang. LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UA</context>
</contexts>
<marker>Chen, Luo, Chang, Chen, Chen, Huang, Gao, 2003</marker>
<rawString>K. Chen, C. Luo, M. Chang, F. Chen, C. Chen, C. Huang, and Z. Gao. 2003. Sinica treebank: Design criteria, representational issues and implementation. In Anne Abeill´e, editor, Treebanks: Building and Using Parsed Corpora, chapter 13, pages 231– 248. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y J Chu</author>
<author>T H Liu</author>
</authors>
<title>On the shortest arborescence of a directed graph.</title>
<date>1965</date>
<journal>Science Sinica,</journal>
<volume>14</volume>
<pages>1400</pages>
<contexts>
<context position="20777" citStr="Chu and Liu, 1965" startWordPosition="3647" endWordPosition="3650">rlying undirected edges are in U or not; this is so that reconstructions are allowed to link unattached tokens to the dummy root. The reconstruction process consists of finding a minimum branching (i.e. a directed minimum spanning tree) for a weighted directed graph obtained from assigning a cost c(i, j) to each arc (i, j) of the following directed graph: D(U) = {Vw, A(U) = A1(U) U A2(U)}. That is, we will find a dependency tree T = (Vw, AT C A(U)) such that the sum of costs of the arcs in AT is minimal. In general, such a minimum branching can be calculated with the ChuLiu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967). Since the graph D(U) has O(n) nodes and O(n) arcs for a string of length n, this can be done in O(n log n) if implemented as described by Tarjan (1977). However, applying these generic techniques is not necessary in this case: since our graph U is acyclic, the problem of reconstructing the forest can be reduced to choosing a root word for each connected component in the graph, linking it as a dependent of the dummy root and directing the other arcs in the component in the (unique) way that makes them point away from the root. It remains to see how to assign the costs c(i, j) </context>
</contexts>
<marker>Chu, Liu, 1965</marker>
<rawString>Y. J. Chu and T. H. Liu. 1965. On the shortest arborescence of a directed graph. Science Sinica, 14:1396– 1400.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A Covington</author>
</authors>
<title>A fundamental algorithm for dependency parsing.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual ACM Southeast Conference,</booktitle>
<pages>95--102</pages>
<contexts>
<context position="3336" citStr="Covington, 2001" startWordPosition="520" endWordPosition="521">tion that leads it to build a dependency link from 1 to 2 instead of the correct link from 2 to 1, this will lead it to a state where the single-head constraint makes it illegal to create the link from 3 to 2. Therefore, a single erroneous choice will cause two attachment errors in the output tree. With the goal of minimizing these sources of errors, we obtain novel undirected variants of several parsers; namely, of the planar and 2- planar parsers by G´omez-Rodr´ıguez and Nivre (2010) and the non-projective list-based parser described by Nivre (2008), which is based on Covington’s algorithm (Covington, 2001). These variants work by collapsing the LEFT-ARC and 0 1 2 3 66 Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 66–76, Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics RIGHT-ARC transitions in the original parsers, which create right-to-left and left-to-right dependency links, into a single ARC transition creating an undirected link. This has the advantage that the single-head constraint need not be observed during the parsing process, since the directed notions of head and dependent are los</context>
<context position="8392" citStr="Covington (2001)" startWordPosition="1411" endWordPosition="1412">s a set of terminal configurations. To obtain a deterministic parser from a nondeterministic transition system, an oracle is used to deterministically select a single transition at 67 each configuration. An oracle for a transition system 5 = (C, T, cs, Ct) is a function o : C —* T. Suitable oracles can be obtained in practice by training classifiers on treebank data (Nivre et al., 2004). 2.3 The Planar, 2-Planar and Covington Transition Systems Our undirected dependency parsers are based on the planar and 2-planar transition systems by G´omez-Rodr´ıguez and Nivre (2010) and the version of the Covington (2001) non-projective parser defined by Nivre (2008). We now outline these directed parsers briefly, a more detailed description can be found in the above references. 2.3.1 Planar The planar transition system by G´omezRodr´ıguez and Nivre (2010) is a linear-time transition-based parser for planar dependency forests, i.e., forests whose dependency arcs do not cross when drawn above the words. The set of planar dependency structures is a very mild extension of that of projective structures (Kuhlmann and Nivre, 2006). Configurations in this system are of the form c = (E, B, A) where E and B are disjoin</context>
<context position="10953" citStr="Covington (2001)" startWordPosition="1865" endWordPosition="1866">umber of treebanks (G´omez-Rodriguez and Nivre, 2010). This transition system, shown in Figure 2, has configurations of the form c = (E0, E1, B, A) , where we call E0 the active stack and E1 the inactive stack. Its SHIFT, LEFT-ARC, RIGHT-ARC and REDUCE transitions work similarly to those in the planar parser, but while SHIFT pushes the first word in the buffer to both stacks; the other three transitions only work with the top of the active stack, ignoring the inactive one. Finally, a SWITCH transition is added that makes the active stack inactive and vice versa. 2.3.3 Covington Non-Projective Covington (2001) proposes several incremental parsing strategies for dependency representations and one of them can recover non-projective dependency graphs. Nivre (2008) implements a variant of this strategy as a transition system with configurations of the form c = (A1, A2, B, A), where A1 and A2 are lists containing partially processed words and B is the buffer list of unprocessed words. The Covington non-projective transition system is shown at the bottom in Figure 2. At each configuration c = (A1, A2, B, A), the parser has to consider whether any dependency arc should be created involving the top of the </context>
<context position="29490" citStr="Covington, 2001" startWordPosition="5177" endWordPosition="5178">guese in the case of the planar parser; and Czech, Danish and Turkish for Covington’s parser. No statistically significant decrease in accuracy was detected in any of the algorithm/dataset combinations. As expected, the good results obtained by the undirected parsers with label-based reconstruction contrast with those obtained by the variants with root-based reconstruction, which performed worse in all the experiments. 6 Discussion We have presented novel variants of the planar and 2-planar transition-based parsers by G´omezRodr´ıguez and Nivre (2010) and of Covington’s non-projective parser (Covington, 2001; Nivre, 2008) which ignore the direction of dependency links, and reconstruction techniques that can be used to recover the direction of the arcs thus produced. The results obtained show that this idea of undirected parsing, together with the label4All the experimental settings and feature models used are included in the supplementary material and also available athttp://www.grupolys.org/-cgomezr/exp/. 5Statistical significance was assessed using Dan Bikel’s randomized comparator: http://www.cis.upenn. edu/-dbikel/software.html based reconstruction technique of Section 4.2, improves parsing a</context>
</contexts>
<marker>Covington, 2001</marker>
<rawString>Michael A. Covington. 2001. A fundamental algorithm for dependency parsing. In Proceedings of the 39th Annual ACM Southeast Conference, pages 95–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jack Edmonds</author>
</authors>
<title>Optimum branchings.</title>
<date>1967</date>
<journal>Journal of Research of the National Bureau of Standards,</journal>
<pages>71--233</pages>
<contexts>
<context position="20793" citStr="Edmonds, 1967" startWordPosition="3651" endWordPosition="3653">dges are in U or not; this is so that reconstructions are allowed to link unattached tokens to the dummy root. The reconstruction process consists of finding a minimum branching (i.e. a directed minimum spanning tree) for a weighted directed graph obtained from assigning a cost c(i, j) to each arc (i, j) of the following directed graph: D(U) = {Vw, A(U) = A1(U) U A2(U)}. That is, we will find a dependency tree T = (Vw, AT C A(U)) such that the sum of costs of the arcs in AT is minimal. In general, such a minimum branching can be calculated with the ChuLiu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967). Since the graph D(U) has O(n) nodes and O(n) arcs for a string of length n, this can be done in O(n log n) if implemented as described by Tarjan (1977). However, applying these generic techniques is not necessary in this case: since our graph U is acyclic, the problem of reconstructing the forest can be reduced to choosing a root word for each connected component in the graph, linking it as a dependent of the dummy root and directing the other arcs in the component in the (unique) way that makes them point away from the root. It remains to see how to assign the costs c(i, j) to the arcs of D</context>
</contexts>
<marker>Edmonds, 1967</marker>
<rawString>Jack Edmonds. 1967. Optimum branchings. Journal of Research of the National Bureau of Standards, 71B:233–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R-E Fan</author>
<author>K-W Chang</author>
<author>C-J Hsieh</author>
<author>X-R Wang</author>
<author>C-J Lin</author>
</authors>
<title>LIBLINEAR: A library for large linear classification.</title>
<date>2008</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>9--1871</pages>
<contexts>
<context position="27332" citStr="Fan et al., 2008" startWordPosition="4825" endWordPosition="4828">arsers, respectively. In addition, we provide a comparison to well-known state-of-the-art projective and nonprojective parsers: the planar parsers are compared to the arc-eager projective parser by Nivre (2003), which is also restricted to planar structures; and the 2-planar parsers are compared with the arc-eager parser with pseudo-projective transformation of Nivre and Nilsson (2005), capable of handling non-planar dependencies. We use SVM classifiers from the LIBSVM package (Chang and Lin, 2001) for all the languages except Chinese, Czech and German. In these, we use the LIBLINEAR package (Fan et al., 2008) for classification, which reduces training time for these larger datasets; and feature models adapted to this system which, in the case of German, result in higher accuracy than published results using LIBSVM. R R L L L { 1 if (i, j) E A1+(U) n (i, j) E� A2(U), 2 if (i, j) E A1−(U) n (i, j) E� A2(U), 2n if (i, j) E A2(U). 72 The LIBSVM feature models for the arc-eager projective and pseudo-projective parsers are the same used by these parsers in the CoNLL-X shared task, where the pseudo-projective version of MaltParser was one of the two top performing systems (Buchholz and Marsi, 2006). For </context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin. 2008. LIBLINEAR: A library for large linear classification. Journal of Machine Learning Research, 9:1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos G´omez-Rodriguez</author>
<author>Joakim Nivre</author>
</authors>
<title>A transition-based parser for 2-planar dependency structures.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>1492--1501</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>G´omez-Rodriguez, Nivre, 2010</marker>
<rawString>Carlos G´omez-Rodriguez and Joakim Nivre. 2010. A transition-based parser for 2-planar dependency structures. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 1492–1501, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Otakar Smrˇz</author>
<author>Petr Zem´anek</author>
<author>Jan ˇSnaidauf</author>
<author>Emanuel Beˇska</author>
</authors>
<title>Prague Arabic Dependency Treebank: Development in data and tools.</title>
<date>2004</date>
<booktitle>In Proceedings of the NEMLAR International Conference on Arabic Language Resources and Tools.</booktitle>
<marker>Hajiˇc, Smrˇz, Zem´anek, ˇSnaidauf, Beˇska, 2004</marker>
<rawString>Jan Hajiˇc, Otakar Smrˇz, Petr Zem´anek, Jan ˇSnaidauf, and Emanuel Beˇska. 2004. Prague Arabic Dependency Treebank: Development in data and tools. In Proceedings of the NEMLAR International Conference on Arabic Language Resources and Tools.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Jarmila Panevov´a</author>
<author>Eva Hajiˇcov´a</author>
<author>Jarmila Panevov´a</author>
<author>Petr Sgall</author>
<author>Petr Pajas</author>
<author>Jan ˇStˇep´anek</author>
<author>JiˇriHavelka</author>
<author>Marie Mikulov´a</author>
</authors>
<date>2006</date>
<booktitle>Prague Dependency Treebank 2.0. CDROM CAT: LDC2006T01, ISBN 1-58563-370-4. Linguistic Data Consortium.</booktitle>
<marker>Hajiˇc, Panevov´a, Hajiˇcov´a, Panevov´a, Sgall, Pajas, ˇStˇep´anek, JiˇriHavelka, Mikulov´a, 2006</marker>
<rawString>Jan Hajiˇc, Jarmila Panevov´a, Eva Hajiˇcov´a, Jarmila Panevov´a, Petr Sgall, Petr Pajas, Jan ˇStˇep´anek, JiˇriHavelka, and Marie Mikulov´a. 2006. Prague Dependency Treebank 2.0. CDROM CAT: LDC2006T01, ISBN 1-58563-370-4. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kenji Sagae</author>
</authors>
<title>Dynamic programming for linear-time incremental parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>1077--1086</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1368" citStr="Huang and Sagae (2010)" startWordPosition="195" endWordPosition="198">transition-based parsers satisfying certain conditions. We apply this approach to obtain undirected variants of the planar and 2-planar parsers and of Covington’s non-projective parser. We perform experiments on several datasets from the CoNLL-X shared task, showing that these variants outperform the original directed algorithms in most of the cases. 1 Introduction Dependency parsing has proven to be very useful for natural language processing tasks. Datadriven dependency parsers such as those by Nivre et al. (2004), McDonald et al. (2005), Titov and Henderson (2007), Martins et al. (2009) or Huang and Sagae (2010) are accurate and efficient, they can be trained from annotated data without the need for a grammar, and they provide a simple representation of syntax that maps to predicateargument structure in a straightforward way. In particular, transition-based dependency parsers (Nivre, 2008) are a type of dependency parsing algorithms which use a model that scores transitions between parser states. Greedy deterministic search can be used to select the transition to be taken at each state, thus achieving linear or quadratic time complexity. Figure 1: An example dependency structure where transition-base</context>
</contexts>
<marker>Huang, Sagae, 2010</marker>
<rawString>Liang Huang and Kenji Sagae. 2010. Dynamic programming for linear-time incremental parsing. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 1077–1086, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias T Kromann</author>
</authors>
<title>The Danish dependency treebank and the underlying linguistic theory.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2nd Workshop on Treebanks and Linguistic Theories (TLT),</booktitle>
<pages>217--220</pages>
<publisher>V¨axj¨o University Press.</publisher>
<location>V¨axj¨o,</location>
<contexts>
<context position="33993" citStr="Kromann, 2003" startWordPosition="5839" endWordPosition="5840">.10) 86.50 (85.86) 82.95 (82.66*) 88.29 (87.45*) 82.89 (82.44) 88.61 (87.55) Turkish 62.70 (71.27) 73.67 (78.57) 59.83 (68.31) 70.15 (75.17) 63.27* (71.63*) 73.93* (78.72*) 62.58 (70.96) 73.09 (77.95) Table 1: Parsing accuracy of the undirected planar parser with naive (UPlanarN) and label-based (UPlanarL) postprocessing in comparison to the directed planar (Planar) and the MaltParser arc-eager projective (MaltP) algorithms, on eight datasets from the CoNLL-X shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al., 2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). We show labelled (LAS) and unlabelled (UAS) attachment score excluding and including punctuation tokens in the scoring (the latter in brackets). Best results for each language are shown in boldface, and results where the undirected parser outperforms the directed version are marked with an asterisk. 2Planar U2PlanarN U2PlanarL MaltPP Lang. LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p) Arabic 66.73 (67.19) 77.33 (77.11) 66.37 (66.93)</context>
</contexts>
<marker>Kromann, 2003</marker>
<rawString>Matthias T. Kromann. 2003. The Danish dependency treebank and the underlying linguistic theory. In Proceedings of the 2nd Workshop on Treebanks and Linguistic Theories (TLT), pages 217–220, V¨axj¨o, Sweden. V¨axj¨o University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
<author>Joakim Nivre</author>
</authors>
<title>Mildly non-projective dependency structures.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions,</booktitle>
<pages>507--514</pages>
<contexts>
<context position="8905" citStr="Kuhlmann and Nivre, 2006" startWordPosition="1489" endWordPosition="1492">ar and 2-planar transition systems by G´omez-Rodr´ıguez and Nivre (2010) and the version of the Covington (2001) non-projective parser defined by Nivre (2008). We now outline these directed parsers briefly, a more detailed description can be found in the above references. 2.3.1 Planar The planar transition system by G´omezRodr´ıguez and Nivre (2010) is a linear-time transition-based parser for planar dependency forests, i.e., forests whose dependency arcs do not cross when drawn above the words. The set of planar dependency structures is a very mild extension of that of projective structures (Kuhlmann and Nivre, 2006). Configurations in this system are of the form c = (E, B, A) where E and B are disjoint lists of nodes from V,,, (for some input w), and A is a set of dependency links over V,,,. The list B, called the buffer, holds the input words that are still to be read. The list E, called the stack, is initially empty and is used to hold words that have dependency links pending to be created. The system is shown at the top in Figure 2, where the notation E |i is used for a stack with top i and tail E, and we invert the notation for the buffer for clarity (i.e., i |B as a buffer with top i and tail B). Th</context>
</contexts>
<marker>Kuhlmann, Nivre, 2006</marker>
<rawString>Marco Kuhlmann and Joakim Nivre. 2006. Mildly non-projective dependency structures. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 507–514.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andre Martins</author>
<author>Noah Smith</author>
<author>Eric Xing</author>
</authors>
<title>Concise integer linear programming formulations for dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACLIJCNLP),</booktitle>
<pages>342--350</pages>
<contexts>
<context position="1342" citStr="Martins et al. (2009)" startWordPosition="190" endWordPosition="193"> by simplifying existing transition-based parsers satisfying certain conditions. We apply this approach to obtain undirected variants of the planar and 2-planar parsers and of Covington’s non-projective parser. We perform experiments on several datasets from the CoNLL-X shared task, showing that these variants outperform the original directed algorithms in most of the cases. 1 Introduction Dependency parsing has proven to be very useful for natural language processing tasks. Datadriven dependency parsers such as those by Nivre et al. (2004), McDonald et al. (2005), Titov and Henderson (2007), Martins et al. (2009) or Huang and Sagae (2010) are accurate and efficient, they can be trained from annotated data without the need for a grammar, and they provide a simple representation of syntax that maps to predicateargument structure in a straightforward way. In particular, transition-based dependency parsers (Nivre, 2008) are a type of dependency parsing algorithms which use a model that scores transitions between parser states. Greedy deterministic search can be used to select the transition to be taken at each state, thus achieving linear or quadratic time complexity. Figure 1: An example dependency struc</context>
</contexts>
<marker>Martins, Smith, Xing, 2009</marker>
<rawString>Andre Martins, Noah Smith, and Eric Xing. 2009. Concise integer linear programming formulations for dependency parsing. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACLIJCNLP), pages 342–350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Characterizing the errors of data-driven dependency parsing models.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>122--131</pages>
<contexts>
<context position="2234" citStr="McDonald and Nivre (2007)" startWordPosition="333" endWordPosition="336">ion-based dependency parsers (Nivre, 2008) are a type of dependency parsing algorithms which use a model that scores transitions between parser states. Greedy deterministic search can be used to select the transition to be taken at each state, thus achieving linear or quadratic time complexity. Figure 1: An example dependency structure where transition-based parsers enforcing the single-head constraint will incur in error propagation if they mistakenly build a dependency link 1 → 2 instead of 2 → 1 (dependency links are represented as arrows going from head to dependent). It has been shown by McDonald and Nivre (2007) that such parsers suffer from error propagation: an early erroneous choice can place the parser in an incorrect state that will in turn lead to more errors. For instance, suppose that a sentence whose correct analysis is the dependency graph in Figure 1 is analyzed by any bottom-up or leftto-right transition-based parser that outputs dependency trees, therefore obeying the single-head constraint (only one incoming arc is allowed per node). If the parser chooses an erroneous transition that leads it to build a dependency link from 1 to 2 instead of the correct link from 2 to 1, this will lead </context>
<context position="25758" citStr="McDonald and Nivre, 2007" startWordPosition="4562" endWordPosition="4565">ust” the links from the dummy root created by the parser, and may choose to change them if it is convenient to get a better agreement with label annotations (see Figure 4 for an example of the difference between both cost assignments). We believe that the better accuracy obtained with this criterion probably stems from the fact that it is biased towards changing links from the root, which tend to be more problematic for transition-based parsers, while respecting the parser output for links located deeper in the dependency structure, for which transition-based parsers tend to be more accurate (McDonald and Nivre, 2007). Note that both variants of label-based reconstruction have the property that, if the undirected parser produces the correct edges and labels for a 0 1 2 3 4 5 0 1 2 3 4 5 0 1 2 3 4 5 Figure 4: a) An undirected graph obtained by the parser with the label-based transformation, b) and c) The dependency graph obtained by each of the variants of the label-based reconstruction (note how the second variant moves an arc from the root). given sentence, then the obtained directed tree is guaranteed to be correct (as it will simply be the tree obtained by decoding the label annotations). 5 Experiments </context>
</contexts>
<marker>McDonald, Nivre, 2007</marker>
<rawString>Ryan McDonald and Joakim Nivre. 2007. Characterizing the errors of data-driven dependency parsing models. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 122–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP),</booktitle>
<pages>523--530</pages>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajiˇc. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP), pages 523–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jens Nilsson</author>
<author>Johan Hall</author>
<author>Joakim Nivre</author>
</authors>
<title>MAMBA meets TIGER: Reconstructing a Swedish treebank from Antiquity.</title>
<date>2005</date>
<booktitle>Proceedings of the NODALIDA Special Session on Treebanks.</booktitle>
<editor>In Peter Juel Henrichsen, editor,</editor>
<contexts>
<context position="34089" citStr="Nilsson et al., 2005" startWordPosition="5852" endWordPosition="5855">0 (71.27) 73.67 (78.57) 59.83 (68.31) 70.15 (75.17) 63.27* (71.63*) 73.93* (78.72*) 62.58 (70.96) 73.09 (77.95) Table 1: Parsing accuracy of the undirected planar parser with naive (UPlanarN) and label-based (UPlanarL) postprocessing in comparison to the directed planar (Planar) and the MaltParser arc-eager projective (MaltP) algorithms, on eight datasets from the CoNLL-X shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al., 2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). We show labelled (LAS) and unlabelled (UAS) attachment score excluding and including punctuation tokens in the scoring (the latter in brackets). Best results for each language are shown in boldface, and results where the undirected parser outperforms the directed version are marked with an asterisk. 2Planar U2PlanarN U2PlanarL MaltPP Lang. LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p) LAS(p) UAS(p) Arabic 66.73 (67.19) 77.33 (77.11) 66.37 (66.93) 77.15 (77.09) 66.13 (66.52) 76.97 (76.70) 65.93 (66.02) 76.79 (76.14) Chinese 84.35 (84.32) 88.</context>
</contexts>
<marker>Nilsson, Hall, Nivre, 2005</marker>
<rawString>Jens Nilsson, Johan Hall, and Joakim Nivre. 2005. MAMBA meets TIGER: Reconstructing a Swedish treebank from Antiquity. In Peter Juel Henrichsen, editor, Proceedings of the NODALIDA Special Session on Treebanks.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Jens Nilsson</author>
</authors>
<title>Pseudoprojective dependency parsing.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>99--106</pages>
<contexts>
<context position="27103" citStr="Nivre and Nilsson (2005)" startWordPosition="4787" endWordPosition="4790">rom the CoNLL-X shared task (Buchholz and Marsi, 2006). Tables 1, 2 and 3 compare the accuracy of the undirected versions with naive and label-based reconstruction to that of the directed versions of the planar, 2-planar and Covington parsers, respectively. In addition, we provide a comparison to well-known state-of-the-art projective and nonprojective parsers: the planar parsers are compared to the arc-eager projective parser by Nivre (2003), which is also restricted to planar structures; and the 2-planar parsers are compared with the arc-eager parser with pseudo-projective transformation of Nivre and Nilsson (2005), capable of handling non-planar dependencies. We use SVM classifiers from the LIBSVM package (Chang and Lin, 2001) for all the languages except Chinese, Czech and German. In these, we use the LIBLINEAR package (Fan et al., 2008) for classification, which reduces training time for these larger datasets; and feature models adapted to this system which, in the case of German, result in higher accuracy than published results using LIBSVM. R R L L L { 1 if (i, j) E A1+(U) n (i, j) E� A2(U), 2 if (i, j) E A1−(U) n (i, j) E� A2(U), 2n if (i, j) E A2(U). 72 The LIBSVM feature models for the arc-eager</context>
</contexts>
<marker>Nivre, Nilsson, 2005</marker>
<rawString>Joakim Nivre and Jens Nilsson. 2005. Pseudoprojective dependency parsing. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 99–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Memory-based dependency parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of the 8th Conference on Computational Natural Language Learning (CoNLL-2004),</booktitle>
<pages>49--56</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1267" citStr="Nivre et al. (2004)" startWordPosition="178" endWordPosition="181">to observe the single-head constraint. Undirected parsers can be obtained by simplifying existing transition-based parsers satisfying certain conditions. We apply this approach to obtain undirected variants of the planar and 2-planar parsers and of Covington’s non-projective parser. We perform experiments on several datasets from the CoNLL-X shared task, showing that these variants outperform the original directed algorithms in most of the cases. 1 Introduction Dependency parsing has proven to be very useful for natural language processing tasks. Datadriven dependency parsers such as those by Nivre et al. (2004), McDonald et al. (2005), Titov and Henderson (2007), Martins et al. (2009) or Huang and Sagae (2010) are accurate and efficient, they can be trained from annotated data without the need for a grammar, and they provide a simple representation of syntax that maps to predicateargument structure in a straightforward way. In particular, transition-based dependency parsers (Nivre, 2008) are a type of dependency parsing algorithms which use a model that scores transitions between parser states. Greedy deterministic search can be used to select the transition to be taken at each state, thus achieving</context>
<context position="8165" citStr="Nivre et al., 2004" startWordPosition="1376" endWordPosition="1379"> ofpossible parser configurations, 2. T is a finite set of transitions, which are partial functions t : C --+ C, 3. cs is a total initialization function mapping each input string to a unique initial configuration, and 4. Ct C C is a set of terminal configurations. To obtain a deterministic parser from a nondeterministic transition system, an oracle is used to deterministically select a single transition at 67 each configuration. An oracle for a transition system 5 = (C, T, cs, Ct) is a function o : C —* T. Suitable oracles can be obtained in practice by training classifiers on treebank data (Nivre et al., 2004). 2.3 The Planar, 2-Planar and Covington Transition Systems Our undirected dependency parsers are based on the planar and 2-planar transition systems by G´omez-Rodr´ıguez and Nivre (2010) and the version of the Covington (2001) non-projective parser defined by Nivre (2008). We now outline these directed parsers briefly, a more detailed description can be found in the above references. 2.3.1 Planar The planar transition system by G´omezRodr´ıguez and Nivre (2010) is a linear-time transition-based parser for planar dependency forests, i.e., forests whose dependency arcs do not cross when drawn a</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2004</marker>
<rawString>Joakim Nivre, Johan Hall, and Jens Nilsson. 2004. Memory-based dependency parsing. In Proceedings of the 8th Conference on Computational Natural Language Learning (CoNLL-2004), pages 49– 56, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>MaltParser: A data-driven parser-generator for dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>2216--2219</pages>
<contexts>
<context position="17034" citStr="Nivre et al., 2006" startWordPosition="2919" endWordPosition="2922">vious section generate undirected graphs. To obtain complete dependency parsers that are able to produce directed dependency forests, we will need a reconstruction step that will assign a direction to the arcs in such a way that the single-head constraint is obeyed. This reconstruction step can be implemented by building a directed graph with weighted arcs corresponding to both possible directions of each undirected edge, and then finding an optimum branching to reduce it to a directed 3These example features are taken from the default model for the planar parser in version 1.5 of MaltParser (Nivre et al., 2006). 69 Planar initial/terminal configurations: cs(w1 ... wn) = h[], [1... n], ∅i, Cf = {hΣ, [], Ai ∈ C} Transitions: SHIFT hΣ, i|B, Ai ⇒ hΣ|i, B, Ai REDUCE hΣ|i, B, Ai ⇒ hΣ, B, Ai LEFT-ARC hΣ|i, j|B, Ai ⇒ hΣ|i, j|B, A ∪ {(j, i)}i only if �k |(k, i) ∈ A (single-head) and i ↔* j ∈6 A (acyclicity). RIGHT-ARC hΣ|i, j|B,Ai ⇒ hΣ|i, j|B,A ∪ {(i, j)}i only if �k |(k, j) ∈ A (single-head) and i ↔* j ∈6 A (acyclicity). 2-Planar initial/terminal configurations: cs(w1 ... wn) = h[], [], [1... n], ∅i, Cf = {hΣ0, Σ1, [], Ai ∈ C} Transitions: SHIFT hΣ0, Σ1, i|B, Ai ⇒ hΣ0|i, Σ1|i, B, Ai REDUCE hΣ0|i, Σ1, B, Ai </context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2006</marker>
<rawString>Joakim Nivre, Johan Hall, and Jens Nilsson. 2006. MaltParser: A data-driven parser-generator for dependency parsing. In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC), pages 2216–2219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>An efficient algorithm for projective dependency parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT),</booktitle>
<pages>149--160</pages>
<contexts>
<context position="14004" citStr="Nivre (2003)" startWordPosition="2402" endWordPosition="2403"> notions of head and dependent are lost in undirected graphs. By performing these transformations and leaving the systems otherwise unchanged, we obtain the undirected variants of the planar, 2-planar and Covington algorithms that are shown in Figure 3. Note that the transformation can be applied to any transition system having LEFT-ARC and RIGHT-ARC transitions that are equal except for the direction of the created link, and thus collapsable into one. The above three transition systems fulfill this property, but not every transition system does. For example, the well-known arceager parser of Nivre (2003) pops a node from the stack when creating left arcs, and pushes a node to the stack when creating right arcs, so the transformation cannot be applied to it.2 2One might think that the arc-eager algorithm could still be transformed by converting each of its arc transitions into an undirected transition, without collapsing them into one. However, this would result into a parser that violates the acyclicity constraint, since the algorithm is designed in such a way that acyclicity is only guaranteed if the single-head constraint is kept. It is easy to see that this problem cannot happen in parsers</context>
<context position="26925" citStr="Nivre (2003)" startWordPosition="4762" endWordPosition="4763">coding the label annotations). 5 Experiments In this section, we evaluate the performance of the undirected planar, 2-planar and Covington parsers on eight datasets from the CoNLL-X shared task (Buchholz and Marsi, 2006). Tables 1, 2 and 3 compare the accuracy of the undirected versions with naive and label-based reconstruction to that of the directed versions of the planar, 2-planar and Covington parsers, respectively. In addition, we provide a comparison to well-known state-of-the-art projective and nonprojective parsers: the planar parsers are compared to the arc-eager projective parser by Nivre (2003), which is also restricted to planar structures; and the 2-planar parsers are compared with the arc-eager parser with pseudo-projective transformation of Nivre and Nilsson (2005), capable of handling non-planar dependencies. We use SVM classifiers from the LIBSVM package (Chang and Lin, 2001) for all the languages except Chinese, Czech and German. In these, we use the LIBLINEAR package (Fan et al., 2008) for classification, which reduces training time for these larger datasets; and feature models adapted to this system which, in the case of German, result in higher accuracy than published resu</context>
</contexts>
<marker>Nivre, 2003</marker>
<rawString>Joakim Nivre. 2003. An efficient algorithm for projective dependency parsing. In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT), pages 149–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Algorithms for Deterministic Incremental Dependency Parsing.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="1651" citStr="Nivre, 2008" startWordPosition="239" endWordPosition="240">form the original directed algorithms in most of the cases. 1 Introduction Dependency parsing has proven to be very useful for natural language processing tasks. Datadriven dependency parsers such as those by Nivre et al. (2004), McDonald et al. (2005), Titov and Henderson (2007), Martins et al. (2009) or Huang and Sagae (2010) are accurate and efficient, they can be trained from annotated data without the need for a grammar, and they provide a simple representation of syntax that maps to predicateargument structure in a straightforward way. In particular, transition-based dependency parsers (Nivre, 2008) are a type of dependency parsing algorithms which use a model that scores transitions between parser states. Greedy deterministic search can be used to select the transition to be taken at each state, thus achieving linear or quadratic time complexity. Figure 1: An example dependency structure where transition-based parsers enforcing the single-head constraint will incur in error propagation if they mistakenly build a dependency link 1 → 2 instead of 2 → 1 (dependency links are represented as arrows going from head to dependent). It has been shown by McDonald and Nivre (2007) that such parser</context>
<context position="3277" citStr="Nivre (2008)" startWordPosition="512" endWordPosition="513">ed per node). If the parser chooses an erroneous transition that leads it to build a dependency link from 1 to 2 instead of the correct link from 2 to 1, this will lead it to a state where the single-head constraint makes it illegal to create the link from 3 to 2. Therefore, a single erroneous choice will cause two attachment errors in the output tree. With the goal of minimizing these sources of errors, we obtain novel undirected variants of several parsers; namely, of the planar and 2- planar parsers by G´omez-Rodr´ıguez and Nivre (2010) and the non-projective list-based parser described by Nivre (2008), which is based on Covington’s algorithm (Covington, 2001). These variants work by collapsing the LEFT-ARC and 0 1 2 3 66 Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 66–76, Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics RIGHT-ARC transitions in the original parsers, which create right-to-left and left-to-right dependency links, into a single ARC transition creating an undirected link. This has the advantage that the single-head constraint need not be observed during the parsing proces</context>
<context position="4938" citStr="Nivre (2008)" startWordPosition="779" endWordPosition="780">ome complexity is moved from the parsing process to this postprocessing step; and each undirected parser will outperform the directed version only if the simplification of the parsing phase is able to avoid more errors than are generated by the post-processing. As will be seen in latter sections, experimental results indicate that this is in fact the case. The rest of this paper is organized as follows: Section 2 introduces some notation and concepts that we will use throughout the paper. In Section 3, we present the undirected versions of the parsers by G´omez-Rodr´ıguez and Nivre (2010) and Nivre (2008), as well as some considerations about the feature models suitable to train them. In Section 4, we discuss post-processing techniques that can be used to recover dependency trees from undirected graphs. Section 5 presents an empirical study of the performance obtained by these parsers, and Section 6 contains a final discussion. 2 Preliminaries 2.1 Dependency Graphs Let w = wi ... wn be an input string. A dependency graph for w is a directed graph G = (Vw, E), where Vw = 10, ... , n} is the set of nodes, and E C Vw x Vw is the set of directed arcs. Each node in Vw encodes the position of a toke</context>
<context position="7327" citStr="Nivre (2008)" startWordPosition="1226" endWordPosition="1227">y constraint: if i --+? j, then not j --+ i. 2. Single-head constraint: if j i, then there is no k =� j such that k --+ i. A node that has no head in a dependency forest is called a root. Some dependency frameworks add the additional constraint that dependency forests have only one root (or, equivalently, that they are connected). Such a forest is called a dependency tree. A dependency tree can be obtained from any dependency forest by linking all of its root nodes as dependents of a dummy root node, conventionally located in position 0 of the input. 2.2 Transition Systems In the framework of Nivre (2008), transitionbased parsers are described by means of a nondeterministic state machine called a transition system. Definition 2 A transition system for dependency parsing is a tuple S = (C, T, cs, Ct), where 1. C is a set ofpossible parser configurations, 2. T is a finite set of transitions, which are partial functions t : C --+ C, 3. cs is a total initialization function mapping each input string to a unique initial configuration, and 4. Ct C C is a set of terminal configurations. To obtain a deterministic parser from a nondeterministic transition system, an oracle is used to deterministically </context>
<context position="11107" citStr="Nivre (2008)" startWordPosition="1886" endWordPosition="1887"> call E0 the active stack and E1 the inactive stack. Its SHIFT, LEFT-ARC, RIGHT-ARC and REDUCE transitions work similarly to those in the planar parser, but while SHIFT pushes the first word in the buffer to both stacks; the other three transitions only work with the top of the active stack, ignoring the inactive one. Finally, a SWITCH transition is added that makes the active stack inactive and vice versa. 2.3.3 Covington Non-Projective Covington (2001) proposes several incremental parsing strategies for dependency representations and one of them can recover non-projective dependency graphs. Nivre (2008) implements a variant of this strategy as a transition system with configurations of the form c = (A1, A2, B, A), where A1 and A2 are lists containing partially processed words and B is the buffer list of unprocessed words. The Covington non-projective transition system is shown at the bottom in Figure 2. At each configuration c = (A1, A2, B, A), the parser has to consider whether any dependency arc should be created involving the top of the buffer and the words in A1. A LEFT-ARC transition adds a link from the first node j in the buffer to the node in the head of the list A1, which is moved t</context>
<context position="29504" citStr="Nivre, 2008" startWordPosition="5179" endWordPosition="5180"> of the planar parser; and Czech, Danish and Turkish for Covington’s parser. No statistically significant decrease in accuracy was detected in any of the algorithm/dataset combinations. As expected, the good results obtained by the undirected parsers with label-based reconstruction contrast with those obtained by the variants with root-based reconstruction, which performed worse in all the experiments. 6 Discussion We have presented novel variants of the planar and 2-planar transition-based parsers by G´omezRodr´ıguez and Nivre (2010) and of Covington’s non-projective parser (Covington, 2001; Nivre, 2008) which ignore the direction of dependency links, and reconstruction techniques that can be used to recover the direction of the arcs thus produced. The results obtained show that this idea of undirected parsing, together with the label4All the experimental settings and feature models used are included in the supplementary material and also available athttp://www.grupolys.org/-cgomezr/exp/. 5Statistical significance was assessed using Dan Bikel’s randomized comparator: http://www.cis.upenn. edu/-dbikel/software.html based reconstruction technique of Section 4.2, improves parsing accuracy on mos</context>
</contexts>
<marker>Nivre, 2008</marker>
<rawString>Joakim Nivre. 2008. Algorithms for Deterministic Incremental Dependency Parsing. Computational Linguistics, 34(4):513–553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
</authors>
<title>Bilge Say, Dilek Zeynep Hakkani-T¨ur, and G¨okhan T¨ur.</title>
<date>2003</date>
<booktitle>Treebanks: Building and Using Parsed Corpora,</booktitle>
<pages>261--277</pages>
<editor>In Anne Abeill´e, editor,</editor>
<publisher>Kluwer.</publisher>
<marker>Oflazer, 2003</marker>
<rawString>Kemal Oflazer, Bilge Say, Dilek Zeynep Hakkani-T¨ur, and G¨okhan T¨ur. 2003. Building a Turkish treebank. In Anne Abeill´e, editor, Treebanks: Building and Using Parsed Corpora, pages 261–277. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Sleator</author>
<author>Davy Temperley</author>
</authors>
<title>Parsing English with a link grammar.</title>
<date>1991</date>
<tech>Technical Report CMU-CS-91-196,</tech>
<institution>Carnegie Mellon University, Computer Science.</institution>
<contexts>
<context position="31729" citStr="Sleator and Temperley, 1991" startWordPosition="5508" endWordPosition="5511">parsers that we have used in this paper is that their LEFT-ARC and RIGHT-ARC transitions have the same effect except for the direction of the links they create. The same transformation and reconstruction techniques could be applied to any other transitionbased dependency parsers sharing this property. The reconstruction techniques alone could potentially be applied to any dependency parser (transition-based or not) as long as it can be somehow converted to output undirected graphs. The idea of parsing with undirected relations between words has been applied before in the work on Link Grammar (Sleator and Temperley, 1991), but in that case the formalism itself works with undirected graphs, which are the final output of the parser. To our knowledge, the idea of using an undirected graph as an intermediate step towards obtaining a dependency structure has not been explored before. Acknowledgments This research has been partially funded by the Spanish Ministry of Economy and Competitiveness and FEDER (projects TIN2010-18552-C03-01 and TIN2010-18552- C03-02), Ministry of Education (FPU Grant Program) and Xunta de Galicia (Rede Galega de Recursos Ling¨uisticos para unha Soc. do Co˜nec.). The experiments were conduc</context>
</contexts>
<marker>Sleator, Temperley, 1991</marker>
<rawString>Daniel Sleator and Davy Temperley. 1991. Parsing English with a link grammar. Technical Report CMU-CS-91-196, Carnegie Mellon University, Computer Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Tarjan</author>
</authors>
<title>Finding optimum branchings.</title>
<date>1977</date>
<journal>Networks,</journal>
<pages>7--25</pages>
<contexts>
<context position="20946" citStr="Tarjan (1977)" startWordPosition="3684" endWordPosition="3685">ing a minimum branching (i.e. a directed minimum spanning tree) for a weighted directed graph obtained from assigning a cost c(i, j) to each arc (i, j) of the following directed graph: D(U) = {Vw, A(U) = A1(U) U A2(U)}. That is, we will find a dependency tree T = (Vw, AT C A(U)) such that the sum of costs of the arcs in AT is minimal. In general, such a minimum branching can be calculated with the ChuLiu-Edmonds algorithm (Chu and Liu, 1965; Edmonds, 1967). Since the graph D(U) has O(n) nodes and O(n) arcs for a string of length n, this can be done in O(n log n) if implemented as described by Tarjan (1977). However, applying these generic techniques is not necessary in this case: since our graph U is acyclic, the problem of reconstructing the forest can be reduced to choosing a root word for each connected component in the graph, linking it as a dependent of the dummy root and directing the other arcs in the component in the (unique) way that makes them point away from the root. It remains to see how to assign the costs c(i, j) to the arcs of D(U): different criteria for assigning scores will lead to different reconstructions. 4.1 Naive reconstruction A first, very simple reconstruction techniq</context>
</contexts>
<marker>Tarjan, 1977</marker>
<rawString>R. E. Tarjan. 1977. Finding optimum branchings. Networks, 7:25–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>James Henderson</author>
</authors>
<title>A latent variable model for generative dependency parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of the 10th International Conference on Parsing Technologies (IWPT),</booktitle>
<pages>144--155</pages>
<contexts>
<context position="1319" citStr="Titov and Henderson (2007)" startWordPosition="186" endWordPosition="189">cted parsers can be obtained by simplifying existing transition-based parsers satisfying certain conditions. We apply this approach to obtain undirected variants of the planar and 2-planar parsers and of Covington’s non-projective parser. We perform experiments on several datasets from the CoNLL-X shared task, showing that these variants outperform the original directed algorithms in most of the cases. 1 Introduction Dependency parsing has proven to be very useful for natural language processing tasks. Datadriven dependency parsers such as those by Nivre et al. (2004), McDonald et al. (2005), Titov and Henderson (2007), Martins et al. (2009) or Huang and Sagae (2010) are accurate and efficient, they can be trained from annotated data without the need for a grammar, and they provide a simple representation of syntax that maps to predicateargument structure in a straightforward way. In particular, transition-based dependency parsers (Nivre, 2008) are a type of dependency parsing algorithms which use a model that scores transitions between parser states. Greedy deterministic search can be used to select the transition to be taken at each state, thus achieving linear or quadratic time complexity. Figure 1: An e</context>
</contexts>
<marker>Titov, Henderson, 2007</marker>
<rawString>Ivan Titov and James Henderson. 2007. A latent variable model for generative dependency parsing. In Proceedings of the 10th International Conference on Parsing Technologies (IWPT), pages 144–155.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>