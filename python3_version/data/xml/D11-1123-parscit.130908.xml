<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.956651">
Structural Opinion Mining for Graph-based Sentiment Representation
</title>
<author confidence="0.999183">
Yuanbin Wu, Qi Zhang, Xuanjing Huang, Lide Wu
</author>
<affiliation confidence="0.999254">
Fudan University
School of Computer Science
</affiliation>
<email confidence="0.998493">
{ybwu,qz,xjhuang,ldwu}@fudan.edu.cn
</email>
<sectionHeader confidence="0.994779" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998709153846154">
Based on analysis of on-line review corpus
we observe that most sentences have compli-
cated opinion structures and they cannot be
well represented by existing methods, such as
frame-based and feature-based ones. In this
work, we propose a novel graph-based rep-
resentation for sentence level sentiment. An
integer linear programming-based structural
learning method is then introduced to produce
the graph representations of input sentences.
Experimental evaluations on a manually la-
beled Chinese corpus demonstrate the effec-
tiveness of the proposed approach.
</bodyText>
<sectionHeader confidence="0.998782" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.965196170212766">
Sentiment analysis has received much attention in
recent years. A number of automatic methods have
been proposed to identify and extract opinions, emo-
tions, and sentiments from text. Previous researches
on sentiment analysis tackled the problem on vari-
ous levels of granularity including document, sen-
tence, phrase and word (Pang et al., 2002; Riloff et
al., 2003; Dave et al., 2003; Takamura et al., 2005;
Kim and Hovy, 2006; Somasundaran et al., 2008;
Dasgupta and Ng, 2009; Hassan and Radev, 2010).
They mainly focused on two directions: sentiment
classification which detects the overall polarity of a
text; sentiment related information extraction which
tries to answer the questions like “who expresses
what opinion on which target”.
Most of the current studies on the second direc-
tion assume that an opinion can be structured as a
frame which is composed of a fixed number of slots.
Typical slots include opinion holder, opinion expres-
sion, and evaluation target. Under this representa-
tion, they defined the task as a slots filling prob-
lem for each of the opinions. Named entity recog-
nition and relation extraction techniques are usually
applied in this task (Hu and Liu, 2004; Kobayashi
et al., 2007; Wu et al., 2009).
However, through data analysis, we observe that
60.5% of sentences in our corpus do not follow the
assumption used by them. A lot of important infor-
mation about an opinion may be lost using those rep-
resentation methods. Consider the following exam-
ples, which are extracted from real online reviews:
Example 1: The interior is a bit noisy on the free-
way1.
Example 2: Takes good pictures during the day-
time. Very poor picture quality at night2.
Based on the definition of opinion unit proposed
by Hu and Liu (2004), from the first example, the
information we can get is the author’s negative opin-
ion about “interior” using an opinion expression
“noisy”. However, the important restriction “on the
freeway”, which narrows the scope of the opinion,
is ignored. In fact, the tuple (“noisy”,“on the free-
way”) cannot correctly express the original opinion:
it is negative but under certain condition. The sec-
ond example is similar. If the conditions “during the
daytime” and “at night” are dropped, the extracted
elements cannot correctly represent user’s opinions.
</bodyText>
<figureCaption confidence="0.5263345">
Example 3: The camera is actually quite good for
outdoors because of the software.
</figureCaption>
<bodyText confidence="0.872134333333333">
Besides that, an opinion expression may induce
other opinions which are not expressed directly. In
example 3, the opinion expression is “good” whose
</bodyText>
<footnote confidence="0.983275">
1http://reviews.carreview.com/blog/2010-ford-focus-
review-the-compact-car-that-can/
2http://www.dooyoo.co.uk/digital-camera/sony-cyber-shot-
dsc-s500/1151680/
</footnote>
<page confidence="0.864674">
1332
</page>
<note confidence="0.958243">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1332–1341,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.951224574468085">
target is “camera”. But the “software” which trig-
gers the opinion expression “good” is also endowed
with a positive opinion. In practice, this induced
opinion on “software” is actually more informative
than its direct counterpart. Mining those opinions
may help to form a complete sentiment analysis re-
sult.
Example 4: The image quality is in the middle of
its class, but it can still be a reasonable choice for
students.
Furthermore, the relations among individual opin-
ions also provide additional information which is
lost when they are considered separately. Example
4 is such a case that the whole positive comment of
camera is expressed by a transition from a negative
opinion to a positive one.
In order to address those issues, this paper de-
scribes a novel sentiment representation and analysis
method. Our main contributions are as follows:
1. We investigate the use of graphs for repre-
senting sentence level sentiment. The ver-
tices are evaluation target, opinion expression,
modifiers of opinion. The Edges represent
relations among them. The semantic rela-
tions among individual opinions are also in-
cluded. Through the graph, various informa-
tion on opinion expressions which is ignored
by current representation methods can be well
handled. And the proposed representation is
language-independent.
2. We propose a supervised structural learning
method which takes a sentence as input and the
proposed sentiment representation for it as out-
put. The inference algorithm is based on in-
teger linear programming which helps to con-
cisely and uniformly handle various properties
of our sentiment representation. By setting ap-
propriate prior substructure constraints of the
graph, the whole algorithm achieves reasonable
performances.
The remaining part of this paper is organized as
follows: In Section 2 we discuss the proposed rep-
resentation method. Section 3 describes the com-
putational model used to construct it. Experimental
results in test collections and analysis are shown in
Section 4. In Section 5, we present the related work
and Section 6 concludes the paper.
</bodyText>
<sectionHeader confidence="0.908607" genericHeader="method">
2 Graph-based Sentiment Representation
</sectionHeader>
<bodyText confidence="0.999835818181818">
In this work, we propose using directed graph to
represent sentiments. In the graph, vertices are
text spans in the sentences which are opinion ex-
pressions, evaluation targets, conditional clauses etc.
Two types of edges are included in the graph: (1)
relations among opinion expressions and their mod-
ifiers; (2) relations among opinion expressions. The
edges of the first type exist within individual opin-
ions. The second type of the edges captures the re-
lations among individual opinions. The following
sections detail the definition.
</bodyText>
<subsectionHeader confidence="0.893768">
2.1 Individual Opinion Representation
</subsectionHeader>
<bodyText confidence="0.999318571428571">
Let r be an opinion expression in a sentence, the rep-
resentation unit for r is a set of relations {(r, dk)}.
For each relation (r, dk), dk is a modifier which is a
span of text specifying the change of r’s meaning.
The relations between modifier and opinion ex-
pression can be the type of any kind. In this work,
we mainly consider two basic types:
</bodyText>
<listItem confidence="0.9805954">
• opinion restriction. (r, dk) is called an opin-
ion restriction if dk narrows r’s scope, adds a
condition, or places limitations on r’s original
meaning.
• opinion expansion. (r, dk) is an opinion expan-
</listItem>
<bodyText confidence="0.958591375">
sion if r’s scope expands to dk, r induces an-
other opinion on dk, or the opinion on dk is im-
plicitly expressed by r.
Mining the opinion restrictions can help to get ac-
curate meaning of an opinion, and the opinion ex-
pansions are useful to cover more indirect opinions.
As with previous sentiment representations, we ac-
tually consider the third type of modifier which dk is
the evaluation target of r.
Figure 1 shows a concrete example. In this ex-
ample, there are three opinion expressions: “good”,
“sharp”, “slightly soft”. The modifiers of “good”
are “indoors” and “Focus accuracy”, where relation
(“good”,“indoors”) is an opinion restriction because
“indoors” is the condition under which “Focus ac-
curacy” is good. On the other hand, the relation
</bodyText>
<page confidence="0.976537">
1333
</page>
<bodyText confidence="0.999484888888889">
(“sharp”, “little 3x optical zooms”) is an opinion ex-
pansion because the “sharp” opinion on “shot” im-
plies a positive opinion on “little 3x optical zooms”.
It is worth to remark that: 1) a modifier dk can re-
late to more than one opinion expression. For exam-
ple, multiple opinion expressions may share a same
condition; 2) dk itself can employ a set of relations,
although the case appears occasionally. The follow-
ing is an example:
</bodyText>
<figureCaption confidence="0.38351">
Example 5: The camera wisely get rid of many
redundant buttons.
</figureCaption>
<bodyText confidence="0.995599">
In the example, “redundant buttons” is the eval-
uation target of opinion expression “wisely get rid
of”, but itself is a relation between “redundant”
and “buttons”. Such nested semantic structure is
described by a path: “wisely get rid of” target
</bodyText>
<equation confidence="0.913743">
�����
[“redundant” targetnested
“buttons”] target.
</equation>
<subsectionHeader confidence="0.8288075">
2.2 Relations between Individual Opinion
Representation
</subsectionHeader>
<bodyText confidence="0.999939913043478">
Assume (ri) are opinion expressions ordered by
their positions in sentence, and each of them has
been represented by relations {(ri, dik)} individu-
ally (the nested relations for dik have also been de-
termined). Then we define two relations on adja-
cent pair ri, ri+1: coordination when the polarities
of ri and ri+1 are consistent, and transition when
they are opposite. Those relations among ri form a
set B called opinion thread. In Figure 1, the opin-
ion thread is: {(“good”, “sharp”), (“sharp”, “slightly
soft”)}.
The whole sentiment representation for a sentence
can be organized by a direct graph G = (V, E). Ver-
tex set V includes all opinion expressions and mod-
ifiers. Edge set E collects both relations of each
individual opinion and relations in opinion thread.
The edges are labeled with relation types in label set
G={“restriction”, “expansion”, “target”, “coordina-
tion”, “transition”} 3.
Compared with previous works, the advantages of
using G as sentiment representation are: 1) for in-
dividual opinions, the modifiers will collect more
information than using opinion expression alone.
</bodyText>
<footnote confidence="0.8408174">
3We don’t define any “label” on vertices: if two span of text
satisfy a relation in G, they are chosen to be vertices and an
edge with proper label will appear in E. In other words, vertices
are identified by checking whether there exist relations among
them.
</footnote>
<bodyText confidence="0.631767666666667">
Focus accuracy was good indoors, and although the
litle 3x optical zooms produced sharp shots, the
edges were slightly soft on the Canon.
</bodyText>
<equation confidence="0.234754">
d31
</equation>
<figureCaption confidence="0.9902255">
Figure 1: Sentiment representation for an example sen-
tence
</figureCaption>
<bodyText confidence="0.999344">
Thus G is a relatively complete and accurate rep-
resentation; 2) the opinion thread can help to catch
global sentiment information, for example the gen-
eral polarity of a sentence, which is dropped when
the opinions are separately represented.
</bodyText>
<sectionHeader confidence="0.983948" genericHeader="method">
3 System Description
</sectionHeader>
<bodyText confidence="0.9999937">
To produce the representation graph G for a sen-
tence, we need to extract candidate vertices and
build the relations among them to get a graph struc-
ture. For the first task, the experimental results in
Section 4 demonstrate that the standard sequential
labeling method with simple features can achieve
reasonable performance. In this section, we focus
on the second task, and assume the vertices in the
graph have already been correctly collected in the
following formulation of algorithm.
</bodyText>
<subsectionHeader confidence="0.996322">
3.1 Preliminaries
</subsectionHeader>
<bodyText confidence="0.998266888888889">
In order to construct graph G, we use a structural
learning method. The framework is from the first or-
der discriminative dependency parsing model (Mc-
donald and Pereira, 2005). A sentence is denoted by
s; x are text spans which will be vertices of graph;
xi is the ith vertex in x ordered by their positions in
s. For a set of vertices x, y is the graph of its sen-
timent representation, and e = (xi, xj) E y is the
direct edge from xi to xj in y. In addition, x0 is a
</bodyText>
<figure confidence="0.99731115">
r2
sharp
good
r1
Target Restriction
Coordinate
Focus
accuracy
indoors
d11 d12
r3
shots
slightly soft
litle 3x optical
zooms
Expansion Target
Transition
d21 d22
Target
edges
</figure>
<page confidence="0.986975">
1334
</page>
<bodyText confidence="0.99763">
virtual root node without inedge. G = {(xn, yn)}n
is training set.
Following the edge based factorization, the score
of a graph is the sum of its edges’ scores,
</bodyText>
<equation confidence="0.9991475">
∑score(x,y) = score(xi, xj)
(xi,xj)EY
∑= αT f(xi, xj), (1)
(xi,xj)EY
</equation>
<bodyText confidence="0.892035">
f(xi, xj) is a high dimensional feature vector of the
edge (xi, xj). The components of f are either 0 or 1.
For example the k-th component could be
</bodyText>
<equation confidence="0.9921805">
fk(xi,xj) = { 1 if xi.POS = JJ and xj.POS = NN
0 otherwise
</equation>
<bodyText confidence="0.994323625">
and label of (xi, xj)is restriction
Then the score of an edge is the linear combination
of f’s components, and the coefficients are in vector
α.
Algorithm 1 shows the parameter learning pro-
cess. It aims to get parameter α which will assign
the correct graph y with the highest score among all
possible graphs of x (denoted by Y).
</bodyText>
<construct confidence="0.389051">
Algorithm 1 Online structural learning
Training Set:G = {(xn,yn)}n
</construct>
<listItem confidence="0.988950909090909">
1: α0 = 0, r = 0, T =maximum iteration
2: fort = 0 to T do
3: for n = 0 to N do
4: y� = arg maxyEY score(xn, y) D Inference
5: if y� =6 yn then
6: update αt to αt+1 D PA
7: r = r + αt+1
8: end if
9: end for
10: end for
11: return α = r/(N ∗ T)
</listItem>
<subsectionHeader confidence="0.965634">
3.2 Inference
</subsectionHeader>
<bodyText confidence="0.9997475">
Like other structural learning tasks, the “arg max”
operation in the algorithm (also called inference)
</bodyText>
<equation confidence="0.998620333333333">
y� = arg max score(x, y)
YEY
αT f(xi, xj) (2)
</equation>
<bodyText confidence="0.999955888888889">
is hard because all possible values of y form a huge
search space. In our case, Y is all possible directed
acyclic graphs of the given vertex set, which num-
ber is exponential. Directly solving the problem of
finding maximum weighted acyclic graph is equiva-
lent to finding maximum feedback arc set, which is a
NP-hard problem (Karp, 1972). We will use integer
linear programming (ILP) as the framework for this
inference problem.
</bodyText>
<subsectionHeader confidence="0.571804">
3.2.1 Graph Properties
</subsectionHeader>
<bodyText confidence="0.955772608695652">
We first show some properties of graph G either
from the definition of relations or corpus statistics.
Property 1. The graph is connected and without
directed cycle. From individual opinion represen-
tation, each subgraph of G which takes an opinion
expression as root is connected and acyclic. Thus
the connectedness is guaranteed for opinion expres-
sions are connected in opinion thread; the acyclic is
guaranteed by the fact that if a modifier is shared by
different opinion expressions, the inedges from them
always keep (directed) acyclic.
Property 2. Each vertex can have one outedge
labeled with coordination or transition at most. The
opinion thread B is a directed path in graph.
Property 3. The graph is sparse. The average
in-degree of a vertex is 1.03 in our corpus, thus the
graph is almost a rooted tree. In other words, the
cases that a modifier connects to more than one opin-
ion expression rarely occur comparing with those
vertices which have a single parent. An explaination
for this sparseness is that opinions in online reviews
always concentrate in local context and have local
semantic connections.
</bodyText>
<subsubsectionHeader confidence="0.475957">
3.2.2 ILP Formulation
</subsubsectionHeader>
<bodyText confidence="0.983726083333333">
Based on the property 3, we divide the inference
algorithm into two steps: i) constructing G’s span-
ning tree (arborescence) with property 1 and 2; ii)
finding additional non-tree edges as a post process-
ing task. The first step is close to the works on ILP
formulations of dependency parsing (Riedel and
Clarke, 2006; Martins et al., 2009). In the second
step, we use a heuristic method which greedily adds
non-tree edges. A similar approximation method
is also used in (Mcdonald and Pereira, 2006) for
acyclic dependency graphs.
Step 1. Find MST. Following the multicommodity
</bodyText>
<equation confidence="0.5432405">
�
∑= arg max
YEY
(xi,xj)EY
</equation>
<page confidence="0.897795">
1335
</page>
<bodyText confidence="0.998418">
flow formulation of maximum spanning tree (MST)
problem in (Magnanti and Wolsey, 1994), the ILP
for MST is:
</bodyText>
<equation confidence="0.999517214285714">
∑max. yij · score(xi, xj) (3)
i,j
∑s.t. yij = |V  |− 1 (4)
i,j
∑ − fujk = δu j,1 ≤ u,j ≤ |V  |(5)
i fuij ∑
k
∑ fu0k = 1, 1 ≤ u ≤ |V  |(6)
k
fuij ≤ yij, 1 ≤ u,j ≤ |V |,
0 ≤ i ≤ |V  |(7)
fuij ≥ 0, 1 ≤ u,j ≤ |V |,
0 ≤ i ≤ |V  |(8)
yij ∈ { 0, 1}, 0 ≤ i, j ≤ |V |. (9)
</equation>
<bodyText confidence="0.997900666666667">
In this formulation, yij is an edge indicator vari-
able that (xi, xj) is a spanning tree edge when yij =
1, (xi, xj) is a non-tree edge when yij = 0. Then
output y is represented by the set {yij, 0 ≤ i, j ≤
|V |} 4. Eq(4) ensures that there will be exactly
|V  |− 1 edges are chosen. Thus if the edges cor-
responding to those non zero yij is a connected sub-
graph, y is a well-formed spanning tree. Objective
function just says the optimal solution of yij have
the maximum weight.
The connectedness is guaranteed if for every ver-
tex, there is exactly one path from root to it. It is for-
mulated by using |V  |− 1 flows {fu,1 ≤ u ≤ |V |}.
fu starts from virtual root x0 towards vertex xu.
Each flow fu = {fuij, 0 ≤ i, j ≤ |V |}. fuij indi-
cates whether flow fu is through edge (xi, xj). so
it should be 0 if edge (xi, xj) does not exist (by
(7)). The Kronecker’s delta δu j in (5) guarantees fu
is only assumed by vertex xu, so fu is a well-formed
path from root to xu. (6) ensures there is only one
flow (path) from root to xu. Thus the subgraph is
connected. The following are our constraints:
c1: Constraint on edges in opinion thread (10)-
(11).
From the definition of opinion thread, we impose
a constraint on every vertex’s outedges in opinion
thread, which are labeled with “coordination” or
</bodyText>
<footnote confidence="0.78989">
4For simplicity, we overload symbol y from the graph of the
sentiment represetation to the MST of it.
</footnote>
<bodyText confidence="0.99956375">
“transition”. Let ffob be a characteristic function on
edges: ffob((j, k)) = 1 when edge (xj, xk) is labeled
with “coordination” or “transition”, otherwise 0. We
denote q variables for vertices:
</bodyText>
<equation confidence="0.9944935">
qj = ∑ yjk · ffob((j, k)), 0 ≤ j ≤ |V |. (10)
k
</equation>
<bodyText confidence="0.911459">
Then following linear inequalities bound the number
of outedges in opinion thread (≤ 1) on each vertex:
</bodyText>
<equation confidence="0.76635">
qj ≤ 1, 0 ≤ j ≤ |V |. (11)
c2: Constraint on target edge (12).
</equation>
<bodyText confidence="0.998763">
We also bound the number of evaluation targets
for a vertex in a similar way. Let fft be characteris-
tic function on edges identifing whether it is labeled
with “target”,
</bodyText>
<equation confidence="0.96182">
∑ yjk · fft((j, k)) ≤ Ct, 0 ≤ j ≤ |V |. (12)
k
</equation>
<bodyText confidence="0.9320961">
The parameter Ct can be adjusted according to the
style of document. In online reviews, authors tend
to use simple and short comments on individual tar-
gets, so Ct could be set small.
c3: Constraint on opinion thread (13)-(18).
From graph property 2, the opinion thread should
be a directed path. It implies the number of con-
nected components whose edges are “coordination”
or “transition” should be less than 1. Two set of ad-
ditional variables are needed: {cj, 0 ≤ j ≤ |V |} and
</bodyText>
<equation confidence="0.930554">
{hj,0 ≤ j ≤ |V |}, where
and
hj = ∑ yij · ffob((i,j)). (13)
i
Then cj = ¬hj ∧ qj, which can be linearized by
cj≥ qj − hj, (14)
cj≤ 1 − hj, (15)
cj≤ qj, (16)
cj≥ 0. (17)
</equation>
<bodyText confidence="0.9614155">
If the sum of cj is no more than 1, the opinion thread
of graph is a directed path.
</bodyText>
<equation confidence="0.828019">
∑ cj ≤ 1. (18)
j
{
cj = ,
1 if an opinion thread starts at xj
0 otherwise
</equation>
<page confidence="0.762176">
1336
</page>
<figure confidence="0.9998870625">
(a) (b)
(c)
1
1
2 3
4
2 3
4 5
5
6 7
6 7
1
2 3
4
5
6 7
</figure>
<figureCaption confidence="0.9936635">
Figure 2: The effects of c1 and c3. Assume solid lines
are edges labeled with “coordination” and “transition”,
dot lines are edges labeled with other types. (a) is an
arbitrary tree. (b) is a tree with c1 constraints. (c) is a
tree with c1 and c3. It shows c1 are not sufficient for
graph property 2: the edges in opinion thread may not be
connected.
Figure 2 illustrates the effects of c1 and c3.
</figureCaption>
<bodyText confidence="0.99860495">
Equations (10)-(18), together with basic multi-
commodity flow model build up the inference algo-
rithm. The entire ILP formulation involves O(|V |3)
variables and O(|V |2) constraints. Generally, ILP
falls into NPC, but as an important result, in the mul-
ticommodity flow formulation of maximum span-
ning tree problem, the integer constraints (9) on yij
can be dropped. So the problem reduces to a linear
programming which is polynomial solvable (Mag-
nanti and Wolsey, 1994). Unfortunately, with our
additional constraints the LP relaxation is not valid.
Step 2. Adding non-tree edges. We examine the
case that a modifier attaches to different opinion ex-
pressions. That often occurs as the result of the
sharing of modifiers among adjacent opinion expres-
sions. We add those edges in the following heuristic
way: If a vertex ri in opinion thread does not have
any modifier, we search the modifiers of its adjacent
vertices ri+1, ri−1 in the opinion thread, and add
edge (ri, d*) where
</bodyText>
<equation confidence="0.9733665">
d* = arg max
dES
</equation>
<bodyText confidence="0.918068">
and S are the modifiers of ri−1 and ri+1.
</bodyText>
<subsectionHeader confidence="0.983716">
3.3 Training
</subsectionHeader>
<bodyText confidence="0.995643333333333">
We use online passive aggressive algorithm (PA)
with Hamming cost of two graphs in training (Cram-
mer et al., 2006).
</bodyText>
<table confidence="0.99898575">
Unigram Feature Template
Inside xi.text w0.text w1.text
Features w0.POS w1.POS
wk−1.text wk.text
wk−1.POS wk.POS
xi.hasDigital
xi.isSingleWord
xi.hasSentimentWord
xi.hasParallelPhrase
Outside w−1.text w−2.text
Features w−1.POS w−2.POS
wk+1.text wk+2.text
wk+1.POS wk+2.POS
c−1.text c−2.text
c−1.POS c−2.POS
cl+1.text cl+2.text
cl+1.POS cl+2.POS
Other Features
distance between parent and child
dependency parsing relations
</table>
<tableCaption confidence="0.999375">
Table 1: Feature set
</tableCaption>
<subsectionHeader confidence="0.942928">
3.4 Feature Construction
</subsectionHeader>
<bodyText confidence="0.995981">
For each vertex xi in graph, we use 2 sets of fea-
tures: inside features which are extracted inside the
text span of xi; outside features which are outside
the text span of xi. A vertex xi is described both in
word sequence (w0, w1, · · · , wk) and character se-
quence (c0, c1, · · · , cl), for the sentences are in Chi-
nese.
</bodyText>
<listItem confidence="0.7042666">
· · · ,w−1, w0, w1, w2, ··· , wk−1, wk
• v •
2z
· · · ,c−1, c0, c1, c2, ··· , cl−1, cl
• v �
</listItem>
<subsectionHeader confidence="0.248741">
2z
</subsectionHeader>
<bodyText confidence="0.99984475">
For an edge (xi, xj), the high dimensional feature
vector f(xi, xj) is generated by using unigram fea-
tures in Table 1 on xi and xj respectively. The dis-
tance between parent and child in sentence is also
attached in features. In order to involve syntactic
information, whether there is certain type of depen-
dency relation between xi and xj is also used as a
feature.
</bodyText>
<equation confidence="0.967392666666667">
score(ri, d),
, wk+1 ···
, cl+1 ···
</equation>
<page confidence="0.990225">
1337
</page>
<sectionHeader confidence="0.998258" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.974542">
4.1 Corpus
</subsectionHeader>
<bodyText confidence="0.999623666666667">
We constructed a Chinese online review corpus from
Pcpop.com, Zol.com.cn, and It168.com, which have
a large number of reviews about digital camera. The
corpus contains 138 documents and 1735 sentences.
Since some sentences do not contain any opinion,
1390 subjective sentences were finally chosen and
manually labeled.
Two annotators labeled the corpus independently.
The annotators started from locating opinion expres-
sions, and for each of them, they annotated other
modifiers related to it. In order to keep the relia-
bility of annotations, another annotator was asked
to check the corpus and determine the conflicts. Fi-
nally, we extracted 6103 elements, which are con-
nected by 6284 relations.
</bodyText>
<table confidence="0.998965333333333">
Relation Number
Target 2479
Coordinate 1173
Transition 154
Restriction 693
Expansion 386
</table>
<tableCaption confidence="0.999421">
Table 2: Statistics of relation types
</tableCaption>
<bodyText confidence="0.998109">
Table 2 shows the number of various relation
types appearing in the labeled corpus. We observe
60.5% of sentences and 32.1% of opinion expres-
sions contain other modifiers besides “target”. Thus
only mining the relations between opinion expres-
sions and evaluation target is actually at risk of inac-
curate and incomplete results.
</bodyText>
<subsectionHeader confidence="0.975441">
4.2 Experiments Configurations
</subsectionHeader>
<bodyText confidence="0.999890444444444">
In all the experiments below, we take 90% of the cor-
pus as training set, 10% as test set and run 10 folder
cross validation. In feature construction, we use
an external Chinese sentiment lexicon which con-
tains 4566 positive opinion words and 4370 nega-
tive opinion words. For Chinese word segment, we
use ctbparser 5. Stanford parser (Klein and Man-
ning, 2003) is used for dependency parsing. In the
settings of PA, the maximum iteration number is
</bodyText>
<footnote confidence="0.879426">
5http://code.google.com/p/ctbparser/
</footnote>
<bodyText confidence="0.999559">
set to 2, which is chosen by maximizing the test-
ing performances, aggressiveness parameter C is set
to 0.00001. For parameters in inference algorithm,
Ct = 2, the solver of ILP is lpsolve6.
We evaluate the system from the following as-
pects: 1) whether the structural information helps
to mining opinion relations. 2) How the proposed
inference algorithm performs with different con-
straints. 3) How the various features affect the sys-
tem. Except for the last one, the feature set used for
different experiments are the same (“In+Out+Dep”
in Table 5). The criteria for evaluation are simi-
lar to the unlabeled attachment score in parser eval-
uations, but due to the equation |E |= |V  |− 1
is not valid if G is not a tree, we evaluate pre-
</bodyText>
<equation confidence="0.984449166666667">
cision#true edges in result graph
P = #edges in result graph ,recall
R = #true edges in result graph and F-score
#edges in true graph ,
_ 2P·R
I — P+R.
</equation>
<subsectionHeader confidence="0.755923">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.999580846153846">
1. The effects of structural information. An alter-
native method to extract relations is directly using
a classifier to judge whether there is a relation be-
tween any two elements. Those kinds of methods
were used in previous opinion mining works (Wu
et al., 2009; Kobayashi et al., 2007). To show the
entire structural information is important for min-
ing relations, we use SVM for binary classification
on candidate pairs. The data point representing a
pair (xi, xj) is the same as the high dimensional fea-
ture vectors f(xi, xj). The setting of our algorithm
“MST+c1+c2+c3” is the basic MST with all the con-
straints. The results are shown in the Table 3.
</bodyText>
<table confidence="0.99952675">
P R F
SVM 64.9 24.0 35.0
MST+c1+c2+c3-m 61.5 74.0 67.2
MST+c1+c2+c3 73.1 71.0 72.1
</table>
<tableCaption confidence="0.999766">
Table 3: Binary classifier and structural learning
</tableCaption>
<bodyText confidence="0.997445">
From the results, the performance of SVM (espe-
cially recall) is relatively poor. A possible reason
is that the huge imbalance of positive and negative
training samples (only O(n) positive pairs among
all n2 pairs). And the absence of global structural
</bodyText>
<footnote confidence="0.982453">
6http://sourceforge.net/projects/lpsolve/
</footnote>
<page confidence="0.994942">
1338
</page>
<bodyText confidence="0.999690833333334">
knowledge makes binary classifier unable to use
the information provided by classification results of
other pairs.
In order to examine whether the complicated sen-
timent representation would disturb the classifier in
finding relations between opinion expressions and
its target, we evaluate the system by discarding the
modifiers of opinion restriction and expansion from
the corpus. The result is shown in the second row of
Table 3. We observe that “MST+c1+c2+c3” is still
better which means at least on overall performance
the additional modifiers do not harm.
</bodyText>
<listItem confidence="0.849468666666667">
2. The effect of constraints on inference algo-
rithm. In the inference algorithm, we utilized the
properties of graph G and adapted the basic multi-
commodity flow ILP to our specific task. To evaluate
how the constraints affect the system, we decompose
the algorithm and combine them in different ways.
</listItem>
<table confidence="0.99982575">
P R F
MST 69.3 67.3 68.3
MST+c1 70.0 68.0 69.0
MST+c2 69.8 67.8 68.8
MST+c1+c2 70.6 68.6 69.6
MST+c1+c3 72.4 70.4 71.4
MST+c1+c2+c3 73.1 71.0 72.1
MST+c1+c2+c3+g 72.5 72.3 72.4
</table>
<tableCaption confidence="0.8817974">
Table 4: Results on inference methods. “MST” is the ba-
sic multicommodity flow formulation of maximum span-
ning tree; c1, c2, c3 are groups of constraint from Section
3.2.2; “g” is our heuristic method for additional non span-
ning tree edges.
</tableCaption>
<bodyText confidence="0.9999">
From Table 4, we observe that with any additional
constraints the inference algorithm outperforms the
basic maximum spanning tree method. It implies al-
though we did not use high order model (e.g. involv-
ing grandparent and sibling features), prior struc-
tural constraints can also help to get a better out-
put graph. By comparing with different constraint
combinations, the constraints on opinion thread (c1,
c3) are more effective than constraints on evaluation
targets (c2). It is because opinion expressions are
more important in the entire sentiment representa-
tion. The main structure of a graph is clear once the
relations between opinion expressions are correctly
determined.
</bodyText>
<sectionHeader confidence="0.581724" genericHeader="method">
3. The effects of various features. We evaluate the
</sectionHeader>
<bodyText confidence="0.999760769230769">
performances of different feature configurations in
Table 5. From the results, the outside feature set is
more effective than inside feature set, even if it does
not use any external resource. A possible reason is
that the content of a vertex can be very complicated
(a vertex even can be a clause), but the features sur-
rounding the vertex are relatively simple and easy
to identify (for example, a single preposition can
identify a complex condition). The dependency fea-
ture has limited effect, due to that lots of online re-
view sentences are ungrammatical and parsing re-
sults are unreliable. And the complexity of vertices
also messes the dependency feature.
</bodyText>
<table confidence="0.999570666666667">
P R F
In-s 66.3 66.3 66.3
In 66.7 66.4 66.6
Out 67.8 67.4 67.6
In+Out 72.0 70.5 71.0
In+Out+Dep 72.5 72.3 72.4
</table>
<tableCaption confidence="0.997824">
Table 5: Results with different features. “In” repre-
</tableCaption>
<bodyText confidence="0.989333333333333">
sents the result of inside feature set; “In-s” is “In” with-
out the external opinion lexicon feature; “Out” uses the
outside feature set; “In+Out” uses both “In” and “Out”,
“In+Out+Dep” adds the dependency feature. The infer-
ence algorithm is “MST+c1+c2+c3+g” in Table 4.
We analyze the errors in test results. A main
source of errors is the confusion of classifier be-
tween “target” relations and “coordination”, “tran-
sition” relations. The reason may be that for a mod-
ification on opinion expression (r, dk), we allow
dk recursively has its own modifiers (Example 5).
Thus an opinion expression can be a modifier which
brings difficulties to classifier.
4. Extraction of vertices. Finally we conduct an
experiment on vertex extraction using standard se-
quential labeling method. The tag set is simply {B,
I, O} which are signs of begin, inside, outside of a
vertex. The underlying model is conditional random
field 7. Feature templates involved are in Table 6.
We only use basic features in the experiment. 10
folder cross validation results are in table 7. We sus-
pect that the performances (especially recall) could
be improved if some external resources(i.e. ontol-
ogy, domain related lexicon, etc.) are involved.
</bodyText>
<footnote confidence="0.974359">
7We use CRF++ toolkit, http://crfpp.sourceforge.net/
</footnote>
<page confidence="0.952952">
1339
</page>
<table confidence="0.994517">
Unigram Template
ci.char character
ci.isDigit digit
ci.isAlpha english letter
ci.isPunc punctuation
ci.inDict in a sentiment word
ci.BWord start of a word
ci.EWord end of a word
</table>
<tableCaption confidence="0.980354">
Table 6: Features for vertex extraction. The sequential
labeling is conducted on character level (ci). The senti-
ment lexicon used in ci.inDict is the same as Table1. We
also use bigram feature templates on ci.char, ci.isAlpha,
ci.inDict with respect to ci_1 and ci+1.
</tableCaption>
<table confidence="0.999943">
P R F
E+Unigram 56.8 45.1 50.3
E+Unigram+Bigram 57.3 47.9 52.1
O+Unigram 71.9 57.2 63.7
O+Unigram+Bigram 72.3 60.2 65.6
</table>
<tableCaption confidence="0.91071325">
Table 7: Results on vertices extraction with 10 folder
cross validation. We use two criterion: 1) the vertex is
correct if it is exactly same as ground truth(“E”), 2) the
vertex is correct if it overlaps with ground truth(“O”).
</tableCaption>
<sectionHeader confidence="0.999867" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.99993517948718">
Opinion mining has recently received considerable
attentions. Large amount of work has been done on
sentimental classification in different levels and sen-
timent related information extraction. Researches on
different types of sentences such as comparative sen-
tences (Jindal and Liu, 2006) and conditional sen-
tences (Narayanan et al., 2009) have also been pro-
posed.
Kobayashi et al. (2007) presented their work on
extracting opinion units including: opinion holder,
subject, aspect and evaluation. They used slots
to represent evaluations, converted the task to two
kinds of relation extraction tasks and proposed a ma-
chine learning-based method which used both con-
textual and statistical clues.
Jindal and Liu (2006) studied the problem of iden-
tifying comparative sentences. They analyzed dif-
ferent types of comparative sentences and proposed
learning approaches to identify them.
Sentiment analysis of conditional sentences were
studied by Narayanan et al. (2009). They aimed
to determine whether opinions expressed on dif-
ferent topics in a conditional sentence are posi-
tive, negative or neutral. They analyzed the con-
ditional sentences in both linguistic and computi-
tional perspectives and used learning method to do
it. They followed the feature-based sentiment anal-
ysis model (Hu and Liu, 2004), which also use flat
frames to represent evaluations.
Integer linear programming was used in many
NLP tasks (Denis and Baldridge, 2007), for its
power in both expressing and approximating various
inference problems, especially in parsing (Riedel
and Clarke, 2006; Martins et al., 2009). Martins
etc. (2009) also applied ILP with flow formulation
for maximum spanning tree, besides, they also han-
dled dependency parse trees involving high order
features(sibling, grandparent), and with projective
constraint.
</bodyText>
<sectionHeader confidence="0.999796" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999931285714286">
This paper introduces a representation method for
opinions in online reviews. Inspections on corpus
show that the information ignored in previous sen-
timent representation can cause incorrect or incom-
plete mining results. We consider opinion restric-
tion, opinion expansions, relations between opin-
ion expressions, and represent them with a directed
graph. Structural learning method is used to produce
the graph for a sentence. An inference algorithm is
proposed based on the properties of the graph. Ex-
perimental evaluations with a manually labeled cor-
pus are given to show the importance of structural
information and effectiveness of proposed inference
algorithm.
</bodyText>
<sectionHeader confidence="0.997667" genericHeader="acknowledgments">
7 Acknowledgement
</sectionHeader>
<bodyText confidence="0.844361909090909">
The author wishes to thank the anonymous review-
ers for their helpful comments. This work was
partially funded by 973 Program (2010CB327906),
National Natural Science Foundation of China
(61003092, 61073069),863 Program of China
(2009AA01A346), Shanghai Science and Tech-
nology Development Funds(10dz1500104), Doc-
toral Fund of Ministry of Education of China
(200802460066), Shanghai Leading Academic Dis-
cipline Project (B114), and Key Projects in
the National Science &amp; Technology Pillar Pro-
</bodyText>
<page confidence="0.965403">
1340
</page>
<bodyText confidence="0.860997">
gram(2009BAH40B04).
</bodyText>
<sectionHeader confidence="0.960151" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999938083333334">
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-
Shwartz, and Yoram Singer. 2006. Online passive-
aggressive algorithms. Journal of Machine Learning
Research, 7:551–585.
Sajib Dasgupta and Vincent Ng. 2009. Mine the easy,
classify the hard: A semi-supervised approach to auto-
matic sentiment classification. In Proceedings ofACL-
IJCNLP.
Kushal Dave, Steve Lawrence, and David M. Pennock.
2003. Mining the peanut gallery: opinion extraction
and semantic classification of product reviews. In Pro-
ceedings of WWW.
Pascal Denis and Jason Baldridge. 2007. Joint determi-
nation of anaphoricity and coreference resolution us-
ing integer programming. In Proceedings of NAACL-
HLT.
Ahmed Hassan and Dragomir R. Radev. 2010. Identify-
ing text polarity using random walks. In Proceedings
of ACL, pages 395–403, Uppsala, Sweden, July. Asso-
ciation for Computational Linguistics.
Minqing Hu and Bing Liu. 2004. Mining and summariz-
ing customer reviews. In Proceedings of SIGKDD.
Nitin Jindal and Bing Liu. 2006. Identifying comparative
sentences in text documents. In Proceedings of SIGIR.
R. Karp. 1972. Reducibility among combinatorial prob-
lems. In R. Miller and J. Thatcher, editors, Complex-
ity of Computer Computations, pages 85–103. Plenum
Press.
Soo-Min Kim and Eduard Hovy. 2006. Automatic iden-
tification of pro and con reasons in online reviews. In
Proceedings of the COLING-ACL.
Dan Klein and Christopher D. Manning. 2003. Fast exact
inference with a factored model for natural language
parsing. In In Advances in Neural Information Pro-
cessing Systems 15 (NIPS, pages 3–10. MIT Press.
Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto.
2007. Extracting aspect-evaluation and aspect-of rela-
tions in opinion mining. In Proceedings of EMNLP-
CoNLL.
Thomas L. Magnanti and Laurence A. Wolsey. 1994.
Optimal trees.
Andre Martins, Noah Smith, and Eric Xing. 2009. Con-
cise integer linear programming formulations for de-
pendency parsing. In Proceedings of ACL-IJCNLP.
R. Mcdonald and F. Pereira. 2005. Identifying gene
and protein mentions in text using conditional random
fields. BMC Bioinformatics.
Ryan Mcdonald and Fernando Pereira. 2006. On-
line learning of approximate dependency parsing al-
gorithms. In Proc. of EACL, pages 81–88.
Ramanathan Narayanan, Bing Liu, and Alok Choudhary.
2009. Sentiment analysis of conditional sentences. In
Proceedings of EMNLP.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment classification using ma-
chine learning techniques. In Proc. of EMNLP 2002.
Sebastian Riedel and James Clarke. 2006. Incremental
integer linear programming for non-projective depen-
dency parsing. In Proceedings of EMNLP.
Ellen Riloff, Janyce Wiebe, and Theresa Wilson. 2003.
Learning subjective nouns using extraction pattern
bootstrapping. In Proceedings of the seventh confer-
ence on Natural language learning at HLT-NAACL.
Swapna Somasundaran, Janyce Wiebe, and Josef Rup-
penhofer. 2008. Discourse level opinion interpreta-
tion. In Proceedings of COLING.
Hiroya Takamura, Takashi Inui, and Manabu Okumura.
2005. Extracting semantic orientations of words using
spin model. In Proceedings of ACL.
Yuanbin Wu, Qi Zhang, Xuangjing Huang, and Lide Wu.
2009. Phrase dependency parsing for opinion mining.
In Proceedings of EMNLP.
</reference>
<page confidence="0.992911">
1341
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.466979">
<title confidence="0.999839">Structural Opinion Mining for Graph-based Sentiment Representation</title>
<author confidence="0.73694">Yuanbin Wu</author>
<author confidence="0.73694">Qi Zhang</author>
<author confidence="0.73694">Xuanjing Huang</author>
<author confidence="0.73694">Lide Fudan</author>
<affiliation confidence="0.961222">School of Computer</affiliation>
<abstract confidence="0.996797071428571">Based on analysis of on-line review corpus we observe that most sentences have complicated opinion structures and they cannot be well represented by existing methods, such as frame-based and feature-based ones. In this work, we propose a novel graph-based representation for sentence level sentiment. An integer linear programming-based structural learning method is then introduced to produce the graph representations of input sentences. Experimental evaluations on a manually labeled Chinese corpus demonstrate the effectiveness of the proposed approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Shai ShalevShwartz</author>
<author>Yoram Singer</author>
</authors>
<title>Online passiveaggressive algorithms.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>7--551</pages>
<contexts>
<context position="19718" citStr="Crammer et al., 2006" startWordPosition="3406" endWordPosition="3410">alid. Step 2. Adding non-tree edges. We examine the case that a modifier attaches to different opinion expressions. That often occurs as the result of the sharing of modifiers among adjacent opinion expressions. We add those edges in the following heuristic way: If a vertex ri in opinion thread does not have any modifier, we search the modifiers of its adjacent vertices ri+1, ri−1 in the opinion thread, and add edge (ri, d*) where d* = arg max dES and S are the modifiers of ri−1 and ri+1. 3.3 Training We use online passive aggressive algorithm (PA) with Hamming cost of two graphs in training (Crammer et al., 2006). Unigram Feature Template Inside xi.text w0.text w1.text Features w0.POS w1.POS wk−1.text wk.text wk−1.POS wk.POS xi.hasDigital xi.isSingleWord xi.hasSentimentWord xi.hasParallelPhrase Outside w−1.text w−2.text Features w−1.POS w−2.POS wk+1.text wk+2.text wk+1.POS wk+2.POS c−1.text c−2.text c−1.POS c−2.POS cl+1.text cl+2.text cl+1.POS cl+2.POS Other Features distance between parent and child dependency parsing relations Table 1: Feature set 3.4 Feature Construction For each vertex xi in graph, we use 2 sets of features: inside features which are extracted inside the text span of xi; outside f</context>
</contexts>
<marker>Crammer, Dekel, Keshet, ShalevShwartz, Singer, 2006</marker>
<rawString>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai ShalevShwartz, and Yoram Singer. 2006. Online passiveaggressive algorithms. Journal of Machine Learning Research, 7:551–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sajib Dasgupta</author>
<author>Vincent Ng</author>
</authors>
<title>Mine the easy, classify the hard: A semi-supervised approach to automatic sentiment classification.</title>
<date>2009</date>
<booktitle>In Proceedings ofACLIJCNLP.</booktitle>
<contexts>
<context position="1250" citStr="Dasgupta and Ng, 2009" startWordPosition="179" endWordPosition="182">t sentences. Experimental evaluations on a manually labeled Chinese corpus demonstrate the effectiveness of the proposed approach. 1 Introduction Sentiment analysis has received much attention in recent years. A number of automatic methods have been proposed to identify and extract opinions, emotions, and sentiments from text. Previous researches on sentiment analysis tackled the problem on various levels of granularity including document, sentence, phrase and word (Pang et al., 2002; Riloff et al., 2003; Dave et al., 2003; Takamura et al., 2005; Kim and Hovy, 2006; Somasundaran et al., 2008; Dasgupta and Ng, 2009; Hassan and Radev, 2010). They mainly focused on two directions: sentiment classification which detects the overall polarity of a text; sentiment related information extraction which tries to answer the questions like “who expresses what opinion on which target”. Most of the current studies on the second direction assume that an opinion can be structured as a frame which is composed of a fixed number of slots. Typical slots include opinion holder, opinion expression, and evaluation target. Under this representation, they defined the task as a slots filling problem for each of the opinions. Na</context>
</contexts>
<marker>Dasgupta, Ng, 2009</marker>
<rawString>Sajib Dasgupta and Vincent Ng. 2009. Mine the easy, classify the hard: A semi-supervised approach to automatic sentiment classification. In Proceedings ofACLIJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kushal Dave</author>
<author>Steve Lawrence</author>
<author>David M Pennock</author>
</authors>
<title>Mining the peanut gallery: opinion extraction and semantic classification of product reviews.</title>
<date>2003</date>
<booktitle>In Proceedings of WWW.</booktitle>
<contexts>
<context position="1157" citStr="Dave et al., 2003" startWordPosition="163" endWordPosition="166">tructural learning method is then introduced to produce the graph representations of input sentences. Experimental evaluations on a manually labeled Chinese corpus demonstrate the effectiveness of the proposed approach. 1 Introduction Sentiment analysis has received much attention in recent years. A number of automatic methods have been proposed to identify and extract opinions, emotions, and sentiments from text. Previous researches on sentiment analysis tackled the problem on various levels of granularity including document, sentence, phrase and word (Pang et al., 2002; Riloff et al., 2003; Dave et al., 2003; Takamura et al., 2005; Kim and Hovy, 2006; Somasundaran et al., 2008; Dasgupta and Ng, 2009; Hassan and Radev, 2010). They mainly focused on two directions: sentiment classification which detects the overall polarity of a text; sentiment related information extraction which tries to answer the questions like “who expresses what opinion on which target”. Most of the current studies on the second direction assume that an opinion can be structured as a frame which is composed of a fixed number of slots. Typical slots include opinion holder, opinion expression, and evaluation target. Under this </context>
</contexts>
<marker>Dave, Lawrence, Pennock, 2003</marker>
<rawString>Kushal Dave, Steve Lawrence, and David M. Pennock. 2003. Mining the peanut gallery: opinion extraction and semantic classification of product reviews. In Proceedings of WWW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascal Denis</author>
<author>Jason Baldridge</author>
</authors>
<title>Joint determination of anaphoricity and coreference resolution using integer programming.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACLHLT.</booktitle>
<contexts>
<context position="31038" citStr="Denis and Baldridge, 2007" startWordPosition="5248" endWordPosition="5251">comparative sentences and proposed learning approaches to identify them. Sentiment analysis of conditional sentences were studied by Narayanan et al. (2009). They aimed to determine whether opinions expressed on different topics in a conditional sentence are positive, negative or neutral. They analyzed the conditional sentences in both linguistic and computitional perspectives and used learning method to do it. They followed the feature-based sentiment analysis model (Hu and Liu, 2004), which also use flat frames to represent evaluations. Integer linear programming was used in many NLP tasks (Denis and Baldridge, 2007), for its power in both expressing and approximating various inference problems, especially in parsing (Riedel and Clarke, 2006; Martins et al., 2009). Martins etc. (2009) also applied ILP with flow formulation for maximum spanning tree, besides, they also handled dependency parse trees involving high order features(sibling, grandparent), and with projective constraint. 6 Conclusions This paper introduces a representation method for opinions in online reviews. Inspections on corpus show that the information ignored in previous sentiment representation can cause incorrect or incomplete mining r</context>
</contexts>
<marker>Denis, Baldridge, 2007</marker>
<rawString>Pascal Denis and Jason Baldridge. 2007. Joint determination of anaphoricity and coreference resolution using integer programming. In Proceedings of NAACLHLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Hassan</author>
<author>Dragomir R Radev</author>
</authors>
<title>Identifying text polarity using random walks.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>395--403</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="1275" citStr="Hassan and Radev, 2010" startWordPosition="183" endWordPosition="186">al evaluations on a manually labeled Chinese corpus demonstrate the effectiveness of the proposed approach. 1 Introduction Sentiment analysis has received much attention in recent years. A number of automatic methods have been proposed to identify and extract opinions, emotions, and sentiments from text. Previous researches on sentiment analysis tackled the problem on various levels of granularity including document, sentence, phrase and word (Pang et al., 2002; Riloff et al., 2003; Dave et al., 2003; Takamura et al., 2005; Kim and Hovy, 2006; Somasundaran et al., 2008; Dasgupta and Ng, 2009; Hassan and Radev, 2010). They mainly focused on two directions: sentiment classification which detects the overall polarity of a text; sentiment related information extraction which tries to answer the questions like “who expresses what opinion on which target”. Most of the current studies on the second direction assume that an opinion can be structured as a frame which is composed of a fixed number of slots. Typical slots include opinion holder, opinion expression, and evaluation target. Under this representation, they defined the task as a slots filling problem for each of the opinions. Named entity recognition an</context>
</contexts>
<marker>Hassan, Radev, 2010</marker>
<rawString>Ahmed Hassan and Dragomir R. Radev. 2010. Identifying text polarity using random walks. In Proceedings of ACL, pages 395–403, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of SIGKDD.</booktitle>
<contexts>
<context position="1958" citStr="Hu and Liu, 2004" startWordPosition="294" endWordPosition="297">hich detects the overall polarity of a text; sentiment related information extraction which tries to answer the questions like “who expresses what opinion on which target”. Most of the current studies on the second direction assume that an opinion can be structured as a frame which is composed of a fixed number of slots. Typical slots include opinion holder, opinion expression, and evaluation target. Under this representation, they defined the task as a slots filling problem for each of the opinions. Named entity recognition and relation extraction techniques are usually applied in this task (Hu and Liu, 2004; Kobayashi et al., 2007; Wu et al., 2009). However, through data analysis, we observe that 60.5% of sentences in our corpus do not follow the assumption used by them. A lot of important information about an opinion may be lost using those representation methods. Consider the following examples, which are extracted from real online reviews: Example 1: The interior is a bit noisy on the freeway1. Example 2: Takes good pictures during the daytime. Very poor picture quality at night2. Based on the definition of opinion unit proposed by Hu and Liu (2004), from the first example, the information we</context>
<context position="30902" citStr="Hu and Liu, 2004" startWordPosition="5227" endWordPosition="5230">stical clues. Jindal and Liu (2006) studied the problem of identifying comparative sentences. They analyzed different types of comparative sentences and proposed learning approaches to identify them. Sentiment analysis of conditional sentences were studied by Narayanan et al. (2009). They aimed to determine whether opinions expressed on different topics in a conditional sentence are positive, negative or neutral. They analyzed the conditional sentences in both linguistic and computitional perspectives and used learning method to do it. They followed the feature-based sentiment analysis model (Hu and Liu, 2004), which also use flat frames to represent evaluations. Integer linear programming was used in many NLP tasks (Denis and Baldridge, 2007), for its power in both expressing and approximating various inference problems, especially in parsing (Riedel and Clarke, 2006; Martins et al., 2009). Martins etc. (2009) also applied ILP with flow formulation for maximum spanning tree, besides, they also handled dependency parse trees involving high order features(sibling, grandparent), and with projective constraint. 6 Conclusions This paper introduces a representation method for opinions in online reviews.</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of SIGKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
</authors>
<title>Identifying comparative sentences in text documents.</title>
<date>2006</date>
<booktitle>In Proceedings of SIGIR.</booktitle>
<contexts>
<context position="29892" citStr="Jindal and Liu, 2006" startWordPosition="5073" endWordPosition="5076"> E+Unigram+Bigram 57.3 47.9 52.1 O+Unigram 71.9 57.2 63.7 O+Unigram+Bigram 72.3 60.2 65.6 Table 7: Results on vertices extraction with 10 folder cross validation. We use two criterion: 1) the vertex is correct if it is exactly same as ground truth(“E”), 2) the vertex is correct if it overlaps with ground truth(“O”). 5 Related Work Opinion mining has recently received considerable attentions. Large amount of work has been done on sentimental classification in different levels and sentiment related information extraction. Researches on different types of sentences such as comparative sentences (Jindal and Liu, 2006) and conditional sentences (Narayanan et al., 2009) have also been proposed. Kobayashi et al. (2007) presented their work on extracting opinion units including: opinion holder, subject, aspect and evaluation. They used slots to represent evaluations, converted the task to two kinds of relation extraction tasks and proposed a machine learning-based method which used both contextual and statistical clues. Jindal and Liu (2006) studied the problem of identifying comparative sentences. They analyzed different types of comparative sentences and proposed learning approaches to identify them. Sentime</context>
</contexts>
<marker>Jindal, Liu, 2006</marker>
<rawString>Nitin Jindal and Bing Liu. 2006. Identifying comparative sentences in text documents. In Proceedings of SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Karp</author>
</authors>
<title>Reducibility among combinatorial problems.</title>
<date>1972</date>
<journal>Complexity of Computer Computations,</journal>
<pages>85--103</pages>
<editor>In R. Miller and J. Thatcher, editors,</editor>
<publisher>Plenum Press.</publisher>
<contexts>
<context position="13041" citStr="Karp, 1972" startWordPosition="2139" endWordPosition="2140">=6 yn then 6: update αt to αt+1 D PA 7: r = r + αt+1 8: end if 9: end for 10: end for 11: return α = r/(N ∗ T) 3.2 Inference Like other structural learning tasks, the “arg max” operation in the algorithm (also called inference) y� = arg max score(x, y) YEY αT f(xi, xj) (2) is hard because all possible values of y form a huge search space. In our case, Y is all possible directed acyclic graphs of the given vertex set, which number is exponential. Directly solving the problem of finding maximum weighted acyclic graph is equivalent to finding maximum feedback arc set, which is a NP-hard problem (Karp, 1972). We will use integer linear programming (ILP) as the framework for this inference problem. 3.2.1 Graph Properties We first show some properties of graph G either from the definition of relations or corpus statistics. Property 1. The graph is connected and without directed cycle. From individual opinion representation, each subgraph of G which takes an opinion expression as root is connected and acyclic. Thus the connectedness is guaranteed for opinion expressions are connected in opinion thread; the acyclic is guaranteed by the fact that if a modifier is shared by different opinion expression</context>
</contexts>
<marker>Karp, 1972</marker>
<rawString>R. Karp. 1972. Reducibility among combinatorial problems. In R. Miller and J. Thatcher, editors, Complexity of Computer Computations, pages 85–103. Plenum Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Automatic identification of pro and con reasons in online reviews.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING-ACL.</booktitle>
<contexts>
<context position="1200" citStr="Kim and Hovy, 2006" startWordPosition="171" endWordPosition="174">ed to produce the graph representations of input sentences. Experimental evaluations on a manually labeled Chinese corpus demonstrate the effectiveness of the proposed approach. 1 Introduction Sentiment analysis has received much attention in recent years. A number of automatic methods have been proposed to identify and extract opinions, emotions, and sentiments from text. Previous researches on sentiment analysis tackled the problem on various levels of granularity including document, sentence, phrase and word (Pang et al., 2002; Riloff et al., 2003; Dave et al., 2003; Takamura et al., 2005; Kim and Hovy, 2006; Somasundaran et al., 2008; Dasgupta and Ng, 2009; Hassan and Radev, 2010). They mainly focused on two directions: sentiment classification which detects the overall polarity of a text; sentiment related information extraction which tries to answer the questions like “who expresses what opinion on which target”. Most of the current studies on the second direction assume that an opinion can be structured as a frame which is composed of a fixed number of slots. Typical slots include opinion holder, opinion expression, and evaluation target. Under this representation, they defined the task as a </context>
</contexts>
<marker>Kim, Hovy, 2006</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2006. Automatic identification of pro and con reasons in online reviews. In Proceedings of the COLING-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Fast exact inference with a factored model for natural language parsing.</title>
<date>2003</date>
<booktitle>In In Advances in Neural Information Processing Systems 15 (NIPS,</booktitle>
<pages>3--10</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="22580" citStr="Klein and Manning, 2003" startWordPosition="3879" endWordPosition="3883">e 60.5% of sentences and 32.1% of opinion expressions contain other modifiers besides “target”. Thus only mining the relations between opinion expressions and evaluation target is actually at risk of inaccurate and incomplete results. 4.2 Experiments Configurations In all the experiments below, we take 90% of the corpus as training set, 10% as test set and run 10 folder cross validation. In feature construction, we use an external Chinese sentiment lexicon which contains 4566 positive opinion words and 4370 negative opinion words. For Chinese word segment, we use ctbparser 5. Stanford parser (Klein and Manning, 2003) is used for dependency parsing. In the settings of PA, the maximum iteration number is 5http://code.google.com/p/ctbparser/ set to 2, which is chosen by maximizing the testing performances, aggressiveness parameter C is set to 0.00001. For parameters in inference algorithm, Ct = 2, the solver of ILP is lpsolve6. We evaluate the system from the following aspects: 1) whether the structural information helps to mining opinion relations. 2) How the proposed inference algorithm performs with different constraints. 3) How the various features affect the system. Except for the last one, the feature </context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Fast exact inference with a factored model for natural language parsing. In In Advances in Neural Information Processing Systems 15 (NIPS, pages 3–10. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nozomi Kobayashi</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Extracting aspect-evaluation and aspect-of relations in opinion mining.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLPCoNLL.</booktitle>
<contexts>
<context position="1982" citStr="Kobayashi et al., 2007" startWordPosition="298" endWordPosition="301">verall polarity of a text; sentiment related information extraction which tries to answer the questions like “who expresses what opinion on which target”. Most of the current studies on the second direction assume that an opinion can be structured as a frame which is composed of a fixed number of slots. Typical slots include opinion holder, opinion expression, and evaluation target. Under this representation, they defined the task as a slots filling problem for each of the opinions. Named entity recognition and relation extraction techniques are usually applied in this task (Hu and Liu, 2004; Kobayashi et al., 2007; Wu et al., 2009). However, through data analysis, we observe that 60.5% of sentences in our corpus do not follow the assumption used by them. A lot of important information about an opinion may be lost using those representation methods. Consider the following examples, which are extracted from real online reviews: Example 1: The interior is a bit noisy on the freeway1. Example 2: Takes good pictures during the daytime. Very poor picture quality at night2. Based on the definition of opinion unit proposed by Hu and Liu (2004), from the first example, the information we can get is the author’s</context>
<context position="23888" citStr="Kobayashi et al., 2007" startWordPosition="4107" endWordPosition="4110">ia for evaluation are similar to the unlabeled attachment score in parser evaluations, but due to the equation |E |= |V |− 1 is not valid if G is not a tree, we evaluate precision#true edges in result graph P = #edges in result graph ,recall R = #true edges in result graph and F-score #edges in true graph , _ 2P·R I — P+R. 4.3 Results 1. The effects of structural information. An alternative method to extract relations is directly using a classifier to judge whether there is a relation between any two elements. Those kinds of methods were used in previous opinion mining works (Wu et al., 2009; Kobayashi et al., 2007). To show the entire structural information is important for mining relations, we use SVM for binary classification on candidate pairs. The data point representing a pair (xi, xj) is the same as the high dimensional feature vectors f(xi, xj). The setting of our algorithm “MST+c1+c2+c3” is the basic MST with all the constraints. The results are shown in the Table 3. P R F SVM 64.9 24.0 35.0 MST+c1+c2+c3-m 61.5 74.0 67.2 MST+c1+c2+c3 73.1 71.0 72.1 Table 3: Binary classifier and structural learning From the results, the performance of SVM (especially recall) is relatively poor. A possible reason</context>
<context position="29992" citStr="Kobayashi et al. (2007)" startWordPosition="5090" endWordPosition="5093"> Results on vertices extraction with 10 folder cross validation. We use two criterion: 1) the vertex is correct if it is exactly same as ground truth(“E”), 2) the vertex is correct if it overlaps with ground truth(“O”). 5 Related Work Opinion mining has recently received considerable attentions. Large amount of work has been done on sentimental classification in different levels and sentiment related information extraction. Researches on different types of sentences such as comparative sentences (Jindal and Liu, 2006) and conditional sentences (Narayanan et al., 2009) have also been proposed. Kobayashi et al. (2007) presented their work on extracting opinion units including: opinion holder, subject, aspect and evaluation. They used slots to represent evaluations, converted the task to two kinds of relation extraction tasks and proposed a machine learning-based method which used both contextual and statistical clues. Jindal and Liu (2006) studied the problem of identifying comparative sentences. They analyzed different types of comparative sentences and proposed learning approaches to identify them. Sentiment analysis of conditional sentences were studied by Narayanan et al. (2009). They aimed to determin</context>
</contexts>
<marker>Kobayashi, Inui, Matsumoto, 2007</marker>
<rawString>Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto. 2007. Extracting aspect-evaluation and aspect-of relations in opinion mining. In Proceedings of EMNLPCoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas L Magnanti</author>
<author>Laurence A Wolsey</author>
</authors>
<date>1994</date>
<note>Optimal trees.</note>
<contexts>
<context position="14990" citStr="Magnanti and Wolsey, 1994" startWordPosition="2456" endWordPosition="2459">steps: i) constructing G’s spanning tree (arborescence) with property 1 and 2; ii) finding additional non-tree edges as a post processing task. The first step is close to the works on ILP formulations of dependency parsing (Riedel and Clarke, 2006; Martins et al., 2009). In the second step, we use a heuristic method which greedily adds non-tree edges. A similar approximation method is also used in (Mcdonald and Pereira, 2006) for acyclic dependency graphs. Step 1. Find MST. Following the multicommodity � ∑= arg max YEY (xi,xj)EY 1335 flow formulation of maximum spanning tree (MST) problem in (Magnanti and Wolsey, 1994), the ILP for MST is: ∑max. yij · score(xi, xj) (3) i,j ∑s.t. yij = |V |− 1 (4) i,j ∑ − fujk = δu j,1 ≤ u,j ≤ |V |(5) i fuij ∑ k ∑ fu0k = 1, 1 ≤ u ≤ |V |(6) k fuij ≤ yij, 1 ≤ u,j ≤ |V |, 0 ≤ i ≤ |V |(7) fuij ≥ 0, 1 ≤ u,j ≤ |V |, 0 ≤ i ≤ |V |(8) yij ∈ { 0, 1}, 0 ≤ i, j ≤ |V |. (9) In this formulation, yij is an edge indicator variable that (xi, xj) is a spanning tree edge when yij = 1, (xi, xj) is a non-tree edge when yij = 0. Then output y is represented by the set {yij, 0 ≤ i, j ≤ |V |} 4. Eq(4) ensures that there will be exactly |V |− 1 edges are chosen. Thus if the edges corresponding to th</context>
<context position="19022" citStr="Magnanti and Wolsey, 1994" startWordPosition="3284" endWordPosition="3288">and c3. It shows c1 are not sufficient for graph property 2: the edges in opinion thread may not be connected. Figure 2 illustrates the effects of c1 and c3. Equations (10)-(18), together with basic multicommodity flow model build up the inference algorithm. The entire ILP formulation involves O(|V |3) variables and O(|V |2) constraints. Generally, ILP falls into NPC, but as an important result, in the multicommodity flow formulation of maximum spanning tree problem, the integer constraints (9) on yij can be dropped. So the problem reduces to a linear programming which is polynomial solvable (Magnanti and Wolsey, 1994). Unfortunately, with our additional constraints the LP relaxation is not valid. Step 2. Adding non-tree edges. We examine the case that a modifier attaches to different opinion expressions. That often occurs as the result of the sharing of modifiers among adjacent opinion expressions. We add those edges in the following heuristic way: If a vertex ri in opinion thread does not have any modifier, we search the modifiers of its adjacent vertices ri+1, ri−1 in the opinion thread, and add edge (ri, d*) where d* = arg max dES and S are the modifiers of ri−1 and ri+1. 3.3 Training We use online pass</context>
</contexts>
<marker>Magnanti, Wolsey, 1994</marker>
<rawString>Thomas L. Magnanti and Laurence A. Wolsey. 1994. Optimal trees.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andre Martins</author>
<author>Noah Smith</author>
<author>Eric Xing</author>
</authors>
<title>Concise integer linear programming formulations for dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP.</booktitle>
<contexts>
<context position="14634" citStr="Martins et al., 2009" startWordPosition="2399" endWordPosition="2402"> connects to more than one opinion expression rarely occur comparing with those vertices which have a single parent. An explaination for this sparseness is that opinions in online reviews always concentrate in local context and have local semantic connections. 3.2.2 ILP Formulation Based on the property 3, we divide the inference algorithm into two steps: i) constructing G’s spanning tree (arborescence) with property 1 and 2; ii) finding additional non-tree edges as a post processing task. The first step is close to the works on ILP formulations of dependency parsing (Riedel and Clarke, 2006; Martins et al., 2009). In the second step, we use a heuristic method which greedily adds non-tree edges. A similar approximation method is also used in (Mcdonald and Pereira, 2006) for acyclic dependency graphs. Step 1. Find MST. Following the multicommodity � ∑= arg max YEY (xi,xj)EY 1335 flow formulation of maximum spanning tree (MST) problem in (Magnanti and Wolsey, 1994), the ILP for MST is: ∑max. yij · score(xi, xj) (3) i,j ∑s.t. yij = |V |− 1 (4) i,j ∑ − fujk = δu j,1 ≤ u,j ≤ |V |(5) i fuij ∑ k ∑ fu0k = 1, 1 ≤ u ≤ |V |(6) k fuij ≤ yij, 1 ≤ u,j ≤ |V |, 0 ≤ i ≤ |V |(7) fuij ≥ 0, 1 ≤ u,j ≤ |V |, 0 ≤ i ≤ |V |(8)</context>
<context position="31188" citStr="Martins et al., 2009" startWordPosition="5270" endWordPosition="5273">). They aimed to determine whether opinions expressed on different topics in a conditional sentence are positive, negative or neutral. They analyzed the conditional sentences in both linguistic and computitional perspectives and used learning method to do it. They followed the feature-based sentiment analysis model (Hu and Liu, 2004), which also use flat frames to represent evaluations. Integer linear programming was used in many NLP tasks (Denis and Baldridge, 2007), for its power in both expressing and approximating various inference problems, especially in parsing (Riedel and Clarke, 2006; Martins et al., 2009). Martins etc. (2009) also applied ILP with flow formulation for maximum spanning tree, besides, they also handled dependency parse trees involving high order features(sibling, grandparent), and with projective constraint. 6 Conclusions This paper introduces a representation method for opinions in online reviews. Inspections on corpus show that the information ignored in previous sentiment representation can cause incorrect or incomplete mining results. We consider opinion restriction, opinion expansions, relations between opinion expressions, and represent them with a directed graph. Structur</context>
</contexts>
<marker>Martins, Smith, Xing, 2009</marker>
<rawString>Andre Martins, Noah Smith, and Eric Xing. 2009. Concise integer linear programming formulations for dependency parsing. In Proceedings of ACL-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mcdonald</author>
<author>F Pereira</author>
</authors>
<title>Identifying gene and protein mentions in text using conditional random fields.</title>
<date>2005</date>
<journal>BMC Bioinformatics.</journal>
<contexts>
<context position="10992" citStr="Mcdonald and Pereira, 2005" startWordPosition="1734" endWordPosition="1738">we need to extract candidate vertices and build the relations among them to get a graph structure. For the first task, the experimental results in Section 4 demonstrate that the standard sequential labeling method with simple features can achieve reasonable performance. In this section, we focus on the second task, and assume the vertices in the graph have already been correctly collected in the following formulation of algorithm. 3.1 Preliminaries In order to construct graph G, we use a structural learning method. The framework is from the first order discriminative dependency parsing model (Mcdonald and Pereira, 2005). A sentence is denoted by s; x are text spans which will be vertices of graph; xi is the ith vertex in x ordered by their positions in s. For a set of vertices x, y is the graph of its sentiment representation, and e = (xi, xj) E y is the direct edge from xi to xj in y. In addition, x0 is a r2 sharp good r1 Target Restriction Coordinate Focus accuracy indoors d11 d12 r3 shots slightly soft litle 3x optical zooms Expansion Target Transition d21 d22 Target edges 1334 virtual root node without inedge. G = {(xn, yn)}n is training set. Following the edge based factorization, the score of a graph i</context>
</contexts>
<marker>Mcdonald, Pereira, 2005</marker>
<rawString>R. Mcdonald and F. Pereira. 2005. Identifying gene and protein mentions in text using conditional random fields. BMC Bioinformatics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Mcdonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proc. of EACL,</booktitle>
<pages>81--88</pages>
<contexts>
<context position="14793" citStr="Mcdonald and Pereira, 2006" startWordPosition="2425" endWordPosition="2428">is that opinions in online reviews always concentrate in local context and have local semantic connections. 3.2.2 ILP Formulation Based on the property 3, we divide the inference algorithm into two steps: i) constructing G’s spanning tree (arborescence) with property 1 and 2; ii) finding additional non-tree edges as a post processing task. The first step is close to the works on ILP formulations of dependency parsing (Riedel and Clarke, 2006; Martins et al., 2009). In the second step, we use a heuristic method which greedily adds non-tree edges. A similar approximation method is also used in (Mcdonald and Pereira, 2006) for acyclic dependency graphs. Step 1. Find MST. Following the multicommodity � ∑= arg max YEY (xi,xj)EY 1335 flow formulation of maximum spanning tree (MST) problem in (Magnanti and Wolsey, 1994), the ILP for MST is: ∑max. yij · score(xi, xj) (3) i,j ∑s.t. yij = |V |− 1 (4) i,j ∑ − fujk = δu j,1 ≤ u,j ≤ |V |(5) i fuij ∑ k ∑ fu0k = 1, 1 ≤ u ≤ |V |(6) k fuij ≤ yij, 1 ≤ u,j ≤ |V |, 0 ≤ i ≤ |V |(7) fuij ≥ 0, 1 ≤ u,j ≤ |V |, 0 ≤ i ≤ |V |(8) yij ∈ { 0, 1}, 0 ≤ i, j ≤ |V |. (9) In this formulation, yij is an edge indicator variable that (xi, xj) is a spanning tree edge when yij = 1, (xi, xj) is a n</context>
</contexts>
<marker>Mcdonald, Pereira, 2006</marker>
<rawString>Ryan Mcdonald and Fernando Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proc. of EACL, pages 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ramanathan Narayanan</author>
<author>Bing Liu</author>
<author>Alok Choudhary</author>
</authors>
<title>Sentiment analysis of conditional sentences.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="29943" citStr="Narayanan et al., 2009" startWordPosition="5081" endWordPosition="5084">7.2 63.7 O+Unigram+Bigram 72.3 60.2 65.6 Table 7: Results on vertices extraction with 10 folder cross validation. We use two criterion: 1) the vertex is correct if it is exactly same as ground truth(“E”), 2) the vertex is correct if it overlaps with ground truth(“O”). 5 Related Work Opinion mining has recently received considerable attentions. Large amount of work has been done on sentimental classification in different levels and sentiment related information extraction. Researches on different types of sentences such as comparative sentences (Jindal and Liu, 2006) and conditional sentences (Narayanan et al., 2009) have also been proposed. Kobayashi et al. (2007) presented their work on extracting opinion units including: opinion holder, subject, aspect and evaluation. They used slots to represent evaluations, converted the task to two kinds of relation extraction tasks and proposed a machine learning-based method which used both contextual and statistical clues. Jindal and Liu (2006) studied the problem of identifying comparative sentences. They analyzed different types of comparative sentences and proposed learning approaches to identify them. Sentiment analysis of conditional sentences were studied b</context>
</contexts>
<marker>Narayanan, Liu, Choudhary, 2009</marker>
<rawString>Ramanathan Narayanan, Bing Liu, and Alok Choudhary. 2009. Sentiment analysis of conditional sentences. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proc. of EMNLP</booktitle>
<contexts>
<context position="1117" citStr="Pang et al., 2002" startWordPosition="155" endWordPosition="158">t. An integer linear programming-based structural learning method is then introduced to produce the graph representations of input sentences. Experimental evaluations on a manually labeled Chinese corpus demonstrate the effectiveness of the proposed approach. 1 Introduction Sentiment analysis has received much attention in recent years. A number of automatic methods have been proposed to identify and extract opinions, emotions, and sentiments from text. Previous researches on sentiment analysis tackled the problem on various levels of granularity including document, sentence, phrase and word (Pang et al., 2002; Riloff et al., 2003; Dave et al., 2003; Takamura et al., 2005; Kim and Hovy, 2006; Somasundaran et al., 2008; Dasgupta and Ng, 2009; Hassan and Radev, 2010). They mainly focused on two directions: sentiment classification which detects the overall polarity of a text; sentiment related information extraction which tries to answer the questions like “who expresses what opinion on which target”. Most of the current studies on the second direction assume that an opinion can be structured as a frame which is composed of a fixed number of slots. Typical slots include opinion holder, opinion expres</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. In Proc. of EMNLP 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>James Clarke</author>
</authors>
<title>Incremental integer linear programming for non-projective dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="14611" citStr="Riedel and Clarke, 2006" startWordPosition="2395" endWordPosition="2398">the cases that a modifier connects to more than one opinion expression rarely occur comparing with those vertices which have a single parent. An explaination for this sparseness is that opinions in online reviews always concentrate in local context and have local semantic connections. 3.2.2 ILP Formulation Based on the property 3, we divide the inference algorithm into two steps: i) constructing G’s spanning tree (arborescence) with property 1 and 2; ii) finding additional non-tree edges as a post processing task. The first step is close to the works on ILP formulations of dependency parsing (Riedel and Clarke, 2006; Martins et al., 2009). In the second step, we use a heuristic method which greedily adds non-tree edges. A similar approximation method is also used in (Mcdonald and Pereira, 2006) for acyclic dependency graphs. Step 1. Find MST. Following the multicommodity � ∑= arg max YEY (xi,xj)EY 1335 flow formulation of maximum spanning tree (MST) problem in (Magnanti and Wolsey, 1994), the ILP for MST is: ∑max. yij · score(xi, xj) (3) i,j ∑s.t. yij = |V |− 1 (4) i,j ∑ − fujk = δu j,1 ≤ u,j ≤ |V |(5) i fuij ∑ k ∑ fu0k = 1, 1 ≤ u ≤ |V |(6) k fuij ≤ yij, 1 ≤ u,j ≤ |V |, 0 ≤ i ≤ |V |(7) fuij ≥ 0, 1 ≤ u,j </context>
<context position="31165" citStr="Riedel and Clarke, 2006" startWordPosition="5266" endWordPosition="5269">by Narayanan et al. (2009). They aimed to determine whether opinions expressed on different topics in a conditional sentence are positive, negative or neutral. They analyzed the conditional sentences in both linguistic and computitional perspectives and used learning method to do it. They followed the feature-based sentiment analysis model (Hu and Liu, 2004), which also use flat frames to represent evaluations. Integer linear programming was used in many NLP tasks (Denis and Baldridge, 2007), for its power in both expressing and approximating various inference problems, especially in parsing (Riedel and Clarke, 2006; Martins et al., 2009). Martins etc. (2009) also applied ILP with flow formulation for maximum spanning tree, besides, they also handled dependency parse trees involving high order features(sibling, grandparent), and with projective constraint. 6 Conclusions This paper introduces a representation method for opinions in online reviews. Inspections on corpus show that the information ignored in previous sentiment representation can cause incorrect or incomplete mining results. We consider opinion restriction, opinion expansions, relations between opinion expressions, and represent them with a d</context>
</contexts>
<marker>Riedel, Clarke, 2006</marker>
<rawString>Sebastian Riedel and James Clarke. 2006. Incremental integer linear programming for non-projective dependency parsing. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
</authors>
<title>Learning subjective nouns using extraction pattern bootstrapping.</title>
<date>2003</date>
<booktitle>In Proceedings of the seventh conference on Natural language learning at HLT-NAACL.</booktitle>
<contexts>
<context position="1138" citStr="Riloff et al., 2003" startWordPosition="159" endWordPosition="162">r programming-based structural learning method is then introduced to produce the graph representations of input sentences. Experimental evaluations on a manually labeled Chinese corpus demonstrate the effectiveness of the proposed approach. 1 Introduction Sentiment analysis has received much attention in recent years. A number of automatic methods have been proposed to identify and extract opinions, emotions, and sentiments from text. Previous researches on sentiment analysis tackled the problem on various levels of granularity including document, sentence, phrase and word (Pang et al., 2002; Riloff et al., 2003; Dave et al., 2003; Takamura et al., 2005; Kim and Hovy, 2006; Somasundaran et al., 2008; Dasgupta and Ng, 2009; Hassan and Radev, 2010). They mainly focused on two directions: sentiment classification which detects the overall polarity of a text; sentiment related information extraction which tries to answer the questions like “who expresses what opinion on which target”. Most of the current studies on the second direction assume that an opinion can be structured as a frame which is composed of a fixed number of slots. Typical slots include opinion holder, opinion expression, and evaluation </context>
</contexts>
<marker>Riloff, Wiebe, Wilson, 2003</marker>
<rawString>Ellen Riloff, Janyce Wiebe, and Theresa Wilson. 2003. Learning subjective nouns using extraction pattern bootstrapping. In Proceedings of the seventh conference on Natural language learning at HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
<author>Janyce Wiebe</author>
<author>Josef Ruppenhofer</author>
</authors>
<title>Discourse level opinion interpretation.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="1227" citStr="Somasundaran et al., 2008" startWordPosition="175" endWordPosition="178">aph representations of input sentences. Experimental evaluations on a manually labeled Chinese corpus demonstrate the effectiveness of the proposed approach. 1 Introduction Sentiment analysis has received much attention in recent years. A number of automatic methods have been proposed to identify and extract opinions, emotions, and sentiments from text. Previous researches on sentiment analysis tackled the problem on various levels of granularity including document, sentence, phrase and word (Pang et al., 2002; Riloff et al., 2003; Dave et al., 2003; Takamura et al., 2005; Kim and Hovy, 2006; Somasundaran et al., 2008; Dasgupta and Ng, 2009; Hassan and Radev, 2010). They mainly focused on two directions: sentiment classification which detects the overall polarity of a text; sentiment related information extraction which tries to answer the questions like “who expresses what opinion on which target”. Most of the current studies on the second direction assume that an opinion can be structured as a frame which is composed of a fixed number of slots. Typical slots include opinion holder, opinion expression, and evaluation target. Under this representation, they defined the task as a slots filling problem for e</context>
</contexts>
<marker>Somasundaran, Wiebe, Ruppenhofer, 2008</marker>
<rawString>Swapna Somasundaran, Janyce Wiebe, and Josef Ruppenhofer. 2008. Discourse level opinion interpretation. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Takashi Inui</author>
<author>Manabu Okumura</author>
</authors>
<title>Extracting semantic orientations of words using spin model.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1180" citStr="Takamura et al., 2005" startWordPosition="167" endWordPosition="170">method is then introduced to produce the graph representations of input sentences. Experimental evaluations on a manually labeled Chinese corpus demonstrate the effectiveness of the proposed approach. 1 Introduction Sentiment analysis has received much attention in recent years. A number of automatic methods have been proposed to identify and extract opinions, emotions, and sentiments from text. Previous researches on sentiment analysis tackled the problem on various levels of granularity including document, sentence, phrase and word (Pang et al., 2002; Riloff et al., 2003; Dave et al., 2003; Takamura et al., 2005; Kim and Hovy, 2006; Somasundaran et al., 2008; Dasgupta and Ng, 2009; Hassan and Radev, 2010). They mainly focused on two directions: sentiment classification which detects the overall polarity of a text; sentiment related information extraction which tries to answer the questions like “who expresses what opinion on which target”. Most of the current studies on the second direction assume that an opinion can be structured as a frame which is composed of a fixed number of slots. Typical slots include opinion holder, opinion expression, and evaluation target. Under this representation, they de</context>
</contexts>
<marker>Takamura, Inui, Okumura, 2005</marker>
<rawString>Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2005. Extracting semantic orientations of words using spin model. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuangjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Phrase dependency parsing for opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="2000" citStr="Wu et al., 2009" startWordPosition="302" endWordPosition="305">t; sentiment related information extraction which tries to answer the questions like “who expresses what opinion on which target”. Most of the current studies on the second direction assume that an opinion can be structured as a frame which is composed of a fixed number of slots. Typical slots include opinion holder, opinion expression, and evaluation target. Under this representation, they defined the task as a slots filling problem for each of the opinions. Named entity recognition and relation extraction techniques are usually applied in this task (Hu and Liu, 2004; Kobayashi et al., 2007; Wu et al., 2009). However, through data analysis, we observe that 60.5% of sentences in our corpus do not follow the assumption used by them. A lot of important information about an opinion may be lost using those representation methods. Consider the following examples, which are extracted from real online reviews: Example 1: The interior is a bit noisy on the freeway1. Example 2: Takes good pictures during the daytime. Very poor picture quality at night2. Based on the definition of opinion unit proposed by Hu and Liu (2004), from the first example, the information we can get is the author’s negative opinion </context>
<context position="23863" citStr="Wu et al., 2009" startWordPosition="4103" endWordPosition="4106">le 5). The criteria for evaluation are similar to the unlabeled attachment score in parser evaluations, but due to the equation |E |= |V |− 1 is not valid if G is not a tree, we evaluate precision#true edges in result graph P = #edges in result graph ,recall R = #true edges in result graph and F-score #edges in true graph , _ 2P·R I — P+R. 4.3 Results 1. The effects of structural information. An alternative method to extract relations is directly using a classifier to judge whether there is a relation between any two elements. Those kinds of methods were used in previous opinion mining works (Wu et al., 2009; Kobayashi et al., 2007). To show the entire structural information is important for mining relations, we use SVM for binary classification on candidate pairs. The data point representing a pair (xi, xj) is the same as the high dimensional feature vectors f(xi, xj). The setting of our algorithm “MST+c1+c2+c3” is the basic MST with all the constraints. The results are shown in the Table 3. P R F SVM 64.9 24.0 35.0 MST+c1+c2+c3-m 61.5 74.0 67.2 MST+c1+c2+c3 73.1 71.0 72.1 Table 3: Binary classifier and structural learning From the results, the performance of SVM (especially recall) is relativel</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2009</marker>
<rawString>Yuanbin Wu, Qi Zhang, Xuangjing Huang, and Lide Wu. 2009. Phrase dependency parsing for opinion mining. In Proceedings of EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>