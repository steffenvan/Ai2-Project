<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.010026">
<title confidence="0.917432">
Reverse Revision and Linear Tree Combination for Dependency Parsing
</title>
<author confidence="0.843776">
Giuseppe Attardi
</author>
<affiliation confidence="0.748294666666667">
Dipartimento di Informatica
Universit`a di Pisa
Pisa, Italy
</affiliation>
<email confidence="0.996363">
attardi@di.unipi.it
</email>
<author confidence="0.885683">
Felice Dell’Orletta
</author>
<affiliation confidence="0.815852333333333">
Dipartimento di Informatica
Universit`a di Pisa
Pisa, Italy
</affiliation>
<email confidence="0.989231">
felice.dellorletta@di.unipi.it
</email>
<sectionHeader confidence="0.99962" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998245">
Deterministic transition-based Shift/Reduce depen-
dency parsers make often mistakes in the analysis of
long span dependencies (McDonald &amp; Nivre, 2007).
Titov and Henderson (2007) address this accuracy
drop by using a beam search instead of a greedy al-
gorithm for predicting the next parser transition.
We propose a parsing method that allows reduc-
ing several of these errors, although maintaining a
quasi linear complexity. The method consists in two
steps: first the sentence is parsed by a determinis-
tic Shift/Reduce parser, then a second deterministic
Shift/Reduce parser analyzes the sentence in reverse
using additional features extracted from the parse
trees produced by the first parser.
Right-to-left parsing has been used as part of
ensemble-based parsers (Sagae &amp; Lavie, 2006; Hall
et al., 2007). Nivre and McDonald (2008) instead
use hints from one parse as features in a second
parse, exploiting the complementary properties of
graph-based parsers (Eisner, 1996; McDonald et al.,
2005) and transition-based dependency parsers (Ya-
mada &amp; Matsumoto, 2003; Nivre &amp; Scholz, 2004).
Also our method uses input from a previous parser
but only uses parsers of a single type, determin-
istic transition-based Shift/Reduce, maintaining an
overall linear complexity. In fact both the en-
semble parsers and the stacking solution of Nivre-
McDonald involve the computation of the maximum
spanning tree (MST) of a graph, which require algo-
rithms of quadratic time complexity (e.g. (Chu &amp;
Liu, 1965; Edmonds, 1967)).
We introduce an alternative linear combination
method. The algorithm is greedy and works by com-
bining the trees top down. We tested it on the de-
pendency trees produced by three parsers, a Left-
to-Right (LR), a Right-to-Left (RL) and a stacked
Right-to-Left parser, or Reverse Revision parser
(Rev2). 1 The experiments show that in practice
its output often outperforms the results produced by
calculating the MST.
</bodyText>
<sectionHeader confidence="0.997184" genericHeader="introduction">
2 Experiments
</sectionHeader>
<bodyText confidence="0.999380090909091">
In the reported experiments we used DeSR (Attardi
at al., 2007), a freely available implementation of
a transition-based parser. The parser processes in-
put tokens advancing on the input with Shift actions
and accumulates processed tokens on a stack with
Reduce actions. The parsing algorithm is fully de-
terministic and linear.
For the LR parser and the Rev2 parser we em-
ployed an SVM classifier while a Maximum Entropy
classifier, with lower accuracy, was used to create
the training set for the Rev2 parser. The reason for
this appears to be that the output of a low accuracy
parser with many errors provides a better source of
learning to the stacked parser.
The Rev2 parser exploits the same basic set of
features as in the LR parser plus the additional fea-
tures extracted from the output of the LR parser
listed in Table 1, where: PHLEMMA is the lemma
of the predicted head, PHPOS is the Part of Speech
of the predicted head, PDEP is the predicted depen-
dency label of a token to its predicted head, PHDIST
indicates whether a token is located before or after
</bodyText>
<footnote confidence="0.982644">
1The stacked Left-to-Right parser produced slightly worse
results than Rev2.
</footnote>
<page confidence="0.9305">
261
</page>
<note confidence="0.4603965">
Proceedings of NAACL HLT 2009: Short Papers, pages 261–264,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<figure confidence="0.999348666666667">
0.
0.
0.
0.
0.
0.
</figure>
<table confidence="0.844152714285714">
Feature Tokens
PHHLEMMA w0 w1
PHDEP w0 w1
PHPOS s0 w0 w1
PHLEMMA s0 w0 w1
PDEP s0 w0 w1
PHDIST s0 w0 w1
</table>
<tableCaption confidence="0.9240945">
Table 1: Additional features used in training the Revision
parser.
</tableCaption>
<bodyText confidence="0.999978741935484">
its predicted head, PHHLEMMA is the lemma of
the predicted grandparent and PHDEP is the pre-
dicted dependency label of the predicted head of a
token to the predicted grandparent. so refers to a to-
ken on top of the stack, wz refers to word at the i-th
relative position with respect to the current word and
parsing direction. This feature model was used for
all languages in our tests.
We present experiments and comparative error
analysis on three representative languages from the
CoNLL 2007 shared task (Nivre at al., 2007): Ital-
ian, Czech and English. We also report an evaluation
on all thirteen languages of the CoNLL-X shared
task (Buchholz &amp; Marsi, 2006), for comparison with
the results by Nivre and McDonald (2008).
Table 2 shows the Labeled Attachment Score
(LAS), for the Left-to-right parser (LR), Right-to-
Left (RL), Reverse Revision parser (Rev2), linear
parser combination (Comb) and MST parser combi-
nation (CombMST).
Figure 1 and 2 present the accuracies of the LR
and Rev2 parsers for English relative to the depen-
dency length and the length of sentences, respec-
tively. For Czech and Italian the RL parser achieves
higher accuracy than the LR parser and the Rev2
parser even higher. The error analysis for Czech
showed that the Rev2 parser improves over the LR
parser everywhere except in the Recall for depen-
dencies of length between 10 and 14. Such an im-
provement has positive impact on the analysis of
sentences longer than 10 tokens, like for Italian.
</bodyText>
<subsectionHeader confidence="0.845623">
2.1 CoNLL-X Results
</subsectionHeader>
<bodyText confidence="0.9983536">
For direct comparison with the approach by Nivre
and McDonald (2008), we present the results on the
CoNLL-X corpora (Table 3): MST and MSTMalt
are the results achieved by the MST parser and the
MST parser using hints from Maltparser, Malt and
</bodyText>
<figureCaption confidence="0.962278">
Figure 1: English. F-Measure relative to dependency
length.
</figureCaption>
<figure confidence="0.9974825">
10 20 30 40 50 60
Sentence Length
</figure>
<figureCaption confidence="0.938189">
Figure 2: English. Accuracy relative to sentence length.
MaltMST the results of the opposite stacking.
</figureCaption>
<subsectionHeader confidence="0.962763">
2.2 Remarks
</subsectionHeader>
<bodyText confidence="0.999931454545454">
The Rev2 parser, informed with data from the LR
parser, achieves better accuracy in twelwe cases, sta-
tistically significantly better in eight.
The error analysis confirms that indeed the Rev2
parser is able to reduce the number of errors made on
long dependency links, which are a major weakness
of a deterministic Shift/Reduce parser. The accuracy
of the Rev2 parser might be further improved by
more sophisticated feature selection, choosing fea-
tures that better represent hints to the second parsing
stage.
</bodyText>
<sectionHeader confidence="0.99359" genericHeader="method">
3 Linear Voting Combination
</sectionHeader>
<bodyText confidence="0.999725">
Our final improvements arise by combining the out-
puts of the three parser models: the LR parser, the
</bodyText>
<figure confidence="0.987765916666667">
96
94
92
90
88
86
84
82
80
Left-to-Right_DeSR
Revision_DeSR
I
</figure>
<page confidence="0.965744">
262
</page>
<table confidence="0.977467681818182">
Language LR RL Rev2 Comb CombMST CoNLL
2007 Best
Czech 77.12 78.20 79.95 80.57 80.25 80.19
English 86.94 87.44 88.34 89.00 88.79 89.61
Italian 81.40 82.89 83.52 84.56 84.28 84.40
Table 2: LAS for selected CoNLL 2007 languages.
Language LR RL Rev2 Comb CombMST Conll-X MST MSTMajt Malt MaltMST
Best
arabic 67.27 66.05 67.54 68.38 68.50 66.91 66.91 68.64 66.71 67.80
bulgarian 86.83 87.13 87.41 88.11 87.85 87.57 87.57 89.05 87.41 88.59
chinese 87.44 85.77 87.51 87.77 87.75 89.96 85.90 88.43 86.92 87.44
czech 79.84 79.46 81.78 82.22 82.22 80.18 80.18 82.26 78.42 81.18
danish 83.89 83.63 84.85 85.47 85.25 84.79 84.79 86.67 84.77 85.43
dutch 75.71 77.27 78.77 79.55 80.19 79.19 79.19 81.63 78.59 79.91
german 85.34 85.20 86.50 87.40 87.38 87.34 87.34 88.46 85.82 87.66
japanese 90.03 90.63 90.87 91.67 91.59 91.65 90.71 91.43 91.65 92.20
portuguese 86.84 87.00 87.86 88.14 88.20 87.60 86.82 87.50 87.60 88.64
slovene 73.64 74.40 75.32 75.72 75.48 73.44 73.44 75.94 70.30 74.24
spanish 81.63 81.61 81.85 83.33 83.13 82.25 82.25 83.99 81.29 82.41
swedish 82.95 81.62 82.91 83.69 83.69 84.58 82.55 84.66 84.58 84.31
turkish 64.91 61.92 63.33 65.27 65.23 65.68 63.19 64.29 65.58 66.28
Average 80.49 80.13 81.27 82.05 82.03 81.63 80.83 82.53 80.74 82.01
</table>
<tableCaption confidence="0.999921">
Table 3: Labeled attachment scores for CoNLL-X corpora.
</tableCaption>
<bodyText confidence="0.98928105">
RL parser and the Rev2 parser.
Instead of using a general algorithm for calcu-
lating the MST of a graph, we exploit the fact that
we are combining trees and hence we developed an
approximate algorithm that has O(kn) complexity,
where n is the number of nodes in a tree and k is the
number of trees being combined.
The algorithm builds the combined tree T incre-
mentally, starting from the empty tree. We will ar-
gue that an invariant of the algorithm is that the par-
tial result T is always a tree.
The algorithm exploits the notion of fringe F, i.e.
the set of arcs whose parent is in T and that can be
added to T without affecting the invariant. Initially
F consists of the roots of all trees to be combined.
The weight of each arc a in the fringe is the number
of parsers that predicted a.
At each step, the algorithm selects from F an arc
a = (h, d, r) among those with maximum weight,
having h ∈ T. Then it:
</bodyText>
<listItem confidence="0.988942666666667">
1. adds a to T
2. removes from F all arcs whose child is d
3. adds to F all arcs (h&apos;, d&apos;, r&apos;) in the original trees
</listItem>
<bodyText confidence="0.999722166666667">
where h&apos; ∈ T and d&apos; ∈/ T.
Step 3 guarantees that no cycles are present in T.
The final T is connected because each added node
is connected to a node in T. T is a local maximum
because if there were another tree with higher score
including arc (h, n, r), either it is present in T or its
weight is smaller than the weight for node (h&apos;, n, r&apos;)
in T, as chosen by the algorithm.
The algorithm has O(kn) complexity. A sketch of
the proof can be given as follows. Step 3 guarantees
that the algorithm is iterated n times, where n is the
number of nodes in a component tree. Using appro-
priate data structures to represent the fringe F, in-
sert or delete operations take constant time. At each
iteration of the algorithm the maximum number of
removals from F (step 2) is constant and it is equal
to k, hence the overall cost is O(nk).
Table 2 shows the results for the three languages
from CoNLL 2007. With respect to the best results
at the CoNLL 2007 Shared Task, the linear parser
combination achieves the best LAS for Czech and
Italian, the second best for English.
The results for the CoNLL-X languages (Table 3)
show also improvements: the Rev2 parser is more
</bodyText>
<page confidence="0.995991">
263
</page>
<bodyText confidence="0.999966086956522">
accurate than MST, except for Bulgarian, Dutch,
German, and Spanish, where the difference is within
1%, and it is often better than the MaltMST stacking.
The improvements of the Rev2 over the LR parser
range from 0.38% for Chinese to 3.84% for Dutch.
The column CombMST shows the results of com-
bining parsers using the Chu-Liu-Edmonds MST al-
gorithm and the same weighting scheme of Lin-
ear Combination algorithm. For most languages
the Linear Combination algorithm leads to a bet-
ter accuracy than the MST algorithm. The some-
what surprising result might be due indeed to the top
down processing of the algorithm: since the algo-
rithm chooses the best among the connections that
are higher in the parse tree, this leads to a prefer-
ence to long spanning links over shorter links even
if these contribute higher weights to the MST.
Finally, the run time of the linear combination al-
gorithm on the whole CoNLL-X test set is 11.2 sec,
while the MST combination requires 92.5 sec.
We also tested weights based on the accuracy
score of each parser for the POS of an arc head, but
this produced less accurate results.
</bodyText>
<sectionHeader confidence="0.999618" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999991148148148">
We presented a method for improving the accuracy
of a dependency parser by using a parser that ana-
lyzes a sentence in reverse using hints from the trees
produced by a forward parser.
We also introduced a new linear algorithm to per-
form parser combination.
Experiments on the corpora of languages from
the CoNLL-X and the CoNLL 2007 shared tasks
show that reverse revision parsing improves the ac-
curacy over a transition-based dependency parser in
all the tested languages. Further improvements are
obtained by using a linear parser combination algo-
rithm on the outputs of three parsers: a LR parser, a
RL parser and a Rev2 parser.
The combination parser achieves accuracies that
are best or second best with respect to the results
of the CoNLL 2007 shared task. Since all the indi-
vidual parsers as well as the combination algorithm
is linear, the combined parser maintains an overall
linear computational time. On the languages from
the CoNLL-X shared task the combination parser
achieves often the best accuracy in ten out of thirteen
languages but falls short of the accuracy achieved
by integrating a graph-based with a transition based
parser.
We expect that further tuning of the method might
help reduce these differences.
</bodyText>
<sectionHeader confidence="0.998517" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999324755555555">
G. Attardi, F. Dell’Orletta, M. Simi, A. Chanev and
M. Ciaramita. 2007. Multilingual Dependency Parsing
and Domain Adaptation using DeSR. In Proc. of the
CoNLL Shared Task Session of EMNLP-CoNLL 2007.
S. Buchholz and E. Marsi. 2006. CoNLL-X shared
task on multilingual dependency parsing. In Proc. of
CoNLL, 149–164.
Y. J. Chu and T. H. Liu. 1965. On the shortest arbores-
cence of a directed graph. Science Sinica(14), 1396–
1400.
J. Edmonds. 1967. Optimum branchings. Journal of Re-
search of the National Bureau of Standards (71B),
233–240.
J. M. Eisner. 1996. Three new probabilistic models for
dependency parsing: An exploration. In Proc. of COL-
ING 1996, 340–345.
J. Hall, et al. 2007. Single Malt or Blended? A Study
in Multilingual Parser Optimization. In Proc. of the
CoNLL Shared Task Session of EMNLP-CoNLL 2007.
R. McDonald and J. Nivre. 2007. Characterizing the Er-
rors of Data-Driven Dependency Parsing Models In
Proc. of EMNLP-CoNLL 2007.
R. McDonald, F. Pereira, K. Ribarov and J. Haji˘c. 2005.
Non-projective Dependency Parsing using Spanning
Tree Algorithms. In Proc. of HLT-EMNLP 2005.
R. McDonald and F. Pereira. 2006. Online Learning
of Approximate Dependency Parsing Algorithms. In
Proc. of EACL 2006.
J. Nivre, et al. 2007. The CoNLL 2007 Shared Task on
Dependency Parsing. In Proc. of the CoNLL Shared
Task Session of EMNLP/CoNLL-2007.
J. Nivre and R. McDonald. 2008. Integrating Graph-
Based and Transition-Based Dependency Parsers. In
Proc. of ACL 2008.
J. Nivre and M. Scholz. 2004. Deterministic Dependency
Parsing of English Text. In Proc. of COLING 2004.
K. Sagae and A. Lavie. 2006. Parser Combination by
Reparsing. In Proc. of HLT-NAACL 2006.
I. Titov and J. Henderson. 2007. Fast and Robust Multi-
lingual Dependency Parsing with a Generative Latent
Variable Model In Proc. of the CoNLL Shared Task
Session of EMNLP/CoNNL-2007.
H. Yamada and Y. Matsumoto. 2003. Statistical depen-
dency analysis using support vector machines. In Proc.
of the 8th IWPT. Nancy, France.
</reference>
<page confidence="0.998206">
264
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.434655">
<title confidence="0.999632">Reverse Revision and Linear Tree Combination for Dependency Parsing</title>
<author confidence="0.876003">Giuseppe</author>
<affiliation confidence="0.993363">Dipartimento di Informatica Universit`a di Pisa</affiliation>
<address confidence="0.994985">Pisa, Italy</address>
<email confidence="0.996154">attardi@di.unipi.it</email>
<author confidence="0.884443">Felice</author>
<affiliation confidence="0.847751333333333">Dipartimento di Universit`a di Pisa,</affiliation>
<email confidence="0.975155">felice.dellorletta@di.unipi.it</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Attardi</author>
<author>F Dell’Orletta</author>
<author>M Simi</author>
<author>A Chanev</author>
<author>M Ciaramita</author>
</authors>
<title>Multilingual Dependency Parsing and Domain Adaptation using DeSR.</title>
<date>2007</date>
<booktitle>In Proc. of the CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<marker>Attardi, Dell’Orletta, Simi, Chanev, Ciaramita, 2007</marker>
<rawString>G. Attardi, F. Dell’Orletta, M. Simi, A. Chanev and M. Ciaramita. 2007. Multilingual Dependency Parsing and Domain Adaptation using DeSR. In Proc. of the CoNLL Shared Task Session of EMNLP-CoNLL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Buchholz</author>
<author>E Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proc. of CoNLL,</booktitle>
<pages>149--164</pages>
<contexts>
<context position="4357" citStr="Buchholz &amp; Marsi, 2006" startWordPosition="700" endWordPosition="703">emma of the predicted grandparent and PHDEP is the predicted dependency label of the predicted head of a token to the predicted grandparent. so refers to a token on top of the stack, wz refers to word at the i-th relative position with respect to the current word and parsing direction. This feature model was used for all languages in our tests. We present experiments and comparative error analysis on three representative languages from the CoNLL 2007 shared task (Nivre at al., 2007): Italian, Czech and English. We also report an evaluation on all thirteen languages of the CoNLL-X shared task (Buchholz &amp; Marsi, 2006), for comparison with the results by Nivre and McDonald (2008). Table 2 shows the Labeled Attachment Score (LAS), for the Left-to-right parser (LR), Right-toLeft (RL), Reverse Revision parser (Rev2), linear parser combination (Comb) and MST parser combination (CombMST). Figure 1 and 2 present the accuracies of the LR and Rev2 parsers for English relative to the dependency length and the length of sentences, respectively. For Czech and Italian the RL parser achieves higher accuracy than the LR parser and the Rev2 parser even higher. The error analysis for Czech showed that the Rev2 parser impro</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>S. Buchholz and E. Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proc. of CoNLL, 149–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y J Chu</author>
<author>T H Liu</author>
</authors>
<title>On the shortest arborescence of a directed graph. Science Sinica(14),</title>
<date>1965</date>
<volume>1396</volume>
<pages>1400</pages>
<contexts>
<context position="1779" citStr="Chu &amp; Liu, 1965" startWordPosition="259" endWordPosition="262">res in a second parse, exploiting the complementary properties of graph-based parsers (Eisner, 1996; McDonald et al., 2005) and transition-based dependency parsers (Yamada &amp; Matsumoto, 2003; Nivre &amp; Scholz, 2004). Also our method uses input from a previous parser but only uses parsers of a single type, deterministic transition-based Shift/Reduce, maintaining an overall linear complexity. In fact both the ensemble parsers and the stacking solution of NivreMcDonald involve the computation of the maximum spanning tree (MST) of a graph, which require algorithms of quadratic time complexity (e.g. (Chu &amp; Liu, 1965; Edmonds, 1967)). We introduce an alternative linear combination method. The algorithm is greedy and works by combining the trees top down. We tested it on the dependency trees produced by three parsers, a Leftto-Right (LR), a Right-to-Left (RL) and a stacked Right-to-Left parser, or Reverse Revision parser (Rev2). 1 The experiments show that in practice its output often outperforms the results produced by calculating the MST. 2 Experiments In the reported experiments we used DeSR (Attardi at al., 2007), a freely available implementation of a transition-based parser. The parser processes inpu</context>
</contexts>
<marker>Chu, Liu, 1965</marker>
<rawString>Y. J. Chu and T. H. Liu. 1965. On the shortest arborescence of a directed graph. Science Sinica(14), 1396– 1400.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Edmonds</author>
</authors>
<title>Optimum branchings.</title>
<date>1967</date>
<journal>Journal of Research of the National Bureau of Standards</journal>
<volume>71</volume>
<pages>233--240</pages>
<contexts>
<context position="1795" citStr="Edmonds, 1967" startWordPosition="263" endWordPosition="264">arse, exploiting the complementary properties of graph-based parsers (Eisner, 1996; McDonald et al., 2005) and transition-based dependency parsers (Yamada &amp; Matsumoto, 2003; Nivre &amp; Scholz, 2004). Also our method uses input from a previous parser but only uses parsers of a single type, deterministic transition-based Shift/Reduce, maintaining an overall linear complexity. In fact both the ensemble parsers and the stacking solution of NivreMcDonald involve the computation of the maximum spanning tree (MST) of a graph, which require algorithms of quadratic time complexity (e.g. (Chu &amp; Liu, 1965; Edmonds, 1967)). We introduce an alternative linear combination method. The algorithm is greedy and works by combining the trees top down. We tested it on the dependency trees produced by three parsers, a Leftto-Right (LR), a Right-to-Left (RL) and a stacked Right-to-Left parser, or Reverse Revision parser (Rev2). 1 The experiments show that in practice its output often outperforms the results produced by calculating the MST. 2 Experiments In the reported experiments we used DeSR (Attardi at al., 2007), a freely available implementation of a transition-based parser. The parser processes input tokens advanci</context>
</contexts>
<marker>Edmonds, 1967</marker>
<rawString>J. Edmonds. 1967. Optimum branchings. Journal of Research of the National Bureau of Standards (71B), 233–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: An exploration.</title>
<date>1996</date>
<booktitle>In Proc. of COLING</booktitle>
<pages>340--345</pages>
<contexts>
<context position="1263" citStr="Eisner, 1996" startWordPosition="179" endWordPosition="180"> these errors, although maintaining a quasi linear complexity. The method consists in two steps: first the sentence is parsed by a deterministic Shift/Reduce parser, then a second deterministic Shift/Reduce parser analyzes the sentence in reverse using additional features extracted from the parse trees produced by the first parser. Right-to-left parsing has been used as part of ensemble-based parsers (Sagae &amp; Lavie, 2006; Hall et al., 2007). Nivre and McDonald (2008) instead use hints from one parse as features in a second parse, exploiting the complementary properties of graph-based parsers (Eisner, 1996; McDonald et al., 2005) and transition-based dependency parsers (Yamada &amp; Matsumoto, 2003; Nivre &amp; Scholz, 2004). Also our method uses input from a previous parser but only uses parsers of a single type, deterministic transition-based Shift/Reduce, maintaining an overall linear complexity. In fact both the ensemble parsers and the stacking solution of NivreMcDonald involve the computation of the maximum spanning tree (MST) of a graph, which require algorithms of quadratic time complexity (e.g. (Chu &amp; Liu, 1965; Edmonds, 1967)). We introduce an alternative linear combination method. The algori</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>J. M. Eisner. 1996. Three new probabilistic models for dependency parsing: An exploration. In Proc. of COLING 1996, 340–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hall</author>
</authors>
<title>Single Malt or Blended? A Study in Multilingual Parser Optimization.</title>
<date>2007</date>
<booktitle>In Proc. of the CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<marker>Hall, 2007</marker>
<rawString>J. Hall, et al. 2007. Single Malt or Blended? A Study in Multilingual Parser Optimization. In Proc. of the CoNLL Shared Task Session of EMNLP-CoNLL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>J Nivre</author>
</authors>
<title>Characterizing the Errors of Data-Driven Dependency Parsing Models In</title>
<date>2007</date>
<booktitle>Proc. of EMNLP-CoNLL</booktitle>
<marker>McDonald, Nivre, 2007</marker>
<rawString>R. McDonald and J. Nivre. 2007. Characterizing the Errors of Data-Driven Dependency Parsing Models In Proc. of EMNLP-CoNLL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
<author>K Ribarov</author>
<author>J Haji˘c</author>
</authors>
<title>Non-projective Dependency Parsing using Spanning Tree Algorithms.</title>
<date>2005</date>
<booktitle>In Proc. of HLT-EMNLP</booktitle>
<marker>McDonald, Pereira, Ribarov, Haji˘c, 2005</marker>
<rawString>R. McDonald, F. Pereira, K. Ribarov and J. Haji˘c. 2005. Non-projective Dependency Parsing using Spanning Tree Algorithms. In Proc. of HLT-EMNLP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
</authors>
<title>Online Learning of Approximate Dependency Parsing Algorithms.</title>
<date>2006</date>
<booktitle>In Proc. of EACL</booktitle>
<marker>McDonald, Pereira, 2006</marker>
<rawString>R. McDonald and F. Pereira. 2006. Online Learning of Approximate Dependency Parsing Algorithms. In Proc. of EACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In Proc. of the CoNLL Shared Task Session of EMNLP/CoNLL-2007.</booktitle>
<marker>Nivre, 2007</marker>
<rawString>J. Nivre, et al. 2007. The CoNLL 2007 Shared Task on Dependency Parsing. In Proc. of the CoNLL Shared Task Session of EMNLP/CoNLL-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>R McDonald</author>
</authors>
<title>Integrating GraphBased and Transition-Based Dependency Parsers.</title>
<date>2008</date>
<booktitle>In Proc. of ACL</booktitle>
<contexts>
<context position="1122" citStr="Nivre and McDonald (2008)" startWordPosition="156" endWordPosition="159">y using a beam search instead of a greedy algorithm for predicting the next parser transition. We propose a parsing method that allows reducing several of these errors, although maintaining a quasi linear complexity. The method consists in two steps: first the sentence is parsed by a deterministic Shift/Reduce parser, then a second deterministic Shift/Reduce parser analyzes the sentence in reverse using additional features extracted from the parse trees produced by the first parser. Right-to-left parsing has been used as part of ensemble-based parsers (Sagae &amp; Lavie, 2006; Hall et al., 2007). Nivre and McDonald (2008) instead use hints from one parse as features in a second parse, exploiting the complementary properties of graph-based parsers (Eisner, 1996; McDonald et al., 2005) and transition-based dependency parsers (Yamada &amp; Matsumoto, 2003; Nivre &amp; Scholz, 2004). Also our method uses input from a previous parser but only uses parsers of a single type, deterministic transition-based Shift/Reduce, maintaining an overall linear complexity. In fact both the ensemble parsers and the stacking solution of NivreMcDonald involve the computation of the maximum spanning tree (MST) of a graph, which require algor</context>
<context position="4419" citStr="Nivre and McDonald (2008)" startWordPosition="710" endWordPosition="713"> dependency label of the predicted head of a token to the predicted grandparent. so refers to a token on top of the stack, wz refers to word at the i-th relative position with respect to the current word and parsing direction. This feature model was used for all languages in our tests. We present experiments and comparative error analysis on three representative languages from the CoNLL 2007 shared task (Nivre at al., 2007): Italian, Czech and English. We also report an evaluation on all thirteen languages of the CoNLL-X shared task (Buchholz &amp; Marsi, 2006), for comparison with the results by Nivre and McDonald (2008). Table 2 shows the Labeled Attachment Score (LAS), for the Left-to-right parser (LR), Right-toLeft (RL), Reverse Revision parser (Rev2), linear parser combination (Comb) and MST parser combination (CombMST). Figure 1 and 2 present the accuracies of the LR and Rev2 parsers for English relative to the dependency length and the length of sentences, respectively. For Czech and Italian the RL parser achieves higher accuracy than the LR parser and the Rev2 parser even higher. The error analysis for Czech showed that the Rev2 parser improves over the LR parser everywhere except in the Recall for dep</context>
</contexts>
<marker>Nivre, McDonald, 2008</marker>
<rawString>J. Nivre and R. McDonald. 2008. Integrating GraphBased and Transition-Based Dependency Parsers. In Proc. of ACL 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>M Scholz</author>
</authors>
<title>Deterministic Dependency Parsing of English Text.</title>
<date>2004</date>
<booktitle>In Proc. of COLING 2004. K. Sagae</booktitle>
<contexts>
<context position="1376" citStr="Nivre &amp; Scholz, 2004" startWordPosition="194" endWordPosition="197">he sentence is parsed by a deterministic Shift/Reduce parser, then a second deterministic Shift/Reduce parser analyzes the sentence in reverse using additional features extracted from the parse trees produced by the first parser. Right-to-left parsing has been used as part of ensemble-based parsers (Sagae &amp; Lavie, 2006; Hall et al., 2007). Nivre and McDonald (2008) instead use hints from one parse as features in a second parse, exploiting the complementary properties of graph-based parsers (Eisner, 1996; McDonald et al., 2005) and transition-based dependency parsers (Yamada &amp; Matsumoto, 2003; Nivre &amp; Scholz, 2004). Also our method uses input from a previous parser but only uses parsers of a single type, deterministic transition-based Shift/Reduce, maintaining an overall linear complexity. In fact both the ensemble parsers and the stacking solution of NivreMcDonald involve the computation of the maximum spanning tree (MST) of a graph, which require algorithms of quadratic time complexity (e.g. (Chu &amp; Liu, 1965; Edmonds, 1967)). We introduce an alternative linear combination method. The algorithm is greedy and works by combining the trees top down. We tested it on the dependency trees produced by three p</context>
</contexts>
<marker>Nivre, Scholz, 2004</marker>
<rawString>J. Nivre and M. Scholz. 2004. Deterministic Dependency Parsing of English Text. In Proc. of COLING 2004. K. Sagae and A. Lavie. 2006. Parser Combination by Reparsing. In Proc. of HLT-NAACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>J Henderson</author>
</authors>
<title>Fast and Robust Multilingual Dependency Parsing with a Generative Latent Variable Model</title>
<date>2007</date>
<booktitle>In Proc. of the CoNLL Shared Task Session of EMNLP/CoNNL-2007.</booktitle>
<marker>Titov, Henderson, 2007</marker>
<rawString>I. Titov and J. Henderson. 2007. Fast and Robust Multilingual Dependency Parsing with a Generative Latent Variable Model In Proc. of the CoNLL Shared Task Session of EMNLP/CoNNL-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yamada</author>
<author>Y Matsumoto</author>
</authors>
<title>Statistical dependency analysis using support vector machines.</title>
<date>2003</date>
<booktitle>In Proc. of the 8th IWPT.</booktitle>
<location>Nancy, France.</location>
<contexts>
<context position="1353" citStr="Yamada &amp; Matsumoto, 2003" startWordPosition="189" endWordPosition="193">ists in two steps: first the sentence is parsed by a deterministic Shift/Reduce parser, then a second deterministic Shift/Reduce parser analyzes the sentence in reverse using additional features extracted from the parse trees produced by the first parser. Right-to-left parsing has been used as part of ensemble-based parsers (Sagae &amp; Lavie, 2006; Hall et al., 2007). Nivre and McDonald (2008) instead use hints from one parse as features in a second parse, exploiting the complementary properties of graph-based parsers (Eisner, 1996; McDonald et al., 2005) and transition-based dependency parsers (Yamada &amp; Matsumoto, 2003; Nivre &amp; Scholz, 2004). Also our method uses input from a previous parser but only uses parsers of a single type, deterministic transition-based Shift/Reduce, maintaining an overall linear complexity. In fact both the ensemble parsers and the stacking solution of NivreMcDonald involve the computation of the maximum spanning tree (MST) of a graph, which require algorithms of quadratic time complexity (e.g. (Chu &amp; Liu, 1965; Edmonds, 1967)). We introduce an alternative linear combination method. The algorithm is greedy and works by combining the trees top down. We tested it on the dependency tr</context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>H. Yamada and Y. Matsumoto. 2003. Statistical dependency analysis using support vector machines. In Proc. of the 8th IWPT. Nancy, France.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>