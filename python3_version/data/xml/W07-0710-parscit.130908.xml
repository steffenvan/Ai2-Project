<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.988119">
Training Non-Parametric Features for Statistical Machine Translation
</title>
<author confidence="0.998762">
Patrick Nguyen, Milind Mahajan and Xiaodong He
</author>
<affiliation confidence="0.868044">
Microsoft Corporation
1 Microsoft Way,
</affiliation>
<address confidence="0.97103">
Redmond, WA 98052
</address>
<email confidence="0.998766">
{panguyen,milindm,xiaohe}@microsoft.com
</email>
<sectionHeader confidence="0.998596" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99986305882353">
Modern statistical machine translation sys-
tems may be seen as using two components:
feature extraction, that summarizes informa-
tion about the translation, and a log-linear
framework to combine features. In this pa-
per, we propose to relax the linearity con-
straints on the combination, and hence relax-
ing constraints of monotonicity and indepen-
dence of feature functions. We expand fea-
tures into a non-parametric, non-linear, and
high-dimensional space. We extend empir-
ical Bayes reward training of model param-
eters to meta parameters of feature genera-
tion. In effect, this allows us to trade away
some human expert feature design for data.
Preliminary results on a standard task show
an encouraging improvement.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999950076923077">
In recent years, statistical machine translation have
experienced a quantum leap in quality thanks to au-
tomatic evaluation (Papineni et al., 2002) and error-
based optimization (Och, 2003). The conditional
log-linear feature combination framework (Berger,
Della Pietra and Della Pietra, 1996) is remarkably
simple and effective in practice. Therefore, re-
cent efforts (Och et al., 2004) have concentrated on
feature design – wherein more intelligent features
may be added. Because of their simplicity, how-
ever, log-linear models impose some constraints on
how new information may be inserted into the sys-
tem to achieve the best results. In other words,
</bodyText>
<page confidence="0.974383">
72
</page>
<bodyText confidence="0.99979525">
new information needs to be parameterized care-
fully into one or more real valued feature functions.
Therefore, that requires some human knowledge and
understanding. When not readily available, this
is typically replaced with painstaking experimenta-
tion. We propose to replace that step with automatic
training of non-parametric agnostic features instead,
hopefully relieving the burden of finding the optimal
parameterization.
First, we define the model and the objective func-
tion training framework, then we describe our new
non-parametric features.
</bodyText>
<sectionHeader confidence="0.996122" genericHeader="introduction">
2 Model
</sectionHeader>
<bodyText confidence="0.999690571428571">
In this section, we describe the general log-linear
model used for statistical machine translation, as
well as a training objective function and algorithm.
The goal is to translate a French (source) sentence
indexed by t, with surface string ft. Among a set of
Kt outcomes, we denote an English (target) a hy-
pothesis with surface string e(kt) indexed by k.
</bodyText>
<sectionHeader confidence="0.905166" genericHeader="method">
2.1 Log-linear Model
</sectionHeader>
<bodyText confidence="0.8642304">
The prevalent translation model in modern systems
is a conditional log-linear model (Och and Ney,
2002). From a hypothesis e(t)
k , we extract features
h(t)
k , abbreviated hk, as a function of e(t)
k and ft. The
conditional probability of a hypothesis e(t)
k given a
source sentence ft is:
</bodyText>
<equation confidence="0.7798745">
pk p(e(t)
k |ft) ° exp[A - hk] �
</equation>
<page confidence="0.325323">
Zft;λ
</page>
<note confidence="0.8599085">
Proceedings of the Second Workshop on Statistical Machine Translation, pages 72–79,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.993474">
where the partition function Zft;λ is given by:
</bodyText>
<equation confidence="0.6974595">
XZft;λ = exp[λ · hj].
j
</equation>
<bodyText confidence="0.995827666666667">
The vector of parameters of the model λ, gives a
relative importance to each feature function compo-
nent.
</bodyText>
<subsectionHeader confidence="0.997608">
2.2 Training Criteria
</subsectionHeader>
<bodyText confidence="0.99961725">
In this section, we quickly review how to adjust λ
to get better translation results. First, let us define
the figure of merit used for evaluation of translation
quality.
</bodyText>
<subsubsectionHeader confidence="0.613018">
2.2.1 BLEU Evaluation
</subsubsectionHeader>
<bodyText confidence="0.999938666666667">
The BLEU score (Papineni et al., 2002) was de-
fined to measure overlap between a hypothesized
translation and a set of human references. n-gram
overlap counts {cn}4n=1 are computed over the test
set sentences, and compared to the total counts of
n-grams in the hypothesis:
</bodyText>
<equation confidence="0.9253925">
cn,(t) k, max. # of matching n-grams for hyp. e(t)
k ,
</equation>
<bodyText confidence="0.999389222222222">
Oracle BLEU hypothesis: There is no easy way
to pick the set hypotheses from an n-best list that
will maximize the overall BLEU score. Instead, to
compute oracle BLEU hypotheses, we chose, for
each sentence independently, the hypothesis with the
highest BLEU score computed for a sentence itself.
We believe that it is a relatively tight lower bound
and equal for practical purposes to the true oracle
BLEU.
</bodyText>
<subsectionHeader confidence="0.896968">
2.2.2 Maximum Likelihood
</subsectionHeader>
<bodyText confidence="0.9995683">
Used in earlier models (Och and Ney, 2002), the
likelihood criterion is defined as the likelihood of an
oracle hypothesis e(t)
k� , typically a single reference
translation, or alternatively the closest match which
was decoded. When the model is correct and infi-
nite amounts of data are available, this method will
converge to the Bayes error (minimum achievable
error), where we define a classification task of se-
lecting k* against all others.
</bodyText>
<subsectionHeader confidence="0.778055">
2.2.3 Regularization Schemes
</subsectionHeader>
<bodyText confidence="0.996415">
One can convert a maximum likelihood problem
into maximum a posteriori using Bayes’ rule:
</bodyText>
<equation confidence="0.725437">
an,(t) k, # of n-grams in hypothesis e(t) Yarg max p(λ |{e(kt), ft }) = arg max Y pkp0(λ),
k . λ t λ t
</equation>
<bodyText confidence="0.999517666666667">
Those quantities are abbreviated ck and ak to sim-
plify the notation. The precision ratio Pn for an n-
gram order n is:
</bodyText>
<equation confidence="0.9909198">
A Pn,(t)
t ck
Pn n, (t)
P.
t ak
</equation>
<bodyText confidence="0.9876916">
A brevity penalty BP is also taken into account, to
avoid favoring overly short sentences:
where r is the average length of the shortest sen-
tence1, and a is the average length of hypotheses.
The BLEU score the set of hypotheses {e(t)
</bodyText>
<equation confidence="0.967864">
k } is:
� X4 �
1
B({e(t)
k }) , BP · exp 4 log Pn .
n=1
</equation>
<footnote confidence="0.68859">
1As implemented by NIST mteval-v11b.pl.
</footnote>
<bodyText confidence="0.999041">
where p0(·) is the prior distribution of λ. The
most frequently used prior in practice is the normal
prior (Chen and Rosenfeld, 2000):
</bodyText>
<equation confidence="0.9453575">
log p0(λ) , −||λ||2
2σ2 − log |σ|,
</equation>
<bodyText confidence="0.9999255">
where σ2 &gt; 0 is the variance. It can be thought of
as the inverse of a Lagrange multiplier when work-
ing with constrained optimization on the Euclidean
norm of λ. When not interpolated with the likeli-
hood, the prior can be thought of as a penalty term.
The entropy penalty may also be used:
</bodyText>
<equation confidence="0.912788">
H , − 1
T
</equation>
<bodyText confidence="0.998572">
Unlike the Gaussian prior, the entropy is indepen-
dent of parameterization (i.e., it does not depend on
how features are expressed).
</bodyText>
<equation confidence="0.980868">
BP , min{1; exp(1 − r)}
,
a
XKt
k=1
pk log pk.
XT
t=1
</equation>
<page confidence="0.996138">
73
</page>
<subsectionHeader confidence="0.821913">
2.2.4 Minimum Error Rate Training
</subsectionHeader>
<bodyText confidence="0.999979538461538">
A good way of training λ is to minimize empirical
top-1 error on training data (Och, 2003). Compared
to maximum-likelihood, we now give partial credit
for sentences which are only partially correct. The
criterion is:
We optimize the λ so that the BLEU score of the
most likely hypotheses is improved. For that reason,
we call this criterion BLEU max. This function is
not convex and there is no known exact efficient op-
timization for it. However, there exists a linear-time
algorithm for exact line search against that objec-
tive. The method is often used in conjunction with
coordinate projection to great success.
</bodyText>
<subsectionHeader confidence="0.957448">
2.2.5 Maximum Empirical Bayes Reward
</subsectionHeader>
<bodyText confidence="0.983554565217391">
The algorithm may be improved by giving partial
credit for confidence pk of the model to partially cor-
rect hypotheses outside of the most likely hypothe-
sis (Smith and Eisner, 2006):
pk log B({ek(t)}).
Instead of the BLEU score, we use its logrithm, be-
cause we think it is exponentially hard to improve
BLEU. This model is equivalent to the previous
model when pk give all the probability mass to the
top-1. That can be reached, for instance, when λ
has a very large norm. There is no known method
to train against this objective directly, however, ef-
ficient approximations have been developed. Again,
it is not convex.
It is hoped that this criterion is better suited for
high-dimensional feature spaces. That is our main
motivation for using this objective function through-
out this paper. With baseline features and on our
data set, this criterion also seemed to lead to results
similar to Minimum Error Rate Training.
We can normalize B to a probability measure
b({e(kt) }). The empirical Bayes reward also coin-
cides with a divergence D(p||b).
</bodyText>
<subsectionHeader confidence="0.99906">
2.3 Training Algorithm
</subsectionHeader>
<bodyText confidence="0.999945333333333">
We train our model using a gradient ascent method
over an approximation of the empirical Bayes re-
ward function.
</bodyText>
<subsectionHeader confidence="0.886873">
2.3.1 Approximation
</subsectionHeader>
<bodyText confidence="0.9994715">
Because the empirical Bayes reward is defined
over a set of sentences, it may not be decomposed
sentence by sentence. This is computationally bur-
densome. Its sufficient statistics are r, Pt ck and
</bodyText>
<equation confidence="0.48093">
P
</equation>
<bodyText confidence="0.999601">
t ak. The function may be reconstructed in a first-
order approximation with respect to each of these
statistics. In practice this has the effect of commut-
ing the expectation inside of the functional, and for
that reason we call this criterion BLEUsoft. This ap-
proximation is called linearization (Smith and Eis-
ner, 2006). We used a first-order approximation for
speed, and ease of interpretation of the derivations.
The new objective function is:
</bodyText>
<equation confidence="0.949022">
PtEcn,(t)
k
log Pt Eak,(t),
</equation>
<bodyText confidence="0.8712645">
where the average bleu penalty is:
}.
</bodyText>
<equation confidence="0.6126855">
Ek,ta1,(t)
k
</equation>
<bodyText confidence="0.9994865">
The expectation is understood to be under the cur-
rent estimate of our log-linear model. Because �BP is
not differentiable, we replace the hard min function
with a sigmoid, yielding:
</bodyText>
<equation confidence="0.9689562">
!
log BP ≈ u(r − Ek,ta1,(t) 1 − r
k ) ,
Ek,ta1,(t)
k
</equation>
<bodyText confidence="0.8260355">
with the sigmoid function u(x) defines a soft step
function:
</bodyText>
<equation confidence="0.99967">
u(x) °= 1
1 + e−T2,
</equation>
<bodyText confidence="0.937315">
with a parameter τ ≫ 1.
</bodyText>
<subsectionHeader confidence="0.500741">
2.3.2 Gradients and Sufficient Statistics
</subsectionHeader>
<bodyText confidence="0.99592225">
We can obtain the gradients of the objective func-
tion using the chain rule by first differentiating with
respect to the probability. First, let us decompose
the log-precision of the expected counts:
</bodyText>
<equation confidence="0.737584333333333">
log Pn = log Ecn,(t)
k − log Ean,(t)
k .
</equation>
<figure confidence="0.983126857142857">
Xarg max B({e(t)
� t kˆ }) : e(t)
kˆ = arg max pj.
��t�
7
1
T
T
X
t=1
Kt
X
k=1
J °= log BP +
1
4
4
X
n=1
r
log BP °= min{0; 1 −
</figure>
<page confidence="0.973217">
74
</page>
<bodyText confidence="0.884487666666667">
Each n-gram precision may be treated separately.
For each n-gram order, let us define sufficient statis-
tics ψ for the precision:
</bodyText>
<equation confidence="0.9099874">
A-1:
co
t,k —
t,k (∇λpk)ck; ψa λ °= X (∇λpk)ak,
t,k
</equation>
<bodyText confidence="0.996933">
where the gradient of the probabilities is given by:
</bodyText>
<equation confidence="0.96075425">
∇λpk = pk(hk − h),
with:
h¯°= XKt pjhj.
j=1
</equation>
<bodyText confidence="0.824975">
The derivative of the precision ˜Pn is:
</bodyText>
<equation confidence="0.976789">
∇λlog ˜Pn = 1 − ψa
λ λ T Eck Eak
� ψc �
For the length, the derivative of log ¯BP is:
u(r−Ea) Ia( − 1) [1 − u(r − Ea)]τ + (Ea)2 J ψa,
</equation>
<bodyText confidence="0.998814">
where ψa, λis the 1-gram component of ψaλ. Finally,
the derivative of the entropy is:
</bodyText>
<equation confidence="0.987627">
X∇λH = (1 + log pk)∇λpk.
</equation>
<bodyText confidence="0.660922">
k,t
</bodyText>
<sectionHeader confidence="0.391857" genericHeader="method">
2.3.3 RProp
</sectionHeader>
<bodyText confidence="0.999036615384615">
For all our experiments, we chose RProp (Ried-
miller and Braun, 1992) as the gradient ascent al-
gorithm. Unlike other gradient algorithms, it is only
based on the sign of the gradient components at each
iteration. It is relatively robust to the objective func-
tion, requires little memory, does not require meta
parameters to be tuned, and is simple to implement.
On the other hand, it typically requires more iter-
ations than stochastic gradient (Kushner and Yin,
1997) or L-BFGS (Nocedal and Wright, 1999).
Using fairly conservative stopping criteria, we ob-
served that RProp was about 6 times faster than Min-
imum Error Rate Training.
</bodyText>
<sectionHeader confidence="0.981731" genericHeader="method">
3 Adding Features
</sectionHeader>
<bodyText confidence="0.999955578947368">
The log-linear model is relatively simple, and is usu-
ally found to yield good performance in practice.
With these considerations in mind, feature engineer-
ing is an active area of research (Och et al., 2004).
Because the model is fairly simple, some of the in-
telligence must be shifted to feature design. After
having decided what new information should go in
the overall score, there is an extra effort involved
in expressing or parameterizing features in a way
which will be easiest for the model learn. Experi-
mentation is usually required to find the best config-
uration.
By adding non-parametric features, we propose
to mitigate the parameterization problem. We will
not add new information, but rather, propose a way
to insulate research from the parameterization. The
system should perform equivalently invariant of any
continuous invertible transformation of the original
input.
</bodyText>
<subsectionHeader confidence="0.997148">
3.1 Existing Features
</subsectionHeader>
<bodyText confidence="0.9806175">
The baseline system is a syntax based machine
translation system as described in (Quirk, Menezes
and Cherry, 2005). Our existing feature set includes
11 features, among which the following:
</bodyText>
<listItem confidence="0.999963666666667">
• Target hypothesis word count.
• Treelet count used to construct the candidate.
• Target language models, based on the Giga-
word corpus (5-gram) and target side of parallel
training data (3-gram).
• Order models, which assign a probability to the
position of each target node relative to its head.
• Treelet translation model.
• Dependency-based bigram language models.
</listItem>
<subsectionHeader confidence="0.978572">
3.2 Re-ranking Framework
</subsectionHeader>
<bodyText confidence="0.999947909090909">
Our algorithm works in a re-ranking framework.
In particular, we are adding features which are not
causal or additive. Features for a hypothesis may
not be accumulating by looking at the English (tar-
get) surface string words from the left to the right
and adding a contribution per word. Word count,
for instance, is causal and additive. This property
is typically required for efficient first-pass decod-
ing. Instead, we look at a hypothesis sentence as a
whole. Furthermore, we assume that the Kt-best list
provided to us contains the entire probability space.
</bodyText>
<page confidence="0.997412">
75
</page>
<bodyText confidence="0.9999125">
In particular, the computation of the partition func-
tion is performed over all Kt-best hypotheses. This
is clearly not correct, and is the subject of further
study. We use the n-best generation scheme inter-
leaved with A optimization as described in (Och,
2003).
</bodyText>
<subsectionHeader confidence="0.999436">
3.3 Issues with Parameterization
</subsectionHeader>
<bodyText confidence="0.999598">
As alluded to earlier, when designing a new feature
in the log-linear model, one has to be careful to find
the best embodiment. In general, a set of features
must satisfy the following properties, ranked from
strict to lax:
</bodyText>
<listItem confidence="0.999765666666667">
• Linearity (warping)
• Monotonicity
• Independence (conjunction)
</listItem>
<bodyText confidence="0.999488176470588">
Firstly, a feature should be linearly correlated with
performance. There should be no region were it
matters less than other regions. For instance, in-
stead of a word count, one might consider adding
its logarithm instead. Secondly, the “goodness” of a
hypothesis associated with a feature must be mono-
tonic. For instance, using the signed difference be-
tween word count in the French (source) and En-
glish (target) does not satisfy this. (In that case, one
would use the absolute value instead.) Lastly, there
should be no inter-dependence between features. As
an example, we can consider adding multiple lan-
guage model scores. Whether we should consider
ratios those of, globally linearly or log-linearly in-
terpolating them, is open to debate. When features
interact across dimensions, it becomes unclear what
the best embodiment should be.
</bodyText>
<subsectionHeader confidence="0.793838">
3.4 Non-parametric Features
</subsectionHeader>
<bodyText confidence="0.999312">
A generic solution may be sought in non-parametric
processing. Our method can be derived from a quan-
tized Parzen estimate of the feature density function.
</bodyText>
<subsectionHeader confidence="0.857621">
3.4.1 Parzen Window
</subsectionHeader>
<bodyText confidence="0.999982">
The Parzen window is an early empirical kernel
method (Duda and Hart, 1973). For an observation
hm, we extrapolate probability mass around it with
a smoothing window 4b(·). The density function is:
</bodyText>
<equation confidence="0.995219333333333">
�K
1
p(h) = M
</equation>
<bodyText confidence="0.927128">
assuming 4b(·) is a density function. Parzen win-
dows converge to the true density estimate, albeit
slowly, under weak assumptions.
</bodyText>
<subsectionHeader confidence="0.830782">
3.4.2 Bin Features
</subsectionHeader>
<bodyText confidence="0.999979647058823">
One popular way of using continuous features in
log-linear models is to convert a single continuous
feature into multiple “bin” features. Each bin feature
is defined as the indicator function of whether the
original continuous feature was in a certain range.
The bins were selected so that each bin collects an
equal share of the probability mass. This is equiva-
lent to the maximum likelihood estimate of the den-
sity function subject to a fixed number of rectangular
density kernels. Since that mapping is not differen-
tiable with respect to the original features, one may
use sigmoids to soften the boundaries.
Bin features are useful to relax the requirements
of linearity and monotonicity. However, because
they work on each feature individually, they do not
address the problem of inter-dependence between
features.
</bodyText>
<subsectionHeader confidence="0.669267">
3.4.3 Gaussian Mixture Model Features
</subsectionHeader>
<bodyText confidence="0.999994555555556">
Bin features may be generalized to multi-
dimensional kernels by using a Gaussian smoothing
window instead of a rectangular window. The direct
analogy is vector quantization. The idea is to weight
specific regions of the feature space differently. As-
suming that we have M Gaussians each with mean
vector µm and diagonal covariance matrix Cm, and
prior weight wm. We will add m new features, each
defined as the posterior in the mixture model:
</bodyText>
<equation confidence="0.65012">
0 wmN(hi µm, Cm)
</equation>
<bodyText confidence="0.914601928571429">
hm Er wrN(hi µr, Cr).
It is believed that any reasonable choice of kernels
will yield roughly equivalent results (Povey et al.,
2004), if the amount of training data and the number
of kernels are both sufficiently large. We show two
methods for obtaining clusters. In contrast with bins,
lossless representation becomes rapidly impossible.
ML kernels: The canonical way of obtaining clus-
ter is to use the standard Gaussian mixture training.
First, a single Gaussian is trained on the whole data
set. Then, the Gaussian is split into two Gaussians,
with each mean vector perturbed, and the Gaus-
sians are retrained using maximum-likelihood in an
-b(h − hm),
</bodyText>
<page confidence="0.9305175">
m=1
76
</page>
<bodyText confidence="0.998798666666667">
expectation-maximization framework (Rabiner and
Huang, 1993). The number of Gaussians is typically
increased exponentially.
Perceptron kernels: We also experimented with
another quicker way of obtaining kernels. We
chose an equal prior and a global covariance matrix.
Means were obtained as follows: for each sentence
in the training set, if the top-1 candidate was differ-
ent from the approximate maximum oracle BLEU
hypothesis, both were inserted. It is a quick way
to bootstrap and may reach the oracle BLEU score
quickly.
In the limit, GMMs will converge to the oracle
BLEU. In the next section, we show how to re-
estimate these kernels if needed.
</bodyText>
<subsectionHeader confidence="0.989074">
3.5 Re-estimation Formulæ
</subsectionHeader>
<bodyText confidence="0.9998645">
Features may also be trained using the same empir-
ical maximum Bayes reward. Let θ be the hyper-
parameter vector used to generate features. In the
case of language models, for instance, this could be
backoff weights. Let us further assume that the fea-
ture values are differentiable with respect to θ. Gra-
dient ascent may be applied again but this time with
respect to θ. Using the chain rule:
</bodyText>
<equation confidence="0.700792">
VeJ = (Veh)(Vhpk)(VpkJ),
</equation>
<bodyText confidence="0.9997265">
with Vhpk = pk(1 − pk)λ. Let us take the example
of re-estimating the mean of a Gaussian kernel µm:
</bodyText>
<equation confidence="0.978597">
VAMhm = −wmhm(1 − hm)C�1
m (µm − h),
for its own feature, and for other posteriors r =� m:
VAMhr = −wrhrhmC�1
m (µm − h),
</equation>
<bodyText confidence="0.9992135">
which is typically close to zero if no two Gaussians
fire simultaneously.
</bodyText>
<sectionHeader confidence="0.994496" genericHeader="evaluation">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.990151">
For our experiments, we used the standard NIST
MT-02 data set to evaluate our system.
</bodyText>
<subsectionHeader confidence="0.994525">
4.1 NIST System
</subsectionHeader>
<bodyText confidence="0.999941636363637">
A relatively simple baseline was used for our exper-
iments. The system is syntactically-driven (Quirk,
Menezes and Cherry, 2005). The system was trained
on 175k sentences which were selected from the
NIST training data (NIST, 2006) to cover words in
source language sentences of the MT02 develop-
ment and evaluation sets. The 5-gram target lan-
guage model was trained on the Gigaword mono-
lingual data using absolute discounting smoothing.
In a single decoding, the system generated 1000 hy-
potheses per sentence whenever possible.
</bodyText>
<subsectionHeader confidence="0.996401">
4.2 Leave-one-out Training
</subsectionHeader>
<bodyText confidence="0.999978928571429">
In order to have enough data for training, we gen-
erated our n-best lists using 10-fold leave-one-out
training: base feature extraction models were trained
on 9/10th of the data, then used for decoding the
held-out set. The process was repeated for all 10
parts. A single λ was then optimized on the com-
bined lists of all systems. That λ was used for an-
other round of 10 decodings. The process was re-
peated until it reached convergence after 7 iterations.
Each decoding generated about 100 hypotheses, and
there was relatively little overlap across decodings.
Therefore, there were about 1M hypotheses in total.
The combined list of all iterations was used for all
subsequent experiments of feature expansion.
</bodyText>
<subsectionHeader confidence="0.999204">
4.3 BLEU Training Results
</subsectionHeader>
<bodyText confidence="0.9999515">
We tried training systems under the empirical Bayes
reward criterion, and appending either bin or GMM
features. We will find that bin features are es-
sentially ineffective while GMM features show a
modest improvement. We did not retrain hyper-
parameters.
</bodyText>
<subsectionHeader confidence="0.94658">
4.3.1 Convexity of the Empirical Bayes Reward
</subsectionHeader>
<bodyText confidence="0.999949714285714">
The first question to ask is how many local op-
tima does the cost surface have using the standard
features. A complex cost surface indicates that some
gain may be had with non-linear features, but it also
shows that special care should be taken during op-
timization. Non-convexity is revealed by sensitivity
to initialization points. Thus, we decided to initial-
ize from all vertices of the unit hypercube, and since
we had 11 features, we ran 211 experiments. The
histogram of BLEU scores on dev data after conver-
gence is shown on Figure 1. We also plotted the his-
togram of an example dimension in Figure 2. The
range of BLEU scores and lambdas is reasonably
narrow. Even though λ seems to be bimodal, we see
</bodyText>
<page confidence="0.994983">
77
</page>
<bodyText confidence="0.99816425">
that this does not seriously affect the BLEU score.
This is not definitive evidence but we provisionally
pretend that the cost surface is almost convex for
practical purposes.
</bodyText>
<figure confidence="0.979867428571429">
800
number of trained models 600
400
200
0
24.8 24.9 25 25.1 25.2 25.3 25.4
BLEU score
</figure>
<figureCaption confidence="0.9978125">
Figure 1: Histogram of BLEU scores after training
from 211 initializations.
</figureCaption>
<bodyText confidence="0.995415875">
bins and re-trained. On Figure 3, we show that relax-
ing the monotonicity constraint leads to rough val-
ues for A. Surprisingly, the BLEU score and ob-
jective on the training set only increases marginally.
Starting from A = 0, we obtained nearly exactly the
same training objective value. By varying the num-
ber of bins (20-50), we observed similar behavior as
well.
</bodyText>
<figure confidence="0.998623363636364">
0 10 20 30 40 50
original weights
trained weights
value 1
0.5
0
−0.5
−1
−1.5
bin id
λ value
</figure>
<figureCaption confidence="0.9945585">
Figure 2: Histogram of one A parameter after train-
ing from 211 initializations.
</figureCaption>
<subsectionHeader confidence="0.714615">
4.3.2 Bin Features
</subsectionHeader>
<bodyText confidence="0.999773444444444">
A log-linear model can be converted into a bin
feature model nearly exactly by setting A values
in such a way that scores will be equal. Equiva-
lent weights (marked as ‘original’ in Figure 3) have
the shape of an error function (erf): this is because
the input feature is a cummulative random variable,
which quickly converges to a Gaussian (by the cen-
tral limit theorem). After training the A weights for
the log-linear model, weights may be converted into
</bodyText>
<figureCaption confidence="0.66449">
Figure 3: Values before and after training bin fea-
tures. Monotonicity constraint has been relaxed.
BLEU score is virtually unchanged.
</figureCaption>
<subsubsectionHeader confidence="0.597786">
4.3.3 GMM Features
</subsubsectionHeader>
<bodyText confidence="0.999984142857143">
Experiments were carried out with GMM fea-
tures. The summary is shown on Table 1. The
baseline was the log-linear model trained with the
baseline features. The baseline features are included
in all systems. We trained GMM models using the
iterative mixture splitting interleaved with EM re-
estimation, split up to 1024 and 16384 Gaussians,
which we call GMM-ML-1k and GMM-ML-16k re-
spectively. We also used the “perceptron” selec-
tion features on the training set to bootstrap quickly
to 300k Gaussians (GMM-PCP-300k), and ran the
same algorithm on the development set (GMM-
PCP-2k). Therefore, GMM-PCP-300k had 300k
features, and was trained on 175k sentences (each
with about 700 hypotheses). For all experiments but
“unreg” (unregularized), we chose a prior Gaussian
prior with variance empirically by looking at the de-
velopment set. For all but GMM-PCP-300k, regu-
larization did not seem to have a noticeably positive
effect on development BLEU scores. All systems
were seeded with the baseline log-linear model, and
</bodyText>
<figure confidence="0.9961766">
−60 −40 −20 0
number of trained models
400
700
600
500
300
200
100
0
</figure>
<page confidence="0.99215">
78
</page>
<bodyText confidence="0.9993033">
all additional weights set to zero, and then trained
with about 50 iterations, but convergence in BLEU
score, empirical reward, and development BLEU
score occurred after about 30 iterations. In that set-
ting, we found that regularized empirical Bayes re-
ward, BLEU score on training data, and BLEU score
on development and evaluation to be well corre-
lated. Cursory experiments revealed that using mul-
tiple initializations did not significantly alter the fi-
nal BLEU score.
</bodyText>
<table confidence="0.970004375">
System Train Dev Eval
Oracle 14.10 N/A N/A
Baseline 10.95 35.15 25.95
GMM-ML-1k 10.95 35.15 25.95
GMM-ML-16k 11.09 35.25 25.89
GMM-PCP-2k 10.95 35.15 25.95
GMM-PCP-300k-unreg 13.00 N/A N/A
GMM-PCP-300k 12.11 35.74 26.42
</table>
<tableCaption confidence="0.986797">
Table 1: BLEU scores for GMM features vs the lin-
</tableCaption>
<bodyText confidence="0.971131909090909">
ear baseline, using different selection methods and
number of kernels.
Perceptron kernels based on the training set im-
proved the baseline by 0.5 BLEU points. We mea-
sured significance with the Wilcoxon signed rank
test, by batching 10 sentences at a time to produce
an observation. The difference was found to be sig-
nificant at a 0.9-confidence level. The improvement
may be limited due to local optima or the fact that
original feature are well-suited for log-linear mod-
els.
</bodyText>
<sectionHeader confidence="0.999597" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999628125">
In this paper, we have introduced a non-parametric
feature expansion, which guarantees invariance to
the specific embodiment of the original features.
Feature generation models, including feature ex-
pansion, may be trained using maximum regular-
ized empirical Bayes reward. This may be used as
an end-to-end framework to train all parameters of
the machine translation system. Experimentally, we
found that Gaussian mixture model (GMM) features
yielded a 0.5 BLEU improvement.
Although this is an encouraging result, further
study is required on hyper-parameter re-estimation,
presence of local optima, use of complex original
features to test the effectiveness of the parameteri-
zation invariance, and evaluation on a more compet-
itive baseline.
</bodyText>
<sectionHeader confidence="0.998457" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999706880952381">
K. Papineni, S. Roukos, T. Ward, W.-J. Zhu. 2002.
BLEU: a methodfor automatic evaluation of machine
translation. ACL’02.
A. Berger, S. Della Pietra, and V. Della Pietra. 1996.
A Maximum Entropy Approach to Natural Language
Processing. Computational Linguistics, vol 22:1, pp.
39–71.
S. Chen and R. Rosenfeld. 2000. A survey of smoothing
techniquesforME models. IEEE Trans. on Speech and
Audio Processing, vol 8:2, pp. 37–50.
R. O. Duda and P. E. Hart. 1973. Pattern Classification
and Scene Analysis. Wiley &amp; Sons, 1973.
H. J. Kushner and G. G. Yin. 1997. Stochastic Approxi-
mation Algorithms and Applications. Springer-Verlag,
1997.
National Institute of Standards and Technology. 2006.
The 2006 Machine Translation Evaluation Plan.
J. Nocedal and S. J. Wright. 1999. Numerical Optimiza-
tion. Springer-Verlag, 1999.
F. J. Och. 2003. Minimum Error Rate Training in Statis-
tical Machine Translation. ACL’03.
F. J. Och, D. Gildea, S. Khudanpur, A. Sarkar, K. Ya-
mada, A. Fraser, S. Kumar, L. Shen, D. Smith, K. Eng,
V. Jain, Z. Jin, and D. Radev. 2004. A Smorgas-
bord of Features for Statistical Machine Translation.
HLT/NAACL’04.
F. J. Och and H. Ney. 2002. Discriminative Training
and Maximum Entropy Models for Statistical Machine
Translation. ACL’02.
D. Povey, B. Kingsbury, L. Mangu, G. Saon, H. Soltau
and G. Zweig. 2004. fMPE: Discriminatively trained
features for speech recognition. RT’04 Meeting.
C. Quirk, A. Menezes and C. Cherry. 2005. De-
pendency Tree Translation: Syntactically Informed
Phrasal SMT. ACL’05.
L. R. Rabiner and B.-H. Huang. 1993. Fundamentals of
Speech Recognition. Prentice Hall.
M. Riedmiller and H. Braun. 1992. RPROP: A Fast
Adaptive Learning Algorithm. Proc. of ISCIS VII.
D. A. Smith and J. Eisner. 2006. Minimum-Risk
Annealing for Training Log-Linear Models. ACL-
COLING’06.
</reference>
<page confidence="0.999041">
79
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.579315">
<title confidence="0.999951">Training Non-Parametric Features for Statistical Machine Translation</title>
<author confidence="0.926006">Patrick Nguyen</author>
<author confidence="0.926006">Milind Mahajan</author>
<author confidence="0.926006">Xiaodong</author>
<affiliation confidence="0.7676455">Microsoft 1 Microsoft</affiliation>
<address confidence="0.974355">Redmond, WA</address>
<abstract confidence="0.999644055555556">Modern statistical machine translation systems may be seen as using two components: feature extraction, that summarizes information about the translation, and a log-linear framework to combine features. In this paper, we propose to relax the linearity constraints on the combination, and hence relaxing constraints of monotonicity and independence of feature functions. We expand features into a non-parametric, non-linear, and high-dimensional space. We extend empirical Bayes reward training of model parameters to meta parameters of feature generation. In effect, this allows us to trade away some human expert feature design for data. Preliminary results on a standard task show an encouraging improvement.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W-J Zhu</author>
</authors>
<title>BLEU: a methodfor automatic evaluation of machine translation.</title>
<date>2002</date>
<pages>02</pages>
<contexts>
<context position="1094" citStr="Papineni et al., 2002" startWordPosition="155" endWordPosition="158">y constraints on the combination, and hence relaxing constraints of monotonicity and independence of feature functions. We expand features into a non-parametric, non-linear, and high-dimensional space. We extend empirical Bayes reward training of model parameters to meta parameters of feature generation. In effect, this allows us to trade away some human expert feature design for data. Preliminary results on a standard task show an encouraging improvement. 1 Introduction In recent years, statistical machine translation have experienced a quantum leap in quality thanks to automatic evaluation (Papineni et al., 2002) and errorbased optimization (Och, 2003). The conditional log-linear feature combination framework (Berger, Della Pietra and Della Pietra, 1996) is remarkably simple and effective in practice. Therefore, recent efforts (Och et al., 2004) have concentrated on feature design – wherein more intelligent features may be added. Because of their simplicity, however, log-linear models impose some constraints on how new information may be inserted into the system to achieve the best results. In other words, 72 new information needs to be parameterized carefully into one or more real valued feature func</context>
<context position="3450" citStr="Papineni et al., 2002" startWordPosition="531" endWordPosition="534"> pk p(e(t) k |ft) ° exp[A - hk] � Zft;λ Proceedings of the Second Workshop on Statistical Machine Translation, pages 72–79, Prague, June 2007. c�2007 Association for Computational Linguistics where the partition function Zft;λ is given by: XZft;λ = exp[λ · hj]. j The vector of parameters of the model λ, gives a relative importance to each feature function component. 2.2 Training Criteria In this section, we quickly review how to adjust λ to get better translation results. First, let us define the figure of merit used for evaluation of translation quality. 2.2.1 BLEU Evaluation The BLEU score (Papineni et al., 2002) was defined to measure overlap between a hypothesized translation and a set of human references. n-gram overlap counts {cn}4n=1 are computed over the test set sentences, and compared to the total counts of n-grams in the hypothesis: cn,(t) k, max. # of matching n-grams for hyp. e(t) k , Oracle BLEU hypothesis: There is no easy way to pick the set hypotheses from an n-best list that will maximize the overall BLEU score. Instead, to compute oracle BLEU hypotheses, we chose, for each sentence independently, the hypothesis with the highest BLEU score computed for a sentence itself. We believe tha</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, W.-J. Zhu. 2002. BLEU: a methodfor automatic evaluation of machine translation. ACL’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
</authors>
<title>A Maximum Entropy Approach to Natural Language Processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<pages>39--71</pages>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>A. Berger, S. Della Pietra, and V. Della Pietra. 1996. A Maximum Entropy Approach to Natural Language Processing. Computational Linguistics, vol 22:1, pp. 39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Chen</author>
<author>R Rosenfeld</author>
</authors>
<title>A survey of smoothing techniquesforME models.</title>
<date>2000</date>
<journal>IEEE Trans. on Speech and Audio Processing,</journal>
<volume>8</volume>
<pages>37--50</pages>
<contexts>
<context position="5451" citStr="Chen and Rosenfeld, 2000" startWordPosition="889" endWordPosition="892"> k . λ t λ t Those quantities are abbreviated ck and ak to simplify the notation. The precision ratio Pn for an ngram order n is: A Pn,(t) t ck Pn n, (t) P. t ak A brevity penalty BP is also taken into account, to avoid favoring overly short sentences: where r is the average length of the shortest sentence1, and a is the average length of hypotheses. The BLEU score the set of hypotheses {e(t) k } is: � X4 � 1 B({e(t) k }) , BP · exp 4 log Pn . n=1 1As implemented by NIST mteval-v11b.pl. where p0(·) is the prior distribution of λ. The most frequently used prior in practice is the normal prior (Chen and Rosenfeld, 2000): log p0(λ) , −||λ||2 2σ2 − log |σ|, where σ2 &gt; 0 is the variance. It can be thought of as the inverse of a Lagrange multiplier when working with constrained optimization on the Euclidean norm of λ. When not interpolated with the likelihood, the prior can be thought of as a penalty term. The entropy penalty may also be used: H , − 1 T Unlike the Gaussian prior, the entropy is independent of parameterization (i.e., it does not depend on how features are expressed). BP , min{1; exp(1 − r)} , a XKt k=1 pk log pk. XT t=1 73 2.2.4 Minimum Error Rate Training A good way of training λ is to minimize </context>
</contexts>
<marker>Chen, Rosenfeld, 2000</marker>
<rawString>S. Chen and R. Rosenfeld. 2000. A survey of smoothing techniquesforME models. IEEE Trans. on Speech and Audio Processing, vol 8:2, pp. 37–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R O Duda</author>
<author>P E Hart</author>
</authors>
<title>Pattern Classification and Scene Analysis.</title>
<date>1973</date>
<publisher>Wiley &amp; Sons,</publisher>
<contexts>
<context position="14329" citStr="Duda and Hart, 1973" startWordPosition="2413" endWordPosition="2416">ly, there should be no inter-dependence between features. As an example, we can consider adding multiple language model scores. Whether we should consider ratios those of, globally linearly or log-linearly interpolating them, is open to debate. When features interact across dimensions, it becomes unclear what the best embodiment should be. 3.4 Non-parametric Features A generic solution may be sought in non-parametric processing. Our method can be derived from a quantized Parzen estimate of the feature density function. 3.4.1 Parzen Window The Parzen window is an early empirical kernel method (Duda and Hart, 1973). For an observation hm, we extrapolate probability mass around it with a smoothing window 4b(·). The density function is: �K 1 p(h) = M assuming 4b(·) is a density function. Parzen windows converge to the true density estimate, albeit slowly, under weak assumptions. 3.4.2 Bin Features One popular way of using continuous features in log-linear models is to convert a single continuous feature into multiple “bin” features. Each bin feature is defined as the indicator function of whether the original continuous feature was in a certain range. The bins were selected so that each bin collects an eq</context>
</contexts>
<marker>Duda, Hart, 1973</marker>
<rawString>R. O. Duda and P. E. Hart. 1973. Pattern Classification and Scene Analysis. Wiley &amp; Sons, 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H J Kushner</author>
<author>G G Yin</author>
</authors>
<title>Stochastic Approximation Algorithms and Applications.</title>
<date>1997</date>
<publisher>Springer-Verlag,</publisher>
<contexts>
<context position="10386" citStr="Kushner and Yin, 1997" startWordPosition="1784" endWordPosition="1787"> − u(r − Ea)]τ + (Ea)2 J ψa, where ψa, λis the 1-gram component of ψaλ. Finally, the derivative of the entropy is: X∇λH = (1 + log pk)∇λpk. k,t 2.3.3 RProp For all our experiments, we chose RProp (Riedmiller and Braun, 1992) as the gradient ascent algorithm. Unlike other gradient algorithms, it is only based on the sign of the gradient components at each iteration. It is relatively robust to the objective function, requires little memory, does not require meta parameters to be tuned, and is simple to implement. On the other hand, it typically requires more iterations than stochastic gradient (Kushner and Yin, 1997) or L-BFGS (Nocedal and Wright, 1999). Using fairly conservative stopping criteria, we observed that RProp was about 6 times faster than Minimum Error Rate Training. 3 Adding Features The log-linear model is relatively simple, and is usually found to yield good performance in practice. With these considerations in mind, feature engineering is an active area of research (Och et al., 2004). Because the model is fairly simple, some of the intelligence must be shifted to feature design. After having decided what new information should go in the overall score, there is an extra effort involved in e</context>
</contexts>
<marker>Kushner, Yin, 1997</marker>
<rawString>H. J. Kushner and G. G. Yin. 1997. Stochastic Approximation Algorithms and Applications. Springer-Verlag, 1997.</rawString>
</citation>
<citation valid="true">
<title>of Standards and Technology.</title>
<date>2006</date>
<journal>Machine Translation Evaluation Plan.</journal>
<publisher>The</publisher>
<institution>National Institute</institution>
<marker>2006</marker>
<rawString>National Institute of Standards and Technology. 2006. The 2006 Machine Translation Evaluation Plan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nocedal</author>
<author>S J Wright</author>
</authors>
<title>Numerical Optimization.</title>
<date>1999</date>
<publisher>Springer-Verlag,</publisher>
<contexts>
<context position="10423" citStr="Nocedal and Wright, 1999" startWordPosition="1790" endWordPosition="1793"> ψa, λis the 1-gram component of ψaλ. Finally, the derivative of the entropy is: X∇λH = (1 + log pk)∇λpk. k,t 2.3.3 RProp For all our experiments, we chose RProp (Riedmiller and Braun, 1992) as the gradient ascent algorithm. Unlike other gradient algorithms, it is only based on the sign of the gradient components at each iteration. It is relatively robust to the objective function, requires little memory, does not require meta parameters to be tuned, and is simple to implement. On the other hand, it typically requires more iterations than stochastic gradient (Kushner and Yin, 1997) or L-BFGS (Nocedal and Wright, 1999). Using fairly conservative stopping criteria, we observed that RProp was about 6 times faster than Minimum Error Rate Training. 3 Adding Features The log-linear model is relatively simple, and is usually found to yield good performance in practice. With these considerations in mind, feature engineering is an active area of research (Och et al., 2004). Because the model is fairly simple, some of the intelligence must be shifted to feature design. After having decided what new information should go in the overall score, there is an extra effort involved in expressing or parameterizing features </context>
</contexts>
<marker>Nocedal, Wright, 1999</marker>
<rawString>J. Nocedal and S. J. Wright. 1999. Numerical Optimization. Springer-Verlag, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum Error Rate Training</title>
<date>2003</date>
<booktitle>in Statistical Machine Translation. ACL’03.</booktitle>
<contexts>
<context position="1134" citStr="Och, 2003" startWordPosition="163" endWordPosition="164"> constraints of monotonicity and independence of feature functions. We expand features into a non-parametric, non-linear, and high-dimensional space. We extend empirical Bayes reward training of model parameters to meta parameters of feature generation. In effect, this allows us to trade away some human expert feature design for data. Preliminary results on a standard task show an encouraging improvement. 1 Introduction In recent years, statistical machine translation have experienced a quantum leap in quality thanks to automatic evaluation (Papineni et al., 2002) and errorbased optimization (Och, 2003). The conditional log-linear feature combination framework (Berger, Della Pietra and Della Pietra, 1996) is remarkably simple and effective in practice. Therefore, recent efforts (Och et al., 2004) have concentrated on feature design – wherein more intelligent features may be added. Because of their simplicity, however, log-linear models impose some constraints on how new information may be inserted into the system to achieve the best results. In other words, 72 new information needs to be parameterized carefully into one or more real valued feature functions. Therefore, that requires some hum</context>
<context position="6101" citStr="Och, 2003" startWordPosition="1018" endWordPosition="1019">re σ2 &gt; 0 is the variance. It can be thought of as the inverse of a Lagrange multiplier when working with constrained optimization on the Euclidean norm of λ. When not interpolated with the likelihood, the prior can be thought of as a penalty term. The entropy penalty may also be used: H , − 1 T Unlike the Gaussian prior, the entropy is independent of parameterization (i.e., it does not depend on how features are expressed). BP , min{1; exp(1 − r)} , a XKt k=1 pk log pk. XT t=1 73 2.2.4 Minimum Error Rate Training A good way of training λ is to minimize empirical top-1 error on training data (Och, 2003). Compared to maximum-likelihood, we now give partial credit for sentences which are only partially correct. The criterion is: We optimize the λ so that the BLEU score of the most likely hypotheses is improved. For that reason, we call this criterion BLEU max. This function is not convex and there is no known exact efficient optimization for it. However, there exists a linear-time algorithm for exact line search against that objective. The method is often used in conjunction with coordinate projection to great success. 2.2.5 Maximum Empirical Bayes Reward The algorithm may be improved by givin</context>
<context position="12886" citStr="Och, 2003" startWordPosition="2186" endWordPosition="2187">ing words from the left to the right and adding a contribution per word. Word count, for instance, is causal and additive. This property is typically required for efficient first-pass decoding. Instead, we look at a hypothesis sentence as a whole. Furthermore, we assume that the Kt-best list provided to us contains the entire probability space. 75 In particular, the computation of the partition function is performed over all Kt-best hypotheses. This is clearly not correct, and is the subject of further study. We use the n-best generation scheme interleaved with A optimization as described in (Och, 2003). 3.3 Issues with Parameterization As alluded to earlier, when designing a new feature in the log-linear model, one has to be careful to find the best embodiment. In general, a set of features must satisfy the following properties, ranked from strict to lax: • Linearity (warping) • Monotonicity • Independence (conjunction) Firstly, a feature should be linearly correlated with performance. There should be no region were it matters less than other regions. For instance, instead of a word count, one might consider adding its logarithm instead. Secondly, the “goodness” of a hypothesis associated w</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>F. J. Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. ACL’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>D Gildea</author>
<author>S Khudanpur</author>
<author>A Sarkar</author>
<author>K Yamada</author>
<author>A Fraser</author>
<author>S Kumar</author>
<author>L Shen</author>
<author>D Smith</author>
<author>K Eng</author>
<author>V Jain</author>
<author>Z Jin</author>
<author>D Radev</author>
</authors>
<title>A Smorgasbord of Features for Statistical Machine Translation.</title>
<date>2004</date>
<contexts>
<context position="1331" citStr="Och et al., 2004" startWordPosition="189" endWordPosition="192">g of model parameters to meta parameters of feature generation. In effect, this allows us to trade away some human expert feature design for data. Preliminary results on a standard task show an encouraging improvement. 1 Introduction In recent years, statistical machine translation have experienced a quantum leap in quality thanks to automatic evaluation (Papineni et al., 2002) and errorbased optimization (Och, 2003). The conditional log-linear feature combination framework (Berger, Della Pietra and Della Pietra, 1996) is remarkably simple and effective in practice. Therefore, recent efforts (Och et al., 2004) have concentrated on feature design – wherein more intelligent features may be added. Because of their simplicity, however, log-linear models impose some constraints on how new information may be inserted into the system to achieve the best results. In other words, 72 new information needs to be parameterized carefully into one or more real valued feature functions. Therefore, that requires some human knowledge and understanding. When not readily available, this is typically replaced with painstaking experimentation. We propose to replace that step with automatic training of non-parametric ag</context>
<context position="10776" citStr="Och et al., 2004" startWordPosition="1849" endWordPosition="1852">the objective function, requires little memory, does not require meta parameters to be tuned, and is simple to implement. On the other hand, it typically requires more iterations than stochastic gradient (Kushner and Yin, 1997) or L-BFGS (Nocedal and Wright, 1999). Using fairly conservative stopping criteria, we observed that RProp was about 6 times faster than Minimum Error Rate Training. 3 Adding Features The log-linear model is relatively simple, and is usually found to yield good performance in practice. With these considerations in mind, feature engineering is an active area of research (Och et al., 2004). Because the model is fairly simple, some of the intelligence must be shifted to feature design. After having decided what new information should go in the overall score, there is an extra effort involved in expressing or parameterizing features in a way which will be easiest for the model learn. Experimentation is usually required to find the best configuration. By adding non-parametric features, we propose to mitigate the parameterization problem. We will not add new information, but rather, propose a way to insulate research from the parameterization. The system should perform equivalently</context>
</contexts>
<marker>Och, Gildea, Khudanpur, Sarkar, Yamada, Fraser, Kumar, Shen, Smith, Eng, Jain, Jin, Radev, 2004</marker>
<rawString>F. J. Och, D. Gildea, S. Khudanpur, A. Sarkar, K. Yamada, A. Fraser, S. Kumar, L. Shen, D. Smith, K. Eng, V. Jain, Z. Jin, and D. Radev. 2004. A Smorgasbord of Features for Statistical Machine Translation. HLT/NAACL’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Discriminative Training and Maximum Entropy Models for Statistical Machine Translation.</title>
<date>2002</date>
<contexts>
<context position="2641" citStr="Och and Ney, 2002" startWordPosition="392" endWordPosition="395">ion. First, we define the model and the objective function training framework, then we describe our new non-parametric features. 2 Model In this section, we describe the general log-linear model used for statistical machine translation, as well as a training objective function and algorithm. The goal is to translate a French (source) sentence indexed by t, with surface string ft. Among a set of Kt outcomes, we denote an English (target) a hypothesis with surface string e(kt) indexed by k. 2.1 Log-linear Model The prevalent translation model in modern systems is a conditional log-linear model (Och and Ney, 2002). From a hypothesis e(t) k , we extract features h(t) k , abbreviated hk, as a function of e(t) k and ft. The conditional probability of a hypothesis e(t) k given a source sentence ft is: pk p(e(t) k |ft) ° exp[A - hk] � Zft;λ Proceedings of the Second Workshop on Statistical Machine Translation, pages 72–79, Prague, June 2007. c�2007 Association for Computational Linguistics where the partition function Zft;λ is given by: XZft;λ = exp[λ · hj]. j The vector of parameters of the model λ, gives a relative importance to each feature function component. 2.2 Training Criteria In this section, we qu</context>
<context position="4214" citStr="Och and Ney, 2002" startWordPosition="660" endWordPosition="663"> the test set sentences, and compared to the total counts of n-grams in the hypothesis: cn,(t) k, max. # of matching n-grams for hyp. e(t) k , Oracle BLEU hypothesis: There is no easy way to pick the set hypotheses from an n-best list that will maximize the overall BLEU score. Instead, to compute oracle BLEU hypotheses, we chose, for each sentence independently, the hypothesis with the highest BLEU score computed for a sentence itself. We believe that it is a relatively tight lower bound and equal for practical purposes to the true oracle BLEU. 2.2.2 Maximum Likelihood Used in earlier models (Och and Ney, 2002), the likelihood criterion is defined as the likelihood of an oracle hypothesis e(t) k� , typically a single reference translation, or alternatively the closest match which was decoded. When the model is correct and infinite amounts of data are available, this method will converge to the Bayes error (minimum achievable error), where we define a classification task of selecting k* against all others. 2.2.3 Regularization Schemes One can convert a maximum likelihood problem into maximum a posteriori using Bayes’ rule: an,(t) k, # of n-grams in hypothesis e(t) Yarg max p(λ |{e(kt), ft }) = arg ma</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>F. J. Och and H. Ney. 2002. Discriminative Training and Maximum Entropy Models for Statistical Machine Translation. ACL’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Povey</author>
<author>B Kingsbury</author>
<author>L Mangu</author>
<author>G Saon</author>
<author>H Soltau</author>
<author>G Zweig</author>
</authors>
<title>fMPE: Discriminatively trained features for speech recognition.</title>
<date>2004</date>
<tech>RT’04 Meeting.</tech>
<contexts>
<context position="16064" citStr="Povey et al., 2004" startWordPosition="2697" endWordPosition="2700">sian Mixture Model Features Bin features may be generalized to multidimensional kernels by using a Gaussian smoothing window instead of a rectangular window. The direct analogy is vector quantization. The idea is to weight specific regions of the feature space differently. Assuming that we have M Gaussians each with mean vector µm and diagonal covariance matrix Cm, and prior weight wm. We will add m new features, each defined as the posterior in the mixture model: 0 wmN(hi µm, Cm) hm Er wrN(hi µr, Cr). It is believed that any reasonable choice of kernels will yield roughly equivalent results (Povey et al., 2004), if the amount of training data and the number of kernels are both sufficiently large. We show two methods for obtaining clusters. In contrast with bins, lossless representation becomes rapidly impossible. ML kernels: The canonical way of obtaining cluster is to use the standard Gaussian mixture training. First, a single Gaussian is trained on the whole data set. Then, the Gaussian is split into two Gaussians, with each mean vector perturbed, and the Gaussians are retrained using maximum-likelihood in an -b(h − hm), m=1 76 expectation-maximization framework (Rabiner and Huang, 1993). The numb</context>
</contexts>
<marker>Povey, Kingsbury, Mangu, Saon, Soltau, Zweig, 2004</marker>
<rawString>D. Povey, B. Kingsbury, L. Mangu, G. Saon, H. Soltau and G. Zweig. 2004. fMPE: Discriminatively trained features for speech recognition. RT’04 Meeting.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Quirk</author>
<author>A Menezes</author>
<author>C Cherry</author>
</authors>
<title>Dependency Tree Translation: Syntactically Informed Phrasal</title>
<date>2005</date>
<booktitle>SMT. ACL’05.</booktitle>
<marker>Quirk, Menezes, Cherry, 2005</marker>
<rawString>C. Quirk, A. Menezes and C. Cherry. 2005. Dependency Tree Translation: Syntactically Informed Phrasal SMT. ACL’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Rabiner</author>
<author>B-H Huang</author>
</authors>
<title>Fundamentals of Speech Recognition.</title>
<date>1993</date>
<publisher>Prentice Hall.</publisher>
<contexts>
<context position="16654" citStr="Rabiner and Huang, 1993" startWordPosition="2790" endWordPosition="2793">alent results (Povey et al., 2004), if the amount of training data and the number of kernels are both sufficiently large. We show two methods for obtaining clusters. In contrast with bins, lossless representation becomes rapidly impossible. ML kernels: The canonical way of obtaining cluster is to use the standard Gaussian mixture training. First, a single Gaussian is trained on the whole data set. Then, the Gaussian is split into two Gaussians, with each mean vector perturbed, and the Gaussians are retrained using maximum-likelihood in an -b(h − hm), m=1 76 expectation-maximization framework (Rabiner and Huang, 1993). The number of Gaussians is typically increased exponentially. Perceptron kernels: We also experimented with another quicker way of obtaining kernels. We chose an equal prior and a global covariance matrix. Means were obtained as follows: for each sentence in the training set, if the top-1 candidate was different from the approximate maximum oracle BLEU hypothesis, both were inserted. It is a quick way to bootstrap and may reach the oracle BLEU score quickly. In the limit, GMMs will converge to the oracle BLEU. In the next section, we show how to reestimate these kernels if needed. 3.5 Re-est</context>
</contexts>
<marker>Rabiner, Huang, 1993</marker>
<rawString>L. R. Rabiner and B.-H. Huang. 1993. Fundamentals of Speech Recognition. Prentice Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Riedmiller</author>
<author>H Braun</author>
</authors>
<title>RPROP: A Fast Adaptive Learning Algorithm.</title>
<date>1992</date>
<booktitle>Proc. of ISCIS VII.</booktitle>
<contexts>
<context position="9988" citStr="Riedmiller and Braun, 1992" startWordPosition="1717" endWordPosition="1721">n may be treated separately. For each n-gram order, let us define sufficient statistics ψ for the precision: A-1: co t,k — t,k (∇λpk)ck; ψa λ °= X (∇λpk)ak, t,k where the gradient of the probabilities is given by: ∇λpk = pk(hk − h), with: h¯°= XKt pjhj. j=1 The derivative of the precision ˜Pn is: ∇λlog ˜Pn = 1 − ψa λ λ T Eck Eak � ψc � For the length, the derivative of log ¯BP is: u(r−Ea) Ia( − 1) [1 − u(r − Ea)]τ + (Ea)2 J ψa, where ψa, λis the 1-gram component of ψaλ. Finally, the derivative of the entropy is: X∇λH = (1 + log pk)∇λpk. k,t 2.3.3 RProp For all our experiments, we chose RProp (Riedmiller and Braun, 1992) as the gradient ascent algorithm. Unlike other gradient algorithms, it is only based on the sign of the gradient components at each iteration. It is relatively robust to the objective function, requires little memory, does not require meta parameters to be tuned, and is simple to implement. On the other hand, it typically requires more iterations than stochastic gradient (Kushner and Yin, 1997) or L-BFGS (Nocedal and Wright, 1999). Using fairly conservative stopping criteria, we observed that RProp was about 6 times faster than Minimum Error Rate Training. 3 Adding Features The log-linear mod</context>
</contexts>
<marker>Riedmiller, Braun, 1992</marker>
<rawString>M. Riedmiller and H. Braun. 1992. RPROP: A Fast Adaptive Learning Algorithm. Proc. of ISCIS VII.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Smith</author>
<author>J Eisner</author>
</authors>
<title>Minimum-Risk Annealing for Training Log-Linear Models.</title>
<date>2006</date>
<contexts>
<context position="6843" citStr="Smith and Eisner, 2006" startWordPosition="1138" endWordPosition="1141">ion is: We optimize the λ so that the BLEU score of the most likely hypotheses is improved. For that reason, we call this criterion BLEU max. This function is not convex and there is no known exact efficient optimization for it. However, there exists a linear-time algorithm for exact line search against that objective. The method is often used in conjunction with coordinate projection to great success. 2.2.5 Maximum Empirical Bayes Reward The algorithm may be improved by giving partial credit for confidence pk of the model to partially correct hypotheses outside of the most likely hypothesis (Smith and Eisner, 2006): pk log B({ek(t)}). Instead of the BLEU score, we use its logrithm, because we think it is exponentially hard to improve BLEU. This model is equivalent to the previous model when pk give all the probability mass to the top-1. That can be reached, for instance, when λ has a very large norm. There is no known method to train against this objective directly, however, efficient approximations have been developed. Again, it is not convex. It is hoped that this criterion is better suited for high-dimensional feature spaces. That is our main motivation for using this objective function throughout th</context>
<context position="8382" citStr="Smith and Eisner, 2006" startWordPosition="1396" endWordPosition="1400">gradient ascent method over an approximation of the empirical Bayes reward function. 2.3.1 Approximation Because the empirical Bayes reward is defined over a set of sentences, it may not be decomposed sentence by sentence. This is computationally burdensome. Its sufficient statistics are r, Pt ck and P t ak. The function may be reconstructed in a firstorder approximation with respect to each of these statistics. In practice this has the effect of commuting the expectation inside of the functional, and for that reason we call this criterion BLEUsoft. This approximation is called linearization (Smith and Eisner, 2006). We used a first-order approximation for speed, and ease of interpretation of the derivations. The new objective function is: PtEcn,(t) k log Pt Eak,(t), where the average bleu penalty is: }. Ek,ta1,(t) k The expectation is understood to be under the current estimate of our log-linear model. Because �BP is not differentiable, we replace the hard min function with a sigmoid, yielding: ! log BP ≈ u(r − Ek,ta1,(t) 1 − r k ) , Ek,ta1,(t) k with the sigmoid function u(x) defines a soft step function: u(x) °= 1 1 + e−T2, with a parameter τ ≫ 1. 2.3.2 Gradients and Sufficient Statistics We can obtai</context>
</contexts>
<marker>Smith, Eisner, 2006</marker>
<rawString>D. A. Smith and J. Eisner. 2006. Minimum-Risk Annealing for Training Log-Linear Models. ACLCOLING’06.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>