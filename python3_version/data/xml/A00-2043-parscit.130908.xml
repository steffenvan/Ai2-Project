<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003641">
<title confidence="0.988077">
An Empirical Assessment of Semantic Interpretation
</title>
<author confidence="0.996797">
Martin Romacker &amp; Udo Hahn
</author>
<affiliation confidence="0.950853">
Text Understanding Lab, leFI Group,
Freiburg University, Freiburg, D-79085, Germany
</affiliation>
<email confidence="0.446244">
{mr,hahn}Ocoling.uni-freiburg.de
</email>
<sectionHeader confidence="0.94503" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999858777777778">
We introduce a framework for semantic interpreta-
tion in which dependency structures are mapped to
conceptual representations based on a parsimonious
set of interpretation schemata. Our focus is on the
empirical evaluation of this approach to semantic in-
terpretation, i.e., its quality in terms of recall and
precision. Measurements are taken with respect to
two real-world domains, viz, information technology
test reports and medical finding reports.
</bodyText>
<sectionHeader confidence="0.995502" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999971958333334">
Semantic interpretation has been an actively investi-
gated issue on the research agenda of the logic-based
paradigm of NLP in the late eighties (e.g., Charniak
and Goldman (1988), Moore (1989), Pereira and
Pollack (1991)). With the emergence of empirical
methodologies in the early nineties, attention has al-
most completely shifted away from this topic. Since
then, semantic issues have mainly been dealt with
under a lexical perspective, viz, in terms of the res-
olution of lexico-semantic ambiguities (e.g., Schiitze
(1998), Pedersen and Bruce (1998)) and the gener-
ation of lexical hierarchies from large text corpora
(e.g., Li and Abe (1996), Hirakawa et al. (1996))
massively using statistical techniques.
The research on semantic interpretation that was
conducted in the pre-empiricist age of NLP was
mainly driven by an interest in logical formalisms
as carriers for appropriate semantic representations
of NL utterances. With this representational bias,
computational matters — how can semantic repre-
sentation structures be properly derived from parse
trees for a large variety of linguistic phenomena? —
became a secondary issue. In particular, this re-
search lacked entirely quantitative data reflecting
the accuracy of the proposed semantic interpreta-
tion mechanisms on real-world language data.
One might be tempted to argue that recent eval-
uation efforts within the field of information extrac-
tion (IE) systems (Chinchor et al., 1993) are going to
remedy this shortcoming. Given, however, the fixed
number of knowledge templates and the restricted
types of entities, locations, and events they encode
as target information to be extracted, one readily re-
alizes that such an evaluation framework provides,
at best, a considerably biased, overly selective test
environment for judging the understanding potential
of text analysis systems which are not tuned for this
special application.
On the other hand, the IE experiments clearly in-
dicate the need for a quantitative assessment of the
interpretative performance of natural language un-
derstanding systems. We will focus on this challenge
and propose such a general evaluation framework.
We first outline the model of semantic interpretation
underlying our approach and then focus on its em-
pirical assessment for two basic syntactic structures
of the German language, viz. genitives and auxiliary
constructions, in two domains.
</bodyText>
<sectionHeader confidence="0.90072" genericHeader="method">
2 The Basic Model for Semantic
Interpretation
</sectionHeader>
<bodyText confidence="0.98632488">
The problem of semantic interpretation can be de-
scribed as the mapping from syntactic to semantic
(or conceptual) representation structures. In our ap-
proach, the syntactic representation structures are
given as dependency graphs (Hahn et al., 1994). Un-
like constituency-based syntactic descriptions, de-
pendency graphs consist of lexical nodes only, and
these nodes are connected by vertices, each one of
which is labeled by a particular dependency relation
(cf. Figure 1).
For the purpose of semantic interpretation, de-
pendency graphs can be decomposed into semanti-
cally interpretable subgraphs.&apos; Basically, two types
of semantically interpretable subgraphs can be dis-
tinguished. The first one consists of lexical nodes
which are labeled by content words only (lexical in-
stances of verbs, nouns, adjectives or adverbs) and
which are directly linked by a single dependency re-
lation of any type whatsoever. Such a subgraph is
illustrated in Figure 1 by Speicher- genatt - Com-
puters. The second type of subgraph is also delim-
ited by labels of content words but, in addition, a
series of n 1. . . 4 intermediary lexical nodes may
&apos;This notion and all subsequent criteria for interpretation
are formally described in Romacker et al. (1999).
</bodyText>
<page confidence="0.994083">
327
</page>
<figureCaption confidence="0.999348">
Figure 1: Dependency Graph for a Sample Sentence
</figureCaption>
<figure confidence="0.971465666666667">
C:1 Context; IT-DOMAItt X
pro
SDRAM-Modulen
IThe memory of the computer -- can -- with SDRAM-modules -- extended-- be!
The memory of the computer can be extended with SDRAM-modules
subject: kann
verbpart: werden
verbp/&apos;
ppadjunct: erw itert
Mit
Spei her
speciftert
Der Computers
specifiej„:
des 1
COMPUTER-SYSTEM. 02
HAS-WORKING-MEMORY
/EMORY
0 I 1
0
EXTENSION-PATIENT
SDRAN-MODLILE. 03
EXTENSION-CO-PATIENT
CD --tof,POSSIBLE
MODALITY
0----o.:PRESENT
TENSE
</figure>
<figureCaption confidence="0.999834">
Figure 2: Concept Graph for a Sample Sentence
</figureCaption>
<bodyText confidence="0.999889358024691">
appear between these content words, all of which are
labeled by non-content words (such as auxiliary or
modal verbs, prepositions). Hence, in contrast to
direct linkage we speak here of indirect linkage be-
tween content words. Such a subgraph, with two
intervening non-content words — the modal &amp;quot;kann&amp;quot;
and the auxiliary &amp;quot;werden&amp;quot; —, is given in Figure 1 by
Speicher — subject — kann — verbpart — werden —
verbpart — erweitert. Another subgraph with just
one intervening non-content word — the preposition
&amp;quot;mit&amp;quot; — is illustrated by erweitert— ppadjunct — mit
— pobject — SDRAM-Modulen. From these consid-
erations follows that, e.g., the subgraph spanned by
Speicher and SDRAM-Modulen does not form a
semantically interpretable subgraph, since the con-
tent word erweitert intervenes on the linking path.
Our approach to semantic interpretation sub-
scribes to the principles of locality and composition-
ality. It operates on discrete and well-defined units
(subgraphs) of the parse tree, and the results of se-
mantic interpretation are incrementally combined by
fusing semantically interpretable subgraphs.
As semantic target language we have chosen the
framework of KL-ONE-type description logics (DL)
(Woods and Schmolze, 1992). Since these logics are
characterized by a settheoretical semantics we stay
on solid formal ground. Furthermore, we take ad-
vantage of the powerful inference engine of DL sys-
tems, the description classifier, which turns out to be
essential for embedded reasoning during the seman-
tic interpretation process. By equating the semantic
representation language with the conceptual one, we
follow arguments discussed by Allen (1993).
The basic idea for semantic interpretation is as
follows: Each lexical surface form of a content word
is associated with a set of concept identifiers repre-
senting its (different) lexical meanings. This way,
lexical ambiguity is accounted for. These concep-
tual correlates are internal to the domain knowledge
base, where they are described by a list of attributes
or conceptual roles, and corresponding restrictions
on permitted attribute values or role fillers are asso-
ciated with them.
As an example, consider the description for the
concept COMPUTER-SYSTEM. It may be character-
ized by a set of roles, such as HAS-HARD-DISK or HAS-
WORKING-MEMORY, with corresponding restrictions
on the concept types of potential role fillers. HAS-
WORKING-MEMORY, e.g., sanctions only fillers of
the concept type MEMORY. These conceptual con-
straints are used for semantic filtering, i.e., for the
elimination of syntactically admissible dependency
graphs which, nevertheless, do not have a valid se-
mantic interpretation.
Semantic interpretation, in effect, boils down to
finding appropriate conceptual relations in the do-
main knowledge that link the conceptual correlates
of the two content words spanning the semanti-
cally interpretable subgraph, irrespective of whether
a direct or an indirect linkage holds at the syn-
tactic level. Accordingly, Figure 2 depicts the se-
mantic/conceptual interpretation of the dependency
structure given in Figure 1. Instances represent-
ing the concrete discourse entities and events in
the sample sentence are visualized as solid rectan-
gles containing a unique identifier (e.g., COMPUTER-
SYsTEm.02). Labeled and directed edges indicate
instance roles. Dashed rectangles characterize sym-
bols used as makers for tense and modality.&apos;
Note that in Figure 2 each tuple of content words
which configures a minimal subgraph in Figure 1
has already received an interpretation in terms of a
relation linking the conceptual correlates. For exam-
ple, Speicher genatt — Computers (cf. Figure 1,
box 1) is mapped to COMPUTER-SYSTEM.02 HAS-
WORKING-MEMORY MEmoRY.01 (cf. Figure 2, box
1). However, the search for a valid conceptual rela-
tion is not only limited to a simple one-link slot-filler
structure. We rather may determine conceptual re-
lation paths between conceptual correlates of lexical
items, the length of which may be greater than 1.
</bodyText>
<footnote confidence="0.9976445">
2We currently do not further interpret the information con-
tained in tense or modality markers.
</footnote>
<page confidence="0.995557">
328
</page>
<figureCaption confidence="0.999396">
Figure 3: Fragment of the Lexeme Class Hierarchy
</figureCaption>
<figure confidence="0.994086416666667">
&lt;(patient co-patient)&gt;
werden_passive Speicher (memory) m t (with)
&lt;plas-part instrument ...I&gt;
Lexeme
Nominal Preposition
Ve
VerbTrans Auxiliary
&lt;subject: (agent patient)&gt;
&lt;dirobject: (patient co-patient)&gt;
Noun. Pronoun
&lt;genitive attribute:0&gt;
erweitern (extend)
</figure>
<bodyText confidence="0.999831024390244">
(Thus, the need for role composition in the DL lan-
guage becomes evident.) The directed search in the
concept graph of the domain knowledge requires so-
phisticated structural and topological constraints to
be manageable at all. These constraints are encap-
sulated in a special path finding and path evaluation
algorithm specified in Markert and Hahn (1997).
Besides these conceptual constraints holding in
the domain knowledge, we further attempt to reduce
the search space for finding relation paths by two
kinds of syntactic criteria. First, the search may be
constrained by the type of dependency relation hold-
ing between the content words of the currently con-
sidered semantically interpretable subgraph (direct
linkage), or it may be constrained by the intervening
lexical material, viz, the non-content words (indirect
linkage). Each of these syntactic constraints has an
immediate mapping to conceptual ones.
For some dependency configurations, however, no
syntactic constraints may apply. Such a case of un-
constrained semantic interpretation (e.g., for geni-
tive attributes directly linked by the genatt relation)
leads to an exhaustive directed search in the knowl-
edge base in order to find all conceptually compati-
ble role fillings among the two concepts involved.
Syntactic restrictions on semantic interpretation
either come from lexeme classes or concrete lexemes.
They are organized in terms of the lexeme class hi-
erarchy superimposed on the fully lexicalized depen-
dency grammar we use (Hahn et al., 1994). In the
fragment depicted in Figure 3, the lexeme class of
transitive verbs, VERBTRANS, requires that when-
ever a subject dependency relation is encountered,
semantic interpretation is constrained to the con-
ceptual roles AGENT or PATIENT and all their sub-
relations (such as EXTENSION-PATIENT). All other
conceptual roles are excluded from the subsequent
semantic interpretation. Exploiting the property in-
heritance mechanisms provided by the hierarchic or-
ganization of the lexicalized dependency grammar,
all concrete lexemes subsumed by the lexeme class
VERBTRANS, like &amp;quot;erweitern&amp;quot; (extend), inherit the
corresponding constraint. However, there are lexeme
classes such as NOUN which do not render any con-
straints for dependency relations such as evidenced
by gen [hive] att[ribute] (cf. Fig. 3).
It may even happen that such restrictions can only
be attached to concrete lexemes in order to avoid
overgeneralization. Fortunately, we observed that
this only happened to be the case for closed-class,
i.e., non-content words. Accordingly, in Figure 3
the preposition &amp;quot;with&amp;quot; is characterized by the con-
straint that only the conceptual roles HAS-PART, IN-
STRUMENT, etc. must be taken into consideration for
semantic interpretation.
Since the constraints at the lexeme class or the lex-
eme level are hard-wired in the class hierarchy, we
refer to the mapping of dependency relations (or id-
iosyncratic lexemes) to a set of conceptual relations
(expanded to their transitive closure) as static inter-
pretation. In contradistinction, the computation of
relation paths for tuples of concepts during the sen-
tence analysis process is called dynamic interpreta-
tion, since the latter process incorporates additional
conceptual constraints on the fly.
The above-mentioned conventions allow the
specification of high-level semantic interpretation
schemata covering a large variety of different syntac-
tic constructions by a single schema. For instance,
each syntactic construction for which no conceptual
constraints apply (e.g., the interpretation of geni-
tives, most adjectives, etc.) receives its semantic
interpretation by instantiating the same interpreta-
tion schema (Romacker et al., 1999). The power of
this approach comes from the fact that these high-
level schemata are instantiated in the course of the
parsing process by exploiting the dense specifications
of the inheritance hierarchies both at the grammar
level (the lexeme class hierarchy), as well as the con-
ceptual level (the concept and role hierarchies).
We currently supply up to ten semantic interpre-
tation schemata for declaratives, relatives, and pas-
</bodyText>
<page confidence="0.995381">
329
</page>
<bodyText confidence="0.99996">
sives at the clause level, complement subcategoriza-
tion via PPs, auxiliaries, all tenses at the VP level,
pre- and and postnominal modifiers at the NP level,
and anaphoric expressions. We currently do not ac-
count for control verbs (work in progress), coordina-
tion and quantification.
</bodyText>
<sectionHeader confidence="0.991709" genericHeader="method">
3 The Evaluation of Semantic
Interpretation
</sectionHeader>
<bodyText confidence="0.999963674418605">
In this section, we want to discuss, for two particular
types of German language phenomena, the adequacy
of our approach in the light of concrete language
data taken from the two corpora we work with. This
part of the enterprise, the empirical assessment of se-
mantic interpretation, is almost entirely neglected in
the literature (for two notable exceptions, cf. Bon-
nema et al. (1997) and Bean et al. (1998)).
Though similarities exist (viz, dealing with the
performance of NLP systems in terms of their abil-
ity to generate semantic/conceptual structures), the
semantic interpretation (SI) task has to be clearly
distinguished from the information extraction (IE)
task and its standard evaluation settings (Chinchor
et al., 1993). In the IE task, a small subset of the
templates from the entire domain is selected into
which information from the texts are mapped. Also,
the design of these templates focus on particularly
interesting facets (roles, in our terminology), so that
an IE system does not have to deal with the full
range of qualifications that might occur — even re-
lating to relevant, selected concepts. Note that in
any case, a priori relevance decisions limit the range
of a posteriori fact retrieval.
The SI task, however, is far less restricted. We
here evaluate the adequacy of the conceptual rep-
resentation structures relating, in principle (only re-
stricted, of course, by the limits of the knowledge ac-
quisition devices), to the entire domain of discourse,
with all qualifications mentioned in a text. Whether
these are relevant or not for a particular application
has to be determined by subsequent data/knowledge
cleansing. In this sense, semantic interpretation
might deliver the raw data for transformation into
appropriate IE target structures. Only because
of feasibility reasons, the designers of IE systems
equate IE with SI. The cross-linking of IE and SI
tasks, however, bears the risk of having to determine,
in advance, what will be relevant or not for later re-
trieval processes, assumptions which are likely to be
flawed by the dynamics of domains and the unpre-
dictability of the full range of interests of prospective
users.
</bodyText>
<subsectionHeader confidence="0.987704">
3.1 Methodological Issues
</subsectionHeader>
<bodyText confidence="0.996623344262295">
Our methodology to deal with the evaluation of se-
mantic interpretation is based on a triple division of
test conditions. The first category relates to checks
whether so-called static constraints, effected by the
mapping from a single dependency relation to one
or more conceptual relations, are valid (cf. Figure 3
for restrictions of this type). Second, one may in-
vestigate the appropriateness of the results from the
search of the domain knowledge base, i.e., whether a
relation between two concepts can be determined at
all, and, if so, whether that relation (or role chain)
is adequate. The conceptual constraints which come
into play at this stage of processing are here referred
to as dynamic constraint propagation, since they are
to be computed on the fly, while judging the valid-
ity of the role chain in question.3 Third, interactions
between the above-mentioned static constraints and
dynamic constraint propagation may occur. This
is the case for the interpretation of auxiliaries or
prepositions, where intervening lexical material and
associated constraints have to be accounted for si-
multaneously.
In our evaluation study, we investigated the effects
of category II and category III phenomena by consid-
ering genitives and modal as well as auxiliary verbs,
respectively. The knowledge background is consti-
tuted by a domain ontology that is divided into an
upper generic part (containing about 1,500 concepts
and relations) and domain-specific extensions. We
here report on the two specialized domains we deal
with — a hardware-biased information technology
(IT) domain model and an ontology covering parts
of anatomical medicine (MED). Each of these two
domain models adds roughly about 1,400 concepts
and relations to the upper model. Corresponding
lexeme entries in the lexicon provide linkages to the
entire ontology. In order to avoid error chaining, we
always assume a correct parse to be delivered for the
semantic interpretation process.
We took a random selection of 54 texts (compris-
ing 18,500 words) from the two text corpora, viz.
IT test reports and MEDical finding reports. For
evaluation purposes (cf. Table 1), we concentrated
on the interpretation of genitives (as an instance of
direct linkage; GEN) and on the interpretation of
periphrastic verbal complexes, i.e., passive, tempo-
ral and modal constructions (as instances of indirect
linkage; MODAUX).
The choice of these two grammatical patterns al-
lows us to ignore the problems caused by syntac-
tic ambiguity, since in our data no structural am-
3Note that computations at the domain knowledge level
which go beyond mere type checking are usually located out-
side the scope the semantic considerations. This is due to
the fact that encyclopedic knowledge and its repercussions on
the understanding process are typically not considered part
of the semantic interpretation task proper. While this may
be true from a strict linguistic point of view, from the com-
putational perspective of NLP this position cannot seriously
be maintained. Even more so, when semantic and conceptual
representations are collapsed.
</bodyText>
<page confidence="0.988515">
330
</page>
<bodyText confidence="0.960817557894737">
biguities occurred. If one were to investigate the
combined effects of syntactic ambiguity and seman-
tic interpretation the evaluation scenario had to be
changed. Methodologically, the first step were to ex-
plore the precision of a semantic interpretation task
without structural ambiguities (as we do) and then,
in the next step, incorporate the treatment of syn-
tactic ambiguities (e.g., by semantic filtering devices,
cf. Bonnema et al. (1997)).
Several guidelines were defined for the evaluation
procedure. A major issue dealt with the correctness
of a semantic interpretation. In cases with interpre-
tation, we considered a semantic interpretation to
be a correct one, if the conceptual relation between
the two concepts involved was considered adequate
by introspection (otherwise, incorrect). This qualifi-
cation is not as subjective as it may sound, since we
applied really strict conditions adjusted to the fine-
grained domain knowledge.4 Interpretations were
considered to be correct in those cases which con-
tained exactly one relation, as well as cases of se-
mantical/conceptual ambiguities (up to three read-
ings, the most), presumed the relation set contained
the correct one.&apos; A special case of incorrectness,
called nil, occurred when no relation path could be
determined though the two concepts under scrutiny
were contained in the domain knowledge base and
an interpretation should have been computed.
We further categorized the cases where the sys-
tem failed to produce an interpretation due to at
least one concept specification missing (with respect
to the two linked content words in a semantically
interpretable subgraph). In all those cases with-
out interpretation, insufficient coverage of the upper
model was contrasted with that of the two domain
models in focus, MED and IT, and with cases in
which concepts referred to other domains, e.g., fash-
ion or food. Ontological subareas that could nei-
ther be assigned to the upper model nor to partic-
ular domains were denoted by phrases referring to
time (e.g., &amp;quot;the beginning of the year&amp;quot;), space (e.g.,
4The majority of cases were easy to judge. For instance,
&amp;quot;the infiltration of the stroma&amp;quot; resulted in a correct reading
- STROMA being the PATIENT Of the INFILTRATION event -,
as well as in an incorrect one - being the AGENT of the IN-
FILTRATION. Among the incorrect semantic interpretations we
also categorized, e.g., the interpretation of the expression &amp;quot;the
prices of the manufacturers&amp;quot; as a conceptual linkage from
PRICE via PRICE-OF to PRODUCT via HAS-MANUFACTURER to
MANUFACTURER (this type of role chaining can be considered
an intriguing example of the embedded reasoning performed
by the description logic inference engine), since it did not ac-
count for the interpretation that MANUFACTURERS fix PRICES
as part of their marketing strategies. After all, correct inter-
pretations always boiled down to entirely evident cases, e.g.,
HARD-DISK PART-OF COMPUTER.
5At the level of semantic interpretation, the notion of se-
mantic ambiguity relates to the fact that the search algorithm
for valid conceptual relation paths retrieves more than a single
relation (chain).
&amp;quot;the surface of the storage medium&amp;quot;), and abstract
notions (e.g., &amp;quot;the acceptance of IT technology&amp;quot;).
Finally, we further distinguished evaluative expres-
sions (e.g., &amp;quot;the advantages of plasma display&amp;quot;) from
figurative language, including idiomatic expressions
(e.g., &amp;quot;the heart of the notebook&amp;quot;).
At first glance, the choice of genitives may appear
somewhat trivial. From a syntactic point of view,
genitives are directly linked and, indeed, constitute
an easy case to deal with at the dependency level.
From a conceptual perspective, however, they pro-
vide a real challenge. Since no static constraints are
involved in the interpretation of genitives (cf. Figure
3, lexeme class NouN) and, hence, no prescriptions
of (dis)allowed conceptual relations are made, an un-
constrained search (apart from connectivity condi-
tions imposed on the emerging role chains) of the
domain knowledge base is started. Hence, the main
burden rests on the dynamic constraint processing
part of semantic interpretation, i.e., the path find-
ing procedure muddling through the complete do-
main knowledge base in order to select the adequate
conceptual reading(s). Therefore, genitives make a
strong case for test category II mentioned above.
Dependency graphs involving modal verbs or aux-
iliaries are certainly more complex at the syntac-
tic level, since the corresponding semantically in-
terpretable subgraphs may be composed of up to
six lexical nodes. However, all intervening non-
content-word nodes accumulate constraints for the
search of a valid relation for semantic interpretations
and, hence, allows us to test category III phenom-
ena. The search space is usually pruned, since only
those relations that are sanctioned by the interven-
ing nodes have to be taken into consideration.
</bodyText>
<subsectionHeader confidence="0.99888">
3.2 Evaluation Data
</subsectionHeader>
<bodyText confidence="0.999979222222222">
We considered a total of almost 250 genitives in all
these texts, from which about 59%/33% (MED/IT)
received an interpretation.6 Out of the total loss due
to incomplete conceptual coverage, 56%08% (23 of
41 genitives/57 of 98 genitives) can be attributed to
insufficient coverage of the domain models. Only the
remaining 44%/42% are due to the residual factors
listed in Table 1.
In our sample, the number of syntactic construc-
tions containing modal verbs or auxiliaries amout to
292 examples. Compared to genitives, we obtained
a more favorable recall for both domains: 66% for
MED and 40% for IT. As for genitives, lacking in-
terpretations, in the majority of cases, can be at-
tributed to insufficient conceptual coverage. For the
IT domain, however, a dramatic increase in the num-
ber of missing concepts is due to gaps in the upper
model (78 or 63%) indicating that a large number of
</bodyText>
<footnote confidence="0.9478425">
6Confidence intervals at a 95% reliability level are given in
brackets in Table 1.
</footnote>
<page confidence="0.988705">
331
</page>
<table confidence="0.999860454545455">
MED-GEN IT-GEN MED-MODAUX IT-MODAUX
# texts 29 25 29 25
# words 4,300 14,200 4,300 14,200
recall 57% 31% 66% 40%
precision 97% 94% 95% 85%
# occurrences ... 100 147 58 234
... with interpretation 59 (59%) 49 (33%) 40 (69%) 111 (47%)
[confidence intervals] [48%-67%] [24%-41%] [56%-81%] [40%-53%]
correct (single reading) 53 (53%) 28 (19%) 38 (66%) 88 (38%)
correct (multiple readings) 4 (4%) 18 (12%) 0 (0%) 6 (3%)
incorrect 0 3 0 14
nil 2 0 2 3
... without interpretation 41 (41%) 98 (67%) 18 (31%) 123 (53%)
domain model (MED/IT) 23 (23%) 57 (39%) 11(19%) 42 (34%)
upper model 3 23 5 78
other domains 0 4 0 0
time 0 15 0 1
space 7 8 0 5
abstracta, generics 11 12 0 16
evaluative expressions 0 8 0 3
figurative language 1 17 2 24
miscellaneous 0 1 0 3
</table>
<tableCaption confidence="0.7772455">
Table 1: Empirical Results for the Semantic Interpretation of Genitives (GEN) and Modal Verbs and Aux-
iliaries (MODAUX) in the IT and MED domains
</tableCaption>
<bodyText confidence="0.9994175625">
essential concepts for verbs were not modeled. Also,
figurative speech plays a more important role in IT
with 24 occurrences. Both observations mirror the
fact that IT reports are linguistically far less con-
strained and are rhetorically more advanced than
their MED counterparts.
Another interesting observation which is not made
explicit in Table 1 concerns the distribution of modal
verbs and auxiliaries. In MED, we encountered 57
passives and just one modal verb and no temporal
auxiliaries, i.e., our data are in line with prevailing
findings about the basic patterns of medical sublan-
guage (Dunham, 1986). For the IT domain, cor-
responding occurrences were far less biased, viz. 80
passives, 131 modal verbs, and 23 temporal auxil-
iaries. Finally, for the two domains 25 samples con-
tained both modal verbs and auxiliaries, thus form-
ing semantically interpretable subgraphs with four
word nodes.
One might be tempted to formulate a null hy-
pothesis concerning the detrimental impact of the
length of semantically interpretable subgraphs (i.e.,
the number of intervening lexical nodes carrying
non-content words) on the quality of semantic inter-
pretation. In order to assess the role of the length
of the path in a dependency graph, we separately
investigated the results for these subclasses of com-
bined verbal complexes. From the entire four-node
set (cf. Table 2) with 25 occurrences (3 for MED and
22 for IT), 16 received an interpretation (3 for MED,
13 for IT). While we neglect the MED data due to
the small absolute numbers, the IT domain revealed
</bodyText>
<table confidence="0.998200571428572">
MED IT
4-nodes 4-nodes
recall - 59%
precision - 85%
# occurrences ... 3 22
...with interpretation 3 13
correct 3 11
</table>
<tableCaption confidence="0.949397">
Table 2: Interpretation Results for Semantically In-
terpretable Graphs Consisting of Four Nodes
</tableCaption>
<bodyText confidence="0.99984980952381">
59% recall and 85% precision. If we compare this
to the overall figures for recall (40%) and precision
(85%), the data might indicate a gain in recall for
longer subgraphs, while precision keeps stable.
The results we have worked out are just a first step
into a larger series of broader and deeper evaluation
efforts. The concrete values we present, sobering as
they may be for recall (57%/31% for genitives and
66%/40% for modal verbs and auxiliaries), encour-
aging, however, for precision (97%/94% for genitives
and 95%/85% for modal verbs and auxiliaries), can
only be interpreted relative to other data still lacking
on a broader scale.
As with any such evaluation, idiosyncrasies of the
coverage of the knowledge bases are inevitably tied
with the results and, thus, put limits on too far-
reaching generalizations. However, our data reflect
the intention to submit a knowledge-intensive text
understander to a realistic, i.e., conceptually un-
constrained and therefore &amp;quot;unfriendly&amp;quot; test environ-
ment.
</bodyText>
<page confidence="0.995701">
332
</page>
<bodyText confidence="0.999953875">
Judged from the figures of our recall data, there
is no doubt, whatsoever, that conceptual coverage
of the domain constitutes the bottleneck for any
knowledge-based approach to NLP.7 Sublanguage
differences are also mirrored systematically in these
data, since medical texts adhere more closely to well-
established concept taxonomies and writing stan-
dards than magazine articles in the IT domain.
</bodyText>
<sectionHeader confidence="0.999582" genericHeader="method">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999968209302326">
After a period of active research within the logic-
based paradigm (e.g., Charniak and Goldman
(1988), Moore (1989), Pereira and Pollack (1991)),
work on semantic interpretation has almost ceased
with the emergence of the empiricist movement in
NLP (cf. Bos et al. (1996) for one of the more recent
studies dealing with logic-based semantic interpreta-
tion in the framework of the VERBMOBIL project).
Only few methodological proposals for semantic
computations were made since then (e.g., higher-
order colored unification as a mechanism to avoid
over-generation inherent to unconstrained higher-
order unification (Gardent and Kohlhase, 1996)).
An issue which has lately received more focused at-
tention are ways to cope with the tremendous com-
plexity of semantic interpretations in the light of an
exploding number of (scope) ambiguities. Within
the underspecification framework of semantic repre-
sentations, e.g., Dorre (1997) proposes a polynomial
algorithm which constructs packed semantic repre-
sentations directly from parse forests.
All the previously mentioned studies (with the ex-
ception of the experimental setup in Done (1997)),
however, lack an empirical foundation of their var-
ious claims. Though the MUC evaluation rounds
(Chinchor et al., 1993) yield the flavor of an empiri-
cal assessment of semantic structures, their scope is
far too limited to count as an adequate evaluation
platform for semantic interpretation. Nirenburg et
al. (1996) already criticize the &apos;black-box&apos; architec-
ture underlying MUC-style evaluations, which pre-
cludes to draw serious conclusions from the short-
comings of MUC-style systems as far as single lin-
guistic modules are concerned. More generally, in
this paper the rationale underlying size (of the lex-
icons, knowledge or rule bases) as the major assess-
ment category is questioned. Rather dimensions re-
lating to the depth and breadth of the knowledge
sources involved in complex system behavior should
be taken more seriously into consideration. This is
exactly what we intended to provide in this paper.
As far as evaluation studies are concerned dealing
with the assessment of semantic interpretations, few
</bodyText>
<footnote confidence="0.652024">
7At least for the medical domain, we are currently actively
pursuing research on the semiautomatic creation of large-scale
ontologies from weak knowledge sources (medical terminolo-
gies); cf. Schulz and Hahn (2000).
</footnote>
<bodyText confidence="0.999940964285715">
have been carried out, some of which under severe
restrictions. For instance, Bean et al. (1998) nar-
row semantic interpretation down to a very limited
range of spatial relations in anatomy, while Gomez et
al. (1997) bias the result by preselecting only those
phrases that were already covered by their domain
models, thus optimizing for precision while shunting
aside recall considerations.
A recent study by Bonnema et al. (1997) comes
closest to a serious confrontation with a wide range
of real-world data (Dutch dialogues on a train travel
domain). This study proceeds from a corpus of
annotated parse trees to which are assigned type-
logical formulae which express the corresponding se-
mantic interpretation. The goal of this work is to
compute the most probable semantic interpretation
for a given parse tree. Accuracy (i.e., precision) is
rather high and ranges between 89,2%-92,3% de-
pending on the training size and depth of the parse
tree. Our accuracy criterion is weaker (the intended
meaning must be included in the set of all read-
ings), which might explain the slightly higher rates
we achieve for precision. However, this study does
not distinguish between different syntactic construc-
tions that undergo semantic interpretation, nor does
it consider the level of conceptual interpretation (we
focus on) as distinguished from the level of semantic
interpretation to which Bonnema et al. refer.
</bodyText>
<sectionHeader confidence="0.999219" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.986169269230769">
The evaluation of the quality and adequacy of se-
mantic interpretation data is still in its infancy. Our
approach which confronts semantic interpretation
devices with a random sample of textual real-world
data, without intentionally constraining the selec-
tion of these language data, is a real challenge for
the proposed methodology and it is unique in its
experimental rigor. ,
However, our work is just a step in the right di-
rection rather than giving a complete picture or al-
lowing final conclusions. Two reasons may be given
for the lack of such experiments. First, interest in
the deeper conceptual aspects of text interpretation
has ceased in the past years, with almost all efforts
devoted to robust and shallow syntactic processing
of large data sets. This also results in a lack of so-
phisticated semantic and conceptual specifications,
in particular, for larger text analysis systems. Sec-
ond, providing a gold standard for semantic inter-
pretation is, in itself, an incredibly underconstrained
and time-consuming process for which almost no re-
sources have been allocated in the NLP community
up to now.
Acknowledgements. We want to thank the mem-
bers of the [@F1 group for close cooperation. Martin Ro-
macker is supported by a grant from DFG (Ha 2097/5-1).
</bodyText>
<page confidence="0.998849">
333
</page>
<sectionHeader confidence="0.979369" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999828132743362">
James F. Allen. 1993. Natural language, knowledge
representation, and logical form. In M. Bates and
R. M. Weischedel, editors, Challenges in Natural
Language Processing, pages 146-175. Cambridge:
Cambridge University Press.
Carol A. Bean, Thomas C. Rindflesch, and
Charles A. Sneiderman. 1998. Automatic seman-
tic interpretation of anatomic spatial relationships
in clinical text. In Proceedings of the 1998 AMIA
Annual Fall Symposium., pages 897-901. Orlando,
Florida, November 7-11, 1998.
Remko Bonnema, Rens Bod, and Remko Scha. 1997.
A DOP model for semantic interpretation. In Pro-
ceedings of the 35th Annual Meeting of the Asso-
ciation for Computational Linguistics &amp; 8th Con-
ference of the European Chapter of the ACL, pages
159-167. Madrid, Spain, July 7-12, 1997.
Johan Bos, Bjorn Gamback, Christian Lieske,
Yoshiki Mori, Manfred Pinkal, and Karsten
Worm. 1996. Compositional semantics in VERB-
MOBIL. In COLING&apos;96 - Proceedings of the 16th
International Conference on Computational Lin-
guistics, pages 131-136. Copenhagen, Denmark,
August 5-9, 1996.
Eugene Charniak and Robert Goldman. 1988. A
logic for semantic interpretation. In Proceedings
of the 26th Annual Meeting of the Association for
Computational Linguistics, pages 87-94. Buffalo,
New York, U.S.A., 7-10 June 1988.
Nancy Chinchor, Lynette Hirschman, and David D.
Lewis. 1993. Evaluating message understanding
systems: an analysis of the third Message Un-
derstanding Conference (MUC-3). Computational
Linguistics, 19(3):409-447.
Jochen DOrre. 1997. Efficient construction of un-
derspecified semantics under massive ambiguity.
In Proceedings of the 35th Annual Meeting of the
Association for Computational Linguistics &amp; 8th
Conference of the European Chapter of the ACL,
pages 386-393. Madrid, Spain, July 7-12, 1997.
George Dunham. 1986. The role of syntax in the
sublanguage of medical diagnostic statements. In
R. Grishman and R. Kittredge, editors, Analyz-
ing Language in Restricted Domains: Sublanguage
Description and Processing, pages 175-194. Hills-
dale, NJ &amp; London: Lawrence Erlbaum.
Claire Gardent and Michael Kohlhase. 1996.
Higher-order coloured unification and natural lan-
guage semantics. In ACL &apos;96 - Proceedings of the
34th Annual Meeting of the Association for Com-
putational Linguistics, pages 1-9. Santa Cruz,
California, U.S.A., 24-27 June 1996.
Fernando Gomez, Carlos Segami, and Richard
Hull. 1997. Determining prepositional attach-
ment, prepositional meaning, verb meaning and
thematic roles. Computational Intell., 13(1):1-31.
Udo Hahn, Susanne Schacht, and Norbert Broker.
1994. Concurrent, object-oriented natural lan-
guage parsing: the PARSETALK model. Inter-
national Journal of Human-Computer Studies,
41(1/2):179-222.
Hideki Hirakawa, Zhonghui Xu, and Kenneth Haase.
1996. Inherited feature-based similarity measure
based on large semantic hierarchy and large text
corpus. In COLING&apos;96 - Proceedings of the 16th
International Conference on Computational Lin-
guistics, pages 508-513. Copenhagen, Denmark,
August 5-9, 1996.
Hang Li and Naoki Abe. 1996. Clustering words
with the MDL principle. In COLING&apos;96 - Pro-
ceedings of the 16th International Conference on
Computational Linguistics, pages 4-9. Copen-
hagen, Denmark, August 5-9, 1996.
Katja Markert and Udo Hahn. 1997. On the in-
teraction of metonymies and anaphora. In IJ-
CAP97 - Proceedings of the 15th International
Joint Conference on Artificial Intelligence, pages
1010-1015. Nagoya, Japan, August 23-29, 1997.
Robert C. Moore. 1989. Unification-based seman-
tic interpretation. In Proceedings of the 27th An-
nual Meeting of the Association for Computa-
tional Linguistics, pages 33-41. Vancouver, B.C.,
Canada, 26-29 June 1989.
Sergei Nirenburg, Kavi Mahesh, and Stephen Beale.
1996. Measuring semantic coverage. In COL-
ING &apos;96 - Proceedings of the 16th International
Conference on Computational Linguistics, pages
83-88. Copenhagen, Denmark, August 5-9, 1996.
Ted Pedersen and Rebecca Bruce. 1998. Knowledge
lean word-sense disambiguation. In AAAI&apos;98 -
Proceedings of the 15th National Conference on
Artificial Intelligence, pages 800-805. Madison,
Wisconsin, July 26-30, 1998.
Fernando C.N. Pereira and Martha E. Pollack. 1991.
Incremental interpretation. Artificial Intelligence,
50(1):37-82.
Martin Romacker, Katja Markert, and Udo Hahn.
1999. Lean semantic interpretation. In IJCAP99
- Proceedings of the 16th International Joint Con-
ference on Artificial Intelligence, pages 868-875.
Stockholm, Sweden, July 31 - August 6, 1999.
Stefan Schulz and Udo Hahn. 2000. Knowledge en-
gineering by large-scale knowledge reuse: experi-
ence from the medical domain. In Proceedings of
the 7th International Conference on Principles of
Knowledge Representation and Reasoning. Breck-
enridge, CO, USA, April 12-15, 2000.
Hinrich Schiitze. 1998. Automatic word sense
discrimination. Computational Linguistics,
24(1):97-124.
William A. Woods and James G. Schmolze. 1992.
The KL-ONE family. Computers ei Mathematics
with Applications, 23(2/5):133-177.
</reference>
<page confidence="0.99906">
334
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.922582">
<title confidence="0.999655">An Empirical Assessment of Semantic Interpretation</title>
<author confidence="0.944613">Romacker</author>
<author confidence="0.944613">UdoHahn</author>
<affiliation confidence="0.998243">Text Understanding Lab, leFI Group,</affiliation>
<address confidence="0.990222">Freiburg University, Freiburg, D-79085, Germany</address>
<email confidence="0.999362">mrOcoling.uni-freiburg.de</email>
<email confidence="0.999362">hahnOcoling.uni-freiburg.de</email>
<abstract confidence="0.9986618">We introduce a framework for semantic interpretation in which dependency structures are mapped to conceptual representations based on a parsimonious set of interpretation schemata. Our focus is on the empirical evaluation of this approach to semantic interpretation, i.e., its quality in terms of recall and precision. Measurements are taken with respect to real-world domains, technology test reports and medical finding reports.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
</authors>
<title>Natural language, knowledge representation, and logical form.</title>
<date>1993</date>
<booktitle>Challenges in Natural Language Processing,</booktitle>
<pages>146--175</pages>
<editor>In M. Bates and R. M. Weischedel, editors,</editor>
<publisher>Cambridge: Cambridge University Press.</publisher>
<contexts>
<context position="6541" citStr="Allen (1993)" startWordPosition="984" endWordPosition="985">ntally combined by fusing semantically interpretable subgraphs. As semantic target language we have chosen the framework of KL-ONE-type description logics (DL) (Woods and Schmolze, 1992). Since these logics are characterized by a settheoretical semantics we stay on solid formal ground. Furthermore, we take advantage of the powerful inference engine of DL systems, the description classifier, which turns out to be essential for embedded reasoning during the semantic interpretation process. By equating the semantic representation language with the conceptual one, we follow arguments discussed by Allen (1993). The basic idea for semantic interpretation is as follows: Each lexical surface form of a content word is associated with a set of concept identifiers representing its (different) lexical meanings. This way, lexical ambiguity is accounted for. These conceptual correlates are internal to the domain knowledge base, where they are described by a list of attributes or conceptual roles, and corresponding restrictions on permitted attribute values or role fillers are associated with them. As an example, consider the description for the concept COMPUTER-SYSTEM. It may be characterized by a set of ro</context>
</contexts>
<marker>Allen, 1993</marker>
<rawString>James F. Allen. 1993. Natural language, knowledge representation, and logical form. In M. Bates and R. M. Weischedel, editors, Challenges in Natural Language Processing, pages 146-175. Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carol A Bean</author>
<author>Thomas C Rindflesch</author>
<author>Charles A Sneiderman</author>
</authors>
<title>Automatic semantic interpretation of anatomic spatial relationships in clinical text.</title>
<date>1998</date>
<booktitle>In Proceedings of the 1998 AMIA Annual Fall Symposium.,</booktitle>
<pages>897--901</pages>
<location>Orlando, Florida,</location>
<contexts>
<context position="14150" citStr="Bean et al. (1998)" startWordPosition="2132" endWordPosition="2135">d postnominal modifiers at the NP level, and anaphoric expressions. We currently do not account for control verbs (work in progress), coordination and quantification. 3 The Evaluation of Semantic Interpretation In this section, we want to discuss, for two particular types of German language phenomena, the adequacy of our approach in the light of concrete language data taken from the two corpora we work with. This part of the enterprise, the empirical assessment of semantic interpretation, is almost entirely neglected in the literature (for two notable exceptions, cf. Bonnema et al. (1997) and Bean et al. (1998)). Though similarities exist (viz, dealing with the performance of NLP systems in terms of their ability to generate semantic/conceptual structures), the semantic interpretation (SI) task has to be clearly distinguished from the information extraction (IE) task and its standard evaluation settings (Chinchor et al., 1993). In the IE task, a small subset of the templates from the entire domain is selected into which information from the texts are mapped. Also, the design of these templates focus on particularly interesting facets (roles, in our terminology), so that an IE system does not have to</context>
<context position="31442" citStr="Bean et al. (1998)" startWordPosition="4880" endWordPosition="4883">lating to the depth and breadth of the knowledge sources involved in complex system behavior should be taken more seriously into consideration. This is exactly what we intended to provide in this paper. As far as evaluation studies are concerned dealing with the assessment of semantic interpretations, few 7At least for the medical domain, we are currently actively pursuing research on the semiautomatic creation of large-scale ontologies from weak knowledge sources (medical terminologies); cf. Schulz and Hahn (2000). have been carried out, some of which under severe restrictions. For instance, Bean et al. (1998) narrow semantic interpretation down to a very limited range of spatial relations in anatomy, while Gomez et al. (1997) bias the result by preselecting only those phrases that were already covered by their domain models, thus optimizing for precision while shunting aside recall considerations. A recent study by Bonnema et al. (1997) comes closest to a serious confrontation with a wide range of real-world data (Dutch dialogues on a train travel domain). This study proceeds from a corpus of annotated parse trees to which are assigned typelogical formulae which express the corresponding semantic </context>
</contexts>
<marker>Bean, Rindflesch, Sneiderman, 1998</marker>
<rawString>Carol A. Bean, Thomas C. Rindflesch, and Charles A. Sneiderman. 1998. Automatic semantic interpretation of anatomic spatial relationships in clinical text. In Proceedings of the 1998 AMIA Annual Fall Symposium., pages 897-901. Orlando, Florida, November 7-11, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remko Bonnema</author>
<author>Rens Bod</author>
<author>Remko Scha</author>
</authors>
<title>A DOP model for semantic interpretation.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics &amp; 8th Conference of the European Chapter of the ACL,</booktitle>
<pages>159--167</pages>
<location>Madrid, Spain,</location>
<contexts>
<context position="14127" citStr="Bonnema et al. (1997)" startWordPosition="2126" endWordPosition="2130"> the VP level, pre- and and postnominal modifiers at the NP level, and anaphoric expressions. We currently do not account for control verbs (work in progress), coordination and quantification. 3 The Evaluation of Semantic Interpretation In this section, we want to discuss, for two particular types of German language phenomena, the adequacy of our approach in the light of concrete language data taken from the two corpora we work with. This part of the enterprise, the empirical assessment of semantic interpretation, is almost entirely neglected in the literature (for two notable exceptions, cf. Bonnema et al. (1997) and Bean et al. (1998)). Though similarities exist (viz, dealing with the performance of NLP systems in terms of their ability to generate semantic/conceptual structures), the semantic interpretation (SI) task has to be clearly distinguished from the information extraction (IE) task and its standard evaluation settings (Chinchor et al., 1993). In the IE task, a small subset of the templates from the entire domain is selected into which information from the texts are mapped. Also, the design of these templates focus on particularly interesting facets (roles, in our terminology), so that an IE </context>
<context position="19461" citStr="Bonnema et al. (1997)" startWordPosition="2967" endWordPosition="2970">nt of view, from the computational perspective of NLP this position cannot seriously be maintained. Even more so, when semantic and conceptual representations are collapsed. 330 biguities occurred. If one were to investigate the combined effects of syntactic ambiguity and semantic interpretation the evaluation scenario had to be changed. Methodologically, the first step were to explore the precision of a semantic interpretation task without structural ambiguities (as we do) and then, in the next step, incorporate the treatment of syntactic ambiguities (e.g., by semantic filtering devices, cf. Bonnema et al. (1997)). Several guidelines were defined for the evaluation procedure. A major issue dealt with the correctness of a semantic interpretation. In cases with interpretation, we considered a semantic interpretation to be a correct one, if the conceptual relation between the two concepts involved was considered adequate by introspection (otherwise, incorrect). This qualification is not as subjective as it may sound, since we applied really strict conditions adjusted to the finegrained domain knowledge.4 Interpretations were considered to be correct in those cases which contained exactly one relation, as</context>
<context position="31776" citStr="Bonnema et al. (1997)" startWordPosition="4933" endWordPosition="4936">l domain, we are currently actively pursuing research on the semiautomatic creation of large-scale ontologies from weak knowledge sources (medical terminologies); cf. Schulz and Hahn (2000). have been carried out, some of which under severe restrictions. For instance, Bean et al. (1998) narrow semantic interpretation down to a very limited range of spatial relations in anatomy, while Gomez et al. (1997) bias the result by preselecting only those phrases that were already covered by their domain models, thus optimizing for precision while shunting aside recall considerations. A recent study by Bonnema et al. (1997) comes closest to a serious confrontation with a wide range of real-world data (Dutch dialogues on a train travel domain). This study proceeds from a corpus of annotated parse trees to which are assigned typelogical formulae which express the corresponding semantic interpretation. The goal of this work is to compute the most probable semantic interpretation for a given parse tree. Accuracy (i.e., precision) is rather high and ranges between 89,2%-92,3% depending on the training size and depth of the parse tree. Our accuracy criterion is weaker (the intended meaning must be included in the set </context>
</contexts>
<marker>Bonnema, Bod, Scha, 1997</marker>
<rawString>Remko Bonnema, Rens Bod, and Remko Scha. 1997. A DOP model for semantic interpretation. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics &amp; 8th Conference of the European Chapter of the ACL, pages 159-167. Madrid, Spain, July 7-12, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Bjorn Gamback</author>
<author>Christian Lieske</author>
<author>Yoshiki Mori</author>
<author>Manfred Pinkal</author>
<author>Karsten Worm</author>
</authors>
<title>Compositional semantics in VERBMOBIL.</title>
<date>1996</date>
<booktitle>In COLING&apos;96 - Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<pages>131--136</pages>
<location>Copenhagen, Denmark,</location>
<contexts>
<context position="29256" citStr="Bos et al. (1996)" startWordPosition="4550" endWordPosition="4553">whatsoever, that conceptual coverage of the domain constitutes the bottleneck for any knowledge-based approach to NLP.7 Sublanguage differences are also mirrored systematically in these data, since medical texts adhere more closely to wellestablished concept taxonomies and writing standards than magazine articles in the IT domain. 4 Related Work After a period of active research within the logicbased paradigm (e.g., Charniak and Goldman (1988), Moore (1989), Pereira and Pollack (1991)), work on semantic interpretation has almost ceased with the emergence of the empiricist movement in NLP (cf. Bos et al. (1996) for one of the more recent studies dealing with logic-based semantic interpretation in the framework of the VERBMOBIL project). Only few methodological proposals for semantic computations were made since then (e.g., higherorder colored unification as a mechanism to avoid over-generation inherent to unconstrained higherorder unification (Gardent and Kohlhase, 1996)). An issue which has lately received more focused attention are ways to cope with the tremendous complexity of semantic interpretations in the light of an exploding number of (scope) ambiguities. Within the underspecification framew</context>
</contexts>
<marker>Bos, Gamback, Lieske, Mori, Pinkal, Worm, 1996</marker>
<rawString>Johan Bos, Bjorn Gamback, Christian Lieske, Yoshiki Mori, Manfred Pinkal, and Karsten Worm. 1996. Compositional semantics in VERBMOBIL. In COLING&apos;96 - Proceedings of the 16th International Conference on Computational Linguistics, pages 131-136. Copenhagen, Denmark, August 5-9, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Robert Goldman</author>
</authors>
<title>A logic for semantic interpretation.</title>
<date>1988</date>
<booktitle>In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>87--94</pages>
<location>Buffalo, New York, U.S.A.,</location>
<contexts>
<context position="848" citStr="Charniak and Goldman (1988)" startWordPosition="115" endWordPosition="118">amework for semantic interpretation in which dependency structures are mapped to conceptual representations based on a parsimonious set of interpretation schemata. Our focus is on the empirical evaluation of this approach to semantic interpretation, i.e., its quality in terms of recall and precision. Measurements are taken with respect to two real-world domains, viz, information technology test reports and medical finding reports. 1 Introduction Semantic interpretation has been an actively investigated issue on the research agenda of the logic-based paradigm of NLP in the late eighties (e.g., Charniak and Goldman (1988), Moore (1989), Pereira and Pollack (1991)). With the emergence of empirical methodologies in the early nineties, attention has almost completely shifted away from this topic. Since then, semantic issues have mainly been dealt with under a lexical perspective, viz, in terms of the resolution of lexico-semantic ambiguities (e.g., Schiitze (1998), Pedersen and Bruce (1998)) and the generation of lexical hierarchies from large text corpora (e.g., Li and Abe (1996), Hirakawa et al. (1996)) massively using statistical techniques. The research on semantic interpretation that was conducted in the pre</context>
<context position="29086" citStr="Charniak and Goldman (1988)" startWordPosition="4523" endWordPosition="4526"> text understander to a realistic, i.e., conceptually unconstrained and therefore &amp;quot;unfriendly&amp;quot; test environment. 332 Judged from the figures of our recall data, there is no doubt, whatsoever, that conceptual coverage of the domain constitutes the bottleneck for any knowledge-based approach to NLP.7 Sublanguage differences are also mirrored systematically in these data, since medical texts adhere more closely to wellestablished concept taxonomies and writing standards than magazine articles in the IT domain. 4 Related Work After a period of active research within the logicbased paradigm (e.g., Charniak and Goldman (1988), Moore (1989), Pereira and Pollack (1991)), work on semantic interpretation has almost ceased with the emergence of the empiricist movement in NLP (cf. Bos et al. (1996) for one of the more recent studies dealing with logic-based semantic interpretation in the framework of the VERBMOBIL project). Only few methodological proposals for semantic computations were made since then (e.g., higherorder colored unification as a mechanism to avoid over-generation inherent to unconstrained higherorder unification (Gardent and Kohlhase, 1996)). An issue which has lately received more focused attention ar</context>
</contexts>
<marker>Charniak, Goldman, 1988</marker>
<rawString>Eugene Charniak and Robert Goldman. 1988. A logic for semantic interpretation. In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, pages 87-94. Buffalo, New York, U.S.A., 7-10 June 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Chinchor</author>
<author>Lynette Hirschman</author>
<author>David D Lewis</author>
</authors>
<title>Evaluating message understanding systems: an analysis of the third</title>
<date>1993</date>
<booktitle>Message Understanding Conference (MUC-3). Computational Linguistics,</booktitle>
<pages>19--3</pages>
<contexts>
<context position="2114" citStr="Chinchor et al., 1993" startWordPosition="305" endWordPosition="308">an interest in logical formalisms as carriers for appropriate semantic representations of NL utterances. With this representational bias, computational matters — how can semantic representation structures be properly derived from parse trees for a large variety of linguistic phenomena? — became a secondary issue. In particular, this research lacked entirely quantitative data reflecting the accuracy of the proposed semantic interpretation mechanisms on real-world language data. One might be tempted to argue that recent evaluation efforts within the field of information extraction (IE) systems (Chinchor et al., 1993) are going to remedy this shortcoming. Given, however, the fixed number of knowledge templates and the restricted types of entities, locations, and events they encode as target information to be extracted, one readily realizes that such an evaluation framework provides, at best, a considerably biased, overly selective test environment for judging the understanding potential of text analysis systems which are not tuned for this special application. On the other hand, the IE experiments clearly indicate the need for a quantitative assessment of the interpretative performance of natural language </context>
<context position="14472" citStr="Chinchor et al., 1993" startWordPosition="2178" endWordPosition="2181"> our approach in the light of concrete language data taken from the two corpora we work with. This part of the enterprise, the empirical assessment of semantic interpretation, is almost entirely neglected in the literature (for two notable exceptions, cf. Bonnema et al. (1997) and Bean et al. (1998)). Though similarities exist (viz, dealing with the performance of NLP systems in terms of their ability to generate semantic/conceptual structures), the semantic interpretation (SI) task has to be clearly distinguished from the information extraction (IE) task and its standard evaluation settings (Chinchor et al., 1993). In the IE task, a small subset of the templates from the entire domain is selected into which information from the texts are mapped. Also, the design of these templates focus on particularly interesting facets (roles, in our terminology), so that an IE system does not have to deal with the full range of qualifications that might occur — even relating to relevant, selected concepts. Note that in any case, a priori relevance decisions limit the range of a posteriori fact retrieval. The SI task, however, is far less restricted. We here evaluate the adequacy of the conceptual representation stru</context>
<context position="30237" citStr="Chinchor et al., 1993" startWordPosition="4694" endWordPosition="4697">e, 1996)). An issue which has lately received more focused attention are ways to cope with the tremendous complexity of semantic interpretations in the light of an exploding number of (scope) ambiguities. Within the underspecification framework of semantic representations, e.g., Dorre (1997) proposes a polynomial algorithm which constructs packed semantic representations directly from parse forests. All the previously mentioned studies (with the exception of the experimental setup in Done (1997)), however, lack an empirical foundation of their various claims. Though the MUC evaluation rounds (Chinchor et al., 1993) yield the flavor of an empirical assessment of semantic structures, their scope is far too limited to count as an adequate evaluation platform for semantic interpretation. Nirenburg et al. (1996) already criticize the &apos;black-box&apos; architecture underlying MUC-style evaluations, which precludes to draw serious conclusions from the shortcomings of MUC-style systems as far as single linguistic modules are concerned. More generally, in this paper the rationale underlying size (of the lexicons, knowledge or rule bases) as the major assessment category is questioned. Rather dimensions relating to the</context>
</contexts>
<marker>Chinchor, Hirschman, Lewis, 1993</marker>
<rawString>Nancy Chinchor, Lynette Hirschman, and David D. Lewis. 1993. Evaluating message understanding systems: an analysis of the third Message Understanding Conference (MUC-3). Computational Linguistics, 19(3):409-447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jochen DOrre</author>
</authors>
<title>Efficient construction of underspecified semantics under massive ambiguity.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics &amp; 8th Conference of the European Chapter of the ACL,</booktitle>
<pages>386--393</pages>
<location>Madrid, Spain,</location>
<marker>DOrre, 1997</marker>
<rawString>Jochen DOrre. 1997. Efficient construction of underspecified semantics under massive ambiguity. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics &amp; 8th Conference of the European Chapter of the ACL, pages 386-393. Madrid, Spain, July 7-12, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Dunham</author>
</authors>
<title>The role of syntax in the sublanguage of medical diagnostic statements.</title>
<date>1986</date>
<booktitle>Analyzing Language in Restricted Domains: Sublanguage Description and Processing,</booktitle>
<pages>175--194</pages>
<editor>In R. Grishman and R. Kittredge, editors,</editor>
<location>Hillsdale, NJ &amp; London: Lawrence Erlbaum.</location>
<contexts>
<context position="26411" citStr="Dunham, 1986" startWordPosition="4095" endWordPosition="4096">ns essential concepts for verbs were not modeled. Also, figurative speech plays a more important role in IT with 24 occurrences. Both observations mirror the fact that IT reports are linguistically far less constrained and are rhetorically more advanced than their MED counterparts. Another interesting observation which is not made explicit in Table 1 concerns the distribution of modal verbs and auxiliaries. In MED, we encountered 57 passives and just one modal verb and no temporal auxiliaries, i.e., our data are in line with prevailing findings about the basic patterns of medical sublanguage (Dunham, 1986). For the IT domain, corresponding occurrences were far less biased, viz. 80 passives, 131 modal verbs, and 23 temporal auxiliaries. Finally, for the two domains 25 samples contained both modal verbs and auxiliaries, thus forming semantically interpretable subgraphs with four word nodes. One might be tempted to formulate a null hypothesis concerning the detrimental impact of the length of semantically interpretable subgraphs (i.e., the number of intervening lexical nodes carrying non-content words) on the quality of semantic interpretation. In order to assess the role of the length of the path</context>
</contexts>
<marker>Dunham, 1986</marker>
<rawString>George Dunham. 1986. The role of syntax in the sublanguage of medical diagnostic statements. In R. Grishman and R. Kittredge, editors, Analyzing Language in Restricted Domains: Sublanguage Description and Processing, pages 175-194. Hillsdale, NJ &amp; London: Lawrence Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Gardent</author>
<author>Michael Kohlhase</author>
</authors>
<title>Higher-order coloured unification and natural language semantics.</title>
<date>1996</date>
<booktitle>In ACL &apos;96 - Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1--9</pages>
<location>Santa Cruz, California, U.S.A.,</location>
<contexts>
<context position="29623" citStr="Gardent and Kohlhase, 1996" startWordPosition="4602" endWordPosition="4605">eriod of active research within the logicbased paradigm (e.g., Charniak and Goldman (1988), Moore (1989), Pereira and Pollack (1991)), work on semantic interpretation has almost ceased with the emergence of the empiricist movement in NLP (cf. Bos et al. (1996) for one of the more recent studies dealing with logic-based semantic interpretation in the framework of the VERBMOBIL project). Only few methodological proposals for semantic computations were made since then (e.g., higherorder colored unification as a mechanism to avoid over-generation inherent to unconstrained higherorder unification (Gardent and Kohlhase, 1996)). An issue which has lately received more focused attention are ways to cope with the tremendous complexity of semantic interpretations in the light of an exploding number of (scope) ambiguities. Within the underspecification framework of semantic representations, e.g., Dorre (1997) proposes a polynomial algorithm which constructs packed semantic representations directly from parse forests. All the previously mentioned studies (with the exception of the experimental setup in Done (1997)), however, lack an empirical foundation of their various claims. Though the MUC evaluation rounds (Chinchor</context>
</contexts>
<marker>Gardent, Kohlhase, 1996</marker>
<rawString>Claire Gardent and Michael Kohlhase. 1996. Higher-order coloured unification and natural language semantics. In ACL &apos;96 - Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, pages 1-9. Santa Cruz, California, U.S.A., 24-27 June 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Gomez</author>
<author>Carlos Segami</author>
<author>Richard Hull</author>
</authors>
<title>Determining prepositional attachment, prepositional meaning, verb meaning and thematic roles.</title>
<date>1997</date>
<journal>Computational Intell.,</journal>
<pages>13--1</pages>
<contexts>
<context position="31561" citStr="Gomez et al. (1997)" startWordPosition="4900" endWordPosition="4903">ously into consideration. This is exactly what we intended to provide in this paper. As far as evaluation studies are concerned dealing with the assessment of semantic interpretations, few 7At least for the medical domain, we are currently actively pursuing research on the semiautomatic creation of large-scale ontologies from weak knowledge sources (medical terminologies); cf. Schulz and Hahn (2000). have been carried out, some of which under severe restrictions. For instance, Bean et al. (1998) narrow semantic interpretation down to a very limited range of spatial relations in anatomy, while Gomez et al. (1997) bias the result by preselecting only those phrases that were already covered by their domain models, thus optimizing for precision while shunting aside recall considerations. A recent study by Bonnema et al. (1997) comes closest to a serious confrontation with a wide range of real-world data (Dutch dialogues on a train travel domain). This study proceeds from a corpus of annotated parse trees to which are assigned typelogical formulae which express the corresponding semantic interpretation. The goal of this work is to compute the most probable semantic interpretation for a given parse tree. A</context>
</contexts>
<marker>Gomez, Segami, Hull, 1997</marker>
<rawString>Fernando Gomez, Carlos Segami, and Richard Hull. 1997. Determining prepositional attachment, prepositional meaning, verb meaning and thematic roles. Computational Intell., 13(1):1-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Udo Hahn</author>
<author>Susanne Schacht</author>
<author>Norbert Broker</author>
</authors>
<title>Concurrent, object-oriented natural language parsing: the PARSETALK model.</title>
<date>1994</date>
<journal>International Journal of Human-Computer Studies,</journal>
<pages>41--1</pages>
<contexts>
<context position="3352" citStr="Hahn et al., 1994" startWordPosition="491" endWordPosition="494">s. We will focus on this challenge and propose such a general evaluation framework. We first outline the model of semantic interpretation underlying our approach and then focus on its empirical assessment for two basic syntactic structures of the German language, viz. genitives and auxiliary constructions, in two domains. 2 The Basic Model for Semantic Interpretation The problem of semantic interpretation can be described as the mapping from syntactic to semantic (or conceptual) representation structures. In our approach, the syntactic representation structures are given as dependency graphs (Hahn et al., 1994). Unlike constituency-based syntactic descriptions, dependency graphs consist of lexical nodes only, and these nodes are connected by vertices, each one of which is labeled by a particular dependency relation (cf. Figure 1). For the purpose of semantic interpretation, dependency graphs can be decomposed into semantically interpretable subgraphs.&apos; Basically, two types of semantically interpretable subgraphs can be distinguished. The first one consists of lexical nodes which are labeled by content words only (lexical instances of verbs, nouns, adjectives or adverbs) and which are directly linked</context>
<context position="10809" citStr="Hahn et al., 1994" startWordPosition="1625" endWordPosition="1628">onceptual ones. For some dependency configurations, however, no syntactic constraints may apply. Such a case of unconstrained semantic interpretation (e.g., for genitive attributes directly linked by the genatt relation) leads to an exhaustive directed search in the knowledge base in order to find all conceptually compatible role fillings among the two concepts involved. Syntactic restrictions on semantic interpretation either come from lexeme classes or concrete lexemes. They are organized in terms of the lexeme class hierarchy superimposed on the fully lexicalized dependency grammar we use (Hahn et al., 1994). In the fragment depicted in Figure 3, the lexeme class of transitive verbs, VERBTRANS, requires that whenever a subject dependency relation is encountered, semantic interpretation is constrained to the conceptual roles AGENT or PATIENT and all their subrelations (such as EXTENSION-PATIENT). All other conceptual roles are excluded from the subsequent semantic interpretation. Exploiting the property inheritance mechanisms provided by the hierarchic organization of the lexicalized dependency grammar, all concrete lexemes subsumed by the lexeme class VERBTRANS, like &amp;quot;erweitern&amp;quot; (extend), inherit</context>
</contexts>
<marker>Hahn, Schacht, Broker, 1994</marker>
<rawString>Udo Hahn, Susanne Schacht, and Norbert Broker. 1994. Concurrent, object-oriented natural language parsing: the PARSETALK model. International Journal of Human-Computer Studies, 41(1/2):179-222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Hirakawa</author>
<author>Zhonghui Xu</author>
<author>Kenneth Haase</author>
</authors>
<title>Inherited feature-based similarity measure based on large semantic hierarchy and large text corpus.</title>
<date>1996</date>
<booktitle>In COLING&apos;96 - Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<pages>508--513</pages>
<location>Copenhagen, Denmark,</location>
<contexts>
<context position="1337" citStr="Hirakawa et al. (1996)" startWordPosition="191" endWordPosition="194"> investigated issue on the research agenda of the logic-based paradigm of NLP in the late eighties (e.g., Charniak and Goldman (1988), Moore (1989), Pereira and Pollack (1991)). With the emergence of empirical methodologies in the early nineties, attention has almost completely shifted away from this topic. Since then, semantic issues have mainly been dealt with under a lexical perspective, viz, in terms of the resolution of lexico-semantic ambiguities (e.g., Schiitze (1998), Pedersen and Bruce (1998)) and the generation of lexical hierarchies from large text corpora (e.g., Li and Abe (1996), Hirakawa et al. (1996)) massively using statistical techniques. The research on semantic interpretation that was conducted in the pre-empiricist age of NLP was mainly driven by an interest in logical formalisms as carriers for appropriate semantic representations of NL utterances. With this representational bias, computational matters — how can semantic representation structures be properly derived from parse trees for a large variety of linguistic phenomena? — became a secondary issue. In particular, this research lacked entirely quantitative data reflecting the accuracy of the proposed semantic interpretation mec</context>
</contexts>
<marker>Hirakawa, Xu, Haase, 1996</marker>
<rawString>Hideki Hirakawa, Zhonghui Xu, and Kenneth Haase. 1996. Inherited feature-based similarity measure based on large semantic hierarchy and large text corpus. In COLING&apos;96 - Proceedings of the 16th International Conference on Computational Linguistics, pages 508-513. Copenhagen, Denmark, August 5-9, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Li</author>
<author>Naoki Abe</author>
</authors>
<title>Clustering words with the MDL principle.</title>
<date>1996</date>
<booktitle>In COLING&apos;96 - Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<pages>4--9</pages>
<location>Copenhagen, Denmark,</location>
<contexts>
<context position="1313" citStr="Li and Abe (1996)" startWordPosition="187" endWordPosition="190">as been an actively investigated issue on the research agenda of the logic-based paradigm of NLP in the late eighties (e.g., Charniak and Goldman (1988), Moore (1989), Pereira and Pollack (1991)). With the emergence of empirical methodologies in the early nineties, attention has almost completely shifted away from this topic. Since then, semantic issues have mainly been dealt with under a lexical perspective, viz, in terms of the resolution of lexico-semantic ambiguities (e.g., Schiitze (1998), Pedersen and Bruce (1998)) and the generation of lexical hierarchies from large text corpora (e.g., Li and Abe (1996), Hirakawa et al. (1996)) massively using statistical techniques. The research on semantic interpretation that was conducted in the pre-empiricist age of NLP was mainly driven by an interest in logical formalisms as carriers for appropriate semantic representations of NL utterances. With this representational bias, computational matters — how can semantic representation structures be properly derived from parse trees for a large variety of linguistic phenomena? — became a secondary issue. In particular, this research lacked entirely quantitative data reflecting the accuracy of the proposed sem</context>
</contexts>
<marker>Li, Abe, 1996</marker>
<rawString>Hang Li and Naoki Abe. 1996. Clustering words with the MDL principle. In COLING&apos;96 - Proceedings of the 16th International Conference on Computational Linguistics, pages 4-9. Copenhagen, Denmark, August 5-9, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Markert</author>
<author>Udo Hahn</author>
</authors>
<title>On the interaction of metonymies and anaphora.</title>
<date>1997</date>
<booktitle>In IJCAP97 - Proceedings of the 15th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1010--1015</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="9648" citStr="Markert and Hahn (1997)" startWordPosition="1449" endWordPosition="1452">erarchy &lt;(patient co-patient)&gt; werden_passive Speicher (memory) m t (with) &lt;plas-part instrument ...I&gt; Lexeme Nominal Preposition Ve VerbTrans Auxiliary &lt;subject: (agent patient)&gt; &lt;dirobject: (patient co-patient)&gt; Noun. Pronoun &lt;genitive attribute:0&gt; erweitern (extend) (Thus, the need for role composition in the DL language becomes evident.) The directed search in the concept graph of the domain knowledge requires sophisticated structural and topological constraints to be manageable at all. These constraints are encapsulated in a special path finding and path evaluation algorithm specified in Markert and Hahn (1997). Besides these conceptual constraints holding in the domain knowledge, we further attempt to reduce the search space for finding relation paths by two kinds of syntactic criteria. First, the search may be constrained by the type of dependency relation holding between the content words of the currently considered semantically interpretable subgraph (direct linkage), or it may be constrained by the intervening lexical material, viz, the non-content words (indirect linkage). Each of these syntactic constraints has an immediate mapping to conceptual ones. For some dependency configurations, howev</context>
</contexts>
<marker>Markert, Hahn, 1997</marker>
<rawString>Katja Markert and Udo Hahn. 1997. On the interaction of metonymies and anaphora. In IJCAP97 - Proceedings of the 15th International Joint Conference on Artificial Intelligence, pages 1010-1015. Nagoya, Japan, August 23-29, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>Unification-based semantic interpretation.</title>
<date>1989</date>
<booktitle>In Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>33--41</pages>
<location>Vancouver, B.C.,</location>
<contexts>
<context position="862" citStr="Moore (1989)" startWordPosition="119" endWordPosition="120">tation in which dependency structures are mapped to conceptual representations based on a parsimonious set of interpretation schemata. Our focus is on the empirical evaluation of this approach to semantic interpretation, i.e., its quality in terms of recall and precision. Measurements are taken with respect to two real-world domains, viz, information technology test reports and medical finding reports. 1 Introduction Semantic interpretation has been an actively investigated issue on the research agenda of the logic-based paradigm of NLP in the late eighties (e.g., Charniak and Goldman (1988), Moore (1989), Pereira and Pollack (1991)). With the emergence of empirical methodologies in the early nineties, attention has almost completely shifted away from this topic. Since then, semantic issues have mainly been dealt with under a lexical perspective, viz, in terms of the resolution of lexico-semantic ambiguities (e.g., Schiitze (1998), Pedersen and Bruce (1998)) and the generation of lexical hierarchies from large text corpora (e.g., Li and Abe (1996), Hirakawa et al. (1996)) massively using statistical techniques. The research on semantic interpretation that was conducted in the pre-empiricist ag</context>
<context position="29100" citStr="Moore (1989)" startWordPosition="4527" endWordPosition="4528">stic, i.e., conceptually unconstrained and therefore &amp;quot;unfriendly&amp;quot; test environment. 332 Judged from the figures of our recall data, there is no doubt, whatsoever, that conceptual coverage of the domain constitutes the bottleneck for any knowledge-based approach to NLP.7 Sublanguage differences are also mirrored systematically in these data, since medical texts adhere more closely to wellestablished concept taxonomies and writing standards than magazine articles in the IT domain. 4 Related Work After a period of active research within the logicbased paradigm (e.g., Charniak and Goldman (1988), Moore (1989), Pereira and Pollack (1991)), work on semantic interpretation has almost ceased with the emergence of the empiricist movement in NLP (cf. Bos et al. (1996) for one of the more recent studies dealing with logic-based semantic interpretation in the framework of the VERBMOBIL project). Only few methodological proposals for semantic computations were made since then (e.g., higherorder colored unification as a mechanism to avoid over-generation inherent to unconstrained higherorder unification (Gardent and Kohlhase, 1996)). An issue which has lately received more focused attention are ways to cope</context>
</contexts>
<marker>Moore, 1989</marker>
<rawString>Robert C. Moore. 1989. Unification-based semantic interpretation. In Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics, pages 33-41. Vancouver, B.C., Canada, 26-29 June 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergei Nirenburg</author>
<author>Kavi Mahesh</author>
<author>Stephen Beale</author>
</authors>
<title>Measuring semantic coverage.</title>
<date>1996</date>
<booktitle>In COLING &apos;96 - Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<pages>83--88</pages>
<location>Copenhagen, Denmark,</location>
<contexts>
<context position="30433" citStr="Nirenburg et al. (1996)" startWordPosition="4725" endWordPosition="4728">iguities. Within the underspecification framework of semantic representations, e.g., Dorre (1997) proposes a polynomial algorithm which constructs packed semantic representations directly from parse forests. All the previously mentioned studies (with the exception of the experimental setup in Done (1997)), however, lack an empirical foundation of their various claims. Though the MUC evaluation rounds (Chinchor et al., 1993) yield the flavor of an empirical assessment of semantic structures, their scope is far too limited to count as an adequate evaluation platform for semantic interpretation. Nirenburg et al. (1996) already criticize the &apos;black-box&apos; architecture underlying MUC-style evaluations, which precludes to draw serious conclusions from the shortcomings of MUC-style systems as far as single linguistic modules are concerned. More generally, in this paper the rationale underlying size (of the lexicons, knowledge or rule bases) as the major assessment category is questioned. Rather dimensions relating to the depth and breadth of the knowledge sources involved in complex system behavior should be taken more seriously into consideration. This is exactly what we intended to provide in this paper. As far</context>
</contexts>
<marker>Nirenburg, Mahesh, Beale, 1996</marker>
<rawString>Sergei Nirenburg, Kavi Mahesh, and Stephen Beale. 1996. Measuring semantic coverage. In COLING &apos;96 - Proceedings of the 16th International Conference on Computational Linguistics, pages 83-88. Copenhagen, Denmark, August 5-9, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Rebecca Bruce</author>
</authors>
<title>Knowledge lean word-sense disambiguation.</title>
<date>1998</date>
<booktitle>In AAAI&apos;98 -Proceedings of the 15th National Conference on Artificial Intelligence,</booktitle>
<pages>800--805</pages>
<location>Madison, Wisconsin,</location>
<contexts>
<context position="1221" citStr="Pedersen and Bruce (1998)" startWordPosition="171" endWordPosition="174">mation technology test reports and medical finding reports. 1 Introduction Semantic interpretation has been an actively investigated issue on the research agenda of the logic-based paradigm of NLP in the late eighties (e.g., Charniak and Goldman (1988), Moore (1989), Pereira and Pollack (1991)). With the emergence of empirical methodologies in the early nineties, attention has almost completely shifted away from this topic. Since then, semantic issues have mainly been dealt with under a lexical perspective, viz, in terms of the resolution of lexico-semantic ambiguities (e.g., Schiitze (1998), Pedersen and Bruce (1998)) and the generation of lexical hierarchies from large text corpora (e.g., Li and Abe (1996), Hirakawa et al. (1996)) massively using statistical techniques. The research on semantic interpretation that was conducted in the pre-empiricist age of NLP was mainly driven by an interest in logical formalisms as carriers for appropriate semantic representations of NL utterances. With this representational bias, computational matters — how can semantic representation structures be properly derived from parse trees for a large variety of linguistic phenomena? — became a secondary issue. In particular,</context>
</contexts>
<marker>Pedersen, Bruce, 1998</marker>
<rawString>Ted Pedersen and Rebecca Bruce. 1998. Knowledge lean word-sense disambiguation. In AAAI&apos;98 -Proceedings of the 15th National Conference on Artificial Intelligence, pages 800-805. Madison, Wisconsin, July 26-30, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>Martha E Pollack</author>
</authors>
<title>Incremental interpretation.</title>
<date>1991</date>
<journal>Artificial Intelligence,</journal>
<pages>50--1</pages>
<contexts>
<context position="890" citStr="Pereira and Pollack (1991)" startWordPosition="121" endWordPosition="124">h dependency structures are mapped to conceptual representations based on a parsimonious set of interpretation schemata. Our focus is on the empirical evaluation of this approach to semantic interpretation, i.e., its quality in terms of recall and precision. Measurements are taken with respect to two real-world domains, viz, information technology test reports and medical finding reports. 1 Introduction Semantic interpretation has been an actively investigated issue on the research agenda of the logic-based paradigm of NLP in the late eighties (e.g., Charniak and Goldman (1988), Moore (1989), Pereira and Pollack (1991)). With the emergence of empirical methodologies in the early nineties, attention has almost completely shifted away from this topic. Since then, semantic issues have mainly been dealt with under a lexical perspective, viz, in terms of the resolution of lexico-semantic ambiguities (e.g., Schiitze (1998), Pedersen and Bruce (1998)) and the generation of lexical hierarchies from large text corpora (e.g., Li and Abe (1996), Hirakawa et al. (1996)) massively using statistical techniques. The research on semantic interpretation that was conducted in the pre-empiricist age of NLP was mainly driven b</context>
<context position="29128" citStr="Pereira and Pollack (1991)" startWordPosition="4529" endWordPosition="4532">nceptually unconstrained and therefore &amp;quot;unfriendly&amp;quot; test environment. 332 Judged from the figures of our recall data, there is no doubt, whatsoever, that conceptual coverage of the domain constitutes the bottleneck for any knowledge-based approach to NLP.7 Sublanguage differences are also mirrored systematically in these data, since medical texts adhere more closely to wellestablished concept taxonomies and writing standards than magazine articles in the IT domain. 4 Related Work After a period of active research within the logicbased paradigm (e.g., Charniak and Goldman (1988), Moore (1989), Pereira and Pollack (1991)), work on semantic interpretation has almost ceased with the emergence of the empiricist movement in NLP (cf. Bos et al. (1996) for one of the more recent studies dealing with logic-based semantic interpretation in the framework of the VERBMOBIL project). Only few methodological proposals for semantic computations were made since then (e.g., higherorder colored unification as a mechanism to avoid over-generation inherent to unconstrained higherorder unification (Gardent and Kohlhase, 1996)). An issue which has lately received more focused attention are ways to cope with the tremendous complex</context>
</contexts>
<marker>Pereira, Pollack, 1991</marker>
<rawString>Fernando C.N. Pereira and Martha E. Pollack. 1991. Incremental interpretation. Artificial Intelligence, 50(1):37-82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Romacker</author>
<author>Katja Markert</author>
<author>Udo Hahn</author>
</authors>
<title>Lean semantic interpretation.</title>
<date>1999</date>
<booktitle>In IJCAP99 - Proceedings of the 16th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>868--875</pages>
<location>Stockholm, Sweden,</location>
<contexts>
<context position="4338" citStr="Romacker et al. (1999)" startWordPosition="650" endWordPosition="653">types of semantically interpretable subgraphs can be distinguished. The first one consists of lexical nodes which are labeled by content words only (lexical instances of verbs, nouns, adjectives or adverbs) and which are directly linked by a single dependency relation of any type whatsoever. Such a subgraph is illustrated in Figure 1 by Speicher- genatt - Computers. The second type of subgraph is also delimited by labels of content words but, in addition, a series of n 1. . . 4 intermediary lexical nodes may &apos;This notion and all subsequent criteria for interpretation are formally described in Romacker et al. (1999). 327 Figure 1: Dependency Graph for a Sample Sentence C:1 Context; IT-DOMAItt X pro SDRAM-Modulen IThe memory of the computer -- can -- with SDRAM-modules -- extended-- be! The memory of the computer can be extended with SDRAM-modules subject: kann verbpart: werden verbp/&apos; ppadjunct: erw itert Mit Spei her speciftert Der Computers specifiej„: des 1 COMPUTER-SYSTEM. 02 HAS-WORKING-MEMORY /EMORY 0 I 1 0 EXTENSION-PATIENT SDRAN-MODLILE. 03 EXTENSION-CO-PATIENT CD --tof,POSSIBLE MODALITY 0----o.:PRESENT TENSE Figure 2: Concept Graph for a Sample Sentence appear between these content words, all of</context>
<context position="12985" citStr="Romacker et al., 1999" startWordPosition="1943" endWordPosition="1946">ths for tuples of concepts during the sentence analysis process is called dynamic interpretation, since the latter process incorporates additional conceptual constraints on the fly. The above-mentioned conventions allow the specification of high-level semantic interpretation schemata covering a large variety of different syntactic constructions by a single schema. For instance, each syntactic construction for which no conceptual constraints apply (e.g., the interpretation of genitives, most adjectives, etc.) receives its semantic interpretation by instantiating the same interpretation schema (Romacker et al., 1999). The power of this approach comes from the fact that these highlevel schemata are instantiated in the course of the parsing process by exploiting the dense specifications of the inheritance hierarchies both at the grammar level (the lexeme class hierarchy), as well as the conceptual level (the concept and role hierarchies). We currently supply up to ten semantic interpretation schemata for declaratives, relatives, and pas329 sives at the clause level, complement subcategorization via PPs, auxiliaries, all tenses at the VP level, pre- and and postnominal modifiers at the NP level, and anaphori</context>
</contexts>
<marker>Romacker, Markert, Hahn, 1999</marker>
<rawString>Martin Romacker, Katja Markert, and Udo Hahn. 1999. Lean semantic interpretation. In IJCAP99 - Proceedings of the 16th International Joint Conference on Artificial Intelligence, pages 868-875. Stockholm, Sweden, July 31 - August 6, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Schulz</author>
<author>Udo Hahn</author>
</authors>
<title>Knowledge engineering by large-scale knowledge reuse: experience from the medical domain.</title>
<date>2000</date>
<booktitle>In Proceedings of the 7th International Conference on Principles of Knowledge Representation and Reasoning.</booktitle>
<location>Breckenridge, CO, USA,</location>
<contexts>
<context position="31344" citStr="Schulz and Hahn (2000)" startWordPosition="4864" endWordPosition="4867">exicons, knowledge or rule bases) as the major assessment category is questioned. Rather dimensions relating to the depth and breadth of the knowledge sources involved in complex system behavior should be taken more seriously into consideration. This is exactly what we intended to provide in this paper. As far as evaluation studies are concerned dealing with the assessment of semantic interpretations, few 7At least for the medical domain, we are currently actively pursuing research on the semiautomatic creation of large-scale ontologies from weak knowledge sources (medical terminologies); cf. Schulz and Hahn (2000). have been carried out, some of which under severe restrictions. For instance, Bean et al. (1998) narrow semantic interpretation down to a very limited range of spatial relations in anatomy, while Gomez et al. (1997) bias the result by preselecting only those phrases that were already covered by their domain models, thus optimizing for precision while shunting aside recall considerations. A recent study by Bonnema et al. (1997) comes closest to a serious confrontation with a wide range of real-world data (Dutch dialogues on a train travel domain). This study proceeds from a corpus of annotate</context>
</contexts>
<marker>Schulz, Hahn, 2000</marker>
<rawString>Stefan Schulz and Udo Hahn. 2000. Knowledge engineering by large-scale knowledge reuse: experience from the medical domain. In Proceedings of the 7th International Conference on Principles of Knowledge Representation and Reasoning. Breckenridge, CO, USA, April 12-15, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Schiitze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<pages>24--1</pages>
<contexts>
<context position="1194" citStr="Schiitze (1998)" startWordPosition="169" endWordPosition="170">mains, viz, information technology test reports and medical finding reports. 1 Introduction Semantic interpretation has been an actively investigated issue on the research agenda of the logic-based paradigm of NLP in the late eighties (e.g., Charniak and Goldman (1988), Moore (1989), Pereira and Pollack (1991)). With the emergence of empirical methodologies in the early nineties, attention has almost completely shifted away from this topic. Since then, semantic issues have mainly been dealt with under a lexical perspective, viz, in terms of the resolution of lexico-semantic ambiguities (e.g., Schiitze (1998), Pedersen and Bruce (1998)) and the generation of lexical hierarchies from large text corpora (e.g., Li and Abe (1996), Hirakawa et al. (1996)) massively using statistical techniques. The research on semantic interpretation that was conducted in the pre-empiricist age of NLP was mainly driven by an interest in logical formalisms as carriers for appropriate semantic representations of NL utterances. With this representational bias, computational matters — how can semantic representation structures be properly derived from parse trees for a large variety of linguistic phenomena? — became a seco</context>
</contexts>
<marker>Schiitze, 1998</marker>
<rawString>Hinrich Schiitze. 1998. Automatic word sense discrimination. Computational Linguistics, 24(1):97-124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Woods</author>
<author>James G Schmolze</author>
</authors>
<date>1992</date>
<booktitle>The KL-ONE family. Computers ei Mathematics with Applications,</booktitle>
<pages>23--2</pages>
<contexts>
<context position="6115" citStr="Woods and Schmolze, 1992" startWordPosition="918" endWordPosition="921">considerations follows that, e.g., the subgraph spanned by Speicher and SDRAM-Modulen does not form a semantically interpretable subgraph, since the content word erweitert intervenes on the linking path. Our approach to semantic interpretation subscribes to the principles of locality and compositionality. It operates on discrete and well-defined units (subgraphs) of the parse tree, and the results of semantic interpretation are incrementally combined by fusing semantically interpretable subgraphs. As semantic target language we have chosen the framework of KL-ONE-type description logics (DL) (Woods and Schmolze, 1992). Since these logics are characterized by a settheoretical semantics we stay on solid formal ground. Furthermore, we take advantage of the powerful inference engine of DL systems, the description classifier, which turns out to be essential for embedded reasoning during the semantic interpretation process. By equating the semantic representation language with the conceptual one, we follow arguments discussed by Allen (1993). The basic idea for semantic interpretation is as follows: Each lexical surface form of a content word is associated with a set of concept identifiers representing its (diff</context>
</contexts>
<marker>Woods, Schmolze, 1992</marker>
<rawString>William A. Woods and James G. Schmolze. 1992. The KL-ONE family. Computers ei Mathematics with Applications, 23(2/5):133-177.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>