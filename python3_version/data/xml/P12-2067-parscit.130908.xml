<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.026811">
<title confidence="0.9984595">
Exploiting Latent Information to Predict Diffusions of Novel Topics on
Social Networks
</title>
<author confidence="0.9938815">
Tsung-Ting Kuo1*, San-Chuan Hung1, Wei-Shih Lin1, Nanyun Peng1, Shou-De Lin1,
Wei-Fen Lin2
</author>
<affiliation confidence="0.8853005">
1Graduate Institute of Networking and Multimedia, National Taiwan University, Taiwan
2MobiApps Corporation, Taiwan
</affiliation>
<email confidence="0.995028">
*d97944007@csie.ntu.edu.tw
</email>
<sectionHeader confidence="0.997318" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9995685625">
This paper brings a marriage of two seemly
unrelated topics, natural language
processing (NLP) and social network
analysis (SNA). We propose a new task in
SNA which is to predict the diffusion of a
new topic, and design a learning-based
framework to solve this problem. We
exploit the latent semantic information
among users, topics, and social connections
as features for prediction. Our framework is
evaluated on real data collected from public
domain. The experiments show 16% AUC
improvement over baseline methods. The
source code and dataset are available at
http://www.csie.ntu.edu.tw/~d97944007/dif
fusion/
</bodyText>
<sectionHeader confidence="0.994765" genericHeader="keywords">
1 Background
</sectionHeader>
<bodyText confidence="0.999979226415095">
The diffusion of information on social networks
has been studied for decades. Generally, the
proposed strategies can be categorized into two
categories, model-driven and data-driven. The
model-driven strategies, such as independent
cascade model (Kempe et al., 2003), rely on
certain manually crafted, usually intuitive, models
to fit the diffusion data without using diffusion
history. The data-driven strategies usually utilize
learning-based approaches to predict the future
propagation given historical records of prediction
(Fei et al., 2011; Galuba et al., 2010; Petrovic et al.,
2011). Data-driven strategies usually perform
better than model-driven approaches because the
past diffusion behavior is used during learning
(Galuba et al., 2010).
Recently, researchers started to exploit content
information in data-driven diffusion models (Fei et
al., 2011; Petrovic et al., 2011; Zhu et al., 2011).
However, most of the data-driven approaches
assume that in order to train a model and predict
the future diffusion of a topic, it is required to
obtain historical records about how this topic has
propagated in a social network (Petrovic et al.,
2011; Zhu et al., 2011). We argue that such
assumption does not always hold in the real-world
scenario, and being able to forecast the propagation
of novel or unseen topics is more valuable in
practice. For example, a company would like to
know which users are more likely to be the source
of ‘viva voce’ of a newly released product for
advertising purpose. A political party might want
to estimate the potential degree of responses of a
half-baked policy before deciding to bring it up to
public. To achieve such goal, it is required to
predict the future propagation behavior of a topic
even before any actual diffusion happens on this
topic (i.e., no historical propagation data of this
topic are available). Lin et al. also propose an idea
aiming at predicting the inference of implicit
diffusions for novel topics (Lin et al., 2011). The
main difference between their work and ours is that
they focus on implicit diffusions, whose data are
usually not available. Consequently, they need to
rely on a model-driven approach instead of a data-
driven approach. On the other hand, our work
focuses on the prediction of explicit diffusion
behaviors. Despite the fact that no diffusion data of
novel topics is available, we can still design a data-
driven approach taking advantage of some explicit
diffusion data of known topics. Our experiments
show that being able to utilize such information is
critical for diffusion prediction.
</bodyText>
<sectionHeader confidence="0.982509" genericHeader="introduction">
2 The Novel-Topic Diffusion Model
</sectionHeader>
<bodyText confidence="0.999568">
We start by assuming an existing social network G
= (V, E), where V is the set of nodes (or user) v,
and E is the set of link e. The set of topics is
</bodyText>
<page confidence="0.986683">
344
</page>
<note confidence="0.6838995">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 344–348,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999924347826087">
denoted as T. Among them, some are considered as
novel topics (denoted as N), while the rest (R) are
used as the training records. We are also given a
set of diffusion records D = {d  |d = (src, dest, t)},
where src is the source node (or diffusion source),
dest is the destination node, and t is the topic of the
diffusion that belongs to R but not N. We assume
that diffusions cannot occur between nodes without
direct social connection; any diffusion pair implies
the existence of a link e = (src, dest) ∈ E. Finally,
we assume there are sets of keywords or tags that
relevant to each topic (including existing and novel
topics). Note that the set of keywords for novel
topics should be seen in that of existing topics.
From these sets of keywords, we construct a topic-
word matrix TW = (P(wordj  |topici))i,j of which the
elements stand for the conditional probabilities that
a word appears in the text of a certain topic.
Similarly, we also construct a user-word matrix
UW= (P(wordj  |useri))i,j from these sets of
keywords. Given the above information, the goal is
to predict whether a given link is active (i.e.,
belongs to a diffusion link) for topics in N.
</bodyText>
<subsectionHeader confidence="0.975027">
2.1 The Framework
</subsectionHeader>
<bodyText confidence="0.999982142857143">
The main challenge of this problem lays in that the
past diffusion behaviors of new topics are missing.
To address this challenge, we propose a supervised
diffusion discovery framework that exploits the
latent semantic information among users, topics,
and their explicit / implicit interactions. Intuitively,
four kinds of information are useful for prediction:
</bodyText>
<listItem confidence="0.9993877">
• Topic information: Intuitively, knowing the
signatures of a topic (e.g., is it about politics?)
is critical to the success of the prediction.
• User information: The information of a user
such as the personality (e.g., whether this user
is aggressive or passive) is generally useful.
• User-topic interaction: Understanding the users&apos;
preference on certain topics can improve the
quality of prediction.
• Global information: We include some global
</listItem>
<bodyText confidence="0.957024666666667">
features (e.g., topology info) of social network.
Below we will describe how these four kinds of
information can be modeled in our framework.
</bodyText>
<subsectionHeader confidence="0.992316">
2.2 Topic Information
</subsectionHeader>
<bodyText confidence="0.999854333333333">
We extract hidden topic category information to
model topic signature. In particular, we exploit the
Latent Dirichlet Allocation (LDA) method (Blei et
al., 2003), which is a widely used topic modeling
technique, to decompose the topic-word matrix TW
into hidden topic categories:
</bodyText>
<equation confidence="0.953709">
TW = TH * HW
</equation>
<bodyText confidence="0.999818310344827">
, where TH is a topic-hidden matrix, HW is hidden-
word matrix, and h is the manually-chosen
parameter to determine the size of hidden topic
categories. TH indicates the distribution of each
topic to hidden topic categories, and HW indicates
the distribution of each lexical term to hidden topic
categories. Note that TW and TH include both
existing and novel topics. We utilize THt,*, the row
vector of the topic-hidden matrix TH for a topic t,
as a feature set. In brief, we apply LDA to extract
the topic-hidden vector THt,* to model topic
signature (TG) for both existing and novel topics.
Topic information can be further exploited. To
predict whether a novel topic will be propagated
through a link, we can first enumerate the existing
topics that have been propagated through this link.
For each such topic, we can calculate its similarity
with the new topic based on the hidden vectors
generated above (e.g., using cosine similarity
between feature vectors). Then, we sum up the
similarity values as a new feature: topic similarity
(TS). For example, a link has previously
propagated two topics for a total of three times
{ACL, KDD, ACL}, and we would like to know
whether a new topic, EMNLP, will propagate
through this link. We can use the topic-hidden
vector to generate the similarity values between
EMNLP and the other topics (e.g., {0.6, 0.4, 0.6}),
and then sum them up (1.6) as the value of TS.
</bodyText>
<subsectionHeader confidence="0.989137">
2.3 User Information
</subsectionHeader>
<bodyText confidence="0.99945125">
Similar to topic information, we extract latent
personal information to model user signature (the
users are anonymized already). We apply LDA on
the user-word matrix UW:
</bodyText>
<equation confidence="0.972963">
UW = UM * MW
</equation>
<bodyText confidence="0.999071111111111">
, where UM is the user-hidden matrix, MW is the
hidden-word matrix, and m is the manually-chosen
size of hidden user categories. UM indicates the
distribution of each user to the hidden user
categories (e.g., age). We then use UMu,*, the row
vector of UM for the user u, as a feature set. In
brief, we apply LDA to extract the user-hidden
vector UMu,* for both source and destination nodes
of a link to model user signature (UG).
</bodyText>
<page confidence="0.995489">
345
</page>
<subsectionHeader confidence="0.731039">
2.4 User-Topic Interaction
</subsectionHeader>
<bodyText confidence="0.993273">
Modeling user-topic interaction turns out to be
non-trivial. It is not useful to exploit latent
semantic analysis directly on the user-topic matrix
</bodyText>
<equation confidence="0.5072865">
UR = UQ * QR , where UR represents how many
times each user is diffused for existing topic R (R
</equation>
<bodyText confidence="0.995943625">
∈ T), because UR does not contain information of
novel topics, and neither do UQ and QR. Given no
propagation record about novel topics, we propose
a method that allows us to still extract implicit
user-topic information. First, we extract from the
matrix TH (described in Section 2.2) a subset RH
that contains only information about existing topics.
Next we apply left division to derive another user-
hidden matrix UH:
UH = (RH \ URT)T = ((RHT RH )-1 RHT URT)T
Using left division, we generate the UH matrix
using existing topic information. Finally, we
exploit UHu,*, the row vector of the user-hidden
matrix UH for the user u, as a feature set.
Note that novel topics were included in the
process of learning the hidden topic categories on
RH; therefore the features learned here do
implicitly utilize some latent information of novel
topics, which is not the case for UM. Experiments
confirm the superiority of our approach.
Furthermore, our approach ensures that the hidden
categories in topic-hidden and user-hidden
matrices are identical. Intuitively, our method
directly models the user’s preference to topics’
signature (e.g., how capable is this user to
propagate topics in politics category?). In contrast,
the UM mentioned in Section 2.3 represents the
users’ signature (e.g., aggressiveness) and has
nothing to do with their opinions on a topic. In
short, we obtain the user-hidden probability vector
UHu,* as a feature set, which models user
preferences to latent categories (UPLC).
</bodyText>
<subsectionHeader confidence="0.974548">
2.5 Global Features
</subsectionHeader>
<bodyText confidence="0.999880222222222">
Given a candidate link, we can extract global
social features such as in-degree (ID) and out-
degree (OD). We tried other features such as
PageRank values but found them not useful.
Moreover, we extract the number of distinct topics
(NDT) for a link as a feature. The intuition behind
this is that the more distinct topics a user has
diffused to another, the more likely the diffusion
will happen for novel topics.
</bodyText>
<subsectionHeader confidence="0.996927">
2.6 Complexity Analysis
</subsectionHeader>
<bodyText confidence="0.999436">
The complexity to produce each feature is as below:
</bodyText>
<listItem confidence="0.999077818181818">
(1) Topic information: O(I * |T |* h * Bt) for LDA
using Gibbs sampling, where I is # of the
iterations in sampling, |T |is # of topics, and Bt
is the average # of tokens in a topic.
(2) User information: O(I * |V |* m * Bu) , where
|V |is # of users, and Bu is the average # of
tokens for a user.
(3) User-topic interaction: the time complexity is
O(h3 + h2 * |T |+ h * |T |* |V|).
(4) Global features: O(|D|), where |D |is # of
diffusions.
</listItem>
<sectionHeader confidence="0.998975" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999946333333333">
For evaluation, we try to use the diffusion records
of old topics to predict whether a diffusion link
exists between two nodes given a new topic.
</bodyText>
<subsectionHeader confidence="0.990716">
3.1 Dataset and Evaluation Metric
</subsectionHeader>
<bodyText confidence="0.999863758620689">
We first identify 100 most popular topic (e.g.,
earthquake) from the Plurk micro-blog site
between 01/2011 and 05/2011. Plurk is a popular
micro-blog service in Asia with more than 5
million users (Kuo et al., 2011). We manually
separate the 100 topics into 7 groups. We use
topic-wise 4-fold cross validation to evaluate our
method, because there are only 100 available
topics. For each group, we select 3/4 of the topics
as training and 1/4 as validation.
The positive diffusion records are generated
based on the post-response behavior. That is, if a
person x posts a message containing one of the
selected topic t, and later there is a person y
responding to this message, we consider a
diffusion of t has occurred from x to y (i.e., (x, y, t)
is a positive instance). Our dataset contains a total
of 1,642,894 positive instances out of 100 distinct
topics; the largest and smallest topic contains
303,424 and 2,166 diffusions, respectively. Also,
the same amount of negative instances for each
topic (totally 1,642,894) is sampled for binary
classification (similar to the setup in KDD Cup
2011 Track 2). The negative links of a topic t are
sampled randomly based on the absence of
responses for that given topic.
The underlying social network is created using
the post-response behavior as well. We assume
there is an acquaintance link between x and y if and
</bodyText>
<page confidence="0.997668">
346
</page>
<bodyText confidence="0.999973285714286">
only if x has responded to y (or vice versa) on at
least one topic. Eventually we generated a social
network of 163,034 nodes and 382,878 links.
Furthermore, the sets of keywords for each topic
are required to create the TW and UW matrices for
latent topic analysis; we simply extract the content
of posts and responses for each topic to create both
matrices. We set the hidden category number h = m
= 7, which is equal to the number of topic groups.
We use area under ROC curve (AUC) to
evaluate our proposed framework (Davis and
Goadrich, 2006); we rank the testing instances
based on their likelihood of being positive, and
compare it with the ground truth to compute AUC.
</bodyText>
<subsectionHeader confidence="0.999717">
3.2 Implementation and Baseline
</subsectionHeader>
<bodyText confidence="0.999986428571429">
After trying many classifiers and obtaining similar
results for all of them, we report only results from
LIBLINEAR with c=0.0001 (Fan et al., 2008) due
to space limitation. We remove stop-words, use
SCWS (Hightman, 2012) for tokenization, and
MALLET (McCallum, 2002) and GibbsLDA++
(Phan and Nguyen, 2007) for LDA.
There are three baseline models we compare the
result with. First, we simply use the total number
of existing diffusions among all topics between
two nodes as the single feature for prediction.
Second, we exploit the independent cascading
model (Kempe et al., 2003), and utilize the
normalized total number of diffusions as the
propagation probability of each link. Third, we try
the heat diffusion model (Ma et al., 2008), set
initial heat proportional to out-degree, and tune the
diffusion time parameter until the best results are
obtained. Note that we did not compare with any
data-driven approaches, as we have not identified
one that can predict diffusion of novel topics.
</bodyText>
<subsectionHeader confidence="0.949839">
3.3 Results
</subsectionHeader>
<bodyText confidence="0.9984074375">
The result of each model is shown in Table 1. All
except two features outperform the baseline. The
best single feature is TS. Note that UPLC performs
better than UG, which verifies our hypothesis that
maintaining the same hidden features across
different LDA models is better. We further conduct
experiments to evaluate different combinations of
features (Table 2), and found that the best one (TS
+ ID + NDT) results in about 16% improvement
over the baseline, and outperforms the combination
of all features. As stated in (Witten et al., 2011),
adding useless features may cause the performance
of classifiers to deteriorate. Intuitively, TS captures
both latent topic and historical diffusion
information, while ID and NDT provide
complementary social characteristics of users.
</bodyText>
<table confidence="0.999567333333333">
Method Feature AUC
Baseline Existing Diffusion 58.25%
Independent Cascade 51.53%
Heat Diffusion 56.08%
Learning Topic Signature (TG) 50.80%
Topic Similarity (TS) 69.93%
User Signature (UG) 56.59%
User Preferences to 61.33%
Latent Categories (UPLC)
In-degree (ID) 65.55%
Out-degree (OD) 59.73%
Number of Distinct Topics (NDT) 55.42%
</table>
<tableCaption confidence="0.990267">
Table 1: Single-feature results.
</tableCaption>
<table confidence="0.999843875">
Method Feature AUC
Baseline Existing Diffusion 58.25%
Learning ALL 65.06%
TS + UPLC + ID + NDT 67.67%
TS + UPLC + ID 64.80%
TS + UPLC + NDT 66.01%
TS + ID + NDT 73.95%
UPLC + ID + NDT 67.24%
</table>
<tableCaption confidence="0.974599">
Table 2: Feature combination results.
</tableCaption>
<sectionHeader confidence="0.998293" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.984856">
The main contributions of this paper are as below:
</bodyText>
<listItem confidence="0.68873875">
1. We propose a novel task of predicting the
diffusion of unseen topics, which has wide
applications in real-world.
2. Compared to the traditional model-driven or
</listItem>
<bodyText confidence="0.9739528">
content-independent data-driven works on
diffusion analysis, our solution demonstrates
how one can bring together ideas from two
different but promising areas, NLP and SNA,
to solve a challenging problem.
3. Promising experiment result (74% in AUC)
not only demonstrates the usefulness of the
proposed models, but also indicates that
predicting diffusion of unseen topics without
historical diffusion data is feasible.
</bodyText>
<sectionHeader confidence="0.999033" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<footnote confidence="0.669926">
This work was also supported by National Science
Council, National Taiwan University and Intel
Corporation under Grants NSC 100-2911-I-002-001,
and 101R7501.
</footnote>
<page confidence="0.996187">
347
</page>
<sectionHeader confidence="0.996329" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999903234375">
David M. Blei, Andrew Y. Ng &amp; Michael I. Jordan.
2003. Latent dirichlet allocation. J. Mach. Learn.
Res., 3.993-1022.
Jesse Davis &amp; Mark Goadrich. 2006. The relationship
between Precision-Recall and ROC curves.
Proceedings of the 23rd international conference on
Machine learning, Pittsburgh, Pennsylvania.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang &amp; Chih-Jen Lin. 2008. LIBLINEAR: A
Library for Large Linear Classification. J. Mach.
Learn. Res., 9.1871-74.
Hongliang Fei, Ruoyi Jiang, Yuhao Yang, Bo Luo &amp;
Jun Huan. 2011. Content based social behavior
prediction: a multi-task learning approach.
Proceedings of the 20th ACM international
conference on Information and knowledge
management, Glasgow, Scotland, UK.
Wojciech Galuba, Karl Aberer, Dipanjan Chakraborty,
Zoran Despotovic &amp; Wolfgang Kellerer. 2010.
Outtweeting the twitterers - predicting information
cascades in microblogs. Proceedings of the 3rd
conference on Online social networks, Boston, MA.
Hightman. 2012. Simple Chinese Words Segmentation
(SCWS).
David Kempe, Jon Kleinberg &amp; Eva Tardos. 2003.
Maximizing the spread of influence through a social
network. Proceedings of the ninth ACM SIGKDD
international conference on Knowledge discovery
and data mining, Washington, D.C.
Tsung-Ting Kuo, San-Chuan Hung, Wei-Shih Lin,
Shou-De Lin, Ting-Chun Peng &amp; Chia-Chun Shih.
2011. Assessing the Quality of Diffusion Models
Using Real-World Social Network Data. Conference
on Technologies and Applications of Artificial
Intelligence, 2011.
C.X. Lin, Q.Z. Mei, Y.L. Jiang, J.W. Han &amp; S.X. Qi.
2011. Inferring the Diffusion and Evolution of
Topics in Social Communities. Proceedings of the
IEEE International Conference on Data Mining,
2011.
Hao Ma, Haixuan Yang, Michael R. Lyu &amp; Irwin King.
2008. Mining social networks using heat diffusion
processes for marketing candidates selection.
Proceeding of the 17th ACM conference on
Information and knowledge management, Napa
Valley, California, USA.
Andrew Kachites McCallum. 2002. MALLET: A
Machine Learning for Language Toolkit.
Sasa Petrovic, Miles Osborne &amp; Victor Lavrenko. 2011.
RT to Win! Predicting Message Propagation in
Twitter. International AAAI Conference on Weblogs
and Social Media, 2011.
Xuan-Hieu Phan &amp; Cam-Tu Nguyen. 2007.
GibbsLDA++: A C/C++ implementation of latent
Dirichlet allocation (LDA).
Ian H. Witten, Eibe Frank &amp; Mark A. Hall. 2011. Data
Mining: Practical machine learning tools and
techniques. San Francisco: Morgan Kaufmann
Publishers Inc.
Jiang Zhu, Fei Xiong, Dongzhen Piao, Yun Liu &amp; Ying
Zhang. 2011. Statistically Modeling the
Effectiveness of Disaster Information in Social
Media. Proceedings of the 2011 IEEE Global
Humanitarian Technology Conference.
</reference>
<page confidence="0.998063">
348
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000277">
<title confidence="0.9992435">Exploiting Latent Information to Predict Diffusions of Novel Topics Social Networks</title>
<author confidence="0.993263">San-Chuan Wei-Shih Nanyun Shou-De</author>
<affiliation confidence="0.8378605">Institute of Networking and Multimedia, National Taiwan University, Corporation, Taiwan</affiliation>
<email confidence="0.887646">*d97944007@csie.ntu.edu.tw</email>
<abstract confidence="0.997105">This paper brings a marriage of two seemly unrelated topics, natural language processing (NLP) and social network analysis (SNA). We propose a new task in SNA which is to predict the diffusion of a new topic, and design a learning-based framework to solve this problem. We exploit the latent semantic information among users, topics, and social connections as features for prediction. Our framework is evaluated on real data collected from public domain. The experiments show 16% AUC improvement over baseline methods. The source code and dataset are available at http://www.csie.ntu.edu.tw/~d97944007/dif fusion/ 1 Background The diffusion of information on social networks has been studied for decades. Generally, the proposed strategies can be categorized into two categories, model-driven and data-driven. The model-driven strategies, such as independent cascade model (Kempe et al., 2003), rely on certain manually crafted, usually intuitive, models to fit the diffusion data without using diffusion history. The data-driven strategies usually utilize learning-based approaches to predict the future propagation given historical records of prediction (Fei et al., 2011; Galuba et al., 2010; Petrovic et al., 2011). Data-driven strategies usually perform better than model-driven approaches because the past diffusion behavior is used during learning (Galuba et al., 2010). Recently, researchers started to exploit content information in data-driven diffusion models (Fei et al., 2011; Petrovic et al., 2011; Zhu et al., 2011). However, most of the data-driven approaches assume that in order to train a model and predict the future diffusion of a topic, it is required to obtain historical records about how this topic has propagated in a social network (Petrovic et al., 2011; Zhu et al., 2011). We argue that such assumption does not always hold in the real-world scenario, and being able to forecast the propagation of novel or unseen topics is more valuable in practice. For example, a company would like to know which users are more likely to be the source ‘viva voce’ of a product for advertising purpose. A political party might want to estimate the potential degree of responses of a half-baked policy before deciding to bring it up to public. To achieve such goal, it is required to predict the future propagation behavior of a topic actual diffusion happens on this topic (i.e., no historical propagation data of this topic are available). Lin et al. also propose an idea aiming at predicting the inference of implicit diffusions for novel topics (Lin et al., 2011). The main difference between their work and ours is that they focus on implicit diffusions, whose data are usually not available. Consequently, they need to rely on a model-driven approach instead of a datadriven approach. On the other hand, our work focuses on the prediction of explicit diffusion behaviors. Despite the fact that no diffusion data of novel topics is available, we can still design a datadriven approach taking advantage of some explicit diffusion data of known topics. Our experiments show that being able to utilize such information is critical for diffusion prediction. 2 The Novel-Topic Diffusion Model start by assuming an existing social network where the set of nodes (or user) the set of link The set of topics is 344 of the 50th Annual Meeting of the Association for Computational pages 344–348, Republic of Korea, 8-14 July 2012. Association for Computational Linguistics as Among them, some are considered as topics (denoted as while the rest are used as the training records. We are also given a of diffusion records the source node (or diffusion source), the destination node, and the topic of the that belongs to not We assume that diffusions cannot occur between nodes without direct social connection; any diffusion pair implies existence of a link Finally, we assume there are sets of keywords or tags that to (including existing and novel topics). Note that the set of keywords for novel topics should be seen in that of existing topics. these sets of construct a topicmatrix TW = which the elements stand for the conditional probabilities that a word appears in the text of a certain topic. Similarly, we also construct a user-word matrix these sets of keywords. Given the above information, the goal is to predict whether a given link is active (i.e., to a diffusion link) for topics in Framework The main challenge of this problem lays in that the past diffusion behaviors of new topics are missing. To address this challenge, we propose a supervised diffusion discovery framework that exploits the latent semantic information among users, topics, and their explicit / implicit interactions. Intuitively, four kinds of information are useful for prediction: Topic Intuitively, knowing the signatures of a topic (e.g., is it about politics?) is critical to the success of the prediction. User The information of a user such as the personality (e.g., whether this user is aggressive or passive) is generally useful. User-topic Understanding the users&apos; preference on certain topics can improve the quality of prediction. Global We include some global features (e.g., topology info) of social network. Below we will describe how these four kinds of information can be modeled in our framework. Information We extract hidden topic category information to In particular, we exploit the Latent Dirichlet Allocation (LDA) method (Blei et al., 2003), which is a widely used topic modeling to decompose the topic-word matrix into hidden topic categories: * HW where a topic-hidden matrix, hiddenmatrix, and the manually-chosen parameter to determine the size of hidden topic the distribution of each to hidden topic categories, and the distribution of each lexical term to hidden topic Note that both and novel topics. We utilize the row of the topic-hidden matrix a topic as a feature set. In brief, we apply LDA to extract topic-hidden vector to model for both existing and novel topics. Topic information can be further exploited. To predict whether a novel topic will be propagated through a link, we can first enumerate the existing topics that have been propagated through this link. For each such topic, we can calculate its similarity with the new topic based on the hidden vectors generated above (e.g., using cosine similarity between feature vectors). Then, we sum up the values as a new feature: similarity For example, a link has previously propagated two topics for a total of three times {ACL, KDD, ACL}, and we would like to know whether a new topic, EMNLP, will propagate through this link. We can use the topic-hidden vector to generate the similarity values between EMNLP and the other topics (e.g., {0.6, 0.4, 0.6}), then sum them up (1.6) as the value of Information Similar to topic information, we extract latent information to model signature users are anonymized already). We apply LDA on user-word matrix * MW where the user-hidden matrix, the matrix, and the manually-chosen of hidden user categories. the distribution of each user to the hidden user (e.g., age). We then use the row of the user a feature set. In brief, we apply LDA to extract the user-hidden for both source and destination nodes a link to model signature 345 Interaction Modeling user-topic interaction turns out to be non-trivial. It is not useful to exploit latent semantic analysis directly on the user-topic matrix * QR where many each user is diffused for existing topic R not contain information of topics, and neither do Given no propagation record about novel topics, we propose a method that allows us to still extract implicit user-topic information. First, we extract from the in Section 2.2) a subset that contains only information about existing topics. Next we apply left division to derive another usermatrix = RH left division, we generate the using existing topic information. Finally, we the row vector of the user-hidden the user as a feature set. Note that novel topics were included in the process of learning the hidden topic categories on therefore the features learned here do implicitly utilize some latent information of novel which is not the case for Experiments confirm the superiority of our approach. Furthermore, our approach ensures that the hidden categories in topic-hidden and user-hidden matrices are identical. Intuitively, our method directly models the user’s preference to topics’ signature (e.g., how capable is this user to propagate topics in politics category?). In contrast, in Section 2.3 represents the users’ signature (e.g., aggressiveness) and has nothing to do with their opinions on a topic. In short, we obtain the user-hidden probability vector a feature set, which models to latent categories Features Given a candidate link, we can extract global features such as (ID) out- We tried other features such as PageRank values but found them not useful. we extract the of distinct topics a link as a feature. The intuition behind this is that the more distinct topics a user has diffused to another, the more likely the diffusion will happen for novel topics. Analysis The complexity to produce each feature is as below: Topic * h * for LDA Gibbs sampling, where # of the in sampling, is # of topics, and is the average # of tokens in a topic. User * * * , where is # of users, and is the average # of tokens for a user. User-topic the time complexity is + * + * Global where is # of diffusions. 3 Experiments For evaluation, we try to use the diffusion records of old topics to predict whether a diffusion link exists between two nodes given a new topic. and Evaluation Metric We first identify 100 most popular topic (e.g., earthquake) from the Plurk micro-blog site between 01/2011 and 05/2011. Plurk is a popular micro-blog service in Asia with more than 5 million users (Kuo et al., 2011). We manually separate the 100 topics into 7 groups. We use topic-wise 4-fold cross validation to evaluate our method, because there are only 100 available topics. For each group, we select 3/4 of the topics as training and 1/4 as validation. The positive diffusion records are generated based on the post-response behavior. That is, if a a message containing one of the topic and later there is a person responding to this message, we consider a of occurred from y, t) is a positive instance). Our dataset contains a total of 1,642,894 positive instances out of 100 distinct topics; the largest and smallest topic contains 303,424 and 2,166 diffusions, respectively. Also, the same amount of negative instances for each topic (totally 1,642,894) is sampled for binary classification (similar to the setup in KDD Cup Track 2). The negative links of a topic sampled randomly based on the absence of responses for that given topic. The underlying social network is created using the post-response behavior as well. We assume is an acquaintance link between and 346 if responded to vice versa) on at least one topic. Eventually we generated a social network of 163,034 nodes and 382,878 links. Furthermore, the sets of keywords for each topic required to create the for latent topic analysis; we simply extract the content of posts and responses for each topic to create both We set the hidden category number = 7, which is equal to the number of topic groups. We use area under ROC curve (AUC) to evaluate our proposed framework (Davis and Goadrich, 2006); we rank the testing instances based on their likelihood of being positive, and compare it with the ground truth to compute AUC. and Baseline After trying many classifiers and obtaining similar results for all of them, we report only results from LIBLINEAR with c=0.0001 (Fan et al., 2008) due to space limitation. We remove stop-words, use SCWS (Hightman, 2012) for tokenization, and MALLET (McCallum, 2002) and GibbsLDA++ (Phan and Nguyen, 2007) for LDA. There are three baseline models we compare the result with. First, we simply use the total number of existing diffusions among all topics between two nodes as the single feature for prediction. Second, we exploit the independent cascading model (Kempe et al., 2003), and utilize the normalized total number of diffusions as the propagation probability of each link. Third, we try the heat diffusion model (Ma et al., 2008), set initial heat proportional to out-degree, and tune the diffusion time parameter until the best results are obtained. Note that we did not compare with any data-driven approaches, as we have not identified one that can predict diffusion of novel topics. The result of each model is shown in Table 1. All except two features outperform the baseline. The single feature is Note that than which verifies our hypothesis that maintaining the same hidden features across different LDA models is better. We further conduct experiments to evaluate different combinations of (Table 2), and found that the best one results in about 16% improvement over the baseline, and outperforms the combination of all features. As stated in (Witten et al., 2011), adding useless features may cause the performance classifiers to deteriorate. Intuitively, both latent topic and historical diffusion while complementary social characteristics of users. Method Feature AUC Baseline Existing Diffusion 58.25% Independent Cascade 51.53% Heat Diffusion 56.08% Learning 50.80% 69.93% 56.59% 61.33% 65.55% 59.73% of 55.42% Table 1: Single-feature results. Method Feature AUC Baseline Existing Diffusion 58.25% Learning ALL 65.06% 67.67% 64.80% 66.01% 73.95% 67.24% Table 2: Feature combination results. 4 Conclusions The main contributions of this paper are as below: 1. We propose a novel task of predicting the diffusion of unseen topics, which has wide applications in real-world. 2. Compared to the traditional model-driven or content-independent data-driven works on diffusion analysis, our solution demonstrates how one can bring together ideas from two different but promising areas, NLP and SNA, to solve a challenging problem. 3. Promising experiment result (74% in AUC) not only demonstrates the usefulness of the proposed models, but also indicates that predicting diffusion of unseen topics without historical diffusion data is feasible.</abstract>
<note confidence="0.945478166666667">Acknowledgments This work was also supported by National Science Council, National Taiwan University and Intel Corporation under Grants NSC 100-2911-I-002-001, and 101R7501. 347</note>
<title confidence="0.85">References</title>
<author confidence="0.861279">David M Blei</author>
<author confidence="0.861279">Andrew Y Ng</author>
<author confidence="0.861279">Michael I Jordan</author>
<note confidence="0.8224745">2003. Latent dirichlet allocation. J. Mach. Learn. Res., 3.993-1022. Jesse Davis &amp; Mark Goadrich. 2006. The relationship between Precision-Recall and ROC curves. Proceedings of the 23rd international conference on Machine learning, Pittsburgh, Pennsylvania. Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang- Rui Wang &amp; Chih-Jen Lin. 2008. LIBLINEAR: A Library for Large Linear Classification. J. Mach. Learn. Res., 9.1871-74. Hongliang Fei, Ruoyi Jiang, Yuhao Yang, Bo Luo &amp; Jun Huan. 2011. Content based social behavior prediction: a multi-task learning approach. Proceedings of the 20th ACM international conference on Information and knowledge management, Glasgow, Scotland, UK. Wojciech Galuba, Karl Aberer, Dipanjan Chakraborty, Zoran Despotovic &amp; Wolfgang Kellerer. 2010. Outtweeting the twitterers predicting information cascades in microblogs. Proceedings of the 3rd conference on Online social networks, Boston, MA. Hightman. 2012. Simple Chinese Words Segmentation (SCWS). David Kempe, Jon Kleinberg &amp; Eva Tardos. 2003. Maximizing the spread of influence through a social network. Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, Washington, D.C. Tsung-Ting Kuo, San-Chuan Hung, Wei-Shih Lin, Shou-De Lin, Ting-Chun Peng &amp; Chia-Chun Shih. 2011. Assessing the Quality of Diffusion Models Using Real-World Social Network Data. Conference on Technologies and Applications of Artificial Intelligence, 2011. C.X. Lin, Q.Z. Mei, Y.L. Jiang, J.W. Han &amp; S.X. Qi. 2011. Inferring the Diffusion and Evolution of Topics in Social Communities. Proceedings of the IEEE International Conference on Data Mining, 2011. Hao Ma, Haixuan Yang, Michael R. Lyu &amp; Irwin King. 2008. Mining social networks using heat diffusion processes for marketing candidates selection. Proceeding of the 17th ACM conference on Information and knowledge management, Napa</note>
<address confidence="0.958118">Valley, California, USA.</address>
<note confidence="0.7544558">Andrew Kachites McCallum. 2002. MALLET: A Machine Learning for Language Toolkit. Sasa Petrovic, Miles Osborne &amp; Victor Lavrenko. 2011. RT to Win! Predicting Message Propagation in Twitter. International AAAI Conference on Weblogs and Social Media, 2011. Xuan-Hieu Phan &amp; Cam-Tu Nguyen. 2007. GibbsLDA++: A C/C++ implementation of latent Dirichlet allocation (LDA). Ian H. Witten, Eibe Frank &amp; Mark A. Hall. 2011. Data</note>
<title confidence="0.45198">Mining: Practical machine learning tools and</title>
<author confidence="0.938943">San Francisco Morgan Kaufmann</author>
<affiliation confidence="0.982444">Publishers Inc.</affiliation>
<address confidence="0.780363">Jiang Zhu, Fei Xiong, Dongzhen Piao, Yun Liu &amp; Ying</address>
<note confidence="0.6746448">Zhang. 2011. Statistically Modeling the Effectiveness of Disaster Information in Social Media. Proceedings of the 2011 IEEE Global Humanitarian Technology Conference. 348</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>3--993</pages>
<contexts>
<context position="6234" citStr="Blei et al., 2003" startWordPosition="987" endWordPosition="990">ation: The information of a user such as the personality (e.g., whether this user is aggressive or passive) is generally useful. • User-topic interaction: Understanding the users&apos; preference on certain topics can improve the quality of prediction. • Global information: We include some global features (e.g., topology info) of social network. Below we will describe how these four kinds of information can be modeled in our framework. 2.2 Topic Information We extract hidden topic category information to model topic signature. In particular, we exploit the Latent Dirichlet Allocation (LDA) method (Blei et al., 2003), which is a widely used topic modeling technique, to decompose the topic-word matrix TW into hidden topic categories: TW = TH * HW , where TH is a topic-hidden matrix, HW is hiddenword matrix, and h is the manually-chosen parameter to determine the size of hidden topic categories. TH indicates the distribution of each topic to hidden topic categories, and HW indicates the distribution of each lexical term to hidden topic categories. Note that TW and TH include both existing and novel topics. We utilize THt,*, the row vector of the topic-hidden matrix TH for a topic t, as a feature set. In bri</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng &amp; Michael I. Jordan. 2003. Latent dirichlet allocation. J. Mach. Learn. Res., 3.993-1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jesse Davis</author>
<author>Mark Goadrich</author>
</authors>
<title>The relationship between Precision-Recall and ROC curves.</title>
<date>2006</date>
<booktitle>Proceedings of the 23rd international conference on Machine learning,</booktitle>
<location>Pittsburgh, Pennsylvania.</location>
<contexts>
<context position="13241" citStr="Davis and Goadrich, 2006" startWordPosition="2201" endWordPosition="2204">or as well. We assume there is an acquaintance link between x and y if and 346 only if x has responded to y (or vice versa) on at least one topic. Eventually we generated a social network of 163,034 nodes and 382,878 links. Furthermore, the sets of keywords for each topic are required to create the TW and UW matrices for latent topic analysis; we simply extract the content of posts and responses for each topic to create both matrices. We set the hidden category number h = m = 7, which is equal to the number of topic groups. We use area under ROC curve (AUC) to evaluate our proposed framework (Davis and Goadrich, 2006); we rank the testing instances based on their likelihood of being positive, and compare it with the ground truth to compute AUC. 3.2 Implementation and Baseline After trying many classifiers and obtaining similar results for all of them, we report only results from LIBLINEAR with c=0.0001 (Fan et al., 2008) due to space limitation. We remove stop-words, use SCWS (Hightman, 2012) for tokenization, and MALLET (McCallum, 2002) and GibbsLDA++ (Phan and Nguyen, 2007) for LDA. There are three baseline models we compare the result with. First, we simply use the total number of existing diffusions am</context>
</contexts>
<marker>Davis, Goadrich, 2006</marker>
<rawString>Jesse Davis &amp; Mark Goadrich. 2006. The relationship between Precision-Recall and ROC curves. Proceedings of the 23rd international conference on Machine learning, Pittsburgh, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>XiangRui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBLINEAR: A Library for Large Linear Classification.</title>
<date>2008</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>9--1871</pages>
<contexts>
<context position="13550" citStr="Fan et al., 2008" startWordPosition="2251" endWordPosition="2254">s for latent topic analysis; we simply extract the content of posts and responses for each topic to create both matrices. We set the hidden category number h = m = 7, which is equal to the number of topic groups. We use area under ROC curve (AUC) to evaluate our proposed framework (Davis and Goadrich, 2006); we rank the testing instances based on their likelihood of being positive, and compare it with the ground truth to compute AUC. 3.2 Implementation and Baseline After trying many classifiers and obtaining similar results for all of them, we report only results from LIBLINEAR with c=0.0001 (Fan et al., 2008) due to space limitation. We remove stop-words, use SCWS (Hightman, 2012) for tokenization, and MALLET (McCallum, 2002) and GibbsLDA++ (Phan and Nguyen, 2007) for LDA. There are three baseline models we compare the result with. First, we simply use the total number of existing diffusions among all topics between two nodes as the single feature for prediction. Second, we exploit the independent cascading model (Kempe et al., 2003), and utilize the normalized total number of diffusions as the propagation probability of each link. Third, we try the heat diffusion model (Ma et al., 2008), set init</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang &amp; Chih-Jen Lin. 2008. LIBLINEAR: A Library for Large Linear Classification. J. Mach. Learn. Res., 9.1871-74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongliang Fei</author>
<author>Ruoyi Jiang</author>
<author>Yuhao Yang</author>
<author>Bo Luo</author>
<author>Jun Huan</author>
</authors>
<title>Content based social behavior prediction: a multi-task learning approach.</title>
<date>2011</date>
<booktitle>Proceedings of the 20th ACM international conference on Information and knowledge management,</booktitle>
<location>Glasgow, Scotland, UK.</location>
<contexts>
<context position="1502" citStr="Fei et al., 2011" startWordPosition="203" endWordPosition="206">ble at http://www.csie.ntu.edu.tw/~d97944007/dif fusion/ 1 Background The diffusion of information on social networks has been studied for decades. Generally, the proposed strategies can be categorized into two categories, model-driven and data-driven. The model-driven strategies, such as independent cascade model (Kempe et al., 2003), rely on certain manually crafted, usually intuitive, models to fit the diffusion data without using diffusion history. The data-driven strategies usually utilize learning-based approaches to predict the future propagation given historical records of prediction (Fei et al., 2011; Galuba et al., 2010; Petrovic et al., 2011). Data-driven strategies usually perform better than model-driven approaches because the past diffusion behavior is used during learning (Galuba et al., 2010). Recently, researchers started to exploit content information in data-driven diffusion models (Fei et al., 2011; Petrovic et al., 2011; Zhu et al., 2011). However, most of the data-driven approaches assume that in order to train a model and predict the future diffusion of a topic, it is required to obtain historical records about how this topic has propagated in a social network (Petrovic et a</context>
</contexts>
<marker>Fei, Jiang, Yang, Luo, Huan, 2011</marker>
<rawString>Hongliang Fei, Ruoyi Jiang, Yuhao Yang, Bo Luo &amp; Jun Huan. 2011. Content based social behavior prediction: a multi-task learning approach. Proceedings of the 20th ACM international conference on Information and knowledge management, Glasgow, Scotland, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wojciech Galuba</author>
<author>Karl Aberer</author>
</authors>
<title>Dipanjan Chakraborty, Zoran Despotovic &amp; Wolfgang Kellerer.</title>
<date>2010</date>
<booktitle>Proceedings of the 3rd conference on Online social networks,</booktitle>
<location>Boston, MA.</location>
<marker>Galuba, Aberer, 2010</marker>
<rawString>Wojciech Galuba, Karl Aberer, Dipanjan Chakraborty, Zoran Despotovic &amp; Wolfgang Kellerer. 2010. Outtweeting the twitterers - predicting information cascades in microblogs. Proceedings of the 3rd conference on Online social networks, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hightman</author>
</authors>
<title>Simple Chinese Words Segmentation (SCWS).</title>
<date>2012</date>
<contexts>
<context position="13623" citStr="Hightman, 2012" startWordPosition="2264" endWordPosition="2265">ponses for each topic to create both matrices. We set the hidden category number h = m = 7, which is equal to the number of topic groups. We use area under ROC curve (AUC) to evaluate our proposed framework (Davis and Goadrich, 2006); we rank the testing instances based on their likelihood of being positive, and compare it with the ground truth to compute AUC. 3.2 Implementation and Baseline After trying many classifiers and obtaining similar results for all of them, we report only results from LIBLINEAR with c=0.0001 (Fan et al., 2008) due to space limitation. We remove stop-words, use SCWS (Hightman, 2012) for tokenization, and MALLET (McCallum, 2002) and GibbsLDA++ (Phan and Nguyen, 2007) for LDA. There are three baseline models we compare the result with. First, we simply use the total number of existing diffusions among all topics between two nodes as the single feature for prediction. Second, we exploit the independent cascading model (Kempe et al., 2003), and utilize the normalized total number of diffusions as the propagation probability of each link. Third, we try the heat diffusion model (Ma et al., 2008), set initial heat proportional to out-degree, and tune the diffusion time paramete</context>
</contexts>
<marker>Hightman, 2012</marker>
<rawString>Hightman. 2012. Simple Chinese Words Segmentation (SCWS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Kempe</author>
<author>Jon Kleinberg</author>
<author>Eva Tardos</author>
</authors>
<title>Maximizing the spread of influence through a social network.</title>
<date>2003</date>
<booktitle>Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<location>Washington, D.C.</location>
<contexts>
<context position="1222" citStr="Kempe et al., 2003" startWordPosition="165" endWordPosition="168">xploit the latent semantic information among users, topics, and social connections as features for prediction. Our framework is evaluated on real data collected from public domain. The experiments show 16% AUC improvement over baseline methods. The source code and dataset are available at http://www.csie.ntu.edu.tw/~d97944007/dif fusion/ 1 Background The diffusion of information on social networks has been studied for decades. Generally, the proposed strategies can be categorized into two categories, model-driven and data-driven. The model-driven strategies, such as independent cascade model (Kempe et al., 2003), rely on certain manually crafted, usually intuitive, models to fit the diffusion data without using diffusion history. The data-driven strategies usually utilize learning-based approaches to predict the future propagation given historical records of prediction (Fei et al., 2011; Galuba et al., 2010; Petrovic et al., 2011). Data-driven strategies usually perform better than model-driven approaches because the past diffusion behavior is used during learning (Galuba et al., 2010). Recently, researchers started to exploit content information in data-driven diffusion models (Fei et al., 2011; Pet</context>
<context position="13983" citStr="Kempe et al., 2003" startWordPosition="2319" endWordPosition="2322">e AUC. 3.2 Implementation and Baseline After trying many classifiers and obtaining similar results for all of them, we report only results from LIBLINEAR with c=0.0001 (Fan et al., 2008) due to space limitation. We remove stop-words, use SCWS (Hightman, 2012) for tokenization, and MALLET (McCallum, 2002) and GibbsLDA++ (Phan and Nguyen, 2007) for LDA. There are three baseline models we compare the result with. First, we simply use the total number of existing diffusions among all topics between two nodes as the single feature for prediction. Second, we exploit the independent cascading model (Kempe et al., 2003), and utilize the normalized total number of diffusions as the propagation probability of each link. Third, we try the heat diffusion model (Ma et al., 2008), set initial heat proportional to out-degree, and tune the diffusion time parameter until the best results are obtained. Note that we did not compare with any data-driven approaches, as we have not identified one that can predict diffusion of novel topics. 3.3 Results The result of each model is shown in Table 1. All except two features outperform the baseline. The best single feature is TS. Note that UPLC performs better than UG, which v</context>
</contexts>
<marker>Kempe, Kleinberg, Tardos, 2003</marker>
<rawString>David Kempe, Jon Kleinberg &amp; Eva Tardos. 2003. Maximizing the spread of influence through a social network. Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, Washington, D.C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tsung-Ting Kuo</author>
<author>San-Chuan Hung</author>
<author>Wei-Shih Lin</author>
<author>Ting-Chun Peng Shou-De Lin</author>
<author>Chia-Chun Shih</author>
</authors>
<title>Assessing the Quality of Diffusion Models Using Real-World Social Network Data.</title>
<date>2011</date>
<booktitle>Conference on Technologies and Applications of Artificial Intelligence,</booktitle>
<marker>Kuo, Hung, Lin, Shou-De Lin, Shih, 2011</marker>
<rawString>Tsung-Ting Kuo, San-Chuan Hung, Wei-Shih Lin, Shou-De Lin, Ting-Chun Peng &amp; Chia-Chun Shih. 2011. Assessing the Quality of Diffusion Models Using Real-World Social Network Data. Conference on Technologies and Applications of Artificial Intelligence, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C X Lin</author>
<author>Q Z Mei</author>
<author>Y L Jiang</author>
<author>J W Han</author>
<author>S X Qi</author>
</authors>
<title>Inferring the Diffusion and Evolution of Topics in Social Communities.</title>
<date>2011</date>
<booktitle>Proceedings of the IEEE International Conference on Data Mining,</booktitle>
<contexts>
<context position="2943" citStr="Lin et al., 2011" startWordPosition="441" endWordPosition="444">mpany would like to know which users are more likely to be the source of ‘viva voce’ of a newly released product for advertising purpose. A political party might want to estimate the potential degree of responses of a half-baked policy before deciding to bring it up to public. To achieve such goal, it is required to predict the future propagation behavior of a topic even before any actual diffusion happens on this topic (i.e., no historical propagation data of this topic are available). Lin et al. also propose an idea aiming at predicting the inference of implicit diffusions for novel topics (Lin et al., 2011). The main difference between their work and ours is that they focus on implicit diffusions, whose data are usually not available. Consequently, they need to rely on a model-driven approach instead of a datadriven approach. On the other hand, our work focuses on the prediction of explicit diffusion behaviors. Despite the fact that no diffusion data of novel topics is available, we can still design a datadriven approach taking advantage of some explicit diffusion data of known topics. Our experiments show that being able to utilize such information is critical for diffusion prediction. 2 The No</context>
</contexts>
<marker>Lin, Mei, Jiang, Han, Qi, 2011</marker>
<rawString>C.X. Lin, Q.Z. Mei, Y.L. Jiang, J.W. Han &amp; S.X. Qi. 2011. Inferring the Diffusion and Evolution of Topics in Social Communities. Proceedings of the IEEE International Conference on Data Mining, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Ma</author>
<author>Haixuan Yang</author>
<author>Michael R Lyu</author>
<author>Irwin King</author>
</authors>
<title>Mining social networks using heat diffusion processes for marketing candidates selection.</title>
<date>2008</date>
<booktitle>Proceeding of the 17th ACM conference on Information and knowledge management,</booktitle>
<location>Napa Valley, California, USA.</location>
<contexts>
<context position="14140" citStr="Ma et al., 2008" startWordPosition="2345" endWordPosition="2348">=0.0001 (Fan et al., 2008) due to space limitation. We remove stop-words, use SCWS (Hightman, 2012) for tokenization, and MALLET (McCallum, 2002) and GibbsLDA++ (Phan and Nguyen, 2007) for LDA. There are three baseline models we compare the result with. First, we simply use the total number of existing diffusions among all topics between two nodes as the single feature for prediction. Second, we exploit the independent cascading model (Kempe et al., 2003), and utilize the normalized total number of diffusions as the propagation probability of each link. Third, we try the heat diffusion model (Ma et al., 2008), set initial heat proportional to out-degree, and tune the diffusion time parameter until the best results are obtained. Note that we did not compare with any data-driven approaches, as we have not identified one that can predict diffusion of novel topics. 3.3 Results The result of each model is shown in Table 1. All except two features outperform the baseline. The best single feature is TS. Note that UPLC performs better than UG, which verifies our hypothesis that maintaining the same hidden features across different LDA models is better. We further conduct experiments to evaluate different </context>
</contexts>
<marker>Ma, Yang, Lyu, King, 2008</marker>
<rawString>Hao Ma, Haixuan Yang, Michael R. Lyu &amp; Irwin King. 2008. Mining social networks using heat diffusion processes for marketing candidates selection. Proceeding of the 17th ACM conference on Information and knowledge management, Napa Valley, California, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>MALLET: A Machine Learning for Language Toolkit.</title>
<date>2002</date>
<contexts>
<context position="13669" citStr="McCallum, 2002" startWordPosition="2270" endWordPosition="2271"> We set the hidden category number h = m = 7, which is equal to the number of topic groups. We use area under ROC curve (AUC) to evaluate our proposed framework (Davis and Goadrich, 2006); we rank the testing instances based on their likelihood of being positive, and compare it with the ground truth to compute AUC. 3.2 Implementation and Baseline After trying many classifiers and obtaining similar results for all of them, we report only results from LIBLINEAR with c=0.0001 (Fan et al., 2008) due to space limitation. We remove stop-words, use SCWS (Hightman, 2012) for tokenization, and MALLET (McCallum, 2002) and GibbsLDA++ (Phan and Nguyen, 2007) for LDA. There are three baseline models we compare the result with. First, we simply use the total number of existing diffusions among all topics between two nodes as the single feature for prediction. Second, we exploit the independent cascading model (Kempe et al., 2003), and utilize the normalized total number of diffusions as the propagation probability of each link. Third, we try the heat diffusion model (Ma et al., 2008), set initial heat proportional to out-degree, and tune the diffusion time parameter until the best results are obtained. Note th</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew Kachites McCallum. 2002. MALLET: A Machine Learning for Language Toolkit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sasa Petrovic</author>
<author>Miles Osborne</author>
<author>Victor Lavrenko</author>
</authors>
<title>RT to Win! Predicting Message Propagation</title>
<date>2011</date>
<booktitle>in Twitter. International AAAI Conference on Weblogs and Social Media,</booktitle>
<contexts>
<context position="1547" citStr="Petrovic et al., 2011" startWordPosition="211" endWordPosition="214">44007/dif fusion/ 1 Background The diffusion of information on social networks has been studied for decades. Generally, the proposed strategies can be categorized into two categories, model-driven and data-driven. The model-driven strategies, such as independent cascade model (Kempe et al., 2003), rely on certain manually crafted, usually intuitive, models to fit the diffusion data without using diffusion history. The data-driven strategies usually utilize learning-based approaches to predict the future propagation given historical records of prediction (Fei et al., 2011; Galuba et al., 2010; Petrovic et al., 2011). Data-driven strategies usually perform better than model-driven approaches because the past diffusion behavior is used during learning (Galuba et al., 2010). Recently, researchers started to exploit content information in data-driven diffusion models (Fei et al., 2011; Petrovic et al., 2011; Zhu et al., 2011). However, most of the data-driven approaches assume that in order to train a model and predict the future diffusion of a topic, it is required to obtain historical records about how this topic has propagated in a social network (Petrovic et al., 2011; Zhu et al., 2011). We argue that su</context>
</contexts>
<marker>Petrovic, Osborne, Lavrenko, 2011</marker>
<rawString>Sasa Petrovic, Miles Osborne &amp; Victor Lavrenko. 2011. RT to Win! Predicting Message Propagation in Twitter. International AAAI Conference on Weblogs and Social Media, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuan-Hieu Phan</author>
<author>Cam-Tu Nguyen</author>
</authors>
<title>GibbsLDA++: A C/C++ implementation of latent Dirichlet allocation (LDA).</title>
<date>2007</date>
<contexts>
<context position="13708" citStr="Phan and Nguyen, 2007" startWordPosition="2274" endWordPosition="2277">er h = m = 7, which is equal to the number of topic groups. We use area under ROC curve (AUC) to evaluate our proposed framework (Davis and Goadrich, 2006); we rank the testing instances based on their likelihood of being positive, and compare it with the ground truth to compute AUC. 3.2 Implementation and Baseline After trying many classifiers and obtaining similar results for all of them, we report only results from LIBLINEAR with c=0.0001 (Fan et al., 2008) due to space limitation. We remove stop-words, use SCWS (Hightman, 2012) for tokenization, and MALLET (McCallum, 2002) and GibbsLDA++ (Phan and Nguyen, 2007) for LDA. There are three baseline models we compare the result with. First, we simply use the total number of existing diffusions among all topics between two nodes as the single feature for prediction. Second, we exploit the independent cascading model (Kempe et al., 2003), and utilize the normalized total number of diffusions as the propagation probability of each link. Third, we try the heat diffusion model (Ma et al., 2008), set initial heat proportional to out-degree, and tune the diffusion time parameter until the best results are obtained. Note that we did not compare with any data-dri</context>
</contexts>
<marker>Phan, Nguyen, 2007</marker>
<rawString>Xuan-Hieu Phan &amp; Cam-Tu Nguyen. 2007. GibbsLDA++: A C/C++ implementation of latent Dirichlet allocation (LDA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
<author>Mark A Hall</author>
</authors>
<title>Data Mining: Practical machine learning tools and techniques.</title>
<date>2011</date>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco:</location>
<contexts>
<context position="14955" citStr="Witten et al., 2011" startWordPosition="2479" endWordPosition="2482">not identified one that can predict diffusion of novel topics. 3.3 Results The result of each model is shown in Table 1. All except two features outperform the baseline. The best single feature is TS. Note that UPLC performs better than UG, which verifies our hypothesis that maintaining the same hidden features across different LDA models is better. We further conduct experiments to evaluate different combinations of features (Table 2), and found that the best one (TS + ID + NDT) results in about 16% improvement over the baseline, and outperforms the combination of all features. As stated in (Witten et al., 2011), adding useless features may cause the performance of classifiers to deteriorate. Intuitively, TS captures both latent topic and historical diffusion information, while ID and NDT provide complementary social characteristics of users. Method Feature AUC Baseline Existing Diffusion 58.25% Independent Cascade 51.53% Heat Diffusion 56.08% Learning Topic Signature (TG) 50.80% Topic Similarity (TS) 69.93% User Signature (UG) 56.59% User Preferences to 61.33% Latent Categories (UPLC) In-degree (ID) 65.55% Out-degree (OD) 59.73% Number of Distinct Topics (NDT) 55.42% Table 1: Single-feature results.</context>
</contexts>
<marker>Witten, Frank, Hall, 2011</marker>
<rawString>Ian H. Witten, Eibe Frank &amp; Mark A. Hall. 2011. Data Mining: Practical machine learning tools and techniques. San Francisco: Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiang Zhu</author>
<author>Fei Xiong</author>
<author>Dongzhen Piao</author>
<author>Yun Liu</author>
<author>Ying Zhang</author>
</authors>
<date>2011</date>
<booktitle>Statistically Modeling the Effectiveness of Disaster Information in Social Media. Proceedings of the 2011 IEEE Global Humanitarian Technology Conference.</booktitle>
<contexts>
<context position="1859" citStr="Zhu et al., 2011" startWordPosition="255" endWordPosition="258">nually crafted, usually intuitive, models to fit the diffusion data without using diffusion history. The data-driven strategies usually utilize learning-based approaches to predict the future propagation given historical records of prediction (Fei et al., 2011; Galuba et al., 2010; Petrovic et al., 2011). Data-driven strategies usually perform better than model-driven approaches because the past diffusion behavior is used during learning (Galuba et al., 2010). Recently, researchers started to exploit content information in data-driven diffusion models (Fei et al., 2011; Petrovic et al., 2011; Zhu et al., 2011). However, most of the data-driven approaches assume that in order to train a model and predict the future diffusion of a topic, it is required to obtain historical records about how this topic has propagated in a social network (Petrovic et al., 2011; Zhu et al., 2011). We argue that such assumption does not always hold in the real-world scenario, and being able to forecast the propagation of novel or unseen topics is more valuable in practice. For example, a company would like to know which users are more likely to be the source of ‘viva voce’ of a newly released product for advertising purp</context>
</contexts>
<marker>Zhu, Xiong, Piao, Liu, Zhang, 2011</marker>
<rawString>Jiang Zhu, Fei Xiong, Dongzhen Piao, Yun Liu &amp; Ying Zhang. 2011. Statistically Modeling the Effectiveness of Disaster Information in Social Media. Proceedings of the 2011 IEEE Global Humanitarian Technology Conference.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>