<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003127">
<title confidence="0.428283">
BOOK REVIEWS
FOUNDATIONS OF ILLOCUTIONARY LOGIC
</title>
<author confidence="0.837823">
John R. Searle and Daniel Vanderveken
</author>
<affiliation confidence="0.919480666666667">
(University of California, Berkeley, CA; and
Universite de Quebec, Trois Rivieres)
Cambridge, England: Cambridge University Press,
</affiliation>
<figure confidence="0.9064138">
1985, xi + 227 pp.
ISBN 0-521-26324-7; $34.50 (hb)
Reviewed by
Leonard Bole
Polish Academy of Sciences
</figure>
<bodyText confidence="0.996127333333333">
This book is a lecture on illocutionary logic. The first
chapters present this topic, discussing in detail the basic
notions and introducing notation, which is highly devel-
oped. The first chapter deals with the notion of illocu-
tionary force and its seven elements:
• Illocutionary point: type of utterance. All utterances
have been divided into five types: assertives, direc-
tives, commissives, declarations, and expressives.
Illocutionary point constitutes the most important and
basic element of illocutionary force, for it determines
the objective, the intention of the utterance. Other
elements only change its shade.
</bodyText>
<listItem confidence="0.991079741935484">
• Degree of strength of the illocutionary point: the
strength of the utterance, which determines the de-
gree of involvement of the interlocutor. The degree of
strength of the illocutionary point enables to differen-
tiate between two utterances of the same type, e.g., I
request, I implore.
• Mode of achievement: mode of utterance. This ele-
ment determines the position of the interlocutor. For
example, directives require expression by a person
respected by the person to whom the command is
addressed.
• Propositional content conditions: conditions pertain-
ing to the content of an utterance. Certain content
conditions are imposed on utterances. For example, it
is impossible to apologize for an event that is going to
take place or to propose a change of events that took
place in the past.
• Preparatory conditions: the set of conditions that
must occur for the utterance to be fulfilled. If for
example we request someone Please, stop shouting,
the preparatory condition of this utterance is that
someone is shouting.
• Sincerity conditions: the set of conditions pertaining
to the state of mental disposition, which must be
fulfilled if the utterance is to be sincere. For example,
it is impossible to say I am very sorry, but I am not
sorry at all.
• Degree of strength of the sincerity conditions. Be-
cause states of mental disposition can be expressed
with different strengths, this element serves to indi-
cate these differences.
</listItem>
<bodyText confidence="0.9999950625">
The second chapter introduces formal notation and
defines the above notions in terms of the theory of sets.
It also includes a formal presentation of some features
of illocutionary force and of its elements. The next
chapter discusses logical structure of the set of illocu-
tionary forces. Five elementary illocutionary forces are
introduced, which correspond to the five types of
utterances. The authors also deal with possible opera-
tions on illocutionary force. A set of all illocutionary
forces can be constructed in a recurrent way, using
these operations, starting from a set of elementary
illocutionary forces. The fourth chapter defines new
terms and relations connected with utterances. These
are terms pertaining to fulfillment of utterances (e.g.,
successful performance, non-defective performance,
failure), features of illocutionary act (e.g., relation of
strong commitment), and features relating to sets of
illocutionary acts (e.g., illocutionary consistency, con-
gruence). The fifth chapter includes a broader discus-
sion on some elements of illocutionary force.
The next three chapters constitute the actual content
of the book. They are an independent part, including a
formal and complex presentation of illocutionary logic.
The sixth chapter is a collection of all definitions,
axioms, and postulates of the above logic. The seventh
and eighth chapters include theorems concerning all the
notions discussed earlier and relations, together with
comments and outlines of argumentations.
The last chapter constitutes a sort of appendix to the
book, for it includes a set of English verbs, followed by
their semantic descriptions, annotated with their rela-
tionship to the logic discussed.
</bodyText>
<sectionHeader confidence="0.888141" genericHeader="abstract">
COMMENTS
</sectionHeader>
<bodyText confidence="0.999640692307692">
The book includes many examples illustrating the no-
tions introduced, making it easier for the readers to
acquire them. The authors present not only theorems
that &amp;quot;introduce something new&amp;quot; to the theory, but also
some that state that some rules of classical logic cannot
be transferred to illocutionary logic. Many theorems are
supported by interesting examples.
One of the disadvantages of the book is that the
authors have limited their discussion to the English
language. The book does not include any evaluation of
the application of the presented theory in the descrip-
tion of other languages.
After reading this book, the reader has an impression
</bodyText>
<page confidence="0.948136">
74 Computational Linguistics, Volume 14, Number 2, June 1988
</page>
<note confidence="0.681756">
Book Reviews Memory and Context for Language Interpretation
</note>
<bodyText confidence="0.985962105263158">
that the only objective of the book is description of
linguistic phenomena. It is difficult to imagine practical
application of the theory in natural-language processing
systems. Although the book was not aimed at present-
ing practical applications, a short chapter on this topic
could dispel the doubts of a reader studying this type of
problem for the first time. Furthermore, the addition of
an index would have facilitated the reader in returning
to certain issues or unmemorized definitions.
Still, this book is one of the more interesting recent
publications on the application of logic in natural-
language description. Reading it will inspire further
research on the logical structure of natural language,
and is highly recommended.
Leonard Bolc is the editor of several collections of papers on
various aspects of natural-language systems, including the
recent Natural-language parsing systems (Springer-Verlag).
His address is: Instytut Podstaw Informatyka, Polskiej Aka-
demii Nauk, PKiN, pok. 1050, 00-901 Warszawa, Poland.
</bodyText>
<sectionHeader confidence="0.969749333333333" genericHeader="method">
MEMORY AND CONTEXT FOR LANGUAGE
INTERPRETATION
(STUDIES IN NATURAL-LANGUAGE PROCESSING)
</sectionHeader>
<subsectionHeader confidence="0.739247">
Hiyan Alshawi
</subsectionHeader>
<affiliation confidence="0.3455375">
(SRI International, Cambridge, England)
Cambridge, England: Cambridge University Press,
</affiliation>
<figure confidence="0.809941428571429">
1987, ix + 188 pp.
ISBN 0-521-34059-4, $29.95 (hb) (20% discount to
ACL members)
Reviewed by
Jean-Pierre Corriveau
University of Toronto and
Bell-Northern Research
</figure>
<bodyText confidence="0.999401291139241">
This book is a reorganization of a 1983 doctoral thesis.
It seems little effort has been spent to take into account
the impressive amount of research in text comprehen-
sion since 1983. Indeed, the reference section lists only
five post-1983 entries. Nevertheless the book is very
relevant to the field of computational linguistics: it
constitutes an archetype of the assumptions, strategies,
and limitations faced by anyone attempting to imple-
ment a text-processing tool.
This relatively short book (188 pages, double-spaced)
is divided into two parts. The first, comprising four
chapters, overviews the model, which is then detailed in
the second part. The first chapter introduces the basic
assumptions and goals of the thesis; the research fo-
cuses on memory mechanisms, not inferencing or rea-
soning. The author states that the work is carried out in
terms of automatic natural-language processing (NLP)
and thus that he will avoid claims and suggestions about
human language processing. Indeed, the title is some-
what misleading: the use of the word &amp;quot;memory&amp;quot; in the
dissertation has little to do with human memory. In
essence, the thesis describes marker-passing algorithms
used to select between possible candidates for disam-
biguation. The algorithms search for candidates in a
database and choose between them according to the
current context, which simply constrains memory re-
trieval. The system, called Capture, was designed not
only for text processing but also to process collections
of English paragraphs and produce an output incorpo-
rable into a conventional database.
The second chapter overviews the representational
scheme and algorithms developed by the author. The
knowledge base is constructed out of two types of
assertions: specializations (IS-A declarations) and corre-
spondences, which take the form role Cl of owner D1 is
a role-specialization of role C2 whose owner is D2.
These types of assertions can carry further information
about the relationships between their arguments. This
information is encoded as a list of flags given as an
additional argument to the assertion. The author re-
marks that &amp;quot;the motivation for the choice of flags that
were defined for the memory formalism is simply that
these seem to be useful, in practice, for stating infor-
mation at the level of this kind of formalism&amp;quot;. Context
is represented by a collection of context factors, each of
which contributes activation to a particular set of mem-
ory entities (i.e., to the &amp;quot;objects&amp;quot; referred to in the
assertions). There are seven major types of context
factor, including recency, syntactic emphasis, deixis,
and a priori subject area. These are essentially static
rules that define how activation is managed for each
memory entity involved during comprehension. The
rules are applied for disambiguation and for defining the
focus space; that is, the set of most &amp;quot;activated&amp;quot; mem-
ory entities. In the remainder of the chapter, Alshawi
discusses his standard marker-passing model.
The third chapter addresses the problem of interpre-
tation. The author tackles noun phrase (NP) reference
interpretation, compound NPs, possessive NPs, with-
PPs, and word-sense disambiguation. Conditionals, ne-
gation, and &amp;quot;phenomena going beyond memory mech-
anisms&amp;quot; (e.g., modality and metaphor) are not handled.
The algorithms are simple to understand but often lack
proper motivation. In the fourth chapter, Alshawi dis-
cusses related research as of 1983. In particular, the
author acknowledges the strong influence of Fahlman&apos;s
work on marker-passing, and of Grosz&apos;s notion of global
focus.
The second part starts on page 76. In the rest of the
book, Alshawi details the ideas of the first part (see
summary table, p. 94) and elaborates on the Capture
feature that creates a relational database as the result of
text processing. The author concludes with a chapter on
the complexity of techniques for efficient retrieval from
a database, a topic too often ignored in NLP models.
I said above that this book is, in my opinion, an
archetype of the NLP thesis in computational linguis-
tics. The first appendix, which lists some of the 30 short
texts processed by Capture, confirms this: the examples
</bodyText>
<page confidence="0.2871">
Computational Linguistics, Volume 14, Number 2, June 1988 75
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.021420">
<title confidence="0.98778">BOOK REVIEWS FOUNDATIONS OF ILLOCUTIONARY LOGIC</title>
<author confidence="0.999973">John R Searle</author>
<author confidence="0.999973">Daniel Vanderveken</author>
<affiliation confidence="0.968797">(University of California, Berkeley, CA; and Universite de Quebec, Trois Rivieres) Cambridge, England: Cambridge University Press,</affiliation>
<address confidence="0.870442">1985, xi + 227 pp.</address>
<note confidence="0.904024">ISBN 0-521-26324-7; $34.50 (hb) Reviewed by</note>
<author confidence="0.972128">Leonard Bole</author>
<abstract confidence="0.990601881818182">Polish Academy of Sciences This book is a lecture on illocutionary logic. The first chapters present this topic, discussing in detail the basic notions and introducing notation, which is highly developed. The first chapter deals with the notion of illocutionary force and its seven elements: • Illocutionary point: type of utterance. All utterances have been divided into five types: assertives, directives, commissives, declarations, and expressives. Illocutionary point constitutes the most important and basic element of illocutionary force, for it determines the objective, the intention of the utterance. Other elements only change its shade. • Degree of strength of the illocutionary point: the strength of the utterance, which determines the degree of involvement of the interlocutor. The degree of strength of the illocutionary point enables to differenbetween two utterances of the same type, e.g., request, I implore. • Mode of achievement: mode of utterance. This element determines the position of the interlocutor. For example, directives require expression by a person respected by the person to whom the command is addressed. • Propositional content conditions: conditions pertaining to the content of an utterance. Certain content conditions are imposed on utterances. For example, it is impossible to apologize for an event that is going to take place or to propose a change of events that took place in the past. • Preparatory conditions: the set of conditions that must occur for the utterance to be fulfilled. If for we request someone stop shouting, the preparatory condition of this utterance is that someone is shouting. • Sincerity conditions: the set of conditions pertaining to the state of mental disposition, which must be fulfilled if the utterance is to be sincere. For example, is impossible to say am very sorry, but I am not sorry at all. • Degree of strength of the sincerity conditions. Because states of mental disposition can be expressed with different strengths, this element serves to indicate these differences. The second chapter introduces formal notation and defines the above notions in terms of the theory of sets. It also includes a formal presentation of some features of illocutionary force and of its elements. The next chapter discusses logical structure of the set of illocutionary forces. Five elementary illocutionary forces are introduced, which correspond to the five types of utterances. The authors also deal with possible operations on illocutionary force. A set of all illocutionary forces can be constructed in a recurrent way, using these operations, starting from a set of elementary illocutionary forces. The fourth chapter defines new terms and relations connected with utterances. These are terms pertaining to fulfillment of utterances (e.g., successful performance, non-defective performance, failure), features of illocutionary act (e.g., relation of strong commitment), and features relating to sets of illocutionary acts (e.g., illocutionary consistency, congruence). The fifth chapter includes a broader discussion on some elements of illocutionary force. The next three chapters constitute the actual content of the book. They are an independent part, including a formal and complex presentation of illocutionary logic. The sixth chapter is a collection of all definitions, axioms, and postulates of the above logic. The seventh and eighth chapters include theorems concerning all the notions discussed earlier and relations, together with comments and outlines of argumentations. The last chapter constitutes a sort of appendix to the book, for it includes a set of English verbs, followed by their semantic descriptions, annotated with their relationship to the logic discussed. COMMENTS The book includes many examples illustrating the notions introduced, making it easier for the readers to acquire them. The authors present not only theorems that &amp;quot;introduce something new&amp;quot; to the theory, but also some that state that some rules of classical logic cannot be transferred to illocutionary logic. Many theorems are supported by interesting examples. One of the disadvantages of the book is that the authors have limited their discussion to the English language. The book does not include any evaluation of the application of the presented theory in the description of other languages. After reading this book, the reader has an impression Linguistics, Volume 14, Number 2, June 1988 Book Reviews Memory and Context for Language Interpretation that the only objective of the book is description of linguistic phenomena. It is difficult to imagine practical application of the theory in natural-language processing systems. Although the book was not aimed at presenting practical applications, a short chapter on this topic could dispel the doubts of a reader studying this type of problem for the first time. Furthermore, the addition of an index would have facilitated the reader in returning to certain issues or unmemorized definitions. Still, this book is one of the more interesting recent publications on the application of logic in naturallanguage description. Reading it will inspire further research on the logical structure of natural language, and is highly recommended. Bolc the editor of several collections of papers on various aspects of natural-language systems, including the parsing systems His address is: Instytut Podstaw Informatyka, Polskiej Aka-</abstract>
<address confidence="0.310232">demii Nauk, PKiN, pok. 1050, 00-901 Warszawa, Poland.</address>
<title confidence="0.965737">MEMORY AND CONTEXT FOR LANGUAGE INTERPRETATION (STUDIES IN NATURAL-LANGUAGE PROCESSING)</title>
<author confidence="0.985214">Hiyan Alshawi</author>
<affiliation confidence="0.8756075">(SRI International, Cambridge, England) Cambridge, England: Cambridge University Press,</affiliation>
<address confidence="0.719704">1987, ix + 188 pp.</address>
<note confidence="0.985096333333333">ISBN 0-521-34059-4, $29.95 (hb) (20% discount to ACL members) Reviewed by</note>
<author confidence="0.99198">Jean-Pierre Corriveau</author>
<affiliation confidence="0.857368">University of Toronto and Bell-Northern Research</affiliation>
<abstract confidence="0.997176822784811">This book is a reorganization of a 1983 doctoral thesis. It seems little effort has been spent to take into account the impressive amount of research in text comprehension since 1983. Indeed, the reference section lists only five post-1983 entries. Nevertheless the book is very relevant to the field of computational linguistics: it constitutes an archetype of the assumptions, strategies, and limitations faced by anyone attempting to implement a text-processing tool. This relatively short book (188 pages, double-spaced) is divided into two parts. The first, comprising four chapters, overviews the model, which is then detailed in the second part. The first chapter introduces the basic assumptions and goals of the thesis; the research focuses on memory mechanisms, not inferencing or reasoning. The author states that the work is carried out in terms of automatic natural-language processing (NLP) and thus that he will avoid claims and suggestions about human language processing. Indeed, the title is somewhat misleading: the use of the word &amp;quot;memory&amp;quot; in the dissertation has little to do with human memory. In essence, the thesis describes marker-passing algorithms to select between possible candidates for disambiguation. The algorithms search for candidates in a database and choose between them according to the context, which simply constrains memory re- The system, called designed not only for text processing but also to process collections of English paragraphs and produce an output incorporable into a conventional database. The second chapter overviews the representational scheme and algorithms developed by the author. The knowledge base is constructed out of two types of declarations) and corretake the form Cl of owner D1 is a role-specialization of role C2 whose owner is D2. These types of assertions can carry further information about the relationships between their arguments. This information is encoded as a list of flags given as an additional argument to the assertion. The author remarks that &amp;quot;the motivation for the choice of flags that were defined for the memory formalism is simply that these seem to be useful, in practice, for stating information at the level of this kind of formalism&amp;quot;. Context is represented by a collection of context factors, each of which contributes activation to a particular set of memory entities (i.e., to the &amp;quot;objects&amp;quot; referred to in the assertions). There are seven major types of context factor, including recency, syntactic emphasis, deixis, and a priori subject area. These are essentially static rules that define how activation is managed for each memory entity involved during comprehension. The rules are applied for disambiguation and for defining the focus space; that is, the set of most &amp;quot;activated&amp;quot; memory entities. In the remainder of the chapter, Alshawi discusses his standard marker-passing model. The third chapter addresses the problem of interpretation. The author tackles noun phrase (NP) reference compound NPs, possessive NPs, with- PPs, and word-sense disambiguation. Conditionals, neand &amp;quot;phenomena going beyond memory mechanisms&amp;quot; (e.g., modality and metaphor) are not handled. The algorithms are simple to understand but often lack motivation. In the fourth chapter, Alshawi discusses related research as of 1983. In particular, the author acknowledges the strong influence of Fahlman&apos;s on marker-passing, and of Grosz&apos;s notion of focus. The second part starts on page 76. In the rest of the book, Alshawi details the ideas of the first part (see summary table, p. 94) and elaborates on the Capture feature that creates a relational database as the result of text processing. The author concludes with a chapter on the complexity of techniques for efficient retrieval from a database, a topic too often ignored in NLP models. I said above that this book is, in my opinion, an of the NLP thesis in computational linguistics. The first appendix, which lists some of the 30 short texts processed by Capture, confirms this: the examples</abstract>
<intro confidence="0.689109">Computational Linguistics, Volume 14, Number 2, June 1988 75</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>