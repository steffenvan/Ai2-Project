<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.112880">
<title confidence="0.9950415">
An Efficient Two Stage Approach to Robust Language
Interpretation
</title>
<author confidence="0.967056">
Carolyn Penstein Rose
</author>
<affiliation confidence="0.958145">
Carnegie Mellon University
</affiliation>
<address confidence="0.878479">
Baker Hall 135F
Pittsburgh, PA 15213
</address>
<email confidence="0.953926">
cproseacs.cmu.edu
</email>
<sectionHeader confidence="0.997848" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998756">
The most basic task of a natural language interface
is to map the user&apos;s utterance onto some meaning
representation which can then be used for further
processing. The three biggest challenges which con-
tinue to stand in the way of accomplishing even this
most basic task are extragrammaticality, ambiguity,
and recognition errors. The system presented here,
ROSE1: RObustness with Structural Evolution, re-
pairs extragrammatical input in two stages. The
first stage, Repair Hypothesis Formation, is respon-
sible for assembling a set of hypotheses about the
meaning of the ungrammatical utterance. This stage
is itself divided into two steps, Partial Parsing and
Combination. In the Combination step, the frag-
ments from a partial parse are assembled into a set
of meaning representation hypotheses. In ROSE&apos;s
second stage, Interaction with the user, the system
generates a set of queries and then uses the user&apos;s
answers to these queries to narrow down to a single
best meaning representation hypothesis.
</bodyText>
<sectionHeader confidence="0.9393805" genericHeader="keywords">
2 Comparison to Alternative
Approaches
</sectionHeader>
<bodyText confidence="0.995781451612903">
Rather than placing the full burden of robustness on
the parser itself, I argue that it is more economical
for Partial Parsing and Combination to be separate
steps in the Hypothesis Formation stage. Efforts
towards solving the problem of extragrammaticality
have primarily been in the direction of building flexi-
ble parsers. In principle, Minimum Distance Parsers
(Lehman, 1989; Hipp, 1992) have the greatest flex-
ibility. They fit an extragrammatical sentence to
the parsing grammar through a series of insertions,
deletions, and transpositions. Since any string can
be mapped onto any other string through a series
of insertions, deletions, and transpositions, this ap-
proach makes it possible to perform any desired re-
pair. The underlying assumption behind the MDP
approach is that the analysis of the string which de-
viates the least from the input string is most likely
&apos;ROSE is pronounced Rose, like the wine.
to be the best analysis. Thus, Minimum Distance
Parsing appears to be a reasonable approach.
In practice, however, Minimum Distance Parsing
has only been used successfully in very small and
limited domains. Lehman&apos;s core grammar, described
in (Lehman, 1989), has on the order of 300 rules,
and all of the inputs to her system can be assumed
to be commands to a calendar program. Hipp&apos;s Cir-
cuit Fix-It Shop system, described in (Hipp, 1992),
has a vocabulary of only 125 words and a grammar
size of only 500 rules. Flexible parsing algorithms
introduce a great deal of extra ambiguity. This in
turn may deem certain approaches impractical for
systems of realistic scale. Therefore, an important
question one must ask is whether the MDP approach
can scale up to a larger system and/or domain.
An example of a less powerful parsing algorithm
is Lavie&apos;s GLR* skipping parser described in (Lavie,
1995). This parser is capable of skipping over any
portion of an input utterance that cannot be incor-
porated into a grammatical analysis and recover the
analysis of the largest grammatical subset of the ut-
terance. Partial analyses for skipped portions of the
utterance are also returned by the parser. Thus,
whereas MDP considers insertions and transposi-
tions in addition to deletions, GLR* only considers
deletions. The weakness of this and other partial
parsing approaches (Abney, 1997; Nord, 1997; Srini-
vas et al., 1997; Federici, Montemagni, and Pirrelli,
1997) is that part of the original meaning of the ut-
terance may be thrown away with the portion(s) of
the utterance which are skipped if only the analy-
sis for the largest subset is returned, or part of the
analysis will be missing if the parser only attempts
to build a partial parse. These less powerful algo-
rithms trade coverage for speed. The idea is to in-
troduce enough flexibility to gain an acceptable level
of coverage at an acceptable computational expense.
The goal behind ROSE and other two stage ap-
proaches (Ehrlich and Hanrieder, 1997; Danieli and
Gerbino, 1995) is to increase the coverage possible
at a reasonable computational cost by introducing
a post-processing repair stage, which constructs a
complete meaning representation out of the frag-
</bodyText>
<page confidence="0.997788">
3
</page>
<bodyText confidence="0.996758125">
ments of a partial parse. Since the input to the that specifies that the temporal expression should be
second stage is a collection of partial parses, the ad- inserted into the when slot in the *busy frame. Other
ditional flexibility that is introduced at this second hypotheses are also evolved and tested as the genetic
stage can be channeled just to the part of the anal- programming system runs, such as the alternative
ysis that the parser does not have enough knowl- example included in Figure 1. A fitness function
edge to handle straightforwardly. This is unlike the ranks hypotheses, narrowing down on a small set.
MDP approach, where the full amount of flexibility The final result is selected through interaction with
is unnecessarily applied to every part of the anal- the user.
ysis. Therefore, this two stage process is more ef- References
ficient since the first stage is highly constrained by Abney, S. 1997. Partial parsing via finite-state cas-
the grammar and the results of this first stage are cades. In Proceedings of the Eight European Sum-
then used to constrain the search in the second stage. mer School In Logic, Language and Information,
Additionally, in cases where the limited flexibility Prague, Czech Republic.
parser is sufficient, the second stage can be entirely Danieli, M. and E. Gerbino. 1995. Metrics for evalu-
bypassed, yielding an even greater savings in time. ating dialogue strategies in a spoken language sys-
3 A Simple Example tem. In Working Notes of the AA AI Spring Sym-
The heart of the ROSE approach is the Combi- posium on Empirical Methods in Discourse Inter-
nation Mechanism, a genetic programming (Koza, pretation and Generation.
1992; Koza, 1994) environment in which programs Ehrlich, U. and G. Hanrieder. 1997. Robust speech
are evolved which combine the fragments of a partial parsing. In Proceedings of the Eight European
parse into a complete meaning representation struc- Summer School In Logic, Language and Informa-
ture. I present a simple example in Figure 1 for the tion, Prague, Czech Republic.
sake of clarity. This should not be taken to be an Federici, S., S. Montemagni, and V. Pirrelli. 1997.
indication of the full potential of this approach. Shallow parsing and text chunking: a view on un-
</bodyText>
<figureCaption confidence="0.790094037037037">
Chunks: derspecification in syntax. In Proceedings of the
1. Thursday Eight European Summer School In Logic, Lan-
((frame *simple time) guage and Information, Prague, Czech Republic.
(day-of-week thursday)) Hipp, D. R. 1992. Design and Development of
2. I am out Spoken Natural-Language Dialog Parsing Systems.
((frame *busy) Ph.D. thesis, Dept. of Computer Science, Duke
(who ((frame *i)))) University.
Ideal Repair Hypothesis: Koza, J. 1992. Genetic Programming: On the Pro-
(my-comb gramming of Computers by Means of Natural Se-
((frame *busy) (who ((frame *i)))) lection. MIT Press.
((frame *simple-time) (day-of-week thursday)) Koza, J. 1994. Genetic Programming II. MIT Press.
when) Lavie, A. 1995. A Grammar Based Robust Parser
An Alternative Repair Hypothesis: For Spontaneous Speech. Ph.D. thesis, School of
(my-comb Computer Science, Carnegie Mellon University.
((frame *busy) (who ((frame *i)))) Lehman, J. F. 1989. Adaptive Parsing: Self-
((frame *simple-time) (day-of-week thursday)) Extending Natural Language Interfaces. Ph.D.
why) thesis, School of Computer Science, Carnegie Mel-
Result of Ideal Hypothesis: lon University. CMU-CS-89-191.
((frame *busy) Nord, G. Van. 1997. Robist parsing with the head-
(who ((frame *i))) corner parser. In Proceedings of the Eight Euro-
(when ((frame *simple-time) pean Summer School In Logic, Language and In-
(day-of-week thursday)))) formation, Prague, Czech Republic.
Figure 1: Combination Example Srinivas, B., C. Doran, B. Hockey, and A. Joshi.
The ideal repair hypothesis for this example is one 1997. An approach to robust partial parsing and
4 evaluation metrics. In Proceedings of the Eight
European Summer School In Logic, Language and
Information, Prague, Czech Republic.
</figureCaption>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.122840">
<title confidence="0.999275">An Efficient Two Stage Approach to Robust Language Interpretation</title>
<author confidence="0.999253">Carolyn Penstein Rose</author>
<affiliation confidence="0.999963">Carnegie Mellon University</affiliation>
<address confidence="0.999252">Baker Hall 135F Pittsburgh, PA 15213</address>
<email confidence="0.98526">cproseacs.cmu.edu</email>
<abstract confidence="0.999113825581395">The most basic task of a natural language interface is to map the user&apos;s utterance onto some meaning representation which can then be used for further processing. The three biggest challenges which continue to stand in the way of accomplishing even this most basic task are extragrammaticality, ambiguity, and recognition errors. The system presented here, RObustness with Structural Evolution, repairs extragrammatical input in two stages. The first stage, Repair Hypothesis Formation, is responsible for assembling a set of hypotheses about the meaning of the ungrammatical utterance. This stage is itself divided into two steps, Partial Parsing and Combination. In the Combination step, the fragments from a partial parse are assembled into a set of meaning representation hypotheses. In ROSE&apos;s second stage, Interaction with the user, the system generates a set of queries and then uses the user&apos;s answers to these queries to narrow down to a single best meaning representation hypothesis. 2 Comparison to Alternative Approaches Rather than placing the full burden of robustness on the parser itself, I argue that it is more economical for Partial Parsing and Combination to be separate steps in the Hypothesis Formation stage. Efforts towards solving the problem of extragrammaticality have primarily been in the direction of building flexible parsers. In principle, Minimum Distance Parsers (Lehman, 1989; Hipp, 1992) have the greatest flexibility. They fit an extragrammatical sentence to the parsing grammar through a series of insertions, deletions, and transpositions. Since any string can be mapped onto any other string through a series of insertions, deletions, and transpositions, this approach makes it possible to perform any desired repair. The underlying assumption behind the MDP approach is that the analysis of the string which deviates the least from the input string is most likely &apos;ROSE is pronounced Rose, like the wine. to be the best analysis. Thus, Minimum Distance Parsing appears to be a reasonable approach. In practice, however, Minimum Distance Parsing has only been used successfully in very small and limited domains. Lehman&apos;s core grammar, described in (Lehman, 1989), has on the order of 300 rules, and all of the inputs to her system can be assumed to be commands to a calendar program. Hipp&apos;s Circuit Fix-It Shop system, described in (Hipp, 1992), has a vocabulary of only 125 words and a grammar size of only 500 rules. Flexible parsing algorithms introduce a great deal of extra ambiguity. This in turn may deem certain approaches impractical for systems of realistic scale. Therefore, an important question one must ask is whether the MDP approach can scale up to a larger system and/or domain. An example of a less powerful parsing algorithm is Lavie&apos;s GLR* skipping parser described in (Lavie, 1995). This parser is capable of skipping over any portion of an input utterance that cannot be incorporated into a grammatical analysis and recover the analysis of the largest grammatical subset of the utterance. Partial analyses for skipped portions of the utterance are also returned by the parser. Thus, whereas MDP considers insertions and transpositions in addition to deletions, GLR* only considers deletions. The weakness of this and other partial parsing approaches (Abney, 1997; Nord, 1997; Srinivas et al., 1997; Federici, Montemagni, and Pirrelli, 1997) is that part of the original meaning of the utterance may be thrown away with the portion(s) of the utterance which are skipped if only the analysis for the largest subset is returned, or part of the analysis will be missing if the parser only attempts to build a partial parse. These less powerful algorithms trade coverage for speed. The idea is to introduce enough flexibility to gain an acceptable level of coverage at an acceptable computational expense. The goal behind ROSE and other two stage approaches (Ehrlich and Hanrieder, 1997; Danieli and Gerbino, 1995) is to increase the coverage possible at a reasonable computational cost by introducing a post-processing repair stage, which constructs a meaning representation out of the frag- 3 ments of a partial parse. Since the input to the second stage is a collection of partial parses, the ad-ditional flexibility that is introduced at this second stage can be channeled just to the part of the anal-ysis that the parser does not have enough knowl-edge to handle straightforwardly. This is unlike the MDP approach, where the full amount of flexibility is unnecessarily applied to every part of the anal-ysis. Therefore, this two stage process is more ef-ficient since the first stage is highly constrained by the grammar and the results of this first stage are then used to constrain the search in the second stage. Additionally, in cases where the limited flexibility parser is sufficient, the second stage can be entirely bypassed, yielding an even greater savings in time. that specifies that the temporal expression should be into the in the *busy frame. Other hypotheses are also evolved and tested as the genetic programming system runs, such as the alternative example included in Figure 1. A fitness function ranks hypotheses, narrowing down on a small set. The final result is selected through interaction with the user.</abstract>
<note confidence="0.756227363636364">3 A Simple Example References The heart of the ROSE approach is the Combi-nation Mechanism, a genetic programming (Koza, 1992; Koza, 1994) environment in which programs are evolved which combine the fragments of a partial parse into a complete meaning representation struc-ture. I present a simple example in Figure 1 for the sake of clarity. This should not be taken to be an indication of the full potential of this approach. Abney, S. 1997. Partial parsing via finite-state cas- In of the Eight European Sum- School In Logic, Language Prague, Czech Republic. Chunks: Danieli, M. and E. Gerbino. 1995. Metrics for evalu-ating dialogue strategies in a spoken language sys- In Notes of the AA AI Spring Sym-posium on Empirical Methods in Discourse Inter-pretation and Generation. 1. Thursday Ehrlich, U. and G. Hanrieder. 1997. Robust speech In of the Eight European Summer School In Logic, Language and Informa-tion, Prague, Czech Republic. time) (day-of-week thursday)) Federici, S., S. Montemagni, and V. Pirrelli. 1997. Shallow parsing and text chunking: a view on unin syntax. In of the Eight European Summer School In Logic, Lan-guage and Information, Prague, Czech Republic. 2. I am out ((frame *busy) (who ((frame *i)))) D. R. 1992. and Development of Spoken Natural-Language Dialog Parsing Systems. Ph.D. thesis, Dept. of Computer Science, Duke University. Ideal Repair Hypothesis: J. 1992. Programming: On the Pro-gramming of Computers by Means of Natural Se- Press. (my-comb J. 1994. Programming II. Press. *busy) (who ((frame A. 1995. Grammar Based Robust Parser Spontaneous Speech. thesis, School of Computer Science, Carnegie Mellon University. ((frame *simple-time) (day-of-week thursday)) when) J. F. 1989. Parsing: Self- Natural Language Interfaces. thesis, School of Computer Science, Carnegie Mel- CMU-CS-89-191. An Alternative Repair Hypothesis: Nord, G. Van. 1997. Robist parsing with the headparser. In of the Eight Euro-pean Summer School In Logic, Language and In-formation, Prague, Czech Republic. (my-comb Srinivas, B., C. Doran, B. Hockey, and A. Joshi. 1997. An approach to robust partial parsing and metrics. In of the Eight European Summer School In Logic, Language and Information, Prague, Czech Republic. ((frame *busy) (who ((frame *i)))) ((frame *simple-time) (day-of-week thursday)) why) Result of Ideal Hypothesis: ((frame *busy) ((frame (when ((frame *simple-time) (day-of-week thursday)))) Figure 1: Combination Example The ideal repair hypothesis for this example is one 4</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>