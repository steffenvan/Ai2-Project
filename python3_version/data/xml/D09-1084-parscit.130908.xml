<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000015">
<title confidence="0.9622215">
A Relational Model of Semantic Similarity between Words using
Automatically Extracted Lexical Pattern Clusters from the Web
</title>
<figure confidence="0.543255833333333">
Danushka Bollegala *
danushka@mi.ci.i.
u-tokyo.ac.jp
Mitsuru Ishizuka
ishizuka@i.
u-tokyo.ac.jp
</figure>
<subsectionHeader confidence="0.296543">
Yutaka Matsuo
</subsectionHeader>
<bodyText confidence="0.8381575">
matsuo@biz-model.
t.u-tokyo.ac.jp
</bodyText>
<affiliation confidence="0.905233">
The University of Tokyo
</affiliation>
<address confidence="0.473802">
7-3-1, Hongo, Tokyo, 113-8656, Japan
</address>
<sectionHeader confidence="0.979715" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999658307692308">
Semantic similarity is a central concept
that extends across numerous fields such
as artificial intelligence, natural language
processing, cognitive science and psychol-
ogy. Accurate measurement of semantic
similarity between words is essential for
various tasks such as, document cluster-
ing, information retrieval, and synonym
extraction. We propose a novel model
of semantic similarity using the semantic
relations that exist among words. Given
two words, first, we represent the seman-
tic relations that hold between those words
using automatically extracted lexical pat-
tern clusters. Next, the semantic similar-
ity between the two words is computed
using a Mahalanobis distance measure.
We compare the proposed similarity mea-
sure against previously proposed seman-
tic similarity measures on Miller-Charles
benchmark dataset and WordSimilarity-
353 collection. The proposed method out-
performs all existing web-based seman-
tic similarity measures, achieving a Pear-
son correlation coefficient of 0.867 on the
Millet-Charles dataset.
</bodyText>
<sectionHeader confidence="0.999469" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.974156150943397">
Similarity is a fundamental concept in theories
of knowledge and behavior. Psychological ex-
periments have shown that similarity acts as an
organizing principle by which individuals clas-
sify objects, and make generalizations (Goldstone,
1994). For example, a biologist would classify
a newly found animal specimen based upon the
properties that it shares with existing categories
of animals. We can then make additional infer-
ences on the new specimen using the properties
Research Fellow of the Japan Society for the Promotion
of Science (JSPS)
known for the existing category. As the simi-
larity between two objects X and Y increases,
so does the probability of correctly inferring that
Y has the property T upon knowing that X has
T (Tenenbaum, 1999). Accurate measurement of
semantic similarity between lexical units such as
words or phrases is important for numerous tasks
in natural language processing such as word sense
disambiguation (Resnik, 1995), synonym extrac-
tion (Lin, 1998a), and automatic thesauri gener-
ation (Curran, 2002). In information retrieval,
similar or related words are used to expand user
queries to improve recall (Sahami and Heilman,
2006).
Semantic similarity is a context dependent and
dynamic phenomenon. New words are constantly
being created and existing words are assigned with
new senses on the Web. To decide whether two
words are semantically similar, it is important to
know the semantic relations that hold between the
words. For example, the words horse and cow can
be considered semantically similar because both
horses and cows are useful animals in agriculture.
Similarly, a horse and a car can be considered se-
mantically similar because cars, and historically
horses, are used for transportation. Semantic re-
lations such as X and Y are used in agriculture,
or X and Y are used for transportation, exist be-
tween two words X and Y in these examples. We
use bold-italics, X, to denote the slot of a word X
in a lexical pattern.
We propose a relational model to compute the
semantic similarity between two words. First, us-
ing snippets retrieved from a web search engine,
we present an automatic lexical pattern extraction
algorithm to represent the semantic relations that
exist between two words. For example, given two
words ostrich and bird, we extract X is a Y, X is
a large Y, and X is a flightless Y from the Web.
Using a set of semantically related words as train-
ing data, we evaluate the confidence of a lexical
</bodyText>
<page confidence="0.985518">
803
</page>
<note confidence="0.9966055">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 803–812,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.99992204">
pattern as an indicator of semantic similarity. For
example, the pattern X is a Y is a better indica-
tor of semantic similarity between X and Y than
the pattern X and Y. Consequently, we would like
to emphasize the former pattern by assigning it a
higher confidence score. It is noteworthy that all
lexical patterns are not independent – multiple lex-
ical patterns can express the same semantic rela-
tion. For example, the pattern X is a large Y sub-
sumes the more general pattern X is a Y and they
both indicate a hypernymic relationship between
X and Y. By clustering the semantically related
patterns into groups, we can both overcome the
data sparseness problem, and reduce the number
of parameters during training. To identify seman-
tically related patterns, we use a sequential pattern
clustering algorithm that is based on the distribu-
tional hypothesis (Harris, 1954). We represent two
words by a feature vector defined over the clus-
ters of patterns. Finally, the semantic similarity
is computed as the Mahalanobis distance between
points corresponding to the feature vectors. By
using Mahalanobis distance instead of Euclidean
distance, we can account for the inter-dependence
between semantic relations.
</bodyText>
<sectionHeader confidence="0.999879" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999377573333334">
Geometric models, such as multi-dimensional
scaling has been used in psychological ex-
periments analyzing the properties of similar-
ity (Krumhansl, 1978). These models represent
objects as points in some coordinate space such
that the observed dissimilarities between objects
correspond to the metric distances between the re-
spective points. Geometric models assume that
objects can be adequately represented as points in
some coordinate space and that dissimilarity be-
haves like a metric distance function satisfying
minimality, symmetry, and triangle inequality as-
sumptions. However, both dimensional and metric
assumptions are open to question.
Tversky (1977) proposed the contrast model of
similarity to overcome the problems in geometric
models. The contrast model relies on featural rep-
resentation of objects, and it is used to compute the
similarity between the representations of two ob-
jects. Similarity is defined as an increasing func-
tion of common features (i.e. features in common
to the two objects), and as a decreasing function of
distinctive features (i.e. features that apply to one
object but not the other). The attributes of objects
are primal to contrast model and it does not ex-
plicitly incorporate the relations between objects
when measuring similarity.
Hahn et al. (2003) define similarity between
two representations as the complexity required to
transform one representation into the other. Their
model of similarity is based on the Representa-
tional Distortion theory, which aims to provide
a theoretical framework of similarity judgments.
Their experiments using pattern sequences and ge-
ometric shapes show an inverse correlation be-
tween the number of transformations required to
convert one pattern (or shape) to another, and the
perceived similarity ratings by human subjects.
How to represent an object, which transformations
are allowed on a representation, and how to mea-
sure the complexity of a transformation, are all
important decisions in the transformational model
of similarity. Although distance measures such as
edit distance have been used to find approximate
matches in a dictionary, it is not obvious how to
compute semantic similarity between words using
representational distortion theory.
Given a taxonomy of concepts, a straightfor-
ward method to calculate similarity between two
words (or concepts) is to find the length of the
shortest path connecting the two words in the tax-
onomy (Rada et al., 1989). If a word is polyse-
mous (i.e. has more than one sense) then multi-
ple paths might exist between the two words. In
such cases, only the shortest path between any two
senses of the words is considered for calculating
similarity. A problem that is frequently acknowl-
edged with this approach is that it relies on the
notion that all links in the taxonomy represent a
uniform distance. As a solution to this problem,
Schickel-Zuber and Faltings (2007) propose ontol-
ogy structure based similarity (OSS) between two
concepts in an ontology, which is an asymmetric
distance function.
Resnik (1995) proposed a similarity measure
using information content. He defined the similar-
ity between two concepts C1 and C2 in the taxon-
omy as the maximum of the information content of
all concepts C that subsume both C1 and C2. Then
the similarity between two words is defined as the
maximum of the similarity between any concepts
that the words belong to. He used WordNet as the
taxonomy; information content is calculated using
the Brown corpus.
Li et al., (2003) combined structural seman-
</bodyText>
<page confidence="0.997109">
804
</page>
<bodyText confidence="0.999956166666667">
tic information from a lexical taxonomy, and in-
formation content from a corpus, in a nonlinear
model. They proposed a similarity measure that
uses shortest path length, depth and local density
in a taxonomy. Their experiments reported a Pear-
son correlation coefficient of 0.8914 on the Miller-
Charles benchmark dataset (Miller and Charles,
1998). Lin (1998b) defined the similarity between
two concepts as the information that is in common
to both concepts and the information contained in
each individual concept.
Cilibrasi and Vitanyi (2007) proposed a distance
metric between words using page-counts retrieved
from a web search engine. The proposed metric is
named Normalized Google Distance (NGD) and is
defined as the normalized information distance (Li
et al., 2004) between two strings. They evaluate
NGD in a word classification task. Unfortunately
NGD only uses page-counts of words and ignores
the context in which the words appear. Therefore,
it produces inaccurate similarity scores when one
or both words between which similarity is com-
puted are polysemous.
Sahami and Heilman (2006) measured semantic
similarity between two queries using snippets re-
turned for those queries by a search engine. For
each query, they collect snippets from a search
engine and represent each snippet as a TF-IDF-
weighted term vector. Each vector is L2 normal-
ized and the centroid of the set of vectors is com-
puted. Semantic similarity between two queries
is then defined as the inner product between the
corresponding centroid vectors. They did not
compare their similarity measure with taxonomy-
based similarity measures.
Chen et al., (2006) propose a web-based double-
checking model to compute the semantic similar-
ity between words. For two words X and Y , they
collect snippets for each word from a web search
engine. Then they count the number of occur-
rences of X in the snippets for Y , and Y in the
snippets for X. The two values are combined non-
linearly to compute the similarity between X and
Y . This method heavily depends on the search en-
gine’s ranking algorithm. Although two words X
and Y may be very similar, there is no reason to
believe that one can find Y in the snippets for X,
or vice versa. This observation is confirmed by the
experimental results in their paper which reports 0
similarity scores for many pairs of words in the
Miller-Charles dataset.
In our previous work (Bollegala et al., 2007),
we proposed a semantic similarity measure using
page counts and snippets retrieved from a Web
search engine. To compute the similarity between
two words X and Y , we queried a web search en-
gine using the query X AND Y and extract lex-
ical patterns that combine X and Y from snip-
pets. A feature vector is formed using frequen-
cies of 200 lexical patterns in snippets and four
co-occurrence measures: Dice coefficient, overlap
coefficient, Jaccard coefficient and pointwise mu-
tual information. We trained a two-class support
vector machine using automatically selected syn-
onymous and non-synonymous word pairs from
WordNet. This method reports a Pearson corre-
lation coefficient of 0.837 with Miller-Charles rat-
ings. However, it does not consider the relatedness
between patterns.
Gabrilovich and Markovitch (2007) represent
words using weighted vectors of Wikipedia-based
concepts, and define the similarity between words
as the cosine of the angle between the correspond-
ing vectors. Their method can be used to com-
pute similarity between words as well as between
texts. Although Wikipedia is growing in popular-
ity, not all concepts found on the Web have arti-
cles in Wikipedia. Specially, novel or not very
popular concepts are not adequately covered by
Wikipedia. Moreover, their method requires the
concepts to be independent. For non-independent,
hierarchical taxonomies such as open directory
project (ODP)1, their method produces suboptimal
results.
</bodyText>
<sectionHeader confidence="0.999797" genericHeader="method">
3 Relational Model of Similarity
</sectionHeader>
<bodyText confidence="0.967804071428571">
We propose a model to compute the semantic sim-
ilarity between two words a and b using the set
of semantic relations R(a, b) that hold between a
and b. We call the proposed model the relational
model of semantic similarity and it is defined by
the following equation,
sim(a, b) _ °(R(a, b)). (1)
Here, sim(a, b) is the semantic similarity between
the two words a and b, and ° is a weighting
function defined over the set of semantic relations
R(a, b). Given that a particular set of semantic
relations are known to hold between two words,
the function ° expresses our confidence on those
words being semantically similar.
</bodyText>
<footnote confidence="0.996814">
1http://www.dmoz.org
</footnote>
<page confidence="0.997808">
805
</page>
<bodyText confidence="0.997841260869565">
A semantic relation can be expressed in a num-
ber of ways. For example, given a taxonomy of
words such as the WordNet, semantic relations
(i.e. hypernymy, meronymy, synonymy etc.) be-
tween words can be directly looked up in the tax-
onomy. Alternatively, the labels of the edges in
the path connecting two words can be used as
semantic relations. However, in this paper we
do not assume the availability of manually cre-
ated resources such as dictionaries or taxonomies.
We represent semantic relations using automati-
cally extracted lexical patterns. Lexical patterns
have been successfully used to represent various
semantic relations between words such as hyper-
nymy (Hearst, 1992), and meronymy (Berland and
Charniak, 1999). Following these previous ap-
proaches, we represent R(a, b) as a set of lexical
patterns. Moreover, we denote the frequency of a
lexical pattern r for a word pair (a, b) by f(r, a, b).
So far we have not defined the functional form
of °. A straightforward approach is to use a lin-
early weighted combination of relations as shown
below,
</bodyText>
<equation confidence="0.993799">
°(R(a, b)) = � wz x f(rz, a, b). (2)
riER(a,b)
</equation>
<bodyText confidence="0.999553619047619">
Here, wz is the weight associated with the lexical
pattern rz and can be determined using training
data. However, this formulation has two funda-
mental drawbacks. First, the number of weight
parameters wz is equal to the number of lexical
patterns. Typically two words can co-occur in nu-
merous patterns. Consequently, we end up with a
large number of parameters in the model. Com-
plex models with a large number of parameters
are difficult to train because they tend to overfit to
the training data. Second, the linear combination
given in Equation 2 assumes the lexical patterns
to be mutually independent. However, in practice
this is not true. For example, both patterns X is a
Y and Y such as X indicate a hypernymic relation
between X and Y.
To overcome the above mentioned limitations,
we first cluster the lexical patterns to identify the
semantically related patterns. Our clustering algo-
rithm is detailed in section 3.2. Next, we define °
using the formed clusters as follows,
</bodyText>
<equation confidence="0.824266">
°(R(a, b)) = xbAQ. (3)
</equation>
<bodyText confidence="0.99950635483871">
Here, xab is a feature vector representing the
words a and b. Each formed cluster contributes
a feature in vector xab as described later in Sec-
tion 5. The vector a is a prototypical vector rep-
resenting synonymous word pairs. We compute
a as the centroid of feature vectors representing
synonymous word pairs. A is the inter-cluster cor-
relation matrix. The (i, j)-th element of matrix A
denotes the correlation between the two clusters cz
and cp Matrix A is expected to capture the de-
pendence between semantic relations. Intuitively,
if two clusters i and j are highly correlated, then
the (i, j)-th element of A will be closer to 1. Equa-
tion 3 computes the similarity between a word pair
(a, b) and a set of synonymous word pairs. In-
tuitively, if the relations that exist between a and
b are typical relations that hold between synony-
mous word pairs, then Equation 3 returns a high
similarity score for a and b.
The proposed relational model of semantic sim-
ilarity differs from feature models of similarity,
such as the contrast model (Tversky, 1977), in
that it is defined over the set of semantic relations
that exist between two words instead of the set of
features for each word. Specifically, in contrast
model, the similarity S(a, b) between two objects
a and b is defined in terms of the features common
to a and b, A n B, the features that are distinctive
to a, A − B, and the features that are distinctive to
b, B − A. The contrast model is formalized in the
following equation,
</bodyText>
<equation confidence="0.557981">
S(a, b) = Of(A n B) − af(A − B) − Of(B − A). (4)
</equation>
<bodyText confidence="0.999973095238096">
Here, the function f measures the salience of a
particular set of features, and non-negative param-
eters a, Q, and 0 determine the relative weights
assigned to the different components. However, in
the relational model of similarity we do not focus
on features of individual words but on relations be-
tween two words.
Modeling similarity as a phenomenon of rela-
tions between objects rather than features of indi-
vidual objects is central to computational models
of analogy-making such as the structure mapping
theory (SMT) (Falkenhainer et al., 1989). SMT
claims that an analogy is a mapping of knowl-
edge from one domain (base) into another (target)
which conveys that a system of relations known
to hold in the base also holds in the target. The
target objects do not have to resemble their corre-
sponding base objects. During the mapping pro-
cess, features of individual objects are dropped
and only relations are mapped. The proposed rela-
tional model of similarity uses this relational view
</bodyText>
<page confidence="0.992369">
806
</page>
<note confidence="0.4310455">
Ostrich, a large, flightless bird that lives in the dry grass-
lands of Africa.
</note>
<figureCaption confidence="0.554687">
Figure 1: A snippet returned for the query “ostrich
* * * * * bird”.
</figureCaption>
<bodyText confidence="0.980699571428571">
not. We do not skip the word not when gen-
erating subsequences. For example, this con-
dition ensures that from the snippet X is not a
Y, we do not produce the subsequence X is a
Y.
of similarity to compute semantic similarity be-
tween words.
</bodyText>
<subsectionHeader confidence="0.999859">
3.1 Extracting Lexical Patterns
</subsectionHeader>
<bodyText confidence="0.994067457142857">
To compute semantic similarity between two
words using the relational model (Equation 3),
we must first extract the numerous lexical pat-
terns from contexts in which those two words ap-
pear. For this purpose, we propose a pattern ex-
traction algorithm using snippets retrieved from
a web search engine. The proposed method re-
quires no language-dependent preprocessing such
as part-of-speech tagging or dependency parsing,
which can be both time consuming at Web scale,
and likely to produce incorrect results because of
the fragmented and ill-formed snippets.
Given two words a and b, we query a web search
engine using the wildcard query “a * * * * * b”
and download snippets. The “*” operator matches
one word or none in a web page. Therefore, our
wildcard query retrieves snippets in which a and
b appear within a window of seven words. We
attempt to approximate the local context of two
words using wildcard queries. For example, Fig-
ure 1 shows a snippet retrieved for the query “os-
trich * * * * * bird”.
For a snippet S, retrieved for a word pair (a, b),
first, we replace the two words a and b, respec-
tively, with two variables X and Y. We replace all
numeric values by D, a marker for digits. Next,
we generate all subsequences of words from S that
satisfy all of the following conditions.
(i). A subsequence must contain exactly one oc-
currence of each X and Y
(ii). The maximum length of a subsequence is L
words.
(iii). A subsequence is allowed to have gaps. How-
ever, we do not allow gaps of more than g
number of words. Moreover, the total length
of all gaps in a subsequence should not ex-
ceed G words.
(iv). We expand all negation contractions in a con-
text. For example, didn’t is expanded to did
Finally, we count the frequency of all generated
subsequences and only use subsequences that oc-
cur more than N times as lexical patterns.
The parameters L, g, G and N are set exper-
imentally, as explained later in Section 6. It is
noteworthy that the proposed pattern extraction al-
gorithm considers all the words in a snippet, and
is not limited to extracting patterns only from the
mid-fix (i.e., the portion of text in a snippet that
appears between the queried words). Moreover,
the consideration of gaps enables us to capture re-
lations between distant words in a snippet. We use
a modified version of the prefixspan algorithm (Pei
et al., 2004) to generate subsequences from a text
snippet. Specifically, we use the constraints (ii)-
(iv) to prune the search space of candidate sub-
sequences. For example, if a subsequence has
reached the maximum length L, or contains the
maximum number of gaps G, then we will not ex-
tend it further. By pruning the search space, we
can speed up the pattern generation process. How-
ever, none of these modifications affect the accu-
racy of the proposed semantic similarity measure
because the modified version of the prefixspan al-
gorithm still generates the exact set of patterns that
we would obtain if we used the original prefixspan
algorithm (i.e. without pruning) and subsequently
remove patterns that violate the above mentioned
constraints. For example, some patterns extracted
form the snippet shown in Figure 1 are: X, a large
Y, X a flightless Y, and X, large Y lives.
</bodyText>
<subsectionHeader confidence="0.999962">
3.2 Clustering Lexical Patterns
</subsectionHeader>
<bodyText confidence="0.999967230769231">
A semantic relation can be expressed using more
than one pattern. By grouping the semantically
related patterns, we can both reduce the model
complexity in Equation 2, and consider the depen-
dence among semantic relations in Equation 3. We
use the distributional hypothesis (Harris, 1954) to
find semantically related lexical patterns. The dis-
tributional hypothesis states that words that occur
in the same context have similar meanings. If two
lexical patterns are similarly distributed over a set
of word pairs, then from the distributional hypoth-
esis it follows that the two patterns must be similar.
We represent a pattern p by a vector p in which
</bodyText>
<page confidence="0.993701">
807
</page>
<bodyText confidence="0.999229875">
the i-th element is the frequency f(a2, b2, p) of p in
a word pair (a2, b2). Given a set P of patterns and
a similarity threshold 0, Algorithm 1 returns clus-
ters of similar patterns. First, the function SORT
sorts the patterns in the descending order of their
total occurrences in all word pairs. The total oc-
currences of a pattern p is defined as µ(p), and is
given by,
</bodyText>
<equation confidence="0.9982565">
µ(p) = � f(a, b, p). (5)
(a,b)EW
</equation>
<bodyText confidence="0.99917224">
Here, W is the set of word pairs. Then the outer
for-loop (starting at line 3), repeatedly takes a pat-
tern pi from the ordered set P, and in the inner for-
loop (starting at line 6), finds the cluster, c* (E C)
that is most similar to pi. Similarity between pi
and the cluster centroid cj is computed using co-
sine similarity. The centroid vector cj of cluster cj
is defined as the vector sum of all pattern vectors
for patterns in that cluster (i.e. cj = EpEc, p).
If the maximum similarity exceeds the threshold
0, we append pi to c* (line 14). Here, the op-
erator ® denotes vector addition. Otherwise, we
form a new cluster {pi} and append it to C, the
set of clusters. After all patterns are clustered,
we compute the (i, j) element of the inter-cluster
correlation matrix A (Equation 3) as the inner-
product between the centroid vectors ci and cj of
the corresponding clusters i and j. The parame-
ter 0 (E [0, 1]) determines the purity of the formed
clusters and is set experimentally in Section 5. Al-
gorithm 1 scales linearly with the number of pat-
terns. Moreover, sorting the patterns by their to-
tal word pair frequency prior to clustering ensures
that the final set of clusters contains the most com-
mon relations in the dataset.
</bodyText>
<sectionHeader confidence="0.997734" genericHeader="method">
4 Evaluation Procedure
</sectionHeader>
<bodyText confidence="0.999473166666667">
Evaluating a semantic similarity measure is diffi-
cult because the notion of semantic similarity is
subjective. Miller-Charles (1998) dataset has been
frequently used to benchmark semantic similar-
ity measures. Miller-Charles dataset contains 30
word pairs rated by a group of 38 human subjects.
The word pairs are rated on a scale from 0 (no sim-
ilarity) to 4 (perfect synonymy). Because of the
omission of two word pairs in earlier versions of
WordNet, most researchers had used only 28 pairs
for evaluations. The degree of correlation between
the human ratings in the benchmark dataset and
the similarity scores produced by an automatic se-
mantic similarity measure, can be considered as a
Algorithm 1 Sequential pattern clustering algo-
rithm.
Input: patterns P = {p1, ... , pn}, threshold 0
Output: clusters C
</bodyText>
<listItem confidence="0.987428210526316">
1: SORT(P)
2: C +— {}
3: for pattern pi E P do
4: max +— −oc
5: c* +— null
6: for cluster cj E C do
7: sim +— cosine(pi, cj)
8: if sim &gt; max then
9: max +— sim
10: c* +— cj
11: end if
12: end for
13: if max &gt; 0 then
14: c* +— c* ® pi
15: else
16: C +— C U {pi}
17: end if
18: end for
19: return C
</listItem>
<bodyText confidence="0.999541230769231">
measurement of how well the semantic similarity
measure captures the notion of semantic similar-
ity held by humans. In addition to Miller-Charles
dataset we also evaluate on the WordSimilarity-
353 (Finkelstein et al., 2002) dataset. In con-
trast to Miller-Charles dataset which has only 30
word pairs, WordSimilarity-353 dataset contains
353 word pairs. Each pair has 13-16 human judg-
ments, which were averaged for each pair to pro-
duce a single relatedness score. Following the pre-
vious work, we use both Miller-Charles dataset
and WordSimilarity-353 dataset to evaluate the
proposed semantic similarity measure.
</bodyText>
<sectionHeader confidence="0.965136" genericHeader="method">
5 Computing Semantic Similarity
</sectionHeader>
<bodyText confidence="0.999911818181818">
To extract lexical patterns that express numer-
ous semantic relations, we first select synonymous
words from WordNet synsets. A synset is a set
of synonymous words assigned for a particular
sense of a word in WordNet. We randomly select
2000 synsets of nouns from WordNet. From each
synset, a pair of synonymous words is selected.
For polysemous nouns, we selected synonyms
from the dominant sense. To perform a fair evalu-
ation, we do not select any words that appear in the
Miller-Charles dataset or the WordSimilarity-353
</bodyText>
<page confidence="0.995104">
808
</page>
<table confidence="0.8318215">
1.4 We use the clustering Algorithm 1 to cluster the
1.3 extracted patterns. The only parameter in Algo-
1.2 rithm 1, the clustering threshold 0, is set as fol-
1.1 lows. We vary the value of theta 0 from 0 to 1,
1 and use Algorithm 1 to cluster the extracted set
0.9 of patterns. We use the resultant set of clusters to
0.8 represent a word pair by a feature vector. We com-
0.7 pute a feature from each cluster as follows. First,
0.6 we assign a weight wij to a pattern pi that is in a
0.5 cluster cj as follows,
0.4
0.3
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Clustering Threshold
</table>
<figureCaption confidence="0.964553">
Figure 2: Average similarity vs. clustering thresh-
</figureCaption>
<figure confidence="0.9563505">
old 0
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Clustering Threshold
</figure>
<figureCaption confidence="0.999985">
Figure 3: Sparsity vs. clustering threshold 0
</figureCaption>
<bodyText confidence="0.999867842105263">
dataset, which are used later for evaluation pur-
poses. As we describe later, the clustering thresh-
old 0 is tuned using this set of 2000 word pairs
selected from the WordNet.
We use the YahooBOSS API2 and download
1000 snippets for each of those word pairs. Ex-
perimentally, we set the values for the parameters
in the pattern extraction algorithm (Section 3.1):
L = 5, g = 2, G = 4, and extract 5,238,637
unique patterns. However, only 1, 680,914 of
those patterns occur more than twice. Low fre-
quency patterns often contain misspellings and are
not suitable for training. Therefore, we selected
patterns that occur at least 10 times in the snip-
pet collection. Moreover, we remove very long
patterns (ca. over 20 characters). The final set
contains 140, 691 unique lexical patterns. The re-
mainder of the experiments described in the paper
use those patterns.
</bodyText>
<footnote confidence="0.594304">
2http://developer.yahoo.com/search/boss/
</footnote>
<equation confidence="0.969736">
µ(pi) (6)
EgEcj µ(q).
</equation>
<bodyText confidence="0.997821833333333">
Here, µ(q) is the total frequency of a pattern, and it
is given by Equation 5. Because we perform a hard
clustering on patterns, a pattern can belong to only
one cluster (i.e. wij = 0 for pi V cj). Finally, we
compute the value of the j-th feature in the feature
vector for word pair (a, b) as follows,
</bodyText>
<equation confidence="0.968607">
E wijf(a, b, pi). (7)
piEcj
</equation>
<bodyText confidence="0.999458714285714">
For each set of clusters, we compute the element
Aij of the corresponding inter-cluster correlation
matrix A by the cosine similarity between the cen-
troid vectors for clusters ci and cj. The prototype
vector Q in Equation 3 is computed as the vector
sum of individual feature vectors for the synony-
mous word pairs selected from the WordNet as de-
scribed above. We then use Equation 3 to compute
the average of similarity scores for synonymous
word pairs we selected from WordNet.
We select the 0 that maximizes the average
similarity score between those synonymous word
pairs. Formally, the optimal value of 0, 0 is given
by the following Equation,
</bodyText>
<equation confidence="0.9996755">
0 = argmaxgE[0,1] (|W |E(a,b)EW
1 �sim(a, b) . (8)
</equation>
<bodyText confidence="0.996023166666667">
Here, W is the set of synonymous word pairs
(a, b), |W  |is the total number of synonymous
word pairs (i.e. 2000 in our experiments), and
sim(a, b) is given by Equation 3. Because the av-
erages are taken over 2000 word pairs this proce-
dure gives a reliable estimate for 0. Moreover,
this method does not require negative training
instances such as, non-synonymous word pairs,
which are difficult to create manually. Average
similarity scores for various 0 values are shown
in Figure 2. From Figure 2, we see that initially
average similarity increases when 0 is increased.
</bodyText>
<equation confidence="0.836982">
wij =
</equation>
<page confidence="0.989794">
809
</page>
<bodyText confidence="0.999988259259259">
This is because clustering of semantically related
patterns reduces the sparseness in feature vectors.
Average similarity is stable within a range of 0 val-
ues between 0.5 and 0.7. However, increasing 0
beyond 0.7 results in a rapid drop of average sim-
ilarity. To explain this behavior consider Figure
3 where we plot the sparsity of the set of clusters
(i.e. the ratio between singletons to total clusters)
against threshold 0. As seen from Figure 3, high 0
values result in a high percentage of singletons be-
cause only highly similar patterns will form clus-
ters. Consequently, feature vectors for different
word pairs do not have many features in common.
The maximum average similarity score of 1.303 is
obtained with 0 = 0.7, corresponding to 17,015
total clusters out of which 12,476 are singletons
with exactly one pattern (sparsity = 0.733). For
the remainder of the experiments in this paper we
set 0 to this optimal value and use the correspond-
ing set of clusters to compute semantic similarity
by Equation 3. Similarity scores computed us-
ing Equation 3 can be greater than 1 (see Figure
2) because of the terms corresponding to the non-
diagonal elements in A. We do not normalize the
similarity scores to [0, 1] range in our experiments
because the evaluation metrics we use are insensi-
tive to linear transformations of similarity scores.
</bodyText>
<sectionHeader confidence="0.999244" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.999889328767124">
Table 1 compares the proposed method against
Miller-Charles ratings (MC), and previously pro-
posed web-based semantic similarity measures:
Jaccard, Dice, Overlap, PMI (Bollegala et al.,
2007), Normalized Google Distance (NGD) (Cili-
brasi and Vitanyi, 2007), Sahami and Heil-
man (SH) (2006), co-occurrence double checking
model (CODC) (Chen et al., 2006), and support
vector machine-based (SVM) approach (Bollegala
et al., 2007). The bottom row of Table 1 shows the
Pearson correlation coefficient of similarity scores
produced by each algorithm with MC. All similar-
ity scores, except for the human-ratings in Miller-
Charles dataset, are normalized to [0, 1] range for
the ease of comparison. It is noteworthy that the
Pearson correlation coefficient is invariant under a
linear transformation. All similarity scores shown
in Table 1 except for the proposed method are
taken from the original published papers.
The highest correlation is reported by the pro-
posed semantic similarity measure. The improve-
ment of the proposed method is statistically sig-
nificant (confidence interval [0.73, 0.93]) against
all the similarity measures compared in Table 1
except against the SVM approach. From Table 1
we see that measures that use contextual informa-
tion from snippets (e.g. SH, CODC, SVM, and
proposed) outperform the ones that use only co-
occurrence statistics (e.g. Jaccard, overlap, Dice,
PMI, and NGD) such as page-counts. This is be-
cause similarity measures that use contextual in-
formation are better equipped to compute the sim-
ilarity between polysemous words. Although both
SVM and proposed methods use lexical patterns,
unlike the proposed method, the SVM method
does not consider the relatedness between pat-
terns. The superior performance of the proposed
method is attributable to its consideration of relat-
edness of patterns.
Table 2 summarizes the previously proposed
WordNet-based semantic similarity measures. De-
spite the fact that the proposed method does not
use manually compiled resources such as Word-
Net for computing similarity, its performance is
comparable to similarity measures that use Word-
Net. We believe that the proposed method will
be useful to compute the semantic similarity be-
tween named-entities for which manually created
resources are either incomplete or do not exist.
We evaluate the proposed method using the
WordSimilarity-353 dataset. Experimental re-
sults are presented in Table 3. Following pre-
vious work, we use Spearman rank correlation
coefficient, which does not require ratings to be
linearly dependent, for the evaluations on this
dataset. Likewise with the Miller-Charles ratings,
we measure the correlation between the similar-
ity scores produced by the proposed method for
word pairs in the WordSimilarity-353 dataset and
the human ratings. A higher Spearman correla-
tion coefficient (value=0.504, confidence interval
[0.422, 0.578]) indicates a better agreement with
the human notion of semantic similarity. From Ta-
ble 3 we can see that the proposed method outper-
forms a wide variety of semantic similarity mea-
sures developed using numerous resources includ-
ing lexical resources such as WordNet and knowl-
edge sources such as Wikipedia (i.e. WikiRe-
late!). In contrast to the Miller-Charles dataset
which only contains common English words se-
lected from the WordNet, the WordSimilarity-353
dataset contains word pairs where one or both
words are named entities (e.g. (Maradona, foot-
</bodyText>
<page confidence="0.998204">
810
</page>
<tableCaption confidence="0.99975">
Table 1: Semantic similarity scores on Miller-Charles dataset
</tableCaption>
<table confidence="0.991301875">
Word Pair MC Jaccrad Dice Overlap PMI NGD SH CODC SVM Proposed
automobile-car 3.920 0.650 0.664 0.831 0.427 0.466 0.225 0.008 0.980 0.918
journey-voyage 3.840 0.408 0.424 0.164 0.468 0.556 0.121 0.005 0.996 1.000
gem-jewel 3.840 0.287 0.300 0.075 0.688 0.566 0.052 0.012 0.686 0.817
boy-lad 3.760 0.177 0.186 0.593 0.632 0.456 0.109 0.000 0.974 0.958
coast-shore 3.700 0.783 0.794 0.510 0.561 0.603 0.089 0.006 0.945 0.975
asylum-madhouse 3.610 0.013 0.014 0.082 0.813 0.782 0.052 0.000 0.773 0.794
magician-wizard 3.500 0.287 0.301 0.370 0.863 0.572 0.057 0.008 1.000 0.997
midday-noon 3.420 0.096 0.101 0.116 0.586 0.687 0.069 0.010 0.819 0.987
furnace-stove 3.110 0.395 0.410 0.099 1.000 0.638 0.074 0.011 0.889 0.878
food-fruit 3.080 0.751 0.763 1.000 0.449 0.616 0.045 0.004 0.998 0.940
bird-cock 3.050 0.143 0.151 0.144 0.428 0.562 0.018 0.006 0.593 0.867
bird-crane 2.970 0.227 0.238 0.209 0.516 0.563 0.055 0.000 0.879 0.846
implement-tool 2.950 1.000 1.000 0.507 0.297 0.750 0.098 0.005 0.684 0.496
brother-monk 2.820 0.253 0.265 0.326 0.623 0.495 0.064 0.007 0.377 0.265
crane-implement 1.680 0.061 0.065 0.100 0.194 0.559 0.039 0.000 0.133 0.056
brother-lad 1.660 0.179 0.189 0.356 0.645 0.505 0.058 0.005 0.344 0.132
car-journey 1.160 0.438 0.454 0.365 0.205 0.410 0.047 0.004 0.286 0.165
monk-oracle 1.100 0.004 0.005 0.002 0.000 0.579 0.015 0.000 0.328 0.798
food-rooster 0.890 0.001 0.001 0.412 0.207 0.568 0.022 0.000 0.060 0.018
coast-hill 0.870 0.963 0.965 0.263 0.350 0.669 0.070 0.000 0.874 0.356
forest-graveyard 0.840 0.057 0.061 0.230 0.495 0.612 0.006 0.000 0.547 0.442
monk-slave 0.550 0.172 0.181 0.047 0.611 0.698 0.026 0.000 0.375 0.243
coast-forest 0.420 0.861 0.869 0.295 0.417 0.545 0.060 0.000 0.405 0.150
lad-wizard 0.420 0.062 0.065 0.050 0.426 0.657 0.038 0.000 0.220 0.231
cord-smile 0.130 0.092 0.097 0.015 0.208 0.460 0.025 0.000 0 0.006
glass-magician 0.110 0.107 0.113 0.396 0.598 0.488 0.037 0.000 0.180 0.050
rooster-voyage 0.080 0.000 0.000 0.000 0.228 0.487 0.049 0.000 0.017 0.052
noon-string 0.080 0.116 0.123 0.040 0.102 0.488 0.024 0.000 0.018 0.000
Correlation - 0.260 0.267 0.382 0.549 0.205 0.580 0.694 0.834 0.867
Table 3: Results on WordSimilarity-353 dataset.
Method Correlation
WordNet Edges (Jarmasz, 1993) 0.27
Hirst &amp; St-Onge (1997) 0.34
Jiang &amp; Conrath (1998) 0.34
WikiRelate! (Strube and Ponzetto, 2006) 0.19-0.48
Leacock &amp; Chodrow (1998) 0.36
Lin (1998b) 0.36
Resnik (1995) 0.37
Proposed 0.504
</table>
<tableCaption confidence="0.9619575">
Table 2: Comparison with WordNet-based simi-
larity measures.
</tableCaption>
<table confidence="0.985525666666667">
Method Correlation
Edge-counting 0.664
Jiang &amp; Conrath (1998) 0.848
Lin (1998a) 0.822
Resnik (1995) 0.745
Li et al. (2003) 0.891
</table>
<bodyText confidence="0.9989701875">
ball) and (Jerusalem, Israel)). Because the pro-
posed method use snippets retrieved from a web
search engine, it is capable of extracting expres-
sive lexical patterns that can explicitly state the re-
lationship between two entities.
If we must compare n objects using a feature
model of similarity, then we only need to define
features for each of those n objects. However, in
the proposed relational model we must define re-
lations between all pairs of objects. In the case
where all n objects are different, this requires us to
define relations for n(n−1)/2 object pairs. Defin-
ing relations for all pairs can be computationally
costly for large n values. Efficiently comparing n
objects using a relational model is an interesting
future research direction of the current work.
</bodyText>
<sectionHeader confidence="0.999386" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999974153846154">
We proposed a relational model to measure the
semantic similarity between two words. First, to
represent the numerous semantic relations that ex-
ist between two words, we extract lexical patterns
from snippets retrieved from a web search engine.
Second, we cluster the extracted patterns to iden-
tify the semantically related patterns. Third, us-
ing the pattern clusters we define a feature vector
to represent two words and compute the semantic
similarity by taking into account the inter-cluster
correlation. The proposed method outperformed
all existing web-based semantic similarity mea-
sures on two benchmark datasets.
</bodyText>
<page confidence="0.996823">
811
</page>
<sectionHeader confidence="0.998345" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999875840425532">
M. Berland and E. Charniak. 1999. Finding parts in
very large corpora. In Proc. of ACL’99, pages 57–
64.
D. Bollegala, Y. Matsuo, and M. Ishizuka. 2007. Mea-
suring semantic similarity between words using web
search engines. In Proc. of WWW’07, pages 757–
766.
H. Chen, M. Lin, and Y. Wei. 2006. Novel association
measures using web search with double checking. In
Proc. of the COLING/ACL ’06, pages 1009–1016.
R.L. Cilibrasi and P.M.B. Vitanyi. 2007. The google
similarity distance. IEEE Transactions on Knowl-
edge and Data Engineering, 19(3):370–383.
J. Curran. 2002. Ensemble menthods for automatic
thesaurus extraction. In Proc. of EMNLP.
B. Falkenhainer, K.D. Forbus, and D. Gentner. 1989.
Structure mapping engine: Algorithm and examples.
Arti�cial Intelligence, 41:1–63.
L. Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin,
Z. Solan, G. Wolfman, and E. Ruppin. 2002. Plac-
ing search in context: The concept revisited. ACM
TOIS, 20:116–131.
E. Gabrilovich and S. Markovitch. 2007. Comput-
ing semantic relatedness using wikipedia-based ex-
plicit semantic analysis. In Proc. of IJCAI’07, pages
1606–1611.
R. L. Goldstone. 1994. The role of similarity in cat-
egorization: providing a groundwork. Cognition,
52:125–157.
U. Hahn, N. Chater, and L. B. Richardson. 2003. Sim-
ilarity as transformation. Cognition, 87:1–32.
Z. Harris. 1954. Distributional structure. Word,
10:146–162.
M.A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proc. of 14th
COLING, pages 539–545.
G. Hirst and D. St-Onge. 1997. Lexical chains as rep-
resentations of context for the detection and correc-
tion of malapropisms.
M. Jarmasz. 1993. Roget’s thesaurus as a lexical re-
source for natural language processing. Master’s
thesis, University of Ottawa.
J.J. Jiang and D.W. Conrath. 1998. Semantic similarity
based on corpus statistics and lexical taxonomy. In
Proc. of ROCLING’98.
C. L. Krumhansl. 1978. Concerning the applicability
of geometric models to similarity data: The inter-
relationship between similarity and spatial density.
Psychological Review, 85:445–463.
C. Leacock and M. Chodorow. 1998. Combining Lo-
cal Context and WordNet Similarity for Word Sense
Identi�cation. MIT.
M. Li, X. Chen, X. Li, B. Ma, and P.M.B. Vitanyi.
2004. The similarity metric. IEEE Transactions on
Information Theory, 50(12):3250–3264.
D. Lin. 1998a. Automatic retreival and clustering of
similar words. In Proc. of the 17th COLING, pages
768–774.
D. Lin. 1998b. An information-theoretic definition of
similarity. In Proc. of the 15th ICML, pages 296–
304.
G. Miller and W. Charles. 1998. Contextual corre-
lates of semantic similarity. Language and Cogni-
tive Processes, 6(1):1–28.
J. Pei, J. Han, B. Mortazavi-Asi, J. Wang, H. Pinto,
Q. Chen, U. Dayal, and M. Hsu. 2004. Mining se-
quential patterns by pattern-growth: the prefixspan
approach. IEEE Transactions on Knowledge and
Data Engineering, 16(11):1424–1440.
R. Rada, H. Mili, E. Bichnell, and M. Blettner. 1989.
Development and application of a metric on seman-
tic nets. IEEE Transactions on Systems, Man and
Cybernetics, 9(1):17–30.
P. Resnik. 1995. Using information content to evalu-
ate semantic similarity in a taxonomy. In Proc. of
IJCAI’95.
M. Sahami and T. Heilman. 2006. A web-based kernel
function for measuring the similarity of short text
snippets. In Proc. of WWW’06.
V. Schickel-Zuber and B. Faltings. 2007. Oss: A se-
mantic similarity function based on hierarchical on-
tologies. In Proc. of IJCAI’07, pages 551–556.
M. Strube and S. P. Ponzetto. 2006. Wikirelate! com-
puting semantic relatedness using wikipedia. In
Proc. of AAAI’ 06.
J. B. Tenenbaum. 1999. Bayesian modeling of human
concept learning. In NIPS’99.
A. Tversky. 1977. Features of similarity. Psychologi-
cal Review, 84:327–652.
D. McLean Y. Li, Zuhair A. Bandar. 2003. An ap-
proch for measuring semantic similarity between
words using multiple information sources. IEEE
Transactions on Knowledge and Data Engineering,
15(4):871–882.
</reference>
<page confidence="0.997866">
812
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.054656">
<title confidence="0.969167">A Relational Model of Semantic Similarity between Words using Automatically Extracted Lexical Pattern Clusters from the Web</title>
<author confidence="0.582273">Bollegala</author>
<abstract confidence="0.463019">danushka@mi.ci.i. u-tokyo.ac.jp Mitsuru u-tokyo.ac.jp Yutaka</abstract>
<affiliation confidence="0.929767">The University of</affiliation>
<address confidence="0.877772">7-3-1, Hongo, Tokyo, 113-8656, Japan</address>
<abstract confidence="0.993202222222222">Semantic similarity is a central concept that extends across numerous fields such as artificial intelligence, natural language processing, cognitive science and psychology. Accurate measurement of semantic similarity between words is essential for various tasks such as, document clustering, information retrieval, and synonym extraction. We propose a novel model of semantic similarity using the semantic relations that exist among words. Given two words, first, we represent the semantic relations that hold between those words using automatically extracted lexical pattern clusters. Next, the semantic similarity between the two words is computed using a Mahalanobis distance measure. We compare the proposed similarity measure against previously proposed semantic similarity measures on Miller-Charles benchmark dataset and WordSimilarity- 353 collection. The proposed method outperforms all existing web-based semantic similarity measures, achieving a Pearcorrelation coefficient of the Millet-Charles dataset.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Berland</author>
<author>E Charniak</author>
</authors>
<title>Finding parts in very large corpora.</title>
<date>1999</date>
<booktitle>In Proc. of ACL’99,</booktitle>
<pages>57--64</pages>
<contexts>
<context position="14003" citStr="Berland and Charniak, 1999" startWordPosition="2223" endWordPosition="2226">rds such as the WordNet, semantic relations (i.e. hypernymy, meronymy, synonymy etc.) between words can be directly looked up in the taxonomy. Alternatively, the labels of the edges in the path connecting two words can be used as semantic relations. However, in this paper we do not assume the availability of manually created resources such as dictionaries or taxonomies. We represent semantic relations using automatically extracted lexical patterns. Lexical patterns have been successfully used to represent various semantic relations between words such as hypernymy (Hearst, 1992), and meronymy (Berland and Charniak, 1999). Following these previous approaches, we represent R(a, b) as a set of lexical patterns. Moreover, we denote the frequency of a lexical pattern r for a word pair (a, b) by f(r, a, b). So far we have not defined the functional form of °. A straightforward approach is to use a linearly weighted combination of relations as shown below, °(R(a, b)) = � wz x f(rz, a, b). (2) riER(a,b) Here, wz is the weight associated with the lexical pattern rz and can be determined using training data. However, this formulation has two fundamental drawbacks. First, the number of weight parameters wz is equal to t</context>
</contexts>
<marker>Berland, Charniak, 1999</marker>
<rawString>M. Berland and E. Charniak. 1999. Finding parts in very large corpora. In Proc. of ACL’99, pages 57– 64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bollegala</author>
<author>Y Matsuo</author>
<author>M Ishizuka</author>
</authors>
<title>Measuring semantic similarity between words using web search engines.</title>
<date>2007</date>
<booktitle>In Proc. of WWW’07,</booktitle>
<pages>757--766</pages>
<contexts>
<context position="11151" citStr="Bollegala et al., 2007" startWordPosition="1765" endWordPosition="1768">from a web search engine. Then they count the number of occurrences of X in the snippets for Y , and Y in the snippets for X. The two values are combined nonlinearly to compute the similarity between X and Y . This method heavily depends on the search engine’s ranking algorithm. Although two words X and Y may be very similar, there is no reason to believe that one can find Y in the snippets for X, or vice versa. This observation is confirmed by the experimental results in their paper which reports 0 similarity scores for many pairs of words in the Miller-Charles dataset. In our previous work (Bollegala et al., 2007), we proposed a semantic similarity measure using page counts and snippets retrieved from a Web search engine. To compute the similarity between two words X and Y , we queried a web search engine using the query X AND Y and extract lexical patterns that combine X and Y from snippets. A feature vector is formed using frequencies of 200 lexical patterns in snippets and four co-occurrence measures: Dice coefficient, overlap coefficient, Jaccard coefficient and pointwise mutual information. We trained a two-class support vector machine using automatically selected synonymous and non-synonymous wor</context>
<context position="31042" citStr="Bollegala et al., 2007" startWordPosition="5231" endWordPosition="5234">e and use the corresponding set of clusters to compute semantic similarity by Equation 3. Similarity scores computed using Equation 3 can be greater than 1 (see Figure 2) because of the terms corresponding to the nondiagonal elements in A. We do not normalize the similarity scores to [0, 1] range in our experiments because the evaluation metrics we use are insensitive to linear transformations of similarity scores. 6 Experiments Table 1 compares the proposed method against Miller-Charles ratings (MC), and previously proposed web-based semantic similarity measures: Jaccard, Dice, Overlap, PMI (Bollegala et al., 2007), Normalized Google Distance (NGD) (Cilibrasi and Vitanyi, 2007), Sahami and Heilman (SH) (2006), co-occurrence double checking model (CODC) (Chen et al., 2006), and support vector machine-based (SVM) approach (Bollegala et al., 2007). The bottom row of Table 1 shows the Pearson correlation coefficient of similarity scores produced by each algorithm with MC. All similarity scores, except for the human-ratings in MillerCharles dataset, are normalized to [0, 1] range for the ease of comparison. It is noteworthy that the Pearson correlation coefficient is invariant under a linear transformation. </context>
</contexts>
<marker>Bollegala, Matsuo, Ishizuka, 2007</marker>
<rawString>D. Bollegala, Y. Matsuo, and M. Ishizuka. 2007. Measuring semantic similarity between words using web search engines. In Proc. of WWW’07, pages 757– 766.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Chen</author>
<author>M Lin</author>
<author>Y Wei</author>
</authors>
<title>Novel association measures using web search with double checking.</title>
<date>2006</date>
<booktitle>In Proc. of the COLING/ACL ’06,</booktitle>
<pages>1009--1016</pages>
<contexts>
<context position="10376" citStr="Chen et al., (2006)" startWordPosition="1621" endWordPosition="1624">ds between which similarity is computed are polysemous. Sahami and Heilman (2006) measured semantic similarity between two queries using snippets returned for those queries by a search engine. For each query, they collect snippets from a search engine and represent each snippet as a TF-IDFweighted term vector. Each vector is L2 normalized and the centroid of the set of vectors is computed. Semantic similarity between two queries is then defined as the inner product between the corresponding centroid vectors. They did not compare their similarity measure with taxonomybased similarity measures. Chen et al., (2006) propose a web-based doublechecking model to compute the semantic similarity between words. For two words X and Y , they collect snippets for each word from a web search engine. Then they count the number of occurrences of X in the snippets for Y , and Y in the snippets for X. The two values are combined nonlinearly to compute the similarity between X and Y . This method heavily depends on the search engine’s ranking algorithm. Although two words X and Y may be very similar, there is no reason to believe that one can find Y in the snippets for X, or vice versa. This observation is confirmed by</context>
<context position="31202" citStr="Chen et al., 2006" startWordPosition="5255" endWordPosition="5258">re 2) because of the terms corresponding to the nondiagonal elements in A. We do not normalize the similarity scores to [0, 1] range in our experiments because the evaluation metrics we use are insensitive to linear transformations of similarity scores. 6 Experiments Table 1 compares the proposed method against Miller-Charles ratings (MC), and previously proposed web-based semantic similarity measures: Jaccard, Dice, Overlap, PMI (Bollegala et al., 2007), Normalized Google Distance (NGD) (Cilibrasi and Vitanyi, 2007), Sahami and Heilman (SH) (2006), co-occurrence double checking model (CODC) (Chen et al., 2006), and support vector machine-based (SVM) approach (Bollegala et al., 2007). The bottom row of Table 1 shows the Pearson correlation coefficient of similarity scores produced by each algorithm with MC. All similarity scores, except for the human-ratings in MillerCharles dataset, are normalized to [0, 1] range for the ease of comparison. It is noteworthy that the Pearson correlation coefficient is invariant under a linear transformation. All similarity scores shown in Table 1 except for the proposed method are taken from the original published papers. The highest correlation is reported by the p</context>
</contexts>
<marker>Chen, Lin, Wei, 2006</marker>
<rawString>H. Chen, M. Lin, and Y. Wei. 2006. Novel association measures using web search with double checking. In Proc. of the COLING/ACL ’06, pages 1009–1016.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L Cilibrasi</author>
<author>P M B Vitanyi</author>
</authors>
<title>The google similarity distance.</title>
<date>2007</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<volume>19</volume>
<issue>3</issue>
<contexts>
<context position="9285" citStr="Cilibrasi and Vitanyi (2007)" startWordPosition="1449" endWordPosition="1452"> is calculated using the Brown corpus. Li et al., (2003) combined structural seman804 tic information from a lexical taxonomy, and information content from a corpus, in a nonlinear model. They proposed a similarity measure that uses shortest path length, depth and local density in a taxonomy. Their experiments reported a Pearson correlation coefficient of 0.8914 on the MillerCharles benchmark dataset (Miller and Charles, 1998). Lin (1998b) defined the similarity between two concepts as the information that is in common to both concepts and the information contained in each individual concept. Cilibrasi and Vitanyi (2007) proposed a distance metric between words using page-counts retrieved from a web search engine. The proposed metric is named Normalized Google Distance (NGD) and is defined as the normalized information distance (Li et al., 2004) between two strings. They evaluate NGD in a word classification task. Unfortunately NGD only uses page-counts of words and ignores the context in which the words appear. Therefore, it produces inaccurate similarity scores when one or both words between which similarity is computed are polysemous. Sahami and Heilman (2006) measured semantic similarity between two queri</context>
<context position="31106" citStr="Cilibrasi and Vitanyi, 2007" startWordPosition="5239" endWordPosition="5243">ntic similarity by Equation 3. Similarity scores computed using Equation 3 can be greater than 1 (see Figure 2) because of the terms corresponding to the nondiagonal elements in A. We do not normalize the similarity scores to [0, 1] range in our experiments because the evaluation metrics we use are insensitive to linear transformations of similarity scores. 6 Experiments Table 1 compares the proposed method against Miller-Charles ratings (MC), and previously proposed web-based semantic similarity measures: Jaccard, Dice, Overlap, PMI (Bollegala et al., 2007), Normalized Google Distance (NGD) (Cilibrasi and Vitanyi, 2007), Sahami and Heilman (SH) (2006), co-occurrence double checking model (CODC) (Chen et al., 2006), and support vector machine-based (SVM) approach (Bollegala et al., 2007). The bottom row of Table 1 shows the Pearson correlation coefficient of similarity scores produced by each algorithm with MC. All similarity scores, except for the human-ratings in MillerCharles dataset, are normalized to [0, 1] range for the ease of comparison. It is noteworthy that the Pearson correlation coefficient is invariant under a linear transformation. All similarity scores shown in Table 1 except for the proposed m</context>
</contexts>
<marker>Cilibrasi, Vitanyi, 2007</marker>
<rawString>R.L. Cilibrasi and P.M.B. Vitanyi. 2007. The google similarity distance. IEEE Transactions on Knowledge and Data Engineering, 19(3):370–383.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Curran</author>
</authors>
<title>Ensemble menthods for automatic thesaurus extraction.</title>
<date>2002</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="2417" citStr="Curran, 2002" startWordPosition="346" endWordPosition="347">ences on the new specimen using the properties Research Fellow of the Japan Society for the Promotion of Science (JSPS) known for the existing category. As the similarity between two objects X and Y increases, so does the probability of correctly inferring that Y has the property T upon knowing that X has T (Tenenbaum, 1999). Accurate measurement of semantic similarity between lexical units such as words or phrases is important for numerous tasks in natural language processing such as word sense disambiguation (Resnik, 1995), synonym extraction (Lin, 1998a), and automatic thesauri generation (Curran, 2002). In information retrieval, similar or related words are used to expand user queries to improve recall (Sahami and Heilman, 2006). Semantic similarity is a context dependent and dynamic phenomenon. New words are constantly being created and existing words are assigned with new senses on the Web. To decide whether two words are semantically similar, it is important to know the semantic relations that hold between the words. For example, the words horse and cow can be considered semantically similar because both horses and cows are useful animals in agriculture. Similarly, a horse and a car can </context>
</contexts>
<marker>Curran, 2002</marker>
<rawString>J. Curran. 2002. Ensemble menthods for automatic thesaurus extraction. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Falkenhainer</author>
<author>K D Forbus</author>
<author>D Gentner</author>
</authors>
<title>Structure mapping engine: Algorithm and examples.</title>
<date>1989</date>
<journal>Arti�cial Intelligence,</journal>
<pages>41--1</pages>
<contexts>
<context position="17477" citStr="Falkenhainer et al., 1989" startWordPosition="2838" endWordPosition="2841">ed in the following equation, S(a, b) = Of(A n B) − af(A − B) − Of(B − A). (4) Here, the function f measures the salience of a particular set of features, and non-negative parameters a, Q, and 0 determine the relative weights assigned to the different components. However, in the relational model of similarity we do not focus on features of individual words but on relations between two words. Modeling similarity as a phenomenon of relations between objects rather than features of individual objects is central to computational models of analogy-making such as the structure mapping theory (SMT) (Falkenhainer et al., 1989). SMT claims that an analogy is a mapping of knowledge from one domain (base) into another (target) which conveys that a system of relations known to hold in the base also holds in the target. The target objects do not have to resemble their corresponding base objects. During the mapping process, features of individual objects are dropped and only relations are mapped. The proposed relational model of similarity uses this relational view 806 Ostrich, a large, flightless bird that lives in the dry grasslands of Africa. Figure 1: A snippet returned for the query “ostrich * * * * * bird”. not. We</context>
</contexts>
<marker>Falkenhainer, Forbus, Gentner, 1989</marker>
<rawString>B. Falkenhainer, K.D. Forbus, and D. Gentner. 1989. Structure mapping engine: Algorithm and examples. Arti�cial Intelligence, 41:1–63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Finkelstein</author>
<author>E Gabrilovich</author>
<author>Y Matias</author>
<author>E Rivlin</author>
<author>Z Solan</author>
<author>G Wolfman</author>
<author>E Ruppin</author>
</authors>
<title>Placing search in context: The concept revisited.</title>
<date>2002</date>
<journal>ACM TOIS,</journal>
<pages>20--116</pages>
<contexts>
<context position="25231" citStr="Finkelstein et al., 2002" startWordPosition="4228" endWordPosition="4231">equential pattern clustering algorithm. Input: patterns P = {p1, ... , pn}, threshold 0 Output: clusters C 1: SORT(P) 2: C +— {} 3: for pattern pi E P do 4: max +— −oc 5: c* +— null 6: for cluster cj E C do 7: sim +— cosine(pi, cj) 8: if sim &gt; max then 9: max +— sim 10: c* +— cj 11: end if 12: end for 13: if max &gt; 0 then 14: c* +— c* ® pi 15: else 16: C +— C U {pi} 17: end if 18: end for 19: return C measurement of how well the semantic similarity measure captures the notion of semantic similarity held by humans. In addition to Miller-Charles dataset we also evaluate on the WordSimilarity353 (Finkelstein et al., 2002) dataset. In contrast to Miller-Charles dataset which has only 30 word pairs, WordSimilarity-353 dataset contains 353 word pairs. Each pair has 13-16 human judgments, which were averaged for each pair to produce a single relatedness score. Following the previous work, we use both Miller-Charles dataset and WordSimilarity-353 dataset to evaluate the proposed semantic similarity measure. 5 Computing Semantic Similarity To extract lexical patterns that express numerous semantic relations, we first select synonymous words from WordNet synsets. A synset is a set of synonymous words assigned for a p</context>
</contexts>
<marker>Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, Ruppin, 2002</marker>
<rawString>L. Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin, Z. Solan, G. Wolfman, and E. Ruppin. 2002. Placing search in context: The concept revisited. ACM TOIS, 20:116–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Gabrilovich</author>
<author>S Markovitch</author>
</authors>
<title>Computing semantic relatedness using wikipedia-based explicit semantic analysis.</title>
<date>2007</date>
<booktitle>In Proc. of IJCAI’07,</booktitle>
<pages>1606--1611</pages>
<contexts>
<context position="11962" citStr="Gabrilovich and Markovitch (2007)" startWordPosition="1893" endWordPosition="1896">web search engine using the query X AND Y and extract lexical patterns that combine X and Y from snippets. A feature vector is formed using frequencies of 200 lexical patterns in snippets and four co-occurrence measures: Dice coefficient, overlap coefficient, Jaccard coefficient and pointwise mutual information. We trained a two-class support vector machine using automatically selected synonymous and non-synonymous word pairs from WordNet. This method reports a Pearson correlation coefficient of 0.837 with Miller-Charles ratings. However, it does not consider the relatedness between patterns. Gabrilovich and Markovitch (2007) represent words using weighted vectors of Wikipedia-based concepts, and define the similarity between words as the cosine of the angle between the corresponding vectors. Their method can be used to compute similarity between words as well as between texts. Although Wikipedia is growing in popularity, not all concepts found on the Web have articles in Wikipedia. Specially, novel or not very popular concepts are not adequately covered by Wikipedia. Moreover, their method requires the concepts to be independent. For non-independent, hierarchical taxonomies such as open directory project (ODP)1, </context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>E. Gabrilovich and S. Markovitch. 2007. Computing semantic relatedness using wikipedia-based explicit semantic analysis. In Proc. of IJCAI’07, pages 1606–1611.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L Goldstone</author>
</authors>
<title>The role of similarity in categorization: providing a groundwork.</title>
<date>1994</date>
<journal>Cognition,</journal>
<pages>52--125</pages>
<contexts>
<context position="1621" citStr="Goldstone, 1994" startWordPosition="219" endWordPosition="220">is distance measure. We compare the proposed similarity measure against previously proposed semantic similarity measures on Miller-Charles benchmark dataset and WordSimilarity353 collection. The proposed method outperforms all existing web-based semantic similarity measures, achieving a Pearson correlation coefficient of 0.867 on the Millet-Charles dataset. 1 Introduction Similarity is a fundamental concept in theories of knowledge and behavior. Psychological experiments have shown that similarity acts as an organizing principle by which individuals classify objects, and make generalizations (Goldstone, 1994). For example, a biologist would classify a newly found animal specimen based upon the properties that it shares with existing categories of animals. We can then make additional inferences on the new specimen using the properties Research Fellow of the Japan Society for the Promotion of Science (JSPS) known for the existing category. As the similarity between two objects X and Y increases, so does the probability of correctly inferring that Y has the property T upon knowing that X has T (Tenenbaum, 1999). Accurate measurement of semantic similarity between lexical units such as words or phrase</context>
</contexts>
<marker>Goldstone, 1994</marker>
<rawString>R. L. Goldstone. 1994. The role of similarity in categorization: providing a groundwork. Cognition, 52:125–157.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hahn</author>
<author>N Chater</author>
<author>L B Richardson</author>
</authors>
<title>Similarity as transformation.</title>
<date>2003</date>
<journal>Cognition,</journal>
<pages>87--1</pages>
<contexts>
<context position="6512" citStr="Hahn et al. (2003)" startWordPosition="1007" endWordPosition="1010">ntrast model of similarity to overcome the problems in geometric models. The contrast model relies on featural representation of objects, and it is used to compute the similarity between the representations of two objects. Similarity is defined as an increasing function of common features (i.e. features in common to the two objects), and as a decreasing function of distinctive features (i.e. features that apply to one object but not the other). The attributes of objects are primal to contrast model and it does not explicitly incorporate the relations between objects when measuring similarity. Hahn et al. (2003) define similarity between two representations as the complexity required to transform one representation into the other. Their model of similarity is based on the Representational Distortion theory, which aims to provide a theoretical framework of similarity judgments. Their experiments using pattern sequences and geometric shapes show an inverse correlation between the number of transformations required to convert one pattern (or shape) to another, and the perceived similarity ratings by human subjects. How to represent an object, which transformations are allowed on a representation, and ho</context>
</contexts>
<marker>Hahn, Chater, Richardson, 2003</marker>
<rawString>U. Hahn, N. Chater, and L. B. Richardson. 2003. Similarity as transformation. Cognition, 87:1–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Harris</author>
</authors>
<date>1954</date>
<booktitle>Distributional structure. Word,</booktitle>
<pages>10--146</pages>
<contexts>
<context position="4864" citStr="Harris, 1954" startWordPosition="761" endWordPosition="762">nfidence score. It is noteworthy that all lexical patterns are not independent – multiple lexical patterns can express the same semantic relation. For example, the pattern X is a large Y subsumes the more general pattern X is a Y and they both indicate a hypernymic relationship between X and Y. By clustering the semantically related patterns into groups, we can both overcome the data sparseness problem, and reduce the number of parameters during training. To identify semantically related patterns, we use a sequential pattern clustering algorithm that is based on the distributional hypothesis (Harris, 1954). We represent two words by a feature vector defined over the clusters of patterns. Finally, the semantic similarity is computed as the Mahalanobis distance between points corresponding to the feature vectors. By using Mahalanobis distance instead of Euclidean distance, we can account for the inter-dependence between semantic relations. 2 Related Work Geometric models, such as multi-dimensional scaling has been used in psychological experiments analyzing the properties of similarity (Krumhansl, 1978). These models represent objects as points in some coordinate space such that the observed diss</context>
<context position="21878" citStr="Harris, 1954" startWordPosition="3611" endWordPosition="3612">we would obtain if we used the original prefixspan algorithm (i.e. without pruning) and subsequently remove patterns that violate the above mentioned constraints. For example, some patterns extracted form the snippet shown in Figure 1 are: X, a large Y, X a flightless Y, and X, large Y lives. 3.2 Clustering Lexical Patterns A semantic relation can be expressed using more than one pattern. By grouping the semantically related patterns, we can both reduce the model complexity in Equation 2, and consider the dependence among semantic relations in Equation 3. We use the distributional hypothesis (Harris, 1954) to find semantically related lexical patterns. The distributional hypothesis states that words that occur in the same context have similar meanings. If two lexical patterns are similarly distributed over a set of word pairs, then from the distributional hypothesis it follows that the two patterns must be similar. We represent a pattern p by a vector p in which 807 the i-th element is the frequency f(a2, b2, p) of p in a word pair (a2, b2). Given a set P of patterns and a similarity threshold 0, Algorithm 1 returns clusters of similar patterns. First, the function SORT sorts the patterns in th</context>
</contexts>
<marker>Harris, 1954</marker>
<rawString>Z. Harris. 1954. Distributional structure. Word, 10:146–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proc. of 14th COLING,</booktitle>
<pages>539--545</pages>
<contexts>
<context position="13960" citStr="Hearst, 1992" startWordPosition="2219" endWordPosition="2220">ample, given a taxonomy of words such as the WordNet, semantic relations (i.e. hypernymy, meronymy, synonymy etc.) between words can be directly looked up in the taxonomy. Alternatively, the labels of the edges in the path connecting two words can be used as semantic relations. However, in this paper we do not assume the availability of manually created resources such as dictionaries or taxonomies. We represent semantic relations using automatically extracted lexical patterns. Lexical patterns have been successfully used to represent various semantic relations between words such as hypernymy (Hearst, 1992), and meronymy (Berland and Charniak, 1999). Following these previous approaches, we represent R(a, b) as a set of lexical patterns. Moreover, we denote the frequency of a lexical pattern r for a word pair (a, b) by f(r, a, b). So far we have not defined the functional form of °. A straightforward approach is to use a linearly weighted combination of relations as shown below, °(R(a, b)) = � wz x f(rz, a, b). (2) riER(a,b) Here, wz is the weight associated with the lexical pattern rz and can be determined using training data. However, this formulation has two fundamental drawbacks. First, the n</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>M.A. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proc. of 14th COLING, pages 539–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hirst</author>
<author>D St-Onge</author>
</authors>
<title>Lexical chains as representations of context for the detection and correction of malapropisms.</title>
<date>1997</date>
<contexts>
<context position="36626" citStr="Hirst &amp; St-Onge (1997)" startWordPosition="6082" endWordPosition="6085">st-forest 0.420 0.861 0.869 0.295 0.417 0.545 0.060 0.000 0.405 0.150 lad-wizard 0.420 0.062 0.065 0.050 0.426 0.657 0.038 0.000 0.220 0.231 cord-smile 0.130 0.092 0.097 0.015 0.208 0.460 0.025 0.000 0 0.006 glass-magician 0.110 0.107 0.113 0.396 0.598 0.488 0.037 0.000 0.180 0.050 rooster-voyage 0.080 0.000 0.000 0.000 0.228 0.487 0.049 0.000 0.017 0.052 noon-string 0.080 0.116 0.123 0.040 0.102 0.488 0.024 0.000 0.018 0.000 Correlation - 0.260 0.267 0.382 0.549 0.205 0.580 0.694 0.834 0.867 Table 3: Results on WordSimilarity-353 dataset. Method Correlation WordNet Edges (Jarmasz, 1993) 0.27 Hirst &amp; St-Onge (1997) 0.34 Jiang &amp; Conrath (1998) 0.34 WikiRelate! (Strube and Ponzetto, 2006) 0.19-0.48 Leacock &amp; Chodrow (1998) 0.36 Lin (1998b) 0.36 Resnik (1995) 0.37 Proposed 0.504 Table 2: Comparison with WordNet-based similarity measures. Method Correlation Edge-counting 0.664 Jiang &amp; Conrath (1998) 0.848 Lin (1998a) 0.822 Resnik (1995) 0.745 Li et al. (2003) 0.891 ball) and (Jerusalem, Israel)). Because the proposed method use snippets retrieved from a web search engine, it is capable of extracting expressive lexical patterns that can explicitly state the relationship between two entities. If we must compa</context>
</contexts>
<marker>Hirst, St-Onge, 1997</marker>
<rawString>G. Hirst and D. St-Onge. 1997. Lexical chains as representations of context for the detection and correction of malapropisms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Jarmasz</author>
</authors>
<title>Roget’s thesaurus as a lexical resource for natural language processing. Master’s thesis,</title>
<date>1993</date>
<institution>University of Ottawa.</institution>
<contexts>
<context position="36598" citStr="Jarmasz, 1993" startWordPosition="6079" endWordPosition="6080">.000 0.375 0.243 coast-forest 0.420 0.861 0.869 0.295 0.417 0.545 0.060 0.000 0.405 0.150 lad-wizard 0.420 0.062 0.065 0.050 0.426 0.657 0.038 0.000 0.220 0.231 cord-smile 0.130 0.092 0.097 0.015 0.208 0.460 0.025 0.000 0 0.006 glass-magician 0.110 0.107 0.113 0.396 0.598 0.488 0.037 0.000 0.180 0.050 rooster-voyage 0.080 0.000 0.000 0.000 0.228 0.487 0.049 0.000 0.017 0.052 noon-string 0.080 0.116 0.123 0.040 0.102 0.488 0.024 0.000 0.018 0.000 Correlation - 0.260 0.267 0.382 0.549 0.205 0.580 0.694 0.834 0.867 Table 3: Results on WordSimilarity-353 dataset. Method Correlation WordNet Edges (Jarmasz, 1993) 0.27 Hirst &amp; St-Onge (1997) 0.34 Jiang &amp; Conrath (1998) 0.34 WikiRelate! (Strube and Ponzetto, 2006) 0.19-0.48 Leacock &amp; Chodrow (1998) 0.36 Lin (1998b) 0.36 Resnik (1995) 0.37 Proposed 0.504 Table 2: Comparison with WordNet-based similarity measures. Method Correlation Edge-counting 0.664 Jiang &amp; Conrath (1998) 0.848 Lin (1998a) 0.822 Resnik (1995) 0.745 Li et al. (2003) 0.891 ball) and (Jerusalem, Israel)). Because the proposed method use snippets retrieved from a web search engine, it is capable of extracting expressive lexical patterns that can explicitly state the relationship between tw</context>
</contexts>
<marker>Jarmasz, 1993</marker>
<rawString>M. Jarmasz. 1993. Roget’s thesaurus as a lexical resource for natural language processing. Master’s thesis, University of Ottawa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Jiang</author>
<author>D W Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1998</date>
<booktitle>In Proc. of ROCLING’98.</booktitle>
<contexts>
<context position="36654" citStr="Jiang &amp; Conrath (1998)" startWordPosition="6087" endWordPosition="6090">0.295 0.417 0.545 0.060 0.000 0.405 0.150 lad-wizard 0.420 0.062 0.065 0.050 0.426 0.657 0.038 0.000 0.220 0.231 cord-smile 0.130 0.092 0.097 0.015 0.208 0.460 0.025 0.000 0 0.006 glass-magician 0.110 0.107 0.113 0.396 0.598 0.488 0.037 0.000 0.180 0.050 rooster-voyage 0.080 0.000 0.000 0.000 0.228 0.487 0.049 0.000 0.017 0.052 noon-string 0.080 0.116 0.123 0.040 0.102 0.488 0.024 0.000 0.018 0.000 Correlation - 0.260 0.267 0.382 0.549 0.205 0.580 0.694 0.834 0.867 Table 3: Results on WordSimilarity-353 dataset. Method Correlation WordNet Edges (Jarmasz, 1993) 0.27 Hirst &amp; St-Onge (1997) 0.34 Jiang &amp; Conrath (1998) 0.34 WikiRelate! (Strube and Ponzetto, 2006) 0.19-0.48 Leacock &amp; Chodrow (1998) 0.36 Lin (1998b) 0.36 Resnik (1995) 0.37 Proposed 0.504 Table 2: Comparison with WordNet-based similarity measures. Method Correlation Edge-counting 0.664 Jiang &amp; Conrath (1998) 0.848 Lin (1998a) 0.822 Resnik (1995) 0.745 Li et al. (2003) 0.891 ball) and (Jerusalem, Israel)). Because the proposed method use snippets retrieved from a web search engine, it is capable of extracting expressive lexical patterns that can explicitly state the relationship between two entities. If we must compare n objects using a feature</context>
</contexts>
<marker>Jiang, Conrath, 1998</marker>
<rawString>J.J. Jiang and D.W. Conrath. 1998. Semantic similarity based on corpus statistics and lexical taxonomy. In Proc. of ROCLING’98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Krumhansl</author>
</authors>
<title>Concerning the applicability of geometric models to similarity data: The interrelationship between similarity and spatial density. Psychological Review,</title>
<date>1978</date>
<pages>85--445</pages>
<contexts>
<context position="5369" citStr="Krumhansl, 1978" startWordPosition="834" endWordPosition="835"> we use a sequential pattern clustering algorithm that is based on the distributional hypothesis (Harris, 1954). We represent two words by a feature vector defined over the clusters of patterns. Finally, the semantic similarity is computed as the Mahalanobis distance between points corresponding to the feature vectors. By using Mahalanobis distance instead of Euclidean distance, we can account for the inter-dependence between semantic relations. 2 Related Work Geometric models, such as multi-dimensional scaling has been used in psychological experiments analyzing the properties of similarity (Krumhansl, 1978). These models represent objects as points in some coordinate space such that the observed dissimilarities between objects correspond to the metric distances between the respective points. Geometric models assume that objects can be adequately represented as points in some coordinate space and that dissimilarity behaves like a metric distance function satisfying minimality, symmetry, and triangle inequality assumptions. However, both dimensional and metric assumptions are open to question. Tversky (1977) proposed the contrast model of similarity to overcome the problems in geometric models. Th</context>
</contexts>
<marker>Krumhansl, 1978</marker>
<rawString>C. L. Krumhansl. 1978. Concerning the applicability of geometric models to similarity data: The interrelationship between similarity and spatial density. Psychological Review, 85:445–463.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Leacock</author>
<author>M Chodorow</author>
</authors>
<title>Combining Local Context and WordNet Similarity for Word Sense Identi�cation.</title>
<date>1998</date>
<publisher>MIT.</publisher>
<marker>Leacock, Chodorow, 1998</marker>
<rawString>C. Leacock and M. Chodorow. 1998. Combining Local Context and WordNet Similarity for Word Sense Identi�cation. MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Li</author>
<author>X Chen</author>
<author>X Li</author>
<author>B Ma</author>
<author>P M B Vitanyi</author>
</authors>
<title>The similarity metric.</title>
<date>2004</date>
<journal>IEEE Transactions on Information Theory,</journal>
<volume>50</volume>
<issue>12</issue>
<contexts>
<context position="9514" citStr="Li et al., 2004" startWordPosition="1484" endWordPosition="1487"> path length, depth and local density in a taxonomy. Their experiments reported a Pearson correlation coefficient of 0.8914 on the MillerCharles benchmark dataset (Miller and Charles, 1998). Lin (1998b) defined the similarity between two concepts as the information that is in common to both concepts and the information contained in each individual concept. Cilibrasi and Vitanyi (2007) proposed a distance metric between words using page-counts retrieved from a web search engine. The proposed metric is named Normalized Google Distance (NGD) and is defined as the normalized information distance (Li et al., 2004) between two strings. They evaluate NGD in a word classification task. Unfortunately NGD only uses page-counts of words and ignores the context in which the words appear. Therefore, it produces inaccurate similarity scores when one or both words between which similarity is computed are polysemous. Sahami and Heilman (2006) measured semantic similarity between two queries using snippets returned for those queries by a search engine. For each query, they collect snippets from a search engine and represent each snippet as a TF-IDFweighted term vector. Each vector is L2 normalized and the centroid</context>
</contexts>
<marker>Li, Chen, Li, Ma, Vitanyi, 2004</marker>
<rawString>M. Li, X. Chen, X. Li, B. Ma, and P.M.B. Vitanyi. 2004. The similarity metric. IEEE Transactions on Information Theory, 50(12):3250–3264.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Automatic retreival and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proc. of the 17th COLING,</booktitle>
<pages>768--774</pages>
<contexts>
<context position="2365" citStr="Lin, 1998" startWordPosition="339" endWordPosition="340">es of animals. We can then make additional inferences on the new specimen using the properties Research Fellow of the Japan Society for the Promotion of Science (JSPS) known for the existing category. As the similarity between two objects X and Y increases, so does the probability of correctly inferring that Y has the property T upon knowing that X has T (Tenenbaum, 1999). Accurate measurement of semantic similarity between lexical units such as words or phrases is important for numerous tasks in natural language processing such as word sense disambiguation (Resnik, 1995), synonym extraction (Lin, 1998a), and automatic thesauri generation (Curran, 2002). In information retrieval, similar or related words are used to expand user queries to improve recall (Sahami and Heilman, 2006). Semantic similarity is a context dependent and dynamic phenomenon. New words are constantly being created and existing words are assigned with new senses on the Web. To decide whether two words are semantically similar, it is important to know the semantic relations that hold between the words. For example, the words horse and cow can be considered semantically similar because both horses and cows are useful anima</context>
<context position="9098" citStr="Lin (1998" startWordPosition="1423" endWordPosition="1424">larity between two words is defined as the maximum of the similarity between any concepts that the words belong to. He used WordNet as the taxonomy; information content is calculated using the Brown corpus. Li et al., (2003) combined structural seman804 tic information from a lexical taxonomy, and information content from a corpus, in a nonlinear model. They proposed a similarity measure that uses shortest path length, depth and local density in a taxonomy. Their experiments reported a Pearson correlation coefficient of 0.8914 on the MillerCharles benchmark dataset (Miller and Charles, 1998). Lin (1998b) defined the similarity between two concepts as the information that is in common to both concepts and the information contained in each individual concept. Cilibrasi and Vitanyi (2007) proposed a distance metric between words using page-counts retrieved from a web search engine. The proposed metric is named Normalized Google Distance (NGD) and is defined as the normalized information distance (Li et al., 2004) between two strings. They evaluate NGD in a word classification task. Unfortunately NGD only uses page-counts of words and ignores the context in which the words appear. Therefore, it</context>
<context position="36749" citStr="Lin (1998" startWordPosition="6103" endWordPosition="6104">.231 cord-smile 0.130 0.092 0.097 0.015 0.208 0.460 0.025 0.000 0 0.006 glass-magician 0.110 0.107 0.113 0.396 0.598 0.488 0.037 0.000 0.180 0.050 rooster-voyage 0.080 0.000 0.000 0.000 0.228 0.487 0.049 0.000 0.017 0.052 noon-string 0.080 0.116 0.123 0.040 0.102 0.488 0.024 0.000 0.018 0.000 Correlation - 0.260 0.267 0.382 0.549 0.205 0.580 0.694 0.834 0.867 Table 3: Results on WordSimilarity-353 dataset. Method Correlation WordNet Edges (Jarmasz, 1993) 0.27 Hirst &amp; St-Onge (1997) 0.34 Jiang &amp; Conrath (1998) 0.34 WikiRelate! (Strube and Ponzetto, 2006) 0.19-0.48 Leacock &amp; Chodrow (1998) 0.36 Lin (1998b) 0.36 Resnik (1995) 0.37 Proposed 0.504 Table 2: Comparison with WordNet-based similarity measures. Method Correlation Edge-counting 0.664 Jiang &amp; Conrath (1998) 0.848 Lin (1998a) 0.822 Resnik (1995) 0.745 Li et al. (2003) 0.891 ball) and (Jerusalem, Israel)). Because the proposed method use snippets retrieved from a web search engine, it is capable of extracting expressive lexical patterns that can explicitly state the relationship between two entities. If we must compare n objects using a feature model of similarity, then we only need to define features for each of those n objects. However</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>D. Lin. 1998a. Automatic retreival and clustering of similar words. In Proc. of the 17th COLING, pages 768–774.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>An information-theoretic definition of similarity.</title>
<date>1998</date>
<booktitle>In Proc. of the 15th ICML,</booktitle>
<pages>296--304</pages>
<contexts>
<context position="2365" citStr="Lin, 1998" startWordPosition="339" endWordPosition="340">es of animals. We can then make additional inferences on the new specimen using the properties Research Fellow of the Japan Society for the Promotion of Science (JSPS) known for the existing category. As the similarity between two objects X and Y increases, so does the probability of correctly inferring that Y has the property T upon knowing that X has T (Tenenbaum, 1999). Accurate measurement of semantic similarity between lexical units such as words or phrases is important for numerous tasks in natural language processing such as word sense disambiguation (Resnik, 1995), synonym extraction (Lin, 1998a), and automatic thesauri generation (Curran, 2002). In information retrieval, similar or related words are used to expand user queries to improve recall (Sahami and Heilman, 2006). Semantic similarity is a context dependent and dynamic phenomenon. New words are constantly being created and existing words are assigned with new senses on the Web. To decide whether two words are semantically similar, it is important to know the semantic relations that hold between the words. For example, the words horse and cow can be considered semantically similar because both horses and cows are useful anima</context>
<context position="9098" citStr="Lin (1998" startWordPosition="1423" endWordPosition="1424">larity between two words is defined as the maximum of the similarity between any concepts that the words belong to. He used WordNet as the taxonomy; information content is calculated using the Brown corpus. Li et al., (2003) combined structural seman804 tic information from a lexical taxonomy, and information content from a corpus, in a nonlinear model. They proposed a similarity measure that uses shortest path length, depth and local density in a taxonomy. Their experiments reported a Pearson correlation coefficient of 0.8914 on the MillerCharles benchmark dataset (Miller and Charles, 1998). Lin (1998b) defined the similarity between two concepts as the information that is in common to both concepts and the information contained in each individual concept. Cilibrasi and Vitanyi (2007) proposed a distance metric between words using page-counts retrieved from a web search engine. The proposed metric is named Normalized Google Distance (NGD) and is defined as the normalized information distance (Li et al., 2004) between two strings. They evaluate NGD in a word classification task. Unfortunately NGD only uses page-counts of words and ignores the context in which the words appear. Therefore, it</context>
<context position="36749" citStr="Lin (1998" startWordPosition="6103" endWordPosition="6104">.231 cord-smile 0.130 0.092 0.097 0.015 0.208 0.460 0.025 0.000 0 0.006 glass-magician 0.110 0.107 0.113 0.396 0.598 0.488 0.037 0.000 0.180 0.050 rooster-voyage 0.080 0.000 0.000 0.000 0.228 0.487 0.049 0.000 0.017 0.052 noon-string 0.080 0.116 0.123 0.040 0.102 0.488 0.024 0.000 0.018 0.000 Correlation - 0.260 0.267 0.382 0.549 0.205 0.580 0.694 0.834 0.867 Table 3: Results on WordSimilarity-353 dataset. Method Correlation WordNet Edges (Jarmasz, 1993) 0.27 Hirst &amp; St-Onge (1997) 0.34 Jiang &amp; Conrath (1998) 0.34 WikiRelate! (Strube and Ponzetto, 2006) 0.19-0.48 Leacock &amp; Chodrow (1998) 0.36 Lin (1998b) 0.36 Resnik (1995) 0.37 Proposed 0.504 Table 2: Comparison with WordNet-based similarity measures. Method Correlation Edge-counting 0.664 Jiang &amp; Conrath (1998) 0.848 Lin (1998a) 0.822 Resnik (1995) 0.745 Li et al. (2003) 0.891 ball) and (Jerusalem, Israel)). Because the proposed method use snippets retrieved from a web search engine, it is capable of extracting expressive lexical patterns that can explicitly state the relationship between two entities. If we must compare n objects using a feature model of similarity, then we only need to define features for each of those n objects. However</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>D. Lin. 1998b. An information-theoretic definition of similarity. In Proc. of the 15th ICML, pages 296– 304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
<author>W Charles</author>
</authors>
<title>Contextual correlates of semantic similarity.</title>
<date>1998</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>6--1</pages>
<contexts>
<context position="9087" citStr="Miller and Charles, 1998" startWordPosition="1419" endWordPosition="1422">th C1 and C2. Then the similarity between two words is defined as the maximum of the similarity between any concepts that the words belong to. He used WordNet as the taxonomy; information content is calculated using the Brown corpus. Li et al., (2003) combined structural seman804 tic information from a lexical taxonomy, and information content from a corpus, in a nonlinear model. They proposed a similarity measure that uses shortest path length, depth and local density in a taxonomy. Their experiments reported a Pearson correlation coefficient of 0.8914 on the MillerCharles benchmark dataset (Miller and Charles, 1998). Lin (1998b) defined the similarity between two concepts as the information that is in common to both concepts and the information contained in each individual concept. Cilibrasi and Vitanyi (2007) proposed a distance metric between words using page-counts retrieved from a web search engine. The proposed metric is named Normalized Google Distance (NGD) and is defined as the normalized information distance (Li et al., 2004) between two strings. They evaluate NGD in a word classification task. Unfortunately NGD only uses page-counts of words and ignores the context in which the words appear. Th</context>
</contexts>
<marker>Miller, Charles, 1998</marker>
<rawString>G. Miller and W. Charles. 1998. Contextual correlates of semantic similarity. Language and Cognitive Processes, 6(1):1–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pei</author>
<author>J Han</author>
<author>B Mortazavi-Asi</author>
<author>J Wang</author>
<author>H Pinto</author>
<author>Q Chen</author>
<author>U Dayal</author>
<author>M Hsu</author>
</authors>
<title>Mining sequential patterns by pattern-growth: the prefixspan approach.</title>
<date>2004</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<volume>16</volume>
<issue>11</issue>
<contexts>
<context position="20693" citStr="Pei et al., 2004" startWordPosition="3415" endWordPosition="3418">y of all generated subsequences and only use subsequences that occur more than N times as lexical patterns. The parameters L, g, G and N are set experimentally, as explained later in Section 6. It is noteworthy that the proposed pattern extraction algorithm considers all the words in a snippet, and is not limited to extracting patterns only from the mid-fix (i.e., the portion of text in a snippet that appears between the queried words). Moreover, the consideration of gaps enables us to capture relations between distant words in a snippet. We use a modified version of the prefixspan algorithm (Pei et al., 2004) to generate subsequences from a text snippet. Specifically, we use the constraints (ii)- (iv) to prune the search space of candidate subsequences. For example, if a subsequence has reached the maximum length L, or contains the maximum number of gaps G, then we will not extend it further. By pruning the search space, we can speed up the pattern generation process. However, none of these modifications affect the accuracy of the proposed semantic similarity measure because the modified version of the prefixspan algorithm still generates the exact set of patterns that we would obtain if we used t</context>
</contexts>
<marker>Pei, Han, Mortazavi-Asi, Wang, Pinto, Chen, Dayal, Hsu, 2004</marker>
<rawString>J. Pei, J. Han, B. Mortazavi-Asi, J. Wang, H. Pinto, Q. Chen, U. Dayal, and M. Hsu. 2004. Mining sequential patterns by pattern-growth: the prefixspan approach. IEEE Transactions on Knowledge and Data Engineering, 16(11):1424–1440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rada</author>
<author>H Mili</author>
<author>E Bichnell</author>
<author>M Blettner</author>
</authors>
<title>Development and application of a metric on semantic nets.</title>
<date>1989</date>
<journal>IEEE Transactions on Systems, Man and Cybernetics,</journal>
<volume>9</volume>
<issue>1</issue>
<contexts>
<context position="7666" citStr="Rada et al., 1989" startWordPosition="1183" endWordPosition="1186">t, which transformations are allowed on a representation, and how to measure the complexity of a transformation, are all important decisions in the transformational model of similarity. Although distance measures such as edit distance have been used to find approximate matches in a dictionary, it is not obvious how to compute semantic similarity between words using representational distortion theory. Given a taxonomy of concepts, a straightforward method to calculate similarity between two words (or concepts) is to find the length of the shortest path connecting the two words in the taxonomy (Rada et al., 1989). If a word is polysemous (i.e. has more than one sense) then multiple paths might exist between the two words. In such cases, only the shortest path between any two senses of the words is considered for calculating similarity. A problem that is frequently acknowledged with this approach is that it relies on the notion that all links in the taxonomy represent a uniform distance. As a solution to this problem, Schickel-Zuber and Faltings (2007) propose ontology structure based similarity (OSS) between two concepts in an ontology, which is an asymmetric distance function. Resnik (1995) proposed </context>
</contexts>
<marker>Rada, Mili, Bichnell, Blettner, 1989</marker>
<rawString>R. Rada, H. Mili, E. Bichnell, and M. Blettner. 1989. Development and application of a metric on semantic nets. IEEE Transactions on Systems, Man and Cybernetics, 9(1):17–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity in a taxonomy.</title>
<date>1995</date>
<booktitle>In Proc. of IJCAI’95.</booktitle>
<contexts>
<context position="2334" citStr="Resnik, 1995" startWordPosition="334" endWordPosition="335">at it shares with existing categories of animals. We can then make additional inferences on the new specimen using the properties Research Fellow of the Japan Society for the Promotion of Science (JSPS) known for the existing category. As the similarity between two objects X and Y increases, so does the probability of correctly inferring that Y has the property T upon knowing that X has T (Tenenbaum, 1999). Accurate measurement of semantic similarity between lexical units such as words or phrases is important for numerous tasks in natural language processing such as word sense disambiguation (Resnik, 1995), synonym extraction (Lin, 1998a), and automatic thesauri generation (Curran, 2002). In information retrieval, similar or related words are used to expand user queries to improve recall (Sahami and Heilman, 2006). Semantic similarity is a context dependent and dynamic phenomenon. New words are constantly being created and existing words are assigned with new senses on the Web. To decide whether two words are semantically similar, it is important to know the semantic relations that hold between the words. For example, the words horse and cow can be considered semantically similar because both h</context>
<context position="8256" citStr="Resnik (1995)" startWordPosition="1284" endWordPosition="1285">omy (Rada et al., 1989). If a word is polysemous (i.e. has more than one sense) then multiple paths might exist between the two words. In such cases, only the shortest path between any two senses of the words is considered for calculating similarity. A problem that is frequently acknowledged with this approach is that it relies on the notion that all links in the taxonomy represent a uniform distance. As a solution to this problem, Schickel-Zuber and Faltings (2007) propose ontology structure based similarity (OSS) between two concepts in an ontology, which is an asymmetric distance function. Resnik (1995) proposed a similarity measure using information content. He defined the similarity between two concepts C1 and C2 in the taxonomy as the maximum of the information content of all concepts C that subsume both C1 and C2. Then the similarity between two words is defined as the maximum of the similarity between any concepts that the words belong to. He used WordNet as the taxonomy; information content is calculated using the Brown corpus. Li et al., (2003) combined structural seman804 tic information from a lexical taxonomy, and information content from a corpus, in a nonlinear model. They propos</context>
<context position="36770" citStr="Resnik (1995)" startWordPosition="6106" endWordPosition="6107">.130 0.092 0.097 0.015 0.208 0.460 0.025 0.000 0 0.006 glass-magician 0.110 0.107 0.113 0.396 0.598 0.488 0.037 0.000 0.180 0.050 rooster-voyage 0.080 0.000 0.000 0.000 0.228 0.487 0.049 0.000 0.017 0.052 noon-string 0.080 0.116 0.123 0.040 0.102 0.488 0.024 0.000 0.018 0.000 Correlation - 0.260 0.267 0.382 0.549 0.205 0.580 0.694 0.834 0.867 Table 3: Results on WordSimilarity-353 dataset. Method Correlation WordNet Edges (Jarmasz, 1993) 0.27 Hirst &amp; St-Onge (1997) 0.34 Jiang &amp; Conrath (1998) 0.34 WikiRelate! (Strube and Ponzetto, 2006) 0.19-0.48 Leacock &amp; Chodrow (1998) 0.36 Lin (1998b) 0.36 Resnik (1995) 0.37 Proposed 0.504 Table 2: Comparison with WordNet-based similarity measures. Method Correlation Edge-counting 0.664 Jiang &amp; Conrath (1998) 0.848 Lin (1998a) 0.822 Resnik (1995) 0.745 Li et al. (2003) 0.891 ball) and (Jerusalem, Israel)). Because the proposed method use snippets retrieved from a web search engine, it is capable of extracting expressive lexical patterns that can explicitly state the relationship between two entities. If we must compare n objects using a feature model of similarity, then we only need to define features for each of those n objects. However, in the proposed rel</context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>P. Resnik. 1995. Using information content to evaluate semantic similarity in a taxonomy. In Proc. of IJCAI’95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sahami</author>
<author>T Heilman</author>
</authors>
<title>A web-based kernel function for measuring the similarity of short text snippets.</title>
<date>2006</date>
<booktitle>In Proc. of WWW’06.</booktitle>
<contexts>
<context position="2546" citStr="Sahami and Heilman, 2006" startWordPosition="364" endWordPosition="367">S) known for the existing category. As the similarity between two objects X and Y increases, so does the probability of correctly inferring that Y has the property T upon knowing that X has T (Tenenbaum, 1999). Accurate measurement of semantic similarity between lexical units such as words or phrases is important for numerous tasks in natural language processing such as word sense disambiguation (Resnik, 1995), synonym extraction (Lin, 1998a), and automatic thesauri generation (Curran, 2002). In information retrieval, similar or related words are used to expand user queries to improve recall (Sahami and Heilman, 2006). Semantic similarity is a context dependent and dynamic phenomenon. New words are constantly being created and existing words are assigned with new senses on the Web. To decide whether two words are semantically similar, it is important to know the semantic relations that hold between the words. For example, the words horse and cow can be considered semantically similar because both horses and cows are useful animals in agriculture. Similarly, a horse and a car can be considered semantically similar because cars, and historically horses, are used for transportation. Semantic relations such as</context>
<context position="9838" citStr="Sahami and Heilman (2006)" startWordPosition="1534" endWordPosition="1537">ation contained in each individual concept. Cilibrasi and Vitanyi (2007) proposed a distance metric between words using page-counts retrieved from a web search engine. The proposed metric is named Normalized Google Distance (NGD) and is defined as the normalized information distance (Li et al., 2004) between two strings. They evaluate NGD in a word classification task. Unfortunately NGD only uses page-counts of words and ignores the context in which the words appear. Therefore, it produces inaccurate similarity scores when one or both words between which similarity is computed are polysemous. Sahami and Heilman (2006) measured semantic similarity between two queries using snippets returned for those queries by a search engine. For each query, they collect snippets from a search engine and represent each snippet as a TF-IDFweighted term vector. Each vector is L2 normalized and the centroid of the set of vectors is computed. Semantic similarity between two queries is then defined as the inner product between the corresponding centroid vectors. They did not compare their similarity measure with taxonomybased similarity measures. Chen et al., (2006) propose a web-based doublechecking model to compute the seman</context>
</contexts>
<marker>Sahami, Heilman, 2006</marker>
<rawString>M. Sahami and T. Heilman. 2006. A web-based kernel function for measuring the similarity of short text snippets. In Proc. of WWW’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Schickel-Zuber</author>
<author>B Faltings</author>
</authors>
<title>Oss: A semantic similarity function based on hierarchical ontologies.</title>
<date>2007</date>
<booktitle>In Proc. of IJCAI’07,</booktitle>
<pages>551--556</pages>
<contexts>
<context position="8113" citStr="Schickel-Zuber and Faltings (2007)" startWordPosition="1261" endWordPosition="1264">s, a straightforward method to calculate similarity between two words (or concepts) is to find the length of the shortest path connecting the two words in the taxonomy (Rada et al., 1989). If a word is polysemous (i.e. has more than one sense) then multiple paths might exist between the two words. In such cases, only the shortest path between any two senses of the words is considered for calculating similarity. A problem that is frequently acknowledged with this approach is that it relies on the notion that all links in the taxonomy represent a uniform distance. As a solution to this problem, Schickel-Zuber and Faltings (2007) propose ontology structure based similarity (OSS) between two concepts in an ontology, which is an asymmetric distance function. Resnik (1995) proposed a similarity measure using information content. He defined the similarity between two concepts C1 and C2 in the taxonomy as the maximum of the information content of all concepts C that subsume both C1 and C2. Then the similarity between two words is defined as the maximum of the similarity between any concepts that the words belong to. He used WordNet as the taxonomy; information content is calculated using the Brown corpus. Li et al., (2003)</context>
</contexts>
<marker>Schickel-Zuber, Faltings, 2007</marker>
<rawString>V. Schickel-Zuber and B. Faltings. 2007. Oss: A semantic similarity function based on hierarchical ontologies. In Proc. of IJCAI’07, pages 551–556.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
<author>S P Ponzetto</author>
</authors>
<title>Wikirelate! computing semantic relatedness using wikipedia.</title>
<date>2006</date>
<booktitle>In Proc. of AAAI’ 06.</booktitle>
<contexts>
<context position="36699" citStr="Strube and Ponzetto, 2006" startWordPosition="6093" endWordPosition="6096"> lad-wizard 0.420 0.062 0.065 0.050 0.426 0.657 0.038 0.000 0.220 0.231 cord-smile 0.130 0.092 0.097 0.015 0.208 0.460 0.025 0.000 0 0.006 glass-magician 0.110 0.107 0.113 0.396 0.598 0.488 0.037 0.000 0.180 0.050 rooster-voyage 0.080 0.000 0.000 0.000 0.228 0.487 0.049 0.000 0.017 0.052 noon-string 0.080 0.116 0.123 0.040 0.102 0.488 0.024 0.000 0.018 0.000 Correlation - 0.260 0.267 0.382 0.549 0.205 0.580 0.694 0.834 0.867 Table 3: Results on WordSimilarity-353 dataset. Method Correlation WordNet Edges (Jarmasz, 1993) 0.27 Hirst &amp; St-Onge (1997) 0.34 Jiang &amp; Conrath (1998) 0.34 WikiRelate! (Strube and Ponzetto, 2006) 0.19-0.48 Leacock &amp; Chodrow (1998) 0.36 Lin (1998b) 0.36 Resnik (1995) 0.37 Proposed 0.504 Table 2: Comparison with WordNet-based similarity measures. Method Correlation Edge-counting 0.664 Jiang &amp; Conrath (1998) 0.848 Lin (1998a) 0.822 Resnik (1995) 0.745 Li et al. (2003) 0.891 ball) and (Jerusalem, Israel)). Because the proposed method use snippets retrieved from a web search engine, it is capable of extracting expressive lexical patterns that can explicitly state the relationship between two entities. If we must compare n objects using a feature model of similarity, then we only need to de</context>
</contexts>
<marker>Strube, Ponzetto, 2006</marker>
<rawString>M. Strube and S. P. Ponzetto. 2006. Wikirelate! computing semantic relatedness using wikipedia. In Proc. of AAAI’ 06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J B Tenenbaum</author>
</authors>
<title>Bayesian modeling of human concept learning.</title>
<date>1999</date>
<booktitle>In NIPS’99.</booktitle>
<contexts>
<context position="2130" citStr="Tenenbaum, 1999" startWordPosition="305" endWordPosition="306">s an organizing principle by which individuals classify objects, and make generalizations (Goldstone, 1994). For example, a biologist would classify a newly found animal specimen based upon the properties that it shares with existing categories of animals. We can then make additional inferences on the new specimen using the properties Research Fellow of the Japan Society for the Promotion of Science (JSPS) known for the existing category. As the similarity between two objects X and Y increases, so does the probability of correctly inferring that Y has the property T upon knowing that X has T (Tenenbaum, 1999). Accurate measurement of semantic similarity between lexical units such as words or phrases is important for numerous tasks in natural language processing such as word sense disambiguation (Resnik, 1995), synonym extraction (Lin, 1998a), and automatic thesauri generation (Curran, 2002). In information retrieval, similar or related words are used to expand user queries to improve recall (Sahami and Heilman, 2006). Semantic similarity is a context dependent and dynamic phenomenon. New words are constantly being created and existing words are assigned with new senses on the Web. To decide whethe</context>
</contexts>
<marker>Tenenbaum, 1999</marker>
<rawString>J. B. Tenenbaum. 1999. Bayesian modeling of human concept learning. In NIPS’99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Tversky</author>
</authors>
<title>Features of similarity.</title>
<date>1977</date>
<journal>Psychological Review,</journal>
<pages>84--327</pages>
<contexts>
<context position="5878" citStr="Tversky (1977)" startWordPosition="906" endWordPosition="907">aling has been used in psychological experiments analyzing the properties of similarity (Krumhansl, 1978). These models represent objects as points in some coordinate space such that the observed dissimilarities between objects correspond to the metric distances between the respective points. Geometric models assume that objects can be adequately represented as points in some coordinate space and that dissimilarity behaves like a metric distance function satisfying minimality, symmetry, and triangle inequality assumptions. However, both dimensional and metric assumptions are open to question. Tversky (1977) proposed the contrast model of similarity to overcome the problems in geometric models. The contrast model relies on featural representation of objects, and it is used to compute the similarity between the representations of two objects. Similarity is defined as an increasing function of common features (i.e. features in common to the two objects), and as a decreasing function of distinctive features (i.e. features that apply to one object but not the other). The attributes of objects are primal to contrast model and it does not explicitly incorporate the relations between objects when measur</context>
<context position="16443" citStr="Tversky, 1977" startWordPosition="2653" endWordPosition="2654">z and cp Matrix A is expected to capture the dependence between semantic relations. Intuitively, if two clusters i and j are highly correlated, then the (i, j)-th element of A will be closer to 1. Equation 3 computes the similarity between a word pair (a, b) and a set of synonymous word pairs. Intuitively, if the relations that exist between a and b are typical relations that hold between synonymous word pairs, then Equation 3 returns a high similarity score for a and b. The proposed relational model of semantic similarity differs from feature models of similarity, such as the contrast model (Tversky, 1977), in that it is defined over the set of semantic relations that exist between two words instead of the set of features for each word. Specifically, in contrast model, the similarity S(a, b) between two objects a and b is defined in terms of the features common to a and b, A n B, the features that are distinctive to a, A − B, and the features that are distinctive to b, B − A. The contrast model is formalized in the following equation, S(a, b) = Of(A n B) − af(A − B) − Of(B − A). (4) Here, the function f measures the salience of a particular set of features, and non-negative parameters a, Q, and</context>
</contexts>
<marker>Tversky, 1977</marker>
<rawString>A. Tversky. 1977. Features of similarity. Psychological Review, 84:327–652.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McLean Y Li</author>
<author>Zuhair A Bandar</author>
</authors>
<title>An approch for measuring semantic similarity between words using multiple information sources.</title>
<date>2003</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<volume>15</volume>
<issue>4</issue>
<marker>Li, Bandar, 2003</marker>
<rawString>D. McLean Y. Li, Zuhair A. Bandar. 2003. An approch for measuring semantic similarity between words using multiple information sources. IEEE Transactions on Knowledge and Data Engineering, 15(4):871–882.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>