<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.743309">
<figure confidence="0.988593571428572">
. . .
Frames
. . .
Models . . . . . .
(a) Linear Sequence of Mixture Models
(b) The Equivalent Full Gaussian Transition Model
(c) Pruned Gaussian Transition Model
</figure>
<bodyText confidence="0.9800915">
Hence data sufficiency becomes a concern. In our
experiments, we choose to model only frequent tran-
sitions. For everything else, we revert to the tradi-
tional HMM-GMM model: aii =
</bodyText>
<subsectionHeader confidence="0.995923">
3.2 Pruning
</subsectionHeader>
<bodyText confidence="0.999763769230769">
Even in conventional HMM training, it is common to
ignore transition probabilities. Their contribution to
the overall score is quite small, in comparison to ob-
servation probabilities in a continuous HMM (which
is several orders of magnitude larger). The same
is true for Gaussian transition probabilities. While
GTM offers better discrimination between trajecto-
ries, all trajectories are nonetheless still permitted.
Pruning unlikely transitions leads to a model that
is both more compact and more prudent. In reality,
however, we need to exercise great care in pruning
so as not to prune away unseen trajectories (due to
a limited training set).
</bodyText>
<sectionHeader confidence="0.998671" genericHeader="abstract">
4 Experiments
</sectionHeader>
<bodyText confidence="0.998141714285714">
Experiments are carried out on the Switchboard
(SWB) task using the Janus system (Soltau et al.,
2002). The test set is a 1 hour subset of the 2001
Hub5e evaluation set. Acoustic training uses a 66
hours subset of the SWB data. We use a 15k vocab-
ulary and a trigram language model trained on SWB
and CallHome. The front-end has vocal tract length
normalization, cepstral mean normalization, an 11-
frame window to derive delta and double-delta, linear
discriminant analysis and semi-tied covariance with
a single class. The acoustic model has roughly 6000
mixtures with a total of 86K Gaussians, on average
14 Gaussians per model.
We apply a two-tiered strategy to cope with the
data sufficiency issue. Before training, we count the
number of transitions for each model pair on the
training data, using Viterbi alignment. Only tran-
sitions with counts above a certain threshold are
modeled with GTM. Of about 6000 mixture mod-
els, a total of 40K model pairs (out of a poten-
tial 6K x6K=36M) has been observed. It turns out
that most of the transitions (72%) are within the
same model (corresponding to self-loop in HMM).
We choose to model the most frequent 9400 model
pairs with GTM. Not surprisingly, most of the 6000
same-model pairs are among those chosen. During
training, we also apply a minimum count criterion:
a transition model is updated only if the Gaussian
receives enough training counts.
One iteration of Baum-Welch training gives signif-
icant improvement in term of likelihood. Log like-
lihood per frame improves from —50.67 to —49.18,
while conventional HMM training can only improve
less than 0.1. Considering the baseline acoustic
model has already been highly optimized, this in-
dicates improved acoustic modeling.
GTM transitions are pruned if their probabilities
fall below a certain threshold (default is le-5). Ta-
ble 1 shows word error rates for GTM models pruned
against different thresholds. It is encouraging that a
0.5% gain is obtained after pruning away almost 2/3
of all transitions.
</bodyText>
<table confidence="0.999885428571429">
Pruning Avg. # Transitions WER
Threshold per Gaussian (%)
baseline 14.4 34.1
le-5 9.7 33.7
le-3 6.6 33.7
0.01 4.6 33.6
0.05 2.7 33.9
</table>
<tableCaption confidence="0.999468">
Table 1: Word Error Rates on Switchboard
</tableCaption>
<sectionHeader confidence="0.989793" genericHeader="categories and subject descriptors">
5 Future Work
</sectionHeader>
<bodyText confidence="0.999888636363636">
In this paper, we have presented Gaussian Transition
Model, a new approach to model trajectories within
the HMM framework. Preliminary experiments have
shown encouraging improvements.
There are several possibilities for further im-
provements. First, when modifying the decoder to
use GTM, we used Viterbi approximation at word
boundaries, which means trajectory information is
lost upon word transition. Second, we plan to ex-
tend GTM to handle deletions in sloppy speech, a
major challenge in LVCSR.
</bodyText>
<sectionHeader confidence="0.998142" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.989853235294118">
R. Iyer, H. Gish, M. Siu, G. Zavaliagkos, and S. Mat-
soukas. 1998. Hidden markov models for trajec-
tory modeling. In Proc. ICSLP.
M. Ostendorf, V. Digilakis, and 0. Kimball. 1996.
From hmms to segment models: A unified view of
stochastic modeling for speech recognition. IEEE
Transactions on Speech and Audio Processing.
L. Rabiner. 1989. A tutorial on hidden markov mod-
els and selected applications in speech recognition.
In Proc. IEEE, 77 (2), 257-286.
M. Saraclar, H. Nock, and S. Khudanpur. 2000.
Pronunciation modeling by sharing gaussian den-
sities across phonetic models. Computer Speech
and Language, 14(2):137-160, April.
H. Soltau, H. Yu, F. Metze, C. Ffigen, Y. Pan, and
S. Jou. 2002. ISL meeting recognition. In Rich
Transcription Workshop, Vienna, VA.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.104827">
<abstract confidence="0.983968959183673">Frames . . . . . . . . (a) Linear Sequence of Mixture Models (b) The Equivalent Full Gaussian Transition Model (c) Pruned Gaussian Transition Model Hence data sufficiency becomes a concern. In our experiments, we choose to model only frequent transitions. For everything else, we revert to the tradi- HMM-GMM model: = 3.2 Pruning Even in conventional HMM training, it is common to ignore transition probabilities. Their contribution to the overall score is quite small, in comparison to observation probabilities in a continuous HMM (which is several orders of magnitude larger). The same is true for Gaussian transition probabilities. While GTM offers better discrimination between trajectories, all trajectories are nonetheless still permitted. Pruning unlikely transitions leads to a model that is both more compact and more prudent. In reality, however, we need to exercise great care in pruning so as not to prune away unseen trajectories (due to a limited training set). 4 Experiments Experiments are carried out on the Switchboard (SWB) task using the Janus system (Soltau et al., 2002). The test set is a 1 hour subset of the 2001 Hub5e evaluation set. Acoustic training uses a 66 hours subset of the SWB data. We use a 15k vocabulary and a trigram language model trained on SWB and CallHome. The front-end has vocal tract length cepstral mean normalization, an 11frame window to derive delta and double-delta, linear discriminant analysis and semi-tied covariance with a single class. The acoustic model has roughly 6000 mixtures with a total of 86K Gaussians, on average 14 Gaussians per model. We apply a two-tiered strategy to cope with the data sufficiency issue. Before training, we count the number of transitions for each model pair on the training data, using Viterbi alignment. Only transitions with counts above a certain threshold are modeled with GTM. Of about 6000 mixture models, a total of 40K model pairs (out of a potential 6K x6K=36M) has been observed. It turns out that most of the transitions (72%) are within the same model (corresponding to self-loop in HMM). We choose to model the most frequent 9400 model pairs with GTM. Not surprisingly, most of the 6000 same-model pairs are among those chosen. During training, we also apply a minimum count criterion: a transition model is updated only if the Gaussian receives enough training counts. One iteration of Baum-Welch training gives significant improvement in term of likelihood. Log likelihood per frame improves from —50.67 to —49.18, while conventional HMM training can only improve less than 0.1. Considering the baseline acoustic model has already been highly optimized, this indicates improved acoustic modeling. GTM transitions are pruned if their probabilities fall below a certain threshold (default is le-5). Table 1 shows word error rates for GTM models pruned against different thresholds. It is encouraging that a 0.5% gain is obtained after pruning away almost 2/3 of all transitions. Threshold Avg. # Transitions per Gaussian WER (%) baseline 14.4 34.1 le-5 9.7 33.7 le-3 6.6 33.7 0.01 4.6 33.6 0.05 2.7 33.9 Table 1: Word Error Rates on Switchboard 5 Future Work In this paper, we have presented Gaussian Transition Model, a new approach to model trajectories within the HMM framework. Preliminary experiments have shown encouraging improvements. There are several possibilities for further improvements. First, when modifying the decoder to use GTM, we used Viterbi approximation at word boundaries, which means trajectory information is lost upon word transition. Second, we plan to extend GTM to handle deletions in sloppy speech, a major challenge in LVCSR. References R. Iyer, H. Gish, M. Siu, G. Zavaliagkos, and S. Matsoukas. 1998. Hidden markov models for trajecmodeling. In ICSLP. Ostendorf, V. Digilakis, and 1996. From hmms to segment models: A unified view of modeling for speech recognition. Transactions on Speech and Audio Processing. L. Rabiner. 1989. A tutorial on hidden markov models and selected applications in speech recognition.</abstract>
<note confidence="0.61599175">IEEE, 77 (2), 257-286. M. Saraclar, H. Nock, and S. Khudanpur. 2000. Pronunciation modeling by sharing gaussian denacross phonetic models. Speech Language, April. H. Soltau, H. Yu, F. Metze, C. Ffigen, Y. Pan, and Jou. 2002. ISL meeting recognition. In Workshop, VA.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Iyer</author>
<author>H Gish</author>
<author>M Siu</author>
<author>G Zavaliagkos</author>
<author>S Matsoukas</author>
</authors>
<title>Hidden markov models for trajectory modeling. In</title>
<date>1998</date>
<booktitle>Proc. ICSLP.</booktitle>
<marker>Iyer, Gish, Siu, Zavaliagkos, Matsoukas, 1998</marker>
<rawString>R. Iyer, H. Gish, M. Siu, G. Zavaliagkos, and S. Matsoukas. 1998. Hidden markov models for trajectory modeling. In Proc. ICSLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ostendorf</author>
<author>V Digilakis</author>
</authors>
<title>From hmms to segment models: A unified view of stochastic modeling for speech recognition.</title>
<date>1996</date>
<journal>IEEE Transactions on Speech and Audio Processing.</journal>
<marker>Ostendorf, Digilakis, 1996</marker>
<rawString>M. Ostendorf, V. Digilakis, and 0. Kimball. 1996. From hmms to segment models: A unified view of stochastic modeling for speech recognition. IEEE Transactions on Speech and Audio Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Rabiner</author>
</authors>
<title>A tutorial on hidden markov models and selected applications in speech recognition.</title>
<date>1989</date>
<booktitle>In Proc. IEEE,</booktitle>
<volume>77</volume>
<issue>2</issue>
<pages>257--286</pages>
<marker>Rabiner, 1989</marker>
<rawString>L. Rabiner. 1989. A tutorial on hidden markov models and selected applications in speech recognition. In Proc. IEEE, 77 (2), 257-286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Saraclar</author>
<author>H Nock</author>
<author>S Khudanpur</author>
</authors>
<title>Pronunciation modeling by sharing gaussian densities across phonetic models. Computer Speech and Language,</title>
<date>2000</date>
<pages>14--2</pages>
<marker>Saraclar, Nock, Khudanpur, 2000</marker>
<rawString>M. Saraclar, H. Nock, and S. Khudanpur. 2000. Pronunciation modeling by sharing gaussian densities across phonetic models. Computer Speech and Language, 14(2):137-160, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Soltau</author>
<author>H Yu</author>
<author>F Metze</author>
<author>C Ffigen</author>
<author>Y Pan</author>
<author>S Jou</author>
</authors>
<title>ISL meeting recognition. In Rich Transcription Workshop,</title>
<date>2002</date>
<location>Vienna, VA.</location>
<contexts>
<context position="1117" citStr="Soltau et al., 2002" startWordPosition="179" endWordPosition="182">comparison to observation probabilities in a continuous HMM (which is several orders of magnitude larger). The same is true for Gaussian transition probabilities. While GTM offers better discrimination between trajectories, all trajectories are nonetheless still permitted. Pruning unlikely transitions leads to a model that is both more compact and more prudent. In reality, however, we need to exercise great care in pruning so as not to prune away unseen trajectories (due to a limited training set). 4 Experiments Experiments are carried out on the Switchboard (SWB) task using the Janus system (Soltau et al., 2002). The test set is a 1 hour subset of the 2001 Hub5e evaluation set. Acoustic training uses a 66 hours subset of the SWB data. We use a 15k vocabulary and a trigram language model trained on SWB and CallHome. The front-end has vocal tract length normalization, cepstral mean normalization, an 11- frame window to derive delta and double-delta, linear discriminant analysis and semi-tied covariance with a single class. The acoustic model has roughly 6000 mixtures with a total of 86K Gaussians, on average 14 Gaussians per model. We apply a two-tiered strategy to cope with the data sufficiency issue.</context>
</contexts>
<marker>Soltau, Yu, Metze, Ffigen, Pan, Jou, 2002</marker>
<rawString>H. Soltau, H. Yu, F. Metze, C. Ffigen, Y. Pan, and S. Jou. 2002. ISL meeting recognition. In Rich Transcription Workshop, Vienna, VA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>