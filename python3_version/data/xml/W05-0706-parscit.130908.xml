<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000079">
<title confidence="0.997002">
Choosing an Optimal Architecture for Segmentation and POS-Tagging of
Modern Hebrew
</title>
<author confidence="0.997374">
Roy Bar-Haim
</author>
<affiliation confidence="0.9914395">
Dept. of Computer Science
Bar-Ilan University
</affiliation>
<address confidence="0.689438">
Ramat-Gan 52900, Israel
</address>
<email confidence="0.993443">
barhair@cs.biu.ac.il
</email>
<author confidence="0.835151">
Khalil Sima’an
</author>
<affiliation confidence="0.749367">
ILLC
</affiliation>
<address confidence="0.6128545">
Universiteit van Amsterdam
Amsterdam, The Netherlands
</address>
<email confidence="0.995081">
simaan@science.uva.nl
</email>
<author confidence="0.991502">
Yoad Winter
</author>
<affiliation confidence="0.830792">
Dept. of Computer Science
Technion
</affiliation>
<address confidence="0.85451">
Haifa 32000, Israel
</address>
<email confidence="0.99612">
winter@cs.technion.ac.il
</email>
<sectionHeader confidence="0.995599" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.986894545454545">
A major architectural decision in de-
signing a disambiguation model for seg-
mentation and Part-of-Speech (POS) tag-
ging in Semitic languages concerns the
choice of the input-output terminal sym-
bols over which the probability distribu-
tions are defined. In this paper we de-
velop a segmenter and a tagger for He-
brew based on Hidden Markov Models
(HMMs). We start out from a morpholog-
ical analyzer and a very small morpholog-
ically annotated corpus. We show that a
model whose terminal symbols are word
segments (=morphemes), is advantageous
over a word-level model for the task of
POS tagging. However, for segmentation
alone, the morpheme-level model has no
significant advantage over the word-level
model. Error analysis shows that both
models are not adequate for resolving a
common type of segmentation ambiguity
in Hebrew – whether or not a word in a
written text is prefixed by a definiteness
marker. Hence, we propose a morpheme-
level model where the definiteness mor-
pheme is treated as a possible feature of
morpheme terminals. This model exhibits
the best overall performance, both in POS
tagging and in segmentation. Despite the
small size of the annotated corpus avail-
able for Hebrew, the results achieved us-
ing our best model are on par with recent
results on Modern Standard Arabic.
</bodyText>
<sectionHeader confidence="0.997682" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999923666666667">
Texts in Semitic languages like Modern Hebrew
(henceforth Hebrew) and Modern Standard Ara-
bic (henceforth Arabic), are based on writing sys-
tems that allow the concatenation of different lexi-
cal units, called morphemes. Morphemes may be-
long to various Part-of-Speech (POS) classes, and
their concatenation forms textual units delimited by
white space, which are commonly referred to as
words. Hence, the task of POS tagging for Semitic
languages consists of a segmentation subtask and
a classification subtask. Crucially, words can be
segmented into different alternative morpheme se-
quences, where in each segmentation morphemes
may be ambiguous in terms of their POS tag. This
results in a high level of overall ambiguity, aggra-
vated by the lack of vocalization in modern Semitic
texts.
One crucial problem concerning POS tagging of
Semitic languages is how to adapt existing methods
in the best way, and which architectural choices have
to be made in light of the limited availability of an-
notated corpora (especially for Hebrew). This paper
outlines some alternative architectures for POS tag-
ging of Hebrew text, and studies them empirically.
This leads to some general conclusions about the op-
timal architecture for disambiguating Hebrew, and
(reasonably) other Semitic languages as well. The
choice of tokenization level has major consequences
for the implementation using HMMs, the sparseness
of the statistics, the balance of the Markov condi-
</bodyText>
<page confidence="0.993313">
39
</page>
<note confidence="0.9931095">
Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages, pages 39–46,
Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<bodyText confidence="0.985855192307693">
tioning, and the possible loss of information. The
paper reports on extensive experiments for compar-
ing different architectures and studying the effects
of this choice on the overall result. Our best result
is on par with the best reported POS tagging results
for Arabic, despite the much smaller size of our an-
notated corpus.
The paper is structured as follows. Section 2 de-
fines the task of POS tagging in Hebrew, describes
the existing corpora and discusses existing related
work. Section 3 concentrates on defining the dif-
ferent levels of tokenization, specifies the details of
the probabilistic framework that the tagger employs,
and describes the techniques used for smoothing the
probability estimates. Section 4 compares the differ-
ent levels of tokenization empirically, discusses their
limitations, and proposes an improved model, which
outperforms both of the initial models. Finally, sec-
tion 5 discusses the conclusions of our study for seg-
mentation and POS tagging of Hebrew in particular,
and Semitic languages in general.
2 Task definition, corpora and related
work
Words in Hebrew texts, similar to words in Ara-
bic and other Semitic languages, consist of a stem
and optional prefixes and suffixes. Prefixes include
conjunctions, prepositions, complementizers and the
definiteness marker (in a strict well-defined order).
Suffixes include inflectional suffixes (denoting gen-
der, number, person and tense), pronominal comple-
ments with verbs and prepositions, and possessive
pronouns with nouns.
By the term word segmentation we henceforth re-
fer to identifying the prefixes, the stem and suffixes
of the word. By POS tag disambiguation we mean
the assignment of a proper POS tag to each of these
morphemes.
In defining the task of segmentation and POS tag-
ging, we ignore part of the information that is usu-
ally found in Hebrew morphological analyses. The
internal morphological structure of stems is not an-
alyzed, and the POS tag assigned to stems includes
no information about their root, template/pattern, in-
flectional features and suffixes. Only pronominal
complement suffixes on verbs and prepositions are
identified as separate morphemes. The construct
state/absolute,1 and the existence of a possessive
suffix are identified using the POS tag assigned to
the stem, and not as a separate segment or feature.
Some of these conventions are illustrated by the seg-
mentation and POS tagging of the word wfnpgfnw
(“and that we met”, pronounced ve-she-nifgashnu):2
</bodyText>
<listItem confidence="0.412054666666667">
w/CC: conjunction
f/COM: complementizer
npgfnw/VB: verb
</listItem>
<bodyText confidence="0.942772">
Our segmentation and POS tagging conform with
the annotation scheme used in the Hebrew Treebank
(Sima’an et al., 2001), described next.
</bodyText>
<subsectionHeader confidence="0.995012">
2.1 Available corpora
</subsectionHeader>
<bodyText confidence="0.999757086956522">
The Hebrew Treebank (Sima’an et al., 2001) con-
sists of syntactically annotated sentences taken from
articles from the Ha’aretz daily newspaper. We ex-
tracted from the treebank a mapping from each word
to its analysis as a sequence of POS tagged mor-
phemes. The treebank version used in the current
work contains 57 articles, which amount to 1,892
sentences, 35,848 words, and 48,332 morphemes.
In addition to the manually tagged corpus, we have
access to an untagged corpus containing 337,651
words, also originating from Ha’aretz newspaper.
The tag set, containing 28 categories, was ob-
tained from the full morphological tagging by re-
moving the gender, number, person and tense fea-
tures. This tag set was used for training the POS
tagger. In the evaluation of the results, however, we
perform a further grouping of some POS tags, lead-
ing to a reduced POS tag set of 21 categories. The
tag set and the grouping scheme are shown below:
{NN}, {NN-H}, {NNT}, {NNP}, {PRP,AGR}, {JJ}, {JJT},
{RB,MOD}, {RBR}, {VB,AUX}, {VB-M}, {IN,COM,REL},
{CC}, {QW}, {HAM}, {WDT,DT}, {CD,CDT}, {AT}, {H},
{POS}, {ZVL}.
</bodyText>
<subsectionHeader confidence="0.543957">
2.2 Related work on Hebrew and Arabic
</subsectionHeader>
<bodyText confidence="0.986974">
Due to the lack of substantial tagged corpora, most
previous corpus-based work on Hebrew focus on the
</bodyText>
<footnote confidence="0.997772714285714">
1The Semitic construct state is a special form of a word
that participates in compounds. For instance, in the Hebrew
compound bdiqt hjenh (“check of the claim”), the word bdiqt
(“check of”/“test of”) is the construct form of the absolute form
bdiqh (“check”/“test”).
2In this paper we use Latin transliteration for Hebrew letters
following (Sima’an et al., 2001).
</footnote>
<page confidence="0.998995">
40
</page>
<bodyText confidence="0.999973333333333">
development of techniques for learning probabilities
from large unannotated corpora. The candidate anal-
yses for each word were usually obtained from a
morphological analyzer.
Levinger et al. (1995) propose a method for
choosing a most probable analysis for Hebrew
words using an unannotated corpus, where each
analysis consists of the lemma and a set of morpho-
logical features. They estimate the relative frequen-
cies of the possible analyses for a given word w by
defining a set of “similar words” 5W (A) for each
possible analysis A of w. Each word w&apos; in 5W (A)
corresponds to an analysis A&apos; which differs from A
in exactly one feature. Since each set is expected to
contain different words, it is possible to approximate
the frequency of the different analyses using the av-
erage frequency of the words in each set, estimated
from the untagged corpus.
Carmel and Maarek (1999) follow Levinger et
al. in estimating context independent probabilities
from an untagged corpus. Their algorithm learns fre-
quencies of morphological patterns (combinations
of morphological features) from the unambiguous
words in the corpus.
Several works aimed at improving the “similar
words” method by considering the context of the
word. Levinger (1992) adds a short context filter that
enforces grammatical constraints and rules out im-
possible analyses. Segal’s (2000) system includes,
in addition to a somewhat different implementation
of “similar words”, two additional components: cor-
rection rules a` la Brill (1995), and a rudimentary de-
terministic syntactic parser.
Using HMMs for POS tagging and segmenting
Hebrew was previously discussed in (Adler, 2001).
The HMM in Adler’s work is trained on an untagged
corpus, using the Baum-Welch algorithm (Baum,
1972). Adler suggests various methods for perform-
ing both tagging and segmentation, most notable are
(a) The usage of word-level tags, which uniquely de-
termine the segmentation and the tag of each mor-
pheme, and (b) The usage of a two-dimensional
Markov model with morpheme-level tags. Only the
first method (word-level tags) was tested, resulting
in an accuracy of 82%. In the present paper, both
word-level tagging and morpheme-level tagging are
evaluated.
Moving on to Arabic, Lee et al. (2003) describe a
word segmentation system for Arabic that uses an n-
gram language model over morphemes. They start
with a seed segmenter, based on a language model
and a stem vocabulary derived from a manually seg-
mented corpus. The seed segmenter is improved it-
eratively by applying a bootstrapping scheme to a
large unsegmented corpus. Their system achieves
accuracy of 97.1% (per word).
Diab et al. (2004) use Support Vector Machines
(SVMs) for the tasks of word segmentation and POS
tagging (and also Base Phrase Chunking). For seg-
mentation, they report precision of 99.09% and re-
call of 99.15%, when measuring morphemes that
were correctly identified. For tagging, Diab et al.
report accuracy of 95.49%, with a tag set of 24 POS
tags. Tagging was applied to segmented words, us-
ing the “gold” segmentation from the annotated cor-
pus (Mona Diab, p.c.).
</bodyText>
<sectionHeader confidence="0.9742255" genericHeader="method">
3 Architectures for POS tagging Semitic
languages
</sectionHeader>
<bodyText confidence="0.999972909090909">
Our segmentation and POS tagging system consists
of a morphological analyzer that assigns a set of
possible candidate analyses to each word, and a dis-
ambiguator that selects from this set a single pre-
ferred analysis per word. Each candidate analysis
consists of a segmentation of the word into mor-
phemes, and a POS tag assignment to these mor-
phemes. In this section we concentrate on the ar-
chitectural decisions in devising an optimal disam-
biguator, given a morphological analyzer for He-
brew (or another Semitic language).
</bodyText>
<subsectionHeader confidence="0.999824">
3.1 Defining the input/output
</subsectionHeader>
<bodyText confidence="0.985156846153846">
An initial crucial decision in building a disambigua-
tor for a Semitic text concerns the “tokenization” of
the input sentence: what constitutes a terminal (i.e.,
input) symbol. Unlike English POS tagging, where
the terminals are usually assumed to be words (de-
limited by white spaces), in Semitic texts there are
two reasonable options for fixing the kind of termi-
nal symbols, which directly define the correspond-
ing kind of nonterminal (i.e., output) symbols:
Words (W): The terminals are words as they ap-
pear in the text. In this case a nonterminal a
that is assigned to a word w consists of a se-
quence of POS tags, each assigned to a mor-
</bodyText>
<page confidence="0.996667">
41
</page>
<bodyText confidence="0.999808583333333">
pheme of w, delimited with a special segmenta-
tion symbol. We henceforth refer to such com-
plex nonterminals as analyses. For instance,
the analysis IN-H-NN for the Hebrew word
bbit uniquely encodes the segmentation b-h-bit.
In Hebrew, this unique encoding of the segmen-
tation by the sequence of POS tags in the anal-
ysis is a general property: given a word w and
a complex nonterminal a = [t1 ... tp] for w, it
is possible to extend a back to a full analysis
a˜ = [(m1, t1) ... (mp, tp)], which includes the
morphemes m1 ... mp that make out w. This is
done by finding a match for a in Analyses(w),
the set of possible analyses of w. Except for
very rare cases, this match is unique.
Morphemes (M): In this case the nonterminals are
the usual POS tags, and the segmentation is
given by the input morpheme sequence. Note
that information about how morphemes are
joined into words is lost in this case.
Having described the main input-output options for
the disambiguator, we move on to describing the
probabilistic framework that underlies their work-
ings.
</bodyText>
<subsectionHeader confidence="0.999221">
3.2 The probabilistic framework
</subsectionHeader>
<bodyText confidence="0.999979">
Let wk1 be the input sentence, a sequence of words
w1 ... wk. If tokenization is per word, then the
disambiguator aims at finding the nonterminal se-
quence ak1 that has the highest joint probability with
the given sentence wk1:
</bodyText>
<equation confidence="0.972123333333333">
arg max P(wk1, ak1) (1)
ak
1
</equation>
<bodyText confidence="0.965560625">
This setting is the standard formulation of proba-
bilistic tagging for languages like English.
If tokenization is per morpheme, the disambigua-
tor aims at finding a combination of a segmentation
mn1 and a tagging tn1 for mn1, such that their joint
probability with the given sentence, wk1, is maxi-
mized:
morphological analyzer). Note that n can be dif-
ferent from k, and may vary for different segmen-
tations. The original sentence can be uniquely re-
covered from the segmentation and the tagging.
Since all the (mn1, tn1) pairs that are the input for
the disambiguator were derived from wk1, we have
P(wk1|mn1, tn1) = 1, and thus P(wk1, mn1, tn1) =
P(tn1, mn1). Therefore, Formula (2) can be simpli-
fied as:
</bodyText>
<equation confidence="0.880947">
arg max P(mn1, tn1) (3)
(mn1 ,tn1 )EANALY SES(wk 1)
</equation>
<bodyText confidence="0.900578928571429">
Formulas (1) and (3) can be represented in a unified
formula that applies to both word tokenization and
morpheme tokenization:
arg max P(en1, An1) (4)
(en1 ,An 1 )EANALY SES(wk1 )
In Formula (4) en1 represents either a sequence of
words or a sequence of morphemes, depending on
the level of tokenization, and An1 are the respective
nonterminals – either POS tags or word-level anal-
yses. Thus, the disambiguator aims at finding the
most probable (terminal sequence, nonterminal
sequence) for the given sentence, where in the
case of word-tokenization there is only one possible
terminal sequence for the sentence.
</bodyText>
<subsectionHeader confidence="0.988841">
3.3 HMM probabilistic model
</subsectionHeader>
<bodyText confidence="0.999537285714286">
The actual probabilistic model used in this work for
estimating P(en1, An1) is based on Hidden Markov
Models (HMMs). HMMs underly many successful
POS taggers , e.g. (Church, 1988; Charniak et al.,
1993).
For a k-th order Markov model (k = 1 or k = 2),
we rewrite (4) as:
</bodyText>
<equation confidence="0.894161">
arg max
en 1 ,An 1 P(n n
e1 , A1 �
P(Ai  |Ai−k, ... , Ai−1)P(ei  |Ai)
n
arg max
en 1 ,An 1 i=1
arg max P(wk 1, m1n, tn1), (2) (5)
(mn1 ,tn1 )EANALY SES(wk 1)
</equation>
<bodyText confidence="0.9999206">
where ANALY SES(wk1) is the set of possible
analyses for the input sentence wk1 (output by the
For reasons of data sparseness, actual models we use
work with k = 2 for the morpheme level tokeniza-
tion, and with k = 1 for the word level tokenization.
</bodyText>
<page confidence="0.995788">
42
</page>
<bodyText confidence="0.996328277777778">
For these models, two kinds of probabilities need
to be estimated: P(ei  |Ai) (lexical model) and
P(Ai  |Ai−k, ... , Ai−1) (language model). Because
the only manually POS tagged corpus that was avail-
able to us for training the HMM was relatively small
(less than 4% of the Wall Street Journal (WSJ) por-
tion of the Penn treebank), it is inevitable that major
effort must be dedicated to alleviating the sparseness
problems that arise. For smoothing the nonterminal
language model probabilities we employ the stan-
dard backoff smoothing method of Katz (1987).
Naturally, the relative frequency estimates of
the lexical model suffer from more severe data-
sparseness than the estimates for the language
model. On average, 31.3% of the test words do
not appear in the training corpus. Our smooth-
ing method for the lexical probabilities is described
next.
</bodyText>
<subsectionHeader confidence="0.999054">
3.4 Bootstrapping a better lexical model
</subsectionHeader>
<bodyText confidence="0.939630333333333">
For the sake of exposition, we assume word-level
tokenization for the rest of this subsection. The
method used for the morpheme-level tagger is very
similar.
The smoothing of the lexical probability of a word
w given an analysis a, i.e., P(w  |a) = P(w,a)
</bodyText>
<equation confidence="0.928003">
P (a) ,
</equation>
<bodyText confidence="0.999849428571429">
is accomplished by smoothing the joint probability
P(w, a) only, i.e., we do not smooth P(a).3 To
smooth P(w, a), we use a linear interpolation of
the relative frequency estimates from the annotated
training corpus (denoted rftr(w, a)) together with
estimates obtained by unsupervised estimation from
a large unannotated corpus (denoted emauto(w, a)):
</bodyText>
<equation confidence="0.997701">
P(w, a) = A rftr(w, a)+(1−A) emauto(w, a)
(6)
</equation>
<bodyText confidence="0.999940625">
where A is an interpolation factor, experimentally set
to 0.85.
Our unsupervised estimation method can be
viewed as a single iteration of the Baum-Welch
(Forward-Backward) estimation algorithm (Baum,
1972) with minor differences. We apply this method
to the untagged corpus of 340K words. Our method
starts out from a naively smoothed relative fre-
</bodyText>
<equation confidence="0.88272975">
3the smoothed probabilities are normalized so that
E. P(w, a) = P(a)
quency lexical model in our POS tagger:
�
(1 − p0) rftr(w, a) ftr(w) &gt; 0
PLM0(w|a) =
p0 otherwise
(7)
</equation>
<bodyText confidence="0.996853777777778">
Where ftr(w) is the occurrence frequency of w in
the training corpus, and p0 is a constant set experi-
mentally to 10−10. We denote the tagger that em-
ploys a smoothed language model and the lexical
model PLMo by the probability distribution Pbasi,
(over analyses, i.e., morpheme-tag sequences).
In the unsupervised algorithm, the model Pbasi,
is used to induce a distribution of alternative analy-
ses (morpheme-tag sequences) for each of the sen-
tences in the untagged corpus; we limit the num-
ber of alternative analyses per sentence to 300. This
way we transform the untagged corpus into a “cor-
pus” containing weighted analyses (i.e., morpheme-
tag sequences). This corpus is then used to calcu-
late the updated lexical model probabilities using
maximum-likelihood estimation. Adding the test
sentences to the untagged corpus ensures non-zero
probabilities for the test words.
</bodyText>
<subsectionHeader confidence="0.833476">
3.5 Implementation4
</subsectionHeader>
<bodyText confidence="0.9999666">
The set of candidate analyses was obtained from Se-
gal’s morphological analyzer (Segal, 2000). The
analyzer’s dictionary contains 17,544 base forms
that can be inflected. After this dictionary was ex-
tended with the tagged training corpus, it recog-
nizes 96.14% of the words in the test set.5 For each
train/test split of the corpus, we only use the training
data for enhancing the dictionary. We used SRILM
(Stolcke, 2002) for constructing language models,
and for disambiguation.
</bodyText>
<sectionHeader confidence="0.998855" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.976244857142857">
In this section we report on an empirical comparison
between the two levels of tokenization presented in
the previous section. Analysis of the results leads to
an improved morpheme-level model, which outper-
forms both of the initial models.
Each architectural configuration was evaluated in
5-fold cross-validated experiments. In a train/test
</bodyText>
<footnote confidence="0.99815325">
4http://www.cs.technion.ac.il/—barhaim/MorphTagger/
5Unrecognized words are assumed to be proper nouns, and
the morphological analyzer proposes possible segmentations for
the word, based on the recognition of possible prefixes.
</footnote>
<page confidence="0.999856">
43
</page>
<bodyText confidence="0.9997785">
split of the corpus, the training set includes 1,598
sentences on average, which on average amount to
28,738 words and 39,282 morphemes. The test set
includes 250 sentences. We estimate segmentation
accuracy – the percentage of words correctly seg-
mented into morphemes, as well as tagging accu-
racy – the percentage of words that were correctly
segmented for which each morpheme was assigned
the correct POS tag.
For each parameter, the average over the five folds
is reported, with the standard deviation in parenthe-
ses. We used two-tailed paired t-test for testing the
significance of the difference between the average
results of different systems. The significance level
(p-value) is reported.
The first two lines in Table 1 detail the results ob-
tained for both word (W) and morpheme (M) lev-
els of tokenization. The tagging accuracy of the
</bodyText>
<table confidence="0.999729">
Accuracy per word (%)
Tokenization Tagging Segmentation
W 89.42 (0.9) 96.43 (0.3)
M 90.21 (1.2) 96.25 (0.5)
M+h 90.51 (1.0) 96.74 (0.5)
</table>
<tableCaption confidence="0.999644">
Table 1: Level of tokenization - experimental results
</tableCaption>
<bodyText confidence="0.999779984848485">
morpheme tagger is considerably better than what
is achieved by the word tagger (difference of 0.79%
with significance level p = 0.01). This is in spite of
the fact that the segmentation achieved by the word
tagger is a little better (and a segmentation error im-
plies incorrect tagging). Our hypothesis is that:
Morpheme-level taggers outperform
word-level taggers in their tagging ac-
curacy, since they suffer less from data
sparseness. However, they lack some
word-level knowledge that is required for
segmentation.
This hypothesis is supported by the number of
once-occurring terminals in each level: 8,582 in the
word level, versus 5,129 in the morpheme level.
Motivated by this hypothesis, we next consider
what kind of word-level information is required for
the morpheme-level tagger in order to do better in
segmentation. One natural enhancement for the
morpheme-level model involves adding information
about word boundaries to the tag set. In the en-
hanced tag set, nonterminal symbols include addi-
tional features that indicate whether the tagged mor-
pheme starts/ends a word. Unfortunately, we found
that adding word boundary information in this way
did not improve segmentation accuracy.
However, error analysis revealed a very common
type of segmentation errors, which was found to be
considerably more frequent in morpheme tagging
than in word tagging. This kind of errors involves
a missing or an extra covert definiteness marker ’h’.
For example, the word bbit can be segmented either
as b-bit (“in a house”) or as b-h-bit (“in the house”),
pronounced bebayit and babayit, respectively. Un-
like other cases of segmentation ambiguity, which
often just manifest lexical facts about spelling of He-
brew stems, this kind of ambiguity is productive: it
occurs whenever the stem’s POS allows definiteness,
and is preceded by one of the prepositions b/k/l. In
morpheme tagging, this type of error was found on
average in 1.71% of the words (46% of the segmen-
tation errors). In word tagging, it was found only
in 1.36% of the words (38% of the segmentation er-
rors).
Since in Hebrew there should be agreement be-
tween the definiteness status of a noun and its related
adjective, this kind of ambiguity can sometimes be
resolved syntactically. For instance:
“bbit hgdwl” implies b-h-bit (“in the big house”)
“bbit gdwl” implies b-bit (“in a big house”)
By contrast, in many other cases both analyses
are syntactically valid, and the choice between them
requires consideration of a wider context, or some
world knowledge. For example, in the sentence
hlknw lmsibh (“we went to a/the party”), lmsibh
can be analyzed either as l-msibh (indefinite,“to a
party”) or as l-h-mbsibh (definite,“to the party”).
Whether we prefer “the party” or “a party” depends
on contextual information that is not available for
the POS tagger.
Lexical statistics can provide valuable informa-
tion in such situations, since some nouns are more
common in their definite form, while other nouns are
more common as indefinite. For example, consider
the word lmmflh (“to a/the government”), which can
be segmented either as l-mmflh or l-h-mmflh. The
</bodyText>
<page confidence="0.996162">
44
</page>
<table confidence="0.99930525">
Tokenization Analysis
W (lmmflh IN-H-NN)
M (IN l) (H h) (NN mmflh)
M+h (IN l) (H-NN hmmflh)
</table>
<tableCaption confidence="0.8450845">
Table 2: Representation of l-h-mmflh in each level
of tokenization
</tableCaption>
<bodyText confidence="0.99775341025641">
stem mmflh (“government”) was found 25 times in
the corpus, out of which only two occurrences were
indefinite. This strong lexical evidence in favor of
l-h-mmflh is completely missed by the morpheme-
level tagger, in which morphemes are assumed to
be independent. The lexical model of the word-
level tagger better models this difference, since it
does take into account the frequencies of l-mmflh
and l-h-mmlh, in measuring P(lmmflh IN-NN) and
P(lmmflh IN-H-NN). However, since the word tag-
ger considers lmmflh, hmmflh (“the government”),
and mmflh (“a government”) as independent words,
it still exploits only part of the potential lexical evi-
dence about definiteness.
In order to better model such situations, we
changed the morpheme-level model as follows. In
definite words the definiteness article h is treated
as a manifestation of a morphological feature of the
stem. Hence the definiteness marker’s POS tag (H)
is prefixed to the POS tag of the stem. We refer by
M+h to the resulting model that uses this assump-
tion, which is rather standard in theoretical linguistic
studies of Hebrew. The M+h model can be viewed as
an intermediate level of tokenization, between mor-
pheme and word tokenization. The different analy-
ses obtained by the three models of tokenization are
demonstrated in Table 2.
As shown in Table 1, the M+h model shows
remarkable improvement in segmentation (0.49%,
p &lt; 0.001) compared with the initial morpheme-
level model (M). As expected, the frequency of seg-
mentation errors that involve covert definiteness (h)
dropped from 1.71% to 1.25%. The adjusted mor-
pheme tagger also outperforms the word level tagger
in segmentation (0.31%, p = 0.069). Tagging was
improved as well (0.3%, p = 0.068). According to
these results, tokenization as in the M+h model is
preferable to both plain-morpheme and plain-word
tokenization.
</bodyText>
<sectionHeader confidence="0.99732" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999967863636364">
Developing a word segmenter and POS tagger for
Hebrew with less than 30K annotated words for
training is a challenging task, especially given the
morphological complexity and high degree of am-
biguity in Hebrew. For comparison, in English a
baseline model that selects the most frequent POS
tag achieves accuracy of around the 90% (Charniak
et al., 1993). However, in Hebrew we found that a
parallel baseline model achieves only 84% using the
available corpus.
The architecture proposed in this paper addresses
the severe sparseness problems that arise in a num-
ber of ways. First, the M+h model, which was
found to perform best, is based on morpheme-
level tokenization, which suffers of data sparse-
ness less than word tokenization, and makes use of
multi-morpheme nonterminals only in specific cases
where it was found to be valuable. The number of
nonterminal types found in the corpus for this model
is 49 (including 11 types of punctuation marks),
which is much closer to the morpheme-level model
(39 types) than to the word-level model (205 types).
Second, the bootstrapping method we present ex-
ploits additional resources such as a morphological
analyzer and an untagged corpus, to improve lexi-
cal probabilities, which suffer from data sparseness
the most. The improved lexical model contributes
1.5% to the tagging accuracy, and 0.6% to the seg-
mentation accuracy (compared with using the basic
lexical model), making it a crucial component of our
system.
Among the few other tools available for POS tag-
ging and morphological disambiguation in Hebrew,
the only one that is freely available for extensive
training and evaluation as performed in this paper
is Segal’s ((Segal, 2000), see section 2.2). Com-
paring our best architecture to the Segal tagger’s re-
sults under the same experimental setting shows an
improvement of 1.5% in segmentation accuracy and
4.5% in tagging accuracy over Segal’s results.
Moving on to Arabic, in a setting comparable to
(Diab et al., 2004), in which the correct segmenta-
tion is given, our tagger achieves accuracy per mor-
pheme of 94.9%. This result is close to the re-
</bodyText>
<page confidence="0.997149">
45
</page>
<bodyText confidence="0.999991217391304">
sult reported by Diab et al., although our result was
achieved using a much smaller annotated corpus.
We therefore believe that future work may benefit
from applying our model, or variations thereof, to
Arabic and other Semitic languages.
One of the main sources for tagging errors in our
model is the coverage of the morphological analyzer.
The analyzer misses the correct analysis of 3.78% of
the test words. Hence, the upper bound for the accu-
racy of the disambiguator is 96.22%. Increasing the
coverage while maintaining the quality of the pro-
posed analyses (avoiding over-generation as much
as possible), is crucial for improving the tagging re-
sults.
It should also be mentioned that a new version of
the Hebrew treebank, now containing approximately
5,000 sentences, was released after the current work
was completed. We believe that the additional an-
notated data will allow to refine our model, both in
terms of accuracy and in terms of coverage, by ex-
panding the tag set with additional morpho-syntactic
features like gender and number, which are prevalent
in Hebrew and other Semitic languages.
</bodyText>
<sectionHeader confidence="0.9982" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999751272727273">
We thank Gilad Ben-Avi, Ido Dagan and Alon Itai
for their insightful remarks on major aspects of this
work. The financial and computational support of
the Knowledge Center for Processing Hebrew is
gratefully acknowledged. The first author would like
to thank the Technion for partially funding his part
of the research. The first and third authors are grate-
ful to the ILLC of the University of Amsterdam for
its hospitality while working on this research. We
also thank Andreas Stolcke for his devoted technical
assistance with SRILM.
</bodyText>
<sectionHeader confidence="0.999452" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999833538461538">
Meni Adler. 2001. Hidden Markov Model for Hebrew
part-of-speech tagging. Master’s thesis, Ben Gurion
University, Israel. In Hebrew.
Leonard Baum. 1972. An inequality and associated max-
imization technique in statistical estimation for proba-
bilistic functions of a Markov process. In Inequalities
III:Proceedings of the Third Symposium on Inequali-
ties, University of California, Los Angeles, pp.1-8.
Eric Brill. 1995. Transformation-based error-driven
learning and natural language processing: A case
study in part-of-speech tagging. Computational Lin-
guistic, 21:784–789.
David Carmel and Yoelle Maarek. 1999. Morphological
disambiguation for Hebrew search systems. In Pro-
ceedings of the 4th international workshop,NGITS-99.
Eugene Charniak, Curtis Hendrickson, Neil Jacobson,
and Mike Perkowitz. 1993. Equations for part-of-
speech tagging. In National Conference on Artificial
Intelligence, pages 784–789.
K. W. Church. 1988. A stochastic parts program and
noun phrase parser for unrestricted text. In Proc. of
the Second Conference on Applied Natural Language
Processing, pages 136–143, Austin, TX.
Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004.
Automatic tagging of Arabic text: From raw text to
base phrase chunks. In HLT-NAACL 2004: Short Pa-
pers, pages 149–152.
S.M. Katz. 1987. Estimation of probabilities from sparse
data from the language model component of a speech
recognizer. IEEE Transactions of Acoustics, Speech
and Signal Processing, 35(3):400–401.
Young-Suk Lee, Kishore Papineni, Salim Roukos, Os-
sama Emam, and Hany Hassan. 2003. Language
model based Arabic word segmentation. In ACL,
pages 399–406.
M. Levinger, U. Ornan, and A. Itai. 1995. Morphological
disambiguation in Hebrew using a priori probabilities.
Computational Linguistics, 21:383–404.
Moshe Levinger. 1992. Morphological disambiguation
in Hebrew. Master’s thesis, Computer Science Depart-
ment, Technion, Haifa, Israel. In Hebrew.
Erel Segal. 2000. Hebrew morphological ana-
lyzer for Hebrew undotted texts. Master’s the-
sis, Computer Science Department, Technion,
Haifa, Israel. http://www.cs.technion.ac.il/-
-erelsgl/bxi/hmntx/teud.html.
K. Sima’an, A. Itai, Y. Winter, A. Altman, and N. Nativ.
2001. Building a tree-bank of Modern Hebrew text.
Traitment Automatique des Langues, 42:347–380.
Andreas Stolcke. 2002. SRILM - an extensible language
modeling toolkit. In ICSLP, pages 901–904, Denver,
Colorado, September.
</reference>
<page confidence="0.999612">
46
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.118158">
<title confidence="0.99021">Choosing an Optimal Architecture for Segmentation and POS-Tagging of Modern Hebrew</title>
<author confidence="0.979786">Roy</author>
<affiliation confidence="0.8709885">Dept. of Computer Bar-Ilan</affiliation>
<address confidence="0.821758">Ramat-Gan 52900,</address>
<email confidence="0.997228">barhair@cs.biu.ac.il</email>
<author confidence="0.744817">Khalil</author>
<affiliation confidence="0.986397">Universiteit van</affiliation>
<address confidence="0.681466">Amsterdam, The</address>
<email confidence="0.966131">simaan@science.uva.nl</email>
<author confidence="0.370046">Yoad</author>
<affiliation confidence="0.993403">Dept. of Computer</affiliation>
<address confidence="0.975508">Haifa 32000,</address>
<email confidence="0.998001">winter@cs.technion.ac.il</email>
<abstract confidence="0.998474235294118">A major architectural decision in designing a disambiguation model for segmentation and Part-of-Speech (POS) tagging in Semitic languages concerns the choice of the input-output terminal symbols over which the probability distributions are defined. In this paper we develop a segmenter and a tagger for Hebrew based on Hidden Markov Models (HMMs). We start out from a morphological analyzer and a very small morphologically annotated corpus. We show that a model whose terminal symbols are word segments (=morphemes), is advantageous over a word-level model for the task of POS tagging. However, for segmentation alone, the morpheme-level model has no significant advantage over the word-level model. Error analysis shows that both models are not adequate for resolving a common type of segmentation ambiguity in Hebrew – whether or not a word in a written text is prefixed by a definiteness marker. Hence, we propose a morphemelevel model where the definiteness morpheme is treated as a possible feature of morpheme terminals. This model exhibits the best overall performance, both in POS tagging and in segmentation. Despite the small size of the annotated corpus available for Hebrew, the results achieved using our best model are on par with recent results on Modern Standard Arabic.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Meni Adler</author>
</authors>
<title>Hidden Markov Model for Hebrew part-of-speech tagging. Master’s thesis,</title>
<date>2001</date>
<institution>Ben Gurion University, Israel. In Hebrew.</institution>
<contexts>
<context position="9239" citStr="Adler, 2001" startWordPosition="1440" endWordPosition="1441">erns (combinations of morphological features) from the unambiguous words in the corpus. Several works aimed at improving the “similar words” method by considering the context of the word. Levinger (1992) adds a short context filter that enforces grammatical constraints and rules out impossible analyses. Segal’s (2000) system includes, in addition to a somewhat different implementation of “similar words”, two additional components: correction rules a` la Brill (1995), and a rudimentary deterministic syntactic parser. Using HMMs for POS tagging and segmenting Hebrew was previously discussed in (Adler, 2001). The HMM in Adler’s work is trained on an untagged corpus, using the Baum-Welch algorithm (Baum, 1972). Adler suggests various methods for performing both tagging and segmentation, most notable are (a) The usage of word-level tags, which uniquely determine the segmentation and the tag of each morpheme, and (b) The usage of a two-dimensional Markov model with morpheme-level tags. Only the first method (word-level tags) was tested, resulting in an accuracy of 82%. In the present paper, both word-level tagging and morpheme-level tagging are evaluated. Moving on to Arabic, Lee et al. (2003) descr</context>
</contexts>
<marker>Adler, 2001</marker>
<rawString>Meni Adler. 2001. Hidden Markov Model for Hebrew part-of-speech tagging. Master’s thesis, Ben Gurion University, Israel. In Hebrew.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Baum</author>
</authors>
<title>An inequality and associated maximization technique in statistical estimation for probabilistic functions of a Markov process.</title>
<date>1972</date>
<booktitle>In Inequalities III:Proceedings of the Third Symposium on Inequalities,</booktitle>
<pages>1--8</pages>
<location>University of California, Los Angeles,</location>
<contexts>
<context position="9342" citStr="Baum, 1972" startWordPosition="1457" endWordPosition="1458">med at improving the “similar words” method by considering the context of the word. Levinger (1992) adds a short context filter that enforces grammatical constraints and rules out impossible analyses. Segal’s (2000) system includes, in addition to a somewhat different implementation of “similar words”, two additional components: correction rules a` la Brill (1995), and a rudimentary deterministic syntactic parser. Using HMMs for POS tagging and segmenting Hebrew was previously discussed in (Adler, 2001). The HMM in Adler’s work is trained on an untagged corpus, using the Baum-Welch algorithm (Baum, 1972). Adler suggests various methods for performing both tagging and segmentation, most notable are (a) The usage of word-level tags, which uniquely determine the segmentation and the tag of each morpheme, and (b) The usage of a two-dimensional Markov model with morpheme-level tags. Only the first method (word-level tags) was tested, resulting in an accuracy of 82%. In the present paper, both word-level tagging and morpheme-level tagging are evaluated. Moving on to Arabic, Lee et al. (2003) describe a word segmentation system for Arabic that uses an ngram language model over morphemes. They start </context>
<context position="17095" citStr="Baum, 1972" startWordPosition="2782" endWordPosition="2783">P (a) , is accomplished by smoothing the joint probability P(w, a) only, i.e., we do not smooth P(a).3 To smooth P(w, a), we use a linear interpolation of the relative frequency estimates from the annotated training corpus (denoted rftr(w, a)) together with estimates obtained by unsupervised estimation from a large unannotated corpus (denoted emauto(w, a)): P(w, a) = A rftr(w, a)+(1−A) emauto(w, a) (6) where A is an interpolation factor, experimentally set to 0.85. Our unsupervised estimation method can be viewed as a single iteration of the Baum-Welch (Forward-Backward) estimation algorithm (Baum, 1972) with minor differences. We apply this method to the untagged corpus of 340K words. Our method starts out from a naively smoothed relative fre3the smoothed probabilities are normalized so that E. P(w, a) = P(a) quency lexical model in our POS tagger: � (1 − p0) rftr(w, a) ftr(w) &gt; 0 PLM0(w|a) = p0 otherwise (7) Where ftr(w) is the occurrence frequency of w in the training corpus, and p0 is a constant set experimentally to 10−10. We denote the tagger that employs a smoothed language model and the lexical model PLMo by the probability distribution Pbasi, (over analyses, i.e., morpheme-tag sequen</context>
</contexts>
<marker>Baum, 1972</marker>
<rawString>Leonard Baum. 1972. An inequality and associated maximization technique in statistical estimation for probabilistic functions of a Markov process. In Inequalities III:Proceedings of the Third Symposium on Inequalities, University of California, Los Angeles, pp.1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistic,</journal>
<pages>21--784</pages>
<contexts>
<context position="9097" citStr="Brill (1995)" startWordPosition="1419" endWordPosition="1420">inger et al. in estimating context independent probabilities from an untagged corpus. Their algorithm learns frequencies of morphological patterns (combinations of morphological features) from the unambiguous words in the corpus. Several works aimed at improving the “similar words” method by considering the context of the word. Levinger (1992) adds a short context filter that enforces grammatical constraints and rules out impossible analyses. Segal’s (2000) system includes, in addition to a somewhat different implementation of “similar words”, two additional components: correction rules a` la Brill (1995), and a rudimentary deterministic syntactic parser. Using HMMs for POS tagging and segmenting Hebrew was previously discussed in (Adler, 2001). The HMM in Adler’s work is trained on an untagged corpus, using the Baum-Welch algorithm (Baum, 1972). Adler suggests various methods for performing both tagging and segmentation, most notable are (a) The usage of word-level tags, which uniquely determine the segmentation and the tag of each morpheme, and (b) The usage of a two-dimensional Markov model with morpheme-level tags. Only the first method (word-level tags) was tested, resulting in an accurac</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Eric Brill. 1995. Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging. Computational Linguistic, 21:784–789.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Carmel</author>
<author>Yoelle Maarek</author>
</authors>
<title>Morphological disambiguation for Hebrew search systems.</title>
<date>1999</date>
<booktitle>In Proceedings of the 4th international workshop,NGITS-99.</booktitle>
<contexts>
<context position="8474" citStr="Carmel and Maarek (1999)" startWordPosition="1328" endWordPosition="1331">for Hebrew words using an unannotated corpus, where each analysis consists of the lemma and a set of morphological features. They estimate the relative frequencies of the possible analyses for a given word w by defining a set of “similar words” 5W (A) for each possible analysis A of w. Each word w&apos; in 5W (A) corresponds to an analysis A&apos; which differs from A in exactly one feature. Since each set is expected to contain different words, it is possible to approximate the frequency of the different analyses using the average frequency of the words in each set, estimated from the untagged corpus. Carmel and Maarek (1999) follow Levinger et al. in estimating context independent probabilities from an untagged corpus. Their algorithm learns frequencies of morphological patterns (combinations of morphological features) from the unambiguous words in the corpus. Several works aimed at improving the “similar words” method by considering the context of the word. Levinger (1992) adds a short context filter that enforces grammatical constraints and rules out impossible analyses. Segal’s (2000) system includes, in addition to a somewhat different implementation of “similar words”, two additional components: correction r</context>
</contexts>
<marker>Carmel, Maarek, 1999</marker>
<rawString>David Carmel and Yoelle Maarek. 1999. Morphological disambiguation for Hebrew search systems. In Proceedings of the 4th international workshop,NGITS-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Curtis Hendrickson</author>
<author>Neil Jacobson</author>
<author>Mike Perkowitz</author>
</authors>
<title>Equations for part-ofspeech tagging.</title>
<date>1993</date>
<booktitle>In National Conference on Artificial Intelligence,</booktitle>
<pages>784--789</pages>
<contexts>
<context position="14865" citStr="Charniak et al., 1993" startWordPosition="2393" endWordPosition="2396">quence of words or a sequence of morphemes, depending on the level of tokenization, and An1 are the respective nonterminals – either POS tags or word-level analyses. Thus, the disambiguator aims at finding the most probable (terminal sequence, nonterminal sequence) for the given sentence, where in the case of word-tokenization there is only one possible terminal sequence for the sentence. 3.3 HMM probabilistic model The actual probabilistic model used in this work for estimating P(en1, An1) is based on Hidden Markov Models (HMMs). HMMs underly many successful POS taggers , e.g. (Church, 1988; Charniak et al., 1993). For a k-th order Markov model (k = 1 or k = 2), we rewrite (4) as: arg max en 1 ,An 1 P(n n e1 , A1 � P(Ai |Ai−k, ... , Ai−1)P(ei |Ai) n arg max en 1 ,An 1 i=1 arg max P(wk 1, m1n, tn1), (2) (5) (mn1 ,tn1 )EANALY SES(wk 1) where ANALY SES(wk1) is the set of possible analyses for the input sentence wk1 (output by the For reasons of data sparseness, actual models we use work with k = 2 for the morpheme level tokenization, and with k = 1 for the word level tokenization. 42 For these models, two kinds of probabilities need to be estimated: P(ei |Ai) (lexical model) and P(Ai |Ai−k, ... , Ai−1) (l</context>
<context position="25888" citStr="Charniak et al., 1993" startWordPosition="4184" endWordPosition="4187">agger also outperforms the word level tagger in segmentation (0.31%, p = 0.069). Tagging was improved as well (0.3%, p = 0.068). According to these results, tokenization as in the M+h model is preferable to both plain-morpheme and plain-word tokenization. 5 Conclusion Developing a word segmenter and POS tagger for Hebrew with less than 30K annotated words for training is a challenging task, especially given the morphological complexity and high degree of ambiguity in Hebrew. For comparison, in English a baseline model that selects the most frequent POS tag achieves accuracy of around the 90% (Charniak et al., 1993). However, in Hebrew we found that a parallel baseline model achieves only 84% using the available corpus. The architecture proposed in this paper addresses the severe sparseness problems that arise in a number of ways. First, the M+h model, which was found to perform best, is based on morphemelevel tokenization, which suffers of data sparseness less than word tokenization, and makes use of multi-morpheme nonterminals only in specific cases where it was found to be valuable. The number of nonterminal types found in the corpus for this model is 49 (including 11 types of punctuation marks), whic</context>
</contexts>
<marker>Charniak, Hendrickson, Jacobson, Perkowitz, 1993</marker>
<rawString>Eugene Charniak, Curtis Hendrickson, Neil Jacobson, and Mike Perkowitz. 1993. Equations for part-ofspeech tagging. In National Conference on Artificial Intelligence, pages 784–789.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
</authors>
<title>A stochastic parts program and noun phrase parser for unrestricted text.</title>
<date>1988</date>
<booktitle>In Proc. of the Second Conference on Applied Natural Language Processing,</booktitle>
<pages>136--143</pages>
<location>Austin, TX.</location>
<contexts>
<context position="14841" citStr="Church, 1988" startWordPosition="2391" endWordPosition="2392">ts either a sequence of words or a sequence of morphemes, depending on the level of tokenization, and An1 are the respective nonterminals – either POS tags or word-level analyses. Thus, the disambiguator aims at finding the most probable (terminal sequence, nonterminal sequence) for the given sentence, where in the case of word-tokenization there is only one possible terminal sequence for the sentence. 3.3 HMM probabilistic model The actual probabilistic model used in this work for estimating P(en1, An1) is based on Hidden Markov Models (HMMs). HMMs underly many successful POS taggers , e.g. (Church, 1988; Charniak et al., 1993). For a k-th order Markov model (k = 1 or k = 2), we rewrite (4) as: arg max en 1 ,An 1 P(n n e1 , A1 � P(Ai |Ai−k, ... , Ai−1)P(ei |Ai) n arg max en 1 ,An 1 i=1 arg max P(wk 1, m1n, tn1), (2) (5) (mn1 ,tn1 )EANALY SES(wk 1) where ANALY SES(wk1) is the set of possible analyses for the input sentence wk1 (output by the For reasons of data sparseness, actual models we use work with k = 2 for the morpheme level tokenization, and with k = 1 for the word level tokenization. 42 For these models, two kinds of probabilities need to be estimated: P(ei |Ai) (lexical model) and P(</context>
</contexts>
<marker>Church, 1988</marker>
<rawString>K. W. Church. 1988. A stochastic parts program and noun phrase parser for unrestricted text. In Proc. of the Second Conference on Applied Natural Language Processing, pages 136–143, Austin, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Kadri Hacioglu</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic tagging of Arabic text: From raw text to base phrase chunks.</title>
<date>2004</date>
<booktitle>In HLT-NAACL 2004: Short Papers,</booktitle>
<pages>149--152</pages>
<contexts>
<context position="10234" citStr="Diab et al. (2004)" startWordPosition="1601" endWordPosition="1604">tags. Only the first method (word-level tags) was tested, resulting in an accuracy of 82%. In the present paper, both word-level tagging and morpheme-level tagging are evaluated. Moving on to Arabic, Lee et al. (2003) describe a word segmentation system for Arabic that uses an ngram language model over morphemes. They start with a seed segmenter, based on a language model and a stem vocabulary derived from a manually segmented corpus. The seed segmenter is improved iteratively by applying a bootstrapping scheme to a large unsegmented corpus. Their system achieves accuracy of 97.1% (per word). Diab et al. (2004) use Support Vector Machines (SVMs) for the tasks of word segmentation and POS tagging (and also Base Phrase Chunking). For segmentation, they report precision of 99.09% and recall of 99.15%, when measuring morphemes that were correctly identified. For tagging, Diab et al. report accuracy of 95.49%, with a tag set of 24 POS tags. Tagging was applied to segmented words, using the “gold” segmentation from the annotated corpus (Mona Diab, p.c.). 3 Architectures for POS tagging Semitic languages Our segmentation and POS tagging system consists of a morphological analyzer that assigns a set of poss</context>
<context position="27508" citStr="Diab et al., 2004" startWordPosition="4447" endWordPosition="4450">on accuracy (compared with using the basic lexical model), making it a crucial component of our system. Among the few other tools available for POS tagging and morphological disambiguation in Hebrew, the only one that is freely available for extensive training and evaluation as performed in this paper is Segal’s ((Segal, 2000), see section 2.2). Comparing our best architecture to the Segal tagger’s results under the same experimental setting shows an improvement of 1.5% in segmentation accuracy and 4.5% in tagging accuracy over Segal’s results. Moving on to Arabic, in a setting comparable to (Diab et al., 2004), in which the correct segmentation is given, our tagger achieves accuracy per morpheme of 94.9%. This result is close to the re45 sult reported by Diab et al., although our result was achieved using a much smaller annotated corpus. We therefore believe that future work may benefit from applying our model, or variations thereof, to Arabic and other Semitic languages. One of the main sources for tagging errors in our model is the coverage of the morphological analyzer. The analyzer misses the correct analysis of 3.78% of the test words. Hence, the upper bound for the accuracy of the disambiguat</context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2004</marker>
<rawString>Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004. Automatic tagging of Arabic text: From raw text to base phrase chunks. In HLT-NAACL 2004: Short Papers, pages 149–152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Katz</author>
</authors>
<title>Estimation of probabilities from sparse data from the language model component of a speech recognizer.</title>
<date>1987</date>
<journal>IEEE Transactions of Acoustics, Speech and Signal Processing,</journal>
<volume>35</volume>
<issue>3</issue>
<contexts>
<context position="15895" citStr="Katz (1987)" startWordPosition="2591" endWordPosition="2592">ation, and with k = 1 for the word level tokenization. 42 For these models, two kinds of probabilities need to be estimated: P(ei |Ai) (lexical model) and P(Ai |Ai−k, ... , Ai−1) (language model). Because the only manually POS tagged corpus that was available to us for training the HMM was relatively small (less than 4% of the Wall Street Journal (WSJ) portion of the Penn treebank), it is inevitable that major effort must be dedicated to alleviating the sparseness problems that arise. For smoothing the nonterminal language model probabilities we employ the standard backoff smoothing method of Katz (1987). Naturally, the relative frequency estimates of the lexical model suffer from more severe datasparseness than the estimates for the language model. On average, 31.3% of the test words do not appear in the training corpus. Our smoothing method for the lexical probabilities is described next. 3.4 Bootstrapping a better lexical model For the sake of exposition, we assume word-level tokenization for the rest of this subsection. The method used for the morpheme-level tagger is very similar. The smoothing of the lexical probability of a word w given an analysis a, i.e., P(w |a) = P(w,a) P (a) , is </context>
</contexts>
<marker>Katz, 1987</marker>
<rawString>S.M. Katz. 1987. Estimation of probabilities from sparse data from the language model component of a speech recognizer. IEEE Transactions of Acoustics, Speech and Signal Processing, 35(3):400–401.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Suk Lee</author>
</authors>
<title>Kishore Papineni, Salim Roukos, Ossama Emam, and Hany Hassan.</title>
<date>2003</date>
<booktitle>In ACL,</booktitle>
<pages>399--406</pages>
<marker>Lee, 2003</marker>
<rawString>Young-Suk Lee, Kishore Papineni, Salim Roukos, Ossama Emam, and Hany Hassan. 2003. Language model based Arabic word segmentation. In ACL, pages 399–406.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Levinger</author>
<author>U Ornan</author>
<author>A Itai</author>
</authors>
<title>Morphological disambiguation in Hebrew using a priori probabilities.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--383</pages>
<contexts>
<context position="7794" citStr="Levinger et al. (1995)" startWordPosition="1208" endWordPosition="1211">a, most previous corpus-based work on Hebrew focus on the 1The Semitic construct state is a special form of a word that participates in compounds. For instance, in the Hebrew compound bdiqt hjenh (“check of the claim”), the word bdiqt (“check of”/“test of”) is the construct form of the absolute form bdiqh (“check”/“test”). 2In this paper we use Latin transliteration for Hebrew letters following (Sima’an et al., 2001). 40 development of techniques for learning probabilities from large unannotated corpora. The candidate analyses for each word were usually obtained from a morphological analyzer. Levinger et al. (1995) propose a method for choosing a most probable analysis for Hebrew words using an unannotated corpus, where each analysis consists of the lemma and a set of morphological features. They estimate the relative frequencies of the possible analyses for a given word w by defining a set of “similar words” 5W (A) for each possible analysis A of w. Each word w&apos; in 5W (A) corresponds to an analysis A&apos; which differs from A in exactly one feature. Since each set is expected to contain different words, it is possible to approximate the frequency of the different analyses using the average frequency of the</context>
</contexts>
<marker>Levinger, Ornan, Itai, 1995</marker>
<rawString>M. Levinger, U. Ornan, and A. Itai. 1995. Morphological disambiguation in Hebrew using a priori probabilities. Computational Linguistics, 21:383–404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moshe Levinger</author>
</authors>
<title>Morphological disambiguation in Hebrew.</title>
<date>1992</date>
<tech>Master’s thesis,</tech>
<institution>Computer Science Department,</institution>
<location>Technion, Haifa, Israel. In Hebrew.</location>
<contexts>
<context position="8830" citStr="Levinger (1992)" startWordPosition="1380" endWordPosition="1381">xactly one feature. Since each set is expected to contain different words, it is possible to approximate the frequency of the different analyses using the average frequency of the words in each set, estimated from the untagged corpus. Carmel and Maarek (1999) follow Levinger et al. in estimating context independent probabilities from an untagged corpus. Their algorithm learns frequencies of morphological patterns (combinations of morphological features) from the unambiguous words in the corpus. Several works aimed at improving the “similar words” method by considering the context of the word. Levinger (1992) adds a short context filter that enforces grammatical constraints and rules out impossible analyses. Segal’s (2000) system includes, in addition to a somewhat different implementation of “similar words”, two additional components: correction rules a` la Brill (1995), and a rudimentary deterministic syntactic parser. Using HMMs for POS tagging and segmenting Hebrew was previously discussed in (Adler, 2001). The HMM in Adler’s work is trained on an untagged corpus, using the Baum-Welch algorithm (Baum, 1972). Adler suggests various methods for performing both tagging and segmentation, most nota</context>
</contexts>
<marker>Levinger, 1992</marker>
<rawString>Moshe Levinger. 1992. Morphological disambiguation in Hebrew. Master’s thesis, Computer Science Department, Technion, Haifa, Israel. In Hebrew.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erel Segal</author>
</authors>
<title>Hebrew morphological analyzer for Hebrew undotted texts.</title>
<date>2000</date>
<tech>Master’s thesis,</tech>
<institution>Computer Science Department, Technion,</institution>
<contexts>
<context position="18391" citStr="Segal, 2000" startWordPosition="2993" endWordPosition="2994">on of alternative analyses (morpheme-tag sequences) for each of the sentences in the untagged corpus; we limit the number of alternative analyses per sentence to 300. This way we transform the untagged corpus into a “corpus” containing weighted analyses (i.e., morphemetag sequences). This corpus is then used to calculate the updated lexical model probabilities using maximum-likelihood estimation. Adding the test sentences to the untagged corpus ensures non-zero probabilities for the test words. 3.5 Implementation4 The set of candidate analyses was obtained from Segal’s morphological analyzer (Segal, 2000). The analyzer’s dictionary contains 17,544 base forms that can be inflected. After this dictionary was extended with the tagged training corpus, it recognizes 96.14% of the words in the test set.5 For each train/test split of the corpus, we only use the training data for enhancing the dictionary. We used SRILM (Stolcke, 2002) for constructing language models, and for disambiguation. 4 Evaluation In this section we report on an empirical comparison between the two levels of tokenization presented in the previous section. Analysis of the results leads to an improved morpheme-level model, which </context>
<context position="27218" citStr="Segal, 2000" startWordPosition="4401" endWordPosition="4402">pping method we present exploits additional resources such as a morphological analyzer and an untagged corpus, to improve lexical probabilities, which suffer from data sparseness the most. The improved lexical model contributes 1.5% to the tagging accuracy, and 0.6% to the segmentation accuracy (compared with using the basic lexical model), making it a crucial component of our system. Among the few other tools available for POS tagging and morphological disambiguation in Hebrew, the only one that is freely available for extensive training and evaluation as performed in this paper is Segal’s ((Segal, 2000), see section 2.2). Comparing our best architecture to the Segal tagger’s results under the same experimental setting shows an improvement of 1.5% in segmentation accuracy and 4.5% in tagging accuracy over Segal’s results. Moving on to Arabic, in a setting comparable to (Diab et al., 2004), in which the correct segmentation is given, our tagger achieves accuracy per morpheme of 94.9%. This result is close to the re45 sult reported by Diab et al., although our result was achieved using a much smaller annotated corpus. We therefore believe that future work may benefit from applying our model, or</context>
</contexts>
<marker>Segal, 2000</marker>
<rawString>Erel Segal. 2000. Hebrew morphological analyzer for Hebrew undotted texts. Master’s thesis, Computer Science Department, Technion,</rawString>
</citation>
<citation valid="false">
<authors>
<author>Israel Haifa</author>
</authors>
<note>http://www.cs.technion.ac.il/--erelsgl/bxi/hmntx/teud.html.</note>
<marker>Haifa, </marker>
<rawString>Haifa, Israel. http://www.cs.technion.ac.il/--erelsgl/bxi/hmntx/teud.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sima’an</author>
<author>A Itai</author>
<author>Y Winter</author>
<author>A Altman</author>
<author>N Nativ</author>
</authors>
<title>Building a tree-bank of Modern Hebrew text. Traitment Automatique des Langues,</title>
<date>2001</date>
<pages>42--347</pages>
<marker>Sima’an, Itai, Winter, Altman, Nativ, 2001</marker>
<rawString>K. Sima’an, A. Itai, Y. Winter, A. Altman, and N. Nativ. 2001. Building a tree-bank of Modern Hebrew text. Traitment Automatique des Langues, 42:347–380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In ICSLP,</booktitle>
<pages>901--904</pages>
<location>Denver, Colorado,</location>
<contexts>
<context position="18719" citStr="Stolcke, 2002" startWordPosition="3048" endWordPosition="3049"> updated lexical model probabilities using maximum-likelihood estimation. Adding the test sentences to the untagged corpus ensures non-zero probabilities for the test words. 3.5 Implementation4 The set of candidate analyses was obtained from Segal’s morphological analyzer (Segal, 2000). The analyzer’s dictionary contains 17,544 base forms that can be inflected. After this dictionary was extended with the tagged training corpus, it recognizes 96.14% of the words in the test set.5 For each train/test split of the corpus, we only use the training data for enhancing the dictionary. We used SRILM (Stolcke, 2002) for constructing language models, and for disambiguation. 4 Evaluation In this section we report on an empirical comparison between the two levels of tokenization presented in the previous section. Analysis of the results leads to an improved morpheme-level model, which outperforms both of the initial models. Each architectural configuration was evaluated in 5-fold cross-validated experiments. In a train/test 4http://www.cs.technion.ac.il/—barhaim/MorphTagger/ 5Unrecognized words are assumed to be proper nouns, and the morphological analyzer proposes possible segmentations for the word, based</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an extensible language modeling toolkit. In ICSLP, pages 901–904, Denver, Colorado, September.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>