<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000987">
<title confidence="0.804563">
DISTINGUISHING USER MODELS FROM DISCOURSE MODELS
</title>
<author confidence="0.999282">
Wolfgang Wahlster
</author>
<affiliation confidence="0.993013">
Department of Computer Science
University of Saarbrticken
</affiliation>
<sectionHeader confidence="0.6963005" genericHeader="abstract">
West Germany
1 INTRODUCTION
</sectionHeader>
<bodyText confidence="0.992928333333333">
In the discussion about the relationship between user
models (UMs) and discourse models (DMs) so far, at
least three positions have been stated explicitly:
</bodyText>
<listItem confidence="0.82001725">
Pl. the DM is a part of the UM (e.g., Schuster)
P2. the DM intersects the UM (e.g., Chin)
P3. the DM and the UM are distinct (e.g., Wahlster
1986, Cohen)
</listItem>
<bodyText confidence="0.968924194805195">
Of course, the interpretation of these positions depends
on the definition of the terms involved and the under-
lying notion of the &amp;quot;part-of&amp;quot;, &amp;quot;intersect&amp;quot;, and &amp;quot;dis-
tinct&amp;quot; relations. The relationships cannot simply be
interpreted in a set-theoretic sense, since all definitions
for UMs and DMs proposed so far depend not only on
representation structures, but also on processes used
for the construction, maintenance, and exploitation of
these structures.
Since this is a terminological, and not an empirical,
discussion, as I pointed out in Wahlster (1986), Pl—P3
are primarily normative statements. So, P3, for in-
stance, must be interpreted as &amp;quot;The terms UM and DM
should be defined in such a way, that they do not
overlap&amp;quot;.
This view seems not to be shared by all participants
in the discussion. Schuster, for example, tries to prove
her position (P1) in a set-theoretic sense. First, she
argues that &amp;quot;the user model contains information that
does not appear in the discourse model&amp;quot; and then she
&amp;quot;proves&amp;quot; that &amp;quot;any information in the discourse model
is also in the user model&amp;quot;.
I disagree not only with the form, but also with the
content of Schuster&apos;s argumentation. She writes &amp;quot;only
if the discourse model is part of the user model can the
system take it into account in its responses and its
reasoning about the users&amp;quot;. By considering an isomor-
phic argumentation like &amp;quot;only if a tomato is part of
cheese, can one use it to prepare pizza&amp;quot; it becomes
clear that this proof is flawed.
Also, Monk points out correctly that if one follows
Schuster&apos;s argumentation one should &amp;quot;view the gram-
mar as part of the user model, because the grammar is
necessary for understanding and producing utter-
ances&amp;quot;.
Today, it is a standard hypothesis in Al and compu-
tational linguistics that models for the language under-
standing and generation process must exploit various
knowledge sources, including in many cases a DM and
a UM. For example, in Jameson and Wahlster (1982) we
described the NP generator of the HAM-ANS system,
in which the generation of a definite or indefinite des-
cription was influenced both by the UM and the DM.
But this in no way means that one must be included in
the other.
As long as there is no definitive evidence (e.g., from
psychology or the neurosciences) for a particular struc-
ture, content, and use (or even existence) of UMs and
DMs in the human information processing system, in Al
the notions of UM and DM are concepts that help on the
one hand to construct a theory of natural language
dialog behavior, and on the other hand to structure the
software systems that realize natural language systems.
From the second point of view, which is the engi-
neering perspective, the question of whether P1, P2, or
P3 holds, is easy to decide so far. In most of the
implemented systems the data structures and proce-
dures labeled UM and DM are completely distinct.
Even the recent GUMS package (Finin 1988), a general
user modeling component, contains no specific repre-
sentation structures or processes for discourse model-
ing.
Since the discussion above suggests that we view the
relation between the UM and the DM mainly as a
terminological problem, in the next section we focus on
possible definitions for UMs and DMs. Although often
terminological discussions become quite tedious, at this
point it seems to be important to define these concepts
as precisely as possible, since many researchers are
discovering interesting relationships between discourse
and user models.
Copyright 1988 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted provided
that the copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page. To
copy otherwise, or to republish, requires a fee and/or specific permission.
0362-613X/ 88 /0100•-•$03.00
Computational Linguistics, Volume 14, Number 3, September 1988 101
Wolfgang Wahlster Distinguishing User Models from Discourse Models
</bodyText>
<sectionHeader confidence="0.924409" genericHeader="method">
2 DEFINING USER MODELS AND DISCOURSE MODELS
</sectionHeader>
<bodyText confidence="0.98996035483871">
Some authors define user models simply as information
that the system has about its users (e.g., Schuster). I
think this definition is too broad. Consider an NL
interface to a data base, which contains the following
relation:
EMP# NAME AGE BONUS
26 Jones 32 40
When Mr. Jones happens to be the user of this system
and asks, &amp;quot;What is my bonus?&amp;quot;, the system should
respond &amp;quot;40&amp;quot;. In this case, the system has information
about the user, but one would not like to say that its
response was based on a user model.
Even if one restricts the definition above to &amp;quot;infor-
mation about the user put to use&amp;quot; (see Sparck Jones), it
is not strong enough. If a deductive data base in addition
to the relation above includes a rule like &amp;quot;If AGE(X) &gt;
30 and BONUS(X) &gt; 35 then STATUS(X) = 10&amp;quot; and
Mr. Jones asks, &amp;quot;What is my status?&amp;quot; the system
should respond &amp;quot;10&amp;quot;. Even though the deductive
DBMS uses information about the user to instantiate the
inference rule, such a system should not be construed as
having a user model.
I propose the following joint definitions of user model
and user modeling component (see Wahlster and Kobsa
1988) as well as discourse model and discourse model-
ing component in the context of NL dialog systems:
A user model is a knowledge source that contains
explicit assumptions on all aspects of the user that may
be relevant for the dialog behavior of the system. A user
modeling component is that part of a dialog system
whose function is to
</bodyText>
<listItem confidence="0.9930276">
• incrementally build up a user model;
• store, update, and delete entries in it;
• maintain the consistency of the model; and
• supply other components of the system with assump-
tions about the user.
</listItem>
<bodyText confidence="0.9988018">
A discourse model is a knowledge source that contains
the system&apos;s description of the syntax, semantics, and
pragmatics of a dialog as it proceeds. A discourse
modeling component is that part of a dialog system
whose function is to
</bodyText>
<listItem confidence="0.9656232">
• incrementally build up a discourse model;
• store and update entries in it; and
• supply other components of the system with informa-
tion about the structure and content of the previous
segments of the dialog.
</listItem>
<bodyText confidence="0.990507083333333">
While it seems commonly agreed upon that a DM
should contain a syntactic and semantic description of
discourse segments, a record of the discourse entities
mentioned, the attentional structure of the dialog in-
cluding a focus space stack, anaphoric links, and de-
scriptions of individual utterances on the speech act
level, there seem to be many other ingredients needed
for a good discourse representation which are not yet
worked out in current computational discourse theory.
Therefore, I prefer to refer only to the abstract levels of
necessary discourse representation in the definition
above.
</bodyText>
<sectionHeader confidence="0.999549" genericHeader="method">
3 SOME DIFFERENCES AND SIMILARITIES BETWEEN USER
MODELS AND DISCOURSE MODELS
</sectionHeader>
<bodyText confidence="0.99923075">
An important difference between a discourse model and
a user model is that entries in the user model often must
be explicitly deleted or updated, whereas in the dis-
course model entries describing the structure and con-
tent of utterances of the ongoing dialog are never
deleted (except for forgetting phenomena, which are
beyond the scope of the current discussion). Thus,
according to our definition above, a belief revision
component is an important part of a user modeling
component.
Consider the following dialog with a hypothetical
tutoring system in the SCHOLAR tradition.
</bodyText>
<equation confidence="0.9177122">
System: (1) Tell me about California.
User: (2) San Francisco is the capital of
California.
System: (3) No, that&apos;s wrong.
User: (4) I see. So, that&apos;s not the capital.
</equation>
<listItem confidence="0.8061916">
(5) Then, what is its capital?
System: (6) Sacramento.
(7) Now, tell me why you mentioned San
Francisco first, when you began to talk
about California.
</listItem>
<bodyText confidence="0.9842056">
A simple consequence of the user&apos;s response (2) is an
entry in the system&apos;s user model, which represents the
fact, that the system believes that the user believes
(B1). After (3), and certainly after (4) the user model
should contain (B1&apos;).
</bodyText>
<equation confidence="0.846389333333333">
(B1) capital(California, San-Francisco)
(B1&apos;) not(capital(California, San-Francisco))
(B2) capital(California, Sacramento)
</equation>
<bodyText confidence="0.999925866666667">
This means that the user modeling component has to
remove (B1) from the user model (in a reason mainte-
nance system this causes (B1) to be added to the set of
beliefs, which are currently &amp;quot;out&amp;quot;). After (6) the user&apos;s
belief (B2) should be added to the system&apos;s user model.
If the apriori user model contains &amp;quot;For each state there
exists one and only one capital&amp;quot; as a mutual believed
fact, then the user modeling component can also re-
move (B1&apos;) after adding (B2).
In the discourse model, of course, the fact that the
user uttered sentence (2) should not be deleted. For
example, the system could go on and ask the user a
question like (7), which explicitly refers to the fact that
(2) was the first reaction to (1). What this simply means
is that the fact that the user made a particular assertion
</bodyText>
<page confidence="0.948191">
102 Computational Linguistics, Volume 14, Number 3, September 1988
</page>
<note confidence="0.378674">
Wolfgang Wahlster Distinguishing User Models from Discourse Models
</note>
<bodyText confidence="0.99517675">
remains true even if the user&apos;s belief changes and he
withdraws his previous assertion.
Even a metacommunicative act like (9) should not
delete entries in the discourse model, as the successful
anaphoric reference in (10) to a discourse entity intro-
duced in (8) suggests. But it is obvious that in the user
model the corresponding representation of the user&apos;s
wants has to be changed.
</bodyText>
<listItem confidence="0.804714666666667">
User:(8) I don&apos;t want to travel with my kids.
(9) Forget what I just said.
(10) I want to travel with them.
</listItem>
<bodyText confidence="0.999955962962963">
This does not imply that the discourse model is static
and the user model is dynamic. The discourse model is
also highly dynamic (consider, e.g., focus shifting), but
it lacks the notion of logical consistency, which is
important for belief revision and default reasoning in a
user modeling component. In my view, the discourse
model is like an annotated trace of the various levels of
the system&apos;s processing involved in understanding the
user&apos;s utterances and generating its own dialog contri-
butions.
Let&apos;s consider another example to emphasize the
differences between a UM and a DM. Suppose that the
system plays the role of a travel agent, who wants to sell
trips to the well-known holiday places A and B, for
which it has some reasonably priced offers. When the
user asks, &amp;quot;What are your cheapest trips?&amp;quot; the system
lists A and B first, followed by a hastily presented list of
eight other places with names, which it assumes are
totally unfamiliar to the user. In the system&apos;s DM all ten
places appear, but the user modeling component of the
system explicitly assumes that the user only believes
&amp;quot;cheap-trip-to(A)&amp;quot;, &amp;quot;cheap-trip-to(B)&amp;quot; together with
the belief that there are some other cheap trips avail-
able. This is exactly the aim of the uncooperative
behavior of the travel agent: Now, it is likely that the
user wants to know more about the offers A and B,
which the agent wants to sell. But if the user later finds
out that a trip to one of the other places is much cheaper
and better, and complains to the travel agent, &amp;quot;Why
didn&apos;t you suggest this trip right at the beginning?&amp;quot;, the
travel agent can refer back to his DM and say, &amp;quot;I
mentioned this place among my first suggestions&amp;quot;.
Some authors claim that the discourse model expires
at the end of a dialog, while parts of the user model may
be saved for further use (e.g., Chin). I think that is
wrong. Often a dialog participant is able to paraphrase a
segment of a previous dialog without remembering who
the dialog partner was and at what time and location the
dialog took place. While he may not be able to recon-
struct the exact phrasing, he has access to a represen-
tation of the semantics and pragmatics of the interac-
tion. Furthermore, I think that often conversational
rules and tactics are learned by induction over a large
set of interaction patterns extracted from discourse
models, which were partially saved in episodic memory,
where they are not necessarily associated with a long-
term user model. In order to learn how to use a language
it seems to be important to not always discard the
complete discourse model after the end of a conversa-
tion.
On the other hand, one often has many assumptions
about the beliefs, plans, and goals of a dialog partner
before a new dialog begins (cf. Wahlster and Kobsa
1988), without having a clear idea from which actual
dialogs the assumptions in this user model were de-
rived. Thus I agree with Monk that the short-term/
long-term criterion cannot be used to distinguish user
models and discourse models. If one prefers to restrict
the term discourse model to an ongoing conversation
and to define the saved portions of it as part of the world
knowledge, then one should do the same for the term
user model, so that again the criterion does not discrim-
Mate.
While in many cases the UM component and the DM
component process the same input (e.g., a meaning
representation of the last utterance), and their output is
used by the same processes, I would suggest that both
components be kept separate. Even if there is some
information, which should be present in both models, it
will be represented in another form, since, as I pointed
out above, the functionality and the type of processing
of the UM and DM components are so different. In this
case we have a multiple knowledge representation in the
UM and the DM, which is quite common in complex Al
systems.
As I remarked in the beginning, in asking who is right
in this discussion, one must carefully evaluate the
corresponding definitions for UM and DM proposed by
the respective authors. In this paper, I introduced and
motivated definitions, under which a UM and a DM are
separate, but related to each other.
</bodyText>
<sectionHeader confidence="0.998675" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.977871214285714">
Finin, T. W. 1988 GUMS: A General User Modeling Shell. In Kobsa,
A. and Wahlster, W. (eds.), User Models in Dialog Systems.
Springer-Verlag, Berlin—New York.
Jameson, A. and Wahlster, W. 1982 User Modeling in Anaphora
Generation: Ellipsis and Definite Description. In Proceedings of
the 1982 European Conference on Artificial Intelligence, Orsay,
France; 222-227.
Wahlster, W. 1986 Some Terminological Remarks on User Modeling.
Paper presented at the International Workshop on User Modeling,
Maria Laach, W. Germany.
Wahlster, W. and Kobsa, A. 1988 User Models in Dialog Systems. In
Kobsa, A. and Wahlster, W. (eds.), User Models in Dialog
Systems. Springer-Verlag, Berlin—New York.
Computational Linguistics, Volume 14, Number 3, September 1988 103
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.743685">
<title confidence="0.998387">DISTINGUISHING USER MODELS FROM DISCOURSE MODELS</title>
<author confidence="0.981202">Wolfgang Wahlster</author>
<affiliation confidence="0.999002">Department of Computer University of</affiliation>
<address confidence="0.759581">West Germany</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T W Finin</author>
</authors>
<title>GUMS: A General User Modeling Shell.</title>
<date>1988</date>
<booktitle>User Models in Dialog Systems.</booktitle>
<editor>In Kobsa, A. and Wahlster, W. (eds.),</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin—New York.</location>
<contexts>
<context position="3373" citStr="Finin 1988" startWordPosition="570" endWordPosition="571">tent, and use (or even existence) of UMs and DMs in the human information processing system, in Al the notions of UM and DM are concepts that help on the one hand to construct a theory of natural language dialog behavior, and on the other hand to structure the software systems that realize natural language systems. From the second point of view, which is the engineering perspective, the question of whether P1, P2, or P3 holds, is easy to decide so far. In most of the implemented systems the data structures and procedures labeled UM and DM are completely distinct. Even the recent GUMS package (Finin 1988), a general user modeling component, contains no specific representation structures or processes for discourse modeling. Since the discussion above suggests that we view the relation between the UM and the DM mainly as a terminological problem, in the next section we focus on possible definitions for UMs and DMs. Although often terminological discussions become quite tedious, at this point it seems to be important to define these concepts as precisely as possible, since many researchers are discovering interesting relationships between discourse and user models. Copyright 1988 by the Associati</context>
</contexts>
<marker>Finin, 1988</marker>
<rawString>Finin, T. W. 1988 GUMS: A General User Modeling Shell. In Kobsa, A. and Wahlster, W. (eds.), User Models in Dialog Systems. Springer-Verlag, Berlin—New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Jameson</author>
<author>W Wahlster</author>
</authors>
<title>User Modeling in Anaphora Generation: Ellipsis and Definite Description.</title>
<date>1982</date>
<booktitle>In Proceedings of the 1982 European Conference on Artificial Intelligence,</booktitle>
<pages>222--227</pages>
<location>Orsay, France;</location>
<contexts>
<context position="2418" citStr="Jameson and Wahlster (1982)" startWordPosition="397" endWordPosition="400">nsidering an isomorphic argumentation like &amp;quot;only if a tomato is part of cheese, can one use it to prepare pizza&amp;quot; it becomes clear that this proof is flawed. Also, Monk points out correctly that if one follows Schuster&apos;s argumentation one should &amp;quot;view the grammar as part of the user model, because the grammar is necessary for understanding and producing utterances&amp;quot;. Today, it is a standard hypothesis in Al and computational linguistics that models for the language understanding and generation process must exploit various knowledge sources, including in many cases a DM and a UM. For example, in Jameson and Wahlster (1982) we described the NP generator of the HAM-ANS system, in which the generation of a definite or indefinite description was influenced both by the UM and the DM. But this in no way means that one must be included in the other. As long as there is no definitive evidence (e.g., from psychology or the neurosciences) for a particular structure, content, and use (or even existence) of UMs and DMs in the human information processing system, in Al the notions of UM and DM are concepts that help on the one hand to construct a theory of natural language dialog behavior, and on the other hand to structure</context>
</contexts>
<marker>Jameson, Wahlster, 1982</marker>
<rawString>Jameson, A. and Wahlster, W. 1982 User Modeling in Anaphora Generation: Ellipsis and Definite Description. In Proceedings of the 1982 European Conference on Artificial Intelligence, Orsay, France; 222-227.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wahlster</author>
</authors>
<title>Some Terminological Remarks on User Modeling.</title>
<date>1986</date>
<booktitle>Paper presented at the International Workshop on User Modeling,</booktitle>
<location>Maria Laach, W.</location>
<contexts>
<context position="1017" citStr="Wahlster (1986)" startWordPosition="157" endWordPosition="158"> the DM and the UM are distinct (e.g., Wahlster 1986, Cohen) Of course, the interpretation of these positions depends on the definition of the terms involved and the underlying notion of the &amp;quot;part-of&amp;quot;, &amp;quot;intersect&amp;quot;, and &amp;quot;distinct&amp;quot; relations. The relationships cannot simply be interpreted in a set-theoretic sense, since all definitions for UMs and DMs proposed so far depend not only on representation structures, but also on processes used for the construction, maintenance, and exploitation of these structures. Since this is a terminological, and not an empirical, discussion, as I pointed out in Wahlster (1986), Pl—P3 are primarily normative statements. So, P3, for instance, must be interpreted as &amp;quot;The terms UM and DM should be defined in such a way, that they do not overlap&amp;quot;. This view seems not to be shared by all participants in the discussion. Schuster, for example, tries to prove her position (P1) in a set-theoretic sense. First, she argues that &amp;quot;the user model contains information that does not appear in the discourse model&amp;quot; and then she &amp;quot;proves&amp;quot; that &amp;quot;any information in the discourse model is also in the user model&amp;quot;. I disagree not only with the form, but also with the content of Schuster&apos;s a</context>
</contexts>
<marker>Wahlster, 1986</marker>
<rawString>Wahlster, W. 1986 Some Terminological Remarks on User Modeling. Paper presented at the International Workshop on User Modeling, Maria Laach, W. Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wahlster</author>
<author>A Kobsa</author>
</authors>
<title>User Models in Dialog Systems.</title>
<date>1988</date>
<booktitle>User Models in Dialog Systems.</booktitle>
<editor>In Kobsa, A. and Wahlster, W. (eds.),</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin—New York.</location>
<contexts>
<context position="5634" citStr="Wahlster and Kobsa 1988" startWordPosition="941" endWordPosition="944">user model. Even if one restricts the definition above to &amp;quot;information about the user put to use&amp;quot; (see Sparck Jones), it is not strong enough. If a deductive data base in addition to the relation above includes a rule like &amp;quot;If AGE(X) &gt; 30 and BONUS(X) &gt; 35 then STATUS(X) = 10&amp;quot; and Mr. Jones asks, &amp;quot;What is my status?&amp;quot; the system should respond &amp;quot;10&amp;quot;. Even though the deductive DBMS uses information about the user to instantiate the inference rule, such a system should not be construed as having a user model. I propose the following joint definitions of user model and user modeling component (see Wahlster and Kobsa 1988) as well as discourse model and discourse modeling component in the context of NL dialog systems: A user model is a knowledge source that contains explicit assumptions on all aspects of the user that may be relevant for the dialog behavior of the system. A user modeling component is that part of a dialog system whose function is to • incrementally build up a user model; • store, update, and delete entries in it; • maintain the consistency of the model; and • supply other components of the system with assumptions about the user. A discourse model is a knowledge source that contains the system&apos;s</context>
<context position="12754" citStr="Wahlster and Kobsa 1988" startWordPosition="2150" endWordPosition="2153"> pragmatics of the interaction. Furthermore, I think that often conversational rules and tactics are learned by induction over a large set of interaction patterns extracted from discourse models, which were partially saved in episodic memory, where they are not necessarily associated with a longterm user model. In order to learn how to use a language it seems to be important to not always discard the complete discourse model after the end of a conversation. On the other hand, one often has many assumptions about the beliefs, plans, and goals of a dialog partner before a new dialog begins (cf. Wahlster and Kobsa 1988), without having a clear idea from which actual dialogs the assumptions in this user model were derived. Thus I agree with Monk that the short-term/ long-term criterion cannot be used to distinguish user models and discourse models. If one prefers to restrict the term discourse model to an ongoing conversation and to define the saved portions of it as part of the world knowledge, then one should do the same for the term user model, so that again the criterion does not discrimMate. While in many cases the UM component and the DM component process the same input (e.g., a meaning representation o</context>
</contexts>
<marker>Wahlster, Kobsa, 1988</marker>
<rawString>Wahlster, W. and Kobsa, A. 1988 User Models in Dialog Systems. In Kobsa, A. and Wahlster, W. (eds.), User Models in Dialog Systems. Springer-Verlag, Berlin—New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Computational Linguistics</author>
</authors>
<date>1988</date>
<volume>14</volume>
<pages>103</pages>
<marker>Linguistics, 1988</marker>
<rawString>Computational Linguistics, Volume 14, Number 3, September 1988 103</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>