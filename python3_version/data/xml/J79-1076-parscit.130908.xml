<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.858163483870968">
kmerican Journal of Computational Linguistics Microfiche 76
THE FINITE STRING
NEWSLE1TER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
VOLUME 15 - NUMBER 3 JUNE 1978
AMERICAN JOURNAL OF COMPUTATIONAL LINGUISTICS is published 437
the Association for Computational Linguistics.
SECRETARY-TREASURER: Donald E. Walker, SRI International&amp;quot;,
Menlo Park, California 94025
EDITOR: David G. Hays, 5048 Lakeshore Road, Ramburg, New
York, 14075
ASSOCIATE EDITOR: George E. Heidorn, IBM Research Center,
P.O. Bbx 218, Yorktown Heights, New York 10598
EDITORIAL ASSISTANT: William Benzon
Copyright 1978
Association for Computational Linguistics
American Journal of Computational Linguistics Microfiche 76: 2
CONTENTS
TINLAP-2: F)ROGRAM AND ABSTRACTS 3
DICTION&apos;ARY SOICIETY or NORTH AMERICA: SPECIAL MEETING 37
NCO&apos;79 PERSONAL COMPUTING FESTIVAL, 38
1979, NATIONAL tromPuTgR CONFERENCE 39
SHORT NOTICE OE &apos;UPCOMING CONFERENCES 40
RECOGNITION MEMORY (REM): SEMIONICS ASSOCIATES . 43
SCREENSPLITTER 54
THE TARGET PRIJECT&apos;S INTERACTIVE COMPUTERIZED MULTILINGUAL
DICtIONARY, John Burge
,62
American Journal of Computational Linguistics Microfiche 76: 3
TINLAP- 2: PROGRAH AND ABSTRACTS
JULY 25 - 27
UNIVERSITY OF ILLINOIS AT URBANA CHAMPAIGN
</note>
<bodyText confidence="0.95516412">
TINLAP-2 will consist of six sequential sessions, each of which
will address questions of current theoretical interest and
questions on long-range research directions. In each session
researchers from artificial intelligence, linguistics, psych-
ology, and philosophy will focus their points of view on a
particular topic (see schedule below).
Proceedings will be dvailable before the meeting. Each author
will give a 10-15 minute presentation (which may include a cri-
tique of other papers, an amplification of points in the w.Lit,-
ten paper, etc.) followed by a 90 minute discussion period
where questions and cnmments from the audience will be welcome.
There will be other interesting evenus durin6 and after the
workshop, including the ACL Annual Meeting, a banquet, several
opportunities for informal discussions, and events associated
with the Linguistic Institute, to be held at the University
of Illinois this summer. The LSA (Linguistic Society of
TINLAP- 2 4
America) meeting will be held at the University of Illinois
immediately aftet TINLAP-2, July 28-30. Information shout
the LSA meeting can be obtained from Proressor Braj Kachru,
Department of Linguistics, University of Illinois.
The program for TINLAP-2 is listed immediately below The frame
number for the abstract is given in parentheses. Bxesentations for
which no abstract was available arp designated with an asterisk.
PROGRAM
</bodyText>
<note confidence="0.6320272">
Reception and Registration at Levis
Faculty Center; Snacks and Cash Bar
LANGUAGE REPRESENTATION AND PSYCHOLOC=Y
Chair: Dedre Gentner, BBN (7)
Pane.Lists:
</note>
<affiliation confidence="0.514588">
David Rumelhart, University of
California, San Diego*
</affiliation>
<author confidence="0.8960965">
Roger Schank, Yale*
Leonard Talmy, Neuropsychiatric
</author>
<affiliation confidence="0.992524">
Institute of Los Angeles, UCLA
</affiliation>
<author confidence="0.692784">
Terry Winograd, Stanford and Xerox PARC
William Woods, BBN*
</author>
<figure confidence="0.658506">
July 24 7:00 pm
9:00 pm
July LD 9:00 am
11-45 am
</figure>
<note confidence="0.66976825">
1:30 pm- LANGUAGE REPRESENTATION AND REFERENCE
4:15 pm Chair: Bpnnie Lynn Webber, BBN (10)
Panelists:
hn Anderson, Yale (11)
</note>
<table confidence="0.272700625">
TINLAP-2 5:00 pm (Representation and Reference)
July 25 7:00 pm Herbert Clark, Stanford (13)
ikndrew Ortony, University of Illinois (14)
3arbara Partee, University of
Massachusetts (15)
:andace Sidner IT (16)
Informal DiArcussion, Cash Bar and Snacks;
Levis Faculty Center
</table>
<note confidence="0.613657333333333">
July 26 9:00 am- DISCOURSE: SPEECH ACTS AND DIALOGUE
11:45 am Chair: Barbara Grosz, SRI International
Panelists:
</note>
<author confidence="0.459119">
Joseph Grimes. Cornell (18)
</author>
<affiliation confidence="0.655953">
Jerry Morgan, University of Illinois (19)
</affiliation>
<address confidence="0.6956548">
David Olson, Tordnto (20)
RaymondPertault, Toronto*
Andee Rubin, BBN (21)
1:30 Pm LANGUAGE AND PERCEPTION
4:15 Pm Chair: David Waltz, University of Illinois (23)
</address>
<email confidence="0.176991">
anelists:
</email>
<affiliation confidence="0.456337">
Ruzena Bajcsy, University of Pennsylvania (24)
</affiliation>
<author confidence="0.532458">
Ray Jackendoff, Brandeis (26)
Stephen Kosslyn, Harvard*
</author>
<affiliation confidence="0.806884666666667">
Zenon Pylyshyn, University of
Western Ohtario (27)
Yorick Wilks, University of Essex (28)
</affiliation>
<note confidence="0.6144889">
,TINLAP-2
July 26 5/00 pm - ACL ANNUAL MEETING
6:00 pm
6.30 pm Banquet (optional)
Speaker JON ALLEN, M.I T
July 27 9.00 am - INFERENCE MECHANISMS&apos;IN NATURAL LANGUAGE
11.45 am Chair. Arairind Joshi, University of
Pennsylvania**
Panelists:
Eugeoe Charniak, Yale (29)
</note>
<author confidence="0.961906">
Allan Collins, Yale (30)
</author>
<affiliation confidence="0.8854695">
Jerrold Kaplan, University of Pennsylvania (31)
Raymond Reiter, University of
</affiliation>
<address confidence="0.595332571428571">
British Columbia (32)
Charles Rieger, University of Maryland (34)
Stuart Shapiro, SUNY Buffalo (35)
Rand Spiro, University of Illinois (36)
1:30 pm - COMPUTATIONAL MODELS AS &apos;A VEHICLE FOR
4:15 pm THEORETICAL LINGUISTICS
Chair. Rona1d Kaplan, Xerox PARC*
</address>
<note confidence="0.273175">
Panelists.
</note>
<author confidence="0.7791235">
Joseph Grimes, Cornell*
Mark Liberman, Bell Laboratories*
Mitch Marcus, MIT*
Tom Wasow, Stanford*
</author>
<note confidence="0.933543">
**No paper to be presented.
ABSTRACTS 7
</note>
<sectionHeader confidence="0.4312075" genericHeader="abstract">
TESTING THE PSYCHOLOGICAL REALITY
OF A REPRESENTATIONAL MODEL
</sectionHeader>
<bodyText confidence="0.877978466666667">
Dedre Gentner
ttolt Beranek and Newman, Inc.
A research program is described in which a particular re-
presentational format for meaning is tested as broadly 0,s po$sible.
In this format, developed by the LNR research group at The Uni-
versity of California at San Diego, verbs are represdnted aL inter-
connected sets of subpredicates. These subpredicates may be
thought of as the almost inevitable inferences that a listener
makes when a verb is used in a sentence. They confer a meaning
structure on the sentence in which the verb is used. To be
psychologically valid, these representations should capture
(at least):
1. Similarity of meaning:
The more similar two verbs seem in meaning to people,
the more their representations should overlap.
</bodyText>
<sectionHeader confidence="0.767403" genericHeader="introduction">
2. Confusability:
</sectionHeader>
<bodyText confidence="0.984317">
The more confusable two verb meanings are for people,
the more their representations overlap.
</bodyText>
<sectionHeader confidence="0.450655" genericHeader="method">
3. Memory for sentences containing the verb:
</sectionHeader>
<bodyText confidence="0.923720818181818">
The sentence structures set up by the verb&apos;s meaning
should in part determine the way in which sentences
are remembered,.
SemanAc integration:
The representations should allow for the integration
of information from different sentences into discourse
structure.
5. Acquisition patterns:
The structural partitions in the representations should
correspond to the structures children acquire when they
are learning the meanings of the verbE
</bodyText>
<page confidence="0.357374">
6. Patterns of extension:
</page>
<bodyText confidence="0.985709294117647">
The representations should be extendable so as to reflect
the ways in which people interpret verb meanings when the
verbs are used outside their normal context.
7. Reaction times:
The time taken to comprehend a sentence using a given
verb should reflect the structural complexity of the
verb meaning.
Experiments concerned with predictions 1 - 5 are described
here. The results are promising for a general approach of repre-
sentation of meaning in terms of interrelated subpredicates, but
do not clearly distinguish between several similar representations.
For example, to test prediction (2), I read people sentences con-
taining verbs with similar meanings, and asked them to recall the
sentences. The degree of overlap in the semantic structures was
a good predictor of the number of confusions between sentences.
In another sentence-memory experiment (prediction (3)) semantically
complex verbs that provided more underlying interconnections
between the nouns in a sentence led to better memory fot the nouns
in the sentence than simple general verbs, or than other cdmplex
verbs that did not provide such extra interconnections. To test
prediction (5), I tested children&apos;s comprehension of a set of pos
session verbs. Both the order of acquisition among the verbs and
the kinds of errors fitted well with an account of the acquisition
of verb meaning in terms of interconnected subpredicates
This research illustrates a breadth-first approach to testing
a representation. In the breadth-first approach, many different
psychological predictions are made. Each different area of pre-
diction requires a sat of process assumptions, and in each case
the process assumptions used are those that seem most plausible
given previous research in the field. If one representational
format can make correct predictions about a number of different
kinds of psychological phenomena, then that representation stands
a greater chance of being generally useful than one which was
tested in only one depth-first way.
</bodyText>
<note confidence="0.941757">
The Relation of Grammar to Cognition
Leonard Talmy
Neuropsychiatric Institute, UCLA
</note>
<bodyText confidence="0.883518442307692">
A sentence (or other portibtof discourse) is +Aran to evoke in
the listener a meaning complex, here called a &amp;quot;cOgnitive representation&amp;quot;
The lexical elements of the sentence seem, by and large, to specify
the content, or substance, of the cognitive representation, while the
grammatical elements specify its structure. Thus, looking systemat-
ically al the actual notions specifiea by grammatical elements can
give us a handle for ascertaining the very makeup of (linguistic-)
cognitive structuring. We accordingly examine a number of grammatically
specified notion, obserVe the systems or categories in which they
pattegp, and speculate on broader cognitive connections.
Some provisional findings have already emerged: Grammatical
specifications for struCture are preponderantly relativistic or
topological, and exclude the fixed or metrically Euclidean. The
systems in which grammatidal notions pattern include:
plexity (uniplex/multiplex) degree of extensionality
state. of boundedness pattern of distribution
state of dividedness axial characteristios
level of synthesis perspectival characteristics
level of exemplarity scenes.breakup characteristics
4rammatical specification of structuring appears, in certain abstract
characteristics, to be isomorphic with the otructuring of visual
percevtion.
Reference:
Talmy, L. Rubber-Sheet Cognition in Language. In: Papers from
the 13th Regional Meeting, Chicago Linguistic Society.
W. Beach, et. al., eds. University of Chicago. 1977.
Description Formation and niscourse Model. Synthesis lb
Bennie Lynn gebber
Bolt Beranek and Newman Inc.
50 Moulton Street
Cambridge, MA 09138
Researchers in linguistics, psychology and artificial intelligence have
recently begun to abandon a.purely linguistic approach to definite anaphora
(definite pronouns and noun phrases. Instead they posit the notion af reference
into a model that a listener/reader is synthesizing from the idiscource: the
referent of a definite anaphor is then not a linguistic object, but rather an
entity in a model. Such a model has been called a &amp;quot;world of discourse&amp;quot;
[levin &amp; Goldman, 1978]; a &amp;quot;universe of discourse&amp;quot; [1yons 1978], andiscoutse
model&amp;quot; [Nash-Webber 1977; Webber 1978] and a &amp;quot;domain of interpretation&amp;quot;
[Stenning 1975], inter alia. Its synthesis is what interests me.
Discourse model synthesis intuitively&apos; seems to result from interactions
between the listener/reader&apos;s expectations and various features of the text.
What these interactions are is not clear. A discussion of how the listener
reader&apos;s changing expectations can atiect discourse model synthesis can be
bound in [Collins, Brown &amp; Larkin, 1977]. What I shall discuss here are some
features of the text that affect what entities appear in a discourse model and
how such entities are described. In the course of presenting these features,
I will argue that having an appropriate description for a discourse entity
is critical to its successful reference later an. I will then argue that
recognizing formal aspects of the text is critical to the formulatioh of
appropriate descriptions. While this is not a sufficient condition for
successful reference, it is certainly a necessary one.
</bodyText>
<sectionHeader confidence="0.940901" genericHeader="method">
References
</sectionHeader>
<affiliation confidence="0.5765015">
Collins, A., Brown, J.S. &amp; Larkin, K. (1977)
Inference in Text Understanding. Technical Report No. 40, Center
for the Study of Reading, University of Illinois and Bolt Beranek
&amp; Newman Inc. December 1977.
</affiliation>
<author confidence="0.920109">
Levin J. &amp; Goodman, N. (1978)
</author>
<affiliation confidence="0.431625">
Process Models of Reference. Unpublished MS., Information Sciences
Institute, Marina Del Rey CA.
Lyons, J. (1977)
Semantics. England: Gambridge University Press, 1977.
</affiliation>
<bodyText confidence="0.93194">
Nash-Webber, F.L. (1977)
Inference in an Approach to Discourse Anaphora. Technical Report No. 77,
Center for the Study of Reading, University of Illinois and Bolt Beranek
&amp; Newman Inc. December 1977.
Stenning, K. (1975)
Understanding English Articles and Quaqtifiers. Unpublishted Doctoral
Dissertation, the Rockefeller University, 1975.
Weeper, E.L. (1978)
A Formal Approach to Discourse Anaphora. Technical Report No. 2761,
Bolt Beranek &amp; Newman Inc., Cambridge MA April 1978.
</bodyText>
<subsectionHeader confidence="0.953384666666667">
Representation of Iftdividuals in S=ulantic Nets
John Anderson
Yale University
</subsectionHeader>
<bodyText confidence="0.985251133333333">
Abstract
Research is reported concerned with how subjects process
multiplegreferring expressions 4 In one experiment, subjects
learn sentences such as:
The smart Russian cursed the salesgirl
The smart Russian rescued the kitten
The tall lawyer adopted the child
Th t tall lawyer Caused the accident
and only later learn that the smart Russian is the same person as
the tall lawyer,. How do subjects integrate the information about
the smart Russian Otth information about the tall lawyer? It is
information subjects have set up two nodes in memory, one for
each definite description. Upon learning of the identity of the
two descriptions, they introduce into memory a proposition indicating
the identity of the two individual nodes. They also start a
</bodyText>
<subsectionHeader confidence="0.506615">
process of copying information from one node to the other node.
</subsectionHeader>
<bodyText confidence="0.90052">
In effect, they choose to abandon one of the nodes.
It is argued that a similar process occurs when subjects
recognize the referent of a definite description—but on a much
shorter time scale. So, suppose a subject hears:
The first president of the United States was a bad husband.
The proposal is that the subject creates a new node to represent
the subject of that sentence, attaches to this node network structure
to encode it is the first president of the United States, uses this
network structure to guide a search of memory for the referent, finds
a node corresponding to George Washington (GW), indicates that the
new node and the GW node are the same, copies fromthe new node to
the GW nOde the bad husband predicate, and abandons the nev node.
Data is presented consistent with this process model for dealing
with the referents of definite descriptions.
lz.
</bodyText>
<page confidence="0.508122">
13
</page>
<sectionHeader confidence="0.68138" genericHeader="method">
Reference Diaries
</sectionHeader>
<subsectionHeader confidence="0.981992666666667">
Herbert H. Clark and Catherine Marshall
Stanford University
Standford CA
</subsectionHeader>
<bodyText confidence="0.9972288125">
Speakers and listeners are forced to keep diaries about what they now
about each other because, to use or interpret a definite reference, they
have to assess the knowledge they &amp;quot;Ahare&amp;quot; with each other about the thing
being referred to. More prediseXy, it can be shown that the speaker and
listener have to assess what is technically called their mutual knowledge
about the referent. This, however, raises a striking paradox. The assess-
ment of mutual knowledge logically requires an infinity of separate tests,
and if each test takes a finite amount of time, then people would take an
infinite length of time to make or interpret any definite reference.
As a solutiun to this problem, we argue, people use the heuristic of search-
ing their diaries for an event that satisfies a condition we call triple
co-presence. With such an event they can satisfy the inffnity of tests
required by mutual knowledge in a single step. We discuss the kinds of
events that satisfy tripble co-presence, -iad we provide experimental evi-
dence that when people cannot find such an event they are open to error
in their int_expretation of definite reference.
</bodyText>
<note confidence="0.538169">
Some pragmatic constraints on the construction
Ind interpretation of definite, descriptions.
</note>
<author confidence="0.432405">
Andrew Ortony
</author>
<affiliation confidence="0.625496">
University of Illinois at Urbana-Champaiyn
</affiliation>
<sectionHeader confidence="0.690208" genericHeader="method">
Abstract
</sectionHeader>
<subsectionHeader confidence="0.380827">
6oth the production and the comprehension of definite descrip-
</subsectionHeader>
<bodyText confidence="0.907424">
tions requires that inferences be made. In many cases the infer-
ences are trivial and of little theareticak importance or in-
terest. However, there is a class of definite descriptions that
have the characteristic that their relation to their. antecedents
depends on pragmatic inferences (contrasted with deductiveiy
</bodyText>
<equation confidence="0.5924685">
loi-
ical inferences). In such cases, the predicate un0Prlying
</equation>
<bodyText confidence="0.991052">
definite descr&apos;iption cannot be taken to be true of the antecedent
as a result of any entailment retations. Rather, the predicate is
taken as beim; proabilistically related. This paper examines
This clas;, of &amp;quot;pragmatic definite descriptions&amp;quot; more closely,
paying particular attention &apos;fo what constrains the set of candi-
date descriptions that can be used to refer to the antecedent,
ne of the results of this eXarftinaion is the postulation of a
theory about the extent to which an indirect speech act v can be
</bodyText>
<figure confidence="0.233707">
4
ind irect.
14
Bound Variables and Other Anaphors 15
Barbara H. Partee
</figure>
<sectionHeader confidence="0.692523" genericHeader="method">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.9561275">
The aim of the paper is to delimit a subset of pronominal anaphora
for which the logicians notion of bound variables gives the best account.
It can be argued that some cases of anaphora must be iewed this way
some cases cannot be. The clearest cases of bound variable emporia. involve
antecedents like every man and no man which are singular in form but do
not refer to individuals. But even with an antecedent like John, an ana-
phoric pronoun must sometimes pkvielded as a bound variable to account for
one of the readings (the so-called &amp;quot;sloppy identity&amp;quot; reeding) of 0):
</bodyText>
<listItem confidence="0.896414">
(1) John was sure he would win+, and so was Bill.
</listItem>
<bodyText confidence="0.955801666666667">
Bouud variable anaphora will be coRtrasted with free &amp;quot;discourse&amp;quot; anaphora;
the differences between them suggest that the former is essentially a
semantic phenomenon, the latter largely pragmatic.
</bodyText>
<subsectionHeader confidence="0.84876625">
The Usle of Focus ag a Tool for
Disambiguation of Definite Noun Phrases
Candy Sidner
MIT Al Lab
</subsectionHeader>
<bodyText confidence="0.997462">
This paper will center on a discussion of the use of focus in
the interpretation of anaphoric noun phrases in discourse. The
need for focus will be discussed, and a description of focus shifting
will be given. Focus provides a means of representing the central
concept of a discourse. The ways in which a definite noun phrase,
specific or generie, can be used are constrained by its relation to
the focus and by the ways in which the focus can be shifted. The
discussion of anaphoric defnps will present a taxonomy of cases,
distinguished by the relation of the defnp to the focus, This taxonomy
inclues several kinds of inference dependent cases. The paper will
concentrate discussing on the process of understanding defnps, and
will present rules governing the ways a defnp can be used so that the
hearer/reader can understand its co-referent. This paper will also
distinguish reference, co-reference and internal reference, and point
out the need for these distinctions in natural language research.
</bodyText>
<page confidence="0.597998">
16
17
</page>
<sectionHeader confidence="0.3429" genericHeader="method">
FOCUSING IN DIALOG
Barbara J. Grosz
SRI International
</sectionHeader>
<subsectionHeader confidence="0.690742">
Menlo Park, CalifoLnia
</subsectionHeader>
<bodyText confidence="0.99970725">
wnen two people talk they focus On only a snail portion of what
each of them knows or believes. Both what gets said and how it gets
interpreted depend on this narrowing of attention to a common
highlighted portion of knowledge. One of the effects of understanding
an utterance is to become focused on certain entities (relationships and
objects) and on particular views of those entities. A speaker provides
a hearer with clues to what to look at and how to look at it -- what to
focus on, how to focus on it, and how wide or narrow that focus should
be. &apos;These clues may be linguistic or they may come from knowledge about
the relationships among entities in the domain (the structure of the
things being talked about) or from the environment in which the dialog
occurs. Linguistic cues may be either explicit, given directly by
certain words, or implicit, deriving from sentential structure or frou
rhetorical relationships between sentences.
This paper examines focusing in dialog, discusses an initial
representation in which focusing is based on domain structure cues, and
examines from this perspective what other information and models are
needed to extend the formalization of focusing to more general dialogs.
The importance of focusing is illustrated by considering its role in the
processes of understanding and generating definite descriptions.
</bodyText>
<sectionHeader confidence="0.506148" genericHeader="method">
TOPIC LEVELS
</sectionHeader>
<bodyText confidence="0.947699">
Joseph E. Grimes
Cornell Universii-
Ithaca, N.Y.
In order to interpret either a dialogue or a monologue; some
referential elements mgst be agreed on by the speaker and the hearer as
a starting point. This is the topic in the sense proposed by Searle and
Gundel. g Even though the topic normally shifts away from its starting
Point in the course of a text, whatever is being treated as topic in a
particular part of the text receives special treatment in determining
the expression to be uSed.,
Two leve3,s of topic, global 4nd local, in English conversation have
ben noted by Grosz. They imply different strategies for establishing
the reference of pronouns. It is useful to consider them in the light
of two other languages, Longuda of Nigeria and Bacairi of Brazil, that
distinguish topic from nontopic by their pronoun systems.
Finally, there is some evidence from both Greek and English that
there may be more than two topic levels operating simultaneously in
nonconversational texts.
</bodyText>
<figure confidence="0.585325166666667">
18
ABSTRACT
Toward a rational model of discourse comprehension
J. L. Morgan
Center for the Study of Reading
and
</figure>
<affiliation confidence="0.5241305">
Department of Linguistics
University of Illinois
</affiliation>
<bodyText confidence="0.998822529411765">
Models of discourse Vr text often treat connected discourse in
a manner anaLogous to the treatment of sentences in traditional and
generative grammar; i.e. as a formai object to be decoded by means
of certain formal operanions. I point out in this paper that even
where this view is not explicitly, proposed, it is often implicit.
Against this common view I argue that the only kind of discourse
model that is likely to succeed is one that is built around two
important hypotheses: first, that the key to discourse comprehension
is the attempt to infer the details of the plan that the speaker/
writer follows in constructing the text; second; that a large portion
of the work of a discourse comprehension model should be derived from
a theory of practical reasoning. I will sketch the outline of a model
(or more accurately, a schema for a large class of possible models)
that incorporates these suggestions, pointing out the role of
practical reasoning processes, and arguing that notoriously confused
notions like &amp;quot;given/new&amp;quot; and &amp;quot;6xpected information&amp;quot; can only be made
sense of in such a model.
</bodyText>
<page confidence="0.545347">
19
</page>
<sectionHeader confidence="0.3390485" genericHeader="method">
SOME SOCIAL AND LOGICAL ASPECTS OF MEANING IN THE LANOROAGE OF
SCHOOL-AGED CHILDREN
</sectionHeader>
<author confidence="0.481089">
David R. Olson
</author>
<affiliation confidence="0.4875085">
Ontario Institute for Studieg in Education
Toronto, Canada
</affiliation>
<bodyText confidence="0.999266315789474">
It is conventional to treat the meaning of an utterahce in a
discourse in terms of two components the ?ropositional component and
the pragmatic or speech act component, the first indicating the meaning
of the sentence, the seconal indicating its intended use,by the speaker.
I shall present some arguments and evidence that thesp two systems are
interdependent. Roughly, it appears that social considerations,
primarily status, determine which aspects of a proposition are
lexicalized in the utterance. Thus, a child with high status relative
to his interlocutor may use a command, &amp;quot;Give me a block&amp;quot;, while if he
has low status relative to his interlocutor he may use a request, &amp;quot;May I
have a block?&amp;quot; If he is an equal, a peer, (and perhaps only then) he
will use an explicit true proposition such as, &amp;quot;You have two more than
me.&amp;quot; Only in this third case is the propositional meaning explicit in
the sentence per se, and only in this case is an affirmative or negative
response dependent strictly upon truth conditions (rather than
compliance, for example).
This conception of the social aspects of meaning will be examined
through an analysis of what is said vs. what is meant in some child-
child and teacher-child conversations,*
</bodyText>
<figure confidence="0.38165">
20
</figure>
<page confidence="0.967942">
■1..*Wwfa■mMIMP.1
</page>
<affiliation confidence="0.604858">
Paper prepared for TheoretiCal Issues in Natural Language Processing
(TINLAP). Urbana, University of Illinois, July 25-27, 1978.
</affiliation>
<figure confidence="0.529808666666667">
WHO AK I TALKING TO AND CAN THEY TALK BACK:
THE EFFECT OF AUDIENCE AND INTERACTION ON DISCOURSE MODELS
Andee Rubin
</figure>
<figureCaption confidence="0.2031875">
Bolt Beranek and Newman Inc.
Cambridge, Mass.
</figureCaption>
<bodyText confidence="0.997224535714286">
Communication among people occurs in a vast variety of settings
from reading a book to participating in a conversation, from listening
to a tape to reading a transcript of a lecture. Most discussions of
discourse, speech acts and dialogue, however, consider a very particular
kind of communicative situation: face-to-face oral conversations between
two participants in which there is a common spatial and temporal
context. Dialogues between a computer system and a person differ from
this model along at least two dimensions: the modality of the
interaction (current computer-person dialogues are written) and the lack
of spatial commonality, indicated by the impossibility of communicating
with gestures and facial expressions. The implications of these
differehces for theories of discourse are poorly understood4, worse yet,
they illusttate only a small subset of the dimensions along which
language experiences may vary. What relevance do the theories we
advance to account for these interchanges have for other communicative
experiences such as listening to a lecture or reading a play?
This paper will focus on two other aspedts of language experience
which have consequences for the dialogue models we build: audience and
the degree of interaction. In both situations described above, the
audience is a single other person (or system) and interaction between
the participants - or even interruption - is immediate. But in a book,
for example, the audience is larae and not well defined and the book s
reader must adopt new strategies to compensate for the fact that
interaction is impossible. In a personal letter, on the other hand, the
audiPnce is a single other person, similar to the conversational
situation. Interaction, however, is impossible or at least attenuated;
the reader can obtain clarifying information, but the time lapse will be
significant.
</bodyText>
<page confidence="0.758307">
21
</page>
<bodyText confidence="0.997709">
will consider in this paper &apos;where various language experiences
lie along these two dimensions and what the implications of these
differences are for mode4 of discourse and dialogue.
</bodyText>
<page confidence="0.653652">
22
</page>
<affiliation confidence="0.72496225">
On the Interdependence of Language and Perception
David L. Waltz
Coordinated Science Laboratory
University of Illinois at Urbana/Champaign
</affiliation>
<bodyText confidence="0.998763105263158">
Without a connection to the real world via perception, a language
system cannot know what it is talking about. Similarly, a perceptual
system must have ways of expressing its outputs via a language (spoken,
written, gestural or Gthet). The relationship between-perception and
Language is explored, with special attention to what implications
results in language research have or our models of vision systems,
and vice-versa. It is suggested that early language learning is an
especially fertile area or this exploration. Within this area, we
argue that perceptual data is conceptualized prior to language acquisition
according to largely innate strategies, that this conceptualization is
in terms of an internal, non-ambiguous &amp;quot;language,&amp;quot; that Language production
from its beginnings to adulthood is a projection oI the internal Language
which selects and highlights the most important portions of internal
concepts, and that schemata produced in the sensory/motor world are
evolved into .chemata to describe abstract worlds. Examples are provided
which stress the importance of &amp;quot;gestalt&amp;quot; (figure-ground) relationships 4,
and vrojecttlon (3-D to 2-1/2 or 2-D , conceptual to linguistic, and
linguistic to conceptual); finally mechanisms for an integrated vision-
language system are proposed, and some preliminary results are described
</bodyText>
<figure confidence="0.839760333333333">
23
24
The Problem of NaMing Shapes:
Vision-Language Interface
by
R. Bajcay*
and
A.K. Joshi*
Computer and information Science Department
Vniversity of Pennsylvania
Philadelphia, PA 1904
1., Introduction
</figure>
<bodyText confidence="0.970341956521739">
In Wit&apos;, panop,wo wt11 poso morv questions than present soluticm. We want to
raise some questions in the context of the representation of shapes of -3-D objects
One way to get a handle on this problem is to investigate whether labels of shapes
and their acquisition reveals any structure of attributes or components of shapes
that might be used for representation purposes. Another aspect of the puzzle of
rcpresentation is the question whether the information is to be stored in analog
or:pf6positional form, and at what level this transformation from analog to pro-
positional form takes place.
In general, shape of a 3-D compact object has two aspects: the surface
aspect, and the volume aspect. The surface aspect includes properties like con-
cavity, convexity, planarity of surfaces, edges, and corners. The volume aspect
distinguishes objects with hoJes from those without (topological properties), and
describes object with respect to their symmetry planes and axes, relative pro-
porLions, etc.
This Tork has been supported &apos;under NSF Grant nqrS76-191465 and &apos;NSF Grant WIICS76
19466.
25
We will discuss some questions pertinent to representation of a shape of a
3-D compact object, without holes, for example: Is the surface aspect more im-
portant than the volume aspect?, Are there any shape primitives? In what form
are shape attributes stored?, etc. We shall extensively draw from psychological
and psycho-linguistic literature, as well as from the recent Al activities in
this area.
</bodyText>
<subsectionHeader confidence="0.507461333333333">
An Argument Combining Linguistic and Visual Evidence
Ray Jackendoff
Brandeis University
</subsectionHeader>
<bodyText confidence="0.841047333333333">
ABSTRACT
The notion from gestalt psychology of a &amp;quot;figure&amp;quot; emerging trom
a &amp;quot;background&amp;quot; will be shown to be crucially involved in g complete
descrIption of the successful communication of so-called
&amp;quot;pragmatic anaphora&amp;quot; - uses of pronouns without iinguistiic
antecedents such as that in (1).
</bodyText>
<equation confidence="0.491285">
(1) I bought that pointing last Saturday.
</equation>
<bodyText confidence="0.9983206">
A survey of types of pragmatic anaphora in English will then be
used to show that the notion of figure&amp;quot; must encompass a much
wider range of perceptual entities than commonly assumed. Finally
the implications for linguistic semantics, philosophy, percept ial
theory, and cognitive theory will be discussed
</bodyText>
<figure confidence="0.80365425">
26
(very tentative abstract) 27
Language and Perception
Zenon Pylyshyn
</figure>
<affiliation confidence="0.39522">
University of Western Ontario
</affiliation>
<bodyText confidence="0.996494461538461">
A language comprehension system without a perceptual component would,
in an important sense, not know what it was talking about even if it could
carry on a sensible dialogue. More significantly, a theory of comprehension
would be seriously deficient if it di3O not relate linguistic representations
to ones which derive from non-linguistic sources. This bridge is necessary
in order to explain how terms refer as well as to explain how language is
acquired. This paper will distuss and support the position that natural
language learning is only possible because of the prior existence of
mentalese --a language-like system of representation for perceptual as well
as more abstract conceptual contents. How this comes into being cannot be
given as an information processing explanation since it requires an account
of the development of the underlying machine architecture--not of its
langu&apos;age processing software (i.e., interpreters).
</bodyText>
<table confidence="0.906963">
- 28
SEMANTIC PRIMITIVES IN LANGUAGE AND VISION
Yorick Wilks
Department of Language and Linguistics
University of Essex
England
</table>
<sectionHeader confidence="0.587347" genericHeader="method">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.993787111111111">
An argumeti.t is presented that, on the basis of the evidence at
present available, there is no reason to believe that the semantic
primitives required by natural language understanding have any
basis or grounding in vision. And, moreover, whatever may
ultimately turn out to be the way we work, there is no reason
to believe that trying to ground one sphere of Al on the other
language primitives on visual ones, would assist research in
either area. A number of systems of primitives are examined
briefly in order to strengthen the above argument.
</bodyText>
<figure confidence="0.50206625">
With a Spoon in my Hand this must be the Eating Frame
Eugene Charniak
Department of Computer Science
Yale University
</figure>
<sectionHeader confidence="0.581197" genericHeader="method">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.9979728">
A language comprehension program using &amp;quot;trames,&amp;quot; &amp;quot;scripts,&amp;quot; etc.
must be able to decide which frames are appropriate to the text. Often
there will be explicit indication (&amp;quot;Fred was playing tennis&amp;quot; suggests
the TENNIS frame) but it is not always so easy. (&amp;quot;The. steering wheel
was hot, but Jack had to be home by 3&amp;quot; suggests DRIVING, but how?)
This paper will examine how a program might go about determining the
appropriate frame in such cases. The basic idea will be taken over
from Minsky (1975) in that it will be assumed that one usually has one
or more context frames, so that one only needs worry if information
comes in which does not fit them. As opposed to Minsky however the
suggestions for new context frames will not come from the old ones, but
rather directly from the conflicting information. A major portion of
the paper then will be concerned with how we will index context frames
(e.g., DRIVING) under the clues which suggest them (e.g., STEERING-
WHEEL).
</bodyText>
<figure confidence="0.7647632">
29
AtIstitact 30
Human Pato be Reasoning
Allan Cottin-s
Bolt Beranek and Newman Inc,
</figure>
<bodyText confidence="0.993094090909091">
The papot autt-Lnes a computationat theoty oti human peaus.ibte /reasoning
con4tAucted 6ton anatysiis oic peope.e&apos;s answem to evettyday que.oU,ons. Lihe
the theoty L exptessed in a. content-.4ndevendent 6ohnia,U.,Nn, tinUke togit, the
the.oity „spec.i.6ie,s how dL66epLeizt inlionmation n nienny a66ectis the cePtt (Linty o6 the.
cone titsions rtit,ami. The. theony co )1.6 ts 06 a ctivail6 IlaUz ed space o 6 di.66eitent
in6eAtnce t ypeh and theiA ceibtainty conch-tins, inc1udbt9 a vaivitty 06 meta-
iin6e)Lenee types ttheite the ine.A.ence. depend,s on the peAson&apos;s knowtecige about ILLs
own knowt.edge. Tile pto to cots 6h.on peopte.&apos;,6 ante; to gum tions cute zlnaZyzed
Wwi o the. di6f,e)t.ent iFtticitence types, The. papa atzo ditcusse)s how menioty
stAuctuteci Ut muttipe.e ways to isuppott the di66eAent in6e/Lenc.e. type&apos;s, and
how the iniotnat.i.ort- iound in memoty de,teAmineis which in6e.P.ence t ype,s cute. PlIggne,d.
</bodyText>
<page confidence="0.804297">
31
</page>
<figure confidence="0.2261665">
Indirect Responses to Loaded Questions
S. Jerrold Kaplan
University of Pennsylvania
ABSTRACT:
</figure>
<bodyText confidence="0.9459892">
Casual useit.of natural lanp:uage (NL) systems are typically inexpert not
only with regard to the technical details of the underlyint, programs, but often
&apos;with regard to the structure and/or content of the domain of discourse.
Consequently, NL systems must he designed to respond appropriately when they
can detect a misconception on the part of the user. Several conventions e&gt;ist
in cooperative conver&apos;,ation that allow a speaker to indirectly encode their
intentions and beliefs about the domain into their utterances, (&amp;quot;loading&amp;quot; the
utterances) and allow (in fact, often require) a cooperative respondent to
address those intentions and beliefs beyond a literal r*sponse. To be effective,
NL computer systems must do the same.
This paper will explore several types of indirect responses to NL questions)
showing that in the Data Basc query domain -unerea computational models exist
that can -determine both when an indirect response is required and what that
response should be. implementation of these ideas will be presented that
demonstrates their immediate practipl valte in N.14. systems. This paper will
take the position that language related inferences (i.e., inferences driven
lirectly from the phrasing of the question) are to a great extent separable from
deeper reasoning and deduction processes, and are sufficient to produce a
wide variety of useful and cooperative behavior.
S.J. Kaplan
</bodyText>
<figure confidence="0.55334875">
32
Ray Reiter
University of British Columbia
ABSTRACT
</figure>
<bodyText confidence="0.9132866">
I propose to discuss a number of principles for structuring knowledge,
principles which arc motivated by the need for efficient deductive inference in
question-anqw-ring systems. The notion of structure that I will define is, in
some sense, orthogonal to but not antithetical to a number of current ideas in
Al regarding the organization of knowledge.
Intensional vs. Extensional Reptesentations of Knowledv
Given a predicate P, we can represent what we know aboutP extensionally,
or intensionally, e.g. as a procedure or a general axiom) or by some combination of
both. Hoc,&apos; should this decision be made? It turns out that if we represent
appropriate predicates extensionally then
</bodyText>
<listItem confidence="0.897337333333333">
(i) No thfinite deductive searches can arise.
(ii) Certain intensional knowledge becomes irrelevant for
deduction and may be discarded.
</listItem>
<bodyText confidence="0.970327416666667">
The Closed World Assumption “Ng0
In domains for: which we have perfect knowledge (e.g. blocks worlds) it
is appropriate to make the CWA. This means, roughly speaking, that to establish
a negative fact, it is suffidlent to fail to prove its positive counterpart. The
CGOL yields a significant decrease in the complexity of deductive reasoning. In
addition, it induces a decomposition of the available knowledge into two components,
one of which is used only for integrity, and the other only for deductive inference.
Horn Duta Bases
It is well known that whenever the knowledge about a domain is
representable by Horn formulae (i.e. formulae of he form Pli.kPk.. dkpl.?Pn4.1 where
Pl&apos;&amp;quot;&amp;quot;Pn+1 are positive) then consequent and/or antecedent reasoning is complete
for that domain. This result is not true for non Horn domains - more ;,.ophisticated
</bodyText>
<page confidence="0.441684">
33
</page>
<bodyText confidence="0.942831857142857">
reasoning, such as case analysis, may be required. Another nice feature of Horn
domains is that the CA does not lead to any inconsistencies. Not all domains car
,representod by Hbrn formulae. For some such domains it is possible to render
then &amp;quot;essentially&amp;quot; Horn by extensionally representing certain appropriately choser
predicates, in which case all of the Virtues (If Horn domains may be salvaged.
Summary
I am proposing the following structuring principles;
</bodyText>
<listItem confidence="0.984102571428571">
1. If possible, make the CWA.
2. If the knowledge base is non Horn, make it &amp;quot;essentially&amp;quot; Horn by
extensionally representing appropriate predibates.
I. Eliminate infinite deduction paths .by extensionally representing certain
suitably chosen predicats.
4. Under 1, 2 and 3, certaliasntensions will no longer be relevant for
deduction. Remove these.
</listItem>
<figure confidence="0.891925333333333">
Inference and Parsing Architecture in GRINO-1,
a Dull-Scale Story Comprehonder
Chuck Riefler
Computer Selonce Department
. University of Maryland
College Park, Na --land 20742
</figure>
<figureCaption confidence="0.9398905">
APSTRACT: The paper kiescriut:s the inference and parsin7 components
of GRIND-I, a full-scale story comprehension project bud on a
Walt Disney rook of the Month Club book, &amp;quot;The Magic Grinder&amp;quot;.
Topics include: (1) the sense network parser and it interaction
with iriference, (2) character porsomaity trait modelinr, via
behavioral tags, (3) two-character relationship modelinry, and (4)
plot representation and plot level,preliction. The main areas of
emphasis will be on the representation of inference, and on the
various types of inference conditioning that stem from the
character models and plot.
</figureCaption>
<figure confidence="0.44284525">
34
Path-Based and Node-Based Inference in Semantic Networks*
Stuart C. Shapiro
Department of Computer Science
</figure>
<affiliation confidence="0.719197">
State University of New York at Buffalo
Amherst, New York 14226
</affiliation>
<sectionHeader confidence="0.638679" genericHeader="method">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999693571428572">
Two styles of performing inference in semantic networks are presented
and compared,. Path-based inference allows an arc or a path or arcs
between-two given nodes to be inferred from the existence of another
specified path between the same two nodes. Path-based inference rules
may be written using a binary relational calculus notation. Node-based
inference allows a structure of nodes to be inferred from the existence
pf an instance of a pattern of node structures. Node-based inference
rules can be constructed in a semantic network using a,variant of a pred-
icate calculus notation. Path-bastd inference is more efficient, while
node-based inference is more general. A method is described of combining
the two styles in a single system in order to take advantage of the
strengths of each. Applications of oath-based inference rules to the
representation of the extensional equivalence of intensional concepts,
and to the explication of inheritance in hierarchies are sketched..
</bodyText>
<page confidence="0.799134">
35
</page>
<affiliation confidence="0.710493666666667">
Preliminary version of a paper to be presented at &amp;quot;Theoretical Issues in
Natural Language Processing,&amp;quot; the 1978 annual meeting of the Association for
Computational Linguistics, Urbana/Champaign, Illinois, Juky 25-27, 1978.
</affiliation>
<note confidence="0.413735">
36
Processing of Interences
Rand Spiro and Joseph Esposito
University of Illinois
</note>
<sectionHeader confidence="0.909787" genericHeader="method">
Abstract
</sectionHeader>
<bodyText confidence="0.999114777777778">
The hypothesis that pragmatic inferences &apos;presented in text are taken for
granted, superficially processed, and not stably or enduringly represented
in memory was investigated. Stories were read which in some conditions. con-
tained information vitiating the implicational force of explicit. inferences.
The vitiating information was presented eithqr before ot after the inferences.
In Experiment I, errors jr memory for the inferences were prevalent in the
&amp;quot;after&amp;quot; but not the &amp;quot;before&amp;quot; condition. Two kinds of errors were made:
saying the inference had not been presented in the story; or, if it was
remembered as having been presented, altering the specific content of the
inference to produce the opposite f what was actually presented. The latter
errors produced coherence with the vitiating information, and subjects were
not able to differeptiate these errors from correct responses. In Experiment,
II, the results of )(periment I were replicated, and a &amp;quot;spontaneous correction&amp;quot;
interpretation was rejected. The results of both experiments combine to sup-
wit the hypothesis of superficial processing and unstable representation of
explicit inferences. The results provile a link betWeen processes vl..curring
at comprehension and recall in the State of Schema model of accommodative
reconstruction.
</bodyText>
<note confidence="0.525272">
American Journal of Computational Linguistics Microfiche 76: 37
</note>
<table confidence="0.885791870967742">
DICTIONARY SOCIETY OF NORTH AnERICA
SPECIAL MEETING
JULY 27, 1978
UNIVERSITY OF ILLINOIS, URBANA
ROOM 407, LEVIS FACULTY CENTER
CONTACT: Dr. Ladislav Zgusta Phone 217 - 333-3563
Department of Linguistics
4o8s Foreign Langkiages Building
University of :11inois, Urbana
61801
KEYNOTE LECTURE: YAKOV MALKIEL, DEPARTMENT OF LINGUISTICS,
UNIVERSITY OF CALIFORNIA, BERKELEY
The Lexicographer as a Mediator Between
Linguistics and Society
Other lectures include:
FREDERIC G. CASSIDY, Computer Mapping of
Lexical Variants for DARE
JOHN J. NITTI, Computers and the Old Spanish
Dictionary
NEIL H. OLSEN, Computational Lexicography at
the University of Hawaii - Methods and
Applications (participation tentative)
GEORGE FARR (NEH), Funding Possibilities fOr
Lexicographic Work (participation ter;ative)
HOUSING: Illini Union $15.00 single
University of Illinois 21.00 double
Green Street Make reservations directly with
Urbana Kul the Union.
American Journal of Computational Linguistics Microfiche 76: 38
NCC &apos;79 PERSONAL COMPUTING FESTIVAL
JUNE 5 - 7, 19Z91 NEW YORK CITY
</table>
<sectionHeader confidence="0.7355658" genericHeader="method">
PRESENT A PAPER
GIVE A IALK
ORGANIZE A PANEL
DELIVER A TUTORIAL
THEME: IS WORTH IT?
</sectionHeader>
<bodyText confidence="0.6194828">
Is WHAT WORTH IT? Any and every aspect of personal computing
is being questioned
WHAT IS IT WOHTH? How is personal computing enriching our
individual lives, the lives of our families,
and improving the quality of life in general?
</bodyText>
<sectionHeader confidence="0.689755" genericHeader="method">
IS IT WORTH WHAT? he money, the time, the effort, the acquiring
</sectionHeader>
<bodyText confidence="0.9852746">
Jf technical expertise, even the criticism.
Potential participants should send a &amp;quot;letter of intent&amp;quot; as soon
as possible, but no later than February 1, 1979 to Jay P. Lucas
The letter should include an abstract and a brief biography
PAPERS presented during the erogram will be published. Potential
authors will be mailed a Festival Author&apos;s Kit with instructions
and materials. Papers must be received by March 15, 1979 in
the specified camera-ready format. Authors will be notified by
May 1, 1979.
PANELS, TUTORIALS AND TALKS: Session leaders should submit a
brief abstract describing either the scope of the proposed ses-
sion or the tentative title of the presentation by February 1,
1979. The prospective organizer should submit a list of pro-
posed participants, their affiliations, and a brief biography of
each.
</bodyText>
<sectionHeader confidence="0.6797055" genericHeader="method">
JOINT PROGRAM CHAIRMEN
FESTIVAL CHAIRMAN
</sectionHeader>
<footnote confidence="0.893998125">
Richard Kuzmack
1435 Layman Street
McLean, VA 22101
Russell Adams
3008 Mosby Street
Alexandria, VA
22305
Jay P. Lucas
</footnote>
<note confidence="0.3461075">
3409 Saylor Place
Alexandria, VA
</note>
<page confidence="0.532579">
22304-
</page>
<figure confidence="0.544773555555556">
703 821-2873(home) 701 548-8261(home) 703 751-3332 (homE)
American Journal of Computatiou al Linguistics fficrosiche 76: 39
1979 NATIONAL COMPUTER CONFERENCE
JUNE 4 - 7, NEW YORK CITY
How TO PARTICIPATE: Write a paper.
Propose a te6hnieal or panel session
Volunteer to be a panelist.
Send ideas for topics.
Suggest special activities.
</figure>
<sectionHeader confidence="0.9308775" genericHeader="method">
SUGGESTED AREAS FOR PARTICIPATION:
MANAGEMENT SCIENCE AND TECHNOLOGY
APPLICATIONS SOCIAL IMPLICATIONS
GUIDELINES:
</sectionHeader>
<bodyText confidence="0.983293">
PAPERS: Should be previously unpublished. Must be in
final form with quality figures and tables. 411 papers
will be refereed. 2500 words to 5000 words. Six copies
of the paper should be submitted along with six copies of
a title page containitag a title, L50 word abstract, 4 to
6 keywerrds, author&apos;s affiliation, telephone number and
mailing address.
TECHNICAL OR PANEL SESSIONS: Proposals should include
a topic description, suggested session chairpersons and
presenters, panelists, and indicttion or importance of
session and anticipated audience.
</bodyText>
<sectionHeader confidence="0.5480245" genericHeader="method">
SEND SUBMISSIONS BY NOVEMBER 1, 1978 TO THE PROGRAM CHAIRMAN.
CONFERENCE CHAIRMAN:
</sectionHeader>
<footnote confidence="0.92429525">
Merlin G. Smith
1.J. Watson Research
P.O. Box 218
Yorktown Heights9
New York 10598
PROGRAM CHAIRMAN
Richard E. Merwin
Box 32222
</footnote>
<table confidence="0.904963132075472">
Washington, DC 20007
American Journal of Computational Linguistics Microfiche 76; 40
SHORT NOTICE OF UPCOMINGCONFERENCES
FOURTH JOINT INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION
November 7 - 10, 1978
Kyoto, Japan
Sponsor: IEEE
Contact: Professor Makato Nagao
Department of Electrical Engineering
Kyoto University
Sakyo, Kyoto 606 JAPAN
ACM &apos;78
December 4 - 6, 1978
Washington, D.0
Contact: Richard Austing
Department of Computer Science
University of Maryland
College Park, MD
COMPUTER ELEMENTS WORKSHOP ON PUTTTING A MATURINr: TECHNOLOGY
TO WORK
December ll - 14, 1978
Mesa, Arizona
Sponsor: IEEE - CS
Contact: S.M. Neville
Bell Labs, Room 2B438
Naperville, IL 60540
CONFERENCES
145th ANNUAL MEETING OF AAAS
January 3 - 8, 1979
Chicago, Illinois
Contact: Dr. Arthur Herschman
1776 Massachusetts Avenue, NW
Washington, DC 20005
Exhtbits Dr. Edward Ruffing
Only: Scherago Associates
1515 Broadway
New York, NY 10036
ANNUAL MEETING OF THE COMPUTER LAW ASSOCIATION
March 4, 1979
Washington, D.C.
Contact: Michael Iuurbuaw
Suite 1100
1776 K St., N.W.
Washington, DC 20006
NFAIS 21st ANNUAL CONFERtNCL
March 6 - 7, 1979
Arlington, VA
Contact: Toni Carbo Bearman
NFAIS
3401 Market St.
Philadelphia, PA 19102
ANNUAL CONFERENCE OF THE CANADIAN LIBRARY ASSOCIATION
June 14 - 20
</table>
<affiliation confidence="0.577952166666667">
Ottawa, Ontario, Canada
Contact: Business Manager
Canadian Library Association
151 Sparks Street, 9th Floor
Ottawa, Ontario KlP 5E3
Canada
</affiliation>
<page confidence="0.514596">
41
</page>
<figure confidence="0.91737615">
CONFERENCES 41;
AMERICAN LIBRARY ASSOCIATION ANNUAL CONFERENCE
June 24 - 30, 1979
Dallas, Texas
Contact: American Library AssocLacion
50 East Huron Street
Chidago, IL 60,611
SIXTH tNTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE
(IJCAI-79)
August 20 24
Tokyo, Japan
Contact f Prof. Bruce Buchanan, Program Chairman
Computer Science Department
Stanford University
Stanford, CA 9,4305
American Journal of Computational Linguistics Microfiche 76: 43
RECOGNI,T-ION IlEllORY
SEMIONICS ASSOCIATES: TECIINICAL NOTE
Rec. ognition Memory (REM)
Associative Memory
</figure>
<figureCaption confidence="0.363581">
Computer memoileS may be di ided into mo
t)pes, one of which has been almost un-
knovo up to now, e\cept amonl,specialibis In
the v.-ell-known pe stored it ern-f4 are accessed
by means of their addicisses the address
being a number that identines the location in
</figureCaption>
<bodyText confidence="0.9934556">
mlnk-h the item is tofed rlus is the type of
mcmor) used in all the Ak omputers,
throughout the histor) er.e-lectronic data pro-
cessing The relati■cl little-knomn t pe has
been discussed and ,dreamed about b) ‘arious
computer scientisVS for some ) ears 11018 , un-
der the decioations Associative Memory and
Content- AddresGable Memory (CAM). With
this t) pe of memory an item may be accessed
simply b) *being named if it is present, those
10■ at1011N A\ hick ha ‘e it recognire it arrd re-
spond In his re, ebt book on the sullecti l&apos;w-
fcssor (a\ton Foster describes the dit Ici ence
bc1s■een these two t)pes of memories by
omp,fr■son
ilk a i1 nation in s filch ‘rica.her
mants to Isnom %cinch student, in th:
an). ha\ e a paTilL :Wu book. If he operates like
omputer v itli triollventIo-rwl mcniory (and
assuming no prior dues that mould eliminate
certain portions of the class from k on,,Idera-
lion) he mould start As ith the first at in the
fist roN.‘ and ask the stvdent in that scat, Do,
)ou have this book&amp;quot; lie would then icpeat
this step for the se, ond se:rt, and so fotth,
through e‘er) seat in the class If he op..rated
like an .:,ssociatitC memor). on thc other hand
he t.ould simpl) SJ ■ to the milo=le Jass ‘&apos;■ill
all the students mho have this book please
raise their hands.&amp;quot; As this illustration sug-
</bodyText>
<equation confidence="0.3268945">
1 CdNiop 1.0%ter, Cntitt.nt Pai-al1L1 Proke.ors
Vn Nost1;nci Rti9htild, 1976
</equation>
<bodyText confidence="0.824508272727273">
ressics the .0,..1‘..1111,1!:es kU RC i1 mot s
col .ins knit1 of tocognition oi mnloiin iton ie-
trieval or language pi o, essing at ion ar
rather striking 111;iy then h ,omputers
(&amp;quot;1th a \\ Lire c\,,Ttions) alma\ s been knit
\vith 1OLJIIOT1 ak.,essed memories&apos; I here are
apparent!) tmo maim reasons ( I mt.( la 01
Itl&apos;a\ 1/1111/01he or tradition, and doubt-
less mote important. I the 1.1e,itei ,c‘sts
oked in building is5o.„1.itic emcillonws
Recognition Memory
</bodyText>
<subsectionHeader confidence="0.594483">
O■er a .1)...116d of ..e\etal ■ eat. 110\\ , v,inotp,
</subsectionHeader>
<bodyText confidence="0.9702889">
l011111111ff lia\C bCell \A It MC di
iSi tek.11111Cal journals pioposinr designs -and ap-
phcations for associative memories 2 and a
fem. e \perimental nUvdels ha c e been ,onsttuLt-
ed, but at such great cost that the) hi, t&apos; re-
nwinvd e\i&apos;vinnvntal is no&amp;quot; si11,-k&apos;
1472, a commercial]) ,i‘,Ithible ‘,1 cm it h
an a,,0,,1sitne ni.. mor) but it is ■ , \p, 11-
e and therefore jrot hick &apos;Ned nor ot.
ltlelA 1.1&apos;01\ n Ng unst this i
</bodyText>
<subsectionHeader confidence="0.780236">
S.inionrcs ,1 A Otill .17\m‘ has CIL \ C10[1,:d
</subsectionHeader>
<bodyText confidence="0.85047125">
pe (it s) „died Re. mtion Mcnio■rs
(R1 M) mluch cmbo,lies sonic lint :mons t pat-
cuts pendun..0 that vn uI .ulti‘c luemories
t,o»onu al to co,t1u,1 \‘ bile la, hurl., sine
ot the d(haritolle■ of nioie Lik,V1
memories RI \I 19,1‘ 111C11 es,lenildi prop-
Cities \Nab the harp) feature that it
can be built at cost,. not -mud] hu :her thLin
those of cornentional Lomputer
omit mast. I o.ler s, price ,omildi-Non, put the
pr sen il a ailahle online!,
memory s\ stem (as ot 147 4) at about 200
</bodyText>
<footnote confidence="0.551428666666667">
2 SS Iau am..1 11 S I i, \`-&apos;..i,i11“, 1&apos;100.‘0,0 \Rh&apos;
ti.k.turt. A Sure&apos;. ACM ( .,1111,t ;■tv Su•■v‘s Vol q &amp;quot;No I,
Match P477
</footnote>
<equation confidence="0.9203045">
44
11111C■ t.`\1)011SIN&apos;t.&apos; t.011SIt&apos;llt1011,11 omptiter
inemori &apos;s
\110ther NN aY Of (lost ring the ‘..tpabiltris of
</equation>
<bodyText confidence="0.9652925">
hs to k.Onipare it w ith R (Random
Nckess Nlemory) and RON1 (Read Only Man-
</bodyText>
<equation confidence="0.9339086">
or) ), R is the 4. OM er111011.11 computer
in e IllOrV d i ced 110 c et !led ;MOM
CSS
bet. ue it 11,1S tlh: OrCrt) that ac-
t. ess al) hdd to yin.) of iN 1.1,ations (en
,liosen iI tandoin) by Loot:act witfi semi-
aL1/4 es. memory t not tuttlier dis,u,seii in this
tedmi1/4ii notc), .1 more limited t,s of Yok. a-
t ecissed memo; y in w Inch only ono
loLation snailable at a ttnite RON1 is limited
</equation>
<bodyText confidence="0.959688111111111">
re,01 rxidom ,i„e memor) whi,11 hds its
intorinsmon fi\ed No that ii Lsin be read from
hut not \\ iitten into ( rhere i lso the PROM
progran»nable R()\1, and rhe 1 PROM
cia.ahle PROM ) R011, R \M„ Ind RI \1 ate
tompaied in Llit.s I o1lo ing table
REM Functions
\ 1h% Lib], ,1,111/4,0,, RI \ L i. t\\(1luu, non,
not o.,,puter
thi m iiiI ion1/4.;ipa1-olit there
the huhlion whioh osier a1h inulthw roe
111 ability to write Int oint won into i&apos;n.ultiple
stotage location,s in one operation NNith
R NM, b■ contrast it N r;ossible to w iite into
lust one location at a time that w Inc}
h iden-
tified h:t the address supplied \‘ith the .\\ rite
I on
1 he rt,olmition function is desLribed abo.e
mil), in its mniplest and most direct lariety
that In which a memor■ loLation reLtninires
that It. Loritents e\actl match the presented
data RFN1 also recognition functions in-
vol\ int.:. quantitative vomparkons. (1) greater
than or equal -to (2) than or equal to The
three ie ties of recognition ate built into the
RIN hat dw are Besides being usable`dire‘lly,
they pro rde the 11,,y,is for v‘itio.us additional
funk.tiions SpectriA)c by -software, such as (I)
not equal to, (2) greater than, (3) less than,
(.-4) „between e., greater than lower limit but
less than upper Wit).
Moreo■er, different In including no
fun,tion, can be perrormed on different por-
tions of RI N1 entries &amp;quot;No function&apos; means
that a Lertain portion &apos;of the REM entry is
ha te1er happens to be there
Is acLepted
rhe u.c of these aim] Lapabilitiev,h perhaps
best understOOd 1llth the help of an t. ample
Let u iiprose that we ha‘e a REM s) stem
1 laded with a file of entries, each en tr■ eon-
&apos;at in of in about an inch\
Fhe cntr■ is formatted, let us say, to consist
of the folloNxing
</bodyText>
<listItem confidence="0.9585251">
(1 ) 1. ast name
(?.) First name and initial (or initial and middle
name, Or .-..)
(3) Street address
(4) City
(5) State-and /ip t_ode
I c1 phorh number
(7) OIL n patron
(8) \initial inc(,,,ne
(g) \ge
</listItem>
<bodyText confidence="0.995387875">
We could then, if desired obtain a list of all
the persons ( 1) II\ log in Arizona. (2) no more
than 35 N ea,rs old. (3) x‘ith annual Likomes of
S20 000 or higher Notice that diff,.rent re_cog-
Mtkili functions (equal to less than or equal
to grc—iter than or equal to) can be periormed
upon different portions of the entr. (includ-
ing no fuii1 tion at all for the irrele,■ant por-
</bodyText>
<table confidence="0.822986625">
MODES OF OPERATION
Write RecognirdMulti Write
1
Rfad
ROM!
RAM +
REM
+ 1 +
</table>
<page confidence="0.692733">
45
</page>
<bodyText confidence="0.9966338">
lions of the entry) Also, since the system is
peifectly flemble as to what it does with the
result of the recognition operation, we may
ask it to read out just a portion of (rather
than th.e whole of) the qualifying entries (e g ,
Just the name and the telephone number) or
we may alternatively specify that some infor-
mation is lb be written into some part of-the
qualifying entries., -by means of the multiwrite
operation Or, one field of the entry might
contain an address to a location in a disk file
where more extehsive information about the
indiviclual i&amp;-stored.
Note that functions such as those just de-
scribed can be performed by ordinary compu-
ters; but they AN ould be required to perform
searching operations in place of recognition,
and a series_of individuall write instructions in
place of multi-vcrite. The time of ope-ration is
considerably loner, and it increases sharply
as the size of the file grows By contrast, a
recognize or multi-write operation can be per-
formed throughout REM about as fast as a
read or write operation, and the time does not
increase with the size of the memory.
Moreover, for elaborate specifications such as
that in the above illustration, the...software can
get quite complex in systems with ordinary
(RAM) memories And more complex software
requires not only more human time for its
creation, hut also more memory space It is t4
course for just such reasons that some Ram
have been willing to build, and othersAMMII
to buy, associatne processors even almgmfry
high prices that have proailed untilf■ia
Masking
A mask may he applied to any of the REM-
functions, even to the ordinary location-
accessed read and lk rite operations The mask
has the function of blocking out certain bits,
so that they are unaffected by the operation
Any pattern of 1 s and O&apos;s can be used as a
mask the bit positions for which the mask
has I participate in the operation while those
for which the mask has 0 are masked out. The
sire of the mask is that of the computer word,
which has been set at one byte (eight bits) in
the first REM systems being made awailable
by SEM1ONICS. As an example, the mask
10000000 would cause all bit positions but
the leftmost to be ignored by whatever it is
used with. With the multi-write operation,
this mask V* ill allow data (0 or 1) to be written
in the leftmost bit position leaving the other
positions unchanged Such an operation might
be used to flag all records which have %.3 t i sfi e(i
a preceding recognition opeiation.
Effective masking of byte-sized units is also
provided for, but without the need for o‘ert
masks Since the Central Processing Unit
(CPU) operates upon only one computer
word at a time. it simply omits consideration
of those which are to be effectively masked
This simple practice is followed in the aboc&apos;e
illustration, in which certain entire fields
(e g Last name&amp;quot;) are ignored in specifying
the recognition criteria. At smaller le‘els,
down to the individual byte, it is just as easy
to usidi such recognition criteria as, for ex-
ample (1) last name beginning with B (all
other letters disregarded), (2) telephone area
code 303, (3) first digit of the zip code greater
than or equal to 7 (4) last name Anderson
(\x here ? indicates wild character--i e , byte to
be ignored)
</bodyText>
<subsectionHeader confidence="0.653914">
Complex Functions
</subsectionHeader>
<bodyText confidence="0.978393727272727">
Systems 141(211 have the capabilities described
above are oalled Content-Addressable Parallel
Processors&amp;quot; ((&apos;APP&apos;s) by roster Such ma-
chines are quite pow eiful By interweaving
recoemition and multi-wi ite operations, with
appropriate use of bit-masking, a CAPP is able
to achine spevdS, flexibility, and programming
ease well beyond the range of exen %cry large
and expensive computers of the con\ entional
kind.
Thus a recognelion operation, as already men-
</bodyText>
<page confidence="0.622036">
46
</page>
<bodyText confidence="0.992372238095238">
tioned, Lan- be followed by a multi wiite op-
eration, ting a IllaSk, to flag all records
ineetimg the paiticular .et of lec otmitron cri-
teria These 1-11igs may now be included in the
enter la for subsequent recognition operations
It is thus easy to include either-or conditions
in the recognition euteria In the aboNe ex-
ample, instead of asking for the records of ail
pLINOILS his nig in krirona, one could specify
Ati/ona, New iMexico, or Colorado The ap-
propriate REM s■ stem subroutine can then
multi-write a flag in all &apos;records with ArLiona,
then try New Mexico and multi-write a flag in
the same position of these responding records,
then hike&apos; Ise for Colorado; after whieh those
records with the flag are the ones satisfying
the dismncti■e criterion
Other complex operations made po.sible by
the abilities of REM include (I) incrementing
the count field of all record meeting specified
recoLmition eritena, (2) bit b bit comranson
of an input pattern with stored patterns, (3)
locating the record lid\ ing the maximum value
for a specified byte position or field (e a the
count field), (4) like (3) for minimum due
(useful, in alphabetic sorting since alphabetic
order corresponds to numeric in standard 131-
11aTy codes for alphabetic characters, (5) Find-
ing best fit in pattern, recognition situations in
111L11 there is not likely to be a perfect match,
by Lombining (1), (2) and (3) (6) printing
out an ordered list (based on alphabetic or nu-
meric order of speeined field) of all records
meeting specified recognition criteria, (7)
mo \ingInformdtion from one field to another
\\ ith,in all records or all reLords. meeting spec-
ified recognition criteria, (8) adding a constant
o (or subtracting from) all records having
pecifred properties, (9) adding two fields (or
ubtracting, one fit)111 the other) within all rec-
•Irds ha\ mg specified properties; (10) Natious
ogiLal operations upon flags, etc.
</bodyText>
<note confidence="0.386664">
The REM Data System
RENY t,&apos;,111 be plicIsaged Ith arious types 01
</note>
<bodyText confidence="0.928531111111111">
equipment besides the CPU for different appli-
cations In the typical system, the CPU is also
connected to some RAM (for programs and
other in trot requirmg tha somewhat
nore e\pen,sive REM) and I.C) various peripher-
al devices, such as a keyboard for input, CRT
a.ndfor printer for output, and external storage
on tape and or disk A typical REM Data Sys-
tem may be diagrammed as follows
</bodyText>
<figure confidence="0.558568166666667">
INPUT
OUTPUT
TERMINAL
MAGNETIC
DISK
STORAGE
CPU
REM
RAM
SES.MtONICS ©Printed in USA
Cd:ollorn 1-1277 PIM
T innul Rudd
H,Iseley, CA 94705
`)/100
47
&apos;TECHNICAL NOTE
Applications and Markets for REM
Recognition Memory (REM)
</figure>
<figureCaption confidence="0.500427111111111">
In ilen,ral, RIA1,is useful wheiL\ cr seaiLliing
is required \NItil ZrclinarN computers and
here\ er ordinary Lompuler m)ftv■ are sr,tems
are heinu ii,ed for inLhe&apos;xinit or other means of
keeping traLk of where data is stored Its ad-
antages he mainly in grLatl) incrcasd speed
of prOLeSSMC. and in simplification of soft-
ware. In addition, the multi-wine capabilit■
and the opera-tions it makes a\adable. sin_h as
</figureCaption>
<bodyText confidence="0.9728838">
parallel arithmetic, open up new is! as in
(...01npUlt:r appl1CatiOnS hich pi on drn niers
and system desiaiers wirbe exploring for
mari ■ ears to come
Since REM can &apos;do e\er\ thing that oidinary
RAM can do in addition to parallel proLess-
,iinLe its Lost is only moderat,e1N high-
er thin that of RAM it,ina) beLome as V. ice-
1 used as R M during, the next ro to 15
ears Fins prospeLt seems espechill likel%in
icy, of the fact that hard w ate s.o.sts are Lon-,
tinume tq tIoLline while the Lo&apos;st of soft are,
hleh requires pikvranunt.&apos;rs Lontinues 10 in-
crease&apos; Thus the supruivail grcatei ONt of
REM s:\
s.ems Lan be &apos;repaid num, times o‘er
in sa\ings of progiarnming L ost.s The poten-
tial market_for REM is thus no less than \&amp;quot;..!St
and it appears possible that RI_M will it:\ olu-
tionize the computer industry
ro one tan foresee all the 14 tt 1de, elopments
F bring after prourdinniers and
urn-
puter scientists get a dunce to work with it
But so eral areas are immedialift appai-ent in
which a REM system has dear advant:a2es
mer ordinary computers Sonic of the areas
are oullined-belLm , and %.0.pi1icb_11.aied compu-
ter people wirl ha\ e. no diffi.,~1.11-t.&apos; filling in the
outline \\A-11 fin the pp-sil-nlities
</bodyText>
<sectionHeader confidence="0.570905" genericHeader="method">
1. Pattern Recognition
</sectionHeader>
<bodyText confidence="0.549441666666667">
The basic pro.t.ss In pattern reco‘&amp;quot;nti-on is
inatt..hin,2 Junta] represeillatictm.s-of inpCit pat-
terns against stored representations. VEM al-
lows such comparison to be done \Nun the
\thole colleLtion of stored r,Trisentation.k,y),
one operation Other useful cepabilnies rrt-
REM Inch are helpful in pattern ieLognition
are &apos;finding. best fit amoni.: imperfect matches,
masking out irrele\ ant or relatilely unimport-
ant bits, taking account of context restric-
tions, and multiple ItAci reco,mition (in v, Inch
first-10 el pi o\ isional percepts tire as !d on
</bodyText>
<figure confidence="0.640832416666667">
to se..ond l l of reLOgr,tion, etc
Some -,peafic&apos;area
CiptLal Lliaracter-re,,):„Inition (ptinted
text 1 eodcrs)
Speech recognition (\oie ini,ut to
Lomp,..tters)
• Finerplint identifiLation*
\\&apos;,2.A11,4 rd?ie rn anal &gt; sis
Bubble anal■sis
PiL turd ana! sis
R,iclar an il■
1011 Srilef&apos;; f .4inal,.161■77 -Sin Jose&apos;, ‘.0
</figure>
<footnote confidence="0.8657394">
c■slf.Int in its test is relaihel) slew, 1.1,1)4 16
hours to compare one rsa -Feces prrut:; ith ito*Luice
base of 17,000 t.rinqral prints But when th:
is cthnplote, it \N IB S:an the entire file in k% eral
imnutes
</footnote>
<note confidence="0.687653">
48
</note>
<sectionHeader confidence="0.929481" genericHeader="method">
2. information Retrif.n,a1
</sectionHeader>
<bodyText confidence="0.950765">
In it-pian diffLient furii ifiafl lion re-
11 J.\ al ma; acLount fol mote than hall of all
Loirputer usage today I he lieaut) ot RI M
for gaining at.cess to infoimdtion is that it
dlIOV■S the user simply to rime what he
\\
in the reLord v Iii,h satisfies the
ie“)Iiires, in effeLt, that it has h,:en a\ked
lot ii rt olditurv coriputer, c,,it get
ii ii d i rec I aL.,.ess to informatioit onl■
111Cdlls of the address of the loLati,in \\liete it
1.1 ‘,tored When the!, hi \ e to /phi ,,,iiriLthing
they must either s:.areli 1htoti1411 Inuit tpie lo-
Lations setrall OF use a softv, are de\ iLe like
hash coding fl sli :oding is quite limited m
its usefuln,:ss, liel,ause it
laLks It \k ul Is on1N if
seart.11 Isk.&apos;„ \kind) ;Nis &amp;quot;sl!tcl&amp;quot; into :in ad-
dregs or appt ON, mine address i iIkays used
For e\ample. in a lesenation I eifl for a
particular Lruis: line, i,cess to teLord re-
UlTiCS ( I) passenger s na,ne, and ( T.) trip nUrn-
her If all 111(11111 Mg passe1ii2.er doei,n&apos;t
her his trip number he is out of luck both
items of data are used for the hashing.
In general. \\ here\ er ,.1,t.LeNS to ieLords might
be kk anted in dIfiCrent search keys at differ-
ent times (c author or title of author-and-
title in d hi1&apos;li&apos;!1 pJ1ft in f,wn,ctron s stem ).
</bodyText>
<figure confidence="0.743015333333333">
the oid,n,tr, s, stern n cHIT21/4,
WI-
1ieni 111■12% for ca,..11 t\ pL„ of ‘,„frcn ke■, .cid
di,tate. the ,.hoice of ,1 lO■A-,05t
-JO I 11n is for
Lrt 111,‹ li 1,i fil:s Lon be
L ;loin I nal slot C one &apos;midi at
IiinL into i&lt;1 \I foi !Lint:\ I paiposes A
jie ide on the other &apos;land, should
t■ pro\ 1,1td \kith U I1 .V1 11111c.A. LOn-
t Ening ill t Chit infoir-,ation from eaeh
ice,m1 ib11,i likels to bc. neLded lot rettieN al
rairo,es Su,li IIILICN sInL,&apos; it in RI M
automati,all■
1 lie folloi,\ of , in ireas is only
nalesti‘e
Automatic telephone direct of ies
( I c Ini director
( CnIti nse 1,2, large
itt 11 01 N\ steins
I iiirar LateloLls
FT eight ‘N11111111.111 1110111101 Ing
In entor cot-it ol &apos;,tents
CLI`-.1 0 ner FlicS
Per,onn el files
Institanc, holder Ilk_
BiiiIaLcount and ,redit card information
Nik.‘di,a1 data systems
Computet a•sistecl 1 gal
3. Linguictic Automation
</figure>
<figureCaption confidence="0.591632428571429">
onl■ thosc. for \,111011 it _an bk. is 11&apos;,11 utah 1 1.)\k ard such coils
used to 1 CirleN e iii h n ni won \ 1 Ll1ctgc utilcrstjnU (MI; tind trans-
kontraNt, &amp;quot;rntilt,-tiune&apos;asi,ial I oi
evmiple, 1sop,./le ,hithor-(itie it &amp;quot;log be ! t 1 ( 111 I )t.&apos; C 11 1, 0 11 t\erit,■.;cirS
a,Lessed 1).■ erthei authid 1111(... 01 1 ■LIth or 1 &amp;quot;,Itt.&apos;d t.,0 fat ftir t\ko
b■ pair of the &apos;,line ot I tf, tttfl ) ut Ink J.. , ( I) III:,3,(inate rn()Llel-, of ling-
fluis if a user doesn kno\i, ■\ Libel the spell- uistic stiu,tute (2) limitatit,ns of ordinar■
</figureCaption>
<reference confidence="0.782134583333333">
ing is MI R of \II I R he in ask for
\It R
RI NI ,J11 be used in 0; ILL: Jiff lent
\ka■s for info&apos; illation stol,iLie and rum: Nat
depending on OW si.ie -of the tile, A sinalJ
s,ale file Lan he stored entnel■ in RI M, but
coin-p,it; \■111C11
it les Co-&apos;,,ideiable pi ogies has no\k liven
: 1 &apos;tie on th, ol thi iolileins and
ide1/4. 1) 1ii LU I to th; se mid
Hie IIUP 4,111 Of tio2 it L 0111t1011 L Jpohlit y.
\\ Ilk 11 IS 1`,1SIL to larguage pio,;,!L,,,ing at all
</reference>
<page confidence="0.770655">
49
</page>
<bodyText confidence="0.952042020833333">
leNels (phonology, iporphology 1,t ax
riantit.$), is p,.rhaps be,t iPastroted the
dit.tionar look-up problem In fact it i not a
plo141..m at all f,.)1. RI &amp;quot;&apos;A One 1L only 10
name the \\ ord one .1/4\ ent,., lo to its
dieti,nar\ entrs. No lo.)k-..,T), in the of
ear ehing, k required. The diffA. 1..nce b,1\\,.en
the RI and the ordinais eon
ti ct.tr,,ponds to that :en
the lr.,man \Nilo n.,\\ of the
\ (wall:Aar} of _a i.mguge z-„nd i p-ei(Jil \kik)
ov,ii internal \ o.abulars infotin..etion
and must loot, up e, er■ 1/41/4...)rd di„tiun-
ary (a tedious process that v, ill be let ailed
\\ ithout much pleasure all .1/4\ ho ha\ e
qudk.d lot eign langualles) LooL i ni up \ °rt.&apos;s
in a ch_tionar&gt; requires sear.J.i.ulk.I. -hilt to the
a old. it is ,l&gt; recog-
nized. and the rc..,o &apos;ni(on I. to
the semantic and gr...inniatieal i rmation
needed to pro-cess the \Nord
REM N 1;1-,,n‘Ne ideal for 10;i:ill...tie ;tile tv
general ,\s a simple illustr.ation consider a
ntaetie rule \\ hich S..L■S ilidt a detk.rminer
(e the • a&apos; &apos;am&amp;quot;) follo\\ ed Fs a noun lc i3
noun phrase
De No
Suppos.e that thi, rule i&lt;,,,,toted ip RI N1 along
(Atha rule, and at.11&apos;,.11k 0.1.11.11
ar.,o,ig other 11-.1;14iliat (&apos;..e 1, d (le-
t, ( De ) an,t1 .`Co ;1(11&apos;,;) (No) Then
i1i dg Ill 11/4c r lied •
Hi a ,iniple tv.o Rta,..,,e re, i„.1.11(in
After the reLognition of the fo1/4ohis &apos;the&apos;
dog .he sequenLe of ■N .(10,2‘• Dt No
pro\ Rled bs their dli_tionars
Pizod 11\ the left-hand lion of- the rile.-
fioin 1/41/4 Ilia the klentifieetion NP ,,in &apos;)e read
Out Or onto 11„: nest le \ el of ntaetic
rc&apos; )flit Ion
lift&apos;,Tidi.,111(in%, for 1.,;&apos;,:,11•,.), ,.,47(N•&apos;,„.:1K)11 arc)
man) ankl Named. and v, innol 1 pe to fi e-
sec all the possibilities at pi esent One has
unls to Lon,sidt.
r 1 p...n..i\e the 1.1e of
1,4ni.7,1,t0e is in human life to ,,,e1 r Lint of the
e of potential appli,Atons ,,nti prod-
u1/4.ts tildr \ill umerge
</bodyText>
<reference confidence="0.657867144927536">
r„,1,11,ne,, plo,Itk1/4.1 \\.,tli more and hiore
soplii,tie, led line
1..■:‘,1vMic atil(),nailan ,iS an area (.,.0% CTs the
t\kr) L,...ten.r.i! pi o. e,ses of lansp„i 1(2.: untle:ct and-
Inc- and Toth...Lon. Most lanzli.c-
tP,inlz dc&amp;quot;\ ices Vs ill 11,3\ e „ap_dbilit,es in both
,f,eas to \ For 3
tran-1.iting 1.1,ine riust hae
capability in the •Jur,e and produc-
tion capabilit in the target 1,1:-..-uage The
follov,ing list of po,-1.1)1e de icc Incorporating
one or both of ti.ese merels
Tramlot Vi; .res
Cr . cc
he ! let Fr. s edia
ne ()relator
V0iee-(1,-.„.za1ed IThirs TI L r1iuin 1s
File Vole Crratd rev, er
\alutpe&apos; tur R&apos;eac..-ig to the Mind
R riters
1-\I I ditors
Co.-Tilers fo4 (_rdin rs I g1h a, a pro-
4 S.rnple Prc.;,srssing
his, ledd r lio,n ii nstit. &apos;\uto,n,ition
in t)..it the ri)-1 nt ,. 1/4 „ns aHi I&apos;
to Lin.1,1,.JaJ thft le\ ts itoperaie,, (Ton
,tlier the i 1.. .2,st 1.10
, .1, ;,..,,1/41/4111,,,i1 an.■
1.v■ ■)1 11, ,11 tr. ((a.: of&apos;1/41/4i .1 I :lig-
ri.s! the le\ t, al&amp;quot;; vIritt....n in I \ naples 0,f
,1 N.,2 v.1°,1,_11
p- \\ t, 1;1:
)7(.11&apos;0 e \I&apos; lists)
for ;no&apos; e
itt.‘ris t:ian Just v. olds also core
50
under this 1Ljc1Ing, vimples of more com-
ple\ wieries mi.-111,10 1,011)1 jij1 jin of‘\ ordc
CO-Ot. 4111e1ILCS Or IA ONTS Ith LI t it It&apos;d
liflUlU number or intent:lung \\ or Aarae-
ters, anJ parts of ords (i e d1ll11dr diame-
ter sequt.iik.-es). and they might also in hide
Boolean operators Such 1&apos;.1- hug also
Lonics under the licadine of In Re-
trie\ v, ludi is farthL r lrealLd obo\ e.
5. Sciernific Research
RI \1 i CI} cffe,ti e inany t pe of research
that in\ 01\ es lool.ine for %. miLLitions in large
quantities of data Some fields in \\ inch this
1.\ pe of Ill\ e‘,i1,&apos;,111011 S an important part
\\ ith some illustrations to cu,2gest the kind of
inquu;s to v, Inch REM isNl ell suited. are
inguistics
Corrlations of ill\ en phonologh_al
oper,,ties with i2eomphic areas
Col relations among different features
of s\ ntactic structure
Anthropolop SoLiolocy. Demograph
Do societies or communities \\Inch
ha\ e properties A, B, &amp; C also hie
property D or
IL me, IL hi
Correlations arnon:z specified oil ..&apos;c
tiof•,‘ mplomns meilKal histories
pes of Ii. iuiitent II 0111&amp;quot;&apos;&amp;quot;R_ntd1
fa,i Ors et
.0llo11116.
PI &amp;quot;ILS
tc
</reference>
<sectionHeader confidence="0.738149" genericHeader="method">
6 Computer Science
</sectionHeader>
<bodyText confidence="0.9398058125">
lo the oipuIr 5..1t.1111si, 110 Is ill\ oh ed in
de \ dopuIg nev, .,imputer ipphk at tons, pro-
l&apos;ramnung lanyu -.12s, and a1,2,-1111,1n)C, 1:1_11 of-
fers potentials that from 111c c 1 Npt. of
the r1,2,.ent CIII ordy hc dimi.■ un igined
Among the possibilities, that can be \
at, pt c&apos; lit, - besides those .tipplis.ation
drcds ti cited abo\ e, RI,N1 ,i1 fordsft,pin IL resting
Opportunities for \\ Owl.: -por&apos;fiLu-
larl■ for sti,h li&apos;lM1&amp;quot;.!0‘. as coRoi
and NP1. \\ Inch are probabl bet tLi sidled to
RI N1 stcms than flies- .&apos;re to ordinal \orn-
puters Further that can only
dinil.\ be fort ,,L en, are 1it,e1,■, to cnit.i:le \\ hen
i.olnputer ictists 1-H\ e-a J ant_e to ,2\plore
the &apos;mph...mons Of,41,11
arithmetic. parallel mo\ orient of data and
par)illel operations upon programs themseh es
r(ral,her than jut upon data)
7. Simulation and Modelling
Finz... Luca O\ crlaps \kith the preLeding and
v,ith 1. instils-tic kutomation, but is distinct
enough i to \\ arrant its cmn headine. here. The
two disiplmnes inosi in\ 01\ ed are
ArtifiLial Intelligecue and Cogniti\
\ 11 Clic of its t. ss.ntial rec-
oinituni N1 s.; steiTi is more like the
a ii hi al]] 11 p 1/4.(1&amp;quot;,11&apos;,It,I• are It
ii1._lernIt I.11e1 `-:11,..t1 to \ all
:si1l-111,ms IP drill-IL 1,11 1111C1111_C11,c and L01:111-
11\ e 1ia\ e along
up to no\\ computer as the
</bodyText>
<reference confidence="0.643536">
1)t.&amp;quot;,t dil,11)1e 1\e d-pite Its Ii11113-
11011&apos;-,
SEMIONICS
The Car ernont
Minnel Acid
B(-2r !,1\/, CA 04705
41`;) U18 7100
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.8959525">Journal of Computational Linguistics 76 THE FINITE STRING NEWSLE1TER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS VOLUME 15 - NUMBER 3 JUNE 1978 JOURNAL OF COMPUTATIONAL LINGUISTICS is published the Association for Computational Linguistics.</note>
<affiliation confidence="0.981255">SECRETARY-TREASURER: Donald E. Walker, SRI International&amp;quot;,</affiliation>
<address confidence="0.998212">Menlo Park, California 94025 EDITOR: David G. Hays, 5048 Lakeshore Road, Ramburg, New York, 14075</address>
<affiliation confidence="0.961771">ASSOCIATE EDITOR: George E. Heidorn, IBM Research Center,</affiliation>
<address confidence="0.968627">P.O. Bbx 218, Yorktown Heights, New York 10598</address>
<note confidence="0.899988176470588">Benzon Copyright 1978 Association for Computational Linguistics Journal of Computational Linguistics 2 CONTENTS TINLAP-2: F)ROGRAM AND ABSTRACTS 3 SOICIETY AMERICA: SPECIAL MEETING 37 PERSONAL 38 NATIONAL 39 NOTICE CONFERENCES 40 RECOGNITION MEMORY (REM): SEMIONICS ASSOCIATES . 43 SCREENSPLITTER 54 THE TARGET PRIJECT&apos;S INTERACTIVE COMPUTERIZED MULTILINGUAL Burge Journal of Computational Linguistics 76: 3 TINLAP- 2: PROGRAH AND ABSTRACTS JULY 25 - 27</note>
<affiliation confidence="0.996417">UNIVERSITY OF ILLINOIS AT URBANA CHAMPAIGN</affiliation>
<abstract confidence="0.991533173913044">TINLAP-2 will consist of six sequential sessions, each of which address of current theoretical interest and on long-range research directions. In session from artificial linguistics, psychology, and philosophy will focus their points of view on a particular topic (see schedule below). Proceedings will be dvailable before the meeting. Each author give a 10-15 minute presentation (which include a critique of other papers, an amplification of points in the w.Lit,ten paper, etc.) followed by a 90 minute discussion period where questions and cnmments from the audience will be welcome. There will be other interesting evenus durin6 and after the workshop, including the ACL Annual Meeting, a banquet, several opportunities for informal discussions, and events associated the Linguistic Institute, to be held the University of Illinois this summer. The LSA (Linguistic Society of America) meeting will be held at the University of Illinois immediately aftet TINLAP-2, July 28-30. Information shout the LSA meeting can be obtained from Proressor Braj Kachru, Department of Linguistics, University of Illinois. The program for TINLAP-2 is listed immediately below The frame number for the abstract is given in parentheses. Bxesentations for which no abstract was available arp designated with an asterisk.</abstract>
<title confidence="0.3415135">PROGRAM Reception and Registration at Levis</title>
<affiliation confidence="0.7966225">Center; Snacks and LANGUAGE REPRESENTATION AND PSYCHOLOC=Y</affiliation>
<address confidence="0.479534">Chair: Dedre Gentner, BBN (7)</address>
<email confidence="0.297125">Pane.Lists:</email>
<affiliation confidence="0.942861">Rumelhart, University</affiliation>
<address confidence="0.38885">Diego*</address>
<author confidence="0.498695">Roger Schank</author>
<author confidence="0.498695">Yale Leonard Talmy</author>
<author confidence="0.498695">Neuropsychiatric</author>
<affiliation confidence="0.826088">Institute of Los Angeles, UCLA</affiliation>
<author confidence="0.8038795">Terry Winograd</author>
<author confidence="0.8038795">Stanford</author>
<author confidence="0.8038795">Xerox PARC William Woods</author>
<author confidence="0.8038795">BBN</author>
<date confidence="0.861747">July 24 7:00 pm</date>
<note confidence="0.9415772">9:00 pm July LD 9:00 am 11-45 am 1:30 pm- LANGUAGE REPRESENTATION AND REFERENCE 4:15 pm Chair: Bpnnie Lynn Webber, BBN (10) Panelists: hn Anderson, Yale (11) TINLAP-2 July 25 5:00 (Representation and Reference) Herbert Clark, Stanford (13) 7:00 pm ikndrew Ortony, University of Illinois (14) 3arbara Partee, University of Massachusetts (15) :andace Sidner IT (16)</note>
<affiliation confidence="0.582569">Informal DiArcussion, Cash Bar and Snacks; Levis Faculty Center</affiliation>
<address confidence="0.7424835">July 26 9:00 am- DISCOURSE: SPEECH ACTS AND DIALOGUE 11:45 am Chair: Barbara Grosz, SRI</address>
<title confidence="0.210055">Panelists:</title>
<author confidence="0.2994055">Cornell Jerry Morgan</author>
<author confidence="0.2994055">University of Illinois</author>
<affiliation confidence="0.619489">Olson,</affiliation>
<address confidence="0.88617275">RaymondPertault, Toronto* Andee Rubin, BBN (21) 1:30 Pm LANGUAGE AND PERCEPTION 4:15 Chair: David Waltz, University of Illinois (23)</address>
<email confidence="0.641324">anelists:</email>
<author confidence="0.625768666666667">Ruzena Bajcsy</author>
<author confidence="0.625768666666667">University of Pennsylvania Ray Jackendoff</author>
<author confidence="0.625768666666667">Brandeis Stephen Kosslyn</author>
<author confidence="0.625768666666667">Harvard</author>
<affiliation confidence="0.846393666666667">Zenon Pylyshyn, University of Western Ohtario (27) Wilks, University of Essex</affiliation>
<pubnum confidence="0.538654">TINLAP-2</pubnum>
<date confidence="0.756745">July 26 5/00 pm - ACL ANNUAL MEETING</date>
<note confidence="0.7123492">6:00 pm 6.30 pm Banquet (optional) Speaker JON ALLEN, M.I T 27 9.00 am - MECHANISMS&apos;IN LANGUAGE 11.45 am Chair. Arairind Joshi, University of Pennsylvania** Panelists: Charniak, Yale Allan Collins, Yale (30) Jerrold Kaplan, University of Pennsylvania (31) Raymond Reiter, University of British Columbia (32) of Maryland (34) Stuart Shapiro, SUNY Buffalo (35) Rand Spiro, University of Illinois (36) 1:30 pm - COMPUTATIONAL MODELS AS &apos;A VEHICLE FOR 4:15 pm THEORETICAL LINGUISTICS Chair. Rona1d Kaplan, Xerox PARC* Panelists. Joseph Grimes, Cornell*</note>
<author confidence="0.720337">Mark Liberman</author>
<author confidence="0.720337">Bell Laboratories Mitch Marcus</author>
<author confidence="0.720337">MIT Tom Wasow</author>
<author confidence="0.720337">Stanford</author>
<note confidence="0.51036">No paper to be presented.</note>
<title confidence="0.6582385">TESTING THE PSYCHOLOGICAL REALITY OF A REPRESENTATIONAL MODEL</title>
<author confidence="0.773736">Dedre Gentner</author>
<affiliation confidence="0.822152">ttolt Beranek and Newman, Inc.</affiliation>
<abstract confidence="0.997234258064516">research program is in which a particular refor meaning is tested as broadly 0,s po$sible. this format, developed by LNR research group at The Uniof California San Diego, verbs are represdnted aL interof subpredicates. subpredicates may be of as the inevitable that a listener when a is used in They confer meaning structure on the sentence in which the verb is used. To be valid, these should capture 1. Similarity of meaning: two verbs in meaning to the more their representations should overlap. 2. Confusability: more confusable two verb are for people, the more their representations overlap. 3. Memory for sentences containing the verb: structures set up by the verb&apos;s meaning should in part determine the way in which sentences are remembered,. SemanAc integration: The representations should allow for the integration of information from different sentences into discourse structure. 5. Acquisition patterns: partitions in representations should correspond to the structures children acquire when they are learning the meanings of the verbE 6. Patterns of extension: The representations should be extendable so as to reflect the ways in which people interpret verb meanings when the verbs are used outside their normal context. 7. Reaction times: The time taken to comprehend a sentence using a given verb should reflect the structural complexity of the verb meaning. Experiments concerned with predictions 1 - 5 are described here. The results are promising for a general approach of representation of meaning in terms of interrelated subpredicates, but do not clearly distinguish between several similar representations. For example, to test prediction (2), I read people sentences containing verbs with similar meanings, and asked them to recall the sentences. The degree of overlap in the semantic structures was a good predictor of the number of confusions between sentences. In another sentence-memory experiment (prediction (3)) semantically complex verbs that provided more underlying interconnections between the nouns in a sentence led to better memory fot the nouns in the sentence than simple general verbs, or than other cdmplex verbs that did not provide such extra interconnections. To test tested children&apos;s comprehension of a set of pos session verbs. Both the order of acquisition among the verbs and the kinds of errors fitted well with an account of the acquisition of verb meaning in terms of interconnected subpredicates This research illustrates a breadth-first approach to testing a representation. In the breadth-first approach, many different psychological predictions are made. Each different area of prediction requires a sat of process assumptions, and in each case the process assumptions used are those that seem most plausible given previous research in the field. If one representational format can make correct predictions about a number of different kinds of psychological phenomena, then that representation stands a greater chance of being generally useful than one which was tested in only one depth-first way.</abstract>
<title confidence="0.973425">The Relation of Grammar to Cognition</title>
<author confidence="0.662477">Leonard Talmy Neuropsychiatric Institute</author>
<author confidence="0.662477">UCLA</author>
<abstract confidence="0.993036227272727">A sentence (or other portibtof discourse) is +Aran to evoke in the listener a meaning complex, here called a &amp;quot;cOgnitive representation&amp;quot; The lexical elements of the sentence seem, by and large, to specify the content, or substance, of the cognitive representation, while the grammatical elements specify its structure. Thus, looking systematically al the actual notions specifiea by grammatical elements can give us a handle for ascertaining the very makeup of (linguistic-) cognitive structuring. We accordingly examine a number of grammatically specified notion, obserVe the systems or categories in which they pattegp, and speculate on broader cognitive connections. Some provisional findings have already emerged: Grammatical specifications for struCture are preponderantly relativistic or topological, and exclude the fixed or metrically Euclidean. The systems in which grammatidal notions pattern include: plexity (uniplex/multiplex) degree of extensionality pattern of distribution state. of boundedness axial characteristios perspectival characteristics scenes.breakup characteristics state of dividedness level of synthesis level of exemplarity 4rammatical specification of structuring appears, in certain abstract characteristics, to be isomorphic with the otructuring of visual percevtion.</abstract>
<note confidence="0.9042306">Reference: Talmy, L. Rubber-Sheet Cognition in Language. In: Papers from the 13th Regional Meeting, Chicago Linguistic Society. Beach, et. al., eds. University of Chicago. Formation and niscourse Model. Synthesis</note>
<email confidence="0.68651">gebber</email>
<affiliation confidence="0.923221">Bolt Beranek and Newman Inc.</affiliation>
<address confidence="0.929492">50 Moulton Street 09138</address>
<abstract confidence="0.995755571428571">Researchers in linguistics, psychology and artificial intelligence have recently begun to abandon a.purely linguistic approach to definite anaphora pronouns and noun they the notion af reference that a listener/reader is synthesizing from the idiscource: the referent of a definite anaphor is then not a linguistic object, but rather an entity in a model. Such a model has been called a &amp;quot;world of discourse&amp;quot; &amp; Goldman, 1978]; a &amp;quot;universe of discourse&amp;quot; [1yons 1978], model&amp;quot; [Nash-Webber 1977; Webber 1978] and a &amp;quot;domain of interpretation&amp;quot; [Stenning 1975], inter alia. Its synthesis is what interests me. Discourse model synthesis intuitively&apos; seems to result from interactions between the listener/reader&apos;s expectations and various features of the text. these interactions not clear. A discussion of how the listener reader&apos;s changing expectations can atiect discourse model synthesis can be in [Collins, &amp; What I shall discuss here are some of the that what entities appear in a discourse model and such entities are described. course of presenting these features, I will argue that having an appropriate description for a discourse entity critical its successful reference later an. I will then argue that recognizing formal aspects of the text is critical to the formulatioh of descriptions. While is not sufficient condition for reference, certainly one.</abstract>
<note confidence="0.983014">References Collins, A., Brown, J.S. &amp; Larkin, K. (1977) Inference in Text Understanding. Technical Report No. 40, Center the of Reading, of Illinois and Bolt Beranek &amp; Newman Inc. December 1977. J. &amp; N. (1978) of Unpublished MS., Information Sciences Institute, Marina Del Rey CA. Lyons, J. (1977) Semantics. England: Gambridge University Press, 1977. Nash-Webber, F.L. (1977) in an Approach to Discourse No. 77, for the Study of Reading, University of Illinois Bolt Beranek Newman Inc. 1977. Stenning, K. (1975) English Articles and Quaqtifiers. Unpublishted Rockefeller University, 1975. (1978) A Formal Approach to Discourse Anaphora. Technical Report No. 2761, Beranek &amp; Newman Inc., MA April 1978.</note>
<title confidence="0.979705">Representation of Iftdividuals in S=ulantic Nets</title>
<author confidence="0.997811">John Anderson</author>
<affiliation confidence="0.988106">Yale University</affiliation>
<abstract confidence="0.9742293125">Research is reported concerned with how subjects process multiplegreferring expressions 4 In one experiment, subjects learn sentences such as: smart Russian cursed The smart Russian rescued the kitten The tall lawyer adopted the child Th t tall lawyer Caused the accident and only later learn that the smart Russian is the same person as the tall lawyer,. How do subjects integrate the information about the smart Russian Otth information about the tall lawyer? It is information subjects have set up two nodes in memory, one for each definite description. Upon learning of the identity of the descriptions, into memory a proposition indicating the identity of the two individual nodes. They also start a of copying information from one node to the other effect, they choose abandon of the nodes. is argued that a similar occurs when subjects recognize the referent of a definite description—but on a much shorter time scale. So, suppose a subject hears: The first president of the United States was a bad husband. The proposal is that the subject creates a new node to represent the subject of that sentence, attaches to this node network structure to encode it is the first president of the United States, uses this network structure to guide a search of memory for the referent, finds a node corresponding to George Washington (GW), indicates that the new node and the GW node are the same, copies fromthe new node to the GW nOde the bad husband predicate, and abandons the nev node. Data is presented consistent with this process model for dealing with the referents of definite descriptions. lz. 13</abstract>
<title confidence="0.999309">Reference Diaries</title>
<author confidence="0.999487">Herbert H Clark</author>
<author confidence="0.999487">Catherine Marshall</author>
<affiliation confidence="0.999842">Stanford University</affiliation>
<author confidence="0.751572">Standford CA</author>
<abstract confidence="0.994108944444445">Speakers and listeners are forced to keep diaries about what they now about each other because, to use or interpret a definite reference, they have to assess the knowledge they &amp;quot;Ahare&amp;quot; with each other about the thing referred to. More prediseXy, it can be shown that the listener have to assess what is technically called their mutual knowledge about the referent. This, however, raises a striking paradox. The assessment of mutual knowledge logically requires an infinity of separate tests, and if each test takes a finite amount of time, then people would take an length of time to make or any definite a solutiun to this problem, we people the heuristic of searchtheir diaries for an event that a we call triple such an event they can satisfy inffnity of required by mutual knowledge in a single step. We discuss the kinds of that satisfy co-presence, -iad we provide experimental evithat when people cannot find event they are open to error their int_expretation definite reference. pragmatic on the Ind interpretation of definite, descriptions.</abstract>
<author confidence="0.962007">Andrew Ortony</author>
<affiliation confidence="0.815582">of Illinois</affiliation>
<abstract confidence="0.996508052631579">production and the of definite descriprequires that be made. In many cases inferare trivial and of little theareticak importance or interest. However, there is a class of definite descriptions the characteristic relation to their. antecedents on with deductiveiy loiical inferences). In such cases, the predicate un0Prlying definite descr&apos;iption cannot be taken to be true of the antecedent a result of any the predicate as beim; proabilistically This examines clas;, of &amp;quot;pragmatic definite descriptions&amp;quot; closely, paying particular attention &apos;fo what constrains the set of candidescriptions that can used to to the antecedent, of the results of this is the of a about extent which an indirect act can be 4 ind irect.</abstract>
<note confidence="0.6912655">14 Bound Variables and Other Anaphors 15</note>
<author confidence="0.986125">Barbara H Partee</author>
<abstract confidence="0.999605">The aim of the paper is to delimit a subset of pronominal anaphora for which the logicians notion of bound variables gives the best account. It can be argued that some cases of anaphora must be iewed this way cases cannot be. The clearest cases of variable emporia. involve manand no man which are singular in form but do not refer to individuals. But even with an antecedent like John, an anaphoric pronoun must sometimes pkvielded as a bound variable to account for of the readings (the so-called &amp;quot;sloppy identity&amp;quot; reeding) of John sure he would win+, so was Bill. Bouud variable anaphora will be coRtrasted with free &amp;quot;discourse&amp;quot; anaphora; differences between the is phenomenon, the largely pragmatic.</abstract>
<title confidence="0.9845955">The Usle of Focus ag a Tool for Disambiguation of Definite Noun Phrases</title>
<author confidence="0.865582">Candy</author>
<affiliation confidence="0.334167">MIT Al Lab</affiliation>
<abstract confidence="0.994413333333333">This paper will center on a discussion of the use of focus in the interpretation of anaphoric noun phrases in discourse. The need for focus will be discussed, and a description of focus shifting will be given. Focus provides a means of representing the central concept of a discourse. The ways in which a definite noun phrase, specific or generie, can be used are constrained by its relation to the focus and by the ways in which the focus can be shifted. The discussion of anaphoric defnps will present a taxonomy of cases, distinguished by the relation of the defnp to the focus, This taxonomy inclues several kinds of inference dependent cases. The paper will concentrate discussing on the process of understanding defnps, and will present rules governing the ways a defnp can be used so that the hearer/reader can understand its co-referent. This paper will also distinguish reference, co-reference and internal reference, and point out the need for these distinctions in natural language research.</abstract>
<date confidence="0.4827765">16 17</date>
<title confidence="0.994139">FOCUSING IN DIALOG</title>
<author confidence="0.999999">Barbara J Grosz</author>
<affiliation confidence="0.999982">SRI International</affiliation>
<address confidence="0.99376">Menlo Park, CalifoLnia</address>
<abstract confidence="0.9996213">wnen two people talk they focus On only a snail portion of what each of them knows or believes. Both what gets said and how it gets depend on this narrowing of to a highlighted portion of knowledge. One of the effects of understanding an utterance is to become focused on certain entities (relationships and and on views of those A speaker provides a hearer with clues to what to look at and how to look at it -what to on, how to focus on and how wide or narrow that focus should &apos;These clues may be linguistic or may come from knowledge about relationships among entities the domain (the structure of the being talked about) from in which the occurs. Linguistic cues may be either explicit, given directly by words, or deriving from sentential structure or frou relationships This paper examines focusing in dialog, discusses an initial in which focusing is based on structure cues, and this perspective what information and models needed to extend the formalization of focusing to more general dialogs. importance of focusing is illustrated by its role understanding and generating descriptions.</abstract>
<affiliation confidence="0.912911">TOPIC LEVELS Grimes Cornell Universii-</affiliation>
<address confidence="0.96821">Ithaca, N.Y.</address>
<abstract confidence="0.946328058823529">In order to interpret either a dialogue or a monologue; some referential elements mgst be agreed on by the speaker and the hearer as starting point. This is the topic the sense proposed by Searle and g Even topic normally shifts away from its starting Point in the course of a text, whatever is being treated as topic in a particular part of the text receives special treatment in determining the expression to be uSed., leve3,s of topic, global 4nd local, in conversation have noted by They imply different strategies for establishing reference of pronouns. It is useful to consider them in light of two other languages, Longuda of Nigeria and Bacairi of Brazil, that distinguish topic from nontopic by their pronoun systems. Finally, there is some evidence from both Greek and English that there may be more than two topic levels operating simultaneously in nonconversational texts. 18 ABSTRACT</abstract>
<title confidence="0.933047">Toward a rational model of discourse comprehension</title>
<author confidence="0.998975">J L Morgan</author>
<affiliation confidence="0.98575175">Center for the Study of Reading and Department of Linguistics University of Illinois</affiliation>
<abstract confidence="0.99043205882353">Models of discourse Vr text often treat connected discourse in a manner anaLogous to the treatment of sentences in traditional and grammar; i.e. as a formai be decoded by means certain formal point out in this paper that even where this view is not explicitly, proposed, it is often implicit. Against this common view I argue that the only kind of discourse model that is likely to succeed is one that is built around two important hypotheses: first, that the key to discourse comprehension is the attempt to infer the details of the plan that the speaker/ writer follows in constructing the text; second; that a large portion of the work of a discourse comprehension model should be derived from a theory of practical reasoning. I will sketch the outline of a model (or more accurately, a schema for a large class of possible models) that incorporates these suggestions, pointing out the role of practical reasoning processes, and arguing that notoriously confused like and &amp;quot;6xpected only sense of in such a model.</abstract>
<date confidence="0.764236">19</date>
<title confidence="0.973721">SOME SOCIAL AND LOGICAL ASPECTS OF MEANING IN THE LANOROAGE OF SCHOOL-AGED CHILDREN</title>
<author confidence="0.999991">David R Olson</author>
<affiliation confidence="0.999962">Institute for Studieg Education</affiliation>
<address confidence="0.988243">Toronto, Canada</address>
<abstract confidence="0.979193947368421">is to the meaning of an utterahce in a in terms of two component and pragmatic speech the first indicating the meaning the the seconal indicating intended use,by the speaker. shall present some arguments and evidence that systems Roughly, appears that primarily status, determine which aspects of a proposition are in the utterance. Thus, child high status relative his interlocutor may use a command, &amp;quot;Give block&amp;quot;, while if he has low status relative to his interlocutor he may use a request, &amp;quot;May I a block?&amp;quot; If he is an equal, a peer, (and perhaps only then) will use an explicit true proposition such as, &amp;quot;You have two more than Only in this case is the meaning explicit in the sentence per se, and only in this case is an affirmative or negative dependent strictly upon truth conditions (rather compliance, for example). This conception of the social aspects of meaning will be examined through an analysis of what is said vs. what is meant in some childchild and teacher-child conversations,*</abstract>
<note confidence="0.7050725">20 ■1..*Wwfa■mMIMP.1 Paper prepared for TheoretiCal Issues in Natural Language Processing Urbana, University of July 1978.</note>
<title confidence="0.98268">WHO AK I TALKING TO AND CAN THEY TALK BACK: THE EFFECT OF AUDIENCE AND INTERACTION ON DISCOURSE MODELS</title>
<author confidence="0.995028">Andee Rubin</author>
<affiliation confidence="0.482745">Bolt Beranek and Newman</affiliation>
<address confidence="0.920623">Cambridge, Mass.</address>
<abstract confidence="0.976313636363637">among occurs a vast variety of reading a to participating a from a tape a transcript of a lecture. Most discussions of discourse, speech acts and dialogue, however, consider a very particular of communicative oral conversations between two participants in which there is a common spatial and temporal context. Dialogues between a computer system and a person differ from model least two modality of the interaction (current computer-person dialogues are written) and the lack of spatial commonality, indicated by the impossibility of communicating gestures and facial expressions. The implications of differehces for theories of discourse are poorly understood4, worse yet, they illusttate only a small subset of the dimensions along which language experiences may vary. What relevance do the theories we to account for these interchanges have other communicative experiences such as listening to a lecture or reading a play? This paper will focus on two other aspedts of language experience have consequences for the dialogue models we build: audienceand degree of interaction.In both situations described above, the audience is a single other person (or system) and interaction between the participants or even interruption is immediate. But in a book, for example, the audience is larae and not well defined and the book s reader must adopt new strategies to compensate for the fact that interaction is impossible. In a personal letter, on the other hand, the is a single other person, similar to situation. Interaction, however, is impossible or at least attenuated; the reader can obtain clarifying information, but the time lapse will be significant. 21 consider in this paper &apos;where experiences lie along these two dimensions and what the implications of these differences are for mode4 of discourse and dialogue. 22</abstract>
<title confidence="0.99905">On the Interdependence of Language and Perception</title>
<author confidence="0.999993">David L Waltz</author>
<affiliation confidence="0.999413">Coordinated Science Laboratory University of Illinois at Urbana/Champaign</affiliation>
<abstract confidence="0.953162285714286">Without a connection to the real world via perception, a language system cannot know what it is talking about. Similarly, a perceptual system must have ways of expressing its outputs via a language (spoken, written, gestural or Gthet). The relationship between-perception and Language is explored, with special attention to what implications results in language research have or our models of vision systems, and vice-versa. It is suggested that early language learning is an especially fertile area or this exploration. Within this area, we argue that perceptual data is conceptualized prior to language acquisition according to largely innate strategies, that this conceptualization is in terms of an internal, non-ambiguous &amp;quot;language,&amp;quot; that Language production its beginnings to adulthood is a projectionoI the internal Language which selects and highlights the most important portions of internal concepts, and that schemata produced in the sensory/motor world are evolved into .chemata to describe abstract worlds. Examples are provided stress the importance of &amp;quot;gestalt&amp;quot; (figure-ground) relationships and vrojecttlon (3-D to 2-1/2 or 2-D , conceptual to linguistic, and linguistic to conceptual); finally mechanisms for an integrated visionlanguage system are proposed, and some preliminary results are described 23 24</abstract>
<title confidence="0.990706">The Problem of NaMing Shapes: Vision-Language Interface</title>
<author confidence="0.91243525">by R Bajcay</author>
<author confidence="0.91243525">A K Joshi</author>
<affiliation confidence="0.9991885">Computer and information Science Department Vniversity of Pennsylvania</affiliation>
<address confidence="0.996969">Philadelphia, PA 1904</address>
<abstract confidence="0.996886608695652">panop,wo wt11 poso morv questions than present soluticm. We want to some questions in the context of the of shapes of objects One way to get a handle on this problem is to investigate whether labels of shapes and their acquisition reveals any structure of attributes or components of shapes that might be used for representation purposes. Another aspect of the puzzle of rcpresentation is the question whether the information is to be stored in analog or:pf6positional form, and at what level this transformation from analog to proform takes general, shape of a 3-D compact object has two aspects: surface and the aspect.The surface aspect includes like concavity, convexity, planarity of surfaces, edges, and corners. The volume aspect distinguishes objects with hoJes from those without (topological properties), and describes object with respect to their symmetry planes and axes, relative proporLions, etc. has been supported &apos;under NSF Grant and &apos;NSF Grant WIICS76 19466. 25 We will discuss some questions pertinent to representation of a shape of a 3-D compact object, without holes, for example: Is the surface aspect more important than the volume aspect?, Are there any shape primitives? In what form are shape attributes stored?, etc. We shall extensively draw from psychological and psycho-linguistic literature, as well as from the recent Al activities in this area.</abstract>
<title confidence="0.939273">An Argument Combining Linguistic and Visual Evidence</title>
<author confidence="0.99997">Ray Jackendoff</author>
<affiliation confidence="0.998601">Brandeis University</affiliation>
<abstract confidence="0.991766571428571">The notion from gestalt psychology of a &amp;quot;figure&amp;quot; emerging trom &amp;quot;background&amp;quot; will be shown to crucially involved in of the successful so-called anaphora&amp;quot; uses of pronouns without such as thatin (1). (1) I bought that pointing last Saturday. A survey of types of pragmatic anaphora in English will then be used to show that the notion of figure&amp;quot; must encompass a much range of perceptual entities than implications for linguistic philosophy, percept ial theory, and cognitive theory will be discussed 26 tentative abstract</abstract>
<title confidence="0.980485">Language and Perception</title>
<author confidence="0.99646">Zenon Pylyshyn</author>
<affiliation confidence="0.989436">University of Western Ontario</affiliation>
<abstract confidence="0.989166769230769">A language comprehension system without a perceptual component would, in an important sense, not know what it was talking about even if it could carry on a sensible dialogue. More significantly, a theory of comprehension be seriously deficient if it not relate linguistic representations to ones which derive from non-linguistic sources. This bridge is necessary order to explain how terms refer as well as to language is acquired. This paper will distuss and support the position that natural language learning is only possible because of the prior existence of mentalese--a language-like system of representation for perceptual as well as more abstract conceptual contents. How this comes into being cannot be given as an information processing explanation since it requires an account the of underlying machine architecture--not of its langu&apos;age processing software (i.e., interpreters).</abstract>
<note confidence="0.353097">28</note>
<title confidence="0.964381">SEMANTIC PRIMITIVES IN LANGUAGE AND VISION</title>
<author confidence="0.996995">Yorick Wilks</author>
<affiliation confidence="0.9998755">Department of Language and Linguistics University of Essex</affiliation>
<address confidence="0.778258">England</address>
<abstract confidence="0.9986605">An argumeti.t is presented that, on the basis of the evidence at there is no reason to believe that the semantic required by natural have any basis or grounding in vision. And, moreover, whatever may ultimately turn out to be the way we work, there is no reason to believe that trying to ground one sphere of Al on the other primitives on visual ones, would research in either area. A number of systems of primitives are examined in order the above argument.</abstract>
<title confidence="0.984976">With a Spoon in my Hand this must be the Eating Frame</title>
<author confidence="0.998427">Eugene Charniak</author>
<affiliation confidence="0.9894335">Department of Computer Science Yale University</affiliation>
<abstract confidence="0.926547566666667">language program using &amp;quot;trames,&amp;quot; &amp;quot;scripts,&amp;quot; etc. able to decide which frames are appropriate to the text. Often there will be explicit indication (&amp;quot;Fred was playing tennis&amp;quot; suggests the TENNIS frame) but it is not always so easy. (&amp;quot;The. steering wheel was hot, but Jack had to be home by 3&amp;quot; suggests DRIVING, but how?) This paper will examine how a program might go about determining the appropriate frame in such cases. The basic idea will be taken over Minsky (1975) in that it will assumed one usually has one or more context frames, so that one only needs worry if information comes in which does not fit them. As opposed to Minsky however the suggestions for new context frames will not come from the old ones, but rather directly from the conflicting information. A major portion of the paper then will be concerned with how we will index context frames DRIVING) under the clues which them (e.g., STEERING- WHEEL). 29 Human Pato be Reasoning Bolt Beranek and Newman Inc, a computationat theoty oti human peaus.ibte /reasoning que.oU,ons. L in content-.4ndevendent togit, the how dL66epLeizt n nienny a66ectis the cePtt (Linty titsions rtit,ami. The. theony ts a ctivail6 t ypeh and theiA ceibtainty conch-tins, inc1udbt9 a 06 metathe ine.A.ence. depend,s the about Tile 6h.on ante; tions o the. di6f,e)t.ent iFtticitence types, The. papa how menioty Ut muttipe.e ways to isuppott the type&apos;s, the iniotnat.i.ortin memoty de,teAmineis which in6e.P.ence t ype,s cute.</abstract>
<note confidence="0.257367">31</note>
<title confidence="0.990988">Indirect Responses to Loaded Questions</title>
<author confidence="0.999935">S Jerrold Kaplan</author>
<affiliation confidence="0.997649">University of Pennsylvania</affiliation>
<abstract confidence="0.99897415">Casual useit.of natural lanp:uage (NL) systems are typically inexpert not only with regard to the technical details of the underlyint, programs, but often regard to the and/or content of the domain of discourse. Consequently, NL systems must he designed to respond appropriately when they can detect a misconception on the part of the user. Several conventions e&gt;ist in cooperative conver&apos;,ation that allow a speaker to indirectly encode their intentions and beliefs about the domain into their utterances, (&amp;quot;loading&amp;quot; the utterances) and allow (in fact, often require) a cooperative respondent to address those intentions and beliefs beyond a literal r*sponse. To be effective, NL computer systems must do the same. paper will explore several types indirect responses NL that in the Data Basc query domain models exist can -determine an indirect response is required and whatthat should be. implementation of these ideas will be presented immediate practipl valte in N.14. systems. This paper will the position that inferences(i.e., inferences driven from the phrasing of the question) are to a great separable from deeper reasoning and deduction processes, and are sufficient to produce a wide variety of useful and cooperative behavior.</abstract>
<author confidence="0.524569">S J Kaplan</author>
<email confidence="0.231518">32</email>
<author confidence="0.9999">Ray Reiter</author>
<affiliation confidence="0.998851">University of British Columbia</affiliation>
<abstract confidence="0.998432024390244">I propose to discuss a number of principles for structuring knowledge, principles which arc motivated by the need for efficient deductive inference in systems. The notion of structure that I will define is, in some sense, orthogonal to but not antithetical to a number of current ideas in Al regarding the organization of knowledge. Intensional vs. Extensional Reptesentations of Knowledv Given a predicate P, we can represent what we know aboutP extensionally, or intensionally, e.g. as a procedure or a general axiom) or by some combination of both. Hoc,&apos; should this decision be made? It turns out that if we represent appropriate predicates extensionally then (i) No thfinite deductive searches can arise. (ii) Certain intensional knowledge becomes irrelevant for deduction and may be discarded. The Closed World Assumption “Ng0 In domains for: which we have perfect knowledge (e.g. blocks worlds) it is appropriate to make the CWA. This means, roughly speaking, that to establish a negative fact, it is suffidlent to fail to prove its positive counterpart. The CGOL yields a significant decrease in the complexity of deductive reasoning. In addition, it induces a decomposition of the available knowledge into two components, which is used only for integrity, and the other only for deductive inference. Horn Duta Bases is known that whenever the knowledge about a domain is by Horn formulae (i.e. formulae of he form where positive) then consequent and/or antecedent reasoning is complete domain. This result is not true for non Horn domains more ;,.ophisticated 33 reasoning, such as case analysis, may be required. Another nice feature of Horn is that the CA does not lead to any inconsistencies. domains car formulae. For some such domains it is possible to render then &amp;quot;essentially&amp;quot; Horn by extensionally representing certain appropriately choser in which case all of the Virtues domains may be salvaged. Summary proposing the following structuring principles; If make the CWA. If knowledge base is non Horn, make it &amp;quot;essentially&amp;quot; Horn by extensionally representing appropriate predibates. infinite paths .by extensionally representing certain suitably chosen predicats. 1, 2 3, will no longer be relevant for deduction. Remove these.</abstract>
<title confidence="0.7106695">Inference and Parsing Architecture in GRINO-1, a Dull-Scale Story Comprehonder</title>
<author confidence="0.999173">Chuck Riefler</author>
<affiliation confidence="0.9975285">Computer Selonce Department . University of Maryland</affiliation>
<address confidence="0.998342">Park, 20742</address>
<abstract confidence="0.919502727272727">APSTRACT: The paper kiescriut:s the inference and parsin7 components of GRIND-I, a full-scale story comprehension project bud on a Walt Disney rook of the Month Club book, &amp;quot;The Magic Grinder&amp;quot;. Topics include: (1) the sense network parser and it with iriference, (2) character porsomaity trait modelinr, via behavioral tags, (3) two-character relationship modelinry, and (4) plot representation and plot level,preliction. The main areas of emphasis will be on the representation of inference, and on the various types of inference conditioning that stem from the character models and plot. 34</abstract>
<title confidence="0.99057">Path-Based and Node-Based Inference in Semantic Networks*</title>
<author confidence="0.999986">Stuart C Shapiro</author>
<affiliation confidence="0.9997995">Department of Computer Science State University of New York at Buffalo</affiliation>
<address confidence="0.999786">Amherst, New York 14226</address>
<abstract confidence="0.96679">Two styles of performing inference in semantic networks are presented and compared,. Path-based inference allows an arc or a path or arcs between-two given nodes to be inferred from the existence of another specified path between the same two nodes. Path-based inference rules may be written using a binary relational calculus notation. Node-based inference allows a structure of nodes to be inferred from the existence pf an instance of a pattern of node structures. Node-based inference can be constructed in a semantic network using of a predicate calculus notation. Path-bastd inference is more efficient, while inference is more general. A method is described of the two styles in a single system in order to take advantage of the strengths of each. Applications of oath-based inference rules to the representation of the extensional equivalence of intensional concepts, to the explication of inheritance in hierarchies are 35 Preliminary version of a paper to be presented at &amp;quot;Theoretical Issues in</abstract>
<note confidence="0.877569666666667">Natural Language Processing,&amp;quot; the 1978 annual meeting of the Association for Computational Linguistics, Urbana/Champaign, Illinois, Juky 25-27, 1978. 36</note>
<title confidence="0.994721">Processing of Interences</title>
<author confidence="0.999975">Rand Spiro</author>
<author confidence="0.999975">Joseph Esposito</author>
<affiliation confidence="0.998985">University of Illinois</affiliation>
<abstract confidence="0.999536578947368">hypothesis that inferences &apos;presented in text taken for processed, and not stably or enduringly memory investigated. Stories were read which some conditions. coninformation the implicational force of inferences. vitiating presented eithqr ot after inferences. Experiment I, errors memory for the inferences were prevalent in the &amp;quot;after&amp;quot; but not the &amp;quot;before&amp;quot; condition. Two kinds of errors were made: the inference not been presented in the story; or, if it was remembered as having been presented, altering the specific content of the to produce the f what was actually The latter produced coherence with the vitiating information, and subjects to differeptiate these errors from correct responses. the results )(periment replicated, and a &amp;quot;spontaneous was The results of both experiments combine to supthe hypothesis superficial processing and unstable representation of explicit inferences. The results provile a link betWeen processes vl..curring at comprehension and recall in the State of Schema model of accommodative reconstruction.</abstract>
<note confidence="0.580615">Journal of Computational Linguistics 76: 37 DICTIONARY SOCIETY OF NORTH AnERICA SPECIAL MEETING</note>
<date confidence="0.947161">1978</date>
<affiliation confidence="0.981865">UNIVERSITY OF ILLINOIS, URBANA</affiliation>
<address confidence="0.754389">ROOM 407, LEVIS FACULTY CENTER Dr. Ladislav Phone 217 - 333-3563</address>
<affiliation confidence="0.997081">Department of Linguistics</affiliation>
<address confidence="0.696715666666667">Langkiages Building University of :11inois, Urbana 61801</address>
<affiliation confidence="0.957263">LECTURE: MALKIEL, DEPARTMENT OF LINGUISTICS, UNIVERSITY OF CALIFORNIA, BERKELEY</affiliation>
<title confidence="0.8317486">The Lexicographer as a Mediator Between Society Other lectures include: of Lexical Variants for DARE</title>
<author confidence="0.970451">J NITTI</author>
<author confidence="0.970451">the Old Spanish</author>
<affiliation confidence="0.49305">Dictionary</affiliation>
<abstract confidence="0.759063571428571">Lexicography at of Hawaii - Methods and Applications (participation tentative) FARR Possibilities Lexicographic Work (participation ter;ative) HOUSING: Illini Union University of Illinois Green Street $15.00 single 21.00 double Make reservations directly with the Union.</abstract>
<note confidence="0.626842333333333">Journal of Computational Linguistics 76: 38 NCC &apos;79 PERSONAL COMPUTING FESTIVAL 5 - 7, 19Z91 NEW CITY</note>
<title confidence="0.697429">PRESENT A PAPER GIVE A IALK ORGANIZE A PANEL DELIVER A TUTORIAL</title>
<author confidence="0.761671">WORTH IT</author>
<abstract confidence="0.983119857142857">WHAT IT? and every aspect of personal is being questioned IS IT How is personal computing enriching our individual lives, the lives of our families, and improving the quality of life in general? IT WORTH he money, the time, the effort, the Jf technical expertise, even the criticism. Potential participants should send a &amp;quot;letter of intent&amp;quot; as soon as possible, but no later than February 1, 1979 to Jay P. Lucas letter should include abstract and a brief biography presented during the will be published. Potential authors will be mailed a Festival Author&apos;s Kit with instructions and materials. Papers must be received by March 15, 1979 in the specified camera-ready format. Authors will be notified by May 1, 1979. TUTORIALS AND TALKS: Session leaders a brief abstract describing either the scope of the proposed sesor the tentative title of the by February 1, 1979. The prospective organizer should submit a list of proparticipants, their and a brief biography of each.</abstract>
<title confidence="0.923327">JOINT PROGRAM CHAIRMEN FESTIVAL CHAIRMAN</title>
<author confidence="0.999286">Richard Kuzmack</author>
<address confidence="0.974818">1435 Layman Street McLean, VA 22101 Russell Adams 3008 Mosby Street Alexandria, VA 22305</address>
<author confidence="0.961461">Jay P Lucas</author>
<address confidence="0.856135333333333">3409 Saylor Place Alexandria, VA 22304-</address>
<phone confidence="0.456746">703 821-2873(home) 701 548-8261(home) 703 751-3332 (homE)</phone>
<affiliation confidence="0.322719">Journal of Computatiou al Linguistics 76: 39</affiliation>
<address confidence="0.652369">1979 NATIONAL COMPUTER CONFERENCE 4 - NEW YORK CITY</address>
<abstract confidence="0.7206322">PARTICIPATE: a paper. Propose a te6hnieal or panel session Volunteer to be a panelist. Send ideas for topics. Suggest special activities.</abstract>
<title confidence="0.398115666666667">SUGGESTED AREAS FOR PARTICIPATION: MANAGEMENT SCIENCE AND TECHNOLOGY APPLICATIONS SOCIAL IMPLICATIONS</title>
<abstract confidence="0.936292769230769">GUIDELINES: be previously unpublished. Must be in form with tables. 411 papers will be refereed. 2500 words to 5000 words. Six copies of the paper should be submitted along with six copies of title containitag a L50 word abstract, 4 to keywerrds, author&apos;s number and mailing address. TECHNICAL OR PANEL SESSIONS: Proposals should include a topic description, suggested session chairpersons and presenters, panelists, and indicttion or importance of session and anticipated audience. SEND SUBMISSIONS BY NOVEMBER 1, 1978 TO THE PROGRAM CHAIRMAN.</abstract>
<title confidence="0.592762">CONFERENCE CHAIRMAN:</title>
<author confidence="0.95043">Merlin G Smith</author>
<affiliation confidence="0.626436">Watson</affiliation>
<address confidence="0.981238666666667">P.O. Box 218 Yorktown Heights9 New York 10598</address>
<title confidence="0.836812">PROGRAM CHAIRMAN</title>
<author confidence="0.997696">Richard E Merwin</author>
<address confidence="0.98823">Box 32222 Washington, DC 20007</address>
<note confidence="0.612680333333333">Journal of Computational Linguistics SHORT NOTICE OF UPCOMINGCONFERENCES FOURTH JOINT INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION</note>
<date confidence="0.898289">November 7 - 10, 1978</date>
<affiliation confidence="0.6235212">Kyoto, Japan Sponsor: IEEE Contact: Professor Makato Nagao Department of Electrical Engineering Kyoto University</affiliation>
<address confidence="0.993229">Sakyo, Kyoto 606 JAPAN</address>
<note confidence="0.497478">ACM &apos;78</note>
<date confidence="0.977254">December 4 - 6, 1978</date>
<address confidence="0.822843">Washington, D.0</address>
<author confidence="0.600787">Contact Richard Austing</author>
<affiliation confidence="0.9998425">Department of Computer Science University of Maryland</affiliation>
<address confidence="0.992324">College Park, MD</address>
<affiliation confidence="0.649245">COMPUTER ELEMENTS WORKSHOP ON PUTTTING A MATURINr: TECHNOLOGY</affiliation>
<author confidence="0.575312">TO WORK</author>
<date confidence="0.952808">December ll - 14, 1978</date>
<address confidence="0.967902">Mesa, Arizona</address>
<affiliation confidence="0.450764">Sponsor: IEEE - CS Contact: S.M. Neville</affiliation>
<address confidence="0.650668">Labs, Room Naperville, IL 60540</address>
<note confidence="0.9135835">CONFERENCES 145th ANNUAL MEETING OF AAAS</note>
<date confidence="0.790876">January 3 - 8, 1979</date>
<address confidence="0.93652175">Chicago, Illinois Contact: Dr. Arthur Herschman 1776 Massachusetts Avenue, NW Washington, DC 20005</address>
<author confidence="0.87565">Edward Ruffing</author>
<affiliation confidence="0.93219">Only: Scherago</affiliation>
<address confidence="0.999131">1515 Broadway New York, NY 10036</address>
<affiliation confidence="0.972595">ANNUAL MEETING OF THE COMPUTER LAW ASSOCIATION</affiliation>
<date confidence="0.644618">March 4, 1979</date>
<affiliation confidence="0.298278">Washington, D.C. Michael</affiliation>
<address confidence="0.72916475">Suite 1100 1776 K St., N.W. Washington, DC 20006 NFAIS 21st ANNUAL CONFERtNCL</address>
<date confidence="0.823278">March 6 - 7, 1979</date>
<address confidence="0.510852">Arlington, VA</address>
<author confidence="0.878803">Contact Toni Carbo Bearman</author>
<affiliation confidence="0.931149">NFAIS</affiliation>
<address confidence="0.8342405">3401 Market St. PA</address>
<affiliation confidence="0.843345">ANNUAL CONFERENCE OF THE CANADIAN LIBRARY ASSOCIATION</affiliation>
<address confidence="0.9064035">June 14 - 20 Ottawa, Ontario, Canada</address>
<affiliation confidence="0.82546">Contact: Business Manager Canadian Library Association</affiliation>
<address confidence="0.953911666666667">151 Sparks Street, 9th Floor Ottawa, Ontario KlP 5E3 Canada</address>
<note confidence="0.506462">41 AMERICAN LIBRARY ASSOCIATION ANNUAL CONFERENCE</note>
<date confidence="0.83894">June 24 - 30, 1979</date>
<note confidence="0.487856833333333">Dallas, Texas Contact: American Library AssocLacion 50 East Huron Street IL SIXTH tNTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-79)</note>
<date confidence="0.655281">August 20 24</date>
<address confidence="0.535717">Tokyo, Japan</address>
<affiliation confidence="0.879305666666667">Contact f Prof. Bruce Buchanan, Program Chairman Computer Science Department Stanford University</affiliation>
<address confidence="0.998758">Stanford, CA 9,4305</address>
<note confidence="0.733636">Journal of Computational Linguistics</note>
<title confidence="0.771066">RECOGNI,T-ION IlEllORY SEMIONICS ASSOCIATES: TECIINICAL NOTE Rec. ognition Memory (REM) Associative Memory</title>
<abstract confidence="0.989733456666667">Computer memoileS may be di ided into mo which has been almost unup to now, e\cept pe stored it ern-f4 are by means of their addicisses the address being a number that identines the location in mlnk-h the item is tofed rlus is the type of used in all Ak the histor) data processing The relati■cl little-knomn t pe has been discussed and ,dreamed about b) ‘arious scientisVS ) 11018 , under the decioations Associative Memory and Content- AddresGable Memory (CAM). With this t) pe of memory an item may be accessed simply b) *being named if it is present, those at1011N A\ ha ‘e it recognire it arrd respond In his re, ebt book on the sullecti l&apos;wfcssor (a\ton Foster describes the dit Ici ence bc1s■een these two t)pes of memories by omp,fr■son i1 nation s filch ‘rica.her mants to Isnom %cinch student, in th: ha\ a paTilL book. If he operates like v itli (and assuming no prior dues that mould eliminate portions of the class from he mould the first at in and ask the stvdent in that scat, Do, this book&amp;quot; would then icpeat step for se, ond and so fotth, through e‘er) seat in the class If he op..rated like an .:,ssociatitC memor). on thc other hand t.ould simpl) SJ ■ to the milo=le Jass students mho have this book please their As this illustration sug- Cntitt.nt Proke.ors Rti9htild, 1976 RC i1 .ins of tocognition oi mnloiin iton ieor language pi o, essing at ion rather striking 111;iy then h a c\,,Ttions) alma\ s been knit ak.,essed memories&apos; here tmo maim ( la 1/1111/01he and doubtless mote important. I the 1.1e,itei in building is5o.„1.itic Recognition Memory a of ..e\etal ■ eat. 110\\ , v,inotp, l011111111ff lia\C bCell \A It MC di pioposinr designs -and apfor associative memories 2and a fem. e \perimental nUvdels ha c e been ,onsttuLtbut at such great cost that the) hi, t&apos; ree\i&apos;vinnvntal is no&amp;quot; a commercial]) ‘,1 ni.. mor) but it is ■ , \p, therefore jrot hick &apos;Ned nor ot. 1.1&apos;01\ Ng unst this i A Otill .17\m‘ has CIL \ (it s) Re. mtion Mcnio■rs M) mluch cmbo,lies sonic lint :mons t patcuts pendun..0 that vn uI .ulti‘c al to \‘ bile la, sine the d(haritolle■ of nioie RI \I 111C11 propharp) feature that be built not -mud] hu :her thLin of cornentional mast. I s, pr sen il a ailahle online!, s\ stem (as ot 4) at about 200 SS Iau 11 S I \Rh&apos; A Sure&apos;. ACM ( ;■tv Su•■v‘s Vol q &amp;quot;No I, 44 t.`\1)011SIN&apos;t.&apos; inemori &apos;s NN aY Of ring the ‘..tpabiltris of hs to k.Onipare it w ith R Nlemory) and RON1 (Read Only Man- ), R is the OM er111011.11 e IllOrV d i ced 110 et CSS ue it 11,1S tlh: OrCrt) that acess al) hdd to iN ,liosen iI tandoin) by Loot:act witfi semiaL1/4 es. memory t not tuttlier dis,u,seii in this notc), .1 more limited t,s of Yok. at ecissed memo; y in w Inch only ono snailable at a ttnite RON1 is memor) whi,11 hds intorinsmon fi\ed No that ii Lsin be read from hut not \\ iitten into ( rhere i lso the progran»nable R()\1, and rhe 1 PROM cia.ahle PROM ) R011, R \M„ Ind RI \1 ate tompaied in Llit.s I o1lo ing table REM Functions RI \ L i. t\\(1luu, non, m iiiI there the huhlion whioh osier a1h inulthw roe 111 ability to write Int oint won into i&apos;n.ultiple in one operation NNith R NM, b■ contrast it N r;ossible to w iite into lust one location at a time that w Inc} identified h:t the address supplied \‘ith the .\\ rite I on he function is desLribed abo.e mil), in its mniplest and most direct lariety that In which a memor■ loLation reLtninires that It. Loritents e\actl match the presented RFN1 also recognition functions invol\ int.:. quantitative vomparkons. (1) greater than or equal -to (2) than or equal to The three ie ties of recognition ate built into the RIN hat dw are Besides being usable`dire‘lly, they pro rde the 11,,y,is for v‘itio.us additional SpectriA)c by -software, such as (I) not equal to, (2) greater than, (3) less than, (.-4) „between e., greater than lower limit less than upper Wit). Moreo■er, different In including no fun,tion, can be perrormed on different portions of RI N1 entries &amp;quot;No function&apos; means portion &apos;of the REM entry is to be there u.c of aim] understOOd 1llth the help of an Let u iiprose that we ha‘e a REM s) stem laded with a file of entries, each eon- &apos;at in of in about an inch\ is formatted, let us say, to consist of the folloNxing (1 ) 1. ast name (?.) First name and initial (or initial and middle name, Or .-..) (3) Street address (4) City (5) State-and /ip t_ode I c1 phorh number (7) OIL n patron \initial (g) \ge could then, if desired obtain of all persons ( 1) II\ log in (2) no more 35 old. (3) x‘ith annual Likomes of 000 or higher Notice that re_cog- Mtkili functions (equal to less than or equal to grc—iter than or equal to) can be periormed different portions of the (includno fuii1 tion at all for the irrele,■ant por- MODES OF OPERATION Write RecognirdMulti Write 1 Rfad ROM! RAM + REM + 1 + 45 lions of the entry) Also, since the system is peifectly flemble as to what it does with the result of the recognition operation, we may ask it to read out just a portion of (rather than th.e whole of) the qualifying entries (e g , Just the name and the telephone number) or we may alternatively specify that some inforwritten into some part of-the qualifying entries., -by means of the multiwrite operation Or, one field of the entry might contain an address to a location in a disk file where more extehsive information about the Note that functions such as those just described can be performed by ordinary computers; but they AN ould be required to perform searching operations in place of recognition, series_of individuall write instructions in place of multi-vcrite. The time of ope-ration is considerably loner, and it increases sharply as the size of the file grows By contrast, a recognize or multi-write operation can be performed throughout REM about as fast as a or write operation, and the time does increase with the size of the memory. Moreover, for elaborate specifications such as that in the above illustration, the...software can get quite complex in systems with ordinary (RAM) memories And more complex software requires not only more human time for its more memory space It is t4 course for just such reasons that some Ram have been willing to build, and othersAMMII to buy, associatne processors even almgmfry high prices that have proailed untilf■ia Masking A mask may he applied to any of the REMthe ordinary locationaccessed read and lk rite operations The mask has the function of blocking out certain bits, so that they are unaffected by the operation Any pattern of 1 s and O&apos;s can be used as a mask the bit positions for which the mask has I participate in the operation while those for which the mask has 0 are masked out. The sire of the mask is that of the computer word, has been set at one byte (eight the first REM systems being made awailable by SEM1ONICS. As an example, the mask 10000000 would cause all bit positions but the leftmost to be ignored by whatever it is used with. With the multi-write operation, mask allow data (0 or 1) to be written in the leftmost bit position leaving the other positions unchanged Such an operation might used to flag all records which have i sfi e(i a preceding recognition opeiation. Effective masking of byte-sized units is also provided for, but without the need for o‘ert masks Since the Central Processing Unit (CPU) operates upon only one computer word at a time. it simply omits consideration of those which are to be effectively masked This simple practice is followed in the aboc&apos;e illustration, in which certain entire fields (e g Last name&amp;quot;) are ignored in the recognition criteria. At smaller le‘els, down to the individual byte, it is just as easy to usidi such recognition criteria as, for example (1) last name beginning with B (all other letters disregarded), (2) telephone area code 303, (3) first digit of the zip code greater than or equal to 7 (4) last name Anderson here ? indicates e , byte be ignored) Complex Functions the capabilities described above are oalled Content-Addressable Parallel Processors&amp;quot; ((&apos;APP&apos;s) by roster Such machines are quite pow eiful By interweaving recoemition and multi-wi ite operations, with appropriate use of bit-masking, a CAPP is able achine flexibility, and programming ease well beyond the range of exen %cry large and expensive computers of the con\ entional kind. a recognelion operation, as already men- 46 Lanbe followed by a wiite opting a flag all records ineetimg the paiticular .et of lec otmitron criteria These 1-11igs may now be included in the enter la for subsequent recognition operations thus easy to include either-or conditions in the recognition euteria In the aboNe example, instead of asking for the records of ail his in krirona, one could specify Ati/ona, New iMexico, or Colorado The appropriate REM s■ stem subroutine can then multi-write a flag in all &apos;records with ArLiona, try New Mexico and multi-write in the same position of these responding records, then hike&apos; Ise for Colorado; after whieh those records with the flag are the ones satisfying the dismncti■e criterion Other complex operations made po.sible by abilities of REM include the count field of all record meeting specified recoLmition eritena, (2) bit b bit comranson of an input pattern with stored patterns, (3) locating the record lid\ ing the maximum value for a specified byte position or field (e a the field), (3) for minimum (useful, in alphabetic sorting since alphabetic order corresponds to numeric in standard 131- 11aTy codes for alphabetic characters, (5) Findbest pattern, recognition situations in there not likely to be a perfect match, by Lombining (1), (2) and (3) (6) printing out an ordered list (based on alphabetic or nuspeeined field) of all records meeting specified recognition criteria, (7) \ingInformdtion one field to another \\ ith,in all records or all reLords. meeting specified recognition criteria, (8) adding a constant o (or subtracting from) all records having pecifred properties, (9) adding two fields (or one fit)111 the other) within rec- •Irds ha\ mg specified properties; (10) Natious operations upon etc. The REM Data System besides the CPU for different In the typical system, the CPU connected to some RAM (for programs and requirmg tha REM) and peripheral devices, such as a keyboard for input, CRT printer for output, and storage tape and disk typical REM Data Sysmay be as follows TERMINAL</abstract>
<title confidence="0.64751">MAGNETIC DISK STORAGE CPU REM</title>
<author confidence="0.763829">RAM</author>
<affiliation confidence="0.36245">SES.MtONICS ©Printed in USA 1-1277 PIM</affiliation>
<address confidence="0.603847">Cd:ollorn T innul Rudd CA 94705 47</address>
<title confidence="0.881651666666667">apos;TECHNICAL NOTE Applications and Markets for REM Recognition Memory (REM)</title>
<abstract confidence="0.997387852842809">RIA1,is useful wheiL\ cr seaiLliing is required \NItil ZrclinarN computers and ordinary m)ftv■ are for inLhe&apos;xinit or other means of keeping traLk of where data is stored Its adantages he mainly in grLatl) incrcasd speed of prOLeSSMC. and in simplification of software. In addition, the multi-wine capabilit■ and the opera-tions it makes a\adable. sin_h as arithmetic, open up new is! as appl1CatiOnS hich on and system desiaiers wirbe exploring for mari ■ ears to come Since REM can &apos;do e\er\ thing that oidinary RAM can do in addition to parallel proLessits Lost is only moderat,e1N highthin that of RAM it,ina) beLome V. iceused as R M during, the next 15 prospeLt seems espechill the fact that hard w ate s.o.sts are Lon-, tq tIoLline while the Lo&apos;st of soft pikvranunt.&apos;rs Lontinues 10 in- Thus the supruivail ONt REM s:\ s.ems Lan be &apos;repaid num, times o‘er of progiarnming L ost.s The potential market_for REM is thus no less than \&amp;quot;..!St and it appears possible that RI_M will it:\ oluthe computer one tan foresee all the tt F bring after prourdinniers and urnputer scientists get a dunce to work with it so eral areas are immedialift appai-ent which a REM system has dear advant:a2es mer ordinary computers Sonic of the areas , and %.0.pi1icb_11.aied compupeople e. no filling in the \\A-11 fin the 1. Pattern Recognition basic pro.t.ss In pattern reco‘&amp;quot;nti-on Junta] represeillatictm.s-of inpCit patterns against stored representations. VEM allows such comparison to be done \Nun the colleLtion of stored operation Other useful cepabilnies REM Inch are helpful in pattern ieLognition are &apos;finding. best fit amoni.: imperfect matches, masking out irrele\ ant or relatilely unimportant bits, taking account of context restricand multiple ItAci (in v, Inch first-10 el pi o\ isional percepts tire as !d on to se..ond l l of Some -,peafic&apos;area CiptLal Lliaracter-re,,):„Inition (ptinted 1 recognition (\oie to Lomp,..tters) • Finerplint identifiLation* rd?ie anal &gt; sis Bubble anal■sis PiL turd ana! sis R,iclar an il■ ‘.0 in its test is slew, 1.1,1)4 hours to compare one rsa -Feces prrut:; ith ito*Luice base of 17,000 t.rinqral prints But when th: cthnplote, it \N IB S:an the file k% eral imnutes 48 information it-pian diffLient furii ifiafl lion re- 11 J.\ al ma; acLount fol mote than hall of all Loirputer usage today I he lieaut) ot RI M for gaining at.cess to infoimdtion is that it dlIOV■S the user simply to rime what he \\ in the reLord v Iii,h satisfies the in effeLt, that it has a\ked ii rt olditurv get ii ii d i rec I aL.,.ess to informatioit onl■ 111Cdlls of the address of the loLati,in \\liete it ‘,tored When the!, hi \ e to must either 1htoti1411 Inuit tpie lo- Lations setrall OF use a softv, are de\ iLe hash coding fl sli :oding is quite limited m its usefuln,:ss, liel,ause it It Isk.&apos;„ \kind) ;Nis into :in addregs or appt ON, mine address i iIkays used For e\ample. in a lesenation I eifl for a Lruis: line, i,cess to teLord re- UlTiCS ( I) passenger s na,ne, and ( T.) trip nUrn- If all 111(11111 Mg passe1ii2.er her his trip number he is out of luck both items of data are used for the hashing. In general. \\ here\ er ,.1,t.LeNS to ieLords might kk anted in dIfiCrent search keys at differtimes (c author or title of in hi1&apos;li&apos;!1 pJ1ft in sstem ). oid,n,tr, s, stern n WI- 111■12% for ca,..11 t\ pL„ of .cid di,tate. the ,.hoice of ,1 lO■A-,05t 11n is for li 1,i fil:s Lon be L ;loin I nal slot C one &apos;midi IiinL into i&lt;1 \I foi !Lint:\ I paiposes A on the other &apos;land, should pro\ 1,1td \kith U I1 11111c.A. Ening ill t Chit from eaeh ice,m1 ib11,i likels to bc. neLded lot rettieN al Su,li IIILICN sInL,&apos; it in RI automati,all■ 1 lie folloi,\ of , in ireas is only nalesti‘e Automatic telephone direct of ies ( I c Ini director CnIti large 01 N\ steins I iiirar LateloLls eight Ing entor ol CLI`-.1 0 ner FlicS el files Institanc, holder Ilk_ and ,redit card information Nik.‘di,a1 data systems Computet a•sistecl 1 gal Automation thosc. for it _an bk. 1 1.)\k ard such coils used to 1 CirleN e iii h n ni won \ (MI; tind trans- I oi evmiple, 1sop,./le ,hithor-(itie it &amp;quot;log be 1 ( 111 I C 11 1, 0 11 erthei authid 1 ■LIth or 1 &amp;quot;,Itt.&apos;d t.,0 fat ftir t\ko the &apos;,line ot I tf, tttfl ) ut Ink J.. , I) III:,3,(inate rn()Llel-, of lingif a user doesn kno\i, ■\ Libel the spelluistic (2) of ordinar■ ing is MI R of \II I R he in ask for \It R RI NI ,J11 be used in 0; ILL: Jiff lent \ka■s for info&apos; illation stol,iLie and rum: Nat on -of the A s,ale file Lan he stored entnel■ in RI M, but les pi ogies has no\k liven : 1 &apos;tie on th, ol thi iolileins and 1) LU I to th; se mid Hie IIUP 4,111 Of tio2 it L 0111t1011 L Jpohlit y. Ilk 11 IS 1`,1SIL to larguage at all 49 leNels (phonology, iporphology 1,t ax riantit.$), is p,.rhaps be,t iPastroted the dit.tionar look-up problem In fact it i not a at all RI &amp;quot;&apos;A One 1L only 10 the \\ ord one .1/4\ lo to its dieti,nar\ entrs. No lo.)k-..,T), in the of ear ehing, k required. The diffA. 1..nce b,1\\,.en the RI and the ordinais eon ti ct.tr,,ponds to that :en lr.,man \Nilo of (wall:Aar} of _a i.mguge i \kik) ov,ii internal \ o.abulars infotin..etion must loot, up e, er■ 1/41/4...)rd ary (a tedious process that v, ill be let ailed ithout much pleasure all ho ha\ eign langualles) LooL i ni up \ °rt.&apos;s a ch_tionar&gt; requires sear.J.i.ulk.I. to the aold. it is ,l&gt; recognized. and the rc..,o &apos;ni(on I. to the semantic and gr...inniatieal i rmation to the \Nord REM N 1;1-,,n‘Ne ideal for 10;i:ill...tie ;tile tv ,\s a simple consider a ntaetie rule \\ hich S..L■S ilidt a detk.rminer (e the • a&apos; &apos;am&amp;quot;) follo\\ ed Fs a noun lc noun phrase De No that rule ip RI N1 along rule, and at.11&apos;,.11k other (&apos;..e d (let, ( De ) an,t1 .`Co ;1(11&apos;,;) (No) Then r lied a ,iniple tv.o re, i„.1.11(in After the reLognition of the fo1/4ohis &apos;the&apos; dog .he sequenLe of ■N .(10,2‘• Dt pro\ Rled bs their dli_tionars the left-hand lion the fioin 1/41/4 Ilia the klentifieetion NP ,,in &apos;)e read Out Or onto 11„: nest le \ el of ntaetic rc&apos; )flit Ion for ,.,47(N•&apos;,„.:1K)11 arc) ankl Named. and v, innol 1 pe to fi sec all the possibilities at pi esent One has to 1 p...n..i\e the 1.1e is in human life to r Lint of the of potential appli,Atons prodtildr umerge plo,Itk1/4.1 more and led line atil(),nailan ,iS an area (.,.0% CTs the L,...ten.r.i! pi o. e,ses of lansp„i 1(2.: untle:ct andand Toth...Lon. Most ices ill e „ap_dbilit,es in both ,f,eas to \ For 3 riust in the •Jur,e and produccapabilit in the target The list of de icc Incorporating one or both of ti.ese merels Tramlot Vi; .res Cr . cc he ! let Fr. s edia ne ()relator IThirs File Vole Crratd rev, tur to the R I ditors fo4 (_rdin rs I g1h a, a pro- 4 S.rnple Prc.;,srssing ledd r ii nstit. &apos;\uto,n,ition the nt ,. 1/4 „ns thft le\ ts (Ton the i 1.. .1, an.■ ■)1 tr. ((a.: of&apos;1/41/4i .1 I :ligthe le\ t, al&amp;quot;; vIritt....n in \ \\ 1;1: )7(.11&apos;0 e \I&apos; lists) for ;no&apos; e itt.‘ris t:ian Just v. olds also core 50 under this 1Ljc1Ing, vimples of more comwieries mi.-111,10 jin CO-Ot. 4111e1ILCS Or IA ONTS Ith LI t it It&apos;d or intent:lung \\ or ters, anJ parts of ords (i e d1ll11dr diameand they might also Boolean operators Such 1&apos;.1hug also under the licadine of In Rev, ludi is farthL r e. 5. Sciernific Research i cffe,ti e t pe of research in\ 01\ es lool.ine for in large quantities of data Some fields in \\ inch this pe of S important ith some illustrations to the kind of to v, Inch REM suited. inguistics Corrlations of ill\ en phonologh_al oper,,ties with i2eomphic areas Col relations among different features of s\ ntactic structure Anthropolop SoLiolocy. Demograph Do societies or communities \\Inch ha\ e properties A, B, &amp; C also hie property D or IL hi Correlations arnon:z specified oil ..&apos;c tiof•,‘ mplomns meilKal histories Ii. iuiitent II et .0llo11116. PI &amp;quot;ILS tc 6 Computer Science lo the oipuIr 5..1t.1111si, 110 Is ill\ oh ed in \ dopuIg nev, .,imputer at tons, prolanyu and 1:1_11 ofpotentials that c 1 CIII ordy hc dimi.■ un the that can be \ pt c&apos; lit, besides those ti abo\ ,i1 for \\ Owl.: for sti,h li&apos;lM1&amp;quot;.!0‘. as and NP1. \\ Inch are probabl bet tLi sidled to N1 stcms than flies- .&apos;re to ordinal \ornputers Further that can only be are 1it,e1,■, to cnit.i:le \\ hen ictists J ant_e to &apos;mph...mons arithmetic. parallel mo\ orient of data and operations upon programs themseh es jut upon data) and Modelling Luca O\ crlaps \kith the preLeding 1. kutomation, but is distinct enough i to \\ arrant its cmn headine. here. The two disiplmnes inosi in\ 01\ ed ArtifiLial Intelligecue and Cogniti\ \ 11 Clic its t. ss.ntial rec- N1 steiTi is like the hi p are It I.11e1 to 1,11 and 11\ e 1ia\ e along to no\\ computer the 1\e Its</abstract>
<author confidence="0.4169375">The Car Minnel Acid</author>
<affiliation confidence="0.352375">CA</affiliation>
<address confidence="0.356658">41`;) U18 7100</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>ing is MI R of \II I R he in ask for \It R RI NI ,J11 be used in 0; ILL: Jiff lent \ka■s for info&apos; illation stol,iLie and rum: Nat depending on OW si.ie -of the tile, A sinalJ s,ale file Lan he stored entnel■ in RI M, but coin-p,it; \■111C11 it les Co-&apos;,,ideiable pi ogies has no\k liven : 1 &apos;tie on th, ol thi iolileins and ide1/4. 1) 1ii LU I to th; se mid</title>
<booktitle>Hie IIUP 4,111 Of tio2 it L 0111t1011 L Jpohlit y. \\ Ilk 11 IS 1`,1SIL</booktitle>
<marker></marker>
<rawString>ing is MI R of \II I R he in ask for \It R RI NI ,J11 be used in 0; ILL: Jiff lent \ka■s for info&apos; illation stol,iLie and rum: Nat depending on OW si.ie -of the tile, A sinalJ s,ale file Lan he stored entnel■ in RI M, but coin-p,it; \■111C11 it les Co-&apos;,,ideiable pi ogies has no\k liven : 1 &apos;tie on th, ol thi iolileins and ide1/4. 1) 1ii LU I to th; se mid Hie IIUP 4,111 Of tio2 it L 0111t1011 L Jpohlit y. \\ Ilk 11 IS 1`,1SIL to larguage pio,;,!L,,,ing at all r„,1,11,ne,, plo,Itk1/4.1 \\.,tli more and hiore soplii,tie, led line 1..■:‘,1vMic atil(),nailan ,iS an area (.,.0% CTs the t\kr) L,...ten.r.i! pi o. e,ses of lansp„i 1(2.: untle:ct andInc- and Toth...Lon. Most lanzli.ctP,inlz dc&amp;quot;\ ices Vs ill 11,3\ e „ap_dbilit,es in both ,f,eas to \ For 3 tran-1.iting 1.1,ine riust hae capability in the •Jur,e and production capabilit in the target 1,1:-..-uage The follov,ing list of po,-1.1)1e de icc Incorporating one or both of ti.ese merels Tramlot Vi; .res Cr . cc he ! let Fr. s edia ne ()relator V0iee-(1,-.„.za1ed IThirs TI L r1iuin 1s</rawString>
</citation>
<citation valid="false">
<title>File Vole Crratd rev, er \alutpe&apos; tur R&apos;eac..-ig to the Mind R riters 1-\I I ditors Co.-Tilers fo4 (_rdin rs I g1h a, a pro4 S.rnple Prc.;,srssing his, ledd r lio,n ii nstit. &apos;\uto,n,ition in t)..it the ri)-1 nt ,. 1/4 „ns aHi I&apos; to Lin.1,1,.JaJ thft le\ ts itoperaie,, (Ton ,tlier the i 1.. .2,st 1.10 , .1, ;,..,,1/41/4111,,,i1 an.■ 1.v■ ■)1 11, ,11 tr. ((a.: of&apos;1/41/4i .1 I :ligri.s! the le\ t, al&amp;quot;; vIritt....n in I \ naples 0,f ,1 N.,2 v.1°,1,_11 p- \\ t, 1;1: )7(.11&apos;0 e \I&apos; lists) for ;no&apos; e itt.‘ris t:ian Just v. olds also core under this 1Ljc1Ing, vimples of more comple\</title>
<booktitle>wieries mi.-111,10 1,011)1 jij1 jin of‘\ ordc CO-Ot. 4111e1ILCS Or IA ONTS Ith LI t</booktitle>
<marker></marker>
<rawString>File Vole Crratd rev, er \alutpe&apos; tur R&apos;eac..-ig to the Mind R riters 1-\I I ditors Co.-Tilers fo4 (_rdin rs I g1h a, a pro4 S.rnple Prc.;,srssing his, ledd r lio,n ii nstit. &apos;\uto,n,ition in t)..it the ri)-1 nt ,. 1/4 „ns aHi I&apos; to Lin.1,1,.JaJ thft le\ ts itoperaie,, (Ton ,tlier the i 1.. .2,st 1.10 , .1, ;,..,,1/41/4111,,,i1 an.■ 1.v■ ■)1 11, ,11 tr. ((a.: of&apos;1/41/4i .1 I :ligri.s! the le\ t, al&amp;quot;; vIritt....n in I \ naples 0,f ,1 N.,2 v.1°,1,_11 p- \\ t, 1;1: )7(.11&apos;0 e \I&apos; lists) for ;no&apos; e itt.‘ris t:ian Just v. olds also core under this 1Ljc1Ing, vimples of more comple\ wieries mi.-111,10 1,011)1 jij1 jin of‘\ ordc CO-Ot. 4111e1ILCS Or IA ONTS Ith LI t it It&apos;d liflUlU number or intent:lung \\ or Aaraeters, anJ parts of ords (i e d1ll11dr diameter sequt.iik.-es). and they might also in hide Boolean operators Such 1&apos;.1- hug also Lonics under the licadine of In Retrie\ v, ludi is farthL r lrealLd obo\ e. 5. Sciernific Research RI \1 i CI} cffe,ti e inany t pe of research that in\ 01\ es lool.ine for %. miLLitions in large quantities of data Some fields in \\ inch this 1.\ pe of Ill\ e‘,i1,&apos;,111011 S an important part \\ ith some illustrations to cu,2gest the kind of inquu;s to v, Inch REM isNl ell suited. are inguistics</rawString>
</citation>
<citation valid="false">
<title>Corrlations of ill\ en phonologh_al oper,,ties with i2eomphic areas Col relations among different features of s\ ntactic structure</title>
<marker></marker>
<rawString>Corrlations of ill\ en phonologh_al oper,,ties with i2eomphic areas Col relations among different features of s\ ntactic structure</rawString>
</citation>
<citation valid="false">
<authors>
<author>Anthropolop SoLiolocy</author>
</authors>
<title>Demograph Do societies or communities \\Inch ha\ e properties</title>
<journal>A, B, &amp; C</journal>
<note>also hie property D or</note>
<marker>SoLiolocy, </marker>
<rawString>Anthropolop SoLiolocy. Demograph Do societies or communities \\Inch ha\ e properties A, B, &amp; C also hie property D or</rawString>
</citation>
<citation valid="false">
<authors>
<author>IL me</author>
</authors>
<title>IL hi Correlations arnon:z specified oil ..&apos;c tiof•,‘ mplomns meilKal histories pes of Ii. iuiitent II 0111&amp;quot;&apos;&amp;quot;R_ntd1 fa,i Ors et .0llo11116.</title>
<marker>me, </marker>
<rawString>IL me, IL hi Correlations arnon:z specified oil ..&apos;c tiof•,‘ mplomns meilKal histories pes of Ii. iuiitent II 0111&amp;quot;&apos;&amp;quot;R_ntd1 fa,i Ors et .0llo11116.</rawString>
</citation>
<citation valid="false">
<authors>
<author>PI</author>
</authors>
<title>ILS tc 1)t.&amp;quot;,t dil,11)1e 1\e d-pite Its Ii11113-11011&apos;-,</title>
<marker>PI, </marker>
<rawString>PI &amp;quot;ILS tc 1)t.&amp;quot;,t dil,11)1e 1\e d-pite Its Ii11113-11011&apos;-,</rawString>
</citation>
<citation valid="false">
<title>SEMIONICS The Car ernont Minnel Acid B(-2r !,1\/,</title>
<journal>CA</journal>
<volume>04705</volume>
<pages>7100</pages>
<marker></marker>
<rawString>SEMIONICS The Car ernont Minnel Acid B(-2r !,1\/, CA 04705 41`;) U18 7100</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>