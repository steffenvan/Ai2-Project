<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.90676">
The FINITE STRING Newsletter Abstracts of Current Literature
</note>
<title confidence="0.841878666666667">
Abstracts of Current Literature
Knowledge Representation and Retrieval for
Natural Language Processing
</title>
<author confidence="0.585892">
A.M. Frisch and J.F. Allen
</author>
<affiliation confidence="0.836466">
Computer Science Department
University of Rochester
</affiliation>
<sectionHeader confidence="0.127377" genericHeader="abstract">
Rochester, NY 14627
</sectionHeader>
<subsectionHeader confidence="0.340991">
Technical Report TR104, December 1982, 50 pages.
</subsectionHeader>
<bodyText confidence="0.999880181818182">
We are building a computer system called ARGOT that
acts as a computer operator conversing with a comput-
er user. Since performance in this domain requires
ARGOT to have efficient access to a large body of
diverse knowledge, a major part of our research effort
has been focused on issues of knowledge representa-
tion and retrieval. This paper describes ARGOT&apos;s
representation language, the retriever used to access a
knowledge base of sentences of the language, and how
their design has been influenced by the task domain
and system organization.
</bodyText>
<subsectionHeader confidence="0.665551">
A Connectionist Scheme for Modelling Word
Sense Disambiguation
</subsectionHeader>
<author confidence="0.585127">
G.W. Cottrell and S.I. Small
</author>
<affiliation confidence="0.8748675">
Computer Science Department
University of Rochester
</affiliation>
<address confidence="0.303671">
Rochester, NY 14627
</address>
<subsubsectionHeader confidence="0.8152455">
Technical Report TR122.
Cognition and Brain Theory 6, 1 (1983): 89-120.
</subsubsectionHeader>
<bodyText confidence="0.999945952380952">
This paper advocates the interdisciplinary development
of a computational theory of human language compre-
hension and proposes a collection of initial constraints
from which to start on such an enterprise. The const-
raints come from several disparate sources, including:
(1) human physiology and language malfunctions; (2)
human language behaviors under different processing
conditions; (3) computational architectures for lan-
guage comprehension; and (4) human and computer
visual understanding. Our modeling effort thus em-
ploys an architecture significantly different from the
typical computer and closer to that of the human
brain. We use a particular spreading activation or
active semantic network scheme, called connection ism,
which entails a massive number of appropriately con-
nected computing units that communicate through
weighted levels of excitation and inhibition. This pa-
per surveys a number of fundamental language com-
prehension issues from the new perspective, and pres-
ents some simulation results of a parsing model based
on these considerations.
</bodyText>
<note confidence="0.3585485">
The HORNE Reasoning System
J.F. Allen, M. Giuliano, and A.M. Frisch
</note>
<affiliation confidence="0.817828333333333">
Computer Science Department
University of Rochester
Rochester, NY 14627
</affiliation>
<subsubsectionHeader confidence="0.564254">
Technical Report TR126, October 1983, â€” 60 pages.
</subsubsectionHeader>
<bodyText confidence="0.999189944444444">
HORNE is a programming system that offers a set of
tools for building automated reasoning systems. It
offers three major modes of inference: (1) a horn
clause theorem prover (a backwards chaining mecha-
nism); (2) a forward chaining mechanism; and (3) a
constraint posting mechanism for restricting the range
of variables. All three modes use a common repre-
sentation of facts, namely horn clauses with universal-
ly quantified variables, and use the unification algor-
ithm. In addition, they all share the following addi-
tional specialized reasoning capabilities: (1) variables
may be typed with a fairly general type theory that
allows intersecting types; (2) full reasoning about
equality between ground terms, and limited equality
reasoning for quantified terms; and (3) escapes into
LISP for use as necessary. This paper contains an
introduction to each of these facilities, and the HORN
User&apos;s manual.
</bodyText>
<sectionHeader confidence="0.52333" genericHeader="categories and subject descriptors">
Discourse and Problem Solving
</sectionHeader>
<subsectionHeader confidence="0.248623">
D. Litman
Computer Science Department
University of Rochester
Rochester, NY 14627
</subsectionHeader>
<bodyText confidence="0.931649458333333">
Technical Report TR130, July 1983, 50 pages.
Also, Report No. 5338, Bolt Beranek and Newman Inc.
This report proposes a plan-based natural language
system that incorporates knowledge of both plan and
discourse structure of task-oriented dialogues. An
initial representation of communicative (discourse)
actions is discussed; in particular, how to incorporate
knowledge of legal moves as action effects rather than
grammars. The subtle differences implicit in various
surface realizations are also examined, as well as the
structure of these communicative actions in actual
dialogues. It is suggested that both local and global
discourse structures are necessary (although analysis
of the latter has been emphasized here). It is also
suggested that planning models need to be extended to
include two agent plan execution. Finally, a model of
the goal recognition process is presented. Communi-
cative and task knowledge work in parallel, one source
dynamically taking control over the other and reducing
the search space, depending on the kind of discourse
(task-oriented, conversational, etc.). Communicative
recognition is hypothesized to be simple, using the
knowledge provided by the analysis of surface phe-
nomena and task plan recognition.
</bodyText>
<subsectionHeader confidence="0.6471155">
Three Strategic Goals in Conversational
Openings
</subsectionHeader>
<note confidence="0.752999142857143">
Michael Rosner
ISSCO
54 Route des Acacias
1227 Geneva, Switzerland
Working Paper 46, 1981.
40 American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983
The FINITE STRING Newsletter Abstracts of Current Literature
</note>
<bodyText confidence="0.999807222222222">
This paper tries to explain a short transcript of a con-
versational opening as completely as possible within
the framework that takes conversational behaviour as
defined by a sophisticated planning mechanism. It is
argued that a crucial role is played by the satisfaction,
by each participant, of three strategic goals relating to
attention, identification, and greeting. Additional
tactics for gaining information are also described as
necessary to account for this transcript.
</bodyText>
<figure confidence="0.287859285714286">
A Poor Man&apos;s Flavor System -- Part 1
F. diPrimio and Th. Christaller
ISSCO
54 Route des Acacias
1227 Geneva, Switzerland
Working Paper 47, 1983.
(Address requests to Michael Rosner at ISSCO.)
</figure>
<bodyText confidence="0.999581">
This paper is the result of an attempt to understand
&apos;flavors&apos;, the object-oriented programming system in
Lispmachine Lisp. The authors argue that the basic
principles of such systems are not easily accessible to
the programming public, because papers on the subject
rarely discuss the concrete details. Accordingly, the
authors&apos; approach is pedagogical, and takes the form
of a description of the evolution of their own flavor
system. An appendix contains programming examples
that are sufficiently detailed to enable an average LISP
programmer to build a flavor system, and experiment
with the essential concepts of object-oriented pro-
gramming.
</bodyText>
<figure confidence="0.580913571428571">
A Government-and-Binding Parser for French
E. Wehrli
ISSCO
54 Route des Acacias
1227 Geneva, Switzerland
Working Paper 48, forthcoming.
(Address requests to Michael Rosner at ISSCO.)
</figure>
<subsectionHeader confidence="0.482128">
Computational Explication of Intensionality
</subsectionHeader>
<affiliation confidence="0.735677">
J.S. Bien
Institute of Informatics
University of Warsaw
</affiliation>
<construct confidence="0.841721">
Report 107, Janusz S. Bien (Ed.), Papers in Computational
Linguistics I, paper 1.
</construct>
<bodyText confidence="0.9999418">
An obvious requirement for a language understanding
system of practical use is that the system tells &amp;quot;the
truth and only the truth&amp;quot;, and so called
&amp;quot;intensionality&amp;quot; of natural languages is one of the
main obstacles on the way to formulate a strict defini-
tion of truth for natural languages. Although it may
be possible to account for it using the apparatus of
formal logic, in the present state of art it seems more
useful to describe this property of natural language in
the terms of computer science. The paper represents
the problem of intensionality, shows its relation to
some aspects of programming languages and outlines
the way in which the intensionality is to be accounted
for in the &amp;quot;multiple environments model of natural
language&amp;quot; being developed by the author.
</bodyText>
<note confidence="0.679845">
Parsing Free Word Order Languages in Prolog
</note>
<author confidence="0.768823">
J.S. Bien, K. Laus-Maczynska, S. Szpakowicz
</author>
<affiliation confidence="0.984483">
Institute of Informatics
University of Warsaw
</affiliation>
<construct confidence="0.744665">
Report 107, Janusz S. Bien (Ed.), Papers in Computational
Linguistics I. paper 2.
</construct>
<bodyText confidence="0.999931666666667">
The Prolog programming language allows the user to
write powerful parsers in the form of metamorphosis
grammars. However, the metamorphosis grammars, as
defined by Colmerauer, have to specify strictly the
order of terminal and nonterminal symbols. A modifi-
cation of Prolog has been implemented that allows
&amp;quot;floating terminals&amp;quot; to be included in a metamorphosis
grammar together with some information enabling one
to control the search for such a terminal in the unpro-
cessed part of the input. The modification is illustrat-
ed by several examples from the Polish language, and
some open questions are discussed.
</bodyText>
<subsectionHeader confidence="0.8395075">
The Partial Analysis of a Sentence in Montague
Grammar
</subsectionHeader>
<author confidence="0.761026">
W. Lukaszewicz
</author>
<affiliation confidence="0.9371215">
Institute of Informatics
University of Warsaw
</affiliation>
<construct confidence="0.7945505">
Report 107, Janusz S. Bien (Ed.), Papers in Computational
Linguistics I, paper 3.
</construct>
<bodyText confidence="0.9459992">
Montague translates a simple fragment of English into
tensed intensional logic, an extension of the typed
A-calculus. In the following note, we use notational
conventions of Montague.
Consider the English sentence,
</bodyText>
<listItem confidence="0.6406545">
(1) John asserts that Mary asserts that a man such
that he runs walks.
</listItem>
<bodyText confidence="0.999865333333333">
We shall be interested in an analysis of (1) with re-
spect to the nominal phrases &apos;a man such that he runs&apos;.
This phrase may be introduced on different syntactical
levels leading to different derivations of (1). Three of
these derivations are displayed in the enclosed dia-
grams.
</bodyText>
<subsectionHeader confidence="0.7633055">
Toward Computational Description of Written
Polish
</subsectionHeader>
<affiliation confidence="0.791622">
J.S. Bien, S. Szpakowicz
Institute of Informatics
University of Warsaw
</affiliation>
<construct confidence="0.805347">
Report 110, Janusz S. Bien (Ed.), Papers in Computational
Linguistics II, paper 1.
</construct>
<bodyText confidence="0.96492625">
We present briefly the activity of the Warsaw Univer-
sity computational linguistics team. The team is an
informal group that consolidates around a seminar at
the Institute of Informatics, co-ordinated by Prof.
Zygmunt Saloni. The group adheres to a &amp;quot;bootstrap-
American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 41
The FINITE STRING Newsletter Abstracts of Current Literature
ping methodology&amp;quot;: we focus on developing surface
linguistic descriptions that should allow us to create
efficient tools for low-level processing of natural lan-
guage texts, in hope that it will pay when more sophis-
ticated problems are attacked.
</bodyText>
<subsectionHeader confidence="0.9057998">
A Simple Dialogue in Polish: Interactive Railway
Guide
S. Szpakowicz, M. Swidzinski
Institute of Informatics
University of Warsaw
</subsectionHeader>
<construct confidence="0.7719385">
Report 110, Janusz S. Bien (Ed.), Papers in Computational
Linguistics II, paper 2.
</construct>
<bodyText confidence="0.999577647058824">
In this paper we present the results of an experiment
in computational linguistics: the design and implemen-
tation of an interactive train timetable information
system. The experiment was completed in early 1979.
It is a rather simple case study in dialogue system con-
struction. Our system can hardly be compared with
such sophisticated systems as GUS or HAMP-RPM.
However, we do not pretend to compete with them,
because our system is the very first program for con-
versing in Polish that performs full analysis of the
input data. Although the system cannot handle the
anaphoric references, it covers a variety of types of
syntactic structures occurring in typical timetable dia-
logues in Polish. It is worth emphasizing that highly
inflected languages such as Polish provide a number of
specific problems to be solved, such as inflection, con-
gruence, free word order, etc.
</bodyText>
<subsectionHeader confidence="0.79472775">
On Surface-Syntactic Analysis of Polish
J.S. Bien, S. Szpakowicz
Institute of Informatics
University of Warsaw
</subsectionHeader>
<construct confidence="0.6878835">
Report 110, Janusz S. Bien (Ed.), Papers in Computational
Linguistics II, paper 3.
</construct>
<bodyText confidence="0.999398153846154">
By surface syntax we mean such a structural descrip-
tion of a sentence that is sufficient to disambiguate
practically all purely morphological ambiguities con-
cerning the words that constitute the sentence. After
describing briefly the. operations prerequisite to the
syntactic analysis, we present the existing parsers of
Polish. Although the parsers are based on sound lin-
guistic principles and produce surface-syntactic struc-
tures of quite complicated sentences, they do not cap-
ture many correct word order variations. We show a
few linguistic phenomena related to word order that
present serious difficulties in designing a more general
parser of Polish.
</bodyText>
<subsectionHeader confidence="0.9932145">
Toward a Parsing Method for Free Word Order
Languages
</subsectionHeader>
<affiliation confidence="0.626448666666667">
J.S. Bien, S. Szpakowicz
Institute of Informatics
University of Warsaw
</affiliation>
<construct confidence="0.87095">
Report 110, Janusz S. Bien (Ed.), Papers in Computational
Linguistics II, paper 4.
</construct>
<bodyText confidence="0.999943470588235">
Formal syntactic descriptions have usually been based
either on the immediate-constituents or on the depen-
dency philosophy. Neither of them seems directly
applicable to free word order languages. We try to
take a fresh start and reanalyse the basic notions of
syntax and parsing. Certain relations between sen-
tence components help disambiguate the morphological
properties of individual words without resorting to
their meanings; these relations constitute the level of
syntax. By the syntactic structure of a sentence we
understand some explicit representation of all the syn-
tactic relations between its components. Parsing is a
process of establishing all syntactic structures of a
given text. We adopt Marcus&apos;s wait-and-see strategy
as a general hint and our own IC-based syntactic de-
scription of Polish as a starting point in our future
work on a parser for Polish.
</bodyText>
<subsectionHeader confidence="0.995237">
Constraining a Deterministic Parser
</subsectionHeader>
<bodyText confidence="0.769516">
J. Bachenko, D. Hindle, and E. Fitzpatrick
</bodyText>
<subsectionHeader confidence="0.9071126">
Computer Science and Systems Branch
Information Technology Division
Naval Research Laboratory
Washington, DC 20375
Proceedings of AAAI, August 1983: 8-11.
</subsectionHeader>
<bodyText confidence="0.99994675">
At the Naval Research Laboratory, we are building a
deterministic parser, based on principles proposed by
Marcus, that can be used in interpreting military mes-
sage narrative. A central goal of our project is to
make the parser useful for real-time applications by
constraining the parser&apos;s actions and so enhancing its
efficiency. In this paper, we propose that a parser can
determine the correct structures for English without
looking past the &amp;quot;left corner&amp;quot; of a constituent, i.e., the
leftmost element of the constituent along with its lexi-
cal category (e.g., N, V, Adj). We show that this Left
Corner Constraint, which has been built into our par-
ser, leads quite naturally to a description of verb com-
plements in English that is consistent with the findings
of recent linguistic theory, in particular, Chomsky&apos;s
government and binding (GB) framework.
</bodyText>
<subsectionHeader confidence="0.938187285714286">
Tracking User Goals in an Information-Seeking
Environment
Sandra Carberry
Department of Computer Science
University of Delaware
Newark, DE 19711
Proceedings of AAAI, August 1983: 59-63.
</subsectionHeader>
<bodyText confidence="0.999986">
This paper presents a model for hypothesizing and
tracking the changing task-level goals of a speaker
during the course of an information-seeking dialogue.
It allows a complex set of domain-dependent plans,
forming a hierarchical structure of component goals
and actions. Our model builds the user&apos;s plan as the
</bodyText>
<page confidence="0.83387">
42 American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983
</page>
<note confidence="0.417856">
The FINITE STRING Newsletter Abstracts of Current Literature
</note>
<bodyText confidence="0.9998645">
dialogue progresses, maintains both a local and a glob-
al plan context, and differentiates between past goals
and goals currently pursued by the user. This research
is part of a project to develop a robust natural lan-
guage interface. If an utterance cannot be interpreted
normally or a response cannot be generated due to
pragmatic overshoot, the strong expectations about the
utterance provided by our context model can be used
as an aid in processing the input and producing useful
responses.
</bodyText>
<subsectionHeader confidence="0.919245">
QE-III: A Formal Approach to Natural Language
Querying
James Clifford
Graduate School of Business Administration
New York University
New York, NY
Proceedings of AAAI, August 1983: 79-83.
</subsectionHeader>
<bodyText confidence="0.999627875">
In this paper we present an overview of QE-III, a lan-
guage designed for natural-language querying of his-
torical data bases. QE-III is defined formally with a
Montague Grammar, extended to provide an interpre-
tation for questions and temporal reference. Moreo-
ver, in addition to the traditional syntactic and seman-
tic components, a formal pragmatic interpretation for
the sentences of QE-III is also defined.
</bodyText>
<subsectionHeader confidence="0.821489571428571">
Repairing Miscommunication: Relaxation in
Reference
Bradley A. Goodman
Bolt Beranek and Newman Inc.
10 Moulton Street
Cambridge, MA 02238
Proceedings of AAAI, August 1983: 134-138.
</subsectionHeader>
<bodyText confidence="0.999982411764706">
In natural language interactions, a speaker and listener
cannot be assured to have the same beliefs, contexts,
backgrounds or goals. This leads to difficulties and
mistakes when a listener tries to interpret a speaker&apos;s
utterance. One principal source of trouble is the de-
scription constructed by the speaker to refer to an
actual object in the world. The description can be
imprecise, confused, ambiguous or overly specific; it
might be interpreted under the wrong context. This
paper explores the problem of resolving such reference
failures in the context of the task of assembling a toy
water pump. We are using actual protocols to drive
the design of a program that plays the part of an ap-
prentice who must interpret the instructions of an
expert and carry them out. A primary means for the
apprentice to repair such descriptions is by relaxing
parts of the description.
</bodyText>
<subsectionHeader confidence="0.9189406">
Phonotactic and Lexical Constraints in Speech
Recognition
Daniel P. Huttenlocher and Victor W. Zue
Department of Electrical Engineering and Computer Science
Massachusetts Institute of Technology
</subsectionHeader>
<bodyText confidence="0.529662">
Cambridge, MA 02139
</bodyText>
<subsectionHeader confidence="0.509223">
Proceedings of AAAI, August 1983: 172-176.
</subsectionHeader>
<bodyText confidence="0.999876333333333">
We demonstrate a method for partitioning a large lexi-
con into small equivalence classes, based on sequential
phonetic and prosodic constraints. The representation
is attractive for speech recognition systems because it
allows all but a small number of word candidates to be
excluded, using only gross phonetic and prosodic in-
formation. The approach is a robust one in that the
representation is relatively insensitive to phonetic vari-
ability and recognition error.
</bodyText>
<sectionHeader confidence="0.920762" genericHeader="method">
RESEARCHER: An Overview
</sectionHeader>
<subsectionHeader confidence="0.8954878">
Michael Lebowitz
Department of Computer Science
Columbia University
New York, NY 10027
Proceedings of AAAI, August 1983: 232-235.
</subsectionHeader>
<bodyText confidence="0.999940933333333">
Described in this paper is a computer system,
RESEARCHER, being developed at Columbia that
reads natural language text in the form of patent ab-
stracts and creates a permanent long-term memory
based on concepts generalized from these texts, form-
ing an intelligent information system. This paper is
intended to give an overview of RESEARCHER. We
will describe briefly the four main areas dealt with in
the design of RESEARCHER: (1) knowledge represen-
tation, where a canonical scheme for representing
physical objects has been developed; (2) memory-
based text processing; (3) generalization and
generalization-based memory organization that treats
concept formation as an integral part of understand-
ing, and (4) generalization-based question answering.
</bodyText>
<subsectionHeader confidence="0.928617571428571">
An Overview of the Penman Text Generation
System
William C. Mann
USC Information Sciences Institute
4676 Admiralty Way
Marina del Rey, CA 90291
Proceedings of AAAI, August 1983: 261-265.
</subsectionHeader>
<bodyText confidence="0.995596575757576">
The problem of programming computers to produce
natural language explanations and other texts on de-
mand is an active research area in artificial intelli-
gence. In the past, research systems designed for this
purpose have been limited by the weakness of their
linguistic bases, especially their grammars, and their
techniques often cannot be transferred to new knowl-
edge domains.
A new text generation system, Penman, is designed
to overcome these problems and produce fluent multi-
paragraph text in English in response to a goal pre-
sented to the system. Penman consists of four major
modules: a knowledge acquisition module that can per-
form domain-specific searches for knowledge relevant
American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 43
The FINITE STRING Newsletter Abstracts of Current Literature
to a given communication goal; a text planning module
that can organize the relevant information, decide
what portion to present, and decide how to lead the
reader&apos;s attention and knowledge through the content;
a sentence generation module based on a large systemic
grammar of English; and an evaluation and
plan-perturbation module that revises text plans based
on evaluation of text produced.
Development of Penman has included implementa-
tion of the largest systemic grammar of English in a
single notation. A new semantic notation has been
added to the systemic framework, and the semantics of
nearly the entire grammar has been defined. The se-
mantics is designed to be independent of the system&apos;s
knowledge notation, so that it is usable with widely
differing knowledge representations, including both
frame-based and predicate-calculus-based approaches.
</bodyText>
<subsectionHeader confidence="0.824518142857143">
Recursion in Text and Its Use in Language
Generation
Kathleen R. McKeown
Department of Computer Science
Columbia University
New York, NY 10027
Proceedings of AAAI, August 1983: 270-273.
</subsectionHeader>
<bodyText confidence="0.999916375">
In this paper I show how textual structure is recursive
in nature; that is, the same rhetorical strategies that
are available for constructing the text&apos;s macrostructure
are available for constructing its sub-sequences as
well, resulting in a hierarchically structured text. The
recursive formalism presented can be used by a gener-
ation system to vary the amount of detail it presents
for the same discourse goal in different situations.
</bodyText>
<subsectionHeader confidence="0.821299625">
Reasons for Beliefs in Understanding: Applica-
tions of Non-Monotonic Dependencies to Story
Processing
Paul O&apos;Rorke
Coordinated Science Laboratory
University of Illinois at Urbana-Champaign
Urbana, IL 61801
Proceedings of AAAI, August 1983: 306-309.
</subsectionHeader>
<bodyText confidence="0.9999928">
Many of the inferences and decisions which contribute
to understanding involve fallible assumptions. When
these assumptions are undermined, computational
models of comprehension should respond rationally.
This paper crossbreeds Al research on problem solving
and understanding to produce a hybrid model
(&apos;reasoned understanding&apos;). In particular, the paper
shows how non-monotonic dependencies enable a
schema-based story processor to adjust to new infor-
mation requiring the retraction of assumptions.
</bodyText>
<subsectionHeader confidence="0.9561232">
Inference-Driven Semantic Analysis
Martha Stone Palmer
SDC - A Burroughs Company
and University of Pennsylvania
Philadelphia, PA
</subsectionHeader>
<subsubsectionHeader confidence="0.446321">
Proceedings of AAAI, August 1983: 310-313.
</subsubsectionHeader>
<bodyText confidence="0.999989529411765">
A primary problem in the area of natural language
processing is the problem of semantic analysis. This
involves both formalizing the general and domain-
dependent semantic information relevant to the task
involved, and developing a uniform method for access
to that information. Natural language interfaces are
generally also required to have access to the syntactic
analysis of a sentence as well as knowledge of the
prior discourse to produce a semantic representation
adequate for the task. This paper briefly describes
previous approaches to semantic analysis, specifically
those approaches which can be described as using
templates, and corresponding multiple levels of repre-
sentation. It then presents an alternative to the temp-
late approach, inference-driven semantic analysis,
which can perform the same tasks but without needing
as many levels of representation.
</bodyText>
<subsectionHeader confidence="0.7191484">
Interactive Script Instantiation
Michael J. Pazzani
The MITRE Corporation
Bedford, MA 01730
Proceedings of AAAI, August 1983: 320-326.
</subsectionHeader>
<bodyText confidence="0.99993023076923">
The KNOBS (Engelman 1980) planning system is an
experimental expert system that assists a user by in-
stantiating a stereotypical solution to his problem.
SNUKA, the natural language understanding compo-
nent of KNOBS, can engage in a dialog with the user
to allow him to enter components of a plan or to ask
questions about the contents of a data base that de-
scribes the planning world. User input is processed
with respect to several knowledge sources including
word definitions; scripts that describe the relationships
among the scenes of the problem solution; and four
production system rule bases that determine the proper
data base access for answering questions, infer missing
meaning elements, describe how to conduct a conver-
sation, and monitor the topic of the conversation.
SNUKA differs from GUS (Bobrow 1977), a dialog
system similar to SNUKA in its goals, in its use of a
script to guide the conversation, interpret indirect an-
swers to questions, determine the referents to nomi-
nals, perform inferences to answer the user&apos;s ques-
tions, and decide upon the order of asking questions of
the user to maintain a coherent conversation. SNUKA
differs from other script-based language understanders
such as SAM (Cullingford 1978) and FRUMP (DeJong
1979) in its role as a conversational participant instead
of a story understander.
</bodyText>
<subsectionHeader confidence="0.437549">
Deterministic and Bottom-Up Parsing in Prolog
Edward P. Stabler, Jr.
</subsectionHeader>
<bodyText confidence="0.280762">
44 American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983
The FINITE STRING Newsletter Abstracts of Current Literature
</bodyText>
<subsectionHeader confidence="0.694894">
University of Western Ontario
London, Canada
</subsectionHeader>
<subsubsectionHeader confidence="0.416302">
Proceedings of AAAI, August 1983: 383-386.
</subsubsectionHeader>
<bodyText confidence="0.999969692307692">
It is well known that top-down backtracking context
free parsers are easy to write in Prolog, and that these
parsers can be extended to give them the power of
ATN&apos;s. This report shows that a number of other fa-
miliar parser designs can be very naturally implement-
ed in Prolog. The top-down parsers can easily be
constrained to do deterministic parsing of LL(k) lan-
guages. Bottom-up backtrack parsers can also be ele-
gantly implemented and similarly constrained to do
deterministic LR(k) parsing. Very natural extensions
of these LF(k) parser designs suffice for deterministic
parsing of natural languages of the sort carried out by
the Marcus (1980) parser.
</bodyText>
<sectionHeader confidence="0.6388475" genericHeader="method">
MCHART: A Flexible, Modular Chart Parsing
System
</sectionHeader>
<subsectionHeader confidence="0.949839166666667">
Henry Thompson
Department of Artificial Intelligence
University of Edinburgh
Hope Park Square, Meadow Lane
Edinburgh EH87 9NW Scotland
Proceedings of AAAI, August 1983: 408-410.
</subsectionHeader>
<bodyText confidence="0.999961466666667">
One of the most attractive properties of the active
chart parsing methodology (Kay 1980, Thompson and
Ritchie 1983) is the distinction it makes possible be-
tween essential bookkeeping mechanisms, scheduling
issues, and details of grammatical formalisms.
MCHART is a framework within which active chart
parsing systems can be constructed. It provides the
essential bookkeeping mechanisms, and carefully struc-
tured interfaces for the specification of scheduling and
grammatical formalism. The resulting flexibility makes
it useful both for pedagogical purposes and for quick
prototyping. The system is available in UCILISP,
FranzLisp, and Interlisp versions, together with a sim-
ple lexicon facility, example parsers and detailed docu-
mentation.
</bodyText>
<subsectionHeader confidence="0.844975142857143">
Mapping Between Semantic Representations
Using Horn Clauses
Ralph M. Weischedel
Computer and Information Sciences
University of Delaware
Newark, DE 19711
Proceedings of AAAI, August 1983: 424-428.
</subsectionHeader>
<bodyText confidence="0.99906175">
Even after an unambiguous semantic interpretation has
been computed for a sentence in context, there are at
least three reasons that a system may map the seman-
tic representation R into another form S.
</bodyText>
<listItem confidence="0.9983348">
1. The terms of R, while reflecting the user view, may
require deeper understanding, e.g., may require a
version S where metaphors have been analyzed.
2. Transformations of R may be more appropriate for
the underlying application system, e.g., S may be a
</listItem>
<bodyText confidence="0.665472">
more nearly optimal form. These transformations
may not be linguistically motivated.
</bodyText>
<listItem confidence="0.9241975">
3. Some transformations may depend on non-
structural context.
</listItem>
<bodyText confidence="0.999797285714285">
Design considerations may favor factoring the process
into two stages, for reasons of understandability or for
easier transportability of the components.
This paper describes the use of Horn clauses for
the three clauses of transformations listed above. The
transformations are part of a system that converts the
English description of a software module into a formal
specification, i.e., an abstract data type.
The following abstracts refer to papers in Proceedings
of the Eighth International Joint Conference on Artifi-
cial Intelligence 8-11 August 1983, Karlsruhe, West
Germany. International Joint Conference on Artificial
Intelligence, Inc., 1983. Distributor: William Kauf-
mann, Inc., 95 First Street, Los Altos, CA 94022.
</bodyText>
<subsectionHeader confidence="0.887964666666667">
Phrase Structure Grammars and Natural
Languages
Gerald Gazdar
Cognitive Studies Programme
University of Sussex
Brighton BN1 9QN
</subsectionHeader>
<subsubsectionHeader confidence="0.382408">
Proc. Eighth IJCAI, August 1983, Vol. 1: 556.
</subsubsectionHeader>
<bodyText confidence="0.999090321428571">
During most of the last two decades, computational
linguists and AI researchers working on natural lan-
guage have assumed that phrase structure grammars,
despite their computational tractability, were unsatis-
factory devices for expressing the syntax of natural
languages. However, during the same period, they
have come to realize that transformational grammars
whatever their linguistic merits, are computationally
intractable as they stand. The assumption, unchal-
lenged for many years, that PSGs were inadequate for
natural languages is based on arguments originally
advanced by transformational linguists in the late
1950s and early 1960s. But recent work has shown
that none of those arguments were valid. The present
paper draws on that work to argue that (i) there is no
reason, at the present time, to think that natural lan-
guages are not context-free languages; (ii) there are
good reasons to think that the notations needed to
capture significant syntactic generalizations will char-
acterize phrase structure grammars or some minor
generalization of them; and (iii) there are good rea-
sons for believing that such grammars, and the mono-
stratal representations they induce, provide the neces-
sary basis for the semantic interpretation of natural
languages. If these arguments are valid, then the pro-
spects for a fruitful interaction between theoretical
linguistics and AI are much brighter than they would
otherwise be.
</bodyText>
<table confidence="0.961062">
American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 45
The FINITE STRING Newsletter Abstracts of Current Literature
Formal Theories of Language Acquisition: Prac-
tical and Theoretical Perspectives
Daniel N. Osherson
Center for Cognitive Science
Massachusetts Institute of Technology
Cambridge, MA 02139
Michael Stob
Department of Mathematics
Calvin College
Grand Rapids, IL 49506
Scott Weinstein
Department of Philosophy
University of Pennsylvania
Philadelphia, PA 19104
</table>
<subsubsectionHeader confidence="0.634811">
Proc. Eighth IJCAI, August 1983, Vol. 1: 566
</subsubsectionHeader>
<bodyText confidence="0.999554916666667">
Learning Theory is the study of systems that imple-
ment functions from evidential states to theories. The
theoretical framework developed in the theory makes
possible the comparison of classes of algorithms that
embody distinct learning strategies along a variety of
dimensions. Such comparisons yield valuable informa-
tion to those concerned with inference problems in
Cognitive Science and Artificial Intelligence. The
present paper employs the framework of Learning
Theory to study the design specifications of inductive
systems which are of interest in the domain of lan-
guage acquisition.
</bodyText>
<table confidence="0.759641">
Transportability and Generality in a Natural-
Language Interface System
Paul Martin, Douglas Appelt, Fernando Pereira
Artificial Intelligence Center
SRI International
Menlo Park, CA 94025
</table>
<subsubsectionHeader confidence="0.589068">
Proc. Eighth IJCAI, August 1983, Vol. 1: 573
</subsubsectionHeader>
<bodyText confidence="0.9999671875">
This paper describes the design of a transportable
natural language (NL) interface to data bases and the
constraints that transportability places on each compo-
nent of such a system. By a transportable NL system,
we mean an NL processing system that is constructed
so that a domain expert (rather than an Al or linguis-
tics expert) can move the system to a new application
domain. After discussing the general problems pre-
sented by transportability, this paper describes TEAM
(an acronym for Transportable English data base Ac-
cess Medium), a demonstrable prototype of such a
system. The discussion of TEAM shows how domain-
independent and domain-dependent information can
be separated in the different components of an NL
interface system, and presents one method of obtain-
ing domain-specific information from a domain expert.
</bodyText>
<subsectionHeader confidence="0.468258">
Focus Constraints on Language Generation
</subsectionHeader>
<author confidence="0.393089">
Kathleen R. McKeown
</author>
<affiliation confidence="0.592604">
Department of Computer Science
Columbia University
</affiliation>
<address confidence="0.382142">
New York, NY 10027
</address>
<subsubsectionHeader confidence="0.62092">
Proc. Eighth IJCAI, August 1983, Vol. 1: 582
</subsubsectionHeader>
<bodyText confidence="0.999661764705882">
Computer generation of natural language requires the
ability to make reasoned choices from a large number
of possible things to say as well as from a large num-
ber of expressive possibilities. This paper examines in
detail how one influence on a generated text, focus of
attention, can be used to constrain the many possibili-
ties that a generation system must consider. A compu-
tational treatment of focus of attention is presented
that can be used to constrain what the system needs to
consider when deciding what to say next. In this proc-
ess, information is produced that provides constraints
on which words and syntactic structures best express
the system&apos;s intent, thus ensuring that its resulting text
is coherent. This analysis has been used in the fully
implemented TEXT system, which generates paragraph
length responses to questions about data base struc-
ture.
</bodyText>
<table confidence="0.8243563">
Beyond Domain Independence: Experience with
the Development of a German Language Access
System to Highly Diverse Background Systems
W. Hoeppner, T. Christaller, H. Marburger, K. Monk,
B. Nebel, M. O&apos;Leary, W. Wahlster
Research Unit for Information Science and Artificial Intelli-
gence
University of Hamburg
Mittelweg 179
D-2000 Hamburg 13, F.R. Germany
</table>
<subsubsectionHeader confidence="0.564945">
Proc. Eighth IJCAI, August 1983, Vol. 1: 588
</subsubsectionHeader>
<bodyText confidence="0.999801045454546">
For natural language dialog systems, going beyond
domain independence means the attempt to create a
core system that can serve as a basis for interfaces to
various application classes that differ not only with
respect to the domain of discourse but also with re-
spect to dialog type, user type, intended system behav-
ior, and background system. In the design and imple-
mentation of HAM-ANS, which is presently operational
as an interface to an expert system, a vision system
and a data base system, we have shown that going
beyond domain independence is possible. HAM-ANS is
a large natural language dialog system with both con-
siderable depth and breadth, which accepts typed input
in colloquial German and produces typed German
responses quickly enough to make it practical for real-
time interaction. One goal of this paper is to report
on the lessons learned during the realization of the
system HAM-ANS. This paper introduces the overall
structure of the system&apos;s processing units and knowl-
edge sources. In addition we describe some of the
innovative features concerning the strategy of semantic
interpretation.
</bodyText>
<page confidence="0.79121">
46 American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983
</page>
<table confidence="0.988103142857143">
The FINITE STRING Newsletter Abstracts of Current Literature
TELEGRAM: A Grammar Formalism for Lan-
guage Planning
Douglas E. Appelt
Artificial Intelligence Center
SRI International
Menlo Park, CA 94025
</table>
<subsubsectionHeader confidence="0.506194">
Proc. Eighth IJCAI, August 1983, Vol. 1: 595
</subsubsectionHeader>
<bodyText confidence="0.970478166666667">
Planning provides the basis for a theory of language
generation that considers the communicative goals of
the speaker when producing utterances. One central
problem in designing a system based on such a theory
is specifying the requisite linguistic knowledge in a
form that interfaces well with a planning system and
allows for the encoding of discourse information. The
TELEGRAM (TELEological GRAMmar) system de-
scribed in this paper solves this problem by annotating
a unification grammar with assertions about how
grammatical choices are used to achieve various goals,
and by enabling the planner to augment the functional
description of an utterance as it is being unified. The
control structures of the planner and the grammar
unifier are then merged in a manner that makes it
possible for general planning to be guided by unifica-
tion of a particular functional description.
An Indirect Approach to Types of Speech Acts
</bodyText>
<subsectionHeader confidence="0.612137">
Jeremy El!man
Department of Psychology
University of Warwick
Coventry, UK
</subsectionHeader>
<subsubsectionHeader confidence="0.67195">
Proc. Eighth IJCAI, August 1983, Vol. 1: 600
</subsubsectionHeader>
<bodyText confidence="0.999801222222222">
Considerations of the similarity between direct and
indirect speech act understanding give rise to the no-
tion that taxonomies of speech acts may not be helpful
in modelling language understanding. A computer
model that treats representations of direct and indirect
speech acts similarly and successfully has been imple-
mented without any such taxonomy and without an
explicit representation of the difference between direct
and indirect speech acts.
</bodyText>
<table confidence="0.50652">
Mutual Beliefs in Conversational Systems:
Their Role in Referring Expressions
Gopalan Nadathur, Aravind K. Joshi
Department of Computer and Information Science
University of Pennsylvania
Philadelphia, PA 19104
</table>
<subsubsectionHeader confidence="0.652917">
Proc. Eighth IJCAI, August 1983, Vol. 1: 603
</subsubsectionHeader>
<bodyText confidence="0.999498294117647">
Shared knowledge and beliefs affect conversational
situations in various ways. One aspect in which they
play a role is the choice of referring expressions. It is
of interest to analyse this role since a natural language
system must be able to decide when it can use a par-
ticular referring expression; or alternatively what a
particular expressions refers to. In this paper we at-
tempt to formally characterise conditions for these.
Specifically, we differ with the traditional notion of
mutual knowledge and belief, state a conversational
conjecture that convinces us to do so, express a weak-
ened notion in a formal system for reasoning about
knowledge, and show how this might be used to decide
on satisfactory referring expressions. It is desirable to
express a weakened notion of mutual belief that paral-
lels that for mutual knowledge; this aspect is currently
being investigated.
</bodyText>
<table confidence="0.975617666666667">
Some Issues in Generation from a Semantic
Representation
Laurence Danlos
Laboratoire d&apos;Automatique Documentaire et Linguistique
(CNRS)
Artificial Intelligence Project (Yale University)
</table>
<subsubsectionHeader confidence="0.632076">
Proc. Eighth IJCAI, August 1983, Vol. 1: 606
</subsubsectionHeader>
<bodyText confidence="0.999063">
This paper investigates certain problems in the prod-
uction of text from a language-free representation and
proposes a model of generation to treat these prob-
lems. We deal with generation of connected text. We
show that the generation of a connected text cannot
be reduced to a simple combination of phrases ex-
pressing sub-parts of the representation, but must be
based on patterns of discourse structure reflecting the
whole representation.
</bodyText>
<table confidence="0.949568166666667">
Generation in a Natural Language Interface
Paul S. Jacobs
Division of Computer Science
Department of EECS
University of California
Berkeley, CA 94720
</table>
<subsubsectionHeader confidence="0.535847">
Proc. Eighth IJCAI, August 1983, Vol, 1: 610
</subsubsectionHeader>
<bodyText confidence="0.999351444444444">
The PHRED (PHRasal English Diction) generator pro-
duces the natural language output of Berkeley&apos;s UNIX
Consultant system (UC). The generator shares its
knowledge base with the language analyzer PHRAN
(PHRasal ANalyser). The parser and generator, to-
gether a component of UC&apos;s user interface, draw from
a database of pattern-concept pairs where the basic
unit of the linguistic patterns is the phrase. Both are
designed to provide multilingual capabilities, to facili-
tate linguistic paraphrases, and to be adaptable to the
individual user&apos;s vocabulary and knowledge. The gen-
erator affords extensibility, simplicity, and processing
speed while performing the task of producing natural
language utterances from conceptual representations
using a large knowledge base. This paper describes
the implementation of the phrasal generator and dis-
cusses the role of generation in a user-friendly natural
language interface.
</bodyText>
<table confidence="0.87386275">
American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 47
The FINITE STRING Newsletter Abstracts of Current Literature
Generation of Japanese Sentences from Con-
ceptual Representation
Shun Ishizaki
Electrotechnical Laboratory
1-1-4 Umezono Sakura-mura Niihari-qun
lbaraki, Japan 305
</table>
<subsubsectionHeader confidence="0.49112">
Proc. Eighth IJCAI, August 1983, Vol. 1: 613
</subsubsectionHeader>
<bodyText confidence="0.999753923076923">
This paper describes an attempt to generate Japanese
sentences from conceptual representation. This gener-
ator infers the temporal order of events included in the
conceptual representation using causal chains and
MPOs. Appropriate conjunctives between the events
and case markers for subjects are used based on the
representation. This generator was first built as part
of the Machine Translation Project in the Computer
Science Department of Yale University in 1982. It has
subsequently been improved at ETL in Japan. About
15 stories are parsed into conceptual representations
from Spanish newspaper stories (Lytinen and Shank
1982) and then Japanese sentences are generated.
</bodyText>
<subsectionHeader confidence="0.742154375">
Impression Monitoring in Evaluation-Oriented
Dialog. The Role of the Listener&apos;s Assumed Ex-
pectations and Values in the Generation of In-
formative Statements
Anthony Jameson
Department of Social Psychology
University of Nijmegen
6500 HE Nijmegen, The Netherlands
</subsectionHeader>
<subsubsectionHeader confidence="0.564207">
Proc. Eighth IJCAI, August 1983, Vol. 2: 616
</subsubsectionHeader>
<bodyText confidence="0.999952166666667">
A prototype dialog system is presented which special-
izes in responding to the questions of a user who is
assumed to be attempting to form an evaluation of a
given object. On the basis of explicit assumptions
concerning the evaluator&apos;s standards and prior expec-
tations, the system goes beyond the direct answering
of the questions by selecting additional comments
according to their anticipated impact on the
evaluator&apos;s impressions of the object. The system may
be positively or negatively biased in its selection of
comments; taking into account the (possibly different)
bias which it assumes the evaluator to ascribe to it, it
anticipates how the fact that it has failed to make
certain comments is likely to be interpreted. The
system&apos;s central concepts are also used to quantify the
notion of the relatedness of a given comment to a
given topic and to guide the selection of connectives
and sentential adverbs.
</bodyText>
<subsectionHeader confidence="0.732667333333333">
Shifting Meaning Representations
Karen Sparck Jones
Computer Laboratory
University of Cambridge
Corn Exchange Street
Cambridge CB2 3QG ENGLAND
</subsectionHeader>
<subsubsectionHeader confidence="0.577682">
Proc. Eighth IJCAI, August 1983, Vol. 2: 621
</subsubsectionHeader>
<bodyText confidence="0.999368916666667">
This paper argues that a number of different kinds of
meaning representation, between which partial transla-
tions can be made as needed, are all required for a
reasonably comprehensive language processing system.
These representations capture different and possibly
complementary aspects of a text&apos;s form, content and
reference worlds, and are suited to different subtasks
of the language processor. Initial testing of the propo-
sition via a system designed for natural language ac-
cess to databases is described, showing how different
types of meaning representation with different charac-
teristics are called for, related, and used.
</bodyText>
<figure confidence="0.557457125">
Frame Activated Inferences in a Story Under-
standing Program
Peter Norvig
Division of Computer science
Department of EECS
University of California
Berkeley, CA 94720
Proc. Eighth IJCAI, August 1983, Vol. 2: 624
</figure>
<bodyText confidence="0.999670666666667">
An effective story understander must be able to reason
about characters in the story, their affects, actions,
plans, and goals, as well as the settings and important
points of the story. In many systems this has been
done with separate inference mechanisms for each
class of knowledge structure. This paper proposes a
story understander with a unified frame-based infer-
ence component used on each class of knowledge
structure.
</bodyText>
<subsectionHeader confidence="0.9653232">
Structural Relations -- A Case Against Case
Ingeborg Steinacker, Harald Trost
Department of Medical Cybernetics
University of Vienna
Austria
</subsectionHeader>
<subsubsectionHeader confidence="0.614682">
Proc. Eighth IJCAI, August 1983, Vol. 2: 627
</subsubsectionHeader>
<bodyText confidence="0.999971789473684">
Usually semantic parsers of NLU systems rely on some
type of &apos;deep case&apos; (Riesbeck and Schank 1976, Trost
and Steinacker 1981) to control analysis. While we do
not want to deny the advantages of such an approach
(we use it ourselves), we propose to apply a different
approach in order to analyse words that derive their
meaning from the semantic category of their depend-
ent constituents. The algorithm we present in this
paper disambiguates such words by making use of one
of the important properties of an SI-Net (Brachman
1979), the strict distinction between structure and
contents of the net. Structurally, all semantic relations
are represented in the same way; therefore we evalu-
ate this level to find out if there is a relation between
the representation of the constituents of such a word.
After a link has been found, its semantic interpretation
is taken to be the sense of the word. Besides being
used for disambiguation, the algorithm is applicable to
solve other problems related to parsing as well, e.g.,
</bodyText>
<page confidence="0.812562">
48 American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983
</page>
<table confidence="0.265862111111111">
The FINITE STRING Newsletter Abstracts of Current Literature
interpretation of metaphors or problems related to
resolution of definite anaphora.
The FOPHO Speech Recognition Project
Mary O&apos;Kane
School of Information Science
Canberra College of Advanced Education
P.O. Box 1
Belconnen, 2616 AUSTRALIA
</table>
<subsubsectionHeader confidence="0.478418">
Proc. Eighth IJCAI, August 1983, Vol. 2: 630
</subsubsectionHeader>
<bodyText confidence="0.998023733333333">
The FOPHO (Foreign PHOnetician) speech recognition
project concerns the development of a system to prod-
uce a reasonably high quality phonetic transcription
output from continuous speech input. The system is
developed to perform in a way which approximates the
actions of a phonetician trying to transcribe a foreign
tongue (in the case of FOPHO, Australian English).
Because of this central philosophy, FOPHO is a very
interactive system and has facilities for automatic
learning and analysis of its own performance. Good
quality recognition is achieved through algorithms
which are very context-dependent and which are sensi-
tive to a variety of possible productions of similar
sounds even though the system itself is speaker inde-
pendent.
</bodyText>
<figure confidence="0.58502525">
A System for Improving the Recognition of
Fluently Spoken German Speech
Joachim Mudler
Institut fur Nachrichtentechnik
Technische Universitat Braunschweig
Schleinitzstr. 23
0-3300 Braunschweig, Fed. Rep. Germany
Proc. Eighth IJCAI, August 1983, Vol. 2: 633
</figure>
<bodyText confidence="0.999637458333333">
A research project for improving the recognition of
fluently spoken German speech is presented. The
work is in progress at present.
It should be investigated, how far aspects of se-
mantics and inferences could improve the automatic
speech recognition. The work is part of a speech rec-
ognition system that receives speech signals, converts
them into forms suitable for further actions and finally
puts out the spoken text in characters. The system
itself operates at three stages. Within the first one the
signal analysis is performed using a well-known me-
thod. This analysis segments the signal into certain
subword units and, for each segment, produces a set of
weighted candidates. At the second stage these candi-
dates are used to generate weighted word hypotheses
with the aid of an extensive lexicon. The hypotheses
have to be verified or falsified within the following
processing steps at the third stage. Thereby the algo-
rithm uses a best-first strategy (hypotheses with high-
est weight first).
Besides syntactic/grammatical aspects, semantic
analysis and inferences mentioned above are the
methods that should lead to a certain text comprehen-
sion.
</bodyText>
<subsectionHeader confidence="0.5077102">
Allophonic and Phonotactic Constraints are
Useful
Kenneth W. Church
Massachusetts Institute of Technology
Cambridge, MA 02139
</subsectionHeader>
<subsubsectionHeader confidence="0.603829">
Proc. Eighth IJCAI, August 1983, Vol. 2: 636
</subsubsectionHeader>
<bodyText confidence="0.9997156">
This paper argues that allophonic and phonotactic cues
are a source of constraint, not a source of noise as
many speech researchers have assumed in the past.
These constraints are formulated so that they can be
exploited with well-known parsing techniques.
</bodyText>
<subsectionHeader confidence="0.8060925">
A Recognition Method of Connected Spoken
Words with Syntactical Constraints by Aug-
mented Continuous DP Algorithm
Sei-ichi Nakagawa
</subsectionHeader>
<bodyText confidence="0.220084666666667">
Department of Information and Computer Science
Toyohashi University of Technology
Toyohashi, 440 Japan
</bodyText>
<subsubsectionHeader confidence="0.41442">
Proc. Eighth IJCAI, August 1983, Vol. 2: 639
</subsubsectionHeader>
<bodyText confidence="0.999952125">
The technique of dynamic time warping by using dy-
namic programming is powerful for isolated word rec-
ognition.
An augmented continuous dynamic programming
algorithm is proposed for connected spoken word rec-
ognition with syntactical constraints. The algorithm is
based on the same principle of two level DP and level
building DP. Although our algorithm obtains a near
optimal solution for the recognition principle based on
pattern matching, it is computationally more efficient
than the conventional methods and also does not re-
quire many memory storages. Therefore it is useful
for connected word recognition with syntactical const-
raints in a large vocabulary. The amount of computa-
tion is almost the same as that for isolated word recog-
nition.
</bodyText>
<subsectionHeader confidence="0.866285416666667">
Over-Answering Yes-No Questions: Extended
Responses in a NL Interface to a Vision System
Wolfgang Wahlster, Heinz Marburger
Research Unit for Information Science and Artificial Intelli-
gence
University of Hamburg
Mittelweg 179
D-2000 Hamburg 13, F.R. Germany
Anthony Jameson
Psychologisch Laboratorium
Faculteit der Sociale Wetenschappen
Katholieke Universiteit
</subsectionHeader>
<footnote confidence="0.6669728">
Montessorilaan 3
NL-6500 HE Nijmegen, The Netherlands
Stephan Busemann
Research Unit for Information Science and Artificial Intelli-
gence
</footnote>
<affiliation confidence="0.409227">
University of Hamburg
</affiliation>
<note confidence="0.79941">
American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 49
The FINITE STRING Newsletter Abstracts of Current Literature
Proc. Eighth IJCAI, August 1983, Vol. 2: 643
</note>
<bodyText confidence="0.999975272727273">
This paper addresses the problem of over-answering
yes-no questions, i.e. of generating extended responses
that provide additional information to yes-no questions
that pragmatically must be interpreted as wh-
questions. Although the general notion of extended
responses has already been explored, our paper reports
on the first attempt to build a NL system able to elab-
orate on a response as a result of anticipating obvious
follow-up questions, in particular by providing addi-
tional case role fillers, by using more specific quantifi-
ers and by generating partial answers to both parts of
questions containing coordinating conjunctions. As a
further innovation, the system explicitly deals with the
informativeness-simplicity trade-off when generating
extended responses. We describe both an efficient
implementation of the proposed methods, which use
message passing as realized by the FLAVOR mecha-
nism and the extensive linguistic knowledge incorpo-
rated in the verbalization component. The structure of
the implemented NL generation component is illustrat-
ed using a detailed example of the system&apos;s perform-
ance as an interface to an image understanding system.
</bodyText>
<table confidence="0.521579625">
Demand and Requirements for Natural Lan-
guage Systems. Results of an Inquiry.
Katharina Monk
Research Unit for Information Science and Artificial Intelli-
gence
University of Hamburg
Mittelweg 179
0-2000 Hamburg 13, F.R. Germany
</table>
<subsubsectionHeader confidence="0.473952">
Proc. Eighth IJCAI, August 1983, Vol. 2: 647
</subsubsectionHeader>
<bodyText confidence="0.999908333333333">
This paper presents the results of a market inquiry on
German natural language systems (NLS), which may
provide a basis for discussions about applications of Al
systems. Features of application areas in which NLS
are desired are analyzed and requirements for capabili-
ties of NLS are determined.
</bodyText>
<subsectionHeader confidence="0.946762166666667">
Varieties of User Misconceptions: Detection
and Correction
Bonnie Lynn Webber, Eric Mays
Department of Computer and Information Science
University of Pennsylvania
Philadelphia, PA 19104
</subsectionHeader>
<subsubsectionHeader confidence="0.532151">
Proc. Eighth IJCAI, August 1983, Vol. 2: 650
</subsubsectionHeader>
<bodyText confidence="0.998661375">
This paper discusses some of our research into detect-
ing and reconciling critical differences between a
user&apos;s view of the world and the system&apos;s. We feel
there is benefit to the gained by separating misconcep-
tions into two main classes: misconceptions about
what is the case and misconceptions about what can be
the case. We review some initial work in both areas
and discuss our work in progress.
</bodyText>
<note confidence="0.429824">
The XCALIBUR Project
</note>
<table confidence="0.981784375">
Jaime G. Carbonell, W. Mark Boggs, Michael L.
Mauldin
Computer Science Department
Carnegie-Mellon University
Pittsburgh, PA 15213
Peter G. Anick
Digital Equipment Corporation
Hudson, MA 01749
</table>
<subsubsectionHeader confidence="0.423422">
Proc. Eighth IJCAI, August 1983, Vol. 2: 653
</subsubsectionHeader>
<bodyText confidence="0.9978364">
The inevitable proliferation of expert systems under-
scores the need for robust, friendly interfaces requiring
minimal user training. The objective of the
XCALIBUR project is to meet this need by providing
natural comprehension and generation in the context
of a focused mixed-initiative dialog. The XCALIBUR
architecture is discussed, including its three central
components (parser, generator and information man-
ager), its methods of handling ellipsis and imperfect
input, and its relation to the underlying expert system.
</bodyText>
<subsectionHeader confidence="0.932713666666667">
Towards a Computable Model of Meaning-Text
Relations Within a Natural Soblanguage
Richard Kittredge, Igor Mel&apos;cuk
Department of Linguistics
University of Montreal
Montreal H3C 3J7 CANADA
</subsectionHeader>
<subsubsectionHeader confidence="0.424849">
Proc. Eighth IJCAI, August 1983, Vol. 2: 657
</subsubsectionHeader>
<bodyText confidence="0.999963095238095">
A computable linguistic model is proposed for relating
texts to their meanings within a natural sublanguage of
English (stock market reports). Oriented networks are
used to represent meanings which are first established
by a linguistic analysis of the paraphrase sets found in
the sublanguage. Several types of correspondence
rules map fragments of the semantic network onto
portions of deep syntactic dependency trees in a recur-
sive process which does not &amp;quot;consume&amp;quot; the network,
but rather uses it as a kind of blueprint. Additional
representation levels (not illustrated) are required to
relate these trees to final texts through surface syntac-
tic and morphological stages. Important features of
this model are (1) its capacity to represent the full
paraphrastic power of language within an interesting
natural sublanguage, and (2) its bidirectionality, allow-
ing the modelling of both analysis and synthesis of
texts. Implementation is planned first as a device for
synthesizing stock market reports (SMRAD system),
but later possible applications include translation or
paraphrasing of texts from this natural domain.
</bodyText>
<sectionHeader confidence="0.268311" genericHeader="method">
Q-TRANS: Query Translation into English
</sectionHeader>
<reference confidence="0.314928">
Eva-Maria M. Mueckstein
IBM Thomas J. Watson Research Center
Yorktown Heights, NY 10598
Proc. Eighth IJCAI, August 1983, Vol. 2: 660
</reference>
<bodyText confidence="0.87933">
Q-TRANS, which stands for Query-TRANSlation Sys-
tem, translates formal database queries into English to
</bodyText>
<page confidence="0.449323">
50 American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983
</page>
<note confidence="0.574675">
The FINITE STRING Newsletter Abstracts of Current Literature
</note>
<bodyText confidence="0.999842043478261">
enhance the usability of both natural and formal lan-
guage database access systems. Q-TRANS is designed
for the database query language SQL, whose query
expressions serve as an abstract representation from
which an English paraphrase is generated. Q-TRANS
is also intended to be part of the Transformational
Question Answering System (TQA system), which
provides a natural language interface for database
query, analyzing and ultimately translating the English
queries into SQL expressions. The concepts and me-
thods used in 0-TRANS to arrive at a query translation
are, however, independent from the TQA system ex-
cept for compatibility of lexical and grammatical cov-
erage of the paraphrases produced. The paraphrases
generated are true translations of the SQL expressions
which are the input to Q-TRANS and serve in a sense
as deep structures that get mapped into English imper-
atives. The grammatical English structures 0-TRANS
produces obey somewhat conflicting constraints in that
they preserve as much of the SQL structure as neces-
sary to reflect the internal logic to the user, and at the
same time represent as natural English sentences as
possible.
</bodyText>
<subsectionHeader confidence="0.743085">
Understanding Natural Language Through Paral-
lel Process of Syntactic and Semantic Knowl-
</subsectionHeader>
<table confidence="0.943225166666666">
edge: An Application to Data Base Query
R. Comino, R. Gemello
CSELT - Centro Studi e Laboratori Telecomunicazioni S.p.A.
Via G. Reiss Romoli
274 - 10148 Torino (Italy)
G. Guida, R. Gemello
Milan Polytechnic Artificial Intelligence Project
Milano (Italy)
C. Rullent, L. Sisto
CSELT
M. Somalvico
Milan Polytechnic Al Project
</table>
<subsubsectionHeader confidence="0.465566">
Proc. Eighth IJCAI, August 1983, Vol. 2: 663
</subsubsectionHeader>
<bodyText confidence="0.999937823529412">
This paper describes the main features of the PARNAX
system for natural language access (in Italian) to an
ADABAS data base. The core of the system is consti-
tuted by the analyzer that includes parallel processing
of syntactic and semantic knowledge. It is argued that
this feature (together with the new macro- and micro-
analysis technique which is only shortly mentioned in
this paper) allowed the system to reach a good linguis-
tic coverage, still ensuring an acceptable degree of
efficiency. After the basic architecture and operation
of PARNAX have been described, attention is focused
on the parallel syntactic/semantic analyzer which is
illustrated in detail. The advantages obtained through
parallelism are also shortly discussed. Examples of
PARNAX operation are presented. References to rela-
ted works are mentioned, and directions for future
research are outlined.
</bodyText>
<note confidence="0.528040833333333">
A Framework for Processing Corrections in
Task-Oriented Dialogues
Philip J. Hayes, Jaime G. Carbonell
Carnegie-Mellon University
Pittsburgh, PA 15213
Proc. Eighth IJCAI, August 1983, Vol. 2: 668
</note>
<bodyText confidence="0.9996466">
Mundane discourse abounds with utterances referring
to other utterances. These meta-language utterances
appear with surprising frequency in task-oriented dia-
logues, such as those arising in the context of a natural
language interface to an operating system. This paper
identifies some simpler types of dialogue-level meta-
language utterance and provides a computational
framework to process such phrases in the context of a
case-frame parser exploiting strongly-typed domain
semantics.
</bodyText>
<subsectionHeader confidence="0.79439875">
Graph Grammar Approach to Natural Language
Parsing and Understanding
Eero Hyvonen
Digital Systems Laboratory
</subsectionHeader>
<affiliation confidence="0.381254">
Helsinki University of Technology
02150 Espoo 15, Finland
</affiliation>
<subsubsectionHeader confidence="0.416718">
Proc. Eighth IJCAI, August 1983, Vol. 2: 671
</subsubsectionHeader>
<bodyText confidence="0.999913">
String grammars have been found in many ways inade-
quate for parsing inflectional languages with &amp;quot;free&amp;quot;
word order. To overcome these problems we have
replaced linear string grammars and tree transforma-
tions by their multidimensional generalization, graph
grammars. In our approach, parsing is seen as a trans-
formation between two graph languages, namely the
sets of morphological and semantic representations of
natural language sentences. An experimental Finnish
question-answering system SUVI based on graph gram-
mars has been implemented. In SUVI the role of indi-
vidual words is active. Each word is associated to a
syntactic-semantic constituent type that is represented
by a transition network-like graph whose transitions
correspond to transformations in the derivation graph.
Parsing is performed by interpreting the constituent
type graphs corresponding to the words of the current
sentence.
</bodyText>
<sectionHeader confidence="0.548924" genericHeader="method">
Articles and Resource Control
</sectionHeader>
<reference confidence="0.359808333333333">
Jamusz S. Bien
Institute of Informatics
Warsaw University
P.O.Box 1210
00-901 Warszawa, Poland
Proc. Eighth IJCAI, August 1983, Vol. 2: 675
</reference>
<bodyText confidence="0.944272461538462">
The paper discusses how the resource control hypothe-
sis introduced earlier by the author accounts for the
rather mysterious fact that English articles ,are ren-
dered in Slavonic languages by word order and vice
versa. The definite versus indefinite distinction is
viewed as a manifestation of the variable depth of
American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 51
The FINITE STRING Newsletter Abstracts of Current Literature
nominal phrase processing. The depth of processing is
determined by the availability of resources, which is
indirectly controlled by the speaker with sufficient
precision,; articles appear to be only some of several
resource control devices available in natural languages.
</bodyText>
<subsectionHeader confidence="0.741721">
Activation-base Parsing
Mark A. Jones
State University of New York at Stony Brook
Long Island, New York 11794
</subsectionHeader>
<subsubsectionHeader confidence="0.673163">
Proc. Eighth IJCAI, August 1983, Vol. 2: 678
</subsubsectionHeader>
<bodyText confidence="0.9999623">
A model is presented that describes natural language
parsing in terms of a uniform activation algorithm
which operates over an interconnected, declarative
structure of nodes and node instances. The algorithm
directs the flow of activation and expectation using
only local information and, hence, supports substantial
concurrency. A representation is introduced to ex-
press node relationships and activation agreement.
Examples of several linguistic processes and their in-
terrelationships are described.
</bodyText>
<subsectionHeader confidence="0.654142166666667">
Two-Level Model for Morphological Analysis
Kimmo Koskenniemi
Department of General Linguistics
University of Helsinki
Hallituskatu 11-13
SF-00100 Helsinki 10, Finland
</subsectionHeader>
<subsubsectionHeader confidence="0.591132">
Proc. Eighth IJCAI, August 1983, Vol. 2: 683
</subsubsectionHeader>
<bodyText confidence="0.9999938">
This paper presents a new linguistic, computationally
implemented model for morphological analysis and
synthesis. It is general in the sense that the same lan-
guage independent algorithm and the same computer
program can operate on a wide range of languages,
including highly inflected ones such as Finnish, Rus-
sian or Sanskrit. The new model is unrestricted in
scope and it is capable of handling the whole language
system as well as ordinary running text. A full de-
scription for Finnish has been completed and tested,
and the entries in the Dictionary of Modern Standard
Finnish have been converted into a format compatible
with it.
The model is based on a lexicon that defines the
word roots, inflectional morphemes and certain non-
phonological alternation patterns, and on a set of par-
allel rules that define phonologically oriented phenom-
ena. The rules are implemented as parallel finite state
automata, and the same description can be run both in
the producing and in the analyzing direction.
</bodyText>
<subsectionHeader confidence="0.650809666666667">
A Modular Parser for French
Eric Wehrli
Geneva University Hospital
</subsectionHeader>
<subsubsectionHeader confidence="0.735143">
Proc. Eighth IJCAI, August 1983, Vol. 2: 686
</subsubsectionHeader>
<bodyText confidence="0.9971151">
In this paper, we describe an efficient parser for
French based on an adaptation of Chomsky&apos;s
Government-Binding (GB) theory. Reflecting the
modular concept of a GB grammar, the parser consists
of several distinct procedures corresponding to the
subsystems of the grammar (e.g., phrase-structure
rules, binding, control, `theta&apos;-theory, etc.). The inter-
action of these fairly simple modules produces the kind
of complexity required in order to build all the linguis-
tically motivated structures for a given sentence.
</bodyText>
<table confidence="0.708634">
An Object-Oriented Parser for Text
Understanding
Brian Phillips
Texas Instruments, Inc.
P.O. Box 226015, MS 238
Dallas, TX 75266
</table>
<subsubsectionHeader confidence="0.528755">
Proc. Eighth IJCAI, August 1983, Vol. 2: 690
</subsubsectionHeader>
<bodyText confidence="0.999889083333333">
The parser is part of a text understanding system in
which structural ambiguity is a major problem. All
components of the system use a message-passing con-
trol structure. A general advantage of this form of
control is that it allows the flexible integration of div-
erse knowledge sources. The parser transmits sub-
sentential constituents for semantic interpretation. A
pseudo-parallel version of the left-corner parsing al-
gorithm with top-down filtering is used. As blind
transmission would send spurious constituents, a delay
mechanism is used to queue constituents until all alter-
native analyses of a segment have been completed.
</bodyText>
<sectionHeader confidence="0.6713065" genericHeader="method">
A Prolog Implementation of Lexical Functional
Grammar
</sectionHeader>
<subsectionHeader confidence="0.821899">
Uwe Reyle, Werner Frey
Institute of Linguistics
University of Stuttgart
</subsectionHeader>
<subsubsectionHeader confidence="0.674646">
Proc. Eighth IJCAI, August 1983, Vol. 2: 693
</subsubsectionHeader>
<bodyText confidence="0.998504684210526">
Lexical functional grammar (LFG) is an attempt to
solve problems that arise in transformational grammar
and ATN-formalisms (Bresnan 1982). Another power-
ful formalism for describing natural languages follows
from a method for expressing grammars in logic, due
to Colmerauer (1978) and Kowalski (1974), called
definite clause grammars (DCG) (Warren, Pereira
1980). Both formalisms are a natural extension of
context-free grammars (CFG).
The aim of this paper is to show
â€” how LFG can be translated into DCG;
â€” that the procedural semantics of PROLOG provides
an efficient tool for LFG-implementations in that it
allows the construction of function structures (f-
structures) directly during the parsing process. I.e.,
it is not necessary to have a separate component
which first derives a set of functional equations
from the parse tree, and secondly generates an f-
structure by solving these equations.
</bodyText>
<page confidence="0.696947">
52 American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983
</page>
<table confidence="0.660335">
The FINITE STRING Newsletter Abstracts of Current Literature
A Breadth-First Parsing Model
John Bear
Linguistics Research Center
University of Texas
Austin, TX 78712
</table>
<note confidence="0.409118">
Proc. Eighth IJCAI, August 1983, Vol. 2: 696
</note>
<bodyText confidence="0.99971">
Recent attempts at modeling humans&apos; abilities at proc-
essing natural language have centered around depth-
first parsing algorithms, and control strategies for
making the best choices for disambiguation and atta-
chment. This paper proposes a breadth-first algorithm
as a model. The algorithm avoids some of the com-
mon pitfalls of depth-first approaches regarding ambi-
guity, and by using more pre-computed information
about the grammar, avoids some of the usual problems
of parallel parsing algorithms as well.
</bodyText>
<subsectionHeader confidence="0.657498666666667">
Sentence Disambiguation by a Shift-Reduce
Parsing Technique
Stuart M. Shieber
Artificial Intelligence Center
SRI International
Menlo Park, CA 94025
</subsectionHeader>
<subsubsectionHeader confidence="0.458132">
Proc. Eighth IJCAI, August 1983, Vol. 2: 699
</subsubsectionHeader>
<bodyText confidence="0.99935375">
Native speakers of English show definite and consist-
ent preferences for certain readings of syntactically
ambiguous sentences. A user of a natural-language
processing system would naturally expect it to reflect
the same preferences. Thus, such systems must model
in some way the linguistic performance as well as the
linguistic competence of the native speaker. We have
developed a parsing algorithm â€” a variant of the
LALR(1) shift-reduce algorithm â€” that models the
preference behavior of native speakers for a range of
syntactic preference phenomena reported in the psy-
cholinguistic literature, including the recent data on
lexical preferences. The algorithm yields the preferred
parse deterministically, without building multiple parse
trees and choosing among them. As a side effect, it
displays appropriate behavior in processing the much
discussed garden-path sentences. The parsing algo-
rithm has been implemented and has confirmed the
feasibility of our approach to the modeling of these
phenomena.
</bodyText>
<reference confidence="0.680816333333333">
Word Formation in Natural Language Process-
ing Systems
Roy J. Byrd
IBM Thomas J. Watson Research center
Yorktown Heights, NY 10598
Proc. Eighth IJCAI, August 1983, Vol. 2: 704
</reference>
<bodyText confidence="0.9984706">
Systems which process natural language require a reli-
able source of information about words. Not only
must their lexical subsystems handle a large number of
known words; they must also cope with coinages. The
morphological principles underlying the notion
&amp;quot;possible word&amp;quot; are under active study by linguists,
and are articulated in the theory of word formation.
This paper presents a technique for building lexical
subsystems which embody these principles by emulat-
ing the behavior of word formation rules. These sub-
systems combine totally idiosyncratic lexical informa-
tion, stored in a dictionary, with systematic informa-
tion derived from word structure. Applications for
lexical subsystems built along the lines described here
will be discussed.
</bodyText>
<sectionHeader confidence="0.521678" genericHeader="method">
A Deterministic Syntactic-Semantic Parser
</sectionHeader>
<reference confidence="0.8103364">
Gerard Sabah, Mohamed Rady
GR22, PARIS VI
4 Place Jussieu
75230 PARIS CEDEX 5
Proc. Eighth IJCAI, August 1983, Vol. 2: 707
</reference>
<bodyText confidence="0.992996684210526">
We consider that we have made a decisive step to-
wards determinism in parsing. We agree with
Winograd&apos;s hesitation to evaluate the determinism
hypothesis as formulated by Marcus. However, this
does not make us doubt about the possibility of deter-
minism; on the contrary, we examined not only how to
improve over Marcus, but also the historical reasons of
the non-determinism of most systems.
Our improvements are based on two principles:
syntactic-semantic integration, and quasi-simultane-
ousness. The first means that there is no such thing as
&amp;quot;the autonomy of syntax&amp;quot; (Marcus); so, we agree with
Schank and, further, we showed that local semantic
ambiguities could be solved deterministically. (Marcus
(Ch. 10) claims that these ambiguities need parallel
processing.) The second permits the processing of
structures too difficult for PARSIFAL, e.g., locally
ambiguous PP attachments.
Detailed examples support our proposals.
</bodyText>
<sectionHeader confidence="0.401017" genericHeader="method">
A Deterministic Parser with Broad Coverage
</sectionHeader>
<reference confidence="0.5445788">
Robert C. Berwick
Artificial Intelligence Laboratory
Massachusetts Instititute of Technology
Cambridge, MA 02139
Proc. Eighth IJCAI, August 1983, Vol. 2: 710
</reference>
<bodyText confidence="0.993590125">
This paper is a progress report on a series of three
significant extensions to the original parsing design of
Marcus (1980). The extensions are: The range of
syntactic phenomena handled has been enlarged en-
compassing sentences with Verb Phrase deletion, gap-
ping, and rightward movement, and an additional out-
put representation of anaphor-antecedent relationships
has been added (including pronoun and quantifier
interpretation). A complete analysis of the parsing
design has been carried out, clarifying the parser&apos;s
relationship to the extended I.R(k,t) parsing method as
original defined by Knuth (1965) and explored by
Szymanski and Williams (1976). The formal model
has led directly to the design of a &amp;quot;stripped down&amp;quot;
American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 53
The FINITE STRING Newsletter Abstracts of Current Literature
parser that uses standard I.R(k) technology and to
results about the class of languages that can be han-
dled by Marcus-style parsers (briefly, the class of lan-
guages is defined by those that can be handled by a
deterministic, two-stack, push-down automaton with
several restrictions on the transfer of material between
the two stacks, and includes some strictly context-
sensitive languages).
</bodyText>
<reference confidence="0.792690428571429">
Narrative Complexity Based on Summarization
Algorithms
Wendy G. Lehnert
Department of Computer and Information Science
University of Massachusetts
Amherst, MA 01003
Proc. Eighth IJCAI, August 1983, Vol. 2: 713
</reference>
<bodyText confidence="0.995531052631579">
Narrative structures can only be defined in terms of
some internal memory representation, but narrative
complexity is more properly characterized by informa-
tion processing requirements. Story grammars, plan
and goal hierarchies, and causal chain representations
all provide a sense of structure which is largely re-
moved from the processes that produce or access that
memory representation. In this paper we introduce
the notion of algorithmic equivalence as a means of
generating more algorithmically-oriented taxonomies
for memory representations. Using memory represent-
ations based on plot units, we define two narratives to
be algorithmically equivalent if they can be effectively
summarized by the same retrieval process. This per-
spective on representational strategies is an especially
natural one from a processing point of view, since the
computational complexity of a particular information
processing task must be measured in terms of the al-
gorithms involved.
</bodyText>
<reference confidence="0.884338857142857">
Japanese Language Semantic Analyzer Based
on an Extended Case Frame Model
Akira Shimazu, Syozo Naito, Hirosato Nomura
Musashino Electrical Communication Laboratory, N.T.T.
3-9-11, Midoricho, Musashino
Tokyo, 180, Japan
Proc. Eighth IJCAI, August 1983, Vol. 2: 717
</reference>
<bodyText confidence="0.999385375">
This paper describes a Japanese language semantic
analyzer based on an extended case frame model,
which consists of a relatively large collection of case
relations, modalities and conjunctive relations. The
analyzer performs four stage analysis using a frame
type knowledge base. It also utilizes plausibility
scores for dealing with ambiguities and local scene
frames for the prediction of omitted case elements.
</bodyText>
<reference confidence="0.973943555555556">
Syntax. Semantics and Pragmatics in Concert:
An Incremental, Multilevel Approach in Recon-
structing Task-Oriented Dialogues
Manfred Gehrke
Project &amp;quot;Prozedural Dialogmodelle&amp;quot;
Department of Linguistics and Literature
University of Bielefeld
Bielefeld, FRG
Proc. Eighth IJCAI, August 1983, Vol. 2: 721
</reference>
<bodyText confidence="0.999844933333333">
This paper gives an overview of a model for the recon-
struction of task-oriented dialogues based on an inter-
active, multilevel parsing formalism. It is applied to
route description dialogues. It will be shown how the
pragmatic aspects of such dialogues are taken into
account on different levels of processing. The ap-
proach described is based on an extension of the con-
cept of cascaded ATNs. Furthermore this approach
uses knowledge sources (KSs) for every participant in
the dialogue in which knowledge about the world and
a partner model is built up during the analysis of a
dialogue. These KSs are supplied to the parsing proc-
ess, as well. In this paper special importance is laid on
the description of the interaction and cooperation of
the different processing components of this formalism.
</bodyText>
<reference confidence="0.83675525">
Event Models for Recognition and Natural Lan-
guage Description of events in Real-World Im-
age Sequences
Bernd Neumann, Hans-Joachim Novak
Fachbereich Informatik
Schulterstrasse 70
0-2000 Hamburg 13, W. Germany
Proc. Eighth IJCAI, August 1983, Vol. 2: 724
</reference>
<bodyText confidence="0.99837">
For an adequate interpretation of image sequences it is
not only necessary to recognize objects and object
positions but also certain interesting temporal develop-
ments of the scene, called events. In this paper we
discuss event models for traffic scenes at high-level
conceptual structures which permit interfacing to an
existing natural language dialogue system. Event mod-
els are declarative descriptions of classes of vents or-
ganized around verbs of locomotion. They involve
components which are directly related to the deep case
structure of a corresponding natural language descrip-
tion. Event models may be used for bottom-up scene
description as well as top-down question-answering.
They may also incorporate expectations about a scene,
thus providing an interface to experience and common
sense.
</bodyText>
<reference confidence="0.846813166666667">
Automatic Construction of a Knowledge Base
by Analysing Texts in Natural Language
Werner Frey, Uwe Reyle, Christian Rohrer
Department of Linguistics
University of Stuttgart
Proc. Eighth IJCAI, August 1983, Vol. 2: 727
</reference>
<page confidence="0.88386">
54 American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983
</page>
<bodyText confidence="0.974946857142857">
The FINITE STRING Newsletter Abstracts of Current Literature
We present a system which translates sentences from a
subset of German into a database. This database will
function as the basis for a question-answering system.
The system is applied to a complete text and not to
isolated sentences. As an intermediate stage between
the German text and the database we use the Dis-
course Representation Structures (DRS) invented by
Hans Kamp. Kamp&apos;s system has been chosen because
it handles intrasentential and intersentential relations
uniformly. Within Kamp&apos;s system one can account for
certain types of anaphoric relations for which no other
linguistic theory has provided a solution.
The input to our system is analyses by a parser
which is based on lexical functional grammar. This is
the first attempt to combine research on discourse
representation with lexical functional grammar with
the help of the formalism of Definite Clause Grammar.
For the construction of the database out of the
DRSs, two solutions are proposed. First, a translation
of the DRSs into a set of PROLOG clauses enriched
with some additional deductive principles. Second, the
formulation of inference rules which operate directly
on the DRS.
So far we have implemented the following compo-
nents: parser of German, translation rules which map
syntactic trees into DRSs and rules which translate
DRSs into PROLOG-clauses.
</bodyText>
<reference confidence="0.938538">
Why Good Writing Is Easier to Understand
John H. Clippinger, Jr.
Brattle Research Corporation
6 Faneuil Hall Market Place
Boston, MA 02109
David D. McDonald
Department of Computer and Information Science
University of Massachusetts
Amherst, MA 01003
Proc. Eighth IJCAI, August 1983, Vol. 2: 730
</reference>
<bodyText confidence="0.99784285">
Writing is &amp;quot;good&amp;quot; when it anticipates the knowledge
that its readers will bring to it â€” the questions they will
implicitly ask â€” and tailors its content and form ac-
cordingly. A large part of this tailoring involves the
careful use of &amp;quot;discourse clues&amp;quot;; choices of wording,
patterns of phrasing, and specific discourse connec-
tives that signal the structure and intent of a text to
the audience. We begin by examining an instance of
bad writing, rewriting it to illustrate the importance of
discourse conventions in avoiding false interpretations.
We continue with an example of a larger scale dis-
course pattern, and show how the recognition of such
patterns captures important inferences &amp;quot;for free&amp;quot;,
making a general-purpose deduction component largely
unnecessary. The paper concludes with a brief discus-
sion of the design of a language understanding system
presently under development that uses discourse clues
and commonsense reasoning to direct the text under-
standing process in a flexible and opportunistic man-
ner.
</bodyText>
<note confidence="0.366509">
American Journal of Computational Linguistics, Volume 9, Number 1, January-March 1983 55
</note>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.240034">
<title confidence="0.99879075">The FINITE STRING Newsletter Abstracts of Current Literature Abstracts of Current Literature Knowledge Representation and Retrieval for Natural Language Processing</title>
<author confidence="0.999152">A M Frisch</author>
<author confidence="0.999152">J F Allen</author>
<affiliation confidence="0.9999385">Computer Science Department University of Rochester</affiliation>
<address confidence="0.99959">Rochester, NY 14627</address>
<abstract confidence="0.998744666666667">Technical Report TR104, December 1982, 50 pages. We are building a computer system called ARGOT that acts as a computer operator conversing with a computer user. Since performance in this domain requires ARGOT to have efficient access to a large body of diverse knowledge, a major part of our research effort has been focused on issues of knowledge representation and retrieval. This paper describes ARGOT&apos;s representation language, the retriever used to access a knowledge base of sentences of the language, and how their design has been influenced by the task domain and system organization.</abstract>
<title confidence="0.9888645">A Connectionist Scheme for Modelling Word Sense Disambiguation</title>
<author confidence="0.999815">G W Cottrell</author>
<author confidence="0.999815">S I Small</author>
<affiliation confidence="0.999971">Computer Science Department University of Rochester</affiliation>
<address confidence="0.999604">Rochester, NY 14627</address>
<pubnum confidence="0.970201">Technical Report TR122.</pubnum>
<abstract confidence="0.979319590909091">Cognition and Brain Theory 6, 1 (1983): 89-120. This paper advocates the interdisciplinary development of a computational theory of human language comprehension and proposes a collection of initial constraints from which to start on such an enterprise. The constraints come from several disparate sources, including: (1) human physiology and language malfunctions; (2) human language behaviors under different processing conditions; (3) computational architectures for language comprehension; and (4) human and computer visual understanding. Our modeling effort thus employs an architecture significantly different from the typical computer and closer to that of the human brain. We use a particular spreading activation or semantic network scheme, called ism, which entails a massive number of appropriately connected computing units that communicate through weighted levels of excitation and inhibition. This paper surveys a number of fundamental language comprehension issues from the new perspective, and presents some simulation results of a parsing model based on these considerations.</abstract>
<title confidence="0.998458">The HORNE Reasoning System</title>
<author confidence="0.999852">M Giuliano</author>
<author confidence="0.999852">A M Frisch</author>
<affiliation confidence="0.999957">Computer Science Department University of Rochester</affiliation>
<address confidence="0.99959">Rochester, NY 14627</address>
<abstract confidence="0.99706325">Technical Report TR126, October 1983, â€” 60 pages. a programming system that offers a set of tools for building automated reasoning systems. It offers three major modes of inference: (1) a horn clause theorem prover (a backwards chaining mechanism); (2) a forward chaining mechanism; and (3) a constraint posting mechanism for restricting the range of variables. All three modes use a common representation of facts, namely horn clauses with universally quantified variables, and use the unification algorithm. In addition, they all share the following additional specialized reasoning capabilities: (1) variables may be typed with a fairly general type theory that allows intersecting types; (2) full reasoning about equality between ground terms, and limited equality reasoning for quantified terms; and (3) escapes into</abstract>
<intro confidence="0.363904">LISP for use as necessary. This paper contains an</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Eva-Maria M Mueckstein IBM Thomas J</author>
</authors>
<pages>10598</pages>
<institution>Watson Research Center</institution>
<location>Yorktown Heights, NY</location>
<marker>J, </marker>
<rawString>Eva-Maria M. Mueckstein IBM Thomas J. Watson Research Center Yorktown Heights, NY 10598</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eighth IJCAI</author>
</authors>
<date>1983</date>
<booktitle>Proc. Eighth IJCAI,</booktitle>
<volume>2</volume>
<pages>660</pages>
<institution>Bien Institute of Informatics Warsaw University</institution>
<location>Warszawa, Poland</location>
<marker>IJCAI, 1983</marker>
<rawString>Proc. Eighth IJCAI, August 1983, Vol. 2: 660 Jamusz S. Bien Institute of Informatics Warsaw University P.O.Box 1210 00-901 Warszawa, Poland Proc. Eighth IJCAI, August 1983, Vol. 2: 675 Word Formation in Natural Language Processing Systems</rawString>
</citation>
<citation valid="false">
<authors>
<author>Roy J Byrd IBM Thomas J</author>
</authors>
<title>Watson Research center Yorktown Heights,</title>
<pages>10598</pages>
<location>NY</location>
<marker>J, </marker>
<rawString>Roy J. Byrd IBM Thomas J. Watson Research center Yorktown Heights, NY 10598</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eighth IJCAI</author>
</authors>
<date>1983</date>
<booktitle>GR22, PARIS VI 4 Place Jussieu 75230 PARIS CEDEX 5 Proc. Eighth IJCAI,</booktitle>
<volume>2</volume>
<pages>704</pages>
<location>Gerard Sabah, Mohamed Rady</location>
<marker>IJCAI, 1983</marker>
<rawString>Proc. Eighth IJCAI, August 1983, Vol. 2: 704 Gerard Sabah, Mohamed Rady GR22, PARIS VI 4 Place Jussieu 75230 PARIS CEDEX 5 Proc. Eighth IJCAI, August 1983, Vol. 2: 707</rawString>
</citation>
<citation valid="false">
<authors>
<author>C Robert</author>
</authors>
<pages>02139</pages>
<institution>Berwick Artificial Intelligence Laboratory Massachusetts Instititute of Technology</institution>
<location>Cambridge, MA</location>
<marker>Robert, </marker>
<rawString>Robert C. Berwick Artificial Intelligence Laboratory Massachusetts Instititute of Technology Cambridge, MA 02139</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eighth IJCAI</author>
</authors>
<date>1983</date>
<journal>Narrative Complexity Based on Summarization Algorithms</journal>
<volume>2</volume>
<pages>710</pages>
<marker>IJCAI, 1983</marker>
<rawString>Proc. Eighth IJCAI, August 1983, Vol. 2: 710 Narrative Complexity Based on Summarization Algorithms</rawString>
</citation>
<citation valid="false">
<authors>
<author>G Wendy</author>
</authors>
<pages>01003</pages>
<institution>Lehnert Department of Computer and Information Science University of Massachusetts</institution>
<location>Amherst, MA</location>
<marker>Wendy, </marker>
<rawString>Wendy G. Lehnert Department of Computer and Information Science University of Massachusetts Amherst, MA 01003</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eighth IJCAI</author>
</authors>
<title>713 Japanese Language Semantic Analyzer Based on an Extended Case Frame Model Akira Shimazu, Syozo Naito, Hirosato Nomura Musashino Electrical Communication Laboratory,</title>
<date>1983</date>
<tech>N.T.T. 3-9-11,</tech>
<volume>2</volume>
<location>Midoricho, Musashino</location>
<marker>IJCAI, 1983</marker>
<rawString>Proc. Eighth IJCAI, August 1983, Vol. 2: 713 Japanese Language Semantic Analyzer Based on an Extended Case Frame Model Akira Shimazu, Syozo Naito, Hirosato Nomura Musashino Electrical Communication Laboratory, N.T.T. 3-9-11, Midoricho, Musashino</rawString>
</citation>
<citation valid="false">
<location>Tokyo, 180, Japan</location>
<marker></marker>
<rawString>Tokyo, 180, Japan</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eighth IJCAI</author>
</authors>
<title>Syntax. Semantics and Pragmatics in Concert: An Incremental, Multilevel Approach in Reconstructing Task-Oriented Dialogues</title>
<date>1983</date>
<volume>2</volume>
<pages>717</pages>
<marker>IJCAI, 1983</marker>
<rawString>Proc. Eighth IJCAI, August 1983, Vol. 2: 717 Syntax. Semantics and Pragmatics in Concert: An Incremental, Multilevel Approach in Reconstructing Task-Oriented Dialogues</rawString>
</citation>
<citation valid="false">
<authors>
<author>Manfred Gehrke</author>
</authors>
<title>Project &amp;quot;Prozedural Dialogmodelle&amp;quot;</title>
<institution>Department of Linguistics and Literature University of Bielefeld</institution>
<marker>Gehrke, </marker>
<rawString>Manfred Gehrke Project &amp;quot;Prozedural Dialogmodelle&amp;quot; Department of Linguistics and Literature University of Bielefeld</rawString>
</citation>
<citation valid="false">
<location>Bielefeld, FRG</location>
<marker></marker>
<rawString>Bielefeld, FRG</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eighth IJCAI</author>
</authors>
<title>721 Event Models for Recognition and Natural Language Description of events in Real-World Image Sequences</title>
<date>1983</date>
<volume>2</volume>
<marker>IJCAI, 1983</marker>
<rawString>Proc. Eighth IJCAI, August 1983, Vol. 2: 721 Event Models for Recognition and Natural Language Description of events in Real-World Image Sequences</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Neumann</author>
</authors>
<title>Hans-Joachim Novak Fachbereich Informatik</title>
<date></date>
<journal>Schulterstrasse</journal>
<volume>70</volume>
<pages>0--2000</pages>
<location>Hamburg 13, W.</location>
<marker>Neumann, </marker>
<rawString>Bernd Neumann, Hans-Joachim Novak Fachbereich Informatik Schulterstrasse 70 0-2000 Hamburg 13, W. Germany</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eighth IJCAI</author>
</authors>
<title>724 Automatic Construction of a Knowledge Base by Analysing Texts in Natural Language</title>
<date>1983</date>
<volume>2</volume>
<marker>IJCAI, 1983</marker>
<rawString>Proc. Eighth IJCAI, August 1983, Vol. 2: 724 Automatic Construction of a Knowledge Base by Analysing Texts in Natural Language</rawString>
</citation>
<citation valid="true">
<authors>
<author>Werner Frey</author>
</authors>
<title>Uwe Reyle, Christian Rohrer</title>
<date>1983</date>
<booktitle>Proc. Eighth IJCAI,</booktitle>
<volume>2</volume>
<pages>727</pages>
<institution>Department of Linguistics University of Stuttgart</institution>
<marker>Frey, 1983</marker>
<rawString>Werner Frey, Uwe Reyle, Christian Rohrer Department of Linguistics University of Stuttgart Proc. Eighth IJCAI, August 1983, Vol. 2: 727</rawString>
</citation>
<citation valid="false">
<authors>
<author>Why Good</author>
</authors>
<title>Writing Is Easier to Understand</title>
<journal>Brattle Research Corporation</journal>
<volume>6</volume>
<pages>02109</pages>
<institution>Faneuil Hall Market Place</institution>
<location>Boston, MA</location>
<marker>Good, </marker>
<rawString>Why Good Writing Is Easier to Understand John H. Clippinger, Jr. Brattle Research Corporation 6 Faneuil Hall Market Place Boston, MA 02109</rawString>
</citation>
<citation valid="false">
<authors>
<author>D David</author>
</authors>
<pages>01003</pages>
<institution>McDonald Department of Computer and Information Science University of Massachusetts</institution>
<location>Amherst, MA</location>
<marker>David, </marker>
<rawString>David D. McDonald Department of Computer and Information Science University of Massachusetts Amherst, MA 01003</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eighth IJCAI</author>
</authors>
<date>1983</date>
<volume>2</volume>
<pages>730</pages>
<marker>IJCAI, 1983</marker>
<rawString>Proc. Eighth IJCAI, August 1983, Vol. 2: 730</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>