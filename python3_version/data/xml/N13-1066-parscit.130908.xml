<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000097">
<title confidence="0.989734">
Processing Spontaneous Orthography
</title>
<author confidence="0.998985">
Ramy Eskander, Nizar Habash, Owen Rambow, and Nadi Tomeh
</author>
<affiliation confidence="0.9980955">
Center for Computational Learning Systems
Columbia University
</affiliation>
<email confidence="0.997536">
{reskander,habash,rambow,nadi}@ccls.columbia.edu
</email>
<sectionHeader confidence="0.997372" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998508461538462">
In cases in which there is no standard or-
thography for a language or language vari-
ant, written texts will display a variety of or-
thographic choices. This is problematic for
natural language processing (NLP) because it
creates spurious data sparseness. We study
the transformation of spontaneously spelled
Egyptian Arabic into a conventionalized or-
thography which we have previously proposed
for NLP purposes. We show that a two-stage
process can reduce divergences from this stan-
dard by 69%, making subsequent processing
of Egyptian Arabic easier.
</bodyText>
<sectionHeader confidence="0.999514" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999983909090909">
In areas with diglossia, vernacular spoken variants
(“low”) of a language family co-exist with a largely
written variant (“high”), which is often not spoken
as a native language. Traditionally, the low variants
have not been written: written language is reserved
for formal occasions and in those formal occasions
only the high variant is used. Prototypical exam-
ples of diglossia are the German speaking parts of
Switzerland, and the Arab world. The advent of the
internet has changed linguistic behavior: it is now
common to find written informal conversations, in
the form of email exchanges, text messages, Twit-
ter exchanges, and interactions on blogs and in web
forums. These written conversations are typically
written in the low variants (or in a mixture of low and
high), since conversations in the high variant seem
unnatural to the discourse participants. For natural
language processing (NLP), this poses many chal-
lenges, one of which is the fact that the low vari-
ants have not been written much in the past and
do not have a standard orthography which is gen-
erally agreed on by the linguistic community (and
perhaps sanctioned by an authoritative institution).
Instead, each discourse participant devises a spon-
taneous orthography, in which she chooses among
conventions from the high variant to render the spo-
ken language. We are thus faced with a large number
of ways to spell the same word, none of which can
be assumed as “standard” since there is no standard.
As a result, the increased data sparseness adds to the
challenges of NLP tasks such as machine transla-
tion, compared to languages for which orthography
is standardized.
In this paper, we work on Egyptian Arabic
(EGY). We follow the conventions which we have
previously proposed for the normalized orthogra-
phy for EGY (Habash et al., 2012), called CODA
(Conventional Orthography for Dialectal Arabic). In
this paper, we investigate how easy it is to con-
vert spontaneous orthography of EGY written in
Arabic script into CODA orthography automatically.
We will refer to this process as “normalization” or
“codafication”. We present a freely available system
called CODAFY, which we propose as a preproces-
sor for NLP modules for EGY. We show that a “do
nothing” baseline achieves a normalization perfor-
mance of 75.5%, and CODAFY achieves a normal-
ization performance of 92.4%, an error reduction of
69.2% over this baseline on an unseen test set.
The paper is structured as follows. We first re-
view relevant linguistic facts in Section 2 and then
present the conventionalized orthography we use in
this paper. After reviewing related work in Sec-
tion 4, we present our data (Section 5), our approach
(Section 6), and our results (Section 7). We conclude
</bodyText>
<page confidence="0.982326">
585
</page>
<note confidence="0.4862795">
Proceedings of NAACL-HLT 2013, pages 585–595,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.895433">
with a discussion of future work.
</bodyText>
<sectionHeader confidence="0.995599" genericHeader="introduction">
2 Linguistic Facts
</sectionHeader>
<subsectionHeader confidence="0.998412">
2.1 Writing without a Standard Orthography
</subsectionHeader>
<bodyText confidence="0.997775820512821">
An orthography is a specification of how the words
of a language are mapped to and from a particular
script (in our case, the Arabic script). In cases when
a standard orthography is absent, writers make deci-
sions about spontaneous orthography based on vari-
ous criteria. Most prominent among them is phonol-
ogy: how can my pronunciation of the word be
rendered in the chosen writing system, given some
(language-specific) assumptions about grapheme-to-
phoneme mapping? Often, these assumptions come
from the “high” variant of the language, or some re-
lated language. Another criterion for choosing or-
thography is a cognate in a related language or lan-
guage variant (Modern Standard Arabic or MSA,
the high variant for EGY), where a cognate pair is
a pair of words (or morphemes) in two languages
or language variants which are related by etymol-
ogy (in some unspecified manner) and which have
roughly the same meaning. Finally, the chosen
spontaneous orthography can be altered to reflect
speech effects, notably the lengthening of syllables
to represent emphasis or other effects (such asQ��J�J���_J»
ktyyyyr1 ‘very’).
It is important to distinguish typos from sponta-
neous orthography. We define spontaneous orthog-
raphy to be an intentional choice of graphemes to
render the words in a language or language variant.
We define a typographical error (typo) to be an un-
intended sequence of graphemes. For example, @Y»
kdA and èY»kdh can be intended spellings for EGY
/kida/ ‘like this’, while @Q»krA is not a plausible in-
tentional spelling since it neither relates /kida/ to an
MSA cognate, nor does the sequence of graphemes
represent the phonology of EGY using standard as-
sumptions. Instead, we can explain the spelling by
assuming that the writer accidentally substituted the
grapheme Pfor the grapheme X, which look some-
what alike and are near each other on some Arabic
keyboard layouts. Of course, when we encounter
</bodyText>
<footnote confidence="0.6184435">
1Arabic transliteration is presented in the Habash-Soudi-
Buckwalter scheme (Habash et al., 2007): (in alphabetical or-
der) Abt0jHxdðrzsšSDT ˇDS-yfqklmnhwy and the additional sym-
bols: ’ Z, Â I, Aˇ@�, A¯�@, wˆ j , yˆZø , h a, ý ø.
</footnote>
<bodyText confidence="0.992386333333333">
a specific spelling in a corpus, it can be, in certain
cases, difficult to determine whether it is a conscious
choice or a typo.
</bodyText>
<subsectionHeader confidence="0.755135">
2.2 Relevant Differences between EGY and
MSA
</subsectionHeader>
<bodyText confidence="0.997198875">
Lexical Variations Lexically, the number of differ-
ences is quite significant. For example, EGY &amp;quot;@QÓ
mrAt ‘wife [of]’ corresponds to MSA ak.ðP� zwjh. In
such cases of lexical difference, no cognate spelling
is available.
Phonological Variations There is an extensive
literature on the phonology of Arabic dialects (Wat-
son, 2002; Holes, 2004; Habash, 2010). Several
phonological differences exist between EGY and
MSA which relate to orthography. Here, we dis-
cuss one representative difference. The MSA con-
sonant H~ /O/ is pronounced as /t/ in EGY (or /s/
in more recent borrowings from MSA). For exam-
ple, MSAQ��ºK� ykOr ‘increase (imperfective)’ is pro-
nounced /yakOur/ in MSA versus /yiktar/ in EGY,
giving rise to the EGY phonological spelling Q��ºK�
yktr.
Morphological Variations There are a lot of
morphological differences between MSA and EGY.
For orthography, two differences are most relevant.
The MSA future proclitic /sa/+ (spelled +€ s+) ap-
pears in EGY as /ha/+ or /Ha/+. The two forms ap-
pear in free variation, and we have not been able
to find a variable that predicts which form is used
when. This variation is not a general phonological
variation between /h/ and /H/, we find it only in this
morpheme. Predictably, this leads to two spellings
in EGY: +h H+ and +-ë h+. Negation in EGY is
realized as the circum-clitic /m¯a/+ ... +/š/. The prin-
cipal orthographic question is whether the prefix is
a separate word or is part of the main word; both
variants are found.
</bodyText>
<sectionHeader confidence="0.999362" genericHeader="method">
3 CODA
</sectionHeader>
<bodyText confidence="0.9734302">
CODA is a conventionalized orthography for Arabic
dialects (Habash et al., 2012). In this section, we
summarize CODA so that the reader can understand
the goals of this paper. CODA has five key proper-
ties.
</bodyText>
<footnote confidence="0.480798">
1. CODA is an internally consistent and coherent
convention for writing DA: every word has a
</footnote>
<page confidence="0.98766">
586
</page>
<bodyText confidence="0.594609">
single orthographic rendering.
</bodyText>
<listItem confidence="0.9556207">
2. CODA is created for computational purposes.
3. CODA uses the Arabic script as used for MSA,
with no extra symbols from, for example, Per-
sian or Urdu.
4. CODA is intended as a unified framework for
writing all dialects. In this paper, we only dis-
cuss the instantiation of CODA for EGY.
5. CODA aims to maintain a level of dialectal
uniqueness while using conventions based on
similarities between MSA and the dialects.
</listItem>
<bodyText confidence="0.9901875">
We list some features of CODA relevant to this
paper.
Phonological Spelling CODA generally uses
phonological spelling for EGY (as MSA spelling
does for MSA).
Etymologically Spelled Consonants A limited
number of consonants may be spelled differently
from their phonology if the following two conditions
are met: (1) the consonant must be an EGY root
radical and (2) the EGY root must have a cognate
MSA root. If the conditions are met, then we spell
the consonant using the corresponding radical from
the cognate MSA root of the dialectal word’s root.
One such example is the spelling of the EGY verb
pronounced /kitir/ asQeTkθr ‘ it increased’.
Morphologically Faithful CODA preserves di-
alectal morphology and spells the dialectal mor-
phemes (clitics and inflections) phonologically. For
example, for the attachable future marker clitic, the
variant +h is chosen, not the MSA +€, so that
EGY /Hatiktar/ (and its variant /hatiktar/) are both
spelled Q��º:k Htkθr. The negation prefix and indi-
rect object pronoun (l+pronoun) suffixes are sepa-
rated, e.g., LrAêË 7,Ê�¯ AÓ mA qlt lhAš /ma’ultilh¯aš/ ‘I
did not tell her’.
Alif-Maqsura The letter ø ý is often used in
Egypt to write word-final ø y and vice versa (even
�
when writing MSA). In CODA, all rules for us-
ing Alif-Maqsura are the same as MSA. For exam-
ple, EGY /maSr¯ı/ ‘Egyptian’ can be seen in sponta-
neous orthography as øQå”Ó mSrý, but in CODA it
</bodyText>
<equation confidence="0.906559777777778">
is ø
Qå”Ó mSry.
Ta-Marbuta As in MSA, the Ta-Marbuta (S h) is
used morphemically in CODA. The Ta-Marbuta is
always written as S h� in CODA, e.g., /’arbaςa/ ‘four’
is aªK.P�@ Ârbςh in CODA, though it can be found as
�
éªK.P @ Ârbςh (or éªK.P@ Arbςh) in spontaneous orthog-
raphy.
</equation>
<bodyText confidence="0.997765">
Lexical Exceptions EGY CODA guidelines in-
clude a word list specifying ad hoc spellings of EGY
words that may be inconsistent with the default map-
ping outlined above. An example is /kida/ ‘like this’,
which we find as both @Y»kdA and èY»kdh in spon-
taneous orthography; the CODA spelling is èY»kdh.
</bodyText>
<sectionHeader confidence="0.999976" genericHeader="method">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999952294117647">
To our knowledge, this paper is the first to discuss
the task of automatically providing a conventional-
ized spelling for a written Arabic dialect text. While
there is no direct precedent, we discuss here some
related research.
Our proposed work has some similarity to auto-
matic spelling correction (ASC) and related tasks
such as post editing for optical character recogni-
tion (OCR). Our task is different from ASC since
ASC work assumes a standard orthography that the
writer is also assumed to aim for. Both supervised
and unsupervised approaches to this task have been
explored. Unsupervised approaches rely on improv-
ing the fluency of the text and reducing the percent-
age of out-of-vocabulary words using NLP tools, re-
sources, and heuristics, e.g., morphological analyz-
ers, language models, and edit-distance measure, re-
spectively (Kukich, 1992; Oflazer, 1996; Ben Oth-
mane Zribi and Ben Ahmed, 2003; Shaalan et al.,
2003; Haddad and Yaseen, 2007; Hassan et al.,
2008; Shaalan et al., 2010; Alkanhal et al., 2012).
Supervised approaches learn models of correction
by training on paired examples of errors and their
corrections. This data is hard to come by nat-
urally, though for applications such as OCR cor-
pora can be created from the application itself (Ko-
lak and Resnik, 2002; Magdy and Darwish, 2006;
Abuhakema et al., 2008; Habash and Roth, 2011).
There has been some work on conversion of di-
alectal Arabic to MSA. Al-Gaphari and Al-Yadoumi
(2010) introduced a rule-based method to convert
Sanaani dialect to MSA, and Shaalan et al. (2007)
used a rule-based lexical transfer approach to trans-
form from EGY to MSA. Similarly, both Sawaf
</bodyText>
<page confidence="0.984355">
587
</page>
<bodyText confidence="0.999534777777778">
(2010) and Salloum and Habash (2011) showed
that translating dialectal Arabic to MSA can im-
prove dialectal Arabic machine translation into En-
glish by pivoting on MSA. A common feature across
these conversion efforts is the use of morphological
analysis and morphosyntactic transformation rules
(for example, Al-Gaphari and Al-Yadoumi (2010)).
While all this work is similar to ours in that dialec-
tal input is processed, our output is still dialectal,
while the work on conversion aims for a transforma-
tion into MSA.
The work most closely related to ours is that of
Dasigi and Diab (2011). They identify the spelling
variants in a given document and normalize them.
However, they do not present a system that con-
verts spontaneous spelling to a pre-existing conven-
tion such as CODA, and thus their results cannot
be directly related to ours. Furthermore, their tech-
nique is different. First, similarity metrics based on
string difference are used to identify if two strings
are similar. Also, a contextual string similarity is
used based on the fact that if two words are ortho-
graphic variants of each other, then they are bound
to appear in similar contexts. After identifying the
similar strings, the strings of interest are modeled in
a vector space and clustered according to the simi-
larity of their vectors.
</bodyText>
<sectionHeader confidence="0.99689" genericHeader="method">
5 Data
</sectionHeader>
<bodyText confidence="0.9996823">
In this work, we use a manually annotated
EGY Arabic corpus, developed by the Linguis-
tic Data Consortium (LDC), and labeled as “ARZ”
(Maamouri et al., 2012), parts 1, 2, 3, 4 and 5.
The corpus consists of about 160K words (excluding
numbers and punctuations), and follows the part-of-
speech (POS) guidelines used by the LDC for Egyp-
tian Arabic. The corpus contains a full analysis of
Egyptian Arabic text in spontaneous orthography.
The analysis includes the correct CODA orthogra-
phy of the raw text, in addition to the full morpho-
logical/POS annotations.
Data Preparation We divide the ARZ corpus into
three parts: training, development and test, which
are of about 122K, 19K and 19K words, respec-
tively. We only consider the orthographic informa-
tion in the ARZ corpus: for every word in the cor-
pus, we retain the spontaneous orthographic form
and its CODA-compliant form.
We manually checked the CODA-compliant an-
notations for about 500 words in the development
corpus. We found that the accuracy of the gold an-
notations in this subset is about 93%. We performed
next an error analysis for the erroneous gold annota-
tions. About one half of the gold errors are CODA
phonological and orthographical errors. Examples
of the CODA phonological errors include wrong ad-
ditions and deletions of I A and S y, in addition to
the :)/)� t/0 transformations, and the transforma-
tions that correspond to the different phonological
forms of pronouncing the letter o h. The CODA or-
thographical errors are those errors where a word or-
thography looks the same as its pronunciation, while
it should not be, such as the o/:o h/h transformations.
One fifth of the gold errors are annotation typos,
such as writing :)I�gb:s qTwrAt instead of :)I�LL:s
qTArAt ‘trains’. Moreover, 9% of the gold errors are
wrong merges for the negation particle La mA and
the indirect object pronouns (l+pronouns). Since we
use the gold in our study, and given the error analy-
sis for the gold, we expect a qualitatively better gold
standard to yield better results.
Transformation Statistics We observe two types
of transformations when converting from sponta-
neous orthography to CODA: character substitu-
tions that do not affect the word length, and charac-
ter additions/deletions that change the word length.
Tables 1 and 2 show the most common character
substitution and addition/deletion transformations,
respectively, as they appear in the training corpus,
associated with their frequencies relative to the oc-
currence of transformations. The character sub-
stitutions are dominant, and constitute about 84%
of all the transformations in the training corpus.
While the classification of the character substitu-
tions is automatically generated, the classification of
the character additions/deletions is done manually
using a random sample of 400 additions/deletions
in the training corpus. This is because many addi-
tions/deletions are ambiguous.
</bodyText>
<sectionHeader confidence="0.996451" genericHeader="method">
6 Approach
</sectionHeader>
<bodyText confidence="0.999952333333333">
We describe next the various approaches for spon-
taneous orthography codafication. Our codafication
techniques fall into two main categories: contex-
</bodyText>
<page confidence="0.99388">
588
</page>
<table confidence="0.999390375">
Transformation Frequency %
����
@/@/@�/@ A/Â/�A/A¯ ⇔ @/@/@�/@ A/Â/�A/A¯ 38.5
ø� y ⇔ ø ý 29.7
è h ⇔ a n 16.9
è h ⇔ h H 2.5
H�0 ⇔ u/€ t/s 1.0
@ A ⇔ è h 0.7
�
†� � 0.4
q ⇔ @/@/@/@/Z/ð /Zø A/Â/ A/¯A/’/w/y
ð w ⇔ è h 0.3
X�ð ⇔ X/P�d/z 0.3
a n ⇔ H�t 0.3
@ A ⇔ a n 0.2
• D ⇔ X/Y � d/z/D� 0.2
</table>
<tableCaption confidence="0.9647485">
Table 1: Spontaneous to CODA character substitu-
tion transformations
</tableCaption>
<table confidence="0.9999561">
Transformation Frequency %
Errors in closed class words 22.0
Missing space after AÓ/B/AK� mA/lA/yA 19.0
@ A additions &amp; deletions 16.8
Gold errors 10.3
Speech effects 8.5
Missing space before È l (+pron) 8.5
ð/è/@ð w/h/wA ⇔ ð/è/@ð w/h/wA 8.3
ø 3.0
y additions &amp; deletions
</table>
<tableCaption confidence="0.975336">
Table 2: Spontaneous to CODA character addi-
tion/deletion transformations
</tableCaption>
<bodyText confidence="0.7248595">
tual and non-contextual, where the non-contextual
approaches are a lot faster than the contextual ones.
</bodyText>
<subsectionHeader confidence="0.99317">
6.1 Speech Effect Handling
</subsectionHeader>
<bodyText confidence="0.973189125">
Before applying any codafication techniques, we
perform a special preprocessing step for speech ef-
fects, which represent redundant repetitions of some
letter in sequence. Sometimes people intend these
repetitions to show affirmation or intensification.
This is simply handled by removing the repetitions
when a letter is repeated more than twice in a row,
except for some letters whose repetitions for more
than once indicates a speech effect; these letters
�
are @ A, @ A, Z ’, Zø y, ø ý and S h. Handling
speech effects on its own corrects about 2% of the
non-CODA spontaneous orthography to its CODA-
compliant form, without introducing any new errors.
In all experiments we report in this paper, we have
initially processed speech effects.
</bodyText>
<subsectionHeader confidence="0.996803">
6.2 Character Edit Classification (CEC)
</subsectionHeader>
<bodyText confidence="0.999981222222222">
In this approach, a set of transformations is applied
on a character level, where a character may receive
a change or not. As a result, a word changes if one
or more of its characters is changed. The output of
these transformations is what constitutes the CODA
orthography. This is a surface modeling technique
that does not depend on the word context (though it
does depend on character context inside the word).
First, we train classifiers for the most frequent
transformations from EGY spontaneous orthogra-
phy to the corresponding CODA, listed in Tables 1
and 2 in Section 5. Second, we apply the trained
classifiers to generate the CODA output.
Training the classifiers For each transformation
listed in the data section, we train a separate classi-
fier. The classifiers are trained on our training cor-
pus using the k-nearest neighbor algorithm (k-NN)
(Wang et al., 2000), which is a method for classi-
fying objects based on the closest training examples
in the feature space. We did experiments using the
other classification methods included in the WEKA
machine learning tool (Hall et al., 2009), including
SVMs, Naïve Bayes, and decision trees. However,
k-NN gives the best results for our problem.
In the training process, a set of nine static features
is applied, which are the character that is queried for
the transformation with its preceding and following
two characters (a special token indicates a character
position that does not exist because it is beyond the
word boundary), along with the first two and the last
two characters in the underlying word.
In this model, each data point is a character, where
a classifier determines whether a character should
receive a substitution, deletion, or addition of an-
other character. The effect of each classifier is ex-
amined separately on the development set. We then
determine for each classification whether it helps or
weakens the process by comparing its effect to the
baseline which is doing nothing, i.e., no change to
a word occurs. Those classifiers that on their own
perform worse than the baseline are eliminated. For
eliminating the classifiers, we examine them in a de-
scending order according to the frequencies of their
corresponding transformations. We now discuss the
seven classifiers we retain in our system:
</bodyText>
<page confidence="0.993668">
589
</page>
<bodyText confidence="0.982725">
The classifier can change any @ A form into any
other @ A form. The arbitrary selection of the
</bodyText>
<listItem confidence="0.9211597">
different @ A forms represents the most frequent
divergence from CODA in Arabic spontaneous
orthography.
2. The ø/ø y/ý classifier. The classifier handles
�
transformations between ø
y and ø ý in both
directions, as their selection is mostly arbitrary
in EGY spontaneous orthography.
3. The è/0/ð h/h//w classifier. The classifier han-
</listItem>
<bodyText confidence="0.994004533333333">
dles transformations between è h, o h� and ð w
in both directions. These transformations are
likely to happen at word endings, since they
represent common misspellings in writing è h,
S h� and ð w, where è h is often substituted for
the graphically similar o h, and è h andð w can
both be used to represent the 3rd person mascu-
line singular accusative or genitive clitic. (Note
that in Table 1, we list transformations between
è h and o h� as well as between è h and ð w; the
remaining transformations are not frequent.)
4. The è/h h/H classifier. The transformation
from è h to h H is likely to happen at word
beginnings, since it represents a common devi-
ation in writing the h H future particle.
</bodyText>
<sectionHeader confidence="0.665272" genericHeader="method">
5. The @ A deletion classifier. The classifier han-
</sectionHeader>
<bodyText confidence="0.99786075">
dles the deletion of extra @ A at some positions,
which is a common deviation in EGY sponta-
neous orthography, where the CODA orthog-
raphy requires only short vowels instead.
</bodyText>
<sectionHeader confidence="0.90652" genericHeader="method">
6. The @ A addition classifier. The classifier han-
</sectionHeader>
<bodyText confidence="0.991456888888889">
dles the addition of @ A in some positions, where
it is mostly omitted in EGY spontaneous or-
thography, such as adding @ A after the h H fu-
ture particle and the H. b progressive particle
(when used with the 1st person singular imper-
fective), as well as the ð w plural pronoun at
word endings. When training this classifier, we
target the letter after which the @ A should be
added.
7. The space addition classifier. The classifier
handles the addition of spaces in the middle
of words, i.e., splitting a word into two words.
This is required to add spaces after AÓ/B/AK�
mA/lA/yA for negation and vocation, and be-
fore the indirect object l+pronoun, so that the
text becomes CODA-compliant.
Generating CODA Orthography Next, we ap-
ply the trained classifiers on the spontaneous-
orthography text. Each classifier determines a set
of character corrections, where the characters may
receive transformations corresponding to those on
which the classifier is trained. The classifiers are
independent of one another, so their order of appli-
cation is irrelevant.
By way of example, we apply the classifiers on the
word éªK.P@ Arbςh, ‘four’. The first classifier, corre-
sponding to the different @ A forms, determines the
</bodyText>
<page confidence="0.676221">
6
</page>
<bodyText confidence="0.990238555555556">
transformation of @ A to @ Â, while the è/o h/h clas-
sifier determines the correction of è h to o h. The
other classifiers are either not involved since they do
not work on any of the word characters, or they de-
termine that no character transformation should hap-
pen for this word. Thus applying the CEC tech-
nique in this case changes the word éªK.P@ Arbςh to
�
@ Ârbςh, which is the correct CODA form.
</bodyText>
<subsectionHeader confidence="0.998027">
6.3 Maximum Likelihood Estimate (MLE)
</subsectionHeader>
<bodyText confidence="0.999969933333333">
Another surface modeling approach for spontaneous
orthography codafication is to use a maximum like-
lihood model that operates on the word level. In this
approach, we build a unigram model that replaces
every word in the spontaneous orthography with its
most likely CODA form as seen in the training data.
This assumes that the underlying word exists in the
training corpus. For unseen words, the technique
keeps them with no change.
The MLE approach chooses the correct CODA
form for most of the words seen in training, making
this approach highly dependent on the training data.
It is efficient at correcting common misspellings in
frequent words, especially those that are from closed
classes.
</bodyText>
<subsectionHeader confidence="0.998482">
6.4 Morphological Tagger
</subsectionHeader>
<bodyText confidence="0.999610333333333">
In addition to the approaches discussed above, we
use a morphological tagger, MADAARZ (Mor-
phological Analysis and Disambiguation for Egyp-
</bodyText>
<figure confidence="0.994903666666667">
1. The different @ A form (@/
�
@/@�/@ A/Â /ˇA/¯A) classifier.
�
éªK
~.P
</figure>
<page confidence="0.990451">
590
</page>
<bodyText confidence="0.945433866666667">
tian Arabic) (Habash et al., 2013). Although
MADAARZ is originally developed to work as a
morphological tagger, it still can help the codafica-
tion process, since the choice of a full morpholog-
ical analysis for a word in context determines its
CODA spelling. Therefore, MADAARZ is able to
correct many word misspellings that are common in
spontaneous orthography. These corrections include
��
(@/@/@�/@ A/Â/ ˇA/¯A), ø
/ø y/ý and è/S h/h transforma-
tions. However, MADAARZ, as a codafication tech-
nique, uses the context of the word, which makes
it a contextual modeling approach unlike CEC and
MLE. It is much slower than they are.
</bodyText>
<subsectionHeader confidence="0.972824">
6.5 Combined Techniques
</subsectionHeader>
<bodyText confidence="0.99996225">
The CEC and MLE techniques can be applied
alone, or they can be applied together in a pipeline in
either order. This gives a total of four possible com-
binations. Next, we conducted experiments with
MADAARZ, running alone and as a pre- or postpro-
cessor for a combination of CEC and/or MLE. In
all cases, when we first apply one module and then
another on the output of the first, we train the sec-
ond module on the training corpus which has been
passed through the first module. The results of run-
ning the different codafication approaches are dis-
cussed next.
</bodyText>
<sectionHeader confidence="0.999753" genericHeader="evaluation">
7 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.999483">
7.1 Accuracy Evaluation
</subsectionHeader>
<bodyText confidence="0.999782984615385">
The different codafication approaches, discussed in
the previous section, are tested against the develop-
ment set, which was not used as part of our train-
ing. The evaluation metric we use is a word accuracy
metric, i.e., we evaluate how well we can correctly
predict the CODA form of the input spontaneous or-
thography.
Table 3 lists the effects of using the different
codafication approaches. For each approach, two
numbers are reported; exact and normalized. In
the exact evaluation, the output of the codafica-
tion approach is exactly matched against the correct
CODA orthography, while in the normalized eval-
uation, the match is relaxed for the (@/@/@�/@ A/Â/ˇA/¯A)
and ø
/ø y/ý alternations, i.e., these differences do
not count as errors. In many NLP applications (such
as machine translation), the input is normalized for
these two phenomena, so that the normalized evalu-
ation gives a sense of the relevance of codafication
to downstream processes which normalize.
In this evaluation we compare our different
codafication techniques, CEC, MLE, CEC+MLE
and MLE+CEC, against the baseline. We also show
the effect of using MADAARZ as a codafication sys-
tem. We see that MLE on its own outperforms CEC.
Running CEC first and then MLE gives us our best
result using surface techniques, namely 91.5%, for
an error reduction of 63.4% against the baseline.
This configuration also gives the highest normalized
accuracy of 95.2%, for an error reduction of 49.5%
against the baseline.
We now turn to deep modeling techniques.
The performance of MADAARZ on its own as a
codafication system is close to the performance of
CEC+MLE, by which it is outperformed in the
exact-match accuracy by 0.4%.
The best deep modeling (and the best overall)
performance is achieved when running MADAARZ
on top of MLE. This gives the highest accuracy
of 92.6% (exact) and 95.8% (normalized), for er-
ror reductions of 68.1% (exact) and 55.8% (nor-
malized) against the baseline, respectively. Note
that the non-contextual modeling techniques CEC
(5,584 words/sec) and MLE (6,698 words/sec)
are a lot faster than the deep modeling tech-
nique MADAARZ (53 words/sec), while their com-
bination CEC+MLE+MADAARZ is the slowest
among all the approaches, operating at a rate of 52
words/sec. Thus, a small drop in accuracy results in
a large increase in speed.
We also evaluated using MADAMSA (v 3.2)
(Morphological Analysis and Disambiguation for
MSA) (Habash and Rambow, 2005; Habash et al.,
2010). MADAMSA is able to do some codafication,
but it performs far worse than our codafication ap-
proaches.
Table 4 lists the results of the best perform-
ing codafication surface approach, CEC+MLE, and
deep approach, MLE+MADAARZ, when applied
on the test set, which was not used as part of our
training or development, i.e., a completely blind
test. We see that on the test set, the addition
of MADAARZ improves results relatively more as
compared to the development set.
</bodyText>
<page confidence="0.993904">
591
</page>
<table confidence="0.999966133333333">
Approach Exact Match Norm Match w/s
Acc% ER% Acc% ER%
Baseline 76.8 90.5
MADAMSA 83.6 29.3 91.7 12.6 70
CEC 90.0 56.9 93.9 35.8 5,584
MLE 90.5 59.1 94.6 43.2 6,698
CEC+MLE 91.5 63.4 95.2 49.5 4,284
MLE+CEC 90.7 59.9 94.7 44.2 4,284
MADAARZ 91.1 61.6 95.2 49.5 53
MADAARZ+CEC 91.5 63.4 95.4 51.6 53
MADAARZ+MLE 91.9 65.1 95.8 55.8 53
CEC+MADAARZ 92.2 66.4 95.6 53.7 53
MLE+MADAARZ 92.6 68.1 95.8 55.8 53
MADAARZ+CEC+MLE 91.8 64.7 95.6 53.7 52
CEC+MLE+MADAARZ 92.0 65.5 95.8 55.8 52
</table>
<tableCaption confidence="0.99684">
Table 3: Comparison of the performance of the different codafication approaches on the development corpus.
Acc stands for Accuracy; ER is error reduction against the Baseline. w/s is speed (words/sec).
</tableCaption>
<table confidence="0.999947">
Approach Exact Match Norm Match
Acc% ER% Acc% ER%
Baseline 75.5 89.7
CEC+MLE 91.3 64.5 94.8 49.5
MLE+MADAARZ 92.9 71.0 95.5 56.3
</table>
<tableCaption confidence="0.994937">
Table 4: Comparison of the performance of the
</tableCaption>
<bodyText confidence="0.841526333333333">
different codafication approaches on the test cor-
pus. Acc stands for Accuracy; ER is error reduction
against the Baseline.
</bodyText>
<subsectionHeader confidence="0.996575">
7.2 Extrinsic Evaluation
</subsectionHeader>
<bodyText confidence="0.999891558139535">
Morphological Analysis We tested the effect of
codafication on morphological tagging, specifically
full POS and lemma determination in context by
the morphological tagger MADAARZ. Here, we
are evaluating MADAARZ not on its conversion
to CODA (as above), but on its core functional-
ity, namely morphological tagging. We compare
the performance of MADAARZ against running
CEC+MLE+MADAARZ. When tested on the de-
velopment set, the initial CEC+MLE codafication
step helps MADAARZ improve the identification
of the complete Arabic (Buckwalter) POS tag from
84% to 85.3%, for an error reduction of 8.1%, while
the correct lemma choice increases from 85.2% to
85.7%, for an error reduction of 3.4%. When tested
on the test set, we get improvements on the choice
of the complete Buckwalter POS tag and lemma
from 84.5% to 85.4% (5.8% error reduction) and
from 86.3% to 86.7% (2.9% error reduction), re-
spectively.
Arabic to English MT The goal of this exper-
iment is to test the effect of codafication on ma-
chine translation from dialectal Arabic to English.
We use the open-source Moses toolkit (Koehn et
al., 2007) to build a phrase-based SMT system. We
use MGIZA++ for word alignment (Gao and Vogel,
2008). Phrase translations of up to 8 words are ex-
tracted in the phrase table. We use SRILM (Stol-
cke, 2002) with modified Kneser-Ney smoothing to
build two 4-gram language models. The first model
is trained on the English side of the bitext, while
the other is trained on the English Gigaword data.
Feature weights are tuned to maximize BLEU (Pap-
ineni et al., 2002) on a development set using MERT
(Och, 2003). We perform case-insensitive evalua-
tion in terms of the BLEU metric.
We train the system on dialectal Arabic-English
parallel data, obtained from several LDC corpora,
which amounts to -500k sentences with 3.8M unto-
kenized words on the Arabic side. The development
set, used for tuning the parameters of the MT sys-
tem, has 1,547 sentences with 15,585 untokenized
Arabic words. The test set has 1,065 sentences with
</bodyText>
<page confidence="0.991912">
592
</page>
<bodyText confidence="0.998454058823529">
12,116 untokenized Arabic words. Both develop-
ment and test sets have two reference translations
each. The English data is lower-cased and tokenized
using simple punctuation-based rules.
We build two systems which vary in preprocess-
ing of the Arabic text. The baseline system ap-
plies only simple punctuation-based rules. The sec-
ond system applies our codafication in addition to
punctuation separation. The Arabic text is Alif/Ya
normalized and is kept untokenized in both set-
tings. The baseline system achieves a BLEU score
of 22.1%. The system using codafication obtains a
BLEU score of 22.6%, and outperforms the baseline
by 0.5% absolute BLEU points. This result shows
that improvements observed in intrinsic evaluation
of codafication carry on to the extrinsic task of ma-
chine translation.
</bodyText>
<subsectionHeader confidence="0.810787">
7.3 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999981133333333">
We conducted an error analysis for the best perform-
ing codafication approach on the development set.
The most frequent error types are listed in Table 5.
About two thirds of the errors are CODA phonolog-
ical and orthographical errors, denoted by CODA-
Phon and CODA-Orth, respectively. The wrong ad-
ditions and deletions of I A and S y and the u/u t/O
transformations are examples of CODA phonologi-
cal errors. The CODA orthographic errors include
cases such as the S/S y/ý transformations. 21% of
the errors are not real errors in the codafication out-
put, but result from gold errors. Finally, about 13%
of the errors are wrong merges and splits for the the
negation particle lA mA, the vocative particle l�� yA
and the indirect-object l+pronouns.
</bodyText>
<sectionHeader confidence="0.994841" genericHeader="conclusions">
8 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999967111111111">
We have presented the problem of transforming
spontaneous orthography of the Egyptian Arabic di-
alect into a conventionalized form, CODA. Our best
technique involves a combination of character trans-
formations, whole-word transformations, and the
use of a full morphological tagger. The tagger can
be omitted for a small decrease in performance and
a large increase in speed.2 In future work, we plan
to extend our approach to other Arabic dialects. We
</bodyText>
<footnote confidence="0.6838115">
2Our system will be freely available. Please contact the au-
thors for more information.
</footnote>
<table confidence="0.999906916666667">
Error Type Description Percentage
Gold Error Annotation Error 21.0
CODA-Orth 13.7
� h ⇔ �� ��
CODA-Phon I A → e 8.7
Merge lA mA/NEG_PART 7.3
CODA-Phon a → Sy 6.8
CODA-Phon e → I A 5.9
CODA-Orth S y ⇔ S ý 4.1
Merge l�� yA/VOC_PART 3.7
CODA-Phon o h ⇔ � H 3.2
CODA-Phon S y ⇔ S ý 3.2
</table>
<tableCaption confidence="0.9604805">
Table 5: System Error Analysis: the most frequent
error types.
</tableCaption>
<bodyText confidence="0.995309333333333">
will also investigate incorporating the unsupervised
work of Dasigi and Diab (2011) into our algorithm,
as well as other unsupervised techniques.
</bodyText>
<sectionHeader confidence="0.975455" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.999823444444444">
This paper is based upon work supported by
the Defense Advanced Research Projects Agency
(DARPA) under Contract No. HR0011-12-C-0014.
Any opinions, findings and conclusions or recom-
mendations expressed in this paper are those of the
authors and do not necessarily reflect the views of
DARPA. We thank three anonymous reviewers for
helpful comments, and Ryan Roth for help with run-
ning MADA.
</bodyText>
<page confidence="0.998464">
593
</page>
<sectionHeader confidence="0.996293" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999513925233645">
G. Abuhakema, R. Faraj, A. Feldman, and E. Fitzpatrick.
2008. Annotating an Arabic Learner Corpus for Er-
ror. Proceedings of the Sixth International Language
Resources and Evaluation (LREC’08).
G Al-Gaphari and M Al-Yadoumi. 2010. A method
to convert Sana’ani accent to Modern Standard Ara-
bic. International Journal of Information Science and
Management, pages 39–49.
Mohamed I. Alkanhal, Mohammed A. Al-Badrashiny,
Mansour M. Alghamdi, and Abdulaziz O. Al-
Qabbany. 2012. Automatic Stochastic Arabic
Spelling Correction With Emphasis on Space Inser-
tions and Deletions. IEEE Transactions on Audio,
Speech &amp; Language Processing, 20:2111–2122.
Chiraz Ben Othmane Zribi and Mohammed Ben Ahmed.
2003. Efficient Automatic Correction of Misspelled
Arabic Words Based on Contextual Information. In
Proceedings of the Knowledge-Based Intelligent Infor-
mation and Engineering Systems Conference, Oxford,
UK.
Pradeep Dasigi and Mona Diab. 2011. CODACT: To-
wardsIdentifying Orthographic Variants in Dialectal
Arabic. In Proceedings of the 5th International Joint
Conference on Natural Language Processing, pages
318–326, Chaing Mai, Thailand.
Qin Gao and Stephan Vogel. 2008. Parallel implemen-
tations of word alignment tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, SETQA-NLP ’08, pages 49–57,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Nizar Habash and Owen Rambow. 2005. Arabic Tok-
enization, Part-of-Speech Tagging and Morphological
Disambiguation in One Fell Swoop. In Proceedings of
the 43rd Annual Meeting of the Association for Com-
putational Linguistics (ACL’05), pages 573–580, Ann
Arbor, Michigan.
Nizar Habash and Ryan Roth. 2011. Using deep mor-
phology to improve automatic error detection in ara-
bic handwriting recognition. In Proceedings of the
49th Annual Meeting of the Association for Compu-
tational Linguistics: Human Language Technologies,
pages 875–884, Portland, Oregon, USA, June. Associ-
ation for Computational Linguistics.
Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.
2007. On Arabic Transliteration. In A. van den Bosch
and A. Soudi, editors, Arabic Computational Mor-
phology: Knowledge-based and Empirical Methods.
Springer.
Nizar Habash, Owen Rambow, and Ryan Roth. 2010.
MADA+TOKAN Manual. Technical Report CCLS-
10-01, Center for Computational Learning Systems
(CCLS), Columbia University.
Nizar Habash, Mona Diab, and Owen Rabmow. 2012.
Conventional Orthography for Dialectal Arabic. In
Proceedings of the Language Resources and Evalua-
tion Conference (LREC), Istanbul.
Nizar Habash, Ryan Roth, Owen Rambow, Ramy Eskan-
der, and Nadi Tomeh. 2013. Morphological Analysis
and Disambiguation for Dialectal Arabic. In Proceed-
ings of the 2013 Conference of the North American
Chapter of the Association for Computational Linguis-
tics: Human Language Technologies (NAACL-HLT),
Atlanta, GA.
Nizar Habash. 2010. Introduction to Arabic Natural
Language Processing. Morgan &amp; Claypool Publish-
ers.
Bassam Haddad and Mustafa Yaseen. 2007. Detection
and Correction of Non-Words in Arabic: A Hybrid
Approach. International Journal of Computer Pro-
cessing Of Languages (IJCPOL).
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The weka data mining software: an update.
SIGKDDExplor. Newsl., 11(1):10–18.
Ahmed Hassan, Sara Noeman, and Hany Hassan. 2008.
Language Independent Text Correction using Finite
State Automata. In Proceedings of the International
Joint Conference on Natural Language Processing
(IJCNLP 2008).
Clive Holes. 2004. Modern Arabic: Structures, Func-
tions, and Varieties. Georgetown Classics in Ara-
bic Language and Linguistics. Georgetown University
Press.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Christo-
pher Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine
Moran, Richard Zens, Christopher Dyer, Ondrej Bo-
jar, Alexandra Constantin, and Evan Herbst. 2007.
Moses: open source toolkit for statistical machine
translation. In Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguistics
Companion Volume Proceedings of the Demo and
Poster Sessions, pages 177–180, Prague, Czech Re-
public.
Okan Kolak and Philip Resnik. 2002. OCR error cor-
rection using a noisy channel model. In Proceedings
of the second international conference on Human Lan-
guage Technology Research.
Karen Kukich. 1992. Techniques for Automatically
Correcting Words in Text. ACM Computing Surveys,
24(4).
Mohamed Maamouri, Ann Bies, Seth Kulick, Dalila
Tabessi, and Sondos Krouna. 2012. Egyptian Arabic
Treebank Pilot.
Walid Magdy and Kareem Darwish. 2006. Arabic OCR
Error Correction Using Character Segment Correction,
</reference>
<page confidence="0.985507">
594
</page>
<reference confidence="0.999530529411765">
Language Modeling, and Shallow Morphology. In
Proceedings of 2006 Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP 2006),
pages 408–414, Sydney, Austrailia.
Franz Josef Och. 2003. Minimum Error Rate Training
for Statistical Machine Translation. In Proceedings
of the 41st Annual Conference of the Association for
Computational Linguistics, pages 160–167, Sapporo,
Japan.
Kemal Oflazer. 1996. Error-tolerant finite-state recog-
nition with applications to morphological analysis
and spelling correction. Computational Linguistics,
22:73–90.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic Eval-
uation of Machine Translation. In Proceedings of the
40th Annual Meeting of the Association for Computa-
tional Linguistics, pages 311–318, Philadelphia, PA.
Wael Salloum and Nizar Habash. 2011. Dialectal
to Standard Arabic Paraphrasing to Improve Arabic-
English Statistical Machine Translation. In Proceed-
ings of the First Workshop on Algorithms and Re-
sources for Modelling of Dialects and Language Va-
rieties, pages 10–21, Edinburgh, Scotland.
Hassan Sawaf. 2010. Arabic dialect handling in hybrid
machine translation. In Proceedings of the Confer-
ence of the Association for Machine Translation in the
Americas (AMTA), Denver, Colorado.
Khaled Shaalan, Amin Allam, and Abdallah Gomah.
2003. Towards Automatic Spell Checking for Ara-
bic. In Conference on Language Engineering, ELSE,
Cairo, Egypt.
K. Shaalan, Abo Bakr, and I. H. Ziedan. 2007. Transfer-
ring Egyptian Colloquial into Modern Standard Ara-
bic. In International Conference on Recent Advances
in Natural Language Processing (RANLP), Borovets,
Bulgaria.
K. Shaalan, R. Aref, and A. Fahmy. 2010. An approach
for analyzing and correcting spelling errors for non-
native Arabic learners. Proceedings of Informatics
and Systems (INFOS).
Andreas Stolcke. 2002. SRILM - an Extensible Lan-
guage Modeling Toolkit. In Proceedings of the Inter-
national Conference on Spoken Language Processing
(ICSLP), volume 2, pages 901–904, Denver, CO.
Jun Wang, Zucker, and Jean-Daniel. 2000. Solving
multiple-instance problem: A lazy learning approach.
In Pat Langley, editor, 17th International Conference
on Machine Learning, pages 1119–1125.
Janet C. E. Watson. 2002. The Phonology and Morphol-
ogy of Arabic. Oxford University Press.
</reference>
<page confidence="0.998675">
595
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.561091">
<title confidence="0.994207">Processing Spontaneous Orthography</title>
<author confidence="0.962314">Ramy Eskander</author>
<author confidence="0.962314">Nizar Habash</author>
<author confidence="0.962314">Owen Rambow</author>
<author confidence="0.962314">Nadi</author>
<affiliation confidence="0.8129945">Center for Computational Learning Columbia</affiliation>
<email confidence="0.999833">reskander@ccls.columbia.edu</email>
<email confidence="0.999833">habash@ccls.columbia.edu</email>
<email confidence="0.999833">rambow@ccls.columbia.edu</email>
<email confidence="0.999833">nadi@ccls.columbia.edu</email>
<abstract confidence="0.994937714285714">In cases in which there is no standard orthography for a language or language variant, written texts will display a variety of orthographic choices. This is problematic for natural language processing (NLP) because it creates spurious data sparseness. We study the transformation of spontaneously spelled Egyptian Arabic into a conventionalized orthography which we have previously proposed for NLP purposes. We show that a two-stage process can reduce divergences from this standard by 69%, making subsequent processing of Egyptian Arabic easier.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Abuhakema</author>
<author>R Faraj</author>
<author>A Feldman</author>
<author>E Fitzpatrick</author>
</authors>
<title>Annotating an Arabic Learner Corpus for Error.</title>
<date>2008</date>
<booktitle>Proceedings of the Sixth International Language Resources and Evaluation (LREC’08).</booktitle>
<contexts>
<context position="11605" citStr="Abuhakema et al., 2008" startWordPosition="1903" endWordPosition="1906"> NLP tools, resources, and heuristics, e.g., morphological analyzers, language models, and edit-distance measure, respectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) used a rule-based lexical transfer approach to transform from EGY to MSA. Similarly, both Sawaf 587 (2010) and Salloum and Habash (2011) showed that translating dialectal Arabic to MSA can improve dialectal Arabic machine translation into English by pivoting on MSA. A common feature across these conversion efforts is the use of morphological analysis and morphosyntactic transform</context>
</contexts>
<marker>Abuhakema, Faraj, Feldman, Fitzpatrick, 2008</marker>
<rawString>G. Abuhakema, R. Faraj, A. Feldman, and E. Fitzpatrick. 2008. Annotating an Arabic Learner Corpus for Error. Proceedings of the Sixth International Language Resources and Evaluation (LREC’08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Al-Gaphari</author>
<author>M Al-Yadoumi</author>
</authors>
<title>A method to convert Sana’ani accent to Modern Standard Arabic.</title>
<date>2010</date>
<journal>International Journal of Information Science and Management,</journal>
<pages>39--49</pages>
<contexts>
<context position="11730" citStr="Al-Gaphari and Al-Yadoumi (2010)" startWordPosition="1924" endWordPosition="1927">espectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) used a rule-based lexical transfer approach to transform from EGY to MSA. Similarly, both Sawaf 587 (2010) and Salloum and Habash (2011) showed that translating dialectal Arabic to MSA can improve dialectal Arabic machine translation into English by pivoting on MSA. A common feature across these conversion efforts is the use of morphological analysis and morphosyntactic transformation rules (for example, Al-Gaphari and Al-Yadoumi (2010)). While all this work is similar to ours in that dialectal input i</context>
</contexts>
<marker>Al-Gaphari, Al-Yadoumi, 2010</marker>
<rawString>G Al-Gaphari and M Al-Yadoumi. 2010. A method to convert Sana’ani accent to Modern Standard Arabic. International Journal of Information Science and Management, pages 39–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed I Alkanhal</author>
<author>Mohammed A Al-Badrashiny</author>
<author>Mansour M Alghamdi</author>
<author>Abdulaziz O AlQabbany</author>
</authors>
<title>Automatic Stochastic Arabic Spelling Correction With Emphasis on Space Insertions and Deletions.</title>
<date>2012</date>
<journal>IEEE Transactions on Audio, Speech &amp; Language Processing,</journal>
<pages>20--2111</pages>
<contexts>
<context position="11291" citStr="Alkanhal et al., 2012" startWordPosition="1850" endWordPosition="1853">s different from ASC since ASC work assumes a standard orthography that the writer is also assumed to aim for. Both supervised and unsupervised approaches to this task have been explored. Unsupervised approaches rely on improving the fluency of the text and reducing the percentage of out-of-vocabulary words using NLP tools, resources, and heuristics, e.g., morphological analyzers, language models, and edit-distance measure, respectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) used a rule-based lexical transfer approach to transform from EGY to</context>
</contexts>
<marker>Alkanhal, Al-Badrashiny, Alghamdi, AlQabbany, 2012</marker>
<rawString>Mohamed I. Alkanhal, Mohammed A. Al-Badrashiny, Mansour M. Alghamdi, and Abdulaziz O. AlQabbany. 2012. Automatic Stochastic Arabic Spelling Correction With Emphasis on Space Insertions and Deletions. IEEE Transactions on Audio, Speech &amp; Language Processing, 20:2111–2122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chiraz Ben Othmane Zribi</author>
<author>Mohammed Ben Ahmed</author>
</authors>
<title>Efficient Automatic Correction of Misspelled Arabic Words Based on Contextual Information.</title>
<date>2003</date>
<booktitle>In Proceedings of the Knowledge-Based Intelligent Information and Engineering Systems Conference,</booktitle>
<location>Oxford, UK.</location>
<marker>Zribi, Ahmed, 2003</marker>
<rawString>Chiraz Ben Othmane Zribi and Mohammed Ben Ahmed. 2003. Efficient Automatic Correction of Misspelled Arabic Words Based on Contextual Information. In Proceedings of the Knowledge-Based Intelligent Information and Engineering Systems Conference, Oxford, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pradeep Dasigi</author>
<author>Mona Diab</author>
</authors>
<title>CODACT: TowardsIdentifying Orthographic Variants in Dialectal Arabic.</title>
<date>2011</date>
<booktitle>In Proceedings of the 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>318--326</pages>
<location>Chaing Mai, Thailand.</location>
<contexts>
<context position="12510" citStr="Dasigi and Diab (2011)" startWordPosition="2052" endWordPosition="2055"> to MSA. Similarly, both Sawaf 587 (2010) and Salloum and Habash (2011) showed that translating dialectal Arabic to MSA can improve dialectal Arabic machine translation into English by pivoting on MSA. A common feature across these conversion efforts is the use of morphological analysis and morphosyntactic transformation rules (for example, Al-Gaphari and Al-Yadoumi (2010)). While all this work is similar to ours in that dialectal input is processed, our output is still dialectal, while the work on conversion aims for a transformation into MSA. The work most closely related to ours is that of Dasigi and Diab (2011). They identify the spelling variants in a given document and normalize them. However, they do not present a system that converts spontaneous spelling to a pre-existing convention such as CODA, and thus their results cannot be directly related to ours. Furthermore, their technique is different. First, similarity metrics based on string difference are used to identify if two strings are similar. Also, a contextual string similarity is used based on the fact that if two words are orthographic variants of each other, then they are bound to appear in similar contexts. After identifying the similar</context>
</contexts>
<marker>Dasigi, Diab, 2011</marker>
<rawString>Pradeep Dasigi and Mona Diab. 2011. CODACT: TowardsIdentifying Orthographic Variants in Dialectal Arabic. In Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 318–326, Chaing Mai, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Gao</author>
<author>Stephan Vogel</author>
</authors>
<title>Parallel implementations of word alignment tool.</title>
<date>2008</date>
<booktitle>In Software Engineering, Testing, and Quality Assurance for Natural Language Processing, SETQA-NLP ’08,</booktitle>
<pages>49--57</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="30568" citStr="Gao and Vogel, 2008" startWordPosition="5066" endWordPosition="5069"> reduction of 8.1%, while the correct lemma choice increases from 85.2% to 85.7%, for an error reduction of 3.4%. When tested on the test set, we get improvements on the choice of the complete Buckwalter POS tag and lemma from 84.5% to 85.4% (5.8% error reduction) and from 86.3% to 86.7% (2.9% error reduction), respectively. Arabic to English MT The goal of this experiment is to test the effect of codafication on machine translation from dialectal Arabic to English. We use the open-source Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system. We use MGIZA++ for word alignment (Gao and Vogel, 2008). Phrase translations of up to 8 words are extracted in the phrase table. We use SRILM (Stolcke, 2002) with modified Kneser-Ney smoothing to build two 4-gram language models. The first model is trained on the English side of the bitext, while the other is trained on the English Gigaword data. Feature weights are tuned to maximize BLEU (Papineni et al., 2002) on a development set using MERT (Och, 2003). We perform case-insensitive evaluation in terms of the BLEU metric. We train the system on dialectal Arabic-English parallel data, obtained from several LDC corpora, which amounts to -500k sente</context>
</contexts>
<marker>Gao, Vogel, 2008</marker>
<rawString>Qin Gao and Stephan Vogel. 2008. Parallel implementations of word alignment tool. In Software Engineering, Testing, and Quality Assurance for Natural Language Processing, SETQA-NLP ’08, pages 49–57, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>573--580</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="27874" citStr="Habash and Rambow, 2005" startWordPosition="4622" endWordPosition="4625">t accuracy of 92.6% (exact) and 95.8% (normalized), for error reductions of 68.1% (exact) and 55.8% (normalized) against the baseline, respectively. Note that the non-contextual modeling techniques CEC (5,584 words/sec) and MLE (6,698 words/sec) are a lot faster than the deep modeling technique MADAARZ (53 words/sec), while their combination CEC+MLE+MADAARZ is the slowest among all the approaches, operating at a rate of 52 words/sec. Thus, a small drop in accuracy results in a large increase in speed. We also evaluated using MADAMSA (v 3.2) (Morphological Analysis and Disambiguation for MSA) (Habash and Rambow, 2005; Habash et al., 2010). MADAMSA is able to do some codafication, but it performs far worse than our codafication approaches. Table 4 lists the results of the best performing codafication surface approach, CEC+MLE, and deep approach, MLE+MADAARZ, when applied on the test set, which was not used as part of our training or development, i.e., a completely blind test. We see that on the test set, the addition of MADAARZ improves results relatively more as compared to the development set. 591 Approach Exact Match Norm Match w/s Acc% ER% Acc% ER% Baseline 76.8 90.5 MADAMSA 83.6 29.3 91.7 12.6 70 CEC </context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 573–580, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ryan Roth</author>
</authors>
<title>Using deep morphology to improve automatic error detection in arabic handwriting recognition.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>875--884</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="11629" citStr="Habash and Roth, 2011" startWordPosition="1907" endWordPosition="1910">nd heuristics, e.g., morphological analyzers, language models, and edit-distance measure, respectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) used a rule-based lexical transfer approach to transform from EGY to MSA. Similarly, both Sawaf 587 (2010) and Salloum and Habash (2011) showed that translating dialectal Arabic to MSA can improve dialectal Arabic machine translation into English by pivoting on MSA. A common feature across these conversion efforts is the use of morphological analysis and morphosyntactic transformation rules (for example</context>
</contexts>
<marker>Habash, Roth, 2011</marker>
<rawString>Nizar Habash and Ryan Roth. 2011. Using deep morphology to improve automatic error detection in arabic handwriting recognition. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 875–884, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Abdelhadi Soudi</author>
<author>Tim Buckwalter</author>
</authors>
<title>On Arabic Transliteration.</title>
<date>2007</date>
<booktitle>Arabic Computational Morphology: Knowledge-based and Empirical Methods.</booktitle>
<editor>In A. van den Bosch and A. Soudi, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="5737" citStr="Habash et al., 2007" startWordPosition="909" endWordPosition="912">mes. For example, @Y» kdA and èY»kdh can be intended spellings for EGY /kida/ ‘like this’, while @Q»krA is not a plausible intentional spelling since it neither relates /kida/ to an MSA cognate, nor does the sequence of graphemes represent the phonology of EGY using standard assumptions. Instead, we can explain the spelling by assuming that the writer accidentally substituted the grapheme Pfor the grapheme X, which look somewhat alike and are near each other on some Arabic keyboard layouts. Of course, when we encounter 1Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007): (in alphabetical order) Abt0jHxdðrzsšSDT ˇDS-yfqklmnhwy and the additional symbols: ’ Z, Â I, Aˇ@�, A¯�@, wˆ j , yˆZø , h a, ý ø. a specific spelling in a corpus, it can be, in certain cases, difficult to determine whether it is a conscious choice or a typo. 2.2 Relevant Differences between EGY and MSA Lexical Variations Lexically, the number of differences is quite significant. For example, EGY &amp;quot;@QÓ mrAt ‘wife [of]’ corresponds to MSA ak.ðP� zwjh. In such cases of lexical difference, no cognate spelling is available. Phonological Variations There is an extensive literature on the phonology </context>
</contexts>
<marker>Habash, Soudi, Buckwalter, 2007</marker>
<rawString>Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter. 2007. On Arabic Transliteration. In A. van den Bosch and A. Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Methods. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Ryan Roth</author>
</authors>
<date>2010</date>
<tech>MADA+TOKAN Manual. Technical Report CCLS10-01,</tech>
<institution>Center for Computational Learning Systems (CCLS), Columbia University.</institution>
<contexts>
<context position="27896" citStr="Habash et al., 2010" startWordPosition="4626" endWordPosition="4629">t) and 95.8% (normalized), for error reductions of 68.1% (exact) and 55.8% (normalized) against the baseline, respectively. Note that the non-contextual modeling techniques CEC (5,584 words/sec) and MLE (6,698 words/sec) are a lot faster than the deep modeling technique MADAARZ (53 words/sec), while their combination CEC+MLE+MADAARZ is the slowest among all the approaches, operating at a rate of 52 words/sec. Thus, a small drop in accuracy results in a large increase in speed. We also evaluated using MADAMSA (v 3.2) (Morphological Analysis and Disambiguation for MSA) (Habash and Rambow, 2005; Habash et al., 2010). MADAMSA is able to do some codafication, but it performs far worse than our codafication approaches. Table 4 lists the results of the best performing codafication surface approach, CEC+MLE, and deep approach, MLE+MADAARZ, when applied on the test set, which was not used as part of our training or development, i.e., a completely blind test. We see that on the test set, the addition of MADAARZ improves results relatively more as compared to the development set. 591 Approach Exact Match Norm Match w/s Acc% ER% Acc% ER% Baseline 76.8 90.5 MADAMSA 83.6 29.3 91.7 12.6 70 CEC 90.0 56.9 93.9 35.8 5,</context>
</contexts>
<marker>Habash, Rambow, Roth, 2010</marker>
<rawString>Nizar Habash, Owen Rambow, and Ryan Roth. 2010. MADA+TOKAN Manual. Technical Report CCLS10-01, Center for Computational Learning Systems (CCLS), Columbia University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Mona Diab</author>
<author>Owen Rabmow</author>
</authors>
<title>Conventional Orthography for Dialectal Arabic.</title>
<date>2012</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC),</booktitle>
<location>Istanbul.</location>
<contexts>
<context position="2589" citStr="Habash et al., 2012" startWordPosition="403" endWordPosition="406">e participant devises a spontaneous orthography, in which she chooses among conventions from the high variant to render the spoken language. We are thus faced with a large number of ways to spell the same word, none of which can be assumed as “standard” since there is no standard. As a result, the increased data sparseness adds to the challenges of NLP tasks such as machine translation, compared to languages for which orthography is standardized. In this paper, we work on Egyptian Arabic (EGY). We follow the conventions which we have previously proposed for the normalized orthography for EGY (Habash et al., 2012), called CODA (Conventional Orthography for Dialectal Arabic). In this paper, we investigate how easy it is to convert spontaneous orthography of EGY written in Arabic script into CODA orthography automatically. We will refer to this process as “normalization” or “codafication”. We present a freely available system called CODAFY, which we propose as a preprocessor for NLP modules for EGY. We show that a “do nothing” baseline achieves a normalization performance of 75.5%, and CODAFY achieves a normalization performance of 92.4%, an error reduction of 69.2% over this baseline on an unseen test s</context>
<context position="7608" citStr="Habash et al., 2012" startWordPosition="1227" endWordPosition="1230"> appears in EGY as /ha/+ or /Ha/+. The two forms appear in free variation, and we have not been able to find a variable that predicts which form is used when. This variation is not a general phonological variation between /h/ and /H/, we find it only in this morpheme. Predictably, this leads to two spellings in EGY: +h H+ and +-ë h+. Negation in EGY is realized as the circum-clitic /m¯a/+ ... +/š/. The principal orthographic question is whether the prefix is a separate word or is part of the main word; both variants are found. 3 CODA CODA is a conventionalized orthography for Arabic dialects (Habash et al., 2012). In this section, we summarize CODA so that the reader can understand the goals of this paper. CODA has five key properties. 1. CODA is an internally consistent and coherent convention for writing DA: every word has a 586 single orthographic rendering. 2. CODA is created for computational purposes. 3. CODA uses the Arabic script as used for MSA, with no extra symbols from, for example, Persian or Urdu. 4. CODA is intended as a unified framework for writing all dialects. In this paper, we only discuss the instantiation of CODA for EGY. 5. CODA aims to maintain a level of dialectal uniqueness w</context>
</contexts>
<marker>Habash, Diab, Rabmow, 2012</marker>
<rawString>Nizar Habash, Mona Diab, and Owen Rabmow. 2012. Conventional Orthography for Dialectal Arabic. In Proceedings of the Language Resources and Evaluation Conference (LREC), Istanbul.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ryan Roth</author>
<author>Owen Rambow</author>
<author>Ramy Eskander</author>
<author>Nadi Tomeh</author>
</authors>
<title>Morphological Analysis and Disambiguation for Dialectal Arabic.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<location>Atlanta, GA.</location>
<contexts>
<context position="24223" citStr="Habash et al., 2013" startWordPosition="4021" endWordPosition="4024"> in the training corpus. For unseen words, the technique keeps them with no change. The MLE approach chooses the correct CODA form for most of the words seen in training, making this approach highly dependent on the training data. It is efficient at correcting common misspellings in frequent words, especially those that are from closed classes. 6.4 Morphological Tagger In addition to the approaches discussed above, we use a morphological tagger, MADAARZ (Morphological Analysis and Disambiguation for Egyp1. The different @ A form (@/ � @/@�/@ A/Â /ˇA/¯A) classifier. � éªK ~.P 590 tian Arabic) (Habash et al., 2013). Although MADAARZ is originally developed to work as a morphological tagger, it still can help the codafication process, since the choice of a full morphological analysis for a word in context determines its CODA spelling. Therefore, MADAARZ is able to correct many word misspellings that are common in spontaneous orthography. These corrections include �� (@/@/@�/@ A/Â/ ˇA/¯A), ø /ø y/ý and è/S h/h transformations. However, MADAARZ, as a codafication technique, uses the context of the word, which makes it a contextual modeling approach unlike CEC and MLE. It is much slower than they are. 6.5 C</context>
</contexts>
<marker>Habash, Roth, Rambow, Eskander, Tomeh, 2013</marker>
<rawString>Nizar Habash, Ryan Roth, Owen Rambow, Ramy Eskander, and Nadi Tomeh. 2013. Morphological Analysis and Disambiguation for Dialectal Arabic. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), Atlanta, GA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Introduction to Arabic Natural Language Processing.</title>
<date>2010</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="6397" citStr="Habash, 2010" startWordPosition="1022" endWordPosition="1023">yfqklmnhwy and the additional symbols: ’ Z, Â I, Aˇ@�, A¯�@, wˆ j , yˆZø , h a, ý ø. a specific spelling in a corpus, it can be, in certain cases, difficult to determine whether it is a conscious choice or a typo. 2.2 Relevant Differences between EGY and MSA Lexical Variations Lexically, the number of differences is quite significant. For example, EGY &amp;quot;@QÓ mrAt ‘wife [of]’ corresponds to MSA ak.ðP� zwjh. In such cases of lexical difference, no cognate spelling is available. Phonological Variations There is an extensive literature on the phonology of Arabic dialects (Watson, 2002; Holes, 2004; Habash, 2010). Several phonological differences exist between EGY and MSA which relate to orthography. Here, we discuss one representative difference. The MSA consonant H~ /O/ is pronounced as /t/ in EGY (or /s/ in more recent borrowings from MSA). For example, MSAQ��ºK� ykOr ‘increase (imperfective)’ is pronounced /yakOur/ in MSA versus /yiktar/ in EGY, giving rise to the EGY phonological spelling Q��ºK� yktr. Morphological Variations There are a lot of morphological differences between MSA and EGY. For orthography, two differences are most relevant. The MSA future proclitic /sa/+ (spelled +€ s+) appears </context>
</contexts>
<marker>Habash, 2010</marker>
<rawString>Nizar Habash. 2010. Introduction to Arabic Natural Language Processing. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bassam Haddad</author>
<author>Mustafa Yaseen</author>
</authors>
<title>Detection and Correction of Non-Words in Arabic: A Hybrid Approach.</title>
<date>2007</date>
<journal>International Journal of Computer Processing Of Languages (IJCPOL).</journal>
<contexts>
<context position="11224" citStr="Haddad and Yaseen, 2007" startWordPosition="1838" endWordPosition="1841"> as post editing for optical character recognition (OCR). Our task is different from ASC since ASC work assumes a standard orthography that the writer is also assumed to aim for. Both supervised and unsupervised approaches to this task have been explored. Unsupervised approaches rely on improving the fluency of the text and reducing the percentage of out-of-vocabulary words using NLP tools, resources, and heuristics, e.g., morphological analyzers, language models, and edit-distance measure, respectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) u</context>
</contexts>
<marker>Haddad, Yaseen, 2007</marker>
<rawString>Bassam Haddad and Mustafa Yaseen. 2007. Detection and Correction of Non-Words in Arabic: A Hybrid Approach. International Journal of Computer Processing Of Languages (IJCPOL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The weka data mining software: an update.</title>
<date>2009</date>
<journal>SIGKDDExplor. Newsl.,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="19016" citStr="Hall et al., 2009" startWordPosition="3132" endWordPosition="3135">rom EGY spontaneous orthography to the corresponding CODA, listed in Tables 1 and 2 in Section 5. Second, we apply the trained classifiers to generate the CODA output. Training the classifiers For each transformation listed in the data section, we train a separate classifier. The classifiers are trained on our training corpus using the k-nearest neighbor algorithm (k-NN) (Wang et al., 2000), which is a method for classifying objects based on the closest training examples in the feature space. We did experiments using the other classification methods included in the WEKA machine learning tool (Hall et al., 2009), including SVMs, Naïve Bayes, and decision trees. However, k-NN gives the best results for our problem. In the training process, a set of nine static features is applied, which are the character that is queried for the transformation with its preceding and following two characters (a special token indicates a character position that does not exist because it is beyond the word boundary), along with the first two and the last two characters in the underlying word. In this model, each data point is a character, where a classifier determines whether a character should receive a substitution, del</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The weka data mining software: an update. SIGKDDExplor. Newsl., 11(1):10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Hassan</author>
<author>Sara Noeman</author>
<author>Hany Hassan</author>
</authors>
<title>Language Independent Text Correction using Finite State Automata.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Joint Conference on Natural Language Processing (IJCNLP</booktitle>
<contexts>
<context position="11245" citStr="Hassan et al., 2008" startWordPosition="1842" endWordPosition="1845">cal character recognition (OCR). Our task is different from ASC since ASC work assumes a standard orthography that the writer is also assumed to aim for. Both supervised and unsupervised approaches to this task have been explored. Unsupervised approaches rely on improving the fluency of the text and reducing the percentage of out-of-vocabulary words using NLP tools, resources, and heuristics, e.g., morphological analyzers, language models, and edit-distance measure, respectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) used a rule-based lexi</context>
</contexts>
<marker>Hassan, Noeman, Hassan, 2008</marker>
<rawString>Ahmed Hassan, Sara Noeman, and Hany Hassan. 2008. Language Independent Text Correction using Finite State Automata. In Proceedings of the International Joint Conference on Natural Language Processing (IJCNLP 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Clive Holes</author>
</authors>
<title>Modern Arabic: Structures, Functions, and Varieties. Georgetown Classics in Arabic Language and Linguistics.</title>
<date>2004</date>
<publisher>Georgetown University Press.</publisher>
<contexts>
<context position="6382" citStr="Holes, 2004" startWordPosition="1020" endWordPosition="1021">ðrzsšSDT ˇDS-yfqklmnhwy and the additional symbols: ’ Z, Â I, Aˇ@�, A¯�@, wˆ j , yˆZø , h a, ý ø. a specific spelling in a corpus, it can be, in certain cases, difficult to determine whether it is a conscious choice or a typo. 2.2 Relevant Differences between EGY and MSA Lexical Variations Lexically, the number of differences is quite significant. For example, EGY &amp;quot;@QÓ mrAt ‘wife [of]’ corresponds to MSA ak.ðP� zwjh. In such cases of lexical difference, no cognate spelling is available. Phonological Variations There is an extensive literature on the phonology of Arabic dialects (Watson, 2002; Holes, 2004; Habash, 2010). Several phonological differences exist between EGY and MSA which relate to orthography. Here, we discuss one representative difference. The MSA consonant H~ /O/ is pronounced as /t/ in EGY (or /s/ in more recent borrowings from MSA). For example, MSAQ��ºK� ykOr ‘increase (imperfective)’ is pronounced /yakOur/ in MSA versus /yiktar/ in EGY, giving rise to the EGY phonological spelling Q��ºK� yktr. Morphological Variations There are a lot of morphological differences between MSA and EGY. For orthography, two differences are most relevant. The MSA future proclitic /sa/+ (spelled </context>
</contexts>
<marker>Holes, 2004</marker>
<rawString>Clive Holes. 2004. Modern Arabic: Structures, Functions, and Varieties. Georgetown Classics in Arabic Language and Linguistics. Georgetown University Press.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Christopher Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Christopher Dyer</author>
<author>Ondrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="30476" citStr="Koehn et al., 2007" startWordPosition="5050" endWordPosition="5053"> identification of the complete Arabic (Buckwalter) POS tag from 84% to 85.3%, for an error reduction of 8.1%, while the correct lemma choice increases from 85.2% to 85.7%, for an error reduction of 3.4%. When tested on the test set, we get improvements on the choice of the complete Buckwalter POS tag and lemma from 84.5% to 85.4% (5.8% error reduction) and from 86.3% to 86.7% (2.9% error reduction), respectively. Arabic to English MT The goal of this experiment is to test the effect of codafication on machine translation from dialectal Arabic to English. We use the open-source Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system. We use MGIZA++ for word alignment (Gao and Vogel, 2008). Phrase translations of up to 8 words are extracted in the phrase table. We use SRILM (Stolcke, 2002) with modified Kneser-Ney smoothing to build two 4-gram language models. The first model is trained on the English side of the bitext, while the other is trained on the English Gigaword data. Feature weights are tuned to maximize BLEU (Papineni et al., 2002) on a development set using MERT (Och, 2003). We perform case-insensitive evaluation in terms of the BLEU metric. We train the system on dialectal A</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Christopher Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Christopher Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177–180, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Okan Kolak</author>
<author>Philip Resnik</author>
</authors>
<title>OCR error correction using a noisy channel model.</title>
<date>2002</date>
<booktitle>In Proceedings of the second international conference on Human Language Technology Research.</booktitle>
<contexts>
<context position="11556" citStr="Kolak and Resnik, 2002" startWordPosition="1894" endWordPosition="1898">g the percentage of out-of-vocabulary words using NLP tools, resources, and heuristics, e.g., morphological analyzers, language models, and edit-distance measure, respectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) used a rule-based lexical transfer approach to transform from EGY to MSA. Similarly, both Sawaf 587 (2010) and Salloum and Habash (2011) showed that translating dialectal Arabic to MSA can improve dialectal Arabic machine translation into English by pivoting on MSA. A common feature across these conversion efforts is the use of mor</context>
</contexts>
<marker>Kolak, Resnik, 2002</marker>
<rawString>Okan Kolak and Philip Resnik. 2002. OCR error correction using a noisy channel model. In Proceedings of the second international conference on Human Language Technology Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Kukich</author>
</authors>
<title>Techniques for Automatically Correcting Words in Text.</title>
<date>1992</date>
<journal>ACM Computing Surveys,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="11123" citStr="Kukich, 1992" startWordPosition="1822" endWordPosition="1823">sed work has some similarity to automatic spelling correction (ASC) and related tasks such as post editing for optical character recognition (OCR). Our task is different from ASC since ASC work assumes a standard orthography that the writer is also assumed to aim for. Both supervised and unsupervised approaches to this task have been explored. Unsupervised approaches rely on improving the fluency of the text and reducing the percentage of out-of-vocabulary words using NLP tools, resources, and heuristics, e.g., morphological analyzers, language models, and edit-distance measure, respectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi</context>
</contexts>
<marker>Kukich, 1992</marker>
<rawString>Karen Kukich. 1992. Techniques for Automatically Correcting Words in Text. ACM Computing Surveys, 24(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Seth Kulick</author>
<author>Dalila Tabessi</author>
<author>Sondos Krouna</author>
</authors>
<title>Egyptian Arabic Treebank Pilot.</title>
<date>2012</date>
<contexts>
<context position="13397" citStr="Maamouri et al., 2012" startWordPosition="2201" endWordPosition="2204"> their technique is different. First, similarity metrics based on string difference are used to identify if two strings are similar. Also, a contextual string similarity is used based on the fact that if two words are orthographic variants of each other, then they are bound to appear in similar contexts. After identifying the similar strings, the strings of interest are modeled in a vector space and clustered according to the similarity of their vectors. 5 Data In this work, we use a manually annotated EGY Arabic corpus, developed by the Linguistic Data Consortium (LDC), and labeled as “ARZ” (Maamouri et al., 2012), parts 1, 2, 3, 4 and 5. The corpus consists of about 160K words (excluding numbers and punctuations), and follows the part-ofspeech (POS) guidelines used by the LDC for Egyptian Arabic. The corpus contains a full analysis of Egyptian Arabic text in spontaneous orthography. The analysis includes the correct CODA orthography of the raw text, in addition to the full morphological/POS annotations. Data Preparation We divide the ARZ corpus into three parts: training, development and test, which are of about 122K, 19K and 19K words, respectively. We only consider the orthographic information in th</context>
</contexts>
<marker>Maamouri, Bies, Kulick, Tabessi, Krouna, 2012</marker>
<rawString>Mohamed Maamouri, Ann Bies, Seth Kulick, Dalila Tabessi, and Sondos Krouna. 2012. Egyptian Arabic Treebank Pilot.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walid Magdy</author>
<author>Kareem Darwish</author>
</authors>
<title>Arabic OCR Error Correction Using Character Segment Correction, Language Modeling, and Shallow Morphology.</title>
<date>2006</date>
<booktitle>In Proceedings of 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>408--414</pages>
<location>Sydney, Austrailia.</location>
<contexts>
<context position="11581" citStr="Magdy and Darwish, 2006" startWordPosition="1899" endWordPosition="1902">of-vocabulary words using NLP tools, resources, and heuristics, e.g., morphological analyzers, language models, and edit-distance measure, respectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) used a rule-based lexical transfer approach to transform from EGY to MSA. Similarly, both Sawaf 587 (2010) and Salloum and Habash (2011) showed that translating dialectal Arabic to MSA can improve dialectal Arabic machine translation into English by pivoting on MSA. A common feature across these conversion efforts is the use of morphological analysis and m</context>
</contexts>
<marker>Magdy, Darwish, 2006</marker>
<rawString>Walid Magdy and Kareem Darwish. 2006. Arabic OCR Error Correction Using Character Segment Correction, Language Modeling, and Shallow Morphology. In Proceedings of 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 408–414, Sydney, Austrailia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum Error Rate Training for Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Conference of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="30972" citStr="Och, 2003" startWordPosition="5140" endWordPosition="5141">on machine translation from dialectal Arabic to English. We use the open-source Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system. We use MGIZA++ for word alignment (Gao and Vogel, 2008). Phrase translations of up to 8 words are extracted in the phrase table. We use SRILM (Stolcke, 2002) with modified Kneser-Ney smoothing to build two 4-gram language models. The first model is trained on the English side of the bitext, while the other is trained on the English Gigaword data. Feature weights are tuned to maximize BLEU (Papineni et al., 2002) on a development set using MERT (Och, 2003). We perform case-insensitive evaluation in terms of the BLEU metric. We train the system on dialectal Arabic-English parallel data, obtained from several LDC corpora, which amounts to -500k sentences with 3.8M untokenized words on the Arabic side. The development set, used for tuning the parameters of the MT system, has 1,547 sentences with 15,585 untokenized Arabic words. The test set has 1,065 sentences with 592 12,116 untokenized Arabic words. Both development and test sets have two reference translations each. The English data is lower-cased and tokenized using simple punctuation-based ru</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum Error Rate Training for Statistical Machine Translation. In Proceedings of the 41st Annual Conference of the Association for Computational Linguistics, pages 160–167, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
</authors>
<title>Error-tolerant finite-state recognition with applications to morphological analysis and spelling correction.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--73</pages>
<contexts>
<context position="11138" citStr="Oflazer, 1996" startWordPosition="1824" endWordPosition="1825">ome similarity to automatic spelling correction (ASC) and related tasks such as post editing for optical character recognition (OCR). Our task is different from ASC since ASC work assumes a standard orthography that the writer is also assumed to aim for. Both supervised and unsupervised approaches to this task have been explored. Unsupervised approaches rely on improving the fluency of the text and reducing the percentage of out-of-vocabulary words using NLP tools, resources, and heuristics, e.g., morphological analyzers, language models, and edit-distance measure, respectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introdu</context>
</contexts>
<marker>Oflazer, 1996</marker>
<rawString>Kemal Oflazer. 1996. Error-tolerant finite-state recognition with applications to morphological analysis and spelling correction. Computational Linguistics, 22:73–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="30928" citStr="Papineni et al., 2002" startWordPosition="5129" endWordPosition="5133">f this experiment is to test the effect of codafication on machine translation from dialectal Arabic to English. We use the open-source Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system. We use MGIZA++ for word alignment (Gao and Vogel, 2008). Phrase translations of up to 8 words are extracted in the phrase table. We use SRILM (Stolcke, 2002) with modified Kneser-Ney smoothing to build two 4-gram language models. The first model is trained on the English side of the bitext, while the other is trained on the English Gigaword data. Feature weights are tuned to maximize BLEU (Papineni et al., 2002) on a development set using MERT (Och, 2003). We perform case-insensitive evaluation in terms of the BLEU metric. We train the system on dialectal Arabic-English parallel data, obtained from several LDC corpora, which amounts to -500k sentences with 3.8M untokenized words on the Arabic side. The development set, used for tuning the parameters of the MT system, has 1,547 sentences with 15,585 untokenized Arabic words. The test set has 1,065 sentences with 592 12,116 untokenized Arabic words. Both development and test sets have two reference translations each. The English data is lower-cased and</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wael Salloum</author>
<author>Nizar Habash</author>
</authors>
<title>Dialectal to Standard Arabic Paraphrasing to Improve ArabicEnglish Statistical Machine Translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties,</booktitle>
<pages>10--21</pages>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="11959" citStr="Salloum and Habash (2011)" startWordPosition="1962" endWordPosition="1965">rection by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) used a rule-based lexical transfer approach to transform from EGY to MSA. Similarly, both Sawaf 587 (2010) and Salloum and Habash (2011) showed that translating dialectal Arabic to MSA can improve dialectal Arabic machine translation into English by pivoting on MSA. A common feature across these conversion efforts is the use of morphological analysis and morphosyntactic transformation rules (for example, Al-Gaphari and Al-Yadoumi (2010)). While all this work is similar to ours in that dialectal input is processed, our output is still dialectal, while the work on conversion aims for a transformation into MSA. The work most closely related to ours is that of Dasigi and Diab (2011). They identify the spelling variants in a given </context>
</contexts>
<marker>Salloum, Habash, 2011</marker>
<rawString>Wael Salloum and Nizar Habash. 2011. Dialectal to Standard Arabic Paraphrasing to Improve ArabicEnglish Statistical Machine Translation. In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties, pages 10–21, Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Sawaf</author>
</authors>
<title>Arabic dialect handling in hybrid machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference of the Association for Machine Translation in the Americas (AMTA),</booktitle>
<location>Denver, Colorado.</location>
<marker>Sawaf, 2010</marker>
<rawString>Hassan Sawaf. 2010. Arabic dialect handling in hybrid machine translation. In Proceedings of the Conference of the Association for Machine Translation in the Americas (AMTA), Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Khaled Shaalan</author>
<author>Amin Allam</author>
<author>Abdallah Gomah</author>
</authors>
<title>Towards Automatic Spell Checking for Arabic.</title>
<date>2003</date>
<booktitle>In Conference on Language Engineering,</booktitle>
<location>ELSE, Cairo, Egypt.</location>
<contexts>
<context position="11199" citStr="Shaalan et al., 2003" startWordPosition="1834" endWordPosition="1837">and related tasks such as post editing for optical character recognition (OCR). Our task is different from ASC since ASC work assumes a standard orthography that the writer is also assumed to aim for. Both supervised and unsupervised approaches to this task have been explored. Unsupervised approaches rely on improving the fluency of the text and reducing the percentage of out-of-vocabulary words using NLP tools, resources, and heuristics, e.g., morphological analyzers, language models, and edit-distance measure, respectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, an</context>
</contexts>
<marker>Shaalan, Allam, Gomah, 2003</marker>
<rawString>Khaled Shaalan, Amin Allam, and Abdallah Gomah. 2003. Towards Automatic Spell Checking for Arabic. In Conference on Language Engineering, ELSE, Cairo, Egypt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Shaalan</author>
<author>Abo Bakr</author>
<author>I H Ziedan</author>
</authors>
<title>Transferring Egyptian Colloquial into Modern Standard Arabic.</title>
<date>2007</date>
<booktitle>In International Conference on Recent Advances in Natural Language Processing (RANLP), Borovets,</booktitle>
<contexts>
<context position="11822" citStr="Shaalan et al. (2007)" startWordPosition="1939" endWordPosition="1942">Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) used a rule-based lexical transfer approach to transform from EGY to MSA. Similarly, both Sawaf 587 (2010) and Salloum and Habash (2011) showed that translating dialectal Arabic to MSA can improve dialectal Arabic machine translation into English by pivoting on MSA. A common feature across these conversion efforts is the use of morphological analysis and morphosyntactic transformation rules (for example, Al-Gaphari and Al-Yadoumi (2010)). While all this work is similar to ours in that dialectal input is processed, our output is still dialectal, while the work on conversion aims for a transfor</context>
</contexts>
<marker>Shaalan, Bakr, Ziedan, 2007</marker>
<rawString>K. Shaalan, Abo Bakr, and I. H. Ziedan. 2007. Transferring Egyptian Colloquial into Modern Standard Arabic. In International Conference on Recent Advances in Natural Language Processing (RANLP), Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Shaalan</author>
<author>R Aref</author>
<author>A Fahmy</author>
</authors>
<title>An approach for analyzing and correcting spelling errors for nonnative Arabic learners.</title>
<date>2010</date>
<booktitle>Proceedings of Informatics and Systems (INFOS).</booktitle>
<contexts>
<context position="11267" citStr="Shaalan et al., 2010" startWordPosition="1846" endWordPosition="1849">tion (OCR). Our task is different from ASC since ASC work assumes a standard orthography that the writer is also assumed to aim for. Both supervised and unsupervised approaches to this task have been explored. Unsupervised approaches rely on improving the fluency of the text and reducing the percentage of out-of-vocabulary words using NLP tools, resources, and heuristics, e.g., morphological analyzers, language models, and edit-distance measure, respectively (Kukich, 1992; Oflazer, 1996; Ben Othmane Zribi and Ben Ahmed, 2003; Shaalan et al., 2003; Haddad and Yaseen, 2007; Hassan et al., 2008; Shaalan et al., 2010; Alkanhal et al., 2012). Supervised approaches learn models of correction by training on paired examples of errors and their corrections. This data is hard to come by naturally, though for applications such as OCR corpora can be created from the application itself (Kolak and Resnik, 2002; Magdy and Darwish, 2006; Abuhakema et al., 2008; Habash and Roth, 2011). There has been some work on conversion of dialectal Arabic to MSA. Al-Gaphari and Al-Yadoumi (2010) introduced a rule-based method to convert Sanaani dialect to MSA, and Shaalan et al. (2007) used a rule-based lexical transfer approach </context>
</contexts>
<marker>Shaalan, Aref, Fahmy, 2010</marker>
<rawString>K. Shaalan, R. Aref, and A. Fahmy. 2010. An approach for analyzing and correcting spelling errors for nonnative Arabic learners. Proceedings of Informatics and Systems (INFOS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing (ICSLP),</booktitle>
<volume>2</volume>
<pages>901--904</pages>
<location>Denver, CO.</location>
<contexts>
<context position="30670" citStr="Stolcke, 2002" startWordPosition="5087" endWordPosition="5089">3.4%. When tested on the test set, we get improvements on the choice of the complete Buckwalter POS tag and lemma from 84.5% to 85.4% (5.8% error reduction) and from 86.3% to 86.7% (2.9% error reduction), respectively. Arabic to English MT The goal of this experiment is to test the effect of codafication on machine translation from dialectal Arabic to English. We use the open-source Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system. We use MGIZA++ for word alignment (Gao and Vogel, 2008). Phrase translations of up to 8 words are extracted in the phrase table. We use SRILM (Stolcke, 2002) with modified Kneser-Ney smoothing to build two 4-gram language models. The first model is trained on the English side of the bitext, while the other is trained on the English Gigaword data. Feature weights are tuned to maximize BLEU (Papineni et al., 2002) on a development set using MERT (Och, 2003). We perform case-insensitive evaluation in terms of the BLEU metric. We train the system on dialectal Arabic-English parallel data, obtained from several LDC corpora, which amounts to -500k sentences with 3.8M untokenized words on the Arabic side. The development set, used for tuning the paramete</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an Extensible Language Modeling Toolkit. In Proceedings of the International Conference on Spoken Language Processing (ICSLP), volume 2, pages 901–904, Denver, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Wang</author>
<author>Zucker</author>
<author>Jean-Daniel</author>
</authors>
<title>Solving multiple-instance problem: A lazy learning approach.</title>
<date>2000</date>
<booktitle>17th International Conference on Machine Learning,</booktitle>
<pages>1119--1125</pages>
<editor>In Pat Langley, editor,</editor>
<contexts>
<context position="18791" citStr="Wang et al., 2000" startWordPosition="3095" endWordPosition="3098">CODA orthography. This is a surface modeling technique that does not depend on the word context (though it does depend on character context inside the word). First, we train classifiers for the most frequent transformations from EGY spontaneous orthography to the corresponding CODA, listed in Tables 1 and 2 in Section 5. Second, we apply the trained classifiers to generate the CODA output. Training the classifiers For each transformation listed in the data section, we train a separate classifier. The classifiers are trained on our training corpus using the k-nearest neighbor algorithm (k-NN) (Wang et al., 2000), which is a method for classifying objects based on the closest training examples in the feature space. We did experiments using the other classification methods included in the WEKA machine learning tool (Hall et al., 2009), including SVMs, Naïve Bayes, and decision trees. However, k-NN gives the best results for our problem. In the training process, a set of nine static features is applied, which are the character that is queried for the transformation with its preceding and following two characters (a special token indicates a character position that does not exist because it is beyond the</context>
</contexts>
<marker>Wang, Zucker, Jean-Daniel, 2000</marker>
<rawString>Jun Wang, Zucker, and Jean-Daniel. 2000. Solving multiple-instance problem: A lazy learning approach. In Pat Langley, editor, 17th International Conference on Machine Learning, pages 1119–1125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet C E Watson</author>
</authors>
<title>The Phonology and Morphology of Arabic.</title>
<date>2002</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="6369" citStr="Watson, 2002" startWordPosition="1017" endWordPosition="1019">rder) Abt0jHxdðrzsšSDT ˇDS-yfqklmnhwy and the additional symbols: ’ Z, Â I, Aˇ@�, A¯�@, wˆ j , yˆZø , h a, ý ø. a specific spelling in a corpus, it can be, in certain cases, difficult to determine whether it is a conscious choice or a typo. 2.2 Relevant Differences between EGY and MSA Lexical Variations Lexically, the number of differences is quite significant. For example, EGY &amp;quot;@QÓ mrAt ‘wife [of]’ corresponds to MSA ak.ðP� zwjh. In such cases of lexical difference, no cognate spelling is available. Phonological Variations There is an extensive literature on the phonology of Arabic dialects (Watson, 2002; Holes, 2004; Habash, 2010). Several phonological differences exist between EGY and MSA which relate to orthography. Here, we discuss one representative difference. The MSA consonant H~ /O/ is pronounced as /t/ in EGY (or /s/ in more recent borrowings from MSA). For example, MSAQ��ºK� ykOr ‘increase (imperfective)’ is pronounced /yakOur/ in MSA versus /yiktar/ in EGY, giving rise to the EGY phonological spelling Q��ºK� yktr. Morphological Variations There are a lot of morphological differences between MSA and EGY. For orthography, two differences are most relevant. The MSA future proclitic /s</context>
</contexts>
<marker>Watson, 2002</marker>
<rawString>Janet C. E. Watson. 2002. The Phonology and Morphology of Arabic. Oxford University Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>