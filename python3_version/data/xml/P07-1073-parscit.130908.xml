<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000750">
<title confidence="0.996206">
Learning to Extract Relations from the Web
using Minimal Supervision
</title>
<author confidence="0.931201">
Razvan C. Bunescu
</author>
<affiliation confidence="0.968405">
Department of Computer Sciences
University of Texas at Austin
1 University Station C0500
</affiliation>
<address confidence="0.854481">
Austin, TX 78712
</address>
<email confidence="0.998551">
razvan@cs.utexas.edu
</email>
<author confidence="0.558223">
Raymond J. Mooney
</author>
<affiliation confidence="0.956124333333333">
Department of Computer Sciences
University of Texas at Austin
1 University Station C0500
</affiliation>
<address confidence="0.853696">
Austin, TX 78712
</address>
<email confidence="0.998742">
mooney@cs.utexas.edu
</email>
<sectionHeader confidence="0.996662" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999856181818182">
We present a new approach to relation ex-
traction that requires only a handful of train-
ing examples. Given a few pairs of named
entities known to exhibit or not exhibit a
particular relation, bags of sentences con-
taining the pairs are extracted from the web.
We extend an existing relation extraction
method to handle this weaker form of su-
pervision, and present experimental results
demonstrating that our approach can reliably
extract relations from web documents.
</bodyText>
<sectionHeader confidence="0.99878" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999801421052631">
A growing body of recent work in information
extraction has addressed the problem of relation
extraction (RE), identifying relationships between
entities stated in text, such as LivesIn(Person,
Location) or EmployedBy(Person, Company).
Supervised learning has been shown to be effective
for RE (Zelenko et al., 2003; Culotta and Sorensen,
2004; Bunescu and Mooney, 2006); however, anno-
tating large corpora with examples of the relations
to be extracted is expensive and tedious.
In this paper, we introduce a supervised learning
approach to RE that requires only a handful of
training examples and uses the web as a corpus.
Given a few pairs of well-known entities that
clearly exhibit or do not exhibit a particular re-
lation, such as CorpAcquired(Google, YouTube)
and not(CorpAcquired(Yahoo, Microsoft)), a
search engine is used to find sentences on the web
that mention both of the entities in each of the pairs.
</bodyText>
<page confidence="0.983479">
576
</page>
<bodyText confidence="0.999901793103448">
Although not all of the sentences for positive pairs
will state the desired relationship, many of them
will. Presumably, none of the sentences for negative
pairs state the targeted relation. Multiple instance
learning (MIL) is a machine learning framework
that exploits this sort of weak supervision, in
which a positive bag is a set of instances which is
guaranteed to contain at least one positive example,
and a negative bag is a set of instances all of which
are negative. MIL was originally introduced to
solve a problem in biochemistry (Dietterich et
al., 1997); however, it has since been applied to
problems in other areas such as classifying image
regions in computer vision (Zhang et al., 2002), and
text categorization (Andrews et al., 2003; Ray and
Craven, 2005).
We have extended an existing approach to rela-
tion extraction using support vector machines and
string kernels (Bunescu and Mooney, 2006) to han-
dle this weaker form of MIL supervision. This ap-
proach can sometimes be misled by textual features
correlated with the specific entities in the few train-
ing pairs provided. Therefore, we also describe a
method for weighting features in order to focus on
those correlated with the target relation rather than
with the individual entities. We present experimen-
tal results demonstrating that our approach is able to
accurately extract relations from the web by learning
from such weak supervision.
</bodyText>
<sectionHeader confidence="0.970868" genericHeader="introduction">
2 Problem Description
</sectionHeader>
<bodyText confidence="0.976505666666667">
We address the task of learning a relation extrac-
tion system targeted to a fixed binary relationship
R. The only supervision given to the learning algo-
</bodyText>
<note confidence="0.9023045">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 576–583,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.997613230769231">
rithm is a small set of pairs of named entities that are
known to belong (positive) or not belong (negative)
to the given relationship. Table 1 shows four posi-
tive and two negative example pairs for the corpo-
rate acquisition relationship. For each pair, a bag of
sentences containing the two arguments can be ex-
tracted from a corpus of text documents. The corpus
is assumed to be sufficiently large and diverse such
that, if the pair is positive, it is highly likely that the
corresponding bag contains at least one sentence that
explicitly asserts the relationship R between the two
arguments. In Section 6 we describe a method for
extracting bags of relevant sentences from the web.
</bodyText>
<table confidence="0.999784">
+/− Arg a1 Arg a2
+ Google YouTube
+ Adobe Systems Macromedia
+ Viacom DreamWorks
+ Novartis Eon Labs
− Yahoo Microsoft
− Pfizer Teva
</table>
<tableCaption confidence="0.999544">
Table 1: Corporate Acquisition Pairs.
</tableCaption>
<bodyText confidence="0.87552192">
Using a limited set of entity pairs (e.g. those in
Table 1) and their associated bags as training data,
the aim is to induce a relation extraction system that
can reliably decide whether two entities mentioned
in the same sentence exhibit the target relationship
or not. In particular, when tested on the example
sentences from Figure 1, the system should classify
S1, S3,and S4 as positive, and S2 and S5 as negative.
+/S1: Search engine giant Google has bought video-
sharing website YouTube in a controversial $1.6 billion
deal.
−/S2: The companies will merge Google’s search ex-
pertise with YouTube’s video expertise, pushing what
executives believe is a hot emerging market of video
offered over the Internet.
+/S3: Google has acquired social media company,
YouTube for $1.65 billion in a stock-for-stock transaction
as announced by Google Inc. on October 9, 2006.
+/S4: Drug giant Pfizer Inc. has reached an agreement
to buy the private biotechnology firm Rinat Neuroscience
Corp., the companies announced Thursday.
−/S5: He has also received consulting fees from Al-
pharma, Eli Lilly and Company, Pfizer, Wyeth Pharmaceu-
ticals, Rinat Neuroscience, Elan Pharmaceuticals, and For-
est Laboratories.
</bodyText>
<figureCaption confidence="0.999336">
Figure 1: Sentence examples.
</figureCaption>
<bodyText confidence="0.999988">
As formulated above, the learning task can be
seen as an instance of multiple instance learning.
However, there are important properties that set it
apart from problems previously considered in MIL.
The most distinguishing characteristic is that the
number of bags is very small, while the average size
of the bags is very large.
</bodyText>
<sectionHeader confidence="0.982354" genericHeader="method">
3 Multiple Instance Learning
</sectionHeader>
<bodyText confidence="0.999883815789474">
Since its introduction by Dietterich (1997), an ex-
tensive and quite diverse set of methods have been
proposed for solving the MIL problem. For the task
of relation extraction, we consider only MIL meth-
ods where the decision function can be expressed in
terms of kernels computed between bag instances.
This choice was motivated by the comparatively
high accuracy obtained by kernel-based SVMs when
applied to various natural language tasks, and in par-
ticular to relation extraction. Through the use of ker-
nels, SVMs (Vapnik, 1998; Sch¨olkopf and Smola,
2002) can work efficiently with instances that im-
plicitly belong to a high dimensional feature space.
When used for classification, the decision function
computed by the learning algorithm is equivalent to
a hyperplane in this feature space. Overfitting is
avoided in the SVM formulation by requiring that
positive and negative training instances be maxi-
mally separated by the decision hyperplane.
Gartner et al. (2002) adapted SVMs to the MIL
setting using various multi-instance kernels. Two
of these – the normalized set kernel, and the statis-
tic kernel – have been experimentally compared to
other methods by Ray and Craven (2005), with com-
petitive results. Alternatively, a simple approach to
MIL is to transform it into a standard supervised
learning problem by labeling all instances from pos-
itive bags as positive. An interesting outcome of the
study conducted by Ray and Craven (2005) was that,
despite the class noise in the resulting positive ex-
amples, such a simple approach often obtains com-
petitive results when compared against other more
sophisticated MIL methods.
We believe that an MIL method based on multi-
instance kernels is not appropriate for training
datasets that contain just a few, very large bags. In
a multi-instance kernel approach, only bags (and
not instances) are considered as training examples,
</bodyText>
<page confidence="0.98133">
577
</page>
<bodyText confidence="0.981011818181818">
which means that the number of support vectors is
going to be upper bounded by the number of train-
ing bags. Taking the bags from Table 1 as a sam-
ple training set, the decision function is going to be
specified by at most seven parameters: the coeffi-
cients for at most six support vectors, plus an op-
tional bias parameter. A hypothesis space character-
ized by such a small number of parameters is likely
to have insufficient capacity.
Based on these observations, we decided to trans-
form the MIL problem into a standard supervised
problem as described above. The use of this ap-
proach is further motivated by its simplicity and its
observed competitive performance on very diverse
datasets (Ray and Craven, 2005). Let X be the set
of bags used for training, Xp C X the set of posi-
tive bags, and Xn C X the set of negative bags. For
any instance x E X from a bag X E X, let φ(x)
be the (implicit) feature vector representation of x.
Then the corresponding SVM optimization problem
can be formulated as in Figure 2:
minimize:
</bodyText>
<equation confidence="0.995760333333333">
J(w, b, ξ) = 2 lw l2 + L (cp L —p + cn Lp =n
�-p =
XEXp
�=n =
XEXn
subject to:
w φ(x) + b &gt; +1 − ξx, bx E X E Xp
w φ(x) + b &lt; −1 + ξx, bxEXEXn
ξx &gt; 0
</equation>
<figureCaption confidence="0.990183">
Figure 2: SVM Optimization Problem.
</figureCaption>
<bodyText confidence="0.9982579375">
The capacity control parameter C is normalized
by the total number of instances L = Lp + Ln =
EXEXp |X |+ EXEXn |X|, so that it remains in-
dependent of the size of the dataset. The additional
non-negative parameter cp (cn = 1−cp) controls the
relative influence that false negative vs. false posi-
tive errors have on the value of the objective func-
tion. Because not all instances from positive bags
are real positive instances, it makes sense to have
false negative errors be penalized less than false pos-
itive errors (i.e. cp &lt; 0.5).
In the dual formulation of the optimization prob-
lem from Figure 2, bag instances appear only inside
dot products of the form K(x1, x2) = φ(x1)φ(x2).
The kernel K is instantiated to a subsequence ker-
nel, as described in the next section.
</bodyText>
<sectionHeader confidence="0.994503" genericHeader="method">
4 Relation Extraction Kernel
</sectionHeader>
<bodyText confidence="0.999815230769231">
The training bags consist of sentences extracted
from online documents, using the methodology de-
scribed in Section 6. Parsing web documents in
order to obtain a syntactic analysis often gives un-
reliable results – the type of narrative can vary
greatly from one web document to another, and sen-
tences with grammatical errors are frequent. There-
fore, for the initial experiments, we used a modi-
fied version of the subsequence kernel of Bunescu
and Mooney (2006), which does not require syn-
tactic information. This kernel computes the num-
ber of common subsequences of tokens between two
sentences. The subsequences are constrained to be
“anchored” at the two entity names, and there is
a maximum number of tokens that can appear in
a sequence. For example, a subsequence feature
for the sentence S1 in Figure 1 is s� = “(e1) ...
bought ... (e2) ... in ... billion ... deal”, where
(e1) and (e2) are generic placeholders for the two
entity names. The subsequence kernel induces a
feature space where each dimension corresponds
to a sequence of words. Any such sequence that
matches a subsequence of words in a sentence exam-
ple is down-weighted as a function of the total length
of the gaps between every two consecutive words.
More exactly, let s = w1w2 ... wk be a sequence of
k words, and s� = w1 g1 w2 g2 . . . wk−1 gk−1 wk a
matching subsequence in a relation example, where
gi stands for any sequence of words between wi and
wi+1. Then the sequence s will be represented in the
relation example as a feature with weight computed
as τ(s) = λgP). The parameter λ controls the mag-
nitude of the gap penalty, where g(s) = Ei |gi |is
the total gap.
Many relations, like the ones that we explore in
the experimental evaluation, cannot be expressed
without using at least one content word. We there-
fore modified the kernel computation to optionally
ignore subsequence patterns formed exclusively of
</bodyText>
<figure confidence="0.84731525">
� ξx
xEX
� ξx
xEX
</figure>
<page confidence="0.957461">
578
</page>
<bodyText confidence="0.994033686274509">
stop words and punctuation signs. In Section 5.1, FrameNet terminology (Baker et al., 1998), these
we introduce a new weighting scheme, wherein a correspond to instantiated frame elements. For ex-
weight is assigned to every token. Correspondingly, ample, the corporate acquisition frame can be seen
every sequence feature will have an additional mul- as a subtype of the “Getting” frame in FrameNet.
tiplicative weight, computed as the product of the The core elements in this frame are the Recipi-
weights of all the tokens in the sequence. The aim ent (e.g. Google) and the Theme (e.g. YouTube),
of this new weighting scheme, as detailed in the next which for the acquisition relationship coincide with
section, is to eliminate the bias caused by the special the two arguments. They do not contribute any
structure of the relation extraction MIL problem. bias, since they are replaced with the generic tags
5 Two Types of Bias (e1) and (e2) in all sentences from the bag. There
As already hinted at the end of Section 2, there is are however other frame elements – peripheral, or
one important property that distinguishes the cur- extra-thematic – that can be instantiated with the
rent MIL setting for relation extraction from other same value in many sentences. In Figure 1, for in-
MIL problems: the training dataset contains very stance, sentence 53 contains two non-core frame ele-
few bags, and each bag can be very large. Con- ments: the Means element (e.g “in a stock-for-stock
sequently, an application of the learning model de- transaction”) and the Time element (e.g. “on Oc-
scribed in Sections 3 &amp; 4 is bound to be affected by tober 9, 2006”). Words from these elements, like
the following two types of bias: “stock”, or “October”, are likely to occur very often
■ [Type I Bias] By definition, all sentences inside in the Google-YouTube bag, and because the train-
a bag are constrained to contain the same two ar- ing dataset contains only a few other bags, subse-
guments. Words that are semantically correlated quence patterns containing these words will be given
with either of the two arguments are likely to oc- too much weight in the learned model. This is prob-
cur in many sentences. For example, consider the lematic, since these words can appear in many other
sentences 51 and 52 from the bag associated with frames, and thus the learned model is likely to make
“Google” and “YouTube” (as shown in Figure 1). errors. Instead, we would like the model to fo-
They both contain the words “search” – highly cor- cus on words that trigger the target relationship (in
related with “Google”, and “video” – highly corre- FrameNet, these are the lexical units associated with
lated with “YouTube”, and it is likely that a signifi- the target frame).
cant percentage of sentences in this bag contain one 5.1 A Solution for Type I Bias
of the two words (or both). The two entities can be In order to account for how strongly the words in a
mentioned in the same sentence for reasons other sequence are correlated with either of the individual
than the target relation R, and these noisy training arguments of the relation, we modify the formula for
sentences are likely to contain words that are corre- the sequence weight T(s) by factoring in a weight
lated with the two entities, without any relationship T(w) for each word in the sequence, as illustrated in
to R. A learning model where the features are based Equation 1.
on words, or word sequences, is going to give too 11 T(s) � A���s) · T(w) (1)
much weight to words or combinations of words that wEs
are correlated with either of individual arguments. Given a predefined set of weights T(w), it is straight-
This overweighting will adversely affect extraction forward to update the recursive computation of
performance through an increased number of errors. the subsequence kernel so that it reflects the new
A method for eliminating this type of bias is intro- weighting scheme.
duced in Section 5.1. If all the word weights are set to 1, then the new
■ [Type II Bias] While Type I bias is due to words kernel is equivalent to the old one. What we want,
that are correlated with the arguments of a relation however, is a set of weights where words that are
instance, the Type II bias is caused by words that correlated with either of the two arguments are given
are specific to the relation instance itself. Using lower weights. For any word, the decrease in weight
579
should reflect the degree of correlation between that
word and the two arguments. Before showing the
formula used for computing the word weights, we
first introduce some notation:
</bodyText>
<equation confidence="0.99941075">
T(w) = C(X, w)
P(wjX.a1 V X.a2)
= 1 − (2)
P(wjX)
</equation>
<bodyText confidence="0.996328416666667">
The quantity P(wjX.a1 V X.a2) • C(X) represents
the expected number of sentences in which w would
occur, if the only causes were X.a1 or X.a2, inde-
pendent of each other. We want to discard this quan-
tity from the total number of occurrences C(X, w),
so that the effect of correlations with X.a1 or X.a2
is eliminated.
We still need to compute P(wjX.a1 V X.a2). Be-
cause in the definition of P(wjX.a1 V X.a2), the ar-
guments X.a1 and X.a2 were considered indepen-
dent causes, P(wjX.a1 V X.a2) can be computed
with the noisy-or operator (Pearl, 1986):
</bodyText>
<equation confidence="0.998373">
P(•) = 1−(1−P(wja1)) • (1−P(wja2)) (3)
= P(wja1)+P(wja2)−P(wja1) • P(wja2)
</equation>
<bodyText confidence="0.972745235294118">
The quantity P(wja) represents the probability that
the word w appears in a sentence due only to the
presence of a, and it could be estimated using counts
on a sufficiently large corpus. For our experimen-
tal evaluation, we used the following approxima-
tion: given an argument a, a set of sentences con-
taining a are extracted from web documents (de-
tails in Section 6). Then P(wja) is simply approxi-
mated with the ratio of the number of sentences con-
taining w over the total number of sentences, i.e.
P(wja) = C(w, a)/C(a). Because this may be an
overestimate (w may appear in a sentence contain-
ing a due to causes other than a), and also because
of data sparsity, the quantity T(w) may sometimes
result in a negative value – in these cases it is set to
0, which is equivalent to ignoring the word w in all
subsequence patterns.
</bodyText>
<sectionHeader confidence="0.996322" genericHeader="method">
6 MIL Relation Extraction Datasets
</sectionHeader>
<bodyText confidence="0.997516666666666">
For the purpose of evaluation, we created two
datasets: one for corporate acquisitions, as shown
in Table 2, and one for the person-birthplace rela-
tion, with the example pairs from Table 3. In both
tables, the top part shows the training pairs, while
the bottom part shows the test pairs.
</bodyText>
<table confidence="0.999907727272727">
+/− Arg a1 Arg a2 Size
+ Google YouTube 1375
+ Adobe Systems Macromedia 622
+ Viacom DreamWorks 323
+ Novartis Eon Labs 311
− Yahoo Microsoft 163
− Pfizer Teva 247
+ Pfizer Rinat Neuroscience 50 (41)
+ Yahoo Inktomi 433 (115)
− Google Apple 281
− Viacom NBC 231
</table>
<tableCaption confidence="0.877252">
Table 2: Corporate Acquisition Pairs.
</tableCaption>
<table confidence="0.999975363636364">
+/− Arg a1 Arg a2 Size
+ Franz Kafka Prague 552
+ Andre Agassi Las Vegas 386
+ Charlie Chaplin London 292
+ George Gershwin New York 260
− Luc Besson New York 74
− Wolfgang A. Mozart Vienna 288
+ Luc Besson Paris 126 (6)
+ Marie Antoinette Vienna 105 (39)
− Charlie Chaplin Hollywood 266
− George Gershwin London 104
</table>
<tableCaption confidence="0.999758">
Table 3: Person-Birthplace Pairs.
</tableCaption>
<bodyText confidence="0.9542368">
Given a pair of arguments (a1, a2), the corre-
sponding bag of sentences is created as follows:
■ A query string “a1 * * * * * * * a2” containing
seven wildcard symbols between the two arguments
is submitted to Google. The preferences are set to
search only for pages written in English, with Safe-
search turned on. This type of query will match doc-
uments where an occurrence of a1 is separated from
an occurrence of a2 by at most seven content words.
This is an approximation of our actual information
</bodyText>
<listItem confidence="0.8289405">
• Let X E X be an arbitrary bag, and let X.a1
and X.a2 be the two arguments associated with
the bag.
• Let C(X) be the size of the bag (i.e. the num-
</listItem>
<bodyText confidence="0.926652857142857">
ber of sentences in the bag), and C(X, w) the
number of sentences in the bag X that contain
the word w. Let P(wjX) = C(X, w)/C(X).
• Let P(wjX.a1 V X.a2) be the probability that
the word w appears in a sentence due only to
the presence of X.a1 or X.a2, assuming X.a1
and X.a2 are independent causes for w.
The word weights are computed as follows:
C(X, w) − P(wjX.a1 V X.a2) • C(X)
580
need: “return all documents containing a1 and a2 in itive bags in the person-birthplace dataset are sig-
the same sentence”. nificantly sparser in real positive instances than the
■ The returned documents (limited by Google to positive bags in the corporate acquisition dataset.
the first 1000) are downloaded, and then the text The subsequence kernel described in Section 4
is extracted using the HTML parser from the Java was used as a custom kernel for the LibSVM2 Java
Swing package. Whenever possible, the appropriate package. When run with the default parameters,
HTML tags (e.g. BR, DD, P, etc.) are used as hard the results were extremely poor – too much weight
end-of-sentence indicators. The text is further seg- was given to the slack term in the objective func-
mented into sentences with the OpenNLP1 package. tion. Minimizing the regularization term is essen-
■ Sentences that do not contain both arguments a1 tial in order to capture subsequence patterns shared
and a2 are discarded. For every remaining sentence, among positive bags. Therefore LibSVM was mod-
we find the occurrences of a1 and a2 that are clos- ified to solve the optimization problem from Fig-
est to each other, and create a relation example by ure 2, where the capacity parameter C is normal-
replacing a1 with (e1) and a2 with (e2). All other ized by the size of the transformed dataset. In this
occurrences of a1 and a2 are replaced with a null new formulation, C is set to its default value of 1.0
token ignored by the subsequence kernel. – changing it to other values did not result in signifi-
The number of sentences in every bag is shown in cant improvement. The trade-off between false pos-
the last column of Tables 2 &amp; 3. Because Google itive and false negative errors is controlled by the
also counts pages that are deemed too similar in the parameter cp. When set to its default value of 0.5,
first 1000, some of the bags can be relatively small. false-negative errors and false positive errors have
As described in Section 5.1, the word-argument the same impact on the objective function. As ex-
correlations are modeled through the quantity pected, setting cp to a smaller value (0.1) resulted
P(wla) = C(w, a)/C(a), estimated as the ratio be- in better performance. Tests with even lower values
tween the number of sentences containing w and a, did not improve the results.
and the number of sentences containing a. These We compare the following four systems:
counts are computed over a bag of sentences con- ■ SSK–MIL: This corresponds to the MIL formu-
taining a, which is created by querying Google for lation from Section 3, with the original subsequence
the argument a, and then by processing the results kernel described in Section 4.
as described above. ■ SSK–T1: This is the SSK–MIL system aug-
7 Experimental Evaluation mented with word weights, so that the Type I bias
Each dataset is split into two sets of bags: one is reduced, as described in Section 5.1.
for training and one for testing. The test dataset ■ BW-MIL: This is a bag-of-words kernel, in
was purposefully made difficult by including neg- which the relation examples are classified based on
ative bags with arguments that during training were the unordered words contained in the sentence. This
used in positive bags, and vice-versa. In order to baseline shows the performance of a standard text-
evaluate the relation extraction performance at the classification approach to the problem using a state-
sentence level, we manually annotated all instances of-the art algorithm (SVM).
from the positive test bags. The last column in Ta- ■ SSK–SIL: This corresponds to the original sub-
bles 2 &amp; 3 shows, between parentheses, how many sequence kernel trained with traditional, single in-
instances from the positive test bags are real pos- stance learning (SIL) supervision. For evaluation,
itive instances. The corporate acquisition test set we train on the manually labeled instances from the
has a total of 995 instances, out of which 156 are test bags. We use a combination of one positive bag
positive. The person-birthplace test set has a total and one negative bag for training, while the other
of 601 instances, and only 45 of them are positive. two bags are used for testing. The results are aver-
Extrapolating from the test set distribution, the pos- aged over all four possible combinations. Note that
the supervision provided to SSK–SIL requires sig-
</bodyText>
<figure confidence="0.985307243243243">
1http://opennlp.sourceforge.net 2http://www.csie.ntu.edu.tw/˜cjlin/libsvm
581
Precision (%)
Precision (%)
0 10 20 30 40 50 60 70 80 90 100
Recall (%)
0 10 20 30 40 50 60 70 80 90 100
Recall (%)
100
90
80
70
60
50
40
30
20
10
0
SSK-T1
SSK-MIL
BW-MIL
100
90
80
70
60
50
40
30
20
10
0
SSK-T1
SSK-MIL
BW-MIL
(a) Corporate Acquisitions (b) Person-Birthplace
</figure>
<figureCaption confidence="0.99986">
Figure 3: Precision-Recall graphs on the two datasets.
</figureCaption>
<bodyText confidence="0.998521166666667">
nificantly more annotation effort, therefore, given a
sufficient amount of training examples, we expect
this system to perform at least as well as its MIL
counterpart.
In Figure 3, precision is plotted against recall by
varying a threshold on the value of the SVM deci-
sion function. To avoid clutter, we show only the
graphs for the first three systems. In Table 4 we
show the area under the precision recall curves of
all four systems. Overall, the learned relation extrac-
tors are able to identify the relationship in novel sen-
tences quite accurately and significantly out-perform
a bag-of-words baseline. The new version of the
subsequence kernel SSK–T1 is significantly more
accurate in the MIL setting than the original sub-
sequence kernel SSK–MIL, and is also competitive
with SSK–SIL, which was trained using a reason-
able amount of manually labeled sentence examples.
</bodyText>
<table confidence="0.969621666666667">
Dataset SSK–MIL SSK–T1 BW–MIL SSK–SIL
(a) CA 76.9% 81.1% 45.9% 80.4%
(b) PB 72.5% 78.2% 69.2% 73.4%
</table>
<tableCaption confidence="0.996179">
Table 4: Area Under Precision-Recall Curve.
</tableCaption>
<sectionHeader confidence="0.99928" genericHeader="method">
8 Future Work
</sectionHeader>
<bodyText confidence="0.999864258064516">
An interesting potential application of our approach
is a web relation-extraction system similar to Google
Sets, in which the user provides only a handful of
pairs of entities known to exhibit or not to exhibit
a particular relation, and the system is used to find
other pairs of entities exhibiting the same relation.
Ideally, the user would only need to provide pos-
itive pairs. Sentences containing one of the rela-
tion arguments could be extracted from the web, and
likely negative sentence examples automatically cre-
ated by pairing this entity with other named enti-
ties mentioned in the sentence. In this scenario, the
training set can contain both false positive and false
negative noise. One useful side effect is that Type
I bias is partially removed – some bias still remains
due to combinations of at least two words, each cor-
related with a different argument of the relation.
We are also investigating methods for reducing Type
II bias, either by modifying the word weights, or by
integrating an appropriate measure of word distri-
bution across positive bags directly in the objective
function for the MIL problem. Alternatively, im-
plicit negative evidence can be extracted from sen-
tences in positive bags by exploiting the fact that, be-
sides the two relation arguments, a sentence from a
positive bag may contain other entity mentions. Any
pair of entities different from the relation pair is very
likely to be a negative example for that relation. This
is similar to the concept of negative neighborhoods
introduced by Smith and Eisner (2005), and has the
potential of eliminating both Type I and Type II bias.
</bodyText>
<sectionHeader confidence="0.999957" genericHeader="method">
9 Related Work
</sectionHeader>
<bodyText confidence="0.99791975">
One of the earliest IE methods designed to work
with a reduced amount of supervision is that of
Hearst (1992), where a small set of seed patterns
is used in a bootstrapping fashion to mine pairs of
</bodyText>
<page confidence="0.991387">
582
</page>
<bodyText confidence="0.99997424137931">
hypernym-hyponym nouns. Bootstrapping is actu-
ally orthogonal to our method, which could be used
as the pattern learner in every bootstrapping itera-
tion. A more recent IE system that works by boot-
strapping relation extraction patterns from the web is
KNOWITALL (Etzioni et al., 2005). For a given tar-
get relation, supervision in KNOWITALL is provided
as a rule template containing words that describe the
class of the arguments (e.g. “company”), and a small
set of seed extraction patterns (e.g. “has acquired”).
In our approach, the type of supervision is different –
we ask only for pairs of entities known to exhibit the
target relation or not. Also, KNOWITALL requires
large numbers of search engine queries in order to
collect and validate extraction patterns, therefore ex-
periments can take weeks to complete. Compara-
tively, the approach presented in this paper requires
only a small number of queries: one query per rela-
tion pair, and one query for each relation argument.
Craven and Kumlien (1999) create a noisy train-
ing set for the subcellular-localization relation by
mining Medline for sentences that contain tuples
extracted from relevant medical databases. To our
knowledge, this is the first approach that is using a
“weakly” labeled dataset for relation extraction. The
resulting bags however are very dense in positive ex-
amples, and they are also many and small – conse-
quently, the two types of bias are not likely to have
significant impact on their system’s performance.
</bodyText>
<sectionHeader confidence="0.997653" genericHeader="conclusions">
10 Conclusion
</sectionHeader>
<bodyText confidence="0.9999973">
We have presented a new approach to relation ex-
traction that leverages the vast amount of informa-
tion available on the web. The new RE system is
trained using only a handful of entity pairs known to
exhibit and not exhibit the target relationship. We
have extended an existing relation extraction ker-
nel to learn in this setting and to resolve problems
caused by the minimal supervision provided. Exper-
imental results demonstrate that the new approach
can reliably extract relations from web documents.
</bodyText>
<sectionHeader confidence="0.999332" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99780825">
We would like to thank the anonymous reviewers for
their helpful suggestions. This work was supported
by grant IIS-0325116 from the NSF, and a gift from
Google Inc.
</bodyText>
<sectionHeader confidence="0.998403" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99988188">
Stuart Andrews, Ioannis Tsochantaridis, and Thomas Hofmann.
2003. Support vector machines for multiple-instance learn-
ing. In NIPS 15, pages 561–568, Vancouver, BC. MIT Press.
Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998.
The Berkeley FrameNet project. In Proc. of COLINGACL
’98, pages 86–90, San Francisco, CA. Morgan Kaufmann
Publishers.
Razvan C. Bunescu and Raymond J. Mooney. 2006. Sub-
sequence kernels for relation extraction. In Y. Weiss,
B. Sch¨olkopf, and J. Platt, editors, NIPS 18.
M. Craven and J. Kumlien. 1999. Constructing biologi-
cal knowledge bases by extracting information from text
sources. In Proc. of ISMB’99, pages 77–86, Heidelberg,
Germany.
Aron Culotta and Jeffrey Sorensen. 2004. Dependency tree
kernels for relation extraction. In Proc. of ACL’04, pages
423–429, Barcelona, Spain, July.
Thomas G. Dietterich, Richard H. Lathrop, and Tomas Lozano-
Perez. 1997. Solving the multiple instance problem with
axis-parallel rectangles. Arti�cial Intelligence, 89(1-2):31–
71.
Oren Etzioni, Michael Cafarella, Doug Downey, Ana-Maria
Popescu, Tal Shaked, Stephen Soderland, Daniel S. Weld,
and Alexander Yates. 2005. Unsupervised named-entity ex-
traction from the web: an experimental study. Arti�cial In-
telligence, 165(1):91–134.
T. Gartner, P.A. Flach, A. Kowalczyk, and A.J. Smola. 2002.
Multi-instance kernels. In In Proc. of ICML’02, pages 179–
186, Sydney, Australia, July. Morgan Kaufmann.
M. A. Hearst. 1992. Automatic acquisition of hyponyms from
large text corpora. In Proc. of ACL’92, Nantes, France.
Judea Pearl. 1986. Fusion, propagation, and structuring in be-
lief networks. Arti�cial Intelligence, 29(3):241–288.
Soumya Ray and Mark Craven. 2005. Supervised versus mul-
tiple instance learning: An empirical comparison. In Proc.
of ICML’05, pages 697–704, Bonn, Germany.
Bernhard Sch¨olkopf and Alexander J. Smola. 2002. Learning
with kernels - support vector machines, regularization, opti-
mization and beyond. MIT Press, Cambridge, MA.
N. A. Smith and J. Eisner. 2005. Contrastive estimation: Train-
ing log-linear models on unlabeled data. In Proc. of ACL’05,
pages 354–362, Ann Arbor, Michigan.
Vladimir N. Vapnik. 1998. Statistical Learning Theory. John
Wiley &amp; Sons.
D. Zelenko, C. Aone, and A. Richardella. 2003. Kernel meth-
ods for relation extraction. Journal of Machine Learning
Research, 3:1083–1106.
Q. Zhang, S. A. Goldman, W. Yu, and J. Fritts. 2002. Content-
based image retrieval using multiple-instance learning. In
Proc. of ICML’02, pages 682–689.
</reference>
<page confidence="0.999125">
583
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.273066">
<title confidence="0.9965065">Learning to Extract Relations from the Web using Minimal Supervision</title>
<author confidence="0.999866">Razvan C Bunescu</author>
<affiliation confidence="0.90517">Department of Computer Sciences University of Texas at Austin 1 University Station C0500</affiliation>
<address confidence="0.70456">Austin, TX 78712</address>
<email confidence="0.999564">razvan@cs.utexas.edu</email>
<author confidence="0.999997">Raymond J Mooney</author>
<affiliation confidence="0.86955275">Department of Computer Sciences University of Texas at Austin 1 University Station C0500 Austin, TX 78712</affiliation>
<email confidence="0.999538">mooney@cs.utexas.edu</email>
<abstract confidence="0.999662833333333">We present a new approach to relation extraction that requires only a handful of training examples. Given a few pairs of named entities known to exhibit or not exhibit a particular relation, bags of sentences containing the pairs are extracted from the web. We extend an existing relation extraction method to handle this weaker form of supervision, and present experimental results demonstrating that our approach can reliably extract relations from web documents.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Stuart Andrews</author>
<author>Ioannis Tsochantaridis</author>
<author>Thomas Hofmann</author>
</authors>
<title>Support vector machines for multiple-instance learning.</title>
<date>2003</date>
<booktitle>In NIPS 15,</booktitle>
<pages>561--568</pages>
<publisher>MIT Press.</publisher>
<location>Vancouver, BC.</location>
<contexts>
<context position="2519" citStr="Andrews et al., 2003" startWordPosition="393" endWordPosition="396">e sentences for negative pairs state the targeted relation. Multiple instance learning (MIL) is a machine learning framework that exploits this sort of weak supervision, in which a positive bag is a set of instances which is guaranteed to contain at least one positive example, and a negative bag is a set of instances all of which are negative. MIL was originally introduced to solve a problem in biochemistry (Dietterich et al., 1997); however, it has since been applied to problems in other areas such as classifying image regions in computer vision (Zhang et al., 2002), and text categorization (Andrews et al., 2003; Ray and Craven, 2005). We have extended an existing approach to relation extraction using support vector machines and string kernels (Bunescu and Mooney, 2006) to handle this weaker form of MIL supervision. This approach can sometimes be misled by textual features correlated with the specific entities in the few training pairs provided. Therefore, we also describe a method for weighting features in order to focus on those correlated with the target relation rather than with the individual entities. We present experimental results demonstrating that our approach is able to accurately extract </context>
</contexts>
<marker>Andrews, Tsochantaridis, Hofmann, 2003</marker>
<rawString>Stuart Andrews, Ioannis Tsochantaridis, and Thomas Hofmann. 2003. Support vector machines for multiple-instance learning. In NIPS 15, pages 561–568, Vancouver, BC. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In Proc. of COLINGACL ’98,</booktitle>
<pages>86--90</pages>
<publisher>Morgan Kaufmann Publishers.</publisher>
<location>San Francisco, CA.</location>
<contexts>
<context position="11882" citStr="Baker et al., 1998" startWordPosition="1989" endWordPosition="1992">or any sequence of words between wi and wi+1. Then the sequence s will be represented in the relation example as a feature with weight computed as τ(s) = λgP). The parameter λ controls the magnitude of the gap penalty, where g(s) = Ei |gi |is the total gap. Many relations, like the ones that we explore in the experimental evaluation, cannot be expressed without using at least one content word. We therefore modified the kernel computation to optionally ignore subsequence patterns formed exclusively of � ξx xEX � ξx xEX 578 stop words and punctuation signs. In Section 5.1, FrameNet terminology (Baker et al., 1998), these we introduce a new weighting scheme, wherein a correspond to instantiated frame elements. For exweight is assigned to every token. Correspondingly, ample, the corporate acquisition frame can be seen every sequence feature will have an additional mul- as a subtype of the “Getting” frame in FrameNet. tiplicative weight, computed as the product of the The core elements in this frame are the Recipiweights of all the tokens in the sequence. The aim ent (e.g. Google) and the Theme (e.g. YouTube), of this new weighting scheme, as detailed in the next which for the acquisition relationship coi</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet project. In Proc. of COLINGACL ’98, pages 86–90, San Francisco, CA. Morgan Kaufmann Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
<author>Raymond J Mooney</author>
</authors>
<title>Subsequence kernels for relation extraction.</title>
<date>2006</date>
<journal>NIPS</journal>
<volume>18</volume>
<editor>In Y. Weiss, B. Sch¨olkopf, and J. Platt, editors,</editor>
<contexts>
<context position="1219" citStr="Bunescu and Mooney, 2006" startWordPosition="178" endWordPosition="181">irs are extracted from the web. We extend an existing relation extraction method to handle this weaker form of supervision, and present experimental results demonstrating that our approach can reliably extract relations from web documents. 1 Introduction A growing body of recent work in information extraction has addressed the problem of relation extraction (RE), identifying relationships between entities stated in text, such as LivesIn(Person, Location) or EmployedBy(Person, Company). Supervised learning has been shown to be effective for RE (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2006); however, annotating large corpora with examples of the relations to be extracted is expensive and tedious. In this paper, we introduce a supervised learning approach to RE that requires only a handful of training examples and uses the web as a corpus. Given a few pairs of well-known entities that clearly exhibit or do not exhibit a particular relation, such as CorpAcquired(Google, YouTube) and not(CorpAcquired(Yahoo, Microsoft)), a search engine is used to find sentences on the web that mention both of the entities in each of the pairs. 576 Although not all of the sentences for positive pair</context>
<context position="2680" citStr="Bunescu and Mooney, 2006" startWordPosition="418" endWordPosition="421"> supervision, in which a positive bag is a set of instances which is guaranteed to contain at least one positive example, and a negative bag is a set of instances all of which are negative. MIL was originally introduced to solve a problem in biochemistry (Dietterich et al., 1997); however, it has since been applied to problems in other areas such as classifying image regions in computer vision (Zhang et al., 2002), and text categorization (Andrews et al., 2003; Ray and Craven, 2005). We have extended an existing approach to relation extraction using support vector machines and string kernels (Bunescu and Mooney, 2006) to handle this weaker form of MIL supervision. This approach can sometimes be misled by textual features correlated with the specific entities in the few training pairs provided. Therefore, we also describe a method for weighting features in order to focus on those correlated with the target relation rather than with the individual entities. We present experimental results demonstrating that our approach is able to accurately extract relations from the web by learning from such weak supervision. 2 Problem Description We address the task of learning a relation extraction system targeted to a f</context>
<context position="10336" citStr="Bunescu and Mooney (2006)" startWordPosition="1712" endWordPosition="1715">dot products of the form K(x1, x2) = φ(x1)φ(x2). The kernel K is instantiated to a subsequence kernel, as described in the next section. 4 Relation Extraction Kernel The training bags consist of sentences extracted from online documents, using the methodology described in Section 6. Parsing web documents in order to obtain a syntactic analysis often gives unreliable results – the type of narrative can vary greatly from one web document to another, and sentences with grammatical errors are frequent. Therefore, for the initial experiments, we used a modified version of the subsequence kernel of Bunescu and Mooney (2006), which does not require syntactic information. This kernel computes the number of common subsequences of tokens between two sentences. The subsequences are constrained to be “anchored” at the two entity names, and there is a maximum number of tokens that can appear in a sequence. For example, a subsequence feature for the sentence S1 in Figure 1 is s� = “(e1) ... bought ... (e2) ... in ... billion ... deal”, where (e1) and (e2) are generic placeholders for the two entity names. The subsequence kernel induces a feature space where each dimension corresponds to a sequence of words. Any such seq</context>
</contexts>
<marker>Bunescu, Mooney, 2006</marker>
<rawString>Razvan C. Bunescu and Raymond J. Mooney. 2006. Subsequence kernels for relation extraction. In Y. Weiss, B. Sch¨olkopf, and J. Platt, editors, NIPS 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Craven</author>
<author>J Kumlien</author>
</authors>
<title>Constructing biological knowledge bases by extracting information from text sources.</title>
<date>1999</date>
<booktitle>In Proc. of ISMB’99,</booktitle>
<pages>77--86</pages>
<location>Heidelberg, Germany.</location>
<contexts>
<context position="28586" citStr="Craven and Kumlien (1999)" startWordPosition="4886" endWordPosition="4889"> words that describe the class of the arguments (e.g. “company”), and a small set of seed extraction patterns (e.g. “has acquired”). In our approach, the type of supervision is different – we ask only for pairs of entities known to exhibit the target relation or not. Also, KNOWITALL requires large numbers of search engine queries in order to collect and validate extraction patterns, therefore experiments can take weeks to complete. Comparatively, the approach presented in this paper requires only a small number of queries: one query per relation pair, and one query for each relation argument. Craven and Kumlien (1999) create a noisy training set for the subcellular-localization relation by mining Medline for sentences that contain tuples extracted from relevant medical databases. To our knowledge, this is the first approach that is using a “weakly” labeled dataset for relation extraction. The resulting bags however are very dense in positive examples, and they are also many and small – consequently, the two types of bias are not likely to have significant impact on their system’s performance. 10 Conclusion We have presented a new approach to relation extraction that leverages the vast amount of information</context>
</contexts>
<marker>Craven, Kumlien, 1999</marker>
<rawString>M. Craven and J. Kumlien. 1999. Constructing biological knowledge bases by extracting information from text sources. In Proc. of ISMB’99, pages 77–86, Heidelberg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Jeffrey Sorensen</author>
</authors>
<title>Dependency tree kernels for relation extraction.</title>
<date>2004</date>
<booktitle>In Proc. of ACL’04,</booktitle>
<pages>423--429</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="1192" citStr="Culotta and Sorensen, 2004" startWordPosition="174" endWordPosition="177"> sentences containing the pairs are extracted from the web. We extend an existing relation extraction method to handle this weaker form of supervision, and present experimental results demonstrating that our approach can reliably extract relations from web documents. 1 Introduction A growing body of recent work in information extraction has addressed the problem of relation extraction (RE), identifying relationships between entities stated in text, such as LivesIn(Person, Location) or EmployedBy(Person, Company). Supervised learning has been shown to be effective for RE (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2006); however, annotating large corpora with examples of the relations to be extracted is expensive and tedious. In this paper, we introduce a supervised learning approach to RE that requires only a handful of training examples and uses the web as a corpus. Given a few pairs of well-known entities that clearly exhibit or do not exhibit a particular relation, such as CorpAcquired(Google, YouTube) and not(CorpAcquired(Yahoo, Microsoft)), a search engine is used to find sentences on the web that mention both of the entities in each of the pairs. 576 Although not all of the </context>
</contexts>
<marker>Culotta, Sorensen, 2004</marker>
<rawString>Aron Culotta and Jeffrey Sorensen. 2004. Dependency tree kernels for relation extraction. In Proc. of ACL’04, pages 423–429, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas G Dietterich</author>
<author>Richard H Lathrop</author>
<author>Tomas LozanoPerez</author>
</authors>
<title>Solving the multiple instance problem with axis-parallel rectangles.</title>
<date>1997</date>
<journal>Arti�cial Intelligence,</journal>
<pages>89--1</pages>
<contexts>
<context position="2335" citStr="Dietterich et al., 1997" startWordPosition="363" endWordPosition="366">t mention both of the entities in each of the pairs. 576 Although not all of the sentences for positive pairs will state the desired relationship, many of them will. Presumably, none of the sentences for negative pairs state the targeted relation. Multiple instance learning (MIL) is a machine learning framework that exploits this sort of weak supervision, in which a positive bag is a set of instances which is guaranteed to contain at least one positive example, and a negative bag is a set of instances all of which are negative. MIL was originally introduced to solve a problem in biochemistry (Dietterich et al., 1997); however, it has since been applied to problems in other areas such as classifying image regions in computer vision (Zhang et al., 2002), and text categorization (Andrews et al., 2003; Ray and Craven, 2005). We have extended an existing approach to relation extraction using support vector machines and string kernels (Bunescu and Mooney, 2006) to handle this weaker form of MIL supervision. This approach can sometimes be misled by textual features correlated with the specific entities in the few training pairs provided. Therefore, we also describe a method for weighting features in order to foc</context>
</contexts>
<marker>Dietterich, Lathrop, LozanoPerez, 1997</marker>
<rawString>Thomas G. Dietterich, Richard H. Lathrop, and Tomas LozanoPerez. 1997. Solving the multiple instance problem with axis-parallel rectangles. Arti�cial Intelligence, 89(1-2):31– 71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Michael Cafarella</author>
<author>Doug Downey</author>
<author>Ana-Maria Popescu</author>
<author>Tal Shaked</author>
<author>Stephen Soderland</author>
<author>Daniel S Weld</author>
<author>Alexander Yates</author>
</authors>
<title>Unsupervised named-entity extraction from the web: an experimental study.</title>
<date>2005</date>
<journal>Arti�cial Intelligence,</journal>
<volume>165</volume>
<issue>1</issue>
<contexts>
<context position="27864" citStr="Etzioni et al., 2005" startWordPosition="4767" endWordPosition="4770">e neighborhoods introduced by Smith and Eisner (2005), and has the potential of eliminating both Type I and Type II bias. 9 Related Work One of the earliest IE methods designed to work with a reduced amount of supervision is that of Hearst (1992), where a small set of seed patterns is used in a bootstrapping fashion to mine pairs of 582 hypernym-hyponym nouns. Bootstrapping is actually orthogonal to our method, which could be used as the pattern learner in every bootstrapping iteration. A more recent IE system that works by bootstrapping relation extraction patterns from the web is KNOWITALL (Etzioni et al., 2005). For a given target relation, supervision in KNOWITALL is provided as a rule template containing words that describe the class of the arguments (e.g. “company”), and a small set of seed extraction patterns (e.g. “has acquired”). In our approach, the type of supervision is different – we ask only for pairs of entities known to exhibit the target relation or not. Also, KNOWITALL requires large numbers of search engine queries in order to collect and validate extraction patterns, therefore experiments can take weeks to complete. Comparatively, the approach presented in this paper requires only a</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Popescu, Shaked, Soderland, Weld, Yates, 2005</marker>
<rawString>Oren Etzioni, Michael Cafarella, Doug Downey, Ana-Maria Popescu, Tal Shaked, Stephen Soderland, Daniel S. Weld, and Alexander Yates. 2005. Unsupervised named-entity extraction from the web: an experimental study. Arti�cial Intelligence, 165(1):91–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Gartner</author>
<author>P A Flach</author>
<author>A Kowalczyk</author>
<author>A J Smola</author>
</authors>
<title>Multi-instance kernels. In</title>
<date>2002</date>
<booktitle>In Proc. of ICML’02,</booktitle>
<pages>179--186</pages>
<publisher>Morgan Kaufmann.</publisher>
<location>Sydney, Australia,</location>
<contexts>
<context position="6957" citStr="Gartner et al. (2002)" startWordPosition="1104" endWordPosition="1107">gh accuracy obtained by kernel-based SVMs when applied to various natural language tasks, and in particular to relation extraction. Through the use of kernels, SVMs (Vapnik, 1998; Sch¨olkopf and Smola, 2002) can work efficiently with instances that implicitly belong to a high dimensional feature space. When used for classification, the decision function computed by the learning algorithm is equivalent to a hyperplane in this feature space. Overfitting is avoided in the SVM formulation by requiring that positive and negative training instances be maximally separated by the decision hyperplane. Gartner et al. (2002) adapted SVMs to the MIL setting using various multi-instance kernels. Two of these – the normalized set kernel, and the statistic kernel – have been experimentally compared to other methods by Ray and Craven (2005), with competitive results. Alternatively, a simple approach to MIL is to transform it into a standard supervised learning problem by labeling all instances from positive bags as positive. An interesting outcome of the study conducted by Ray and Craven (2005) was that, despite the class noise in the resulting positive examples, such a simple approach often obtains competitive result</context>
</contexts>
<marker>Gartner, Flach, Kowalczyk, Smola, 2002</marker>
<rawString>T. Gartner, P.A. Flach, A. Kowalczyk, and A.J. Smola. 2002. Multi-instance kernels. In In Proc. of ICML’02, pages 179– 186, Sydney, Australia, July. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proc. of ACL’92,</booktitle>
<location>Nantes, France.</location>
<contexts>
<context position="27489" citStr="Hearst (1992)" startWordPosition="4706" endWordPosition="4707">vely, implicit negative evidence can be extracted from sentences in positive bags by exploiting the fact that, besides the two relation arguments, a sentence from a positive bag may contain other entity mentions. Any pair of entities different from the relation pair is very likely to be a negative example for that relation. This is similar to the concept of negative neighborhoods introduced by Smith and Eisner (2005), and has the potential of eliminating both Type I and Type II bias. 9 Related Work One of the earliest IE methods designed to work with a reduced amount of supervision is that of Hearst (1992), where a small set of seed patterns is used in a bootstrapping fashion to mine pairs of 582 hypernym-hyponym nouns. Bootstrapping is actually orthogonal to our method, which could be used as the pattern learner in every bootstrapping iteration. A more recent IE system that works by bootstrapping relation extraction patterns from the web is KNOWITALL (Etzioni et al., 2005). For a given target relation, supervision in KNOWITALL is provided as a rule template containing words that describe the class of the arguments (e.g. “company”), and a small set of seed extraction patterns (e.g. “has acquire</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>M. A. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proc. of ACL’92, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judea Pearl</author>
</authors>
<title>Fusion, propagation, and structuring in belief networks.</title>
<date>1986</date>
<journal>Arti�cial Intelligence,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="16989" citStr="Pearl, 1986" startWordPosition="2883" endWordPosition="2884">uce some notation: T(w) = C(X, w) P(wjX.a1 V X.a2) = 1 − (2) P(wjX) The quantity P(wjX.a1 V X.a2) • C(X) represents the expected number of sentences in which w would occur, if the only causes were X.a1 or X.a2, independent of each other. We want to discard this quantity from the total number of occurrences C(X, w), so that the effect of correlations with X.a1 or X.a2 is eliminated. We still need to compute P(wjX.a1 V X.a2). Because in the definition of P(wjX.a1 V X.a2), the arguments X.a1 and X.a2 were considered independent causes, P(wjX.a1 V X.a2) can be computed with the noisy-or operator (Pearl, 1986): P(•) = 1−(1−P(wja1)) • (1−P(wja2)) (3) = P(wja1)+P(wja2)−P(wja1) • P(wja2) The quantity P(wja) represents the probability that the word w appears in a sentence due only to the presence of a, and it could be estimated using counts on a sufficiently large corpus. For our experimental evaluation, we used the following approximation: given an argument a, a set of sentences containing a are extracted from web documents (details in Section 6). Then P(wja) is simply approximated with the ratio of the number of sentences containing w over the total number of sentences, i.e. P(wja) = C(w, a)/C(a). Be</context>
</contexts>
<marker>Pearl, 1986</marker>
<rawString>Judea Pearl. 1986. Fusion, propagation, and structuring in belief networks. Arti�cial Intelligence, 29(3):241–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soumya Ray</author>
<author>Mark Craven</author>
</authors>
<title>Supervised versus multiple instance learning: An empirical comparison.</title>
<date>2005</date>
<booktitle>In Proc. of ICML’05,</booktitle>
<pages>697--704</pages>
<location>Bonn, Germany.</location>
<contexts>
<context position="2542" citStr="Ray and Craven, 2005" startWordPosition="397" endWordPosition="400">ve pairs state the targeted relation. Multiple instance learning (MIL) is a machine learning framework that exploits this sort of weak supervision, in which a positive bag is a set of instances which is guaranteed to contain at least one positive example, and a negative bag is a set of instances all of which are negative. MIL was originally introduced to solve a problem in biochemistry (Dietterich et al., 1997); however, it has since been applied to problems in other areas such as classifying image regions in computer vision (Zhang et al., 2002), and text categorization (Andrews et al., 2003; Ray and Craven, 2005). We have extended an existing approach to relation extraction using support vector machines and string kernels (Bunescu and Mooney, 2006) to handle this weaker form of MIL supervision. This approach can sometimes be misled by textual features correlated with the specific entities in the few training pairs provided. Therefore, we also describe a method for weighting features in order to focus on those correlated with the target relation rather than with the individual entities. We present experimental results demonstrating that our approach is able to accurately extract relations from the web </context>
<context position="7172" citStr="Ray and Craven (2005)" startWordPosition="1140" endWordPosition="1143">k efficiently with instances that implicitly belong to a high dimensional feature space. When used for classification, the decision function computed by the learning algorithm is equivalent to a hyperplane in this feature space. Overfitting is avoided in the SVM formulation by requiring that positive and negative training instances be maximally separated by the decision hyperplane. Gartner et al. (2002) adapted SVMs to the MIL setting using various multi-instance kernels. Two of these – the normalized set kernel, and the statistic kernel – have been experimentally compared to other methods by Ray and Craven (2005), with competitive results. Alternatively, a simple approach to MIL is to transform it into a standard supervised learning problem by labeling all instances from positive bags as positive. An interesting outcome of the study conducted by Ray and Craven (2005) was that, despite the class noise in the resulting positive examples, such a simple approach often obtains competitive results when compared against other more sophisticated MIL methods. We believe that an MIL method based on multiinstance kernels is not appropriate for training datasets that contain just a few, very large bags. In a mult</context>
<context position="8580" citStr="Ray and Craven, 2005" startWordPosition="1376" endWordPosition="1379">r of training bags. Taking the bags from Table 1 as a sample training set, the decision function is going to be specified by at most seven parameters: the coefficients for at most six support vectors, plus an optional bias parameter. A hypothesis space characterized by such a small number of parameters is likely to have insufficient capacity. Based on these observations, we decided to transform the MIL problem into a standard supervised problem as described above. The use of this approach is further motivated by its simplicity and its observed competitive performance on very diverse datasets (Ray and Craven, 2005). Let X be the set of bags used for training, Xp C X the set of positive bags, and Xn C X the set of negative bags. For any instance x E X from a bag X E X, let φ(x) be the (implicit) feature vector representation of x. Then the corresponding SVM optimization problem can be formulated as in Figure 2: minimize: J(w, b, ξ) = 2 lw l2 + L (cp L —p + cn Lp =n �-p = XEXp �=n = XEXn subject to: w φ(x) + b &gt; +1 − ξx, bx E X E Xp w φ(x) + b &lt; −1 + ξx, bxEXEXn ξx &gt; 0 Figure 2: SVM Optimization Problem. The capacity control parameter C is normalized by the total number of instances L = Lp + Ln = EXEXp |X</context>
</contexts>
<marker>Ray, Craven, 2005</marker>
<rawString>Soumya Ray and Mark Craven. 2005. Supervised versus multiple instance learning: An empirical comparison. In Proc. of ICML’05, pages 697–704, Bonn, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernhard Sch¨olkopf</author>
<author>Alexander J Smola</author>
</authors>
<title>Learning with kernels - support vector machines, regularization, optimization and beyond.</title>
<date>2002</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Sch¨olkopf, Smola, 2002</marker>
<rawString>Bernhard Sch¨olkopf and Alexander J. Smola. 2002. Learning with kernels - support vector machines, regularization, optimization and beyond. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N A Smith</author>
<author>J Eisner</author>
</authors>
<title>Contrastive estimation: Training log-linear models on unlabeled data.</title>
<date>2005</date>
<booktitle>In Proc. of ACL’05,</booktitle>
<pages>354--362</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="27296" citStr="Smith and Eisner (2005)" startWordPosition="4668" endWordPosition="4671">ng Type II bias, either by modifying the word weights, or by integrating an appropriate measure of word distribution across positive bags directly in the objective function for the MIL problem. Alternatively, implicit negative evidence can be extracted from sentences in positive bags by exploiting the fact that, besides the two relation arguments, a sentence from a positive bag may contain other entity mentions. Any pair of entities different from the relation pair is very likely to be a negative example for that relation. This is similar to the concept of negative neighborhoods introduced by Smith and Eisner (2005), and has the potential of eliminating both Type I and Type II bias. 9 Related Work One of the earliest IE methods designed to work with a reduced amount of supervision is that of Hearst (1992), where a small set of seed patterns is used in a bootstrapping fashion to mine pairs of 582 hypernym-hyponym nouns. Bootstrapping is actually orthogonal to our method, which could be used as the pattern learner in every bootstrapping iteration. A more recent IE system that works by bootstrapping relation extraction patterns from the web is KNOWITALL (Etzioni et al., 2005). For a given target relation, s</context>
</contexts>
<marker>Smith, Eisner, 2005</marker>
<rawString>N. A. Smith and J. Eisner. 2005. Contrastive estimation: Training log-linear models on unlabeled data. In Proc. of ACL’05, pages 354–362, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>John Wiley &amp; Sons.</publisher>
<contexts>
<context position="6514" citStr="Vapnik, 1998" startWordPosition="1039" endWordPosition="1040">ll, while the average size of the bags is very large. 3 Multiple Instance Learning Since its introduction by Dietterich (1997), an extensive and quite diverse set of methods have been proposed for solving the MIL problem. For the task of relation extraction, we consider only MIL methods where the decision function can be expressed in terms of kernels computed between bag instances. This choice was motivated by the comparatively high accuracy obtained by kernel-based SVMs when applied to various natural language tasks, and in particular to relation extraction. Through the use of kernels, SVMs (Vapnik, 1998; Sch¨olkopf and Smola, 2002) can work efficiently with instances that implicitly belong to a high dimensional feature space. When used for classification, the decision function computed by the learning algorithm is equivalent to a hyperplane in this feature space. Overfitting is avoided in the SVM formulation by requiring that positive and negative training instances be maximally separated by the decision hyperplane. Gartner et al. (2002) adapted SVMs to the MIL setting using various multi-instance kernels. Two of these – the normalized set kernel, and the statistic kernel – have been experim</context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>Vladimir N. Vapnik. 1998. Statistical Learning Theory. John Wiley &amp; Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Zelenko</author>
<author>C Aone</author>
<author>A Richardella</author>
</authors>
<title>Kernel methods for relation extraction.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--1083</pages>
<contexts>
<context position="1164" citStr="Zelenko et al., 2003" startWordPosition="170" endWordPosition="173">ular relation, bags of sentences containing the pairs are extracted from the web. We extend an existing relation extraction method to handle this weaker form of supervision, and present experimental results demonstrating that our approach can reliably extract relations from web documents. 1 Introduction A growing body of recent work in information extraction has addressed the problem of relation extraction (RE), identifying relationships between entities stated in text, such as LivesIn(Person, Location) or EmployedBy(Person, Company). Supervised learning has been shown to be effective for RE (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2006); however, annotating large corpora with examples of the relations to be extracted is expensive and tedious. In this paper, we introduce a supervised learning approach to RE that requires only a handful of training examples and uses the web as a corpus. Given a few pairs of well-known entities that clearly exhibit or do not exhibit a particular relation, such as CorpAcquired(Google, YouTube) and not(CorpAcquired(Yahoo, Microsoft)), a search engine is used to find sentences on the web that mention both of the entities in each of the pairs. </context>
</contexts>
<marker>Zelenko, Aone, Richardella, 2003</marker>
<rawString>D. Zelenko, C. Aone, and A. Richardella. 2003. Kernel methods for relation extraction. Journal of Machine Learning Research, 3:1083–1106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Zhang</author>
<author>S A Goldman</author>
<author>W Yu</author>
<author>J Fritts</author>
</authors>
<title>Contentbased image retrieval using multiple-instance learning.</title>
<date>2002</date>
<booktitle>In Proc. of ICML’02,</booktitle>
<pages>682--689</pages>
<contexts>
<context position="2472" citStr="Zhang et al., 2002" startWordPosition="386" endWordPosition="389">hip, many of them will. Presumably, none of the sentences for negative pairs state the targeted relation. Multiple instance learning (MIL) is a machine learning framework that exploits this sort of weak supervision, in which a positive bag is a set of instances which is guaranteed to contain at least one positive example, and a negative bag is a set of instances all of which are negative. MIL was originally introduced to solve a problem in biochemistry (Dietterich et al., 1997); however, it has since been applied to problems in other areas such as classifying image regions in computer vision (Zhang et al., 2002), and text categorization (Andrews et al., 2003; Ray and Craven, 2005). We have extended an existing approach to relation extraction using support vector machines and string kernels (Bunescu and Mooney, 2006) to handle this weaker form of MIL supervision. This approach can sometimes be misled by textual features correlated with the specific entities in the few training pairs provided. Therefore, we also describe a method for weighting features in order to focus on those correlated with the target relation rather than with the individual entities. We present experimental results demonstrating t</context>
</contexts>
<marker>Zhang, Goldman, Yu, Fritts, 2002</marker>
<rawString>Q. Zhang, S. A. Goldman, W. Yu, and J. Fritts. 2002. Contentbased image retrieval using multiple-instance learning. In Proc. of ICML’02, pages 682–689.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>