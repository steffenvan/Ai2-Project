<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000043">
<title confidence="0.982807">
A New Approach to Lexical Disambiguation of Arabic Text
</title>
<author confidence="0.707194">
Rushin Shah
</author>
<affiliation confidence="0.623348">
Carnegie Mellon University
</affiliation>
<address confidence="0.3767415">
5000 Forbes Avenue
Pittsburgh, PA 15213, USA
</address>
<email confidence="0.743371">
rnshah@cs.cmu.edu
</email>
<note confidence="0.723797">
Paramveer S. Dhillon, Mark Liberman,
Dean Foster, Mohamed Maamouri
and Lyle Ungar
</note>
<affiliation confidence="0.938359">
University of Pennsylvania
</affiliation>
<address confidence="0.6717925">
3451 Walnut Street
Philadelphia, PA 19104, USA
</address>
<email confidence="0.992296">
{dhillon|myl|ungar}@cis.upenn.edu,
foster@wharton.upenn.edu,
maamouri@ldc.upenn.edu
</email>
<sectionHeader confidence="0.99859" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999168458333334">
We describe a model for the lexical analy-
sis of Arabic text, using the lists of alterna-
tives supplied by a broad-coverage morpho-
logical analyzer, SAMA, which include sta-
ble lemma IDs that correspond to combina-
tions of broad word sense categories and POS
tags. We break down each of the hundreds
of thousands of possible lexical labels into
its constituent elements, including lemma ID
and part-of-speech. Features are computed
for each lexical token based on its local and
document-level context and used in a novel,
simple, and highly efficient two-stage super-
vised machine learning algorithm that over-
comes the extreme sparsity of label distribu-
tion in the training data. The resulting system
achieves accuracy of 90.6% for its first choice,
and 96.2% for its top two choices, in selecting
among the alternatives provided by the SAMA
lexical analyzer. We have successfully used
this system in applications such as an online
reading helper for intermediate learners of the
Arabic language, and a tool for improving the
productivity of Arabic Treebank annotators.
</bodyText>
<sectionHeader confidence="0.968998" genericHeader="categories and subject descriptors">
1 Background and Motivation
</sectionHeader>
<bodyText confidence="0.998676816901409">
This paper presents a methodology for generating
high quality lexical analysis of highly inflected lan-
guages, and demonstrates excellent performance ap-
plying our approach to Arabic. Lexical analysis of
the written form of a language involves resolving,
explicitly or implicitly, several different kinds of am-
biguities. Unfortunately, the usual ways of talking
about this process are also ambiguous, and our gen-
eral approach to the problem, though not unprece-
dented, has uncommon aspects. Therefore, in order
to avoid confusion, we begin by describing how we
define the problem.
In an inflected language with an alphabetic writ-
ing system, a central issue is how to interpret strings
of characters as forms of words. For example, the
English letter-string ‘winds’ will normally be in-
terpreted in one of four different ways, all four
of which involve the sequence of two formatives
wind+s. The stem ‘wind’ might be analyzed as (1) a
noun meaning something like “air in motion”, pro-
nounced [wInd] , which we can associate with an ar-
bitrary but stable identifier like wind n1; (2) a verb
wind v1 derived from that noun, and pronounced the
same way; (3) a verb wind v2 meaning something
like “(cause to) twist”, pronounced [waInd]; or (4)
a noun wind n2 derived from that verb, and pro-
nounced the same way. Each of these “lemmas”, or
dictionary entries, will have several distinguishable
senses, which we may also wish to associate with
stable identifiers. The affix ‘-s’ might be analyzed
as the plural inflection, if the stem is a noun; or as
the third-person singular inflection, if the stem is a
verb.
We see this analysis as conceptually divided into
four parts: 1) Morphological analysis, which rec-
ognizes that the letter-string ‘winds’ might be (per-
haps among other things) wind/N + s/PLURAL or
wind/V + s/3SING; 2) Morphological disambigua-
tion, which involves deciding, for example, that in
the phrase “the four winds”, ‘winds’ is probably a
plural noun, i.e. wind/N + s/PLURAL; 3) Lemma
analysis, which involves recognizing that the stem
wind in ‘winds’ might be any of the four lem-
mas listed above – perhaps with a further listing of
senses or other sub-entries for each of them; and 4)
Lemma disambiguation, deciding, for example, that
the phrase “the four winds” probably involves the
lemma wind n1.
Confusingly, the standard word-analysis tasks in
computational linguistics involve various combina-
tions of pieces of these logically-distinguished op-
erations. Thus, “part of speech (POS) tagging” is
mainly what we’ve called “morphological disam-
biguation”, except that it doesn’t necessarily require
identifying the specific stems and affixes involved.
In some cases, it also may require a small amount of
“lemma disambiguation”, for example to distinguish
a proper noun from a common noun. “Sense disam-
biguation” is basically a form of what we’ve called
“lemma disambiguation”, except that the sense dis-
ambiguation task may assume that the part of speech
is known, and may break down lexical identity more
finely than our system happens to do. “Lemmatiza-
tion” generally refers to a radically simplified form
of “lemma analysis” and “lemma disambiguation”,
where the goal is simply to collapse different in-
flected forms of any similarly-spelled stems, so that
the strings ‘wind’, ‘winds’, ‘winded’, ‘winding’ will
all be treated as instances of the same thing, without
in fact making any attempt to determine the identity
of “lemmas” in the traditional sense of dictionary
entries.
Linguists use the term morphology to include all
aspects of lexical analysis under discussion here.
But in most computational applications, “morpho-
logical analysis” does not include the disambigua-
tion of lemmas, because most morphological ana-
lyzers do not reference a set of stable lemma IDs.
So for the purposes of this paper, we will continue to
discuss lemma analysis and disambiguation as con-
ceptually distinct from morphological analysis and
disambiguation, although, in fact, our system dis-
ambiguates both of these aspects of lexical analysis
at the same time.
The lexical analysis of textual character-strings
is a more complex and consequential problem in
Arabic than it is in English, for several reasons.
First, Arabic inflectional morphology is more com-
plex than English inflectional morphology is. Where
an English verb has five basic forms, for example,
an Arabic verb in principle may have dozens. Sec-
ond, the Arabic orthographic system writes elements
such as prepositions, articles, and possessive pro-
nouns without setting them off by spaces, roughly
as if the English phrase “in a way” were written “in-
away”. This leads to an enormous increase in the
number of distinct “orthographic words”, and a sub-
stantial increase in ambiguity. Third, short vowels
are normally omitted in Arabic text, roughly as if
English “in a way” were written “nway”.
As a result, a whitespace/punctuation-delimited
letter-string in Arabic text typically has many more
alternative analyses than a comparable English
letter-string does, and these analyses have many
more parts, drawn from a much larger vocabulary of
form-classes. While an English “tagger” can spec-
ify the morphosyntactic status of a word by choos-
ing from a few dozen tags, an equivalent level of
detail in Arabic would require thousands of alterna-
tives. Similarly, the number of lemmas that might
play a role in a given letter-sequence is generally
much larger in Arabic than in English.
We start our labeling of Arabic text with the alter-
native analyses provided by SAMA v. 3.1, the Stan-
dard Arabic Morphological Analyzer (Maamouri et
al., 2009). SAMA is an updated version of the ear-
lier Buckwalter analyzers (Buckwalter, 2004), with
a number of significant differences in analysis to
make it compatible with the LDC Arabic Treebank
3-v3.2 (Maamouri et al., 2004). The input to SAMA
is an Arabic orthographic word (a string of letters
delimited by whitespace or punctuation), and the
output of SAMA is a set of alternative analyses, as
shown in Table 1. For a typical word, SAMA pro-
duces approximately a dozen alternative analyses,
but for certain highly ambiguous words it can pro-
duce hundreds of alternatives.
The SAMA analyzer has good coverage; for typ-
ical texts, the correct analysis of an orthographic
word can be found somewhere in SAMA’s list of
alternatives about 95% of the time. However, this
broad coverage comes at a cost; the list of analytic
alternatives must include a long Zipfian tail of rare
or contextually-implausible analyses, which collec-
tively are correct often enough to make a large con-
tribution to the coverage statistics. Furthermore,
SAMA’s long lists of alternative analyses are not
evaluated or ordered in terms of overall or contex-
tual plausibility. This makes the results less useful
in most practical applications.
Our goal is to rank these alternative analyses so
that the correct answer is as near to the top of the list
</bodyText>
<table confidence="0.9997253">
Token Lemma Vocalization Segmentation Morphology Gloss
yHlm Halam-u 1 yaHolumu ya + Holum + IV3MS + IV + IV- he / it + dream + [ind.]
u SUFF MOOD:I
yHlm Halam-u 1 yaHoluma ya + Holum + IV3MS + IV + IV- he / it + dream + [sub.]
a SUFF MOOD:S
yHlm Halum-u 1 yaHolumo ya + Holum + IV3MS + IV + IV- he / it + be gentle + [jus.]
o SUFF MOOD:J
qbl qabil-a 1 qabila qabil + a PV + PV- accept/receive/approve +
SUFF SUBJ:3MS he/it [verb]
qbl qabol 1 qabol qabol NOUN Before
</table>
<tableCaption confidence="0.999949">
Table 1: Partial output of SAMA for yHlm and qbl. On average, every token produces more than 10 such analyses
</tableCaption>
<bodyText confidence="0.994704411764706">
as possible. Despite some risk of confusion, we’ll
refer to SAMA’s list of alternative analyses for an
orthographic word as potential labels for that word.
And despite a greater risk of confusion, we’ll refer to
the assignment of probabilities to the set of SAMA
labels for a particular Arabic word in a particular
textual context as tagging, by analogy to the oper-
ation of a stochastic part-of-speech tagger, which
similarly assigns probabilities to the set of labels
available for a word in textual context.
Although our algorithms have been developed for
the particular case of Arabic and the particular set
of lexical-analysis labels produced by SAMA, they
should be applicable without modification to the sets
of labels produced by any broad-coverage lexical
analyzer for the orthographic words of any highly-
inflected language.
In choosing our approach, we have been moti-
vated by two specific applications. One applica-
tion aims to help learners of Arabic in reading text,
by offering a choice of English glosses with asso-
ciated Arabic morphological analyses and vocaliza-
tions. SAMA’s excellent coverage is an important
basis for this help; but SAMA’s long, unranked list
of alternative analyses for a particular letter-string,
where many analyses may involve rare words or al-
ternatives that are completely implausible in the con-
text, will be confusing at best for a learner. It is
much more helpful for the list to be ranked so that
the correct answer is almost always near the top, and
is usually one of the top two or three alternatives.
In our second application, this same sort of rank-
ing is also helpful for the linguistically expert native
speakers who do Arabic Treebank analysis. These
annotators understand the text without difficulty, but
find it time-consuming and fatiguing to scan a long
list of rare or contextually-implausible alternatives
for the correct SAMA output. Their work is faster
and more accurate if they start with a list that is
ranked accurately in order of contextual plausibility.
Other applications are also possible, such as vo-
calization of Arabic text for text-to-speech synthe-
sis, or lexical analysis for Arabic parsing. However,
our initial goals have been to rank the list of SAMA
outputs for human users.
We note in passing that the existence of set of sta-
ble “lemma IDs” is an unusual feature of SAMA,
which in our opinion ought to be emulated by ap-
proaches to lexical analysis in other languages. The
lack of such stable lemma IDs has helped to disguise
the fact that without lemma analysis and disam-
biguation, morphological analyses and disambigua-
tion is only a partial solution to the problem of lexi-
cal analysis.
In principle, it is obvious that lemma disambigua-
tion and morphological disambiguation are mutually
beneficial. If we know the answer to one of the ques-
tions, the other one is easier to answer. However,
these two tasks require rather different sets of con-
textual features. Lemma disambiguation is similar
to the problem of word-sense disambiguation – on
some definitions, they are identical – and as a re-
sult, it benefits from paragraph-level and document-
level bag-of-words attributes that help to character-
ize what the text is “about” and therefore which lem-
mas are more likely to play a role in it. In contrast,
morphological disambiguation mainly depends on
features of nearby words, which help to character-
ize how inflected forms of these lemmas might fit
into local phrasal structures.
2 Problem and Methodology
Consider a collection of tokens (observations), ti, re-
ferred to by index i E 11, ... , n}, where each token
is associated with a set of p features, xij, for the jth
feature, and a label, li, which is a combination of
a lemma and a morphological analysis. We use in-
dicator functions yik to indicate whether or not the
kth label for the ith token is present. We represent
the complete set of features and labels for the en-
tire training data using matrix notation as X and Y ,
respectively. Our goal is to predict the label l (or
equivalently, the vector y for a given feature vector
x.
A standard linear regression model of this prob-
lem would be
</bodyText>
<equation confidence="0.99232">
y = xβ + E (1)
</equation>
<bodyText confidence="0.994552">
The standard linear regression estimate of β (ig-
noring, for simplicity the fact that the ys are 0/1) is:
</bodyText>
<equation confidence="0.999143">
βˆ 1 T
T
= (XtrainXtrain) XtrainYtrain (2)
</equation>
<bodyText confidence="0.999948698113208">
where Ytrain is an n x h matrix containing 0s and
1s indicating whether or not each of the h possible
labels is the correct label (li) for each of the n tokens
ti, Xtrain is an n x p matrix of context features for
each of the n tokens, the coefficients βˆ are p x h.
However, this is a large, sparse, multiple label
problem, and the above formulation is neither statis-
tically nor computationally efficient. Each observa-
tion (x, y) consists of thousands of features associ-
ated with thousands of potential labels, almost all of
which are zero. Worse, the matrix of coefficients β,
to be estimated is large (p x h) and one should thus
use some sort of transfer learning to share strength
across the different labels.
We present a novel principled and highly compu-
tationally efficient method of estimating this multi-
label model. We use a two stage procedure, first
using a subset (Xtrain1,Ytrain1) of training data
to give a fast approximate estimate of β; we then
use a second smaller subset of the training data
(Xtrain2, Ytrain2,) to “correct” these estimates in a
way that we will show can be viewed as a spe-
cialized shrinkage. Our first stage estimation ap-
proximates β, but avoids the expensive computa-
tion of (XTtrainXtrain)−1. Our second stage corrects
(shrinks) these initial estimates in a manner special-
ized to this problem. The second stage takes ad-
vantage of the fact that we only need to consider
those candidate labels produced by SAMA. Thus,
only dozens of the thousands of possible labels are
considered for each token.
We now present our algorithm. We start with a
corpus D of documents d of labeled Arabic text. As
described above, each token, ti is associated with a
set of features characterizing its context, computed
from the other words in the same document, and a la-
bel, li = (lemmai, morphologyi), which is a combi-
nation of a lemma and a morphological analysis. As
described below, we introduce a novel factorization
of the morphology into 15 different components.
Our estimation algorithm, shown in Algorithm 1,
has two stages. We partition the training corpus into
two subsets, one of which (Xtrain1) is used to es-
timate the coefficients βs and the other of which
(Xtrain2) is used to optimally “shrink” these coeffi-
cient estimates to reduce variance and prevent over-
fitting due to data sparsity.
For the first stage of our estimation procedure, we
simplify the estimate of the (β) matrix (Equation 2)
to avoid the inversion of the very high dimensional
(p x p) matrix (XT X) by approximating (XT X) by
its diagonal, Var(X), the inverse of which is trivial
to compute; i.e. we estimate β using
</bodyText>
<equation confidence="0.994098">
βˆ = Var(Xtrain1)−1XT train1Ytrain1 (3)
</equation>
<bodyText confidence="0.9998668">
For the second stage, we assume that the coeffi-
cients for each feature can be shrunk differently, but
that coefficients for each feature should be shrunk
the same regardless of what label they are predict-
ing. Thus, for a given observation we predict:
</bodyText>
<equation confidence="0.881539">
ˆβjkxij (4)
</equation>
<bodyText confidence="0.9995174">
where the weights wj indicate how much to shrink
each of the p features.
In practice, we fold the variance of each of the j
features into the weight, giving a slightly modified
equation:
</bodyText>
<equation confidence="0.989403625">
p
ˆgik = E αjβ∗jkxij (5)
j=1
wj
ˆgik =
p
E
j=1
</equation>
<bodyText confidence="0.999776119047619">
where 0∗ = XTtrain1Ytrain1 is just a matrix of the
counts of how often each context feature shows up
with each label in the first training set. The vec-
tor α, which we will estimate by regression, is just
the shrinkage weights w rescaled by the feature vari-
ance.
Note that the formation here is different from the
first stage. Instead of having each observation be
a token, we now let each observation be a (token,
label) pair, but only include those labels that were
output by SAMA. For a given token ti and poten-
tial label lk, our goal is to approximate the indica-
tor function g(i, k), which is 1 if the kth label of
token ti is present, and 0 otherwise. We find candi-
date labels using a morphological analyzer (namely
SAMA), which returns a set of possible candidate
labels, say C(t), for each Arabic token t. Our pre-
dicted label for ti is then argmaxk∈C(ti)g(i, k).
The regression model for learning the weights αj
in the second stage thus has a row for each label
g(i, k) associated with a SAMA candidate for each
token i = ntrain1+1 . . . ntrain2 in the second train-
ing set. The value of g(i, k) is predicted as a func-
tion of the feature vector zijk = 0∗jkxij.
The shrinkage coefficients, αj, could be estimated
from theory, using a version of James-Stein shrink-
age (James and Stein, 1961), but in practice, superior
results are obtained by estimating them empirically.
Since there are only p of them (unlike the p ∗ h 0s),
a relatively small training set is sufficient. We found
that regression-SVMs work slightly better than lin-
ear regression and significantly better than standard
classification SVMs for this problem.
Prediction is then done in the obvious way by tak-
ing the tokens in a test corpus Dtest, generating con-
text features and candidate SAMA labels for each
token ti, and selected the candidate label with the
highest score ˆg(i, k) that we set out to learn. More
formally, The model parameters 0∗ and α produced
by the algorithm allow one to estimate the most
likely label for a new token ti out of a set of can-
didate labels C(ti) using
</bodyText>
<equation confidence="0.934001">
p
kpred = argmaxk∈C(ti) 11 αj0∗jkxij (6)
j=1
</equation>
<bodyText confidence="0.99947">
The most expensive part of the procedure is es-
timating 0∗, which requires for each token in cor-
</bodyText>
<equation confidence="0.7131348">
Algorithm 1 Training algorithm.
Input: A training corpus Dtrain of n observations
(Xtrain, Ytrain)
Partition Dtrain into two sets, D1 and D2, of sizes
ntrain1 and ntrain2 = n − ntrain1 observations
// Using D1, estimate 0∗
0∗jk = �ntrain1
i=1 xijyik for the jth feature and kth
label
// Using D2, estimate αj
</equation>
<bodyText confidence="0.99742672">
// Generate new “features” Z and the true labels
g(i, k) for each of the SAMA candidate labels for
each of the tokens in D2
zijk = 0∗jkxij for i in i = ntrain1 + 1 ... ntrain2
Estimate αj for the above (feature,label) pairs
(zijk, g(i, k)) using Regression SVMs
Output: α and 0∗
pus D1, (a subset of D), finding the co-occurrence
frequencies of each label element (a lemma, or a
part of the morphological segmentation) with the
target token and jointly with the token and with
other tokens or characters in the context of the to-
ken of interest. For example, given an Arabic to-
ken, “yHlm”, we count what fraction of the time
it is associated with each lemma (e.g. Halam-
u 1), count(lemma=Halam-u 1, token=yHlm) and
each segment (e.g. “ya”), count(segment=ya, to-
ken=yHlm). (Of course, most tokens never show up
with most lemmas or segments; this is not a prob-
lem.) We also find the base rates of the components
of the labels (e.g., count(lemma=Halam-u 1), and
what fraction of the time the label shows up in vari-
ous contexts, e.g. count(lemma=Halam-u 1, previ-
ous token = yHlm). We describe these features in
more detail below.
</bodyText>
<sectionHeader confidence="0.997752" genericHeader="keywords">
3 Features and Labels used for Training
</sectionHeader>
<bodyText confidence="0.999979673076923">
Our approach to tagging Arabic differs from conven-
tional approaches in the two-part shrinkage-based
method used, and in the choice of both features and
labels used in our model. For features, we study
both local context variables, as described above, and
document-level word frequencies. For the labels, the
key question is what labels are included and how
they are factored. Standard “taggers” work by doing
an n-way classification of all the alternatives, which
is not feasible here due to the thousands of possi-
ble labels. Standard approaches such as Conditional
Random Fields (CRFs) are intractable with so many
labels. Moreover, few if any taggers do any lemma
disambiguation; that is partly because one must start
with some standard inventory of lemmas, which are
not available for most languages, perhaps because
the importance of lemma disambiguation has been
underestimated.
We make a couple of important design decisions
to deal with these issues. First, we perform lemma
disambiguation in addition to “tagging”. As men-
tioned above, lemmas and morphological informa-
tion are not independent; the choice of lemma often
influences morphology and vice versa. For example,
Table 1 contains two analyses for the word qbl. For
the first analysis, where the lemma is qabil-a 1 and
the gloss is accept/receive/approve + he/it [verb],
the word is a verb. However, for the second anal-
ysis, where the lemma is qabol 1 and the gloss is
before, the word is a noun.
Simultaneous lemma disambiguation and tagging
introduces additional complexity: An analysis of
ATB and SAMA shows that there are approximately
2,200 possible morphological analyses (“tags”) and
40,000 possible lemmas; even accounting for the
fact that most combinations of lemmas and mor-
phological analyses don’t occur, the size of the la-
bel space is still in the order of tens of thousands.
To deal with data sparsity, our second design de-
cision is to factor the labels. We factor each label
l into a set of 16 label elements (LEs). These in-
clude lemmas, as well as morphological elements
such as basic part-of-speech, suffix, gender, num-
ber, mood, etc. These are explained in detail below.
Thus, since each label l is a set of 15 categorical
variables, each y in the first learning stage is actu-
ally a vector with 16 nonzero components and thou-
sands of zeros. Since we do simultaneous estimation
of the entire set of label elements, the value g(i, k)
being predicted in the second learning phase is 1 if
the entire label set is correct, and zero otherwise. We
do not learn separate models for each label.
</bodyText>
<subsectionHeader confidence="0.992501">
3.1 Label Elements (LEs)
</subsectionHeader>
<bodyText confidence="0.9999485">
The fact that there are tens of thousands of possible
labels presents the problem of extreme sparsity of
label distribution in the training data. We find that a
model that estimates coefficients 0* to predict a sin-
</bodyText>
<table confidence="0.9988350625">
LE Description
lemma Lemma
pre1 Closer prefix
pre2 Farther prefix
det Determiner
pos Basic POS
dpos Additional data on basic pos
suf Suffix
perpos Person (basic pos)
numpos Number (basic pos)
genpos Gender (basic pos)
persuf Person (suffix)
numsuf Number (suffix)
gensuf Gender (suffix)
mood Mood of verb
pron Pronoun suffix
</table>
<tableCaption confidence="0.984196">
Table 2: Label Elements (LEs). Examples of additional
</tableCaption>
<bodyText confidence="0.828506846153846">
data on basic POS include whether a noun is proper or
common, whether a verb is transitive or not, etc. Both
the basic POS and its suffix may have person, gender and
number data.
gle label (a label being in the Cartesian product of
the set of label elements) yields poor performance.
Therefore, as just mentioned, we factor each label
l into a set of label elements (LEs), and learn the
correlations 0* between features and label elements,
rather than features and entire label sets. This re-
duces, but does not come close to eliminating, the
problem sparsity. A complete list of these LEs and
their possible values is detailed in Table 2.
</bodyText>
<subsectionHeader confidence="0.8892615">
3.2 Features
3.2.1 Local Context Features
</subsectionHeader>
<bodyText confidence="0.999897384615385">
We take (t, l) pairs from D2, and for each such
pair generate features Z based on co-occurrence
statistics 0* in D1, as mentioned in Algorithm 2.
These statistics include unigram co-occurrence fre-
quencies of each label with the target token and bi-
gram co-occurrence of the label with the token and
with other tokens or characters in the context of the
target token. We define them formally in Table 3.
Let Zbaseline denote the set of all such basic features
based on the local context statistics of the target to-
ken, namely the words and letters preceding and fol-
lowing it. We will use this set to create a baseline
model.
</bodyText>
<table confidence="0.99864725">
Statistic Description
Freq countD1(t, l)
PrevWord countD1(t, l, t−1)
NextWord countD1(t, l, t+1)
PreviLetter countD1(t, l, first letter(t−1))
NextiLetter countD1(t, l, first letter(t+1)
PrevfLetter countD1(t, l, last letter(t−1)
NextfLetter countD1(t, l, last letter(t+1)
</table>
<tableCaption confidence="0.967119">
Table 3: Co-occurrence statistics a∗. We use these to
generate feature sets for our regression SVMs.
</tableCaption>
<bodyText confidence="0.9992105">
For each label element (LE) e, we define a set of
features Ze similar to Zbaseline; these features are
based on co-occurrence frequencies of the particular
LE e, not the entire label l.
Finally, we define an aggregate feature set Zaggr
as follows:
</bodyText>
<equation confidence="0.941658">
�Zaggr = Zbaseline {Ze} (7)
</equation>
<bodyText confidence="0.954382">
where e E {lemma, pre1, pre2, det, pos, dpos,
suf, perpos, numpos, genpos, persuf, numsuf, gensuf,
mood, pron}.
</bodyText>
<subsectionHeader confidence="0.849441">
3.2.2 Document Level Features
</subsectionHeader>
<bodyText confidence="0.999915066666667">
When trying to predict the lemma, it is useful to
include not just the words and characters immedi-
ately adjacent to the target token, but also the all the
words in the document. These words capture the
“topic” of the document, and help to disambiguate
different lemmas, which tend to be used or not used
based on the topic being discussed, similarly to the
way that word sense disambiguation systems in En-
glish sometimes use the “bag of words” the docu-
ment to disambiguate, for example a “bank” for de-
positing money from a “bank” of a river. More pre-
cisely, we augment the features for each target token
with the counts of each word in the document (the
“term frequency” tf) in which the token occurs with
a given label.
</bodyText>
<equation confidence="0.8237695">
�
Zfull = Zaggr Ztf (8)
</equation>
<bodyText confidence="0.999643333333333">
This set Zfull is our final feature set. We use Zfull
to train an SVM model Mfull; this is our final pre-
dictive model.
</bodyText>
<subsectionHeader confidence="0.996828">
3.3 Corpora used for Training and Testing
</subsectionHeader>
<bodyText confidence="0.999934666666667">
We use three modules of the Penn Arabic Tree-
bank (ATB) (Maamouri et al., 2004), namely ATB1,
ATB2 and ATB3 as our corpus of labeled Ara-
bic text, D. Each ATB module is a collection
of newswire data from a particular agency. ATB1
uses the Associated Press as a source, ATB2 uses
Ummah, and ATB3 uses Annahar. D contains a total
of 1,835 documents, accounting for approximately
350,000 words. We construct the training and test-
ing sets Dtrain and Dtest from D using 10-fold cross
validation, and we construct D1 and D2 from Dtrain
by randomly performing a 9:1 split.
As mentioned earlier, we use the SAMA mor-
phological analyzer to obtain candidate labels C(t)
for each token t while training and testing an SVM
model on D2 and Dtest respectively. A sample out-
put of SAMA is shown in Table 1. To improve cov-
erage, we also add to C(t) all the labels l seen for t
in D1. We find that doing so improves coverage to
98%. This is an upper bound on the accuracy of our
model.
</bodyText>
<equation confidence="0.8580655">
�
C(t) = SAMA(t) {l|(t, l) E D1} (9)
</equation>
<sectionHeader confidence="0.999775" genericHeader="introduction">
4 Results
</sectionHeader>
<bodyText confidence="0.998698434782609">
We use two metrics of accuracy: A1, which mea-
sures the percentage of tokens for which the model
assigns the highest score to the correct label or LE
value (or E1= 100−A1, the corresponding percent-
age error), and A2, which measures the percentage
of tokens for which the correct label or LE value
is one of the two highest ranked choices returned
by the model (or E2 = 100 − A2). We test our
model Mfull on Dtest and achieve A1 and A2 scores
of 90.6% and 96.2% respectively. The accuracy
achieved by our Mfull model is, to the best of our
knowledge, higher than prior approaches have been
able to achieve so far for the problem of combined
morphological and lemma disambiguation. This is
all the more impressive considering that the upper
bound on accuracy for our model is 98% because,
as described above, our set of candidate labels is in-
complete.
In order to analyze how well different LEs can be
predicted, we train an SVM model Me for each LE
e using the feature set Ze, and test all such models
on Dtest. The results for all the LEs are reported in
the form of error percentages E1 and E2 in Table 4.
</bodyText>
<table confidence="0.999763">
Model E1 E2 Model E1 E2
Mlemma 11.1 4.9 Mpre1 1.9 1.4
Mpre2 0.2 0 Mdet 0.7 0.1
Mpos 23.4 4.0 Mdpos 10.3 1.9
Msuf 7.6 2.5 Mperpos 3.0 0.1
Mnumpos 3.2 0.2 Mgenpos 1.8 0.1
Mpersuf 3.2 0.1 Mnumsuf 8.2 0.5
Mgensuf 11.6 0.4 Mmood 1.6 1.4
Mpron 1.8 0.6 Mcase 14.7 5.9
Mfull 9.4 3.8 - - -
</table>
<tableCaption confidence="0.998412">
Table 4: Results of Me for each LE e. Note: The results
reported are 10 fold cross validation test accuracies and
no parameters have been tuned on them.
</tableCaption>
<bodyText confidence="0.999971529411765">
A comparison of the results for Mfull with the
results for Mlemma and Mpos is particularly infor-
mative. We see that Mfull is able to achieve a sub-
stantially lower E1 error score (9.4%) than Mlemma
(11.1%) and Mpos (23.4%); in other words, we find
that our full model is able to predict lemmas and ba-
sic parts-of-speech more accurately than the individ-
ual models for each of these elements.
We examine the effect of varying the size of D2,
i.e. the number of SVM training instances, on the
performance of Mfull on Dtest, and find that with
increasing sizes of D2, E1 reduces only slightly
from 9.5% to 9.4%, and shows no improvement
thereafter. We also find that the use of document-
level features in Mlemma reduces E1 and E2 per-
centages for Mlemma by 5.7% and 3.2% respec-
tively.
</bodyText>
<subsectionHeader confidence="0.988699">
4.1 Comparison to Alternate Approaches
4.1.1 Structured Prediction Models
</subsectionHeader>
<bodyText confidence="0.985433828571428">
Preliminary experiments showed that knowing the
predicted labels (lemma + morphology) of the sur-
rounding words can slightly improve the predic-
tive accuracy of our model. To further investi-
gate this effect, we tried running experiments us-
ing different structured models, namely CRF (Con-
ditional Random Fields) (Lafferty et al., 2001),
(Structured) MIRA (Margin Infused Relaxation Al-
gorithm) (Crammer et al., 2006) and Structured
Perceptron (Collins, 2002). We used linear chain
CRFs as implemented in MALLET Toolbox (Mc-
Callum, 2001) and for Structured MIRA and Per-
ceptron we used their implementations from EDLIN
Toolbox (Ganchev and Georgiev, 2009). However,
given the vast label space of our problem, running
these methods proved infeasible. The time complex-
ity of these methods scales badly with the number of
labels; It took a week to train a linear chain CRF
for only ∼ 50 labels and though MIRA and Per-
ceptron are online algorithms, they also become in-
tractable beyond a few hundred labels. Since our
label space contains combinations of lemmas and
morphologies, so even after factoring, the dimension
of the label space is in the order of thousands.
We also tried a naive version (two-pass approxi-
mation) of these structured models. In addition to
the features in Zfull, we include the predicted la-
bels for the tokens preceding and following the tar-
get token as features. This new model is not only
slow to train, but also achieves only slightly lower
error rates (1.2% lower E1 and 1.0% lower E2) than
Mfull. This provides an upper bound on the bene-
fit of using the more complex structured models, and
suggests that given their computational demands our
(unstructured) model Mfull is a better choice.
</bodyText>
<subsectionHeader confidence="0.763462">
4.1.2 MADA
</subsectionHeader>
<bodyText confidence="0.999934166666667">
(Habash and Rambow, 2005) perform morpho-
logical disambiguation using a morphological ana-
lyzer. (Roth et al., 2008) augment this with lemma
disambiguation; they call their system MADA. Our
work differs from theirs in a number of respects;
most notably, they don’t use the two step regres-
sion procedure that we use. Also, they do not learn
a single model from a feature set based on labels
and LEs; instead, they combine models for indi-
vidual elements by using weighted agreement. Fi-
nally, MADA uses a slightly different morphological
analyzer (ALMORGEANA) than our system does
(SAMA). We tested MADA v2.32 on our dataset
using its full feature set, and found that it gaveE1
and E2 error rates of 16.9 and 12.6 respectively.
These errors are substantially higher than those from
our system, but it should be noted that the numbers
cannot be directly compared since we tested their
system without retraining, and also used different
test conditions (the full set of ATB 1,2 and 3 for
MADA, versus 10-fold cross validation on ATB 1,2
and 3 for our system). Also, ALMORGEANA in
MADAv2.32 uses older lexicons than those used by
SAMA.1
</bodyText>
<subsubsectionHeader confidence="0.504603">
4.1.3 Other Alternatives
</subsubsectionHeader>
<bodyText confidence="0.999362826086956">
Unfactored Labels: To illustrate the benefit ob-
tained by breaking down each label l into
LEs, we contrast the performance of our Mfull
model to an SVM model Mbaseline trained us-
ing only the feature set Zbaseline, which only
contains features based on entire labels, those
based on individual LEs.
Independent lemma and morphology prediction:
Another alternative approach is to pre-
dict lemmas and morphological analyses
separately. We construct a feature set
Zlemma&apos; — Zfull − Zlemma and train an SVM
model Mlemma&apos; using this feature set. Labels
are then predicted by simply combining the
results predicted independently by Mlemma
and Mlemma&apos;. Let Mind denote this approach.
Unigram Features: Finally, we also consider a
context-less approach, i.e. using only “uni-
gram” features for labels as well as LEs. We
call this feature set Zuni, and the correspond-
ing SVM model Muni.
The results of these various models, along with
those of Mfull are summarized in Table 5.
</bodyText>
<table confidence="0.999093333333333">
Model E1 E2
Mbaseline 13.6 9.1
Mind 18.7 6.0
Muni 11.6 6.4
Mcheat 8.2 2.8
Mfull 9.4 3.8
</table>
<tableCaption confidence="0.89790175">
Table 5: Percent error rates of alternative approaches.
Note: The results reported are 10 fold cross validation
test accuracies and no parameters have been tuned on
them. We used same train-test splits for all the datasets.
</tableCaption>
<sectionHeader confidence="0.999935" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.9990185">
(Hajic, 2000) show that for highly inflectional
languages, the use of a morphological analyzer
</bodyText>
<footnote confidence="0.805065">
1A new version of MADA was released very close to the
submission deadline for this conference.
</footnote>
<bodyText confidence="0.999865568965517">
improves accuracy of disambiguation. (Diab et
al., 2004) perform tokenization, POS tagging
and base phrase chunking using an SVM based
learner. (Ahmed and N¨urnberger, 2008) perform
word-sense disambiguation using a Naive Bayesian
model and rely on parallel corpora and match-
ing schemes instead of a morphological ana-
lyzer. (Kulick, 2010) perform simultaneous tok-
enization and part-of-speech tagging for Arabic by
separating closed and open-class items and focus-
ing on the likelihood of possible stems of open-
class words. (Mohamed and K¨ubler, 2010) present
a hybrid method between word-based and segment-
based POS tagging for Arabic and report good re-
sults. (Toutanova and Cherry, 2009) perform joint
lemmatization and part-of-speech tagging for En-
glish, Bulgarian, Czech and Slovene, but they do
not use the two step estimation-shrinkage model de-
scribed in this paper; nor do they factor labels. The
idea of joint lemmatization and part-of-speech tag-
ging has also been discussed in the context of Hun-
garian in (Kornai, 1994).
A substantial amount of relevant work has been
done previously for Hebrew. (Adler and Elhadad,
2006) perform Hebrew morphological disambigua-
tion using an unsupervised morpheme-based HMM,
but they report lower scores than those achieved by
our model. Moreover, their analysis doesn’t include
lemma IDs, which is a novelty of our model. (Gold-
berg et al., 2008) extend the work of (Adler and El-
hadad, 2006) by using an EM algorithm, and achieve
an accuracy of 88% for full morphological analy-
sis, but again, this does not include lemma IDs. To
the best of our knowledge, there is no existing re-
search for Hebrew that does what we did for Arabic,
namely to use simultaneous lemma and morpholog-
ical disambiguation to improve both. (Dinur et al.,
2009) show that prepositions and function words can
be accurately segmented using unsupervised meth-
ods. However, by using this method as a preprocess-
ing step, we would lose the power of a simultaneous
solution for these problems. Our method is closer in
style to a CRF, giving much of the accuracy gains of
simultaneous solution, while being about 4 orders of
magnitude easier to train.
We believe that our use of factored labels is novel
for the problem of simultaneous lemma and mor-
phological disambiguation; however, (Smith et al.,
2005) and (Hatori et al., 2008) have previously
made use of features based on parts of labels in
CRF models for morphological disambiguation and
word-sense disambiguation respectively. Also, we
note that there is a similarity between our two-stage
machine learning approach and log-linear models in
machine translation that break the data in two parts,
estimating log-probabilities of generative models
from one part, and discriminatively re-weighting the
models using the second part.
</bodyText>
<sectionHeader confidence="0.999528" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999986935483871">
We introduced a new approach to accurately predict
labels consisting of both lemmas and morphologi-
cal analyses for Arabic text. We obtained an accu-
racy of over 90% – substantially higher than current
state-of-the-art systems. Key to our success is the
factoring of labels into lemma and a large set of mor-
phosyntactic elements, and the use of an algorithm
that computes a simple initial estimate of the coef-
ficient relating each contextual feature to each la-
bel element (simply by counting co-occurrence) and
then regularizes these features by shrinking each of
the coefficients for each feature by an amount deter-
mined by supervised learning using only the candi-
date label sets produced by SAMA.
We also showed that using features of word n-
grams is preferable to using features of only individ-
ual tokens of data. Finally, we showed that a model
using a full feature set based on labels as well as
factored components of labels, which we call label
elements (LEs) works better than a model created
by combining individual models for each LE. We
believe that the approach we have used to create our
model can be successfully applied not just to Arabic
but also to other languages such as Turkish, Hungar-
ian and Finnish that have highly inflectional mor-
phology. The current accuracy of of our model, get-
ting the correct answer among the top two choices
96.2% of the time is high enough to be highly use-
ful for tasks such as aiding the manual annotation
of Arabic text; a more complete automation would
require that accuracy for the single top choice.
</bodyText>
<sectionHeader confidence="0.999553" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.994501833333333">
We woud like to thank everyone at the Linguis-
tic Data Consortium, especially Christopher Cieri,
David Graff, Seth Kulick, Ann Bies, Wajdi Za-
ghouani and Basma Bouziri for their help. We also
wish to thank the anonymous reviewers for their
comments and suggestions.
</bodyText>
<sectionHeader confidence="0.998048" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999902221052631">
Meni Adler and Michael Elhadad. 2006. An Unsuper-
vised Morpheme-Based HMM for Hebrew Morpho-
logical Disambiguation. In Proceedings of the 21st
International Conference on Computational Linguis-
tics and the 44th annual meeting of the Association for
Computational Linguistics.
Farag Ahmed and Andreas N¨urnberger. 2008. Ara-
bic/English Word Translation Disambiguation using
Parallel Corpora and Matching Schemes. In Proceed-
ings of EAMT’08, Hamburg, Germany.
Tim Buckwalter. 2004. Buckwalter Arabic Morphologi-
cal Analyzer version 2.0.
Michael Collins. 2002. Discriminative Training Meth-
ods for Hidden Markov Models: Theory and Experi-
ments with Perceptron Algorithms. In Proceedings of
EMNLP’02.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-
Shwartz, and Yoram Singer. 2006. Online Passive-
Aggressive Algorithms. Journal of Machine Learning
Research, 7:551–585.
Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004.
Automatic Tagging of Arabic text: From Raw Text to
Base Phrase Chunks. In Proceedings of the 5th Meet-
ing of the North American Chapter of the Associa-
tion for Computational Linguistics/Human Language
Technologies Conference (HLT-NAACL’04).
Elad Dinur, Dmitry Davidov, and Ari Rappoport. 2009.
Unsupervised Concept Discovery in Hebrew Using
Simple Unsupervised Word Prefix Segmentation for
Hebrew and Arabic. In Proceedings of the EACL 2009
Workshop on Computational Approaches to Semitic
Languages.
Kuzman Ganchev and Georgi Georgiev. 2009. Edlin:
An Easy to Read Linear Learning Framework. In Pro-
ceedings of RANLP’09.
Yoav Goldberg, Meni Adler, and Michael Elhadad. 2008.
EM Can Find Pretty Good HMM POS-Taggers (When
Given a Good Start)*. In Proceedings of ACL’08.
Nizar Habash and Owen Rambow. 2005. Arabic Tok-
enization, Part-of-Speech Tagging and Morphological
Disambiguation in One Fell Swoop. In Proceedings of
ACL’05, Ann Arbor, MI, USA.
Jan Hajic. 2000. Morphological Tagging: Data vs. Dic-
tionaries. In Proceedings of the 1st Meeting of the
North American Chapter of the Association for Com-
putational Linguistics (NAACL’00).
Jun Hatori, Yusuke Miyao, and Jun’ichi Tsujii. 2008.
Word Sense Disambiguation for All Words using Tree-
Structured Conditional Random Fields. In Proceed-
ings of COLing’08.
W. James and Charles Stein. 1961. Estimation with
Quadratic Loss. In Proceedings of the Fourth Berkeley
Symposium on Mathematical Statistics and Probabil-
ity, Volume 1.
Andr´as Kornai. 1994. On Hungarian morphology (Lin-
guistica, Series A: Studia et Dissertationes 14). Lin-
guistics Institute of Hungarian Academy of Sciences,
Budapest.
Seth Kulick. 2010. Simultaneous Tokenization and Part-
of-Speech Tagging for Arabic without a Morphologi-
cal Analyzer. In Proceedings of ACL’10.
John D. Lafferty, Andrew McCallum, and Fernando C. N.
Pereira. 2001. Conditional Random Fields: Proba-
bilistic Models for Segmenting and Labeling Sequence
Data. In Proceedings of ICML’01, pages 282–289.
Mohamed Maamouri, Ann Bies, and Tim Buckwalter.
2004. The Penn Arabic Treebank: Building a Large
Scale Annotated Arabic Corpus. In Proceedings of
NEMLAR Conference on Arabic Language Resources
and Tools.
Mohamed Maamouri, David Graff, Basma Bouziri, Son-
dos Krouna, and Seth Kulick. 2009. LDC Standard
Arabic Morphological Analyzer (SAMA) v. 3.0.
Andrew McCallum, 2001. MALLET: A Machine Learn-
ing for Language Toolkit. Software available at
http://mallet.cs.umass.edu.
Emad Mohamed and Sandra K¨ubler. 2010. Arabic Part
of Speech Tagging. In Proceedings of LREC’10.
Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab,
and Cynthia Rudin. 2008. Arabic Morphological Tag-
ging, Diacritization, and Lemmatization Using Lex-
eme Models and Feature Ranking. In Proceedings of
ACL’08, Columbus, Ohio, USA.
Noah A. Smith, David A. Smith, and Roy W. Tromble.
2005. Context-Based Morphological Disambiguation
with Random Fields*. In Proceedings of Human
Language Technology Conference and Conference on
Empirical Methods in Natural Language Processing
(HLT/EMNLP).
Kristina Toutanova and Colin Cherry. 2009. A Global
Model for Joint Lemmatization and Part-of-Speech
Prediction. In Proceedings of the Joint Conference of
the 47th Annual Meeting of the ACL and the 4th Inter-
national Joint Conference on Natural Language Pro-
cessing, pages 486–494.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.999736">A New Approach to Lexical Disambiguation of Arabic Text</title>
<author confidence="0.984107">Rushin</author>
<affiliation confidence="0.997045">Carnegie Mellon</affiliation>
<address confidence="0.9963245">5000 Forbes Pittsburgh, PA 15213,</address>
<email confidence="0.999631">rnshah@cs.cmu.edu</email>
<author confidence="0.9907255">Paramveer S Dhillon</author>
<author confidence="0.9907255">Mark Dean Foster</author>
<author confidence="0.9907255">Mohamed</author>
<affiliation confidence="0.9041315">and Lyle University of</affiliation>
<address confidence="0.9794025">3451 Walnut Philadelphia, PA 19104,</address>
<email confidence="0.999561">maamouri@ldc.upenn.edu</email>
<abstract confidence="0.999069972495089">We describe a model for the lexical analysis of Arabic text, using the lists of alternatives supplied by a broad-coverage morphological analyzer, SAMA, which include stable lemma IDs that correspond to combinations of broad word sense categories and POS tags. We break down each of the hundreds of thousands of possible lexical labels into its constituent elements, including lemma ID and part-of-speech. Features are computed for each lexical token based on its local and document-level context and used in a novel, simple, and highly efficient two-stage supervised machine learning algorithm that overcomes the extreme sparsity of label distribution in the training data. The resulting system achieves accuracy of 90.6% for its first choice, and 96.2% for its top two choices, in selecting among the alternatives provided by the SAMA lexical analyzer. We have successfully used this system in applications such as an online reading helper for intermediate learners of the Arabic language, and a tool for improving the productivity of Arabic Treebank annotators. 1 Background and Motivation This paper presents a methodology for generating high quality lexical analysis of highly inflected languages, and demonstrates excellent performance applying our approach to Arabic. Lexical analysis of the written form of a language involves resolving, explicitly or implicitly, several different kinds of ambiguities. Unfortunately, the usual ways of talking about this process are also ambiguous, and our general approach to the problem, though not unprecedented, has uncommon aspects. Therefore, in order to avoid confusion, we begin by describing how we define the problem. In an inflected language with an alphabetic writing system, a central issue is how to interpret strings of characters as forms of words. For example, the English letter-string ‘winds’ will normally be interpreted in one of four different ways, all four of which involve the sequence of two formatives The stem ‘wind’ might be analyzed as (1) a noun meaning something like “air in motion”, pro- , which we can associate with an arbut stable identifier like (2) a verb v1 from that noun, and pronounced the way; (3) a verb v2 something “(cause to) twist”, pronounced or (4) noun n2 from that verb, and pronounced the same way. Each of these “lemmas”, or dictionary entries, will have several distinguishable senses, which we may also wish to associate with stable identifiers. The affix ‘-s’ might be analyzed as the plural inflection, if the stem is a noun; or as the third-person singular inflection, if the stem is a verb. We see this analysis as conceptually divided into parts: 1) which recognizes that the letter-string ‘winds’ might be (peramong other things) 2) disambiguawhich involves deciding, for example, that in the phrase “the four winds”, ‘winds’ is probably a noun, i.e. 3) which involves recognizing that the stem wind in ‘winds’ might be any of the four lemmas listed above – perhaps with a further listing of senses or other sub-entries for each of them; and 4) deciding, for example, that the phrase “the four winds” probably involves the Confusingly, the standard word-analysis tasks in computational linguistics involve various combinations of pieces of these logically-distinguished operations. Thus, “part of speech (POS) tagging” is mainly what we’ve called “morphological disambiguation”, except that it doesn’t necessarily require identifying the specific stems and affixes involved. In some cases, it also may require a small amount of “lemma disambiguation”, for example to distinguish a proper noun from a common noun. “Sense disambiguation” is basically a form of what we’ve called “lemma disambiguation”, except that the sense disambiguation task may assume that the part of speech is known, and may break down lexical identity more finely than our system happens to do. “Lemmatization” generally refers to a radically simplified form of “lemma analysis” and “lemma disambiguation”, where the goal is simply to collapse different inflected forms of any similarly-spelled stems, so that the strings ‘wind’, ‘winds’, ‘winded’, ‘winding’ will all be treated as instances of the same thing, without in fact making any attempt to determine the identity of “lemmas” in the traditional sense of dictionary entries. use the term include all aspects of lexical analysis under discussion here. But in most computational applications, “morphological analysis” does not include the disambiguation of lemmas, because most morphological analyzers do not reference a set of stable lemma IDs. So for the purposes of this paper, we will continue to discuss lemma analysis and disambiguation as conceptually distinct from morphological analysis and disambiguation, although, in fact, our system disambiguates both of these aspects of lexical analysis at the same time. The lexical analysis of textual character-strings is a more complex and consequential problem in Arabic than it is in English, for several reasons. First, Arabic inflectional morphology is more complex than English inflectional morphology is. Where an English verb has five basic forms, for example, an Arabic verb in principle may have dozens. Second, the Arabic orthographic system writes elements such as prepositions, articles, and possessive pronouns without setting them off by spaces, roughly as if the English phrase “in a way” were written “inaway”. This leads to an enormous increase in the number of distinct “orthographic words”, and a substantial increase in ambiguity. Third, short vowels are normally omitted in Arabic text, roughly as if English “in a way” were written “nway”. As a result, a whitespace/punctuation-delimited letter-string in Arabic text typically has many more alternative analyses than a comparable English letter-string does, and these analyses have many more parts, drawn from a much larger vocabulary of form-classes. While an English “tagger” can specify the morphosyntactic status of a word by choosing from a few dozen tags, an equivalent level of detail in Arabic would require thousands of alternatives. Similarly, the number of lemmas that might play a role in a given letter-sequence is generally much larger in Arabic than in English. We start our labeling of Arabic text with the alternative analyses provided by SAMA v. 3.1, the Standard Arabic Morphological Analyzer (Maamouri et al., 2009). SAMA is an updated version of the earlier Buckwalter analyzers (Buckwalter, 2004), with a number of significant differences in analysis to make it compatible with the LDC Arabic Treebank 3-v3.2 (Maamouri et al., 2004). The input to SAMA is an Arabic orthographic word (a string of letters delimited by whitespace or punctuation), and the output of SAMA is a set of alternative analyses, as shown in Table 1. For a typical word, SAMA produces approximately a dozen alternative analyses, but for certain highly ambiguous words it can produce hundreds of alternatives. The SAMA analyzer has good coverage; for typical texts, the correct analysis of an orthographic word can be found somewhere in SAMA’s list of about the time. However, this broad coverage comes at a cost; the list of analytic alternatives must include a long Zipfian tail of rare or contextually-implausible analyses, which collectively are correct often enough to make a large contribution to the coverage statistics. Furthermore, SAMA’s long lists of alternative analyses are not evaluated or ordered in terms of overall or contextual plausibility. This makes the results less useful in most practical applications. Our goal is to rank these alternative analyses so that the correct answer is as near to the top of the list Token Lemma Vocalization Segmentation Morphology Gloss yHlm Halam-u 1 yaHolumu ya + Holum + u IV3MS + IV + IV- SUFF MOOD:I he / it + dream + [ind.] yHlm Halam-u 1 yaHoluma ya + Holum + a IV3MS + IV + IV- SUFF MOOD:S he / it + dream + [sub.] yHlm Halum-u 1 yaHolumo ya + Holum + o IV3MS + IV + IV- SUFF MOOD:J he / it + be gentle + [jus.] qbl qabil-a 1 qabila qabil + a PV + PVaccept/receive/approve + he/it [verb] SUFF SUBJ:3MS qbl qabol 1 qabol qabol NOUN Before 1: Partial output of SAMA for On average, every token produces more than 10 such analyses as possible. Despite some risk of confusion, we’ll refer to SAMA’s list of alternative analyses for an word as potential that word. And despite a greater risk of confusion, we’ll refer to the assignment of probabilities to the set of SAMA labels for a particular Arabic word in a particular context as by analogy to the operation of a stochastic part-of-speech tagger, which similarly assigns probabilities to the set of labels available for a word in textual context. Although our algorithms have been developed for the particular case of Arabic and the particular set of lexical-analysis labels produced by SAMA, they should be applicable without modification to the sets of labels produced by any broad-coverage lexical analyzer for the orthographic words of any highlyinflected language. In choosing our approach, we have been motivated by two specific applications. One application aims to help learners of Arabic in reading text, by offering a choice of English glosses with associated Arabic morphological analyses and vocalizations. SAMA’s excellent coverage is an important basis for this help; but SAMA’s long, unranked list of alternative analyses for a particular letter-string, where many analyses may involve rare words or alternatives that are completely implausible in the context, will be confusing at best for a learner. It is much more helpful for the list to be ranked so that the correct answer is almost always near the top, and is usually one of the top two or three alternatives. In our second application, this same sort of ranking is also helpful for the linguistically expert native speakers who do Arabic Treebank analysis. These annotators understand the text without difficulty, but find it time-consuming and fatiguing to scan a long list of rare or contextually-implausible alternatives for the correct SAMA output. Their work is faster and more accurate if they start with a list that is ranked accurately in order of contextual plausibility. Other applications are also possible, such as vocalization of Arabic text for text-to-speech synthesis, or lexical analysis for Arabic parsing. However, our initial goals have been to rank the list of SAMA outputs for human users. We note in passing that the existence of set of stable “lemma IDs” is an unusual feature of SAMA, which in our opinion ought to be emulated by approaches to lexical analysis in other languages. The lack of such stable lemma IDs has helped to disguise the fact that without lemma analysis and disambiguation, morphological analyses and disambiguation is only a partial solution to the problem of lexical analysis. In principle, it is obvious that lemma disambiguation and morphological disambiguation are mutually beneficial. If we know the answer to one of the questions, the other one is easier to answer. However, these two tasks require rather different sets of contextual features. Lemma disambiguation is similar to the problem of word-sense disambiguation – on some definitions, they are identical – and as a result, it benefits from paragraph-level and documentlevel bag-of-words attributes that help to characterize what the text is “about” and therefore which lemmas are more likely to play a role in it. In contrast, morphological disambiguation mainly depends on of nearby words, which help to characterize how inflected forms of these lemmas might fit into local phrasal structures. 2 Problem and Methodology a collection of tokens (observations), reto by index ... , where each token associated with a set of for the and a label, which is a combination of a lemma and a morphological analysis. We use infunctions indicate whether or not the for the is present. We represent the complete set of features and labels for the entraining data using matrix notation as Our goal is to predict the label the vector a given feature vector A standard linear regression model of this problem would be standard linear regression estimate of (igfor simplicity the fact that the are 0/1) is: T an containing and indicating whether or not each of the is the correct label for each of the an of context features for of the the coefficients However, this is a large, sparse, multiple label problem, and the above formulation is neither statistically nor computationally efficient. Each observaof thousands of features associated with thousands of potential labels, almost all of are zero. Worse, the matrix of coefficients be estimated is large and one should thus use some sort of transfer learning to share strength across the different labels. We present a novel principled and highly computationally efficient method of estimating this multilabel model. We use a two stage procedure, first a subset training data give a fast approximate estimate of we then use a second smaller subset of the training data to “correct” these estimates in a way that we will show can be viewed as a specialized shrinkage. Our first stage estimation apbut avoids the expensive computaof second stage corrects (shrinks) these initial estimates in a manner specialized to this problem. The second stage takes advantage of the fact that we only need to consider those candidate labels produced by SAMA. Thus, only dozens of the thousands of possible labels are considered for each token. We now present our algorithm. We start with a documents labeled Arabic text. As above, each token, associated with a set of features characterizing its context, computed from the other words in the same document, and a lawhich is a combination of a lemma and a morphological analysis. As described below, we introduce a novel factorization of the morphology into 15 different components. Our estimation algorithm, shown in Algorithm 1, has two stages. We partition the training corpus into subsets, one of which used to esthe coefficients and the other of which is used to optimally “shrink” these coefficient estimates to reduce variance and prevent overfitting due to data sparsity. For the first stage of our estimation procedure, we the estimate of the matrix (Equation 2) to avoid the inversion of the very high dimensional by approximating by diagonal, the inverse of which is trivial compute; i.e. we estimate = For the second stage, we assume that the coefficients for each feature can be shrunk differently, but that coefficients for each feature should be shrunk the same regardless of what label they are predicting. Thus, for a given observation we predict: the weights how much to shrink of the practice, we fold the variance of each of the features into the weight, giving a slightly modified equation: p p E = just a matrix of the counts of how often each context feature shows up with each label in the first training set. The vecwhich we will estimate by regression, is just shrinkage weights by the feature variance. Note that the formation here is different from the first stage. Instead of having each observation be a token, we now let each observation be a (token, label) pair, but only include those labels that were by SAMA. For a given token potenlabel our goal is to approximate the indicafunction which is 1 if the label of present, and 0 otherwise. We find candidate labels using a morphological analyzer (namely SAMA), which returns a set of possible candidate say for each Arabic token Our prelabel for then regression model for learning the weights in the second stage thus has a row for each label with a SAMA candidate for each . . the second trainset. The value of predicted as a funcof the feature vector shrinkage coefficients, could be estimated from theory, using a version of James-Stein shrinkage (James and Stein, 1961), but in practice, superior results are obtained by estimating them empirically. there are only them (unlike the a relatively small training set is sufficient. We found that regression-SVMs work slightly better than linear regression and significantly better than standard classification SVMs for this problem. Prediction is then done in the obvious way by takthe tokens in a test corpus generating context features and candidate SAMA labels for each and selected the candidate label with the score we set out to learn. More The model parameters and by the algorithm allow one to estimate the most label for a new token of a set of canlabels p The most expensive part of the procedure is eswhich requires for each token in cor- 1 algorithm. A training corpus two sets, of sizes and Using estimate the feature and label Using estimate Generate new “features” the true labels each of the SAMA candidate labels for of the tokens in 1 the above (feature,label) pairs Regression SVMs (a subset of finding the co-occurrence frequencies of each label element (a lemma, or a part of the morphological segmentation) with the target token and jointly with the token and with other tokens or characters in the context of the token of interest. For example, given an Arabic towe count what fraction of the time is associated with each lemma (e.g. Halam- 1, segment (e.g. “ya”), to- (Of course, most tokens never show up with most lemmas or segments; this is not a problem.) We also find the base rates of the components the labels (e.g., and what fraction of the time the label shows up in varicontexts, e.g. 1, previtoken = We describe these features in more detail below. 3 Features and Labels used for Training Our approach to tagging Arabic differs from conventional approaches in the two-part shrinkage-based method used, and in the choice of both features and labels used in our model. For features, we study both local context variables, as described above, and document-level word frequencies. For the labels, the key question is what labels are included and how they are factored. Standard “taggers” work by doing an n-way classification of all the alternatives, which not feasible here due to the thousands of possible labels. Standard approaches such as Conditional Random Fields (CRFs) are intractable with so many labels. Moreover, few if any taggers do any lemma disambiguation; that is partly because one must start with some standard inventory of lemmas, which are not available for most languages, perhaps because the importance of lemma disambiguation has been underestimated. We make a couple of important design decisions to deal with these issues. First, we perform lemma disambiguation in addition to “tagging”. As mentioned above, lemmas and morphological information are not independent; the choice of lemma often influences morphology and vice versa. For example, 1 contains two analyses for the word For first analysis, where the lemma is 1 gloss is + he/it the word is a verb. However, for the second analwhere the lemma is 1 the gloss is the word is a noun. Simultaneous lemma disambiguation and tagging introduces additional complexity: An analysis of ATB and SAMA shows that there are approximately 2,200 possible morphological analyses (“tags”) and 40,000 possible lemmas; even accounting for the fact that most combinations of lemmas and morphological analyses don’t occur, the size of the label space is still in the order of tens of thousands. To deal with data sparsity, our second design decision is to factor the labels. We factor each label a set of 16 label elements These include lemmas, as well as morphological elements such as basic part-of-speech, suffix, gender, number, mood, etc. These are explained in detail below. since each label a set of 15 categorical each the first learning stage is actually a vector with 16 nonzero components and thousands of zeros. Since we do simultaneous estimation the entire set of label elements, the value being predicted in the second learning phase is 1 if the entire label set is correct, and zero otherwise. We separate models for each label. 3.1 Label Elements (LEs) The fact that there are tens of thousands of possible labels presents the problem of extreme sparsity of label distribution in the training data. We find that a that estimates coefficients to predict a sin- LE Description lemma Lemma pre1 Closer prefix pre2 Farther prefix det Determiner pos Basic POS dpos Additional data on basic pos suf Suffix perpos Person (basic pos) numpos Number (basic pos) genpos Gender (basic pos) persuf Person (suffix) numsuf Number (suffix) gensuf Gender (suffix) mood Mood of verb pron Pronoun suffix 2: Label Elements Examples of additional data on basic POS include whether a noun is proper or common, whether a verb is transitive or not, etc. Both the basic POS and its suffix may have person, gender and number data. gle label (a label being in the Cartesian product of the set of label elements) yields poor performance. Therefore, as just mentioned, we factor each label a set of label elements and learn the between features and label elements, rather than features and entire label sets. This reduces, but does not come close to eliminating, the sparsity. A complete list of these and their possible values is detailed in Table 2. 3.2 Features 3.2.1 Local Context Features take from and for each such generate features on co-occurrence in as mentioned in Algorithm 2. These statistics include unigram co-occurrence frequencies of each label with the target token and bigram co-occurrence of the label with the token and with other tokens or characters in the context of the target token. We define them formally in Table 3. the set of all such basic features based on the local context statistics of the target token, namely the words and letters preceding and following it. We will use this set to create a baseline model.</abstract>
<title confidence="0.860218">Statistic Description Freq</title>
<keyword confidence="0.590986666666667">PrevWord l, NextWord l, PreviLetter l, NextiLetter l, PrevfLetter l, NextfLetter l,</keyword>
<abstract confidence="0.983991091803279">3: Co-occurrence statistics We use these to generate feature sets for our regression SVMs. each label element we define a set of similar to these features are based on co-occurrence frequencies of the particular not the entire label we define an aggregate feature set as follows: pre1, pre2, det, pos, dpos, suf, perpos, numpos, genpos, persuf, numsuf, gensuf, 3.2.2 Document Level Features When trying to predict the lemma, it is useful to include not just the words and characters immediately adjacent to the target token, but also the all the words in the document. These words capture the “topic” of the document, and help to disambiguate different lemmas, which tend to be used or not used based on the topic being discussed, similarly to the way that word sense disambiguation systems in English sometimes use the “bag of words” the document to disambiguate, for example a “bank” for depositing money from a “bank” of a river. More precisely, we augment the features for each target token with the counts of each word in the document (the frequency” in which the token occurs with a given label. � set our final feature set. We use train an SVM model this is our final predictive model. 3.3 Corpora used for Training and Testing We use three modules of the Penn Arabic Treebank (ATB) (Maamouri et al., 2004), namely ATB1, ATB2 and ATB3 as our corpus of labeled Aratext, Each ATB module is a collection of newswire data from a particular agency. ATB1 uses the Associated Press as a source, ATB2 uses and ATB3 uses Annahar. a total of 1,835 documents, accounting for approximately 350,000 words. We construct the training and testsets and 10-fold cross and we construct by randomly performing a 9:1 split. As mentioned earlier, we use the SAMA moranalyzer to obtain candidate labels each token training and testing an SVM on A sample output of SAMA is shown in Table 1. To improve covwe also add to all the labels for We find that doing so improves coverage to This is an upper bound on the accuracy of our model. � = 4 Results use two metrics of accuracy: which measures the percentage of tokens for which the model the highest score to the correct label or (or the corresponding percenterror), and which measures the percentage tokens for which the correct label or is one of the two highest ranked choices returned the model (or 100 We test our on achieve of 90.6% and 96.2% respectively. The accuracy by our is, to the best of our knowledge, higher than prior approaches have been able to achieve so far for the problem of combined morphological and lemma disambiguation. This is all the more impressive considering that the upper on accuracy for our model is as described above, our set of candidate labels is incomplete. order to analyze how well different can be we train an SVM model for each the feature set and test all such models The results for all the are reported in form of error percentages Table 4. Model E1 E2 Model E1 E2 11.1 4.9 1.9 1.4 0.2 0 0.7 0.1 23.4 4.0 10.3 1.9 7.6 2.5 3.0 0.1 3.2 0.2 1.8 0.1 3.2 0.1 8.2 0.5 11.6 0.4 1.6 1.4 1.8 0.6 14.7 5.9 9.4 3.8 - - - 4: Results of for each results reported are 10 fold cross validation test accuracies and no parameters have been tuned on them. comparison of the results for the for and particularly infor- We see that able to achieve a sublower score (9.4%) than and in other words, we find that our full model is able to predict lemmas and basic parts-of-speech more accurately than the individual models for each of these elements. examine the effect of varying the size of i.e. the number of SVM training instances, on the of onand find that with sizes of only slightly from 9.5% to 9.4%, and shows no improvement thereafter. We also find that the use of documentfeatures in perfor 5.7% and 3.2% respectively. 4.1 Comparison to Alternate Approaches 4.1.1 Structured Prediction Models Preliminary experiments showed that knowing the predicted labels (lemma + morphology) of the surrounding words can slightly improve the predictive accuracy of our model. To further investigate this effect, we tried running experiments using different structured models, namely CRF (Conditional Random Fields) (Lafferty et al., 2001), (Structured) MIRA (Margin Infused Relaxation Algorithm) (Crammer et al., 2006) and Structured Perceptron (Collins, 2002). We used linear chain CRFs as implemented in MALLET Toolbox (Mc- Callum, 2001) and for Structured MIRA and Perceptron we used their implementations from EDLIN Toolbox (Ganchev and Georgiev, 2009). However, given the vast label space of our problem, running these methods proved infeasible. The time complexity of these methods scales badly with the number of labels; It took a week to train a linear chain CRF only and though MIRA and Perceptron are online algorithms, they also become intractable beyond a few hundred labels. Since our label space contains combinations of lemmas and morphologies, so even after factoring, the dimension of the label space is in the order of thousands. We also tried a naive version (two-pass approximation) of these structured models. In addition to features in we include the predicted labels for the tokens preceding and following the target token as features. This new model is not only slow to train, but also achieves only slightly lower rates (1.2% lower 1.0% lower than This provides an upper bound on the benefit of using the more complex structured models, and suggests that given their computational demands our model a better choice. 4.1.2 MADA (Habash and Rambow, 2005) perform morphological disambiguation using a morphological analyzer. (Roth et al., 2008) augment this with lemma disambiguation; they call their system MADA. Our work differs from theirs in a number of respects; most notably, they don’t use the two step regression procedure that we use. Also, they do not learn a single model from a feature set based on labels instead, they combine models for individual elements by using weighted agreement. Finally, MADA uses a slightly different morphological analyzer (ALMORGEANA) than our system does (SAMA). We tested MADA v2.32 on our dataset its full feature set, and found that it rates of These errors are substantially higher than those from our system, but it should be noted that the numbers cannot be directly compared since we tested their system without retraining, and also used different test conditions (the full set of ATB 1,2 and 3 for MADA, versus 10-fold cross validation on ATB 1,2 and 3 for our system). Also, ALMORGEANA in MADAv2.32 uses older lexicons than those used by 4.1.3 Other Alternatives Labels: illustrate the benefit obby breaking down each label we contrast the performance of our to an SVM model usonly the feature set which only contains features based on entire labels, those on individual Independent lemma and morphology prediction: Another alternative approach is to predict lemmas and morphological analyses separately. We construct a feature train an SVM this feature set. Labels are then predicted by simply combining the predicted independently by this approach. Features: we also consider a context-less approach, i.e. using only “unifeatures for labels as well as We this feature set and the correspond- SVM model The results of these various models, along with of summarized in Table 5. Model E1 E2 13.6 9.1 18.7 6.0 11.6 6.4 8.2 2.8 9.4 3.8 Table 5: Percent error rates of alternative approaches. results reported are 10 fold cross validation test accuracies and no parameters have been tuned on them. We used same train-test splits for all the datasets. 5 Related Work (Hajic, 2000) show that for highly inflectional languages, the use of a morphological analyzer new version of MADA was released very close to the submission deadline for this conference. improves accuracy of disambiguation. (Diab et al., 2004) perform tokenization, POS tagging and base phrase chunking using an SVM based learner. (Ahmed and N¨urnberger, 2008) perform word-sense disambiguation using a Naive Bayesian model and rely on parallel corpora and matching schemes instead of a morphological analyzer. (Kulick, 2010) perform simultaneous tokenization and part-of-speech tagging for Arabic by separating closed and open-class items and focusing on the likelihood of possible stems of openclass words. (Mohamed and K¨ubler, 2010) present a hybrid method between word-based and segmentbased POS tagging for Arabic and report good results. (Toutanova and Cherry, 2009) perform joint lemmatization and part-of-speech tagging for English, Bulgarian, Czech and Slovene, but they do not use the two step estimation-shrinkage model described in this paper; nor do they factor labels. The idea of joint lemmatization and part-of-speech tagging has also been discussed in the context of Hungarian in (Kornai, 1994). A substantial amount of relevant work has been done previously for Hebrew. (Adler and Elhadad, 2006) perform Hebrew morphological disambiguation using an unsupervised morpheme-based HMM, but they report lower scores than those achieved by our model. Moreover, their analysis doesn’t include lemma IDs, which is a novelty of our model. (Goldberg et al., 2008) extend the work of (Adler and Elhadad, 2006) by using an EM algorithm, and achieve an accuracy of 88% for full morphological analysis, but again, this does not include lemma IDs. To the best of our knowledge, there is no existing research for Hebrew that does what we did for Arabic, namely to use simultaneous lemma and morphological disambiguation to improve both. (Dinur et al., 2009) show that prepositions and function words can be accurately segmented using unsupervised methods. However, by using this method as a preprocessstep, we would lose the power of a these problems. Our method is closer in style to a CRF, giving much of the accuracy gains of simultaneous solution, while being about 4 orders of magnitude easier to train. We believe that our use of factored labels is novel for the problem of simultaneous lemma and morphological disambiguation; however, (Smith et al., 2005) and (Hatori et al., 2008) have previously made use of features based on parts of labels in CRF models for morphological disambiguation and word-sense disambiguation respectively. Also, we note that there is a similarity between our two-stage machine learning approach and log-linear models in machine translation that break the data in two parts, estimating log-probabilities of generative models from one part, and discriminatively re-weighting the models using the second part. 6 Conclusions We introduced a new approach to accurately predict labels consisting of both lemmas and morphological analyses for Arabic text. We obtained an accuracy of over 90% – substantially higher than current state-of-the-art systems. Key to our success is the factoring of labels into lemma and a large set of morphosyntactic elements, and the use of an algorithm that computes a simple initial estimate of the coefficient relating each contextual feature to each label element (simply by counting co-occurrence) and then regularizes these features by shrinking each of the coefficients for each feature by an amount determined by supervised learning using only the candidate label sets produced by SAMA. We also showed that using features of word ngrams is preferable to using features of only individual tokens of data. Finally, we showed that a model using a full feature set based on labels as well as factored components of labels, which we call label works better than a model created combining individual models for each We believe that the approach we have used to create our model can be successfully applied not just to Arabic but also to other languages such as Turkish, Hungarian and Finnish that have highly inflectional morphology. The current accuracy of of our model, getting the correct answer among the top two choices 96.2% of the time is high enough to be highly useful for tasks such as aiding the manual annotation of Arabic text; a more complete automation would require that accuracy for the single top choice. Acknowledgments We woud like to thank everyone at the Linguistic Data Consortium, especially Christopher Cieri, David Graff, Seth Kulick, Ann Bies, Wajdi Zaghouani and Basma Bouziri for their help. We also wish to thank the anonymous reviewers for their comments and suggestions.</abstract>
<note confidence="0.7696618">References Meni Adler and Michael Elhadad. 2006. An Unsupervised Morpheme-Based HMM for Hebrew Morpho- Disambiguation. In of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Farag Ahmed and Andreas N¨urnberger. 2008. Arabic/English Word Translation Disambiguation using Corpora and Matching Schemes. In Proceedof Hamburg, Germany. Tim Buckwalter. 2004. Buckwalter Arabic Morphological Analyzer version 2.0. Michael Collins. 2002. Discriminative Training Methods for Hidden Markov Models: Theory and Experiwith Perceptron Algorithms. In of Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev- Shwartz, and Yoram Singer. 2006. Online Passive- Algorithms. of Machine Learning 7:551–585. Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004.</note>
<title confidence="0.64723775">Automatic Tagging of Arabic text: From Raw Text to Phrase Chunks. In of the 5th Meeting of the North American Chapter of the Association for Computational Linguistics/Human Language</title>
<note confidence="0.7925369">Conference Elad Dinur, Dmitry Davidov, and Ari Rappoport. 2009. Unsupervised Concept Discovery in Hebrew Using Simple Unsupervised Word Prefix Segmentation for and Arabic. In of the EACL 2009 Workshop on Computational Approaches to Semitic Kuzman Ganchev and Georgi Georgiev. 2009. Edlin: Easy to Read Linear Learning Framework. In Proof Yoav Goldberg, Meni Adler, and Michael Elhadad. 2008.</note>
<author confidence="0.567115">Arabic Tok-</author>
<affiliation confidence="0.222511">enization, Part-of-Speech Tagging and Morphological in One Fell Swoop. In of</affiliation>
<address confidence="0.680225">Ann Arbor, MI, USA.</address>
<author confidence="0.860311">Morphological Tagging Data vs Dic-</author>
<note confidence="0.9559125">In of the 1st Meeting of the North American Chapter of the Association for Com- Linguistics Jun Hatori, Yusuke Miyao, and Jun’ichi Tsujii. 2008.</note>
<title confidence="0.844070714285714">Word Sense Disambiguation for All Words using Tree- Conditional Random Fields. In Proceedof W. James and Charles Stein. 1961. Estimation with Loss. In of the Fourth Berkeley Symposium on Mathematical Statistics and Probabil- Volume</title>
<author confidence="0.924331">On Hungarian morphology</author>
<affiliation confidence="0.985845">guistics Institute of Hungarian Academy of Sciences,</affiliation>
<address confidence="0.580596">Seth Kulick. 2010. Simultaneous Tokenization and Part-</address>
<note confidence="0.754550571428571">of-Speech Tagging for Arabic without a Morphologi- Analyzer. In of John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence In of pages 282–289. Mohamed Maamouri, Ann Bies, and Tim Buckwalter. 2004. The Penn Arabic Treebank: Building a Large Annotated Arabic Corpus. In of NEMLAR Conference on Arabic Language Resources Mohamed Maamouri, David Graff, Basma Bouziri, Sondos Krouna, and Seth Kulick. 2009. LDC Standard Arabic Morphological Analyzer (SAMA) v. 3.0. McCallum, 2001. A Machine Learn-</note>
<title confidence="0.901664">for Language Software available at Emad Mohamed and Sandra K¨ubler. 2010. Arabic Part Speech Tagging. In of</title>
<author confidence="0.999578">Ryan Roth</author>
<author confidence="0.999578">Owen Rambow</author>
<author confidence="0.999578">Nizar Habash</author>
<author confidence="0.999578">Mona Diab</author>
<affiliation confidence="0.765648">and Cynthia Rudin. 2008. Arabic Morphological Tagging, Diacritization, and Lemmatization Using Lex- Models and Feature Ranking. In of</affiliation>
<address confidence="0.99933">Columbus, Ohio, USA.</address>
<author confidence="0.979551">Noah A Smith</author>
<author confidence="0.979551">David A Smith</author>
<author confidence="0.979551">Roy W Tromble</author>
<title confidence="0.76364275">2005. Context-Based Morphological Disambiguation Random Fields*. In of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</title>
<author confidence="0.753424">A Global</author>
<affiliation confidence="0.269086">Model for Joint Lemmatization and Part-of-Speech</affiliation>
<note confidence="0.8837875">In of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Propages 486–494.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Meni Adler</author>
<author>Michael Elhadad</author>
</authors>
<title>An Unsupervised Morpheme-Based HMM for Hebrew Morphological Disambiguation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="35164" citStr="Adler and Elhadad, 2006" startWordPosition="5975" endWordPosition="5978">f openclass words. (Mohamed and K¨ubler, 2010) present a hybrid method between word-based and segmentbased POS tagging for Arabic and report good results. (Toutanova and Cherry, 2009) perform joint lemmatization and part-of-speech tagging for English, Bulgarian, Czech and Slovene, but they do not use the two step estimation-shrinkage model described in this paper; nor do they factor labels. The idea of joint lemmatization and part-of-speech tagging has also been discussed in the context of Hungarian in (Kornai, 1994). A substantial amount of relevant work has been done previously for Hebrew. (Adler and Elhadad, 2006) perform Hebrew morphological disambiguation using an unsupervised morpheme-based HMM, but they report lower scores than those achieved by our model. Moreover, their analysis doesn’t include lemma IDs, which is a novelty of our model. (Goldberg et al., 2008) extend the work of (Adler and Elhadad, 2006) by using an EM algorithm, and achieve an accuracy of 88% for full morphological analysis, but again, this does not include lemma IDs. To the best of our knowledge, there is no existing research for Hebrew that does what we did for Arabic, namely to use simultaneous lemma and morphological disamb</context>
</contexts>
<marker>Adler, Elhadad, 2006</marker>
<rawString>Meni Adler and Michael Elhadad. 2006. An Unsupervised Morpheme-Based HMM for Hebrew Morphological Disambiguation. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Farag Ahmed</author>
<author>Andreas N¨urnberger</author>
</authors>
<title>Arabic/English Word Translation Disambiguation using Parallel Corpora and Matching Schemes.</title>
<date>2008</date>
<booktitle>In Proceedings of EAMT’08,</booktitle>
<location>Hamburg, Germany.</location>
<marker>Ahmed, N¨urnberger, 2008</marker>
<rawString>Farag Ahmed and Andreas N¨urnberger. 2008. Arabic/English Word Translation Disambiguation using Parallel Corpora and Matching Schemes. In Proceedings of EAMT’08, Hamburg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<title>Buckwalter Arabic Morphological Analyzer version 2.0.</title>
<date>2004</date>
<contexts>
<context position="7175" citStr="Buckwalter, 2004" startWordPosition="1133" endWordPosition="1134">awn from a much larger vocabulary of form-classes. While an English “tagger” can specify the morphosyntactic status of a word by choosing from a few dozen tags, an equivalent level of detail in Arabic would require thousands of alternatives. Similarly, the number of lemmas that might play a role in a given letter-sequence is generally much larger in Arabic than in English. We start our labeling of Arabic text with the alternative analyses provided by SAMA v. 3.1, the Standard Arabic Morphological Analyzer (Maamouri et al., 2009). SAMA is an updated version of the earlier Buckwalter analyzers (Buckwalter, 2004), with a number of significant differences in analysis to make it compatible with the LDC Arabic Treebank 3-v3.2 (Maamouri et al., 2004). The input to SAMA is an Arabic orthographic word (a string of letters delimited by whitespace or punctuation), and the output of SAMA is a set of alternative analyses, as shown in Table 1. For a typical word, SAMA produces approximately a dozen alternative analyses, but for certain highly ambiguous words it can produce hundreds of alternatives. The SAMA analyzer has good coverage; for typical texts, the correct analysis of an orthographic word can be found s</context>
</contexts>
<marker>Buckwalter, 2004</marker>
<rawString>Tim Buckwalter. 2004. Buckwalter Arabic Morphological Analyzer version 2.0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP’02.</booktitle>
<contexts>
<context position="30137" citStr="Collins, 2002" startWordPosition="5149" endWordPosition="5150">res in Mlemma reduces E1 and E2 percentages for Mlemma by 5.7% and 3.2% respectively. 4.1 Comparison to Alternate Approaches 4.1.1 Structured Prediction Models Preliminary experiments showed that knowing the predicted labels (lemma + morphology) of the surrounding words can slightly improve the predictive accuracy of our model. To further investigate this effect, we tried running experiments using different structured models, namely CRF (Conditional Random Fields) (Lafferty et al., 2001), (Structured) MIRA (Margin Infused Relaxation Algorithm) (Crammer et al., 2006) and Structured Perceptron (Collins, 2002). We used linear chain CRFs as implemented in MALLET Toolbox (McCallum, 2001) and for Structured MIRA and Perceptron we used their implementations from EDLIN Toolbox (Ganchev and Georgiev, 2009). However, given the vast label space of our problem, running these methods proved infeasible. The time complexity of these methods scales badly with the number of labels; It took a week to train a linear chain CRF for only ∼ 50 labels and though MIRA and Perceptron are online algorithms, they also become intractable beyond a few hundred labels. Since our label space contains combinations of lemmas and </context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms. In Proceedings of EMNLP’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Shai ShalevShwartz</author>
<author>Yoram Singer</author>
</authors>
<title>Online PassiveAggressive Algorithms.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>7--551</pages>
<contexts>
<context position="30095" citStr="Crammer et al., 2006" startWordPosition="5142" endWordPosition="5145"> We also find that the use of documentlevel features in Mlemma reduces E1 and E2 percentages for Mlemma by 5.7% and 3.2% respectively. 4.1 Comparison to Alternate Approaches 4.1.1 Structured Prediction Models Preliminary experiments showed that knowing the predicted labels (lemma + morphology) of the surrounding words can slightly improve the predictive accuracy of our model. To further investigate this effect, we tried running experiments using different structured models, namely CRF (Conditional Random Fields) (Lafferty et al., 2001), (Structured) MIRA (Margin Infused Relaxation Algorithm) (Crammer et al., 2006) and Structured Perceptron (Collins, 2002). We used linear chain CRFs as implemented in MALLET Toolbox (McCallum, 2001) and for Structured MIRA and Perceptron we used their implementations from EDLIN Toolbox (Ganchev and Georgiev, 2009). However, given the vast label space of our problem, running these methods proved infeasible. The time complexity of these methods scales badly with the number of labels; It took a week to train a linear chain CRF for only ∼ 50 labels and though MIRA and Perceptron are online algorithms, they also become intractable beyond a few hundred labels. Since our label </context>
</contexts>
<marker>Crammer, Dekel, Keshet, ShalevShwartz, Singer, 2006</marker>
<rawString>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai ShalevShwartz, and Yoram Singer. 2006. Online PassiveAggressive Algorithms. Journal of Machine Learning Research, 7:551–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Kadri Hacioglu</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic Tagging of Arabic text: From Raw Text to Base Phrase Chunks.</title>
<date>2004</date>
<booktitle>In Proceedings of the 5th Meeting of the North American Chapter of the Association for Computational Linguistics/Human Language Technologies Conference (HLT-NAACL’04).</booktitle>
<contexts>
<context position="34093" citStr="Diab et al., 2004" startWordPosition="5808" endWordPosition="5811">th those of Mfull are summarized in Table 5. Model E1 E2 Mbaseline 13.6 9.1 Mind 18.7 6.0 Muni 11.6 6.4 Mcheat 8.2 2.8 Mfull 9.4 3.8 Table 5: Percent error rates of alternative approaches. Note: The results reported are 10 fold cross validation test accuracies and no parameters have been tuned on them. We used same train-test splits for all the datasets. 5 Related Work (Hajic, 2000) show that for highly inflectional languages, the use of a morphological analyzer 1A new version of MADA was released very close to the submission deadline for this conference. improves accuracy of disambiguation. (Diab et al., 2004) perform tokenization, POS tagging and base phrase chunking using an SVM based learner. (Ahmed and N¨urnberger, 2008) perform word-sense disambiguation using a Naive Bayesian model and rely on parallel corpora and matching schemes instead of a morphological analyzer. (Kulick, 2010) perform simultaneous tokenization and part-of-speech tagging for Arabic by separating closed and open-class items and focusing on the likelihood of possible stems of openclass words. (Mohamed and K¨ubler, 2010) present a hybrid method between word-based and segmentbased POS tagging for Arabic and report good results</context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2004</marker>
<rawString>Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004. Automatic Tagging of Arabic text: From Raw Text to Base Phrase Chunks. In Proceedings of the 5th Meeting of the North American Chapter of the Association for Computational Linguistics/Human Language Technologies Conference (HLT-NAACL’04).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elad Dinur</author>
<author>Dmitry Davidov</author>
<author>Ari Rappoport</author>
</authors>
<title>Unsupervised Concept Discovery in Hebrew Using Simple Unsupervised Word Prefix Segmentation for Hebrew and Arabic.</title>
<date>2009</date>
<booktitle>In Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages.</booktitle>
<contexts>
<context position="35810" citStr="Dinur et al., 2009" startWordPosition="6085" endWordPosition="6088">al disambiguation using an unsupervised morpheme-based HMM, but they report lower scores than those achieved by our model. Moreover, their analysis doesn’t include lemma IDs, which is a novelty of our model. (Goldberg et al., 2008) extend the work of (Adler and Elhadad, 2006) by using an EM algorithm, and achieve an accuracy of 88% for full morphological analysis, but again, this does not include lemma IDs. To the best of our knowledge, there is no existing research for Hebrew that does what we did for Arabic, namely to use simultaneous lemma and morphological disambiguation to improve both. (Dinur et al., 2009) show that prepositions and function words can be accurately segmented using unsupervised methods. However, by using this method as a preprocessing step, we would lose the power of a simultaneous solution for these problems. Our method is closer in style to a CRF, giving much of the accuracy gains of simultaneous solution, while being about 4 orders of magnitude easier to train. We believe that our use of factored labels is novel for the problem of simultaneous lemma and morphological disambiguation; however, (Smith et al., 2005) and (Hatori et al., 2008) have previously made use of features b</context>
</contexts>
<marker>Dinur, Davidov, Rappoport, 2009</marker>
<rawString>Elad Dinur, Dmitry Davidov, and Ari Rappoport. 2009. Unsupervised Concept Discovery in Hebrew Using Simple Unsupervised Word Prefix Segmentation for Hebrew and Arabic. In Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Georgi Georgiev</author>
</authors>
<title>Edlin: An Easy to Read Linear Learning Framework.</title>
<date>2009</date>
<booktitle>In Proceedings of RANLP’09.</booktitle>
<contexts>
<context position="30331" citStr="Ganchev and Georgiev, 2009" startWordPosition="5178" endWordPosition="5181">ts showed that knowing the predicted labels (lemma + morphology) of the surrounding words can slightly improve the predictive accuracy of our model. To further investigate this effect, we tried running experiments using different structured models, namely CRF (Conditional Random Fields) (Lafferty et al., 2001), (Structured) MIRA (Margin Infused Relaxation Algorithm) (Crammer et al., 2006) and Structured Perceptron (Collins, 2002). We used linear chain CRFs as implemented in MALLET Toolbox (McCallum, 2001) and for Structured MIRA and Perceptron we used their implementations from EDLIN Toolbox (Ganchev and Georgiev, 2009). However, given the vast label space of our problem, running these methods proved infeasible. The time complexity of these methods scales badly with the number of labels; It took a week to train a linear chain CRF for only ∼ 50 labels and though MIRA and Perceptron are online algorithms, they also become intractable beyond a few hundred labels. Since our label space contains combinations of lemmas and morphologies, so even after factoring, the dimension of the label space is in the order of thousands. We also tried a naive version (two-pass approximation) of these structured models. In additi</context>
</contexts>
<marker>Ganchev, Georgiev, 2009</marker>
<rawString>Kuzman Ganchev and Georgi Georgiev. 2009. Edlin: An Easy to Read Linear Learning Framework. In Proceedings of RANLP’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Meni Adler</author>
<author>Michael Elhadad</author>
</authors>
<title>EM Can Find Pretty Good HMM POS-Taggers (When Given a Good Start)*.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL’08.</booktitle>
<contexts>
<context position="35422" citStr="Goldberg et al., 2008" startWordPosition="6014" endWordPosition="6018">n, Czech and Slovene, but they do not use the two step estimation-shrinkage model described in this paper; nor do they factor labels. The idea of joint lemmatization and part-of-speech tagging has also been discussed in the context of Hungarian in (Kornai, 1994). A substantial amount of relevant work has been done previously for Hebrew. (Adler and Elhadad, 2006) perform Hebrew morphological disambiguation using an unsupervised morpheme-based HMM, but they report lower scores than those achieved by our model. Moreover, their analysis doesn’t include lemma IDs, which is a novelty of our model. (Goldberg et al., 2008) extend the work of (Adler and Elhadad, 2006) by using an EM algorithm, and achieve an accuracy of 88% for full morphological analysis, but again, this does not include lemma IDs. To the best of our knowledge, there is no existing research for Hebrew that does what we did for Arabic, namely to use simultaneous lemma and morphological disambiguation to improve both. (Dinur et al., 2009) show that prepositions and function words can be accurately segmented using unsupervised methods. However, by using this method as a preprocessing step, we would lose the power of a simultaneous solution for the</context>
</contexts>
<marker>Goldberg, Adler, Elhadad, 2008</marker>
<rawString>Yoav Goldberg, Meni Adler, and Michael Elhadad. 2008. EM Can Find Pretty Good HMM POS-Taggers (When Given a Good Start)*. In Proceedings of ACL’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL’05,</booktitle>
<location>Ann Arbor, MI, USA.</location>
<contexts>
<context position="31427" citStr="Habash and Rambow, 2005" startWordPosition="5367" endWordPosition="5370">space is in the order of thousands. We also tried a naive version (two-pass approximation) of these structured models. In addition to the features in Zfull, we include the predicted labels for the tokens preceding and following the target token as features. This new model is not only slow to train, but also achieves only slightly lower error rates (1.2% lower E1 and 1.0% lower E2) than Mfull. This provides an upper bound on the benefit of using the more complex structured models, and suggests that given their computational demands our (unstructured) model Mfull is a better choice. 4.1.2 MADA (Habash and Rambow, 2005) perform morphological disambiguation using a morphological analyzer. (Roth et al., 2008) augment this with lemma disambiguation; they call their system MADA. Our work differs from theirs in a number of respects; most notably, they don’t use the two step regression procedure that we use. Also, they do not learn a single model from a feature set based on labels and LEs; instead, they combine models for individual elements by using weighted agreement. Finally, MADA uses a slightly different morphological analyzer (ALMORGEANA) than our system does (SAMA). We tested MADA v2.32 on our dataset using</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proceedings of ACL’05, Ann Arbor, MI, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajic</author>
</authors>
<title>Morphological Tagging: Data vs. Dictionaries.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL’00).</booktitle>
<contexts>
<context position="33860" citStr="Hajic, 2000" startWordPosition="5774" endWordPosition="5775">Finally, we also consider a context-less approach, i.e. using only “unigram” features for labels as well as LEs. We call this feature set Zuni, and the corresponding SVM model Muni. The results of these various models, along with those of Mfull are summarized in Table 5. Model E1 E2 Mbaseline 13.6 9.1 Mind 18.7 6.0 Muni 11.6 6.4 Mcheat 8.2 2.8 Mfull 9.4 3.8 Table 5: Percent error rates of alternative approaches. Note: The results reported are 10 fold cross validation test accuracies and no parameters have been tuned on them. We used same train-test splits for all the datasets. 5 Related Work (Hajic, 2000) show that for highly inflectional languages, the use of a morphological analyzer 1A new version of MADA was released very close to the submission deadline for this conference. improves accuracy of disambiguation. (Diab et al., 2004) perform tokenization, POS tagging and base phrase chunking using an SVM based learner. (Ahmed and N¨urnberger, 2008) perform word-sense disambiguation using a Naive Bayesian model and rely on parallel corpora and matching schemes instead of a morphological analyzer. (Kulick, 2010) perform simultaneous tokenization and part-of-speech tagging for Arabic by separatin</context>
</contexts>
<marker>Hajic, 2000</marker>
<rawString>Jan Hajic. 2000. Morphological Tagging: Data vs. Dictionaries. In Proceedings of the 1st Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL’00).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Hatori</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Word Sense Disambiguation for All Words using TreeStructured Conditional Random Fields.</title>
<date>2008</date>
<booktitle>In Proceedings of COLing’08.</booktitle>
<contexts>
<context position="36371" citStr="Hatori et al., 2008" startWordPosition="6179" endWordPosition="6182">ogical disambiguation to improve both. (Dinur et al., 2009) show that prepositions and function words can be accurately segmented using unsupervised methods. However, by using this method as a preprocessing step, we would lose the power of a simultaneous solution for these problems. Our method is closer in style to a CRF, giving much of the accuracy gains of simultaneous solution, while being about 4 orders of magnitude easier to train. We believe that our use of factored labels is novel for the problem of simultaneous lemma and morphological disambiguation; however, (Smith et al., 2005) and (Hatori et al., 2008) have previously made use of features based on parts of labels in CRF models for morphological disambiguation and word-sense disambiguation respectively. Also, we note that there is a similarity between our two-stage machine learning approach and log-linear models in machine translation that break the data in two parts, estimating log-probabilities of generative models from one part, and discriminatively re-weighting the models using the second part. 6 Conclusions We introduced a new approach to accurately predict labels consisting of both lemmas and morphological analyses for Arabic text. We </context>
</contexts>
<marker>Hatori, Miyao, Tsujii, 2008</marker>
<rawString>Jun Hatori, Yusuke Miyao, and Jun’ichi Tsujii. 2008. Word Sense Disambiguation for All Words using TreeStructured Conditional Random Fields. In Proceedings of COLing’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W James</author>
<author>Charles Stein</author>
</authors>
<title>Estimation with Quadratic Loss.</title>
<date>1961</date>
<booktitle>In Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability,</booktitle>
<volume>1</volume>
<contexts>
<context position="17714" citStr="James and Stein, 1961" startWordPosition="2977" endWordPosition="2980">e labels using a morphological analyzer (namely SAMA), which returns a set of possible candidate labels, say C(t), for each Arabic token t. Our predicted label for ti is then argmaxk∈C(ti)g(i, k). The regression model for learning the weights αj in the second stage thus has a row for each label g(i, k) associated with a SAMA candidate for each token i = ntrain1+1 . . . ntrain2 in the second training set. The value of g(i, k) is predicted as a function of the feature vector zijk = 0∗jkxij. The shrinkage coefficients, αj, could be estimated from theory, using a version of James-Stein shrinkage (James and Stein, 1961), but in practice, superior results are obtained by estimating them empirically. Since there are only p of them (unlike the p ∗ h 0s), a relatively small training set is sufficient. We found that regression-SVMs work slightly better than linear regression and significantly better than standard classification SVMs for this problem. Prediction is then done in the obvious way by taking the tokens in a test corpus Dtest, generating context features and candidate SAMA labels for each token ti, and selected the candidate label with the highest score ˆg(i, k) that we set out to learn. More formally, </context>
</contexts>
<marker>James, Stein, 1961</marker>
<rawString>W. James and Charles Stein. 1961. Estimation with Quadratic Loss. In Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´as Kornai</author>
</authors>
<title>On Hungarian morphology (Linguistica, Series A: Studia et Dissertationes 14). Linguistics Institute of Hungarian Academy of Sciences,</title>
<date>1994</date>
<location>Budapest.</location>
<contexts>
<context position="35062" citStr="Kornai, 1994" startWordPosition="5961" endWordPosition="5962">y separating closed and open-class items and focusing on the likelihood of possible stems of openclass words. (Mohamed and K¨ubler, 2010) present a hybrid method between word-based and segmentbased POS tagging for Arabic and report good results. (Toutanova and Cherry, 2009) perform joint lemmatization and part-of-speech tagging for English, Bulgarian, Czech and Slovene, but they do not use the two step estimation-shrinkage model described in this paper; nor do they factor labels. The idea of joint lemmatization and part-of-speech tagging has also been discussed in the context of Hungarian in (Kornai, 1994). A substantial amount of relevant work has been done previously for Hebrew. (Adler and Elhadad, 2006) perform Hebrew morphological disambiguation using an unsupervised morpheme-based HMM, but they report lower scores than those achieved by our model. Moreover, their analysis doesn’t include lemma IDs, which is a novelty of our model. (Goldberg et al., 2008) extend the work of (Adler and Elhadad, 2006) by using an EM algorithm, and achieve an accuracy of 88% for full morphological analysis, but again, this does not include lemma IDs. To the best of our knowledge, there is no existing research </context>
</contexts>
<marker>Kornai, 1994</marker>
<rawString>Andr´as Kornai. 1994. On Hungarian morphology (Linguistica, Series A: Studia et Dissertationes 14). Linguistics Institute of Hungarian Academy of Sciences, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seth Kulick</author>
</authors>
<title>Simultaneous Tokenization and Partof-Speech Tagging for Arabic without a Morphological Analyzer.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL’10.</booktitle>
<contexts>
<context position="34375" citStr="Kulick, 2010" startWordPosition="5852" endWordPosition="5853">n tuned on them. We used same train-test splits for all the datasets. 5 Related Work (Hajic, 2000) show that for highly inflectional languages, the use of a morphological analyzer 1A new version of MADA was released very close to the submission deadline for this conference. improves accuracy of disambiguation. (Diab et al., 2004) perform tokenization, POS tagging and base phrase chunking using an SVM based learner. (Ahmed and N¨urnberger, 2008) perform word-sense disambiguation using a Naive Bayesian model and rely on parallel corpora and matching schemes instead of a morphological analyzer. (Kulick, 2010) perform simultaneous tokenization and part-of-speech tagging for Arabic by separating closed and open-class items and focusing on the likelihood of possible stems of openclass words. (Mohamed and K¨ubler, 2010) present a hybrid method between word-based and segmentbased POS tagging for Arabic and report good results. (Toutanova and Cherry, 2009) perform joint lemmatization and part-of-speech tagging for English, Bulgarian, Czech and Slovene, but they do not use the two step estimation-shrinkage model described in this paper; nor do they factor labels. The idea of joint lemmatization and part-</context>
</contexts>
<marker>Kulick, 2010</marker>
<rawString>Seth Kulick. 2010. Simultaneous Tokenization and Partof-Speech Tagging for Arabic without a Morphological Analyzer. In Proceedings of ACL’10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.</title>
<date>2001</date>
<booktitle>In Proceedings of ICML’01,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="30015" citStr="Lafferty et al., 2001" startWordPosition="5131" endWordPosition="5134"> E1 reduces only slightly from 9.5% to 9.4%, and shows no improvement thereafter. We also find that the use of documentlevel features in Mlemma reduces E1 and E2 percentages for Mlemma by 5.7% and 3.2% respectively. 4.1 Comparison to Alternate Approaches 4.1.1 Structured Prediction Models Preliminary experiments showed that knowing the predicted labels (lemma + morphology) of the surrounding words can slightly improve the predictive accuracy of our model. To further investigate this effect, we tried running experiments using different structured models, namely CRF (Conditional Random Fields) (Lafferty et al., 2001), (Structured) MIRA (Margin Infused Relaxation Algorithm) (Crammer et al., 2006) and Structured Perceptron (Collins, 2002). We used linear chain CRFs as implemented in MALLET Toolbox (McCallum, 2001) and for Structured MIRA and Perceptron we used their implementations from EDLIN Toolbox (Ganchev and Georgiev, 2009). However, given the vast label space of our problem, running these methods proved infeasible. The time complexity of these methods scales badly with the number of labels; It took a week to train a linear chain CRF for only ∼ 50 labels and though MIRA and Perceptron are online algori</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. In Proceedings of ICML’01, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Tim Buckwalter</author>
</authors>
<title>The Penn Arabic Treebank: Building a Large Scale Annotated Arabic Corpus.</title>
<date>2004</date>
<booktitle>In Proceedings of NEMLAR Conference on Arabic Language Resources and Tools.</booktitle>
<contexts>
<context position="7311" citStr="Maamouri et al., 2004" startWordPosition="1153" endWordPosition="1156">oosing from a few dozen tags, an equivalent level of detail in Arabic would require thousands of alternatives. Similarly, the number of lemmas that might play a role in a given letter-sequence is generally much larger in Arabic than in English. We start our labeling of Arabic text with the alternative analyses provided by SAMA v. 3.1, the Standard Arabic Morphological Analyzer (Maamouri et al., 2009). SAMA is an updated version of the earlier Buckwalter analyzers (Buckwalter, 2004), with a number of significant differences in analysis to make it compatible with the LDC Arabic Treebank 3-v3.2 (Maamouri et al., 2004). The input to SAMA is an Arabic orthographic word (a string of letters delimited by whitespace or punctuation), and the output of SAMA is a set of alternative analyses, as shown in Table 1. For a typical word, SAMA produces approximately a dozen alternative analyses, but for certain highly ambiguous words it can produce hundreds of alternatives. The SAMA analyzer has good coverage; for typical texts, the correct analysis of an orthographic word can be found somewhere in SAMA’s list of alternatives about 95% of the time. However, this broad coverage comes at a cost; the list of analytic altern</context>
<context position="26356" citStr="Maamouri et al., 2004" startWordPosition="4460" endWordPosition="4463">hat word sense disambiguation systems in English sometimes use the “bag of words” the document to disambiguate, for example a “bank” for depositing money from a “bank” of a river. More precisely, we augment the features for each target token with the counts of each word in the document (the “term frequency” tf) in which the token occurs with a given label. � Zfull = Zaggr Ztf (8) This set Zfull is our final feature set. We use Zfull to train an SVM model Mfull; this is our final predictive model. 3.3 Corpora used for Training and Testing We use three modules of the Penn Arabic Treebank (ATB) (Maamouri et al., 2004), namely ATB1, ATB2 and ATB3 as our corpus of labeled Arabic text, D. Each ATB module is a collection of newswire data from a particular agency. ATB1 uses the Associated Press as a source, ATB2 uses Ummah, and ATB3 uses Annahar. D contains a total of 1,835 documents, accounting for approximately 350,000 words. We construct the training and testing sets Dtrain and Dtest from D using 10-fold cross validation, and we construct D1 and D2 from Dtrain by randomly performing a 9:1 split. As mentioned earlier, we use the SAMA morphological analyzer to obtain candidate labels C(t) for each token t whil</context>
</contexts>
<marker>Maamouri, Bies, Buckwalter, 2004</marker>
<rawString>Mohamed Maamouri, Ann Bies, and Tim Buckwalter. 2004. The Penn Arabic Treebank: Building a Large Scale Annotated Arabic Corpus. In Proceedings of NEMLAR Conference on Arabic Language Resources and Tools.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>David Graff</author>
<author>Basma Bouziri</author>
<author>Sondos Krouna</author>
<author>Seth Kulick</author>
</authors>
<date>2009</date>
<journal>LDC Standard Arabic Morphological Analyzer (SAMA) v.</journal>
<volume>3</volume>
<contexts>
<context position="7092" citStr="Maamouri et al., 2009" startWordPosition="1118" endWordPosition="1121">han a comparable English letter-string does, and these analyses have many more parts, drawn from a much larger vocabulary of form-classes. While an English “tagger” can specify the morphosyntactic status of a word by choosing from a few dozen tags, an equivalent level of detail in Arabic would require thousands of alternatives. Similarly, the number of lemmas that might play a role in a given letter-sequence is generally much larger in Arabic than in English. We start our labeling of Arabic text with the alternative analyses provided by SAMA v. 3.1, the Standard Arabic Morphological Analyzer (Maamouri et al., 2009). SAMA is an updated version of the earlier Buckwalter analyzers (Buckwalter, 2004), with a number of significant differences in analysis to make it compatible with the LDC Arabic Treebank 3-v3.2 (Maamouri et al., 2004). The input to SAMA is an Arabic orthographic word (a string of letters delimited by whitespace or punctuation), and the output of SAMA is a set of alternative analyses, as shown in Table 1. For a typical word, SAMA produces approximately a dozen alternative analyses, but for certain highly ambiguous words it can produce hundreds of alternatives. The SAMA analyzer has good cover</context>
</contexts>
<marker>Maamouri, Graff, Bouziri, Krouna, Kulick, 2009</marker>
<rawString>Mohamed Maamouri, David Graff, Basma Bouziri, Sondos Krouna, and Seth Kulick. 2009. LDC Standard Arabic Morphological Analyzer (SAMA) v. 3.0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
</authors>
<title>MALLET: A Machine Learning for Language Toolkit. Software available at http://mallet.cs.umass.edu.</title>
<date>2001</date>
<contexts>
<context position="30214" citStr="McCallum, 2001" startWordPosition="5161" endWordPosition="5163">ectively. 4.1 Comparison to Alternate Approaches 4.1.1 Structured Prediction Models Preliminary experiments showed that knowing the predicted labels (lemma + morphology) of the surrounding words can slightly improve the predictive accuracy of our model. To further investigate this effect, we tried running experiments using different structured models, namely CRF (Conditional Random Fields) (Lafferty et al., 2001), (Structured) MIRA (Margin Infused Relaxation Algorithm) (Crammer et al., 2006) and Structured Perceptron (Collins, 2002). We used linear chain CRFs as implemented in MALLET Toolbox (McCallum, 2001) and for Structured MIRA and Perceptron we used their implementations from EDLIN Toolbox (Ganchev and Georgiev, 2009). However, given the vast label space of our problem, running these methods proved infeasible. The time complexity of these methods scales badly with the number of labels; It took a week to train a linear chain CRF for only ∼ 50 labels and though MIRA and Perceptron are online algorithms, they also become intractable beyond a few hundred labels. Since our label space contains combinations of lemmas and morphologies, so even after factoring, the dimension of the label space is in</context>
</contexts>
<marker>McCallum, 2001</marker>
<rawString>Andrew McCallum, 2001. MALLET: A Machine Learning for Language Toolkit. Software available at http://mallet.cs.umass.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emad Mohamed</author>
<author>Sandra K¨ubler</author>
</authors>
<title>Arabic Part of Speech Tagging.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC’10.</booktitle>
<marker>Mohamed, K¨ubler, 2010</marker>
<rawString>Emad Mohamed and Sandra K¨ubler. 2010. Arabic Part of Speech Tagging. In Proceedings of LREC’10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Roth</author>
<author>Owen Rambow</author>
<author>Nizar Habash</author>
<author>Mona Diab</author>
<author>Cynthia Rudin</author>
</authors>
<title>Arabic Morphological Tagging, Diacritization, and Lemmatization Using Lexeme Models and Feature Ranking.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL’08,</booktitle>
<location>Columbus, Ohio, USA.</location>
<contexts>
<context position="31516" citStr="Roth et al., 2008" startWordPosition="5380" endWordPosition="5383">hese structured models. In addition to the features in Zfull, we include the predicted labels for the tokens preceding and following the target token as features. This new model is not only slow to train, but also achieves only slightly lower error rates (1.2% lower E1 and 1.0% lower E2) than Mfull. This provides an upper bound on the benefit of using the more complex structured models, and suggests that given their computational demands our (unstructured) model Mfull is a better choice. 4.1.2 MADA (Habash and Rambow, 2005) perform morphological disambiguation using a morphological analyzer. (Roth et al., 2008) augment this with lemma disambiguation; they call their system MADA. Our work differs from theirs in a number of respects; most notably, they don’t use the two step regression procedure that we use. Also, they do not learn a single model from a feature set based on labels and LEs; instead, they combine models for individual elements by using weighted agreement. Finally, MADA uses a slightly different morphological analyzer (ALMORGEANA) than our system does (SAMA). We tested MADA v2.32 on our dataset using its full feature set, and found that it gaveE1 and E2 error rates of 16.9 and 12.6 respe</context>
</contexts>
<marker>Roth, Rambow, Habash, Diab, Rudin, 2008</marker>
<rawString>Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab, and Cynthia Rudin. 2008. Arabic Morphological Tagging, Diacritization, and Lemmatization Using Lexeme Models and Feature Ranking. In Proceedings of ACL’08, Columbus, Ohio, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah A Smith</author>
<author>David A Smith</author>
<author>Roy W Tromble</author>
</authors>
<title>Context-Based Morphological Disambiguation with Random Fields*.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP).</booktitle>
<contexts>
<context position="36345" citStr="Smith et al., 2005" startWordPosition="6174" endWordPosition="6177">taneous lemma and morphological disambiguation to improve both. (Dinur et al., 2009) show that prepositions and function words can be accurately segmented using unsupervised methods. However, by using this method as a preprocessing step, we would lose the power of a simultaneous solution for these problems. Our method is closer in style to a CRF, giving much of the accuracy gains of simultaneous solution, while being about 4 orders of magnitude easier to train. We believe that our use of factored labels is novel for the problem of simultaneous lemma and morphological disambiguation; however, (Smith et al., 2005) and (Hatori et al., 2008) have previously made use of features based on parts of labels in CRF models for morphological disambiguation and word-sense disambiguation respectively. Also, we note that there is a similarity between our two-stage machine learning approach and log-linear models in machine translation that break the data in two parts, estimating log-probabilities of generative models from one part, and discriminatively re-weighting the models using the second part. 6 Conclusions We introduced a new approach to accurately predict labels consisting of both lemmas and morphological ana</context>
</contexts>
<marker>Smith, Smith, Tromble, 2005</marker>
<rawString>Noah A. Smith, David A. Smith, and Roy W. Tromble. 2005. Context-Based Morphological Disambiguation with Random Fields*. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Colin Cherry</author>
</authors>
<title>A Global Model for Joint Lemmatization and Part-of-Speech Prediction.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing,</booktitle>
<pages>486--494</pages>
<contexts>
<context position="34723" citStr="Toutanova and Cherry, 2009" startWordPosition="5904" endWordPosition="5907">rform tokenization, POS tagging and base phrase chunking using an SVM based learner. (Ahmed and N¨urnberger, 2008) perform word-sense disambiguation using a Naive Bayesian model and rely on parallel corpora and matching schemes instead of a morphological analyzer. (Kulick, 2010) perform simultaneous tokenization and part-of-speech tagging for Arabic by separating closed and open-class items and focusing on the likelihood of possible stems of openclass words. (Mohamed and K¨ubler, 2010) present a hybrid method between word-based and segmentbased POS tagging for Arabic and report good results. (Toutanova and Cherry, 2009) perform joint lemmatization and part-of-speech tagging for English, Bulgarian, Czech and Slovene, but they do not use the two step estimation-shrinkage model described in this paper; nor do they factor labels. The idea of joint lemmatization and part-of-speech tagging has also been discussed in the context of Hungarian in (Kornai, 1994). A substantial amount of relevant work has been done previously for Hebrew. (Adler and Elhadad, 2006) perform Hebrew morphological disambiguation using an unsupervised morpheme-based HMM, but they report lower scores than those achieved by our model. Moreover,</context>
</contexts>
<marker>Toutanova, Cherry, 2009</marker>
<rawString>Kristina Toutanova and Colin Cherry. 2009. A Global Model for Joint Lemmatization and Part-of-Speech Prediction. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing, pages 486–494.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>