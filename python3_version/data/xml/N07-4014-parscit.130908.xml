<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.047319">
<title confidence="0.996117">
The Hidden Information State Dialogue Manager:
A Real-World POMDP-Based System
</title>
<author confidence="0.996793">
Steve Young, Jost Schatzmann, Blaise Thomson, Karl Weilhammer, Hui Ye
</author>
<affiliation confidence="0.995573">
Cambridge University Engineering Department
</affiliation>
<address confidence="0.54674">
Trumpington Street, Cambridge, CB21PZ, United Kingdom
</address>
<email confidence="0.974277">
{sjy, js532, brmt2, kw278, hy216}@eng.cam.ac.uk
</email>
<sectionHeader confidence="0.995402" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996692">
The Hidden Information State (HIS)
Dialogue System is the first trainable
and scalable implementation of a spoken
dialog system based on the Partially-
Observable Markov-Decision-Process
(POMDP) model of dialogue. The system
responds to n-best output from the speech
recogniser, maintains multiple concurrent
dialogue state hypotheses, and provides
a visual display showing how competing
hypotheses are ranked. The demo is
a prototype application for the Tourist
Information Domain and achieved a task
completion rate of over 90% in a recent
user study.
</bodyText>
<sectionHeader confidence="0.704786" genericHeader="method">
1 Partially Observable Markov Decision
</sectionHeader>
<subsectionHeader confidence="0.916264">
Processes for Dialogue Systems
</subsectionHeader>
<bodyText confidence="0.999912571428571">
Recent work on statistical models for spoken di-
alogue systems has argued that Partially Observ-
able Markov Decision Processes (POMDPs) provide
a principled mathematical framework for modeling
the uncertainty inherent in human-machine dialogue
(Williams, 2006; Young, 2006; Williams and Young,
2007). Briefly speaking, POMDPs extend the tra-
ditional fully-observable Markov Decision Process
(MDP) framework by maintaining a belief state, ie.
a probability distribution over dialogue states. This
enables the dialogue manager to avoid and recover
from recognition errors by sharing and shifting prob-
ability mass between multiple hypotheses of the cur-
rent dialogue state. The framework also naturally
</bodyText>
<page confidence="0.893558">
27
</page>
<bodyText confidence="0.999008866666667">
incorporates n-best lists of multiple recognition hy-
potheses coming from the speech recogniser.
Due to the vast number of possible dialogue states
and policies, the use of POMDPs in practical dia-
logue systems is far from straightforward. The size
of the belief state scales linearly with the number of
dialogue states and belief state updates at every turn
during a dialogue require all state probabilities to be
recomputed. This is too computationally intensive
to be practical with current technology. Worse than
that, the complexity involved in policy optimisation
grows exponentially with the number of states and
system actions and neither exact nor approximate al-
gorithms exist that provide a tractable solution for
systems with thousands of states.
</bodyText>
<sectionHeader confidence="0.9401535" genericHeader="method">
2 The Hidden Information State (HIS)
Dialogue Manager
</sectionHeader>
<bodyText confidence="0.9997335">
The Hidden Information State (HIS) dialogue man-
ager presented in this demonstration is the first train-
able and scalable dialogue system based on the
POMDP model. As described in (Young, 2006;
Young et al., 2007) it partitions the state space using
a tree-based representation of user goals so that only
a small set of partition beliefs needs to be updated
at every turn. In order to make policy optimisation
tractable, a much reduced summary space is main-
tained in addition to the master state space. Policies
are optimised in summary space and the selected
summary actions are then mapped back to master
space to form system actions. Apart from some very
simple ontology definitions, the dialog manager has
no application dependent heuristics.
The system uses a grid-based discretisation of the
</bodyText>
<note confidence="0.370395">
NAACL HLT Demonstration Program, pages 27–28,
</note>
<affiliation confidence="0.662517">
Rochester, New York, USA, April 2007. c�2007 Association for Computational Linguistics
</affiliation>
<figureCaption confidence="0.969129">
Figure 1: The HIS Demo System is a Tourist Infor-
mation application for a fictitious town
Figure 2: A system screenshot showing the ranking
of competing dialogue state hypotheses
</figureCaption>
<bodyText confidence="0.9997825">
state space and online c-greedy policy optimisation.
While this offers the potential for online adaptation
with real users at a later stage, a simulated user is
needed to bootstrap the training process. A novel
agenda-based simulation technique was used for this
step, as described in (Schatzmann et al., 2007).
</bodyText>
<sectionHeader confidence="0.997024" genericHeader="method">
3 The HIS Demo System
</sectionHeader>
<bodyText confidence="0.999978666666667">
The HIS demo system is a prototype application for
the Tourist Information domain. Users are assumed
to be visiting a fictitious town called “Jasonville”
(see Fig. 1) and need to find a suitable hotel, bar
or restaurant subject to certain constraints. Exam-
ples of task scenarios are “finding a cheap Chinese
restaurant near the post office in the centre of town”
or “a wine bar with Jazz music on the riverside”.
Once a venue is found, users may request further in-
formation such as the phone number or the address.
At run-time, the system provides a visual display
(see Fig. 2) which shows how competing dialogue
state hypotheses are being ranked. This allows de-
velopers to gain a better understanding of the inter-
nal operation of the system.
</bodyText>
<sectionHeader confidence="0.967193" genericHeader="method">
4 Demo System Performance
</sectionHeader>
<bodyText confidence="0.999960875">
In a recent user study the demo system was evalu-
ated by 40 human subjects. In total, 160 dialogues
were recorded with an average Word-Error-Rate of
29.8%. The performance of the system was mea-
sured based on the recommendation of a correct
venue and achieved a task completion rate of 90.6%
with an average number of 5.59 dialogue turns to
completion (Thomson et al., 2007).
The results demonstrate that POMDPs facilitate
design and implementation of spoken dialogue sys-
tems, and that the implementation used in the HIS
dialogue manager can be scaled to handle real world
tasks. The user study results also show that a
simulated user can be successfully used to train a
POMDP dialogue policy that performs well in ex-
periments with real users.
</bodyText>
<sectionHeader confidence="0.983436" genericHeader="conclusions">
5 Accompanying materials
</sectionHeader>
<bodyText confidence="0.999085666666667">
The demo system and related materials are accessi-
ble online at our website
http://mi.eng.cam.ac.uk/research/dialogue/.
</bodyText>
<sectionHeader confidence="0.998573" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9997911">
J. Schatzmann, B. Thomson, K. Weilhammer, H. Ye, and
S. Young. 2007. Agenda-Based User Simulation for Boot-
strapping a POMDP Dialogue System. In Proceedings of
HLT/NAACL, Rochester, NY.
B. Thomson, J. Schatzmann, K. Weilhammer, H. Ye, and
S. Young. 2007. Training a real-world POMDP-based Di-
alogue System. In Proceedings of Bridging the Gap: Aca-
demic and Industrial Research in Dialog Technology, Work-
shop at HLT/NAACL, Rochester, NY.
J. D. Williams and S. Young. 2007. Partially Observable
Markov Decision Processes for Spoken Dialog Systems.
Computer Speech and Language, 21(2):231–422.
J. D. Williams. 2006. Partially Observable Markov Decision
Processes for Spoken Dialogue Management. Ph.D. thesis,
University of Cambridge.
S. Young, J. Schatzmann, K. Weilhammer, and H. Ye. 2007.
The Hidden Information State Approach to Dialog Manage-
ment. In Proc. ofICASSP (forthcoming), Honolulu, Hawaii.
S. Young. 2006. Using POMDPs for Dialog Management. In
Proc. ofIEEE/ACL SLT, Palm Beach, Aruba.
</reference>
<page confidence="0.999072">
28
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001434">
<title confidence="0.9998425">The Hidden Information State Dialogue A Real-World POMDP-Based System</title>
<author confidence="0.998898">Steve Young</author>
<author confidence="0.998898">Jost Schatzmann</author>
<author confidence="0.998898">Blaise Thomson</author>
<author confidence="0.998898">Karl Weilhammer</author>
<author confidence="0.998898">Hui</author>
<affiliation confidence="0.999375">Cambridge University Engineering</affiliation>
<address confidence="0.674944">Trumpington Street, Cambridge, CB21PZ, United</address>
<email confidence="0.405239">js532,brmt2,kw278,</email>
<abstract confidence="0.9995621875">The Hidden Information State (HIS) Dialogue System is the first trainable and scalable implementation of a spoken system based on the Partially- Observable (POMDP) model of dialogue. The system responds to n-best output from the speech recogniser, maintains multiple concurrent dialogue state hypotheses, and provides a visual display showing how competing hypotheses are ranked. The demo is a prototype application for the Tourist Information Domain and achieved a task completion rate of over 90% in a recent user study.</abstract>
<title confidence="0.7676">1 Partially Observable Markov Decision Processes for Dialogue Systems</title>
<abstract confidence="0.974842666666667">Recent work on statistical models for spoken dialogue systems has argued that Partially Observable Markov Decision Processes (POMDPs) provide a principled mathematical framework for modeling the uncertainty inherent in human-machine dialogue (Williams, 2006; Young, 2006; Williams and Young, 2007). Briefly speaking, POMDPs extend the traditional fully-observable Markov Decision Process framework by maintaining a ie. a probability distribution over dialogue states. This enables the dialogue manager to avoid and recover from recognition errors by sharing and shifting probability mass between multiple hypotheses of the current dialogue state. The framework also naturally 27 incorporates n-best lists of multiple recognition hypotheses coming from the speech recogniser. Due to the vast number of possible dialogue states and policies, the use of POMDPs in practical dialogue systems is far from straightforward. The size of the belief state scales linearly with the number of dialogue states and belief state updates at every turn during a dialogue require all state probabilities to be recomputed. This is too computationally intensive to be practical with current technology. Worse than that, the complexity involved in policy optimisation grows exponentially with the number of states and system actions and neither exact nor approximate algorithms exist that provide a tractable solution for systems with thousands of states. 2 The Hidden Information State (HIS) Dialogue Manager The Hidden Information State (HIS) dialogue manager presented in this demonstration is the first trainable and scalable dialogue system based on the POMDP model. As described in (Young, 2006; Young et al., 2007) it partitions the state space using a tree-based representation of user goals so that only a small set of partition beliefs needs to be updated at every turn. In order to make policy optimisation tractable, a much reduced summary space is maintained in addition to the master state space. Policies are optimised in summary space and the selected summary actions are then mapped back to master space to form system actions. Apart from some very simple ontology definitions, the dialog manager has no application dependent heuristics. The system uses a grid-based discretisation of the HLT Demonstration pages 27–28, New York, USA, April 2007. Association for Computational Linguistics Figure 1: The HIS Demo System is a Tourist Information application for a fictitious town Figure 2: A system screenshot showing the ranking of competing dialogue state hypotheses space and online policy optimisation. While this offers the potential for online adaptation with real users at a later stage, a simulated user is needed to bootstrap the training process. A novel agenda-based simulation technique was used for this step, as described in (Schatzmann et al., 2007). 3 The HIS Demo System The HIS demo system is a prototype application for the Tourist Information domain. Users are assumed to be visiting a fictitious town called “Jasonville” (see Fig. 1) and need to find a suitable hotel, bar or restaurant subject to certain constraints. Examof task scenarios are a cheap Chinese restaurant near the post office in the centre of town” wine bar with Jazz music on the Once a venue is found, users may request further information such as the phone number or the address. At run-time, the system provides a visual display (see Fig. 2) which shows how competing dialogue state hypotheses are being ranked. This allows developers to gain a better understanding of the internal operation of the system. 4 Demo System Performance In a recent user study the demo system was evaluated by 40 human subjects. In total, 160 dialogues were recorded with an average Word-Error-Rate of 29.8%. The performance of the system was measured based on the recommendation of a correct venue and achieved a task completion rate of 90.6% with an average number of 5.59 dialogue turns to completion (Thomson et al., 2007). The results demonstrate that POMDPs facilitate design and implementation of spoken dialogue systems, and that the implementation used in the HIS dialogue manager can be scaled to handle real world tasks. The user study results also show that a simulated user can be successfully used to train a POMDP dialogue policy that performs well in experiments with real users. 5 Accompanying materials The demo system and related materials are accessible online at our website</abstract>
<title confidence="0.754268">References</title>
<author confidence="0.721272">Agenda-Based User Simulation for Boot-</author>
<affiliation confidence="0.411461">a POMDP Dialogue System. In of</affiliation>
<address confidence="0.543168">Rochester,</address>
<note confidence="0.725682411764706">B. Thomson, J. Schatzmann, K. Weilhammer, H. Ye, and S. Young. 2007. Training a real-world POMDP-based Di- System. In of Bridging the Gap: Academic and Industrial Research in Dialog Technology, Workat HLT/NAACL, Rochester, J. D. Williams and S. Young. 2007. Partially Observable Markov Decision Processes for Spoken Dialog Systems. Speech and 21(2):231–422. D. Williams. 2006. Observable Markov Decision for Spoken Dialogue Ph.D. thesis, University of Cambridge. S. Young, J. Schatzmann, K. Weilhammer, and H. Ye. 2007. The Hidden Information State Approach to Dialog Manage- In ofICASSP Honolulu, Hawaii. S. Young. 2006. Using POMDPs for Dialog Management. In ofIEEE/ACL Palm Beach, Aruba. 28</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Schatzmann</author>
<author>B Thomson</author>
<author>K Weilhammer</author>
<author>H Ye</author>
<author>S Young</author>
</authors>
<title>Agenda-Based User Simulation for Bootstrapping a POMDP Dialogue System. In</title>
<date>2007</date>
<booktitle>Proceedings of HLT/NAACL,</booktitle>
<location>Rochester, NY.</location>
<contexts>
<context position="3852" citStr="Schatzmann et al., 2007" startWordPosition="571" endWordPosition="574">he NAACL HLT Demonstration Program, pages 27–28, Rochester, New York, USA, April 2007. c�2007 Association for Computational Linguistics Figure 1: The HIS Demo System is a Tourist Information application for a fictitious town Figure 2: A system screenshot showing the ranking of competing dialogue state hypotheses state space and online c-greedy policy optimisation. While this offers the potential for online adaptation with real users at a later stage, a simulated user is needed to bootstrap the training process. A novel agenda-based simulation technique was used for this step, as described in (Schatzmann et al., 2007). 3 The HIS Demo System The HIS demo system is a prototype application for the Tourist Information domain. Users are assumed to be visiting a fictitious town called “Jasonville” (see Fig. 1) and need to find a suitable hotel, bar or restaurant subject to certain constraints. Examples of task scenarios are “finding a cheap Chinese restaurant near the post office in the centre of town” or “a wine bar with Jazz music on the riverside”. Once a venue is found, users may request further information such as the phone number or the address. At run-time, the system provides a visual display (see Fig. 2</context>
</contexts>
<marker>Schatzmann, Thomson, Weilhammer, Ye, Young, 2007</marker>
<rawString>J. Schatzmann, B. Thomson, K. Weilhammer, H. Ye, and S. Young. 2007. Agenda-Based User Simulation for Bootstrapping a POMDP Dialogue System. In Proceedings of HLT/NAACL, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Thomson</author>
<author>J Schatzmann</author>
<author>K Weilhammer</author>
<author>H Ye</author>
<author>S Young</author>
</authors>
<title>Training a real-world POMDP-based Dialogue System. In</title>
<date>2007</date>
<booktitle>Proceedings of Bridging the Gap: Academic and Industrial Research in Dialog Technology, Workshop at HLT/NAACL,</booktitle>
<location>Rochester, NY.</location>
<marker>Thomson, Schatzmann, Weilhammer, Ye, Young, 2007</marker>
<rawString>B. Thomson, J. Schatzmann, K. Weilhammer, H. Ye, and S. Young. 2007. Training a real-world POMDP-based Dialogue System. In Proceedings of Bridging the Gap: Academic and Industrial Research in Dialog Technology, Workshop at HLT/NAACL, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Williams</author>
<author>S Young</author>
</authors>
<title>Partially Observable Markov Decision Processes for Spoken Dialog Systems.</title>
<date>2007</date>
<journal>Computer Speech and Language,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="1223" citStr="Williams and Young, 2007" startWordPosition="163" endWordPosition="166">e concurrent dialogue state hypotheses, and provides a visual display showing how competing hypotheses are ranked. The demo is a prototype application for the Tourist Information Domain and achieved a task completion rate of over 90% in a recent user study. 1 Partially Observable Markov Decision Processes for Dialogue Systems Recent work on statistical models for spoken dialogue systems has argued that Partially Observable Markov Decision Processes (POMDPs) provide a principled mathematical framework for modeling the uncertainty inherent in human-machine dialogue (Williams, 2006; Young, 2006; Williams and Young, 2007). Briefly speaking, POMDPs extend the traditional fully-observable Markov Decision Process (MDP) framework by maintaining a belief state, ie. a probability distribution over dialogue states. This enables the dialogue manager to avoid and recover from recognition errors by sharing and shifting probability mass between multiple hypotheses of the current dialogue state. The framework also naturally 27 incorporates n-best lists of multiple recognition hypotheses coming from the speech recogniser. Due to the vast number of possible dialogue states and policies, the use of POMDPs in practical dialog</context>
</contexts>
<marker>Williams, Young, 2007</marker>
<rawString>J. D. Williams and S. Young. 2007. Partially Observable Markov Decision Processes for Spoken Dialog Systems. Computer Speech and Language, 21(2):231–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Williams</author>
</authors>
<title>Partially Observable Markov Decision Processes for Spoken Dialogue Management.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Cambridge.</institution>
<contexts>
<context position="1183" citStr="Williams, 2006" startWordPosition="159" endWordPosition="160">recogniser, maintains multiple concurrent dialogue state hypotheses, and provides a visual display showing how competing hypotheses are ranked. The demo is a prototype application for the Tourist Information Domain and achieved a task completion rate of over 90% in a recent user study. 1 Partially Observable Markov Decision Processes for Dialogue Systems Recent work on statistical models for spoken dialogue systems has argued that Partially Observable Markov Decision Processes (POMDPs) provide a principled mathematical framework for modeling the uncertainty inherent in human-machine dialogue (Williams, 2006; Young, 2006; Williams and Young, 2007). Briefly speaking, POMDPs extend the traditional fully-observable Markov Decision Process (MDP) framework by maintaining a belief state, ie. a probability distribution over dialogue states. This enables the dialogue manager to avoid and recover from recognition errors by sharing and shifting probability mass between multiple hypotheses of the current dialogue state. The framework also naturally 27 incorporates n-best lists of multiple recognition hypotheses coming from the speech recogniser. Due to the vast number of possible dialogue states and policie</context>
</contexts>
<marker>Williams, 2006</marker>
<rawString>J. D. Williams. 2006. Partially Observable Markov Decision Processes for Spoken Dialogue Management. Ph.D. thesis, University of Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Young</author>
<author>J Schatzmann</author>
<author>K Weilhammer</author>
<author>H Ye</author>
</authors>
<title>The Hidden Information State Approach to Dialog Management.</title>
<date>2007</date>
<booktitle>In Proc. ofICASSP (forthcoming),</booktitle>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="2646" citStr="Young et al., 2007" startWordPosition="381" endWordPosition="384">ties to be recomputed. This is too computationally intensive to be practical with current technology. Worse than that, the complexity involved in policy optimisation grows exponentially with the number of states and system actions and neither exact nor approximate algorithms exist that provide a tractable solution for systems with thousands of states. 2 The Hidden Information State (HIS) Dialogue Manager The Hidden Information State (HIS) dialogue manager presented in this demonstration is the first trainable and scalable dialogue system based on the POMDP model. As described in (Young, 2006; Young et al., 2007) it partitions the state space using a tree-based representation of user goals so that only a small set of partition beliefs needs to be updated at every turn. In order to make policy optimisation tractable, a much reduced summary space is maintained in addition to the master state space. Policies are optimised in summary space and the selected summary actions are then mapped back to master space to form system actions. Apart from some very simple ontology definitions, the dialog manager has no application dependent heuristics. The system uses a grid-based discretisation of the NAACL HLT Demon</context>
</contexts>
<marker>Young, Schatzmann, Weilhammer, Ye, 2007</marker>
<rawString>S. Young, J. Schatzmann, K. Weilhammer, and H. Ye. 2007. The Hidden Information State Approach to Dialog Management. In Proc. ofICASSP (forthcoming), Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Young</author>
</authors>
<title>Using POMDPs for Dialog Management.</title>
<date>2006</date>
<booktitle>In Proc. ofIEEE/ACL SLT,</booktitle>
<location>Palm Beach, Aruba.</location>
<contexts>
<context position="1196" citStr="Young, 2006" startWordPosition="161" endWordPosition="162">tains multiple concurrent dialogue state hypotheses, and provides a visual display showing how competing hypotheses are ranked. The demo is a prototype application for the Tourist Information Domain and achieved a task completion rate of over 90% in a recent user study. 1 Partially Observable Markov Decision Processes for Dialogue Systems Recent work on statistical models for spoken dialogue systems has argued that Partially Observable Markov Decision Processes (POMDPs) provide a principled mathematical framework for modeling the uncertainty inherent in human-machine dialogue (Williams, 2006; Young, 2006; Williams and Young, 2007). Briefly speaking, POMDPs extend the traditional fully-observable Markov Decision Process (MDP) framework by maintaining a belief state, ie. a probability distribution over dialogue states. This enables the dialogue manager to avoid and recover from recognition errors by sharing and shifting probability mass between multiple hypotheses of the current dialogue state. The framework also naturally 27 incorporates n-best lists of multiple recognition hypotheses coming from the speech recogniser. Due to the vast number of possible dialogue states and policies, the use of</context>
<context position="2625" citStr="Young, 2006" startWordPosition="379" endWordPosition="380">ate probabilities to be recomputed. This is too computationally intensive to be practical with current technology. Worse than that, the complexity involved in policy optimisation grows exponentially with the number of states and system actions and neither exact nor approximate algorithms exist that provide a tractable solution for systems with thousands of states. 2 The Hidden Information State (HIS) Dialogue Manager The Hidden Information State (HIS) dialogue manager presented in this demonstration is the first trainable and scalable dialogue system based on the POMDP model. As described in (Young, 2006; Young et al., 2007) it partitions the state space using a tree-based representation of user goals so that only a small set of partition beliefs needs to be updated at every turn. In order to make policy optimisation tractable, a much reduced summary space is maintained in addition to the master state space. Policies are optimised in summary space and the selected summary actions are then mapped back to master space to form system actions. Apart from some very simple ontology definitions, the dialog manager has no application dependent heuristics. The system uses a grid-based discretisation o</context>
</contexts>
<marker>Young, 2006</marker>
<rawString>S. Young. 2006. Using POMDPs for Dialog Management. In Proc. ofIEEE/ACL SLT, Palm Beach, Aruba.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>