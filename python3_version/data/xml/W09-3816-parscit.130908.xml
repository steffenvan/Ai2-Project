<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009052">
<title confidence="0.991608">
Co-Parsing with Competitive Models
</title>
<author confidence="0.994021">
Lidia Khmylko Kilian A. Foth
</author>
<affiliation confidence="0.9961055">
Natural Language Systems Group smartSpeed GmbH &amp; Co. KG
University of Hamburg, Germany Hamburg, Germany
</affiliation>
<email confidence="0.965486">
khmylko@informatik.uni-hamburg.de kilian.foth@smartspeed.com
</email>
<author confidence="0.999649">
Wolfgang Menzel
</author>
<affiliation confidence="0.996431">
Natural Language Systems Group
University of Hamburg, Germany
</affiliation>
<email confidence="0.993999">
menzel@informatik.uni-hamburg.de
</email>
<sectionHeader confidence="0.993796" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999978411764706">
We present an asymmetric approach to
a run-time combination of two parsers
where one component serves as a predic-
tor to the other one. Predictions are inte-
grated by means of weighted constraints
and therefore are subject to preferential
decisions. Previously, the same architec-
ture has been successfully used with pre-
dictors providing partial or inferior infor-
mation about the parsing problem. It has
now been applied to a situation where the
predictor produces exactly the same type
of information at a fully competitive qual-
ity level. Results show that the combined
system outperforms its individual compo-
nents, even though their performance in
isolation is already fairly high.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999944763636364">
Machine learning techniques for automatically ac-
quiring processing models from a data collec-
tion and traditional methods of eliciting linguistic
knowledge from human experts are usually con-
sidered as two alternative roadmaps towards nat-
ural language processing solutions. Since the re-
sulting components exhibit quite different perfor-
mance characteristics with respect to coverage, ro-
bustness and output quality, they might be able to
provide some kind of complementary information,
which could even lead to a notable degree of syn-
ergy between them when combined within a single
system solution.
For the task of dependency parsing, the high
potential for such a synergy has indeed been
demonstrated already (e.g. Zeman and ˇZabokrtsk´y
(2005), Foth and Menzel (2006)).
A popular approach for combining alterna-
tive decision procedures is voting (Zeman and
ˇZabokrtsk´y, 2005). It makes use of a symmet-
ric architecture, where a meta component chooses
from among the available candidate hypotheses by
means of a (weighted) voting scheme. Such an ap-
proach not only requires the target structures of all
components to be of the same kind, but in case of
complex structures like parse trees also requires
sophisticated decision procedures which are able
to select the optimal hypotheses with respect to ad-
ditional global constraints (e.g. the tree property).
Since this optimization problem has to be solved
by the individual parser anyhow, an asymmetric
architecture suggests itself as an alternative.
In asymmetric architectures, a master compo-
nent, i.e. a full fledged parser, is solely in charge of
deciding on the target structure, whilst the others
(so called helper or predictor components) provide
additional evidence which is integrated into the
global decision by suitable means. Such a scheme
has been extensively investigated for the Weighted
Constraint Dependency Grammar, WCDG (Foth,
2006). External evidence from the predictor com-
ponents is integrated by means of constraints,
which check for compatibility between a local
structure and a prediction, and penalize this hy-
pothesis in case of a conflict. So far, however,
all the additional information sources which have
been considered in this research differed consider-
ably from the master component: They either fo-
cused on particular aspects of the parsing problem
(e.g. POS tagging, chunking, PP attachment), or
used a simplified scheme for structural annotation
(e.g. projective instead of non-projective trees).
This paper takes one step further by investigat-
ing the same architecture under the additional con-
dition that (1) the helper component provides the
</bodyText>
<page confidence="0.983133">
99
</page>
<note confidence="0.8775505">
Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 99–107,
Paris, October 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999053227272727">
very same kind of target structure as the master,
and (2) the quality levels of each of the compo-
nents in isolation are considered.
As a helper component MSTParser (McDon-
ald, 2006), a state-of-the-art dependency parser for
non-projective structures based on a discrimina-
tive learning paradigm, is considered. The accu-
racy of MSTParser differs insignificatly from that
of WCDG with all the previously used helper com-
ponents active.
Section two introduces WCDG with a special
emphasis on the soft integration of external ev-
idence while section three describes MSTParser
which is used as a new predictor component. Since
parsing results for these systems have been re-
ported in quite different experimental settings we
first evaluate them under comparable conditions
and provide the results of using MSTParser as a
guiding predictor for WCDG in section four and
discuss whether the expected synergies have re-
ally materialized. Section five concentrates on a
comparative error analysis.
</bodyText>
<sectionHeader confidence="0.996953" genericHeader="introduction">
2 WCDG
</sectionHeader>
<bodyText confidence="0.99994025">
The formalism of a Constraint Dependency Gram-
mar was first introduced by Maruyama (1990)
and suggests modeling natural language with the
help of constraints. Schr¨oder (2002) has extended
the approach to Weighted Constraint Dependency
Grammar, WCDG, where weights are used to fur-
ther disambiguate between competing structural
alternatives. A WCDG models natural language
as labeled dependency trees and is entirely declar-
ative. It has no derivation rules — instead, con-
straints license well-formed tree structures. The
reference implementation of WCDG for the Ger-
man language used for the experiments described
below contains about 1, 000 manually compiled
constraints.1
Every constraint of the WCDG carries a weight,
also referred to as a penalty, in the interval from
zero to one, a lower value of the weight re-
flects its greater importance. Constraints having
zero weights are referred to as hard and are used
for prohibitive rules. Constraints with a weight
greater than zero, also called defeasible, may ex-
press universal principles or vague preferences for
language phenomena.
</bodyText>
<footnote confidence="0.978696">
1Freely available from http://nats-www.
informatik.uni-hamburg.de/view/CDG/
DownloadPage
</footnote>
<bodyText confidence="0.999925764705883">
Attempts have been made to compute the
weights of a WCDG automatically by observing
which weight vectors perform best on a given cor-
pus, but the computations did not bring any sig-
nificant improvements to the manually assigned
scored (Schr¨oder et al., 2001). Empirically, the
absolute values of defeasible constraints usually
do not matter greatly as long as the relative impor-
tance of the rules remains preserved so that typical
constructions are preferred, but seldom variations
are also allowed. Thus, the values of weights of
the WCDG constraints have to be determined by
the grammar writer experimentally.
If a set of dependency edges in a parse found by
the system violates any of the constraints, it is reg-
istered as a constraint violation between the struc-
ture and the rules of the language. The score of an
analysis is the product of all the weights for con-
straint violations occurring in the structure. It be-
comes possible to differentiate between the qual-
ity of different parse results: the analysis with a
higher score is considered preferable. Although,
under these conditions, an analysis having only a
few grave conflicts may be preferred by the system
against another one with a great number of smaller
constraint violations, but it ensures that an analysis
which violates any of the hard constraints always
receives the lowest possible score.
The parsing problem is being treated in the
WCDG system as a Constraint Satisfaction Prob-
lem. While a complete search is intractable for
such a problem, transformation-based solution
methods provide a reliable heuristic alternative.
Starting with an initial guess about the optimal
tree, changes of labels, subordinations, or lexi-
cal variants are applied, with constraint violations
used as a control mechanism guiding the transfor-
mation process (Foth et al., 2000).
A transformation-based search cannot guaran-
tee to find the best solution to the constraint sat-
isfaction problem. Compared to the resource re-
quirements of a complete search, however, it is not
only more efficient, but can also be interrupted at
any time. Even if interrupted, it will always return
an analysis, together with a list of constraint viola-
tions it was not able to remove. The algorithm ter-
minates on its own if no violated constraints with
a weight above a predefined threshold remain. Al-
ternatively, a timeout condition can be imposed.
The same kind of constraints that describe
grammar rules, can also be used as an interface
</bodyText>
<page confidence="0.985923">
100
</page>
<bodyText confidence="0.999959833333333">
to external predictor components. Thus, the for-
malism turned out to be flexible enough to incor-
porate other sources of knowledge into the de-
cision process on the optimal structural interpre-
tation. Foth and Menzel (2006) have reported
about five additional statistical components that
have been successfully integrated into WCDG:
POS tagger, chunker, supertagger, PP attacher and
a shift-reduce oracle parser. They have also shown
that the accuracy improves if multiple compo-
nents interact and consistent predictions no longer
can be guaranteed. Even thought previously in-
tegrated predictor components have an accuracy
that is mostly — with the exception of the tag-
ger — below that of the parser itself, WCDG not
only avoids error propagation successfully, it also
improves its results consistently with each compo-
nent added.
</bodyText>
<sectionHeader confidence="0.998549" genericHeader="method">
3 MSTParser
</sectionHeader>
<bodyText confidence="0.999971340909091">
MSTParser (McDonald, 2006) is a state-of-the-art
language independent data-driven parser. It pro-
cesses the input in two separate stages. In the first,
the dependency structure is determined, labeling is
applied to it successively in the second. The rea-
sons of its efficiency lie in the successful combi-
nation of discriminative learning with graph-based
solution methods for the parsing problem.
In this edge-factored graph-based model, each
edge of the dependency graph is assigned a real-
valued score by its linear model. The score of the
graph is defined as the sum of its edge scores.
If a scoring function for edges is known, the
parsing problem becomes equivalent to finding the
highest scoring directed spanning tree in the com-
plete graph over the given sentence, and the cor-
rect parse can be obtained by searching the space
of valid dependency graphs for a tree with a max-
imum score.
This formalism allows to find efficient solutions
for both projective and non-projective trees. When
only features over single edges are taken into ac-
count, the complexity falls to O(n2) (McDonald
et al., 2005).
Not only a single edge, but also adjacent edges
may be included into the scoring function. As a
result, intractability problems arise for the non-
projective algorithm, but an efficient approximate
algorithm based on exhaustive search is provided
for this case (McDonald et al., 2006). This algo-
rithm was also used for our experiments.2
The parsing model of MSTParser has the advan-
tage that it can be trained globally and eventually
be applied with an exact inference algorithm. On
the other hand, the parser has only limited access
to the history of parsing decisions. To avoid com-
plexity problems, the scores (and the feature rep-
resentations) are restricted to a single edge or ad-
jacent edges. Outsourcing labeling into a separate
stage comes at the price of not being able to com-
bine knowledge about the label and the structure it
is attached to. Such combined evidence, however,
might be helpful for some disambiguation prob-
lems.
</bodyText>
<sectionHeader confidence="0.89418" genericHeader="method">
4 Guiding WCDG by Predictions of
MSTParser
</sectionHeader>
<bodyText confidence="0.9999619375">
MSTParser predictions are integrated into the de-
cision procedure of WCDG by means of two ad-
ditional constraints, which monitor each depen-
dency hypothesis for being in accord with the pre-
diction and penalize it if a mismatch has been
found. One of the constraints checks the attach-
ment point being the same, while the other takes
care of the dependency label.
To properly adjust the weights of these con-
straints, it has to be determined how valuable the
information of the predictor is relative to the infor-
mation already present in the system. This grada-
tion is needed to establish a balance between the
influence of the grammar and the predictor. Ac-
cording to the scoring principles of WCDG, a low
weight strongly deprecates all deviations from the
prediction, thus forcing the system to follow them
almost without exception. Higher weights, on the
other hand, enable the grammar to override a pre-
diction. This, however, also means that predic-
tions have less guiding effect of the transformation
process. Typically for WCDG, the best suitable
weights have to be tuned on development data.
To determine the best constraint weights the
WCDG grammar has been extended with three
additional constraints similar to those used for
the shift-reduce predictor in the previous experi-
ments (Foth, 2006). Two of them advise WCDG
on the structural information available from the
MSTParser result and one fetches the edge label
predicted.
As a result of these experiments, the optimum
</bodyText>
<footnote confidence="0.9857575">
2MSTParser is freely available from http://
sourceforge.net/projects/mstparser
</footnote>
<page confidence="0.997991">
101
</page>
<bodyText confidence="0.992679074074074">
weight for the attachment predictions has been ad-
justed to 0.75. Compared to a weight of 0.9 for
the shift-reduce parser, this is a rather strong in-
fluence, which also reflects the differences in the
reliability of these two information sources. With
a weight of 0.9, the integration of the label predic-
tions is considerably weaker, which is consistent
with their lower degree of accuracy.
Evaluation
The most common general measures for the qual-
ity of dependency trees are structural accuracy
that points out the percentage of words correctly
attached to their head word, and labeled accuracy
which is the ratio of the correctly attached words
which also have the correct label. Still, it is dif-
ficult to directly compare the results reported for
different parsers, as the evaluation results are in-
fluenced by the data used during the experiment,
the domain of the data, and different annotation
guidelines. Moreover, the particular kind of POS
information might be relevant, which either can be
obtained from the manual annotations or be pro-
vided by a real tagger. Even such a condition
as the treatment of punctuation has not yet be-
come a standard. Following the evaluation proce-
dure in the CoNLL-X shared task (Buchholz and
Marsi, 2006), we will not include punctuation into
the performance measures, as was done in previ-
ous WCDG experiments (Foth and Menzel, 2006).
The source of POS tagging information will need
to be specified in each individual case.
All the evaluations were performed on a thou-
sand sentences (18,602 – 19,601) from the
NEGRA treebank, the same data set that was pre-
viously used in the performance evaluations of
WCDG, e.g. in (Foth, 2006). The NEGRA
treebank is a collection of newspaper articles; in
the original, it stores phrase structure annotations.
These have been automatically translated into de-
pendency trees and then manually corrected to
bring them in accord with the annotation guide-
lines of WCDG. The major difference consists
in a different treatment of non-projectivity, where
WCDG only allows non-projectivity in the attach-
ment of verbal arguments, relative clauses and co-
ordinations, i.e., the cases where it helps to de-
crease ambiguity. Furthermore, corrections were
applied when the annotations of NEGRA itself
turned out to be inconsistent (usually in connec-
tion with co-ordinated or elliptical structures, ad-
verbs and subclauses).
Unfortunately, these manually corrected data
were only available for a small part (3, 000 sen-
tences) of the NEGRA corpus, which is not
sufficient for training MSTParser on WCDG-
conforming tree structures. Previous evaluations
of the MSTParser have used much larger train-
ing sets. E.g., during the CoNLL-X shared
task 39,216 sentences from the TIGER Treebank
(Brants et al., 2002) were used.
Therefore, we used 20, 000 sentences from the
online archive of www.heise.de as an alterna-
tive training set. They have been manually an-
notated according to the WCDG guidelines (and
are referred to heiseticker in the following)3.
The texts in this corpus are all from roughly the
same domain as in NEGRA, and although very
many technical terms and proper nouns are used,
the sentences have only a slightly longer mean
length compared to the NEGRA corpus.
Using POS tags from the gold annotations,
MSTParser achieves 90.5% structural and 87.5%
labeled accuracy on the aforementioned NEGRA
test set (Table 1). Even a model trained on the
inconsistent NEGRA data excluding the test set
reaches state-of-the-art 90.5 and 87.3% for struc-
tural and labeled accuracy respectively, despite
the obvious mismatch between training and test
data. This performance is almost the same as the
90.4%/87.3% reported on the TIGER data during
the CoNLL-X 2006 shared task.
</bodyText>
<equation confidence="0.891799666666667">
Experiment structural labeled
MSTParser-h
MSTParser-N
MSTParser(CoNLL-X)
WCDG + MST
WCDG + MST + 5P
</equation>
<tableCaption confidence="0.740192333333333">
Table 1: Structural/labeled accuracy results with
POS tagging from the gold standard. WCDG
— no statistical enhancements used. MSTParser-
</tableCaption>
<equation confidence="0.722271">
h — MSTParser trained on the heiseticker.
MSTParser-N — MSTParser trained on NEGRA.
5P — with all five statistical predictors of WCDG.
</equation>
<bodyText confidence="0.999517333333333">
As is to be expected, if a real POS tagger is used
in the experiments with MSTParser, the accuracy
is reduced quite expectedly by approximately one
</bodyText>
<footnote confidence="0.950435428571429">
3The heiseticker dependency treebank is under
preparation and will be available soon.
90.5 87.5
90.5 87.3
90.4 87.3
92.9 91.3
93.3 92.0
</footnote>
<page confidence="0.986061">
102
</page>
<bodyText confidence="0.998488">
percent to 89.5%/86.0% (Table 2 (B)). All the re-
sults obtained with a real POS tagger are summa-
rized in Table 2. For comparison, under the same
evaluation conditions, the performance of WCDG
with different predictors is summarized in Table 2
(A).
</bodyText>
<table confidence="0.999834826086957">
Experiment structural labeled
WCDG 88.0 86.0
CP 88.6 86.5
PP 89.4 87.3
ST 90.8 89.2
SR 90.0 88.4
PP+SR 90.2 88.6
ST+SR 91.0 89.4
ST+PP 90.8 89.2
5P 91.3 90.0
MSTParser 89.5 86.0
WCDG + MST 92.0 90.5
PP 92.0 90.6
CP 92.1 90.6
SR 92.2 90.6
ST 92.4 90.9
CP+SR 92.3 90.7
CP+ST 92.6 91.0
ST+SR 92.9 91.4
PP+CP+ST 92.6 91.1
PP+ST+SR 92.8 91.3
CP+ST+SR 92.9 91.4
5P 92.9 91.4
</table>
<tableCaption confidence="0.8385775">
Table 2: Structural/labeled accuracy results with
a real POS tagger. (A) WCDG experiments with
</tableCaption>
<bodyText confidence="0.994623541666667">
different statistical enhancements (B) MSTParser
experiment with a real POS tagger. (C) Com-
bined experiments of WCDG and MSTParser with
other statistical enhancements of WCDG. CP —
chunker, ST — supertagger, PP — prepositional
attacher, SR — shift-reduce oracle parser, 5P —
POS + CP + PP + ST + SR.
The combined experiments in which MSTParser
was used as a predictor for WCDG have achieved
higher accuracy than each of the combined com-
ponents in isolation: the structural accuracy rises
to 92.0% while the labeled accuracy also gets over
the 90%-boundary (WCDG + MST experiment in
Table 2 (C)) .
Finally, the MSTParser predictor was evaluated
in combination with the other predictors avail-
able for WCDG. The results of the experiments
are shown in Table 2 (C). Every combination of
MSTParser with other predictors (first four exper-
iments) improves the accuracy. The increase is
highest (0.4%) for the combination with the su-
pertagger. This confirms earlier experiments with
WCDG, in which the supertagger also contributed
the largest gains.
The experimental results again confirm that
WCDG is a reliable platform for information in-
tegration. Although the use of multiple predictors
does not lead to an accumulation of the individual
improvements, the performance of predictor com-
binations is always higher that using them sepa-
rately. A maximum performance of 92.9%/91.4%
is reached with all the six available predictors ac-
tive. For comparison, the same experiment with
POS tags from the gold standard has achieved even
better results of 93.3%/92.0% (Table 1).
Unfortunately, the PP attacher brings accuracy
reductions when it is working parallel to the shift-
reduce predictor (experiment PP + CP + SR in Ta-
ble 2 (C)). This effect has already been observed
in the experiments that combined the two alone
(experiment PP + SR in Table 2 (A)). When MST
was combined with the PP attacher (experiment
PP in Table 2 (C)), the increase of the performance
was also below a tenth of a percent. The possible
reasons why the use of an additional information
source does not improve the performance in this
case may be the disadvantages of the PP attacher
compared to a full parser.
</bodyText>
<sectionHeader confidence="0.999195" genericHeader="method">
5 Error Analysis
</sectionHeader>
<bodyText confidence="0.9997885">
A very useful property of WCDG is that it not only
can be used as a parser, but also as a diagnostic
tool for dependency structures. Applied to a given
dependency tree, any constraint violation reported
by the constraint solver indicates an inconsistency
between the structure and the WCDG constraint
grammar.
Among the most frequent hard constraint vio-
lations found in the MSTParser results are double
subjects, double objects and direct objects in pas-
sive, projectivity violations, conjunctions without
a clause as well as subordinate clause without con-
junction.
These findings are in line with the analysis of
</bodyText>
<page confidence="0.998745">
103
</page>
<bodyText confidence="0.999875411764706">
McDonald and Nivre (2007). For example, the
errors in distinguishing noun complements of the
verb may be due to the fact that MSTParser is
more precise for longer dependency arcs and has
no access to the parsing history.
In absolute figures, MSTParser commits 1509
attachment errors of which 902 are corrected by
WCDG. On the other hand, WCDG adds another
542 errors of its own, so that the final result still
contains 1149 errors.
For most labels, accuracy of the predictor com-
bination is higher than in each of the parsers
alone. A particularly large gain has been observed
for coordinated elements (KON and CJ), subor-
dinate (NEB) and relative (REL) clauses, indi-
rect accusative objects (OBJA), genitive modifiers
(GMOD) and apposition (APP). Table 3) summa-
rizes the values of structural precision, the ratio of
the number of correct attachment of a given label
to the number of all the predictions for that label
made by the parser, and label recall, the ratio be-
tween the number of correct labeling decisions and
desired labeling.
In this respect, the increase in the structural pre-
cision of the PP attachment seems worth men-
tioning. MSTParser attaches 79.3% of PPs cor-
rectly on the used test set. Although MSTParser
does not use any special PP-attachment resolu-
tion mechanisms, it is comparable with the re-
sult of WCDG combined with the PP attacher that
achieves 78.7% structural precision for PP edges.
If MSTParser is trained on NEGRA exclud-
ing the test set — the rest of NEGRA lacking
consistence mentioned above — it performs even
better, attaching 80.4% of PP-s correctly. Thus,
MSTParser as a statistical parser trained on a full
corpus becomes a strong competitor for a PP at-
tacher that has been trained on restricted four-
tuples input.
As for the errors in the MSTParser output that
are most often corrected in the hybrid experiment,
this happens for both the structural precision and
label recall of most verb complements, such as di-
rect and indirect objects, or clausal objects as well
as for subordinate and relative clauses for such
subordinate clauses.
It even comes to one case in which the synergy
took place in spite of the incorrect predictions. Al-
though MSTParser has predicted possessive modi-
fiers more seldom than WCDG alone (the label re-
call of MSTParser for possessive modification was
</bodyText>
<table confidence="0.999436263157895">
Label p (1) p (2) p (3)
r r r
DET 98.4 99.3 98.7 99.5 99.3 99.5
PN 97.4 97.4 98.0 98.0 98.0 98.7
PP 67.6 98.1 78.3 97.4 80.1 98.5
ADV 76.6 94.7 79.4 95.4 82.2 97.2
SUBJ 94.0 90.9 91.3 86.4 95.8 94.0
ATTR 95.2 95.8 97.7 98.2 98.3 98.4
S 89.2 90.1 89.3 90.5 90.5 91.0
AUX 95.9 94.2 98.6 97.8 98.7 97.6
OBJA 87.9 83.9 83.8 72.5 92.5 88.7
APP 85.1 88.5 88.9 90.9 90.9 94.0
KON 78.9 88.1 78.9 88.3 86.0 89.2
CJ 85.6 86.5 90.9 91.4 93.0 93.5
GMOD 90.7 90.7 89.0 85.3 96.3 95.8
KONJ 88.6 91.9 91.9 95.7 95.1 95.7
PRED 90.3 75.0 85.4 60.4 91.7 76.4
NEB 68.9 82.8 73.0 66.4 79.5 90.2
REL 64.8 77.9 59.0 77.0 68.9 86.9
</table>
<tableCaption confidence="0.99359">
Table 3: Per label structural precision (p,
</tableCaption>
<bodyText confidence="0.99459452">
%) and label recal (r, %) in comparison for
the experiments with the real POS tagger (1)
WCDG, (2) MSTParser, (3) WCDG combined
with MSTParser
over 5% below that of WCDG) its structural pre-
cision and label recall in the combined experiment
are by around 6% greater than WCDG result.
Cases in which WCDG performs worse with
the predictor than its predictor alone can hardly be
found. Still, one may observe many cases in which
the predictor has a negative influence on the per-
formance of WCDG, such as for different kinds of
objects (indirect objects, object clauses and infini-
tive objects) and parenthetic matrix clauses. For
all, the result of MSTParser was below that of
the baseline WCDG with only the POS tagger ac-
tive. Same can be said about the labeled accu-
racy for split verb prefixes and nominal time ex-
pressions. This worsening effect can be attributed
to the lower values of the WCDG constraints for
the corresponding labels and edges than for the
MSTParser predictor. Thus, the search could not
find a decision scoring better than that when the
MSTParser prediction has been followed.
Around 15% of the sentences in the test set are
</bodyText>
<page confidence="0.997875">
104
</page>
<bodyText confidence="0.994908076923077">
not projective. The accuracy of MSTParser on the
projective sentences of the test set is higher than
that on the non-projective sentences by more than
3 percent (Table 4), although these values can-
not be compared directly as the mean length of
non-projective sentences is longer (25.0 vs. 15.3
words).
Table 4: Structural accuracy, (%), for different
parsing runs for non-projective vs. projective sen-
tences.
MSTParser generally tends to find many more
non-projective edges than the data has, while the
precision remains restricted. The number of non-
projective edges was determined by counting how
often an edge crosses some other edge. Thus, if
a non-projective edge crossed three other edges
the number of non-projective edges equals three.
For MSTParser experiments with a real POS tag-
ger (MSTParser POS-experiment in Table 5), the
non-projective edge recall, the ratio of the non-
projective edges found in the experiment to the
corresponding value in the gold standard, is at
23% and non-projective edge precision, the ratio
of the correctly found non-projective edges to all
non-projective edges found, is also only 36% (sec-
ond column in Table 5).
</bodyText>
<table confidence="0.996752666666667">
Experiment Edges Sentences
r p r p
MSTParser (POS) 23 36 35 44
WCDG (POS) 37 53 51 63
WCDG (POS + SR) 41 47 57 55
WCDG (POS + MST) 48 53 61 61
</table>
<tableCaption confidence="0.673813333333333">
Table 5: Recall (r, %) and precision (p, %) of the
non-projective edges and sentences for different
parsing runs.
</tableCaption>
<bodyText confidence="0.999676571428571">
Precision and recall of non-projective sentences
is a less rigid measure. If at least one edge-
crossing is correctly identified in a non-projective
sentence, it is added to the correctly identified
non-projective sentences, even if the identified
edge-crossing is not the one annotated in the gold
standard and the ratios are calculated respectively
(right column of Table 5). Under these relaxed
conditions, MSTParser correctly identifies slightly
less than a half of the non-projective sentences
and over a third of non-projective edges. In fact,
WCDG under the same conditions (WCDG POS-
experiment in Table 5) has a non-projective sen-
tence precision of 63% and a non-projective edge
precision of 53%. Still, WCDG misses a consid-
erable amount of non-projectivities. More impor-
tantly, as the present shift-reduce predictor has not
been designed for non-projective parsing, its in-
clusion reduces the non-projective sentence and
edge precision of WCDG — to 55% and 47% re-
spectively — WCDG (POS+SR) in Table 5.
The expected benefits for the non-projective
sentences have not yet been observed to the full
extent. The precision of the combined system to
find non-projective sentences and edges remained
limited by the performance that WCDG was able
to achieve alone (WCDG (POS+MST) in Table 5).
While MSTParser in many cases predicts non-
projectivity correctly WCDG is seldom capable of
accepting this external evidence. On the contrary,
WCDG often accepts an incorrect projective solu-
tion of the predictor instead of relying on its own
cues. In its interaction with external predictors
WCDG should typically decide about the alterna-
tives.
</bodyText>
<sectionHeader confidence="0.9999" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999892">
So far, approaches to hybrid parsing have been
mainly based on the idea of a post-hoc selec-
tion which can be carried out for either complete
parses, or individual constituents and dependency
edges, respectively. The selection component it-
self can be based on heuristics, like a majority
vote. Alternatively, a second-level classifier is
trained to decide which component to trust under
which conditions and therefore the approach is of-
ten referred to as classifier stacking.
In a series of experiments, Henderson and Brill
(1999) combined three constituency-based parsers
by a selection mechanism for either complete pars-
ing results (parser switching) or individual con-
stituents (parse hybridization), using both a heuris-
tic decision rule as well as a naive Bayesian clas-
sifier in each case. Among the heuristics consid-
ered were majority votes for constituents and a
</bodyText>
<table confidence="0.9434022">
Experiment Non-proj. Proj.
MSTParser (POS) 88.2 91.7
WCDG (POS) 87.2 90.2
WCDG (POS + SR) 88.7 92.2
WCDG (POS + MST) 91.3 93.6
</table>
<page confidence="0.997362">
105
</page>
<bodyText confidence="0.9999795">
similarity-based measure for complete trees. Tests
on Penn Treebank data showed a clear improve-
ment of the combined results over the best individ-
ual parser. Constituent selection outperformed the
complete parse selection scheme, and Bayesian se-
lection was slightly superior.
Instead of coupling different data-driven parsers
which all provide comparable analyses for com-
plete sentences, Rupp et al. (2000) combined dif-
ferently elaborated structural descriptions (namely
chunks and phrase structure trees) obtained by
data-driven components with the output of a
HPSG-parser. Driven by the requirements of the
particular application (speech-to-speech transla-
tion), the focus was not only on parse selection,
but also on combining incomplete results. How-
ever, no quantitative evaluation of the results has
been published.
Zeman and ˇZabokrtsk´y (2005) applied the se-
lection idea to dependency structures and extended
it by using more context features. They com-
bined seven different parsers for Czech, among
them also a system based on a manually com-
piled rule set. Some of the individual parsers had
a fairly poor performance, but even a simple vot-
ing scheme on single edges contributed a signifi-
cant improvement while the best results have been
obtained for a combination that did not include
the worst components. Alternatively the authors
experimented with a trained selection component
which not only had access to the alternative local
parsing results, but also to their structural context.
Neither a memory-based approach nor a model
based on decision trees did result in further gains.
In two separate experiments, Sagae and Lavie
(2006) combined a number of dependency and
constituent parsers, respectively. They created a
new weighted search space from the results of
the individual component parsers using different
weighting schemes for the candidates. They then
reparsed this search space and found a consistent
improvement for the dependency structures, but
not for the constituent-based ones.
While all these approaches attempt to integrate
the available evidence at parse time, Nivre and
McDonald (2008) pursued an alternative architec-
ture, where integration is achieved already at train-
ing time. They combined the two state-of-the-
art data-driven dependency parsers, MaltParser
(Nivre et al., 2006) and MSTParser (McDonald et
al., 2006), by integrating the features of each of the
classifiers into the parsing model of the other one
at training time. Since the two parsers are based
on quite different model types (namely a history-
based vs. a structure-based one), they exhibit a
remarkable complementary behavior (McDonald
and Nivre, 2007). Accordingly, significant mutual
benefits have been observed. Note, however, that
one of the major benefits of MaltParser, its incre-
mental left-to-right processing, is sacrificed under
such a combination scheme.
Martins et al. (2008) use stacked learning to
overcome the restriction to the single-edge fea-
tures in both MaltParser and MSTParser. They
suggest an architecture with two layers, where the
output of a standard parser in the first level pro-
vides new features for a parser in the subsequent
level. During the training phase, the second parser
learns to correct mistakes made by the first one. It
allows to involve higher-order predicted edges to
simulate non-local features in the second parser.
The results are competitive with McDonald and
Nivre (2007) while O(n2) runtime of the spanning
tree algorithm is preserved.
</bodyText>
<sectionHeader confidence="0.998376" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999796538461538">
Integrating MSTParser as a full predictor with
WCDG is beneficial for both of them. Since these
systems take their decisions based on completely
different sources of knowledge, combining both
helps avoid many mistakes each of them commits
in isolation. Altogether, with a real POS tagger, an
accuracy level of 92.9%/91.3% has been reached
(the last row in Table 2 (C)), which is higher than
what any of the parsers achieved alone. With POS
tagging from the gold standard, the accuracy has
been at 93.3%/92.0% (the last row in Table 1). To
the knowledge of the authors, these accuracy val-
ues are also better than any previous parsing re-
sults on the NEGRA test set.
WCDG can profit from the combination not
only with ancillary predictors for specific parsing
subtasks, but also with another full parser. This
result was achieved even though the second parser
is very similar to WCDG with respect to both the
richness and the accuracy of its target structures.
The probable reason lies in the considerable dif-
ference in the error profiles of both systems as re-
gards specific linguistic phenomena. WCDG was
also used as a diagnostic tool for the errors of
MSTParser.
Possibly, a higher degree of synergy could be
</bodyText>
<page confidence="0.994178">
106
</page>
<bodyText confidence="0.999879269230769">
achieved if a stronger coupling of the compo-
nents were established by also using the scores of
MSTParser as additional information for WCDG,
reflecting the intuitive notion of preference or
plausibility of the predictions. This could be done
for the optimal parse tree alone as well as for the
complete hypothesis space. Alternatively, the out-
put of MSTParser can be used as a initial state
for the transformation procedure of WCDG. Vice
versa, MSTParser could be enriched with addi-
tional features based on the output of WCDG, sim-
ilar to the feature-based integration of data-driven
parsers evaluated by Nivre and McDonald (2008).
At the moment, the integration constraints treats
all attachment and label predictions as being uni-
formly reliable. To individualize them with re-
spect to their type or origin could not only make
the system sensitive to qualitative differences be-
tween predictions (for instance, with respect to
different labels). It would also allow the parser
to accommodate multiple oracle predictors and to
carefully distinguish between typical configura-
tions in which one prediction should be preferred
over an alternative one. MaltParser (Nivre et al.,
2006) is certainly a good candidate for carrying
out such experiments.
</bodyText>
<sectionHeader confidence="0.999075" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999912253333334">
Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolf-
gang Lezius, and George Smith. 2002. The TIGER
treebank. In: Proceedings of the First Workshop on
Treebanks and Linguistic Theories (TLT), pages 24–
41.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proc. CoNLL, pages 149 – 164.
Kilian A. Foth and Wolfgang Menzel. 2006. Hybrid
parsing: using probabilistic models as predictors for
a symbolic parser. In Proc. 21st Int. Conference on
Computational Linguistics and ACL-44, pages 321–
328.
Kilian A. Foth, Wolfgang Menzel, and Ingo Schr¨oder.
2000. A Transformation-based Parsing Technique
with Anytime Properties. In 4th Int. Workshop on
Parsing Technologies, IWPT-2000, pages 89 – 100.
Kilian A. Foth. 2006. Hybrid Methods of Natural Lan-
guage Analysis. Doctoral thesis, Hamburg Univer-
sity.
John C. Henderson and Eric Brill. 1999. Exploiting
diversity in natural language processing: Combining
parsers. In Proceedings 4th Conference on Empiri-
cal Methods in Natural Language Processing, pages
187–194.
Andr´e F. T. Martins, Dipanjan Das, Noah A. Smith, and
Eric P. Xing. 2008. Stacking Dependency Parsers.
In Proc. of the 2008 Conf. on Empirical Methods in
Natural Language Processing, pages 157 – 166.
Hiroshi Maruyama. 1990. Structural disambiguation
with constraint propagation. In Proc. 28th Annual
Meeting of the ACL (ACL-90), pages 31–38.
Ryan McDonald and Joakim Nivre. 2007. Character-
izing the errors of data-driven dependency parsing
models. In Proc. EMNLP-CoNLL, pages 122 – 131.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Haji˘c. 2005. Non-projective dependency
parsing using spanning tree algorithms. In Proc.
HLT/EMNLP, pages 523 – 530.
Ryan McDonald, Kevin Lerman, and Fernando Pereira.
2006. Multilingual dependency analysis with a two-
stage discriminative parser. In Proc. CoNLL, pages
216 – 220.
Ryan McDonald. 2006. Discriminative Learning and
Spanning Tree Algorithms for Dependency Parsing.
PhD dissertation, University of Pennsylvania.
Joakim Nivre and Ryan McDonald. 2008. Integrat-
ing graph-based and transition-based dependency
parsers. In Proc. ACL-08: HLT, pages 950–958.
Joakim Nivre, Johan Hall, Jens Nilsson, G¨ulsen
Eryiˇgit, and Svetoslav Marinov. 2006. Labelled
pseudo-projective dependency parsing with support
vector machines. In Proc. CoNLL-2006, pages 221–
225.
Christopher G. Rupp, J¨org Spilker, Martin Klarner, and
Karsten L. Worm. 2000. Combining analyses from
various parsers. In Wolfgang Wahlster, editor, Verb-
mobil: Foundations of Speech-to-Speech Transla-
tion, pages 311–320. Springer-Verlag, Berlin etc.
Kenji Sagae and Alon Lavie. 2006. Parser combi-
nations by reparsing. In Proc. HLT/NAACL, pages
129–132.
Ingo Schr¨oder. 2002. Natural Language Parsing with
Graded Constraints. Ph.D. thesis, Dept. of Com-
puter Science, University of Hamburg, Germany.
Ingo Schr¨oder, Horia F. Pop, Wolfgang Menzel, and
Kilian A. Foth. 2001. Learning grammar weights
using genetic algorithms. In Proc. Euroconference
Recent Advances in Natural Language Processing,
pages 235 – 239.
Daniel Zeman and Zdenˇek ˇZabokrtsk´y. 2005. Improv-
ing parsing accuracy by combining diverse depen-
dency parsers. In Proc. 9th International Workshop
on Parsing Technologies (IWPT-2005), pages 171–
178, Vancouver, B.C.
</reference>
<page confidence="0.998701">
107
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.751122">
<title confidence="0.997221">Co-Parsing with Competitive Models</title>
<author confidence="0.999935">Lidia Khmylko Kilian A Foth</author>
<affiliation confidence="0.936987">Natural Language Systems Group smartSpeed GmbH &amp; Co. KG University of Hamburg, Germany Hamburg, Germany</affiliation>
<email confidence="0.995189">khmylko@informatik.uni-hamburg.dekilian.foth@smartspeed.com</email>
<author confidence="0.921533">Wolfgang Menzel</author>
<affiliation confidence="0.947325">Natural Language Systems University of Hamburg, Germany</affiliation>
<email confidence="0.998146">menzel@informatik.uni-hamburg.de</email>
<abstract confidence="0.998097444444444">We present an asymmetric approach to a run-time combination of two parsers where one component serves as a predictor to the other one. Predictions are integrated by means of weighted constraints and therefore are subject to preferential decisions. Previously, the same architecture has been successfully used with predictors providing partial or inferior information about the parsing problem. It has now been applied to a situation where the predictor produces exactly the same type of information at a fully competitive quality level. Results show that the combined system outperforms its individual components, even though their performance in isolation is already fairly high.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sabine Brants</author>
<author>Stefanie Dipper</author>
<author>Silvia Hansen</author>
<author>Wolfgang Lezius</author>
<author>George Smith</author>
</authors>
<title>The TIGER treebank. In:</title>
<date>2002</date>
<booktitle>Proceedings of the First Workshop on Treebanks and Linguistic Theories (TLT),</booktitle>
<pages>24--41</pages>
<contexts>
<context position="15693" citStr="Brants et al., 2002" startWordPosition="2466" endWordPosition="2469"> cases where it helps to decrease ambiguity. Furthermore, corrections were applied when the annotations of NEGRA itself turned out to be inconsistent (usually in connection with co-ordinated or elliptical structures, adverbs and subclauses). Unfortunately, these manually corrected data were only available for a small part (3, 000 sentences) of the NEGRA corpus, which is not sufficient for training MSTParser on WCDGconforming tree structures. Previous evaluations of the MSTParser have used much larger training sets. E.g., during the CoNLL-X shared task 39,216 sentences from the TIGER Treebank (Brants et al., 2002) were used. Therefore, we used 20, 000 sentences from the online archive of www.heise.de as an alternative training set. They have been manually annotated according to the WCDG guidelines (and are referred to heiseticker in the following)3. The texts in this corpus are all from roughly the same domain as in NEGRA, and although very many technical terms and proper nouns are used, the sentences have only a slightly longer mean length compared to the NEGRA corpus. Using POS tags from the gold annotations, MSTParser achieves 90.5% structural and 87.5% labeled accuracy on the aforementioned NEGRA t</context>
</contexts>
<marker>Brants, Dipper, Hansen, Lezius, Smith, 2002</marker>
<rawString>Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang Lezius, and George Smith. 2002. The TIGER treebank. In: Proceedings of the First Workshop on Treebanks and Linguistic Theories (TLT), pages 24– 41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proc. CoNLL,</booktitle>
<pages>149--164</pages>
<contexts>
<context position="14176" citStr="Buchholz and Marsi, 2006" startWordPosition="2227" endWordPosition="2230"> the correctly attached words which also have the correct label. Still, it is difficult to directly compare the results reported for different parsers, as the evaluation results are influenced by the data used during the experiment, the domain of the data, and different annotation guidelines. Moreover, the particular kind of POS information might be relevant, which either can be obtained from the manual annotations or be provided by a real tagger. Even such a condition as the treatment of punctuation has not yet become a standard. Following the evaluation procedure in the CoNLL-X shared task (Buchholz and Marsi, 2006), we will not include punctuation into the performance measures, as was done in previous WCDG experiments (Foth and Menzel, 2006). The source of POS tagging information will need to be specified in each individual case. All the evaluations were performed on a thousand sentences (18,602 – 19,601) from the NEGRA treebank, the same data set that was previously used in the performance evaluations of WCDG, e.g. in (Foth, 2006). The NEGRA treebank is a collection of newspaper articles; in the original, it stores phrase structure annotations. These have been automatically translated into dependency t</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proc. CoNLL, pages 149 – 164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kilian A Foth</author>
<author>Wolfgang Menzel</author>
</authors>
<title>Hybrid parsing: using probabilistic models as predictors for a symbolic parser.</title>
<date>2006</date>
<booktitle>In Proc. 21st Int. Conference on Computational Linguistics and ACL-44,</booktitle>
<pages>321--328</pages>
<contexts>
<context position="1810" citStr="Foth and Menzel (2006)" startWordPosition="260" endWordPosition="263">c knowledge from human experts are usually considered as two alternative roadmaps towards natural language processing solutions. Since the resulting components exhibit quite different performance characteristics with respect to coverage, robustness and output quality, they might be able to provide some kind of complementary information, which could even lead to a notable degree of synergy between them when combined within a single system solution. For the task of dependency parsing, the high potential for such a synergy has indeed been demonstrated already (e.g. Zeman and ˇZabokrtsk´y (2005), Foth and Menzel (2006)). A popular approach for combining alternative decision procedures is voting (Zeman and ˇZabokrtsk´y, 2005). It makes use of a symmetric architecture, where a meta component chooses from among the available candidate hypotheses by means of a (weighted) voting scheme. Such an approach not only requires the target structures of all components to be of the same kind, but in case of complex structures like parse trees also requires sophisticated decision procedures which are able to select the optimal hypotheses with respect to additional global constraints (e.g. the tree property). Since this op</context>
<context position="8685" citStr="Foth and Menzel (2006)" startWordPosition="1332" endWordPosition="1335"> at any time. Even if interrupted, it will always return an analysis, together with a list of constraint violations it was not able to remove. The algorithm terminates on its own if no violated constraints with a weight above a predefined threshold remain. Alternatively, a timeout condition can be imposed. The same kind of constraints that describe grammar rules, can also be used as an interface 100 to external predictor components. Thus, the formalism turned out to be flexible enough to incorporate other sources of knowledge into the decision process on the optimal structural interpretation. Foth and Menzel (2006) have reported about five additional statistical components that have been successfully integrated into WCDG: POS tagger, chunker, supertagger, PP attacher and a shift-reduce oracle parser. They have also shown that the accuracy improves if multiple components interact and consistent predictions no longer can be guaranteed. Even thought previously integrated predictor components have an accuracy that is mostly — with the exception of the tagger — below that of the parser itself, WCDG not only avoids error propagation successfully, it also improves its results consistently with each component a</context>
<context position="14305" citStr="Foth and Menzel, 2006" startWordPosition="2248" endWordPosition="2251"> different parsers, as the evaluation results are influenced by the data used during the experiment, the domain of the data, and different annotation guidelines. Moreover, the particular kind of POS information might be relevant, which either can be obtained from the manual annotations or be provided by a real tagger. Even such a condition as the treatment of punctuation has not yet become a standard. Following the evaluation procedure in the CoNLL-X shared task (Buchholz and Marsi, 2006), we will not include punctuation into the performance measures, as was done in previous WCDG experiments (Foth and Menzel, 2006). The source of POS tagging information will need to be specified in each individual case. All the evaluations were performed on a thousand sentences (18,602 – 19,601) from the NEGRA treebank, the same data set that was previously used in the performance evaluations of WCDG, e.g. in (Foth, 2006). The NEGRA treebank is a collection of newspaper articles; in the original, it stores phrase structure annotations. These have been automatically translated into dependency trees and then manually corrected to bring them in accord with the annotation guidelines of WCDG. The major difference consists in</context>
</contexts>
<marker>Foth, Menzel, 2006</marker>
<rawString>Kilian A. Foth and Wolfgang Menzel. 2006. Hybrid parsing: using probabilistic models as predictors for a symbolic parser. In Proc. 21st Int. Conference on Computational Linguistics and ACL-44, pages 321– 328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kilian A Foth</author>
<author>Wolfgang Menzel</author>
<author>Ingo Schr¨oder</author>
</authors>
<title>A Transformation-based Parsing Technique with Anytime Properties.</title>
<date>2000</date>
<booktitle>In 4th Int. Workshop on Parsing Technologies, IWPT-2000,</booktitle>
<pages>89--100</pages>
<marker>Foth, Menzel, Schr¨oder, 2000</marker>
<rawString>Kilian A. Foth, Wolfgang Menzel, and Ingo Schr¨oder. 2000. A Transformation-based Parsing Technique with Anytime Properties. In 4th Int. Workshop on Parsing Technologies, IWPT-2000, pages 89 – 100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kilian A Foth</author>
</authors>
<title>Hybrid Methods of Natural Language Analysis. Doctoral thesis,</title>
<date>2006</date>
<institution>Hamburg University.</institution>
<contexts>
<context position="2941" citStr="Foth, 2006" startWordPosition="436" endWordPosition="437">respect to additional global constraints (e.g. the tree property). Since this optimization problem has to be solved by the individual parser anyhow, an asymmetric architecture suggests itself as an alternative. In asymmetric architectures, a master component, i.e. a full fledged parser, is solely in charge of deciding on the target structure, whilst the others (so called helper or predictor components) provide additional evidence which is integrated into the global decision by suitable means. Such a scheme has been extensively investigated for the Weighted Constraint Dependency Grammar, WCDG (Foth, 2006). External evidence from the predictor components is integrated by means of constraints, which check for compatibility between a local structure and a prediction, and penalize this hypothesis in case of a conflict. So far, however, all the additional information sources which have been considered in this research differed considerably from the master component: They either focused on particular aspects of the parsing problem (e.g. POS tagging, chunking, PP attachment), or used a simplified scheme for structural annotation (e.g. projective instead of non-projective trees). This paper takes one </context>
<context position="12673" citStr="Foth, 2006" startWordPosition="1986" endWordPosition="1987">s of WCDG, a low weight strongly deprecates all deviations from the prediction, thus forcing the system to follow them almost without exception. Higher weights, on the other hand, enable the grammar to override a prediction. This, however, also means that predictions have less guiding effect of the transformation process. Typically for WCDG, the best suitable weights have to be tuned on development data. To determine the best constraint weights the WCDG grammar has been extended with three additional constraints similar to those used for the shift-reduce predictor in the previous experiments (Foth, 2006). Two of them advise WCDG on the structural information available from the MSTParser result and one fetches the edge label predicted. As a result of these experiments, the optimum 2MSTParser is freely available from http:// sourceforge.net/projects/mstparser 101 weight for the attachment predictions has been adjusted to 0.75. Compared to a weight of 0.9 for the shift-reduce parser, this is a rather strong influence, which also reflects the differences in the reliability of these two information sources. With a weight of 0.9, the integration of the label predictions is considerably weaker, whic</context>
<context position="14601" citStr="Foth, 2006" startWordPosition="2301" endWordPosition="2302">real tagger. Even such a condition as the treatment of punctuation has not yet become a standard. Following the evaluation procedure in the CoNLL-X shared task (Buchholz and Marsi, 2006), we will not include punctuation into the performance measures, as was done in previous WCDG experiments (Foth and Menzel, 2006). The source of POS tagging information will need to be specified in each individual case. All the evaluations were performed on a thousand sentences (18,602 – 19,601) from the NEGRA treebank, the same data set that was previously used in the performance evaluations of WCDG, e.g. in (Foth, 2006). The NEGRA treebank is a collection of newspaper articles; in the original, it stores phrase structure annotations. These have been automatically translated into dependency trees and then manually corrected to bring them in accord with the annotation guidelines of WCDG. The major difference consists in a different treatment of non-projectivity, where WCDG only allows non-projectivity in the attachment of verbal arguments, relative clauses and coordinations, i.e., the cases where it helps to decrease ambiguity. Furthermore, corrections were applied when the annotations of NEGRA itself turned o</context>
</contexts>
<marker>Foth, 2006</marker>
<rawString>Kilian A. Foth. 2006. Hybrid Methods of Natural Language Analysis. Doctoral thesis, Hamburg University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C Henderson</author>
<author>Eric Brill</author>
</authors>
<title>Exploiting diversity in natural language processing: Combining parsers.</title>
<date>1999</date>
<booktitle>In Proceedings 4th Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>187--194</pages>
<contexts>
<context position="28531" citStr="Henderson and Brill (1999)" startWordPosition="4620" endWordPosition="4623">ion with external predictors WCDG should typically decide about the alternatives. 6 Related Work So far, approaches to hybrid parsing have been mainly based on the idea of a post-hoc selection which can be carried out for either complete parses, or individual constituents and dependency edges, respectively. The selection component itself can be based on heuristics, like a majority vote. Alternatively, a second-level classifier is trained to decide which component to trust under which conditions and therefore the approach is often referred to as classifier stacking. In a series of experiments, Henderson and Brill (1999) combined three constituency-based parsers by a selection mechanism for either complete parsing results (parser switching) or individual constituents (parse hybridization), using both a heuristic decision rule as well as a naive Bayesian classifier in each case. Among the heuristics considered were majority votes for constituents and a Experiment Non-proj. Proj. MSTParser (POS) 88.2 91.7 WCDG (POS) 87.2 90.2 WCDG (POS + SR) 88.7 92.2 WCDG (POS + MST) 91.3 93.6 105 similarity-based measure for complete trees. Tests on Penn Treebank data showed a clear improvement of the combined results over th</context>
</contexts>
<marker>Henderson, Brill, 1999</marker>
<rawString>John C. Henderson and Eric Brill. 1999. Exploiting diversity in natural language processing: Combining parsers. In Proceedings 4th Conference on Empirical Methods in Natural Language Processing, pages 187–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e F T Martins</author>
<author>Dipanjan Das</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>Stacking Dependency Parsers.</title>
<date>2008</date>
<booktitle>In Proc. of the 2008 Conf. on Empirical Methods in Natural Language Processing,</booktitle>
<pages>157--166</pages>
<contexts>
<context position="31886" citStr="Martins et al. (2008)" startWordPosition="5131" endWordPosition="5134">ency parsers, MaltParser (Nivre et al., 2006) and MSTParser (McDonald et al., 2006), by integrating the features of each of the classifiers into the parsing model of the other one at training time. Since the two parsers are based on quite different model types (namely a historybased vs. a structure-based one), they exhibit a remarkable complementary behavior (McDonald and Nivre, 2007). Accordingly, significant mutual benefits have been observed. Note, however, that one of the major benefits of MaltParser, its incremental left-to-right processing, is sacrificed under such a combination scheme. Martins et al. (2008) use stacked learning to overcome the restriction to the single-edge features in both MaltParser and MSTParser. They suggest an architecture with two layers, where the output of a standard parser in the first level provides new features for a parser in the subsequent level. During the training phase, the second parser learns to correct mistakes made by the first one. It allows to involve higher-order predicted edges to simulate non-local features in the second parser. The results are competitive with McDonald and Nivre (2007) while O(n2) runtime of the spanning tree algorithm is preserved. 7 C</context>
</contexts>
<marker>Martins, Das, Smith, Xing, 2008</marker>
<rawString>Andr´e F. T. Martins, Dipanjan Das, Noah A. Smith, and Eric P. Xing. 2008. Stacking Dependency Parsers. In Proc. of the 2008 Conf. on Empirical Methods in Natural Language Processing, pages 157 – 166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Maruyama</author>
</authors>
<title>Structural disambiguation with constraint propagation.</title>
<date>1990</date>
<booktitle>In Proc. 28th Annual Meeting of the ACL (ACL-90),</booktitle>
<pages>31--38</pages>
<contexts>
<context position="4912" citStr="Maruyama (1990)" startWordPosition="737" endWordPosition="738">h a special emphasis on the soft integration of external evidence while section three describes MSTParser which is used as a new predictor component. Since parsing results for these systems have been reported in quite different experimental settings we first evaluate them under comparable conditions and provide the results of using MSTParser as a guiding predictor for WCDG in section four and discuss whether the expected synergies have really materialized. Section five concentrates on a comparative error analysis. 2 WCDG The formalism of a Constraint Dependency Grammar was first introduced by Maruyama (1990) and suggests modeling natural language with the help of constraints. Schr¨oder (2002) has extended the approach to Weighted Constraint Dependency Grammar, WCDG, where weights are used to further disambiguate between competing structural alternatives. A WCDG models natural language as labeled dependency trees and is entirely declarative. It has no derivation rules — instead, constraints license well-formed tree structures. The reference implementation of WCDG for the German language used for the experiments described below contains about 1, 000 manually compiled constraints.1 Every constraint </context>
</contexts>
<marker>Maruyama, 1990</marker>
<rawString>Hiroshi Maruyama. 1990. Structural disambiguation with constraint propagation. In Proc. 28th Annual Meeting of the ACL (ACL-90), pages 31–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Characterizing the errors of data-driven dependency parsing models.</title>
<date>2007</date>
<booktitle>In Proc. EMNLP-CoNLL,</booktitle>
<pages>122--131</pages>
<contexts>
<context position="20856" citStr="McDonald and Nivre (2007)" startWordPosition="3318" endWordPosition="3321">perty of WCDG is that it not only can be used as a parser, but also as a diagnostic tool for dependency structures. Applied to a given dependency tree, any constraint violation reported by the constraint solver indicates an inconsistency between the structure and the WCDG constraint grammar. Among the most frequent hard constraint violations found in the MSTParser results are double subjects, double objects and direct objects in passive, projectivity violations, conjunctions without a clause as well as subordinate clause without conjunction. These findings are in line with the analysis of 103 McDonald and Nivre (2007). For example, the errors in distinguishing noun complements of the verb may be due to the fact that MSTParser is more precise for longer dependency arcs and has no access to the parsing history. In absolute figures, MSTParser commits 1509 attachment errors of which 902 are corrected by WCDG. On the other hand, WCDG adds another 542 errors of its own, so that the final result still contains 1149 errors. For most labels, accuracy of the predictor combination is higher than in each of the parsers alone. A particularly large gain has been observed for coordinated elements (KON and CJ), subordinat</context>
<context position="31652" citStr="McDonald and Nivre, 2007" startWordPosition="5098" endWordPosition="5101">hes attempt to integrate the available evidence at parse time, Nivre and McDonald (2008) pursued an alternative architecture, where integration is achieved already at training time. They combined the two state-of-theart data-driven dependency parsers, MaltParser (Nivre et al., 2006) and MSTParser (McDonald et al., 2006), by integrating the features of each of the classifiers into the parsing model of the other one at training time. Since the two parsers are based on quite different model types (namely a historybased vs. a structure-based one), they exhibit a remarkable complementary behavior (McDonald and Nivre, 2007). Accordingly, significant mutual benefits have been observed. Note, however, that one of the major benefits of MaltParser, its incremental left-to-right processing, is sacrificed under such a combination scheme. Martins et al. (2008) use stacked learning to overcome the restriction to the single-edge features in both MaltParser and MSTParser. They suggest an architecture with two layers, where the output of a standard parser in the first level provides new features for a parser in the subsequent level. During the training phase, the second parser learns to correct mistakes made by the first o</context>
</contexts>
<marker>McDonald, Nivre, 2007</marker>
<rawString>Ryan McDonald and Joakim Nivre. 2007. Characterizing the errors of data-driven dependency parsing models. In Proc. EMNLP-CoNLL, pages 122 – 131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Haji˘c</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proc. HLT/EMNLP,</booktitle>
<pages>523--530</pages>
<marker>McDonald, Pereira, Ribarov, Haji˘c, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Haji˘c. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proc. HLT/EMNLP, pages 523 – 530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Kevin Lerman</author>
<author>Fernando Pereira</author>
</authors>
<title>Multilingual dependency analysis with a twostage discriminative parser.</title>
<date>2006</date>
<booktitle>In Proc. CoNLL,</booktitle>
<pages>216--220</pages>
<contexts>
<context position="10687" citStr="McDonald et al., 2006" startWordPosition="1652" endWordPosition="1655">tence, and the correct parse can be obtained by searching the space of valid dependency graphs for a tree with a maximum score. This formalism allows to find efficient solutions for both projective and non-projective trees. When only features over single edges are taken into account, the complexity falls to O(n2) (McDonald et al., 2005). Not only a single edge, but also adjacent edges may be included into the scoring function. As a result, intractability problems arise for the nonprojective algorithm, but an efficient approximate algorithm based on exhaustive search is provided for this case (McDonald et al., 2006). This algorithm was also used for our experiments.2 The parsing model of MSTParser has the advantage that it can be trained globally and eventually be applied with an exact inference algorithm. On the other hand, the parser has only limited access to the history of parsing decisions. To avoid complexity problems, the scores (and the feature representations) are restricted to a single edge or adjacent edges. Outsourcing labeling into a separate stage comes at the price of not being able to combine knowledge about the label and the structure it is attached to. Such combined evidence, however, m</context>
<context position="31348" citStr="McDonald et al., 2006" startWordPosition="5049" endWordPosition="5052">a new weighted search space from the results of the individual component parsers using different weighting schemes for the candidates. They then reparsed this search space and found a consistent improvement for the dependency structures, but not for the constituent-based ones. While all these approaches attempt to integrate the available evidence at parse time, Nivre and McDonald (2008) pursued an alternative architecture, where integration is achieved already at training time. They combined the two state-of-theart data-driven dependency parsers, MaltParser (Nivre et al., 2006) and MSTParser (McDonald et al., 2006), by integrating the features of each of the classifiers into the parsing model of the other one at training time. Since the two parsers are based on quite different model types (namely a historybased vs. a structure-based one), they exhibit a remarkable complementary behavior (McDonald and Nivre, 2007). Accordingly, significant mutual benefits have been observed. Note, however, that one of the major benefits of MaltParser, its incremental left-to-right processing, is sacrificed under such a combination scheme. Martins et al. (2008) use stacked learning to overcome the restriction to the singl</context>
</contexts>
<marker>McDonald, Lerman, Pereira, 2006</marker>
<rawString>Ryan McDonald, Kevin Lerman, and Fernando Pereira. 2006. Multilingual dependency analysis with a twostage discriminative parser. In Proc. CoNLL, pages 216 – 220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
</authors>
<title>Discriminative Learning and Spanning Tree Algorithms for Dependency Parsing.</title>
<date>2006</date>
<institution>University of Pennsylvania.</institution>
<note>PhD dissertation,</note>
<contexts>
<context position="4015" citStr="McDonald, 2006" startWordPosition="599" endWordPosition="601">P attachment), or used a simplified scheme for structural annotation (e.g. projective instead of non-projective trees). This paper takes one step further by investigating the same architecture under the additional condition that (1) the helper component provides the 99 Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 99–107, Paris, October 2009. c�2009 Association for Computational Linguistics very same kind of target structure as the master, and (2) the quality levels of each of the components in isolation are considered. As a helper component MSTParser (McDonald, 2006), a state-of-the-art dependency parser for non-projective structures based on a discriminative learning paradigm, is considered. The accuracy of MSTParser differs insignificatly from that of WCDG with all the previously used helper components active. Section two introduces WCDG with a special emphasis on the soft integration of external evidence while section three describes MSTParser which is used as a new predictor component. Since parsing results for these systems have been reported in quite different experimental settings we first evaluate them under comparable conditions and provide the r</context>
<context position="9329" citStr="McDonald, 2006" startWordPosition="1431" endWordPosition="1432">itional statistical components that have been successfully integrated into WCDG: POS tagger, chunker, supertagger, PP attacher and a shift-reduce oracle parser. They have also shown that the accuracy improves if multiple components interact and consistent predictions no longer can be guaranteed. Even thought previously integrated predictor components have an accuracy that is mostly — with the exception of the tagger — below that of the parser itself, WCDG not only avoids error propagation successfully, it also improves its results consistently with each component added. 3 MSTParser MSTParser (McDonald, 2006) is a state-of-the-art language independent data-driven parser. It processes the input in two separate stages. In the first, the dependency structure is determined, labeling is applied to it successively in the second. The reasons of its efficiency lie in the successful combination of discriminative learning with graph-based solution methods for the parsing problem. In this edge-factored graph-based model, each edge of the dependency graph is assigned a realvalued score by its linear model. The score of the graph is defined as the sum of its edge scores. If a scoring function for edges is know</context>
</contexts>
<marker>McDonald, 2006</marker>
<rawString>Ryan McDonald. 2006. Discriminative Learning and Spanning Tree Algorithms for Dependency Parsing. PhD dissertation, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Ryan McDonald</author>
</authors>
<title>Integrating graph-based and transition-based dependency parsers.</title>
<date>2008</date>
<booktitle>In Proc. ACL-08: HLT,</booktitle>
<pages>950--958</pages>
<contexts>
<context position="31115" citStr="Nivre and McDonald (2008)" startWordPosition="5015" endWordPosition="5018">t. Neither a memory-based approach nor a model based on decision trees did result in further gains. In two separate experiments, Sagae and Lavie (2006) combined a number of dependency and constituent parsers, respectively. They created a new weighted search space from the results of the individual component parsers using different weighting schemes for the candidates. They then reparsed this search space and found a consistent improvement for the dependency structures, but not for the constituent-based ones. While all these approaches attempt to integrate the available evidence at parse time, Nivre and McDonald (2008) pursued an alternative architecture, where integration is achieved already at training time. They combined the two state-of-theart data-driven dependency parsers, MaltParser (Nivre et al., 2006) and MSTParser (McDonald et al., 2006), by integrating the features of each of the classifiers into the parsing model of the other one at training time. Since the two parsers are based on quite different model types (namely a historybased vs. a structure-based one), they exhibit a remarkable complementary behavior (McDonald and Nivre, 2007). Accordingly, significant mutual benefits have been observed. </context>
<context position="34338" citStr="Nivre and McDonald (2008)" startWordPosition="5537" endWordPosition="5540">eved if a stronger coupling of the components were established by also using the scores of MSTParser as additional information for WCDG, reflecting the intuitive notion of preference or plausibility of the predictions. This could be done for the optimal parse tree alone as well as for the complete hypothesis space. Alternatively, the output of MSTParser can be used as a initial state for the transformation procedure of WCDG. Vice versa, MSTParser could be enriched with additional features based on the output of WCDG, similar to the feature-based integration of data-driven parsers evaluated by Nivre and McDonald (2008). At the moment, the integration constraints treats all attachment and label predictions as being uniformly reliable. To individualize them with respect to their type or origin could not only make the system sensitive to qualitative differences between predictions (for instance, with respect to different labels). It would also allow the parser to accommodate multiple oracle predictors and to carefully distinguish between typical configurations in which one prediction should be preferred over an alternative one. MaltParser (Nivre et al., 2006) is certainly a good candidate for carrying out such</context>
</contexts>
<marker>Nivre, McDonald, 2008</marker>
<rawString>Joakim Nivre and Ryan McDonald. 2008. Integrating graph-based and transition-based dependency parsers. In Proc. ACL-08: HLT, pages 950–958.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
<author>G¨ulsen Eryiˇgit</author>
<author>Svetoslav Marinov</author>
</authors>
<title>Labelled pseudo-projective dependency parsing with support vector machines.</title>
<date>2006</date>
<booktitle>In Proc. CoNLL-2006,</booktitle>
<pages>221--225</pages>
<marker>Nivre, Hall, Nilsson, Eryiˇgit, Marinov, 2006</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, G¨ulsen Eryiˇgit, and Svetoslav Marinov. 2006. Labelled pseudo-projective dependency parsing with support vector machines. In Proc. CoNLL-2006, pages 221– 225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher G Rupp</author>
<author>J¨org Spilker</author>
<author>Martin Klarner</author>
<author>Karsten L Worm</author>
</authors>
<title>Combining analyses from various parsers.</title>
<date>2000</date>
<booktitle>Verbmobil: Foundations of Speech-to-Speech Translation,</booktitle>
<pages>311--320</pages>
<editor>In Wolfgang Wahlster, editor,</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin etc.</location>
<contexts>
<context position="29405" citStr="Rupp et al. (2000)" startWordPosition="4755" endWordPosition="4758"> case. Among the heuristics considered were majority votes for constituents and a Experiment Non-proj. Proj. MSTParser (POS) 88.2 91.7 WCDG (POS) 87.2 90.2 WCDG (POS + SR) 88.7 92.2 WCDG (POS + MST) 91.3 93.6 105 similarity-based measure for complete trees. Tests on Penn Treebank data showed a clear improvement of the combined results over the best individual parser. Constituent selection outperformed the complete parse selection scheme, and Bayesian selection was slightly superior. Instead of coupling different data-driven parsers which all provide comparable analyses for complete sentences, Rupp et al. (2000) combined differently elaborated structural descriptions (namely chunks and phrase structure trees) obtained by data-driven components with the output of a HPSG-parser. Driven by the requirements of the particular application (speech-to-speech translation), the focus was not only on parse selection, but also on combining incomplete results. However, no quantitative evaluation of the results has been published. Zeman and ˇZabokrtsk´y (2005) applied the selection idea to dependency structures and extended it by using more context features. They combined seven different parsers for Czech, among t</context>
</contexts>
<marker>Rupp, Spilker, Klarner, Worm, 2000</marker>
<rawString>Christopher G. Rupp, J¨org Spilker, Martin Klarner, and Karsten L. Worm. 2000. Combining analyses from various parsers. In Wolfgang Wahlster, editor, Verbmobil: Foundations of Speech-to-Speech Translation, pages 311–320. Springer-Verlag, Berlin etc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Alon Lavie</author>
</authors>
<title>Parser combinations by reparsing.</title>
<date>2006</date>
<booktitle>In Proc. HLT/NAACL,</booktitle>
<pages>129--132</pages>
<contexts>
<context position="30641" citStr="Sagae and Lavie (2006)" startWordPosition="4946" endWordPosition="4949">tem based on a manually compiled rule set. Some of the individual parsers had a fairly poor performance, but even a simple voting scheme on single edges contributed a significant improvement while the best results have been obtained for a combination that did not include the worst components. Alternatively the authors experimented with a trained selection component which not only had access to the alternative local parsing results, but also to their structural context. Neither a memory-based approach nor a model based on decision trees did result in further gains. In two separate experiments, Sagae and Lavie (2006) combined a number of dependency and constituent parsers, respectively. They created a new weighted search space from the results of the individual component parsers using different weighting schemes for the candidates. They then reparsed this search space and found a consistent improvement for the dependency structures, but not for the constituent-based ones. While all these approaches attempt to integrate the available evidence at parse time, Nivre and McDonald (2008) pursued an alternative architecture, where integration is achieved already at training time. They combined the two state-of-t</context>
</contexts>
<marker>Sagae, Lavie, 2006</marker>
<rawString>Kenji Sagae and Alon Lavie. 2006. Parser combinations by reparsing. In Proc. HLT/NAACL, pages 129–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ingo Schr¨oder</author>
</authors>
<title>Natural Language Parsing with Graded Constraints.</title>
<date>2002</date>
<tech>Ph.D. thesis,</tech>
<institution>Dept. of Computer Science, University of Hamburg,</institution>
<marker>Schr¨oder, 2002</marker>
<rawString>Ingo Schr¨oder. 2002. Natural Language Parsing with Graded Constraints. Ph.D. thesis, Dept. of Computer Science, University of Hamburg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ingo Schr¨oder</author>
<author>Horia F Pop</author>
<author>Wolfgang Menzel</author>
<author>Kilian A Foth</author>
</authors>
<title>Learning grammar weights using genetic algorithms.</title>
<date>2001</date>
<booktitle>In Proc. Euroconference Recent Advances in Natural Language Processing,</booktitle>
<pages>235--239</pages>
<marker>Schr¨oder, Pop, Menzel, Foth, 2001</marker>
<rawString>Ingo Schr¨oder, Horia F. Pop, Wolfgang Menzel, and Kilian A. Foth. 2001. Learning grammar weights using genetic algorithms. In Proc. Euroconference Recent Advances in Natural Language Processing, pages 235 – 239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Zeman</author>
<author>Zdenˇek ˇZabokrtsk´y</author>
</authors>
<title>Improving parsing accuracy by combining diverse dependency parsers.</title>
<date>2005</date>
<booktitle>In Proc. 9th International Workshop on Parsing Technologies (IWPT-2005),</booktitle>
<pages>171--178</pages>
<location>Vancouver, B.C.</location>
<marker>Zeman, ˇZabokrtsk´y, 2005</marker>
<rawString>Daniel Zeman and Zdenˇek ˇZabokrtsk´y. 2005. Improving parsing accuracy by combining diverse dependency parsers. In Proc. 9th International Workshop on Parsing Technologies (IWPT-2005), pages 171– 178, Vancouver, B.C.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>