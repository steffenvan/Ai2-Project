<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000084">
<title confidence="0.9969225">
Sinhala Grapheme-to-Phoneme Conversion and
Rules for Schwa Epenthesis
</title>
<author confidence="0.990188">
Asanka Wasala, Ruvan Weerasinghe and Kumudu Gamage
</author>
<affiliation confidence="0.998289">
Language Technology Research Laboratory
University of Colombo School of Computing
</affiliation>
<address confidence="0.569078">
35, Reid Avenue, Colombo 07, Sri Lanka
</address>
<email confidence="0.999025">
{awasala,kgamage}@webmail.cmb.ac.lk, arw@ucsc.cmb.ac.lk
</email>
<sectionHeader confidence="0.995647" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999964466666667">
This paper describes an architecture to
convert Sinhala Unicode text into pho-
nemic specification of pronunciation. The
study was mainly focused on disambigu-
ating schwa-/a/ and /a/ vowel epenthesis
for consonants, which is one of the sig-
nificant problems found in Sinhala. This
problem has been addressed by formulat-
ing a set of rules. The proposed set of
rules was tested using 30,000 distinct
words obtained from a corpus and com-
pared with the same words manually
transcribed to phonemes by an expert.
The Grapheme-to-Phoneme (G2P) con-
version model achieves 98 % accuracy.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999956016949153">
The conversion of Text-to-Speech (TTS) in-
volves many important processes. These proc-
esses can be divided mainly in to three parts; text
analysis, linguistic analysis and waveform gen-
eration (Black and Lenzo, 2003). The text analy-
sis process is responsible for converting the non-
textual content into text. This process also in-
volves tokenization and normalization of the
text. The identification of words or chunks of
text is called text-tokenization. Text normaliza-
tion establishes the correct interpretation of the
input text by expanding the abbreviations and
acronyms. This is done by replacing the non-
alphabetic characters, numbers, and punctuation
with appropriate text strings depending on the
context. The linguistic analysis process involves
finding the correct pronunciation of words, and
assigning prosodic features (eg. phrasing, intona-
tion, stress) to the phonemic string to be spoken.
The final process of a TTS system is waveform
generation which involves the production of an
acoustic digital signal using a particular synthesis
approach such as formant synthesis, articulatory
synthesis or waveform concatenation (Lemmetty,
1999). The text analysis and linguistic analysis
processes together are known as the Natural
Language Processing (NLP) component, while
the waveform generation process is known as the
Digital Signal Processing (DSP) component of a
TTS System (Dutoit, 1997).
Finding correct pronunciation for a given
word is one of the first and most significant tasks
in the linguistic analysis process. The component
which is responsible for this task in a TTS sys-
tem is often named the Grapheme-To-Phoneme
(G2P), Text-to-Phone or Letter-To-Sound (LTS)
conversion module. This module accepts a word
and generates the corresponding phonemic tran-
scription. Further, this phonemic transcription
can be annotated with appropriate prosodic
markers (Syllables, Accents, Stress etc) as well.
In this paper, we describe the implementation
and evaluation of a G2P conversion model for a
Sinhala TTS system. A Sinhala TTS system is
being developed based on Festival, the open
source speech synthesis framework. Letter to
sound conversion for Sinhala usually has simple
one to one mapping between orthography and
phonemic transcription for most Sinhala letters.
However some G2P conversion rules are pro-
posed in this paper to complement the generation
of more accurate phonemic transcription.
The rest of this paper is organized as follows:
Section 2 gives an overview of the Sinhala pho-
nemic inventory and the Sinhala writing system,
Section 3 briefly discusses G2P conversion ap-
proaches. Section 4 describes the schwa epenthe-
sis issue peculiar to Sinhala and Section 5 ex-
plains the Sinhala G2P conversion architecture.
</bodyText>
<page confidence="0.964599">
890
</page>
<note confidence="0.7219445">
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 890–897,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.9992112">
Section 6 gives experimental results and our dis-
cussion on it. The work is summarized in the
final section.
“ඦ”, which symbolizes the consonant sound /Ô~/
exists, it is not considered a phoneme in Sinhala.
</bodyText>
<sectionHeader confidence="0.861876" genericHeader="method">
2 Sinhala Phonemic Inventory and
</sectionHeader>
<subsectionHeader confidence="0.800453">
Writing System
2.1 The Sinhala Phonemic Inventory
</subsectionHeader>
<bodyText confidence="0.996193">
Sinhala is the official language of Sri Lanka and
the mother tongue of the majority - 74% of its
population. Spoken Sinhala contains 40 segmen-
tal phonemes; 14 vowels and 26 consonants as
classified below in Table 1 and Table 2 (Ka-
runatillake, 2004).
There are two nasalized vowels occurring in
two or three words in Sinhala. They are /a~/, /a~:/,
/æ~/ and /æ~:/ (Karunatillake, 2004). Spoken Sin-
hala also has following Diphthongs; /iu/, /eu/,
/æu/, /ou/, /au/, /ui/, /ei/, /æi/, /oi/ and /ai/
(Disanayaka, 1991).
</bodyText>
<table confidence="0.746038">
Front Central Back
Short Long Short Long Short Long
High i i: u u:
Mid e e: \ \: o o:
Low æ æ: a a:
</table>
<tableCaption confidence="0.997672">
Table 1. Spoken Sinhala Vowel Classification.
</tableCaption>
<table confidence="0.998300416666667">
Lab.Den. Alv.Ret.Pal. Vel.Glo.
Stops Voiceless p t ˇ k
Voiced b d Î 9
AffricatesVoiced Voiceless c
Ô
Pre-nasalized b~ d~ Î~ 9~
voiced stops
Nasals m n Jt ˜
Trill r
Lateral l
Spirants f s ß h
Semivowels w j
</table>
<tableCaption confidence="0.9582175">
Table 2*. Spoken Sinhala Consonant
Classification.
</tableCaption>
<bodyText confidence="0.774147">
A separate sign for vowel /\/ is not provided by
the Sinhala writing system. In terms of distribu-
tion, the vowel /\/ does not occur at the begin-
ning of a syllable except in the conjugational
variants of verbs formed from the verbal stem
/k\r\/ (to do). In contrast to this, though the letter
* Lab. – Labial, Den. – Dental, Alv. – Alveolar, Ret. –
Retroflex, Pal. – Palatal, Vel. – Velar and Glo. – Glottal.
</bodyText>
<subsectionHeader confidence="0.9983">
2.2 The Sinhala Writing System
</subsectionHeader>
<bodyText confidence="0.998941">
The Sinhala character set has 18 vowels, and 42
consonants as shown in Table 3.
</bodyText>
<tableCaption confidence="0.851312">
Table 3. Sinhala Character Set.
</tableCaption>
<bodyText confidence="0.995916875">
Sinhala characters are written left to right in
horizontal lines. Words are delimited by a space
in general. Vowels have corresponding full-
character forms when they appear in an absolute
initial position of a word. In other positions, they
appear as ‘strokes’ and, are used with consonants
to denote vowel modifiers. All vowels except
“ඎ” /iru:/, are able to occur in word initial posi-
tions (Disanayaka, 1995). The vowel /ə/ and /ə:/
occurs only in loan words of English origin.
Since there are no special symbols to represent
them, frequently the “අ” vowel is used to sym-
bolize them (Karunatillake, 2004).
All consonants occur in word initial position
except /ŋ/ and nasals (Disanayaka, 1995). The
symbols “ණ”, and “ළ” represent the retroflex
nasal /rl/ and the retroflex lateral /l/ respectively.
But they are pronounced as their respective
alveolar counterparts “න”-/n/ and “ල”-/l/.
Similarly, the symbol “ෂ” representing the
retroflex sibilant /g/, is pronounced as the palatal
sibilant “ශ”-/ß/. The corresponding aspirated
symbols of letters ක, ග, ච, ජ, ට, ඩ, ත, ද, ප, බ
namely ඛ, ඝ, ඡ, ඣ, ඪ, ථ, ධ, ඵ, භ respectively
are pronounced like the corresponding un-
aspirates (Karunatillake, 2004). When conso-
nants are combined with /r/ or /j/, special con-
junct symbols are used. “ර්”-/r/ immediately fol-
lowing a consonant can be marked by the symbol
“◌ɡ” added to the bottom of the consonant preced-
ing it. Similarly, “ය්”-/j/, immediately following
consonant can be marked by the symbol “◌ɕ”
</bodyText>
<equation confidence="0.8778881">
Vowels and corresponding vowel modifiers
(within brackets):
අ ආ(◌ා) ඇ(◌ැ) ඈ(◌ෑ) ඉ(◌ි) ඊ(◌ී) උ(◌ු) ඌ(◌ූ) ඍ(◌ෘ)
ඎ(◌ෲ) ඏ(◌ෟ) ඐ(◌ෳ) එ(ෙ◌) ඒ(ෙ◌ේ) ඓ(ෛ◌)
ඔ(ෙ◌ො) ඕ (ෙ◌ෝ) ඖ(ෙ◌ෞ)
Consonants:
ක ඛ ග ඝ ඞ ඟ ච ඡ ජ ඣ ඤ ඦ ට ඨ ඩ ඪ ණ ඬ ත ථ ද
ධ න ඳ ප ඵ බ භ ම ඹ ය ර ල ව ශ ෂ ස හ ළ ෆ ◌ං ◌ඃ
Special symbols: ɡ◌ ◌ɕ ɠ ඥ
Inherent vowel remover (Hal marker): ◌්
</equation>
<page confidence="0.985153">
891
</page>
<bodyText confidence="0.999842714285714">
added to the right-hand side of the consonant
preceding it (Karunatillake, 2004). “ඏ” /ilu/ and
“ඐ” /ilu:/ do not occur in contemporary Sinhala
(Disanayaka, 1995). Though there are 60 sym-
bols in Sinhala (Disanayaka, 1995), only 42
symbols are necessary to represent Spoken Sin-
hala (Karunatillake, 2004).
</bodyText>
<sectionHeader confidence="0.975706" genericHeader="method">
3 G2P Conversion Approaches
</sectionHeader>
<bodyText confidence="0.999977970588236">
The issue of mapping textual content into pho-
nemic content is highly language dependent.
Three main approaches of G2P conversion are;
use of a pronunciation dictionary, use of well
defined language-dependent rules and data-
driven methods (El-Imam and Don, 2005).
One of the easiest ways of G2P conversion is
the use of a lexicon or pronunciation dictionary.
A lexicon consists of a large list of words to-
gether with their pronunciation. There are several
limitations to the use of lexicons. It is practically
impossible to construct such to cover the whole
vocabulary of a language owing to Zipfian phe-
nomena. Though a large lexicon is constructed,
one would face other limitations such as efficient
access, memory storage etc. Most lexicons often
do not include many proper names, and only
very few provide pronunciations for abbrevia-
tions and acronyms. Only a few lexicons provide
distinct entries for morphological productions of
words. In addition, pronunciations of some
words differ based on the context and their parts-
of-speech. Further, an enormous effort has to be
made to develop a comprehensive lexicon. In
practical scenarios, speech synthesizers as well
as speech recognizers need to be able to produce
the pronunciation of words that are not in the
lexicon. Names, morphological productivity and
numbers are the three most important cases that
cause the use of lexica to be impractical (Juraf-
sky and Martin, 2000).
To overcome these difficulties, rules can be
specified on how letters can be mapped to pho-
nemes. In this way, the size of the lexicon can be
reduced as only to contain exceptions to the
rules. In contrast to the above fact, some systems
rely on using very large lexicons, together with a
set of letter-to-sound conversion rules to deal
with words which are not found in the lexicon
(Black and Lenzo, 2003).
These language and context dependent rules
are formulated using phonetic and linguistic
knowledge of a particular language. The com-
plexity of devising a set of rules for a particular
language is dependent on the degree of corre-
spondence between graphemes and phonemes.
For some languages such as English and French,
the relationship is complex and require large
numbers of rules (El-Imam and Don, 2005;
Damper et al., 1998), while some languages such
as Urdu (Hussain, 2004), and Hindi (Ramakish-
nan et al., 2004; Choudhury, 2003) show regular
behavior and thus pronunciation can be modeled
by defining fairly regular simple rules.
Data-driven methods are widely used to avoid
tedious manual work involving the above ap-
proaches. In these methods, G2P rules are cap-
tured by means of various machine learning
techniques based on a large amount of training
data. Most previous data-driven approaches have
been used for English. Widely used data-driven
approaches include, Pronunciation by Analogy
(PbA), Neural Networks (Damper et al., 1998),
and Finite-State-Machines (Jurafsky and Martin,
2000). Black et al. (1998) discussed a method for
building general letter-to-sound rules suitable for
any language, based on training a CART – deci-
sion tree.
</bodyText>
<sectionHeader confidence="0.931532" genericHeader="method">
4 Schwa Epenthesis in Sinhala
</sectionHeader>
<bodyText confidence="0.999518275862069">
G2P conversion problems encountered in Sinhala
are similar to those encountered in the Hindi lan-
guage (Ramakishnan et al., 2004). All consonant
graphemes in Sinhala are associated with an in-
herent vowel schwa-/a/ or /a/ which is not repre-
sented in orthography. Vowels other than /a/ and
/a/ are represented in orthographic text by plac-
ing specific vowel modifier diacritics around the
consonant grapheme. In the absence of any
vowel modifier for a particular consonant graph-
eme, there is an ambiguity of associating /a/ or
/a/ as the vowel modifier. The inherent vowel
association in Sinhala can be distinguished from
Hindi. In Hindi the only possible association is
schwa vowel where as in Sinhala either of
vowel-/a/ or schwa-/a/ can be associated with a
consonant. Native Sinhala speakers are naturally
capable of choosing the association of the appro-
priate vowel (/a/ or /a/) in context. Moreover,
linguistic rules describing the transformation of
G2P, is rarely found in literature, with available
literature not providing any precise procedure
suitable for G2P conversion of contemporary
Sinhala. Automating the G2P conversion process
is a difficult task due to the ambiguity of choos-
ing between /a/ and /a/.
A similar phenomenon is observed in Hindi
and Malay as well. In Hindi, the “deletion of the
schwa vowel (in some cases)” is successfully
</bodyText>
<page confidence="0.991067">
892
</page>
<bodyText confidence="0.999711416666667">
solved by using rule based algorithms (Choud-
hury 2003; Ramakishnan et al., 2004). In Malay,
the character ‘e’ can be pronounced as either
vowel /e/ or /a/, and rule based algorithms are
used to address this ambiguity (El-Imam and
Don, 2005).
In our research, a set of rules is proposed to
disambiguate epenthesis of /a/ and /a/, when as-
sociating with consonants. Unlike in Hindi, in
Sinhala, the schwa is not deleted, instead always
inserted. Hence, this process is named “Schwa
Epenthesis” in this paper.
</bodyText>
<sectionHeader confidence="0.982415" genericHeader="method">
5 Sinhala G2P Conversion Architecture
</sectionHeader>
<bodyText confidence="0.9992605">
An architecture is proposed to convert Sinhala
Unicode text into phonemes encompassing a set
of rules to handle schwa epenthesis. The G2P
architecture developed for Sinhala is identical to
the Hindi G2P architecture (Ramakishnan et al.,
2004). The input to the system is normalized
Sinhala Unicode text. The G2P engine first maps
all characters in the input word into correspond-
ing phonemes by using the letter-to-phoneme
mapping table below (Table 4).
</bodyText>
<table confidence="0.999146733333333">
q /a/ a) ,&amp;oo /o/ @ /Î~/ - /f/
q1,o3 /a:/ ®,&amp;o� /o:/ 2z,c5 /t/ oaa /ru:/
q1,o1 /æ/ `}a,&amp;oo /ou/ �,� /d/
ge,o1 /æ:/ -,a /k/ 4 /d~/
9 ,o� /i/ m,a /˝/ �,� /p/
a,o� /i:/ V,o. /˜/ a,m /b/
C,o� /u/ � /˝~/ a /m/
C&apos;i.o� /u:/ a,ffi /c/ @ /b~/
na /ri/ C6,m@ /Ô/ CZ /j/
oa /ru/ er, /μ/ 6 /r/
0 /ilu/ er, /jμ/ C,G /l/
Os /ilu:/ C5 /Ô~/ a /w/
6 ,&amp;o /e/ a,� /ˇ/ W,N /ß/
6,&amp;od /e:/ a,� /Î/ n /s/
&amp;6,&amp;&amp;o /ai/ M,4r. /n/ m,os /h/
</table>
<tableCaption confidence="0.999301">
Table 4. G2P Mapping Table
</tableCaption>
<bodyText confidence="0.9999338">
The mapping procedure is given in section 5.1.
Then, a set of rules are applied to this phonemic
string in a specific order to obtain a more accu-
rate version. This phonemic string is then com-
pared with the entries in the exception lexicon. If
a matching entry is found, the correct pronuncia-
tion form of the text is obtained from the lexicon,
otherwise the resultant phonemic string is re-
turned. Hence, the final output of G2P model is
the phonemic transcription of the input text.
</bodyText>
<subsectionHeader confidence="0.982689">
5.1 G2P Mapping Procedure
</subsectionHeader>
<bodyText confidence="0.999748222222222">
Each tokenized word represented by Unicode
normalization form is analyzed by individual
graphemes from left to right. By using the G2P
mapping table (Table 4), corresponding pho-
nemes are obtained. As in the given example
Figure 1, no mappings are required for the Zero-
Width-Joiner and diacritic Hal marker “o3” (Ha-
lant) which is used to remove the inherent vowel
in a consonant.
</bodyText>
<figureCaption confidence="0.997292">
Figure 1. G2P Mapping (Example).
</figureCaption>
<bodyText confidence="0.999989166666667">
The next step is epenthesis of schwa-/a/ for
consonants. In Sinhala, the tendency of associat-
ing a /a/ with consonant is very much higher than
associating vowel /a/. Therefore, initially, all
plausible consonants are associated with /a/. To
obtain the accurate pronunciation, the assigned
/a/ is altered to /a/ or vice versa by applying the
set of rules given in next section. However, when
associating /a/ with consonants, /a/ should asso-
ciate only with consonant graphemes excluding
the graphemes “o.”, “V” and “os”, which do not
contain any vowel modifier or diacritic Hal
marker. In the above example, only /n/ and first
/j/ are associated with schwa, because other con-
sonants violate the above principle. When schwa
is associated with appropriate consonants, the
resultant phonemic string for the given example
(section 5.1) is; /namjaji/.
</bodyText>
<subsectionHeader confidence="0.997786">
5.2 G2P Conversion Rules
</subsectionHeader>
<bodyText confidence="0.999994916666667">
It is observed that resultant phoneme strings
from the above procedure should undergo several
modifications in terms of schwa assignments into
vowel /a/ or vice versa, in order to obtain the ac-
curate pronunciation of a particular word.
Guided by the literature (Karunatillake, 2004), it
was noticed that these modifications can be car-
ried out by formulating a set of rules.
The G2P rules were formulated with the aid of
phonological rules described in the linguistic
literature (Karunatillake, 2004) and by a com-
prehensive word search analysis using the UCSC
</bodyText>
<page confidence="0.997968">
893
</page>
<bodyText confidence="0.996579294117647">
Sinhala corpus BETA (2005). Some of these ex-
isting phonological rules were altered in order to
reflect the observations made in the corpus word
analysis and to achieve more accurate results.
The proposed new set of rules is empirically
shown to be effective and can be conveniently
implemented using regular expressions.
Each rule given below is applied from left to
right, and the presented order of the rules is to be
preserved. Except for rule #1, rule #5, rule #6
and rule #8, all other rules are applied repeatedly
many times to a single word until the conditions
presented in the rules are satisfied.
Rule #1: If the nucleus of the first syllable is a
schwa, the schwa should be replaced by vowel
/a/ (Karunatillake, 2004), except in the following
situations;
</bodyText>
<figure confidence="0.788019">
(a) The syllable starts with /s/ followed by /v/.
(ie. /sv/)
(b) The first syllable starts with /k/ where as,
</figure>
<listItem confidence="0.930500875">
/k/ is followed by /a/ and subsequently /a/ is pre-
ceded by /r/. (ie. /kar/)
(c) The word consists of a single syllable having
CV structure (eg. /da/�)
Rule #2:
(a) If /r/ is preceded by any consonant, followed
by /a/ and subsequently followed by /h/, then /a/
should be replaced by /a/.
(/[consonant]rah/-&gt;/[consonant]rah/ )
(b) If /r/ is preceded by any consonant, followed
by /a/ and subsequently followed by any conso-
nant other than /h/, then /a/ should be replaced by
/a/.
(/[consonant]ra[!h]/-&gt;/[consonant]ra[!h]/ )
(c) If /r/ is preceded by any consonant, followed
by /a/ and subsequently followed by any conso-
nant other than /h/, then /a/ should be replaced by
/a/.
(/[consonant]ra[!h]/-&gt;/[consonant]ra!h]/)
(d) If /r/ is preceded by any consonant, followed
by /a/ and subsequently followed by /h/, then /a/
is retained.
(/[consonant]ra[h]/-&gt;/[consonant]ra[h]/)
Rule #3: If any vowel in the set {/a/, /e/, /æ/, /o/,
</listItem>
<bodyText confidence="0.980686">
/\/} is followed by /h/ and subsequently /h/ is
preceded by schwa, then schwa should replaced
by vowel /a/.
Rule #4: If schwa is followed by a consonant
cluster, the schwa should be replaced by /a/ (Ka-
runatillake, 2004).
Rule #5: If /a/ is followed by the word final con-
sonant, it should be replaced by /a/, except in the
situations where the word final consonant is /r/,
/b/, /ct/ or /t/.
Rule #6: At the end of a word, if schwa precedes
the phoneme sequence /ji/, the schwa should be
replaced by /a/ (Karunatillake, 2004).
Rule #7: If the /k/ is followed by schwa, and
subsequent phonemes are /r/ or /l/ followed by
/u/, then schwa should be replaced by phoneme
/a/. (ie. /ka(r|l)u/-&gt;/ka(r|l)u/)
Rule #8: Within the given context of following
words, /a/ found in phoneme sequence /kal/, (the
left hand side of the arrow) should be changed to
/a/ as shown in the right hand side.
</bodyText>
<listItem confidence="0.99963625">
• /kal(a:|e:|o:)y/-&gt;/kal(a:|e:|o:)y/
• /kale(m|h)(u|i)/-&gt;/kale(m|h)(u|i)/
• /kalah(u|i)/-&gt;/kaleh(u|i)/
• /kala/-&gt;/kala/
</listItem>
<bodyText confidence="0.99856075">
The above rules handle the schwa epenthesis
problem. The corresponding diphthongs (refer
section 2) are then obtained by processing the
resultant phonetized string. This string is again
analyzed from left to right, and the phoneme se-
quences given in the first column of Table 5 are
replaced by the diphthong, represented in the
second column.
</bodyText>
<table confidence="0.999789">
Phoneme Sequence Diphthong
/i/ /w/ /u/ /iu/
/e/ /w/ /u/ /eu/
/æ/ /w/ /u/ /æu/
/o/ /w/ /u/ /ou/
/a/ /w/ /u/ /au/
/u/ /j/ /i/ /ui/
/e/ /j/ /i/ /ei/
/æ/ /j/ /i/ /æi/
/o/ /j/ /i/ /oi/
/a/ /j/ /i/ /ai/
</table>
<tableCaption confidence="0.997757">
Table 5. Diphthong Mapping Table.
</tableCaption>
<bodyText confidence="0.948794666666667">
The application of the above rules for the
given example (section 5.1) is illustrated in Fig-
ure 2.
</bodyText>
<figureCaption confidence="0.971834">
Figure 2. Application of G2P Rules – An Exam-
ple.
</figureCaption>
<page confidence="0.997988">
894
</page>
<sectionHeader confidence="0.998615" genericHeader="evaluation">
6 Results and Discussion
</sectionHeader>
<bodyText confidence="0.998776548387097">
Text obtained from the category “News Paper&gt;
Feature Articles &gt; Other” of the UCSC Sinhala
corpus was chosen for testing due to the hetero-
geneous nature of these texts and hence per-
ceived better representation of the language in
this part of the corpus*. A list of distinct words
was first extracted, and the 30,000 most fre-
quently occurring words chosen for testing.
The overall accuracy of our G2P module was
calculated at 98%, in comparison with the same
words correctly transcribed by an expert.
Since this is the first known documented work
on implementing a G2P scheme for Sinhala, its
contribution to the existing body of knowledge is
difficult to evaluate. However, an experiment
was conducted in order to arrive at an approxi-
mation of the scale of this contribution.
It was first necessary, to define a baseline
against which this work could be measured.
While this could be done by giving a single de-
fault letter-to-sound mapping for any Sinhala
letter, owing to the near universal application of
rule #1 in Sinhala words (22766 of the 30000
words used in testing), the baseline was defined
by the application of this rule in addition to the
‘default mapping’. This baseline gives us an er-
ror of approximately 24%. Since the proposed
solution reduces this error to 2%, this work can
claim to have improved performance by 22%.
An error analysis revealed the following types
of errors (Table 6):
</bodyText>
<table confidence="0.9972003">
Error description # of
words
Compound words- (ie. Single words 382
formed by combining 2 or more distinct
words; such as in the case of the English
word “thereafter”).
Foreign (mainly English) words directly 116
encoded in Sinhala. eg. ෆැෂන් - fashion,
කැම්පස් - campus.
Other 118
</table>
<tableCaption confidence="0.965701">
Table 6. Types of Errors.
</tableCaption>
<bodyText confidence="0.9855174375">
The errors categorized as “Other” are given
below with clarifications:
• The modifier used to denote long vowel
“ආ” /a:/ is “◌ා” which is known as “Aela-
pilla”. eg. consonant “ක්” /k/ associates
with “◌ා” /a:/ to produce grapheme “කා” is
pronounced as /ka:/. The above exercise
* This accounts for almost two-thirds of the size of this ver-
sion of the corpus.
revealed some 37 words end without
vowel modifier “◌ා”, but are usually pro-
nounced with the associated long vowel
/a:/. In the following examples, each input
word is listed first, followed by the erro-
neous output of G2P conversion, and cor-
rect transcription.
</bodyText>
<equation confidence="0.861665666666667">
“අම්ම”(mother) -&gt; /ammə/ -&gt; /amma:/
“අක්ක”(sister) -&gt; /akkə/ -&gt; /akka:/
“ගත්ත”(taken)-&gt; /gattə/ -&gt; /gatta:/
</equation>
<listItem confidence="0.629218666666667">
• There were 27 words associated with er-
roneous conversion of words having the
letter “හ”, which corresponds to phoneme
/h/. The study revealed this letter shows an
unusual behavior in G2P conversion.
• The modifier used to denote vowel “ඍ”
</listItem>
<bodyText confidence="0.972079794117647">
◌ෘ” is known as “Geta-pilla”. When
this vowel appears as the initial letter of a
word, it is pronounced as /ri/ as in “ඍණ”
/rinə/ (minus). When the corresponding
vowel modifier appears in a middle of a
word most of the time it is pronounced as
/ru/ (Disanayaka, 2000). eg. “කෘතිය”
(book)is pronounced as /krutijə/, “පෘෂ්ඨය”
(surface) - /prußˇ\j\/, “උත්කෘෂ්ට” (excel-
lent)-/utkrußˇ\/. But 13 words were found
as exceptions of this general rule. In those
words, the “◌ෘ” is pronounced as /ur/
rather than /ru/. eg. “පවෘත් ති” (news)-
/prəwurti/,“සමෘද්ධි”(prosperity)-/samurdi/,
“විවෘත” (opened) - /wiwurtə/.
• In general, vowel modifiers “◌ැ” (Adha-
pilla), “◌ෑ” (Diga Adha-pilla) symbolizes
the vowel “ඇ” /æ/ and “ඈ” /æ:/ respec-
tively. eg. consonant “ක්” /k/ combines
with vowel modifier “◌ැ” to create “කැ”
which is pronounced as /kæ/. Few words
were found where this rule is violated. In
such words, the vowel modifiers “◌ැ” and
“◌ෑ” represent vowels “උ”- /u/, and “ඌ”-
/u:/ respectively. eg. “ජනශැති” (legend) -
/Ôanəßruti/, “කෑර” (cruel) - /kru:r\/.
• The verbal stem “කර” (to do) is pro-
nounced as /kərə/. Though there are many
words starting with the same verbal stem,
there are a few other words differently
pronounced as /karə/ or /kara/. eg.
“කරත්තය” (cart) /karattəyə/, “කරවල”
(dried fish) /karəvələ/.
- “
</bodyText>
<page confidence="0.993892">
895
</page>
<listItem confidence="0.832454333333333">
• A few of the remaining errors are due to
homographs; “€)2n” - /vanə/, /vənə/; “me”
-/kalə/, /kələ/; “m6” - /karə/, /kərə/.
</listItem>
<bodyText confidence="0.999987592592593">
The above error analysis itself shows that the
model can be extended. Failures in the current
model are mostly due to compound words and
foreign words directly encoded in Sinhala
(1.66%). The accuracy of the G2P model can be
increased significantly by incorporating a
method to identify compound words and tran-
scribe them accurately. If the constituent words
of a compound word can be identified and sepa-
rated, the same set of rules can be applied for
each constituent word, and the resultant pho-
netized strings combined to obtain the correct
pronunciation. The same problem is observed in
the Hindi language too. Ramakishnan et al.
(2004) proposed a procedure for extracting com-
pound words from a Hindi corpus. The utiliza-
tion of compound word lexicon in their rule-
based G2P conversion module improved the ac-
curacy of G2P conversion by 1.6% (Ramakish-
nan et al., 2004). In our architecture, the most
frequently occurring compound words and for-
eign words are dealt with the aid of an excep-
tions lexicon. Homographs are also disambigu-
ated using the most frequently occurring words
in Sinhala. Future improvements of the architec-
ture will include incorporation of a compound
word identification and phonetization module.
</bodyText>
<sectionHeader confidence="0.998509" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.998370739130435">
In this paper, the problem of Sinhala grapheme-
to-phoneme conversion is addressed with a spe-
cial focus on dealing with the schwa epenthesis.
The proposed G2P conversion mechanism will
be useful in various applications in the speech
domain. To the best of our knowledge no other
documented evidence has been reported for Sin-
hala grapheme-to-phoneme conversion in the
literature. There are no other approaches avail-
able for the transcription of Sinhala text that pro-
vides a platform for comparison of the proposed
rule-based method. The empirical evidence from
a wide spectrum Sinhala corpus indicates that the
proposed model can account for nearly 98% of
cases accurately.
The proposed G2P module is fully imple-
mented in Sinhala TTS being developed at Lan-
guage Technology Research Lab, UCSC. A
demonstration tool of the proposed G2P module
integrated with Sinhala syllabification algorithm
proposed by Weerasinghe et al. (2005) is avail-
able for download from:
http://www.ucsc.cmb.ac.lk/ltrl/downloads.html
</bodyText>
<sectionHeader confidence="0.921623" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.954243944444444">
This work has been supported through the PAN
Localization Project, (http://www.PANL10n.net)
grant from the International Development Re-
search Center (IDRC), Ottawa, Canada, adminis-
tered through the Center for Research in Urdu
Language Processing, National University of
Computer and Emerging Sciences, Pakistan. The
authors would like to thank Sinhala Language
scholars Prof. R.M.W. Rajapaksha, and Prof. J.B.
Dissanayake for their invaluable support and ad-
vice throughout the study. Special thanks to Dr.
Sarmad Hussain (NUCES, Pakistan) for his
guidance and advices. We also wish to acknowl-
edge the contribution of Mr. Viraj Welgama, Mr.
Dulip Herath, and Mr. Nishantha Medagoda of
Language Technology Research Laboratory of
the University of Colombo School of Comput-
ing, Sri Lanka.
</bodyText>
<sectionHeader confidence="0.988494" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999458892857143">
Alan W. Black and Kevin A. Lenzo. 2003. Building
Synthetic Voices, Language Technologies Insti-
tute, Carnegie Mellon University and Cepstral
LLC. Retrieved from http://festvox.org/bsv/
Alan W. Black, Kevin Lenzo, and Vincent Pagel.
1998. Issues in Building General Letter to Sound
Rules. In Proc. of the 3rd ESCA Workshop on
Speech Synthesis, pages 77–80.
Monojit Choudhury. 2003. Rule-Based Grapheme to
Phoneme Mapping for Hindi Speech Synthesis,
presented at the 90th Indian Science Congress
of the International Speech Communication
Association (ISCA), Bangalore.
R.I. Damper, Y. Marchand, M.J. Adamson and K.
Gustafson. 1998. Comparative Evaluation of Let-
ter-to-Sound Conversion Techniques for English
Text-to-Speech Synthesis. In Proc. Third
ESCA/COCOSDA Workshop on Speech Syn-
thesis, pages 53- 58, Blue Mountains, NSW, Aus-
tralia.
J.B. Disanayaka. 1991. The Structure of Spoken
Sinhala, National Institute of Education, Ma-
haragama.
J.B. Disanayaka. 2000. Basaka Mahima: 2, Akuru
ha pili, S. Godage &amp; Bros., 661, P. D. S.
Kularathna Mawatha, Colombo 10.
J.B. Disanayaka. 1995. Grammar of Contemporary
Literary Sinhala - Introduction to Grammar,
</reference>
<page confidence="0.988698">
896
</page>
<reference confidence="0.997485619047619">
Structure of Spoken Sinhala, S. Godage &amp; Bros.,
661, P. D. S. Kularathna Mawatha, Colombo 10.
T. Dutoit. 1997. An Introduction to Text-to-
Speech Synthesis, Kluwer Academic Publishers,
Dordrecht, Netherlands.
Yousif A. El-Imam and Zuraidah M. Don. 2005.
Rules and Algorithms for Phonetic Transcription of
Standard Malay, IEICE Trans Inf &amp; Syst, E88-D
2354-2372.
Sarmad Hussain. 2004. Letter-to-Sound Conversion
for Urdu Text-to-Speech System, Proceedings of
Workshop on &amp;quot;Computational Approaches to
Arabic Script-based Languages,&amp;quot; COLING
2004, p. 74-49, Geneva, Switzerland.
Daniel Jurafsky and James H. Martin. 2000. Speech
and Language Processing: An Introduction to
Natural Language Processing, Computational
Linguistics, and Speech Recognition. Pearson
Education (Singapore) Pte. Ltd, Indian Branch, 482
F.I.E. Patparganj, Delhi 110 092, India.
W.S. Karunatillake. 2004. An Introduction to Spo-
ken Sinhala, 3rd edn., M.D. Gunasena &amp; Co. ltd.,
217, Olcott Mawatha, Colombo 11.
Sami Lemmetty. 1999. Review of Speech Synthesis
Technology, MSc. thesis, Helsinki University of
Technology.
A.G. Ramakishnan, Kalika Bali, Partha Pratim Taluk-
dar N. and Sridhar Krishna. 2004. Tools for the
Development of a Hindi Speech Synthesis System,
In 5th ISCA Speech Synthesis Workshop, Pitts-
burgh. pages 109-114.
Ruvan Weerasinghe, Asanka Wasala and Kumudu
Gamage. 2005. A Rule Based Syllabification Algo-
rithm for Sinhala, Proceedings of 2nd Interna-
tional Joint Conference on Natural Language
Processing (IJCNLP-05), p. 438-449, Jeju Is-
land, Korea.
UCSC Sinhala Corpus BETA. 2005. Retrieved Au-
gust 30, 2005, from University of Colombo School
of Computing, Language Technology Research
Laboratory Web site:
http://www.ucsc.cmb.ac.lk/ltrl/downloads.html
</reference>
<page confidence="0.997582">
897
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.503418">
<title confidence="0.9972565">Sinhala Grapheme-to-Phoneme Conversion and Rules for Schwa Epenthesis</title>
<author confidence="0.995209">Asanka Wasala</author>
<author confidence="0.995209">Ruvan Weerasinghe</author>
<author confidence="0.995209">Kumudu Gamage</author>
<affiliation confidence="0.9999815">Language Technology Research Laboratory University of Colombo School of Computing</affiliation>
<address confidence="0.995091">35, Reid Avenue, Colombo 07, Sri Lanka</address>
<email confidence="0.990599">awasala@webmail.cmb.ac.lk,arw@ucsc.cmb.ac.lk</email>
<email confidence="0.990599">kgamage@webmail.cmb.ac.lk,arw@ucsc.cmb.ac.lk</email>
<abstract confidence="0.9432459375">This paper describes an architecture to convert Sinhala Unicode text into phonemic specification of pronunciation. The study was mainly focused on disambiguand /a/ vowel epenthesis for consonants, which is one of the significant problems found in Sinhala. This problem has been addressed by formulating a set of rules. The proposed set of rules was tested using 30,000 distinct words obtained from a corpus and compared with the same words manually transcribed to phonemes by an expert. The Grapheme-to-Phoneme (G2P) conversion model achieves 98 % accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alan W Black</author>
<author>Kevin A Lenzo</author>
</authors>
<title>Building Synthetic Voices,</title>
<date>2003</date>
<institution>Language Technologies Institute, Carnegie Mellon University and Cepstral LLC.</institution>
<note>Retrieved from http://festvox.org/bsv/</note>
<contexts>
<context position="1109" citStr="Black and Lenzo, 2003" startWordPosition="159" endWordPosition="162">vowel epenthesis for consonants, which is one of the significant problems found in Sinhala. This problem has been addressed by formulating a set of rules. The proposed set of rules was tested using 30,000 distinct words obtained from a corpus and compared with the same words manually transcribed to phonemes by an expert. The Grapheme-to-Phoneme (G2P) conversion model achieves 98 % accuracy. 1 Introduction The conversion of Text-to-Speech (TTS) involves many important processes. These processes can be divided mainly in to three parts; text analysis, linguistic analysis and waveform generation (Black and Lenzo, 2003). The text analysis process is responsible for converting the nontextual content into text. This process also involves tokenization and normalization of the text. The identification of words or chunks of text is called text-tokenization. Text normalization establishes the correct interpretation of the input text by expanding the abbreviations and acronyms. This is done by replacing the nonalphabetic characters, numbers, and punctuation with appropriate text strings depending on the context. The linguistic analysis process involves finding the correct pronunciation of words, and assigning proso</context>
<context position="9534" citStr="Black and Lenzo, 2003" startWordPosition="1552" endWordPosition="1555">uce the pronunciation of words that are not in the lexicon. Names, morphological productivity and numbers are the three most important cases that cause the use of lexica to be impractical (Jurafsky and Martin, 2000). To overcome these difficulties, rules can be specified on how letters can be mapped to phonemes. In this way, the size of the lexicon can be reduced as only to contain exceptions to the rules. In contrast to the above fact, some systems rely on using very large lexicons, together with a set of letter-to-sound conversion rules to deal with words which are not found in the lexicon (Black and Lenzo, 2003). These language and context dependent rules are formulated using phonetic and linguistic knowledge of a particular language. The complexity of devising a set of rules for a particular language is dependent on the degree of correspondence between graphemes and phonemes. For some languages such as English and French, the relationship is complex and require large numbers of rules (El-Imam and Don, 2005; Damper et al., 1998), while some languages such as Urdu (Hussain, 2004), and Hindi (Ramakishnan et al., 2004; Choudhury, 2003) show regular behavior and thus pronunciation can be modeled by defin</context>
</contexts>
<marker>Black, Lenzo, 2003</marker>
<rawString>Alan W. Black and Kevin A. Lenzo. 2003. Building Synthetic Voices, Language Technologies Institute, Carnegie Mellon University and Cepstral LLC. Retrieved from http://festvox.org/bsv/</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan W Black</author>
<author>Kevin Lenzo</author>
<author>Vincent Pagel</author>
</authors>
<title>Issues in Building General Letter to Sound Rules.</title>
<date>1998</date>
<booktitle>In Proc. of the 3rd ESCA Workshop on Speech Synthesis,</booktitle>
<pages>77--80</pages>
<contexts>
<context position="10649" citStr="Black et al. (1998)" startWordPosition="1724" endWordPosition="1727">hnan et al., 2004; Choudhury, 2003) show regular behavior and thus pronunciation can be modeled by defining fairly regular simple rules. Data-driven methods are widely used to avoid tedious manual work involving the above approaches. In these methods, G2P rules are captured by means of various machine learning techniques based on a large amount of training data. Most previous data-driven approaches have been used for English. Widely used data-driven approaches include, Pronunciation by Analogy (PbA), Neural Networks (Damper et al., 1998), and Finite-State-Machines (Jurafsky and Martin, 2000). Black et al. (1998) discussed a method for building general letter-to-sound rules suitable for any language, based on training a CART – decision tree. 4 Schwa Epenthesis in Sinhala G2P conversion problems encountered in Sinhala are similar to those encountered in the Hindi language (Ramakishnan et al., 2004). All consonant graphemes in Sinhala are associated with an inherent vowel schwa-/a/ or /a/ which is not represented in orthography. Vowels other than /a/ and /a/ are represented in orthographic text by placing specific vowel modifier diacritics around the consonant grapheme. In the absence of any vowel modif</context>
</contexts>
<marker>Black, Lenzo, Pagel, 1998</marker>
<rawString>Alan W. Black, Kevin Lenzo, and Vincent Pagel. 1998. Issues in Building General Letter to Sound Rules. In Proc. of the 3rd ESCA Workshop on Speech Synthesis, pages 77–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Monojit Choudhury</author>
</authors>
<title>Rule-Based Grapheme to Phoneme Mapping for Hindi Speech Synthesis, presented at</title>
<date>2003</date>
<booktitle>the 90th Indian Science Congress of the International Speech Communication Association (ISCA),</booktitle>
<location>Bangalore.</location>
<contexts>
<context position="10065" citStr="Choudhury, 2003" startWordPosition="1639" endWordPosition="1640">n rules to deal with words which are not found in the lexicon (Black and Lenzo, 2003). These language and context dependent rules are formulated using phonetic and linguistic knowledge of a particular language. The complexity of devising a set of rules for a particular language is dependent on the degree of correspondence between graphemes and phonemes. For some languages such as English and French, the relationship is complex and require large numbers of rules (El-Imam and Don, 2005; Damper et al., 1998), while some languages such as Urdu (Hussain, 2004), and Hindi (Ramakishnan et al., 2004; Choudhury, 2003) show regular behavior and thus pronunciation can be modeled by defining fairly regular simple rules. Data-driven methods are widely used to avoid tedious manual work involving the above approaches. In these methods, G2P rules are captured by means of various machine learning techniques based on a large amount of training data. Most previous data-driven approaches have been used for English. Widely used data-driven approaches include, Pronunciation by Analogy (PbA), Neural Networks (Damper et al., 1998), and Finite-State-Machines (Jurafsky and Martin, 2000). Black et al. (1998) discussed a met</context>
<context position="12220" citStr="Choudhury 2003" startWordPosition="1978" endWordPosition="1980"> naturally capable of choosing the association of the appropriate vowel (/a/ or /a/) in context. Moreover, linguistic rules describing the transformation of G2P, is rarely found in literature, with available literature not providing any precise procedure suitable for G2P conversion of contemporary Sinhala. Automating the G2P conversion process is a difficult task due to the ambiguity of choosing between /a/ and /a/. A similar phenomenon is observed in Hindi and Malay as well. In Hindi, the “deletion of the schwa vowel (in some cases)” is successfully 892 solved by using rule based algorithms (Choudhury 2003; Ramakishnan et al., 2004). In Malay, the character ‘e’ can be pronounced as either vowel /e/ or /a/, and rule based algorithms are used to address this ambiguity (El-Imam and Don, 2005). In our research, a set of rules is proposed to disambiguate epenthesis of /a/ and /a/, when associating with consonants. Unlike in Hindi, in Sinhala, the schwa is not deleted, instead always inserted. Hence, this process is named “Schwa Epenthesis” in this paper. 5 Sinhala G2P Conversion Architecture An architecture is proposed to convert Sinhala Unicode text into phonemes encompassing a set of rules to hand</context>
</contexts>
<marker>Choudhury, 2003</marker>
<rawString>Monojit Choudhury. 2003. Rule-Based Grapheme to Phoneme Mapping for Hindi Speech Synthesis, presented at the 90th Indian Science Congress of the International Speech Communication Association (ISCA), Bangalore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R I Damper</author>
<author>Y Marchand</author>
<author>M J Adamson</author>
<author>K Gustafson</author>
</authors>
<title>Comparative Evaluation of Letter-to-Sound Conversion Techniques for English Text-to-Speech Synthesis.</title>
<date>1998</date>
<booktitle>In Proc. Third ESCA/COCOSDA Workshop on Speech Synthesis,</booktitle>
<pages>53--58</pages>
<location>Blue Mountains, NSW,</location>
<contexts>
<context position="9959" citStr="Damper et al., 1998" startWordPosition="1620" endWordPosition="1623">e above fact, some systems rely on using very large lexicons, together with a set of letter-to-sound conversion rules to deal with words which are not found in the lexicon (Black and Lenzo, 2003). These language and context dependent rules are formulated using phonetic and linguistic knowledge of a particular language. The complexity of devising a set of rules for a particular language is dependent on the degree of correspondence between graphemes and phonemes. For some languages such as English and French, the relationship is complex and require large numbers of rules (El-Imam and Don, 2005; Damper et al., 1998), while some languages such as Urdu (Hussain, 2004), and Hindi (Ramakishnan et al., 2004; Choudhury, 2003) show regular behavior and thus pronunciation can be modeled by defining fairly regular simple rules. Data-driven methods are widely used to avoid tedious manual work involving the above approaches. In these methods, G2P rules are captured by means of various machine learning techniques based on a large amount of training data. Most previous data-driven approaches have been used for English. Widely used data-driven approaches include, Pronunciation by Analogy (PbA), Neural Networks (Damper</context>
</contexts>
<marker>Damper, Marchand, Adamson, Gustafson, 1998</marker>
<rawString>R.I. Damper, Y. Marchand, M.J. Adamson and K. Gustafson. 1998. Comparative Evaluation of Letter-to-Sound Conversion Techniques for English Text-to-Speech Synthesis. In Proc. Third ESCA/COCOSDA Workshop on Speech Synthesis, pages 53- 58, Blue Mountains, NSW, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J B Disanayaka</author>
</authors>
<date>1991</date>
<booktitle>The Structure of Spoken Sinhala, National Institute of Education,</booktitle>
<location>Maharagama.</location>
<contexts>
<context position="4586" citStr="Disanayaka, 1991" startWordPosition="693" endWordPosition="694"> a phoneme in Sinhala. 2 Sinhala Phonemic Inventory and Writing System 2.1 The Sinhala Phonemic Inventory Sinhala is the official language of Sri Lanka and the mother tongue of the majority - 74% of its population. Spoken Sinhala contains 40 segmental phonemes; 14 vowels and 26 consonants as classified below in Table 1 and Table 2 (Karunatillake, 2004). There are two nasalized vowels occurring in two or three words in Sinhala. They are /a~/, /a~:/, /æ~/ and /æ~:/ (Karunatillake, 2004). Spoken Sinhala also has following Diphthongs; /iu/, /eu/, /æu/, /ou/, /au/, /ui/, /ei/, /æi/, /oi/ and /ai/ (Disanayaka, 1991). Front Central Back Short Long Short Long Short Long High i i: u u: Mid e e: \ \: o o: Low æ æ: a a: Table 1. Spoken Sinhala Vowel Classification. Lab.Den. Alv.Ret.Pal. Vel.Glo. Stops Voiceless p t ˇ k Voiced b d Î 9 AffricatesVoiced Voiceless c Ô Pre-nasalized b~ d~ Î~ 9~ voiced stops Nasals m n Jt ˜ Trill r Lateral l Spirants f s ß h Semivowels w j Table 2*. Spoken Sinhala Consonant Classification. A separate sign for vowel /\/ is not provided by the Sinhala writing system. In terms of distribution, the vowel /\/ does not occur at the beginning of a syllable except in the conjugational vari</context>
</contexts>
<marker>Disanayaka, 1991</marker>
<rawString>J.B. Disanayaka. 1991. The Structure of Spoken Sinhala, National Institute of Education, Maharagama.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J B Disanayaka</author>
</authors>
<title>Basaka Mahima: 2, Akuru ha pili,</title>
<date>2000</date>
<journal>S. Godage &amp; Bros., 661, P. D. S. Kularathna Mawatha, Colombo</journal>
<volume>10</volume>
<contexts>
<context position="22451" citStr="Disanayaka, 2000" startWordPosition="3722" endWordPosition="3723"> “අම්ම”(mother) -&gt; /ammə/ -&gt; /amma:/ “අක්ක”(sister) -&gt; /akkə/ -&gt; /akka:/ “ගත්ත”(taken)-&gt; /gattə/ -&gt; /gatta:/ • There were 27 words associated with erroneous conversion of words having the letter “හ”, which corresponds to phoneme /h/. The study revealed this letter shows an unusual behavior in G2P conversion. • The modifier used to denote vowel “ඍ” ◌ෘ” is known as “Geta-pilla”. When this vowel appears as the initial letter of a word, it is pronounced as /ri/ as in “ඍණ” /rinə/ (minus). When the corresponding vowel modifier appears in a middle of a word most of the time it is pronounced as /ru/ (Disanayaka, 2000). eg. “කෘතිය” (book)is pronounced as /krutijə/, “පෘෂ්ඨය” (surface) - /prußˇ\j\/, “උත්කෘෂ්ට” (excellent)-/utkrußˇ\/. But 13 words were found as exceptions of this general rule. In those words, the “◌ෘ” is pronounced as /ur/ rather than /ru/. eg. “පවෘත් ති” (news)- /prəwurti/,“සමෘද්ධි”(prosperity)-/samurdi/, “විවෘත” (opened) - /wiwurtə/. • In general, vowel modifiers “◌ැ” (Adhapilla), “◌ෑ” (Diga Adha-pilla) symbolizes the vowel “ඇ” /æ/ and “ඈ” /æ:/ respectively. eg. consonant “ක්” /k/ combines with vowel modifier “◌ැ” to create “කැ” which is pronounced as /kæ/. Few words were found where this ru</context>
</contexts>
<marker>Disanayaka, 2000</marker>
<rawString>J.B. Disanayaka. 2000. Basaka Mahima: 2, Akuru ha pili, S. Godage &amp; Bros., 661, P. D. S. Kularathna Mawatha, Colombo 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J B Disanayaka</author>
</authors>
<title>Grammar of Contemporary Literary Sinhala - Introduction to Grammar,</title>
<date>1995</date>
<journal>Structure of Spoken Sinhala, S. Godage &amp; Bros., 661, P. D. S. Kularathna Mawatha, Colombo</journal>
<volume>10</volume>
<contexts>
<context position="5951" citStr="Disanayaka, 1995" startWordPosition="942" endWordPosition="943">t. – Retroflex, Pal. – Palatal, Vel. – Velar and Glo. – Glottal. 2.2 The Sinhala Writing System The Sinhala character set has 18 vowels, and 42 consonants as shown in Table 3. Table 3. Sinhala Character Set. Sinhala characters are written left to right in horizontal lines. Words are delimited by a space in general. Vowels have corresponding fullcharacter forms when they appear in an absolute initial position of a word. In other positions, they appear as ‘strokes’ and, are used with consonants to denote vowel modifiers. All vowels except “ඎ” /iru:/, are able to occur in word initial positions (Disanayaka, 1995). The vowel /ə/ and /ə:/ occurs only in loan words of English origin. Since there are no special symbols to represent them, frequently the “අ” vowel is used to symbolize them (Karunatillake, 2004). All consonants occur in word initial position except /ŋ/ and nasals (Disanayaka, 1995). The symbols “ණ”, and “ළ” represent the retroflex nasal /rl/ and the retroflex lateral /l/ respectively. But they are pronounced as their respective alveolar counterparts “න”-/n/ and “ල”-/l/. Similarly, the symbol “ෂ” representing the retroflex sibilant /g/, is pronounced as the palatal sibilant “ශ”-/ß/. The corre</context>
<context position="7531" citStr="Disanayaka, 1995" startWordPosition="1226" endWordPosition="1227">of the consonant preceding it. Similarly, “ය්”-/j/, immediately following consonant can be marked by the symbol “◌ɕ” Vowels and corresponding vowel modifiers (within brackets): අ ආ(◌ා) ඇ(◌ැ) ඈ(◌ෑ) ඉ(◌ි) ඊ(◌ී) උ(◌ු) ඌ(◌ූ) ඍ(◌ෘ) ඎ(◌ෲ) ඏ(◌ෟ) ඐ(◌ෳ) එ(ෙ◌) ඒ(ෙ◌ේ) ඓ(ෛ◌) ඔ(ෙ◌ො) ඕ (ෙ◌ෝ) ඖ(ෙ◌ෞ) Consonants: ක ඛ ග ඝ ඞ ඟ ච ඡ ජ ඣ ඤ ඦ ට ඨ ඩ ඪ ණ ඬ ත ථ ද ධ න ඳ ප ඵ බ භ ම ඹ ය ර ල ව ශ ෂ ස හ ළ ෆ ◌ං ◌ඃ Special symbols: ɡ◌ ◌ɕ ɠ ඥ Inherent vowel remover (Hal marker): ◌් 891 added to the right-hand side of the consonant preceding it (Karunatillake, 2004). “ඏ” /ilu/ and “ඐ” /ilu:/ do not occur in contemporary Sinhala (Disanayaka, 1995). Though there are 60 symbols in Sinhala (Disanayaka, 1995), only 42 symbols are necessary to represent Spoken Sinhala (Karunatillake, 2004). 3 G2P Conversion Approaches The issue of mapping textual content into phonemic content is highly language dependent. Three main approaches of G2P conversion are; use of a pronunciation dictionary, use of well defined language-dependent rules and datadriven methods (El-Imam and Don, 2005). One of the easiest ways of G2P conversion is the use of a lexicon or pronunciation dictionary. A lexicon consists of a large list of words together with their pronuncia</context>
</contexts>
<marker>Disanayaka, 1995</marker>
<rawString>J.B. Disanayaka. 1995. Grammar of Contemporary Literary Sinhala - Introduction to Grammar, Structure of Spoken Sinhala, S. Godage &amp; Bros., 661, P. D. S. Kularathna Mawatha, Colombo 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dutoit</author>
</authors>
<title>An Introduction to Text-toSpeech Synthesis,</title>
<date>1997</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht, Netherlands.</location>
<contexts>
<context position="2292" citStr="Dutoit, 1997" startWordPosition="334" endWordPosition="335"> of words, and assigning prosodic features (eg. phrasing, intonation, stress) to the phonemic string to be spoken. The final process of a TTS system is waveform generation which involves the production of an acoustic digital signal using a particular synthesis approach such as formant synthesis, articulatory synthesis or waveform concatenation (Lemmetty, 1999). The text analysis and linguistic analysis processes together are known as the Natural Language Processing (NLP) component, while the waveform generation process is known as the Digital Signal Processing (DSP) component of a TTS System (Dutoit, 1997). Finding correct pronunciation for a given word is one of the first and most significant tasks in the linguistic analysis process. The component which is responsible for this task in a TTS system is often named the Grapheme-To-Phoneme (G2P), Text-to-Phone or Letter-To-Sound (LTS) conversion module. This module accepts a word and generates the corresponding phonemic transcription. Further, this phonemic transcription can be annotated with appropriate prosodic markers (Syllables, Accents, Stress etc) as well. In this paper, we describe the implementation and evaluation of a G2P conversion model</context>
</contexts>
<marker>Dutoit, 1997</marker>
<rawString>T. Dutoit. 1997. An Introduction to Text-toSpeech Synthesis, Kluwer Academic Publishers, Dordrecht, Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yousif A El-Imam</author>
<author>Zuraidah M Don</author>
</authors>
<title>Rules and Algorithms for Phonetic Transcription of Standard Malay,</title>
<date>2005</date>
<journal>IEICE Trans Inf &amp; Syst,</journal>
<volume>88</volume>
<pages>2354--2372</pages>
<contexts>
<context position="7961" citStr="El-Imam and Don, 2005" startWordPosition="1290" endWordPosition="1293"> remover (Hal marker): ◌් 891 added to the right-hand side of the consonant preceding it (Karunatillake, 2004). “ඏ” /ilu/ and “ඐ” /ilu:/ do not occur in contemporary Sinhala (Disanayaka, 1995). Though there are 60 symbols in Sinhala (Disanayaka, 1995), only 42 symbols are necessary to represent Spoken Sinhala (Karunatillake, 2004). 3 G2P Conversion Approaches The issue of mapping textual content into phonemic content is highly language dependent. Three main approaches of G2P conversion are; use of a pronunciation dictionary, use of well defined language-dependent rules and datadriven methods (El-Imam and Don, 2005). One of the easiest ways of G2P conversion is the use of a lexicon or pronunciation dictionary. A lexicon consists of a large list of words together with their pronunciation. There are several limitations to the use of lexicons. It is practically impossible to construct such to cover the whole vocabulary of a language owing to Zipfian phenomena. Though a large lexicon is constructed, one would face other limitations such as efficient access, memory storage etc. Most lexicons often do not include many proper names, and only very few provide pronunciations for abbreviations and acronyms. Only a</context>
<context position="9937" citStr="El-Imam and Don, 2005" startWordPosition="1616" endWordPosition="1619">ules. In contrast to the above fact, some systems rely on using very large lexicons, together with a set of letter-to-sound conversion rules to deal with words which are not found in the lexicon (Black and Lenzo, 2003). These language and context dependent rules are formulated using phonetic and linguistic knowledge of a particular language. The complexity of devising a set of rules for a particular language is dependent on the degree of correspondence between graphemes and phonemes. For some languages such as English and French, the relationship is complex and require large numbers of rules (El-Imam and Don, 2005; Damper et al., 1998), while some languages such as Urdu (Hussain, 2004), and Hindi (Ramakishnan et al., 2004; Choudhury, 2003) show regular behavior and thus pronunciation can be modeled by defining fairly regular simple rules. Data-driven methods are widely used to avoid tedious manual work involving the above approaches. In these methods, G2P rules are captured by means of various machine learning techniques based on a large amount of training data. Most previous data-driven approaches have been used for English. Widely used data-driven approaches include, Pronunciation by Analogy (PbA), N</context>
<context position="12407" citStr="El-Imam and Don, 2005" startWordPosition="2009" endWordPosition="2012">n literature, with available literature not providing any precise procedure suitable for G2P conversion of contemporary Sinhala. Automating the G2P conversion process is a difficult task due to the ambiguity of choosing between /a/ and /a/. A similar phenomenon is observed in Hindi and Malay as well. In Hindi, the “deletion of the schwa vowel (in some cases)” is successfully 892 solved by using rule based algorithms (Choudhury 2003; Ramakishnan et al., 2004). In Malay, the character ‘e’ can be pronounced as either vowel /e/ or /a/, and rule based algorithms are used to address this ambiguity (El-Imam and Don, 2005). In our research, a set of rules is proposed to disambiguate epenthesis of /a/ and /a/, when associating with consonants. Unlike in Hindi, in Sinhala, the schwa is not deleted, instead always inserted. Hence, this process is named “Schwa Epenthesis” in this paper. 5 Sinhala G2P Conversion Architecture An architecture is proposed to convert Sinhala Unicode text into phonemes encompassing a set of rules to handle schwa epenthesis. The G2P architecture developed for Sinhala is identical to the Hindi G2P architecture (Ramakishnan et al., 2004). The input to the system is normalized Sinhala Unicod</context>
</contexts>
<marker>El-Imam, Don, 2005</marker>
<rawString>Yousif A. El-Imam and Zuraidah M. Don. 2005. Rules and Algorithms for Phonetic Transcription of Standard Malay, IEICE Trans Inf &amp; Syst, E88-D 2354-2372.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarmad Hussain</author>
</authors>
<title>Letter-to-Sound Conversion for Urdu Text-to-Speech System,</title>
<date>2004</date>
<booktitle>Proceedings of Workshop on &amp;quot;Computational Approaches to Arabic Script-based Languages,&amp;quot; COLING 2004,</booktitle>
<pages>74--49</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="10010" citStr="Hussain, 2004" startWordPosition="1630" endWordPosition="1631">ons, together with a set of letter-to-sound conversion rules to deal with words which are not found in the lexicon (Black and Lenzo, 2003). These language and context dependent rules are formulated using phonetic and linguistic knowledge of a particular language. The complexity of devising a set of rules for a particular language is dependent on the degree of correspondence between graphemes and phonemes. For some languages such as English and French, the relationship is complex and require large numbers of rules (El-Imam and Don, 2005; Damper et al., 1998), while some languages such as Urdu (Hussain, 2004), and Hindi (Ramakishnan et al., 2004; Choudhury, 2003) show regular behavior and thus pronunciation can be modeled by defining fairly regular simple rules. Data-driven methods are widely used to avoid tedious manual work involving the above approaches. In these methods, G2P rules are captured by means of various machine learning techniques based on a large amount of training data. Most previous data-driven approaches have been used for English. Widely used data-driven approaches include, Pronunciation by Analogy (PbA), Neural Networks (Damper et al., 1998), and Finite-State-Machines (Jurafsky</context>
</contexts>
<marker>Hussain, 2004</marker>
<rawString>Sarmad Hussain. 2004. Letter-to-Sound Conversion for Urdu Text-to-Speech System, Proceedings of Workshop on &amp;quot;Computational Approaches to Arabic Script-based Languages,&amp;quot; COLING 2004, p. 74-49, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James H Martin</author>
</authors>
<title>Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition.</title>
<date>2000</date>
<journal>Pte. Ltd, Indian Branch, 482 F.I.E. Patparganj, Delhi</journal>
<volume>110</volume>
<pages>092</pages>
<publisher>Pearson Education</publisher>
<contexts>
<context position="9127" citStr="Jurafsky and Martin, 2000" startWordPosition="1478" endWordPosition="1482">rovide pronunciations for abbreviations and acronyms. Only a few lexicons provide distinct entries for morphological productions of words. In addition, pronunciations of some words differ based on the context and their partsof-speech. Further, an enormous effort has to be made to develop a comprehensive lexicon. In practical scenarios, speech synthesizers as well as speech recognizers need to be able to produce the pronunciation of words that are not in the lexicon. Names, morphological productivity and numbers are the three most important cases that cause the use of lexica to be impractical (Jurafsky and Martin, 2000). To overcome these difficulties, rules can be specified on how letters can be mapped to phonemes. In this way, the size of the lexicon can be reduced as only to contain exceptions to the rules. In contrast to the above fact, some systems rely on using very large lexicons, together with a set of letter-to-sound conversion rules to deal with words which are not found in the lexicon (Black and Lenzo, 2003). These language and context dependent rules are formulated using phonetic and linguistic knowledge of a particular language. The complexity of devising a set of rules for a particular language</context>
<context position="10628" citStr="Jurafsky and Martin, 2000" startWordPosition="1720" endWordPosition="1723">n, 2004), and Hindi (Ramakishnan et al., 2004; Choudhury, 2003) show regular behavior and thus pronunciation can be modeled by defining fairly regular simple rules. Data-driven methods are widely used to avoid tedious manual work involving the above approaches. In these methods, G2P rules are captured by means of various machine learning techniques based on a large amount of training data. Most previous data-driven approaches have been used for English. Widely used data-driven approaches include, Pronunciation by Analogy (PbA), Neural Networks (Damper et al., 1998), and Finite-State-Machines (Jurafsky and Martin, 2000). Black et al. (1998) discussed a method for building general letter-to-sound rules suitable for any language, based on training a CART – decision tree. 4 Schwa Epenthesis in Sinhala G2P conversion problems encountered in Sinhala are similar to those encountered in the Hindi language (Ramakishnan et al., 2004). All consonant graphemes in Sinhala are associated with an inherent vowel schwa-/a/ or /a/ which is not represented in orthography. Vowels other than /a/ and /a/ are represented in orthographic text by placing specific vowel modifier diacritics around the consonant grapheme. In the absen</context>
</contexts>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Daniel Jurafsky and James H. Martin. 2000. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition. Pearson Education (Singapore) Pte. Ltd, Indian Branch, 482 F.I.E. Patparganj, Delhi 110 092, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W S Karunatillake</author>
</authors>
<title>An Introduction to Spoken Sinhala, 3rd edn.,</title>
<date>2004</date>
<journal>M.D. Gunasena &amp; Co. ltd., 217, Olcott Mawatha, Colombo</journal>
<volume>11</volume>
<contexts>
<context position="4323" citStr="Karunatillake, 2004" startWordPosition="650" endWordPosition="652">pages 890–897, Sydney, July 2006. c�2006 Association for Computational Linguistics Section 6 gives experimental results and our discussion on it. The work is summarized in the final section. “ඦ”, which symbolizes the consonant sound /Ô~/ exists, it is not considered a phoneme in Sinhala. 2 Sinhala Phonemic Inventory and Writing System 2.1 The Sinhala Phonemic Inventory Sinhala is the official language of Sri Lanka and the mother tongue of the majority - 74% of its population. Spoken Sinhala contains 40 segmental phonemes; 14 vowels and 26 consonants as classified below in Table 1 and Table 2 (Karunatillake, 2004). There are two nasalized vowels occurring in two or three words in Sinhala. They are /a~/, /a~:/, /æ~/ and /æ~:/ (Karunatillake, 2004). Spoken Sinhala also has following Diphthongs; /iu/, /eu/, /æu/, /ou/, /au/, /ui/, /ei/, /æi/, /oi/ and /ai/ (Disanayaka, 1991). Front Central Back Short Long Short Long Short Long High i i: u u: Mid e e: \ \: o o: Low æ æ: a a: Table 1. Spoken Sinhala Vowel Classification. Lab.Den. Alv.Ret.Pal. Vel.Glo. Stops Voiceless p t ˇ k Voiced b d Î 9 AffricatesVoiced Voiceless c Ô Pre-nasalized b~ d~ Î~ 9~ voiced stops Nasals m n Jt ˜ Trill r Lateral l Spirants f s ß </context>
<context position="6147" citStr="Karunatillake, 2004" startWordPosition="976" endWordPosition="977">Character Set. Sinhala characters are written left to right in horizontal lines. Words are delimited by a space in general. Vowels have corresponding fullcharacter forms when they appear in an absolute initial position of a word. In other positions, they appear as ‘strokes’ and, are used with consonants to denote vowel modifiers. All vowels except “ඎ” /iru:/, are able to occur in word initial positions (Disanayaka, 1995). The vowel /ə/ and /ə:/ occurs only in loan words of English origin. Since there are no special symbols to represent them, frequently the “අ” vowel is used to symbolize them (Karunatillake, 2004). All consonants occur in word initial position except /ŋ/ and nasals (Disanayaka, 1995). The symbols “ණ”, and “ළ” represent the retroflex nasal /rl/ and the retroflex lateral /l/ respectively. But they are pronounced as their respective alveolar counterparts “න”-/n/ and “ල”-/l/. Similarly, the symbol “ෂ” representing the retroflex sibilant /g/, is pronounced as the palatal sibilant “ශ”-/ß/. The corresponding aspirated symbols of letters ක, ග, ච, ජ, ට, ඩ, ත, ද, ප, බ namely ඛ, ඝ, ඡ, ඣ, ඪ, ථ, ධ, ඵ, භ respectively are pronounced like the corresponding unaspirates (Karunatillake, 2004). When conso</context>
<context position="7449" citStr="Karunatillake, 2004" startWordPosition="1213" endWordPosition="1214">mediately following a consonant can be marked by the symbol “◌ɡ” added to the bottom of the consonant preceding it. Similarly, “ය්”-/j/, immediately following consonant can be marked by the symbol “◌ɕ” Vowels and corresponding vowel modifiers (within brackets): අ ආ(◌ා) ඇ(◌ැ) ඈ(◌ෑ) ඉ(◌ි) ඊ(◌ී) උ(◌ු) ඌ(◌ූ) ඍ(◌ෘ) ඎ(◌ෲ) ඏ(◌ෟ) ඐ(◌ෳ) එ(ෙ◌) ඒ(ෙ◌ේ) ඓ(ෛ◌) ඔ(ෙ◌ො) ඕ (ෙ◌ෝ) ඖ(ෙ◌ෞ) Consonants: ක ඛ ග ඝ ඞ ඟ ච ඡ ජ ඣ ඤ ඦ ට ඨ ඩ ඪ ණ ඬ ත ථ ද ධ න ඳ ප ඵ බ භ ම ඹ ය ර ල ව ශ ෂ ස හ ළ ෆ ◌ං ◌ඃ Special symbols: ɡ◌ ◌ɕ ɠ ඥ Inherent vowel remover (Hal marker): ◌් 891 added to the right-hand side of the consonant preceding it (Karunatillake, 2004). “ඏ” /ilu/ and “ඐ” /ilu:/ do not occur in contemporary Sinhala (Disanayaka, 1995). Though there are 60 symbols in Sinhala (Disanayaka, 1995), only 42 symbols are necessary to represent Spoken Sinhala (Karunatillake, 2004). 3 G2P Conversion Approaches The issue of mapping textual content into phonemic content is highly language dependent. Three main approaches of G2P conversion are; use of a pronunciation dictionary, use of well defined language-dependent rules and datadriven methods (El-Imam and Don, 2005). One of the easiest ways of G2P conversion is the use of a lexicon or pronunciation dic</context>
<context position="15675" citStr="Karunatillake, 2004" startWordPosition="2573" endWordPosition="2574">contain any vowel modifier or diacritic Hal marker. In the above example, only /n/ and first /j/ are associated with schwa, because other consonants violate the above principle. When schwa is associated with appropriate consonants, the resultant phonemic string for the given example (section 5.1) is; /namjaji/. 5.2 G2P Conversion Rules It is observed that resultant phoneme strings from the above procedure should undergo several modifications in terms of schwa assignments into vowel /a/ or vice versa, in order to obtain the accurate pronunciation of a particular word. Guided by the literature (Karunatillake, 2004), it was noticed that these modifications can be carried out by formulating a set of rules. The G2P rules were formulated with the aid of phonological rules described in the linguistic literature (Karunatillake, 2004) and by a comprehensive word search analysis using the UCSC 893 Sinhala corpus BETA (2005). Some of these existing phonological rules were altered in order to reflect the observations made in the corpus word analysis and to achieve more accurate results. The proposed new set of rules is empirically shown to be effective and can be conveniently implemented using regular expressions</context>
<context position="17974" citStr="Karunatillake, 2004" startWordPosition="2956" endWordPosition="2958">c) If /r/ is preceded by any consonant, followed by /a/ and subsequently followed by any consonant other than /h/, then /a/ should be replaced by /a/. (/[consonant]ra[!h]/-&gt;/[consonant]ra!h]/) (d) If /r/ is preceded by any consonant, followed by /a/ and subsequently followed by /h/, then /a/ is retained. (/[consonant]ra[h]/-&gt;/[consonant]ra[h]/) Rule #3: If any vowel in the set {/a/, /e/, /æ/, /o/, /\/} is followed by /h/ and subsequently /h/ is preceded by schwa, then schwa should replaced by vowel /a/. Rule #4: If schwa is followed by a consonant cluster, the schwa should be replaced by /a/ (Karunatillake, 2004). Rule #5: If /a/ is followed by the word final consonant, it should be replaced by /a/, except in the situations where the word final consonant is /r/, /b/, /ct/ or /t/. Rule #6: At the end of a word, if schwa precedes the phoneme sequence /ji/, the schwa should be replaced by /a/ (Karunatillake, 2004). Rule #7: If the /k/ is followed by schwa, and subsequent phonemes are /r/ or /l/ followed by /u/, then schwa should be replaced by phoneme /a/. (ie. /ka(r|l)u/-&gt;/ka(r|l)u/) Rule #8: Within the given context of following words, /a/ found in phoneme sequence /kal/, (the left hand side of the arr</context>
</contexts>
<marker>Karunatillake, 2004</marker>
<rawString>W.S. Karunatillake. 2004. An Introduction to Spoken Sinhala, 3rd edn., M.D. Gunasena &amp; Co. ltd., 217, Olcott Mawatha, Colombo 11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sami Lemmetty</author>
</authors>
<title>Review of Speech Synthesis Technology,</title>
<date>1999</date>
<tech>MSc. thesis,</tech>
<institution>Helsinki University of Technology.</institution>
<contexts>
<context position="2041" citStr="Lemmetty, 1999" startWordPosition="297" endWordPosition="298">expanding the abbreviations and acronyms. This is done by replacing the nonalphabetic characters, numbers, and punctuation with appropriate text strings depending on the context. The linguistic analysis process involves finding the correct pronunciation of words, and assigning prosodic features (eg. phrasing, intonation, stress) to the phonemic string to be spoken. The final process of a TTS system is waveform generation which involves the production of an acoustic digital signal using a particular synthesis approach such as formant synthesis, articulatory synthesis or waveform concatenation (Lemmetty, 1999). The text analysis and linguistic analysis processes together are known as the Natural Language Processing (NLP) component, while the waveform generation process is known as the Digital Signal Processing (DSP) component of a TTS System (Dutoit, 1997). Finding correct pronunciation for a given word is one of the first and most significant tasks in the linguistic analysis process. The component which is responsible for this task in a TTS system is often named the Grapheme-To-Phoneme (G2P), Text-to-Phone or Letter-To-Sound (LTS) conversion module. This module accepts a word and generates the cor</context>
</contexts>
<marker>Lemmetty, 1999</marker>
<rawString>Sami Lemmetty. 1999. Review of Speech Synthesis Technology, MSc. thesis, Helsinki University of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A G Ramakishnan</author>
<author>Kalika Bali</author>
</authors>
<title>Partha Pratim Talukdar</title>
<date>2004</date>
<booktitle>In 5th ISCA Speech Synthesis Workshop,</booktitle>
<pages>109--114</pages>
<location>Pittsburgh.</location>
<marker>Ramakishnan, Bali, 2004</marker>
<rawString>A.G. Ramakishnan, Kalika Bali, Partha Pratim Talukdar N. and Sridhar Krishna. 2004. Tools for the Development of a Hindi Speech Synthesis System, In 5th ISCA Speech Synthesis Workshop, Pittsburgh. pages 109-114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruvan Weerasinghe</author>
<author>Asanka Wasala</author>
<author>Kumudu Gamage</author>
</authors>
<title>A Rule Based Syllabification Algorithm for Sinhala,</title>
<date>2005</date>
<booktitle>Proceedings of 2nd International Joint Conference on Natural Language Processing (IJCNLP-05),</booktitle>
<pages>438--449</pages>
<location>Jeju Island,</location>
<contexts>
<context position="25780" citStr="Weerasinghe et al. (2005)" startWordPosition="4252" endWordPosition="4255"> been reported for Sinhala grapheme-to-phoneme conversion in the literature. There are no other approaches available for the transcription of Sinhala text that provides a platform for comparison of the proposed rule-based method. The empirical evidence from a wide spectrum Sinhala corpus indicates that the proposed model can account for nearly 98% of cases accurately. The proposed G2P module is fully implemented in Sinhala TTS being developed at Language Technology Research Lab, UCSC. A demonstration tool of the proposed G2P module integrated with Sinhala syllabification algorithm proposed by Weerasinghe et al. (2005) is available for download from: http://www.ucsc.cmb.ac.lk/ltrl/downloads.html Acknowledgement This work has been supported through the PAN Localization Project, (http://www.PANL10n.net) grant from the International Development Research Center (IDRC), Ottawa, Canada, administered through the Center for Research in Urdu Language Processing, National University of Computer and Emerging Sciences, Pakistan. The authors would like to thank Sinhala Language scholars Prof. R.M.W. Rajapaksha, and Prof. J.B. Dissanayake for their invaluable support and advice throughout the study. Special thanks to Dr.</context>
</contexts>
<marker>Weerasinghe, Wasala, Gamage, 2005</marker>
<rawString>Ruvan Weerasinghe, Asanka Wasala and Kumudu Gamage. 2005. A Rule Based Syllabification Algorithm for Sinhala, Proceedings of 2nd International Joint Conference on Natural Language Processing (IJCNLP-05), p. 438-449, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>UCSC Sinhala Corpus BETA</author>
</authors>
<title>Retrieved</title>
<date>2005</date>
<institution>from University of Colombo School of Computing, Language Technology Research Laboratory</institution>
<note>Web site:</note>
<contexts>
<context position="15982" citStr="BETA (2005)" startWordPosition="2624" endWordPosition="2625"> G2P Conversion Rules It is observed that resultant phoneme strings from the above procedure should undergo several modifications in terms of schwa assignments into vowel /a/ or vice versa, in order to obtain the accurate pronunciation of a particular word. Guided by the literature (Karunatillake, 2004), it was noticed that these modifications can be carried out by formulating a set of rules. The G2P rules were formulated with the aid of phonological rules described in the linguistic literature (Karunatillake, 2004) and by a comprehensive word search analysis using the UCSC 893 Sinhala corpus BETA (2005). Some of these existing phonological rules were altered in order to reflect the observations made in the corpus word analysis and to achieve more accurate results. The proposed new set of rules is empirically shown to be effective and can be conveniently implemented using regular expressions. Each rule given below is applied from left to right, and the presented order of the rules is to be preserved. Except for rule #1, rule #5, rule #6 and rule #8, all other rules are applied repeatedly many times to a single word until the conditions presented in the rules are satisfied. Rule #1: If the nuc</context>
</contexts>
<marker>BETA, 2005</marker>
<rawString>UCSC Sinhala Corpus BETA. 2005. Retrieved August 30, 2005, from University of Colombo School of Computing, Language Technology Research Laboratory Web site:</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>