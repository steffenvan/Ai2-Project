<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99745">
Lexical Generalization in CCG Grammar Induction for Semantic Parsing
</title>
<author confidence="0.992518">
Tom Kwiatkowski∗ Luke Zettlemoyer† Sharon Goldwater∗ Mark Steedman∗
</author>
<email confidence="0.780501">
t.m.kwiatkowksi@sms.ed.ac.uk lsz@cs.washington.edu sgwater@inf.ed.ac.uk steedman@inf.ed.ac.uk
</email>
<affiliation confidence="0.9990335">
∗School of Informatics †Computer Science &amp; Engineering
University of Edinburgh University of Washington
</affiliation>
<address confidence="0.760639">
Edinburgh, EH8 9AB, UK Seattle, WA 98195
</address>
<sectionHeader confidence="0.988799" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999909315789474">
We consider the problem of learning fac-
tored probabilistic CCG grammars for seman-
tic parsing from data containing sentences
paired with logical-form meaning representa-
tions. Traditional CCG lexicons list lexical
items that pair words and phrases with syntac-
tic and semantic content. Such lexicons can
be inefficient when words appear repeatedly
with closely related lexical content. In this
paper, we introduce factored lexicons, which
include both lexemes to model word meaning
and templates to model systematic variation in
word usage. We also present an algorithm for
learning factored CCG lexicons, along with a
probabilistic parse-selection model. Evalua-
tions on benchmark datasets demonstrate that
the approach learns highly accurate parsers,
whose generalization performance benefits
greatly from the lexical factoring.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9983134">
Semantic parsers automatically recover representa-
tions of meaning from natural language sentences.
Recent work has focused on learning such parsers
directly from corpora made up of sentences paired
with logical meaning representations (Kate et al.,
2005; Kate and Mooney, 2006; Wong and Mooney,
2006, 2007; Zettlemoyer and Collins, 2005, 2007;
Lu et al., 2008; Kwiatkowski et al., 2010).
For example, in a flight booking domain we
might have access to training examples such as:
</bodyText>
<note confidence="0.475702">
Sentence: I want flights from Boston
Meaning: λx. f light(x) ∧ f rom(x,bos)
</note>
<page confidence="0.977293">
1512
</page>
<bodyText confidence="0.999903571428571">
and the goal is to learn a grammar that can map new,
unseen, sentences onto their corresponding mean-
ings, or logical forms.
One approach to this problem has developed al-
gorithms for leaning probabilistic CCG grammars
(Zettlemoyer and Collins, 2005, 2007; Kwiatkowski
et al., 2010). These grammars are well-suited to the
task of semantic parsing, as they closely link syn-
tax and semantics. They can be used to model a
wide range of complex linguistic phenomena and are
strongly lexicalized, storing all language-specific
grammatical information directly with the words in
the lexicon. For example, a typical learned lexicon
might include entries such as:
</bodyText>
<listItem confidence="0.9993229">
(1) flight ` N :λx.flight(x)
(2) flight ` N/(S|NP):λ fλx. flight(x) ∧ f (x)
(3) flight ` N\N :λ fλx. flight(x) ∧ f (x)
(4) fare ` N :λx.cost(x)
(5) fare ` N/(S|NP):λ fλx.cost(x) ∧ f (x)
(6) fare ` N\N :λ fλx.cost(x) ∧ f (x)
(7) Boston ` NP:bos
(8) Boston ` N\N :λ fλx. f rom(x,bos) ∧ f (x)
(9) New York ` NP:nyc
(10) New York ` N\N :λ fλx. f rom(x,nyc) ∧ f (x)
</listItem>
<bodyText confidence="0.9993543">
Although lexicalization of this kind is useful
for learning, as we will see, these grammars can
also suffer from sparsity in the training data, since
closely related entries must be repeatedly learned for
all members of a certain class of words. For exam-
ple, the list above shows a selection of lexical items
that would have to be learned separately.
In this list, the word “flight” is paired with the
predicate flight in three separate lexical items which
are required for different syntactic contexts. Item
</bodyText>
<note confidence="0.9516165">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1512–1523,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.998122413793104">
(1) has the standard N category for entries of this are required to construct the final meaning represen-
type, item (2) allows the use of the word “flight” tations are not explicitly labeled in the training data.
with that-less relative clauses such as “flight depart- Instead, we model them with hidden variables and
ing Boston”, and item (3) is useful for phrases with develop an online learning approach that simultane-
unconventional word order such as “from Boston ously estimates the parameters of a log-linear pars-
flight to New York”. Representing these three lexi- ing model, while inducing the factored lexicon.
cal items separately is inefficient, since each word of We evaluate the approach on the benchmark Atis
this class (such as “fare”) will require three similarly and GeoQuery domains. This is a challenging setup,
structured lexical entries differing only in predicate since the GeoQuery data has complex meaning rep-
name. There may also be systemtatic semantic vari- resentations and sentences in multiple languages,
ation between entries for a certain class of words. while the Atis data contains spontaneous, unedited
For example, in (6) “Boston” is paired with the con- text that can be difficult to analyze with a formal
stant bos that represents its meaning. However, item grammar representation. Our approach achieves at
(7) also adds the predicate from to the logical form. or near state-of-the-art recall across all conditions,
This might be used to analyse somewhat elliptical, despite having no English or domain-specific infor-
unedited sentences such as “Show me flights Boston mation built in. We believe that ours is the only sys-
to New York,” which can be challenging for seman- tem of sufficient generality to run with this degree of
tic parsers (Zettlemoyer and Collins, 2007). success on all of these datasets.
This paper builds upon the insight that a large pro- 2 Related work
portion of the variation between lexical items for There has been significant previous work on learn-
a given class of words is systematic. Therefore it ing semantic parsers from training sentences la-
should be represented once and applied to a small set belled with logical form meaning representations.
of basic lexical units. 1 We develop a factored lex- We extend a line of research that has addressed
icon that captures this insight by distinguishing lex- this problem by developing CCG grammar induc-
emes, which pair words with logical constants, from tion techniques. Zettlemoyer and Collins (2005,
lexical templates, which map lexemes to full lexical 2007) presented approaches that use hand gener-
items. As we will see, this can lead to a significantly ated, English-language specific rules to generate lex-
more compact lexicon that can be learned from less ical items from logical forms as well as English
data. Each word or phrase will be associated with a specific type-shifting rules and relaxations of the
few lexemes that can be combined with a shared set CCG combinators to model spontaneous, unedited
of general templates. sentences. Zettlemoyer and Collins (2009) extends
We develop an approach to learning factored, this work to the case of learning in context depen-
probabilistic CCG grammars for semantic pars- dent environments. Kwiatkowski et al. (2010) de-
ing. Following previous work (Kwiatkowski et al., scribed an approach for language-independent learn-
2010), we make use of a higher-order unification ing that replaces the hand-specified templates with
learning scheme that defines a space of CCG gram- a higher-order-unification-based lexical induction
mars consistent with the (sentence, logical form) method, but their approach does not scale well to
training pairs. However, instead of constructing challenging, unedited sentences. The learning ap-
fully specified lexical items for the learned grammar, proach we develop for inducing factored lexicons is
we automatically generate sets of lexemes and lexi- also language independent, but scales well to these
cal templates to model each example. This is a dif- challenging sentences.
ficult learning problem, since the CCG analyses that There have been a number of other approaches
for learning semantic parsers, including ones based
on machine translation techniques (Papineni et al.,
1997; Ramaswamy and Kleindienst, 2000; Wong
and Mooney, 2006), parsing models (Miller et al.,
1996; Ge and Mooney, 2006; Lu et al., 2008), in-
1A related tactic is commonly used in wide-coverage CCG
parsers derived from treebanks, such as work by Hockenmaier
and Steedman (2002) and Clark and Curran (2007). These
parsers make extensive use of category-changing unary rules,
to avoid data sparsity for systematically related categories (such
as those related by type-raising). We will automatically learn to
represent these types of generalizations in the factored lexicon.
1513
ductive logic programming algorithms (Zelle and
Mooney, 1996; Thompson and Mooney, 2002; Tang
and Mooney, 2000), probabilistic automata (He and
Young, 2005, 2006), and ideas from string kernels
and support vector machines (Kate and Mooney,
2006; Nguyen et al., 2006).
More recent work has focused on training se-
mantic parsers without supervision in the form of
logical-form annotations. Clarke et al. (2010) and
Liang et al. (2011) replace semantic annotations in
the training set with target answers which are more
easily available. Goldwasser et al. (2011) present
work on unsupervised learning of logical form struc-
ture. However, all of these systems require signifi-
cantly more domain and language specific initializa-
tion than the approach presented here.
Other work has learnt semantic analyses from text
in the context of interactions in computational envi-
ronments (Branavan et al. (2010), Vogel and Juraf-
sky (2010)); text grounded in partial observations of
a world state (Liang et al., 2009); and from raw text
alone (Poon and Domingos, 2009, 2010).
There is also related work that uses the CCG
grammar formalism. Clark and Curran (2003)
present a method for learning the parameters of a
log-linear CCG parsing model from fully annotated
normal–form parse trees. Watkinson and Manand-
har (1999) describe an unsupervised approach for
learning syntactic CCG lexicons. Bos et al. (2004)
present an algorithm for building semantic represen-
tations from CCG parses but requires fully–specified
CCG derivations in the training data.
</bodyText>
<sectionHeader confidence="0.902986" genericHeader="introduction">
3 Overview of the Approach
</sectionHeader>
<bodyText confidence="0.999918647058823">
Here we give a formal definition of the problem and
an overview of the learning approach.
Problem We will learn a semantic parser that
takes a sentences x and returns a logical form z repre-
senting its underlying meaning. We assume we have
input data {(xi,zi)|i = 1...n} containing sentences
xi and logical forms zi, for example xi =“Show me
flights to Boston” and zi = λx. flight(x)nto(x,bos).
Model We will represent the parser as a factored,
probabilistic CCG (PCCG) grammar. A traditional
CCG lexical item would fully specify the syntax and
semantics for a word (reviewed in Section 4). For
example, Boston �- NP : bos represents the entry for
the word “Boston” with syntactic category NP and
meaning represented by the constant bos. Where a
lexicon would usually list lexical items such as this,
we instead use a factored lexicon (L,T) containing:
</bodyText>
<listItem confidence="0.986332222222222">
• A list of lexemes L. Each lexeme pairs a word
or phrase with a list of logical constants that can
be used to construct its meaning. For example,
one lexeme might be (Boston,[bos]).
• A list of lexical templates T. Each template
takes a lexeme and maps it on to a full lexical
item. For example, there is a single template
that can map the lexeme above to the final lex-
ical entry Boston �- NP : bos.
</listItem>
<bodyText confidence="0.9998615">
We will make central use of this factored repre-
sentation to provide a more compact representation
of the lexicon that can be learned efficiently.
The factored PCCG will also contain a parameter
vector, θ, that defines a log-linear distribution over
the possible parses y, conditioned on the sentence x.
Learning Our approach for learning factored PC-
CGs extends the work of Kwiatkowski et al. (2010),
as reviewed in Section 7. Specifically, we modify
the lexical learning, to produce lexemes and tem-
plates, as well as the feature space of the model, but
reuse the existing parameter estimation techniques
and overall learning cycle, as described in Section 7.
We present the complete approach in three parts
by describing the factored representation of the lex-
icon (Section 5), techniques for proposing potential
new lexemes and templates (Section 6), and finally
a complete learning algorithm (Section 7). How-
ever, the next section first reviews the required back-
ground on semantic parsing with CCG.
</bodyText>
<sectionHeader confidence="0.999458" genericHeader="method">
4 Background
</sectionHeader>
<subsectionHeader confidence="0.999511">
4.1 Lambda Calculus
</subsectionHeader>
<bodyText confidence="0.9998645">
We represent the meanings of sentences, words
and phrases with logical expressions that can con-
tain constants, quantifiers, logical connectors and
lambda abstractions. We construct the meanings of
sentences from the meanings of words and phrases
using lambda-calculus operations. We use a version
of the typed lambda calculus (Carpenter, 1997), in
which the basic types include e, for entities; t, for
truth values; and i for numbers. We also have func-
tion types that are assigned to lambda expressions.
</bodyText>
<page confidence="0.990287">
1514
</page>
<bodyText confidence="0.999061">
The expression λx.flight(x) takes an entity and re-
turns a truth value, and has the function type he,ti.
</bodyText>
<subsectionHeader confidence="0.984991">
4.2 Combinatory Categorial Grammar
</subsectionHeader>
<bodyText confidence="0.9985826">
CCG (Steedman, 1996, 2000) is a linguistic formal-
ism that tightly couples syntax and semantics, and
can be used to model a wide range of language phe-
nomena. A traditional CCG grammar includes a lex-
icon Λ with entries like the following:
</bodyText>
<equation confidence="0.974803">
flights ` N :λx. f light(x)
to ` (N\N)/NP:λy.λ f .λx. f (x) ∧to(x,y)
Boston ` NP:bos
</equation>
<bodyText confidence="0.998191692307692">
where each lexical item w`X : h has words w, a syn-
tactic category X, and a logical form h. For the first
example, these are “flights,” N, and λx. flight(x).
In this paper, we introduce a new way of represent-
ing lexical items as (lexeme, template) pairs, as de-
scribed in section 5.
CCG syntactic categories may be atomic (such
as S or NP) or complex (such as (N\N)/NP)
where the slash combinators encode word order
information. CCG uses a small set of combinatory
rules to build syntactic parses and semantic repre-
sentations concurrently. Two example combinatory
rules are forward (&gt;) and backward (&lt;) application:
</bodyText>
<equation confidence="0.98254">
X/Y : f Y : g ⇒ X : f (g) (&gt;)
Y : g X\Y : f ⇒ X : f (g) (&lt;)
</equation>
<bodyText confidence="0.967791">
These rules apply to build syntactic and semantic
derivations under the control of the word order infor-
mation encoded in the slash directions of the lexical
entries. For example, given the lexicon above, the
phrase “flights to Boston” can be parsed to produce:
flights to Boston
These rules allow a relaxed notion of constituency
which helps limit the number of distinct CCG lexical
items required.
To the standard forward and backward slashes of
CCG we also add a vertical slash for which the di-
rection of application is underspecified. We shall see
examples of this in Section 10.
</bodyText>
<subsectionHeader confidence="0.999029">
4.3 Probabilistic CCGs
</subsectionHeader>
<bodyText confidence="0.999950285714286">
Due to ambiguity in both the CCG lexicon and the
order in which combinators are applied, there will
be many parses for each sentence. We discriminate
between competing parses using a log-linear model
which has a feature vector φ and a parameter vector
θ. The probability of a parse y that returns logical
form z, given a sentence x is defined as:
</bodyText>
<equation confidence="0.997061">
eθ·φ(x,y,z)
P(y,z|x;θ,Λ) = (1)
∑(y0,z0) eθ·φ(x,y0,z0)
</equation>
<bodyText confidence="0.935196714285714">
Section 8 fully defines the set of features used in the
system presented. The most important of these con-
trol the generation of lexical items from (lexeme,
template) pairs. Each (lexeme, template) pair used
in a parse fires three features as we will see in more
detail later.
The parsing, or inference, problem done at test
time requires us to find the most likely logical form
z given a sentence x, assuming the parameters θ and
lexicon Λ are known:
f (x) = argmax p(z|x;θ,Λ) (2)
z
where the probability of the logical form is found by
summing over all parses that produce it:
</bodyText>
<equation confidence="0.947272375">
p(z|x;θ,Λ) = ∑ p(y,z|x;θ,Λ) (3)
y
N (N\N)/NP NP
λx. f light(x) λyλ f λx. f (x) ∧to(x,y) bos
(N\N) &gt;
λ f λx. f (x) ∧to(x,bos)
N
λx. f light(x) ∧to(x,bos)
</equation>
<bodyText confidence="0.87220325">
where each step in the parse is labeled with the com-
binatory rule (− &gt; or − &lt;) that was used.
CCG also includes combinatory rules of forward
(&gt; B) and backward (&lt; B) composition:
</bodyText>
<construct confidence="0.276744">
X/Y : f Y/Z : g ⇒ X/Z : λx.f(g(x)) (&gt; B)
Y\Z : g X\Y : f ⇒ X\Z : λx. f(g(x)) (&lt; B)
</construct>
<bodyText confidence="0.97658575">
In this approach the distribution over parse trees y
is modeled as a hidden variable. The sum over
parses in Eq. 3 can be calculated efficiently using
the inside-outside algorithm with a CKY-style pars-
ing algorithm.
To estimate the parameters themselves, we
use stochastic gradient updates (LeCun et al.,
1998). Given a set of n sentence-meaning pairs
{(xi,zi) : i = 1...n}, we update the parameters θ it-
eratively, for each example i, by following the local
gradient of the conditional log-likelihood objective
&lt;
</bodyText>
<page confidence="0.735409">
1515
</page>
<bodyText confidence="0.99895">
Oi = logP(zi|xi;θ,Λ). The local gradient of the in-
dividual parameter θj associated with feature φj and
training instance (xi,zi) is given by:
</bodyText>
<equation confidence="0.9799125">
= Ep(y|xi,zi;θ,Λ)[φj(xi,y,zi)] (4)
−Ep(y,z|xi;θ,Λ)[φj(xi,y,z)]
</equation>
<bodyText confidence="0.907171857142857">
As with Eq. 3, all of the expectations in Eq. 4 are
calculated through the use of the inside-outside al-
gorithm on a pruned parse chart. For a sentence
of length m, each parse chart span is pruned using
2
a beam width proportional to m3 , to allow larger
beams for shorter sentences.
</bodyText>
<sectionHeader confidence="0.995433" genericHeader="method">
5 Factored Lexicons
</sectionHeader>
<bodyText confidence="0.999739333333333">
A factored lexicon includes a set L of lexemes and
a set T of lexical templates. In this section, we for-
mally define these sets, and describe how they are
used to build CCG parses. We will use a set of lex-
ical items from our running example to discuss the
details of how the following lexical items:
</bodyText>
<listItem confidence="0.9608414">
(1) flight ` N :λx.flight(x)
(2) flight ` N/(S|NP):λ fλx. f light(x) ∧ f (x)
(6) Boston ` NP:bos
(7) Boston ` N\N :λ fλx. f rom(x,bos) ∧ f (x)
are constructed from specific lexemes and templates.
</listItem>
<subsectionHeader confidence="0.893429">
5.1 Lexemes
</subsectionHeader>
<bodyText confidence="0.999990375">
A lexeme (w,~c) pairs a word sequence w with an
ordered list of logical constants c~ = [c1 ...cm]. For
example, item (1) and (2) above would come from
a single lexeme (flight,[flight]). Similar lexemes
would be represented for other predicates, for exam-
ple (fare,[cost]). Lexemes also can contain multiple
constants, for example (cheapest,[argmin,cost]),
which we will see more examples of later.
</bodyText>
<subsectionHeader confidence="0.999553">
5.2 Lexical Templates
</subsectionHeader>
<bodyText confidence="0.9994855">
A lexical template takes a lexeme and produces a
lexical item. Templates have the general form
</bodyText>
<equation confidence="0.476187">
λ(ω,~v).[ω `X :h~v]
</equation>
<bodyText confidence="0.998898076923077">
where h~v is a logical expression that contains vari-
ables from the list ~v. Applying this template to the
input lexeme (w,~c) gives the full lexical item w `
X :h where the variable ω has been replaced with the
wordspan w and the logical form h has been created
by replacing each of the variables in~v with the coun-
terpart constant from ~c. For example, the lexical
item (6) above would be constructed from the lex-
eme (Boston,[bos]) using the template λ(ω,~v).[ω `
NP:v1]. Items (1) and (2) would both be constructed
from the single lexeme (flight,[flight]) with the two
different templates λ(ω,~v).[ω ` N : λx.v1(x)] and
λ(ω,~v).[ω `N/(S|NP): λ fλx.v1(x) ∧ f (x)]
</bodyText>
<subsectionHeader confidence="0.999707">
5.3 Parsing with a Factored Lexicon
</subsectionHeader>
<bodyText confidence="0.99943725">
In general, there can by many different (lexeme,
template) pairs that produce the same lexical item.
For example, lexical item (7) in our running ex-
ample above can be constructed from the lexemes
(Boston,[bos]) and (Boston,[from,bos]), given ap-
propriate templates.
To model this ambiguity, we include the selection
of a (lexeme, template) pair as a decision to be made
while constructing a CCG parse tree. Given the lex-
ical item produced by the chosen lexeme and tem-
plate, parsing continues with the traditional combi-
nators, as reviewed in Section 4.2. This direct inte-
gration allows for features that signal which lexemes
and templates have been used while also allowing
for well defined marginal probabilities, by summing
over all ways of deriving a specific lexical item.
</bodyText>
<sectionHeader confidence="0.966882" genericHeader="method">
6 Learning Factored Lexicons
</sectionHeader>
<bodyText confidence="0.9999648">
To induce factored lexicons, we will make use of two
procedures, presented in this section, that factor lexi-
cal items into lexemes and templates. Section 7 will
describe how this factoring operation is integrated
into the complete learning algorithm.
</bodyText>
<subsectionHeader confidence="0.997062">
6.1 Maximal Factorings
</subsectionHeader>
<bodyText confidence="0.9532273125">
Given a lexical item l of the form w `X : h with
words w, a syntactic category X, and a logical form
h, we define the maximal factoring to be the unique
(lexeme, template) pair that can be used to recon-
struct l and includes all of the constants of h in
the lexeme (listed in a fixed order based on an
ordered traversal of h). For example, the maxi-
mal factoring for the lexical item Boston ` NP :
bos is the pair we saw before: (Boston,[bos]) and
λ(ω,~v).[ω ` NP : v1]. Similarly, the lexical item
Boston ` N\N : λ f .λx. f (x) ∧ from(x,bos) would
be factored to produce (Boston,[from,bos]) and
λ(ω,~v).[ω ` N\N :λ f.λx.f(x)∧v1(x,v2)].
As we will see in Section 7, this notion of factor-
∂Oi
∂θj
</bodyText>
<page confidence="0.807149">
1516
</page>
<bodyText confidence="0.999462166666667">
ing can be directly incorporated into existing algo-
rithms that learn CCG lexicons. When the original
algorithm would have added an entry l to the lexi-
con, we can instead compute the factoring of l and
add the corresponding lexeme and template to the
factored lexicon.
</bodyText>
<subsectionHeader confidence="0.992648">
6.2 Introducing Templates with Content
</subsectionHeader>
<bodyText confidence="0.98180827027027">
Maximal factorings, as just described, provide for
significant lexical generalization but do not handle
all of the cases needed to learn effectively. For
instance, the maximal split for the item Boston `
N\N : λ f.λx. f (x) ∧ from(x,bos) would introduce
the lexeme (Boston,[from,bos]), which is subopti-
mal since each possible city would need a lexeme
of this type, with the additional from constant in-
cluded. Instead, we would ideally like to learn the
lexeme (Boston,[bos]) and have a template that in-
troduces the from constant. This would model the
desired generalization with a single lexeme per city.
In order to permit the introduction of extra con-
stants into lexical items, we allow the creation of
templates that contain logical constants through par-
tial factorings. For instance, the template below can
introduce the predicate from
λ(ω,v).[ω `N\N :λ f.λx.f(x)∧ from(x,v1)]
The use of templates to introduce extra semantic
constants into a lexical item is similar to, but more
general than, the English-specific type-shifting rules
used in Zettlemoyer and Collins (2007), which were
introduced to model spontaneous, unedited text.
They are useful, as we will see, in learning to re-
cover semantic content that is implied, but not ex-
plicitly stated, such as our original motivating phrase
“flights Boston to New York.”
To propose templates which introduce semantic
content, during learning, we build on the intuition
that we need to recover from missing words, such
as in the example above. In this scenario, there
should also be other sentences that actually include
the word, in our example this would be something
like “flights from Boston.” We will also assume
that we have learned a good factored lexicon for the
complete example that could produce the parse:
flights from Boston
</bodyText>
<equation confidence="0.7202758">
N (N\N)/NP NP
λx. f light(x) λyλ fλx. f (x) ∧ f rom(x,y) bos
&gt;
N
λx. f light(x) ∧ from(x,bos)
</equation>
<bodyText confidence="0.999609235294118">
Given analyses of this form, we introduce new
templates that will allow us to recover from miss-
ing words, for example if “from” was dropped. We
identify commonly occurring nodes in the best parse
trees found during training, in this case the non-
terminal spanning “from Boston,” and introduce
templates that can produce the nonterminal, even if
one of the words is missing. Here, this approach
would introduce the desired template λ(ω,v).[ω `
N\N : λ f .λx. f (x) ∧ from(x,v1)] for mapping the
lexeme (Boston,[bos]) directly to the intermediate
structure.
Not all templates introduced this way will model
valid generalizations. However, we will incorporate
them into a learning algorithm with indicator fea-
tures that can be weighted to control their use. The
next section presents the complete approach.
</bodyText>
<sectionHeader confidence="0.917506" genericHeader="method">
7 Learning Factored PCCGs
</sectionHeader>
<bodyText confidence="0.999808285714286">
Our Factored Unification Based Learning (FUBL)
method extends the UBL algorithm (Kwiatkowski
et al., 2010) to induce factored lexicons, while also
simultanously estimating the parameters of a log-
linear CCG parsing model. In this section, we first
review the NEW-LEX lexical induction procedure
from UBL, and then present the FUBL algorithm.
</bodyText>
<subsectionHeader confidence="0.887344">
7.1 Background: NEW-LEX
</subsectionHeader>
<bodyText confidence="0.999806538461539">
NEW-LEX generates lexical items by splitting and
merging nodes in the best parse tree of each training
example. Each parse node has a CCG category X : h
and a sequence of words w that it spans. We will
present an overview of the approach using the run-
ning example with the phrase w =“in Boston” and
the category X : h = S\NP : λx.loc(x,bos), which is
of the type commonly seen during learning. The
splitting procedure is a two step process that first
splits the logical form h, then splits the CCG syn-
tactic category X and finally splits the string w.
The first step enumerates all possible splits of
the logical form h into a pair of new expressions
</bodyText>
<equation confidence="0.575923">
(N\N)
λ fλx. f (x) ∧ f rom(x,bos)
&lt;
</equation>
<page confidence="0.899261">
1517
</page>
<bodyText confidence="0.958704181818182">
(f,g) that can be used to reconstruct h by ei-
ther function application (h = f (g)) or composition
(h = λx. f (g(x))). For example, one possible split is:
(f = λy.λx.loc(x,y) , g = bos)
which corresponds to the function application case.
The next two steps enumerate all ways of splitting
the syntactic category X and words w to introduce
two new lexical items which can be recombined with
CCG combinators (application or composition) to
recreate the original parse node X : h spanning w. In
our example, one possibility would be:
</bodyText>
<equation confidence="0.56397">
(in`(S\NP)/NP:λy.λx.loc(x,y) , Boston`NP:bos)
</equation>
<bodyText confidence="0.999350166666667">
which could be recombined with the forward appli-
cation combinator from Section 4.2.
To assign categories while splitting, the grammar
used by NEW-LEX only uses two atomic syntac-
tic categories S and NP. This allows NEW-LEX to
make use of a direct mapping from semantic type
to syntactic category when proposing syntactic cate-
gories. In this schema, the standard syntactic cat-
egory N is replaced by the category S|NP which
matches the type he,ti and uses the vertical slash in-
troduced in Section 4.2. We will see categories such
as this in the evaluation.
</bodyText>
<subsectionHeader confidence="0.988789">
7.2 The FUBL Algorithm
</subsectionHeader>
<bodyText confidence="0.905029228571429">
Figure 1 shows the FUBL learning algorithm. We
assume training data {(xi,zi) : i = 1...n} where each
example is a sentence xi paired with a logical form
zi. The algorithm induces a factored PCCG, includ-
ing the lexemes L, templates T, and parameters θ.
The algorithm is online, repeatedly performing
both lexical expansion (Step 1) and a parameter up-
date (Step 2) for each training example. The over-
all approach is closely related to the UBL algo-
rithm (Kwiatkowski et al., 2010), but includes exten-
sions for updating the factored lexicon, as motivated
in Section 6.
Initialization The model is initialized with a fac-
tored lexicon as follows. MAX-FAC is a function
that takes a lexical item l and returns the maximal
factoring of it, that is the unique, maximal (lexeme,
template) pair that can be combined to construct l,
as described in Section 6.1. We apply MAX-FAC to
each of the training examples (xi,zi), creating a sin-
gle way of producing the desired meaning zi from a
Inputs: Training set {(xi,zi) : i = 1...n} where each
example is a sentence xi paired with a logical form
zi. Set of entity name lexemes Le. Number of itera-
tions J. Learning rate parameter α0 and cooling rate
parameter c. Empty lexeme set L. Empty template
set T.
Definitions: NEW-LEX(y) returns a set of new lex-
ical items from a parse y as described in Sec-
tion 7.1. MAX-FAC(l) generates a (lexeme, tem-
plate) pair from a lexical item l. PART-FAC(y)
generates a set of templates from parse y. Both of
these are described in Section 7.2. The distributions
p(y|x,z;θ,(L,T)) and p(y,z|x;θ,(L,T)) are defined
by the log-linear model described in Section 4.3.
Initialization:
</bodyText>
<listItem confidence="0.997296666666667">
• For i = 1...n
• (ψ,π) = MAX-FAC(xi ` S : zi)
• L = L∪ψ , T = T ∪π
• Set L = L∪Le.
• Initialize θ using coocurrence statistics, as de-
scribed in Section 8.
</listItem>
<equation confidence="0.6175">
Algorithm:
Fort = 1...J,i = 1...n :
Step 1: (Add Lexemes and Templates)
</equation>
<listItem confidence="0.918915727272727">
• Let y∗ = argmaxy p(y|xi,zi;θ,(L,T))
• For l ∈ NEW-LEX(y∗)
• (ψ,π) = MAX-FAC(l)
• L = L∪ψ , T = T ∪π
• II = PART-FAC(y∗) , T = T ∪ II
Step 2: (Update Parameters)
• Let γ = α0
1+c×k where k = i+t × n.
• Let o = Ep(y|xi,zi;θ,(L,T))[φ(xi,y,zi)]
−Ep(y,z|xi;θ,(L,T))[φ(xi,y,z)]
• Set θ = θ +γo
</listItem>
<figureCaption confidence="0.963627">
Output: Lexemes L, templates T, and parameters θ.
Figure 1: The FUBL learning algorithm.
</figureCaption>
<bodyText confidence="0.967960444444444">
lexeme containing all of the words in xi. The lex-
emes and templates created in this way provide the
initial factored lexicon.
Step 1 The first step of the learning algorithm in
Figure 1 adds lexemes and templates to the fac-
tored model given by performing manipulations on
the highest scoring correct parse y∗ of the current
training example (xi,zi). First the NEW-LEX pro-
cedure is run on y∗ as described in Section 6.1 to
</bodyText>
<page confidence="0.982812">
1518
</page>
<bodyText confidence="0.999511928571428">
generate new lexical items. We then use the func-
tion MAX-FAC to create the maximal factorings of
each of these new lexical items as described in Sec-
tion 6 and these are added to the factored represen-
tation of the lexicon. New templates can also be in-
troduced through partial factorings of internal parse
nodes as described in Section 6.2. These templates
are generated by using the function PART-FAC to
abstract over the wordspan and a subset of the con-
stants contained in the internal parse nodes of y∗.
This step allows for templates that introduce new
semantic content to model elliptical language, as de-
scribed in Section 6.2.
Step 2 The second step does a stochastic gradient
descent update on the parameters θ used in the pars-
ing model. This update is described in Section 4.3
Discussion The FUBL algorithm makes use of a
direct online approach, where lexemes and tem-
plates are introduced in place while analyzing spe-
cific sentences. In general, this will overgeneralize;
not all ways of combining lexemes and templates
will produce high quality lexical items. However,
the overall approach includes features, presented in
Section 8, that can be used to learn which ones are
best in practice. The complete algorithm iterates be-
tween adding new lexical content and updating the
parameters of the parsing model with each proce-
dure guiding the other.
</bodyText>
<sectionHeader confidence="0.996832" genericHeader="method">
8 Experimental setup
</sectionHeader>
<bodyText confidence="0.999006421875">
Data Sets We evaluate on two benchmark seman-
tic parsing datasets: GeoQuery, which is made up of
natural language queries to a database of geograph-
ical information; and Atis, which contains natural
language queries to a flight booking system. The
Geo880 dataset has 880 (English-sentence, logical-
form) pairs split into a training set of 600 pairs and
a test set of 280. The Geo250 data is a subset of
the Geo880 sentences that have been translated into
Japanese, Spanish and Turkish as well as the original
English. We follow the standard evaluation proce-
dure for Geo250, using 10-fold cross validation ex-
periments with the same splits of the data as Wong
and Mooney (2007). The Atis dataset contains 5410
(sentence, logical-form) pairs split into a 4480 ex-
ample training set, a 480 example development set
and a 450 example test set.
Evaluation Metrics We report exact match Re-
call (percentage of sentences for which the correct
logical-form was returned), Precision (percentage of
returned logical-forms that are correct) and F1 (har-
monic mean of Precision and Recall). For Atis we
also report partial match Recall (percentage of cor-
rect literals returned), Precision (percentage of re-
turned literals that are correct) and F1, computed as
described by Zettlemoyer and Collins (2007).
Features We introduce two types of features to
discriminate between parses: lexical features and
logical-form features.
Lexical features fire on the lexemes and templates
used to build the lexical items used in a parse. For
each (lexeme,template) pair used to create a lexi-
cal item we have indicator features φl for the lex-
eme used, φt for the template used, and φ(l,t) for the
pair that was used. We assign the features on lexi-
cal templates a weight of 0.1 to prevent them from
swamping the far less frequent but equally informa-
tive lexeme features.
Logical-form features are computed on the
lambda-calculus expression z returned at the root of
the parse. Each time a predicate p in z takes an
argument a with type Ty(a) in position i, it trig-
gers two binary indicator features: φ(p,a,i) for the
predicate-argument relation; and φ(p,Ty(a),i) for the
predicate argument-type relation. Boolean opera-
tor features look at predicates that occurr together
in conjunctions and disjunctions. For each variable
vi that fills argument slot i in two conjoined pred-
icates p1 and p2 we introduce a binary indicator
feature φconj(i,p1,p2). We introduce similar features
φdisj(i,p1,p2) for variables vi that are shared by predi-
cates in a disjunction.
Initialization The weights for lexeme features are
initialized according to coocurrance statistics be-
tween words and logical constants. These are esti-
mated with the Giza++ (Och and Ney, 2003) imple-
mentation of IBM Model 1. The initial weights for
templates are set by adding −0.1 for each slash in
the syntactic category and −2 if the template con-
tains logical constants. Features on lexeme-template
pairs and all parse features are initialized to zero.
Systems We compare performance to all recently-
published, directly-comparable results. For Geo-
Query, this includes the ZC05, ZC07 (Zettlemoyer
</bodyText>
<page confidence="0.979823">
1519
</page>
<table confidence="0.999353">
System Exact Match
Rec. Pre. F1
ZC07 74.4 87.3 80.4
UBL 65.6 67.1 66.3
FUBL 81.9 82.1 82.0
</table>
<tableCaption confidence="0.998205">
Table 1: Performance on the Atis development set.
</tableCaption>
<table confidence="0.9998055">
System Exact Match Partial Match
Rec. Pre. F1. Rec. Pre. F1
ZC07 84.6 85.8 85.2 96.7 95.1 95.9
HY06 - - - - - 90.3
UBL 71.4 72.1 71.7 78.2 98.2 87.1
FUBL 82.8 82.8 82.8 95.2 93.6 94.6
</table>
<tableCaption confidence="0.999819">
Table 2: Performance on the Atis test set.
</tableCaption>
<bodyText confidence="0.9785712">
and Collins, 2005, 2007), λ-WASP (Wong and
Mooney, 2007), UBL (Kwiatkowski et al., 2010)
systems and DCS (Liang et al., 2011). For Atis,
we report results from HY06 (He and Young, 2006),
ZC07, and UBL.
</bodyText>
<sectionHeader confidence="0.999616" genericHeader="evaluation">
9 Results
</sectionHeader>
<bodyText confidence="0.999921892857143">
Tables 1-4 present the results on the Atis and Geo-
query domains. In all cases, FUBL achieves at or
near state-of-the-art recall (overall number of correct
parses) when compared to directly comparable sys-
tems and it significantly outperforms UBL on Atis.
On Geo880 the only higher recall is achieved
by DCS with prototypes - which uses signifi-
cant English-specific resources, including manually
specified lexical content, but does not require train-
ing sentences annotated with logical-forms. On
Geo250, FUBL achieves the highest recall across
languages. Each individual result should be inter-
preted with care, as a single percentage point cor-
responds to 2-3 sentences, but the overall trend is
encouraging.
On the Atis development set, FUBL outperforms
ZC07 by 7.5% of recall but on the Atis test set
FUBL lags ZC07 by 2%. The reasons for this dis-
crepancy are not clear, however, it is possible that
the syntactic constructions found in the Atis test set
do not exhibit the same degree of variation as those
seen in the development set. This would negate the
need for the very general lexicon learnt by FUBL.
Across the evaluations, despite achieving high re-
call, FUBL achieves significantly lower precision
than ZC07 and λ-WASP. This illustrates the trade-
off from having a very general model of proposing
lexical structure. With the ability to skip unseen
</bodyText>
<table confidence="0.99940375">
System Rec. Pre. F1
Labelled Logical Forms
ZC05 79.3 96.3 87.0
ZC07 86.1 91.6 88.8
UBL 87.9 88.5 88.2
FUBL 88.6 88.6 88.6
Labelled Question Answers
DCS 91.1 - -
</table>
<tableCaption confidence="0.99779">
Table 3: Exact match accuracy on the Geo880 test set.
</tableCaption>
<table confidence="0.9995007">
System Rec. English F1 Rec. Spanish F1
Pre. Pre.
λ-WASP 75.6 91.8 82.9 80.0 92.5 85.8
UBL 81.8 83.5 82.6 81.4 83.4 82.4
FUBL 83.7 83.7 83.7 85.6 85.8 85.7
System Rec. Japanese F1 Rec. Turkish F1
Pre. Pre.
λ-WASP 81.2 90.1 85.8 68.8 90.4 78.1
UBL 83.0 83.2 83.1 71.8 77.8 74.6
FUBL 83.2 83.8 83.5 72.5 73.7 73.1
</table>
<tableCaption confidence="0.999799">
Table 4: Exact-match accuracy on the Geo250 data set.
</tableCaption>
<bodyText confidence="0.99983275">
words, FUBL returns a parse for all of the Atis test
sentences, since the factored lexicons we are learn-
ing can produce a very large number of lexical items.
These parses are, however, not always correct.
</bodyText>
<sectionHeader confidence="0.852919" genericHeader="evaluation">
10 Analysis
</sectionHeader>
<bodyText confidence="0.99963565">
The Atis results in Tables 1 and 2 highlight the ad-
vantages of factored lexicons. FUBL outperforms
the UBL baseline by 16 and 11 points respectively
in exact-match recall. Without making any modi-
fication to the CCG grammars or parsing combina-
tors, we are able to induce a lexicon that is general
enough model the natural occurring variations in the
data, for example due to sloppy, unedited sentences.
Figure 2 shows a parse returned by FUBL for
a sentence on which UBL failed. While
the word “cheapest” is seen 208 times in the
training data, in only a handful of these in-
stances is it seen in the middle of an utter-
ance. For this reason, UBL never proposes
the lexical item, cheapest �- NP\(S|NP)/(S|NP) :
λ fλg.argmin(λx.f(x)ng(x),λy.cost(y)), which is
used to parse the sentence in Figure 2. In contrast,
FUBL uses a lexeme learned from the same word in
different contexts, along with a template learnt from
similar words in a similar context, to learn to per-
</bodyText>
<page confidence="0.951928">
1520
</page>
<table confidence="0.9492825">
pittsburgh to atlanta the cheapest on july twentieth
NP (S|NP)\NP/NP NP NP\(S|NP)/(S|NP) (S|NP)/NP/NP NP NP
pit λxλyλz.to(z,x) atl λ fλg.argmin(λx.f(x) ∧g(x),λy.cost(y)) λxλyλz.month(z,x) jul 20
∧ f rom(z,y) ∧day(z,y)
</table>
<figure confidence="0.936864333333333">
&gt; &gt;
(S|NP)\NP (S|NP)/NP
λxλy.to(y,atl) ∧ from(y,x) λxλy.month(y, jul) ∧day(y,x)
&lt; &gt;
(S|NP) (S|NP)
NP\(S|NP)
λ f .argmin(λx. f (x) ∧ month(x, jul) ∧ day(x,20),λy.cost(y))
NP
argmin(λx.from(x, pit) ∧to(x,atl) ∧month(x, jul) ∧ day(x,20),λy.cost(y))
</figure>
<figureCaption confidence="0.999252666666667">
Figure 2: An example learned parse. FUBL can learn this type of analysis with novel combinations of lexemes and
templates at test time, even if the individual words, like “cheapest,” were never seen in similar syntactic constructions
during training, as described in Section 10.
</figureCaption>
<figure confidence="0.859982666666667">
λx.to(x,atl) ∧ from(x, pit) λx.month(x, jul) ∧ day(x,20)
&gt;
&lt;
</figure>
<bodyText confidence="0.997694423076923">
form the desired analysis.
As well as providing a new way to search the lex-
icon during training, the factored lexicon provides a
way of proposing new, unseen, lexical items at test
time. We find that new, non-NP, lexical items are
used in 6% of the development set parses.
Interestingly, the addition of templates that intro-
duce semantic content (as described in Section 6.2)
account for only 1.2% of recall on the Atis develop-
ment set. This is suprising as elliptical constructions
are found in a much larger proportion of the sen-
tences than this. In practice, FUBL learns to model
many elliptical constructions with lexemes and tem-
plates introduced through maximal factorings. For
example, the lexeme (to,[from,to]) can be used
with the correct lexical template to deal with our
motivating example “flights Boston to New York”.
Templates that introduce content are therefore only
used in truly novel elliptical constructions for which
an alternative analysis could not be learned.
Table 5 shows a selection of lexemes and tem-
plates learned for Atis. Examples 2 and 3 show that
morphological variants of the same word must still
be stored in separate lexemes. However, as these
lexemes now share templates, the total number of
lexical variants that must be learned is reduced.
</bodyText>
<sectionHeader confidence="0.996979" genericHeader="conclusions">
11 Discussion
</sectionHeader>
<bodyText confidence="0.998467333333333">
We argued that factored CCG lexicons, which in-
clude both lexemes and lexical templates, provide
a compact representation of lexical knowledge that
can have advantages for learning. We also described
a complete approach for inducing factored, prob-
abilistic CCGs for semantic parsing, and demon-
</bodyText>
<figure confidence="0.859135">
Most common lexemes by type of constants in~c.
1 e (Boston,[bos]) (Denver,[den])
2 he,ti (flight,[flight]) (flights,[flight])
3 he,ii (fare,[cost]) (fares,[cost])
4 he,he,tii (from,[from]) (to,[to])
5 (cheapest,[argmin,cost])
he,ii, he,ti (earliest,[argmin,dep time])
6 hi,hi,tii, (after,[&gt;,dep time])
he,ii (before,[&lt;,dep time])
Most common templates matching lexemes above.
1 λ(ω,~v).ω `NP:v1
2 λ(ω,~v).ω `S|NP:λx.v1(x)
3 λ(ω,~v).ω `NP|NP:λx.v1(x)
4 λ(ω,~v).ω `S|NP/NP\(S|NP):λxλy.v1(x,y)
5 λ(ω,~v).ω `NP/(S|NP):λ f.v1(λx.f(x),λy,v2(y))
6 λ(ω,~v).ω `S|NP\(S|NP)/NP:
λxλyλz.v1(v2(z),x) ∧y(x)
</figure>
<tableCaption confidence="0.9704165">
Table 5: Example lexemes and templates learned from
the Atis development set.
</tableCaption>
<bodyText confidence="0.9989217">
strated strong performance across a wider range of
benchmark datasets that any previous approach.
In the future, it will also be important to ex-
plore morphological models, to better model vari-
ation within the existing lexemes. The factored lex-
ical representation also has significant potential for
lexical transfer learning, where we would need to
learn new lexemes for each target application, but
much of the information in the templates could, po-
tentially, be ported across domains.
</bodyText>
<sectionHeader confidence="0.997764" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9369315">
The work was supported in part by EU ERC Ad-
vanced Fellowship 249520 GRAMPLUS, and an
ESPRC PhD studentship. We would like to thank
Yoav Artzi for helpful discussions.
</bodyText>
<page confidence="0.99106">
1521
</page>
<sectionHeader confidence="0.996217" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999686404040404">
Bos, Johan, Stephen Clark, Mark Steedman, James R.
Curran, and Julia Hockenmaier. 2004. Wide-coverage
semantic representations from a CCG parser. In Pro-
ceedings of the International Conference on Computa-
tional Linguistics.
Branavan, S.R.K., Luke Zettlemoyer, and Regina Barzi-
lay. 2010. Reading between the lines: Learning to map
high-level instructions to commands. In Association
for Computational Linguistics (ACL).
Carpenter, Bob. 1997. Type-Logical Semantics. The MIT
Press.
Clark, Stephen and James R. Curran. 2003. Log-linear
models for wide-coverage CCG parsing. In Proceed-
ings of the Conference on Empirical Methods in Natu-
ral Language Processing.
Clark, Stephen and James R. Curran. 2007. Wide-
coverage efficient statistical parsing with CCG
and log-linear models. Computational Linguistics
33(4):493–552.
Clarke, James, Dan Goldwasser, Ming-Wei Chang, and
Dan Roth. 2010. Driving semantic parsing from
the world’s response. In Proceedings of the Four-
teenth Conference on Computational Natural Lan-
guage Learning (CoNLL-2010). Uppsala, Sweden,
pages 18–27.
Ge, Ruifang and Raymond J. Mooney. 2006. Discrimina-
tive reranking for semantic parsing. In Proceedings of
the COLING/ACL 2006 Main Conference Poster Ses-
sions.
Goldwasser, Dan, Roi Reichart, James Clarke, and Dan
Roth. 2011. Confidence driven unsupervised semantic
parsing. In Association for Computational Linguistics
(ACL).
He, Yulan and Steve Young. 2005. Semantic processing
using the hidden vector state model. Computer Speech
and Language .
He, Yulan and Steve Young. 2006. Spoken language
understanding using the hidden vector state model.
Speech Communication 48(3-4).
Hockenmaier, Julia and Mark Steedman. 2002. Gener-
ative models for statistical parsing with Combinatory
Categorial Grammar. In Proceedings of the 40th Meet-
ing of the ACL. Philadelphia, PA, pages 335–342.
Kate, Rohit J. and Raymond J. Mooney. 2006. Using
string-kernels for learning semantic parsers. In Pro-
ceedings of the 44th Annual Meeting of the Association
for Computational Linguistics.
Kate, Rohit J., Yuk Wah Wong, and Raymond J. Mooney.
2005. Learning to transform natural to formal lan-
guages. In Proceedings of the National Conference
on Artificial Intelligence.
Kwiatkowski, Tom, Luke Zettlemoyer, Sharon Goldwa-
ter, and Mark Steedman. 2010. Inducing probabilistic
CCG grammars from logical form with higher-order
unification. In Proceedings of the Conference on Em-
perical Methods in Natural Language Processing.
LeCun, Y., L. Bottou, Y. Bengio, and P. Haffner. 1998.
Gradient-based learning applied to document recogni-
tion. Proceedings of the IEEE 86(11):2278–2324.
Liang, P., M. I. Jordan, and D. Klein. 2009. Learning
semantic correspondences with less supervision. In
Association for Computational Linguistics and Inter-
national Joint Conference on Natural Language Pro-
cessing (ACL-IJCNLP).
Liang, P., M. I. Jordan, and D. Klein. 2011. Learning
dependency-based compositional semantics. In Asso-
ciation for Computational Linguistics (ACL).
Lu, Wei, Hwee Tou Ng, Wee Sun Lee, and Luke S. Zettle-
moyer. 2008. A generative model for parsing natural
language to meaning representations. In Proceedings
of The Conference on Empirical Methods in Natural
Language Processing.
Miller, Scott, David Stallard, Robert J. Bobrow, and
Richard L. Schwartz. 1996. A fully statistical approach
to natural language interfaces. In Proc. of the Associ-
ation for Computational Linguistics.
Nguyen, Le-Minh, Akira Shimazu, and Xuan-Hieu Phan.
2006. Semantic parsing with structured SVM ensem-
ble classification models. In Proceedings of the COL-
ING/ACL 2006 Main Conference Poster Sessions.
Och, Franz Josef and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics 29(1):19–51.
Papineni, K. A., S. Roukos, and T. R. Ward. 1997.
Feature-based language understanding. In Proceed-
ings of European Conference on Speech Communica-
tion and Technology.
Poon, Hoifung and Pedro Domingos. 2009. Unsuper-
vised semantic parsing. In Conference on Empirical
Methods in Natural Language Processing (EMNLP).
Poon, Hoifung and Pedro Domingos. 2010. Unsuper-
vised ontology induction from text. In Association for
Computational Linguistics (ACL).
Ramaswamy, Ganesh N. and Jan Kleindienst. 2000. Hier-
archical feature-based translation for scalable natural
language understanding. In Proceedings of Interna-
tional Conference on Spoken Language Processing.
Steedman, Mark. 1996. Surface Structure and Interpre-
tation. The MIT Press.
</reference>
<page confidence="0.839596">
1522
</page>
<reference confidence="0.999593106382979">
Steedman, Mark. 2000. The Syntactic Process. The MIT
Press.
Tang, Lappoon R. and Raymond J. Mooney. 2000. Au-
tomated construction of database interfaces: Integrat-
ing statistical and relational learning for semantic pars-
ing. In Proceedings of the Joint Conference on Empiri-
cal Methods in Natural Language Processing and Very
Large Corpora.
Thompson, Cynthia A. and Raymond J. Mooney. 2002.
Acquiring word-meaning mappings for natural lan-
guage interfaces. Journal of Artificial Intelligence Re-
search 18.
Vogel, Adam and Dan Jurafsky. 2010. Learning to follow
navigational directions. In Association for Computa-
tional Linguistics (ACL).
Watkinson, Stephen and Suresh Manandhar. 1999. Un-
supervised lexical learning with categorial grammars
using the LLL corpus. In Proceedings of the 1st Work-
shop on Learning Language in Logic.
Wong, Yuk Wah and Raymond Mooney. 2006. Learning
for semantic parsing with statistical machine transla-
tion. In Proceedings of the Human Language Technol-
ogy Conference of the NAACL.
Wong, Yuk Wah and Raymond Mooney. 2007. Learn-
ing synchronous grammars for semantic parsing with
lambda calculus. In Proceedings of the Association for
Computational Linguistics.
Zelle, John M. and Raymond J. Mooney. 1996. Learn-
ing to parse database queries using inductive logic pro-
gramming. In Proceedings of the National Conference
on Artificial Intelligence.
Zettlemoyer, Luke S. and Michael Collins. 2005. Learn-
ing to map sentences to logical form: Structured clas-
sification with probabilistic categorial grammars. In
Proceedings of the Conference on Uncertainty in Arti-
ficial Intelligence.
Zettlemoyer, Luke S. and Michael Collins. 2007. On-
line learning of relaxed CCG grammars for parsing to
logical form. In Proc. of the Joint Conference on Em-
pirical Methods in Natural Language Processing and
Computational Natural Language Learning.
Zettlemoyer, Luke S. and Michael Collins. 2009. Learn-
ing context-dependent mappings from sentences to
logical form. In Proceedings of The Joint Conference
of the Association for Computational Linguistics and
International Joint Conference on Natural Language
Processing.
</reference>
<page confidence="0.956997">
1523
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.698962">
<title confidence="0.995674">Lexical Generalization in CCG Grammar Induction for Semantic Parsing</title>
<author confidence="0.726771">t m kwiatkowksisms ed ac uk lszcs washington edu sgwaterinf ed ac uk steedmaninf ed ac uk</author>
<affiliation confidence="0.9933975">of Informatics Science &amp; Engineering University of Edinburgh University of Washington</affiliation>
<address confidence="0.99941">Edinburgh, EH8 9AB, UK Seattle, WA 98195</address>
<abstract confidence="0.9984003">We consider the problem of learning factored probabilistic CCG grammars for semantic parsing from data containing sentences paired with logical-form meaning representations. Traditional CCG lexicons list lexical items that pair words and phrases with syntactic and semantic content. Such lexicons can be inefficient when words appear repeatedly with closely related lexical content. In this paper, we introduce factored lexicons, which both model word meaning model systematic variation in word usage. We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance benefits greatly from the lexical factoring.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Stephen Clark</author>
<author>Mark Steedman</author>
<author>James R Curran</author>
<author>Julia Hockenmaier</author>
</authors>
<title>Wide-coverage semantic representations from a CCG parser.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="9742" citStr="Bos et al. (2004)" startWordPosition="1512" endWordPosition="1515">s learnt semantic analyses from text in the context of interactions in computational environments (Branavan et al. (2010), Vogel and Jurafsky (2010)); text grounded in partial observations of a world state (Liang et al., 2009); and from raw text alone (Poon and Domingos, 2009, 2010). There is also related work that uses the CCG grammar formalism. Clark and Curran (2003) present a method for learning the parameters of a log-linear CCG parsing model from fully annotated normal–form parse trees. Watkinson and Manandhar (1999) describe an unsupervised approach for learning syntactic CCG lexicons. Bos et al. (2004) present an algorithm for building semantic representations from CCG parses but requires fully–specified CCG derivations in the training data. 3 Overview of the Approach Here we give a formal definition of the problem and an overview of the learning approach. Problem We will learn a semantic parser that takes a sentences x and returns a logical form z representing its underlying meaning. We assume we have input data {(xi,zi)|i = 1...n} containing sentences xi and logical forms zi, for example xi =“Show me flights to Boston” and zi = λx. flight(x)nto(x,bos). Model We will represent the parser a</context>
</contexts>
<marker>Bos, Clark, Steedman, Curran, Hockenmaier, 2004</marker>
<rawString>Bos, Johan, Stephen Clark, Mark Steedman, James R. Curran, and Julia Hockenmaier. 2004. Wide-coverage semantic representations from a CCG parser. In Proceedings of the International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R K Branavan</author>
<author>Luke Zettlemoyer</author>
<author>Regina Barzilay</author>
</authors>
<title>Reading between the lines: Learning to map high-level instructions to commands.</title>
<date>2010</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="9246" citStr="Branavan et al. (2010)" startWordPosition="1432" endWordPosition="1435">e recent work has focused on training semantic parsers without supervision in the form of logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) replace semantic annotations in the training set with target answers which are more easily available. Goldwasser et al. (2011) present work on unsupervised learning of logical form structure. However, all of these systems require significantly more domain and language specific initialization than the approach presented here. Other work has learnt semantic analyses from text in the context of interactions in computational environments (Branavan et al. (2010), Vogel and Jurafsky (2010)); text grounded in partial observations of a world state (Liang et al., 2009); and from raw text alone (Poon and Domingos, 2009, 2010). There is also related work that uses the CCG grammar formalism. Clark and Curran (2003) present a method for learning the parameters of a log-linear CCG parsing model from fully annotated normal–form parse trees. Watkinson and Manandhar (1999) describe an unsupervised approach for learning syntactic CCG lexicons. Bos et al. (2004) present an algorithm for building semantic representations from CCG parses but requires fully–specified</context>
</contexts>
<marker>Branavan, Zettlemoyer, Barzilay, 2010</marker>
<rawString>Branavan, S.R.K., Luke Zettlemoyer, and Regina Barzilay. 2010. Reading between the lines: Learning to map high-level instructions to commands. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>Type-Logical Semantics.</title>
<date>1997</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="12541" citStr="Carpenter, 1997" startWordPosition="1977" endWordPosition="1978">con (Section 5), techniques for proposing potential new lexemes and templates (Section 6), and finally a complete learning algorithm (Section 7). However, the next section first reviews the required background on semantic parsing with CCG. 4 Background 4.1 Lambda Calculus We represent the meanings of sentences, words and phrases with logical expressions that can contain constants, quantifiers, logical connectors and lambda abstractions. We construct the meanings of sentences from the meanings of words and phrases using lambda-calculus operations. We use a version of the typed lambda calculus (Carpenter, 1997), in which the basic types include e, for entities; t, for truth values; and i for numbers. We also have function types that are assigned to lambda expressions. 1514 The expression λx.flight(x) takes an entity and returns a truth value, and has the function type he,ti. 4.2 Combinatory Categorial Grammar CCG (Steedman, 1996, 2000) is a linguistic formalism that tightly couples syntax and semantics, and can be used to model a wide range of language phenomena. A traditional CCG grammar includes a lexicon Λ with entries like the following: flights ` N :λx. f light(x) to ` (N\N)/NP:λy.λ f .λx. f (x</context>
</contexts>
<marker>Carpenter, 1997</marker>
<rawString>Carpenter, Bob. 1997. Type-Logical Semantics. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>Log-linear models for wide-coverage CCG parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="9497" citStr="Clark and Curran (2003)" startWordPosition="1475" endWordPosition="1478">y available. Goldwasser et al. (2011) present work on unsupervised learning of logical form structure. However, all of these systems require significantly more domain and language specific initialization than the approach presented here. Other work has learnt semantic analyses from text in the context of interactions in computational environments (Branavan et al. (2010), Vogel and Jurafsky (2010)); text grounded in partial observations of a world state (Liang et al., 2009); and from raw text alone (Poon and Domingos, 2009, 2010). There is also related work that uses the CCG grammar formalism. Clark and Curran (2003) present a method for learning the parameters of a log-linear CCG parsing model from fully annotated normal–form parse trees. Watkinson and Manandhar (1999) describe an unsupervised approach for learning syntactic CCG lexicons. Bos et al. (2004) present an algorithm for building semantic representations from CCG parses but requires fully–specified CCG derivations in the training data. 3 Overview of the Approach Here we give a formal definition of the problem and an overview of the learning approach. Problem We will learn a semantic parser that takes a sentences x and returns a logical form z r</context>
</contexts>
<marker>Clark, Curran, 2003</marker>
<rawString>Clark, Stephen and James R. Curran. 2003. Log-linear models for wide-coverage CCG parsing. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>Widecoverage efficient statistical parsing with CCG and log-linear models.</title>
<date>2007</date>
<journal>Computational Linguistics</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="8080" citStr="Clark and Curran (2007)" startWordPosition="1257" endWordPosition="1260">age independent, but scales well to these cal templates to model each example. This is a dif- challenging sentences. ficult learning problem, since the CCG analyses that There have been a number of other approaches for learning semantic parsers, including ones based on machine translation techniques (Papineni et al., 1997; Ramaswamy and Kleindienst, 2000; Wong and Mooney, 2006), parsing models (Miller et al., 1996; Ge and Mooney, 2006; Lu et al., 2008), in1A related tactic is commonly used in wide-coverage CCG parsers derived from treebanks, such as work by Hockenmaier and Steedman (2002) and Clark and Curran (2007). These parsers make extensive use of category-changing unary rules, to avoid data sparsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996; Thompson and Mooney, 2002; Tang and Mooney, 2000), probabilistic automata (He and Young, 2005, 2006), and ideas from string kernels and support vector machines (Kate and Mooney, 2006; Nguyen et al., 2006). More recent work has focused on training semantic parsers w</context>
</contexts>
<marker>Clark, Curran, 2007</marker>
<rawString>Clark, Stephen and James R. Curran. 2007. Widecoverage efficient statistical parsing with CCG and log-linear models. Computational Linguistics 33(4):493–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Dan Goldwasser</author>
<author>Ming-Wei Chang</author>
<author>Dan Roth</author>
</authors>
<title>Driving semantic parsing from the world’s response.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010).</booktitle>
<pages>18--27</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="8760" citStr="Clarke et al. (2010)" startWordPosition="1357" endWordPosition="1360">y rules, to avoid data sparsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996; Thompson and Mooney, 2002; Tang and Mooney, 2000), probabilistic automata (He and Young, 2005, 2006), and ideas from string kernels and support vector machines (Kate and Mooney, 2006; Nguyen et al., 2006). More recent work has focused on training semantic parsers without supervision in the form of logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) replace semantic annotations in the training set with target answers which are more easily available. Goldwasser et al. (2011) present work on unsupervised learning of logical form structure. However, all of these systems require significantly more domain and language specific initialization than the approach presented here. Other work has learnt semantic analyses from text in the context of interactions in computational environments (Branavan et al. (2010), Vogel and Jurafsky (2010)); text grounded in partial observations of a world state (Liang et al., 2009); and fro</context>
</contexts>
<marker>Clarke, Goldwasser, Chang, Roth, 2010</marker>
<rawString>Clarke, James, Dan Goldwasser, Ming-Wei Chang, and Dan Roth. 2010. Driving semantic parsing from the world’s response. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010). Uppsala, Sweden, pages 18–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruifang Ge</author>
<author>Raymond J Mooney</author>
</authors>
<title>Discriminative reranking for semantic parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions.</booktitle>
<contexts>
<context position="7895" citStr="Ge and Mooney, 2006" startWordPosition="1226" endWordPosition="1229"> learning apfully specified lexical items for the learned grammar, proach we develop for inducing factored lexicons is we automatically generate sets of lexemes and lexi- also language independent, but scales well to these cal templates to model each example. This is a dif- challenging sentences. ficult learning problem, since the CCG analyses that There have been a number of other approaches for learning semantic parsers, including ones based on machine translation techniques (Papineni et al., 1997; Ramaswamy and Kleindienst, 2000; Wong and Mooney, 2006), parsing models (Miller et al., 1996; Ge and Mooney, 2006; Lu et al., 2008), in1A related tactic is commonly used in wide-coverage CCG parsers derived from treebanks, such as work by Hockenmaier and Steedman (2002) and Clark and Curran (2007). These parsers make extensive use of category-changing unary rules, to avoid data sparsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996; Thompson and Mooney, 2002; Tang and Mooney, 2000), probabilistic automata (He an</context>
</contexts>
<marker>Ge, Mooney, 2006</marker>
<rawString>Ge, Ruifang and Raymond J. Mooney. 2006. Discriminative reranking for semantic parsing. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Goldwasser</author>
<author>Roi Reichart</author>
<author>James Clarke</author>
<author>Dan Roth</author>
</authors>
<title>Confidence driven unsupervised semantic parsing.</title>
<date>2011</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="8911" citStr="Goldwasser et al. (2011)" startWordPosition="1381" endWordPosition="1384">sent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996; Thompson and Mooney, 2002; Tang and Mooney, 2000), probabilistic automata (He and Young, 2005, 2006), and ideas from string kernels and support vector machines (Kate and Mooney, 2006; Nguyen et al., 2006). More recent work has focused on training semantic parsers without supervision in the form of logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) replace semantic annotations in the training set with target answers which are more easily available. Goldwasser et al. (2011) present work on unsupervised learning of logical form structure. However, all of these systems require significantly more domain and language specific initialization than the approach presented here. Other work has learnt semantic analyses from text in the context of interactions in computational environments (Branavan et al. (2010), Vogel and Jurafsky (2010)); text grounded in partial observations of a world state (Liang et al., 2009); and from raw text alone (Poon and Domingos, 2009, 2010). There is also related work that uses the CCG grammar formalism. Clark and Curran (2003) present a met</context>
</contexts>
<marker>Goldwasser, Reichart, Clarke, Roth, 2011</marker>
<rawString>Goldwasser, Dan, Roi Reichart, James Clarke, and Dan Roth. 2011. Confidence driven unsupervised semantic parsing. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yulan He</author>
<author>Steve Young</author>
</authors>
<title>Semantic processing using the hidden vector state model. Computer Speech and Language .</title>
<date>2005</date>
<contexts>
<context position="8508" citStr="He and Young, 2005" startWordPosition="1317" endWordPosition="1320"> 2006; Lu et al., 2008), in1A related tactic is commonly used in wide-coverage CCG parsers derived from treebanks, such as work by Hockenmaier and Steedman (2002) and Clark and Curran (2007). These parsers make extensive use of category-changing unary rules, to avoid data sparsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996; Thompson and Mooney, 2002; Tang and Mooney, 2000), probabilistic automata (He and Young, 2005, 2006), and ideas from string kernels and support vector machines (Kate and Mooney, 2006; Nguyen et al., 2006). More recent work has focused on training semantic parsers without supervision in the form of logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) replace semantic annotations in the training set with target answers which are more easily available. Goldwasser et al. (2011) present work on unsupervised learning of logical form structure. However, all of these systems require significantly more domain and language specific initialization than the approach presented he</context>
</contexts>
<marker>He, Young, 2005</marker>
<rawString>He, Yulan and Steve Young. 2005. Semantic processing using the hidden vector state model. Computer Speech and Language .</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yulan He</author>
<author>Steve Young</author>
</authors>
<title>Spoken language understanding using the hidden vector state model.</title>
<date>2006</date>
<journal>Speech Communication</journal>
<pages>48--3</pages>
<contexts>
<context position="33346" citStr="He and Young, 2006" startWordPosition="5563" endWordPosition="5566">lts. For GeoQuery, this includes the ZC05, ZC07 (Zettlemoyer 1519 System Exact Match Rec. Pre. F1 ZC07 74.4 87.3 80.4 UBL 65.6 67.1 66.3 FUBL 81.9 82.1 82.0 Table 1: Performance on the Atis development set. System Exact Match Partial Match Rec. Pre. F1. Rec. Pre. F1 ZC07 84.6 85.8 85.2 96.7 95.1 95.9 HY06 - - - - - 90.3 UBL 71.4 72.1 71.7 78.2 98.2 87.1 FUBL 82.8 82.8 82.8 95.2 93.6 94.6 Table 2: Performance on the Atis test set. and Collins, 2005, 2007), λ-WASP (Wong and Mooney, 2007), UBL (Kwiatkowski et al., 2010) systems and DCS (Liang et al., 2011). For Atis, we report results from HY06 (He and Young, 2006), ZC07, and UBL. 9 Results Tables 1-4 present the results on the Atis and Geoquery domains. In all cases, FUBL achieves at or near state-of-the-art recall (overall number of correct parses) when compared to directly comparable systems and it significantly outperforms UBL on Atis. On Geo880 the only higher recall is achieved by DCS with prototypes - which uses significant English-specific resources, including manually specified lexical content, but does not require training sentences annotated with logical-forms. On Geo250, FUBL achieves the highest recall across languages. Each individual resu</context>
</contexts>
<marker>He, Young, 2006</marker>
<rawString>He, Yulan and Steve Young. 2006. Spoken language understanding using the hidden vector state model. Speech Communication 48(3-4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>Generative models for statistical parsing with Combinatory Categorial Grammar.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Meeting of the ACL.</booktitle>
<pages>335--342</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="8052" citStr="Hockenmaier and Steedman (2002)" startWordPosition="1252" endWordPosition="1255">sets of lexemes and lexi- also language independent, but scales well to these cal templates to model each example. This is a dif- challenging sentences. ficult learning problem, since the CCG analyses that There have been a number of other approaches for learning semantic parsers, including ones based on machine translation techniques (Papineni et al., 1997; Ramaswamy and Kleindienst, 2000; Wong and Mooney, 2006), parsing models (Miller et al., 1996; Ge and Mooney, 2006; Lu et al., 2008), in1A related tactic is commonly used in wide-coverage CCG parsers derived from treebanks, such as work by Hockenmaier and Steedman (2002) and Clark and Curran (2007). These parsers make extensive use of category-changing unary rules, to avoid data sparsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996; Thompson and Mooney, 2002; Tang and Mooney, 2000), probabilistic automata (He and Young, 2005, 2006), and ideas from string kernels and support vector machines (Kate and Mooney, 2006; Nguyen et al., 2006). More recent work has focused on</context>
</contexts>
<marker>Hockenmaier, Steedman, 2002</marker>
<rawString>Hockenmaier, Julia and Mark Steedman. 2002. Generative models for statistical parsing with Combinatory Categorial Grammar. In Proceedings of the 40th Meeting of the ACL. Philadelphia, PA, pages 335–342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rohit J Kate</author>
<author>Raymond J Mooney</author>
</authors>
<title>Using string-kernels for learning semantic parsers.</title>
<date>2006</date>
<booktitle>In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1503" citStr="Kate and Mooney, 2006" startWordPosition="198" endWordPosition="201">odel systematic variation in word usage. We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance benefits greatly from the lexical factoring. 1 Introduction Semantic parsers automatically recover representations of meaning from natural language sentences. Recent work has focused on learning such parsers directly from corpora made up of sentences paired with logical meaning representations (Kate et al., 2005; Kate and Mooney, 2006; Wong and Mooney, 2006, 2007; Zettlemoyer and Collins, 2005, 2007; Lu et al., 2008; Kwiatkowski et al., 2010). For example, in a flight booking domain we might have access to training examples such as: Sentence: I want flights from Boston Meaning: λx. f light(x) ∧ f rom(x,bos) 1512 and the goal is to learn a grammar that can map new, unseen, sentences onto their corresponding meanings, or logical forms. One approach to this problem has developed algorithms for leaning probabilistic CCG grammars (Zettlemoyer and Collins, 2005, 2007; Kwiatkowski et al., 2010). These grammars are well-suited to </context>
<context position="8597" citStr="Kate and Mooney, 2006" startWordPosition="1331" endWordPosition="1334">sers derived from treebanks, such as work by Hockenmaier and Steedman (2002) and Clark and Curran (2007). These parsers make extensive use of category-changing unary rules, to avoid data sparsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996; Thompson and Mooney, 2002; Tang and Mooney, 2000), probabilistic automata (He and Young, 2005, 2006), and ideas from string kernels and support vector machines (Kate and Mooney, 2006; Nguyen et al., 2006). More recent work has focused on training semantic parsers without supervision in the form of logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) replace semantic annotations in the training set with target answers which are more easily available. Goldwasser et al. (2011) present work on unsupervised learning of logical form structure. However, all of these systems require significantly more domain and language specific initialization than the approach presented here. Other work has learnt semantic analyses from text in the context of interactions in c</context>
</contexts>
<marker>Kate, Mooney, 2006</marker>
<rawString>Kate, Rohit J. and Raymond J. Mooney. 2006. Using string-kernels for learning semantic parsers. In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rohit J Kate</author>
<author>Yuk Wah Wong</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to transform natural to formal languages.</title>
<date>2005</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="1480" citStr="Kate et al., 2005" startWordPosition="194" endWordPosition="197"> and templates to model systematic variation in word usage. We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance benefits greatly from the lexical factoring. 1 Introduction Semantic parsers automatically recover representations of meaning from natural language sentences. Recent work has focused on learning such parsers directly from corpora made up of sentences paired with logical meaning representations (Kate et al., 2005; Kate and Mooney, 2006; Wong and Mooney, 2006, 2007; Zettlemoyer and Collins, 2005, 2007; Lu et al., 2008; Kwiatkowski et al., 2010). For example, in a flight booking domain we might have access to training examples such as: Sentence: I want flights from Boston Meaning: λx. f light(x) ∧ f rom(x,bos) 1512 and the goal is to learn a grammar that can map new, unseen, sentences onto their corresponding meanings, or logical forms. One approach to this problem has developed algorithms for leaning probabilistic CCG grammars (Zettlemoyer and Collins, 2005, 2007; Kwiatkowski et al., 2010). These gramm</context>
</contexts>
<marker>Kate, Wong, Mooney, 2005</marker>
<rawString>Kate, Rohit J., Yuk Wah Wong, and Raymond J. Mooney. 2005. Learning to transform natural to formal languages. In Proceedings of the National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Kwiatkowski</author>
<author>Luke Zettlemoyer</author>
<author>Sharon Goldwater</author>
<author>Mark Steedman</author>
</authors>
<title>Inducing probabilistic CCG grammars from logical form with higher-order unification.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Emperical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="1613" citStr="Kwiatkowski et al., 2010" startWordPosition="216" endWordPosition="219">along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance benefits greatly from the lexical factoring. 1 Introduction Semantic parsers automatically recover representations of meaning from natural language sentences. Recent work has focused on learning such parsers directly from corpora made up of sentences paired with logical meaning representations (Kate et al., 2005; Kate and Mooney, 2006; Wong and Mooney, 2006, 2007; Zettlemoyer and Collins, 2005, 2007; Lu et al., 2008; Kwiatkowski et al., 2010). For example, in a flight booking domain we might have access to training examples such as: Sentence: I want flights from Boston Meaning: λx. f light(x) ∧ f rom(x,bos) 1512 and the goal is to learn a grammar that can map new, unseen, sentences onto their corresponding meanings, or logical forms. One approach to this problem has developed algorithms for leaning probabilistic CCG grammars (Zettlemoyer and Collins, 2005, 2007; Kwiatkowski et al., 2010). These grammars are well-suited to the task of semantic parsing, as they closely link syntax and semantics. They can be used to model a wide rang</context>
<context position="6786" citStr="Kwiatkowski et al. (2010)" startWordPosition="1063" endWordPosition="1066">ignificantly ated, English-language specific rules to generate lexmore compact lexicon that can be learned from less ical items from logical forms as well as English data. Each word or phrase will be associated with a specific type-shifting rules and relaxations of the few lexemes that can be combined with a shared set CCG combinators to model spontaneous, unedited of general templates. sentences. Zettlemoyer and Collins (2009) extends We develop an approach to learning factored, this work to the case of learning in context depenprobabilistic CCG grammars for semantic pars- dent environments. Kwiatkowski et al. (2010) deing. Following previous work (Kwiatkowski et al., scribed an approach for language-independent learn2010), we make use of a higher-order unification ing that replaces the hand-specified templates with learning scheme that defines a space of CCG gram- a higher-order-unification-based lexical induction mars consistent with the (sentence, logical form) method, but their approach does not scale well to training pairs. However, instead of constructing challenging, unedited sentences. The learning apfully specified lexical items for the learned grammar, proach we develop for inducing factored lex</context>
<context position="11563" citStr="Kwiatkowski et al. (2010)" startWordPosition="1825" endWordPosition="1828">,[bos]). • A list of lexical templates T. Each template takes a lexeme and maps it on to a full lexical item. For example, there is a single template that can map the lexeme above to the final lexical entry Boston �- NP : bos. We will make central use of this factored representation to provide a more compact representation of the lexicon that can be learned efficiently. The factored PCCG will also contain a parameter vector, θ, that defines a log-linear distribution over the possible parses y, conditioned on the sentence x. Learning Our approach for learning factored PCCGs extends the work of Kwiatkowski et al. (2010), as reviewed in Section 7. Specifically, we modify the lexical learning, to produce lexemes and templates, as well as the feature space of the model, but reuse the existing parameter estimation techniques and overall learning cycle, as described in Section 7. We present the complete approach in three parts by describing the factored representation of the lexicon (Section 5), techniques for proposing potential new lexemes and templates (Section 6), and finally a complete learning algorithm (Section 7). However, the next section first reviews the required background on semantic parsing with CCG</context>
<context position="23513" citStr="Kwiatkowski et al., 2010" startWordPosition="3870" endWordPosition="3873"> produce the nonterminal, even if one of the words is missing. Here, this approach would introduce the desired template λ(ω,v).[ω ` N\N : λ f .λx. f (x) ∧ from(x,v1)] for mapping the lexeme (Boston,[bos]) directly to the intermediate structure. Not all templates introduced this way will model valid generalizations. However, we will incorporate them into a learning algorithm with indicator features that can be weighted to control their use. The next section presents the complete approach. 7 Learning Factored PCCGs Our Factored Unification Based Learning (FUBL) method extends the UBL algorithm (Kwiatkowski et al., 2010) to induce factored lexicons, while also simultanously estimating the parameters of a loglinear CCG parsing model. In this section, we first review the NEW-LEX lexical induction procedure from UBL, and then present the FUBL algorithm. 7.1 Background: NEW-LEX NEW-LEX generates lexical items by splitting and merging nodes in the best parse tree of each training example. Each parse node has a CCG category X : h and a sequence of words w that it spans. We will present an overview of the approach using the running example with the phrase w =“in Boston” and the category X : h = S\NP : λx.loc(x,bos),</context>
<context position="26094" citStr="Kwiatkowski et al., 2010" startWordPosition="4319" endWordPosition="4322">the type he,ti and uses the vertical slash introduced in Section 4.2. We will see categories such as this in the evaluation. 7.2 The FUBL Algorithm Figure 1 shows the FUBL learning algorithm. We assume training data {(xi,zi) : i = 1...n} where each example is a sentence xi paired with a logical form zi. The algorithm induces a factored PCCG, including the lexemes L, templates T, and parameters θ. The algorithm is online, repeatedly performing both lexical expansion (Step 1) and a parameter update (Step 2) for each training example. The overall approach is closely related to the UBL algorithm (Kwiatkowski et al., 2010), but includes extensions for updating the factored lexicon, as motivated in Section 6. Initialization The model is initialized with a factored lexicon as follows. MAX-FAC is a function that takes a lexical item l and returns the maximal factoring of it, that is the unique, maximal (lexeme, template) pair that can be combined to construct l, as described in Section 6.1. We apply MAX-FAC to each of the training examples (xi,zi), creating a single way of producing the desired meaning zi from a Inputs: Training set {(xi,zi) : i = 1...n} where each example is a sentence xi paired with a logical fo</context>
<context position="33249" citStr="Kwiatkowski et al., 2010" startWordPosition="5545" endWordPosition="5548"> initialized to zero. Systems We compare performance to all recentlypublished, directly-comparable results. For GeoQuery, this includes the ZC05, ZC07 (Zettlemoyer 1519 System Exact Match Rec. Pre. F1 ZC07 74.4 87.3 80.4 UBL 65.6 67.1 66.3 FUBL 81.9 82.1 82.0 Table 1: Performance on the Atis development set. System Exact Match Partial Match Rec. Pre. F1. Rec. Pre. F1 ZC07 84.6 85.8 85.2 96.7 95.1 95.9 HY06 - - - - - 90.3 UBL 71.4 72.1 71.7 78.2 98.2 87.1 FUBL 82.8 82.8 82.8 95.2 93.6 94.6 Table 2: Performance on the Atis test set. and Collins, 2005, 2007), λ-WASP (Wong and Mooney, 2007), UBL (Kwiatkowski et al., 2010) systems and DCS (Liang et al., 2011). For Atis, we report results from HY06 (He and Young, 2006), ZC07, and UBL. 9 Results Tables 1-4 present the results on the Atis and Geoquery domains. In all cases, FUBL achieves at or near state-of-the-art recall (overall number of correct parses) when compared to directly comparable systems and it significantly outperforms UBL on Atis. On Geo880 the only higher recall is achieved by DCS with prototypes - which uses significant English-specific resources, including manually specified lexical content, but does not require training sentences annotated with </context>
</contexts>
<marker>Kwiatkowski, Zettlemoyer, Goldwater, Steedman, 2010</marker>
<rawString>Kwiatkowski, Tom, Luke Zettlemoyer, Sharon Goldwater, and Mark Steedman. 2010. Inducing probabilistic CCG grammars from logical form with higher-order unification. In Proceedings of the Conference on Emperical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y LeCun</author>
<author>L Bottou</author>
<author>Y Bengio</author>
<author>P Haffner</author>
</authors>
<title>Gradient-based learning applied to document recognition.</title>
<date>1998</date>
<journal>Proceedings of the IEEE</journal>
<volume>86</volume>
<issue>11</issue>
<contexts>
<context position="16152" citStr="LeCun et al., 1998" startWordPosition="2631" endWordPosition="2634">. f (x) ∧to(x,bos) N λx. f light(x) ∧to(x,bos) where each step in the parse is labeled with the combinatory rule (− &gt; or − &lt;) that was used. CCG also includes combinatory rules of forward (&gt; B) and backward (&lt; B) composition: X/Y : f Y/Z : g ⇒ X/Z : λx.f(g(x)) (&gt; B) Y\Z : g X\Y : f ⇒ X\Z : λx. f(g(x)) (&lt; B) In this approach the distribution over parse trees y is modeled as a hidden variable. The sum over parses in Eq. 3 can be calculated efficiently using the inside-outside algorithm with a CKY-style parsing algorithm. To estimate the parameters themselves, we use stochastic gradient updates (LeCun et al., 1998). Given a set of n sentence-meaning pairs {(xi,zi) : i = 1...n}, we update the parameters θ iteratively, for each example i, by following the local gradient of the conditional log-likelihood objective &lt; 1515 Oi = logP(zi|xi;θ,Λ). The local gradient of the individual parameter θj associated with feature φj and training instance (xi,zi) is given by: = Ep(y|xi,zi;θ,Λ)[φj(xi,y,zi)] (4) −Ep(y,z|xi;θ,Λ)[φj(xi,y,z)] As with Eq. 3, all of the expectations in Eq. 4 are calculated through the use of the inside-outside algorithm on a pruned parse chart. For a sentence of length m, each parse chart span i</context>
</contexts>
<marker>LeCun, Bottou, Bengio, Haffner, 1998</marker>
<rawString>LeCun, Y., L. Bottou, Y. Bengio, and P. Haffner. 1998. Gradient-based learning applied to document recognition. Proceedings of the IEEE 86(11):2278–2324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Liang</author>
<author>M I Jordan</author>
<author>D Klein</author>
</authors>
<title>Learning semantic correspondences with less supervision.</title>
<date>2009</date>
<booktitle>In Association for Computational Linguistics and International Joint Conference on Natural Language Processing (ACL-IJCNLP).</booktitle>
<contexts>
<context position="9351" citStr="Liang et al., 2009" startWordPosition="1450" endWordPosition="1453">ations. Clarke et al. (2010) and Liang et al. (2011) replace semantic annotations in the training set with target answers which are more easily available. Goldwasser et al. (2011) present work on unsupervised learning of logical form structure. However, all of these systems require significantly more domain and language specific initialization than the approach presented here. Other work has learnt semantic analyses from text in the context of interactions in computational environments (Branavan et al. (2010), Vogel and Jurafsky (2010)); text grounded in partial observations of a world state (Liang et al., 2009); and from raw text alone (Poon and Domingos, 2009, 2010). There is also related work that uses the CCG grammar formalism. Clark and Curran (2003) present a method for learning the parameters of a log-linear CCG parsing model from fully annotated normal–form parse trees. Watkinson and Manandhar (1999) describe an unsupervised approach for learning syntactic CCG lexicons. Bos et al. (2004) present an algorithm for building semantic representations from CCG parses but requires fully–specified CCG derivations in the training data. 3 Overview of the Approach Here we give a formal definition of the</context>
</contexts>
<marker>Liang, Jordan, Klein, 2009</marker>
<rawString>Liang, P., M. I. Jordan, and D. Klein. 2009. Learning semantic correspondences with less supervision. In Association for Computational Linguistics and International Joint Conference on Natural Language Processing (ACL-IJCNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Liang</author>
<author>M I Jordan</author>
<author>D Klein</author>
</authors>
<title>Learning dependency-based compositional semantics.</title>
<date>2011</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="8784" citStr="Liang et al. (2011)" startWordPosition="1362" endWordPosition="1365">arsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996; Thompson and Mooney, 2002; Tang and Mooney, 2000), probabilistic automata (He and Young, 2005, 2006), and ideas from string kernels and support vector machines (Kate and Mooney, 2006; Nguyen et al., 2006). More recent work has focused on training semantic parsers without supervision in the form of logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) replace semantic annotations in the training set with target answers which are more easily available. Goldwasser et al. (2011) present work on unsupervised learning of logical form structure. However, all of these systems require significantly more domain and language specific initialization than the approach presented here. Other work has learnt semantic analyses from text in the context of interactions in computational environments (Branavan et al. (2010), Vogel and Jurafsky (2010)); text grounded in partial observations of a world state (Liang et al., 2009); and from raw text alone (Poon a</context>
<context position="33286" citStr="Liang et al., 2011" startWordPosition="5552" endWordPosition="5555">rformance to all recentlypublished, directly-comparable results. For GeoQuery, this includes the ZC05, ZC07 (Zettlemoyer 1519 System Exact Match Rec. Pre. F1 ZC07 74.4 87.3 80.4 UBL 65.6 67.1 66.3 FUBL 81.9 82.1 82.0 Table 1: Performance on the Atis development set. System Exact Match Partial Match Rec. Pre. F1. Rec. Pre. F1 ZC07 84.6 85.8 85.2 96.7 95.1 95.9 HY06 - - - - - 90.3 UBL 71.4 72.1 71.7 78.2 98.2 87.1 FUBL 82.8 82.8 82.8 95.2 93.6 94.6 Table 2: Performance on the Atis test set. and Collins, 2005, 2007), λ-WASP (Wong and Mooney, 2007), UBL (Kwiatkowski et al., 2010) systems and DCS (Liang et al., 2011). For Atis, we report results from HY06 (He and Young, 2006), ZC07, and UBL. 9 Results Tables 1-4 present the results on the Atis and Geoquery domains. In all cases, FUBL achieves at or near state-of-the-art recall (overall number of correct parses) when compared to directly comparable systems and it significantly outperforms UBL on Atis. On Geo880 the only higher recall is achieved by DCS with prototypes - which uses significant English-specific resources, including manually specified lexical content, but does not require training sentences annotated with logical-forms. On Geo250, FUBL achiev</context>
</contexts>
<marker>Liang, Jordan, Klein, 2011</marker>
<rawString>Liang, P., M. I. Jordan, and D. Klein. 2011. Learning dependency-based compositional semantics. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Lu</author>
<author>Hwee Tou Ng</author>
<author>Wee Sun Lee</author>
<author>Luke S Zettlemoyer</author>
</authors>
<title>A generative model for parsing natural language to meaning representations.</title>
<date>2008</date>
<booktitle>In Proceedings of The Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="1586" citStr="Lu et al., 2008" startWordPosition="212" endWordPosition="215">ed CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance benefits greatly from the lexical factoring. 1 Introduction Semantic parsers automatically recover representations of meaning from natural language sentences. Recent work has focused on learning such parsers directly from corpora made up of sentences paired with logical meaning representations (Kate et al., 2005; Kate and Mooney, 2006; Wong and Mooney, 2006, 2007; Zettlemoyer and Collins, 2005, 2007; Lu et al., 2008; Kwiatkowski et al., 2010). For example, in a flight booking domain we might have access to training examples such as: Sentence: I want flights from Boston Meaning: λx. f light(x) ∧ f rom(x,bos) 1512 and the goal is to learn a grammar that can map new, unseen, sentences onto their corresponding meanings, or logical forms. One approach to this problem has developed algorithms for leaning probabilistic CCG grammars (Zettlemoyer and Collins, 2005, 2007; Kwiatkowski et al., 2010). These grammars are well-suited to the task of semantic parsing, as they closely link syntax and semantics. They can b</context>
<context position="7913" citStr="Lu et al., 2008" startWordPosition="1230" endWordPosition="1233">cified lexical items for the learned grammar, proach we develop for inducing factored lexicons is we automatically generate sets of lexemes and lexi- also language independent, but scales well to these cal templates to model each example. This is a dif- challenging sentences. ficult learning problem, since the CCG analyses that There have been a number of other approaches for learning semantic parsers, including ones based on machine translation techniques (Papineni et al., 1997; Ramaswamy and Kleindienst, 2000; Wong and Mooney, 2006), parsing models (Miller et al., 1996; Ge and Mooney, 2006; Lu et al., 2008), in1A related tactic is commonly used in wide-coverage CCG parsers derived from treebanks, such as work by Hockenmaier and Steedman (2002) and Clark and Curran (2007). These parsers make extensive use of category-changing unary rules, to avoid data sparsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996; Thompson and Mooney, 2002; Tang and Mooney, 2000), probabilistic automata (He and Young, 2005, 200</context>
</contexts>
<marker>Lu, Ng, Lee, Zettlemoyer, 2008</marker>
<rawString>Lu, Wei, Hwee Tou Ng, Wee Sun Lee, and Luke S. Zettlemoyer. 2008. A generative model for parsing natural language to meaning representations. In Proceedings of The Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Miller</author>
<author>David Stallard</author>
<author>Robert J Bobrow</author>
<author>Richard L Schwartz</author>
</authors>
<title>A fully statistical approach to natural language interfaces.</title>
<date>1996</date>
<booktitle>In Proc. of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="7874" citStr="Miller et al., 1996" startWordPosition="1222" endWordPosition="1225">edited sentences. The learning apfully specified lexical items for the learned grammar, proach we develop for inducing factored lexicons is we automatically generate sets of lexemes and lexi- also language independent, but scales well to these cal templates to model each example. This is a dif- challenging sentences. ficult learning problem, since the CCG analyses that There have been a number of other approaches for learning semantic parsers, including ones based on machine translation techniques (Papineni et al., 1997; Ramaswamy and Kleindienst, 2000; Wong and Mooney, 2006), parsing models (Miller et al., 1996; Ge and Mooney, 2006; Lu et al., 2008), in1A related tactic is commonly used in wide-coverage CCG parsers derived from treebanks, such as work by Hockenmaier and Steedman (2002) and Clark and Curran (2007). These parsers make extensive use of category-changing unary rules, to avoid data sparsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996; Thompson and Mooney, 2002; Tang and Mooney, 2000), probabil</context>
</contexts>
<marker>Miller, Stallard, Bobrow, Schwartz, 1996</marker>
<rawString>Miller, Scott, David Stallard, Robert J. Bobrow, and Richard L. Schwartz. 1996. A fully statistical approach to natural language interfaces. In Proc. of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Le-Minh Nguyen</author>
<author>Akira Shimazu</author>
<author>Xuan-Hieu Phan</author>
</authors>
<title>Semantic parsing with structured SVM ensemble classification models.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions.</booktitle>
<contexts>
<context position="8619" citStr="Nguyen et al., 2006" startWordPosition="1335" endWordPosition="1338">anks, such as work by Hockenmaier and Steedman (2002) and Clark and Curran (2007). These parsers make extensive use of category-changing unary rules, to avoid data sparsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996; Thompson and Mooney, 2002; Tang and Mooney, 2000), probabilistic automata (He and Young, 2005, 2006), and ideas from string kernels and support vector machines (Kate and Mooney, 2006; Nguyen et al., 2006). More recent work has focused on training semantic parsers without supervision in the form of logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) replace semantic annotations in the training set with target answers which are more easily available. Goldwasser et al. (2011) present work on unsupervised learning of logical form structure. However, all of these systems require significantly more domain and language specific initialization than the approach presented here. Other work has learnt semantic analyses from text in the context of interactions in computational environme</context>
</contexts>
<marker>Nguyen, Shimazu, Phan, 2006</marker>
<rawString>Nguyen, Le-Minh, Akira Shimazu, and Xuan-Hieu Phan. 2006. Semantic parsing with structured SVM ensemble classification models. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="32383" citStr="Och and Ney, 2003" startWordPosition="5394" endWordPosition="5397">ument relation; and φ(p,Ty(a),i) for the predicate argument-type relation. Boolean operator features look at predicates that occurr together in conjunctions and disjunctions. For each variable vi that fills argument slot i in two conjoined predicates p1 and p2 we introduce a binary indicator feature φconj(i,p1,p2). We introduce similar features φdisj(i,p1,p2) for variables vi that are shared by predicates in a disjunction. Initialization The weights for lexeme features are initialized according to coocurrance statistics between words and logical constants. These are estimated with the Giza++ (Och and Ney, 2003) implementation of IBM Model 1. The initial weights for templates are set by adding −0.1 for each slash in the syntactic category and −2 if the template contains logical constants. Features on lexeme-template pairs and all parse features are initialized to zero. Systems We compare performance to all recentlypublished, directly-comparable results. For GeoQuery, this includes the ZC05, ZC07 (Zettlemoyer 1519 System Exact Match Rec. Pre. F1 ZC07 74.4 87.3 80.4 UBL 65.6 67.1 66.3 FUBL 81.9 82.1 82.0 Table 1: Performance on the Atis development set. System Exact Match Partial Match Rec. Pre. F1. Re</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Och, Franz Josef and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K A Papineni</author>
<author>S Roukos</author>
<author>T R Ward</author>
</authors>
<title>Feature-based language understanding.</title>
<date>1997</date>
<booktitle>In Proceedings of European Conference on Speech Communication and Technology.</booktitle>
<contexts>
<context position="7780" citStr="Papineni et al., 1997" startWordPosition="1208" endWordPosition="1211">approach does not scale well to training pairs. However, instead of constructing challenging, unedited sentences. The learning apfully specified lexical items for the learned grammar, proach we develop for inducing factored lexicons is we automatically generate sets of lexemes and lexi- also language independent, but scales well to these cal templates to model each example. This is a dif- challenging sentences. ficult learning problem, since the CCG analyses that There have been a number of other approaches for learning semantic parsers, including ones based on machine translation techniques (Papineni et al., 1997; Ramaswamy and Kleindienst, 2000; Wong and Mooney, 2006), parsing models (Miller et al., 1996; Ge and Mooney, 2006; Lu et al., 2008), in1A related tactic is commonly used in wide-coverage CCG parsers derived from treebanks, such as work by Hockenmaier and Steedman (2002) and Clark and Curran (2007). These parsers make extensive use of category-changing unary rules, to avoid data sparsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming a</context>
</contexts>
<marker>Papineni, Roukos, Ward, 1997</marker>
<rawString>Papineni, K. A., S. Roukos, and T. R. Ward. 1997. Feature-based language understanding. In Proceedings of European Conference on Speech Communication and Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Unsupervised semantic parsing.</title>
<date>2009</date>
<booktitle>In Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="9401" citStr="Poon and Domingos, 2009" startWordPosition="1459" endWordPosition="1462">(2011) replace semantic annotations in the training set with target answers which are more easily available. Goldwasser et al. (2011) present work on unsupervised learning of logical form structure. However, all of these systems require significantly more domain and language specific initialization than the approach presented here. Other work has learnt semantic analyses from text in the context of interactions in computational environments (Branavan et al. (2010), Vogel and Jurafsky (2010)); text grounded in partial observations of a world state (Liang et al., 2009); and from raw text alone (Poon and Domingos, 2009, 2010). There is also related work that uses the CCG grammar formalism. Clark and Curran (2003) present a method for learning the parameters of a log-linear CCG parsing model from fully annotated normal–form parse trees. Watkinson and Manandhar (1999) describe an unsupervised approach for learning syntactic CCG lexicons. Bos et al. (2004) present an algorithm for building semantic representations from CCG parses but requires fully–specified CCG derivations in the training data. 3 Overview of the Approach Here we give a formal definition of the problem and an overview of the learning approach.</context>
</contexts>
<marker>Poon, Domingos, 2009</marker>
<rawString>Poon, Hoifung and Pedro Domingos. 2009. Unsupervised semantic parsing. In Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Unsupervised ontology induction from text.</title>
<date>2010</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<marker>Poon, Domingos, 2010</marker>
<rawString>Poon, Hoifung and Pedro Domingos. 2010. Unsupervised ontology induction from text. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ganesh N Ramaswamy</author>
<author>Jan Kleindienst</author>
</authors>
<title>Hierarchical feature-based translation for scalable natural language understanding.</title>
<date>2000</date>
<booktitle>In Proceedings of International Conference on Spoken Language Processing.</booktitle>
<contexts>
<context position="7813" citStr="Ramaswamy and Kleindienst, 2000" startWordPosition="1212" endWordPosition="1215"> well to training pairs. However, instead of constructing challenging, unedited sentences. The learning apfully specified lexical items for the learned grammar, proach we develop for inducing factored lexicons is we automatically generate sets of lexemes and lexi- also language independent, but scales well to these cal templates to model each example. This is a dif- challenging sentences. ficult learning problem, since the CCG analyses that There have been a number of other approaches for learning semantic parsers, including ones based on machine translation techniques (Papineni et al., 1997; Ramaswamy and Kleindienst, 2000; Wong and Mooney, 2006), parsing models (Miller et al., 1996; Ge and Mooney, 2006; Lu et al., 2008), in1A related tactic is commonly used in wide-coverage CCG parsers derived from treebanks, such as work by Hockenmaier and Steedman (2002) and Clark and Curran (2007). These parsers make extensive use of category-changing unary rules, to avoid data sparsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996</context>
</contexts>
<marker>Ramaswamy, Kleindienst, 2000</marker>
<rawString>Ramaswamy, Ganesh N. and Jan Kleindienst. 2000. Hierarchical feature-based translation for scalable natural language understanding. In Proceedings of International Conference on Spoken Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Surface Structure and Interpretation.</title>
<date>1996</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="12865" citStr="Steedman, 1996" startWordPosition="2032" endWordPosition="2033">ases with logical expressions that can contain constants, quantifiers, logical connectors and lambda abstractions. We construct the meanings of sentences from the meanings of words and phrases using lambda-calculus operations. We use a version of the typed lambda calculus (Carpenter, 1997), in which the basic types include e, for entities; t, for truth values; and i for numbers. We also have function types that are assigned to lambda expressions. 1514 The expression λx.flight(x) takes an entity and returns a truth value, and has the function type he,ti. 4.2 Combinatory Categorial Grammar CCG (Steedman, 1996, 2000) is a linguistic formalism that tightly couples syntax and semantics, and can be used to model a wide range of language phenomena. A traditional CCG grammar includes a lexicon Λ with entries like the following: flights ` N :λx. f light(x) to ` (N\N)/NP:λy.λ f .λx. f (x) ∧to(x,y) Boston ` NP:bos where each lexical item w`X : h has words w, a syntactic category X, and a logical form h. For the first example, these are “flights,” N, and λx. flight(x). In this paper, we introduce a new way of representing lexical items as (lexeme, template) pairs, as described in section 5. CCG syntactic ca</context>
</contexts>
<marker>Steedman, 1996</marker>
<rawString>Steedman, Mark. 1996. Surface Structure and Interpretation. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>The MIT Press.</publisher>
<marker>Steedman, 2000</marker>
<rawString>Steedman, Mark. 2000. The Syntactic Process. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lappoon R Tang</author>
<author>Raymond J Mooney</author>
</authors>
<title>Automated construction of database interfaces: Integrating statistical and relational learning for semantic parsing.</title>
<date>2000</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</booktitle>
<contexts>
<context position="8464" citStr="Tang and Mooney, 2000" startWordPosition="1311" endWordPosition="1314">sing models (Miller et al., 1996; Ge and Mooney, 2006; Lu et al., 2008), in1A related tactic is commonly used in wide-coverage CCG parsers derived from treebanks, such as work by Hockenmaier and Steedman (2002) and Clark and Curran (2007). These parsers make extensive use of category-changing unary rules, to avoid data sparsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996; Thompson and Mooney, 2002; Tang and Mooney, 2000), probabilistic automata (He and Young, 2005, 2006), and ideas from string kernels and support vector machines (Kate and Mooney, 2006; Nguyen et al., 2006). More recent work has focused on training semantic parsers without supervision in the form of logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) replace semantic annotations in the training set with target answers which are more easily available. Goldwasser et al. (2011) present work on unsupervised learning of logical form structure. However, all of these systems require significantly more domain and language specific i</context>
</contexts>
<marker>Tang, Mooney, 2000</marker>
<rawString>Tang, Lappoon R. and Raymond J. Mooney. 2000. Automated construction of database interfaces: Integrating statistical and relational learning for semantic parsing. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia A Thompson</author>
<author>Raymond J Mooney</author>
</authors>
<title>Acquiring word-meaning mappings for natural language interfaces.</title>
<date>2002</date>
<journal>Journal of Artificial Intelligence Research</journal>
<volume>18</volume>
<contexts>
<context position="8440" citStr="Thompson and Mooney, 2002" startWordPosition="1307" endWordPosition="1310">Wong and Mooney, 2006), parsing models (Miller et al., 1996; Ge and Mooney, 2006; Lu et al., 2008), in1A related tactic is commonly used in wide-coverage CCG parsers derived from treebanks, such as work by Hockenmaier and Steedman (2002) and Clark and Curran (2007). These parsers make extensive use of category-changing unary rules, to avoid data sparsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996; Thompson and Mooney, 2002; Tang and Mooney, 2000), probabilistic automata (He and Young, 2005, 2006), and ideas from string kernels and support vector machines (Kate and Mooney, 2006; Nguyen et al., 2006). More recent work has focused on training semantic parsers without supervision in the form of logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) replace semantic annotations in the training set with target answers which are more easily available. Goldwasser et al. (2011) present work on unsupervised learning of logical form structure. However, all of these systems require significantly more domain</context>
</contexts>
<marker>Thompson, Mooney, 2002</marker>
<rawString>Thompson, Cynthia A. and Raymond J. Mooney. 2002. Acquiring word-meaning mappings for natural language interfaces. Journal of Artificial Intelligence Research 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Vogel</author>
<author>Dan Jurafsky</author>
</authors>
<title>Learning to follow navigational directions.</title>
<date>2010</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="9273" citStr="Vogel and Jurafsky (2010)" startWordPosition="1436" endWordPosition="1440">d on training semantic parsers without supervision in the form of logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) replace semantic annotations in the training set with target answers which are more easily available. Goldwasser et al. (2011) present work on unsupervised learning of logical form structure. However, all of these systems require significantly more domain and language specific initialization than the approach presented here. Other work has learnt semantic analyses from text in the context of interactions in computational environments (Branavan et al. (2010), Vogel and Jurafsky (2010)); text grounded in partial observations of a world state (Liang et al., 2009); and from raw text alone (Poon and Domingos, 2009, 2010). There is also related work that uses the CCG grammar formalism. Clark and Curran (2003) present a method for learning the parameters of a log-linear CCG parsing model from fully annotated normal–form parse trees. Watkinson and Manandhar (1999) describe an unsupervised approach for learning syntactic CCG lexicons. Bos et al. (2004) present an algorithm for building semantic representations from CCG parses but requires fully–specified CCG derivations in the tra</context>
</contexts>
<marker>Vogel, Jurafsky, 2010</marker>
<rawString>Vogel, Adam and Dan Jurafsky. 2010. Learning to follow navigational directions. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Watkinson</author>
<author>Suresh Manandhar</author>
</authors>
<title>Unsupervised lexical learning with categorial grammars using the LLL corpus.</title>
<date>1999</date>
<booktitle>In Proceedings of the 1st Workshop on Learning Language in Logic.</booktitle>
<contexts>
<context position="9653" citStr="Watkinson and Manandhar (1999)" startWordPosition="1498" endWordPosition="1502">antly more domain and language specific initialization than the approach presented here. Other work has learnt semantic analyses from text in the context of interactions in computational environments (Branavan et al. (2010), Vogel and Jurafsky (2010)); text grounded in partial observations of a world state (Liang et al., 2009); and from raw text alone (Poon and Domingos, 2009, 2010). There is also related work that uses the CCG grammar formalism. Clark and Curran (2003) present a method for learning the parameters of a log-linear CCG parsing model from fully annotated normal–form parse trees. Watkinson and Manandhar (1999) describe an unsupervised approach for learning syntactic CCG lexicons. Bos et al. (2004) present an algorithm for building semantic representations from CCG parses but requires fully–specified CCG derivations in the training data. 3 Overview of the Approach Here we give a formal definition of the problem and an overview of the learning approach. Problem We will learn a semantic parser that takes a sentences x and returns a logical form z representing its underlying meaning. We assume we have input data {(xi,zi)|i = 1...n} containing sentences xi and logical forms zi, for example xi =“Show me </context>
</contexts>
<marker>Watkinson, Manandhar, 1999</marker>
<rawString>Watkinson, Stephen and Suresh Manandhar. 1999. Unsupervised lexical learning with categorial grammars using the LLL corpus. In Proceedings of the 1st Workshop on Learning Language in Logic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuk Wah Wong</author>
<author>Raymond Mooney</author>
</authors>
<title>Learning for semantic parsing with statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL.</booktitle>
<contexts>
<context position="1526" citStr="Wong and Mooney, 2006" startWordPosition="202" endWordPosition="205">on in word usage. We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance benefits greatly from the lexical factoring. 1 Introduction Semantic parsers automatically recover representations of meaning from natural language sentences. Recent work has focused on learning such parsers directly from corpora made up of sentences paired with logical meaning representations (Kate et al., 2005; Kate and Mooney, 2006; Wong and Mooney, 2006, 2007; Zettlemoyer and Collins, 2005, 2007; Lu et al., 2008; Kwiatkowski et al., 2010). For example, in a flight booking domain we might have access to training examples such as: Sentence: I want flights from Boston Meaning: λx. f light(x) ∧ f rom(x,bos) 1512 and the goal is to learn a grammar that can map new, unseen, sentences onto their corresponding meanings, or logical forms. One approach to this problem has developed algorithms for leaning probabilistic CCG grammars (Zettlemoyer and Collins, 2005, 2007; Kwiatkowski et al., 2010). These grammars are well-suited to the task of semantic pa</context>
<context position="7837" citStr="Wong and Mooney, 2006" startWordPosition="1216" endWordPosition="1219"> instead of constructing challenging, unedited sentences. The learning apfully specified lexical items for the learned grammar, proach we develop for inducing factored lexicons is we automatically generate sets of lexemes and lexi- also language independent, but scales well to these cal templates to model each example. This is a dif- challenging sentences. ficult learning problem, since the CCG analyses that There have been a number of other approaches for learning semantic parsers, including ones based on machine translation techniques (Papineni et al., 1997; Ramaswamy and Kleindienst, 2000; Wong and Mooney, 2006), parsing models (Miller et al., 1996; Ge and Mooney, 2006; Lu et al., 2008), in1A related tactic is commonly used in wide-coverage CCG parsers derived from treebanks, such as work by Hockenmaier and Steedman (2002) and Clark and Curran (2007). These parsers make extensive use of category-changing unary rules, to avoid data sparsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996; Thompson and Mooney, 2</context>
</contexts>
<marker>Wong, Mooney, 2006</marker>
<rawString>Wong, Yuk Wah and Raymond Mooney. 2006. Learning for semantic parsing with statistical machine translation. In Proceedings of the Human Language Technology Conference of the NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuk Wah Wong</author>
<author>Raymond Mooney</author>
</authors>
<title>Learning synchronous grammars for semantic parsing with lambda calculus.</title>
<date>2007</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="30342" citStr="Wong and Mooney (2007)" startWordPosition="5068" endWordPosition="5071">rsing datasets: GeoQuery, which is made up of natural language queries to a database of geographical information; and Atis, which contains natural language queries to a flight booking system. The Geo880 dataset has 880 (English-sentence, logicalform) pairs split into a training set of 600 pairs and a test set of 280. The Geo250 data is a subset of the Geo880 sentences that have been translated into Japanese, Spanish and Turkish as well as the original English. We follow the standard evaluation procedure for Geo250, using 10-fold cross validation experiments with the same splits of the data as Wong and Mooney (2007). The Atis dataset contains 5410 (sentence, logical-form) pairs split into a 4480 example training set, a 480 example development set and a 450 example test set. Evaluation Metrics We report exact match Recall (percentage of sentences for which the correct logical-form was returned), Precision (percentage of returned logical-forms that are correct) and F1 (harmonic mean of Precision and Recall). For Atis we also report partial match Recall (percentage of correct literals returned), Precision (percentage of returned literals that are correct) and F1, computed as described by Zettlemoyer and Col</context>
<context position="33217" citStr="Wong and Mooney, 2007" startWordPosition="5540" endWordPosition="5543">rs and all parse features are initialized to zero. Systems We compare performance to all recentlypublished, directly-comparable results. For GeoQuery, this includes the ZC05, ZC07 (Zettlemoyer 1519 System Exact Match Rec. Pre. F1 ZC07 74.4 87.3 80.4 UBL 65.6 67.1 66.3 FUBL 81.9 82.1 82.0 Table 1: Performance on the Atis development set. System Exact Match Partial Match Rec. Pre. F1. Rec. Pre. F1 ZC07 84.6 85.8 85.2 96.7 95.1 95.9 HY06 - - - - - 90.3 UBL 71.4 72.1 71.7 78.2 98.2 87.1 FUBL 82.8 82.8 82.8 95.2 93.6 94.6 Table 2: Performance on the Atis test set. and Collins, 2005, 2007), λ-WASP (Wong and Mooney, 2007), UBL (Kwiatkowski et al., 2010) systems and DCS (Liang et al., 2011). For Atis, we report results from HY06 (He and Young, 2006), ZC07, and UBL. 9 Results Tables 1-4 present the results on the Atis and Geoquery domains. In all cases, FUBL achieves at or near state-of-the-art recall (overall number of correct parses) when compared to directly comparable systems and it significantly outperforms UBL on Atis. On Geo880 the only higher recall is achieved by DCS with prototypes - which uses significant English-specific resources, including manually specified lexical content, but does not require tr</context>
</contexts>
<marker>Wong, Mooney, 2007</marker>
<rawString>Wong, Yuk Wah and Raymond Mooney. 2007. Learning synchronous grammars for semantic parsing with lambda calculus. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John M Zelle</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to parse database queries using inductive logic programming.</title>
<date>1996</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="8413" citStr="Zelle and Mooney, 1996" startWordPosition="1303" endWordPosition="1306"> and Kleindienst, 2000; Wong and Mooney, 2006), parsing models (Miller et al., 1996; Ge and Mooney, 2006; Lu et al., 2008), in1A related tactic is commonly used in wide-coverage CCG parsers derived from treebanks, such as work by Hockenmaier and Steedman (2002) and Clark and Curran (2007). These parsers make extensive use of category-changing unary rules, to avoid data sparsity for systematically related categories (such as those related by type-raising). We will automatically learn to represent these types of generalizations in the factored lexicon. 1513 ductive logic programming algorithms (Zelle and Mooney, 1996; Thompson and Mooney, 2002; Tang and Mooney, 2000), probabilistic automata (He and Young, 2005, 2006), and ideas from string kernels and support vector machines (Kate and Mooney, 2006; Nguyen et al., 2006). More recent work has focused on training semantic parsers without supervision in the form of logical-form annotations. Clarke et al. (2010) and Liang et al. (2011) replace semantic annotations in the training set with target answers which are more easily available. Goldwasser et al. (2011) present work on unsupervised learning of logical form structure. However, all of these systems requir</context>
</contexts>
<marker>Zelle, Mooney, 1996</marker>
<rawString>Zelle, John M. and Raymond J. Mooney. 1996. Learning to parse database queries using inductive logic programming. In Proceedings of the National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke S Zettlemoyer</author>
<author>Michael Collins</author>
</authors>
<title>Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Uncertainty in Artificial Intelligence.</booktitle>
<contexts>
<context position="1563" citStr="Zettlemoyer and Collins, 2005" startWordPosition="207" endWordPosition="210">sent an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model. Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance benefits greatly from the lexical factoring. 1 Introduction Semantic parsers automatically recover representations of meaning from natural language sentences. Recent work has focused on learning such parsers directly from corpora made up of sentences paired with logical meaning representations (Kate et al., 2005; Kate and Mooney, 2006; Wong and Mooney, 2006, 2007; Zettlemoyer and Collins, 2005, 2007; Lu et al., 2008; Kwiatkowski et al., 2010). For example, in a flight booking domain we might have access to training examples such as: Sentence: I want flights from Boston Meaning: λx. f light(x) ∧ f rom(x,bos) 1512 and the goal is to learn a grammar that can map new, unseen, sentences onto their corresponding meanings, or logical forms. One approach to this problem has developed algorithms for leaning probabilistic CCG grammars (Zettlemoyer and Collins, 2005, 2007; Kwiatkowski et al., 2010). These grammars are well-suited to the task of semantic parsing, as they closely link syntax an</context>
<context position="6017" citStr="Zettlemoyer and Collins (2005" startWordPosition="941" endWordPosition="944"> a large pro- 2 Related work portion of the variation between lexical items for There has been significant previous work on learna given class of words is systematic. Therefore it ing semantic parsers from training sentences lashould be represented once and applied to a small set belled with logical form meaning representations. of basic lexical units. 1 We develop a factored lex- We extend a line of research that has addressed icon that captures this insight by distinguishing lex- this problem by developing CCG grammar inducemes, which pair words with logical constants, from tion techniques. Zettlemoyer and Collins (2005, lexical templates, which map lexemes to full lexical 2007) presented approaches that use hand generitems. As we will see, this can lead to a significantly ated, English-language specific rules to generate lexmore compact lexicon that can be learned from less ical items from logical forms as well as English data. Each word or phrase will be associated with a specific type-shifting rules and relaxations of the few lexemes that can be combined with a shared set CCG combinators to model spontaneous, unedited of general templates. sentences. Zettlemoyer and Collins (2009) extends We develop an ap</context>
</contexts>
<marker>Zettlemoyer, Collins, 2005</marker>
<rawString>Zettlemoyer, Luke S. and Michael Collins. 2005. Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars. In Proceedings of the Conference on Uncertainty in Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke S Zettlemoyer</author>
<author>Michael Collins</author>
</authors>
<title>Online learning of relaxed CCG grammars for parsing to logical form.</title>
<date>2007</date>
<booktitle>In Proc. of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</booktitle>
<contexts>
<context position="5313" citStr="Zettlemoyer and Collins, 2007" startWordPosition="826" endWordPosition="829">ith the con- text that can be difficult to analyze with a formal stant bos that represents its meaning. However, item grammar representation. Our approach achieves at (7) also adds the predicate from to the logical form. or near state-of-the-art recall across all conditions, This might be used to analyse somewhat elliptical, despite having no English or domain-specific inforunedited sentences such as “Show me flights Boston mation built in. We believe that ours is the only systo New York,” which can be challenging for seman- tem of sufficient generality to run with this degree of tic parsers (Zettlemoyer and Collins, 2007). success on all of these datasets. This paper builds upon the insight that a large pro- 2 Related work portion of the variation between lexical items for There has been significant previous work on learna given class of words is systematic. Therefore it ing semantic parsers from training sentences lashould be represented once and applied to a small set belled with logical form meaning representations. of basic lexical units. 1 We develop a factored lex- We extend a line of research that has addressed icon that captures this insight by distinguishing lex- this problem by developing CCG grammar</context>
<context position="21771" citStr="Zettlemoyer and Collins (2007)" startWordPosition="3582" endWordPosition="3585">n the lexeme (Boston,[bos]) and have a template that introduces the from constant. This would model the desired generalization with a single lexeme per city. In order to permit the introduction of extra constants into lexical items, we allow the creation of templates that contain logical constants through partial factorings. For instance, the template below can introduce the predicate from λ(ω,v).[ω `N\N :λ f.λx.f(x)∧ from(x,v1)] The use of templates to introduce extra semantic constants into a lexical item is similar to, but more general than, the English-specific type-shifting rules used in Zettlemoyer and Collins (2007), which were introduced to model spontaneous, unedited text. They are useful, as we will see, in learning to recover semantic content that is implied, but not explicitly stated, such as our original motivating phrase “flights Boston to New York.” To propose templates which introduce semantic content, during learning, we build on the intuition that we need to recover from missing words, such as in the example above. In this scenario, there should also be other sentences that actually include the word, in our example this would be something like “flights from Boston.” We will also assume that we</context>
<context position="30953" citStr="Zettlemoyer and Collins (2007)" startWordPosition="5163" endWordPosition="5166">g and Mooney (2007). The Atis dataset contains 5410 (sentence, logical-form) pairs split into a 4480 example training set, a 480 example development set and a 450 example test set. Evaluation Metrics We report exact match Recall (percentage of sentences for which the correct logical-form was returned), Precision (percentage of returned logical-forms that are correct) and F1 (harmonic mean of Precision and Recall). For Atis we also report partial match Recall (percentage of correct literals returned), Precision (percentage of returned literals that are correct) and F1, computed as described by Zettlemoyer and Collins (2007). Features We introduce two types of features to discriminate between parses: lexical features and logical-form features. Lexical features fire on the lexemes and templates used to build the lexical items used in a parse. For each (lexeme,template) pair used to create a lexical item we have indicator features φl for the lexeme used, φt for the template used, and φ(l,t) for the pair that was used. We assign the features on lexical templates a weight of 0.1 to prevent them from swamping the far less frequent but equally informative lexeme features. Logical-form features are computed on the lambd</context>
</contexts>
<marker>Zettlemoyer, Collins, 2007</marker>
<rawString>Zettlemoyer, Luke S. and Michael Collins. 2007. Online learning of relaxed CCG grammars for parsing to logical form. In Proc. of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke S Zettlemoyer</author>
<author>Michael Collins</author>
</authors>
<title>Learning context-dependent mappings from sentences to logical form.</title>
<date>2009</date>
<booktitle>In Proceedings of The Joint Conference of the Association for Computational Linguistics and International Joint Conference on Natural Language Processing.</booktitle>
<contexts>
<context position="6592" citStr="Zettlemoyer and Collins (2009)" startWordPosition="1033" endWordPosition="1036">ts, from tion techniques. Zettlemoyer and Collins (2005, lexical templates, which map lexemes to full lexical 2007) presented approaches that use hand generitems. As we will see, this can lead to a significantly ated, English-language specific rules to generate lexmore compact lexicon that can be learned from less ical items from logical forms as well as English data. Each word or phrase will be associated with a specific type-shifting rules and relaxations of the few lexemes that can be combined with a shared set CCG combinators to model spontaneous, unedited of general templates. sentences. Zettlemoyer and Collins (2009) extends We develop an approach to learning factored, this work to the case of learning in context depenprobabilistic CCG grammars for semantic pars- dent environments. Kwiatkowski et al. (2010) deing. Following previous work (Kwiatkowski et al., scribed an approach for language-independent learn2010), we make use of a higher-order unification ing that replaces the hand-specified templates with learning scheme that defines a space of CCG gram- a higher-order-unification-based lexical induction mars consistent with the (sentence, logical form) method, but their approach does not scale well to t</context>
</contexts>
<marker>Zettlemoyer, Collins, 2009</marker>
<rawString>Zettlemoyer, Luke S. and Michael Collins. 2009. Learning context-dependent mappings from sentences to logical form. In Proceedings of The Joint Conference of the Association for Computational Linguistics and International Joint Conference on Natural Language Processing.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>