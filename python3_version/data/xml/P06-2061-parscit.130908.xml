<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001654">
<title confidence="0.9985035">
Integration of Speech to Computer-Assisted Translation Using
Finite-State Automata
</title>
<author confidence="0.983506">
Shahram Khadivi Richard Zens Hermann Ney
</author>
<affiliation confidence="0.94188">
Lehrstuhl f¨ur Informatik 6 – Computer Science Department
RWTH Aachen University, D-52056 Aachen, Germany
</affiliation>
<email confidence="0.994565">
{khadivi,zens,ney}@cs.rwth-aachen.de
</email>
<sectionHeader confidence="0.993769" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999897">
State-of-the-art computer-assisted transla-
tion engines are based on a statistical pre-
diction engine, which interactively pro-
vides completions to what a human trans-
lator types. The integration of human
speech into a computer-assisted system is
also a challenging area and is the aim of
this paper. So far, only a few methods
for integrating statistical machine transla-
tion (MT) models with automatic speech
recognition (ASR) models have been stud-
ied. They were mainly based on N-
best rescoring approach. N-best rescor-
ing is not an appropriate search method
for building a real-time prediction engine.
In this paper, we study the incorporation
of MT models and ASR models using
finite-state automata. We also propose
some transducers based on MT models for
rescoring the ASR word graphs.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999874">
A desired feature of computer-assisted transla-
tion (CAT) systems is the integration of the hu-
man speech into the system, as skilled human
translators are faster at dictating than typing the
translations (Brown et al., 1994). Additionally,
incorporation of a statistical prediction engine, i.e.
a statistical interactive machine translation system,
to the CAT system is another useful feature. A sta-
tistical prediction engine provides the completions
to what a human translator types (Foster et al.,
1997; Och et al., 2003). Then, one possible proce-
dure for skilled human translators is to provide the
oral translation of a given source text and then to
post-edit the recognized text. In the post-editing
step, a prediction engine helps to decrease the
amount of human interaction (Och et al., 2003).
In a CAT system with integrated speech, two
sources of information are available to recognize
the speech input: the target language speech
and the given source language text. The target
language speech is a human-produced translation
of the source language text. Statistical machine
translation (MT) models are employed to take into
account the source text for increasing the accuracy
of automatic speech recognition (ASR) models.
</bodyText>
<sectionHeader confidence="0.474753" genericHeader="related work">
Related Work
</sectionHeader>
<bodyText confidence="0.999940428571429">
The idea of incorporating ASR and MT models
was independently initiated by two groups:
researchers at IBM (Brown et al., 1994),
and researchers involved in the TransTalk
project (Dymetman et al., 1994; Brousseau
et al., 1995). In (Brown et al., 1994), the
authors proposed a method to integrate the IBM
translation model 2 (Brown et al., 1993) with
an ASR system. The main idea was to design
a language model (LM) to combine the trigram
language model probability with the translation
probability for each target word. They reported a
perplexity reduction, but no recognition results.
In the TransTalk project, the authors improved
the ASR performance by rescoring the ASR
N-best lists with a translation model. They also
introduced the idea of a dynamic vocabulary for
a speech recognition system where translation
models were generated for each source language
sentence. The better performing of the two is the
N-best rescoring.
Recently, (Khadivi et al., 2005) and (Paulik et
al., 2005a; Paulik et al., 2005b) have studied the
integration of ASR and MT models. The first
work showed a detailed analysis of the effect of
different MT models on rescoring the ASR N-best
lists. The other two works considered two parallel
N-best lists, generated by MT and ASR systems,
</bodyText>
<page confidence="0.98874">
467
</page>
<note confidence="0.723976">
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 467–474,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999992363636364">
respectively. They showed improvement in the
ASR N-best rescoring when some proposed fea-
tures are extracted from the MT N-best list. The
main concept among all features was to generate
different kinds of language models from the MT
N-best list.
All of the above methods are based on an N-
best rescoring approach. In this paper, we study
different methods for integrating MT models to
ASR word graphs instead of N-best list. We
consider ASR word graphs as finite-state automata
(FSA), then the integration of MT models to ASR
word graphs can benefit from FSA algorithms.
The ASR word graphs are a compact representa-
tion of possible recognition hypotheses. Thus, the
integration of MT models to ASR word graphs can
be considered as an N-best rescoring but with very
large value for N. Another advantage of working
with ASR word graphs is the capability to pass
on the word graphs for further processing. For
instance, the resulting word graph can be used in
the prediction engine of a CAT system (Och et al.,
2003).
The remaining part is structured as follows: in
Section 2, a general model for an automatic text
dictation system in the computer-assisted transla-
tion framework will be described. In Section 3,
the details of the machine translation system and
the speech recognition system along with the lan-
guage model will be explained. In Section 4,
different methods for integrating MT models into
ASR models will be described, and also the exper-
imental results will be shown in the same section.
</bodyText>
<sectionHeader confidence="0.97766" genericHeader="method">
2 Speech-Enabled CAT Models
</sectionHeader>
<bodyText confidence="0.997852111111111">
In a speech-enabled computer-assisted translation
system, we are given a source language sentence
fJ1 = f1 ... fj ... fJ, which is to be translated into
a target language sentence eI1 = e1 ... ei ... eI,
and an acoustic signal xT1 = x1 ... xt ... xT,
which is the spoken target language sentence.
Among all possible target language sentences, we
will choose the sentence with the highest probabil-
ity:
</bodyText>
<equation confidence="0.980088">
{Pr(eI1|fJ1 , xT1 )} (1)
{Pr(eI1)Pr(fJ1 |eI1)Pr(xT1 |eI1)}(2)
</equation>
<bodyText confidence="0.995554">
Eq. 1 is decomposed into Eq. 2 by assuming
conditional independency between xT1 and fJ1 .
The decomposition into three knowledge sources
allows for an independent modeling of the target
language model Pr(eI1), the translation model
Pr(fJ1 |eI1) and the acoustic model Pr(xT1 |eI1).
Another approach for modeling the posterior
probability Pr(eI1|fJ1 , xT1 )is direct modeling us-
ing a log-linear model. The decision rule is given
by:
</bodyText>
<equation confidence="0.984067">
1 λmhm(eI 1, fJ 1 ,xT 1 ) (3)
</equation>
<bodyText confidence="0.99995895">
Each of the terms hm(eI1, fJ1 , xT1 )denotes one
of the various models which are involved in the
recognition procedure. Each individual model is
weighted by its scaling factor λm. As there is
no direct dependence between fJ1 and xT1 , the
hm(eI1, fJ1 , xT1 )is in one of these two forms:
hm(eI1, xT1 ) and hm(eI1, fJ1 ). Due to the argmax
operator which denotes the search, no renormal-
ization is considered in Eq. 3. This approach has
been suggested by (Papineni et al., 1997; Papineni
et al., 1998) for a natural language understanding
task, by (Beyerlein, 1998) for an ASR task, and
by (Och and Ney, 2002) for an MT task. This
approach is a generalization of Eq. 2. The di-
rect modeling has the advantage that additional
models can be easily integrated into the overall
system. The model scaling factors λM1 are trained
on a development corpus according to the final
recognition quality measured by the word error
rate (WER)(Och, 2003).
</bodyText>
<subsectionHeader confidence="0.556252">
Search
</subsectionHeader>
<bodyText confidence="0.9998765">
The search in the MT and the ASR systems is
already very complex, therefore a fully integrated
search to combine ASR and MT models will
considerably increase the complexity. To reduce
the complexity of the search, we perform two
independent searches with the MT and the ASR
systems, the search result of each system will be
represented as a large word graph. We consider
MT and ASR word graphs as FSA. Then, we are
able to use FSA algorithms to integrate MT and
ASR word graphs. The FSA implementation of
the search allows us to use standard optimized
algorithms, e.g. available from an open source
toolkit (Kanthak and Ney, 2004).
The recognition process is performed in two
steps. First, the baseline ASR system generates a
word graph in the FSA format for a given utterance
xT1 . Second, the translation models rescore each
word graph based on the corresponding source
language sentence. For each utterance, the deci-
sion about the best sentence is made according to
the recognition and the translation models.
</bodyText>
<equation confidence="0.900605625">
ˆe1 =argmax
ˆI
I,ei
�=argmax
I,ei
ˆe 1 = argmax � M
ˆI E
I,ei m=1
</equation>
<page confidence="0.999128">
468
</page>
<sectionHeader confidence="0.996753" genericHeader="method">
3 Baseline Components
</sectionHeader>
<bodyText confidence="0.999828333333333">
In this section, we briefly describe the basic sys-
tem components, namely the MT and the ASR
systems.
</bodyText>
<subsectionHeader confidence="0.999354">
3.1 Machine Translation System
</subsectionHeader>
<bodyText confidence="0.999988666666667">
We make use of the RWTH phrase-based statis-
tical machine translation system for the English
to German automatic translation. The system in-
cludes the following models: an n-gram language
model, a phrase translation model and a word-
based lexicon model. The latter two models are
used for both directions: German to English and
English to German. Additionally, a word penalty
and a phrase penalty are included. The reordering
model of the baseline system is distance-based, i.e.
it assigns costs based on the distance from the end
position of a phrase to the start position of the next
phrase. More details about the baseline system
can be found in (Zens and Ney, 2004; Zens et al.,
2005).
</bodyText>
<subsectionHeader confidence="0.999867">
3.2 Automatic Speech Recognition System
</subsectionHeader>
<bodyText confidence="0.999966875">
The acoustic model of the ASR system is trained
on the VerbMobil II corpus (Sixtus et al., 2000).
The corpus consists of German large-vocabulary
conversational speech: 36k training sentences
(61.5h) from 857 speakers. The test corpus is
created from the German part of the bilingual
English-German XEROX corpus (Khadivi et al.,
2005): 1562 sentences including 18k running
words (2.6h) from 10 speakers. The test cor-
pus contains 114 out-of-vocabulary (OOV) words.
The remaining part of the XEROX corpus is used
to train a back off trigram language model us-
ing the SRI language modeling toolkit (Stolcke,
2002). The LM perplexity of the speech recogni-
tion test corpus is about 83. The acoustic model of
the ASR system can be characterized as follows:
</bodyText>
<listItem confidence="0.999228384615385">
• recognition vocabulary of 16716 words;
• 3-state-HMM topology with skip;
• 2500 decision tree based generalized within-
word triphone states including noise plus one
state for silence;
• 237k gender independent Gaussian densities
with global pooled diagonal covariance;
• 16 MFCC features;
• 33 acoustic features after applying LDA;
• LDA is fed with 11 subsequent MFCC vec-
tors;
• maximum likelihood training using Viterbi
approximation.
</listItem>
<tableCaption confidence="0.959145">
Table 1: Statistics of the machine translation cor-
pus.
</tableCaption>
<table confidence="0.998798363636364">
English German
Train: Sentences 47 619
Running Words 528 779 467 633
Vocabulary 9 816 16 716
Singletons 2 302 6 064
Dev: Sentences 700
Running Words 8 823 8 050
Unknown words 56 108
Eval: Sentences 862
Running Words 11 019 10 094
Unknown words 58 100
</table>
<bodyText confidence="0.999537666666667">
The test corpus recognition word error rate is
20.4%. Compared to the previous system (Khadivi
et al., 2005), which has a WER of 21.2%, we
obtain a 3.8% relative improvement in WER. This
improvement is due to a better and complete opti-
mization of the overall ASR system.
</bodyText>
<sectionHeader confidence="0.996155" genericHeader="method">
4 Integration Approaches
</sectionHeader>
<bodyText confidence="0.999934444444445">
In this section, we will introduce several ap-
proaches to integrate the MT models with the ASR
models. To present the content of this section in a
more reader-friendly way, we will first explain the
task and corpus statistics, then we will present the
results of N-best rescoring. Afterwards, we will
describe the new methods for integrating the MT
models with the ASR models. In each sub-section,
we will also present the recognition results.
</bodyText>
<subsectionHeader confidence="0.984234">
4.1 Task
</subsectionHeader>
<bodyText confidence="0.927781454545455">
The translation models are trained on the part of
the English-German XEROX corpus which was
not used in the speech recognition test corpus. We
divide the speech recognition test corpus into two
parts, the first 700 utterances as the development
corpus and the rest as the evaluation corpus. The
development corpus is used to optimize the scal-
ing factors of different models (explained in Sec-
tion 2). The statistics of the corpus are depicted in
Table 1. The German part of the training corpus is
also used to train the language model.
</bodyText>
<subsectionHeader confidence="0.989788">
4.2 N-best Rescoring
</subsectionHeader>
<bodyText confidence="0.99997625">
To rescore the N-best lists, we use the method
of (Khadivi et al., 2005). But the results shown
here are different from that work due to a better
optimization of the overall ASR system, using a
</bodyText>
<page confidence="0.999784">
469
</page>
<tableCaption confidence="0.9963635">
Table 2: Recognition WER [%] using N-best
rescoring method.
</tableCaption>
<table confidence="0.9930784">
Models Dev Eval
MT 47.1 50.5
ASR 19.3 21.3
ASR+MT IBM-1 17.8 19.0
HMM 18.2 19.2
IBM-3 17.1 18.4
IBM-4 17.1 18.3
IBM-5 16.6 18.2
Phrase 18.8 20.3
-based
</table>
<bodyText confidence="0.998956888888889">
better MT system, and generating a larger N-best
list from the ASR word graphs. We rescore the
ASR N-best lists with the standard HMM (Vogel
et al., 1996) and IBM (Brown et al., 1993) MT
models. The development and evaluation sets N-
best lists sizes are sufficiently large to achieve
almost the best possible results, on average 1738
hypotheses per each source sentence are extracted
from the ASR word graphs.
The recognition results are summarized in Ta-
ble 2. In this table, the translation results of the
MT system are shown first, which are obtained
using the phrase-based approach. Then the recog-
nition results of the ASR system are shown. After-
wards, the results of combined speech recognition
and translation models are presented.
For each translation model, the N-best lists
are rescored based on the translation probability
p(ei fi) of that model and the probabilities of
speech recognition and language models. In the
last row of Table 2, the N-best lists are rescored
based on the full machine translation system ex-
plained in Section 3.1.
The best possible hypothesis achievable from
the N-best list has the WER (oracle WER) of
11.2% and 12.4% for development and test sets,
respectively.
</bodyText>
<subsectionHeader confidence="0.983646">
4.3 Direct Integration
</subsectionHeader>
<bodyText confidence="0.998674470588235">
At the first glance, an obvious method to combine
the ASR and MT systems is the integration at the
level of word graphs. This means the ASR system
generates a large word graph for the input target
language speech, and the MT system also gener-
ates a large word graph for the source language
text. Both MT and ASR word graphs are in the
target language. These two word graphs can be
considered as two FSA, then using FSA theory,
we can integrate two word graphs by applying the
composition algorithm.
We conducted a set of experiments to integrate
the ASR and MT systems using this method. We
obtain a WER of 19.0% and 20.9% for devel-
opment and evaluation sets, respectively. The
results are comparable to N-best rescoring results
for the phrase-based model which is presented in
Table 2. The achieved improvements over the
ASR baseline are statistically significant at the
99% level (Bisani and Ney, 2004). However, the
results are not promising compared to the results
of the rescoring method presented in Table 2 for
HMM and IBM translation models. A detailed
analysis revealed that only 31.8% and 26.7% of
sentences in the development and evaluation sets
have identical paths in both FSA, respectively. In
other words, the search algorithm was not able to
find any identical paths in two given FSA for the
remaining sentences. Thus, the two FSA are very
different from each other. One explanation for
the failure of this method is the large difference
between the WERs of two systems, as shown in
Table 2 the WER for the MT system is more than
twice as high as for the ASR system.
</bodyText>
<subsectionHeader confidence="0.82258">
4.4 Integrated Search
</subsectionHeader>
<bodyText confidence="0.999939636363637">
In Section 4.3, two separate word graphs are
generated using the MT and the ASR systems.
Another explanation for the failure of the direct
integration method is the independent search to
generate the word graphs. The search in the MT
and the ASR systems is already very complex,
therefore a full integrated search to combine ASR
and MT models will considerably increase the
complexity.
However, it is possible to reduce this problem
by integrating the ASR word graphs into the gen-
eration process of the MT word graphs. This
means, the ASR word graph is used in addition to
the usual language model. This kind of integration
forces the MT system to generate identical paths to
those in the ASR word graph. Using this approach,
the number of identical paths in MT and ASR
word graphs are increased to 39.7% and 34.4%
of the sentences in development and evaluation
sets, respectively. The WER of the integrated
system are 19.0% and 20.7% for development and
evaluation sets.
</bodyText>
<subsectionHeader confidence="0.959109">
4.5 Lexicon-Based Transducer
</subsectionHeader>
<bodyText confidence="0.99923">
The idea of a dynamic vocabulary, restricting and
weighting the word lexicon of the ASR was first
</bodyText>
<page confidence="0.989039">
470
</page>
<bodyText confidence="0.999331944444444">
introduced in (Brousseau et al., 1995). The idea
was also seen later in (Paulik et al., 2005b), they
extract the words of the MT N-best list to restrict
the vocabulary of the ASR system. But they both
reported a negative effect from this method on
the recognition accuracy. Here, we extend the
dynamic vocabulary idea by weighting the ASR
vocabulary based on the source language text and
the translation models. We use the lexicon model
of the HMM and the IBM MT models. Based on
these lexicon models, we assign to each possible
target word e the probability Pr(e|fJ1 ). One way
to compute this probability is inspired by IBM
Model 1:
We can design a simple transducer (or more pre-
cisely an acceptor) using probability in Eq. 4 to
efficiently rescore all paths (hypotheses) in the
word graph with IBM Model 1:
</bodyText>
<equation confidence="0.9991492">
I J
PIBM-1(eI1 |fJ1 ) = 1
(J + 1 ll
(J + 1) · p(ei|fJ
1 1 )
</equation>
<bodyText confidence="0.9994535">
The transducer is formed by one node and a num-
ber of self loops for each target language word. In
each arc of this transducer, the input label is target
word e and the weight is − log 1
</bodyText>
<equation confidence="0.589618">
J+1 · p(e|fJ1 ).
</equation>
<bodyText confidence="0.999941214285714">
We conducted experiments using the proposed
transducer. We built different transducers with the
lexicons of HMM and IBM translation models. In
Table 3, the recognition results of the rescored
word graphs are shown. The results are very
promising compared to the N-best list rescoring,
especially as the designed transducer is very sim-
ple. Similar to the results for the N-best rescoring
approach, these experiments also show the benefit
of using HMM and IBM Models to rescore the
ASR word graphs.
Due to its simplicity, this model can be easily
integrated into the ASR search. It is a sentence
specific unigram LM.
</bodyText>
<subsectionHeader confidence="0.980388">
4.6 Phrase-Based Transducer
</subsectionHeader>
<bodyText confidence="0.994518">
The phrase-based translation model is the main
component of our translation system. The pairs
of source and corresponding target phrases are
extracted from the word-aligned bilingual training
</bodyText>
<tableCaption confidence="0.977726">
Table 3: Recognition WER [%] using lexicon-
based transducer to rescore ASR word graphs.
</tableCaption>
<table confidence="0.932141">
Models Dev Eval
ASR 19.3 21.3
ASR+MT IBM-1 17.5 19.0
HMM 17.8 19.2
IBM-3 17.7 18.8
IBM-4 17.8 18.8
IBM-5 17.6 18.9
J
</table>
<bodyText confidence="0.999359292682927">
corpus (Zens and Ney, 2004). In this section, we
design a transducer to rescore the ASR word graph
using the phrase-based model of the MT system.
For each source language sentence, we extract all
possible phrases from the word-aligned training
corpus. Using the target part of these phrases
we build a transducer similar to the lexicon-based
transducer. But instead of a target word on each
arc, we have the target part of a phrase. The weight
of each arc is the negative logarithm of the phrase
translation probability.
This transducer is a good approximation of non-
monotone phrase-based-lexicon score. Using the
designed transducer it is possible that some parts
of the source texts are not covered or covered more
than once. Then, this model can be compared
to the IBM-3 and IBM-4 models, as they also
have the same characteristic in covering the source
words. The above assumption is not critical for
rescoring the ASR word graphs, as we are con-
fident that the word order is correct in the ASR
output. In addition, we assume low probability for
the existence of phrase pairs that have the same
target phrase but different source phrases within a
particular source language sentence.
Using the phrase-based transducer to rescore
the ASR word graph results in WER of 18.8%
and 20.2% for development and evaluation sets,
respectively. The improvements are statistically
significant at the 99% level compared to the ASR
system. The results are very similar to the results
obtained using N-best rescoring method. But
the transducer implementation is much simpler
because it does not consider the word-based lex-
icon, the word penalty, the phrase penalty, and
the reordering models, it just makes use of phrase
translation model. The designed transducer is
much faster in rescoring the word graph than the
MT system in rescoring the N-best list. The av-
erage speed to rescore the ASR word graphs with
this transducer is 49.4 words/sec (source language
</bodyText>
<equation confidence="0.9994002">
p(e|fj)
Pr(e |fJ1 ) = 1
J + 1
j=0
)z
I
p(ei|fj)
i=1 j=0
I
i=1
</equation>
<page confidence="0.977117">
471
</page>
<bodyText confidence="0.999977478260869">
text words), while the average speed to translate
the source language text using the MT system is
8.3 words/sec. The average speed for rescoring
the N-best list is even slower and it depends on
the size of N-best list.
A surprising result of the experiments as has
also been observed in (Khadivi et al., 2005), is that
the phrase-based model, which performs the best
in MT, has the least contribution in improving the
recognition results. The phrase-based model uses
more context in the source language to generate
better translations by means of better word selec-
tion and better word order. In a CAT system, the
ASR system has much better recognition quality
than MT system, and the word order of the ASR
output is correct. On the other hand, the ASR
recognition errors are usually single word errors
and they are independent from the context. There-
fore, the task of the MT models in a CAT system is
to enhance the confidence of the recognized words
based on the source language text, and it seems
that the single word based MT models are more
suitable than phrase-based model in this task.
</bodyText>
<subsectionHeader confidence="0.992267">
4.7 Fertility-Based Transducer
</subsectionHeader>
<bodyText confidence="0.999973263157895">
In (Brown et al., 1993), three alignment models
are described that include fertility models, these
are IBM Models 3, 4, and 5. The fertility-based
alignment models have a more complicated struc-
ture than the simple IBM Model 1. The fertility
model estimates the probability distribution for
aligning multiple source words to a single target
word. The fertility model provides the probabili-
ties p(O|e) for aligning a target word e to 0 source
words. In this section, we propose a method for
rescoring ASR word graphs based on the lexicon
and fertility models.
In (Knight and Al-Onaizan, 1998), some trans-
ducers are described to build a finite-state based
translation system. We use the same transduc-
ers for rescoring ASR word graphs. Here, we
have three transducers: lexicon, null-emitter, and
fertility. The lexicon transducer is formed by
one node and a number of self loops for each
target language word, similar to IBM Model 1
transducer in Section 4.5. On each arc of the
lexicon transducer, there is a lexicon entry: the
input label is a target word e, the output label is
a source word f, and the weight is − log p(f|e).
The null-emitter transducer, as its name states,
emits the null word with a pre-defined probability
after each input word. The fertility transducer is
also a simple transducer to map zero or several
instances of a source word to one instance of the
source word.
The ASR word graphs are composed succes-
sively with the lexicon, null-emitter, fertility trans-
ducers and finally with the source language sen-
tence. In the resulting transducer, the input labels
of the best path represent the best hypothesis.
The mathematical description of the proposed
method is as follows. We can decompose Eq. 1
using Bayes’ decision rule:
</bodyText>
<equation confidence="0.9974605">
{Pr(eI�|fJ1 , xT1 )} (4)
{Pr(fJ1 )Pr(eI�|fJ1 )Pr(xT1 |eI�)}(5)
</equation>
<bodyText confidence="0.998836909090909">
In Eq. 5, the term Pr(xT 1 |eI�) is the acoustic model
and can be represented with the ASR word graph1,
the term Pr(eI�|fJ1 ) is the translation model of
the target language text to the source language
text. The translation model can be represented
by lexicon, fertility, and null-emitter transducers.
Finally, the term Pr(fJ1 ) is a very simple language
model, it is the source language sentence.
The source language model in Eq. 5 can be
formed into the acceptor form in two different
ways:
</bodyText>
<listItem confidence="0.864346">
1. a linear acceptor, i.e. a sequence of nodes
with one incoming arc and one outgoing arc,
the words of source language text are placed
consecutively in the arcs of the acceptor,
2. an acceptor containing possible permuta-
tions. To limit the permutations, we used an
approach as in (Kanthak et al., 2005).
</listItem>
<bodyText confidence="0.999675714285714">
Each of these two acceptors results in different
constraints for the generation of the hypotheses.
The first acceptor restricts the system to generate
exactly the same source language sentence, while
the second acceptor forces the system to generate
the hypotheses that are a reordered variant of
the source language sentence. The experiments
conducted do not show any significant difference
in the recognition results among the two source
language acceptors, except that the second accep-
tor is much slower than the first acceptor. There-
fore, we use the first model in our experiments.
Table 4 shows the results of rescoring the ASR
word graphs using the fertility-based transducers.
</bodyText>
<footnote confidence="0.7426095">
1Actually, the ASR word graph is obtained by using
Pr(x1 jei) and Pr(el) models. However, It does not cause
any problem in the modeling, especially when we make use
of the direct modeling, Eq. 3
</footnote>
<figure confidence="0.9723624">
�e� =argmax
�I
I,ei
∼=argmax
I,ei
</figure>
<page confidence="0.997744">
472
</page>
<tableCaption confidence="0.995246">
Table 4: Recognition WER [%] using fertility-
based transducer to rescore ASR word graphs.
</tableCaption>
<table confidence="0.9953758">
Models Dev Eval
ASR 19.3 21.3
ASR+MT IBM-3 17.4 18.6
IBM-4 17.4 18.5
IBM-5 17.6 18.7
</table>
<bodyText confidence="0.999878307692308">
As Table 4 shows, we get almost the same
or slightly better results when compared to the
lexicon-based transducers.
Another interesting point about Eq. 5 is its simi-
larity to speech translation (translation from target
spoken language to source language text). Then,
we can describe a speech-enabled CAT system
as similar to a speech translation system, except
that we aim to get the best ASR output (the best
path in the ASR word graph) rather than the best
translation. This is because the best translation,
which is the source language sentence, is already
given.
</bodyText>
<sectionHeader confidence="0.998835" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999952535714286">
We have studied different approaches to integrate
MT with ASR models, mainly using finite-state
automata. We have proposed three types of trans-
ducers to rescore the ASR word graphs: lexicon-
based, phrase-based and fertility-based transduc-
ers. All improvements of the combined models
are statistically significant at the 99% level with
respect to the baseline system, i.e. ASR only.
In general, N-best rescoring is a simplification
of word graph rescoring. As the size of N-best
list is increased, the results obtained by N-best
list rescoring approach the results of the word
graph rescoring. But we should consider that the
statement is correct when we use exactly the same
model and the same implementation to rescore the
N-best list and word graph. Figure 1 shows the
effect of the N-best list size on the recognition
WER of the evaluation set. As we expected, the
recognition results of N-best rescoring improve
as N becomes larger, until the point that the
recognition result converges to its optimum value.
As shown in Figure 1, we should not expect that
word graph rescoring methods outperform the N-
best rescoring method, when the size of N-best
lists are large enough. In Table 2, the recognition
results are calculated using a large enough size for
N-best lists, a maximum of 5,000 per sentence,
which results in the average of 1738 hypotheses
</bodyText>
<figure confidence="0.938974">
1 10 100 1000 10000
Size of N-best list (N), in log scale
</figure>
<figureCaption confidence="0.968005">
Figure 1: The N-best rescoring results for differ-
ent N-best sizes on the evaluation set.
</figureCaption>
<bodyText confidence="0.997943454545455">
per sentence. An advantage of the word graph
rescoring is the confidence of achieving the best
possible results based on a given rescoring model.
The word graph rescoring methods presented in
this paper improve the baseline ASR system with
statistical significance. The results are competitive
with the best results of N-best rescoring. For the
simple models like IBM-1, the transducer-based
integration generates similar or better results than
N-best rescoring approach. For the more com-
plex translation models, IBM-3 to IBM-5, the
N-best rescoring produces better results than the
transducer-based approach, especially for IBM-
5. The main reason is due to exact estimation
of IBM-5 model scores on the N-best list, while
the transducer-based implementation of IBM-3 to
IBM-5 is not exact and simplified. However, we
observe that the fertility-based transducer which
can be considered as a simplified version of IBM-
3 to IBM-5 models can still obtain good results,
especially if we compare the results on the evalu-
ation set.
</bodyText>
<sectionHeader confidence="0.953014" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999941166666667">
This work has been funded by the European
Union under the RTD project TransType2 (IST
2001 32091) and the integrated project TC-
STAR - Technology and Corpora for Speech
to Speech Translation -(IST-2002-FP6-506738,
http://www.tc-star.org).
</bodyText>
<sectionHeader confidence="0.998492" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.80614175">
P. Beyerlein. 1998. Discriminative model combina-
tion. In Proc. IEEE Int. Conf. on Acoustics, Speech,
and Signal Processing (ICASSP), volume 1, pages
481 – 484, Seattle, WA, May.
</reference>
<figure confidence="0.993428230769231">
IBM-1
HMM
IBM-3
IBM-4
IBM-5
WER [%] 21.5
21
20.5
20
19.5
19
18.5
18
</figure>
<page confidence="0.996821">
473
</page>
<reference confidence="0.999724017699115">
M. Bisani and H. Ney. 2004. Bootstrap estimates
for confidence intervals in ASR performance evalu-
ationx. In IEEE International Conference on Acous-
tics, Speech, and Signal Processing, pages 409–412,
Montreal, Canada, May.
J. Brousseau, C. Drouin, G. Foster, P. Isabelle,
R. Kuhn, Y. Normandin, and P. Plamondon. 1995.
French speech recognition in an automatic dictation
system for translators: the transtalk project. In Pro-
ceedings of Eurospeech, pages 193–196, Madrid,
Spain.
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and
R. L. Mercer. 1993. The mathematics of statistical
machine translation: Parameter estimation. Compu-
tational Linguistics, 19(2):263–311, June.
P. F. Brown, S. F. Chen, S. A. Della Pietra, V. J. Della
Pietra, A. S. Kehler, and R. L. Mercer. 1994. Au-
tomatic speech recognition in machine-aided trans-
lation. Computer Speech and Language, 8(3):177–
187, July.
M. Dymetman, J. Brousseau, G. Foster, P. Isabelle,
Y. Normandin, and P. Plamondon. 1994. Towards
an automatic dictation system for translators: the
TransTalk project. In Proceedings of ICSLP-94,
pages 193–196, Yokohama, Japan.
G. Foster, P. Isabelle, and P. Plamondon. 1997. Target-
text mediated interactive machine translation. Ma-
chine Translation, 12(1):175–194.
S. Kanthak and H. Ney. 2004. FSA: An efficient
and flexible C++ toolkit for finite state automata
using on-demand computation. In Proc. of the 42nd
Annual Meeting of the Association for Computa-
tional Linguistics (ACL), pages 510–517, Barcelona,
Spain, July.
S. Kanthak, D. Vilar, E. Matusov, R. Zens, and
H. Ney. 2005. Novel reordering approaches in
phrase-based statistical machine translation. In 43rd
Annual Meeting of the Assoc. for Computational
Linguistics: Proc. Workshop on Building and Using
Parallel Texts: Data-Driven Machine Translation
and Beyond, pages 167–174, Ann Arbor, Michigan,
June.
S. Khadivi, A. Zolnay, and H. Ney. 2005. Automatic
text dictation in computer-assisted translation. In
Interspeech’2005 - Eurospeech, 9th European Con-
ference on Speech Communication and Technology,
pages 2265–2268, Portugal, Lisbon.
K. Knight and Y. Al-Onaizan. 1998. Translation
with finite-state devices. In D. Farwell, L. Gerber,
and E. H. Hovy, editors, AMTA, volume 1529 of
Lecture Notes in Computer Science, pages 421–437.
Springer Verlag.
F. J. Och and H. Ney. 2002. Discriminative training
and maximum entropy models for statistical ma-
chine translation. In Proc. of the 40th Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 295–302, Philadelphia, PA, July.
F. J. Och, R. Zens, and H. Ney. 2003. Efficient search
for interactive statistical machine translation. In
EACL03: 10th Conf. of the Europ. Chapter of the
Association for Computational Linguistics, pages
387–393, Budapest, Hungary, April.
F. J. Och. 2003. Minimum error rate training in
statistical machine translation. In Proc. of the 41th
Annual Meeting of the Association for Computa-
tional Linguistics (ACL), pages 160–167, Sapporo,
Japan, July.
K. A. Papineni, S. Roukos, and R. T. Ward. 1997.
Feature-based language understanding. In EU-
ROSPEECH, pages 1435–1438, Rhodes, Greece,
September.
K. A. Papineni, S. Roukos, and R. T. Ward. 1998.
Maximum likelihood and discriminative training
of direct translation models. In Proc. IEEE Int.
Conf. on Acoustics, Speech, and Signal Processing
(ICASSP), volume 1, pages 189–192, Seattle, WA,
May.
M. Paulik, S. St¨uker, C. F¨ugen, , T. Schultz, T. Schaaf,
and A. Waibel. 2005a. Speech translation enhanced
automatic speech recognition. In Automatic Speech
Recognition and Understanding Workshop (ASRU),
pages 121–126, Puerto Rico, San Juan.
M. Paulik, C. F¨ugen, S. St¨uker, T. Schultz, T. Schaaf,
and A. Waibel. 2005b. Document driven machine
translation enhanced ASR. In Interspeech’2005 -
Eurospeech, 9th European Conference on Speech
Communication and Technology, pages 2261–2264,
Portugal, Lisbon.
A. Sixtus, S. Molau, S.Kanthak, R. Schl¨uter, and
H. Ney. 2000. Recent improvements of the
RWTH large vocabulary speech recognition system
on spontaneous speech. In Proc. IEEE Int. Conf. on
Acoustics, Speech, and Signal Processing (ICASSP),
pages 1671 – 1674, Istanbul, Turkey, June.
A. Stolcke. 2002. SRILM – an extensible lan-
guage modeling toolkit. In Proc. of the Int. Conf.
on Speech and Language Processing (ICSLP), vol-
ume 2, pages 901–904, Denver, CO, September.
S. Vogel, H. Ney, and C. Tillmann. 1996. HMM-
based word alignment in statistical translation. In
COLING ’96: The 16th Int. Conf. on Computational
Linguistics, pages 836–841, Copenhagen, Denmark,
August.
R. Zens and H. Ney. 2004. Improvements in phrase-
based statistical machine translation. In Proc. of the
Human Language Technology Conf. (HLT-NAACL),
pages 257–264, Boston, MA, May.
R. Zens, O. Bender, S. Hasan, S. Khadivi, E. Matusov,
J. Xu, Y. Zhang, and H. Ney. 2005. The RWTH
phrase-based statistical machine translation system.
In Proceedings of the International Workshop on
Spoken Language Translation (IWSLT), pages 155–
162, Pittsburgh, PA, October.
</reference>
<page confidence="0.998982">
474
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.806954">
<title confidence="0.9880495">Integration of Speech to Computer-Assisted Translation Using Finite-State Automata</title>
<author confidence="0.998932">Shahram Khadivi Richard Zens Hermann Ney</author>
<affiliation confidence="0.862575">Lehrstuhl f¨ur Informatik 6 – Computer Science Department</affiliation>
<address confidence="0.849517">RWTH Aachen University, D-52056 Aachen, Germany</address>
<abstract confidence="0.999559142857143">State-of-the-art computer-assisted translation engines are based on a statistical prediction engine, which interactively provides completions to what a human translator types. The integration of human speech into a computer-assisted system is also a challenging area and is the aim of this paper. So far, only a few methods for integrating statistical machine translation (MT) models with automatic speech recognition (ASR) models have been stud- They were mainly based on rescoring approach. rescoring is not an appropriate search method for building a real-time prediction engine. In this paper, we study the incorporation of MT models and ASR models using finite-state automata. We also propose some transducers based on MT models for rescoring the ASR word graphs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Beyerlein</author>
</authors>
<title>Discriminative model combination. In</title>
<date>1998</date>
<booktitle>Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP),</booktitle>
<volume>1</volume>
<pages>481--484</pages>
<location>Seattle, WA,</location>
<contexts>
<context position="6758" citStr="Beyerlein, 1998" startWordPosition="1091" endWordPosition="1092">sion rule is given by: 1 λmhm(eI 1, fJ 1 ,xT 1 ) (3) Each of the terms hm(eI1, fJ1 , xT1 )denotes one of the various models which are involved in the recognition procedure. Each individual model is weighted by its scaling factor λm. As there is no direct dependence between fJ1 and xT1 , the hm(eI1, fJ1 , xT1 )is in one of these two forms: hm(eI1, xT1 ) and hm(eI1, fJ1 ). Due to the argmax operator which denotes the search, no renormalization is considered in Eq. 3. This approach has been suggested by (Papineni et al., 1997; Papineni et al., 1998) for a natural language understanding task, by (Beyerlein, 1998) for an ASR task, and by (Och and Ney, 2002) for an MT task. This approach is a generalization of Eq. 2. The direct modeling has the advantage that additional models can be easily integrated into the overall system. The model scaling factors λM1 are trained on a development corpus according to the final recognition quality measured by the word error rate (WER)(Och, 2003). Search The search in the MT and the ASR systems is already very complex, therefore a fully integrated search to combine ASR and MT models will considerably increase the complexity. To reduce the complexity of the search, we p</context>
</contexts>
<marker>Beyerlein, 1998</marker>
<rawString>P. Beyerlein. 1998. Discriminative model combination. In Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), volume 1, pages 481 – 484, Seattle, WA, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bisani</author>
<author>H Ney</author>
</authors>
<title>Bootstrap estimates for confidence intervals in ASR performance evaluationx.</title>
<date>2004</date>
<booktitle>In IEEE International Conference on Acoustics, Speech, and Signal Processing,</booktitle>
<pages>409--412</pages>
<location>Montreal, Canada,</location>
<contexts>
<context position="14436" citStr="Bisani and Ney, 2004" startWordPosition="2393" endWordPosition="2396">nguage text. Both MT and ASR word graphs are in the target language. These two word graphs can be considered as two FSA, then using FSA theory, we can integrate two word graphs by applying the composition algorithm. We conducted a set of experiments to integrate the ASR and MT systems using this method. We obtain a WER of 19.0% and 20.9% for development and evaluation sets, respectively. The results are comparable to N-best rescoring results for the phrase-based model which is presented in Table 2. The achieved improvements over the ASR baseline are statistically significant at the 99% level (Bisani and Ney, 2004). However, the results are not promising compared to the results of the rescoring method presented in Table 2 for HMM and IBM translation models. A detailed analysis revealed that only 31.8% and 26.7% of sentences in the development and evaluation sets have identical paths in both FSA, respectively. In other words, the search algorithm was not able to find any identical paths in two given FSA for the remaining sentences. Thus, the two FSA are very different from each other. One explanation for the failure of this method is the large difference between the WERs of two systems, as shown in Table</context>
</contexts>
<marker>Bisani, Ney, 2004</marker>
<rawString>M. Bisani and H. Ney. 2004. Bootstrap estimates for confidence intervals in ASR performance evaluationx. In IEEE International Conference on Acoustics, Speech, and Signal Processing, pages 409–412, Montreal, Canada, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Brousseau</author>
<author>C Drouin</author>
<author>G Foster</author>
<author>P Isabelle</author>
<author>R Kuhn</author>
<author>Y Normandin</author>
<author>P Plamondon</author>
</authors>
<title>French speech recognition in an automatic dictation system for translators: the transtalk project.</title>
<date>1995</date>
<booktitle>In Proceedings of Eurospeech,</booktitle>
<pages>193--196</pages>
<location>Madrid,</location>
<contexts>
<context position="2545" citStr="Brousseau et al., 1995" startWordPosition="383" endWordPosition="386">urces of information are available to recognize the speech input: the target language speech and the given source language text. The target language speech is a human-produced translation of the source language text. Statistical machine translation (MT) models are employed to take into account the source text for increasing the accuracy of automatic speech recognition (ASR) models. Related Work The idea of incorporating ASR and MT models was independently initiated by two groups: researchers at IBM (Brown et al., 1994), and researchers involved in the TransTalk project (Dymetman et al., 1994; Brousseau et al., 1995). In (Brown et al., 1994), the authors proposed a method to integrate the IBM translation model 2 (Brown et al., 1993) with an ASR system. The main idea was to design a language model (LM) to combine the trigram language model probability with the translation probability for each target word. They reported a perplexity reduction, but no recognition results. In the TransTalk project, the authors improved the ASR performance by rescoring the ASR N-best lists with a translation model. They also introduced the idea of a dynamic vocabulary for a speech recognition system where translation models we</context>
<context position="16278" citStr="Brousseau et al., 1995" startWordPosition="2709" endWordPosition="2712"> This means, the ASR word graph is used in addition to the usual language model. This kind of integration forces the MT system to generate identical paths to those in the ASR word graph. Using this approach, the number of identical paths in MT and ASR word graphs are increased to 39.7% and 34.4% of the sentences in development and evaluation sets, respectively. The WER of the integrated system are 19.0% and 20.7% for development and evaluation sets. 4.5 Lexicon-Based Transducer The idea of a dynamic vocabulary, restricting and weighting the word lexicon of the ASR was first 470 introduced in (Brousseau et al., 1995). The idea was also seen later in (Paulik et al., 2005b), they extract the words of the MT N-best list to restrict the vocabulary of the ASR system. But they both reported a negative effect from this method on the recognition accuracy. Here, we extend the dynamic vocabulary idea by weighting the ASR vocabulary based on the source language text and the translation models. We use the lexicon model of the HMM and the IBM MT models. Based on these lexicon models, we assign to each possible target word e the probability Pr(e|fJ1 ). One way to compute this probability is inspired by IBM Model 1: We </context>
</contexts>
<marker>Brousseau, Drouin, Foster, Isabelle, Kuhn, Normandin, Plamondon, 1995</marker>
<rawString>J. Brousseau, C. Drouin, G. Foster, P. Isabelle, R. Kuhn, Y. Normandin, and P. Plamondon. 1995. French speech recognition in an automatic dictation system for translators: the transtalk project. In Proceedings of Eurospeech, pages 193–196, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="2663" citStr="Brown et al., 1993" startWordPosition="404" endWordPosition="407"> text. The target language speech is a human-produced translation of the source language text. Statistical machine translation (MT) models are employed to take into account the source text for increasing the accuracy of automatic speech recognition (ASR) models. Related Work The idea of incorporating ASR and MT models was independently initiated by two groups: researchers at IBM (Brown et al., 1994), and researchers involved in the TransTalk project (Dymetman et al., 1994; Brousseau et al., 1995). In (Brown et al., 1994), the authors proposed a method to integrate the IBM translation model 2 (Brown et al., 1993) with an ASR system. The main idea was to design a language model (LM) to combine the trigram language model probability with the translation probability for each target word. They reported a perplexity reduction, but no recognition results. In the TransTalk project, the authors improved the ASR performance by rescoring the ASR N-best lists with a translation model. They also introduced the idea of a dynamic vocabulary for a speech recognition system where translation models were generated for each source language sentence. The better performing of the two is the N-best rescoring. Recently, (K</context>
<context position="12494" citStr="Brown et al., 1993" startWordPosition="2067" endWordPosition="2070">del. 4.2 N-best Rescoring To rescore the N-best lists, we use the method of (Khadivi et al., 2005). But the results shown here are different from that work due to a better optimization of the overall ASR system, using a 469 Table 2: Recognition WER [%] using N-best rescoring method. Models Dev Eval MT 47.1 50.5 ASR 19.3 21.3 ASR+MT IBM-1 17.8 19.0 HMM 18.2 19.2 IBM-3 17.1 18.4 IBM-4 17.1 18.3 IBM-5 16.6 18.2 Phrase 18.8 20.3 -based better MT system, and generating a larger N-best list from the ASR word graphs. We rescore the ASR N-best lists with the standard HMM (Vogel et al., 1996) and IBM (Brown et al., 1993) MT models. The development and evaluation sets Nbest lists sizes are sufficiently large to achieve almost the best possible results, on average 1738 hypotheses per each source sentence are extracted from the ASR word graphs. The recognition results are summarized in Table 2. In this table, the translation results of the MT system are shown first, which are obtained using the phrase-based approach. Then the recognition results of the ASR system are shown. Afterwards, the results of combined speech recognition and translation models are presented. For each translation model, the N-best lists ar</context>
<context position="21512" citStr="Brown et al., 1993" startWordPosition="3615" endWordPosition="3618">lations by means of better word selection and better word order. In a CAT system, the ASR system has much better recognition quality than MT system, and the word order of the ASR output is correct. On the other hand, the ASR recognition errors are usually single word errors and they are independent from the context. Therefore, the task of the MT models in a CAT system is to enhance the confidence of the recognized words based on the source language text, and it seems that the single word based MT models are more suitable than phrase-based model in this task. 4.7 Fertility-Based Transducer In (Brown et al., 1993), three alignment models are described that include fertility models, these are IBM Models 3, 4, and 5. The fertility-based alignment models have a more complicated structure than the simple IBM Model 1. The fertility model estimates the probability distribution for aligning multiple source words to a single target word. The fertility model provides the probabilities p(O|e) for aligning a target word e to 0 source words. In this section, we propose a method for rescoring ASR word graphs based on the lexicon and fertility models. In (Knight and Al-Onaizan, 1998), some transducers are described </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S F Chen</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>A S Kehler</author>
<author>R L Mercer</author>
</authors>
<title>Automatic speech recognition in machine-aided translation.</title>
<date>1994</date>
<journal>Computer Speech and Language,</journal>
<volume>8</volume>
<issue>3</issue>
<pages>187</pages>
<contexts>
<context position="1299" citStr="Brown et al., 1994" startWordPosition="190" endWordPosition="193">h recognition (ASR) models have been studied. They were mainly based on Nbest rescoring approach. N-best rescoring is not an appropriate search method for building a real-time prediction engine. In this paper, we study the incorporation of MT models and ASR models using finite-state automata. We also propose some transducers based on MT models for rescoring the ASR word graphs. 1 Introduction A desired feature of computer-assisted translation (CAT) systems is the integration of the human speech into the system, as skilled human translators are faster at dictating than typing the translations (Brown et al., 1994). Additionally, incorporation of a statistical prediction engine, i.e. a statistical interactive machine translation system, to the CAT system is another useful feature. A statistical prediction engine provides the completions to what a human translator types (Foster et al., 1997; Och et al., 2003). Then, one possible procedure for skilled human translators is to provide the oral translation of a given source text and then to post-edit the recognized text. In the post-editing step, a prediction engine helps to decrease the amount of human interaction (Och et al., 2003). In a CAT system with in</context>
<context position="2570" citStr="Brown et al., 1994" startWordPosition="388" endWordPosition="391">lable to recognize the speech input: the target language speech and the given source language text. The target language speech is a human-produced translation of the source language text. Statistical machine translation (MT) models are employed to take into account the source text for increasing the accuracy of automatic speech recognition (ASR) models. Related Work The idea of incorporating ASR and MT models was independently initiated by two groups: researchers at IBM (Brown et al., 1994), and researchers involved in the TransTalk project (Dymetman et al., 1994; Brousseau et al., 1995). In (Brown et al., 1994), the authors proposed a method to integrate the IBM translation model 2 (Brown et al., 1993) with an ASR system. The main idea was to design a language model (LM) to combine the trigram language model probability with the translation probability for each target word. They reported a perplexity reduction, but no recognition results. In the TransTalk project, the authors improved the ASR performance by rescoring the ASR N-best lists with a translation model. They also introduced the idea of a dynamic vocabulary for a speech recognition system where translation models were generated for each sou</context>
</contexts>
<marker>Brown, Chen, Pietra, Pietra, Kehler, Mercer, 1994</marker>
<rawString>P. F. Brown, S. F. Chen, S. A. Della Pietra, V. J. Della Pietra, A. S. Kehler, and R. L. Mercer. 1994. Automatic speech recognition in machine-aided translation. Computer Speech and Language, 8(3):177– 187, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dymetman</author>
<author>J Brousseau</author>
<author>G Foster</author>
<author>P Isabelle</author>
<author>Y Normandin</author>
<author>P Plamondon</author>
</authors>
<title>Towards an automatic dictation system for translators: the TransTalk project.</title>
<date>1994</date>
<booktitle>In Proceedings of ICSLP-94,</booktitle>
<pages>193--196</pages>
<location>Yokohama, Japan.</location>
<contexts>
<context position="2520" citStr="Dymetman et al., 1994" startWordPosition="379" endWordPosition="382">tegrated speech, two sources of information are available to recognize the speech input: the target language speech and the given source language text. The target language speech is a human-produced translation of the source language text. Statistical machine translation (MT) models are employed to take into account the source text for increasing the accuracy of automatic speech recognition (ASR) models. Related Work The idea of incorporating ASR and MT models was independently initiated by two groups: researchers at IBM (Brown et al., 1994), and researchers involved in the TransTalk project (Dymetman et al., 1994; Brousseau et al., 1995). In (Brown et al., 1994), the authors proposed a method to integrate the IBM translation model 2 (Brown et al., 1993) with an ASR system. The main idea was to design a language model (LM) to combine the trigram language model probability with the translation probability for each target word. They reported a perplexity reduction, but no recognition results. In the TransTalk project, the authors improved the ASR performance by rescoring the ASR N-best lists with a translation model. They also introduced the idea of a dynamic vocabulary for a speech recognition system wh</context>
</contexts>
<marker>Dymetman, Brousseau, Foster, Isabelle, Normandin, Plamondon, 1994</marker>
<rawString>M. Dymetman, J. Brousseau, G. Foster, P. Isabelle, Y. Normandin, and P. Plamondon. 1994. Towards an automatic dictation system for translators: the TransTalk project. In Proceedings of ICSLP-94, pages 193–196, Yokohama, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Foster</author>
<author>P Isabelle</author>
<author>P Plamondon</author>
</authors>
<title>Targettext mediated interactive machine translation.</title>
<date>1997</date>
<journal>Machine Translation,</journal>
<volume>12</volume>
<issue>1</issue>
<contexts>
<context position="1579" citStr="Foster et al., 1997" startWordPosition="230" endWordPosition="233">ate automata. We also propose some transducers based on MT models for rescoring the ASR word graphs. 1 Introduction A desired feature of computer-assisted translation (CAT) systems is the integration of the human speech into the system, as skilled human translators are faster at dictating than typing the translations (Brown et al., 1994). Additionally, incorporation of a statistical prediction engine, i.e. a statistical interactive machine translation system, to the CAT system is another useful feature. A statistical prediction engine provides the completions to what a human translator types (Foster et al., 1997; Och et al., 2003). Then, one possible procedure for skilled human translators is to provide the oral translation of a given source text and then to post-edit the recognized text. In the post-editing step, a prediction engine helps to decrease the amount of human interaction (Och et al., 2003). In a CAT system with integrated speech, two sources of information are available to recognize the speech input: the target language speech and the given source language text. The target language speech is a human-produced translation of the source language text. Statistical machine translation (MT) mod</context>
</contexts>
<marker>Foster, Isabelle, Plamondon, 1997</marker>
<rawString>G. Foster, P. Isabelle, and P. Plamondon. 1997. Targettext mediated interactive machine translation. Machine Translation, 12(1):175–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kanthak</author>
<author>H Ney</author>
</authors>
<title>FSA: An efficient and flexible C++ toolkit for finite state automata using on-demand computation.</title>
<date>2004</date>
<booktitle>In Proc. of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>510--517</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="7770" citStr="Kanthak and Ney, 2004" startWordPosition="1265" endWordPosition="1268">ch in the MT and the ASR systems is already very complex, therefore a fully integrated search to combine ASR and MT models will considerably increase the complexity. To reduce the complexity of the search, we perform two independent searches with the MT and the ASR systems, the search result of each system will be represented as a large word graph. We consider MT and ASR word graphs as FSA. Then, we are able to use FSA algorithms to integrate MT and ASR word graphs. The FSA implementation of the search allows us to use standard optimized algorithms, e.g. available from an open source toolkit (Kanthak and Ney, 2004). The recognition process is performed in two steps. First, the baseline ASR system generates a word graph in the FSA format for a given utterance xT1 . Second, the translation models rescore each word graph based on the corresponding source language sentence. For each utterance, the decision about the best sentence is made according to the recognition and the translation models. ˆe1 =argmax ˆI I,ei �=argmax I,ei ˆe 1 = argmax � M ˆI E I,ei m=1 468 3 Baseline Components In this section, we briefly describe the basic system components, namely the MT and the ASR systems. 3.1 Machine Translation </context>
</contexts>
<marker>Kanthak, Ney, 2004</marker>
<rawString>S. Kanthak and H. Ney. 2004. FSA: An efficient and flexible C++ toolkit for finite state automata using on-demand computation. In Proc. of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL), pages 510–517, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kanthak</author>
<author>D Vilar</author>
<author>E Matusov</author>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>Novel reordering approaches in phrase-based statistical machine translation.</title>
<date>2005</date>
<booktitle>In 43rd Annual Meeting of the Assoc. for Computational Linguistics: Proc. Workshop on Building and Using Parallel Texts: Data-Driven Machine Translation and Beyond,</booktitle>
<pages>167--174</pages>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="24095" citStr="Kanthak et al., 2005" startWordPosition="4051" endWordPosition="4054">ext to the source language text. The translation model can be represented by lexicon, fertility, and null-emitter transducers. Finally, the term Pr(fJ1 ) is a very simple language model, it is the source language sentence. The source language model in Eq. 5 can be formed into the acceptor form in two different ways: 1. a linear acceptor, i.e. a sequence of nodes with one incoming arc and one outgoing arc, the words of source language text are placed consecutively in the arcs of the acceptor, 2. an acceptor containing possible permutations. To limit the permutations, we used an approach as in (Kanthak et al., 2005). Each of these two acceptors results in different constraints for the generation of the hypotheses. The first acceptor restricts the system to generate exactly the same source language sentence, while the second acceptor forces the system to generate the hypotheses that are a reordered variant of the source language sentence. The experiments conducted do not show any significant difference in the recognition results among the two source language acceptors, except that the second acceptor is much slower than the first acceptor. Therefore, we use the first model in our experiments. Table 4 show</context>
</contexts>
<marker>Kanthak, Vilar, Matusov, Zens, Ney, 2005</marker>
<rawString>S. Kanthak, D. Vilar, E. Matusov, R. Zens, and H. Ney. 2005. Novel reordering approaches in phrase-based statistical machine translation. In 43rd Annual Meeting of the Assoc. for Computational Linguistics: Proc. Workshop on Building and Using Parallel Texts: Data-Driven Machine Translation and Beyond, pages 167–174, Ann Arbor, Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Khadivi</author>
<author>A Zolnay</author>
<author>H Ney</author>
</authors>
<title>Automatic text dictation in computer-assisted translation.</title>
<date>2005</date>
<booktitle>In Interspeech’2005 - Eurospeech, 9th European Conference on Speech Communication and Technology,</booktitle>
<pages>2265--2268</pages>
<location>Portugal, Lisbon.</location>
<contexts>
<context position="3283" citStr="Khadivi et al., 2005" startWordPosition="501" endWordPosition="504">) with an ASR system. The main idea was to design a language model (LM) to combine the trigram language model probability with the translation probability for each target word. They reported a perplexity reduction, but no recognition results. In the TransTalk project, the authors improved the ASR performance by rescoring the ASR N-best lists with a translation model. They also introduced the idea of a dynamic vocabulary for a speech recognition system where translation models were generated for each source language sentence. The better performing of the two is the N-best rescoring. Recently, (Khadivi et al., 2005) and (Paulik et al., 2005a; Paulik et al., 2005b) have studied the integration of ASR and MT models. The first work showed a detailed analysis of the effect of different MT models on rescoring the ASR N-best lists. The other two works considered two parallel N-best lists, generated by MT and ASR systems, 467 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 467–474, Sydney, July 2006. c�2006 Association for Computational Linguistics respectively. They showed improvement in the ASR N-best rescoring when some proposed features are extracted from the MT N-best list. The ma</context>
<context position="9437" citStr="Khadivi et al., 2005" startWordPosition="1542" endWordPosition="1545">eline system is distance-based, i.e. it assigns costs based on the distance from the end position of a phrase to the start position of the next phrase. More details about the baseline system can be found in (Zens and Ney, 2004; Zens et al., 2005). 3.2 Automatic Speech Recognition System The acoustic model of the ASR system is trained on the VerbMobil II corpus (Sixtus et al., 2000). The corpus consists of German large-vocabulary conversational speech: 36k training sentences (61.5h) from 857 speakers. The test corpus is created from the German part of the bilingual English-German XEROX corpus (Khadivi et al., 2005): 1562 sentences including 18k running words (2.6h) from 10 speakers. The test corpus contains 114 out-of-vocabulary (OOV) words. The remaining part of the XEROX corpus is used to train a back off trigram language model using the SRI language modeling toolkit (Stolcke, 2002). The LM perplexity of the speech recognition test corpus is about 83. The acoustic model of the ASR system can be characterized as follows: • recognition vocabulary of 16716 words; • 3-state-HMM topology with skip; • 2500 decision tree based generalized withinword triphone states including noise plus one state for silence;</context>
<context position="10705" citStr="Khadivi et al., 2005" startWordPosition="1754" endWordPosition="1757">ith global pooled diagonal covariance; • 16 MFCC features; • 33 acoustic features after applying LDA; • LDA is fed with 11 subsequent MFCC vectors; • maximum likelihood training using Viterbi approximation. Table 1: Statistics of the machine translation corpus. English German Train: Sentences 47 619 Running Words 528 779 467 633 Vocabulary 9 816 16 716 Singletons 2 302 6 064 Dev: Sentences 700 Running Words 8 823 8 050 Unknown words 56 108 Eval: Sentences 862 Running Words 11 019 10 094 Unknown words 58 100 The test corpus recognition word error rate is 20.4%. Compared to the previous system (Khadivi et al., 2005), which has a WER of 21.2%, we obtain a 3.8% relative improvement in WER. This improvement is due to a better and complete optimization of the overall ASR system. 4 Integration Approaches In this section, we will introduce several approaches to integrate the MT models with the ASR models. To present the content of this section in a more reader-friendly way, we will first explain the task and corpus statistics, then we will present the results of N-best rescoring. Afterwards, we will describe the new methods for integrating the MT models with the ASR models. In each sub-section, we will also pr</context>
<context position="11973" citStr="Khadivi et al., 2005" startWordPosition="1972" endWordPosition="1975">nslation models are trained on the part of the English-German XEROX corpus which was not used in the speech recognition test corpus. We divide the speech recognition test corpus into two parts, the first 700 utterances as the development corpus and the rest as the evaluation corpus. The development corpus is used to optimize the scaling factors of different models (explained in Section 2). The statistics of the corpus are depicted in Table 1. The German part of the training corpus is also used to train the language model. 4.2 N-best Rescoring To rescore the N-best lists, we use the method of (Khadivi et al., 2005). But the results shown here are different from that work due to a better optimization of the overall ASR system, using a 469 Table 2: Recognition WER [%] using N-best rescoring method. Models Dev Eval MT 47.1 50.5 ASR 19.3 21.3 ASR+MT IBM-1 17.8 19.0 HMM 18.2 19.2 IBM-3 17.1 18.4 IBM-4 17.1 18.3 IBM-5 16.6 18.2 Phrase 18.8 20.3 -based better MT system, and generating a larger N-best list from the ASR word graphs. We rescore the ASR N-best lists with the standard HMM (Vogel et al., 1996) and IBM (Brown et al., 1993) MT models. The development and evaluation sets Nbest lists sizes are sufficien</context>
<context position="20675" citStr="Khadivi et al., 2005" startWordPosition="3471" endWordPosition="3474">hrase translation model. The designed transducer is much faster in rescoring the word graph than the MT system in rescoring the N-best list. The average speed to rescore the ASR word graphs with this transducer is 49.4 words/sec (source language p(e|fj) Pr(e |fJ1 ) = 1 J + 1 j=0 )z I p(ei|fj) i=1 j=0 I i=1 471 text words), while the average speed to translate the source language text using the MT system is 8.3 words/sec. The average speed for rescoring the N-best list is even slower and it depends on the size of N-best list. A surprising result of the experiments as has also been observed in (Khadivi et al., 2005), is that the phrase-based model, which performs the best in MT, has the least contribution in improving the recognition results. The phrase-based model uses more context in the source language to generate better translations by means of better word selection and better word order. In a CAT system, the ASR system has much better recognition quality than MT system, and the word order of the ASR output is correct. On the other hand, the ASR recognition errors are usually single word errors and they are independent from the context. Therefore, the task of the MT models in a CAT system is to enhan</context>
</contexts>
<marker>Khadivi, Zolnay, Ney, 2005</marker>
<rawString>S. Khadivi, A. Zolnay, and H. Ney. 2005. Automatic text dictation in computer-assisted translation. In Interspeech’2005 - Eurospeech, 9th European Conference on Speech Communication and Technology, pages 2265–2268, Portugal, Lisbon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>Y Al-Onaizan</author>
</authors>
<title>Translation with finite-state devices.</title>
<date>1998</date>
<booktitle>of Lecture Notes in Computer Science,</booktitle>
<volume>1529</volume>
<pages>421--437</pages>
<editor>In D. Farwell, L. Gerber, and E. H. Hovy, editors, AMTA,</editor>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="22079" citStr="Knight and Al-Onaizan, 1998" startWordPosition="3707" endWordPosition="3710"> task. 4.7 Fertility-Based Transducer In (Brown et al., 1993), three alignment models are described that include fertility models, these are IBM Models 3, 4, and 5. The fertility-based alignment models have a more complicated structure than the simple IBM Model 1. The fertility model estimates the probability distribution for aligning multiple source words to a single target word. The fertility model provides the probabilities p(O|e) for aligning a target word e to 0 source words. In this section, we propose a method for rescoring ASR word graphs based on the lexicon and fertility models. In (Knight and Al-Onaizan, 1998), some transducers are described to build a finite-state based translation system. We use the same transducers for rescoring ASR word graphs. Here, we have three transducers: lexicon, null-emitter, and fertility. The lexicon transducer is formed by one node and a number of self loops for each target language word, similar to IBM Model 1 transducer in Section 4.5. On each arc of the lexicon transducer, there is a lexicon entry: the input label is a target word e, the output label is a source word f, and the weight is − log p(f|e). The null-emitter transducer, as its name states, emits the null </context>
</contexts>
<marker>Knight, Al-Onaizan, 1998</marker>
<rawString>K. Knight and Y. Al-Onaizan. 1998. Translation with finite-state devices. In D. Farwell, L. Gerber, and E. H. Hovy, editors, AMTA, volume 1529 of Lecture Notes in Computer Science, pages 421–437. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proc. of the 40th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>295--302</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="6802" citStr="Och and Ney, 2002" startWordPosition="1099" endWordPosition="1102">xT 1 ) (3) Each of the terms hm(eI1, fJ1 , xT1 )denotes one of the various models which are involved in the recognition procedure. Each individual model is weighted by its scaling factor λm. As there is no direct dependence between fJ1 and xT1 , the hm(eI1, fJ1 , xT1 )is in one of these two forms: hm(eI1, xT1 ) and hm(eI1, fJ1 ). Due to the argmax operator which denotes the search, no renormalization is considered in Eq. 3. This approach has been suggested by (Papineni et al., 1997; Papineni et al., 1998) for a natural language understanding task, by (Beyerlein, 1998) for an ASR task, and by (Och and Ney, 2002) for an MT task. This approach is a generalization of Eq. 2. The direct modeling has the advantage that additional models can be easily integrated into the overall system. The model scaling factors λM1 are trained on a development corpus according to the final recognition quality measured by the word error rate (WER)(Och, 2003). Search The search in the MT and the ASR systems is already very complex, therefore a fully integrated search to combine ASR and MT models will considerably increase the complexity. To reduce the complexity of the search, we perform two independent searches with the MT </context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>F. J. Och and H. Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proc. of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 295–302, Philadelphia, PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>Efficient search for interactive statistical machine translation.</title>
<date>2003</date>
<booktitle>In EACL03: 10th Conf. of the Europ. Chapter of the Association for Computational Linguistics,</booktitle>
<pages>387--393</pages>
<location>Budapest, Hungary,</location>
<contexts>
<context position="1598" citStr="Och et al., 2003" startWordPosition="234" endWordPosition="237"> propose some transducers based on MT models for rescoring the ASR word graphs. 1 Introduction A desired feature of computer-assisted translation (CAT) systems is the integration of the human speech into the system, as skilled human translators are faster at dictating than typing the translations (Brown et al., 1994). Additionally, incorporation of a statistical prediction engine, i.e. a statistical interactive machine translation system, to the CAT system is another useful feature. A statistical prediction engine provides the completions to what a human translator types (Foster et al., 1997; Och et al., 2003). Then, one possible procedure for skilled human translators is to provide the oral translation of a given source text and then to post-edit the recognized text. In the post-editing step, a prediction engine helps to decrease the amount of human interaction (Och et al., 2003). In a CAT system with integrated speech, two sources of information are available to recognize the speech input: the target language speech and the given source language text. The target language speech is a human-produced translation of the source language text. Statistical machine translation (MT) models are employed to</context>
<context position="4755" citStr="Och et al., 2003" startWordPosition="748" endWordPosition="751">aphs instead of N-best list. We consider ASR word graphs as finite-state automata (FSA), then the integration of MT models to ASR word graphs can benefit from FSA algorithms. The ASR word graphs are a compact representation of possible recognition hypotheses. Thus, the integration of MT models to ASR word graphs can be considered as an N-best rescoring but with very large value for N. Another advantage of working with ASR word graphs is the capability to pass on the word graphs for further processing. For instance, the resulting word graph can be used in the prediction engine of a CAT system (Och et al., 2003). The remaining part is structured as follows: in Section 2, a general model for an automatic text dictation system in the computer-assisted translation framework will be described. In Section 3, the details of the machine translation system and the speech recognition system along with the language model will be explained. In Section 4, different methods for integrating MT models into ASR models will be described, and also the experimental results will be shown in the same section. 2 Speech-Enabled CAT Models In a speech-enabled computer-assisted translation system, we are given a source langu</context>
</contexts>
<marker>Och, Zens, Ney, 2003</marker>
<rawString>F. J. Och, R. Zens, and H. Ney. 2003. Efficient search for interactive statistical machine translation. In EACL03: 10th Conf. of the Europ. Chapter of the Association for Computational Linguistics, pages 387–393, Budapest, Hungary, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. of the 41th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan,</location>
<contexts>
<context position="7131" citStr="Och, 2003" startWordPosition="1156" endWordPosition="1157">o the argmax operator which denotes the search, no renormalization is considered in Eq. 3. This approach has been suggested by (Papineni et al., 1997; Papineni et al., 1998) for a natural language understanding task, by (Beyerlein, 1998) for an ASR task, and by (Och and Ney, 2002) for an MT task. This approach is a generalization of Eq. 2. The direct modeling has the advantage that additional models can be easily integrated into the overall system. The model scaling factors λM1 are trained on a development corpus according to the final recognition quality measured by the word error rate (WER)(Och, 2003). Search The search in the MT and the ASR systems is already very complex, therefore a fully integrated search to combine ASR and MT models will considerably increase the complexity. To reduce the complexity of the search, we perform two independent searches with the MT and the ASR systems, the search result of each system will be represented as a large word graph. We consider MT and ASR word graphs as FSA. Then, we are able to use FSA algorithms to integrate MT and ASR word graphs. The FSA implementation of the search allows us to use standard optimized algorithms, e.g. available from an open</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>F. J. Och. 2003. Minimum error rate training in statistical machine translation. In Proc. of the 41th Annual Meeting of the Association for Computational Linguistics (ACL), pages 160–167, Sapporo, Japan, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K A Papineni</author>
<author>S Roukos</author>
<author>R T Ward</author>
</authors>
<title>Feature-based language understanding.</title>
<date>1997</date>
<booktitle>In EUROSPEECH,</booktitle>
<pages>1435--1438</pages>
<location>Rhodes, Greece,</location>
<contexts>
<context position="6670" citStr="Papineni et al., 1997" startWordPosition="1076" endWordPosition="1079">posterior probability Pr(eI1|fJ1 , xT1 )is direct modeling using a log-linear model. The decision rule is given by: 1 λmhm(eI 1, fJ 1 ,xT 1 ) (3) Each of the terms hm(eI1, fJ1 , xT1 )denotes one of the various models which are involved in the recognition procedure. Each individual model is weighted by its scaling factor λm. As there is no direct dependence between fJ1 and xT1 , the hm(eI1, fJ1 , xT1 )is in one of these two forms: hm(eI1, xT1 ) and hm(eI1, fJ1 ). Due to the argmax operator which denotes the search, no renormalization is considered in Eq. 3. This approach has been suggested by (Papineni et al., 1997; Papineni et al., 1998) for a natural language understanding task, by (Beyerlein, 1998) for an ASR task, and by (Och and Ney, 2002) for an MT task. This approach is a generalization of Eq. 2. The direct modeling has the advantage that additional models can be easily integrated into the overall system. The model scaling factors λM1 are trained on a development corpus according to the final recognition quality measured by the word error rate (WER)(Och, 2003). Search The search in the MT and the ASR systems is already very complex, therefore a fully integrated search to combine ASR and MT models</context>
</contexts>
<marker>Papineni, Roukos, Ward, 1997</marker>
<rawString>K. A. Papineni, S. Roukos, and R. T. Ward. 1997. Feature-based language understanding. In EUROSPEECH, pages 1435–1438, Rhodes, Greece, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K A Papineni</author>
<author>S Roukos</author>
<author>R T Ward</author>
</authors>
<title>Maximum likelihood and discriminative training of direct translation models.</title>
<date>1998</date>
<booktitle>In Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP),</booktitle>
<volume>1</volume>
<pages>189--192</pages>
<location>Seattle, WA,</location>
<contexts>
<context position="6694" citStr="Papineni et al., 1998" startWordPosition="1080" endWordPosition="1083">r(eI1|fJ1 , xT1 )is direct modeling using a log-linear model. The decision rule is given by: 1 λmhm(eI 1, fJ 1 ,xT 1 ) (3) Each of the terms hm(eI1, fJ1 , xT1 )denotes one of the various models which are involved in the recognition procedure. Each individual model is weighted by its scaling factor λm. As there is no direct dependence between fJ1 and xT1 , the hm(eI1, fJ1 , xT1 )is in one of these two forms: hm(eI1, xT1 ) and hm(eI1, fJ1 ). Due to the argmax operator which denotes the search, no renormalization is considered in Eq. 3. This approach has been suggested by (Papineni et al., 1997; Papineni et al., 1998) for a natural language understanding task, by (Beyerlein, 1998) for an ASR task, and by (Och and Ney, 2002) for an MT task. This approach is a generalization of Eq. 2. The direct modeling has the advantage that additional models can be easily integrated into the overall system. The model scaling factors λM1 are trained on a development corpus according to the final recognition quality measured by the word error rate (WER)(Och, 2003). Search The search in the MT and the ASR systems is already very complex, therefore a fully integrated search to combine ASR and MT models will considerably incre</context>
</contexts>
<marker>Papineni, Roukos, Ward, 1998</marker>
<rawString>K. A. Papineni, S. Roukos, and R. T. Ward. 1998. Maximum likelihood and discriminative training of direct translation models. In Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), volume 1, pages 189–192, Seattle, WA, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Schultz</author>
<author>T Schaaf</author>
<author>A Waibel</author>
</authors>
<title>Speech translation enhanced automatic speech recognition.</title>
<date>2005</date>
<booktitle>In Automatic Speech Recognition and Understanding Workshop (ASRU),</booktitle>
<pages>121--126</pages>
<location>Puerto Rico, San Juan.</location>
<marker>Schultz, Schaaf, Waibel, 2005</marker>
<rawString>M. Paulik, S. St¨uker, C. F¨ugen, , T. Schultz, T. Schaaf, and A. Waibel. 2005a. Speech translation enhanced automatic speech recognition. In Automatic Speech Recognition and Understanding Workshop (ASRU), pages 121–126, Puerto Rico, San Juan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Paulik</author>
<author>C F¨ugen</author>
<author>S St¨uker</author>
<author>T Schultz</author>
<author>T Schaaf</author>
<author>A Waibel</author>
</authors>
<title>Document driven machine translation enhanced ASR.</title>
<date>2005</date>
<booktitle>In Interspeech’2005 -Eurospeech, 9th European Conference on Speech Communication and Technology,</booktitle>
<pages>2261--2264</pages>
<location>Portugal, Lisbon.</location>
<marker>Paulik, F¨ugen, St¨uker, Schultz, Schaaf, Waibel, 2005</marker>
<rawString>M. Paulik, C. F¨ugen, S. St¨uker, T. Schultz, T. Schaaf, and A. Waibel. 2005b. Document driven machine translation enhanced ASR. In Interspeech’2005 -Eurospeech, 9th European Conference on Speech Communication and Technology, pages 2261–2264, Portugal, Lisbon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Sixtus</author>
<author>S Molau</author>
<author>R Schl¨uter S Kanthak</author>
<author>H Ney</author>
</authors>
<title>Recent improvements of the RWTH large vocabulary speech recognition system on spontaneous speech.</title>
<date>2000</date>
<booktitle>In Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP),</booktitle>
<pages>1671--1674</pages>
<location>Istanbul, Turkey,</location>
<contexts>
<context position="9200" citStr="Sixtus et al., 2000" startWordPosition="1508" endWordPosition="1511">ranslation model and a wordbased lexicon model. The latter two models are used for both directions: German to English and English to German. Additionally, a word penalty and a phrase penalty are included. The reordering model of the baseline system is distance-based, i.e. it assigns costs based on the distance from the end position of a phrase to the start position of the next phrase. More details about the baseline system can be found in (Zens and Ney, 2004; Zens et al., 2005). 3.2 Automatic Speech Recognition System The acoustic model of the ASR system is trained on the VerbMobil II corpus (Sixtus et al., 2000). The corpus consists of German large-vocabulary conversational speech: 36k training sentences (61.5h) from 857 speakers. The test corpus is created from the German part of the bilingual English-German XEROX corpus (Khadivi et al., 2005): 1562 sentences including 18k running words (2.6h) from 10 speakers. The test corpus contains 114 out-of-vocabulary (OOV) words. The remaining part of the XEROX corpus is used to train a back off trigram language model using the SRI language modeling toolkit (Stolcke, 2002). The LM perplexity of the speech recognition test corpus is about 83. The acoustic mode</context>
</contexts>
<marker>Sixtus, Molau, Kanthak, Ney, 2000</marker>
<rawString>A. Sixtus, S. Molau, S.Kanthak, R. Schl¨uter, and H. Ney. 2000. Recent improvements of the RWTH large vocabulary speech recognition system on spontaneous speech. In Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), pages 1671 – 1674, Istanbul, Turkey, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILM – an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proc. of the Int. Conf. on Speech and Language Processing (ICSLP),</booktitle>
<volume>2</volume>
<pages>901--904</pages>
<location>Denver, CO,</location>
<contexts>
<context position="9712" citStr="Stolcke, 2002" startWordPosition="1589" endWordPosition="1590">ystem The acoustic model of the ASR system is trained on the VerbMobil II corpus (Sixtus et al., 2000). The corpus consists of German large-vocabulary conversational speech: 36k training sentences (61.5h) from 857 speakers. The test corpus is created from the German part of the bilingual English-German XEROX corpus (Khadivi et al., 2005): 1562 sentences including 18k running words (2.6h) from 10 speakers. The test corpus contains 114 out-of-vocabulary (OOV) words. The remaining part of the XEROX corpus is used to train a back off trigram language model using the SRI language modeling toolkit (Stolcke, 2002). The LM perplexity of the speech recognition test corpus is about 83. The acoustic model of the ASR system can be characterized as follows: • recognition vocabulary of 16716 words; • 3-state-HMM topology with skip; • 2500 decision tree based generalized withinword triphone states including noise plus one state for silence; • 237k gender independent Gaussian densities with global pooled diagonal covariance; • 16 MFCC features; • 33 acoustic features after applying LDA; • LDA is fed with 11 subsequent MFCC vectors; • maximum likelihood training using Viterbi approximation. Table 1: Statistics o</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. SRILM – an extensible language modeling toolkit. In Proc. of the Int. Conf. on Speech and Language Processing (ICSLP), volume 2, pages 901–904, Denver, CO, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vogel</author>
<author>H Ney</author>
<author>C Tillmann</author>
</authors>
<title>HMMbased word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In COLING ’96: The 16th Int. Conf. on Computational Linguistics,</booktitle>
<pages>836--841</pages>
<location>Copenhagen, Denmark,</location>
<contexts>
<context position="12465" citStr="Vogel et al., 1996" startWordPosition="2061" endWordPosition="2064">used to train the language model. 4.2 N-best Rescoring To rescore the N-best lists, we use the method of (Khadivi et al., 2005). But the results shown here are different from that work due to a better optimization of the overall ASR system, using a 469 Table 2: Recognition WER [%] using N-best rescoring method. Models Dev Eval MT 47.1 50.5 ASR 19.3 21.3 ASR+MT IBM-1 17.8 19.0 HMM 18.2 19.2 IBM-3 17.1 18.4 IBM-4 17.1 18.3 IBM-5 16.6 18.2 Phrase 18.8 20.3 -based better MT system, and generating a larger N-best list from the ASR word graphs. We rescore the ASR N-best lists with the standard HMM (Vogel et al., 1996) and IBM (Brown et al., 1993) MT models. The development and evaluation sets Nbest lists sizes are sufficiently large to achieve almost the best possible results, on average 1738 hypotheses per each source sentence are extracted from the ASR word graphs. The recognition results are summarized in Table 2. In this table, the translation results of the MT system are shown first, which are obtained using the phrase-based approach. Then the recognition results of the ASR system are shown. Afterwards, the results of combined speech recognition and translation models are presented. For each translati</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>S. Vogel, H. Ney, and C. Tillmann. 1996. HMMbased word alignment in statistical translation. In COLING ’96: The 16th Int. Conf. on Computational Linguistics, pages 836–841, Copenhagen, Denmark, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>Improvements in phrasebased statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proc. of the Human Language Technology Conf. (HLT-NAACL),</booktitle>
<pages>257--264</pages>
<location>Boston, MA,</location>
<contexts>
<context position="9042" citStr="Zens and Ney, 2004" startWordPosition="1481" endWordPosition="1484">l machine translation system for the English to German automatic translation. The system includes the following models: an n-gram language model, a phrase translation model and a wordbased lexicon model. The latter two models are used for both directions: German to English and English to German. Additionally, a word penalty and a phrase penalty are included. The reordering model of the baseline system is distance-based, i.e. it assigns costs based on the distance from the end position of a phrase to the start position of the next phrase. More details about the baseline system can be found in (Zens and Ney, 2004; Zens et al., 2005). 3.2 Automatic Speech Recognition System The acoustic model of the ASR system is trained on the VerbMobil II corpus (Sixtus et al., 2000). The corpus consists of German large-vocabulary conversational speech: 36k training sentences (61.5h) from 857 speakers. The test corpus is created from the German part of the bilingual English-German XEROX corpus (Khadivi et al., 2005): 1562 sentences including 18k running words (2.6h) from 10 speakers. The test corpus contains 114 out-of-vocabulary (OOV) words. The remaining part of the XEROX corpus is used to train a back off trigram </context>
<context position="18379" citStr="Zens and Ney, 2004" startWordPosition="3081" endWordPosition="3084">MM and IBM Models to rescore the ASR word graphs. Due to its simplicity, this model can be easily integrated into the ASR search. It is a sentence specific unigram LM. 4.6 Phrase-Based Transducer The phrase-based translation model is the main component of our translation system. The pairs of source and corresponding target phrases are extracted from the word-aligned bilingual training Table 3: Recognition WER [%] using lexiconbased transducer to rescore ASR word graphs. Models Dev Eval ASR 19.3 21.3 ASR+MT IBM-1 17.5 19.0 HMM 17.8 19.2 IBM-3 17.7 18.8 IBM-4 17.8 18.8 IBM-5 17.6 18.9 J corpus (Zens and Ney, 2004). In this section, we design a transducer to rescore the ASR word graph using the phrase-based model of the MT system. For each source language sentence, we extract all possible phrases from the word-aligned training corpus. Using the target part of these phrases we build a transducer similar to the lexicon-based transducer. But instead of a target word on each arc, we have the target part of a phrase. The weight of each arc is the negative logarithm of the phrase translation probability. This transducer is a good approximation of nonmonotone phrase-based-lexicon score. Using the designed tran</context>
</contexts>
<marker>Zens, Ney, 2004</marker>
<rawString>R. Zens and H. Ney. 2004. Improvements in phrasebased statistical machine translation. In Proc. of the Human Language Technology Conf. (HLT-NAACL), pages 257–264, Boston, MA, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>O Bender</author>
<author>S Hasan</author>
<author>S Khadivi</author>
<author>E Matusov</author>
<author>J Xu</author>
<author>Y Zhang</author>
<author>H Ney</author>
</authors>
<title>The RWTH phrase-based statistical machine translation system.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation (IWSLT),</booktitle>
<pages>155--162</pages>
<location>Pittsburgh, PA,</location>
<contexts>
<context position="9062" citStr="Zens et al., 2005" startWordPosition="1485" endWordPosition="1488">n system for the English to German automatic translation. The system includes the following models: an n-gram language model, a phrase translation model and a wordbased lexicon model. The latter two models are used for both directions: German to English and English to German. Additionally, a word penalty and a phrase penalty are included. The reordering model of the baseline system is distance-based, i.e. it assigns costs based on the distance from the end position of a phrase to the start position of the next phrase. More details about the baseline system can be found in (Zens and Ney, 2004; Zens et al., 2005). 3.2 Automatic Speech Recognition System The acoustic model of the ASR system is trained on the VerbMobil II corpus (Sixtus et al., 2000). The corpus consists of German large-vocabulary conversational speech: 36k training sentences (61.5h) from 857 speakers. The test corpus is created from the German part of the bilingual English-German XEROX corpus (Khadivi et al., 2005): 1562 sentences including 18k running words (2.6h) from 10 speakers. The test corpus contains 114 out-of-vocabulary (OOV) words. The remaining part of the XEROX corpus is used to train a back off trigram language model using</context>
</contexts>
<marker>Zens, Bender, Hasan, Khadivi, Matusov, Xu, Zhang, Ney, 2005</marker>
<rawString>R. Zens, O. Bender, S. Hasan, S. Khadivi, E. Matusov, J. Xu, Y. Zhang, and H. Ney. 2005. The RWTH phrase-based statistical machine translation system. In Proceedings of the International Workshop on Spoken Language Translation (IWSLT), pages 155– 162, Pittsburgh, PA, October.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>