<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.013330">
<title confidence="0.923838">
Building an Annotated Corpus in the Molecular-Biology Domain
</title>
<author confidence="0.999093">
Yuka Tateisi, Tomoko Ohta, Nigel Collier, Chikashi Nobata, Jun-ichi Tsujii
</author>
<affiliation confidence="0.999298333333333">
Department of Information Science
Graduate School of Science
University of Tokyo,
</affiliation>
<address confidence="0.734238">
7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033, Japan
</address>
<sectionHeader confidence="0.823161" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999810235294118">
Corpus annotation is now a key topic for all ar-
eas of natural language processing (NLP) and
information extraction (IE) which employ su-
pervised learning. With the explosion of re-
sults in molecular-biology there is an increased
need for IE to extract knowledge to support
database building and to search intelligently for
information in online journal collections. To
support this we are building a corpus of an-
notated abstracts taken from National Library
of Medicine’s MEDLINE database. In this pa-
per we report on this new corpus, its ontologi-
cal basis, and our experience in designing the
annotation scheme. Experimental results are
shown for inter-annotator agreement and com-
ments are made on methodological considera-
tions.
</bodyText>
<sectionHeader confidence="0.996305" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999971078651686">
In the field of molecular biology there have re-
cently been rapid advances that have motivated
researchers to construct very large databases in
order to share knowledge about biological sub-
stances and their reactions. A large part of this
knowledge is only available in unformalized re-
search papers and information extraction (IE)
from such sources is becoming crucial to help
support timely database updating and to help
researchers avoid problems associated with in-
formation overload.
For this purpose, various NLP techniques
have been applied to extract substance names
and other terms (Ohta et al., 1997; Fukuda et
al., 1998; Proux et al., 1998; Nobata et al., 1999)
as well as information concerning the nature
and interaction of proteins and genes (Sekimizu
et al., 1998; Blaschke et al., 1999; Hamphrays
et al., 2000; Thomas et al., 2000; Rindflesch
et al., 2000). The nomenclatures of genes and
associated proteins for model organisms such
as S. Cerevisiae (yeast) and D. Melanogaster
(fruit fly) are established so that good dictio-
naries for those names have been constructed.
However nomenclatures for humans are not yet
available as the whole picture of the human
genome has yet to be revealed, this results in
arbitrary names being used by researchers who
identified the structure of proteins and genes,
so dictionary-based approaches might not be
as e↵ective as in the case of model organisms.
Thus many of the previous researchers either
limit their scope to extracting information on
substances like enzymes which have established
naming conventions (Hamphrays et al., 2000)
or extracting information on ‘substance’ giving
up the distinction between the class of sub-
stance like protein and DNA (Fukuda et al.,
1998; Proux et al., 1998; Sekimizu et al., 1998;
Thomas et al., 2000).
Term identification and classification meth-
ods based on statistical learning seem to be
more generalizable to new knowledge types and
representations than the methods based on dic-
tionaries and hand-constructed heuristic rules.
We think that a corpus-based, machine-learning
approach is quite promising, and to support
this we are building a corpus of annotated ab-
stracts taken from National Library of Medicine
(NLM)’s MEDLINE database.
Corpus annotation is now a key topic for all
areas of natural language processing and lin-
guistically annotated corpus such as treebanks
are now established. In information extraction
task, annotated corpora have been made mainly
for the judgment set of information extraction
competitions such as MUC (Chinchor, 1998).
We think that technical terms of a scientific
domain share common characteristics with the
“Named Entities” and the tasks we attempt in-
volve recognition and classification of the names
of substances and their locations, just as named
entity recognition task in MUC conferences. We
therefore try to model our annotation task after
the definition of “EnameX” (Chincor, 1998a)
of MUC conferences. Unlike in MUC confer-
ences, we don’t make a precise definition of how
the recognized names are used in further infor-
mation extraction task such as event identifica-
tion, because we want the recognition technol-
ogy to be independent of the further task. Our
work is also compared to word-sense annotation
(e.g.,(Bruce and Wiebe, 1998)) where instances
of words that have multiple senses are labelled
for the sense it denotes according to a certain
dictionary or thesaurus.
We first built a conceptual model (ontology)
of substances and sources (substance location),
and designed a tag set based on the ontology
which conforms to SGML/XML format. Us-
ing the tag set, we annotated the entities such
names that appears in the abstracts of research
papers taken from the MEDLINE database. In
this paper we report on this new corpus, its on-
tological basis, and our experience in designing
the annotation scheme. Experimental results
are shown for inter-annotator agreement and
comments are made on methodological consid-
erations.
</bodyText>
<sectionHeader confidence="0.697792" genericHeader="method">
2 Design of The Tag Set
</sectionHeader>
<subsectionHeader confidence="0.997705">
2.1 Underlying Ontology
</subsectionHeader>
<bodyText confidence="0.996285202898551">
The task of annotation can be regarded as iden-
tifying and classifying the names that appears
in the texts according to a pre-defined classifi-
cation. For a reliable classification, the classifi-
cation must be well-defined and easy to under-
stand by the domain experts who annotate the
texts. To fulfill this requirement, we create a
concrete data model (ontology) of the biologi-
cal domain on which the tag sets are based.
Ontologies have been developed in the
biomedical sciences for several applications.
Such ontologies include conceptual hierarchies
for databases covering diseases and drug names.
Construction of a more general ontology e.g.
(Baker et al., 1999) is being attempted by
several groups interested in interconnecting
databases under a uniform view.
We start from a taxonomy illustrated in Fig-
ure 11. In this taxonomy, we classify sub-
stances according to their chemical character-
istics rather than their biological role. This
is unlike other existing ontologies in the biol-
ogy field (Baker et al., 1999; Schulze-Kremer,
1998), which mix the classification by biological
role and by chemical structure. The reason that
we have adopted this approach is that we con-
sider mixing two criteria prevents the mutually
exclusive classification and thus makes the an-
notated task more complicated by introducing
nested tag structures and context dependent se-
mantic tags. In our initial annotation work we
therefore chose to simplify the classification by
concentrating on the chemical structure.
Chemical classification of substances is quite
independent of the biological context in which
it appears, and is therefore more stably defined.
For example, the chemical characteristics of a
protein can be easily defined, but its biological
role may vary depending on the biological con-
text, e.g., it may work as an enzyme for one
species but a poison for others. Therefore, in
our model we do not classify substance as en-
zymes, transcription factors, genes, etc. but
as proteins, DNAs, RNAs, etc. They are fur-
ther classified into families, complexes, individ-
ual molecules, subunits, domains, and regions,
because these super- and sub- structures often
have separate names. This classification is non-
controversial among biologists and can be easily
expanded into other ontologies.
Sources are biological locations where sub-
stances are found and their reactions take place,
such as human (an organism), liver (a tissue),
leukocyte (a cell), membrane (a sub-location of
a cell) or HeLa (a cultured cell line). Organisms
are further classified into multi-cell organisms,
mono-cell organisms other than viruses, and
viruses. Organism, tissue, cell, sub-locations
are interrelated with part-of relation but that
relation is not shown in Figure 1. Based on this
domain model, we annotate the names of pro-
teins, DNAs, RNAs, and sources using the tags
shown in Table 1.
An example of an annotated text is shown
in Figure 2: the UI number is a unique iden-
tifier of the abstract in MEDLINE assigned by
&apos;In Figure 1 the concepts represented in bold are
reflected in the tag set and the concepts represented in
italic are reflected in the attributes.
</bodyText>
<figureCaption confidence="0.7951195">
Figure 1: The taxonomy used as a domain
model of our tagging scheme
</figureCaption>
<tableCaption confidence="0.867842">
Table 1: Tags and their target objects
</tableCaption>
<figureCaption confidence="0.989168066666667">
tag object
&lt;PROTEIN&gt; the names of proteins, in-
cluding protein groups, fam-
ilies, molecules, complexes,
and substructures
&lt;DNA&gt; the names of DNAs, including
DNA molecules, DNA groups,
DNA regions, and genes
&lt;RNA&gt; the names of RNAs, including
DNA molecules, RNA groups,
RNA regions, and genes
&lt;SOURCE&gt; the sources of substances, i.e.,
the names of organisms, tis-
sues, cells, sub-locations of
cells, and cell lines
</figureCaption>
<bodyText confidence="0.999595333333333">
the National Library of Medicine, TI is the ti-
tle, and AB is the abstract text. The unsure
attribute shown in the text is optional. This is
used when annotators are unsure about whether
a name should be tagged or whether the bound-
ary of the tagged name is correct, and when the
annotator was sure about the instance of the
markup, unsure attribute can be omitted (or
can be assigned the value ok).
</bodyText>
<sectionHeader confidence="0.938714" genericHeader="method">
3 Tagging Task
</sectionHeader>
<bodyText confidence="0.998002">
Before beginning the tagging process we made
a preliminary experiment by tagging 100 ab-
</bodyText>
<construct confidence="0.978989807692308">
UI - 91012785
TI - &lt;PROTEIN unsure=ok&gt;Lymphotoxin&lt;/PROTEIN&gt;
activation by &lt;SOURCE subtype=cl unsure=ok&gt;human
T-cell leukemia virus type I-infected cell
lines&lt;/SOURCE&gt;: role for &lt;PROTEIN unsure=ok&gt;NF-kappa
B&lt;/PROTEIN&gt;. AB - &lt;SOURCE subtype=cl
unsure=ok&gt;Human T-cell leukemia virus type
I (HTLV-I)-infected T-cell lines&lt;/SOURCE&gt;
constitutively produce high levels of biologically
active &lt;PROTEIN unsure=ok&gt;lymphotoxin&lt;/PROTEIN&gt;
(&lt;PROTEIN unsure=ok&gt;LT&lt;/PROTEIN&gt;; &lt;PROTEIN
unsure=ok&gt;tumor necrosis factor-beta&lt;/PROTEIN&gt;)
protein and &lt;RNA unsure=ok&gt;LT mRNA&lt;/RNA&gt;.
To understand the regulation of &lt;PROTEIN
unsure=ok&gt;LT&lt;/PROTEIN&gt; transcription by &lt;SOURCE
subtype=vi unsure=ok&gt;HTLV-I&lt;/SOURCE&gt;, we analyzed
the ability of a series of deletions of the
&lt;DNA unsure=ok&gt;LT promoter&lt;/DNA&gt; to drive the
&lt;DNA unsure=ok&gt;chloramphenicol acetyltransferase
(CAT) reporter gene&lt;/DNA&gt; in &lt;SOURCE subtype=cl
unsure=ok&gt;HTLV-I-positive MT-2 cells&lt;/SOURCE&gt;. The
smallest &lt;DNA unsure=ok&gt;LT promoter fragment&lt;/DNA&gt;
(-140 to +77) that was able to drive CAT activity
contained a site that was similar to the &lt;DNA
unsure=ok&gt;immunoglobulin kappa-chain NF-kappa
B-binding site&lt;/DNA&gt;.
</construct>
<figureCaption confidence="0.999226">
Figure 2: Example of Annotated Text
</figureCaption>
<bodyText confidence="0.999820681818182">
stracts. The abstracts were 116 words long on
average. One of the authors, who has a doctor-
ate in molecular biology, manually tagged the
abstracts. The process took about 40 hours.
2125 proteins, 358 DNAs, 30 RNAs, and 801
SOURCEs are tagged.
Ten abstracts out of the 100 were randomly
chosen and three other volunteers, two medical
science researchers and one biology researcher,
were asked to annotate them with our tagging
scheme. We gave a brief explanation on the tag-
ging task and scheme to each annotator. The
annotators were asked to annotate the text in-
dependently in one weeks’ time.
After the annotation was done, we sent a
questionnaire to annotators to ask for their com-
ments on the tagging task and the guide. From
the feedback of the questionnaire, we learned
that the annotators felt the task to be relatively
easy, but there are several cases where the they
were unsure about which tags to be assigned
where. The cases include:
</bodyText>
<listItem confidence="0.9957385">
• where two or more names are conjoined
with and or or, e.g., IRF-1 mRNA and
protein
• the ambiguity in some papers concerning
</listItem>
<figure confidence="0.96675478125">
other
nucleic acid monomer
natural
SOURCE
protein family/group
protein complex
protein molecule
protein substructure
subunit of protein complex
domain/region of protein
amino PROTEIN
peptide
amino acid monomer
DNA family/group
DNA molecule
domain/region of DNA
RNA family/group
RNA molecule
domain/region of RNA
nucleic
DNA
RNA
other polymer of nucleic acid
multi-cell organism
mono-cell organism
virus
organism
tissue
cell type
sub-location of cells
substance
cultured cell line
</figure>
<tableCaption confidence="0.995804">
Table 2: The percentage of inter-annotator agreement on 10 abstracts
</tableCaption>
<table confidence="0.999584875">
T1 T2 T3 T4 T5 T6 T7 T8 T9 T10 Mean
A0-A1 100.00 69.05 38.18 82.76 69.81 83.87 74.07 83.33 88.31 91.67 77.29
A0-A2 100.00 60.98 66.13 67.65 80.49 72.31 72.73 90.11 84.21 71.43 76.78
A0-A3 95.24 59.09 57.63 96.55 86.05 83.82 69.64 79.55 85.71 84.91 78.44
A1-A2 100.00 83.78 41.18 60.61 62.00 67.21 83.02 77.65 80.82 78.72 72.55
A1-A3 95.24 52.50 66.67 78.57 61.54 76.56 77.78 70.73 79.73 76.47 72.76
A2-A3 95.24 51.28 47.27 63.64 85.00 76.12 85.45 82.02 83.56 65.38 73.85
Mean 97.62 62.78 52.84 74.96 74.15 76.65 77.16 80.57 83.72 78.10 75.85
</table>
<bodyText confidence="0.998577">
whether names denote DNAs, RNAs or
proteins,
The annotators also said that the concrete ex-
ample of tagged texts are more useful than
descriptions and more examples should be in-
cluded in the manual.
Two-way agreement rate is scored accord-
ing to the scheme used in MUC confer-
ences(Chincor, 1998b). This scoring scheme
uses the F-measure derived from recall and pre-
cision. Recall R and precision P are given by:
</bodyText>
<equation confidence="0.953757">
R = |X n Y |/|X |(1)
and
P = |X n Y |/|Y  |(2)
</equation>
<bodyText confidence="0.996134333333333">
where X is the set of ‘correct’ objects and Y is
the set of ‘retrieved’ objects. The F-measure is
the harmonic mean of R and P given by
</bodyText>
<equation confidence="0.843966">
F = 1/(1/P + 1/R) = 2 x |X n Y |/(|X |+ |Y |)
(3)
</equation>
<bodyText confidence="0.99949296875">
and this F can be used to measure the agree-
ment of two sets of objects neither of which are
considered ‘correct’ (note that F is symmetric
with regards to X and Y ).
The F-measures multiplied by 100 to show
the percentage of the agreement between anno-
tators for the 10 abstracts are shown in Table 2.
In Table 2, T1, ..., T10 denotes the abstracts
and A0, ..., A3 denotes annotators. The ta-
ble shows that the agreement rate, comparable
to man-machine agreement of systems partici-
pated in MUC, is not good for inter-annotator
agreement rate. The disagreement indicate that
there are several problems in the definition of
the target and the description in the manual,
some of which seem to be specific to this do-
main2.
We investigate into the case of disagreement
by aligning the tagged text and examining the
disagreed parts by hand. We found that the dis-
agreement could be classified into several pat-
terns enlisted below. The numbers in the paren-
theses in the items are the number of the occur-
rence of the disagreement in total 10 texts. See
Table 3 for examples3.
Division (27): The cases where a same part
of a text is tagged as one by some annotators
but divided into two (or more) parts by others.
They were further classified into the following
cases.
D-1 (13) parenthesized abbreviations, full
forms, and synonyms
</bodyText>
<equation confidence="0.9442918">
D-2 (3) appositive phrases
D-3 (6) names of a substance which includes
SOURCE names
D-4 (2) names of a complex
D-5 (3) conjoined names
</equation>
<bodyText confidence="0.998890444444445">
Part (60): The cases where a part of phrases
is included between &lt;TAG&gt; and &lt;/TAG&gt; by some
annotators but not by others. They were fur-
ther classified into the following cases.
P-1 (30) the cases where the substances des-
ignated by the tagged part are changed by
whether the words following a name are
tagged together or not: in 10 cases, dif-
ferent tags are used by the annotators; in
</bodyText>
<footnote confidence="0.9462774">
2Though it may not be directly compared, inter-
annotator agreement for the judgment set of IREX
conference on Japanese information extraction(Sekine,
1999) is reported to be around 97% in F-measure.
3Attributes are omitted in the examples.
</footnote>
<tableCaption confidence="0.994524">
Table 3: Examples of disagreement
</tableCaption>
<table confidence="0.998632344827586">
Cases Examples
D-1 &lt;SOURCE&gt;Mycobacterium avium complex (MAC)&lt;/SOURCE&gt;
&lt;SOURCE&gt;Mycobacterium avium complex&lt;/SOURCE&gt; (&lt;SOURCE&gt;MAC&lt;/SOURCE&gt;)
D-2 &lt;SOURCE&gt;U937, a human monocytoid cell line&lt;/SOURCE&gt;
&lt;SOURCE&gt;U937&lt;/SOURCE&gt;, &lt;SOURCE&gt;a human monocytoid cell line&lt;/SOURCE&gt;
D-3 &lt;PROTEIN&gt;Human erythroid 5-aminolevulinate synthase&lt;/PROTEIN&gt;
&lt;SOURCE&gt;Human erythroid&lt;/SOURCE&gt; &lt;PROTEIN&gt;5-aminolevulinate
synthase&lt;/PROTEIN&gt;
D-4 &lt;PROTEIN&gt;p50-p65&lt;/PROTEIN&gt;
&lt;PROTEIN&gt;p50&lt;/PROTEIN&gt;-&lt;PROTEIN&gt;p65&lt;/PROTEIN&gt;
D-5 &lt;RNA&gt;ferritin or transferritin receptor mRNAs&lt;/RNA&gt;
&lt;PROTEIN&gt;ferritin&lt;/PROTEIN&gt; or &lt;RNA&gt;transferritin receptor mRNAs&lt;/RNA&gt;
P-1 &lt;DNA&gt;AP-2 consensus binding sequences&lt;/DNA&gt;
(di↵erent &lt;PROTEIN&gt;AP-2&lt;/PROTEIN&gt; consensus binding sequences
tags)
P-1 &lt;PROTEIN&gt;IRF-2 repressor&lt;/PROTEIN&gt;
(same tags) &lt;PROTEIN&gt;IRF-2&lt;/PROTEIN&gt; repressor
P-2 &lt;PROTEIN&gt;Stat91 protein &lt;/PROTEIN&gt;
&lt;PROTEIN&gt;Stat91&lt;/PROTEIN&gt; protein
P-3 &lt;RNA&gt;housekeeping ALAS mRNA&lt;/RNA&gt;
housekeeping &lt;RNA&gt;ALAS mRNA&lt;/RNA&gt;
P-4 &lt;PROTEIN&gt;transcription factor AP-2&lt;/PROTEIN&gt;
transcription factor &lt;PROTEIN&gt;AP-2&lt;/PROTEIN&gt;
P-5 &lt;DNA&gt;the terminal protein 1 gene promoter&lt;/DNA&gt;
the &lt;DNA&gt;terminal protein 1 gene promoter&lt;/DNA&gt;
Class &lt;RNA&gt;TAR&lt;/RNA&gt;
&lt;DNA&gt;TAR&lt;/DNA&gt;
Missing &lt;DNA&gt;21 bp repeats&lt;/DNA&gt;
21 bp repeats
</table>
<bodyText confidence="0.945515444444444">
the other 20 cases, the same tags are used
by the annotators.
P-2 (18) the cases where the substances des-
ignated by the tagged part are not a↵ected
by whether the words following a name are
tagged together or not
P-3 (6) the preceding attributive phrase that
narrows the meaning of the phrase
P-4 (5) the preceding appositive phrase
</bodyText>
<equation confidence="0.657282">
P-5 (1) determiners
</equation>
<bodyText confidence="0.999518319148937">
Class (19): The same part of text is tagged
with di↵erent tags
Missing (25): A part of text is tagged by some
annotators but not by others
The result shows that most of disagreement
involves recognizing the names, i.e., identifying
the range of words in sentence that are part of
the names. On the other hand, there are rela-
tively few cases where classification of the names
alone is the problem.
The disagreement involving abbreviation and
synonym (case D-1) will be simply solved by
explicitly giving an instruction as to whether a
full form and its abbreviation (or a name and its
synonym) should be separated or not. The case
of appositives (cases D-2 and P-5) and deter-
miners are also easy to solve by giving explicit
instruction, though the distinction between ap-
positives or determiners and other attributive
phrases (case P-4) must be carefully stated in
the instruction. The cases involving words that
follow a name that do not a↵ect the substance
the name designates (P-2) should be handled
similarly with a careful description of such cases
in the instruction.
The cases that involve the source names (case
D-3) and the following words that modify the
meaning of the phrase (P-1) are more difficult,
because the names with or without the modi-
fying phrases are recognized by the annotators.
One solution would be to allow nesting tags, but
this might complicate the tagging scheme and
be the cause of another type of error. Simple
heuristics of ‘taking the longest phrase’ might
work here, but in the case of preceding modi-
fiers (P-3) the heuristic is not desirable, because
most of the preceding modifiers are just descrip-
tion of a characteristics of a substance.
The names tagged by some annotators but
not by others (case M) were mostly the terms
that describes the parts of a gene as in the ex-
ample above, or the terms that denotes a family
or a class of substances. Such parts or families
are considered to be the ‘substance’ by some
annotators but not by others. Incorporating
the distinction between families, individual sub-
stances, and parts of the substance would help
to make the classification of names clearer and
result in more consistent annotation.
One of the difficulties of this task compared
to MUC named entity extraction is that our
targets are inherently unique names of classes,
whereas the targets of MUC named entity ex-
traction are names of unique entities. When
we refer to a specific protein or DNA, we don’t
refer to a specific molecule, but rather a class
of molecules that have the same characteris-
tics. As the name of a class, when a researcher
finds a new substance, the substance is often
named after the combination of its function, lo-
cation, etc. For example, “B-cell specific tran-
scription factor” is a name of a protein (there
is an entry in the SwissProt database). This re-
sults in the difficulty of distinguishing the names
of substances from general description of the
substance. In cases such as “Human erythroid
5-aminolevulinate synthase”, some researchers
recognize it as a name but some only recog-
nize “5-aminolevulinate synthase” as a name
and “Human erythroid” as just a description
and separate the part as different entity. Also
the prenominal modifiers are recognized or not
recognized as a part of the name depending on
whether the names with or without the modify-
ing phrases are recognized by the annotators.
The classification error, though relatively few,
also might be from the nature of this domain.
Most of the inconsistency are suspected to be
from conventional use of the protein names to
denote the genes that transcribe the protein.
For example, NF-kappa B gene is a name of
a gene that transcribe the protein NF-kappa
B, and the authors often omit the word gene
where they think it is clear from the context
that the particular occurrence of NF-kappa B
denotes the DNA. This require the annotators
good background knowledge and careful read-
ing, and sometimes the cause of annotation er-
rors. Even the participated annotators, who are
qualified specialist of the domain, are sometimes
unsure about the target, according to the ques-
tionnaire. This might be resolved if the full pa-
per could be referenced in the process of anno-
tation.
</bodyText>
<sectionHeader confidence="0.987091" genericHeader="conclusions">
4 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999993386363637">
We are in the process of developing a high-
quality tagging scheme for semantic annotation
of substances and their sources which play an
important role in molecular-biology events. We
have shown the results of initial inter-annotator
agreement tests using the current scheme. Af-
ter the initial experiment, we revised the tag-
ging manual to give more precise definitions
and more examples, and also added attributes
to denote the distinction of whether the pro-
tein (DNA, RNA) is a molecule, complex, sub-
structure, region, etc. We tagged 500 abstracts
according to the revised manual and tagging-
scheme, which are in the process of cross-
checking and cleaning up the errors. When they
are done we plan to make the corpus available
to the public along with the tagging manual.
Establishing the training process of annota-
tors, including communication between anno-
tators to get agreement on tagging strategies,
which is reported to improve the agreement rate
(Dan Melamed, 1998; Wiebe et al., 1999) should
also be necessary to help them make consist an-
notation.
One of the concerns that we have is that our
target task is more difficult than the traditional
named entity recognition task, because of the
naming convention (or the lack of it) of the
molecular-biology domain and because the task
requires very precise knowledge of the special-
ist. To solve this problem, tagging tools that
incorporates the reference function to the exter-
nal sources such as substance databases, on-line
glossaries, and full-text of the paper should also
be of great help.
The preliminary corpus, though it may be
‘noisy’, can be useful as a training set for recog-
nition program of biological names and terms.
The preliminary corpus can also be used to gain
the knowledge of how the tagged names are re-
lated to each other and other names, in order
to give feedback to the annotators and enhance
the domain model and enables us to annotate
more rich information such as biological roles.
</bodyText>
<sectionHeader confidence="0.997625" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995247402298851">
P. G. Baker, C. A. Goble, S. Bechhofer, N. W.
Paton, R. Stevens, and A. Brass. 1999.
An ontology for bioinformatics applications.
15:510–520.
C. Blaschke, M. A. Andrade, C. Ouzounis,
and A. Valencia. 1999. Automatic extraction
of biological information from scientific text:
protein-protein interactions. In Proc. 7th In-
ternational conference on Intelligent Systems
for Molecular Biology, pages 60–67.
R. Bruce and J. Wiebe. 1998. Word sense dis-
tinguishability and inter-coder agreement. In
Proc. 3rd Conference on Empirical Methods
in Natural Language Processing, pages 53–60.
N. Chinchor. 1998. Overview of MUC-
7. In Proceedings of 7th Message Un-
derstanding Conference. available at
http://www.muc.saic.com/proceedings.
N. Chincor. 1998a. MUC-7 named en-
tity task definition version 3.5. In
Proceedings of 7th Message Under-
standing Conference. available at
http://www.muc.saic.com/proceedings.
N. Chincor. 1998b. MUC-7 test scores in-
troduction. In Proceedings of 7th Mes-
sage Understanding Conference. available at
http://www.muc.saic.com/proceedings.
I Dan Melamed. 1998. Manual annota-
tion of translation equivalence:the blinker
project. Technical Report IRCS-98-07, IRCS,
University of Pennsylvania. available at
ftp://ftp.cis.upenn.edu/pub/ircs/tr/98-07/.
K. Fukuda, T. Tsunoda, A. Tamura, and
T. Takagi. 1998. Towards information ex-
traction: Identifying protein names from bi-
ological papers. In Proc. 3rd Pacific Symoi-
sium of Biocomputing, pages 707–718.
K. Hamphrays, G. Demetriou, and
R. Gaizauskas. 2000. Two applications
of information extraction to biological sci-
ence journal articles: Enzyme interactions
and protein structures. In Proc. 5th Pacific
Symoisium of Biocomputing, pages 72–80.
C. Nobata, N. Collier, and J. Tsujii. 1999.
Automatic term identification and classifica-
tion in biology texts. In Proc 5th Natural
Language Processing Pacific Rim Symoisium,
pages 369–374.
Y. Ohta, Y. Yamamoto, T. Okazaki, and
T. Takagi. 1997. Automatic construction of
knowledge base from biological papers. In
Proc. 5th International Conference on Intel-
ligent Systems for Molocular Biology, pages
218–225.
D. Proux, F. Rechenmann, L. Julliard, V. Pillet,
and B. Jacq. 1998. Detecting gene symbols
and names in biological texts: A first step
toward pertinent information extraction. In
Genome Informatics, pages 72–80. Universal
Academy Press.
T. C. Rindflesch, L. Tanabe, J. N. Weinstein,
and L. Hunter. 2000. Edgar: Extraction of
drugs, genes and relations from the biomedi-
cal literature. In Proc. 5th Pacific Symposium
on Biocomputing, pages 514–525.
S. Schulze-Kremer. 1998. Ontologies for molec-
ular biology. In Proc. 3rd Pacific Symposium
on Biocomputing, pages 695–706.
T. Sekimizu, H. S. Park, and J. Tsujii. 1998.
Identifying the interaction between genes and
gene products based on frequently seen verbs
in MEDLINE abstracts. In Genome In-
formatics, pages 62–71. Universal Academy
Press.
S. Sekine. 1999. Analysis of the answer
of named entity extraction. In Proceedings
of the IREX workshop, pages 129–132. in
Japanese.
J. Thomas, D. Milward, C. Ouzounis, S. Pul-
man, and M. Carroll. 2000. Automatic ex-
traction of protein interactions from scientific
abstracts. In Proc. 5th Pacific Symposium on
Biocomputing, pages 538–549.
J. Wiebe, R. Bruce, and T. O’Hara. 1999. De-
velopment and use of a gold standard data set
for subjectivity classifications. In Proceedings
of the 37th Meeting of ACL, pages 246–253.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.806116">
<title confidence="0.999922">Building an Annotated Corpus in the Molecular-Biology Domain</title>
<author confidence="0.994061">Yuka Tateisi</author>
<author confidence="0.994061">Tomoko Ohta</author>
<author confidence="0.994061">Nigel Collier</author>
<author confidence="0.994061">Chikashi Nobata</author>
<author confidence="0.994061">Jun-ichi</author>
<affiliation confidence="0.996582666666667">Department of Information Graduate School of University of</affiliation>
<address confidence="0.900583">7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033, Japan</address>
<abstract confidence="0.994567722222222">Corpus annotation is now a key topic for all areas of natural language processing (NLP) and information extraction (IE) which employ supervised learning. With the explosion of results in molecular-biology there is an increased need for IE to extract knowledge to support database building and to search intelligently for information in online journal collections. To support this we are building a corpus of annotated abstracts taken from National Library of Medicine’s MEDLINE database. In this paper we report on this new corpus, its ontological basis, and our experience in designing the annotation scheme. Experimental results are shown for inter-annotator agreement and comments are made on methodological considerations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P G Baker</author>
<author>C A Goble</author>
<author>S Bechhofer</author>
<author>N W Paton</author>
<author>R Stevens</author>
<author>A Brass</author>
</authors>
<title>An ontology for bioinformatics applications.</title>
<date>1999</date>
<pages>15--510</pages>
<contexts>
<context position="5690" citStr="Baker et al., 1999" startWordPosition="887" endWordPosition="890">entifying and classifying the names that appears in the texts according to a pre-defined classification. For a reliable classification, the classification must be well-defined and easy to understand by the domain experts who annotate the texts. To fulfill this requirement, we create a concrete data model (ontology) of the biological domain on which the tag sets are based. Ontologies have been developed in the biomedical sciences for several applications. Such ontologies include conceptual hierarchies for databases covering diseases and drug names. Construction of a more general ontology e.g. (Baker et al., 1999) is being attempted by several groups interested in interconnecting databases under a uniform view. We start from a taxonomy illustrated in Figure 11. In this taxonomy, we classify substances according to their chemical characteristics rather than their biological role. This is unlike other existing ontologies in the biology field (Baker et al., 1999; Schulze-Kremer, 1998), which mix the classification by biological role and by chemical structure. The reason that we have adopted this approach is that we consider mixing two criteria prevents the mutually exclusive classification and thus makes </context>
</contexts>
<marker>Baker, Goble, Bechhofer, Paton, Stevens, Brass, 1999</marker>
<rawString>P. G. Baker, C. A. Goble, S. Bechhofer, N. W. Paton, R. Stevens, and A. Brass. 1999. An ontology for bioinformatics applications. 15:510–520.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Blaschke</author>
<author>M A Andrade</author>
<author>C Ouzounis</author>
<author>A Valencia</author>
</authors>
<title>Automatic extraction of biological information from scientific text: protein-protein interactions.</title>
<date>1999</date>
<booktitle>In Proc. 7th International conference on Intelligent Systems for Molecular Biology,</booktitle>
<pages>60--67</pages>
<contexts>
<context position="1813" citStr="Blaschke et al., 1999" startWordPosition="277" endWordPosition="280">logical substances and their reactions. A large part of this knowledge is only available in unformalized research papers and information extraction (IE) from such sources is becoming crucial to help support timely database updating and to help researchers avoid problems associated with information overload. For this purpose, various NLP techniques have been applied to extract substance names and other terms (Ohta et al., 1997; Fukuda et al., 1998; Proux et al., 1998; Nobata et al., 1999) as well as information concerning the nature and interaction of proteins and genes (Sekimizu et al., 1998; Blaschke et al., 1999; Hamphrays et al., 2000; Thomas et al., 2000; Rindflesch et al., 2000). The nomenclatures of genes and associated proteins for model organisms such as S. Cerevisiae (yeast) and D. Melanogaster (fruit fly) are established so that good dictionaries for those names have been constructed. However nomenclatures for humans are not yet available as the whole picture of the human genome has yet to be revealed, this results in arbitrary names being used by researchers who identified the structure of proteins and genes, so dictionary-based approaches might not be as e↵ective as in the case of model org</context>
</contexts>
<marker>Blaschke, Andrade, Ouzounis, Valencia, 1999</marker>
<rawString>C. Blaschke, M. A. Andrade, C. Ouzounis, and A. Valencia. 1999. Automatic extraction of biological information from scientific text: protein-protein interactions. In Proc. 7th International conference on Intelligent Systems for Molecular Biology, pages 60–67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bruce</author>
<author>J Wiebe</author>
</authors>
<title>Word sense distinguishability and inter-coder agreement.</title>
<date>1998</date>
<booktitle>In Proc. 3rd Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>53--60</pages>
<contexts>
<context position="4290" citStr="Bruce and Wiebe, 1998" startWordPosition="664" endWordPosition="667">ties” and the tasks we attempt involve recognition and classification of the names of substances and their locations, just as named entity recognition task in MUC conferences. We therefore try to model our annotation task after the definition of “EnameX” (Chincor, 1998a) of MUC conferences. Unlike in MUC conferences, we don’t make a precise definition of how the recognized names are used in further information extraction task such as event identification, because we want the recognition technology to be independent of the further task. Our work is also compared to word-sense annotation (e.g.,(Bruce and Wiebe, 1998)) where instances of words that have multiple senses are labelled for the sense it denotes according to a certain dictionary or thesaurus. We first built a conceptual model (ontology) of substances and sources (substance location), and designed a tag set based on the ontology which conforms to SGML/XML format. Using the tag set, we annotated the entities such names that appears in the abstracts of research papers taken from the MEDLINE database. In this paper we report on this new corpus, its ontological basis, and our experience in designing the annotation scheme. Experimental results are sho</context>
</contexts>
<marker>Bruce, Wiebe, 1998</marker>
<rawString>R. Bruce and J. Wiebe. 1998. Word sense distinguishability and inter-coder agreement. In Proc. 3rd Conference on Empirical Methods in Natural Language Processing, pages 53–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chinchor</author>
</authors>
<title>Overview of MUC7.</title>
<date>1998</date>
<booktitle>In Proceedings of 7th Message Understanding Conference.</booktitle>
<note>available at http://www.muc.saic.com/proceedings.</note>
<contexts>
<context position="3564" citStr="Chinchor, 1998" startWordPosition="550" endWordPosition="551">sentations than the methods based on dictionaries and hand-constructed heuristic rules. We think that a corpus-based, machine-learning approach is quite promising, and to support this we are building a corpus of annotated abstracts taken from National Library of Medicine (NLM)’s MEDLINE database. Corpus annotation is now a key topic for all areas of natural language processing and linguistically annotated corpus such as treebanks are now established. In information extraction task, annotated corpora have been made mainly for the judgment set of information extraction competitions such as MUC (Chinchor, 1998). We think that technical terms of a scientific domain share common characteristics with the “Named Entities” and the tasks we attempt involve recognition and classification of the names of substances and their locations, just as named entity recognition task in MUC conferences. We therefore try to model our annotation task after the definition of “EnameX” (Chincor, 1998a) of MUC conferences. Unlike in MUC conferences, we don’t make a precise definition of how the recognized names are used in further information extraction task such as event identification, because we want the recognition tech</context>
</contexts>
<marker>Chinchor, 1998</marker>
<rawString>N. Chinchor. 1998. Overview of MUC7. In Proceedings of 7th Message Understanding Conference. available at http://www.muc.saic.com/proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chincor</author>
</authors>
<title>MUC-7 named entity task definition version 3.5.</title>
<date>1998</date>
<booktitle>In Proceedings of 7th Message Understanding Conference.</booktitle>
<note>available at http://www.muc.saic.com/proceedings.</note>
<contexts>
<context position="3937" citStr="Chincor, 1998" startWordPosition="608" endWordPosition="609">sing and linguistically annotated corpus such as treebanks are now established. In information extraction task, annotated corpora have been made mainly for the judgment set of information extraction competitions such as MUC (Chinchor, 1998). We think that technical terms of a scientific domain share common characteristics with the “Named Entities” and the tasks we attempt involve recognition and classification of the names of substances and their locations, just as named entity recognition task in MUC conferences. We therefore try to model our annotation task after the definition of “EnameX” (Chincor, 1998a) of MUC conferences. Unlike in MUC conferences, we don’t make a precise definition of how the recognized names are used in further information extraction task such as event identification, because we want the recognition technology to be independent of the further task. Our work is also compared to word-sense annotation (e.g.,(Bruce and Wiebe, 1998)) where instances of words that have multiple senses are labelled for the sense it denotes according to a certain dictionary or thesaurus. We first built a conceptual model (ontology) of substances and sources (substance location), and designed a </context>
<context position="12823" citStr="Chincor, 1998" startWordPosition="1998" endWordPosition="2000">82 69.64 79.55 85.71 84.91 78.44 A1-A2 100.00 83.78 41.18 60.61 62.00 67.21 83.02 77.65 80.82 78.72 72.55 A1-A3 95.24 52.50 66.67 78.57 61.54 76.56 77.78 70.73 79.73 76.47 72.76 A2-A3 95.24 51.28 47.27 63.64 85.00 76.12 85.45 82.02 83.56 65.38 73.85 Mean 97.62 62.78 52.84 74.96 74.15 76.65 77.16 80.57 83.72 78.10 75.85 whether names denote DNAs, RNAs or proteins, The annotators also said that the concrete example of tagged texts are more useful than descriptions and more examples should be included in the manual. Two-way agreement rate is scored according to the scheme used in MUC conferences(Chincor, 1998b). This scoring scheme uses the F-measure derived from recall and precision. Recall R and precision P are given by: R = |X n Y |/|X |(1) and P = |X n Y |/|Y |(2) where X is the set of ‘correct’ objects and Y is the set of ‘retrieved’ objects. The F-measure is the harmonic mean of R and P given by F = 1/(1/P + 1/R) = 2 x |X n Y |/(|X |+ |Y |) (3) and this F can be used to measure the agreement of two sets of objects neither of which are considered ‘correct’ (note that F is symmetric with regards to X and Y ). The F-measures multiplied by 100 to show the percentage of the agreement between anno</context>
</contexts>
<marker>Chincor, 1998</marker>
<rawString>N. Chincor. 1998a. MUC-7 named entity task definition version 3.5. In Proceedings of 7th Message Understanding Conference. available at http://www.muc.saic.com/proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chincor</author>
</authors>
<title>MUC-7 test scores introduction.</title>
<date>1998</date>
<booktitle>In Proceedings of 7th Message Understanding Conference.</booktitle>
<note>available at http://www.muc.saic.com/proceedings.</note>
<contexts>
<context position="3937" citStr="Chincor, 1998" startWordPosition="608" endWordPosition="609">sing and linguistically annotated corpus such as treebanks are now established. In information extraction task, annotated corpora have been made mainly for the judgment set of information extraction competitions such as MUC (Chinchor, 1998). We think that technical terms of a scientific domain share common characteristics with the “Named Entities” and the tasks we attempt involve recognition and classification of the names of substances and their locations, just as named entity recognition task in MUC conferences. We therefore try to model our annotation task after the definition of “EnameX” (Chincor, 1998a) of MUC conferences. Unlike in MUC conferences, we don’t make a precise definition of how the recognized names are used in further information extraction task such as event identification, because we want the recognition technology to be independent of the further task. Our work is also compared to word-sense annotation (e.g.,(Bruce and Wiebe, 1998)) where instances of words that have multiple senses are labelled for the sense it denotes according to a certain dictionary or thesaurus. We first built a conceptual model (ontology) of substances and sources (substance location), and designed a </context>
<context position="12823" citStr="Chincor, 1998" startWordPosition="1998" endWordPosition="2000">82 69.64 79.55 85.71 84.91 78.44 A1-A2 100.00 83.78 41.18 60.61 62.00 67.21 83.02 77.65 80.82 78.72 72.55 A1-A3 95.24 52.50 66.67 78.57 61.54 76.56 77.78 70.73 79.73 76.47 72.76 A2-A3 95.24 51.28 47.27 63.64 85.00 76.12 85.45 82.02 83.56 65.38 73.85 Mean 97.62 62.78 52.84 74.96 74.15 76.65 77.16 80.57 83.72 78.10 75.85 whether names denote DNAs, RNAs or proteins, The annotators also said that the concrete example of tagged texts are more useful than descriptions and more examples should be included in the manual. Two-way agreement rate is scored according to the scheme used in MUC conferences(Chincor, 1998b). This scoring scheme uses the F-measure derived from recall and precision. Recall R and precision P are given by: R = |X n Y |/|X |(1) and P = |X n Y |/|Y |(2) where X is the set of ‘correct’ objects and Y is the set of ‘retrieved’ objects. The F-measure is the harmonic mean of R and P given by F = 1/(1/P + 1/R) = 2 x |X n Y |/(|X |+ |Y |) (3) and this F can be used to measure the agreement of two sets of objects neither of which are considered ‘correct’ (note that F is symmetric with regards to X and Y ). The F-measures multiplied by 100 to show the percentage of the agreement between anno</context>
</contexts>
<marker>Chincor, 1998</marker>
<rawString>N. Chincor. 1998b. MUC-7 test scores introduction. In Proceedings of 7th Message Understanding Conference. available at http://www.muc.saic.com/proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Manual annotation of translation equivalence:the blinker project.</title>
<date>1998</date>
<tech>Technical Report IRCS-98-07,</tech>
<pages>98--07</pages>
<institution>IRCS, University of Pennsylvania.</institution>
<note>available at</note>
<contexts>
<context position="22069" citStr="Melamed, 1998" startWordPosition="3492" endWordPosition="3493"> definitions and more examples, and also added attributes to denote the distinction of whether the protein (DNA, RNA) is a molecule, complex, substructure, region, etc. We tagged 500 abstracts according to the revised manual and taggingscheme, which are in the process of crosschecking and cleaning up the errors. When they are done we plan to make the corpus available to the public along with the tagging manual. Establishing the training process of annotators, including communication between annotators to get agreement on tagging strategies, which is reported to improve the agreement rate (Dan Melamed, 1998; Wiebe et al., 1999) should also be necessary to help them make consist annotation. One of the concerns that we have is that our target task is more difficult than the traditional named entity recognition task, because of the naming convention (or the lack of it) of the molecular-biology domain and because the task requires very precise knowledge of the specialist. To solve this problem, tagging tools that incorporates the reference function to the external sources such as substance databases, on-line glossaries, and full-text of the paper should also be of great help. The preliminary corpus,</context>
</contexts>
<marker>Melamed, 1998</marker>
<rawString>I Dan Melamed. 1998. Manual annotation of translation equivalence:the blinker project. Technical Report IRCS-98-07, IRCS, University of Pennsylvania. available at ftp://ftp.cis.upenn.edu/pub/ircs/tr/98-07/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Fukuda</author>
<author>T Tsunoda</author>
<author>A Tamura</author>
<author>T Takagi</author>
</authors>
<title>Towards information extraction: Identifying protein names from biological papers.</title>
<date>1998</date>
<booktitle>In Proc. 3rd Pacific Symoisium of Biocomputing,</booktitle>
<pages>707--718</pages>
<contexts>
<context position="1642" citStr="Fukuda et al., 1998" startWordPosition="248" endWordPosition="251">ield of molecular biology there have recently been rapid advances that have motivated researchers to construct very large databases in order to share knowledge about biological substances and their reactions. A large part of this knowledge is only available in unformalized research papers and information extraction (IE) from such sources is becoming crucial to help support timely database updating and to help researchers avoid problems associated with information overload. For this purpose, various NLP techniques have been applied to extract substance names and other terms (Ohta et al., 1997; Fukuda et al., 1998; Proux et al., 1998; Nobata et al., 1999) as well as information concerning the nature and interaction of proteins and genes (Sekimizu et al., 1998; Blaschke et al., 1999; Hamphrays et al., 2000; Thomas et al., 2000; Rindflesch et al., 2000). The nomenclatures of genes and associated proteins for model organisms such as S. Cerevisiae (yeast) and D. Melanogaster (fruit fly) are established so that good dictionaries for those names have been constructed. However nomenclatures for humans are not yet available as the whole picture of the human genome has yet to be revealed, this results in arbitr</context>
</contexts>
<marker>Fukuda, Tsunoda, Tamura, Takagi, 1998</marker>
<rawString>K. Fukuda, T. Tsunoda, A. Tamura, and T. Takagi. 1998. Towards information extraction: Identifying protein names from biological papers. In Proc. 3rd Pacific Symoisium of Biocomputing, pages 707–718.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hamphrays</author>
<author>G Demetriou</author>
<author>R Gaizauskas</author>
</authors>
<title>Two applications of information extraction to biological science journal articles: Enzyme interactions and protein structures.</title>
<date>2000</date>
<booktitle>In Proc. 5th Pacific Symoisium of Biocomputing,</booktitle>
<pages>72--80</pages>
<contexts>
<context position="1837" citStr="Hamphrays et al., 2000" startWordPosition="281" endWordPosition="284">their reactions. A large part of this knowledge is only available in unformalized research papers and information extraction (IE) from such sources is becoming crucial to help support timely database updating and to help researchers avoid problems associated with information overload. For this purpose, various NLP techniques have been applied to extract substance names and other terms (Ohta et al., 1997; Fukuda et al., 1998; Proux et al., 1998; Nobata et al., 1999) as well as information concerning the nature and interaction of proteins and genes (Sekimizu et al., 1998; Blaschke et al., 1999; Hamphrays et al., 2000; Thomas et al., 2000; Rindflesch et al., 2000). The nomenclatures of genes and associated proteins for model organisms such as S. Cerevisiae (yeast) and D. Melanogaster (fruit fly) are established so that good dictionaries for those names have been constructed. However nomenclatures for humans are not yet available as the whole picture of the human genome has yet to be revealed, this results in arbitrary names being used by researchers who identified the structure of proteins and genes, so dictionary-based approaches might not be as e↵ective as in the case of model organisms. Thus many of the</context>
</contexts>
<marker>Hamphrays, Demetriou, Gaizauskas, 2000</marker>
<rawString>K. Hamphrays, G. Demetriou, and R. Gaizauskas. 2000. Two applications of information extraction to biological science journal articles: Enzyme interactions and protein structures. In Proc. 5th Pacific Symoisium of Biocomputing, pages 72–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Nobata</author>
<author>N Collier</author>
<author>J Tsujii</author>
</authors>
<title>Automatic term identification and classification in biology texts.</title>
<date>1999</date>
<booktitle>In Proc 5th Natural Language Processing Pacific Rim Symoisium,</booktitle>
<pages>369--374</pages>
<contexts>
<context position="1684" citStr="Nobata et al., 1999" startWordPosition="256" endWordPosition="259">ntly been rapid advances that have motivated researchers to construct very large databases in order to share knowledge about biological substances and their reactions. A large part of this knowledge is only available in unformalized research papers and information extraction (IE) from such sources is becoming crucial to help support timely database updating and to help researchers avoid problems associated with information overload. For this purpose, various NLP techniques have been applied to extract substance names and other terms (Ohta et al., 1997; Fukuda et al., 1998; Proux et al., 1998; Nobata et al., 1999) as well as information concerning the nature and interaction of proteins and genes (Sekimizu et al., 1998; Blaschke et al., 1999; Hamphrays et al., 2000; Thomas et al., 2000; Rindflesch et al., 2000). The nomenclatures of genes and associated proteins for model organisms such as S. Cerevisiae (yeast) and D. Melanogaster (fruit fly) are established so that good dictionaries for those names have been constructed. However nomenclatures for humans are not yet available as the whole picture of the human genome has yet to be revealed, this results in arbitrary names being used by researchers who id</context>
</contexts>
<marker>Nobata, Collier, Tsujii, 1999</marker>
<rawString>C. Nobata, N. Collier, and J. Tsujii. 1999. Automatic term identification and classification in biology texts. In Proc 5th Natural Language Processing Pacific Rim Symoisium, pages 369–374.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Ohta</author>
<author>Y Yamamoto</author>
<author>T Okazaki</author>
<author>T Takagi</author>
</authors>
<title>Automatic construction of knowledge base from biological papers.</title>
<date>1997</date>
<booktitle>In Proc. 5th International Conference on Intelligent Systems for Molocular Biology,</booktitle>
<pages>218--225</pages>
<contexts>
<context position="1621" citStr="Ohta et al., 1997" startWordPosition="244" endWordPosition="247">troduction In the field of molecular biology there have recently been rapid advances that have motivated researchers to construct very large databases in order to share knowledge about biological substances and their reactions. A large part of this knowledge is only available in unformalized research papers and information extraction (IE) from such sources is becoming crucial to help support timely database updating and to help researchers avoid problems associated with information overload. For this purpose, various NLP techniques have been applied to extract substance names and other terms (Ohta et al., 1997; Fukuda et al., 1998; Proux et al., 1998; Nobata et al., 1999) as well as information concerning the nature and interaction of proteins and genes (Sekimizu et al., 1998; Blaschke et al., 1999; Hamphrays et al., 2000; Thomas et al., 2000; Rindflesch et al., 2000). The nomenclatures of genes and associated proteins for model organisms such as S. Cerevisiae (yeast) and D. Melanogaster (fruit fly) are established so that good dictionaries for those names have been constructed. However nomenclatures for humans are not yet available as the whole picture of the human genome has yet to be revealed, t</context>
</contexts>
<marker>Ohta, Yamamoto, Okazaki, Takagi, 1997</marker>
<rawString>Y. Ohta, Y. Yamamoto, T. Okazaki, and T. Takagi. 1997. Automatic construction of knowledge base from biological papers. In Proc. 5th International Conference on Intelligent Systems for Molocular Biology, pages 218–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Proux</author>
<author>F Rechenmann</author>
<author>L Julliard</author>
<author>V Pillet</author>
<author>B Jacq</author>
</authors>
<title>Detecting gene symbols and names in biological texts: A first step toward pertinent information extraction.</title>
<date>1998</date>
<booktitle>In Genome Informatics,</booktitle>
<pages>72--80</pages>
<publisher>Universal Academy Press.</publisher>
<contexts>
<context position="1662" citStr="Proux et al., 1998" startWordPosition="252" endWordPosition="255">logy there have recently been rapid advances that have motivated researchers to construct very large databases in order to share knowledge about biological substances and their reactions. A large part of this knowledge is only available in unformalized research papers and information extraction (IE) from such sources is becoming crucial to help support timely database updating and to help researchers avoid problems associated with information overload. For this purpose, various NLP techniques have been applied to extract substance names and other terms (Ohta et al., 1997; Fukuda et al., 1998; Proux et al., 1998; Nobata et al., 1999) as well as information concerning the nature and interaction of proteins and genes (Sekimizu et al., 1998; Blaschke et al., 1999; Hamphrays et al., 2000; Thomas et al., 2000; Rindflesch et al., 2000). The nomenclatures of genes and associated proteins for model organisms such as S. Cerevisiae (yeast) and D. Melanogaster (fruit fly) are established so that good dictionaries for those names have been constructed. However nomenclatures for humans are not yet available as the whole picture of the human genome has yet to be revealed, this results in arbitrary names being used</context>
</contexts>
<marker>Proux, Rechenmann, Julliard, Pillet, Jacq, 1998</marker>
<rawString>D. Proux, F. Rechenmann, L. Julliard, V. Pillet, and B. Jacq. 1998. Detecting gene symbols and names in biological texts: A first step toward pertinent information extraction. In Genome Informatics, pages 72–80. Universal Academy Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T C Rindflesch</author>
<author>L Tanabe</author>
<author>J N Weinstein</author>
<author>L Hunter</author>
</authors>
<title>Edgar: Extraction of drugs, genes and relations from the biomedical literature.</title>
<date>2000</date>
<booktitle>In Proc. 5th Pacific Symposium on Biocomputing,</booktitle>
<pages>514--525</pages>
<contexts>
<context position="1884" citStr="Rindflesch et al., 2000" startWordPosition="289" endWordPosition="292">ge is only available in unformalized research papers and information extraction (IE) from such sources is becoming crucial to help support timely database updating and to help researchers avoid problems associated with information overload. For this purpose, various NLP techniques have been applied to extract substance names and other terms (Ohta et al., 1997; Fukuda et al., 1998; Proux et al., 1998; Nobata et al., 1999) as well as information concerning the nature and interaction of proteins and genes (Sekimizu et al., 1998; Blaschke et al., 1999; Hamphrays et al., 2000; Thomas et al., 2000; Rindflesch et al., 2000). The nomenclatures of genes and associated proteins for model organisms such as S. Cerevisiae (yeast) and D. Melanogaster (fruit fly) are established so that good dictionaries for those names have been constructed. However nomenclatures for humans are not yet available as the whole picture of the human genome has yet to be revealed, this results in arbitrary names being used by researchers who identified the structure of proteins and genes, so dictionary-based approaches might not be as e↵ective as in the case of model organisms. Thus many of the previous researchers either limit their scope </context>
</contexts>
<marker>Rindflesch, Tanabe, Weinstein, Hunter, 2000</marker>
<rawString>T. C. Rindflesch, L. Tanabe, J. N. Weinstein, and L. Hunter. 2000. Edgar: Extraction of drugs, genes and relations from the biomedical literature. In Proc. 5th Pacific Symposium on Biocomputing, pages 514–525.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Schulze-Kremer</author>
</authors>
<title>Ontologies for molecular biology.</title>
<date>1998</date>
<booktitle>In Proc. 3rd Pacific Symposium on Biocomputing,</booktitle>
<pages>695--706</pages>
<contexts>
<context position="6065" citStr="Schulze-Kremer, 1998" startWordPosition="948" endWordPosition="949">. Ontologies have been developed in the biomedical sciences for several applications. Such ontologies include conceptual hierarchies for databases covering diseases and drug names. Construction of a more general ontology e.g. (Baker et al., 1999) is being attempted by several groups interested in interconnecting databases under a uniform view. We start from a taxonomy illustrated in Figure 11. In this taxonomy, we classify substances according to their chemical characteristics rather than their biological role. This is unlike other existing ontologies in the biology field (Baker et al., 1999; Schulze-Kremer, 1998), which mix the classification by biological role and by chemical structure. The reason that we have adopted this approach is that we consider mixing two criteria prevents the mutually exclusive classification and thus makes the annotated task more complicated by introducing nested tag structures and context dependent semantic tags. In our initial annotation work we therefore chose to simplify the classification by concentrating on the chemical structure. Chemical classification of substances is quite independent of the biological context in which it appears, and is therefore more stably defin</context>
</contexts>
<marker>Schulze-Kremer, 1998</marker>
<rawString>S. Schulze-Kremer. 1998. Ontologies for molecular biology. In Proc. 3rd Pacific Symposium on Biocomputing, pages 695–706.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Sekimizu</author>
<author>H S Park</author>
<author>J Tsujii</author>
</authors>
<title>Identifying the interaction between genes and gene products based on frequently seen verbs in MEDLINE abstracts.</title>
<date>1998</date>
<booktitle>In Genome Informatics,</booktitle>
<pages>62--71</pages>
<publisher>Universal Academy Press.</publisher>
<contexts>
<context position="1790" citStr="Sekimizu et al., 1998" startWordPosition="273" endWordPosition="276">are knowledge about biological substances and their reactions. A large part of this knowledge is only available in unformalized research papers and information extraction (IE) from such sources is becoming crucial to help support timely database updating and to help researchers avoid problems associated with information overload. For this purpose, various NLP techniques have been applied to extract substance names and other terms (Ohta et al., 1997; Fukuda et al., 1998; Proux et al., 1998; Nobata et al., 1999) as well as information concerning the nature and interaction of proteins and genes (Sekimizu et al., 1998; Blaschke et al., 1999; Hamphrays et al., 2000; Thomas et al., 2000; Rindflesch et al., 2000). The nomenclatures of genes and associated proteins for model organisms such as S. Cerevisiae (yeast) and D. Melanogaster (fruit fly) are established so that good dictionaries for those names have been constructed. However nomenclatures for humans are not yet available as the whole picture of the human genome has yet to be revealed, this results in arbitrary names being used by researchers who identified the structure of proteins and genes, so dictionary-based approaches might not be as e↵ective as i</context>
</contexts>
<marker>Sekimizu, Park, Tsujii, 1998</marker>
<rawString>T. Sekimizu, H. S. Park, and J. Tsujii. 1998. Identifying the interaction between genes and gene products based on frequently seen verbs in MEDLINE abstracts. In Genome Informatics, pages 62–71. Universal Academy Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sekine</author>
</authors>
<title>Analysis of the answer of named entity extraction.</title>
<date>1999</date>
<booktitle>In Proceedings of the IREX workshop,</booktitle>
<pages>129--132</pages>
<note>in Japanese.</note>
<contexts>
<context position="15163" citStr="Sekine, 1999" startWordPosition="2428" endWordPosition="2429">ich includes SOURCE names D-4 (2) names of a complex D-5 (3) conjoined names Part (60): The cases where a part of phrases is included between &lt;TAG&gt; and &lt;/TAG&gt; by some annotators but not by others. They were further classified into the following cases. P-1 (30) the cases where the substances designated by the tagged part are changed by whether the words following a name are tagged together or not: in 10 cases, different tags are used by the annotators; in 2Though it may not be directly compared, interannotator agreement for the judgment set of IREX conference on Japanese information extraction(Sekine, 1999) is reported to be around 97% in F-measure. 3Attributes are omitted in the examples. Table 3: Examples of disagreement Cases Examples D-1 &lt;SOURCE&gt;Mycobacterium avium complex (MAC)&lt;/SOURCE&gt; &lt;SOURCE&gt;Mycobacterium avium complex&lt;/SOURCE&gt; (&lt;SOURCE&gt;MAC&lt;/SOURCE&gt;) D-2 &lt;SOURCE&gt;U937, a human monocytoid cell line&lt;/SOURCE&gt; &lt;SOURCE&gt;U937&lt;/SOURCE&gt;, &lt;SOURCE&gt;a human monocytoid cell line&lt;/SOURCE&gt; D-3 &lt;PROTEIN&gt;Human erythroid 5-aminolevulinate synthase&lt;/PROTEIN&gt; &lt;SOURCE&gt;Human erythroid&lt;/SOURCE&gt; &lt;PROTEIN&gt;5-aminolevulinate synthase&lt;/PROTEIN&gt; D-4 &lt;PROTEIN&gt;p50-p65&lt;/PROTEIN&gt; &lt;PROTEIN&gt;p50&lt;/PROTEIN&gt;-&lt;PROTEIN&gt;p65&lt;/PROTE</context>
</contexts>
<marker>Sekine, 1999</marker>
<rawString>S. Sekine. 1999. Analysis of the answer of named entity extraction. In Proceedings of the IREX workshop, pages 129–132. in Japanese.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Thomas</author>
<author>D Milward</author>
<author>C Ouzounis</author>
<author>S Pulman</author>
<author>M Carroll</author>
</authors>
<title>Automatic extraction of protein interactions from scientific abstracts.</title>
<date>2000</date>
<booktitle>In Proc. 5th Pacific Symposium on Biocomputing,</booktitle>
<pages>538--549</pages>
<contexts>
<context position="1858" citStr="Thomas et al., 2000" startWordPosition="285" endWordPosition="288"> part of this knowledge is only available in unformalized research papers and information extraction (IE) from such sources is becoming crucial to help support timely database updating and to help researchers avoid problems associated with information overload. For this purpose, various NLP techniques have been applied to extract substance names and other terms (Ohta et al., 1997; Fukuda et al., 1998; Proux et al., 1998; Nobata et al., 1999) as well as information concerning the nature and interaction of proteins and genes (Sekimizu et al., 1998; Blaschke et al., 1999; Hamphrays et al., 2000; Thomas et al., 2000; Rindflesch et al., 2000). The nomenclatures of genes and associated proteins for model organisms such as S. Cerevisiae (yeast) and D. Melanogaster (fruit fly) are established so that good dictionaries for those names have been constructed. However nomenclatures for humans are not yet available as the whole picture of the human genome has yet to be revealed, this results in arbitrary names being used by researchers who identified the structure of proteins and genes, so dictionary-based approaches might not be as e↵ective as in the case of model organisms. Thus many of the previous researchers</context>
</contexts>
<marker>Thomas, Milward, Ouzounis, Pulman, Carroll, 2000</marker>
<rawString>J. Thomas, D. Milward, C. Ouzounis, S. Pulman, and M. Carroll. 2000. Automatic extraction of protein interactions from scientific abstracts. In Proc. 5th Pacific Symposium on Biocomputing, pages 538–549.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wiebe</author>
<author>R Bruce</author>
<author>T O’Hara</author>
</authors>
<title>Development and use of a gold standard data set for subjectivity classifications.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Meeting of ACL,</booktitle>
<pages>246--253</pages>
<marker>Wiebe, Bruce, O’Hara, 1999</marker>
<rawString>J. Wiebe, R. Bruce, and T. O’Hara. 1999. Development and use of a gold standard data set for subjectivity classifications. In Proceedings of the 37th Meeting of ACL, pages 246–253.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>