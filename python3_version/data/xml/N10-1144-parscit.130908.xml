<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.996269">
Reformulating Discourse Connectives for Non-Expert Readers
</title>
<author confidence="0.983026">
Advaith Siddharthan Napoleon Katsos
</author>
<affiliation confidence="0.994787">
Department of Computing Science Research Centre for English and Applied Linguistics
University of Aberdeen University of Cambridge
</affiliation>
<email confidence="0.99665">
advaith@abdn.ac.uk nk248@cam.ac.uk
</email>
<sectionHeader confidence="0.994512" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.980785333333333">
In this paper we report a behavioural ex-
periment documenting that different lexico-
syntactic formulations of the discourse rela-
tion of causation are deemed more or less ac-
ceptable by different categories of readers. We
further report promising results for automati-
cally selecting the formulation that is most ap-
propriate for a given category of reader using
supervised learning. This investigation is em-
bedded within a longer term research agenda
aimed at summarising scientific writing for lay
readers using appropriate paraphrasing.
</bodyText>
<sectionHeader confidence="0.998749" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999940352941177">
There are many reasons why a speaker/writer would
want to choose one formulation of a discourse rela-
tion over another; for example, maintaining thread
of discourse, avoiding shifts in focus and issues of
salience and end weight. There are also reasons to
use different formulations for different audiences;
for example, to account for differences in reading
skills and domain knowledge. In this paper, we
present a psycholinguistic experiment designed to il-
luminate the factors that determine the appropriate-
ness of particular realisations of discourse relations
for different audiences. The second part of this pa-
per focuses on training a natural language generation
system to predict which realisation choices are more
felicitous than others for a given audience. Our para-
phrases include eight different constructions. Con-
sider 1a.–d. below:
</bodyText>
<listItem confidence="0.77281375">
(1) a. Tom ate because he was hungry.
b. Tom ate because of his hunger.
c. Tom’s hunger caused him to eat.
d. The cause of Tom’s eating was his hunger.
</listItem>
<bodyText confidence="0.999849222222222">
These differ in terms of the lexico-syntactic prop-
erties of the discourse marker (shown in bold font).
Indeed the discourse markers here are conjunctions,
prepositions, verbs and nouns. As a consequence
the propositional content is expressed either as a
clause or a noun phrase (“he was hungry” vs “his
hunger”, etc.). Additionally, the order of presenta-
tion of propositional content can be varied to give
four more lexico-syntactic paraphrases:
</bodyText>
<listItem confidence="0.92620275">
(1) e. Because Tom was hungry, he ate.
f. Because of his hunger, Tom ate.
g. Tom’s eating was caused by his hunger.
h. Tom’s hunger was the cause of his eating.
</listItem>
<bodyText confidence="0.999940214285714">
It is clear that some formulations of this propo-
sitional content are more felicitous than others; for
example, 1a. seems preferable to 1d., but for a
different propositional content, other formulations
might be more felicitous (for instance, example 4,
section 3.1, where the passive seems in fact prefer-
able). While discourse level choices based on infor-
mation ordering play a role in choosing a formula-
tion, it is of particular interest to us that some de-
contextualised information orderings within a sen-
tence are deemed unacceptable. Any summarisation
task that considers discourse coherence should not
introduce sentence-level unacceptability.
We now summarise our main research questions:
</bodyText>
<listItem confidence="0.944025">
1. Are some formulations of a discourse relation more
felicitous than others, given the same propositional
content?
2. Does the reader’s level of domain expertise affect
their preferred formulation?
3. What linguistic features determine which formula-
tions are acceptable?
4. How well can a natural language generator be
trained to predict the most appropriate formulation
</listItem>
<bodyText confidence="0.899046">
for a given category of reader?
In this paper, we focus on causal relations because
these are pervasive in science writing and are inte-
gral to how humans conceptualise the world. The
8 formulations selected are 2 information orderings
</bodyText>
<page confidence="0.966488">
1002
</page>
<note confidence="0.8654945">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 1002–1010,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999955918918919">
of 4 different syntactic constructs; thus we explore a
fairly broad range of constructions.
With regard to genre, we have a particular in-
terest in scientific writing, specifically biomedical
texts. Reformulating such texts for lay audiences is
a highly relevant task today and many news agen-
cies perform this service; e.g., Reuters Health sum-
marises medical literature for lay audiences and
BBC online has a Science/Nature section that re-
ports on science. These services rely either on press
releases by scientists and universities or on special-
ist scientific reporters, thus limiting coverage of a
growing volume of scientific literature in a digital
economy. Thus, reformulating technical writing for
lay audiences is a research area of direct relevance to
information retrieval, information access and sum-
marisation systems.
At the same time, while there are numerous stud-
ies about the effect of text reformulation on people
with different literacy levels or language deficits (see
section 2), the issue of expert vs lay audiences has
received less attention. Further, most studies focus
on narrative texts such as news or history. However,
as Linderholm et al. (2000) note, results from studies
of causality in narrative texts might not carry over to
scientific writing, because inferences are made more
spontaneously during the reading of narrative than
expository texts. Thus comparing expert vs lay read-
ers on the comprehension of causal relations in sci-
entific writing is a most timely investigation.
In section 2, we relate our research to the exist-
ing linguistic, psycholinguistic and computational
literature. Then in section 3, we describe our psy-
cholinguistic experiment that addresses our first two
research questions and in section 4 we present a
computational approach to learning felicitous para-
phrases that addresses the final two questions.
</bodyText>
<sectionHeader confidence="0.802209" genericHeader="introduction">
2 Background and related work
</sectionHeader>
<subsectionHeader confidence="0.988348">
2.1 Expressing causation
</subsectionHeader>
<bodyText confidence="0.999734076923077">
Linguists generally consider five different compo-
nents of meaning (Wolff et al., 2005) in causal ex-
pressions: (a) occurrence of change in patient, (b)
specification of endstate, (c) tendency and concor-
dance, (d) directness and (e) mechanism. The ex-
pressions we consider in this paper, “because” (con-
junction), “because of” (preposition) and “cause”
as noun or verb (periphrastic causatives) express
(a), (b) and in some instances, (c). This is in contrast
to affect verbs that only express (a), link verbs that
express (a–b), lexical causatives that express (a–d)
and resultatives that express (a–e). These distinc-
tions are illustrated by the sentences in example 2:
</bodyText>
<listItem confidence="0.935877692307692">
(2) a. Sara kicked the door. (affect verb – end
state not specified)
b. The door’s breaking was linked to Sara.
(link verb – end state specified, but un-
clear that door has a tendency to break)
c. Sara caused the door to break. / The
door broke because of Sara. (periphrastic
/ preposition – indirect; the door might
have a tendency to break)
d. Sara broke the door. (lexical causative –
directness of action is specified)
e. Sara broke the door open. (resultative –
end state is “open”)
</listItem>
<bodyText confidence="0.999953461538462">
There is much literature on how people prefer
one type of causative over the other based on these
five components of meaning (e.g. see Wolff et al.
(2005)). What is less understood is how one selects
between various expressions that carry similar se-
mantic content. In this paper we consider four con-
structs “because of”, “because”, and “cause” as a
verb and a noun. These express the components of
meaning (a–c) using different syntactic structures.
By considering only these four lexically similar con-
structs, we can focus on the role of the lexis and of
syntax in determining the most felicitous expression
of causation for a given propositional content.
</bodyText>
<subsectionHeader confidence="0.99978">
2.2 Discourse connectives and comprehension
</subsectionHeader>
<bodyText confidence="0.9988907">
Previous work has shown that when texts have been
manually rewritten to make discourse relations such
as causation explicit, reading comprehension is sig-
nificantly improved in middle/high school students
(Beck et al., 1991). Further, connectives that permit
pre-posed adverbial clauses have been found to be
difficult for third to fifth grade readers, even when
the order of mention coincides with the causal (and
temporal) order; for instance, 3b. is more accessible
than 3a. (e.g. from Anderson and Davison (1988)).
</bodyText>
<footnote confidence="0.804518166666667">
(3) a. Because Mexico allowed slavery, many
Americans and their slaves moved to
Mexico during that time.
b. Many Americans and their slaves moved
to Mexico during that time, because
Mexico allowed slavery.
</footnote>
<page confidence="0.983256">
1003
</page>
<bodyText confidence="0.999892071428572">
Such studies show that comprehension can be im-
proved by reformulating text; e.g., making causal
relations explicit had a facilitatory effect for read-
ers with low reading skills (Linderholm et al., 2000;
Beck et al., 1991) and for readers with low levels of
domain expertise (Noordman and Vonk, 1992). Fur-
ther, specific information orderings were found to be
facilitatory by Anderson and Davison (1988).
However, it has not been investigated whether
readers with different levels of domain expertise are
facilitated by any specific lexico-syntactic formula-
tion among the many possible explicit realisations of
a relation. This is a novel question in the linguistics
literature, and we address it in section 3.
</bodyText>
<subsectionHeader confidence="0.99748">
2.3 Connectives and automatic (re)generation
</subsectionHeader>
<bodyText confidence="0.999991684210526">
Much of the work regarding (re)generation of text
based on discourse connectives aims to simplify
text in certain ways, to make it more accessible
to particular classes of readers. The PSET project
(Carroll et al., 1998) considered simplifying news
reports for aphasics. The PSET project focused
mainly on lexical simplification (replacing difficult
words with easier ones), but more recently, there
has been work on syntactic simplification and, in
particular, the way syntactic rewrites interact with
discourse structure and text cohesion (Siddharthan,
2006). Elsewhere, there has been renewed interest in
paraphrasing, including the replacement of words
(especially verbs) with their dictionary definitions
(Kaji et al., 2002) and the replacement of idiomatic
or otherwise troublesome expressions with simpler
ones. The current research emphasis is on auto-
matically learning paraphrases from comparable or
aligned corpora (Barzilay and Lee, 2003; Ibrahim et
al., 2003). The text simplification and paraphrasing
literature does not address paraphrasing that requires
syntactic alterations such as those in example 1 or
the question of appropriateness of different formula-
tions of a discourse relation.
Some natural language generation systems in-
corporate results from psycholinguistic studies to
make principled choices between alternative formu-
lations. For example, SkillSum (Williams and Re-
iter, 2008) and ICONOCLAST (Power et al., 2003)
are two contemporary generation systems that allow
for specifying aspects of style such as choice of dis-
course marker, clause order, repetition and sentence
and paragraph lengths in the form of constraints that
can be optimised. However, to date, these systems
do not consider syntactic reformulations of the type
we are interested in. Our research is directly rele-
vant to such generation systems as it can help such
systems make decisions in a principled manner.
</bodyText>
<subsectionHeader confidence="0.999841">
2.4 Corpus studies and treebanking
</subsectionHeader>
<bodyText confidence="0.999990416666667">
There are two major corpora that mark up discourse
relations – the RST Discourse Treebank based on
Rhetorical Structure Theory (Mann and Thompson,
1988), and the Penn Discourse Treebank (Webber et
al., 2005). Neither is suitable for studies on the fe-
licity of specific formulations of a discourse relation.
As part of this research, we have created a corpus of
144 real text examples, reformulated in 8 ways, giv-
ing 1152 sentences in total.
There have been numerous corpus studies of dis-
course connectives, such as studies on the discourse-
role disambiguation of individual cue-phrases in
spoken and written corpora (e.g., Hirschberg and
Litman (1993)), the substitutability of discourse
connectives (e.g., Hutchinson (2005)), and indeed
corpus studies as a means of informing the choice
of discourse relations to consider in a theory (e.g.,
Knott and Dale (1994); Knott (1996)). A distin-
guishing feature of our approach relative to previ-
ous ones is an in-depth study of syntactic variations;
in contrast, for example, Knott’s taxonomy of dis-
course relations is based on the use of a substitution
text that precludes variants of the same relation hav-
ing different syntax.
</bodyText>
<sectionHeader confidence="0.948055" genericHeader="method">
3 Linguistic acceptability study
</sectionHeader>
<subsectionHeader confidence="0.996665">
3.1 Dataset creation
</subsectionHeader>
<bodyText confidence="0.999907461538462">
We have constructed a dataset that can be used to
gain insights into differences between different real-
isations of discourse relations. In the following, we
will illustrate such rewriting situations using an ex-
ample from a medical article. As mentioned previ-
ously, we are particularly interested in complex syn-
tactic reformulations; in example 4 below, a. is from
the original text and b.–h. are reformulations. There
are two examples each of formulations using “be-
cause”, “because of”, the verb “cause” and the noun
“cause” with different ordering of propositional con-
tent. This provides us with 8 formulations per exam-
ple sentence; for example:
</bodyText>
<page confidence="0.972254">
1004
</page>
<listItem confidence="0.958611733333333">
(4) a. Fructose-induced hypertension is caused
by increased salt absorption by the intes-
tine and kidney. [cause p]
b. Increased salt absorption by the intestine
and kidney causes fructose-induced hy-
pertension. [cause a]
c. Fructose-induced hypertension occurs
because of increased salt absorption by
the intestine and kidney. [a becof b]
d. Because of increased salt absorption by
the intestine and kidney, fructose-induced
hypertension occurs. [becof ba]
e. Fructose-induced hypertension occurs
because there is increased salt absorption
by the intestine and kidney. [a bec b]
</listItem>
<bodyText confidence="0.970835782608696">
f. Because there is increased salt absorp-
tion by the intestine and kidney, fructose-
induced hypertension occurs. [bec ba]
g. Increased salt absorption by the intes-
tine and kidney is the cause of fructose-
induced hypertension. [b causeof a]
h. The cause of fructose-induced hyperten-
sion is increased salt absorption by the in-
testine and kidney. [causeof ab]
Our corpus contains 144 such examples from three
genres (see below), giving 1152 sentences in total.
These 144 examples contain equal numbers of orig-
inal sentences (18) of each of the 8 types. The man-
ual reformulation is formulaic, and it is part of our
broader research effort to automate the process using
transfer rules and a bi-directional grammar. The ex-
ample above is indicative of the process. To make a
clause out of a noun phrase (examples 4c.–f.), we in-
troduce either the copula or the verb “occur”, based
on a subjective judgement of whether this is an event
or a continuous phenomenon. Conversely, to create
a noun phrase from a clause, we use a possessive and
a gerund; for example (simplified for illustration):
</bodyText>
<listItem confidence="0.7681455">
(5) a. Irwin had triumphed because he was so
good a man.
</listItem>
<bodyText confidence="0.959482421052631">
b. The cause of Irwin’s having triumphed
was his being so good a man.
Clearly, there are many different possibilities for
this reformulation; for example:
(5) b’. The cause of Irwin’s triumph was his be-
ing so good a man.
b”. The cause of Irwin’s triumph was his ex-
ceptional goodness as a man.
As part of our wider research agenda, we are ex-
ploring automatic reformulation using transfer rules
and a bi-directional grammar. In this context, given
our immediate interest is in the discourse markers,
we restrict our reformulation method to only gener-
ate sentences such as 5b. This not only makes au-
tomation easier, but also standardises data for our
experiment by removing an aspect of subjectivity
from the manual reformulation.
We used equal numbers of sentences from three
different genres1:
</bodyText>
<listItem confidence="0.997340571428571">
• PubMed Abstracts: Technical writing from the
Biomedical domain
• BNC World: Article from the British National Cor-
pus tagged as World News
• BNC Natural Science: Article from the British Na-
tional Corpus tagged as Natural Science. This cov-
ers popular science writing in the mainstream media
</listItem>
<bodyText confidence="0.99992">
There were 48 example sentences chosen ran-
domly from each genre, such that there were 6 ex-
amples of each of the 8 types of formulation)
</bodyText>
<subsectionHeader confidence="0.995372">
3.2 Experimental setup
</subsectionHeader>
<bodyText confidence="0.999838142857143">
Human judgements for acceptability for each of the
1152 sentences in our corpus were obtained using
the WebExp package (Keller et al., 2008 to appear).2
We investigated acceptability because it is a measure
which reflects both ease of comprehension and sur-
face well-formedness.
The propositional content of 144 sentences was
presented in 8 formulations. Eight participant
groups (A–H) consisting of 6 people each were pre-
sented with exactly one of the eight formulations
of each of 144 different sentences, as per a Latin
square design. Thus, while each participant read
an equal number of sentences in each formulation
type, they never read more than one formulation of
the same propositional content. Each group saw 18
original and 126 reformulated sentences in total, 48
from each genre. This experimental design allows
all statistical comparisons between the eight types
of causal formulations to be within-participants.
Acceptability judgements were elicited on the
sentences without presenting the preceding context
</bodyText>
<footnote confidence="0.942137285714286">
1PubMed URL: http://www.ncbi.nlm.nih.gov/pubmed/
The British National Corpus, version 3 (BNC XML Edition).
2007. Distributed by Oxford University Computing Services on
behalf of the BNC Consortium. http://www.natcorp.ox.ac.uk
2Note that the reformulations are, strictly speaking, gram-
matical according to the authors’ judgement. We are testing
violations of acceptability, rather than grammaticality per se.
</footnote>
<page confidence="0.986727">
1005
</page>
<bodyText confidence="0.999977454545455">
from the original text. The participants were Univer-
sity of Cambridge students (all native English speak-
ers with different academic backgrounds). Post ex-
perimentally we divided participants in two groups
based on having a Science or a non-Science back-
ground3. Rather than giving participants a fixed
scale (e.g. 1–7), we used the magnitude estimation
paradigm, which is more suitable to capture robust
or subtle differences between the relative strength of
acceptability or grammaticality violations (see Bard
et al. (1996); Cowart (1997); Keller (2000)).
</bodyText>
<subsectionHeader confidence="0.998236">
3.3 Magnitude estimation
</subsectionHeader>
<bodyText confidence="0.999929866666667">
Participants were asked to score how acceptable a
modulus sentence was, using any positive number.
They were then asked to score other sentences rel-
ative to this modulus, using any positive number,
even decimals, so that higher scores were assigned
to more acceptable sentences. The advantage of
Magnitude estimation is that the researcher does
not make any assumptions about the number of lin-
guistic distinctions allowed. Each subject makes as
many distinctions as they feel comfortable. Scores
were normalised to allow comparison across partic-
ipants, following standard practice in the literature
by using the z-score: For each participant, each sen-
tence score was normalised so that the mean score is
0 and the standard deviation is 1:
</bodyText>
<equation confidence="0.696348333333333">
xih − µh
zih �
Qh
</equation>
<bodyText confidence="0.9999442">
where zih is participant h’s z-score for the sentence
i when participant h gave a magnitude estimation
score of xih to that sentence. µh is the mean and
Qh the standard deviation of the set of magnitude
estimation scores for user h.
</bodyText>
<sectionHeader confidence="0.83781" genericHeader="method">
3.4 Results
</sectionHeader>
<bodyText confidence="0.952741">
42 out of 48 participants (19 science students and
23 non-science students) completed the experiment,
giving us 3–6 ratings for each of the 1152 sentences.
Figure 1 shows the average z-scores with standard
3Participants provided subject of study prior to participa-
tion in the experiment. Our classification of Science con-
</bodyText>
<affiliation confidence="0.8715435">
sists of Life Sciences(Genetics/Biology/etc), Chemistry, Envi-
ronmental Science, Engineering, Geology, Physics, Medicine,
Pharmacology, Veterinary Science and Zoology. Non-Science
consists of Archaeology, Business, Classics, Education, Liter-
ature&amp;Languages, International Relations, Linguistics, Maths,
Music, Politics and Theology.
</affiliation>
<figure confidence="0.995484">
1
0.8
0.6
0.4
0.2
0
-0.2
-0.4
Original Reformulated All
</figure>
<figureCaption confidence="0.9939795">
Figure 1: Preferences by Field of Study – Science or
Non-Science.
</figureCaption>
<bodyText confidence="0.99970734375">
error bars for Science and non-Science students for
each of the three genres. The first six columns
show the scores for only the 144 Original Sentences.
Note that science students find PubMed sentences
most acceptable (significantly more than BNC Nat-
ural Science; t-test, p &lt; .005), while among non-
science students there is a numerical tendency to find
the world news sentences most acceptable. Both cat-
egories of participants disprefer sentences from the
popular science genre. Columns 7–12 show the av-
erage z-scores for the 1008 reformulated sentences.
Let us note that these are significantly lower than for
the originals (t-test, p &lt; .001).
Some of these results are as expected. With regard
to genre preferences, scientists might find the style
of technical writing acceptable because of familiar-
ity with that style of writing. Second, with regard
to the average score for original and reformulated
sentences, some reformulations just don’t work for
a given propositional content. This pulls the aver-
age for reformulated sentences down. However, on
average 2 out of 7 reformulations score quite high.
It is interesting that the popular science genre is
least preferred by both groups. This suggests that
reformulating technical writing for lay readers is not
a trivial endeavour, even for journalists.
Now consider Figure 2, which shows the aver-
age z-scores for only PubMed sentences for science
and non-science students as a function of sentence
type. For non-science students reading PubMed sen-
tences, three formulations are strongly dispreferred
– “a is caused by b”, “because b, a” and “b is the
</bodyText>
<figure confidence="0.9885806">
Non-S Science
Non-S Science
BNC-World
BNC-NatSci
Pubmed
Non-S Science
1006
1.2
1
0.8
0.6
0.4
0.2
0
-0.2
</figure>
<figureCaption confidence="0.999819">
Figure 2: PubMed type preferences
</figureCaption>
<bodyText confidence="0.998314285714286">
cause of a”. The last two are significantly lower than
“a because b”, “a because of b” and “because of b, a”
(t-test, .005 &lt; p &lt; .01). On the contrary, there are
no strong preferences among the science students
and all the error bars overlap. Let us now look at
some specific differences between science and non-
science students:
</bodyText>
<listItem confidence="0.875845333333333">
1. Science students prefer sentences in the passive
voice, while these are strongly dispreferred by non-
science students. While active voice is the canon-
ical form in English, much of science is written in
the passive by convention. This difference can thus
be explained by different levels of exposure.
2. Non-science students disprefer the use of “cause”
as a noun while science students don’t (columns 3–
4 and 11–12).
3. Non-science students prefer “because of b, a” to
“because b, a” while science students show the op-
posite preference.
</listItem>
<bodyText confidence="0.775148545454545">
The lack of strongly dispreferred formulations in
the Science students is most likely due to two fac-
tors: (a) the group’s familiarity with this genre and
(b) their expert knowledge compensates for accept-
ability even for relatively odd formulations. In the
absence of exposure and background knowledge, the
non-Science students display clear preferences.4
Note that these preferences are not surprising.
The preference for canonical constructs such as ac-
tive voice and conjunction in infix position are well
documented. Our claim however, is that blindly
</bodyText>
<footnote confidence="0.847614333333333">
4While we only show the averages for all sentences, the dis-
tributions for original and reformulated sentences look remark-
ably similar.
</footnote>
<table confidence="0.999865571428571">
Selection Method Av. z
Always select original sentence .61
Replace cause-p, b-causeof-a and causeof-ab .48
with cause-a &amp; bec-ba with a-bec-b
Replace cause-p with cause-a, b-causeof-a .47
with causeof-ab &amp; bec-ba with a-bec-b
Always select most preferred type (a-becof-b) .27
</table>
<tableCaption confidence="0.9971195">
Table 1: Selecting a formulation of PubMed sentences for
non-science students using their global preferences.
</tableCaption>
<bodyText confidence="0.9998263">
rewriting all instances of globally dispreferred con-
structs with globally preferred constructs is counter-
productive because not all formulations are accept-
able for any given propositional content. This claim
is easily verified. Table 1 shows the average z-scores
of non-science students when one formulation of
each of the PubMed sentences is selected based only
on the global preferences in Figure 2. Such rewriting
invariably makes matters worse. In the next section
we present a more intelligent approach.
</bodyText>
<sectionHeader confidence="0.998185" genericHeader="method">
4 Machine learning experiment
</sectionHeader>
<bodyText confidence="0.999201772727273">
The first question we address is: for a given propo-
sitional content, which formulations are acceptable
and which are not? This is a useful question for mul-
tiple reasons. In this paper, our interest stems from
our desire to selectively rewrite causation based on
the properties of the sentence as well as global pref-
erences of categories of users. More generally, this
information is important for summarisation tasks,
where sentences might appear in different contexts
and different information orderings might be de-
sirable for reasons of coherence. Knowing which
formulations are acceptable in isolation for a given
propositional content is thus important.
Since Magnitude estimation scores are freescale,
we first need to determine how high a score needs to
be for that formulation to be considered acceptable.
Our solution is to (a) treat the original formulation
as acceptable and (b) treat any reformulations with
a higher average z-score than the original as also ac-
ceptable. We find that roughly 3 formulations (the
original and another two) out of 8 are acceptable on
average. Our data is summarised below:
</bodyText>
<listItem confidence="0.9472275">
• 1152 Sentences in total (144 originals, 1008 refor-
mulations)
</listItem>
<figureCaption confidence="0.362694">
– 361 labelled as acceptable (31%; 144 origi-
nals, 217 reformulations)
</figureCaption>
<figure confidence="0.829881916666667">
a-bec-b
a-becof-b
b-causeof-a
causeof-ab
bec-ba
becof-ba
cause-a
cause-p
Science Not-Science
1007
– 791 labelled as unacceptable (69%; 791 refor-
mulations)
</figure>
<subsectionHeader confidence="0.927102">
4.1 Features
</subsectionHeader>
<bodyText confidence="0.99999625">
We use shallow features derived from the sentence,
as well as the textual genre. Sentences were parsed
using the RASP parser (Briscoe and Carroll, 2002).
The features we extract are as follows:
</bodyText>
<listItem confidence="0.99636575">
1. Type (8 values: cause a, cause p, a bec b, bec ba,
a becof b, becof ba, a causeof b, causeof ba)
2. Genre (3 values: pubmed, bnc-world, bnc-natsci)
3. Complexity: As an indication of the complexity of
the propositional content, we use the following:
(a) Length Features
• length (in words) of the sentence and each
clause
• length (as proportion of total length) of
each clause
(b) Whether the causative is embedded in a rela-
tive clause or other construct
(c) The presence or absence of copula in each
clause (e.g., “because there is...”)
(d) Whether the causation is quantified (e.g., “a
major cause of...”)
</listItem>
<bodyText confidence="0.99990428">
The only feature that varies between the eight for-
mulations of the same sentence is the “type” feature;
the “genre” and “complexity” features are constant
across reformulations. The reason for using 3(c–d)
as features is that expressions such as “because there
is” might be better formulated as “because of” and
that it is hard to find an exact reformulation when
quantifiers are present (e.g., “a major cause of” is
not equivalent to “often because of”).
Machine performance on this task is not very
good (First Run, Table 2). The problem is that some
propositional content is harder to formulate than oth-
ers. Therefore good formulations of some proposi-
tional content might have much lower scores than
even mediocre formulations of other propositional
content. This makes it hard to learn a function that
distinguishes good from bad formulations for any
particular propositional content. To overcome this,
we run the classifier twice. Given 8 formulations
of 144 sentences Si=1..144,j=1..8, the first run gives
us 1152 probabilities pweka1(Sij) for the acceptabil-
ity of each sentence, independent of propositional
content (these are test-set probabilities using 10-fold
cross-validation). We then run the machine learner
again, with this new feature relative:
</bodyText>
<table confidence="0.9988102">
Classifier Accuracy Kappa
Baseline .69 0
First Run .72 .23
Second Run .85 .65
Only PubMed .89 .73
</table>
<tableCaption confidence="0.983799">
Table 2: Accuracy and Agreement of classifier relative to
human judgement.
</tableCaption>
<table confidence="0.9996974">
Genre Class P R F
All Genres Good .72 .78 .75
Bad .91 .89 .90
Only PubMed Good .89 .89 .89
Bad .89 .97 .92
</table>
<tableCaption confidence="0.939483">
Table 3: Precision, Recall and F-measure of classifier
(second run) relative to human judgement.
</tableCaption>
<listItem confidence="0.749884333333333">
• The ratio of the test-set probability (from the first
run) to the highest of the 8 test-set probabilities for
the different formulations of that sentence:
</listItem>
<equation confidence="0.995893333333333">
pweka1(Si=a,j=b)
relativei=a,j=b =
maxi=a,j=1..8(pweka1(Si=a,j))
</equation>
<bodyText confidence="0.9999762">
Thus probabilities for acceptability are nor-
malised such that the best score for a given proposi-
tional content is 1 and the other 7 formulations score
less than or equal to 1. The second classifier uses
these relative probabilities as an extra feature.
</bodyText>
<subsectionHeader confidence="0.600721">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.999531857142857">
Our results are summarised in Table 2 (accu-
racy and agreement) and Table 3 (f-measure).
We experimented with the Weka toolkit (Wit-
ten and Frank, 2000) and report results using
“weka.classifiers.trees.J48 -C 0.3 -M 3” and 10-fold
cross-validation for both runs.5
Table 2 shows that the first run performs at around
baseline levels, but the second run performs signifi-
cantly better (using z-test, p=0.01 on % Accuracy),
with acceptable agreement of K = 0.656. This in-
creases to 89% (K = .73) when we only consider
technical writing (PubMed genre). Table 3 shows
that precision, recall and f-measure are also around
.90 for PubMed sentences.
</bodyText>
<footnote confidence="0.8405085">
5J48 outperformed other Weka classifiers for this task.
6Following Carletta (1996), we measure agreement in κ,
which follows the formula K = P(a)−P(E) where P(A) is ob-
1−P(E)
</footnote>
<bodyText confidence="0.7269025">
served, and P(E) expected agreement. κ ranges between -1 and
1. κ=0 means agreement is only as expected by chance. Gener-
ally, κ of 0.8 are considered stable, and κ of 0.69 as marginally
stable, according to the strictest scheme applied in the field.
</bodyText>
<page confidence="0.854139">
1008
</page>
<table confidence="0.997135833333333">
Left out feature First Run Second Run
Acc K Acc K
Length .71 -.01 .78 .33
Quantified .71 .20 .75 .36
Embedded .69 .15 .78 .37
Copula Present .72 .20 .79 .44
</table>
<tableCaption confidence="0.997927">
Table 4: Accuracy and Kappa of classifier when com-
plexity features are left out.
</tableCaption>
<bodyText confidence="0.9042175">
All our context features proved useful for the clas-
sification task, with the length features being the
most useful. Table 4 shows the performance of the
classifier when we leave out individual features.
It thus appears that we can determine the accept-
able formulations of a sentence with high accuracy.
The next question is how this information might be
used to benefit a text regeneration system. To evalu-
ate this, we combined our predictions with the user
preferences visible in figure 2 as follows:
• We calculate a prior priorj for each formulation of
type j using the z-score distribution for non-science
students in Figure 2.
• We calculate priorj=b.pweka2(Si=a,j=b) for each
formulation Si=a,j=b of sentence a and type b,
where pweka2(Si=a,j=b) is the probability returned
by the classifier (second run) for formulation b of
sentence a.
</bodyText>
<listItem confidence="0.932414">
• Selectively Reformulate: We reformulate only
</listItem>
<bodyText confidence="0.94255095">
the four dispreferred constructs (cause p, bec ba,
causeof ab, b causeof a) using the formulation for
which the prior times the classifier probability
is the maximum; i.e, for sentence a, we select
maxi=a,j=1..8(prior j.pweka2(Si=a,j)).
Table 5 shows the impact this reformulation has
on the acceptability of the sentences. Our algorithm
selects one formulation of each PubMed sentence
based on our prior knowledge of the preferences of
non-science students, and the Weka-probabilities for
acceptability of each formulation of a sentence. Our
selective reformulation increases the average z-score
from .613 to .713. This is now comparable with the
acceptability ratings of non-scientists for sentences
from the world news genre. Note that reformulation
only using priors resulted in worse results (Table 1).
However there remains scope for improvement. If
we had an oracle that selected the best formulation
of each sentence (as scored by non-scientists), this
would result in an average score of 1.04.
</bodyText>
<table confidence="0.998277666666667">
Genre Version z-score
PubMed Randomly Selected –.17
PubMed Original Sentences .61
PubMed Selectively Reformulate .71
PubMed Selected by Oracle 1.04
BNC World Original Sentences .70
</table>
<tableCaption confidence="0.9975656">
Table 5: Average z-scores for non-science students. Se-
lective reformulation increases the acceptability scores of
sentences drawn from technical writing to levels com-
parable to acceptability scores of sentences drawn from
news reports on world news (their most preferred genre).
</tableCaption>
<sectionHeader confidence="0.986235" genericHeader="conclusions">
5 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999987171428571">
In this investigation we report that science and
non-science university students have different global
preferences regarding which formulations of causa-
tion are acceptable. Using surface features that re-
flect propositional complexity, a machine classifier
can learn which of 8 formulations of a discourse
relation are acceptable (with Accuracy = .89 and
Kappa = .73 for sentences from the PubMed genre).
Using the global preferences of non-science students
as priors, and combining these with machine clas-
sifier predictions of acceptability, we have demon-
strated that it is possible to selectively rewrite sen-
tences from PubMed in a manner that is personalised
for non-science students. This boosts the average z-
score for acceptability from .613 to .713 on PubMed
sentences, a level similar to scores of non-scientists
for sentences from their most preferred World News
genre. We have thus shown that there is potential for
reformulating technical writing for a lay audience –
differences in preferences for expressing a discourse
relation do exist between lay and expert audiences,
and these can be learnt.
While in this paper we focus on the discourse re-
lation of causation, other discourse relations com-
monly used in scientific writing can also be realised
using markers with different syntactic properties; for
instance, contrast can be expressed using markers
such as “while”, “unlike”, “but”, “compared to”, “in
contrast to” or “the difference between”. As part of
our wider goals, we are in the process of extending
the number of discourse relations considered. We
are also in the process of developing a framework
within which we can use transfer rules and a bi-
directional grammar to automate such complex syn-
tactic reformulation.
</bodyText>
<page confidence="0.995084">
1009
</page>
<sectionHeader confidence="0.997364" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.994211714285714">
This work was supported by the Economic and So-
cial Research Council (Grant Number RES-000-22-
3272). We would also like to thank Donia Scott,
Simone Teufel and Ann Copestake for many dis-
cussions that influenced the scope of this work, and
John Williams and Theodora Alexopoulou for their
suggestions on experimental design.
</bodyText>
<sectionHeader confidence="0.998751" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999601021052632">
R.C. Anderson and A. Davison. 1988. Conceptual and
empirical bases of readibility formulas. In Alice Davi-
son and G. M. Green, editors, Linguistic Complexity
and Text Comprehension: Readability Issues Recon-
sidered. Lawrence Erlbaum Associates, Hillsdale, NJ.
E.G. Bard, D. Robertson, and A. Sorace. 1996. Magni-
tude estimation for linguistic acceptability. Language,
72(1):32–68.
R. Barzilay and L. Lee. 2003. Learning to paraphrase:
An unsupervised approach using multiple-sequence
alignment. In HLT-NAACL 2003, pp 16–23.
I.L. Beck, M.G. McKeown, G.M. Sinatra, and J.A. Lox-
terman. 1991. Revising social studies text from a text-
processing perspective: Evidence of improved com-
prehensibility. Reading Research Quarterly, pp 251–
276.
E.J. Briscoe and J. Carroll. 2002. Robust accurate sta-
tistical annotation of general text. In Proc. of the 3rd
International Conference on Language Resources and
Evaluation, pp 1499–1504, Gran Canaria.
J. Carletta. 1996. Assessing agreement on classification
tasks: The kappa statistic. Computational Linguistics,
22(2):249–254.
J. Carroll, G. Minnen, Y. Canning, S. Devlin, and J. Tait.
1998. Practical simplification of English newspaper
text to assist aphasic readers. In Proc. of AAAI98
Workshop on Integrating Artificial Intelligence and As-
sistive Technology, pp 7–10, Madison, WI.
W. Cowart. 1997. Experimental Syntax: applying objec-
tive methods to sentence judgement. Thousand Oaks,
CA: Sage Publications.
J. Hirschberg and D. Litman. 1993. Empirical studies
on the disambiguation of cue phrases. Computational
Linguistics, 19(3):501–530.
B. Hutchinson. 2005. Modelling the substitutability
of discourse connectives. In ACL ’05: Proc. of the
43rd Annual Meeting on Association for Computa-
tional Linguistics, pp 149–156, Morristown, NJ, USA.
Association for Computational Linguistics.
A. Ibrahim, B. Katz, and J. Lin. 2003. Extracting para-
phrases from aligned corpora. In Proc. of The Second
International Workshop on Paraphrasing.
N. Kaji, D. Kawahara, S. Kurohash, and S. Sato. 2002.
Verb paraphrase based on case frame alignment. In
Proc. of the 40th Annual Meeting of the Association
for Computational Linguistics (ACL’02), pp 215–222,
Philadelphia, USA.
F. Keller, S. Gunasekharan, N. Mayo, and M. Corley.
2008, to appear. Timing accuracy of web experiments:
A case study using the webexp software package. Be-
havior Research Methods.
F. Keller. 2000. Gradience in Grammar: Experimental
and Computational Aspects of Degrees of Grammati-
cality. Ph.D. thesis, University of Edinburgh.
A. Knott and R. Dale. 1994. Using linguistic phenom-
ena to motivate a set of coherence relations. Discourse
Processes, 18(1):35–62.
A. Knott. 1996. A Data-Driven Methodology for Moti-
vating a Set of Discourse Relations. Ph.D. thesis, Ph.
D. thesis, Centre for Cognitive Science, University of
Edinburgh, Edinburgh, UK.
T. Linderholm, M.G. Everson, P. van den Broek,
M. Mischinski, A. Crittenden, and J. Samuels. 2000.
Effects of Causal Text Revisions on More-and Less-
Skilled Readers’ Comprehension of Easy and Difficult
Texts. Cognition and Instruction, 18(4):525–556.
W. C. Mann and S. A. Thompson. 1988. Rhetorical
Structure Theory: Towards a functional theory of text
organization. Text, 8(3):243–281.
L. G. M. Noordman and W. Vonk. 1992. Reader’s knowl-
edge and the control of inferences in reading. Lan-
guage and Cognitive Processes, 7:373–391.
R. Power, D. Scott, and N. Bouayad-Agha. 2003. Gen-
erating texts with style. Proc. of the 4 thInternational
Conference on Intelligent Texts Processing and Com-
putational Linguistics.
A. Siddharthan. 2006. Syntactic simplification and text
cohesion. Research on Language and Computation,
4(1):77–109.
B. Webber, A. Joshi, E. Miltsakaki, R. Prasad, N. Di-
nesh, A. Lee, and K. Forbes. 2005. A Short Intro-
duction to the Penn Discourse TreeBank. Treebanking
for discourse and speech: proceedings of the NODAL-
IDA 2005 special session on Treebanksfor spoken lan-
guage and discourse.
S. Williams and E. Reiter. 2008. Generating basic skills
reports for low-skilled readers. Natural Language En-
gineering, 14(04):495–525.
I. Witten and E. Frank. 2000. Data Mining: Practical
Machine Learning Tools and Techniques with Java Im-
plementations. Morgan Kaufmann.
P. Wolff, B. Klettke, T. Ventura, and G. Song. 2005.
Expressing causation in English and other languages.
Categorization inside and outside the laboratory: Es-
says in honor ofDouglas L. Medin, pp 29–48.
</reference>
<page confidence="0.990107">
1010
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.949638">
<title confidence="0.999804">Reformulating Discourse Connectives for Non-Expert Readers</title>
<author confidence="0.997775">Advaith Siddharthan Napoleon Katsos</author>
<affiliation confidence="0.999816">Department of Computing Science Research Centre for English and Applied Linguistics University of Aberdeen University of Cambridge</affiliation>
<email confidence="0.959475">advaith@abdn.ac.uknk248@cam.ac.uk</email>
<abstract confidence="0.999385923076923">In this paper we report a behavioural experiment documenting that different lexicosyntactic formulations of the discourse relaof deemed more or less acceptable by different categories of readers. We further report promising results for automatically selecting the formulation that is most appropriate for a given category of reader using supervised learning. This investigation is embedded within a longer term research agenda aimed at summarising scientific writing for lay readers using appropriate paraphrasing.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R C Anderson</author>
<author>A Davison</author>
</authors>
<title>Conceptual and empirical bases of readibility formulas.</title>
<date>1988</date>
<booktitle>In Alice Davison</booktitle>
<editor>and G. M. Green, editors,</editor>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="8213" citStr="Anderson and Davison (1988)" startWordPosition="1278" endWordPosition="1281">licitous expression of causation for a given propositional content. 2.2 Discourse connectives and comprehension Previous work has shown that when texts have been manually rewritten to make discourse relations such as causation explicit, reading comprehension is significantly improved in middle/high school students (Beck et al., 1991). Further, connectives that permit pre-posed adverbial clauses have been found to be difficult for third to fifth grade readers, even when the order of mention coincides with the causal (and temporal) order; for instance, 3b. is more accessible than 3a. (e.g. from Anderson and Davison (1988)). (3) a. Because Mexico allowed slavery, many Americans and their slaves moved to Mexico during that time. b. Many Americans and their slaves moved to Mexico during that time, because Mexico allowed slavery. 1003 Such studies show that comprehension can be improved by reformulating text; e.g., making causal relations explicit had a facilitatory effect for readers with low reading skills (Linderholm et al., 2000; Beck et al., 1991) and for readers with low levels of domain expertise (Noordman and Vonk, 1992). Further, specific information orderings were found to be facilitatory by Anderson and</context>
</contexts>
<marker>Anderson, Davison, 1988</marker>
<rawString>R.C. Anderson and A. Davison. 1988. Conceptual and empirical bases of readibility formulas. In Alice Davison and G. M. Green, editors, Linguistic Complexity and Text Comprehension: Readability Issues Reconsidered. Lawrence Erlbaum Associates, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E G Bard</author>
<author>D Robertson</author>
<author>A Sorace</author>
</authors>
<title>Magnitude estimation for linguistic acceptability.</title>
<date>1996</date>
<journal>Language,</journal>
<volume>72</volume>
<issue>1</issue>
<contexts>
<context position="17916" citStr="Bard et al. (1996)" startWordPosition="2788" endWordPosition="2791">judgement. We are testing violations of acceptability, rather than grammaticality per se. 1005 from the original text. The participants were University of Cambridge students (all native English speakers with different academic backgrounds). Post experimentally we divided participants in two groups based on having a Science or a non-Science background3. Rather than giving participants a fixed scale (e.g. 1–7), we used the magnitude estimation paradigm, which is more suitable to capture robust or subtle differences between the relative strength of acceptability or grammaticality violations (see Bard et al. (1996); Cowart (1997); Keller (2000)). 3.3 Magnitude estimation Participants were asked to score how acceptable a modulus sentence was, using any positive number. They were then asked to score other sentences relative to this modulus, using any positive number, even decimals, so that higher scores were assigned to more acceptable sentences. The advantage of Magnitude estimation is that the researcher does not make any assumptions about the number of linguistic distinctions allowed. Each subject makes as many distinctions as they feel comfortable. Scores were normalised to allow comparison across par</context>
</contexts>
<marker>Bard, Robertson, Sorace, 1996</marker>
<rawString>E.G. Bard, D. Robertson, and A. Sorace. 1996. Magnitude estimation for linguistic acceptability. Language, 72(1):32–68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>L Lee</author>
</authors>
<title>Learning to paraphrase: An unsupervised approach using multiple-sequence alignment.</title>
<date>2003</date>
<booktitle>In HLT-NAACL</booktitle>
<pages>16--23</pages>
<contexts>
<context position="10129" citStr="Barzilay and Lee, 2003" startWordPosition="1564" endWordPosition="1567">on (replacing difficult words with easier ones), but more recently, there has been work on syntactic simplification and, in particular, the way syntactic rewrites interact with discourse structure and text cohesion (Siddharthan, 2006). Elsewhere, there has been renewed interest in paraphrasing, including the replacement of words (especially verbs) with their dictionary definitions (Kaji et al., 2002) and the replacement of idiomatic or otherwise troublesome expressions with simpler ones. The current research emphasis is on automatically learning paraphrases from comparable or aligned corpora (Barzilay and Lee, 2003; Ibrahim et al., 2003). The text simplification and paraphrasing literature does not address paraphrasing that requires syntactic alterations such as those in example 1 or the question of appropriateness of different formulations of a discourse relation. Some natural language generation systems incorporate results from psycholinguistic studies to make principled choices between alternative formulations. For example, SkillSum (Williams and Reiter, 2008) and ICONOCLAST (Power et al., 2003) are two contemporary generation systems that allow for specifying aspects of style such as choice of disco</context>
</contexts>
<marker>Barzilay, Lee, 2003</marker>
<rawString>R. Barzilay and L. Lee. 2003. Learning to paraphrase: An unsupervised approach using multiple-sequence alignment. In HLT-NAACL 2003, pp 16–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I L Beck</author>
<author>M G McKeown</author>
<author>G M Sinatra</author>
<author>J A Loxterman</author>
</authors>
<title>Revising social studies text from a textprocessing perspective: Evidence of improved comprehensibility. Reading Research Quarterly,</title>
<date>1991</date>
<pages>251--276</pages>
<contexts>
<context position="7921" citStr="Beck et al., 1991" startWordPosition="1232" endWordPosition="1235"> “because of”, “because”, and “cause” as a verb and a noun. These express the components of meaning (a–c) using different syntactic structures. By considering only these four lexically similar constructs, we can focus on the role of the lexis and of syntax in determining the most felicitous expression of causation for a given propositional content. 2.2 Discourse connectives and comprehension Previous work has shown that when texts have been manually rewritten to make discourse relations such as causation explicit, reading comprehension is significantly improved in middle/high school students (Beck et al., 1991). Further, connectives that permit pre-posed adverbial clauses have been found to be difficult for third to fifth grade readers, even when the order of mention coincides with the causal (and temporal) order; for instance, 3b. is more accessible than 3a. (e.g. from Anderson and Davison (1988)). (3) a. Because Mexico allowed slavery, many Americans and their slaves moved to Mexico during that time. b. Many Americans and their slaves moved to Mexico during that time, because Mexico allowed slavery. 1003 Such studies show that comprehension can be improved by reformulating text; e.g., making causa</context>
</contexts>
<marker>Beck, McKeown, Sinatra, Loxterman, 1991</marker>
<rawString>I.L. Beck, M.G. McKeown, G.M. Sinatra, and J.A. Loxterman. 1991. Revising social studies text from a textprocessing perspective: Evidence of improved comprehensibility. Reading Research Quarterly, pp 251– 276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E J Briscoe</author>
<author>J Carroll</author>
</authors>
<title>Robust accurate statistical annotation of general text.</title>
<date>2002</date>
<booktitle>In Proc. of the 3rd International Conference on Language Resources and Evaluation,</booktitle>
<pages>1499--1504</pages>
<institution>Gran Canaria.</institution>
<contexts>
<context position="25545" citStr="Briscoe and Carroll, 2002" startWordPosition="3984" endWordPosition="3987">e than the original as also acceptable. We find that roughly 3 formulations (the original and another two) out of 8 are acceptable on average. Our data is summarised below: • 1152 Sentences in total (144 originals, 1008 reformulations) – 361 labelled as acceptable (31%; 144 originals, 217 reformulations) a-bec-b a-becof-b b-causeof-a causeof-ab bec-ba becof-ba cause-a cause-p Science Not-Science 1007 – 791 labelled as unacceptable (69%; 791 reformulations) 4.1 Features We use shallow features derived from the sentence, as well as the textual genre. Sentences were parsed using the RASP parser (Briscoe and Carroll, 2002). The features we extract are as follows: 1. Type (8 values: cause a, cause p, a bec b, bec ba, a becof b, becof ba, a causeof b, causeof ba) 2. Genre (3 values: pubmed, bnc-world, bnc-natsci) 3. Complexity: As an indication of the complexity of the propositional content, we use the following: (a) Length Features • length (in words) of the sentence and each clause • length (as proportion of total length) of each clause (b) Whether the causative is embedded in a relative clause or other construct (c) The presence or absence of copula in each clause (e.g., “because there is...”) (d) Whether the </context>
</contexts>
<marker>Briscoe, Carroll, 2002</marker>
<rawString>E.J. Briscoe and J. Carroll. 2002. Robust accurate statistical annotation of general text. In Proc. of the 3rd International Conference on Language Resources and Evaluation, pp 1499–1504, Gran Canaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carletta</author>
</authors>
<title>Assessing agreement on classification tasks: The kappa statistic.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="29045" citStr="Carletta (1996)" startWordPosition="4555" endWordPosition="4556">th the Weka toolkit (Witten and Frank, 2000) and report results using “weka.classifiers.trees.J48 -C 0.3 -M 3” and 10-fold cross-validation for both runs.5 Table 2 shows that the first run performs at around baseline levels, but the second run performs significantly better (using z-test, p=0.01 on % Accuracy), with acceptable agreement of K = 0.656. This increases to 89% (K = .73) when we only consider technical writing (PubMed genre). Table 3 shows that precision, recall and f-measure are also around .90 for PubMed sentences. 5J48 outperformed other Weka classifiers for this task. 6Following Carletta (1996), we measure agreement in κ, which follows the formula K = P(a)−P(E) where P(A) is ob1−P(E) served, and P(E) expected agreement. κ ranges between -1 and 1. κ=0 means agreement is only as expected by chance. Generally, κ of 0.8 are considered stable, and κ of 0.69 as marginally stable, according to the strictest scheme applied in the field. 1008 Left out feature First Run Second Run Acc K Acc K Length .71 -.01 .78 .33 Quantified .71 .20 .75 .36 Embedded .69 .15 .78 .37 Copula Present .72 .20 .79 .44 Table 4: Accuracy and Kappa of classifier when complexity features are left out. All our context</context>
</contexts>
<marker>Carletta, 1996</marker>
<rawString>J. Carletta. 1996. Assessing agreement on classification tasks: The kappa statistic. Computational Linguistics, 22(2):249–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carroll</author>
<author>G Minnen</author>
<author>Y Canning</author>
<author>S Devlin</author>
<author>J Tait</author>
</authors>
<title>Practical simplification of English newspaper text to assist aphasic readers.</title>
<date>1998</date>
<booktitle>In Proc. of AAAI98 Workshop on Integrating Artificial Intelligence and Assistive Technology,</booktitle>
<pages>7--10</pages>
<location>Madison, WI.</location>
<contexts>
<context position="9401" citStr="Carroll et al., 1998" startWordPosition="1464" endWordPosition="1467">o be facilitatory by Anderson and Davison (1988). However, it has not been investigated whether readers with different levels of domain expertise are facilitated by any specific lexico-syntactic formulation among the many possible explicit realisations of a relation. This is a novel question in the linguistics literature, and we address it in section 3. 2.3 Connectives and automatic (re)generation Much of the work regarding (re)generation of text based on discourse connectives aims to simplify text in certain ways, to make it more accessible to particular classes of readers. The PSET project (Carroll et al., 1998) considered simplifying news reports for aphasics. The PSET project focused mainly on lexical simplification (replacing difficult words with easier ones), but more recently, there has been work on syntactic simplification and, in particular, the way syntactic rewrites interact with discourse structure and text cohesion (Siddharthan, 2006). Elsewhere, there has been renewed interest in paraphrasing, including the replacement of words (especially verbs) with their dictionary definitions (Kaji et al., 2002) and the replacement of idiomatic or otherwise troublesome expressions with simpler ones. T</context>
</contexts>
<marker>Carroll, Minnen, Canning, Devlin, Tait, 1998</marker>
<rawString>J. Carroll, G. Minnen, Y. Canning, S. Devlin, and J. Tait. 1998. Practical simplification of English newspaper text to assist aphasic readers. In Proc. of AAAI98 Workshop on Integrating Artificial Intelligence and Assistive Technology, pp 7–10, Madison, WI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Cowart</author>
</authors>
<title>Experimental Syntax: applying objective methods to sentence judgement. Thousand Oaks,</title>
<date>1997</date>
<publisher>Sage Publications.</publisher>
<location>CA:</location>
<contexts>
<context position="17931" citStr="Cowart (1997)" startWordPosition="2792" endWordPosition="2793">sting violations of acceptability, rather than grammaticality per se. 1005 from the original text. The participants were University of Cambridge students (all native English speakers with different academic backgrounds). Post experimentally we divided participants in two groups based on having a Science or a non-Science background3. Rather than giving participants a fixed scale (e.g. 1–7), we used the magnitude estimation paradigm, which is more suitable to capture robust or subtle differences between the relative strength of acceptability or grammaticality violations (see Bard et al. (1996); Cowart (1997); Keller (2000)). 3.3 Magnitude estimation Participants were asked to score how acceptable a modulus sentence was, using any positive number. They were then asked to score other sentences relative to this modulus, using any positive number, even decimals, so that higher scores were assigned to more acceptable sentences. The advantage of Magnitude estimation is that the researcher does not make any assumptions about the number of linguistic distinctions allowed. Each subject makes as many distinctions as they feel comfortable. Scores were normalised to allow comparison across participants, foll</context>
</contexts>
<marker>Cowart, 1997</marker>
<rawString>W. Cowart. 1997. Experimental Syntax: applying objective methods to sentence judgement. Thousand Oaks, CA: Sage Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hirschberg</author>
<author>D Litman</author>
</authors>
<title>Empirical studies on the disambiguation of cue phrases.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>3</issue>
<contexts>
<context position="11772" citStr="Hirschberg and Litman (1993)" startWordPosition="1819" endWordPosition="1822">rpora that mark up discourse relations – the RST Discourse Treebank based on Rhetorical Structure Theory (Mann and Thompson, 1988), and the Penn Discourse Treebank (Webber et al., 2005). Neither is suitable for studies on the felicity of specific formulations of a discourse relation. As part of this research, we have created a corpus of 144 real text examples, reformulated in 8 ways, giving 1152 sentences in total. There have been numerous corpus studies of discourse connectives, such as studies on the discourserole disambiguation of individual cue-phrases in spoken and written corpora (e.g., Hirschberg and Litman (1993)), the substitutability of discourse connectives (e.g., Hutchinson (2005)), and indeed corpus studies as a means of informing the choice of discourse relations to consider in a theory (e.g., Knott and Dale (1994); Knott (1996)). A distinguishing feature of our approach relative to previous ones is an in-depth study of syntactic variations; in contrast, for example, Knott’s taxonomy of discourse relations is based on the use of a substitution text that precludes variants of the same relation having different syntax. 3 Linguistic acceptability study 3.1 Dataset creation We have constructed a dat</context>
</contexts>
<marker>Hirschberg, Litman, 1993</marker>
<rawString>J. Hirschberg and D. Litman. 1993. Empirical studies on the disambiguation of cue phrases. Computational Linguistics, 19(3):501–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Hutchinson</author>
</authors>
<title>Modelling the substitutability of discourse connectives.</title>
<date>2005</date>
<booktitle>In ACL ’05: Proc. of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>149--156</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="11845" citStr="Hutchinson (2005)" startWordPosition="1829" endWordPosition="1830">cal Structure Theory (Mann and Thompson, 1988), and the Penn Discourse Treebank (Webber et al., 2005). Neither is suitable for studies on the felicity of specific formulations of a discourse relation. As part of this research, we have created a corpus of 144 real text examples, reformulated in 8 ways, giving 1152 sentences in total. There have been numerous corpus studies of discourse connectives, such as studies on the discourserole disambiguation of individual cue-phrases in spoken and written corpora (e.g., Hirschberg and Litman (1993)), the substitutability of discourse connectives (e.g., Hutchinson (2005)), and indeed corpus studies as a means of informing the choice of discourse relations to consider in a theory (e.g., Knott and Dale (1994); Knott (1996)). A distinguishing feature of our approach relative to previous ones is an in-depth study of syntactic variations; in contrast, for example, Knott’s taxonomy of discourse relations is based on the use of a substitution text that precludes variants of the same relation having different syntax. 3 Linguistic acceptability study 3.1 Dataset creation We have constructed a dataset that can be used to gain insights into differences between different</context>
</contexts>
<marker>Hutchinson, 2005</marker>
<rawString>B. Hutchinson. 2005. Modelling the substitutability of discourse connectives. In ACL ’05: Proc. of the 43rd Annual Meeting on Association for Computational Linguistics, pp 149–156, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ibrahim</author>
<author>B Katz</author>
<author>J Lin</author>
</authors>
<title>Extracting paraphrases from aligned corpora.</title>
<date>2003</date>
<booktitle>In Proc. of The Second International Workshop on Paraphrasing.</booktitle>
<contexts>
<context position="10152" citStr="Ibrahim et al., 2003" startWordPosition="1568" endWordPosition="1571">words with easier ones), but more recently, there has been work on syntactic simplification and, in particular, the way syntactic rewrites interact with discourse structure and text cohesion (Siddharthan, 2006). Elsewhere, there has been renewed interest in paraphrasing, including the replacement of words (especially verbs) with their dictionary definitions (Kaji et al., 2002) and the replacement of idiomatic or otherwise troublesome expressions with simpler ones. The current research emphasis is on automatically learning paraphrases from comparable or aligned corpora (Barzilay and Lee, 2003; Ibrahim et al., 2003). The text simplification and paraphrasing literature does not address paraphrasing that requires syntactic alterations such as those in example 1 or the question of appropriateness of different formulations of a discourse relation. Some natural language generation systems incorporate results from psycholinguistic studies to make principled choices between alternative formulations. For example, SkillSum (Williams and Reiter, 2008) and ICONOCLAST (Power et al., 2003) are two contemporary generation systems that allow for specifying aspects of style such as choice of discourse marker, clause ord</context>
</contexts>
<marker>Ibrahim, Katz, Lin, 2003</marker>
<rawString>A. Ibrahim, B. Katz, and J. Lin. 2003. Extracting paraphrases from aligned corpora. In Proc. of The Second International Workshop on Paraphrasing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Kaji</author>
<author>D Kawahara</author>
<author>S Kurohash</author>
<author>S Sato</author>
</authors>
<title>Verb paraphrase based on case frame alignment.</title>
<date>2002</date>
<booktitle>In Proc. of the 40th Annual Meeting of the Association for Computational Linguistics (ACL’02),</booktitle>
<pages>215--222</pages>
<location>Philadelphia, USA.</location>
<contexts>
<context position="9910" citStr="Kaji et al., 2002" startWordPosition="1533" endWordPosition="1536">in ways, to make it more accessible to particular classes of readers. The PSET project (Carroll et al., 1998) considered simplifying news reports for aphasics. The PSET project focused mainly on lexical simplification (replacing difficult words with easier ones), but more recently, there has been work on syntactic simplification and, in particular, the way syntactic rewrites interact with discourse structure and text cohesion (Siddharthan, 2006). Elsewhere, there has been renewed interest in paraphrasing, including the replacement of words (especially verbs) with their dictionary definitions (Kaji et al., 2002) and the replacement of idiomatic or otherwise troublesome expressions with simpler ones. The current research emphasis is on automatically learning paraphrases from comparable or aligned corpora (Barzilay and Lee, 2003; Ibrahim et al., 2003). The text simplification and paraphrasing literature does not address paraphrasing that requires syntactic alterations such as those in example 1 or the question of appropriateness of different formulations of a discourse relation. Some natural language generation systems incorporate results from psycholinguistic studies to make principled choices between</context>
</contexts>
<marker>Kaji, Kawahara, Kurohash, Sato, 2002</marker>
<rawString>N. Kaji, D. Kawahara, S. Kurohash, and S. Sato. 2002. Verb paraphrase based on case frame alignment. In Proc. of the 40th Annual Meeting of the Association for Computational Linguistics (ACL’02), pp 215–222, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Keller</author>
<author>S Gunasekharan</author>
<author>N Mayo</author>
<author>M Corley</author>
</authors>
<title>to appear. Timing accuracy of web experiments: A case study using the webexp software package. Behavior Research Methods.</title>
<date>2008</date>
<contexts>
<context position="16097" citStr="Keller et al., 2008" startWordPosition="2525" endWordPosition="2528">from three different genres1: • PubMed Abstracts: Technical writing from the Biomedical domain • BNC World: Article from the British National Corpus tagged as World News • BNC Natural Science: Article from the British National Corpus tagged as Natural Science. This covers popular science writing in the mainstream media There were 48 example sentences chosen randomly from each genre, such that there were 6 examples of each of the 8 types of formulation) 3.2 Experimental setup Human judgements for acceptability for each of the 1152 sentences in our corpus were obtained using the WebExp package (Keller et al., 2008 to appear).2 We investigated acceptability because it is a measure which reflects both ease of comprehension and surface well-formedness. The propositional content of 144 sentences was presented in 8 formulations. Eight participant groups (A–H) consisting of 6 people each were presented with exactly one of the eight formulations of each of 144 different sentences, as per a Latin square design. Thus, while each participant read an equal number of sentences in each formulation type, they never read more than one formulation of the same propositional content. Each group saw 18 original and 126 r</context>
</contexts>
<marker>Keller, Gunasekharan, Mayo, Corley, 2008</marker>
<rawString>F. Keller, S. Gunasekharan, N. Mayo, and M. Corley. 2008, to appear. Timing accuracy of web experiments: A case study using the webexp software package. Behavior Research Methods.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Keller</author>
</authors>
<date>2000</date>
<booktitle>Gradience in Grammar: Experimental and Computational Aspects of Degrees of Grammaticality. Ph.D. thesis,</booktitle>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="17946" citStr="Keller (2000)" startWordPosition="2794" endWordPosition="2795">s of acceptability, rather than grammaticality per se. 1005 from the original text. The participants were University of Cambridge students (all native English speakers with different academic backgrounds). Post experimentally we divided participants in two groups based on having a Science or a non-Science background3. Rather than giving participants a fixed scale (e.g. 1–7), we used the magnitude estimation paradigm, which is more suitable to capture robust or subtle differences between the relative strength of acceptability or grammaticality violations (see Bard et al. (1996); Cowart (1997); Keller (2000)). 3.3 Magnitude estimation Participants were asked to score how acceptable a modulus sentence was, using any positive number. They were then asked to score other sentences relative to this modulus, using any positive number, even decimals, so that higher scores were assigned to more acceptable sentences. The advantage of Magnitude estimation is that the researcher does not make any assumptions about the number of linguistic distinctions allowed. Each subject makes as many distinctions as they feel comfortable. Scores were normalised to allow comparison across participants, following standard </context>
</contexts>
<marker>Keller, 2000</marker>
<rawString>F. Keller. 2000. Gradience in Grammar: Experimental and Computational Aspects of Degrees of Grammaticality. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Knott</author>
<author>R Dale</author>
</authors>
<title>Using linguistic phenomena to motivate a set of coherence relations.</title>
<date>1994</date>
<booktitle>Discourse Processes,</booktitle>
<volume>18</volume>
<issue>1</issue>
<contexts>
<context position="11984" citStr="Knott and Dale (1994)" startWordPosition="1851" endWordPosition="1854">on the felicity of specific formulations of a discourse relation. As part of this research, we have created a corpus of 144 real text examples, reformulated in 8 ways, giving 1152 sentences in total. There have been numerous corpus studies of discourse connectives, such as studies on the discourserole disambiguation of individual cue-phrases in spoken and written corpora (e.g., Hirschberg and Litman (1993)), the substitutability of discourse connectives (e.g., Hutchinson (2005)), and indeed corpus studies as a means of informing the choice of discourse relations to consider in a theory (e.g., Knott and Dale (1994); Knott (1996)). A distinguishing feature of our approach relative to previous ones is an in-depth study of syntactic variations; in contrast, for example, Knott’s taxonomy of discourse relations is based on the use of a substitution text that precludes variants of the same relation having different syntax. 3 Linguistic acceptability study 3.1 Dataset creation We have constructed a dataset that can be used to gain insights into differences between different realisations of discourse relations. In the following, we will illustrate such rewriting situations using an example from a medical articl</context>
</contexts>
<marker>Knott, Dale, 1994</marker>
<rawString>A. Knott and R. Dale. 1994. Using linguistic phenomena to motivate a set of coherence relations. Discourse Processes, 18(1):35–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Knott</author>
</authors>
<title>A Data-Driven Methodology for Motivating a Set of Discourse Relations.</title>
<date>1996</date>
<tech>Ph.D. thesis, Ph. D. thesis,</tech>
<institution>Centre for Cognitive Science, University of Edinburgh,</institution>
<location>Edinburgh, UK.</location>
<contexts>
<context position="11998" citStr="Knott (1996)" startWordPosition="1855" endWordPosition="1856">ific formulations of a discourse relation. As part of this research, we have created a corpus of 144 real text examples, reformulated in 8 ways, giving 1152 sentences in total. There have been numerous corpus studies of discourse connectives, such as studies on the discourserole disambiguation of individual cue-phrases in spoken and written corpora (e.g., Hirschberg and Litman (1993)), the substitutability of discourse connectives (e.g., Hutchinson (2005)), and indeed corpus studies as a means of informing the choice of discourse relations to consider in a theory (e.g., Knott and Dale (1994); Knott (1996)). A distinguishing feature of our approach relative to previous ones is an in-depth study of syntactic variations; in contrast, for example, Knott’s taxonomy of discourse relations is based on the use of a substitution text that precludes variants of the same relation having different syntax. 3 Linguistic acceptability study 3.1 Dataset creation We have constructed a dataset that can be used to gain insights into differences between different realisations of discourse relations. In the following, we will illustrate such rewriting situations using an example from a medical article. As mentione</context>
</contexts>
<marker>Knott, 1996</marker>
<rawString>A. Knott. 1996. A Data-Driven Methodology for Motivating a Set of Discourse Relations. Ph.D. thesis, Ph. D. thesis, Centre for Cognitive Science, University of Edinburgh, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Linderholm</author>
<author>M G Everson</author>
<author>P van den Broek</author>
<author>M Mischinski</author>
<author>A Crittenden</author>
<author>J Samuels</author>
</authors>
<date>2000</date>
<booktitle>Effects of Causal Text Revisions on More-and LessSkilled Readers’ Comprehension of Easy and Difficult Texts. Cognition and Instruction,</booktitle>
<volume>18</volume>
<issue>4</issue>
<marker>Linderholm, Everson, van den Broek, Mischinski, Crittenden, Samuels, 2000</marker>
<rawString>T. Linderholm, M.G. Everson, P. van den Broek, M. Mischinski, A. Crittenden, and J. Samuels. 2000. Effects of Causal Text Revisions on More-and LessSkilled Readers’ Comprehension of Easy and Difficult Texts. Cognition and Instruction, 18(4):525–556.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>S A Thompson</author>
</authors>
<title>Rhetorical Structure Theory: Towards a functional theory of text organization.</title>
<date>1988</date>
<tech>Text, 8(3):243–281.</tech>
<contexts>
<context position="11274" citStr="Mann and Thompson, 1988" startWordPosition="1738" endWordPosition="1741">tion systems that allow for specifying aspects of style such as choice of discourse marker, clause order, repetition and sentence and paragraph lengths in the form of constraints that can be optimised. However, to date, these systems do not consider syntactic reformulations of the type we are interested in. Our research is directly relevant to such generation systems as it can help such systems make decisions in a principled manner. 2.4 Corpus studies and treebanking There are two major corpora that mark up discourse relations – the RST Discourse Treebank based on Rhetorical Structure Theory (Mann and Thompson, 1988), and the Penn Discourse Treebank (Webber et al., 2005). Neither is suitable for studies on the felicity of specific formulations of a discourse relation. As part of this research, we have created a corpus of 144 real text examples, reformulated in 8 ways, giving 1152 sentences in total. There have been numerous corpus studies of discourse connectives, such as studies on the discourserole disambiguation of individual cue-phrases in spoken and written corpora (e.g., Hirschberg and Litman (1993)), the substitutability of discourse connectives (e.g., Hutchinson (2005)), and indeed corpus studies </context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>W. C. Mann and S. A. Thompson. 1988. Rhetorical Structure Theory: Towards a functional theory of text organization. Text, 8(3):243–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L G M Noordman</author>
<author>W Vonk</author>
</authors>
<title>Reader’s knowledge and the control of inferences in reading.</title>
<date>1992</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>7--373</pages>
<contexts>
<context position="8726" citStr="Noordman and Vonk, 1992" startWordPosition="1361" endWordPosition="1364">usal (and temporal) order; for instance, 3b. is more accessible than 3a. (e.g. from Anderson and Davison (1988)). (3) a. Because Mexico allowed slavery, many Americans and their slaves moved to Mexico during that time. b. Many Americans and their slaves moved to Mexico during that time, because Mexico allowed slavery. 1003 Such studies show that comprehension can be improved by reformulating text; e.g., making causal relations explicit had a facilitatory effect for readers with low reading skills (Linderholm et al., 2000; Beck et al., 1991) and for readers with low levels of domain expertise (Noordman and Vonk, 1992). Further, specific information orderings were found to be facilitatory by Anderson and Davison (1988). However, it has not been investigated whether readers with different levels of domain expertise are facilitated by any specific lexico-syntactic formulation among the many possible explicit realisations of a relation. This is a novel question in the linguistics literature, and we address it in section 3. 2.3 Connectives and automatic (re)generation Much of the work regarding (re)generation of text based on discourse connectives aims to simplify text in certain ways, to make it more accessibl</context>
</contexts>
<marker>Noordman, Vonk, 1992</marker>
<rawString>L. G. M. Noordman and W. Vonk. 1992. Reader’s knowledge and the control of inferences in reading. Language and Cognitive Processes, 7:373–391.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Power</author>
<author>D Scott</author>
<author>N Bouayad-Agha</author>
</authors>
<title>Generating texts with style.</title>
<date>2003</date>
<booktitle>Proc. of the 4 thInternational Conference on Intelligent Texts Processing and Computational Linguistics.</booktitle>
<contexts>
<context position="10622" citStr="Power et al., 2003" startWordPosition="1634" endWordPosition="1637"> current research emphasis is on automatically learning paraphrases from comparable or aligned corpora (Barzilay and Lee, 2003; Ibrahim et al., 2003). The text simplification and paraphrasing literature does not address paraphrasing that requires syntactic alterations such as those in example 1 or the question of appropriateness of different formulations of a discourse relation. Some natural language generation systems incorporate results from psycholinguistic studies to make principled choices between alternative formulations. For example, SkillSum (Williams and Reiter, 2008) and ICONOCLAST (Power et al., 2003) are two contemporary generation systems that allow for specifying aspects of style such as choice of discourse marker, clause order, repetition and sentence and paragraph lengths in the form of constraints that can be optimised. However, to date, these systems do not consider syntactic reformulations of the type we are interested in. Our research is directly relevant to such generation systems as it can help such systems make decisions in a principled manner. 2.4 Corpus studies and treebanking There are two major corpora that mark up discourse relations – the RST Discourse Treebank based on R</context>
</contexts>
<marker>Power, Scott, Bouayad-Agha, 2003</marker>
<rawString>R. Power, D. Scott, and N. Bouayad-Agha. 2003. Generating texts with style. Proc. of the 4 thInternational Conference on Intelligent Texts Processing and Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Siddharthan</author>
</authors>
<title>Syntactic simplification and text cohesion.</title>
<date>2006</date>
<journal>Research on Language and Computation,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="9741" citStr="Siddharthan, 2006" startWordPosition="1512" endWordPosition="1513">n section 3. 2.3 Connectives and automatic (re)generation Much of the work regarding (re)generation of text based on discourse connectives aims to simplify text in certain ways, to make it more accessible to particular classes of readers. The PSET project (Carroll et al., 1998) considered simplifying news reports for aphasics. The PSET project focused mainly on lexical simplification (replacing difficult words with easier ones), but more recently, there has been work on syntactic simplification and, in particular, the way syntactic rewrites interact with discourse structure and text cohesion (Siddharthan, 2006). Elsewhere, there has been renewed interest in paraphrasing, including the replacement of words (especially verbs) with their dictionary definitions (Kaji et al., 2002) and the replacement of idiomatic or otherwise troublesome expressions with simpler ones. The current research emphasis is on automatically learning paraphrases from comparable or aligned corpora (Barzilay and Lee, 2003; Ibrahim et al., 2003). The text simplification and paraphrasing literature does not address paraphrasing that requires syntactic alterations such as those in example 1 or the question of appropriateness of diff</context>
</contexts>
<marker>Siddharthan, 2006</marker>
<rawString>A. Siddharthan. 2006. Syntactic simplification and text cohesion. Research on Language and Computation, 4(1):77–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Webber</author>
<author>A Joshi</author>
<author>E Miltsakaki</author>
<author>R Prasad</author>
<author>N Dinesh</author>
<author>A Lee</author>
<author>K Forbes</author>
</authors>
<title>A Short Introduction to the Penn Discourse TreeBank. Treebanking for discourse and speech: proceedings of the NODALIDA</title>
<date>2005</date>
<contexts>
<context position="11329" citStr="Webber et al., 2005" startWordPosition="1747" endWordPosition="1750">h as choice of discourse marker, clause order, repetition and sentence and paragraph lengths in the form of constraints that can be optimised. However, to date, these systems do not consider syntactic reformulations of the type we are interested in. Our research is directly relevant to such generation systems as it can help such systems make decisions in a principled manner. 2.4 Corpus studies and treebanking There are two major corpora that mark up discourse relations – the RST Discourse Treebank based on Rhetorical Structure Theory (Mann and Thompson, 1988), and the Penn Discourse Treebank (Webber et al., 2005). Neither is suitable for studies on the felicity of specific formulations of a discourse relation. As part of this research, we have created a corpus of 144 real text examples, reformulated in 8 ways, giving 1152 sentences in total. There have been numerous corpus studies of discourse connectives, such as studies on the discourserole disambiguation of individual cue-phrases in spoken and written corpora (e.g., Hirschberg and Litman (1993)), the substitutability of discourse connectives (e.g., Hutchinson (2005)), and indeed corpus studies as a means of informing the choice of discourse relatio</context>
</contexts>
<marker>Webber, Joshi, Miltsakaki, Prasad, Dinesh, Lee, Forbes, 2005</marker>
<rawString>B. Webber, A. Joshi, E. Miltsakaki, R. Prasad, N. Dinesh, A. Lee, and K. Forbes. 2005. A Short Introduction to the Penn Discourse TreeBank. Treebanking for discourse and speech: proceedings of the NODALIDA 2005 special session on Treebanksfor spoken language and discourse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Williams</author>
<author>E Reiter</author>
</authors>
<title>Generating basic skills reports for low-skilled readers.</title>
<date>2008</date>
<journal>Natural Language Engineering,</journal>
<volume>14</volume>
<issue>04</issue>
<contexts>
<context position="10586" citStr="Williams and Reiter, 2008" startWordPosition="1627" endWordPosition="1631">ublesome expressions with simpler ones. The current research emphasis is on automatically learning paraphrases from comparable or aligned corpora (Barzilay and Lee, 2003; Ibrahim et al., 2003). The text simplification and paraphrasing literature does not address paraphrasing that requires syntactic alterations such as those in example 1 or the question of appropriateness of different formulations of a discourse relation. Some natural language generation systems incorporate results from psycholinguistic studies to make principled choices between alternative formulations. For example, SkillSum (Williams and Reiter, 2008) and ICONOCLAST (Power et al., 2003) are two contemporary generation systems that allow for specifying aspects of style such as choice of discourse marker, clause order, repetition and sentence and paragraph lengths in the form of constraints that can be optimised. However, to date, these systems do not consider syntactic reformulations of the type we are interested in. Our research is directly relevant to such generation systems as it can help such systems make decisions in a principled manner. 2.4 Corpus studies and treebanking There are two major corpora that mark up discourse relations – t</context>
</contexts>
<marker>Williams, Reiter, 2008</marker>
<rawString>S. Williams and E. Reiter. 2008. Generating basic skills reports for low-skilled readers. Natural Language Engineering, 14(04):495–525.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Witten</author>
<author>E Frank</author>
</authors>
<date>2000</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.</booktitle>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="28474" citStr="Witten and Frank, 2000" startWordPosition="4462" endWordPosition="4466"> the test-set probability (from the first run) to the highest of the 8 test-set probabilities for the different formulations of that sentence: pweka1(Si=a,j=b) relativei=a,j=b = maxi=a,j=1..8(pweka1(Si=a,j)) Thus probabilities for acceptability are normalised such that the best score for a given propositional content is 1 and the other 7 formulations score less than or equal to 1. The second classifier uses these relative probabilities as an extra feature. 4.2 Results Our results are summarised in Table 2 (accuracy and agreement) and Table 3 (f-measure). We experimented with the Weka toolkit (Witten and Frank, 2000) and report results using “weka.classifiers.trees.J48 -C 0.3 -M 3” and 10-fold cross-validation for both runs.5 Table 2 shows that the first run performs at around baseline levels, but the second run performs significantly better (using z-test, p=0.01 on % Accuracy), with acceptable agreement of K = 0.656. This increases to 89% (K = .73) when we only consider technical writing (PubMed genre). Table 3 shows that precision, recall and f-measure are also around .90 for PubMed sentences. 5J48 outperformed other Weka classifiers for this task. 6Following Carletta (1996), we measure agreement in κ, </context>
</contexts>
<marker>Witten, Frank, 2000</marker>
<rawString>I. Witten and E. Frank. 2000. Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Wolff</author>
<author>B Klettke</author>
<author>T Ventura</author>
<author>G Song</author>
</authors>
<title>Expressing causation in English and other languages. Categorization inside and outside the laboratory: Essays in honor ofDouglas</title>
<date>2005</date>
<pages>29--48</pages>
<contexts>
<context position="5929" citStr="Wolff et al., 2005" startWordPosition="905" endWordPosition="908">comparing expert vs lay readers on the comprehension of causal relations in scientific writing is a most timely investigation. In section 2, we relate our research to the existing linguistic, psycholinguistic and computational literature. Then in section 3, we describe our psycholinguistic experiment that addresses our first two research questions and in section 4 we present a computational approach to learning felicitous paraphrases that addresses the final two questions. 2 Background and related work 2.1 Expressing causation Linguists generally consider five different components of meaning (Wolff et al., 2005) in causal expressions: (a) occurrence of change in patient, (b) specification of endstate, (c) tendency and concordance, (d) directness and (e) mechanism. The expressions we consider in this paper, “because” (conjunction), “because of” (preposition) and “cause” as noun or verb (periphrastic causatives) express (a), (b) and in some instances, (c). This is in contrast to affect verbs that only express (a), link verbs that express (a–b), lexical causatives that express (a–d) and resultatives that express (a–e). These distinctions are illustrated by the sentences in example 2: (2) a. Sara kicked </context>
<context position="7151" citStr="Wolff et al. (2005)" startWordPosition="1113" endWordPosition="1116"> door. (affect verb – end state not specified) b. The door’s breaking was linked to Sara. (link verb – end state specified, but unclear that door has a tendency to break) c. Sara caused the door to break. / The door broke because of Sara. (periphrastic / preposition – indirect; the door might have a tendency to break) d. Sara broke the door. (lexical causative – directness of action is specified) e. Sara broke the door open. (resultative – end state is “open”) There is much literature on how people prefer one type of causative over the other based on these five components of meaning (e.g. see Wolff et al. (2005)). What is less understood is how one selects between various expressions that carry similar semantic content. In this paper we consider four constructs “because of”, “because”, and “cause” as a verb and a noun. These express the components of meaning (a–c) using different syntactic structures. By considering only these four lexically similar constructs, we can focus on the role of the lexis and of syntax in determining the most felicitous expression of causation for a given propositional content. 2.2 Discourse connectives and comprehension Previous work has shown that when texts have been man</context>
</contexts>
<marker>Wolff, Klettke, Ventura, Song, 2005</marker>
<rawString>P. Wolff, B. Klettke, T. Ventura, and G. Song. 2005. Expressing causation in English and other languages. Categorization inside and outside the laboratory: Essays in honor ofDouglas L. Medin, pp 29–48.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>