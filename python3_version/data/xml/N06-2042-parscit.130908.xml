<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000044">
<title confidence="0.957857">
Word Pronunciation Disambiguation using the Web
</title>
<author confidence="0.71476">
Eiichiro Sumita1, 2
</author>
<sectionHeader confidence="0.835499" genericHeader="abstract">
1 NiCT
2 ATR SLC
</sectionHeader>
<note confidence="0.403653">
Kyoto 619-0288, JAPAN
</note>
<email confidence="0.991691">
eiichiro.sumita@atr.jp
</email>
<author confidence="0.518695">
Fumiaki Sugaya3
</author>
<sectionHeader confidence="0.514404" genericHeader="general terms">
3 KDDI R&amp;D Labs
</sectionHeader>
<address confidence="0.641583">
Saitama 356-8502, JAPAN
</address>
<email confidence="0.98525">
fsugaya@kddilabs.jp
</email>
<sectionHeader confidence="0.997278" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.99989375">
This paper proposes an automatic method
of reading proper names with multiple
pronunciations. First, the method obtains
Web pages that include both the proper
name and its pronunciation. Second, the
method feeds them to the learner for clas-
sification. The current accuracy is around
90% for open data.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999984823529412">
Within text-to-speech programs, it is very impor-
tant to deal with heteronyms, that is, words that are
spelt the same but that have different readings, e.g.
&amp;quot;bow&amp;quot; (a ribbon) and &amp;quot;bow&amp;quot; (of a ship). Reportedly,
Japanese text-to-speech programs read sentences
incorrectly more than 10 percent of the time. This
problem is mainly caused by heteronyms and three
studies have attempted to solve it (Yarowsky,
1996; Li and Takeuchi, 1997; and Umemura and
Shimizu, 2000).
They assumed that the pronunciation of a word
corresponded directly to the sense tag or part-of-
speech of that word. In other words, sense tagging
and part-of-speech tagging can determine the read-
ing of a word. However, proper names have the
same sense tag, for example, “location” for land-
marks and the same part-of-speech, the “noun.”
Clearly then, reading proper names is outside the
scope of previous studies. Also, the proper names
of locations, people, organizations, and others are
dominant sources of heteronyms. Here, we focus
on proper names. Our proposal is similar to previ-
ous studies in that both use machine learning.
However, previous methods used expensive re-
sources, e.g., a corpus in which words are
manually tagged according to their pronunciation.
Instead, we propose a method that automatically
builds a pronunciation-tagged corpus using the
Web as a source of training data for word pronun-
ciation disambiguation.
This paper is arranged as follows. Section 2
proposes solutions, and Sections 3 and 4 report
experimental results. We offer our discussion in
Section 5 and conclusions in Section 6.
</bodyText>
<sectionHeader confidence="0.985342" genericHeader="method">
2 The Proposed Methods
</sectionHeader>
<bodyText confidence="0.9997151">
It is crucial to correctly read proper names in open-
domain text-to-speech programs, for example, ap-
plications that read Web pages or newspaper
articles. To the best of our knowledge, no other
studies have approached this problem. In this paper,
we focus on the Japanese language. In this section,
we first explain the Japanese writing system (Sec-
tions 2.1), followed by our proposal, the basic
method (Section 2.2), and the improved method
(Section 2.3).
</bodyText>
<subsectionHeader confidence="0.99472">
2.1 The Japanese writing system
</subsectionHeader>
<bodyText confidence="0.992790666666667">
First, we should briefly explain the modern Japa-
nese writing system. The Japanese language is rep-
resented by three scripts:
</bodyText>
<listItem confidence="0.9647145">
[i] Kanji, which are characters of Chinese ori-
gin;
[ii] Hiragana, a syllabary (reading); and
[iii] Katakana, also a syllabary (reading).
</listItem>
<table confidence="0.6989595">
Script Sample
KANJI 大平
HIRAGANA (reading) おおだいら
KATAKANA (reading) オオダイラ
</table>
<tableCaption confidence="0.983225">
Table 1 Three writings of a single word
</tableCaption>
<page confidence="0.967499">
165
</page>
<note confidence="0.8703145">
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 165–168,
New York, June 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999878">
As exemplified in Table 1, there are three writ-
ings for the word “大平.” The lower two sam-
ples are representations of the same pronunciation
of “oo daira.”
Listing possible readings can be done by con-
sulting a dictionary (see Section 3.1 for the ex-
periment). Therefore, in this paper, we assume that
listing is performed prior to disambiguation.
</bodyText>
<subsectionHeader confidence="0.997264">
2.2 The basic method based on page hits
</subsectionHeader>
<bodyText confidence="0.985875823529412">
The idea is based on the observation that proper
names in Kanji often co-occur with their pro-
nunciation in Hiragana (or Katakana) within a sin-
gle Web page, as shown Figure 1. In the figure,
the name “大平” in Kanji is indicated with an
oval, and its pronunciation in Katakana, “オオダ
イラ,” is high-lighted with the dotted oval.
According to Google, there are 464 pages in
which “大平” and “オオダイラ” co-occur.
In this sense, the co-occurrence frequency
suggests to us the most common pronunciation.
Figure 1 On the Web, words written in Kanji
often co-occur with the pronunciation written in
Katakana 1
Our simple proposal to pick up the most fre-
quent pronunciation achieves surprisingly high
accuracy for open data, as Section 4 will later show.
</bodyText>
<subsectionHeader confidence="0.99096">
2.3 The improved method using a classifier
</subsectionHeader>
<bodyText confidence="0.999943">
The basic method mentioned above merely selects
the most frequent pronunciation and neglects all
others. This is not disambiguation at all.
The improved method is similar to standard
word-sense disambiguation. The hit pages can pro-
</bodyText>
<page confidence="0.704009">
1
</page>
<bodyText confidence="0.94978925">
http://oyudokoro.mimo.com/area/C/cd/tng/000370/index.html
vide us with training data for reading a particular
word. We feed the downloaded data into the
learner of a classifier. We do not stick to a certain
method of machine learning; any state-of-the-art
method will work. The features used in classifica-
tion will be explained in the latter half of this sub-
section.
</bodyText>
<subsectionHeader confidence="0.628212">
Collecting training data from the Web
</subsectionHeader>
<bodyText confidence="0.9986608">
Our input is a particular word, W, and the set of its
readings, {Rk  |k=1—K}.
In the experiments for this report, L is set to
1,000. Thus, for each reading Rk of W, we have, at
most 1,000 training data Tl(W).
</bodyText>
<subsectionHeader confidence="0.624325">
Training the classifier
</subsectionHeader>
<bodyText confidence="0.999610375">
From the training data Tl(W), we make feature
vectors that are fed into the learner of the decision
tree with the correct reading Rk for the word in
question, W.
Here, we write Tl(W) as W-m W-(m-1) ... W-2 W-1
W W1 W2 ... Wm-1 Wm, where m is from 2 to M,
which hereafter is called the window size.
We use two kinds of features:
</bodyText>
<listItem confidence="0.9448266">
• The part-of-speech of W-2 W-1 and W1 W2
• Keywords within the snippet. In this ex-
periment, keywords are defined as the top
N frequent words, but for W in the bag
consisting of all words in {Tl(W)}.
</listItem>
<bodyText confidence="0.999678333333334">
In this paper, N is set to 100. These features
ground the pronunciation disambiguation task to
the real world through the Web. In other words,
they give us knowledge about the problem at hand,
i.e., how to read proper names in a real-world con-
text.
</bodyText>
<sectionHeader confidence="0.998813" genericHeader="method">
3 Experimental Data
</sectionHeader>
<bodyText confidence="0.999644">
We conducted the experiments using proper loca-
tion names.
</bodyText>
<figure confidence="0.703652125">
For all k =1—K:
i) search the Web using the query “W AND
Rk.”
ii) obtain the set of snippets, {Sl (W, Rj
l=1—L}.
iii) separate Rk from Sl and obtain the set of
training data,{(Tl(W), Rk) |l=1—L}.
end
</figure>
<page confidence="0.964842">
166
</page>
<subsectionHeader confidence="0.997482">
3.1 Ambiguous name lists
</subsectionHeader>
<bodyText confidence="0.997713071428572">
Japan Post openly provides postal address lists
associated with pronunciations .
From that list, we extracted 79,861 pairs of
proper location names and their pronunciations. As
the breakdown of Table 2 shows, 5.7% of proper
location names have multiple pronunciations,
while 94.3% have a single pronunciation. The av-
erage ambiguity is 2.26 for ambiguous types. Next,
we took into consideration the frequency of each
proper name on the Web. Frequency is surrogated
by the page count when the query of a word itself
is searched for using a search engine. About one
quarter of the occurrences were found to be am-
biguous.
</bodyText>
<figure confidence="0.9898525">
Number of type %
readings
1 70,232 94.3
2 3,443 5.7
3 599
4 150
5 45
6 11
7 4
8 2
11 1
total 74,487 100.0
</figure>
<tableCaption confidence="0.9285445">
Table 2 Pronunciation ambiguities in Japanese
location names
</tableCaption>
<bodyText confidence="0.999878">
Our proposal depends on co-occurrences on a
Web page. If the pairing of a word W and its read-
ing R do not occur on the Web, the proposal will
not work. We checked this, and found that there
was only one pair missing out of the 79,861 on our
list. In this sense, the coverage is almost 100%.
</bodyText>
<subsectionHeader confidence="0.999235">
3.2 Open Data
</subsectionHeader>
<bodyText confidence="0.9999025">
We tested the performance of our proposed meth-
ods on openly available data.
Open data were obtained from the EDR corpus,
which consists of sentences from Japanese news-
papers. Every word is tagged with part-of-speech
and pronunciation.
We extracted sentences that include location
heteronyms, that is, those that contain Kanji that
can be found in the above-mentioned list of loca-
tion heteronyms within the postal address data.
There were 268 occurrences in total. There were
72 types of heteronyms.
</bodyText>
<sectionHeader confidence="0.993197" genericHeader="method">
4 Experiment Results
</sectionHeader>
<bodyText confidence="0.9999765">
We conducted two experiments: (1) an open test;
and (2) a study on the degree of ambiguity.
</bodyText>
<subsectionHeader confidence="0.996112">
4.1 Open test
</subsectionHeader>
<bodyText confidence="0.99991625">
We evaluated our proposals, i.e., the basic method
and the improved method with the open data ex-
plained in Section 3.1. Both methods achieved a
high rate of accuracy.
</bodyText>
<subsectionHeader confidence="0.826592">
Basic method performance
</subsectionHeader>
<bodyText confidence="0.9999684">
In the basic method, the most common pronuncia-
tion on the Web is selected. The frequency is esti-
mated by the page count of the query for the
pairing of the word W and its pronunciation, Ri.
There are two variations based on the Hiragana
and Katakana pronunciation scripts. The average
accuracy for the open data was 89.2% for Hiragana
and 86.6% for Katakana (Table 3). These results
are very high, suggesting a strong bias of pronun-
ciation distribution in the open data.
</bodyText>
<subsectionHeader confidence="0.985334">
Scripts Accuracy
</subsectionHeader>
<bodyText confidence="0.8919411">
HIRAGANA 89.2
KATAKANA 86.6
Table 3 Open test accuracy for the basic method
Performance of the improved method
Table 4 shows the average results for all 268
occurrences. The accuracy of the basic method
(Table 3) was lower than that of our improved
proposal in all window sizes, and it was outper-
formed at a window size of ten by about 3.5% for
both Hiragana and Katakana.
</bodyText>
<table confidence="0.997142333333333">
Script M=2 M=5 M=10
HIRAGANA 89.9 90.3 92.9
KATAKANA 89.2 88.4 89.9
</table>
<tableCaption confidence="0.9096635">
Table 4 Open test accuracy for the improved
method
</tableCaption>
<page confidence="0.9937">
167
</page>
<subsectionHeader confidence="0.971587">
4.2 Degree of ambiguity
</subsectionHeader>
<bodyText confidence="0.99998175">
Here, we examine the relationship between the
degree of pronunciation ambiguity and pronuncia-
tion accuracy using a cross-validation test for train-
ing data2 for the improved method with Hiragana.
</bodyText>
<subsectionHeader confidence="0.750339">
Average case
</subsectionHeader>
<bodyText confidence="0.9999464">
We conducted the first experiment with twenty
words 3 that were selected randomly from the Am-
biguous Name List (Section 3.1). The average am-
biguity was 2.1, indicating the average
performance of the improved proposal.
</bodyText>
<table confidence="0.8887465">
Class M=2 M=5 M=10 basic
2.1 89.2 % 90.9 % 92.3 % 67.5%
</table>
<tableCaption confidence="0.965039">
Table 5 Average cases
</tableCaption>
<bodyText confidence="0.991476666666667">
Table 5 summarizes the ten-fold cross valida-
tion, where M in the table is the training data size
(window size). The accuracy changes word by
word, though the average was high about 90% of
the time.
The “basic” column shows the average accu-
racy of the basic method, i.e., the percentage for
the most frequent pronunciation. The improved
method achieves much better accuracy than the
“basic” one.
The most ambiguous case
Next, we obtained the results (Table 6) for the
most ambiguous cases, where the degree of ambi-
guity ranged from six to eleven4. The average am-
biguity was 7.1.
</bodyText>
<table confidence="0.791535">
Class M=2 M=5 M=10 basic
7.1 73.9 % 77.3 % 79.9 % 57.5%
</table>
<tableCaption confidence="0.842605">
Table 6 Most ambiguous cases
</tableCaption>
<footnote confidence="0.7627764">
2 There is some question as to whether the training data cor-
rectly catch all the pronunciations. The experiments in this
subsection are independent of this problem, because our inten-
tion is to compare the performance of the average case and the
most ambiguous case.
</footnote>
<construct confidence="0.613432166666667">
3東浜町, 三角町, 宮丸町, 川戸 ,下坂田, 蓬田, 金沢町, 白木
町, 神保町, 助谷, 新御堂, 糸原, 駿河町, 百目木, 垣内田町,
杉山町, 百戸, 宝山町, 出来島, 神楽町.
4小谷, 上原町, 上原, 小原, 西原, 上町, 大平, 葛原, 平田, 馬
場町, 新田, 土橋町, 大畑町, 上野町, 八幡町, 柚木町, 長田
町, 平原.
</construct>
<bodyText confidence="0.999961833333333">
As we expected, the performances were poorer
than the average cases outlined above, although
they were still high, i.e., the average ranged from
about 70% to about 80 %. Again, the improved
method achieved much better accuracy than the
“basic” method. 5
</bodyText>
<sectionHeader confidence="0.998823" genericHeader="method">
5 Discussion on Transliteration
</sectionHeader>
<bodyText confidence="0.999579625">
Transliteration (Knight and Graehl, 1998) is a
mapping from one system of writing into another,
automation of which has been actively studied be-
tween English and other languages such as Arabic,
Chinese, Korean, Thai, and Japanese. If there are
multiple translation candidates, by incorporating
context in a way similar to our proposal, one will
be able to disambiguate them.
</bodyText>
<sectionHeader confidence="0.999816" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99994">
This paper proposed a new method for reading
proper names. In our proposed method, using Web
pages containing Kanji and Hiragana (or Katakana)
representations of the same proper names, we can
learn how to read proper names with multiple read-
ings via a state-of-the-art machine learner. Thus,
the proposed process requires no human interven-
tion. The current accuracy was around 90% for
open data.
</bodyText>
<sectionHeader confidence="0.99926" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999691083333333">
K. Knight and J. Graehl. 1998 Machine transliteration.
Computational Linguistics, 24(4):599-612.
H. Li and J. Takeuchi. 1997. Using Evidence that is
both string and Reliable in Japanese Homograph Dis-
ambiguation, SIGNL119-9, IPSJ.
Y. Umemura and T. Shimizu. 2000. Japanese homo-
graph disambiguation for speech synthesizers, Toy-
ota Chuo Kenkyujo R&amp;D Review, 35(1):67-74.
D. Yarowsky. 1996. Homograph Disambiguation in
Speech Synthesis. In J. van Santen, R. Sproat, J.
Olive and J. Hirschberg (eds.), Progress in Speech
Synthesis. Springer-Verlag, pp. 159-175.
</reference>
<bodyText confidence="0.676739375">
5 For some words, the basic accuracy is higher than the cross
validation accuracy because the basic method reaches all oc-
currences on the Web thanks to the search engine, while our
improved method limits the number of training data by L in
Section 2.3. For example, the most frequent pronunciation of
“上原” has 93.7% on the Web, whereas the distribution in the
training data is different from such a sharp distribution due to
the limitation of L.
</bodyText>
<page confidence="0.996726">
168
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.703140">
<title confidence="0.968685">Word Pronunciation Disambiguation using the Web</title>
<author confidence="0.808506">Kyoto</author>
<email confidence="0.974205">eiichiro.sumita@atr.jp</email>
<affiliation confidence="0.941149">R&amp;D Labs</affiliation>
<address confidence="0.99225">Saitama 356-8502, JAPAN</address>
<email confidence="0.991067">fsugaya@kddilabs.jp</email>
<abstract confidence="0.994900222222222">This paper proposes an automatic method of reading proper names with multiple pronunciations. First, the method obtains Web pages that include both the proper name and its pronunciation. Second, the method feeds them to the learner for classification. The current accuracy is around 90% for open data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>J Graehl</author>
</authors>
<date>1998</date>
<booktitle>Machine transliteration. Computational Linguistics,</booktitle>
<pages>24--4</pages>
<contexts>
<context position="11157" citStr="Knight and Graehl, 1998" startWordPosition="1893" endWordPosition="1896"> this problem, because our intention is to compare the performance of the average case and the most ambiguous case. 3東浜町, 三角町, 宮丸町, 川戸 ,下坂田, 蓬田, 金沢町, 白木 町, 神保町, 助谷, 新御堂, 糸原, 駿河町, 百目木, 垣内田町, 杉山町, 百戸, 宝山町, 出来島, 神楽町. 4小谷, 上原町, 上原, 小原, 西原, 上町, 大平, 葛原, 平田, 馬 場町, 新田, 土橋町, 大畑町, 上野町, 八幡町, 柚木町, 長田 町, 平原. As we expected, the performances were poorer than the average cases outlined above, although they were still high, i.e., the average ranged from about 70% to about 80 %. Again, the improved method achieved much better accuracy than the “basic” method. 5 5 Discussion on Transliteration Transliteration (Knight and Graehl, 1998) is a mapping from one system of writing into another, automation of which has been actively studied between English and other languages such as Arabic, Chinese, Korean, Thai, and Japanese. If there are multiple translation candidates, by incorporating context in a way similar to our proposal, one will be able to disambiguate them. 6 Conclusion This paper proposed a new method for reading proper names. In our proposed method, using Web pages containing Kanji and Hiragana (or Katakana) representations of the same proper names, we can learn how to read proper names with multiple readings via a s</context>
</contexts>
<marker>Knight, Graehl, 1998</marker>
<rawString>K. Knight and J. Graehl. 1998 Machine transliteration. Computational Linguistics, 24(4):599-612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Li</author>
<author>J Takeuchi</author>
</authors>
<title>Using Evidence that is both string and Reliable</title>
<date>1997</date>
<booktitle>in Japanese Homograph Disambiguation, SIGNL119-9, IPSJ.</booktitle>
<contexts>
<context position="961" citStr="Li and Takeuchi, 1997" startWordPosition="144" endWordPosition="147">ages that include both the proper name and its pronunciation. Second, the method feeds them to the learner for classification. The current accuracy is around 90% for open data. 1 Introduction Within text-to-speech programs, it is very important to deal with heteronyms, that is, words that are spelt the same but that have different readings, e.g. &amp;quot;bow&amp;quot; (a ribbon) and &amp;quot;bow&amp;quot; (of a ship). Reportedly, Japanese text-to-speech programs read sentences incorrectly more than 10 percent of the time. This problem is mainly caused by heteronyms and three studies have attempted to solve it (Yarowsky, 1996; Li and Takeuchi, 1997; and Umemura and Shimizu, 2000). They assumed that the pronunciation of a word corresponded directly to the sense tag or part-ofspeech of that word. In other words, sense tagging and part-of-speech tagging can determine the reading of a word. However, proper names have the same sense tag, for example, “location” for landmarks and the same part-of-speech, the “noun.” Clearly then, reading proper names is outside the scope of previous studies. Also, the proper names of locations, people, organizations, and others are dominant sources of heteronyms. Here, we focus on proper names. Our proposal i</context>
</contexts>
<marker>Li, Takeuchi, 1997</marker>
<rawString>H. Li and J. Takeuchi. 1997. Using Evidence that is both string and Reliable in Japanese Homograph Disambiguation, SIGNL119-9, IPSJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Umemura</author>
<author>T Shimizu</author>
</authors>
<title>Japanese homograph disambiguation for speech synthesizers, Toyota Chuo Kenkyujo R&amp;D Review,</title>
<date>2000</date>
<pages>35--1</pages>
<contexts>
<context position="993" citStr="Umemura and Shimizu, 2000" startWordPosition="149" endWordPosition="152">proper name and its pronunciation. Second, the method feeds them to the learner for classification. The current accuracy is around 90% for open data. 1 Introduction Within text-to-speech programs, it is very important to deal with heteronyms, that is, words that are spelt the same but that have different readings, e.g. &amp;quot;bow&amp;quot; (a ribbon) and &amp;quot;bow&amp;quot; (of a ship). Reportedly, Japanese text-to-speech programs read sentences incorrectly more than 10 percent of the time. This problem is mainly caused by heteronyms and three studies have attempted to solve it (Yarowsky, 1996; Li and Takeuchi, 1997; and Umemura and Shimizu, 2000). They assumed that the pronunciation of a word corresponded directly to the sense tag or part-ofspeech of that word. In other words, sense tagging and part-of-speech tagging can determine the reading of a word. However, proper names have the same sense tag, for example, “location” for landmarks and the same part-of-speech, the “noun.” Clearly then, reading proper names is outside the scope of previous studies. Also, the proper names of locations, people, organizations, and others are dominant sources of heteronyms. Here, we focus on proper names. Our proposal is similar to previous studies in</context>
</contexts>
<marker>Umemura, Shimizu, 2000</marker>
<rawString>Y. Umemura and T. Shimizu. 2000. Japanese homograph disambiguation for speech synthesizers, Toyota Chuo Kenkyujo R&amp;D Review, 35(1):67-74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Homograph Disambiguation in Speech Synthesis.</title>
<date>1996</date>
<booktitle>Progress in Speech Synthesis.</booktitle>
<pages>159--175</pages>
<editor>In J. van Santen, R. Sproat, J. Olive and J. Hirschberg (eds.),</editor>
<publisher>Springer-Verlag,</publisher>
<contexts>
<context position="938" citStr="Yarowsky, 1996" startWordPosition="142" endWordPosition="143">od obtains Web pages that include both the proper name and its pronunciation. Second, the method feeds them to the learner for classification. The current accuracy is around 90% for open data. 1 Introduction Within text-to-speech programs, it is very important to deal with heteronyms, that is, words that are spelt the same but that have different readings, e.g. &amp;quot;bow&amp;quot; (a ribbon) and &amp;quot;bow&amp;quot; (of a ship). Reportedly, Japanese text-to-speech programs read sentences incorrectly more than 10 percent of the time. This problem is mainly caused by heteronyms and three studies have attempted to solve it (Yarowsky, 1996; Li and Takeuchi, 1997; and Umemura and Shimizu, 2000). They assumed that the pronunciation of a word corresponded directly to the sense tag or part-ofspeech of that word. In other words, sense tagging and part-of-speech tagging can determine the reading of a word. However, proper names have the same sense tag, for example, “location” for landmarks and the same part-of-speech, the “noun.” Clearly then, reading proper names is outside the scope of previous studies. Also, the proper names of locations, people, organizations, and others are dominant sources of heteronyms. Here, we focus on prope</context>
</contexts>
<marker>Yarowsky, 1996</marker>
<rawString>D. Yarowsky. 1996. Homograph Disambiguation in Speech Synthesis. In J. van Santen, R. Sproat, J. Olive and J. Hirschberg (eds.), Progress in Speech Synthesis. Springer-Verlag, pp. 159-175.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>