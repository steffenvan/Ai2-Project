<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.059740">
<title confidence="0.996581">
Minimally Lexicalized Dependency Parsing
</title>
<author confidence="0.994224">
Daisuke Kawahara and Kiyotaka Uchimoto
</author>
<affiliation confidence="0.995677">
National Institute of Information and Communications Technology,
</affiliation>
<address confidence="0.898173">
3-5 Hikaridai Seika-cho Soraku-gun, Kyoto, 619-0289, Japan
</address>
<email confidence="0.997037">
{dk, uchimoto}@nict.go.jp
</email>
<sectionHeader confidence="0.995591" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999930769230769">
Dependency structures do not have the infor-
mation of phrase categories in phrase struc-
ture grammar. Thus, dependency parsing
relies heavily on the lexical information of
words. This paper discusses our investiga-
tion into the effectiveness of lexicalization
in dependency parsing. Specifically, by re-
stricting the degree of lexicalization in the
training phase of a parser, we examine the
change in the accuracy of dependency re-
lations. Experimental results indicate that
minimal or low lexicalization is sufficient
for parsing accuracy.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999979071428571">
In recent years, many accurate phrase-structure
parsers have been developed (e.g., (Collins, 1999;
Charniak, 2000)). Since one of the characteristics of
these parsers is the use of lexical information in the
tagged corpus, they are called “lexicalized parsers”.
Unlexicalized parsers, on the other hand, achieved
accuracies almost equivalent to those of lexicalized
parsers (Klein and Manning, 2003; Matsuzaki et al.,
2005; Petrov et al., 2006). Accordingly, we can
say that the state-of-the-art lexicalized parsers are
mainly based on unlexical (grammatical) informa-
tion due to the sparse data problem. Bikel also in-
dicated that Collins’ parser can use bilexical depen-
dencies only 1.49% of the time; the rest of the time,
it backs off to condition one word on just phrasal and
part-of-speech categories (Bikel, 2004).
This paper describes our investigation into the ef-
fectiveness of lexicalization in dependency parsing
instead of phrase-structure parsing. Usual depen-
dency parsing cannot utilize phrase categories, and
thus relies on word information like parts of speech
and lexicalized words. Therefore, we want to know
the performance of dependency parsers that have
minimal or low lexicalization.
Dependency trees have been used in a variety of
NLP applications, such as relation extraction (Cu-
lotta and Sorensen, 2004) and machine translation
(Ding and Palmer, 2005). For such applications, a
fast, efficient and accurate dependency parser is re-
quired to obtain dependency trees from a large cor-
pus. From this point of view, minimally lexicalized
parsers have advantages over fully lexicalized ones
in parsing speed and memory consumption.
We examined the change in performance of de-
pendency parsing by varying the degree of lexical-
ization. The degree of lexicalization is specified by
giving a list of words to be lexicalized, which appear
in a training corpus. For minimal lexicalization, we
used a short list that consists of only high-frequency
words, and for maximal lexicalization, the whole list
was used. Consequently, minimally or low lexical-
ization is sufficient for dependency accuracy.
</bodyText>
<sectionHeader confidence="0.999803" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9984155">
Klein and Manning presented an unlexicalized
PCFG parser that eliminated all the lexicalized pa-
rameters (Klein and Manning, 2003). They manu-
ally split category tags from a linguistic view. This
corresponds to determining the degree of lexicaliza-
tion by hand. Their parser achieved an F1 of 85.7%
for section 23 of the Penn Treebank. Matsuzaki et al.
and Petrov et al. proposed an automatic approach to
</bodyText>
<page confidence="0.988391">
205
</page>
<tableCaption confidence="0.778424222222222">
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 205–208,
Prague, June 2007. c�2007 Association for Computational Linguistics
Dependency accuracy (DA) Proportions of words, except
punctuation marks, that are assigned the correct heads.
Root accuracy (RA) Proportions of root words that are cor-
rectly detected.
Complete rate (CR) Proportions of sentences whose depen-
dency structures are completely correct.
Table 1: Evaluation criteria.
</tableCaption>
<table confidence="0.99973675">
DA RA CR
(Yamada and Matsumoto, 2003) 90.3 91.6 38.4
(Nivre and Scholz, 2004) 87.3 84.3 30.4
(Isozaki et al., 2004) 91.2 95.7 40.7
(McDonald et al., 2005) 90.9 94.2 37.5
(McDonald and Pereira, 2006) 91.5 N/A 42.1
(Corston-Oliver et al., 2006) 90.8 93.7 37.6
Our Base Parser 90.9 92.6 39.2
</table>
<tableCaption confidence="0.999917">
Table 2: Comparison of parser performance.
</tableCaption>
<bodyText confidence="0.9997652">
splitting tags (Matsuzaki et al., 2005; Petrov et al.,
2006). In particular, Petrov et al. reported an F1 of
90.2%, which is equivalent to that of state-of-the-art
lexicalized parsers.
Dependency parsing has been actively studied in
recent years (Yamada and Matsumoto, 2003; Nivre
and Scholz, 2004; Isozaki et al., 2004; McDon-
ald et al., 2005; McDonald and Pereira, 2006;
Corston-Oliver et al., 2006). For instance, Nivre
and Scholz presented a deterministic dependency
parser trained by memory-based learning (Nivre and
Scholz, 2004). McDonald et al. proposed an on-
line large-margin method for training dependency
parsers (McDonald et al., 2005). All of them per-
formed experiments using section 23 of the Penn
Treebank. Table 2 summarizes their dependency ac-
curacies based on three evaluation criteria shown in
Table 1. These parsers believed in the generalization
ability of machine learners and did not pay attention
to the issue of lexicalization.
</bodyText>
<sectionHeader confidence="0.7994885" genericHeader="method">
3 Minimally Lexicalized Dependency
Parsing
</sectionHeader>
<bodyText confidence="0.999981">
We present a simple method for changing the de-
gree of lexicalization in dependency parsing. This
method restricts the use of lexicalized words, so it is
the opposite to tag splitting in phrase-structure pars-
ing. In the remainder of this section, we first de-
scribe a base dependency parser and then report ex-
perimental results.
</bodyText>
<subsectionHeader confidence="0.999925">
3.1 Base Dependency Parser
</subsectionHeader>
<bodyText confidence="0.989603318181818">
We built a parser based on the deterministic algo-
rithm of Nivre and Scholz (Nivre and Scholz, 2004)
as a base dependency parser. We adopted this algo-
rithm because of its linear-time complexity.
In the algorithm, parsing states are represented by
triples (S, I, A), where S is the stack that keeps the
words being under consideration, I is the list of re-
maining input words, and A is the list of determined
dependencies. Given an input word sequence, W,
the parser is first initialized to the triple (nil, W, φ)1.
The parser estimates a dependency relation between
two words (the top elements of stacks S and I). The
algorithm iterates until the list I is empty. There are
four possible operations for a parsing state (where t
is the word on top of S, n is the next input word in
I, and w is any word):
Left In a state (t|S, n|I, A), if there is no depen-
dency relation (t —* w) in A, add the new de-
pendency relation (t —* n) into A and pop S
(remove t), giving the state (S, n|I, A U (t —*
n)).
Right In a state (t|S, n|I, A), if there is no depen-
dency relation (n —* w) in A, add the new de-
pendency relation (n —* t) into A and push n
onto S, giving the state (n|t|S, I, AU(n —* t)).
Reduce In a state (t|S, I, A), if there is a depen-
dency relation (t —* w) in A, pop S, giving the
state (S, I, A).
Shift In a state (S, n|I, A), push n onto S, giving
the state (n|S, I, A).
In this work, we used Support Vector Machines
(SVMs) to predict the operation given a parsing
state. Since SVMs are binary classifiers, we used the
pair-wise method to extend them in order to classify
our four-class task.
The features of a node are the word’s lemma,
the POS/chunk tag and the information of its child
node(s). The lemma is obtained from the word form
using a lemmatizer, except for numbers, which are
replaced by “(num)”. The context features are the
two preceding nodes of node t (and t itself), the two
succeeding nodes of node n (and n itself), and their
&apos;We use “nil” to denote an empty list and ajA to denote a
list with head a and tail A.
</bodyText>
<page confidence="0.987326">
206
</page>
<figure confidence="0.9990883">
Accuracy (%)
88.4
88.2
87.8
87.6
87.4
87.2
88
87
Accuracy (%)
84.8
84.6
84.4
84.2
83.8
83.6
85
84
0 1000 2000 3000 4000 5000
Number of Lexicalized Words
</figure>
<figureCaption confidence="0.9970345">
Figure 1: Dependency accuracies on the WSJ while
changing the degree of lexicalization.
</figureCaption>
<figure confidence="0.9984955">
0 1000 2000 3000 4000 5000
Number of Lexicalized Words
</figure>
<figureCaption confidence="0.905499">
Figure 2: Dependency accuracies on the Brown Cor-
pus while changing the degree of lexicalization.
</figureCaption>
<bodyText confidence="0.996026470588235">
child nodes (lemmas and POS tags). The distance
between nodes n and t is also used as a feature.
We trained our models on sections 2-21 of the
WSJ portion of the Penn Treebank. We used sec-
tion 23 as the test set. Since the original treebank is
based on phrase structure, we converted the treebank
to dependencies using the head rules provided by
Yamada 2. During the training phase, we used intact
POS and chunk tags3. During the testing phase, we
used automatically assigned POS and chunk tags by
Tsuruoka’s tagger4(Tsuruoka and Tsujii, 2005) and
YamCha chunker5(Kudo and Matsumoto, 2001).
We used an SVMs package, TinySVM6,and trained
the SVMs classifiers using a third-order polynomial
kernel. The other parameters are set to default.
The last row in Table 2 shows the accuracies of
our base dependency parser.
</bodyText>
<subsectionHeader confidence="0.999971">
3.2 Degree of Lexicalization vs. Performance
</subsectionHeader>
<bodyText confidence="0.999784571428571">
The degree of lexicalization is specified by giving
a list of words to be lexicalized, which appear in
a training corpus. For minimal lexicalization, we
used a short list that consists of only high-frequency
words, and for maximal lexicalization, the whole list
was used.
To conduct the experiments efficiently, we trained
</bodyText>
<footnote confidence="0.999414142857143">
2http://www.jaist.ac.jp/˜h-yamada/
3In a preliminary experiment, we tried to use automatically
assigned POS and chunk tags, but we did not detect significant
difference in performance.
4http://www-tsujii.is.s.u-tokyo.ac.jp/˜tsuruoka/postagger/
5http://chasen.org/˜taku-ku/software/yamcha/
6http://chasen.org/˜taku-ku/software/TinySVM/
</footnote>
<bodyText confidence="0.9989049375">
our models using the first 10,000 sentences in sec-
tions 2-21 of the WSJ portion of the Penn Treebank.
We used section 24, which is usually used as the
development set, to measure the change in perfor-
mance based on the degree of lexicalization.
We counted word (lemma) frequencies in the
training corpus and made a word list in descending
order of their frequencies. The resultant list con-
sists of 13,729 words, and the most frequent word is
“the”, which occurs 13,252 times, as shown in Table
3. We define the degree of lexicalization as a thresh-
old of the word list. If, for example, this threshold is
set to 1,000, the top 1,000 most frequently occurring
words are lexicalized.
We evaluated dependency accuracies while
changing the threshold of lexicalization. Figure 1
shows the result. The dotted line (88.23%) repre-
sents the dependency accuracy of the maximal lex-
icalization, that is, using the whole word list. We
can see that the decrease in accuracy is less than
1% at the minimal lexicalization (degree=100) and
the accuracy of more than 3,000 degree slightly ex-
ceeds that of the maximal lexicalization. The best
accuracy (88.34%) was achieved at 4,500 degree and
significantly outperformed the accuracy (88.23%) of
the maximal lexicalization (McNemar’s test; p =
0.017 &lt; 0.05). These results indicate that maximal
lexicalization is not so effective for obtaining accu-
rate dependency relations.
We also applied the same trained models to the
Brown Corpus as an experiment of parser adapta-
tion. We first split the Brown Corpus portion of
</bodyText>
<page confidence="0.99316">
207
</page>
<table confidence="0.999724642857143">
rank word freq. rank word freq.
1 ... 13,252 1,000 ... 29
2 . ... 12,858 . ... .
100 ... . 2,000 ... 12
500 . ... 261 . ... .
... . 3,000 ... 7
. ... 64 . ... .
the . watch
, .
. healthvest
week .
. whoop
estate .
.
</table>
<tableCaption confidence="0.999898">
Table 3: Word list.
</tableCaption>
<bodyText confidence="0.999696272727273">
the Penn Treebank into training and testing parts in
the same way as (Roark and Bacchiani, 2003). We
further extracted 2,425 sentences at regular intervals
from the training part and used them to measure the
change in performance while varying the degree of
lexicalization. Figure 2 shows the result. The dot-
ted line (84.75%) represents the accuracy of maxi-
mal lexicalization. The resultant curve is similar to
that of the WSJ experiment7. We can say that our
claim is true even if the testing corpus is outside the
domain.
</bodyText>
<subsectionHeader confidence="0.958111">
3.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999995466666667">
We have presented a minimally or lowly lexical-
ized dependency parser. Its dependency accuracy is
close or almost equivalent to that of fully lexicalized
parsers, despite the lexicalization restriction. Fur-
thermore, the restriction reduces the time and space
complexity. The minimally lexicalized parser (de-
gree=100) took 12m46s to parse the WSJ develop-
ment set and required 111 MB memory. These are
36% of time and 45% of memory reduction, com-
pared to the fully lexicalized one.
The experimental results imply that training cor-
pora are too small to demonstrate the full potential
of lexicalization. We should consider unsupervised
or semi-supervised ways to make lexicalized parsers
more effective and accurate.
</bodyText>
<sectionHeader confidence="0.959815" genericHeader="conclusions">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.867129">
This research is partially supported by special coor-
dination funds for promoting science and technol-
ogy.
</bodyText>
<footnote confidence="0.8923415">
7In the experiment on the Brown Corpus, the difference be-
tween the best accuracy and the baseline was not significant.
</footnote>
<sectionHeader confidence="0.904338" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999825596153846">
Daniel M. Bikel. 2004. Intricacies of Collins’ parsing model.
Computational Linguistics, 30(4):479–511.
Eugene Charniak. 2000. A maximum-entropy-inspired parser.
In Proceedings of NAACL2000, pages 132–139.
Michael Collins. 1999. Head-Driven Statistical Models for
Natural Language Parsing. Ph.D. thesis, University of
Pennsylvania.
Simon Corston-Oliver, Anthony Aue, Kevin Duh, and Eric
Ringger. 2006. Multilingual dependency parsing using
bayes point machines. In Proceedings of HLT-NAACL2006,
pages 160–167.
Aron Culotta and Jeffrey Sorensen. 2004. Dependency tree
kernels for relation extraction. In Proceedings of ACL2004,
pages 423–429.
Yuan Ding and Martha Palmer. 2005. Machine translation
using probabilistic synchronous dependency insertion gram-
mars. In Proceedings of ACL2005, pages 541–548.
Hideki Isozaki, Hideto Kazawa, and Tsutomu Hirao. 2004.
A deterministic word dependency analyzer enhanced with
preference learning. In Proceedings of COLING2004, pages
275–281.
Dan Klein and Christopher D. Manning. 2003. Accurate un-
lexicalized parsing. In Proceedings ofACL2003, pages 423–
430.
Taku Kudo and Yuji Matsumoto. 2001. Chunking with sup-
port vector machines. In Proceedings of NAACL2001, pages
192–199.
Takuya Matsuzaki, Yusuke Miyao, and Jun’ichi Tsujii. 2005.
Probabilistic CFG with latent annotations. In Proceedings
of ACL2005, pages 75–82.
Ryan McDonald and Fernando Pereira. 2006. Online learning
of approximate dependency parsing algorithms. In Proceed-
ings of EACL2006, pages 81–88.
Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005.
Online large-margin training of dependency parsers. In Pro-
ceedings of ACL2005, pages 91–98.
Joakim Nivre and Mario Scholz. 2004. Deterministic de-
pendency parsing of English text. In Proceedings of COL-
ING2004, pages 64–70.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein.
2006. Learning accurate, compact, and interpretable tree an-
notation. In Proceedings of COLING-ACL2006, pages 433–
440.
Brian Roark and Michiel Bacchiani. 2003. Supervised and un-
supervised PCFG adaptation to novel domains. In Proceed-
ings of HLT-NAACL2003, pages 205–212.
Yoshimasa Tsuruoka and Jun’ichi Tsujii. 2005. Bidirectional
inference with the easiest-first strategy for tagging sequence
data. In Proceedings of HLT-EMNLP2005, pages 467–474.
Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical de-
pendency analysis with support vector machines. In Pro-
ceedings of IWPT2003, pages 195–206.
</reference>
<page confidence="0.997776">
208
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.974267">
<title confidence="0.999687">Minimally Lexicalized Dependency Parsing</title>
<author confidence="0.992963">Kawahara Uchimoto</author>
<affiliation confidence="0.999986">National Institute of Information and Communications Technology,</affiliation>
<address confidence="0.997653">3-5 Hikaridai Seika-cho Soraku-gun, Kyoto, 619-0289, Japan</address>
<abstract confidence="0.998835">Dependency structures do not have the information of phrase categories in phrase structure grammar. Thus, dependency parsing relies heavily on the lexical information of words. This paper discusses our investigation into the effectiveness of lexicalization in dependency parsing. Specifically, by restricting the degree of lexicalization in the training phase of a parser, we examine the change in the accuracy of dependency relations. Experimental results indicate that minimal or low lexicalization is sufficient for parsing accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
</authors>
<date>2004</date>
<journal>Intricacies of Collins’ parsing model. Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="1608" citStr="Bikel, 2004" startWordPosition="231" endWordPosition="232">he tagged corpus, they are called “lexicalized parsers”. Unlexicalized parsers, on the other hand, achieved accuracies almost equivalent to those of lexicalized parsers (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006). Accordingly, we can say that the state-of-the-art lexicalized parsers are mainly based on unlexical (grammatical) information due to the sparse data problem. Bikel also indicated that Collins’ parser can use bilexical dependencies only 1.49% of the time; the rest of the time, it backs off to condition one word on just phrasal and part-of-speech categories (Bikel, 2004). This paper describes our investigation into the effectiveness of lexicalization in dependency parsing instead of phrase-structure parsing. Usual dependency parsing cannot utilize phrase categories, and thus relies on word information like parts of speech and lexicalized words. Therefore, we want to know the performance of dependency parsers that have minimal or low lexicalization. Dependency trees have been used in a variety of NLP applications, such as relation extraction (Culotta and Sorensen, 2004) and machine translation (Ding and Palmer, 2005). For such applications, a fast, efficient a</context>
</contexts>
<marker>Bikel, 2004</marker>
<rawString>Daniel M. Bikel. 2004. Intricacies of Collins’ parsing model. Computational Linguistics, 30(4):479–511.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of NAACL2000,</booktitle>
<pages>132--139</pages>
<contexts>
<context position="905" citStr="Charniak, 2000" startWordPosition="121" endWordPosition="122">f phrase categories in phrase structure grammar. Thus, dependency parsing relies heavily on the lexical information of words. This paper discusses our investigation into the effectiveness of lexicalization in dependency parsing. Specifically, by restricting the degree of lexicalization in the training phase of a parser, we examine the change in the accuracy of dependency relations. Experimental results indicate that minimal or low lexicalization is sufficient for parsing accuracy. 1 Introduction In recent years, many accurate phrase-structure parsers have been developed (e.g., (Collins, 1999; Charniak, 2000)). Since one of the characteristics of these parsers is the use of lexical information in the tagged corpus, they are called “lexicalized parsers”. Unlexicalized parsers, on the other hand, achieved accuracies almost equivalent to those of lexicalized parsers (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006). Accordingly, we can say that the state-of-the-art lexicalized parsers are mainly based on unlexical (grammatical) information due to the sparse data problem. Bikel also indicated that Collins’ parser can use bilexical dependencies only 1.49% of the time; the rest of t</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A maximum-entropy-inspired parser. In Proceedings of NAACL2000, pages 132–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="888" citStr="Collins, 1999" startWordPosition="119" endWordPosition="120">e information of phrase categories in phrase structure grammar. Thus, dependency parsing relies heavily on the lexical information of words. This paper discusses our investigation into the effectiveness of lexicalization in dependency parsing. Specifically, by restricting the degree of lexicalization in the training phase of a parser, we examine the change in the accuracy of dependency relations. Experimental results indicate that minimal or low lexicalization is sufficient for parsing accuracy. 1 Introduction In recent years, many accurate phrase-structure parsers have been developed (e.g., (Collins, 1999; Charniak, 2000)). Since one of the characteristics of these parsers is the use of lexical information in the tagged corpus, they are called “lexicalized parsers”. Unlexicalized parsers, on the other hand, achieved accuracies almost equivalent to those of lexicalized parsers (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006). Accordingly, we can say that the state-of-the-art lexicalized parsers are mainly based on unlexical (grammatical) information due to the sparse data problem. Bikel also indicated that Collins’ parser can use bilexical dependencies only 1.49% of the ti</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Corston-Oliver</author>
<author>Anthony Aue</author>
<author>Kevin Duh</author>
<author>Eric Ringger</author>
</authors>
<title>Multilingual dependency parsing using bayes point machines.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL2006,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="4006" citStr="Corston-Oliver et al., 2006" startWordPosition="600" endWordPosition="603">05–208, Prague, June 2007. c�2007 Association for Computational Linguistics Dependency accuracy (DA) Proportions of words, except punctuation marks, that are assigned the correct heads. Root accuracy (RA) Proportions of root words that are correctly detected. Complete rate (CR) Proportions of sentences whose dependency structures are completely correct. Table 1: Evaluation criteria. DA RA CR (Yamada and Matsumoto, 2003) 90.3 91.6 38.4 (Nivre and Scholz, 2004) 87.3 84.3 30.4 (Isozaki et al., 2004) 91.2 95.7 40.7 (McDonald et al., 2005) 90.9 94.2 37.5 (McDonald and Pereira, 2006) 91.5 N/A 42.1 (Corston-Oliver et al., 2006) 90.8 93.7 37.6 Our Base Parser 90.9 92.6 39.2 Table 2: Comparison of parser performance. splitting tags (Matsuzaki et al., 2005; Petrov et al., 2006). In particular, Petrov et al. reported an F1 of 90.2%, which is equivalent to that of state-of-the-art lexicalized parsers. Dependency parsing has been actively studied in recent years (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; Isozaki et al., 2004; McDonald et al., 2005; McDonald and Pereira, 2006; Corston-Oliver et al., 2006). For instance, Nivre and Scholz presented a deterministic dependency parser trained by memory-based learning </context>
</contexts>
<marker>Corston-Oliver, Aue, Duh, Ringger, 2006</marker>
<rawString>Simon Corston-Oliver, Anthony Aue, Kevin Duh, and Eric Ringger. 2006. Multilingual dependency parsing using bayes point machines. In Proceedings of HLT-NAACL2006, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Jeffrey Sorensen</author>
</authors>
<title>Dependency tree kernels for relation extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL2004,</booktitle>
<pages>423--429</pages>
<contexts>
<context position="2116" citStr="Culotta and Sorensen, 2004" startWordPosition="303" endWordPosition="307">e; the rest of the time, it backs off to condition one word on just phrasal and part-of-speech categories (Bikel, 2004). This paper describes our investigation into the effectiveness of lexicalization in dependency parsing instead of phrase-structure parsing. Usual dependency parsing cannot utilize phrase categories, and thus relies on word information like parts of speech and lexicalized words. Therefore, we want to know the performance of dependency parsers that have minimal or low lexicalization. Dependency trees have been used in a variety of NLP applications, such as relation extraction (Culotta and Sorensen, 2004) and machine translation (Ding and Palmer, 2005). For such applications, a fast, efficient and accurate dependency parser is required to obtain dependency trees from a large corpus. From this point of view, minimally lexicalized parsers have advantages over fully lexicalized ones in parsing speed and memory consumption. We examined the change in performance of dependency parsing by varying the degree of lexicalization. The degree of lexicalization is specified by giving a list of words to be lexicalized, which appear in a training corpus. For minimal lexicalization, we used a short list that c</context>
</contexts>
<marker>Culotta, Sorensen, 2004</marker>
<rawString>Aron Culotta and Jeffrey Sorensen. 2004. Dependency tree kernels for relation extraction. In Proceedings of ACL2004, pages 423–429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuan Ding</author>
<author>Martha Palmer</author>
</authors>
<title>Machine translation using probabilistic synchronous dependency insertion grammars.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL2005,</booktitle>
<pages>541--548</pages>
<contexts>
<context position="2164" citStr="Ding and Palmer, 2005" startWordPosition="311" endWordPosition="314">e word on just phrasal and part-of-speech categories (Bikel, 2004). This paper describes our investigation into the effectiveness of lexicalization in dependency parsing instead of phrase-structure parsing. Usual dependency parsing cannot utilize phrase categories, and thus relies on word information like parts of speech and lexicalized words. Therefore, we want to know the performance of dependency parsers that have minimal or low lexicalization. Dependency trees have been used in a variety of NLP applications, such as relation extraction (Culotta and Sorensen, 2004) and machine translation (Ding and Palmer, 2005). For such applications, a fast, efficient and accurate dependency parser is required to obtain dependency trees from a large corpus. From this point of view, minimally lexicalized parsers have advantages over fully lexicalized ones in parsing speed and memory consumption. We examined the change in performance of dependency parsing by varying the degree of lexicalization. The degree of lexicalization is specified by giving a list of words to be lexicalized, which appear in a training corpus. For minimal lexicalization, we used a short list that consists of only high-frequency words, and for ma</context>
</contexts>
<marker>Ding, Palmer, 2005</marker>
<rawString>Yuan Ding and Martha Palmer. 2005. Machine translation using probabilistic synchronous dependency insertion grammars. In Proceedings of ACL2005, pages 541–548.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Isozaki</author>
<author>Hideto Kazawa</author>
<author>Tsutomu Hirao</author>
</authors>
<title>A deterministic word dependency analyzer enhanced with preference learning.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING2004,</booktitle>
<pages>275--281</pages>
<contexts>
<context position="3879" citStr="Isozaki et al., 2004" startWordPosition="579" endWordPosition="582">l. and Petrov et al. proposed an automatic approach to 205 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 205–208, Prague, June 2007. c�2007 Association for Computational Linguistics Dependency accuracy (DA) Proportions of words, except punctuation marks, that are assigned the correct heads. Root accuracy (RA) Proportions of root words that are correctly detected. Complete rate (CR) Proportions of sentences whose dependency structures are completely correct. Table 1: Evaluation criteria. DA RA CR (Yamada and Matsumoto, 2003) 90.3 91.6 38.4 (Nivre and Scholz, 2004) 87.3 84.3 30.4 (Isozaki et al., 2004) 91.2 95.7 40.7 (McDonald et al., 2005) 90.9 94.2 37.5 (McDonald and Pereira, 2006) 91.5 N/A 42.1 (Corston-Oliver et al., 2006) 90.8 93.7 37.6 Our Base Parser 90.9 92.6 39.2 Table 2: Comparison of parser performance. splitting tags (Matsuzaki et al., 2005; Petrov et al., 2006). In particular, Petrov et al. reported an F1 of 90.2%, which is equivalent to that of state-of-the-art lexicalized parsers. Dependency parsing has been actively studied in recent years (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; Isozaki et al., 2004; McDonald et al., 2005; McDonald and Pereira, 2006; Corston-Oli</context>
</contexts>
<marker>Isozaki, Kazawa, Hirao, 2004</marker>
<rawString>Hideki Isozaki, Hideto Kazawa, and Tsutomu Hirao. 2004. A deterministic word dependency analyzer enhanced with preference learning. In Proceedings of COLING2004, pages 275–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings ofACL2003,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="1189" citStr="Klein and Manning, 2003" startWordPosition="161" endWordPosition="164">calization in the training phase of a parser, we examine the change in the accuracy of dependency relations. Experimental results indicate that minimal or low lexicalization is sufficient for parsing accuracy. 1 Introduction In recent years, many accurate phrase-structure parsers have been developed (e.g., (Collins, 1999; Charniak, 2000)). Since one of the characteristics of these parsers is the use of lexical information in the tagged corpus, they are called “lexicalized parsers”. Unlexicalized parsers, on the other hand, achieved accuracies almost equivalent to those of lexicalized parsers (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006). Accordingly, we can say that the state-of-the-art lexicalized parsers are mainly based on unlexical (grammatical) information due to the sparse data problem. Bikel also indicated that Collins’ parser can use bilexical dependencies only 1.49% of the time; the rest of the time, it backs off to condition one word on just phrasal and part-of-speech categories (Bikel, 2004). This paper describes our investigation into the effectiveness of lexicalization in dependency parsing instead of phrase-structure parsing. Usual dependency parsing cannot utilize </context>
<context position="3040" citStr="Klein and Manning, 2003" startWordPosition="447" endWordPosition="450">d memory consumption. We examined the change in performance of dependency parsing by varying the degree of lexicalization. The degree of lexicalization is specified by giving a list of words to be lexicalized, which appear in a training corpus. For minimal lexicalization, we used a short list that consists of only high-frequency words, and for maximal lexicalization, the whole list was used. Consequently, minimally or low lexicalization is sufficient for dependency accuracy. 2 Related Work Klein and Manning presented an unlexicalized PCFG parser that eliminated all the lexicalized parameters (Klein and Manning, 2003). They manually split category tags from a linguistic view. This corresponds to determining the degree of lexicalization by hand. Their parser achieved an F1 of 85.7% for section 23 of the Penn Treebank. Matsuzaki et al. and Petrov et al. proposed an automatic approach to 205 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 205–208, Prague, June 2007. c�2007 Association for Computational Linguistics Dependency accuracy (DA) Proportions of words, except punctuation marks, that are assigned the correct heads. Root accuracy (RA) Proportions of root words that are correctly detected. Co</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings ofACL2003, pages 423– 430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Chunking with support vector machines.</title>
<date>2001</date>
<booktitle>In Proceedings of NAACL2001,</booktitle>
<pages>192--199</pages>
<contexts>
<context position="8467" citStr="Kudo and Matsumoto, 2001" startWordPosition="1397" endWordPosition="1400">nging the degree of lexicalization. child nodes (lemmas and POS tags). The distance between nodes n and t is also used as a feature. We trained our models on sections 2-21 of the WSJ portion of the Penn Treebank. We used section 23 as the test set. Since the original treebank is based on phrase structure, we converted the treebank to dependencies using the head rules provided by Yamada 2. During the training phase, we used intact POS and chunk tags3. During the testing phase, we used automatically assigned POS and chunk tags by Tsuruoka’s tagger4(Tsuruoka and Tsujii, 2005) and YamCha chunker5(Kudo and Matsumoto, 2001). We used an SVMs package, TinySVM6,and trained the SVMs classifiers using a third-order polynomial kernel. The other parameters are set to default. The last row in Table 2 shows the accuracies of our base dependency parser. 3.2 Degree of Lexicalization vs. Performance The degree of lexicalization is specified by giving a list of words to be lexicalized, which appear in a training corpus. For minimal lexicalization, we used a short list that consists of only high-frequency words, and for maximal lexicalization, the whole list was used. To conduct the experiments efficiently, we trained 2http:/</context>
</contexts>
<marker>Kudo, Matsumoto, 2001</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2001. Chunking with support vector machines. In Proceedings of NAACL2001, pages 192–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takuya Matsuzaki</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Probabilistic CFG with latent annotations.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL2005,</booktitle>
<pages>75--82</pages>
<contexts>
<context position="1213" citStr="Matsuzaki et al., 2005" startWordPosition="165" endWordPosition="168">g phase of a parser, we examine the change in the accuracy of dependency relations. Experimental results indicate that minimal or low lexicalization is sufficient for parsing accuracy. 1 Introduction In recent years, many accurate phrase-structure parsers have been developed (e.g., (Collins, 1999; Charniak, 2000)). Since one of the characteristics of these parsers is the use of lexical information in the tagged corpus, they are called “lexicalized parsers”. Unlexicalized parsers, on the other hand, achieved accuracies almost equivalent to those of lexicalized parsers (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006). Accordingly, we can say that the state-of-the-art lexicalized parsers are mainly based on unlexical (grammatical) information due to the sparse data problem. Bikel also indicated that Collins’ parser can use bilexical dependencies only 1.49% of the time; the rest of the time, it backs off to condition one word on just phrasal and part-of-speech categories (Bikel, 2004). This paper describes our investigation into the effectiveness of lexicalization in dependency parsing instead of phrase-structure parsing. Usual dependency parsing cannot utilize phrase categories, and t</context>
<context position="4134" citStr="Matsuzaki et al., 2005" startWordPosition="621" endWordPosition="624">tuation marks, that are assigned the correct heads. Root accuracy (RA) Proportions of root words that are correctly detected. Complete rate (CR) Proportions of sentences whose dependency structures are completely correct. Table 1: Evaluation criteria. DA RA CR (Yamada and Matsumoto, 2003) 90.3 91.6 38.4 (Nivre and Scholz, 2004) 87.3 84.3 30.4 (Isozaki et al., 2004) 91.2 95.7 40.7 (McDonald et al., 2005) 90.9 94.2 37.5 (McDonald and Pereira, 2006) 91.5 N/A 42.1 (Corston-Oliver et al., 2006) 90.8 93.7 37.6 Our Base Parser 90.9 92.6 39.2 Table 2: Comparison of parser performance. splitting tags (Matsuzaki et al., 2005; Petrov et al., 2006). In particular, Petrov et al. reported an F1 of 90.2%, which is equivalent to that of state-of-the-art lexicalized parsers. Dependency parsing has been actively studied in recent years (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; Isozaki et al., 2004; McDonald et al., 2005; McDonald and Pereira, 2006; Corston-Oliver et al., 2006). For instance, Nivre and Scholz presented a deterministic dependency parser trained by memory-based learning (Nivre and Scholz, 2004). McDonald et al. proposed an online large-margin method for training dependency parsers (McDonald et al</context>
</contexts>
<marker>Matsuzaki, Miyao, Tsujii, 2005</marker>
<rawString>Takuya Matsuzaki, Yusuke Miyao, and Jun’ichi Tsujii. 2005. Probabilistic CFG with latent annotations. In Proceedings of ACL2005, pages 75–82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL2006,</booktitle>
<pages>81--88</pages>
<contexts>
<context position="3962" citStr="McDonald and Pereira, 2006" startWordPosition="593" endWordPosition="596"> ACL 2007 Demo and Poster Sessions, pages 205–208, Prague, June 2007. c�2007 Association for Computational Linguistics Dependency accuracy (DA) Proportions of words, except punctuation marks, that are assigned the correct heads. Root accuracy (RA) Proportions of root words that are correctly detected. Complete rate (CR) Proportions of sentences whose dependency structures are completely correct. Table 1: Evaluation criteria. DA RA CR (Yamada and Matsumoto, 2003) 90.3 91.6 38.4 (Nivre and Scholz, 2004) 87.3 84.3 30.4 (Isozaki et al., 2004) 91.2 95.7 40.7 (McDonald et al., 2005) 90.9 94.2 37.5 (McDonald and Pereira, 2006) 91.5 N/A 42.1 (Corston-Oliver et al., 2006) 90.8 93.7 37.6 Our Base Parser 90.9 92.6 39.2 Table 2: Comparison of parser performance. splitting tags (Matsuzaki et al., 2005; Petrov et al., 2006). In particular, Petrov et al. reported an F1 of 90.2%, which is equivalent to that of state-of-the-art lexicalized parsers. Dependency parsing has been actively studied in recent years (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; Isozaki et al., 2004; McDonald et al., 2005; McDonald and Pereira, 2006; Corston-Oliver et al., 2006). For instance, Nivre and Scholz presented a deterministic depende</context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>Ryan McDonald and Fernando Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proceedings of EACL2006, pages 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL2005,</booktitle>
<pages>91--98</pages>
<contexts>
<context position="3918" citStr="McDonald et al., 2005" startWordPosition="586" endWordPosition="589">atic approach to 205 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 205–208, Prague, June 2007. c�2007 Association for Computational Linguistics Dependency accuracy (DA) Proportions of words, except punctuation marks, that are assigned the correct heads. Root accuracy (RA) Proportions of root words that are correctly detected. Complete rate (CR) Proportions of sentences whose dependency structures are completely correct. Table 1: Evaluation criteria. DA RA CR (Yamada and Matsumoto, 2003) 90.3 91.6 38.4 (Nivre and Scholz, 2004) 87.3 84.3 30.4 (Isozaki et al., 2004) 91.2 95.7 40.7 (McDonald et al., 2005) 90.9 94.2 37.5 (McDonald and Pereira, 2006) 91.5 N/A 42.1 (Corston-Oliver et al., 2006) 90.8 93.7 37.6 Our Base Parser 90.9 92.6 39.2 Table 2: Comparison of parser performance. splitting tags (Matsuzaki et al., 2005; Petrov et al., 2006). In particular, Petrov et al. reported an F1 of 90.2%, which is equivalent to that of state-of-the-art lexicalized parsers. Dependency parsing has been actively studied in recent years (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; Isozaki et al., 2004; McDonald et al., 2005; McDonald and Pereira, 2006; Corston-Oliver et al., 2006). For instance, Nivre </context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005. Online large-margin training of dependency parsers. In Proceedings of ACL2005, pages 91–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Mario Scholz</author>
</authors>
<title>Deterministic dependency parsing of English text.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING2004,</booktitle>
<pages>64--70</pages>
<contexts>
<context position="3841" citStr="Nivre and Scholz, 2004" startWordPosition="572" endWordPosition="575"> 23 of the Penn Treebank. Matsuzaki et al. and Petrov et al. proposed an automatic approach to 205 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 205–208, Prague, June 2007. c�2007 Association for Computational Linguistics Dependency accuracy (DA) Proportions of words, except punctuation marks, that are assigned the correct heads. Root accuracy (RA) Proportions of root words that are correctly detected. Complete rate (CR) Proportions of sentences whose dependency structures are completely correct. Table 1: Evaluation criteria. DA RA CR (Yamada and Matsumoto, 2003) 90.3 91.6 38.4 (Nivre and Scholz, 2004) 87.3 84.3 30.4 (Isozaki et al., 2004) 91.2 95.7 40.7 (McDonald et al., 2005) 90.9 94.2 37.5 (McDonald and Pereira, 2006) 91.5 N/A 42.1 (Corston-Oliver et al., 2006) 90.8 93.7 37.6 Our Base Parser 90.9 92.6 39.2 Table 2: Comparison of parser performance. splitting tags (Matsuzaki et al., 2005; Petrov et al., 2006). In particular, Petrov et al. reported an F1 of 90.2%, which is equivalent to that of state-of-the-art lexicalized parsers. Dependency parsing has been actively studied in recent years (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; Isozaki et al., 2004; McDonald et al., 2005; M</context>
<context position="5544" citStr="Nivre and Scholz, 2004" startWordPosition="844" endWordPosition="847">e parsers believed in the generalization ability of machine learners and did not pay attention to the issue of lexicalization. 3 Minimally Lexicalized Dependency Parsing We present a simple method for changing the degree of lexicalization in dependency parsing. This method restricts the use of lexicalized words, so it is the opposite to tag splitting in phrase-structure parsing. In the remainder of this section, we first describe a base dependency parser and then report experimental results. 3.1 Base Dependency Parser We built a parser based on the deterministic algorithm of Nivre and Scholz (Nivre and Scholz, 2004) as a base dependency parser. We adopted this algorithm because of its linear-time complexity. In the algorithm, parsing states are represented by triples (S, I, A), where S is the stack that keeps the words being under consideration, I is the list of remaining input words, and A is the list of determined dependencies. Given an input word sequence, W, the parser is first initialized to the triple (nil, W, φ)1. The parser estimates a dependency relation between two words (the top elements of stacks S and I). The algorithm iterates until the list I is empty. There are four possible operations fo</context>
</contexts>
<marker>Nivre, Scholz, 2004</marker>
<rawString>Joakim Nivre and Mario Scholz. 2004. Deterministic dependency parsing of English text. In Proceedings of COLING2004, pages 64–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL2006,</booktitle>
<pages>433--440</pages>
<contexts>
<context position="1235" citStr="Petrov et al., 2006" startWordPosition="169" endWordPosition="172">examine the change in the accuracy of dependency relations. Experimental results indicate that minimal or low lexicalization is sufficient for parsing accuracy. 1 Introduction In recent years, many accurate phrase-structure parsers have been developed (e.g., (Collins, 1999; Charniak, 2000)). Since one of the characteristics of these parsers is the use of lexical information in the tagged corpus, they are called “lexicalized parsers”. Unlexicalized parsers, on the other hand, achieved accuracies almost equivalent to those of lexicalized parsers (Klein and Manning, 2003; Matsuzaki et al., 2005; Petrov et al., 2006). Accordingly, we can say that the state-of-the-art lexicalized parsers are mainly based on unlexical (grammatical) information due to the sparse data problem. Bikel also indicated that Collins’ parser can use bilexical dependencies only 1.49% of the time; the rest of the time, it backs off to condition one word on just phrasal and part-of-speech categories (Bikel, 2004). This paper describes our investigation into the effectiveness of lexicalization in dependency parsing instead of phrase-structure parsing. Usual dependency parsing cannot utilize phrase categories, and thus relies on word inf</context>
<context position="4156" citStr="Petrov et al., 2006" startWordPosition="625" endWordPosition="628">assigned the correct heads. Root accuracy (RA) Proportions of root words that are correctly detected. Complete rate (CR) Proportions of sentences whose dependency structures are completely correct. Table 1: Evaluation criteria. DA RA CR (Yamada and Matsumoto, 2003) 90.3 91.6 38.4 (Nivre and Scholz, 2004) 87.3 84.3 30.4 (Isozaki et al., 2004) 91.2 95.7 40.7 (McDonald et al., 2005) 90.9 94.2 37.5 (McDonald and Pereira, 2006) 91.5 N/A 42.1 (Corston-Oliver et al., 2006) 90.8 93.7 37.6 Our Base Parser 90.9 92.6 39.2 Table 2: Comparison of parser performance. splitting tags (Matsuzaki et al., 2005; Petrov et al., 2006). In particular, Petrov et al. reported an F1 of 90.2%, which is equivalent to that of state-of-the-art lexicalized parsers. Dependency parsing has been actively studied in recent years (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; Isozaki et al., 2004; McDonald et al., 2005; McDonald and Pereira, 2006; Corston-Oliver et al., 2006). For instance, Nivre and Scholz presented a deterministic dependency parser trained by memory-based learning (Nivre and Scholz, 2004). McDonald et al. proposed an online large-margin method for training dependency parsers (McDonald et al., 2005). All of them </context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proceedings of COLING-ACL2006, pages 433– 440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Michiel Bacchiani</author>
</authors>
<title>Supervised and unsupervised PCFG adaptation to novel domains.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL2003,</booktitle>
<pages>205--212</pages>
<contexts>
<context position="11277" citStr="Roark and Bacchiani, 2003" startWordPosition="1853" endWordPosition="1856">emar’s test; p = 0.017 &lt; 0.05). These results indicate that maximal lexicalization is not so effective for obtaining accurate dependency relations. We also applied the same trained models to the Brown Corpus as an experiment of parser adaptation. We first split the Brown Corpus portion of 207 rank word freq. rank word freq. 1 ... 13,252 1,000 ... 29 2 . ... 12,858 . ... . 100 ... . 2,000 ... 12 500 . ... 261 . ... . ... . 3,000 ... 7 . ... 64 . ... . the . watch , . . healthvest week . . whoop estate . . Table 3: Word list. the Penn Treebank into training and testing parts in the same way as (Roark and Bacchiani, 2003). We further extracted 2,425 sentences at regular intervals from the training part and used them to measure the change in performance while varying the degree of lexicalization. Figure 2 shows the result. The dotted line (84.75%) represents the accuracy of maximal lexicalization. The resultant curve is similar to that of the WSJ experiment7. We can say that our claim is true even if the testing corpus is outside the domain. 3.3 Discussion We have presented a minimally or lowly lexicalized dependency parser. Its dependency accuracy is close or almost equivalent to that of fully lexicalized pars</context>
</contexts>
<marker>Roark, Bacchiani, 2003</marker>
<rawString>Brian Roark and Michiel Bacchiani. 2003. Supervised and unsupervised PCFG adaptation to novel domains. In Proceedings of HLT-NAACL2003, pages 205–212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshimasa Tsuruoka</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Bidirectional inference with the easiest-first strategy for tagging sequence data.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT-EMNLP2005,</booktitle>
<pages>467--474</pages>
<contexts>
<context position="8421" citStr="Tsuruoka and Tsujii, 2005" startWordPosition="1391" endWordPosition="1394">ndency accuracies on the Brown Corpus while changing the degree of lexicalization. child nodes (lemmas and POS tags). The distance between nodes n and t is also used as a feature. We trained our models on sections 2-21 of the WSJ portion of the Penn Treebank. We used section 23 as the test set. Since the original treebank is based on phrase structure, we converted the treebank to dependencies using the head rules provided by Yamada 2. During the training phase, we used intact POS and chunk tags3. During the testing phase, we used automatically assigned POS and chunk tags by Tsuruoka’s tagger4(Tsuruoka and Tsujii, 2005) and YamCha chunker5(Kudo and Matsumoto, 2001). We used an SVMs package, TinySVM6,and trained the SVMs classifiers using a third-order polynomial kernel. The other parameters are set to default. The last row in Table 2 shows the accuracies of our base dependency parser. 3.2 Degree of Lexicalization vs. Performance The degree of lexicalization is specified by giving a list of words to be lexicalized, which appear in a training corpus. For minimal lexicalization, we used a short list that consists of only high-frequency words, and for maximal lexicalization, the whole list was used. To conduct t</context>
</contexts>
<marker>Tsuruoka, Tsujii, 2005</marker>
<rawString>Yoshimasa Tsuruoka and Jun’ichi Tsujii. 2005. Bidirectional inference with the easiest-first strategy for tagging sequence data. In Proceedings of HLT-EMNLP2005, pages 467–474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyasu Yamada</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Statistical dependency analysis with support vector machines.</title>
<date>2003</date>
<booktitle>In Proceedings of IWPT2003,</booktitle>
<pages>195--206</pages>
<contexts>
<context position="3801" citStr="Yamada and Matsumoto, 2003" startWordPosition="565" endWordPosition="568">r parser achieved an F1 of 85.7% for section 23 of the Penn Treebank. Matsuzaki et al. and Petrov et al. proposed an automatic approach to 205 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 205–208, Prague, June 2007. c�2007 Association for Computational Linguistics Dependency accuracy (DA) Proportions of words, except punctuation marks, that are assigned the correct heads. Root accuracy (RA) Proportions of root words that are correctly detected. Complete rate (CR) Proportions of sentences whose dependency structures are completely correct. Table 1: Evaluation criteria. DA RA CR (Yamada and Matsumoto, 2003) 90.3 91.6 38.4 (Nivre and Scholz, 2004) 87.3 84.3 30.4 (Isozaki et al., 2004) 91.2 95.7 40.7 (McDonald et al., 2005) 90.9 94.2 37.5 (McDonald and Pereira, 2006) 91.5 N/A 42.1 (Corston-Oliver et al., 2006) 90.8 93.7 37.6 Our Base Parser 90.9 92.6 39.2 Table 2: Comparison of parser performance. splitting tags (Matsuzaki et al., 2005; Petrov et al., 2006). In particular, Petrov et al. reported an F1 of 90.2%, which is equivalent to that of state-of-the-art lexicalized parsers. Dependency parsing has been actively studied in recent years (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; Isozak</context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical dependency analysis with support vector machines. In Proceedings of IWPT2003, pages 195–206.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>