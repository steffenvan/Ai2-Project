<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000153">
<title confidence="0.970617">
Efficient Parsing of Well-Nested Linear Context-Free Rewriting Systems
</title>
<author confidence="0.999732">
Carlos Gómez-Rodríguez1, Marco Kuhlmann2, and Giorgio Satta3
</author>
<affiliation confidence="0.995755">
1Departamento de Computación, Universidade da Coruña, Spain, cgomezr@udc.es
2Department of Linguistics and Philology, Uppsala University, Sweden, marco.kuhlmann@lingfil.uu.se
3Department of Information Engineering, University of Padua, Italy, satta@dei.unipd.it
</affiliation>
<sectionHeader confidence="0.988936" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996609">
The use of well-nested linear context-free
rewriting systems has been empirically moti-
vated for modeling of the syntax of languages
with discontinuous constituents or relatively
free word order. We present a chart-based pars-
ing algorithm that asymptotically improves the
known running time upper bound for this class
of rewriting systems. Our result is obtained
through a linear space construction of a binary
normal form for the grammar at hand.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999956581818182">
Since its earliest years, one of the main goals of
computational linguistics has been the modeling of
natural language syntax by means of formal gram-
mars. Following results by Huybregts (1984) and
Shieber (1985), special attention has been given to
formalisms that enlarge the generative power of con-
text-free grammars, but still remain below the full
generative power of context-sensitive grammars. On
this line of investigation, mildly context-sensitive
grammar formalisms have been introduced (Joshi,
1985), including, among several others, the tree ad-
joining grammars (TAGs) of Joshi et al. (1975).
Linear context-free rewriting system (LCFRS), in-
troduced by Vijay-Shanker et al. (1987), is a mildly
context-sensitive formalism that allows the deriva-
tion of tuples of strings, i.e., discontinuous phrases.
This feature has been used to model phrase structure
treebanks with discontinuous constituents (Maier and
Søgaard, 2008), as well as to map non-projective de-
pendency trees into discontinuous phrase structures
(Kuhlmann and Satta, 2009).
Informally, in an LCFRS G, each nonterminal can
generate string tuples with a fixed number of compo-
nents. The fan-out of G is defined as the maximum
number of tuple components generated by G. During
a derivation of an LCFRS, tuple components gener-
ated by the nonterminals in the right-hand side of
a production are concatenated to form new tuples,
possibly adding some terminal symbols. The only re-
striction applying to these generalized concatenation
operations is linearity, that is, components cannot be
duplicated or deleted.
The freedom in the rearrangement of components
has specific consequences in terms of the computa-
tional and descriptional complexity of LCFRS. Even
for grammars with bounded fan-out, the universal
recognition problem is NP-hard (Satta, 1992), and
these systems lack Chomsky-like normal forms for
fixed fan-out (Rambow and Satta, 1999) that are es-
pecially convenient in tabular parsing. This is in con-
trast with other mildly context-sensitive formalisms,
and TAG in particular: TAGs can be parsed in poly-
nomial time both with respect to grammar size and
string size, and they can be cast in normal forms
having binary derivation trees only.
It has recently been argued that LCFRS might be
too powerful for modeling languages with discontin-
uous constituents or with relatively free word order,
and that additional restrictions on the rearrangement
of components might be needed. More specifically,
analyses of both dependency and constituency tree-
banks (Kuhlmann and Nivre, 2006; Havelka, 2007;
Maier and Lichte, 2009) have shown that rearrange-
ments of argument tuples almost always satisfy the
so-called well-nestedness condition, a generalization
</bodyText>
<page confidence="0.972687">
276
</page>
<note confidence="0.7521445">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 276–284,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999961230769231">
of the standard condition on balanced brackets. This
condition states that any two components x1, x2 of
some tuple will never be composed with any two
components y1, y2 of some other tuple in such a way
that a ‘crossing’ configuration is realized.
In this paper, we contribute to a better understand-
ing of the formal properties of well-nested LCFRS.
We show that, when fan-out is bounded by any inte-
ger ϕ ≥ 1, these systems can always be transformed,
in an efficient way, into a specific normal form with
no more than two nonterminals in their productions’
right-hand sides. On the basis of this result, we
then develop an efficient parsing algorithm for well-
nested LCFRS, running in time O(ϕ · |G |· |w|2ϕ+2),
where G and w are the input grammar and string,
respectively. Well-nested LCFRS with fan-out ϕ = 2
are weakly equivalent to TAG, and our complex-
ity result reduces to the well-known upper bound
O(|G |· |w|6) for this class. For ϕ &gt; 2, our upper
bound is asymptotically better than the one obtained
from existing parsing algorithms for general LCFRS
or equivalent formalisms (Seki et al., 1991).
Well-nested LCFRS are generatively equivalent
to (among others) coupled context-free grammars
(CCFG), introduced by Hotz and Pitsch (1996).
These authors also provide a normal form and de-
velop a parsing algorithm for CCFGs. One difference
with respect to our result is that the normal form for
CCFGs allows more than two nonterminals to appear
in the right-hand side of a production, even though no
nonterminal may contribute more than two tuple com-
ponents. Also, the construction in (Hotz and Pitsch,
1996) results in a blow-up of the grammar that is ex-
ponential in its fan-out, and the parsing algorithm that
is derived runs in time O(4ϕ · |G |· |w|2ϕ+2). Our
result is therefore a considerable asymptotic improve-
ment over the CCFG result, both with respect to the
normal form construction and the parsing efficiency.
Finally, under a practical perspective, our parser is a
simple chart-based algorithm, while the algorithm in
(Hotz and Pitsch, 1996) involves two passes and is
considerably more complex to analyze and to imple-
ment than ours.
Kanazawa and Salvati (2010) mention a normal
form for well-nested multiple context-free grammars.
Structure In Section 2, we introduce LCFRS and
the class of well-nested LCFRS that is the focus of
this paper. In Section 3, we discuss the parsing com-
plexity of LCFRS, and show why grammars using
our normal form can be parsed efficiently. Section 4
presents the transformation of a well-nested LCFRS
into the normal form. Section 5 concludes the paper.
</bodyText>
<sectionHeader confidence="0.963172" genericHeader="method">
2 Linear Context-Free Rewriting Systems
</sectionHeader>
<bodyText confidence="0.9999335">
We write [n] to denote the set of positive integers up
to and including n: [n] = {1, ... , n}.
</bodyText>
<subsectionHeader confidence="0.999135">
2.1 Linear, non-erasing functions
</subsectionHeader>
<bodyText confidence="0.9922445">
Let Σ be an alphabet. For integers m ≥ 0 and
k1, ... , km, k ≥ 1, a total function
</bodyText>
<equation confidence="0.976651">
f : (Σ*)k1 × ··· × (Σ*)km → (Σ*)k
</equation>
<bodyText confidence="0.907495555555556">
is called a linear, non-erasing function over Σ with
type k1 × · · · × km → k, if it can be defined by an
equation of the form
f(hx1,1, ... , x1,k1i, ... , hxm,1, ..., xm,kmi) = α~ ,
where α~ is a k-tuple of strings over the variables on
the left-hand side of the equation and Σ with the
property that each variable occurs in α~ exactly once.
The values m and k are called the rank and the fan-
out of f, and denoted by ρ(f) and ϕ(f).
</bodyText>
<subsectionHeader confidence="0.998364">
2.2 Linear Context-Free Rewriting Systems
</subsectionHeader>
<bodyText confidence="0.999782125">
For the purposes of this paper, a linear context-free
rewriting system, henceforth LCFRS, is a construct
G = (N, T, P, S), where N is an alphabet of nonter-
minal symbols in which each symbol A is associated
with a positive integer ϕ(A) called its fan-out, T is
an alphabet of terminal symbols, S ∈ N is a distin-
guished start symbol with ϕ(S) = 1; and P is a finite
set of productions of the form
</bodyText>
<equation confidence="0.868355">
p = A → f(A1,...,Am),
</equation>
<bodyText confidence="0.999390888888889">
where m ≥ 0, A, A1, ... , Am ∈ N, and f is a linear,
non-erasing function over the terminal alphabet T
with type ϕ(A1) × · · · × ϕ(Am) → ϕ(A), called the
composition operation associated with p. The rank
of G and the fan-out of G are defined as the maximal
rank and fan-out of the composition operations of G,
and are denoted by ρ(G) and ϕ(G).
The sets of derivation trees of G are the smallest
indexed family of sets DA, A ∈ N, such that, if
</bodyText>
<equation confidence="0.646911">
p = A → f(A1,...,Am)
277
N = {S, R} , T = {a, b, c, d} , P = { p1 = S —* f1(R), p2 = R —* f2(R), p3 = R —* f3 } ,
where: f1((x1,1, x1,2)) = (x1,1 x1,2), f2((x1,1, x1,2)) = (a x1,1 b, cx1,2 d) , f3 = (E, E) .
</equation>
<figureCaption confidence="0.980483">
Figure 1: An LCFRS that generates the string language { anbncndn  |n &gt; 0 }.
</figureCaption>
<bodyText confidence="0.994553">
is a production of G and ti E DAi for all i E [m],
then t = p(t1, ... , tm) E DA. By interpreting pro-
ductions as their associated composition operations
in the obvious way, a derivation tree t E DA evalu-
ates to a cp(A)-tuple of strings over T; we denote this
tuple by val(t). The string language generated by G,
denoted by L(G), is then defined as
</bodyText>
<equation confidence="0.986949">
L(G) = { w E T*  |t E DS, (w) = val(t) } .
</equation>
<bodyText confidence="0.913091857142857">
Two LCFRS are called weakly equivalent, if they
generate the same string language.
Example Figure 1 shows a sample LCFRS G with
p(G) = 1 and cp(G) = 2. The sets of its deriva-
tion trees are DR = { pn2(p3)  |n &gt; 0 } and
DS = { p1(t)  |t E DR }. The string language
generated by G is { anbncndn  |n &gt; 0 }.
</bodyText>
<subsectionHeader confidence="0.999703">
2.3 Characteristic strings
</subsectionHeader>
<bodyText confidence="0.999335">
In the remainder of this paper, we use the following
convenient syntax for tuples of strings. Instead of
</bodyText>
<equation confidence="0.731001">
(v1, ... , vk) , we write v1 $ ··· $ vk ,
</equation>
<bodyText confidence="0.9999802">
using the $-symbol to mark the component bound-
aries. We call this the characteristic string of the tu-
ple, and an occurrence of the symbol $ a gap marker.
We also use this notation for composition operations.
For example, the characteristic string of the operation
</bodyText>
<equation confidence="0.915343">
f((x1,1, x1,2), (x2,1)) = (a x1,1 x2,1, x1,2 b)
</equation>
<bodyText confidence="0.999061333333333">
is a x1,1 x2,1 $ x1,2 b. If we assume the variables on
the left-hand side of an equation to be named ac-
cording to the schema used in Section 2.1, then the
characteristic string of a composition operation deter-
mines that operation completely. We will therefore
freely identify the two, and write productions as
</bodyText>
<equation confidence="0.709853">
p = A —* [v1 $ ··· $ vk](A1, ... , Am) ,
</equation>
<bodyText confidence="0.988498368421053">
where the string inside the brackets is the charac-
teristic string of some composition operation. The
substrings v1, ... , vk are called the components of
the characteristic string. Note that the character-
istic string of a composition operation with type
k1 x · · · x km —* k is a sequence of terminal
symbols, gap markers, and variables from the set
{ xi,j  |i E [m], j E [ki] } in which the number of
gap markers is k−1, and each variable occurs exactly
once. When in the context of such a composition op-
eration we refer to ‘a variable of the form xi,j’, then
it will always be the case that i E [m] and j E [ki].
The identification of composition operations and
their characteristic strings allows us to construct new
operations by string manipulations: if, for example,
we delete some variables from a characteristic string,
then the resulting string still defines a composition
operation (after a suitable renaming of the remaining
variables, which we leave implicit).
</bodyText>
<subsectionHeader confidence="0.993533">
2.4 Canonical LCFRS
</subsectionHeader>
<bodyText confidence="0.999840956521739">
To simplify our presentation, we will assume that
LCFRS are given in a certain canonical form. Intu-
itively, this canonical form requires the variables in
the characteristic string of a composition operation
to be ordered in a certain way.
Formally, the defining equation of a composition
operation f with type k1 x · · · x km —* k is called
canonical, if (i) the sequence obtained from f by
reading variables of the form xi,1 from left to right
has the form x1,1 · · · xm,1; and (ii) for each i E [m],
the sequence obtained from f by reading variables
of the form xi,j from left to right has the form
xi,1 · · · xi,ki. An LCFRS is called canonical, if each
of its composition operations is canonical.
We omit the proof that every LCFRS can be trans-
formed into a weakly equivalent canonical LCFRS.
However, we point out that both the normal form and
the parsing algorithm that we present in this paper
can be applied also to general LCFRS. This is in con-
trast to some left-to-right parsers in the literature on
LCFRS and equivalent formalisms (de la Clergerie,
2002; Kallmeyer and Maier, 2009), which actually
depend on productions in canonical form.
</bodyText>
<subsectionHeader confidence="0.897121">
2.5 Well-nested LCFRS
</subsectionHeader>
<bodyText confidence="0.999628">
We now characterize the class of well-nested LCFRS
that are the focus of this paper. Well-nestedness
was first studied in the context of dependency gram-
mars (Kuhlmann and Möhl, 2007). Kanazawa (2009)
</bodyText>
<page confidence="0.984362">
278
</page>
<bodyText confidence="0.99966525">
defines well-nested multiple context-free grammars,
which are weakly equivalent to well-nested LCFRS.
A composition operation is called well-nested, if it
does not contain a substring of the form
</bodyText>
<equation confidence="0.751546">
xi,i1 ··· xj,j1 ··· xi,i2 ··· xj,j2 , where i =6 j .
</equation>
<bodyText confidence="0.9999065">
For example, the operation x1,1 x2,1$x2,2 x1,2 is well-
nested, while x1,1 x2,1 $ x1,2 x2,2 is not. An LCFRS
is called well-nested, if it contains only well-nested
composition operations.
The class of languages generated by well-nested
LCFRS is properly included in the class of languages
generated by general LCFRS; see Kanazawa and Sal-
vati (2010) for further discussion.
</bodyText>
<sectionHeader confidence="0.984622" genericHeader="method">
3 Parsing LCFRS
</sectionHeader>
<bodyText confidence="0.999796333333333">
We now discuss the parsing complexity of LCFRS,
and motivate our interest in a normal form for well-
nested LCFRS.
</bodyText>
<subsectionHeader confidence="0.99924">
3.1 General parsing schema
</subsectionHeader>
<bodyText confidence="0.999928533333333">
A bottom-up, chart-based parsing algorithm for the
class of (not necessarily well-nested) LCFRS can be
defined by using the formalism of parsing schemata
(Sikkel, 1997). The parsing schemata approach con-
siders parsing as a deduction process (as in Shieber
et al. (1995)), generating intermediate results called
items. Starting with an initial set of items obtained
from each input sentence, a parsing schema defines
a set of deduction steps that can be used to infer
new items from existing ones. Each item contains
information about the sentence’s structure, and a suc-
cessful parsing process will produce at least one final
item containing a full parse for the input.
The item set used by our bottom-up algorithm to
parse an input string w = a1 · · · an with an LCFRS
</bodyText>
<equation confidence="0.926214333333333">
G = (N, T, P, S) will be
I = {[A, (l1, r1), . . . , (lk, rk)] |A ∈ N ∧
0 ≤ li ≤ ri ≤ n ∀i ∈ [k]},
</equation>
<bodyText confidence="0.998916117647059">
where an item [A, (l1, r1), ... , (lk, rk)] can be inter-
preted as the set of those derivation trees t ∈ DA
of G for which
val(t) = al1+1 ··· ar1 $ ··· $ alk+1 ··· ark .
The set of final items is thus F = {[S, (0, n)]}, con-
taining full derivation trees that evaluate to w.
For simplicity of definition of the sets of initial
items and deduction steps, let us assume that pro-
ductions of rank &gt; 0 in our grammar do not contain
terminal symbols in their right-hand sides. This can
be easily achieved from a starting grammar by cre-
ating a nonterminal Aa for each terminal a ∈ T, a
corresponding rank-0 production pa = Aa → [a](),
and then changing each occurrence of a in the char-
acteristic string of a production to the single variable
associated with the fan-out 1 nonterminal Aa. With
this, our initial item set for a string a1 · · · an will be
</bodyText>
<equation confidence="0.939045">
H = {[Aaz, (i − 1, i)] |i ∈ [n]},
</equation>
<bodyText confidence="0.86933">
and each production p = A0 → f(A1,..., Am) of
G (excluding the ones we created for the terminals)
will produce a deduction step of the form given in
Figure 2a, where the indexes are subject to the fol-
lowing constraints, imposed by the semantics of f.
</bodyText>
<listItem confidence="0.99741">
1. If the kth component of the characteristic string
of f starts with xi,j, then l0,k = li,j.
2. If the kth component of the characteristic string
of f ends with xi,j, then r0,k = ri,j.
3. If xi,jxi0,j0 is an infix of the characteristic string
of f, then ri,j = li0,j0.
4. If the kth component of the characteristic string
of f is the empty string, then l0,k = r0,k.
</listItem>
<subsectionHeader confidence="0.997617">
3.2 General complexity
</subsectionHeader>
<bodyText confidence="0.975251347826087">
The time complexity of parsing LCFRS with respect
to the length of the input can be analyzed by counting
the maximum number of indexes that can appear in
an instance of the inference rule above. Although the
total number of indexes is Emi= 2 · ϕ(Ai), some of
0
these indexes are equated by the constraints.
To count the number of independent indexes, con-
sider all the indexes of the form l0,i (corresponding to
the left endpoints of each component of the character-
istic string of f) and those of the form rj,k for j &gt; 0
(corresponding to the right endpoints of each vari-
able in the characteristic string). By the constraints
above, these indexes are mutually independent, and it
is easy to check that any other index is equated to one
of these: indexes r0,i are equated to the index rj,k
corresponding to the last variable xj,k of the ith com-
ponent of the characteristic string, or to l0,i if there
is no such variable; while indexes lj,k with j &gt; 0
are equated to an index l0,i if the variable xj,k is at
the beginning of a component of the characteristic
string, or to an index rj0,k0(j&apos; &gt; 1) if the variable xj,k
follows another variable xj0,k0.
</bodyText>
<page confidence="0.987045">
279
</page>
<table confidence="0.724996">
[A1, (l1,1, r1,1), ... , (l1,ϕ(A1), r1,ϕ(A1))] · · · [Am, (lm,1, rm,1), ... , (lm,ϕ(A�), rm,ϕ(A�))]
[A0, (l0,1, r0,1), ... , (l0,ϕ(A0), r0,ϕ(A0))] r� = l� 1
(a) The general rule for a parsing schema for LCFRS
[B, (l1, r1), ... ,(lm, rm)] [C, (l01, r0 1), ... (l0n,r0n)]
[A, (l1, r1), ... ,(lm, r01), ... (l0n, r0n)]
(b) Deduction step for concatenation
[B, (l1, r1), ... , (lm, rm)] [C, (l01, r01),... (l0n, r0n)] __ __
[A, (l1, r1), ... (li, r01),...
rZ 11, r� 1Z+1
(c) Deduction step for wrapping
</table>
<figureCaption confidence="0.995848">
Figure 2: Deduction steps for parsing LCFRS.
</figureCaption>
<bodyText confidence="0.99871925">
Thus, the parsing complexity (Gildea, 2010) of a
production p = A0 → f(A1, ... , Am) is determined
by ϕ(A0) l-indexes and i∈[m]ϕ(Ai) r-indexes, for
a total complexity of
</bodyText>
<equation confidence="0.730807">
O(|w|ϕ(A0)+EiE[�1 ϕ(Ai))
</equation>
<bodyText confidence="0.999983272727273">
where |w |is the length of the input string. The pars-
ing complexity of an LCFRS will correspond to the
maximum parsing complexity among its productions.
Note that this general complexity matches the result
given by Seki et al. (1991).
In an LCFRS of rank ρ and fan-out ϕ, the maxi-
mum possible parsing complexity is O(|w|ϕ(ρ+1)),
obtained by applying the above expression to a pro-
duction of rank ρ and where each nonterminal has fan-
out ϕ. The asymptotic time complexity of LCFRS
parsing is therefore exponential both in its rank and
its fan-out. This means that it is interesting to trans-
form LCFRS into equivalent forms that reduce their
rank while preserving the fan-out. For sets of LCFRS
that can be transformed into a binary form (i.e., such
that all its rules have rank at most 2), the ρ factor in
the complexity is reduced to a constant, and complex-
ity is improved to O(|w|3ϕ) (see Gómez-Rodríguez
et al. (2009) for further discussion). Unfortunately,
it is known by previous results (Rambow and Satta,
1999) that it is not always possible to convert an
LCFRS into such a binary form without increasing
the fan-out. However, we will show that it is always
possible to build such a binarization for well-nested
LCFRS. Combining this result with the inference
rule and complexity analysis given above, we would
obtain a parser for well-nested LCFRS running in
O(|w|3ϕ) time. But the construction of our binary
normal form additionally restricts binary composition
operations in the binarized LCFRS to be of two spe-
cific forms, concatenation and wrapping, which fur-
ther improves the parsing complexity to O(|w|2ϕ+2),
as we will see below.
</bodyText>
<subsectionHeader confidence="0.99735">
3.3 Concatenation and wrapping
</subsectionHeader>
<bodyText confidence="0.99610772">
A composition operation is called a concatenation
operation, if its characteristic string has the form
x1,1 $ ··· $ x1,m x2,1 $ ··· $ x2,n ,
where m, n ≥ 1. Intuitively, such an operation corre-
sponds to the bottom-up combination of two adjacent
discontinuous constituents into one. An example of
a concatenation operation is the binary parsing rule
used by the standard CKY parser for context-free
grammars, which combines continuous constituents
(represented as 1-tuples of strings in the LCFRS nota-
tion). In the general case, a concatenation operation
will take an m-tuple and an n-tuple and return an
(m + n − 1)-tuple, as the joined constituents may
have gaps that will also appear in the resulting tuple.
If we apply the general parsing rule given in Fig-
ure 2a to a production A → conc(B, C), where conc
is a concatenation operation, then we obtain the de-
duction step given in Figure 2b. This step uses 2m
different l- and r-indexes, and 2n − 1 different l0-
and r0-indexes (excluding l01 which must equal rm),
for a total of 2m+2n−1 = 2(m+n−1)+1 indexes.
Since m + n − 1 is the fan-out of the nonterminal A,
we conclude that the maximum number of indexes in
the step associated with a concatenation operation in
an LCFRS of fan-out ϕ is 2ϕ + 1.
</bodyText>
<page confidence="0.996502">
280
</page>
<figureCaption confidence="0.999927">
Figure 3: Transformation of derivation trees
</figureCaption>
<bodyText confidence="0.9752675">
A linear, non-erasing function is called a wrapping
operation, if its characteristic string has the form
</bodyText>
<equation confidence="0.944312">
x1,1 $ ··· $ x1,i x2,1 $ ··· $ x2,n x1,i+1 $ ··· $ x1,m ,
</equation>
<bodyText confidence="0.999933862068966">
where m, n &gt; 1 and i E [m −1]. Intuitively, such an
operation wraps the tuple derived from a nontermi-
nal B around the tuple derived from a nonterminal C,
filling the ith gap in the former. An example of a
wrapping operation is the adjunction of an auxiliary
tree in tree-adjoining grammar. In the general case, a
wrapping operation will take an m-tuple and an n-tu-
ple and return an (m + n − 2)-tuple of strings: the
gaps of the argument tuples appear in the obtained
tuple, except for one gap in the tuple derived from B
which is filled by the tuple derived from C.
By applying the general parsing rule in Figure 2a
to a production A —* wrapi(B, C), where wrapi is
a wrapping operation, then we obtain the deduction
step given in Figure 2c. This step uses 2m different l-
and r-indexes, and 2n − 2 different l0- and r0-indexes
(discounting l01 and r0n which are equal to other in-
dexes), for a total of 2m+2n−2 = 2(m+n−2)+2
indexes. Since the fan-out of A is m + n − 2, this
means that a wrapping operation needs at most 2cp+2
indexes for an LCFRS of fan-out cp.
From this, we conclude that an LCFRS of fan-
out cp in which all composition operations are ei-
ther concatenation operations, wrapping operations,
or operations of rank 0 or 1, can be parsed in time
O(|w|2ϕ+2). In particular, nullary and unary compo-
sition operations do not affect this worst-case com-
plexity, since their associated deduction steps can
never have more than 2cp indexes.
</bodyText>
<sectionHeader confidence="0.997636" genericHeader="method">
4 Transformation
</sectionHeader>
<bodyText confidence="0.999994">
We now show how to transform a well-nested LCFRS
into the normal form that we have just described.
</bodyText>
<subsectionHeader confidence="0.980487">
4.1 Informal overview
</subsectionHeader>
<bodyText confidence="0.987369225806452">
Consider a production p = A —* f(A1,..., Am),
where m &gt; 2 and f is neither a concatenation nor a
wrapping operation. We will construct new produc-
tions p0, q, r such that every derivation that uses p can
be rewritten into a derivation that uses the new pro-
ductions, and the new productions do not license any
other derivations. Formally, this can be understood as
implementing a tree transformation, where the input
trees are derivations of the original grammar, and the
output trees are derivations of the new grammar. The
situation is illustrated in Figure 3. The tree on top
represents a derivation in the original grammar; this
derivation starts with the rewriting of the nontermi-
nal A using the production p, and continues with the
subderivations t1, ... , tm. The tree at the bottom rep-
resents a derivation in the transformed grammar. This
derivation starts with the rewriting of A using the new
production p0, and continues with two independent
subderivations that start with the new productions q
and r, respectively. The sub-derivations t1, ... , tm
have been partitioned into two sequences
t1,1, ... ,t1,m1 and t2,1, ... ,t2,m2 .
The new production p0 will be either a concatenation
or a wrapping operation, and the rank of both q and r
will be strictly smaller than the rank of p. The trans-
formation will continue with q and r, unless these
have rank one. By applying this strategy exhaustively,
we will thus eventually end up with a grammar that
only has productions with rank at most 2, and in
which all productions with rank 2 are either concate-
nation or wrapping operations.
</bodyText>
<subsectionHeader confidence="0.998877">
4.2 Constructing the composition operations
</subsectionHeader>
<bodyText confidence="0.99948875">
To transform the production p, we first factorize the
composition operation f associated with p into three
new composition operations f0, g, h as follows. Re-
call that we represent composition operations by their
characteristic strings.
In the following, we will assume that no charac-
teristic string starts or ends with a gap marker, or
contains immediate repetitions of gap markers. This
</bodyText>
<equation confidence="0.951093">
before: p
� � �
t1 tm
after: p�
q
� � �
� � �
tq,1 tq,m9
tr,1 tr,mr
r
</equation>
<page confidence="0.991223">
281
</page>
<bodyText confidence="0.9900826">
property can be ensured, without affecting the asymp-
totic complexity, by adding intermediate steps to the
transformation that we report here; we omit the de-
tails due to space reasons. When this property holds,
we are left with the following two cases. Let us call a
sequence of variables joint, if it contains all and only
variables associated with a given nonterminal.
Case 1 f = x1 f1 x2 ··· xk−1 fk−1 xk f* ,
where k &gt; 1, x1, ... , xk are joint variables, and the
suffix f* contains at least one variable. Let
</bodyText>
<equation confidence="0.971535">
g = x1 f1 x2 ··· xk−1 fk−1 xk ,
</equation>
<bodyText confidence="0.992008153846154">
let h = f*, and let f&apos; = conc. As f is well-nested,
both g and h define well-nested composition opera-
tions. By the specific segmentation of f, the ranks of
these operations are strictly smaller than the rank of f.
Furthermore, we have ϕ(f) = ϕ(g) + ϕ(h) — 1.
Case 2 f = x1 f1 x2 · · · xk−1 fk−1 xk ,
where k &gt; 2, x1, ... , xk are joint variables, and there
exist at least one i such that the sequence fi contains
at least one variable. Choose an index j as follows:
if there is at least one i such that fi contains at least
one variable and one gap marker, let j be the minimal
such i; otherwise, let j be the minimal i such that fi
contains at least one variable. Now, let
</bodyText>
<equation confidence="0.906173">
g = x1 f1 x2 ··· xj $ xj+1 ··· xk−1 fk−1 xk ,
</equation>
<bodyText confidence="0.999983714285714">
let h = fj, and let f&apos; = wrapj. As in Case 1, both g
and h define well-nested composition operations
whose ranks are strictly smaller than the rank of f.
Furthermore, we have ϕ(f) = ϕ(g) + ϕ(h) — 2.
Note that at most one of the two cases can apply
to f. Furthermore, since f is well-nested, it is also
true that at least one of the two cases applies. This
is so because for two distinct nonterminals Ai, AiA,
either all variables associated with AiA precede the
leftmost variable associated with Ai, succeed the
rightmost variable associated with Ai, or are placed
between two variables associated with Ai without an-
other variable associated with Ai intervening. (Here,
we have left out the symmetric cases.)
</bodyText>
<subsectionHeader confidence="0.999809">
4.3 Constructing the new productions
</subsectionHeader>
<bodyText confidence="0.999981833333333">
Based on the composition operations, we now con-
struct three new productions p&apos;, q, r as follows. Let B
and C be two fresh nonterminals with ϕ(B) = ϕ(g)
and ϕ(C) = ϕ(h), and let p&apos; = A — f&apos;(B, C).
The production p&apos; rewrites A into B and C and
combines the two subderivations that originate at
these nonterminals using either a concatenation or a
wrapping operation. Now, let Aq,1, ... , Aq,m9 and
Ar,1, . . . , Ar,m,. be the sequences of nonterminals
that are obtained from the sequence A1, ... , Am by
deleting those nonterminals that are not associated
with any variable in g or h, respectively. Then, let
</bodyText>
<equation confidence="0.995761">
q = B — g(Aq,1, ... , Aq,m9) and
r = C — h(&apos;Ar,1, ... , Ar,m,.) .
</equation>
<subsectionHeader confidence="0.983442">
4.4 Example
</subsectionHeader>
<bodyText confidence="0.996299">
We now illustrate the transformation using the con-
crete production p = A — f(A1, A2, A3), where
</bodyText>
<equation confidence="0.700502">
f = x1,1 x2,1 $ x1,2 $ x3,1 .
</equation>
<bodyText confidence="0.999946">
Note that this operation has rank 3 and fan-out 3.
The composition operations are constructed as fol-
lows. The operation f matches the pattern of Case 1,
and hence induces the operations
</bodyText>
<equation confidence="0.962441">
g1 = x1,1 x2,1 $ x1,2 , h1 = $ x3,1 , f&apos;1 = conc .
The productions constructed from these are
p&apos;1 = A — conc(B1, C1),
q1 = B1 — g1(A1, A2) , r1 = C1 — h1(A3) .
</equation>
<bodyText confidence="0.959390857142857">
where B1 and C1 are fresh nonterminals with fan-
out 2. The production r1 has rank one, so it does not
require any further transformations. The transforma-
tion thus continues with q1. The operation g1 matches
the pattern of Case 2, and induces the operations
g2 = x1,1 $ x1,2 , h2 = x2,1$, f&apos;2 = wrap1 .
The productions constructed from these are
</bodyText>
<equation confidence="0.999924">
p&apos;2 = B1 — wrap1(B2, C2) ,
q2 = B2 — g2(A1), r2 = C2 — h2(A2),
</equation>
<bodyText confidence="0.99935175">
where B2 and C2 are fresh nonterminals with fan-
out 2. At this point, the transformation terminates.
We can now delete p from the original grammar, and
replace it with the productions {p&apos;1, r1, p&apos;2, q2, r2}.
</bodyText>
<subsectionHeader confidence="0.992106">
4.5 Correctness
</subsectionHeader>
<bodyText confidence="0.999913125">
To see that the transformation is correct, we need to
verify that each production of the original grammar
is transformed into a set of equivalent normal-form
productions, and that the fan-out of the new grammar
does not exceed the fan-out of the old grammar.
For the first point, we note that the transformation
preserves well-nestedness, decreases the rank of a
production, and is always applicable as long as the
</bodyText>
<page confidence="0.98743">
282
</page>
<bodyText confidence="0.999981555555556">
rank of a production is at most 2 and the production
does not use a concatenation or wrapping operation.
That the new productions are equivalent to the old
ones in the sense of Figure 3 can be proved by induc-
tion on the length of a derivation in the original and
the new grammar, respectively.
Let us now convince ourselves that the fan-out of
the new grammar does not exceed the fan-out of the
old grammar. This is clear in Case 1, where
</bodyText>
<equation confidence="0.994455">
cp(f) = cp(g) + cp(h) − 1
</equation>
<bodyText confidence="0.984823">
implies that both cp(g) ≤ cp(f) and cp(h) ≤ cp(f).
For Case 2, we reason as follows. The fan-out of the
operation h, being constructed from an infix of the
characteristic string of the original operation f, is
clearly bounded by the fan-out of f. For g, we have
</bodyText>
<equation confidence="0.993418">
cp(g) = cp(f) − cp(h) + 2,
</equation>
<bodyText confidence="0.9145935">
Now suppose that the index j was chosen according
to the first alternative. In this case, cp(h) ≥ 2, and
</bodyText>
<equation confidence="0.967863">
cp(g) ≤ cp(f) − 2 + 2 = cp(f) .
</equation>
<bodyText confidence="0.999986">
For the case where j was chosen according to the
second alternative, cp(f) &lt; k (since there are no
immediate repetitions of gap markers), cp(h) = 1,
and cp(g) ≤ k. If we assume that each nonterminal
is productive, then this means that the underlying
LCFRS has at least one production with fan-out k or
more; therefore, the fan-out of g does not increase
the fan-out of the original grammar.
</bodyText>
<subsectionHeader confidence="0.91873">
4.6 Complexity
</subsectionHeader>
<bodyText confidence="0.999882896551724">
To conclude, we now briefly discuss the space com-
plexity of the normal-form transformation. We mea-
sure it in terms of the length of a production, defined
as the length of its string representation, that is, the
string A → [v1 $ ··· $ vk](A1, ... , Am) .
Looking at Figure 3, we note that the normal-form
transformation of a production p can be understood
as the construction of a (not necessarily complete)
binary-branching tree whose leaves correspond to the
productions obtained by splitting the characteristic
string of p and whose non-leaf nodes are labeled with
concatenation and wrapping operations. By construc-
tion, the sum of the lengths of leaf-node productions
is O(|p|). Since the number of inner nodes of a bi-
nary tree with n leaves is bounded by n − 1, we
know that the tree has O(p(p)) inner nodes. As these
nodes correspond to concatenation and wrapping
operations, each inner-node production has length
O(cp(p)). Thus, the sum of the lengths of the produc-
tions created from |p |is O(|p |+ p(p)cp(p)). Since
the rank of a production is always smaller than its
length, this is reduced to O(|p|cp(p)).
Therefore, the size of the normal-form transfor-
mation of an LCFRS G of fan-out cp is O(cp|G|) in
the worst case, and linear space in practice, since
the fan-out is typically bounded by a small integer.
Taking the normal-form transformation into account,
our parser therefore runs in time O(cp · |G |· |w|2cp+2)
where |G |is the original grammar size.
</bodyText>
<sectionHeader confidence="0.999279" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.996273818181818">
In this paper, we have presented an efficient parsing
algorithm for well-nested linear context-free rewrit-
ing systems, based on a new normal form for this
formalism. The normal form takes up linear space
with respect to grammar size, and the algorithm is
based on a bottom-up process that can be applied
to any LCFRS, achieving O(cp · |G |· |w|2cp+2) time
complexity when applied to LCFRS of fan-out cp
in our normal form. This complexity is an asymp-
totic improvement over existing results for this class,
both from parsers specifically geared to well-nested
LCFRS or equivalent formalisms (Hotz and Pitsch,
1996) and from applying general LCFRS parsing
techniques to the well-nested case (Seki et al., 1991).
The class of well-nested LCFRS is an interest-
ing syntactic formalism for languages with discon-
tinuous constituents, providing a good balance be-
tween coverage of linguistic phenomena in natu-
ral language treebanks (Kuhlmann and Nivre, 2006;
Maier and Lichte, 2009) and desirable formal prop-
erties (Kanazawa, 2009). Our results offer a further
argument in support of well-nested LCFRS: while
the complexity of parsing general LCFRS depends
on two dimensions (rank and fan-out), this bidimen-
sional hierarchy collapses into a single dimension
in the well-nested case, where complexity is only
conditioned by the fan-out.
Acknowledgments Gómez-Rodríguez has been
supported by MEC/FEDER (HUM2007-66607-C04)
and Xunta de Galicia (PGIDIT07SIN005206PR, Re-
des Galegas de PL e RI e de Ling. de Corpus, Bolsas
Estadías INCITE/FSE cofinanced). Kuhlmann has
been supported by the Swedish Research Council.
</bodyText>
<page confidence="0.997675">
283
</page>
<sectionHeader confidence="0.983191" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998322381443299">
Éric Villemonte de la Clergerie. 2002. Parsing mildly
context-sensitive languages with thread automata. In
19th International Conference on Computational Lin-
guistics (COLING), pages 1–7, Taipei, Taiwan.
Daniel Gildea. 2010. Optimal parsing strategies for linear
context-free rewriting systems. In Human Language
Technologies: The Eleventh Annual Conference of the
North American Chapter of the Association for Compu-
tational Linguistics, Los Angeles, USA.
Carlos Gómez-Rodríguez, Marco Kuhlmann, Giorgio
Satta, and David J. Weir. 2009. Optimal reduction
of rule length in linear context-free rewriting systems.
In Human Language Technologies: The 2009 Annual
Conference of the North American Chapter of the Asso-
ciation for Computational Linguistics, pages 539–547,
Boulder, CO, USA.
Jiˇrí Havelka. 2007. Beyond projectivity: Multilin-
gual evaluation of constraints and measures on non-
projective structures. In 45th Annual Meeting of the As-
sociation for Computational Linguistics (ACL), pages
608–615.
Günter Hotz and Gisela Pitsch. 1996. On parsing coupled-
context-free languages. Theoretical Computer Science,
161(1–2):205–233.
Riny Huybregts. 1984. The weak inadequacy of context-
free phrase structure grammars. In Ger de Haan, Mieke
Trommelen, and Wim Zonneveld, editors, Van periferie
naar kern, pages 81–99. Foris, Dordrecht, The Nether-
lands.
Aravind K. Joshi, Leon S. Levy, and Masako Takahashi.
1975. Tree Adjunct Grammars. Journal of Computer
and System Sciences, 10(2):136–163.
Aravind K. Joshi. 1985. Tree Adjoining Grammars: How
much context-sensitivity is required to provide reason-
able structural descriptions? In Natural Language
Parsing, pages 206–250. Cambridge University Press.
Laura Kallmeyer and Wolfgang Maier. 2009. An incre-
mental Earley parser for simple range concatenation
grammar. In Proceedings of the 11th International Con-
ference on Parsing Technologies (IWPT 2009), pages
61–64. Association for Computational Linguistics.
Makoto Kanazawa and Sylvain Salvati. 2010. The copy-
ing power of well-nested multiple context-free gram-
mars. In Fourth International Conference on Language
and Automata Theory and Applications, Trier, Ger-
many.
Makoto Kanazawa. 2009. The pumping lemma for well-
nested multiple context-free languages. In Develop-
ments in Language Theory. 13th International Confer-
ence, DLT 2009, Stuttgart, Germany, June 30–July 3,
2009. Proceedings, volume 5583 of Lecture Notes in
Computer Science, pages 312–325.
Marco Kuhlmann and Mathias Möhl. 2007. Mildly
context-sensitive dependency languages. In 45th An-
nual Meeting of the Association for Computational Lin-
guistics (ACL), pages 160–167.
Marco Kuhlmann and Joakim Nivre. 2006. Mildly non-
projective dependency structures. In 21st International
Conference on Computational Linguistics and 44th An-
nual Meeting of the Association for Computational Lin-
guistics (COLING-ACL), Main Conference Poster Ses-
sions, pages 507–514, Sydney, Australia.
Marco Kuhlmann and Giorgio Satta. 2009. Treebank
grammar techniques for non-projective dependency
parsing. In Twelfth Conference of the European Chap-
ter of the Association for Computational Linguistics
(EACL), pages 478–486, Athens, Greece.
Wolfgang Maier and Timm Lichte. 2009. Characterizing
discontinuity in constituent treebanks. In 14th Confer-
ence on Formal Grammar, Bordeaux, France.
Wolfgang Maier and Anders Søgaard. 2008. Treebanks
and mild context-sensitivity. In 13th Conference on
Formal Grammar, pages 61–76, Hamburg, Germany.
Owen Rambow and Giorgio Satta. 1999. Independent
parallelism in finite copying parallel rewriting systems.
Theoretical Computer Science, 223(1–2):87–120.
Giorgio Satta. 1992. Recognition of Linear Context-
Free Rewriting Systems. In 30th Annual Meeting of
the Association for Computational Linguistics (ACL),
pages 89–95, Newark, DE, USA.
Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii, and
Tadao Kasami. 1991. On Multiple Context-Free Gram-
mars. Theoretical Computer Science, 88(2):191–229.
Stuart M. Shieber, Yves Schabes, and Fernando Pereira.
1995. Principles and implementation of deductive pars-
ing. Journal of Logic Programming, 24(1–2):3–36.
Stuart M. Shieber. 1985. Evidence against the context-
freeness of natural language. Linguistics and Philoso-
phy, 8(3):333–343.
Klaas Sikkel. 1997. Parsing Schemata: A Framework
for Specification and Analysis of Parsing Algorithms.
Springer.
K. Vijay-Shanker, David J. Weir, and Aravind K. Joshi.
1987. Characterizing structural descriptions produced
by various grammatical formalisms. In 25th Annual
Meeting of the Association for Computational Linguis-
tics (ACL), pages 104–111, Stanford, CA, USA.
</reference>
<page confidence="0.998309">
284
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.685707">
<title confidence="0.999987">Efficient Parsing of Well-Nested Linear Context-Free Rewriting Systems</title>
<author confidence="0.998214">Marco</author>
<author confidence="0.998214">Giorgio</author>
<affiliation confidence="0.943828">de Computación, Universidade da Coruña, Spain, of Linguistics and Philology, Uppsala University, Sweden,</affiliation>
<address confidence="0.909216">of Information Engineering, University of Padua, Italy,</address>
<abstract confidence="0.985985272727273">The use of well-nested linear context-free rewriting systems has been empirically motivated for modeling of the syntax of languages with discontinuous constituents or relatively free word order. We present a chart-based parsing algorithm that asymptotically improves the known running time upper bound for this class of rewriting systems. Our result is obtained through a linear space construction of a binary normal form for the grammar at hand.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Éric Villemonte de la Clergerie</author>
</authors>
<title>Parsing mildly context-sensitive languages with thread automata.</title>
<date>2002</date>
<booktitle>In 19th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>1--7</pages>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="11879" citStr="Clergerie, 2002" startWordPosition="2071" endWordPosition="2072">the form x1,1 · · · xm,1; and (ii) for each i E [m], the sequence obtained from f by reading variables of the form xi,j from left to right has the form xi,1 · · · xi,ki. An LCFRS is called canonical, if each of its composition operations is canonical. We omit the proof that every LCFRS can be transformed into a weakly equivalent canonical LCFRS. However, we point out that both the normal form and the parsing algorithm that we present in this paper can be applied also to general LCFRS. This is in contrast to some left-to-right parsers in the literature on LCFRS and equivalent formalisms (de la Clergerie, 2002; Kallmeyer and Maier, 2009), which actually depend on productions in canonical form. 2.5 Well-nested LCFRS We now characterize the class of well-nested LCFRS that are the focus of this paper. Well-nestedness was first studied in the context of dependency grammars (Kuhlmann and Möhl, 2007). Kanazawa (2009) 278 defines well-nested multiple context-free grammars, which are weakly equivalent to well-nested LCFRS. A composition operation is called well-nested, if it does not contain a substring of the form xi,i1 ··· xj,j1 ··· xi,i2 ··· xj,j2 , where i =6 j . For example, the operation x1,1 x2,1$x2</context>
</contexts>
<marker>Clergerie, 2002</marker>
<rawString>Éric Villemonte de la Clergerie. 2002. Parsing mildly context-sensitive languages with thread automata. In 19th International Conference on Computational Linguistics (COLING), pages 1–7, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
</authors>
<title>Optimal parsing strategies for linear context-free rewriting systems.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The Eleventh Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<location>Los Angeles, USA.</location>
<contexts>
<context position="17092" citStr="Gildea, 2010" startWordPosition="3025" endWordPosition="3026">ther variable xj0,k0. 279 [A1, (l1,1, r1,1), ... , (l1,ϕ(A1), r1,ϕ(A1))] · · · [Am, (lm,1, rm,1), ... , (lm,ϕ(A�), rm,ϕ(A�))] [A0, (l0,1, r0,1), ... , (l0,ϕ(A0), r0,ϕ(A0))] r� = l� 1 (a) The general rule for a parsing schema for LCFRS [B, (l1, r1), ... ,(lm, rm)] [C, (l01, r0 1), ... (l0n,r0n)] [A, (l1, r1), ... ,(lm, r01), ... (l0n, r0n)] (b) Deduction step for concatenation [B, (l1, r1), ... , (lm, rm)] [C, (l01, r01),... (l0n, r0n)] __ __ [A, (l1, r1), ... (li, r01),... rZ 11, r� 1Z+1 (c) Deduction step for wrapping Figure 2: Deduction steps for parsing LCFRS. Thus, the parsing complexity (Gildea, 2010) of a production p = A0 → f(A1, ... , Am) is determined by ϕ(A0) l-indexes and i∈[m]ϕ(Ai) r-indexes, for a total complexity of O(|w|ϕ(A0)+EiE[�1 ϕ(Ai)) where |w |is the length of the input string. The parsing complexity of an LCFRS will correspond to the maximum parsing complexity among its productions. Note that this general complexity matches the result given by Seki et al. (1991). In an LCFRS of rank ρ and fan-out ϕ, the maximum possible parsing complexity is O(|w|ϕ(ρ+1)), obtained by applying the above expression to a production of rank ρ and where each nonterminal has fanout ϕ. The asympt</context>
</contexts>
<marker>Gildea, 2010</marker>
<rawString>Daniel Gildea. 2010. Optimal parsing strategies for linear context-free rewriting systems. In Human Language Technologies: The Eleventh Annual Conference of the North American Chapter of the Association for Computational Linguistics, Los Angeles, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Gómez-Rodríguez</author>
<author>Marco Kuhlmann</author>
<author>Giorgio Satta</author>
<author>David J Weir</author>
</authors>
<title>Optimal reduction of rule length in linear context-free rewriting systems.</title>
<date>2009</date>
<booktitle>In Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>539--547</pages>
<location>Boulder, CO, USA.</location>
<contexts>
<context position="18161" citStr="Gómez-Rodríguez et al. (2009)" startWordPosition="3211" endWordPosition="3214">ible parsing complexity is O(|w|ϕ(ρ+1)), obtained by applying the above expression to a production of rank ρ and where each nonterminal has fanout ϕ. The asymptotic time complexity of LCFRS parsing is therefore exponential both in its rank and its fan-out. This means that it is interesting to transform LCFRS into equivalent forms that reduce their rank while preserving the fan-out. For sets of LCFRS that can be transformed into a binary form (i.e., such that all its rules have rank at most 2), the ρ factor in the complexity is reduced to a constant, and complexity is improved to O(|w|3ϕ) (see Gómez-Rodríguez et al. (2009) for further discussion). Unfortunately, it is known by previous results (Rambow and Satta, 1999) that it is not always possible to convert an LCFRS into such a binary form without increasing the fan-out. However, we will show that it is always possible to build such a binarization for well-nested LCFRS. Combining this result with the inference rule and complexity analysis given above, we would obtain a parser for well-nested LCFRS running in O(|w|3ϕ) time. But the construction of our binary normal form additionally restricts binary composition operations in the binarized LCFRS to be of two sp</context>
</contexts>
<marker>Gómez-Rodríguez, Kuhlmann, Satta, Weir, 2009</marker>
<rawString>Carlos Gómez-Rodríguez, Marco Kuhlmann, Giorgio Satta, and David J. Weir. 2009. Optimal reduction of rule length in linear context-free rewriting systems. In Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 539–547, Boulder, CO, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiˇrí Havelka</author>
</authors>
<title>Beyond projectivity: Multilingual evaluation of constraints and measures on nonprojective structures.</title>
<date>2007</date>
<booktitle>In 45th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>608--615</pages>
<contexts>
<context position="3432" citStr="Havelka, 2007" startWordPosition="502" endWordPosition="503">arsing. This is in contrast with other mildly context-sensitive formalisms, and TAG in particular: TAGs can be parsed in polynomial time both with respect to grammar size and string size, and they can be cast in normal forms having binary derivation trees only. It has recently been argued that LCFRS might be too powerful for modeling languages with discontinuous constituents or with relatively free word order, and that additional restrictions on the rearrangement of components might be needed. More specifically, analyses of both dependency and constituency treebanks (Kuhlmann and Nivre, 2006; Havelka, 2007; Maier and Lichte, 2009) have shown that rearrangements of argument tuples almost always satisfy the so-called well-nestedness condition, a generalization 276 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 276–284, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics of the standard condition on balanced brackets. This condition states that any two components x1, x2 of some tuple will never be composed with any two components y1, y2 of some other tuple in such a way that a ‘crossing’ configuration is real</context>
</contexts>
<marker>Havelka, 2007</marker>
<rawString>Jiˇrí Havelka. 2007. Beyond projectivity: Multilingual evaluation of constraints and measures on nonprojective structures. In 45th Annual Meeting of the Association for Computational Linguistics (ACL), pages 608–615.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Günter Hotz</author>
<author>Gisela Pitsch</author>
</authors>
<title>On parsing coupledcontext-free languages.</title>
<date>1996</date>
<journal>Theoretical Computer Science,</journal>
<pages>161--1</pages>
<contexts>
<context position="5033" citStr="Hotz and Pitsch (1996)" startWordPosition="760" endWordPosition="763">n efficient parsing algorithm for wellnested LCFRS, running in time O(ϕ · |G |· |w|2ϕ+2), where G and w are the input grammar and string, respectively. Well-nested LCFRS with fan-out ϕ = 2 are weakly equivalent to TAG, and our complexity result reduces to the well-known upper bound O(|G |· |w|6) for this class. For ϕ &gt; 2, our upper bound is asymptotically better than the one obtained from existing parsing algorithms for general LCFRS or equivalent formalisms (Seki et al., 1991). Well-nested LCFRS are generatively equivalent to (among others) coupled context-free grammars (CCFG), introduced by Hotz and Pitsch (1996). These authors also provide a normal form and develop a parsing algorithm for CCFGs. One difference with respect to our result is that the normal form for CCFGs allows more than two nonterminals to appear in the right-hand side of a production, even though no nonterminal may contribute more than two tuple components. Also, the construction in (Hotz and Pitsch, 1996) results in a blow-up of the grammar that is exponential in its fan-out, and the parsing algorithm that is derived runs in time O(4ϕ · |G |· |w|2ϕ+2). Our result is therefore a considerable asymptotic improvement over the CCFG resu</context>
<context position="31662" citStr="Hotz and Pitsch, 1996" startWordPosition="5670" endWordPosition="5673">nclusion In this paper, we have presented an efficient parsing algorithm for well-nested linear context-free rewriting systems, based on a new normal form for this formalism. The normal form takes up linear space with respect to grammar size, and the algorithm is based on a bottom-up process that can be applied to any LCFRS, achieving O(cp · |G |· |w|2cp+2) time complexity when applied to LCFRS of fan-out cp in our normal form. This complexity is an asymptotic improvement over existing results for this class, both from parsers specifically geared to well-nested LCFRS or equivalent formalisms (Hotz and Pitsch, 1996) and from applying general LCFRS parsing techniques to the well-nested case (Seki et al., 1991). The class of well-nested LCFRS is an interesting syntactic formalism for languages with discontinuous constituents, providing a good balance between coverage of linguistic phenomena in natural language treebanks (Kuhlmann and Nivre, 2006; Maier and Lichte, 2009) and desirable formal properties (Kanazawa, 2009). Our results offer a further argument in support of well-nested LCFRS: while the complexity of parsing general LCFRS depends on two dimensions (rank and fan-out), this bidimensional hierarchy</context>
</contexts>
<marker>Hotz, Pitsch, 1996</marker>
<rawString>Günter Hotz and Gisela Pitsch. 1996. On parsing coupledcontext-free languages. Theoretical Computer Science, 161(1–2):205–233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Riny Huybregts</author>
</authors>
<title>The weak inadequacy of contextfree phrase structure grammars.</title>
<date>1984</date>
<booktitle>In Ger de Haan, Mieke Trommelen, and Wim Zonneveld, editors, Van periferie naar kern,</booktitle>
<pages>81--99</pages>
<location>Foris, Dordrecht, The Netherlands.</location>
<contexts>
<context position="1057" citStr="Huybregts (1984)" startWordPosition="142" endWordPosition="143">free rewriting systems has been empirically motivated for modeling of the syntax of languages with discontinuous constituents or relatively free word order. We present a chart-based parsing algorithm that asymptotically improves the known running time upper bound for this class of rewriting systems. Our result is obtained through a linear space construction of a binary normal form for the grammar at hand. 1 Introduction Since its earliest years, one of the main goals of computational linguistics has been the modeling of natural language syntax by means of formal grammars. Following results by Huybregts (1984) and Shieber (1985), special attention has been given to formalisms that enlarge the generative power of context-free grammars, but still remain below the full generative power of context-sensitive grammars. On this line of investigation, mildly context-sensitive grammar formalisms have been introduced (Joshi, 1985), including, among several others, the tree adjoining grammars (TAGs) of Joshi et al. (1975). Linear context-free rewriting system (LCFRS), introduced by Vijay-Shanker et al. (1987), is a mildly context-sensitive formalism that allows the derivation of tuples of strings, i.e., disco</context>
</contexts>
<marker>Huybregts, 1984</marker>
<rawString>Riny Huybregts. 1984. The weak inadequacy of contextfree phrase structure grammars. In Ger de Haan, Mieke Trommelen, and Wim Zonneveld, editors, Van periferie naar kern, pages 81–99. Foris, Dordrecht, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>Leon S Levy</author>
<author>Masako Takahashi</author>
</authors>
<title>Tree Adjunct Grammars.</title>
<date>1975</date>
<journal>Journal of Computer and System Sciences,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="1466" citStr="Joshi et al. (1975)" startWordPosition="199" endWordPosition="202">d. 1 Introduction Since its earliest years, one of the main goals of computational linguistics has been the modeling of natural language syntax by means of formal grammars. Following results by Huybregts (1984) and Shieber (1985), special attention has been given to formalisms that enlarge the generative power of context-free grammars, but still remain below the full generative power of context-sensitive grammars. On this line of investigation, mildly context-sensitive grammar formalisms have been introduced (Joshi, 1985), including, among several others, the tree adjoining grammars (TAGs) of Joshi et al. (1975). Linear context-free rewriting system (LCFRS), introduced by Vijay-Shanker et al. (1987), is a mildly context-sensitive formalism that allows the derivation of tuples of strings, i.e., discontinuous phrases. This feature has been used to model phrase structure treebanks with discontinuous constituents (Maier and Søgaard, 2008), as well as to map non-projective dependency trees into discontinuous phrase structures (Kuhlmann and Satta, 2009). Informally, in an LCFRS G, each nonterminal can generate string tuples with a fixed number of components. The fan-out of G is defined as the maximum numbe</context>
</contexts>
<marker>Joshi, Levy, Takahashi, 1975</marker>
<rawString>Aravind K. Joshi, Leon S. Levy, and Masako Takahashi. 1975. Tree Adjunct Grammars. Journal of Computer and System Sciences, 10(2):136–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
</authors>
<title>Tree Adjoining Grammars: How much context-sensitivity is required to provide reasonable structural descriptions?</title>
<date>1985</date>
<booktitle>In Natural Language Parsing,</booktitle>
<pages>206--250</pages>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1374" citStr="Joshi, 1985" startWordPosition="186" endWordPosition="187">ed through a linear space construction of a binary normal form for the grammar at hand. 1 Introduction Since its earliest years, one of the main goals of computational linguistics has been the modeling of natural language syntax by means of formal grammars. Following results by Huybregts (1984) and Shieber (1985), special attention has been given to formalisms that enlarge the generative power of context-free grammars, but still remain below the full generative power of context-sensitive grammars. On this line of investigation, mildly context-sensitive grammar formalisms have been introduced (Joshi, 1985), including, among several others, the tree adjoining grammars (TAGs) of Joshi et al. (1975). Linear context-free rewriting system (LCFRS), introduced by Vijay-Shanker et al. (1987), is a mildly context-sensitive formalism that allows the derivation of tuples of strings, i.e., discontinuous phrases. This feature has been used to model phrase structure treebanks with discontinuous constituents (Maier and Søgaard, 2008), as well as to map non-projective dependency trees into discontinuous phrase structures (Kuhlmann and Satta, 2009). Informally, in an LCFRS G, each nonterminal can generate strin</context>
</contexts>
<marker>Joshi, 1985</marker>
<rawString>Aravind K. Joshi. 1985. Tree Adjoining Grammars: How much context-sensitivity is required to provide reasonable structural descriptions? In Natural Language Parsing, pages 206–250. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Kallmeyer</author>
<author>Wolfgang Maier</author>
</authors>
<title>An incremental Earley parser for simple range concatenation grammar.</title>
<date>2009</date>
<booktitle>In Proceedings of the 11th International Conference on Parsing Technologies (IWPT</booktitle>
<pages>61--64</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="11907" citStr="Kallmeyer and Maier, 2009" startWordPosition="2073" endWordPosition="2076"> · xm,1; and (ii) for each i E [m], the sequence obtained from f by reading variables of the form xi,j from left to right has the form xi,1 · · · xi,ki. An LCFRS is called canonical, if each of its composition operations is canonical. We omit the proof that every LCFRS can be transformed into a weakly equivalent canonical LCFRS. However, we point out that both the normal form and the parsing algorithm that we present in this paper can be applied also to general LCFRS. This is in contrast to some left-to-right parsers in the literature on LCFRS and equivalent formalisms (de la Clergerie, 2002; Kallmeyer and Maier, 2009), which actually depend on productions in canonical form. 2.5 Well-nested LCFRS We now characterize the class of well-nested LCFRS that are the focus of this paper. Well-nestedness was first studied in the context of dependency grammars (Kuhlmann and Möhl, 2007). Kanazawa (2009) 278 defines well-nested multiple context-free grammars, which are weakly equivalent to well-nested LCFRS. A composition operation is called well-nested, if it does not contain a substring of the form xi,i1 ··· xj,j1 ··· xi,i2 ··· xj,j2 , where i =6 j . For example, the operation x1,1 x2,1$x2,2 x1,2 is wellnested, while</context>
</contexts>
<marker>Kallmeyer, Maier, 2009</marker>
<rawString>Laura Kallmeyer and Wolfgang Maier. 2009. An incremental Earley parser for simple range concatenation grammar. In Proceedings of the 11th International Conference on Parsing Technologies (IWPT 2009), pages 61–64. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Kanazawa</author>
<author>Sylvain Salvati</author>
</authors>
<title>The copying power of well-nested multiple context-free grammars.</title>
<date>2010</date>
<booktitle>In Fourth International Conference on Language and Automata Theory and Applications,</booktitle>
<location>Trier, Germany.</location>
<contexts>
<context position="5967" citStr="Kanazawa and Salvati (2010)" startWordPosition="917" endWordPosition="920"> components. Also, the construction in (Hotz and Pitsch, 1996) results in a blow-up of the grammar that is exponential in its fan-out, and the parsing algorithm that is derived runs in time O(4ϕ · |G |· |w|2ϕ+2). Our result is therefore a considerable asymptotic improvement over the CCFG result, both with respect to the normal form construction and the parsing efficiency. Finally, under a practical perspective, our parser is a simple chart-based algorithm, while the algorithm in (Hotz and Pitsch, 1996) involves two passes and is considerably more complex to analyze and to implement than ours. Kanazawa and Salvati (2010) mention a normal form for well-nested multiple context-free grammars. Structure In Section 2, we introduce LCFRS and the class of well-nested LCFRS that is the focus of this paper. In Section 3, we discuss the parsing complexity of LCFRS, and show why grammars using our normal form can be parsed efficiently. Section 4 presents the transformation of a well-nested LCFRS into the normal form. Section 5 concludes the paper. 2 Linear Context-Free Rewriting Systems We write [n] to denote the set of positive integers up to and including n: [n] = {1, ... , n}. 2.1 Linear, non-erasing functions Let Σ </context>
<context position="12786" citStr="Kanazawa and Salvati (2010)" startWordPosition="2213" endWordPosition="2217">öhl, 2007). Kanazawa (2009) 278 defines well-nested multiple context-free grammars, which are weakly equivalent to well-nested LCFRS. A composition operation is called well-nested, if it does not contain a substring of the form xi,i1 ··· xj,j1 ··· xi,i2 ··· xj,j2 , where i =6 j . For example, the operation x1,1 x2,1$x2,2 x1,2 is wellnested, while x1,1 x2,1 $ x1,2 x2,2 is not. An LCFRS is called well-nested, if it contains only well-nested composition operations. The class of languages generated by well-nested LCFRS is properly included in the class of languages generated by general LCFRS; see Kanazawa and Salvati (2010) for further discussion. 3 Parsing LCFRS We now discuss the parsing complexity of LCFRS, and motivate our interest in a normal form for wellnested LCFRS. 3.1 General parsing schema A bottom-up, chart-based parsing algorithm for the class of (not necessarily well-nested) LCFRS can be defined by using the formalism of parsing schemata (Sikkel, 1997). The parsing schemata approach considers parsing as a deduction process (as in Shieber et al. (1995)), generating intermediate results called items. Starting with an initial set of items obtained from each input sentence, a parsing schema defines a s</context>
</contexts>
<marker>Kanazawa, Salvati, 2010</marker>
<rawString>Makoto Kanazawa and Sylvain Salvati. 2010. The copying power of well-nested multiple context-free grammars. In Fourth International Conference on Language and Automata Theory and Applications, Trier, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Kanazawa</author>
</authors>
<title>The pumping lemma for wellnested multiple context-free languages.</title>
<date>2009</date>
<booktitle>In Developments in Language Theory. 13th International Conference, DLT 2009,</booktitle>
<volume>30</volume>
<pages>312--325</pages>
<location>Stuttgart, Germany,</location>
<contexts>
<context position="12186" citStr="Kanazawa (2009)" startWordPosition="2118" endWordPosition="2119">nto a weakly equivalent canonical LCFRS. However, we point out that both the normal form and the parsing algorithm that we present in this paper can be applied also to general LCFRS. This is in contrast to some left-to-right parsers in the literature on LCFRS and equivalent formalisms (de la Clergerie, 2002; Kallmeyer and Maier, 2009), which actually depend on productions in canonical form. 2.5 Well-nested LCFRS We now characterize the class of well-nested LCFRS that are the focus of this paper. Well-nestedness was first studied in the context of dependency grammars (Kuhlmann and Möhl, 2007). Kanazawa (2009) 278 defines well-nested multiple context-free grammars, which are weakly equivalent to well-nested LCFRS. A composition operation is called well-nested, if it does not contain a substring of the form xi,i1 ··· xj,j1 ··· xi,i2 ··· xj,j2 , where i =6 j . For example, the operation x1,1 x2,1$x2,2 x1,2 is wellnested, while x1,1 x2,1 $ x1,2 x2,2 is not. An LCFRS is called well-nested, if it contains only well-nested composition operations. The class of languages generated by well-nested LCFRS is properly included in the class of languages generated by general LCFRS; see Kanazawa and Salvati (2010)</context>
</contexts>
<marker>Kanazawa, 2009</marker>
<rawString>Makoto Kanazawa. 2009. The pumping lemma for wellnested multiple context-free languages. In Developments in Language Theory. 13th International Conference, DLT 2009, Stuttgart, Germany, June 30–July 3, 2009. Proceedings, volume 5583 of Lecture Notes in Computer Science, pages 312–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
<author>Mathias Möhl</author>
</authors>
<title>Mildly context-sensitive dependency languages.</title>
<date>2007</date>
<booktitle>In 45th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>160--167</pages>
<contexts>
<context position="12169" citStr="Kuhlmann and Möhl, 2007" startWordPosition="2114" endWordPosition="2117">LCFRS can be transformed into a weakly equivalent canonical LCFRS. However, we point out that both the normal form and the parsing algorithm that we present in this paper can be applied also to general LCFRS. This is in contrast to some left-to-right parsers in the literature on LCFRS and equivalent formalisms (de la Clergerie, 2002; Kallmeyer and Maier, 2009), which actually depend on productions in canonical form. 2.5 Well-nested LCFRS We now characterize the class of well-nested LCFRS that are the focus of this paper. Well-nestedness was first studied in the context of dependency grammars (Kuhlmann and Möhl, 2007). Kanazawa (2009) 278 defines well-nested multiple context-free grammars, which are weakly equivalent to well-nested LCFRS. A composition operation is called well-nested, if it does not contain a substring of the form xi,i1 ··· xj,j1 ··· xi,i2 ··· xj,j2 , where i =6 j . For example, the operation x1,1 x2,1$x2,2 x1,2 is wellnested, while x1,1 x2,1 $ x1,2 x2,2 is not. An LCFRS is called well-nested, if it contains only well-nested composition operations. The class of languages generated by well-nested LCFRS is properly included in the class of languages generated by general LCFRS; see Kanazawa a</context>
</contexts>
<marker>Kuhlmann, Möhl, 2007</marker>
<rawString>Marco Kuhlmann and Mathias Möhl. 2007. Mildly context-sensitive dependency languages. In 45th Annual Meeting of the Association for Computational Linguistics (ACL), pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
<author>Joakim Nivre</author>
</authors>
<title>Mildly nonprojective dependency structures.</title>
<date>2006</date>
<booktitle>In 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL), Main Conference Poster Sessions,</booktitle>
<pages>507--514</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="3417" citStr="Kuhlmann and Nivre, 2006" startWordPosition="498" endWordPosition="501">ly convenient in tabular parsing. This is in contrast with other mildly context-sensitive formalisms, and TAG in particular: TAGs can be parsed in polynomial time both with respect to grammar size and string size, and they can be cast in normal forms having binary derivation trees only. It has recently been argued that LCFRS might be too powerful for modeling languages with discontinuous constituents or with relatively free word order, and that additional restrictions on the rearrangement of components might be needed. More specifically, analyses of both dependency and constituency treebanks (Kuhlmann and Nivre, 2006; Havelka, 2007; Maier and Lichte, 2009) have shown that rearrangements of argument tuples almost always satisfy the so-called well-nestedness condition, a generalization 276 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 276–284, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics of the standard condition on balanced brackets. This condition states that any two components x1, x2 of some tuple will never be composed with any two components y1, y2 of some other tuple in such a way that a ‘crossing’ config</context>
<context position="31996" citStr="Kuhlmann and Nivre, 2006" startWordPosition="5721" endWordPosition="5724">ving O(cp · |G |· |w|2cp+2) time complexity when applied to LCFRS of fan-out cp in our normal form. This complexity is an asymptotic improvement over existing results for this class, both from parsers specifically geared to well-nested LCFRS or equivalent formalisms (Hotz and Pitsch, 1996) and from applying general LCFRS parsing techniques to the well-nested case (Seki et al., 1991). The class of well-nested LCFRS is an interesting syntactic formalism for languages with discontinuous constituents, providing a good balance between coverage of linguistic phenomena in natural language treebanks (Kuhlmann and Nivre, 2006; Maier and Lichte, 2009) and desirable formal properties (Kanazawa, 2009). Our results offer a further argument in support of well-nested LCFRS: while the complexity of parsing general LCFRS depends on two dimensions (rank and fan-out), this bidimensional hierarchy collapses into a single dimension in the well-nested case, where complexity is only conditioned by the fan-out. Acknowledgments Gómez-Rodríguez has been supported by MEC/FEDER (HUM2007-66607-C04) and Xunta de Galicia (PGIDIT07SIN005206PR, Redes Galegas de PL e RI e de Ling. de Corpus, Bolsas Estadías INCITE/FSE cofinanced). Kuhlman</context>
</contexts>
<marker>Kuhlmann, Nivre, 2006</marker>
<rawString>Marco Kuhlmann and Joakim Nivre. 2006. Mildly nonprojective dependency structures. In 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL), Main Conference Poster Sessions, pages 507–514, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
<author>Giorgio Satta</author>
</authors>
<title>Treebank grammar techniques for non-projective dependency parsing.</title>
<date>2009</date>
<booktitle>In Twelfth Conference of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>478--486</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="1910" citStr="Kuhlmann and Satta, 2009" startWordPosition="262" endWordPosition="265">stigation, mildly context-sensitive grammar formalisms have been introduced (Joshi, 1985), including, among several others, the tree adjoining grammars (TAGs) of Joshi et al. (1975). Linear context-free rewriting system (LCFRS), introduced by Vijay-Shanker et al. (1987), is a mildly context-sensitive formalism that allows the derivation of tuples of strings, i.e., discontinuous phrases. This feature has been used to model phrase structure treebanks with discontinuous constituents (Maier and Søgaard, 2008), as well as to map non-projective dependency trees into discontinuous phrase structures (Kuhlmann and Satta, 2009). Informally, in an LCFRS G, each nonterminal can generate string tuples with a fixed number of components. The fan-out of G is defined as the maximum number of tuple components generated by G. During a derivation of an LCFRS, tuple components generated by the nonterminals in the right-hand side of a production are concatenated to form new tuples, possibly adding some terminal symbols. The only restriction applying to these generalized concatenation operations is linearity, that is, components cannot be duplicated or deleted. The freedom in the rearrangement of components has specific conseque</context>
</contexts>
<marker>Kuhlmann, Satta, 2009</marker>
<rawString>Marco Kuhlmann and Giorgio Satta. 2009. Treebank grammar techniques for non-projective dependency parsing. In Twelfth Conference of the European Chapter of the Association for Computational Linguistics (EACL), pages 478–486, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Maier</author>
<author>Timm Lichte</author>
</authors>
<title>Characterizing discontinuity in constituent treebanks.</title>
<date>2009</date>
<booktitle>In 14th Conference on Formal Grammar,</booktitle>
<location>Bordeaux, France.</location>
<contexts>
<context position="3457" citStr="Maier and Lichte, 2009" startWordPosition="504" endWordPosition="507"> in contrast with other mildly context-sensitive formalisms, and TAG in particular: TAGs can be parsed in polynomial time both with respect to grammar size and string size, and they can be cast in normal forms having binary derivation trees only. It has recently been argued that LCFRS might be too powerful for modeling languages with discontinuous constituents or with relatively free word order, and that additional restrictions on the rearrangement of components might be needed. More specifically, analyses of both dependency and constituency treebanks (Kuhlmann and Nivre, 2006; Havelka, 2007; Maier and Lichte, 2009) have shown that rearrangements of argument tuples almost always satisfy the so-called well-nestedness condition, a generalization 276 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 276–284, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics of the standard condition on balanced brackets. This condition states that any two components x1, x2 of some tuple will never be composed with any two components y1, y2 of some other tuple in such a way that a ‘crossing’ configuration is realized. In this paper, we c</context>
<context position="32021" citStr="Maier and Lichte, 2009" startWordPosition="5725" endWordPosition="5728">) time complexity when applied to LCFRS of fan-out cp in our normal form. This complexity is an asymptotic improvement over existing results for this class, both from parsers specifically geared to well-nested LCFRS or equivalent formalisms (Hotz and Pitsch, 1996) and from applying general LCFRS parsing techniques to the well-nested case (Seki et al., 1991). The class of well-nested LCFRS is an interesting syntactic formalism for languages with discontinuous constituents, providing a good balance between coverage of linguistic phenomena in natural language treebanks (Kuhlmann and Nivre, 2006; Maier and Lichte, 2009) and desirable formal properties (Kanazawa, 2009). Our results offer a further argument in support of well-nested LCFRS: while the complexity of parsing general LCFRS depends on two dimensions (rank and fan-out), this bidimensional hierarchy collapses into a single dimension in the well-nested case, where complexity is only conditioned by the fan-out. Acknowledgments Gómez-Rodríguez has been supported by MEC/FEDER (HUM2007-66607-C04) and Xunta de Galicia (PGIDIT07SIN005206PR, Redes Galegas de PL e RI e de Ling. de Corpus, Bolsas Estadías INCITE/FSE cofinanced). Kuhlmann has been supported by t</context>
</contexts>
<marker>Maier, Lichte, 2009</marker>
<rawString>Wolfgang Maier and Timm Lichte. 2009. Characterizing discontinuity in constituent treebanks. In 14th Conference on Formal Grammar, Bordeaux, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Maier</author>
<author>Anders Søgaard</author>
</authors>
<title>Treebanks and mild context-sensitivity.</title>
<date>2008</date>
<booktitle>In 13th Conference on Formal Grammar,</booktitle>
<pages>61--76</pages>
<location>Hamburg, Germany.</location>
<contexts>
<context position="1795" citStr="Maier and Søgaard, 2008" startWordPosition="245" endWordPosition="248">ree grammars, but still remain below the full generative power of context-sensitive grammars. On this line of investigation, mildly context-sensitive grammar formalisms have been introduced (Joshi, 1985), including, among several others, the tree adjoining grammars (TAGs) of Joshi et al. (1975). Linear context-free rewriting system (LCFRS), introduced by Vijay-Shanker et al. (1987), is a mildly context-sensitive formalism that allows the derivation of tuples of strings, i.e., discontinuous phrases. This feature has been used to model phrase structure treebanks with discontinuous constituents (Maier and Søgaard, 2008), as well as to map non-projective dependency trees into discontinuous phrase structures (Kuhlmann and Satta, 2009). Informally, in an LCFRS G, each nonterminal can generate string tuples with a fixed number of components. The fan-out of G is defined as the maximum number of tuple components generated by G. During a derivation of an LCFRS, tuple components generated by the nonterminals in the right-hand side of a production are concatenated to form new tuples, possibly adding some terminal symbols. The only restriction applying to these generalized concatenation operations is linearity, that i</context>
</contexts>
<marker>Maier, Søgaard, 2008</marker>
<rawString>Wolfgang Maier and Anders Søgaard. 2008. Treebanks and mild context-sensitivity. In 13th Conference on Formal Grammar, pages 61–76, Hamburg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Owen Rambow</author>
<author>Giorgio Satta</author>
</authors>
<title>Independent parallelism in finite copying parallel rewriting systems.</title>
<date>1999</date>
<journal>Theoretical Computer Science,</journal>
<pages>223--1</pages>
<contexts>
<context position="2775" citStr="Rambow and Satta, 1999" startWordPosition="396" endWordPosition="399">s generated by the nonterminals in the right-hand side of a production are concatenated to form new tuples, possibly adding some terminal symbols. The only restriction applying to these generalized concatenation operations is linearity, that is, components cannot be duplicated or deleted. The freedom in the rearrangement of components has specific consequences in terms of the computational and descriptional complexity of LCFRS. Even for grammars with bounded fan-out, the universal recognition problem is NP-hard (Satta, 1992), and these systems lack Chomsky-like normal forms for fixed fan-out (Rambow and Satta, 1999) that are especially convenient in tabular parsing. This is in contrast with other mildly context-sensitive formalisms, and TAG in particular: TAGs can be parsed in polynomial time both with respect to grammar size and string size, and they can be cast in normal forms having binary derivation trees only. It has recently been argued that LCFRS might be too powerful for modeling languages with discontinuous constituents or with relatively free word order, and that additional restrictions on the rearrangement of components might be needed. More specifically, analyses of both dependency and consti</context>
<context position="18258" citStr="Rambow and Satta, 1999" startWordPosition="3225" endWordPosition="3228">ank ρ and where each nonterminal has fanout ϕ. The asymptotic time complexity of LCFRS parsing is therefore exponential both in its rank and its fan-out. This means that it is interesting to transform LCFRS into equivalent forms that reduce their rank while preserving the fan-out. For sets of LCFRS that can be transformed into a binary form (i.e., such that all its rules have rank at most 2), the ρ factor in the complexity is reduced to a constant, and complexity is improved to O(|w|3ϕ) (see Gómez-Rodríguez et al. (2009) for further discussion). Unfortunately, it is known by previous results (Rambow and Satta, 1999) that it is not always possible to convert an LCFRS into such a binary form without increasing the fan-out. However, we will show that it is always possible to build such a binarization for well-nested LCFRS. Combining this result with the inference rule and complexity analysis given above, we would obtain a parser for well-nested LCFRS running in O(|w|3ϕ) time. But the construction of our binary normal form additionally restricts binary composition operations in the binarized LCFRS to be of two specific forms, concatenation and wrapping, which further improves the parsing complexity to O(|w|2</context>
</contexts>
<marker>Rambow, Satta, 1999</marker>
<rawString>Owen Rambow and Giorgio Satta. 1999. Independent parallelism in finite copying parallel rewriting systems. Theoretical Computer Science, 223(1–2):87–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
</authors>
<title>Recognition of Linear ContextFree Rewriting Systems.</title>
<date>1992</date>
<booktitle>In 30th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>89--95</pages>
<location>Newark, DE, USA.</location>
<contexts>
<context position="2682" citStr="Satta, 1992" startWordPosition="384" endWordPosition="385"> tuple components generated by G. During a derivation of an LCFRS, tuple components generated by the nonterminals in the right-hand side of a production are concatenated to form new tuples, possibly adding some terminal symbols. The only restriction applying to these generalized concatenation operations is linearity, that is, components cannot be duplicated or deleted. The freedom in the rearrangement of components has specific consequences in terms of the computational and descriptional complexity of LCFRS. Even for grammars with bounded fan-out, the universal recognition problem is NP-hard (Satta, 1992), and these systems lack Chomsky-like normal forms for fixed fan-out (Rambow and Satta, 1999) that are especially convenient in tabular parsing. This is in contrast with other mildly context-sensitive formalisms, and TAG in particular: TAGs can be parsed in polynomial time both with respect to grammar size and string size, and they can be cast in normal forms having binary derivation trees only. It has recently been argued that LCFRS might be too powerful for modeling languages with discontinuous constituents or with relatively free word order, and that additional restrictions on the rearrange</context>
</contexts>
<marker>Satta, 1992</marker>
<rawString>Giorgio Satta. 1992. Recognition of Linear ContextFree Rewriting Systems. In 30th Annual Meeting of the Association for Computational Linguistics (ACL), pages 89–95, Newark, DE, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyuki Seki</author>
<author>Takashi Matsumura</author>
<author>Mamoru Fujii</author>
<author>Tadao Kasami</author>
</authors>
<title>On Multiple Context-Free Grammars.</title>
<date>1991</date>
<journal>Theoretical Computer Science,</journal>
<volume>88</volume>
<issue>2</issue>
<contexts>
<context position="4893" citStr="Seki et al., 1991" startWordPosition="742" endWordPosition="745">ic normal form with no more than two nonterminals in their productions’ right-hand sides. On the basis of this result, we then develop an efficient parsing algorithm for wellnested LCFRS, running in time O(ϕ · |G |· |w|2ϕ+2), where G and w are the input grammar and string, respectively. Well-nested LCFRS with fan-out ϕ = 2 are weakly equivalent to TAG, and our complexity result reduces to the well-known upper bound O(|G |· |w|6) for this class. For ϕ &gt; 2, our upper bound is asymptotically better than the one obtained from existing parsing algorithms for general LCFRS or equivalent formalisms (Seki et al., 1991). Well-nested LCFRS are generatively equivalent to (among others) coupled context-free grammars (CCFG), introduced by Hotz and Pitsch (1996). These authors also provide a normal form and develop a parsing algorithm for CCFGs. One difference with respect to our result is that the normal form for CCFGs allows more than two nonterminals to appear in the right-hand side of a production, even though no nonterminal may contribute more than two tuple components. Also, the construction in (Hotz and Pitsch, 1996) results in a blow-up of the grammar that is exponential in its fan-out, and the parsing al</context>
<context position="17477" citStr="Seki et al. (1991)" startWordPosition="3089" endWordPosition="3092">B, (l1, r1), ... , (lm, rm)] [C, (l01, r01),... (l0n, r0n)] __ __ [A, (l1, r1), ... (li, r01),... rZ 11, r� 1Z+1 (c) Deduction step for wrapping Figure 2: Deduction steps for parsing LCFRS. Thus, the parsing complexity (Gildea, 2010) of a production p = A0 → f(A1, ... , Am) is determined by ϕ(A0) l-indexes and i∈[m]ϕ(Ai) r-indexes, for a total complexity of O(|w|ϕ(A0)+EiE[�1 ϕ(Ai)) where |w |is the length of the input string. The parsing complexity of an LCFRS will correspond to the maximum parsing complexity among its productions. Note that this general complexity matches the result given by Seki et al. (1991). In an LCFRS of rank ρ and fan-out ϕ, the maximum possible parsing complexity is O(|w|ϕ(ρ+1)), obtained by applying the above expression to a production of rank ρ and where each nonterminal has fanout ϕ. The asymptotic time complexity of LCFRS parsing is therefore exponential both in its rank and its fan-out. This means that it is interesting to transform LCFRS into equivalent forms that reduce their rank while preserving the fan-out. For sets of LCFRS that can be transformed into a binary form (i.e., such that all its rules have rank at most 2), the ρ factor in the complexity is reduced to a</context>
<context position="31757" citStr="Seki et al., 1991" startWordPosition="5685" endWordPosition="5688">text-free rewriting systems, based on a new normal form for this formalism. The normal form takes up linear space with respect to grammar size, and the algorithm is based on a bottom-up process that can be applied to any LCFRS, achieving O(cp · |G |· |w|2cp+2) time complexity when applied to LCFRS of fan-out cp in our normal form. This complexity is an asymptotic improvement over existing results for this class, both from parsers specifically geared to well-nested LCFRS or equivalent formalisms (Hotz and Pitsch, 1996) and from applying general LCFRS parsing techniques to the well-nested case (Seki et al., 1991). The class of well-nested LCFRS is an interesting syntactic formalism for languages with discontinuous constituents, providing a good balance between coverage of linguistic phenomena in natural language treebanks (Kuhlmann and Nivre, 2006; Maier and Lichte, 2009) and desirable formal properties (Kanazawa, 2009). Our results offer a further argument in support of well-nested LCFRS: while the complexity of parsing general LCFRS depends on two dimensions (rank and fan-out), this bidimensional hierarchy collapses into a single dimension in the well-nested case, where complexity is only conditione</context>
</contexts>
<marker>Seki, Matsumura, Fujii, Kasami, 1991</marker>
<rawString>Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii, and Tadao Kasami. 1991. On Multiple Context-Free Grammars. Theoretical Computer Science, 88(2):191–229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
<author>Yves Schabes</author>
<author>Fernando Pereira</author>
</authors>
<title>Principles and implementation of deductive parsing.</title>
<date>1995</date>
<journal>Journal of Logic Programming,</journal>
<pages>24--1</pages>
<contexts>
<context position="13236" citStr="Shieber et al. (1995)" startWordPosition="2286" endWordPosition="2289">perations. The class of languages generated by well-nested LCFRS is properly included in the class of languages generated by general LCFRS; see Kanazawa and Salvati (2010) for further discussion. 3 Parsing LCFRS We now discuss the parsing complexity of LCFRS, and motivate our interest in a normal form for wellnested LCFRS. 3.1 General parsing schema A bottom-up, chart-based parsing algorithm for the class of (not necessarily well-nested) LCFRS can be defined by using the formalism of parsing schemata (Sikkel, 1997). The parsing schemata approach considers parsing as a deduction process (as in Shieber et al. (1995)), generating intermediate results called items. Starting with an initial set of items obtained from each input sentence, a parsing schema defines a set of deduction steps that can be used to infer new items from existing ones. Each item contains information about the sentence’s structure, and a successful parsing process will produce at least one final item containing a full parse for the input. The item set used by our bottom-up algorithm to parse an input string w = a1 · · · an with an LCFRS G = (N, T, P, S) will be I = {[A, (l1, r1), . . . , (lk, rk)] |A ∈ N ∧ 0 ≤ li ≤ ri ≤ n ∀i ∈ [k]}, wh</context>
</contexts>
<marker>Shieber, Schabes, Pereira, 1995</marker>
<rawString>Stuart M. Shieber, Yves Schabes, and Fernando Pereira. 1995. Principles and implementation of deductive parsing. Journal of Logic Programming, 24(1–2):3–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>Evidence against the contextfreeness of natural language.</title>
<date>1985</date>
<journal>Linguistics and Philosophy,</journal>
<volume>8</volume>
<issue>3</issue>
<contexts>
<context position="1076" citStr="Shieber (1985)" startWordPosition="145" endWordPosition="146">s has been empirically motivated for modeling of the syntax of languages with discontinuous constituents or relatively free word order. We present a chart-based parsing algorithm that asymptotically improves the known running time upper bound for this class of rewriting systems. Our result is obtained through a linear space construction of a binary normal form for the grammar at hand. 1 Introduction Since its earliest years, one of the main goals of computational linguistics has been the modeling of natural language syntax by means of formal grammars. Following results by Huybregts (1984) and Shieber (1985), special attention has been given to formalisms that enlarge the generative power of context-free grammars, but still remain below the full generative power of context-sensitive grammars. On this line of investigation, mildly context-sensitive grammar formalisms have been introduced (Joshi, 1985), including, among several others, the tree adjoining grammars (TAGs) of Joshi et al. (1975). Linear context-free rewriting system (LCFRS), introduced by Vijay-Shanker et al. (1987), is a mildly context-sensitive formalism that allows the derivation of tuples of strings, i.e., discontinuous phrases. T</context>
</contexts>
<marker>Shieber, 1985</marker>
<rawString>Stuart M. Shieber. 1985. Evidence against the contextfreeness of natural language. Linguistics and Philosophy, 8(3):333–343.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaas Sikkel</author>
</authors>
<title>Parsing Schemata: A Framework for Specification and Analysis of Parsing Algorithms.</title>
<date>1997</date>
<publisher>Springer.</publisher>
<contexts>
<context position="13135" citStr="Sikkel, 1997" startWordPosition="2271" endWordPosition="2272">,2 x2,2 is not. An LCFRS is called well-nested, if it contains only well-nested composition operations. The class of languages generated by well-nested LCFRS is properly included in the class of languages generated by general LCFRS; see Kanazawa and Salvati (2010) for further discussion. 3 Parsing LCFRS We now discuss the parsing complexity of LCFRS, and motivate our interest in a normal form for wellnested LCFRS. 3.1 General parsing schema A bottom-up, chart-based parsing algorithm for the class of (not necessarily well-nested) LCFRS can be defined by using the formalism of parsing schemata (Sikkel, 1997). The parsing schemata approach considers parsing as a deduction process (as in Shieber et al. (1995)), generating intermediate results called items. Starting with an initial set of items obtained from each input sentence, a parsing schema defines a set of deduction steps that can be used to infer new items from existing ones. Each item contains information about the sentence’s structure, and a successful parsing process will produce at least one final item containing a full parse for the input. The item set used by our bottom-up algorithm to parse an input string w = a1 · · · an with an LCFRS</context>
</contexts>
<marker>Sikkel, 1997</marker>
<rawString>Klaas Sikkel. 1997. Parsing Schemata: A Framework for Specification and Analysis of Parsing Algorithms. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>David J Weir</author>
<author>Aravind K Joshi</author>
</authors>
<title>Characterizing structural descriptions produced by various grammatical formalisms.</title>
<date>1987</date>
<booktitle>In 25th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>104--111</pages>
<location>Stanford, CA, USA.</location>
<contexts>
<context position="1555" citStr="Vijay-Shanker et al. (1987)" startWordPosition="211" endWordPosition="214">l linguistics has been the modeling of natural language syntax by means of formal grammars. Following results by Huybregts (1984) and Shieber (1985), special attention has been given to formalisms that enlarge the generative power of context-free grammars, but still remain below the full generative power of context-sensitive grammars. On this line of investigation, mildly context-sensitive grammar formalisms have been introduced (Joshi, 1985), including, among several others, the tree adjoining grammars (TAGs) of Joshi et al. (1975). Linear context-free rewriting system (LCFRS), introduced by Vijay-Shanker et al. (1987), is a mildly context-sensitive formalism that allows the derivation of tuples of strings, i.e., discontinuous phrases. This feature has been used to model phrase structure treebanks with discontinuous constituents (Maier and Søgaard, 2008), as well as to map non-projective dependency trees into discontinuous phrase structures (Kuhlmann and Satta, 2009). Informally, in an LCFRS G, each nonterminal can generate string tuples with a fixed number of components. The fan-out of G is defined as the maximum number of tuple components generated by G. During a derivation of an LCFRS, tuple components g</context>
</contexts>
<marker>Vijay-Shanker, Weir, Joshi, 1987</marker>
<rawString>K. Vijay-Shanker, David J. Weir, and Aravind K. Joshi. 1987. Characterizing structural descriptions produced by various grammatical formalisms. In 25th Annual Meeting of the Association for Computational Linguistics (ACL), pages 104–111, Stanford, CA, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>