<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.137136">
<title confidence="0.9987615">
What’s in a Name?
Entity Type Variation across Two Biomedical Subdomains
</title>
<author confidence="0.992778">
Claudiu Mih˘ail˘a and Riza Theresa Batista-Navarro
</author>
<affiliation confidence="0.9978725">
National Centre for Text Mining
School of Computer Science, University of Manchester
</affiliation>
<address confidence="0.742995">
Manchester Interdisciplinary Biocentre,
131 Princess Street, M1 7DN, Manchester, UK
</address>
<email confidence="0.9946205">
claudiu.mihaila@cs.man.ac.uk
riza.batista-navarro@cs.man.ac.uk
</email>
<sectionHeader confidence="0.995577" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999797333333333">
There are lexical, syntactic, semantic and
discourse variations amongst the languages
used in various biomedical subdomains. It
is important to recognise such differences
and understand that biomedical tools that
work well on some subdomains may not
work as well on others. We report here
on the semantic variations that occur in
the sublanguages of two biomedical subdo-
mains, i.e. cell biology and pharmacology,
at the level of named entity information. By
building a classifier using ratios of named
entities as features, we show that named en-
tity information can discriminate between
documents from each subdomain. More
specifically, our classifier can distinguish
between documents belonging to each sub-
domain with an accuracy of 91.1% F-score.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999301211538462">
Biomedical information extraction efforts in the
past decade have focussed on fundamental tasks
needed to create intelligent systems capable
of improving search engine results and easing
the work of biologists. More specifically, re-
searchers have concentrated mainly on named en-
tity recognition, mapping them to concepts in
curated databases (Krallinger et al., 2008) and
extracting simple binary relations between enti-
ties. Recently, an increasing number of resources
that facilitate the training of systems to extract
more detailed information have become available,
e.g., PennBioIE (Kulick et al., 2004), GENE-
TAG (Tanabe et al., 2005), BioInfer (Pyysalo et
al., 2007), GENIA (Kim et al., 2008), GREC
(Thompson et al., 2009) and Metaknowledge GE-
NIA (Thompson et al., 2011). Moreover, several
other annotated corpora have been developed for
shared task purposes, such as BioCreative I, II, III
(Arighi et al., 2011) and BioNLP Shared Tasks
2009 and 2011 (Cohen et al., 2009; Kim et al.,
2011).
Many of the tools currently used for biomedi-
cal language processing were trained and evalu-
ated on such popular corpora, most of which con-
sist of documents from the molecular biology sub-
domain. However, previous studies (discussed in
Section 2) have established that different biomed-
ical sublanguages exhibit linguistic variations. It
follows that tools which were developed and eval-
uated on corpora derived from one subdomain
might not always perform as well on corpora from
other subdomains. Understanding these linguistic
variations is essential to the process of adaptat-
ing natural language processing tools to new do-
mains.
In this paper, we highlight the variations be-
tween biomedical sublanguages by focussing on
the different types of named entities (NEs) that
are relevant to them. We show that the frequen-
cies of different named entity types vary enough
to allow a classifier for scientific subdomains to
be built based upon them.
The study is performed on open access jour-
nal articles present in the UK PubMed Central1
(UKPMC) (McEntyre et al., 2010), an article
database that extends the functionality of the orig-
inal PubMed Central (PMC) repository2. This
database was chosen as our source, since most of
the documents within it are already tagged with
named entity information. We report here on the
results obtained for two biomedical subdomains,
</bodyText>
<footnote confidence="0.999242">
1http://ukpmc.ac.uk/
2http://www.ncbi.nlm.nih.gov/pmc
</footnote>
<page confidence="0.977741">
38
</page>
<note confidence="0.903524">
Proceedings of the EACL 2012 Student Research Workshop, pages 38–45,
Avignon, France, 26 April 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999785428571428">
i.e. cell biology and pharmacology. Our focus on
these two particular subdomains is motivated by
an increasing interest expressed by the biomedi-
cal research community, according to recent find-
ings that have shown their relevance to discover-
ing possible causes and treatments for incurable
diseases, such as cancer or Alzheimer’s Disease.
</bodyText>
<sectionHeader confidence="0.999549" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999964975609757">
Harris (1968) introduced a formalisation of the
notion of sublanguage, which was defined as a
subset of general language. According to this
theory, it is possible to process specialised lan-
guages, since they have a structure that can be ex-
pressed in a computable form. More recently, sev-
eral works on the study of biomedical languages
substantiated his theory.
For instance, Sager et al. (1987) worked on
pharmacological literature and lipid metabolism,
whereas Friedman et al. (2002) analysed the prop-
erties of clinical and biomolecular sublanguages.
Other studies have investigated the differ-
ences between general and biomedical lan-
guages by focussing on specific linguistic aspects,
such as verb-argument relations and pronomi-
nal anaphora. For instance, Wattarujeekrit et al.
(2004) analysed the predicate-argument structures
of 30 verbs used in biomedical articles. Their re-
sults suggest that, in certain cases, a significant
difference exists in the predicate frames compared
to those obtained from analysing news articles in
the PropBank project (Palmer et al., 2005). Sim-
ilarly, based on the GENIA and PennBioIE cor-
pora, Cohen et al. (2008) performed a study of
argument realisation with respect to the nominal-
isation and alternation of biomedical verbs. They
concluded that there is a high occurrence of these
phenomena in this semantically restricted do-
main, and underline that this sublanguage model
applies only to biomedical language.
Taking a different angle, Nguyen and Kim
(2008) examined the differences in the use of
pronouns by studying general domains (MUC
and ACE) and one biomedical domain (GENIA).
They observed that compared to the MUC and
ACE corpora, the GENIA corpus has significantly
more occurrences of neutral and third-person pro-
nouns, whilst first and second person pronouns
are non-existent.
Verspoor et al. (2009) measured lexical and
structural variation in biomedical Open Access
journals and subscription-based journals, con-
cluding that there are no significant differences
between them. Therefore, a model trained on one
of these sources can be used successfully on the
other, as long as the subject matter is maintained.
Furthermore, they compared a mouse genomics
corpus with two reference corpora, one composed
of newswire texts and another of general biomed-
ical articles. In this case, unsurprisingly, signifi-
cant differences were found across many linguis-
tic dimensions. Relevant to our study is the com-
parison between the more specific mouse genome
corpus to the more general biomedical one: whilst
similar from some points of view, such as nega-
tion and passivisation, they differ in sentence
length and semantic features, such as the presence
of various named entities.
Our work is most similar to that of Lippincott
et al. (2011), in which a clustering-based quantita-
tive analysis of the linguistic variations across 38
different biomedical sublanguages is presented.
They investigated four dimensions relevant to the
performance of NLP systems, i.e. vocabulary,
syntax, semantics and discourse structure. With
regard to semantic features, the authors induced
a topic model using Latent Dirichlet Analysis for
each word, and then extended the model to docu-
ments and subdomains according to observed dis-
tributions. Their conclusion is that a machine
learning system is able to create robust clusters
of subdomains, thus proving their hypothesis that
the commonly used molecular biology subdomain
is not representative of the domain as a whole.
In contrast, we examine the differences be-
tween biomedical sublanguages at the semantic
level, using only named entities. Furthermore,
we choose to perform our analysis only on two
subdomains (i.e. cell biology and pharmacology),
and try to classify these by using supervised ma-
chine learning algorithms.
</bodyText>
<sectionHeader confidence="0.99781" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.999893222222222">
We designed an experiment in which various ma-
chine learning algorithms are trained and tested
on data obtained from open access journal arti-
cles. Firstly, a corpus of articles was created (Sec-
tion 3.1), after which the documents were auto-
matically annotated with named entities (Section
3.2). We then extracted a number features rele-
vant to the named entities present in the corpus
(Section 3.3).
</bodyText>
<page confidence="0.996155">
39
</page>
<subsectionHeader confidence="0.997795">
3.1 Corpus development
</subsectionHeader>
<bodyText confidence="0.99995671875">
Our corpus was created by first searching the
NLM Catalog3 for journals whose Broad Sub-
ject Term attributes contain only cell biology or
pharmacology, and then narrowing down the re-
sults to those which are in English and avail-
able via PubMed Central. Also, since we are
concentrating on full-text documents, we retained
only those journals that are available within the
PubMed Open Access subset4. According to this
procedure, we obtained a final list of two journals
for cell biology and six for pharmacology.
Using the PMC IDs of all articles published
in the selected journals, we retrieved documents
from UK PubMed Central. This database was
chosen as our source as the documents it contains
are already tagged with named entity information.
A total of 360 articles was retrieved for each cat-
egory, i.e. cell biology and pharmacology.
The retrieved documents were encoded in
XML format. Several unusable fragments were
removed before converting them to plain text. Ex-
amples of such fragments are article metadata (au-
thors, their affiliations, publishing history, etc.),
tables, figures and references. Table 1 shows the
statistics regarding the corpus following the ap-
plication of the pre-processing step. In the case
of pharmacology, the document collection con-
tains almost 1.4 million words, whilst the set of
cell biology articles consists of almost 2.5 million
words. The ratio of named entities to the total
number of words is almost the same in the two
collections, i.e. about 10%.
</bodyText>
<table confidence="0.80086675">
Subdomain Cell biology Pharmacology
No. of docs. 360 360
No. of words 2.49 m. 1.35 m.
No. of NEs 231761 103484
</table>
<tableCaption confidence="0.999761">
Table 1: Named entity types and their source.
</tableCaption>
<subsectionHeader confidence="0.999942">
3.2 Tagging of Named Entities
</subsectionHeader>
<bodyText confidence="0.99991025">
To extract named entities from the corpus, we
used a simple method that augments the named
entities present in the UKPMC articles with the
output of two named entity recognition tools
</bodyText>
<footnote confidence="0.97774675">
3http://www.ncbi.nlm.nih.gov/
nlmcatalog
4http://www.ncbi.nlm.nih.gov/pmc/
tools/openftlist
</footnote>
<bodyText confidence="0.999935428571428">
(NERs), i.e. NeMine and OSCAR. The types of
entities in the output be each of the two tools, to-
gether with the NE types present in the UKPMC
articles, are summarised in Table 2.
Named entities in the UKPMC database were
identified using NeMine (Sasaki et al., 2008), a
dictionary-based statistical named entity recogni-
tion system. This system was later extended and
used by Nobata et al. (2009) to recognise more
types, such as phenomena, processes, organs and
symptoms. We used this most recent version of
the software as our second source of more diverse
entity types.
The Open-Source Chemistry Analysis Rou-
tines (OSCAR) software (Jessop et al., 2011) is
a toolkit for the recognition of named entities and
data in chemistry publications. Currently in its
fourth version, it uses three types of chemical en-
tity recognisers, namely regular expressions, pat-
terns and Maximum Entropy Markov models.
In total, 20 different classes of entities were
considered in this study. However, due to the
combination of several NERs, some NE types are
identified by more than one NER. Furthermore,
some of the NE types are more general and cover
other more specific types, which are also anno-
tated by one or mroe of the tools. This can lead to
double annotation. For instance, the Gene|Protein
type is more general than both Gene and Protein,
whereas the Chemical molecule type is a hyper-
nym of Gene, Protein, Drug and Metabolite. In
the case of multiple annotations over the same
span of text, we removed the more general labels,
so that each NE has only one label. Contradictory
cases, where two NERs label one NE with com-
pletely different tags, were not found.
After augmenting the existing NEs by running
the two NER tools on the corpus, the outputs were
combined to give a single “silver” annotation list.
This operation was performed by computing the
mathematical union of the three individual anno-
tation sets, as shown in Equation 1.
</bodyText>
<equation confidence="0.729389">
Asilver = AUKPMC U AOscar U ANeMine (1)
</equation>
<bodyText confidence="0.999939833333333">
Table 3 shows the ratios of named entities to the
number of words in each subcorpus. The Pz� sign
indicates strictly positive percentages, but which
are rounded down to zero in this table for for-
matting purposes. In the four places where it oc-
curs, the percentages lie between 0% and 0.005%,
</bodyText>
<page confidence="0.97695">
40
</page>
<table confidence="0.999940714285714">
Type UKPMC NeMine OSCAR
Gene ✓ ✓
Protein ✓ ✓
Gene|Protein ✓
Disease ✓ ✓
Drug ✓ ✓
Metabolite ✓ ✓
Bacteria ✓
Diagnostic process ✓
General phenomenon ✓
Human phenomenon ✓
Indicator ✓
Natural phenomenon ✓
Organ ✓
Pathologic function ✓
Symptom ✓
Therapeutic process ✓
Chemical molecule ✓
Chemical adjective ✓
Enzyme ✓
Reaction ✓
</table>
<tableCaption confidence="0.999546">
Table 2: Named entity types and their source.
</tableCaption>
<bodyText confidence="0.999937888888889">
exclusively. It can be observed that some entity
types have approximately the same percentages in
the two subdomains, e.g. phenomena and reac-
tions. However, large differences can be observed
in the case of some of the other entity types. For
instance, chemical molecules occur twice as of-
ten in pharmacology articles than in cell biology,
whereas proteins appear almost three times more
often in cell biology than in pharmacology.
</bodyText>
<subsectionHeader confidence="0.993357">
3.3 Experimental setup
</subsectionHeader>
<bodyText confidence="0.999972">
Using the corpus described previously, we cre-
ated a training set for supervised machine learn-
ing algorithms. Every document in the corpus
was transformed into a vector consisting of 20
features. Each of these features corresponds to
an entity type in Table 2, having a numeric value
ranging from 0 to 1. This number represents the
ratio of the specific entity type to the total number
of named entities recognised in that document, as
shown in Equation 2.
</bodyText>
<equation confidence="0.996923">
0 = nN e (2)
</equation>
<bodyText confidence="0.999862370370371">
where ntype represents the number of NEs of a
certain type in a document and N represents the
total number of NEs in that document.
Furthermore, each vector was labelled with the
subdomain to which the respective document be-
longs (i.e., cell biology or pharmacology).
Weka (Witten and Frank, 2005; Hall et al.,
2009) was employed as the machine learning
framework, due to its large variety of classifica-
tion algorithms. We experimented with a large
number of classifiers, ranging from Bayesian nets
to functions, decision trees, decision rules and
meta-classifiers. The best performing classifiers
are shown in Table 4. BayesNet is an implemen-
tation of Bayesian Networks, SMO is an imple-
mentation of Support Vector Machines, J48 is an
implementation of decision trees, whilst Jrip is an
implementation of decision rules. Random For-
est is an ensemble classifier that consists of many
decision trees (in this study, J48 was used), out-
putting the class that occurs most frequently in the
output of individual trees.
The baseline that has been used is ZeroR, a sim-
ple algorithm that classifies all instances as per-
taining to the majority class. Since our classes
have equal numbers of instances, the F-score of
ZeroR is 50%.
</bodyText>
<page confidence="0.998529">
41
</page>
<table confidence="0.999902">
Type CellBio Pharma
Enzyme 0.05% 0.09%
Bacteria 0.01% 0.16%
Chemical adjective PZ�0% PZ�0%
Chemical molecule 30.13% 60.86%
Diagnose process 0.03% 0.23%
Disease 3.35% 4.27%
Drug 1.25% 2.83%
Gene 0.87% 1.09%
Gene|Protein 5.02% 0.89%
General phenomenon PZ�0% 0.01%
Human phenomenon 0% PZ�0%
Indicator 0.36% 0.16%
Metabolite 3.26% 7.53%
Natural phenomenon 0.02% 0.1%
Organ 0.09% 0.27%
Pathologic function 0.04% 0.04%
Protein 53.31% 19.13%
Reaction 1.71% 1.31%
Symptom 0.03% 0.06%
Therapeutic process 0.47% 0.96%
</table>
<tableCaption confidence="0.9614165">
Table 3: Ratios of NE types to the total number of NEs
in the two subdomains.
</tableCaption>
<sectionHeader confidence="0.99972" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.99988325">
The previously described features were used as in-
put to various supervised machine learning algo-
rithms; results and error analysis are provided in
Section 4.1 and Section 4.2, respectively.
</bodyText>
<subsectionHeader confidence="0.984097">
4.1 Experimental results
</subsectionHeader>
<bodyText confidence="0.99913075">
As can be seen from Table 4, Random Forest
performs best, with 91.1% F-score. The other
three classifiers give lower results, varying be-
tween 86% and 89.5%.
</bodyText>
<table confidence="0.999857">
Algorithm P R F1
BayesNet 89.5 89.4 89.4
SMO 86.1 86.1 86.1
JRip 87.8 87.8 87.8
J48 86.8 86.8 86.8
Random Forest 91.3 91.1 91.1
</table>
<tableCaption confidence="0.992443">
Table 4: Classification results for the best-performing
algorithms.
</tableCaption>
<bodyText confidence="0.999409333333333">
We also employed AdaBoost in conjunction
with the previously mentioned four classifiers,
and the results are given in Table 5. AdaBoost
is a meta-algorithm that adapts itself during the
course of several iterations in the sense that in
each iteration, classifiers built are tweaked to cor-
rect those instances misclassified by prior classi-
fiers. In this study, AdaBoost was run over 20
iterations, and it significantly improved the result
of J48, by almost 4%, to 90.3%. However, Ad-
aBoost decreased the F-score of Random Forest
by 1% and that of BayesNet by 0.3%.
</bodyText>
<table confidence="0.999853166666667">
Algorithm P R F1
BayesNet 89.2 89.2 89.2
SMO 86.1 86.1 86.1
JRip 87.9 87.9 87.9
J48 90.3 90.3 90.3
Random Forest 90.3 90.1 90.1
</table>
<tableCaption confidence="0.9711755">
Table 5: Classification results for AdaBoost in con-
junction with the best-performing algorithms.
</tableCaption>
<bodyText confidence="0.999967655172414">
In order to determine which features have the
most influence on classification, regardless of
the classifying algorithm, two attribute evaluators
were used to measure the information gain for
each feature and to compute the value of the chi-
squared statistic with respect to the class. The val-
ues obtained are shown in Table 6, and to illustrate
their influence, are plotted in Figure 1, after being
normalised.
Unsurprisingly, Protein is the feature with the
most discriminatory power, considering it has the
highest count and it occurs almost three times
more often in the cell biology class than in the
pharmacology class. Chemical molecules follow
closely, again due to a high count and large differ-
ence between the classes. Due to their high scores
obtained from the attribute evaluators, we ran the
experiment again considering only these two fea-
tures. The Random Forest classifier achieved an
F-score of 80% using these parameters.
At the other end of the scale, there are five
features which have very little influence in dis-
criminating between the two classes. The corre-
sponding named entity types have the lowest oc-
currence counts in the corpora, with the exception
of Organ. When running Random Forest with
these five features only, an F-score of 50.5% is
obtained. This result is very close to the baseline,
surpassing it by only a small fraction.
</bodyText>
<subsectionHeader confidence="0.987037">
4.2 Error analysis
</subsectionHeader>
<bodyText confidence="0.970305">
As can be seen in Table 7, a total of 64 papers
were misclassified by the Random Forest classi-
</bodyText>
<page confidence="0.996355">
42
</page>
<table confidence="0.999927619047619">
Attribute InfoGain ChiSquare
Protein 0.4482 386.5648
Chemical molecule 0.3169 272.0111
Gene|Protein 0.2265 211.8034
Indicator 0.1805 170.0186
Gene 0.1718 156.9504
Metabolite 0.1667 155.8135
Reaction 0.1545 144.6946
Drug 0.1301 124.2604
Therapeutic process 0.1259 111.4571
Disease 0.1189 111.1882
Chemical adjective 0.0642 55.5556
Enzyme 0.0473 41.089
Diagnostic process 0.0388 32.1161
Bacteria 0.0297 26.0522
Natural phenomenon 0.0227 20.8004
Pathologic function 0 0
Symptom 0 0
General phenomenon 0 0
Organ 0 0
Human phenomenon 0 0
</table>
<tableCaption confidence="0.990948">
Table 6: Attribute selection output from two attribute
evaluators.
</tableCaption>
<bodyText confidence="0.99921">
fier, the best performing algorithm. Of these, 45
(i.e. 70%) are cell biology papers which were in-
correctly classified as belonging to pharmacology,
whilst the remaining 19 belong to the pharmacol-
ogy class and are classified as cell biology.
</bodyText>
<table confidence="0.993900666666667">
Labelled as Cell_bio Pharma
Cell_bio 315 19
Pharma 45 341
</table>
<tableCaption confidence="0.984963">
Table 7: Confusion matrix for the Random Forest clas-
sifier.
</tableCaption>
<bodyText confidence="0.999922615384615">
As previously mentioned, the two features that
achieved the highest information gain are the ra-
tios for the Protein and Chemical molecule types.
Accordingly, only these two features were consid-
ered in this error analysis.
We firstly examined the features of the cell
biology documents which were incorrectly clas-
sified as pharmacology papers. It was notice-
able that the majority of the misclassified doc-
uments in this case have a small percentage of
Proteins (less than 0.35) and/or a large percent-
age of Chemical molecules (greater than 0.58). To
confirm this observation, a sample of documents
</bodyText>
<figureCaption confidence="0.998713">
Figure 1: Normalised attribute selection output from
two attribute evaluators.
</figureCaption>
<bodyText confidence="0.999962823529412">
was accessed via the PubMed Central page which
provides links to identified entities such as com-
pounds, substances, genes and proteins. For in-
stance, the misclassified cell biology paper with
PMCID 2755470 was found to have no proteins,
whilst the one with PMCID 2679709 has quite a
large number of substances (chemical molecules).
We also analysed the features of papers in the
pharmacology subdomain which were misclassi-
fied as cell biology documents. In contrast to
the first type of misclassification, these documents
have a large percentage of Proteins and/or small
percentage of Chemical molecules. For example,
the pharmacology paper with PMCID 2817930
contains many protein instances, whilst the one
with PMCID 2680808 has no mentions of chemi-
cal molecules.
</bodyText>
<sectionHeader confidence="0.998268" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999428">
We have shown that with the help of named en-
tity identification, classifiers can be built that are
able to distinguish between papers belonging to
different biomedical subdomains. The Random
Forest algorithm is able to discriminate between
cell biology and pharmacology open-access full-
text articles with an F-score of 91%. This result
supports the hypothesis that sublanguages used in
different biomedical domains exhibit significant
semantic variations. Such variations should there-
fore be considered when adapting automated tools
</bodyText>
<figure confidence="0.999133083333333">
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
InfoGain
ChiSquare
</figure>
<page confidence="0.999773">
43
</page>
<bodyText confidence="0.999885076923077">
developed for a particular subdomain to new sub-
domains.
One possible future direction is to analyse mul-
tiple medical subdomains, such as neurology, vi-
rology and critical care. This could enable the
measurement of the distance between various sub-
domains with respect to specific named entity
types. Furthermore, a comparison of the method
described above with those using bag-of-words
or other non-semantic features could further en-
force the importance of named entities in doc-
ument classification and sublanguage identifica-
tion.
</bodyText>
<sectionHeader confidence="0.996932" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9995875">
We would like to acknowledge the help given
by Dr. C.J. Rupp in obtaining the collection of
documents from the Open Access section of the
UKMPC.
</bodyText>
<sectionHeader confidence="0.998161" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999867954545455">
Cecilia Arighi, Zhiyong Lu, Martin Krallinger, Kevin
Cohen, W Wilbur, Alfonso Valencia, Lynette
Hirschman, and Cathy Wu. 2011. Overview of
the BioCreative III Workshop. BMC Bioinformat-
ics, 12(Suppl 8):S1.
Kevin Bretonnel Cohen, Martha Palmer, and Lawrence
Hunter. 2008. Nominalization and alternations in
biomedical language. PLoS ONE, 3(9):e3158, 09.
Kevin Bretonnel Cohen, Dina Demner-Fushman,
Sophia Ananiadou, John Pestian, Jun’ichi Tsujii,
and Bonnie Webber, editors. 2009. Proceedings of
the BioNLP 2009 Workshop. Association for Com-
putational Linguistics, Boulder, Colorado, June.
Carol Friedman, Pauline Kra, and Andrey Rzhetsky.
2002. Two biomedical sublanguages: a description
based on the theories of Zellig Harris. Journal of
Biomedical Informatics, 35(4):222–235.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The weka data mining software: An update.
SIGKDD Explorations, 11(1).
Zellig Harris. 1968. Mathematical Structures of Lan-
guage. John Wiley and Son, New York.
David Jessop, Sam Adams, Egon Willighagen, Lezan
Hawizy, and Peter Murray-Rust. 2011. Oscar4:
a flexible architecture for chemical text-mining.
Journal of Cheminformatics, 3(1):41.
Jin-Dong Kim, Tomoko Ohta, and Jun’ichi Tsujii.
2008. Corpus annotation for mining biomedi-
cal events from literature. BMC Bioinformatics,
9(1):10.
Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-
nori Yonezawa. 2011. Overview of genia event
task in bionlp shared task 2011. In Proceedings
of BioNLP Shared Task 2011 Workshop, pages 7–
15, Portland, Oregon, USA, June. Association for
Computational Linguistics.
Martin Krallinger, Alexander Morgan, Larry Smith,
Florian Leitner, Lorraine Tanabe, John Wilbur,
Lynette Hirschman, and Alfonso Valencia. 2008.
Evaluation of text-mining systems for biology:
overview of the second biocreative community
challenge. Genome Biology, 9(Suppl 2):S1.
Seth Kulick, Ann Bies, Mark Liberman, Mark Mandel,
Ryan McDonald, Martha Palmer, Andrew Schein,
and Lyle Ungar. 2004. Integrated annotation for
biomedical information extraction. In Proceedings
of the BioLINK 2004.
Thomas Lippincott, Diarmuid Seaghdha, and Anna
Korhonen. 2011. Exploring subdomain varia-
tion in biomedical language. BMC Bioinformatics,
12(1):212.
Johanna R. McEntyre, Sophia Ananiadou, Stephen
Andrews, William J. Black, Richard Boulderstone,
Paula Buttery, David Chaplin, Sandeepreddy Che-
vuru, Norman Cobley, Lee-Ann Coleman, Paul
Davey, Bharti Gupta, Lesley Haji-Gholam, Craig
Hawkins, Alan Horne, Simon J. Hubbard, Jee-
Hyub Kim, Ian Lewin, Vic Lyte, Ross MacIn-
tyre, Sami Mansoor, Linda Mason, John Mc-
Naught, Elizabeth Newbold, Chikashi Nobata,
Ernest Ong, Sharmila Pillai, Dietrich Rebholz-
Schuhmann, Heather Rosie, Rob Rowbotham, C. J.
Rupp, Peter Stoehr, and Philip Vaughan. 2010.
UKPMC: a full text article resource for the life sci-
ences. Nucleic Acids Research.
Ngan L. T. Nguyen and Jin-Dong Kim. 2008. Explor-
ing domain differences for the design of pronoun
resolution systems for biomedical text. In Proceed-
ings of the 22nd International Conference on Com-
putational Linguistics - Volume 1, COLING ’08,
pages 625–632, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Chikashi Nobata, Yutaka Sasaki, Noaki Okazaki,
C. J. Rupp, Jun’ichi Tsujii, and Sophia Ananiadou.
2009. Semantic search on digital document reposi-
tories based on text mining results. In International
Conferences on Digital Libraries and the Semantic
Web 2009 (ICSD2009), pages 34–48.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The proposition bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31(1):71–105.
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari
Bjorne, Jorma Boberg, Jouni Jarvinen, and Tapio
Salakoski. 2007. BioInfer: a corpus for infor-
mation extraction in the biomedical domain. BMC
Bioinformatics, 8(1):50.
</reference>
<page confidence="0.979781">
44
</page>
<reference confidence="0.999354741935484">
Naomi Sager, Carol Friedman, and Margaret Lyman.
1987. Medical Language Processing: Computer
Management of Narrative Data. Addison-Wesley,
Reading, MA.
Yutaka Sasaki, Yoshimasa Tsuruoka, John McNaught,
and Sophia Ananiadou. 2008. How to make the
most of NE dictionaries in statistical NER. BMC
Bioinformatics, 9(Suppl 11):S5.
Lorraine Tanabe, Natalie Xie, Lynne Thom, Wayne
Matten, and W John Wilbur. 2005. GENETAG: a
tagged corpus for gene/protein named entity recog-
nition. BMCBioinformatics, 6(Suppl 1):S3.
Paul Thompson, Syed Iqbal, John McNaught, and
Sophia Ananiadou. 2009. Construction of an an-
notated corpus to support biomedical information
extraction. BMCBioinformatics, 10(1):349.
Paul Thompson, Raheel Nawaz, John McNaught, and
Sophia Ananiadou. 2011. Enriching a biomedi-
cal event corpus with meta-knowledge annotation.
BMCBioinformatics, 12(1):393.
Karin Verspoor, Kevin Bretonnel Cohen, and
Lawrence Hunter. 2009. The textual characteristics
of traditional and open access scientific journals are
similar. BMC Bioinformatics, 10(1):183.
Tuangthong Wattarujeekrit, Parantu Shah, and Nigel
Collier. 2004. PASBio: predicate-argument struc-
tures for event extraction in molecular biology.
BMC Bioinformatics, 5(1):155.
Ian Witten and Eibe Frank. 2005. Data Mining: Prac-
tical Machine Learning Tools and Techniques (Sec-
ond Edition). Morgan Kaufmann.
</reference>
<page confidence="0.99939">
45
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.603651">
<title confidence="0.995063">What’s in a Name? Entity Type Variation across Two Biomedical Subdomains</title>
<author confidence="0.97006">Claudiu Mih˘ail˘a</author>
<author confidence="0.97006">Riza Theresa</author>
<affiliation confidence="0.979927333333333">National Centre for Text School of Computer Science, University of Manchester Interdisciplinary</affiliation>
<address confidence="0.983205">131 Princess Street, M1 7DN, Manchester,</address>
<email confidence="0.999752">riza.batista-navarro@cs.man.ac.uk</email>
<abstract confidence="0.982388684210526">There are lexical, syntactic, semantic and discourse variations amongst the languages used in various biomedical subdomains. It is important to recognise such differences and understand that biomedical tools that work well on some subdomains may not work as well on others. We report here on the semantic variations that occur in the sublanguages of two biomedical subdomains, i.e. cell biology and pharmacology, at the level of named entity information. By building a classifier using ratios of named entities as features, we show that named entity information can discriminate between documents from each subdomain. More specifically, our classifier can distinguish between documents belonging to each subdomain with an accuracy of 91.1% F-score.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Cecilia Arighi</author>
<author>Zhiyong Lu</author>
<author>Martin Krallinger</author>
<author>Kevin Cohen</author>
<author>W Wilbur</author>
<author>Alfonso Valencia</author>
<author>Lynette Hirschman</author>
<author>Cathy Wu</author>
</authors>
<date>2011</date>
<booktitle>Overview of the BioCreative III Workshop. BMC Bioinformatics, 12(Suppl 8):S1.</booktitle>
<contexts>
<context position="2045" citStr="Arighi et al., 2011" startWordPosition="292" endWordPosition="295">mapping them to concepts in curated databases (Krallinger et al., 2008) and extracting simple binary relations between entities. Recently, an increasing number of resources that facilitate the training of systems to extract more detailed information have become available, e.g., PennBioIE (Kulick et al., 2004), GENETAG (Tanabe et al., 2005), BioInfer (Pyysalo et al., 2007), GENIA (Kim et al., 2008), GREC (Thompson et al., 2009) and Metaknowledge GENIA (Thompson et al., 2011). Moreover, several other annotated corpora have been developed for shared task purposes, such as BioCreative I, II, III (Arighi et al., 2011) and BioNLP Shared Tasks 2009 and 2011 (Cohen et al., 2009; Kim et al., 2011). Many of the tools currently used for biomedical language processing were trained and evaluated on such popular corpora, most of which consist of documents from the molecular biology subdomain. However, previous studies (discussed in Section 2) have established that different biomedical sublanguages exhibit linguistic variations. It follows that tools which were developed and evaluated on corpora derived from one subdomain might not always perform as well on corpora from other subdomains. Understanding these linguist</context>
</contexts>
<marker>Arighi, Lu, Krallinger, Cohen, Wilbur, Valencia, Hirschman, Wu, 2011</marker>
<rawString>Cecilia Arighi, Zhiyong Lu, Martin Krallinger, Kevin Cohen, W Wilbur, Alfonso Valencia, Lynette Hirschman, and Cathy Wu. 2011. Overview of the BioCreative III Workshop. BMC Bioinformatics, 12(Suppl 8):S1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Bretonnel Cohen</author>
<author>Martha Palmer</author>
<author>Lawrence Hunter</author>
</authors>
<title>Nominalization and alternations in biomedical language.</title>
<date>2008</date>
<journal>PLoS ONE,</journal>
<volume>3</volume>
<issue>9</issue>
<pages>09</pages>
<contexts>
<context position="5191" citStr="Cohen et al. (2008)" startWordPosition="777" endWordPosition="780">molecular sublanguages. Other studies have investigated the differences between general and biomedical languages by focussing on specific linguistic aspects, such as verb-argument relations and pronominal anaphora. For instance, Wattarujeekrit et al. (2004) analysed the predicate-argument structures of 30 verbs used in biomedical articles. Their results suggest that, in certain cases, a significant difference exists in the predicate frames compared to those obtained from analysing news articles in the PropBank project (Palmer et al., 2005). Similarly, based on the GENIA and PennBioIE corpora, Cohen et al. (2008) performed a study of argument realisation with respect to the nominalisation and alternation of biomedical verbs. They concluded that there is a high occurrence of these phenomena in this semantically restricted domain, and underline that this sublanguage model applies only to biomedical language. Taking a different angle, Nguyen and Kim (2008) examined the differences in the use of pronouns by studying general domains (MUC and ACE) and one biomedical domain (GENIA). They observed that compared to the MUC and ACE corpora, the GENIA corpus has significantly more occurrences of neutral and thir</context>
</contexts>
<marker>Cohen, Palmer, Hunter, 2008</marker>
<rawString>Kevin Bretonnel Cohen, Martha Palmer, and Lawrence Hunter. 2008. Nominalization and alternations in biomedical language. PLoS ONE, 3(9):e3158, 09.</rawString>
</citation>
<citation valid="true">
<date>2009</date>
<booktitle>Proceedings of the BioNLP 2009 Workshop. Association for Computational Linguistics,</booktitle>
<editor>Kevin Bretonnel Cohen, Dina Demner-Fushman, Sophia Ananiadou, John Pestian, Jun’ichi Tsujii, and Bonnie Webber, editors.</editor>
<location>Boulder, Colorado,</location>
<contexts>
<context position="5890" citStr="(2009)" startWordPosition="888" endWordPosition="888"> of biomedical verbs. They concluded that there is a high occurrence of these phenomena in this semantically restricted domain, and underline that this sublanguage model applies only to biomedical language. Taking a different angle, Nguyen and Kim (2008) examined the differences in the use of pronouns by studying general domains (MUC and ACE) and one biomedical domain (GENIA). They observed that compared to the MUC and ACE corpora, the GENIA corpus has significantly more occurrences of neutral and third-person pronouns, whilst first and second person pronouns are non-existent. Verspoor et al. (2009) measured lexical and structural variation in biomedical Open Access journals and subscription-based journals, concluding that there are no significant differences between them. Therefore, a model trained on one of these sources can be used successfully on the other, as long as the subject matter is maintained. Furthermore, they compared a mouse genomics corpus with two reference corpora, one composed of newswire texts and another of general biomedical articles. In this case, unsurprisingly, significant differences were found across many linguistic dimensions. Relevant to our study is the comp</context>
<context position="10623" citStr="(2009)" startWordPosition="1634" endWordPosition="1634">od that augments the named entities present in the UKPMC articles with the output of two named entity recognition tools 3http://www.ncbi.nlm.nih.gov/ nlmcatalog 4http://www.ncbi.nlm.nih.gov/pmc/ tools/openftlist (NERs), i.e. NeMine and OSCAR. The types of entities in the output be each of the two tools, together with the NE types present in the UKPMC articles, are summarised in Table 2. Named entities in the UKPMC database were identified using NeMine (Sasaki et al., 2008), a dictionary-based statistical named entity recognition system. This system was later extended and used by Nobata et al. (2009) to recognise more types, such as phenomena, processes, organs and symptoms. We used this most recent version of the software as our second source of more diverse entity types. The Open-Source Chemistry Analysis Routines (OSCAR) software (Jessop et al., 2011) is a toolkit for the recognition of named entities and data in chemistry publications. Currently in its fourth version, it uses three types of chemical entity recognisers, namely regular expressions, patterns and Maximum Entropy Markov models. In total, 20 different classes of entities were considered in this study. However, due to the co</context>
</contexts>
<marker>2009</marker>
<rawString>Kevin Bretonnel Cohen, Dina Demner-Fushman, Sophia Ananiadou, John Pestian, Jun’ichi Tsujii, and Bonnie Webber, editors. 2009. Proceedings of the BioNLP 2009 Workshop. Association for Computational Linguistics, Boulder, Colorado, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carol Friedman</author>
<author>Pauline Kra</author>
<author>Andrey Rzhetsky</author>
</authors>
<title>Two biomedical sublanguages: a description based on the theories of Zellig Harris.</title>
<date>2002</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>35</volume>
<issue>4</issue>
<contexts>
<context position="4528" citStr="Friedman et al. (2002)" startWordPosition="678" endWordPosition="681">eir relevance to discovering possible causes and treatments for incurable diseases, such as cancer or Alzheimer’s Disease. 2 Related work Harris (1968) introduced a formalisation of the notion of sublanguage, which was defined as a subset of general language. According to this theory, it is possible to process specialised languages, since they have a structure that can be expressed in a computable form. More recently, several works on the study of biomedical languages substantiated his theory. For instance, Sager et al. (1987) worked on pharmacological literature and lipid metabolism, whereas Friedman et al. (2002) analysed the properties of clinical and biomolecular sublanguages. Other studies have investigated the differences between general and biomedical languages by focussing on specific linguistic aspects, such as verb-argument relations and pronominal anaphora. For instance, Wattarujeekrit et al. (2004) analysed the predicate-argument structures of 30 verbs used in biomedical articles. Their results suggest that, in certain cases, a significant difference exists in the predicate frames compared to those obtained from analysing news articles in the PropBank project (Palmer et al., 2005). Similarly</context>
</contexts>
<marker>Friedman, Kra, Rzhetsky, 2002</marker>
<rawString>Carol Friedman, Pauline Kra, and Andrey Rzhetsky. 2002. Two biomedical sublanguages: a description based on the theories of Zellig Harris. Journal of Biomedical Informatics, 35(4):222–235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The weka data mining software: An update.</title>
<date>2009</date>
<journal>SIGKDD Explorations,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="14101" citStr="Hall et al., 2009" startWordPosition="2224" endWordPosition="2227"> consisting of 20 features. Each of these features corresponds to an entity type in Table 2, having a numeric value ranging from 0 to 1. This number represents the ratio of the specific entity type to the total number of named entities recognised in that document, as shown in Equation 2. 0 = nN e (2) where ntype represents the number of NEs of a certain type in a document and N represents the total number of NEs in that document. Furthermore, each vector was labelled with the subdomain to which the respective document belongs (i.e., cell biology or pharmacology). Weka (Witten and Frank, 2005; Hall et al., 2009) was employed as the machine learning framework, due to its large variety of classification algorithms. We experimented with a large number of classifiers, ranging from Bayesian nets to functions, decision trees, decision rules and meta-classifiers. The best performing classifiers are shown in Table 4. BayesNet is an implementation of Bayesian Networks, SMO is an implementation of Support Vector Machines, J48 is an implementation of decision trees, whilst Jrip is an implementation of decision rules. Random Forest is an ensemble classifier that consists of many decision trees (in this study, J4</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The weka data mining software: An update. SIGKDD Explorations, 11(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<title>Mathematical Structures of Language.</title>
<date>1968</date>
<publisher>John Wiley and Son,</publisher>
<location>New York.</location>
<contexts>
<context position="4057" citStr="Harris (1968)" startWordPosition="605" endWordPosition="606">obtained for two biomedical subdomains, 1http://ukpmc.ac.uk/ 2http://www.ncbi.nlm.nih.gov/pmc 38 Proceedings of the EACL 2012 Student Research Workshop, pages 38–45, Avignon, France, 26 April 2012. c�2012 Association for Computational Linguistics i.e. cell biology and pharmacology. Our focus on these two particular subdomains is motivated by an increasing interest expressed by the biomedical research community, according to recent findings that have shown their relevance to discovering possible causes and treatments for incurable diseases, such as cancer or Alzheimer’s Disease. 2 Related work Harris (1968) introduced a formalisation of the notion of sublanguage, which was defined as a subset of general language. According to this theory, it is possible to process specialised languages, since they have a structure that can be expressed in a computable form. More recently, several works on the study of biomedical languages substantiated his theory. For instance, Sager et al. (1987) worked on pharmacological literature and lipid metabolism, whereas Friedman et al. (2002) analysed the properties of clinical and biomolecular sublanguages. Other studies have investigated the differences between gener</context>
</contexts>
<marker>Harris, 1968</marker>
<rawString>Zellig Harris. 1968. Mathematical Structures of Language. John Wiley and Son, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Jessop</author>
<author>Sam Adams</author>
<author>Egon Willighagen</author>
<author>Lezan Hawizy</author>
<author>Peter Murray-Rust</author>
</authors>
<title>Oscar4: a flexible architecture for chemical text-mining.</title>
<date>2011</date>
<journal>Journal of Cheminformatics,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="10882" citStr="Jessop et al., 2011" startWordPosition="1672" endWordPosition="1675">e types of entities in the output be each of the two tools, together with the NE types present in the UKPMC articles, are summarised in Table 2. Named entities in the UKPMC database were identified using NeMine (Sasaki et al., 2008), a dictionary-based statistical named entity recognition system. This system was later extended and used by Nobata et al. (2009) to recognise more types, such as phenomena, processes, organs and symptoms. We used this most recent version of the software as our second source of more diverse entity types. The Open-Source Chemistry Analysis Routines (OSCAR) software (Jessop et al., 2011) is a toolkit for the recognition of named entities and data in chemistry publications. Currently in its fourth version, it uses three types of chemical entity recognisers, namely regular expressions, patterns and Maximum Entropy Markov models. In total, 20 different classes of entities were considered in this study. However, due to the combination of several NERs, some NE types are identified by more than one NER. Furthermore, some of the NE types are more general and cover other more specific types, which are also annotated by one or mroe of the tools. This can lead to double annotation. For</context>
</contexts>
<marker>Jessop, Adams, Willighagen, Hawizy, Murray-Rust, 2011</marker>
<rawString>David Jessop, Sam Adams, Egon Willighagen, Lezan Hawizy, and Peter Murray-Rust. 2011. Oscar4: a flexible architecture for chemical text-mining. Journal of Cheminformatics, 3(1):41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Corpus annotation for mining biomedical events from literature.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<issue>1</issue>
<contexts>
<context position="1825" citStr="Kim et al., 2008" startWordPosition="257" endWordPosition="260">undamental tasks needed to create intelligent systems capable of improving search engine results and easing the work of biologists. More specifically, researchers have concentrated mainly on named entity recognition, mapping them to concepts in curated databases (Krallinger et al., 2008) and extracting simple binary relations between entities. Recently, an increasing number of resources that facilitate the training of systems to extract more detailed information have become available, e.g., PennBioIE (Kulick et al., 2004), GENETAG (Tanabe et al., 2005), BioInfer (Pyysalo et al., 2007), GENIA (Kim et al., 2008), GREC (Thompson et al., 2009) and Metaknowledge GENIA (Thompson et al., 2011). Moreover, several other annotated corpora have been developed for shared task purposes, such as BioCreative I, II, III (Arighi et al., 2011) and BioNLP Shared Tasks 2009 and 2011 (Cohen et al., 2009; Kim et al., 2011). Many of the tools currently used for biomedical language processing were trained and evaluated on such popular corpora, most of which consist of documents from the molecular biology subdomain. However, previous studies (discussed in Section 2) have established that different biomedical sublanguages e</context>
</contexts>
<marker>Kim, Ohta, Tsujii, 2008</marker>
<rawString>Jin-Dong Kim, Tomoko Ohta, and Jun’ichi Tsujii. 2008. Corpus annotation for mining biomedical events from literature. BMC Bioinformatics, 9(1):10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Yue Wang</author>
<author>Toshihisa Takagi</author>
<author>Akinori Yonezawa</author>
</authors>
<title>Overview of genia event task in bionlp shared task 2011.</title>
<date>2011</date>
<booktitle>In Proceedings of BioNLP Shared Task 2011 Workshop, pages 7– 15,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="2122" citStr="Kim et al., 2011" startWordPosition="307" endWordPosition="310">acting simple binary relations between entities. Recently, an increasing number of resources that facilitate the training of systems to extract more detailed information have become available, e.g., PennBioIE (Kulick et al., 2004), GENETAG (Tanabe et al., 2005), BioInfer (Pyysalo et al., 2007), GENIA (Kim et al., 2008), GREC (Thompson et al., 2009) and Metaknowledge GENIA (Thompson et al., 2011). Moreover, several other annotated corpora have been developed for shared task purposes, such as BioCreative I, II, III (Arighi et al., 2011) and BioNLP Shared Tasks 2009 and 2011 (Cohen et al., 2009; Kim et al., 2011). Many of the tools currently used for biomedical language processing were trained and evaluated on such popular corpora, most of which consist of documents from the molecular biology subdomain. However, previous studies (discussed in Section 2) have established that different biomedical sublanguages exhibit linguistic variations. It follows that tools which were developed and evaluated on corpora derived from one subdomain might not always perform as well on corpora from other subdomains. Understanding these linguistic variations is essential to the process of adaptating natural language proc</context>
</contexts>
<marker>Kim, Wang, Takagi, Yonezawa, 2011</marker>
<rawString>Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Akinori Yonezawa. 2011. Overview of genia event task in bionlp shared task 2011. In Proceedings of BioNLP Shared Task 2011 Workshop, pages 7– 15, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Krallinger</author>
<author>Alexander Morgan</author>
<author>Larry Smith</author>
<author>Florian Leitner</author>
<author>Lorraine Tanabe</author>
<author>John Wilbur</author>
<author>Lynette Hirschman</author>
<author>Alfonso Valencia</author>
</authors>
<title>Evaluation of text-mining systems for biology: overview of the second biocreative community challenge. Genome Biology, 9(Suppl 2):S1.</title>
<date>2008</date>
<contexts>
<context position="1496" citStr="Krallinger et al., 2008" startWordPosition="207" endWordPosition="210">ies as features, we show that named entity information can discriminate between documents from each subdomain. More specifically, our classifier can distinguish between documents belonging to each subdomain with an accuracy of 91.1% F-score. 1 Introduction Biomedical information extraction efforts in the past decade have focussed on fundamental tasks needed to create intelligent systems capable of improving search engine results and easing the work of biologists. More specifically, researchers have concentrated mainly on named entity recognition, mapping them to concepts in curated databases (Krallinger et al., 2008) and extracting simple binary relations between entities. Recently, an increasing number of resources that facilitate the training of systems to extract more detailed information have become available, e.g., PennBioIE (Kulick et al., 2004), GENETAG (Tanabe et al., 2005), BioInfer (Pyysalo et al., 2007), GENIA (Kim et al., 2008), GREC (Thompson et al., 2009) and Metaknowledge GENIA (Thompson et al., 2011). Moreover, several other annotated corpora have been developed for shared task purposes, such as BioCreative I, II, III (Arighi et al., 2011) and BioNLP Shared Tasks 2009 and 2011 (Cohen et al</context>
</contexts>
<marker>Krallinger, Morgan, Smith, Leitner, Tanabe, Wilbur, Hirschman, Valencia, 2008</marker>
<rawString>Martin Krallinger, Alexander Morgan, Larry Smith, Florian Leitner, Lorraine Tanabe, John Wilbur, Lynette Hirschman, and Alfonso Valencia. 2008. Evaluation of text-mining systems for biology: overview of the second biocreative community challenge. Genome Biology, 9(Suppl 2):S1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seth Kulick</author>
<author>Ann Bies</author>
<author>Mark Liberman</author>
<author>Mark Mandel</author>
<author>Ryan McDonald</author>
<author>Martha Palmer</author>
<author>Andrew Schein</author>
<author>Lyle Ungar</author>
</authors>
<title>Integrated annotation for biomedical information extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of the BioLINK</booktitle>
<contexts>
<context position="1735" citStr="Kulick et al., 2004" startWordPosition="241" endWordPosition="244"> Introduction Biomedical information extraction efforts in the past decade have focussed on fundamental tasks needed to create intelligent systems capable of improving search engine results and easing the work of biologists. More specifically, researchers have concentrated mainly on named entity recognition, mapping them to concepts in curated databases (Krallinger et al., 2008) and extracting simple binary relations between entities. Recently, an increasing number of resources that facilitate the training of systems to extract more detailed information have become available, e.g., PennBioIE (Kulick et al., 2004), GENETAG (Tanabe et al., 2005), BioInfer (Pyysalo et al., 2007), GENIA (Kim et al., 2008), GREC (Thompson et al., 2009) and Metaknowledge GENIA (Thompson et al., 2011). Moreover, several other annotated corpora have been developed for shared task purposes, such as BioCreative I, II, III (Arighi et al., 2011) and BioNLP Shared Tasks 2009 and 2011 (Cohen et al., 2009; Kim et al., 2011). Many of the tools currently used for biomedical language processing were trained and evaluated on such popular corpora, most of which consist of documents from the molecular biology subdomain. However, previous </context>
</contexts>
<marker>Kulick, Bies, Liberman, Mandel, McDonald, Palmer, Schein, Ungar, 2004</marker>
<rawString>Seth Kulick, Ann Bies, Mark Liberman, Mark Mandel, Ryan McDonald, Martha Palmer, Andrew Schein, and Lyle Ungar. 2004. Integrated annotation for biomedical information extraction. In Proceedings of the BioLINK 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Lippincott</author>
<author>Diarmuid Seaghdha</author>
<author>Anna Korhonen</author>
</authors>
<title>Exploring subdomain variation in biomedical language.</title>
<date>2011</date>
<journal>BMC Bioinformatics,</journal>
<volume>12</volume>
<issue>1</issue>
<contexts>
<context position="6818" citStr="Lippincott et al. (2011)" startWordPosition="1031" endWordPosition="1034">ntained. Furthermore, they compared a mouse genomics corpus with two reference corpora, one composed of newswire texts and another of general biomedical articles. In this case, unsurprisingly, significant differences were found across many linguistic dimensions. Relevant to our study is the comparison between the more specific mouse genome corpus to the more general biomedical one: whilst similar from some points of view, such as negation and passivisation, they differ in sentence length and semantic features, such as the presence of various named entities. Our work is most similar to that of Lippincott et al. (2011), in which a clustering-based quantitative analysis of the linguistic variations across 38 different biomedical sublanguages is presented. They investigated four dimensions relevant to the performance of NLP systems, i.e. vocabulary, syntax, semantics and discourse structure. With regard to semantic features, the authors induced a topic model using Latent Dirichlet Analysis for each word, and then extended the model to documents and subdomains according to observed distributions. Their conclusion is that a machine learning system is able to create robust clusters of subdomains, thus proving th</context>
</contexts>
<marker>Lippincott, Seaghdha, Korhonen, 2011</marker>
<rawString>Thomas Lippincott, Diarmuid Seaghdha, and Anna Korhonen. 2011. Exploring subdomain variation in biomedical language. BMC Bioinformatics, 12(1):212.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Johanna R McEntyre</author>
<author>Sophia Ananiadou</author>
<author>Stephen Andrews</author>
<author>William J Black</author>
<author>Richard Boulderstone</author>
<author>Paula Buttery</author>
<author>David Chaplin</author>
<author>Sandeepreddy Chevuru</author>
<author>Norman Cobley</author>
<author>Lee-Ann Coleman</author>
<author>Paul Davey</author>
<author>Bharti Gupta</author>
<author>Lesley Haji-Gholam</author>
<author>Craig Hawkins</author>
<author>Alan Horne</author>
<author>Simon J Hubbard</author>
<author>JeeHyub Kim</author>
</authors>
<title>UKPMC: a full text article resource for the life sciences.</title>
<date>2010</date>
<journal>Nucleic Acids Research.</journal>
<location>Ian Lewin, Vic Lyte, Ross MacIntyre, Sami Mansoor, Linda Mason, John McNaught, Elizabeth Newbold, Chikashi Nobata, Ernest Ong, Sharmila</location>
<contexts>
<context position="3183" citStr="McEntyre et al., 2010" startWordPosition="477" endWordPosition="480">lways perform as well on corpora from other subdomains. Understanding these linguistic variations is essential to the process of adaptating natural language processing tools to new domains. In this paper, we highlight the variations between biomedical sublanguages by focussing on the different types of named entities (NEs) that are relevant to them. We show that the frequencies of different named entity types vary enough to allow a classifier for scientific subdomains to be built based upon them. The study is performed on open access journal articles present in the UK PubMed Central1 (UKPMC) (McEntyre et al., 2010), an article database that extends the functionality of the original PubMed Central (PMC) repository2. This database was chosen as our source, since most of the documents within it are already tagged with named entity information. We report here on the results obtained for two biomedical subdomains, 1http://ukpmc.ac.uk/ 2http://www.ncbi.nlm.nih.gov/pmc 38 Proceedings of the EACL 2012 Student Research Workshop, pages 38–45, Avignon, France, 26 April 2012. c�2012 Association for Computational Linguistics i.e. cell biology and pharmacology. Our focus on these two particular subdomains is motivate</context>
</contexts>
<marker>McEntyre, Ananiadou, Andrews, Black, Boulderstone, Buttery, Chaplin, Chevuru, Cobley, Coleman, Davey, Gupta, Haji-Gholam, Hawkins, Horne, Hubbard, Kim, 2010</marker>
<rawString>Johanna R. McEntyre, Sophia Ananiadou, Stephen Andrews, William J. Black, Richard Boulderstone, Paula Buttery, David Chaplin, Sandeepreddy Chevuru, Norman Cobley, Lee-Ann Coleman, Paul Davey, Bharti Gupta, Lesley Haji-Gholam, Craig Hawkins, Alan Horne, Simon J. Hubbard, JeeHyub Kim, Ian Lewin, Vic Lyte, Ross MacIntyre, Sami Mansoor, Linda Mason, John McNaught, Elizabeth Newbold, Chikashi Nobata, Ernest Ong, Sharmila Pillai, Dietrich RebholzSchuhmann, Heather Rosie, Rob Rowbotham, C. J. Rupp, Peter Stoehr, and Philip Vaughan. 2010. UKPMC: a full text article resource for the life sciences. Nucleic Acids Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ngan L T Nguyen</author>
<author>Jin-Dong Kim</author>
</authors>
<title>Exploring domain differences for the design of pronoun resolution systems for biomedical text.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1, COLING ’08,</booktitle>
<pages>625--632</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="5538" citStr="Nguyen and Kim (2008)" startWordPosition="830" endWordPosition="833">ir results suggest that, in certain cases, a significant difference exists in the predicate frames compared to those obtained from analysing news articles in the PropBank project (Palmer et al., 2005). Similarly, based on the GENIA and PennBioIE corpora, Cohen et al. (2008) performed a study of argument realisation with respect to the nominalisation and alternation of biomedical verbs. They concluded that there is a high occurrence of these phenomena in this semantically restricted domain, and underline that this sublanguage model applies only to biomedical language. Taking a different angle, Nguyen and Kim (2008) examined the differences in the use of pronouns by studying general domains (MUC and ACE) and one biomedical domain (GENIA). They observed that compared to the MUC and ACE corpora, the GENIA corpus has significantly more occurrences of neutral and third-person pronouns, whilst first and second person pronouns are non-existent. Verspoor et al. (2009) measured lexical and structural variation in biomedical Open Access journals and subscription-based journals, concluding that there are no significant differences between them. Therefore, a model trained on one of these sources can be used success</context>
</contexts>
<marker>Nguyen, Kim, 2008</marker>
<rawString>Ngan L. T. Nguyen and Jin-Dong Kim. 2008. Exploring domain differences for the design of pronoun resolution systems for biomedical text. In Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1, COLING ’08, pages 625–632, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chikashi Nobata</author>
<author>Yutaka Sasaki</author>
<author>Noaki Okazaki</author>
<author>C J Rupp</author>
<author>Jun’ichi Tsujii</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Semantic search on digital document repositories based on text mining results.</title>
<date>2009</date>
<booktitle>In International Conferences on Digital Libraries and the Semantic Web</booktitle>
<pages>34--48</pages>
<contexts>
<context position="10623" citStr="Nobata et al. (2009)" startWordPosition="1631" endWordPosition="1634"> a simple method that augments the named entities present in the UKPMC articles with the output of two named entity recognition tools 3http://www.ncbi.nlm.nih.gov/ nlmcatalog 4http://www.ncbi.nlm.nih.gov/pmc/ tools/openftlist (NERs), i.e. NeMine and OSCAR. The types of entities in the output be each of the two tools, together with the NE types present in the UKPMC articles, are summarised in Table 2. Named entities in the UKPMC database were identified using NeMine (Sasaki et al., 2008), a dictionary-based statistical named entity recognition system. This system was later extended and used by Nobata et al. (2009) to recognise more types, such as phenomena, processes, organs and symptoms. We used this most recent version of the software as our second source of more diverse entity types. The Open-Source Chemistry Analysis Routines (OSCAR) software (Jessop et al., 2011) is a toolkit for the recognition of named entities and data in chemistry publications. Currently in its fourth version, it uses three types of chemical entity recognisers, namely regular expressions, patterns and Maximum Entropy Markov models. In total, 20 different classes of entities were considered in this study. However, due to the co</context>
</contexts>
<marker>Nobata, Sasaki, Okazaki, Rupp, Tsujii, Ananiadou, 2009</marker>
<rawString>Chikashi Nobata, Yutaka Sasaki, Noaki Okazaki, C. J. Rupp, Jun’ichi Tsujii, and Sophia Ananiadou. 2009. Semantic search on digital document repositories based on text mining results. In International Conferences on Digital Libraries and the Semantic Web 2009 (ICSD2009), pages 34–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The proposition bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="5117" citStr="Palmer et al., 2005" startWordPosition="763" endWordPosition="766"> whereas Friedman et al. (2002) analysed the properties of clinical and biomolecular sublanguages. Other studies have investigated the differences between general and biomedical languages by focussing on specific linguistic aspects, such as verb-argument relations and pronominal anaphora. For instance, Wattarujeekrit et al. (2004) analysed the predicate-argument structures of 30 verbs used in biomedical articles. Their results suggest that, in certain cases, a significant difference exists in the predicate frames compared to those obtained from analysing news articles in the PropBank project (Palmer et al., 2005). Similarly, based on the GENIA and PennBioIE corpora, Cohen et al. (2008) performed a study of argument realisation with respect to the nominalisation and alternation of biomedical verbs. They concluded that there is a high occurrence of these phenomena in this semantically restricted domain, and underline that this sublanguage model applies only to biomedical language. Taking a different angle, Nguyen and Kim (2008) examined the differences in the use of pronouns by studying general domains (MUC and ACE) and one biomedical domain (GENIA). They observed that compared to the MUC and ACE corpor</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The proposition bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sampo Pyysalo</author>
<author>Filip Ginter</author>
<author>Juho Heimonen</author>
<author>Jari Bjorne</author>
<author>Jorma Boberg</author>
<author>Jouni Jarvinen</author>
<author>Tapio Salakoski</author>
</authors>
<title>BioInfer: a corpus for information extraction in the biomedical domain.</title>
<date>2007</date>
<journal>BMC Bioinformatics,</journal>
<volume>8</volume>
<issue>1</issue>
<contexts>
<context position="1799" citStr="Pyysalo et al., 2007" startWordPosition="252" endWordPosition="255">past decade have focussed on fundamental tasks needed to create intelligent systems capable of improving search engine results and easing the work of biologists. More specifically, researchers have concentrated mainly on named entity recognition, mapping them to concepts in curated databases (Krallinger et al., 2008) and extracting simple binary relations between entities. Recently, an increasing number of resources that facilitate the training of systems to extract more detailed information have become available, e.g., PennBioIE (Kulick et al., 2004), GENETAG (Tanabe et al., 2005), BioInfer (Pyysalo et al., 2007), GENIA (Kim et al., 2008), GREC (Thompson et al., 2009) and Metaknowledge GENIA (Thompson et al., 2011). Moreover, several other annotated corpora have been developed for shared task purposes, such as BioCreative I, II, III (Arighi et al., 2011) and BioNLP Shared Tasks 2009 and 2011 (Cohen et al., 2009; Kim et al., 2011). Many of the tools currently used for biomedical language processing were trained and evaluated on such popular corpora, most of which consist of documents from the molecular biology subdomain. However, previous studies (discussed in Section 2) have established that different</context>
</contexts>
<marker>Pyysalo, Ginter, Heimonen, Bjorne, Boberg, Jarvinen, Salakoski, 2007</marker>
<rawString>Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari Bjorne, Jorma Boberg, Jouni Jarvinen, and Tapio Salakoski. 2007. BioInfer: a corpus for information extraction in the biomedical domain. BMC Bioinformatics, 8(1):50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naomi Sager</author>
<author>Carol Friedman</author>
<author>Margaret Lyman</author>
</authors>
<date>1987</date>
<booktitle>Medical Language Processing: Computer Management of Narrative Data.</booktitle>
<publisher>Addison-Wesley,</publisher>
<location>Reading, MA.</location>
<contexts>
<context position="4438" citStr="Sager et al. (1987)" startWordPosition="666" endWordPosition="669">d by the biomedical research community, according to recent findings that have shown their relevance to discovering possible causes and treatments for incurable diseases, such as cancer or Alzheimer’s Disease. 2 Related work Harris (1968) introduced a formalisation of the notion of sublanguage, which was defined as a subset of general language. According to this theory, it is possible to process specialised languages, since they have a structure that can be expressed in a computable form. More recently, several works on the study of biomedical languages substantiated his theory. For instance, Sager et al. (1987) worked on pharmacological literature and lipid metabolism, whereas Friedman et al. (2002) analysed the properties of clinical and biomolecular sublanguages. Other studies have investigated the differences between general and biomedical languages by focussing on specific linguistic aspects, such as verb-argument relations and pronominal anaphora. For instance, Wattarujeekrit et al. (2004) analysed the predicate-argument structures of 30 verbs used in biomedical articles. Their results suggest that, in certain cases, a significant difference exists in the predicate frames compared to those obta</context>
</contexts>
<marker>Sager, Friedman, Lyman, 1987</marker>
<rawString>Naomi Sager, Carol Friedman, and Margaret Lyman. 1987. Medical Language Processing: Computer Management of Narrative Data. Addison-Wesley, Reading, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yutaka Sasaki</author>
<author>Yoshimasa Tsuruoka</author>
<author>John McNaught</author>
<author>Sophia Ananiadou</author>
</authors>
<title>How to make the most of NE dictionaries in statistical NER. BMC Bioinformatics, 9(Suppl 11):S5.</title>
<date>2008</date>
<contexts>
<context position="10494" citStr="Sasaki et al., 2008" startWordPosition="1611" endWordPosition="1614">84 Table 1: Named entity types and their source. 3.2 Tagging of Named Entities To extract named entities from the corpus, we used a simple method that augments the named entities present in the UKPMC articles with the output of two named entity recognition tools 3http://www.ncbi.nlm.nih.gov/ nlmcatalog 4http://www.ncbi.nlm.nih.gov/pmc/ tools/openftlist (NERs), i.e. NeMine and OSCAR. The types of entities in the output be each of the two tools, together with the NE types present in the UKPMC articles, are summarised in Table 2. Named entities in the UKPMC database were identified using NeMine (Sasaki et al., 2008), a dictionary-based statistical named entity recognition system. This system was later extended and used by Nobata et al. (2009) to recognise more types, such as phenomena, processes, organs and symptoms. We used this most recent version of the software as our second source of more diverse entity types. The Open-Source Chemistry Analysis Routines (OSCAR) software (Jessop et al., 2011) is a toolkit for the recognition of named entities and data in chemistry publications. Currently in its fourth version, it uses three types of chemical entity recognisers, namely regular expressions, patterns an</context>
</contexts>
<marker>Sasaki, Tsuruoka, McNaught, Ananiadou, 2008</marker>
<rawString>Yutaka Sasaki, Yoshimasa Tsuruoka, John McNaught, and Sophia Ananiadou. 2008. How to make the most of NE dictionaries in statistical NER. BMC Bioinformatics, 9(Suppl 11):S5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lorraine Tanabe</author>
<author>Natalie Xie</author>
<author>Lynne Thom</author>
<author>Wayne Matten</author>
<author>W John Wilbur</author>
</authors>
<title>GENETAG: a tagged corpus for gene/protein named entity recognition. BMCBioinformatics, 6(Suppl 1):S3.</title>
<date>2005</date>
<contexts>
<context position="1766" citStr="Tanabe et al., 2005" startWordPosition="247" endWordPosition="250">ation extraction efforts in the past decade have focussed on fundamental tasks needed to create intelligent systems capable of improving search engine results and easing the work of biologists. More specifically, researchers have concentrated mainly on named entity recognition, mapping them to concepts in curated databases (Krallinger et al., 2008) and extracting simple binary relations between entities. Recently, an increasing number of resources that facilitate the training of systems to extract more detailed information have become available, e.g., PennBioIE (Kulick et al., 2004), GENETAG (Tanabe et al., 2005), BioInfer (Pyysalo et al., 2007), GENIA (Kim et al., 2008), GREC (Thompson et al., 2009) and Metaknowledge GENIA (Thompson et al., 2011). Moreover, several other annotated corpora have been developed for shared task purposes, such as BioCreative I, II, III (Arighi et al., 2011) and BioNLP Shared Tasks 2009 and 2011 (Cohen et al., 2009; Kim et al., 2011). Many of the tools currently used for biomedical language processing were trained and evaluated on such popular corpora, most of which consist of documents from the molecular biology subdomain. However, previous studies (discussed in Section 2</context>
</contexts>
<marker>Tanabe, Xie, Thom, Matten, Wilbur, 2005</marker>
<rawString>Lorraine Tanabe, Natalie Xie, Lynne Thom, Wayne Matten, and W John Wilbur. 2005. GENETAG: a tagged corpus for gene/protein named entity recognition. BMCBioinformatics, 6(Suppl 1):S3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Thompson</author>
<author>Syed Iqbal</author>
<author>John McNaught</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Construction of an annotated corpus to support biomedical information extraction.</title>
<date>2009</date>
<journal>BMCBioinformatics,</journal>
<volume>10</volume>
<issue>1</issue>
<contexts>
<context position="1855" citStr="Thompson et al., 2009" startWordPosition="262" endWordPosition="265">o create intelligent systems capable of improving search engine results and easing the work of biologists. More specifically, researchers have concentrated mainly on named entity recognition, mapping them to concepts in curated databases (Krallinger et al., 2008) and extracting simple binary relations between entities. Recently, an increasing number of resources that facilitate the training of systems to extract more detailed information have become available, e.g., PennBioIE (Kulick et al., 2004), GENETAG (Tanabe et al., 2005), BioInfer (Pyysalo et al., 2007), GENIA (Kim et al., 2008), GREC (Thompson et al., 2009) and Metaknowledge GENIA (Thompson et al., 2011). Moreover, several other annotated corpora have been developed for shared task purposes, such as BioCreative I, II, III (Arighi et al., 2011) and BioNLP Shared Tasks 2009 and 2011 (Cohen et al., 2009; Kim et al., 2011). Many of the tools currently used for biomedical language processing were trained and evaluated on such popular corpora, most of which consist of documents from the molecular biology subdomain. However, previous studies (discussed in Section 2) have established that different biomedical sublanguages exhibit linguistic variations. </context>
</contexts>
<marker>Thompson, Iqbal, McNaught, Ananiadou, 2009</marker>
<rawString>Paul Thompson, Syed Iqbal, John McNaught, and Sophia Ananiadou. 2009. Construction of an annotated corpus to support biomedical information extraction. BMCBioinformatics, 10(1):349.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Thompson</author>
<author>Raheel Nawaz</author>
<author>John McNaught</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Enriching a biomedical event corpus with meta-knowledge annotation.</title>
<date>2011</date>
<journal>BMCBioinformatics,</journal>
<volume>12</volume>
<issue>1</issue>
<contexts>
<context position="1903" citStr="Thompson et al., 2011" startWordPosition="270" endWordPosition="273">g search engine results and easing the work of biologists. More specifically, researchers have concentrated mainly on named entity recognition, mapping them to concepts in curated databases (Krallinger et al., 2008) and extracting simple binary relations between entities. Recently, an increasing number of resources that facilitate the training of systems to extract more detailed information have become available, e.g., PennBioIE (Kulick et al., 2004), GENETAG (Tanabe et al., 2005), BioInfer (Pyysalo et al., 2007), GENIA (Kim et al., 2008), GREC (Thompson et al., 2009) and Metaknowledge GENIA (Thompson et al., 2011). Moreover, several other annotated corpora have been developed for shared task purposes, such as BioCreative I, II, III (Arighi et al., 2011) and BioNLP Shared Tasks 2009 and 2011 (Cohen et al., 2009; Kim et al., 2011). Many of the tools currently used for biomedical language processing were trained and evaluated on such popular corpora, most of which consist of documents from the molecular biology subdomain. However, previous studies (discussed in Section 2) have established that different biomedical sublanguages exhibit linguistic variations. It follows that tools which were developed and e</context>
</contexts>
<marker>Thompson, Nawaz, McNaught, Ananiadou, 2011</marker>
<rawString>Paul Thompson, Raheel Nawaz, John McNaught, and Sophia Ananiadou. 2011. Enriching a biomedical event corpus with meta-knowledge annotation. BMCBioinformatics, 12(1):393.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Verspoor</author>
<author>Kevin Bretonnel Cohen</author>
<author>Lawrence Hunter</author>
</authors>
<title>The textual characteristics of traditional and open access scientific journals are similar.</title>
<date>2009</date>
<journal>BMC Bioinformatics,</journal>
<volume>10</volume>
<issue>1</issue>
<contexts>
<context position="5890" citStr="Verspoor et al. (2009)" startWordPosition="885" endWordPosition="888"> and alternation of biomedical verbs. They concluded that there is a high occurrence of these phenomena in this semantically restricted domain, and underline that this sublanguage model applies only to biomedical language. Taking a different angle, Nguyen and Kim (2008) examined the differences in the use of pronouns by studying general domains (MUC and ACE) and one biomedical domain (GENIA). They observed that compared to the MUC and ACE corpora, the GENIA corpus has significantly more occurrences of neutral and third-person pronouns, whilst first and second person pronouns are non-existent. Verspoor et al. (2009) measured lexical and structural variation in biomedical Open Access journals and subscription-based journals, concluding that there are no significant differences between them. Therefore, a model trained on one of these sources can be used successfully on the other, as long as the subject matter is maintained. Furthermore, they compared a mouse genomics corpus with two reference corpora, one composed of newswire texts and another of general biomedical articles. In this case, unsurprisingly, significant differences were found across many linguistic dimensions. Relevant to our study is the comp</context>
</contexts>
<marker>Verspoor, Cohen, Hunter, 2009</marker>
<rawString>Karin Verspoor, Kevin Bretonnel Cohen, and Lawrence Hunter. 2009. The textual characteristics of traditional and open access scientific journals are similar. BMC Bioinformatics, 10(1):183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tuangthong Wattarujeekrit</author>
<author>Parantu Shah</author>
<author>Nigel Collier</author>
</authors>
<title>PASBio: predicate-argument structures for event extraction in molecular biology.</title>
<date>2004</date>
<journal>BMC Bioinformatics,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="4829" citStr="Wattarujeekrit et al. (2004)" startWordPosition="720" endWordPosition="723">sible to process specialised languages, since they have a structure that can be expressed in a computable form. More recently, several works on the study of biomedical languages substantiated his theory. For instance, Sager et al. (1987) worked on pharmacological literature and lipid metabolism, whereas Friedman et al. (2002) analysed the properties of clinical and biomolecular sublanguages. Other studies have investigated the differences between general and biomedical languages by focussing on specific linguistic aspects, such as verb-argument relations and pronominal anaphora. For instance, Wattarujeekrit et al. (2004) analysed the predicate-argument structures of 30 verbs used in biomedical articles. Their results suggest that, in certain cases, a significant difference exists in the predicate frames compared to those obtained from analysing news articles in the PropBank project (Palmer et al., 2005). Similarly, based on the GENIA and PennBioIE corpora, Cohen et al. (2008) performed a study of argument realisation with respect to the nominalisation and alternation of biomedical verbs. They concluded that there is a high occurrence of these phenomena in this semantically restricted domain, and underline tha</context>
</contexts>
<marker>Wattarujeekrit, Shah, Collier, 2004</marker>
<rawString>Tuangthong Wattarujeekrit, Parantu Shah, and Nigel Collier. 2004. PASBio: predicate-argument structures for event extraction in molecular biology. BMC Bioinformatics, 5(1):155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Witten</author>
<author>Eibe Frank</author>
</authors>
<date>2005</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques (Second Edition).</booktitle>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="14081" citStr="Witten and Frank, 2005" startWordPosition="2220" endWordPosition="2223">ransformed into a vector consisting of 20 features. Each of these features corresponds to an entity type in Table 2, having a numeric value ranging from 0 to 1. This number represents the ratio of the specific entity type to the total number of named entities recognised in that document, as shown in Equation 2. 0 = nN e (2) where ntype represents the number of NEs of a certain type in a document and N represents the total number of NEs in that document. Furthermore, each vector was labelled with the subdomain to which the respective document belongs (i.e., cell biology or pharmacology). Weka (Witten and Frank, 2005; Hall et al., 2009) was employed as the machine learning framework, due to its large variety of classification algorithms. We experimented with a large number of classifiers, ranging from Bayesian nets to functions, decision trees, decision rules and meta-classifiers. The best performing classifiers are shown in Table 4. BayesNet is an implementation of Bayesian Networks, SMO is an implementation of Support Vector Machines, J48 is an implementation of decision trees, whilst Jrip is an implementation of decision rules. Random Forest is an ensemble classifier that consists of many decision tree</context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>Ian Witten and Eibe Frank. 2005. Data Mining: Practical Machine Learning Tools and Techniques (Second Edition). Morgan Kaufmann.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>