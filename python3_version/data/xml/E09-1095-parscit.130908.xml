<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002190">
<title confidence="0.992319">
Growing Finely-Discriminating Taxonomies from Seeds
of Varying Quality and Size
</title>
<author confidence="0.999046">
Tony Veale
</author>
<affiliation confidence="0.809990333333333">
School of Computer Science
University College Dublin
Ireland
</affiliation>
<email confidence="0.997352">
tony.veale@ucd.ie
</email>
<author confidence="0.996948">
Guofu Li
</author>
<affiliation confidence="0.809966">
School of Computer Science
University College Dublin
Ireland
</affiliation>
<email confidence="0.997267">
guofu.li@ucd.ie
</email>
<author confidence="0.998091">
Yanfen Hao
</author>
<affiliation confidence="0.809879">
School of Computer Science
University College Dublin
Ireland
</affiliation>
<email confidence="0.997322">
yanfen.hao@ucd.ie
</email>
<sectionHeader confidence="0.993848" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9976435">
Concept taxonomies offer a powerful means
for organizing knowledge, but this organiza-
tion must allow for many overlapping and
fine-grained perspectives if a general-purpose
taxonomy is to reflect concepts as they are
actually employed and reasoned about in ev-
eryday usage. We present here a means of
bootstrapping finely-discriminating tax-
onomies from a variety of different starting
points, or seeds, that are acquired from three
different sources: WordNet, ConceptNet and
the web at large.
</bodyText>
<sectionHeader confidence="0.998788" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999975196969698">
Taxonomies provide a natural and intuitive
means of organizing information, from the bio-
logical taxonomies of the Linnaean system to the
layout of supermarkets and bookstores to the or-
ganizational structure of companies. Taxonomies
also provide the structural backbone for ontolo-
gies in computer science, from common-sense
ontologies like Cyc (Lenat and Guha, 1990) and
SUMO (Niles and Pease, 2001) to lexical ontolo-
gies like WordNet (Miller et al., 1990). Each of
these uses is based on the same root-branch-leaf
metaphor: the broadest terms with the widest
scope occupy the highest positions of a taxono-
my, near the root, while specific terms with the
most local concerns are located lower in the hier-
archy, nearest the leaves. The more interior
nodes that a taxonomy possesses, the finer the
conceptual distinctions and the more gradated the
similarity judgments it can make (e.g., Budanit-
sky and Hirst, 2006).
General-purpose computational taxonomies
are called upon to perform both coarse-grained
and fine-grained judgments. In NLP, for in-
stance, the semantics of “eat” requires just
enough knowledge to discriminate foods like
tofu and cheese from non-foods like wool and
steel, while specific applications in the domain of
cooking and recipes (e.g., Hammond’s (1986)
CHEF) require enough discrimination to know
that tofu can be replaced with clotted cheese in
many recipes because each is a soft, white and
bland food.
So while much depends on the domain of us-
age, it remains an open question as to how many
nodes a good taxonomy should possess. Prince-
ton WordNet, for instance, strives for as many
nodes as there are word senses in English, yet it
also contains a substantial number of composite
nodes that are lexicalized not as single words,
but as complex phrases. Print dictionaries intend-
ed for human consumption aim for some econo-
my of structure, and typically do not include the
meaning of phrases that can be understood as
straightforward compositions of the meaning of
their parts (Hanks, 2004). But WordNet also
serves another purpose, as a lexical knowledge-
base for computers, not humans, a context in
which concerns about space seem quaint. When
space is not a issue, there seems no good reason
to exclude nodes from a concept taxonomy mere-
ly for being composites of other ideas; the real
test of entry is whether a given node adds value
to a taxonomy, by increasing its level of internal
organization through the systematic dissection of
overly broad categories into finer, more intuitive
and manageable clusters.
In this paper we describe a means by which
finely-discriminating taxonomies can be grown
from a variety of different knowledge seeds.
These taxonomies comprise composite categories
that can be lexicalized as phrases of the form
“ADJ NOUN”, such as Sharp-Instrument, which
represents the set of all instruments that are typi-
cally considered sharp, such as knives, scissors,
chisels and can-openers. While WordNet already
contains an equivalent category, named Edge-
</bodyText>
<note confidence="0.9229485">
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 835–842,
Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.99819">
835
</page>
<bodyText confidence="0.99995928">
Tool, which it defines with the gloss “any cutting
tool with a sharp cutting edge”, it provides no
structural basis for inferring that any member of
this category can be considered sharp. For the
most part, if two ideas (word senses) belong to
the same semantic category X in WordNet, the
most we can infer is that both possess the trivial
property X-ness. Our goal here is to construct
taxonomies whose form makes explicit the actual
properties that accrue from membership in a cat-
egory.
Past work on related approaches to taxonomy
creation are discussed in section 2, while section
3 describes the different knowledge seeds that
serve as the starting point for our bootstrapping
process. In section 4 we describe the bootstrap-
ping process in more detail; such processes are
prone to noise, so we also discuss how the ac-
quired categorizations are validated and filtered
after each bootstrapping cycle. An evaluation of
the key ideas is then presented in section 5, to
determine which seed yields the highest quality
taxonomy once bootstrapping is completed. The
paper then concludes with some final remarks in
section 6.
</bodyText>
<sectionHeader confidence="0.999692" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999951444444445">
Simple pattern-matching techniques can be sur-
prisingly effective for the extraction of lexico-se-
mantic relations from text when those relations
are expressed using relatively stable and unam-
biguous syntagmatic patterns (Ahlswede and
Evens, 1988). For instance, the work of Hearst
(1992) typifies this surgical approach to relation
extraction, in which a system fishes in a large
text for particular word sequences that strongly
suggest a semantic relationship such as hyper-
nymy or, in the case of Charniak and Berland
(1999), the part-whole relation. Such efforts offer
high precision but can exhibit low recall on mod-
erate-sized corpora, and extract just a tiny (but
very useful) subset of the semantic content of a
text. The KnowItAll system of Etzioni et al.
(2004) employs the same generic patterns as
Hearst (e.g., “NPs such as NP1, NP2, ...”), and
more besides, to extract a whole range of facts
that can be exploited for web-based question-an-
swering. Cimiano and Wenderoth (2007) also
use a range of Hearst-like patterns to find text se-
quences in web-text that are indicative of the lex-
ico-semantic properties of words; in particular,
these authors use phrases like “to * a new
NOUN” and “the purpose of NOUN is to *” to
identify the formal (isa), agentive (made by) and
telic (used for) roles of nouns.
Snow, Jurafsky and Ng (2004) use supervised
learning techniques to acquire those syntagmatic
patterns that prove most useful for extracting hy-
pernym relations from text. They train their sys-
tem using pairs of WordNet terms that exemplify
the hypernym relation; these are used to identify
specific sentences in corpora that are most likely
to express the relation in lexical terms. A binary
classifier is then trained on lexico-syntactic fea-
tures that are extracted from a dependency-struc-
ture parse of these sentences. Kashyap et al.,
(2005) experiment with a bootstrapping approach
to growing concept taxonomies in the medical
domain. A gold standard taxonomy provides
terms that are used to retrieve documents which
are then hierarchically clustered; cohesiveness
measures are used to yield a taxonomy of terms
that can then further drive the retrieval and clus-
tering cycle. Kozareva et al. (2008) use a boot-
strapping approach that extends the fixed-pattern
approach of Hearst (1992) in two intriguing
ways. First, they use a doubly-anchored retrieval
pattern of the form “NOUNcat such as NOUNexam-
ple and *” to ground the retrieval relative to a
known example of hypernymy, so that any val-
ues extracted for the wildcard * are likely to be
coordinate terms of NOUNexample and even more
likely to be good examples of NOUNcat. Second-
ly, they construct a graph of terms that co-occur
within this pattern to determine which terms are
supported by others, and by how much. These
authors also use two kinds of bootstrapping: the
first variation, dubbed reckless, uses the candi-
dates extracted from the double-anchored pattern
(via *) as exemplars (NOUNexample) for successive
retrieval cycles; the second variation first checks
whether a candidate is sufficiently supported to
be used as an exemplar in future retrieval cycles.
The approach we describe here is most similar
to that of Kozareva et al. (2008). We too use a
double-anchored pattern, but place the anchors in
different places to obtain the query patterns
“ADJcat NOUNcat such as *” and “ADJcat * such
as NOUNexample”. As a result, we obtain a finely-
discriminating taxonomy based on categories
that are explicitly annotated with the properties
(ADJcat) that they bequeath to their members.
These categories have an obvious descriptive and
organizational utility, but of a kind that one is
unlikely to find in conventional resources like
WordNet and Wikipedia. Kozareva et al. (2008)
test their approach on relatively simple and ob-
jective categories like states, countries (both
</bodyText>
<page confidence="0.997536">
836
</page>
<bodyText confidence="0.9999108">
closed sets), singers and fish (both open, the for-
mer more so than the latter), but not on complex
categories in which members are tied both to a
general category, like food, and to a stereotypical
property, like sweet (Veale and Hao, 2007). By
validating membership in these complex cate-
gories using WordNet-based heuristics, we can
hang these categories and members on specific
WordNet senses, and thus enrich WordNet with
this additional taxonomic structure.
</bodyText>
<sectionHeader confidence="0.996775" genericHeader="method">
3 Seeds for Taxonomic Growth
</sectionHeader>
<bodyText confidence="0.9999949">
A fine-grained taxonomy can be viewed as a set
of triples Tijk = &lt;Ci, Dj, Pk&gt;, where Ci denotes a
child of the parent term Pk that possesses the dis-
criminating property Dj; in effect, each such
triple expresses that Ci is a specialization of the
complex taxonym Dj-Pk. Thus, the belief that
cola is a carbonated-drink is expressed by the
triple &lt;cola, carbonated, drink&gt;. From this triple
we can identify other categorizations of cola
(such as treat and refreshment) via the web query
“carbonated * such as cola”, or we can identify
other similarly fizzy drinks via the query “car-
bonated drinks such as *”. So this web-based
bootstrapping of fine-grained category hierar-
chies requires that we already possess a collec-
tion of fine-grained distinctions of a relatively
high-quality. We now consider three different
starting points for this bootstrapping process, as
extracted from three different resources: Word-
Net, ConceptNet and the web at large.
</bodyText>
<subsectionHeader confidence="0.994507">
3.1 WordNet
</subsectionHeader>
<bodyText confidence="0.999972833333333">
The noun-sense taxonomy of WordNet makes a
number of fine-grained distinctions that prove
useful in clustering entities into smaller and more
natural groupings. For instance, WordNet differ-
entiates {feline, felid) into the sub-categories
{true_cat, cat) and {big_cat, cat), the former
serving to group domesticated cats with other
cats of a similar size, the latter serving to cluster
cats that are larger, wilder and more exotic.
However, such fine-grained distinctions are the
exception rather than the norm in WordNet, and
not one of the 60+ words of the form Xess in
WordNet that denote a person (such as huntress,
waitress, Jewess, etc.) express the defining prop-
erty female in explicit taxonomic terms.
Nonetheless, the free-text glosses associated with
WordNet sense-entries often do state the kind of
distinctions we would wish to find expressed as
explicit taxonyms. A shallow parse of these
glosses thus yields a sizable number of fine-
grained distinctions, such as &lt;lioness, female,
lion&gt;, &lt;espresso, strong, coffee&gt; and both
&lt;messiah, awaited, king&gt; and &lt;messiah, expect-
ed, deliverer&gt;.
</bodyText>
<subsectionHeader confidence="0.997858">
3.2 ConceptNet
</subsectionHeader>
<bodyText confidence="0.999978">
Despite its taxonomic organization, WordNet
owes much to the centralized and authority-pre-
serving craft of traditional lexicography. Con-
ceptNet (Liu and Singh, 2004), in contrast, is a
far less authoritative knowledge-source, one that
owes more to the workings of the WWW than to
conventional print dictionaries. Comprising fac-
toids culled from the template-structured contri-
butions of thousands of web users, ConceptNet
expresses many relationships that accurately re-
flect a public, common-sense view on a given
topic (from vampires to dentists) and many more
that are simply bizarre or ill-formed. Looking to
the relation that interests us here, the IsA rela-
tion, ConceptNet tells us that an espresso is a
strong coffee (correctly, like WordNet) but that a
bagel is a Jewish word (confusing use with men-
tion). Likewise, we find that expressionism is an
artistic style (correct, though WordNet deems it
an artistic movement) but that an explosion is a
suicide attack (confusing formal and telic roles).
Since we cannot trust the content of ConceptNet
directly, lest we bootstrap from a highly unreli-
able starting point, we use WordNet as a simple
filter. While the concise form of ConceptNet
contains over 30,000 IsA propositions, we con-
sider as our seed collection only those that define
a noun concept (such as “espresso”) in terms of a
binary compound (e.g., “strong coffee”) where
the head of the latter (e.g., “coffee”) denotes a
WordNet hypernym of some sense of the former.
This yields triples such as &lt;Wyoming, great,
state&gt;, &lt;wreck, serious, accident&gt; and &lt;wolf,
wild, animal&gt;.
</bodyText>
<subsectionHeader confidence="0.997114">
3.3 Web-derived Stereotypes
</subsectionHeader>
<bodyText confidence="0.999994076923077">
Veale and Hao (2007) also use the observations
of web-users to acquire common perceptions of
oft-mentioned ideas, but do so by harvesting sim-
ile expressions of the form “as ADJ as a NOUN”
directly from the web. Their approach hinges on
the fact that similes exploit stereotypes to draw
out the salient properties of a target, thereby al-
lowing rich descriptions of those stereotypes to
be easily acquired, e.g., that snowflakes are pure
and unique, acrobats are agile and nimble, knifes
are sharp and dangerous, viruses are malicious
and infectious, and so on. However, because they
find that almost 15% of their web-harvested sim-
</bodyText>
<page confidence="0.984796">
837
</page>
<bodyText confidence="0.9999805625">
iles are ironic (e.g., “as subtle as a rock”, “as bul-
letproof as a sponge-cake”, etc.), they filter irony
from these associations by hand, to yield a siz-
able database of stereotypical attributions that
describes over 6000 noun concepts in terms of
over 2000 adjectival properties. However, be-
cause Veale and Hao’s data directly maps stereo-
typical properties to simile vehicles, it does not
provide a parent category for these vehicles.
Thus, the seed triples derived from this data are
only partially instantiated; for instance, we ob-
tain &lt;surgeon, skilful, ?&gt;, &lt;virus, malicious, ?&gt;
and &lt;dog, loyal, ?&gt;. This does not prove to be a
serious impediment, however, as the missing
field of each triple is quickly identified during
the first cycle of bootstrapping.
</bodyText>
<subsectionHeader confidence="0.992908">
3.4 Overview of Seed Resources
</subsectionHeader>
<bodyText confidence="0.9947409375">
Neither of these three seeds is an entirely useful
knowledge-base in its own right. The WordNet-
based seed is clearly a representation of conve-
nience, since it contains only those properties
that can be acquired from the glosses that happen
to be amenable to a simple shallow-parse. The
ConceptNet seed is likewise a small collection of
low-hanging fruit, made smaller still by the use
of WordNet as a coarse but very necessary noise-
filter. And while the simile-derived distinctions
obtained from Veale and Hao paint a richly de-
tailed picture of the most frequent objects of
comparison, this seed offers no coverage for the
majority of concepts that are insufficiently note-
worthy to be found in web similes. A quantita-
tive comparison of all three seeds is provided in
</bodyText>
<tableCaption confidence="0.547064">
Table 1 below.
</tableCaption>
<table confidence="0.999542333333333">
WordNet ConceptNet Simile
# terms 12,227 1,133 6512
in total
# triples 51,314 1808 16,688
in total
# triples 4.12 1.6 2.56
per term
# fea- 2305 550 1172
tures
</table>
<tableCaption confidence="0.9923535">
Table 1: The size of seed collections yielded from
different sources.
</tableCaption>
<bodyText confidence="0.999888933333333">
We can see that WordNet-derived seed is clearly
the largest and apparently the most comprehen-
sive knowledge-source of the three: it contains
the most terms (concepts), the most features (dis-
criminating properties of those concepts), and the
most triples (which situate those concepts in par-
ent categories that are further specialized by
these discriminating features). But size is only
weakly suggestive of quality, and as we shall see
in the next section, even such dramatic differ-
ences in scale can disappear after several cycles
of bootstrapping. In section 5 we will then con-
sider which of these seeds yields the highest
quality taxonomies after bootstrapping has been
applied.
</bodyText>
<sectionHeader confidence="0.950501" genericHeader="method">
4 Bootstrapping from Seeds
</sectionHeader>
<bodyText confidence="0.9987273">
The seeds of the previous section each represent
a different starting collection of triples. It is the
goal of the bootstrapping process to grow these
collections of triples, to capture more of the
terms – and more of the distinctions – that a tax-
onomy is expected to know about. The expansion
set of a triple Tijk = &lt;Ci, Dj, Pk&gt; is the set of
triples that can be acquired from the web using
the following query expansions (* is a search
wildcard):
</bodyText>
<listItem confidence="0.998297">
1. “Dj * such as Ci”
2. “Dj Pk such as *”
</listItem>
<bodyText confidence="0.999903166666667">
In the first query, a noun is sought to yield anoth-
er categorization of Ci, while in the second, other
members of the fine-grained category Dj-Pk are
sought to accompany Ci. In parsing the text snip-
pets returned by these queries, we also exploit
text sequences that match the following patterns:
</bodyText>
<listItem confidence="0.9989385">
3. “* and Dj Pk such as *”
4. “* and Dj * such as Ci”
</listItem>
<bodyText confidence="0.99996695">
These last two patterns allow us to learn new dis-
criminating features by noting how these dis-
criminators are combined to reinforce each other
in some ad-hoc category formulations. For in-
stance, the phrase “cold and refreshing beverages
such as lemonade” allows us to acquire the
triples &lt;lemonade, cold, beverage&gt; and &lt;lemon-
ade, refreshing, beverage&gt;. This pattern is neces-
sary if the bootstrapping process is to expand be-
yond the limited vocabulary of discriminating
features (Dj) found in the original seed collec-
tions of triples.
We denote the mapping from a triple T to the
set of additional triples that can be acquired from
the web using the above queries/patterns as ex-
pand(T&apos;). We currently implement this function
using the Google search API. Our experiences
with each query suggest that 200 snippets is a
good search range for the first query, while 50 is
usually more than adequate for the second.
</bodyText>
<page confidence="0.991797">
838
</page>
<bodyText confidence="0.991229666666667">
We can now denote the knowledge that is ac-
quired when starting from a given seed collection
S after t cycles of bootstrapping as KtS. Thus,
</bodyText>
<equation confidence="0.994842166666667">
K0S=S
K 1 S=K 0 S ∪
{T ∣ T &apos;∈S ∧ T ∈expand T &apos;}
S S
Kt1=Kt ∪
{T ∣ T &apos;∈KtS ∧ T ∈expand T &apos; }
</equation>
<bodyText confidence="0.999759230769231">
Web queries, and the small snippets of text that
they return, offer just a keyhole view of language
as it is used in real documents. Unsurprisingly,
the new triples acquired from the web via ex-
pand(T&apos;) are likely to be very noisy indeed. Fol-
lowing Kozareva et al. (2008), we can either in-
dulge in reckless bootstrapping, which ignores
the question of noise until all bootstrapping is
finished, or we can apply a noise filter after each
incremental step. The latter approach has the ad-
ditional advantage of keeping the search-space as
small as possible, which is a major consideration
when bootstrapping from sizable seeds. We use a
simple WordNet-based filter called near-miss: a
new triple &lt;Ci, Dj, Pk&gt; is accepted if WordNet
contains a sense of Ci that is a descendant of
some sense of Pk (a hit), or a sense of Ci that is a
descendant of the direct hypernym of some sense
of Pk (a near-miss). This allows the bootstrapping
process to acquire structures that are not simply a
decorated version of the basic WordNet taxono-
my, but to acquire hierarchical relations whose
undifferentiated forms are not in WordNet (yet
are largely compatible with WordNet). This non-
reckless bootstrapping process can be expressed
as follows:
</bodyText>
<equation confidence="0.996155333333333">
K t�
S =Kt S ∪ {T ∣ T&apos;∈KtS ∧
T ∈ filternear−missexpand T &apos;}
</equation>
<bodyText confidence="0.984105214285714">
Figure 1 and figure 2 below illustrate the rate of
growth of triple-sets from each of our three
seeds.
Referring again to table 1, we note that while
the ConceptNet collection is by far the smallest
of the three seeds – more that 7 times smaller
than the simile-derived seed, and almost 40 times
smaller than the WordNet seed – this difference
is size shrinks considerably over the course of
five bootstrapping cycles. The WordNet near-
miss filter ensures that the large body of triples
grown from each seed are broadly sound, and
that we are not simply generating comparable
quantities of nonsense in each case.
</bodyText>
<figure confidence="0.996534416666667">
1800000
1600000
1400000
1200000
1000000
800000
600000
400000
200000
0
0 1 2 3 4 5
Bootstrapping Cycle
</figure>
<figureCaption confidence="0.999096">
Figure 1: Growth in the number of acquired triples,
over 5 cycles of bootstrapping from different seeds.
</figureCaption>
<figure confidence="0.910066">
Bootstrapping Cycle
</figure>
<figureCaption confidence="0.991651333333333">
Figure 2: Growth in the number of terms described by
the acquired triples, over 5 cycles of bootstrapping
from different seeds.
</figureCaption>
<subsectionHeader confidence="0.998513">
4.1 An Example
</subsectionHeader>
<bodyText confidence="0.99996585">
Consider cola, for which the simile seed has one
triple: &lt;cola, refreshing, beverage&gt;. After a sin-
gle cycle of bootstrapping, we find that cola can
now be described as an effervescent beverage, a
sweet beverage, a nonalcoholic beverage and
more. After a second cycle, we find it described
as a sugary food, a fizzy drink and a dark mixer.
After a third cycle, it is found to be a sensitive
beverage, an everyday beverage and a common
drink. After a fourth cycle, it is also found to be
an irritating food and an unhealthy drink. After
the fifth cycle, it is found to be a stimulating
drink, a toxic food and a corrosive substance. In
all, the single cola triple in the simile seed yields
14 triples after 1 cycle, 43 triples after 2 cycles,
72 after 3 cycles, 93 after 4 cycles, and 102 after
5 cycles. During these bootstrapping cycles, the
description refreshing beverage additionally be-
comes associated with the terms champagne,
lemonade and beer.
</bodyText>
<figure confidence="0.999666588235294">
0 1 2 3 4 5
# Terms
250000
200000
350000
300000
150000
100000
50000
0
WordNet
Simile
ConceptNet
# Triples
WordNet
Simile
ConceptNet
</figure>
<page confidence="0.995512">
839
</page>
<sectionHeader confidence="0.994714" genericHeader="method">
5 Empirical Evaluation
</sectionHeader>
<bodyText confidence="0.996331417910448">
The WordNet near-miss filter thus ensures that
the parent field (Pk) of every triple contains a val-
ue that is sensible for the given child concept
(Ci), but does not ensure that the discriminating
property (Dj) in each triple is equally sensible
and apropos. To see whether the bootstrapping
process is simply padding the seed taxonomy
with large quantities of noise, or whether the ac-
quired Dj values do indeed mark out the implicit
essence of the Ci terms they describe, we need an
evaluation framework that can quantify the onto-
logical usefulness of these Dj values. For this, we
use the experimental setup of Almuhareb and
Poesio (2005), who use information extraction
from the web to acquire attribute values for dif-
ferent terms/concepts, and who then compare the
taxonomy that can be induced by clustering these
values with the taxonomic backbone of Word-
Net.
Almuhareb and Poesio first created a balanced
set of 402 nouns from 21 different semantic
classes in WordNet. They then acquired attested
attribute values for these nouns (such as hot for
coffee, red for car, etc.) using the query &amp;quot;(a|an|
the) * Ci (is|was)&amp;quot; to find corresponding Dj val-
ues for each Ci. Unlike our work, these authors
did not seek to acquire hypernyms for each Ci
during this search, and did not try to link the ac-
quired attribute values to a particular branching
point (Pk) in the taxonomy (they did, however,
seek matching attributes for these values, such as
Temperature for hot, but that aspect is not rele-
vant here). They acquired 94,989 attribute values
in all for the 402 test nouns. These values were
then used as features of the corresponding nouns
in a clustering experiment, using the CLUTO
system of Karypis (2002). By using attribute val-
ues as a basis for partitioning the set of 402
nouns into 21 different categories, Almuhareb
and Poesio attempted to reconstruct the original
21 WordNet categories from which the nouns
were drawn. The more accurate the match to the
original WordNet clustering, the more these at-
tribute values can be seen (and used) as a repre-
sentation of conceptual structure. In their first at-
tempt, they achieved just a 56.7% clustering ac-
curacy against the original human-assigned cate-
gories of WordNet. But after using a noise-filter
to remove almost half of the web-harvested at-
tribute values, they achieve a higher cluster accu-
racy of 62.7%. More specifically, Poesio and Al-
muhareb achieve a cluster purity of 0.627 and a
cluster entropy of 0.338 using 51,345 features to
describe and cluster the 402 nouns.1
We replicate the above experiments using the
same 402 nouns, and assess the clustering accur-
acy (again using WordNet as a gold-standard)
after each bootstrapping cycle. Recall that we use
only the Dj fields of each triple as features for the
clustering process, so the comparison with the
WordNet gold-standard is still a fair one. Once
again, the goal is to determine how much like the
human-crafted WordNet taxonomy is the tax-
onomy that is clustered automatically from the
discriminating words Dj only. The clustering ac-
curacy for all three seeds are shown in Tables 2,
3 and 4.
</bodyText>
<table confidence="0.999189166666667">
Cycle E P # Features Coverage
1st .327 .629 907 66%
2nd .253 .712 1,482 77%
3rd .272 .717 2,114 82%
4th .312 .640 2,473 83%
5th .289 .684 2,752 83%
</table>
<tableCaption confidence="0.838882">
Table 2: Clustering accuracy using the WordNet seed
</tableCaption>
<table confidence="0.953655571428571">
collection (E denotes Entropy and P stands for Purity)
Cycle E P # Features Coverage
1st .115 .842 363 41%
2nd .255 .724 787 59%
3rd .286 .694 1,362 74%
4th .279 .694 1,853 79%
5th .299 .673 2,274 82%
</table>
<tableCaption confidence="0.994901">
Table 3: Clustering accuracy using the ConceptNet
seed collection
</tableCaption>
<table confidence="0.999900666666667">
Cycle E P # Features Coverage
1st .254 .716 837 59%
2nd .280 .712 1,338 73%
3rd .289 .693 1,944 79%
4th .313 .660 2,312 82%
5th .157 .843 2,614 82%
</table>
<tableCaption confidence="0.8313465">
Table 4: Clustering accuracy using the Simile seed
collection
</tableCaption>
<bodyText confidence="0.8539335">
The test-set of 402 nouns contains some low-fre-
quency words, such as casuarina, cinchona, do-
decahedron, and concavity, and Almuhareb and
1 We use cluster purity as a reflection of clustering accu-
racy. We express accuracy as a percentage; hence a pu-
rity of 0.627 is seen as an accuracy of 62.7%.
</bodyText>
<page confidence="0.989365">
840
</page>
<bodyText confidence="0.999805045454546">
Poesio note that one third of their data-set has a
low-frequency of between 5-100 occurrences in
the British National Corpus. Looking to the cov-
erage column of each table, we thus see that
there are words in the Poesio and Almuhareb
data set for which no triples can be acquired in 5
cycles of bootstrapping. Interestingly, though
each seed is quite different in origin and size (see
again Table 1), all reach similar levels of cover-
age (-82%) after 5 bootstrapping cycles. Test
nouns for which all three seeds fail to reach a de-
scription include yesteryear, nonce (very rare),
salient (more typically an adjective), jag, droop,
fluting, fete, throb, poundage, stinging, rouble,
rupee, riel, drachma, escudo, dinar, dirham,
lira, dispensation, hoard, airstream (not typical-
ly a solid compound), riverside and curling. Fig-
ures 3 and 4 summarize the key findings in the
above tables: while bootstrapping from all three
seeds converges to the same level of coverage,
the simile seed clearly produces the highest qual-
ity taxonomy.
</bodyText>
<figure confidence="0.999017090909091">
0.90
0.85
0.80
0.75
0.70
0.65
0.60
0.45
0.40
1 2 3 4 5
Bootstrapping Cycle
</figure>
<figureCaption confidence="0.9621745">
Figure 3: Growth in the coverage from different
seed sources.
</figureCaption>
<figure confidence="0.846313">
Bootstrapping Cycle
</figure>
<figureCaption confidence="0.933093666666667">
Figure 4: Divergence in the clustering Purity
achieved using different seed sources. The results of
Poesio and Almuhareb are shown as the straight line:
</figureCaption>
<bodyText confidence="0.993419888888889">
y = 0.627.
Both the WordNet and ConceptNet seeds
achieve comparable accuracies of 68% and 67%
respectively after 5 cycles of bootstrapping,
which compares well with the accuracy of 62.7%
achieved by Poesio and Almuhareb. However,
the simile seed clearly yields the best accuracy of
84.3%, which also exceeds the accuracy of
66.4% achieved by Poesio and Almuhareb when
using both values and attributes (such as Tem-
perature, Color, etc.) for clustering, or the accu-
racy of 70.9% they achieve when using attributes
alone. Furthermore, bootstrapping from the simi-
le seed yields higher cluster accuracy on the 402-
noun data-set than Veale and Hao (2008) them-
selves achieve with their simile data on the same
test-set (69.85%).
But most striking of all is the concision of the
representations that are acquired using bootstrap-
ping. The simile seed yields a high cluster accu-
racy using a pool of just 2,614 fine discrimina-
tors, while Poesio and Almuhareb use 51,345
features even after their feature-set has been fil-
tered for noise. Though starting from different
initial scales, each seed converges toward a fea-
ture-set that is roughly twenty times smaller than
that used by Poesio and Almuhareb.
</bodyText>
<sectionHeader confidence="0.999535" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999982785714286">
These experiments reveal that seed knowledge of
different authoritativeness, quality and size will
tend to converge toward roughly the same num-
ber of finely discriminating properties and to-
ward much the same coverage after 5 or so cy-
cles of bootstrapping. Nonetheless, quality wins
out, and the simile-derived seed knowledge
shows itself to be a clearly superior basis for rea-
soning about the structure and organization of
conceptual categories. Bootstrapping from the
simile seed yields a slightly smaller set of dis-
criminating features than bootstrapping from the
WordNet seed, one that is many times smaller
than the Poesio and Almuhareb feature set. What
matters is that they are the right features to dis-
criminate with.
There appears to be a number of reasons for
this significant difference in quality. For one,
Veale and Hao (2007) show that similes express
highly stereotypical beliefs that strongly influ-
ence the affective disposition of a term/concept;
negatively perceived concepts are commonly
used to exemplify negative properties in similes,
while positively perceived concepts are widely
used to exemplify positive properties. Veale and
Hao (2008) go on to argue that similes offer a
very concise snapshot of those widely-held be-
liefs that are the cornerstone of everyday reason-
</bodyText>
<figure confidence="0.999719052631579">
1 2 3 4 5
Purity
1.00
0.90
0.80
0.70
0.60
0.50
0.40
WordNet
Simile
ConceptNet
Poesio &amp; Alm.
Coverage
0.55
0.50
WordNet
Simile
ConceptNet
</figure>
<page confidence="0.992211">
841
</page>
<bodyText confidence="0.999972064516129">
ing, and which should thus be the corner-stone of
any general-purpose taxonomy. In addition, be-
liefs expressed via the “as Dj as Ci” form of simi-
les appear to lend themselves to re-expression
via the “Dj Pk such as Ci” form; in each case, a
concept Ci is held up as an exemplar of a salient
property Dj. Since the “such as” bootstrapping
pattern seeks out expressions of prototypicality
on the web, a simile-derived seed set is likely the
best starting point for this search.
All three seeds appear to suffer the same cov-
erage limitations, topping out at about 82% of
the words in the Poesio and Almuhareb data-set.
Indeed, after 5 bootstrapping cycles, all three
seeds give rise to taxonomies that overlap on 328
words from the 402-noun test-set, accounting for
81.59% of the test-set. In effect then, bootstrap-
ping stumbles over the same core of hard words
in each case, no matter the seed that is used. As
such, the problem of coverage lies not in the seed
collection, but in the queries used to perform the
bootstrapping. The same coverage limitations
will thus apply to other bootstrapping approaches
to knowledge acquisition, such as Kozareva et
al. (2008), which rely on much the same stock
patterns. So while bootstrapping may not be a
general solution for acquiring all aspects of a
general-purpose taxonomy, it is clearly useful in
acquiring large swathes of such a taxonomy if
given a sufficiently high-quality seed to start
from.
</bodyText>
<sectionHeader confidence="0.998198" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995331763888889">
Ahlswede, T. and Evans, M. (1988). Parsing vs. Text
Processing in the analysis of dictionary definitions.
In Proc. of the 26th Annual Meeting of the ACL, pp
217-224.
Almuhareb, A. and Poesio, M. (2005). Concept
Learning and Categorization from the Web. In
Proc. of the annual meeting of the Cognitive Sci-
ence Society, Italy, July.
Budanitsky, A. and Hirst, G. (2006). Evaluating
WordNet-based Measures of Lexical Semantic Re-
latedness. Computational Linguistics, 32(1):13-47.
Cimiano, P. and Wenderoth, J. (2007). Automatic Ac-
quisition of Ranked Qualia Structures from the
Web. In Proc. of the 45th Annual Meeting of the
ACL, pp 888-895.
Charniak, E. and Berland, M. (1999). Finding parts in
very large corpora. In Proc. of the 37th Annual
Meeting of the ACL, pp 57–64.
Etzioni, O., Kok, S., Soderland, S., Cafarella, M.,
Popescu, A-M., Weld, D., Downey, D., Shaked, T.
and Yates, A. (2004). Web-scale information ex-
traction in KnowItAll (preliminary results). In
Proc. of the 13th WWW Conference, pp 100–109.
Hammond, K. J. (1986). CHEF : A Model of Case--
based Planning. In Proc. of the 5th National Con-
ference on Artificial Intelligence, pp 267--271,
Philadelphia, Pennsylvania. American Association
for Artificial Intelligence.
Hanks, P. (2004). WordNet: What is to be done? In
Proc. of GWC’2004, the 2nd Global WordNet con-
ference, Masaryk University, Brno.
Hearst, M. (1992). Automatic acquisition of hy-
ponyms from large text corpora. In Proc. of the
14th Int. Conf. on Computational Linguistics, pp
539–545.
Kashyap, V. Ramakrishnan, C. and Sheth, T. A.
(2005). TaxaMiner: an experimentation framework
for automated taxonomy bootstrapping. Int. Jour-
nal of Web and Grid Services 1(2), pp 240-266.
Karypis, G. (2002). CLUTO: A clustering toolkit.
Technical Report 02-017, University of Minnesota.
http://www-users.cs.umn.edu/~karypis/cluto/.
Kozareva, Z., Riloff, E. and Hovy, E. (2008). Seman-
tic Class Learning from the Web with Hyponym
Pattern Linkage Graphs. In Proc. of the 46th Annu-
al Meeting of the ACL.
Lenat, D. B. and Guha, R. V. (1990). Building large
knowledge-based systems: representation and in-
ference in the Cyc project. NY: Addison-Wesley.
Liu, H. and Singh, P. (2004), ConceptNet: A Practical
Commonsense Reasoning Toolkit. BT Technology
Journal, 22(4):211-226.
Miller, G., Beckwith,R., Fellbaum, C., Gross, D. and
Miller, K.J. (1990). Introduction to WordNet: an
on-line lexical database. Int. Journal of Lexicogra-
phy, 3(4):235 – 244.
Niles, I. and Pease, A. (2001). Toward a standard up-
per ontology. In Proc. of the 2nd International Con-
ference on Formal Ontology in Information Sys-
tems (FOIS-2001).
Snow, R., Jurafsky, D. and Ng, A. Y. (2004). Learn-
ing syntactic patterns for automatic hypernym dis-
covery. Advances in Neural Information Process-
ing Systems 17.
Veale, T. and Hao, Y. (2007). Making Lexical On-
tologies Functional and Context-Sensitive. In Proc.
of the 45th Annual Meeting of the ACL, pp 57–64.
Veale, T. and Hao, Y. (2008). A Fluid Knowledge
Representation for Understanding and Generating
Creative Metaphors. In Proc. of Coling 2008, The
22nd International Conference on Computational
Linguistics, Manchester.
</reference>
<page confidence="0.998015">
842
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.126309">
<title confidence="0.993726">Growing Finely-Discriminating Taxonomies from Seeds of Varying Quality and Size</title>
<author confidence="0.999996">Tony Veale</author>
<affiliation confidence="0.9997035">School of Computer Science University College Dublin</affiliation>
<address confidence="0.523823">Ireland</address>
<email confidence="0.953661">tony.veale@ucd.ie</email>
<author confidence="0.993341">Guofu Li</author>
<affiliation confidence="0.9997175">School of Computer Science University College Dublin</affiliation>
<address confidence="0.525296">Ireland</address>
<email confidence="0.964243">guofu.li@ucd.ie</email>
<author confidence="0.999417">Yanfen Hao</author>
<affiliation confidence="0.851477333333333">School of Computer Science University College Dublin Ireland</affiliation>
<email confidence="0.983548">yanfen.hao@ucd.ie</email>
<abstract confidence="0.991104153846154">Concept taxonomies offer a powerful means for organizing knowledge, but this organization must allow for many overlapping and fine-grained perspectives if a general-purpose taxonomy is to reflect concepts as they are actually employed and reasoned about in everyday usage. We present here a means of bootstrapping finely-discriminating taxonomies from a variety of different starting points, or seeds, that are acquired from three different sources: WordNet, ConceptNet and the web at large.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Ahlswede</author>
<author>M Evans</author>
</authors>
<title>Parsing vs. Text Processing in the analysis of dictionary definitions.</title>
<date>1988</date>
<booktitle>In Proc. of the 26th Annual Meeting of the ACL,</booktitle>
<pages>217--224</pages>
<marker>Ahlswede, Evans, 1988</marker>
<rawString>Ahlswede, T. and Evans, M. (1988). Parsing vs. Text Processing in the analysis of dictionary definitions. In Proc. of the 26th Annual Meeting of the ACL, pp 217-224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Almuhareb</author>
<author>M Poesio</author>
</authors>
<title>Concept Learning and Categorization from the Web. In</title>
<date>2005</date>
<booktitle>Proc. of the annual meeting of the Cognitive Science Society,</booktitle>
<location>Italy,</location>
<contexts>
<context position="22363" citStr="Almuhareb and Poesio (2005)" startWordPosition="3681" endWordPosition="3684">ear-miss filter thus ensures that the parent field (Pk) of every triple contains a value that is sensible for the given child concept (Ci), but does not ensure that the discriminating property (Dj) in each triple is equally sensible and apropos. To see whether the bootstrapping process is simply padding the seed taxonomy with large quantities of noise, or whether the acquired Dj values do indeed mark out the implicit essence of the Ci terms they describe, we need an evaluation framework that can quantify the ontological usefulness of these Dj values. For this, we use the experimental setup of Almuhareb and Poesio (2005), who use information extraction from the web to acquire attribute values for different terms/concepts, and who then compare the taxonomy that can be induced by clustering these values with the taxonomic backbone of WordNet. Almuhareb and Poesio first created a balanced set of 402 nouns from 21 different semantic classes in WordNet. They then acquired attested attribute values for these nouns (such as hot for coffee, red for car, etc.) using the query &amp;quot;(a|an| the) * Ci (is|was)&amp;quot; to find corresponding Dj values for each Ci. Unlike our work, these authors did not seek to acquire hypernyms for ea</context>
</contexts>
<marker>Almuhareb, Poesio, 2005</marker>
<rawString>Almuhareb, A. and Poesio, M. (2005). Concept Learning and Categorization from the Web. In Proc. of the annual meeting of the Cognitive Science Society, Italy, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Budanitsky</author>
<author>G Hirst</author>
</authors>
<title>Evaluating WordNet-based Measures of Lexical Semantic Relatedness.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<pages>32--1</pages>
<contexts>
<context position="1774" citStr="Budanitsky and Hirst, 2006" startWordPosition="261" endWordPosition="265">n computer science, from common-sense ontologies like Cyc (Lenat and Guha, 1990) and SUMO (Niles and Pease, 2001) to lexical ontologies like WordNet (Miller et al., 1990). Each of these uses is based on the same root-branch-leaf metaphor: the broadest terms with the widest scope occupy the highest positions of a taxonomy, near the root, while specific terms with the most local concerns are located lower in the hierarchy, nearest the leaves. The more interior nodes that a taxonomy possesses, the finer the conceptual distinctions and the more gradated the similarity judgments it can make (e.g., Budanitsky and Hirst, 2006). General-purpose computational taxonomies are called upon to perform both coarse-grained and fine-grained judgments. In NLP, for instance, the semantics of “eat” requires just enough knowledge to discriminate foods like tofu and cheese from non-foods like wool and steel, while specific applications in the domain of cooking and recipes (e.g., Hammond’s (1986) CHEF) require enough discrimination to know that tofu can be replaced with clotted cheese in many recipes because each is a soft, white and bland food. So while much depends on the domain of usage, it remains an open question as to how ma</context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>Budanitsky, A. and Hirst, G. (2006). Evaluating WordNet-based Measures of Lexical Semantic Relatedness. Computational Linguistics, 32(1):13-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cimiano</author>
<author>J Wenderoth</author>
</authors>
<title>Automatic Acquisition of Ranked Qualia Structures from the Web.</title>
<date>2007</date>
<booktitle>In Proc. of the 45th Annual Meeting of the ACL,</booktitle>
<pages>888--895</pages>
<contexts>
<context position="6163" citStr="Cimiano and Wenderoth (2007)" startWordPosition="972" endWordPosition="975">em fishes in a large text for particular word sequences that strongly suggest a semantic relationship such as hypernymy or, in the case of Charniak and Berland (1999), the part-whole relation. Such efforts offer high precision but can exhibit low recall on moderate-sized corpora, and extract just a tiny (but very useful) subset of the semantic content of a text. The KnowItAll system of Etzioni et al. (2004) employs the same generic patterns as Hearst (e.g., “NPs such as NP1, NP2, ...”), and more besides, to extract a whole range of facts that can be exploited for web-based question-answering. Cimiano and Wenderoth (2007) also use a range of Hearst-like patterns to find text sequences in web-text that are indicative of the lexico-semantic properties of words; in particular, these authors use phrases like “to * a new NOUN” and “the purpose of NOUN is to *” to identify the formal (isa), agentive (made by) and telic (used for) roles of nouns. Snow, Jurafsky and Ng (2004) use supervised learning techniques to acquire those syntagmatic patterns that prove most useful for extracting hypernym relations from text. They train their system using pairs of WordNet terms that exemplify the hypernym relation; these are used</context>
</contexts>
<marker>Cimiano, Wenderoth, 2007</marker>
<rawString>Cimiano, P. and Wenderoth, J. (2007). Automatic Acquisition of Ranked Qualia Structures from the Web. In Proc. of the 45th Annual Meeting of the ACL, pp 888-895.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>M Berland</author>
</authors>
<title>Finding parts in very large corpora.</title>
<date>1999</date>
<booktitle>In Proc. of the 37th Annual Meeting of the ACL,</booktitle>
<pages>57--64</pages>
<contexts>
<context position="5701" citStr="Charniak and Berland (1999)" startWordPosition="895" endWordPosition="898">tstrapping is completed. The paper then concludes with some final remarks in section 6. 2 Related Work Simple pattern-matching techniques can be surprisingly effective for the extraction of lexico-semantic relations from text when those relations are expressed using relatively stable and unambiguous syntagmatic patterns (Ahlswede and Evens, 1988). For instance, the work of Hearst (1992) typifies this surgical approach to relation extraction, in which a system fishes in a large text for particular word sequences that strongly suggest a semantic relationship such as hypernymy or, in the case of Charniak and Berland (1999), the part-whole relation. Such efforts offer high precision but can exhibit low recall on moderate-sized corpora, and extract just a tiny (but very useful) subset of the semantic content of a text. The KnowItAll system of Etzioni et al. (2004) employs the same generic patterns as Hearst (e.g., “NPs such as NP1, NP2, ...”), and more besides, to extract a whole range of facts that can be exploited for web-based question-answering. Cimiano and Wenderoth (2007) also use a range of Hearst-like patterns to find text sequences in web-text that are indicative of the lexico-semantic properties of word</context>
</contexts>
<marker>Charniak, Berland, 1999</marker>
<rawString>Charniak, E. and Berland, M. (1999). Finding parts in very large corpora. In Proc. of the 37th Annual Meeting of the ACL, pp 57–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Etzioni</author>
<author>S Kok</author>
<author>S Soderland</author>
<author>M Cafarella</author>
<author>A-M Popescu</author>
<author>D Weld</author>
<author>D Downey</author>
<author>T Shaked</author>
<author>A Yates</author>
</authors>
<title>Web-scale information extraction in KnowItAll (preliminary results).</title>
<date>2004</date>
<booktitle>In Proc. of the 13th WWW Conference,</booktitle>
<pages>100--109</pages>
<contexts>
<context position="5945" citStr="Etzioni et al. (2004)" startWordPosition="936" endWordPosition="939"> expressed using relatively stable and unambiguous syntagmatic patterns (Ahlswede and Evens, 1988). For instance, the work of Hearst (1992) typifies this surgical approach to relation extraction, in which a system fishes in a large text for particular word sequences that strongly suggest a semantic relationship such as hypernymy or, in the case of Charniak and Berland (1999), the part-whole relation. Such efforts offer high precision but can exhibit low recall on moderate-sized corpora, and extract just a tiny (but very useful) subset of the semantic content of a text. The KnowItAll system of Etzioni et al. (2004) employs the same generic patterns as Hearst (e.g., “NPs such as NP1, NP2, ...”), and more besides, to extract a whole range of facts that can be exploited for web-based question-answering. Cimiano and Wenderoth (2007) also use a range of Hearst-like patterns to find text sequences in web-text that are indicative of the lexico-semantic properties of words; in particular, these authors use phrases like “to * a new NOUN” and “the purpose of NOUN is to *” to identify the formal (isa), agentive (made by) and telic (used for) roles of nouns. Snow, Jurafsky and Ng (2004) use supervised learning tech</context>
</contexts>
<marker>Etzioni, Kok, Soderland, Cafarella, Popescu, Weld, Downey, Shaked, Yates, 2004</marker>
<rawString>Etzioni, O., Kok, S., Soderland, S., Cafarella, M., Popescu, A-M., Weld, D., Downey, D., Shaked, T. and Yates, A. (2004). Web-scale information extraction in KnowItAll (preliminary results). In Proc. of the 13th WWW Conference, pp 100–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K J Hammond</author>
</authors>
<title>CHEF : A Model of Case--based Planning.</title>
<date>1986</date>
<journal>Artificial Intelligence.</journal>
<booktitle>In Proc. of the 5th National Conference on Artificial Intelligence,</booktitle>
<pages>267--271</pages>
<publisher>American Association for</publisher>
<location>Philadelphia, Pennsylvania.</location>
<marker>Hammond, 1986</marker>
<rawString>Hammond, K. J. (1986). CHEF : A Model of Case--based Planning. In Proc. of the 5th National Conference on Artificial Intelligence, pp 267--271, Philadelphia, Pennsylvania. American Association for Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Hanks</author>
</authors>
<title>WordNet: What is to be done?</title>
<date>2004</date>
<booktitle>In Proc. of GWC’2004, the 2nd Global WordNet conference,</booktitle>
<institution>Masaryk University,</institution>
<location>Brno.</location>
<contexts>
<context position="2873" citStr="Hanks, 2004" startWordPosition="443" endWordPosition="444">oft, white and bland food. So while much depends on the domain of usage, it remains an open question as to how many nodes a good taxonomy should possess. Princeton WordNet, for instance, strives for as many nodes as there are word senses in English, yet it also contains a substantial number of composite nodes that are lexicalized not as single words, but as complex phrases. Print dictionaries intended for human consumption aim for some economy of structure, and typically do not include the meaning of phrases that can be understood as straightforward compositions of the meaning of their parts (Hanks, 2004). But WordNet also serves another purpose, as a lexical knowledgebase for computers, not humans, a context in which concerns about space seem quaint. When space is not a issue, there seems no good reason to exclude nodes from a concept taxonomy merely for being composites of other ideas; the real test of entry is whether a given node adds value to a taxonomy, by increasing its level of internal organization through the systematic dissection of overly broad categories into finer, more intuitive and manageable clusters. In this paper we describe a means by which finely-discriminating taxonomies </context>
</contexts>
<marker>Hanks, 2004</marker>
<rawString>Hanks, P. (2004). WordNet: What is to be done? In Proc. of GWC’2004, the 2nd Global WordNet conference, Masaryk University, Brno.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proc. of the 14th Int. Conf. on Computational Linguistics,</booktitle>
<pages>539--545</pages>
<contexts>
<context position="5463" citStr="Hearst (1992)" startWordPosition="858" endWordPosition="859"> how the acquired categorizations are validated and filtered after each bootstrapping cycle. An evaluation of the key ideas is then presented in section 5, to determine which seed yields the highest quality taxonomy once bootstrapping is completed. The paper then concludes with some final remarks in section 6. 2 Related Work Simple pattern-matching techniques can be surprisingly effective for the extraction of lexico-semantic relations from text when those relations are expressed using relatively stable and unambiguous syntagmatic patterns (Ahlswede and Evens, 1988). For instance, the work of Hearst (1992) typifies this surgical approach to relation extraction, in which a system fishes in a large text for particular word sequences that strongly suggest a semantic relationship such as hypernymy or, in the case of Charniak and Berland (1999), the part-whole relation. Such efforts offer high precision but can exhibit low recall on moderate-sized corpora, and extract just a tiny (but very useful) subset of the semantic content of a text. The KnowItAll system of Etzioni et al. (2004) employs the same generic patterns as Hearst (e.g., “NPs such as NP1, NP2, ...”), and more besides, to extract a whole</context>
<context position="7473" citStr="Hearst (1992)" startWordPosition="1186" endWordPosition="1187">l terms. A binary classifier is then trained on lexico-syntactic features that are extracted from a dependency-structure parse of these sentences. Kashyap et al., (2005) experiment with a bootstrapping approach to growing concept taxonomies in the medical domain. A gold standard taxonomy provides terms that are used to retrieve documents which are then hierarchically clustered; cohesiveness measures are used to yield a taxonomy of terms that can then further drive the retrieval and clustering cycle. Kozareva et al. (2008) use a bootstrapping approach that extends the fixed-pattern approach of Hearst (1992) in two intriguing ways. First, they use a doubly-anchored retrieval pattern of the form “NOUNcat such as NOUNexample and *” to ground the retrieval relative to a known example of hypernymy, so that any values extracted for the wildcard * are likely to be coordinate terms of NOUNexample and even more likely to be good examples of NOUNcat. Secondly, they construct a graph of terms that co-occur within this pattern to determine which terms are supported by others, and by how much. These authors also use two kinds of bootstrapping: the first variation, dubbed reckless, uses the candidates extract</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Hearst, M. (1992). Automatic acquisition of hyponyms from large text corpora. In Proc. of the 14th Int. Conf. on Computational Linguistics, pp 539–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ramakrishnan Kashyap</author>
<author>C</author>
<author>T A Sheth</author>
</authors>
<title>TaxaMiner: an experimentation framework for automated taxonomy bootstrapping.</title>
<date>2005</date>
<journal>Int. Journal of Web and Grid Services</journal>
<volume>1</volume>
<issue>2</issue>
<pages>240--266</pages>
<contexts>
<context position="7029" citStr="Kashyap et al., (2005)" startWordPosition="1116" endWordPosition="1119">entify the formal (isa), agentive (made by) and telic (used for) roles of nouns. Snow, Jurafsky and Ng (2004) use supervised learning techniques to acquire those syntagmatic patterns that prove most useful for extracting hypernym relations from text. They train their system using pairs of WordNet terms that exemplify the hypernym relation; these are used to identify specific sentences in corpora that are most likely to express the relation in lexical terms. A binary classifier is then trained on lexico-syntactic features that are extracted from a dependency-structure parse of these sentences. Kashyap et al., (2005) experiment with a bootstrapping approach to growing concept taxonomies in the medical domain. A gold standard taxonomy provides terms that are used to retrieve documents which are then hierarchically clustered; cohesiveness measures are used to yield a taxonomy of terms that can then further drive the retrieval and clustering cycle. Kozareva et al. (2008) use a bootstrapping approach that extends the fixed-pattern approach of Hearst (1992) in two intriguing ways. First, they use a doubly-anchored retrieval pattern of the form “NOUNcat such as NOUNexample and *” to ground the retrieval relativ</context>
</contexts>
<marker>Kashyap, C, Sheth, 2005</marker>
<rawString>Kashyap, V. Ramakrishnan, C. and Sheth, T. A. (2005). TaxaMiner: an experimentation framework for automated taxonomy bootstrapping. Int. Journal of Web and Grid Services 1(2), pp 240-266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Karypis</author>
</authors>
<title>CLUTO: A clustering toolkit.</title>
<date>2002</date>
<tech>Technical Report 02-017,</tech>
<institution>University of Minnesota.</institution>
<note>http://www-users.cs.umn.edu/~karypis/cluto/.</note>
<contexts>
<context position="23431" citStr="Karypis (2002)" startWordPosition="3865" endWordPosition="3866">y &amp;quot;(a|an| the) * Ci (is|was)&amp;quot; to find corresponding Dj values for each Ci. Unlike our work, these authors did not seek to acquire hypernyms for each Ci during this search, and did not try to link the acquired attribute values to a particular branching point (Pk) in the taxonomy (they did, however, seek matching attributes for these values, such as Temperature for hot, but that aspect is not relevant here). They acquired 94,989 attribute values in all for the 402 test nouns. These values were then used as features of the corresponding nouns in a clustering experiment, using the CLUTO system of Karypis (2002). By using attribute values as a basis for partitioning the set of 402 nouns into 21 different categories, Almuhareb and Poesio attempted to reconstruct the original 21 WordNet categories from which the nouns were drawn. The more accurate the match to the original WordNet clustering, the more these attribute values can be seen (and used) as a representation of conceptual structure. In their first attempt, they achieved just a 56.7% clustering accuracy against the original human-assigned categories of WordNet. But after using a noise-filter to remove almost half of the web-harvested attribute v</context>
</contexts>
<marker>Karypis, 2002</marker>
<rawString>Karypis, G. (2002). CLUTO: A clustering toolkit. Technical Report 02-017, University of Minnesota. http://www-users.cs.umn.edu/~karypis/cluto/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Kozareva</author>
<author>E Riloff</author>
<author>E Hovy</author>
</authors>
<title>Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs.</title>
<date>2008</date>
<booktitle>In Proc. of the 46th Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="7387" citStr="Kozareva et al. (2008)" startWordPosition="1171" endWordPosition="1174">o identify specific sentences in corpora that are most likely to express the relation in lexical terms. A binary classifier is then trained on lexico-syntactic features that are extracted from a dependency-structure parse of these sentences. Kashyap et al., (2005) experiment with a bootstrapping approach to growing concept taxonomies in the medical domain. A gold standard taxonomy provides terms that are used to retrieve documents which are then hierarchically clustered; cohesiveness measures are used to yield a taxonomy of terms that can then further drive the retrieval and clustering cycle. Kozareva et al. (2008) use a bootstrapping approach that extends the fixed-pattern approach of Hearst (1992) in two intriguing ways. First, they use a doubly-anchored retrieval pattern of the form “NOUNcat such as NOUNexample and *” to ground the retrieval relative to a known example of hypernymy, so that any values extracted for the wildcard * are likely to be coordinate terms of NOUNexample and even more likely to be good examples of NOUNcat. Secondly, they construct a graph of terms that co-occur within this pattern to determine which terms are supported by others, and by how much. These authors also use two kin</context>
<context position="8927" citStr="Kozareva et al. (2008)" startWordPosition="1421" endWordPosition="1424">cles. The approach we describe here is most similar to that of Kozareva et al. (2008). We too use a double-anchored pattern, but place the anchors in different places to obtain the query patterns “ADJcat NOUNcat such as *” and “ADJcat * such as NOUNexample”. As a result, we obtain a finelydiscriminating taxonomy based on categories that are explicitly annotated with the properties (ADJcat) that they bequeath to their members. These categories have an obvious descriptive and organizational utility, but of a kind that one is unlikely to find in conventional resources like WordNet and Wikipedia. Kozareva et al. (2008) test their approach on relatively simple and objective categories like states, countries (both 836 closed sets), singers and fish (both open, the former more so than the latter), but not on complex categories in which members are tied both to a general category, like food, and to a stereotypical property, like sweet (Veale and Hao, 2007). By validating membership in these complex categories using WordNet-based heuristics, we can hang these categories and members on specific WordNet senses, and thus enrich WordNet with this additional taxonomic structure. 3 Seeds for Taxonomic Growth A fine-gr</context>
<context position="18612" citStr="Kozareva et al. (2008)" startWordPosition="3036" endWordPosition="3039">00 snippets is a good search range for the first query, while 50 is usually more than adequate for the second. 838 We can now denote the knowledge that is acquired when starting from a given seed collection S after t cycles of bootstrapping as KtS. Thus, K0S=S K 1 S=K 0 S ∪ {T ∣ T &apos;∈S ∧ T ∈expand T &apos;} S S Kt1=Kt ∪ {T ∣ T &apos;∈KtS ∧ T ∈expand T &apos; } Web queries, and the small snippets of text that they return, offer just a keyhole view of language as it is used in real documents. Unsurprisingly, the new triples acquired from the web via expand(T&apos;) are likely to be very noisy indeed. Following Kozareva et al. (2008), we can either indulge in reckless bootstrapping, which ignores the question of noise until all bootstrapping is finished, or we can apply a noise filter after each incremental step. The latter approach has the additional advantage of keeping the search-space as small as possible, which is a major consideration when bootstrapping from sizable seeds. We use a simple WordNet-based filter called near-miss: a new triple &lt;Ci, Dj, Pk&gt; is accepted if WordNet contains a sense of Ci that is a descendant of some sense of Pk (a hit), or a sense of Ci that is a descendant of the direct hypernym of some s</context>
</contexts>
<marker>Kozareva, Riloff, Hovy, 2008</marker>
<rawString>Kozareva, Z., Riloff, E. and Hovy, E. (2008). Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs. In Proc. of the 46th Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D B Lenat</author>
<author>R V Guha</author>
</authors>
<title>Building large knowledge-based systems: representation and inference in the Cyc project.</title>
<date>1990</date>
<publisher>NY: Addison-Wesley.</publisher>
<contexts>
<context position="1227" citStr="Lenat and Guha, 1990" startWordPosition="170" endWordPosition="173">ut in everyday usage. We present here a means of bootstrapping finely-discriminating taxonomies from a variety of different starting points, or seeds, that are acquired from three different sources: WordNet, ConceptNet and the web at large. 1 Introduction Taxonomies provide a natural and intuitive means of organizing information, from the biological taxonomies of the Linnaean system to the layout of supermarkets and bookstores to the organizational structure of companies. Taxonomies also provide the structural backbone for ontologies in computer science, from common-sense ontologies like Cyc (Lenat and Guha, 1990) and SUMO (Niles and Pease, 2001) to lexical ontologies like WordNet (Miller et al., 1990). Each of these uses is based on the same root-branch-leaf metaphor: the broadest terms with the widest scope occupy the highest positions of a taxonomy, near the root, while specific terms with the most local concerns are located lower in the hierarchy, nearest the leaves. The more interior nodes that a taxonomy possesses, the finer the conceptual distinctions and the more gradated the similarity judgments it can make (e.g., Budanitsky and Hirst, 2006). General-purpose computational taxonomies are called</context>
</contexts>
<marker>Lenat, Guha, 1990</marker>
<rawString>Lenat, D. B. and Guha, R. V. (1990). Building large knowledge-based systems: representation and inference in the Cyc project. NY: Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Liu</author>
<author>P Singh</author>
</authors>
<title>ConceptNet: A Practical Commonsense Reasoning Toolkit.</title>
<date>2004</date>
<journal>BT Technology Journal,</journal>
<pages>22--4</pages>
<contexts>
<context position="11755" citStr="Liu and Singh, 2004" startWordPosition="1865" endWordPosition="1868">fining property female in explicit taxonomic terms. Nonetheless, the free-text glosses associated with WordNet sense-entries often do state the kind of distinctions we would wish to find expressed as explicit taxonyms. A shallow parse of these glosses thus yields a sizable number of finegrained distinctions, such as &lt;lioness, female, lion&gt;, &lt;espresso, strong, coffee&gt; and both &lt;messiah, awaited, king&gt; and &lt;messiah, expected, deliverer&gt;. 3.2 ConceptNet Despite its taxonomic organization, WordNet owes much to the centralized and authority-preserving craft of traditional lexicography. ConceptNet (Liu and Singh, 2004), in contrast, is a far less authoritative knowledge-source, one that owes more to the workings of the WWW than to conventional print dictionaries. Comprising factoids culled from the template-structured contributions of thousands of web users, ConceptNet expresses many relationships that accurately reflect a public, common-sense view on a given topic (from vampires to dentists) and many more that are simply bizarre or ill-formed. Looking to the relation that interests us here, the IsA relation, ConceptNet tells us that an espresso is a strong coffee (correctly, like WordNet) but that a bagel </context>
</contexts>
<marker>Liu, Singh, 2004</marker>
<rawString>Liu, H. and Singh, P. (2004), ConceptNet: A Practical Commonsense Reasoning Toolkit. BT Technology Journal, 22(4):211-226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
<author>R Beckwith</author>
<author>C Fellbaum</author>
<author>D Gross</author>
<author>K J Miller</author>
</authors>
<title>Introduction to WordNet: an on-line lexical database.</title>
<date>1990</date>
<journal>Int. Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<pages>244</pages>
<contexts>
<context position="1317" citStr="Miller et al., 1990" startWordPosition="186" endWordPosition="189">mies from a variety of different starting points, or seeds, that are acquired from three different sources: WordNet, ConceptNet and the web at large. 1 Introduction Taxonomies provide a natural and intuitive means of organizing information, from the biological taxonomies of the Linnaean system to the layout of supermarkets and bookstores to the organizational structure of companies. Taxonomies also provide the structural backbone for ontologies in computer science, from common-sense ontologies like Cyc (Lenat and Guha, 1990) and SUMO (Niles and Pease, 2001) to lexical ontologies like WordNet (Miller et al., 1990). Each of these uses is based on the same root-branch-leaf metaphor: the broadest terms with the widest scope occupy the highest positions of a taxonomy, near the root, while specific terms with the most local concerns are located lower in the hierarchy, nearest the leaves. The more interior nodes that a taxonomy possesses, the finer the conceptual distinctions and the more gradated the similarity judgments it can make (e.g., Budanitsky and Hirst, 2006). General-purpose computational taxonomies are called upon to perform both coarse-grained and fine-grained judgments. In NLP, for instance, the</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>Miller, G., Beckwith,R., Fellbaum, C., Gross, D. and Miller, K.J. (1990). Introduction to WordNet: an on-line lexical database. Int. Journal of Lexicography, 3(4):235 – 244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Niles</author>
<author>A Pease</author>
</authors>
<title>Toward a standard upper ontology.</title>
<date>2001</date>
<booktitle>In Proc. of the 2nd International Conference on Formal Ontology in Information Systems (FOIS-2001).</booktitle>
<contexts>
<context position="1260" citStr="Niles and Pease, 2001" startWordPosition="176" endWordPosition="179"> here a means of bootstrapping finely-discriminating taxonomies from a variety of different starting points, or seeds, that are acquired from three different sources: WordNet, ConceptNet and the web at large. 1 Introduction Taxonomies provide a natural and intuitive means of organizing information, from the biological taxonomies of the Linnaean system to the layout of supermarkets and bookstores to the organizational structure of companies. Taxonomies also provide the structural backbone for ontologies in computer science, from common-sense ontologies like Cyc (Lenat and Guha, 1990) and SUMO (Niles and Pease, 2001) to lexical ontologies like WordNet (Miller et al., 1990). Each of these uses is based on the same root-branch-leaf metaphor: the broadest terms with the widest scope occupy the highest positions of a taxonomy, near the root, while specific terms with the most local concerns are located lower in the hierarchy, nearest the leaves. The more interior nodes that a taxonomy possesses, the finer the conceptual distinctions and the more gradated the similarity judgments it can make (e.g., Budanitsky and Hirst, 2006). General-purpose computational taxonomies are called upon to perform both coarse-grai</context>
</contexts>
<marker>Niles, Pease, 2001</marker>
<rawString>Niles, I. and Pease, A. (2001). Toward a standard upper ontology. In Proc. of the 2nd International Conference on Formal Ontology in Information Systems (FOIS-2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Snow</author>
<author>D Jurafsky</author>
<author>A Y Ng</author>
</authors>
<title>Learning syntactic patterns for automatic hypernym discovery.</title>
<date>2004</date>
<booktitle>Advances in Neural Information Processing Systems 17.</booktitle>
<marker>Snow, Jurafsky, Ng, 2004</marker>
<rawString>Snow, R., Jurafsky, D. and Ng, A. Y. (2004). Learning syntactic patterns for automatic hypernym discovery. Advances in Neural Information Processing Systems 17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Veale</author>
<author>Y Hao</author>
</authors>
<title>Making Lexical Ontologies Functional and Context-Sensitive.</title>
<date>2007</date>
<booktitle>In Proc. of the 45th Annual Meeting of the ACL,</booktitle>
<pages>57--64</pages>
<contexts>
<context position="9267" citStr="Veale and Hao, 2007" startWordPosition="1479" endWordPosition="1482"> explicitly annotated with the properties (ADJcat) that they bequeath to their members. These categories have an obvious descriptive and organizational utility, but of a kind that one is unlikely to find in conventional resources like WordNet and Wikipedia. Kozareva et al. (2008) test their approach on relatively simple and objective categories like states, countries (both 836 closed sets), singers and fish (both open, the former more so than the latter), but not on complex categories in which members are tied both to a general category, like food, and to a stereotypical property, like sweet (Veale and Hao, 2007). By validating membership in these complex categories using WordNet-based heuristics, we can hang these categories and members on specific WordNet senses, and thus enrich WordNet with this additional taxonomic structure. 3 Seeds for Taxonomic Growth A fine-grained taxonomy can be viewed as a set of triples Tijk = &lt;Ci, Dj, Pk&gt;, where Ci denotes a child of the parent term Pk that possesses the discriminating property Dj; in effect, each such triple expresses that Ci is a specialization of the complex taxonym Dj-Pk. Thus, the belief that cola is a carbonated-drink is expressed by the triple &lt;col</context>
<context position="13226" citStr="Veale and Hao (2007)" startWordPosition="2102" endWordPosition="2105">not trust the content of ConceptNet directly, lest we bootstrap from a highly unreliable starting point, we use WordNet as a simple filter. While the concise form of ConceptNet contains over 30,000 IsA propositions, we consider as our seed collection only those that define a noun concept (such as “espresso”) in terms of a binary compound (e.g., “strong coffee”) where the head of the latter (e.g., “coffee”) denotes a WordNet hypernym of some sense of the former. This yields triples such as &lt;Wyoming, great, state&gt;, &lt;wreck, serious, accident&gt; and &lt;wolf, wild, animal&gt;. 3.3 Web-derived Stereotypes Veale and Hao (2007) also use the observations of web-users to acquire common perceptions of oft-mentioned ideas, but do so by harvesting simile expressions of the form “as ADJ as a NOUN” directly from the web. Their approach hinges on the fact that similes exploit stereotypes to draw out the salient properties of a target, thereby allowing rich descriptions of those stereotypes to be easily acquired, e.g., that snowflakes are pure and unique, acrobats are agile and nimble, knifes are sharp and dangerous, viruses are malicious and infectious, and so on. However, because they find that almost 15% of their web-harv</context>
<context position="29192" citStr="Veale and Hao (2007)" startWordPosition="4832" endWordPosition="4835">fter 5 or so cycles of bootstrapping. Nonetheless, quality wins out, and the simile-derived seed knowledge shows itself to be a clearly superior basis for reasoning about the structure and organization of conceptual categories. Bootstrapping from the simile seed yields a slightly smaller set of discriminating features than bootstrapping from the WordNet seed, one that is many times smaller than the Poesio and Almuhareb feature set. What matters is that they are the right features to discriminate with. There appears to be a number of reasons for this significant difference in quality. For one, Veale and Hao (2007) show that similes express highly stereotypical beliefs that strongly influence the affective disposition of a term/concept; negatively perceived concepts are commonly used to exemplify negative properties in similes, while positively perceived concepts are widely used to exemplify positive properties. Veale and Hao (2008) go on to argue that similes offer a very concise snapshot of those widely-held beliefs that are the cornerstone of everyday reason1 2 3 4 5 Purity 1.00 0.90 0.80 0.70 0.60 0.50 0.40 WordNet Simile ConceptNet Poesio &amp; Alm. Coverage 0.55 0.50 WordNet Simile ConceptNet 841 ing,</context>
</contexts>
<marker>Veale, Hao, 2007</marker>
<rawString>Veale, T. and Hao, Y. (2007). Making Lexical Ontologies Functional and Context-Sensitive. In Proc. of the 45th Annual Meeting of the ACL, pp 57–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Veale</author>
<author>Y Hao</author>
</authors>
<title>A Fluid Knowledge Representation for Understanding and Generating Creative Metaphors.</title>
<date>2008</date>
<booktitle>In Proc. of Coling 2008, The 22nd International Conference on Computational Linguistics,</booktitle>
<location>Manchester.</location>
<contexts>
<context position="27797" citStr="Veale and Hao (2008)" startWordPosition="4605" endWordPosition="4608">nd ConceptNet seeds achieve comparable accuracies of 68% and 67% respectively after 5 cycles of bootstrapping, which compares well with the accuracy of 62.7% achieved by Poesio and Almuhareb. However, the simile seed clearly yields the best accuracy of 84.3%, which also exceeds the accuracy of 66.4% achieved by Poesio and Almuhareb when using both values and attributes (such as Temperature, Color, etc.) for clustering, or the accuracy of 70.9% they achieve when using attributes alone. Furthermore, bootstrapping from the simile seed yields higher cluster accuracy on the 402- noun data-set than Veale and Hao (2008) themselves achieve with their simile data on the same test-set (69.85%). But most striking of all is the concision of the representations that are acquired using bootstrapping. The simile seed yields a high cluster accuracy using a pool of just 2,614 fine discriminators, while Poesio and Almuhareb use 51,345 features even after their feature-set has been filtered for noise. Though starting from different initial scales, each seed converges toward a feature-set that is roughly twenty times smaller than that used by Poesio and Almuhareb. 6 Conclusions These experiments reveal that seed knowledg</context>
<context position="29516" citStr="Veale and Hao (2008)" startWordPosition="4876" endWordPosition="4879"> bootstrapping from the WordNet seed, one that is many times smaller than the Poesio and Almuhareb feature set. What matters is that they are the right features to discriminate with. There appears to be a number of reasons for this significant difference in quality. For one, Veale and Hao (2007) show that similes express highly stereotypical beliefs that strongly influence the affective disposition of a term/concept; negatively perceived concepts are commonly used to exemplify negative properties in similes, while positively perceived concepts are widely used to exemplify positive properties. Veale and Hao (2008) go on to argue that similes offer a very concise snapshot of those widely-held beliefs that are the cornerstone of everyday reason1 2 3 4 5 Purity 1.00 0.90 0.80 0.70 0.60 0.50 0.40 WordNet Simile ConceptNet Poesio &amp; Alm. Coverage 0.55 0.50 WordNet Simile ConceptNet 841 ing, and which should thus be the corner-stone of any general-purpose taxonomy. In addition, beliefs expressed via the “as Dj as Ci” form of similes appear to lend themselves to re-expression via the “Dj Pk such as Ci” form; in each case, a concept Ci is held up as an exemplar of a salient property Dj. Since the “such as” boot</context>
</contexts>
<marker>Veale, Hao, 2008</marker>
<rawString>Veale, T. and Hao, Y. (2008). A Fluid Knowledge Representation for Understanding and Generating Creative Metaphors. In Proc. of Coling 2008, The 22nd International Conference on Computational Linguistics, Manchester.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>