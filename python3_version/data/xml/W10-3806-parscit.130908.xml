<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.016168">
<title confidence="0.913784666666667">
Seeding Statistical Machine Translation with Translation Memory
Output through Tree-Based Structural Alignment
Ventsislav Zhechev Josef van Genabith
</title>
<author confidence="0.874807">
EuroMatrixPlus, CNGL
</author>
<affiliation confidence="0.98852">
School of Computing, Dublin City University
</affiliation>
<author confidence="0.729949">
EuroMatrixPlus, CNGL
</author>
<affiliation confidence="0.965478">
School of Computing, Dublin City University
</affiliation>
<email confidence="0.995089">
contact@VentsislavZhechev.eu josef@computing.dcu.ie
</email>
<sectionHeader confidence="0.99733" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999911260869565">
With the steadily increasing demand for
high-quality translation, the localisation
industry is constantly searching for tech-
nologies that would increase translator
throughput, with the current focus on the
use of high-quality Statistical Machine
Translation (SMT) as a supplement to the
established Translation Memory (TM)
technology. In this paper we present a
novel modular approach that utilises
state-of-the-art sub-tree alignment to pick
out pre-translated segments from a TM
match and seed with them an SMT sys-
tem to produce a final translation. We
show that the presented system can out-
perform pure SMT when a good TM
match is found. It can also be used in a
Computer-Aided Translation (CAT) envi-
ronment to present almost perfect transla-
tions to the human user with markup
highlighting the segments of the transla-
tion that need to be checked manually for
correctness.
</bodyText>
<sectionHeader confidence="0.998939" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.9999390625">
As the world becomes increasingly intercon-
nected, the major trend is to try to deliver ideas
and products to the widest audience possible.
This requires the localisation of products for as
many countries and cultures as possible, with
translation being one of the main parts of the lo-
calisation process. Because of this, the amount of
data that needs professional high-quality transla-
tion is continuing to increase well beyond the
capacity of the world’s human translators.
Thus, current efforts in the localisation indus-
try are mostly directed at the reduction of the
amount of data that needs to be translated from
scratch by hand. Such efforts mainly include the
use of Translation Memory (TM) systems, where
earlier translations are stored in a database and
offered as suggestions when new data needs to
be translated. As TM systems were originally
limited to providing translations only for (al-
most) exact matches of the new data, the integra-
tion of Machine Translation (MT) techniques is
seen as the only feasible development that has
the potential to significantly reduce the amount
of manual translation required.
At the same time, the use of SMT is frowned
upon by the users of CAT tools as they still do
not trust the quality of the SMT output. There are
two main reasons for that. First, currently there is
no reliable way to automatically ascertain the
quality of SMT-generated translations, so that the
user could at a glance make a judgement as to the
amount of effort that might be needed to post-
edit the suggested translation (Simard and Isa-
belle, 2009). Not having such automatic quality
metrics also has the side effect of it being impos-
sible for a Translation-Services Provider (TSP)
company to reliably determine in advance the
increase in translator productivity due to the use
of MT and to adjust their resources-allocation
and cost models correspondingly.
The second major problem for users is that SMT-
generated translations are as a rule only obtained
for cases where the TM system could not produce
a good-enough translation (cf. Heyn, 1996). Given
that the SMT system used is usually trained only
on the data available in the TM, expectedly it also
has few examples from which to construct the
translation, thus producing low quality output.
</bodyText>
<page confidence="0.999585">
43
</page>
<bodyText confidence="0.99975575">
In this paper, we combine a TM, SMT and an
automatic Sub-Tree Alignment (STA) backends
in a single integrated tool. When a new sentence
that needs to be translated is supplied, first a
Fuzzy-Match Score (FMS – see Section 2.2) is
obtained from the TM backend, together with the
suggested matching sentence and its translation.
For sentences that receive a reasonably high
FMS, the STA backend is used to find the corre-
spondences between the input sentence and the
TM-suggested translation, marking up the parts
of the input that are correctly translated by the
TM. The SMT backend is then employed to ob-
tain the final translation from the marked-up in-
put sentence. In this way we expect to achieve a
better result compared to using pure SMT.
In Section 2, we present the technical details
of the design of our system, together with moti-
vation for the particular design choices. Section 3
details the experimental setup and the data set
used for the evaluation results in Section 4. We
present improvements that we plan to investigate
in further work in Section 5, and provide con-
cluding remarks in Section 6.
</bodyText>
<sectionHeader confidence="0.997135" genericHeader="method">
2. System Framework
</sectionHeader>
<bodyText confidence="0.9981035">
We present a system that uses a TM-match to
pre-translate parts of the input sentence and
guide an SMT system to the generation of a
higher-quality translation.
</bodyText>
<sectionHeader confidence="0.537882" genericHeader="method">
2.1. Related Approaches
</sectionHeader>
<bodyText confidence="0.999941733333333">
We are not aware of any published research
where TM output is used to improve the per-
formance of an SMT system in a manner similar
to the system presented in this paper.
Most closely related to our approach are the
systems by Bigici and Dymetman (2008) and
Simard and Isabelle (2009), where the authors
use the TM output to extract new phrase pairs
that supplement the SMT phrase table. Such an
approach, however, does not guarantee that the
SMT system will select the TM-motivated
phrases even if a heavy bias is applied to them.
Another related system is presented in (Smith
and Clark, 2009). Here the authors use a syntax-
based EBMT system to pre-translate and mark-
</bodyText>
<footnote confidence="0.846339">
1 http://www.postgresql.org/
</footnote>
<bodyText confidence="0.999674777777778">
up parts of the input sentence and then supply
this marked-up input to an SMT system. This
differs to our system in two ways. First, Smith
and Clark use EMBT techniques to obtain partial
translations of the input from the complete ex-
ample base, while we are only looking at the best
TM match for the given input. Second, the authors
use dependency structures for EMBT matching,
while we employ phrase-based structures.
</bodyText>
<subsectionHeader confidence="0.99516">
2.2. Translation Memory Backend
</subsectionHeader>
<bodyText confidence="0.999908941176471">
Although the intention is to use a full-scale TM
system as the translation memory backend, to
have complete control over the process for this
initial research we decided to build a simple pro-
totype TM backend ourselves.
We employ a database setup using the Post-
greSQL v.8.4.31 relational database management
(RDBM) system. The segment pairs from a given
TM are stored in this database and assigned
unique IDs for further reference. When a new
sentence is supplied for translation, the database
is searched for (near) matches, using an FMS
based on normalised character-level Levenshtein
edit distance (Levenshtein, 1965).
Thus for each input sentence, from the data-
base we obtain the matching segment with the
highest FMS, its translation and the score itself.
</bodyText>
<subsectionHeader confidence="0.998061">
2.3. Sub-Tree Alignment Backend
</subsectionHeader>
<bodyText confidence="0.999986588235294">
The system presented in this paper uses phrase-
based sub-tree structural alignment (Zhechev,
2010) to discover parts of the input sentence that
correspond to parts of the suggested translation
extracted from the TM database. We chose this
particular tool, because it can produce aligned
phrase-based-tree pairs from unannotated (i.e.
unparsed) data. It can also function fully auto-
matically without the need for any training data.
The only auxiliary requirement it has is for a
probabilistic dictionary for the languages that are
being aligned. As described later in this section,
in our case this is obtained automatically from the
TM data during the training of the SMT backend.
The matching between the input sentence and
the TM-suggested translation is done in a three-
step process. First, the plain TM match and its
</bodyText>
<page confidence="0.998424">
44
</page>
<bodyText confidence="0.956309289156627">
translation are aligned, which produces a sub-
tree-aligned phrase-based tree pair with all non-
terminal nodes labelled ‘X’ (cf. Zhechev, 2010).
As we are only interested in the relations be-
tween the lexical spans of the non-terminal
nodes, we can safely ignore their labels. We call
this first step of our algorithm bilingual alignment.
In the second step, called monolingual align-
ment, the phrase-based tree-annotated version of
the TM match is aligned to the unannotated input
sentence. The reuse of the tree structure for the
TM match allows us to use it in the third step as
an intermediary to establish the available sub-
tree alignments between the input sentence and
the translation suggested from the TM.
During this final alignment, we identify
matched and mismatched portions of the input
sentence and their possible translations in the
TM suggestion and, thus, this step is called
matching. Additionally, the sub-tree alignments
implicitly provide us with reordering informa-
tion, telling us where the portions of the input
sentence that we translate should be positioned in
the final translation.
The alignment process is exemplified in Figure 1.
The tree marked ‘I’ corresponds to the input sen-
tence, the one marked ‘M’ to the TM match and
the one marked ‘T’ to the TM translation. Due to
space constraints, we only display the node ID
numbers of the non-terminal nodes in the phrase-
structure trees — in reality all nodes carry the
label ‘X’. These IDs are used to identify the sub-
sentential alignment links. The lexical items cor-
responding to the leaves of the trees are pre-
sented in the table below the graph.
The alignment process can be visually repre-
sented as starting at a linked node in the I tree
and following the link to the M tree. Then, if
available, we follow the link to the T tree and
this leads us to the T-tree node corresponding to
the I-tree node we started from. In Figure 1, this
results in the I–T alignments I1–T1B, I2–T2, I3–
T1, I4–T32 and I6–T34. The first three links are
matches, because the lexical items covered by
the I nodes correspond exactly to the lexical
items covered by their M node counterparts.
Such alignments provide us with direct TM
translations for our input. The last two links in
the group are mismatched, because there is no
lexical correspondence between the I and M
nodes (node I4 corresponds to the phrase sender
email, while the linked node M10 corresponds to
sender ’s email). Such alignments can only be
used to infer reordering information. In particular
in this case, we can infer that the target word or-
der for the input sentence is address email
sender, which produces the translation adresse
electronique de l’ expediteur.
I 1 2 3
input sender email address
M 1 2 3 4 5
match sender ’s email address .
T 1 2 3 4 5 6 7 8
trans- adresse electro- de l’ expe- du mes-
lation nique diteur sage
Figure 1. Example of sub-tree alignment between
an input sentence, TM match and TM translation
We decided to use sub-tree-based alignment,
rather than plain word alignment (e.g. GIZA++ –
Och and Ney, 2003), due to a number of factors.
First, sub-tree-based alignment provides much
better handling of long-distance reorderings,
while word– and phrase-based alignment models
always have a fixed limit on reordering distance
that tends to be relatively low to allow efficient
computation.
The alignments produced by a sub-tree align-
ment model are also precision-oriented, rather
than recall-oriented (cf. Tinsley, 2010). This is
important in our case, where we want to only
extract those parts of the translation suggested by
the TM for which we are most certain that they
are good translations.
</bodyText>
<figure confidence="0.997455105263158">
1 2
M
13
10 4
6 3
I
1 2
4
6
15
3
36
5
34 8
1 32
2 24 7
3 4 5
18 6
T
</figure>
<page confidence="0.995826">
45
</page>
<bodyText confidence="0.999998545454545">
As stated earlier, the only resource necessary
for the operation of this system is a probabilistic
bilingual dictionary covering the data that needs
to be aligned. For the bilingual alignment step,
such a bilingual dictionary is produced as a by-
product of the training of the SMT backend and
therefore available. For the monolingual align-
ment step, the required probabilistic dictionary is
generated by simply listing each unique token
seen in the source-language data in the TM as
translating only as itself with probability 1.
</bodyText>
<subsectionHeader confidence="0.997362">
2.4. Statistical Machine Translation Backend
</subsectionHeader>
<bodyText confidence="0.999991393939394">
Once the matching step is completed, we have
identified and marked-up the parts of the input
sentence for which translations will be extracted
from the TM suggestions, as well as the parts
that need to be translated from scratch. The
lengths of the non-translated segments vary de-
pending on the FMS, but are in general relatively
short (one to three tokens).
The further processing of the input relies on a
specific feature of the SMT backend we use,
namely the Moses system (Koehn et al., 2007).
We decided to use this particular system as it is
the most widely adopted open-source SMT sys-
tem, both for academic and commercial pur-
poses. In this approach, we annotate the seg-
ments of the input sentence for which transla-
tions have been found from the TM suggestion
using XML tags with the translation correspond-
ing to each segment given as an attribute to the
encapsulating XML tag, similarly to the system
described in (Smith and Clark, 2009). The SMT
backend is supplied with marked-up input in the
form of a string consisting of the concatenation
of the XML-enclosed translated segments and
the plain non-translated segments in the target-
language word order, as established by the
alignment process. The SMT backend is in-
structed to translate this input, while keeping the
translations supplied via the XML annotation.
This allows the SMT backend to produce transla-
tions informed by and conforming to actual ex-
amples from the TM, which should result in im-
provements in translation quality.
</bodyText>
<subsectionHeader confidence="0.996173">
2.5. Auxilliary Tools
</subsectionHeader>
<bodyText confidence="0.99999114893617">
It must be noted that in general the SMT backend
sees the data it needs to translate in the target-
language word order (e.g. it is asked to translate
an English sentence that has French word order).
This, however, does not correspond to the data
found in the TM, which we use for deriving the
SMT models. Because of this discrepancy, we
developed a pre-processing tool that goes over
the TM data performing bilingual alignment and
outputting reordered versions of the sentences it
processes by using the information implicitly
encoded in the sub-tree alignments. In this way
we obtain the necessary reordered data to train a
translation model where the source language al-
ready has the target-language word order. In our
system we than use this model — together with
the proper-word-order model — for translation.
One specific aspect of real-world TM data that
we need to deal with is that they often contain
meta-tag annotations of various sorts. Namely,
annotation tags specific to the file format used for
storing the TM data, XML tags annotating parts
of the text as appearing in Graphical User Inter-
face (GUI) elements, formatting tags specific to
the file format the TM data was originally taken
from, e.g. RTF, OpenDoc, etc. Letting any MT
system try to deal with these tags in a probabilis-
tic manner can easily result in ill-formed, mis-
translated and/or out-of-order meta-tags in the
translation.
This motivates the implementation of a rudi-
mentary handling of meta-tags in the system pre-
sented in this paper, in particular handling the
XML tags found in the TM data we work with,
as described in Section 3. The tool we developed
for this purpose simply builds a map of all
unique XML tags per language and replaces
them in the data with short placeholders that are
designed in such a way that they would not inter-
fere with the rest of the TM data.2 A special case
that the tool has to take care of is when an XML
tag contains an attribute whose value needs to be
translated. In such situations, we decided to not
perform any processing, but rather leave the
XML tag as is, so that all text may be translated
as needed. A complete treatment of meta-tags,
however, is beyond the scope of the current paper.
</bodyText>
<footnote confidence="0.9626345">
2 In the current implementation, the XML tags are replaced with the string 4k&lt;tag_id&gt;d, where &lt;tag_id&gt; is a unique nu-
meric identifier for the XML tag that is being replaced.
</footnote>
<page confidence="0.999154">
46
</page>
<bodyText confidence="0.998951">
We also had to build a dedicated tokeniser/de-
tokeniser pair to handle real world TM data con-
taining meta-tags, e-mail addresses, file paths,
etc., as described in Section 3. Both tools are
implemented as a cascade of regular expression
substitutions in Perl.
Finally, we use a tool to extract the textual
data from the TM. That is, we strip all tags spe-
cific to the format in which the TM is stored, as
they can in general be recreated and thus do not
need to be present during translation. In our par-
ticular case the TM is stored in the XML-based
TMX format.3
</bodyText>
<subsectionHeader confidence="0.9585">
2.6. Complete Workflow
</subsectionHeader>
<bodyText confidence="0.999849903225806">
Besides the components described above, we
also performed two further transformations on
the data. First, we lowercase the TM data before
using it to train the SMT backend models. This
also means that the alignment steps from Section
2.3 are performed on lowercased data, as the bi-
lingual dictionary used there is obtained during
the SMT training process.4
Additionally, the SMT and sub-tree alignment
systems that we use cannot handle certain char-
acters, which we need to mask in the data. For
the SMT backend, this includes ‘|’, ‘&lt;’ and ‘&gt;’
and for the sub-tree aligner, ‘(’ and ‘)’. The rea-
son these characters cannot be handled is that the
SMT system uses ‘|’ internally to separate data
fields in the trained models and ‘&lt;’ and ‘&gt;’ can-
not be handled whilst using XML tags to anno-
tate pre-translated portions of the input. The sub-
tree aligner uses ‘(’ and ‘)’ to represent the
phrase-based tree structures it generates and the
presence of these characters in the data may cre-
ate ambiguity when parsing the tree structures.
All these characters are masked by substituting
in high-Unicode counterparts, namely ‘│’, ‘﹤’,
‘﹥’, ‘﹙’ and ‘﹚’. Visually, there is a very slight
distinction and this is intentionally so to simplify
debugging. However, the fact that the character
codes are different alleviates the problems dis-
cussed above. Of course, in the final output, the
masking is reversed and the translation contains
the regular versions of the characters.
</bodyText>
<figureCaption confidence="0.998278">
Figure 2. Pre-Processing Workflow
</figureCaption>
<bodyText confidence="0.999869047619048">
The complete pre-processing workflow is pre-
sented in Figure 2, where the rectangles with ver-
tical bars represent the use of open-source tools,
while the plain rectangles represent tools devel-
oped by the authors of this paper.
First, the textual data is extracted from the
original TM format, producing one plain-text file
for each language side. These data can either be
pre-loaded in a PostgreSQL database at this time,
or during the first run of the translation system.
Next, the meta-tag-handling tool is used to
generate the substitution tables for the source and
target languages, as well as new files for each
language with the tags substituted by the corre-
sponding identifiers (cf. Section 2.5). These files
are then tokenised, lowercased and all conflicting
characters are masked, as described above.
The pre-processed files are then used to pro-
duce a file containing pairs of sentences in the
input format of the sub-tree aligner, as well as to
generate the probabilistic dictionary required for
</bodyText>
<figure confidence="0.999674301886792">
Sub-Tree Alignment
Input Data
Reordered Source-
Language Data
Meta-Tag
Substitution Maps
Language Models
Bilingual Parallel
Treebank
Language-Model
Training and
Binarisation
Automatic
Word-Alignment
Start
Normal
Word Order
Extract Textual Data
from TMX Format
Meta-Tag Handling
Tokenisation and
Masking of Special
Characters
Generation of
Bilingual Parallel
Treebank
Automatic
Word-Alignment
Reorder Source-
Language Data
Lowercasing
SMT Model
Training and
Binarisation
Generation of Probabilistic
Dictionary for
Monolingual Alignment
Probabilistic Dictionary
for Bilingual Alignment
Probabilistic Dictionary
for Monolingual
Alignment
SMT Model with
Normal Word Order
SMT Model with
Target Word Order
SMT Model
Training and
Binarisation
TMX Data
TM
Database
Stop
</figure>
<footnote confidence="0.959723666666667">
3 http://www.lisa.org/fileadmin/standards/tmx1.4/tmx.htm
4 Currently, we do not use a recaser tool and the translations produced are always in lowercase. This component, however,
will be added in a future version of the system.
</footnote>
<page confidence="0.99959">
47
</page>
<bodyText confidence="0.999898">
the monolingual alignment and to train the SMT
model on the data in the proper word order. The
SMT training produces the necessary bilingual
dictionary for use by the sub-tree aligner, which
is run to obtain a parallel-treebank version of the
TM data. The parallel treebank is then used to
retrieve bilingual alignments for the TM data,
rather than generate them on the fly during trans-
lation. This is an important design decision, as
the complexity of the alignment algorithm is high
for plain-text alignment (cf. Zhechev, 2010).
Once we have generated the bilingual parallel
treebank, we run the reordering tool, which gen-
erates a new plain-text file for the source lan-
guage, where the sentences are modified to con-
form to the target-language word order, as im-
plied by the data in the parallel treebank. This is
then matched with the proper-order target-
language file to train the SMT backend for the
actual use in the translation process.
</bodyText>
<figureCaption confidence="0.995131">
Figure 3. Translation Workflow
</figureCaption>
<bodyText confidence="0.999647583333333">
Once all the necessary files have been gener-
ated and all pre-processing steps have been com-
pleted, the system is ready for use for translation.
The translation workflow is shown in Figure 3,
‘I’, ‘M’ and ‘T’ having the same meanings as in
Figure 1. Here, the first step after an input sen-
tence has been read in is to find the TM match
with the highest FMS. This is done using the
original plain non-pre-processed data to simulate
real-life operation with a proper TM backend.
After the best TM match and its translation are
extracted from the TM, they — together with the
input sentence — are pre-processed by tokenisa-
tion, lowercasing, meta-tag and special-character
substitution. Next, the corresponding tree pair is
extracted from the bilingual parallel treebank to
establish the tree structure for the TM source-
language match. This tree structure is then used
to perform the monolingual alignment, which
allows us to perform the matching step next. Af-
ter the matching is complete, we generate a final
translation as described in Section 2.4. Finally,
the translations are de-tokenised and the XML
tags and special characters are unmasked.
</bodyText>
<sectionHeader confidence="0.996825" genericHeader="method">
3. Experimental Setup
</sectionHeader>
<bodyText confidence="0.999988096774193">
We use real-life TM data from an industrial part-
ner. The TM was generated during the translation
of RTF-formatted customer support documenta-
tion. The data is in TMX format and originally
contains 108 967 English–French translation
segments, out of which 14 segments either have
an empty language side or have an extreme dis-
crepancy in the number of tokens for each lan-
guage side and were therefore discarded.
A particular real-life trait of the data is the
presence of a large number of XML tags. Run-
ning the tag-mapping tool described in Section
2.6, we gathered 2 049 distinct tags for the Eng-
lish side of the data and 2 653 for the French
side. Still, there were certain XML tags that in-
cluded a label argument whose value was trans-
lated from one language to the other. These XML
tags were left intact so that our system could
handle the translation correctly.
The TM data also contain a large number of
file paths, e-mail addresses, URLs and others,
which makes bespoke tokenisation of the data
necessary. Our tokenisation tool ensures that
none of these elements are tokenised, keeps RTF
formatting sequences non-tokenised and properly
handles non-masked XML tags, minimising their
fragmentation.
As translation segments rarely occur more than
once in a TM, we observe a high number of unique
tokens (measured after pre-processing) — 41 379
for English and 49 971 for French —out of
</bodyText>
<figure confidence="0.996687448979592">
Probabilistic Dictionary
for Monolingual
Alignment
Meta-Tag Handling,
Detokenisation and
Unmasking of Special
Characters for Output
SMT Model with
Target Word Order
Meta-Tag
Substitution Maps
Bilingual Parallel
Treebank
Output
Translation
(xml)
Read Input
Sentence
Meta-Tag Handling,
Tokenisation and
Masking of Special
Characters for I, M, T
Find TM Match with
Highest FMS
Extract Bilingual
Alignment for M, T
Perform Alignment
Matching
SMT Backend
(both word orders)
Generate Mono-
lingual Alignment
for M, I
yes
FMS &gt;= 50
no
SMT Backend
(normal word order)
SMT Model with
Normal Word Order
Language Models
xml Approach
Output
Translation
(direct)
TM
Database
Output T
(tm)
</figure>
<page confidence="0.998539">
48
</page>
<bodyText confidence="0.999906066666667">
108 953 segment pairs. The average sentence
length is 13.2 for English and 15.0 for French.
For evaluation, we use a data set of 4977 Eng-
lish–French segments from the domain of the
TM. The sentences in the test set are significantly
shorter on average, compared to the TM — 9.2
tokens for English and 10.9 for French.
It must be noted that we used SMT models
with maximum phrase length of 3 tokens, rather
than the standard 5 tokens, and for decoding we
used a 3-gram language model. This results in
much smaller models than the ones usually used
in mainstream SMT applications. (The standard
for some tools goes as far as 7-token phase-
length limit and 7-gram language models)
</bodyText>
<sectionHeader confidence="0.962655" genericHeader="method">
4. Evaluation Results
</sectionHeader>
<bodyText confidence="0.999955111111111">
For the evaluation of our system, we used a
number of widely accepted automatic metrics,
namely BLEU (Papineni et al., 2002), METEOR
(Banerjee and Lavie, 2005), TER (Snover et al.,
2006) and inverse F-Score based on token-level
precision and recall.
We setup our system to only fully process in-
put sentences for which a TM match with an
FMS over 50% was found, although all sen-
tences were translated directly using the SMT
backend to check the overall pure SMT perform-
ance. The TM-suggested translations were also
output for all input sentences.
The results of the evaluation are given in Fig-
ure 4, where the tm and direct scores are also
given for the FMS range [0%; 50%)∪{100%}.
Across all metrics we see a uniform drop in the
quality of TM-suggested translations, which is
what we expected, given that these translations
contain one or more wrong words. We believe
that the relatively high scores recorded for the
TM-suggested translations at the high end of the
FMS scale are a result of the otherwise perfect
word order and lexical choice. For n-gram-
match-based metrics like the ones we used such a
result is expected and predictable. Although the
inverse F-score results show the potential of our
setup to translate the outstanding tokens in a
90%–100% TM match, it appears that the SMT
system produces word order that does not corre-
spond to the reference translation and because of
this receives lower scores on the other metrics.
The unexpected drop in scores for perfect TM
matches is due to discrepancies between the ref-
erence translations in our test set and the transla-
tions stored in the TM. We believe that this issue
</bodyText>
<figure confidence="0.94653066">
0...50/1963 50...60/779 60...70/621 70...80/537 80...90/537 90...100/375 100/165
FMS Range/Segments
0...50/1963 50...60/779 60...70/621 70...80/537 80...90/537 90...100/375 100/165
FMS Range/Segments
0...50/1963 50...60/779 60...70/621 70...80/537 80...90/537 90...100/375 100/165
FMS Range/Segments
0...50/1963 50...60/779 60...70/621 70...80/537 80...90/537 90...100/375 100/165
FMS Range/Segments
direct
xml
tm
tm
xml
direct
tm
xml
direct
BLEU 0,8
0,7
0,6
0,5
0,4
0,3
0,2
0,1
TER 0,9
0,8
0,7
0,6
0,5
0,4
0,3
0,2
0,1
METEOR 0,9
Inverse F-Score 0,8
0,7
0,6
0,5
0,4
0,3
0,7
0,6
0,5
0,4
0,3
0,2
tm
xml
direct
</figure>
<figureCaption confidence="0.999576">
Figure 4. Evaluation results for English-to-French translation, broken down by FMS range
</figureCaption>
<page confidence="0.997513">
49
</page>
<bodyText confidence="0.999966517241379">
affects all FMS ranges, albeit to a lower extent
for non-perfect matches. Unfortunately, the exact
impact cannot be ascertained without human
evaluation.
We observe a significant drop-off in translation
quality for the direct output below FMS 50%.
This suggests that sentences with such low FMS
should be translated either by a human translator
from scratch, or by an SMT system trained on
different/more data.
Our system (i.e. the xml setup) clearly outper-
forms the direct SMT translation for FMS be-
tween 80 and 100 and has comparable perform-
ance between FMS 70 and 80. Below FMS 70,
the SMT backend has the best performance. Al-
though these results are positive, we still need to
investigate why our system has poor perform-
ance at lower FMS ranges. Theoretically, it
should outperform the SMT backend across all
ranges, as its output is generated by supplying
the SMT backend with good pre-translated frag-
ments. The Inverse F-Score graph suggest that
this is due to worse lexical choice, but only man-
ual evaluation can provide us with clues for solv-
ing the issue.
The discrepancy in the results in the Inverse F-
Score graph with the other metrics suggest that
the biggest problem for our system is producing
output in the expected word-order.
</bodyText>
<sectionHeader confidence="0.999484" genericHeader="method">
5. Future Work
</sectionHeader>
<bodyText confidence="0.999990641025641">
There are a number of possible directions for
improvement that can be explored.
As mentioned earlier, we plan to integrate our
system with a full-featured open-source or com-
mercial TM product that will supply the TM
matches and translations. We expect this to im-
prove our results, as the quality of the TM matches
will better correspond to the reported FMS.
Such an integration will also be the first neces-
sary step to perform a user study evaluating the
effect of the use of our system on post-editing
speeds. We expect the findings of such a study to
show a significant increase of throughput that
will significantly reduce the costs of translation
for large-scale projects.
It would be interesting to also conduct a user
study where our system is used to additionally
mark up the segments that need to be edited in
the final SMT translation. We expect this to pro-
vide additional speedup to the post-editing proc-
ess. Such a study will require tight integration
between our system and a CAT tool and the
modular design we presented will facilitate this
significantly.
The proposed treatment of meta-tags is cur-
rently very rudimentary and may be extended
with additional features and to handle additional
types of tags. The design of our system currently
allows the meta-tag-handling tool to be devel-
oped independently, thus giving the user the
choice of using a different meta-tag tool for each
type of data they work with.
In addition, the reordering tool needs to be
developed further, with emphasis on properly
handling situations where the appropriate posi-
tion of an input-sentence segment cannot be re-
liably established. In general, further research is
needed into the reordering errors introduced by
the SMT system into otherwise good translations.
</bodyText>
<sectionHeader confidence="0.999374" genericHeader="conclusions">
6. Conclusions
</sectionHeader>
<bodyText confidence="0.999969653846154">
In this paper, we presented a novel modular ap-
proach to the utilisation of Translation Memory
data to improve the quality of Statistical Machine
Translation.
The system we developed uses precise sub-
tree-based alignments to reliably determine and
mark up correspondences between an input sen-
tence and a TM-suggested translation, which en-
sures the utilisation of the high-quality transla-
tion data stored in the TM database. An SMT
backend then translates the marked-up input sen-
tence to produce a final translation with im-
proved quality.
Our evaluation shows that the system pre-
sented in this paper significantly improves the
quality of SMT output when using TM matches
with FMS above 80 and produces results on par
with the pure SMT output for SMT between 70
and 80. TM matches with FMS under 70 seem to
provide insufficient reordering information and
too few matches to improve on the SMT output.
Still, further investigation is needed to properly
diagnose the drop in quality for FMS below 70.
We expect further improvements to the reor-
dering functionality of our system to result in
higher-quality output even for lower FMS ranges.
</bodyText>
<page confidence="0.994013">
50
</page>
<sectionHeader confidence="0.999096" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9986526">
This research is funded under the 7th Framework
Programme of the European Commission within
the EuroMatrixPlus project (grant № 231720).
The data used for evaluation was generously pro-
vided by Symantec Ireland.
</bodyText>
<sectionHeader confidence="0.999388" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999920718309859">
Banerjee, Satanjeev and Alon Lavie. 2005. METEOR:
An Automatic Metric for MT Evaluation with
Improved Correlation with Human Judgements.
In Proceedings of the Workshop on Intrinsic and
Extrinsic Evaluation Measures for MT and/or
Summarization at the 43rd Annual Meeting of the
Association for Computational Linguistics
(ACL ’05), pp. 65–72. Ann Arbor, MI.
Bi&amp;i, Ergun and Marc Dymetman. 2008. Dynamic
Translation Memory: Using Statistical Machine
Translation to improve Translation Memory Fuzzy
Matches. In Proceedings of the 9th International
Conference on Intelligent Text Processing and
Computational Linguistics (CICLing ’08),
ed. Alexander F. Gelbukh, pp. 454–465. Vol. 4919
of Lecture Notes in Computer Science. Haifa,
Israel: Springer Verlag.
Heyn, Matthias. 1996. Integrating Machine
Translation into Translation Memory Systems.
In Proceedings of the EAMT Machine Translation
Workshop, TKE ’96, pp. 113–126. Vienna, Austria.
Koehn, Philipp, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine
Moran, Richard Zens, Chris Dyer, Ondřej Bojar,
Alexandra Constantin and Evan Herbst. 2007.
Moses: Open Source Toolkit for Statistical
Machine Translation. In Proceedings of the Demo
and Poster Sessions of the 45th Annual Meeting of
the Association for Computational Linguistics
(ACL ’07), pp. 177–180. Prague, Czech Republic.
Levenshtein, Vladimir I. 1965. Двоичные коды с
исправлением выпадений, вставок и замещений
символов (Binary Codes Capable of Correcting
Deletions, Insertions, and Reversals). )IoicAadtc
Aicadeasuu Hayic CCCP, 163 (4): 845–848.
[reprinted in: Soviet Physics Doklady, 10: 707–710.].
Och, Franz Josef and Hermann Ney. 2003.
A Systematic Comparison of Various Statistical
Alignment Models. Computational Linguistics,
29 (1): 19–51.
Papineni, Kishore, Salim Roukos, Todd Ward and
Wei-Jing Zhu. 2002. BLEU: A Method for
Automatic Evaluation of Machine Translation.
In Proceedings of the 40th Annual Meeting of the
Association of Computational Linguistics
(ACL ’02), pp. 311–318. Philadelphia, PA.
Simard, Michel and Pierre Isabelle. 2009. Phrase-
based Machine Translation in a Computer-assisted
Translation Environment. In The Twelfth Machine
Translation Summit (MT Summit XII), pp. 120–127.
Ottawa, ON, Canada.
Smith, James and Stephen Clark. 2009. EBMT for
SMT: A New EBMT–SMT Hybrid. In Proceedings
of the 3rd International Workshop on Example-
Based Machine Translation (EBMT ’09),
eds. Mikel L. Forcada and Andy Way, pp. 3–10.
Dublin, Ireland.
Snover, Matthew, Bonnie J. Dorr, Richard Schwartz,
Linnea Micciulla and John Makhoul. 2006.
A Study of Translation Edit Rate with Targeted
Human Annotation. In Proceedings of the
7th Conference of the Association for Machine
Translation in the Americas (AMTA ’06),
pp. 223–231. Cambridge, MA.
Tinsley, John. 2010. Resourcing Machine Translation
with Parallel Treebanks. School of Computing,
Dublin City Univercity: PhD Thesis. Dublin, Ireland.
Zhechev, Ventsislav. 2010. Automatic Generation of
Parallel Treebanks. An Efficient Unsupervised
System: Lambert Academic Publishing.
</reference>
<page confidence="0.999122">
51
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.159111">
<title confidence="0.991489">Seeding Statistical Machine Translation with Translation Output through Tree-Based Structural Alignment</title>
<author confidence="0.983854">Ventsislav Zhechev Josef van_Genabith</author>
<affiliation confidence="0.7681415">EuroMatrixPlus, CNGL School of Computing, Dublin City University</affiliation>
<address confidence="0.548261">EuroMatrixPlus, CNGL</address>
<affiliation confidence="0.999385">School of Computing, Dublin City University</affiliation>
<email confidence="0.609812">contact@VentsislavZhechev.eujosef@computing.dcu.ie</email>
<abstract confidence="0.995990208333334">With the steadily increasing demand for high-quality translation, the localisation industry is constantly searching for technologies that would increase translator throughput, with the current focus on the use of high-quality Statistical Machine Translation (SMT) as a supplement to the established Translation Memory (TM) technology. In this paper we present a novel modular approach that utilises state-of-the-art sub-tree alignment to pick out pre-translated segments from a TM match and seed with them an SMT system to produce a final translation. We show that the presented system can outperform pure SMT when a good TM match is found. It can also be used in a Computer-Aided Translation (CAT) environment to present almost perfect translations to the human user with markup highlighting the segments of the translation that need to be checked manually for correctness.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Alon Lavie</author>
</authors>
<title>METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgements.</title>
<date>2005</date>
<booktitle>In Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for MT and/or Summarization at the 43rd Annual Meeting of the Association for Computational Linguistics (ACL ’05),</booktitle>
<pages>65--72</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="24906" citStr="Banerjee and Lavie, 2005" startWordPosition="4132" endWordPosition="4135">shorter on average, compared to the TM — 9.2 tokens for English and 10.9 for French. It must be noted that we used SMT models with maximum phrase length of 3 tokens, rather than the standard 5 tokens, and for decoding we used a 3-gram language model. This results in much smaller models than the ones usually used in mainstream SMT applications. (The standard for some tools goes as far as 7-token phaselength limit and 7-gram language models) 4. Evaluation Results For the evaluation of our system, we used a number of widely accepted automatic metrics, namely BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), TER (Snover et al., 2006) and inverse F-Score based on token-level precision and recall. We setup our system to only fully process input sentences for which a TM match with an FMS over 50% was found, although all sentences were translated directly using the SMT backend to check the overall pure SMT performance. The TM-suggested translations were also output for all input sentences. The results of the evaluation are given in Figure 4, where the tm and direct scores are also given for the FMS range [0%; 50%)∪{100%}. Across all metrics we see a uniform drop in the quality of TM-suggested transl</context>
</contexts>
<marker>Banerjee, Lavie, 2005</marker>
<rawString>Banerjee, Satanjeev and Alon Lavie. 2005. METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgements. In Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for MT and/or Summarization at the 43rd Annual Meeting of the Association for Computational Linguistics (ACL ’05), pp. 65–72. Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ergun Bi&amp;i</author>
<author>Marc Dymetman</author>
</authors>
<title>Dynamic Translation Memory: Using Statistical Machine Translation to improve Translation Memory Fuzzy Matches.</title>
<date>2008</date>
<booktitle>In Proceedings of the 9th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing ’08),</booktitle>
<volume>4919</volume>
<pages>454--465</pages>
<editor>ed. Alexander F. Gelbukh,</editor>
<publisher>Springer Verlag.</publisher>
<location>Haifa, Israel:</location>
<marker>Bi&amp;i, Dymetman, 2008</marker>
<rawString>Bi&amp;i, Ergun and Marc Dymetman. 2008. Dynamic Translation Memory: Using Statistical Machine Translation to improve Translation Memory Fuzzy Matches. In Proceedings of the 9th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing ’08), ed. Alexander F. Gelbukh, pp. 454–465. Vol. 4919 of Lecture Notes in Computer Science. Haifa, Israel: Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Heyn</author>
</authors>
<title>Integrating Machine Translation into Translation Memory Systems.</title>
<date>1996</date>
<booktitle>In Proceedings of the EAMT Machine Translation Workshop, TKE ’96,</booktitle>
<pages>113--126</pages>
<location>Vienna, Austria.</location>
<contexts>
<context position="3297" citStr="Heyn, 1996" startWordPosition="517" endWordPosition="518"> as to the amount of effort that might be needed to postedit the suggested translation (Simard and Isabelle, 2009). Not having such automatic quality metrics also has the side effect of it being impossible for a Translation-Services Provider (TSP) company to reliably determine in advance the increase in translator productivity due to the use of MT and to adjust their resources-allocation and cost models correspondingly. The second major problem for users is that SMTgenerated translations are as a rule only obtained for cases where the TM system could not produce a good-enough translation (cf. Heyn, 1996). Given that the SMT system used is usually trained only on the data available in the TM, expectedly it also has few examples from which to construct the translation, thus producing low quality output. 43 In this paper, we combine a TM, SMT and an automatic Sub-Tree Alignment (STA) backends in a single integrated tool. When a new sentence that needs to be translated is supplied, first a Fuzzy-Match Score (FMS – see Section 2.2) is obtained from the TM backend, together with the suggested matching sentence and its translation. For sentences that receive a reasonably high FMS, the STA backend is</context>
</contexts>
<marker>Heyn, 1996</marker>
<rawString>Heyn, Matthias. 1996. Integrating Machine Translation into Translation Memory Systems. In Proceedings of the EAMT Machine Translation Workshop, TKE ’96, pp. 113–126. Vienna, Austria.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
</authors>
<title>Ondřej Bojar, Alexandra Constantin and Evan Herbst.</title>
<date>2007</date>
<booktitle>In Proceedings of the Demo and Poster Sessions of the 45th Annual Meeting of the Association for Computational Linguistics (ACL ’07),</booktitle>
<pages>177--180</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="12365" citStr="Koehn et al., 2007" startWordPosition="2057" endWordPosition="2060">urce-language data in the TM as translating only as itself with probability 1. 2.4. Statistical Machine Translation Backend Once the matching step is completed, we have identified and marked-up the parts of the input sentence for which translations will be extracted from the TM suggestions, as well as the parts that need to be translated from scratch. The lengths of the non-translated segments vary depending on the FMS, but are in general relatively short (one to three tokens). The further processing of the input relies on a specific feature of the SMT backend we use, namely the Moses system (Koehn et al., 2007). We decided to use this particular system as it is the most widely adopted open-source SMT system, both for academic and commercial purposes. In this approach, we annotate the segments of the input sentence for which translations have been found from the TM suggestion using XML tags with the translation corresponding to each segment given as an attribute to the encapsulating XML tag, similarly to the system described in (Smith and Clark, 2009). The SMT backend is supplied with marked-up input in the form of a string consisting of the concatenation of the XML-enclosed translated segments and t</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, 2007</marker>
<rawString>Koehn, Philipp, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondřej Bojar, Alexandra Constantin and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of the Demo and Poster Sessions of the 45th Annual Meeting of the Association for Computational Linguistics (ACL ’07), pp. 177–180. Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir I Levenshtein</author>
</authors>
<title>Двоичные коды с исправлением выпадений, вставок и замещений символов (Binary Codes Capable of Correcting Deletions, Insertions, and Reversals). )IoicAadtc Aicadeasuu Hayic CCCP, 163 (4): 845–848. [reprinted in:</title>
<date>1965</date>
<journal>Soviet Physics Doklady,</journal>
<volume>10</volume>
<pages>707--710</pages>
<contexts>
<context position="6583" citStr="Levenshtein, 1965" startWordPosition="1070" endWordPosition="1071">though the intention is to use a full-scale TM system as the translation memory backend, to have complete control over the process for this initial research we decided to build a simple prototype TM backend ourselves. We employ a database setup using the PostgreSQL v.8.4.31 relational database management (RDBM) system. The segment pairs from a given TM are stored in this database and assigned unique IDs for further reference. When a new sentence is supplied for translation, the database is searched for (near) matches, using an FMS based on normalised character-level Levenshtein edit distance (Levenshtein, 1965). Thus for each input sentence, from the database we obtain the matching segment with the highest FMS, its translation and the score itself. 2.3. Sub-Tree Alignment Backend The system presented in this paper uses phrasebased sub-tree structural alignment (Zhechev, 2010) to discover parts of the input sentence that correspond to parts of the suggested translation extracted from the TM database. We chose this particular tool, because it can produce aligned phrase-based-tree pairs from unannotated (i.e. unparsed) data. It can also function fully automatically without the need for any training dat</context>
</contexts>
<marker>Levenshtein, 1965</marker>
<rawString>Levenshtein, Vladimir I. 1965. Двоичные коды с исправлением выпадений, вставок и замещений символов (Binary Codes Capable of Correcting Deletions, Insertions, and Reversals). )IoicAadtc Aicadeasuu Hayic CCCP, 163 (4): 845–848. [reprinted in: Soviet Physics Doklady, 10: 707–710.].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="10637" citStr="Och and Ney, 2003" startWordPosition="1760" endWordPosition="1763">h alignments can only be used to infer reordering information. In particular in this case, we can infer that the target word order for the input sentence is address email sender, which produces the translation adresse electronique de l’ expediteur. I 1 2 3 input sender email address M 1 2 3 4 5 match sender ’s email address . T 1 2 3 4 5 6 7 8 trans- adresse electro- de l’ expe- du meslation nique diteur sage Figure 1. Example of sub-tree alignment between an input sentence, TM match and TM translation We decided to use sub-tree-based alignment, rather than plain word alignment (e.g. GIZA++ – Och and Ney, 2003), due to a number of factors. First, sub-tree-based alignment provides much better handling of long-distance reorderings, while word– and phrase-based alignment models always have a fixed limit on reordering distance that tends to be relatively low to allow efficient computation. The alignments produced by a sub-tree alignment model are also precision-oriented, rather than recall-oriented (cf. Tinsley, 2010). This is important in our case, where we want to only extract those parts of the translation suggested by the TM for which we are most certain that they are good translations. 1 2 M 13 10 </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Och, Franz Josef and Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29 (1): 19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: A Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association of Computational Linguistics (ACL ’02),</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="24871" citStr="Papineni et al., 2002" startWordPosition="4127" endWordPosition="4130"> the test set are significantly shorter on average, compared to the TM — 9.2 tokens for English and 10.9 for French. It must be noted that we used SMT models with maximum phrase length of 3 tokens, rather than the standard 5 tokens, and for decoding we used a 3-gram language model. This results in much smaller models than the ones usually used in mainstream SMT applications. (The standard for some tools goes as far as 7-token phaselength limit and 7-gram language models) 4. Evaluation Results For the evaluation of our system, we used a number of widely accepted automatic metrics, namely BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), TER (Snover et al., 2006) and inverse F-Score based on token-level precision and recall. We setup our system to only fully process input sentences for which a TM match with an FMS over 50% was found, although all sentences were translated directly using the SMT backend to check the overall pure SMT performance. The TM-suggested translations were also output for all input sentences. The results of the evaluation are given in Figure 4, where the tm and direct scores are also given for the FMS range [0%; 50%)∪{100%}. Across all metrics we see a uniform drop in</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Papineni, Kishore, Salim Roukos, Todd Ward and Wei-Jing Zhu. 2002. BLEU: A Method for Automatic Evaluation of Machine Translation. In Proceedings of the 40th Annual Meeting of the Association of Computational Linguistics (ACL ’02), pp. 311–318. Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Simard</author>
<author>Pierre Isabelle</author>
</authors>
<title>Phrasebased Machine Translation in a Computer-assisted Translation Environment.</title>
<date>2009</date>
<booktitle>In The Twelfth Machine Translation Summit (MT Summit XII),</booktitle>
<pages>120--127</pages>
<location>Ottawa, ON,</location>
<contexts>
<context position="2800" citStr="Simard and Isabelle, 2009" startWordPosition="435" endWordPosition="439">egration of Machine Translation (MT) techniques is seen as the only feasible development that has the potential to significantly reduce the amount of manual translation required. At the same time, the use of SMT is frowned upon by the users of CAT tools as they still do not trust the quality of the SMT output. There are two main reasons for that. First, currently there is no reliable way to automatically ascertain the quality of SMT-generated translations, so that the user could at a glance make a judgement as to the amount of effort that might be needed to postedit the suggested translation (Simard and Isabelle, 2009). Not having such automatic quality metrics also has the side effect of it being impossible for a Translation-Services Provider (TSP) company to reliably determine in advance the increase in translator productivity due to the use of MT and to adjust their resources-allocation and cost models correspondingly. The second major problem for users is that SMTgenerated translations are as a rule only obtained for cases where the TM system could not produce a good-enough translation (cf. Heyn, 1996). Given that the SMT system used is usually trained only on the data available in the TM, expectedly it</context>
<context position="5099" citStr="Simard and Isabelle (2009)" startWordPosition="826" endWordPosition="829">Section 4. We present improvements that we plan to investigate in further work in Section 5, and provide concluding remarks in Section 6. 2. System Framework We present a system that uses a TM-match to pre-translate parts of the input sentence and guide an SMT system to the generation of a higher-quality translation. 2.1. Related Approaches We are not aware of any published research where TM output is used to improve the performance of an SMT system in a manner similar to the system presented in this paper. Most closely related to our approach are the systems by Bigici and Dymetman (2008) and Simard and Isabelle (2009), where the authors use the TM output to extract new phrase pairs that supplement the SMT phrase table. Such an approach, however, does not guarantee that the SMT system will select the TM-motivated phrases even if a heavy bias is applied to them. Another related system is presented in (Smith and Clark, 2009). Here the authors use a syntaxbased EBMT system to pre-translate and mark1 http://www.postgresql.org/ up parts of the input sentence and then supply this marked-up input to an SMT system. This differs to our system in two ways. First, Smith and Clark use EMBT techniques to obtain partial </context>
</contexts>
<marker>Simard, Isabelle, 2009</marker>
<rawString>Simard, Michel and Pierre Isabelle. 2009. Phrasebased Machine Translation in a Computer-assisted Translation Environment. In The Twelfth Machine Translation Summit (MT Summit XII), pp. 120–127. Ottawa, ON, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Smith</author>
<author>Stephen Clark</author>
</authors>
<title>EBMT for SMT: A New EBMT–SMT Hybrid.</title>
<date>2009</date>
<booktitle>In Proceedings of the 3rd International Workshop on ExampleBased Machine Translation (EBMT ’09),</booktitle>
<pages>3--10</pages>
<editor>eds. Mikel L. Forcada and Andy Way,</editor>
<location>Dublin, Ireland.</location>
<contexts>
<context position="5409" citStr="Smith and Clark, 2009" startWordPosition="879" endWordPosition="882">ion. 2.1. Related Approaches We are not aware of any published research where TM output is used to improve the performance of an SMT system in a manner similar to the system presented in this paper. Most closely related to our approach are the systems by Bigici and Dymetman (2008) and Simard and Isabelle (2009), where the authors use the TM output to extract new phrase pairs that supplement the SMT phrase table. Such an approach, however, does not guarantee that the SMT system will select the TM-motivated phrases even if a heavy bias is applied to them. Another related system is presented in (Smith and Clark, 2009). Here the authors use a syntaxbased EBMT system to pre-translate and mark1 http://www.postgresql.org/ up parts of the input sentence and then supply this marked-up input to an SMT system. This differs to our system in two ways. First, Smith and Clark use EMBT techniques to obtain partial translations of the input from the complete example base, while we are only looking at the best TM match for the given input. Second, the authors use dependency structures for EMBT matching, while we employ phrase-based structures. 2.2. Translation Memory Backend Although the intention is to use a full-scale </context>
<context position="12813" citStr="Smith and Clark, 2009" startWordPosition="2135" endWordPosition="2138">latively short (one to three tokens). The further processing of the input relies on a specific feature of the SMT backend we use, namely the Moses system (Koehn et al., 2007). We decided to use this particular system as it is the most widely adopted open-source SMT system, both for academic and commercial purposes. In this approach, we annotate the segments of the input sentence for which translations have been found from the TM suggestion using XML tags with the translation corresponding to each segment given as an attribute to the encapsulating XML tag, similarly to the system described in (Smith and Clark, 2009). The SMT backend is supplied with marked-up input in the form of a string consisting of the concatenation of the XML-enclosed translated segments and the plain non-translated segments in the targetlanguage word order, as established by the alignment process. The SMT backend is instructed to translate this input, while keeping the translations supplied via the XML annotation. This allows the SMT backend to produce translations informed by and conforming to actual examples from the TM, which should result in improvements in translation quality. 2.5. Auxilliary Tools It must be noted that in gen</context>
</contexts>
<marker>Smith, Clark, 2009</marker>
<rawString>Smith, James and Stephen Clark. 2009. EBMT for SMT: A New EBMT–SMT Hybrid. In Proceedings of the 3rd International Workshop on ExampleBased Machine Translation (EBMT ’09), eds. Mikel L. Forcada and Andy Way, pp. 3–10. Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie J Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A Study of Translation Edit Rate with Targeted Human Annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas (AMTA ’06),</booktitle>
<pages>223--231</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="24933" citStr="Snover et al., 2006" startWordPosition="4137" endWordPosition="4140">the TM — 9.2 tokens for English and 10.9 for French. It must be noted that we used SMT models with maximum phrase length of 3 tokens, rather than the standard 5 tokens, and for decoding we used a 3-gram language model. This results in much smaller models than the ones usually used in mainstream SMT applications. (The standard for some tools goes as far as 7-token phaselength limit and 7-gram language models) 4. Evaluation Results For the evaluation of our system, we used a number of widely accepted automatic metrics, namely BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), TER (Snover et al., 2006) and inverse F-Score based on token-level precision and recall. We setup our system to only fully process input sentences for which a TM match with an FMS over 50% was found, although all sentences were translated directly using the SMT backend to check the overall pure SMT performance. The TM-suggested translations were also output for all input sentences. The results of the evaluation are given in Figure 4, where the tm and direct scores are also given for the FMS range [0%; 50%)∪{100%}. Across all metrics we see a uniform drop in the quality of TM-suggested translations, which is what we ex</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Snover, Matthew, Bonnie J. Dorr, Richard Schwartz, Linnea Micciulla and John Makhoul. 2006. A Study of Translation Edit Rate with Targeted Human Annotation. In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas (AMTA ’06), pp. 223–231. Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Tinsley</author>
</authors>
<title>Resourcing Machine Translation with Parallel Treebanks. School of Computing, Dublin City Univercity: PhD Thesis.</title>
<date>2010</date>
<location>Dublin,</location>
<contexts>
<context position="11048" citStr="Tinsley, 2010" startWordPosition="1820" endWordPosition="1821">gure 1. Example of sub-tree alignment between an input sentence, TM match and TM translation We decided to use sub-tree-based alignment, rather than plain word alignment (e.g. GIZA++ – Och and Ney, 2003), due to a number of factors. First, sub-tree-based alignment provides much better handling of long-distance reorderings, while word– and phrase-based alignment models always have a fixed limit on reordering distance that tends to be relatively low to allow efficient computation. The alignments produced by a sub-tree alignment model are also precision-oriented, rather than recall-oriented (cf. Tinsley, 2010). This is important in our case, where we want to only extract those parts of the translation suggested by the TM for which we are most certain that they are good translations. 1 2 M 13 10 4 6 3 I 1 2 4 6 15 3 36 5 34 8 1 32 2 24 7 3 4 5 18 6 T 45 As stated earlier, the only resource necessary for the operation of this system is a probabilistic bilingual dictionary covering the data that needs to be aligned. For the bilingual alignment step, such a bilingual dictionary is produced as a byproduct of the training of the SMT backend and therefore available. For the monolingual alignment step, the</context>
</contexts>
<marker>Tinsley, 2010</marker>
<rawString>Tinsley, John. 2010. Resourcing Machine Translation with Parallel Treebanks. School of Computing, Dublin City Univercity: PhD Thesis. Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ventsislav Zhechev</author>
</authors>
<title>Automatic Generation of Parallel Treebanks. An Efficient Unsupervised System:</title>
<date>2010</date>
<publisher>Lambert Academic Publishing.</publisher>
<contexts>
<context position="6853" citStr="Zhechev, 2010" startWordPosition="1112" endWordPosition="1113"> relational database management (RDBM) system. The segment pairs from a given TM are stored in this database and assigned unique IDs for further reference. When a new sentence is supplied for translation, the database is searched for (near) matches, using an FMS based on normalised character-level Levenshtein edit distance (Levenshtein, 1965). Thus for each input sentence, from the database we obtain the matching segment with the highest FMS, its translation and the score itself. 2.3. Sub-Tree Alignment Backend The system presented in this paper uses phrasebased sub-tree structural alignment (Zhechev, 2010) to discover parts of the input sentence that correspond to parts of the suggested translation extracted from the TM database. We chose this particular tool, because it can produce aligned phrase-based-tree pairs from unannotated (i.e. unparsed) data. It can also function fully automatically without the need for any training data. The only auxiliary requirement it has is for a probabilistic dictionary for the languages that are being aligned. As described later in this section, in our case this is obtained automatically from the TM data during the training of the SMT backend. The matching betw</context>
<context position="20375" citStr="Zhechev, 2010" startWordPosition="3379" endWordPosition="3380">ercase. This component, however, will be added in a future version of the system. 47 the monolingual alignment and to train the SMT model on the data in the proper word order. The SMT training produces the necessary bilingual dictionary for use by the sub-tree aligner, which is run to obtain a parallel-treebank version of the TM data. The parallel treebank is then used to retrieve bilingual alignments for the TM data, rather than generate them on the fly during translation. This is an important design decision, as the complexity of the alignment algorithm is high for plain-text alignment (cf. Zhechev, 2010). Once we have generated the bilingual parallel treebank, we run the reordering tool, which generates a new plain-text file for the source language, where the sentences are modified to conform to the target-language word order, as implied by the data in the parallel treebank. This is then matched with the proper-order targetlanguage file to train the SMT backend for the actual use in the translation process. Figure 3. Translation Workflow Once all the necessary files have been generated and all pre-processing steps have been completed, the system is ready for use for translation. The translati</context>
</contexts>
<marker>Zhechev, 2010</marker>
<rawString>Zhechev, Ventsislav. 2010. Automatic Generation of Parallel Treebanks. An Efficient Unsupervised System: Lambert Academic Publishing.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>