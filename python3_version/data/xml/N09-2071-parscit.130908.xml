<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001555">
<title confidence="0.986784">
Tightly coupling Speech Recognition and Search
</title>
<author confidence="0.959286">
Taniya Mishra
</author>
<affiliation confidence="0.80759">
AT&amp;T Labs-Research
</affiliation>
<address confidence="0.9236315">
180 Park Ave
Florham Park, NJ 07932
</address>
<email confidence="0.997461">
taniya@research.att.com
</email>
<author confidence="0.450843">
Srinivas Bangalore
</author>
<affiliation confidence="0.396823">
AT&amp;T Labs-Research
</affiliation>
<address confidence="0.8382935">
180 Park Ave
Florham Park, NJ 07932
</address>
<email confidence="0.99913">
srini@research.att.com
</email>
<sectionHeader confidence="0.993912" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999354375">
In this paper, we discuss the benefits of tightly
coupling speech recognition and search com-
ponents in the context of a speech-driven
search application. We demonstrate that by in-
corporating constraints from the information
repository that is being searched not only im-
proves the speech recognition accuracy but
also results in higher search accuracy.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99997315">
With the exponential growth in the use of mobile de-
vices in recent years, the need for speech-driven in-
terfaces is becoming apparent. The limited screen
space and soft keyboards of mobile devices make it
cumbersome to type in text input. Furthermore, by
the mobile nature of these devices, users often would
like to use them in hands-busy environments, ruling
out the possibility of typing text.
In this paper, we focus on the problem of speech-
driven search to access information repositories us-
ing mobile devices. Such an application typically
uses a speech recognizer (ASR) for transforming the
user’s speech input to text and a search component
that uses the resulting text as a query to retrieve
the relevant documents from the information reposi-
tory. For the purposes of this paper, we use the busi-
ness listings containing the name, address and phone
number of businesses as the information repository.
Most of the literature on speech-driven search ap-
plications that are available in the consumer mar-
ket (Acero et al., 2008; Bacchiani et al., 2008;
VLingo FIND, 2009) have quite rightly emphasized
the importance of the robustness of the ASR lan-
guage model and the data needed to build such a ro-
bust language model. We acknowledge that this is a
significant issue for building such systems, and we
provide our approach to creating a language model.
However, in contrast to most of these systems that
treat speech-driven search to be largely an ASR
problem followed by a Search problem, in this pa-
per, we show the benefits of tightly coupling ASR
and Search tasks and illustrate techniques to im-
prove the accuracy of both components by exploit-
ing the co-constraints between the two components.
The outline of the paper is as follows. In Sec-
tion 2, we discuss the set up of our speech-driven
application. In Section 3, we discuss our method to
integrating the speech and search components. We
present the results of the experiments in Section 4
and conclude in Section 5.
</bodyText>
<sectionHeader confidence="0.996504" genericHeader="method">
2 Speech-driven Search
</sectionHeader>
<bodyText confidence="0.999580590909091">
We describe the speech-driven search application in
this section. The user of this application provides
a speech utterance to a mobile device intending to
search for the address and phone number of a busi-
ness. The speech utterance typically contains a busi-
ness name, optionally followed by a city and state
to indicate the location of the business (e.g. pizza
hut near urbana illinois.). User input with a busi-
ness category (laundromats in madison) and without
location information (hospitals) are some variants
supported by this application. The result of ASR is
used to search a business listing database of over 10
million entries to retrieve the entries pertinent to the
user query.
The ASR used to recognize these utterances in-
corporates an acoustic model adapted to speech col-
lected from mobile devices and a trigram language
model that is built from over 10 million text query
logs obtained from the web-based text-driven ver-
sion of this application. The 1-best speech recogni-
tion output is used to retrieve the relevant business
listing entries.
</bodyText>
<page confidence="0.969344">
281
</page>
<note confidence="0.5396565">
Proceedings of NAACL HLT 2009: Short Papers, pages 281–284,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.804629" genericHeader="method">
3 Tightly coupling ASR and Search
</sectionHeader>
<bodyText confidence="0.999966818181818">
As mentioned earlier, most of the speech-driven
search systems use the the 1-best output from the
ASR as the query for the search component. Given
that ASR 1-best output is likely to be erroneous,
this serialization of the ASR and search components
might result in sub-optimal search accuracy. As will
be shown in our experiments, the oracle word/phrase
accuracy using n-best hypotheses is far greater than
the 1-best output. However, using each of the n-
best hypothesis as a query to the search compo-
nent is computationally sub-optimal since the strings
in the n-best hypotheses usually share large subse-
quences with each other. A lattice representation
of the ASR output, in particular, a word-confusion
network (WCN) transformation of the lattice, com-
pactly encodes the n-best hypothesis with the flexi-
bility of pruning alternatives at each word position.
An example of a WCN is shown in Figure 1. In or-
der to obtain a measure of the ambiguity per word
position in the WCN, we define the (average) arc
density of a WCN as the ratio of the total number
of arcs to the number of states in the WCN. As can
be seen, with very small increase in arc density, the
number of paths that are encoded in the WCN can
be increased exponentially. In Figure 2, we show
the improvement in oracle-path word and phrase ac-
curacies as a function of the arc density for our data
set. Oracle-path is a path in the WCN that has the
least edit-distance (Levenshtein, 1966) to the refer-
ence string. It is interesting to note that the oracle
accuracies can be improved by almost 10% absolute
over the 1-best accuracy with small increase in the
arc density.
</bodyText>
<figure confidence="0.699824">
bally/3.625
</figure>
<figureCaption confidence="0.999184">
Figure 1: A sample word confusion network
</figureCaption>
<subsectionHeader confidence="0.997827">
3.1 Representing Search Index as an FST
</subsectionHeader>
<bodyText confidence="0.999475">
In order to exploit WCNs for Search, we have im-
plemented our own search engine instead of using an
</bodyText>
<figure confidence="0.54802">
Arc Densities
</figure>
<figureCaption confidence="0.9946955">
Figure 2: Oracle accuracy graph for the WCNs at differ-
ent arc densities
Figure 3: An example of an FST representing the search
index
</figureCaption>
<bodyText confidence="0.9996807">
off-the-shelf search engine such as Lucene (Hatcher
and Gospodnetic., 2004). We index each business
listing (d) in our data that we intend to search using
the words (wd) in that listing. The pair (wd, d) is
assigned a weight (c(wd,d)) using different metrics,
including the standard tf ∗ idf, as explained below.
This index is represented as a weighted finite-state
transducer (SearchFST) as shown in Figure 3 where
wd is the input symbol, d is the output symbol and
c(wd,d) is the weight of that arc.
</bodyText>
<subsectionHeader confidence="0.998326">
3.2 Relevance Metrics
</subsectionHeader>
<bodyText confidence="0.999787875">
In this section, we describe six different weighting
metrics used to determine the relevance of a docu-
ment for a given query word that we have experi-
mented with in this paper.
idfw: idfw refers to the inverse document fre-
quency of the word, w, which is computed as
ln(D/dw), where D refers to the total number
of documents in the collection, and dw refers to
the total number of documents in the collection
that contain the word, w (Robertson and Jones,
1997; Robertson, 2004).
atfw: atfw refers to average term frequency, which
is computed as cfw/dw (Pirkola et al., 2002).
cfw × idfw: Here cfw refers to the collection fre-
quency, which is simply the total number of oc-
currences of the word, w in the collection.
</bodyText>
<figure confidence="0.99894264516129">
automobiles/6.735
2/1
64
56
1 1.17 1.26 1.37 1.53 1.72 1.93
54
Word accuracy
Phrase accuracy
74
72
70
68
66
62
60
58
automobile:audi_automobile
automobile:automobile_sa
audi:audi_automobile_de
ballys:ballys_fitness
ballys:ballys_hotel/
audi:audi_repair/c
0
ballew/4.704
0 1
ellies/4.037
elliot/4.372
ballys/0.317
elliott/4.513
audi/2.126
Accuracy (in %)
</figure>
<page confidence="0.788017">
282
</page>
<bodyText confidence="0.777840125">
atfw × idfw: (Each term as described above).
Efw,d
|dw |× idfw: Here fw,d refers to the frequency of
the word, w, in the document, d, whereas |dw|
is the length of the document, d, in which the
word, w, occurs.
Ecfw
|dw |× idfw: (Each term as described above).
</bodyText>
<subsectionHeader confidence="0.997657">
3.3 Search
</subsectionHeader>
<bodyText confidence="0.999994130434783">
By composing a query (Qfst) (either a 1-best
string represented as a finite-state acceptor, or a
WCN), with the SearchFST, we obtain all the arcs
(wq,dwq,c(wq,dwq)) where wq is a query word, dwq
is a listing with the query word and, c(wq,dwq) is the
weight associated with that pair. Using this informa-
tion, we aggregate the weight for a listing (dq) across
all query words and rank the retrieved listings in the
descending order of this aggregated weight. We se-
lect the top N listings from this ranked list. The
query composition, listing weight aggregation and
selection of top N listings are computed with finite-
state transducer operations.
In Figure 4, we illustrate the result of reranking
the WCN shown in Figure 1 using the search rele-
vance weights of each word in the WCN. It must be
noted that the least cost path1 for the WCN in Fig-
ure 1 is ballys automobiles while the reranked 1-best
output in Figure 4 is audi automobiles. Given that
the user voice query was audi automobiles, the list-
ings retrieved from the 1-best output after reranking
are much more relevant than those retrieved before
reranking, as shown in Table 1.
</bodyText>
<figure confidence="0.704732">
audi/2.100
</figure>
<figureCaption confidence="0.997659">
Figure 4: A WCN rescored using word-level search rele-
vance weights.
</figureCaption>
<sectionHeader confidence="0.995955" genericHeader="evaluation">
4 Experiments and Results
</sectionHeader>
<bodyText confidence="0.9996505">
We took 852 speech queries collected from users us-
ing a mobile device based speech search application.
We ran the speech recognizer on these queries us-
ing the language model described in Section 2 and
created word-confusion networks such as those il-
lustrated in Figure 1. These 852 utterances were
divided into 300 utterances for the development set
and 552 for the test set.
</bodyText>
<footnote confidence="0.93756">
1We transform the scores into costs and search for minimum
cost paths.
</footnote>
<bodyText confidence="0.984250181818182">
Before rescoring After rescoring
ballys intl auburn audi repair
los angeles ca auburn wa
ballys las vegas audi bellevue repair
las vegas nv bellevue wa
ballys las health spa university audi seattle wa
las vegas nv
ballys cleaners beverly hills audi
palm desert ca los angeles ca
ballys brothers audi independent repairs
yorba linda ca by eurotech livermore ca
</bodyText>
<tableCaption confidence="0.987739333333333">
Table 1: Listings retrieved for query audi automobiles
before and after ASR WCNs were rescored using search
relevance weights.
</tableCaption>
<subsectionHeader confidence="0.994876">
4.1 ASR Experiments
</subsectionHeader>
<bodyText confidence="0.99513375">
The baseline ASR word and sentence (complete
string) accuracies on the development set are 63.1%
and 57.0% while those on the test set are 65.1% and
55.3% respectively.
</bodyText>
<table confidence="0.999687083333333">
Metric Word Sent. Scaling AD
Acc. Acc. Factor
idfw 63.1 57.0 10−3 all
cfw × idfw 63.5 58.3 15 ∗ 10−4 1.37
atfw 63.6 57.3 1 all
atfw × idf 63.1 57.0 10−3 all
fw,d × idf 63.9 58.3 15 ∗ 10−4 1.25
63.5 57.3 1 all
E dfw|
× 71J
idf
E  |dfw
</table>
<tableCaption confidence="0.979634">
Table 2: Performance of the metrics used for rescoring
the WCNs output by ASR. (AD refers to arc density.)
</tableCaption>
<bodyText confidence="0.999960133333333">
In Table 2, we summarize the improvements ob-
tained by rescoring the ASR WCNs based on the dif-
ferent metrics used for computing the word scores
according to the search criteria. The largest im-
provement in word and sentence accuracies is ob-
tained by using the rescoring metric: E fw,d |dfw |× idf.
The word-level accuracy improved from the baseline
accuracy of 63.1% to 63.9% after rescoring while
the sentence-level accuracy improved from 57.0%
to 58.3%. Thus, this rescoring metric, and the cor-
responding pruning AD and the scaling factor was
used to rerank the 552 WCNs in the test set. After
rescoring, on the test set, the word-level accuracy
improved from 65.1% to 65.9% and sentence-level
accuracy improved from 55.3% to 56.2%.
</bodyText>
<figure confidence="0.69289">
0 1
ballys/2.276
automobiles/0.251
2/4
</figure>
<page confidence="0.992518">
283
</page>
<table confidence="0.9987948">
Number of Scores Baseline Reranked
documents
All Precision 0.708 0.728
Documents Recall 0.728 0.742
F-Score 0.718 0.735
</table>
<tableCaption confidence="0.966499666666667">
Table 3: Table showing the relevancy of the search results
obtained by the baseline ASR output compared to those
obtained by the reranked ASR output.
</tableCaption>
<subsectionHeader confidence="0.995226">
4.2 Search Experiments
</subsectionHeader>
<bodyText confidence="0.999994032258065">
To analyze the Search accuracy of the baseline ASR
output in comparison to the ASR output, reranked
using the E f&amp;quot; ��w× idf reranking metric, we used
each of the two sets of ASR outputs (i.e., base-
line and reranked) as queries to our search engine,
SearchFST (described in Section 3). For the search
results produced by each set of queries, we com-
puted the precision, recall, and F-score values of the
listings retrieved with respect to the listings retrieved
by the set of human transcribed queries (Reference).
The precision, recall, and F-scores for the baseline
ASR output and the reranked ASR output, averaged
across each set, is presented in Table 3. For the pur-
poses of this experiment, we assume that the set re-
turned by our SearchFST for the human transcribed
set of queries is the reference search set. This is
however an approximation for a human annotated
search set.
In Table 3, by comparing the search accuracy
scores corresponding to the baseline ASR output to
those corresponding to the reranked ASR output, we
see that reranking the ASR output using the informa-
tion repository produces a substantial improvement
in the accuracy of the search results.
It is interesting to note that even though the
reranking of the ASR as shown in Table 2 is of the
order of 1%, the improvement in Search accuracy is
substantially higher. This indicates to the fact that
exploiting constraints from both components results
in improving the recognition accuracy of that subset
of words that are more relevant for Search.
</bodyText>
<sectionHeader confidence="0.999259" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99574635">
In this paper, we have presented techniques for
tightly coupling ASR and Search. The central idea
behind these techniques is to rerank the ASR out-
put using the constraints (encoded as relevance met-
rics) from the Search task. The relevance metric that
best improved accuracy is E �w,d
�w × idf,,,, as deter-
mined on our development set. Using this metric
to rerank the ASR output of our test set, we im-
proved ASR accuracy from 65.1% to 65.9% at the
word-level and from 55.3% to 56.2% at the phrase
level. This reranking also improved the F-score of
the search component from 0.718 to 0.735. These
results bear out our expectation that tightly coupling
ASR and Search can improve the accuracy of both
components.
Encouraged by the results of our experiments, we
plan to explore other relevance metrics that can en-
code more sophisticated constraints such as the rel-
ative coherence of the terms within a query.
</bodyText>
<sectionHeader confidence="0.998941" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.98794925">
The data used in this work is partly derived from the
Speak4It voice search prototype. We wish to thank
every member of that team for having deployed that
voice search system.
</bodyText>
<sectionHeader confidence="0.998102" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999763222222222">
A. Acero, N. Bernstein, R.Chambers, Y. Ju, X. Li,
J. Odell, O. Scholtz P. Nguyen, and G. Zweig. 2008.
Live search for mobile: Web services by voice on the
cellphone. In Proceedings of ICASSP 2008, Las Ve-
gas.
M. Bacchiani, F. Beaufays, J. Schalkwyk, M. Schuster,
and B. Strope. 2008. Deploying GOOG-411: Early
lesstons in data, measurement and testing. In Proceed-
ings of ICASSP 2008, Las Vegas.
E. Hatcher and O. Gospodnetic. 2004. Lucene in Action
(In Action series). Manning Publications Co., Green-
wich, CT, USA.
V.I. Levenshtein. 1966. Binary codes capable of correct-
ing deletions, insertion and reversals. Soviet Physics
Doklady, 10:707–710.
A. Pirkola, E. Lepa¨anen, and K. J¨arvelin. 2002. The
”ratf” formula (kwok’s formula): exploiting average
term frequency in cross-language retrieval. Informa-
tion Research, 7(2).
S. E. Robertson and K. Sparck Jones. 1997. Simple
proven approaches to text retrieval. Technical report,
Cambridge University.
Stephen Robertson. 2004. Understanding inverse doc-
ument frequency: On theoretical arguments for idf.
Journal of Documentation, 60.
VLingo FIND, 2009.
http://www.vlingomobile.com/downloads.html.
</reference>
<page confidence="0.998372">
284
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.652250">
<title confidence="0.992595">Tightly coupling Speech Recognition and Search</title>
<author confidence="0.935051">Taniya</author>
<affiliation confidence="0.993307">AT&amp;T</affiliation>
<address confidence="0.9719955">180 Park Florham Park, NJ</address>
<email confidence="0.999109">taniya@research.att.com</email>
<author confidence="0.795059">Srinivas</author>
<affiliation confidence="0.984101">AT&amp;T</affiliation>
<address confidence="0.966839">180 Park Florham Park, NJ</address>
<email confidence="0.999526">srini@research.att.com</email>
<abstract confidence="0.999497666666667">In this paper, we discuss the benefits of tightly coupling speech recognition and search components in the context of a speech-driven search application. We demonstrate that by incorporating constraints from the information repository that is being searched not only improves the speech recognition accuracy but also results in higher search accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Acero</author>
<author>N Bernstein</author>
<author>Y Ju R Chambers</author>
<author>X Li</author>
<author>J Odell</author>
<author>O Scholtz P Nguyen</author>
<author>G Zweig</author>
</authors>
<title>Live search for mobile: Web services by voice on the cellphone.</title>
<date>2008</date>
<booktitle>In Proceedings of ICASSP</booktitle>
<location>Las Vegas.</location>
<contexts>
<context position="1642" citStr="Acero et al., 2008" startWordPosition="254" endWordPosition="257">we focus on the problem of speechdriven search to access information repositories using mobile devices. Such an application typically uses a speech recognizer (ASR) for transforming the user’s speech input to text and a search component that uses the resulting text as a query to retrieve the relevant documents from the information repository. For the purposes of this paper, we use the business listings containing the name, address and phone number of businesses as the information repository. Most of the literature on speech-driven search applications that are available in the consumer market (Acero et al., 2008; Bacchiani et al., 2008; VLingo FIND, 2009) have quite rightly emphasized the importance of the robustness of the ASR language model and the data needed to build such a robust language model. We acknowledge that this is a significant issue for building such systems, and we provide our approach to creating a language model. However, in contrast to most of these systems that treat speech-driven search to be largely an ASR problem followed by a Search problem, in this paper, we show the benefits of tightly coupling ASR and Search tasks and illustrate techniques to improve the accuracy of both co</context>
</contexts>
<marker>Acero, Bernstein, Chambers, Li, Odell, Nguyen, Zweig, 2008</marker>
<rawString>A. Acero, N. Bernstein, R.Chambers, Y. Ju, X. Li, J. Odell, O. Scholtz P. Nguyen, and G. Zweig. 2008. Live search for mobile: Web services by voice on the cellphone. In Proceedings of ICASSP 2008, Las Vegas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bacchiani</author>
<author>F Beaufays</author>
<author>J Schalkwyk</author>
<author>M Schuster</author>
<author>B Strope</author>
</authors>
<title>Deploying GOOG-411: Early lesstons in data, measurement and testing.</title>
<date>2008</date>
<booktitle>In Proceedings of ICASSP</booktitle>
<location>Las Vegas.</location>
<contexts>
<context position="1666" citStr="Bacchiani et al., 2008" startWordPosition="258" endWordPosition="261">lem of speechdriven search to access information repositories using mobile devices. Such an application typically uses a speech recognizer (ASR) for transforming the user’s speech input to text and a search component that uses the resulting text as a query to retrieve the relevant documents from the information repository. For the purposes of this paper, we use the business listings containing the name, address and phone number of businesses as the information repository. Most of the literature on speech-driven search applications that are available in the consumer market (Acero et al., 2008; Bacchiani et al., 2008; VLingo FIND, 2009) have quite rightly emphasized the importance of the robustness of the ASR language model and the data needed to build such a robust language model. We acknowledge that this is a significant issue for building such systems, and we provide our approach to creating a language model. However, in contrast to most of these systems that treat speech-driven search to be largely an ASR problem followed by a Search problem, in this paper, we show the benefits of tightly coupling ASR and Search tasks and illustrate techniques to improve the accuracy of both components by exploiting t</context>
</contexts>
<marker>Bacchiani, Beaufays, Schalkwyk, Schuster, Strope, 2008</marker>
<rawString>M. Bacchiani, F. Beaufays, J. Schalkwyk, M. Schuster, and B. Strope. 2008. Deploying GOOG-411: Early lesstons in data, measurement and testing. In Proceedings of ICASSP 2008, Las Vegas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hatcher</author>
<author>O Gospodnetic</author>
</authors>
<title>Lucene in Action (In Action series).</title>
<date>2004</date>
<publisher>Manning Publications Co.,</publisher>
<location>Greenwich, CT, USA.</location>
<marker>Hatcher, Gospodnetic, 2004</marker>
<rawString>E. Hatcher and O. Gospodnetic. 2004. Lucene in Action (In Action series). Manning Publications Co., Greenwich, CT, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V I Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertion and reversals. Soviet Physics Doklady,</title>
<date>1966</date>
<pages>10--707</pages>
<contexts>
<context position="5293" citStr="Levenshtein, 1966" startWordPosition="873" endWordPosition="874">es at each word position. An example of a WCN is shown in Figure 1. In order to obtain a measure of the ambiguity per word position in the WCN, we define the (average) arc density of a WCN as the ratio of the total number of arcs to the number of states in the WCN. As can be seen, with very small increase in arc density, the number of paths that are encoded in the WCN can be increased exponentially. In Figure 2, we show the improvement in oracle-path word and phrase accuracies as a function of the arc density for our data set. Oracle-path is a path in the WCN that has the least edit-distance (Levenshtein, 1966) to the reference string. It is interesting to note that the oracle accuracies can be improved by almost 10% absolute over the 1-best accuracy with small increase in the arc density. bally/3.625 Figure 1: A sample word confusion network 3.1 Representing Search Index as an FST In order to exploit WCNs for Search, we have implemented our own search engine instead of using an Arc Densities Figure 2: Oracle accuracy graph for the WCNs at different arc densities Figure 3: An example of an FST representing the search index off-the-shelf search engine such as Lucene (Hatcher and Gospodnetic., 2004). </context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>V.I. Levenshtein. 1966. Binary codes capable of correcting deletions, insertion and reversals. Soviet Physics Doklady, 10:707–710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Pirkola</author>
<author>E Lepa¨anen</author>
<author>K J¨arvelin</author>
</authors>
<title>The ”ratf” formula (kwok’s formula): exploiting average term frequency in cross-language retrieval.</title>
<date>2002</date>
<journal>Information Research,</journal>
<volume>7</volume>
<issue>2</issue>
<marker>Pirkola, Lepa¨anen, J¨arvelin, 2002</marker>
<rawString>A. Pirkola, E. Lepa¨anen, and K. J¨arvelin. 2002. The ”ratf” formula (kwok’s formula): exploiting average term frequency in cross-language retrieval. Information Research, 7(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S E Robertson</author>
<author>K Sparck Jones</author>
</authors>
<title>Simple proven approaches to text retrieval.</title>
<date>1997</date>
<tech>Technical report,</tech>
<institution>Cambridge University.</institution>
<contexts>
<context position="6798" citStr="Robertson and Jones, 1997" startWordPosition="1135" endWordPosition="1138">te-state transducer (SearchFST) as shown in Figure 3 where wd is the input symbol, d is the output symbol and c(wd,d) is the weight of that arc. 3.2 Relevance Metrics In this section, we describe six different weighting metrics used to determine the relevance of a document for a given query word that we have experimented with in this paper. idfw: idfw refers to the inverse document frequency of the word, w, which is computed as ln(D/dw), where D refers to the total number of documents in the collection, and dw refers to the total number of documents in the collection that contain the word, w (Robertson and Jones, 1997; Robertson, 2004). atfw: atfw refers to average term frequency, which is computed as cfw/dw (Pirkola et al., 2002). cfw × idfw: Here cfw refers to the collection frequency, which is simply the total number of occurrences of the word, w in the collection. automobiles/6.735 2/1 64 56 1 1.17 1.26 1.37 1.53 1.72 1.93 54 Word accuracy Phrase accuracy 74 72 70 68 66 62 60 58 automobile:audi_automobile automobile:automobile_sa audi:audi_automobile_de ballys:ballys_fitness ballys:ballys_hotel/ audi:audi_repair/c 0 ballew/4.704 0 1 ellies/4.037 elliot/4.372 ballys/0.317 elliott/4.513 audi/2.126 Accura</context>
</contexts>
<marker>Robertson, Jones, 1997</marker>
<rawString>S. E. Robertson and K. Sparck Jones. 1997. Simple proven approaches to text retrieval. Technical report, Cambridge University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Robertson</author>
</authors>
<title>Understanding inverse document frequency: On theoretical arguments for idf.</title>
<date>2004</date>
<journal>Journal of Documentation,</journal>
<volume>60</volume>
<contexts>
<context position="6816" citStr="Robertson, 2004" startWordPosition="1139" endWordPosition="1140">FST) as shown in Figure 3 where wd is the input symbol, d is the output symbol and c(wd,d) is the weight of that arc. 3.2 Relevance Metrics In this section, we describe six different weighting metrics used to determine the relevance of a document for a given query word that we have experimented with in this paper. idfw: idfw refers to the inverse document frequency of the word, w, which is computed as ln(D/dw), where D refers to the total number of documents in the collection, and dw refers to the total number of documents in the collection that contain the word, w (Robertson and Jones, 1997; Robertson, 2004). atfw: atfw refers to average term frequency, which is computed as cfw/dw (Pirkola et al., 2002). cfw × idfw: Here cfw refers to the collection frequency, which is simply the total number of occurrences of the word, w in the collection. automobiles/6.735 2/1 64 56 1 1.17 1.26 1.37 1.53 1.72 1.93 54 Word accuracy Phrase accuracy 74 72 70 68 66 62 60 58 automobile:audi_automobile automobile:automobile_sa audi:audi_automobile_de ballys:ballys_fitness ballys:ballys_hotel/ audi:audi_repair/c 0 ballew/4.704 0 1 ellies/4.037 elliot/4.372 ballys/0.317 elliott/4.513 audi/2.126 Accuracy (in %) 282 atfw</context>
</contexts>
<marker>Robertson, 2004</marker>
<rawString>Stephen Robertson. 2004. Understanding inverse document frequency: On theoretical arguments for idf. Journal of Documentation, 60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>VLingo FIND</author>
</authors>
<date>2009</date>
<note>http://www.vlingomobile.com/downloads.html.</note>
<contexts>
<context position="1686" citStr="FIND, 2009" startWordPosition="263" endWordPosition="264">ccess information repositories using mobile devices. Such an application typically uses a speech recognizer (ASR) for transforming the user’s speech input to text and a search component that uses the resulting text as a query to retrieve the relevant documents from the information repository. For the purposes of this paper, we use the business listings containing the name, address and phone number of businesses as the information repository. Most of the literature on speech-driven search applications that are available in the consumer market (Acero et al., 2008; Bacchiani et al., 2008; VLingo FIND, 2009) have quite rightly emphasized the importance of the robustness of the ASR language model and the data needed to build such a robust language model. We acknowledge that this is a significant issue for building such systems, and we provide our approach to creating a language model. However, in contrast to most of these systems that treat speech-driven search to be largely an ASR problem followed by a Search problem, in this paper, we show the benefits of tightly coupling ASR and Search tasks and illustrate techniques to improve the accuracy of both components by exploiting the co-constraints be</context>
</contexts>
<marker>FIND, 2009</marker>
<rawString>VLingo FIND, 2009. http://www.vlingomobile.com/downloads.html.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>