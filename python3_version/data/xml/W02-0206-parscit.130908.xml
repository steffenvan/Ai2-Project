<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.360640">
<note confidence="0.9942395">
Proceedings of the Third SIGdial Workshop on Discourse and Dialogue,
Philadelphia, July 2002, pp. 42-45. Association for Computational Linguistics.
</note>
<title confidence="0.9980815">
An Experiment to Evaluate the Effectiveness of Cross-Media Cues in
Computer Media
</title>
<author confidence="0.992738">
Nancy Green
</author>
<affiliation confidence="0.971988666666667">
Department of Mathematical Sciences
383 Bryan Building
University of North Carolina Greensboro
</affiliation>
<address confidence="0.687326">
Greensboro, NC 27402
</address>
<email confidence="0.997696">
nlgreen@uncg.edu
</email>
<sectionHeader confidence="0.995619" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998295">
We present the motivation for and
design of an experiment to evaluate
the usefulness of cross-media cues,
phrases such as &apos;See Figure 1&apos;.
</bodyText>
<sectionHeader confidence="0.998778" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999836588235294">
Authors of English-language print documents
containing both text and graphics traditionally
have used phrases such as &apos;See Figure 1&apos;.
Intuitively, these cross-media cues (CMCs)
help the print reader to integrate information
presented in different media, i.e., printed text
and printed graphics. We are investigating
how, if at all, these cues should be used in
presentations delivered in computer media
such as web pages. Our long-term goal is to
develop a non-application-specific
computational model for the decision of when
to direct the reader&apos;s attention to related
graphics, what kinds of things to say about
them, and where to place the cross-media cues
in the text.
For exploratory purposes, we previously
performed an informal corpus study of the use
of cross-media cues in arguments (Green
2001). However, we contend that print-media-
based corpus studies may not provide sound
information on which to base a model for on-
screen presentations. Human-computer
interaction (HCI) studies have shown that there
are significant differences between reading
from print and computer media, e.g., that
reading from screen is slower and
comprehension is worse (Dillon, 1992; Muter,
1996). Thus, as an alternative to corpus
analysis we have begun controlled user studies
employing &amp;quot;throwaway&amp;quot; prototypes. In this
paper, we present the design and preliminary
results of an experiment on effective cross-
media cue usage in computer media.
</bodyText>
<sectionHeader confidence="0.999933" genericHeader="related work">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.997936">
2.1 Computational linguistics
</subsectionHeader>
<bodyText confidence="0.9997665">
Cross-media cues are similar in some respects
to discourse cue phrases. First, some functions
of cross-media cues can be classified using
discourse coherence relations such as
Preparation, Restatement, Summary,
Evaluation, and Elaboration (Green, 2001).
Second, there is not a one-to-one
correspondence between form and function.
For example, the same CMC can be used to
indicate different coherence relations between
a span of text and the named figure, e.g.,
Restatement and Evaluation. On the other
hand, a relation of Summary can be indicated,
for example, by &apos;From Fig. 9.5, you can see
that&apos; or &apos;(see Figure 4)&apos;. Another similarity is
that CMCs are not always provided to mark
explicitly the relationship obtaining between
text and graphic. Research on discourse cue
placement has framed our thinking on asking
when and where to generate CMCs
(DiEugenio, Moore and Paolucci, 1997).
A multimedia presentation may include
multimodal referring expressions, references to
things in the world made through a
combination of text and graphics (McKeown et
al., 1992; André and Rist, 1994). Such cross-
references are similar to cross-media cues in
that they direct the user&apos;s attention to a related
graphic. However, their function is different,
namely, to enable the user to perform reference
resolution. Another form of cross-reference,
discourse deixis is the use of an expression that
refers to part of the document containing it,
e.g., &apos;the next chapter&apos; (Paraboni and van
Deemter, 1999). Although a user&apos;s
interpretation of a cross-media cue may
depend on discourse deixis to determine the
graphic in question, the problem of selecting
an appropriate description to refer to a graphic
(e.g. &apos;Figure 4&apos; versus &apos;the Figure below&apos;) is
not a concern of our work at present.
In our previous corpus study of multimedia
arguments, we classified text in a document as
either argument-bearing or commentary-
bearing, where the latter is text about a graphic
included in the document (Green 2001). The
topics of commentary-bearing text include the
graphic&apos;s role in the argument (e.g. &apos;From Fig.
9.5, you can see that&apos;), the interpretation of
graphical elements in terms of the underlying
domain and data, and salient visual features of
the graphic. Furthermore, we noted that
commentary-bearing and argument-bearing
text may be interleaved, and that the ratio of
the number of sentences of commentary to
their related CMC may be many to one.
Previous work in caption generation is
relevant to the question of what kinds of things
to say about accompanying graphics (Mittal et
al., 1998; Fasciano and Lapalme, 1999).
However, neither of those systems face the
problem of integrating commentary-bearing
text with text generated to achieve other
presentation goals.
</bodyText>
<subsectionHeader confidence="0.965601">
2.2 Human-Computer Interaction
</subsectionHeader>
<bodyText confidence="0.9999658">
HCI research has focused on interaction
techniques and features of layout that influence
effectiveness. Use of contact points, control
buttons in text on a web page that enable
readers to control related animations (Faraday
and Sutcliffe, 1999), is an interaction
technique that, like CMCs, explicitly marks the
relationship between information presented in
two media. That paper provides experimental
evidence that contact points improve
comprehension of integrated text and
animation.
According to Moreno and Mayer&apos;s Spatial
Contiguity Principle (2000), learning in
multimedia presentations is improved when
related text and graphics are spatially
contiguous rather than separated. However,
this does not imply that instead of providing
CMCs a generator can rely on layout alone, for
the following reasons. First, a generator may
have responsibility for producing text but not
have control over layout, e.g. when a
document is displayed by a web browser.
Second, a graphic may be relevant to multiple
non-contiguous spans of text in a document.
</bodyText>
<sectionHeader confidence="0.999824" genericHeader="method">
3 Experiment
</sectionHeader>
<subsectionHeader confidence="0.997704">
3.1 Overview
</subsectionHeader>
<bodyText confidence="0.999964547169812">
As a first step, we must address a basic
question: is it ever worthwhile to generate
cross-media cues in computer presentations?
Thus we designed a between-groups
experiment (Lewis &amp; Rieman, 1994) to test
whether performance on tasks requiring a
subject to skim for information presented in
text and graphics via a web browser would
benefit from the inclusion of cross-media cues
in the text. Skimming, defined as &amp;quot;moving
rapidly through text to locate specific
information or gain the gist&amp;quot;, is a type of
reading strategy often used by readers of web
pages (Dyson and Haselgrove 2001).
Each of the three groups of subjects
receives a different version of a presentation
consisting of four articles. Each article fills a
19 inch computer screen and consists of a short
text followed by several figures with
information graphics such as line graphs and
bar charts. The graphics are arranged in a row
near the bottom of the screen so that the cost to
the user of looking up and down between text
and graphics is the same for each figure.
Multiple figures are provided so that the reader
is required to determine which figure is
relevant to the task.
In version 1, the layout of each article
consists of text containing no cross-media cues
followed by the figures. A short caption is
given under each graphic. In version 2, the
caption text has been removed from the figures
and integrated into the paragraph of text above
the figures, i.e., it now functions as
commentary text. Version 3 is identical to
version 2 except that for each figure a cross-
media cue of the form &apos;See Figure n.&apos; has been
inserted in the text; the CMC is inserted
following the commentary created from the
corresponding caption in Version 1.
Version 1 represents the case where it is
feasible to design the layout so that text
commenting upon a figure can be placed in
proximity to the figure (i.e. maximizing
adherence to the Spatial Contiguity Principle).
We assume that task performance will be best
for version 1 and include it in the experiment
to provide a baseline. The main point of the
experiment, however, is to compare
performance on version 2 with performance on
version 3. Then, if performance on version 3
is better, we have shown that CMCs can be
useful to readers performing a similar task.
</bodyText>
<subsectionHeader confidence="0.994338">
3.2 Experimental Design
</subsectionHeader>
<bodyText confidence="0.999897125">
The independent variable is the version of the
article that is presented. The three versions are
constructed by varying layout and presence of
cross media cue phrases as described above.
The dependent variables are the time to
complete the tests (Time) and score on the tests
(Score). Time and Score are compared
between groups.
</bodyText>
<subsectionHeader confidence="0.987951">
3.3 Participants
</subsectionHeader>
<bodyText confidence="0.999998285714286">
The participants (subjects) are undergraduate
college students. The participants are randomly
assigned to one of three groups. Each group is
tested on a different version of the same
articles. Information about college major and
experience using computers is collected via a
short questionnaire before the experiment.
</bodyText>
<subsectionHeader confidence="0.806698">
3.4 Materials
</subsectionHeader>
<bodyText confidence="0.999993555555556">
Each article was constructed by the
experimenter by selecting an excerpt from a
published source; the sources of the four
articles represent different genre, topics,
layouts, and audiences. (We chose to use
excerpts rather than authoring our own articles
to avoid experimenter bias.) The excerpts are
approximately the same word-length and,
except for the first article, which is used for
practice and only includes two figures, each
excerpt includes three figures. The layout was
modified by the experimenter to create
versions 1 through 3. Other differences in
presentation (e.g., line length, color scheme,
font style, and font size) between different
versions of the same article and between
articles were minimized as much as possible.
The multiple choice test for each article
consists of one question asking the subject to
identify one of the main points of the
presentation, and three questions asking the
subject to identify where in the presentation
certain facts were given. For the identification
questions the subject is asked to select one or
more of the following choices: in the text, in
the graph in Figure 1, in the graph in Figure 2,
in the graph in Figure 3, or none of the above.
</bodyText>
<subsectionHeader confidence="0.967699">
3.5 Procedure
</subsectionHeader>
<bodyText confidence="0.99998444">
Each participant is given a series of four tests
displayed on a desktop PC with a 19 inch color
monitor. The first test is used as a practice test
and data collected from it will not be used. The
test series is implemented by a computer
program written in HTML and Javascript that
is run by a web browser. Scrolling is disabled
throughout the test series. The first screen of
each test presents an article; the next screen
contains the four test questions described
above. The participant is free to move back
and forth between the article and the test
question screen for it by using
Forward/Backward buttons, but cannot see the
article and test question screens at the same
time. The participant cannot go back to
previous tests, and is not allowed to go on to
the next test until he or she has answered all
questions on the current test and has confirmed
that he or she is ready to go on to the next test.
The participant answers the test questions
using the computer mouse. The program
records the participant&apos;s answers and times
automatically. Subjects are not told that their
task time is being measured.
</bodyText>
<subsectionHeader confidence="0.998832">
3.6 Status of Work
</subsectionHeader>
<bodyText confidence="0.99997">
We have finished running the pilot version of
the experiment and are currently running the
main experiment. It is interesting that in the
post-experiment questionnaire, some subjects
who have received version 2 have commented
that references to the figures (i.e. CMCs)
would have been helpful.
</bodyText>
<sectionHeader confidence="0.999852" genericHeader="discussions">
4 Discussion
</sectionHeader>
<bodyText confidence="0.9999624">
We have presented the motivation for and
design of an experiment to evaluate the
usefulness of cross-media cues in multimedia
presentations shown on computer screens. In
future work, we plan to investigate questions
of cross-media cue placement, e.g., whether to
insert a CMC before or after commentary
about the named figure. An interesting
question is whether CMC placement should be
influenced by discourse structure.
</bodyText>
<sectionHeader confidence="0.994556" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999796">
We thank Jennifer Brooks of the University of
North Carolina at Greensboro for her
implementation of much of the Javascript
programs used in the experiment and for
running an initial group of subjects through it.
</bodyText>
<sectionHeader confidence="0.993893" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.975950460317461">
E. André and T. Rist. 1994.. Referring to
World Objects with Text and Pictures.
COLING-94, 530-534.
A. Dillon. 1992. Reading from paper versus
screens: a critical review of the empirical
literature. Ergonomics, 35, 1297-1326.
M.C. Dyson and M. Haselgrove. 2001. The
influence of reading speed and line length on
the effectiveness of reading from screen.
International Journal of Human-Computer
Studies, 54, 585-612.
Barbara Di Eugenio, Johanna D. Moore,
Massimo Paolucci. 1997. Learning Features
that Predict Cue Usage, Proceedings 35th
Annual Meeting of the Association for
Computational Linguistics.
P. Faraday and A. Sutcliffe. 1999. Authoring
Animated Web Pages Using &apos;Contact Points&apos;,
in Proceedings of CHI &apos;99, 458-465.
M. Fasciano and G. Lapalme. 1999.
Intentions in the coordinated generation of
graphics and text from tabular data.
Knowledge and Information Systems, Oct
1999.
N. Green. 2001. An Empirical Study of
Multimedia Argumentation. Proceedings of
the International Conference on
Computational Systems, Workshop on
Computational Models of Natural Language
Arguments, May 2001. Springer Lecture Notes
in Computer Science 2073, pp. 1009-18.
Lewis &amp; Rieman. 1994. Lewis, C. and
Rieman, R. Task-Centered User Interface
Design: A Practical Introduction.
[ftp://ftp.cs.colorado.edu]
K. R. McKeown, S. K. Feiner, J. Robin, D.D.
Seligmann, and M. Tanenblatt. 1992.
Generating Cross-References for Multimedia
Explanation. Proceedings of AAAI, 9-16.
V. Mittal, J. Moore, G. Carenini, and S.
Roth. 1998. Describing Complex Charts in
Natural Language: A Caption Generation
System. Computational. Linguistics, Vol.
24, issue 3, (1998), 431-467.
R. Moreno and R. Mayer. 2000. A Learner-
Centered Approach to Multimedia
Explanations: Deriving Instructional Design
Principles from Cognitive Theory, Interactive
Multimedia Electronic Journal of Computer-
Enhanced Learning.
P. Muter. 1996. Interface design and
optimization of reading of continuous text. In
H. Van Oostendorp and S. DeMul (eds.)
Cognitive Aspects of Electronic Text
Processing, pp. 161-180.
I. Paraboni and K. van Deemter. 1999. Issues
for the Generation of Document Deixis. In
André et al. (Eds.), Deixis, Demonstration
and Deictic Belief in Multimedia Contexts,
Proceedings of the Workshop associated with
the 11th European Summer School in Logic,
Language and Information (ESSLLI),
Utrecht, The Netherlands, 1999, pp. 43-48.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.046774">
<note confidence="0.384337666666667">Proceedings of the Third SIGdial Workshop on Discourse and Dialogue, Philadelphia, July 2002, pp. 42-45. Association for Computational Linguistics. An Experiment to Evaluate the Effectiveness of Cross-Media Cues in</note>
<affiliation confidence="0.830851">Computer Media Nancy Department of Mathematical</affiliation>
<address confidence="0.943436">383 Bryan</address>
<affiliation confidence="0.9534">University of North Carolina</affiliation>
<address confidence="0.926466">Greensboro, NC 27402</address>
<email confidence="0.999495">nlgreen@uncg.edu</email>
<abstract confidence="0.998654">We present the motivation for and design of an experiment to evaluate the usefulness of cross-media cues,</abstract>
<intro confidence="0.459085">such as Figure</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E André</author>
<author>T Rist</author>
</authors>
<title>Referring to World Objects with Text and Pictures.</title>
<date>1994</date>
<volume>94</volume>
<pages>530--534</pages>
<contexts>
<context position="3100" citStr="André and Rist, 1994" startWordPosition="462" endWordPosition="465">atement and Evaluation. On the other hand, a relation of Summary can be indicated, for example, by &apos;From Fig. 9.5, you can see that&apos; or &apos;(see Figure 4)&apos;. Another similarity is that CMCs are not always provided to mark explicitly the relationship obtaining between text and graphic. Research on discourse cue placement has framed our thinking on asking when and where to generate CMCs (DiEugenio, Moore and Paolucci, 1997). A multimedia presentation may include multimodal referring expressions, references to things in the world made through a combination of text and graphics (McKeown et al., 1992; André and Rist, 1994). Such crossreferences are similar to cross-media cues in that they direct the user&apos;s attention to a related graphic. However, their function is different, namely, to enable the user to perform reference resolution. Another form of cross-reference, discourse deixis is the use of an expression that refers to part of the document containing it, e.g., &apos;the next chapter&apos; (Paraboni and van Deemter, 1999). Although a user&apos;s interpretation of a cross-media cue may depend on discourse deixis to determine the graphic in question, the problem of selecting an appropriate description to refer to a graphic</context>
</contexts>
<marker>André, Rist, 1994</marker>
<rawString>E. André and T. Rist. 1994.. Referring to World Objects with Text and Pictures. COLING-94, 530-534.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Dillon</author>
</authors>
<title>Reading from paper versus screens: a critical review of the empirical literature.</title>
<date>1992</date>
<journal>Ergonomics,</journal>
<volume>35</volume>
<pages>1297--1326</pages>
<contexts>
<context position="1707" citStr="Dillon, 1992" startWordPosition="251" endWordPosition="252">n to related graphics, what kinds of things to say about them, and where to place the cross-media cues in the text. For exploratory purposes, we previously performed an informal corpus study of the use of cross-media cues in arguments (Green 2001). However, we contend that print-mediabased corpus studies may not provide sound information on which to base a model for onscreen presentations. Human-computer interaction (HCI) studies have shown that there are significant differences between reading from print and computer media, e.g., that reading from screen is slower and comprehension is worse (Dillon, 1992; Muter, 1996). Thus, as an alternative to corpus analysis we have begun controlled user studies employing &amp;quot;throwaway&amp;quot; prototypes. In this paper, we present the design and preliminary results of an experiment on effective crossmedia cue usage in computer media. 2 Related Work 2.1 Computational linguistics Cross-media cues are similar in some respects to discourse cue phrases. First, some functions of cross-media cues can be classified using discourse coherence relations such as Preparation, Restatement, Summary, Evaluation, and Elaboration (Green, 2001). Second, there is not a one-to-one corre</context>
</contexts>
<marker>Dillon, 1992</marker>
<rawString>A. Dillon. 1992. Reading from paper versus screens: a critical review of the empirical literature. Ergonomics, 35, 1297-1326.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M C Dyson</author>
<author>M Haselgrove</author>
</authors>
<title>The influence of reading speed and line length on the effectiveness of reading from screen.</title>
<date>2001</date>
<journal>International Journal of Human-Computer Studies,</journal>
<volume>54</volume>
<pages>585--612</pages>
<contexts>
<context position="6457" citStr="Dyson and Haselgrove 2001" startWordPosition="984" endWordPosition="987">in a document. 3 Experiment 3.1 Overview As a first step, we must address a basic question: is it ever worthwhile to generate cross-media cues in computer presentations? Thus we designed a between-groups experiment (Lewis &amp; Rieman, 1994) to test whether performance on tasks requiring a subject to skim for information presented in text and graphics via a web browser would benefit from the inclusion of cross-media cues in the text. Skimming, defined as &amp;quot;moving rapidly through text to locate specific information or gain the gist&amp;quot;, is a type of reading strategy often used by readers of web pages (Dyson and Haselgrove 2001). Each of the three groups of subjects receives a different version of a presentation consisting of four articles. Each article fills a 19 inch computer screen and consists of a short text followed by several figures with information graphics such as line graphs and bar charts. The graphics are arranged in a row near the bottom of the screen so that the cost to the user of looking up and down between text and graphics is the same for each figure. Multiple figures are provided so that the reader is required to determine which figure is relevant to the task. In version 1, the layout of each arti</context>
</contexts>
<marker>Dyson, Haselgrove, 2001</marker>
<rawString>M.C. Dyson and M. Haselgrove. 2001. The influence of reading speed and line length on the effectiveness of reading from screen. International Journal of Human-Computer Studies, 54, 585-612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Di Eugenio</author>
<author>Johanna D Moore</author>
<author>Massimo Paolucci</author>
</authors>
<title>Learning Features that Predict Cue Usage,</title>
<date>1997</date>
<booktitle>Proceedings 35th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<marker>Di Eugenio, Moore, Paolucci, 1997</marker>
<rawString>Barbara Di Eugenio, Johanna D. Moore, Massimo Paolucci. 1997. Learning Features that Predict Cue Usage, Proceedings 35th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Faraday</author>
<author>A Sutcliffe</author>
</authors>
<title>Authoring Animated Web Pages Using &apos;Contact Points&apos;,</title>
<date>1999</date>
<booktitle>in Proceedings of CHI &apos;99,</booktitle>
<pages>458--465</pages>
<contexts>
<context position="5043" citStr="Faraday and Sutcliffe, 1999" startWordPosition="765" endWordPosition="768">related CMC may be many to one. Previous work in caption generation is relevant to the question of what kinds of things to say about accompanying graphics (Mittal et al., 1998; Fasciano and Lapalme, 1999). However, neither of those systems face the problem of integrating commentary-bearing text with text generated to achieve other presentation goals. 2.2 Human-Computer Interaction HCI research has focused on interaction techniques and features of layout that influence effectiveness. Use of contact points, control buttons in text on a web page that enable readers to control related animations (Faraday and Sutcliffe, 1999), is an interaction technique that, like CMCs, explicitly marks the relationship between information presented in two media. That paper provides experimental evidence that contact points improve comprehension of integrated text and animation. According to Moreno and Mayer&apos;s Spatial Contiguity Principle (2000), learning in multimedia presentations is improved when related text and graphics are spatially contiguous rather than separated. However, this does not imply that instead of providing CMCs a generator can rely on layout alone, for the following reasons. First, a generator may have respons</context>
</contexts>
<marker>Faraday, Sutcliffe, 1999</marker>
<rawString>P. Faraday and A. Sutcliffe. 1999. Authoring Animated Web Pages Using &apos;Contact Points&apos;, in Proceedings of CHI &apos;99, 458-465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Fasciano</author>
<author>G Lapalme</author>
</authors>
<title>Intentions in the coordinated generation of graphics and text from tabular data. Knowledge and Information Systems,</title>
<date>1999</date>
<contexts>
<context position="4619" citStr="Fasciano and Lapalme, 1999" startWordPosition="705" endWordPosition="708">en 2001). The topics of commentary-bearing text include the graphic&apos;s role in the argument (e.g. &apos;From Fig. 9.5, you can see that&apos;), the interpretation of graphical elements in terms of the underlying domain and data, and salient visual features of the graphic. Furthermore, we noted that commentary-bearing and argument-bearing text may be interleaved, and that the ratio of the number of sentences of commentary to their related CMC may be many to one. Previous work in caption generation is relevant to the question of what kinds of things to say about accompanying graphics (Mittal et al., 1998; Fasciano and Lapalme, 1999). However, neither of those systems face the problem of integrating commentary-bearing text with text generated to achieve other presentation goals. 2.2 Human-Computer Interaction HCI research has focused on interaction techniques and features of layout that influence effectiveness. Use of contact points, control buttons in text on a web page that enable readers to control related animations (Faraday and Sutcliffe, 1999), is an interaction technique that, like CMCs, explicitly marks the relationship between information presented in two media. That paper provides experimental evidence that cont</context>
</contexts>
<marker>Fasciano, Lapalme, 1999</marker>
<rawString>M. Fasciano and G. Lapalme. 1999. Intentions in the coordinated generation of graphics and text from tabular data. Knowledge and Information Systems, Oct 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Green</author>
</authors>
<title>An Empirical Study of Multimedia Argumentation.</title>
<date>2001</date>
<journal>Lecture Notes in Computer Science</journal>
<booktitle>Proceedings of the International Conference on Computational Systems, Workshop on Computational Models of Natural Language Arguments,</booktitle>
<pages>1009--18</pages>
<publisher>Springer</publisher>
<contexts>
<context position="1342" citStr="Green 2001" startWordPosition="197" endWordPosition="198">ader to integrate information presented in different media, i.e., printed text and printed graphics. We are investigating how, if at all, these cues should be used in presentations delivered in computer media such as web pages. Our long-term goal is to develop a non-application-specific computational model for the decision of when to direct the reader&apos;s attention to related graphics, what kinds of things to say about them, and where to place the cross-media cues in the text. For exploratory purposes, we previously performed an informal corpus study of the use of cross-media cues in arguments (Green 2001). However, we contend that print-mediabased corpus studies may not provide sound information on which to base a model for onscreen presentations. Human-computer interaction (HCI) studies have shown that there are significant differences between reading from print and computer media, e.g., that reading from screen is slower and comprehension is worse (Dillon, 1992; Muter, 1996). Thus, as an alternative to corpus analysis we have begun controlled user studies employing &amp;quot;throwaway&amp;quot; prototypes. In this paper, we present the design and preliminary results of an experiment on effective crossmedia cu</context>
<context position="4000" citStr="Green 2001" startWordPosition="608" endWordPosition="609">sion that refers to part of the document containing it, e.g., &apos;the next chapter&apos; (Paraboni and van Deemter, 1999). Although a user&apos;s interpretation of a cross-media cue may depend on discourse deixis to determine the graphic in question, the problem of selecting an appropriate description to refer to a graphic (e.g. &apos;Figure 4&apos; versus &apos;the Figure below&apos;) is not a concern of our work at present. In our previous corpus study of multimedia arguments, we classified text in a document as either argument-bearing or commentarybearing, where the latter is text about a graphic included in the document (Green 2001). The topics of commentary-bearing text include the graphic&apos;s role in the argument (e.g. &apos;From Fig. 9.5, you can see that&apos;), the interpretation of graphical elements in terms of the underlying domain and data, and salient visual features of the graphic. Furthermore, we noted that commentary-bearing and argument-bearing text may be interleaved, and that the ratio of the number of sentences of commentary to their related CMC may be many to one. Previous work in caption generation is relevant to the question of what kinds of things to say about accompanying graphics (Mittal et al., 1998; Fasciano</context>
</contexts>
<marker>Green, 2001</marker>
<rawString>N. Green. 2001. An Empirical Study of Multimedia Argumentation. Proceedings of the International Conference on Computational Systems, Workshop on Computational Models of Natural Language Arguments, May 2001. Springer Lecture Notes in Computer Science 2073, pp. 1009-18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lewis</author>
<author>Rieman</author>
</authors>
<title>Task-Centered User Interface Design: A Practical Introduction. [ftp://ftp.cs.colorado.edu]</title>
<date>1994</date>
<booktitle>Proceedings of AAAI,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="6068" citStr="Lewis &amp; Rieman, 1994" startWordPosition="919" endWordPosition="922">y contiguous rather than separated. However, this does not imply that instead of providing CMCs a generator can rely on layout alone, for the following reasons. First, a generator may have responsibility for producing text but not have control over layout, e.g. when a document is displayed by a web browser. Second, a graphic may be relevant to multiple non-contiguous spans of text in a document. 3 Experiment 3.1 Overview As a first step, we must address a basic question: is it ever worthwhile to generate cross-media cues in computer presentations? Thus we designed a between-groups experiment (Lewis &amp; Rieman, 1994) to test whether performance on tasks requiring a subject to skim for information presented in text and graphics via a web browser would benefit from the inclusion of cross-media cues in the text. Skimming, defined as &amp;quot;moving rapidly through text to locate specific information or gain the gist&amp;quot;, is a type of reading strategy often used by readers of web pages (Dyson and Haselgrove 2001). Each of the three groups of subjects receives a different version of a presentation consisting of four articles. Each article fills a 19 inch computer screen and consists of a short text followed by several fi</context>
</contexts>
<marker>Lewis, Rieman, 1994</marker>
<rawString>Lewis &amp; Rieman. 1994. Lewis, C. and Rieman, R. Task-Centered User Interface Design: A Practical Introduction. [ftp://ftp.cs.colorado.edu] K. R. McKeown, S. K. Feiner, J. Robin, D.D. Seligmann, and M. Tanenblatt. 1992. Generating Cross-References for Multimedia Explanation. Proceedings of AAAI, 9-16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Mittal</author>
<author>J Moore</author>
<author>G Carenini</author>
<author>S Roth</author>
</authors>
<title>Describing Complex Charts in Natural Language: A Caption Generation System.</title>
<date>1998</date>
<journal>Computational. Linguistics,</journal>
<volume>24</volume>
<pages>431--467</pages>
<contexts>
<context position="4590" citStr="Mittal et al., 1998" startWordPosition="701" endWordPosition="704"> in the document (Green 2001). The topics of commentary-bearing text include the graphic&apos;s role in the argument (e.g. &apos;From Fig. 9.5, you can see that&apos;), the interpretation of graphical elements in terms of the underlying domain and data, and salient visual features of the graphic. Furthermore, we noted that commentary-bearing and argument-bearing text may be interleaved, and that the ratio of the number of sentences of commentary to their related CMC may be many to one. Previous work in caption generation is relevant to the question of what kinds of things to say about accompanying graphics (Mittal et al., 1998; Fasciano and Lapalme, 1999). However, neither of those systems face the problem of integrating commentary-bearing text with text generated to achieve other presentation goals. 2.2 Human-Computer Interaction HCI research has focused on interaction techniques and features of layout that influence effectiveness. Use of contact points, control buttons in text on a web page that enable readers to control related animations (Faraday and Sutcliffe, 1999), is an interaction technique that, like CMCs, explicitly marks the relationship between information presented in two media. That paper provides ex</context>
</contexts>
<marker>Mittal, Moore, Carenini, Roth, 1998</marker>
<rawString>V. Mittal, J. Moore, G. Carenini, and S. Roth. 1998. Describing Complex Charts in Natural Language: A Caption Generation System. Computational. Linguistics, Vol. 24, issue 3, (1998), 431-467.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Moreno</author>
<author>R Mayer</author>
</authors>
<title>A LearnerCentered Approach to Multimedia Explanations: Deriving Instructional Design Principles from Cognitive Theory, Interactive Multimedia Electronic</title>
<date>2000</date>
<journal>Journal of ComputerEnhanced Learning.</journal>
<marker>Moreno, Mayer, 2000</marker>
<rawString>R. Moreno and R. Mayer. 2000. A LearnerCentered Approach to Multimedia Explanations: Deriving Instructional Design Principles from Cognitive Theory, Interactive Multimedia Electronic Journal of ComputerEnhanced Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Muter</author>
</authors>
<title>Interface design and optimization of reading of continuous text.</title>
<date>1996</date>
<booktitle>Cognitive Aspects of Electronic Text Processing,</booktitle>
<pages>161--180</pages>
<editor>In H. Van Oostendorp and S. DeMul (eds.)</editor>
<contexts>
<context position="1721" citStr="Muter, 1996" startWordPosition="253" endWordPosition="254">raphics, what kinds of things to say about them, and where to place the cross-media cues in the text. For exploratory purposes, we previously performed an informal corpus study of the use of cross-media cues in arguments (Green 2001). However, we contend that print-mediabased corpus studies may not provide sound information on which to base a model for onscreen presentations. Human-computer interaction (HCI) studies have shown that there are significant differences between reading from print and computer media, e.g., that reading from screen is slower and comprehension is worse (Dillon, 1992; Muter, 1996). Thus, as an alternative to corpus analysis we have begun controlled user studies employing &amp;quot;throwaway&amp;quot; prototypes. In this paper, we present the design and preliminary results of an experiment on effective crossmedia cue usage in computer media. 2 Related Work 2.1 Computational linguistics Cross-media cues are similar in some respects to discourse cue phrases. First, some functions of cross-media cues can be classified using discourse coherence relations such as Preparation, Restatement, Summary, Evaluation, and Elaboration (Green, 2001). Second, there is not a one-to-one correspondence betw</context>
</contexts>
<marker>Muter, 1996</marker>
<rawString>P. Muter. 1996. Interface design and optimization of reading of continuous text. In H. Van Oostendorp and S. DeMul (eds.) Cognitive Aspects of Electronic Text Processing, pp. 161-180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Paraboni</author>
<author>K van Deemter</author>
</authors>
<title>Issues for the Generation of Document Deixis.</title>
<date>1999</date>
<booktitle>In André et al. (Eds.), Deixis, Demonstration and Deictic Belief in Multimedia Contexts, Proceedings of the Workshop associated with the 11th European Summer School in Logic, Language and Information (ESSLLI),</booktitle>
<pages>43--48</pages>
<location>Utrecht, The Netherlands,</location>
<marker>Paraboni, van Deemter, 1999</marker>
<rawString>I. Paraboni and K. van Deemter. 1999. Issues for the Generation of Document Deixis. In André et al. (Eds.), Deixis, Demonstration and Deictic Belief in Multimedia Contexts, Proceedings of the Workshop associated with the 11th European Summer School in Logic, Language and Information (ESSLLI), Utrecht, The Netherlands, 1999, pp. 43-48.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>