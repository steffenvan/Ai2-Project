<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000353">
<title confidence="0.997158">
Dudley North visits North London:
Learning When to Transliterate to Arabic
</title>
<author confidence="0.976203">
Mahmoud Azab Houda Bouamor Behrang Mohit Kemal Oflazer
</author>
<affiliation confidence="0.981009">
Carnegie Mellon University
</affiliation>
<address confidence="0.848557">
P.O. Box 24866, Doha, Qatar
</address>
<email confidence="0.995886">
{mazab, hbouamor, behrang, ko}@qatar.cmu.edu
</email>
<sectionHeader confidence="0.995601" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997943166666667">
We report the results of our work on automat-
ing the transliteration decision of named en-
tities for English to Arabic machine trans-
lation. We construct a classification-based
framework to automate this decision, evalu-
ate our classifier both in the limited news and
the diverse Wikipedia domains, and achieve
promising accuracy. Moreover, we demon-
strate a reduction of translation error and
an improvement in the performance of an
English-to-Arabic machine translation sys-
tem.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998796842105263">
Translation of named entities (NEs) is important
for NLP applications such as Machine Translation
(MT) and Cross-lingual Information Retrieval. For
MT, NEs are major subset of the out-of-vocabulary
terms (OOVs). Due to their diversity, they cannot
always be found in parallel corpora, dictionaries or
gazetteers. Thus, state-of-the-art of MT needs to
handle NEs in specific ways. For instance, in the
English-Arabic automatic translation example given
in Figure 1, the noun ”North” has been erroneously
translated to ”aJ�ËAÒ A‚Ë@ /Al$mAlyp ” (indicating the
north direction in English) instead of being translit-
erated to ” uPñ�K / nwrv”.
As shown in Figure 1, direct translation of in-
vocabulary terms could degrade translation quality.
Also blind transliteration of OOVs does not neces-
sarily contribute to translation adequacy and may ac-
tually create noisy contexts for the language model
and the decoder.
</bodyText>
<note confidence="0.685927">
English Input: Dudley North was an English merchant.
</note>
<figure confidence="0.78044725">
SMT output:usÊs B@ Qk.L- :JL,�all JXðX OA¿
kAn dwdly Al$mAlyp tAjr AlInjlyzyp.
Correct Translation: .ø��Q,�Êm.�� @� Qk. A�K ������ ú�ÍXðX �àA¿
kAn dwdly nwrv tAjr Injlyzy.
</figure>
<figureCaption confidence="0.999965">
Figure 1: Example of a NE translation error.
</figureCaption>
<bodyText confidence="0.997859636363636">
An intelligent decision between translation and
transliteration should use semantic and contextual
information such as the type of the named-entity
and the surrounding terms. In this paper, we con-
struct and evaluate a classification-based framework
to automate the translation vs. transliteration deci-
sion. We evaluate our classifier both in the limited
news and diverse Wikipedia domains, and achieve
promising accuracy. Moreover, we conduct an ex-
trinsic evaluation of the classifier within an English
to Arabic MT system. In an in-domain (news) MT
task, the classifier contributes to a modest (yet sig-
nificant) improvement in MT quality. Moreover, for
a Wikipedia translation task, we demonstrate that
our classifier can reduce the erroneous translation of
60.5% of the named entities.
In summary our contributions are: (a) We au-
tomatically construct a bilingual lexicon of NEs
paired with the transliteration/translation decisions
in two domains.1 (b) We build a binary classi-
fier for transliteration and translation decision with
a promising accuracy (c) We demonstrate its utility
</bodyText>
<footnote confidence="0.908807333333333">
1The dataset can be found at
http://www.qatar.cmu.edu/˜behrang/NETLexicon
.
</footnote>
<page confidence="0.992759">
439
</page>
<subsectionHeader confidence="0.249062">
Proceedings of NAACL-HLT 2013, pages 439–444,
</subsectionHeader>
<bodyText confidence="0.946833857142857">
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
within an MT framework.
2 Learning when to transliterate
We model the decision as a binary classification at
the token level. A token (within a named-entity)
gets translation or transliteration label. In ”Dudley
North” and ”North London”, our classifier is ex-
pected to choose transliteration of ”North” in the
former case, as opposed to translation in the latter.
The binary decision needs to use a rich set of local
and contextual features. We use the Support Vector
Machines as a robust framework for binary classifi-
cation using a set of interdependent features.2 We
build two classifiers: (a) Classifier Crews, trained
on a large set of distinct NEs extracted from news-
related parallel corpora; and (b) Classifier Cdzverse,
trained on a combination of the news related NEs
and a smaller set of diverse-topic NEs extracted
from Wikipedia titles. We evaluate the two classi-
fiers in both news and the diverse domains to ob-
serve the effects of noise and domain change.
</bodyText>
<subsectionHeader confidence="0.998075">
2.1 Preparing the labeled data
</subsectionHeader>
<bodyText confidence="0.999971739130435">
Our classifier requires a set of NEs with token-level
gold labels. We compile such data from two re-
sources: We heuristically extract and label parallel
NEs from a large word aligned parallel corpus and
we use a lexicon of bilingual NEs collected from
Arabic and Wikipedia titles. Starting with a word
aligned parallel corpus, we use the UIUC NE tag-
ger (Ratinov and Roth, 2009) to tag the English
sentences with four classes of NEs: Person (PER),
Location (LOC), Organization (ORG) and Miscella-
neous (MISC). Furthermore, we use the word align-
ments to project and collect the span of the asso-
ciated Arabic named-entities. To reduce the noisy
nature of word alignments, we designed a procedure
to clean up the noisy Arabic NE spans by POS ver-
ification, and heuristically filtering impossible items
(e.g. verbs). This results in a bilingual lexicon of
about 57K named-entity pairs. The distribution of
NEs categories is reported in Table 1.
To train and evaluate the Cdzverse classifier, we
expand our labeled data with Wikipedia NEs us-
ing the cross-lingual hyperlinks. Wikipedia article
titles often correspond to NEs (Kazama and Tori-
</bodyText>
<footnote confidence="0.817519">
2We use the LIBSVM package (Chang and Lin, 2011).
</footnote>
<table confidence="0.998853">
PER LOC ORG MISC
News/57K 43.0% 10.0% 40.0% 7.0%
Wiki/4K 73.0% 19.0% 2.5% 5.5%
</table>
<tableCaption confidence="0.9869185">
Table 1: Distribution of the four NE categories used in
57K News and 4K Wiki datasets.
</tableCaption>
<bodyText confidence="0.99996525">
sawa, 2007) and have been already used in different
works for NEs recognition (Nothman et al., 2013)
and disambiguation (Cucerzan, 2007). We improve
the Arabic-English Wikipedia title lexicon of Mo-
hit et al. (2012) and build a Wikipedia exclusive
lexicon with 4K bilingual entities. In order to test
the domain effects, our lexicon includes only NEs
which are not present in the parallel corpus. The
statistics given in Table 1 demonstrate different na-
ture of the labeled datasets. The two datasets were
labeled semi-automatically using the transliteration
similarity measure (Frscore) proposed by Freeman et
al. (2006), a variant of edit distance measuring the
similarity between an English word and its Arabic
transliteration. In our experiments, English tokens
having an Frscore &gt; 0.6 are considered as translit-
eration, others having Frscore &lt; 0.5 as transla-
tion. These thresholds were determined after tuning
with a held out development set. For tokens having
Frscore between 0.5 and 0.6, the decision is not ob-
vious. To label these instances (around 5K unique
tokens), we manually transliterate them using Mi-
crosoft Maren tool.3 We again compute the Frscore
between the obtained transliteration, in its Buckwal-
ter form and the corresponding English token and
use the same threshold to distinguish between the
two classes. Some examples of NEs and their ap-
propriate classes are presented in Table 2.
</bodyText>
<subsectionHeader confidence="0.904047">
Transliteration Translation
</subsectionHeader>
<bodyText confidence="0.7012415">
Minnesota H A�Kñ‚.:J�Ó/mynyswta : 0.77 Agency H dËA¿ð/wkAlp : 0.33
Fluke H 1/4ñÊ�¯/flwk : 0.57 Islamic H eJ�ÓCƒB@/AlAslAmyp : 0.55
</bodyText>
<tableCaption confidence="0.977638">
Table 2: Examples of NEs labeled using Freeman Score.
</tableCaption>
<subsectionHeader confidence="0.998208">
2.2 Classification Features
</subsectionHeader>
<bodyText confidence="0.99687725">
We use a total of 32 features selected from the fol-
lowing classes:
Token-based features: These consist of several
features based on the token string and indicate
</bodyText>
<footnote confidence="0.920434">
3http://afkar.microsoft.com/en/maren
</footnote>
<page confidence="0.995742">
440
</page>
<bodyText confidence="0.999985208333333">
whether the token is capital initial, composed en-
tirely of capital letters, ends with a period (such
as Mr.), contains a digit or a Latin number (e.g.
Muhammad II) or contains punctuation marks. The
string of the token is also added as a feature. We
also add the POS tag, which could be a good indica-
tor for proper nouns that should mainly be translit-
erated. We also check if the token is a regular noun
in the WORDNET (Fellbaum, 1998) which increases
its chance of being translated as opposed to translit-
erated.
Semantic features: These features mainly indi-
cate the NE category obtained using an NE tag-
ger. We also define a number of markers of person
(such as Doctor, Engineer, etc.) and organization
(such as Corp.) names. We used the list of mark-
ers available at: http://drupal.org/node/
1439292, that we extended manually.
Contextual features: These features are related
to the token’s local context within the NE. These
include information about the current token’s sur-
rounding tokens, its relative position in the NE (be-
ginning, middle or end). Another feature represents
the length of the NE in number of tokens.
</bodyText>
<subsectionHeader confidence="0.933436">
2.3 Experiments
</subsectionHeader>
<bodyText confidence="0.999936142857143">
We train two classifiers and tune their parameters us-
ing a held out development set of 500 NEs drawn
randomly from the news parallel corpus. We use 55k
NEs from the same corpus to train the Cnews clas-
sifier. Furthermore, we train the Cdiverse classifier
cumulatively with the 55K news NEs and another
4600 NEs from Wikipedia titles.
The classifiers are evaluated on three different
datasets: TestNews which consists of 2K of NEs
selected randomly from the news corpus, TestWiki
consisting of 1K NEs extracted from the Wikipedia
and TestCombination, an aggregation of the two pre-
vious sets. We manually reviewed the labels of these
test sets and fixed any incorrect labels. Table 3 com-
pares the accuracy of the two classifiers under dif-
ferent training and test data settings. Starting with
a majority class baseline, our classifiers achieve a
promising performance in most settings. The major-
ity class for both classifiers is the translation which
performs as a baseline approach with an accuracy
equal to the distribution of the two classes. We also
</bodyText>
<table confidence="0.99893125">
TestNews TestWiki TestCombination
Baseline 56.70 57.09 56.89
Cnews 90.40 84.10 88.64
Cdiverse 90.42 86.00 89.18
</table>
<tableCaption confidence="0.9581775">
Table 3: Accuracy results for the two classifiers and the
baseline on the three test datasets
</tableCaption>
<bodyText confidence="0.998137076923077">
observe that the addition of a small diverse training
set in Cdiverse provides a relatively large improve-
ment (about 2%) when tested on Wikipedia. Fi-
nally, Figure 2 illustrates the contribution of differ-
ent classes of features on our diverse classifier (eval-
uated on TestWiki). We observe a fairly linear rela-
tionship between the size of the training data and the
accuracy. Furthermore, we observe that the features
describing the category of the NE are more impor-
tant than the token’s local context. For example, in
the case of ”Dudley North” and ”North London”, the
most effective feature for the decision is the category
of the named entities.
</bodyText>
<figure confidence="0.9500885">
All \Token \Context \Semantic
86
Accuracy 81
76
20,000 30,000 40,000 50,000 60,000
# of examples in the train set
</figure>
<figureCaption confidence="0.985747">
Figure 2: Learning curves obtained on Wiki dataset by
removing features individually.
</figureCaption>
<sectionHeader confidence="0.995536" genericHeader="introduction">
3 Extrinsic MT evaluation
</sectionHeader>
<bodyText confidence="0.999951375">
We evaluate the effects of the classifier on an En-
glish to Arabic statistical MT system. Our first eval-
uation focuses on the utility of our classifier in pre-
venting erroneous translation of NEs which need to
be transliterated. In the following experiments we
use Cnews classifier. In order to experiment with a
diverse set of NEs, we conducted a study on a small
corpus (98,197 terms) of Wikipedia articles from a
</bodyText>
<page confidence="0.997609">
441
</page>
<bodyText confidence="0.93883776">
diverse set of topics. We use 10 Wikipedia articles
describing: Anarchism, Artemis, Buddhism, Isfa-
han, Shawn Michaels, Turkey, etc. We first use our
classifier to locate the subset of NEs which should
be transliterated. An annotator validates the deci-
sion and examines the phrase table on the default
MT decision on those NEs. We observe that out of
1031 NE tokens, 624 tokens (60.5%) which would
have been translated incorrectly, are directed to the
transliteration module.
Finally, we deploy the transliteration classifier as
a pre-translation component to the MT system.4 Our
MT test set is the MEDAR corpus (Maegaard et
al., 2010). The MEDAR corpus consists of about
10,000 words English texts on news related to the
climate change with four Arabic reference transla-
tions. Due to the lack of non-news English-Arabic
corpus, we have to limit this experiment only to
the news domain. However, we expect that many
of the NEs may already exist in the training cor-
pus and the effects of the classifier is more limited
than using a diverse domain like Wikipedia. We au-
tomatically locate the NEs in the source language
sentences and use the classifier to find those which
should be transliterated. For such terms, we offer
the transliterated form as an option to the decoder
aiming to improve the decoding process. For that
a human annotator selected the transliterations from
the suggested list that is provided by the automatic
transliterator (Maren) without any knowledge of the
reference transliterations.
Table 4 shows the impact of adding the classifier
to the SMT pipeline with a modest improvement.
Moreover, a bilingual annotator examined the au-
tomatically tagged NEs in the MT test set and la-
beled them with the translation vs. transliteration
4The baseline MT system is the MOSES phrase-based de-
coder (Koehn et al., 2007) trained on a standard English-Arabic
parallel corpus. The 18 million parallel corpus consists of
the non-UN parts of the NIST corpus distributed by the Lin-
guistic Data Consortium. We perform the standard prepro-
cessing and tokenization on the English side. We also use
MADA+TOKAN (Habash et al., 2009) to preprocess and tok-
enize the Arabic side of the corpus. We use the standard setting
of GIZA++ and the grow-diagonal-final heuristic of MOSES
to get the word alignments. We use a set of 500 sentences
to tune the decoder parameters using the MERT (Och, 2003).
We use El Kholy and Habash (2010) detokenization framework
for the Arabic decoding. We evaluate the MT system with the
BLEU metric (Papineni et al., 2002).
</bodyText>
<table confidence="0.7369905">
MT Baseline + Classifier
16.91
</table>
<tableCaption confidence="0.9470125">
Table 4: Results of the extrinsic usage of the classifier in
SMT
</tableCaption>
<bodyText confidence="0.9999431875">
decisions. Having such gold standard decisions, we
evaluated the classifier against the MT test set. The
classifier’s accuracy was 89% which is as strong as
the earlier intrinsic evaluation. The false positives
are 5% which represents around 12.6% of the total
errors.
The following example shows how our classifier
prevents the MT to choose a wrong decoding for
the NE Python (being transliterated rather than
translated). Moreover, the MT system transliterates
the term Monty that is unknown to the underlying
system. Such entities tend to be unseen in the
standard news corpora and consequently unknown
(UNK) to the MT systems. Using our classi-
fier in such conditions is expected to reduce the
domain gap and improve the translation quality.
</bodyText>
<table confidence="0.531229666666667">
English Input: The British comedy troupe Monty Python.
Baseline MT: .ù�ª3@ UNK �éJ��KA¢��Q�.Ë@ �éK�YJ�ÓñºË@ vQaË@
Alfrqp Alkwmydyp AlbryTAnyp UNK AfEY
MT+Classifier:. dj �L� ����� �. a�;A¢�„Q�.Ë@ v�YJ�ÓñºË@ vQaË@
Alfrqp Alkwmydyp AlbryTAnyp mwnty
bAyvwn.
</table>
<sectionHeader confidence="0.997068" genericHeader="related work">
4 Related work
</sectionHeader>
<bodyText confidence="0.999514684210526">
A number of efforts have been made to undertake the NE
translation problem for different language pairs. Among
them some use sequence of phonetic-based probabilistic
models to convert names written in Arabic into the En-
glish script (Glover-Stalls and Knight, 1998) for translit-
eration of names and technical terms that occurs in Ara-
bic texts and originate in English. Others rely on spelling-
based model that directly maps an English letter sequence
into an Arabic one (Al-Onaizan and Knight, 2002a). In a
related work, Al-Onaizan and Knight (2002b) describe a
combination of a phonetic-based model and a spelling-
based one to build a transliteration model to generate
Arabic to English name translations. In the same direc-
tion, Hassan et al. (2007) extracted NE translation pairs
from both comparable and parallel corpora and evaluate
their quality in a NE translation system. More recently,
Ling et al. (2011) propose a Web-based method that trans-
lates Chinese NEs into English. Our work is similar in
its general objectives and framework to the work pre-
</bodyText>
<figure confidence="0.6095285">
MT Baseline
BLEU 16.63
</figure>
<page confidence="0.995979">
442
</page>
<bodyText confidence="0.967739181818182">
sented by Hermjakob et al. (2008), which describes an
approach for identifying NEs that should be transliter-
ated from Arabic into English during translation. Their
method seeks to find a corresponding English word for
each Arabic word in a parallel corpus, and tag the Ara-
bic words as either NEs or non-NEs based on a match-
ing algorithm. In contrast, we tackle this problem in the
reverse direction (translating/transliterating English NEs
into Arabic). We also present a novel binary classifier for
identifying NEs that should be translated and those that
should be transliterated.
</bodyText>
<sectionHeader confidence="0.97151" genericHeader="conclusions">
5 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.990284272727273">
We reported our recent progress on building a classi-
fier which decides if an MT system should translate or
transliterate a given named entity. The classifier shows
a promising performance in both intrinsic and extrinsic
evaluations. We believe that our framework can be ex-
panded to new languages if the required data resources
and tools (mainly parallel corpus, Named Entity tagger
and transliteration engine) are available. We plan to ex-
pand the features and apply the classifier to new lan-
guages and conduct MT experiments in domains other
than news.
</bodyText>
<sectionHeader confidence="0.999019" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999502111111111">
We thank Nizar Habash and colleagues for the MADA,
Arabic detokenization and the transliteration similarity
software and also their valuable suggestions. We thank
anonymous reviewers for their valuable comments and
suggestions. This publication was made possible by
grants YSREP-1-018-1-004 and NPRP-09-1140-1-177
from the Qatar National Research Fund (a member of
the Qatar Foundation). The statements made herein are
solely the responsibility of the authors.
</bodyText>
<sectionHeader confidence="0.998447" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99933680597015">
Yaser Al-Onaizan and Kevin Knight. 2002a. Named-
Entity translation. In Proceedings of HLT, San Fran-
cisco, USA.
Yaser Al-Onaizan and Kevin Knight. 2002b. Translating
Named Entities Using Monolingual and Bilingual Re-
sources. In Proceedings of ACL, Philadelphia, USA.
Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-
SVM: A Library for Support Vector Machines. ACM
Transactions on Intelligent Systems and Technology,
2:27:1–27:27. Software available at http://www.
csie.ntu.edu.tw/˜cjlin/libsvm.
Silviu Cucerzan. 2007. Large-Scale Named-Entity Dis-
ambiguation Based on Wikipedia Data. In Proceed-
ings of EMNLP-CoNLL, Prague, Czech Republic.
Ahmed El Kholy and Nizar Habash. 2010. Techniques
for Arabic Morphological Detokenization and Ortho-
graphic Denormalization. In Proceedings of LREC,
Valletta, Malta.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. The MIT Press.
Andrew Freeman, Sherri Condon, and Christopher Ack-
erman. 2006. Cross Linguistic Name Matching in
English and Arabic. In Proceedings of NAACL, New
York City, USA.
Bonnie Glover-Stalls and Kevin Knight. 1998. Trans-
lating Named and Technical Terms in Arabic Text. In
Proceeding of the COLING/ACL Workshop on Compu-
tational Approaches to Semitic Languages, Montreal,
Canada.
Nizar Habash, Owen Rambow, and Ryan Roth. 2009.
Mada+Tokan: A Toolkit for Arabic Tokenization, Dia-
critization, Morphological Disambiguation, POS Tag-
ging, Stemming and Lemmatization. In Proceed-
ings of the Second International Conference on Ara-
bic Language Resources and Tools (MEDAR), Cairo,
Egypt.
Ahmed Hassan, Haytham Fahmy, and Hany Hassan.
2007. Improving Named Entity Translation by Ex-
ploiting Comparable and Parallel Corpora. In Pro-
ceedings of RANLP, Borovets, Bulgaria.
Ulf Hermjakob, Kevin Knight, and Hal Daum´e III. 2008.
Name Translation in Statistical Machine Translation
- Learning When to Transliterate. In Proceedings of
ACL-HLT, Columbus, Ohio.
Jun’ichi Kazama and Kentaro Torisawa. 2007. Ex-
ploiting Wikipedia as External Knowledge for Named-
Entity Recognition. In Proceedings of EMNLP-
CoNLL, Prague, Czech Republic.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In Pro-
ceedings of ACL: Demo session, Prague, Czech Re-
public.
Wang Ling, Pavel Calado, Bruno Martins, Isabel Tran-
coso, and Alan Black. 2011. Named-Entity Transla-
tion using Anchor Texts. In Proceedings of IWSLT,
San Francisco, USA.
Bente Maegaard, Mohamed Attia, Khalid Choukri,
Olivier Hamon, Steven Krauwer, and Mustafa Yaseen.
2010. Cooperation for Arabic Language Resources
and Tools–The MEDAR Project. In Proceedings of
LREC, Valetta, Malta.
Behrang Mohit, Nathan Schneider, Rishav Bhowmick,
Kemal Oflazer, and Noah A. Smith. 2012. Recall-
</reference>
<page confidence="0.990824">
443
</page>
<reference confidence="0.9972315">
Oriented Learning of Named Entities in Arabic
Wikipedia. In Proceedings of EACL, Avignon, France.
Joel Nothman, Nicky Ringland, Will Radford, Tara Mur-
phy, and James R. Curran. 2013. Learning Multilin-
gual Named Entity Recognition from Wikipedia. Ar-
tificial Intelligence, 194(0):151 – 175.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proceedings of
ACL, Sapporo, Japan.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic
Evaluation of Machine Translation. In Proceedings of
ACL, Philadelphia, USA.
Lev Ratinov and Dan Roth. 2009. Design Challenges
and Misconceptions in Named Entity Recognition. In
Proceedings of CONLL, Boulder, USA.
</reference>
<page confidence="0.998958">
444
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.487555">
<title confidence="0.8141385">Dudley North visits North London: Learning When to Transliterate to Arabic</title>
<author confidence="0.999081">Mahmoud Azab Houda Bouamor Behrang Mohit Kemal Oflazer</author>
<affiliation confidence="0.999641">Carnegie Mellon University</affiliation>
<address confidence="0.999091">P.O. Box 24866, Doha, Qatar</address>
<email confidence="0.983409">hbouamor,behrang,</email>
<abstract confidence="0.983616538461538">We report the results of our work on automating the transliteration decision of named entities for English to Arabic machine translation. We construct a classification-based framework to automate this decision, evaluate our classifier both in the limited news and the diverse Wikipedia domains, and achieve promising accuracy. Moreover, we demonstrate a reduction of translation error and an improvement in the performance of an English-to-Arabic machine translation system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Kevin Knight</author>
</authors>
<title>NamedEntity translation.</title>
<date>2002</date>
<booktitle>In Proceedings of HLT,</booktitle>
<location>San Francisco, USA.</location>
<contexts>
<context position="15232" citStr="Al-Onaizan and Knight, 2002" startWordPosition="2432" endWordPosition="2435">yp UNK AfEY MT+Classifier:. dj �L� ����� �. a�;A¢�„Q�.Ë@ v�YJ�ÓñºË@ vQaË@ Alfrqp Alkwmydyp AlbryTAnyp mwnty bAyvwn. 4 Related work A number of efforts have been made to undertake the NE translation problem for different language pairs. Among them some use sequence of phonetic-based probabilistic models to convert names written in Arabic into the English script (Glover-Stalls and Knight, 1998) for transliteration of names and technical terms that occurs in Arabic texts and originate in English. Others rely on spellingbased model that directly maps an English letter sequence into an Arabic one (Al-Onaizan and Knight, 2002a). In a related work, Al-Onaizan and Knight (2002b) describe a combination of a phonetic-based model and a spellingbased one to build a transliteration model to generate Arabic to English name translations. In the same direction, Hassan et al. (2007) extracted NE translation pairs from both comparable and parallel corpora and evaluate their quality in a NE translation system. More recently, Ling et al. (2011) propose a Web-based method that translates Chinese NEs into English. Our work is similar in its general objectives and framework to the work preMT Baseline BLEU 16.63 442 sented by Hermj</context>
</contexts>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Yaser Al-Onaizan and Kevin Knight. 2002a. NamedEntity translation. In Proceedings of HLT, San Francisco, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Kevin Knight</author>
</authors>
<title>Translating Named Entities Using Monolingual and Bilingual Resources.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Philadelphia, USA.</location>
<contexts>
<context position="15232" citStr="Al-Onaizan and Knight, 2002" startWordPosition="2432" endWordPosition="2435">yp UNK AfEY MT+Classifier:. dj �L� ����� �. a�;A¢�„Q�.Ë@ v�YJ�ÓñºË@ vQaË@ Alfrqp Alkwmydyp AlbryTAnyp mwnty bAyvwn. 4 Related work A number of efforts have been made to undertake the NE translation problem for different language pairs. Among them some use sequence of phonetic-based probabilistic models to convert names written in Arabic into the English script (Glover-Stalls and Knight, 1998) for transliteration of names and technical terms that occurs in Arabic texts and originate in English. Others rely on spellingbased model that directly maps an English letter sequence into an Arabic one (Al-Onaizan and Knight, 2002a). In a related work, Al-Onaizan and Knight (2002b) describe a combination of a phonetic-based model and a spellingbased one to build a transliteration model to generate Arabic to English name translations. In the same direction, Hassan et al. (2007) extracted NE translation pairs from both comparable and parallel corpora and evaluate their quality in a NE translation system. More recently, Ling et al. (2011) propose a Web-based method that translates Chinese NEs into English. Our work is similar in its general objectives and framework to the work preMT Baseline BLEU 16.63 442 sented by Hermj</context>
</contexts>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Yaser Al-Onaizan and Kevin Knight. 2002b. Translating Named Entities Using Monolingual and Bilingual Resources. In Proceedings of ACL, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A Library for Support Vector Machines.</title>
<date>2011</date>
<booktitle>ACM Transactions on Intelligent Systems and Technology,</booktitle>
<pages>2--27</pages>
<note>Software available at http://www. csie.ntu.edu.tw/˜cjlin/libsvm.</note>
<contexts>
<context position="5378" citStr="Chang and Lin, 2011" startWordPosition="830" endWordPosition="833">nd collect the span of the associated Arabic named-entities. To reduce the noisy nature of word alignments, we designed a procedure to clean up the noisy Arabic NE spans by POS verification, and heuristically filtering impossible items (e.g. verbs). This results in a bilingual lexicon of about 57K named-entity pairs. The distribution of NEs categories is reported in Table 1. To train and evaluate the Cdzverse classifier, we expand our labeled data with Wikipedia NEs using the cross-lingual hyperlinks. Wikipedia article titles often correspond to NEs (Kazama and Tori2We use the LIBSVM package (Chang and Lin, 2011). PER LOC ORG MISC News/57K 43.0% 10.0% 40.0% 7.0% Wiki/4K 73.0% 19.0% 2.5% 5.5% Table 1: Distribution of the four NE categories used in 57K News and 4K Wiki datasets. sawa, 2007) and have been already used in different works for NEs recognition (Nothman et al., 2013) and disambiguation (Cucerzan, 2007). We improve the Arabic-English Wikipedia title lexicon of Mohit et al. (2012) and build a Wikipedia exclusive lexicon with 4K bilingual entities. In order to test the domain effects, our lexicon includes only NEs which are not present in the parallel corpus. The statistics given in Table 1 demo</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A Library for Support Vector Machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27. Software available at http://www. csie.ntu.edu.tw/˜cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
</authors>
<title>Large-Scale Named-Entity Disambiguation Based on Wikipedia Data.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="5682" citStr="Cucerzan, 2007" startWordPosition="883" endWordPosition="884">ty pairs. The distribution of NEs categories is reported in Table 1. To train and evaluate the Cdzverse classifier, we expand our labeled data with Wikipedia NEs using the cross-lingual hyperlinks. Wikipedia article titles often correspond to NEs (Kazama and Tori2We use the LIBSVM package (Chang and Lin, 2011). PER LOC ORG MISC News/57K 43.0% 10.0% 40.0% 7.0% Wiki/4K 73.0% 19.0% 2.5% 5.5% Table 1: Distribution of the four NE categories used in 57K News and 4K Wiki datasets. sawa, 2007) and have been already used in different works for NEs recognition (Nothman et al., 2013) and disambiguation (Cucerzan, 2007). We improve the Arabic-English Wikipedia title lexicon of Mohit et al. (2012) and build a Wikipedia exclusive lexicon with 4K bilingual entities. In order to test the domain effects, our lexicon includes only NEs which are not present in the parallel corpus. The statistics given in Table 1 demonstrate different nature of the labeled datasets. The two datasets were labeled semi-automatically using the transliteration similarity measure (Frscore) proposed by Freeman et al. (2006), a variant of edit distance measuring the similarity between an English word and its Arabic transliteration. In our </context>
</contexts>
<marker>Cucerzan, 2007</marker>
<rawString>Silviu Cucerzan. 2007. Large-Scale Named-Entity Disambiguation Based on Wikipedia Data. In Proceedings of EMNLP-CoNLL, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed El Kholy</author>
<author>Nizar Habash</author>
</authors>
<title>Techniques for Arabic Morphological Detokenization and Orthographic Denormalization.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC,</booktitle>
<location>Valletta,</location>
<marker>El Kholy, Habash, 2010</marker>
<rawString>Ahmed El Kholy and Nizar Habash. 2010. Techniques for Arabic Morphological Detokenization and Orthographic Denormalization. In Proceedings of LREC, Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="7829" citStr="Fellbaum, 1998" startWordPosition="1228" endWordPosition="1229">atures selected from the following classes: Token-based features: These consist of several features based on the token string and indicate 3http://afkar.microsoft.com/en/maren 440 whether the token is capital initial, composed entirely of capital letters, ends with a period (such as Mr.), contains a digit or a Latin number (e.g. Muhammad II) or contains punctuation marks. The string of the token is also added as a feature. We also add the POS tag, which could be a good indicator for proper nouns that should mainly be transliterated. We also check if the token is a regular noun in the WORDNET (Fellbaum, 1998) which increases its chance of being translated as opposed to transliterated. Semantic features: These features mainly indicate the NE category obtained using an NE tagger. We also define a number of markers of person (such as Doctor, Engineer, etc.) and organization (such as Corp.) names. We used the list of markers available at: http://drupal.org/node/ 1439292, that we extended manually. Contextual features: These features are related to the token’s local context within the NE. These include information about the current token’s surrounding tokens, its relative position in the NE (beginning,</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Freeman</author>
<author>Sherri Condon</author>
<author>Christopher Ackerman</author>
</authors>
<title>Cross Linguistic Name Matching in English and Arabic.</title>
<date>2006</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<location>New York City, USA.</location>
<contexts>
<context position="6165" citStr="Freeman et al. (2006)" startWordPosition="956" endWordPosition="959">. sawa, 2007) and have been already used in different works for NEs recognition (Nothman et al., 2013) and disambiguation (Cucerzan, 2007). We improve the Arabic-English Wikipedia title lexicon of Mohit et al. (2012) and build a Wikipedia exclusive lexicon with 4K bilingual entities. In order to test the domain effects, our lexicon includes only NEs which are not present in the parallel corpus. The statistics given in Table 1 demonstrate different nature of the labeled datasets. The two datasets were labeled semi-automatically using the transliteration similarity measure (Frscore) proposed by Freeman et al. (2006), a variant of edit distance measuring the similarity between an English word and its Arabic transliteration. In our experiments, English tokens having an Frscore &gt; 0.6 are considered as transliteration, others having Frscore &lt; 0.5 as translation. These thresholds were determined after tuning with a held out development set. For tokens having Frscore between 0.5 and 0.6, the decision is not obvious. To label these instances (around 5K unique tokens), we manually transliterate them using Microsoft Maren tool.3 We again compute the Frscore between the obtained transliteration, in its Buckwalter </context>
</contexts>
<marker>Freeman, Condon, Ackerman, 2006</marker>
<rawString>Andrew Freeman, Sherri Condon, and Christopher Ackerman. 2006. Cross Linguistic Name Matching in English and Arabic. In Proceedings of NAACL, New York City, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Glover-Stalls</author>
<author>Kevin Knight</author>
</authors>
<title>Translating Named and Technical Terms in Arabic Text.</title>
<date>1998</date>
<booktitle>In Proceeding of the COLING/ACL Workshop on Computational Approaches to Semitic Languages,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="15000" citStr="Glover-Stalls and Knight, 1998" startWordPosition="2393" endWordPosition="2396">ier in such conditions is expected to reduce the domain gap and improve the translation quality. English Input: The British comedy troupe Monty Python. Baseline MT: .ù�ª3@ UNK �éJ��KA¢��Q�.Ë@ �éK�YJ�ÓñºË@ vQaË@ Alfrqp Alkwmydyp AlbryTAnyp UNK AfEY MT+Classifier:. dj �L� ����� �. a�;A¢�„Q�.Ë@ v�YJ�ÓñºË@ vQaË@ Alfrqp Alkwmydyp AlbryTAnyp mwnty bAyvwn. 4 Related work A number of efforts have been made to undertake the NE translation problem for different language pairs. Among them some use sequence of phonetic-based probabilistic models to convert names written in Arabic into the English script (Glover-Stalls and Knight, 1998) for transliteration of names and technical terms that occurs in Arabic texts and originate in English. Others rely on spellingbased model that directly maps an English letter sequence into an Arabic one (Al-Onaizan and Knight, 2002a). In a related work, Al-Onaizan and Knight (2002b) describe a combination of a phonetic-based model and a spellingbased one to build a transliteration model to generate Arabic to English name translations. In the same direction, Hassan et al. (2007) extracted NE translation pairs from both comparable and parallel corpora and evaluate their quality in a NE translat</context>
</contexts>
<marker>Glover-Stalls, Knight, 1998</marker>
<rawString>Bonnie Glover-Stalls and Kevin Knight. 1998. Translating Named and Technical Terms in Arabic Text. In Proceeding of the COLING/ACL Workshop on Computational Approaches to Semitic Languages, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Ryan Roth</author>
</authors>
<title>Mada+Tokan: A Toolkit for Arabic Tokenization, Diacritization, Morphological Disambiguation, POS Tagging, Stemming and Lemmatization.</title>
<date>2009</date>
<booktitle>In Proceedings of the Second International Conference on Arabic Language Resources and Tools (MEDAR),</booktitle>
<location>Cairo, Egypt.</location>
<contexts>
<context position="13208" citStr="Habash et al., 2009" startWordPosition="2108" endWordPosition="2111">le 4 shows the impact of adding the classifier to the SMT pipeline with a modest improvement. Moreover, a bilingual annotator examined the automatically tagged NEs in the MT test set and labeled them with the translation vs. transliteration 4The baseline MT system is the MOSES phrase-based decoder (Koehn et al., 2007) trained on a standard English-Arabic parallel corpus. The 18 million parallel corpus consists of the non-UN parts of the NIST corpus distributed by the Linguistic Data Consortium. We perform the standard preprocessing and tokenization on the English side. We also use MADA+TOKAN (Habash et al., 2009) to preprocess and tokenize the Arabic side of the corpus. We use the standard setting of GIZA++ and the grow-diagonal-final heuristic of MOSES to get the word alignments. We use a set of 500 sentences to tune the decoder parameters using the MERT (Och, 2003). We use El Kholy and Habash (2010) detokenization framework for the Arabic decoding. We evaluate the MT system with the BLEU metric (Papineni et al., 2002). MT Baseline + Classifier 16.91 Table 4: Results of the extrinsic usage of the classifier in SMT decisions. Having such gold standard decisions, we evaluated the classifier against the</context>
</contexts>
<marker>Habash, Rambow, Roth, 2009</marker>
<rawString>Nizar Habash, Owen Rambow, and Ryan Roth. 2009. Mada+Tokan: A Toolkit for Arabic Tokenization, Diacritization, Morphological Disambiguation, POS Tagging, Stemming and Lemmatization. In Proceedings of the Second International Conference on Arabic Language Resources and Tools (MEDAR), Cairo, Egypt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Hassan</author>
<author>Haytham Fahmy</author>
<author>Hany Hassan</author>
</authors>
<title>Improving Named Entity Translation by Exploiting Comparable and Parallel Corpora.</title>
<date>2007</date>
<booktitle>In Proceedings of RANLP, Borovets,</booktitle>
<contexts>
<context position="15483" citStr="Hassan et al. (2007)" startWordPosition="2473" endWordPosition="2476">quence of phonetic-based probabilistic models to convert names written in Arabic into the English script (Glover-Stalls and Knight, 1998) for transliteration of names and technical terms that occurs in Arabic texts and originate in English. Others rely on spellingbased model that directly maps an English letter sequence into an Arabic one (Al-Onaizan and Knight, 2002a). In a related work, Al-Onaizan and Knight (2002b) describe a combination of a phonetic-based model and a spellingbased one to build a transliteration model to generate Arabic to English name translations. In the same direction, Hassan et al. (2007) extracted NE translation pairs from both comparable and parallel corpora and evaluate their quality in a NE translation system. More recently, Ling et al. (2011) propose a Web-based method that translates Chinese NEs into English. Our work is similar in its general objectives and framework to the work preMT Baseline BLEU 16.63 442 sented by Hermjakob et al. (2008), which describes an approach for identifying NEs that should be transliterated from Arabic into English during translation. Their method seeks to find a corresponding English word for each Arabic word in a parallel corpus, and tag t</context>
</contexts>
<marker>Hassan, Fahmy, Hassan, 2007</marker>
<rawString>Ahmed Hassan, Haytham Fahmy, and Hany Hassan. 2007. Improving Named Entity Translation by Exploiting Comparable and Parallel Corpora. In Proceedings of RANLP, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulf Hermjakob</author>
<author>Kevin Knight</author>
<author>Hal Daum´e</author>
</authors>
<title>Name Translation in Statistical Machine Translation - Learning When to Transliterate.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT,</booktitle>
<location>Columbus, Ohio.</location>
<marker>Hermjakob, Knight, Daum´e, 2008</marker>
<rawString>Ulf Hermjakob, Kevin Knight, and Hal Daum´e III. 2008. Name Translation in Statistical Machine Translation - Learning When to Transliterate. In Proceedings of ACL-HLT, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun’ichi Kazama</author>
<author>Kentaro Torisawa</author>
</authors>
<title>Exploiting Wikipedia as External Knowledge for NamedEntity Recognition.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLPCoNLL,</booktitle>
<location>Prague, Czech Republic.</location>
<marker>Kazama, Torisawa, 2007</marker>
<rawString>Jun’ichi Kazama and Kentaro Torisawa. 2007. Exploiting Wikipedia as External Knowledge for NamedEntity Recognition. In Proceedings of EMNLPCoNLL, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL: Demo session,</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="12907" citStr="Koehn et al., 2007" startWordPosition="2060" endWordPosition="2063"> we offer the transliterated form as an option to the decoder aiming to improve the decoding process. For that a human annotator selected the transliterations from the suggested list that is provided by the automatic transliterator (Maren) without any knowledge of the reference transliterations. Table 4 shows the impact of adding the classifier to the SMT pipeline with a modest improvement. Moreover, a bilingual annotator examined the automatically tagged NEs in the MT test set and labeled them with the translation vs. transliteration 4The baseline MT system is the MOSES phrase-based decoder (Koehn et al., 2007) trained on a standard English-Arabic parallel corpus. The 18 million parallel corpus consists of the non-UN parts of the NIST corpus distributed by the Linguistic Data Consortium. We perform the standard preprocessing and tokenization on the English side. We also use MADA+TOKAN (Habash et al., 2009) to preprocess and tokenize the Arabic side of the corpus. We use the standard setting of GIZA++ and the grow-diagonal-final heuristic of MOSES to get the word alignments. We use a set of 500 sentences to tune the decoder parameters using the MERT (Och, 2003). We use El Kholy and Habash (2010) deto</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of ACL: Demo session, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wang Ling</author>
<author>Pavel Calado</author>
<author>Bruno Martins</author>
<author>Isabel Trancoso</author>
<author>Alan Black</author>
</authors>
<title>Named-Entity Translation using Anchor Texts.</title>
<date>2011</date>
<booktitle>In Proceedings of IWSLT,</booktitle>
<location>San Francisco, USA.</location>
<contexts>
<context position="15645" citStr="Ling et al. (2011)" startWordPosition="2498" endWordPosition="2501">es and technical terms that occurs in Arabic texts and originate in English. Others rely on spellingbased model that directly maps an English letter sequence into an Arabic one (Al-Onaizan and Knight, 2002a). In a related work, Al-Onaizan and Knight (2002b) describe a combination of a phonetic-based model and a spellingbased one to build a transliteration model to generate Arabic to English name translations. In the same direction, Hassan et al. (2007) extracted NE translation pairs from both comparable and parallel corpora and evaluate their quality in a NE translation system. More recently, Ling et al. (2011) propose a Web-based method that translates Chinese NEs into English. Our work is similar in its general objectives and framework to the work preMT Baseline BLEU 16.63 442 sented by Hermjakob et al. (2008), which describes an approach for identifying NEs that should be transliterated from Arabic into English during translation. Their method seeks to find a corresponding English word for each Arabic word in a parallel corpus, and tag the Arabic words as either NEs or non-NEs based on a matching algorithm. In contrast, we tackle this problem in the reverse direction (translating/transliterating </context>
</contexts>
<marker>Ling, Calado, Martins, Trancoso, Black, 2011</marker>
<rawString>Wang Ling, Pavel Calado, Bruno Martins, Isabel Trancoso, and Alan Black. 2011. Named-Entity Translation using Anchor Texts. In Proceedings of IWSLT, San Francisco, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bente Maegaard</author>
<author>Mohamed Attia</author>
<author>Khalid Choukri</author>
<author>Olivier Hamon</author>
<author>Steven Krauwer</author>
<author>Mustafa Yaseen</author>
</authors>
<title>Cooperation for Arabic Language Resources and Tools–The MEDAR Project.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC, Valetta,</booktitle>
<contexts>
<context position="11712" citStr="Maegaard et al., 2010" startWordPosition="1862" endWordPosition="1865">of topics. We use 10 Wikipedia articles describing: Anarchism, Artemis, Buddhism, Isfahan, Shawn Michaels, Turkey, etc. We first use our classifier to locate the subset of NEs which should be transliterated. An annotator validates the decision and examines the phrase table on the default MT decision on those NEs. We observe that out of 1031 NE tokens, 624 tokens (60.5%) which would have been translated incorrectly, are directed to the transliteration module. Finally, we deploy the transliteration classifier as a pre-translation component to the MT system.4 Our MT test set is the MEDAR corpus (Maegaard et al., 2010). The MEDAR corpus consists of about 10,000 words English texts on news related to the climate change with four Arabic reference translations. Due to the lack of non-news English-Arabic corpus, we have to limit this experiment only to the news domain. However, we expect that many of the NEs may already exist in the training corpus and the effects of the classifier is more limited than using a diverse domain like Wikipedia. We automatically locate the NEs in the source language sentences and use the classifier to find those which should be transliterated. For such terms, we offer the transliter</context>
</contexts>
<marker>Maegaard, Attia, Choukri, Hamon, Krauwer, Yaseen, 2010</marker>
<rawString>Bente Maegaard, Mohamed Attia, Khalid Choukri, Olivier Hamon, Steven Krauwer, and Mustafa Yaseen. 2010. Cooperation for Arabic Language Resources and Tools–The MEDAR Project. In Proceedings of LREC, Valetta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Behrang Mohit</author>
<author>Nathan Schneider</author>
<author>Rishav Bhowmick</author>
<author>Kemal Oflazer</author>
<author>Noah A Smith</author>
</authors>
<title>RecallOriented Learning of Named Entities in Arabic Wikipedia.</title>
<date>2012</date>
<booktitle>In Proceedings of EACL,</booktitle>
<location>Avignon, France.</location>
<contexts>
<context position="5760" citStr="Mohit et al. (2012)" startWordPosition="893" endWordPosition="897">ain and evaluate the Cdzverse classifier, we expand our labeled data with Wikipedia NEs using the cross-lingual hyperlinks. Wikipedia article titles often correspond to NEs (Kazama and Tori2We use the LIBSVM package (Chang and Lin, 2011). PER LOC ORG MISC News/57K 43.0% 10.0% 40.0% 7.0% Wiki/4K 73.0% 19.0% 2.5% 5.5% Table 1: Distribution of the four NE categories used in 57K News and 4K Wiki datasets. sawa, 2007) and have been already used in different works for NEs recognition (Nothman et al., 2013) and disambiguation (Cucerzan, 2007). We improve the Arabic-English Wikipedia title lexicon of Mohit et al. (2012) and build a Wikipedia exclusive lexicon with 4K bilingual entities. In order to test the domain effects, our lexicon includes only NEs which are not present in the parallel corpus. The statistics given in Table 1 demonstrate different nature of the labeled datasets. The two datasets were labeled semi-automatically using the transliteration similarity measure (Frscore) proposed by Freeman et al. (2006), a variant of edit distance measuring the similarity between an English word and its Arabic transliteration. In our experiments, English tokens having an Frscore &gt; 0.6 are considered as translit</context>
</contexts>
<marker>Mohit, Schneider, Bhowmick, Oflazer, Smith, 2012</marker>
<rawString>Behrang Mohit, Nathan Schneider, Rishav Bhowmick, Kemal Oflazer, and Noah A. Smith. 2012. RecallOriented Learning of Named Entities in Arabic Wikipedia. In Proceedings of EACL, Avignon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Nothman</author>
<author>Nicky Ringland</author>
<author>Will Radford</author>
<author>Tara Murphy</author>
<author>James R Curran</author>
</authors>
<title>Learning Multilingual Named Entity Recognition from Wikipedia.</title>
<date>2013</date>
<journal>Artificial Intelligence,</journal>
<volume>194</volume>
<issue>0</issue>
<pages>175</pages>
<contexts>
<context position="5646" citStr="Nothman et al., 2013" startWordPosition="877" endWordPosition="880"> bilingual lexicon of about 57K named-entity pairs. The distribution of NEs categories is reported in Table 1. To train and evaluate the Cdzverse classifier, we expand our labeled data with Wikipedia NEs using the cross-lingual hyperlinks. Wikipedia article titles often correspond to NEs (Kazama and Tori2We use the LIBSVM package (Chang and Lin, 2011). PER LOC ORG MISC News/57K 43.0% 10.0% 40.0% 7.0% Wiki/4K 73.0% 19.0% 2.5% 5.5% Table 1: Distribution of the four NE categories used in 57K News and 4K Wiki datasets. sawa, 2007) and have been already used in different works for NEs recognition (Nothman et al., 2013) and disambiguation (Cucerzan, 2007). We improve the Arabic-English Wikipedia title lexicon of Mohit et al. (2012) and build a Wikipedia exclusive lexicon with 4K bilingual entities. In order to test the domain effects, our lexicon includes only NEs which are not present in the parallel corpus. The statistics given in Table 1 demonstrate different nature of the labeled datasets. The two datasets were labeled semi-automatically using the transliteration similarity measure (Frscore) proposed by Freeman et al. (2006), a variant of edit distance measuring the similarity between an English word and</context>
</contexts>
<marker>Nothman, Ringland, Radford, Murphy, Curran, 2013</marker>
<rawString>Joel Nothman, Nicky Ringland, Will Radford, Tara Murphy, and James R. Curran. 2013. Learning Multilingual Named Entity Recognition from Wikipedia. Artificial Intelligence, 194(0):151 – 175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum Error Rate Training in Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="13467" citStr="Och, 2003" startWordPosition="2156" endWordPosition="2157">he MOSES phrase-based decoder (Koehn et al., 2007) trained on a standard English-Arabic parallel corpus. The 18 million parallel corpus consists of the non-UN parts of the NIST corpus distributed by the Linguistic Data Consortium. We perform the standard preprocessing and tokenization on the English side. We also use MADA+TOKAN (Habash et al., 2009) to preprocess and tokenize the Arabic side of the corpus. We use the standard setting of GIZA++ and the grow-diagonal-final heuristic of MOSES to get the word alignments. We use a set of 500 sentences to tune the decoder parameters using the MERT (Och, 2003). We use El Kholy and Habash (2010) detokenization framework for the Arabic decoding. We evaluate the MT system with the BLEU metric (Papineni et al., 2002). MT Baseline + Classifier 16.91 Table 4: Results of the extrinsic usage of the classifier in SMT decisions. Having such gold standard decisions, we evaluated the classifier against the MT test set. The classifier’s accuracy was 89% which is as strong as the earlier intrinsic evaluation. The false positives are 5% which represents around 12.6% of the total errors. The following example shows how our classifier prevents the MT to choose a wr</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Proceedings of ACL, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Philadelphia, USA.</location>
<contexts>
<context position="13623" citStr="Papineni et al., 2002" startWordPosition="2180" endWordPosition="2183"> of the non-UN parts of the NIST corpus distributed by the Linguistic Data Consortium. We perform the standard preprocessing and tokenization on the English side. We also use MADA+TOKAN (Habash et al., 2009) to preprocess and tokenize the Arabic side of the corpus. We use the standard setting of GIZA++ and the grow-diagonal-final heuristic of MOSES to get the word alignments. We use a set of 500 sentences to tune the decoder parameters using the MERT (Och, 2003). We use El Kholy and Habash (2010) detokenization framework for the Arabic decoding. We evaluate the MT system with the BLEU metric (Papineni et al., 2002). MT Baseline + Classifier 16.91 Table 4: Results of the extrinsic usage of the classifier in SMT decisions. Having such gold standard decisions, we evaluated the classifier against the MT test set. The classifier’s accuracy was 89% which is as strong as the earlier intrinsic evaluation. The false positives are 5% which represents around 12.6% of the total errors. The following example shows how our classifier prevents the MT to choose a wrong decoding for the NE Python (being transliterated rather than translated). Moreover, the MT system transliterates the term Monty that is unknown to the u</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings of ACL, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
</authors>
<title>Design Challenges and Misconceptions in Named Entity Recognition.</title>
<date>2009</date>
<booktitle>In Proceedings of CONLL,</booktitle>
<location>Boulder, USA.</location>
<contexts>
<context position="4575" citStr="Ratinov and Roth, 2009" startWordPosition="700" endWordPosition="703">of the news related NEs and a smaller set of diverse-topic NEs extracted from Wikipedia titles. We evaluate the two classifiers in both news and the diverse domains to observe the effects of noise and domain change. 2.1 Preparing the labeled data Our classifier requires a set of NEs with token-level gold labels. We compile such data from two resources: We heuristically extract and label parallel NEs from a large word aligned parallel corpus and we use a lexicon of bilingual NEs collected from Arabic and Wikipedia titles. Starting with a word aligned parallel corpus, we use the UIUC NE tagger (Ratinov and Roth, 2009) to tag the English sentences with four classes of NEs: Person (PER), Location (LOC), Organization (ORG) and Miscellaneous (MISC). Furthermore, we use the word alignments to project and collect the span of the associated Arabic named-entities. To reduce the noisy nature of word alignments, we designed a procedure to clean up the noisy Arabic NE spans by POS verification, and heuristically filtering impossible items (e.g. verbs). This results in a bilingual lexicon of about 57K named-entity pairs. The distribution of NEs categories is reported in Table 1. To train and evaluate the Cdzverse clas</context>
</contexts>
<marker>Ratinov, Roth, 2009</marker>
<rawString>Lev Ratinov and Dan Roth. 2009. Design Challenges and Misconceptions in Named Entity Recognition. In Proceedings of CONLL, Boulder, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>