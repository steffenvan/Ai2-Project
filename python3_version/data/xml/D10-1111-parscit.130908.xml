<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9929135">
Staying Informed: Supervised and Semi-Supervised Multi-view
Topical Analysis of Ideological Perspective
</title>
<author confidence="0.99368">
Amr Ahmed
</author>
<affiliation confidence="0.9906825">
School of Computer Science
Carnegie Mellon University
</affiliation>
<email confidence="0.998437">
amahmed@cs.cmu.edu
</email>
<sectionHeader confidence="0.993895" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998073166666667">
With the proliferation of user-generated arti-
cles over the web, it becomes imperative to de-
velop automated methods that are aware of the
ideological-bias implicit in a document col-
lection. While there exist methods that can
classify the ideological bias of a given docu-
ment, little has been done toward understand-
ing the nature of this bias on a topical-level. In
this paper we address the problem of modeling
ideological perspective on a topical level using
a factored topic model. We develop efficient
inference algorithms using Collapsed Gibbs
sampling for posterior inference, and give var-
ious evaluations and illustrations of the util-
ity of our model on various document collec-
tions with promising results. Finally we give a
Metropolis-Hasting inference algorithm for a
semi-supervised extension with decent results.
</bodyText>
<sectionHeader confidence="0.998995" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9991668">
With the avalanche of user-generated articles over
the web, it is quite important to develop models that
can recognize the ideological bias behind a given
document, summarize where this bias is manifested
on a topical level, and provide the user with alter-
nate views that would help him/her staying informed
about different perspectives. In this paper, we fol-
low the notion of ideology as defines by Van Dijk
in (Dijk, 1998) as “a set of general abstract beliefs
commonly shared by a group of people.” In other
words, an ideology is a set of ideas that directs one’s
goals, expectations, and actions. For instance, free-
dom of choice is a general aim that directs the ac-
tions of“liberals”, whereas conservation of values is
the parallel for “conservatives”.
</bodyText>
<author confidence="0.92044">
Eric P. Xing
</author>
<affiliation confidence="0.9942555">
School of Computer Science
Carnegie Mellon University
</affiliation>
<email confidence="0.993681">
epxing@cs.cmu.edu
</email>
<bodyText confidence="0.9376395">
We can attribute the lexical variations of the word
content of a document to three factors:
</bodyText>
<listItem confidence="0.591570666666667">
• Writer Ideological Belief. A liberal writer
might use words like freedom and choice re-
gardless of the topical content of the document.
</listItem>
<bodyText confidence="0.946364">
These words define the abstract notion of be-
lief held by the writer and its frequency in the
document largely depends on the writer’s style.
</bodyText>
<listItem confidence="0.860312833333333">
• Topical Content. This constitutes the main
source of the lexical variations in a given docu-
ment. For instance, a document about abortion
is more likely to have facts related to abortion,
health, marriage and relationships.
• Topic-Ideology Interaction. When a liberal
thinker writes about abortion, his/her abstract
beliefs are materialized into a set of concrete
opinions and stances, therefore, we might find
words like: pro-choice and feminism. On the
contrary, a conservative writer might stress is-
sues like pro-life, God and faith.
</listItem>
<bodyText confidence="0.955918230769231">
Given a collection of ideologically-labeled docu-
ments, our goal is to develop a computer model that
factors the document collection into a representation
that reflects the aforementioned three sources of lex-
ical variations. This representation can then be used
for:
• Visualization. By visualizing the abstract no-
tion of belief in each ideology, and the way
each ideology approaches and views main-
stream topics, the user can view and contrast
each ideology side-by-side and build the right
mental landscape that acts as the basis for
his/her future decision making.
</bodyText>
<page confidence="0.923014">
1140
</page>
<note confidence="0.7509115">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1140–1150,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<listItem confidence="0.935100818181818">
• Classification or Ideology Identification.
Given a document, we would like to tell the
user from which side it was written, and ex-
plain the ideological bias in the document at a
topical level.
• Staying Informed: Getting alternative
views1. Given a document written from per-
spective A, we would like the model to provide
the user with other documents that represent al-
ternative views about the same topic addressed
in the original document.
</listItem>
<bodyText confidence="0.999946">
In this paper, we approach this problem using
Topic Models (Blei et al., 2003). We introduce a
factored topic model that we call multi-view Latent
Dirichlet Allocation or mview-LDA for short. Our
model views the word content of each document as
the result of the interaction between the document’s
idealogical and topical dimensions. The rest of this
paper is organized as follows. First, in Section 2,
we review related work, and then present our model
in Section 3. Then in Section 4, we detail a col-
lapsed Gibbs sampling algorithm for posterior infer-
ence. Sections 5 and 6 give details about the dataset
used in the evaluation and illustrate the capabilities
of our model using both qualitative and quantitative
measures. Section 7 describes and evaluates the ef-
ficacy of a semi-supervised extension, and finally in
Section 8 we conclude and list several directions for
future research.
</bodyText>
<sectionHeader confidence="0.999745" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.993544923076923">
Ideological text is inherently subjective, thus our
work is related to the growing area of subjectiv-
ity analysis(Wiebe et al., 2004; Riloff et al., 2003).
The goal of this area of research is to learn to dis-
criminate between subjective and objective text. In
contrast,in modeling ideology, we aim toward con-
trasting two or more ideological perspectives each of
which is subjective in nature. Further more, subjec-
tive text can be classified into sentiments which gave
rise to a surge of work in automatic opinion min-
ing (Wiebe et al., 2004; Yu and Hatzivassiloglou,
2003; Pang et al., 2002; Turney and Littman, 2003;
Popescu and Etzioni, 2005) as well as sentiment
</bodyText>
<footnote confidence="0.986005">
1In this paper, we use the words ideology, view, perspective
interchangeably to denote the same concept
</footnote>
<note confidence="0.815227666666667">
analysis and product review mining (Nasukawa and
Yi, 2003; Hu and Liu, 2004; Pang and Lee, 2008;
Branavan et al., 2008; Titov and McDonald, 2008;
</note>
<bodyText confidence="0.983282944444445">
Titov and McDonald, 2008; Mei et al., 2007; Ling
et al., 2008). The research goal of sentiment anal-
ysis and classification is to identify language used
to convey positive and negative opinions, which dif-
fers from contrasting two ideological perspectives.
While ideology can be expressed in the form of a
sentiment toward a given topic,like abortion, ideo-
logical perspectives are reflected in many ways other
than sentiments as we will illustrate later in the pa-
per. Perhaps more related to this paper is the work
of (Fortuna et al., 2008; Lin et al., 2008) whose
goal is to detect bias in news articles via discrimina-
tive and generative approaches, respectively. How-
ever, this work still addresses ideology at an abstract
level as opposed to our approach of modeling ideol-
ogy at a topical level. Finally, independently, (Paul
and Girju, 2009) gives a construction similar to ours
however for a different task 2.
</bodyText>
<sectionHeader confidence="0.958687" genericHeader="method">
3 Multi-View Topic Models
</sectionHeader>
<bodyText confidence="0.999944133333333">
In this section we introduce multi-view topic mod-
els, or mview-LDA for short. Our model, mview-
LDA, views each document as the result of the in-
teraction between its topical and idealogical dimen-
sions. The model seeks to explain lexical variabili-
ties in the document by attributing this variabilities
to one of those dimensions or to their interactions.
Topic models, like LDA, define a generative process
for a document collection based on a set of parame-
ters. LDA employs a semantic entity known as topic
to drive the generation of the document in question.
Each topic is represented by a topic-specific word
distribution which is modeled as a multinomial dis-
tribution over words, denoted by Multi(0). The
generative process of LDA proceeds as follows:
</bodyText>
<listItem confidence="0.99779425">
1. Draw topic proportions Bd|α — Dir(α).
2. For each word
(a) Draw a topic zn|Bd — Mult(Bd).
(b) Draw a word wn|zn, 0 — Multi(0,,).
</listItem>
<bodyText confidence="0.998562">
In step 1 each document d samples a topic-mixing
vector Bd from a Dirichlet prior. The component Bd,k
</bodyText>
<footnote confidence="0.998797">
2In fact, we only get to know about this related work after
our paper was accepted
</footnote>
<page confidence="0.994112">
1141
</page>
<figure confidence="0.981181708333334">
Variable Meaning
w word
v document’s ideology
z topic
x1, x2 word switches, one per word (see text)
θ document-specific distribution over topics
ξ document’s expected usage of the ideology’s
background topic
Q ideology’s background-topic
β ideology-independent topic distribution
φ ideology-specific topic distribution
λ topic bias across ideology
a1 b1
a2 b2
z
x2
x1
V
w
V
N
K
v
D
</figure>
<figureCaption confidence="0.99999">
Figure 1: A plate diagram of the graphical model.
</figureCaption>
<bodyText confidence="0.999800727272727">
of this vector defines how likely topic k will appear
in document d. For each word in the document w,,,,
a topic indicator z,,, is sampled from θd, and then
the word itself is sampled from a topic-specific word
distribution specified by this indicator. Thus LDA
can capture and represent lexical variabilities via the
components of θd which represents the topical con-
tent of the document. In the next section we will ex-
plain how our new model mview-LDA can capture
other sources of lexical variabilities beyond topical
content.
</bodyText>
<subsectionHeader confidence="0.991817">
3.1 Multi-View LDA
</subsectionHeader>
<bodyText confidence="0.990143714285714">
As we noted earlier, LDA captures lexical variabili-
ties due to topical content via θd and the set of top-
ics β1:K. In mview-LDA each document d is tagged
with the ideological view it represents via the ob-
served variable vd which takes values in the discrete
range: 11, 2, · · · , V } as shown in Fig. 1. For sim-
plicity, lets first assume that V = 2. The topics β1:K
retain the same meaning: a set of K multinomial
distributions each of which represents a given theme
or factual topic. In addition, we utilize an ideology-
specific topic Q„ which is again a multinomial dis-
tribution over the same vocabulary. Q„ models the
abstract belief shared by all the documents written
from view v. In other words, if v denotes the liberal
perspective, then Q„ gives high probability to words
like progressive, choice, etc. Moreover, we defined
a set of K x V topics that we refer to as ideology-
specific topics. For example, topic φ„,k represents
how ideology v addresses topic k. The generative
process of a document d with ideological view vd
proceeds as follows:
</bodyText>
<listItem confidence="0.997302333333333">
1. Draw ξd — Beta(a1, b1)
2. Draw topic proportions θd|α — Dir(α2).
3. For each word wn
</listItem>
<equation confidence="0.7764386">
(a) Draw xn,1 — Bernoulli(ξd)
(b) If(xn,1 = 1)
i. Draw wn|xn,1 = 1 — Multi(Qvd)
(c) If(xn,1 = 0)
i. Draw zn|θd — Mult(θd).
ii. Draw xn,2|vd, zn — Bernoulli(λz,)
iii. If(xn,2 = 1)
A. Draw wn|zn, β — Multi(βzj.
iv. If(xn,2 = 0)
A. Draw wn|vd, zn — Multi(φvd,z�).
</equation>
<bodyText confidence="0.999956176470588">
In step 1, we draw a document-specific biased
coin,ξd. The bias of this coin determines the pro-
portions of words in the document that are gener-
ated from its ideology background topic Q„d. As in
LDA, we draw the document-specific topic propor-
tion θd from a Dirichlet prior. θd thus controls the
lexical variabilities due to topical content inside the
document.
To generate a word w,,,, we first generate a coin
flip x,,,,1 from the coin ξd. If it turns head, then
we proceed to generate this word from the ideology-
specific topic associated with the document’s ideo-
logical view vd. In this case, the word is drawn in-
dependently of the topical content of the document,
and thus accounts for the lexical variation due to the
ideology associated with the document. The propor-
tion of such words is document-specific by design
</bodyText>
<page confidence="0.973658">
1142
</page>
<bodyText confidence="0.999992454545454">
and depends on the writer’s style to a large degree.
If xn,1 turns to be tail,we proceed to the next step
and draw a topic-indicator zn. Now, we have two
choices: either to generate this word directly from
the ideology-independent portion of the topic 0zn,
or to draw the word from the ideology-specific por-
tion Ovd,zn. The choice here is not document spe-
cific, but rather depends on the interaction between
the ideology and the specific topic in question. If
the ideology associated with the document holds a
strong opinion or view with regard to this topic,
then we expect that most of the time we will take
the second choice, and generate wn from Ovd,zn;
and vice versa. This decision is controlled by the
Bernoulli variable Azn. Therefore, in step c.ii, we
first generate a coin flip xn,2 from Azn. Based on
xn,2 we either generate the word from the ideology-
independent portion of the topic Ozn, and this con-
stitutes how the model accounts for lexical variation
due to the topical content of the document, or gen-
erate the word from the ideology-specific portion of
the topic Ovd,zn, and this specifies how the model
accounts for lexical variation due to the interaction
between the topical and ideological dimensions of
the document.
Finally, it is worth mentioning that the decision to
model Azn3 at the topic-ideology level rather than at
the document level, as we have done with fid, stems
from our goal to capture ideology-specific behavior
on a corpus level rather than capturing document-
specific writing style. However, it is worth mention-
ing that if one truly seeks to measure the degree of
bias associated with a given document,then one can
compute the frequency of the event xn,2 = 0 from
posterior samples. In this case, Azn acts as the prior
bias only. Moreover, computing the frequency of
the event xn,2 = 0 and zn = k gives the document’s
bias toward topic k per se.
Finally, it is worth mentioning that all multino-
mial topics in the model: Q, Q, 0 are generated once
for the whole collection from a symmetric Dirichlet
prior, similarly, all bias variables, A1:K are sampled
from a Beta distribution also once at the beginning
of the generative process.
</bodyText>
<footnote confidence="0.945925">
3In an earlier version of the work we modeled A on a per-
ideology basis, however, we found that using a single shared A
results in more robust results
</footnote>
<sectionHeader confidence="0.408703" genericHeader="method">
4 Posterior Inference Via Collapsed Gibbs
Sampling
</sectionHeader>
<bodyText confidence="0.984692">
The main tasks can be summarized as follows:
</bodyText>
<listItem confidence="0.967374285714286">
• Learning: Given a collection of documents,
find a point estimate of the model parameters
(i.e. 0, Q, 0, A,etc.).
• Inference: Given a new document, and a point
estimate of the model parameters, find the pos-
terior distribution of the latent variables associ-
ated with the document at hand:
</listItem>
<equation confidence="0.466534">
(Bd, {xn,1}, {zn}, {xn,2}).
</equation>
<bodyText confidence="0.9997904">
Under a hierarchical Bayesian setting, like the ap-
proach we took in this paper, both of these tasks can
be handled via posterior inference. Under the gener-
ative process, and hyperparmaters choices, outlined
in section 3, we seek to compute:
</bodyText>
<equation confidence="0.55636">
P(d1:D, 01:K, fl1:V , 01:V,1:K, A1:K|a, a, b, W, V),
</equation>
<bodyText confidence="0.99959748275862">
where d is a shorthand for the hidden variables
(Bd, fid, z, x1, x2) in document d. The above poste-
rior probability is unfortunately intractable,and we
approximate it via a collapsed Gibbs sampling pro-
cedure (Griffiths and Steyvers, 2004; Gelman et al.,
2003) by integrating out, i.e. collapsing, the fol-
lowing hidden variables: the topic-mixing vectors
Bd and the ideology bias �d for each document, as
well as all the multinomial topic distributions: (Q, Q
and 0) in addition to the ideology-topic biases given
by the set of A random variables.
Therefore, the state of the sampler at each itera-
tion contains only the following topic indicators and
coin flips for each document:(z, x1, x2). We alter-
nate sampling each of these variables conditioned on
its Markov blanket until convergence. At conver-
gence, we can calculate expected values for all the
parameters that were integrated out, especially for
the topic distributions, for each document’s latent
representation (mixing-vector) and for all coin bi-
ases. To ease the calculation of the Gibbs sampling
update equations we keep a set of sufficient statistics
(SS) in the form of co-occurrence counts and sum
matrices of the form
CEQ eqto denote the number of
times instance a appeared with instance q. For ex-
ample, CW K
wk gives the number of times word w was
sampled from the ideology-independent portion of
</bodyText>
<page confidence="0.933391">
1143
</page>
<bodyText confidence="0.994993833333333">
topic k. Moreover, we follow the standard practice
of using the subscript −i to denote the same quan-
tity it is added to without the contribution of item
i. For example,CW K
wk,−i is the same as CW K
wk with-
out the contribution of word wi. For simplicity, we
might drop dependencies on the document whenever
the meaning is implicit form the context.
For word wn in document d, instead of sampling
zn, xn,1, xn,2 independently, we sample them as a
block as follows:
</bodyText>
<equation confidence="0.999899428571429">
P(xn,1 = 1|wn = w,vd = v) ∝
DX1 CV W
vw,−n + α1
(Cd1,−n + a1) ×
P(xn,1 = 0, x2,n = 1, zn = k|wn = w, vd = v)
CKX2
k1,−n + a2
∝ (CDX1
d0,−n + b1) × CKX2 k1,−n + CKX2
k0,−n + a2 + b2
KW
Ckw,−n + α1
× Ew0(CKW
kw0,−n + α1) ×
</equation>
<bodyText confidence="0.999823962962963">
The above three equations can be normalized to
form a 2 ∗ K + 1 multinomial distribution: one
component for generating a word from the ideol-
ogy topic, K components for generating the word
from the ideology-independent portion of topic k =
1, · · · , K, and finally K components for generat-
ing the word from the ideology-specific portion of
topic k = 1, · · · , K. Each of these 2 ∗ K + 1
cases corresponds to a unique assignment of the
variables zn, xn,1, xn,2. Therefore, our Gibbs sam-
pler just repeatedly draws sample from this 2∗K+1-
components multinomial distribution until conver-
gence. Upon convergence, we compute point es-
timates for all the collapsed variables by a simple
marginalization of the appropriate count matrices.
During inference, we hold the corpus-level count
matrices fixed, and keep sampling from the above
2∗K +1-component multinomial while only chang-
ing the document-level count matrices: CDK, CDX1
until convergence. Upon convergence, we compute
estimates for �d and Bd by normalizing CDK and
CDX1 (or possibly averaging this quantity across
posterior samples). As we mentioned in Section 3,
to compute the ideology-bias in addressing a given
topic say k in a given document, say d, we can sim-
ply compute the expected value of the event xn,2 =
0 and zn = k across posterior samples.
</bodyText>
<sectionHeader confidence="0.991829" genericHeader="method">
5 Data Sets
</sectionHeader>
<bodyText confidence="0.999997666666667">
We evaluated our model over three datasets: the bit-
terlemons croups and a two political blog-data set.
Below we give details of each dataset.
</bodyText>
<subsectionHeader confidence="0.969901">
5.1 The Bitterlemons dataset
</subsectionHeader>
<bodyText confidence="0.999985380952381">
The bitterlemons corpus consists of
the articles published on the website
http://bitterlemons.org/. The website
is set up to contribute to mutual understanding
between Palestinians and Israelis through the
open exchange of ideas. Every week, an issue
about the Israeli-Palestinian conflict is selected for
discussion, and a Palestinian editor and an Israeli
editor contribute one article each addressing the
issue. In addition, the Israeli and Palestinian editors
invite one Israeli and one Palestinian to express
their views on the issue. The data was collected
and pre-proceed as describes in (Lin et al., 2008).
Overall, the dataset contains 297 documents written
from the Israeli’s point of view, and 297 documents
written from the Palestinian’s point of view. On
average each document contains around 740 words.
After trimming words appearing less than 5 times,
we ended up with a vocabulary size of 4100 words.
We split the dataset randomly and used 80% of the
documents for training and the rest for testing.
</bodyText>
<subsectionHeader confidence="0.998971">
5.2 The Political Blog Datasets
</subsectionHeader>
<bodyText confidence="0.9997095">
The first dataset refereed to as Blog-1 is a subset
of the data collected and processed in (Yano et al.,
2009). The authors in (Yano et al., 2009) collected
blog posts from blog sites focusing on American
politics during the period November 2007 to Oc-
tober 2008. We selected three blog sites from this
dataset: the Right Wing News (right-ideology) ;
the Carpetbagger, and Daily Kos as representatives
</bodyText>
<equation confidence="0.976456681818182">
Ew0(CV W
vw0,−n + α1)
DK
Cdk,−n + α2
Ek0(CDK
dk0,−n + α2)
P(xn,1 = 0, x2,n = 0, zn = k|wn = w, vd = v)
∝ (CDX1 ,−n 2
d0,−n + b1) ×
CKX2 + CKX2 + a2 + b
k1 k0
,−n ,−n 2
CKX2 + b
k0
V KW
× Cvkw,−n + α1 ×
DK
Cdk,−n + α2
EDK
k0(Cdk 0,− n + α2)
E w0(CV KW
vkw0,−n + α1)
</equation>
<page confidence="0.94815">
1144
</page>
<figure confidence="0.703996054945055">
Israeli View
US role
Palestinian View
Israeli
Background
topic
palestinian
israeli
peace
year
political
process
state
end
right
government
need
conflict
way
security
process force terrorism unit
road demand provide
confidence element interim
discussion want union succee
point build positive recognize
present timetable
peace strategic plo hizballah
islamic neighbor territorial
radical iran relation think
obviou countri mandate
greater conventional intifada
affect jihad time
arafat state leader roadmap
george election month iraq
week peace june realistic
yasir senior involvement
clinton november post
mandate terrorism
Arab Involvement
roadmap phase violence
security ceasefire state plan
international step implement
authority final quartet issue
map effort
bush US president american
sharon administration prime
settlement pressure policy
washington ariel new middle
Roadmap process
israel syria syrian negotiate
lebanon deal conference
concession asad agreement
regional october initiative
relationship
track negotiation official
leadership position
withdrawal time victory
present second stand
circumstance represent sense
talk strategy issue participant
parti negotiator
unit state american george
powell minister colin visit
internal policy statement
express pro previous package
work transfer european
administration receive
roadmap end settlement
implementation obligation
stop expansion commitment
consolidate fulfill unit illegal
present previou assassination
meet forward negative calm
Palestinian
Background
topic
palestinian
israeli
Peace
political
occupation
process
end
security
conflict
way
government
people
time year
force
negotiation
</figure>
<figureCaption confidence="0.998884">
Figure 2: Illustrating the big picture overview over the bitterlemons dataset using few topics. Each box lists the top
words in the corresponding multinomial topic distribution. See text for more details
</figureCaption>
<bodyText confidence="0.999797173913044">
of the liberal view (left-ideology). After trimming
short posts of less than 20 words, we ended up with
2040 posts distributed as 1400 from the left-wing
and the rest from the right-wing. On average, each
post contains around 100 words and the total size of
the vocabulary is 14276 words. For this dataset, we
followed the train-test split in (Yano et al., 2009).
In this split each blog is represented in both train-
ing and test sets. Thus this dataset does not measure
the model’s ability to generalize to a totally different
writing style.
The second dataset refereed to as Blog-2 is sim-
ilar to Blog-1 in its topical content and time frame
but larger in its blog coverage (Eisenstein and Xing,
2010). Blog-2 spans 6 blogs: three from the left-
wing and three from the right-wing. The dataset
contains 13246 posts. After removing words that
appear less then 20 times, the total vocabulary be-
comes 13236 with an average of 200 words per post.
We used 4 blogs (2 from each view) for training
and held two blogs (one from each view) for test-
ing. Thus this dataset measures the model’s ability
to generalize to a totally new blog.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="method">
6 Experimental Results
</sectionHeader>
<bodyText confidence="0.9998265">
In this section we gave various qualitative and quan-
titative evaluations of our model over the datasets
listed in Section 5. For all experiments, we set
a1 = .01, a2 = .1, a = 1 and b = 1. We run Gibbs
sampling during training for 1000 iterations. During
inference, we ran Gibbs sampling for 300 iterations,
and took 10 samples, with 50-iterations lag, for eval-
uations.
</bodyText>
<subsectionHeader confidence="0.998688">
6.1 Visualization and Browsing
</subsectionHeader>
<bodyText confidence="0.9999928">
One advantage of our approach is its ability to create
a “big-picture” overview of the interaction between
ideology and topics. In figure 2 we show a portion of
that diagram over the bitterlemons dataset. First note
how the ideology-specific topics in both ideology
share the top-three words, which highlights that the
two ideologies seek peace even though they still both
disagree on other issues. The figure gives example
of three topics: the US role, the Roadmap peace
process, and the Arab involvement in the conflict
</bodyText>
<page confidence="0.982677">
1145
</page>
<bodyText confidence="0.999974977272727">
(the name of these topics were hand-crafted). For
each topic, we display the top words in the ideology-
independent part of the topic (Q), along with top
words in each ideology’s view of the topic (0).
For example, when discussing the roadmap pro-
cess, the Palestinian view brings the following is-
sues: [the Israeli side should] implement the oblig-
atory points in this agreement, stop expansion of
settlements, and move forward to the commitments
brought by this process. On the other hand, the Is-
raeli side brings the following points: [Israelis] need
to build confidence [with Palestinian], address the
role of terrorism on the implementation of the pro-
cess, and ask for a positive recognition of Israel
from the different Palestinian political parties. As
we can see, the ideology-specific portion of the topic
needn’t always represent a sentiment shared by its
members toward a given topic, but it might rather
includes extra important dimensions that need to be
taken into consideration when addressing this topic.
Another interesting topic addresses the involve-
ment of the neighboring Arab countries in the con-
flict. From the Israeli point of view, Israel is worried
about the existence of hizballah [in lebanon] and its
relationship with radical Iran, and how this might
affect the Palestinian-uprising (Intifada) and Jihad.
From the other side, the Palestinians think that the
Arab neighbors need to be involved in the peace pro-
cess and negotiations as some of these countries like
Syria and Lebanon are involved in the conflict.
The user can use the above chart as an entry point
to retrieve various documents pertinent to a given
topic or to a given view over a specific topic. For
instance, if the user asks for a representative sam-
ple of the Israeli(Palestinian) view with regard to the
roadmap process, the system can first retrieve docu-
ments tagged with the Israeli(Palestinian) view and
having a high topical value in their latent representa-
tion 0 over this topic. Finally, the system then sorts
these documents by how much bias they show over
this topic. As we discussed in Section 4, this can be
done by computing the expected value of the event
xn,2 = 0 and zn = k where k is the topic under
consideration.
</bodyText>
<subsectionHeader confidence="0.998127">
6.2 Classification
</subsectionHeader>
<bodyText confidence="0.9998076">
We have also performed a classification task over
all the datasets. The Scenario proceeded as follows.
We train a model over the training data with various
number of topics. Then given a test document, we
predict its ideology using the following equation:
</bodyText>
<equation confidence="0.953994">
vd = argmax„EVP(wdjv); (1)
</equation>
<bodyText confidence="0.999786">
We use three baselines. The first baseline
is an SVM classifier trained on the normalized
word frequency of each document. We trained
SVM using a regularization parameter in the range
11, 10, 20, · · · ,100} and report the best result (i.e.
no cross-validation was performed). The other
two are supervised LDA models: supervised LDA
(sLDA) (Wang et. al., 2009; Blei and McCauliffe,
2007) and discLDA (Lacoste-Julien et al., 2008).
discLDA is a conditional model that divides the
available number of topics into class-specific top-
ics and shared-topics. Since the code is not publicly
available, we followed the same strategy in the orig-
inal paper and share 0.1K topics across ideologies
and then divide the rest of the topics between ide-
ologies4. However, unlike our model, there are no
internal relationships between these two sets of top-
ics. The decision rule employed by discLDA is very
similar to the one we used for mview-LDA in Eq
(1). For sLDA, we used the publicly available code
by the authors.
As shown in Figure 3, our model performs better
than the baselines over the three datasets. We should
note from this figure that mview-LDA peaks at a
small number of topics, however, each topic is repre-
sented by three multinomials. Moreover, it is evident
from the figure that the experiment over the blog-
2 dataset which measures each model’s ability to
generalizes to a totally unseen new blog is a harder
task than generalizing to unseen posts form the same
blog. However, our model still performs competi-
tively with the SVM baseline. We believe that sep-
arating each topic into an ideology-independent part
and ideology-specific part is the key behind this per-
formance, as it is expected that the new blogs would
still share much of the ideology-independent parts
of the topics and hopefully would use similar (but
</bodyText>
<footnote confidence="0.976362">
4(Lacoste-Julien et al., 2008) gave an optimization algo-
rithm for learning the topic structure (transformation matrix),
however since the code is not available, we resorted to one of
the fixed splitting strategies mentioned in the paper. We tried
other splits but this one gives the best results
</footnote>
<page confidence="0.993886">
1146
</page>
<figure confidence="0.997727">
(a) (b) (c)
</figure>
<figureCaption confidence="0.985828">
Figure 3: Classification accuracy over the Bitterlemons dataset in (a) and over the two blog datasets in (b) and (c). For SVM we
give the best result obtained across a wide range of the SVM’s regularization parameter(not the cross-validation result).
</figureCaption>
<bodyText confidence="0.999914181818182">
no necessarily all) words from the ideology-specific
parts of each topic when addressing this topic.
Finally, it should be noted that the bitterlemons
dataset is a multi-author dataset and thus the models
were tested on some authors that were not seen dur-
ing training, however, two factors contributed to the
good performance by all models over this dataset.
The first being the larger size of each document (740
words per document as compared to 200 words per
post in blog-2) and the second being the more formal
writing style in the bitterlemons dataset.
</bodyText>
<subsectionHeader confidence="0.999426">
6.3 An Ablation Study
</subsectionHeader>
<bodyText confidence="0.9997965">
To understand the contribution of each component of
our model, we conducted an ablation study over the
bitterlemons dataset. In this experiment we turned-
off one feature of our model at a time and mea-
sured the classification performance. The results are
shown in Figure 4. Full, refers to the full model; No-
Q refers to a model in which the ideology-specific
background topic Q is turned-off; and No-0 refers
to a model in which the ideology-specific portions of
the topics are turned-off. As evident from the figure,
0 is more important to the model than Q and the dif-
ference in performance between the full model and
the No-0 model is rather significant. In fact without
0 the model has little power to discriminate between
ideologies beyond the ideology-specific background
topic Q.
</bodyText>
<subsectionHeader confidence="0.982673">
6.4 Retrieval: Getting the Other Views
</subsectionHeader>
<bodyText confidence="0.998521333333333">
To evaluate the ability of our model in finding al-
ternative views toward a given topic, we conducted
the following experiment over the Bitterlemons cor-
pus. In this corpus each document is associated with
a meta-topic that highlights the issues addressed in
this document like: “A possible Jordanian role”,
</bodyText>
<figureCaption confidence="0.99457">
Figure 4: An Ablation study over the bitterlemons dataset.
</figureCaption>
<bodyText confidence="0.999983086956522">
“Demography and the conflict”,etc. There are a to-
tal of 148 meta-topics. These topics were not used
in fitting our model but we use them in the evalu-
ation as follows. We divided the dataset into 60%
for training and 40% for testing. We trained mview-
LDA over the training set, and then used the learned
model to infer the latent representation of the test
documents as well as their ideologies. We then used
each document in the training set as a query to re-
trieve documents from the test set that address the
same meta-topic in the query document but from the
other-side’s perspective. Note that we have access to
the view of the query document but not the view of
the test document. Moreover, the value of the meta-
topic is only used to construct the ground-truth result
of each query over the test set. In addition to mview-
LDA, we also implemented a strong baseline using
SVM+Dirichlet smoothing that we will refer to as
LM. In this baseline, we build an SVM classifier
over the training set, and use Dirichlet-smoothing
to represent each document (in test and training set)
as a multinomial-distribution over the vocabulary.
Given a query document d, we rank documents in
</bodyText>
<page confidence="0.996226">
1147
</page>
<figureCaption confidence="0.998455">
Figure 5: Evaluating the performance of the view-Retrieval task. Figure compare performance between mview-LD vs. an SVM+a
smoothed language model approach using three measures: average rank, best rank and rank at full recall. ( Lower better)
</figureCaption>
<bodyText confidence="0.902308">
.
the test set by each model as follows:
</bodyText>
<listItem confidence="0.98172">
• mview-LDA: we computed the cosine-distance
</listItem>
<subsubsectionHeader confidence="0.601009">
between ��v−LDA−shared and ��v−LDA−shared
</subsubsectionHeader>
<bodyText confidence="0.957303090909091">
d d�
weighted by the probability that d&apos; is written
from a different view than vd. The latter
quantity can be computed by normaliz-
ing P(v|d&apos;). Moreover, ��v−LDA−shared a
d,k
&amp; I[(xn,1 = 0) and (xn,2 = 1) and (zn = k)],
and n ranges over words in document d. In-
tuitively, we would like 0&apos;−LDA−shared to
d
reflect variation due to the topical content, but
not ideological view of the document.
• LM: For a document d&apos;, we apply the SVM
classifier to get P(v|d&apos;), then we measure sim-
ilarity by computing the cosine-distance be-
tween the smoothed multinomial-distribution
of d and d&apos;. We combine these two components
as in mview-LDA.
Finally we rank documents in the test set in a
descending-order and evaluate the resulting rank-
ing using three measures: the rank at full recall
(lowest rank), average rank, and best rank of the
ground-truth documents as they appear in the pre-
dicted ranking. Figure 5 shows the results across a
number of topics. From this figure, it is clear that
our model outperforms this baseline over all mea-
sures. It should be noted that this is a very hard
task since the meta-topics are very fine-grained like:
Settlements revisited, The status of the settlements,
Is the roadmap still relevant?,The ceasefire and the
roadmap: a progress report,etc. We did not attempt
to cluster these meta-topics since our goal is just to
compare our model against the baseline.
</bodyText>
<sectionHeader confidence="0.989581" genericHeader="method">
7 A Semi-Supervised Extension
</sectionHeader>
<bodyText confidence="0.9999881">
In this section we present and assess the efficacy of
a semi-supervised extension of mview-LDA. In this
setting, the model is given a set of ideologically-
labeled documents and a set of unlabeled docu-
ments. One of the key advantages of using a prob-
abilistic graphical model is the ability to deal with
hidden variables in a principled way. Thus the only
change needed in this case is adding a single step in
the sampling algorithm to sample the ideology v of
an unlabeled document as follows:
</bodyText>
<equation confidence="0.903866">
P(vd = v|rest) a P(wd|vd = v, zd, x1,d, x2,d)
</equation>
<bodyText confidence="0.9980136875">
Note that the probability of the indicators
(x1,d, x2,d, zd) do not depend on the view of the
document and thus got absorbed in the normaliza-
tion constant, and thus one only needs to measures
the likelihood of generating the words in the doc-
ument under the view v. We divide the words
into three groups: Ad = {wn|xn,1 = 11 is the
set of words generated from the view-background
topic, Bd,k = {wn|zn = k, xn,1 = 0, xn,2 =
11 is the set of words generated from Qk, and
Cd,k = {wn|zn = k, xn,1 = 0, xn,2 = 01 is the
set of words generated from Ok,v. The probabil-
ity of Bd,k does not depend on the value of v and
thus can be absorbed into the normalization factor.
Therefore, we only need to compute the following
probability:P(Ad, Cd,1:K|vd = v, rest)=
</bodyText>
<figure confidence="0.464691666666667">
� P(Cd,k  |0k,v, rest)p(Ok,v  |rest)d0k,v
kr I
k,v
</figure>
<footnote confidence="0.363076">
x JP(Ad |Q, rest)p(Q|rest)dQ (2)
sz
</footnote>
<page confidence="0.981314">
1148
</page>
<bodyText confidence="0.984784333333333">
All the integrals in (2) reduce to the ratio of two
log partition functions. For example, the product of
integrals containing Cd,k reduce to:
</bodyText>
<figure confidence="0.983255636363636">
R mview-LDA ss-mview-LDA
80 65.60 66.41
60 62.31 65.43
20 60.87 63.25
77�77 r (CDKW,X2=0 + CV KWd + α I Table 1: Classification performance of the semi-
llw l dkw vkw,− it supervised model. R is the ratio of labeled documents.
Y
k
r rPw r DKW,X2=0Cdkw + CVKWvkw,−d + α1l)
P VK 111
X r\ w f LC&apos;vkww + α (3)
</figure>
<figureCaption confidence="0.741226">
7 7 (C�ktwd l lw r + α1)
</figureCaption>
<bodyText confidence="0.996120888888889">
Unfortunately, the above scheme does not mix
well because the value of the integrals in (2) are
very low for any view other than the view of the
document in the current state of the sampler. This
happens because of the tight coupling between vd
and the indicators (x1, x2, z). To remedy this prob-
lem we used a Metropolis-Hasting step to sample
(vd, x1, x2, z) jointly. We construct a set of V pro-
posals each of which is indexed by a possible view:
qv(x1, x2, z) = P(x1, x2, z|vd = v, wd). Since
we have a collection of proposal distributions, we
select one of them at random at each step. To
generate a sample from qv∗(), we run a few it-
erations of a restricted Gibbs scan over the docu-
ment d conditioned on fixing vd = v* and then
take the last sample jointly with v* as our pro-
posed new state. With probability min(r,1), the new
state (v*, x1*, x2*, z*) is accepted, otherwise the
old state is retained. The acceptance ratio,r, is com-
puted as: r = p(Wd|v∗,X1∗,X2∗,Z∗), where the non-*
p(Wd |v,X1,X2,Z)
variables represent the current state of the sampler.
It is interesting to note that the above acceptance ra-
tio is equivalent to a likelihood ratio test. We com-
pute the marginal probability P(wd|..) using the
estimated-theta method (Wallach et al., 2009).
We evaluated the semi-supervised extension using
the blog-2 dataset as follows. We reveal R% of the
labels in the training set; then we train mview-LDA
only over the labeled portion and train the semi-
supervised version (ss-mview-LDA) on both the la-
beled and unlabeled documents. Finally we evaluate
the classification performance on the test set. We
used R = 120, 40, 801. The results are given in Ta-
ble 1 which shows a decent improvement over the
supervised mview-LDA.
</bodyText>
<sectionHeader confidence="0.993911" genericHeader="discussions">
8 Discussion and Future Work
</sectionHeader>
<bodyText confidence="0.999977862068965">
In this paper, we addressed the problem of model-
ing ideological perspective at a topical level. We
developed a factored topic model that we called
multiView-LDA or mview-LDA for short. mview-
LDA factors a document collection into three set
of topics: ideology-specific, topic-specific, and
ideology-topic ones. We showed that the resulting
representation can be used to give a bird-eyes’ view
to where each ideology stands with regard to main-
stream topics. Moreover, we illustrated how the la-
tent structure induced by the model can by used to
perform bias-detection at the document and topic
level, and retrieve documents that represent alterna-
tive views.
It is important to mention that our model induces
a hierarchical structure over the topics, and thus it
is interesting to contrast it with hierarchical topic
models like hLDA (Blei et al., 2003) and PAM (Li
and McCallum, 2006; Mimno et al., 2007). First,
these models are unsupervised in nature, while our
model is supervised. Second, the semantic of the
hierarchical structure in our model is different than
the one induced by those models since documents in
our model are constrained to use a specific portion
of the topic structure while in those models docu-
ments can freely sample words from any topic. Fi-
nally,in the future we plan to extend our model to
perform joint modeling and summarization of ide-
alogical discourse.
</bodyText>
<sectionHeader confidence="0.994799" genericHeader="acknowledgments">
9 Acknowledgment
</sectionHeader>
<bodyText confidence="0.99597875">
We thank Jacob Eisenstein, John Lafferty, Tom
Mitchell, and the anonymous reviewers for their
helpful comments and suggestions. This work is
supported in part by grants NSF IIS- 0713379,
NSF DBI-0546594 career award to EPX, ONR
N000140910758, DARPA NBCH1080007, and
AFOSR FA9550010247. EPX is supported by an
Alfred P. Sloan Research Fellowship.
</bodyText>
<page confidence="0.994972">
1149
</page>
<sectionHeader confidence="0.995885" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999885697916667">
J. Wiebe, T. Wilson, R.Bruce, M. Bell, and M. Martin.
Learning subjective language. Computational Linguis-
tics, 30(3), 2004.
H. Yu and V. Hatzivassiloglou. Towards answering opin-
ion questions: Separating facts from opinions and
identifying the polarity of opinion sentences. In Pro-
ceedings of EMNLP-2003
B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs
up? Sentiment classification using machine learning
techniques. In Proceedings of EMNLP-2002.
P. Turney and M. Littman. Measuring praise and criti-
cism: Inference of semantic orientation from associa-
tion. ACM TOIS, 21(4):315346, 2003
A. Popescu and O. Etzioni. Extracting product fea-
tures and opinions from reviews. In Proceedings of
HLT/EMNLP-2005, pages 339346, 2005.
T. Nasukawa and J. Yi. Sentiment analysis: Capturing
favorability using natural language processing. In Pro-
ceedings of K-CAP, 2003.
M. Hu and B. Liu. Mining and summarizing customer
reviews. In Proceedings of KDD, 2004.
B. Pang and L. Lee. Opinion mining and sentiment anal-
ysis. Foundations and Trends in Information Retrieval,
2(12), 1135, 2008.
S. Branavan, H. Chen, J. Eisenstein and R. Barzilay.
Learning Document-Level Semantic Properties from
Free-text Annotations, Proceedings of ACL, 2008.
I. Titov and R. McDonald. Modeling Online Reviews
with Multi-Grain Topic Models International World
Wide Web Conference (WWW), 2008.
I. Titov and R. McDonald. A Joint Model of Text and
Aspect Ratings for Sentiment Summarization Associ-
ation for Computational Linguistics (ACL), 2008.
Q. Mei, X. Ling, M. Wondra, H. Su, ChengXiang Zhai.
Topic Sentiment Mixture: Modeling Facets and Opin-
ions in Weblogs, Proceedings of the 16th International
World Wide Web Conference (WWW), pages 171-
180, 2007.
X. Ling, Q. Mei, C. Zhai, B. Schatz. Mining Multi-
Faceted Overviews of Arbitrary Topics in a Text Col-
lection, Proceedings of the 15th ACM SIGKDD In-
ternational Conference on Knowledge Discovery and
Data Mining (KDD’ 08), pages 497-505, 2008
B. Fortuna , C. Galleguillos, N. Cristianini. Detecting
the bias in media with statistical learning methods.
In: Text Mining: Theory and Applications. Taylor and
Francis Publisher,2008.
W. Lin, E.P. Xing, and A. Hauptmann. A Joint Topic and
Perspective Model for Ideological Discourse Euro-
pean Conference on Machine Learning and Principles
and Practice of Knowledge Discovery in Databases
(ECML/PKDD), 2008.
T. A. Van Dijk. Ideology: A multidisciplinary approach.
Sage Publications, 1998.
T. Griffiths, M. Steyvers Finding scientific topics.PNAS,
101:5228-5235, 2004.
A. Gelman, J. Carlin, Hal Stern, and Donald Ru-
bin. Bayesian Data Analysis, Chapman-Hall, 2 edi-
tion,2003.
D. Blei, A. Ng, and M. Jordan. Latent Dirichlet al-
location. Journal of Machine Learning Research,
3:9931022, January 2003.
T. Yano, W. W. Cohen, and N. A. Smith. Predicting
Response to Political Blog Posts with Topic Models.
NAACL-HLT 2009, Boulder, CO, MayJune 2009
J. Eisenstein and E.P. Xing.The CMU-2008 Political
Blog Corpus. CMU-ML-10-101 Technical Report,
2010.
C. Wang, D. Blei and L. Fei-Fei. Simultaneous image
classification and annotation. CVPR, 2010.
D. Blei and J. McAuliffe. Supervised topic models. NIPS,
2007.
S. Lacoste-Julien, F. Sha, and M. Jordan. DiscLDA:
Discriminative Learning for Dimensionality Reduc-
tion and Classification. Neural Information Process-
ing Systems Conference (NIPS08), Vancouver, British
Columbia, December 2008.
E. Riloff, J. Wiebe, and T. Wilson. Learning subjective
nouns using extraction pattern bootstrapping. In Pro-
ceedings of CoNLL-2003.
D. Blei, T. Griffiths, M. Jordan, and J. Tenenbaum. Hier-
archical topic models and the nested Chinese restau-
rant process. In Neural Information Processing Sys-
tems (NIPS)16, 2003.
D. Mimno, W. Li and A. McCallum. Mixtures of Hier-
archical Topics with Pachinko Allocation. In Interna-
tional Conference of Machine Learning, ICML, 2007.
W. Li, and A. McCallum. Pachinko Allocation: DAG-
structured Mixture Models of Topic Correlations. In
International Conference of Machine Learning, ICML,
2006.
M. Paul and R. Girju. Cross-cultural Analysis of Blogs
and Forums with Mixed-Collection Topic Models.
EMNLP 2009.
H. Wallach, I. Murray, R. Salakhutdinov, and D. Mimno.
Evaluation Methods for Topic Models. ICML 2009.
</reference>
<page confidence="0.992097">
1150
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.929125">
<title confidence="0.9851185">Staying Informed: Supervised and Semi-Supervised Topical Analysis of Ideological Perspective</title>
<author confidence="0.967814">Amr</author>
<affiliation confidence="0.9972275">School of Computer Carnegie Mellon</affiliation>
<email confidence="0.998787">amahmed@cs.cmu.edu</email>
<abstract confidence="0.999570368421053">With the proliferation of user-generated articles over the web, it becomes imperative to develop automated methods that are aware of the ideological-bias implicit in a document collection. While there exist methods that can classify the ideological bias of a given document, little has been done toward understanding the nature of this bias on a topical-level. In this paper we address the problem of modeling ideological perspective on a topical level using a factored topic model. We develop efficient inference algorithms using Collapsed Gibbs sampling for posterior inference, and give various evaluations and illustrations of the utility of our model on various document collections with promising results. Finally we give a Metropolis-Hasting inference algorithm for a semi-supervised extension with decent results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Wiebe</author>
<author>T Wilson</author>
<author>M Bell R Bruce</author>
<author>M Martin</author>
</authors>
<title>Learning subjective language.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>3</issue>
<contexts>
<context position="5032" citStr="Wiebe et al., 2004" startWordPosition="792" endWordPosition="795">ed work, and then present our model in Section 3. Then in Section 4, we detail a collapsed Gibbs sampling algorithm for posterior inference. Sections 5 and 6 give details about the dataset used in the evaluation and illustrate the capabilities of our model using both qualitative and quantitative measures. Section 7 describes and evaluates the efficacy of a semi-supervised extension, and finally in Section 8 we conclude and list several directions for future research. 2 Related Work Ideological text is inherently subjective, thus our work is related to the growing area of subjectivity analysis(Wiebe et al., 2004; Riloff et al., 2003). The goal of this area of research is to learn to discriminate between subjective and objective text. In contrast,in modeling ideology, we aim toward contrasting two or more ideological perspectives each of which is subjective in nature. Further more, subjective text can be classified into sentiments which gave rise to a surge of work in automatic opinion mining (Wiebe et al., 2004; Yu and Hatzivassiloglou, 2003; Pang et al., 2002; Turney and Littman, 2003; Popescu and Etzioni, 2005) as well as sentiment 1In this paper, we use the words ideology, view, perspective interc</context>
</contexts>
<marker>Wiebe, Wilson, Bruce, Martin, 2004</marker>
<rawString>J. Wiebe, T. Wilson, R.Bruce, M. Bell, and M. Martin. Learning subjective language. Computational Linguistics, 30(3), 2004.</rawString>
</citation>
<citation valid="false">
<authors>
<author>H Yu</author>
<author>V Hatzivassiloglou</author>
</authors>
<title>Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences.</title>
<booktitle>In Proceedings of EMNLP-2003</booktitle>
<marker>Yu, Hatzivassiloglou, </marker>
<rawString>H. Yu and V. Hatzivassiloglou. Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences. In Proceedings of EMNLP-2003</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
<author>S Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP-2002.</booktitle>
<contexts>
<context position="5489" citStr="Pang et al., 2002" startWordPosition="870" endWordPosition="873">ure research. 2 Related Work Ideological text is inherently subjective, thus our work is related to the growing area of subjectivity analysis(Wiebe et al., 2004; Riloff et al., 2003). The goal of this area of research is to learn to discriminate between subjective and objective text. In contrast,in modeling ideology, we aim toward contrasting two or more ideological perspectives each of which is subjective in nature. Further more, subjective text can be classified into sentiments which gave rise to a surge of work in automatic opinion mining (Wiebe et al., 2004; Yu and Hatzivassiloglou, 2003; Pang et al., 2002; Turney and Littman, 2003; Popescu and Etzioni, 2005) as well as sentiment 1In this paper, we use the words ideology, view, perspective interchangeably to denote the same concept analysis and product review mining (Nasukawa and Yi, 2003; Hu and Liu, 2004; Pang and Lee, 2008; Branavan et al., 2008; Titov and McDonald, 2008; Titov and McDonald, 2008; Mei et al., 2007; Ling et al., 2008). The research goal of sentiment analysis and classification is to identify language used to convey positive and negative opinions, which differs from contrasting two ideological perspectives. While ideology can </context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. In Proceedings of EMNLP-2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
<author>M Littman</author>
</authors>
<title>Measuring praise and criticism: Inference of semantic orientation from association.</title>
<date>2003</date>
<journal>ACM TOIS,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="5515" citStr="Turney and Littman, 2003" startWordPosition="874" endWordPosition="877">ated Work Ideological text is inherently subjective, thus our work is related to the growing area of subjectivity analysis(Wiebe et al., 2004; Riloff et al., 2003). The goal of this area of research is to learn to discriminate between subjective and objective text. In contrast,in modeling ideology, we aim toward contrasting two or more ideological perspectives each of which is subjective in nature. Further more, subjective text can be classified into sentiments which gave rise to a surge of work in automatic opinion mining (Wiebe et al., 2004; Yu and Hatzivassiloglou, 2003; Pang et al., 2002; Turney and Littman, 2003; Popescu and Etzioni, 2005) as well as sentiment 1In this paper, we use the words ideology, view, perspective interchangeably to denote the same concept analysis and product review mining (Nasukawa and Yi, 2003; Hu and Liu, 2004; Pang and Lee, 2008; Branavan et al., 2008; Titov and McDonald, 2008; Titov and McDonald, 2008; Mei et al., 2007; Ling et al., 2008). The research goal of sentiment analysis and classification is to identify language used to convey positive and negative opinions, which differs from contrasting two ideological perspectives. While ideology can be expressed in the form o</context>
</contexts>
<marker>Turney, Littman, 2003</marker>
<rawString>P. Turney and M. Littman. Measuring praise and criticism: Inference of semantic orientation from association. ACM TOIS, 21(4):315346, 2003</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Popescu</author>
<author>O Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP-2005,</booktitle>
<pages>339346</pages>
<contexts>
<context position="5543" citStr="Popescu and Etzioni, 2005" startWordPosition="878" endWordPosition="881"> is inherently subjective, thus our work is related to the growing area of subjectivity analysis(Wiebe et al., 2004; Riloff et al., 2003). The goal of this area of research is to learn to discriminate between subjective and objective text. In contrast,in modeling ideology, we aim toward contrasting two or more ideological perspectives each of which is subjective in nature. Further more, subjective text can be classified into sentiments which gave rise to a surge of work in automatic opinion mining (Wiebe et al., 2004; Yu and Hatzivassiloglou, 2003; Pang et al., 2002; Turney and Littman, 2003; Popescu and Etzioni, 2005) as well as sentiment 1In this paper, we use the words ideology, view, perspective interchangeably to denote the same concept analysis and product review mining (Nasukawa and Yi, 2003; Hu and Liu, 2004; Pang and Lee, 2008; Branavan et al., 2008; Titov and McDonald, 2008; Titov and McDonald, 2008; Mei et al., 2007; Ling et al., 2008). The research goal of sentiment analysis and classification is to identify language used to convey positive and negative opinions, which differs from contrasting two ideological perspectives. While ideology can be expressed in the form of a sentiment toward a given</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>A. Popescu and O. Etzioni. Extracting product features and opinions from reviews. In Proceedings of HLT/EMNLP-2005, pages 339346, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Nasukawa</author>
<author>J Yi</author>
</authors>
<title>Sentiment analysis: Capturing favorability using natural language processing.</title>
<date>2003</date>
<booktitle>In Proceedings of K-CAP,</booktitle>
<contexts>
<context position="5726" citStr="Nasukawa and Yi, 2003" startWordPosition="907" endWordPosition="910">discriminate between subjective and objective text. In contrast,in modeling ideology, we aim toward contrasting two or more ideological perspectives each of which is subjective in nature. Further more, subjective text can be classified into sentiments which gave rise to a surge of work in automatic opinion mining (Wiebe et al., 2004; Yu and Hatzivassiloglou, 2003; Pang et al., 2002; Turney and Littman, 2003; Popescu and Etzioni, 2005) as well as sentiment 1In this paper, we use the words ideology, view, perspective interchangeably to denote the same concept analysis and product review mining (Nasukawa and Yi, 2003; Hu and Liu, 2004; Pang and Lee, 2008; Branavan et al., 2008; Titov and McDonald, 2008; Titov and McDonald, 2008; Mei et al., 2007; Ling et al., 2008). The research goal of sentiment analysis and classification is to identify language used to convey positive and negative opinions, which differs from contrasting two ideological perspectives. While ideology can be expressed in the form of a sentiment toward a given topic,like abortion, ideological perspectives are reflected in many ways other than sentiments as we will illustrate later in the paper. Perhaps more related to this paper is the wor</context>
</contexts>
<marker>Nasukawa, Yi, 2003</marker>
<rawString>T. Nasukawa and J. Yi. Sentiment analysis: Capturing favorability using natural language processing. In Proceedings of K-CAP, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hu</author>
<author>B Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of KDD,</booktitle>
<contexts>
<context position="5744" citStr="Hu and Liu, 2004" startWordPosition="911" endWordPosition="914">bjective and objective text. In contrast,in modeling ideology, we aim toward contrasting two or more ideological perspectives each of which is subjective in nature. Further more, subjective text can be classified into sentiments which gave rise to a surge of work in automatic opinion mining (Wiebe et al., 2004; Yu and Hatzivassiloglou, 2003; Pang et al., 2002; Turney and Littman, 2003; Popescu and Etzioni, 2005) as well as sentiment 1In this paper, we use the words ideology, view, perspective interchangeably to denote the same concept analysis and product review mining (Nasukawa and Yi, 2003; Hu and Liu, 2004; Pang and Lee, 2008; Branavan et al., 2008; Titov and McDonald, 2008; Titov and McDonald, 2008; Mei et al., 2007; Ling et al., 2008). The research goal of sentiment analysis and classification is to identify language used to convey positive and negative opinions, which differs from contrasting two ideological perspectives. While ideology can be expressed in the form of a sentiment toward a given topic,like abortion, ideological perspectives are reflected in many ways other than sentiments as we will illustrate later in the paper. Perhaps more related to this paper is the work of (Fortuna et a</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>M. Hu and B. Liu. Mining and summarizing customer reviews. In Proceedings of KDD, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<volume>2</volume>
<issue>12</issue>
<pages>1135</pages>
<contexts>
<context position="5764" citStr="Pang and Lee, 2008" startWordPosition="915" endWordPosition="918">tive text. In contrast,in modeling ideology, we aim toward contrasting two or more ideological perspectives each of which is subjective in nature. Further more, subjective text can be classified into sentiments which gave rise to a surge of work in automatic opinion mining (Wiebe et al., 2004; Yu and Hatzivassiloglou, 2003; Pang et al., 2002; Turney and Littman, 2003; Popescu and Etzioni, 2005) as well as sentiment 1In this paper, we use the words ideology, view, perspective interchangeably to denote the same concept analysis and product review mining (Nasukawa and Yi, 2003; Hu and Liu, 2004; Pang and Lee, 2008; Branavan et al., 2008; Titov and McDonald, 2008; Titov and McDonald, 2008; Mei et al., 2007; Ling et al., 2008). The research goal of sentiment analysis and classification is to identify language used to convey positive and negative opinions, which differs from contrasting two ideological perspectives. While ideology can be expressed in the form of a sentiment toward a given topic,like abortion, ideological perspectives are reflected in many ways other than sentiments as we will illustrate later in the paper. Perhaps more related to this paper is the work of (Fortuna et al., 2008; Lin et al.</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>B. Pang and L. Lee. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(12), 1135, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Branavan</author>
<author>H Chen</author>
<author>J Eisenstein</author>
<author>R Barzilay</author>
</authors>
<title>Learning Document-Level Semantic Properties from Free-text Annotations,</title>
<date>2008</date>
<booktitle>Proceedings of ACL,</booktitle>
<contexts>
<context position="5787" citStr="Branavan et al., 2008" startWordPosition="919" endWordPosition="922">st,in modeling ideology, we aim toward contrasting two or more ideological perspectives each of which is subjective in nature. Further more, subjective text can be classified into sentiments which gave rise to a surge of work in automatic opinion mining (Wiebe et al., 2004; Yu and Hatzivassiloglou, 2003; Pang et al., 2002; Turney and Littman, 2003; Popescu and Etzioni, 2005) as well as sentiment 1In this paper, we use the words ideology, view, perspective interchangeably to denote the same concept analysis and product review mining (Nasukawa and Yi, 2003; Hu and Liu, 2004; Pang and Lee, 2008; Branavan et al., 2008; Titov and McDonald, 2008; Titov and McDonald, 2008; Mei et al., 2007; Ling et al., 2008). The research goal of sentiment analysis and classification is to identify language used to convey positive and negative opinions, which differs from contrasting two ideological perspectives. While ideology can be expressed in the form of a sentiment toward a given topic,like abortion, ideological perspectives are reflected in many ways other than sentiments as we will illustrate later in the paper. Perhaps more related to this paper is the work of (Fortuna et al., 2008; Lin et al., 2008) whose goal is t</context>
</contexts>
<marker>Branavan, Chen, Eisenstein, Barzilay, 2008</marker>
<rawString>S. Branavan, H. Chen, J. Eisenstein and R. Barzilay. Learning Document-Level Semantic Properties from Free-text Annotations, Proceedings of ACL, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>R McDonald</author>
</authors>
<title>Modeling Online Reviews with Multi-Grain Topic Models International World Wide Web Conference (WWW),</title>
<date>2008</date>
<contexts>
<context position="5813" citStr="Titov and McDonald, 2008" startWordPosition="923" endWordPosition="926">, we aim toward contrasting two or more ideological perspectives each of which is subjective in nature. Further more, subjective text can be classified into sentiments which gave rise to a surge of work in automatic opinion mining (Wiebe et al., 2004; Yu and Hatzivassiloglou, 2003; Pang et al., 2002; Turney and Littman, 2003; Popescu and Etzioni, 2005) as well as sentiment 1In this paper, we use the words ideology, view, perspective interchangeably to denote the same concept analysis and product review mining (Nasukawa and Yi, 2003; Hu and Liu, 2004; Pang and Lee, 2008; Branavan et al., 2008; Titov and McDonald, 2008; Titov and McDonald, 2008; Mei et al., 2007; Ling et al., 2008). The research goal of sentiment analysis and classification is to identify language used to convey positive and negative opinions, which differs from contrasting two ideological perspectives. While ideology can be expressed in the form of a sentiment toward a given topic,like abortion, ideological perspectives are reflected in many ways other than sentiments as we will illustrate later in the paper. Perhaps more related to this paper is the work of (Fortuna et al., 2008; Lin et al., 2008) whose goal is to detect bias in news arti</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>I. Titov and R. McDonald. Modeling Online Reviews with Multi-Grain Topic Models International World Wide Web Conference (WWW), 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>R McDonald</author>
</authors>
<title>A Joint Model of Text and Aspect Ratings for Sentiment Summarization Association for Computational Linguistics (ACL),</title>
<date>2008</date>
<contexts>
<context position="5813" citStr="Titov and McDonald, 2008" startWordPosition="923" endWordPosition="926">, we aim toward contrasting two or more ideological perspectives each of which is subjective in nature. Further more, subjective text can be classified into sentiments which gave rise to a surge of work in automatic opinion mining (Wiebe et al., 2004; Yu and Hatzivassiloglou, 2003; Pang et al., 2002; Turney and Littman, 2003; Popescu and Etzioni, 2005) as well as sentiment 1In this paper, we use the words ideology, view, perspective interchangeably to denote the same concept analysis and product review mining (Nasukawa and Yi, 2003; Hu and Liu, 2004; Pang and Lee, 2008; Branavan et al., 2008; Titov and McDonald, 2008; Titov and McDonald, 2008; Mei et al., 2007; Ling et al., 2008). The research goal of sentiment analysis and classification is to identify language used to convey positive and negative opinions, which differs from contrasting two ideological perspectives. While ideology can be expressed in the form of a sentiment toward a given topic,like abortion, ideological perspectives are reflected in many ways other than sentiments as we will illustrate later in the paper. Perhaps more related to this paper is the work of (Fortuna et al., 2008; Lin et al., 2008) whose goal is to detect bias in news arti</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>I. Titov and R. McDonald. A Joint Model of Text and Aspect Ratings for Sentiment Summarization Association for Computational Linguistics (ACL), 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Mei</author>
<author>X Ling</author>
<author>M Wondra</author>
<author>H Su</author>
</authors>
<title>ChengXiang Zhai. Topic Sentiment Mixture: Modeling Facets and Opinions in Weblogs,</title>
<date>2007</date>
<booktitle>Proceedings of the 16th International World Wide Web Conference (WWW),</booktitle>
<pages>171--180</pages>
<contexts>
<context position="5857" citStr="Mei et al., 2007" startWordPosition="931" endWordPosition="934">perspectives each of which is subjective in nature. Further more, subjective text can be classified into sentiments which gave rise to a surge of work in automatic opinion mining (Wiebe et al., 2004; Yu and Hatzivassiloglou, 2003; Pang et al., 2002; Turney and Littman, 2003; Popescu and Etzioni, 2005) as well as sentiment 1In this paper, we use the words ideology, view, perspective interchangeably to denote the same concept analysis and product review mining (Nasukawa and Yi, 2003; Hu and Liu, 2004; Pang and Lee, 2008; Branavan et al., 2008; Titov and McDonald, 2008; Titov and McDonald, 2008; Mei et al., 2007; Ling et al., 2008). The research goal of sentiment analysis and classification is to identify language used to convey positive and negative opinions, which differs from contrasting two ideological perspectives. While ideology can be expressed in the form of a sentiment toward a given topic,like abortion, ideological perspectives are reflected in many ways other than sentiments as we will illustrate later in the paper. Perhaps more related to this paper is the work of (Fortuna et al., 2008; Lin et al., 2008) whose goal is to detect bias in news articles via discriminative and generative appro</context>
</contexts>
<marker>Mei, Ling, Wondra, Su, 2007</marker>
<rawString>Q. Mei, X. Ling, M. Wondra, H. Su, ChengXiang Zhai. Topic Sentiment Mixture: Modeling Facets and Opinions in Weblogs, Proceedings of the 16th International World Wide Web Conference (WWW), pages 171-180, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Ling</author>
<author>Q Mei</author>
<author>C Zhai</author>
<author>B Schatz</author>
</authors>
<title>Mining MultiFaceted Overviews of Arbitrary Topics in a Text Collection,</title>
<date>2008</date>
<booktitle>Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’ 08),</booktitle>
<pages>497--505</pages>
<contexts>
<context position="5877" citStr="Ling et al., 2008" startWordPosition="935" endWordPosition="938">of which is subjective in nature. Further more, subjective text can be classified into sentiments which gave rise to a surge of work in automatic opinion mining (Wiebe et al., 2004; Yu and Hatzivassiloglou, 2003; Pang et al., 2002; Turney and Littman, 2003; Popescu and Etzioni, 2005) as well as sentiment 1In this paper, we use the words ideology, view, perspective interchangeably to denote the same concept analysis and product review mining (Nasukawa and Yi, 2003; Hu and Liu, 2004; Pang and Lee, 2008; Branavan et al., 2008; Titov and McDonald, 2008; Titov and McDonald, 2008; Mei et al., 2007; Ling et al., 2008). The research goal of sentiment analysis and classification is to identify language used to convey positive and negative opinions, which differs from contrasting two ideological perspectives. While ideology can be expressed in the form of a sentiment toward a given topic,like abortion, ideological perspectives are reflected in many ways other than sentiments as we will illustrate later in the paper. Perhaps more related to this paper is the work of (Fortuna et al., 2008; Lin et al., 2008) whose goal is to detect bias in news articles via discriminative and generative approaches, respectively.</context>
</contexts>
<marker>Ling, Mei, Zhai, Schatz, 2008</marker>
<rawString>X. Ling, Q. Mei, C. Zhai, B. Schatz. Mining MultiFaceted Overviews of Arbitrary Topics in a Text Collection, Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’ 08), pages 497-505, 2008</rawString>
</citation>
<citation valid="false">
<authors>
<author>C Galleguillos</author>
<author>N Cristianini</author>
</authors>
<title>Detecting the bias in media with statistical learning methods. In: Text Mining: Theory and Applications. Taylor and Francis Publisher,2008.</title>
<marker>Galleguillos, Cristianini, </marker>
<rawString>B. Fortuna , C. Galleguillos, N. Cristianini. Detecting the bias in media with statistical learning methods. In: Text Mining: Theory and Applications. Taylor and Francis Publisher,2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Lin</author>
<author>E P Xing</author>
<author>A Hauptmann</author>
</authors>
<title>A Joint Topic and Perspective Model for Ideological</title>
<date>2008</date>
<booktitle>Discourse European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML/PKDD),</booktitle>
<contexts>
<context position="6371" citStr="Lin et al., 2008" startWordPosition="1017" endWordPosition="1020"> Lee, 2008; Branavan et al., 2008; Titov and McDonald, 2008; Titov and McDonald, 2008; Mei et al., 2007; Ling et al., 2008). The research goal of sentiment analysis and classification is to identify language used to convey positive and negative opinions, which differs from contrasting two ideological perspectives. While ideology can be expressed in the form of a sentiment toward a given topic,like abortion, ideological perspectives are reflected in many ways other than sentiments as we will illustrate later in the paper. Perhaps more related to this paper is the work of (Fortuna et al., 2008; Lin et al., 2008) whose goal is to detect bias in news articles via discriminative and generative approaches, respectively. However, this work still addresses ideology at an abstract level as opposed to our approach of modeling ideology at a topical level. Finally, independently, (Paul and Girju, 2009) gives a construction similar to ours however for a different task 2. 3 Multi-View Topic Models In this section we introduce multi-view topic models, or mview-LDA for short. Our model, mviewLDA, views each document as the result of the interaction between its topical and idealogical dimensions. The model seeks to</context>
<context position="18220" citStr="Lin et al., 2008" startWordPosition="3076" endWordPosition="3079">set The bitterlemons corpus consists of the articles published on the website http://bitterlemons.org/. The website is set up to contribute to mutual understanding between Palestinians and Israelis through the open exchange of ideas. Every week, an issue about the Israeli-Palestinian conflict is selected for discussion, and a Palestinian editor and an Israeli editor contribute one article each addressing the issue. In addition, the Israeli and Palestinian editors invite one Israeli and one Palestinian to express their views on the issue. The data was collected and pre-proceed as describes in (Lin et al., 2008). Overall, the dataset contains 297 documents written from the Israeli’s point of view, and 297 documents written from the Palestinian’s point of view. On average each document contains around 740 words. After trimming words appearing less than 5 times, we ended up with a vocabulary size of 4100 words. We split the dataset randomly and used 80% of the documents for training and the rest for testing. 5.2 The Political Blog Datasets The first dataset refereed to as Blog-1 is a subset of the data collected and processed in (Yano et al., 2009). The authors in (Yano et al., 2009) collected blog pos</context>
</contexts>
<marker>Lin, Xing, Hauptmann, 2008</marker>
<rawString>W. Lin, E.P. Xing, and A. Hauptmann. A Joint Topic and Perspective Model for Ideological Discourse European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML/PKDD), 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T A Van Dijk</author>
</authors>
<title>Ideology: A multidisciplinary approach.</title>
<date>1998</date>
<publisher>Sage Publications,</publisher>
<marker>Van Dijk, 1998</marker>
<rawString>T. A. Van Dijk. Ideology: A multidisciplinary approach. Sage Publications, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Griffiths</author>
<author>M</author>
</authors>
<title>Steyvers Finding scientific topics.PNAS,</title>
<date>2004</date>
<pages>101--5228</pages>
<marker>Griffiths, M, 2004</marker>
<rawString>T. Griffiths, M. Steyvers Finding scientific topics.PNAS, 101:5228-5235, 2004.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Gelman</author>
<author>J Carlin</author>
<author>Hal Stern</author>
<author>Donald Rubin</author>
</authors>
<journal>Bayesian Data Analysis, Chapman-Hall,</journal>
<volume>2</volume>
<pages>2003</pages>
<marker>Gelman, Carlin, Stern, Rubin, </marker>
<rawString>A. Gelman, J. Carlin, Hal Stern, and Donald Rubin. Bayesian Data Analysis, Chapman-Hall, 2 edition,2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blei</author>
<author>A Ng</author>
<author>M Jordan</author>
</authors>
<title>Latent Dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--9931022</pages>
<contexts>
<context position="4074" citStr="Blei et al., 2003" startWordPosition="636" endWordPosition="639">50, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics • Classification or Ideology Identification. Given a document, we would like to tell the user from which side it was written, and explain the ideological bias in the document at a topical level. • Staying Informed: Getting alternative views1. Given a document written from perspective A, we would like the model to provide the user with other documents that represent alternative views about the same topic addressed in the original document. In this paper, we approach this problem using Topic Models (Blei et al., 2003). We introduce a factored topic model that we call multi-view Latent Dirichlet Allocation or mview-LDA for short. Our model views the word content of each document as the result of the interaction between the document’s idealogical and topical dimensions. The rest of this paper is organized as follows. First, in Section 2, we review related work, and then present our model in Section 3. Then in Section 4, we detail a collapsed Gibbs sampling algorithm for posterior inference. Sections 5 and 6 give details about the dataset used in the evaluation and illustrate the capabilities of our model usi</context>
<context position="37360" citStr="Blei et al., 2003" startWordPosition="6313" endWordPosition="6316">ree set of topics: ideology-specific, topic-specific, and ideology-topic ones. We showed that the resulting representation can be used to give a bird-eyes’ view to where each ideology stands with regard to mainstream topics. Moreover, we illustrated how the latent structure induced by the model can by used to perform bias-detection at the document and topic level, and retrieve documents that represent alternative views. It is important to mention that our model induces a hierarchical structure over the topics, and thus it is interesting to contrast it with hierarchical topic models like hLDA (Blei et al., 2003) and PAM (Li and McCallum, 2006; Mimno et al., 2007). First, these models are unsupervised in nature, while our model is supervised. Second, the semantic of the hierarchical structure in our model is different than the one induced by those models since documents in our model are constrained to use a specific portion of the topic structure while in those models documents can freely sample words from any topic. Finally,in the future we plan to extend our model to perform joint modeling and summarization of idealogical discourse. 9 Acknowledgment We thank Jacob Eisenstein, John Lafferty, Tom Mitc</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>D. Blei, A. Ng, and M. Jordan. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:9931022, January 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Yano</author>
<author>W W Cohen</author>
<author>N A Smith</author>
</authors>
<title>Predicting Response to Political Blog Posts with Topic Models.</title>
<date>2009</date>
<booktitle>NAACL-HLT 2009,</booktitle>
<location>Boulder, CO, MayJune</location>
<contexts>
<context position="18765" citStr="Yano et al., 2009" startWordPosition="3169" endWordPosition="3172">The data was collected and pre-proceed as describes in (Lin et al., 2008). Overall, the dataset contains 297 documents written from the Israeli’s point of view, and 297 documents written from the Palestinian’s point of view. On average each document contains around 740 words. After trimming words appearing less than 5 times, we ended up with a vocabulary size of 4100 words. We split the dataset randomly and used 80% of the documents for training and the rest for testing. 5.2 The Political Blog Datasets The first dataset refereed to as Blog-1 is a subset of the data collected and processed in (Yano et al., 2009). The authors in (Yano et al., 2009) collected blog posts from blog sites focusing on American politics during the period November 2007 to October 2008. We selected three blog sites from this dataset: the Right Wing News (right-ideology) ; the Carpetbagger, and Daily Kos as representatives Ew0(CV W vw0,−n + α1) DK Cdk,−n + α2 Ek0(CDK dk0,−n + α2) P(xn,1 = 0, x2,n = 0, zn = k|wn = w, vd = v) ∝ (CDX1 ,−n 2 d0,−n + b1) × CKX2 + CKX2 + a2 + b k1 k0 ,−n ,−n 2 CKX2 + b k0 V KW × Cvkw,−n + α1 × DK Cdk,−n + α2 EDK k0(Cdk 0,− n + α2) E w0(CV KW vkw0,−n + α1) 1144 Israeli View US role Palestinian View I</context>
<context position="21550" citStr="Yano et al., 2009" startWordPosition="3594" endWordPosition="3597">t way government people time year force negotiation Figure 2: Illustrating the big picture overview over the bitterlemons dataset using few topics. Each box lists the top words in the corresponding multinomial topic distribution. See text for more details of the liberal view (left-ideology). After trimming short posts of less than 20 words, we ended up with 2040 posts distributed as 1400 from the left-wing and the rest from the right-wing. On average, each post contains around 100 words and the total size of the vocabulary is 14276 words. For this dataset, we followed the train-test split in (Yano et al., 2009). In this split each blog is represented in both training and test sets. Thus this dataset does not measure the model’s ability to generalize to a totally different writing style. The second dataset refereed to as Blog-2 is similar to Blog-1 in its topical content and time frame but larger in its blog coverage (Eisenstein and Xing, 2010). Blog-2 spans 6 blogs: three from the leftwing and three from the right-wing. The dataset contains 13246 posts. After removing words that appear less then 20 times, the total vocabulary becomes 13236 with an average of 200 words per post. We used 4 blogs (2 fr</context>
</contexts>
<marker>Yano, Cohen, Smith, 2009</marker>
<rawString>T. Yano, W. W. Cohen, and N. A. Smith. Predicting Response to Political Blog Posts with Topic Models. NAACL-HLT 2009, Boulder, CO, MayJune 2009</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisenstein</author>
<author>E P</author>
</authors>
<date>2010</date>
<tech>Xing.The CMU-2008 Political Blog Corpus. CMU-ML-10-101 Technical Report,</tech>
<marker>Eisenstein, P, 2010</marker>
<rawString>J. Eisenstein and E.P. Xing.The CMU-2008 Political Blog Corpus. CMU-ML-10-101 Technical Report, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Wang</author>
<author>D Blei</author>
<author>L Fei-Fei</author>
</authors>
<title>Simultaneous image classification and annotation. CVPR,</title>
<date>2010</date>
<publisher>NIPS,</publisher>
<marker>Wang, Blei, Fei-Fei, 2010</marker>
<rawString>C. Wang, D. Blei and L. Fei-Fei. Simultaneous image classification and annotation. CVPR, 2010. D. Blei and J. McAuliffe. Supervised topic models. NIPS, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Lacoste-Julien</author>
<author>F Sha</author>
<author>M Jordan</author>
</authors>
<title>DiscLDA: Discriminative Learning for Dimensionality Reduction and Classification.</title>
<date>2008</date>
<booktitle>Neural Information Processing Systems Conference (NIPS08),</booktitle>
<location>Vancouver, British Columbia,</location>
<contexts>
<context position="26218" citStr="Lacoste-Julien et al., 2008" startWordPosition="4384" endWordPosition="4387">ceeded as follows. We train a model over the training data with various number of topics. Then given a test document, we predict its ideology using the following equation: vd = argmax„EVP(wdjv); (1) We use three baselines. The first baseline is an SVM classifier trained on the normalized word frequency of each document. We trained SVM using a regularization parameter in the range 11, 10, 20, · · · ,100} and report the best result (i.e. no cross-validation was performed). The other two are supervised LDA models: supervised LDA (sLDA) (Wang et. al., 2009; Blei and McCauliffe, 2007) and discLDA (Lacoste-Julien et al., 2008). discLDA is a conditional model that divides the available number of topics into class-specific topics and shared-topics. Since the code is not publicly available, we followed the same strategy in the original paper and share 0.1K topics across ideologies and then divide the rest of the topics between ideologies4. However, unlike our model, there are no internal relationships between these two sets of topics. The decision rule employed by discLDA is very similar to the one we used for mview-LDA in Eq (1). For sLDA, we used the publicly available code by the authors. As shown in Figure 3, our </context>
<context position="27639" citStr="Lacoste-Julien et al., 2008" startWordPosition="4624" endWordPosition="4627">ultinomials. Moreover, it is evident from the figure that the experiment over the blog2 dataset which measures each model’s ability to generalizes to a totally unseen new blog is a harder task than generalizing to unseen posts form the same blog. However, our model still performs competitively with the SVM baseline. We believe that separating each topic into an ideology-independent part and ideology-specific part is the key behind this performance, as it is expected that the new blogs would still share much of the ideology-independent parts of the topics and hopefully would use similar (but 4(Lacoste-Julien et al., 2008) gave an optimization algorithm for learning the topic structure (transformation matrix), however since the code is not available, we resorted to one of the fixed splitting strategies mentioned in the paper. We tried other splits but this one gives the best results 1146 (a) (b) (c) Figure 3: Classification accuracy over the Bitterlemons dataset in (a) and over the two blog datasets in (b) and (c). For SVM we give the best result obtained across a wide range of the SVM’s regularization parameter(not the cross-validation result). no necessarily all) words from the ideology-specific parts of each</context>
</contexts>
<marker>Lacoste-Julien, Sha, Jordan, 2008</marker>
<rawString>S. Lacoste-Julien, F. Sha, and M. Jordan. DiscLDA: Discriminative Learning for Dimensionality Reduction and Classification. Neural Information Processing Systems Conference (NIPS08), Vancouver, British Columbia, December 2008.</rawString>
</citation>
<citation valid="false">
<authors>
<author>E Riloff</author>
<author>J Wiebe</author>
<author>T Wilson</author>
</authors>
<title>Learning subjective nouns using extraction pattern bootstrapping.</title>
<booktitle>In Proceedings of CoNLL-2003.</booktitle>
<marker>Riloff, Wiebe, Wilson, </marker>
<rawString>E. Riloff, J. Wiebe, and T. Wilson. Learning subjective nouns using extraction pattern bootstrapping. In Proceedings of CoNLL-2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blei</author>
<author>T Griffiths</author>
<author>M Jordan</author>
<author>J Tenenbaum</author>
</authors>
<title>Hierarchical topic models and the nested Chinese restaurant process.</title>
<date>2003</date>
<booktitle>In Neural Information Processing Systems (NIPS)16,</booktitle>
<contexts>
<context position="4074" citStr="Blei et al., 2003" startWordPosition="636" endWordPosition="639">50, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics • Classification or Ideology Identification. Given a document, we would like to tell the user from which side it was written, and explain the ideological bias in the document at a topical level. • Staying Informed: Getting alternative views1. Given a document written from perspective A, we would like the model to provide the user with other documents that represent alternative views about the same topic addressed in the original document. In this paper, we approach this problem using Topic Models (Blei et al., 2003). We introduce a factored topic model that we call multi-view Latent Dirichlet Allocation or mview-LDA for short. Our model views the word content of each document as the result of the interaction between the document’s idealogical and topical dimensions. The rest of this paper is organized as follows. First, in Section 2, we review related work, and then present our model in Section 3. Then in Section 4, we detail a collapsed Gibbs sampling algorithm for posterior inference. Sections 5 and 6 give details about the dataset used in the evaluation and illustrate the capabilities of our model usi</context>
<context position="37360" citStr="Blei et al., 2003" startWordPosition="6313" endWordPosition="6316">ree set of topics: ideology-specific, topic-specific, and ideology-topic ones. We showed that the resulting representation can be used to give a bird-eyes’ view to where each ideology stands with regard to mainstream topics. Moreover, we illustrated how the latent structure induced by the model can by used to perform bias-detection at the document and topic level, and retrieve documents that represent alternative views. It is important to mention that our model induces a hierarchical structure over the topics, and thus it is interesting to contrast it with hierarchical topic models like hLDA (Blei et al., 2003) and PAM (Li and McCallum, 2006; Mimno et al., 2007). First, these models are unsupervised in nature, while our model is supervised. Second, the semantic of the hierarchical structure in our model is different than the one induced by those models since documents in our model are constrained to use a specific portion of the topic structure while in those models documents can freely sample words from any topic. Finally,in the future we plan to extend our model to perform joint modeling and summarization of idealogical discourse. 9 Acknowledgment We thank Jacob Eisenstein, John Lafferty, Tom Mitc</context>
</contexts>
<marker>Blei, Griffiths, Jordan, Tenenbaum, 2003</marker>
<rawString>D. Blei, T. Griffiths, M. Jordan, and J. Tenenbaum. Hierarchical topic models and the nested Chinese restaurant process. In Neural Information Processing Systems (NIPS)16, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Mimno</author>
<author>W Li</author>
<author>A McCallum</author>
</authors>
<title>Mixtures of Hierarchical Topics with Pachinko Allocation.</title>
<date>2007</date>
<booktitle>In International Conference of Machine Learning, ICML,</booktitle>
<contexts>
<context position="37412" citStr="Mimno et al., 2007" startWordPosition="6323" endWordPosition="6326">c, and ideology-topic ones. We showed that the resulting representation can be used to give a bird-eyes’ view to where each ideology stands with regard to mainstream topics. Moreover, we illustrated how the latent structure induced by the model can by used to perform bias-detection at the document and topic level, and retrieve documents that represent alternative views. It is important to mention that our model induces a hierarchical structure over the topics, and thus it is interesting to contrast it with hierarchical topic models like hLDA (Blei et al., 2003) and PAM (Li and McCallum, 2006; Mimno et al., 2007). First, these models are unsupervised in nature, while our model is supervised. Second, the semantic of the hierarchical structure in our model is different than the one induced by those models since documents in our model are constrained to use a specific portion of the topic structure while in those models documents can freely sample words from any topic. Finally,in the future we plan to extend our model to perform joint modeling and summarization of idealogical discourse. 9 Acknowledgment We thank Jacob Eisenstein, John Lafferty, Tom Mitchell, and the anonymous reviewers for their helpful </context>
</contexts>
<marker>Mimno, Li, McCallum, 2007</marker>
<rawString>D. Mimno, W. Li and A. McCallum. Mixtures of Hierarchical Topics with Pachinko Allocation. In International Conference of Machine Learning, ICML, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Li</author>
<author>A McCallum</author>
</authors>
<title>Pachinko Allocation: DAGstructured Mixture Models of Topic Correlations.</title>
<date>2006</date>
<booktitle>In International Conference of Machine Learning, ICML,</booktitle>
<contexts>
<context position="37391" citStr="Li and McCallum, 2006" startWordPosition="6319" endWordPosition="6322">specific, topic-specific, and ideology-topic ones. We showed that the resulting representation can be used to give a bird-eyes’ view to where each ideology stands with regard to mainstream topics. Moreover, we illustrated how the latent structure induced by the model can by used to perform bias-detection at the document and topic level, and retrieve documents that represent alternative views. It is important to mention that our model induces a hierarchical structure over the topics, and thus it is interesting to contrast it with hierarchical topic models like hLDA (Blei et al., 2003) and PAM (Li and McCallum, 2006; Mimno et al., 2007). First, these models are unsupervised in nature, while our model is supervised. Second, the semantic of the hierarchical structure in our model is different than the one induced by those models since documents in our model are constrained to use a specific portion of the topic structure while in those models documents can freely sample words from any topic. Finally,in the future we plan to extend our model to perform joint modeling and summarization of idealogical discourse. 9 Acknowledgment We thank Jacob Eisenstein, John Lafferty, Tom Mitchell, and the anonymous reviewe</context>
</contexts>
<marker>Li, McCallum, 2006</marker>
<rawString>W. Li, and A. McCallum. Pachinko Allocation: DAGstructured Mixture Models of Topic Correlations. In International Conference of Machine Learning, ICML, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Paul</author>
<author>R Girju</author>
</authors>
<title>Cross-cultural Analysis of Blogs and Forums with Mixed-Collection Topic Models. EMNLP</title>
<date>2009</date>
<contexts>
<context position="6657" citStr="Paul and Girju, 2009" startWordPosition="1063" endWordPosition="1066">ing two ideological perspectives. While ideology can be expressed in the form of a sentiment toward a given topic,like abortion, ideological perspectives are reflected in many ways other than sentiments as we will illustrate later in the paper. Perhaps more related to this paper is the work of (Fortuna et al., 2008; Lin et al., 2008) whose goal is to detect bias in news articles via discriminative and generative approaches, respectively. However, this work still addresses ideology at an abstract level as opposed to our approach of modeling ideology at a topical level. Finally, independently, (Paul and Girju, 2009) gives a construction similar to ours however for a different task 2. 3 Multi-View Topic Models In this section we introduce multi-view topic models, or mview-LDA for short. Our model, mviewLDA, views each document as the result of the interaction between its topical and idealogical dimensions. The model seeks to explain lexical variabilities in the document by attributing this variabilities to one of those dimensions or to their interactions. Topic models, like LDA, define a generative process for a document collection based on a set of parameters. LDA employs a semantic entity known as topic</context>
</contexts>
<marker>Paul, Girju, 2009</marker>
<rawString>M. Paul and R. Girju. Cross-cultural Analysis of Blogs and Forums with Mixed-Collection Topic Models. EMNLP 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Wallach</author>
<author>I Murray</author>
<author>R Salakhutdinov</author>
<author>D Mimno</author>
</authors>
<title>Evaluation Methods for Topic Models. ICML</title>
<date>2009</date>
<contexts>
<context position="36010" citStr="Wallach et al., 2009" startWordPosition="6093" endWordPosition="6096">erations of a restricted Gibbs scan over the document d conditioned on fixing vd = v* and then take the last sample jointly with v* as our proposed new state. With probability min(r,1), the new state (v*, x1*, x2*, z*) is accepted, otherwise the old state is retained. The acceptance ratio,r, is computed as: r = p(Wd|v∗,X1∗,X2∗,Z∗), where the non-* p(Wd |v,X1,X2,Z) variables represent the current state of the sampler. It is interesting to note that the above acceptance ratio is equivalent to a likelihood ratio test. We compute the marginal probability P(wd|..) using the estimated-theta method (Wallach et al., 2009). We evaluated the semi-supervised extension using the blog-2 dataset as follows. We reveal R% of the labels in the training set; then we train mview-LDA only over the labeled portion and train the semisupervised version (ss-mview-LDA) on both the labeled and unlabeled documents. Finally we evaluate the classification performance on the test set. We used R = 120, 40, 801. The results are given in Table 1 which shows a decent improvement over the supervised mview-LDA. 8 Discussion and Future Work In this paper, we addressed the problem of modeling ideological perspective at a topical level. We </context>
</contexts>
<marker>Wallach, Murray, Salakhutdinov, Mimno, 2009</marker>
<rawString>H. Wallach, I. Murray, R. Salakhutdinov, and D. Mimno. Evaluation Methods for Topic Models. ICML 2009.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>