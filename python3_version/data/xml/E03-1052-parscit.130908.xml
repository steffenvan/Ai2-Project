<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000602">
<title confidence="0.993332">
Constraint Based Integration of Deep and Shallow Parsing Techniques
</title>
<author confidence="0.994638">
Michael Daum and Kilian A. Foth and Wolfgang Menzel
</author>
<affiliation confidence="0.996147666666667">
Natural Language Systems
Department of Computer Science
University of Hamburg
</affiliation>
<bodyText confidence="0.37539">
(michalfothlwolfgang) @nats . informatik uni-hamburg . de
</bodyText>
<sectionHeader confidence="0.982176" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999923636363636">
To investigate the contributions of tag-
gers or chunkers to the performance
of a deep syntactic parser, Weighted
Constraint Dependency Grammars have
been extended to also take into con-
sideration information from external
sources. Using a weak information fu-
sion scheme based on constraint opti-
mization techniques, a parsing accuracy
has been achieved which is comparable
to other (stochastic) parsers.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999765590909091">
To investigate the contributions of different shal-
low processing components like taggers or chun-
kers to the performance of a deep syntactic
parser, Weighted Constraint Dependency Gram-
mars (WCDG) have been extended to also
take into consideration information from external
sources. Constraints in the WCDG framework
are (partially) defeasible conditions on admissible
structural configurations in a dependency tree for
a given natural language utterance. By defining
conditions (1) on word forms and their positional
relationships, (2) on links between word forms,
and (3) on the labels attached to these links, they
license certain dependency relations or combina-
tions thereof and assign a score to them. These
scores give an estimate of the appropriateness of a
particular partial structure. Constraint optimiza-
tion techniques are used to obtain the structure
with the best overall score, which is chosen as the
optimal representation of the utterance. Due to the
use of weighted constraints throughout the gram-
mar, WCDG comes with a number of advantages:
</bodyText>
<listItem confidence="0.992793684210526">
• A WCDG grammar is able to accomodate
conflicting requirements as they can often
be found in natural language, e.g. in case
of ordering preferences. WCDG shares this
property with Optimality Theory (Prince and
Smolensky, forthc).
• Since constraints can be violated, the gram-
mar also accepts unusual or even deviant in-
put (usually with a lower global score) and
assigns a structural interpretation to it.
• To a large degree a WCDG parser does not
depend crucially on a complete set of con-
straints. Although performance degrades if
some constraints are deactivated, it usually
does so in a graceful manner.
• Constraints offer an ideal interface to inte-
grate external processing components as ad-
ditional sources of evidence into the decision
about the optimal structural interpretation.
</listItem>
<bodyText confidence="0.999939736842105">
It is this last advantage which this paper is fo-
cussing upon. Shallow processing components
like taggers or chunkers can be integrated into the
deep analysis simply by providing additional con-
straints. If a scoring scheme is also available for
such an external contribution (and it usually is),
it can be combined with the internal scores as-
signed by the constraints of the grammar. Sim-
ilar to the arbitration of conflicting requirements
within the grammar itself, the general optimiza-
tion procedure allows the WCDG parser to han-
dle possible conflicts between predictions of dif-
ferent origin. This weak integration of hypotheses
not only makes the approach an ideal platform for
information fusion. Moreover the individual con-
tributions certain information sources make to the
overall performance of the parser can be exactly
measured, simply by switching the corresponding
constraints on or off.
</bodyText>
<page confidence="0.997337">
99
</page>
<bodyText confidence="0.9952765">
2 The WCDG language modelling system
In dependency grammar, syntactic structure is
modelled not by nested constituents but as a set
of direct relations between two words. Usually
an utterance is represented as a tree with as many
nodes as there are words, the finite verb forming
the root of the tree. To express different types
of dependency relations, the vertices are often en-
riched with different labels, e.g. to distinguish sub-
jects from objects.
Instead of giving generative rules about how to
construct a dependency tree, a Constraint depen-
dency grammar declares constraints, i.e. proper-
ties that a well-formed tree should fulfill. Finding
a well-formed syntactic structure takes on the form
of a constraint satisfaction problem (CSP), which
can be solved by a variety of solution methods.
This kind of dependency grammar was introduced
by Maruyama (Maruyama, 1990).
The constraints about well-formedness are no-
tated as logical formulas. A common rule is to
postulate that subjects typically precede their fi-
nite verb and objects follow it. This can be ex-
pressed by requiring that for all edges with the
label `SUBF , the governor must occur to the left
of the modifier, and the inverse for edges labelled
`OBJA&apos;.
Applying these constraints to an example analy-
sis (Figure 1), we see that two of the dependencies
actually violate them. Since this is not incorrect
in German but merely marks a topicalization, it is
useful to gradate the constraints. This is the defin-
ing characteristic of Weighted CDG (Schroder,
2001): The grammar writer can assign different
weights to the constraints to indicate their relative
strength. The weights of violated constraints are
multiplied to obtain the score for an entire depen-
dency tree. Violation of a constraint is tolerated if
no other analysis has a higher overall score. This
property leads to considerable robustness against
ungrammatical or extragrammatical input. Note
that a low figure for the weight corresponds to a
strong constraint, while a high figure (near 1) has
little influence under the multiplicative scheme.
Introducing constraint weights turns the CSP
into a constraint optimization problem, which is
considerably harder to solve, since one particular
solution must be found rather than just one of a
number of solutions. Furthermore, weighted con-
straints do not allow us to prune away an alter-
native, leading to very large search spaces. In
fact, analyzing long sentences with WCDG usu-
ally leads to problems that are too large to be
solved exactly. However, heuristic methods have
been developed that can approximate the opti-
mal solution, where the quality of the solution in-
creases over time as more alternatives are tried
(Foth et al., 2000).
</bodyText>
<sectionHeader confidence="0.997003" genericHeader="method">
3 Experimental setup
</sectionHeader>
<bodyText confidence="0.99984">
For our experiments we analysed 1845 unedited
sentences from German online newscasts on buy-
ing or selling events, with an average length of
24 word forms (see Table 1 for a distribution of
sentence lengths). We employed a handwritten
WCDG of German that aims to perform a very
thorough analysis; in addition to establishing syn-
tax structure, it assigns each dependency one of
28 labels. It must also determine the exact word
class and morphological form of each word. At
the same time the lexicon was kept incomplete; of
the open word classes of German, only the verbs
are modelled while most nouns and adjectives are
not&apos;. Therefore, about 29% of all tokens are effec-
tively unknown words and receive a totally under-
specified representation.
In the experimental setup chosen we run the op-
timization process on each sentence, and interrupt
it if it has not terminated by itself after three min-
utes. In this case, the best dependency structure
established so far is returned as the parsing result.
If no additional knowledge sources (like the tagger
and the chunker) are used the parser terminates by
itself after 134 seconds on average. By the mea-
sure of labelled recall, which counts how many
dependencies are established correctly along with
their labels, only 50.7% recall2 is achieved on the
average; although the WCDG usually assigns the
desired analysis a near-optimal score, this analy-
sis is often not found simply because the problem
</bodyText>
<footnote confidence="0.991645166666667">
1However, nouns and proper names can be recognized au-
tomatically by their capital initials.
2Since all possible dependency analyses for a sentence
have the same number of dependency edges, recall and pre-
cision are always equal for a fully disambiguated tree. The
term accuracy is sometimes used instead.
</footnote>
<page confidence="0.964366">
100
</page>
<figure confidence="0.999564">
COT
---_-_-_-_-_-___
ORJ.
ADV
PART
die Fiff 1712 ganz verkaufen
}?OOT
die
die
Vol stande
nun ziehen
Konsequenzen und
AUX
sind bereft
ROOT
KON
sue1-- oBTA—
DET
</figure>
<figureCaption confidence="0.9428465">
Figure 1: Example of a labelled dependency analysis for a German sentence (Management now bears
the consequences and agrees to sell the company outright.)
</figureCaption>
<bodyText confidence="0.9999106">
space is too large. To measure the effect of the
time limitation on accuracy, we conducted con-
trol experiments with the time limited to 6 minutes
instead for comparison; the corresponding recall
measures are given in Table 2 in brackets. They
show that the time limit is not a great source of
error.
Obviously the parsing process would bene-
fit from additional information about the correct
analysis, even if it is uncertain, as long as it can
be produced with little effort. This is the motiva-
tion behind the following experiments: to integrate
a shallow but efficient information source into a
thorough but slow parser to see whether a net gain
can be achieved.
</bodyText>
<table confidence="0.60719">
length ... 10 ... 20 ... 30 ... 40 ... 50 ... 60 ...
# sentences 160 650 651 274 81 19 10
</table>
<tableCaption confidence="0.994188">
Table 1: Distribution of sentence length.
</tableCaption>
<sectionHeader confidence="0.823092" genericHeader="method">
4 Integration of a tagger
</sectionHeader>
<bodyText confidence="0.9999793">
The most common type of partial language anal-
ysis is part-of-speech tagging: annotating each
word in the input string with its grammatical cate-
gory. In contrast to single tag gers, so-called multi
taggers assign a word different categories with dif-
ferent probabilities. POS tagging is susceptible
to statistical analysis, and very high accuracy has
been reported on well-known corpora.
Since part of the task of WCDG analysis is to
resolve lexical ambiguity, the information com-
piled by a POS tagger is directly helpful: We can
write a constraint that penalizes any mismatch be-
tween the lexical category under consideration and
the category predicted by the tagger. In the case
of multi tagging the penalty is proportional to the
score emitted by the tagger. In single tagging this
algorithm can only assign a constraint weight of 0
or 1, since our tagger does not report the internal
confidence value, so that all but one lexical vari-
ants are actually forbidden entirely. To reduce the
impact of tagging errors in both tagging modes,
the weight of the constraint can be smoothed to en-
sure that all other categories are merely punished
but not eliminated (Foth and Hagenstrom, 2002).
By adding or omitting a single constraint in the
existing dependency grammar, we can accurately
measure how useful the contribution of the POS
tagger is to the parsing process, independently of
how accurate it is. As a first experiment, we sim-
ulated the ideal POS tagger (one which makes no
mistakes at all) by giving the tagging constraint ac-
cess to our manual annotations. Under these ide-
alized conditions, we achieved a labelled recall of
75.8% under the same conditions as before. Also,
processing took only a third of the time necessary
before. Obviously, the POS information is very
useful for solving the optimization problem posed
by the WCDG.
Note that the information introduced by the
POS tagger is not strictly new: The original gram-
mar already contains rules about what syntactic
categories can combine to build larger structures,
and thus the parser already solves the tagging
problem as part of a much harder problem. The
introduction of explicit POS scores simply serves
to guide the parser more quickly toward structures
that are probably part of the optimal analysis.
Since an ideal POS tagger is unavailable, we
then investigated how useful a less accurate but
available information source can be. Among
</bodyText>
<page confidence="0.99449">
101
</page>
<bodyText confidence="0.999707274509804">
the freely available POS taggers for German, the
one that performs best on our corpus of online
newscasts is the statistical Markov tagger Tri-
grams&apos;n&apos;Tags (TnT) (Brants, 2000). Although
trained on a similar corpus of German newspaper
text, even this tagger achieves only 92.3% accu-
racy in multi-tagging mode. One reason for this is
that the distribution of word categories differs con-
siderably between the two corpora: Our sentences
contain ten times as much foreign-language mate-
rial (Fm) as the tagger&apos;s training set, and also more
names (NE), both of which are (in German) very
difficult to distinguish from proper nouns. There-
fore, in many cases the information provided by
the tagger is actually misleading.
However, even though the accuracy of this in-
formation source is comparatively low, the benefit
is still high. Supplying the tagging constraint with
the output of TnT in multi-tagging mode yields
a labelled recall of 73.7%. Comparing experi-
ments 3 and 4 in Table 2 shows that almost the full
benefit of having access to POS information can be
reaped even if the POS tagger is markedly inaccu-
rate. Using TnT in single-tagging mode achieves
only 71.1% recall.
A complication arises because the scores in-
troduced from shallow analysis change the orig-
inal optimization problem. In the extreme case,
if the POS tagger makes a serious error and for-
bids that variant of a word that is part of the de-
sired analysis, a different analysis may become nu-
merically optimal. This means that the optimiza-
tion procedure would not find the preferred analy-
sis even if no search errors ever occurred. But as
noted above, knowledge about syntactic categories
is provided redundantly by the constraint grammar
as well as by the tagger. Errors of the tagger can
thus be partially compensated if the combined ev-
idence of other constraints is sufficient to keep the
linguistically preferred structure optimal.
Also, many typical tagger errors do not affect
the syntactic structure much, e.g. if the tagger
identifies a noun as a proper name. Since both
word classes can fill much the same roles, the new
optimal analysis will be essentially the same as the
old one, except for one lexical selection. Under the
measure of labelled recall, this would not be an er-
ror. Only if a more disruptive error is made does
the structure change drastically. For these reasons,
the benefit of the POS tagger outweighs the cost
of occasional misclassifications.
</bodyText>
<sectionHeader confidence="0.949115" genericHeader="method">
5 Integration of a chunker
</sectionHeader>
<bodyText confidence="0.998432552631578">
Another source of shallow syntactic information
are the partial parsers known as chunk parsers.
The object of these is not to build a complete syn-
tactic structure but only to identify coherent word
sequences of particular types. The typical appli-
cation of chunk parsing is the detection of noun
phrases, e.g. for information extraction.
Simple chunk parsers only determine the ex-
tents of chunks, but neither the interrelationships
between them nor their internal structure. How-
ever, they sometimes try to assign to each chunk
a lexical head which can then represent the entire
chunk. The idea is that once a chunk has been
detected, only its head need be considered for at-
tachment when building the complete syntax tree.
This notion allows us to write useful disam-
biguating constraints. Assume that the constraint
engine knows, for each word, the extent of the
chunk that it belongs to, and the head word of
that chunk. A grammar can then constrain all de-
pendency edges to those that either connect two
chunk heads or attach a word to the head of its
own chunk. Again, this condition can be expressed
with a single unary constraint.
The chunk constraint allows the grammar to
rule out on structural grounds many subordina-
tions that would otherwise appear perfectly rea-
sonable. Consider the case of determiners. Since
German noun phrases can be nested, the distance
between a noun and its determiner can become un-
predictably large. Where several noun phrases oc-
cur in a sentence, this results in a combinatorial
number of possible determiner relations, neither
of which can be ruled out without considering the
whole sentence. If the example sentence from Fig-
ure 1 is divided into chunks, each of the definite
articles can be unambiguously paired with the fol-
lowing noun:
</bodyText>
<table confidence="0.44987775">
Nun/ADV [VC ziehenNVFIN] [NC die/ART Vorstande/
NN] [NC die/ART Konsequenzen/NN] und/KON [VC
sind/VAFIN] bereit/ADJD ,/$, [NC die/ART Firma/NN]
komplett/ADJD [VC zu/PTKZU verkaufen/VVINF] ./$.
</table>
<tableCaption confidence="0.177878">
Thus the ambiguity about determiner attachment
</tableCaption>
<page confidence="0.972461">
102
</page>
<figure confidence="0.998174">
20 30 40 50 60 &gt;60
sentence length
</figure>
<figureCaption confidence="0.99941">
Figure 2: Labelled Recall per problem size.
Figure 3: Labelled Recall of different chunkers.
</figureCaption>
<bodyText confidence="0.974937835820896">
is completely resolved. Many other syntactic rela-
tions can profit from similar reasoning.
To find out how much this additional infor-
mation can contribute to the parsing process, we
first simulated the ideal chunk parser by supplying
our program with the correct chunk boundaries as
present in our gold-standard annotations. As line 7
in Table 2 shows, the syntactic accuracy increases
by about 5 percentage points. Obviously, this is
the upper limit of utility that chunk information
can supply in our case.3
To test the performance of an actual chunk
parser we used the decision-tree based TreeTag-
ger (Schmid, 1994), a freely available tool that is
capable of assigning POS tags and of determining
3The chunk parser actually used in the following experi-
ment requires tagged input to operate so that it is not possible
to test its effect in isolation, i.e. without POS tagging. There-
fore this idealized experiment also employs the TnT tagger.
noun, verb and prepositional chunks in German
text. Since its tagging accuracy is no better than
TnT on our corpus, we only use it to extract chunk
information. When run as a chunk parser for Ger-
man, the TreeTagger correctly recalls 87.4% of the
chunks present in our annotations. The chunks
that it emits are correct in 82.3% of all cases.
Since the TreeTagger does not compute lexical
head words we have to supply simple rules of our
own to insert head markers into its output: in noun
chunks, the leftmost noun or proper name is the
head; in verb chunks, the finite verb is the head;
failing that, the rightmost word is the head; in
prepositional chunks, the preposition is the head.
When enriching the TreeTagger output with
these markers, we have all the necessary infor-
mation to implement the chunk constraint outlined
above. Line 5 in Table 2 shows the results of sup-
plying the grammar with the output of TreeTagger
rather than a perfect chunk parser. It can be seen
that the inaccuracy of its output has a severe im-
pact on parsing accuracy: the benefit on parsing
accuracy of using this chunk parser is only half of
what would theoretically be possible.
The raw precision and recall of the TreeTag-
ger may actually be misleading, since a WCDG
parser does not explicitly establish any chunks.
In fact, many mis-predicted chunk boundaries do
not lead to violation of the chunk constraint and
consequently cause no harm to the parser, other
than not providing a possible benefit. It might be
more reasonable to measure how many spurious
constraint violations are actually caused by errors
of the chunk parser. In the annotations of all test
sentences, 702 out of 44099 syntactic dependency
edges (1.6%) mistakenly trigger the chunker con-
straint because the TreeTagger disagrees with our
annotations. Measured in this way, even an ac-
curacy of 98.4% already halves the utility of the
information.
As distributed, the TreeTagger consistently
makes some questionable judgements that dis-
agree with our grammar. For instance, it always
groups postpositions with the following rather
than the preceding noun phrase. We consider this
a modelling error. Since we could not modify the
TreeTagger itself, we filtered its output through a
finite-state transducer that undoes this and some
</bodyText>
<figure confidence="0.997935966666667">
no tagger
single lagger
idnekroh!JI:rr
real chunker - -
0.7 0.8 0.9
02 03 0.4 0.5 0.6
constraint weight
ideal chunker -
real chunker
augmented chunker
78.59
78%
77.5%
77%
76%
75.5%
75%
74.5 /
0
72, 76.5%
100
90%
80%
70%
7, 60%
50%
40%
30%
20%
10
</figure>
<page confidence="0.995209">
103
</page>
<table confidence="0.999613444444444">
tagger chunker weight rel. time% unlabelled recall% labelled recall%
1 none none 100.0 58.2 50.7
2 single none 35.2 75.7 71.1
3 multi none 44.1 78.2 73.7
4 ideal none 31.0 80.2 75.8
5 multi real 0.4 39.4 80.0 (80.6) 75.7 (76.2)
6 multi augmented 0.0 36.2 79.9 75.5
7 multi ideal 0.0 33.4 82.7 (83.0) 78.3 (78.7)
8 ideal ideal 0.0 22.4 83.9 79.7
</table>
<tableCaption confidence="0.994126">
Table 2: Influence of partial parsing information on the recall of a deep syntax analysis. Numbers in
brackets are for experiments with a relaxed timeout condition.
</tableCaption>
<bodyText confidence="0.8112772">
other incorrect groupings.
There are also some coordinative constructions
that the TreeTagger invariably groups incorrectly,
such as the following:
... [VC vermietet/VVPP] oder/KON [VC verkauft/VVPP
worden/VAPP seienNAFIN]
(...had been rented or sold)
The final verb chunk appears very plausible, but
since our grammar actually groups such coordina-
tions as follows:
</bodyText>
<equation confidence="0.788288">
[[vermietet/V VPP oder/KON verkauft/V VPP] wor-
den/VAPP seienNAFIN]
</equation>
<bodyText confidence="0.999989575">
the obvious choice of verb chunks likewise leads
to a constraint violation. Because coordinative
constructions usually are much more complicated
than this case, it would be difficult to handle them
all in the output filter; instead we add an explicit
exception in the chunker constraint that the com-
plements of conjunctions may cross chunk bound-
aries to the left, thus anticipating the consistent er-
ror of the chunk parser.
With these automatic corrections in place, the
number of chunker constraint violations is reduced
to 477 out of 44099 (1.1%). As can be seen
in line 6 in Table 2, a further benefit of these
automatic corrections cannot be shown; in fact,
they are often counter-productive, since the modi-
fied chunker constraint allows some more correct
edges, but also many more incorrect ones.
A different way of guarding against errors in the
shallow information source would be to assign a
higher score to the constraint that integrates it. If
edges that violate chunk boundaries are discour-
aged rather than forbidden, the other constraints
may eventually override the chunk information if
the evidence is strong enough, as with the integra-
tion of POS information. Of course, this weakens
the positive effect of the information source in all
other cases. Figure 3 shows that while the overall
benefit can be raised for some constraint weights,
the improvement is not great.
The question arises why chunk information as
an information source suffers more from inac-
curacy than POS information, particularly since
some chunker errors do not change the optimiza-
tion problem at all. On the other hand, where an
incorrect POS tag affects primarily one lexical se-
lection, an incorrect chunk bracket can penalize
several correct syntactic edges at once; it usually
forbids the desired structural alternative entirely,
forcing the parser to interpret at least part of a sen-
tence differently in a more fundamental way.
</bodyText>
<sectionHeader confidence="0.99994" genericHeader="evaluation">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999875357142857">
Most current approaches to probabilistic parsing
are based on the output of a tagger. Some systems
parse only the sequence of single best tags (c.f.
(Brants, 1999)). If, however, a lexically sensitive
model is desired, the tagger is invoked only as fall
back solution for unknown words (c.f. (Collins,
1999)). Both solutions differ from the approach
adopted here in that they cannot explicitly mea-
sure the contribution of the tagging results to the
overall performance of the parser.
(Charniak et al., 1996) performes a compari-
son of single tagging (where the tagger provides
a unique tag assignment) to multi-tagging (which
leaves the decision among several possible tags to
</bodyText>
<page confidence="0.997865">
104
</page>
<bodyText confidence="0.999979342105263">
the parser). He concludes that multi-tagging gives
no significant advantage. This result has not been
confirmed by our findings, which indeed show a
small but reliable advantage of multi tagging over
single tagging. The contrast might be explained
by considering the different information sources
used in both cases. (Charniak et al., 1996) com-
bined two purely stochastic models, which prob-
ably capture rather similar kinds of model infor-
mation from their training data, whereas in our
case information of completely different origin has
been brought together. While the tagger is geared
towards exploiting sequential patterns in a sen-
tence, the parser relies more on possible structural
configurations and subcategorization information.
There has also been a number of investigations
on how to integrate chunk-boundary information
into a parsing procedure. For Italian, (Basili et
al., 1998) segment a sentence using a chunker and
a clause boundary detection based on verb sub-
categorization frames. Based on this information
inter-chunk dependencies are computed using a
special purpose parser which is sensitive to the
type of chunks. Recall and precision for inter-
chunk dependencies (not full dependency struc-
tures) of 75.2% and 72.1% respectively have been
achieved on a small test set of 56 sentences (1149
words).
Since chunk-boundary information is ultima-
tively required by the parsing procedure and con-
sidered to be non-defeasible, no figures of merit
are available which would allow estimation of the
contribution of chunk boundaries to the overall be-
haviour of the system.
Such figures have been given, however, for an
architecture which integrates shallow information
(coming from a tagger, a named entity recognizer,
an external semantic database and a topological
parser) by guiding a deep HPSG-parser towards
the most plausible interpretation (Cryssmann et
al., 2002). This approach increased the coverage
of the overall system from 12.5% to 22.1% on the
NEGRA-corpus but failed to reduce the average
number of analyses which even grew from 16.19%
to 18.53% per sentence. In contrast, due to its in-
herent robustness properties our parser always re-
turns the single best solution, i.e. it has a coverage
of 100% and always achieves full disambiguation.
In this respect our approach is more similar to
stochastic parsers. Here, evaluation results for the
analysis of dependency relations have been pub-
lished by (Collins, 1999) among others. In his
parser dependency links can be recovered from the
head-modifier relationships of a phrase-structure
model with 91% accuracy for unlabelled depen-
dencies measured on Wall Street Journal sentences
taken from the Penn Treebank.
The parser has also been sucessfully ported to
Czech, a highly inflected language with free word-
order. Here 80% accuracy for unlabelled depen-
dencies have been achieved (Collins et al., 1999),
which is surprisingly close to our results on a Ger-
man corpus. In the experiment for Czech an indi-
rect approach has been pursued, converting the de-
pendency structures of the Prague Tree Bank into
Penn-Treebank-like phrase structure trees. In con-
trast to this approach, WCDG parses dependency
structures directly.
Comparable results are available for a LFG-
parser (Riezler et al., 2002) which uses partial
parsing and skimming techniques to achieve full
coverage, along with a stochastic parse selection
model to guarantee full diambiguation. An f-score
of 73.0% for the extraction of dependency rela-
tions for 700 Wall Street Journal sentences has
been reported.
</bodyText>
<sectionHeader confidence="0.999044" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999983222222222">
By integrating the results from two components
for shallow syntactic analysis we were able to ad-
vance a dependency parser based on constraint op-
timization techniques to a new level of robust per-
formance. Thanks to the weak integration of ev-
idence from different sources, a high degree of
tolerance against missing lexical information, re-
duced run time requirements and a considerably
improved parsing accuracy have been achieved.
Thus, processing of free running text became an
option, and results have been obtained which are
comparable to other approaches.
Since the system has not been composed as a
strict sequence of components, but integrates evi-
dence from different modules in a single decision
procedure, the overall performance does not cru-
cially depend on the availability of certain types
of information. This would allow us to measure
</bodyText>
<page confidence="0.997619">
105
</page>
<bodyText confidence="0.99992075">
the contribution of individual information sources
to the overall performance rather precisely. Three
main conclusions can be drawn from the experi-
ments conducted so far:
</bodyText>
<listItem confidence="0.9553886">
• Even unreliable information can be useful to
contribute to a better performance.
• The system is much more sensitive against
chunk errors, than it is against tagging errors.
• Delayed decisions, as in the case of multi tag-
</listItem>
<bodyText confidence="0.951350318181818">
ging, might result in an advantage, as long as
the different contributions come from rather
complementary sources of evidence.
Several possibilities to further investigate weak in-
formation fusion within the hybrid architecture of
a WCDG parser can easily be imagined. First of
all, other types of chunkers should be considered.
LoPar (Schmid and Schulte im Walde, 2002), for
instance, which became recently available, can
contribute recursive chunks and provides much
better chunking results for coordinated structures.
Moreover, LoPar does not depend on the avail-
ability of external tagging information. Therefore
the net contribution of the chunker without an ad-
ditional tagger could also be determined, a con-
figuration which was not available so far. Fur-
thermore, by providing the necessary constraints,
completely different classes of shallow syntactic
sources can be included as well. Thus the utility
of evidence from a specialized attacher (e.g. for
PP-attachment) or a model of lexical associations
could be studied in more detail.
</bodyText>
<sectionHeader confidence="0.998008" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.978344333333333">
This research has been partially supported by
Deutsche Forschungsgemeinschaft under grant
Me 1472/4-1.
</bodyText>
<sectionHeader confidence="0.998976" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999039706896551">
R. Basili, M. T. Pazienza, and F. M. Zanzotto. 1998.
Efficient parsing for information extraction. In Proc.
13th Europ. Conf. on Artificial Intelligence, pages
135-139, Brighton, UK.
Thorsten Brants. 1999. Cascaded markov models. In
Proc. 9th Conf of the Europ. Chapter of the ACL,
EACL-99, pages 118– 125, Bergen, Norway.
Thorsten Brants. 2000. TnT — a statistical part-of-
speech tagger. In Sixth Applied Natural Language
Processing Coq: (ANLP-2000), Seattle, WA, USA.
E. Charniak, G. Carroll, J. Adcock, A. Cassandra,
Y. Gotoh, J. Katz, M. L. Littman, and J. McCann.
1996. Taggers for parsers. Artificial Intelligence,
85:45 –57.
Michael Collins, Jan Hajie, Lance Ramshaw, and
Christoph Tillmann. 1999. A statistical parser for
czech. In Proc. 37th Annual Meeting of the ACL,
ACL-99, pages 505 – 512, College Park, MD.
Michael Collins. 1999. Head-Driven Statistical Mod-
els for Natural Language Parsing. PhD thesis, Uni-
versity of Pennsylvania, Philadephia, PA.
B. Cryssmann, A. Frank, B. Kiefer, S. Muller, G. Neu-
mann, J. Piskorski, U. Schafer, M. Siegel, H. Uszko-
reit, F. Xu, M. Becker, and H.-U. Krieger. 2002. An
integrated architecture for shallow and deep process-
ing. In Proc. 40th Annual Meeting of the ACL, pages
441 – 448, Philadephia, PA.
Kilian A. Foth and Jochen Hagenstrom. 2002. Tag-
ging for robust parsers. In 2nd Workshop on Robust
Methods in Analysis of Natural Language Data, RO-
MAND2002, pages 21 – 32, Frascati, Italy.
Kilian A. Foth, Wolfgang Menzel, and Ingo Schaider.
2000. A Transformation-based Parsing Technique
with Anytime Properties. In 4th Int. Workshop on
Parsing Technologies, pages 89 – 100, Trento, Italy.
Hiroshi Maruyama. 1990. Structural disambiguation
with constraint propagation. In 28th Annual Meet-
ing of the ACL, pages 31 –38, Pittsburgh.
A. Prince and P. Smolensky. forthc. Optimality The-
ory: Constraint interaction in generative grammar.
Linguistic Inquiry Monograph Series. MIT Press.
S. Riezler, T. H. King, R. M. Kaplan, R. Crouch, J. T.
Maxwell III, and M. Johnson. 2002. Parsing the
wall street journal using a lexical-functional gram-
mar and discriminative estimation techniques. In
Proc. 40th Annual Meeting of the ACL, pages 271
– 278, Philadephia, PA.
Helmut Schmid and Sabine Schulte im Walde. 2002.
Robust german noun chunking with a probabilistic
context-free grammar. In Proc. 18th Int. Conf on
Computational Linguistics, COLING-00, pages 726
– 732, Saarbracken, Germany.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In Mt. Conf: on New
Methods in Language Processing, Manchester, UK.
Ingo Schroder. 2001. Natural Language Parsing with
Graded Constraints. Phd thesis, Dept. of Computer
Science, University of Hamburg, Germany.
</reference>
<page confidence="0.997405">
106
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.445324">
<title confidence="0.999892">Constraint Based Integration of Deep and Shallow Parsing Techniques</title>
<author confidence="0.826921">Daum A Foth Menzel</author>
<affiliation confidence="0.910141333333333">Natural Language Systems Department of Computer Science University of Hamburg</affiliation>
<email confidence="0.626625">@nats.informatik.de</email>
<abstract confidence="0.997893583333333">To investigate the contributions of taggers or chunkers to the performance of a deep syntactic parser, Weighted Constraint Dependency Grammars have been extended to also take into consideration information from external sources. Using a weak information fusion scheme based on constraint optimization techniques, a parsing accuracy has been achieved which is comparable to other (stochastic) parsers.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Basili</author>
<author>M T Pazienza</author>
<author>F M Zanzotto</author>
</authors>
<title>Efficient parsing for information extraction.</title>
<date>1998</date>
<booktitle>In Proc. 13th Europ. Conf. on Artificial Intelligence,</booktitle>
<pages>135--139</pages>
<location>Brighton, UK.</location>
<contexts>
<context position="23982" citStr="Basili et al., 1998" startWordPosition="3907" endWordPosition="3910">rent information sources used in both cases. (Charniak et al., 1996) combined two purely stochastic models, which probably capture rather similar kinds of model information from their training data, whereas in our case information of completely different origin has been brought together. While the tagger is geared towards exploiting sequential patterns in a sentence, the parser relies more on possible structural configurations and subcategorization information. There has also been a number of investigations on how to integrate chunk-boundary information into a parsing procedure. For Italian, (Basili et al., 1998) segment a sentence using a chunker and a clause boundary detection based on verb subcategorization frames. Based on this information inter-chunk dependencies are computed using a special purpose parser which is sensitive to the type of chunks. Recall and precision for interchunk dependencies (not full dependency structures) of 75.2% and 72.1% respectively have been achieved on a small test set of 56 sentences (1149 words). Since chunk-boundary information is ultimatively required by the parsing procedure and considered to be non-defeasible, no figures of merit are available which would allow </context>
</contexts>
<marker>Basili, Pazienza, Zanzotto, 1998</marker>
<rawString>R. Basili, M. T. Pazienza, and F. M. Zanzotto. 1998. Efficient parsing for information extraction. In Proc. 13th Europ. Conf. on Artificial Intelligence, pages 135-139, Brighton, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>Cascaded markov models.</title>
<date>1999</date>
<booktitle>In Proc. 9th Conf of the Europ. Chapter of the ACL, EACL-99,</booktitle>
<pages>118--125</pages>
<location>Bergen, Norway.</location>
<contexts>
<context position="22573" citStr="Brants, 1999" startWordPosition="3693" endWordPosition="3694"> POS information, particularly since some chunker errors do not change the optimization problem at all. On the other hand, where an incorrect POS tag affects primarily one lexical selection, an incorrect chunk bracket can penalize several correct syntactic edges at once; it usually forbids the desired structural alternative entirely, forcing the parser to interpret at least part of a sentence differently in a more fundamental way. 6 Related Work Most current approaches to probabilistic parsing are based on the output of a tagger. Some systems parse only the sequence of single best tags (c.f. (Brants, 1999)). If, however, a lexically sensitive model is desired, the tagger is invoked only as fall back solution for unknown words (c.f. (Collins, 1999)). Both solutions differ from the approach adopted here in that they cannot explicitly measure the contribution of the tagging results to the overall performance of the parser. (Charniak et al., 1996) performes a comparison of single tagging (where the tagger provides a unique tag assignment) to multi-tagging (which leaves the decision among several possible tags to 104 the parser). He concludes that multi-tagging gives no significant advantage. This r</context>
</contexts>
<marker>Brants, 1999</marker>
<rawString>Thorsten Brants. 1999. Cascaded markov models. In Proc. 9th Conf of the Europ. Chapter of the ACL, EACL-99, pages 118– 125, Bergen, Norway.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>TnT — a statistical part-ofspeech tagger.</title>
<date>2000</date>
<booktitle>In Sixth Applied Natural Language Processing Coq: (ANLP-2000),</booktitle>
<location>Seattle, WA, USA.</location>
<contexts>
<context position="11629" citStr="Brants, 2000" startWordPosition="1883" endWordPosition="1884">tic categories can combine to build larger structures, and thus the parser already solves the tagging problem as part of a much harder problem. The introduction of explicit POS scores simply serves to guide the parser more quickly toward structures that are probably part of the optimal analysis. Since an ideal POS tagger is unavailable, we then investigated how useful a less accurate but available information source can be. Among 101 the freely available POS taggers for German, the one that performs best on our corpus of online newscasts is the statistical Markov tagger Trigrams&apos;n&apos;Tags (TnT) (Brants, 2000). Although trained on a similar corpus of German newspaper text, even this tagger achieves only 92.3% accuracy in multi-tagging mode. One reason for this is that the distribution of word categories differs considerably between the two corpora: Our sentences contain ten times as much foreign-language material (Fm) as the tagger&apos;s training set, and also more names (NE), both of which are (in German) very difficult to distinguish from proper nouns. Therefore, in many cases the information provided by the tagger is actually misleading. However, even though the accuracy of this information source i</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Thorsten Brants. 2000. TnT — a statistical part-ofspeech tagger. In Sixth Applied Natural Language Processing Coq: (ANLP-2000), Seattle, WA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>G Carroll</author>
<author>J Adcock</author>
<author>A Cassandra</author>
<author>Y Gotoh</author>
<author>J Katz</author>
<author>M L Littman</author>
<author>J McCann</author>
</authors>
<title>Taggers for parsers.</title>
<date>1996</date>
<journal>Artificial Intelligence,</journal>
<volume>85</volume>
<pages>57</pages>
<contexts>
<context position="22917" citStr="Charniak et al., 1996" startWordPosition="3746" endWordPosition="3749"> forcing the parser to interpret at least part of a sentence differently in a more fundamental way. 6 Related Work Most current approaches to probabilistic parsing are based on the output of a tagger. Some systems parse only the sequence of single best tags (c.f. (Brants, 1999)). If, however, a lexically sensitive model is desired, the tagger is invoked only as fall back solution for unknown words (c.f. (Collins, 1999)). Both solutions differ from the approach adopted here in that they cannot explicitly measure the contribution of the tagging results to the overall performance of the parser. (Charniak et al., 1996) performes a comparison of single tagging (where the tagger provides a unique tag assignment) to multi-tagging (which leaves the decision among several possible tags to 104 the parser). He concludes that multi-tagging gives no significant advantage. This result has not been confirmed by our findings, which indeed show a small but reliable advantage of multi tagging over single tagging. The contrast might be explained by considering the different information sources used in both cases. (Charniak et al., 1996) combined two purely stochastic models, which probably capture rather similar kinds of </context>
</contexts>
<marker>Charniak, Carroll, Adcock, Cassandra, Gotoh, Katz, Littman, McCann, 1996</marker>
<rawString>E. Charniak, G. Carroll, J. Adcock, A. Cassandra, Y. Gotoh, J. Katz, M. L. Littman, and J. McCann. 1996. Taggers for parsers. Artificial Intelligence, 85:45 –57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Jan Hajie</author>
<author>Lance Ramshaw</author>
<author>Christoph Tillmann</author>
</authors>
<title>A statistical parser for czech.</title>
<date>1999</date>
<booktitle>In Proc. 37th Annual Meeting of the ACL, ACL-99,</booktitle>
<pages>505--512</pages>
<location>College Park, MD.</location>
<contexts>
<context position="25963" citStr="Collins et al., 1999" startWordPosition="4217" endWordPosition="4220">ambiguation. In this respect our approach is more similar to stochastic parsers. Here, evaluation results for the analysis of dependency relations have been published by (Collins, 1999) among others. In his parser dependency links can be recovered from the head-modifier relationships of a phrase-structure model with 91% accuracy for unlabelled dependencies measured on Wall Street Journal sentences taken from the Penn Treebank. The parser has also been sucessfully ported to Czech, a highly inflected language with free wordorder. Here 80% accuracy for unlabelled dependencies have been achieved (Collins et al., 1999), which is surprisingly close to our results on a German corpus. In the experiment for Czech an indirect approach has been pursued, converting the dependency structures of the Prague Tree Bank into Penn-Treebank-like phrase structure trees. In contrast to this approach, WCDG parses dependency structures directly. Comparable results are available for a LFGparser (Riezler et al., 2002) which uses partial parsing and skimming techniques to achieve full coverage, along with a stochastic parse selection model to guarantee full diambiguation. An f-score of 73.0% for the extraction of dependency rela</context>
</contexts>
<marker>Collins, Hajie, Ramshaw, Tillmann, 1999</marker>
<rawString>Michael Collins, Jan Hajie, Lance Ramshaw, and Christoph Tillmann. 1999. A statistical parser for czech. In Proc. 37th Annual Meeting of the ACL, ACL-99, pages 505 – 512, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>PhD thesis,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadephia, PA.</location>
<contexts>
<context position="22717" citStr="Collins, 1999" startWordPosition="3716" endWordPosition="3717">OS tag affects primarily one lexical selection, an incorrect chunk bracket can penalize several correct syntactic edges at once; it usually forbids the desired structural alternative entirely, forcing the parser to interpret at least part of a sentence differently in a more fundamental way. 6 Related Work Most current approaches to probabilistic parsing are based on the output of a tagger. Some systems parse only the sequence of single best tags (c.f. (Brants, 1999)). If, however, a lexically sensitive model is desired, the tagger is invoked only as fall back solution for unknown words (c.f. (Collins, 1999)). Both solutions differ from the approach adopted here in that they cannot explicitly measure the contribution of the tagging results to the overall performance of the parser. (Charniak et al., 1996) performes a comparison of single tagging (where the tagger provides a unique tag assignment) to multi-tagging (which leaves the decision among several possible tags to 104 the parser). He concludes that multi-tagging gives no significant advantage. This result has not been confirmed by our findings, which indeed show a small but reliable advantage of multi tagging over single tagging. The contras</context>
<context position="25527" citStr="Collins, 1999" startWordPosition="4152" endWordPosition="4153">the most plausible interpretation (Cryssmann et al., 2002). This approach increased the coverage of the overall system from 12.5% to 22.1% on the NEGRA-corpus but failed to reduce the average number of analyses which even grew from 16.19% to 18.53% per sentence. In contrast, due to its inherent robustness properties our parser always returns the single best solution, i.e. it has a coverage of 100% and always achieves full disambiguation. In this respect our approach is more similar to stochastic parsers. Here, evaluation results for the analysis of dependency relations have been published by (Collins, 1999) among others. In his parser dependency links can be recovered from the head-modifier relationships of a phrase-structure model with 91% accuracy for unlabelled dependencies measured on Wall Street Journal sentences taken from the Penn Treebank. The parser has also been sucessfully ported to Czech, a highly inflected language with free wordorder. Here 80% accuracy for unlabelled dependencies have been achieved (Collins et al., 1999), which is surprisingly close to our results on a German corpus. In the experiment for Czech an indirect approach has been pursued, converting the dependency struct</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. PhD thesis, University of Pennsylvania, Philadephia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Cryssmann</author>
<author>A Frank</author>
<author>B Kiefer</author>
<author>S Muller</author>
<author>G Neumann</author>
<author>J Piskorski</author>
<author>U Schafer</author>
<author>M Siegel</author>
<author>H Uszkoreit</author>
<author>F Xu</author>
<author>M Becker</author>
<author>H-U Krieger</author>
</authors>
<title>An integrated architecture for shallow and deep processing.</title>
<date>2002</date>
<booktitle>In Proc. 40th Annual Meeting of the ACL,</booktitle>
<pages>441--448</pages>
<location>Philadephia, PA.</location>
<contexts>
<context position="24971" citStr="Cryssmann et al., 2002" startWordPosition="4059" endWordPosition="4062">en achieved on a small test set of 56 sentences (1149 words). Since chunk-boundary information is ultimatively required by the parsing procedure and considered to be non-defeasible, no figures of merit are available which would allow estimation of the contribution of chunk boundaries to the overall behaviour of the system. Such figures have been given, however, for an architecture which integrates shallow information (coming from a tagger, a named entity recognizer, an external semantic database and a topological parser) by guiding a deep HPSG-parser towards the most plausible interpretation (Cryssmann et al., 2002). This approach increased the coverage of the overall system from 12.5% to 22.1% on the NEGRA-corpus but failed to reduce the average number of analyses which even grew from 16.19% to 18.53% per sentence. In contrast, due to its inherent robustness properties our parser always returns the single best solution, i.e. it has a coverage of 100% and always achieves full disambiguation. In this respect our approach is more similar to stochastic parsers. Here, evaluation results for the analysis of dependency relations have been published by (Collins, 1999) among others. In his parser dependency link</context>
</contexts>
<marker>Cryssmann, Frank, Kiefer, Muller, Neumann, Piskorski, Schafer, Siegel, Uszkoreit, Xu, Becker, Krieger, 2002</marker>
<rawString>B. Cryssmann, A. Frank, B. Kiefer, S. Muller, G. Neumann, J. Piskorski, U. Schafer, M. Siegel, H. Uszkoreit, F. Xu, M. Becker, and H.-U. Krieger. 2002. An integrated architecture for shallow and deep processing. In Proc. 40th Annual Meeting of the ACL, pages 441 – 448, Philadephia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kilian A Foth</author>
<author>Jochen Hagenstrom</author>
</authors>
<title>Tagging for robust parsers.</title>
<date>2002</date>
<booktitle>In 2nd Workshop on Robust Methods in Analysis of Natural Language Data, ROMAND2002,</booktitle>
<pages>21--32</pages>
<location>Frascati, Italy.</location>
<contexts>
<context position="10225" citStr="Foth and Hagenstrom, 2002" startWordPosition="1651" endWordPosition="1654">lizes any mismatch between the lexical category under consideration and the category predicted by the tagger. In the case of multi tagging the penalty is proportional to the score emitted by the tagger. In single tagging this algorithm can only assign a constraint weight of 0 or 1, since our tagger does not report the internal confidence value, so that all but one lexical variants are actually forbidden entirely. To reduce the impact of tagging errors in both tagging modes, the weight of the constraint can be smoothed to ensure that all other categories are merely punished but not eliminated (Foth and Hagenstrom, 2002). By adding or omitting a single constraint in the existing dependency grammar, we can accurately measure how useful the contribution of the POS tagger is to the parsing process, independently of how accurate it is. As a first experiment, we simulated the ideal POS tagger (one which makes no mistakes at all) by giving the tagging constraint access to our manual annotations. Under these idealized conditions, we achieved a labelled recall of 75.8% under the same conditions as before. Also, processing took only a third of the time necessary before. Obviously, the POS information is very useful fo</context>
</contexts>
<marker>Foth, Hagenstrom, 2002</marker>
<rawString>Kilian A. Foth and Jochen Hagenstrom. 2002. Tagging for robust parsers. In 2nd Workshop on Robust Methods in Analysis of Natural Language Data, ROMAND2002, pages 21 – 32, Frascati, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kilian A Foth</author>
<author>Wolfgang Menzel</author>
<author>Ingo Schaider</author>
</authors>
<title>A Transformation-based Parsing Technique with Anytime Properties.</title>
<date>2000</date>
<booktitle>In 4th Int. Workshop on Parsing Technologies, pages 89 – 100,</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="6136" citStr="Foth et al., 2000" startWordPosition="963" endWordPosition="966">int weights turns the CSP into a constraint optimization problem, which is considerably harder to solve, since one particular solution must be found rather than just one of a number of solutions. Furthermore, weighted constraints do not allow us to prune away an alternative, leading to very large search spaces. In fact, analyzing long sentences with WCDG usually leads to problems that are too large to be solved exactly. However, heuristic methods have been developed that can approximate the optimal solution, where the quality of the solution increases over time as more alternatives are tried (Foth et al., 2000). 3 Experimental setup For our experiments we analysed 1845 unedited sentences from German online newscasts on buying or selling events, with an average length of 24 word forms (see Table 1 for a distribution of sentence lengths). We employed a handwritten WCDG of German that aims to perform a very thorough analysis; in addition to establishing syntax structure, it assigns each dependency one of 28 labels. It must also determine the exact word class and morphological form of each word. At the same time the lexicon was kept incomplete; of the open word classes of German, only the verbs are mode</context>
</contexts>
<marker>Foth, Menzel, Schaider, 2000</marker>
<rawString>Kilian A. Foth, Wolfgang Menzel, and Ingo Schaider. 2000. A Transformation-based Parsing Technique with Anytime Properties. In 4th Int. Workshop on Parsing Technologies, pages 89 – 100, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Maruyama</author>
</authors>
<title>Structural disambiguation with constraint propagation.</title>
<date>1990</date>
<booktitle>In 28th Annual Meeting of the ACL,</booktitle>
<pages>31--38</pages>
<location>Pittsburgh.</location>
<contexts>
<context position="4298" citStr="Maruyama, 1990" startWordPosition="665" endWordPosition="666">he finite verb forming the root of the tree. To express different types of dependency relations, the vertices are often enriched with different labels, e.g. to distinguish subjects from objects. Instead of giving generative rules about how to construct a dependency tree, a Constraint dependency grammar declares constraints, i.e. properties that a well-formed tree should fulfill. Finding a well-formed syntactic structure takes on the form of a constraint satisfaction problem (CSP), which can be solved by a variety of solution methods. This kind of dependency grammar was introduced by Maruyama (Maruyama, 1990). The constraints about well-formedness are notated as logical formulas. A common rule is to postulate that subjects typically precede their finite verb and objects follow it. This can be expressed by requiring that for all edges with the label `SUBF , the governor must occur to the left of the modifier, and the inverse for edges labelled `OBJA&apos;. Applying these constraints to an example analysis (Figure 1), we see that two of the dependencies actually violate them. Since this is not incorrect in German but merely marks a topicalization, it is useful to gradate the constraints. This is the defi</context>
</contexts>
<marker>Maruyama, 1990</marker>
<rawString>Hiroshi Maruyama. 1990. Structural disambiguation with constraint propagation. In 28th Annual Meeting of the ACL, pages 31 –38, Pittsburgh.</rawString>
</citation>
<citation valid="false">
<authors>
<author>forthc</author>
</authors>
<title>Optimality Theory: Constraint interaction in generative grammar. Linguistic Inquiry Monograph Series.</title>
<publisher>MIT Press.</publisher>
<marker>forthc, </marker>
<rawString>A. Prince and P. Smolensky. forthc. Optimality Theory: Constraint interaction in generative grammar. Linguistic Inquiry Monograph Series. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riezler</author>
<author>T H King</author>
<author>R M Kaplan</author>
<author>R Crouch</author>
<author>J T Maxwell</author>
<author>M Johnson</author>
</authors>
<title>Parsing the wall street journal using a lexical-functional grammar and discriminative estimation techniques.</title>
<date>2002</date>
<booktitle>In Proc. 40th Annual Meeting of the ACL,</booktitle>
<pages>271--278</pages>
<location>Philadephia, PA.</location>
<contexts>
<context position="26349" citStr="Riezler et al., 2002" startWordPosition="4279" endWordPosition="4282">rnal sentences taken from the Penn Treebank. The parser has also been sucessfully ported to Czech, a highly inflected language with free wordorder. Here 80% accuracy for unlabelled dependencies have been achieved (Collins et al., 1999), which is surprisingly close to our results on a German corpus. In the experiment for Czech an indirect approach has been pursued, converting the dependency structures of the Prague Tree Bank into Penn-Treebank-like phrase structure trees. In contrast to this approach, WCDG parses dependency structures directly. Comparable results are available for a LFGparser (Riezler et al., 2002) which uses partial parsing and skimming techniques to achieve full coverage, along with a stochastic parse selection model to guarantee full diambiguation. An f-score of 73.0% for the extraction of dependency relations for 700 Wall Street Journal sentences has been reported. 7 Conclusions By integrating the results from two components for shallow syntactic analysis we were able to advance a dependency parser based on constraint optimization techniques to a new level of robust performance. Thanks to the weak integration of evidence from different sources, a high degree of tolerance against mis</context>
</contexts>
<marker>Riezler, King, Kaplan, Crouch, Maxwell, Johnson, 2002</marker>
<rawString>S. Riezler, T. H. King, R. M. Kaplan, R. Crouch, J. T. Maxwell III, and M. Johnson. 2002. Parsing the wall street journal using a lexical-functional grammar and discriminative estimation techniques. In Proc. 40th Annual Meeting of the ACL, pages 271 – 278, Philadephia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Robust german noun chunking with a probabilistic context-free grammar.</title>
<date>2002</date>
<booktitle>In Proc. 18th Int. Conf on Computational Linguistics, COLING-00,</booktitle>
<pages>726--732</pages>
<location>Saarbracken, Germany.</location>
<marker>Schmid, Walde, 2002</marker>
<rawString>Helmut Schmid and Sabine Schulte im Walde. 2002. Robust german noun chunking with a probabilistic context-free grammar. In Proc. 18th Int. Conf on Computational Linguistics, COLING-00, pages 726 – 732, Saarbracken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Mt. Conf: on New Methods in Language Processing,</booktitle>
<location>Manchester, UK.</location>
<contexts>
<context position="16675" citStr="Schmid, 1994" startWordPosition="2715" endWordPosition="2716">completely resolved. Many other syntactic relations can profit from similar reasoning. To find out how much this additional information can contribute to the parsing process, we first simulated the ideal chunk parser by supplying our program with the correct chunk boundaries as present in our gold-standard annotations. As line 7 in Table 2 shows, the syntactic accuracy increases by about 5 percentage points. Obviously, this is the upper limit of utility that chunk information can supply in our case.3 To test the performance of an actual chunk parser we used the decision-tree based TreeTagger (Schmid, 1994), a freely available tool that is capable of assigning POS tags and of determining 3The chunk parser actually used in the following experiment requires tagged input to operate so that it is not possible to test its effect in isolation, i.e. without POS tagging. Therefore this idealized experiment also employs the TnT tagger. noun, verb and prepositional chunks in German text. Since its tagging accuracy is no better than TnT on our corpus, we only use it to extract chunk information. When run as a chunk parser for German, the TreeTagger correctly recalls 87.4% of the chunks present in our annot</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Mt. Conf: on New Methods in Language Processing, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ingo Schroder</author>
</authors>
<title>Natural Language Parsing with Graded Constraints.</title>
<date>2001</date>
<tech>Phd thesis,</tech>
<institution>Dept. of Computer Science, University of Hamburg,</institution>
<contexts>
<context position="4950" citStr="Schroder, 2001" startWordPosition="776" endWordPosition="777">ss are notated as logical formulas. A common rule is to postulate that subjects typically precede their finite verb and objects follow it. This can be expressed by requiring that for all edges with the label `SUBF , the governor must occur to the left of the modifier, and the inverse for edges labelled `OBJA&apos;. Applying these constraints to an example analysis (Figure 1), we see that two of the dependencies actually violate them. Since this is not incorrect in German but merely marks a topicalization, it is useful to gradate the constraints. This is the defining characteristic of Weighted CDG (Schroder, 2001): The grammar writer can assign different weights to the constraints to indicate their relative strength. The weights of violated constraints are multiplied to obtain the score for an entire dependency tree. Violation of a constraint is tolerated if no other analysis has a higher overall score. This property leads to considerable robustness against ungrammatical or extragrammatical input. Note that a low figure for the weight corresponds to a strong constraint, while a high figure (near 1) has little influence under the multiplicative scheme. Introducing constraint weights turns the CSP into a</context>
</contexts>
<marker>Schroder, 2001</marker>
<rawString>Ingo Schroder. 2001. Natural Language Parsing with Graded Constraints. Phd thesis, Dept. of Computer Science, University of Hamburg, Germany.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>