<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.041341">
<title confidence="0.99797">
Generalizing over Lexical Features:
Selectional Preferences for Semantic Role Classification
</title>
<author confidence="0.681098">
Be˜nat Zapirain, Eneko Agirre
</author>
<affiliation confidence="0.830369666666667">
Ixa Taldea
University of the Basque Country
Donostia, Basque Country
</affiliation>
<email confidence="0.997602">
{benat.zapirain,e.agirre}@ehu.es
</email>
<author confidence="0.953524">
Lluis M`arquez
</author>
<affiliation confidence="0.984981">
TALP Research Center
Technical University of Catalonia
</affiliation>
<address confidence="0.930071">
Barcelona, Catalonia
</address>
<email confidence="0.998995">
lluism@lsi.upc.edu
</email>
<sectionHeader confidence="0.997389" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999629428571429">
This paper explores methods to allevi-
ate the effect of lexical sparseness in the
classification of verbal arguments. We
show how automatically generated selec-
tional preferences are able to generalize
and perform better than lexical features in
a large dataset for semantic role classifi-
cation. The best results are obtained with
a novel second-order distributional simi-
larity measure, and the positive effect is
specially relevant for out-of-domain data.
Our findings suggest that selectional pref-
erences have potential for improving a full
system for Semantic Role Labeling.
</bodyText>
<sectionHeader confidence="0.99939" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999534333333334">
Semantic Role Labeling (SRL) systems usually
approach the problem as a sequence of two sub-
tasks: argument identification and classification.
While the former is mostly a syntactic task, the
latter requires semantic knowledge to be taken
into account. Current systems capture semantics
through lexicalized features on the predicate and
the head word of the argument to be classified.
Since lexical features tend to be sparse (especially
when the training corpus is small) SRL systems
are prone to overfit the training data and general-
ize poorly to new corpora.
This work explores the usefulness of selectional
preferences to alleviate the lexical dependence of
SRL systems. Selectional preferences introduce
semantic generalizations on the type of arguments
preferred by the predicates. Therefore, they are
expected to improve generalization on infrequent
and unknown words, and increase the discrimina-
tive power of the argument classifiers.
For instance, consider these two sentences:
JFK was assassinated (in Dallas)Location
JFK was assassinated (in November)Temporal
Both share syntactic and argument structure, so
the lexical features (i.e., the words ‘Dallas’ and
‘November’) represent the most important knowl-
edge to discriminate between the two different ad-
junct roles. The problem is that, in new text,
one may encounter similar expressions with new
words like Texas or Autumn.
We propose a concrete classification problem as
our main evaluation setting for the acquired selec-
tional preferences: given a verb occurrence and
a nominal head word of a constituent dependant
on that verb, assign the most plausible role to the
headword according to the selectional preference
model. This problem is directly connected to ar-
gument classification in SRL, but we have iso-
lated the evaluation from the complete SRL task.
This first step allows us to analyze the potential
of selectional preferences as a source of seman-
tic knowledge for discriminating among different
role labels. Ongoing work is devoted to the inte-
gration of selectional preference–derived features
in a complete SRL system.
</bodyText>
<sectionHeader confidence="0.999895" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998097235294118">
Automatic acquisition of selectional preferences
is a relatively old topic, and will mention the
most relevant references. Resnik (1993) proposed
to model selectional preferences using semantic
classes from WordNet in order to tackle ambiguity
issues in syntax (noun-compounds, coordination,
PP-attachment).
Brockman and Lapata (2003) compared sev-
eral class-based models (including Resnik’s se-
lectional preferences) on a syntactic plausibility
judgement task for German. The models re-
turn weights for (verb, syntactic function, noun)
triples, and the correlation with human plausibil-
ity judgement is used for evaluation. Resnik’s
selectional preference scored best among class-
based methods, but it performed equal to a simple,
purely lexical, conditional probability model.
</bodyText>
<page confidence="0.991599">
73
</page>
<note confidence="0.92558">
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 73–76,
Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999958586956522">
Distributional similarity has also been used to
tackle syntactic ambiguity. Pantel and Lin (2000)
obtained very good results using the distributional
similarity measure defined by Lin (1998).
The application of selectional preferences to se-
mantic roles (as opposed to syntactic functions)
is more recent. Gildea and Jurafsky (2002) is
the only one applying selectional preferences in
a real SRL task. They used distributional clus-
tering and WordNet-based techniques on a SRL
task on FrameNet roles. They report a very small
improvement of the overall performance when us-
ing distributional clustering techniques. In this pa-
per we present complementary experiments, with
a different role set and annotated corpus (Prop-
Bank), a wider range of selectional preference
models, and the analysis of out-of-domain results.
Other papers applying semantic preferences
in the context of semantic roles, rely on the
evaluation on pseudo tasks or human plausibil-
ity judgments. In (Erk, 2007) a distributional
similarity–based model for selectional preferences
is introduced, reminiscent of that of Pantel and
Lin (2000). The results over 100 frame-specific
roles showed that distributional similarities get
smaller error rates than Resnik and EM, with Lin’s
formula having the smallest error rate. Moreover,
coverage of distributional similarities and Resnik
are rather low. Our distributional model for selec-
tional preferences follows her formalization.
Currently, there are several models of distri-
butional similarity that could be used for selec-
tional preferences. More recently, Pad´o and Lap-
ata (2007) presented a study of several parameters
that define a broad family of distributional similar-
ity models, including publicly available software.
Our paper tests similar techniques to those pre-
sented above, but we evaluate selectional prefer-
ence models in a setting directly related to SR
classification, i.e., given a selectional preference
model for a verb we find the role which fits best
for a given head word. The problem is indeed
qualitatively different: we do not have to choose
among the head words competing for a role (as
in the papers above) but among selectional prefer-
ences competing for a head word.
</bodyText>
<sectionHeader confidence="0.991619" genericHeader="method">
3 Selectional Preference Models
</sectionHeader>
<bodyText confidence="0.999362972222222">
In this section we present all the variants for ac-
quiring selectional preferences used in our study,
and how we apply them to the SR classification.
WordNet-based SP models: we use Resnik’s se-
lectional preference model.
Distributional SP models: Given the availabil-
ity of publicly available resources for distribu-
tional similarity, we used 1) a ready-made the-
saurus (Lin, 1998), and 2) software (Pad´o and La-
pata, 2007) which we run on the British National
Corpus (BNC).
In the first case, Lin constructed his thesaurus
based on his own similarity formula run over a
large parsed corpus comprising journalism texts.
The thesaurus lists, for each word, the most sim-
ilar words, with their weight. In order to get the
similarity for two words, we could check the entry
in the thesaurus for either word. But given that
the thesaurus is not symmetric, we take the av-
erage of both similarities. We will refer to this
similarity measure as simth
lin. Another option is
to use second-order similarity, where we compute
the similarity of two words using the entries in the
thesaurus, either using the cosine or Jaccard mea-
sures. We will refer to these similarity measures
as simth2
jac and simth2
cos hereinafter.
For the second case, we tried the optimal pa-
rameters as described in (Pad´o and Lapata, 2007,
p. 179): word-based space, medium context, log-
likelihood association, and 2,000 basis elements.
We tested Jaccard, cosine and Lin’s measure (Lin,
1998) for similarity, yielding simjac, simcos and
simlin, respectively.
</bodyText>
<subsectionHeader confidence="0.962081">
3.1 Role Classification with SP Models
</subsectionHeader>
<bodyText confidence="0.999571733333333">
Given a target sentence where a predicate and sev-
eral potential argument and adjunct head words
occur, the goal is to assign a role label to each of
the head words. The classification of candidate
head words is performed independently of each
other.
Since we want to evaluate the ability of selec-
tional preference models to discriminate among
different roles, this is the only knowledge that will
be used to perform classification (avoiding the in-
clusion of any other feature commonly used in
SRL). Thus, for each head word, we will simply
select the role (r) of the predicate (p) which fits
best the head word (w). This selection rule is for-
malized as:
</bodyText>
<equation confidence="0.572619">
R(p, w) = arg maxr∈Roles(p) 5(p, r, w)
</equation>
<bodyText confidence="0.984590666666667">
being 5(p, r, w) the prediction of the selectional
preference model, which can be instantiated with
all the variants mentioned above.
</bodyText>
<page confidence="0.99361">
74
</page>
<bodyText confidence="0.999971">
For the sake of comparison we also define a lex-
ical baseline model, which will determine the con-
tribution of lexical features in argument classifica-
tion. For a test pair (p, w) the model returns the
role under which the head word occurred most of-
ten in the training data given the predicate.
</bodyText>
<sectionHeader confidence="0.997172" genericHeader="method">
4 Experimental Setting
</sectionHeader>
<bodyText confidence="0.999960114285714">
The data used in this work is the benchmark cor-
pus provided by the CoNLL-2005 shared task on
SRL (Carreras and M`arquez, 2005). The dataset,
of over 1 million tokens, comprises PropBank sec-
tions 02-21 for training, and sections 24 and 23 for
development and test, respectively. In these ex-
periments, NEG, DIS and MOD arguments have
been discarded because, apart from not being con-
sidered “pure” adjunct roles, the selectional pref-
erences implemented in this study are not able to
deal with non-nominal argument heads.
The predicate–rol–head (p, r, w) triples for gen-
eralizing the selectional preferences are extracted
from the arguments of the training set, yield-
ing 71,240 triples, from which 5,587 different
predicate-role selectional preferences (p, r) are
derived by instantiating the different models in
Section 3.
Selectional preferences are then used, to predict
the corresponding roles of the (p, w) pairs from
the test corpora. The test set contains 4,134 pairs
(covering 505 different predicates) to be classified
into the appropriate role label. In order to study
the behavior on out-of-domain data, we also tested
on the PropBanked part of the Brown corpus. This
corpus contains 2,932 (p, w) pairs covering 491
different predicates.
The performance of each selectional preference
model is evaluated by calculating the standard pre-
cision, recall and F1 measures. It is worth men-
tioning that none of the models is able to predict
the role when facing an unknown head word. This
happens more often with WordNet based models,
which have a lower word coverage compared to
distributional similarity–based models.
</bodyText>
<sectionHeader confidence="0.999813" genericHeader="evaluation">
5 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999757833333333">
The results are presented in Table 1. The lexi-
cal row corresponds to the baseline lexical match
method. The following row corresponds to the
WordNet-based selectional preference model. The
distributional models follow, including the results
obtained by the three similarity formulas on the
</bodyText>
<table confidence="0.993485090909091">
prec. rec. Fl prec. recall Fl
lexical .779 .349 .482 .663 .059 .108
res .589 .495 .537 .505 .379 .433
simJac .573 .564 .569 .481 .452 .466
simcos .607 .598 .602 .507 .476 .491
simLin .580 .560 .570 .500 .470 .485
simthLin .635 .625 .630 .494 .464 .478
simth2 .657 .646 .651 .531 .499 .515
Jac .654 .644 .649 .531 .499 .515
simth2
cos
</table>
<tableCaption confidence="0.9880965">
Table 1: Results for WSJ test (left), and Brown
test (right)
</tableCaption>
<bodyText confidence="0.977156">
co-occurrences extracted from the BNC (simJac,
simcos simLin), and the results obtained when
using Lin’s thesaurus directly (simthLin) and as a
second-order vector (simth2
Jac and simth2
cos).
As expected, the lexical baseline attains very
high precision in all datasets, which underscores
the importance of the lexical head word features
in argument classification. The recall is quite
low, specially in Brown, confirming and extend-
ing (Pradhan et al., 2008), which also reports sim-
ilar performance drops when doing argument clas-
sification on out-of-domain data.
One of the main goals of our experiments is to
overcome the data sparseness of lexical features
both on in-domain and out-of-domain data. All
our selectional preference models improve over
the lexical matching baseline in recall, up to 30
absolute percentage points in the WSJ test dataset
and 44 absolute percentage points in the Brown
corpus. This comes at the cost of reduced preci-
sion, but the overall F-score shows that all selec-
tional preference models improve over the base-
line, with up to 17 absolute percentage points
on the WSJ datasets and 41 absolute percentage
points on the Brown dataset. The results, thus,
show that selectional preferences are indeed alle-
viating the lexical sparseness problem.
As an example, consider the following head
words of potential arguments of the verb wear
found in the test set: doctor, men, tie, shoe. None
of these nouns occurred as heads of arguments of
wear in the training data, and thus the lexical fea-
ture would be unable to predict any role for them.
Using selectional preferences, we successfully as-
signed the Arg0 role to doctor and men, and the
Arg1 role to tie and shoe.
Regarding the selectional preference variants,
WordNet-based and first-order distributional sim-
ilarity models attain similar levels of precision,
but the former are clearly worse on recall and F1.
</bodyText>
<page confidence="0.997257">
75
</page>
<bodyText confidence="0.999884">
The performance loss on recall can be explained
by the worse lexical coverage of WordNet when
compared to automatically generated thesauri. Ex-
amples of words missing in WordNet include ab-
breviations (e.g., Inc., Corp.) and brand names
(e.g., Texaco, Sony). The second-order distribu-
tional similarity measures perform best overall,
both in precision and recall. As far as we know,
it is the first time that these models are applied to
selectional preference modeling, and they prove to
be a strong alternative to first-order models. The
relative performance of the methods is consistent
across the two datasets, stressing the robustness of
all methods used.
Regarding the use of similarity software (Pad´o
and Lapata, 2007) on the BNC vs. the use of
Lin’s ready-made thesaurus, both seem to perform
similarly, as exemplified by the similar results of
simLin and simthLin. The fact that the former per-
formed better on the Brown data, and worse on the
WSJ data could be related to the different corpora
used to compute the co-occurrence, balanced cor-
pus and journalism texts respectively. This could
be an indication of the potential of distributional
thesauri to adapt to the target domain.
Regarding the similarity metrics, the cosine
seems to perform consistently better for first-order
distributional similarity, while Jaccard provided
slightly better results for second-order similarity.
The best overall performance was for second-
order similarity, also using the cosine. Given
the computational complexity involved in build-
ing a complete thesaurus based on the similarity
software, we used the ready-made thesaurus of
Lin, but could not try the second-order version on
BNC.
</bodyText>
<sectionHeader confidence="0.998901" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99998875">
We have empirically shown how automatically
generated selectional preferences, using WordNet
and distributional similarity measures, are able to
effectively generalize lexical features and, thus,
improve classification performance in a large-
scale argument classification task on the CoNLL-
2005 dataset. The experiments show substantial
gains on recall and F1 compared to lexical match-
ing, both on the in-domain WSJ test and, espe-
cially, on the out-of-domain Brown test.
Alternative selectional models were studied and
compared. WordNet-based models attain good
levels of precision but lower recall than distribu-
tional similarity methods. A new second-order
similarity method proposed in this paper attains
the best results overall in all datasets.
The evidence gathered in this paper suggests
that using semantic knowledge in the form of se-
lectional preferences has a high potential for im-
proving the results of a full system for SRL, spe-
cially when training data is scarce or when applied
to out-of-domain corpora.
Current efforts are devoted to study the integra-
tion of the selectional preference models presented
in this paper in a in-house SRL system. We are
particularly interested in domain adaptation, and
whether distributional similarities can profit from
domain corpora for better performance.
</bodyText>
<sectionHeader confidence="0.999739" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<reference confidence="0.5256408">
This work has been partially funded by the EU Commis-
sion (project KYOTO ICT-2007-211423) and Spanish Re-
search Department (project KNOW TIN2006-15049-C03-
01). Be˜nat enjoys a PhD grant from the University of the
Basque Country.
</reference>
<sectionHeader confidence="0.978858" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997083448275862">
Carsten Brockmann and Mirella Lapata. 2003. Evaluating
and combining approaches to selectional preference ac-
quisition. In Proceedings of the 10th Conference of the
European Chapter of the ACL, pages 27–34.
X. Carreras and L. M`arquez. 2005. Introduction to the
CoNLL-2005 Shared Task: Semantic role labeling. In
Proceedings of the Ninth Conference on Computational
Natural Language Learning (CoNLL-2005), pages 152–
164, Ann Arbor, MI, USA.
Katrin Erk. 2007. A simple, similarity-based model for se-
lectional preferences. In Proceedings of the 45th Annual
Meeting of the Association of Computational Linguistics,
pages 216–223, Prague, Czech Republic.
D. Gildea and D. Jurafsky. 2002. Automatic labeling of se-
mantic roles. Computational Linguistics, 28(3):245–288.
Dekang Lin. 1998. Automatic retrieval and clustering of
similar words. In COLING-ACL, pages 768–774.
Sebastian Pad´o and Mirella Lapata. 2007. Dependency-
based construction of semantic space models. Computa-
tional Linguistics, 33(2):161–199, June.
Patrick Pantel and Dekang Lin. 2000. An unsupervised ap-
proach to prepositional phrase attachment using contex-
tually similar words. In Proceedings of the 38th Annual
Conference of the ACL, pages 101–108.
S. Pradhan, W. Ward, and J. H. Martin. 2008. Towards robust
semantic role labeling. Computational Linguistics, 34(2).
Philip Resnik. 1993. Semantic classes and syntactic ambigu-
ity. In Proceedings of the workshop on Human Language
Technology, pages 278–283, Morristown, NJ, USA.
</reference>
<page confidence="0.991786">
76
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.361025">
<title confidence="0.969133666666667">Generalizing over Lexical Features: Selectional Preferences for Semantic Role Classification Zapirain, Eneko Agirre</title>
<author confidence="0.941835">Ixa Taldea</author>
<affiliation confidence="0.996132">University of the Basque Country</affiliation>
<address confidence="0.452454">Donostia, Basque Country</address>
<author confidence="0.875786">Lluis M`arquez</author>
<affiliation confidence="0.9994905">TALP Research Center Technical University of Catalonia</affiliation>
<address confidence="0.961771">Barcelona, Catalonia</address>
<email confidence="0.999764">lluism@lsi.upc.edu</email>
<abstract confidence="0.997436533333333">This paper explores methods to alleviate the effect of lexical sparseness in the classification of verbal arguments. We show how automatically generated selectional preferences are able to generalize and perform better than lexical features in a large dataset for semantic role classification. The best results are obtained with a novel second-order distributional similarity measure, and the positive effect is specially relevant for out-of-domain data. Our findings suggest that selectional preferences have potential for improving a full system for Semantic Role Labeling.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>This work has been partially funded by the EU Commission (project KYOTO ICT-2007-211423) and Spanish Research Department (project KNOW TIN2006-15049-C03-01). Be˜nat enjoys a PhD grant from the University of the Basque Country.</title>
<marker></marker>
<rawString>This work has been partially funded by the EU Commission (project KYOTO ICT-2007-211423) and Spanish Research Department (project KNOW TIN2006-15049-C03-01). Be˜nat enjoys a PhD grant from the University of the Basque Country.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carsten Brockmann</author>
<author>Mirella Lapata</author>
</authors>
<title>Evaluating and combining approaches to selectional preference acquisition.</title>
<date>2003</date>
<booktitle>In Proceedings of the 10th Conference of the European Chapter of the ACL,</booktitle>
<pages>27--34</pages>
<marker>Brockmann, Lapata, 2003</marker>
<rawString>Carsten Brockmann and Mirella Lapata. 2003. Evaluating and combining approaches to selectional preference acquisition. In Proceedings of the 10th Conference of the European Chapter of the ACL, pages 27–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>L M`arquez</author>
</authors>
<title>Introduction to the CoNLL-2005 Shared Task: Semantic role labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005),</booktitle>
<pages>152--164</pages>
<location>Ann Arbor, MI, USA.</location>
<marker>Carreras, M`arquez, 2005</marker>
<rawString>X. Carreras and L. M`arquez. 2005. Introduction to the CoNLL-2005 Shared Task: Semantic role labeling. In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005), pages 152– 164, Ann Arbor, MI, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
</authors>
<title>A simple, similarity-based model for selectional preferences.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>216--223</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="4924" citStr="Erk, 2007" startWordPosition="719" endWordPosition="720">l preferences in a real SRL task. They used distributional clustering and WordNet-based techniques on a SRL task on FrameNet roles. They report a very small improvement of the overall performance when using distributional clustering techniques. In this paper we present complementary experiments, with a different role set and annotated corpus (PropBank), a wider range of selectional preference models, and the analysis of out-of-domain results. Other papers applying semantic preferences in the context of semantic roles, rely on the evaluation on pseudo tasks or human plausibility judgments. In (Erk, 2007) a distributional similarity–based model for selectional preferences is introduced, reminiscent of that of Pantel and Lin (2000). The results over 100 frame-specific roles showed that distributional similarities get smaller error rates than Resnik and EM, with Lin’s formula having the smallest error rate. Moreover, coverage of distributional similarities and Resnik are rather low. Our distributional model for selectional preferences follows her formalization. Currently, there are several models of distributional similarity that could be used for selectional preferences. More recently, Pad´o an</context>
</contexts>
<marker>Erk, 2007</marker>
<rawString>Katrin Erk. 2007. A simple, similarity-based model for selectional preferences. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 216–223, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="4278" citStr="Gildea and Jurafsky (2002)" startWordPosition="617" endWordPosition="620">valuation. Resnik’s selectional preference scored best among classbased methods, but it performed equal to a simple, purely lexical, conditional probability model. 73 Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 73–76, Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP Distributional similarity has also been used to tackle syntactic ambiguity. Pantel and Lin (2000) obtained very good results using the distributional similarity measure defined by Lin (1998). The application of selectional preferences to semantic roles (as opposed to syntactic functions) is more recent. Gildea and Jurafsky (2002) is the only one applying selectional preferences in a real SRL task. They used distributional clustering and WordNet-based techniques on a SRL task on FrameNet roles. They report a very small improvement of the overall performance when using distributional clustering techniques. In this paper we present complementary experiments, with a different role set and annotated corpus (PropBank), a wider range of selectional preference models, and the analysis of out-of-domain results. Other papers applying semantic preferences in the context of semantic roles, rely on the evaluation on pseudo tasks o</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>D. Gildea and D. Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In COLING-ACL,</booktitle>
<pages>768--774</pages>
<contexts>
<context position="4137" citStr="Lin (1998)" startWordPosition="598" endWordPosition="599">urn weights for (verb, syntactic function, noun) triples, and the correlation with human plausibility judgement is used for evaluation. Resnik’s selectional preference scored best among classbased methods, but it performed equal to a simple, purely lexical, conditional probability model. 73 Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 73–76, Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP Distributional similarity has also been used to tackle syntactic ambiguity. Pantel and Lin (2000) obtained very good results using the distributional similarity measure defined by Lin (1998). The application of selectional preferences to semantic roles (as opposed to syntactic functions) is more recent. Gildea and Jurafsky (2002) is the only one applying selectional preferences in a real SRL task. They used distributional clustering and WordNet-based techniques on a SRL task on FrameNet roles. They report a very small improvement of the overall performance when using distributional clustering techniques. In this paper we present complementary experiments, with a different role set and annotated corpus (PropBank), a wider range of selectional preference models, and the analysis of</context>
<context position="6561" citStr="Lin, 1998" startWordPosition="971" endWordPosition="972"> The problem is indeed qualitatively different: we do not have to choose among the head words competing for a role (as in the papers above) but among selectional preferences competing for a head word. 3 Selectional Preference Models In this section we present all the variants for acquiring selectional preferences used in our study, and how we apply them to the SR classification. WordNet-based SP models: we use Resnik’s selectional preference model. Distributional SP models: Given the availability of publicly available resources for distributional similarity, we used 1) a ready-made thesaurus (Lin, 1998), and 2) software (Pad´o and Lapata, 2007) which we run on the British National Corpus (BNC). In the first case, Lin constructed his thesaurus based on his own similarity formula run over a large parsed corpus comprising journalism texts. The thesaurus lists, for each word, the most similar words, with their weight. In order to get the similarity for two words, we could check the entry in the thesaurus for either word. But given that the thesaurus is not symmetric, we take the average of both similarities. We will refer to this similarity measure as simth lin. Another option is to use second-o</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In COLING-ACL, pages 768–774.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Mirella Lapata</author>
</authors>
<title>Dependencybased construction of semantic space models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<marker>Pad´o, Lapata, 2007</marker>
<rawString>Sebastian Pad´o and Mirella Lapata. 2007. Dependencybased construction of semantic space models. Computational Linguistics, 33(2):161–199, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Dekang Lin</author>
</authors>
<title>An unsupervised approach to prepositional phrase attachment using contextually similar words.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Conference of the ACL,</booktitle>
<pages>101--108</pages>
<contexts>
<context position="4044" citStr="Pantel and Lin (2000)" startWordPosition="583" endWordPosition="586"> Resnik’s selectional preferences) on a syntactic plausibility judgement task for German. The models return weights for (verb, syntactic function, noun) triples, and the correlation with human plausibility judgement is used for evaluation. Resnik’s selectional preference scored best among classbased methods, but it performed equal to a simple, purely lexical, conditional probability model. 73 Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 73–76, Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP Distributional similarity has also been used to tackle syntactic ambiguity. Pantel and Lin (2000) obtained very good results using the distributional similarity measure defined by Lin (1998). The application of selectional preferences to semantic roles (as opposed to syntactic functions) is more recent. Gildea and Jurafsky (2002) is the only one applying selectional preferences in a real SRL task. They used distributional clustering and WordNet-based techniques on a SRL task on FrameNet roles. They report a very small improvement of the overall performance when using distributional clustering techniques. In this paper we present complementary experiments, with a different role set and ann</context>
</contexts>
<marker>Pantel, Lin, 2000</marker>
<rawString>Patrick Pantel and Dekang Lin. 2000. An unsupervised approach to prepositional phrase attachment using contextually similar words. In Proceedings of the 38th Annual Conference of the ACL, pages 101–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pradhan</author>
<author>W Ward</author>
<author>J H Martin</author>
</authors>
<title>Towards robust semantic role labeling.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="11673" citStr="Pradhan et al., 2008" startWordPosition="1814" endWordPosition="1817">630 .494 .464 .478 simth2 .657 .646 .651 .531 .499 .515 Jac .654 .644 .649 .531 .499 .515 simth2 cos Table 1: Results for WSJ test (left), and Brown test (right) co-occurrences extracted from the BNC (simJac, simcos simLin), and the results obtained when using Lin’s thesaurus directly (simthLin) and as a second-order vector (simth2 Jac and simth2 cos). As expected, the lexical baseline attains very high precision in all datasets, which underscores the importance of the lexical head word features in argument classification. The recall is quite low, specially in Brown, confirming and extending (Pradhan et al., 2008), which also reports similar performance drops when doing argument classification on out-of-domain data. One of the main goals of our experiments is to overcome the data sparseness of lexical features both on in-domain and out-of-domain data. All our selectional preference models improve over the lexical matching baseline in recall, up to 30 absolute percentage points in the WSJ test dataset and 44 absolute percentage points in the Brown corpus. This comes at the cost of reduced precision, but the overall F-score shows that all selectional preference models improve over the baseline, with up t</context>
</contexts>
<marker>Pradhan, Ward, Martin, 2008</marker>
<rawString>S. Pradhan, W. Ward, and J. H. Martin. 2008. Towards robust semantic role labeling. Computational Linguistics, 34(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Semantic classes and syntactic ambiguity.</title>
<date>1993</date>
<booktitle>In Proceedings of the workshop on Human Language Technology,</booktitle>
<pages>278--283</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="3178" citStr="Resnik (1993)" startWordPosition="464" endWordPosition="465">headword according to the selectional preference model. This problem is directly connected to argument classification in SRL, but we have isolated the evaluation from the complete SRL task. This first step allows us to analyze the potential of selectional preferences as a source of semantic knowledge for discriminating among different role labels. Ongoing work is devoted to the integration of selectional preference–derived features in a complete SRL system. 2 Related Work Automatic acquisition of selectional preferences is a relatively old topic, and will mention the most relevant references. Resnik (1993) proposed to model selectional preferences using semantic classes from WordNet in order to tackle ambiguity issues in syntax (noun-compounds, coordination, PP-attachment). Brockman and Lapata (2003) compared several class-based models (including Resnik’s selectional preferences) on a syntactic plausibility judgement task for German. The models return weights for (verb, syntactic function, noun) triples, and the correlation with human plausibility judgement is used for evaluation. Resnik’s selectional preference scored best among classbased methods, but it performed equal to a simple, purely le</context>
</contexts>
<marker>Resnik, 1993</marker>
<rawString>Philip Resnik. 1993. Semantic classes and syntactic ambiguity. In Proceedings of the workshop on Human Language Technology, pages 278–283, Morristown, NJ, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>