<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000179">
<title confidence="0.83447">
Book Reviews
Parsing Schemata for Practical Text Analysis
</title>
<author confidence="0.891284">
Carlos G´omez Rodriguez
</author>
<affiliation confidence="0.6235">
(University of A Coru˜na)
London: Imperial College Press (Mathematics, computing, language, and life
</affiliation>
<figure confidence="0.55290525">
series, edited by Carlos Martin-Vide, volume 1), 2010, xiv+275 pp; hardbound,
ISBN 978-1-84816-560-1, $89.00
Reviewed by
Anoop Sarkar
</figure>
<affiliation confidence="0.404722">
Simon Fraser University
</affiliation>
<bodyText confidence="0.968305692307692">
Deductive systems are a widely used exposition technique in contemporary computa-
tional linguistics to explain novel parsing algorithms (e.g., Huang and Sagae 2010) and
decoders in machine translation (e.g., Huang and Mi 2010). Deductive parsing provides
a succinct formal syntax that abstracts away the implementation details yet directly
reflects the time and space complexity of the underlying algorithm.
A deductive system can be viewed as a domain-specific declarative schema that
specifies a parser at an abstract level, focusing on the semantics of the parser actions
rather than implementation. The schema itself can be compiled into an executable parser
allowing implementation optimizations to be shared across different parsing algo-
rithms. Schemas thus provide quick prototyping of parsing algorithms. In the notation
used by the compiler described in this book we would describe the familiar CYK parsing
algorithm (Kasami 1965; Younger 1967) as the following declarative specification:
@step Unary
</bodyText>
<equation confidence="0.981028142857143">
[a, i, i + 1] A → a
[A,i,i + 1]
@step Binary
[B, i, j]
[C,j,k] A → B C
[A, i, k]
@goal [S, 0, length]
</equation>
<bodyText confidence="0.999027636363636">
Deductive systems can provide a framework to prove correctness (soundness and
completeness) of a parsing algorithm. Well-formed transformations of deductive sys-
tems would permit the addition of new capabilities such as weighted rules in the
grammar. Deductive systems could also provide a means to compare different parsing
algorithms. This book provides several examples of how such properties can be useful
in parsing theory and parsing implementation, in particular for converting a parser
into an error-correcting parser and explicitly showing the relationship between several
dependency parsing algorithms.
Sikkel’s definition of parsing schemas (Sikkel 1997) extends deductive systems
by formally defining the semantics of items and related concepts used in deductive
systems. In particular, items are sets of partial constituency trees that are licensed by
</bodyText>
<footnote confidence="0.335401">
© 2011 Association for Computational Linguistics
Computational Linguistics Volume 37, Number 4
</footnote>
<bodyText confidence="0.99994670212766">
rules of the grammar. As a result, parsing schemas allow compilation of schemas to
executable parsers and also permit formal reasoning about properties of the parser
directly. Unlike many deductive systems used to define parsers, there is no one-to-
one relationship between a parsing schema and algorithm. In later work, Alonso Pardo
et al. (1999) showed parsing schemas can be used to define parsers for other grammar
formalisms such as tree-adjoining grammars.
This book, which is an extended version of Carlos G´omez Rodr´ıguez’s Ph.D. thesis
work, extends the theory and practice of parsing schemas in several directions. There
are three major parts to this book:
Compiling and executing parsing schemas. The first part of the book provides a language
syntax that can be used to precisely specify parsing schemas and a compiler for this
domain-specific language. The syntax is shown in the CYK example above. The full
specification also includes interpretations for indices such as i and i + 1 as word posi-
tions, A, B, C as grammar symbols, and how deduction steps and goals are converted
into parser code. The implementation details, including static analysis of the schema
and the Java code generation, are described well and in sufficient detail. The source
code of the compiler for parsing schemas is available for download at www.grupocole.
org/software/COMPAS. (The code is typical research software—it takes some effort to
use it, but once you do, you can play with compiling and running most of the schemas
in the book.) This part of the book contains experiments on comparing many different
parsing schemas for each of these formalisms. The comparison is done using hand-
written grammars with feature structures (the parsers include feature unification) and
evaluated on test-suite data rather than on modern Treebank grammars and data from
newswire and other “real-world” data. Another issue is that the comparison does not
include the GHR parser (Graham, Harrison, and Ruzzo 1980), which may impact the
comparison between CYK and Earley parsers. Also, interesting synthetic-data exper-
iments are presented that compare tree-adjoining parsers with context-free parsers; it
is not clear whether these results extend to natural language corpora. With regard to
implementation of schemas, the focus is mainly on agenda-based implementation of de-
ductive steps rather than, say, the use of (pushdown) transducers to produce parse trees.
Error-repair parsers. The second part of the book focuses on error-repair in parsing (using
parsing schemas, of course). Such an approach tries to deal with limited coverage of the
grammar by performing insertions, deletions, or substitutions on the input string. This
makes a lot of sense in programming language parsers, but for natural languages it
makes little sense to transform the input because the grammar has poor coverage. It is
trivial to add (weighted) glue rules that accept any input string, or a finite-state acceptor
of strings can be used as a back-off grammar to improve coverage. Speech repair and
other such cases are typically handled using appropriate augmentations of the under-
lying grammar combined with grammar-driven edits (Charniak and Johnson 2001).
Despite this, error-repair is a good use-case for parsing schemas. G´omez Rodr´ıguez can
show that some existing error-repair parsers are in fact provably correct, and also a
generic recipe can be given that converts any given parser schema into an error-repair
parser schema. This is an instructive use of parsing schema transformations, because it
is easy to show that the changes preserve correctness.
Parsing schemas for dependency parsers. This third part of the book has the potential to be
the most popular. There is increased interest in multilingual dependency parsing, and
there are a large number of different dependency parsing algorithms. Parsing schemas
</bodyText>
<page confidence="0.985838">
882
</page>
<subsectionHeader confidence="0.809679">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.999203487804878">
allow a concise description of many different parsing algorithms, and G´omez Rodriguez
provides many parsing schemas corresponding to popular dependency parsing algo-
rithms; there are too many to list here, but he provides schemas for no less than ten
dependency parsers, including some that recover non-projective dependencies. He also
provides explicit relationships between schemas for these varied parsers, such as item
refinement (an item deduced in one parser is broken up as multiple items in another
parser) or step refinement (a deduction step in one parser can be emulated by a sequence
of steps in another parser). It is also useful that these relationships are transitive and
reflexive. However, it is in describing dependency parsing that the biggest weakness
of parsing schemas is exposed and its potential role as an universal language for the
parsing community runs into trouble. Non-constructive aspects of parsing cannot be
represented with a schema, because that violates the semantics of deductive steps.
For instance, in a parser that computes the dependency tree by using the minimum
spanning tree (MST) algorithm (McDonald et al. 2005), there is a step that eliminates
cycles in the graph. This step is not constructive and therefore the MST parser cannot
be represented as a schema. Parsing schemas are generally grammar-driven and often
parsers are written without any finite underlying grammar, which makes tree building
harder to describe concisely.
The discussion of related work touches on the use of Prolog for parsing schemas
(Shieber, Schabes, and Pereira 1995), Datalog for specifying parsers (McAllester 2002;
Liu and Stoller 2003), the DyALog system (Villemonte de la Clergerie 2005), and Dyna
(Eisner, Goldlust, and Smith 2005). It is true that Dyna is quite powerful because it is a
full general-purpose declarative programming language, but for that reason it offers
an attractive alternative to parsing schemas. On the other hand, schemas do allow
formal reasoning about parsers that may be more fine-grained than is possible in Dyna.
Surprisingly, work on semiring parsing (Goodman 1998, 1999) is not mentioned. The
use of probabilities or weights is generally ignored in this book, even though it enables
interesting methods for speeding up parsers such as coarse to fine parsing (Goodman
1997) or generalized A∗ search for parsing (Pauls and Klein 2009). While there is more
than enough content in this book, it does not cover the use of parsing schemas in
machine translation. In particular, formal properties of schemas might make it easier
to describe and implement the integration of language models into parsing algorithms
for synchronous context-free grammars (Chiang 2007). Schemas might have much to
offer with respect to proving correctness in machine translation decoders.
The potential reader for this book is likely to be a parsing enthusiast curious about
the power of schemas to represent parsing algorithms succinctly and to prove them
correct. They might also be interested in showing relationships between their novel
parsing schemas and other well-known parsers, or showing how extensions to existing
parsers are well justified. Dependency parsing enthusiasts who want to wrap their head
around the many different parsing algorithms out there might also be interested in the
concise description of such parsers.
</bodyText>
<note confidence="0.844868">
References Charniak, Eugene and Mark Johnson.
Alonso Pardo, Miguel A., David Cabrero 2001. Edit detection and parsing for
</note>
<bodyText confidence="0.294120142857143">
Souto, Eric de la Clergerie, and transcribed speech. In Proceedings
Manuel Vilares Ferro. 1999. Tabular of the Second Meeting of the North
algorithms for TAG parsing. In American Chapter of the Association for
Proceedings of the Ninth Conference Computational Linguistics, Pittsburgh, PA.
of the European Chapter of the Association Chiang, David. 2007. Hierarchical
for Computational Linguistics, phrase-based translation. Computational
pages 150–157, Bergen. Linguistics, 33(2):201–228.
</bodyText>
<page confidence="0.98721">
883
</page>
<note confidence="0.766006833333333">
Computational Linguistics Volume 37, Number 4
Eisner, Jason, Eric Goldlust, and Noah A.
Smith. 2005. Compiling comp ling:
Weighted dynamic programming and the
Dyna language. In Proceedings of the Human
Language Technology Conference and
</note>
<reference confidence="0.983780156626506">
Conference on Empirical Methods in Natural
Language Processing, pages 281–290,
Vancouver, Canada.
Goodman, Joshua. 1997. Global thresholding
and multiple-pass parsing. In Proceedings
of the Second Conference on Empirical
Methods in Natural Language Processing:
EMNLP-1997, pages 11–25, Providence, RI.
Goodman, Joshua. 1998. Parsing inside-out.
Ph.D. thesis, Harvard University,
Cambridge, MA.
Goodman, Joshua. 1999. Semiring parsing.
Computational Linguistics, 25(4):573–605.
Graham, Susan L., Michael Harrison, and
Walter L. Ruzzo.1980. An improved
context-free recognizer. ACM Transactions
on Programming Languages and Systems,
2(3):415–462.
Huang, Liang and Haitao Mi. 2010. Efficient
incremental decoding for tree-to-string
translation. In Proceedings of the 2010
Conference on Empirical Methods in Natural
Language Processing, pages 273–283,
Cambridge, MA.
Huang, Liang and Kenji Sagae. 2010.
Dynamic programming for linear-time
incremental parsing. In Proceedings of the
48th Annual Meeting of the Association for
Computational Linguistics, pages 1077–1086,
Uppsala.
Kasami, Tadao. 1965. An efficient recognition
and syntax analysis algorithm for
context-free languages. Technical Report
AFCRL-65-758, Air Force Cambridge
Research Laboratory, Bedford, MA.
Liu, Yanhong A. and Scott D. Stoller. 2003.
From Datalog rules to efficient programs
with time and space guarantees. In
Proceedings of the 5th ACM SIGPLAN
International Conference on Principles and
Practice of Declarative Programming,
pages 172–183, Uppsala, Sweden.
McAllester, David. 2002. On the complexity
analysis of static analyses. Journal of the
Association for Computing Machinery,
49(4):512–537.
McDonald, Ryan T., Fernando Pereira,
Kiril Ribarov, and Jan Hajiˇc. 2005.
Non-projective dependency parsing using
spanning tree algorithms. In Proceedings
of the Human Language Technologies and
Empirical Methods in Natural Language
Processing Conference, pages 523–530,
Vancouver, Canada.
Pauls, Adam and Dan Klein. 2009.
Hierarchical search for parsing.
In Proceedings of Human Language
Technologies: The 2009 Annual Conference
of the North American Chapter of the
Association for Computational Linguistics,
pages 557–565, Boulder, CO.
Shieber, Stuart M., Yves Schabes, and
Fernando C. N. Pereira. 1995. Principles
and implementation of deductive
parsing. Journal of Logic Programming,
24(1–2):3–36.
Sikkel, Klaas. 1997. Parsing Schemata:
A Framework for Specification and Analysis
of Parsing Algorithms. Springer, Berlin.
Villemonte de la Clergerie, ´Eric. 2005.
DyALog: a Tabular Logic Programming
based environment for NLP. Proceedings
of the 2nd International Workshop on
Constraint Solving and Language
Processing, Barcelona, Spain.
Younger, Daniel H. 1967. Recognition and
parsing of context-free languages in time
n3. Information and Control, 10:189–208.
Anoop Sarkar is an Associate Professor at Simon Fraser University, Burnaby, BC, Canada, where
he co-directs the Natural Language Laboratory (natlang.cs.sfu.ca). His research is focused on
statistical parsing and machine translation. His interests also include formal language theory and
stochastic grammars, in particular tree automata and tree-adjoining grammars. His e-mail address
is anoop@cs.sfu.ca.
</reference>
<page confidence="0.998595">
884
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.998188">Book Reviews Parsing Schemata for Practical Text Analysis</title>
<author confidence="0.999367">Carlos G´omez Rodriguez</author>
<affiliation confidence="0.931403">of A</affiliation>
<note confidence="0.83314675">London: Imperial College Press (Mathematics, computing, language, and life series, edited by Carlos Martin-Vide, volume 1), 2010, xiv+275 pp; hardbound, ISBN 978-1-84816-560-1, $89.00 Reviewed by</note>
<author confidence="0.74551">Anoop Sarkar</author>
<affiliation confidence="0.832591">Simon Fraser University</affiliation>
<abstract confidence="0.992349841666666">Deductive systems are a widely used exposition technique in contemporary computational linguistics to explain novel parsing algorithms (e.g., Huang and Sagae 2010) and decoders in machine translation (e.g., Huang and Mi 2010). Deductive parsing provides a succinct formal syntax that abstracts away the implementation details yet directly reflects the time and space complexity of the underlying algorithm. A deductive system can be viewed as a domain-specific declarative schema that specifies a parser at an abstract level, focusing on the semantics of the parser actions rather than implementation. The schema itself can be compiled into an executable parser allowing implementation optimizations to be shared across different parsing algorithms. Schemas thus provide quick prototyping of parsing algorithms. In the notation used by the compiler described in this book we would describe the familiar CYK parsing algorithm (Kasami 1965; Younger 1967) as the following declarative specification: Unary 1]A Binary C 0, Deductive systems can provide a framework to prove correctness (soundness and completeness) of a parsing algorithm. Well-formed transformations of deductive systems would permit the addition of new capabilities such as weighted rules in the grammar. Deductive systems could also provide a means to compare different parsing algorithms. This book provides several examples of how such properties can be useful in parsing theory and parsing implementation, in particular for converting a parser into an error-correcting parser and explicitly showing the relationship between several dependency parsing algorithms. Sikkel’s definition of parsing schemas (Sikkel 1997) extends deductive systems by formally defining the semantics of items and related concepts used in deductive systems. In particular, items are sets of partial constituency trees that are licensed by © 2011 Association for Computational Linguistics Computational Linguistics Volume 37, Number 4 rules of the grammar. As a result, parsing schemas allow compilation of schemas to executable parsers and also permit formal reasoning about properties of the parser directly. Unlike many deductive systems used to define parsers, there is no one-toone relationship between a parsing schema and algorithm. In later work, Alonso Pardo et al. (1999) showed parsing schemas can be used to define parsers for other grammar formalisms such as tree-adjoining grammars. This book, which is an extended version of Carlos G´omez Rodr´ıguez’s Ph.D. thesis work, extends the theory and practice of parsing schemas in several directions. There are three major parts to this book: and executing parsing schemas. first part of the book provides a language syntax that can be used to precisely specify parsing schemas and a compiler for this domain-specific language. The syntax is shown in the CYK example above. The full also includes interpretations for indices such as as word posigrammar symbols, and how deduction steps and goals are converted into parser code. The implementation details, including static analysis of the schema and the Java code generation, are described well and in sufficient detail. The source of the compiler for parsing schemas is available for download at (The code is typical research software—it takes some effort to use it, but once you do, you can play with compiling and running most of the schemas in the book.) This part of the book contains experiments on comparing many different parsing schemas for each of these formalisms. The comparison is done using handwritten grammars with feature structures (the parsers include feature unification) and evaluated on test-suite data rather than on modern Treebank grammars and data from newswire and other “real-world” data. Another issue is that the comparison does not include the GHR parser (Graham, Harrison, and Ruzzo 1980), which may impact the comparison between CYK and Earley parsers. Also, interesting synthetic-data experiments are presented that compare tree-adjoining parsers with context-free parsers; it is not clear whether these results extend to natural language corpora. With regard to implementation of schemas, the focus is mainly on agenda-based implementation of deductive steps rather than, say, the use of (pushdown) transducers to produce parse trees. parsers. second part of the book focuses on error-repair in parsing (using parsing schemas, of course). Such an approach tries to deal with limited coverage of the grammar by performing insertions, deletions, or substitutions on the input string. This makes a lot of sense in programming language parsers, but for natural languages it makes little sense to transform the input because the grammar has poor coverage. It is trivial to add (weighted) glue rules that accept any input string, or a finite-state acceptor of strings can be used as a back-off grammar to improve coverage. Speech repair and other such cases are typically handled using appropriate augmentations of the underlying grammar combined with grammar-driven edits (Charniak and Johnson 2001). Despite this, error-repair is a good use-case for parsing schemas. G´omez Rodr´ıguez can show that some existing error-repair parsers are in fact provably correct, and also a generic recipe can be given that converts any given parser schema into an error-repair parser schema. This is an instructive use of parsing schema transformations, because it is easy to show that the changes preserve correctness. schemas for dependency parsers. third part of the book has the potential to be the most popular. There is increased interest in multilingual dependency parsing, and there are a large number of different dependency parsing algorithms. Parsing schemas 882 Book Reviews allow a concise description of many different parsing algorithms, and G´omez Rodriguez provides many parsing schemas corresponding to popular dependency parsing algorithms; there are too many to list here, but he provides schemas for no less than ten dependency parsers, including some that recover non-projective dependencies. He also provides explicit relationships between schemas for these varied parsers, such as item refinement (an item deduced in one parser is broken up as multiple items in another parser) or step refinement (a deduction step in one parser can be emulated by a sequence of steps in another parser). It is also useful that these relationships are transitive and reflexive. However, it is in describing dependency parsing that the biggest weakness of parsing schemas is exposed and its potential role as an universal language for the parsing community runs into trouble. Non-constructive aspects of parsing cannot be represented with a schema, because that violates the semantics of deductive steps. For instance, in a parser that computes the dependency tree by using the minimum spanning tree (MST) algorithm (McDonald et al. 2005), there is a step that eliminates cycles in the graph. This step is not constructive and therefore the MST parser cannot be represented as a schema. Parsing schemas are generally grammar-driven and often parsers are written without any finite underlying grammar, which makes tree building harder to describe concisely. The discussion of related work touches on the use of Prolog for parsing schemas (Shieber, Schabes, and Pereira 1995), Datalog for specifying parsers (McAllester 2002; Liu and Stoller 2003), the DyALog system (Villemonte de la Clergerie 2005), and Dyna (Eisner, Goldlust, and Smith 2005). It is true that Dyna is quite powerful because it is a full general-purpose declarative programming language, but for that reason it offers an attractive alternative to parsing schemas. On the other hand, schemas do allow formal reasoning about parsers that may be more fine-grained than is possible in Dyna. Surprisingly, work on semiring parsing (Goodman 1998, 1999) is not mentioned. The use of probabilities or weights is generally ignored in this book, even though it enables interesting methods for speeding up parsers such as coarse to fine parsing (Goodman or generalized for parsing (Pauls and Klein 2009). While there is more than enough content in this book, it does not cover the use of parsing schemas in machine translation. In particular, formal properties of schemas might make it easier to describe and implement the integration of language models into parsing algorithms for synchronous context-free grammars (Chiang 2007). Schemas might have much to offer with respect to proving correctness in machine translation decoders. The potential reader for this book is likely to be a parsing enthusiast curious about the power of schemas to represent parsing algorithms succinctly and to prove them correct. They might also be interested in showing relationships between their novel parsing schemas and other well-known parsers, or showing how extensions to existing parsers are well justified. Dependency parsing enthusiasts who want to wrap their head around the many different parsing algorithms out there might also be interested in the concise description of such parsers.</abstract>
<note confidence="0.878854818181818">References Charniak, Eugene and Mark Johnson. 2001. Edit detection and parsing for speech. In of the Second Meeting of the North American Chapter of the Association for Pittsburgh, PA. Alonso Pardo, Miguel A., David Cabrero Souto, Eric de la Clergerie, and Manuel Vilares Ferro. 1999. Tabular algorithms for TAG parsing. In Proceedings of the Ninth Conference of the European Chapter of the Association Computational pages 150–157, Bergen. Chiang, David. 2007. Hierarchical translation. 33(2):201–228. 883 Computational Linguistics Volume 37, Number 4 Eisner, Jason, Eric Goldlust, and Noah A. Smith. 2005. Compiling comp ling: Weighted dynamic programming and the language. In of the Human Language Technology Conference and Conference on Empirical Methods in Natural pages 281–290,</note>
<address confidence="0.892262">Vancouver, Canada. Goodman, Joshua. 1997. Global thresholding</address>
<abstract confidence="0.578644">multiple-pass parsing. In of the Second Conference on Empirical</abstract>
<note confidence="0.891712666666667">Methods in Natural Language Processing: pages 11–25, Providence, RI. Joshua. 1998.</note>
<affiliation confidence="0.628888">Ph.D. thesis, Harvard University,</affiliation>
<address confidence="0.671655">Cambridge, MA. Goodman, Joshua. 1999. Semiring parsing.</address>
<email confidence="0.210897">25(4):573–605.</email>
<author confidence="0.486927">Susan L Graham</author>
<author confidence="0.486927">Michael Harrison</author>
<abstract confidence="0.706346777777778">Walter L. Ruzzo.1980. An improved recognizer. Transactions Programming Languages and 2(3):415–462. Huang, Liang and Haitao Mi. 2010. Efficient incremental decoding for tree-to-string In of the 2010 Conference on Empirical Methods in Natural pages 273–283,</abstract>
<address confidence="0.432099">Cambridge, MA.</address>
<note confidence="0.7704835">Huang, Liang and Kenji Sagae. 2010. Dynamic programming for linear-time parsing. In of the 48th Annual Meeting of the Association for pages 1077–1086, Uppsala. Kasami, Tadao. 1965. An efficient recognition and syntax analysis algorithm for context-free languages. Technical Report AFCRL-65-758, Air Force Cambridge Research Laboratory, Bedford, MA. Liu, Yanhong A. and Scott D. Stoller. 2003. From Datalog rules to efficient programs with time and space guarantees. In Proceedings of the 5th ACM SIGPLAN International Conference on Principles and of Declarative pages 172–183, Uppsala, Sweden. McAllester, David. 2002. On the complexity of static analyses. of the for Computing 49(4):512–537. McDonald, Ryan T., Fernando Pereira, Kiril Ribarov, and Jan Hajiˇc. 2005.</note>
<title confidence="0.511566">Non-projective dependency parsing using</title>
<author confidence="0.405941">In</author>
<affiliation confidence="0.4221195">of the Human Language Technologies and Empirical Methods in Natural Language</affiliation>
<address confidence="0.7673705">pages 523–530, Vancouver, Canada.</address>
<note confidence="0.8853039375">Pauls, Adam and Dan Klein. 2009. Hierarchical search for parsing. of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the for Computational pages 557–565, Boulder, CO. Shieber, Stuart M., Yves Schabes, and Fernando C. N. Pereira. 1995. Principles and implementation of deductive of Logic 24(1–2):3–36. Klaas. 1997. Schemata: A Framework for Specification and Analysis Parsing Springer, Berlin. Villemonte de la Clergerie, ´Eric. 2005.</note>
<title confidence="0.6479485">DyALog: a Tabular Logic Programming environment for NLP. of the 2nd International Workshop on Constraint Solving and Language</title>
<address confidence="0.877182">Barcelona, Spain. Younger, Daniel H. 1967. Recognition and</address>
<abstract confidence="0.9834525">parsing of context-free languages in time and 10:189–208. Sarkar an Associate Professor at Simon Fraser University, Burnaby, BC, Canada, where co-directs the Natural Language Laboratory His research is focused on statistical parsing and machine translation. His interests also include formal language theory and stochastic grammars, in particular tree automata and tree-adjoining grammars. His e-mail address</abstract>
<intro confidence="0.55321">884</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>281--290</pages>
<location>Vancouver, Canada.</location>
<marker></marker>
<rawString>Conference on Empirical Methods in Natural Language Processing, pages 281–290, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joshua Goodman</author>
</authors>
<title>Global thresholding and multiple-pass parsing.</title>
<date>1997</date>
<booktitle>In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing: EMNLP-1997,</booktitle>
<pages>11--25</pages>
<location>Providence, RI.</location>
<contexts>
<context position="8651" citStr="Goodman 1997" startWordPosition="1327" endWordPosition="1328">d Dyna (Eisner, Goldlust, and Smith 2005). It is true that Dyna is quite powerful because it is a full general-purpose declarative programming language, but for that reason it offers an attractive alternative to parsing schemas. On the other hand, schemas do allow formal reasoning about parsers that may be more fine-grained than is possible in Dyna. Surprisingly, work on semiring parsing (Goodman 1998, 1999) is not mentioned. The use of probabilities or weights is generally ignored in this book, even though it enables interesting methods for speeding up parsers such as coarse to fine parsing (Goodman 1997) or generalized A∗ search for parsing (Pauls and Klein 2009). While there is more than enough content in this book, it does not cover the use of parsing schemas in machine translation. In particular, formal properties of schemas might make it easier to describe and implement the integration of language models into parsing algorithms for synchronous context-free grammars (Chiang 2007). Schemas might have much to offer with respect to proving correctness in machine translation decoders. The potential reader for this book is likely to be a parsing enthusiast curious about the power of schemas to </context>
</contexts>
<marker>Goodman, 1997</marker>
<rawString>Goodman, Joshua. 1997. Global thresholding and multiple-pass parsing. In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing: EMNLP-1997, pages 11–25, Providence, RI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joshua Goodman</author>
</authors>
<title>Parsing inside-out.</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<institution>Harvard University,</institution>
<location>Cambridge, MA.</location>
<contexts>
<context position="8442" citStr="Goodman 1998" startWordPosition="1293" endWordPosition="1294">s on the use of Prolog for parsing schemas (Shieber, Schabes, and Pereira 1995), Datalog for specifying parsers (McAllester 2002; Liu and Stoller 2003), the DyALog system (Villemonte de la Clergerie 2005), and Dyna (Eisner, Goldlust, and Smith 2005). It is true that Dyna is quite powerful because it is a full general-purpose declarative programming language, but for that reason it offers an attractive alternative to parsing schemas. On the other hand, schemas do allow formal reasoning about parsers that may be more fine-grained than is possible in Dyna. Surprisingly, work on semiring parsing (Goodman 1998, 1999) is not mentioned. The use of probabilities or weights is generally ignored in this book, even though it enables interesting methods for speeding up parsers such as coarse to fine parsing (Goodman 1997) or generalized A∗ search for parsing (Pauls and Klein 2009). While there is more than enough content in this book, it does not cover the use of parsing schemas in machine translation. In particular, formal properties of schemas might make it easier to describe and implement the integration of language models into parsing algorithms for synchronous context-free grammars (Chiang 2007). Sch</context>
</contexts>
<marker>Goodman, 1998</marker>
<rawString>Goodman, Joshua. 1998. Parsing inside-out. Ph.D. thesis, Harvard University, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joshua Goodman</author>
</authors>
<title>Semiring parsing.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>4</issue>
<marker>Goodman, 1999</marker>
<rawString>Goodman, Joshua. 1999. Semiring parsing. Computational Linguistics, 25(4):573–605.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Susan L Graham</author>
<author>Michael Harrison</author>
<author>Walter L Ruzzo 1980</author>
</authors>
<title>An improved context-free recognizer.</title>
<journal>ACM Transactions on Programming Languages and Systems,</journal>
<volume>2</volume>
<issue>3</issue>
<marker>Graham, Harrison, 1980, </marker>
<rawString>Graham, Susan L., Michael Harrison, and Walter L. Ruzzo.1980. An improved context-free recognizer. ACM Transactions on Programming Languages and Systems, 2(3):415–462.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Haitao Mi</author>
</authors>
<title>Efficient incremental decoding for tree-to-string translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>273--283</pages>
<location>Cambridge, MA.</location>
<marker>Huang, Mi, 2010</marker>
<rawString>Huang, Liang and Haitao Mi. 2010. Efficient incremental decoding for tree-to-string translation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 273–283, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kenji Sagae</author>
</authors>
<title>Dynamic programming for linear-time incremental parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1077--1086</pages>
<location>Uppsala.</location>
<marker>Huang, Sagae, 2010</marker>
<rawString>Huang, Liang and Kenji Sagae. 2010. Dynamic programming for linear-time incremental parsing. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1077–1086, Uppsala.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tadao Kasami</author>
</authors>
<title>An efficient recognition and syntax analysis algorithm for context-free languages.</title>
<date>1965</date>
<tech>Technical Report AFCRL-65-758,</tech>
<institution>Air Force Cambridge Research Laboratory,</institution>
<location>Bedford, MA.</location>
<contexts>
<context position="1278" citStr="Kasami 1965" startWordPosition="181" endWordPosition="182">yet directly reflects the time and space complexity of the underlying algorithm. A deductive system can be viewed as a domain-specific declarative schema that specifies a parser at an abstract level, focusing on the semantics of the parser actions rather than implementation. The schema itself can be compiled into an executable parser allowing implementation optimizations to be shared across different parsing algorithms. Schemas thus provide quick prototyping of parsing algorithms. In the notation used by the compiler described in this book we would describe the familiar CYK parsing algorithm (Kasami 1965; Younger 1967) as the following declarative specification: @step Unary [a, i, i + 1] A → a [A,i,i + 1] @step Binary [B, i, j] [C,j,k] A → B C [A, i, k] @goal [S, 0, length] Deductive systems can provide a framework to prove correctness (soundness and completeness) of a parsing algorithm. Well-formed transformations of deductive systems would permit the addition of new capabilities such as weighted rules in the grammar. Deductive systems could also provide a means to compare different parsing algorithms. This book provides several examples of how such properties can be useful in parsing theory</context>
</contexts>
<marker>Kasami, 1965</marker>
<rawString>Kasami, Tadao. 1965. An efficient recognition and syntax analysis algorithm for context-free languages. Technical Report AFCRL-65-758, Air Force Cambridge Research Laboratory, Bedford, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yanhong A Liu</author>
<author>Scott D Stoller</author>
</authors>
<title>From Datalog rules to efficient programs with time and space guarantees.</title>
<date>2003</date>
<booktitle>In Proceedings of the 5th ACM SIGPLAN International Conference on Principles and Practice of Declarative Programming,</booktitle>
<pages>172--183</pages>
<location>Uppsala,</location>
<contexts>
<context position="7981" citStr="Liu and Stoller 2003" startWordPosition="1219" endWordPosition="1222">parser that computes the dependency tree by using the minimum spanning tree (MST) algorithm (McDonald et al. 2005), there is a step that eliminates cycles in the graph. This step is not constructive and therefore the MST parser cannot be represented as a schema. Parsing schemas are generally grammar-driven and often parsers are written without any finite underlying grammar, which makes tree building harder to describe concisely. The discussion of related work touches on the use of Prolog for parsing schemas (Shieber, Schabes, and Pereira 1995), Datalog for specifying parsers (McAllester 2002; Liu and Stoller 2003), the DyALog system (Villemonte de la Clergerie 2005), and Dyna (Eisner, Goldlust, and Smith 2005). It is true that Dyna is quite powerful because it is a full general-purpose declarative programming language, but for that reason it offers an attractive alternative to parsing schemas. On the other hand, schemas do allow formal reasoning about parsers that may be more fine-grained than is possible in Dyna. Surprisingly, work on semiring parsing (Goodman 1998, 1999) is not mentioned. The use of probabilities or weights is generally ignored in this book, even though it enables interesting methods</context>
</contexts>
<marker>Liu, Stoller, 2003</marker>
<rawString>Liu, Yanhong A. and Scott D. Stoller. 2003. From Datalog rules to efficient programs with time and space guarantees. In Proceedings of the 5th ACM SIGPLAN International Conference on Principles and Practice of Declarative Programming, pages 172–183, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McAllester</author>
</authors>
<title>On the complexity analysis of static analyses.</title>
<date>2002</date>
<journal>Journal of the Association for Computing Machinery,</journal>
<volume>49</volume>
<issue>4</issue>
<contexts>
<context position="7958" citStr="McAllester 2002" startWordPosition="1217" endWordPosition="1218">r instance, in a parser that computes the dependency tree by using the minimum spanning tree (MST) algorithm (McDonald et al. 2005), there is a step that eliminates cycles in the graph. This step is not constructive and therefore the MST parser cannot be represented as a schema. Parsing schemas are generally grammar-driven and often parsers are written without any finite underlying grammar, which makes tree building harder to describe concisely. The discussion of related work touches on the use of Prolog for parsing schemas (Shieber, Schabes, and Pereira 1995), Datalog for specifying parsers (McAllester 2002; Liu and Stoller 2003), the DyALog system (Villemonte de la Clergerie 2005), and Dyna (Eisner, Goldlust, and Smith 2005). It is true that Dyna is quite powerful because it is a full general-purpose declarative programming language, but for that reason it offers an attractive alternative to parsing schemas. On the other hand, schemas do allow formal reasoning about parsers that may be more fine-grained than is possible in Dyna. Surprisingly, work on semiring parsing (Goodman 1998, 1999) is not mentioned. The use of probabilities or weights is generally ignored in this book, even though it enab</context>
</contexts>
<marker>McAllester, 2002</marker>
<rawString>McAllester, David. 2002. On the complexity analysis of static analyses. Journal of the Association for Computing Machinery, 49(4):512–537.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan T McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of the Human Language Technologies and Empirical Methods in Natural Language Processing Conference,</booktitle>
<pages>523--530</pages>
<location>Vancouver, Canada.</location>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>McDonald, Ryan T., Fernando Pereira, Kiril Ribarov, and Jan Hajiˇc. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of the Human Language Technologies and Empirical Methods in Natural Language Processing Conference, pages 523–530, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Pauls</author>
<author>Dan Klein</author>
</authors>
<date>2009</date>
<note>Hierarchical search for parsing.</note>
<contexts>
<context position="8711" citStr="Pauls and Klein 2009" startWordPosition="1335" endWordPosition="1338">e that Dyna is quite powerful because it is a full general-purpose declarative programming language, but for that reason it offers an attractive alternative to parsing schemas. On the other hand, schemas do allow formal reasoning about parsers that may be more fine-grained than is possible in Dyna. Surprisingly, work on semiring parsing (Goodman 1998, 1999) is not mentioned. The use of probabilities or weights is generally ignored in this book, even though it enables interesting methods for speeding up parsers such as coarse to fine parsing (Goodman 1997) or generalized A∗ search for parsing (Pauls and Klein 2009). While there is more than enough content in this book, it does not cover the use of parsing schemas in machine translation. In particular, formal properties of schemas might make it easier to describe and implement the integration of language models into parsing algorithms for synchronous context-free grammars (Chiang 2007). Schemas might have much to offer with respect to proving correctness in machine translation decoders. The potential reader for this book is likely to be a parsing enthusiast curious about the power of schemas to represent parsing algorithms succinctly and to prove them co</context>
</contexts>
<marker>Pauls, Klein, 2009</marker>
<rawString>Pauls, Adam and Dan Klein. 2009. Hierarchical search for parsing.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>557--565</pages>
<location>Boulder, CO.</location>
<marker></marker>
<rawString>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 557–565, Boulder, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
<author>Yves Schabes</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Principles and implementation of deductive parsing.</title>
<date>1995</date>
<journal>Journal of Logic Programming,</journal>
<pages>24--1</pages>
<marker>Shieber, Schabes, Pereira, 1995</marker>
<rawString>Shieber, Stuart M., Yves Schabes, and Fernando C. N. Pereira. 1995. Principles and implementation of deductive parsing. Journal of Logic Programming, 24(1–2):3–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaas Sikkel</author>
</authors>
<title>Parsing Schemata: A Framework for Specification and Analysis of Parsing Algorithms.</title>
<date>1997</date>
<publisher>Springer,</publisher>
<location>Berlin.</location>
<contexts>
<context position="2116" citStr="Sikkel 1997" startWordPosition="311" endWordPosition="312">orrectness (soundness and completeness) of a parsing algorithm. Well-formed transformations of deductive systems would permit the addition of new capabilities such as weighted rules in the grammar. Deductive systems could also provide a means to compare different parsing algorithms. This book provides several examples of how such properties can be useful in parsing theory and parsing implementation, in particular for converting a parser into an error-correcting parser and explicitly showing the relationship between several dependency parsing algorithms. Sikkel’s definition of parsing schemas (Sikkel 1997) extends deductive systems by formally defining the semantics of items and related concepts used in deductive systems. In particular, items are sets of partial constituency trees that are licensed by © 2011 Association for Computational Linguistics Computational Linguistics Volume 37, Number 4 rules of the grammar. As a result, parsing schemas allow compilation of schemas to executable parsers and also permit formal reasoning about properties of the parser directly. Unlike many deductive systems used to define parsers, there is no one-toone relationship between a parsing schema and algorithm. </context>
</contexts>
<marker>Sikkel, 1997</marker>
<rawString>Sikkel, Klaas. 1997. Parsing Schemata: A Framework for Specification and Analysis of Parsing Algorithms. Springer, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Villemonte de la Clergerie</author>
<author>´Eric</author>
</authors>
<title>DyALog: a Tabular Logic Programming based environment for NLP.</title>
<date>2005</date>
<booktitle>Proceedings of the 2nd International Workshop on Constraint Solving and Language Processing,</booktitle>
<location>Barcelona,</location>
<marker>Clergerie, ´Eric, 2005</marker>
<rawString>Villemonte de la Clergerie, ´Eric. 2005. DyALog: a Tabular Logic Programming based environment for NLP. Proceedings of the 2nd International Workshop on Constraint Solving and Language Processing, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel H Younger</author>
</authors>
<title>Recognition and parsing of context-free languages</title>
<date>1967</date>
<booktitle>in time n3. Information and Control,</booktitle>
<pages>10--189</pages>
<contexts>
<context position="1293" citStr="Younger 1967" startWordPosition="183" endWordPosition="184">reflects the time and space complexity of the underlying algorithm. A deductive system can be viewed as a domain-specific declarative schema that specifies a parser at an abstract level, focusing on the semantics of the parser actions rather than implementation. The schema itself can be compiled into an executable parser allowing implementation optimizations to be shared across different parsing algorithms. Schemas thus provide quick prototyping of parsing algorithms. In the notation used by the compiler described in this book we would describe the familiar CYK parsing algorithm (Kasami 1965; Younger 1967) as the following declarative specification: @step Unary [a, i, i + 1] A → a [A,i,i + 1] @step Binary [B, i, j] [C,j,k] A → B C [A, i, k] @goal [S, 0, length] Deductive systems can provide a framework to prove correctness (soundness and completeness) of a parsing algorithm. Well-formed transformations of deductive systems would permit the addition of new capabilities such as weighted rules in the grammar. Deductive systems could also provide a means to compare different parsing algorithms. This book provides several examples of how such properties can be useful in parsing theory and parsing im</context>
</contexts>
<marker>Younger, 1967</marker>
<rawString>Younger, Daniel H. 1967. Recognition and parsing of context-free languages in time n3. Information and Control, 10:189–208.</rawString>
</citation>
<citation valid="false">
<title>Anoop Sarkar is an Associate Professor at Simon Fraser University, Burnaby, BC, Canada, where he co-directs the Natural Language Laboratory (natlang.cs.sfu.ca). His research is focused on statistical parsing and machine translation. His interests also include formal language theory and stochastic grammars, in particular tree automata and tree-adjoining grammars. His e-mail address is anoop@cs.sfu.ca.</title>
<marker></marker>
<rawString>Anoop Sarkar is an Associate Professor at Simon Fraser University, Burnaby, BC, Canada, where he co-directs the Natural Language Laboratory (natlang.cs.sfu.ca). His research is focused on statistical parsing and machine translation. His interests also include formal language theory and stochastic grammars, in particular tree automata and tree-adjoining grammars. His e-mail address is anoop@cs.sfu.ca.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>