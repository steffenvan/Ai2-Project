<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007954">
<title confidence="0.923711">
Book Review
The Cambridge Grammar of the English Language
</title>
<author confidence="0.998476">
Rodney Huddleston and Geoffrey K. Pullum
</author>
<affiliation confidence="0.99266">
(University of Queensland and University of California, Santa Cruz)
</affiliation>
<address confidence="0.64115">
Cambridge, England: Cambridge
University Press, 2002, xvii+1842 pp;
hardbound, ISBN 0-521-43146-8, $150.00
</address>
<figure confidence="0.6964555">
Reviewed by
Chris Brew
</figure>
<affiliation confidence="0.690431">
The Ohio State University
</affiliation>
<bodyText confidence="0.999574176470588">
The Cambridge Grammar of the English Language is a comprehensive descriptive grammar
of English designed to be accessible to the general reader. Part of the declared goal
is to produce a grammar that “incorporates insights from the theoretical literature
but presents them in a way that is accessible to readers without formal training in
linguistics.”
Although the grammar is styled as “descriptive” and eschews complex notation,
it is clearly the product of authors for whom formal and theoretical issues and ar-
guments are of significant interest and concern. The challenge to which the authors
have risen is to present complex materials in a largely nontechnical manner and to
do so without sacrificing precision and clarity. In this they have largely succeeded.
The dedicated general reader should be able to glean from the book not only a great
deal of detailed knowledge about the way in which English works, but also a sense
of how the grammar is organized and an implicit understanding of some of the ways
in which formal linguists have learned to make and sustain arguments. But although
the influence of formalist approaches is evident, there is also an obvious love for and
enjoyment of the language itself.
For computational linguists, the grammar may also evoke the strong impression
that its authors are implicitly operating with a covert but precise set of assumptions
about the formal mechanisms that underlie the grammar, and some may be drawn
to the project of making these assumptions explicit, perhaps by using the book as
the basis for a large-scale computational grammar, very likely one in the tradition of
Pullum’s earlier work (Gazdar et al. 1985). Such a project, although very worthwhile,
would probably be too long-term for most of us, so we now turn to other ways in
which the availability of the grammar may enhance the practice of computational
linguistics.
One obvious role is as a guide to English grammar for people who build gram-
matical artifacts. Such artifacts include not only large-scale computational grammars
(Grover, Carroll, and Briscoe 1993; Copestake and Flickinger 2000) but also treebanks
(Marcus, Santorini, and Marcinkiewicz 1994). It is idle to speculate on whether the
Penn Treebank or the Alvey Natural Language Tools would have been significantly
different if the Cambridge Grammar had been around to influence them, but it should
become a routine part of the training of future grammar writers and treebank anno-
tators that they absorb as much as is feasible of this grammar. This will not be too
onerous: Few annotation manuals are as enjoyable to read as this grammar.
</bodyText>
<subsectionHeader confidence="0.971155">
Book Review
</subsectionHeader>
<bodyText confidence="0.999982307692308">
Another role for the grammar is as an organized repository for language data.
Although corpora were used in the preparation of the grammar, there are also many
constructed examples. Indeed, for system builders, the copious collection of negative
examples is perhaps the most significant aspect of the publication. They encode sig-
nificant linguistic intuition that is not otherwise available in a single package.
One immediate concern for the system builder will be to design a suitable mecha-
nism for accessing, decoding, and deploying the information that is in principle avail-
able in the grammar. Indeed, it is not even clear to me how the typical human reader
will approach this. It is certainly possible to read whole sections or chapters in strict
sequence, and when one does this, one begins to appreciate the subtlety and inter-
connectedness of the analyses. It is also clear that it will be a wonderful resource for
teachers and learners of English. Many of the negative examples resemble the kind of
thing that non-native speakers produce (e.g., from page 220):
</bodyText>
<subsectionHeader confidence="0.429311">
Example 1
</subsectionHeader>
<bodyText confidence="0.9149275">
a. *It contains of egg and milk.
b. *He bought it to Pat.
It therefore seems likely that the discussion surrounding these examples will be of
benefit. But how will readers who want to obtain this benefit know where to look?
The grammar provides a lexical index, so one can look up contain, but this does not
lead to the relevant example (it does, however, lead to the useful comment that some
verbs such as contain, belong, matter, and own have a strong tendency to resist the
progressive form even in examples like the following (page 168):
</bodyText>
<subsectionHeader confidence="0.665827">
Example 2
</subsectionHeader>
<bodyText confidence="0.999595904761905">
At the moment she owns both blocks, but she’s selling one next week.
The impact of lexical and syntactic data on computational linguistics is much
greater when it is available in electronic form (and some computational linguists read
inverted indices for fun). In discussion on Linguist List, responding to a critical review
by Joybrato Mukherjee (LINGUIST 13.1853, July 4, 2002), Pullum and Huddleston
explain their position on the use of corpus material:
It is true that for examples we standardly mined the Brown corpus
for American English, the London-Oslo-Bergen corpus for British En-
glish, and the Australian Corpus of English for Australian English
(we had convenient interactive access to these through the courtesy
of Macquarie University), and these total three million words. But
these corpora were merely sources of illustrative examples, nearly al-
ways edited for expository reasons. (It is one of the errors of strictly
corpus-oriented grammars to use only raw attested data for purposes
of illustration. We think it is counterproductive to quote a sentence
with a subject NP containing a long and distracting relative clause
when all we are concerned to illustrate is the order of adjuncts in the
verb phrase.) (LINGUIST 13.1932, July 17, 2002)
This is an entirely reasonable position, especially if one envisages the main use of a
written book as to be read by human readers. The situation changes when one begins
(as computational linguists often do) to think of a book as a resource for exploitation
</bodyText>
<page confidence="0.991874">
145
</page>
<table confidence="0.465595">
Computational Linguistics Volume 29, Number 1
</table>
<tableCaption confidence="0.997339">
Table 1
</tableCaption>
<bodyText confidence="0.789448">
The chapter listing.
</bodyText>
<listItem confidence="0.99866380952381">
1. Preliminaries (GKP and RH)
2. Syntactic overview (RH)
3. The verb (RH)
4. The clause: complements (RH)
5. Nouns and noun phrases (John Payne and RH)
6. Adjectives and adverbs (GKP and RH)
7. Prepositions and preposition phrases (GKP and RH)
8. The clause: adjuncts (Anita Mittwoch, RH, and Peter Collins)
9. Negation (GKP and RH)
10. Clause type and illocutionary force (RH)
11. Content clauses and reported speech (RH)
12. Relative clauses and unbounded dependencies (RH, GKP, and Peter Peterson)
13. Comparative constructions (RH)
14. Non-finite and verbless clauses (RH)
15. Coordination and supplementation (RH, John Payne, and Peter Peterson)
16. Information packaging (Gregory Ward, Betty Birner, and RH)
17. Deixis and anaphora (Lesley Stirling and RH)
18. Inflectional morphology and related matters (Frank Palmer, RH, and GKP)
19. Lexical word-formation (Laurie Bauer and RH)
20. Punctuation (Geoffrey Nunberg, Ted Briscoe, and RH)
Note: RH = Rodney Huddleston; GKP = Geoffrey K. Pullum
</listItem>
<bodyText confidence="0.985128928571428">
by computer programs. The authors are under no obligation whatsoever to regard
their book in this light. But it remains the case that an exhaustive concordance of
examples would also be very useful for the language learner. This might take up
more space than is warranted in a printed book but would be highly appropriate
in an electronic version, where space is no longer at a premium. The publishers of
the grammar also are the creators of the Cambridge International Dictionary of English
(Procter 1995), which is backed by corpora and has spawned a variety of electronic
complements, so this is not new territory for them. Because the examples are edited,
it may not be easy to identify the source material unambiguously, but when possible
it would be especially useful if the concordance contained explicit back references to
corpus material. We know that in many cases the source material will be in one of the
three corpora named by Huddleston and Pullum. It would be an excellent summer
project to apply fuzzy-string-matching technology to generate automatically a first
draft of this concordance.
Since the book is a large team effort, it is worth drawing attention to the manage-
ment structure: Rodney Huddleston acted as the hub, having a hand in the writing
of every one of the 20 chapters; Geoffrey Pullum is also named on the front cover,
contributing to five chapters, and a team of 13 other linguists gave time and effort.
This works really well: readers get the benefit of multiple-author expertise without the
pain of gratuitous stylistic variations. As can be seen from Table 1, the term grammar
is interpreted broadly to include not only sentence syntax, but also lexis, pragmatics,
and punctuation. There are no in-text citations, another deliberate design decision to
make the grammar more inviting to the general reader, but pointers to further reading
are provided.
Everything about this book is a credit to the authors and the publishers. It is
authoritative, interesting, reasonably priced (for a book of this size), beautifully de-
signed, well proofread, and enjoyable to handle. Without training, few owners will
have the arm strength to read it on the beach or in the bath, but those who can would
</bodyText>
<page confidence="0.996715">
146
</page>
<subsectionHeader confidence="0.917538">
Book Review
</subsectionHeader>
<bodyText confidence="0.999981727272727">
probably enjoy the experience. It is both a modern complement to existing descriptive
grammars (Quirk et al. 1985; Biber et al. 1999) and an important resource for anyone
interested in working with or finding out about English.
In addition, the book is a very complete and convincing demonstration that the
ideas of modern theoretical linguistics can be deployed in the detailed description of
a particular language. Pedagogically, it might also work as a tool for sneaking the
ideas of formal linguistics into the minds of people initially more interested in the
language itself. That is a topic for a different review, but this book is as appropriate
for the formally trained linguist wishing to broaden the range of data that a theory
covers as for the software engineer wishing to augment NLP skills with a more serious
understanding of how the language works.
</bodyText>
<sectionHeader confidence="0.994344" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.999640948717949">
Biber, Douglas, Stig Johansson, Geoffrey
Leech, Susan Conrad, and Edward
Finegan. 1999. Longman Grammar of Spoken
and Written English. Pearson ESL, Harlow,
England.
Copestake, Ann and Dan Flickinger. 2000.
An open-source grammar development
environment and broad-coverage English
grammar using HPSG. In Proceedings of the
Second Conference on Language Resources and
Evaluation (LREC-2000), Athens, Greece.
Gazdar, Gerald, Ewan Klein, Geoffrey
Pullum, and Ivan Sag. 1985. Generalized
Phrase Structure Grammar. Harvard
University Press, Cambridge, MA.
Grover, Claire, John Carroll, and Ted Briscoe.
1993. The Alvey natural language tools
grammar. Technical report, Human
Communication Research Centre,
University of Edinburgh and Computer
Laboratory, Cambridge University.
Marcus, Mitchell P., Beatrice Santorini, and
Mary Ann Marcinkiewicz. 1994. Building
a large annotated corpus of English: The
Penn Treebank. Computational Linguistics,
19(2):313–330.
Procter, Paul, editor. 1995. Cambridge
International Dictionary of English.
Cambridge University Press, Cambridge,
England.
Quirk, Randolph, Sidney Greenbaum,
Geoffrey Leech, and Jan Svartvik. 1985. A
Comprehensive Grammar of the English
Language. Longman, London.
Chris Brew is an assistant professor of computational linguistics and language technology at the
Ohio State University. His recent research has concerned the use of corpus-based methods in
speech synthesis and in lexical semantics. Brew’s address is: Department of Linguistics, The
Ohio State University, Oxley Hall, 1712 Neil Avenue, Columbus, OH 43210; e-mail: cbrew@ling.
ohio-state.edu.
</reference>
<page confidence="0.998094">
147
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.997488">Book Review The Cambridge Grammar of the English Language</title>
<author confidence="0.999982">Rodney Huddleston</author>
<author confidence="0.999982">Geoffrey K Pullum</author>
<affiliation confidence="0.999385">(University of Queensland and University of California, Santa Cruz)</affiliation>
<address confidence="0.991203">Cambridge, England: Cambridge</address>
<note confidence="0.916918">University Press, 2002, xvii+1842 pp; hardbound, ISBN 0-521-43146-8, $150.00 Reviewed by</note>
<author confidence="0.999487">Chris Brew</author>
<affiliation confidence="0.9961">The Ohio State University</affiliation>
<abstract confidence="0.991732240963855">Grammar of the English Language a comprehensive descriptive grammar of English designed to be accessible to the general reader. Part of the declared goal is to produce a grammar that “incorporates insights from the theoretical literature but presents them in a way that is accessible to readers without formal training in linguistics.” Although the grammar is styled as “descriptive” and eschews complex notation, it is clearly the product of authors for whom formal and theoretical issues and arguments are of significant interest and concern. The challenge to which the authors have risen is to present complex materials in a largely nontechnical manner and to do so without sacrificing precision and clarity. In this they have largely succeeded. The dedicated general reader should be able to glean from the book not only a great deal of detailed knowledge about the way in which English works, but also a sense of how the grammar is organized and an implicit understanding of some of the ways in which formal linguists have learned to make and sustain arguments. But although the influence of formalist approaches is evident, there is also an obvious love for and enjoyment of the language itself. For computational linguists, the grammar may also evoke the strong impression that its authors are implicitly operating with a covert but precise set of assumptions about the formal mechanisms that underlie the grammar, and some may be drawn to the project of making these assumptions explicit, perhaps by using the book as the basis for a large-scale computational grammar, very likely one in the tradition of Pullum’s earlier work (Gazdar et al. 1985). Such a project, although very worthwhile, would probably be too long-term for most of us, so we now turn to other ways in which the availability of the grammar may enhance the practice of computational linguistics. One obvious role is as a guide to English grammar for people who build grammatical artifacts. Such artifacts include not only large-scale computational grammars (Grover, Carroll, and Briscoe 1993; Copestake and Flickinger 2000) but also treebanks (Marcus, Santorini, and Marcinkiewicz 1994). It is idle to speculate on whether the Penn Treebank or the Alvey Natural Language Tools would have been significantly if the Grammar been around to influence them, but it should become a routine part of the training of future grammar writers and treebank annotators that they absorb as much as is feasible of this grammar. This will not be too onerous: Few annotation manuals are as enjoyable to read as this grammar. Book Review Another role for the grammar is as an organized repository for language data. Although corpora were used in the preparation of the grammar, there are also many constructed examples. Indeed, for system builders, the copious collection of negative examples is perhaps the most significant aspect of the publication. They encode significant linguistic intuition that is not otherwise available in a single package. One immediate concern for the system builder will be to design a suitable mechanism for accessing, decoding, and deploying the information that is in principle available in the grammar. Indeed, it is not even clear to me how the typical human reader will approach this. It is certainly possible to read whole sections or chapters in strict sequence, and when one does this, one begins to appreciate the subtlety and interconnectedness of the analyses. It is also clear that it will be a wonderful resource for teachers and learners of English. Many of the negative examples resemble the kind of thing that non-native speakers produce (e.g., from page 220): Example 1 a. *It contains of egg and milk. b. *He bought it to Pat. It therefore seems likely that the discussion surrounding these examples will be of benefit. But how will readers who want to obtain this benefit know where to look? grammar provides a lexical index, so one can look up but this does not lead to the relevant example (it does, however, lead to the useful comment that some such as belong, and a strong tendency to resist the progressive form even in examples like the following (page 168): Example 2 At the moment she owns both blocks, but she’s selling one next week. The impact of lexical and syntactic data on computational linguistics is much greater when it is available in electronic form (and some computational linguists read inverted indices for fun). In discussion on Linguist List, responding to a critical review by Joybrato Mukherjee (LINGUIST 13.1853, July 4, 2002), Pullum and Huddleston explain their position on the use of corpus material: It is true that for examples we standardly mined the Brown corpus for American English, the London-Oslo-Bergen corpus for British English, and the Australian Corpus of English for Australian English (we had convenient interactive access to these through the courtesy of Macquarie University), and these total three million words. But these corpora were merely sources of illustrative examples, nearly always edited for expository reasons. (It is one of the errors of strictly corpus-oriented grammars to use only raw attested data for purposes of illustration. We think it is counterproductive to quote a sentence with a subject NP containing a long and distracting relative clause when all we are concerned to illustrate is the order of adjuncts in the verb phrase.) (LINGUIST 13.1932, July 17, 2002) This is an entirely reasonable position, especially if one envisages the main use of a written book as to be read by human readers. The situation changes when one begins (as computational linguists often do) to think of a book as a resource for exploitation 145 Computational Linguistics Volume 29, Number 1 Table 1 The chapter listing.</abstract>
<title confidence="0.838864571428572">Preliminaries Syntactic overview The verb The clause: complements Nouns and noun phrases (John Payne and Adjectives and adverbs Prepositions and preposition phrases</title>
<note confidence="0.488415181818182">The clause: adjuncts (Anita Mittwoch, and Peter Collins) Negation Clause type and illocutionary force Content clauses and reported speech Relative clauses and unbounded dependencies and Peter Peterson) Comparative constructions Non-finite and verbless clauses Coordination and supplementation John Payne, and Peter Peterson) Information packaging (Gregory Ward, Betty Birner, and Deixis and anaphora (Lesley Stirling and Inflectional morphology and related matters (Frank Palmer, and</note>
<title confidence="0.7176625">Lexical word-formation (Laurie Bauer and Punctuation (Geoffrey Nunberg, Ted Briscoe, and</title>
<author confidence="0.951358">Rodney Huddleston</author>
<author confidence="0.951358">Geoffrey K Pullum</author>
<abstract confidence="0.997842048780488">by computer programs. The authors are under no obligation whatsoever to regard their book in this light. But it remains the case that an exhaustive concordance of examples would also be very useful for the language learner. This might take up more space than is warranted in a printed book but would be highly appropriate in an electronic version, where space is no longer at a premium. The publishers of grammar also are the creators of the International Dictionary of English (Procter 1995), which is backed by corpora and has spawned a variety of electronic complements, so this is not new territory for them. Because the examples are edited, it may not be easy to identify the source material unambiguously, but when possible it would be especially useful if the concordance contained explicit back references to corpus material. We know that in many cases the source material will be in one of the three corpora named by Huddleston and Pullum. It would be an excellent summer project to apply fuzzy-string-matching technology to generate automatically a first draft of this concordance. Since the book is a large team effort, it is worth drawing attention to the management structure: Rodney Huddleston acted as the hub, having a hand in the writing of every one of the 20 chapters; Geoffrey Pullum is also named on the front cover, contributing to five chapters, and a team of 13 other linguists gave time and effort. This works really well: readers get the benefit of multiple-author expertise without the of gratuitous stylistic variations. As can be seen from Table 1, the term is interpreted broadly to include not only sentence syntax, but also lexis, pragmatics, and punctuation. There are no in-text citations, another deliberate design decision to make the grammar more inviting to the general reader, but pointers to further reading are provided. Everything about this book is a credit to the authors and the publishers. It is authoritative, interesting, reasonably priced (for a book of this size), beautifully designed, well proofread, and enjoyable to handle. Without training, few owners will have the arm strength to read it on the beach or in the bath, but those who can would 146 Book Review probably enjoy the experience. It is both a modern complement to existing descriptive grammars (Quirk et al. 1985; Biber et al. 1999) and an important resource for anyone interested in working with or finding out about English. In addition, the book is a very complete and convincing demonstration that the ideas of modern theoretical linguistics can be deployed in the detailed description of a particular language. Pedagogically, it might also work as a tool for sneaking the ideas of formal linguistics into the minds of people initially more interested in the language itself. That is a topic for a different review, but this book is as appropriate for the formally trained linguist wishing to broaden the range of data that a theory covers as for the software engineer wishing to augment NLP skills with a more serious understanding of how the language works.</abstract>
<title confidence="0.52314">References</title>
<author confidence="0.573315">Douglas Biber</author>
<author confidence="0.573315">Stig Johansson</author>
<author confidence="0.573315">Geoffrey</author>
<affiliation confidence="0.590758333333333">Leech, Susan Conrad, and Edward 1999. Grammar of Spoken Written Pearson ESL, Harlow,</affiliation>
<address confidence="0.8343435">England. Copestake, Ann and Dan Flickinger. 2000.</address>
<abstract confidence="0.761836666666667">An open-source grammar development environment and broad-coverage English using HPSG. In of the</abstract>
<affiliation confidence="0.729185">Second Conference on Language Resources and</affiliation>
<address confidence="0.6649345">Athens, Greece. Gazdar, Gerald, Ewan Klein, Geoffrey</address>
<note confidence="0.8164124">and Ivan Sag. 1985. Structure Harvard University Press, Cambridge, MA. Grover, Claire, John Carroll, and Ted Briscoe. 1993. The Alvey natural language tools</note>
<author confidence="0.555547">Technical report</author>
<author confidence="0.555547">Human</author>
<affiliation confidence="0.990442666666667">Communication Research Centre, University of Edinburgh and Computer Laboratory, Cambridge University.</affiliation>
<address confidence="0.661887">Marcus, Mitchell P., Beatrice Santorini, and</address>
<author confidence="0.938386">Building</author>
<note confidence="0.59574125">a large annotated corpus of English: The Treebank. 19(2):313–330. Paul, editor. 1995. Dictionary of Cambridge University Press, Cambridge, England. Quirk, Randolph, Sidney Greenbaum, Leech, and Jan Svartvik. 1985. Comprehensive Grammar of the English Longman, London. Brew an assistant professor of computational linguistics and language technology at the</note>
<affiliation confidence="0.747843">Ohio State University. His recent research has concerned the use of corpus-based methods in speech synthesis and in lexical semantics. Brew’s address is: Department of Linguistics, The</affiliation>
<address confidence="0.665265">Ohio State University, Oxley Hall, 1712 Neil Avenue, Columbus, OH 43210; e-mail: cbrew@ling.</address>
<email confidence="0.767629">ohio-state.edu.</email>
<intro confidence="0.566437">147</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Douglas Biber</author>
<author>Stig Johansson</author>
<author>Geoffrey Leech</author>
<author>Susan Conrad</author>
<author>Edward Finegan</author>
</authors>
<title>Longman Grammar of Spoken and Written English. Pearson ESL,</title>
<date>1999</date>
<location>Harlow, England.</location>
<contexts>
<context position="9559" citStr="Biber et al. 1999" startWordPosition="1552" endWordPosition="1555">er deliberate design decision to make the grammar more inviting to the general reader, but pointers to further reading are provided. Everything about this book is a credit to the authors and the publishers. It is authoritative, interesting, reasonably priced (for a book of this size), beautifully designed, well proofread, and enjoyable to handle. Without training, few owners will have the arm strength to read it on the beach or in the bath, but those who can would 146 Book Review probably enjoy the experience. It is both a modern complement to existing descriptive grammars (Quirk et al. 1985; Biber et al. 1999) and an important resource for anyone interested in working with or finding out about English. In addition, the book is a very complete and convincing demonstration that the ideas of modern theoretical linguistics can be deployed in the detailed description of a particular language. Pedagogically, it might also work as a tool for sneaking the ideas of formal linguistics into the minds of people initially more interested in the language itself. That is a topic for a different review, but this book is as appropriate for the formally trained linguist wishing to broaden the range of data that a th</context>
</contexts>
<marker>Biber, Johansson, Leech, Conrad, Finegan, 1999</marker>
<rawString>Biber, Douglas, Stig Johansson, Geoffrey Leech, Susan Conrad, and Edward Finegan. 1999. Longman Grammar of Spoken and Written English. Pearson ESL, Harlow, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>An open-source grammar development environment and broad-coverage English grammar using HPSG.</title>
<date>2000</date>
<booktitle>In Proceedings of the Second Conference on Language Resources and Evaluation (LREC-2000),</booktitle>
<location>Athens, Greece.</location>
<contexts>
<context position="2439" citStr="Copestake and Flickinger 2000" startWordPosition="383" endWordPosition="386">these assumptions explicit, perhaps by using the book as the basis for a large-scale computational grammar, very likely one in the tradition of Pullum’s earlier work (Gazdar et al. 1985). Such a project, although very worthwhile, would probably be too long-term for most of us, so we now turn to other ways in which the availability of the grammar may enhance the practice of computational linguistics. One obvious role is as a guide to English grammar for people who build grammatical artifacts. Such artifacts include not only large-scale computational grammars (Grover, Carroll, and Briscoe 1993; Copestake and Flickinger 2000) but also treebanks (Marcus, Santorini, and Marcinkiewicz 1994). It is idle to speculate on whether the Penn Treebank or the Alvey Natural Language Tools would have been significantly different if the Cambridge Grammar had been around to influence them, but it should become a routine part of the training of future grammar writers and treebank annotators that they absorb as much as is feasible of this grammar. This will not be too onerous: Few annotation manuals are as enjoyable to read as this grammar. Book Review Another role for the grammar is as an organized repository for language data. Al</context>
</contexts>
<marker>Copestake, Flickinger, 2000</marker>
<rawString>Copestake, Ann and Dan Flickinger. 2000. An open-source grammar development environment and broad-coverage English grammar using HPSG. In Proceedings of the Second Conference on Language Resources and Evaluation (LREC-2000), Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Gazdar</author>
<author>Ewan Klein</author>
<author>Geoffrey Pullum</author>
<author>Ivan Sag</author>
</authors>
<title>Generalized Phrase Structure Grammar.</title>
<date>1985</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1995" citStr="Gazdar et al. 1985" startWordPosition="313" endWordPosition="316">to make and sustain arguments. But although the influence of formalist approaches is evident, there is also an obvious love for and enjoyment of the language itself. For computational linguists, the grammar may also evoke the strong impression that its authors are implicitly operating with a covert but precise set of assumptions about the formal mechanisms that underlie the grammar, and some may be drawn to the project of making these assumptions explicit, perhaps by using the book as the basis for a large-scale computational grammar, very likely one in the tradition of Pullum’s earlier work (Gazdar et al. 1985). Such a project, although very worthwhile, would probably be too long-term for most of us, so we now turn to other ways in which the availability of the grammar may enhance the practice of computational linguistics. One obvious role is as a guide to English grammar for people who build grammatical artifacts. Such artifacts include not only large-scale computational grammars (Grover, Carroll, and Briscoe 1993; Copestake and Flickinger 2000) but also treebanks (Marcus, Santorini, and Marcinkiewicz 1994). It is idle to speculate on whether the Penn Treebank or the Alvey Natural Language Tools wo</context>
</contexts>
<marker>Gazdar, Klein, Pullum, Sag, 1985</marker>
<rawString>Gazdar, Gerald, Ewan Klein, Geoffrey Pullum, and Ivan Sag. 1985. Generalized Phrase Structure Grammar. Harvard University Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Grover</author>
<author>John Carroll</author>
<author>Ted Briscoe</author>
</authors>
<title>The Alvey natural language tools grammar.</title>
<date>1993</date>
<tech>Technical report,</tech>
<institution>Human Communication Research Centre, University of Edinburgh and Computer Laboratory, Cambridge University.</institution>
<marker>Grover, Carroll, Briscoe, 1993</marker>
<rawString>Grover, Claire, John Carroll, and Ted Briscoe. 1993. The Alvey natural language tools grammar. Technical report, Human Communication Research Centre, University of Edinburgh and Computer Laboratory, Cambridge University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date>1994</date>
<marker>Marcus, Santorini, Marcinkiewicz, 1994</marker>
<rawString>Marcus, Mitchell P., Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<title>Cambridge International Dictionary of English.</title>
<date>1995</date>
<editor>Procter, Paul, editor.</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, England.</location>
<marker>1995</marker>
<rawString>Procter, Paul, editor. 1995. Cambridge International Dictionary of English. Cambridge University Press, Cambridge, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Randolph Quirk</author>
<author>Sidney Greenbaum</author>
<author>Geoffrey Leech</author>
<author>Jan Svartvik</author>
</authors>
<title>A Comprehensive Grammar of the English Language.</title>
<date>1985</date>
<location>Longman, London.</location>
<contexts>
<context position="9539" citStr="Quirk et al. 1985" startWordPosition="1548" endWordPosition="1551">xt citations, another deliberate design decision to make the grammar more inviting to the general reader, but pointers to further reading are provided. Everything about this book is a credit to the authors and the publishers. It is authoritative, interesting, reasonably priced (for a book of this size), beautifully designed, well proofread, and enjoyable to handle. Without training, few owners will have the arm strength to read it on the beach or in the bath, but those who can would 146 Book Review probably enjoy the experience. It is both a modern complement to existing descriptive grammars (Quirk et al. 1985; Biber et al. 1999) and an important resource for anyone interested in working with or finding out about English. In addition, the book is a very complete and convincing demonstration that the ideas of modern theoretical linguistics can be deployed in the detailed description of a particular language. Pedagogically, it might also work as a tool for sneaking the ideas of formal linguistics into the minds of people initially more interested in the language itself. That is a topic for a different review, but this book is as appropriate for the formally trained linguist wishing to broaden the ran</context>
</contexts>
<marker>Quirk, Greenbaum, Leech, Svartvik, 1985</marker>
<rawString>Quirk, Randolph, Sidney Greenbaum, Geoffrey Leech, and Jan Svartvik. 1985. A Comprehensive Grammar of the English Language. Longman, London.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Chris Brew</author>
</authors>
<title>is an assistant professor of computational linguistics and language technology at the Ohio State University. His recent research has concerned the use of corpus-based methods in speech synthesis and in lexical semantics. Brew’s address is: Department of Linguistics, The Ohio State University, Oxley Hall, 1712 Neil Avenue, Columbus, OH 43210; e-mail: cbrew@ling.</title>
<tech>ohio-state.edu.</tech>
<marker>Brew, </marker>
<rawString>Chris Brew is an assistant professor of computational linguistics and language technology at the Ohio State University. His recent research has concerned the use of corpus-based methods in speech synthesis and in lexical semantics. Brew’s address is: Department of Linguistics, The Ohio State University, Oxley Hall, 1712 Neil Avenue, Columbus, OH 43210; e-mail: cbrew@ling. ohio-state.edu.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>