<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000778">
<title confidence="0.551742">
Briefly Noted
Vision, Instruction, and Action
</title>
<author confidence="0.228329">
David Chapman
</author>
<bodyText confidence="0.987285">
(Teleos Research)
Cambridge, MA: The MIT Press (Artificial
Intelligence Series), 1991, xiii + 295 pp.
Hardbound, ISBN 0-262-03181-7, $35.00
This book is about a comprehensive theory
of activity and a computer program (Sonja)
that uses the theory to play a video game
(Amazon) from the same perspective as a hu-
man player. Chapman&apos;s main point is an ar-
gument about the kinds of architectures and
internal representations that are plausible for
modeling human activity. Starting with the
essential connectionism of the human brain, he
argues against &amp;quot;mentalese&amp;quot; and in favor of
deictic representations such as THE-CAR-WHICH-
IS-ABOUT-TO-HIT-ME. He argues that repre-
sentations that are to be useful for the rou-
tines that make up most of human activity
must be grounded in perception and be cen-
tered on the representing agent&apos;s perspective
of the world. Most of the book is about how
one can implement Chapman&apos;s theory of ac-
tivity by reference to a biologically based
model of visual perception.
Chapman incorporates instruction by hav-
ing Sonja accept very simple, canned sugges-
tions from a human &amp;quot;kibbitzer.&amp;quot; Since Sonja
interprets them in terms of what it sees in the
world and what routines it thinks it should
perform next, it automatically uses them in
the right way, only, for instance, turning left
when it reaches the next left turning rather
than at the exact time of the instruction. How-
ever, Sonja relies on its kibbitzers having a
very similar model of the game to its own in
order to decode references correctly; for in-
stance, alanylthelthat amulet is always the one
that Sonja reckons is most relevant to the cur-
rent situation. This entails that kibbitzers can
only serve to reorient Sonja&apos;s attention rather
than suggesting novel things to try. Chapman
considers this a benefit because most human
activity is routine, but I think that most in-
struction is exactly about learning new ways
of looking at a domain. I imagine that even in
video games, kibbitzers are most useful for
novice players who want to learn the right
tricks. It is not at all clear that Chapman&apos;s
ideas could be straightforwardly adapted for
more complex instruction-giving. Beyond the
central message about representations, there
is little new work that researchers in instruc-
tion will wish to take away from the book.
As for the book&apos;s cover, it would be more
at home on the top shelf of a newsstand than
among scholarly works. Chapman may only
be bothered &amp;quot;on political grounds&amp;quot; by vio-
lence (p. 62) and not by sexism (but do we
really believe his claim that it would have
been very difficult to find a suitable nonvi-
olent domain?), but someone should tell the
publishers that dressing one&apos;s theory of ac-
tivity in a chain-mail bikini won&apos;t necessarily
help it sell.—Jean Carletta, University of Edin-
burgh
</bodyText>
<subsectionHeader confidence="0.8209445">
Foundational Issues in Natural
Language Processing
Peter Sells, Stuart M. Shieber, and Thomas
Wasow (editors)
</subsectionHeader>
<bodyText confidence="0.988738657142857">
(Stanford University, Harvard University, and
Stanford University)
Cambridge, MA: The MIT Press (System
Development Foundation Benchmark
Series), 1991, vii + 232 pp.
Hardbound, ISBN 0-262-19303-5, $32.50
This book makes available in convenient form
four papers that have already been widely
circulated among specialists. All four were
presented at Santa Cruz in January 1987 and
distributed, in draft, at the 1987 Linguistic
Institute.
William Rounds&apos;s paper, &amp;quot;Computational
complexity and natural language processing&amp;quot;
(pp. 9-29), introduces complexity theory to
linguists. It predates Barton, Berwick, and Ris-
tad 1987 and covers much of the same ground.
On Rounds&apos;s view, two of the most impor-
tant issues are learnability of the language
and conciseness of the grammatical descrip-
tion.
&amp;quot;The convergence of mildly context-sensi-
tive grammar formalisms&amp;quot; (pp. 31-81), by Ar-
avind K. Joshi, K. Vijay-Shanker, and David
Weir, compares several newer theories of
grammar, all of which use phrase structure
rules slightly augmented by other mechan-
isms (making them context-sensitive, but only
&amp;quot;mildly&amp;quot; so). The authors focus on Tree Ad-
joining Grammar (TAG) and compare it to
Generalized Phrase Structure Grammar
(GPSG), Head Grammar, and other formal-
isms.
Janet Dean Fodor&apos;s &amp;quot;Sentence processing
and the mental grammar&amp;quot; (pp. 83-113) in-
</bodyText>
<page confidence="0.997316">
388
</page>
<bodyText confidence="0.975947323529412">
Briefly Noted
troduces psycholinguistics from a computa-
tional viewpoint, with emphasis on method-
ology. As examples she discusses, at length,
the experimental evidence on two issues:
whether there is a syntactic level other than
surface structure (but distinct from seman-
tics), and whether trace binding is separate
from phrase-structure parsing (as implicitly
claimed by GB theory but not GPSG). She
points out the notorious &amp;quot;problem of null re-
sults&amp;quot;:
If the sentence-matching studies fail to re-
veal mental representations of S-structure,
that might be because there are none, or
it might be because the sentence-matching
task is not sensitive to them. (p. 91)
In a footnote Fodor apologizes for the de-
layed publication and cites important newer
literature.
Finally, Robert C. Berwick&apos;s &amp;quot;Principle-
based parsing&amp;quot; (pp. 115-226) advocates an
approach to parsing in which the grammar
rules are not represented directly, but inferred
from more abstract principles. In practice this
means GB theory, and its fortunate effect has
been to create versions of GB in which hand-
waving is impossible. Berwick&apos;s paper is lu-
cidly written, presupposes no knowledge of
GB, and summarizes much of the work of his
colleagues, including Kashket&apos;s free-word-
order parser for Warlpiri and Berwick and
Fong&apos;s principle-ordering heuristics.—
Michael A. Covington, University of Georgia.
</bodyText>
<sectionHeader confidence="0.663216" genericHeader="abstract">
Reference
</sectionHeader>
<bodyText confidence="0.598541666666667">
Barton, G. Edward; Berwick, Robert C.; and
Ristad, Eric Sven (1987). Computational Com-
plexity and Natural Language. The MIT Press.
</bodyText>
<note confidence="0.6778682">
Computatio Linguae: Aufsatze zur
algorithmischen und quantitativen
Analyse der Sprache [Papers on Algo-
rithmic and Quantitative Analysis of
Language]
</note>
<bodyText confidence="0.929128916666667">
Ursula Klenk (editor)
(Universitat Gottingen)
Stuttgart: Franz Steiner Verlag (Zeitschrift
fiir Dialektologie und Linguistik; Beihefte,
edited by Joachim Goschel, with Rudolph
Freudenberg and Dieter Stellmacher,
Number 73), 1992, v + 169 pp.
Paperbound, ISBN 3-515-06049-9, DM 58.00
The contents of the volume are the following:
Stuart Davis, &amp;quot;Investigating English phono-
tactic constraints using a computerized
lexicon&amp;quot;
</bodyText>
<subsubsectionHeader confidence="0.577865">
Ramon Faulk and Frances Goertzel Gustayson,
</subsubsectionHeader>
<bodyText confidence="0.986005">
&amp;quot;Toward a predictive theory of natural lan-
guage&amp;quot;
Dafydd Gibbon, &amp;quot;ILEX: A linguistic approach
to computational lexica&amp;quot;
Hans Goebl, &amp;quot;Dendrogramme fin Dienst der
Dialektometrie. Zwei hierarchisch-agglo-
merative Klassifikationen von Daten des
Sprachatlasses AIS&amp;quot; [Dendrograms for dia-
lectometry: Two hierarchical-agglomerative
classifications of data in the AIS language
atlas]
Axel Janf3en, &amp;quot;Segmentierung franzOsischer
Wortformen in Morphe ohne Verwendung
eines Lexikons&amp;quot; [Segmenting French word-
forms into morphs without using a lexi-
con]
Harri fdppinen, &amp;quot;Finite state computational
morphology&amp;quot;
Ursula Klenk, &amp;quot;Verfahren morphologischer Seg-
mentierung und die Wortstruktur des
Spanischen&amp;quot; [Morphological segmentation
and the word structure of Spanish]
Hagen Langer and Sven Naumann, &amp;quot;Syntak-
tische Hierarchie und lineare Abfolge&amp;quot;
[Syntactic hierarchy and linear sequence]
Wolf Thiimmel, &amp;quot;Uber strukturen- und kate-
gorienvielfalt in kombinatorischen katego-
rialsyntaxen&amp;quot; [On the variety of structures
and categories in combinatorial categorial
grammars]
</bodyText>
<page confidence="0.998597">
389
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000189">
<title confidence="0.9903285">Briefly Noted Vision, Instruction, and Action</title>
<author confidence="0.985591">David Chapman</author>
<note confidence="0.6681342">(Teleos Research) Cambridge, MA: The MIT Press (Artificial Intelligence Series), 1991, xiii + 295 pp. Hardbound, ISBN 0-262-03181-7, $35.00 This book is about a comprehensive theory</note>
<abstract confidence="0.99185065">of activity and a computer program (Sonja) that uses the theory to play a video game (Amazon) from the same perspective as a human player. Chapman&apos;s main point is an argument about the kinds of architectures and internal representations that are plausible for modeling human activity. Starting with the connectionism the human brain, he argues against &amp;quot;mentalese&amp;quot; and in favor of representations as argues that representations that are to be useful for the routines that make up most of human activity must be grounded in perception and be centered on the representing agent&apos;s perspective of the world. Most of the book is about how one can implement Chapman&apos;s theory of activity by reference to a biologically based model of visual perception. Chapman incorporates instruction by having Sonja accept very simple, canned suggestions from a human &amp;quot;kibbitzer.&amp;quot; Since Sonja interprets them in terms of what it sees in the world and what routines it thinks it should perform next, it automatically uses them in the right way, only, for instance, turning left when it reaches the next left turning rather than at the exact time of the instruction. However, Sonja relies on its kibbitzers having a very similar model of the game to its own in order to decode references correctly; for inamulet always the one that Sonja reckons is most relevant to the current situation. This entails that kibbitzers can only serve to reorient Sonja&apos;s attention rather than suggesting novel things to try. Chapman considers this a benefit because most human is routine, but that most instruction is exactly about learning new ways of looking at a domain. I imagine that even in video games, kibbitzers are most useful for novice players who want to learn the right tricks. It is not at all clear that Chapman&apos;s ideas could be straightforwardly adapted for more complex instruction-giving. Beyond the central message about representations, there is little new work that researchers in instruction will wish to take away from the book. As for the book&apos;s cover, it would be more at home on the top shelf of a newsstand than among scholarly works. Chapman may only be bothered &amp;quot;on political grounds&amp;quot; by violence (p. 62) and not by sexism (but do we really believe his claim that it would have been very difficult to find a suitable nonviolent domain?), but someone should tell the publishers that dressing one&apos;s theory of activity in a chain-mail bikini won&apos;t necessarily it University of Edinburgh</abstract>
<title confidence="0.768">Foundational Issues in Natural Language Processing</title>
<author confidence="0.707362">Peter Sells</author>
<author confidence="0.707362">Stuart M Shieber</author>
<author confidence="0.707362">Thomas</author>
<affiliation confidence="0.866073333333333">Wasow (editors) (Stanford University, Harvard University, and Stanford University)</affiliation>
<address confidence="0.967623">Cambridge, MA: The MIT Press (System</address>
<note confidence="0.7831461">Development Foundation Benchmark Series), 1991, vii + 232 pp. Hardbound, ISBN 0-262-19303-5, $32.50 This book makes available in convenient form four papers that have already been widely circulated among specialists. All four were presented at Santa Cruz in January 1987 and distributed, in draft, at the 1987 Linguistic Institute. William Rounds&apos;s paper, &amp;quot;Computational</note>
<abstract confidence="0.996394929824561">complexity and natural language processing&amp;quot; (pp. 9-29), introduces complexity theory to linguists. It predates Barton, Berwick, and Ristad 1987 and covers much of the same ground. On Rounds&apos;s view, two of the most important issues are learnability of the language and conciseness of the grammatical description. &amp;quot;The convergence of mildly context-sensitive grammar formalisms&amp;quot; (pp. 31-81), by Aravind K. Joshi, K. Vijay-Shanker, and David Weir, compares several newer theories of grammar, all of which use phrase structure rules slightly augmented by other mechanisms (making them context-sensitive, but only &amp;quot;mildly&amp;quot; so). The authors focus on Tree Adjoining Grammar (TAG) and compare it to Generalized Phrase Structure Grammar (GPSG), Head Grammar, and other formalisms. Janet Dean Fodor&apos;s &amp;quot;Sentence processing the mental grammar&amp;quot; (pp. 83-113) in- 388 Briefly Noted troduces psycholinguistics from a computational viewpoint, with emphasis on methodology. As examples she discusses, at length, the experimental evidence on two issues: whether there is a syntactic level other than surface structure (but distinct from semantics), and whether trace binding is separate from phrase-structure parsing (as implicitly claimed by GB theory but not GPSG). She points out the notorious &amp;quot;problem of null results&amp;quot;: If the sentence-matching studies fail to reveal mental representations of S-structure, that might be because there are none, or it might be because the sentence-matching task is not sensitive to them. (p. 91) In a footnote Fodor apologizes for the delayed publication and cites important newer literature. Finally, Robert C. Berwick&apos;s &amp;quot;Principlebased parsing&amp;quot; (pp. 115-226) advocates an approach to parsing in which the grammar rules are not represented directly, but inferred from more abstract principles. In practice this means GB theory, and its fortunate effect has been to create versions of GB in which handwaving is impossible. Berwick&apos;s paper is lucidly written, presupposes no knowledge of GB, and summarizes much of the work of his colleagues, including Kashket&apos;s free-wordorder parser for Warlpiri and Berwick and principle-ordering Michael A. Covington, University of Georgia.</abstract>
<title confidence="0.504869">Reference</title>
<author confidence="0.8765005">G Edward Barton</author>
<author confidence="0.8765005">Robert C Berwick</author>
<author confidence="0.8765005">Eric Sven</author>
<affiliation confidence="0.910958">and Natural Language. MIT Press.</affiliation>
<title confidence="0.670864">Computatio Linguae: Aufsatze zur algorithmischen und quantitativen Analyse der Sprache [Papers on Algorithmic and Quantitative Analysis of Language]</title>
<author confidence="0.977792">Ursula Klenk</author>
<affiliation confidence="0.532119">(Universitat Gottingen) Stuttgart: Franz Steiner Verlag (Zeitschrift fiir Dialektologie und Linguistik; Beihefte,</affiliation>
<note confidence="0.86641">edited by Joachim Goschel, with Rudolph Freudenberg and Dieter Stellmacher, Number 73), 1992, v + 169 pp. Paperbound, ISBN 3-515-06049-9, DM 58.00 The contents of the volume are the following: Davis, English phono-</note>
<abstract confidence="0.970539424242424">tactic constraints using a computerized lexicon&amp;quot; Ramon Faulk and Frances Goertzel Gustayson, &amp;quot;Toward a predictive theory of natural language&amp;quot; Gibbon, A linguistic approach to computational lexica&amp;quot; Goebl, fin Dienst der Dialektometrie. Zwei hierarchisch-agglomerative Klassifikationen von Daten des Sprachatlasses AIS&amp;quot; [Dendrograms for dialectometry: Two hierarchical-agglomerative classifications of data in the AIS language atlas] Janf3en, franzOsischer Wortformen in Morphe ohne Verwendung eines Lexikons&amp;quot; [Segmenting French wordforms into morphs without using a lexicon] fdppinen, state computational morphology&amp;quot; Klenk, morphologischer Segmentierung und die Wortstruktur des Spanischen&amp;quot; [Morphological segmentation and the word structure of Spanish] Langer and Sven Naumann, &amp;quot;Syntaktische Hierarchie und lineare Abfolge&amp;quot; [Syntactic hierarchy and linear sequence] Thiimmel, strukturenund kategorienvielfalt in kombinatorischen kategorialsyntaxen&amp;quot; [On the variety of structures and categories in combinatorial categorial grammars]</abstract>
<intro confidence="0.654677">389</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>