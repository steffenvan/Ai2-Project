<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.033348">
<title confidence="0.893159">
Distinguishing Common and Proper Nouns
</title>
<author confidence="0.809994">
Judita Preiss and Mark Stevenson
</author>
<affiliation confidence="0.828337">
{j.preiss, r.m.stevenson}@sheffield.ac.uk
Department of Computer Science,
University of Sheffield
</affiliation>
<address confidence="0.848985">
211 Portobello, Sheffield S1 4DP
United Kingdom
</address>
<sectionHeader confidence="0.970054" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999795">
We describe a number of techniques for auto-
matically deriving lists of common and proper
nouns, and show that the distinction between
the two can be made automatically using a
vector space model learning algorithm. We
present a direct evaluation on the British Na-
tional Corpus, and application based evalua-
tions on Twitter messages and on automatic
speech recognition (where the system could be
employed to restore case).
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999581714285714">
Some nouns are homographs (they have the same
written form, but different meaning) which can be
used to denote either a common or proper noun, for
example the word apple in the following examples:
(1) Apple designs and creates iPod (2) The Apple II
series is a set of 8-bit home computers (3) The apple
is the pomaceous fruit of the apple tree (4) For apple
enthusiasts – tasting notes and apple identification.
The common and proper uses are not always as
clearly distinct as in this example; for example, a
specific instance of a common noun, e.g., District
Court turns court into a proper noun.
While heuristically, proper nouns often start with
a capital letter in English, capitalization can be in-
consistent, incorrect or omitted, and the presence or
absence of an article cannot be relied on.
The problem of distinguishing between common
and proper usages of nouns has not received much
attention within language processing, despite being
an important component for many tasks including
machine translation (Lopez, 2008; Hermjakob et al.,
</bodyText>
<page confidence="0.954549">
80
</page>
<bodyText confidence="0.999482285714286">
2008), sentiment analysis (Pang and Lee, 2008; Wil-
son et al., 2009) and topic tracking (Petrovi´c et al.,
2010). Approaches to the problem also have appli-
cations to tasks such as web search (Chen et al.,
1998; Baeza-Yates and Ribeiro-Neto, 2011), and
case restoration (e.g., in automatic speech recogni-
tion output) (Baldwin et al., 2009), but frequently
involve the manual creation of a gazeteer (a list of
proper nouns), which suffer not only from omissions
but also often do not allow the listed words to as-
sume their common role in text.
This paper presents methods for generating lists
of nouns that have both common and proper usages
(Section 2) and methods for identifying the type of
usage (Section 3) which are evaluated using data de-
rived automatically from the BNC (Section 4) and
on two applications (Section 5). It shows that it is
difficult to automatically construct lists of ambigu-
ous nouns but also that they can be distinguished ef-
fectively using standard features from Word Sense
Disambiguation.
</bodyText>
<sectionHeader confidence="0.955327" genericHeader="method">
2 Generating Lists of Nouns
</sectionHeader>
<bodyText confidence="0.999562545454545">
To our knowledge, no comprehensive list of com-
mon nouns with proper noun usage is available. We
develop a number of heuristics to generate such lists
automatically.
Part of speech tags A number of part of speech
(PoS) taggers assign different tags to common and
proper nouns. Ambiguous nouns are identified by
tagging a corpus and extracting those that have
had both tags assigned, together with the frequency
of occurrence of the common/proper usage. The
CLAWS (Garside, 1987) and the RASP taggers
</bodyText>
<subsubsectionHeader confidence="0.347991">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference
</subsubsectionHeader>
<bodyText confidence="0.989529326530612">
and the Shared Task, pages 80–84, Atlanta, Georgia, June 13-14, 2013. c�2013 Association for Computational Linguistics
(Briscoe et al., 2006) were applied to the British Na-
tional Corpus (BNC) (Leech, 1992) to generate the
lists BNCclaws and BNCrasp respectively. In addi-
tion the RASP tagger was also run over the 1.75 bil-
lion word Gigaword corpus (Graff, 2003) to extract
the list Gigaword.
Capitalization Nouns appearing intra-
sententially with both lower and upper case
first letters are assumed to be ambiguous. This
technique is applied to the 5-grams from the Google
corpus (Brants and Franz, 2006) and the BNC
(creating the lists 5-grams and BNCcaps).
Wikipedia includes disambiguation pages for
ambiguous words which provide information about
their potential usage. Wikipedia pages for nouns
with senses (according to the disambiguation page)
in a set of predefined categories were identified to
form the list Wikipedia.
Named entity recognition The Stanford Named
Entity Recogniser (Finkel et al., 2005) was run over
the BNC and any nouns that occur in the corpus with
both named entity and non-named entity tags are ex-
tracted to form the list Stanford.
WordNet The final heuristic makes use of Word-
Net (Fellbaum, 1998) which lists nouns that are of-
ten used as proper nouns with capitalisation. Nouns
which appeared in both a capitalized and lowercased
form were extracted to create the list WordNet.
Table 1 shows the number of nouns identified by
each technique in the column labeled words which
demonstrates that the number of nouns identified
varies significantly depending upon which heuris-
tic is used. A pairwise score is also shown to in-
dicate the consistency between each list and two ex-
ample lists, BNCclaws and Gigaword. It can be seen
that the level of overlap is quite low and the various
heuristics generate quite different lists of nouns. In
particular the recall is low, in almost all cases less
than a third of nouns in one list appear in the other.
One possible reason for the low overlap between
the noun lists is mistakes by the heuristics used to
extract them. For example, if a PoS tagger mistak-
enly tags just one instance of a common noun as
proper then that noun will be added to the list ex-
tracted by the part of speech heuristic. Two filter-
ing schemes were applied to improve the accuracy of
the lists: (1) minimum frequency of occurrence, the
noun must appear more than a set number of times
</bodyText>
<table confidence="0.9992898">
words BNCclaws Gigaword
P R P R
BNCclaws 41,110 100 100 31 2
BNCrasp 20,901 52 27 45 17
BNCcaps 18,524 56 26 66 21
5-grams 27,170 45 29 59 28
Gigaword 57,196 22 31 100 100
Wikipedia 7,351 49 9 59 8
WordNet 798 75 1 68 1
Stanford 64,875 43 67 26 29
</table>
<tableCaption confidence="0.998440333333333">
Table 1: Pairwise comparison of lists. The nouns in each
list are compared against the BNCclaws and Gigaword
lists. Results are computed for P(recision) and R(ecall).
</tableCaption>
<bodyText confidence="0.999724375">
in the corpus and (2) bias, the least common type of
noun usage (i.e., common or proper) must account
for more than a set percentage of all usages.
We experimented with various values for these fil-
ters and a selection of results is shown in Table 2,
where freq is the minimum frequency of occurrence
filter and bias indicates the percentage of the less
frequent noun type.
</bodyText>
<table confidence="0.994842666666667">
bias freq words BNCclaws Gigaword
P R P R
BNCclaws 40 100 274 100 1 53 1
BNCrasp 30 100 253 94 1 85 0
5-grams 40 150 305 80 1 67 0
Stanford 40 200 260 87 1 47 0
</table>
<tableCaption confidence="0.999478">
Table 2: Pairwise comparison of lists with filtering
</tableCaption>
<bodyText confidence="0.9996438125">
Precision (against BNCclaws) increased as the fil-
ters become more aggressive. However comparison
with Gigaword does not show such high precision
and recall is extremely low in all cases.
These experiments demonstrate that it is difficult
to automatically generate a list of nouns that exhibit
both common and proper usages. Manual analy-
sis of the lists generated suggest that the heuristics
can identify ambiguous nouns but intersecting the
lists results in the loss of some obviously ambigu-
ous nouns (however, their union introduces a large
amount of noise). We select nouns from the lists
created by these heuristics (such that the distribu-
tion of either the common or proper noun sense in
the data was not less than 45%) for experiments in
the following sections.1
</bodyText>
<footnote confidence="0.9998065">
1The 100 words selected for our evaluation are available at
http://pastehtml.com/view/cjsbs4xvl.txt
</footnote>
<page confidence="0.998499">
81
</page>
<sectionHeader confidence="0.995299" genericHeader="method">
3 Identifying Noun Types
</sectionHeader>
<bodyText confidence="0.999977333333333">
We cast the problem of distinguishing between com-
mon and proper usages of nouns as a classification
task and develop the following approaches.
</bodyText>
<subsectionHeader confidence="0.996892">
3.1 Most frequent usage
</subsectionHeader>
<bodyText confidence="0.999942">
A naive baseline is supplied by assigning each word
its most frequent usage form (common or proper
noun). The most frequent usage is derived from the
training portion of labeled data.
</bodyText>
<subsectionHeader confidence="0.997407">
3.2 n-gram system
</subsectionHeader>
<bodyText confidence="0.999977333333333">
A system based on n-grams was implemented using
NLTK (Bird et al., 2009). Five-grams, four-grams,
trigrams and bigrams from the training corpus are
matched against a test corpus sentence, and results
of each match are summed to yield a preferred use in
the given context with a higher weight (experimen-
tally determined) being assigned to longer n-grams.
The system backs off to the most frequent usage (as
derived from the training data).
</bodyText>
<subsectionHeader confidence="0.971399">
3.3 Vector Space Model (VSM)
</subsectionHeader>
<bodyText confidence="0.999314857142857">
Distinguishing between common and proper nouns
can be viewed as a classification problem. Treating
the problem in this manner is reminiscent of tech-
niques commonly employed in Word Sense Disam-
biguation (WSD). Our supervised approach is based
on an existing WSD system (Agirre and Martinez,
2004) that uses a wide range of features:
</bodyText>
<listItem confidence="0.997463083333333">
• Word form, lemma or PoS bigrams and tri-
grams containing the target word.
• Preceding or following lemma (or word form)
content word appearing in the same sentence as
the target word.
• High-likelihood, salient, bigrams.
• Lemmas of all content words in the same sen-
tence as the target word.
• Lemmas of all content words within a f4 word
window of the target word.
• Non stopword lemmas which appear more than
twice throughout the corpus.
</listItem>
<bodyText confidence="0.999828">
Each occurrence of a common / proper noun is
represented as a binary vector in which each position
indicates the presence or absence of a feature. A
centroid vector is created during the training phase
for the common noun and the proper noun instances
of a word. During the test phase, the centroids are
compared to the vector of each test instance using
the cosine metric, and the word is assigned the type
of the closest centroid.
</bodyText>
<sectionHeader confidence="0.999099" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999981612903226">
The approaches described in the previous section are
evaluated on two data sets extracted automatically
from the BNC. The BNC-PoS data set is created
using the output from the CLAWS tagger. Nouns
assigned the tag NP0 are treated as proper nouns
and those assigned any other nominal tag as com-
mon nouns. (According to the BNC manual the
NP0 tag has a precision 83.99% and recall 97.76%.2)
This data set consists of all sentences in the BNC in
which the target word appears. The second data set,
BNC-Capital, is created using capitalisation infor-
mation and consists of instances of the target noun
that do not appear sentence-initially. Any instances
that are capitalised are treated as proper nouns and
those which are non-capitalised as common nouns.
Experiments were carried out using capitalised
and decapitalized versions of the two test corpora.
The decapitalised versions by lowercasing each cor-
pus and using it for training and testing. Results are
presented in Table 3. Ten fold cross validation is
used for all experiments: i.e. 9/10th of the corpus
were used to acquire the training data centroids and
1/10th was used for evaluation. The average perfor-
mance over the 10 experiments is reported.
The vector space model (VSM) outperforms other
approaches on both corpora. Performance is partic-
ularly high when capitalisation is included (VSM w
caps). However, this approach still outperforms the
baseline without case information (VSM w/o caps),
demonstrating that using this simple approach is less
effective than making use of local context.
</bodyText>
<footnote confidence="0.986169333333333">
2No manual annotation of common and proper nouns in this
corpus exists and thus an exact accuracy figure for this corpus
cannot be obtained.
</footnote>
<page confidence="0.993743">
82
</page>
<table confidence="0.999153142857143">
Gold standard
BNC-PoS BNC-Capital
Most frequent 79% 67%
n-gram w caps 80% 77%
n-gram w/o caps 68% 56%
VSM w caps 90% 100%
VSM w/o caps 86% 80%
</table>
<tableCaption confidence="0.998638">
Table 3: BNC evaluation results
</tableCaption>
<sectionHeader confidence="0.992388" genericHeader="method">
5 Applications
</sectionHeader>
<bodyText confidence="0.994178">
We also carried out experiments on two types of
text in which capitalization information may not be
available: social media and ASR output.
</bodyText>
<subsectionHeader confidence="0.827243">
5.1 Twitter
</subsectionHeader>
<bodyText confidence="0.9997045625">
As demonstrated in the BNC based evaluations, the
system can be applied to text which does not contain
capitalization information to identify proper nouns
(and, as a side effect, enable the correction of capi-
talization). An example of such a dataset are the (up
to) 140 character messages posted on Twitter.
There are some interesting observations to be
made on messages downloaded from Twitter. Al-
though some users choose to always tweet in lower
case, the overall distribution of capitalization in
tweets is high for the 100 words selected in Section 2
and only 3.7% of the downloaded tweets are entirely
lower case. It also appeared that users who capital-
ize, do so fairly consistently.
This allows the creation of a dataset based on
downloaded Twitter data3:
</bodyText>
<listItem confidence="0.884821714285714">
1. Identify purely lower case tweets containing
the target word. These will form the test data
(and are manually assigned usage).
2. Any non-sentence initial occurrences of the tar-
get word are used as training instances: lower
case indicating a common instance, upper case
indicating a proper instance.
</listItem>
<bodyText confidence="0.944038666666667">
14 words4 were randomly selected from the list
used in Section 4 and their lowercase tweet instances
were manually annotated by a single annotator. The
</bodyText>
<footnote confidence="0.961786666666667">
3http://search.twitter.com/api
4abbot, bull, cathedral, dawn, herald, justice, knight, lily,
lodge, manor, park, president, raven and windows
</footnote>
<table confidence="0.999423333333333">
Training corpus MF n-grams VSM
Twitter 59% 40% 60%
BNCclaw decap 59% 44% 79%
</table>
<tableCaption confidence="0.999875">
Table 4: Results on the Twitter data
</tableCaption>
<bodyText confidence="0.9975309375">
average proportion of proper nouns in the test data
was 59%.
The results for the three systems are presented in
Table 4. As the length of the average sentence in the
Twitter data is only 15 words (compared to 27 words
in the BNCclaws data for the same target words),
the Twitter data is likely to be suffering sparseness
issues. This hypothesis is partly supported by the in-
crease in performance when the BNCclaws decapi-
talized data is added to the training data, however,
the performance of the n-gram system remains be-
low the most frequent use. On closer examination,
this is likely due to the skew in the data – there are
many more examples for the common use of each
noun, and thus each context is much more likely to
have been seen in this setting.
</bodyText>
<subsectionHeader confidence="0.999708">
5.2 Automatic speech recognition
</subsectionHeader>
<bodyText confidence="0.999972130434783">
Most automatic speech recognition (ASR) systems
do not provide capitalization. However, our sys-
tem does not rely on capitalization information, and
therefore can identify proper / common nouns even
if capitalization is absent. Also, once proper nouns
are identified, the system can be used to restore case
– a feature which allows an evaluation to take place
on this dataset. We use the TDT2 Test and Speech
corpus (Cieri et al., 1999), which contains ASR and
a manually transcribed version of news texts from
six different sources, to demonstrate the usefulness
of this system for this task.
The ASR corpus is restricted to those segments
which contain an equal number of target word oc-
currences in the ASR text and the manually tran-
scribed version, and all such segments are extracted.
The gold standard, and the most frequent usage, are
drawn from the manually transcribed data.
Again, results are based on an average perfor-
mance obtained using a ten fold cross validation.
Three versions of training data are used: the 9/10 of
ASR data (with labels provided by the manual tran-
scription), the equivalent 9/10 of lowercased manu-
</bodyText>
<page confidence="0.995675">
83
</page>
<table confidence="0.998946666666667">
Training corpus MF n-grams VSM
Manual 66% 42% 73%
ASR 63% 41% 79%
</table>
<tableCaption confidence="0.999827">
Table 5: Results on the ASR data
</tableCaption>
<bodyText confidence="0.999927125">
ally transcribed data, and a combination of the two.
The results can be seen in Table 5. The perfor-
mance rise obtained with the VSM model when the
ASR data is used is likely due to the repeated errors
within this, which will not be appearing in the man-
ually transcribed texts. The n-gram performance is
greatly affected by the low volume of training data
available, and again, a large skew within this.
</bodyText>
<sectionHeader confidence="0.999561" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999956727272727">
We automatically generate lists of common and
proper nouns using a number of different techniques.
A vector space model technique for distinguish-
ing common and proper nouns is found to achieve
high performance when evaluated on the BNC. This
greatly outperforms a simple n-gram based system,
due to its better adaptability to sparse training data.
Two application based evaluations also demonstrate
the system’s performance and as a side effect the
system could serve as a technique for automatic case
restoration.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997952">
The authors are grateful to the funding for this
research received from Google (Google Research
Award) and the UK Engineering and Physical Sci-
ences Research Council (EP/J008427/1).
</bodyText>
<sectionHeader confidence="0.997083" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998141984848485">
Agirre, E. and Martinez, D. (2004). The Basque Coun-
try University system: English and Basque tasks.
In Senseval-3: Third International Workshop on the
Evaluation of Systems for the Semantic Analysis of
Text, pages 44–48.
Baeza-Yates, R. and Ribeiro-Neto, B. (2011). Modern
Information Retrieval: The Concepts and Technology
Behind Search. Addison Wesley Longman Limited,
Essex.
Baldwin, T., Paul, M., and Joseph, A. (2009). Restoring
punctuation and casing in English text. In Proceedings
of the 22nd Australian Joint Conference on Artificial
Intelligence (AI09), pages 547–556.
Bird, S., Klein, E., and Loper, E. (2009). Natural Lan-
guage Processing with Python – Analyzing Text with
the Natural Language Toolkit. O’Reilly.
Brants, T. and Franz, A. (2006). Web 1T 5-gram v1.
Briscoe, T., Carroll, J., and Watson, R. (2006). The sec-
ond release of the RASP system. In Proceedings of the
COLING/ACL 2006 Interactive Presentation Sessions.
Chen, H., Huang, S., Ding, Y., and Tsai, S. (1998).
Proper name translation in cross-language information
retrieval. In Proceedings of the 36th Annual Meeting
of the Association for Computational Linguistics and
17th International Conference on Computational Lin-
guistics, Volume 1, pages 232–236, Montreal, Canada.
Cieri, C., Graff, D., Liberman, M., Martey, N., and
Strassel, S. (1999). The TDT-2 text and speech cor-
pus. In Proceedings of DARPA Broadcast News Work-
shop, pages 57–60.
Fellbaum, C., editor (1998). WordNet: An Electronic
Lexical Database and some of its Applications. MIT
Press, Cambridge, MA.
Finkel, J. R., Grenager, T., and Manning, C. (2005). In-
corporating non-local information into information ex-
traction systems by Gibbs sampling. In Proceedings of
the 43nd Annual Meeting of the Association for Com-
putational Linguistics, pages 363–370.
Garside, R. (1987). The CLAWS word-tagging system.
In Garside, R., Leech, G., and Sampson, G., editors,
The Computational Analysis of English: A Corpus-
based Approach. London: Longman.
Graff, D. (2003). English Gigaword. Technical report,
Linguistic Data Consortium.
Hermjakob, U., Knight, K., and Daum´e III, H. (2008).
Name translation in statistical machine translation -
learning when to transliterate. In Proceedings ofACL-
08: HLT, pages 389–397, Columbus, Ohio.
Leech, G. (1992). 100 million words of English:
the British National Corpus. Language Research,
28(1):1–13.
Lopez, A. (2008). Statistical machine translation. ACM
Computing Surveys, 40(3):1–49.
Pang, B. and Lee, L. (2008). Opinion mining and senti-
ment analysis. Foundations and Trends in Information
Retrieval, Vol. 2(1-2):pp. 1–135.
Petrovi´c, S., Osborne, M., and Lavrenko, V. (2010).
Streaming first story detection with application to twit-
ter. In Human Language Technologies: The 2010 An-
nual Conference of the North American Chapter of
the Association for Computational Linguistics, pages
181–189, Los Angeles, California.
Wilson, T., Wiebe, J., and Hoffman, P. (2009). Recogniz-
ing contextual polarity: an exploration of features for
phrase-level sentiment analysis. Computational Lin-
guistics, 35(5).
</reference>
<page confidence="0.999243">
84
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.362127">
<title confidence="0.999121">Distinguishing Common and Proper Nouns</title>
<author confidence="0.865878">Preiss</author>
<affiliation confidence="0.9989495">Department of Computer University of</affiliation>
<address confidence="0.6616675">211 Portobello, Sheffield S1 United Kingdom</address>
<abstract confidence="0.991846">We describe a number of techniques for automatically deriving lists of common and proper nouns, and show that the distinction between the two can be made automatically using a vector space model learning algorithm. We present a direct evaluation on the British National Corpus, and application based evaluations on Twitter messages and on automatic speech recognition (where the system could be employed to restore case).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>D Martinez</author>
</authors>
<title>The Basque Country University system: English and Basque tasks. In</title>
<date>2004</date>
<booktitle>Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text,</booktitle>
<pages>44--48</pages>
<contexts>
<context position="8824" citStr="Agirre and Martinez, 2004" startWordPosition="1470" endWordPosition="1473">corpus are matched against a test corpus sentence, and results of each match are summed to yield a preferred use in the given context with a higher weight (experimentally determined) being assigned to longer n-grams. The system backs off to the most frequent usage (as derived from the training data). 3.3 Vector Space Model (VSM) Distinguishing between common and proper nouns can be viewed as a classification problem. Treating the problem in this manner is reminiscent of techniques commonly employed in Word Sense Disambiguation (WSD). Our supervised approach is based on an existing WSD system (Agirre and Martinez, 2004) that uses a wide range of features: • Word form, lemma or PoS bigrams and trigrams containing the target word. • Preceding or following lemma (or word form) content word appearing in the same sentence as the target word. • High-likelihood, salient, bigrams. • Lemmas of all content words in the same sentence as the target word. • Lemmas of all content words within a f4 word window of the target word. • Non stopword lemmas which appear more than twice throughout the corpus. Each occurrence of a common / proper noun is represented as a binary vector in which each position indicates the presence </context>
</contexts>
<marker>Agirre, Martinez, 2004</marker>
<rawString>Agirre, E. and Martinez, D. (2004). The Basque Country University system: English and Basque tasks. In Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, pages 44–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Baeza-Yates</author>
<author>B Ribeiro-Neto</author>
</authors>
<title>Modern Information Retrieval: The Concepts and Technology Behind Search.</title>
<date>2011</date>
<publisher>Addison Wesley Longman Limited,</publisher>
<location>Essex.</location>
<contexts>
<context position="1957" citStr="Baeza-Yates and Ribeiro-Neto, 2011" startWordPosition="308" endWordPosition="311"> letter in English, capitalization can be inconsistent, incorrect or omitted, and the presence or absence of an article cannot be relied on. The problem of distinguishing between common and proper usages of nouns has not received much attention within language processing, despite being an important component for many tasks including machine translation (Lopez, 2008; Hermjakob et al., 80 2008), sentiment analysis (Pang and Lee, 2008; Wilson et al., 2009) and topic tracking (Petrovi´c et al., 2010). Approaches to the problem also have applications to tasks such as web search (Chen et al., 1998; Baeza-Yates and Ribeiro-Neto, 2011), and case restoration (e.g., in automatic speech recognition output) (Baldwin et al., 2009), but frequently involve the manual creation of a gazeteer (a list of proper nouns), which suffer not only from omissions but also often do not allow the listed words to assume their common role in text. This paper presents methods for generating lists of nouns that have both common and proper usages (Section 2) and methods for identifying the type of usage (Section 3) which are evaluated using data derived automatically from the BNC (Section 4) and on two applications (Section 5). It shows that it is d</context>
</contexts>
<marker>Baeza-Yates, Ribeiro-Neto, 2011</marker>
<rawString>Baeza-Yates, R. and Ribeiro-Neto, B. (2011). Modern Information Retrieval: The Concepts and Technology Behind Search. Addison Wesley Longman Limited, Essex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Baldwin</author>
<author>M Paul</author>
<author>A Joseph</author>
</authors>
<title>Restoring punctuation and casing in English text.</title>
<date>2009</date>
<booktitle>In Proceedings of the 22nd Australian Joint Conference on Artificial Intelligence (AI09),</booktitle>
<pages>547--556</pages>
<contexts>
<context position="2049" citStr="Baldwin et al., 2009" startWordPosition="322" endWordPosition="325">of an article cannot be relied on. The problem of distinguishing between common and proper usages of nouns has not received much attention within language processing, despite being an important component for many tasks including machine translation (Lopez, 2008; Hermjakob et al., 80 2008), sentiment analysis (Pang and Lee, 2008; Wilson et al., 2009) and topic tracking (Petrovi´c et al., 2010). Approaches to the problem also have applications to tasks such as web search (Chen et al., 1998; Baeza-Yates and Ribeiro-Neto, 2011), and case restoration (e.g., in automatic speech recognition output) (Baldwin et al., 2009), but frequently involve the manual creation of a gazeteer (a list of proper nouns), which suffer not only from omissions but also often do not allow the listed words to assume their common role in text. This paper presents methods for generating lists of nouns that have both common and proper usages (Section 2) and methods for identifying the type of usage (Section 3) which are evaluated using data derived automatically from the BNC (Section 4) and on two applications (Section 5). It shows that it is difficult to automatically construct lists of ambiguous nouns but also that they can be disti</context>
</contexts>
<marker>Baldwin, Paul, Joseph, 2009</marker>
<rawString>Baldwin, T., Paul, M., and Joseph, A. (2009). Restoring punctuation and casing in English text. In Proceedings of the 22nd Australian Joint Conference on Artificial Intelligence (AI09), pages 547–556.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bird</author>
<author>E Klein</author>
<author>E Loper</author>
</authors>
<title>Web 1T 5-gram v1.</title>
<date>2009</date>
<booktitle>Natural Language Processing with Python – Analyzing Text with the Natural Language Toolkit.</booktitle>
<contexts>
<context position="8133" citStr="Bird et al., 2009" startWordPosition="1360" endWordPosition="1363">45%) for experiments in the following sections.1 1The 100 words selected for our evaluation are available at http://pastehtml.com/view/cjsbs4xvl.txt 81 3 Identifying Noun Types We cast the problem of distinguishing between common and proper usages of nouns as a classification task and develop the following approaches. 3.1 Most frequent usage A naive baseline is supplied by assigning each word its most frequent usage form (common or proper noun). The most frequent usage is derived from the training portion of labeled data. 3.2 n-gram system A system based on n-grams was implemented using NLTK (Bird et al., 2009). Five-grams, four-grams, trigrams and bigrams from the training corpus are matched against a test corpus sentence, and results of each match are summed to yield a preferred use in the given context with a higher weight (experimentally determined) being assigned to longer n-grams. The system backs off to the most frequent usage (as derived from the training data). 3.3 Vector Space Model (VSM) Distinguishing between common and proper nouns can be viewed as a classification problem. Treating the problem in this manner is reminiscent of techniques commonly employed in Word Sense Disambiguation (W</context>
</contexts>
<marker>Bird, Klein, Loper, 2009</marker>
<rawString>Bird, S., Klein, E., and Loper, E. (2009). Natural Language Processing with Python – Analyzing Text with the Natural Language Toolkit. O’Reilly. Brants, T. and Franz, A. (2006). Web 1T 5-gram v1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Briscoe</author>
<author>J Carroll</author>
<author>R Watson</author>
</authors>
<title>The second release of the RASP system.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL</booktitle>
<contexts>
<context position="3510" citStr="Briscoe et al., 2006" startWordPosition="559" endWordPosition="562">ate such lists automatically. Part of speech tags A number of part of speech (PoS) taggers assign different tags to common and proper nouns. Ambiguous nouns are identified by tagging a corpus and extracting those that have had both tags assigned, together with the frequency of occurrence of the common/proper usage. The CLAWS (Garside, 1987) and the RASP taggers Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference and the Shared Task, pages 80–84, Atlanta, Georgia, June 13-14, 2013. c�2013 Association for Computational Linguistics (Briscoe et al., 2006) were applied to the British National Corpus (BNC) (Leech, 1992) to generate the lists BNCclaws and BNCrasp respectively. In addition the RASP tagger was also run over the 1.75 billion word Gigaword corpus (Graff, 2003) to extract the list Gigaword. Capitalization Nouns appearing intrasententially with both lower and upper case first letters are assumed to be ambiguous. This technique is applied to the 5-grams from the Google corpus (Brants and Franz, 2006) and the BNC (creating the lists 5-grams and BNCcaps). Wikipedia includes disambiguation pages for ambiguous words which provide informatio</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Briscoe, T., Carroll, J., and Watson, R. (2006). The second release of the RASP system. In Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Chen</author>
<author>S Huang</author>
<author>Y Ding</author>
<author>S Tsai</author>
</authors>
<title>Proper name translation in cross-language information retrieval.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>232--236</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="1920" citStr="Chen et al., 1998" startWordPosition="304" endWordPosition="307">tart with a capital letter in English, capitalization can be inconsistent, incorrect or omitted, and the presence or absence of an article cannot be relied on. The problem of distinguishing between common and proper usages of nouns has not received much attention within language processing, despite being an important component for many tasks including machine translation (Lopez, 2008; Hermjakob et al., 80 2008), sentiment analysis (Pang and Lee, 2008; Wilson et al., 2009) and topic tracking (Petrovi´c et al., 2010). Approaches to the problem also have applications to tasks such as web search (Chen et al., 1998; Baeza-Yates and Ribeiro-Neto, 2011), and case restoration (e.g., in automatic speech recognition output) (Baldwin et al., 2009), but frequently involve the manual creation of a gazeteer (a list of proper nouns), which suffer not only from omissions but also often do not allow the listed words to assume their common role in text. This paper presents methods for generating lists of nouns that have both common and proper usages (Section 2) and methods for identifying the type of usage (Section 3) which are evaluated using data derived automatically from the BNC (Section 4) and on two applicatio</context>
</contexts>
<marker>Chen, Huang, Ding, Tsai, 1998</marker>
<rawString>Chen, H., Huang, S., Ding, Y., and Tsai, S. (1998). Proper name translation in cross-language information retrieval. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1, pages 232–236, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cieri</author>
<author>D Graff</author>
<author>M Liberman</author>
<author>N Martey</author>
<author>S Strassel</author>
</authors>
<title>The TDT-2 text and speech corpus.</title>
<date>1999</date>
<booktitle>In Proceedings of DARPA Broadcast News Workshop,</booktitle>
<pages>57--60</pages>
<contexts>
<context position="14481" citStr="Cieri et al., 1999" startWordPosition="2420" endWordPosition="2423"> the data – there are many more examples for the common use of each noun, and thus each context is much more likely to have been seen in this setting. 5.2 Automatic speech recognition Most automatic speech recognition (ASR) systems do not provide capitalization. However, our system does not rely on capitalization information, and therefore can identify proper / common nouns even if capitalization is absent. Also, once proper nouns are identified, the system can be used to restore case – a feature which allows an evaluation to take place on this dataset. We use the TDT2 Test and Speech corpus (Cieri et al., 1999), which contains ASR and a manually transcribed version of news texts from six different sources, to demonstrate the usefulness of this system for this task. The ASR corpus is restricted to those segments which contain an equal number of target word occurrences in the ASR text and the manually transcribed version, and all such segments are extracted. The gold standard, and the most frequent usage, are drawn from the manually transcribed data. Again, results are based on an average performance obtained using a ten fold cross validation. Three versions of training data are used: the 9/10 of ASR </context>
</contexts>
<marker>Cieri, Graff, Liberman, Martey, Strassel, 1999</marker>
<rawString>Cieri, C., Graff, D., Liberman, M., Martey, N., and Strassel, S. (1999). The TDT-2 text and speech corpus. In Proceedings of DARPA Broadcast News Workshop, pages 57–60.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database and some of its Applications.</title>
<date>1998</date>
<editor>Fellbaum, C., editor</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1998</marker>
<rawString>Fellbaum, C., editor (1998). WordNet: An Electronic Lexical Database and some of its Applications. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Finkel</author>
<author>T Grenager</author>
<author>C Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by Gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>363--370</pages>
<contexts>
<context position="4379" citStr="Finkel et al., 2005" startWordPosition="694" endWordPosition="697"> Capitalization Nouns appearing intrasententially with both lower and upper case first letters are assumed to be ambiguous. This technique is applied to the 5-grams from the Google corpus (Brants and Franz, 2006) and the BNC (creating the lists 5-grams and BNCcaps). Wikipedia includes disambiguation pages for ambiguous words which provide information about their potential usage. Wikipedia pages for nouns with senses (according to the disambiguation page) in a set of predefined categories were identified to form the list Wikipedia. Named entity recognition The Stanford Named Entity Recogniser (Finkel et al., 2005) was run over the BNC and any nouns that occur in the corpus with both named entity and non-named entity tags are extracted to form the list Stanford. WordNet The final heuristic makes use of WordNet (Fellbaum, 1998) which lists nouns that are often used as proper nouns with capitalisation. Nouns which appeared in both a capitalized and lowercased form were extracted to create the list WordNet. Table 1 shows the number of nouns identified by each technique in the column labeled words which demonstrates that the number of nouns identified varies significantly depending upon which heuristic is u</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Finkel, J. R., Grenager, T., and Manning, C. (2005). Incorporating non-local information into information extraction systems by Gibbs sampling. In Proceedings of the 43nd Annual Meeting of the Association for Computational Linguistics, pages 363–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Garside</author>
</authors>
<title>The CLAWS word-tagging system.</title>
<date>1987</date>
<booktitle>The Computational Analysis of English: A Corpusbased Approach.</booktitle>
<editor>In Garside, R., Leech, G., and Sampson, G., editors,</editor>
<publisher>Longman.</publisher>
<location>London:</location>
<contexts>
<context position="3231" citStr="Garside, 1987" startWordPosition="521" endWordPosition="522"> but also that they can be distinguished effectively using standard features from Word Sense Disambiguation. 2 Generating Lists of Nouns To our knowledge, no comprehensive list of common nouns with proper noun usage is available. We develop a number of heuristics to generate such lists automatically. Part of speech tags A number of part of speech (PoS) taggers assign different tags to common and proper nouns. Ambiguous nouns are identified by tagging a corpus and extracting those that have had both tags assigned, together with the frequency of occurrence of the common/proper usage. The CLAWS (Garside, 1987) and the RASP taggers Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference and the Shared Task, pages 80–84, Atlanta, Georgia, June 13-14, 2013. c�2013 Association for Computational Linguistics (Briscoe et al., 2006) were applied to the British National Corpus (BNC) (Leech, 1992) to generate the lists BNCclaws and BNCrasp respectively. In addition the RASP tagger was also run over the 1.75 billion word Gigaword corpus (Graff, 2003) to extract the list Gigaword. Capitalization Nouns appearing intrasententially with both lower and up</context>
</contexts>
<marker>Garside, 1987</marker>
<rawString>Garside, R. (1987). The CLAWS word-tagging system. In Garside, R., Leech, G., and Sampson, G., editors, The Computational Analysis of English: A Corpusbased Approach. London: Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Graff</author>
</authors>
<title>English Gigaword.</title>
<date>2003</date>
<tech>Technical report,</tech>
<institution>Linguistic Data Consortium.</institution>
<contexts>
<context position="3729" citStr="Graff, 2003" startWordPosition="599" endWordPosition="600">oth tags assigned, together with the frequency of occurrence of the common/proper usage. The CLAWS (Garside, 1987) and the RASP taggers Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference and the Shared Task, pages 80–84, Atlanta, Georgia, June 13-14, 2013. c�2013 Association for Computational Linguistics (Briscoe et al., 2006) were applied to the British National Corpus (BNC) (Leech, 1992) to generate the lists BNCclaws and BNCrasp respectively. In addition the RASP tagger was also run over the 1.75 billion word Gigaword corpus (Graff, 2003) to extract the list Gigaword. Capitalization Nouns appearing intrasententially with both lower and upper case first letters are assumed to be ambiguous. This technique is applied to the 5-grams from the Google corpus (Brants and Franz, 2006) and the BNC (creating the lists 5-grams and BNCcaps). Wikipedia includes disambiguation pages for ambiguous words which provide information about their potential usage. Wikipedia pages for nouns with senses (according to the disambiguation page) in a set of predefined categories were identified to form the list Wikipedia. Named entity recognition The Stan</context>
</contexts>
<marker>Graff, 2003</marker>
<rawString>Graff, D. (2003). English Gigaword. Technical report, Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hermjakob</author>
<author>K Knight</author>
<author>H Daum´e</author>
</authors>
<title>Name translation in statistical machine translation -learning when to transliterate.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL08: HLT,</booktitle>
<pages>389--397</pages>
<location>Columbus, Ohio.</location>
<marker>Hermjakob, Knight, Daum´e, 2008</marker>
<rawString>Hermjakob, U., Knight, K., and Daum´e III, H. (2008). Name translation in statistical machine translation -learning when to transliterate. In Proceedings ofACL08: HLT, pages 389–397, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Leech</author>
</authors>
<title>100 million words of English:</title>
<date>1992</date>
<journal>the British National Corpus. Language Research,</journal>
<volume>28</volume>
<issue>1</issue>
<contexts>
<context position="3574" citStr="Leech, 1992" startWordPosition="572" endWordPosition="573">ech (PoS) taggers assign different tags to common and proper nouns. Ambiguous nouns are identified by tagging a corpus and extracting those that have had both tags assigned, together with the frequency of occurrence of the common/proper usage. The CLAWS (Garside, 1987) and the RASP taggers Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference and the Shared Task, pages 80–84, Atlanta, Georgia, June 13-14, 2013. c�2013 Association for Computational Linguistics (Briscoe et al., 2006) were applied to the British National Corpus (BNC) (Leech, 1992) to generate the lists BNCclaws and BNCrasp respectively. In addition the RASP tagger was also run over the 1.75 billion word Gigaword corpus (Graff, 2003) to extract the list Gigaword. Capitalization Nouns appearing intrasententially with both lower and upper case first letters are assumed to be ambiguous. This technique is applied to the 5-grams from the Google corpus (Brants and Franz, 2006) and the BNC (creating the lists 5-grams and BNCcaps). Wikipedia includes disambiguation pages for ambiguous words which provide information about their potential usage. Wikipedia pages for nouns with se</context>
</contexts>
<marker>Leech, 1992</marker>
<rawString>Leech, G. (1992). 100 million words of English: the British National Corpus. Language Research, 28(1):1–13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lopez</author>
</authors>
<title>Statistical machine translation.</title>
<date>2008</date>
<journal>ACM Computing Surveys,</journal>
<volume>40</volume>
<issue>3</issue>
<contexts>
<context position="1689" citStr="Lopez, 2008" startWordPosition="265" endWordPosition="266">e common and proper uses are not always as clearly distinct as in this example; for example, a specific instance of a common noun, e.g., District Court turns court into a proper noun. While heuristically, proper nouns often start with a capital letter in English, capitalization can be inconsistent, incorrect or omitted, and the presence or absence of an article cannot be relied on. The problem of distinguishing between common and proper usages of nouns has not received much attention within language processing, despite being an important component for many tasks including machine translation (Lopez, 2008; Hermjakob et al., 80 2008), sentiment analysis (Pang and Lee, 2008; Wilson et al., 2009) and topic tracking (Petrovi´c et al., 2010). Approaches to the problem also have applications to tasks such as web search (Chen et al., 1998; Baeza-Yates and Ribeiro-Neto, 2011), and case restoration (e.g., in automatic speech recognition output) (Baldwin et al., 2009), but frequently involve the manual creation of a gazeteer (a list of proper nouns), which suffer not only from omissions but also often do not allow the listed words to assume their common role in text. This paper presents methods for gene</context>
</contexts>
<marker>Lopez, 2008</marker>
<rawString>Lopez, A. (2008). Statistical machine translation. ACM Computing Surveys, 40(3):1–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<volume>Vol.</volume>
<pages>2--1</pages>
<contexts>
<context position="1757" citStr="Pang and Lee, 2008" startWordPosition="274" endWordPosition="277">s in this example; for example, a specific instance of a common noun, e.g., District Court turns court into a proper noun. While heuristically, proper nouns often start with a capital letter in English, capitalization can be inconsistent, incorrect or omitted, and the presence or absence of an article cannot be relied on. The problem of distinguishing between common and proper usages of nouns has not received much attention within language processing, despite being an important component for many tasks including machine translation (Lopez, 2008; Hermjakob et al., 80 2008), sentiment analysis (Pang and Lee, 2008; Wilson et al., 2009) and topic tracking (Petrovi´c et al., 2010). Approaches to the problem also have applications to tasks such as web search (Chen et al., 1998; Baeza-Yates and Ribeiro-Neto, 2011), and case restoration (e.g., in automatic speech recognition output) (Baldwin et al., 2009), but frequently involve the manual creation of a gazeteer (a list of proper nouns), which suffer not only from omissions but also often do not allow the listed words to assume their common role in text. This paper presents methods for generating lists of nouns that have both common and proper usages (Secti</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Pang, B. and Lee, L. (2008). Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, Vol. 2(1-2):pp. 1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrovi´c</author>
<author>M Osborne</author>
<author>V Lavrenko</author>
</authors>
<title>Streaming first story detection with application to twitter.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>181--189</pages>
<location>Los Angeles, California.</location>
<marker>Petrovi´c, Osborne, Lavrenko, 2010</marker>
<rawString>Petrovi´c, S., Osborne, M., and Lavrenko, V. (2010). Streaming first story detection with application to twitter. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 181–189, Los Angeles, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>J Wiebe</author>
<author>P Hoffman</author>
</authors>
<title>Recognizing contextual polarity: an exploration of features for phrase-level sentiment analysis.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>5</issue>
<contexts>
<context position="1779" citStr="Wilson et al., 2009" startWordPosition="278" endWordPosition="282">or example, a specific instance of a common noun, e.g., District Court turns court into a proper noun. While heuristically, proper nouns often start with a capital letter in English, capitalization can be inconsistent, incorrect or omitted, and the presence or absence of an article cannot be relied on. The problem of distinguishing between common and proper usages of nouns has not received much attention within language processing, despite being an important component for many tasks including machine translation (Lopez, 2008; Hermjakob et al., 80 2008), sentiment analysis (Pang and Lee, 2008; Wilson et al., 2009) and topic tracking (Petrovi´c et al., 2010). Approaches to the problem also have applications to tasks such as web search (Chen et al., 1998; Baeza-Yates and Ribeiro-Neto, 2011), and case restoration (e.g., in automatic speech recognition output) (Baldwin et al., 2009), but frequently involve the manual creation of a gazeteer (a list of proper nouns), which suffer not only from omissions but also often do not allow the listed words to assume their common role in text. This paper presents methods for generating lists of nouns that have both common and proper usages (Section 2) and methods for </context>
</contexts>
<marker>Wilson, Wiebe, Hoffman, 2009</marker>
<rawString>Wilson, T., Wiebe, J., and Hoffman, P. (2009). Recognizing contextual polarity: an exploration of features for phrase-level sentiment analysis. Computational Linguistics, 35(5).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>