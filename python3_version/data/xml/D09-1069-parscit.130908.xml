<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.998327">
Can Chinese Phonemes Improve Machine Transliteration?:
A Comparative Study of English-to-Chinese Transliteration Models
</title>
<author confidence="0.99608">
Jong-Hoon Oh, Kiyotaka Uchimoto, and Kentaro Torisawa
</author>
<affiliation confidence="0.99314">
Language Infrastructure Group, MASTAR Project,
National Institute of Information and Communications Technology (NICT)
</affiliation>
<address confidence="0.957855">
3-5 Hikaridai Seika-cho, Soraku-gun, Kyoto 619-0289 Japan
</address>
<email confidence="0.999728">
{rovellia,uchimoto,torisawa}@nict.go.jp
</email>
<sectionHeader confidence="0.994814" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999637684210526">
Inspired by the success of English
grapheme-to-phoneme research in speech
synthesis, many researchers have pro-
posed phoneme-based English-to-Chinese
transliteration models. However, such ap-
proaches have severely suffered from the
errors in Chinese phoneme-to-grapheme
conversion. To address this issue,
we propose a new English-to-Chinese
transliteration model and make system-
atic comparisons with the conventional
models. Our proposed model relies on
the joint use of Chinese phonemes and
their corresponding English graphemes
and phonemes. Experiments showed that
Chinese phonemes in our proposed model
can contribute to the performance im-
provement in English-to-Chinese translit-
eration.
</bodyText>
<sectionHeader confidence="0.998492" genericHeader="keywords">
1 Introduction
</sectionHeader>
<subsectionHeader confidence="0.97256">
1.1 Motivation
</subsectionHeader>
<bodyText confidence="0.999278">
Transliteration, i.e., phonetic translation, is com-
monly used to translate proper names and techni-
cal terms across languages. A variety of English-
to-Chinese machine transliteration models has
been proposed in the last decade (Meng et al.,
2001; Gao et al., 2004; Jiang et al., 2007; Lee
and Chang, 2003; Li et al., 2004; Li et al., 2007;
Wan and Verspoor, 1998; Virga and Khudanpur,
2003). They can be categorized into those based
on Chinese phonemes (Meng et al., 2001; Gao
et al., 2004; Jiang et al., 2007; Lee and Chang,
2003; Wan and Verspoor, 1998; Virga and Khu-
danpur, 2003) and those that don’t rely on Chinese
phonemes (Li et al., 2004; Li et al., 2007).
Inspired by the success of English grapheme-to-
phoneme research in speech synthesis, many re-
searchers have proposed phoneme-based English-
to-Chinese transliteration models. In these ap-
proaches, Chinese phonemes are generated from
English graphemes or phonemes, and then the
Chinese phonemes are converted into Chinese
graphemes (or characters), where Chinese Pinyin
strings1 are used for representing a syllable-level
Chinese phoneme sequence. Despite its high ac-
curacy in generating Chinese phonemes from En-
glish, this approach has severely suffered from er-
rors in Chinese phoneme-to-grapheme conversion,
mainly caused by Chinese homophone confusion
– one Chinese Pinyin string can correspond to sev-
eral Chinese characters (Li et al., 2004). For ex-
ample, the Pinyin string “LI” corresponds to such
different Chinese characters as fg, V1, and �. For
this reason, it has been reported that English-to-
Chinese transliteration without Chinese phonemes
outperforms that with Chinese phonemes (Li et al.,
2004).
Then “Can Chinese phonemes improve
English-to-Chinese transliteration, if we can re-
duce the errors in Chinese phoneme-to-grapheme
conversion?” Our research starts from this
question.
</bodyText>
<subsectionHeader confidence="0.983331">
1.2 Our Approach
</subsectionHeader>
<bodyText confidence="0.9601306">
Previous approaches using Chinese phonemes
have relied only on Chinese phonemes in Chi-
nese phoneme-to-grapheme conversion. However,
the simple use of Chinese phonemes doesn’t al-
ways provide a good clue to reduce the ambi-
guity in Chinese phoneme-to-grapheme conver-
sion. Let us explain with an example, the Chinese
transliteration of Greeley in Table 1, where Chi-
nese phonemes are represented in terms of Chi-
nese Pinyin strings and English phonemes are rep-
resented by ARPAbet symbols2.
In Table 1, Chinese Pinyin string “LI” corre-
sponds to two different Chinese characters, N. and
1Pinyin, the most commonly used Romanization sys-
tem for Chinese characters, faithfully represents Chinese
</bodyText>
<page confidence="0.94877">
658
</page>
<note confidence="0.8975095">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 658–667,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
• The MS models always showed the worst
performance due to the severe error rate in
Chinese phoneme-to-grapheme conversion.
Table 1: Chinese Pinyin string “LI” and its corre-
sponding Chinese characters in Chinese transliter-
ation of Greeley
English grapheme g ree ley
English phoneme G R IY L IY
Chinese Pinyin GE LI LI
Chinese character 4 ffi f11
</note>
<bodyText confidence="0.99891425">
fg. It seems difficult to find evidence for select-
ing the correct Chinese character corresponding to
each Chinese Pinyin string “LI” by just looking
at the sequence of Chinese Pinyin strings “GE LI
LI.” However, English graphemes (ree and ley) or
phonemes (“R IY” and “L IY”) corresponding to
Chinese Pinyin string “LI”, especially their conso-
nant parts (r and l in the English graphemes and
“R” and “L” in the English phonemes), provide
strong evidence to resolve the ambiguity. Thus,
we can easily find rules for the conversion from
Chinese Pinyin string “LI” to N. and fl] as follows:
</bodyText>
<listItem confidence="0.846581">
• ( “R 7I�Y&amp;quot;, LI ) → W
J
• ( “L 1 1 &amp;quot;, LI ) → iN
</listItem>
<bodyText confidence="0.988575571428571">
Based on the observation, we propose an
English-to-Chinese transliteration model based on
the joint use of Chinese phonemes and their corre-
sponding English graphemes and phonemes. We
define a set of English-to-Chinese transliteration
models and categorize them into the following
three classes:
</bodyText>
<listItem confidence="0.883757214285714">
• MI: Models Independent of Chinese
phonemes
• MS: Models based on Simple use of Chinese
phonemes
• MJ: Models based on Joint use of Chi-
nese phonemes and English graphemes and
phonemes that correspond to our proposed
model.
Our comparison among the three types of translit-
eration models can be summarized as follows.
• The MI models relying on either English
graphemes or phonemes could not outper-
form those based on both English graphemes
and phonemes.
</listItem>
<footnote confidence="0.883530333333333">
phonemes and syllables (Yin and Felley, 1990).
2http://www.cs.cmu.edu/˜laura/pages/
arpabet.ps
</footnote>
<listItem confidence="0.95352575">
• The MJ models significantly reduced er-
rors in Chinese phoneme-to-grapheme con-
version; thus they achieved the best perfor-
mance.
</listItem>
<bodyText confidence="0.999802166666667">
The rest of this paper is organized as follows.
Section 2 introduces the notations used through-
out this paper. Section 3 describes the translitera-
tion models we compared. Section 4 describes our
tests and results. Section 5 concludes the paper
with a summary.
</bodyText>
<sectionHeader confidence="0.990225" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<bodyText confidence="0.999661117647059">
Let EG be an English word composed of n English
graphemes, and let EP be a sequence of English
phonemes that represents the pronunciation of EG.
Let CG be a sequence of Chinese graphemes cor-
responding to the Chinese transliteration of EG,
and let CP be a sequence of Chinese phonemes
that represents the pronunciation of CG.
CP corresponds to a sequence of the Chinese
Pinyin strings of CG. Because a Chinese Pinyin
string represents the pronunciation of a sylla-
ble consisting of consonants and vowels, we di-
vide a Chinese Pinyin string into consonant and
vowel parts like “L+I”, “L+I+N”, and “SH+A.”
In this paper, we define a Chinese phoneme
as the vowel and consonant parts in a Chinese
Pinyin string (e.g., “L”, “SH”, and “I”). A Chi-
nese character usually corresponds to multiple
English graphemes, English phonemes, and Chi-
nese phonemes (i.e., W corresponds to English
graphemes ree, English phonemes “R IY”, and
Chinese phonemes “L I” in Table 1). To repre-
sent these many-to-one correspondences, we use
the well-known BIO labeling scheme to represent
a Chinese character, where B and I represent the
beginning and inside/end of the Chinese charac-
ters, respectively, and O is not used. Each Chi-
nese phoneme corresponds to a Chinese character
with B and I labels. For example, Chinese charac-
ter “-T-” in Table 1 can be represented as “N:B”
and “�:I”, where “-T-:B” and “N:I” correspond
to Chinese phonemes “L” and “I”, respectively. In
this paper, we define a Chinese grapheme as a Chi-
nese character represented with a BIO label, e.g.,
“-T-:B” and “T:I.”
</bodyText>
<page confidence="0.998324">
659
</page>
<subsectionHeader confidence="0.954073">
3.1 Basic Transliteration Models
</subsectionHeader>
<bodyText confidence="0.7810282">
The basic transliteration models in each class are
denoted as M(x, y).
Table 2: egi and its corresponding epi, cpi, and cgi
in Greeley and its corresponding Chinese translit-
eration “*fflfIJ”
</bodyText>
<table confidence="0.9829195">
i 1 2 3 4 5 6 7
EG g r e e l e y
EP G R IY L IY
CP GE L I L I
GE LI LI
CG *:B ffl:B ffl:I fIJ:B fIJ:I
</table>
<bodyText confidence="0.982149">
Then EP, CP, and CG can be segmented into a
series of sub-strings, each of which corresponds to
an English grapheme in EG. We can thus write
</bodyText>
<listItem confidence="0.999715">
• EG = eg1, ··· , egn = egn1
• EP = ep1, ··· ,epn = epn1
• CP = cp1, ··· ,cpn = cpn1
• CG = cg1,··· ,cgn = cgn1
</listItem>
<bodyText confidence="0.999781384615385">
where egi, epi, cpi, and cgi represent the ith
English grapheme, English phonemes, Chinese
phonemes, and Chinese graphemes corresponding
to egi, respectively.
Based on the definition, we model English-
to-Chinese transliteration so that each English
grapheme is tagged with its corresponding En-
glish phonemes, Chinese phonemes, and Chinese
graphemes. Table 2 illustrates egi, epi, cpi, and
cgi with the same example listed in Table 1 (En-
glish word Greeley and its corresponding Chinese
transliteration “*fflfIJ”)3, where represents an
empty string.
</bodyText>
<sectionHeader confidence="0.998413" genericHeader="method">
3 Transliteration Model
</sectionHeader>
<bodyText confidence="0.999848">
We defined eighteen transliteration models to be
compared. These transliteration models are clas-
sified into three classes, MI, MS, and M,I as de-
scribed in Section 1.2; each class has three basic
transliteration models and three hybrid ones. In
this section, we first describe the basic translit-
eration models in each class by focusing on the
main difference among the three classes and then
describe the hybrid transliteration models.
</bodyText>
<footnote confidence="0.9014865">
3We performed alignment between EG and EP and be-
tween EP and CP in a similar manner presented in Li et al.
(2004). Then the two alignment results were merged using
EP as a pivot. Finally, we made a correspondence relation
among egi, epi, cpi, and cgi using the merged alignment re-
sult and the Pinyin table.
</footnote>
<listItem confidence="0.996626333333333">
• (x, y) E X x Y
• x E X = tEG, EP, EGP}
• y E Y = t , CP, JCP}
</listItem>
<bodyText confidence="0.986536863636364">
x is an English-side parameter representing En-
glish grapheme (EG), English phoneme (EP), and
the joint use of English grapheme and phoneme
(EGP = (EG, EP)) that contributes to generat-
ing Chinese phonemes or Chinese graphemes in
a transliteration model. y is a Chinese-phoneme
parameter that represents a way of using Chinese
phonemes to generate Chinese graphemes in a
transliteration model. Since M(x, ) represents
a transliteration model that does not rely on Chi-
nese phonemes, it falls into MI, while M(x, CP)
corresponds to a transliteration model in MS that
only uses Chinese phonemes in Chinese phoneme-
to-grapheme conversion. M(x, JCP) is a translit-
eration model in the M,I class that generates Chi-
nese transliterations based on joint use of x and
Chinese phoneme CP, where x E X. Thus,
M(x, JCP) can be rewritten as M(x, (x, CP)),
where the joint representation of x and CP,
(x, CP), is used in Chinese phoneme-to-grapheme
conversion. The three basic models in M,I can be
interpreted as follows:
</bodyText>
<listItem confidence="0.999805333333333">
• M(EG, JCP) = M(EG, (EG, CP))
• M(EP, JCP) = M(EP, (EP, CP))
• M(EGP, JCP) = M(EGP, (EGP, CP))
</listItem>
<bodyText confidence="0.956073066666667">
M(EG, JCP) directly converts English
graphemes into Chinese phonemes without
the help of English phonemes and then gener-
ates Chinese transliterations based on the joint
representation of English graphemes and Chi-
nese phonemes. The main difference between
M(EP, JCP) and M(EGP, JCP) lies in the
use of English graphemes to generate Chinese
phonemes and graphemes. English graphemes
are only used in English grapheme-to-phoneme
conversion, and English phonemes play a crucial
role for generating Chinese transliteration in
M(EP, JCP). Chinese phoneme-to-grapheme
conversion that relies on the joint use of English
graphemes, English phonemes, and Chinese
</bodyText>
<page confidence="0.701358">
660
</page>
<equation confidence="0.9957175">
�PM(EG,JCP )(CG|EG) = P(CP|EG) x P(CG|EG,CP) (1)
VCP
�PM(EP ,JCP )(CG|EG) = � P(EP|EG) x P(CP|EP) x P(CG|EP, CP) (2)
VCP VEP
�PM(EGP ,JCP )(CG|EG) = E P(EP|EG) x P(CP|EG,EP) x P(CG|EG,EP,CP) (3)
VCP VEP
PM(EG,CP )(CG|EG) = � P(CP|EG) x P(CG|CP) (4)
VCP
PM(EP ,CP )(CG|EG) = � E P(EP|EG) x P(CP|EP) x P(CG|CP) (5)
VCP VEP
�PM(EGP ,CP )(CG|EG) = E P(EP|EG) x P(CP|EG,EP) x P(CG|CP) (6)
VCP VEP
</equation>
<bodyText confidence="0.998385">
phonemes is the key feature of M(EGP, JCP).
Because M(x, JCP) can be interpreted as
M(x, (x, CP)), English-side parameter x de-
termines the English graphemes and phonemes,
or both jointly used with Chinese phonemes in
Chinese phoneme-to-grapheme conversion. Then
we can represent the three basic transliteration
models as in Eqs. (1)–(3), where P(CG|EG, CP),
P(CG|EP, CP), and P(CG|EG, EP, CP) are the
key points in our proposed models, MJ.
The three basic transliteration models in MS
– M(EG, CP), M(EP, CP), and M(EGP, CP) –
are formulated as Eqs. (4)–(6). Chinese phoneme-
based transliteration models in the literature fall
into either M(EG, CP) or M(EP, CP) (Meng et
al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee
and Chang, 2003; Wan and Verspoor, 1998; Virga
and Khudanpur, 2003). The three basic transliter-
ation models in MS are identical as those in MJ,
except for the Chinese phoneme-to-grapheme con-
version method. They only depend on Chinese
phonemes in Chinese phoneme-to-grapheme con-
version represented as P(CG|CP) in Eqs. (4)–(6).
</bodyText>
<equation confidence="0.992979142857143">
PM(EG,O)(CG|EG) = P(CG|EG) (7)
PM(EP ,O)(CG|EG) (8)
�= P(EP |EG) x P(CG|EP)
VEP
PM(EGP ,O)(CG|EG) (9)
�= P(EP|EG) x P(CG|EG,EP)
VEP
</equation>
<bodyText confidence="0.999805727272727">
The three basic transliteration models in MI are
represented in Eqs. (7)–(9). Because the MI mod-
els are independent of Chinese phonemes, they are
the same as the transliteration models in the lit-
erature used for machine transliteration from En-
glish to other languages without relying on target-
language phonemes (Karimi et al., 2007; Malik,
2006; Oh et al., 2006; Sherif and Kondrak, 2007;
Yoon et al., 2007). Note that M(EG, 0) is the
same transliteration model as the one proposed by
Li et al. (2004).
</bodyText>
<subsectionHeader confidence="0.999382">
3.2 Hybrid Transliteration Models
</subsectionHeader>
<bodyText confidence="0.981684142857143">
The hybrid transliteration models in each class
are defined by discrete mixture between the prob-
ability distribution of the two basic transliter-
ation models, as in Eq. (10) (Al-Onaizan and
Knight, 2002; Oh et al., 2006), where 0 &lt; α &lt;
1. We denote a hybrid transliteration model be-
tween two basic transliteration models M(x1, y)
</bodyText>
<construct confidence="0.709008166666667">
and M(x2, y) as M(x1 + x2, y, α), where y E
Y = {0, CP, JCP}, x1 =� x2, and x1, x2 E
X = {EG, EP, EGP}. In this paper, we define
three types of hybrid transliteration models in each
class: M(EG + EP, y, α), M(EG + EGP, y, α),
and M(EP + EGP, y, α).
</construct>
<equation confidence="0.997075333333333">
PM(x1+x2,y,α)(CG|EG) (10)
= α x PM(x1,y)(CG|EG)
+ (1 − α) x PM(x2,y)(CG|EG)
</equation>
<subsectionHeader confidence="0.998022">
3.3 Probability Estimation
</subsectionHeader>
<bodyText confidence="0.9995542">
Because Eqs. (1)–(9) can be estimated in a similar
way, we limit our focus to Eq. (3) in this section.
Assuming that P(EP|EG), P(CP|EG, EP), and
P(CG|EG, EP, CP) in Eq. (3) depend on the size
of the context window, k (k = 3 in this paper),
</bodyText>
<page confidence="0.998126">
661
</page>
<tableCaption confidence="0.994651">
Table 3: Feature functions for P(cgi|cgi−1
</tableCaption>
<equation confidence="0.976916416666667">
i−k, (eg, ep, cp�i+k
i−k) with an example in Table 2, where i = 2
f1 gram3(egi) egi+2
i = “ree” cgi = “ffl
air c c c “G&amp;quot; c •B&amp;quot; c= &amp;quot;ffl:B”
f2 p 11 7�i-1 � 9i-1 7�i-1 = , 9i-1 = gi —
air c c ) c i = “GE L” c •B&amp;quot; c = &amp;quot; B”
f3 p 12( gi-1 A-1 pi−1 — gi-1= gi —
f4 pair22(cpi−1,cgi−2) egii−1 = “gr”, epi i−1 = “G R” cgi = “N:B”
f5 triple1(egi, cpi, cgi−1) egi = “r”, cpi−1 = “GE”, c &amp;quot; •B&amp;quot; &amp;quot;N:B&amp;quot;
gi-1= c gi =
f6 triple2(egi−1, cgi−1, cpi−1) egi−1 = “g”, cpi i−1= “GE L”, cgi−1= “�:B” cgi = “~:B”
</equation>
<bodyText confidence="0.9905687">
they can be simplified into a series of products in
Eqs. (11)–(13).
The maximum entropy model is used to esti-
mate the probabilities in Eqs. (11)–(13) (Berger
et al., 1996). Generally, a conditional maxi-
mum entropy model is an exponential model that
gives the conditional probability, as described in
Eq. (14), where λi is the parameter to be estimated
and fi(a, b) is a feature function corresponding to
λi (Berger et al., 1996; Ratnaparkhi, 1997):
</bodyText>
<equation confidence="0.996517722222222">
P (epi|epi−1
i−k,egi+k
i−k) (11)
i
P(CP |EG, EP) (12)
�
≈P(cpi|cpi−1
i−k,�eg, ep�i+k
i−k)
i
P(CG|EG, EP, CP) (13)
�
≈P(cgi|cgi−1
i−k, (eg, ep, cp�i+k
i−k)
)
P(b a — exp(Ei λifi(a, b)) 14)
l I — Eb&apos; exp(Ei λifi(a, b&apos;))
</equation>
<bodyText confidence="0.9876186">
fi(a, b) is a binary function returning TRUE
or FALSE based on context a and output b.
If fi(a, b)=1, its corresponding model parame-
ter λi contributes toward conditional probability
P(b |a) (Berger et al., 1996; Ratnaparkhi, 1997).
The feature functions used here are defined in
terms of context predicates — a function return-
ing TRUE or FALSE that depends on the presence
of the information in the current context (Ratna-
parkhi, 1997). Context predicates and their de-
scriptions used are given in Table 4.
N-GRAM includes gram1(uj), gram2(uj), and
gram3(uj) corresponding to a unigram, a bigram,
and a trigram, respectively. PAIR includes a pair of
unigrams (pair11), unigram and bigram (pair12),
and bigrams (pair22). TRIPLE includes a triple of
three unigrams (triple1) and a triple of two uni-
grams and one bigram (triple2). Note that if dif-
ferent context predicates represent the same con-
text, we accept one of them and ignore the others
</bodyText>
<equation confidence="0.99376025">
i
ptions
N-GRAM
uj
uj,
vk)
vk)
TRIPLE
vk, wl) uj, vk, wl
triple2(uj, vk,
gram1(uj)
j+1
gram2(uj) ujj+2
gram3(uj) uj
pair11(uj,vk)
vkpair12(uj,
uj,vk+1
kpair22(uj,
uj+1
j,vk+1
k
triple1(uj,
wl) uj, vk, wl+1
l
</equation>
<tableCaption confidence="0.9885895">
Table 4: Context predicates and their descri
(e.g., pair12(uj,uj+1) = trigram(uj) =
Table 3 represents the examples of feature func-
tions for
</tableCaption>
<bodyText confidence="0.7323165">
(eg, ep,
We used the
</bodyText>
<subsectionHeader confidence="0.579413">
Entropy Modeling
</subsectionHeader>
<bodyText confidence="0.99982">
to estimate the probabilities and the
LBFGS algorithm to find
in Eq. (14). For
each transliteration model, we produced n-best
transliterations using a stack decoder (Schwartz
an
</bodyText>
<equation confidence="0.987085">
uj+2
j ).
P(cgi|cgi−1
i−k,
cp)i+k
i−k).
“Maximum
Toolkit”4
λi
</equation>
<bodyText confidence="0.951041">
d Chow, 1990).
nese phonemes or the class of tran
sliteration mod-
els in our experiments.
</bodyText>
<sectionHeader confidence="0.939746" genericHeader="method">
4 Testing and Results
</sectionHeader>
<figure confidence="0.491333">
Category Context predicates Descri
ption
PAIR
</figure>
<subsectionHeader confidence="0.857297">
3.4 Summary
</subsectionHeader>
<bodyText confidence="0.87377">
In this paper, we defined eighteen transliteration
models to be compared. There are six translitera-
tion models, three basic and three hybrid ones, in
each class, MI, MS, and MJ. We compared the
transliteration models from the viewpoint of Chi-
We used the same test set used in Li et al. (2004)
for our
It contains 37,694 pairs of English
words and their official Chinese tran
testing5.
sliterations
</bodyText>
<footnote confidence="0.932856166666667">
4Available at
test set was also used in
machine translit-
eration shared
for English-to-Chinese tran
http://homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.html5This
</footnote>
<equation confidence="0.7443975">
“NEWS09
task”
sliteration (Li
et al., 2009)
�
P (EP |EG) ≈
</equation>
<page confidence="0.959793">
662
</page>
<bodyText confidence="0.999290666666667">
extracted from the “Chinese Transliteration of For-
eign Personal Names” (Xinhua News Agency,
1992), which includes names in English, French,
German, and many other foreign languages (Li et
al., 2004). We used the same test data as in Li et
al. (2004). But we randomly selected 90% of the
training data used in Li et al. (2004) as our training
data and the remainder as the development data, as
shown in Table 5.
</bodyText>
<tableCaption confidence="0.9267455">
Table 5: Number of English-Chinese translitera-
tion pairs in each data set
</tableCaption>
<table confidence="0.97974375">
Ours Li et al. (2004)
Training data 31,299 34,777
Development data 3,478 N/A
Blind test data 2,896 2,896
</table>
<bodyText confidence="0.99939528125">
We used the training data for training the
transliteration models. For each model, we tuned
the parameters including the number of iterations
for training the maximum entropy model and a
Gaussian prior for smoothing the maximum en-
tropy model using the development data. Further,
the development data was used to select param-
eter α of the hybrid transliteration models. We
varied parameter α from 0 to 1 in 0.1 intervals
(i.e., α=0, 0.1, 0.2, · · · ,1) and tested the perfor-
mance of the hybrid models with the development
data. Then we chose α that showed the best per-
formance in each hybrid model. The blind test
data was used for evaluating the performance of
each transliteration model. The CMU Pronounc-
ing Dictionary6, which contains about 120,000
English words and their pronunciations, was used
for estimating P(EP|EG).
We conducted two experiments. First, we com-
pared the overall performance of the translitera-
tion models. Second, we investigated the effect
of training data size on the performance of each
transliteration model.
The evaluation was done for word accuracy
in top-1 (ACC), Chinese pronunciation accuracy
(CPA) and a mean reciprocal rank (MRR) met-
ric (Kantor and Voorhees, 2000; Li et al., 2009;
Chang et al., 2009). ACC measures how many
correct transliterations appeared in the top-1 re-
sult of each system. CPA measures the Chinese
pronunciation accuracy in the top-1 of the n-best
Chinese pronunciation. We used CPA for com-
</bodyText>
<footnote confidence="0.78221">
6Available at http://www.speech.cs.cmu.edu/
cgi-bin/cmudict
</footnote>
<bodyText confidence="0.9995532">
paring the performance between systems based on
Chinese phonemes. MRR, mean reciprocal ranks
of n-best results of each system over the test en-
tries, is an evaluation measure for n-best translit-
erations. If a transliteration generated by a system
matches a reference transliteration7 at the rth posi-
tion of the n-best results, its reciprocal rank equals
1/r; otherwise its reciprocal rank equals 0, where
1 ≤ r ≤ n. We produced 10-best Chinese translit-
erations for each English word in our experiments.
</bodyText>
<subsectionHeader confidence="0.998829">
4.1 Comparison of the Overall Performance
</subsectionHeader>
<bodyText confidence="0.999537243243243">
Table 6 represents the overall performance of one
system in a previous work (Li et al., 2004) and
eighteen systems based on the transliteration mod-
els defined in this paper. ACC, MRR, and CPA
represent the evaluation results for each model
trained by our training data. To test transliteration
models without the errors introduced by incorrect
Chinese phonemes, we carried out the experiments
with the correct Chinese pronunciation (or the
correct Chinese phoneme sequence) in Chinese
phoneme-to-grapheme conversion. In the exper-
iment, we put the correct Chinese pronunciation
into the top-1 of the n-best Chinese pronunciation
with the highest probability, say P(CP|EG)=1;
thus CPA was assumed to be 100%. The ACC
of the transliteration models under this condition
is denoted as ACC’ in Table 6. TRAIN represents
the evaluation results of the transliteration mod-
els trained by our training data. To compare Li
et al. (2004) and transliteration models defined in
this paper under the same condition, we also car-
ried out experiments with the same training data
in Li et al. (2004). Since the training data used
in Li et al. (2004) is identical as the union of
our training and development data, we denoted it
as TRAIN+DEV in Table 6. In both TRAIN and
TRAIN+DEV, we used the same parameter setting
that was obtained by using the development data.
LI04 represents a system in Li et al. (2004),
and its ACC’ in TRAIN+DEV is taken from the
literature. The systems based on the translitera-
tion models defined in our paper are represented
from the second row in Table 6. The phoneme-
based transliteration models in the literature cor-
respond to either M(EG, CP) (Wan and Verspoor,
1998; Lee and Chang, 2003; Jiang et al., 2007) or
M(EP, CP) (Meng et al., 2001; Gao et al., 2004;
</bodyText>
<footnote confidence="0.977383">
7In our test set, an English word corresponds to one refer-
ence Chinese transliteration.
</footnote>
<page confidence="0.999121">
663
</page>
<tableCaption confidence="0.999659">
Table 6: Comparison of the overall performance
</tableCaption>
<table confidence="0.973713727272727">
Class Model TRAIN TRAIN+DEV
ACC MRR CPA ACC’ ACC MRR CPA ACC’
LI04 N/A N/A N/A N/A 70.1 N/A N/A N/A
M(EG, JCP) 71.9 80.4 72.3 88.2 72.3 80.7 73.1 88.9
M(EP, JCP) 61.1 70.3 62.4 82.8 61.1 70.6 63.1 83.8
MJ M(EGP, JCP) 72.3 80.9 73.2 89.6 73.5 81.5 73.9 90.4
M(EG+EP, JCP, 0.7) 72.8 80.7 73.8 89.7 73.2 81.0 74.7 90.5
M(EG+EGP, JCP, 0.6) 73.5 81.7 74.2 90.6 73.7 81.8 74.8 91.2
M(EP+EGP, JCP, 0.1) 71.6 80.3 73.3 89.8 72.5 80.8 73.8 90.1
M(EG, 0) 70.0 78.5 N/A N/A 70.6 79.0 N/A N/A
M(EP, 0) 58.5 69.3 N/A N/A 59.4 70.1 N/A N/A
MI M(EGP, 0) 71.2 79.9 N/A N/A 72.3 80.7 N/A N/A
M(EG+EP, 0, 0.7) 70.7 79.1 N/A N/A 72.0 80.0 N/A N/A
M(EG+EGP, 0, 0.4) 72.0 80.3 N/A N/A 72.8 80.9 N/A N/A
M(EP+EGP, 0, 0.1) 71.0 79.6 N/A N/A 72.0 80.4 N/A N/A
M(EG, CP) 58.9 70.2 72.3 78.4 59.1 70.4 73.1 78.4
M(EP, CP) 50.2 62.3 62.4 78.4 50.4 62.6 63.1 78.5
MS M(EGP, CP) 59.1 70.4 73.2 78.4 59.3 70.5 73.9 78.5
M(EG+EP, CP, 0.8) 59.7 71.3 73.8 79.0 60.3 71.7 74.7 79.0
M(EG+EGP, CP, 0.6) 59.8 71.7 74.2 78.9 60.6 72.1 74.8 78.9
M(EP+EGP, CP, 0.1) 58.8 70.4 73.3 78.9 59.4 70.7 73.8 78.8
Virga and Khudanpur, 2003).
</table>
<bodyText confidence="0.999793075471698">
A comparison between the basic and hybrid
transliteration models showed that the hybrid
ones usually performed better (the exception was
M(EP+EGP, y, α) but the performance still com-
parable to the basic ones in each class). Es-
pecially, the hybrid ones based on the best two
basic transliteration models, M(EG+EGP, y, α),
showed the best performance.
A comparison among the MI, MS, and
MJ models showed that Chinese phonemes did
contribute to the performance improvement of
English-to-Chinese transliteration when Chinese
phonemes were used together with their corre-
sponding English graphemes and phonemes in
Chinese phoneme-to-grapheme conversion. A
one-tail paired t-test between the MI and MJ
models showed that the results of the MJ mod-
els were always significantly better than those
of the MI models if the MI and MJ models
shared the same English-side parameter, x ∈
{EG, EP, EGP} (level of significance = 0.001).
In the results obtained by the MS and MJ mod-
els, the figures in CPA are the same when the MS
and our MJ models share the same English-side
parameter. Moreover, the difference between the
figures in ACC and CPA can be interpreted as
the error rate of Chinese phoneme-to-grapheme
conversion. Our proposed MJ models gener-
ated Chinese transliterations with a very low er-
ror rate in Chinese phoneme-to-grapheme conver-
sion, while the MS models suffered from a signif-
icant error rate in Chinese phoneme-to-grapheme
conversion. ACC’ showed that the MJ models
still outperformed the MS models even without
errors in generating Chinese pronunciation from
the English words. These results indicate that the
joint use of Chinese phonemes and their corre-
sponding English graphemes and phonemes sig-
nificantly improved the performance in Chinese
phoneme-to-grapheme conversion and English-to-
Chinese transliteration.
Table 7 shows the Chinese transliterations gen-
erated by M(EG, 0), M(EGP, 0), M(EG, JCP),
and M(EGP, JCP) where English or Chinese
phonemes contributed to the correct translitera-
tion. In this table, the first column show the
English words and their English phonemes, and
the second and third columns represent the Chi-
nese transliterations and their phonemes. Note
that the Chinese phonemes in the second and third
columns of the MI models are not used in translit-
eration. They are shown in the table to indicate
the difference in the Chinese phonemes of Chinese
</bodyText>
<page confidence="0.987849">
664
</page>
<figure confidence="0.990276176470588">
0.8
0.6
0.4
0.2
0
P(赖|Reinhardt) P(莱|Reinhardt)
(a) Probability distribution when Chi-
nese phonemes are not given
0.8
0.6
0.4
0.2
0
1
P(cg|Reinhardt, &amp;quot;LAI YIN ..&amp;quot;) P(cg|Reinhardt, &amp;quot;LAI NA ..&amp;quot;)
P(cg|Reinhardt, &amp;quot;LAI NEI ..&amp;quot;)
赖 莱
</figure>
<tableCaption confidence="0.942688">
Table 7: Top-1 results of M(EG, 0), M(EGP, 0),
</tableCaption>
<note confidence="0.471818">
M(EG, JCP), and M(EGP, JCP), where * rep-
</note>
<table confidence="0.918921705882353">
resents incorrect transliterations
MI models M(EG,φ) M(EGP,φ)
Emily 埃米利* 埃米利*
(EH M IH L IY) (AI MI LI) (AI MI LI)
Ivy 伊维* 艾维
(AY V IY) (YI WEI) (AI WEI)
Reinhardt 赖因哈特* 赖因哈特*
(R AI N HH AA R T) (LAI YIN HA TE) (LAI YIN HA TE)
MJ models M(EG,JCP) M(EGP,JCP)
Emily 埃米莉 埃米莉
(EH M IH L IY) AI MI LI AI MI LI
Ivy 伊维* 艾维
(AY V IY) YI WEI AI WEI
Reinhardt 莱因哈特 莱因哈特
(R AI N HH AA R T) LAI YIN HA TE LAI YIN HA TE
(b) Probability distribution when Chinese phonemes are
given
</table>
<bodyText confidence="0.97384864516129">
transliterations between the MI and MJ models.
For Emily and Reinhardt, the MJ models gen-
erated correct Chinese transliterations, but the MI
models did not. Figure 1 shows the probabil-
ity distribution when a transliteration model gen-
erates the first Chinese character in the Chinese
transliteration of Reinhardt with and without Chi-
nese phonemes. Two Chinese characters, V and
A, were strong candidates and A is the correct
one in this case. Without Chinese phonemes,
M(EG, 0), which is based on P(cglReinhardt)
in Figure 1(a) preferring 0 to A, generated the
incorrect transliteration as shown in Table 7. How-
ever, Figure 1(b) shows that A can be selected
if the correct Chinese phoneme sequence “LAI
YIN ...” is given. Three Chinese phoneme se-
quences starting with “LAI YIN ...”, “LAI NA
...”, and “LAI NEI ...” were generated from Rein-
hardt, where “LAI YIN ...” was the best Chinese
phoneme sequence based on the probability distri-
bution in Figure 1(c). As a result, M(EG, JCP),
which jointly used Chinese phonemes with En-
glish graphemes, generated the correct Chinese
transliteration of Reinhardt based on two probabil-
ity distribution in Figures 1(b) and 1(c). In the case
of Ivy, English phonemes contributed to generat-
ing the correct transliteration in the M(EGP, 0)
and M(EGP, JCP) models.
Chinese transliterations sometimes reflect the
English word’s pronunciation as well as the Chi-
nese character’s meaning (Li et al., 2007). Li
</bodyText>
<listItem confidence="0.4297895">
(c) Probability distribution for Chinese phoneme se-
quence “LAI YIN ...” and others
</listItem>
<figureCaption confidence="0.990283">
Figure 1: Probability distribution for the first Chi-
nese character in the Chinese transliteration of
Reinhardt: M(EG, 0) vs. M(EG, JCP)
</figureCaption>
<bodyText confidence="0.997296647058823">
et al. (2007) defined such a Chinese transliter-
ation as a phonetic-semantic transliteration (se-
mantic transliteration) to distinguish it from a
usual phonetic transliteration. One fact that
affects semantic transliteration is gender asso-
ciation (Li et al., 2007). For example, V1
(meaining jasmine) is frequently used in Chi-
nese transliterations of female names but sel-
dom in common person names. Because Emily
is often used in female names, the results ob-
tained by the M(EG, JCP) and M(EGP, JCP)
models are acceptable. This indicates that Chi-
nese phonemes coupled with English graphemes
or those coupled with English graphemes and
phonemes could provide evidence required for se-
mantic transliteration as well as phonetic translit-
eration. As a result, M(EGP, 0), M(EG, JCP),
</bodyText>
<figure confidence="0.997015857142857">
0.8
0.6
0.4
0.2
0
1
P(&amp;quot;LAI YIN ..&amp;quot;|Reinhardt) P(¬&amp;quot;LAI YIN ..&amp;quot;|Reinhardt)
</figure>
<page confidence="0.990494">
665
</page>
<bodyText confidence="0.99169825">
and M(EGP, JCP), which used phonemes cou-
pled with English graphemes, achieved higher per-
formance than M(EG, 0), which relied only on
English graphemes.
</bodyText>
<figure confidence="0.9838335">
Training Data Size (%)
(a) Basic transliteration models
Training Data Size (%)
(b) Hybrid transliteration models
</figure>
<figureCaption confidence="0.9920175">
Figure 2: Performance of each system with differ-
ent training data size
</figureCaption>
<bodyText confidence="0.999689434782609">
We investigated the effect of training data size
on the performance of each transliteration model.
We randomly selected training data with ratios
from 10 to 90% and compared the performance
of each system trained by different sizes of train-
ing data. The results for the basic translitera-
tion models in Figure 2(a) can be categorized into
three groups. M(EGP, 0) and M(EGP, JCP)
fall into the best group, where they showed the
best performance regardless of training data size.
M(EG, 0) and M(EG, JCP) belong to the mid-
dle group, where they showed lower performance
than the best group if the training data size is
small, but their performance is comparable to the
best group if the size of the training data is large
enough. The others always showed lower perfor-
mance than both the best and middle groups. Fig-
ure 2(b) shows that hybrid transliteration models,
on average, were less sensitive to the training data
size than the basic ones, because the two differ-
ent basic transliteration models used in the hybrid
ones boosted transliteration performance by com-
plementing each other’s weak points.
</bodyText>
<sectionHeader confidence="0.998709" genericHeader="evaluation">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999961521739131">
We proposed a new English-to-Chinese transliter-
ation model based on Chinese phonemes and their
corresponding English graphemes and phonemes.
We defined eighteen English-to-Chinese translit-
eration models including our proposed model and
classified them into three classes based on the role
of Chinese phonemes in the transliteration mod-
els. Experiments showed that Chinese phonemes
in our proposed model can contribute to the
performance improvement in English-to-Chinese
transliteration.
Now we can answer Yes to this paper’s key ques-
tion, “Can Chinese phonemes improve machine
transliteration?” Actually, this is the second time
the same question has been answered. The pre-
vious answer, which was unfortunately reported
as No by Li et al. (2004), has been accepted as
true for the last five years; the research issue has
been considered closed. In this paper, we found
a new answer that contradicts the previous an-
swer. We hope that our answer promotes research
on phoneme-based English-to-Chinese translitera-
tion.
</bodyText>
<sectionHeader confidence="0.632791" genericHeader="conclusions">
Appendix: Illustration of Basic
</sectionHeader>
<figure confidence="0.971378394736842">
Transliteration Models in MJ and MS
(c) MS models
4.2 Effect of Training Data Size
20 40 60 80
MRR
40
20
80
70
60
50
30
M(EG,φ)
M(EP,φ)
M(EGP,φ)
M(EG,CP)
M(EP,CP)
M(EGP,CP)
M(EG,JCP)
M(EP,JCP)
M(EGP,JCP)
20 40 60 80
MRR
40
80
70
60
50
30
M(EG+EP,φ,0.7)
M(EG+EGP,φ,0.4)
M(EP+EGP,φ,0.1)
M(EG+EP,CP,0.8)
M(EG+EGP,CP,0.6)
M(EP+EGP,CP,0.1)
M(EG+EP,JCP,0.7)
M(EG+EGP,JCP,0.6)
M(EP+EGP,JCP,0.1)
)
M(EGP,JCP
:
)
M(EG
,CP
M(EG,J CP
EG
CP
CG
M(EP,J CP
CP
CG
:
CP
CG
(a) MJ models
EG
CP
CG
M(EP,CP
CP
CG
M(EGP,CP
CP
CG
:
)
EG EP
EG EP
:
)
EG EP
:
)
EG EP
:
)
</figure>
<sectionHeader confidence="0.941367" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999859613636363">
Y. Al-Onaizan and Kevin Knight. 2002. Translating
named entities using monolingual and bilingual re-
sources. In Proc. ofACL ’02, pages 400–408.
A. L. Berger, S. D. Pietra, and V. J. D. Pietra. 1996. A
maximum entropy approach to natural language pro-
cessing. Computational Linguistics, 22(1):39–71.
M. Chang, D. Goldwasser, D. Roth, and Y. Tu. 2009.
Unsupervised constraint driven learning for translit-
eration discovery. In Proceedings of NAACL HLT’
09.
Wei Gao, Kam-Fai Wong, and Wai Lam. 2004.
Phoneme-based transliteration of foreign names for
OOV problem. In Proc. of IJCNLP 2004, pages
110–119.
Long Jiang, Ming Zhou, Lee-Feng Chien, and Cheng
Niu. 2007. Named entity translation with web min-
ing and transliteration. In Proc. of IJCAI ’07, pages
1629–1634.
Paul B. Kantor and Ellen M. Voorhees. 2000. The trec-
5 confusion track: Comparing retrieval methods for
scanned text. Information Retrieval, 2:165–176.
Sarvnaz Karimi, Falk Scholer, and Andrew Turpin.
2007. Collapsed consonant and vowel models: New
approaches for English-Persian transliteration and
back-transliteration. In Proceedings of ACL ’07,
pages 648–655.
Chun-Jen Lee and Jason S. Chang. 2003. Acqui-
sition of English-Chinese transliterated word pairs
from parallel-aligned texts using a statistical ma-
chine transliteration model. In Proc. ofHLT-NAACL
2003 Workshop on Building and Using Parallel
Texts, pages 96–103.
Haizhou Li, Min Zhang, and Su Jian. 2004. A joint
source-channel model for machine transliteration.
In Proceedings of the 42th Annual Meeting ofthe As-
sociation of Computational Linguistics, pages 160–
167.
Haizhou Li, Khe Chai Sim, Jin-Shea Kuo, and Minghui
Dong. 2007. Semantic transliteration of personal
names. In Proceedings of the 45th Annual Meeting
of the Association of Computational Linguistics.
Haizhou Li, A Kumaran, Min Zhang, and Vladimir
Pervouchine. 2009. Whitepaper of NEWS 2009
machine transliteration shared task. In Proc. of
ACL-IJCNLP 2009 Named Entities Workshop.
M.G. Abbas Malik. 2006. Punjabi machine translit-
eration. In Proceedings of the COLING/ACL 2006,
pages 1137–1144.
H.M. Meng, Wai-Kit Lo, Berlin Chen, and K. Tang.
2001. Generating phonetic cognates to handle
named entities in English-Chinese cross-language
spoken document retrieval. In Proc. of Auto-
matic Speech Recognition and Understanding, 2001.
ASRU ’01, pages 311–314.
Jong-Hoon Oh, Key-Sun Choi, and Hitoshi Isahara.
2006. A comparison of different machine transliter-
ation models. Journal of Artificial Intelligence Re-
search (JAIR), 27:119–151.
Adwait Ratnaparkhi. 1997. A linear observed time sta-
tistical parser based on maximal entropy models. In
Proceedings of the Second Conference on Empirical
Methods in Natural Language Processing, pages 1–
10.
Richard Schwartz and Yen-Lu Chow. 1990. The N-
Best algorithm: an efficient procedure for finding
top N sentence hypotheses. In Proc. ofICASSP ’90,
pages 81–84.
Tarek Sherif and Grzegorz Kondrak. 2007. Substring-
based transliteration. In Proceedings of ACL ’07,
pages 944–951.
Paola Virga and Sanjeev Khudanpur. 2003. Translit-
eration of proper names in cross-lingual information
retrieval. In Proc. ofACL 2003 Workshop on Multi-
lingual and Mixed-language Named Entity Recogni-
tion, pages 57–64.
Stephen Wan and Cornelia Maria Verspoor. 1998. Au-
tomatic English-Chinese name transliteration for de-
velopment of multilingual resources. In Proc. of
COLING ’98, pages 1352–1356.
Xinhua News Agency. 1992. Chinese transliteration
offoreign personal names. The Commercial Press.
Binyong Yin and Mary Felley. 1990. Chinese Roman-
ization: Pronunciation and Orthography. Sinolin-
gua.
Su-Youn Yoon, Kyoung-Young Kim, and Richard
Sproat. 2007. Multilingual transliteration using
feature based phonetic method. In Proceedings of
ACL’07, pages 112–119.
</reference>
<page confidence="0.997174">
667
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.665728">
<title confidence="0.9995425">Can Chinese Phonemes Improve Machine Transliteration?: A Comparative Study of English-to-Chinese Transliteration Models</title>
<author confidence="0.932631">Jong-Hoon Oh</author>
<author confidence="0.932631">Kiyotaka Uchimoto</author>
<author confidence="0.932631">Kentaro</author>
<affiliation confidence="0.973977">Language Infrastructure Group, MASTAR National Institute of Information and Communications Technology</affiliation>
<address confidence="0.951854">3-5 Hikaridai Seika-cho, Soraku-gun, Kyoto 619-0289</address>
<abstract confidence="0.9879994">Inspired by the success of English grapheme-to-phoneme research in speech synthesis, many researchers have proposed phoneme-based English-to-Chinese transliteration models. However, such approaches have severely suffered from the errors in Chinese phoneme-to-grapheme conversion. To address this we propose a new English-to-Chinese transliteration model and make systematic comparisons with the conventional models. Our proposed model relies on the joint use of Chinese phonemes and their corresponding English graphemes and phonemes. Experiments showed that Chinese phonemes in our proposed model can contribute to the performance improvement in English-to-Chinese transliteration.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Al-Onaizan</author>
<author>Kevin Knight</author>
</authors>
<title>Translating named entities using monolingual and bilingual resources.</title>
<date>2002</date>
<booktitle>In Proc. ofACL ’02,</booktitle>
<pages>400--408</pages>
<contexts>
<context position="13644" citStr="Al-Onaizan and Knight, 2002" startWordPosition="2220" endWordPosition="2223">dent of Chinese phonemes, they are the same as the transliteration models in the literature used for machine transliteration from English to other languages without relying on targetlanguage phonemes (Karimi et al., 2007; Malik, 2006; Oh et al., 2006; Sherif and Kondrak, 2007; Yoon et al., 2007). Note that M(EG, 0) is the same transliteration model as the one proposed by Li et al. (2004). 3.2 Hybrid Transliteration Models The hybrid transliteration models in each class are defined by discrete mixture between the probability distribution of the two basic transliteration models, as in Eq. (10) (Al-Onaizan and Knight, 2002; Oh et al., 2006), where 0 &lt; α &lt; 1. We denote a hybrid transliteration model between two basic transliteration models M(x1, y) and M(x2, y) as M(x1 + x2, y, α), where y E Y = {0, CP, JCP}, x1 =� x2, and x1, x2 E X = {EG, EP, EGP}. In this paper, we define three types of hybrid transliteration models in each class: M(EG + EP, y, α), M(EG + EGP, y, α), and M(EP + EGP, y, α). PM(x1+x2,y,α)(CG|EG) (10) = α x PM(x1,y)(CG|EG) + (1 − α) x PM(x2,y)(CG|EG) 3.3 Probability Estimation Because Eqs. (1)–(9) can be estimated in a similar way, we limit our focus to Eq. (3) in this section. Assuming that P(E</context>
</contexts>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Y. Al-Onaizan and Kevin Knight. 2002. Translating named entities using monolingual and bilingual resources. In Proc. ofACL ’02, pages 400–408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Berger</author>
<author>S D Pietra</author>
<author>V J D Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="15070" citStr="Berger et al., 1996" startWordPosition="2520" endWordPosition="2523">le in Table 2, where i = 2 f1 gram3(egi) egi+2 i = “ree” cgi = “ffl air c c c “G&amp;quot; c •B&amp;quot; c= &amp;quot;ffl:B” f2 p 11 7�i-1 � 9i-1 7�i-1 = , 9i-1 = gi — air c c ) c i = “GE L” c •B&amp;quot; c = &amp;quot; B” f3 p 12( gi-1 A-1 pi−1 — gi-1= gi — f4 pair22(cpi−1,cgi−2) egii−1 = “gr”, epi i−1 = “G R” cgi = “N:B” f5 triple1(egi, cpi, cgi−1) egi = “r”, cpi−1 = “GE”, c &amp;quot; •B&amp;quot; &amp;quot;N:B&amp;quot; gi-1= c gi = f6 triple2(egi−1, cgi−1, cpi−1) egi−1 = “g”, cpi i−1= “GE L”, cgi−1= “�:B” cgi = “~:B” they can be simplified into a series of products in Eqs. (11)–(13). The maximum entropy model is used to estimate the probabilities in Eqs. (11)–(13) (Berger et al., 1996). Generally, a conditional maximum entropy model is an exponential model that gives the conditional probability, as described in Eq. (14), where λi is the parameter to be estimated and fi(a, b) is a feature function corresponding to λi (Berger et al., 1996; Ratnaparkhi, 1997): P (epi|epi−1 i−k,egi+k i−k) (11) i P(CP |EG, EP) (12) � ≈P(cpi|cpi−1 i−k,�eg, ep�i+k i−k) i P(CG|EG, EP, CP) (13) � ≈P(cgi|cgi−1 i−k, (eg, ep, cp�i+k i−k) ) P(b a — exp(Ei λifi(a, b)) 14) l I — Eb&apos; exp(Ei λifi(a, b&apos;)) fi(a, b) is a binary function returning TRUE or FALSE based on context a and output b. If fi(a, b)=1, it</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>A. L. Berger, S. D. Pietra, and V. J. D. Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chang</author>
<author>D Goldwasser</author>
<author>D Roth</author>
<author>Y Tu</author>
</authors>
<title>Unsupervised constraint driven learning for transliteration discovery.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL HLT’ 09.</booktitle>
<contexts>
<context position="19751" citStr="Chang et al., 2009" startWordPosition="3294" endWordPosition="3297">a was used for evaluating the performance of each transliteration model. The CMU Pronouncing Dictionary6, which contains about 120,000 English words and their pronunciations, was used for estimating P(EP|EG). We conducted two experiments. First, we compared the overall performance of the transliteration models. Second, we investigated the effect of training data size on the performance of each transliteration model. The evaluation was done for word accuracy in top-1 (ACC), Chinese pronunciation accuracy (CPA) and a mean reciprocal rank (MRR) metric (Kantor and Voorhees, 2000; Li et al., 2009; Chang et al., 2009). ACC measures how many correct transliterations appeared in the top-1 result of each system. CPA measures the Chinese pronunciation accuracy in the top-1 of the n-best Chinese pronunciation. We used CPA for com6Available at http://www.speech.cs.cmu.edu/ cgi-bin/cmudict paring the performance between systems based on Chinese phonemes. MRR, mean reciprocal ranks of n-best results of each system over the test entries, is an evaluation measure for n-best transliterations. If a transliteration generated by a system matches a reference transliteration7 at the rth position of the n-best results, its</context>
</contexts>
<marker>Chang, Goldwasser, Roth, Tu, 2009</marker>
<rawString>M. Chang, D. Goldwasser, D. Roth, and Y. Tu. 2009. Unsupervised constraint driven learning for transliteration discovery. In Proceedings of NAACL HLT’ 09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Gao</author>
<author>Kam-Fai Wong</author>
<author>Wai Lam</author>
</authors>
<title>Phoneme-based transliteration of foreign names for OOV problem.</title>
<date>2004</date>
<booktitle>In Proc. of IJCNLP</booktitle>
<pages>110--119</pages>
<contexts>
<context position="1380" citStr="Gao et al., 2004" startWordPosition="175" endWordPosition="178">make systematic comparisons with the conventional models. Our proposed model relies on the joint use of Chinese phonemes and their corresponding English graphemes and phonemes. Experiments showed that Chinese phonemes in our proposed model can contribute to the performance improvement in English-to-Chinese transliteration. 1 Introduction 1.1 Motivation Transliteration, i.e., phonetic translation, is commonly used to translate proper names and technical terms across languages. A variety of Englishto-Chinese machine transliteration models has been proposed in the last decade (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Li et al., 2004; Li et al., 2007; Wan and Verspoor, 1998; Virga and Khudanpur, 2003). They can be categorized into those based on Chinese phonemes (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Wan and Verspoor, 1998; Virga and Khudanpur, 2003) and those that don’t rely on Chinese phonemes (Li et al., 2004; Li et al., 2007). Inspired by the success of English grapheme-tophoneme research in speech synthesis, many researchers have proposed phoneme-based Englishto-Chinese transliteration models. In these approaches, Chines</context>
<context position="12422" citStr="Gao et al., 2004" startWordPosition="2022" endWordPosition="2025"> as M(x, (x, CP)), English-side parameter x determines the English graphemes and phonemes, or both jointly used with Chinese phonemes in Chinese phoneme-to-grapheme conversion. Then we can represent the three basic transliteration models as in Eqs. (1)–(3), where P(CG|EG, CP), P(CG|EP, CP), and P(CG|EG, EP, CP) are the key points in our proposed models, MJ. The three basic transliteration models in MS – M(EG, CP), M(EP, CP), and M(EGP, CP) – are formulated as Eqs. (4)–(6). Chinese phonemebased transliteration models in the literature fall into either M(EG, CP) or M(EP, CP) (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Wan and Verspoor, 1998; Virga and Khudanpur, 2003). The three basic transliteration models in MS are identical as those in MJ, except for the Chinese phoneme-to-grapheme conversion method. They only depend on Chinese phonemes in Chinese phoneme-to-grapheme conversion represented as P(CG|CP) in Eqs. (4)–(6). PM(EG,O)(CG|EG) = P(CG|EG) (7) PM(EP ,O)(CG|EG) (8) �= P(EP |EG) x P(CG|EP) VEP PM(EGP ,O)(CG|EG) (9) �= P(EP|EG) x P(CG|EG,EP) VEP The three basic transliteration models in MI are represented in Eqs. (7)–(9). Because the MI models are independent </context>
<context position="22335" citStr="Gao et al., 2004" startWordPosition="3718" endWordPosition="3721">on of our training and development data, we denoted it as TRAIN+DEV in Table 6. In both TRAIN and TRAIN+DEV, we used the same parameter setting that was obtained by using the development data. LI04 represents a system in Li et al. (2004), and its ACC’ in TRAIN+DEV is taken from the literature. The systems based on the transliteration models defined in our paper are represented from the second row in Table 6. The phonemebased transliteration models in the literature correspond to either M(EG, CP) (Wan and Verspoor, 1998; Lee and Chang, 2003; Jiang et al., 2007) or M(EP, CP) (Meng et al., 2001; Gao et al., 2004; 7In our test set, an English word corresponds to one reference Chinese transliteration. 663 Table 6: Comparison of the overall performance Class Model TRAIN TRAIN+DEV ACC MRR CPA ACC’ ACC MRR CPA ACC’ LI04 N/A N/A N/A N/A 70.1 N/A N/A N/A M(EG, JCP) 71.9 80.4 72.3 88.2 72.3 80.7 73.1 88.9 M(EP, JCP) 61.1 70.3 62.4 82.8 61.1 70.6 63.1 83.8 MJ M(EGP, JCP) 72.3 80.9 73.2 89.6 73.5 81.5 73.9 90.4 M(EG+EP, JCP, 0.7) 72.8 80.7 73.8 89.7 73.2 81.0 74.7 90.5 M(EG+EGP, JCP, 0.6) 73.5 81.7 74.2 90.6 73.7 81.8 74.8 91.2 M(EP+EGP, JCP, 0.1) 71.6 80.3 73.3 89.8 72.5 80.8 73.8 90.1 M(EG, 0) 70.0 78.5 N/A </context>
</contexts>
<marker>Gao, Wong, Lam, 2004</marker>
<rawString>Wei Gao, Kam-Fai Wong, and Wai Lam. 2004. Phoneme-based transliteration of foreign names for OOV problem. In Proc. of IJCNLP 2004, pages 110–119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Jiang</author>
<author>Ming Zhou</author>
<author>Lee-Feng Chien</author>
<author>Cheng Niu</author>
</authors>
<title>Named entity translation with web mining and transliteration.</title>
<date>2007</date>
<booktitle>In Proc. of IJCAI ’07,</booktitle>
<pages>1629--1634</pages>
<contexts>
<context position="1400" citStr="Jiang et al., 2007" startWordPosition="179" endWordPosition="182">mparisons with the conventional models. Our proposed model relies on the joint use of Chinese phonemes and their corresponding English graphemes and phonemes. Experiments showed that Chinese phonemes in our proposed model can contribute to the performance improvement in English-to-Chinese transliteration. 1 Introduction 1.1 Motivation Transliteration, i.e., phonetic translation, is commonly used to translate proper names and technical terms across languages. A variety of Englishto-Chinese machine transliteration models has been proposed in the last decade (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Li et al., 2004; Li et al., 2007; Wan and Verspoor, 1998; Virga and Khudanpur, 2003). They can be categorized into those based on Chinese phonemes (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Wan and Verspoor, 1998; Virga and Khudanpur, 2003) and those that don’t rely on Chinese phonemes (Li et al., 2004; Li et al., 2007). Inspired by the success of English grapheme-tophoneme research in speech synthesis, many researchers have proposed phoneme-based Englishto-Chinese transliteration models. In these approaches, Chinese phonemes are gener</context>
<context position="12442" citStr="Jiang et al., 2007" startWordPosition="2026" endWordPosition="2029"> English-side parameter x determines the English graphemes and phonemes, or both jointly used with Chinese phonemes in Chinese phoneme-to-grapheme conversion. Then we can represent the three basic transliteration models as in Eqs. (1)–(3), where P(CG|EG, CP), P(CG|EP, CP), and P(CG|EG, EP, CP) are the key points in our proposed models, MJ. The three basic transliteration models in MS – M(EG, CP), M(EP, CP), and M(EGP, CP) – are formulated as Eqs. (4)–(6). Chinese phonemebased transliteration models in the literature fall into either M(EG, CP) or M(EP, CP) (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Wan and Verspoor, 1998; Virga and Khudanpur, 2003). The three basic transliteration models in MS are identical as those in MJ, except for the Chinese phoneme-to-grapheme conversion method. They only depend on Chinese phonemes in Chinese phoneme-to-grapheme conversion represented as P(CG|CP) in Eqs. (4)–(6). PM(EG,O)(CG|EG) = P(CG|EG) (7) PM(EP ,O)(CG|EG) (8) �= P(EP |EG) x P(CG|EP) VEP PM(EGP ,O)(CG|EG) (9) �= P(EP|EG) x P(CG|EG,EP) VEP The three basic transliteration models in MI are represented in Eqs. (7)–(9). Because the MI models are independent of Chinese phonemes,</context>
<context position="22285" citStr="Jiang et al., 2007" startWordPosition="3707" endWordPosition="3710">data used in Li et al. (2004) is identical as the union of our training and development data, we denoted it as TRAIN+DEV in Table 6. In both TRAIN and TRAIN+DEV, we used the same parameter setting that was obtained by using the development data. LI04 represents a system in Li et al. (2004), and its ACC’ in TRAIN+DEV is taken from the literature. The systems based on the transliteration models defined in our paper are represented from the second row in Table 6. The phonemebased transliteration models in the literature correspond to either M(EG, CP) (Wan and Verspoor, 1998; Lee and Chang, 2003; Jiang et al., 2007) or M(EP, CP) (Meng et al., 2001; Gao et al., 2004; 7In our test set, an English word corresponds to one reference Chinese transliteration. 663 Table 6: Comparison of the overall performance Class Model TRAIN TRAIN+DEV ACC MRR CPA ACC’ ACC MRR CPA ACC’ LI04 N/A N/A N/A N/A 70.1 N/A N/A N/A M(EG, JCP) 71.9 80.4 72.3 88.2 72.3 80.7 73.1 88.9 M(EP, JCP) 61.1 70.3 62.4 82.8 61.1 70.6 63.1 83.8 MJ M(EGP, JCP) 72.3 80.9 73.2 89.6 73.5 81.5 73.9 90.4 M(EG+EP, JCP, 0.7) 72.8 80.7 73.8 89.7 73.2 81.0 74.7 90.5 M(EG+EGP, JCP, 0.6) 73.5 81.7 74.2 90.6 73.7 81.8 74.8 91.2 M(EP+EGP, JCP, 0.1) 71.6 80.3 73.</context>
</contexts>
<marker>Jiang, Zhou, Chien, Niu, 2007</marker>
<rawString>Long Jiang, Ming Zhou, Lee-Feng Chien, and Cheng Niu. 2007. Named entity translation with web mining and transliteration. In Proc. of IJCAI ’07, pages 1629–1634.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul B Kantor</author>
<author>Ellen M Voorhees</author>
</authors>
<title>The trec5 confusion track: Comparing retrieval methods for scanned text. Information Retrieval,</title>
<date>2000</date>
<pages>2--165</pages>
<contexts>
<context position="19713" citStr="Kantor and Voorhees, 2000" startWordPosition="3286" endWordPosition="3289">nce in each hybrid model. The blind test data was used for evaluating the performance of each transliteration model. The CMU Pronouncing Dictionary6, which contains about 120,000 English words and their pronunciations, was used for estimating P(EP|EG). We conducted two experiments. First, we compared the overall performance of the transliteration models. Second, we investigated the effect of training data size on the performance of each transliteration model. The evaluation was done for word accuracy in top-1 (ACC), Chinese pronunciation accuracy (CPA) and a mean reciprocal rank (MRR) metric (Kantor and Voorhees, 2000; Li et al., 2009; Chang et al., 2009). ACC measures how many correct transliterations appeared in the top-1 result of each system. CPA measures the Chinese pronunciation accuracy in the top-1 of the n-best Chinese pronunciation. We used CPA for com6Available at http://www.speech.cs.cmu.edu/ cgi-bin/cmudict paring the performance between systems based on Chinese phonemes. MRR, mean reciprocal ranks of n-best results of each system over the test entries, is an evaluation measure for n-best transliterations. If a transliteration generated by a system matches a reference transliteration7 at the r</context>
</contexts>
<marker>Kantor, Voorhees, 2000</marker>
<rawString>Paul B. Kantor and Ellen M. Voorhees. 2000. The trec5 confusion track: Comparing retrieval methods for scanned text. Information Retrieval, 2:165–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarvnaz Karimi</author>
<author>Falk Scholer</author>
<author>Andrew Turpin</author>
</authors>
<title>Collapsed consonant and vowel models: New approaches for English-Persian transliteration and back-transliteration.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL ’07,</booktitle>
<pages>648--655</pages>
<contexts>
<context position="13237" citStr="Karimi et al., 2007" startWordPosition="2152" endWordPosition="2155">neme-to-grapheme conversion method. They only depend on Chinese phonemes in Chinese phoneme-to-grapheme conversion represented as P(CG|CP) in Eqs. (4)–(6). PM(EG,O)(CG|EG) = P(CG|EG) (7) PM(EP ,O)(CG|EG) (8) �= P(EP |EG) x P(CG|EP) VEP PM(EGP ,O)(CG|EG) (9) �= P(EP|EG) x P(CG|EG,EP) VEP The three basic transliteration models in MI are represented in Eqs. (7)–(9). Because the MI models are independent of Chinese phonemes, they are the same as the transliteration models in the literature used for machine transliteration from English to other languages without relying on targetlanguage phonemes (Karimi et al., 2007; Malik, 2006; Oh et al., 2006; Sherif and Kondrak, 2007; Yoon et al., 2007). Note that M(EG, 0) is the same transliteration model as the one proposed by Li et al. (2004). 3.2 Hybrid Transliteration Models The hybrid transliteration models in each class are defined by discrete mixture between the probability distribution of the two basic transliteration models, as in Eq. (10) (Al-Onaizan and Knight, 2002; Oh et al., 2006), where 0 &lt; α &lt; 1. We denote a hybrid transliteration model between two basic transliteration models M(x1, y) and M(x2, y) as M(x1 + x2, y, α), where y E Y = {0, CP, JCP}, x1 </context>
</contexts>
<marker>Karimi, Scholer, Turpin, 2007</marker>
<rawString>Sarvnaz Karimi, Falk Scholer, and Andrew Turpin. 2007. Collapsed consonant and vowel models: New approaches for English-Persian transliteration and back-transliteration. In Proceedings of ACL ’07, pages 648–655.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chun-Jen Lee</author>
<author>Jason S Chang</author>
</authors>
<title>Acquisition of English-Chinese transliterated word pairs from parallel-aligned texts using a statistical machine transliteration model.</title>
<date>2003</date>
<booktitle>In Proc. ofHLT-NAACL 2003 Workshop on Building and Using Parallel Texts,</booktitle>
<pages>96--103</pages>
<contexts>
<context position="1421" citStr="Lee and Chang, 2003" startWordPosition="183" endWordPosition="186">onventional models. Our proposed model relies on the joint use of Chinese phonemes and their corresponding English graphemes and phonemes. Experiments showed that Chinese phonemes in our proposed model can contribute to the performance improvement in English-to-Chinese transliteration. 1 Introduction 1.1 Motivation Transliteration, i.e., phonetic translation, is commonly used to translate proper names and technical terms across languages. A variety of Englishto-Chinese machine transliteration models has been proposed in the last decade (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Li et al., 2004; Li et al., 2007; Wan and Verspoor, 1998; Virga and Khudanpur, 2003). They can be categorized into those based on Chinese phonemes (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Wan and Verspoor, 1998; Virga and Khudanpur, 2003) and those that don’t rely on Chinese phonemes (Li et al., 2004; Li et al., 2007). Inspired by the success of English grapheme-tophoneme research in speech synthesis, many researchers have proposed phoneme-based Englishto-Chinese transliteration models. In these approaches, Chinese phonemes are generated from English gra</context>
<context position="12463" citStr="Lee and Chang, 2003" startWordPosition="2030" endWordPosition="2033">ter x determines the English graphemes and phonemes, or both jointly used with Chinese phonemes in Chinese phoneme-to-grapheme conversion. Then we can represent the three basic transliteration models as in Eqs. (1)–(3), where P(CG|EG, CP), P(CG|EP, CP), and P(CG|EG, EP, CP) are the key points in our proposed models, MJ. The three basic transliteration models in MS – M(EG, CP), M(EP, CP), and M(EGP, CP) – are formulated as Eqs. (4)–(6). Chinese phonemebased transliteration models in the literature fall into either M(EG, CP) or M(EP, CP) (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Wan and Verspoor, 1998; Virga and Khudanpur, 2003). The three basic transliteration models in MS are identical as those in MJ, except for the Chinese phoneme-to-grapheme conversion method. They only depend on Chinese phonemes in Chinese phoneme-to-grapheme conversion represented as P(CG|CP) in Eqs. (4)–(6). PM(EG,O)(CG|EG) = P(CG|EG) (7) PM(EP ,O)(CG|EG) (8) �= P(EP |EG) x P(CG|EP) VEP PM(EGP ,O)(CG|EG) (9) �= P(EP|EG) x P(CG|EG,EP) VEP The three basic transliteration models in MI are represented in Eqs. (7)–(9). Because the MI models are independent of Chinese phonemes, they are the same as</context>
<context position="22264" citStr="Lee and Chang, 2003" startWordPosition="3703" endWordPosition="3706">. Since the training data used in Li et al. (2004) is identical as the union of our training and development data, we denoted it as TRAIN+DEV in Table 6. In both TRAIN and TRAIN+DEV, we used the same parameter setting that was obtained by using the development data. LI04 represents a system in Li et al. (2004), and its ACC’ in TRAIN+DEV is taken from the literature. The systems based on the transliteration models defined in our paper are represented from the second row in Table 6. The phonemebased transliteration models in the literature correspond to either M(EG, CP) (Wan and Verspoor, 1998; Lee and Chang, 2003; Jiang et al., 2007) or M(EP, CP) (Meng et al., 2001; Gao et al., 2004; 7In our test set, an English word corresponds to one reference Chinese transliteration. 663 Table 6: Comparison of the overall performance Class Model TRAIN TRAIN+DEV ACC MRR CPA ACC’ ACC MRR CPA ACC’ LI04 N/A N/A N/A N/A 70.1 N/A N/A N/A M(EG, JCP) 71.9 80.4 72.3 88.2 72.3 80.7 73.1 88.9 M(EP, JCP) 61.1 70.3 62.4 82.8 61.1 70.6 63.1 83.8 MJ M(EGP, JCP) 72.3 80.9 73.2 89.6 73.5 81.5 73.9 90.4 M(EG+EP, JCP, 0.7) 72.8 80.7 73.8 89.7 73.2 81.0 74.7 90.5 M(EG+EGP, JCP, 0.6) 73.5 81.7 74.2 90.6 73.7 81.8 74.8 91.2 M(EP+EGP, JC</context>
</contexts>
<marker>Lee, Chang, 2003</marker>
<rawString>Chun-Jen Lee and Jason S. Chang. 2003. Acquisition of English-Chinese transliterated word pairs from parallel-aligned texts using a statistical machine transliteration model. In Proc. ofHLT-NAACL 2003 Workshop on Building and Using Parallel Texts, pages 96–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haizhou Li</author>
<author>Min Zhang</author>
<author>Su Jian</author>
</authors>
<title>A joint source-channel model for machine transliteration.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42th Annual Meeting ofthe Association of Computational Linguistics,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="1438" citStr="Li et al., 2004" startWordPosition="187" endWordPosition="190">ur proposed model relies on the joint use of Chinese phonemes and their corresponding English graphemes and phonemes. Experiments showed that Chinese phonemes in our proposed model can contribute to the performance improvement in English-to-Chinese transliteration. 1 Introduction 1.1 Motivation Transliteration, i.e., phonetic translation, is commonly used to translate proper names and technical terms across languages. A variety of Englishto-Chinese machine transliteration models has been proposed in the last decade (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Li et al., 2004; Li et al., 2007; Wan and Verspoor, 1998; Virga and Khudanpur, 2003). They can be categorized into those based on Chinese phonemes (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Wan and Verspoor, 1998; Virga and Khudanpur, 2003) and those that don’t rely on Chinese phonemes (Li et al., 2004; Li et al., 2007). Inspired by the success of English grapheme-tophoneme research in speech synthesis, many researchers have proposed phoneme-based Englishto-Chinese transliteration models. In these approaches, Chinese phonemes are generated from English graphemes or phoneme</context>
<context position="2784" citStr="Li et al., 2004" startWordPosition="397" endWordPosition="400">representing a syllable-level Chinese phoneme sequence. Despite its high accuracy in generating Chinese phonemes from English, this approach has severely suffered from errors in Chinese phoneme-to-grapheme conversion, mainly caused by Chinese homophone confusion – one Chinese Pinyin string can correspond to several Chinese characters (Li et al., 2004). For example, the Pinyin string “LI” corresponds to such different Chinese characters as fg, V1, and �. For this reason, it has been reported that English-toChinese transliteration without Chinese phonemes outperforms that with Chinese phonemes (Li et al., 2004). Then “Can Chinese phonemes improve English-to-Chinese transliteration, if we can reduce the errors in Chinese phoneme-to-grapheme conversion?” Our research starts from this question. 1.2 Our Approach Previous approaches using Chinese phonemes have relied only on Chinese phonemes in Chinese phoneme-to-grapheme conversion. However, the simple use of Chinese phonemes doesn’t always provide a good clue to reduce the ambiguity in Chinese phoneme-to-grapheme conversion. Let us explain with an example, the Chinese transliteration of Greeley in Table 1, where Chinese phonemes are represented in term</context>
<context position="9320" citStr="Li et al. (2004)" startWordPosition="1495" endWordPosition="1498">flfIJ”)3, where represents an empty string. 3 Transliteration Model We defined eighteen transliteration models to be compared. These transliteration models are classified into three classes, MI, MS, and M,I as described in Section 1.2; each class has three basic transliteration models and three hybrid ones. In this section, we first describe the basic transliteration models in each class by focusing on the main difference among the three classes and then describe the hybrid transliteration models. 3We performed alignment between EG and EP and between EP and CP in a similar manner presented in Li et al. (2004). Then the two alignment results were merged using EP as a pivot. Finally, we made a correspondence relation among egi, epi, cpi, and cgi using the merged alignment result and the Pinyin table. • (x, y) E X x Y • x E X = tEG, EP, EGP} • y E Y = t , CP, JCP} x is an English-side parameter representing English grapheme (EG), English phoneme (EP), and the joint use of English grapheme and phoneme (EGP = (EG, EP)) that contributes to generating Chinese phonemes or Chinese graphemes in a transliteration model. y is a Chinese-phoneme parameter that represents a way of using Chinese phonemes to gener</context>
<context position="13407" citStr="Li et al. (2004)" startWordPosition="2184" endWordPosition="2187"> P(CG|EG) (7) PM(EP ,O)(CG|EG) (8) �= P(EP |EG) x P(CG|EP) VEP PM(EGP ,O)(CG|EG) (9) �= P(EP|EG) x P(CG|EG,EP) VEP The three basic transliteration models in MI are represented in Eqs. (7)–(9). Because the MI models are independent of Chinese phonemes, they are the same as the transliteration models in the literature used for machine transliteration from English to other languages without relying on targetlanguage phonemes (Karimi et al., 2007; Malik, 2006; Oh et al., 2006; Sherif and Kondrak, 2007; Yoon et al., 2007). Note that M(EG, 0) is the same transliteration model as the one proposed by Li et al. (2004). 3.2 Hybrid Transliteration Models The hybrid transliteration models in each class are defined by discrete mixture between the probability distribution of the two basic transliteration models, as in Eq. (10) (Al-Onaizan and Knight, 2002; Oh et al., 2006), where 0 &lt; α &lt; 1. We denote a hybrid transliteration model between two basic transliteration models M(x1, y) and M(x2, y) as M(x1 + x2, y, α), where y E Y = {0, CP, JCP}, x1 =� x2, and x1, x2 E X = {EG, EP, EGP}. In this paper, we define three types of hybrid transliteration models in each class: M(EG + EP, y, α), M(EG + EGP, y, α), and M(EP </context>
<context position="17594" citStr="Li et al. (2004)" startWordPosition="2942" endWordPosition="2945">ransliteration model, we produced n-best transliterations using a stack decoder (Schwartz an uj+2 j ). P(cgi|cgi−1 i−k, cp)i+k i−k). “Maximum Toolkit”4 λi d Chow, 1990). nese phonemes or the class of tran sliteration models in our experiments. 4 Testing and Results Category Context predicates Descri ption PAIR 3.4 Summary In this paper, we defined eighteen transliteration models to be compared. There are six transliteration models, three basic and three hybrid ones, in each class, MI, MS, and MJ. We compared the transliteration models from the viewpoint of ChiWe used the same test set used in Li et al. (2004) for our It contains 37,694 pairs of English words and their official Chinese tran testing5. sliterations 4Available at test set was also used in machine transliteration shared for English-to-Chinese tran http://homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.html5This “NEWS09 task” sliteration (Li et al., 2009) � P (EP |EG) ≈ 662 extracted from the “Chinese Transliteration of Foreign Personal Names” (Xinhua News Agency, 1992), which includes names in English, French, German, and many other foreign languages (Li et al., 2004). We used the same test data as in Li et al. (2004). But we randomly s</context>
<context position="20659" citStr="Li et al., 2004" startWordPosition="3437" endWordPosition="3440">e between systems based on Chinese phonemes. MRR, mean reciprocal ranks of n-best results of each system over the test entries, is an evaluation measure for n-best transliterations. If a transliteration generated by a system matches a reference transliteration7 at the rth position of the n-best results, its reciprocal rank equals 1/r; otherwise its reciprocal rank equals 0, where 1 ≤ r ≤ n. We produced 10-best Chinese transliterations for each English word in our experiments. 4.1 Comparison of the Overall Performance Table 6 represents the overall performance of one system in a previous work (Li et al., 2004) and eighteen systems based on the transliteration models defined in this paper. ACC, MRR, and CPA represent the evaluation results for each model trained by our training data. To test transliteration models without the errors introduced by incorrect Chinese phonemes, we carried out the experiments with the correct Chinese pronunciation (or the correct Chinese phoneme sequence) in Chinese phoneme-to-grapheme conversion. In the experiment, we put the correct Chinese pronunciation into the top-1 of the n-best Chinese pronunciation with the highest probability, say P(CP|EG)=1; thus CPA was assume</context>
<context position="21956" citStr="Li et al. (2004)" startWordPosition="3650" endWordPosition="3653">ed as ACC’ in Table 6. TRAIN represents the evaluation results of the transliteration models trained by our training data. To compare Li et al. (2004) and transliteration models defined in this paper under the same condition, we also carried out experiments with the same training data in Li et al. (2004). Since the training data used in Li et al. (2004) is identical as the union of our training and development data, we denoted it as TRAIN+DEV in Table 6. In both TRAIN and TRAIN+DEV, we used the same parameter setting that was obtained by using the development data. LI04 represents a system in Li et al. (2004), and its ACC’ in TRAIN+DEV is taken from the literature. The systems based on the transliteration models defined in our paper are represented from the second row in Table 6. The phonemebased transliteration models in the literature correspond to either M(EG, CP) (Wan and Verspoor, 1998; Lee and Chang, 2003; Jiang et al., 2007) or M(EP, CP) (Meng et al., 2001; Gao et al., 2004; 7In our test set, an English word corresponds to one reference Chinese transliteration. 663 Table 6: Comparison of the overall performance Class Model TRAIN TRAIN+DEV ACC MRR CPA ACC’ ACC MRR CPA ACC’ LI04 N/A N/A N/A N</context>
<context position="31437" citStr="Li et al. (2004)" startWordPosition="5245" endWordPosition="5248"> phonemes. We defined eighteen English-to-Chinese transliteration models including our proposed model and classified them into three classes based on the role of Chinese phonemes in the transliteration models. Experiments showed that Chinese phonemes in our proposed model can contribute to the performance improvement in English-to-Chinese transliteration. Now we can answer Yes to this paper’s key question, “Can Chinese phonemes improve machine transliteration?” Actually, this is the second time the same question has been answered. The previous answer, which was unfortunately reported as No by Li et al. (2004), has been accepted as true for the last five years; the research issue has been considered closed. In this paper, we found a new answer that contradicts the previous answer. We hope that our answer promotes research on phoneme-based English-to-Chinese transliteration. Appendix: Illustration of Basic Transliteration Models in MJ and MS (c) MS models 4.2 Effect of Training Data Size 20 40 60 80 MRR 40 20 80 70 60 50 30 M(EG,φ) M(EP,φ) M(EGP,φ) M(EG,CP) M(EP,CP) M(EGP,CP) M(EG,JCP) M(EP,JCP) M(EGP,JCP) 20 40 60 80 MRR 40 80 70 60 50 30 M(EG+EP,φ,0.7) M(EG+EGP,φ,0.4) M(EP+EGP,φ,0.1) M(EG+EP,CP,0.</context>
</contexts>
<marker>Li, Zhang, Jian, 2004</marker>
<rawString>Haizhou Li, Min Zhang, and Su Jian. 2004. A joint source-channel model for machine transliteration. In Proceedings of the 42th Annual Meeting ofthe Association of Computational Linguistics, pages 160– 167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haizhou Li</author>
<author>Khe Chai Sim</author>
<author>Jin-Shea Kuo</author>
<author>Minghui Dong</author>
</authors>
<title>Semantic transliteration of personal names.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics.</booktitle>
<contexts>
<context position="1455" citStr="Li et al., 2007" startWordPosition="191" endWordPosition="194"> relies on the joint use of Chinese phonemes and their corresponding English graphemes and phonemes. Experiments showed that Chinese phonemes in our proposed model can contribute to the performance improvement in English-to-Chinese transliteration. 1 Introduction 1.1 Motivation Transliteration, i.e., phonetic translation, is commonly used to translate proper names and technical terms across languages. A variety of Englishto-Chinese machine transliteration models has been proposed in the last decade (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Li et al., 2004; Li et al., 2007; Wan and Verspoor, 1998; Virga and Khudanpur, 2003). They can be categorized into those based on Chinese phonemes (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Wan and Verspoor, 1998; Virga and Khudanpur, 2003) and those that don’t rely on Chinese phonemes (Li et al., 2004; Li et al., 2007). Inspired by the success of English grapheme-tophoneme research in speech synthesis, many researchers have proposed phoneme-based Englishto-Chinese transliteration models. In these approaches, Chinese phonemes are generated from English graphemes or phonemes, and then the C</context>
<context position="28169" citStr="Li et al., 2007" startWordPosition="4728" endWordPosition="4731">e generated from Reinhardt, where “LAI YIN ...” was the best Chinese phoneme sequence based on the probability distribution in Figure 1(c). As a result, M(EG, JCP), which jointly used Chinese phonemes with English graphemes, generated the correct Chinese transliteration of Reinhardt based on two probability distribution in Figures 1(b) and 1(c). In the case of Ivy, English phonemes contributed to generating the correct transliteration in the M(EGP, 0) and M(EGP, JCP) models. Chinese transliterations sometimes reflect the English word’s pronunciation as well as the Chinese character’s meaning (Li et al., 2007). Li (c) Probability distribution for Chinese phoneme sequence “LAI YIN ...” and others Figure 1: Probability distribution for the first Chinese character in the Chinese transliteration of Reinhardt: M(EG, 0) vs. M(EG, JCP) et al. (2007) defined such a Chinese transliteration as a phonetic-semantic transliteration (semantic transliteration) to distinguish it from a usual phonetic transliteration. One fact that affects semantic transliteration is gender association (Li et al., 2007). For example, V1 (meaining jasmine) is frequently used in Chinese transliterations of female names but seldom in </context>
</contexts>
<marker>Li, Sim, Kuo, Dong, 2007</marker>
<rawString>Haizhou Li, Khe Chai Sim, Jin-Shea Kuo, and Minghui Dong. 2007. Semantic transliteration of personal names. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haizhou Li</author>
<author>A Kumaran</author>
<author>Min Zhang</author>
<author>Vladimir Pervouchine</author>
</authors>
<title>machine transliteration shared task.</title>
<date>2009</date>
<journal>Whitepaper of NEWS</journal>
<booktitle>In Proc. of ACL-IJCNLP 2009 Named Entities Workshop.</booktitle>
<contexts>
<context position="17906" citStr="Li et al., 2009" startWordPosition="2981" endWordPosition="2984">3.4 Summary In this paper, we defined eighteen transliteration models to be compared. There are six transliteration models, three basic and three hybrid ones, in each class, MI, MS, and MJ. We compared the transliteration models from the viewpoint of ChiWe used the same test set used in Li et al. (2004) for our It contains 37,694 pairs of English words and their official Chinese tran testing5. sliterations 4Available at test set was also used in machine transliteration shared for English-to-Chinese tran http://homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.html5This “NEWS09 task” sliteration (Li et al., 2009) � P (EP |EG) ≈ 662 extracted from the “Chinese Transliteration of Foreign Personal Names” (Xinhua News Agency, 1992), which includes names in English, French, German, and many other foreign languages (Li et al., 2004). We used the same test data as in Li et al. (2004). But we randomly selected 90% of the training data used in Li et al. (2004) as our training data and the remainder as the development data, as shown in Table 5. Table 5: Number of English-Chinese transliteration pairs in each data set Ours Li et al. (2004) Training data 31,299 34,777 Development data 3,478 N/A Blind test data 2,</context>
<context position="19730" citStr="Li et al., 2009" startWordPosition="3290" endWordPosition="3293">he blind test data was used for evaluating the performance of each transliteration model. The CMU Pronouncing Dictionary6, which contains about 120,000 English words and their pronunciations, was used for estimating P(EP|EG). We conducted two experiments. First, we compared the overall performance of the transliteration models. Second, we investigated the effect of training data size on the performance of each transliteration model. The evaluation was done for word accuracy in top-1 (ACC), Chinese pronunciation accuracy (CPA) and a mean reciprocal rank (MRR) metric (Kantor and Voorhees, 2000; Li et al., 2009; Chang et al., 2009). ACC measures how many correct transliterations appeared in the top-1 result of each system. CPA measures the Chinese pronunciation accuracy in the top-1 of the n-best Chinese pronunciation. We used CPA for com6Available at http://www.speech.cs.cmu.edu/ cgi-bin/cmudict paring the performance between systems based on Chinese phonemes. MRR, mean reciprocal ranks of n-best results of each system over the test entries, is an evaluation measure for n-best transliterations. If a transliteration generated by a system matches a reference transliteration7 at the rth position of th</context>
</contexts>
<marker>Li, Kumaran, Zhang, Pervouchine, 2009</marker>
<rawString>Haizhou Li, A Kumaran, Min Zhang, and Vladimir Pervouchine. 2009. Whitepaper of NEWS 2009 machine transliteration shared task. In Proc. of ACL-IJCNLP 2009 Named Entities Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M G Abbas Malik</author>
</authors>
<title>Punjabi machine transliteration.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL</booktitle>
<pages>1137--1144</pages>
<contexts>
<context position="13250" citStr="Malik, 2006" startWordPosition="2156" endWordPosition="2157">ersion method. They only depend on Chinese phonemes in Chinese phoneme-to-grapheme conversion represented as P(CG|CP) in Eqs. (4)–(6). PM(EG,O)(CG|EG) = P(CG|EG) (7) PM(EP ,O)(CG|EG) (8) �= P(EP |EG) x P(CG|EP) VEP PM(EGP ,O)(CG|EG) (9) �= P(EP|EG) x P(CG|EG,EP) VEP The three basic transliteration models in MI are represented in Eqs. (7)–(9). Because the MI models are independent of Chinese phonemes, they are the same as the transliteration models in the literature used for machine transliteration from English to other languages without relying on targetlanguage phonemes (Karimi et al., 2007; Malik, 2006; Oh et al., 2006; Sherif and Kondrak, 2007; Yoon et al., 2007). Note that M(EG, 0) is the same transliteration model as the one proposed by Li et al. (2004). 3.2 Hybrid Transliteration Models The hybrid transliteration models in each class are defined by discrete mixture between the probability distribution of the two basic transliteration models, as in Eq. (10) (Al-Onaizan and Knight, 2002; Oh et al., 2006), where 0 &lt; α &lt; 1. We denote a hybrid transliteration model between two basic transliteration models M(x1, y) and M(x2, y) as M(x1 + x2, y, α), where y E Y = {0, CP, JCP}, x1 =� x2, and x1</context>
</contexts>
<marker>Malik, 2006</marker>
<rawString>M.G. Abbas Malik. 2006. Punjabi machine transliteration. In Proceedings of the COLING/ACL 2006, pages 1137–1144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H M Meng</author>
<author>Wai-Kit Lo</author>
<author>Berlin Chen</author>
<author>K Tang</author>
</authors>
<title>Generating phonetic cognates to handle named entities in English-Chinese cross-language spoken document retrieval.</title>
<date>2001</date>
<journal>ASRU</journal>
<booktitle>In Proc. of Automatic Speech Recognition and Understanding,</booktitle>
<volume>01</volume>
<pages>311--314</pages>
<contexts>
<context position="1362" citStr="Meng et al., 2001" startWordPosition="171" endWordPosition="174">teration model and make systematic comparisons with the conventional models. Our proposed model relies on the joint use of Chinese phonemes and their corresponding English graphemes and phonemes. Experiments showed that Chinese phonemes in our proposed model can contribute to the performance improvement in English-to-Chinese transliteration. 1 Introduction 1.1 Motivation Transliteration, i.e., phonetic translation, is commonly used to translate proper names and technical terms across languages. A variety of Englishto-Chinese machine transliteration models has been proposed in the last decade (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Li et al., 2004; Li et al., 2007; Wan and Verspoor, 1998; Virga and Khudanpur, 2003). They can be categorized into those based on Chinese phonemes (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Wan and Verspoor, 1998; Virga and Khudanpur, 2003) and those that don’t rely on Chinese phonemes (Li et al., 2004; Li et al., 2007). Inspired by the success of English grapheme-tophoneme research in speech synthesis, many researchers have proposed phoneme-based Englishto-Chinese transliteration models. In these </context>
<context position="12404" citStr="Meng et al., 2001" startWordPosition="2018" endWordPosition="2021"> can be interpreted as M(x, (x, CP)), English-side parameter x determines the English graphemes and phonemes, or both jointly used with Chinese phonemes in Chinese phoneme-to-grapheme conversion. Then we can represent the three basic transliteration models as in Eqs. (1)–(3), where P(CG|EG, CP), P(CG|EP, CP), and P(CG|EG, EP, CP) are the key points in our proposed models, MJ. The three basic transliteration models in MS – M(EG, CP), M(EP, CP), and M(EGP, CP) – are formulated as Eqs. (4)–(6). Chinese phonemebased transliteration models in the literature fall into either M(EG, CP) or M(EP, CP) (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Wan and Verspoor, 1998; Virga and Khudanpur, 2003). The three basic transliteration models in MS are identical as those in MJ, except for the Chinese phoneme-to-grapheme conversion method. They only depend on Chinese phonemes in Chinese phoneme-to-grapheme conversion represented as P(CG|CP) in Eqs. (4)–(6). PM(EG,O)(CG|EG) = P(CG|EG) (7) PM(EP ,O)(CG|EG) (8) �= P(EP |EG) x P(CG|EP) VEP PM(EGP ,O)(CG|EG) (9) �= P(EP|EG) x P(CG|EG,EP) VEP The three basic transliteration models in MI are represented in Eqs. (7)–(9). Because the MI model</context>
<context position="22317" citStr="Meng et al., 2001" startWordPosition="3714" endWordPosition="3717">dentical as the union of our training and development data, we denoted it as TRAIN+DEV in Table 6. In both TRAIN and TRAIN+DEV, we used the same parameter setting that was obtained by using the development data. LI04 represents a system in Li et al. (2004), and its ACC’ in TRAIN+DEV is taken from the literature. The systems based on the transliteration models defined in our paper are represented from the second row in Table 6. The phonemebased transliteration models in the literature correspond to either M(EG, CP) (Wan and Verspoor, 1998; Lee and Chang, 2003; Jiang et al., 2007) or M(EP, CP) (Meng et al., 2001; Gao et al., 2004; 7In our test set, an English word corresponds to one reference Chinese transliteration. 663 Table 6: Comparison of the overall performance Class Model TRAIN TRAIN+DEV ACC MRR CPA ACC’ ACC MRR CPA ACC’ LI04 N/A N/A N/A N/A 70.1 N/A N/A N/A M(EG, JCP) 71.9 80.4 72.3 88.2 72.3 80.7 73.1 88.9 M(EP, JCP) 61.1 70.3 62.4 82.8 61.1 70.6 63.1 83.8 MJ M(EGP, JCP) 72.3 80.9 73.2 89.6 73.5 81.5 73.9 90.4 M(EG+EP, JCP, 0.7) 72.8 80.7 73.8 89.7 73.2 81.0 74.7 90.5 M(EG+EGP, JCP, 0.6) 73.5 81.7 74.2 90.6 73.7 81.8 74.8 91.2 M(EP+EGP, JCP, 0.1) 71.6 80.3 73.3 89.8 72.5 80.8 73.8 90.1 M(EG,</context>
</contexts>
<marker>Meng, Lo, Chen, Tang, 2001</marker>
<rawString>H.M. Meng, Wai-Kit Lo, Berlin Chen, and K. Tang. 2001. Generating phonetic cognates to handle named entities in English-Chinese cross-language spoken document retrieval. In Proc. of Automatic Speech Recognition and Understanding, 2001. ASRU ’01, pages 311–314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jong-Hoon Oh</author>
<author>Key-Sun Choi</author>
<author>Hitoshi Isahara</author>
</authors>
<title>A comparison of different machine transliteration models.</title>
<date>2006</date>
<journal>Journal of Artificial Intelligence Research (JAIR),</journal>
<pages>27--119</pages>
<contexts>
<context position="13267" citStr="Oh et al., 2006" startWordPosition="2158" endWordPosition="2161">. They only depend on Chinese phonemes in Chinese phoneme-to-grapheme conversion represented as P(CG|CP) in Eqs. (4)–(6). PM(EG,O)(CG|EG) = P(CG|EG) (7) PM(EP ,O)(CG|EG) (8) �= P(EP |EG) x P(CG|EP) VEP PM(EGP ,O)(CG|EG) (9) �= P(EP|EG) x P(CG|EG,EP) VEP The three basic transliteration models in MI are represented in Eqs. (7)–(9). Because the MI models are independent of Chinese phonemes, they are the same as the transliteration models in the literature used for machine transliteration from English to other languages without relying on targetlanguage phonemes (Karimi et al., 2007; Malik, 2006; Oh et al., 2006; Sherif and Kondrak, 2007; Yoon et al., 2007). Note that M(EG, 0) is the same transliteration model as the one proposed by Li et al. (2004). 3.2 Hybrid Transliteration Models The hybrid transliteration models in each class are defined by discrete mixture between the probability distribution of the two basic transliteration models, as in Eq. (10) (Al-Onaizan and Knight, 2002; Oh et al., 2006), where 0 &lt; α &lt; 1. We denote a hybrid transliteration model between two basic transliteration models M(x1, y) and M(x2, y) as M(x1 + x2, y, α), where y E Y = {0, CP, JCP}, x1 =� x2, and x1, x2 E X = {EG, E</context>
</contexts>
<marker>Oh, Choi, Isahara, 2006</marker>
<rawString>Jong-Hoon Oh, Key-Sun Choi, and Hitoshi Isahara. 2006. A comparison of different machine transliteration models. Journal of Artificial Intelligence Research (JAIR), 27:119–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A linear observed time statistical parser based on maximal entropy models.</title>
<date>1997</date>
<booktitle>In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1--10</pages>
<contexts>
<context position="15346" citStr="Ratnaparkhi, 1997" startWordPosition="2567" endWordPosition="2568">:B” f5 triple1(egi, cpi, cgi−1) egi = “r”, cpi−1 = “GE”, c &amp;quot; •B&amp;quot; &amp;quot;N:B&amp;quot; gi-1= c gi = f6 triple2(egi−1, cgi−1, cpi−1) egi−1 = “g”, cpi i−1= “GE L”, cgi−1= “�:B” cgi = “~:B” they can be simplified into a series of products in Eqs. (11)–(13). The maximum entropy model is used to estimate the probabilities in Eqs. (11)–(13) (Berger et al., 1996). Generally, a conditional maximum entropy model is an exponential model that gives the conditional probability, as described in Eq. (14), where λi is the parameter to be estimated and fi(a, b) is a feature function corresponding to λi (Berger et al., 1996; Ratnaparkhi, 1997): P (epi|epi−1 i−k,egi+k i−k) (11) i P(CP |EG, EP) (12) � ≈P(cpi|cpi−1 i−k,�eg, ep�i+k i−k) i P(CG|EG, EP, CP) (13) � ≈P(cgi|cgi−1 i−k, (eg, ep, cp�i+k i−k) ) P(b a — exp(Ei λifi(a, b)) 14) l I — Eb&apos; exp(Ei λifi(a, b&apos;)) fi(a, b) is a binary function returning TRUE or FALSE based on context a and output b. If fi(a, b)=1, its corresponding model parameter λi contributes toward conditional probability P(b |a) (Berger et al., 1996; Ratnaparkhi, 1997). The feature functions used here are defined in terms of context predicates — a function returning TRUE or FALSE that depends on the presence of the </context>
</contexts>
<marker>Ratnaparkhi, 1997</marker>
<rawString>Adwait Ratnaparkhi. 1997. A linear observed time statistical parser based on maximal entropy models. In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing, pages 1– 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Schwartz</author>
<author>Yen-Lu Chow</author>
</authors>
<title>The NBest algorithm: an efficient procedure for finding top N sentence hypotheses.</title>
<date>1990</date>
<booktitle>In Proc. ofICASSP ’90,</booktitle>
<pages>81--84</pages>
<marker>Schwartz, Chow, 1990</marker>
<rawString>Richard Schwartz and Yen-Lu Chow. 1990. The NBest algorithm: an efficient procedure for finding top N sentence hypotheses. In Proc. ofICASSP ’90, pages 81–84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tarek Sherif</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Substringbased transliteration.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL ’07,</booktitle>
<pages>944--951</pages>
<contexts>
<context position="13293" citStr="Sherif and Kondrak, 2007" startWordPosition="2162" endWordPosition="2165">d on Chinese phonemes in Chinese phoneme-to-grapheme conversion represented as P(CG|CP) in Eqs. (4)–(6). PM(EG,O)(CG|EG) = P(CG|EG) (7) PM(EP ,O)(CG|EG) (8) �= P(EP |EG) x P(CG|EP) VEP PM(EGP ,O)(CG|EG) (9) �= P(EP|EG) x P(CG|EG,EP) VEP The three basic transliteration models in MI are represented in Eqs. (7)–(9). Because the MI models are independent of Chinese phonemes, they are the same as the transliteration models in the literature used for machine transliteration from English to other languages without relying on targetlanguage phonemes (Karimi et al., 2007; Malik, 2006; Oh et al., 2006; Sherif and Kondrak, 2007; Yoon et al., 2007). Note that M(EG, 0) is the same transliteration model as the one proposed by Li et al. (2004). 3.2 Hybrid Transliteration Models The hybrid transliteration models in each class are defined by discrete mixture between the probability distribution of the two basic transliteration models, as in Eq. (10) (Al-Onaizan and Knight, 2002; Oh et al., 2006), where 0 &lt; α &lt; 1. We denote a hybrid transliteration model between two basic transliteration models M(x1, y) and M(x2, y) as M(x1 + x2, y, α), where y E Y = {0, CP, JCP}, x1 =� x2, and x1, x2 E X = {EG, EP, EGP}. In this paper, we</context>
</contexts>
<marker>Sherif, Kondrak, 2007</marker>
<rawString>Tarek Sherif and Grzegorz Kondrak. 2007. Substringbased transliteration. In Proceedings of ACL ’07, pages 944–951.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Virga</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>Transliteration of proper names in cross-lingual information retrieval.</title>
<date>2003</date>
<booktitle>In Proc. ofACL 2003 Workshop on Multilingual and Mixed-language Named Entity Recognition,</booktitle>
<pages>57--64</pages>
<contexts>
<context position="1507" citStr="Virga and Khudanpur, 2003" startWordPosition="199" endWordPosition="202">mes and their corresponding English graphemes and phonemes. Experiments showed that Chinese phonemes in our proposed model can contribute to the performance improvement in English-to-Chinese transliteration. 1 Introduction 1.1 Motivation Transliteration, i.e., phonetic translation, is commonly used to translate proper names and technical terms across languages. A variety of Englishto-Chinese machine transliteration models has been proposed in the last decade (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Li et al., 2004; Li et al., 2007; Wan and Verspoor, 1998; Virga and Khudanpur, 2003). They can be categorized into those based on Chinese phonemes (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Wan and Verspoor, 1998; Virga and Khudanpur, 2003) and those that don’t rely on Chinese phonemes (Li et al., 2004; Li et al., 2007). Inspired by the success of English grapheme-tophoneme research in speech synthesis, many researchers have proposed phoneme-based Englishto-Chinese transliteration models. In these approaches, Chinese phonemes are generated from English graphemes or phonemes, and then the Chinese phonemes are converted into Chinese graphemes</context>
<context position="12515" citStr="Virga and Khudanpur, 2003" startWordPosition="2038" endWordPosition="2041">onemes, or both jointly used with Chinese phonemes in Chinese phoneme-to-grapheme conversion. Then we can represent the three basic transliteration models as in Eqs. (1)–(3), where P(CG|EG, CP), P(CG|EP, CP), and P(CG|EG, EP, CP) are the key points in our proposed models, MJ. The three basic transliteration models in MS – M(EG, CP), M(EP, CP), and M(EGP, CP) – are formulated as Eqs. (4)–(6). Chinese phonemebased transliteration models in the literature fall into either M(EG, CP) or M(EP, CP) (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Wan and Verspoor, 1998; Virga and Khudanpur, 2003). The three basic transliteration models in MS are identical as those in MJ, except for the Chinese phoneme-to-grapheme conversion method. They only depend on Chinese phonemes in Chinese phoneme-to-grapheme conversion represented as P(CG|CP) in Eqs. (4)–(6). PM(EG,O)(CG|EG) = P(CG|EG) (7) PM(EP ,O)(CG|EG) (8) �= P(EP |EG) x P(CG|EP) VEP PM(EGP ,O)(CG|EG) (9) �= P(EP|EG) x P(CG|EG,EP) VEP The three basic transliteration models in MI are represented in Eqs. (7)–(9). Because the MI models are independent of Chinese phonemes, they are the same as the transliteration models in the literature used f</context>
<context position="23568" citStr="Virga and Khudanpur, 2003" startWordPosition="3957" endWordPosition="3960">6 79.0 N/A N/A M(EP, 0) 58.5 69.3 N/A N/A 59.4 70.1 N/A N/A MI M(EGP, 0) 71.2 79.9 N/A N/A 72.3 80.7 N/A N/A M(EG+EP, 0, 0.7) 70.7 79.1 N/A N/A 72.0 80.0 N/A N/A M(EG+EGP, 0, 0.4) 72.0 80.3 N/A N/A 72.8 80.9 N/A N/A M(EP+EGP, 0, 0.1) 71.0 79.6 N/A N/A 72.0 80.4 N/A N/A M(EG, CP) 58.9 70.2 72.3 78.4 59.1 70.4 73.1 78.4 M(EP, CP) 50.2 62.3 62.4 78.4 50.4 62.6 63.1 78.5 MS M(EGP, CP) 59.1 70.4 73.2 78.4 59.3 70.5 73.9 78.5 M(EG+EP, CP, 0.8) 59.7 71.3 73.8 79.0 60.3 71.7 74.7 79.0 M(EG+EGP, CP, 0.6) 59.8 71.7 74.2 78.9 60.6 72.1 74.8 78.9 M(EP+EGP, CP, 0.1) 58.8 70.4 73.3 78.9 59.4 70.7 73.8 78.8 Virga and Khudanpur, 2003). A comparison between the basic and hybrid transliteration models showed that the hybrid ones usually performed better (the exception was M(EP+EGP, y, α) but the performance still comparable to the basic ones in each class). Especially, the hybrid ones based on the best two basic transliteration models, M(EG+EGP, y, α), showed the best performance. A comparison among the MI, MS, and MJ models showed that Chinese phonemes did contribute to the performance improvement of English-to-Chinese transliteration when Chinese phonemes were used together with their corresponding English graphemes and ph</context>
</contexts>
<marker>Virga, Khudanpur, 2003</marker>
<rawString>Paola Virga and Sanjeev Khudanpur. 2003. Transliteration of proper names in cross-lingual information retrieval. In Proc. ofACL 2003 Workshop on Multilingual and Mixed-language Named Entity Recognition, pages 57–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Wan</author>
<author>Cornelia Maria Verspoor</author>
</authors>
<title>Automatic English-Chinese name transliteration for development of multilingual resources.</title>
<date>1998</date>
<booktitle>In Proc. of COLING ’98,</booktitle>
<pages>1352--1356</pages>
<contexts>
<context position="1479" citStr="Wan and Verspoor, 1998" startWordPosition="195" endWordPosition="198">int use of Chinese phonemes and their corresponding English graphemes and phonemes. Experiments showed that Chinese phonemes in our proposed model can contribute to the performance improvement in English-to-Chinese transliteration. 1 Introduction 1.1 Motivation Transliteration, i.e., phonetic translation, is commonly used to translate proper names and technical terms across languages. A variety of Englishto-Chinese machine transliteration models has been proposed in the last decade (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Li et al., 2004; Li et al., 2007; Wan and Verspoor, 1998; Virga and Khudanpur, 2003). They can be categorized into those based on Chinese phonemes (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Wan and Verspoor, 1998; Virga and Khudanpur, 2003) and those that don’t rely on Chinese phonemes (Li et al., 2004; Li et al., 2007). Inspired by the success of English grapheme-tophoneme research in speech synthesis, many researchers have proposed phoneme-based Englishto-Chinese transliteration models. In these approaches, Chinese phonemes are generated from English graphemes or phonemes, and then the Chinese phonemes are conv</context>
<context position="12487" citStr="Wan and Verspoor, 1998" startWordPosition="2034" endWordPosition="2037">English graphemes and phonemes, or both jointly used with Chinese phonemes in Chinese phoneme-to-grapheme conversion. Then we can represent the three basic transliteration models as in Eqs. (1)–(3), where P(CG|EG, CP), P(CG|EP, CP), and P(CG|EG, EP, CP) are the key points in our proposed models, MJ. The three basic transliteration models in MS – M(EG, CP), M(EP, CP), and M(EGP, CP) – are formulated as Eqs. (4)–(6). Chinese phonemebased transliteration models in the literature fall into either M(EG, CP) or M(EP, CP) (Meng et al., 2001; Gao et al., 2004; Jiang et al., 2007; Lee and Chang, 2003; Wan and Verspoor, 1998; Virga and Khudanpur, 2003). The three basic transliteration models in MS are identical as those in MJ, except for the Chinese phoneme-to-grapheme conversion method. They only depend on Chinese phonemes in Chinese phoneme-to-grapheme conversion represented as P(CG|CP) in Eqs. (4)–(6). PM(EG,O)(CG|EG) = P(CG|EG) (7) PM(EP ,O)(CG|EG) (8) �= P(EP |EG) x P(CG|EP) VEP PM(EGP ,O)(CG|EG) (9) �= P(EP|EG) x P(CG|EG,EP) VEP The three basic transliteration models in MI are represented in Eqs. (7)–(9). Because the MI models are independent of Chinese phonemes, they are the same as the transliteration mod</context>
<context position="22243" citStr="Wan and Verspoor, 1998" startWordPosition="3699" endWordPosition="3702">data in Li et al. (2004). Since the training data used in Li et al. (2004) is identical as the union of our training and development data, we denoted it as TRAIN+DEV in Table 6. In both TRAIN and TRAIN+DEV, we used the same parameter setting that was obtained by using the development data. LI04 represents a system in Li et al. (2004), and its ACC’ in TRAIN+DEV is taken from the literature. The systems based on the transliteration models defined in our paper are represented from the second row in Table 6. The phonemebased transliteration models in the literature correspond to either M(EG, CP) (Wan and Verspoor, 1998; Lee and Chang, 2003; Jiang et al., 2007) or M(EP, CP) (Meng et al., 2001; Gao et al., 2004; 7In our test set, an English word corresponds to one reference Chinese transliteration. 663 Table 6: Comparison of the overall performance Class Model TRAIN TRAIN+DEV ACC MRR CPA ACC’ ACC MRR CPA ACC’ LI04 N/A N/A N/A N/A 70.1 N/A N/A N/A M(EG, JCP) 71.9 80.4 72.3 88.2 72.3 80.7 73.1 88.9 M(EP, JCP) 61.1 70.3 62.4 82.8 61.1 70.6 63.1 83.8 MJ M(EGP, JCP) 72.3 80.9 73.2 89.6 73.5 81.5 73.9 90.4 M(EG+EP, JCP, 0.7) 72.8 80.7 73.8 89.7 73.2 81.0 74.7 90.5 M(EG+EGP, JCP, 0.6) 73.5 81.7 74.2 90.6 73.7 81.8 7</context>
</contexts>
<marker>Wan, Verspoor, 1998</marker>
<rawString>Stephen Wan and Cornelia Maria Verspoor. 1998. Automatic English-Chinese name transliteration for development of multilingual resources. In Proc. of COLING ’98, pages 1352–1356.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xinhua News Agency</author>
</authors>
<title>Chinese transliteration offoreign personal names.</title>
<date>1992</date>
<publisher>The Commercial Press.</publisher>
<contexts>
<context position="18023" citStr="Agency, 1992" startWordPosition="3003" endWordPosition="3004">ls, three basic and three hybrid ones, in each class, MI, MS, and MJ. We compared the transliteration models from the viewpoint of ChiWe used the same test set used in Li et al. (2004) for our It contains 37,694 pairs of English words and their official Chinese tran testing5. sliterations 4Available at test set was also used in machine transliteration shared for English-to-Chinese tran http://homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.html5This “NEWS09 task” sliteration (Li et al., 2009) � P (EP |EG) ≈ 662 extracted from the “Chinese Transliteration of Foreign Personal Names” (Xinhua News Agency, 1992), which includes names in English, French, German, and many other foreign languages (Li et al., 2004). We used the same test data as in Li et al. (2004). But we randomly selected 90% of the training data used in Li et al. (2004) as our training data and the remainder as the development data, as shown in Table 5. Table 5: Number of English-Chinese transliteration pairs in each data set Ours Li et al. (2004) Training data 31,299 34,777 Development data 3,478 N/A Blind test data 2,896 2,896 We used the training data for training the transliteration models. For each model, we tuned the parameters </context>
</contexts>
<marker>Agency, 1992</marker>
<rawString>Xinhua News Agency. 1992. Chinese transliteration offoreign personal names. The Commercial Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Binyong Yin</author>
<author>Mary Felley</author>
</authors>
<title>Chinese Romanization: Pronunciation and Orthography.</title>
<date>1990</date>
<publisher>Sinolingua.</publisher>
<contexts>
<context position="5604" citStr="Yin and Felley, 1990" startWordPosition="857" endWordPosition="860">nemes. We define a set of English-to-Chinese transliteration models and categorize them into the following three classes: • MI: Models Independent of Chinese phonemes • MS: Models based on Simple use of Chinese phonemes • MJ: Models based on Joint use of Chinese phonemes and English graphemes and phonemes that correspond to our proposed model. Our comparison among the three types of transliteration models can be summarized as follows. • The MI models relying on either English graphemes or phonemes could not outperform those based on both English graphemes and phonemes. phonemes and syllables (Yin and Felley, 1990). 2http://www.cs.cmu.edu/˜laura/pages/ arpabet.ps • The MJ models significantly reduced errors in Chinese phoneme-to-grapheme conversion; thus they achieved the best performance. The rest of this paper is organized as follows. Section 2 introduces the notations used throughout this paper. Section 3 describes the transliteration models we compared. Section 4 describes our tests and results. Section 5 concludes the paper with a summary. 2 Preliminaries Let EG be an English word composed of n English graphemes, and let EP be a sequence of English phonemes that represents the pronunciation of EG. </context>
</contexts>
<marker>Yin, Felley, 1990</marker>
<rawString>Binyong Yin and Mary Felley. 1990. Chinese Romanization: Pronunciation and Orthography. Sinolingua.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su-Youn Yoon</author>
<author>Kyoung-Young Kim</author>
<author>Richard Sproat</author>
</authors>
<title>Multilingual transliteration using feature based phonetic method.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL’07,</booktitle>
<pages>112--119</pages>
<contexts>
<context position="13313" citStr="Yoon et al., 2007" startWordPosition="2166" endWordPosition="2169">hinese phoneme-to-grapheme conversion represented as P(CG|CP) in Eqs. (4)–(6). PM(EG,O)(CG|EG) = P(CG|EG) (7) PM(EP ,O)(CG|EG) (8) �= P(EP |EG) x P(CG|EP) VEP PM(EGP ,O)(CG|EG) (9) �= P(EP|EG) x P(CG|EG,EP) VEP The three basic transliteration models in MI are represented in Eqs. (7)–(9). Because the MI models are independent of Chinese phonemes, they are the same as the transliteration models in the literature used for machine transliteration from English to other languages without relying on targetlanguage phonemes (Karimi et al., 2007; Malik, 2006; Oh et al., 2006; Sherif and Kondrak, 2007; Yoon et al., 2007). Note that M(EG, 0) is the same transliteration model as the one proposed by Li et al. (2004). 3.2 Hybrid Transliteration Models The hybrid transliteration models in each class are defined by discrete mixture between the probability distribution of the two basic transliteration models, as in Eq. (10) (Al-Onaizan and Knight, 2002; Oh et al., 2006), where 0 &lt; α &lt; 1. We denote a hybrid transliteration model between two basic transliteration models M(x1, y) and M(x2, y) as M(x1 + x2, y, α), where y E Y = {0, CP, JCP}, x1 =� x2, and x1, x2 E X = {EG, EP, EGP}. In this paper, we define three types </context>
</contexts>
<marker>Yoon, Kim, Sproat, 2007</marker>
<rawString>Su-Youn Yoon, Kyoung-Young Kim, and Richard Sproat. 2007. Multilingual transliteration using feature based phonetic method. In Proceedings of ACL’07, pages 112–119.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>