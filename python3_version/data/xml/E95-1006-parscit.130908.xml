<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000278">
<title confidence="0.999683">
A Specification Language for
Lexical Functional Grammars
</title>
<author confidence="0.991845">
Patrick Blackburn and Claire Gardent
</author>
<affiliation confidence="0.912464">
Computerlinguistik
</affiliation>
<address confidence="0.702973">
Universitat des Saarlandes
Postfach 1150, D-66041 Saarbriicken
Germany
</address>
<email confidence="0.864182">
{patrick,claire}Ocoli.uni-sb.de
</email>
<sectionHeader confidence="0.993296" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999871">
This paper defines a language G for spe-
cifying LFG grammars. This enables
constraints on LFG&apos;s composite onto-
logy (c-structures synchronised with f-
structures) to be stated directly; no ap-
peal to the LFG construction algorithm
is needed. We use to specify schemata
annotated rules and the LFG uniquen-
ess, completeness and coherence princip-
les. Broader issues raised by this work
are noted and discussed.
</bodyText>
<sectionHeader confidence="0.997908" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999654676056338">
Unlike most linguistic theories, LFG (see Kaplan
and Bresnan (1982)) treats grammatical relations
as first class citizens. Accordingly, it casts its lin-
guistic analyses in terms of a composite ontology:
two independent domains — a domain of consti-
tuency information (c-structure), and a domain of
grammatical function information (f-structure) —
linked together in a mutually constraining man-
ner. As has been amply demonstrated over the
last fifteen years, this view permits perspicuous
analyses of a wide variety of linguistic data.
However standard formalisations of LFG do not
capture its strikingly simple underlying intuitions.
Instead, they make a detour via the LFG con-
struction algorithm, which explains how equatio-
nal constraints linking subtrees and feature struc-
tures are to be resolved. The main point of the
present paper is to show that such detours are
unnecessary. We define a specification language
,C in which (most of) the interactions between c-
and f-structure typical of LFG grammars can be
stated directly.
The key idea underlying our approach is to
think about LFG model theoretically. That is,
our first task will be to give a precise — and trans-
parent — mathematical picture of the LFG onto-
logy. As has already been noted, the basic enti-
ties underlying the LFG analyses are composite
structures consisting of a finite tree, a finite fea-
ture structure, and a function that links the two.
Such structures can straightforwardly be thought
of as models, in the usual sense of first order model
theory (see Hodges (1993)). Viewing the LFG on-
tology in such terms does no violence to intuition:
indeed, as we shall see, a more direct mathemati-
cal embodiment of the LFG universe can hardly
be imagined.
Once the ontological issues have been settled we
turn to our ultimate goal: providing a specifica-
tion language for LFG grammars. Actually, with
the ontological issues settled it is a relatively sim-
ple task to devise suitable specification languages:
we simply consider how LFG linguists talk about
such structures when they write grammars. That
is, we ask ourselves what kind of constraints the
linguist wishes to impose, and then devise a lan-
guage in which they can be stated.
Thus we shall proceed as follows. After a brief
introduction to LFG,&apos; we isolate a class of models
which obviously mirrors the composite nature of
the LFG ontology, and then turn to the task of de-
vising a language for talking about them. We opt
for a particularly simple specification language: a
propositional language enriched with operators for
talking about c- and f-structures, together with a
path equality construct for enforcing synchronisa-
tion between the two domains. We illustrate its
use by showing how to capture the effect of sche-
mata annotated rules, and the LFG uniqueness,
completeness and coherence principles.
Before proceeding, a word of motivation is in
order. Firstly, we believe that there are practical
reasons for interest in grammatical specification
languages: formal specification seems important
(perhaps essential) if robust large scale grammars
are to be defined and maintained. Moreover, the
essentially model theoretic slant on specification
we propose here seems particularly well suited to
this aim. Models do not in any sense &amp;quot;code&amp;quot; the
LFG ontology: they take it pretty much at face va-
lue. In our view this is crucial. Formal approaches
</bodyText>
<footnote confidence="0.9969995">
1This paper is based upon the original formula-
tion of LFG, that of Kaplan and Bresnan (1982), and
will not discuss such later innovations as functional
uncertainty.
</footnote>
<page confidence="0.99967">
39
</page>
<bodyText confidence="0.999981952380952">
to grammatical theorising should reflect linguistic
intuitions as directly as possible, otherwise they
run the risk of being an obstacle, not an aid, to
grammar development.
The approach also raises theoretical issues. The
model theoretic approach to specification langua-
ges forces one to think about linguistic ontologies
in a systematic way, and to locate them in a well
understood mathematical space. This has at least
two advantages. Firstly, it offers the prospect of
meaningful comparison of linguistic frameworks.
Secondly, it can highlight anomalous aspects of
a given system. For example, as we shall later
see, there seems to be no reasonable way to deal
with LFG&apos;s =, definitions using the simple models
of the present paper. There is a plausible model
theoretic strategy strategy for extending our ac-
count to cover =c; but the nature of the required
extension clearly shows that =, is of a quite diffe-
rent character to the bulk of LFG. We discuss the
matter in the paper&apos;s concluding section.
</bodyText>
<sectionHeader confidence="0.972899" genericHeader="method">
2 Lexical Functional Grammar
</sectionHeader>
<bodyText confidence="0.955444266666667">
A lexical functional grammar consists of three
main components: a set of context free rules anno-
tated with schemata, a set of well formedness con-
ditions on feature structures, and a lexicon. The
role of these components is to assign two interrela-
ted structures to any linguistic entity licensed by
the grammar: a tree (the c-structure) and a fea-
ture structure (the f-structure). Briefly, the con-
text free skeleton of the grammar rules describes
the c-structure, the well-formedness conditions re-
strict f-structure admissibility, and the schemata
synchronise the information contained in the c-
and f-structures.
--+ NP VP
=
</bodyText>
<listItem confidence="0.912075">
(2) NP --+ Det N
(3) VP --+ V
t=1
</listItem>
<equation confidence="0.9171835">
a Det, (1 SPEC) = a, (1 NUM) = sing
girl N, (1 PRED) = girl, (I NUM) = sing
walks V, (1 PRED) = walk((subj)),
(1 TENSE) = pst
</equation>
<figureCaption confidence="0.990678">
Figure 1: An LFG grammar fragment
</figureCaption>
<bodyText confidence="0.999937041666667">
To see how this works, let&apos;s run through a sim-
ple example. Consider the grammar given in Fi-
gure 1. Briefly, the up- and down-arrows in the
schemata can be read as follows: I Feature denotes
the value of Feature in the f-structure associated
with the tree node immediately dominating the
current tree node, whereas 1 Feature denotes the
value of Feature in the f-structure associated with
the current tree node. For instance, in rule (1) the
NP schema indicates that the f-structure associa-
ted with the NP node is the value of the SUB)
feature in the f-structure associated with the mo-
ther node. As for the VP schema, it requires that
the f-structure associated with the mother node is
identical with the f-structure associated with the
VP node.
Given the above lexical entries, it is possible
to assign a correctly interrelated c-structure and
f-structure to the sentence A girl walks. Moreo-
ver, the resulting f-structure respects the LFG
well formedness conditions, namely the uniquen-
ess, completeness and coherence principles discus-
sed in section 5. Thus A girl walks is accepted by
this grammar.
</bodyText>
<sectionHeader confidence="0.957756" genericHeader="method">
3 Modeling the LFG ontology
</sectionHeader>
<bodyText confidence="0.99990785">
The ontology underlying LFG is a composite one,
consisting of trees, feature structures and links
between the two. Our first task is to mathemati-
cally model this ontology, and to do so as trans-
parently as possible. That is, the mathematical
entities we introduce should clearly reflect the in-
tuitions important to LFG theorising — &amp;quot;No co-
ding!&amp;quot;, should be our slogan. In this section, we
introduce such a representation of LFG ontology.
In the following section, we shall present a formal
language G for talking about this representation;
that is, a language for specifying LFG grammars.
We work with the following objects. A mo-
del M is a tripartite structure (T, zoomin,
where T is our mathematical picture of c- struc-
ture, .7&amp;quot; our picture of f-structure, and zoomin
our picture of the link between the two. We
now define each of these components. Our de-
finitions are given with respect to a signature of
the form (Cat, Atom, Feat), where Cat, Atom and
Feat are non-empty, finite or denumerably infinite
sets. The intuition is that these sets denote the
syntactic categories, the atomic values, and the
features that the linguist has chosen for some lan-
guage. For instance, Cat could be {S, NP, VP, V},
Atom might be {sg,p1,third, fem,masc} and
Feat might be {subj, obj, pred, nb, case, gd}.
Firstly we define T. As this is our mathema-
tical embodiment of c-structure (that is, a cate-
gory labeled tree) we take it to be a pair (T,Vi) ,
where T is a finite ordered tree and Vt is a function
from the set of tree nodes to Cat. We will freely
use the usual tree terminology such as mother-of,
daughter-of, dominates, and so on.
Second, we take .7- to be a tuple of the form
(W, ffaLEFeat, initial, Final, Vf), where W is a fi-
nite, non-empty set of nodes; f, is a partial func-
tion from W to W, for all a E Feat; initial is a
unique node in W such that any other node w&apos;
of W can be reached by applying a finite number
</bodyText>
<equation confidence="0.773557">
SUBJ) =
</equation>
<page confidence="0.934947">
40
</page>
<bodyText confidence="0.999927">
of fc, to initial; Final is a non-empty set of no-
des such that for all fa and all w E Final, fa(w)
is undefined; and V1 is a function from Final to
Atom. This is a standard way of viewing feature
structures, and is appropriate for LFG.
Finally, we take zoomin, the link between c-
structure and f-structure information, to be a par-
tial function from T to W. This completes our
mathematical picture of LFG ontology. It is cer-
tainly a precise picture (all three components, and
how they are related are well defined), but, just
as importantly, it is also a faithful picture; models
capture the LFG ontology perspicuously.
</bodyText>
<sectionHeader confidence="0.915982" genericHeader="method">
4 A Specification Language
</sectionHeader>
<bodyText confidence="0.999808016666667">
Although models pin down the essence of the LFG
universe, our work has only just begun. For a
start, not all models are created equal. Which
of them correspond to grammatical utterances of
English? Of Dutch? Moreover, there is a practical
issue to be addressed: how should we go about
saying which models we deem &apos;good&apos;? To put in
another way, in what medium should we specify
grammars?
Now, it is certainly possible to talk about mo-
dels using natural language (as readers of this pa-
per will already be aware) and for many purposes
(such as discussion with other linguists) natural
language is undoubtedly the best medium. Ho-
wever, if our goal is to specify large scale gram-
mars in a clear, unambiguous manner, and to do
so in such a way that our grammatical analyses
are machine verifiable, then the use of formal spe-
cification languages has obvious advantages. But
which formal specification language? There is no
single best answer: it depends on one&apos;s goals. Ho-
wever there are some important rules of thumb:
one should carefully consider the expressive capa-
bilities required; and a judicious commitment to
simplicity and elegance will probably pay off in
the long run. Bearing this advice in mind, let us
consider the nature of LFG grammars.
Firstly, LFG grammars impose constraints on
T. Context free rules are typically used for this
purpose — which means, in effect, that constraints
are being imposed on the &apos;daughter of&apos; and &apos;sister
of&apos; relations of the tree. Secondly, LFG grammars
impose general constraints on various features in
Such constraints (for example the completen-
ess constraint) are usually expressed in English
and make reference to specific features (notably
pred). Thirdly, LFG grammars impose constraints
on zoomin. As we have already seen, this is done
by annotating the context free rules with equati-
ons. These constraints regulate the interaction of
the &apos;mother of&apos; relation on T, zoomin, and specific
features in F.
Thus a specification language adequate for LFG
must be capable of talking about the usual tree re-
lations, the various features, and zoomin; it must
also be powerful enough to permit the statement
of generalisations; and it must have some mecha-
nism for regulating the interaction between T and
F. These desiderata can be met by making use
of a propositional language augmented with (1)
modal operators for talking about trees (2) modal
operators for talking about feature structures, and
(3) a modal operator for talking about zoomin,
together with a path equality construct for syn-
chronising the information flow between the two
domains. Let us build such a language.
Our language is called E and its primi-
tive symbols (with respect to a given signature
(Cat, Atom, Feat)) consists of (1) all items in Cat
and Atom (2) two constants, c-struct and f-struct,
</bodyText>
<listItem confidence="0.9948245">
(3) the Boolean connectives (true, false, A,
etc.), (4) three tree modalities (up), (down) and
•, (5) a modality (a), for each feature a E Feat,
(6) a synchronisation modality (zoomin), (7) a
</listItem>
<bodyText confidence="0.969485181818182">
path equality constructor ;4, together with (8) the
brackets ) and (.
The basic well formed formulas (basic wffs) of
are: {true, false, c-struct, f-struct}UCatUAtomU
Patheq, where Patheq is defined as follows. Let t,
t&apos; be finite (possibly null) sequences of the moda-
lities (up) and (down), and let f, f&apos; be finite (pos-
sibly null) sequences of feature modalities. Then
i(zoomin) f t&apos; (zoomin) is in Patheq, and no-
thing else is.
The wffs of r are defined as follows: (1) all basic
wffs are wffs, (2) all Boolean combinations of wffs
are wffs, (3) if 0 is a wff then so is MO, where
M E {(a) : a E Feat} U {(up), (down), (zoomin)}
and (4) if n &gt;0, and 01, , 07, are wffs, then so
is •(017 • • • 10n)- Nothing else is a wff.
Now for the satisfaction definition. We induc-
tively define a three place relation k which holds
between models M, nodes n and wffs 0. Intui-
tively, M, n 0 means that the constraint 0 holds
at (is true at, is satisfied at) the node n in model
M. The required inductive definition is as follows:
</bodyText>
<equation confidence="0.985239846153846">
M,n = true
M,n false
M, n = c-struct
n is a tree node
M, n = f-struct
n is a feature structure node
M,n c
14(n) = c, (for all c E Cat)
M,n k a
(n) = a, (for all a E Atom)
M,n
not M , n
M,n I=A
</equation>
<bodyText confidence="0.970772416666667">
M,nk and M, n=&amp;
M, n = (a)0
fcr(n) exists and M, f,,(n) (I)
(for all a E Feat)
always
never
iff
iff
if
iff
if
iff
</bodyText>
<page confidence="0.993758">
41
</page>
<figure confidence="0.782988538461538">
M, n (down)q5 if
n is a tree node with
at least one daughter n&apos; such that
M, (b
M, n (up) (1) if
n is a tree node with
a mother node m and
M, m
n = (zoomin)0
n is a tree node,
zoomin(n) is defined, and
M,zoomin(n) k
m, n .(01,...,0k)
</figure>
<bodyText confidence="0.980066438596491">
n is a tree node with
exactly k daughters n1 . . .nk and
M, ni k nk 1= Ok
M, n = t(zoomin) f t&apos; (zoomin) f&apos;
n is a tree node, and there is a
feature structure node w such that
n(St; zoomin;Sf)w and
n(St,; zoomin; S f,)w
For the most part the import of these clauses
should be clear. The constants .true and false play
their usual role, c-struct and f-struct give us &apos;la-
bels&apos; for our two domains, while the elements of
Cat and Atom enable us to talk about syntactic
categories and atomic f-structure information re-
spectively. The clauses for and A are the usual
definitions of classical logic, thus we have all pro-
positional calculus at our disposal; as we shall
see, this gives us the flexibility required to for-
mulate non-trivial general constraints. More in-
teresting are the clauses for the modalities. The
unary modalities (a), (up), (down), and (zoomin)
and the variable arity modality • give us access
to the binary relations important in formulating
LFG grammars. Incidentally, • is essentially a
piece of syntactic sugar; it could be replaced by a
collection of unary modalities (see Blackburn and
Meyer-Viol (1994)). However, as the • operator
is quite a convenient piece of syntax for captu-
ring the effect of phrase structure rules, we have
included it as a primitive in G.
In fact, the only clause in the satisfaction &apos;de-
finition which is at all complex is that for
It can be glossed as follows. Let St and St, be
the path sequences through the tree correspon-
ding to t and t&apos; respectively, and let Sf and Sf,
be the path sequences through the feature struc-
ture corresponding to f and f&apos; respectively. Then
t(zoomin) f t&apos; (zoomin) f&apos; is satisfied at a tree
node t if there is a feature structure node w that
can be reached from t by making both the tran-
sition sequence St; zoomin; S1 and the transition
sequence St&apos;; zoomin; S f, . Clearly, this construct
is closely related to the Kasper Rounds path equa-
lity (see Kasper and Rounds (1990)); the princi-
ple difference is that whereas the Kasper Rounds
enforces path equalities within the domain of lea-
ture structures, the LFG path equality enforces
equalities between the tree domain and the fea-
ture structure domain.
If M, n 0 then we say that 0 is satisfied in M
at n. If M, n 0 for all nodes n in M then we say
that 0 is valid in M and write M = 0. Intuitively,
to say that 0 is valid in M is to say that the
constraint 0 holds universally; it is a completely
general fact about M. As we shall see in the next
section, the notion of validity has an important
role to play in grammar specification.
</bodyText>
<sectionHeader confidence="0.965509" genericHeader="method">
5 Specifying Grammars
</sectionHeader>
<bodyText confidence="0.999780588235294">
We will now illustrate how r can be used to spe-
cify grammars. The basic idea is as follows. We
write down a wff 0G which expresses all our desi-
red grammatical constraints. That is, we state in
.0 which trees and feature structures are admissi-
ble, and how tree and feature based information is
to be synchronised; examples will be given shortly.
Now, a model is simply a mathematical embodi-
ment of LFG sentence structure, thus those mo-
dels M in which 0G is valid are precisely the sent-
ence structures which embody all our grammatical
principles.
Now for some examples. Let&apos;s first consider how
to write specifications which capture the effect of
schemata annotated grammar rules. Suppose we
want to capture the meaning of rule (1) of Figure
1, repeated here for convenience:
</bodyText>
<equation confidence="0.9939755">
S NP VP
suBJ) =1 t=1
</equation>
<bodyText confidence="0.998554583333333">
Recall that this annotated rule licenses structures
consisting of a binary tree whose mother node m
is labeled S and whose daughter nodes n1 and n2
are labeled NP and VP respectively; and where,
furthermore, the S and VP nodes (that is, in and
n2) are related to the same f-structure node w;
while the NP node (that is, n1) is related to the
node w&apos; in the f-structure that is reached by ma-
king a SUBJ transition from w.
This is precisely the kind of structural cons-
traint that .0 is designed to specify. We do so
as follows:
</bodyText>
<equation confidence="0.586565">
S .(NP A (up)(zoomin)(subj) (zoomin),
VP A (up)(zoomin) (zoomin))
</equation>
<bodyText confidence="0.936619333333333">
This formula is satisfied in a model M at any node
m if m is labeled with the category S, has exactly
two daughters n1 and n2 labeled with category
NP and VP respectively. Moreover, n1 must be
associated with an f-structure node w&apos; which can
also be reached by making a (subj) transition from
the f-structure node w associated with the mother
node of m. (In other words, that part of the f-
structure that is associated with the NP node is
re-entrant with the value of the subj feature in
if
if
</bodyText>
<page confidence="0.989707">
42
</page>
<bodyText confidence="0.984372793103448">
the f-structure associated with the S node.) And
finally, n2 must be associated with that f-structure
node w which m. (In other words, the part of the
f-structure that is associated with the VP node is
re-entrant with that part of the f-structure which
is associated with the S node.)
In short, we have captured the effect of an an-
notated rule purely declaratively. There is no ap-
peal to any construction algorithm; we have sim-
ply stated how we want the different pieces to fit
together. Note that • specifies local tree admissi-
bility (thus obviating the need for rewrite rules),
and (zoomin), (up) and work together to cap-
ture the effect of 1 and 1.
In any realistic LFG grammar there will be se-
veral — often many — such annotated rules, and
acceptable c-structures are those in which each
non-terminal node is licensed by one of them. We
specify this as follows. For each such rule we form
the analogous ,C wff Or (just as we did in the pre-
vious example) and then we form the disjunction
V Or of all such wffs. Now, any non-terminal node
in the c-structure should satisfy one of these dis-
junctions (that is, each sub-tree of c-struct must
be licensed by one of these conditions); moreover
the disjunction is irrelevant to the terminal nodes
of c-struct and all the nodes in f-struct. Thus we
demand that the following conditional statement
be valid:
(c-struct A (down)true) —*V Cbr&apos;
This says that if we are at a c-struct node which
has at least one daughter (that is, a non-terminal
node) then one of the subtree licensing disjuncts
(or &apos;rules&apos;) must be satisfied there. This picks pre-
cisely those models in which all the tree nodes are
appropriately licensed. Note that the statement
is indeed valid in such models: it is true at all the
non-terminal nodes, and is vacuously satisfied at
terminal tree nodes and nodes of f-struct.
We now turn to the second main component
of LFG, the well formedness conditions on f-
structures.
Consider first the uniqueness principle. In es-
sence, this principle states that in a given f-
structure, a particular attribute may have at most
one value. In E this restriction is &apos;built in&apos;: it fol-
lows from the choices made concerning the ma-
thematical objects composing models. Essenti-
ally, the uniqueness principle is enforced by two
choices. First, I/1 associates atoms only with fi-
nal nodes of f-structures; and as V1 is a func-
tion, the atom so associated is unique. In ef-
fect, this hard-wires prohibitions against constant-
compound and constant-constant clashes into the
semantics of E. Second, we have modeled featu-
res as partial functions on the f-structure nodes
— this ensures that any complex valued attribute
is either undefined, or is associated with a uni-
que sub-part of the current f-structure. In short,
as required, any attribute will have at most one
value.
We turn to the completeness principle. In LFG,
this applies to a (small) finite number of attributes
(that is, transitions in the feature structure). This
collection includes the grammatical functions (e.g.
subj, obj, iobj) together with some longer transiti-
ons such as obi; obj and to; obj. Let GF be a meta-
variable over the modalities corresponding to the
elements of this set, thus GF contains such items
as (subj), (obj), (iobj), (obl)(obj) and (to)(obj).
Now, the completeness principle requires that any
of these features appearing as an attribute in the
value of the FRED attribute must also appear as
an attribute of the f-structure immediately con-
taining this FRED attribute, and this recursively.
The following wff is valid on precisely those mo-
dels satisfying the completeness principle:
(pred)GF true GF true.
Finally, consider the counterpart of the com-
pleteness principle, the coherence principle. This
applies to the same attributes as the completen-
ess principle and requires that whenever they oc-
cur in an f-structure they must also occur in the
f-structure associated with its FRED attribute.
This is tantamount to demanding the validity of
the following formula:
(GF true A (pred)true) (pred)GF true
</bodyText>
<sectionHeader confidence="0.946618" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999987037037037">
The discussion so far should have given the reader
some idea of how to specify LFG grammars using
C. To conclude we would like to discuss =, defi-
nitions. This topic bears on an important general
issue: how are the &apos;dynamic&apos; (or &apos;generative&apos;, or
&apos;procedural&apos;) aspects of grammar to be reconciled
with the &apos;static&apos;, (or &apos;declarative&apos;) model theoretic
world view.
The point is this. Although the LFG equations
discussed so far were defining equations, LFG also
allows so-called constraining equations (written
=c)• Kaplan and Bresnan explain the difference as
follows. Defining equations allow a feature-value
pair to be inserted into an f-structure providing
no conflicting information is present. That is,
they add a feature value pair to any consistent f-
structure. In contrast, constraining equations are
intended to constrain the value of an already exi-
sting feature-value pair. The essential difference
is that constraining equations require that the fea-
ture under consideration already has a value, whe-
reas defining equations apply independently of the
feature value instantiation level.
In short, constraining equations are essentially
a global check on completed structures which re-
quire the presence of certain feature values. They
have an eminently procedural character, and there
</bodyText>
<page confidence="0.999249">
43
</page>
<bodyText confidence="0.999947510638298">
is no obvious way to handle this idea in the pre-
sent set up. The bulk of LFG involves stating
constraints about a single model, and r is well
equipped for this task, but constraining equations
involve looking at the structure of other possible
parse trees. (In this respect they are reminiscent
of the feature specification defaults of GPSG.) The
approach of the present paper has been driven by
the view that (a) models capture the essence of
LFG ontology, and, (b) the task of the linguist is
to explain, in terms of the relations that exist wi-
thin a single model, what grammatical structure
is. Most of the discussion in Kaplan and Bres-
nan (1982) is conducted in such terms. However
constraining equations broaden the scope of the
permitted discourse; basically, they allow implicit
appeal to possible derivational structure. In short,
in common with most of the grammatical forma-
lisms with which we are familiar, LFG seems to
have a dynamic residue that resists a purely de-
clarative analysis. What should be done?
We see three possible responses. Firstly, we
note that the model theoretic approach can al-
most certainly be extended to cover constraining
equations. The move involved is analogous to the
way first order logic (a so-called &apos;extensional&apos; lo-
gic) can be extended to cope with intensional no-
tions such as belief and necessity. The basic idea
— it&apos;s the key idea underlying first order Kripke
semantics — is to move from dealing with a sin-
gle model to dealing with a collection of models
linked by an accessibility relation. Just as quan-
tification over possible states of affairs yields ana-
lyses of intensional phenomena, so quantification
over related models could provide a `denotational
semantics&apos; for =,. Preliminary work suggests that
the required structures have formal similarities to
the structures used in preferential semantics for
default and non-monotonic reasoning. This first
response seems to be a very promising line of work:
the requisite tools are there, and the approach
would tackle a full blooded version of LFG head
on. The drawback is the complexity it introduces
into an (up till now) quite simple story. Is such
additional complexity really needed?
A second response is to admit that there is a
dynamic residue, but to deal with it in overtly
computational terms. In particular, it may be
possible to augment our approach with an ex-
plicit operational semantics, perhaps the evolving
algebra approach adopted by Moss and Johnson
(1994). Their approach is attractive, because it
permits a computational treatment of dynamism
that abstracts from low level algorithmic details.
In short, the second strategy is a &apos;divide and con-
quer&apos; strategy: treat structural issues using model
theoretic tools, and procedural issues with (reve-
aling) computational tools. It&apos;s worth remarking
that this second response is not incompatible with
the first; it is common to provide programming
languages with both a denotational and an opera-
tional semantics.
The third strategy is both simpler and more
speculative. While it certainly seems to be the
case that LFG (and other &apos;declarative&apos; forma-
lisms) have procedural residues, it is far from clear
that these residues are necessary. One of the most
striking features of LFG (and indeed, GPSG) is
the way that purely structural (that is, model
theoretic) argumentation dominates. Perhaps the
procedural aspects are there more or less by ac-
cident? After all, both LFG and GPSG drew on
(and developed) a heterogeneous collection of tra-
ditional grammar specification tools, such as con-
text free rules, equations, and features. It could
be the case such procedural residues as =, are
simply an artifact of using the wrong tools for tal-
king about models. If this is the case, it might be
highly misguided to attempt to capture =, using
a logical specification language. Better, perhaps,
would be to draw on what is good in LFG and
to explore the logical options that arise naturally
when the model theoretic view is taken as pri-
mary. Needless to say, the most important task
that faces this third response is to get on with the
business of writing grammars; that, and nothing
else, is the acid test.
It is perhaps worth adding that at present the
authors simply do not know what the best re-
sponse is. If nothing else, the present work has
made very clear to us that the interplay of sta-
tic and dynamic ideas in generative grammar is
a delicate and complex matter which only further
work can resolve.
</bodyText>
<sectionHeader confidence="0.997878" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993192105263158">
Patrick Blackburn and Wilfried Meyer-Viol. 1994.
Linguistics, Logic and Finite Trees. Bulletin
of the IGPL, 2, pp. 3-29. Available by an-
onymous ftp from theory.doc.ic.ac.uk, directory
theory/forum/igpl/Bulletin.
Wilfrid Hodges. 1993. Model Theory. Cambridge
University Press.
Ron Kaplan and Joan Bresnan. 1982. Lexical-
Functional Grammar: A formal system for
grammatical representation. In The Mental Re-
presentation of Grammatical Relations, pp. 173
– 280, MIT Press.
R. Kasper and W. Rounds. 1990. The Logic of
Unification in Grammar. Linguistics and Phi-
losophy, 13, pp. 33-58.
Lawrence Moss and David Johnson. 1994. Dyna-
mic Interpretations of Constraint-Based Gram-
mar Formalisms. To appear in Journal of Logic,
Language and Information.
</reference>
<page confidence="0.999292">
44
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.783612">
<title confidence="0.9998825">A Specification Language for Lexical Functional Grammars</title>
<author confidence="0.995704">Patrick Blackburn</author>
<author confidence="0.995704">Claire Gardent</author>
<affiliation confidence="0.9439335">Computerlinguistik Universitat des Saarlandes</affiliation>
<address confidence="0.925922">Postfach 1150, D-66041 Saarbriicken Germany</address>
<abstract confidence="0.998897833333333">paper defines a language specifying LFG grammars. This enables constraints on LFG&apos;s composite ontology (c-structures synchronised with fstructures) to be stated directly; no appeal to the LFG construction algorithm is needed. We use to specify schemata annotated rules and the LFG uniqueness, completeness and coherence principles. Broader issues raised by this work are noted and discussed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Patrick Blackburn</author>
<author>Wilfried Meyer-Viol</author>
</authors>
<title>Linguistics, Logic and Finite Trees.</title>
<date>1994</date>
<journal>Bulletin of the IGPL,</journal>
<volume>2</volume>
<pages>3--29</pages>
<contexts>
<context position="15404" citStr="Blackburn and Meyer-Viol (1994)" startWordPosition="2663" endWordPosition="2666">ructure information respectively. The clauses for and A are the usual definitions of classical logic, thus we have all propositional calculus at our disposal; as we shall see, this gives us the flexibility required to formulate non-trivial general constraints. More interesting are the clauses for the modalities. The unary modalities (a), (up), (down), and (zoomin) and the variable arity modality • give us access to the binary relations important in formulating LFG grammars. Incidentally, • is essentially a piece of syntactic sugar; it could be replaced by a collection of unary modalities (see Blackburn and Meyer-Viol (1994)). However, as the • operator is quite a convenient piece of syntax for capturing the effect of phrase structure rules, we have included it as a primitive in G. In fact, the only clause in the satisfaction &apos;definition which is at all complex is that for It can be glossed as follows. Let St and St, be the path sequences through the tree corresponding to t and t&apos; respectively, and let Sf and Sf, be the path sequences through the feature structure corresponding to f and f&apos; respectively. Then t(zoomin) f t&apos; (zoomin) f&apos; is satisfied at a tree node t if there is a feature structure node w that can b</context>
</contexts>
<marker>Blackburn, Meyer-Viol, 1994</marker>
<rawString>Patrick Blackburn and Wilfried Meyer-Viol. 1994. Linguistics, Logic and Finite Trees. Bulletin of the IGPL, 2, pp. 3-29. Available by anonymous ftp from theory.doc.ic.ac.uk, directory theory/forum/igpl/Bulletin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wilfrid Hodges</author>
</authors>
<title>Model Theory.</title>
<date>1993</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="2182" citStr="Hodges (1993)" startWordPosition="337" endWordPosition="338">h (most of) the interactions between cand f-structure typical of LFG grammars can be stated directly. The key idea underlying our approach is to think about LFG model theoretically. That is, our first task will be to give a precise — and transparent — mathematical picture of the LFG ontology. As has already been noted, the basic entities underlying the LFG analyses are composite structures consisting of a finite tree, a finite feature structure, and a function that links the two. Such structures can straightforwardly be thought of as models, in the usual sense of first order model theory (see Hodges (1993)). Viewing the LFG ontology in such terms does no violence to intuition: indeed, as we shall see, a more direct mathematical embodiment of the LFG universe can hardly be imagined. Once the ontological issues have been settled we turn to our ultimate goal: providing a specification language for LFG grammars. Actually, with the ontological issues settled it is a relatively simple task to devise suitable specification languages: we simply consider how LFG linguists talk about such structures when they write grammars. That is, we ask ourselves what kind of constraints the linguist wishes to impose</context>
</contexts>
<marker>Hodges, 1993</marker>
<rawString>Wilfrid Hodges. 1993. Model Theory. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ron Kaplan</author>
<author>Joan Bresnan</author>
</authors>
<title>LexicalFunctional Grammar: A formal system for grammatical representation.</title>
<date>1982</date>
<booktitle>In The Mental Representation of Grammatical Relations,</booktitle>
<pages>173--280</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="710" citStr="Kaplan and Bresnan (1982)" startWordPosition="96" endWordPosition="99"> Gardent Computerlinguistik Universitat des Saarlandes Postfach 1150, D-66041 Saarbriicken Germany {patrick,claire}Ocoli.uni-sb.de Abstract This paper defines a language G for specifying LFG grammars. This enables constraints on LFG&apos;s composite ontology (c-structures synchronised with fstructures) to be stated directly; no appeal to the LFG construction algorithm is needed. We use to specify schemata annotated rules and the LFG uniqueness, completeness and coherence principles. Broader issues raised by this work are noted and discussed. 1 Introduction Unlike most linguistic theories, LFG (see Kaplan and Bresnan (1982)) treats grammatical relations as first class citizens. Accordingly, it casts its linguistic analyses in terms of a composite ontology: two independent domains — a domain of constituency information (c-structure), and a domain of grammatical function information (f-structure) — linked together in a mutually constraining manner. As has been amply demonstrated over the last fifteen years, this view permits perspicuous analyses of a wide variety of linguistic data. However standard formalisations of LFG do not capture its strikingly simple underlying intuitions. Instead, they make a detour via th</context>
<context position="4106" citStr="Kaplan and Bresnan (1982)" startWordPosition="649" endWordPosition="652">eding, a word of motivation is in order. Firstly, we believe that there are practical reasons for interest in grammatical specification languages: formal specification seems important (perhaps essential) if robust large scale grammars are to be defined and maintained. Moreover, the essentially model theoretic slant on specification we propose here seems particularly well suited to this aim. Models do not in any sense &amp;quot;code&amp;quot; the LFG ontology: they take it pretty much at face value. In our view this is crucial. Formal approaches 1This paper is based upon the original formulation of LFG, that of Kaplan and Bresnan (1982), and will not discuss such later innovations as functional uncertainty. 39 to grammatical theorising should reflect linguistic intuitions as directly as possible, otherwise they run the risk of being an obstacle, not an aid, to grammar development. The approach also raises theoretical issues. The model theoretic approach to specification languages forces one to think about linguistic ontologies in a systematic way, and to locate them in a well understood mathematical space. This has at least two advantages. Firstly, it offers the prospect of meaningful comparison of linguistic frameworks. Sec</context>
<context position="24721" citStr="Kaplan and Bresnan (1982)" startWordPosition="4287" endWordPosition="4291">dle this idea in the present set up. The bulk of LFG involves stating constraints about a single model, and r is well equipped for this task, but constraining equations involve looking at the structure of other possible parse trees. (In this respect they are reminiscent of the feature specification defaults of GPSG.) The approach of the present paper has been driven by the view that (a) models capture the essence of LFG ontology, and, (b) the task of the linguist is to explain, in terms of the relations that exist within a single model, what grammatical structure is. Most of the discussion in Kaplan and Bresnan (1982) is conducted in such terms. However constraining equations broaden the scope of the permitted discourse; basically, they allow implicit appeal to possible derivational structure. In short, in common with most of the grammatical formalisms with which we are familiar, LFG seems to have a dynamic residue that resists a purely declarative analysis. What should be done? We see three possible responses. Firstly, we note that the model theoretic approach can almost certainly be extended to cover constraining equations. The move involved is analogous to the way first order logic (a so-called &apos;extensi</context>
</contexts>
<marker>Kaplan, Bresnan, 1982</marker>
<rawString>Ron Kaplan and Joan Bresnan. 1982. LexicalFunctional Grammar: A formal system for grammatical representation. In The Mental Representation of Grammatical Relations, pp. 173 – 280, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kasper</author>
<author>W Rounds</author>
</authors>
<title>The Logic of Unification in Grammar.</title>
<date>1990</date>
<journal>Linguistics and Philosophy,</journal>
<volume>13</volume>
<pages>33--58</pages>
<contexts>
<context position="16230" citStr="Kasper and Rounds (1990)" startWordPosition="2819" endWordPosition="2822">ion &apos;definition which is at all complex is that for It can be glossed as follows. Let St and St, be the path sequences through the tree corresponding to t and t&apos; respectively, and let Sf and Sf, be the path sequences through the feature structure corresponding to f and f&apos; respectively. Then t(zoomin) f t&apos; (zoomin) f&apos; is satisfied at a tree node t if there is a feature structure node w that can be reached from t by making both the transition sequence St; zoomin; S1 and the transition sequence St&apos;; zoomin; S f, . Clearly, this construct is closely related to the Kasper Rounds path equality (see Kasper and Rounds (1990)); the principle difference is that whereas the Kasper Rounds enforces path equalities within the domain of leature structures, the LFG path equality enforces equalities between the tree domain and the feature structure domain. If M, n 0 then we say that 0 is satisfied in M at n. If M, n 0 for all nodes n in M then we say that 0 is valid in M and write M = 0. Intuitively, to say that 0 is valid in M is to say that the constraint 0 holds universally; it is a completely general fact about M. As we shall see in the next section, the notion of validity has an important role to play in grammar spec</context>
</contexts>
<marker>Kasper, Rounds, 1990</marker>
<rawString>R. Kasper and W. Rounds. 1990. The Logic of Unification in Grammar. Linguistics and Philosophy, 13, pp. 33-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Moss</author>
<author>David Johnson</author>
</authors>
<title>Dynamic Interpretations of Constraint-Based Grammar Formalisms.</title>
<date>1994</date>
<journal>Journal of Logic, Language and Information.</journal>
<note>To appear in</note>
<contexts>
<context position="26544" citStr="Moss and Johnson (1994)" startWordPosition="4583" endWordPosition="4586">s for default and non-monotonic reasoning. This first response seems to be a very promising line of work: the requisite tools are there, and the approach would tackle a full blooded version of LFG head on. The drawback is the complexity it introduces into an (up till now) quite simple story. Is such additional complexity really needed? A second response is to admit that there is a dynamic residue, but to deal with it in overtly computational terms. In particular, it may be possible to augment our approach with an explicit operational semantics, perhaps the evolving algebra approach adopted by Moss and Johnson (1994). Their approach is attractive, because it permits a computational treatment of dynamism that abstracts from low level algorithmic details. In short, the second strategy is a &apos;divide and conquer&apos; strategy: treat structural issues using model theoretic tools, and procedural issues with (revealing) computational tools. It&apos;s worth remarking that this second response is not incompatible with the first; it is common to provide programming languages with both a denotational and an operational semantics. The third strategy is both simpler and more speculative. While it certainly seems to be the case </context>
</contexts>
<marker>Moss, Johnson, 1994</marker>
<rawString>Lawrence Moss and David Johnson. 1994. Dynamic Interpretations of Constraint-Based Grammar Formalisms. To appear in Journal of Logic, Language and Information.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>