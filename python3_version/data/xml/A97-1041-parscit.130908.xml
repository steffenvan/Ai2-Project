<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.010561">
<title confidence="0.948799">
Language Generation for Multimedia Healthcare Briefings
</title>
<author confidence="0.948949">
Kathleen R. McKeown
Shimei Pan and James Shaw
</author>
<affiliation confidence="0.9961805">
Dept. of Computer Science
Columbia University
</affiliation>
<address confidence="0.992508">
New York, NY 10027, USA
</address>
<email confidence="0.999657">
kathy,pan,shaw@cs.columbia.edu
</email>
<sectionHeader confidence="0.994819" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999741705882353">
This paper identifies issues for language
generation that arose in developing a
multimedia interface to healthcare data
that includes coordinated speech, text
and graphics. In order to produce brief
speech for time-pressured caregivers, the
system both combines related informa-
tion into a single sentence and uses ab-
breviated references in speech when an
unambiguous textual reference is also
used. Finally, due to the temporal nature
of the speech, the language generation
module needs to communicate informa-
tion about the ordering and duration of
references to other temporal media, such
as graphics, in order to allow for coordi-
nation between media.
</bodyText>
<sectionHeader confidence="0.998784" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999927473684211">
In a hospital setting it can be difficult for care-
givers to obtain needed information about patients
in a timely fashion. In a Cardiac Intensive Care
Unit (ICU), communication regarding patient sta-
tus is critical during the hour immediately follow-
ing a coronary arterial bypass graft (CABG). It
is at this critical point, when care is being trans-
ferred from the Operating Room (OR) to the ICU
and monitoring is at a minimum, that the pa-
tient is most vulnerable to delays in treatment.
During this time, there are a number of care-
givers who need information about patient status
and plans for care, including the ICU nurses who
must prepare for patient arrival, the cardiologist
who is off-site during the operation, and residents
and attendings who will aid in determining post-
operative care. The only people who can provide
this information are those who were present dur-
ing surgery and they are often too busy attending
</bodyText>
<note confidence="0.8965285">
Desmond A. Jordan*
Barry A. Allen**
</note>
<affiliation confidence="0.93751075">
Dept. of Anesthesiology* and
Medical Informatics Dept.**
College of Physicians and Surgeons
Columbia University
</affiliation>
<address confidence="0.927406">
New York, NY 10032
</address>
<bodyText confidence="0.999120230769231">
to the patient to communicate much detail.
To address this need, we are developing a mul-
timedia briefing system, MAGIC (Multimedia Ab-
stract Generation for Intensive Care), that takes
as input online data collected during the surgical
operation as well as information stored in the main
databases at Columbia Presbyterian Medical Cen-
ter (Roderer and Clayton, 1992). MAGIC gener-
ates a multimedia briefing that integrates speech,
text, and animated graphics to provide an update
on patient status (Dalal et al., 1996a). In this pa-
per, we describe the issues that arise for language
generation in this context:
</bodyText>
<listItem confidence="0.9895834375">
• Conciseness: The generation process must
make coordinated use of speech and text to
produce an overview that is short enough for
time pressured caregivers to follow, but un-
ambiguous in meaning.
• Media specific tailoring: Generation must
take into account that one output medium is
speech, as opposed to the more usual writ-
ten language, producing wording and sen-
tence structure appropriate for spoken lan-
guage.
• Coordination with other media: The lan-
guage generation process must produce
enough information so that speech and text
can be coordinated with the accompanying
graphics.
</listItem>
<bodyText confidence="0.9853728">
In the following sections, we first provide an
overview of the full MAGIC architecture and then
describe the specific language generation issues
that we address. We close with a discussion of
our current directions.
</bodyText>
<sectionHeader confidence="0.630227" genericHeader="method">
2 System Overview
</sectionHeader>
<bodyText confidence="0.675187">
MAGIC&apos;s architecture is shown in Figure 1.
MAGIC exploits the extensive online data avail-
</bodyText>
<page confidence="0.990247">
277
</page>
<figure confidence="0.998808142857143">
Graphics Generator
Semantic
Component
Hypotactic
Component
Paratactic,&apos;
Component
</figure>
<figureCaption confidence="0.951796">
Figure 1: MAGIC system architecture.
</figureCaption>
<figure confidence="0.996606153846154">
.51n3Ch
Media
Cool-dint/tor
If
SURGEAT&amp;T
TTS
Medical
Databases
Data Servos-,
Des Fitter
General
Content
Planner
</figure>
<bodyText confidence="0.99667805882353">
able through Columbia Presbyterian Medical Cen-
ter (CPMC) as its source of content for its brief-
ing. Operative events during surgery are moni-
tored through the LifeLog database system (Mod-
ular Instruments Inc.), which polls medical de-
vices (ventilators, pressure monitors and alike) ev-
ery minute from the start of the case to the end
recording information such as vital signs. In ad-
dition, physicians (anesthesiologist and anesthe-
sia residents) enter data throughout the course of
the patient&apos;s surgery, including start of cardiopul-
monary bypass and end of bypass as well as sub-
jective clinical factors such as heart sounds and
breath sounds that cannot be retrieved by med-
ical devices. In addition, CPMC main databases
provide information from the online patient record
(e.g., medical history).
From this large body of information, the data
filter selects information that is relevant to the
bypass surgery and patient care in the ICU.
MAGIC&apos;s content planner then uses a multimedia
plan to select and partially order information for
the presentation, taking into account the caregiver
the briefing is intended for (nurse or physician).
The media allocator allocates content to media,
and finally, the media specific generators realize
content in their own specific media (see (Zhou and
Feiner, 1997) for details on the graphics genera-
tor). A media coordinator is responsible for en-
suring that spoken output and animated graphics
are temporally coordinated.
Within this context, the speech generator re-
ceives as input a partially ordered conceptual rep-
resentation of information to be communicated.
The generator includes a micro-planner, which is
responsible for ordering and grouping information
into sentences. Our approach to micro-planning
integrates a variety of different types of operators
for aggregation information within a single sen-
tence. Aggregation using semantic operators is
enabled through access to the underlying domain
hierarchy, while aggregation using linguistic op-
erators (e.g., hypotactic operators, which add in-
formation using modifiers such as adjectives, and
paratactic operators which create, for example,
conjunctions) is enabled through lookahead to the
lexicon used during realization.
The speech generator also includes a re-
alization component, implemented using the
FUF/SURGE sentence generator (Elhadad, 1992;
Robin, 1994), which produces the actual language
to be spoken as well as textual descriptions that
are used as labels in the visual presentation. It
performs lexical choice and syntactic realization.
Our version of the FUF/SURGE sentence gener-
ator produces sentences annotated with prosodic
information and pause durations. This output is
sent to a speech synthesizer in order to produce
final speech. (Currently, we are using AT&amp;T Bell
Laboratories&apos; Text To Speech System).
Our use of speech as an output medium pro-
vides an eyes-free environment that allows care-
givers the opportunity to turn away from the dis-
play and continue carrying out tasks involving pa-
tient care. Speech can also clarify graphical con-
ventions without requiring the user to look away
from the graphics to read an associated text. Cur-
rently, communication between OR caregivers and
</bodyText>
<page confidence="0.984337">
278
</page>
<bodyText confidence="0.9996038">
ICU caregivers is carried out orally in the ICU
when the patient is brought in. Thus, the use
of speech within MAGIC models current practice.
Future planned evaluations will examine caregiver
satisfaction with the spoken medium versus text.
</bodyText>
<sectionHeader confidence="0.99345" genericHeader="method">
3 Issues for Language Generation
</sectionHeader>
<bodyText confidence="0.9999916">
In the early stages of system development, a pri-
mary constraint on the language generation pro-
cess was identified during an informal evalua-
tion with ICU nurses and residents (Dalal et al.,
1996a). Due to time constraints in carrying out
tasks, nurses, in particular, noted that speech
takes time and therefore, spoken language output
should be brief and to the point, while text, which
is used to annotate the graphical illustration, may
provide unambiguous references to the equipment
and drugs being used. In the following sections,
we show how we meet this constraint both in the
speech content planner, which organizes the con-
tent as sentences, and in the speech sentence gen-
erator, which produces actual language.
In all of the language generation components,
the fact that spoken language is the output
medium and not written language, influences how
generation is carried out. We note this influence
on the generation process throughout the section.
An example showing the spoken output for a
given patient and a screen shot at a single point
in the briefing is shown in Figure 3.
In actual output, sentences are coordinated
with the corresponding part of the graphical illus-
tration using highlighting and other graphical ac-
tions. In the paper, we show the kinds of modifica-
tions that it was necessary to make to the language
generator in order to allow the media coordinator
to synchronize speech with changing graphics.
</bodyText>
<subsectionHeader confidence="0.998776">
3.1 Speech Micro-Planner
</subsectionHeader>
<bodyText confidence="0.999473666666667">
The speech micro-planner is given as input a set
of information that must be conveyed. In order to
ensure that speech is brief and yet still conveys the
necessary information, the speech micro-planner
attempts to fit more information into individual
sentences, thereby using fewer words.
Out of the set of propositions given as input,
the micro-planner selects one proposition to start
with. It attempts to include as many other propo-
sitions as it can as adjectives or other modifiers
of information already included. To do this, from
the remaining propositions, it selects a proposition
which is related to one of the propositions already
selected via its arguments. It then checks whether
it can be lexicalized as a modifier by looking ahead
</bodyText>
<figure confidence="0.831197777777778">
S. Jones
MRS: 4433667 History: Tispertemian Surgeon: Dr, Smith
ISAMU. Operatien:CMIG
Age, PO
Grader Feumle
Swan-Gam with Carats
Venhindur Atermaker
Peripheral IV
Belo. Plov
</figure>
<figureCaption confidence="0.775264416666667">
Voice: Ms. Jones is an 80 year old, hypertensive, dia-
betic, female patient of Dr. Smith undergoing CABG.
Presently, she is 30 minutes post-bypass and will ar-
rive in the unit shortly. The existing infusion lines
are two IVs, an arterial line, and a Swan-Ganz with
Cordis. The patient has received massive vasotonic
therapy, massive cardiotonic therapy, and massive-
volume blood-replacement therapy. Drips in proto-
col concentrations are nitroglycerin, levophed, dobu-
tamine, epinephrine, and inocor...
Figure 2: Multimedia presentation generated by
MAGIC
</figureCaption>
<bodyText confidence="0.999557461538461">
to the lexicon used by the lexical chooser to deter-
mine if such a choice exists. The syntactic con-
straint is recorded in the intermediate form, but
the lexical chooser may later decide to realize the
proposition by any word of the same syntactic cat-
egory or transform a modifier and a noun into a
semantic equivalent noun or noun phrase.
The micro-planner uses information from the
lexicon to determine how to combine the propo-
sitions together while satisfying grammatical and
lexical constraints. Semantic aggregation is the
first category of operators applied to the set of re-
lated propositions in order to produce concise ex-
pressions, as shown in lower portion of Fig. 1. Us-
ing ontological and lexical information, it can re-
duce the number of propositions by replacing them
with fewer propositions with equivalent meanings.
While carrying out hypotactic aggregation opera-
tors, a current central proposition is selected and
the system searches through the un-aggregated
propositions to find those that can be realized
as adjectives, prepositional phrases and relative
clauses, and merges them in. After hypotactic ag-
gregation, the un-aggregated propositions are then
combined using paratactic operators, such as ap-
positions or coordinations.
</bodyText>
<table confidence="0.55505075">
Swan-Gam:
PAD 1.1
Peri here! TV
trictiel Line
</table>
<page confidence="0.927875">
279
</page>
<tableCaption confidence="0.804860222222222">
X is a patient.
X has property last name = Jones.
X has property age = 80 years old.
X has property history = hypertension property.
X has property history = diabetes property.
X has property gender = female.
X has property surgery = CABG.
X has property doctor = Y.
Y has property last name = Smith.
</tableCaption>
<figureCaption confidence="0.560439">
Figure 3: propositions for the first sentence
In the first sentence of the example output, the
micro-planner has combined the 9 input proposi-
tions shown above in Figure 3 into a single sen-
tence: Ms Jones is an 80 year old hypertensive,
diabetic female patient of Dr. Smith undergoing
CABG. In this example this is possible, in part be-
cause the patient&apos;s medical history (diabetes and
hypertension) can be realized as adjectives. In
another example, &amp;quot;Mr. Smith is a 60 year old
male patient of Dr. Jordan undergoing CABG.
He has a medical history of transient ischemic
attacks, pulmonary hypertension, and peptic ul-
cers.&amp;quot;, the medical history can only be realized
as noun phrases, thus requiring a second sentence
and necessarily, more words.
</figureCaption>
<subsectionHeader confidence="0.99963">
3.2 Speech Sentence Generator
</subsectionHeader>
<bodyText confidence="0.999824021276596">
The speech sentence generator also contributes to
the goal of keeping spoken output brief, but in-
formative. In particular, through its lexical choice
component, it selects references to medical con-
cepts that are shorter and more colloquial than
the text counterpart. As long as the text label
on the screen is generated using the full, unam-
biguous reference, speech can use an abbreviated
expression. For example, when referring to the de-
vices which have been implanted, speech can use
the term &amp;quot;pacemaker&amp;quot; so long as the textual label
specifies it as &amp;quot;ventricular pacemaker&amp;quot;. Similarly,
MAGIC uses &amp;quot;balloon pump&amp;quot; in speech instead
of &amp;quot;intra-aortic balloon pump&amp;quot;, which is already
shown on the screen.
In order to do this, lexical choice in both me-
dia must be coordinated. Lexical choice for text
always selects the full reference, but lexical choice
for speech must check what expression the text
generator is using. Basically, the speech lexical
chooser must check what attributes the text gen-
erator includes in its reference and omit those.
Finally, we suspect that the syntactic structure
of sentences generated for spoken output should be
simpler than that generated for written language.
This hypothesis is in conflict with our criteria for
generating as few sentences as possible, which of-
ten results in more complex sentences. This is
in part acceptable due to the fact that MAGIC&apos;s
output is closer to formal speech, such as one
might find in a radio show, as opposed to infor-
mal conversation. It is, after all, a planned one-
way presentation. In order to make the generated
sentences more comprehensible, however, we have
modified the lexical chooser and syntactic gener-
ator to produce pauses at complex constitutions
to increase intelligibility of the output. Currently,
we are using a pause prediction algorithm which
utilizes the sentence&apos;s semantic structure, syntac-
tic structure as well as the linear phrase length
constraint to predict the pause position and rela-
tive strength. Our current work involves modify-
ing the FUF/SURGE language generation package
so that it can produce prosodic and pause infor-
mation needed as input to a speech synthesizer, to
produce a generic spoken language sentence gen-
erator.
</bodyText>
<subsectionHeader confidence="0.998494">
3.3 Producing Information for Media
Coordination
</subsectionHeader>
<bodyText confidence="0.989574225806452">
Language generation in MAGIC is also affected
by the fact that language is used in the context
of other media as well. While there are specific
modules in MAGIC whose task is concerned with
utilizing multiple media, media coordination af-
fects the language generation process also. In par-
ticular, in order to produce a coordinated presen-
tation, MAGIC must temporally coordinate spo-
ken language with animated graphics, both tem-
poral media. This means that spoken references
must be coordinated with graphical references to
the same information. Graphical references may
include highlighting of the portion of the illustra-
tion which refers to the same information as speech
or appearance of new information on the screen.
Temporal coordination involves two problems: en-
suring that ordering of spoken references to infor-
mation is compatible with spatial ordering of the
graphical actions and synchronizing the duration
of spoken and graphical references (Dalai et al.,
1996b).
In order to achieve this, language generation
must provide a partial ordering of spoken refer-
ences at a fairly early point in the generation pro-
cess. This ordering indicates its preference for how
spoken references are to be ordered in the output
linear speech in accordance with both graphical
and presentation constraints. For example, in the
first sentence of the example shown in Figure 3,
the speech components have a preference for med-
ical history (i.e., &amp;quot;hypertensive, diabetic&amp;quot;) to be
</bodyText>
<page confidence="0.984854">
280
</page>
<bodyText confidence="0.999945433333333">
presented before information about the surgeon, as
this allows for more concise output. It would be
possible for medical history to be presented after
all other information in the sentence by generat-
ing a separate sentence (e.g., &amp;quot;She has a history
of hypertension and diabetes.&amp;quot;) but this is less
preferable from the language point of view. In our
work, we have modified the structure of the lexical
chooser so that it can record its decisions about or-
dering, using partial ordering for any grammatical
variation that may happen later when the final
syntactic structure of the sentence is generated.
These are then sent to the media coordinator for
negotiating with graphics an ordering that is com-
patible to both. Details on the implementation
of this negotiation are presented in (Dalal et al.,
1996b) and (Pan and McKeown, 1996).
In order to synchronize duration of the spo-
ken and graphical references, the lexical chooser
invokes the speech synthesizer to calculate the du-
ration of each lexical phrase that it generates. By
maintaining a correspondence between the refer-
ential string generated and the concepts that those
referential actions refer to, negotiation with graph-
ics has a common basis for communication. In
order to provide for more flexible synchronization,
the speech sentence generator includes facilities for
modifying pauses if conflicts with graphics dura-
tions arise (see (Pan and McKeown, 1996) for de-
tails).
</bodyText>
<sectionHeader confidence="0.999864" genericHeader="method">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999982466666667">
There is considerable interest in producing fluent
and concise sentences. EPICURE (Dale, 1992),
PLANDoc(Kukich et al., 1994; Shaw, 1995), and
systems developed by Dalianis and Hovy (Dalia-
nis and Hovy, 1993) all use various forms of con-
junction and ellipsis to generate more concise sen-
tences. In (Horacek, 1992) aggregation is per-
formed at text-structure level. In addition to con-
joining VP and NPs, FLowDoc(Passonneau et
al., 1996) uses ontological generalization to com-
bine descriptions of a set of objects into a more
general description. Based on a corpus analy-
sis in the basketball domain, (Robin, 1994) cat-
alogued a set of revision operators such as adjoin
and nominalization in his system STREAK. Un-
like STREAK, MAGIC does not use revision to
combine information in a sentence.
Generating spoken language from meanings or
concepts (Meaning to Speech, MTS) is a new topic
and only a few such systems were developed in
recent years. In (Prevost, 1995) and (Steedman,
1996), they explore a way to generate spoken lan-
guage with accurate contrastive stress based on in-
formation structure and carefully modeled domain
knowledge. In (Davis and Hirschberg, 1988), spo-
ken directions are generated with richer intonation
features. Both of these systems took advantage of
the richer and more precise semantic information
that is available during the process of Meaning to
Speech production.
</bodyText>
<sectionHeader confidence="0.9949925" genericHeader="method">
5 Conclusions and Current
Directions
</sectionHeader>
<bodyText confidence="0.9999625">
The context of multimedia briefings for access to
healthcare data places new demands on the lan-
guage generation process. Language generation in
MAGIC addresses its user&apos;s needs for a brief, yet
unambiguous, briefing by coordinating spoken lan-
guage with the accompanying textual references in
the graphical illustration and by combining infor-
mation into fewer sentences. It also must explicitly
represent its decisions as it generates a sentence in
order to provide information to the media coordi-
nator for negotiation with graphics.
Our development of MAGIC is very much an
ongoing research project. We are continuing to
work on improved coordination of media, use of
the syntactic and semantic structure of generated
language to improve the quality of the synthesized
speech, and analysis of a corpus of radio speech to
identify characteristics of formal, spoken language.
</bodyText>
<sectionHeader confidence="0.999252" genericHeader="conclusions">
6 Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998999375">
MAGIC is a joint project which involves the Nat-
ural Language Processing group (the authors),
the Graphics and User Interface group (Steve
Feiner, Michelle Zhou and Tobias Hollerer), the
Knowledge Representation group (Mukesh Dalal
and Yong Feng) in the Department of Com-
puter Science of Columbia University and Dr.
Desmond Jordan and Prof. Barry Allen at the
Columbia College of Physicians and Surgeons (au-
thors). This work is supported by DARPA Con-
tract DAAL01-94-K-0119, the Columbia Univer-
sity Center for Advanced Technology in High
Performance Computing and Communications in
Healthcare (funded by the New York State Sci-
ence and Technology Foundation) and NSF Grants
GER-90-2406.
</bodyText>
<page confidence="0.996047">
281
</page>
<sectionHeader confidence="0.991744" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999386577464789">
M. Dalal, S. Feiner, K. McKeown, D. Jordan,
B. Allen, and Y. alSafadi. 1996a. Magic: An
experimental system for generating multimedia
briefings about post-bypass patient status. In
Proceedings of American Medical Informatics
Association 1996 Fall.
M. Dalal, S. Feiner, K. McKeown, S. Pan,
M. Zhou, T. Hollerer, J. Shaw, Y. Feng, and
J. Fromer. 1996b. Negotiation for automated
generation of temporal multimedia presenta-
tions. In Proceedings of ACM Multimedia &apos;96.
R. Dale. 1992. Generating Referring Expressions:
Constructing Descriptions in a Domain of Ob-
jects and Processes. MIT Press, Cambridge,
MA.
H. Dalianis and E. Hovy. 1993. Aggregation in
natural language generation. In Proceedings
of the Fourth European Workshop on Natural
Language Generation, pages 67-78, Pisa, Italy.
J. Davis and J. Hirschberg. 1988. Assigning in-
tonational features in synthesized spoken dis-
course. In Proceedings of the 26th Annual
Meeting of the Association for Computational
Linguistics, pages 187-193, Buffalo, New York.
M. Elhadad. 1992. Using argumentation to con-
trol lexical choice: A functional unification-
based approach. Ph.D. thesis, Computer Sci-
ence Department, Columbia University.
H. Horacek. 1992. An integrated view of text
planning. In Aspects of Automated Natural
Language Generation, pages 29-44. Springer-
Verlag.
K. Kukich, K. McKeown, and J. Shaw. 1994.
Practical issues in automatic documentation
generation. In Proceedings of the 4th ACL
Conference on Applied Natural Language Pro-
cessing, pages 7-14, Stuttgart.
S. Pan and K. McKeown. 1996. Spoken language
generation in a multimedia system. In Proceed-
ings of ICSLP 96, volume 1, pages 374-377,
Philadelphia, PA.
R. Passonneau, K. Kukich, V. Hatzivassiloglou,
L. Lefkowitz, and H. Jing. 1996. Gener-
ating summaries of work flow diagrams. In
Proceedings of the International Conference on
Natural Language Processing and Industrial
Applications, pages 204-210, New Brunswick,
Canada, June. Univeristy of Moncton.
S. Prevost. 1995. A Semantics of Contrast and In-
formaiton Structure for Specifying Intonation
in Spoken Language Generation. Ph.D. thesis,
University of Pennsylvania.
J. Robin. 1994. Revision-Based Generation of
Natural Language Summaries Providing His-
torical Background. Ph.D. thesis, Computer
Science Department, Columbia University.
N. Roderer and P. Clayton. 1992. Iaims at
columbia presbyterian medical center: Accom-
plishments and challenges. In Bull. Am. Med.
Lib. Assoc., pages 253-262.
J. Shaw. 1995. Conciseness through aggregation
in text generation. In Proceedings of the 33rd
ACL (Student Session), pages 329-331.
M. Steedman. 1996. Representing discourse in-
formationn for spoken dialogue generation. In
Proceedings of ISSD 96, pages 89-92, Philadel-
phia, PA.
M. Zhou and S. Feiner. 1997. Top-down hier-
archical planning of coherent visual discourse.
In Proc. IUI &apos;97 (1997 Int. Conf. on Intelligent
User Interfaces), Orlando, FL, January 6-9.
</reference>
<page confidence="0.997425">
282
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.970740">
<title confidence="0.999857">Language Generation for Multimedia Healthcare Briefings</title>
<author confidence="0.996882">Kathleen R McKeown Pan Shaw</author>
<affiliation confidence="0.9999005">Dept. of Computer Science Columbia University</affiliation>
<address confidence="0.999849">New York, NY 10027, USA</address>
<email confidence="0.999849">kathy,pan,shaw@cs.columbia.edu</email>
<abstract confidence="0.998742333333333">This paper identifies issues for language generation that arose in developing a multimedia interface to healthcare data that includes coordinated speech, text and graphics. In order to produce brief speech for time-pressured caregivers, the system both combines related information into a single sentence and uses abbreviated references in speech when an unambiguous textual reference is also used. Finally, due to the temporal nature of the speech, the language generation module needs to communicate information about the ordering and duration of references to other temporal media, such as graphics, in order to allow for coordination between media.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Dalal</author>
<author>S Feiner</author>
<author>K McKeown</author>
<author>D Jordan</author>
<author>B Allen</author>
<author>Y alSafadi</author>
</authors>
<title>Magic: An experimental system for generating multimedia briefings about post-bypass patient status.</title>
<date>1996</date>
<booktitle>In Proceedings of American Medical Informatics Association</booktitle>
<note>Fall.</note>
<contexts>
<context position="2482" citStr="Dalal et al., 1996" startWordPosition="387" endWordPosition="390">nd Medical Informatics Dept.** College of Physicians and Surgeons Columbia University New York, NY 10032 to the patient to communicate much detail. To address this need, we are developing a multimedia briefing system, MAGIC (Multimedia Abstract Generation for Intensive Care), that takes as input online data collected during the surgical operation as well as information stored in the main databases at Columbia Presbyterian Medical Center (Roderer and Clayton, 1992). MAGIC generates a multimedia briefing that integrates speech, text, and animated graphics to provide an update on patient status (Dalal et al., 1996a). In this paper, we describe the issues that arise for language generation in this context: • Conciseness: The generation process must make coordinated use of speech and text to produce an overview that is short enough for time pressured caregivers to follow, but unambiguous in meaning. • Media specific tailoring: Generation must take into account that one output medium is speech, as opposed to the more usual written language, producing wording and sentence structure appropriate for spoken language. • Coordination with other media: The language generation process must produce enough informat</context>
<context position="7389" citStr="Dalal et al., 1996" startWordPosition="1141" endWordPosition="1144">nventions without requiring the user to look away from the graphics to read an associated text. Currently, communication between OR caregivers and 278 ICU caregivers is carried out orally in the ICU when the patient is brought in. Thus, the use of speech within MAGIC models current practice. Future planned evaluations will examine caregiver satisfaction with the spoken medium versus text. 3 Issues for Language Generation In the early stages of system development, a primary constraint on the language generation process was identified during an informal evaluation with ICU nurses and residents (Dalal et al., 1996a). Due to time constraints in carrying out tasks, nurses, in particular, noted that speech takes time and therefore, spoken language output should be brief and to the point, while text, which is used to annotate the graphical illustration, may provide unambiguous references to the equipment and drugs being used. In the following sections, we show how we meet this constraint both in the speech content planner, which organizes the content as sentences, and in the speech sentence generator, which produces actual language. In all of the language generation components, the fact that spoken languag</context>
<context position="17029" citStr="Dalal et al., 1996" startWordPosition="2691" endWordPosition="2694">ence by generating a separate sentence (e.g., &amp;quot;She has a history of hypertension and diabetes.&amp;quot;) but this is less preferable from the language point of view. In our work, we have modified the structure of the lexical chooser so that it can record its decisions about ordering, using partial ordering for any grammatical variation that may happen later when the final syntactic structure of the sentence is generated. These are then sent to the media coordinator for negotiating with graphics an ordering that is compatible to both. Details on the implementation of this negotiation are presented in (Dalal et al., 1996b) and (Pan and McKeown, 1996). In order to synchronize duration of the spoken and graphical references, the lexical chooser invokes the speech synthesizer to calculate the duration of each lexical phrase that it generates. By maintaining a correspondence between the referential string generated and the concepts that those referential actions refer to, negotiation with graphics has a common basis for communication. In order to provide for more flexible synchronization, the speech sentence generator includes facilities for modifying pauses if conflicts with graphics durations arise (see (Pan an</context>
</contexts>
<marker>Dalal, Feiner, McKeown, Jordan, Allen, alSafadi, 1996</marker>
<rawString>M. Dalal, S. Feiner, K. McKeown, D. Jordan, B. Allen, and Y. alSafadi. 1996a. Magic: An experimental system for generating multimedia briefings about post-bypass patient status. In Proceedings of American Medical Informatics Association 1996 Fall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dalal</author>
<author>S Feiner</author>
<author>K McKeown</author>
<author>S Pan</author>
<author>M Zhou</author>
<author>T Hollerer</author>
<author>J Shaw</author>
<author>Y Feng</author>
<author>J Fromer</author>
</authors>
<title>Negotiation for automated generation of temporal multimedia presentations.</title>
<date>1996</date>
<booktitle>In Proceedings of ACM Multimedia &apos;96.</booktitle>
<contexts>
<context position="2482" citStr="Dalal et al., 1996" startWordPosition="387" endWordPosition="390">nd Medical Informatics Dept.** College of Physicians and Surgeons Columbia University New York, NY 10032 to the patient to communicate much detail. To address this need, we are developing a multimedia briefing system, MAGIC (Multimedia Abstract Generation for Intensive Care), that takes as input online data collected during the surgical operation as well as information stored in the main databases at Columbia Presbyterian Medical Center (Roderer and Clayton, 1992). MAGIC generates a multimedia briefing that integrates speech, text, and animated graphics to provide an update on patient status (Dalal et al., 1996a). In this paper, we describe the issues that arise for language generation in this context: • Conciseness: The generation process must make coordinated use of speech and text to produce an overview that is short enough for time pressured caregivers to follow, but unambiguous in meaning. • Media specific tailoring: Generation must take into account that one output medium is speech, as opposed to the more usual written language, producing wording and sentence structure appropriate for spoken language. • Coordination with other media: The language generation process must produce enough informat</context>
<context position="7389" citStr="Dalal et al., 1996" startWordPosition="1141" endWordPosition="1144">nventions without requiring the user to look away from the graphics to read an associated text. Currently, communication between OR caregivers and 278 ICU caregivers is carried out orally in the ICU when the patient is brought in. Thus, the use of speech within MAGIC models current practice. Future planned evaluations will examine caregiver satisfaction with the spoken medium versus text. 3 Issues for Language Generation In the early stages of system development, a primary constraint on the language generation process was identified during an informal evaluation with ICU nurses and residents (Dalal et al., 1996a). Due to time constraints in carrying out tasks, nurses, in particular, noted that speech takes time and therefore, spoken language output should be brief and to the point, while text, which is used to annotate the graphical illustration, may provide unambiguous references to the equipment and drugs being used. In the following sections, we show how we meet this constraint both in the speech content planner, which organizes the content as sentences, and in the speech sentence generator, which produces actual language. In all of the language generation components, the fact that spoken languag</context>
<context position="17029" citStr="Dalal et al., 1996" startWordPosition="2691" endWordPosition="2694">ence by generating a separate sentence (e.g., &amp;quot;She has a history of hypertension and diabetes.&amp;quot;) but this is less preferable from the language point of view. In our work, we have modified the structure of the lexical chooser so that it can record its decisions about ordering, using partial ordering for any grammatical variation that may happen later when the final syntactic structure of the sentence is generated. These are then sent to the media coordinator for negotiating with graphics an ordering that is compatible to both. Details on the implementation of this negotiation are presented in (Dalal et al., 1996b) and (Pan and McKeown, 1996). In order to synchronize duration of the spoken and graphical references, the lexical chooser invokes the speech synthesizer to calculate the duration of each lexical phrase that it generates. By maintaining a correspondence between the referential string generated and the concepts that those referential actions refer to, negotiation with graphics has a common basis for communication. In order to provide for more flexible synchronization, the speech sentence generator includes facilities for modifying pauses if conflicts with graphics durations arise (see (Pan an</context>
</contexts>
<marker>Dalal, Feiner, McKeown, Pan, Zhou, Hollerer, Shaw, Feng, Fromer, 1996</marker>
<rawString>M. Dalal, S. Feiner, K. McKeown, S. Pan, M. Zhou, T. Hollerer, J. Shaw, Y. Feng, and J. Fromer. 1996b. Negotiation for automated generation of temporal multimedia presentations. In Proceedings of ACM Multimedia &apos;96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
</authors>
<title>Generating Referring Expressions: Constructing Descriptions in a Domain of Objects and Processes.</title>
<date>1992</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="17769" citStr="Dale, 1992" startWordPosition="2806" endWordPosition="2807">kes the speech synthesizer to calculate the duration of each lexical phrase that it generates. By maintaining a correspondence between the referential string generated and the concepts that those referential actions refer to, negotiation with graphics has a common basis for communication. In order to provide for more flexible synchronization, the speech sentence generator includes facilities for modifying pauses if conflicts with graphics durations arise (see (Pan and McKeown, 1996) for details). 4 Related Work There is considerable interest in producing fluent and concise sentences. EPICURE (Dale, 1992), PLANDoc(Kukich et al., 1994; Shaw, 1995), and systems developed by Dalianis and Hovy (Dalianis and Hovy, 1993) all use various forms of conjunction and ellipsis to generate more concise sentences. In (Horacek, 1992) aggregation is performed at text-structure level. In addition to conjoining VP and NPs, FLowDoc(Passonneau et al., 1996) uses ontological generalization to combine descriptions of a set of objects into a more general description. Based on a corpus analysis in the basketball domain, (Robin, 1994) catalogued a set of revision operators such as adjoin and nominalization in his syste</context>
</contexts>
<marker>Dale, 1992</marker>
<rawString>R. Dale. 1992. Generating Referring Expressions: Constructing Descriptions in a Domain of Objects and Processes. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Dalianis</author>
<author>E Hovy</author>
</authors>
<title>Aggregation in natural language generation.</title>
<date>1993</date>
<booktitle>In Proceedings of the Fourth European Workshop on Natural Language Generation,</booktitle>
<pages>67--78</pages>
<location>Pisa, Italy.</location>
<contexts>
<context position="17881" citStr="Dalianis and Hovy, 1993" startWordPosition="2821" endWordPosition="2825">aintaining a correspondence between the referential string generated and the concepts that those referential actions refer to, negotiation with graphics has a common basis for communication. In order to provide for more flexible synchronization, the speech sentence generator includes facilities for modifying pauses if conflicts with graphics durations arise (see (Pan and McKeown, 1996) for details). 4 Related Work There is considerable interest in producing fluent and concise sentences. EPICURE (Dale, 1992), PLANDoc(Kukich et al., 1994; Shaw, 1995), and systems developed by Dalianis and Hovy (Dalianis and Hovy, 1993) all use various forms of conjunction and ellipsis to generate more concise sentences. In (Horacek, 1992) aggregation is performed at text-structure level. In addition to conjoining VP and NPs, FLowDoc(Passonneau et al., 1996) uses ontological generalization to combine descriptions of a set of objects into a more general description. Based on a corpus analysis in the basketball domain, (Robin, 1994) catalogued a set of revision operators such as adjoin and nominalization in his system STREAK. Unlike STREAK, MAGIC does not use revision to combine information in a sentence. Generating spoken lan</context>
</contexts>
<marker>Dalianis, Hovy, 1993</marker>
<rawString>H. Dalianis and E. Hovy. 1993. Aggregation in natural language generation. In Proceedings of the Fourth European Workshop on Natural Language Generation, pages 67-78, Pisa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Davis</author>
<author>J Hirschberg</author>
</authors>
<title>Assigning intonational features in synthesized spoken discourse.</title>
<date>1988</date>
<booktitle>In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>187--193</pages>
<location>Buffalo, New York.</location>
<contexts>
<context position="18836" citStr="Davis and Hirschberg, 1988" startWordPosition="2978" endWordPosition="2981">iption. Based on a corpus analysis in the basketball domain, (Robin, 1994) catalogued a set of revision operators such as adjoin and nominalization in his system STREAK. Unlike STREAK, MAGIC does not use revision to combine information in a sentence. Generating spoken language from meanings or concepts (Meaning to Speech, MTS) is a new topic and only a few such systems were developed in recent years. In (Prevost, 1995) and (Steedman, 1996), they explore a way to generate spoken language with accurate contrastive stress based on information structure and carefully modeled domain knowledge. In (Davis and Hirschberg, 1988), spoken directions are generated with richer intonation features. Both of these systems took advantage of the richer and more precise semantic information that is available during the process of Meaning to Speech production. 5 Conclusions and Current Directions The context of multimedia briefings for access to healthcare data places new demands on the language generation process. Language generation in MAGIC addresses its user&apos;s needs for a brief, yet unambiguous, briefing by coordinating spoken language with the accompanying textual references in the graphical illustration and by combining i</context>
</contexts>
<marker>Davis, Hirschberg, 1988</marker>
<rawString>J. Davis and J. Hirschberg. 1988. Assigning intonational features in synthesized spoken discourse. In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics, pages 187-193, Buffalo, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Elhadad</author>
</authors>
<title>Using argumentation to control lexical choice: A functional unificationbased approach.</title>
<date>1992</date>
<tech>Ph.D. thesis,</tech>
<institution>Computer Science Department, Columbia University.</institution>
<contexts>
<context position="6061" citStr="Elhadad, 1992" startWordPosition="929" endWordPosition="930">micro-planning integrates a variety of different types of operators for aggregation information within a single sentence. Aggregation using semantic operators is enabled through access to the underlying domain hierarchy, while aggregation using linguistic operators (e.g., hypotactic operators, which add information using modifiers such as adjectives, and paratactic operators which create, for example, conjunctions) is enabled through lookahead to the lexicon used during realization. The speech generator also includes a realization component, implemented using the FUF/SURGE sentence generator (Elhadad, 1992; Robin, 1994), which produces the actual language to be spoken as well as textual descriptions that are used as labels in the visual presentation. It performs lexical choice and syntactic realization. Our version of the FUF/SURGE sentence generator produces sentences annotated with prosodic information and pause durations. This output is sent to a speech synthesizer in order to produce final speech. (Currently, we are using AT&amp;T Bell Laboratories&apos; Text To Speech System). Our use of speech as an output medium provides an eyes-free environment that allows caregivers the opportunity to turn away</context>
</contexts>
<marker>Elhadad, 1992</marker>
<rawString>M. Elhadad. 1992. Using argumentation to control lexical choice: A functional unificationbased approach. Ph.D. thesis, Computer Science Department, Columbia University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Horacek</author>
</authors>
<title>An integrated view of text planning.</title>
<date>1992</date>
<journal>In Aspects of Automated Natural Language Generation,</journal>
<pages>29--44</pages>
<publisher>SpringerVerlag.</publisher>
<contexts>
<context position="17986" citStr="Horacek, 1992" startWordPosition="2842" endWordPosition="2843">s refer to, negotiation with graphics has a common basis for communication. In order to provide for more flexible synchronization, the speech sentence generator includes facilities for modifying pauses if conflicts with graphics durations arise (see (Pan and McKeown, 1996) for details). 4 Related Work There is considerable interest in producing fluent and concise sentences. EPICURE (Dale, 1992), PLANDoc(Kukich et al., 1994; Shaw, 1995), and systems developed by Dalianis and Hovy (Dalianis and Hovy, 1993) all use various forms of conjunction and ellipsis to generate more concise sentences. In (Horacek, 1992) aggregation is performed at text-structure level. In addition to conjoining VP and NPs, FLowDoc(Passonneau et al., 1996) uses ontological generalization to combine descriptions of a set of objects into a more general description. Based on a corpus analysis in the basketball domain, (Robin, 1994) catalogued a set of revision operators such as adjoin and nominalization in his system STREAK. Unlike STREAK, MAGIC does not use revision to combine information in a sentence. Generating spoken language from meanings or concepts (Meaning to Speech, MTS) is a new topic and only a few such systems were </context>
</contexts>
<marker>Horacek, 1992</marker>
<rawString>H. Horacek. 1992. An integrated view of text planning. In Aspects of Automated Natural Language Generation, pages 29-44. SpringerVerlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kukich</author>
<author>K McKeown</author>
<author>J Shaw</author>
</authors>
<title>Practical issues in automatic documentation generation.</title>
<date>1994</date>
<booktitle>In Proceedings of the 4th ACL Conference on Applied Natural Language Processing,</booktitle>
<pages>7--14</pages>
<location>Stuttgart.</location>
<contexts>
<context position="17798" citStr="Kukich et al., 1994" startWordPosition="2808" endWordPosition="2811">sizer to calculate the duration of each lexical phrase that it generates. By maintaining a correspondence between the referential string generated and the concepts that those referential actions refer to, negotiation with graphics has a common basis for communication. In order to provide for more flexible synchronization, the speech sentence generator includes facilities for modifying pauses if conflicts with graphics durations arise (see (Pan and McKeown, 1996) for details). 4 Related Work There is considerable interest in producing fluent and concise sentences. EPICURE (Dale, 1992), PLANDoc(Kukich et al., 1994; Shaw, 1995), and systems developed by Dalianis and Hovy (Dalianis and Hovy, 1993) all use various forms of conjunction and ellipsis to generate more concise sentences. In (Horacek, 1992) aggregation is performed at text-structure level. In addition to conjoining VP and NPs, FLowDoc(Passonneau et al., 1996) uses ontological generalization to combine descriptions of a set of objects into a more general description. Based on a corpus analysis in the basketball domain, (Robin, 1994) catalogued a set of revision operators such as adjoin and nominalization in his system STREAK. Unlike STREAK, MAGI</context>
</contexts>
<marker>Kukich, McKeown, Shaw, 1994</marker>
<rawString>K. Kukich, K. McKeown, and J. Shaw. 1994. Practical issues in automatic documentation generation. In Proceedings of the 4th ACL Conference on Applied Natural Language Processing, pages 7-14, Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pan</author>
<author>K McKeown</author>
</authors>
<title>Spoken language generation in a multimedia system.</title>
<date>1996</date>
<booktitle>In Proceedings of ICSLP 96,</booktitle>
<volume>1</volume>
<pages>374--377</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="17059" citStr="Pan and McKeown, 1996" startWordPosition="2696" endWordPosition="2699">ate sentence (e.g., &amp;quot;She has a history of hypertension and diabetes.&amp;quot;) but this is less preferable from the language point of view. In our work, we have modified the structure of the lexical chooser so that it can record its decisions about ordering, using partial ordering for any grammatical variation that may happen later when the final syntactic structure of the sentence is generated. These are then sent to the media coordinator for negotiating with graphics an ordering that is compatible to both. Details on the implementation of this negotiation are presented in (Dalal et al., 1996b) and (Pan and McKeown, 1996). In order to synchronize duration of the spoken and graphical references, the lexical chooser invokes the speech synthesizer to calculate the duration of each lexical phrase that it generates. By maintaining a correspondence between the referential string generated and the concepts that those referential actions refer to, negotiation with graphics has a common basis for communication. In order to provide for more flexible synchronization, the speech sentence generator includes facilities for modifying pauses if conflicts with graphics durations arise (see (Pan and McKeown, 1996) for details).</context>
</contexts>
<marker>Pan, McKeown, 1996</marker>
<rawString>S. Pan and K. McKeown. 1996. Spoken language generation in a multimedia system. In Proceedings of ICSLP 96, volume 1, pages 374-377, Philadelphia, PA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R Passonneau</author>
<author>K Kukich</author>
<author>V Hatzivassiloglou</author>
</authors>
<marker>Passonneau, Kukich, Hatzivassiloglou, </marker>
<rawString>R. Passonneau, K. Kukich, V. Hatzivassiloglou,</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lefkowitz</author>
<author>H Jing</author>
</authors>
<title>Generating summaries of work flow diagrams.</title>
<date>1996</date>
<booktitle>In Proceedings of the International Conference on Natural Language Processing and Industrial Applications,</booktitle>
<pages>204--210</pages>
<institution>Univeristy of Moncton.</institution>
<location>New Brunswick, Canada,</location>
<marker>Lefkowitz, Jing, 1996</marker>
<rawString>L. Lefkowitz, and H. Jing. 1996. Generating summaries of work flow diagrams. In Proceedings of the International Conference on Natural Language Processing and Industrial Applications, pages 204-210, New Brunswick, Canada, June. Univeristy of Moncton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Prevost</author>
</authors>
<title>A Semantics of Contrast and Informaiton Structure for Specifying Intonation in Spoken Language Generation.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="18631" citStr="Prevost, 1995" startWordPosition="2949" endWordPosition="2950">xt-structure level. In addition to conjoining VP and NPs, FLowDoc(Passonneau et al., 1996) uses ontological generalization to combine descriptions of a set of objects into a more general description. Based on a corpus analysis in the basketball domain, (Robin, 1994) catalogued a set of revision operators such as adjoin and nominalization in his system STREAK. Unlike STREAK, MAGIC does not use revision to combine information in a sentence. Generating spoken language from meanings or concepts (Meaning to Speech, MTS) is a new topic and only a few such systems were developed in recent years. In (Prevost, 1995) and (Steedman, 1996), they explore a way to generate spoken language with accurate contrastive stress based on information structure and carefully modeled domain knowledge. In (Davis and Hirschberg, 1988), spoken directions are generated with richer intonation features. Both of these systems took advantage of the richer and more precise semantic information that is available during the process of Meaning to Speech production. 5 Conclusions and Current Directions The context of multimedia briefings for access to healthcare data places new demands on the language generation process. Language ge</context>
</contexts>
<marker>Prevost, 1995</marker>
<rawString>S. Prevost. 1995. A Semantics of Contrast and Informaiton Structure for Specifying Intonation in Spoken Language Generation. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Robin</author>
</authors>
<title>Revision-Based Generation of Natural Language Summaries Providing Historical Background.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>Computer Science Department, Columbia University.</institution>
<contexts>
<context position="6075" citStr="Robin, 1994" startWordPosition="931" endWordPosition="932">integrates a variety of different types of operators for aggregation information within a single sentence. Aggregation using semantic operators is enabled through access to the underlying domain hierarchy, while aggregation using linguistic operators (e.g., hypotactic operators, which add information using modifiers such as adjectives, and paratactic operators which create, for example, conjunctions) is enabled through lookahead to the lexicon used during realization. The speech generator also includes a realization component, implemented using the FUF/SURGE sentence generator (Elhadad, 1992; Robin, 1994), which produces the actual language to be spoken as well as textual descriptions that are used as labels in the visual presentation. It performs lexical choice and syntactic realization. Our version of the FUF/SURGE sentence generator produces sentences annotated with prosodic information and pause durations. This output is sent to a speech synthesizer in order to produce final speech. (Currently, we are using AT&amp;T Bell Laboratories&apos; Text To Speech System). Our use of speech as an output medium provides an eyes-free environment that allows caregivers the opportunity to turn away from the disp</context>
<context position="18283" citStr="Robin, 1994" startWordPosition="2890" endWordPosition="2891">ork There is considerable interest in producing fluent and concise sentences. EPICURE (Dale, 1992), PLANDoc(Kukich et al., 1994; Shaw, 1995), and systems developed by Dalianis and Hovy (Dalianis and Hovy, 1993) all use various forms of conjunction and ellipsis to generate more concise sentences. In (Horacek, 1992) aggregation is performed at text-structure level. In addition to conjoining VP and NPs, FLowDoc(Passonneau et al., 1996) uses ontological generalization to combine descriptions of a set of objects into a more general description. Based on a corpus analysis in the basketball domain, (Robin, 1994) catalogued a set of revision operators such as adjoin and nominalization in his system STREAK. Unlike STREAK, MAGIC does not use revision to combine information in a sentence. Generating spoken language from meanings or concepts (Meaning to Speech, MTS) is a new topic and only a few such systems were developed in recent years. In (Prevost, 1995) and (Steedman, 1996), they explore a way to generate spoken language with accurate contrastive stress based on information structure and carefully modeled domain knowledge. In (Davis and Hirschberg, 1988), spoken directions are generated with richer i</context>
</contexts>
<marker>Robin, 1994</marker>
<rawString>J. Robin. 1994. Revision-Based Generation of Natural Language Summaries Providing Historical Background. Ph.D. thesis, Computer Science Department, Columbia University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Roderer</author>
<author>P Clayton</author>
</authors>
<title>Iaims at columbia presbyterian medical center: Accomplishments and challenges.</title>
<date>1992</date>
<journal>In Bull. Am. Med. Lib. Assoc.,</journal>
<pages>253--262</pages>
<contexts>
<context position="2332" citStr="Roderer and Clayton, 1992" startWordPosition="363" endWordPosition="366">his information are those who were present during surgery and they are often too busy attending Desmond A. Jordan* Barry A. Allen** Dept. of Anesthesiology* and Medical Informatics Dept.** College of Physicians and Surgeons Columbia University New York, NY 10032 to the patient to communicate much detail. To address this need, we are developing a multimedia briefing system, MAGIC (Multimedia Abstract Generation for Intensive Care), that takes as input online data collected during the surgical operation as well as information stored in the main databases at Columbia Presbyterian Medical Center (Roderer and Clayton, 1992). MAGIC generates a multimedia briefing that integrates speech, text, and animated graphics to provide an update on patient status (Dalal et al., 1996a). In this paper, we describe the issues that arise for language generation in this context: • Conciseness: The generation process must make coordinated use of speech and text to produce an overview that is short enough for time pressured caregivers to follow, but unambiguous in meaning. • Media specific tailoring: Generation must take into account that one output medium is speech, as opposed to the more usual written language, producing wording</context>
</contexts>
<marker>Roderer, Clayton, 1992</marker>
<rawString>N. Roderer and P. Clayton. 1992. Iaims at columbia presbyterian medical center: Accomplishments and challenges. In Bull. Am. Med. Lib. Assoc., pages 253-262.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Shaw</author>
</authors>
<title>Conciseness through aggregation in text generation.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd ACL (Student Session),</booktitle>
<pages>329--331</pages>
<contexts>
<context position="17811" citStr="Shaw, 1995" startWordPosition="2812" endWordPosition="2813">e duration of each lexical phrase that it generates. By maintaining a correspondence between the referential string generated and the concepts that those referential actions refer to, negotiation with graphics has a common basis for communication. In order to provide for more flexible synchronization, the speech sentence generator includes facilities for modifying pauses if conflicts with graphics durations arise (see (Pan and McKeown, 1996) for details). 4 Related Work There is considerable interest in producing fluent and concise sentences. EPICURE (Dale, 1992), PLANDoc(Kukich et al., 1994; Shaw, 1995), and systems developed by Dalianis and Hovy (Dalianis and Hovy, 1993) all use various forms of conjunction and ellipsis to generate more concise sentences. In (Horacek, 1992) aggregation is performed at text-structure level. In addition to conjoining VP and NPs, FLowDoc(Passonneau et al., 1996) uses ontological generalization to combine descriptions of a set of objects into a more general description. Based on a corpus analysis in the basketball domain, (Robin, 1994) catalogued a set of revision operators such as adjoin and nominalization in his system STREAK. Unlike STREAK, MAGIC does not us</context>
</contexts>
<marker>Shaw, 1995</marker>
<rawString>J. Shaw. 1995. Conciseness through aggregation in text generation. In Proceedings of the 33rd ACL (Student Session), pages 329-331.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>Representing discourse informationn for spoken dialogue generation.</title>
<date>1996</date>
<booktitle>In Proceedings of ISSD 96,</booktitle>
<pages>89--92</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="18652" citStr="Steedman, 1996" startWordPosition="2952" endWordPosition="2953">In addition to conjoining VP and NPs, FLowDoc(Passonneau et al., 1996) uses ontological generalization to combine descriptions of a set of objects into a more general description. Based on a corpus analysis in the basketball domain, (Robin, 1994) catalogued a set of revision operators such as adjoin and nominalization in his system STREAK. Unlike STREAK, MAGIC does not use revision to combine information in a sentence. Generating spoken language from meanings or concepts (Meaning to Speech, MTS) is a new topic and only a few such systems were developed in recent years. In (Prevost, 1995) and (Steedman, 1996), they explore a way to generate spoken language with accurate contrastive stress based on information structure and carefully modeled domain knowledge. In (Davis and Hirschberg, 1988), spoken directions are generated with richer intonation features. Both of these systems took advantage of the richer and more precise semantic information that is available during the process of Meaning to Speech production. 5 Conclusions and Current Directions The context of multimedia briefings for access to healthcare data places new demands on the language generation process. Language generation in MAGIC add</context>
</contexts>
<marker>Steedman, 1996</marker>
<rawString>M. Steedman. 1996. Representing discourse informationn for spoken dialogue generation. In Proceedings of ISSD 96, pages 89-92, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Zhou</author>
<author>S Feiner</author>
</authors>
<title>Top-down hierarchical planning of coherent visual discourse.</title>
<date>1997</date>
<booktitle>In Proc. IUI &apos;97</booktitle>
<pages>6--9</pages>
<location>Orlando, FL,</location>
<contexts>
<context position="5018" citStr="Zhou and Feiner, 1997" startWordPosition="781" endWordPosition="784">evices. In addition, CPMC main databases provide information from the online patient record (e.g., medical history). From this large body of information, the data filter selects information that is relevant to the bypass surgery and patient care in the ICU. MAGIC&apos;s content planner then uses a multimedia plan to select and partially order information for the presentation, taking into account the caregiver the briefing is intended for (nurse or physician). The media allocator allocates content to media, and finally, the media specific generators realize content in their own specific media (see (Zhou and Feiner, 1997) for details on the graphics generator). A media coordinator is responsible for ensuring that spoken output and animated graphics are temporally coordinated. Within this context, the speech generator receives as input a partially ordered conceptual representation of information to be communicated. The generator includes a micro-planner, which is responsible for ordering and grouping information into sentences. Our approach to micro-planning integrates a variety of different types of operators for aggregation information within a single sentence. Aggregation using semantic operators is enabled </context>
</contexts>
<marker>Zhou, Feiner, 1997</marker>
<rawString>M. Zhou and S. Feiner. 1997. Top-down hierarchical planning of coherent visual discourse. In Proc. IUI &apos;97 (1997 Int. Conf. on Intelligent User Interfaces), Orlando, FL, January 6-9.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>