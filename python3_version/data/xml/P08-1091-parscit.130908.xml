<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000025">
<title confidence="0.976551">
Semantic Role Labeling Systems for Arabic using Kernel Methods
</title>
<author confidence="0.995558">
Mona Diab
</author>
<affiliation confidence="0.992266">
CCLS, Columbia University
</affiliation>
<address confidence="0.966015">
New York, NY 10115, USA
</address>
<email confidence="0.998833">
mdiab@ccls.columbia.edu
</email>
<author confidence="0.981515">
Alessandro Moschitti
</author>
<affiliation confidence="0.981981">
DISI, University of Trento
</affiliation>
<address confidence="0.481016">
Trento, I-38100, Italy
</address>
<email confidence="0.9846">
moschitti@disi.unitn.it
</email>
<author confidence="0.948138">
Daniele Pighin
</author>
<affiliation confidence="0.940573">
FBK-irst; DISI, University of Trento
</affiliation>
<address confidence="0.468864">
Trento, I-38100, Italy
</address>
<email confidence="0.98907">
pighin@fbk.eu
</email>
<sectionHeader confidence="0.993783" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999597785714286">
There is a widely held belief in the natural lan-
guage and computational linguistics commu-
nities that Semantic Role Labeling (SRL) is
a significant step toward improving important
applications, e.g. question answering and in-
formation extraction. In this paper, we present
an SRL system for Modern Standard Arabic
that exploits many aspects of the rich mor-
phological features of the language. The ex-
periments on the pilot Arabic Propbank data
show that our system based on Support Vector
Machines and Kernel Methods yields a global
SRL F1 score of 82.17%, which improves the
current state-of-the-art in Arabic SRL.
</bodyText>
<sectionHeader confidence="0.998793" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999976152542373">
Shallow approaches to semantic processing are mak-
ing large strides in the direction of efficiently and
effectively deriving tacit semantic information from
text. Semantic Role Labeling (SRL) is one such ap-
proach. With the advent of faster and more power-
ful computers, more effective machine learning al-
gorithms, and importantly, large data resources an-
notated with relevant levels of semantic information,
such as the FrameNet (Baker et al., 1998) and Prob-
Bank (Kingsbury and Palmer, 2003), we are seeing
a surge in efficient approaches to SRL (Carreras and
M`arquez, 2005).
SRL is the process by which predicates and their
arguments are identified and their roles are defined
in a sentence. For example, in the English sen-
tence, ‘John likes apples.’, the predicate is ‘likes’
whereas ‘John’ and ‘apples’, bear the semantic role
labels agent (ARG0) and theme (ARG1). The cru-
cial fact about semantic roles is that regardless of
the overt syntactic structure variation, the underly-
ing predicates remain the same. Hence, for the sen-
tence ‘John opened the door’ and ‘the door opened’,
though ‘the door’ is the object of the first sentence
and the subject of the second, it is the ‘theme’ in
both sentences. Same idea applies to passive con-
structions, for example.
There is a widely held belief in the NLP and com-
putational linguistics communities that identifying
and defining roles of predicate arguments in a sen-
tence has a lot of potential for and is a significant
step toward improving important applications such
as document retrieval, machine translation, question
answering and information extraction (Moschitti et
al., 2007).
To date, most of the reported SRL systems are for
English, and most of the data resources exist for En-
glish. We do see some headway for other languages
such as German and Chinese (Erk and Pado, 2006;
Sun and Jurafsky, 2004). The systems for the other
languages follow the successful models devised for
English, e.g. (Gildea and Jurafsky, 2002; Gildea and
Palmer, 2002; Chen and Rambow, 2003; Thompson
et al., 2003; Pradhan et al., 2003; Moschitti, 2004;
Xue and Palmer, 2004; Haghighi et al., 2005). In the
same spirit and facilitated by the release of the Se-
mEval 2007 Task 18 data1, based on the Pilot Arabic
Propbank, a preliminary SRL system exists for Ara-
bic2 (Diab and Moschitti, 2007; Diab et al., 2007a).
However, it did not exploit some special character-
istics of the Arabic language on the SRL task.
In this paper, we present an SRL system for MSA
that exploits many aspects of the rich morphological
features of the language. It is based on a supervised
model that uses support vector machines (SVM)
technology (Vapnik, 1998) for argument boundary
detection and argument classification. It is trained
and tested using the pilot Arabic Propbank data re-
leased as part of the SemEval 2007 data. Given the
lack of a reliable Arabic deep syntactic parser, we
</bodyText>
<footnote confidence="0.999141">
1http://nlp.cs.swarthmore.edu/semeval/
2We use Arabic to refer to Modern Standard Arabic (MSA).
</footnote>
<page confidence="0.872495">
798
</page>
<note confidence="0.734543">
Proceedings of ACL-08: HLT, pages 798–806,
</note>
<page confidence="0.530755">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.993437222222222">
use gold standard trees from the Arabic Tree Bank
(ATB) (Maamouri et al., 2004).
This paper is laid out as follows: Section 2
presents facts about the Arabic language especially
in relevant contrast to English; Section 3 presents
the approach and system adopted for this work; Sec-
tion 4 presents the experimental setup, results and
discussion. Finally, Section 5 draws our conclu-
sions.
</bodyText>
<sectionHeader confidence="0.698655" genericHeader="introduction">
2 Arabic Language and Impact on SRL
</sectionHeader>
<bodyText confidence="0.999771848484849">
Arabic is a very different language from English in
several respects relevant to the SRL task. Arabic is a
semitic language. It is known for its templatic mor-
phology where words are made up of roots and af-
fixes. Clitics agglutinate to words. Clitics include
prepositions, conjunctions, and pronouns.
In contrast to English, Arabic exhibits rich mor-
phology. Similar to English, Arabic verbs explic-
itly encode tense, voice, Number, and Person fea-
tures. Additionally, Arabic encodes verbs with Gen-
der, Mood (subjunctive, indicative and jussive) in-
formation. For nominals (nouns, adjectives, proper
names), Arabic encodes syntactic Case (accusative,
genitive and nominative), Number, Gender and Def-
initeness features. In general, many of the morpho-
logical features of the language are expressed via
short vowels also known as diacritics3.
Unlike English, syntactically Arabic is a pro-drop
language, where the subject of a verb may be im-
plicitly encoded in the verb morphology. Hence, we
observe sentences such as ÈA�®Z,,�.Ë@ É¿@ Akl AlbrtqAl
‘ate-[he] the-oranges’, where the verb Akl encodes
the third Person Masculine Singular subject in the
verbal morphology. It is worth noting that in the
ATB 35% of all sentences are pro-dropped for sub-
ject (Maamouri et al., 2006). Unless the syntactic
parse is very accurate in identifying the pro-dropped
case, identifying the syntactic subject and the under-
lying semantic arguments are a challenge for such
pro-drop cases.
Arabic syntax exhibits relative free word order.
Arabic allows for both subject-verb-object (SVO)
and verb-subject-object (VSO) argument orders.4 In
</bodyText>
<footnote confidence="0.98346175">
3Diacritics encode the vocalic structure, namely the short
vowels, as well as the gemmination marker for consonantal dou-
bling, among other markers.
4MSA less often allows for OSV, or OVS.
</footnote>
<bodyText confidence="0.999836113636364">
the VSO constructions, the verb agrees with the syn-
tactic subject in Gender only, while in the SVO con-
structions, the verb agrees with the subject in both
Number and Gender. Even though, in the ATB, an
equal distribution of both VSO and SVO is observed
(each appearing 30% of the time), it is known that
in general Arabic is predominantly in VSO order.
Moreover, the pro-drop cases could effectively be
perceived as VSO orders for the purposes of SRL.
Syntactic Case is very important in the cases of VSO
and pro-drop constructions as they indicate the syn-
tactic roles of the object arguments with accusative
Case. Unless the morphology of syntactic Case is
explicitly present, such free word order could run
the SRL system into significant confusion for many
of the predicates where both arguments are semanti-
cally of the same type.
Arabic exhibits more complex noun phrases than
English mainly to express possession. These con-
structions are known as idafa constructions. Mod-
ern standard Arabic does not have a special parti-
cle expressing possession. In these complex struc-
tures a surface indefinite noun (missing an explicit
definite article) may be followed by a definite noun
marked with genitive Case, rendering the first noun
syntactically definite. For example, .:4@ Ég. P rjl
Albyt ‘man the-house’ meaning ‘man of the house’,
Ég. P becomes definite. An adjective modifying the
noun Ég. P will have to agree with it in Number,
Gender, Definiteness, and Case. However, with-
out explicit morphological encoding of these agree-
ments, the scope of the arguments would be con-
fusing to an SRL system. In a sentence such as
ÉK�ñ¢Ë@ x4@ Ég. P rjlu Albyti AlTwylu meaning ‘the
tall man of the house’: ‘man’ is definite, masculine,
singular, nominative, corresponding to Definiteness,
Gender, Number and Case, respectively; ‘the-house’
is definite, masculine, singular, genitive; ‘the-tall’ is
definite, masculine, singular, nominative. We note
that ‘man’ and ‘tall’ agree in Number, Gender, Case
and Definiteness. Syntactic Case is marked using
short vowels u, and i at the end of the word. Hence,
rjlu and AlTwylu agree in their Case ending5 With-
out the explicit marking of the Case information,
</bodyText>
<footnote confidence="0.998292666666667">
5The presence of the Albyti is crucial as it renders rjlu defi-
nite therefore allowing the agreement with AlTwylu to be com-
plete.
</footnote>
<page confidence="0.996828">
799
</page>
<figureCaption confidence="0.999855">
Figure 1: Annotated Arabic Tree corresponding to ‘Chinese Prime minister Zhu Rongjy started an official visit to India last Sunday.’
</figureCaption>
<figure confidence="0.998253666666666">
S
NN
•aKP
president
NP
NN
Z@P �ñË@
ministers
NPARGO
NP
JJ
úæJ�’Ë@
�
Chinese
VP
NPARGI
VBDp�edicate
�
@YK.
started
NNP
ðP
Zhu
NP
NNP
úm�� ðP
�.
Rongji
NN
5PAK
P
visit
NP
L�ÖÞ...P
official
JJ
IN
È
to
PP
NP
NNP
Y�JêË@
India
NN
YgB@
Sunday
JJ
úæ•AÖÏ@
�
�
past
NPARGM−T MP
NP
</figure>
<bodyText confidence="0.999748114285714">
namely in the word endings, it could be equally valid
that ‘the-tall’ modifies ‘the-house’ since they agree
in Number, Gender and Definiteness as explicitly
marked by the Definiteness article Al. Hence, these
idafa constructions could be tricky for SRL in the
absence of explicit morphological features. This is
compounded by the general absence of short vowels,
expressed by diacritics (i.e. the u and i in rjlu and Al-
byti,) in naturally occurring text. Idafa constructions
in the ATB exhibit recursive structure, embedding
other NPs, compared to English where possession is
annotated with flat NPs and is designated by a pos-
sessive marker.
Arabic texts are underspecified for diacritics to
different degrees depending on the genre of the
text (Diab et al., 2007b). Such an underspecifica-
tion of diacritics masks some of the very relevant
morpho-syntactic interactions between the different
categories such as agreement between nominals and
their modifiers as exemplified before, or verbs and
their subjects.
Having highlighted the differences, we hypothe-
size that the interaction between the rich morphol-
ogy (if explicitly marked and present) and syntax
could help with the SRL task. The presence of ex-
plicit Number and Gender agreement as well as Case
information aids with identification of the syntactic
subject and object even if the word order is relatively
free. Gender, Number, Definiteness and Case agree-
ment between nouns and their modifiers and other
nominals, should give clues to the scope of argu-
ments as well as their classes. The presence of such
morpho-syntactic information should lead to better
argument boundary detection and better classifica-
tion.
</bodyText>
<sectionHeader confidence="0.95693" genericHeader="method">
3 An SRL system for Arabic
</sectionHeader>
<bodyText confidence="0.9984205">
The previous section suggests that an optimal model
should take into account specific characteristics of
</bodyText>
<table confidence="0.968191">
Feature Name Description
Predicate Lemmatization of the predicate word
Path Syntactic path linking the predicate and
an argument, e.g. NNTNPTVPJVBX
Partial path Path feature limited to the branching of
the argument
No-direction path Like Path without traversal directions
Phrase type Syntactic type of the argument node
Position Relative position of the argument with
respect to the predicate
Verb subcategorization Production rule expanding the predicate
parent node
Syntactic Frame Position of the NPs surrounding the
predicate
First and last word/POS First and last words and POS tags of
candidate argument phrases
</table>
<tableCaption confidence="0.999609">
Table 1: Standard linguistic features employed by most SRL systems.
</tableCaption>
<bodyText confidence="0.999920933333333">
Arabic. In this research, we go beyond the previ-
ously proposed basic SRL system for Arabic (Diab
et al., 2007a; Diab and Moschitti, 2007). We exploit
the full morphological potential of the language to
verify our hypothesis that taking advantage of the
interaction between morphology and syntax can im-
prove on a basic SRL system for morphologically
rich languages.
Similar to the previous Arabic SRL systems, our
adopted SRL models use Support Vector Machines
to implement a two step classification approach,
i.e. boundary detection and argument classifica-
tion. Such models have already been investigated
in (Pradhan et al., 2005; Moschitti et al., 2005). The
two step classification description is as follows.
</bodyText>
<subsectionHeader confidence="0.998094">
3.1 Predicate Argument Extraction
</subsectionHeader>
<bodyText confidence="0.999972875">
The extraction of predicative structures is based on
the sentence level. Given a sentence, its predicates,
as indicated by verbs, have to be identified along
with their arguments. This problem is usually di-
vided in two subtasks: (a) the detection of the target
argument boundaries, i.e. the span of the argument
words in the sentence, and (b) the classification of
the argument type, e.g. Arg0 or ArgM for Propbank
</bodyText>
<page confidence="0.990744">
800
</page>
<figureCaption confidence="0.962775">
Figure 2: Fragment space generated by a tree kernel function for the sentence Mary bought a cat.
</figureCaption>
<figure confidence="0.999885684210526">
D
S
N
VP
VP
VP
VP
VP
NP
NP
NNP
VBD
a
cat
a
cat
a
cat
a
cat
NP
VBD NP
VBD
NP
VBD
NP
VBD
NP
D
N
NNP
bought
bought
D N
bought
D N
bought
Mary
VBD
NP
D
N
D
N
Mary
bought
D
N
cat
�
VBD
NP
VP
NNP
a cat ...
bought
Mary
</figure>
<figureCaption confidence="0.30743">
or Agent and Goal for the FrameNet.
</figureCaption>
<bodyText confidence="0.995648">
The standard approach to learn both the detection
and the classification of predicate arguments is sum-
marized by the following steps:
</bodyText>
<listItem confidence="0.9865493">
(a) Given a sentence from the training-set, generate
a full syntactic parse-tree;
(b) let P and A be the set of predicates and the set
of parse-tree nodes (i.e. the potential arguments), re-
spectively;
(c) for each pair (p, a) E P x A: extract the feature
representation set, Fp,a and put it in T+ (positive ex-
amples) if the subtree rooted in a covers exactly the
words of one argument of p, otherwise put it in T−
(negative examples).
</listItem>
<bodyText confidence="0.996976518518519">
For instance, in Figure 1, for each combination of
the predicate started with the nodes NP, S, VP, VPD,
NNP, NN, PP, JJ or IN the instances Fstarted,a are
generated. In case the node a exactly covers ‘presi-
dent ministers Chinese Zhu Rongji’ or ‘visit official
to India’, Fp,a will be a positive instance otherwise
it will be a negative one, e.g. Fstarted,IN.
The T+ and T− sets are used to train the bound-
ary classifier. To train the multi-class classifier, T+
can be reorganized as positive T+argi and negative
T−argi examples for each argument i. This way, an in-
dividual ONE-vs-ALL classifier for each argument i
can be trained. We adopt this solution, according
to (Pradhan et al., 2005), since it is simple and ef-
fective. In the classification phase, given an unseen
sentence, all its Fp,a are generated and classified by
each individual classifier Ci. The argument associ-
ated with the maximum among the scores provided
by the individual classifiers is eventually selected.
The above approach assigns labels independently,
without considering the whole predicate argument
structure. As a consequence, the classifier output
may generate overlapping arguments. Thus, to make
the annotations globally consistent, we apply a dis-
ambiguating heuristic adopted from (Diab and Mos-
chitti, 2007) that selects only one argument among
multiple overlapping arguments.
</bodyText>
<subsectionHeader confidence="0.961072">
3.2 Features
</subsectionHeader>
<bodyText confidence="0.9995385">
The discovery of relevant features is, as usual, a
complex task. The choice of features is further com-
pounded for a language such as Arabic given its rich
morphology and morpho-syntactic interactions.
To date, there is a common consensus on the set of
basic standard features for SRL, which we will refer
to as standard. The set of standard features, refers to
unstructured information derived from parse trees.
e.g. Phrase Type, Predicate Word or Head Word.
Typically the standard features are language inde-
pendent. In our experiments we employ the features
listed in Table 1, defined in (Gildea and Jurafsky,
2002; Pradhan et al., 2005; Xue and Palmer, 2004).
For example, the Phrase Type indicates the syntac-
tic type of the phrase labeled as a predicate argu-
ment, e.g. NP for ARG1 in Figure 1. The Parse Tree
Path contains the path in the parse tree between the
predicate and the argument phrase, expressed as a
sequence of nonterminal labels linked by direction
(up or down) symbols, e.g. VBD T VP ↓ NP for
ARG1 in Figure 1. The Predicate Word is the surface
form of the verbal predicate, e.g. started for all argu-
ments. The standard features, as successful as they
are, are designed primarily for English. They are not
exploiting the different characteristics of the Arabic
language as expressed through morphology. Hence,
we explicitly encode new SRL features that capture
the richness of Arabic morphology and its role in
morpho-syntactic behavior. The set of morphologi-
cal attributes include: inflectional morphology such
as Number, Gender, Definiteness, Mood, Case, Per-
son; derivational morphology such as the Lemma
form of the words with all the diacritics explicitly
marked; vowelized and fully diacritized form of the
surface form; the English gloss6. It is worth noting
that there exists highly accurate morphological tag-
gers for Arabic such as the MADA system (Habash
and Rambow, 2005; Roth et al., 2008). MADA tags
</bodyText>
<footnote confidence="0.996709">
6The gloss is not sense disambiguated, hence they include
homonyms.
</footnote>
<page confidence="0.990409">
801
</page>
<figure confidence="0.851489222222222">
Feature Name Description
Definiteness Applies to nominals, values are definite, indefinite or inapplicable
Number Applies to nominals and verbs, values are singular, plural or dual or inapplicable
Gender Applies to nominals, values are feminine, masculine or inapplicable
Case Applies to nominals, values are accusative, genitive, nominative or inapplicable
Mood Applies to verbs, values are subjunctive, indicative, jussive or inapplicable
Person Applies to verbs and pronouns, values are 1st, 2nd, 3rd person or inapplicable
Lemma The citation form of the word fully diacritized with the short vowels and gemmination markers if applicable
Gloss this is the corresponding English meaning as rendered by the underlying lexicon.
</figure>
<tableCaption confidence="0.874992">
Vocalized word The surface form of the word with all the relevant diacritics. Unlike Lemma, it includes all the inflections.
Unvowelized word The naturally occurring form of the word in the sentence with no diacritics.
Table 2: Rich morphological features encoded in the Extended Argument Structure Tree (EAST).
</tableCaption>
<bodyText confidence="0.999643076923077">
modern standard Arabic with all the relevant mor-
phological features as well as it produces highly ac-
curate lemma and gloss information by tapping into
an underlying morphological lexicon. A list of the
extended features is described in Table 2.
The set of possible features and their combina-
tions are very large leading to an intractable fea-
ture selection problem. Therefore, we exploit well
known kernel methods, namely tree kernels, to ro-
bustly experiment with all the features simultane-
ously. Such kernel engineering, as shown in (Mos-
chitti, 2004), allows us to experiment with many
syntactic/semantic features seamlessly.
</bodyText>
<sectionHeader confidence="0.496769" genericHeader="method">
3.3 Engineering Arabic Features with Kernel
Methods
</sectionHeader>
<bodyText confidence="0.999990090909091">
Feature engineering via kernel methods is a useful
technique that allows us to save a lot of time in the
design and implementation of features. The basic
idea is (a) to design a set of basic value-attribute
features and apply polynomial kernels and generate
all possible combinations; or (b) to design basic tree
structures expressing properties related to the target
linguistic objects and use tree kernels to generate
all possible tree subparts, which will constitute the
feature representation vectors for the learning algo-
rithm.
Tree kernels evaluate the similarity between two
trees in terms of their overlap, generally measured
as the number of common substructures (Collins
and Duffy, 2002). For example, Figure 2, shows
a small parse tree and some of its fragments. To
design a function which computes the number of
common substructures between two trees t1 and t2,
let us define the set of fragments F={f1, f2, ..} and
the indicator function IZ(n), equal to 1 if the tar-
get fZ is rooted at node n and 0 otherwise. A tree
kernel function KT(·) over two trees is defined as:
</bodyText>
<figure confidence="0.576681">
VP
</figure>
<figureCaption confidence="0.9987875">
Figure 3: Example of the positive AST structured feature encoding
the argument ARG0 in the sentence depicted in Figure 1.
</figureCaption>
<bodyText confidence="0.877814375">
KT(t1, t2) = En1ENt1 En2ENt2 Δ(n1, n2), where
Nt1 and Nt2 are the sets of nodes of t1 and t2, re-
spectively. The function Δ(·) evaluates the num-
ber of common fragments rooted in n1 and n2, i.e.
Δ(n1, n2) = ����
Z=1 IZ(n1)IZ(n2). Δ can be ef-
ficiently computed with the algorithm proposed in
(Collins and Duffy, 2002).
</bodyText>
<subsectionHeader confidence="0.982388">
3.4 Structural Features for Arabic
</subsectionHeader>
<bodyText confidence="0.9998722">
In order to incorporate the characteristically rich
Arabic morphology features structurally in the tree
representations, we convert the features into value-
attribute pairs at the leaf node level of the tree. Fig
1 illustrates the morphologically underspecified tree
with some of the morphological features encoded in
the POS tag such as VBD indicating past tense. This
contrasts with Fig. 4 which shows an excerpt of the
same tree encoding the chosen relevant morpholog-
ical features.
For the sake of classification, we will be dealing
with two kinds of structures: the Argument Structure
Tree (AST) (Pighin and Basili, 2006) and the Ex-
tended Argument Structure Tree (EAST). The AST
is defined as the minimal subtree encompassing all
and only the leaf nodes encoding words belonging
to the predicate or one of its arguments. An AST
example is shown in Figure 3. The EAST is the
corresponding structure in which all the leaf nodes
have been extended with the ten morphological fea-
</bodyText>
<figure confidence="0.99933325">
NP
NP
NP
VBD
�
@YK.
NN
• P
NN
Z@P �PñË@
NNP
ðP
úæJ
’Ë@
�
NNP
úm~ ðP
�.
NP
JJ
</figure>
<page confidence="0.83287">
802
</page>
<figureCaption confidence="0.991507">
Figure 4: An excerpt of the EAST corresponding to the AST shown in Figure 3, with attribute-value extended morphological features represented
as leaf nodes.
</figureCaption>
<figure confidence="0.998390137254902">
NP
NP
FEAT
Person
3
FEAT
Gender
MASC
...
NN
NP
FEAT
Number
S
FEAT
Lemma
bada&gt;-a
FEAT
FEAT
UnVocal
bd&gt;
...
FEAT
Vocal
bada&gt;a
FEAT
Gloss
start/begin+he/it
Definite
FEAT
Case
GEN
DEF
FEAT
Number
S
FEAT
Gender
MASC
FEAT
Lemma
ra}iys
FEAT
Gloss
president/head/chairman
FEAT
Vocal
ra}iysi
VP
VBD
NP
</figure>
<bodyText confidence="0.994275078947368">
tures described in Table 2, forming a vector of 10
preterminal-terminal node pairs that replace the sur-
face of the leaf. The resulting EAST structure is
shown in Figure 4.
Not all the features are instantiated for all the leaf
node words. Due to space limitations, in the fig-
ure we did not include the Features that have NULL
values. For instance, Definiteness is always asso-
�
ciated with nominals, hence the verb @YK. bd’ ‘start’
is assigned a NULL value for the Definite feature.
Verbs exhibit Gender information depending on in-
flections. For our example, @YK. ‘started’ is inflected
for masculine Gender, singular Number, third per-
son. On the other hand, the noun Z@P �PñË@ is definite
and is assigned genitive Case since it is in a posses-
sive, idafa, construction.
The features encoded by the EAST can provide
very useful hints for boundary and role classifica-
tion. Considering Figure 1, argument boundaries is
not as straight forward to identify as there are sev-
eral NPs. Assuming that the inner most NP ‘minis-
ters the-Chinese’ is a valid Argument could poten-
tially be accepted. There is ample evidence that any
NN followed by a JJ would make a perfectly valid
Argument. However, an AST structure would mask
the fact that the JJ ‘the-Chinese’ does not modify the
NN ‘ministers’ since they do not agree in Number7,
and in syntactic Case, where the latter is genitive and
the former is nominative. ‘the-Chinese’ in fact mod-
ifies ‘president’ as they agree on all the underlying
morphological features. Conversely, the EAST in
Figure 4 explicitly encodes this agreement includ-
ing an agreement on Definiteness. It is worth noting
that just observing the Arabic word•~
;P ‘president’
in Fig 1, the system would assume that it is an indef-
inite word since it does not include the definite arti-
</bodyText>
<footnote confidence="0.7053915">
7The POS tag on this node is NN as broken plural, however,
the underlying morphological feature Number is plural.
</footnote>
<bodyText confidence="0.965393958333333">
cle È@. Therefore, the system could be lead astray to
conclude that ‘the-Chinese’ does not modify ‘pres-
ident’ but rather ‘the-ministers’. Without knowing
the Case information and the agreement features be-
tween the verb @YK. ‘started’ and the two nouns head-
ing the two main NPs in our tree, the syntactic sub-
ject can be either SPAK
P ‘visit’ or •
;P ‘president’ in
Figure 1. The EAST is more effective in identifying
the first noun as the syntactic subject and the second
as the object since the morphological information in-
dicates that they are in nominative and accusative
Case, respectively. Also the agreement in Gender
and Number between the verb and the syntactic sub-
ject is identified in the enriched tree. We see that LYK.
‘started’ and •~
KP ‘president’ agree in being singu-
lar and masculine. If 3PAK�P ‘visit’ were the syntactic
subject, we would have seen the verb inflected as
&amp;quot;�@YK. ‘started-FEM’ with a feminine inflection to re-
flect the verb-subject agreement on Gender. Hence
these agreement features should help with the clas-
sification task.
</bodyText>
<sectionHeader confidence="0.99914" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9540771875">
In these experiments we investigate (a) if the tech-
nology proposed in previous work for automatic
SRL of English texts is suitable for Arabic SRL
systems, and (b) the impact of tree kernels using
new tree structures on Arabic SRL. For this purpose,
we test our models on the two individual phases
of the traditional 2-stage SRL model (i.e. bound-
ary detection and argument classification) and on
the complete SRL task. We use three different fea-
ture spaces: a set of standard attribute-value features
and the AST and the EAST structures defined in
3.4. Standard feature vectors can be combined with
a polynomial kernel (Poly), which, when the de-
gree is larger than 1, automatically generates feature
conjunctions. This, as suggested in (Pradhan et al.,
2005; Moschitti, 2004), can help stressing the differ-
</bodyText>
<page confidence="0.997265">
803
</page>
<bodyText confidence="0.998685714285714">
ences between different argument types. Tree struc-
tures can be used in the learning algorithm thanks to
the tree kernels described in Section 3.3. Moreover,
to verify if the above feature sets are equivalent or
complementary, we can join them by means of addi-
tive operation which always produces a valid kernel
(Shawe-Taylor and Cristianini, 2004).
</bodyText>
<subsectionHeader confidence="0.995504">
4.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.999976444444444">
We use the dataset released in the SemEval 2007
Task 18 on Arabic Semantic Labeling (Diab et al.,
2007a). The data covers the 95 most frequent
verbs in the Arabic Treebank III ver. 2 (ATB).
The ATB consists of MSA newswire data from the
Annhar newspaper, spanning the months from July
to November, 2002. All our experiments are carried
out with gold standard trees.
An important characteristic of the dataset is
the use of unvowelized Arabic in the Buckwalter
transliteration scheme for deriving the basic features
for the AST experimental condition. The data com-
prises a development set, a test set and a training
set of 886, 902 and 8,402 sentences, respectively,
where each set contain 1725, 1661 and 21,194 argu-
ment instances. These instances are distributed over
26 different role types. The training instances of
the boundary detection task also include parse-tree
nodes that do not correspond to correct boundaries
(we only considered 350K examples). For the exper-
iments, we use SVM-Light-TK toolkit8 (Moschitti,
2004; Moschitti, 2006) and its SVM-Light default
parameters. The system performance, i.e. F1 on sin-
gle boundary and role classifier, accuracy of the role
multi-classifier and the F1 of the complete SRL sys-
tems, are computed by means of the CoNLL evalua-
tor9.
</bodyText>
<sectionHeader confidence="0.767856" genericHeader="evaluation">
4.2 Results
</sectionHeader>
<bodyText confidence="0.998606375">
Figure 5 reports the F1 of the SVM boundary classi-
fier using Polynomial Kernels with a degree from 1
to 6 (i.e. Polyi), the AST and the EAST kernels and
their combinations. We note that as we introduce
conjunctions, i.e. a degree larger than 2, the F1 in-
creases by more than 3 percentage points. Thus, not
only are the English features meaningful for Ara-
bic but also their combinations are important, reveal-
</bodyText>
<footnote confidence="0.9983705">
8http://disi.unitn.it/—moschitti
9http://www.lsi.upc.es/—srlconll/soft.html
</footnote>
<figureCaption confidence="0.9937682">
Figure 5: Impact of polynomial kernel, tree kernels and their combi-
nations on boundary detection.
Figure 6: Impact of the polynomial kernel, tree kernels and their
combinations on the accuracy in role classification (gold boundaries)
and on the F1 of complete SRL task (boundary + role classification).
</figureCaption>
<bodyText confidence="0.999980625">
ing that both languages share an underlying syntax-
semantics interface. Moreover, we note that the F1
of EAST is higher than the F1 of AST which in turn
is higher than the linear kernel (Poly1). However,
when conjunctive features (Poly2-4) are used the
system accuracy exceeds those of tree kernel mod-
els alone. Further increasing the polynomial degree
(Poly5-6) generates very complex hypotheses which
result in very low accuracy values.
Therefore, to improve the polynomial kernel, we
sum it to the contribution of AST and/or EAST,
obtaining AST+Poly3 (polynomial kernel of degree
3), EAST+Poly3 and AST+EAST+Poly3, whose F1
scores are also shown in Figure 5. Such com-
bined models improve on the best polynomial ker-
nel. However, not much difference is shown be-
tween AST and EAST on boundary detection. This
is expected since we are using gold standard trees.
We hypothesize that the rich morphological fea-
tures will help more with the role classification
task. Therefore, we evaluate role classification with
gold boundaries. The curve labeled ”classification”
in Figure 6 illustrates the accuracy of the SVM
role multi-classifier according to different kernels.
</bodyText>
<page confidence="0.99561">
804
</page>
<table confidence="0.972018833333333">
P3 AST EAST AP3+ EP3T+AS
EAST+
P3
P 81.73 80.33 81.7 81.73 82.46 83.08
R 78.93 75.98 77.42 80.01 80.67 81.28
F1 80.31 78.09 79.51 80.86 81.56 82.17
</table>
<tableCaption confidence="0.999817">
Table 3: F1 of different models on the Arabic SRL task.
</tableCaption>
<bodyText confidence="0.999595857142857">
Again, we note that a degree larger than 1 yields
a significant improvement of more than 3 percent
points, suggesting that the design of Arabic SRL
system based on SVMs requires polynomial kernels.
In contrast to the boundary results, EAST highly im-
proves over AST (by about 3 percentage points) and
produces an F1 comparable to the best Polynomial
kernel. Moreover, AST+Poly3, EAST+Poly3 and
AST+EAST+Poly3 all yield different degrees of im-
provement, where the latter model is both the richest
in terms of features and the most accurate.
These results strongly suggest that: (a) tree ker-
nels generate new syntactic features that are useful
for the classification of Arabic semantic roles; (b)
the richer morphology of Arabic language should
be exploited effectively to obtain accurate SRL sys-
tems; (c) tree kernels appears to be a viable approach
to effectively achieve this goal.
To illustrate the practical feasibility of our system,
we investigate the complete SRL task where both
the boundary detection and argument role classifica-
tion are performed automatically. The curve labeled
”boundary + role classification” in Figure 6 reports
the F1 of SRL systems based on the previous ker-
nels. The trend of the plot is similar to the gold-
standard boundaries case. The difference among
the F1 scores of the AST+Poly3, EAST+Poly3 and
AST+EAST+Poly3 is slightly reduced. This may
be attributed to the fact that they produce similar
boundary detection results, which in turn, for the
global SRL outcome, are summed to those of the
classification phase. Table 3 details the differences
among the models and shows that the best model
improves the SRL system based on the polynomial
kernel, i.e. the SRL state-of-the-art for Arabic, by
about 2 percentage points. This is a very large im-
provement for SRL systems (Carreras and M`arquez,
2005). These results confirm that the new enriched
structures along with tree kernels are a promising ap-
proach for Arabic SRL systems.
Finally, Table 4 reports the F1 of the best model,
AST+EAST+Poly3, for individual arguments in the
</bodyText>
<table confidence="0.99993075">
Role Precision Recall FQ=1
ARG0 96.14% 97.27% 96.70
ARG0-STR 100.00% 20.00% 33.33
ARG1 88.52% 92.70% 90.57
ARG1-STR 33.33% 15.38% 21.05
ARG2 69.35% 76.67% 72.82
ARG3 66.67% 16.67% 26.67
ARGM-ADV 66.98% 61.74% 64.25
ARGM-CAU 100.00% 9.09% 16.67
ARGM-CND 25.00% 33.33% 28.57
ARGM-LOC 67.44% 95.08% 78.91
ARGM-MNR 54.00% 49.09% 51.43
ARGM-NEG 80.85% 97.44% 88.37
ARGM-PRD 20.00% 8.33% 11.76
ARGM-PRP 85.71% 66.67% 75.00
ARGM-TMP 91.35% 88.79% 90.05
</table>
<tableCaption confidence="0.692923">
Table 4: SRL F1 of the single arguments using the
AST+EAST+Poly3 kernel.
</tableCaption>
<bodyText confidence="0.9997679">
SRL task. We note that, as for English SRL, ARG0
shows high values (96.70%). Conversely, ARG1
seems more difficult to be classified in Arabic. The
F1 for ARG1 is only 90.57% compared with 96.70%
for ARG0.
This may be attributed to the different possi-
ble syntactic orders of Arabic consructions confus-
ing the syntactic subject with the object especially
where there is no clear morphological features on
the arguments to decide either way.
</bodyText>
<sectionHeader confidence="0.999567" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999979066666667">
We have presented a model for Arabic SRL that
yields a global SRL F1 score of 82.17% by combin-
ing rich structured features and traditional attribute-
value features derived from English SRL systems.
The resulting system significantly improves previ-
ously reported results on the same task and dataset.
This outcome is very promising given that the avail-
able data is small compared to the English data sets.
For future work, we would like to explore further
explicit morphological features such as aspect tense
and voice as well as richer POS tag sets such as those
proposed in (Diab, 2007). Finally, we would like to
experiment with automatic parses and different syn-
tactic formalisms such as dependencies and shallow
parses.
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<reference confidence="0.9932615">
Mona Diab is partly funded by DARPA Contract No. HR0011-
06-C-0023. Alessandro Moschitti has been partially funded by
CCLS of the Columbia University and by the FP6 IST LUNA
project contract no 33549.
</reference>
<page confidence="0.999517">
805
</page>
<sectionHeader confidence="0.995864" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999945346534654">
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet Project. In COLING-
ACL ’98: University ofMontr6al.
Xavier Carreras and Lluis M`arquez. 2005. Introduction
to the CoNLL-2005 Shared Task: Semantic Role La-
beling. In Proceedings of CoNLL-2005, Ann Arbor,
Michigan.
John Chen and Owen Rambow. 2003. Use of Deep Lin-
guistic Features for the Recognition and Labeling of
Semantic Arguments. In Proceedings ofEMNLP, Sap-
poro, Japan.
Michael Collins and Nigel Duffy. 2002. New Ranking
Algorithms for Parsing and Tagging: Kernels over Dis-
crete structures, and the voted perceptron. In ACL02.
Mona Diab and Alessandro Moschitti. 2007. Semantic
Parsing for Modern Standard Arabic. In Proceedings
of RANLP, Borovets, Bulgaria.
Mona Diab, Musa Alkhalifa, Sabry ElKateb, Christiane
Fellbaum, Aous Mansouri, and Martha Palmer. 2007a.
Semeval-2007 task 18: Arabic Semantic Labeling. In
Proceedings of SemEval-2007, Prague, Czech Repub-
lic.
Mona Diab, Mahmoud Ghoneim, and Nizar Habash.
2007b. Arabic Diacritization in the Context of Sta-
tistical Machine Translation. In Proceedings of MT-
Summit, Copenhagen, Denmark.
Mona Diab. 2007. Towards an Optimal Pos Tag Set for
Modern Standard Arabic Processing. In Proceedings
of RANLP, Borovets, Bulgaria.
Katrin Erk and Sebastian Pado. 2006. Shalmaneser – A
Toolchain for Shallow Semantic Parsing. Proceedings
of LREC.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic La-
beling of Semantic Roles. Computational Linguistics.
Daniel Gildea and Martha Palmer. 2002. The Neces-
sity of Parsing for Predicate Argument Recognition.
In Proceedings ofACL-02, Philadelphia, PA, USA.
Nizar Habash and Owen Rambow. 2005. Arabic Tok-
enization, Part-of-Speech Tagging and Morphological
Disambiguation in One Fell Swoop. In Proceedings of
ACL’05, Ann Arbor, Michigan.
Aria Haghighi, Kristina Toutanova, and Christopher
Manning. 2005. A Joint Model for Semantic Role
Labeling. In Proceedings ofCoNLL-2005, Ann Arbor,
Michigan.
Paul Kingsbury and Martha Palmer. 2003. Propbank: the
Next Level of Treebank. In Proceedings of Treebanks
and Lexical Theories.
Mohamed Maamouri, Ann Bies, Tim Buckwalter, and
Wigdan Mekki. 2004. The Penn Arabic Treebank :
Building a Large-Scale Annotated Arabic Corpus.
Mohamed Maamouri, Ann Bies, Tim Buckwalter, Mona
Diab, Nizar Habash, Owen Rambow, and Dalila
Tabessi. 2006. Developing and Using a Pilot Dialectal
Arabic Treebank.
Alessandro Moschitti, Ana-Maria Giuglea, Bonaventura
Coppola, and Roberto Basili. 2005. Hierarchical
Semantic Role Labeling. In Proceedings of CoNLL-
2005, Ann Arbor, Michigan.
Alessandro Moschitti, Silvia Quarteroni, Roberto Basili,
and Suresh Manandhar. 2007. Exploiting Syntactic
and Shallow Semantic Kernels for Question Answer
Classification. In Proceedings of ACL’07, Prague,
Czech Republic.
Alessandro Moschitti. 2004. A Study on Convolution
Kernels for Shallow Semantic Parsing. In proceedings
ofACL’04, Barcelona, Spain.
Alessandro Moschitti. 2006. Making Tree Kernels Prac-
tical for Natural Language Learning. In Proceedings
ofEACL’06.
Alessandro Moschitti, Daniele Pighin and Roberto Basili.
2006. Semantic Role Labeling via Tree Kernel Joint
Inference. In Proceedings of CoNLL-X.
Sameer Pradhan, Kadri Hacioglu, Wayne Ward, James H.
Martin, and Daniel Jurafsky. 2003. Semantic Role
Parsing: Adding Semantic Structure to Unstructured
Text. In Proceedings ICDM’03, Melbourne, USA.
Sameer Pradhan, Kadri Hacioglu, Valerie Krugler,
Wayne Ward, James H. Martin, and Daniel Jurafsky.
2005. Support Vector Learning for Semantic Argu-
ment Classification. Machine Learning.
Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab,
and Cynthia Rudin. 2008. Arabic Morphological Tag-
ging, Diacritization, and Lemmatization Using Lex-
eme Models and Feature Ranking. In ACL’08, Short
Papers, Columbus, Ohio, June.
John Shawe-Taylor and Nello Cristianini. 2004. Kernel
Methods for Pattern Analysis. Cambridge University
Press.
Honglin Sun and Daniel Jurafsky. 2004. Shallow Seman-
tic Parsing of Chinese. In Proceedings of NAACL-
HLT.
Cynthia A. Thompson, Roger Levy, and Christopher
Manning. 2003. A Generative Model for Semantic
Role Labeling. In ECML’03.
Vladimir N. Vapnik. 1998. Statistical Learning Theory.
John Wiley and Sons.
Nianwen Xue and Martha Palmer. 2004. Calibrating
Features for Semantic Role Labeling. In Dekang Lin
and Dekai Wu, editors, Proceedings of EMNLP 2004,
Barcelona, Spain.
</reference>
<page confidence="0.998817">
806
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.867221">
<title confidence="0.999685">Semantic Role Labeling Systems for Arabic using Kernel Methods</title>
<author confidence="0.999908">Mona Diab</author>
<affiliation confidence="0.999048">CCLS, Columbia University</affiliation>
<address confidence="0.999528">New York, NY 10115, USA</address>
<email confidence="0.999739">mdiab@ccls.columbia.edu</email>
<author confidence="0.999581">Alessandro Moschitti</author>
<affiliation confidence="0.999947">DISI, University of Trento</affiliation>
<address confidence="0.999007">Trento, I-38100, Italy</address>
<email confidence="0.996132">moschitti@disi.unitn.it</email>
<author confidence="0.969055">Daniele Pighin</author>
<affiliation confidence="0.951194">FBK-irst; DISI, University of Trento</affiliation>
<address confidence="0.998927">Trento, I-38100, Italy</address>
<email confidence="0.996983">pighin@fbk.eu</email>
<abstract confidence="0.994832">There is a widely held belief in the natural language and computational linguistics communities that Semantic Role Labeling (SRL) is a significant step toward improving important applications, e.g. question answering and information extraction. In this paper, we present an SRL system for Modern Standard Arabic that exploits many aspects of the rich morphological features of the language. The experiments on the pilot Arabic Propbank data show that our system based on Support Vector Machines and Kernel Methods yields a global of 82.17%, which improves the current state-of-the-art in Arabic SRL.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Mona</author>
</authors>
<title>Diab is partly funded by DARPA Contract No. HR0011-06-C-0023. Alessandro Moschitti has been partially funded by CCLS of the Columbia University and by the FP6 IST LUNA project contract no 33549.</title>
<marker>Mona, </marker>
<rawString>Mona Diab is partly funded by DARPA Contract No. HR0011-06-C-0023. Alessandro Moschitti has been partially funded by CCLS of the Columbia University and by the FP6 IST LUNA project contract no 33549.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet Project.</title>
<date>1998</date>
<booktitle>In COLINGACL ’98: University ofMontr6al.</booktitle>
<contexts>
<context position="1415" citStr="Baker et al., 1998" startWordPosition="207" endWordPosition="210">ystem based on Support Vector Machines and Kernel Methods yields a global SRL F1 score of 82.17%, which improves the current state-of-the-art in Arabic SRL. 1 Introduction Shallow approaches to semantic processing are making large strides in the direction of efficiently and effectively deriving tacit semantic information from text. Semantic Role Labeling (SRL) is one such approach. With the advent of faster and more powerful computers, more effective machine learning algorithms, and importantly, large data resources annotated with relevant levels of semantic information, such as the FrameNet (Baker et al., 1998) and ProbBank (Kingsbury and Palmer, 2003), we are seeing a surge in efficient approaches to SRL (Carreras and M`arquez, 2005). SRL is the process by which predicates and their arguments are identified and their roles are defined in a sentence. For example, in the English sentence, ‘John likes apples.’, the predicate is ‘likes’ whereas ‘John’ and ‘apples’, bear the semantic role labels agent (ARG0) and theme (ARG1). The crucial fact about semantic roles is that regardless of the overt syntactic structure variation, the underlying predicates remain the same. Hence, for the sentence ‘John opened</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet Project. In COLINGACL ’98: University ofMontr6al.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Lluis M`arquez</author>
</authors>
<title>Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of CoNLL-2005,</booktitle>
<location>Ann Arbor, Michigan.</location>
<marker>Carreras, M`arquez, 2005</marker>
<rawString>Xavier Carreras and Lluis M`arquez. 2005. Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling. In Proceedings of CoNLL-2005, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Chen</author>
<author>Owen Rambow</author>
</authors>
<title>Use of Deep Linguistic Features for the Recognition and Labeling of Semantic Arguments.</title>
<date>2003</date>
<booktitle>In Proceedings ofEMNLP,</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="2988" citStr="Chen and Rambow, 2003" startWordPosition="468" endWordPosition="471">ts in a sentence has a lot of potential for and is a significant step toward improving important applications such as document retrieval, machine translation, question answering and information extraction (Moschitti et al., 2007). To date, most of the reported SRL systems are for English, and most of the data resources exist for English. We do see some headway for other languages such as German and Chinese (Erk and Pado, 2006; Sun and Jurafsky, 2004). The systems for the other languages follow the successful models devised for English, e.g. (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Thompson et al., 2003; Pradhan et al., 2003; Moschitti, 2004; Xue and Palmer, 2004; Haghighi et al., 2005). In the same spirit and facilitated by the release of the SemEval 2007 Task 18 data1, based on the Pilot Arabic Propbank, a preliminary SRL system exists for Arabic2 (Diab and Moschitti, 2007; Diab et al., 2007a). However, it did not exploit some special characteristics of the Arabic language on the SRL task. In this paper, we present an SRL system for MSA that exploits many aspects of the rich morphological features of the language. It is based on a supervised model that uses support v</context>
</contexts>
<marker>Chen, Rambow, 2003</marker>
<rawString>John Chen and Owen Rambow. 2003. Use of Deep Linguistic Features for the Recognition and Labeling of Semantic Arguments. In Proceedings ofEMNLP, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Nigel Duffy</author>
</authors>
<title>New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete structures, and the voted perceptron.</title>
<date>2002</date>
<booktitle>In ACL02.</booktitle>
<contexts>
<context position="19394" citStr="Collins and Duffy, 2002" startWordPosition="3120" endWordPosition="3123">us to save a lot of time in the design and implementation of features. The basic idea is (a) to design a set of basic value-attribute features and apply polynomial kernels and generate all possible combinations; or (b) to design basic tree structures expressing properties related to the target linguistic objects and use tree kernels to generate all possible tree subparts, which will constitute the feature representation vectors for the learning algorithm. Tree kernels evaluate the similarity between two trees in terms of their overlap, generally measured as the number of common substructures (Collins and Duffy, 2002). For example, Figure 2, shows a small parse tree and some of its fragments. To design a function which computes the number of common substructures between two trees t1 and t2, let us define the set of fragments F={f1, f2, ..} and the indicator function IZ(n), equal to 1 if the target fZ is rooted at node n and 0 otherwise. A tree kernel function KT(·) over two trees is defined as: VP Figure 3: Example of the positive AST structured feature encoding the argument ARG0 in the sentence depicted in Figure 1. KT(t1, t2) = En1ENt1 En2ENt2 Δ(n1, n2), where Nt1 and Nt2 are the sets of nodes of t1 and </context>
</contexts>
<marker>Collins, Duffy, 2002</marker>
<rawString>Michael Collins and Nigel Duffy. 2002. New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete structures, and the voted perceptron. In ACL02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Semantic Parsing for Modern Standard Arabic.</title>
<date>2007</date>
<booktitle>In Proceedings of RANLP, Borovets,</booktitle>
<contexts>
<context position="3288" citStr="Diab and Moschitti, 2007" startWordPosition="521" endWordPosition="524">t of the data resources exist for English. We do see some headway for other languages such as German and Chinese (Erk and Pado, 2006; Sun and Jurafsky, 2004). The systems for the other languages follow the successful models devised for English, e.g. (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Thompson et al., 2003; Pradhan et al., 2003; Moschitti, 2004; Xue and Palmer, 2004; Haghighi et al., 2005). In the same spirit and facilitated by the release of the SemEval 2007 Task 18 data1, based on the Pilot Arabic Propbank, a preliminary SRL system exists for Arabic2 (Diab and Moschitti, 2007; Diab et al., 2007a). However, it did not exploit some special characteristics of the Arabic language on the SRL task. In this paper, we present an SRL system for MSA that exploits many aspects of the rich morphological features of the language. It is based on a supervised model that uses support vector machines (SVM) technology (Vapnik, 1998) for argument boundary detection and argument classification. It is trained and tested using the pilot Arabic Propbank data released as part of the SemEval 2007 data. Given the lack of a reliable Arabic deep syntactic parser, we 1http://nlp.cs.swarthmore</context>
<context position="11664" citStr="Diab and Moschitti, 2007" startWordPosition="1858" endWordPosition="1861"> of the argument No-direction path Like Path without traversal directions Phrase type Syntactic type of the argument node Position Relative position of the argument with respect to the predicate Verb subcategorization Production rule expanding the predicate parent node Syntactic Frame Position of the NPs surrounding the predicate First and last word/POS First and last words and POS tags of candidate argument phrases Table 1: Standard linguistic features employed by most SRL systems. Arabic. In this research, we go beyond the previously proposed basic SRL system for Arabic (Diab et al., 2007a; Diab and Moschitti, 2007). We exploit the full morphological potential of the language to verify our hypothesis that taking advantage of the interaction between morphology and syntax can improve on a basic SRL system for morphologically rich languages. Similar to the previous Arabic SRL systems, our adopted SRL models use Support Vector Machines to implement a two step classification approach, i.e. boundary detection and argument classification. Such models have already been investigated in (Pradhan et al., 2005; Moschitti et al., 2005). The two step classification description is as follows. 3.1 Predicate Argument Ext</context>
<context position="14894" citStr="Diab and Moschitti, 2007" startWordPosition="2413" endWordPosition="2417"> to (Pradhan et al., 2005), since it is simple and effective. In the classification phase, given an unseen sentence, all its Fp,a are generated and classified by each individual classifier Ci. The argument associated with the maximum among the scores provided by the individual classifiers is eventually selected. The above approach assigns labels independently, without considering the whole predicate argument structure. As a consequence, the classifier output may generate overlapping arguments. Thus, to make the annotations globally consistent, we apply a disambiguating heuristic adopted from (Diab and Moschitti, 2007) that selects only one argument among multiple overlapping arguments. 3.2 Features The discovery of relevant features is, as usual, a complex task. The choice of features is further compounded for a language such as Arabic given its rich morphology and morpho-syntactic interactions. To date, there is a common consensus on the set of basic standard features for SRL, which we will refer to as standard. The set of standard features, refers to unstructured information derived from parse trees. e.g. Phrase Type, Predicate Word or Head Word. Typically the standard features are language independent. </context>
</contexts>
<marker>Diab, Moschitti, 2007</marker>
<rawString>Mona Diab and Alessandro Moschitti. 2007. Semantic Parsing for Modern Standard Arabic. In Proceedings of RANLP, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Musa Alkhalifa</author>
<author>Sabry ElKateb</author>
<author>Christiane Fellbaum</author>
<author>Aous Mansouri</author>
<author>Martha Palmer</author>
</authors>
<date>2007</date>
<booktitle>Semeval-2007 task 18: Arabic Semantic Labeling. In Proceedings of SemEval-2007,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="3307" citStr="Diab et al., 2007" startWordPosition="525" endWordPosition="528">ist for English. We do see some headway for other languages such as German and Chinese (Erk and Pado, 2006; Sun and Jurafsky, 2004). The systems for the other languages follow the successful models devised for English, e.g. (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Thompson et al., 2003; Pradhan et al., 2003; Moschitti, 2004; Xue and Palmer, 2004; Haghighi et al., 2005). In the same spirit and facilitated by the release of the SemEval 2007 Task 18 data1, based on the Pilot Arabic Propbank, a preliminary SRL system exists for Arabic2 (Diab and Moschitti, 2007; Diab et al., 2007a). However, it did not exploit some special characteristics of the Arabic language on the SRL task. In this paper, we present an SRL system for MSA that exploits many aspects of the rich morphological features of the language. It is based on a supervised model that uses support vector machines (SVM) technology (Vapnik, 1998) for argument boundary detection and argument classification. It is trained and tested using the pilot Arabic Propbank data released as part of the SemEval 2007 data. Given the lack of a reliable Arabic deep syntactic parser, we 1http://nlp.cs.swarthmore.edu/semeval/ 2We u</context>
<context position="9802" citStr="Diab et al., 2007" startWordPosition="1574" endWordPosition="1577">explicitly marked by the Definiteness article Al. Hence, these idafa constructions could be tricky for SRL in the absence of explicit morphological features. This is compounded by the general absence of short vowels, expressed by diacritics (i.e. the u and i in rjlu and Albyti,) in naturally occurring text. Idafa constructions in the ATB exhibit recursive structure, embedding other NPs, compared to English where possession is annotated with flat NPs and is designated by a possessive marker. Arabic texts are underspecified for diacritics to different degrees depending on the genre of the text (Diab et al., 2007b). Such an underspecification of diacritics masks some of the very relevant morpho-syntactic interactions between the different categories such as agreement between nominals and their modifiers as exemplified before, or verbs and their subjects. Having highlighted the differences, we hypothesize that the interaction between the rich morphology (if explicitly marked and present) and syntax could help with the SRL task. The presence of explicit Number and Gender agreement as well as Case information aids with identification of the syntactic subject and object even if the word order is relativel</context>
<context position="11636" citStr="Diab et al., 2007" startWordPosition="1854" endWordPosition="1857">ted to the branching of the argument No-direction path Like Path without traversal directions Phrase type Syntactic type of the argument node Position Relative position of the argument with respect to the predicate Verb subcategorization Production rule expanding the predicate parent node Syntactic Frame Position of the NPs surrounding the predicate First and last word/POS First and last words and POS tags of candidate argument phrases Table 1: Standard linguistic features employed by most SRL systems. Arabic. In this research, we go beyond the previously proposed basic SRL system for Arabic (Diab et al., 2007a; Diab and Moschitti, 2007). We exploit the full morphological potential of the language to verify our hypothesis that taking advantage of the interaction between morphology and syntax can improve on a basic SRL system for morphologically rich languages. Similar to the previous Arabic SRL systems, our adopted SRL models use Support Vector Machines to implement a two step classification approach, i.e. boundary detection and argument classification. Such models have already been investigated in (Pradhan et al., 2005; Moschitti et al., 2005). The two step classification description is as follows</context>
<context position="26022" citStr="Diab et al., 2007" startWordPosition="4254" endWordPosition="4257"> automatically generates feature conjunctions. This, as suggested in (Pradhan et al., 2005; Moschitti, 2004), can help stressing the differ803 ences between different argument types. Tree structures can be used in the learning algorithm thanks to the tree kernels described in Section 3.3. Moreover, to verify if the above feature sets are equivalent or complementary, we can join them by means of additive operation which always produces a valid kernel (Shawe-Taylor and Cristianini, 2004). 4.1 Experimental setup We use the dataset released in the SemEval 2007 Task 18 on Arabic Semantic Labeling (Diab et al., 2007a). The data covers the 95 most frequent verbs in the Arabic Treebank III ver. 2 (ATB). The ATB consists of MSA newswire data from the Annhar newspaper, spanning the months from July to November, 2002. All our experiments are carried out with gold standard trees. An important characteristic of the dataset is the use of unvowelized Arabic in the Buckwalter transliteration scheme for deriving the basic features for the AST experimental condition. The data comprises a development set, a test set and a training set of 886, 902 and 8,402 sentences, respectively, where each set contain 1725, 1661 an</context>
</contexts>
<marker>Diab, Alkhalifa, ElKateb, Fellbaum, Mansouri, Palmer, 2007</marker>
<rawString>Mona Diab, Musa Alkhalifa, Sabry ElKateb, Christiane Fellbaum, Aous Mansouri, and Martha Palmer. 2007a. Semeval-2007 task 18: Arabic Semantic Labeling. In Proceedings of SemEval-2007, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Mahmoud Ghoneim</author>
<author>Nizar Habash</author>
</authors>
<title>Arabic Diacritization in the Context of Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of MTSummit,</booktitle>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="3307" citStr="Diab et al., 2007" startWordPosition="525" endWordPosition="528">ist for English. We do see some headway for other languages such as German and Chinese (Erk and Pado, 2006; Sun and Jurafsky, 2004). The systems for the other languages follow the successful models devised for English, e.g. (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Thompson et al., 2003; Pradhan et al., 2003; Moschitti, 2004; Xue and Palmer, 2004; Haghighi et al., 2005). In the same spirit and facilitated by the release of the SemEval 2007 Task 18 data1, based on the Pilot Arabic Propbank, a preliminary SRL system exists for Arabic2 (Diab and Moschitti, 2007; Diab et al., 2007a). However, it did not exploit some special characteristics of the Arabic language on the SRL task. In this paper, we present an SRL system for MSA that exploits many aspects of the rich morphological features of the language. It is based on a supervised model that uses support vector machines (SVM) technology (Vapnik, 1998) for argument boundary detection and argument classification. It is trained and tested using the pilot Arabic Propbank data released as part of the SemEval 2007 data. Given the lack of a reliable Arabic deep syntactic parser, we 1http://nlp.cs.swarthmore.edu/semeval/ 2We u</context>
<context position="9802" citStr="Diab et al., 2007" startWordPosition="1574" endWordPosition="1577">explicitly marked by the Definiteness article Al. Hence, these idafa constructions could be tricky for SRL in the absence of explicit morphological features. This is compounded by the general absence of short vowels, expressed by diacritics (i.e. the u and i in rjlu and Albyti,) in naturally occurring text. Idafa constructions in the ATB exhibit recursive structure, embedding other NPs, compared to English where possession is annotated with flat NPs and is designated by a possessive marker. Arabic texts are underspecified for diacritics to different degrees depending on the genre of the text (Diab et al., 2007b). Such an underspecification of diacritics masks some of the very relevant morpho-syntactic interactions between the different categories such as agreement between nominals and their modifiers as exemplified before, or verbs and their subjects. Having highlighted the differences, we hypothesize that the interaction between the rich morphology (if explicitly marked and present) and syntax could help with the SRL task. The presence of explicit Number and Gender agreement as well as Case information aids with identification of the syntactic subject and object even if the word order is relativel</context>
<context position="11636" citStr="Diab et al., 2007" startWordPosition="1854" endWordPosition="1857">ted to the branching of the argument No-direction path Like Path without traversal directions Phrase type Syntactic type of the argument node Position Relative position of the argument with respect to the predicate Verb subcategorization Production rule expanding the predicate parent node Syntactic Frame Position of the NPs surrounding the predicate First and last word/POS First and last words and POS tags of candidate argument phrases Table 1: Standard linguistic features employed by most SRL systems. Arabic. In this research, we go beyond the previously proposed basic SRL system for Arabic (Diab et al., 2007a; Diab and Moschitti, 2007). We exploit the full morphological potential of the language to verify our hypothesis that taking advantage of the interaction between morphology and syntax can improve on a basic SRL system for morphologically rich languages. Similar to the previous Arabic SRL systems, our adopted SRL models use Support Vector Machines to implement a two step classification approach, i.e. boundary detection and argument classification. Such models have already been investigated in (Pradhan et al., 2005; Moschitti et al., 2005). The two step classification description is as follows</context>
<context position="26022" citStr="Diab et al., 2007" startWordPosition="4254" endWordPosition="4257"> automatically generates feature conjunctions. This, as suggested in (Pradhan et al., 2005; Moschitti, 2004), can help stressing the differ803 ences between different argument types. Tree structures can be used in the learning algorithm thanks to the tree kernels described in Section 3.3. Moreover, to verify if the above feature sets are equivalent or complementary, we can join them by means of additive operation which always produces a valid kernel (Shawe-Taylor and Cristianini, 2004). 4.1 Experimental setup We use the dataset released in the SemEval 2007 Task 18 on Arabic Semantic Labeling (Diab et al., 2007a). The data covers the 95 most frequent verbs in the Arabic Treebank III ver. 2 (ATB). The ATB consists of MSA newswire data from the Annhar newspaper, spanning the months from July to November, 2002. All our experiments are carried out with gold standard trees. An important characteristic of the dataset is the use of unvowelized Arabic in the Buckwalter transliteration scheme for deriving the basic features for the AST experimental condition. The data comprises a development set, a test set and a training set of 886, 902 and 8,402 sentences, respectively, where each set contain 1725, 1661 an</context>
</contexts>
<marker>Diab, Ghoneim, Habash, 2007</marker>
<rawString>Mona Diab, Mahmoud Ghoneim, and Nizar Habash. 2007b. Arabic Diacritization in the Context of Statistical Machine Translation. In Proceedings of MTSummit, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
</authors>
<title>Towards an Optimal Pos Tag Set for Modern Standard Arabic Processing.</title>
<date>2007</date>
<booktitle>In Proceedings of RANLP, Borovets,</booktitle>
<marker>Diab, 2007</marker>
<rawString>Mona Diab. 2007. Towards an Optimal Pos Tag Set for Modern Standard Arabic Processing. In Proceedings of RANLP, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Pado</author>
</authors>
<title>Shalmaneser – A Toolchain for Shallow Semantic Parsing.</title>
<date>2006</date>
<booktitle>Proceedings of LREC.</booktitle>
<contexts>
<context position="2796" citStr="Erk and Pado, 2006" startWordPosition="438" endWordPosition="441">ea applies to passive constructions, for example. There is a widely held belief in the NLP and computational linguistics communities that identifying and defining roles of predicate arguments in a sentence has a lot of potential for and is a significant step toward improving important applications such as document retrieval, machine translation, question answering and information extraction (Moschitti et al., 2007). To date, most of the reported SRL systems are for English, and most of the data resources exist for English. We do see some headway for other languages such as German and Chinese (Erk and Pado, 2006; Sun and Jurafsky, 2004). The systems for the other languages follow the successful models devised for English, e.g. (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Thompson et al., 2003; Pradhan et al., 2003; Moschitti, 2004; Xue and Palmer, 2004; Haghighi et al., 2005). In the same spirit and facilitated by the release of the SemEval 2007 Task 18 data1, based on the Pilot Arabic Propbank, a preliminary SRL system exists for Arabic2 (Diab and Moschitti, 2007; Diab et al., 2007a). However, it did not exploit some special characteristics of the Arabic language on th</context>
</contexts>
<marker>Erk, Pado, 2006</marker>
<rawString>Katrin Erk and Sebastian Pado. 2006. Shalmaneser – A Toolchain for Shallow Semantic Parsing. Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic Labeling of Semantic Roles. Computational Linguistics.</title>
<date>2002</date>
<contexts>
<context position="2940" citStr="Gildea and Jurafsky, 2002" startWordPosition="460" endWordPosition="463"> identifying and defining roles of predicate arguments in a sentence has a lot of potential for and is a significant step toward improving important applications such as document retrieval, machine translation, question answering and information extraction (Moschitti et al., 2007). To date, most of the reported SRL systems are for English, and most of the data resources exist for English. We do see some headway for other languages such as German and Chinese (Erk and Pado, 2006; Sun and Jurafsky, 2004). The systems for the other languages follow the successful models devised for English, e.g. (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Thompson et al., 2003; Pradhan et al., 2003; Moschitti, 2004; Xue and Palmer, 2004; Haghighi et al., 2005). In the same spirit and facilitated by the release of the SemEval 2007 Task 18 data1, based on the Pilot Arabic Propbank, a preliminary SRL system exists for Arabic2 (Diab and Moschitti, 2007; Diab et al., 2007a). However, it did not exploit some special characteristics of the Arabic language on the SRL task. In this paper, we present an SRL system for MSA that exploits many aspects of the rich morphological features of the language. It is</context>
<context position="15592" citStr="Gildea and Jurafsky, 2002" startWordPosition="2526" endWordPosition="2529"> Features The discovery of relevant features is, as usual, a complex task. The choice of features is further compounded for a language such as Arabic given its rich morphology and morpho-syntactic interactions. To date, there is a common consensus on the set of basic standard features for SRL, which we will refer to as standard. The set of standard features, refers to unstructured information derived from parse trees. e.g. Phrase Type, Predicate Word or Head Word. Typically the standard features are language independent. In our experiments we employ the features listed in Table 1, defined in (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Xue and Palmer, 2004). For example, the Phrase Type indicates the syntactic type of the phrase labeled as a predicate argument, e.g. NP for ARG1 in Figure 1. The Parse Tree Path contains the path in the parse tree between the predicate and the argument phrase, expressed as a sequence of nonterminal labels linked by direction (up or down) symbols, e.g. VBD T VP ↓ NP for ARG1 in Figure 1. The Predicate Word is the surface form of the verbal predicate, e.g. started for all arguments. The standard features, as successful as they are, are designed primarily for English. They</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic Labeling of Semantic Roles. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Martha Palmer</author>
</authors>
<title>The Necessity of Parsing for Predicate Argument Recognition.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL-02,</booktitle>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="2965" citStr="Gildea and Palmer, 2002" startWordPosition="464" endWordPosition="467">oles of predicate arguments in a sentence has a lot of potential for and is a significant step toward improving important applications such as document retrieval, machine translation, question answering and information extraction (Moschitti et al., 2007). To date, most of the reported SRL systems are for English, and most of the data resources exist for English. We do see some headway for other languages such as German and Chinese (Erk and Pado, 2006; Sun and Jurafsky, 2004). The systems for the other languages follow the successful models devised for English, e.g. (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Thompson et al., 2003; Pradhan et al., 2003; Moschitti, 2004; Xue and Palmer, 2004; Haghighi et al., 2005). In the same spirit and facilitated by the release of the SemEval 2007 Task 18 data1, based on the Pilot Arabic Propbank, a preliminary SRL system exists for Arabic2 (Diab and Moschitti, 2007; Diab et al., 2007a). However, it did not exploit some special characteristics of the Arabic language on the SRL task. In this paper, we present an SRL system for MSA that exploits many aspects of the rich morphological features of the language. It is based on a supervised mo</context>
</contexts>
<marker>Gildea, Palmer, 2002</marker>
<rawString>Daniel Gildea and Martha Palmer. 2002. The Necessity of Parsing for Predicate Argument Recognition. In Proceedings ofACL-02, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL’05,</booktitle>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="16875" citStr="Habash and Rambow, 2005" startWordPosition="2737" endWordPosition="2740">bic language as expressed through morphology. Hence, we explicitly encode new SRL features that capture the richness of Arabic morphology and its role in morpho-syntactic behavior. The set of morphological attributes include: inflectional morphology such as Number, Gender, Definiteness, Mood, Case, Person; derivational morphology such as the Lemma form of the words with all the diacritics explicitly marked; vowelized and fully diacritized form of the surface form; the English gloss6. It is worth noting that there exists highly accurate morphological taggers for Arabic such as the MADA system (Habash and Rambow, 2005; Roth et al., 2008). MADA tags 6The gloss is not sense disambiguated, hence they include homonyms. 801 Feature Name Description Definiteness Applies to nominals, values are definite, indefinite or inapplicable Number Applies to nominals and verbs, values are singular, plural or dual or inapplicable Gender Applies to nominals, values are feminine, masculine or inapplicable Case Applies to nominals, values are accusative, genitive, nominative or inapplicable Mood Applies to verbs, values are subjunctive, indicative, jussive or inapplicable Person Applies to verbs and pronouns, values are 1st, 2</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proceedings of ACL’05, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Kristina Toutanova</author>
<author>Christopher Manning</author>
</authors>
<title>A Joint Model for Semantic Role Labeling.</title>
<date>2005</date>
<booktitle>In Proceedings ofCoNLL-2005,</booktitle>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="3096" citStr="Haghighi et al., 2005" startWordPosition="486" endWordPosition="489">ns such as document retrieval, machine translation, question answering and information extraction (Moschitti et al., 2007). To date, most of the reported SRL systems are for English, and most of the data resources exist for English. We do see some headway for other languages such as German and Chinese (Erk and Pado, 2006; Sun and Jurafsky, 2004). The systems for the other languages follow the successful models devised for English, e.g. (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Thompson et al., 2003; Pradhan et al., 2003; Moschitti, 2004; Xue and Palmer, 2004; Haghighi et al., 2005). In the same spirit and facilitated by the release of the SemEval 2007 Task 18 data1, based on the Pilot Arabic Propbank, a preliminary SRL system exists for Arabic2 (Diab and Moschitti, 2007; Diab et al., 2007a). However, it did not exploit some special characteristics of the Arabic language on the SRL task. In this paper, we present an SRL system for MSA that exploits many aspects of the rich morphological features of the language. It is based on a supervised model that uses support vector machines (SVM) technology (Vapnik, 1998) for argument boundary detection and argument classification. </context>
</contexts>
<marker>Haghighi, Toutanova, Manning, 2005</marker>
<rawString>Aria Haghighi, Kristina Toutanova, and Christopher Manning. 2005. A Joint Model for Semantic Role Labeling. In Proceedings ofCoNLL-2005, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Kingsbury</author>
<author>Martha Palmer</author>
</authors>
<title>Propbank: the Next Level of Treebank.</title>
<date>2003</date>
<booktitle>In Proceedings of Treebanks and Lexical Theories.</booktitle>
<contexts>
<context position="1457" citStr="Kingsbury and Palmer, 2003" startWordPosition="214" endWordPosition="217">ines and Kernel Methods yields a global SRL F1 score of 82.17%, which improves the current state-of-the-art in Arabic SRL. 1 Introduction Shallow approaches to semantic processing are making large strides in the direction of efficiently and effectively deriving tacit semantic information from text. Semantic Role Labeling (SRL) is one such approach. With the advent of faster and more powerful computers, more effective machine learning algorithms, and importantly, large data resources annotated with relevant levels of semantic information, such as the FrameNet (Baker et al., 1998) and ProbBank (Kingsbury and Palmer, 2003), we are seeing a surge in efficient approaches to SRL (Carreras and M`arquez, 2005). SRL is the process by which predicates and their arguments are identified and their roles are defined in a sentence. For example, in the English sentence, ‘John likes apples.’, the predicate is ‘likes’ whereas ‘John’ and ‘apples’, bear the semantic role labels agent (ARG0) and theme (ARG1). The crucial fact about semantic roles is that regardless of the overt syntactic structure variation, the underlying predicates remain the same. Hence, for the sentence ‘John opened the door’ and ‘the door opened’, though ‘</context>
</contexts>
<marker>Kingsbury, Palmer, 2003</marker>
<rawString>Paul Kingsbury and Martha Palmer. 2003. Propbank: the Next Level of Treebank. In Proceedings of Treebanks and Lexical Theories.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Tim Buckwalter</author>
<author>Wigdan Mekki</author>
</authors>
<title>The Penn Arabic Treebank : Building a Large-Scale Annotated Arabic Corpus.</title>
<date>2004</date>
<contexts>
<context position="4166" citStr="Maamouri et al., 2004" startWordPosition="660" endWordPosition="663">ed on a supervised model that uses support vector machines (SVM) technology (Vapnik, 1998) for argument boundary detection and argument classification. It is trained and tested using the pilot Arabic Propbank data released as part of the SemEval 2007 data. Given the lack of a reliable Arabic deep syntactic parser, we 1http://nlp.cs.swarthmore.edu/semeval/ 2We use Arabic to refer to Modern Standard Arabic (MSA). 798 Proceedings of ACL-08: HLT, pages 798–806, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics use gold standard trees from the Arabic Tree Bank (ATB) (Maamouri et al., 2004). This paper is laid out as follows: Section 2 presents facts about the Arabic language especially in relevant contrast to English; Section 3 presents the approach and system adopted for this work; Section 4 presents the experimental setup, results and discussion. Finally, Section 5 draws our conclusions. 2 Arabic Language and Impact on SRL Arabic is a very different language from English in several respects relevant to the SRL task. Arabic is a semitic language. It is known for its templatic morphology where words are made up of roots and affixes. Clitics agglutinate to words. Clitics include</context>
</contexts>
<marker>Maamouri, Bies, Buckwalter, Mekki, 2004</marker>
<rawString>Mohamed Maamouri, Ann Bies, Tim Buckwalter, and Wigdan Mekki. 2004. The Penn Arabic Treebank : Building a Large-Scale Annotated Arabic Corpus.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Tim Buckwalter</author>
<author>Mona Diab</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Dalila Tabessi</author>
</authors>
<title>Developing and Using a Pilot Dialectal Arabic Treebank.</title>
<date>2006</date>
<contexts>
<context position="5776" citStr="Maamouri et al., 2006" startWordPosition="914" endWordPosition="917"> genitive and nominative), Number, Gender and Definiteness features. In general, many of the morphological features of the language are expressed via short vowels also known as diacritics3. Unlike English, syntactically Arabic is a pro-drop language, where the subject of a verb may be implicitly encoded in the verb morphology. Hence, we observe sentences such as ÈA�®Z,,�.Ë@ É¿@ Akl AlbrtqAl ‘ate-[he] the-oranges’, where the verb Akl encodes the third Person Masculine Singular subject in the verbal morphology. It is worth noting that in the ATB 35% of all sentences are pro-dropped for subject (Maamouri et al., 2006). Unless the syntactic parse is very accurate in identifying the pro-dropped case, identifying the syntactic subject and the underlying semantic arguments are a challenge for such pro-drop cases. Arabic syntax exhibits relative free word order. Arabic allows for both subject-verb-object (SVO) and verb-subject-object (VSO) argument orders.4 In 3Diacritics encode the vocalic structure, namely the short vowels, as well as the gemmination marker for consonantal doubling, among other markers. 4MSA less often allows for OSV, or OVS. the VSO constructions, the verb agrees with the syntactic subject i</context>
</contexts>
<marker>Maamouri, Bies, Buckwalter, Diab, Habash, Rambow, Tabessi, 2006</marker>
<rawString>Mohamed Maamouri, Ann Bies, Tim Buckwalter, Mona Diab, Nizar Habash, Owen Rambow, and Dalila Tabessi. 2006. Developing and Using a Pilot Dialectal Arabic Treebank.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Ana-Maria Giuglea</author>
<author>Bonaventura Coppola</author>
<author>Roberto Basili</author>
</authors>
<title>Hierarchical Semantic Role Labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of CoNLL2005,</booktitle>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="12181" citStr="Moschitti et al., 2005" startWordPosition="1937" endWordPosition="1940"> beyond the previously proposed basic SRL system for Arabic (Diab et al., 2007a; Diab and Moschitti, 2007). We exploit the full morphological potential of the language to verify our hypothesis that taking advantage of the interaction between morphology and syntax can improve on a basic SRL system for morphologically rich languages. Similar to the previous Arabic SRL systems, our adopted SRL models use Support Vector Machines to implement a two step classification approach, i.e. boundary detection and argument classification. Such models have already been investigated in (Pradhan et al., 2005; Moschitti et al., 2005). The two step classification description is as follows. 3.1 Predicate Argument Extraction The extraction of predicative structures is based on the sentence level. Given a sentence, its predicates, as indicated by verbs, have to be identified along with their arguments. This problem is usually divided in two subtasks: (a) the detection of the target argument boundaries, i.e. the span of the argument words in the sentence, and (b) the classification of the argument type, e.g. Arg0 or ArgM for Propbank 800 Figure 2: Fragment space generated by a tree kernel function for the sentence Mary bought </context>
</contexts>
<marker>Moschitti, Giuglea, Coppola, Basili, 2005</marker>
<rawString>Alessandro Moschitti, Ana-Maria Giuglea, Bonaventura Coppola, and Roberto Basili. 2005. Hierarchical Semantic Role Labeling. In Proceedings of CoNLL2005, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Silvia Quarteroni</author>
<author>Roberto Basili</author>
<author>Suresh Manandhar</author>
</authors>
<title>Exploiting Syntactic and Shallow Semantic Kernels for Question Answer Classification.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL’07,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2596" citStr="Moschitti et al., 2007" startWordPosition="400" endWordPosition="403">same. Hence, for the sentence ‘John opened the door’ and ‘the door opened’, though ‘the door’ is the object of the first sentence and the subject of the second, it is the ‘theme’ in both sentences. Same idea applies to passive constructions, for example. There is a widely held belief in the NLP and computational linguistics communities that identifying and defining roles of predicate arguments in a sentence has a lot of potential for and is a significant step toward improving important applications such as document retrieval, machine translation, question answering and information extraction (Moschitti et al., 2007). To date, most of the reported SRL systems are for English, and most of the data resources exist for English. We do see some headway for other languages such as German and Chinese (Erk and Pado, 2006; Sun and Jurafsky, 2004). The systems for the other languages follow the successful models devised for English, e.g. (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Thompson et al., 2003; Pradhan et al., 2003; Moschitti, 2004; Xue and Palmer, 2004; Haghighi et al., 2005). In the same spirit and facilitated by the release of the SemEval 2007 Task 18 data1, based on the </context>
</contexts>
<marker>Moschitti, Quarteroni, Basili, Manandhar, 2007</marker>
<rawString>Alessandro Moschitti, Silvia Quarteroni, Roberto Basili, and Suresh Manandhar. 2007. Exploiting Syntactic and Shallow Semantic Kernels for Question Answer Classification. In Proceedings of ACL’07, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>A Study on Convolution Kernels for Shallow Semantic Parsing.</title>
<date>2004</date>
<booktitle>In proceedings ofACL’04,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="3050" citStr="Moschitti, 2004" startWordPosition="480" endWordPosition="481">p toward improving important applications such as document retrieval, machine translation, question answering and information extraction (Moschitti et al., 2007). To date, most of the reported SRL systems are for English, and most of the data resources exist for English. We do see some headway for other languages such as German and Chinese (Erk and Pado, 2006; Sun and Jurafsky, 2004). The systems for the other languages follow the successful models devised for English, e.g. (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Thompson et al., 2003; Pradhan et al., 2003; Moschitti, 2004; Xue and Palmer, 2004; Haghighi et al., 2005). In the same spirit and facilitated by the release of the SemEval 2007 Task 18 data1, based on the Pilot Arabic Propbank, a preliminary SRL system exists for Arabic2 (Diab and Moschitti, 2007; Diab et al., 2007a). However, it did not exploit some special characteristics of the Arabic language on the SRL task. In this paper, we present an SRL system for MSA that exploits many aspects of the rich morphological features of the language. It is based on a supervised model that uses support vector machines (SVM) technology (Vapnik, 1998) for argument bo</context>
<context position="18569" citStr="Moschitti, 2004" startWordPosition="2996" endWordPosition="2998"> features encoded in the Extended Argument Structure Tree (EAST). modern standard Arabic with all the relevant morphological features as well as it produces highly accurate lemma and gloss information by tapping into an underlying morphological lexicon. A list of the extended features is described in Table 2. The set of possible features and their combinations are very large leading to an intractable feature selection problem. Therefore, we exploit well known kernel methods, namely tree kernels, to robustly experiment with all the features simultaneously. Such kernel engineering, as shown in (Moschitti, 2004), allows us to experiment with many syntactic/semantic features seamlessly. 3.3 Engineering Arabic Features with Kernel Methods Feature engineering via kernel methods is a useful technique that allows us to save a lot of time in the design and implementation of features. The basic idea is (a) to design a set of basic value-attribute features and apply polynomial kernels and generate all possible combinations; or (b) to design basic tree structures expressing properties related to the target linguistic objects and use tree kernels to generate all possible tree subparts, which will constitute th</context>
<context position="25513" citStr="Moschitti, 2004" startWordPosition="4172" endWordPosition="4173"> (b) the impact of tree kernels using new tree structures on Arabic SRL. For this purpose, we test our models on the two individual phases of the traditional 2-stage SRL model (i.e. boundary detection and argument classification) and on the complete SRL task. We use three different feature spaces: a set of standard attribute-value features and the AST and the EAST structures defined in 3.4. Standard feature vectors can be combined with a polynomial kernel (Poly), which, when the degree is larger than 1, automatically generates feature conjunctions. This, as suggested in (Pradhan et al., 2005; Moschitti, 2004), can help stressing the differ803 ences between different argument types. Tree structures can be used in the learning algorithm thanks to the tree kernels described in Section 3.3. Moreover, to verify if the above feature sets are equivalent or complementary, we can join them by means of additive operation which always produces a valid kernel (Shawe-Taylor and Cristianini, 2004). 4.1 Experimental setup We use the dataset released in the SemEval 2007 Task 18 on Arabic Semantic Labeling (Diab et al., 2007a). The data covers the 95 most frequent verbs in the Arabic Treebank III ver. 2 (ATB). The</context>
<context position="26944" citStr="Moschitti, 2004" startWordPosition="4403" endWordPosition="4404">is the use of unvowelized Arabic in the Buckwalter transliteration scheme for deriving the basic features for the AST experimental condition. The data comprises a development set, a test set and a training set of 886, 902 and 8,402 sentences, respectively, where each set contain 1725, 1661 and 21,194 argument instances. These instances are distributed over 26 different role types. The training instances of the boundary detection task also include parse-tree nodes that do not correspond to correct boundaries (we only considered 350K examples). For the experiments, we use SVM-Light-TK toolkit8 (Moschitti, 2004; Moschitti, 2006) and its SVM-Light default parameters. The system performance, i.e. F1 on single boundary and role classifier, accuracy of the role multi-classifier and the F1 of the complete SRL systems, are computed by means of the CoNLL evaluator9. 4.2 Results Figure 5 reports the F1 of the SVM boundary classifier using Polynomial Kernels with a degree from 1 to 6 (i.e. Polyi), the AST and the EAST kernels and their combinations. We note that as we introduce conjunctions, i.e. a degree larger than 2, the F1 increases by more than 3 percentage points. Thus, not only are the English feature</context>
</contexts>
<marker>Moschitti, 2004</marker>
<rawString>Alessandro Moschitti. 2004. A Study on Convolution Kernels for Shallow Semantic Parsing. In proceedings ofACL’04, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Making Tree Kernels Practical for Natural Language Learning.</title>
<date>2006</date>
<booktitle>In Proceedings ofEACL’06.</booktitle>
<contexts>
<context position="26962" citStr="Moschitti, 2006" startWordPosition="4405" endWordPosition="4406">owelized Arabic in the Buckwalter transliteration scheme for deriving the basic features for the AST experimental condition. The data comprises a development set, a test set and a training set of 886, 902 and 8,402 sentences, respectively, where each set contain 1725, 1661 and 21,194 argument instances. These instances are distributed over 26 different role types. The training instances of the boundary detection task also include parse-tree nodes that do not correspond to correct boundaries (we only considered 350K examples). For the experiments, we use SVM-Light-TK toolkit8 (Moschitti, 2004; Moschitti, 2006) and its SVM-Light default parameters. The system performance, i.e. F1 on single boundary and role classifier, accuracy of the role multi-classifier and the F1 of the complete SRL systems, are computed by means of the CoNLL evaluator9. 4.2 Results Figure 5 reports the F1 of the SVM boundary classifier using Polynomial Kernels with a degree from 1 to 6 (i.e. Polyi), the AST and the EAST kernels and their combinations. We note that as we introduce conjunctions, i.e. a degree larger than 2, the F1 increases by more than 3 percentage points. Thus, not only are the English features meaningful for A</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006. Making Tree Kernels Practical for Natural Language Learning. In Proceedings ofEACL’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Daniele Pighin</author>
<author>Roberto Basili</author>
</authors>
<title>Semantic Role Labeling via Tree Kernel Joint Inference.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL-X.</booktitle>
<marker>Moschitti, Pighin, Basili, 2006</marker>
<rawString>Alessandro Moschitti, Daniele Pighin and Roberto Basili. 2006. Semantic Role Labeling via Tree Kernel Joint Inference. In Proceedings of CoNLL-X.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Kadri Hacioglu</author>
<author>Wayne Ward</author>
<author>James H Martin</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Semantic Role Parsing: Adding Semantic Structure to Unstructured Text.</title>
<date>2003</date>
<booktitle>In Proceedings ICDM’03,</booktitle>
<location>Melbourne, USA.</location>
<contexts>
<context position="3033" citStr="Pradhan et al., 2003" startWordPosition="476" endWordPosition="479">d is a significant step toward improving important applications such as document retrieval, machine translation, question answering and information extraction (Moschitti et al., 2007). To date, most of the reported SRL systems are for English, and most of the data resources exist for English. We do see some headway for other languages such as German and Chinese (Erk and Pado, 2006; Sun and Jurafsky, 2004). The systems for the other languages follow the successful models devised for English, e.g. (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Thompson et al., 2003; Pradhan et al., 2003; Moschitti, 2004; Xue and Palmer, 2004; Haghighi et al., 2005). In the same spirit and facilitated by the release of the SemEval 2007 Task 18 data1, based on the Pilot Arabic Propbank, a preliminary SRL system exists for Arabic2 (Diab and Moschitti, 2007; Diab et al., 2007a). However, it did not exploit some special characteristics of the Arabic language on the SRL task. In this paper, we present an SRL system for MSA that exploits many aspects of the rich morphological features of the language. It is based on a supervised model that uses support vector machines (SVM) technology (Vapnik, 1998</context>
</contexts>
<marker>Pradhan, Hacioglu, Ward, Martin, Jurafsky, 2003</marker>
<rawString>Sameer Pradhan, Kadri Hacioglu, Wayne Ward, James H. Martin, and Daniel Jurafsky. 2003. Semantic Role Parsing: Adding Semantic Structure to Unstructured Text. In Proceedings ICDM’03, Melbourne, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Kadri Hacioglu</author>
<author>Valerie Krugler</author>
<author>Wayne Ward</author>
<author>James H Martin</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Support Vector Learning for Semantic Argument Classification.</title>
<date>2005</date>
<journal>Machine Learning.</journal>
<contexts>
<context position="12156" citStr="Pradhan et al., 2005" startWordPosition="1933" endWordPosition="1936">n this research, we go beyond the previously proposed basic SRL system for Arabic (Diab et al., 2007a; Diab and Moschitti, 2007). We exploit the full morphological potential of the language to verify our hypothesis that taking advantage of the interaction between morphology and syntax can improve on a basic SRL system for morphologically rich languages. Similar to the previous Arabic SRL systems, our adopted SRL models use Support Vector Machines to implement a two step classification approach, i.e. boundary detection and argument classification. Such models have already been investigated in (Pradhan et al., 2005; Moschitti et al., 2005). The two step classification description is as follows. 3.1 Predicate Argument Extraction The extraction of predicative structures is based on the sentence level. Given a sentence, its predicates, as indicated by verbs, have to be identified along with their arguments. This problem is usually divided in two subtasks: (a) the detection of the target argument boundaries, i.e. the span of the argument words in the sentence, and (b) the classification of the argument type, e.g. Arg0 or ArgM for Propbank 800 Figure 2: Fragment space generated by a tree kernel function for </context>
<context position="14295" citStr="Pradhan et al., 2005" startWordPosition="2326" endWordPosition="2329">ted with the nodes NP, S, VP, VPD, NNP, NN, PP, JJ or IN the instances Fstarted,a are generated. In case the node a exactly covers ‘president ministers Chinese Zhu Rongji’ or ‘visit official to India’, Fp,a will be a positive instance otherwise it will be a negative one, e.g. Fstarted,IN. The T+ and T− sets are used to train the boundary classifier. To train the multi-class classifier, T+ can be reorganized as positive T+argi and negative T−argi examples for each argument i. This way, an individual ONE-vs-ALL classifier for each argument i can be trained. We adopt this solution, according to (Pradhan et al., 2005), since it is simple and effective. In the classification phase, given an unseen sentence, all its Fp,a are generated and classified by each individual classifier Ci. The argument associated with the maximum among the scores provided by the individual classifiers is eventually selected. The above approach assigns labels independently, without considering the whole predicate argument structure. As a consequence, the classifier output may generate overlapping arguments. Thus, to make the annotations globally consistent, we apply a disambiguating heuristic adopted from (Diab and Moschitti, 2007) </context>
<context position="15614" citStr="Pradhan et al., 2005" startWordPosition="2530" endWordPosition="2533">relevant features is, as usual, a complex task. The choice of features is further compounded for a language such as Arabic given its rich morphology and morpho-syntactic interactions. To date, there is a common consensus on the set of basic standard features for SRL, which we will refer to as standard. The set of standard features, refers to unstructured information derived from parse trees. e.g. Phrase Type, Predicate Word or Head Word. Typically the standard features are language independent. In our experiments we employ the features listed in Table 1, defined in (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Xue and Palmer, 2004). For example, the Phrase Type indicates the syntactic type of the phrase labeled as a predicate argument, e.g. NP for ARG1 in Figure 1. The Parse Tree Path contains the path in the parse tree between the predicate and the argument phrase, expressed as a sequence of nonterminal labels linked by direction (up or down) symbols, e.g. VBD T VP ↓ NP for ARG1 in Figure 1. The Predicate Word is the surface form of the verbal predicate, e.g. started for all arguments. The standard features, as successful as they are, are designed primarily for English. They are not exploiting th</context>
<context position="25495" citStr="Pradhan et al., 2005" startWordPosition="4168" endWordPosition="4171">rabic SRL systems, and (b) the impact of tree kernels using new tree structures on Arabic SRL. For this purpose, we test our models on the two individual phases of the traditional 2-stage SRL model (i.e. boundary detection and argument classification) and on the complete SRL task. We use three different feature spaces: a set of standard attribute-value features and the AST and the EAST structures defined in 3.4. Standard feature vectors can be combined with a polynomial kernel (Poly), which, when the degree is larger than 1, automatically generates feature conjunctions. This, as suggested in (Pradhan et al., 2005; Moschitti, 2004), can help stressing the differ803 ences between different argument types. Tree structures can be used in the learning algorithm thanks to the tree kernels described in Section 3.3. Moreover, to verify if the above feature sets are equivalent or complementary, we can join them by means of additive operation which always produces a valid kernel (Shawe-Taylor and Cristianini, 2004). 4.1 Experimental setup We use the dataset released in the SemEval 2007 Task 18 on Arabic Semantic Labeling (Diab et al., 2007a). The data covers the 95 most frequent verbs in the Arabic Treebank III</context>
</contexts>
<marker>Pradhan, Hacioglu, Krugler, Ward, Martin, Jurafsky, 2005</marker>
<rawString>Sameer Pradhan, Kadri Hacioglu, Valerie Krugler, Wayne Ward, James H. Martin, and Daniel Jurafsky. 2005. Support Vector Learning for Semantic Argument Classification. Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Roth</author>
<author>Owen Rambow</author>
<author>Nizar Habash</author>
<author>Mona Diab</author>
<author>Cynthia Rudin</author>
</authors>
<title>Arabic Morphological Tagging, Diacritization, and Lemmatization Using Lexeme Models and Feature Ranking.</title>
<date>2008</date>
<booktitle>In ACL’08, Short Papers,</booktitle>
<location>Columbus, Ohio,</location>
<contexts>
<context position="16895" citStr="Roth et al., 2008" startWordPosition="2741" endWordPosition="2744"> through morphology. Hence, we explicitly encode new SRL features that capture the richness of Arabic morphology and its role in morpho-syntactic behavior. The set of morphological attributes include: inflectional morphology such as Number, Gender, Definiteness, Mood, Case, Person; derivational morphology such as the Lemma form of the words with all the diacritics explicitly marked; vowelized and fully diacritized form of the surface form; the English gloss6. It is worth noting that there exists highly accurate morphological taggers for Arabic such as the MADA system (Habash and Rambow, 2005; Roth et al., 2008). MADA tags 6The gloss is not sense disambiguated, hence they include homonyms. 801 Feature Name Description Definiteness Applies to nominals, values are definite, indefinite or inapplicable Number Applies to nominals and verbs, values are singular, plural or dual or inapplicable Gender Applies to nominals, values are feminine, masculine or inapplicable Case Applies to nominals, values are accusative, genitive, nominative or inapplicable Mood Applies to verbs, values are subjunctive, indicative, jussive or inapplicable Person Applies to verbs and pronouns, values are 1st, 2nd, 3rd person or in</context>
</contexts>
<marker>Roth, Rambow, Habash, Diab, Rudin, 2008</marker>
<rawString>Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab, and Cynthia Rudin. 2008. Arabic Morphological Tagging, Diacritization, and Lemmatization Using Lexeme Models and Feature Ranking. In ACL’08, Short Papers, Columbus, Ohio, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
</authors>
<title>Kernel Methods for Pattern Analysis.</title>
<date>2004</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="25895" citStr="Shawe-Taylor and Cristianini, 2004" startWordPosition="4232" endWordPosition="4235">AST structures defined in 3.4. Standard feature vectors can be combined with a polynomial kernel (Poly), which, when the degree is larger than 1, automatically generates feature conjunctions. This, as suggested in (Pradhan et al., 2005; Moschitti, 2004), can help stressing the differ803 ences between different argument types. Tree structures can be used in the learning algorithm thanks to the tree kernels described in Section 3.3. Moreover, to verify if the above feature sets are equivalent or complementary, we can join them by means of additive operation which always produces a valid kernel (Shawe-Taylor and Cristianini, 2004). 4.1 Experimental setup We use the dataset released in the SemEval 2007 Task 18 on Arabic Semantic Labeling (Diab et al., 2007a). The data covers the 95 most frequent verbs in the Arabic Treebank III ver. 2 (ATB). The ATB consists of MSA newswire data from the Annhar newspaper, spanning the months from July to November, 2002. All our experiments are carried out with gold standard trees. An important characteristic of the dataset is the use of unvowelized Arabic in the Buckwalter transliteration scheme for deriving the basic features for the AST experimental condition. The data comprises a dev</context>
</contexts>
<marker>Shawe-Taylor, Cristianini, 2004</marker>
<rawString>John Shawe-Taylor and Nello Cristianini. 2004. Kernel Methods for Pattern Analysis. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Honglin Sun</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Shallow Semantic Parsing of Chinese.</title>
<date>2004</date>
<booktitle>In Proceedings of NAACLHLT.</booktitle>
<contexts>
<context position="2821" citStr="Sun and Jurafsky, 2004" startWordPosition="442" endWordPosition="445">e constructions, for example. There is a widely held belief in the NLP and computational linguistics communities that identifying and defining roles of predicate arguments in a sentence has a lot of potential for and is a significant step toward improving important applications such as document retrieval, machine translation, question answering and information extraction (Moschitti et al., 2007). To date, most of the reported SRL systems are for English, and most of the data resources exist for English. We do see some headway for other languages such as German and Chinese (Erk and Pado, 2006; Sun and Jurafsky, 2004). The systems for the other languages follow the successful models devised for English, e.g. (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Thompson et al., 2003; Pradhan et al., 2003; Moschitti, 2004; Xue and Palmer, 2004; Haghighi et al., 2005). In the same spirit and facilitated by the release of the SemEval 2007 Task 18 data1, based on the Pilot Arabic Propbank, a preliminary SRL system exists for Arabic2 (Diab and Moschitti, 2007; Diab et al., 2007a). However, it did not exploit some special characteristics of the Arabic language on the SRL task. In this paper</context>
</contexts>
<marker>Sun, Jurafsky, 2004</marker>
<rawString>Honglin Sun and Daniel Jurafsky. 2004. Shallow Semantic Parsing of Chinese. In Proceedings of NAACLHLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia A Thompson</author>
<author>Roger Levy</author>
<author>Christopher Manning</author>
</authors>
<title>A Generative Model for Semantic Role Labeling.</title>
<date>2003</date>
<booktitle>In ECML’03.</booktitle>
<contexts>
<context position="3011" citStr="Thompson et al., 2003" startWordPosition="472" endWordPosition="475">lot of potential for and is a significant step toward improving important applications such as document retrieval, machine translation, question answering and information extraction (Moschitti et al., 2007). To date, most of the reported SRL systems are for English, and most of the data resources exist for English. We do see some headway for other languages such as German and Chinese (Erk and Pado, 2006; Sun and Jurafsky, 2004). The systems for the other languages follow the successful models devised for English, e.g. (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Thompson et al., 2003; Pradhan et al., 2003; Moschitti, 2004; Xue and Palmer, 2004; Haghighi et al., 2005). In the same spirit and facilitated by the release of the SemEval 2007 Task 18 data1, based on the Pilot Arabic Propbank, a preliminary SRL system exists for Arabic2 (Diab and Moschitti, 2007; Diab et al., 2007a). However, it did not exploit some special characteristics of the Arabic language on the SRL task. In this paper, we present an SRL system for MSA that exploits many aspects of the rich morphological features of the language. It is based on a supervised model that uses support vector machines (SVM) te</context>
</contexts>
<marker>Thompson, Levy, Manning, 2003</marker>
<rawString>Cynthia A. Thompson, Roger Levy, and Christopher Manning. 2003. A Generative Model for Semantic Role Labeling. In ECML’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>John Wiley and Sons.</publisher>
<contexts>
<context position="3634" citStr="Vapnik, 1998" startWordPosition="582" endWordPosition="583">et al., 2003; Moschitti, 2004; Xue and Palmer, 2004; Haghighi et al., 2005). In the same spirit and facilitated by the release of the SemEval 2007 Task 18 data1, based on the Pilot Arabic Propbank, a preliminary SRL system exists for Arabic2 (Diab and Moschitti, 2007; Diab et al., 2007a). However, it did not exploit some special characteristics of the Arabic language on the SRL task. In this paper, we present an SRL system for MSA that exploits many aspects of the rich morphological features of the language. It is based on a supervised model that uses support vector machines (SVM) technology (Vapnik, 1998) for argument boundary detection and argument classification. It is trained and tested using the pilot Arabic Propbank data released as part of the SemEval 2007 data. Given the lack of a reliable Arabic deep syntactic parser, we 1http://nlp.cs.swarthmore.edu/semeval/ 2We use Arabic to refer to Modern Standard Arabic (MSA). 798 Proceedings of ACL-08: HLT, pages 798–806, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics use gold standard trees from the Arabic Tree Bank (ATB) (Maamouri et al., 2004). This paper is laid out as follows: Section 2 presents facts about </context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>Vladimir N. Vapnik. 1998. Statistical Learning Theory. John Wiley and Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Calibrating Features for Semantic Role Labeling.</title>
<date>2004</date>
<booktitle>In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004,</booktitle>
<location>Barcelona, Spain.</location>
<contexts>
<context position="3072" citStr="Xue and Palmer, 2004" startWordPosition="482" endWordPosition="485">g important applications such as document retrieval, machine translation, question answering and information extraction (Moschitti et al., 2007). To date, most of the reported SRL systems are for English, and most of the data resources exist for English. We do see some headway for other languages such as German and Chinese (Erk and Pado, 2006; Sun and Jurafsky, 2004). The systems for the other languages follow the successful models devised for English, e.g. (Gildea and Jurafsky, 2002; Gildea and Palmer, 2002; Chen and Rambow, 2003; Thompson et al., 2003; Pradhan et al., 2003; Moschitti, 2004; Xue and Palmer, 2004; Haghighi et al., 2005). In the same spirit and facilitated by the release of the SemEval 2007 Task 18 data1, based on the Pilot Arabic Propbank, a preliminary SRL system exists for Arabic2 (Diab and Moschitti, 2007; Diab et al., 2007a). However, it did not exploit some special characteristics of the Arabic language on the SRL task. In this paper, we present an SRL system for MSA that exploits many aspects of the rich morphological features of the language. It is based on a supervised model that uses support vector machines (SVM) technology (Vapnik, 1998) for argument boundary detection and a</context>
<context position="15637" citStr="Xue and Palmer, 2004" startWordPosition="2534" endWordPosition="2537">as usual, a complex task. The choice of features is further compounded for a language such as Arabic given its rich morphology and morpho-syntactic interactions. To date, there is a common consensus on the set of basic standard features for SRL, which we will refer to as standard. The set of standard features, refers to unstructured information derived from parse trees. e.g. Phrase Type, Predicate Word or Head Word. Typically the standard features are language independent. In our experiments we employ the features listed in Table 1, defined in (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Xue and Palmer, 2004). For example, the Phrase Type indicates the syntactic type of the phrase labeled as a predicate argument, e.g. NP for ARG1 in Figure 1. The Parse Tree Path contains the path in the parse tree between the predicate and the argument phrase, expressed as a sequence of nonterminal labels linked by direction (up or down) symbols, e.g. VBD T VP ↓ NP for ARG1 in Figure 1. The Predicate Word is the surface form of the verbal predicate, e.g. started for all arguments. The standard features, as successful as they are, are designed primarily for English. They are not exploiting the different characteris</context>
</contexts>
<marker>Xue, Palmer, 2004</marker>
<rawString>Nianwen Xue and Martha Palmer. 2004. Calibrating Features for Semantic Role Labeling. In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004, Barcelona, Spain.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>