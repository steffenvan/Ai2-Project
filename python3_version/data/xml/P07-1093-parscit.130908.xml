<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.891065">
A Maximum Expected Utility Framework for Binary Sequence Labeling
</title>
<author confidence="0.882">
Martin Jansche*
</author>
<email confidence="0.927438">
jansche@acm.org
</email>
<sectionHeader confidence="0.996629" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999944363636364">
We consider the problem of predictive infer-
ence for probabilistic binary sequence label-
ing models under F-score as utility. For a
simple class of models, we show that the
number of hypotheses whose expected F-
score needs to be evaluated is linear in the
sequence length and present a framework for
efficiently evaluating the expectation of many
common loss/utility functions, including the
F-score. This framework includes both exact
and faster inexact calculation methods.
</bodyText>
<sectionHeader confidence="0.999815" genericHeader="introduction">
1 Introduction
</sectionHeader>
<subsectionHeader confidence="0.999196">
1.1 Motivation and Scope
</subsectionHeader>
<bodyText confidence="0.999904136363636">
The weighted F-score (van Rijsbergen, 1974) plays
an important role in the evaluation of binary classi-
fiers, as it neatly summarizes a classifier’s ability to
identify the positive class. A variety of methods ex-
ists for training classifiers that optimize the F-score,
or some similar trade-off between false positives and
false negatives, precision and recall, sensitivity and
specificity, type I error and type II error rate, etc.
Among the most general methods are those of Mozer
et al. (2001), whose constrained optimization tech-
nique is similar to those in (Gao et al., 2006; Jansche,
2005). More specialized methods also exist, for ex-
ample for support vector machines (Musicant et al.,
2003) and for conditional random fields (Gross et al.,
2007; Suzuki et al., 2006).
All of these methods are about classifier training.
In this paper we focus primarily on the related, but
orthogonal, issue of predictive inference with a fully
trained probabilistic classifier. Using the weighted
F-score as our utility function, predictive inference
amounts to choosing an optimal hypothesis which
maximizes the expected utility. We refer to this as
</bodyText>
<affiliation confidence="0.2151805">
*Current affiliation: Google Inc. Former affiliation: Center
of Computational Learning Systems, Columbia University.
</affiliation>
<bodyText confidence="0.999937636363636">
the prediction or decoding task. In general, decoding
can be a hard computational problem (Casacuberta
and de la Higuera, 2000; Knight, 1999). In this paper
we show that the maximum expected F-score decod-
ing problem can be solved in polynomial time under
certain assumptions about the underlying probabil-
ity model. One key ingredient in our solution is a
very general framework for evaluating the expected
F-score, and indeed many other utility functions, of
a fixed hypothesis.1 This framework can also be ap-
plied to discriminative classifier training.
</bodyText>
<subsectionHeader confidence="0.97859">
1.2 Background and Notation
</subsectionHeader>
<bodyText confidence="0.9993737">
We formulate our approach in terms of sequence la-
beling, although it has applications beyond that. This
is motivated by the fact that our framework for evalu-
ating expected utility is indeed applicable to general
sequence labeling tasks, while our decoding method
is more restricted. Another reason is that the F-score
is only meaningful for comparing two (multi)sets or
two binary sequences, but the notation for multisets
is slightly more awkward.
All tasks considered here involve strings of binary
labels. We write the length of a given string y E
{0,1}n as |y |= n. It is convenient to view such strings
as real vectors – whose components happen to be 0
or 1 – with the dot product defined as usual. Then
y y is the number of ones that occur in the string y.
For two strings x,y of the same length |x |= |y |the
number of ones that occur at corresponding indices
is x y.
Given a hypothesis z and a gold standard label
sequence y, we define the following quantities:
</bodyText>
<listItem confidence="0.9976095">
1. T = y y, the genuine positives;
2. P = z z, the predicted positives;
3. A = z y, the true positives (predicted positives
that are genuinely positive);
</listItem>
<footnote confidence="0.919852">
1A proof-of-concept implementation is available at http:
//purl.org/net/jansche/meu_framework/.
</footnote>
<page confidence="0.930358">
736
</page>
<note confidence="0.818196">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 736–743,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<listItem confidence="0.9786175">
4. Recl = A/T, recall (a.k.a. sensitivity or power);
5. Prec = A/P, precision.
</listItem>
<bodyText confidence="0.991054333333333">
The β-weighted F-score is then defined as the
weighted harmonic mean of recall and precision. This
simplifies to
</bodyText>
<equation confidence="0.999657">
(β + 1) A
Fβ = P+β T (β &gt; 0) (1)
</equation>
<bodyText confidence="0.9999318">
where we assume for convenience that 0/0 def � 1 to
avoid explicitly dealing with the special case of the
denominator being zero. We will write the weighted
F-score from now on as F(z,y) to emphasize that it
is a function of z and y.
</bodyText>
<subsectionHeader confidence="0.825565">
1.3 Expected F-Score
</subsectionHeader>
<bodyText confidence="0.997556642857143">
In Section 3 we will develop a method for evaluating
the expectation of the F-score, which can also be
used as a smooth approximation of the raw F-score
during classifier training: in that task (which we will
not discuss further in this paper), z are the supervised
labels, y is the classifier output, and the challenge is
that F(z,y) does not depend smoothly on the param-
eters of the classifier. Gradient-based optimization
techniques are not applicable unless some of the quan-
tities defined above are replaced by approximations
that depend smoothly on the classifier’s parameters.
For example, the constrained optimization method
of (Mozer et al., 2001) relies on approximations of
sensitivity (which they call CA) and specificity2 (their
CR); related techniques (Gao et al., 2006; Jansche,
2005) rely on approximations of true positives, false
positives, and false negatives, and, indirectly, recall
and precision. Unlike these methods we compute the
expected F-score exactly, without relying on ad hoc
approximations of the true positives, etc.
Being able to efficiently compute the expected
F-score is a prerequisite for maximizing it during de-
coding. More precisely, we compute the expectation
of the function y 7→ F(z,y), (2)
which is a unary function obtained by holding the
first argument of the binary function F fixed. It will
henceforth be abbreviated as F(z,·), and we will de-
note its expected value by
</bodyText>
<equation confidence="0.874480333333333">
E[F(z,·)] = Y F(z,y) Pr(y). (3)
y∈{0,1}|z|
2Defined as [(~1−z)· (~1− y)]/[(~1− y) ·(~1 − y)].
</equation>
<bodyText confidence="0.998157090909091">
This expectation is taken with respect to a probability
model over binary label sequences, written as Pr(y)
for simplicity. This probability model may be condi-
tional, that is, in general it will depend on covariates
x and parameters θ. We have suppressed both in our
notation, since x is fixed during training and decod-
ing, and we assume that the model is fully identified
during decoding. This is for clarity only and does not
limit the class of models, though we will introduce
additional, limiting assumptions shortly. We are now
ready to tackle the inference task formally.
</bodyText>
<sectionHeader confidence="0.940605" genericHeader="method">
2 Maximum Expected F-Score Inference
</sectionHeader>
<subsectionHeader confidence="0.994009">
2.1 Problem Statement
</subsectionHeader>
<bodyText confidence="0.9997825">
Optimal predictive inference under F-score utility
requires us to find an hypothesis zˆ of length n which
maximizes the expected F-score relative to a given
probabilistic sequence labeling model:
</bodyText>
<equation confidence="0.99587775">
zˆ = argmax
z∈{0,1}n E[F(z,·)] = argmaxyF(z,y) Pr(y).
z∈{0,1}n y
(4)
</equation>
<bodyText confidence="0.998751">
We require the probability model to factor into inde-
pendent Bernoulli components (Markov order zero):
</bodyText>
<equation confidence="0.9791115">
pyi
i (1 − pi)1−yi. (5)
</equation>
<bodyText confidence="0.99997595">
In practical applications we might choose the overall
probability distribution to be the product of indepen-
dent logistic regression models, for example. Ordi-
nary classification arises as a special case when the
yi are i.i.d., that is, a single probabilistic classifier is
used to find Pr(yi = 1  |xi). For our present purposes
it is sufficient to assume that the inference algorithm
takes as its input the vector (p1,..., pn), where pi is
the probability that yi = 1.
The discrete maximization problem (4) cannot be
solved naively, since the number of hypotheses that
would need to be evaluated in a brute-force search for
an optimal hypothesis zˆ is exponential in the sequence
length n. We show below that in fact only a few
hypotheses (n+1 instead of 2n) need to be examined
in order to find an optimal one.
The inference algorithm is the intuitive one, analo-
gous to the following simple observation: Start with
the hypothesis z = 00...0 and evaluate its raw F-
score F(z,y) relative to a fixed but unknown binary
</bodyText>
<equation confidence="0.999216">
Pr(y = (y1,...,yn)) =
n
H
i=1
</equation>
<page confidence="0.971003">
737
</page>
<bodyText confidence="0.999946769230769">
string y. Then z will have perfect precision (no posi-
tive labels means no chance to make mistakes), and
zero recall (unless y = z). Switch on any bit of z that
is currently off. Then precision will decrease or re-
main equal, while recall will increase or remain equal.
Repeat until z = 11...1 is reached, in which case re-
call will be perfect and precision at its minimum. The
inference algorithm for expected F-score follows the
same strategy, and in particular it switches on the
bits of z in order of non-increasing probability: start
with 00...0, then switch on the bit i1 = argmaxi pi,
etc. until 11...1 is reached. We now show that this
intuitive strategy is indeed admissible.
</bodyText>
<subsectionHeader confidence="0.991293">
2.2 Outer and Inner Maximization
</subsectionHeader>
<bodyText confidence="0.999072">
In general, maximization can be carried out piece-
wise, since
</bodyText>
<equation confidence="0.9890455">
argmax f(x) = argmax f(x),
x∈X x∈{argmaxy∈Y f(y)|Y∈7r(X)}
</equation>
<bodyText confidence="0.958867846153846">
where 7r(X) is any family (Y1,Y2,...) of nonempty
subsets of X whose union UiYi is equal to X. (Recur-
sive application would lead to a divide-and-conquer
algorithm.) Duplication of effort is avoided if 7c(X)
is a partition of X.
Here we partition the set {0,1}n into equivalence
classes based on the number of ones in a string
(viewed as a real vector). Define Sm to be the set
Sm = {s ∈ {0,1}n  |s·s = m}
consisting of all binary strings of fixed length n that
contain exactly m ones. Then the maximization prob-
lem (4) can be transformed into an inner maximiza-
tion
</bodyText>
<equation confidence="0.9209196">
ˆs(m) = argmax E[F(s,·)], (6)
s∈Sm
followed by an outer maximization
zˆ = argmax E[F(z,·)]. (7)
z∈{ˆs(0),...,ˆs(n)}
</equation>
<subsectionHeader confidence="0.999228">
2.3 Closed-Form Inner Maximization
</subsectionHeader>
<bodyText confidence="0.9999624">
The key insight is that the inner maximization prob-
lem (6) can be solved analytically. Given a vector
p = (p1,..., pn) of probabilities, define z(m) to be the
binary label sequence with exactly m ones and n − m
zeroes where for all indices i,k we have
</bodyText>
<equation confidence="0.5095735">
[� z�m)= 1∧zkm)= 0 → pi ≥ pk.
Algorithm 1 Maximizing the Expected F-Score.
</equation>
<listItem confidence="0.735069066666667">
1: Input: probabilities p = (p1,..., pn)
2: I ← indices of p sorted by non-increasing probability
3: z ← 0...0
4: a ← 0
5: v ← expectF(z, p)
6: for j ← 1 to n do
7: i ← I[j]
8: z[i] ← 1 // switch on the ith bit
9: u ← expectF(z, p)
10: if u &gt; v then
11: a ← j
12: v ← u
13: for j ← a+1 tondo
14: z[I[j]] ← 0
15: return (z,v)
</listItem>
<bodyText confidence="0.965569">
In other words, the most probable m bits (according
to p) in z(m) are set and the least probable n − m bits
are off. We rely on the following result, whose proof
is deferred to Appendix A:
</bodyText>
<equation confidence="0.794984666666667">
Theorem 1. (∀s ∈ Sm) E[F(z(m),·)] ≥ E[F(s,·)].
Because z(m) is maximal in Sm, we may equate
z(m) = argmaxs∈Sm E[F(s,·)] = ˆs(m) (modulo ties,
</equation>
<bodyText confidence="0.724112">
which can always arise with argmax).
</bodyText>
<subsectionHeader confidence="0.998716">
2.4 Pedestrian Outer Maximization
</subsectionHeader>
<bodyText confidence="0.999955875">
With the inner maximization (6) thus solved, the outer
maximization (7) can be carried out naively, since
only n + 1 hypotheses need to be evaluated. This
is precisely what Algorithm 1 does, which keeps
track of the maximum value in v. On termination
z = argmaxsE[F(s,·)]. Correctness follows directly
from our results in this section.
Algorithm 1 runs in time O(nlogn+n f(n)). A
total of O(nlogn) time is required for accessing the
vector p in sorted order (line 2). This dominates the
O(n) time required to explicitly generate the optimal
hypothesis (lines 13–14). The algorithm invokes a
subroutine expectF(z, p) a total of n + 1 times. This
subroutine, which is the topic of the next section,
evaluates, in time f (n), the expected F-score (with
respect to p) of a given hypothesis z of length n.
</bodyText>
<sectionHeader confidence="0.964608" genericHeader="method">
3 Computing the Expected F-Score
</sectionHeader>
<subsectionHeader confidence="0.998994">
3.1 Problem Statement
</subsectionHeader>
<bodyText confidence="0.9996765">
We now turn to the problem of computing the ex-
pected value (3) of the F-score for a given hypothesis
z relative to a fully identified probability model. The
method presented here does not strictly require the
</bodyText>
<page confidence="0.988283">
738
</page>
<bodyText confidence="0.999536823529412">
zeroth-order Markov assumption (5) instated earlier
(a higher-order Markov assumption will suffice), but
it shall remain in effect for simplicity.
As with the maximization problem (4), the sum
in (3) is over exponentially many terms and cannot be
computed naively. But observe that the F-score (1)
is a (rational) function of integer counts which are
bounded, so it can take on only a finite, and indeed
small, number of distinct values. We shall see shortly
that the function (2) whose expectation we wish to
compute has a domain whose cardinality is exponen-
tial in n, but the cardinality of its range is polynomial
in n. The latter is sufficient to ensure that its ex-
pectation can be computed in polynomial time. The
method we are about to develop is in fact very general
and applies to many other loss and utility functions
besides the F-score.
</bodyText>
<subsectionHeader confidence="0.99749">
3.2 Expected F-Score as an Integral
</subsectionHeader>
<bodyText confidence="0.999989714285714">
A few notions from real analysis are helpful because
they highlight the importance of thinking about func-
tions in terms of their range, level sets, and the equiv-
alence classes they induce on their domain (the kernel
of the function). A function g : Ω —* R is said to be
simple if it can be expressed as a linear combination
of indicator functions (characteristic functions):
</bodyText>
<equation confidence="0.9864245">
g(x) = ∑ ak xBk(x),
kEK
</equation>
<bodyText confidence="0.969178">
where K is a finite index set, ak E R, and Bk C Ω.
(xS : S —* {0,1} is the characteristic function of set S.)
Let Ω be a countable set and Y be a probability
measure on Ω. Then the expectation of g is given by
the Lebesgue integral of g. In the case of a simple
function g as defined above, the integral, and hence
the expectation, is defined as
</bodyText>
<equation confidence="0.98739">
�E[g] =Ωg d� = ∑ak Y(Bk). (8)
kEK
</equation>
<bodyText confidence="0.9991665">
This gives us a general recipe for evaluating E[g]
when Ω is much larger than the range of g. Instead of
computing the sum ∑yEΩg(y) Y({y}) we can com-
pute the sum in (8) above. This directly yields an
efficient algorithm whenever K is sufficiently small
and Y(Bk) can be evaluated efficiently.
The expected F-score is thus the Lebesgue integral
of the function (2). Looking at the definition of the
F-score in (1) we see that the only expressions which
depend on y are A = z · y and T = y · y (P = z · z is
fixed because z is). But 0 &lt; z · y &lt; y · y &lt; n = 1zI.
Therefore F(z,·) takes on at most (n + 1)(n + 2)/2,
i.e. quadratically many, distinct values. It is a simple
function with
</bodyText>
<equation confidence="0.999778">
K = {(A,T) E N0 xN0 I A &lt; T &lt; JzJ, A &lt; z·z}
a(A T) = zPz+ ) T where 0/0 def 1
B(A,T) = {y I z · y = A, y·y = T}.
</equation>
<subsectionHeader confidence="0.985153">
3.3 Computing Membership in Bk
</subsectionHeader>
<bodyText confidence="0.997974777777778">
Observe that the family of sets (B(A,T)) (A,T)EK is a
partition (namely the kernel of F(z,·)) of the set Ω =
{0,1}n of all label sequences of length n. In turn it
gives rise to a function h : Ω —* K where h(y) = k
iff y E Bk. The function h can be computed by a
deterministic finite automaton, viewed as a sequence
classifier: rather than assigning binary accept/reject
labels, it assigns arbitrary labels from a finite set, in
this case the index set K. For simplicity we show
the initial portion of a slightly more general two-tape
automaton h&apos; in Figure 1. It reads the two sequences
z and y on its two input tapes and counts the number
of matching positive labels (represented as Y) as well
as the number of positive labels on the second tape.
Its behavior is therefore h&apos;(z,y) = (z · y, y · y). The
function h is obtained as a special case when z (the
first tape) is fixed.
Note that this only applies to the special case when
</bodyText>
<figure confidence="0.998066857142857">
Y:n, n:n 1,1
Y:Y
0,0
n:Y
Y:n, n:n
Y:n, n:n Y:Y
0,1
Y:Y
n:Y
n:Y
Y:n, n:n
Y:n, n:n Y:Y
Y:n, n:n Y:Y
2,2
0,2
1,2
Y:Y
n:Y
n:Y
n:Y
Y:n, n:n
Y:n, n:n
Y:n, n:n
Y:n, n:n
2,3
3,3
0,3
1,3
</figure>
<figureCaption confidence="0.999003">
Figure 1: Finite State Classifier h&apos;.
</figureCaption>
<page confidence="0.966349">
739
</page>
<bodyText confidence="0.503562">
Algorithm 2 Simple Function Instance for F-Score.
</bodyText>
<equation confidence="0.972011142857143">
def start():
return (0,0)
def transition(k,z,i,yi):
(A,T) &lt;-- k
if yi = 1 then
T &lt;-- T +1
if z[i] = 1 then
A &lt;-- A+1
return (A,T)
def a(k,z):
(A,T) &lt;-- k
F &lt;-- (P + 1) A // where 0/0 def = 1
z·z+(i T
return F
</equation>
<bodyText confidence="0.8534">
Algorithm 3 Value of a Simple Function.
</bodyText>
<listItem confidence="0.9836645">
1: Input: instance g of the simple function interface, strings z
and y of length n
2: k &lt;-- g.start()
3: for i &lt;-- 1 to n do
4: k &lt;-- g.transition(k,z,i,y[i])
5: return g.a(k,z)
</listItem>
<bodyText confidence="0.998446166666667">
the family B = (Bk)kEK is a partition of 91. It is al-
ways possible to express any simple function in this
way, but in general there may be an exponential in-
crease in the size of K when the family B is required
to be a partition. However for the special cases we
consider here this problem does not arise.
</bodyText>
<subsectionHeader confidence="0.955127">
3.4 The Simple Function Trick
</subsectionHeader>
<bodyText confidence="0.999981666666667">
In general, what we will call the simple function trick
amounts to representing the simple function g whose
expectation we want to compute by:
</bodyText>
<listItem confidence="0.998547333333333">
1. a finite index set K (perhaps implicit),
2. a deterministic finite state classifier h : 9 1—* K,
3. and a vector of coefficients (ak)kEK.
</listItem>
<bodyText confidence="0.982218933333333">
In practice, this means instantiating an interface with
three methods: the start and transition function of the
transducer which computes h&apos; (and from which h can
be derived), and an accessor method for the coeffi-
cients a. Algorithm 2 shows the F-score instance.
Any simple function g expressed as an instance of
this interface can then be evaluated very simply as
g(x) = ah(x). This is shown in Algorithm 3.
Evaluating E[g] is also straightforward: Compose
the DFA h with the probability model p and use an al-
gebraic path algorithm to compute the total probabil-
ity mass Y(Bk) for each final state k of the resulting
automaton. If p factors into independent components
as required by (5), the composition is greatly sim-
Algorithm 4 Expectation of a Simple Function.
</bodyText>
<listItem confidence="0.765684375">
1: Input: instance g of the simple function interface, string z
and probability vector p of length n
2: M &lt;-- Map()
3: M[g.start()] &lt;-- 1
4: for i &lt;-- 1 to n do
5: N &lt;-- Map()
6: for (k,P) E M do
7: // transition on yi = 0
</listItem>
<figure confidence="0.979732928571429">
8: k0 &lt;-- g.transition(k,z,i,0)
9: if k0 E/ N then
10: N[k0] &lt;-- 0
11: N[k0] &lt;-- N[k0]+Px(1— p[i])
12: // transition on yi = 1
13: k1 &lt;-- g.transition(k,z,i,1)
14: if k1 E/ N then
15: N[k1] &lt;-- 0
16: N[k1] &lt;-- N[k1] +P x p[i]
17: M &lt;-- N
18: E &lt; --0
19: for (k,P) E M do
20: E &lt;-- E + g.a(k,z) xP
21: return E
</figure>
<bodyText confidence="0.999295206896552">
plified. If p incorporates label history (higher-order
Markov assumption), nothing changes in principle,
though the following algorithm assumes for simplic-
ity that the stronger assumption is in effect.
Algorithm 4 expands the following composed au-
tomaton, represented implicitly: the finite-state trans-
ducer h&apos; specified as part of the simple function object
g is composed on the left with the string z (yielding
h) and on the right with the probability model p. The
outer loop variable i is an index into z and hence a
state in the automaton that accepts z; the variable
k keeps track of the states of the automaton imple-
mented by g; and the probability model has a single
state by assumption, which does not need to be rep-
resented explicitly. Exploring the states in order of
increasing i puts them in topological order, which
means that the algebraic path problem can be solved
in time linear in the size of the composed automaton.
The maps M and N keep track of the algebraic dis-
tance from the start state to each intermediate state.
On termination of the first outer loop (lines 4–17),
the map M contains the final states together with
their distances. The algebraic distance of a final state
k is now equal to Y(Bk), so the expected value E
can be computed in the second loop (lines 18–20) as
suggested by (8).
When the utility function interface g is instantiated
as in Algorithm 2 to represent the F-score, the run-
time of Algorithm 4 is cubic in n, with very small
</bodyText>
<page confidence="0.988978">
740
</page>
<bodyText confidence="0.999746428571429">
constants.3 The first main loop iterates over n. The
inner loop iterates over the states expanded at itera-
tion i, of which there are O(i2) many when dealing
with the F-score. The second main loop iterates over
the final states, whose number is quadratic in n in
this case. The overall cubic runtime of the first loop
dominates the computation.
</bodyText>
<subsectionHeader confidence="0.900487">
3.5 Other Utility Functions
</subsectionHeader>
<bodyText confidence="0.99993208">
With other functions g the runtime of Algorithm 4
will depend on the asymptotic size of the index set K.
If there are asymptotically as many intermediate
states at any point as there are final states, then the
general asymptotic runtime is O(n JKJ).
Many loss/utility functions are subsumed by the
present framework. Zero–one loss is trivial: the au-
tomaton has two states (success, failure); it starts and
remains in the success state as long as the symbols
read on both tapes match; on the first mismatch it
transitions to, and remains in, the failure state.
Hamming (1950) distance is similar to zero–one
loss, but counts the number of mismatches (bounded
by n), whereas zero–one loss only counts up to a
threshold of one.
A more interesting case is given by the Pk-score
(Beeferman et al., 1999) and its generalizations,
which moves a sliding window of size k over a pair
of label sequences (z,y) and counts the number of
windows which contain a segment boundary on one
of the sequences but not the other. To compute its
expectation in our framework, all we have to do is
express the sliding window mechanism as an automa-
ton, which can be done very naturally (see the proof-
of-concept implementation for further details).
</bodyText>
<sectionHeader confidence="0.997437" genericHeader="method">
4 Faster Inexact Computations
</sectionHeader>
<bodyText confidence="0.992596666666667">
Because the exact computation of the expected F-
score by Algorithm 4 requires cubic time, the overall
runtime of Algorithm 1 (the decoder) is quartic.4
</bodyText>
<footnote confidence="0.9002786">
3A tight upper bound on the total number of states of the com-
posed automaton in the worst case is 12 n3 + 58 n2 + 12n+ 1J .
4It is possible to speed up the decoding algorithm in absolute
terms, though not asymptotically, by exploiting the fact that it
explores very similar hypotheses in sequence. Algorithm 4 can
be modified to store and return all of its intermediate map data-
structures. This modified algorithm then requires cubic space
instead of quadratic space. This additional storage cost pays
off when the algorithm is called a second time, with its formal
parameter z bound to a string that differs from the one of the
</footnote>
<bodyText confidence="0.999836255813953">
Faster decoding can be achieved by modifying Al-
gorithm 4 to compute an approximation (in fact, a
lower bound) of the expected F-score.5 This is done
by introducing an additional parameter L which limits
the number of intermediate states that get expanded.
Instead of iterating over all states and their associ-
ated probabilities (inner loop starting at line 6), one
iterates over the top L states only. We require that
L &gt; 1 for this to be meaningful. Before entering the
inner loop the entries of the map M are expanded
and, using the linear time selection algorithm, the
top L entries are selected. Because each state that
gets expanded in the inner loop has out-degree 2, the
new state map N will contain at most 2L states. This
means that we have an additional loop invariant: the
size of M is always less than or equal to 2L. There-
fore the selection algorithm runs in time O(L), and
so does the abridged inner loop, as well as the sec-
ond outer loop. The overall runtime of this modified
algorithm is therefore O(nL).
If L is a constant function, the inexact computation
of the expected F-score runs in linear time and the
overall decoding algorithm in quadratic time. In par-
ticular if L = 1 the approximate expected F-score is
equal to the F-score of the MAP hypothesis, and the
modified inference algorithm reduces to a variant of
Viterbi decoding. If L is a linear function of n, the
overall decoding algorithm runs in cubic time.
We experimentally compared the exact quartic-
time decoding algorithm with the approximate decod-
ing algorithm for L = 2n and for L = 1. We computed
the absolute difference between the expected F-score
of the optimal hypothesis (as found by the exact al-
gorithm) and the expected F-score of the winning
hypothesis found by the approximate decoding algo-
rithm. For different sequence lengths n E 11,...,501
we performed 10 runs of the different decoding al-
gorithms on randomly generated probability vectors
p, where each pi was randomly drawn from a contin-
uous uniform distribution on (0,1), or, in a second
experiment, from a Beta(1/2,1/2) distribution (to
simulate an over-trained classifier).
For L = 1 there is a substantial difference of about
</bodyText>
<footnote confidence="0.9930516">
preceding run in just one position. This means that the map
data-structures only need to be recomputed from that position
forward. However, this does not lead to an asymptotically faster
algorithm in the worst case.
5For error bounds, see the proof-of-concept implementation.
</footnote>
<page confidence="0.996266">
741
</page>
<bodyText confidence="0.99985875">
0.6 between the expected F-scores of the winning
hypothesis computed by the exact algorithm and by
the approximate algorithm. Nevertheless the approx-
imate decoding algorithm found the optimal hypoth-
esis more than 99% of the time. This is presumably
due to the additional regularization inherent in the
discrete maximization of the decoder proper: even
though the computed expected F-scores may be far
from their exact values, this does not necessarily af-
fect the behavior of the decoder very much, since it
only needs to find the maximum among a small num-
ber of such scores. The error introduced by the ap-
proximation would have to be large enough to disturb
the order of the hypotheses examined by the decoder
in such a way that the true maximum is reordered.
This generally does not seem to happen.
For L = 2n the computed approximate expected F-
scores were indistinguishable from their exact values.
Consequently the approximate decoder found the true
maximum every time.
</bodyText>
<sectionHeader confidence="0.978974" genericHeader="method">
5 Conclusion and Related Work
</sectionHeader>
<bodyText confidence="0.999994886363637">
We have presented efficient algorithms for maximum
expected F-score decoding. Our exact algorithm runs
in quartic time, but an approximate cubic-time variant
is indistinguishable in practice. A quadratic-time
approximation makes very few mistakes and remains
practically useful.
We have further described a general framework
for computing the expectations of certain loss/utility
functions. Our method relies on the fact that many
functions are sparse, in the sense of having a finite
range that is much smaller than their codomain. To
evaluate their expectations, we can use the simple
function trick and concentrate on their level sets:
it suffices to evaluate the probability of those sets/
events. The fact that the commonly used utility func-
tions like the F-score have only polynomially many
level sets is sufficient (but not necessary) to ensure
that our method is efficient. Because the coefficients
ak can be arbitrary (in fact, they can be generalized to
be elements of a vector space over the reals), we can
deal with functions that go beyond simple counts.
Like the methods developed by Allauzen et al.
(2003) and Cortes et al. (2003) our technique incor-
porates finite automata, but uses a direct threshold-
counting technique, rather than a nondeterministic
counting technique which relies on path multiplici-
ties. This makes it easy to formulate the simultaneous
counting of two distinct quantities, such as our A and
T, and to reason about the resulting automata.
The method described here is similar in spirit to
those of Gao et al. (2006) and Jansche (2005), who
discuss maximum expected F-score training of deci-
sion trees and logistic regression models. However,
the present work is considerably more general in two
ways: (1) the expected utility computations presented
here are not tied in any way to particular classifiers,
but can be used with large classes of probabilistic
models; and (2) our framework extends beyond the
computation of F-scores, which fall out as a special
case, to other loss and utility functions, including the
Pk score. More importantly, expected F-score com-
putation as presented here can be exact, if desired,
whereas the cited works always use an approximation
to the quantities we have called A and T.
</bodyText>
<sectionHeader confidence="0.997054" genericHeader="method">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9492376">
Most of this research was conducted while I was affilated with
the Center for Computational Learning Systems, Columbia Uni-
versity. I would like to thank my colleagues at Google, in partic-
ular Ryan McDonald, as well as two anonymous reviewers for
valuable feedback.
</bodyText>
<sectionHeader confidence="0.998917" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.993594724137931">
Cyril Allauzen, Mehryar Mohri, and Brian Roark. 2003. Gen-
eralized algorithms for constructing language models. In
Proceedings of the 41st Annual Meeting of the Association
for Computational Linguistics.
Doug Beeferman, Adam Berger, and John Lafferty. 1999. Sta-
tistical models for text segmentation. Machine Learning,
34(1–3):177–210.
Francisco Casacuberta and Colin de la Higuera. 2000. Computa-
tional complexity of problems on probabilistic grammars and
transducers. In 5th International Colloquium on Grammatical
Inference.
Corinna Cortes, Patrick Haffner, and Mehryar Mohri. 2003. Ra-
tional kernels. In Advances in Neural Information Processing
Systems, volume 15.
Sheng Gao, Wen Wu, Chin-Hui Lee, and Tai-Seng Chua. 2006.
A maximal figure-of-merit (MFoM)-learning approach to ro-
bust classifier design for text categorization. ACM Transac-
tions on Information Systems, 24(2):190–218. Also in ICML
2004.
Samuel S. Gross, Olga Russakovsky, Chuong B. Do, and Ser-
afim Batzoglou. 2007. Training conditional random fields
for maximum labelwise accuracy. In Advances in Neural
Information Processing Systems, volume 19.
R. W. Hamming. 1950. Error detecting and error correcting
codes. The Bell System Technical Journal, 26(2):147–160.
Martin Jansche. 2005. Maximum expected F-measure training
of logistic regression models. In Proceedings of Human Lan-
guage Technology Conference and Conference on Empirical
Methods in Natural Language Processing.
</reference>
<page confidence="0.985775">
742
</page>
<reference confidence="0.998371315789474">
Kevin Knight. 1999. Decoding complexity in word-replacement
translation models. Computational Linguistics, 25(4):607–
615.
Michael C. Mozer, Robert Dodier, Michael D. Colagrosso,
C´esar Guerra-Salcedo, and Richard Wolniewicz. 2001. Prod-
ding the ROC curve: Constrained optimization of classifier
performance. In Advances in Neural Information Processing
Systems, volume 14.
David R. Musicant, Vipin Kumar, and Aysel Ozgur. 2003.
Optimizing F-measure with support vector machines. In
Proceedings of the Sixteenth International Florida Artificial
Intelligence Research Society Conference.
Jun Suzuki, Erik McDermott, and Hideki Isozaki. 2006. Train-
ing conditional random fields with multivariate evaluation
measures. In Proceedings of the 21st International Confer-
ence on Computational Linguistics and 44th Annual Meeting
of the Association for Computational Linguistics.
C. J. van Rijsbergen. 1974. Foundation of evaluation. Journal
of Documentation, 30(4):365–373.
</reference>
<sectionHeader confidence="0.971492" genericHeader="method">
Appendix A Proof of Theorem 1
</sectionHeader>
<bodyText confidence="0.636479">
The proof of Theorem 1 employs the following lemma:
</bodyText>
<construct confidence="0.88125625">
Theorem 2. For fixed n and p, let s,t E Sm for some m with
1 &lt; m &lt; n. Further assume that s and t differ only in two bits,
i and k, in such a way that si = 1, sk = 0; ti = 0, tk = 1; and
pi &gt; pk. Then E[F(s,·)] &gt; E[F(t,·)].
</construct>
<bodyText confidence="0.993473333333333">
Proof. Express the expected F-score E[F(s,·)] as a sum and
split the summation into two parts:
where A = s · z is the number of true positives between s and z
(s and y have an additional true positive at i by construction);
T = y·y = z·z is the number of positive labels in y and z (identical
by assumption); and
</bodyText>
<equation confidence="0.9678945">
Pr(z)
(1− pi) pk
</equation>
<bodyText confidence="0.902401">
is the probability of y and z evaluated on all positions except for
i and k. This equality holds because of the zeroth-order Markov
assumption (5) imposed on Pr(y). C0 and C1 are constants that
allow us to focus on the essential aspects.
The situation for t is similar, except for the true positives:
</bodyText>
<equation confidence="0.977271777777778">
F(t,y) Pr(y) +F(t,z) Pr(z)
(β + 1)A (β + 1)(A + 1)
m+βT Pr(y)+ =m+βT Pr(z)
= [A pi(1− pk) +(A+1)(1− pi)pk] (β + 1)
m + C
βT
= [pk + (pi + pk − 2pipk)A − pipk] (β + 1) C
m+βT
= [pk +C0] C1
</equation>
<bodyText confidence="0.998239">
where all constants have the same values as above. But pi &gt; pk
by assumption, pk +C0 &gt; 0, and C1 &gt; 0, so we have
</bodyText>
<equation confidence="0.9847808">
F(s,y) Pr(y) +F(s,z) Pr(z) = [pi +C0] C1
&gt; F(t,y) Pr(y)+F(t,z) Pr(z) = [pk +C0] C1,
Pr(y) =
pi (1 − pk)
C=
</equation>
<bodyText confidence="0.997076">
If yi = yk then F(s,y) = F(t,y), for three reasons: the number
of ones in s and t is the same (namely m) by assumption; y is
constant; and the number of true positives is the same, that is
s · y = t · y. The latter holds because s and y agree everywhere
except on i and k; if yi = yk = 0, then there are no true positives
at i and k; and if yi = yk = 1 then si is a true positive but sk is
not, and conversely tk is but ti is not. Therefore
</bodyText>
<equation confidence="0.924979333333333">
∑ F(s,y) Pr(y) = ∑ F(t,y) Pr(y). (9)
y y
yi=yk yi=yk
</equation>
<bodyText confidence="0.9735086">
Focus on those summands where yi =� yk. Specifically group
them into pairs (y,z) where y and z are identical except that
yi = 1 and yk = 0, but zi = 0 and zk = 1. In other words, the two
summations on the right-hand side of the following equality are
carried out in parallel:
</bodyText>
<equation confidence="0.9452314">
= [(A+1)pi(1− pk)+A(1− pi)pk] (β + 1)
m + C
βT
= [pi + (pi + pk − 2pipk)A − pipk] (β + 1)
m + βT C
</equation>
<bodyText confidence="0.97741832">
= [pi +C0] C1,
The theorem follows from equality (9) and inequality (10).
Proof of Theorem 1: (Vs E Sm) E[F(z(m),·)] &gt; E[F(s,·)].
Observe that z(m) E Sm by definition (see Section 2.3). For
m = 0 and m = n the theorem holds trivially because Sm is a
singleton set. In the nontrivial cases, Theorem 2 is applied
repeatedly. The string z(m) can be transformed into any other
string s E Sm by repeatedly clearing a more likely set bit and
setting a less likely unset bit.
In particular this can be done as follows: First, find the indices
where z(m) and s disagree. By construction there must be an even
number of such indices; indeed there are equinumerous sets
nilzi(m)= 1∧si = 0o1 n jj zj
(m)= 0∧sj = 1o.
This holds because the total number of ones is fixed and identical
in z(m) and s, and so is the total number of zeroes. Next, sort
those indices by non-increasing probability and represent them
as i1,...,ik and j1,..., jk. Let s0 = z(m). Then let s1 be identical
to s0 except that si1 = 0 and sj1 = 1. Form s2,...,sk along the
same lines and observe that sk = s by construction. By definition
of z(m) it must be the case that pir &gt; pjr for all r E {1,...,k}.
Therefore Theorem 2 applies at every step along the way from
z(m) = s0 to sk = s, and so the expected utility is non-increasing
along that path.
Then, focusing on s first:
</bodyText>
<figure confidence="0.967064379310345">
F(s,y) Pr(y) + F(s,z) Pr(z)
(β + 1)(A + 1) (β + 1)A
= Pr(y) + Pr(z)
m+βT m+βT
∑
y
yiOyk
F(s,y) Pr(y) + ∑
z
zi=0
zk=1
F(s,y) Pr(y) = ∑
y
yi=1
yk=0
F(s,z) Pr(z).
∑ F(s,y) Pr(y) &gt; ∑
y y
yiOyk
F(t,y) Pr(y). (10)
yiOyk
∑ F(s,y) Pr(y) = ∑
y y
yi=yk
F(s,y) Pr(y).
and therefore
F(s,y) Pr(y) +∑
y
yiOyk
</figure>
<page confidence="0.977391">
743
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.917055">
<title confidence="0.986205">A Maximum Expected Utility Framework for Binary Sequence Labeling</title>
<email confidence="0.942097">jansche@acm.org</email>
<abstract confidence="0.998212833333333">We consider the problem of predictive inference for probabilistic binary sequence labelmodels under as utility. For a simple class of models, we show that the of hypotheses whose expected score needs to be evaluated is linear in the sequence length and present a framework for efficiently evaluating the expectation of many common loss/utility functions, including the This framework includes both exact and faster inexact calculation methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Cyril Allauzen</author>
<author>Mehryar Mohri</author>
<author>Brian Roark</author>
</authors>
<title>Generalized algorithms for constructing language models.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="26111" citStr="Allauzen et al. (2003)" startWordPosition="4587" endWordPosition="4590"> much smaller than their codomain. To evaluate their expectations, we can use the simple function trick and concentrate on their level sets: it suffices to evaluate the probability of those sets/ events. The fact that the commonly used utility functions like the F-score have only polynomially many level sets is sufficient (but not necessary) to ensure that our method is efficient. Because the coefficients ak can be arbitrary (in fact, they can be generalized to be elements of a vector space over the reals), we can deal with functions that go beyond simple counts. Like the methods developed by Allauzen et al. (2003) and Cortes et al. (2003) our technique incorporates finite automata, but uses a direct thresholdcounting technique, rather than a nondeterministic counting technique which relies on path multiplicities. This makes it easy to formulate the simultaneous counting of two distinct quantities, such as our A and T, and to reason about the resulting automata. The method described here is similar in spirit to those of Gao et al. (2006) and Jansche (2005), who discuss maximum expected F-score training of decision trees and logistic regression models. However, the present work is considerably more gener</context>
</contexts>
<marker>Allauzen, Mohri, Roark, 2003</marker>
<rawString>Cyril Allauzen, Mehryar Mohri, and Brian Roark. 2003. Generalized algorithms for constructing language models. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doug Beeferman</author>
<author>Adam Berger</author>
<author>John Lafferty</author>
</authors>
<title>Statistical models for text segmentation.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--1</pages>
<contexts>
<context position="20292" citStr="Beeferman et al., 1999" startWordPosition="3607" endWordPosition="3610">s there are final states, then the general asymptotic runtime is O(n JKJ). Many loss/utility functions are subsumed by the present framework. Zero–one loss is trivial: the automaton has two states (success, failure); it starts and remains in the success state as long as the symbols read on both tapes match; on the first mismatch it transitions to, and remains in, the failure state. Hamming (1950) distance is similar to zero–one loss, but counts the number of mismatches (bounded by n), whereas zero–one loss only counts up to a threshold of one. A more interesting case is given by the Pk-score (Beeferman et al., 1999) and its generalizations, which moves a sliding window of size k over a pair of label sequences (z,y) and counts the number of windows which contain a segment boundary on one of the sequences but not the other. To compute its expectation in our framework, all we have to do is express the sliding window mechanism as an automaton, which can be done very naturally (see the proofof-concept implementation for further details). 4 Faster Inexact Computations Because the exact computation of the expected Fscore by Algorithm 4 requires cubic time, the overall runtime of Algorithm 1 (the decoder) is qua</context>
</contexts>
<marker>Beeferman, Berger, Lafferty, 1999</marker>
<rawString>Doug Beeferman, Adam Berger, and John Lafferty. 1999. Statistical models for text segmentation. Machine Learning, 34(1–3):177–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francisco Casacuberta</author>
<author>Colin de la Higuera</author>
</authors>
<title>Computational complexity of problems on probabilistic grammars and transducers.</title>
<date>2000</date>
<booktitle>In 5th International Colloquium on Grammatical Inference.</booktitle>
<marker>Casacuberta, Higuera, 2000</marker>
<rawString>Francisco Casacuberta and Colin de la Higuera. 2000. Computational complexity of problems on probabilistic grammars and transducers. In 5th International Colloquium on Grammatical Inference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Corinna Cortes</author>
<author>Patrick Haffner</author>
<author>Mehryar Mohri</author>
</authors>
<title>Rational kernels.</title>
<date>2003</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<volume>15</volume>
<contexts>
<context position="26136" citStr="Cortes et al. (2003)" startWordPosition="4592" endWordPosition="4595">domain. To evaluate their expectations, we can use the simple function trick and concentrate on their level sets: it suffices to evaluate the probability of those sets/ events. The fact that the commonly used utility functions like the F-score have only polynomially many level sets is sufficient (but not necessary) to ensure that our method is efficient. Because the coefficients ak can be arbitrary (in fact, they can be generalized to be elements of a vector space over the reals), we can deal with functions that go beyond simple counts. Like the methods developed by Allauzen et al. (2003) and Cortes et al. (2003) our technique incorporates finite automata, but uses a direct thresholdcounting technique, rather than a nondeterministic counting technique which relies on path multiplicities. This makes it easy to formulate the simultaneous counting of two distinct quantities, such as our A and T, and to reason about the resulting automata. The method described here is similar in spirit to those of Gao et al. (2006) and Jansche (2005), who discuss maximum expected F-score training of decision trees and logistic regression models. However, the present work is considerably more general in two ways: (1) the e</context>
</contexts>
<marker>Cortes, Haffner, Mohri, 2003</marker>
<rawString>Corinna Cortes, Patrick Haffner, and Mehryar Mohri. 2003. Rational kernels. In Advances in Neural Information Processing Systems, volume 15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sheng Gao</author>
<author>Wen Wu</author>
<author>Chin-Hui Lee</author>
<author>Tai-Seng Chua</author>
</authors>
<title>A maximal figure-of-merit (MFoM)-learning approach to robust classifier design for text categorization.</title>
<date>2006</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>24</volume>
<issue>2</issue>
<note>Also in ICML</note>
<contexts>
<context position="1198" citStr="Gao et al., 2006" startWordPosition="181" endWordPosition="184">Introduction 1.1 Motivation and Scope The weighted F-score (van Rijsbergen, 1974) plays an important role in the evaluation of binary classifiers, as it neatly summarizes a classifier’s ability to identify the positive class. A variety of methods exists for training classifiers that optimize the F-score, or some similar trade-off between false positives and false negatives, precision and recall, sensitivity and specificity, type I error and type II error rate, etc. Among the most general methods are those of Mozer et al. (2001), whose constrained optimization technique is similar to those in (Gao et al., 2006; Jansche, 2005). More specialized methods also exist, for example for support vector machines (Musicant et al., 2003) and for conditional random fields (Gross et al., 2007; Suzuki et al., 2006). All of these methods are about classifier training. In this paper we focus primarily on the related, but orthogonal, issue of predictive inference with a fully trained probabilistic classifier. Using the weighted F-score as our utility function, predictive inference amounts to choosing an optimal hypothesis which maximizes the expected utility. We refer to this as *Current affiliation: Google Inc. For</context>
<context position="5133" citStr="Gao et al., 2006" startWordPosition="826" endWordPosition="829">fier training: in that task (which we will not discuss further in this paper), z are the supervised labels, y is the classifier output, and the challenge is that F(z,y) does not depend smoothly on the parameters of the classifier. Gradient-based optimization techniques are not applicable unless some of the quantities defined above are replaced by approximations that depend smoothly on the classifier’s parameters. For example, the constrained optimization method of (Mozer et al., 2001) relies on approximations of sensitivity (which they call CA) and specificity2 (their CR); related techniques (Gao et al., 2006; Jansche, 2005) rely on approximations of true positives, false positives, and false negatives, and, indirectly, recall and precision. Unlike these methods we compute the expected F-score exactly, without relying on ad hoc approximations of the true positives, etc. Being able to efficiently compute the expected F-score is a prerequisite for maximizing it during decoding. More precisely, we compute the expectation of the function y 7→ F(z,y), (2) which is a unary function obtained by holding the first argument of the binary function F fixed. It will henceforth be abbreviated as F(z,·), and we </context>
<context position="26542" citStr="Gao et al. (2006)" startWordPosition="4658" endWordPosition="4661">t, they can be generalized to be elements of a vector space over the reals), we can deal with functions that go beyond simple counts. Like the methods developed by Allauzen et al. (2003) and Cortes et al. (2003) our technique incorporates finite automata, but uses a direct thresholdcounting technique, rather than a nondeterministic counting technique which relies on path multiplicities. This makes it easy to formulate the simultaneous counting of two distinct quantities, such as our A and T, and to reason about the resulting automata. The method described here is similar in spirit to those of Gao et al. (2006) and Jansche (2005), who discuss maximum expected F-score training of decision trees and logistic regression models. However, the present work is considerably more general in two ways: (1) the expected utility computations presented here are not tied in any way to particular classifiers, but can be used with large classes of probabilistic models; and (2) our framework extends beyond the computation of F-scores, which fall out as a special case, to other loss and utility functions, including the Pk score. More importantly, expected F-score computation as presented here can be exact, if desired,</context>
</contexts>
<marker>Gao, Wu, Lee, Chua, 2006</marker>
<rawString>Sheng Gao, Wen Wu, Chin-Hui Lee, and Tai-Seng Chua. 2006. A maximal figure-of-merit (MFoM)-learning approach to robust classifier design for text categorization. ACM Transactions on Information Systems, 24(2):190–218. Also in ICML 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel S Gross</author>
<author>Olga Russakovsky</author>
<author>Chuong B Do</author>
<author>Serafim Batzoglou</author>
</authors>
<title>Training conditional random fields for maximum labelwise accuracy.</title>
<date>2007</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<volume>19</volume>
<contexts>
<context position="1370" citStr="Gross et al., 2007" startWordPosition="208" endWordPosition="211"> a classifier’s ability to identify the positive class. A variety of methods exists for training classifiers that optimize the F-score, or some similar trade-off between false positives and false negatives, precision and recall, sensitivity and specificity, type I error and type II error rate, etc. Among the most general methods are those of Mozer et al. (2001), whose constrained optimization technique is similar to those in (Gao et al., 2006; Jansche, 2005). More specialized methods also exist, for example for support vector machines (Musicant et al., 2003) and for conditional random fields (Gross et al., 2007; Suzuki et al., 2006). All of these methods are about classifier training. In this paper we focus primarily on the related, but orthogonal, issue of predictive inference with a fully trained probabilistic classifier. Using the weighted F-score as our utility function, predictive inference amounts to choosing an optimal hypothesis which maximizes the expected utility. We refer to this as *Current affiliation: Google Inc. Former affiliation: Center of Computational Learning Systems, Columbia University. the prediction or decoding task. In general, decoding can be a hard computational problem (C</context>
</contexts>
<marker>Gross, Russakovsky, Do, Batzoglou, 2007</marker>
<rawString>Samuel S. Gross, Olga Russakovsky, Chuong B. Do, and Serafim Batzoglou. 2007. Training conditional random fields for maximum labelwise accuracy. In Advances in Neural Information Processing Systems, volume 19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R W Hamming</author>
</authors>
<title>Error detecting and error correcting codes.</title>
<date>1950</date>
<journal>The Bell System Technical Journal,</journal>
<volume>26</volume>
<issue>2</issue>
<contexts>
<context position="20068" citStr="Hamming (1950)" startWordPosition="3570" endWordPosition="3571">omputation. 3.5 Other Utility Functions With other functions g the runtime of Algorithm 4 will depend on the asymptotic size of the index set K. If there are asymptotically as many intermediate states at any point as there are final states, then the general asymptotic runtime is O(n JKJ). Many loss/utility functions are subsumed by the present framework. Zero–one loss is trivial: the automaton has two states (success, failure); it starts and remains in the success state as long as the symbols read on both tapes match; on the first mismatch it transitions to, and remains in, the failure state. Hamming (1950) distance is similar to zero–one loss, but counts the number of mismatches (bounded by n), whereas zero–one loss only counts up to a threshold of one. A more interesting case is given by the Pk-score (Beeferman et al., 1999) and its generalizations, which moves a sliding window of size k over a pair of label sequences (z,y) and counts the number of windows which contain a segment boundary on one of the sequences but not the other. To compute its expectation in our framework, all we have to do is express the sliding window mechanism as an automaton, which can be done very naturally (see the pro</context>
</contexts>
<marker>Hamming, 1950</marker>
<rawString>R. W. Hamming. 1950. Error detecting and error correcting codes. The Bell System Technical Journal, 26(2):147–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Jansche</author>
</authors>
<title>Maximum expected F-measure training of logistic regression models.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="1214" citStr="Jansche, 2005" startWordPosition="185" endWordPosition="186">otivation and Scope The weighted F-score (van Rijsbergen, 1974) plays an important role in the evaluation of binary classifiers, as it neatly summarizes a classifier’s ability to identify the positive class. A variety of methods exists for training classifiers that optimize the F-score, or some similar trade-off between false positives and false negatives, precision and recall, sensitivity and specificity, type I error and type II error rate, etc. Among the most general methods are those of Mozer et al. (2001), whose constrained optimization technique is similar to those in (Gao et al., 2006; Jansche, 2005). More specialized methods also exist, for example for support vector machines (Musicant et al., 2003) and for conditional random fields (Gross et al., 2007; Suzuki et al., 2006). All of these methods are about classifier training. In this paper we focus primarily on the related, but orthogonal, issue of predictive inference with a fully trained probabilistic classifier. Using the weighted F-score as our utility function, predictive inference amounts to choosing an optimal hypothesis which maximizes the expected utility. We refer to this as *Current affiliation: Google Inc. Former affiliation:</context>
<context position="5149" citStr="Jansche, 2005" startWordPosition="830" endWordPosition="831">that task (which we will not discuss further in this paper), z are the supervised labels, y is the classifier output, and the challenge is that F(z,y) does not depend smoothly on the parameters of the classifier. Gradient-based optimization techniques are not applicable unless some of the quantities defined above are replaced by approximations that depend smoothly on the classifier’s parameters. For example, the constrained optimization method of (Mozer et al., 2001) relies on approximations of sensitivity (which they call CA) and specificity2 (their CR); related techniques (Gao et al., 2006; Jansche, 2005) rely on approximations of true positives, false positives, and false negatives, and, indirectly, recall and precision. Unlike these methods we compute the expected F-score exactly, without relying on ad hoc approximations of the true positives, etc. Being able to efficiently compute the expected F-score is a prerequisite for maximizing it during decoding. More precisely, we compute the expectation of the function y 7→ F(z,y), (2) which is a unary function obtained by holding the first argument of the binary function F fixed. It will henceforth be abbreviated as F(z,·), and we will denote its </context>
<context position="26561" citStr="Jansche (2005)" startWordPosition="4663" endWordPosition="4664">ized to be elements of a vector space over the reals), we can deal with functions that go beyond simple counts. Like the methods developed by Allauzen et al. (2003) and Cortes et al. (2003) our technique incorporates finite automata, but uses a direct thresholdcounting technique, rather than a nondeterministic counting technique which relies on path multiplicities. This makes it easy to formulate the simultaneous counting of two distinct quantities, such as our A and T, and to reason about the resulting automata. The method described here is similar in spirit to those of Gao et al. (2006) and Jansche (2005), who discuss maximum expected F-score training of decision trees and logistic regression models. However, the present work is considerably more general in two ways: (1) the expected utility computations presented here are not tied in any way to particular classifiers, but can be used with large classes of probabilistic models; and (2) our framework extends beyond the computation of F-scores, which fall out as a special case, to other loss and utility functions, including the Pk score. More importantly, expected F-score computation as presented here can be exact, if desired, whereas the cited </context>
</contexts>
<marker>Jansche, 2005</marker>
<rawString>Martin Jansche. 2005. Maximum expected F-measure training of logistic regression models. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
</authors>
<title>Decoding complexity in word-replacement translation models.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>4</issue>
<pages>615</pages>
<contexts>
<context position="2019" citStr="Knight, 1999" startWordPosition="304" endWordPosition="305"> methods are about classifier training. In this paper we focus primarily on the related, but orthogonal, issue of predictive inference with a fully trained probabilistic classifier. Using the weighted F-score as our utility function, predictive inference amounts to choosing an optimal hypothesis which maximizes the expected utility. We refer to this as *Current affiliation: Google Inc. Former affiliation: Center of Computational Learning Systems, Columbia University. the prediction or decoding task. In general, decoding can be a hard computational problem (Casacuberta and de la Higuera, 2000; Knight, 1999). In this paper we show that the maximum expected F-score decoding problem can be solved in polynomial time under certain assumptions about the underlying probability model. One key ingredient in our solution is a very general framework for evaluating the expected F-score, and indeed many other utility functions, of a fixed hypothesis.1 This framework can also be applied to discriminative classifier training. 1.2 Background and Notation We formulate our approach in terms of sequence labeling, although it has applications beyond that. This is motivated by the fact that our framework for evaluat</context>
</contexts>
<marker>Knight, 1999</marker>
<rawString>Kevin Knight. 1999. Decoding complexity in word-replacement translation models. Computational Linguistics, 25(4):607– 615.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael C Mozer</author>
<author>Robert Dodier</author>
<author>Michael D Colagrosso</author>
<author>C´esar Guerra-Salcedo</author>
<author>Richard Wolniewicz</author>
</authors>
<title>Prodding the ROC curve: Constrained optimization of classifier performance.</title>
<date>2001</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<volume>14</volume>
<contexts>
<context position="1115" citStr="Mozer et al. (2001)" startWordPosition="167" endWordPosition="170">F-score. This framework includes both exact and faster inexact calculation methods. 1 Introduction 1.1 Motivation and Scope The weighted F-score (van Rijsbergen, 1974) plays an important role in the evaluation of binary classifiers, as it neatly summarizes a classifier’s ability to identify the positive class. A variety of methods exists for training classifiers that optimize the F-score, or some similar trade-off between false positives and false negatives, precision and recall, sensitivity and specificity, type I error and type II error rate, etc. Among the most general methods are those of Mozer et al. (2001), whose constrained optimization technique is similar to those in (Gao et al., 2006; Jansche, 2005). More specialized methods also exist, for example for support vector machines (Musicant et al., 2003) and for conditional random fields (Gross et al., 2007; Suzuki et al., 2006). All of these methods are about classifier training. In this paper we focus primarily on the related, but orthogonal, issue of predictive inference with a fully trained probabilistic classifier. Using the weighted F-score as our utility function, predictive inference amounts to choosing an optimal hypothesis which maximi</context>
<context position="5006" citStr="Mozer et al., 2001" startWordPosition="807" endWordPosition="810">d for evaluating the expectation of the F-score, which can also be used as a smooth approximation of the raw F-score during classifier training: in that task (which we will not discuss further in this paper), z are the supervised labels, y is the classifier output, and the challenge is that F(z,y) does not depend smoothly on the parameters of the classifier. Gradient-based optimization techniques are not applicable unless some of the quantities defined above are replaced by approximations that depend smoothly on the classifier’s parameters. For example, the constrained optimization method of (Mozer et al., 2001) relies on approximations of sensitivity (which they call CA) and specificity2 (their CR); related techniques (Gao et al., 2006; Jansche, 2005) rely on approximations of true positives, false positives, and false negatives, and, indirectly, recall and precision. Unlike these methods we compute the expected F-score exactly, without relying on ad hoc approximations of the true positives, etc. Being able to efficiently compute the expected F-score is a prerequisite for maximizing it during decoding. More precisely, we compute the expectation of the function y 7→ F(z,y), (2) which is a unary funct</context>
</contexts>
<marker>Mozer, Dodier, Colagrosso, Guerra-Salcedo, Wolniewicz, 2001</marker>
<rawString>Michael C. Mozer, Robert Dodier, Michael D. Colagrosso, C´esar Guerra-Salcedo, and Richard Wolniewicz. 2001. Prodding the ROC curve: Constrained optimization of classifier performance. In Advances in Neural Information Processing Systems, volume 14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R Musicant</author>
<author>Vipin Kumar</author>
<author>Aysel Ozgur</author>
</authors>
<title>Optimizing F-measure with support vector machines.</title>
<date>2003</date>
<booktitle>In Proceedings of the Sixteenth International Florida Artificial Intelligence Research Society Conference.</booktitle>
<contexts>
<context position="1316" citStr="Musicant et al., 2003" startWordPosition="199" endWordPosition="202"> evaluation of binary classifiers, as it neatly summarizes a classifier’s ability to identify the positive class. A variety of methods exists for training classifiers that optimize the F-score, or some similar trade-off between false positives and false negatives, precision and recall, sensitivity and specificity, type I error and type II error rate, etc. Among the most general methods are those of Mozer et al. (2001), whose constrained optimization technique is similar to those in (Gao et al., 2006; Jansche, 2005). More specialized methods also exist, for example for support vector machines (Musicant et al., 2003) and for conditional random fields (Gross et al., 2007; Suzuki et al., 2006). All of these methods are about classifier training. In this paper we focus primarily on the related, but orthogonal, issue of predictive inference with a fully trained probabilistic classifier. Using the weighted F-score as our utility function, predictive inference amounts to choosing an optimal hypothesis which maximizes the expected utility. We refer to this as *Current affiliation: Google Inc. Former affiliation: Center of Computational Learning Systems, Columbia University. the prediction or decoding task. In ge</context>
</contexts>
<marker>Musicant, Kumar, Ozgur, 2003</marker>
<rawString>David R. Musicant, Vipin Kumar, and Aysel Ozgur. 2003. Optimizing F-measure with support vector machines. In Proceedings of the Sixteenth International Florida Artificial Intelligence Research Society Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Suzuki</author>
<author>Erik McDermott</author>
<author>Hideki Isozaki</author>
</authors>
<title>Training conditional random fields with multivariate evaluation measures.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1392" citStr="Suzuki et al., 2006" startWordPosition="212" endWordPosition="215">ity to identify the positive class. A variety of methods exists for training classifiers that optimize the F-score, or some similar trade-off between false positives and false negatives, precision and recall, sensitivity and specificity, type I error and type II error rate, etc. Among the most general methods are those of Mozer et al. (2001), whose constrained optimization technique is similar to those in (Gao et al., 2006; Jansche, 2005). More specialized methods also exist, for example for support vector machines (Musicant et al., 2003) and for conditional random fields (Gross et al., 2007; Suzuki et al., 2006). All of these methods are about classifier training. In this paper we focus primarily on the related, but orthogonal, issue of predictive inference with a fully trained probabilistic classifier. Using the weighted F-score as our utility function, predictive inference amounts to choosing an optimal hypothesis which maximizes the expected utility. We refer to this as *Current affiliation: Google Inc. Former affiliation: Center of Computational Learning Systems, Columbia University. the prediction or decoding task. In general, decoding can be a hard computational problem (Casacuberta and de la H</context>
</contexts>
<marker>Suzuki, McDermott, Isozaki, 2006</marker>
<rawString>Jun Suzuki, Erik McDermott, and Hideki Isozaki. 2006. Training conditional random fields with multivariate evaluation measures. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J van Rijsbergen</author>
</authors>
<title>Foundation of evaluation.</title>
<date>1974</date>
<journal>Journal of Documentation,</journal>
<volume>30</volume>
<issue>4</issue>
<marker>van Rijsbergen, 1974</marker>
<rawString>C. J. van Rijsbergen. 1974. Foundation of evaluation. Journal of Documentation, 30(4):365–373.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>