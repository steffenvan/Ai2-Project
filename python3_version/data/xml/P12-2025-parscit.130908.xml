<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.027443">
<title confidence="0.991012">
Cross-lingual Parse Disambiguation based on Semantic Correspondence
</title>
<author confidence="0.996607">
Lea Frermann Francis Bond
</author>
<affiliation confidence="0.9977335">
Department of Computational Linguistics Linguistics and Multilingual Studies
Saarland University Nanyang Technological University
</affiliation>
<email confidence="0.99366">
frermann@coli.uni-saarland.de bond@ieee.org
</email>
<sectionHeader confidence="0.997302" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999202363636364">
We present a system for cross-lingual parse
disambiguation, exploiting the assumption
that the meaning of a sentence remains un-
changed during translation and the fact that
different languages have different ambiguities.
We simultaneously reduce ambiguity in multi-
ple languages in a fully automatic way. Eval-
uation shows that the system reliably discards
dispreferred parses from the raw parser output,
which results in a pre-selection that can speed
up manual treebanking.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999950846153846">
Treebanks, sets of parsed sentences annotated with a
sytactic structure, are an important resource in NLP.
The manual construction of treebanks, where a hu-
man annotator selects a gold parse from all parses
returned by a parser, is a tedious and error prone pro-
cess. We present a system for simultaneous and ac-
curate partial parse disambiguation of multiple lan-
guages. Using the pre-selected set of parses returned
by the system, the treebanking process for multiple
languages can be sped up.
The system operates on an aligned parallel cor-
pus. The languages of the parallel corpus are con-
sidered as mutual semantic tags: As the meaning of
a sentence stays constant during translation, we are
able to resolve ambiguities which exist in only one
of the langauges by only accepting those interpreta-
tions which are licensed by the other language.
In particular, we select one language as the tar-
get language, translate the other language’s seman-
tics for every parse into the target language and thus
align maximally similar semantic representations.
The parses with the most overlapping semantics are
selected as preferred parses.
As an example consider the English sentence They
closed the shop at five, which has the following two
interpretations due to PP attachment ambiguity:1
</bodyText>
<listItem confidence="0.87705275">
(1) “At five, they closed the shop”
close(they, shop); at(close, 5)
(2) “The shop at five was closed by them”
close(they, shop); at(shop, 5)
</listItem>
<bodyText confidence="0.986616333333333">
The Japanese translation is also ambiguous, but in
a completely different way: it has the possibility of
a zero pronoun (we show the translated semantics).
</bodyText>
<equation confidence="0.449654">
(3) �
</equation>
<bodyText confidence="0.845245">
kare
he
“At 5 o’clock, they closed the shop.”
</bodyText>
<equation confidence="0.99795225">
close(they, shop); at(close, 5)
(4) “At 5 o’clock, as for them, someone closed the shop.”
close(o, shop); at(close, 5)
topic(they,close)
</equation>
<bodyText confidence="0.9992405">
We show the semantic representation of the ambi-
guity with each sentence. Both languages are disam-
biguated by the other language as only the English
interpretation (1) is supported in Japanese, and only
the Japanese interpretation (3) leads to a grammati-
cal English sentence.
</bodyText>
<sectionHeader confidence="0.999914" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999788">
There is no group using exactly the same approach
as ours: automated parallel parse disambiguation
on the basis of semantic analyses. Zhechev and
</bodyText>
<footnote confidence="0.957853">
1In fact it has four, as they can be either plural or the androg-
ynous singular, this is also disambiguated by the Japanese.
</footnote>
<figure confidence="0.99716462962963">
�
ra
PL
11
wa
TOP
5
5
5
�
ji
hour
l&apos;
ni
at
J1
mise
shop
�
wo
ACC
MY)
shime
close
l`
ta
PAST
</figure>
<page confidence="0.968188">
125
</page>
<note confidence="0.6833675">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 125–129,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999895846153847">
Way (2008) automatically generate parallel tree-
banks for training of statistical machine translation
(SMT) systems through sub-tree alignment. We do
not aim to carry out the complete treebanking pro-
cess, but to optimize speed and precision of manual
creation of high-quality treebanks.
Wu (1997) and others have tried to simultane-
ously learn grammars from bilingual texts. Burkett
and Klein (2008) induce node-alignments of syntac-
tic trees with a log-linear model, in order to guide
bilingual parsing. Chen et al. (2011) translate an
existing treebank using an SMT system and then
project parse results from the treebank to the other
language. This results in a very noisy treebank, that
they then clean. These approaches align at the syn-
tactic level (using CFGs and dependencies respec-
tively).
In contrast to the above approaches, we assume
the existence of grammars and use a semantic rep-
resentation as the appropriate level for cross-lingual
processing. We compare semantic sub-structures, as
those are more straightforwardly comparable across
different languages. As a consequence, our system
is applicable to any combination of languages. The
input is plain parallel text, neither side needs to be
treebanked.
</bodyText>
<sectionHeader confidence="0.994821" genericHeader="method">
3 Materials and Methods
</sectionHeader>
<bodyText confidence="0.999963357142857">
We use grammars within the grammatical frame-
work of head-driven phrase-structure grammar
(HPSG Pollard and Sag (1994)), with the seman-
tic representation of minimal recursion semantics
(MRS; Copestake et al. (2005)). We use two large-
scale HPSG grammars and a Japanese-English ma-
chine translation system, all of which were de-
veloped in the DELPH-IN framework:2 The En-
glish Resource Grammar (ERG; Flickinger (2000))
is used for English parsing, and Jacy (Bender and
Siegel, 2004) for parsing Japanese. For Japanese
to English translation we use Jaen, a semantic-
transfer based machine translation system (Bond
et al., 2011).
</bodyText>
<subsectionHeader confidence="0.999786">
3.1 Semantic Interface and Alignment
</subsectionHeader>
<bodyText confidence="0.997184">
For the alignment, we convert the MRS struc-
tures into simplified elementary dependency graphs
</bodyText>
<equation confidence="0.925806166666667">
2http://www.delph-in.net/
x4:pronoun_q[]
e2:_close_v_c[ARG1 x4:pron, ARG2 x9:_shop_n_of]
x9:_the_q[]
e8:_at_p_temp[ARG1 e2, ARG2 x16:_num_hour(5)]
x16:_def_implicit_q[]
</equation>
<figureCaption confidence="0.988358">
Figure 1: EDG for They closed the shop at five.
</figureCaption>
<bodyText confidence="0.99997424137931">
(EDGs), which abstract away information about
grammatical properties of relations and scopal in-
formation. Preliminary experiments showed that the
former kind of information did not contribute to dis-
ambiguation performance, as number is typically
underspecified in Japanese. As we only consider lo-
cal information in the alignment, scopal information
can be ignored as well. An example EDG is dis-
played in Figure 1.
An EDG consists of a bag of elementary predi-
cates (EPs) which are themselves composed of re-
lations. Each line in Figure 1 corresponds to one
EP. Relations are the elementary building blocks of
the EDG, and loosely correspond to words of the
surface string. EPs consist either of atomic rela-
tions (corresponding to quantifiers), or a predicate-
argument structure which is composed of several re-
lations. During alignment, we only consider non-
atomic EPs, as quantifiers should be considered as
grammatical properties of (lexical) relations, which
we chose to ignore.
Given the EDG representations of the translated
Japanese sentence, and the original target language
EDGs, we can straightforwardly align by matching
substructures of different granularity.
Currently, we align at the predicate level. We are
experimenting with aligning further dependency re-
lation based tuples, which would allow us to resolve
more structural ambiguities.
</bodyText>
<subsectionHeader confidence="0.999321">
3.2 The Disambiguation System
</subsectionHeader>
<bodyText confidence="0.999676625">
Ambiguity in the analyses for both languages is re-
duced on the basis of the semantic analyses returned
for each sentence-pair, and a reduced set of pre-
ferred analyses is returned for both languages. For
each sentence-pair, we (1) parse the English and
the Japanese sentence (MRSE and MRSJ) (2) trans-
fer the Japanese MRS analyses to English MRSs
(MRSJE) (3) convert the top 11 translated MRSs
</bodyText>
<page confidence="0.994074">
126
</page>
<bodyText confidence="0.999932533333334">
and the original English MRSs to EDGs3 (EDGE
and EDGJE) (4) align every possible E and JE EDG
combination and determine the set of best aligning
analyses (5) from those, create language specific sets
of preferred parses.
We are comparing semantic representations of the
same language, the English text from the bilingual
corpus and the English machine translation of the
Japanese text. In order to increase robustness of
our alignment system we not only consider com-
plete translations, but also accept partially translated
MRSs in case no complete translation could be pro-
duced. This step significantly increases the recall,
while the partial MRSs proved to be informative
enough for parse disambiguation.
</bodyText>
<sectionHeader confidence="0.998279" genericHeader="method">
4 Evaluation and Results
</sectionHeader>
<bodyText confidence="0.987783833333333">
We evaluate our model on the task of parse disam-
biguation. We use full sentence match as evaluation
metric, a challenging target.
The Tanaka corpus is used for training and testing
(Tanaka, 2001). It is an open corpus of Japanese-
English sentence pairs. We use version (2008-11)
which contains 147,190 sentence pairs. We hold out
4,500 sentence pairs each for development and test.
For each sentence, we compare the number of the-
oretically possible alignments with the number of
preferred alignments returned by our system. On
average, ambiguity is reduced down to 30%. For
English 3.76 and for Japanese 3.87 parses out of
(at most) 11 analyses remain in the partially disam-
biguated list: both languages benefit equally from
the disambiguation.
We evaluate disambiguation accuracy by counting
the number of times the gold parse was present in the
partially disambiguated set (full sentence match).
Table 1 shows the alignment accuracy results.
The correct parse is included in the reduced set
in 80% of the cases for Japanese, and for 82% of
the cases in English. We match atomic relations
when aligning the semantic structures, which is a
very generic method applicable to the vast major-
ity of sentence pairs. This leads to a recall score of
3These are ranked with a model trained on a hand-
treebanked set. The cutoff was determined empirically: For
both languages the gold parse is included in the top 11 parses in
more than 97% of the cases.
</bodyText>
<table confidence="0.94682">
English Japanese
Prec F Prec F
Included 0.820 0.897 0.804 0.887
First Rank 0.659 0.791 0.676 0.803
MRR 0.713 0.829 0.725 0.837
</table>
<tableCaption confidence="0.862668333333333">
Table 1: Accuracy and F-scores for disambiguation per-
formance of our system. Recall was 99% in every case.
’Included’: inclusion of the gold parse in the reduced set
of parses or not. ’First Rank’: ranking of the preferred
parse as top in the reduced list. ’MRR’: mean reciprocal
rank of the gold parse in the list.
</tableCaption>
<bodyText confidence="0.99737464">
99%, and an F-Score of 89.7% and 88.7% for En-
glish and Japanese, respectively.
The reduced list of parser analyses can be further
ranked by the parse ranking model which is included
in the parsers of the respective languages (the same
models with which we determined the top 11 analy-
ses). Given this ranking, we can evaluate how often
the preferred parse is ranked top in our partially dis-
ambiguated list; results are shown in the two bottom
lines of Table 1.
A ranked list of possible preferred parses whose
top rank corresponds with a high probability to the
gold parse should further speed up the manual tree-
banking process.
Performance in the context of the whole pipeline
The performance of parsers and MT system
strongly influences the end-to-end results of the pre-
sented system. In the results given above, this in-
fluence is ignored. We lose around 29% of our data
because no parse could be produced in one or both
languages, or no translation could be produced. and
a further 5% of the sentences did not have the gold
parse in the original set of analyses (before align-
ment): our system could not possibly select the cor-
rect parse in those cases.
</bodyText>
<sectionHeader confidence="0.99907" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999910428571429">
Our system builds on the output of two parsers and
a machine translation system. We reduce ambiguity
for all sentence pairs where a parse could be cre-
ated for both languages, and for which there was at
least a partial translation. For these sentences, the
cross-lingual alignment component achieves a recall
of above 99%, such that we do not lose any addi-
</bodyText>
<page confidence="0.99436">
127
</page>
<bodyText confidence="0.999974825">
tional data. The parsers and the MT system include
a parse ranking system trained on human gold anno-
tations. We use these models in parsing and transla-
tion to select the top 11 analyses. Our system thus
depends on a range of existing technologies. How-
ever, these technologies are available for a range of
languages, and we use them for efficient extension
of linguistic resources.
The effectiveness of cross-lingual parse disam-
biguation on the basis of semantic alignment highly
depends on the languages of choice. Given that we
exploit the differences between languages, pairs of
less related languages should lead to better disam-
biguation performance. Furthermore, disambiguat-
ing with more than two languages should improve
performance. Some ambiguities may be shared be-
tween languages. 4
One weakness when considering the disam-
biguated sentences as training for a parse ranking
model is that the translation fails on similar kinds of
sentences, so there are some phenomena which we
get no examples of — the automatically trained tree-
bank does not have a uniform coverage of phenom-
ena. Our models may not discriminate some phe-
nomena at all.
Our system provides large amounts of automati-
cally annotated data at the only cost of CPU time:
so far we have disambiguated 25,000 sentences: 10
times more than the existing hand annotated gold
data. Using the parser output for speeding up man-
ual treebanking is most effective if the gold parse is
reliably included in the reduced set of parses. In-
creasing precision by accepting more than only the
most overlapping parses may lead to more effective
manual treebanking.
The alignment method we propose does not make
any language-specific assumptions, nor is it limited
to align two languages only. The algorithm is very
flexible, and allows for straightforward exploration
of different numbers and combinations of languages.
</bodyText>
<sectionHeader confidence="0.991908" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9907475">
Translating a sentence into a different language
changes its surface form, but not its meaning. In
</bodyText>
<footnote confidence="0.893230333333333">
4For example the PP attachment ambiguity in John said that
he went on Tuesday where either the saying or the going could
have happened on Tuesday holds in both English and Japanese.
</footnote>
<bodyText confidence="0.9998879375">
parallel corpora, one language can be viewed as a
semantic tag of the other language and vice versa,
which allows for disambiguation of phenomena
which are ambiguous in only one of the languages.
We use the above observations for cross-lingual
parse disambiguation. We experimented with the
language pair of English and Japanese, and were
able to accurately reduce ambiguity in parser anal-
yses simultaneously for both languages to 30% of
the starting ambiguity. The remaining parses can be
used as a pre-selection to speed up the manual tree-
banking process.
We started working on an extrinsic evaluation of
the presented system by training a discriminative
parse ranking model on the output of our alignment
process. Augmenting the Gold training data with
our data improves the model. Our next step will
be to evaluate the system as part of the treebanking
process, and optimize the parameters such as disam-
biguation precision vs. amount of disambiguation.
As no language-specific assumptions are hard
coded in our disambiguation system, it would be
very interesting to apply the system to different lan-
guage pairs as well as groups of more than two lan-
guages. Using a group of languages for disambigua-
tion will likely lead to increased and more accurate
disambiguation, as more constraints are imposed on
the data.
Probably the most important goal for future work
is improving the recall achieved in the complete dis-
ambiguation pipeline. Many sentence-pairs cannot
be disambiguated because either no parse can be
generated for one or both languages, or no (par-
tial) translation can be produced. Following the
idea of partial translations, partial parses may be a
valid backoff. For purposes of cross-lingual align-
ment, partial structures may contribute enough in-
formation for disambiguation. There has been work
regarding partial parsing in the HPSG community
(Zhang and Kordoni, 2008), which we would like to
explore. There is also current work on learning more
types and instances of transfer rules (Haugereid and
Bond, 2011).
Finally, we would like to investigate more align-
ment methods, such as dependency relation based
alignment which we started experimenting with, or
EDM-based metrics as presented in (Dridan and
Oepen, 2011).
</bodyText>
<page confidence="0.997421">
128
</page>
<sectionHeader confidence="0.99921" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999661">
This research was supported in part by the Erasmus
Mundus Action 2 program MULTI of the European
Union, grant agreement number 2009-5259-5 and
the the joint JSPS/NTU grant on Revealing Meaning
Using Multiple Languages. We would like to thank
Takayuki Kuribayashi and Dan Flickinger for their
help with the treebanking.
</bodyText>
<sectionHeader confidence="0.998582" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996972836734694">
Emily M. Bender and Melanie Siegel. 2004. Im-
plementing the syntax of Japanese numeral clas-
sifiers. In Proceedings of the IJC-NLP-2004.
Francis Bond, Stephan Oepen, Eric Nichols, Dan
Flickinger, Erik Velldal, and Petter Haugereid.
2011. Deep open-source machine translation.
Machine Translation, 25(2):87–105.
David Burkett and Dan Klein. 2008. Two languages
are better than one (for syntactic parsing). In Pro-
ceedings of EMNLP, 2008.
Wenliang Chen, Jun’ichi Kazama, Min Zhang,
Yoshimasa Tsuruoka, Yujie Zhang, Yiou Wang,
Kentaro Torisawa, and Haizhou Li. 2011. SMT
helps bitext dependency parsing. In Conference
on Empirical Methods in Natural Language Pro-
cessing (EMNLP2011), pages 73–83. Edinburgh.
Ann Copestake, Dan Flickinger, Carl Pollard, and
Ivan A. Sag. 2005. Minimal recursion semantics –
an introduction. Research on Language and Com-
putation, 3:281–332.
Rebecca Dridan and Stephan Oepen. 2011. Parser
evaluation using elementary dependency match-
ing. In Proceedings of IWPT.
Dan Flickinger. 2000. On building a more efficient
grammar by exploiting types. Natural Language
Engineering, 6(1):15–28. (Special Issue on Effi-
cient Processing with HPSG).
Petter Haugereid and Francis Bond. 2011. Extract-
ing transfer rules for multiword expressions from
parallel corpora. In Proceedings of the Work-
shop on Multiword Expressions: from Parsing
and Generation to the Real World.
Carl Pollard and Ivan A. Sag. 1994. Head
Driven Phrase Structure Grammar. University of
Chicago Press, Chicago.
Yasuhito Tanaka. 2001. Compilation of a multilin-
gual parallel corpus. In Proceedings of PACLING
2001.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel cor-
pora. Computational Linguistics, 23(3):377–403.
Yi Zhang and Valia Kordoni. 2008. Robust parsing
with a large HPSG grammar. In Proceedings of
the Sixth International Conference on Language
Resources and Evaluation (LREC’08).
Ventsislav Zhechev and Andy Way. 2008. Auto-
matic generation of parallel treebanks. In Pro-
ceedings of the 22nd International Conference on
Computational Linguistics (Coling 2008).
</reference>
<page confidence="0.99857">
129
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.932837">
<title confidence="0.992978">Cross-lingual Parse Disambiguation based on Semantic Correspondence</title>
<author confidence="0.99995">Lea Frermann Francis Bond</author>
<affiliation confidence="0.999845">Department of Computational Linguistics Linguistics and Multilingual Studies Saarland University Nanyang Technological University</affiliation>
<email confidence="0.948173">frermann@coli.uni-saarland.debond@ieee.org</email>
<abstract confidence="0.999259166666667">We present a system for cross-lingual parse disambiguation, exploiting the assumption that the meaning of a sentence remains unchanged during translation and the fact that different languages have different ambiguities. We simultaneously reduce ambiguity in multiple languages in a fully automatic way. Evaluation shows that the system reliably discards dispreferred parses from the raw parser output, which results in a pre-selection that can speed up manual treebanking.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Emily M Bender</author>
<author>Melanie Siegel</author>
</authors>
<title>Implementing the syntax of Japanese numeral classifiers.</title>
<date>2004</date>
<booktitle>In Proceedings of the IJC-NLP-2004.</booktitle>
<contexts>
<context position="5093" citStr="Bender and Siegel, 2004" startWordPosition="794" endWordPosition="797">ystem is applicable to any combination of languages. The input is plain parallel text, neither side needs to be treebanked. 3 Materials and Methods We use grammars within the grammatical framework of head-driven phrase-structure grammar (HPSG Pollard and Sag (1994)), with the semantic representation of minimal recursion semantics (MRS; Copestake et al. (2005)). We use two largescale HPSG grammars and a Japanese-English machine translation system, all of which were developed in the DELPH-IN framework:2 The English Resource Grammar (ERG; Flickinger (2000)) is used for English parsing, and Jacy (Bender and Siegel, 2004) for parsing Japanese. For Japanese to English translation we use Jaen, a semantictransfer based machine translation system (Bond et al., 2011). 3.1 Semantic Interface and Alignment For the alignment, we convert the MRS structures into simplified elementary dependency graphs 2http://www.delph-in.net/ x4:pronoun_q[] e2:_close_v_c[ARG1 x4:pron, ARG2 x9:_shop_n_of] x9:_the_q[] e8:_at_p_temp[ARG1 e2, ARG2 x16:_num_hour(5)] x16:_def_implicit_q[] Figure 1: EDG for They closed the shop at five. (EDGs), which abstract away information about grammatical properties of relations and scopal information. P</context>
</contexts>
<marker>Bender, Siegel, 2004</marker>
<rawString>Emily M. Bender and Melanie Siegel. 2004. Implementing the syntax of Japanese numeral classifiers. In Proceedings of the IJC-NLP-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francis Bond</author>
<author>Stephan Oepen</author>
<author>Eric Nichols</author>
<author>Dan Flickinger</author>
<author>Erik Velldal</author>
<author>Petter Haugereid</author>
</authors>
<title>Deep open-source machine translation.</title>
<date>2011</date>
<journal>Machine Translation,</journal>
<volume>25</volume>
<issue>2</issue>
<contexts>
<context position="5236" citStr="Bond et al., 2011" startWordPosition="816" endWordPosition="819">e use grammars within the grammatical framework of head-driven phrase-structure grammar (HPSG Pollard and Sag (1994)), with the semantic representation of minimal recursion semantics (MRS; Copestake et al. (2005)). We use two largescale HPSG grammars and a Japanese-English machine translation system, all of which were developed in the DELPH-IN framework:2 The English Resource Grammar (ERG; Flickinger (2000)) is used for English parsing, and Jacy (Bender and Siegel, 2004) for parsing Japanese. For Japanese to English translation we use Jaen, a semantictransfer based machine translation system (Bond et al., 2011). 3.1 Semantic Interface and Alignment For the alignment, we convert the MRS structures into simplified elementary dependency graphs 2http://www.delph-in.net/ x4:pronoun_q[] e2:_close_v_c[ARG1 x4:pron, ARG2 x9:_shop_n_of] x9:_the_q[] e8:_at_p_temp[ARG1 e2, ARG2 x16:_num_hour(5)] x16:_def_implicit_q[] Figure 1: EDG for They closed the shop at five. (EDGs), which abstract away information about grammatical properties of relations and scopal information. Preliminary experiments showed that the former kind of information did not contribute to disambiguation performance, as number is typically unde</context>
</contexts>
<marker>Bond, Oepen, Nichols, Flickinger, Velldal, Haugereid, 2011</marker>
<rawString>Francis Bond, Stephan Oepen, Eric Nichols, Dan Flickinger, Erik Velldal, and Petter Haugereid. 2011. Deep open-source machine translation. Machine Translation, 25(2):87–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Burkett</author>
<author>Dan Klein</author>
</authors>
<title>Two languages are better than one (for syntactic parsing).</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<contexts>
<context position="3775" citStr="Burkett and Klein (2008)" startWordPosition="589" endWordPosition="592">C MY) shime close l` ta PAST 125 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 125–129, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Way (2008) automatically generate parallel treebanks for training of statistical machine translation (SMT) systems through sub-tree alignment. We do not aim to carry out the complete treebanking process, but to optimize speed and precision of manual creation of high-quality treebanks. Wu (1997) and others have tried to simultaneously learn grammars from bilingual texts. Burkett and Klein (2008) induce node-alignments of syntactic trees with a log-linear model, in order to guide bilingual parsing. Chen et al. (2011) translate an existing treebank using an SMT system and then project parse results from the treebank to the other language. This results in a very noisy treebank, that they then clean. These approaches align at the syntactic level (using CFGs and dependencies respectively). In contrast to the above approaches, we assume the existence of grammars and use a semantic representation as the appropriate level for cross-lingual processing. We compare semantic sub-structures, as t</context>
</contexts>
<marker>Burkett, Klein, 2008</marker>
<rawString>David Burkett and Dan Klein. 2008. Two languages are better than one (for syntactic parsing). In Proceedings of EMNLP, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenliang Chen</author>
<author>Jun’ichi Kazama</author>
<author>Min Zhang</author>
<author>Yoshimasa Tsuruoka</author>
<author>Yujie Zhang</author>
<author>Yiou Wang</author>
<author>Kentaro Torisawa</author>
<author>Haizhou Li</author>
</authors>
<title>SMT helps bitext dependency parsing.</title>
<date>2011</date>
<booktitle>In Conference on Empirical Methods in Natural Language Processing (EMNLP2011),</booktitle>
<pages>73--83</pages>
<location>Edinburgh.</location>
<contexts>
<context position="3898" citStr="Chen et al. (2011)" startWordPosition="609" endWordPosition="612">25–129, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Way (2008) automatically generate parallel treebanks for training of statistical machine translation (SMT) systems through sub-tree alignment. We do not aim to carry out the complete treebanking process, but to optimize speed and precision of manual creation of high-quality treebanks. Wu (1997) and others have tried to simultaneously learn grammars from bilingual texts. Burkett and Klein (2008) induce node-alignments of syntactic trees with a log-linear model, in order to guide bilingual parsing. Chen et al. (2011) translate an existing treebank using an SMT system and then project parse results from the treebank to the other language. This results in a very noisy treebank, that they then clean. These approaches align at the syntactic level (using CFGs and dependencies respectively). In contrast to the above approaches, we assume the existence of grammars and use a semantic representation as the appropriate level for cross-lingual processing. We compare semantic sub-structures, as those are more straightforwardly comparable across different languages. As a consequence, our system is applicable to any co</context>
</contexts>
<marker>Chen, Kazama, Zhang, Tsuruoka, Zhang, Wang, Torisawa, Li, 2011</marker>
<rawString>Wenliang Chen, Jun’ichi Kazama, Min Zhang, Yoshimasa Tsuruoka, Yujie Zhang, Yiou Wang, Kentaro Torisawa, and Haizhou Li. 2011. SMT helps bitext dependency parsing. In Conference on Empirical Methods in Natural Language Processing (EMNLP2011), pages 73–83. Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<date>2005</date>
<booktitle>Minimal recursion semantics – an introduction. Research on Language and Computation,</booktitle>
<pages>3--281</pages>
<contexts>
<context position="4830" citStr="Copestake et al. (2005)" startWordPosition="751" endWordPosition="754">s, we assume the existence of grammars and use a semantic representation as the appropriate level for cross-lingual processing. We compare semantic sub-structures, as those are more straightforwardly comparable across different languages. As a consequence, our system is applicable to any combination of languages. The input is plain parallel text, neither side needs to be treebanked. 3 Materials and Methods We use grammars within the grammatical framework of head-driven phrase-structure grammar (HPSG Pollard and Sag (1994)), with the semantic representation of minimal recursion semantics (MRS; Copestake et al. (2005)). We use two largescale HPSG grammars and a Japanese-English machine translation system, all of which were developed in the DELPH-IN framework:2 The English Resource Grammar (ERG; Flickinger (2000)) is used for English parsing, and Jacy (Bender and Siegel, 2004) for parsing Japanese. For Japanese to English translation we use Jaen, a semantictransfer based machine translation system (Bond et al., 2011). 3.1 Semantic Interface and Alignment For the alignment, we convert the MRS structures into simplified elementary dependency graphs 2http://www.delph-in.net/ x4:pronoun_q[] e2:_close_v_c[ARG1 x</context>
</contexts>
<marker>Copestake, Flickinger, Pollard, Sag, 2005</marker>
<rawString>Ann Copestake, Dan Flickinger, Carl Pollard, and Ivan A. Sag. 2005. Minimal recursion semantics – an introduction. Research on Language and Computation, 3:281–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Dridan</author>
<author>Stephan Oepen</author>
</authors>
<title>Parser evaluation using elementary dependency matching.</title>
<date>2011</date>
<booktitle>In Proceedings of IWPT.</booktitle>
<marker>Dridan, Oepen, 2011</marker>
<rawString>Rebecca Dridan and Stephan Oepen. 2011. Parser evaluation using elementary dependency matching. In Proceedings of IWPT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
</authors>
<title>On building a more efficient grammar by exploiting types.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<booktitle>(Special Issue on Efficient Processing with HPSG).</booktitle>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="5028" citStr="Flickinger (2000)" startWordPosition="785" endWordPosition="786">arable across different languages. As a consequence, our system is applicable to any combination of languages. The input is plain parallel text, neither side needs to be treebanked. 3 Materials and Methods We use grammars within the grammatical framework of head-driven phrase-structure grammar (HPSG Pollard and Sag (1994)), with the semantic representation of minimal recursion semantics (MRS; Copestake et al. (2005)). We use two largescale HPSG grammars and a Japanese-English machine translation system, all of which were developed in the DELPH-IN framework:2 The English Resource Grammar (ERG; Flickinger (2000)) is used for English parsing, and Jacy (Bender and Siegel, 2004) for parsing Japanese. For Japanese to English translation we use Jaen, a semantictransfer based machine translation system (Bond et al., 2011). 3.1 Semantic Interface and Alignment For the alignment, we convert the MRS structures into simplified elementary dependency graphs 2http://www.delph-in.net/ x4:pronoun_q[] e2:_close_v_c[ARG1 x4:pron, ARG2 x9:_shop_n_of] x9:_the_q[] e8:_at_p_temp[ARG1 e2, ARG2 x16:_num_hour(5)] x16:_def_implicit_q[] Figure 1: EDG for They closed the shop at five. (EDGs), which abstract away information ab</context>
</contexts>
<marker>Flickinger, 2000</marker>
<rawString>Dan Flickinger. 2000. On building a more efficient grammar by exploiting types. Natural Language Engineering, 6(1):15–28. (Special Issue on Efficient Processing with HPSG).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Petter Haugereid</author>
<author>Francis Bond</author>
</authors>
<title>Extracting transfer rules for multiword expressions from parallel corpora.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World.</booktitle>
<marker>Haugereid, Bond, 2011</marker>
<rawString>Petter Haugereid and Francis Bond. 2011. Extracting transfer rules for multiword expressions from parallel corpora. In Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Head Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="4734" citStr="Pollard and Sag (1994)" startWordPosition="737" endWordPosition="740"> syntactic level (using CFGs and dependencies respectively). In contrast to the above approaches, we assume the existence of grammars and use a semantic representation as the appropriate level for cross-lingual processing. We compare semantic sub-structures, as those are more straightforwardly comparable across different languages. As a consequence, our system is applicable to any combination of languages. The input is plain parallel text, neither side needs to be treebanked. 3 Materials and Methods We use grammars within the grammatical framework of head-driven phrase-structure grammar (HPSG Pollard and Sag (1994)), with the semantic representation of minimal recursion semantics (MRS; Copestake et al. (2005)). We use two largescale HPSG grammars and a Japanese-English machine translation system, all of which were developed in the DELPH-IN framework:2 The English Resource Grammar (ERG; Flickinger (2000)) is used for English parsing, and Jacy (Bender and Siegel, 2004) for parsing Japanese. For Japanese to English translation we use Jaen, a semantictransfer based machine translation system (Bond et al., 2011). 3.1 Semantic Interface and Alignment For the alignment, we convert the MRS structures into simpl</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Carl Pollard and Ivan A. Sag. 1994. Head Driven Phrase Structure Grammar. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasuhito Tanaka</author>
</authors>
<title>Compilation of a multilingual parallel corpus.</title>
<date>2001</date>
<booktitle>In Proceedings of PACLING</booktitle>
<contexts>
<context position="8286" citStr="Tanaka, 2001" startWordPosition="1285" endWordPosition="1286">lingual corpus and the English machine translation of the Japanese text. In order to increase robustness of our alignment system we not only consider complete translations, but also accept partially translated MRSs in case no complete translation could be produced. This step significantly increases the recall, while the partial MRSs proved to be informative enough for parse disambiguation. 4 Evaluation and Results We evaluate our model on the task of parse disambiguation. We use full sentence match as evaluation metric, a challenging target. The Tanaka corpus is used for training and testing (Tanaka, 2001). It is an open corpus of JapaneseEnglish sentence pairs. We use version (2008-11) which contains 147,190 sentence pairs. We hold out 4,500 sentence pairs each for development and test. For each sentence, we compare the number of theoretically possible alignments with the number of preferred alignments returned by our system. On average, ambiguity is reduced down to 30%. For English 3.76 and for Japanese 3.87 parses out of (at most) 11 analyses remain in the partially disambiguated list: both languages benefit equally from the disambiguation. We evaluate disambiguation accuracy by counting the</context>
</contexts>
<marker>Tanaka, 2001</marker>
<rawString>Yasuhito Tanaka. 2001. Compilation of a multilingual parallel corpus. In Proceedings of PACLING 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="3673" citStr="Wu (1997)" startWordPosition="575" endWordPosition="576">guated by the Japanese. � ra PL 11 wa TOP 5 5 5 � ji hour l&apos; ni at J1 mise shop � wo ACC MY) shime close l` ta PAST 125 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 125–129, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Way (2008) automatically generate parallel treebanks for training of statistical machine translation (SMT) systems through sub-tree alignment. We do not aim to carry out the complete treebanking process, but to optimize speed and precision of manual creation of high-quality treebanks. Wu (1997) and others have tried to simultaneously learn grammars from bilingual texts. Burkett and Klein (2008) induce node-alignments of syntactic trees with a log-linear model, in order to guide bilingual parsing. Chen et al. (2011) translate an existing treebank using an SMT system and then project parse results from the treebank to the other language. This results in a very noisy treebank, that they then clean. These approaches align at the syntactic level (using CFGs and dependencies respectively). In contrast to the above approaches, we assume the existence of grammars and use a semantic represen</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Zhang</author>
<author>Valia Kordoni</author>
</authors>
<title>Robust parsing with a large HPSG grammar.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08).</booktitle>
<contexts>
<context position="15569" citStr="Zhang and Kordoni, 2008" startWordPosition="2496" endWordPosition="2499">guation, as more constraints are imposed on the data. Probably the most important goal for future work is improving the recall achieved in the complete disambiguation pipeline. Many sentence-pairs cannot be disambiguated because either no parse can be generated for one or both languages, or no (partial) translation can be produced. Following the idea of partial translations, partial parses may be a valid backoff. For purposes of cross-lingual alignment, partial structures may contribute enough information for disambiguation. There has been work regarding partial parsing in the HPSG community (Zhang and Kordoni, 2008), which we would like to explore. There is also current work on learning more types and instances of transfer rules (Haugereid and Bond, 2011). Finally, we would like to investigate more alignment methods, such as dependency relation based alignment which we started experimenting with, or EDM-based metrics as presented in (Dridan and Oepen, 2011). 128 Acknowledgments This research was supported in part by the Erasmus Mundus Action 2 program MULTI of the European Union, grant agreement number 2009-5259-5 and the the joint JSPS/NTU grant on Revealing Meaning Using Multiple Languages. We would li</context>
</contexts>
<marker>Zhang, Kordoni, 2008</marker>
<rawString>Yi Zhang and Valia Kordoni. 2008. Robust parsing with a large HPSG grammar. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ventsislav Zhechev</author>
<author>Andy Way</author>
</authors>
<title>Automatic generation of parallel treebanks.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling</booktitle>
<marker>Zhechev, Way, 2008</marker>
<rawString>Ventsislav Zhechev and Andy Way. 2008. Automatic generation of parallel treebanks. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>