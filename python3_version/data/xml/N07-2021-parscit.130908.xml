<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.035199">
<title confidence="0.9971175">
Semi-Supervised Learning for Semantic Parsing
using Support Vector Machines
</title>
<author confidence="0.78463">
Rohit J. Kate and Raymond J. Mooney
</author>
<affiliation confidence="0.924799333333333">
Department of Computer Sciences
The University of Texas at Austin
1 University Station C0500
</affiliation>
<address confidence="0.663007">
Austin, TX 78712-0233, USA
</address>
<email confidence="0.999336">
{rjkate,mooney}@cs.utexas.edu
</email>
<sectionHeader confidence="0.995648" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999978888888889">
We present a method for utilizing unan-
notated sentences to improve a semantic
parser which maps natural language (NL)
sentences into their formal meaning rep-
resentations (MRs). Given NL sentences
annotated with their MRs, the initial su-
pervised semantic parser learns the map-
ping by training Support Vector Machine
(SVM) classifiers for every production in
the MR grammar. Our new method ap-
plies the learned semantic parser to the
unannotated sentences and collects unla-
beled examples which are then used to
retrain the classifiers using a variant of
transductive SVMs. Experimental results
show the improvements obtained over
the purely supervised parser, particularly
when the annotated training set is small.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999671416666667">
Semantic parsing is the task of mapping a natu-
ral language (NL) sentence into a complete, for-
mal meaning representation (MR) which a computer
program can execute to perform some task, like
answering database queries or controlling a robot.
These MRs are expressed in domain-specific unam-
biguous formal meaning representation languages
(MRLs). Given a training corpus of NL sentences
annotated with their correct MRs, the goal of a learn-
ing system for semantic parsing is to induce an ef-
ficient and accurate semantic parser that can map
novel sentences into their correct MRs.
</bodyText>
<page confidence="0.994727">
81
</page>
<bodyText confidence="0.99974052173913">
Several learning systems have been developed for
semantic parsing, many of them recently (Zelle and
Mooney, 1996; Zettlemoyer and Collins, 2005; Ge
and Mooney, 2005; Kate and Mooney, 2006). These
systems use supervised learning methods which
only utilize annotated NL sentences. However, it
requires considerable human effort to annotate sen-
tences. In contrast, unannotated NL sentences are
usually easily available. Semi-supervised learning
methods utilize cheaply available unannotated data
during training along with annotated data and of-
ten perform better than purely supervised learning
methods trained on the same amount of annotated
data (Chapelle et al., 2006). In this paper we present,
to our knowledge, the first semi-supervised learning
system for semantic parsing.
We modify KRISP, a supervised learning sys-
tem for semantic parsing presented in (Kate and
Mooney, 2006), to make a semi-supervised system
we call SEMISUP-KRISP. Experiments on a real-
world dataset show the improvements SEMISUP-
KRISP obtains over KRISP by utilizing unannotated
sentences.
</bodyText>
<sectionHeader confidence="0.97618" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.996140333333333">
This section briefly provides background needed for
describing our approach to semi-supervised seman-
tic parsing.
</bodyText>
<subsectionHeader confidence="0.992528">
2.1 KRISP: The Supervised Semantic Parsing
Learning System
</subsectionHeader>
<bodyText confidence="0.77437">
KRISP (Kernel-based Robust Interpretation for Se-
mantic Parsing) (Kate and Mooney, 2006) is a su-
pervised learning system for semantic parsing which
</bodyText>
<note confidence="0.453049">
Proceedings of NAACL HLT 2007, Companion Volume, pages 81–84,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999874735294118">
takes NL sentences paired with their MRs as train-
ing data. The productions of the formal MRL
grammar are treated like semantic concepts. For
each of these productions, a Support-Vector Ma-
chine (SVM) (Cristianini and Shawe-Taylor, 2000)
classifier is trained using string similarity as the ker-
nel (Lodhi et al., 2002). Each classifier can then
estimate the probability of any NL substring rep-
resenting the semantic concept for its production.
During semantic parsing, the classifiers are called to
estimate probabilities on different substrings of the
sentence to compositionally build the most probable
meaning representation (MR) of the sentence.
KRISP trains the classifiers used in semantic pars-
ing iteratively. In each iteration, for every produc-
tion7in the MRL grammar, KRISP collects pos-
itive and negative examples. In the first iteration,
the set of positive examples for production7con-
tains all sentences whose corresponding MRs use
the production7in their parse trees. The set of neg-
ative examples includes all of the other training sen-
tences. Using these positive and negative examples,
an SVM classifier is trained for each production7
using a string kernel. In subsequent iterations, the
parser learned from the previous iteration is applied
to the training examples and more refined positive
and negative examples, which are more specific sub-
strings within the sentences, are collected for train-
ing. Iterations are continued until the classifiers con-
verge, analogous to iterations in EM (Dempster et
al., 1977). Experimentally, KRISP compares favor-
ably to other existing semantic parsing systems and
is particularly robust to noisy training data (Kate and
Mooney, 2006).
</bodyText>
<subsectionHeader confidence="0.998196">
2.2 Transductive SVMs
</subsectionHeader>
<bodyText confidence="0.999955326923077">
SVMs (Cristianini and Shawe-Taylor, 2000) are
state-of-the-art machine learning methods for clas-
sification. Given positive and negative training ex-
amples in some vector space, an SVM finds the
maximum-margin hyperplane which separates them.
Maximizing the margin prevents over-fitting in very
high-dimensional data which is typical in natural
language processing and thus leads to better general-
ization performance on test examples. When the un-
labeled test examples are also available during train-
ing, a transductive framework for learning (Vapnik,
1998) can further improve the performance on the
test examples.
Transductive SVMs were introduced in
(Joachims, 1999). The key idea is to find the
labeling of the test examples that results in the
maximum-margin hyperplane that separates the
positive and negative examples of both the training
and the test data. This is achieved by including
variables in the SVM’s objective function repre-
senting labels of the test examples. Finding the
exact solution to the resulting optimization problem
is intractable, however Joachims (1999) gives an
approximation algorithm for it. One drawback of
his algorithm is that it requires the proportion of
positive and negative examples in the test data be
close to the proportion in the training data, which
may not always hold, particularly when the training
data is small. Chen et al. (2003) present another
approximation algorithm which we use in our
system because it does not require this assumption.
More recently, new optimization methods have been
used to scale-up transductive SVMs to large data
sets (Collobert et al., 2006), however we did not
face scaling problems in our current experiments.
Although transductive SVMs were originally de-
signed to improve performance on the test data by
utilizing its availability during training, they can also
be directly used in a semi-supervised setting (Ben-
nett and Demiriz, 1999) where unlabeled data is
available during training that comes from the same
distribution as the test data but is not the actual data
on which the classifier is eventually to be tested.
This framework is more realistic in the context of se-
mantic parsing where sentences must be processed
in real-time and it is not practical to re-train the
parser transductively for every new test sentence. In-
stead of using an alternative semi-supervised SVM
algorithm, we preferred to use a transductive SVM
algorithm (Chen et al., 2003) in a semi-supervised
manner, since it is easily implemented on top of an
existing SVM system.
</bodyText>
<sectionHeader confidence="0.984129" genericHeader="method">
3 Semi-Supervised Semantic Parsing
</sectionHeader>
<bodyText confidence="0.9994444">
We modified the existing supervised system KRISP,
described in section 2.1, to incorporate semi-
supervised learning. Supervised learning in KRISP
involves training SVM classifiers on positive and
negative examples that are substrings of the anno-
</bodyText>
<page confidence="0.974634">
82
</page>
<bodyText confidence="0.637652">
function TRAIN SEMISUP KRISP(Annotated corpusA=f(si,mi)ji=1..Ng, MRL grammarG,
</bodyText>
<equation confidence="0.985499">
Unannotated sentences T = fti ji = 1..Mg)
C - fC, j7r 2 Gg = TRAIN KRISP(A,G) // classifiers obtained by training KRISP
Let
P = f p,r = Setof positive examples used in training C, j7r 2 Gg
N = fn, = Set of negative examples used in training C, j7r 2 Gg
U = fu,r = 0j7r 2 Gg // set of unlabeled examples for each production, initially all empty
for i = 1 to M do
N. j7r 2 Gg =COLLECT CLASSIFIER CALLS(PARSE(ti, C))
U=fu,r=u,r[ui&apos;j7r2Gg
for each 7r 2 G do
C, =TRANSDUCTIVE SVM TRAIN(p,r, n,r, u,r) // retrain classifiers utilizing unlabeled examples
return classifiers C = fC, j7r 2 Gg
</equation>
<figureCaption confidence="0.99973">
Figure 1: SEMISUP-KRISP’s training algorithm
</figureCaption>
<bodyText confidence="0.998843457142857">
tated sentences. In order to perform semi-supervised
learning, these classifiers need to be given appropri-
ate unlabeled examples. The key question is: Which
substrings of the unannotated sentences should be
given as unlabeled examples to which productions’
classifiers? Giving all substrings of the unannotated
sentences as unlabeled examples to all of the clas-
sifiers would lead to a huge number of unlabeled
examples that would not conform to the underly-
ing distribution of classes each classifier is trying to
separate. SEMISUP-KRISP’s training algorithm, de-
scribed below and shown in Figure 1, addresses this
issue.
The training algorithm first runs KRISP’s exist-
ing training algorithm and obtains SVM classifiers
for every production in the MRL grammar. Sets of
positive and negative examples that were used for
training the classifiers in the last iteration are col-
lected for each production. Next, the learned parser
is applied to the unannotated sentences. During the
parsing of each sentence, whenever a classifier is
called to estimate the probability of a substring rep-
resenting the semantic concept for its production,
that substring is saved as an unlabeled example for
that classifier. These substrings are representative of
the examples that the classifier will actually need to
handle during testing. Note that the MRs obtained
from parsing the unannotated sentences do not play
a role during training since it is unknown whether
or not they are correct. These sets of unlabeled ex-
amples for each production, along with the sets of
positive and negative examples collected earlier, are
then used to retrain the classifiers using transductive
SVMs. The retrained classifiers are finally returned
and used in the final semantic parser.
</bodyText>
<sectionHeader confidence="0.998638" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999745833333333">
We compared the performance of SEMISUP-KRISP
and KRISP in the GEOQUERY domain for semantic
parsing in which the MRL is a functional language
used to query a U.S. geography database (Kate et
al., 2005). This domain has been used in most of
the previous work. The original corpus contains250
NL queries collected from undergraduate students
and annotated with their correct MRs (Zelle and
Mooney, 1996). Later,630additional NL queries
were collected from real users of a web-based inter-
face and annotated (Tang and Mooney, 2001). We
used this data as unannotated sentences in our cur-
rent experiments. We also collected an additional
407queries from the same interface, making a total
of1,037unannotated sentences.
The systems were evaluated using standard 10-
fold cross validation. All the unannotated sentences
were used for training in each fold. Performance
was measured in terms of precision (the percent-
age of generated MRs that were correct) and recall
(the percentage of all sentences for which correct
MRs were obtained). An output MR is considered
correct if and only if the resulting query retrieves
the same answer as the correct MR when submit-
ted to the database. Since the systems assign confi-
dences to the MRs they generate, the entire range of
the precision-recall trade-off can be obtained for a
system by measuring precision and recall at various
confidence levels. We present learning curves for the
best F-measure (harmonic mean of precision and re-
</bodyText>
<page confidence="0.995726">
83
</page>
<figure confidence="0.9804275">
0 20 40 60 80 100 120 140 160 180 200 220 240
No. of annotated training sentences
</figure>
<figureCaption confidence="0.8605592">
Figure 2: Learning curves for the best F-measures
on the GEOQUERY corpus.
call) obtained across the precision-recall trade-off as
the amount of annotated training data is increased.
Figure 2 shows the results for both systems.
</figureCaption>
<bodyText confidence="0.999960666666666">
The results clearly show the improvement
SEMISUP-KRISP obtains over KRISP by utilizing
unannotated sentences, particularly when the num-
ber of annotated sentences is small. We also show
the performance of a hand-built semantic parser
GEOBASE (Borland International, 1988) for com-
parison. From the figure, it can be seen that, on
average, KRISP achieves the same performance as
GEOBASE when it is given126annotated examples,
while SEMISUP-KRISP reaches this level given only
94annotated examples, a25.4%savings in human-
annotation effort.
</bodyText>
<sectionHeader confidence="0.999567" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999752">
This paper has presented a semi-supervised ap-
proach to semantic parsing. Our method utilizes
unannotated sentences during training by extracting
unlabeled examples for the SVM classifiers it uses to
perform semantic parsing. These classifiers are then
retrained using transductive SVMs. Experimental
results demonstrated that this exploitation of unla-
beled data significantly improved the accuracy of the
resulting parsers when only limited supervised data
was provided.
</bodyText>
<sectionHeader confidence="0.998298" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999345333333333">
This research was supported by a Google research
grant. The experiments were run on the Mastodon
cluster provided by NSF grant EIA-0303609.
</bodyText>
<sectionHeader confidence="0.99031" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999522765957447">
K. Bennett and A. Demiriz. 1999. Semi-supervised support
vector machines. Advances in Neural Information Process-
ing Systems, 11:368–374.
Borland International. 1988. Turbo Prolog 2.0 Reference
Guide. Borland International, Scotts Valley, CA.
O. Chapelle, B. Sch¨olkopf, and A. Zien, editors. 2006. Semi-
Supervised Learning. MIT Press, Cambridge, MA.
Y. Chen, G. Wang, and S. Dong. 2003. Learning with progres-
sive transductive support vector machine. Pattern Recogni-
tion Letters, 24:1845–1855.
R. Collobert, F. Sinz, J. Weston, and L. Bottou. 2006. Large
scale transductive SVMs. Journal of Machine Learning Re-
search, 7(Aug):1687–1712.
N. Cristianini and J. Shawe-Taylor. 2000. An Introduction to
Support Vector Machines and Other Kernel-based Learning
Methods. Cambridge University Press.
A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maxi-
mum likelihood from incomplete data via the EM algorithm.
Journal of the Royal Statistical Society B, 39:1–38.
R. Ge and R. J. Mooney. 2005. A statistical semantic parser
that integrates syntax and semantics. In Proc. of CoNLL-05,
pages 9–16, Ann Arbor, MI, July.
T. Joachims. 1999. Transductive inference for text classifica-
tion using support vector machines. In Proc. of ICML-99,
pages 200–209, Bled, Slovenia, June.
R. J. Kate and R. J. Mooney. 2006. Using string-kernels for
learning semantic parsers. In Proc. of COLING/ACL-06,
pages 913–920, Sydney, Australia, July.
R. J. Kate, Y. W. Wong, and R. J. Mooney. 2005. Learning to
transform natural to formal languages. In Proc. of AAAI-05,
pages 1062–1068, Pittsburgh, PA, July.
H. Lodhi, C. Saunders, J. Shawe-Taylor, N. Cristianini, and
C. Watkins. 2002. Text classification using string kernels.
Journal of Machine Learning Research, 2:419–444.
L. R. Tang and R. J. Mooney. 2001. Using multiple clause con-
structors in inductive logic programming for semantic pars-
ing. In Proc. of ECML-01, pages 466–477, Freiburg, Ger-
many.
V. N. Vapnik. 1998. Statistical Learning Theory. John Wiley
&amp; Sons.
J. M. Zelle and R. J. Mooney. 1996. Learning to parse database
queries using inductive logic programming. In Proc. of
AAAI-96, pages 1050–1055, Portland, OR, August.
L. S. Zettlemoyer and M. Collins. 2005. Learning to map sen-
tences to logical form: Structured classification with proba-
bilistic categorial grammars. In Proc. of UAI-05, Edinburgh,
Scotland, July.
</reference>
<figure confidence="0.998193714285714">
SEMISUP-KRISP
KRISP
GEOBASE
Best F-measure 100
90
80
70
60
50
40
30
20
10
0
</figure>
<page confidence="0.957175">
84
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.539776">
<title confidence="0.9982145">Semi-Supervised Learning for Semantic using Support Vector Machines</title>
<author confidence="0.999957">Rohit J Kate</author>
<author confidence="0.999957">J Raymond</author>
<affiliation confidence="0.886011">Department of Computer The University of Texas at 1 University Station Austin, TX 78712-0233,</affiliation>
<email confidence="0.999767">rjkate@cs.utexas.edu</email>
<email confidence="0.999767">mooney@cs.utexas.edu</email>
<abstract confidence="0.999672894736842">We present a method for utilizing unannotated sentences to improve a semantic parser which maps natural language (NL) sentences into their formal meaning representations (MRs). Given NL sentences annotated with their MRs, the initial supervised semantic parser learns the mapping by training Support Vector Machine (SVM) classifiers for every production in the MR grammar. Our new method applies the learned semantic parser to the unannotated sentences and collects unlabeled examples which are then used to retrain the classifiers using a variant of Experimental results show the improvements obtained over the purely supervised parser, particularly when the annotated training set is small.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Bennett</author>
<author>A Demiriz</author>
</authors>
<title>Semi-supervised support vector machines.</title>
<date>1999</date>
<booktitle>Advances in Neural Information Processing Systems,</booktitle>
<pages>11--368</pages>
<contexts>
<context position="6733" citStr="Bennett and Demiriz, 1999" startWordPosition="1010" endWordPosition="1014">ch may not always hold, particularly when the training data is small. Chen et al. (2003) present another approximation algorithm which we use in our system because it does not require this assumption. More recently, new optimization methods have been used to scale-up transductive SVMs to large data sets (Collobert et al., 2006), however we did not face scaling problems in our current experiments. Although transductive SVMs were originally designed to improve performance on the test data by utilizing its availability during training, they can also be directly used in a semi-supervised setting (Bennett and Demiriz, 1999) where unlabeled data is available during training that comes from the same distribution as the test data but is not the actual data on which the classifier is eventually to be tested. This framework is more realistic in the context of semantic parsing where sentences must be processed in real-time and it is not practical to re-train the parser transductively for every new test sentence. Instead of using an alternative semi-supervised SVM algorithm, we preferred to use a transductive SVM algorithm (Chen et al., 2003) in a semi-supervised manner, since it is easily implemented on top of an exis</context>
</contexts>
<marker>Bennett, Demiriz, 1999</marker>
<rawString>K. Bennett and A. Demiriz. 1999. Semi-supervised support vector machines. Advances in Neural Information Processing Systems, 11:368–374.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Borland International</author>
</authors>
<title>Turbo Prolog 2.0 Reference Guide.</title>
<date>1988</date>
<publisher>Borland International,</publisher>
<location>Scotts Valley, CA.</location>
<contexts>
<context position="12152" citStr="International, 1988" startWordPosition="1883" endWordPosition="1884">ure (harmonic mean of precision and re83 0 20 40 60 80 100 120 140 160 180 200 220 240 No. of annotated training sentences Figure 2: Learning curves for the best F-measures on the GEOQUERY corpus. call) obtained across the precision-recall trade-off as the amount of annotated training data is increased. Figure 2 shows the results for both systems. The results clearly show the improvement SEMISUP-KRISP obtains over KRISP by utilizing unannotated sentences, particularly when the number of annotated sentences is small. We also show the performance of a hand-built semantic parser GEOBASE (Borland International, 1988) for comparison. From the figure, it can be seen that, on average, KRISP achieves the same performance as GEOBASE when it is given126annotated examples, while SEMISUP-KRISP reaches this level given only 94annotated examples, a25.4%savings in humanannotation effort. 5 Conclusions This paper has presented a semi-supervised approach to semantic parsing. Our method utilizes unannotated sentences during training by extracting unlabeled examples for the SVM classifiers it uses to perform semantic parsing. These classifiers are then retrained using transductive SVMs. Experimental results demonstrated</context>
</contexts>
<marker>International, 1988</marker>
<rawString>Borland International. 1988. Turbo Prolog 2.0 Reference Guide. Borland International, Scotts Valley, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Chapelle</author>
<author>B Sch¨olkopf</author>
<author>A Zien</author>
<author>editors</author>
</authors>
<title>SemiSupervised Learning.</title>
<date>2006</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Chapelle, Sch¨olkopf, Zien, editors, 2006</marker>
<rawString>O. Chapelle, B. Sch¨olkopf, and A. Zien, editors. 2006. SemiSupervised Learning. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Chen</author>
<author>G Wang</author>
<author>S Dong</author>
</authors>
<title>Learning with progressive transductive support vector machine. Pattern Recognition Letters,</title>
<date>2003</date>
<pages>24--1845</pages>
<contexts>
<context position="6195" citStr="Chen et al. (2003)" startWordPosition="928" endWordPosition="931"> hyperplane that separates the positive and negative examples of both the training and the test data. This is achieved by including variables in the SVM’s objective function representing labels of the test examples. Finding the exact solution to the resulting optimization problem is intractable, however Joachims (1999) gives an approximation algorithm for it. One drawback of his algorithm is that it requires the proportion of positive and negative examples in the test data be close to the proportion in the training data, which may not always hold, particularly when the training data is small. Chen et al. (2003) present another approximation algorithm which we use in our system because it does not require this assumption. More recently, new optimization methods have been used to scale-up transductive SVMs to large data sets (Collobert et al., 2006), however we did not face scaling problems in our current experiments. Although transductive SVMs were originally designed to improve performance on the test data by utilizing its availability during training, they can also be directly used in a semi-supervised setting (Bennett and Demiriz, 1999) where unlabeled data is available during training that comes </context>
</contexts>
<marker>Chen, Wang, Dong, 2003</marker>
<rawString>Y. Chen, G. Wang, and S. Dong. 2003. Learning with progressive transductive support vector machine. Pattern Recognition Letters, 24:1845–1855.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Collobert</author>
<author>F Sinz</author>
<author>J Weston</author>
<author>L Bottou</author>
</authors>
<title>Large scale transductive SVMs.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>7--1687</pages>
<contexts>
<context position="6436" citStr="Collobert et al., 2006" startWordPosition="965" endWordPosition="968">lution to the resulting optimization problem is intractable, however Joachims (1999) gives an approximation algorithm for it. One drawback of his algorithm is that it requires the proportion of positive and negative examples in the test data be close to the proportion in the training data, which may not always hold, particularly when the training data is small. Chen et al. (2003) present another approximation algorithm which we use in our system because it does not require this assumption. More recently, new optimization methods have been used to scale-up transductive SVMs to large data sets (Collobert et al., 2006), however we did not face scaling problems in our current experiments. Although transductive SVMs were originally designed to improve performance on the test data by utilizing its availability during training, they can also be directly used in a semi-supervised setting (Bennett and Demiriz, 1999) where unlabeled data is available during training that comes from the same distribution as the test data but is not the actual data on which the classifier is eventually to be tested. This framework is more realistic in the context of semantic parsing where sentences must be processed in real-time and</context>
</contexts>
<marker>Collobert, Sinz, Weston, Bottou, 2006</marker>
<rawString>R. Collobert, F. Sinz, J. Weston, and L. Bottou. 2006. Large scale transductive SVMs. Journal of Machine Learning Research, 7(Aug):1687–1712.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Cristianini</author>
<author>J Shawe-Taylor</author>
</authors>
<title>An Introduction to Support Vector Machines and Other Kernel-based Learning Methods.</title>
<date>2000</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="3346" citStr="Cristianini and Shawe-Taylor, 2000" startWordPosition="494" endWordPosition="497">ibing our approach to semi-supervised semantic parsing. 2.1 KRISP: The Supervised Semantic Parsing Learning System KRISP (Kernel-based Robust Interpretation for Semantic Parsing) (Kate and Mooney, 2006) is a supervised learning system for semantic parsing which Proceedings of NAACL HLT 2007, Companion Volume, pages 81–84, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics takes NL sentences paired with their MRs as training data. The productions of the formal MRL grammar are treated like semantic concepts. For each of these productions, a Support-Vector Machine (SVM) (Cristianini and Shawe-Taylor, 2000) classifier is trained using string similarity as the kernel (Lodhi et al., 2002). Each classifier can then estimate the probability of any NL substring representing the semantic concept for its production. During semantic parsing, the classifiers are called to estimate probabilities on different substrings of the sentence to compositionally build the most probable meaning representation (MR) of the sentence. KRISP trains the classifiers used in semantic parsing iteratively. In each iteration, for every production7in the MRL grammar, KRISP collects positive and negative examples. In the first </context>
<context position="4858" citStr="Cristianini and Shawe-Taylor, 2000" startWordPosition="722" endWordPosition="725">er is trained for each production7 using a string kernel. In subsequent iterations, the parser learned from the previous iteration is applied to the training examples and more refined positive and negative examples, which are more specific substrings within the sentences, are collected for training. Iterations are continued until the classifiers converge, analogous to iterations in EM (Dempster et al., 1977). Experimentally, KRISP compares favorably to other existing semantic parsing systems and is particularly robust to noisy training data (Kate and Mooney, 2006). 2.2 Transductive SVMs SVMs (Cristianini and Shawe-Taylor, 2000) are state-of-the-art machine learning methods for classification. Given positive and negative training examples in some vector space, an SVM finds the maximum-margin hyperplane which separates them. Maximizing the margin prevents over-fitting in very high-dimensional data which is typical in natural language processing and thus leads to better generalization performance on test examples. When the unlabeled test examples are also available during training, a transductive framework for learning (Vapnik, 1998) can further improve the performance on the test examples. Transductive SVMs were intro</context>
</contexts>
<marker>Cristianini, Shawe-Taylor, 2000</marker>
<rawString>N. Cristianini and J. Shawe-Taylor. 2000. An Introduction to Support Vector Machines and Other Kernel-based Learning Methods. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A P Dempster</author>
<author>N M Laird</author>
<author>D B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society B,</journal>
<pages>39--1</pages>
<contexts>
<context position="4634" citStr="Dempster et al., 1977" startWordPosition="691" endWordPosition="694">l sentences whose corresponding MRs use the production7in their parse trees. The set of negative examples includes all of the other training sentences. Using these positive and negative examples, an SVM classifier is trained for each production7 using a string kernel. In subsequent iterations, the parser learned from the previous iteration is applied to the training examples and more refined positive and negative examples, which are more specific substrings within the sentences, are collected for training. Iterations are continued until the classifiers converge, analogous to iterations in EM (Dempster et al., 1977). Experimentally, KRISP compares favorably to other existing semantic parsing systems and is particularly robust to noisy training data (Kate and Mooney, 2006). 2.2 Transductive SVMs SVMs (Cristianini and Shawe-Taylor, 2000) are state-of-the-art machine learning methods for classification. Given positive and negative training examples in some vector space, an SVM finds the maximum-margin hyperplane which separates them. Maximizing the margin prevents over-fitting in very high-dimensional data which is typical in natural language processing and thus leads to better generalization performance on</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society B, 39:1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Ge</author>
<author>R J Mooney</author>
</authors>
<title>A statistical semantic parser that integrates syntax and semantics.</title>
<date>2005</date>
<booktitle>In Proc. of CoNLL-05,</booktitle>
<pages>9--16</pages>
<location>Ann Arbor, MI,</location>
<contexts>
<context position="1741" citStr="Ge and Mooney, 2005" startWordPosition="262" endWordPosition="265"> which a computer program can execute to perform some task, like answering database queries or controlling a robot. These MRs are expressed in domain-specific unambiguous formal meaning representation languages (MRLs). Given a training corpus of NL sentences annotated with their correct MRs, the goal of a learning system for semantic parsing is to induce an efficient and accurate semantic parser that can map novel sentences into their correct MRs. 81 Several learning systems have been developed for semantic parsing, many of them recently (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Ge and Mooney, 2005; Kate and Mooney, 2006). These systems use supervised learning methods which only utilize annotated NL sentences. However, it requires considerable human effort to annotate sentences. In contrast, unannotated NL sentences are usually easily available. Semi-supervised learning methods utilize cheaply available unannotated data during training along with annotated data and often perform better than purely supervised learning methods trained on the same amount of annotated data (Chapelle et al., 2006). In this paper we present, to our knowledge, the first semi-supervised learning system for sema</context>
</contexts>
<marker>Ge, Mooney, 2005</marker>
<rawString>R. Ge and R. J. Mooney. 2005. A statistical semantic parser that integrates syntax and semantics. In Proc. of CoNLL-05, pages 9–16, Ann Arbor, MI, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Transductive inference for text classification using support vector machines.</title>
<date>1999</date>
<booktitle>In Proc. of ICML-99,</booktitle>
<pages>200--209</pages>
<location>Bled, Slovenia,</location>
<contexts>
<context position="5483" citStr="Joachims, 1999" startWordPosition="814" endWordPosition="815">-of-the-art machine learning methods for classification. Given positive and negative training examples in some vector space, an SVM finds the maximum-margin hyperplane which separates them. Maximizing the margin prevents over-fitting in very high-dimensional data which is typical in natural language processing and thus leads to better generalization performance on test examples. When the unlabeled test examples are also available during training, a transductive framework for learning (Vapnik, 1998) can further improve the performance on the test examples. Transductive SVMs were introduced in (Joachims, 1999). The key idea is to find the labeling of the test examples that results in the maximum-margin hyperplane that separates the positive and negative examples of both the training and the test data. This is achieved by including variables in the SVM’s objective function representing labels of the test examples. Finding the exact solution to the resulting optimization problem is intractable, however Joachims (1999) gives an approximation algorithm for it. One drawback of his algorithm is that it requires the proportion of positive and negative examples in the test data be close to the proportion i</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>T. Joachims. 1999. Transductive inference for text classification using support vector machines. In Proc. of ICML-99, pages 200–209, Bled, Slovenia, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Kate</author>
<author>R J Mooney</author>
</authors>
<title>Using string-kernels for learning semantic parsers.</title>
<date>2006</date>
<booktitle>In Proc. of COLING/ACL-06,</booktitle>
<pages>913--920</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="1765" citStr="Kate and Mooney, 2006" startWordPosition="266" endWordPosition="269">gram can execute to perform some task, like answering database queries or controlling a robot. These MRs are expressed in domain-specific unambiguous formal meaning representation languages (MRLs). Given a training corpus of NL sentences annotated with their correct MRs, the goal of a learning system for semantic parsing is to induce an efficient and accurate semantic parser that can map novel sentences into their correct MRs. 81 Several learning systems have been developed for semantic parsing, many of them recently (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Ge and Mooney, 2005; Kate and Mooney, 2006). These systems use supervised learning methods which only utilize annotated NL sentences. However, it requires considerable human effort to annotate sentences. In contrast, unannotated NL sentences are usually easily available. Semi-supervised learning methods utilize cheaply available unannotated data during training along with annotated data and often perform better than purely supervised learning methods trained on the same amount of annotated data (Chapelle et al., 2006). In this paper we present, to our knowledge, the first semi-supervised learning system for semantic parsing. We modify </context>
<context position="4793" citStr="Kate and Mooney, 2006" startWordPosition="714" endWordPosition="717">hese positive and negative examples, an SVM classifier is trained for each production7 using a string kernel. In subsequent iterations, the parser learned from the previous iteration is applied to the training examples and more refined positive and negative examples, which are more specific substrings within the sentences, are collected for training. Iterations are continued until the classifiers converge, analogous to iterations in EM (Dempster et al., 1977). Experimentally, KRISP compares favorably to other existing semantic parsing systems and is particularly robust to noisy training data (Kate and Mooney, 2006). 2.2 Transductive SVMs SVMs (Cristianini and Shawe-Taylor, 2000) are state-of-the-art machine learning methods for classification. Given positive and negative training examples in some vector space, an SVM finds the maximum-margin hyperplane which separates them. Maximizing the margin prevents over-fitting in very high-dimensional data which is typical in natural language processing and thus leads to better generalization performance on test examples. When the unlabeled test examples are also available during training, a transductive framework for learning (Vapnik, 1998) can further improve t</context>
</contexts>
<marker>Kate, Mooney, 2006</marker>
<rawString>R. J. Kate and R. J. Mooney. 2006. Using string-kernels for learning semantic parsers. In Proc. of COLING/ACL-06, pages 913–920, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Kate</author>
<author>Y W Wong</author>
<author>R J Mooney</author>
</authors>
<title>Learning to transform natural to formal languages.</title>
<date>2005</date>
<booktitle>In Proc. of AAAI-05,</booktitle>
<pages>1062--1068</pages>
<location>Pittsburgh, PA,</location>
<contexts>
<context position="10304" citStr="Kate et al., 2005" startWordPosition="1588" endWordPosition="1591">om parsing the unannotated sentences do not play a role during training since it is unknown whether or not they are correct. These sets of unlabeled examples for each production, along with the sets of positive and negative examples collected earlier, are then used to retrain the classifiers using transductive SVMs. The retrained classifiers are finally returned and used in the final semantic parser. 4 Experiments We compared the performance of SEMISUP-KRISP and KRISP in the GEOQUERY domain for semantic parsing in which the MRL is a functional language used to query a U.S. geography database (Kate et al., 2005). This domain has been used in most of the previous work. The original corpus contains250 NL queries collected from undergraduate students and annotated with their correct MRs (Zelle and Mooney, 1996). Later,630additional NL queries were collected from real users of a web-based interface and annotated (Tang and Mooney, 2001). We used this data as unannotated sentences in our current experiments. We also collected an additional 407queries from the same interface, making a total of1,037unannotated sentences. The systems were evaluated using standard 10- fold cross validation. All the unannotated</context>
</contexts>
<marker>Kate, Wong, Mooney, 2005</marker>
<rawString>R. J. Kate, Y. W. Wong, and R. J. Mooney. 2005. Learning to transform natural to formal languages. In Proc. of AAAI-05, pages 1062–1068, Pittsburgh, PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Lodhi</author>
<author>C Saunders</author>
<author>J Shawe-Taylor</author>
<author>N Cristianini</author>
<author>C Watkins</author>
</authors>
<title>Text classification using string kernels.</title>
<date>2002</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>2--419</pages>
<contexts>
<context position="3427" citStr="Lodhi et al., 2002" startWordPosition="508" endWordPosition="511">g Learning System KRISP (Kernel-based Robust Interpretation for Semantic Parsing) (Kate and Mooney, 2006) is a supervised learning system for semantic parsing which Proceedings of NAACL HLT 2007, Companion Volume, pages 81–84, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics takes NL sentences paired with their MRs as training data. The productions of the formal MRL grammar are treated like semantic concepts. For each of these productions, a Support-Vector Machine (SVM) (Cristianini and Shawe-Taylor, 2000) classifier is trained using string similarity as the kernel (Lodhi et al., 2002). Each classifier can then estimate the probability of any NL substring representing the semantic concept for its production. During semantic parsing, the classifiers are called to estimate probabilities on different substrings of the sentence to compositionally build the most probable meaning representation (MR) of the sentence. KRISP trains the classifiers used in semantic parsing iteratively. In each iteration, for every production7in the MRL grammar, KRISP collects positive and negative examples. In the first iteration, the set of positive examples for production7contains all sentences who</context>
</contexts>
<marker>Lodhi, Saunders, Shawe-Taylor, Cristianini, Watkins, 2002</marker>
<rawString>H. Lodhi, C. Saunders, J. Shawe-Taylor, N. Cristianini, and C. Watkins. 2002. Text classification using string kernels. Journal of Machine Learning Research, 2:419–444.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Tang</author>
<author>R J Mooney</author>
</authors>
<title>Using multiple clause constructors in inductive logic programming for semantic parsing.</title>
<date>2001</date>
<booktitle>In Proc. of ECML-01,</booktitle>
<pages>466--477</pages>
<location>Freiburg, Germany.</location>
<contexts>
<context position="10630" citStr="Tang and Mooney, 2001" startWordPosition="1638" endWordPosition="1641">retrained classifiers are finally returned and used in the final semantic parser. 4 Experiments We compared the performance of SEMISUP-KRISP and KRISP in the GEOQUERY domain for semantic parsing in which the MRL is a functional language used to query a U.S. geography database (Kate et al., 2005). This domain has been used in most of the previous work. The original corpus contains250 NL queries collected from undergraduate students and annotated with their correct MRs (Zelle and Mooney, 1996). Later,630additional NL queries were collected from real users of a web-based interface and annotated (Tang and Mooney, 2001). We used this data as unannotated sentences in our current experiments. We also collected an additional 407queries from the same interface, making a total of1,037unannotated sentences. The systems were evaluated using standard 10- fold cross validation. All the unannotated sentences were used for training in each fold. Performance was measured in terms of precision (the percentage of generated MRs that were correct) and recall (the percentage of all sentences for which correct MRs were obtained). An output MR is considered correct if and only if the resulting query retrieves the same answer a</context>
</contexts>
<marker>Tang, Mooney, 2001</marker>
<rawString>L. R. Tang and R. J. Mooney. 2001. Using multiple clause constructors in inductive logic programming for semantic parsing. In Proc. of ECML-01, pages 466–477, Freiburg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V N Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>John Wiley &amp; Sons.</publisher>
<contexts>
<context position="5371" citStr="Vapnik, 1998" startWordPosition="798" endWordPosition="799">aining data (Kate and Mooney, 2006). 2.2 Transductive SVMs SVMs (Cristianini and Shawe-Taylor, 2000) are state-of-the-art machine learning methods for classification. Given positive and negative training examples in some vector space, an SVM finds the maximum-margin hyperplane which separates them. Maximizing the margin prevents over-fitting in very high-dimensional data which is typical in natural language processing and thus leads to better generalization performance on test examples. When the unlabeled test examples are also available during training, a transductive framework for learning (Vapnik, 1998) can further improve the performance on the test examples. Transductive SVMs were introduced in (Joachims, 1999). The key idea is to find the labeling of the test examples that results in the maximum-margin hyperplane that separates the positive and negative examples of both the training and the test data. This is achieved by including variables in the SVM’s objective function representing labels of the test examples. Finding the exact solution to the resulting optimization problem is intractable, however Joachims (1999) gives an approximation algorithm for it. One drawback of his algorithm is</context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>V. N. Vapnik. 1998. Statistical Learning Theory. John Wiley &amp; Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Zelle</author>
<author>R J Mooney</author>
</authors>
<title>Learning to parse database queries using inductive logic programming.</title>
<date>1996</date>
<booktitle>In Proc. of AAAI-96,</booktitle>
<pages>1050--1055</pages>
<location>Portland, OR,</location>
<contexts>
<context position="1689" citStr="Zelle and Mooney, 1996" startWordPosition="254" endWordPosition="257">nce into a complete, formal meaning representation (MR) which a computer program can execute to perform some task, like answering database queries or controlling a robot. These MRs are expressed in domain-specific unambiguous formal meaning representation languages (MRLs). Given a training corpus of NL sentences annotated with their correct MRs, the goal of a learning system for semantic parsing is to induce an efficient and accurate semantic parser that can map novel sentences into their correct MRs. 81 Several learning systems have been developed for semantic parsing, many of them recently (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Ge and Mooney, 2005; Kate and Mooney, 2006). These systems use supervised learning methods which only utilize annotated NL sentences. However, it requires considerable human effort to annotate sentences. In contrast, unannotated NL sentences are usually easily available. Semi-supervised learning methods utilize cheaply available unannotated data during training along with annotated data and often perform better than purely supervised learning methods trained on the same amount of annotated data (Chapelle et al., 2006). In this paper we present, to our knowledge</context>
<context position="10504" citStr="Zelle and Mooney, 1996" startWordPosition="1619" endWordPosition="1622">ets of positive and negative examples collected earlier, are then used to retrain the classifiers using transductive SVMs. The retrained classifiers are finally returned and used in the final semantic parser. 4 Experiments We compared the performance of SEMISUP-KRISP and KRISP in the GEOQUERY domain for semantic parsing in which the MRL is a functional language used to query a U.S. geography database (Kate et al., 2005). This domain has been used in most of the previous work. The original corpus contains250 NL queries collected from undergraduate students and annotated with their correct MRs (Zelle and Mooney, 1996). Later,630additional NL queries were collected from real users of a web-based interface and annotated (Tang and Mooney, 2001). We used this data as unannotated sentences in our current experiments. We also collected an additional 407queries from the same interface, making a total of1,037unannotated sentences. The systems were evaluated using standard 10- fold cross validation. All the unannotated sentences were used for training in each fold. Performance was measured in terms of precision (the percentage of generated MRs that were correct) and recall (the percentage of all sentences for which</context>
</contexts>
<marker>Zelle, Mooney, 1996</marker>
<rawString>J. M. Zelle and R. J. Mooney. 1996. Learning to parse database queries using inductive logic programming. In Proc. of AAAI-96, pages 1050–1055, Portland, OR, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L S Zettlemoyer</author>
<author>M Collins</author>
</authors>
<title>Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars.</title>
<date>2005</date>
<booktitle>In Proc. of UAI-05,</booktitle>
<location>Edinburgh, Scotland,</location>
<contexts>
<context position="1720" citStr="Zettlemoyer and Collins, 2005" startWordPosition="258" endWordPosition="261">mal meaning representation (MR) which a computer program can execute to perform some task, like answering database queries or controlling a robot. These MRs are expressed in domain-specific unambiguous formal meaning representation languages (MRLs). Given a training corpus of NL sentences annotated with their correct MRs, the goal of a learning system for semantic parsing is to induce an efficient and accurate semantic parser that can map novel sentences into their correct MRs. 81 Several learning systems have been developed for semantic parsing, many of them recently (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Ge and Mooney, 2005; Kate and Mooney, 2006). These systems use supervised learning methods which only utilize annotated NL sentences. However, it requires considerable human effort to annotate sentences. In contrast, unannotated NL sentences are usually easily available. Semi-supervised learning methods utilize cheaply available unannotated data during training along with annotated data and often perform better than purely supervised learning methods trained on the same amount of annotated data (Chapelle et al., 2006). In this paper we present, to our knowledge, the first semi-supervised lea</context>
</contexts>
<marker>Zettlemoyer, Collins, 2005</marker>
<rawString>L. S. Zettlemoyer and M. Collins. 2005. Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars. In Proc. of UAI-05, Edinburgh, Scotland, July.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>