<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.986556">
The Infinite Tree
</title>
<author confidence="0.988788">
Jenny Rose Finkel, Trond Grenager, and Christopher D. Manning
</author>
<affiliation confidence="0.985899">
Computer Science Department, Stanford University
</affiliation>
<address confidence="0.817651">
Stanford, CA 94305
</address>
<email confidence="0.982165">
{jrfinkel, grenager, manning}@cs.stanford.edu
</email>
<sectionHeader confidence="0.993709" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999922208333333">
Historically, unsupervised learning tech-
niques have lacked a principled technique
for selecting the number of unseen compo-
nents. Research into non-parametric priors,
such as the Dirichlet process, has enabled in-
stead the use of infinite models, in which the
number of hidden categories is not fixed, but
can grow with the amount of training data.
Here we develop the infinite tree, a new infi-
nite model capable of representing recursive
branching structure over an arbitrarily large
set of hidden categories. Specifically, we
develop three infinite tree models, each of
which enforces different independence as-
sumptions, and for each model we define a
simple direct assignment sampling inference
procedure. We demonstrate the utility of
our models by doing unsupervised learning
of part-of-speech tags from treebank depen-
dency skeleton structure, achieving an accu-
racy of 75.34%, and by doing unsupervised
splitting of part-of-speech tags, which in-
creases the accuracy of a generative depen-
dency parser from 85.11% to 87.35%.
</bodyText>
<sectionHeader confidence="0.999125" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999901333333333">
Model-based unsupervised learning techniques have
historically lacked good methods for choosing the
number of unseen components. For example, k-
means or EM clustering require advance specifica-
tion of the number of mixture components. But
the introduction of nonparametric priors such as the
Dirichlet process (Ferguson, 1973) enabled develop-
ment of infinite mixture models, in which the num-
ber of hidden components is not fixed, but emerges
naturally from the training data (Antoniak, 1974).
Teh et al. (2006) proposed the hierarchical Dirich-
let process (HDP) as a way of applying the Dirichlet
process (DP) to more complex model forms, so as to
allow multiple, group-specific, infinite mixture mod-
els to share their mixture components. The closely
related infinite hidden Markov model is an HMM
in which the transitions are modeled using an HDP,
enabling unsupervised learning of sequence models
when the number of hidden states is unknown (Beal
et al., 2002; Teh et al., 2006).
We extend this work by introducing the infinite
tree model, which represents recursive branching
structure over a potentially infinite set of hidden
states. Such models are appropriate for the syntactic
dependency structure of natural language. The hid-
den states represent word categories (“tags”), the ob-
servations they generate represent the words them-
selves, and the tree structure represents syntactic de-
pendencies between pairs of tags.
To validate the model, we test unsupervised learn-
ing of tags conditioned on a given dependency tree
structure. This is useful, because coarse-grained
syntactic categories, such as those used in the Penn
Treebank (PTB), make insufficient distinctions to be
the basis of accurate syntactic parsing (Charniak,
1996). Hence, state-of-the-art parsers either supple-
ment the part-of-speech (POS) tags with the lexical
forms themselves (Collins, 2003; Charniak, 2000),
manually split the tagset into a finer-grained one
(Klein and Manning, 2003a), or learn finer grained
tag distinctions using a heuristic learning procedure
(Petrov et al., 2006). We demonstrate that the tags
learned with our model are correlated with the PTB
POS tags, and furthermore that they improve the ac-
curacy of an automatic parser when used in training.
</bodyText>
<sectionHeader confidence="0.991269" genericHeader="introduction">
2 Finite Trees
</sectionHeader>
<bodyText confidence="0.999608">
We begin by presenting three finite tree models, each
with different independence assumptions.
</bodyText>
<page confidence="0.948595">
272
</page>
<note confidence="0.9594875">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 272–279,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<figureCaption confidence="0.99287475">
Figure 1: A graphical representation of the finite
Bayesian tree model with independent children. The
plate (rectangle) indicates that there is one copy of
the model parameter variables for each state k ≤ C.
</figureCaption>
<subsectionHeader confidence="0.835263">
2.1 Independent Children
</subsectionHeader>
<bodyText confidence="0.999993714285714">
In the first model, children are generated indepen-
dently of each other, conditioned on the parent. Let
t denote both the tree and its root node, c(t) the list
of children of t, ci(t) the ith child of t, and p(t) the
parent of t. Each tree t has a hidden state zt (in a syn-
tax tree, the tag) and an observation xt (the word).1
The probability of a tree is given by the recursive
</bodyText>
<equation confidence="0.938169333333333">
definition:2
11
Ptr(t) = P(xt|zt) t′∈c(t) P(zt′|zt)Ptr(t′)
</equation>
<bodyText confidence="0.9999655">
To make the model Bayesian, we must define ran-
dom variables to represent each of the model’s pa-
rameters, and specify prior distributions for them.
Let each of the hidden state variables have C possi-
ble values which we will index with k. Each state k
has a distinct distribution over observations, param-
eterized by φk, which is distributed according to a
prior distribution over the parameters H:
</bodyText>
<equation confidence="0.751004">
φk|H ∼ H
</equation>
<bodyText confidence="0.999904375">
We generate each observation xt from some distri-
bution F(φzt) parameterized by φzt specific to its
corresponding hidden state zt. If F(φk)s are multi-
nomials, then a natural choice for H would be a
Dirichlet distribution.3
The hidden state zt′ of each child is distributed
according to a multinomial distribution πzt specific
to the hidden state zt of the parent:
</bodyText>
<equation confidence="0.5926265">
xt|zt ∼ F(φzt)
zt′|zt ∼ Multinomial(πzt)
</equation>
<footnote confidence="0.991902428571429">
1To model length, every child list ends with a distinguished
stop node, which has as its state a distinguished stop state.
2We also define a distinguished node to, which generates the
root of the entire tree, and P(xt0|zt0) = 1.
3A Dirichlet distribution is a distribution over the possible
parameters of a multinomial distributions, and is distinct from
the Dirichlet process.
</footnote>
<bodyText confidence="0.890953">
Each multinomial over children 7rk is distributed ac-
cording to a Dirichlet distribution with parameter ρ:
</bodyText>
<equation confidence="0.924689">
7rk|ρ ∼ Dirichlet(ρ, ... , ρ)
</equation>
<bodyText confidence="0.607814">
This model is presented graphically in Figure 1.
</bodyText>
<subsectionHeader confidence="0.998145">
2.2 Simultaneous Children
</subsectionHeader>
<bodyText confidence="0.998413333333333">
The independent child model adopts strong indepen-
dence assumptions, and we may instead want mod-
els in which the children are conditioned on more
than just the parent’s state. Our second model thus
generates the states of all of the children c(t) simul-
taneously:
</bodyText>
<equation confidence="0.884968">
11 Ptr(t) = P(xt|zt)P((zt′)t′∈c(t)|zt) t′∈c(t) Ptr(t′)
</equation>
<bodyText confidence="0.99978075">
where (zt′)t′∈c(t) indicates the list of tags of the chil-
dren of t. To parameterize this model, we replace the
multinomial distribution 7rk over states with a multi-
nomial distribution Ak over lists of states.4
</bodyText>
<subsectionHeader confidence="0.999025">
2.3 Markov Children
</subsectionHeader>
<bodyText confidence="0.997212333333333">
The very large domain size of the child lists in the
simultaneous child model may cause problems of
sparse estimation. Another alternative is to use a
first-order Markov process to generate children, in
which each child’s state is conditioned on the previ-
ous child’s state:
</bodyText>
<equation confidence="0.9461915">
11|c(t)|
Ptr(t) = P(xt|zt) i=1 P(zcz(t)|zcz−,(t),zt)Ptr(t′)
</equation>
<bodyText confidence="0.9999425">
For this model, we augment all child lists with a dis-
tinguished start node, c0(t), which has as its state
a distinguished start state, allowing us to capture
the unique behavior of the first (observed) child. To
parameterize this model, note that we will need to
define C(C + 1) multinomials, one for each parent
state and preceding child state (or a distinguished
start state).
</bodyText>
<sectionHeader confidence="0.967348" genericHeader="method">
3 To Infinity, and Beyond ...
</sectionHeader>
<bodyText confidence="0.9994775">
This section reviews needed background material
for our approach to making our tree models infinite.
</bodyText>
<subsectionHeader confidence="0.998498">
3.1 The Dirichlet Process
</subsectionHeader>
<bodyText confidence="0.99768925">
Suppose we model a document as a bag of words
produced by a mixture model, where the mixture
components might be topics such as business, pol-
itics, sports, etc. Using this model we can generate a
</bodyText>
<footnote confidence="0.484347">
4This requires stipulating a maximum list length.
</footnote>
<equation confidence="0.985123875">
H
ρ
7rk
φk
C
x1 x2 x3
z1
z2 z3
</equation>
<page confidence="0.997946">
273
</page>
<figureCaption confidence="0.965825">
Figure 2: Plot of the density function of a Dirich-
</figureCaption>
<bodyText confidence="0.989412611111111">
let distribution H (the surface) as well as a draw
G (the vertical lines, or sticks) from a Dirichlet
process DP(α0, H) which has H as a base mea-
sure. Both distributions are defined over a sim-
plex in which each point corresponds to a particular
multinomial distribution over three possible words:
“profit”, “game”, and “election”. The placement of
the sticks is drawn from the distribution H, and is
independent of their lengths, which is drawn from a
stick-breaking process with parameter α0.
document by first generating a distribution over top-
ics 7r, and then for each position i in the document,
generating a topic zi from 7r, and then a word xi
from the topic specific distribution φzi. The word
distributions φk for each topic k are drawn from a
base distribution H. In Section 2, we sample C
multinomials φk from H. In the infinite mixture
model we sample an infinite number of multinomi-
als from H, using the Dirichlet process.
Formally, given a base distribution H and a con-
centration parameter α0 (loosely speaking, this con-
trols the relative sizes of the topics), a Dirichlet pro-
cess DP(α0, H) is the distribution of a discrete ran-
dom probability measure G over the same (possibly
continuous) space that H is defined over; thus it is a
measure over measures. In Figure 2, the sticks (ver-
tical lines) show a draw G from a Dirichlet process
where the base measure H is a Dirichlet distribution
over 3 words. A draw comprises of an infinite num-
ber of sticks, and each corresponding topic.
We factor G into two coindexed distributions: 7r,
a distribution over the integers, where the integer
represents the index of a particular topic (i.e., the
height of the sticks in the figure represent the proba-
bility of the topic indexed by that stick) and 0, rep-
resenting the word distribution of each of the top-
</bodyText>
<figure confidence="0.978315">
(a) (b)
</figure>
<figureCaption confidence="0.997959">
Figure 3: A graphical representation of a simple
</figureCaption>
<bodyText confidence="0.995993111111111">
Dirichlet process mixture model (left) and a hierar-
chical Dirichlet process model (right). Note that we
show the stick-breaking representations of the mod-
els, in which we have factored G — DP(α0, H) into
two sets of variables: π and φ.
ics (i.e., the location of the sticks in the figure). To
generate 7r we first generate an infinite sequence of
variables 7r′ = (π′k)∞k=1, each of which is distributed
according to the Beta distribution:
</bodyText>
<equation confidence="0.9980462">
π′k|α0 — Beta(1, α0)
Then 7r = (πk)∞k=1 is defined as:
�k−1
πk = πk (1 — π′i )
i=1
</equation>
<bodyText confidence="0.999882933333333">
Following Pitman (2002) we refer to this process as
π — GEM(α0). It should be noted that E∞k=1 πk =
1,5 and P(i) = πi. Then, according to the DP,
P(φi) = πi. The complete model, is shown graphi-
cally in Figure 3(a).
To build intuition, we walk through the process of
generating from the infinite mixture model for the
document example, where xi is the word at posi-
tion i, and zi is its topic. F is a multinomial dis-
tribution parameterized by 0, and H is a Dirichlet
distribution. Instead of generating all of the infinite
mixture components (πk)∞k=1 at once, we can build
them up incrementally. If there are K known top-
ics, we represent only the known elements (πk)�k=1
and represent the remaining probability mass π,, =
</bodyText>
<footnote confidence="0.5596752">
5This is called the stick-breaking construction: we start with
a stick of unit length, representing the entire probability mass,
and successively break bits off the end of the stick, where the
proportional amount broken off is represented by ir′k and the
absolute amount is represented by irk.
</footnote>
<figure confidence="0.98953171875">
0
0
P(xi = &amp;quot;profit&amp;quot;)
P(xi = &amp;quot;game&amp;quot;)
1
0.8
0.6
0.4
0.2
1
0.8
0.6
0.4
0.2
xji
zji
7rj
)3 H
γ α0
N
φk
00
α0 H
7r φk
00
zi
7r|α0 ∼ GEM(α0)
Ok|H ∼ H
zi|7r ∼ 7r /,�//,,
xi|zi, 0 ∼ F(O.J
xi
N
</figure>
<page confidence="0.787403">
274
</page>
<figureCaption confidence="0.82299325">
Figure 4: A graphical representation of πj, a broken
stick, which is distributed according to a DP with a
broken stick β as a base measure. Each βk corre-
sponds to a φk.
</figureCaption>
<equation confidence="0.890551">
1 − (EKk=1 πk). Initially we have πu = 1 and
φ = ().
</equation>
<bodyText confidence="0.998829">
For the ith position in the document, we first draw
a topic zi ∼ π. If zi =6 u, then we find the coin-
dexed topic φzi. If zi = u, the unseen topic, we
make a draw b ∼ Beta(1, α0) and set πK+1 = bπu
</bodyText>
<equation confidence="0.880918">
andπnew
u = (1 − b)πu. Then we draw a parame-
ter φK+1 ∼ H for the new topic, resulting in π =
(π1, ... , πK+1, πnew
</equation>
<bodyText confidence="0.996150529411765">
u ) and φ = (φ1, ... ,φK+1). A
word is then drawn from this topic and emitted by
the document.
generalize our previous example to a corpus
of documents. As before, we have a set of shared
topics, but now each document has its own charac-
teristic distribution over these topics. We represent
topic distributions both locally (for each document)
and globally (across all documents) by use of a hier-
archical Dirichlet process (HDP), which has a local
DP for each document, in which the base measure is
itself a draw from another, global, DP.
The complete HDP model is represented graphi-
cally in Figure 3(b). Like the DP, it has global bro-
ken stick
=
and topic specific word dis-
</bodyText>
<equation confidence="0.535159">
tribution parameters
=
which are coin-
</equation>
<bodyText confidence="0.776238">
dexed. It differs from the DP in that it also has lo-
cal broken sticks
for each group j (in our case
documents). While the global stick
is generated as before, the local sticks
are dis-
tributed according to a DP with base measure
We illustrate this generation process in Figure 4.
The upper unit line represents
where the size of
segment k represents the value of element
and
the lower unit line represents
</bodyText>
<subsectionHeader confidence="0.391802">
for a
</subsectionHeader>
<bodyText confidence="0.6843325">
particular group j. Each element of the lower stick
was sampled from a part
</bodyText>
<equation confidence="0.975475583333333">
Let’s
β
(βk)∞k=1
φ
(φk)∞k=1,
πj
β∼GEM(γ)
πj
β:πj ∼ DP(α0, β).
β,
βk,
πj∼DP(α0,β)
</equation>
<bodyText confidence="0.98775575">
icular element of the upper
275 stick, and elements of the upper stick may be sam-
pled multiple times or not at all; on average, larger
elements will be sampled more often. Each element
as well as all elements of
that were sampled
from it, corresponds to a particular
Critically,
several distinct
can be sampled from the same
and hence share
this is how components are
shared among groups.
For concreteness, we show how to generate a cor-
pus of documents from the HDP, generating one
document at a time, and incrementally construct-
ing our infinite objects. Initially we have
= 1,
=
and
= 1 for all j. We start with the
first position of the first document and draw a local
topic
which will return u with probabil-
ity 1. Because y11 = u we must make a draw from
the base measure,
which, because this is the first
document, will also return u with probability 1. We
must now break
into
and
and break
into
and
in the same manner presented for
the DP. Since
now corresponds to global topic
1, we sample the word x11
To
sample each subsequent word i, we first sample the
local topic
If
u, and
corre-
sponds to
word
document j, while
βk,
</bodyText>
<figure confidence="0.961866296296296">
πj
φk.
πj
βk
φk;
βu
φ
(),
πju
y11∼π1,
β,
βu
β1
βnew
u ,
π1u
π11
πnew
1u
π11
∼Multinomial(φ1).
y1i∼π1.
y1i=6
π1y1i
βk
x1i∼Multinomial(φk).
πju
</figure>
<bodyText confidence="0.962402666666667">
β continues to grow as more doc-
uments are sampled.
om Section 2.
</bodyText>
<subsectionHeader confidence="0.999274">
3.2 The Hierarchical Dirichlet Process
</subsectionHeader>
<bodyText confidence="0.9987588">
in the global stick, then we sample the
Once the first docu-
ment has been sampled, subsequent documents are
sampled in a similar manner; initially
= 1 for
</bodyText>
<sectionHeader confidence="0.999447" genericHeader="method">
4 Infinite Trees
</sectionHeader>
<bodyText confidence="0.999941">
We now use the techniques from Section 3 to create
infinite versions of each tree model fr
</bodyText>
<subsectionHeader confidence="0.976682">
4.1 Independent Children
</subsectionHeader>
<bodyText confidence="0.890006291666667">
The changes required to make the Bayesian inde-
pendent children model infinite
affect its ba-
sic structure, as can be witnessed by comparing the
graphical depiction of the infinite model in Figure 5
with that of the finite model in Figure 1. The in-
stance variables zt and xt are parameterized as be-
fore. The primary change is that the number of
copies of the state plate is infinite, as are the number
of variables
and
Note also that each distribution over possible
child states
must also be infinite, since the num-
ber of possible child states is potentially infinite. We
achieve this by representing each of the
variables
as a broken stick, an
don’t
πk
φk.
πk
πk
d adopt the same approach of
</bodyText>
<equation confidence="0.764417714285714">
φ1 φ2 φ3 φ4 φ5 φ6 φ7 . . .
β :
πj :
. . .
&apos;y β
α0 πk
H Ok
00
x1 x2 x3
z1
z2 z3
β|7 ∼ GEM(7)
πk|α0, β ∼ DP(α0, β)
0k|H ∼ H
</equation>
<figureCaption confidence="0.9901395">
Figure 5: A graphical representation of the infinite
independent child model.
</figureCaption>
<bodyText confidence="0.9995822">
sampling each πk from a DP with base measure β.
For the dependency tree application, Ok is a vector
representing the parameters of a multinomial over
words, and H is a Dirichlet distribution.
The infinite hidden Markov model (iHMM) or
HDP-HMM (Beal et al., 2002; Teh et al., 2006) is
a model of sequence data with transitions modeled
by an HDP.6 The iHMM can be viewed as a special
case of this model, where each state (except the stop
state) produces exactly one child.
</bodyText>
<subsectionHeader confidence="0.993296">
4.2 Simultaneous Children
</subsectionHeader>
<bodyText confidence="0.999217555555556">
The key problem in the definition of the simulta-
neous children model is that of defining a distribu-
tion over the lists of children produced by each state,
since each child in the list has as its domain the posi-
tive integers, representing the infinite set of possible
states. Our solution is to construct a distribution Lk
over lists of states from the distribution over individ-
ual states πk. The obvious approach is to sample the
states at each position i.i.d.:
</bodyText>
<equation confidence="0.999465">
�P((zt′)t′∈c(t)|π) _ P(zt′|π) _ � 7rzt′
t′∈c(t) t′∈c(t)
</equation>
<bodyText confidence="0.884794733333333">
However, we want our model to be able to rep-
resent the fact that some child lists, ct, are more
or less probable than the product of the individual
child probabilities would indicate. To address this,
we can sample a state-conditional distribution over
child lists Ak from a DP with Lk as a base measure.
6The original iHMM paper (Beal et al., 2002) predates, and
was the motivation for, the work presented in Teh et al. (2006),
and is the origin of the term hierarchical Dirichlet process.
However, they used the term to mean something slightly differ-
ent than the HDP presented in Teh et al. (2006), and presented a
sampling scheme for inference that was a heuristic approxima-
tion of a Gibbs sampler.
Thus, we augment the basic model given in the pre-
vious section with the variables (, Lk, and Ak:
</bodyText>
<equation confidence="0.997582666666667">
Lk|πk — Deterministic, as described above
Ak|(, Lk — DP((, Lk)
ct|Ak — Ak
</equation>
<bodyText confidence="0.999846555555556">
An important consequence of defining Lk locally
(instead of globally, using β instead of the πks) is
that the model captures not only what sequences of
children a state prefers, but also the individual chil-
dren that state prefers; if a state gives high proba-
bility to some particular sequence of children, then
it is likely to also give high probability to other se-
quences containing those same states, or a subset
thereof.
</bodyText>
<subsectionHeader confidence="0.996758">
4.3 Markov Children
</subsectionHeader>
<bodyText confidence="0.9999495">
In the Markov children model, more copies of the
variable π are needed, because each child state must
be conditioned both on the parent state and on the
state of the preceding child. We use a new set of
variables πki, where π is determined by the par-
ent state k and the state of the preceding sibling i.
Each of the πki is distributed as πk was in the basic
model: πki — DP(α0,β).
</bodyText>
<sectionHeader confidence="0.99945" genericHeader="method">
5 Inference
</sectionHeader>
<bodyText confidence="0.979933875">
Our goal in inference is to draw a sample from the
posterior over assignments of states to observations.
We present an inference procedure for the infinite
tree that is based on Gibbs sampling in the direct
assignment representation, so named because we di-
rectly assign global state indices to observations.7
Before we present the procedure, we define a few
count variables. Recall from Figure 4 that each state
k has a local stick πk, each element of which cor-
responds to an element of β. In our sampling pro-
cedure, we only keep elements of πk and β which
correspond to states observed in the data. We define
the variable mjk to be the number of elements of the
finite observed portion of πk which correspond to Qj
and njk to be the number of observations with state
k whose parent’s state is j.
We also need a few model-specific counts. For the
simultaneous children model we need njz, which is
7We adapt one of the sampling schemes mentioned by Teh
et al. (2006) for use in the iHMM. This paper suggests two
sampling schemes for inference, but does not explicitly present
them. Upon discussion with one of the authors (Y. W. Teh,
2006, p.c.), it became clear that inference using the augmented
representation is much more complicated than initially thought.
</bodyText>
<page confidence="0.995044">
276
</page>
<bodyText confidence="0.999942736842105">
the number of times the state sequence z occurred
as the children of state j. For the Markov chil-
dren model we need the count variable njik which
is the number of observations for a node with state
k whose parent’s state is j and whose previous sib-
ling’s state is i. In all cases we represent marginal
counts using dot-notation, e.g., n·k is the total num-
ber of nodes with state k, regardless of parent.
Our procedure alternates between three distinct
sampling stages: (1) sampling the state assignments
z, (2) sampling the counts mjk, and (3) sampling
the global stick β. The only modification of the pro-
cedure that is required for the different tree mod-
els is the method for computing the probability
of the child state sequence given the parent state
P((zt′)t′∈c(t)|zt), defined separately for each model.
Sampling z. In this stage we sample a state for
each tree node. The probability of node t being as-
signed state k is given by:
</bodyText>
<equation confidence="0.984193">
P(zt = k|z−t,β) ∝ P(zt = k, (zt′)t′∈s(t)|zp(t))
· P((zt′)t′∈c(t)|zt = k) · f−xt
k (xt)
</equation>
<bodyText confidence="0.9846574">
where s(t) denotes the set of siblings of t, f−xt
k (xt)
denotes the posterior probability of observation xt
given all other observations assigned to state k, and
z−t denotes all state assignments except zt. In other
words, the probability is proportional to the product
of three terms: the probability of the states of t and
its siblings given its parent zp(t), the probability of
the states of the children c(t) given zt, and the pos-
terior probability of observation xt given zt. Note
that if we sample zt to be a previously unseen state,
we will need to extend β as discussed in Section 3.2.
Now we give the equations for P((zt′)t′∈c(t)|zt)
for each of the models. In the independent child
model the probability of generating each child is:
</bodyText>
<equation confidence="0.995898">
njk + α0βk
Pind(zci(t) = k|zt = j) =
nj· + α0
�Pind((zt′)t′∈c(t)|zt = j) = t′∈c(t) Pind(zt′|zt = j)
</equation>
<bodyText confidence="0.9998425">
For the simultaneous child model, the probability of
generating a sequence of children, z, takes into ac-
count how many times that sequence has been gen-
erated, along with the likelihood of regenerating it:
</bodyText>
<equation confidence="0.973725666666667">
nj, + ζPind(z|zt =j)
Psim((zt′)t′∈c(t) = z|zt =j) =
nj· + ζ
</equation>
<bodyText confidence="0.9361075">
Recall that ζ denotes the concentration parameter
for the sequence generating DP. Lastly, we have the
</bodyText>
<note confidence="0.4999015">
DT NN IN DT NN VBD PRP$ NN TO VB NN EOS
The man in the corner taught his dachshund to play golf EOS
</note>
<figureCaption confidence="0.541772">
Figure 6: An example of a syntactic dependency tree
</figureCaption>
<bodyText confidence="0.9992525">
where the dependencies are between tags (hidden
states), and each tag generates a word (observation).
</bodyText>
<equation confidence="0.94204575">
Markov child model:
Pm(zci(t) =k|zci−1(t) = i, zt = j) =
c(t
Pm((zt′)t′∈c(t)  |zt) = fji=1 Pm(zci(t)|zci−1(t), zt)
</equation>
<bodyText confidence="0.9999722">
Finally, we give the posterior probability of an ob-
servation, given that F(φk) is Multinomial(φk), and
that H is Dirichlet(ρ, ... , ρ). Let N be the vocab-
ulary size and nk be the number of observations x
with state k. Then:
</bodyText>
<equation confidence="0.9882075">
nxtk + ρ
n·k + Nρ
</equation>
<bodyText confidence="0.998188666666667">
Sampling m. We use the following procedure,
which slightly modifies one from (Y. W. Teh, 2006,
p.c.), to sample each mjk:
</bodyText>
<equation confidence="0.761730583333333">
SAMPLEM(j, k)
1 if njk = 0
2 then mjk = 0
3 else mjk = 1
4 for i ← 2 to njk
5 do if rand() &lt; α0
α0+i−1
6 then mjk = mjk + 1
7 return mjk
Sampling β. Lastly, we sample β using the Di-
richlet distribution:
(β1, ... , βK, βu) ∼ Dirichlet(m·1, ... , m·K, α0)
</equation>
<sectionHeader confidence="0.99643" genericHeader="method">
6 Experiments
</sectionHeader>
<bodyText confidence="0.999618363636364">
We demonstrate infinite tree models on two dis-
tinct syntax learning tasks: unsupervised POS learn-
ing conditioned on untagged dependency trees and
learning a split of an existing tagset, which improves
the accuracy of an automatic syntactic parser.
For both tasks, we use a simple modification of
the basic model structure, to allow the trees to gen-
erate dependents on the left and the right with dif-
ferent distributions – as is useful in modeling natu-
ral language. The modification of the independent
child tree is trivial: we have two copies of each of
</bodyText>
<equation confidence="0.90588575">
njik + α0βk
nji· + α0
f−xt
k (xt) =
</equation>
<page confidence="0.984463">
277
</page>
<bodyText confidence="0.999889076923077">
the variables Irk, one each for the left and the right.
Generation of dependents on the right is completely
independent of that for the left. The modifications of
the other models are similar, but now there are sepa-
rate sets of Irk variables for the Markov child model,
and separate Lk and Ak variables for the simultane-
ous child model, for each of the left and right.
For both experiments, we used dependency trees
extracted from the Penn Treebank (Marcus et al.,
1993) using the head rules and dependency extrac-
tor from Yamada and Matsumoto (2003). As is stan-
dard, we used WSJ sections 2–21 for training, sec-
tion 22 for development, and section 23 for testing.
</bodyText>
<subsectionHeader confidence="0.969113">
6.1 Unsupervised POS Learning
</subsectionHeader>
<bodyText confidence="0.997314363636363">
In the first experiment, we do unsupervised part-of-
speech learning conditioned on dependency trees.
To be clear, the input to our algorithm is the de-
pendency structure skeleton of the corpus, but not
the POS tags, and the output is a labeling of each
of the words in the tree for word class. Since the
model knows nothing about the POS annotation, the
new classes have arbitrary integer names, and are
not guaranteed to correlate with the POS tag def-
initions. We found that the choice of α0 and Q
(the concentration parameters) did not affect the out-
put much, while the value of p (the parameter for
the base Dirichlet distribution) made a much larger
difference. For all reported experiments, we set
α0 = Q = 10 and varied p.
We use several metrics to evaluate the word
classes. First, we use the standard approach of
greedily assigning each of the learned classes to the
POS tag with which it has the greatest overlap, and
then computing tagging accuracy (Smith and Eisner,
2005; Haghighi and Klein, 2006).8 Additionally, we
compute the mutual information of the learned clus-
ters with the gold tags, and we compute the cluster
F-score (Ghosh, 2003). See Table 1 for results of
the different models, parameter settings, and met-
rics. Given the variance in the number of classes
learned it is a little difficult to interpret these results,
but it is clear that the Markov child model is the
best; it achieves superior performance to the inde-
pendent child model on all metrics, while learning
fewer word classes. The poor performance of the
simultaneous model warrants further investigation,
but we observed that the distributions learned by that
</bodyText>
<footnote confidence="0.937776">
8The advantage of this metric is that it’s comprehensible.
The disadvantage is that it’s easy to inflate by adding classes.
</footnote>
<table confidence="0.999835">
Model p # Classes Acc. MI F1
Indep. 0.01 943 67.89 2.00 48.29
0.001 1744 73.61 2.23 40.80
0.0001 2437 74.64 2.27 39.47
Simul. 0.01 183 21.36 0.31 21.57
0.001 430 15.77 0.09 13.80
0.0001 549 16.68 0.12 14.29
Markov 0.01 613 68.53 2.12 49.82
0.001 894 75.34 2.31 48.73
</table>
<tableCaption confidence="0.999464">
Table 1: Results of part unsupervised POS tagging
</tableCaption>
<bodyText confidence="0.9819378">
on the different models, using a greedy accuracy
measure.
model are far more spiked, potentially due to double
counting of tags, since the sequence probabilities are
already based on the local probabilities.
For comparison, Haghighi and Klein (2006) re-
port an unsupervised baseline of 41.3%, and a best
result of 80.5% from using hand-labeled prototypes
and distributional similarity. However, they train on
less data, and learn fewer word classes.
</bodyText>
<subsectionHeader confidence="0.990731">
6.2 Unsupervised POS Splitting
</subsectionHeader>
<bodyText confidence="0.99996125">
In the second experiment we use the infinite tree
models to learn a refinement of the PTB tags. We
initialize the set of hidden states to the set of PTB
tags, and then, during inference, constrain the sam-
pling distribution over hidden state zt at each node t
to include only states that are a refinement of the an-
notated PTB tag at that position. The output of this
training procedure is a new annotation of the words
in the PTB with the learned tags. We then compare
the performance of a generative dependency parser
trained on the new refined tags with one trained on
the base PTB tag set. We use the generative de-
pendency parser distributed with the Stanford fac-
tored parser (Klein and Manning, 2003b) for the
comparison, since it performs simultaneous tagging
and parsing during testing. In this experiment, un-
labeled, directed, dependency parsing accuracy for
the best model increased from 85.11% to 87.35%, a
15% error reduction. See Table 2 for the full results
over all models and parameter settings.
</bodyText>
<sectionHeader confidence="0.999965" genericHeader="method">
7 Related Work
</sectionHeader>
<bodyText confidence="0.999976857142857">
The HDP-PCFG (Liang et al., 2007), developed at
the same time as this work, aims to learn state splits
for a binary-branching PCFG. It is similar to our
simultaneous child model, but with several impor-
tant distinctions. As discussed in Section 4.2, in our
model each state has a DP over sequences, with a
base distribution that is defined over the local child
</bodyText>
<page confidence="0.990831">
278
</page>
<table confidence="0.997241">
Model p Accuracy
Baseline – 85.11
Independent 0.01 86.18
0.001 85.88
Markov 0.01 87.15
0.001 87.35
</table>
<tableCaption confidence="0.986924">
Table 2: Results of untyped, directed dependency
</tableCaption>
<bodyText confidence="0.9995315">
parsing, where the POS tags in the training data have
been split according to the various models. At test
time, the POS tagging and parsing are done simulta-
neously by the parser.
state probabilities. In contrast, Liang et al. (2007)
define a global DP over sequences, with the base
measure defined over the global state probabilities,
,3; locally, each state has an HDP, with this global
DP as the base measure. We believe our choice to
be more linguistically sensible: in our model, for a
particular state, dependent sequences which are sim-
ilar to one another increase one another’s likelihood.
Additionally, their modeling decision made it diffi-
cult to define a Gibbs sampler, and instead they use
variational inference. Earlier, Johnson et al. (2007)
presented adaptor grammars, which is a very simi-
lar model to the HDP-PCFG. However they did not
confine themselves to a binary branching structure
and presented a more general framework for defin-
ing the process for splitting the states.
</bodyText>
<sectionHeader confidence="0.992068" genericHeader="discussions">
8 Discussion and Future Work
</sectionHeader>
<bodyText confidence="0.9999856">
We have presented a set of novel infinite tree models
and associated inference algorithms, which are suit-
able for representing syntactic dependency structure.
Because the models represent a potentially infinite
number of hidden states, they permit unsupervised
learning algorithms which naturally select a num-
ber of word classes, or tags, based on qualities of
the data. Although they require substantial techni-
cal background to develop, the learning algorithms
based on the models are actually simple in form, re-
quiring only the maintenance of counts, and the con-
struction of sampling distributions based on these
counts. Our experimental results are preliminary but
promising: they demonstrate that the model is capa-
ble of capturing important syntactic structure.
Much remains to be done in applying infinite
models to language structure, and an interesting ex-
tension would be to develop inference algorithms
that permit completely unsupervised learning of de-
pendency structure.
</bodyText>
<sectionHeader confidence="0.996631" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.971684545454545">
Many thanks to Yeh Whye Teh for several enlight-
ening conversations, and to the following mem-
bers (and honorary member) of the Stanford NLP
group for comments on an earlier draft: Thad
Hughes, David Hall, Surabhi Gupta, Ani Nenkova,
Sebastian Riedel. This work was supported by a
Scottish Enterprise Edinburgh-Stanford Link grant
(R37588), as part of the EASIE project, and by
the Advanced Research and Development Activity
(ARDA)’s Advanced Question Answering for Intel-
ligence (AQUAINT) Phase II Program.
</bodyText>
<sectionHeader confidence="0.996758" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999963934782609">
C. E. Antoniak. 1974. Mixtures of Dirichlet processes with ap-
plications to Bayesian nonparametrics. Annals of Statistics,
2:1152–1174.
M.J. Beal, Z. Ghahramani, and C.E. Rasmussen. 2002. The
infinite hidden Markov model. In Advances in Neural Infor-
mation Processing Systems, pages 577–584.
E. Charniak. 1996. Tree-bank grammars. In AAAI 1996, pages
1031–1036.
E. Charniak. 2000. A maximum-entropy-inspired parser. In
HLT-NAACL 2000, pages 132–139.
M. Collins. 2003. Head-driven statistical models for natural lan-
guage parsing. Computational Linguistics, 29(4):589–637.
T. S. Ferguson. 1973. A Bayesian analysis of some nonpara-
metric problems. Annals of Statistics, 1:209–230.
J. Ghosh. 2003. Scalable clustering methods for data mining. In
N. Ye, editor, Handbook of Data Mining, chapter 10, pages
247–277. Lawrence Erlbaum Assoc.
A. Haghighi and D. Klein. 2006. Prototype-driven learning for
sequence models. In HLT-NAACL 2006.
M. Johnson, T. Griffiths, and S. Goldwater. 2007. Adaptor
grammars: A framework for specifying compositional non-
parametric Bayesian models. In NIPS 2007.
D. Klein and C. D. Manning. 2003a. Accurate unlexicalized
parsing. In ACL 2003.
D. Klein and C. D. Manning. 2003b. Factored A* search for
models over sequences and trees. In IJCAI2003.
P. Liang, S. Petrov, D. Klein, and M. Jordan. 2007. Nonpara-
metric PCFGs using Dirichlet processes. In EMNLP 2007.
M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz. 1993.
Building a large annotated corpus of English: The Penn
Treebank. Computational Linguistics, 19(2):313–330.
S. Petrov, L. Barrett, R. Thibaux, and D. Klein. 2006. Learning
accurate, compact, and interpretable tree annotation. In ACL
44/COLING 21, pages 433–440.
J. Pitman. 2002. Poisson-Dirichlet and GEM invariant distribu-
tions for split-and-merge transformations of an interval par-
tition. Combinatorics, Probability and Computing, 11:501–
514.
N. A. Smith and J. Eisner. 2005. Contrastive estimation: Train-
ing log-linear models on unlabeled data. In ACL 2005.
Y. W. Teh, M.I. Jordan, M. J. Beal, and D.M. Blei. 2006. Hier-
archical Dirichlet processes. Journal of the American Statis-
tical Association, 101:1566–1581.
H. Yamada and Y. Matsumoto. 2003. Statistical dependency
analysis with support vector machines. In Proceedings of
IWPT, pages 195–206.
</reference>
<page confidence="0.998567">
279
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.711044">
<title confidence="0.999779">The Infinite Tree</title>
<author confidence="0.999948">Jenny Rose Finkel</author>
<author confidence="0.999948">Trond Grenager</author>
<author confidence="0.999948">Christopher D Manning</author>
<affiliation confidence="0.99996">Computer Science Department, Stanford University</affiliation>
<address confidence="0.999941">Stanford, CA 94305</address>
<email confidence="0.988464">grenager,</email>
<abstract confidence="0.9886296">Historically, unsupervised learning techniques have lacked a principled technique for selecting the number of unseen components. Research into non-parametric priors, such as the Dirichlet process, has enabled inthe use of in which the number of hidden categories is not fixed, but can grow with the amount of training data. we develop the a new infinite model capable of representing recursive branching structure over an arbitrarily large set of hidden categories. Specifically, we develop three infinite tree models, each of which enforces different independence assumptions, and for each model we define a assignment inference procedure. We demonstrate the utility of our models by doing unsupervised learning of part-of-speech tags from treebank dependency skeleton structure, achieving an accuracy of 75.34%, and by doing unsupervised splitting of part-of-speech tags, which increases the accuracy of a generative dependency parser from 85.11% to 87.35%.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C E Antoniak</author>
</authors>
<title>Mixtures of Dirichlet processes with applications to Bayesian nonparametrics.</title>
<date>1974</date>
<journal>Annals of Statistics,</journal>
<pages>2--1152</pages>
<contexts>
<context position="1733" citStr="Antoniak, 1974" startWordPosition="254" endWordPosition="255"> of part-of-speech tags, which increases the accuracy of a generative dependency parser from 85.11% to 87.35%. 1 Introduction Model-based unsupervised learning techniques have historically lacked good methods for choosing the number of unseen components. For example, kmeans or EM clustering require advance specification of the number of mixture components. But the introduction of nonparametric priors such as the Dirichlet process (Ferguson, 1973) enabled development of infinite mixture models, in which the number of hidden components is not fixed, but emerges naturally from the training data (Antoniak, 1974). Teh et al. (2006) proposed the hierarchical Dirichlet process (HDP) as a way of applying the Dirichlet process (DP) to more complex model forms, so as to allow multiple, group-specific, infinite mixture models to share their mixture components. The closely related infinite hidden Markov model is an HMM in which the transitions are modeled using an HDP, enabling unsupervised learning of sequence models when the number of hidden states is unknown (Beal et al., 2002; Teh et al., 2006). We extend this work by introducing the infinite tree model, which represents recursive branching structure ove</context>
</contexts>
<marker>Antoniak, 1974</marker>
<rawString>C. E. Antoniak. 1974. Mixtures of Dirichlet processes with applications to Bayesian nonparametrics. Annals of Statistics, 2:1152–1174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Beal</author>
<author>Z Ghahramani</author>
<author>C E Rasmussen</author>
</authors>
<title>The infinite hidden Markov model.</title>
<date>2002</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>577--584</pages>
<contexts>
<context position="2202" citStr="Beal et al., 2002" startWordPosition="329" endWordPosition="332">ent of infinite mixture models, in which the number of hidden components is not fixed, but emerges naturally from the training data (Antoniak, 1974). Teh et al. (2006) proposed the hierarchical Dirichlet process (HDP) as a way of applying the Dirichlet process (DP) to more complex model forms, so as to allow multiple, group-specific, infinite mixture models to share their mixture components. The closely related infinite hidden Markov model is an HMM in which the transitions are modeled using an HDP, enabling unsupervised learning of sequence models when the number of hidden states is unknown (Beal et al., 2002; Teh et al., 2006). We extend this work by introducing the infinite tree model, which represents recursive branching structure over a potentially infinite set of hidden states. Such models are appropriate for the syntactic dependency structure of natural language. The hidden states represent word categories (“tags”), the observations they generate represent the words themselves, and the tree structure represents syntactic dependencies between pairs of tags. To validate the model, we test unsupervised learning of tags conditioned on a given dependency tree structure. This is useful, because co</context>
<context position="15820" citStr="Beal et al., 2002" startWordPosition="2747" endWordPosition="2750">states is potentially infinite. We achieve this by representing each of the variables as a broken stick, an don’t πk φk. πk πk d adopt the same approach of φ1 φ2 φ3 φ4 φ5 φ6 φ7 . . . β : πj : . . . &apos;y β α0 πk H Ok 00 x1 x2 x3 z1 z2 z3 β|7 ∼ GEM(7) πk|α0, β ∼ DP(α0, β) 0k|H ∼ H Figure 5: A graphical representation of the infinite independent child model. sampling each πk from a DP with base measure β. For the dependency tree application, Ok is a vector representing the parameters of a multinomial over words, and H is a Dirichlet distribution. The infinite hidden Markov model (iHMM) or HDP-HMM (Beal et al., 2002; Teh et al., 2006) is a model of sequence data with transitions modeled by an HDP.6 The iHMM can be viewed as a special case of this model, where each state (except the stop state) produces exactly one child. 4.2 Simultaneous Children The key problem in the definition of the simultaneous children model is that of defining a distribution over the lists of children produced by each state, since each child in the list has as its domain the positive integers, representing the infinite set of possible states. Our solution is to construct a distribution Lk over lists of states from the distribution</context>
</contexts>
<marker>Beal, Ghahramani, Rasmussen, 2002</marker>
<rawString>M.J. Beal, Z. Ghahramani, and C.E. Rasmussen. 2002. The infinite hidden Markov model. In Advances in Neural Information Processing Systems, pages 577–584.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>Tree-bank grammars.</title>
<date>1996</date>
<booktitle>In AAAI</booktitle>
<pages>1031--1036</pages>
<contexts>
<context position="2977" citStr="Charniak, 1996" startWordPosition="447" endWordPosition="448">of hidden states. Such models are appropriate for the syntactic dependency structure of natural language. The hidden states represent word categories (“tags”), the observations they generate represent the words themselves, and the tree structure represents syntactic dependencies between pairs of tags. To validate the model, we test unsupervised learning of tags conditioned on a given dependency tree structure. This is useful, because coarse-grained syntactic categories, such as those used in the Penn Treebank (PTB), make insufficient distinctions to be the basis of accurate syntactic parsing (Charniak, 1996). Hence, state-of-the-art parsers either supplement the part-of-speech (POS) tags with the lexical forms themselves (Collins, 2003; Charniak, 2000), manually split the tagset into a finer-grained one (Klein and Manning, 2003a), or learn finer grained tag distinctions using a heuristic learning procedure (Petrov et al., 2006). We demonstrate that the tags learned with our model are correlated with the PTB POS tags, and furthermore that they improve the accuracy of an automatic parser when used in training. 2 Finite Trees We begin by presenting three finite tree models, each with different indep</context>
</contexts>
<marker>Charniak, 1996</marker>
<rawString>E. Charniak. 1996. Tree-bank grammars. In AAAI 1996, pages 1031–1036.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>In HLT-NAACL</booktitle>
<pages>132--139</pages>
<contexts>
<context position="3124" citStr="Charniak, 2000" startWordPosition="466" endWordPosition="467">es (“tags”), the observations they generate represent the words themselves, and the tree structure represents syntactic dependencies between pairs of tags. To validate the model, we test unsupervised learning of tags conditioned on a given dependency tree structure. This is useful, because coarse-grained syntactic categories, such as those used in the Penn Treebank (PTB), make insufficient distinctions to be the basis of accurate syntactic parsing (Charniak, 1996). Hence, state-of-the-art parsers either supplement the part-of-speech (POS) tags with the lexical forms themselves (Collins, 2003; Charniak, 2000), manually split the tagset into a finer-grained one (Klein and Manning, 2003a), or learn finer grained tag distinctions using a heuristic learning procedure (Petrov et al., 2006). We demonstrate that the tags learned with our model are correlated with the PTB POS tags, and furthermore that they improve the accuracy of an automatic parser when used in training. 2 Finite Trees We begin by presenting three finite tree models, each with different independence assumptions. 272 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 272–279, Prague, Czech Repub</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>E. Charniak. 2000. A maximum-entropy-inspired parser. In HLT-NAACL 2000, pages 132–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Head-driven statistical models for natural language parsing.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>4</issue>
<contexts>
<context position="3107" citStr="Collins, 2003" startWordPosition="464" endWordPosition="465">t word categories (“tags”), the observations they generate represent the words themselves, and the tree structure represents syntactic dependencies between pairs of tags. To validate the model, we test unsupervised learning of tags conditioned on a given dependency tree structure. This is useful, because coarse-grained syntactic categories, such as those used in the Penn Treebank (PTB), make insufficient distinctions to be the basis of accurate syntactic parsing (Charniak, 1996). Hence, state-of-the-art parsers either supplement the part-of-speech (POS) tags with the lexical forms themselves (Collins, 2003; Charniak, 2000), manually split the tagset into a finer-grained one (Klein and Manning, 2003a), or learn finer grained tag distinctions using a heuristic learning procedure (Petrov et al., 2006). We demonstrate that the tags learned with our model are correlated with the PTB POS tags, and furthermore that they improve the accuracy of an automatic parser when used in training. 2 Finite Trees We begin by presenting three finite tree models, each with different independence assumptions. 272 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 272–279, Pr</context>
</contexts>
<marker>Collins, 2003</marker>
<rawString>M. Collins. 2003. Head-driven statistical models for natural language parsing. Computational Linguistics, 29(4):589–637.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T S Ferguson</author>
</authors>
<title>A Bayesian analysis of some nonparametric problems.</title>
<date>1973</date>
<journal>Annals of Statistics,</journal>
<pages>1--209</pages>
<contexts>
<context position="1568" citStr="Ferguson, 1973" startWordPosition="227" endWordPosition="228"> doing unsupervised learning of part-of-speech tags from treebank dependency skeleton structure, achieving an accuracy of 75.34%, and by doing unsupervised splitting of part-of-speech tags, which increases the accuracy of a generative dependency parser from 85.11% to 87.35%. 1 Introduction Model-based unsupervised learning techniques have historically lacked good methods for choosing the number of unseen components. For example, kmeans or EM clustering require advance specification of the number of mixture components. But the introduction of nonparametric priors such as the Dirichlet process (Ferguson, 1973) enabled development of infinite mixture models, in which the number of hidden components is not fixed, but emerges naturally from the training data (Antoniak, 1974). Teh et al. (2006) proposed the hierarchical Dirichlet process (HDP) as a way of applying the Dirichlet process (DP) to more complex model forms, so as to allow multiple, group-specific, infinite mixture models to share their mixture components. The closely related infinite hidden Markov model is an HMM in which the transitions are modeled using an HDP, enabling unsupervised learning of sequence models when the number of hidden st</context>
</contexts>
<marker>Ferguson, 1973</marker>
<rawString>T. S. Ferguson. 1973. A Bayesian analysis of some nonparametric problems. Annals of Statistics, 1:209–230.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ghosh</author>
</authors>
<title>Scalable clustering methods for data mining.</title>
<date>2003</date>
<booktitle>Handbook of Data Mining, chapter 10,</booktitle>
<pages>247--277</pages>
<editor>In N. Ye, editor,</editor>
<contexts>
<context position="25219" citStr="Ghosh, 2003" startWordPosition="4433" endWordPosition="4434">fect the output much, while the value of p (the parameter for the base Dirichlet distribution) made a much larger difference. For all reported experiments, we set α0 = Q = 10 and varied p. We use several metrics to evaluate the word classes. First, we use the standard approach of greedily assigning each of the learned classes to the POS tag with which it has the greatest overlap, and then computing tagging accuracy (Smith and Eisner, 2005; Haghighi and Klein, 2006).8 Additionally, we compute the mutual information of the learned clusters with the gold tags, and we compute the cluster F-score (Ghosh, 2003). See Table 1 for results of the different models, parameter settings, and metrics. Given the variance in the number of classes learned it is a little difficult to interpret these results, but it is clear that the Markov child model is the best; it achieves superior performance to the independent child model on all metrics, while learning fewer word classes. The poor performance of the simultaneous model warrants further investigation, but we observed that the distributions learned by that 8The advantage of this metric is that it’s comprehensible. The disadvantage is that it’s easy to inflate </context>
</contexts>
<marker>Ghosh, 2003</marker>
<rawString>J. Ghosh. 2003. Scalable clustering methods for data mining. In N. Ye, editor, Handbook of Data Mining, chapter 10, pages 247–277. Lawrence Erlbaum Assoc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Haghighi</author>
<author>D Klein</author>
</authors>
<title>Prototype-driven learning for sequence models.</title>
<date>2006</date>
<booktitle>In HLT-NAACL</booktitle>
<contexts>
<context position="25076" citStr="Haghighi and Klein, 2006" startWordPosition="4408" endWordPosition="4411">eger names, and are not guaranteed to correlate with the POS tag definitions. We found that the choice of α0 and Q (the concentration parameters) did not affect the output much, while the value of p (the parameter for the base Dirichlet distribution) made a much larger difference. For all reported experiments, we set α0 = Q = 10 and varied p. We use several metrics to evaluate the word classes. First, we use the standard approach of greedily assigning each of the learned classes to the POS tag with which it has the greatest overlap, and then computing tagging accuracy (Smith and Eisner, 2005; Haghighi and Klein, 2006).8 Additionally, we compute the mutual information of the learned clusters with the gold tags, and we compute the cluster F-score (Ghosh, 2003). See Table 1 for results of the different models, parameter settings, and metrics. Given the variance in the number of classes learned it is a little difficult to interpret these results, but it is clear that the Markov child model is the best; it achieves superior performance to the independent child model on all metrics, while learning fewer word classes. The poor performance of the simultaneous model warrants further investigation, but we observed t</context>
<context position="26404" citStr="Haghighi and Klein (2006)" startWordPosition="4628" endWordPosition="4631">sadvantage is that it’s easy to inflate by adding classes. Model p # Classes Acc. MI F1 Indep. 0.01 943 67.89 2.00 48.29 0.001 1744 73.61 2.23 40.80 0.0001 2437 74.64 2.27 39.47 Simul. 0.01 183 21.36 0.31 21.57 0.001 430 15.77 0.09 13.80 0.0001 549 16.68 0.12 14.29 Markov 0.01 613 68.53 2.12 49.82 0.001 894 75.34 2.31 48.73 Table 1: Results of part unsupervised POS tagging on the different models, using a greedy accuracy measure. model are far more spiked, potentially due to double counting of tags, since the sequence probabilities are already based on the local probabilities. For comparison, Haghighi and Klein (2006) report an unsupervised baseline of 41.3%, and a best result of 80.5% from using hand-labeled prototypes and distributional similarity. However, they train on less data, and learn fewer word classes. 6.2 Unsupervised POS Splitting In the second experiment we use the infinite tree models to learn a refinement of the PTB tags. We initialize the set of hidden states to the set of PTB tags, and then, during inference, constrain the sampling distribution over hidden state zt at each node t to include only states that are a refinement of the annotated PTB tag at that position. The output of this tra</context>
</contexts>
<marker>Haghighi, Klein, 2006</marker>
<rawString>A. Haghighi and D. Klein. 2006. Prototype-driven learning for sequence models. In HLT-NAACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnson</author>
<author>T Griffiths</author>
<author>S Goldwater</author>
</authors>
<title>Adaptor grammars: A framework for specifying compositional nonparametric Bayesian models.</title>
<date>2007</date>
<booktitle>In NIPS</booktitle>
<contexts>
<context position="28924" citStr="Johnson et al. (2007)" startWordPosition="5052" endWordPosition="5055">parsing are done simultaneously by the parser. state probabilities. In contrast, Liang et al. (2007) define a global DP over sequences, with the base measure defined over the global state probabilities, ,3; locally, each state has an HDP, with this global DP as the base measure. We believe our choice to be more linguistically sensible: in our model, for a particular state, dependent sequences which are similar to one another increase one another’s likelihood. Additionally, their modeling decision made it difficult to define a Gibbs sampler, and instead they use variational inference. Earlier, Johnson et al. (2007) presented adaptor grammars, which is a very similar model to the HDP-PCFG. However they did not confine themselves to a binary branching structure and presented a more general framework for defining the process for splitting the states. 8 Discussion and Future Work We have presented a set of novel infinite tree models and associated inference algorithms, which are suitable for representing syntactic dependency structure. Because the models represent a potentially infinite number of hidden states, they permit unsupervised learning algorithms which naturally select a number of word classes, or </context>
</contexts>
<marker>Johnson, Griffiths, Goldwater, 2007</marker>
<rawString>M. Johnson, T. Griffiths, and S. Goldwater. 2007. Adaptor grammars: A framework for specifying compositional nonparametric Bayesian models. In NIPS 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In ACL</booktitle>
<contexts>
<context position="3201" citStr="Klein and Manning, 2003" startWordPosition="476" endWordPosition="479">elves, and the tree structure represents syntactic dependencies between pairs of tags. To validate the model, we test unsupervised learning of tags conditioned on a given dependency tree structure. This is useful, because coarse-grained syntactic categories, such as those used in the Penn Treebank (PTB), make insufficient distinctions to be the basis of accurate syntactic parsing (Charniak, 1996). Hence, state-of-the-art parsers either supplement the part-of-speech (POS) tags with the lexical forms themselves (Collins, 2003; Charniak, 2000), manually split the tagset into a finer-grained one (Klein and Manning, 2003a), or learn finer grained tag distinctions using a heuristic learning procedure (Petrov et al., 2006). We demonstrate that the tags learned with our model are correlated with the PTB POS tags, and furthermore that they improve the accuracy of an automatic parser when used in training. 2 Finite Trees We begin by presenting three finite tree models, each with different independence assumptions. 272 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 272–279, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics Figure 1: A </context>
<context position="27337" citStr="Klein and Manning, 2003" startWordPosition="4791" endWordPosition="4794">of the PTB tags. We initialize the set of hidden states to the set of PTB tags, and then, during inference, constrain the sampling distribution over hidden state zt at each node t to include only states that are a refinement of the annotated PTB tag at that position. The output of this training procedure is a new annotation of the words in the PTB with the learned tags. We then compare the performance of a generative dependency parser trained on the new refined tags with one trained on the base PTB tag set. We use the generative dependency parser distributed with the Stanford factored parser (Klein and Manning, 2003b) for the comparison, since it performs simultaneous tagging and parsing during testing. In this experiment, unlabeled, directed, dependency parsing accuracy for the best model increased from 85.11% to 87.35%, a 15% error reduction. See Table 2 for the full results over all models and parameter settings. 7 Related Work The HDP-PCFG (Liang et al., 2007), developed at the same time as this work, aims to learn state splits for a binary-branching PCFG. It is similar to our simultaneous child model, but with several important distinctions. As discussed in Section 4.2, in our model each state has a</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>D. Klein and C. D. Manning. 2003a. Accurate unlexicalized parsing. In ACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>Factored A* search for models over sequences and trees.</title>
<date>2003</date>
<booktitle>In IJCAI2003.</booktitle>
<contexts>
<context position="3201" citStr="Klein and Manning, 2003" startWordPosition="476" endWordPosition="479">elves, and the tree structure represents syntactic dependencies between pairs of tags. To validate the model, we test unsupervised learning of tags conditioned on a given dependency tree structure. This is useful, because coarse-grained syntactic categories, such as those used in the Penn Treebank (PTB), make insufficient distinctions to be the basis of accurate syntactic parsing (Charniak, 1996). Hence, state-of-the-art parsers either supplement the part-of-speech (POS) tags with the lexical forms themselves (Collins, 2003; Charniak, 2000), manually split the tagset into a finer-grained one (Klein and Manning, 2003a), or learn finer grained tag distinctions using a heuristic learning procedure (Petrov et al., 2006). We demonstrate that the tags learned with our model are correlated with the PTB POS tags, and furthermore that they improve the accuracy of an automatic parser when used in training. 2 Finite Trees We begin by presenting three finite tree models, each with different independence assumptions. 272 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 272–279, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics Figure 1: A </context>
<context position="27337" citStr="Klein and Manning, 2003" startWordPosition="4791" endWordPosition="4794">of the PTB tags. We initialize the set of hidden states to the set of PTB tags, and then, during inference, constrain the sampling distribution over hidden state zt at each node t to include only states that are a refinement of the annotated PTB tag at that position. The output of this training procedure is a new annotation of the words in the PTB with the learned tags. We then compare the performance of a generative dependency parser trained on the new refined tags with one trained on the base PTB tag set. We use the generative dependency parser distributed with the Stanford factored parser (Klein and Manning, 2003b) for the comparison, since it performs simultaneous tagging and parsing during testing. In this experiment, unlabeled, directed, dependency parsing accuracy for the best model increased from 85.11% to 87.35%, a 15% error reduction. See Table 2 for the full results over all models and parameter settings. 7 Related Work The HDP-PCFG (Liang et al., 2007), developed at the same time as this work, aims to learn state splits for a binary-branching PCFG. It is similar to our simultaneous child model, but with several important distinctions. As discussed in Section 4.2, in our model each state has a</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>D. Klein and C. D. Manning. 2003b. Factored A* search for models over sequences and trees. In IJCAI2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Liang</author>
<author>S Petrov</author>
<author>D Klein</author>
<author>M Jordan</author>
</authors>
<title>Nonparametric PCFGs using Dirichlet processes.</title>
<date>2007</date>
<booktitle>In EMNLP</booktitle>
<contexts>
<context position="27692" citStr="Liang et al., 2007" startWordPosition="4847" endWordPosition="4850">learned tags. We then compare the performance of a generative dependency parser trained on the new refined tags with one trained on the base PTB tag set. We use the generative dependency parser distributed with the Stanford factored parser (Klein and Manning, 2003b) for the comparison, since it performs simultaneous tagging and parsing during testing. In this experiment, unlabeled, directed, dependency parsing accuracy for the best model increased from 85.11% to 87.35%, a 15% error reduction. See Table 2 for the full results over all models and parameter settings. 7 Related Work The HDP-PCFG (Liang et al., 2007), developed at the same time as this work, aims to learn state splits for a binary-branching PCFG. It is similar to our simultaneous child model, but with several important distinctions. As discussed in Section 4.2, in our model each state has a DP over sequences, with a base distribution that is defined over the local child 278 Model p Accuracy Baseline – 85.11 Independent 0.01 86.18 0.001 85.88 Markov 0.01 87.15 0.001 87.35 Table 2: Results of untyped, directed dependency parsing, where the POS tags in the training data have been split according to the various models. At test time, the POS t</context>
</contexts>
<marker>Liang, Petrov, Klein, Jordan, 2007</marker>
<rawString>P. Liang, S. Petrov, D. Klein, and M. Jordan. 2007. Nonparametric PCFGs using Dirichlet processes. In EMNLP 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="23846" citStr="Marcus et al., 1993" startWordPosition="4192" endWordPosition="4195">ng natural language. The modification of the independent child tree is trivial: we have two copies of each of njik + α0βk nji· + α0 f−xt k (xt) = 277 the variables Irk, one each for the left and the right. Generation of dependents on the right is completely independent of that for the left. The modifications of the other models are similar, but now there are separate sets of Irk variables for the Markov child model, and separate Lk and Ak variables for the simultaneous child model, for each of the left and right. For both experiments, we used dependency trees extracted from the Penn Treebank (Marcus et al., 1993) using the head rules and dependency extractor from Yamada and Matsumoto (2003). As is standard, we used WSJ sections 2–21 for training, section 22 for development, and section 23 for testing. 6.1 Unsupervised POS Learning In the first experiment, we do unsupervised part-ofspeech learning conditioned on dependency trees. To be clear, the input to our algorithm is the dependency structure skeleton of the corpus, but not the POS tags, and the output is a labeling of each of the words in the tree for word class. Since the model knows nothing about the POS annotation, the new classes have arbitrar</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>L Barrett</author>
<author>R Thibaux</author>
<author>D Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In ACL 44/COLING 21,</booktitle>
<pages>433--440</pages>
<contexts>
<context position="3303" citStr="Petrov et al., 2006" startWordPosition="491" endWordPosition="494">del, we test unsupervised learning of tags conditioned on a given dependency tree structure. This is useful, because coarse-grained syntactic categories, such as those used in the Penn Treebank (PTB), make insufficient distinctions to be the basis of accurate syntactic parsing (Charniak, 1996). Hence, state-of-the-art parsers either supplement the part-of-speech (POS) tags with the lexical forms themselves (Collins, 2003; Charniak, 2000), manually split the tagset into a finer-grained one (Klein and Manning, 2003a), or learn finer grained tag distinctions using a heuristic learning procedure (Petrov et al., 2006). We demonstrate that the tags learned with our model are correlated with the PTB POS tags, and furthermore that they improve the accuracy of an automatic parser when used in training. 2 Finite Trees We begin by presenting three finite tree models, each with different independence assumptions. 272 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 272–279, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics Figure 1: A graphical representation of the finite Bayesian tree model with independent children. The plate (recta</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>S. Petrov, L. Barrett, R. Thibaux, and D. Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In ACL 44/COLING 21, pages 433–440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pitman</author>
</authors>
<title>Poisson-Dirichlet and GEM invariant distributions for split-and-merge transformations of an interval partition.</title>
<date>2002</date>
<journal>Combinatorics, Probability and Computing,</journal>
<volume>11</volume>
<pages>514</pages>
<contexts>
<context position="10016" citStr="Pitman (2002)" startWordPosition="1637" endWordPosition="1638"> of the top(a) (b) Figure 3: A graphical representation of a simple Dirichlet process mixture model (left) and a hierarchical Dirichlet process model (right). Note that we show the stick-breaking representations of the models, in which we have factored G — DP(α0, H) into two sets of variables: π and φ. ics (i.e., the location of the sticks in the figure). To generate 7r we first generate an infinite sequence of variables 7r′ = (π′k)∞k=1, each of which is distributed according to the Beta distribution: π′k|α0 — Beta(1, α0) Then 7r = (πk)∞k=1 is defined as: �k−1 πk = πk (1 — π′i ) i=1 Following Pitman (2002) we refer to this process as π — GEM(α0). It should be noted that E∞k=1 πk = 1,5 and P(i) = πi. Then, according to the DP, P(φi) = πi. The complete model, is shown graphically in Figure 3(a). To build intuition, we walk through the process of generating from the infinite mixture model for the document example, where xi is the word at position i, and zi is its topic. F is a multinomial distribution parameterized by 0, and H is a Dirichlet distribution. Instead of generating all of the infinite mixture components (πk)∞k=1 at once, we can build them up incrementally. If there are K known topics, </context>
</contexts>
<marker>Pitman, 2002</marker>
<rawString>J. Pitman. 2002. Poisson-Dirichlet and GEM invariant distributions for split-and-merge transformations of an interval partition. Combinatorics, Probability and Computing, 11:501– 514.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N A Smith</author>
<author>J Eisner</author>
</authors>
<title>Contrastive estimation: Training log-linear models on unlabeled data.</title>
<date>2005</date>
<booktitle>In ACL</booktitle>
<contexts>
<context position="25049" citStr="Smith and Eisner, 2005" startWordPosition="4404" endWordPosition="4407">asses have arbitrary integer names, and are not guaranteed to correlate with the POS tag definitions. We found that the choice of α0 and Q (the concentration parameters) did not affect the output much, while the value of p (the parameter for the base Dirichlet distribution) made a much larger difference. For all reported experiments, we set α0 = Q = 10 and varied p. We use several metrics to evaluate the word classes. First, we use the standard approach of greedily assigning each of the learned classes to the POS tag with which it has the greatest overlap, and then computing tagging accuracy (Smith and Eisner, 2005; Haghighi and Klein, 2006).8 Additionally, we compute the mutual information of the learned clusters with the gold tags, and we compute the cluster F-score (Ghosh, 2003). See Table 1 for results of the different models, parameter settings, and metrics. Given the variance in the number of classes learned it is a little difficult to interpret these results, but it is clear that the Markov child model is the best; it achieves superior performance to the independent child model on all metrics, while learning fewer word classes. The poor performance of the simultaneous model warrants further inves</context>
</contexts>
<marker>Smith, Eisner, 2005</marker>
<rawString>N. A. Smith and J. Eisner. 2005. Contrastive estimation: Training log-linear models on unlabeled data. In ACL 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y W Teh</author>
<author>M I Jordan</author>
<author>M J Beal</author>
<author>D M Blei</author>
</authors>
<title>Hierarchical Dirichlet processes.</title>
<date>2006</date>
<journal>Journal of the American Statistical Association,</journal>
<pages>101--1566</pages>
<contexts>
<context position="1752" citStr="Teh et al. (2006)" startWordPosition="256" endWordPosition="259">h tags, which increases the accuracy of a generative dependency parser from 85.11% to 87.35%. 1 Introduction Model-based unsupervised learning techniques have historically lacked good methods for choosing the number of unseen components. For example, kmeans or EM clustering require advance specification of the number of mixture components. But the introduction of nonparametric priors such as the Dirichlet process (Ferguson, 1973) enabled development of infinite mixture models, in which the number of hidden components is not fixed, but emerges naturally from the training data (Antoniak, 1974). Teh et al. (2006) proposed the hierarchical Dirichlet process (HDP) as a way of applying the Dirichlet process (DP) to more complex model forms, so as to allow multiple, group-specific, infinite mixture models to share their mixture components. The closely related infinite hidden Markov model is an HMM in which the transitions are modeled using an HDP, enabling unsupervised learning of sequence models when the number of hidden states is unknown (Beal et al., 2002; Teh et al., 2006). We extend this work by introducing the infinite tree model, which represents recursive branching structure over a potentially inf</context>
<context position="15839" citStr="Teh et al., 2006" startWordPosition="2751" endWordPosition="2754">ly infinite. We achieve this by representing each of the variables as a broken stick, an don’t πk φk. πk πk d adopt the same approach of φ1 φ2 φ3 φ4 φ5 φ6 φ7 . . . β : πj : . . . &apos;y β α0 πk H Ok 00 x1 x2 x3 z1 z2 z3 β|7 ∼ GEM(7) πk|α0, β ∼ DP(α0, β) 0k|H ∼ H Figure 5: A graphical representation of the infinite independent child model. sampling each πk from a DP with base measure β. For the dependency tree application, Ok is a vector representing the parameters of a multinomial over words, and H is a Dirichlet distribution. The infinite hidden Markov model (iHMM) or HDP-HMM (Beal et al., 2002; Teh et al., 2006) is a model of sequence data with transitions modeled by an HDP.6 The iHMM can be viewed as a special case of this model, where each state (except the stop state) produces exactly one child. 4.2 Simultaneous Children The key problem in the definition of the simultaneous children model is that of defining a distribution over the lists of children produced by each state, since each child in the list has as its domain the positive integers, representing the infinite set of possible states. Our solution is to construct a distribution Lk over lists of states from the distribution over individual st</context>
<context position="17173" citStr="Teh et al. (2006)" startWordPosition="2985" endWordPosition="2988">′ t′∈c(t) t′∈c(t) However, we want our model to be able to represent the fact that some child lists, ct, are more or less probable than the product of the individual child probabilities would indicate. To address this, we can sample a state-conditional distribution over child lists Ak from a DP with Lk as a base measure. 6The original iHMM paper (Beal et al., 2002) predates, and was the motivation for, the work presented in Teh et al. (2006), and is the origin of the term hierarchical Dirichlet process. However, they used the term to mean something slightly different than the HDP presented in Teh et al. (2006), and presented a sampling scheme for inference that was a heuristic approximation of a Gibbs sampler. Thus, we augment the basic model given in the previous section with the variables (, Lk, and Ak: Lk|πk — Deterministic, as described above Ak|(, Lk — DP((, Lk) ct|Ak — Ak An important consequence of defining Lk locally (instead of globally, using β instead of the πks) is that the model captures not only what sequences of children a state prefers, but also the individual children that state prefers; if a state gives high probability to some particular sequence of children, then it is likely to</context>
<context position="19249" citStr="Teh et al. (2006)" startWordPosition="3362" endWordPosition="3365">ine a few count variables. Recall from Figure 4 that each state k has a local stick πk, each element of which corresponds to an element of β. In our sampling procedure, we only keep elements of πk and β which correspond to states observed in the data. We define the variable mjk to be the number of elements of the finite observed portion of πk which correspond to Qj and njk to be the number of observations with state k whose parent’s state is j. We also need a few model-specific counts. For the simultaneous children model we need njz, which is 7We adapt one of the sampling schemes mentioned by Teh et al. (2006) for use in the iHMM. This paper suggests two sampling schemes for inference, but does not explicitly present them. Upon discussion with one of the authors (Y. W. Teh, 2006, p.c.), it became clear that inference using the augmented representation is much more complicated than initially thought. 276 the number of times the state sequence z occurred as the children of state j. For the Markov children model we need the count variable njik which is the number of observations for a node with state k whose parent’s state is j and whose previous sibling’s state is i. In all cases we represent margina</context>
</contexts>
<marker>Teh, Jordan, Beal, Blei, 2006</marker>
<rawString>Y. W. Teh, M.I. Jordan, M. J. Beal, and D.M. Blei. 2006. Hierarchical Dirichlet processes. Journal of the American Statistical Association, 101:1566–1581.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yamada</author>
<author>Y Matsumoto</author>
</authors>
<title>Statistical dependency analysis with support vector machines.</title>
<date>2003</date>
<booktitle>In Proceedings of IWPT,</booktitle>
<pages>195--206</pages>
<contexts>
<context position="23925" citStr="Yamada and Matsumoto (2003)" startWordPosition="4205" endWordPosition="4208">rivial: we have two copies of each of njik + α0βk nji· + α0 f−xt k (xt) = 277 the variables Irk, one each for the left and the right. Generation of dependents on the right is completely independent of that for the left. The modifications of the other models are similar, but now there are separate sets of Irk variables for the Markov child model, and separate Lk and Ak variables for the simultaneous child model, for each of the left and right. For both experiments, we used dependency trees extracted from the Penn Treebank (Marcus et al., 1993) using the head rules and dependency extractor from Yamada and Matsumoto (2003). As is standard, we used WSJ sections 2–21 for training, section 22 for development, and section 23 for testing. 6.1 Unsupervised POS Learning In the first experiment, we do unsupervised part-ofspeech learning conditioned on dependency trees. To be clear, the input to our algorithm is the dependency structure skeleton of the corpus, but not the POS tags, and the output is a labeling of each of the words in the tree for word class. Since the model knows nothing about the POS annotation, the new classes have arbitrary integer names, and are not guaranteed to correlate with the POS tag definitio</context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>H. Yamada and Y. Matsumoto. 2003. Statistical dependency analysis with support vector machines. In Proceedings of IWPT, pages 195–206.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>