<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.015833">
<title confidence="0.988169">
Latent Class Transliteration based on Source Language Origin
</title>
<author confidence="0.994311">
Masato Hagiwara
</author>
<affiliation confidence="0.996362">
Rakuten Institute of Technology, New York
</affiliation>
<address confidence="0.83339">
215 Park Avenue South, New York, NY
</address>
<email confidence="0.995451">
masato.hagiwara@mail.rakuten.com
</email>
<author confidence="0.969398">
Satoshi Sekine
</author>
<affiliation confidence="0.979042">
Rakuten Institute of Technology, New York
</affiliation>
<address confidence="0.823958">
215 Park Avenue South, New York, NY
</address>
<email confidence="0.996417">
satoshi.b.sekine@mail.rakuten.com
</email>
<sectionHeader confidence="0.995616" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99945635">
Transliteration, a rich source of proper noun
spelling variations, is usually recognized by
phonetic- or spelling-based models. How-
ever, a single model cannot deal with dif-
ferent words from different language origins,
e.g., “get” in “piaget” and “target.” Li et
al. (2007) propose a method which explicitly
models and classifies the source language ori-
gins and switches transliteration models ac-
cordingly. This model, however, requires an
explicitly tagged training set with language
origins. We propose a novel method which
models language origins as latent classes. The
parameters are learned from a set of translit-
erated word pairs via the EM algorithm. The
experimental results of the transliteration task
of Western names to Japanese show that the
proposed model can achieve higher accuracy
compared to the conventional models without
latent classes.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.985371545454546">
Transliteration (e.g., “,1�7���-7 baraku obama /
Barak Obama”) is phonetic translation between lan-
guages with different writing systems. Words are
often transliterated when imported into differet lan-
guages, which is a major cause of spelling variations
of proper nouns in Japanese and many other lan-
guages. Accurate transliteration is also the key to
robust machine translation systems.
Phonetic-based rewriting models (Knight and
Jonathan, 1998) and spelling-based supervised mod-
els (Brill and Moore, 2000) have been proposed for
</bodyText>
<page confidence="0.977704">
53
</page>
<bodyText confidence="0.999165352941177">
recognizing word-to-word transliteration correspon-
dence. These methods usually learn a single model
given a training set. However, single models cannot
deal with words from multiple language origins. For
example, the “get” parts in “piaget / piaje”
(French origin) and “target / 3r—WJ t¯agetto”
(English origin) may differ in how they are translit-
erated depending on their origins.
Li et al. (2007) tackled this issue by proposing a
class transliteration model, which explicitly models
and classifies origins such as language and genders,
and switches corresponding transliteration model.
This method requires training sets of transliterated
word pairs with language origin. However, it is diffi-
cult to obtain such tagged data, especially for proper
nouns, a rich source of transliterated words. In ad-
dition, the explicitly tagged language origins are not
necessarily helpful for loanwords. For example, the
word “spaghetti” (Italian origin) can also be found
in an English dictionary, but applying an English
model can lead to unwanted results.
In this paper, we propose a latent class transliter-
ation model, which models the source language ori-
gin as unobservable latent classes and applies appro-
priate transliteration models to given transliteration
pairs. The model parameters are learned via the EM
algorithm from training sets of transliterated pairs.
We expect that, for example, a latent class which is
mostly occupied by Italian words would be assigned
to “spaghetti / A,, WT4supageti” and the pair will
be correctly recognized.
In the evaluation experiments, we evaluated the
accuracy in estimating a corresponding Japanese
transliteration given an unknown foreign word,
</bodyText>
<note confidence="0.8405535">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 53–57,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<figureCaption confidence="0.9970875">
Figure 1: Minimum edit operation sequence in the alpha-
beta model (Underlined letters are match operations)
</figureCaption>
<bodyText confidence="0.998856">
using lists of Western names with mixed lan-
guages. The results showed that the proposed model
achieves higher accuracy than conventional models
without latent classes.
Related researches include Llitjos and Black
(2001), where it is shown that source language ori-
gins may improve the pronunciation of proper nouns
in text-to-speech systems. Another one by Ahmad
and Kondrak (2005) estimates character-based error
probabilities from query logs via the EM algorithm.
This model is less general than ours because it only
deals with character-based error probability.
</bodyText>
<sectionHeader confidence="0.99885" genericHeader="method">
2 Alpha-Beta Model
</sectionHeader>
<bodyText confidence="0.999918125">
We adopted the alpha-beta model (Brill and Moore,
2000), which directly models the string substitu-
tion probabilities of transliterated pairs, as the base
model in this paper. This model is an extension to
the conventional edit distance, and gives probabil-
ities to general string substitutions in the form of
α → Q (α, Q are strings of any length). The whole
probability of rewriting word s with t is given by:
</bodyText>
<equation confidence="0.9911225">
PAB(t|s) = max
�����t���,�:���t���
</equation>
<bodyText confidence="0.99971">
where Part(x) is all the possible partitions of word
x. Taking logarithm and regarding − log P(α → Q)
as the substitution cost of α → Q, this maximiza-
tion is equivalent to finding a minimum of total sub-
stitution costs, which can be solved by normal dy-
namic programming (DP). In practice, we condi-
tioned P(α → Q) by the position of α in words,
i.e., at the beginning, in the middle, or at the end of
the word. This conditioning is simply omitted in the
equations in this paper.
The substitution probabilities P(α → Q) are
learned from transliterated pairs. Firstly, we obtain
an edit operation sequence using the normal DP for
edit distance computation. In Figure 1 the sequence
is f→f, a →u, l→r, e→e, E →k, x→k, ... and so on.
Secondly, non-match operations are merged with ad-
jacent edit operations, with the maximum length of
substitution pairs limited to W. When W = 2,
for example, the first non-match operation a →u is
merged with one operation on the left and right, pro-
ducing f→fu and l→ur. Finally, substitution prob-
abilities are calculated as relative frequencies of all
substitution operations created in this way. Note that
the minimum edit operation sequence is not unique,
so we take the averaged frequencies of all the possi-
ble minimum sequences.
</bodyText>
<sectionHeader confidence="0.996859" genericHeader="method">
3 Class Transliteration Model
</sectionHeader>
<bodyText confidence="0.999939954545455">
The alpha-beta model showed better performance in
tasks such as spelling correction (Brill and Moore,
2000), transliteration (Brill et al., 2001), and query
alteration (Hagiwara and Suzuki, 2009). However,
the substitution probabilities learned by this model
are simply the monolithic average of training set
statistics, and cannot be switched depending on the
source language origin of given pairs, as explained
in Section 1.
Li et al. (2007) pointed out that similar problems
arise in Chinese. Transliteration of Indo-European
names such as “-M�-k / Alexandra” can be ad-
dressed by Mandarin pronunciation (Pinyin) “Ya-Li-
Shan-Da,” while Japanese names such as “�U* /
Yamamoto” can only be addressed by considering
the Japanese pronunciation, not the Chinese pro-
nunciation “Shan-Ben.” Therefore, Li et al. took
into consideration two additional factors, i.e., source
language origin l and gender / first / last names g,
and proposed a model which linearly combines the
conditioned probabilities P(t|s, l, g) to obtain the
transliteration probability of s → t as:
</bodyText>
<equation confidence="0.96319475">
�P(t|s)gott = P(t,l, g|s)
l,g
�= P(t|s,l,g)P(l,g|s) (2)
l,g
</equation>
<bodyText confidence="0.999781">
We call the factors c = (l, g) as classes in this paper.
This model can be interpreted as firstly computing
</bodyText>
<equation confidence="0.69483325">
s:
t:
�A P(αz → QZ), (1)
Z=1
</equation>
<page confidence="0.982249">
54
</page>
<bodyText confidence="0.997454666666667">
the class probability distribution given P(c|s) then
taking a weighted sum of P(t|s, c) with regard to
the estimated class c and the target t.
Note that this weighted sum can be regarded
as doing soft-clustering of the input s into classes
with probabilities. Alternatively, we can employ
hard-clustering by taking one class such that c∗ =
arg maxi g P(l, g|s) and compute the transliteration
probability by:
</bodyText>
<equation confidence="0.960652">
P(t|s)hard ∝ P(t|s,c*). (3)
</equation>
<sectionHeader confidence="0.994999" genericHeader="method">
4 Latent Class Transliteration Model
</sectionHeader>
<bodyText confidence="0.99953645">
The model explained in the previous section inte-
grates different transliteration models for words with
different language origins, but it requires us to build
class detection model c from training pairs explicitly
tagged with language origins.
Instead of assigning an explicit class c to each
transliterated pair, we can introduce a random vari-
able z and consider a conditioned string substitution
probability P(α —* Q|z). This latent class z cor-
responds to the classes of transliterated pairs which
share the same transliteration characteristics, such as
language origins and genders. Although z is not di-
rectly observable from sets of transliterated words,
we can compute it via EM algorithm so that it max-
imizes the training set likelihood as shown below.
Due to the space limitation, we only show the up-
date equations. Xtrain is the training set consisting
of transliterated pairs {(sn, tn)|1 &lt; n &lt; N}, N is
the number of training pairs, and K is the number of
latent classes.
</bodyText>
<equation confidence="0.9982198">
Parameters: P(z = k) = πk, P(α → β|z)
(4)
πkP(tn|sn, z = k)
E-Step: γnk = ∑K , (5)
k=1 πkP (tn|sn, z = k)
P(tn|sn, z) = max
TEPart(tn),SEPart(sn)
M-Step: π*k = N , Nk = ∑
N N γnk (6)
n=1
</equation>
<bodyText confidence="0.99937375">
Here, fn(α —* Q) is the frequency of substitution
pair α —* Q in the n-th transliterated pair, whose
calculation method is explained in Section 2. The
final transliteration probability is given by:
</bodyText>
<equation confidence="0.989755">
∑Platent(t|s) = P (t, z|s) = ∑ P(z|s)P(t|s, z)
z z
∑∝ πkP(s|z)P(t|s, z) (7)
z
</equation>
<bodyText confidence="0.99972175">
The proposed model cannot explicitly model
P(s|z), which is in practice approximated by
P(t|s, z). Even omitting this factor only has a
marginal effect on the performance (within 1.1%).
</bodyText>
<sectionHeader confidence="0.999602" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999989333333333">
Here we evaluate the performance of the transliter-
ation models as an information retrieval task, where
the model ranks target t0 for a given source s0, based
on the model P(t0|s0). We used all the t0n in the
test set Xtest= {(s0n, t0n)|1 &lt; n &lt; M} as target
candidates and s0n for queries. Five-fold cross vali-
dation was adopted when learning the models, that
is, the datasets described in the next subsections are
equally splitted into five folds, of which four were
used for training and one for testing. The mean re-
ciprocal rank (MRR) of top 10 ranked candidates
was used as a performance measure.
</bodyText>
<subsectionHeader confidence="0.962518">
5.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.9851788">
Dataset 1: Western Person Name List This
dataset contains 6,717 Western person names and
their Katakana readings taken from an European
name website V L��U 1, consisting of Ger-
man (de), English (en), and French (fr) person name
pairs. The numbers of pairs for these languages are
2,470, 2,492, and 1,747, respectively. Accent marks
for non-English languages were left untouched. Up-
percase was normalized to lowercase.
Dataset 2: Western Proper Noun List This
dataset contains 11,323 proper nouns and their
Japanese counterparts extracted from Wikipedia in-
terwiki. The languages and numbers of pairs con-
tained are: German (de): 2,003, English (en): 5,530,
Spanish (es): 781, French (fr): 1,918, Italian (it):
</bodyText>
<footnote confidence="0.586992">
1http://www.worldsys.org/europe/
</footnote>
<equation confidence="0.994444333333333">
∏ |S |P(αi → βi|z)
i=1
1 N
P(α → β |z = k)* = Nk ∑
fn(α → β)
∑α_β fn(α → β)
</equation>
<page confidence="0.780208">
γnk
n=1
55
</page>
<table confidence="0.917243">
Language de en fr Language de en es fr it
Precision(%) 80.4 77.1 74.7 Precision(%) 65.4 83.3 48.2 57.7 66.1
</table>
<tableCaption confidence="0.99957">
Table 1: Language Class Detection Result (Dataset 1)
</tableCaption>
<bodyText confidence="0.990490131578947">
1,091. Linked English and Japanese titles are ex-
tracted, unless the Japanese title contains any other
characters than Katakana, hyphen, or middle dot.
The language origin of titles were detected
whether appropriate country names are included in
the first sentence of Japanese articles. If they con-
tain “ドイツの (of Germany),” “フランスの (of
France),” “イタリアの (of Italy),” they are marked
as German, French, and Italian origin, respectively.
If the sentence contains any of Spain, Argentina,
Mexico, Peru, or Chile plus “の”(of), it is marked
as Spanish origin. If they contain any of Amer-
ica, England, Australia or Canada plus “の”(of), it
is marked as English origin. The latter parts of
Japanese/foreign titles starting from “,” or “(” were
removed. Japanese and foreign titles were split into
chunks by middle dots and “ ”, respectively, and re-
sulting chunks were aligned. Titles pairs with differ-
ent numbers of chunks, or ones with foreign char-
acter length less than 3 were excluded. All accent
marks were normalized (German “ß” was converted
to “ss”).
Implementation Details P(c|s) of the class
transliteration model was calculated by a charac-
ter 3-gram language model with Witten-Bell dis-
counting. Japanese Katakanas were all converted
to Hepburn-style Roman characters, with minor
changes so as to incorporate foreign pronunciations
such as “wi / ウィ” and “we / ウェ.” The hyphens
“ー” were replaced by the previous vowels (e.g., “ス
パゲッティー” is converted to “supagettii.”)
The maximum length of substitution pairs W de-
scribed in Section 2 was set W = 2. The EM al-
gorithm parameters P(α → Q|z) were initialized to
the probability P(α → Q) of the alpha-beta model
plus Gaussian noise, and Irk were uniformly initial-
ized to 1/K. Based on the preliminary results, we
repeated EM iterations for 40 times.
</bodyText>
<sectionHeader confidence="0.912503" genericHeader="evaluation">
5.2 Results
</sectionHeader>
<reference confidence="0.600325">
Language Class Detection We firstly show the
precision of language detection using the class
</reference>
<tableCaption confidence="0.97846">
Table 2: Language Class Detection Result (Dataset 2)
</tableCaption>
<table confidence="0.9999278">
Model Dataset 1 Dataset 2
AB 94.8 90.9
HARD 90.3 89.8
SOFT 95.7 92.4
LATENT 95.8 92.4
</table>
<tableCaption confidence="0.999751">
Table 3: Model Performance Comparison (MRR; %)
</tableCaption>
<bodyText confidence="0.999810352941176">
transliteration model P(c|s) and Equation (3) (Table
5.2, 5.2). The overall precision is relatively lower
than, e.g., Li et al. (2007), which is attributed to the
fact that European names can be quite ambiguous
(e.g., “Charles” can read “チャールズ ch¯aruzu” or
“シャルル sharuru”) The precision of Dataset 2 is
even worse because it has more classes. We can also
use the result of the latent class transliteration for
clustering by regarding k* = arg maxk &apos;Ynk as the
class of the pair. The resulting cluster purity way
was 0.74.
Transliteration Model Comparison We show
the evaluation results of transliteration candidate re-
trieval task using each of PAB(t|s) (AB), Phard(t|s)
(HARD), Pgoft(t|s) (SOFT), and Platent(t|s) (LA-
TENT) (Table 5.2). The number of latent classes
was K = 3 for Dataset 1 and K = 5 for Dataset 2,
which are the same as the numbers of language ori-
gins. LATENT shows comparable performance ver-
sus SOFT, although it can be higher depending on
the value of K, as stated below. HARD, on the other
hand, shows lower performance, which is mainly
due to the low precision of class detection. The de-
tection errors are alleviated in SOFT by considering
the weighted sum of transliteration probabilities.
We also conducted the evaluation based on the
top-1 accuracy of transliteration candidates. Be-
cause we found out that the tendency of the results
is the same as MRR, we simply omitted the result in
this paper.
The simplest model AB incorrectly reads “Felix
/ フェリックス,” “Read / リード” as “フィリス
Firisu” and “レアード Re¯ado.” This may be because
English pronunciation “x / ックス kkusu” and “ea /
</bodyText>
<page confidence="0.988593">
56
</page>
<bodyText confidence="0.999608666666667">
� ¯i” are influenced by other languages. SOFT
and LATENT can find correct candidates for these
pairs. Irregular pronunciation pairs such as “Caen
/ t ;/ k¯an” (French; misread “-/Y ;/ sh¯an”)
and “Laemmle / 1LA9 Remuri” (English; misread
“9アA Riamu”) were misread by SOFT but not by
LATENT. For more irregular cases such as “Hilda /
�1Lf Iruda”(English), it is difficult to find correct
counterparts even by LATENT.
Finally, we investigated the effect of the number
of latent classes K. The performance is higher when
K is slightly smaller than the number of language
origins in the dataset (e.g., K = 4 for Dataset 2) but
the performance gets unstable for larger values of K
due to the EM algorithm initial values.
</bodyText>
<sectionHeader confidence="0.999706" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99998375">
In this paper, we proposed a latent class translitera-
tion method which models source language origins
as latent classes. The model parameters are learned
from sets of transliterated words with different ori-
gins via the EM algorithm. The experimental re-
sult of Western person / proper name transliteration
task shows that, even though the proposed model
does not rely on explicit language origins, it achieves
higher accuracy versus conventional methods using
explicit language origins. Considering sources other
than Western languages as well as targets other than
Japanese is the future work.
</bodyText>
<sectionHeader confidence="0.999246" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999709272727273">
Farooq Ahmad and Grzegorz Kondrak. 2005. Learning a
spelling error model from search query logs. In Proc.
ofEMNLP-2005, pages 955–962.
Eric Brill and Robert C. Moore. 2000. An improved
error model for noisy channel spelling. In Proc. ACL-
2000, pages 286–293.
Eric Brill, Gary Kacmarcik, and Chris Brockett. 2001.
Automatically harvesting katakana-english term pairs
from search engine query logs. In Proc. NLPRS-2001,
pages 393–399.
Masato Hagiwara and Hisami Suzuki. 2009. Japanese
query alteration based on semantic similarity. In Proc.
ofNAACL-2009, page 191.
Kevin Knight and Graehl Jonathan. 1998. Machine
transliteration. Computational Linguistics, 24:599–
612.
Haizhou Li, Khe Chai Sum, Jin-Shea Kuo, and Minghui
Dong. 2007. Semantic transliteration of personal
names. In Proc. ofACL 2007, pages 120–127.
Ariadna Font Llitjos and Alan W. Black. 2001. Knowl-
edge of language origin improves pronunciation accu-
racy. In Proc. of Eurospeech, pages 1919–1922.
</reference>
<page confidence="0.999145">
57
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.870464">
<title confidence="0.997829">Latent Class Transliteration based on Source Language Origin</title>
<author confidence="0.980629">Masato Hagiwara</author>
<affiliation confidence="0.998084">Rakuten Institute of Technology, New</affiliation>
<address confidence="0.997463">215 Park Avenue South, New York,</address>
<email confidence="0.999914">masato.hagiwara@mail.rakuten.com</email>
<author confidence="0.908128">Satoshi Sekine</author>
<affiliation confidence="0.998338">Rakuten Institute of Technology, New</affiliation>
<address confidence="0.999267">215 Park Avenue South, New York,</address>
<email confidence="0.999961">satoshi.b.sekine@mail.rakuten.com</email>
<abstract confidence="0.999224857142857">Transliteration, a rich source of proper noun spelling variations, is usually recognized by phoneticor spelling-based models. However, a single model cannot deal with different words from different language origins, e.g., “get” in “piaget” and “target.” Li et al. (2007) propose a method which explicitly models and classifies the source language origins and switches transliteration models accordingly. This model, however, requires an explicitly tagged training set with language origins. We propose a novel method which models language origins as latent classes. The parameters are learned from a set of transliterated word pairs via the EM algorithm. The experimental results of the transliteration task of Western names to Japanese show that the proposed model can achieve higher accuracy compared to the conventional models without latent classes.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Language Class</author>
</authors>
<title>Detection We firstly show the precision of language detection using the class</title>
<marker>Class, </marker>
<rawString>Language Class Detection We firstly show the precision of language detection using the class</rawString>
</citation>
<citation valid="true">
<authors>
<author>Farooq Ahmad</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Learning a spelling error model from search query logs.</title>
<date>2005</date>
<booktitle>In Proc. ofEMNLP-2005,</booktitle>
<pages>955--962</pages>
<contexts>
<context position="4096" citStr="Ahmad and Kondrak (2005)" startWordPosition="598" endWordPosition="601">Computational Linguistics:shortpapers, pages 53–57, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics Figure 1: Minimum edit operation sequence in the alphabeta model (Underlined letters are match operations) using lists of Western names with mixed languages. The results showed that the proposed model achieves higher accuracy than conventional models without latent classes. Related researches include Llitjos and Black (2001), where it is shown that source language origins may improve the pronunciation of proper nouns in text-to-speech systems. Another one by Ahmad and Kondrak (2005) estimates character-based error probabilities from query logs via the EM algorithm. This model is less general than ours because it only deals with character-based error probability. 2 Alpha-Beta Model We adopted the alpha-beta model (Brill and Moore, 2000), which directly models the string substitution probabilities of transliterated pairs, as the base model in this paper. This model is an extension to the conventional edit distance, and gives probabilities to general string substitutions in the form of α → Q (α, Q are strings of any length). The whole probability of rewriting word s with t </context>
</contexts>
<marker>Ahmad, Kondrak, 2005</marker>
<rawString>Farooq Ahmad and Grzegorz Kondrak. 2005. Learning a spelling error model from search query logs. In Proc. ofEMNLP-2005, pages 955–962.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Robert C Moore</author>
</authors>
<title>An improved error model for noisy channel spelling.</title>
<date>2000</date>
<booktitle>In Proc. ACL2000,</booktitle>
<pages>286--293</pages>
<contexts>
<context position="1702" citStr="Brill and Moore, 2000" startWordPosition="242" endWordPosition="245">posed model can achieve higher accuracy compared to the conventional models without latent classes. 1 Introduction Transliteration (e.g., “,1�7���-7 baraku obama / Barak Obama”) is phonetic translation between languages with different writing systems. Words are often transliterated when imported into differet languages, which is a major cause of spelling variations of proper nouns in Japanese and many other languages. Accurate transliteration is also the key to robust machine translation systems. Phonetic-based rewriting models (Knight and Jonathan, 1998) and spelling-based supervised models (Brill and Moore, 2000) have been proposed for 53 recognizing word-to-word transliteration correspondence. These methods usually learn a single model given a training set. However, single models cannot deal with words from multiple language origins. For example, the “get” parts in “piaget / piaje” (French origin) and “target / 3r—WJ t¯agetto” (English origin) may differ in how they are transliterated depending on their origins. Li et al. (2007) tackled this issue by proposing a class transliteration model, which explicitly models and classifies origins such as language and genders, and switches corresponding transli</context>
<context position="4354" citStr="Brill and Moore, 2000" startWordPosition="636" endWordPosition="639">estern names with mixed languages. The results showed that the proposed model achieves higher accuracy than conventional models without latent classes. Related researches include Llitjos and Black (2001), where it is shown that source language origins may improve the pronunciation of proper nouns in text-to-speech systems. Another one by Ahmad and Kondrak (2005) estimates character-based error probabilities from query logs via the EM algorithm. This model is less general than ours because it only deals with character-based error probability. 2 Alpha-Beta Model We adopted the alpha-beta model (Brill and Moore, 2000), which directly models the string substitution probabilities of transliterated pairs, as the base model in this paper. This model is an extension to the conventional edit distance, and gives probabilities to general string substitutions in the form of α → Q (α, Q are strings of any length). The whole probability of rewriting word s with t is given by: PAB(t|s) = max �����t���,�:���t��� where Part(x) is all the possible partitions of word x. Taking logarithm and regarding − log P(α → Q) as the substitution cost of α → Q, this maximization is equivalent to finding a minimum of total substitutio</context>
<context position="6142" citStr="Brill and Moore, 2000" startWordPosition="944" endWordPosition="947">djacent edit operations, with the maximum length of substitution pairs limited to W. When W = 2, for example, the first non-match operation a →u is merged with one operation on the left and right, producing f→fu and l→ur. Finally, substitution probabilities are calculated as relative frequencies of all substitution operations created in this way. Note that the minimum edit operation sequence is not unique, so we take the averaged frequencies of all the possible minimum sequences. 3 Class Transliteration Model The alpha-beta model showed better performance in tasks such as spelling correction (Brill and Moore, 2000), transliteration (Brill et al., 2001), and query alteration (Hagiwara and Suzuki, 2009). However, the substitution probabilities learned by this model are simply the monolithic average of training set statistics, and cannot be switched depending on the source language origin of given pairs, as explained in Section 1. Li et al. (2007) pointed out that similar problems arise in Chinese. Transliteration of Indo-European names such as “-M�-k / Alexandra” can be addressed by Mandarin pronunciation (Pinyin) “Ya-LiShan-Da,” while Japanese names such as “�U* / Yamamoto” can only be addressed by consi</context>
</contexts>
<marker>Brill, Moore, 2000</marker>
<rawString>Eric Brill and Robert C. Moore. 2000. An improved error model for noisy channel spelling. In Proc. ACL2000, pages 286–293.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Gary Kacmarcik</author>
<author>Chris Brockett</author>
</authors>
<title>Automatically harvesting katakana-english term pairs from search engine query logs.</title>
<date>2001</date>
<booktitle>In Proc. NLPRS-2001,</booktitle>
<pages>393--399</pages>
<contexts>
<context position="6180" citStr="Brill et al., 2001" startWordPosition="949" endWordPosition="952"> length of substitution pairs limited to W. When W = 2, for example, the first non-match operation a →u is merged with one operation on the left and right, producing f→fu and l→ur. Finally, substitution probabilities are calculated as relative frequencies of all substitution operations created in this way. Note that the minimum edit operation sequence is not unique, so we take the averaged frequencies of all the possible minimum sequences. 3 Class Transliteration Model The alpha-beta model showed better performance in tasks such as spelling correction (Brill and Moore, 2000), transliteration (Brill et al., 2001), and query alteration (Hagiwara and Suzuki, 2009). However, the substitution probabilities learned by this model are simply the monolithic average of training set statistics, and cannot be switched depending on the source language origin of given pairs, as explained in Section 1. Li et al. (2007) pointed out that similar problems arise in Chinese. Transliteration of Indo-European names such as “-M�-k / Alexandra” can be addressed by Mandarin pronunciation (Pinyin) “Ya-LiShan-Da,” while Japanese names such as “�U* / Yamamoto” can only be addressed by considering the Japanese pronunciation, not</context>
</contexts>
<marker>Brill, Kacmarcik, Brockett, 2001</marker>
<rawString>Eric Brill, Gary Kacmarcik, and Chris Brockett. 2001. Automatically harvesting katakana-english term pairs from search engine query logs. In Proc. NLPRS-2001, pages 393–399.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masato Hagiwara</author>
<author>Hisami Suzuki</author>
</authors>
<title>Japanese query alteration based on semantic similarity.</title>
<date>2009</date>
<booktitle>In Proc. ofNAACL-2009,</booktitle>
<pages>191</pages>
<contexts>
<context position="6230" citStr="Hagiwara and Suzuki, 2009" startWordPosition="956" endWordPosition="959"> When W = 2, for example, the first non-match operation a →u is merged with one operation on the left and right, producing f→fu and l→ur. Finally, substitution probabilities are calculated as relative frequencies of all substitution operations created in this way. Note that the minimum edit operation sequence is not unique, so we take the averaged frequencies of all the possible minimum sequences. 3 Class Transliteration Model The alpha-beta model showed better performance in tasks such as spelling correction (Brill and Moore, 2000), transliteration (Brill et al., 2001), and query alteration (Hagiwara and Suzuki, 2009). However, the substitution probabilities learned by this model are simply the monolithic average of training set statistics, and cannot be switched depending on the source language origin of given pairs, as explained in Section 1. Li et al. (2007) pointed out that similar problems arise in Chinese. Transliteration of Indo-European names such as “-M�-k / Alexandra” can be addressed by Mandarin pronunciation (Pinyin) “Ya-LiShan-Da,” while Japanese names such as “�U* / Yamamoto” can only be addressed by considering the Japanese pronunciation, not the Chinese pronunciation “Shan-Ben.” Therefore, </context>
</contexts>
<marker>Hagiwara, Suzuki, 2009</marker>
<rawString>Masato Hagiwara and Hisami Suzuki. 2009. Japanese query alteration based on semantic similarity. In Proc. ofNAACL-2009, page 191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Graehl Jonathan</author>
</authors>
<date>1998</date>
<booktitle>Machine transliteration. Computational Linguistics,</booktitle>
<pages>24--599</pages>
<contexts>
<context position="1641" citStr="Knight and Jonathan, 1998" startWordPosition="233" endWordPosition="236">ansliteration task of Western names to Japanese show that the proposed model can achieve higher accuracy compared to the conventional models without latent classes. 1 Introduction Transliteration (e.g., “,1�7���-7 baraku obama / Barak Obama”) is phonetic translation between languages with different writing systems. Words are often transliterated when imported into differet languages, which is a major cause of spelling variations of proper nouns in Japanese and many other languages. Accurate transliteration is also the key to robust machine translation systems. Phonetic-based rewriting models (Knight and Jonathan, 1998) and spelling-based supervised models (Brill and Moore, 2000) have been proposed for 53 recognizing word-to-word transliteration correspondence. These methods usually learn a single model given a training set. However, single models cannot deal with words from multiple language origins. For example, the “get” parts in “piaget / piaje” (French origin) and “target / 3r—WJ t¯agetto” (English origin) may differ in how they are transliterated depending on their origins. Li et al. (2007) tackled this issue by proposing a class transliteration model, which explicitly models and classifies origins suc</context>
</contexts>
<marker>Knight, Jonathan, 1998</marker>
<rawString>Kevin Knight and Graehl Jonathan. 1998. Machine transliteration. Computational Linguistics, 24:599– 612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haizhou Li</author>
<author>Khe Chai Sum</author>
<author>Jin-Shea Kuo</author>
<author>Minghui Dong</author>
</authors>
<title>Semantic transliteration of personal names.</title>
<date>2007</date>
<booktitle>In Proc. ofACL</booktitle>
<pages>120--127</pages>
<contexts>
<context position="2127" citStr="Li et al. (2007)" startWordPosition="308" endWordPosition="311">transliteration is also the key to robust machine translation systems. Phonetic-based rewriting models (Knight and Jonathan, 1998) and spelling-based supervised models (Brill and Moore, 2000) have been proposed for 53 recognizing word-to-word transliteration correspondence. These methods usually learn a single model given a training set. However, single models cannot deal with words from multiple language origins. For example, the “get” parts in “piaget / piaje” (French origin) and “target / 3r—WJ t¯agetto” (English origin) may differ in how they are transliterated depending on their origins. Li et al. (2007) tackled this issue by proposing a class transliteration model, which explicitly models and classifies origins such as language and genders, and switches corresponding transliteration model. This method requires training sets of transliterated word pairs with language origin. However, it is difficult to obtain such tagged data, especially for proper nouns, a rich source of transliterated words. In addition, the explicitly tagged language origins are not necessarily helpful for loanwords. For example, the word “spaghetti” (Italian origin) can also be found in an English dictionary, but applying</context>
<context position="6478" citStr="Li et al. (2007)" startWordPosition="995" endWordPosition="998">s way. Note that the minimum edit operation sequence is not unique, so we take the averaged frequencies of all the possible minimum sequences. 3 Class Transliteration Model The alpha-beta model showed better performance in tasks such as spelling correction (Brill and Moore, 2000), transliteration (Brill et al., 2001), and query alteration (Hagiwara and Suzuki, 2009). However, the substitution probabilities learned by this model are simply the monolithic average of training set statistics, and cannot be switched depending on the source language origin of given pairs, as explained in Section 1. Li et al. (2007) pointed out that similar problems arise in Chinese. Transliteration of Indo-European names such as “-M�-k / Alexandra” can be addressed by Mandarin pronunciation (Pinyin) “Ya-LiShan-Da,” while Japanese names such as “�U* / Yamamoto” can only be addressed by considering the Japanese pronunciation, not the Chinese pronunciation “Shan-Ben.” Therefore, Li et al. took into consideration two additional factors, i.e., source language origin l and gender / first / last names g, and proposed a model which linearly combines the conditioned probabilities P(t|s, l, g) to obtain the transliteration probab</context>
</contexts>
<marker>Li, Sum, Kuo, Dong, 2007</marker>
<rawString>Haizhou Li, Khe Chai Sum, Jin-Shea Kuo, and Minghui Dong. 2007. Semantic transliteration of personal names. In Proc. ofACL 2007, pages 120–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ariadna Font Llitjos</author>
<author>Alan W Black</author>
</authors>
<title>Knowledge of language origin improves pronunciation accuracy.</title>
<date>2001</date>
<booktitle>In Proc. of Eurospeech,</booktitle>
<pages>1919--1922</pages>
<contexts>
<context position="3935" citStr="Llitjos and Black (2001)" startWordPosition="572" endWordPosition="575">the accuracy in estimating a corresponding Japanese transliteration given an unknown foreign word, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 53–57, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics Figure 1: Minimum edit operation sequence in the alphabeta model (Underlined letters are match operations) using lists of Western names with mixed languages. The results showed that the proposed model achieves higher accuracy than conventional models without latent classes. Related researches include Llitjos and Black (2001), where it is shown that source language origins may improve the pronunciation of proper nouns in text-to-speech systems. Another one by Ahmad and Kondrak (2005) estimates character-based error probabilities from query logs via the EM algorithm. This model is less general than ours because it only deals with character-based error probability. 2 Alpha-Beta Model We adopted the alpha-beta model (Brill and Moore, 2000), which directly models the string substitution probabilities of transliterated pairs, as the base model in this paper. This model is an extension to the conventional edit distance,</context>
</contexts>
<marker>Llitjos, Black, 2001</marker>
<rawString>Ariadna Font Llitjos and Alan W. Black. 2001. Knowledge of language origin improves pronunciation accuracy. In Proc. of Eurospeech, pages 1919–1922.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>