<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99706075">
The NOMAD System:
Expectation-Based Detection and
Correction of Errors during Understanding of
Syntactically and Semantically III-Formed Textl
</title>
<author confidence="0.954866">
Richard H. Granger
</author>
<affiliation confidence="0.908561333333333">
Artificial Intelligence Project, Computer Science Department
and Cognitive Sciences Program
University of California
</affiliation>
<sectionHeader confidence="0.38234" genericHeader="abstract">
Irvine, CA 92717
</sectionHeader>
<bodyText confidence="0.989788">
Most large text-understanding systems have been designed under the assumption that
the input text will be in reasonably &amp;quot;neat&amp;quot; form (for example, newspaper stories and other
edited texts). However, a great deal of natural language text (for example, memos,
messages, rough drafts, conversation transcripts, etc.) have features that differ significantly
from &amp;quot;neat&amp;quot; texts, posing special problems for readers, such as misspelled words, missing
words, poor syntactic construction, unclear or ambiguous interpretation, missing crucial
punctuation, etc. Our solution to these problems is to make use of expectations, based both
on knowledge of surface English and on world knowledge of the situation being described.
These syntactic and semantic expectations can be used to figure out unknown words from
context, constrain the possible word senses of words with multiple meanings (ambiguity), fill
in missing words (ellipsis), and resolve referents (anaphora). This method of using expecta-
tions to aid the understanding of &amp;quot;scruffy&amp;quot; texts has been incorporated into a working
computer program called NOMAD, which understands scruffy texts in the domain of Navy
ship-to-shore messages.
</bodyText>
<sectionHeader confidence="0.992143" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.978207173913044">
The NOMAD system takes unedited English input in a
constrained domain, and works interactively with the
user to encode the message into database-readable
form. The unedited texts in this domain are Naval
ship-to-shore messages, written in &apos;telegraphic&apos; Eng-
lish, often leaving out nouns and verbs, crucial punctu-
ation (such as periods), and making use of ad hoc
abbreviations of words. In addition to these problems
of surface-text processing, these texts can contain
problems of interpretation — that is, which of several
objects is being referred to, or which possible goal
inference is implied. These semantic processing prob-
lems are not easily detectable or solvable based on the
surface text alone but rather require a data base of
1 This research was supported in part by the Naval Ocean
Systems Center under contracts N-00123-81-C-1078 and N6600 I -
83-C-0255, and by the National Science Foundation under grant
1ST-81-20685.
knowledge about the domain of discourse, in this case
ship movements.
Here are examples of each of these two types of
problems. First, one with a number of surface-text
errors:
</bodyText>
<listItem confidence="0.677061">
(1) &apos;Locked on open fired destroyed&apos;
</listItem>
<bodyText confidence="0.948076933333333">
Example (1) is missing crucial punctuation (no bound-
aries separating the three clauses from each other), is
missing subjects and objects for all three verb phrases,
and has a tense mismatch in the middle phrase (&apos;open
fired&apos;). (This is an actual message in the corpus pro-
vided to us by the Navy, not a constructed example.)
NOMAD&apos;s output from this example is:
We aimed at an unknown object.
We fired at the object.
The object was destroyed.
A second message has, in addition to some surface
problems, a goal-based interpretation problem:
Copyright 1984 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted
provided that the copies are not made for direct commercial advantage and the Journal reference and this copyright notice are included on
the first page. To copy otherwise, or to republish, requires a fee and/or specific permission.
</bodyText>
<page confidence="0.5054415">
0362-613X/83/030188-09$03.00
188 American Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983
</page>
<note confidence="0.673416">
Richard H. Granger The NOMAD System
</note>
<bodyText confidence="0.991400714285714">
(2) &apos;Returned bombs to Kashin.&apos;
In addition to the surface problem of a missing sub-
ject, this example is apparently missing mention of
some previous event, implied by the use of &apos;returned&apos;;
and it describes an ambiguous event, that is, either the
peaceable delivery of bombs to the Kashin ship (a
type of enemy ship) or a battle action of firing bombs
in retaliation. Since the input is ambiguous without
the previous message, NOMAD returns a number of
alternative possible outputs to the user, marking one
as &amp;quot;preferred&amp;quot;:
(Preferred Interpretation):
We fired some bombs at a Kashin ship.
(Inferred):
The Kashin ship fired at us previously.
(Alternate Interpretation):
We delivered some bombs to a Kashin ship.
(Inferred):
The Kashin ship had delivered some bombs to
us previously.
NOMAD is interactive: it produces multiple inter-
pretations when necessary, and lets the message-
sender choose among these alternatives. A typical
scenario is:
■ the user (message-sender) will enter a &apos;telegraphic&apos;
message;
■ NOMAD will produce two different possible inter-
pretations of the message in corrected English, and
present them to the user;
■ the user will then choose one of the interpretations;
and
■ a database-readable version of the correctly-
interpreted message is then forwarded from the
ship to a central data base.
Many of the approaches to understanding ill-
formed input focus on syntactic errors separately from
semantic errors (for example, Hayes and Mouradian
1981 and Kwasny and Sondheimer 1981). Both of
these efforts essentially attempt to increase the flexi-
bility of an ATN syntactic parser: the first by using
&apos;parse suspension and continuation&apos;, relaxing con-
straints on consistency and permitting matches out of
their correct order, and the second by relaxing the
constraints required to traverse an ATN arc, and then
providing &apos;deviance notes&apos; specifying the differences
between what was expected and what was actually
seen. These efforts attempt to correct the surface
form of the input, that is, to perform a transformation
from an ill-formed English text to a well-formed Eng-
lish text. Their goals are not to produce a meaning
representation of the input, and hence cannot be said
to &apos;understand&apos; the input. This also leads to the ina-
bility of these systems to generate alternative interpre-
tations of text; once these systems have guessed at a
parse, they cannot back up and re-parse in response to
information from a user.
The approach taken by Hayes and Carbonell
(1981) is closer to that described in this paper, in that
they do build meaning representations. However,
there are still shortcomings; in particular, their systems
cannot understand texts in which a missing or un-
known word is the one that would have built the main
semantic case frame. As will be seen below, NOMAD
builds on the FOUL-UP system (Granger 1977) to
handle such cases (which are frequent in our domain).
Furthermore, like the systems described above, their
systems cannot re-interpret a text when its initial in-
terpretation turns out to be incorrect.
We propose an integrated system of syntactic and
semantic processing, in which world knowledge and
syntactic knowledge are both applied during text proc-
cessing to provide a number of possible interpretations
of a text. Our focus is on interpretations: the goal of
the system is to give rise to an unambiguous meaning
representation. If surface-text problems occur during
processing but an unambiguous interpretation can be
provided and confirmed by the user, then the surface-
text problems are ignored. It is only when interpreta-
tion problems arise that any noted surface-text prob-
lems will be consulted to see if they might have been
the source of the interpretation problem. That is, we
are attempting to attack the overall problem of proc-
essing text, of which the processing of ill-formed text
is a necessary subpart. Our approach implies that the
processing of ill-formed text &apos;falls out&apos; of normal text
processing, via the application of generalized error-
correction processes that operate equally on syntax,
semantics, and pragmatics, and are not designed spe-
cifically for the processing of ill-formed surface text.
NOMAD builds on previous work on conceptual
analysis (Riesbeck and Schank 1976, Birnbaum and
Selfridge 1979), and on error detection and correction
during conceptual analysis (Granger 1977, 1980,
1982a). Selfridge and Engelberg (1984), Lebowitz
(1984), and Dyer (1983) have also recently taken
approaches that are similar to the one proposed here,
attempting to fully exploit the power of integrated
understanding. NOMAD incorporates and integrates
error detection and correction algorithms based on
both syntactic and pragmatic error types, and is there-
fore capable of correctly processing a wide range of
ill-formed texts within the knowledge domain of Navy
messages. NOMAD has actually been installed and is
being used for message processing by the Naval Ocean
Systems Center (NOSC) at San Diego.
</bodyText>
<note confidence="0.307889">
American Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983 189
Richard H. Granger The NOMAD System
</note>
<sectionHeader confidence="0.643938" genericHeader="method">
2. Background: Tolerant Text Processing
</sectionHeader>
<subsectionHeader confidence="0.8953865">
2.1. FOUL-UP figured out unknown words from
context
</subsectionHeader>
<bodyText confidence="0.990884571428571">
The FOUL-UP program (Figuring Out Unknown Lex-
emes in the Understanding Process; Granger 1977)
was the first program that could figure out meanings
of unknown words encountered during text under-
standing. FOUL-UP was an attempt to model the cor-
responding human ability commonly known at
&amp;quot;figuring out a word from context&amp;quot;. FOUL-UP worked
with the SAM system (Cullingford 1977), using the
expectations generated by scripts (Schank and Abelson
1977) to restrict the possible meanings of a word,
based on what object or action would have occurred in
that position according to the script for the story.
For instance, consider the following excerpt from a
newspaper report of a car accident:
</bodyText>
<listItem confidence="0.875915">
(1) Friday, a car swerved off Route 69. The vehicle
struck an embankment.
</listItem>
<bodyText confidence="0.999963823529412">
The word &amp;quot;embankment&amp;quot; was unknown to the SAM
system, but it had encoded predictions about certain
attributes of the expected conceptual object of the
PROPEL action (the object that the vehicle struck);
namely, that it would be a physical object, and would
function as an &amp;quot;obstruction&amp;quot; in the vehicle-accident
script. (In addition, the conceptual analyzer (ELI —
Riesbeck and Schank 1976) had the expectation that
the word in that sentence position would be a noun.)
Hence, when the unknown word was encountered,
FOUL-UP would make use of those expected attributes
to construct a memory entry for the word
&amp;quot;embankment&amp;quot;, indicating that it was a noun, a physi-
cal object, and an &amp;quot;obstruction&amp;quot; in vehicle-accident
situations. It would then create a dictionary definition
that the system would use from then on whenever the
word was encountered in this context.
</bodyText>
<subsectionHeader confidence="0.965689">
2.2. Syntactic (surface) and semantic
(interpreation) text errors
</subsectionHeader>
<bodyText confidence="0.95332003125">
But even if the SAM system had known the word
&amp;quot;embankment&amp;quot;, it would not have been able to handle
a less edited version of the story, such as this
&apos;telegraphic&apos; message, which might have been sent in
by an on-the-scene reporter:
(2) Vehcle acc Rt69; car strck embankment; drivr
dead one psngr inj; ser dmg to car full rpt
frthcmng.
While human readers would have little difficulty un-
derstanding this text, no existing computer programs
could do so.
The scope of this problem is wide; examples of
texts that present &amp;quot;scruffy&amp;quot; difficulties to readers are
completely unedited texts, such as messages composed
in a hurry, with little or no re-writing, rough drafts,
memos, transcripts of conversations, etc. Such texts
may contain these problems, among others: missing
words, ad hoc abbreviations of words, poor syntax,
confusing order of presentation of ideas, misspellings,
lack of punctuation. Even edited texts such as news-
paper stories often contain misspellings, words un-
known to the reader, and ambiguities; and even appar-
ently very simple texts may contain alternative possi-
ble interpretations, which can cause a reader to con-
struct erroneous initial inferences that must later be
corrected (see Granger 1980, 1981a, 1981b).
The following sections describe the NOMAD sys-
tem, which incorporates FOUL-UP&apos;s abilities as well as
significantly extended abilities to use syntactic and
semantic expectations to resolve these difficulties, in
the domain of Navy messages. NOMAD&apos;s processing is
divided into two major categories:
</bodyText>
<listItem confidence="0.938096166666667">
(1) blame assignment, that is, the detection of an er-
ror and the attribution of that error to some
source; and
(2) error correction, the remedy for the source of the
error.
3. How NOMAD Recognizes and Corrects
</listItem>
<subsectionHeader confidence="0.7652455">
Errors
3.1. Introduction
</subsectionHeader>
<bodyText confidence="0.999875892857143">
NOMAD incorporates ideas from, and builds on, earlier
work on conceptual analysis (for example, Reisbeck
and Schank 1976, Birnbaum and Selfridge 1979), situ-
ation and intention inference (for example, Cullingford
1977, Wilensky 1978), and English generation (for
example, Goldman 1973, McGuire 1980). What dif-
ferentiates NOMAD significantly from its predecessors
are its error recognition and error correction abilities,
which enable it to read texts more complex than those
that can be handled by other text understanding sys-
tems.
NOMAD operates by attempting to process texts
left to right, with each word capable of suggesting new
expectations (for example, a verb will follow, the pre-
vious noun group should serve as actor of the current
act, etc.), and applying those suggested expectations to
new inputs. When expectations are met, they result in
additions to the ongoing meaning representation of the
text; when they are not met, they result in &apos;surface-
text alerts&apos;, which are collected for potential later cor-
rective processing.
There are two types of &apos;errors&apos; in NOMAD: surface-
text errors and interpretation errors. Surface-text
errors are potential problems that can be readily de-
tected at surface-text processing time, including, for
example, unknown words and any surface expectation
violations, whether syntactic or semantic. For in-
stance, a syntactic expectation failure such as &apos;no noun
</bodyText>
<page confidence="0.781057">
190 American Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983
</page>
<figureCaption confidence="0.320728">
Richard H. Granger The NOMAD System
</figureCaption>
<bodyText confidence="0.999979125">
group appearing where one was expected&apos; is a surface
alert, but so is a semantic/pragmatic expectation fail-
ure such as &apos;target noun group was expected to de-
scribe an animate actor, but described an inanimate
object instead&apos;. Each of these is equally an expecta-
tion failure, and no difference need be drawn at this
stage of processing between syntactic or semantic
types. It will be seen later that, depending on the type
of surface alert, different suggestions will be made as
to where to look to &apos;assign blame&apos; for the problem,
and how to attempt to correct it.
Interpretation failures, on the other hand, are de-
fined as those that cannot be easily ascribable to the
failure of some particular pre-defined surface expecta-
tion; these arise after some conceptual analysis has
been successfully performed and the resulting repre-
sentation fails to match pragmatic checks such as goal-
based or script-based knowledge of the situation being
described.
Following is a list of nine categories of problems
we have identified that occur often in scruffy unedited
texts, five surface-text problems and four interpreta-
tion problems. Each problem is illustrated by a brief
example from the domain of Navy messages. It will
be seen that these errors often occur in pairs, with
surface-text problems sometimes giving rise to inter-
pretation problems. Note that while these problems
are often referred to in this paper as &apos;errors&apos; in fact
some are not actual &apos;errors&apos;, strictly speaking, but are
rather potential problem indicators that NOMAD recog-
nizes, which may give rise to subsequent interpretation
problems.
</bodyText>
<subsectionHeader confidence="0.402132">
Surface-text problems
</subsectionHeader>
<listItem confidence="0.928760428571428">
1. Unknown words.
Enemy &apos;scudded&apos; bombs at us. — the verb is un-
known to the system.
2. Missing subject, object, etc. of sentences.
Sighted enemy ship. Fired. — the actor who fired is
not explicitly stated.
3. Missing sentence and clause boundaries.
</listItem>
<bodyText confidence="0.7197565">
Locked on opened fire. — two actions, aiming and
firing.
</bodyText>
<listItem confidence="0.8155085">
4. Ambiguous word usage.
Returned bombs to Kashin. — &amp;quot;returned&amp;quot; in the
sense of retaliation after a previous attack, or
&amp;quot;returned&amp;quot; in the sense of &amp;quot;peaceably delivered
to&amp;quot;?
5. Lack of tense agreement.
</listItem>
<bodyText confidence="0.9138395">
Open fired. — the intended tense of &apos;open&apos; is trans-
ferred to &apos;fire&apos;.
</bodyText>
<subsectionHeader confidence="0.333164">
Interpretation problems
</subsectionHeader>
<listItem confidence="0.730406222222222">
1. Causality violation.
Ship sighted overhead. — ships can&apos;t fly; probable
message-sending error.
2. Goal violation.
Returned bombs to Kashin. — one of two ambiguous
interpretations of &apos;returned&apos; (peaceably delivered)
gives rise to apparent goal violation (delivering
weapons to enemy).
3. User confirmation failure.
</listItem>
<bodyText confidence="0.9694525">
NOMAD&apos;s failure is not confirmed by user. (Note
that this is considered by NOMAD to be an inter-
pretation problem even thought it may be due to
the user&apos;s idiosyncrasies, as opposed to violation of
some known semantic rule — the effect is the
same.)
</bodyText>
<listItem confidence="0.724206">
4. Object or event referenced out of known event
sequence.
</listItem>
<bodyText confidence="0.9969542">
Midway lost contact on Kashin. — no previous con-
tact mentioned; this often arises when typical
known situations are mentioned in other than ster-
eotypical (scripty) order.
When these problems arise in a message, NOMAD
must first recognize what the problem(s) is(are)
(which is often difficult to do), and then attempt to
correct the error(s). The following section outlines
the overall processing algorithms NOMAD uses to
process these errors.
</bodyText>
<subsectionHeader confidence="0.966553">
3.2. NOMAD&apos;s error-detection algorithm
</subsectionHeader>
<bodyText confidence="0.9482435">
NOMAD&apos;s algorithm for detection and solution of er-
rors follows a four-step process:
</bodyText>
<listItem confidence="0.996013818181818">
1. Set &apos;alert&apos; flags wherever potential surface-text
problems are detected.
2. Do only partial processing of surface text if neces-
sary due to missing or ambiguous information (that
is, do as much normal processing as possible in the
face of missing information).
3. Check for interpretation problems (causal, goal,
sequencing (script), or user confirmation errors)
after surface sentence processing.
4. Try solutions based on surface &apos;alert&apos; flag catego-
ries.
</listItem>
<bodyText confidence="0.9973035">
To illustrate this process, consider an ambiguous
text, &apos;contact gained on kashin&apos;. During the process-
ing of this text, some surface-text alerts arise (for
example, &apos;contact&apos; can be either a noun or a verb&apos; if
it&apos;s a verb, then there&apos;s either a missing subject or an
expected passive subject coming, etc.), and an inter-
pretation ambiguity: the text can be interpreted as
meaning either
</bodyText>
<listItem confidence="0.92151962962963">
(a) We established visual or radar contact with a
kashin ship.
(b) Our contact (that is, a ship in contact with us)
increased its speed in a chase after a kashin ship.
In the case of &apos;contact gained on kashin&apos;, NOMAD&apos;s
blame assignment algorithm moves through the above
steps as follows:
1. (a) Set both &apos;ambiguous-word-sense&apos; and &apos;ambig-
uous-part-of-speech&apos; alerts for the word &apos;contact&apos;:
it might be either a noun (that is, the ship that is
currently our contact) or a verb (to establish radar
or visual contact).
American Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983 191
Richard H. Granger The NOMAD System
(b) Set &apos;ambiguous-word-sense&apos; alert for word
&apos;gained&apos;: it might mean either &apos;established&apos; as in
&apos;gained (established) radar contact&apos;, or &apos;advanced&apos;
as in &apos;gained (advanced) on enemy during chase&apos;.
2. Product alternate interpretations based on alternate
assumptions about word senses: &apos;established radar
or visual contact with kashin&apos;, and &apos;our contact ship
advanced on kashin&apos;.
3. (a) Look for possible causality or goal violations:
none found.
(b) Ask user for confirmation: user confirms one
interpretation but not the other.
4. Solution: Select interpretation confirmed by user.
</listItem>
<bodyText confidence="0.997852285714286">
Consider another example, &apos;Returned bombs to
Kashin&apos;. As noted above, one of two ambiguous inter-
pretations of &apos;returned&apos; in this text (that is, the
`(peaceably) delivered&apos; interpretation) gives rise to an
apparent goal violation (delivering weapons to enemy).
In the case of &apos;returned bombs to kashin&apos;, the
blame assignment algorithm acts as follows:
</bodyText>
<listItem confidence="0.87712975">
1. (a) Set &apos;ambiguous-word-sense&apos; alert for the word
&apos;returned&apos;: it might have either of two categories of
meaning, corresponding to &apos;re-do a previously-done
action (as in &apos;return the favor&apos;, &apos;return a
transmission&apos;) or &apos;re-deliver a previously-delivered
object (as in &apos;return a (borrowed) book&apos;).
(b) Set &apos;ambiguous-word-sense&apos; alert for word
&apos;bombs&apos;: it might mean either the verb `to bomb&apos;,
</listItem>
<bodyText confidence="0.773266">
present tense, or the plural noun. The former in-
terpretation (that bomb is a verb) also gives rise to
a &apos;missing-clause-boundary&apos; surface alert, since
then the &apos;returned&apos; and &apos;bombs&apos; verbs would be
next to each other.
2. Produce alternate interpretations based on alternate
assumptions about word senses: &apos;Delivered object
(bombs) to kashin&apos; (after they had delivered some
to us) or &apos;fired on kashin&apos; (after they had fired on
</bodyText>
<listItem confidence="0.89975975">
us). (The error-ridden alternate interpretations
that arise from the verb sense of &apos;bombs&apos; are also
generated.)
3. (a) Look for possible causality or goal violations:
</listItem>
<bodyText confidence="0.7635246">
With the &apos;delivery&apos; interpretation, a potential viola-
tion of one of NOMAD&apos;s known goals is found:
Actors of class (enemies) transferring possession of
objects of class (weapons) to recipients of class
(friends), and vice versa.
</bodyText>
<listItem confidence="0.983903727272727">
(b) Order the interpretations in order of prefer-
ence, based on both surface-class and interpreta-
tion-class errors; the goal-violation case above is
not preferred, and the &apos;bombs-as-verb&apos; case is not
preferred, while the &apos;firing back at kashin&apos; interpre-
tation is preferred.
(c) Present preferred interpretation to user; con-
firmed. (If this had failed, then unpreferred inter-
pretations would have been presented.)
4. Solution: Select confirmed interpretation.
4. Blame Assignment in NOMAD
</listItem>
<bodyText confidence="0.999775857142857">
As evidenced in the above examples, there is no simple
relationship between types of errors in the interpreta-
tion of the input, and possible solutions to those er-
rors. This is primarily because the source of an inter-
pretation error is difficult to identify. In general, in-
terpretation problems can arise from any of a number
of surface-text problems, including:
</bodyText>
<listItem confidence="0.877547333333333">
1. words with multiple word senses
Returned bombs to Kashin. — see above discussion;
2. missing clause boundaries
</listItem>
<bodyText confidence="0.88539">
Challenged ship refused to heave to. — can be inter-
preted in any of the following ways: (a) We chal-
lenged a ship. They refused to heave to. (b) We
challenged a ship. We refused to heave to. (c)
The challenged ship refused to heave to.
</bodyText>
<listItem confidence="0.775828">
3. elliptical or telegraphic sentence construction
</listItem>
<bodyText confidence="0.998439512820513">
Contact gained on Kashin. — can be interpreted as:
(a) We established visual or radar contact with a
kashin ship. (b) Our contact (that is, a ship in
contact with us) increased its speed in a chase after
a kashin ship).
As mentioned earlier, NOMAD&apos;s goal is to produce
correct, unambiguous interpretations of input texts. Its
ability to handle ill-formed surface text arises from a
need to be able to find surface-text problems that give
rise to interpretation problems; it attends to surface-
text problems not because they are useful in their own
right but only because they may be useful later in
solving an interpretation problem. NOMAD collects
both surface-text problems and interpretation prob-
lems as it processes a text, and for each interpretation
problem, it attempts to find a corresponding surface
problem that gave rise to it. Once it has an interpreta-
tion problem — surface problem pair, it suggests a solu-
tion for the overall problem based on the characteris-
tics of both the surface problem and the interpretation
problem. In cases where only a surface problem exists
and no interpretation problem has arisen, the surface
problem is simply ignored as being irrelevant to the
true understanding goal of producing a correct, unam-
biguous interpretation. In cases where an interpreta-
tion problem exists but no surface-text problem can be
linked to it, NOMAD suggests possible solutions to the
interpretation problem that do not depend on surface
problems.
The &apos;blame assignment chart&apos; below illustrates some
of NOMAD&apos;S heuristics for finding surface-text alerts
that might correspond to a given interpretation prob-
lem.
NOMAD&apos;s blame assignment algorithm is at the
center of its ability to handle syntactically and seman-
tically ill-formed text. Blame assignment in NOMAD is
capable of dealing with problems at both the surface-
text level and the interpretation level, especially where
interpretation problems arise indirectly from surface-
</bodyText>
<page confidence="0.794318">
192 American Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983
</page>
<table confidence="0.680716041666667">
Richard H. Granger The NOMAD System
INTERPRETATION PROBLEM SUGGESTED SURFACE-TEXT ALERT
Only partial representation Unknown word
constructed
Word with multiple
word senses
SUGGESTED POTENTIAL SOLUTIONS
FOUL-UP:
Expectations and Act-Preference
Try alternate word sense
Causality violation,
Goal violation,
User confirmation failure
Actor or object reference
out of sequence
Expectation failures:
—Syntactic (word)
—Semantic
—Boundary (phrase)
(No surface alert)
Try inferring clause break
Try situation-frame inference
Event referenced (No surface alert)
out of sequence
</table>
<subsectionHeader confidence="0.594552">
Blame Assignment Chart
</subsectionHeader>
<bodyText confidence="0.999952">
level decisions; in general, there is no simple relation-
ship among surface-text problems, interpretation prob-
lems, and potential solutions for these problems.
</bodyText>
<subsectionHeader confidence="0.99936">
4.1. Recognizing and correcting surface errors
</subsectionHeader>
<bodyText confidence="0.9982046">
For each of the five categories of surface problems
handled by the system, NOMAD&apos;s method of recogniz-
ing and correcting the problem is briefly described
here, along with actual English input and output from
NOMAD.
</bodyText>
<sectionHeader confidence="0.380461" genericHeader="method">
1. INPUT:
ENEMY SCUDDED BOMBS AT US.
</sectionHeader>
<bodyText confidence="0.996042">
Problem: Unknown word. The unknown word
&amp;quot;scudded&amp;quot; is trivial to recognize as being unknown,
since it is the only word without a dictionary entry.
Once it has been recognized, NOMAD checks it to
see if it could be (a) a misspelling, (b) an abbrevia-
tion, or (c) a regular verb-tense of some known
word.
Solution: Use expectations to figure out word
meaning from context. When the spelling checkers
fail, a FOUL-UP mechanism is called that uses syn-
tactic expectation (and some morphological analy-
sis) to infer that &apos;scudded&apos; is probably a verb, and
then uses pragmatic knowledge of what actions can
be done by an &apos;enemy&apos; ACTOR, to a &apos;weapon&apos;
OBJECT, direct TO us. At this point, NOMAD uses
a mechanism we term &apos;ACT-preference&apos; (Granger
1977), which exploits both pragmatic knowledge of
what enemies tend to do with weapons, and word-
order knowledge that we have derived of how par-
ticular triads of prepositions, noun-categories, and
verb-categories tend to combine (for example,
`BLAGHED &lt;weapon&gt; AT &lt;ship&gt;&apos; will give rise
to a different inference than `BLAGHED
&lt;weapon&gt; TO &lt;ship&gt;&apos;, or `BLAGHED &lt;weapon&gt;
FOR &lt;ship&gt;&apos;, etc.). This process, detailed in
Granger (1977), arrives at an inference that the
action is probably a &apos;PROPEL&apos; (see Schank and
Abelson 1977). Again, this is only an educated
guess by the system, and may have to be corrected
later on the basis of further information (see Gran-
ger 1980, 1981b).
Finally, NOMAD produces an interpretation of
the input, which the user may or may not confirm.
In the event that the user does not confirm
NOMAD&apos;s initial interpretation, a number of alter-
native interpretations are produced (see Granger
1981a, 1982c) until one is confirmed, or the proc-
ess fails. In this and the following examples,
NOMAD&apos;s &apos;preferred&apos; interpretation is confirmed by
the user.
NOMAD OUTPUT:
An enemy ship fired bombs at our ship.
</bodyText>
<listItem confidence="0.734071">
2. INPUT:
MIDWAY SIGHTED ENEMY. FIRED.
</listItem>
<bodyText confidence="0.963651583333334">
Problem: Missing subject and objects. &apos;Fired&apos;
builds a PROPEL, and expects a subject and objects
to play the conceptual roles of ACTOR (who did
the PROPELing), OBJECT (what got PROPELed)
and RECIPIENT (who got PROPELed at). Howev-
er, no surface subjects or objects are presented
here.
Solution: Use expectations to fill in conceptual
cases. NOMAD uses situational (script-based) ex-
pectations from the known typical sequence of
events in an &amp;quot;ATTACK&amp;quot; — which consists of a
movement (PTRANS), a sighting (ATTEND) and
</bodyText>
<note confidence="0.6721215">
American Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983 193
Richard H. Granger The NOMAD System
</note>
<bodyText confidence="0.991003888888889">
firing (PROPEL) (as in other script-based under-
standers; see Cullingford 1978). Those expecta-
tions say (among other things) that the actor and
recipient of the PROPEL will be the same as the
actor and direction of the ATTEND, and that the
OBJECT that got PROPELed will be some kind of
projectile, which is not further specified here.
NOMAD OUTPUT:
We sighted an enemy ship. We fired at the ship.
</bodyText>
<listItem confidence="0.5481095">
3. INPUT:
LOCKED ON OPENED FIRE.
</listItem>
<bodyText confidence="0.993150166666666">
Problem: Missing sentence boundaries. NOMAD
has no expectations for a new verb (&amp;quot;opened&amp;quot;) to
appear immediately after the completed clause
&amp;quot;locked on&amp;quot;. It tries but fails to connect &amp;quot;opened&amp;quot;
to the phrase &amp;quot;locked on&amp;quot;.
Solution: Assume the syntactic expectations
failed because a clause boundary was not adequate-
ly marked in the message; assume such a boundary
is there. NOMAD assumes that there may have
been an intended sentence separation or clause
break before &amp;quot;opened&amp;quot;, since no expectations can
account for the word in this sentence position.
Hence, NOMAD saves &amp;quot;locked on&amp;quot; as one clause,
and continues to process the rest of the text as a
new sentence.
NOMAD OUTPUT:
We aimed at an unknown object. We fired at the
object.
</bodyText>
<sectionHeader confidence="0.370222" genericHeader="evaluation">
4. INPUT:
</sectionHeader>
<bodyText confidence="0.926103090909091">
RETURNED BOMBS TO ENEMY SHIP.
Problem: Multiple word senses of &apos;returned&apos;,
resulting in ambiguous interpretation of action.
NOMAD cannot tell whether the action here is
&amp;quot;returning&amp;quot; fire to the enemy, that is, firing back at
them (after they presumably had fired at us), or
peaceably delivery bombs, with no firing implied.
Solution: Use expectations of probable goals of
actors. NOMAD first interprets the sentence as
&amp;quot;peaceably delivering&amp;quot; some bombs to the ship.
However, NOMAD contains the knowledge that
enemies do not transfer control of weapons, infor-
mation, personnel, etc., to each other. Hence it
attempts to find an alternative interpretation of the
sentence, in this case finding the &amp;quot;returned fire&amp;quot;
interpretation, which does not violate any of
NOMAD&apos;s knowledge about goals. It then infers, as
in the above example, that the enemy ship must
have previously fired on us.
NOMAD OUTPUT:
An unknown enemy ship fired on us. Then we
fired bombs at them.
</bodyText>
<listItem confidence="0.999230333333333">
5. INPUT:
OPEN FIRED.
Problem: Lack of tense agreement between
</listItem>
<bodyText confidence="0.97514575">
&apos;open&apos; and &apos;fired&apos;.
Solution: Use morphological analyzer to correct
tense of word. NOMAD identifies the phrase &apos;open
fire&apos;, and assumes that past tense was intended (by
default); and so constructs a phrase that correctly
incorporates the tense into the phrase, to make it
&apos;opened fire&apos;. NOMAD then adds the inferred miss-
ing actor. (Note that were this not a known phrase
to NOMAD then the tense agreement would not
have been corrected at the surface level, but rather
the semantic content of the two words would have
contributed to a meaning representation, which
would hae been used to generate a &apos;corrected&apos; ver-
sion of the input.
NOMAD OUTPUT:
We fired bombs at an unspecified target.
</bodyText>
<subsectionHeader confidence="0.995991">
4.2. Recognizing and correcting interpretation
errors
</subsectionHeader>
<bodyText confidence="0.99258">
The four interpretation error-types given above were:
</bodyText>
<listItem confidence="0.999376">
1. causal violations,
2. goal violations,
3. user confirmation failure, and
4. out-of-sequence event or object reference.
</listItem>
<bodyText confidence="0.999986689655172">
The process of detecting or correcting these error
types is different in principle from the five surface
types, for the simple reason that, as opposed to sur-
face errors, which can only be attributed to the
message-sender himself, there are many possible dif-
ferent sources of interpretation errors. In particular,
some surface errors can give rise to apparent interpre-
tation errors. To see this, recall the &apos;returned bombs
to kashin&apos; example above. In this case, NOMAD&apos;s
default selection of a word sense for an ambiguous
word (&apos;returned&apos;) can give rise to an apparent goal
violation error (delivery weapons to an enemy, as op-
posed to firing at an enemy). Hence, the task of
blame assignment here is problematic: an early
surface-processing decision of NOMAD&apos;s can give rise
to an apparent later interpretation problem.
Similarly, a &apos;user confirmation&apos; error (that is, the
user will not confirm any of the interpretations offered
by NOMAD) might be due to any of a number of
things: the user mistyped the original message,
NOMAD made an erroneous surface-text decision, or
NOMAD failed to detect a surface or interpretation
problem in the text. And, a &apos;causal violation&apos; error
(that is, &apos;ship sighted overhead&apos;: ships can&apos;t fly, so the
error is apparently a user error) can be due either to
user errors or to NOMAD&apos;s own interpretation errors.
Finally, an object or event apparently referenced out
of sequence can be due to either user error or an erro-
neous inference by NOMAD.
</bodyText>
<page confidence="0.7276">
194 American Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983
</page>
<note confidence="0.716206">
Richard H. Granger The NOMAD System
</note>
<sectionHeader confidence="0.701643" genericHeader="conclusions">
5. Summary and Conclusions
</sectionHeader>
<subsectionHeader confidence="0.981539">
5.1. NOMAD&apos;s limitations and shortcomings
</subsectionHeader>
<bodyText confidence="0.999989815789474">
NOMAD has proved to be a capable analyzer of ill-
formed text. Some of the standard problems of script-
and plan-based understanders have been satisfactorily
addressed in NOMAD, most notably, the handling of
unknown words (via the FOUL-UP mechanism); and
the script-selection problem, that is, knowing which
scripts to apply monitoring when they go wrong (via
the mechanisms of supplanting incorrect inferences
(Granger 1980), and producing a set of alternate in-
terpretations of a text (Granger 1981a, 198282a,
1982c).
The most important drawback of NOMAD is its lack
of extensibility. Since the system&apos;s knowledge is main-
ly embedded in word-level routines, adding a new
word to the system requires writing a new routine,
possibly duplicating information elsewhere in NOMAD,
and possibly introducing new errors into otherwise-
working NOMAD code. Any new word routine should
ideally take into account interactions with all the
word-level routines already present in the system;
some of those routines may have to be modified in
light of the new entry.
In practice, we do not check every routine when a
new word is added. Rather, we test the system and
make corrections only when a bad interaction is found.
Thus, the system is not guaranteed to be self-
consistent. Since NOMAD has more than a thousand-
word vocabulary, it is impractical to check the entire
system when a new word is added.
Encoding grammatical knowledge at the word level
is also cumbersome. For example, the routine for
nearly every verb makes its own checks for active or
passive usage. A more centralized grammatical mech-
anism would eliminate this kind of redundancy. In
principle, the knowledge currently encoded in the
word-level routines could be made declarative (that is,
stored as data), so as to be more centralized and usa-
ble by other parts of the system.
</bodyText>
<subsectionHeader confidence="0.988676">
5.2. VOX: A VOcabulary eXtension system
</subsectionHeader>
<bodyText confidence="0.999985447368421">
To make the NOMAD system more extensible, we are
currently building a new system that uses not word-
level but phrasal analysis. We call this new system
VOX (for vocabulary extension system). Our goal is
to make this system extensible by interaction with a
user, rather than by adding to the data base program-
matically.
Our ideas about phrasal analysis originate from the
work on the P1-IRAN system (Wilensky and Arens
1982). Phrasal analysis consists of matching the input
to one or more phrase-level patterns stored in a
knowledge data base. When the input has been
matched, it is said to be understood. Semantic actions
can be associated with each phrase, so that whenever a
phrase is matched to part of the input a corresponding
meaning representation for the phrase may be con-
structed.
To extend the knowledge base of the system, we
simply add new patterns to the data base. Ideally,
patterns are independent entities whose interaction
introduces no side effects, so that new phrases can be
easily added to or removed from the data base. A
working prototype of VOX is already up and running
(see Granger, Meyers, Yoshii, and Taylor 1983 and
Meyers 1983), incorporating syntactic and grammati-
cal analyses, semantic analyses and blame assignment,
morphological analysis, and error detection and cate-
gorization. vOX&apos;s phrase knowledge base already
consists of hundreds of phrases, and is being exten-
sively tested. Furthermore, VOX&apos;s data base can be
interactively &apos;edited&apos; by a trained &apos;tutor&apos; to add new
information, including new vocabulary, new syntactic
categories and constructions, and new meanings.
Hence, we hope that VOX may be a first step towards
a &apos;trainable&apos; language-processing system. Granger,
Meyers, Yoshii, and Taylor (1983) and Meyers (1983)
present extensive descriptions of the state of VOX and
the theories underlying it.
</bodyText>
<subsectionHeader confidence="0.9478575">
5.3. Summary: Surface text and its
interpretations
</subsectionHeader>
<bodyText confidence="0.958740916666667">
The ability to understand text is dependent on the
ability to understand what is being described in the
text. Hence, a reader of English must have applicable
knowledge of both the situations that may be de-
scribed in texts (for example, actions, states, se-
quences of events, goals, methods of achieving goals,
etc.), and the surface structures that appear in the
language, that is, the relations between the surface
order of words and phrases, and their corresponding
meaning structures. The process of text understanding
is the combined application of these knowledge
sources as a reader proceeds through a text. This fact
becomes clearest when we investigate the understand-
ing of ill-formed texts, texts that present particular
problems to a reader. The line between correct and
incorrect English is often unclear, so a system that
cannot handle erroneous input is of limited use.
Human understanding is inherently tolerant; people
are naturally able to ignore and deal with many types
of errors, omissions, poor constructions, etc., and get
straight to the meaning of the text. Our theories have
tried to take this ability into account by including
knowledge and mechanisms of error noticing and cor-
recting as implicit parts of our process models of lan-
guage understanding. NOMAD and VOX are primarily
engineering applications incorporating a series of theo-
retical results in language understanding, including
script-based and goal-based understanding, and inte-
grated error-monitoring and supplanting during under-
standing. The NOMAD and VOX systems are the lat-
American Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983 195
Richard H. Granger The NOMAD System
est in a line of &apos;tolerant&apos; language understanders, be-
ginning with FOUL-UP, all based on the use of knowl-
edge of syntax, semantics, and pragmatics at all stages
of the understanding process to cope with errors.
</bodyText>
<sectionHeader confidence="0.988917" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.770568">
Rika Yoshii, Chris Staros, Greg Taylor, and Amnon
Meyers all contributed to the construction of the
NOMAD system; Amnon Meyers has been responsible
for the construction of VOX.
</bodyText>
<sectionHeader confidence="0.94421" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998179989690722">
Birnbaum, L. and Selfridge, M. 1980 Conceptual Analysis of
Natural Language. In Schank, R. and Riesbeck, C., Eds., Inside
Computer Understanding. Lawrence Erlbaum Associates, Hills-
dale, New Jersey.
Cullingford, R. 1977 Controlling Inferences in Story Understand-
ing. Proceedings of the Fifth International Joint Conference on
Artificial Intelligence (IJCAI). Cambridge, Massachusetts.
DeJong, G. 1979 Skimming Stories in Real Time: An Experiment
in Integrated Understanding. Ph.D. Thesis. Computer Science
Department, Yale University, New Haven, Connecticut.
Goldman, N. 1973 The Generation of English Sentences from a
Deep Conceptual Base. Ph.D. Thesis. Stanford University,
Stanford, California.
Granger, R.H. 1977 FOUL-UP: A Program that Figures Out
Meanings of Words from Context. Proceedings of the Fifth
International Joint Conference on Artificial Intelligence (IJCAI).
Cambridge, Massachusetts.
Granger, R.H. 1980 When Expectation Fails: Toward a Self-
Correcting Inference System. Proceedings of the First National
Conference on Artificial Intelligence. Stanford University, Stan-
ford, California.
Granger, R.H. 1981a Directing and Re-directing Inference Pur-
suit: Extra-textual Influences on Text Interpretation. Proceed-
ings of the Seventh International Joint Conference on Artificial
Intelligence (LICA!). Vancouver, British Columbia.
Granger, R.H. 1981b Shaping Explanations: Effects of Question-
ing on Text Interpretation. Proceedings of the Third Annual
Conference of the Cognitive Science Society. Berkeley, California:
193-196.
Granger, R.H. 1982a Judgmental Inference: Inferential Decision-
Making during Understanding. Technical Report #182. Com-
puter Science Department, University of California, Irvine,
California.
Granger, R.H. 1982b Scruffy Text Understanding: Design and
Implementation of &apos;Tolerant&apos; Understanders. Proceedings of the
20th Annual Meeting of the Association for Computational
Linguistics. Toronto, Ontario, Canada: 157-160.
Granger, R.H. 1982c Inference Decisions in Text Understanding.
Proceedings of the Fourth Annual Conference of the Cognitive
Science Society. Ann Arbor, Michigan.
Granger, R.H.; Meyers, A.; Yoshii, R.; and Taylor, G. 1983 An
Extensible Natural Language Understanding System. Proceed-
ings of the Artificial Intelligence Conference. Oakland University,
Rochester, Michigan.
Hayes, P.J. and Mouradian, G.V. 1981 Flexible Parsing. Ameri-
can Journal of Computation Linguistics 7(4): 232-242.
Kwasny, S.C. and Sondheimer, N.K. 1981 Relaxation Techniques
for Parsing Grammatically Ill-Formed Input in Natural Lan-
guage Understanding Systems. American Journal of Computation
Linguistics 7(2): 99-108.
Lebowitz, M. 1981 Generalization and Memory in an Integrated
Understanding System. Computer Science Research Report
186. Yale University, New Haven, Connecticut.
Meyers, A. 1983 Conceptual Grammar. Computer Science Tech-
nical Report #215. University of California, Irvine, California.
McGuire, R. 1980 Political Primaries and Words of Pain. Unpubl-
ished manuscript. Department of Computer Science, Yale
University, New Haven, Connecticut.
Riesbeck, C. and Schank, R. 1976 Comprehension by Computer:
Expectation-based Analysis of Sentences in Context. Computer
Science Research Report 78. Yale University, New Haven,
Connecticut.
Schank, R.C. and Abelson, R. 1977 Scripts, Plans, Goals, and
Understanding. Lawrence Erlbaum Associates, Hillsdale, New
Jersey.
Small, S. 1980 Word Expert Parsing: A Theory of Distributed
Word-Based Natural Language Understanding. Technical Re-
port TR-954. University of Maryland, College Park, Maryland.
Wilensky, R. 1978 Understanding Goal-Based Stories. Computer
Science Technical Report 140. Yale University, New Haven,
Connecticut.
Wilensky, R. and Arens, Y. 1982 PHRAN: A Phrasal Analyzer.
EECS Technical Report. University of California, Berkeley,
California.
APPENDIX: Some Statistics on NOMAD&apos;s
Operation
1. Timing: NOMAD uses about 3 cpu seconds per
word when analyzing Navy messages.
2. Vocabulary size and structure: NOMAD is based on
CA (Birnbaum and Selfridge 1979), and incorpo-
rates &apos;word-expert&apos; routines (Small 1980). Each
word-expert routine can process a whole class of
words, not just an individual word. There are 152
word-expert routines; there are 440 words, inflect-
ed forms, and phrases in NOMAD&apos;s dictionary.
(There are 330 words and phrases, not counting
inflections.)
3. Knowledge: There are 16 situation frames, corre-
sponding roughly to: battle, communication,
location-change, sight, attack, report, command,
communicate, emanate, detect, project, aim, ptrans,
patrol, state-change, causal-result.
4. Benchmarks: NOMAD has successfully processed
about 4000 Navy messages of lengths varying from
1 line to 17 lines of text each. No statistics have
been compiled on NOMAD&apos;s overall success versus
failure rate on all Navy texts.
</reference>
<page confidence="0.929012">
196 American Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.966868">
<title confidence="0.9985645">The NOMAD Expectation-Based Detection Correction of Errors during Understanding Syntactically and Semantically III-Formed Textl</title>
<author confidence="0.999991">Richard H Granger</author>
<affiliation confidence="0.999129333333333">Artificial Intelligence Project, Computer Science and Cognitive Sciences University of</affiliation>
<address confidence="0.997668">Irvine, CA 92717</address>
<abstract confidence="0.998343785714286">Most large text-understanding systems have been designed under the assumption that the input text will be in reasonably &amp;quot;neat&amp;quot; form (for example, newspaper stories and other edited texts). However, a great deal of natural language text (for example, memos, messages, rough drafts, conversation transcripts, etc.) have features that differ significantly from &amp;quot;neat&amp;quot; texts, posing special problems for readers, such as misspelled words, missing words, poor syntactic construction, unclear or ambiguous interpretation, missing crucial etc. Our solution to these problems is to make use of both on knowledge of surface English and on world knowledge of the situation being described. These syntactic and semantic expectations can be used to figure out unknown words from context, constrain the possible word senses of words with multiple meanings (ambiguity), fill in missing words (ellipsis), and resolve referents (anaphora). This method of using expectations to aid the understanding of &amp;quot;scruffy&amp;quot; texts has been incorporated into a working computer program called NOMAD, which understands scruffy texts in the domain of Navy ship-to-shore messages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Birnbaum</author>
<author>M Selfridge</author>
</authors>
<title>Conceptual Analysis of Natural Language. In</title>
<date>1980</date>
<location>Hillsdale, New Jersey.</location>
<marker>Birnbaum, Selfridge, 1980</marker>
<rawString>Birnbaum, L. and Selfridge, M. 1980 Conceptual Analysis of Natural Language. In Schank, R. and Riesbeck, C., Eds., Inside Computer Understanding. Lawrence Erlbaum Associates, Hillsdale, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Cullingford</author>
</authors>
<title>Controlling Inferences in Story Understanding.</title>
<date>1977</date>
<booktitle>Proceedings of the Fifth International Joint Conference on Artificial Intelligence (IJCAI).</booktitle>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="9261" citStr="Cullingford 1977" startWordPosition="1438" endWordPosition="1439"> (NOSC) at San Diego. American Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983 189 Richard H. Granger The NOMAD System 2. Background: Tolerant Text Processing 2.1. FOUL-UP figured out unknown words from context The FOUL-UP program (Figuring Out Unknown Lexemes in the Understanding Process; Granger 1977) was the first program that could figure out meanings of unknown words encountered during text understanding. FOUL-UP was an attempt to model the corresponding human ability commonly known at &amp;quot;figuring out a word from context&amp;quot;. FOUL-UP worked with the SAM system (Cullingford 1977), using the expectations generated by scripts (Schank and Abelson 1977) to restrict the possible meanings of a word, based on what object or action would have occurred in that position according to the script for the story. For instance, consider the following excerpt from a newspaper report of a car accident: (1) Friday, a car swerved off Route 69. The vehicle struck an embankment. The word &amp;quot;embankment&amp;quot; was unknown to the SAM system, but it had encoded predictions about certain attributes of the expected conceptual object of the PROPEL action (the object that the vehicle struck); namely, that</context>
<context position="12546" citStr="Cullingford 1977" startWordPosition="1959" endWordPosition="1960">s to use syntactic and semantic expectations to resolve these difficulties, in the domain of Navy messages. NOMAD&apos;s processing is divided into two major categories: (1) blame assignment, that is, the detection of an error and the attribution of that error to some source; and (2) error correction, the remedy for the source of the error. 3. How NOMAD Recognizes and Corrects Errors 3.1. Introduction NOMAD incorporates ideas from, and builds on, earlier work on conceptual analysis (for example, Reisbeck and Schank 1976, Birnbaum and Selfridge 1979), situation and intention inference (for example, Cullingford 1977, Wilensky 1978), and English generation (for example, Goldman 1973, McGuire 1980). What differentiates NOMAD significantly from its predecessors are its error recognition and error correction abilities, which enable it to read texts more complex than those that can be handled by other text understanding systems. NOMAD operates by attempting to process texts left to right, with each word capable of suggesting new expectations (for example, a verb will follow, the previous noun group should serve as actor of the current act, etc.), and applying those suggested expectations to new inputs. When e</context>
</contexts>
<marker>Cullingford, 1977</marker>
<rawString>Cullingford, R. 1977 Controlling Inferences in Story Understanding. Proceedings of the Fifth International Joint Conference on Artificial Intelligence (IJCAI). Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G DeJong</author>
</authors>
<title>Skimming Stories in Real Time: An Experiment in Integrated Understanding.</title>
<date>1979</date>
<tech>Ph.D. Thesis.</tech>
<institution>Computer Science Department, Yale University,</institution>
<location>New Haven, Connecticut.</location>
<marker>DeJong, 1979</marker>
<rawString>DeJong, G. 1979 Skimming Stories in Real Time: An Experiment in Integrated Understanding. Ph.D. Thesis. Computer Science Department, Yale University, New Haven, Connecticut.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Goldman</author>
</authors>
<title>The Generation of English Sentences from a Deep Conceptual Base.</title>
<date>1973</date>
<tech>Ph.D. Thesis.</tech>
<institution>Stanford University,</institution>
<location>Stanford, California.</location>
<contexts>
<context position="12613" citStr="Goldman 1973" startWordPosition="1968" endWordPosition="1969">ies, in the domain of Navy messages. NOMAD&apos;s processing is divided into two major categories: (1) blame assignment, that is, the detection of an error and the attribution of that error to some source; and (2) error correction, the remedy for the source of the error. 3. How NOMAD Recognizes and Corrects Errors 3.1. Introduction NOMAD incorporates ideas from, and builds on, earlier work on conceptual analysis (for example, Reisbeck and Schank 1976, Birnbaum and Selfridge 1979), situation and intention inference (for example, Cullingford 1977, Wilensky 1978), and English generation (for example, Goldman 1973, McGuire 1980). What differentiates NOMAD significantly from its predecessors are its error recognition and error correction abilities, which enable it to read texts more complex than those that can be handled by other text understanding systems. NOMAD operates by attempting to process texts left to right, with each word capable of suggesting new expectations (for example, a verb will follow, the previous noun group should serve as actor of the current act, etc.), and applying those suggested expectations to new inputs. When expectations are met, they result in additions to the ongoing meanin</context>
</contexts>
<marker>Goldman, 1973</marker>
<rawString>Goldman, N. 1973 The Generation of English Sentences from a Deep Conceptual Base. Ph.D. Thesis. Stanford University, Stanford, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R H Granger</author>
</authors>
<title>FOUL-UP: A Program that Figures Out Meanings of Words from Context.</title>
<date>1977</date>
<booktitle>Proceedings of the Fifth International Joint Conference on Artificial Intelligence (IJCAI).</booktitle>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="6541" citStr="Granger 1977" startWordPosition="1019" endWordPosition="1020"> also leads to the inability of these systems to generate alternative interpretations of text; once these systems have guessed at a parse, they cannot back up and re-parse in response to information from a user. The approach taken by Hayes and Carbonell (1981) is closer to that described in this paper, in that they do build meaning representations. However, there are still shortcomings; in particular, their systems cannot understand texts in which a missing or unknown word is the one that would have built the main semantic case frame. As will be seen below, NOMAD builds on the FOUL-UP system (Granger 1977) to handle such cases (which are frequent in our domain). Furthermore, like the systems described above, their systems cannot re-interpret a text when its initial interpretation turns out to be incorrect. We propose an integrated system of syntactic and semantic processing, in which world knowledge and syntactic knowledge are both applied during text proccessing to provide a number of possible interpretations of a text. Our focus is on interpretations: the goal of the system is to give rise to an unambiguous meaning representation. If surface-text problems occur during processing but an unambi</context>
<context position="8054" citStr="Granger 1977" startWordPosition="1255" endWordPosition="1256">mpting to attack the overall problem of processing text, of which the processing of ill-formed text is a necessary subpart. Our approach implies that the processing of ill-formed text &apos;falls out&apos; of normal text processing, via the application of generalized errorcorrection processes that operate equally on syntax, semantics, and pragmatics, and are not designed specifically for the processing of ill-formed surface text. NOMAD builds on previous work on conceptual analysis (Riesbeck and Schank 1976, Birnbaum and Selfridge 1979), and on error detection and correction during conceptual analysis (Granger 1977, 1980, 1982a). Selfridge and Engelberg (1984), Lebowitz (1984), and Dyer (1983) have also recently taken approaches that are similar to the one proposed here, attempting to fully exploit the power of integrated understanding. NOMAD incorporates and integrates error detection and correction algorithms based on both syntactic and pragmatic error types, and is therefore capable of correctly processing a wide range of ill-formed texts within the knowledge domain of Navy messages. NOMAD has actually been installed and is being used for message processing by the Naval Ocean Systems Center (NOSC) at</context>
<context position="25983" citStr="Granger 1977" startWordPosition="4063" endWordPosition="4064"> a dictionary entry. Once it has been recognized, NOMAD checks it to see if it could be (a) a misspelling, (b) an abbreviation, or (c) a regular verb-tense of some known word. Solution: Use expectations to figure out word meaning from context. When the spelling checkers fail, a FOUL-UP mechanism is called that uses syntactic expectation (and some morphological analysis) to infer that &apos;scudded&apos; is probably a verb, and then uses pragmatic knowledge of what actions can be done by an &apos;enemy&apos; ACTOR, to a &apos;weapon&apos; OBJECT, direct TO us. At this point, NOMAD uses a mechanism we term &apos;ACT-preference&apos; (Granger 1977), which exploits both pragmatic knowledge of what enemies tend to do with weapons, and wordorder knowledge that we have derived of how particular triads of prepositions, noun-categories, and verb-categories tend to combine (for example, `BLAGHED &lt;weapon&gt; AT &lt;ship&gt;&apos; will give rise to a different inference than `BLAGHED &lt;weapon&gt; TO &lt;ship&gt;&apos;, or `BLAGHED &lt;weapon&gt; FOR &lt;ship&gt;&apos;, etc.). This process, detailed in Granger (1977), arrives at an inference that the action is probably a &apos;PROPEL&apos; (see Schank and Abelson 1977). Again, this is only an educated guess by the system, and may have to be corrected </context>
</contexts>
<marker>Granger, 1977</marker>
<rawString>Granger, R.H. 1977 FOUL-UP: A Program that Figures Out Meanings of Words from Context. Proceedings of the Fifth International Joint Conference on Artificial Intelligence (IJCAI). Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R H Granger</author>
</authors>
<title>When Expectation Fails: Toward a SelfCorrecting Inference System.</title>
<date>1980</date>
<booktitle>Proceedings of the First National Conference on Artificial Intelligence.</booktitle>
<location>Stanford University, Stanford, California.</location>
<contexts>
<context position="11782" citStr="Granger 1980" startWordPosition="1843" endWordPosition="1844">posed in a hurry, with little or no re-writing, rough drafts, memos, transcripts of conversations, etc. Such texts may contain these problems, among others: missing words, ad hoc abbreviations of words, poor syntax, confusing order of presentation of ideas, misspellings, lack of punctuation. Even edited texts such as newspaper stories often contain misspellings, words unknown to the reader, and ambiguities; and even apparently very simple texts may contain alternative possible interpretations, which can cause a reader to construct erroneous initial inferences that must later be corrected (see Granger 1980, 1981a, 1981b). The following sections describe the NOMAD system, which incorporates FOUL-UP&apos;s abilities as well as significantly extended abilities to use syntactic and semantic expectations to resolve these difficulties, in the domain of Navy messages. NOMAD&apos;s processing is divided into two major categories: (1) blame assignment, that is, the detection of an error and the attribution of that error to some source; and (2) error correction, the remedy for the source of the error. 3. How NOMAD Recognizes and Corrects Errors 3.1. Introduction NOMAD incorporates ideas from, and builds on, earlie</context>
<context position="26642" citStr="Granger 1980" startWordPosition="4169" endWordPosition="4171">at enemies tend to do with weapons, and wordorder knowledge that we have derived of how particular triads of prepositions, noun-categories, and verb-categories tend to combine (for example, `BLAGHED &lt;weapon&gt; AT &lt;ship&gt;&apos; will give rise to a different inference than `BLAGHED &lt;weapon&gt; TO &lt;ship&gt;&apos;, or `BLAGHED &lt;weapon&gt; FOR &lt;ship&gt;&apos;, etc.). This process, detailed in Granger (1977), arrives at an inference that the action is probably a &apos;PROPEL&apos; (see Schank and Abelson 1977). Again, this is only an educated guess by the system, and may have to be corrected later on the basis of further information (see Granger 1980, 1981b). Finally, NOMAD produces an interpretation of the input, which the user may or may not confirm. In the event that the user does not confirm NOMAD&apos;s initial interpretation, a number of alternative interpretations are produced (see Granger 1981a, 1982c) until one is confirmed, or the process fails. In this and the following examples, NOMAD&apos;s &apos;preferred&apos; interpretation is confirmed by the user. NOMAD OUTPUT: An enemy ship fired bombs at our ship. 2. INPUT: MIDWAY SIGHTED ENEMY. FIRED. Problem: Missing subject and objects. &apos;Fired&apos; builds a PROPEL, and expects a subject and objects to play</context>
<context position="32984" citStr="Granger 1980" startWordPosition="5191" endWordPosition="5192">erican Journal of Computational Linguistics, Volume 9, Numbers 3-4, July-December 1983 Richard H. Granger The NOMAD System 5. Summary and Conclusions 5.1. NOMAD&apos;s limitations and shortcomings NOMAD has proved to be a capable analyzer of illformed text. Some of the standard problems of scriptand plan-based understanders have been satisfactorily addressed in NOMAD, most notably, the handling of unknown words (via the FOUL-UP mechanism); and the script-selection problem, that is, knowing which scripts to apply monitoring when they go wrong (via the mechanisms of supplanting incorrect inferences (Granger 1980), and producing a set of alternate interpretations of a text (Granger 1981a, 198282a, 1982c). The most important drawback of NOMAD is its lack of extensibility. Since the system&apos;s knowledge is mainly embedded in word-level routines, adding a new word to the system requires writing a new routine, possibly duplicating information elsewhere in NOMAD, and possibly introducing new errors into otherwiseworking NOMAD code. Any new word routine should ideally take into account interactions with all the word-level routines already present in the system; some of those routines may have to be modified in</context>
</contexts>
<marker>Granger, 1980</marker>
<rawString>Granger, R.H. 1980 When Expectation Fails: Toward a SelfCorrecting Inference System. Proceedings of the First National Conference on Artificial Intelligence. Stanford University, Stanford, California.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R H Granger</author>
</authors>
<title>1981a Directing and Re-directing Inference Pursuit: Extra-textual Influences on Text Interpretation.</title>
<booktitle>Proceedings of the Seventh International Joint Conference on Artificial Intelligence (LICA!).</booktitle>
<location>Vancouver, British Columbia.</location>
<marker>Granger, </marker>
<rawString>Granger, R.H. 1981a Directing and Re-directing Inference Pursuit: Extra-textual Influences on Text Interpretation. Proceedings of the Seventh International Joint Conference on Artificial Intelligence (LICA!). Vancouver, British Columbia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R H Granger</author>
</authors>
<title>1981b Shaping Explanations: Effects of Questioning on Text Interpretation.</title>
<date></date>
<booktitle>Proceedings of the Third Annual Conference of the Cognitive Science Society.</booktitle>
<location>Berkeley, California:</location>
<marker>Granger, </marker>
<rawString>Granger, R.H. 1981b Shaping Explanations: Effects of Questioning on Text Interpretation. Proceedings of the Third Annual Conference of the Cognitive Science Society. Berkeley, California: 193-196.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R H Granger</author>
</authors>
<title>1982a Judgmental Inference: Inferential DecisionMaking during Understanding.</title>
<tech>Technical Report #182.</tech>
<institution>Computer Science Department, University of California,</institution>
<location>Irvine, California.</location>
<marker>Granger, </marker>
<rawString>Granger, R.H. 1982a Judgmental Inference: Inferential DecisionMaking during Understanding. Technical Report #182. Computer Science Department, University of California, Irvine, California.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R H Granger</author>
</authors>
<title>1982b Scruffy Text Understanding: Design and Implementation of &apos;Tolerant&apos; Understanders.</title>
<booktitle>Proceedings of the 20th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>157--160</pages>
<location>Toronto, Ontario, Canada:</location>
<marker>Granger, </marker>
<rawString>Granger, R.H. 1982b Scruffy Text Understanding: Design and Implementation of &apos;Tolerant&apos; Understanders. Proceedings of the 20th Annual Meeting of the Association for Computational Linguistics. Toronto, Ontario, Canada: 157-160.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R H Granger</author>
</authors>
<title>1982c Inference Decisions in Text Understanding.</title>
<booktitle>Proceedings of the Fourth Annual Conference of the Cognitive Science Society.</booktitle>
<location>Ann Arbor, Michigan.</location>
<marker>Granger, </marker>
<rawString>Granger, R.H. 1982c Inference Decisions in Text Understanding. Proceedings of the Fourth Annual Conference of the Cognitive Science Society. Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R H Granger</author>
<author>A Meyers</author>
<author>R Yoshii</author>
<author>G Taylor</author>
</authors>
<title>An Extensible Natural Language Understanding System.</title>
<date>1983</date>
<booktitle>Proceedings of the Artificial Intelligence Conference.</booktitle>
<location>Oakland University, Rochester, Michigan.</location>
<marker>Granger, Meyers, Yoshii, Taylor, 1983</marker>
<rawString>Granger, R.H.; Meyers, A.; Yoshii, R.; and Taylor, G. 1983 An Extensible Natural Language Understanding System. Proceedings of the Artificial Intelligence Conference. Oakland University, Rochester, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Hayes</author>
<author>G V Mouradian</author>
</authors>
<title>Flexible Parsing.</title>
<date>1981</date>
<journal>American Journal of Computation Linguistics</journal>
<volume>7</volume>
<issue>4</issue>
<pages>232--242</pages>
<contexts>
<context position="5170" citStr="Hayes and Mouradian 1981" startWordPosition="790" endWordPosition="793">when necessary, and lets the messagesender choose among these alternatives. A typical scenario is: ■ the user (message-sender) will enter a &apos;telegraphic&apos; message; ■ NOMAD will produce two different possible interpretations of the message in corrected English, and present them to the user; ■ the user will then choose one of the interpretations; and ■ a database-readable version of the correctlyinterpreted message is then forwarded from the ship to a central data base. Many of the approaches to understanding illformed input focus on syntactic errors separately from semantic errors (for example, Hayes and Mouradian 1981 and Kwasny and Sondheimer 1981). Both of these efforts essentially attempt to increase the flexibility of an ATN syntactic parser: the first by using &apos;parse suspension and continuation&apos;, relaxing constraints on consistency and permitting matches out of their correct order, and the second by relaxing the constraints required to traverse an ATN arc, and then providing &apos;deviance notes&apos; specifying the differences between what was expected and what was actually seen. These efforts attempt to correct the surface form of the input, that is, to perform a transformation from an ill-formed English text</context>
</contexts>
<marker>Hayes, Mouradian, 1981</marker>
<rawString>Hayes, P.J. and Mouradian, G.V. 1981 Flexible Parsing. American Journal of Computation Linguistics 7(4): 232-242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C Kwasny</author>
<author>N K Sondheimer</author>
</authors>
<title>Relaxation Techniques for Parsing Grammatically Ill-Formed Input in Natural Language Understanding Systems.</title>
<date>1981</date>
<journal>American Journal of Computation Linguistics</journal>
<volume>7</volume>
<issue>2</issue>
<pages>99--108</pages>
<contexts>
<context position="5202" citStr="Kwasny and Sondheimer 1981" startWordPosition="795" endWordPosition="798">messagesender choose among these alternatives. A typical scenario is: ■ the user (message-sender) will enter a &apos;telegraphic&apos; message; ■ NOMAD will produce two different possible interpretations of the message in corrected English, and present them to the user; ■ the user will then choose one of the interpretations; and ■ a database-readable version of the correctlyinterpreted message is then forwarded from the ship to a central data base. Many of the approaches to understanding illformed input focus on syntactic errors separately from semantic errors (for example, Hayes and Mouradian 1981 and Kwasny and Sondheimer 1981). Both of these efforts essentially attempt to increase the flexibility of an ATN syntactic parser: the first by using &apos;parse suspension and continuation&apos;, relaxing constraints on consistency and permitting matches out of their correct order, and the second by relaxing the constraints required to traverse an ATN arc, and then providing &apos;deviance notes&apos; specifying the differences between what was expected and what was actually seen. These efforts attempt to correct the surface form of the input, that is, to perform a transformation from an ill-formed English text to a well-formed English text. </context>
</contexts>
<marker>Kwasny, Sondheimer, 1981</marker>
<rawString>Kwasny, S.C. and Sondheimer, N.K. 1981 Relaxation Techniques for Parsing Grammatically Ill-Formed Input in Natural Language Understanding Systems. American Journal of Computation Linguistics 7(2): 99-108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lebowitz</author>
</authors>
<title>Generalization and Memory in an Integrated Understanding System.</title>
<date>1981</date>
<journal>Computer Science Research Report</journal>
<volume>186</volume>
<institution>Yale University,</institution>
<location>New Haven, Connecticut.</location>
<marker>Lebowitz, 1981</marker>
<rawString>Lebowitz, M. 1981 Generalization and Memory in an Integrated Understanding System. Computer Science Research Report 186. Yale University, New Haven, Connecticut.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Meyers</author>
</authors>
<title>Conceptual Grammar. Computer Science</title>
<date>1983</date>
<tech>Technical Report #215.</tech>
<institution>University of California,</institution>
<location>Irvine, California.</location>
<contexts>
<context position="35585" citStr="Meyers 1983" startWordPosition="5629" endWordPosition="5630">en the input has been matched, it is said to be understood. Semantic actions can be associated with each phrase, so that whenever a phrase is matched to part of the input a corresponding meaning representation for the phrase may be constructed. To extend the knowledge base of the system, we simply add new patterns to the data base. Ideally, patterns are independent entities whose interaction introduces no side effects, so that new phrases can be easily added to or removed from the data base. A working prototype of VOX is already up and running (see Granger, Meyers, Yoshii, and Taylor 1983 and Meyers 1983), incorporating syntactic and grammatical analyses, semantic analyses and blame assignment, morphological analysis, and error detection and categorization. vOX&apos;s phrase knowledge base already consists of hundreds of phrases, and is being extensively tested. Furthermore, VOX&apos;s data base can be interactively &apos;edited&apos; by a trained &apos;tutor&apos; to add new information, including new vocabulary, new syntactic categories and constructions, and new meanings. Hence, we hope that VOX may be a first step towards a &apos;trainable&apos; language-processing system. Granger, Meyers, Yoshii, and Taylor (1983) and Meyers (1</context>
</contexts>
<marker>Meyers, 1983</marker>
<rawString>Meyers, A. 1983 Conceptual Grammar. Computer Science Technical Report #215. University of California, Irvine, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McGuire</author>
</authors>
<title>Political Primaries and Words of Pain. Unpublished manuscript.</title>
<date>1980</date>
<institution>Department of Computer Science, Yale University,</institution>
<location>New Haven, Connecticut.</location>
<contexts>
<context position="12628" citStr="McGuire 1980" startWordPosition="1970" endWordPosition="1971">main of Navy messages. NOMAD&apos;s processing is divided into two major categories: (1) blame assignment, that is, the detection of an error and the attribution of that error to some source; and (2) error correction, the remedy for the source of the error. 3. How NOMAD Recognizes and Corrects Errors 3.1. Introduction NOMAD incorporates ideas from, and builds on, earlier work on conceptual analysis (for example, Reisbeck and Schank 1976, Birnbaum and Selfridge 1979), situation and intention inference (for example, Cullingford 1977, Wilensky 1978), and English generation (for example, Goldman 1973, McGuire 1980). What differentiates NOMAD significantly from its predecessors are its error recognition and error correction abilities, which enable it to read texts more complex than those that can be handled by other text understanding systems. NOMAD operates by attempting to process texts left to right, with each word capable of suggesting new expectations (for example, a verb will follow, the previous noun group should serve as actor of the current act, etc.), and applying those suggested expectations to new inputs. When expectations are met, they result in additions to the ongoing meaning representatio</context>
</contexts>
<marker>McGuire, 1980</marker>
<rawString>McGuire, R. 1980 Political Primaries and Words of Pain. Unpublished manuscript. Department of Computer Science, Yale University, New Haven, Connecticut.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Riesbeck</author>
<author>R Schank</author>
</authors>
<title>Comprehension by Computer: Expectation-based Analysis of Sentences in Context.</title>
<date>1976</date>
<journal>Computer Science Research Report</journal>
<volume>78</volume>
<institution>Yale University,</institution>
<location>New Haven, Connecticut.</location>
<contexts>
<context position="7944" citStr="Riesbeck and Schank 1976" startWordPosition="1238" endWordPosition="1241">t problems will be consulted to see if they might have been the source of the interpretation problem. That is, we are attempting to attack the overall problem of processing text, of which the processing of ill-formed text is a necessary subpart. Our approach implies that the processing of ill-formed text &apos;falls out&apos; of normal text processing, via the application of generalized errorcorrection processes that operate equally on syntax, semantics, and pragmatics, and are not designed specifically for the processing of ill-formed surface text. NOMAD builds on previous work on conceptual analysis (Riesbeck and Schank 1976, Birnbaum and Selfridge 1979), and on error detection and correction during conceptual analysis (Granger 1977, 1980, 1982a). Selfridge and Engelberg (1984), Lebowitz (1984), and Dyer (1983) have also recently taken approaches that are similar to the one proposed here, attempting to fully exploit the power of integrated understanding. NOMAD incorporates and integrates error detection and correction algorithms based on both syntactic and pragmatic error types, and is therefore capable of correctly processing a wide range of ill-formed texts within the knowledge domain of Navy messages. NOMAD ha</context>
<context position="10034" citStr="Riesbeck and Schank 1976" startWordPosition="1561" endWordPosition="1564">would have occurred in that position according to the script for the story. For instance, consider the following excerpt from a newspaper report of a car accident: (1) Friday, a car swerved off Route 69. The vehicle struck an embankment. The word &amp;quot;embankment&amp;quot; was unknown to the SAM system, but it had encoded predictions about certain attributes of the expected conceptual object of the PROPEL action (the object that the vehicle struck); namely, that it would be a physical object, and would function as an &amp;quot;obstruction&amp;quot; in the vehicle-accident script. (In addition, the conceptual analyzer (ELI — Riesbeck and Schank 1976) had the expectation that the word in that sentence position would be a noun.) Hence, when the unknown word was encountered, FOUL-UP would make use of those expected attributes to construct a memory entry for the word &amp;quot;embankment&amp;quot;, indicating that it was a noun, a physical object, and an &amp;quot;obstruction&amp;quot; in vehicle-accident situations. It would then create a dictionary definition that the system would use from then on whenever the word was encountered in this context. 2.2. Syntactic (surface) and semantic (interpreation) text errors But even if the SAM system had known the word &amp;quot;embankment&amp;quot;, it w</context>
</contexts>
<marker>Riesbeck, Schank, 1976</marker>
<rawString>Riesbeck, C. and Schank, R. 1976 Comprehension by Computer: Expectation-based Analysis of Sentences in Context. Computer Science Research Report 78. Yale University, New Haven, Connecticut.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Schank</author>
<author>R Abelson</author>
</authors>
<title>Scripts, Plans, Goals, and Understanding. Lawrence Erlbaum Associates,</title>
<date>1977</date>
<location>Hillsdale, New Jersey.</location>
<contexts>
<context position="9332" citStr="Schank and Abelson 1977" startWordPosition="1446" endWordPosition="1449">ics, Volume 9, Numbers 3-4, July-December 1983 189 Richard H. Granger The NOMAD System 2. Background: Tolerant Text Processing 2.1. FOUL-UP figured out unknown words from context The FOUL-UP program (Figuring Out Unknown Lexemes in the Understanding Process; Granger 1977) was the first program that could figure out meanings of unknown words encountered during text understanding. FOUL-UP was an attempt to model the corresponding human ability commonly known at &amp;quot;figuring out a word from context&amp;quot;. FOUL-UP worked with the SAM system (Cullingford 1977), using the expectations generated by scripts (Schank and Abelson 1977) to restrict the possible meanings of a word, based on what object or action would have occurred in that position according to the script for the story. For instance, consider the following excerpt from a newspaper report of a car accident: (1) Friday, a car swerved off Route 69. The vehicle struck an embankment. The word &amp;quot;embankment&amp;quot; was unknown to the SAM system, but it had encoded predictions about certain attributes of the expected conceptual object of the PROPEL action (the object that the vehicle struck); namely, that it would be a physical object, and would function as an &amp;quot;obstruction&amp;quot; </context>
<context position="26499" citStr="Schank and Abelson 1977" startWordPosition="4141" endWordPosition="4144">&apos;weapon&apos; OBJECT, direct TO us. At this point, NOMAD uses a mechanism we term &apos;ACT-preference&apos; (Granger 1977), which exploits both pragmatic knowledge of what enemies tend to do with weapons, and wordorder knowledge that we have derived of how particular triads of prepositions, noun-categories, and verb-categories tend to combine (for example, `BLAGHED &lt;weapon&gt; AT &lt;ship&gt;&apos; will give rise to a different inference than `BLAGHED &lt;weapon&gt; TO &lt;ship&gt;&apos;, or `BLAGHED &lt;weapon&gt; FOR &lt;ship&gt;&apos;, etc.). This process, detailed in Granger (1977), arrives at an inference that the action is probably a &apos;PROPEL&apos; (see Schank and Abelson 1977). Again, this is only an educated guess by the system, and may have to be corrected later on the basis of further information (see Granger 1980, 1981b). Finally, NOMAD produces an interpretation of the input, which the user may or may not confirm. In the event that the user does not confirm NOMAD&apos;s initial interpretation, a number of alternative interpretations are produced (see Granger 1981a, 1982c) until one is confirmed, or the process fails. In this and the following examples, NOMAD&apos;s &apos;preferred&apos; interpretation is confirmed by the user. NOMAD OUTPUT: An enemy ship fired bombs at our ship. </context>
</contexts>
<marker>Schank, Abelson, 1977</marker>
<rawString>Schank, R.C. and Abelson, R. 1977 Scripts, Plans, Goals, and Understanding. Lawrence Erlbaum Associates, Hillsdale, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Small</author>
</authors>
<title>Word Expert Parsing: A Theory of Distributed Word-Based Natural Language Understanding.</title>
<date>1980</date>
<tech>Technical Report TR-954.</tech>
<institution>University of Maryland, College Park,</institution>
<location>Maryland.</location>
<marker>Small, 1980</marker>
<rawString>Small, S. 1980 Word Expert Parsing: A Theory of Distributed Word-Based Natural Language Understanding. Technical Report TR-954. University of Maryland, College Park, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Wilensky</author>
</authors>
<title>Understanding Goal-Based Stories. Computer Science</title>
<date>1978</date>
<tech>Technical Report 140.</tech>
<institution>Yale University,</institution>
<location>New Haven, Connecticut.</location>
<contexts>
<context position="12562" citStr="Wilensky 1978" startWordPosition="1961" endWordPosition="1962"> and semantic expectations to resolve these difficulties, in the domain of Navy messages. NOMAD&apos;s processing is divided into two major categories: (1) blame assignment, that is, the detection of an error and the attribution of that error to some source; and (2) error correction, the remedy for the source of the error. 3. How NOMAD Recognizes and Corrects Errors 3.1. Introduction NOMAD incorporates ideas from, and builds on, earlier work on conceptual analysis (for example, Reisbeck and Schank 1976, Birnbaum and Selfridge 1979), situation and intention inference (for example, Cullingford 1977, Wilensky 1978), and English generation (for example, Goldman 1973, McGuire 1980). What differentiates NOMAD significantly from its predecessors are its error recognition and error correction abilities, which enable it to read texts more complex than those that can be handled by other text understanding systems. NOMAD operates by attempting to process texts left to right, with each word capable of suggesting new expectations (for example, a verb will follow, the previous noun group should serve as actor of the current act, etc.), and applying those suggested expectations to new inputs. When expectations are </context>
</contexts>
<marker>Wilensky, 1978</marker>
<rawString>Wilensky, R. 1978 Understanding Goal-Based Stories. Computer Science Technical Report 140. Yale University, New Haven, Connecticut.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Wilensky</author>
<author>Y Arens</author>
</authors>
<title>PHRAN: A Phrasal Analyzer.</title>
<date>1982</date>
<tech>EECS Technical</tech>
<institution>Report. University of California, Berkeley,</institution>
<location>California.</location>
<contexts>
<context position="34851" citStr="Wilensky and Arens 1982" startWordPosition="5502" endWordPosition="5505">tly encoded in the word-level routines could be made declarative (that is, stored as data), so as to be more centralized and usable by other parts of the system. 5.2. VOX: A VOcabulary eXtension system To make the NOMAD system more extensible, we are currently building a new system that uses not wordlevel but phrasal analysis. We call this new system VOX (for vocabulary extension system). Our goal is to make this system extensible by interaction with a user, rather than by adding to the data base programmatically. Our ideas about phrasal analysis originate from the work on the P1-IRAN system (Wilensky and Arens 1982). Phrasal analysis consists of matching the input to one or more phrase-level patterns stored in a knowledge data base. When the input has been matched, it is said to be understood. Semantic actions can be associated with each phrase, so that whenever a phrase is matched to part of the input a corresponding meaning representation for the phrase may be constructed. To extend the knowledge base of the system, we simply add new patterns to the data base. Ideally, patterns are independent entities whose interaction introduces no side effects, so that new phrases can be easily added to or removed f</context>
</contexts>
<marker>Wilensky, Arens, 1982</marker>
<rawString>Wilensky, R. and Arens, Y. 1982 PHRAN: A Phrasal Analyzer. EECS Technical Report. University of California, Berkeley, California.</rawString>
</citation>
<citation valid="false">
<title>APPENDIX: Some Statistics on NOMAD&apos;s Operation</title>
<marker></marker>
<rawString>APPENDIX: Some Statistics on NOMAD&apos;s Operation</rawString>
</citation>
<citation valid="false">
<authors>
<author>Timing</author>
</authors>
<title>NOMAD uses about 3 cpu seconds per word when analyzing Navy messages.</title>
<marker>Timing, </marker>
<rawString>1. Timing: NOMAD uses about 3 cpu seconds per word when analyzing Navy messages.</rawString>
</citation>
<citation valid="false">
<title>Vocabulary size and structure: NOMAD is based on CA (Birnbaum and Selfridge 1979), and incorporates &apos;word-expert&apos; routines (Small 1980). Each word-expert routine can process a whole class of words, not just an individual word. There are 152 word-expert routines; there are 440 words, inflected forms, and phrases in NOMAD&apos;s dictionary. (There are 330 words and phrases, not counting inflections.)</title>
<marker></marker>
<rawString>2. Vocabulary size and structure: NOMAD is based on CA (Birnbaum and Selfridge 1979), and incorporates &apos;word-expert&apos; routines (Small 1980). Each word-expert routine can process a whole class of words, not just an individual word. There are 152 word-expert routines; there are 440 words, inflected forms, and phrases in NOMAD&apos;s dictionary. (There are 330 words and phrases, not counting inflections.)</rawString>
</citation>
<citation valid="false">
<authors>
<author>Knowledge</author>
</authors>
<title>There are 16 situation frames, corresponding roughly to: battle, communication, location-change,</title>
<note>sight, attack, report, command, communicate, emanate, detect, project, aim, ptrans, patrol, state-change, causal-result.</note>
<marker>Knowledge, </marker>
<rawString>3. Knowledge: There are 16 situation frames, corresponding roughly to: battle, communication, location-change, sight, attack, report, command, communicate, emanate, detect, project, aim, ptrans, patrol, state-change, causal-result.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Benchmarks</author>
</authors>
<title>NOMAD has successfully processed about 4000 Navy messages of lengths varying from 1 line to 17 lines of text each. No statistics have been compiled on NOMAD&apos;s overall success versus failure rate on all Navy texts.</title>
<marker>Benchmarks, </marker>
<rawString>4. Benchmarks: NOMAD has successfully processed about 4000 Navy messages of lengths varying from 1 line to 17 lines of text each. No statistics have been compiled on NOMAD&apos;s overall success versus failure rate on all Navy texts.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>