<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000968">
<title confidence="0.9993645">
Using Distributional Similarity of Multi-way Translations to Predict
Multiword Expression Compositionality
</title>
<author confidence="0.995328">
Bahar Salehi,4° Paul Cook° and Timothy Baldwin4°
</author>
<affiliation confidence="0.980695666666667">
♣ NICTA Victoria Research Laboratory
♥ Department of Computing and Information Systems
The University of Melbourne
</affiliation>
<address confidence="0.689358">
Victoria 3010, Australia
</address>
<email confidence="0.994278">
bsalehi@student.unimelb.edu.au, paulcook@unimelb.edu.au, tb@ldwin.net
</email>
<sectionHeader confidence="0.993898" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999764">
We predict the compositionality of multi-
word expressions using distributional sim-
ilarity between each component word and
the overall expression, based on transla-
tions into multiple languages. We evaluate
the method over English noun compounds,
English verb particle constructions and
German noun compounds. We show that
the estimation of compositionality is im-
proved when using translations into multi-
ple languages, as compared to simply us-
ing distributional similarity in the source
language. We further find that string sim-
ilarity complements distributional similar-
ity.
</bodyText>
<sectionHeader confidence="0.715543" genericHeader="categories and subject descriptors">
1 Compositionality of MWEs
</sectionHeader>
<bodyText confidence="0.999751722222222">
Multiword expressions (hereafter MWEs) are
combinations of words which are lexically, syntac-
tically, semantically or statistically idiosyncratic
(Sag et al., 2002; Baldwin and Kim, 2009). Much
research has been carried out on the extraction and
identification of MWEs1 in English (Schone and
Jurafsky, 2001; Pecina, 2008; Fazly et al., 2009)
and other languages (Dias, 2003; Evert and Krenn,
2005; Salehi et al., 2012). However, considerably
less work has addressed the task of predicting the
meaning of MWEs, especially in non-English lan-
guages. As a step in this direction, the focus of
this study is on predicting the compositionality of
MWEs.
An MWE is fully compositional if its meaning
is predictable from its component words, and it is
non-compositional (or idiomatic) if not. For ex-
ample, stand up “rise to one’s feet” is composi-
</bodyText>
<footnote confidence="0.9694995">
1In this paper, we follow Baldwin and Kim (2009) in
considering MWE “identification” to be a token-level disam-
biguation task, and MWE “extraction” to be a type-level lex-
icon induction task.
</footnote>
<bodyText confidence="0.999951756097561">
tional, because its meaning is clear from the mean-
ing of the components stand and up. However, the
meaning of strike up “to start playing” is largely
unpredictable from the component words strike
and up.
In this study, following McCarthy et al. (2003)
and Reddy et al. (2011), we consider composition-
ality to be graded, and aim to predict the degree
of compositionality. For example, in the dataset
of Reddy et al. (2011), climate change is judged
to be 99% compositional, while silver screen is
48% compositional and ivory tower is 9% com-
positional. Formally, we model compositionality
prediction as a regression task.
An explicit handling of MWEs has been shown
to be useful in NLP applications (Ramisch, 2012).
As an example, Carpuat and Diab (2010) proposed
two strategies for integrating MWEs into statisti-
cal machine translation. They show that even a
large scale bilingual corpus cannot capture all the
necessary information to translate MWEs, and that
in adding the facility to model the compositional-
ity of MWEs into their system, they could improve
translation quality. Acosta et al. (2011) showed
that treating non-compositional MWEs as a sin-
gle unit in information retrieval improves retrieval
effectiveness. For example, while searching for
documents related to ivory tower, we are almost
certainly not interested in documents relating to
elephant tusks.
Our approach is to use a large-scale multi-way
translation lexicon to source translations of MWEs
and their component words, and then model the
relative similarity between each of the component
words and the MWE, using distributional similar-
ity based on monolingual corpora for the source
language and each of the target languages. Our
hypothesis is that using distributional similarity
in more than one language will improve the pre-
diction of compositionality. Importantly, in order
to make the method as language-independent and
</bodyText>
<page confidence="0.974181">
472
</page>
<note confidence="0.99301">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 472–481,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999906583333333">
broadly-applicable as possible, we make no use of
corpus preprocessing such as lemmatisation, and
rely only on the availability of a translation dictio-
nary and monolingual corpora.
Our results confirm our hypothesis that distri-
butional similarity over the source language in ad-
dition to multiple target languages improves the
quality of compositionality prediction. We also
show that our method can be complemented with
string similarity (Salehi and Cook, 2013) to further
improve compositionality prediction. We achieve
state-of-the-art results over two datasets.
</bodyText>
<sectionHeader confidence="0.999781" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9999692">
Most recent work on predicting the composi-
tionality of MWEs can be divided into two
categories: language/construction-specific and
general-purpose. This can be at either the token-
level (over token occurrences of an MWE in a cor-
pus) or type-level (over the MWE string, indepen-
dent of usage). The bulk of work on composition-
ality has been language/construction-specific and
operated at the token-level, using dedicated meth-
ods to identify instances of a given MWE, and
specific properties of the MWE in that language
to predict compositionality (Lin, 1999; Kim and
Baldwin, 2007; Fazly et al., 2009).
General-purpose token-level approaches such
as distributional similarity have been commonly
applied to infer the semantics of a word/MWE
(Schone and Jurafsky, 2001; Baldwin et al., 2003;
Reddy et al., 2011). These techniques are based
on the assumption that the meaning of a word is
predictable from its context of use, via the neigh-
bouring words of token-level occurrences of the
MWE. In order to predict the compositionality of
a given MWE using distributional similarity, the
different contexts of the MWE are compared with
the contexts of its components, and the MWE is
considered to be compositional if the MWE and
component words occur in similar contexts.
Identifying token instances of MWEs is not al-
ways easy, especially when the component words
do not occur sequentially. For example consider
put on in put your jacket on, and put your jacket
on the chair. In the first example put on is an
MWE while in the second example, put on is a
simple verb with prepositional phrase and not an
instance of an MWE. Moreover, if we adopt a con-
servative identification method, the number of to-
ken occurrences will be limited and the distribu-
tional scores may not be reliable. Additionally,
for morphologically-rich languages, it can be dif-
ficult to predict the different word forms a given
MWE type will occur across, posing a challenge
for our requirement of no language-specific pre-
processing.
Pichotta and DeNero (2013) proposed a token-
based method for identifying English phrasal
verbs based on parallel corpora for 50 languages.
They show that they can identify phrasal verbs bet-
ter when they combine information from multiple
languages, in addition to the information they get
from a monolingual corpus. This finding lends
weight to our hypothesis that using translation data
and distributional similarity from each of a range
of target languages, can improve compositionality
prediction. Having said that, the general applica-
bility of the method is questionable — there are
many parallel corpora involving English, but for
other languages, this tends not to be the case.
Salehi and Cook (2013) proposed a general-
purpose type-based approach using translation
data from multiple languages, and string similar-
ity between the MWE and each of the compo-
nent words. They use training data to identify the
best-10 languages for a given family of MWEs, on
which to base the string similarity, and once again
find that translation data improves their results
substantially. Among the four string similarity
measures they experimented with, longest com-
mon substring was found to perform best. Their
proposed method is general and applicable to dif-
ferent families of MWEs in different languages. In
this paper, we reimplement the method of Salehi
and Cook (2013) using longest common substring
(LCS), and both benchmark against this method
and combine it with our distributional similarity-
based method.
</bodyText>
<sectionHeader confidence="0.972222" genericHeader="method">
3 Our Approach
</sectionHeader>
<bodyText confidence="0.99995875">
To predict the compositionality of a given MWE,
we first measure the semantic similarity between
the MWE and each of its component words2 using
distributional similarity based on a monolingual
corpus in the source language. We then repeat the
process for translations of the MWE and its com-
ponent words into each of a range of target lan-
guages, calculating distributional similarity using
</bodyText>
<footnote confidence="0.996898666666667">
2Note that we will always assume that there are two
component words, but the method is easily generalisable to
MWEs with more than two components.
</footnote>
<page confidence="0.998724">
473
</page>
<figure confidence="0.974149333333334">
Score1 for each language Score2 for each language
Translations
MWE component1 component2
Translate
(using Panlex)
Translate
(using Panlex)
Translate
(using Panlex)
CS.mhw
CS.mhw
DS
(using Wikiepdia)
DS
(using Wikiepdia)
s1 s2
Compositionality score
score1 score2
</figure>
<figureCaption confidence="0.999838">
Figure 1: Outline of our approach to computing
</figureCaption>
<bodyText confidence="0.981114666666667">
the distributional similarity (DS) of translations
of an MWE with each of its component words,
for a given target language. score1 and score2
are the similarity for the first and second compo-
nents, respectively. We obtain translations from
Panlex, and use Wikipedia as our corpus for each
language.
a monolingual corpus in the target language (Fig-
ure 1). We additionally use supervised learning to
identify which target languages (or what weights
for each language) optimise the prediction of com-
positionality (Figure 2). We hypothesise that by
using multiple translations — rather than only in-
formation from the source language — we will be
able to better predict compositionality.
We optionally combine our proposed approach
with string similarity, calculated based on the
method of Salehi and Cook (2013), using LCS.
Below, we detail our method for calculating dis-
tributional similarity in a given language, the dif-
ferent methods for combining distributional simi-
larity scores into a single estimate of composition-
ality, and finally the method for selecting the target
languages to use in calculating compositionality.
</bodyText>
<subsectionHeader confidence="0.999188">
3.1 Calculating Distributional Similarity
</subsectionHeader>
<bodyText confidence="0.975990838709678">
In order to be consistent across all languages and
be as language-independent as possible, we calcu-
Figure 2: Outline of the method for combin-
ing distributional similarity scores from multiple
languages, across the components of the MWE.
CSmethod refers to one of the methods described
in Section 3.2 for calculating compositionality.
late distributional similarity in the following man-
ner for a given language.
Tokenisation is based on whitespace delimiters
and punctuation; no lemmatisation or case-folding
is carried out. Token instances of a given MWE
or component word are identified by full-token n-
gram matching over the token stream. We assume
that all full stops and equivalent characters for
other orthographies are sentence boundaries, and
chunk the corpora into (pseudo-)sentences on the
basis of them. For each language, we identify the
51st–1050th most frequent words, and consider
them to be content-bearing words, in the manner
of Sch¨utze (1997). This is based on the assump-
tion that the top-50 most frequent words are stop
words, and not a good choice of word for calculat-
ing distributional similarity over. That is not to say
that we can’t calculate the distributional similarity
for stop words, however (as we will for the verb
particle construction dataset — see Section 4.3.2)
they are simply not used as the dimensions in our
calculation of distributional similarity.
We form a vector of content-bearing words
across all token occurrences of the target word,
</bodyText>
<page confidence="0.995166">
474
</page>
<bodyText confidence="0.999977555555556">
on the basis of these content-bearing words. Dis-
tributional similarity is calculated over these con-
text vectors using cosine similarity. Accord-
ing to Weeds (2003), using dependency rela-
tions with the neighbouring words of the target
word can better predict the meaning of the target
word. However, in line with our assumption of no
language-specific preprocessing, we just use word
co-occurrence.
</bodyText>
<subsectionHeader confidence="0.999938">
3.2 Calculating Compositionality
</subsectionHeader>
<bodyText confidence="0.999991">
First, we need to calculate a combined composi-
tionality score from the individual distributional
similarities between each component word and the
MWE. Following Reddy et al. (2011), we combine
the component scores using the weighted mean (as
shown in Figure 2):
</bodyText>
<equation confidence="0.995871">
comp = αs1 + (1 − α)s2 (1)
</equation>
<bodyText confidence="0.973106804878049">
where s1 and s2 are the scores for the first and
the second component, respectively. We use dif-
ferent α settings for each dataset, as detailed in
Section 4.3.
We experiment with a range of methods for cal-
culating compositionality, as follows:
CSL1: calculate distributional similarity using
only distributional similarity in the source
language corpus (This is the approach used
by Reddy et al. (2011), as discussed in Sec-
tion 2).
CSL2N: exclude the source language, and com-
pute the mean of the distributional similarity
scores for the best-N target languages. The
value of N is selected according to training
data, as detailed in Section 3.3.
CSL1+L2N: calculate distributional similarity
over both the source language (CSL1) and
the mean of the best-N languages (CSL2N),
and combine via the arithmetic mean.3 This
is to examine the hypothesis that using
multiple target languages is better than just
using the source language.
CSSVR(L1+L2): train a support vector regressor
(SVR: Smola and Sch¨olkopf (2004)) over the
distributional similarities for all 52 languages
(source and target languages).
3We also experimented with taking the mean over all the
languages — target and source — but found it best to com-
bine the scores for the target languages first, to give more
weight to the source language.
CSstring: calculate string similarity using the
LCS-based method of Salehi and Cook
(2013).4
CSstring+L1: calculate the mean of the string
similarity (CSstring) and distributional sim-
ilarity in the source language (Salehi and
Cook, 2013).
CSall: calculate the mean of the string similarity
(CSstring) and distributional similarity scores
(CSL1 and CSL2N).
</bodyText>
<subsectionHeader confidence="0.999928">
3.3 Selecting Target Languages
</subsectionHeader>
<bodyText confidence="0.999909476190476">
We experiment with two approaches for combin-
ing the compositionality scores from multiple tar-
get languages.
First, in CSL2N (and CSL1+L2N and CSall that
build off it), we use training data to rank the target
languages according to Pearson’s correlation be-
tween the predicted compositionality scores and
the gold-standard compositionality judgements.
Based on this ranking, we take the best-N lan-
guages, and combine the individual composition-
ality scores by taking the arithmetic mean. We se-
lect N by determining the value that optimises the
correlation over the training data. In other words,
the selection of N and accordingly the best-N lan-
guages are based on nested cross-validation over
training data, independently of the test data for that
iteration of cross-validation.
Second in CSSVR(L1+L2), we combine the
compositionality scores from the source and all 51
target languages into a feature vector, and train an
SVR over the data using LIBSVM.5
</bodyText>
<sectionHeader confidence="0.999591" genericHeader="method">
4 Resources
</sectionHeader>
<bodyText confidence="0.999838333333333">
In this section, we describe the resources required
by our method, and also the datasets used to eval-
uate our method.
</bodyText>
<subsectionHeader confidence="0.882044">
4.1 Monolingual Corpora for Different
Languages
</subsectionHeader>
<bodyText confidence="0.999474">
We collected monolingual corpora for each of 52
languages (51 target languages + 1 source lan-
guage) from XML dumps of Wikipedia. These
languages are based on the 54 target languages
</bodyText>
<footnote confidence="0.9993386">
4Due to differences in our random partitioning, our re-
ported results over the two English datasets differ slightly
over the results of Salehi and Cook (2013) using the same
method.
5http://www.csie.ntu.edu.tw/˜cjlin/libsvm
</footnote>
<page confidence="0.997535">
475
</page>
<bodyText confidence="0.999243818181818">
used by Salehi and Cook (2013), excluding Span-
ish because we happened not to have a dump of
Spanish Wikipedia, and also Chinese and Japanese
because of the need for a language-specific word
tokeniser. The raw corpora were preprocessed us-
ing the WP2TXT toolbox6 to eliminate XML tags,
HTML tags and hyperlinks, and then tokenisa-
tion based on whitespace and punctuation was per-
formed. The corpora vary in size from roughly
750M tokens for English, to roughly 640K tokens
for Marathi.
</bodyText>
<subsectionHeader confidence="0.988722">
4.2 Multilingual Dictionary
</subsectionHeader>
<bodyText confidence="0.999588323529411">
To translate the MWEs and their components,
we follow Salehi and Cook (2013) in using Pan-
lex (Baldwin et al., 2010). This online dictio-
nary is massively multilingual, covering more than
1353 languages. For each MWE dataset (see Sec-
tion 4.3), we translate the MWE and component
words from the source language into each of the
51 languages.
In instances where there is no direct translation
in a given language for a term, we use a pivot lan-
guage to find translation(s) in the target language.
For example, the English noun compound silver
screen has direct translations in only 13 languages
in Panlex, including Vietnamese (m`an bac) but
not French. There is, however, a translation of
m`an bac into French (cin´ema), allowing us to
infer an indirect translation between silver screen
and cin´ema. In this way, if there are no direct
translations into a particular target language, we
search for a single-pivot translation via each of our
other target languages, and combine them all to-
gether as our set of translations for the target lan-
guage of interest.
In the case that no translation (direct or indirect)
can be found for a given source language term into
a particular target language, the compositionality
score for that target language is set to the average
across all target languages for which scores can be
calculated for the given term. If no translations are
available for any target language (e.g. the term is
not in Panlex) the compositionality score for each
target language is set to the average score for that
target language across all other source language
terms.
</bodyText>
<footnote confidence="0.960465">
6http://wp2txt.rubyforge.org/
</footnote>
<subsectionHeader confidence="0.950576">
4.3 Datasets
</subsectionHeader>
<bodyText confidence="0.999814333333333">
We evaluate our proposed method over three
datasets (two English, one German), as described
below.
</bodyText>
<subsubsectionHeader confidence="0.577199">
4.3.1 English Noun Compounds (ENC)
</subsubsectionHeader>
<bodyText confidence="0.999906333333333">
Our first dataset is made up of 90 binary English
noun compounds, from the work of Reddy et al.
(2011). Each noun compound was annotated by
multiple annotators using the integer scale 0 (fully
non-compositional) to 5 (fully compositional). A
final compositionality score was then calculated
as the mean of the scores from the annotators.
If we simplistically consider 2.5 as the threshold
for compositionality, the dataset is relatively well
balanced, containing 48% compositional and 52%
non-compositional noun compounds. Following
Reddy et al. (2011), in combining the component-
wise distributional similarities for this dataset, we
weight the first component in Equation 1 higher
than the second (α = 0.7).
</bodyText>
<sectionHeader confidence="0.6058645" genericHeader="method">
4.3.2 English Verb Particle Constructions
(EVPC)
</sectionHeader>
<bodyText confidence="0.999978678571429">
The second dataset contains 160 English verb par-
ticle constructions (VPCs), from the work of Ban-
nard (2006). In this dataset, a verb particle con-
struction consists of a verb (the head) and a prepo-
sitional particle (e.g. hand in, look up or battle on).
For each component word (the verb and parti-
cle, respectively), multiple annotators were asked
whether the VPC entails the component word. In
order to translate the dataset into a regression task,
we calculate the overall compositionality as the
number of annotations of entailment for the verb,
divided by the total number of verb annotations for
that VPC. That is, following Bannard et al. (2003),
we only consider the compositionality of the verb
component in our experiments (and as such α = 1
in Equation 1).
One area of particular interest with this dataset
will be the robustness of the method to function
words (the particles), both under translation and
in terms of calculating distributional similarity, al-
though the findings of Baldwin (2006) for English
prepositions are at least encouraging in this re-
spect. Additionally, English VPCs can occur in
“split” form (e.g. put your jacket on, from our
earlier example), which will complicate identifi-
cation, and the verb component will often be in-
flected and thus not match under our identification
strategy (for both VPCs and the component verbs).
</bodyText>
<page confidence="0.998089">
476
</page>
<table confidence="0.999929875">
Dataset Language Frequency Family
Italian 100 Romance
French 99 Romance
ENC German 86 Germanic
Vietnamese 83 Viet-Muong
Portuguese 62 Romance
Bulgarian 100 Slavic
Breton 100 Celtic
EVPC Occitan 100 Romance
Indonesian 100 Indonesian
Slovenian 100 Slavic
Polish 100 Slavic
Lithuanian 99 Baltic
GNC Finnish 74 Uralic
Bulgarian 72 Slavic
Czech 40 Slavic
</table>
<tableCaption confidence="0.682267666666667">
Table 1: The 5 best languages for the ENC, EVPC
and GNC datasets. The language family is based
on Voegelin and Voegelin (1977).
</tableCaption>
<subsubsectionHeader confidence="0.657582">
4.3.3 German Noun Compounds (GNC)
</subsubsectionHeader>
<bodyText confidence="0.999974684210526">
Our final dataset is made up of 246 German noun
compounds (von der Heide and Borgwaldt, 2009;
Schulte im Walde et al., 2013). Multiple anno-
tators were asked to rate the compositionality of
each German noun compound on an integer scale
of 1 (non-compositional) to 7 (compositional).
The overall compositionality score is then calcu-
lated as the mean across the annotators. Note that
the component words are provided as part of the
dataset, and that there is no need to perform de-
compounding. Following Schulte im Walde et al.
(2013), we weight the first component higher in
Equation 1 (α = 0.8) when calculating the overall
compositionality score.
This dataset is significant in being non-English,
and also in that German has relatively rich mor-
phology, which we expect to impact on the iden-
tification of both the MWE and the component
words.
</bodyText>
<sectionHeader confidence="0.999933" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999936">
All experiments are carried out using 10 iterations
of 10-fold cross validation, randomly partitioning
the data independently on each of the 10 iterations,
and averaging across all 100 test partitions in our
presented results. In the case of CSL2N and other
methods that make use of it (i.e. CSL1+L2N and
CSall), the languages selected for a given training
fold are then used to compute the compositionality
scores for the instances in the test set. Figures 3a,
3b and 3c are histograms of the number of times
each N is selected over 100 folds on ENC, EVPC
and GNC datasets, respectively. From the his-
tograms, N = 6, N = 15 and N = 2 are the most
commonly selected settings for ENC, EVPC and
GNC, respectively. That is, multiple languages are
generally used, but more languages are used for
English VPCs than either of the compound noun
datasets. The 5 most-selected languages for ENC,
EVPC and GNC are shown in Table 1. As we
can see, there are some languages which are al-
ways selected for a given dataset, but equally the
commonly-selected languages vary considerably
between datasets.
Further analysis reveals that 32 (63%) target
languages for ENC, 25 (49%) target languages
for EVPC, and only 5 (10%) target languages for
GNC have a correlation of r ≥ 0.1 with gold-
standard compositionality judgements. On the
other hand, 8 (16%) target languages for ENC, 2
(4%) target languages for EVPC, and no target lan-
guages for GNC have a correlation of r ≤ −0.1.
</bodyText>
<subsectionHeader confidence="0.971401">
5.1 ENC Results
</subsectionHeader>
<bodyText confidence="0.953669607142857">
English noun compounds are relatively easy to
identify in a corpus,7 because the components oc-
cur sequentially, and the only morphological vari-
ation is in noun number (singular vs. plural). In
other words, the precision for our token match-
ing method is very high, and the recall is also
acceptably high. Partly as a result of the ease
of identification, we get a high correlation of
r = 0.700 for CSL1 (using only source language
data). Using only target languages (CSL2N), the
results drop to r = 0.434, but when we combine
the two (CSL1+L2N), the correlation is higher
than using only source or target language data, at
r = 0.725. When we combine all languages us-
ing SVR, the results rise slightly higher again to
r = 0.744, which is slightly above the correla-
tion of the state-of-the-art method of Salehi and
Cook (2013), which combines their method with
the method of Reddy et al. (2011) (CSstring+L1).
These last two results support our hypothesis that
using translation data can improve the prediction
of compositionality. The results for string similar-
ity on its own (CSstring, r = 0.644) are slightly
lower than those using only source language dis-
tributional similarity, but when combined with
7Although see Lapata and Lascarides (2003) for discus-
sion of the difficulty of reliably identifying low-frequency
English noun compounds.
</bodyText>
<page confidence="0.994274">
477
</page>
<figure confidence="0.994194294117647">
25
20
15
10
5
0 0 5 10 15 20 25
20
18
16
14
12
10
8
6
4
2
00 5 10 15 20 25
Frequency
Frequency
bestN best N
(a) ENC (b) EVPC
20
18
16
14
Frequency 12
10
8
6
4
2
0 0 5 10 15 20 25
best N
(c) GNC
</figure>
<figureCaption confidence="0.955893666666667">
Figure 3: Histograms displaying how many times a given N is selected as the best number of languages
over each dataset. For example, according to the GNC chart, there is a peak for N = 2, which shows
that over 100 folds, the best-2 languages achieved the highest correlation on 18 folds.
</figureCaption>
<table confidence="0.996076875">
Method Summary of the Method ENC EVPC GNC
CSL1 Source language 0.700 0.177 0.141
CSL2N Best-N target languages 0.434 0.398 0.113
CSL1+L2N Source + best-N target languages 0.725 0.312 0.178
CSSVR(L1+L2) SVR (Source + all 51 target languages) 0.744 0.389 0.085
CSstring String Similarity (Salehi and Cook, 2013) 0.644 0.385 0.372
CSstring+L1 CSstring +CSL1 (Salehi and Cook, 2013) 0.739 0.360 0.353
CSall CSL1 + CSL2N + CSstring 0.732 0.417 0.364
</table>
<tableCaption confidence="0.999425">
Table 2: Pearson’s correlation on the ENC, EVPC and GNC datasets
</tableCaption>
<bodyText confidence="0.919093">
CSL1+L2N (i.e. CSall) there is a slight rise in cor-
relation (from r = 0.725 to r = 0.732).
</bodyText>
<subsectionHeader confidence="0.998321">
5.2 EVPC Results
</subsectionHeader>
<bodyText confidence="0.999468566666667">
English VPCs are hard to identify. As discussed
in Section 2, VPC components may not occur se-
quentially, and even when they do occur sequen-
tially, they may not be a VPC. As such, our sim-
plistic identification method has low precision and
recall (hand analysis of 927 identified VPC in-
stances would suggest a precision of around 74%).
There is no question that this is a contributor to
the low correlation for the source language method
(CSL1; r = 0.177). When we use target lan-
guages instead of the source language (CSL2N),
the correlation jumps substantially to r = 0.398.
When we combine English and the target lan-
guages (CSL1+L2N), the results are actually lower
than just using the target languages, because of
the high weight on the target language, which is
not desirable for VPCs, based on the source lan-
guage results. Even for CSSVR(L1+L2), the re-
sults (r = 0.389) are slightly below the target
language-only results. This suggests that when
predicting the compositionality of MWEs which
are hard to identify in the source language, it may
actually be better to use target languages only. The
results for string similarity (CSstring: r = 0.385)
are similar to those for CSL2N. However, as with
the ENC dataset, when we combine string simi-
larity and distributional similarity (CSall), the re-
sults improve, and we achieve the state-of-the-art
for the dataset.
In Table 3, we present classification-based eval-
</bodyText>
<page confidence="0.995347">
478
</page>
<table confidence="0.95667925">
Method Precision Recall F-score (Q = 1) Accuracy
Bannard et al. (2003) 60.8 66.6 63.6 60.0
Salehi and Cook (2013) 86.2 71.8 77.4 69.3
CSall 79.5 89.3 82.0 74.5
</table>
<tableCaption confidence="0.999878">
Table 3: Results (%) for the binary compositionality prediction task on the EVPC dataset
</tableCaption>
<bodyText confidence="0.9993555">
uation over a subset of EVPC, binarising the com-
positionality judgements in the manner of Bannard
et al. (2003). Our method achieves state-of-the-art
results in terms of overall F-score and accuracy.
</bodyText>
<subsectionHeader confidence="0.998781">
5.3 GNC Results
</subsectionHeader>
<bodyText confidence="0.999989490196079">
German is a morphologically-rich language, with
marking of number and case on nouns. Given
that we do not perform any lemmatization or other
language-specific preprocessing, we inevitably
achieve low recall for the identification of noun
compound tokens, although the precision should
be nearly 100%. Partly because of the resultant
sparseness in the distributional similarity method,
the results for CSL1 are low (r = 0.141), al-
though they are lower again when using target lan-
guages (r = 0.113). However, when we combine
the source and target languages (CSL1+L2N) the
results improve to r = 0.178. The results for
CSSVR(L1+L2), on the other hand, are very low
(r = 0.085). Ultimately, simple string similar-
ity achieves the best results for the dataset (r =
0.372), and this result actually drops slightly when
combined with the distributional similarities.
To better understand the reason for the lacklus-
tre results using SVR, we carried out error analysis
and found that, unlike the other two datasets, about
half of the target languages return scores which
correlate negatively with the human judgements.
When we filter these languages from the data, the
score for SVR improves appreciably. For example,
over the best-3 languages overall, we get a corre-
lation score of r = 0.179, which is slightly higher
than CSL1+L2N.
We further investigated the reason for getting
very low and sometimes negative correlations with
many of our target languages. We noted that
about 24% of the German noun compounds in
the dataset do not have entries in Panlex. This
contrasts with ENC where only one instance does
not have an entry in Panlex, and EVPC where all
VPCs have translations in at least one language in
Panlex. We experimented with using string sim-
ilarity scores in the case of such missing transla-
tions, as opposed to the strategy described in Sec-
tion 4.2. The results for CSSVR(L1+L2) rose to
r = 0.269, although this is still below the correla-
tion for just using string similarity.
Our results on the GNC dataset using string
similarity are competitive with the state-of-the-art
results (r = 0.45) using a window-based distribu-
tional similarity approach over monolingual Ger-
man data (Schulte im Walde et al., 2013). Note,
however, that their method used part-of-speech in-
formation and lemmatisation, where ours does not,
in keeping with the language-independent philos-
ophy of this research.
</bodyText>
<sectionHeader confidence="0.996166" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999966421052632">
In this study, we proposed a method to predict the
compositionality of MWEs based on monolingual
distributional similarity between the MWE and
each of its component words, under translation
into multiple target languages. We showed that
using translation and multiple target languages en-
hances compositionality modelling, and also that
there is strong complementarity between our ap-
proach and an approach based on string similarity.
In future work, we hope to address the ques-
tion of translation sparseness, as observed for the
GNC dataset. We also plan to experiment with un-
supervised morphological analysis methods to im-
prove identification recall, and explore the impact
of tokenization. Furthermore, we would like to in-
vestigate the optimal number of stop words and
content-bearing words for each language, and to
look into the development of general unsupervised
methods for compositionality prediction.
</bodyText>
<sectionHeader confidence="0.997749" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999348142857143">
We thank the anonymous reviewers for their
insightful comments and valuable suggestions.
NICTA is funded by the Australian government as
represented by Department of Broadband, Com-
munication and Digital Economy, and the Aus-
tralian Research Council through the ICT Centre
of Excellence programme.
</bodyText>
<page confidence="0.998855">
479
</page>
<sectionHeader confidence="0.967778" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998178181818182">
Otavio Acosta, Aline Villavicencio, and Viviane Mor-
eira. 2011. Identification and treatment of multi-
word expressions applied to information retrieval.
In Proceedings of the Workshop on Multiword Ex-
pressions: from Parsing and Generation to the Real
World, pages 101–109, Portland, USA.
Timothy Baldwin and Su Nam Kim. 2009. Multiword
expressions. In Nitin Indurkhya and Fred J. Dam-
erau, editors, Handbook of Natural Language Pro-
cessing. CRC Press, Boca Raton, USA, 2nd edition.
Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and
Dominic Widdows. 2003. An empirical model
of multiword expression decomposability. In Pro-
ceedings of the ACL-2003 Workshop on Multiword
Expressions: Analysis, Acquisition and Treatment,
pages 89–96, Sapporo, Japan.
Timothy Baldwin, Jonathan Pool, and Susan M Colow-
ick. 2010. Panlex and lextract: Translating all
words of all languages of the world. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics: Demonstrations, pages 37–
40, Beijing, China.
Timothy Baldwin. 2006. Distributional similarity and
preposition semantics. In Patrick Saint-Dizier, ed-
itor, Computational Linguistics Dimensions of Syn-
tax and Semantics of Prepositions, pages 197–210.
Springer, Dordrecht, Netherlands.
Colin Bannard, Timothy Baldwin, and Alex Las-
carides. 2003. A statistical approach to the seman-
tics of verb-particles. In Proceedings of the ACL
2003 workshop on Multiword expressions: analysis,
acquisition and treatment-Volume 18, pages 65–72,
Sapporo, Japan.
Colin James Bannard. 2006. Acquiring Phrasal Lexi-
cons from Corpora. Ph.D. thesis, University of Ed-
inburgh.
Marine Carpuat and Mona Diab. 2010. Task-based
evaluation of multiword expressions: a pilot study
in statistical machine translation. In Human Lan-
guage Technologies: The 2010 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics, pages 242–245, Los
Angeles, USA.
Ga¨el Dias. 2003. Multiword unit hybrid extraction. In
Proceedings of the ACL 2003 Workshop on Multi-
word Expressions: Analysis, Acquisition and Treat-
ment, pages 41–48, Sapporo, Japan.
Stefan Evert and Brigitte Krenn. 2005. Using small
random samples for the manual evaluation of statis-
tical association measures. Computer Speech and
Language, Special Issue on Multiword Expressions,
19(4):450–466.
Afsaneh Fazly, Paul Cook, and Suzanne Stevenson.
2009. Unsupervised type and token identification of
idiomatic expressions. Computational Linguistics,
35(1):61–103.
Su Nam Kim and Timothy Baldwin. 2007. Detecting
compositionality of English verb-particle construc-
tions using semantic similarity. In Proceedings of
the 7th Meeting of the Pacific Association for Com-
putational Linguistics (PACLING 2007), pages 40–
48, Melbourne, Australia.
Mirella Lapata and Alex Lascarides. 2003. Detect-
ing novel compounds: The role of distributional ev-
idence. In Proceedings of the 11th Conference of
the European Chapterfor the Association of Compu-
tational Linguistics (EACL-2003), pages 235–242,
Budapest, Hungary.
Dekang Lin. 1999. Automatic identification of
non-compositional phrases. In Proceedings of the
37th annual meeting of the Association for Compu-
tational Linguistics on Computational Linguistics,
pages 317–324, College Park, USA.
Diana McCarthy, Bill Keller, and John Carroll.
2003. Detecting a continuum of compositionality
in phrasal verbs. In Proceedings of the ACL 2003
workshop on Multiword expressions: analysis, ac-
quisition and treatment-Volume 18, pages 73–80,
Sapporo, Japan.
Pavel Pecina. 2008. Lexical Association Measures:
Collocation Extraction. Ph.D. thesis, Faculty of
Mathematics and Physics, Charles University in
Prague, Prague, Czech Republic.
Karl Pichotta and John DeNero. 2013. Identify-
ing phrasal verbs using many bilingual corpora. In
Proceedings of the 2013 Conference on Empirical
Methods in Natural Language Processing (EMNLP
2013), Seattle, USA.
Carlos Ramisch. 2012. A generic framework for mul-
tiword expressions treatment: from acquisition to
applications. In Proceedings of ACL 2012 Student
Research Workshop, pages 61–66, Jeju Island, Ko-
rea.
Siva Reddy, Diana McCarthy, and Suresh Manandhar.
2011. An empirical study on compositionality in
compound nouns. In Proceedings of IJCNLP, pages
210–218, Chiang Mai, Thailand.
Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copes-
take, and Dan Flickinger. 2002. Multiword ex-
pressions: A pain in the neck for NLP. In Pro-
ceedings of the 3rd International Conference on
Intelligent Text Processing Computational Linguis-
tics (CICLing-2002), pages 189–206, Mexico City,
Mexico.
Bahar Salehi and Paul Cook. 2013. Predicting
the compositionality of multiword expressions using
translations in multiple languages. In Proceedings
of the Second Joint Conference on Lexical and Com-
putational Semantics, volume 1, pages 266–275, At-
lanta, USA.
</reference>
<page confidence="0.975615">
480
</page>
<reference confidence="0.999698147058823">
Bahar Salehi, Narjes Askarian, and Afsaneh Fazly.
2012. Automatic identification of Persian light verb
constructions. In Proceedings of the 13th Inter-
national Conference on Intelligent Text Processing
Computational Linguistics (CICLing-2012), pages
201–210, New Delhi, India.
Patrick Schone and Dan Jurafsky. 2001. Is knowledge-
free induction of multiword unit dictionary head-
words a solved problem. In Proceedings of the 6th
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP 2001), pages 100–108,
Hong Kong, China.
Sabine Schulte im Walde, Stefan M¨uller, and Stephen
Roller. 2013. Exploring vector space models to
predict the compositionality of German noun-noun
compounds. In Proceedings of the Second Joint
Conference on Lexical and Computational Seman-
tics, Atlanta, USA.
Hinrich Sch¨utze. 1997. Ambiguity Resolution in Lan-
guage Learning. CSLI Publications, Stanford, USA.
Alex J Smola and Bernhard Sch¨olkopf. 2004. A tu-
torial on support vector regression. Statistics and
Computing, 14(3):199–222.
Charles Frederick Voegelin and Florence Marie
Voegelin. 1977. Classification and index of the
world’s languages, volume 4. New York: Elsevier.
Claudia von der Heide and Susanne Borgwaldt. 2009.
Assoziationen zu Unter, Basis und Oberbegriffen.
Eine explorative Studie. In Proceedings of the 9th
Norddeutsches Linguistisches Kolloquium, pages
51–74.
Julie Elizabeth Weeds. 2003. Measures and applica-
tions of lexical distributional similarity. Ph.D. the-
sis, University of Sussex.
</reference>
<page confidence="0.998711">
481
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9993">Using Distributional Similarity of Multi-way Translations to Multiword Expression Compositionality</title>
<author confidence="0.912941">Paul</author>
<author confidence="0.912941">Timothy</author>
<affiliation confidence="0.841265333333333">Victoria Research of Computing and Information The University of</affiliation>
<address confidence="0.997798">Victoria 3010, Australia</address>
<email confidence="0.996413">bsalehi@student.unimelb.edu.au,paulcook@unimelb.edu.au,tb@ldwin.net</email>
<abstract confidence="0.998916386363637">We predict the compositionality of multiword expressions using distributional similarity between each component word and the overall expression, based on translations into multiple languages. We evaluate the method over English noun compounds, English verb particle constructions and German noun compounds. We show that the estimation of compositionality is improved when using translations into multiple languages, as compared to simply using distributional similarity in the source language. We further find that string similarity complements distributional similarity. 1 Compositionality of MWEs Multiword expressions (hereafter MWEs) are combinations of words which are lexically, syntactically, semantically or statistically idiosyncratic (Sag et al., 2002; Baldwin and Kim, 2009). Much research has been carried out on the extraction and of in English (Schone and Jurafsky, 2001; Pecina, 2008; Fazly et al., 2009) and other languages (Dias, 2003; Evert and Krenn, 2005; Salehi et al., 2012). However, considerably less work has addressed the task of predicting the meaning of MWEs, especially in non-English languages. As a step in this direction, the focus of this study is on predicting the compositionality of MWEs. An MWE is fully compositional if its meaning is predictable from its component words, and it is non-compositional (or idiomatic) if not. For exup to one’s feet” is composithis paper, we follow Baldwin and Kim (2009) in considering MWE “identification” to be a token-level disambiguation task, and MWE “extraction” to be a type-level lexicon induction task. tional, because its meaning is clear from the meanof the components However, the of up start playing” is largely from the component words In this study, following McCarthy et al. (2003) and Reddy et al. (2011), we consider compositionto be graded, and aim to predict the of compositionality. For example, in the dataset Reddy et al. (2011), change judged be 99% compositional, while screen compositional and tower 9% compositional. Formally, we model compositionality prediction as a regression task. An explicit handling of MWEs has been shown to be useful in NLP applications (Ramisch, 2012). As an example, Carpuat and Diab (2010) proposed two strategies for integrating MWEs into statistical machine translation. They show that even a large scale bilingual corpus cannot capture all the necessary information to translate MWEs, and that in adding the facility to model the compositionality of MWEs into their system, they could improve translation quality. Acosta et al. (2011) showed that treating non-compositional MWEs as a single unit in information retrieval improves retrieval effectiveness. For example, while searching for related to we are almost certainly not interested in documents relating to elephant tusks. Our approach is to use a large-scale multi-way translation lexicon to source translations of MWEs and their component words, and then model the relative similarity between each of the component words and the MWE, using distributional similarity based on monolingual corpora for the source language and each of the target languages. Our hypothesis is that using distributional similarity in more than one language will improve the prediction of compositionality. Importantly, in order to make the method as language-independent and 472 of the 14th Conference of the European Chapter of the Association for Computational pages 472–481, Sweden, April 26-30 2014. Association for Computational Linguistics broadly-applicable as possible, we make no use of corpus preprocessing such as lemmatisation, and rely only on the availability of a translation dictionary and monolingual corpora. Our results confirm our hypothesis that distributional similarity over the source language in addition to multiple target languages improves the quality of compositionality prediction. We also show that our method can be complemented with string similarity (Salehi and Cook, 2013) to further improve compositionality prediction. We achieve state-of-the-art results over two datasets. 2 Related Work Most recent work on predicting the compositionality of MWEs can be divided into two categories: language/construction-specific and general-purpose. This can be at either the tokenlevel (over token occurrences of an MWE in a corpus) or type-level (over the MWE string, independent of usage). The bulk of work on compositionality has been language/construction-specific and operated at the token-level, using dedicated methods to identify instances of a given MWE, and specific properties of the MWE in that language to predict compositionality (Lin, 1999; Kim and Baldwin, 2007; Fazly et al., 2009). General-purpose token-level approaches such as distributional similarity have been commonly applied to infer the semantics of a word/MWE (Schone and Jurafsky, 2001; Baldwin et al., 2003; Reddy et al., 2011). These techniques are based on the assumption that the meaning of a word is predictable from its context of use, via the neighbouring words of token-level occurrences of the MWE. In order to predict the compositionality of a given MWE using distributional similarity, the different contexts of the MWE are compared with the contexts of its components, and the MWE is considered to be compositional if the MWE and component words occur in similar contexts. Identifying token instances of MWEs is not always easy, especially when the component words do not occur sequentially. For example consider on jacket and jacket In the first example on an while in the second example, on a simple verb with prepositional phrase and not an instance of an MWE. Moreover, if we adopt a conservative identification method, the number of token occurrences will be limited and the distributional scores may not be reliable. Additionally, for morphologically-rich languages, it can be difficult to predict the different word forms a given MWE type will occur across, posing a challenge for our requirement of no language-specific preprocessing. Pichotta and DeNero (2013) proposed a tokenbased method for identifying English phrasal verbs based on parallel corpora for 50 languages. They show that they can identify phrasal verbs better when they combine information from multiple languages, in addition to the information they get from a monolingual corpus. This finding lends weight to our hypothesis that using translation data and distributional similarity from each of a range of target languages, can improve compositionality prediction. Having said that, the general applicability of the method is questionable — there are many parallel corpora involving English, but for other languages, this tends not to be the case. Salehi and Cook (2013) proposed a generalpurpose type-based approach using translation data from multiple languages, and string similarity between the MWE and each of the component words. They use training data to identify the best-10 languages for a given family of MWEs, on which to base the string similarity, and once again find that translation data improves their results substantially. Among the four string similarity measures they experimented with, longest common substring was found to perform best. Their proposed method is general and applicable to different families of MWEs in different languages. In this paper, we reimplement the method of Salehi and Cook (2013) using longest common substring (LCS), and both benchmark against this method and combine it with our distributional similaritybased method. 3 Our Approach To predict the compositionality of a given MWE, we first measure the semantic similarity between MWE and each of its component using distributional similarity based on a monolingual corpus in the source language. We then repeat the process for translations of the MWE and its component words into each of a range of target languages, calculating distributional similarity using that we will always assume that there are two component words, but the method is easily generalisable to MWEs with more than two components. 473 for each language for each language Translations (using Panlex) (using Panlex) (using Panlex) DS DS (using Wikiepdia) Compositionality score Figure 1: Outline of our approach to computing the distributional similarity (DS) of translations of an MWE with each of its component words, a given target language. are the similarity for the first and second components, respectively. We obtain translations from Panlex, and use Wikipedia as our corpus for each language. a monolingual corpus in the target language (Figure 1). We additionally use supervised learning to identify which target languages (or what weights for each language) optimise the prediction of compositionality (Figure 2). We hypothesise that by using multiple translations — rather than only information from the source language — we will be able to better predict compositionality. We optionally combine our proposed approach with string similarity, calculated based on the method of Salehi and Cook (2013), using LCS. Below, we detail our method for calculating distributional similarity in a given language, the different methods for combining distributional similarity scores into a single estimate of compositionality, and finally the method for selecting the target languages to use in calculating compositionality. 3.1 Calculating Distributional Similarity In order to be consistent across all languages and as language-independent as possible, we calcu- Figure 2: Outline of the method for combining distributional similarity scores from multiple languages, across the components of the MWE. to one of the methods described in Section 3.2 for calculating compositionality. late distributional similarity in the following manner for a given language. Tokenisation is based on whitespace delimiters and punctuation; no lemmatisation or case-folding is carried out. Token instances of a given MWE component word are identified by full-token gram matching over the token stream. We assume that all full stops and equivalent characters for other orthographies are sentence boundaries, and chunk the corpora into (pseudo-)sentences on the basis of them. For each language, we identify the 51st–1050th most frequent words, and consider them to be content-bearing words, in the manner of Sch¨utze (1997). This is based on the assumption that the top-50 most frequent words are stop words, and not a good choice of word for calculating distributional similarity over. That is not to say that we can’t calculate the distributional similarity for stop words, however (as we will for the verb particle construction dataset — see Section 4.3.2) they are simply not used as the dimensions in our calculation of distributional similarity. We form a vector of content-bearing words across all token occurrences of the target word, 474 on the basis of these content-bearing words. Distributional similarity is calculated over these context vectors using cosine similarity. According to Weeds (2003), using dependency relations with the neighbouring words of the target word can better predict the meaning of the target word. However, in line with our assumption of no language-specific preprocessing, we just use word co-occurrence. 3.2 Calculating Compositionality First, we need to calculate a combined compositionality score from the individual distributional similarities between each component word and the MWE. Following Reddy et al. (2011), we combine the component scores using the weighted mean (as shown in Figure 2): (1 the scores for the first and the second component, respectively. We use diffor each dataset, as detailed in Section 4.3. We experiment with a range of methods for calculating compositionality, as follows: distributional similarity using only distributional similarity in the source language corpus (This is the approach used by Reddy et al. (2011), as discussed in Section 2). the source language, and compute the mean of the distributional similarity for the languages. The of selected according to training data, as detailed in Section 3.3. distributional similarity both the source language and mean of the combine via the arithmetic This is to examine the hypothesis that using multiple target languages is better than just using the source language. a support vector regressor (SVR: Smola and Sch¨olkopf (2004)) over the distributional similarities for all 52 languages (source and target languages). also experimented with taking the mean over all the languages — target and source — but found it best to combine the scores for the target languages first, to give more weight to the source language. string similarity using the LCS-based method of Salehi and Cook the mean of the string and distributional similarity in the source language (Salehi and Cook, 2013). the mean of the string similarity and distributional similarity scores and 3.3 Selecting Target Languages We experiment with two approaches for combining the compositionality scores from multiple target languages. in (andand build off it), we use training data to rank the target languages according to Pearson’s correlation between the predicted compositionality scores and the gold-standard compositionality judgements. on this ranking, we take the languages, and combine the individual compositionality scores by taking the arithmetic mean. We sedetermining the value that optimises the correlation over the training data. In other words, selection of accordingly the languages are based on nested cross-validation over training data, independently of the test data for that iteration of cross-validation. in we combine the compositionality scores from the source and all 51 target languages into a feature vector, and train an over the data using 4 Resources In this section, we describe the resources required by our method, and also the datasets used to evaluate our method. 4.1 Monolingual Corpora for Different Languages We collected monolingual corpora for each of 52 languages (51 target languages + 1 source language) from XML dumps of Wikipedia. These languages are based on the 54 target languages to differences in our random partitioning, our reported results over the two English datasets differ slightly over the results of Salehi and Cook (2013) using the same method. 475 used by Salehi and Cook (2013), excluding Spanish because we happened not to have a dump of Spanish Wikipedia, and also Chinese and Japanese because of the need for a language-specific word tokeniser. The raw corpora were preprocessed usthe WP2TXT to eliminate XML tags, HTML tags and hyperlinks, and then tokenisation based on whitespace and punctuation was performed. The corpora vary in size from roughly 750M tokens for English, to roughly 640K tokens for Marathi. 4.2 Multilingual Dictionary To translate the MWEs and their components, we follow Salehi and Cook (2013) in using Panlex (Baldwin et al., 2010). This online dictionary is massively multilingual, covering more than 1353 languages. For each MWE dataset (see Section 4.3), we translate the MWE and component words from the source language into each of the 51 languages. In instances where there is no direct translation in a given language for a term, we use a pivot language to find translation(s) in the target language. example, the English noun compound direct translations in only 13 languages Panlex, including Vietnamese but not French. There is, however, a translation of bac French allowing us to an indirect translation between screen In this way, if there are no direct translations into a particular target language, we search for a single-pivot translation via each of our other target languages, and combine them all together as our set of translations for the target language of interest. In the case that no translation (direct or indirect) can be found for a given source language term into a particular target language, the compositionality score for that target language is set to the average across all target languages for which scores can be calculated for the given term. If no translations are available for any target language (e.g. the term is not in Panlex) the compositionality score for each target language is set to the average score for that target language across all other source language terms. 4.3 Datasets We evaluate our proposed method over three datasets (two English, one German), as described below. 4.3.1 English Noun Compounds (ENC) Our first dataset is made up of 90 binary English noun compounds, from the work of Reddy et al. (2011). Each noun compound was annotated by multiple annotators using the integer scale 0 (fully non-compositional) to 5 (fully compositional). A final compositionality score was then calculated as the mean of the scores from the annotators. If we simplistically consider 2.5 as the threshold for compositionality, the dataset is relatively well balanced, containing 48% compositional and 52% non-compositional noun compounds. Following Reddy et al. (2011), in combining the componentwise distributional similarities for this dataset, we weight the first component in Equation 1 higher the second 4.3.2 English Verb Particle Constructions (EVPC) The second dataset contains 160 English verb particle constructions (VPCs), from the work of Bannard (2006). In this dataset, a verb particle construction consists of a verb (the head) and a prepoparticle (e.g. up For each component word (the verb and particle, respectively), multiple annotators were asked whether the VPC entails the component word. In order to translate the dataset into a regression task, we calculate the overall compositionality as the number of annotations of entailment for the verb, divided by the total number of verb annotations for that VPC. That is, following Bannard et al. (2003), we only consider the compositionality of the verb in our experiments (and as such 1 in Equation 1). One area of particular interest with this dataset will be the robustness of the method to function words (the particles), both under translation and in terms of calculating distributional similarity, although the findings of Baldwin (2006) for English prepositions are at least encouraging in this respect. Additionally, English VPCs can occur in form (e.g. jacket from our earlier example), which will complicate identification, and the verb component will often be inflected and thus not match under our identification strategy (for both VPCs and the component verbs).</abstract>
<note confidence="0.934912666666667">476 Dataset Language Frequency Family Italian 100 Romance French 99 Romance ENC German 86 Germanic Vietnamese 83 Viet-Muong Portuguese 62 Romance Bulgarian 100 Slavic Breton 100 Celtic EVPC Occitan 100 Romance Indonesian 100 Indonesian Slovenian 100 Slavic Polish 100 Slavic Lithuanian 99 Baltic GNC Finnish 74 Uralic Bulgarian 72 Slavic Czech 40 Slavic Table 1: The 5 best languages for the ENC, EVPC</note>
<abstract confidence="0.960273819277109">and GNC datasets. The language family is based on Voegelin and Voegelin (1977). 4.3.3 German Noun Compounds (GNC) Our final dataset is made up of 246 German noun compounds (von der Heide and Borgwaldt, 2009; Schulte im Walde et al., 2013). Multiple annotators were asked to rate the compositionality of each German noun compound on an integer scale of 1 (non-compositional) to 7 (compositional). The overall compositionality score is then calculated as the mean across the annotators. Note that the component words are provided as part of the dataset, and that there is no need to perform decompounding. Following Schulte im Walde et al. (2013), we weight the first component higher in 1 when calculating the overall compositionality score. This dataset is significant in being non-English, and also in that German has relatively rich morphology, which we expect to impact on the identification of both the MWE and the component words. 5 Results All experiments are carried out using 10 iterations of 10-fold cross validation, randomly partitioning the data independently on each of the 10 iterations, and averaging across all 100 test partitions in our results. In the case of other that make use of it (i.e. the languages selected for a given training fold are then used to compute the compositionality scores for the instances in the test set. Figures 3a, 3b and 3c are histograms of the number of times selected over 100 folds on ENC, EVPC and GNC datasets, respectively. From the his- 6, 15 and 2 are the most commonly selected settings for ENC, EVPC and GNC, respectively. That is, multiple languages are generally used, but more languages are used for English VPCs than either of the compound noun datasets. The 5 most-selected languages for ENC, EVPC and GNC are shown in Table 1. As we can see, there are some languages which are always selected for a given dataset, but equally the commonly-selected languages vary considerably between datasets. Further analysis reveals that 32 (63%) target languages for ENC, 25 (49%) target languages for EVPC, and only 5 (10%) target languages for have a correlation of with goldstandard compositionality judgements. On the other hand, 8 (16%) target languages for ENC, 2 (4%) target languages for EVPC, and no target lanfor GNC have a correlation of 5.1 ENC Results English noun compounds are relatively easy to in a because the components occur sequentially, and the only morphological variation is in noun number (singular vs. plural). In other words, the precision for our token matching method is very high, and the recall is also acceptably high. Partly as a result of the ease of identification, we get a high correlation of for only source language Using only target languages the drop to but when we combine two the correlation is higher than using only source or target language data, at When we combine all languages using SVR, the results rise slightly higher again to which is slightly above the correlation of the state-of-the-art method of Salehi and Cook (2013), which combines their method with method of Reddy et al. (2011) These last two results support our hypothesis that using translation data can improve the prediction of compositionality. The results for string similaron its own r are slightly lower than those using only source language distributional similarity, but when combined with see Lapata and Lascarides (2003) for discussion of the difficulty of reliably identifying low-frequency English noun compounds.</abstract>
<note confidence="0.83248134375">477 25 20 15 10 5 0 0 5 10 15 20 25 20 18 16 14 12 10 8 6 4 2 00 5 10 15 20 25 Frequency Frequency bestN best N (a) ENC (b) EVPC 20 18 16 14 Frequency 12 10 8 6 4 2</note>
<phone confidence="0.77696">0 0 5 10 15 20 25</phone>
<abstract confidence="0.96935023076923">best N (c) GNC 3: Histograms displaying how many times a given selected as the best number of languages each dataset. For example, according to the GNC chart, there is a peak for 2, which shows that over 100 folds, the best-2 languages achieved the highest correlation on 18 folds. Method Summary of the Method ENC EVPC GNC Source language 0.700 0.177 0.141 languages 0.434 0.398 0.113 + languages 0.725 0.312 0.178 SVR (Source + all 51 target languages) 0.744 0.389 0.085 String Similarity (Salehi and Cook, 2013) 0.644 0.385 0.372 and Cook, 2013) 0.739 0.360 0.353 0.732 0.417 0.364 Table 2: Pearson’s correlation on the ENC, EVPC and GNC datasets (i.e.there is a slight rise in cor- (from to 5.2 EVPC Results English VPCs are hard to identify. As discussed in Section 2, VPC components may not occur sequentially, and even when they do occur sequentially, they may not be a VPC. As such, our simplistic identification method has low precision and recall (hand analysis of 927 identified VPC instances would suggest a precision of around 74%). There is no question that this is a contributor to the low correlation for the source language method When we use target laninstead of the source language correlation jumps substantially to When we combine English and the target lanthe results are actually lower than just using the target languages, because of the high weight on the target language, which is not desirable for VPCs, based on the source lanresults. Even for the reare slightly below the target language-only results. This suggests that when predicting the compositionality of MWEs which are hard to identify in the source language, it may actually be better to use target languages only. The for string similarity r similar to those for However, as with the ENC dataset, when we combine string simiand distributional similarity the results improve, and we achieve the state-of-the-art for the dataset. Table 3, we present classification-based eval- 478 Method Precision Recall 1) Accuracy Bannard et al. (2003) 60.8 66.6 63.6 60.0 Salehi and Cook (2013) 86.2 71.8 77.4 69.3 79.5 89.3 82.0 74.5 Table 3: Results (%) for the binary compositionality prediction task on the EVPC dataset uation over a subset of EVPC, binarising the compositionality judgements in the manner of Bannard et al. (2003). Our method achieves state-of-the-art results in terms of overall F-score and accuracy. 5.3 GNC Results German is a morphologically-rich language, with marking of number and case on nouns. Given that we do not perform any lemmatization or other language-specific preprocessing, we inevitably achieve low recall for the identification of noun compound tokens, although the precision should be nearly 100%. Partly because of the resultant sparseness in the distributional similarity method, results for low although they are lower again when using target lan- However, when we combine source and target languages the improve to The results for on the other hand, are very low Ultimately, simple string similarachieves the best results for the dataset and this result actually drops slightly when combined with the distributional similarities. To better understand the reason for the lacklustre results using SVR, we carried out error analysis and found that, unlike the other two datasets, about half of the target languages return scores which correlate negatively with the human judgements. When we filter these languages from the data, the score for SVR improves appreciably. For example, over the best-3 languages overall, we get a correscore of which is slightly higher We further investigated the reason for getting very low and sometimes negative correlations with many of our target languages. We noted that about 24% of the German noun compounds in the dataset do not have entries in Panlex. This contrasts with ENC where only one instance does not have an entry in Panlex, and EVPC where all VPCs have translations in at least one language in Panlex. We experimented with using string similarity scores in the case of such missing translations, as opposed to the strategy described in Sec- 4.2. The results for to although this is still below the correlation for just using string similarity. Our results on the GNC dataset using string similarity are competitive with the state-of-the-art using a window-based distributional similarity approach over monolingual German data (Schulte im Walde et al., 2013). Note, however, that their method used part-of-speech information and lemmatisation, where ours does not, in keeping with the language-independent philosophy of this research. 6 Conclusion and Future Work In this study, we proposed a method to predict the compositionality of MWEs based on monolingual distributional similarity between the MWE and each of its component words, under translation into multiple target languages. We showed that using translation and multiple target languages enhances compositionality modelling, and also that there is strong complementarity between our approach and an approach based on string similarity. In future work, we hope to address the question of translation sparseness, as observed for the GNC dataset. We also plan to experiment with unsupervised morphological analysis methods to improve identification recall, and explore the impact of tokenization. Furthermore, we would like to investigate the optimal number of stop words and content-bearing words for each language, and to look into the development of general unsupervised methods for compositionality prediction. Acknowledgements We thank the anonymous reviewers for their insightful comments and valuable suggestions. NICTA is funded by the Australian government as represented by Department of Broadband, Communication and Digital Economy, and the Australian Research Council through the ICT Centre of Excellence programme. 479 References Otavio Acosta, Aline Villavicencio, and Viviane Moreira. 2011. Identification and treatment of multiword expressions applied to information retrieval. of the Workshop on Multiword Expressions: from Parsing and Generation to the Real</abstract>
<address confidence="0.794124">pages 101–109, Portland, USA.</address>
<author confidence="0.922026">Multiword expressions In Nitin Indurkhya</author>
<author confidence="0.922026">Fred J Dam-</author>
<affiliation confidence="0.690284">editors, of Natural Language Pro-</affiliation>
<note confidence="0.912928421052632">CRC Press, Boca Raton, USA, 2nd edition. Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and Dominic Widdows. 2003. An empirical model multiword expression decomposability. In Proceedings of the ACL-2003 Workshop on Multiword Analysis, Acquisition and pages 89–96, Sapporo, Japan. Timothy Baldwin, Jonathan Pool, and Susan M Colowick. 2010. Panlex and lextract: Translating all of all languages of the world. In Proceedings of the 23rd International Conference on Com- Linguistics: pages 37– 40, Beijing, China. Timothy Baldwin. 2006. Distributional similarity and preposition semantics. In Patrick Saint-Dizier, ed- Linguistics Dimensions of Synand Semantics of pages 197–210. Springer, Dordrecht, Netherlands. Colin Bannard, Timothy Baldwin, and Alex Las-</note>
<abstract confidence="0.856135">carides. 2003. A statistical approach to the semanof verb-particles. In of the ACL 2003 workshop on Multiword expressions: analysis, and treatment-Volume pages 65–72,</abstract>
<address confidence="0.760327">Sapporo, Japan.</address>
<author confidence="0.733806">Phrasal Lexi-</author>
<abstract confidence="0.8780112">from Ph.D. thesis, University of Edinburgh. Marine Carpuat and Mona Diab. 2010. Task-based evaluation of multiword expressions: a pilot study statistical machine translation. In Lan-</abstract>
<note confidence="0.8671545">guage Technologies: The 2010 Annual Conference of the North American Chapter of the Association Computational pages 242–245, Los Angeles, USA. Ga¨el Dias. 2003. Multiword unit hybrid extraction. In Proceedings of the ACL 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatpages 41–48, Sapporo, Japan.</note>
<author confidence="0.454013">Using small</author>
<abstract confidence="0.960876">random samples for the manual evaluation of statisassociation measures. Speech and Special Issue on Multiword 19(4):450–466. Afsaneh Fazly, Paul Cook, and Suzanne Stevenson. 2009. Unsupervised type and token identification of expressions. 35(1):61–103. Su Nam Kim and Timothy Baldwin. 2007. Detecting compositionality of English verb-particle construcusing semantic similarity. In of</abstract>
<note confidence="0.810252227272727">the 7th Meeting of the Pacific Association for Com- Linguistics (PACLING pages 40– 48, Melbourne, Australia. Mirella Lapata and Alex Lascarides. 2003. Detecting novel compounds: The role of distributional ev- In of the 11th Conference of the European Chapterfor the Association of Compu- Linguistics pages 235–242, Budapest, Hungary. Dekang Lin. 1999. Automatic identification of phrases. In of the 37th annual meeting of the Association for Compu- Linguistics on Computational pages 317–324, College Park, USA. Diana McCarthy, Bill Keller, and John Carroll. 2003. Detecting a continuum of compositionality phrasal verbs. In of the ACL 2003 workshop on Multiword expressions: analysis, acand treatment-Volume pages 73–80, Sapporo, Japan. Pecina. 2008. Association Measures: Ph.D. thesis, Faculty of Mathematics and Physics, Charles University in Prague, Prague, Czech Republic. Karl Pichotta and John DeNero. 2013. Identifying phrasal verbs using many bilingual corpora. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP Seattle, USA. Carlos Ramisch. 2012. A generic framework for multiword expressions treatment: from acquisition to In of ACL 2012 Student pages 61–66, Jeju Island, Korea. Siva Reddy, Diana McCarthy, and Suresh Manandhar. 2011. An empirical study on compositionality in nouns. In of pages 210–218, Chiang Mai, Thailand. Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword ex- A pain in the neck for NLP. In Proceedings of the 3rd International Conference on Intelligent Text Processing Computational Linguispages 189–206, Mexico City,</note>
<abstract confidence="0.7267042">Mexico. Bahar Salehi and Paul Cook. 2013. Predicting the compositionality of multiword expressions using in multiple languages. In of the Second Joint Conference on Lexical and Com-</abstract>
<address confidence="0.5360495">volume 1, pages 266–275, Atlanta, USA.</address>
<note confidence="0.703476333333333">480 Bahar Salehi, Narjes Askarian, and Afsaneh Fazly. 2012. Automatic identification of Persian light verb In of the 13th International Conference on Intelligent Text Processing Linguistics pages 201–210, New Delhi, India. Patrick Schone and Dan Jurafsky. 2001. Is knowledgefree induction of multiword unit dictionary heada solved problem. In of the 6th Conference on Empirical Methods in Natural Lan- Processing (EMNLP pages 100–108, Hong Kong, China. Sabine Schulte im Walde, Stefan M¨uller, and Stephen Roller. 2013. Exploring vector space models to predict the compositionality of German noun-noun In of the Second Joint Conference on Lexical and Computational Seman-</note>
<address confidence="0.843374">Atlanta, USA.</address>
<note confidence="0.837796666666667">Sch¨utze. 1997. Resolution in Lan- CSLI Publications, Stanford, USA. Alex J Smola and Bernhard Sch¨olkopf. 2004. A tuon support vector regression. and 14(3):199–222. Charles Frederick Voegelin and Florence Marie 1977. and index of the volume 4. New York: Elsevier. Claudia von der Heide and Susanne Borgwaldt. 2009.</note>
<abstract confidence="0.694252428571429">Assoziationen zu Unter, Basis und Oberbegriffen. explorative Studie. In of the 9th Linguistisches pages 51–74. Elizabeth Weeds. 2003. and applicaof lexical distributional Ph.D. thesis, University of Sussex.</abstract>
<intro confidence="0.314326">481</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Otavio Acosta</author>
<author>Aline Villavicencio</author>
<author>Viviane Moreira</author>
</authors>
<title>Identification and treatment of multiword expressions applied to information retrieval.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World,</booktitle>
<pages>101--109</pages>
<location>Portland, USA.</location>
<contexts>
<context position="3101" citStr="Acosta et al. (2011)" startWordPosition="468" endWordPosition="471">ilver screen is 48% compositional and ivory tower is 9% compositional. Formally, we model compositionality prediction as a regression task. An explicit handling of MWEs has been shown to be useful in NLP applications (Ramisch, 2012). As an example, Carpuat and Diab (2010) proposed two strategies for integrating MWEs into statistical machine translation. They show that even a large scale bilingual corpus cannot capture all the necessary information to translate MWEs, and that in adding the facility to model the compositionality of MWEs into their system, they could improve translation quality. Acosta et al. (2011) showed that treating non-compositional MWEs as a single unit in information retrieval improves retrieval effectiveness. For example, while searching for documents related to ivory tower, we are almost certainly not interested in documents relating to elephant tusks. Our approach is to use a large-scale multi-way translation lexicon to source translations of MWEs and their component words, and then model the relative similarity between each of the component words and the MWE, using distributional similarity based on monolingual corpora for the source language and each of the target languages. </context>
</contexts>
<marker>Acosta, Villavicencio, Moreira, 2011</marker>
<rawString>Otavio Acosta, Aline Villavicencio, and Viviane Moreira. 2011. Identification and treatment of multiword expressions applied to information retrieval. In Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World, pages 101–109, Portland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Su Nam Kim</author>
</authors>
<title>Multiword expressions.</title>
<date>2009</date>
<booktitle>In Nitin Indurkhya</booktitle>
<editor>and Fred J. Damerau, editors,</editor>
<publisher>CRC Press,</publisher>
<location>Boca Raton, USA,</location>
<note>2nd edition.</note>
<contexts>
<context position="1160" citStr="Baldwin and Kim, 2009" startWordPosition="149" endWordPosition="152">ons into multiple languages. We evaluate the method over English noun compounds, English verb particle constructions and German noun compounds. We show that the estimation of compositionality is improved when using translations into multiple languages, as compared to simply using distributional similarity in the source language. We further find that string similarity complements distributional similarity. 1 Compositionality of MWEs Multiword expressions (hereafter MWEs) are combinations of words which are lexically, syntactically, semantically or statistically idiosyncratic (Sag et al., 2002; Baldwin and Kim, 2009). Much research has been carried out on the extraction and identification of MWEs1 in English (Schone and Jurafsky, 2001; Pecina, 2008; Fazly et al., 2009) and other languages (Dias, 2003; Evert and Krenn, 2005; Salehi et al., 2012). However, considerably less work has addressed the task of predicting the meaning of MWEs, especially in non-English languages. As a step in this direction, the focus of this study is on predicting the compositionality of MWEs. An MWE is fully compositional if its meaning is predictable from its component words, and it is non-compositional (or idiomatic) if not. Fo</context>
</contexts>
<marker>Baldwin, Kim, 2009</marker>
<rawString>Timothy Baldwin and Su Nam Kim. 2009. Multiword expressions. In Nitin Indurkhya and Fred J. Damerau, editors, Handbook of Natural Language Processing. CRC Press, Boca Raton, USA, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Colin Bannard</author>
<author>Takaaki Tanaka</author>
<author>Dominic Widdows</author>
</authors>
<title>An empirical model of multiword expression decomposability.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment,</booktitle>
<pages>89--96</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="5479" citStr="Baldwin et al., 2003" startWordPosition="820" endWordPosition="823">ither the tokenlevel (over token occurrences of an MWE in a corpus) or type-level (over the MWE string, independent of usage). The bulk of work on compositionality has been language/construction-specific and operated at the token-level, using dedicated methods to identify instances of a given MWE, and specific properties of the MWE in that language to predict compositionality (Lin, 1999; Kim and Baldwin, 2007; Fazly et al., 2009). General-purpose token-level approaches such as distributional similarity have been commonly applied to infer the semantics of a word/MWE (Schone and Jurafsky, 2001; Baldwin et al., 2003; Reddy et al., 2011). These techniques are based on the assumption that the meaning of a word is predictable from its context of use, via the neighbouring words of token-level occurrences of the MWE. In order to predict the compositionality of a given MWE using distributional similarity, the different contexts of the MWE are compared with the contexts of its components, and the MWE is considered to be compositional if the MWE and component words occur in similar contexts. Identifying token instances of MWEs is not always easy, especially when the component words do not occur sequentially. For</context>
</contexts>
<marker>Baldwin, Bannard, Tanaka, Widdows, 2003</marker>
<rawString>Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and Dominic Widdows. 2003. An empirical model of multiword expression decomposability. In Proceedings of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, pages 89–96, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Jonathan Pool</author>
<author>Susan M Colowick</author>
</authors>
<title>Panlex and lextract: Translating all words of all languages of the world.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Demonstrations,</booktitle>
<pages>37--40</pages>
<location>Beijing, China.</location>
<contexts>
<context position="16278" citStr="Baldwin et al., 2010" startWordPosition="2532" endWordPosition="2535"> by Salehi and Cook (2013), excluding Spanish because we happened not to have a dump of Spanish Wikipedia, and also Chinese and Japanese because of the need for a language-specific word tokeniser. The raw corpora were preprocessed using the WP2TXT toolbox6 to eliminate XML tags, HTML tags and hyperlinks, and then tokenisation based on whitespace and punctuation was performed. The corpora vary in size from roughly 750M tokens for English, to roughly 640K tokens for Marathi. 4.2 Multilingual Dictionary To translate the MWEs and their components, we follow Salehi and Cook (2013) in using Panlex (Baldwin et al., 2010). This online dictionary is massively multilingual, covering more than 1353 languages. For each MWE dataset (see Section 4.3), we translate the MWE and component words from the source language into each of the 51 languages. In instances where there is no direct translation in a given language for a term, we use a pivot language to find translation(s) in the target language. For example, the English noun compound silver screen has direct translations in only 13 languages in Panlex, including Vietnamese (m`an bac) but not French. There is, however, a translation of m`an bac into French (cin´ema)</context>
</contexts>
<marker>Baldwin, Pool, Colowick, 2010</marker>
<rawString>Timothy Baldwin, Jonathan Pool, and Susan M Colowick. 2010. Panlex and lextract: Translating all words of all languages of the world. In Proceedings of the 23rd International Conference on Computational Linguistics: Demonstrations, pages 37– 40, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
</authors>
<title>Distributional similarity and preposition semantics.</title>
<date>2006</date>
<booktitle>Computational Linguistics Dimensions of Syntax and Semantics of Prepositions,</booktitle>
<pages>197--210</pages>
<editor>In Patrick Saint-Dizier, editor,</editor>
<publisher>Springer,</publisher>
<location>Dordrecht, Netherlands.</location>
<contexts>
<context position="19684" citStr="Baldwin (2006)" startWordPosition="3084" endWordPosition="3085">In order to translate the dataset into a regression task, we calculate the overall compositionality as the number of annotations of entailment for the verb, divided by the total number of verb annotations for that VPC. That is, following Bannard et al. (2003), we only consider the compositionality of the verb component in our experiments (and as such α = 1 in Equation 1). One area of particular interest with this dataset will be the robustness of the method to function words (the particles), both under translation and in terms of calculating distributional similarity, although the findings of Baldwin (2006) for English prepositions are at least encouraging in this respect. Additionally, English VPCs can occur in “split” form (e.g. put your jacket on, from our earlier example), which will complicate identification, and the verb component will often be inflected and thus not match under our identification strategy (for both VPCs and the component verbs). 476 Dataset Language Frequency Family Italian 100 Romance French 99 Romance ENC German 86 Germanic Vietnamese 83 Viet-Muong Portuguese 62 Romance Bulgarian 100 Slavic Breton 100 Celtic EVPC Occitan 100 Romance Indonesian 100 Indonesian Slovenian 1</context>
</contexts>
<marker>Baldwin, 2006</marker>
<rawString>Timothy Baldwin. 2006. Distributional similarity and preposition semantics. In Patrick Saint-Dizier, editor, Computational Linguistics Dimensions of Syntax and Semantics of Prepositions, pages 197–210. Springer, Dordrecht, Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Timothy Baldwin</author>
<author>Alex Lascarides</author>
</authors>
<title>A statistical approach to the semantics of verb-particles.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL</booktitle>
<pages>65--72</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="19329" citStr="Bannard et al. (2003)" startWordPosition="3024" endWordPosition="3027">160 English verb particle constructions (VPCs), from the work of Bannard (2006). In this dataset, a verb particle construction consists of a verb (the head) and a prepositional particle (e.g. hand in, look up or battle on). For each component word (the verb and particle, respectively), multiple annotators were asked whether the VPC entails the component word. In order to translate the dataset into a regression task, we calculate the overall compositionality as the number of annotations of entailment for the verb, divided by the total number of verb annotations for that VPC. That is, following Bannard et al. (2003), we only consider the compositionality of the verb component in our experiments (and as such α = 1 in Equation 1). One area of particular interest with this dataset will be the robustness of the method to function words (the particles), both under translation and in terms of calculating distributional similarity, although the findings of Baldwin (2006) for English prepositions are at least encouraging in this respect. Additionally, English VPCs can occur in “split” form (e.g. put your jacket on, from our earlier example), which will complicate identification, and the verb component will often</context>
<context position="26812" citStr="Bannard et al. (2003)" startWordPosition="4310" endWordPosition="4313">.389) are slightly below the target language-only results. This suggests that when predicting the compositionality of MWEs which are hard to identify in the source language, it may actually be better to use target languages only. The results for string similarity (CSstring: r = 0.385) are similar to those for CSL2N. However, as with the ENC dataset, when we combine string similarity and distributional similarity (CSall), the results improve, and we achieve the state-of-the-art for the dataset. In Table 3, we present classification-based eval478 Method Precision Recall F-score (Q = 1) Accuracy Bannard et al. (2003) 60.8 66.6 63.6 60.0 Salehi and Cook (2013) 86.2 71.8 77.4 69.3 CSall 79.5 89.3 82.0 74.5 Table 3: Results (%) for the binary compositionality prediction task on the EVPC dataset uation over a subset of EVPC, binarising the compositionality judgements in the manner of Bannard et al. (2003). Our method achieves state-of-the-art results in terms of overall F-score and accuracy. 5.3 GNC Results German is a morphologically-rich language, with marking of number and case on nouns. Given that we do not perform any lemmatization or other language-specific preprocessing, we inevitably achieve low recal</context>
</contexts>
<marker>Bannard, Baldwin, Lascarides, 2003</marker>
<rawString>Colin Bannard, Timothy Baldwin, and Alex Lascarides. 2003. A statistical approach to the semantics of verb-particles. In Proceedings of the ACL 2003 workshop on Multiword expressions: analysis, acquisition and treatment-Volume 18, pages 65–72, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin James Bannard</author>
</authors>
<title>Acquiring Phrasal Lexicons from Corpora.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="18787" citStr="Bannard (2006)" startWordPosition="2934" endWordPosition="2936">positionality score was then calculated as the mean of the scores from the annotators. If we simplistically consider 2.5 as the threshold for compositionality, the dataset is relatively well balanced, containing 48% compositional and 52% non-compositional noun compounds. Following Reddy et al. (2011), in combining the componentwise distributional similarities for this dataset, we weight the first component in Equation 1 higher than the second (α = 0.7). 4.3.2 English Verb Particle Constructions (EVPC) The second dataset contains 160 English verb particle constructions (VPCs), from the work of Bannard (2006). In this dataset, a verb particle construction consists of a verb (the head) and a prepositional particle (e.g. hand in, look up or battle on). For each component word (the verb and particle, respectively), multiple annotators were asked whether the VPC entails the component word. In order to translate the dataset into a regression task, we calculate the overall compositionality as the number of annotations of entailment for the verb, divided by the total number of verb annotations for that VPC. That is, following Bannard et al. (2003), we only consider the compositionality of the verb compon</context>
</contexts>
<marker>Bannard, 2006</marker>
<rawString>Colin James Bannard. 2006. Acquiring Phrasal Lexicons from Corpora. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Mona Diab</author>
</authors>
<title>Task-based evaluation of multiword expressions: a pilot study in statistical machine translation.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>242--245</pages>
<location>Los Angeles, USA.</location>
<contexts>
<context position="2753" citStr="Carpuat and Diab (2010)" startWordPosition="414" endWordPosition="417"> playing” is largely unpredictable from the component words strike and up. In this study, following McCarthy et al. (2003) and Reddy et al. (2011), we consider compositionality to be graded, and aim to predict the degree of compositionality. For example, in the dataset of Reddy et al. (2011), climate change is judged to be 99% compositional, while silver screen is 48% compositional and ivory tower is 9% compositional. Formally, we model compositionality prediction as a regression task. An explicit handling of MWEs has been shown to be useful in NLP applications (Ramisch, 2012). As an example, Carpuat and Diab (2010) proposed two strategies for integrating MWEs into statistical machine translation. They show that even a large scale bilingual corpus cannot capture all the necessary information to translate MWEs, and that in adding the facility to model the compositionality of MWEs into their system, they could improve translation quality. Acosta et al. (2011) showed that treating non-compositional MWEs as a single unit in information retrieval improves retrieval effectiveness. For example, while searching for documents related to ivory tower, we are almost certainly not interested in documents relating to </context>
</contexts>
<marker>Carpuat, Diab, 2010</marker>
<rawString>Marine Carpuat and Mona Diab. 2010. Task-based evaluation of multiword expressions: a pilot study in statistical machine translation. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 242–245, Los Angeles, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ga¨el Dias</author>
</authors>
<title>Multiword unit hybrid extraction.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment,</booktitle>
<pages>41--48</pages>
<location>Sapporo, Japan.</location>
<marker>Ga¨el Dias, 2003</marker>
<rawString>Ga¨el Dias. 2003. Multiword unit hybrid extraction. In Proceedings of the ACL 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, pages 41–48, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
<author>Brigitte Krenn</author>
</authors>
<title>Using small random samples for the manual evaluation of statistical association measures.</title>
<date>2005</date>
<journal>Computer Speech and Language, Special Issue on Multiword Expressions,</journal>
<volume>19</volume>
<issue>4</issue>
<contexts>
<context position="1370" citStr="Evert and Krenn, 2005" startWordPosition="183" endWordPosition="186">ing translations into multiple languages, as compared to simply using distributional similarity in the source language. We further find that string similarity complements distributional similarity. 1 Compositionality of MWEs Multiword expressions (hereafter MWEs) are combinations of words which are lexically, syntactically, semantically or statistically idiosyncratic (Sag et al., 2002; Baldwin and Kim, 2009). Much research has been carried out on the extraction and identification of MWEs1 in English (Schone and Jurafsky, 2001; Pecina, 2008; Fazly et al., 2009) and other languages (Dias, 2003; Evert and Krenn, 2005; Salehi et al., 2012). However, considerably less work has addressed the task of predicting the meaning of MWEs, especially in non-English languages. As a step in this direction, the focus of this study is on predicting the compositionality of MWEs. An MWE is fully compositional if its meaning is predictable from its component words, and it is non-compositional (or idiomatic) if not. For example, stand up “rise to one’s feet” is composi1In this paper, we follow Baldwin and Kim (2009) in considering MWE “identification” to be a token-level disambiguation task, and MWE “extraction” to be a type</context>
</contexts>
<marker>Evert, Krenn, 2005</marker>
<rawString>Stefan Evert and Brigitte Krenn. 2005. Using small random samples for the manual evaluation of statistical association measures. Computer Speech and Language, Special Issue on Multiword Expressions, 19(4):450–466.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Afsaneh Fazly</author>
<author>Paul Cook</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Unsupervised type and token identification of idiomatic expressions.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>1</issue>
<contexts>
<context position="1315" citStr="Fazly et al., 2009" startWordPosition="174" endWordPosition="177">he estimation of compositionality is improved when using translations into multiple languages, as compared to simply using distributional similarity in the source language. We further find that string similarity complements distributional similarity. 1 Compositionality of MWEs Multiword expressions (hereafter MWEs) are combinations of words which are lexically, syntactically, semantically or statistically idiosyncratic (Sag et al., 2002; Baldwin and Kim, 2009). Much research has been carried out on the extraction and identification of MWEs1 in English (Schone and Jurafsky, 2001; Pecina, 2008; Fazly et al., 2009) and other languages (Dias, 2003; Evert and Krenn, 2005; Salehi et al., 2012). However, considerably less work has addressed the task of predicting the meaning of MWEs, especially in non-English languages. As a step in this direction, the focus of this study is on predicting the compositionality of MWEs. An MWE is fully compositional if its meaning is predictable from its component words, and it is non-compositional (or idiomatic) if not. For example, stand up “rise to one’s feet” is composi1In this paper, we follow Baldwin and Kim (2009) in considering MWE “identification” to be a token-level</context>
<context position="5292" citStr="Fazly et al., 2009" startWordPosition="794" endWordPosition="797">asets. 2 Related Work Most recent work on predicting the compositionality of MWEs can be divided into two categories: language/construction-specific and general-purpose. This can be at either the tokenlevel (over token occurrences of an MWE in a corpus) or type-level (over the MWE string, independent of usage). The bulk of work on compositionality has been language/construction-specific and operated at the token-level, using dedicated methods to identify instances of a given MWE, and specific properties of the MWE in that language to predict compositionality (Lin, 1999; Kim and Baldwin, 2007; Fazly et al., 2009). General-purpose token-level approaches such as distributional similarity have been commonly applied to infer the semantics of a word/MWE (Schone and Jurafsky, 2001; Baldwin et al., 2003; Reddy et al., 2011). These techniques are based on the assumption that the meaning of a word is predictable from its context of use, via the neighbouring words of token-level occurrences of the MWE. In order to predict the compositionality of a given MWE using distributional similarity, the different contexts of the MWE are compared with the contexts of its components, and the MWE is considered to be composi</context>
</contexts>
<marker>Fazly, Cook, Stevenson, 2009</marker>
<rawString>Afsaneh Fazly, Paul Cook, and Suzanne Stevenson. 2009. Unsupervised type and token identification of idiomatic expressions. Computational Linguistics, 35(1):61–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su Nam Kim</author>
<author>Timothy Baldwin</author>
</authors>
<title>Detecting compositionality of English verb-particle constructions using semantic similarity.</title>
<date>2007</date>
<booktitle>In Proceedings of the 7th Meeting of the Pacific Association for Computational Linguistics (PACLING</booktitle>
<pages>40--48</pages>
<location>Melbourne, Australia.</location>
<contexts>
<context position="5271" citStr="Kim and Baldwin, 2007" startWordPosition="790" endWordPosition="793">rt results over two datasets. 2 Related Work Most recent work on predicting the compositionality of MWEs can be divided into two categories: language/construction-specific and general-purpose. This can be at either the tokenlevel (over token occurrences of an MWE in a corpus) or type-level (over the MWE string, independent of usage). The bulk of work on compositionality has been language/construction-specific and operated at the token-level, using dedicated methods to identify instances of a given MWE, and specific properties of the MWE in that language to predict compositionality (Lin, 1999; Kim and Baldwin, 2007; Fazly et al., 2009). General-purpose token-level approaches such as distributional similarity have been commonly applied to infer the semantics of a word/MWE (Schone and Jurafsky, 2001; Baldwin et al., 2003; Reddy et al., 2011). These techniques are based on the assumption that the meaning of a word is predictable from its context of use, via the neighbouring words of token-level occurrences of the MWE. In order to predict the compositionality of a given MWE using distributional similarity, the different contexts of the MWE are compared with the contexts of its components, and the MWE is con</context>
</contexts>
<marker>Kim, Baldwin, 2007</marker>
<rawString>Su Nam Kim and Timothy Baldwin. 2007. Detecting compositionality of English verb-particle constructions using semantic similarity. In Proceedings of the 7th Meeting of the Pacific Association for Computational Linguistics (PACLING 2007), pages 40– 48, Melbourne, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Alex Lascarides</author>
</authors>
<title>Detecting novel compounds: The role of distributional evidence.</title>
<date>2003</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapterfor the Association of Computational Linguistics (EACL-2003),</booktitle>
<pages>235--242</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="24124" citStr="Lapata and Lascarides (2003)" startWordPosition="3831" endWordPosition="3834">, at r = 0.725. When we combine all languages using SVR, the results rise slightly higher again to r = 0.744, which is slightly above the correlation of the state-of-the-art method of Salehi and Cook (2013), which combines their method with the method of Reddy et al. (2011) (CSstring+L1). These last two results support our hypothesis that using translation data can improve the prediction of compositionality. The results for string similarity on its own (CSstring, r = 0.644) are slightly lower than those using only source language distributional similarity, but when combined with 7Although see Lapata and Lascarides (2003) for discussion of the difficulty of reliably identifying low-frequency English noun compounds. 477 25 20 15 10 5 0 0 5 10 15 20 25 20 18 16 14 12 10 8 6 4 2 00 5 10 15 20 25 Frequency Frequency bestN best N (a) ENC (b) EVPC 20 18 16 14 Frequency 12 10 8 6 4 2 0 0 5 10 15 20 25 best N (c) GNC Figure 3: Histograms displaying how many times a given N is selected as the best number of languages over each dataset. For example, according to the GNC chart, there is a peak for N = 2, which shows that over 100 folds, the best-2 languages achieved the highest correlation on 18 folds. Method Summary of </context>
</contexts>
<marker>Lapata, Lascarides, 2003</marker>
<rawString>Mirella Lapata and Alex Lascarides. 2003. Detecting novel compounds: The role of distributional evidence. In Proceedings of the 11th Conference of the European Chapterfor the Association of Computational Linguistics (EACL-2003), pages 235–242, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic identification of non-compositional phrases.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics,</booktitle>
<pages>317--324</pages>
<location>College Park, USA.</location>
<contexts>
<context position="5248" citStr="Lin, 1999" startWordPosition="788" endWordPosition="789">te-of-the-art results over two datasets. 2 Related Work Most recent work on predicting the compositionality of MWEs can be divided into two categories: language/construction-specific and general-purpose. This can be at either the tokenlevel (over token occurrences of an MWE in a corpus) or type-level (over the MWE string, independent of usage). The bulk of work on compositionality has been language/construction-specific and operated at the token-level, using dedicated methods to identify instances of a given MWE, and specific properties of the MWE in that language to predict compositionality (Lin, 1999; Kim and Baldwin, 2007; Fazly et al., 2009). General-purpose token-level approaches such as distributional similarity have been commonly applied to infer the semantics of a word/MWE (Schone and Jurafsky, 2001; Baldwin et al., 2003; Reddy et al., 2011). These techniques are based on the assumption that the meaning of a word is predictable from its context of use, via the neighbouring words of token-level occurrences of the MWE. In order to predict the compositionality of a given MWE using distributional similarity, the different contexts of the MWE are compared with the contexts of its compone</context>
</contexts>
<marker>Lin, 1999</marker>
<rawString>Dekang Lin. 1999. Automatic identification of non-compositional phrases. In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, pages 317–324, College Park, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Bill Keller</author>
<author>John Carroll</author>
</authors>
<title>Detecting a continuum of compositionality in phrasal verbs.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL</booktitle>
<pages>73--80</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="2252" citStr="McCarthy et al. (2003)" startWordPosition="331" endWordPosition="334"> fully compositional if its meaning is predictable from its component words, and it is non-compositional (or idiomatic) if not. For example, stand up “rise to one’s feet” is composi1In this paper, we follow Baldwin and Kim (2009) in considering MWE “identification” to be a token-level disambiguation task, and MWE “extraction” to be a type-level lexicon induction task. tional, because its meaning is clear from the meaning of the components stand and up. However, the meaning of strike up “to start playing” is largely unpredictable from the component words strike and up. In this study, following McCarthy et al. (2003) and Reddy et al. (2011), we consider compositionality to be graded, and aim to predict the degree of compositionality. For example, in the dataset of Reddy et al. (2011), climate change is judged to be 99% compositional, while silver screen is 48% compositional and ivory tower is 9% compositional. Formally, we model compositionality prediction as a regression task. An explicit handling of MWEs has been shown to be useful in NLP applications (Ramisch, 2012). As an example, Carpuat and Diab (2010) proposed two strategies for integrating MWEs into statistical machine translation. They show that </context>
</contexts>
<marker>McCarthy, Keller, Carroll, 2003</marker>
<rawString>Diana McCarthy, Bill Keller, and John Carroll. 2003. Detecting a continuum of compositionality in phrasal verbs. In Proceedings of the ACL 2003 workshop on Multiword expressions: analysis, acquisition and treatment-Volume 18, pages 73–80, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pavel Pecina</author>
</authors>
<title>Lexical Association Measures: Collocation Extraction.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>Faculty of Mathematics and Physics, Charles University in Prague,</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="1294" citStr="Pecina, 2008" startWordPosition="172" endWordPosition="173">We show that the estimation of compositionality is improved when using translations into multiple languages, as compared to simply using distributional similarity in the source language. We further find that string similarity complements distributional similarity. 1 Compositionality of MWEs Multiword expressions (hereafter MWEs) are combinations of words which are lexically, syntactically, semantically or statistically idiosyncratic (Sag et al., 2002; Baldwin and Kim, 2009). Much research has been carried out on the extraction and identification of MWEs1 in English (Schone and Jurafsky, 2001; Pecina, 2008; Fazly et al., 2009) and other languages (Dias, 2003; Evert and Krenn, 2005; Salehi et al., 2012). However, considerably less work has addressed the task of predicting the meaning of MWEs, especially in non-English languages. As a step in this direction, the focus of this study is on predicting the compositionality of MWEs. An MWE is fully compositional if its meaning is predictable from its component words, and it is non-compositional (or idiomatic) if not. For example, stand up “rise to one’s feet” is composi1In this paper, we follow Baldwin and Kim (2009) in considering MWE “identification</context>
</contexts>
<marker>Pecina, 2008</marker>
<rawString>Pavel Pecina. 2008. Lexical Association Measures: Collocation Extraction. Ph.D. thesis, Faculty of Mathematics and Physics, Charles University in Prague, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karl Pichotta</author>
<author>John DeNero</author>
</authors>
<title>Identifying phrasal verbs using many bilingual corpora.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP 2013),</booktitle>
<location>Seattle, USA.</location>
<contexts>
<context position="6714" citStr="Pichotta and DeNero (2013)" startWordPosition="1030" endWordPosition="1033">consider put on in put your jacket on, and put your jacket on the chair. In the first example put on is an MWE while in the second example, put on is a simple verb with prepositional phrase and not an instance of an MWE. Moreover, if we adopt a conservative identification method, the number of token occurrences will be limited and the distributional scores may not be reliable. Additionally, for morphologically-rich languages, it can be difficult to predict the different word forms a given MWE type will occur across, posing a challenge for our requirement of no language-specific preprocessing. Pichotta and DeNero (2013) proposed a tokenbased method for identifying English phrasal verbs based on parallel corpora for 50 languages. They show that they can identify phrasal verbs better when they combine information from multiple languages, in addition to the information they get from a monolingual corpus. This finding lends weight to our hypothesis that using translation data and distributional similarity from each of a range of target languages, can improve compositionality prediction. Having said that, the general applicability of the method is questionable — there are many parallel corpora involving English, </context>
</contexts>
<marker>Pichotta, DeNero, 2013</marker>
<rawString>Karl Pichotta and John DeNero. 2013. Identifying phrasal verbs using many bilingual corpora. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP 2013), Seattle, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Ramisch</author>
</authors>
<title>A generic framework for multiword expressions treatment: from acquisition to applications.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL 2012 Student Research Workshop,</booktitle>
<pages>61--66</pages>
<location>Jeju Island,</location>
<contexts>
<context position="2713" citStr="Ramisch, 2012" startWordPosition="409" endWordPosition="410"> meaning of strike up “to start playing” is largely unpredictable from the component words strike and up. In this study, following McCarthy et al. (2003) and Reddy et al. (2011), we consider compositionality to be graded, and aim to predict the degree of compositionality. For example, in the dataset of Reddy et al. (2011), climate change is judged to be 99% compositional, while silver screen is 48% compositional and ivory tower is 9% compositional. Formally, we model compositionality prediction as a regression task. An explicit handling of MWEs has been shown to be useful in NLP applications (Ramisch, 2012). As an example, Carpuat and Diab (2010) proposed two strategies for integrating MWEs into statistical machine translation. They show that even a large scale bilingual corpus cannot capture all the necessary information to translate MWEs, and that in adding the facility to model the compositionality of MWEs into their system, they could improve translation quality. Acosta et al. (2011) showed that treating non-compositional MWEs as a single unit in information retrieval improves retrieval effectiveness. For example, while searching for documents related to ivory tower, we are almost certainly </context>
</contexts>
<marker>Ramisch, 2012</marker>
<rawString>Carlos Ramisch. 2012. A generic framework for multiword expressions treatment: from acquisition to applications. In Proceedings of ACL 2012 Student Research Workshop, pages 61–66, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siva Reddy</author>
<author>Diana McCarthy</author>
<author>Suresh Manandhar</author>
</authors>
<title>An empirical study on compositionality in compound nouns.</title>
<date>2011</date>
<booktitle>In Proceedings of IJCNLP,</booktitle>
<pages>210--218</pages>
<location>Chiang Mai, Thailand.</location>
<contexts>
<context position="2276" citStr="Reddy et al. (2011)" startWordPosition="336" endWordPosition="339"> meaning is predictable from its component words, and it is non-compositional (or idiomatic) if not. For example, stand up “rise to one’s feet” is composi1In this paper, we follow Baldwin and Kim (2009) in considering MWE “identification” to be a token-level disambiguation task, and MWE “extraction” to be a type-level lexicon induction task. tional, because its meaning is clear from the meaning of the components stand and up. However, the meaning of strike up “to start playing” is largely unpredictable from the component words strike and up. In this study, following McCarthy et al. (2003) and Reddy et al. (2011), we consider compositionality to be graded, and aim to predict the degree of compositionality. For example, in the dataset of Reddy et al. (2011), climate change is judged to be 99% compositional, while silver screen is 48% compositional and ivory tower is 9% compositional. Formally, we model compositionality prediction as a regression task. An explicit handling of MWEs has been shown to be useful in NLP applications (Ramisch, 2012). As an example, Carpuat and Diab (2010) proposed two strategies for integrating MWEs into statistical machine translation. They show that even a large scale bilin</context>
<context position="5500" citStr="Reddy et al., 2011" startWordPosition="824" endWordPosition="827">over token occurrences of an MWE in a corpus) or type-level (over the MWE string, independent of usage). The bulk of work on compositionality has been language/construction-specific and operated at the token-level, using dedicated methods to identify instances of a given MWE, and specific properties of the MWE in that language to predict compositionality (Lin, 1999; Kim and Baldwin, 2007; Fazly et al., 2009). General-purpose token-level approaches such as distributional similarity have been commonly applied to infer the semantics of a word/MWE (Schone and Jurafsky, 2001; Baldwin et al., 2003; Reddy et al., 2011). These techniques are based on the assumption that the meaning of a word is predictable from its context of use, via the neighbouring words of token-level occurrences of the MWE. In order to predict the compositionality of a given MWE using distributional similarity, the different contexts of the MWE are compared with the contexts of its components, and the MWE is considered to be compositional if the MWE and component words occur in similar contexts. Identifying token instances of MWEs is not always easy, especially when the component words do not occur sequentially. For example consider put</context>
<context position="12313" citStr="Reddy et al. (2011)" startWordPosition="1900" endWordPosition="1903">ord, 474 on the basis of these content-bearing words. Distributional similarity is calculated over these context vectors using cosine similarity. According to Weeds (2003), using dependency relations with the neighbouring words of the target word can better predict the meaning of the target word. However, in line with our assumption of no language-specific preprocessing, we just use word co-occurrence. 3.2 Calculating Compositionality First, we need to calculate a combined compositionality score from the individual distributional similarities between each component word and the MWE. Following Reddy et al. (2011), we combine the component scores using the weighted mean (as shown in Figure 2): comp = αs1 + (1 − α)s2 (1) where s1 and s2 are the scores for the first and the second component, respectively. We use different α settings for each dataset, as detailed in Section 4.3. We experiment with a range of methods for calculating compositionality, as follows: CSL1: calculate distributional similarity using only distributional similarity in the source language corpus (This is the approach used by Reddy et al. (2011), as discussed in Section 2). CSL2N: exclude the source language, and compute the mean of </context>
<context position="18024" citStr="Reddy et al. (2011)" startWordPosition="2820" endWordPosition="2823">is set to the average across all target languages for which scores can be calculated for the given term. If no translations are available for any target language (e.g. the term is not in Panlex) the compositionality score for each target language is set to the average score for that target language across all other source language terms. 6http://wp2txt.rubyforge.org/ 4.3 Datasets We evaluate our proposed method over three datasets (two English, one German), as described below. 4.3.1 English Noun Compounds (ENC) Our first dataset is made up of 90 binary English noun compounds, from the work of Reddy et al. (2011). Each noun compound was annotated by multiple annotators using the integer scale 0 (fully non-compositional) to 5 (fully compositional). A final compositionality score was then calculated as the mean of the scores from the annotators. If we simplistically consider 2.5 as the threshold for compositionality, the dataset is relatively well balanced, containing 48% compositional and 52% non-compositional noun compounds. Following Reddy et al. (2011), in combining the componentwise distributional similarities for this dataset, we weight the first component in Equation 1 higher than the second (α =</context>
<context position="23770" citStr="Reddy et al. (2011)" startWordPosition="3778" endWordPosition="3781">recall is also acceptably high. Partly as a result of the ease of identification, we get a high correlation of r = 0.700 for CSL1 (using only source language data). Using only target languages (CSL2N), the results drop to r = 0.434, but when we combine the two (CSL1+L2N), the correlation is higher than using only source or target language data, at r = 0.725. When we combine all languages using SVR, the results rise slightly higher again to r = 0.744, which is slightly above the correlation of the state-of-the-art method of Salehi and Cook (2013), which combines their method with the method of Reddy et al. (2011) (CSstring+L1). These last two results support our hypothesis that using translation data can improve the prediction of compositionality. The results for string similarity on its own (CSstring, r = 0.644) are slightly lower than those using only source language distributional similarity, but when combined with 7Although see Lapata and Lascarides (2003) for discussion of the difficulty of reliably identifying low-frequency English noun compounds. 477 25 20 15 10 5 0 0 5 10 15 20 25 20 18 16 14 12 10 8 6 4 2 00 5 10 15 20 25 Frequency Frequency bestN best N (a) ENC (b) EVPC 20 18 16 14 Frequency</context>
</contexts>
<marker>Reddy, McCarthy, Manandhar, 2011</marker>
<rawString>Siva Reddy, Diana McCarthy, and Suresh Manandhar. 2011. An empirical study on compositionality in compound nouns. In Proceedings of IJCNLP, pages 210–218, Chiang Mai, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Intelligent Text Processing Computational Linguistics (CICLing-2002),</booktitle>
<pages>189--206</pages>
<location>Mexico City, Mexico.</location>
<contexts>
<context position="1136" citStr="Sag et al., 2002" startWordPosition="145" endWordPosition="148">based on translations into multiple languages. We evaluate the method over English noun compounds, English verb particle constructions and German noun compounds. We show that the estimation of compositionality is improved when using translations into multiple languages, as compared to simply using distributional similarity in the source language. We further find that string similarity complements distributional similarity. 1 Compositionality of MWEs Multiword expressions (hereafter MWEs) are combinations of words which are lexically, syntactically, semantically or statistically idiosyncratic (Sag et al., 2002; Baldwin and Kim, 2009). Much research has been carried out on the extraction and identification of MWEs1 in English (Schone and Jurafsky, 2001; Pecina, 2008; Fazly et al., 2009) and other languages (Dias, 2003; Evert and Krenn, 2005; Salehi et al., 2012). However, considerably less work has addressed the task of predicting the meaning of MWEs, especially in non-English languages. As a step in this direction, the focus of this study is on predicting the compositionality of MWEs. An MWE is fully compositional if its meaning is predictable from its component words, and it is non-compositional (</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proceedings of the 3rd International Conference on Intelligent Text Processing Computational Linguistics (CICLing-2002), pages 189–206, Mexico City, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bahar Salehi</author>
<author>Paul Cook</author>
</authors>
<title>Predicting the compositionality of multiword expressions using translations in multiple languages.</title>
<date>2013</date>
<booktitle>In Proceedings of the Second Joint Conference on Lexical and Computational Semantics,</booktitle>
<volume>1</volume>
<pages>266--275</pages>
<location>Atlanta, USA.</location>
<contexts>
<context position="4576" citStr="Salehi and Cook, 2013" startWordPosition="684" endWordPosition="687"> Chapter of the Association for Computational Linguistics, pages 472–481, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics broadly-applicable as possible, we make no use of corpus preprocessing such as lemmatisation, and rely only on the availability of a translation dictionary and monolingual corpora. Our results confirm our hypothesis that distributional similarity over the source language in addition to multiple target languages improves the quality of compositionality prediction. We also show that our method can be complemented with string similarity (Salehi and Cook, 2013) to further improve compositionality prediction. We achieve state-of-the-art results over two datasets. 2 Related Work Most recent work on predicting the compositionality of MWEs can be divided into two categories: language/construction-specific and general-purpose. This can be at either the tokenlevel (over token occurrences of an MWE in a corpus) or type-level (over the MWE string, independent of usage). The bulk of work on compositionality has been language/construction-specific and operated at the token-level, using dedicated methods to identify instances of a given MWE, and specific prope</context>
<context position="7392" citStr="Salehi and Cook (2013)" startWordPosition="1136" endWordPosition="1139">rasal verbs based on parallel corpora for 50 languages. They show that they can identify phrasal verbs better when they combine information from multiple languages, in addition to the information they get from a monolingual corpus. This finding lends weight to our hypothesis that using translation data and distributional similarity from each of a range of target languages, can improve compositionality prediction. Having said that, the general applicability of the method is questionable — there are many parallel corpora involving English, but for other languages, this tends not to be the case. Salehi and Cook (2013) proposed a generalpurpose type-based approach using translation data from multiple languages, and string similarity between the MWE and each of the component words. They use training data to identify the best-10 languages for a given family of MWEs, on which to base the string similarity, and once again find that translation data improves their results substantially. Among the four string similarity measures they experimented with, longest common substring was found to perform best. Their proposed method is general and applicable to different families of MWEs in different languages. In this p</context>
<context position="9862" citStr="Salehi and Cook (2013)" startWordPosition="1523" endWordPosition="1526"> components, respectively. We obtain translations from Panlex, and use Wikipedia as our corpus for each language. a monolingual corpus in the target language (Figure 1). We additionally use supervised learning to identify which target languages (or what weights for each language) optimise the prediction of compositionality (Figure 2). We hypothesise that by using multiple translations — rather than only information from the source language — we will be able to better predict compositionality. We optionally combine our proposed approach with string similarity, calculated based on the method of Salehi and Cook (2013), using LCS. Below, we detail our method for calculating distributional similarity in a given language, the different methods for combining distributional similarity scores into a single estimate of compositionality, and finally the method for selecting the target languages to use in calculating compositionality. 3.1 Calculating Distributional Similarity In order to be consistent across all languages and be as language-independent as possible, we calcuFigure 2: Outline of the method for combining distributional similarity scores from multiple languages, across the components of the MWE. CSmeth</context>
<context position="13816" citStr="Salehi and Cook (2013)" startWordPosition="2145" endWordPosition="2148"> and combine via the arithmetic mean.3 This is to examine the hypothesis that using multiple target languages is better than just using the source language. CSSVR(L1+L2): train a support vector regressor (SVR: Smola and Sch¨olkopf (2004)) over the distributional similarities for all 52 languages (source and target languages). 3We also experimented with taking the mean over all the languages — target and source — but found it best to combine the scores for the target languages first, to give more weight to the source language. CSstring: calculate string similarity using the LCS-based method of Salehi and Cook (2013).4 CSstring+L1: calculate the mean of the string similarity (CSstring) and distributional similarity in the source language (Salehi and Cook, 2013). CSall: calculate the mean of the string similarity (CSstring) and distributional similarity scores (CSL1 and CSL2N). 3.3 Selecting Target Languages We experiment with two approaches for combining the compositionality scores from multiple target languages. First, in CSL2N (and CSL1+L2N and CSall that build off it), we use training data to rank the target languages according to Pearson’s correlation between the predicted compositionality scores and </context>
<context position="15583" citStr="Salehi and Cook (2013)" startWordPosition="2421" endWordPosition="2424"> source and all 51 target languages into a feature vector, and train an SVR over the data using LIBSVM.5 4 Resources In this section, we describe the resources required by our method, and also the datasets used to evaluate our method. 4.1 Monolingual Corpora for Different Languages We collected monolingual corpora for each of 52 languages (51 target languages + 1 source language) from XML dumps of Wikipedia. These languages are based on the 54 target languages 4Due to differences in our random partitioning, our reported results over the two English datasets differ slightly over the results of Salehi and Cook (2013) using the same method. 5http://www.csie.ntu.edu.tw/˜cjlin/libsvm 475 used by Salehi and Cook (2013), excluding Spanish because we happened not to have a dump of Spanish Wikipedia, and also Chinese and Japanese because of the need for a language-specific word tokeniser. The raw corpora were preprocessed using the WP2TXT toolbox6 to eliminate XML tags, HTML tags and hyperlinks, and then tokenisation based on whitespace and punctuation was performed. The corpora vary in size from roughly 750M tokens for English, to roughly 640K tokens for Marathi. 4.2 Multilingual Dictionary To translate the MWE</context>
<context position="23702" citStr="Salehi and Cook (2013)" startWordPosition="3766" endWordPosition="3769">rds, the precision for our token matching method is very high, and the recall is also acceptably high. Partly as a result of the ease of identification, we get a high correlation of r = 0.700 for CSL1 (using only source language data). Using only target languages (CSL2N), the results drop to r = 0.434, but when we combine the two (CSL1+L2N), the correlation is higher than using only source or target language data, at r = 0.725. When we combine all languages using SVR, the results rise slightly higher again to r = 0.744, which is slightly above the correlation of the state-of-the-art method of Salehi and Cook (2013), which combines their method with the method of Reddy et al. (2011) (CSstring+L1). These last two results support our hypothesis that using translation data can improve the prediction of compositionality. The results for string similarity on its own (CSstring, r = 0.644) are slightly lower than those using only source language distributional similarity, but when combined with 7Although see Lapata and Lascarides (2003) for discussion of the difficulty of reliably identifying low-frequency English noun compounds. 477 25 20 15 10 5 0 0 5 10 15 20 25 20 18 16 14 12 10 8 6 4 2 00 5 10 15 20 25 Fre</context>
<context position="25015" citStr="Salehi and Cook, 2013" startWordPosition="4004" endWordPosition="4007"> 15 20 25 best N (c) GNC Figure 3: Histograms displaying how many times a given N is selected as the best number of languages over each dataset. For example, according to the GNC chart, there is a peak for N = 2, which shows that over 100 folds, the best-2 languages achieved the highest correlation on 18 folds. Method Summary of the Method ENC EVPC GNC CSL1 Source language 0.700 0.177 0.141 CSL2N Best-N target languages 0.434 0.398 0.113 CSL1+L2N Source + best-N target languages 0.725 0.312 0.178 CSSVR(L1+L2) SVR (Source + all 51 target languages) 0.744 0.389 0.085 CSstring String Similarity (Salehi and Cook, 2013) 0.644 0.385 0.372 CSstring+L1 CSstring +CSL1 (Salehi and Cook, 2013) 0.739 0.360 0.353 CSall CSL1 + CSL2N + CSstring 0.732 0.417 0.364 Table 2: Pearson’s correlation on the ENC, EVPC and GNC datasets CSL1+L2N (i.e. CSall) there is a slight rise in correlation (from r = 0.725 to r = 0.732). 5.2 EVPC Results English VPCs are hard to identify. As discussed in Section 2, VPC components may not occur sequentially, and even when they do occur sequentially, they may not be a VPC. As such, our simplistic identification method has low precision and recall (hand analysis of 927 identified VPC instances</context>
<context position="26855" citStr="Salehi and Cook (2013)" startWordPosition="4318" endWordPosition="4321">ge-only results. This suggests that when predicting the compositionality of MWEs which are hard to identify in the source language, it may actually be better to use target languages only. The results for string similarity (CSstring: r = 0.385) are similar to those for CSL2N. However, as with the ENC dataset, when we combine string similarity and distributional similarity (CSall), the results improve, and we achieve the state-of-the-art for the dataset. In Table 3, we present classification-based eval478 Method Precision Recall F-score (Q = 1) Accuracy Bannard et al. (2003) 60.8 66.6 63.6 60.0 Salehi and Cook (2013) 86.2 71.8 77.4 69.3 CSall 79.5 89.3 82.0 74.5 Table 3: Results (%) for the binary compositionality prediction task on the EVPC dataset uation over a subset of EVPC, binarising the compositionality judgements in the manner of Bannard et al. (2003). Our method achieves state-of-the-art results in terms of overall F-score and accuracy. 5.3 GNC Results German is a morphologically-rich language, with marking of number and case on nouns. Given that we do not perform any lemmatization or other language-specific preprocessing, we inevitably achieve low recall for the identification of noun compound t</context>
</contexts>
<marker>Salehi, Cook, 2013</marker>
<rawString>Bahar Salehi and Paul Cook. 2013. Predicting the compositionality of multiword expressions using translations in multiple languages. In Proceedings of the Second Joint Conference on Lexical and Computational Semantics, volume 1, pages 266–275, Atlanta, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bahar Salehi</author>
<author>Narjes Askarian</author>
<author>Afsaneh Fazly</author>
</authors>
<title>Automatic identification of Persian light verb constructions.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th International Conference on Intelligent Text Processing Computational Linguistics (CICLing-2012),</booktitle>
<pages>201--210</pages>
<location>New Delhi, India.</location>
<contexts>
<context position="1392" citStr="Salehi et al., 2012" startWordPosition="187" endWordPosition="190">ultiple languages, as compared to simply using distributional similarity in the source language. We further find that string similarity complements distributional similarity. 1 Compositionality of MWEs Multiword expressions (hereafter MWEs) are combinations of words which are lexically, syntactically, semantically or statistically idiosyncratic (Sag et al., 2002; Baldwin and Kim, 2009). Much research has been carried out on the extraction and identification of MWEs1 in English (Schone and Jurafsky, 2001; Pecina, 2008; Fazly et al., 2009) and other languages (Dias, 2003; Evert and Krenn, 2005; Salehi et al., 2012). However, considerably less work has addressed the task of predicting the meaning of MWEs, especially in non-English languages. As a step in this direction, the focus of this study is on predicting the compositionality of MWEs. An MWE is fully compositional if its meaning is predictable from its component words, and it is non-compositional (or idiomatic) if not. For example, stand up “rise to one’s feet” is composi1In this paper, we follow Baldwin and Kim (2009) in considering MWE “identification” to be a token-level disambiguation task, and MWE “extraction” to be a type-level lexicon inducti</context>
</contexts>
<marker>Salehi, Askarian, Fazly, 2012</marker>
<rawString>Bahar Salehi, Narjes Askarian, and Afsaneh Fazly. 2012. Automatic identification of Persian light verb constructions. In Proceedings of the 13th International Conference on Intelligent Text Processing Computational Linguistics (CICLing-2012), pages 201–210, New Delhi, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Schone</author>
<author>Dan Jurafsky</author>
</authors>
<title>Is knowledgefree induction of multiword unit dictionary headwords a solved problem.</title>
<date>2001</date>
<booktitle>In Proceedings of the 6th Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>100--108</pages>
<location>Hong Kong, China.</location>
<contexts>
<context position="1280" citStr="Schone and Jurafsky, 2001" startWordPosition="168" endWordPosition="171">and German noun compounds. We show that the estimation of compositionality is improved when using translations into multiple languages, as compared to simply using distributional similarity in the source language. We further find that string similarity complements distributional similarity. 1 Compositionality of MWEs Multiword expressions (hereafter MWEs) are combinations of words which are lexically, syntactically, semantically or statistically idiosyncratic (Sag et al., 2002; Baldwin and Kim, 2009). Much research has been carried out on the extraction and identification of MWEs1 in English (Schone and Jurafsky, 2001; Pecina, 2008; Fazly et al., 2009) and other languages (Dias, 2003; Evert and Krenn, 2005; Salehi et al., 2012). However, considerably less work has addressed the task of predicting the meaning of MWEs, especially in non-English languages. As a step in this direction, the focus of this study is on predicting the compositionality of MWEs. An MWE is fully compositional if its meaning is predictable from its component words, and it is non-compositional (or idiomatic) if not. For example, stand up “rise to one’s feet” is composi1In this paper, we follow Baldwin and Kim (2009) in considering MWE “</context>
<context position="5457" citStr="Schone and Jurafsky, 2001" startWordPosition="816" endWordPosition="819">l-purpose. This can be at either the tokenlevel (over token occurrences of an MWE in a corpus) or type-level (over the MWE string, independent of usage). The bulk of work on compositionality has been language/construction-specific and operated at the token-level, using dedicated methods to identify instances of a given MWE, and specific properties of the MWE in that language to predict compositionality (Lin, 1999; Kim and Baldwin, 2007; Fazly et al., 2009). General-purpose token-level approaches such as distributional similarity have been commonly applied to infer the semantics of a word/MWE (Schone and Jurafsky, 2001; Baldwin et al., 2003; Reddy et al., 2011). These techniques are based on the assumption that the meaning of a word is predictable from its context of use, via the neighbouring words of token-level occurrences of the MWE. In order to predict the compositionality of a given MWE using distributional similarity, the different contexts of the MWE are compared with the contexts of its components, and the MWE is considered to be compositional if the MWE and component words occur in similar contexts. Identifying token instances of MWEs is not always easy, especially when the component words do not o</context>
</contexts>
<marker>Schone, Jurafsky, 2001</marker>
<rawString>Patrick Schone and Dan Jurafsky. 2001. Is knowledgefree induction of multiword unit dictionary headwords a solved problem. In Proceedings of the 6th Conference on Empirical Methods in Natural Language Processing (EMNLP 2001), pages 100–108, Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
<author>Stefan M¨uller</author>
<author>Stephen Roller</author>
</authors>
<title>Exploring vector space models to predict the compositionality of German noun-noun compounds.</title>
<date>2013</date>
<booktitle>In Proceedings of the Second Joint Conference on Lexical and Computational Semantics,</booktitle>
<location>Atlanta, USA.</location>
<marker>Walde, M¨uller, Roller, 2013</marker>
<rawString>Sabine Schulte im Walde, Stefan M¨uller, and Stephen Roller. 2013. Exploring vector space models to predict the compositionality of German noun-noun compounds. In Proceedings of the Second Joint Conference on Lexical and Computational Semantics, Atlanta, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Ambiguity Resolution in Language Learning.</title>
<date>1997</date>
<publisher>CSLI Publications,</publisher>
<location>Stanford, USA.</location>
<marker>Sch¨utze, 1997</marker>
<rawString>Hinrich Sch¨utze. 1997. Ambiguity Resolution in Language Learning. CSLI Publications, Stanford, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex J Smola</author>
<author>Bernhard Sch¨olkopf</author>
</authors>
<title>A tutorial on support vector regression.</title>
<date>2004</date>
<journal>Statistics and Computing,</journal>
<volume>14</volume>
<issue>3</issue>
<marker>Smola, Sch¨olkopf, 2004</marker>
<rawString>Alex J Smola and Bernhard Sch¨olkopf. 2004. A tutorial on support vector regression. Statistics and Computing, 14(3):199–222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Frederick Voegelin</author>
<author>Florence Marie Voegelin</author>
</authors>
<title>Classification and index of the world’s languages, volume 4.</title>
<date>1977</date>
<publisher>Elsevier.</publisher>
<location>New York:</location>
<contexts>
<context position="20517" citStr="Voegelin and Voegelin (1977)" startWordPosition="3215" endWordPosition="3218">ation, and the verb component will often be inflected and thus not match under our identification strategy (for both VPCs and the component verbs). 476 Dataset Language Frequency Family Italian 100 Romance French 99 Romance ENC German 86 Germanic Vietnamese 83 Viet-Muong Portuguese 62 Romance Bulgarian 100 Slavic Breton 100 Celtic EVPC Occitan 100 Romance Indonesian 100 Indonesian Slovenian 100 Slavic Polish 100 Slavic Lithuanian 99 Baltic GNC Finnish 74 Uralic Bulgarian 72 Slavic Czech 40 Slavic Table 1: The 5 best languages for the ENC, EVPC and GNC datasets. The language family is based on Voegelin and Voegelin (1977). 4.3.3 German Noun Compounds (GNC) Our final dataset is made up of 246 German noun compounds (von der Heide and Borgwaldt, 2009; Schulte im Walde et al., 2013). Multiple annotators were asked to rate the compositionality of each German noun compound on an integer scale of 1 (non-compositional) to 7 (compositional). The overall compositionality score is then calculated as the mean across the annotators. Note that the component words are provided as part of the dataset, and that there is no need to perform decompounding. Following Schulte im Walde et al. (2013), we weight the first component hi</context>
</contexts>
<marker>Voegelin, Voegelin, 1977</marker>
<rawString>Charles Frederick Voegelin and Florence Marie Voegelin. 1977. Classification and index of the world’s languages, volume 4. New York: Elsevier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia von der Heide</author>
<author>Susanne Borgwaldt</author>
</authors>
<title>Assoziationen zu Unter, Basis und Oberbegriffen. Eine explorative Studie.</title>
<date>2009</date>
<booktitle>In Proceedings of the 9th Norddeutsches Linguistisches Kolloquium,</booktitle>
<pages>51--74</pages>
<marker>von der Heide, Borgwaldt, 2009</marker>
<rawString>Claudia von der Heide and Susanne Borgwaldt. 2009. Assoziationen zu Unter, Basis und Oberbegriffen. Eine explorative Studie. In Proceedings of the 9th Norddeutsches Linguistisches Kolloquium, pages 51–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie Elizabeth Weeds</author>
</authors>
<title>Measures and applications of lexical distributional similarity.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Sussex.</institution>
<contexts>
<context position="11865" citStr="Weeds (2003)" startWordPosition="1836" endWordPosition="1837">stop words, and not a good choice of word for calculating distributional similarity over. That is not to say that we can’t calculate the distributional similarity for stop words, however (as we will for the verb particle construction dataset — see Section 4.3.2) they are simply not used as the dimensions in our calculation of distributional similarity. We form a vector of content-bearing words across all token occurrences of the target word, 474 on the basis of these content-bearing words. Distributional similarity is calculated over these context vectors using cosine similarity. According to Weeds (2003), using dependency relations with the neighbouring words of the target word can better predict the meaning of the target word. However, in line with our assumption of no language-specific preprocessing, we just use word co-occurrence. 3.2 Calculating Compositionality First, we need to calculate a combined compositionality score from the individual distributional similarities between each component word and the MWE. Following Reddy et al. (2011), we combine the component scores using the weighted mean (as shown in Figure 2): comp = αs1 + (1 − α)s2 (1) where s1 and s2 are the scores for the firs</context>
</contexts>
<marker>Weeds, 2003</marker>
<rawString>Julie Elizabeth Weeds. 2003. Measures and applications of lexical distributional similarity. Ph.D. thesis, University of Sussex.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>