<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.341859">
<title confidence="0.996528">
State-of-the-Art Kernels for Natural Language Processing
</title>
<author confidence="0.998728">
Alessandro Moschitti
</author>
<affiliation confidence="0.9984525">
Department of Computer Science and Information Engineering
University of Trento
</affiliation>
<address confidence="0.957081">
Via Sommarive 5, 38123 Povo (TN), Italy
</address>
<email confidence="0.997304">
moschitti@disi.unitn.it
</email>
<sectionHeader confidence="0.99494" genericHeader="abstract">
Introduction
</sectionHeader>
<bodyText confidence="0.999986363636364">
In recent years, machine learning (ML) has been
used more and more to solve complex tasks in dif-
ferent disciplines, ranging from Data Mining to In-
formation Retrieval or Natural Language Processing
(NLP). These tasks often require the processing of
structured input, e.g., the ability to extract salient
features from syntactic/semantic structures is criti-
cal to many NLP systems. Mapping such structured
data into explicit feature vectors for ML algorithms
requires large expertise, intuition and deep knowl-
edge about the target linguistic phenomena. Ker-
nel Methods (KM) are powerful ML tools (see e.g.,
(Shawe-Taylor and Cristianini, 2004)), which can al-
leviate the data representation problem. They substi-
tute feature-based similarities with similarity func-
tions, i.e., kernels, directly defined between train-
ing/test instances, e.g., syntactic trees. Hence fea-
ture vectors are not needed any longer. Additionally,
kernel engineering, i.e., the composition or adapta-
tion of several prototype kernels, facilitates the de-
sign of effective similarities required for new tasks,
e.g., (Moschitti, 2004; Moschitti, 2008).
</bodyText>
<subsectionHeader confidence="0.981105">
Tutorial Content
</subsectionHeader>
<bodyText confidence="0.999880692307692">
The tutorial aims at addressing the problems above:
firstly, it will introduce essential and simplified the-
ory of Support Vector Machines and KM with the
only aim of motivating practical procedures and in-
terpreting the results. Secondly, it will simply de-
scribe the current best practices for designing ap-
plications based on effective kernels. For this pur-
pose, it will survey state-of-the-art kernels for di-
verse NLP applications, reconciling the different ap-
proaches with a uniform and global notation/theory.
Such survey will benefit from practical expertise ac-
quired from directly working on many natural lan-
guage applications, ranging from Text Categoriza-
tion to Syntactic/Semantic Parsing. Moreover, prac-
tical demonstrations using SVM-Light-TK toolkit
will nicely support the application-oriented perspec-
tive of the tutorial. The latter will lead NLP re-
searchers with heterogeneous background to the ac-
quisition of the KM know-how, which can be used
to design any target NLP application.
Finally, the tutorial will propose interesting new
best practices, e.g., some recent methods for large-
scale learning with structural kernels (Severyn
and Moschitti, 2011), structural lexical similarities
(Croce et al., 2011) and reverse kernel engineering
(Pighin and Moschitti, 2009).
</bodyText>
<sectionHeader confidence="0.992649" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9379631">
Danilo Croce, Alessandro Moschitti, and Roberto Basili.
2011. Structured Lexical Similarity via Convolution
Kernels on Dependency Trees. In Proc. of EMNLP.
Alessandro Moschitti. 2004. A Study on Convolution
Kernels for Shallow Semantic Parsing. In Proceedings
of ACL.
Alessandro Moschitti. 2008. Kernel Methods, Syntax
and Semantics for Relational Text Categorization. In
Proceedings of CIKM.
Daniele Pighin and Alessandro Moschitti. 2009. Effi-
cient Linearization of Tree Kernel Functions. In Pro-
ceedings of CoNLL.
Aliaksei Severyn and Alessandro Moschitti. 2011. Fast
Support Vector Machines for Structural Kernels. In
ECML.
John Shawe-Taylor and Nello Cristianini. 2004. Kernel
Methods for Pattern Analysis. Cambridge Univ. Press.
2
Tutorial Abstracts of ACL 2012, page 2,
Jeju, Republic of Korea, 8 July 2012. c�2012 Association for Computational Linguistics
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.646790">
<title confidence="0.999922">State-of-the-Art Kernels for Natural Language Processing</title>
<author confidence="0.996767">Alessandro</author>
<affiliation confidence="0.937939">Department of Computer Science and Information University of Via Sommarive 5, 38123 Povo (TN),</affiliation>
<email confidence="0.809548">moschitti@disi.unitn.it</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Danilo Croce</author>
<author>Alessandro Moschitti</author>
<author>Roberto Basili</author>
</authors>
<title>Structured Lexical Similarity via Convolution Kernels on Dependency Trees.</title>
<date>2011</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<marker>Croce, Moschitti, Basili, 2011</marker>
<rawString>Danilo Croce, Alessandro Moschitti, and Roberto Basili. 2011. Structured Lexical Similarity via Convolution Kernels on Dependency Trees. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>A Study on Convolution Kernels for Shallow Semantic Parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1333" citStr="Moschitti, 2004" startWordPosition="186" endWordPosition="187">intuition and deep knowledge about the target linguistic phenomena. Kernel Methods (KM) are powerful ML tools (see e.g., (Shawe-Taylor and Cristianini, 2004)), which can alleviate the data representation problem. They substitute feature-based similarities with similarity functions, i.e., kernels, directly defined between training/test instances, e.g., syntactic trees. Hence feature vectors are not needed any longer. Additionally, kernel engineering, i.e., the composition or adaptation of several prototype kernels, facilitates the design of effective similarities required for new tasks, e.g., (Moschitti, 2004; Moschitti, 2008). Tutorial Content The tutorial aims at addressing the problems above: firstly, it will introduce essential and simplified theory of Support Vector Machines and KM with the only aim of motivating practical procedures and interpreting the results. Secondly, it will simply describe the current best practices for designing applications based on effective kernels. For this purpose, it will survey state-of-the-art kernels for diverse NLP applications, reconciling the different approaches with a uniform and global notation/theory. Such survey will benefit from practical expertise a</context>
</contexts>
<marker>Moschitti, 2004</marker>
<rawString>Alessandro Moschitti. 2004. A Study on Convolution Kernels for Shallow Semantic Parsing. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Kernel Methods, Syntax and Semantics for Relational Text Categorization.</title>
<date>2008</date>
<booktitle>In Proceedings of CIKM.</booktitle>
<contexts>
<context position="1351" citStr="Moschitti, 2008" startWordPosition="188" endWordPosition="189">p knowledge about the target linguistic phenomena. Kernel Methods (KM) are powerful ML tools (see e.g., (Shawe-Taylor and Cristianini, 2004)), which can alleviate the data representation problem. They substitute feature-based similarities with similarity functions, i.e., kernels, directly defined between training/test instances, e.g., syntactic trees. Hence feature vectors are not needed any longer. Additionally, kernel engineering, i.e., the composition or adaptation of several prototype kernels, facilitates the design of effective similarities required for new tasks, e.g., (Moschitti, 2004; Moschitti, 2008). Tutorial Content The tutorial aims at addressing the problems above: firstly, it will introduce essential and simplified theory of Support Vector Machines and KM with the only aim of motivating practical procedures and interpreting the results. Secondly, it will simply describe the current best practices for designing applications based on effective kernels. For this purpose, it will survey state-of-the-art kernels for diverse NLP applications, reconciling the different approaches with a uniform and global notation/theory. Such survey will benefit from practical expertise acquired from direc</context>
</contexts>
<marker>Moschitti, 2008</marker>
<rawString>Alessandro Moschitti. 2008. Kernel Methods, Syntax and Semantics for Relational Text Categorization. In Proceedings of CIKM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniele Pighin</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Efficient Linearization of Tree Kernel Functions.</title>
<date>2009</date>
<booktitle>In Proceedings of CoNLL.</booktitle>
<marker>Pighin, Moschitti, 2009</marker>
<rawString>Daniele Pighin and Alessandro Moschitti. 2009. Efficient Linearization of Tree Kernel Functions. In Proceedings of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aliaksei Severyn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Fast Support Vector Machines for Structural Kernels.</title>
<date>2011</date>
<booktitle>In ECML.</booktitle>
<marker>Severyn, Moschitti, 2011</marker>
<rawString>Aliaksei Severyn and Alessandro Moschitti. 2011. Fast Support Vector Machines for Structural Kernels. In ECML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
</authors>
<title>Kernel Methods for Pattern Analysis. Cambridge Univ.</title>
<date>2004</date>
<volume>2</volume>
<publisher>Press.</publisher>
<contexts>
<context position="875" citStr="Shawe-Taylor and Cristianini, 2004" startWordPosition="120" endWordPosition="123">cent years, machine learning (ML) has been used more and more to solve complex tasks in different disciplines, ranging from Data Mining to Information Retrieval or Natural Language Processing (NLP). These tasks often require the processing of structured input, e.g., the ability to extract salient features from syntactic/semantic structures is critical to many NLP systems. Mapping such structured data into explicit feature vectors for ML algorithms requires large expertise, intuition and deep knowledge about the target linguistic phenomena. Kernel Methods (KM) are powerful ML tools (see e.g., (Shawe-Taylor and Cristianini, 2004)), which can alleviate the data representation problem. They substitute feature-based similarities with similarity functions, i.e., kernels, directly defined between training/test instances, e.g., syntactic trees. Hence feature vectors are not needed any longer. Additionally, kernel engineering, i.e., the composition or adaptation of several prototype kernels, facilitates the design of effective similarities required for new tasks, e.g., (Moschitti, 2004; Moschitti, 2008). Tutorial Content The tutorial aims at addressing the problems above: firstly, it will introduce essential and simplified t</context>
</contexts>
<marker>Shawe-Taylor, Cristianini, 2004</marker>
<rawString>John Shawe-Taylor and Nello Cristianini. 2004. Kernel Methods for Pattern Analysis. Cambridge Univ. Press. 2</rawString>
</citation>
<citation valid="true">
<title>Tutorial Abstracts of ACL 2012, page 2, Jeju,</title>
<date></date>
<booktitle>c�2012 Association for Computational Linguistics</booktitle>
<volume>8</volume>
<location>Republic of</location>
<marker></marker>
<rawString>Tutorial Abstracts of ACL 2012, page 2, Jeju, Republic of Korea, 8 July 2012. c�2012 Association for Computational Linguistics</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>