<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003658">
<title confidence="0.993939">
Measure Word Generation for English-Chinese SMT Systems
</title>
<author confidence="0.994131">
Dongdong Zhang1, Mu Li1, Nan Duan2, Chi-Ho Li1, Ming Zhou1
</author>
<affiliation confidence="0.855946">
1Microsoft Research Asia 2Tianjin University
</affiliation>
<address confidence="0.551844">
Beijing, China Tianjin, China
</address>
<email confidence="0.994908">
{dozhang,muli,v-naduan,chl,mingzhou}@microsoft.com
</email>
<sectionHeader confidence="0.995602" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998821842105263">
Measure words in Chinese are used to indi-
cate the count of nouns. Conventional sta-
tistical machine translation (SMT) systems do
not perform well on measure word generation
due to data sparseness and the potential long
distance dependency between measure words
and their corresponding head words. In this
paper, we propose a statistical model to gen-
erate appropriate measure words of nouns for
an English-to-Chinese SMT system. We mod-
el the probability of measure word generation
by utilizing lexical and syntactic knowledge
from both source and target sentences. Our
model works as a post-processing procedure
over output of statistical machine translation
systems, and can work with any SMT system.
Experimental results show our method can
achieve high precision and recall in measure
word generation.
</bodyText>
<sectionHeader confidence="0.999138" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999772833333333">
In linguistics, measure words (MW) are words or
morphemes used in combination with numerals or
demonstrative pronouns to indicate the count of
nouns1, which are often referred to as head words
(HW).
Chinese measure words are grammatical units
and occur quite often in real text. According to our
survey on the measure word distribution in the
Chinese Penn Treebank and the test datasets distri-
buted by Linguistic Data Consortium (LDC) for
Chinese-to-English machine translation evaluation,
the average occurrence is 0.505 and 0.319 measure
</bodyText>
<footnote confidence="0.620114">
1 The uncommon cases of verbs are not considered.
</footnote>
<page confidence="0.998618">
89
</page>
<bodyText confidence="0.999970393939394">
words per sentence respectively. Unlike in Chinese,
there is no special set of measure words in English.
Measure words are usually used for mass nouns
and any semantically appropriate nouns can func-
tion as the measure words. For example, in the
phrase three bottles of water, the word bottles acts
as a measure word. Countable nouns are almost
never modified by measure words2. Numerals and
indefinite articles are directly followed by counta-
ble nouns to denote the quantity of objects.
Therefore, in the English-to-Chinese machine
translation task we need to take additional efforts
to generate the missing measure words in Chinese.
For example, when translating the English phrase
three books into the Chinese phrases â€œä¸‰æœ¬ä¹¦â€,
where three corresponds to the numeral â€œä¸‰â€ and
books corresponds to the noun â€œä¹¦â€, the Chinese
measure word â€œæœ¬â€ should be generated between
the numeral and the noun.
In most statistical machine translation (SMT)
models (Och et al., 2004; Koehn et al., 2003;
Chiang, 2005), some of measure words can be
generated without modification or additional
processing. For example, in above translation, the
phrase translation table may suggest the word three
be translated into â€œä¸‰â€, â€œä¸‰æœ¬â€, â€œä¸‰åªâ€, etc, and
the word books into â€œä¹¦â€, â€œä¹¦æœ¬â€, â€œåå†Œâ€ (scroll),
etc. Then the SMT model selects the most likely
combination â€œä¸‰æœ¬ä¹¦â€ as the final translation re-
sult. In this example, a measure word candidate set
consisting of â€œæœ¬â€ and â€œåªâ€ can be generated by
bilingual phrases (or synchronous translation rules),
and the best measure word â€œæœ¬â€ from the measure
</bodyText>
<footnote confidence="0.573">
2 There are some exceptional cases, such as â€œ100 head of cat-
tleâ€. But they are very uncommon.
</footnote>
<note confidence="0.781543">
Proceedings of ACL-08: HLT, pages 89â€“96,
</note>
<page confidence="0.497362">
Columbus, Ohio, USA, June 2008. cï¿½2008 Association for Computational Linguistics
</page>
<figure confidence="0.896105857142857">
Pudong &apos;s de-
velopment and
opening up is a century-spanning
æµ¦ä¸œ/ffå‘/
ffIA/ æ˜¯/
ä¸€ é¡¹ æŒ¯å…´/ä¸Šæµ·/ ,/ å»ºè®¾ /ç°ä»£åŒ– /ç»æµ /è·¨/ä¸– å·¥ç¨‹
/ ã€/ è´¸æ˜“/ ã€ /é‡‘è/ tPå¿ƒ/ n/
undertaking
for vigorously promoting shanghai
and constructing a modern econom-
ic , trade , and financial center
çºª/
ã€‚
.
</figure>
<figureCaption confidence="0.999986">
Figure 1. Example of long distance dependency between MW and its modified HW
</figureCaption>
<bodyText confidence="0.9967529">
word candidate set can be selected by the SMT
decoder. However, as we will show below, existing
SMT systems do not deal well with the measure
word generation in general due to data sparseness
and long distance dependencies between measure
words and their corresponding head words.
Due to the limited size of bilingual corpora,
many measure words, as well as the collocations
between a measure and its head word, cannot be
well covered by the phrase translation table in an
SMT system. Moreover, Chinese measure words
often have a long distance dependency to their
head words which makes language model ineffec-
tive in selecting the correct measure words from
the measure word candidate set. For example, in
Figure 1 the distance between the measure word
â€œé¡¹â€ and its head word â€œå·¥ç¨‹â€ (undertaking) is 15.
In this case, an n-gram language model with n&lt;15
cannot capture the MW-HW collocation. Table 1
shows the relative positionâ€™s distribution of head
words around measure words in the Chinese Penn
Treebank, where a negative position indicates that
the head word is to the left of the measure word
and a positive position indicates that the head word
is to the right of the measure word. Although lots
of measure words are close to the head words they
modify, more than sixteen percent of measure
words are far away from their corresponding head
words (the absolute distance is more than 5).
To overcome the disadvantage of measure word
generation in a general SMT system, this paper
proposes a dedicated statistical model to generate
measure words for English-to-Chinese translation.
We model the probability of measure word gen-
eration by utilizing rich lexical and syntactic
knowledge from both source and target sentences.
Three steps are involved in our method to generate
measure words: Identifying the positions to gener-
ate measure words, collecting the measure word
candidate set and selecting the best measure word.
Our method is performed as a post-processing pro-
cedure of the output of SMT systems. The advan-
tage is that it can be easily integrated into any SMT
system. Experimental results show our method can
significantly improve the quality of measure word
generation. We also compared the performance of
our model based on different contextual informa-
tion, and show that both large-scale monolingual
data and parallel bilingual data can be helpful to
generate correct measure words.
</bodyText>
<table confidence="0.999520857142857">
Position Occurrence Position Occurrence
1 39.5% -1 0
2 15.7% -2 0
3 4.7% -3 8.7%
4 1.4% -4 6.8%
5 2.1% -5 4.3%
&gt;5 8.8% &lt;-5 8.0%
</table>
<tableCaption confidence="0.999933">
Table 1. Position distribution of head words
</tableCaption>
<sectionHeader confidence="0.992004" genericHeader="method">
2 Our Method
</sectionHeader>
<subsectionHeader confidence="0.999445">
2.1 Measure word generation in Chinese
</subsectionHeader>
<bodyText confidence="0.999958076923077">
In Chinese, measure words are obligatory in cer-
tain contexts, and the choice of measure word
usually depends on the head wordâ€™s semantics (e.g.,
shape or material). The set of Chinese measure
words is a relatively close set and can be classified
into two categories based on whether they have a
corresponding English translation. Those not hav-
ing an English counterpart need to be generated
during translation. For those having English trans-
lations, such as â€œç±³â€ (meter), â€œå¨â€ (ton), we just
use the translation produced by the SMT system
itself. According to our survey, about 70.4% of
measure words in the Chinese Penn Treebank need
</bodyText>
<page confidence="0.996439">
90
</page>
<bodyText confidence="0.999904">
to be explicitly generated during the translation
process.
In Chinese, there are generally stable linguistic
collocations between measure words and their head
words. Once the head word is determined, the col-
located measure word can usually be selected ac-
cordingly. However, there is no easy way to identi-
fy head words in target Chinese sentences since for
most of the time an SMT output is not a well
formed sentence due to translation errors. Mistake
of head word identification may cause low quality
of measure word generation. In addition, some-
times the head word itself is not enough to deter-
mine the measure word. For example, in Chinese
sentences â€œä»–å®¶æœ‰ 5 å£äººâ€ (there are five people
in his family) and â€œæ€»å…±æœ‰ 5 ä¸ªäººå‚åŠ äº†ä¼šè®®â€ (a
total of five people attended the meeting), where
â€œäººâ€ (people) is the head word collocated with two
different measure words â€œå£â€ and â€œä¸ªâ€, we cannot
determine the measure word just based on the head
word â€œäººâ€.
</bodyText>
<subsectionHeader confidence="0.99454">
2.2 Framework
</subsectionHeader>
<bodyText confidence="0.9999604">
In our framework, a statistical model is used to
generate measure words. The model is applied to
SMT system outputs as a post-processing proce-
dure. Given an English source sentence, an SMT
decoder produces a target Chinese translation, in
which positions for measure word generation are
identified. Based on contextual information con-
tained in both input source sentence and SMT sys-
temâ€™s output translation, a measure word candidate
set M is constructed. Then a measure word selec-
tion model is used to select the best one from M.
Finally, the selected measure word is inserted into
previously determined measure word slot in the
SMT systemâ€™s output, yielding the final translation
result.
</bodyText>
<subsectionHeader confidence="0.997954">
2.3 Measure word position identification
</subsectionHeader>
<bodyText confidence="0.999987">
To identify where to generate measure words in the
SMT outputs, all positions after numerals are
marked at first since measure words often follow
numerals. For other cases in which measure words
do not follow numerals (e.g., â€œè®¸å¤š/å°/ç”µè„‘â€
(many computers), where â€œå°â€ is a measure word
and â€œç”µè„‘â€ (computers) is its head word), we just
mine the set of words which can be followed by
measure words from training corpus. Most of
words in the set are pronouns such as â€œè¯¥â€ (this),
â€œé‚£â€ (that) and â€œè‹¥å¹²â€ (several). In the SMT out-
put, the positions after these words are also identi-
fied as candidate positions to generate measure
words.
</bodyText>
<subsectionHeader confidence="0.992965">
2.4 Candidate measure word generation
</subsectionHeader>
<bodyText confidence="0.999962405405406">
To avoid high computation cost, the measure word
candidate set only consists of those measure words
which can form valid MW-HW collocations with
their head words. We assume that all the surround-
ing words within a certain window size centered on
the given position to generate a measure word are
potential head words, and require that a measure
word candidate must collocate with at least one of
the surrounding words. Valid MW-HW colloca-
tions are mined from the training corpus and a sep-
arate lexicon resource.
There is a possibility that the real head word is
outside the window of given size. To address this
problem, we also use a source window centered on
the position ps, which is aligned to the target meas-
ure word position pt. The link between ps and pt
can be inferred from SMT decoding result. Thus,
the chance of capturing the best measure word in-
creases with the aid of words located in the source
window. For example, given the window size of 10,
although the target head word â€œå·¥ç¨‹â€ (undertaking)
in Figure 1 is located outside the target window, its
corresponding source head word undertaking can
be found in the source window. Based on this
source head word, the best measure word â€œé¡¹â€ will
be included into the candidate measure word set.
This example shows how bilingual information can
enrich the measure word candidate set.
Another special word {NULL} is always in-
cluded in the measure word candidate set. {NULL}
represents those measure words having a corres-
ponding English translation as mentioned in Sec-
tion 2.1. If {NULL} is selected, it means that we
need not generate any measure word at the current
position. Thus, no matter what kinds of measure
words they are, we can handle the issue of measure
word generation in a unified framework.
</bodyText>
<subsectionHeader confidence="0.995937">
2.5 Measure word selection model
</subsectionHeader>
<bodyText confidence="0.999283">
After obtaining the measure word candidate set M,
a measure word selection model is employed to
select the best one from M. Given the contextual
information C in both source window and target
</bodyText>
<page confidence="0.993751">
91
</page>
<bodyText confidence="0.999959">
window, we model the measure word selection as
finding the measure word m* with highest post-
erior probability given C:
</bodyText>
<equation confidence="0.998335">
ğ‘šâˆ— = argmaxà¯ âˆˆà¯†ğ‘ƒ(ğ‘š|ğ¶) (1)
</equation>
<bodyText confidence="0.9976844">
To leverage the collocation knowledge between
measure words and head words, we extend (1) by
introducing a hidden variable h where H represents
all candidate head words located within the target
window:
</bodyText>
<equation confidence="0.97639">
ğ‘šâˆ— = argmaxà¯ âˆˆà¯† âˆ‘à¯›âˆˆà¯ ğ‘ƒ(ğ‘š, â„|ğ¶)
= argmaxà¯ âˆˆà¯† âˆ‘à¯›âˆˆà¯ ğ‘ƒ(â„|ğ¶)ğ‘ƒ(ğ‘š|â„, ğ¶) (2)
</equation>
<bodyText confidence="0.994374833333333">
In (2), ğ‘ƒ(â„|ğ¶) is the head word selection proba-
bility and is empirically estimated according to the
position distribution of head words in Table 1.
ğ‘ƒ (ğ‘š |â„, ğ¶) is the conditional probability of m given
both h and C. We use maximum entropy model to
compute ğ‘ƒ (ğ‘š |â„, ğ¶):
</bodyText>
<equation confidence="0.989159666666667">
(3)
âˆ‘ exp(âˆ‘ ğ‘– ğœ†ğ‘– ğ‘“ğ‘–(ğ‘š ,ğ¶) )
ğ‘šâ€²âˆˆğ‘€
</equation>
<bodyText confidence="0.999960933333333">
Based on the different features used in the com-
putation of ğ‘ƒ (ğ‘š |â„, ğ¶) , we can train two sub-
models â€“ a monolingual model (Mo-ME) which
only uses monolingual (Chinese) features and a
bilingual model (Bi-ME) which integrates bilingual
features. The advantage of the Mo-ME model is
that it can employ an unlimited monolingual target
training corpora, while the Bi-ME model leverages
rich features including both the source and target
information and may improve the precision. Com-
pared to the Mo-ME model, the Bi-ME model suf-
fers from small scale of parallel training data. To
leverage advantages of both models, we use a
combined model Co-ME, by linearly combing the
monolingual and bilingual sub-models:
</bodyText>
<equation confidence="0.98874">
ğ‘šâˆ— = argmaxà¯ âˆˆà¯†ğœ†ğ‘ƒà¯†à¯¢à¬¿à¯†à®¾ + (1 âˆ’ ğœ†)ğ‘ƒà®»à¯œà¬¿à¯†à®¾
</equation>
<bodyText confidence="0.999802333333333">
where ğœ† âˆˆ [0,1] is a free parameter that can be op-
timized on held-out data and it was set to 0.39 in
our experiments.
</bodyText>
<subsectionHeader confidence="0.59992">
2.6 Features
</subsectionHeader>
<bodyText confidence="0.999475869565218">
The computation of Formula (3) involves the fea-
tures listed in Table 2 where the Mo-ME model
only employs target features and the Bi-ME model
leverages both target features and source features.
For target features, n-gram language model
score is defined as the sum of log n-gram probabil-
ities within the target window after the measure
word is filled into the measure word slot. The
MW-HW collocation feature is defined to be a
function f1 to capture the collocation between a
measure word and a head word. For features of
surrounding words, the feature function f2 is de-
fined as 1 if a certain word exists at a certain posi-
tion, otherwise 0. For example, f2(A,-2)=1 means
the second word on the left is â€œAâ€. f2(ä¹¦,3)=1
means the third word on the right is â€œä¹¦â€. For
punctuation position feature function f3, the feature
value is 1 when there is a punctuation following
the measure word, which indicates the target head
word may appear to the left of measure word. Oth-
erwise, it is 0. In practice, we can also ignore the
position part, i.e., a word appears anywhere within
the window is viewed as the same feature.
</bodyText>
<table confidence="0.991589666666667">
Target features Source features
n-gram language model MW-HW collocation
score
MW-HW collocation surrounding words
surrounding words source head word
punctuation position POS tags
</table>
<tableCaption confidence="0.999508">
Table 2. Features used in our model
</tableCaption>
<bodyText confidence="0.999930666666667">
For source language side features, MW-HW col-
location and surrounding words are used in a simi-
lar way as does with target features. The source
head word feature is defined to be a function f4 to
indicate whether a word ei is the source head word
in English according to a parse tree of the source
sentence. Similar to the definition of lexical fea-
tures, we also use a set of features based on POS
tags of source language.
</bodyText>
<sectionHeader confidence="0.66144" genericHeader="method">
3 Model Training and Application
</sectionHeader>
<subsectionHeader confidence="0.99162">
3.1 Training
</subsectionHeader>
<bodyText confidence="0.999977230769231">
We parsed English and Chinese sentences to get
training samples for measure word generation
model. Based on the source syntax parse tree, for
each measure word, we identified its head word by
using a toolkit from (Chiang and Bikel, 2002)
which can heuristically identify head words for
sub-trees. For the bilingual corpus, we also per-
form word alignment to get correspondences be-
tween source and target words. Then, the colloca-
tion between measure words and head words and
their surrounding contextual information are ex-
tracted to train the measure word selection models.
According to word alignment results, we classify
</bodyText>
<equation confidence="0.973230666666667">
exp(âˆ‘ ğ‘– ğœ†ğ‘– ğ‘“ğ‘–(ğ‘š,ğ¶) )
ğ‘ƒ(ğ‘š|â„, ğ¶) =
â€²
</equation>
<page confidence="0.908293">
92
</page>
<bodyText confidence="0.99999235">
measure words into two classes based on whether
they have non-null translations. We map Chinese
measure words having non-null translations to a
unified symbol {NULL} as mentioned in Section
2.4, indicating that we need not generate these kind
of measure words since they can be translated from
English.
In our work, the Berkeley parser (Petrov and
Klein, 2007) was employed to extract syntactic
knowledge from the training corpus. We ran GI-
ZA++ (Och and Ney, 2000) on the training corpus
in both directions with IBM model 4, and then ap-
plied the refinement rule described in (Koehn et al.,
2003) to obtain a many-to-many word alignment
for each sentence pair. We used the SRI Language
Modeling Toolkit (Stolcke, 2002) to train a five-
gram model with modified Kneser-Ney smoothing
(Chen and Goodman, 1998). The Maximum Entro-
py training toolkit from (Zhang, 2006) was em-
ployed to train the measure word selection model.
</bodyText>
<subsectionHeader confidence="0.999282">
3.2 Measure word generation
</subsectionHeader>
<bodyText confidence="0.99988353125">
As mentioned in previous sections, we apply our
measure word generation module into SMT output
as a post-processing step. Given a translation from
an SMT system, we first determine the position pr
at which to generate a Chinese measure word. Cen-
tered on pr, a surrounding word window with spe-
cified size is determined. From translation align-
ments, the corresponding source position ps aligned
to pr can be referred. In the same way, a source
window centered on ps is determined as well. Then,
contextual information within the windows in the
source and the target sentence is extracted and fed
to the measure word selection model. Meanwhile,
the candidate set is obtained based on words in
both windows. Finally, each measure word in the
candidate set is inserted to the position pr, and its
score is calculated based on the models presented
in Section 2.5. The measure word with the highest
probability will be chosen.
There are two reasons why we perform measure
word generation for SMT systems as a post-
processing step. One is that in this way our method
can be easily applied to any SMT system. The oth-
er is that we can leverage both source and target
information during the measure word generation
process. We do not integrate our measure word
generation module into the SMT decoder since
there is only little target contextual information
available during SMT decoding. Moreover, as we
will show in experiment section, a pre-processing
method does not work well when only source in-
formation is available.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.955053">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.999991806451613">
In the experiments, the language model is a Chi-
nese 5-gram language model trained with the Chi-
nese part of the LDC parallel corpus and the Xin-
hua part of the Chinese Gigaword corpus with
about 27 million words. We used an SMT system
similar to Chiang (2005), in which FBIS corpus is
used as the bilingual training data. The training
corpus for Mo-ME model consists of the Chinese
Peen Treebank and the Chinese part of the LDC
parallel corpus with about 2 million sentences. The
Bi-ME model is trained with FBIS corpus, whose
size is smaller than that used in Mo-ME model
training.
We extracted both development and test data set
from years of NIST Chinese-to-English evaluation
data by filtering out sentence pairs not containing
measure words. The development set is extracted
from NIST evaluation data from 2002 to 2004, and
the test set consists of sentence pairs from NIST
evaluation data from 2005 to 2006. There are 759
testing cases for measure word generation in our
test data consisting of 2746 sentence pairs. We use
the English sentences in the data sets as input to
the SMT decoder, and apply our proposed method
to generate measure words for the output from the
decoder. Measure words in Chinese sentences of
the development and test sets are used as refer-
ences. When there are more than one measure
words acceptable at some places, we manually
augment the references with multiple acceptable
measure words.
</bodyText>
<subsectionHeader confidence="0.9312">
4.2 Baseline
</subsectionHeader>
<bodyText confidence="0.999993">
Our baseline is the SMT output where measure
words are generated by a Hiero-like SMT decoder
as discussed in Section 1. Due to noises in the Chi-
nese translations introduced by the SMT system,
we cannot correctly identify all the positions to
generate measure words. Therefore, besides preci-
sion we examine recall in our experiments.
</bodyText>
<subsectionHeader confidence="0.99065">
4.3 Evaluation over SMT output
</subsectionHeader>
<bodyText confidence="0.982478">
Table 3 and Table 4 show the precision and recall
of our measure word generation method. From the
</bodyText>
<page confidence="0.997244">
93
</page>
<bodyText confidence="0.981220666666667">
experimental results, the Mo-ME, Bi-ME and Co-
ME models all outperform the baseline. Compared
with the baseline, the Mo-ME method takes advan-
tage of a large size monolingual training corpus
and reduces the data sparseness problem. The ad-
vantage of the Bi-ME model is being able to make
full use of rich knowledge from both source and
target sentences. Also as shown in Table 3 and Ta-
ble 4, the Co-ME model always achieve the best
results when using the same window size since it
leverages the advantage of both the Mo-ME and
the Bi-ME models.
</bodyText>
<table confidence="0.999476333333333">
Wsize Baseline Mo-ME Bi-ME Co-ME
6 54.82% 64.29% 67.15% 67.66%
8 64.93% 68.50% 69.00%
10 64.72% 69.40% 69.58%
12 65.46% 69.40% 69.76%
14 65.61% 69.69% 70.03%
</table>
<tableCaption confidence="0.996563">
Table 3. Precision over SMT output
</tableCaption>
<table confidence="0.999796">
Wsize Baseline Mo-ME Bi-ME Co-ME
6 45.61% 51.48% 53.69% 54.09%
8 51.98% 54.75% 55.14%
10 51.81% 55.44% 55.58%
12 52.38% 55.44% 55.72%
14 52.50% 55.67% 55.93%
</table>
<tableCaption confidence="0.999865">
Table 4. Recall over SMT output
</tableCaption>
<bodyText confidence="0.999986">
We can see that the Bi-ME model can achieve
better results than the Mo-ME model in both recall
and precision metrics although only a small sized
bilingual corpus is used for Bi-ME model training.
The reason is that the Mo-ME model cannot cor-
rectly handle the cases where head words are lo-
cated outside the target window. However, due to
word order differences between English and Chi-
nese, when target head words are outside the target
window, their corresponding source head words
might be within the source window. The capacity
of capturing head words is improved when both
source and target windows are used, which demon-
strates that bilingual knowledge is useful for meas-
ure word generation.
We compare the results for each model with dif-
ferent window sizes. Larger window size can lead
to better results as shown in Table 3 and Table 4
since more contextual knowledge is used to model
measure word generation. However, enlarging the
window size does not bring significant improve-
ments, The major reason is that even a small win-
dow size is already able to cover most of measure
word collocations, as indicated by the position dis-
tribution of head words in Table 1.
The quality of the SMT output also affects the
quality of measure word generation since our me-
thod is performed in a post-processing step over
the SMT output. Although translation errors de-
grade the measure word generation accuracy, we
achieve about 15% improvement in precision and a
10% increase in recall over baseline. We notice
that the recall is relatively lower. Part of the reason
is some positions to generate measure words are
not successfully identified due to translation errors.
In addition to precision and recall, we also evaluate
the Bleu score (Papineni et al., 2002) changes be-
fore and after applying our measure word genera-
tion method to the SMT output. For our test data,
we only consider sentences containing measure
words for Bleu score evaluation. Our measure
word generation step leads to a Bleu score im-
provement of 0.32 where the window size is set to
10, which shows that it can improve the translation
quality of an English-to-Chinese SMT system.
</bodyText>
<subsectionHeader confidence="0.999502">
4.4 Evaluation over reference data
</subsectionHeader>
<bodyText confidence="0.99899475">
To isolate the impact of the translation errors in
SMT output on the performance of our measure
word generation model, we conducted another ex-
periment with reference bilingual sentences in
which measure words in Chinese sentences are
manually removed. This experiment can show the
performance upper bound of our method without
interference from an SMT system. Table 5 shows
the results. Compared to the results in Table 3, the
precision improvement in the Mo-ME model is
larger than that in the Bi-ME model, which shows
that noisy translation of the SMT system has more
serious influence on the Mo-ME model than the
Bi-ME model. This also indicates that source in-
formation without noises is helpful for measure
word generation.
</bodyText>
<table confidence="0.998183666666667">
Wsize Mo-ME Bi-ME Co-ME
6 71.63% 74.92% 75.72%
8 73.80% 75.48% 76.20%
10 73.80% 74.76% 75.48%
12 73.80% 75.24% 75.96%
14 73.56% 75.48% 76.44%
</table>
<tableCaption confidence="0.999817">
Table 5. Results over reference data
</tableCaption>
<page confidence="0.997854">
94
</page>
<subsectionHeader confidence="0.981453">
4.5 Impacts of features
</subsectionHeader>
<bodyText confidence="0.9015826875">
In this section, we examine the contribution of
both target language based features and source
language based features in our model. Table 6 and
Table 7 show the precision and recall when using
different features. The window size is set to 10. In
the tables, Lm denotes the n-gram language model
feature, Tmh denotes the feature of collocation be-
tween target head words and the candidate measure
word, Smh denotes the feature of collocation be-
tween source head words and the candidate meas-
ure word, Hs denotes the feature of source head
word selection, Punc denotes the feature of target
punctuation position, Tlex denotes surrounding
word features in translation, Slex denotes surround-
ing word features in source sentence, and Pos de-
notes Part-Of-Speech feature.
</bodyText>
<table confidence="0.9856309375">
Feature setting Precision Recall
Baseline 54.82% 45.61%
Lm 51.11% 41.24%
+Tmh 61.43% 49.22%
+Punc 62.54% 50.08%
+Tlex 64.80% 51.87%
Table 6. Feature contribution in Mo-ME model
Feature setting Precision Recall
Baseline 54.82% 45.61%
Lm 51.11% 41.24%
+Tmh+Smh 64.50% 51.64%
+Hs 65.32% 52.26%
+Punc 66.29% 53.10%
+Pos 66.53% 53.25%
+Tlex 67.50% 54.02%
+Slex 69.52% 55.54%
</table>
<tableCaption confidence="0.999233">
Table 7. Feature contribution in Bi-ME model
</tableCaption>
<bodyText confidence="0.99997605">
The experimental results show that all the fea-
tures can bring incremental improvements. The
method with only Lm feature performs worse than
the baseline. However, with more features inte-
grated, our method outperforms the baseline,
which indicates each kind of features we selected
is useful for measure word generation. According
to the results, the feature of MW-HW collocation
has much contribution to reducing the selection
error of measure words given head words. The
contribution of Slex feature explains that other sur-
rounding words in source sentence are also helpful
since head word determination in source language
might be incorrect due to errors in English parse
trees. Meanwhile, the contribution from Smh, Hs
and Slex features demonstrates that bilingual
knowledge can play an important role for measure
word generation. Compared with lexicalized fea-
tures, we do not get much benefit from the Pos
features.
</bodyText>
<subsectionHeader confidence="0.973999">
4.6 Error analysis
</subsectionHeader>
<bodyText confidence="0.999773769230769">
We conducted an error analysis on 100 randomly
selected sentences from the test data. There are
four major kinds of errors as listed in Table 8.
Most errors are caused by failures in finding posi-
tions to generate measure words. The main reason
for this is some hint information used to identify
measure word positions is missing in the noisy
output of SMT systems. Two kinds of errors are
introduced by incomplete head word and MW-HW
collocation coverage, which can be solved by en-
larging the size of training corpus. There are also
head word selection errors due to incorrect syntax
parsing.
</bodyText>
<table confidence="0.989683">
Error type Ratio
unseen head word 32.14%
unseen MW-HW collocation 10.71%
missing MW position 39.29%
incorrect HW selection 10.71%
others 7.14%
</table>
<tableCaption confidence="0.99841">
Table 8. Error distribution
</tableCaption>
<subsectionHeader confidence="0.994332">
4.7 Comparison with other methods
</subsectionHeader>
<bodyText confidence="0.999968684210526">
In this section we compare our statistical methods
with the pre-processing method and the rule-based
methods for measure word generation in a transla-
tion task.
In pre-processing method, only source language
information is available. Given a source sentence,
the corresponding syntax parse tree Ts is first con-
structed with an English parser. Then the pre-
processing method chooses the source head word
hs based on Ts. The candidate measure word with
the highest probability collocated with hs is se-
lected as the best result, where the measure word
candidate set corresponding to each head word is
mined over a bilingual training corpus in advance.
We achieved precision 58.62% and recall 49.25%,
which are worse than the results of our post-
processing based methods. The weakness of the
pre-processing method is twofold. One problem is
data sparseness with respect to collocations be-
</bodyText>
<page confidence="0.995636">
95
</page>
<bodyText confidence="0.9998509">
tween English head words and Chinese measure
words. The other problem comes from the English
head word selection error introduced by using
source parse trees.
We also compared our method with a well-
known rule-based machine translation system â€“
SYSTRAN3. We translated our test data with SY-
STRANâ€™s English-to-Chinese translation engine.
The precision and recall are 63.82% and 51.09%
respectively, which are also lower than our method.
</bodyText>
<sectionHeader confidence="0.999973" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999697083333333">
Most existing rule-based English-to-Chinese MT
systems have a dedicated module handling meas-
ure word generation. In general a rule-based me-
thod uses manually constructed rule patterns to
predict measure words. Like most rule based ap-
proaches, this kind of system requires lots of hu-
man efforts of experienced linguists and usually
cannot easily be adapted to a new domain. The
most relevant work based on statistical methods to
our research might be statistical technologies em-
ployed to model issues such as morphology gener-
ation (Minkov et al., 2007).
</bodyText>
<sectionHeader confidence="0.997116" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999731333333333">
In this paper we propose a statistical model for
measure word generation for English-to-Chinese
SMT systems, in which contextual knowledge
from both source and target sentences is involved.
Experimental results show that our method not on-
ly achieves high precision and recall for generating
measure words, but also improves the quality of
English-to-Chinese SMT systems.
In the future, we plan to investigate more fea-
tures and enlarge coverage to improve the quality
of measure word generation, especially reduce the
errors found in our experiments.
</bodyText>
<sectionHeader confidence="0.996564" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99596">
Special thanks to David Chiang, Stephan Stiller
and the anonymous reviewers for their feedback
and insightful comments.
</bodyText>
<sectionHeader confidence="0.998918" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995298710526316">
Stanley F. Chen and Joshua Goodman. 1998. An Empir-
ical study of smoothing techniques for language
3 http://www.systransoft.com/
modeling. Technical Report TR-10-98, Harvard Uni-
versity Center for Research in Computing Technolo-
gy, 1998.
David Chiang and Daniel M. Bikel. 2002. Recovering
latent information in treebanks. Proceedings of COL-
ING &apos;02, 2002.
David Chiang. 2005. A hierarchical phrase-based mod-
el for statistical machine translation. In Proceedings
of ACL 2005, pages 263-270.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings of
HLT-NAACL 2003, pages 127-133.
Einat Minkov, Kristina Toutanova, and Hisami Suzuki.
2007. Generating complex morphology for machine
translation. In Proceedings of 45th Annual Meeting
of the ACL, pages 128-135.
Franz J. Och and Hermann Ney. 2000. Improved statis-
tical alignment models. In Proceedings of 38th An-
nual Meeting of the ACL, pages 440-447.
Franz J. Och and Hermann Ney. 2004. The alignment
template approach to statistical machine translation.
Computational Linguistics, 30:417-449.
Kishore Papineni, Salim Roukos, ToddWard, and WeiJ-
ing Zhu. 2002. BLEU: a method for automatic evalu-
ation of machine translation. In Proceedings of 40th
Annual Meeting of the ACL, pages 311-318.
Slav Petrov and Dan Klein. 2007. Improved inference
for unlexicalized parsing. In Proceedings of HLT-
NAACL, 2007.
Andreas Stolcke. 2002. SRILM - an extensible language
modeling toolkit. In Proceedings of International
Conference on Spoken Language Processing, volume
2, pages 901-904.
Le Zhang. MaxEnt toolkit. 2006. http://homepages.inf.
ed.ac.uk/s0450736/maxent_toolkit.html
</reference>
<page confidence="0.998437">
96
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.937246">
<title confidence="0.99982">Measure Word Generation for English-Chinese SMT Systems</title>
<author confidence="0.990697">Mu Nan Chi-Ho Ming</author>
<affiliation confidence="0.99985">Research Asia University</affiliation>
<address confidence="0.992009">Beijing, China Tianjin, China</address>
<email confidence="0.999908">dozhang@microsoft.com</email>
<email confidence="0.999908">muli@microsoft.com</email>
<email confidence="0.999908">v-naduan@microsoft.com</email>
<email confidence="0.999908">chl@microsoft.com</email>
<email confidence="0.999908">mingzhou@microsoft.com</email>
<abstract confidence="0.9976822">words in Chinese are to indithe count of nouns. statistical machine translation (SMT) systems do not perform well on measure word generation due to data sparseness and the potential long distance dependency between measure words and their corresponding head words. In this paper, we propose a statistical model to generate appropriate measure words of nouns for an English-to-Chinese SMT system. We model the probability of measure word generation by utilizing lexical and syntactic knowledge from both source and target sentences. Our model works as a post-processing procedure over output of statistical machine translation systems, and can work with any SMT system. Experimental results show our method can achieve high precision and recall in measure word generation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
<author>Joshua Goodman</author>
</authors>
<title>An Empirical study of smoothing techniques for language 3 http://www.systransoft.com/ modeling.</title>
<date>1998</date>
<tech>Technical Report TR-10-98,</tech>
<institution>Harvard University Center for Research in Computing Technology,</institution>
<contexts>
<context position="16192" citStr="Chen and Goodman, 1998" startWordPosition="2698" endWordPosition="2701">n Section 2.4, indicating that we need not generate these kind of measure words since they can be translated from English. In our work, the Berkeley parser (Petrov and Klein, 2007) was employed to extract syntactic knowledge from the training corpus. We ran GIZA++ (Och and Ney, 2000) on the training corpus in both directions with IBM model 4, and then applied the refinement rule described in (Koehn et al., 2003) to obtain a many-to-many word alignment for each sentence pair. We used the SRI Language Modeling Toolkit (Stolcke, 2002) to train a fivegram model with modified Kneser-Ney smoothing (Chen and Goodman, 1998). The Maximum Entropy training toolkit from (Zhang, 2006) was employed to train the measure word selection model. 3.2 Measure word generation As mentioned in previous sections, we apply our measure word generation module into SMT output as a post-processing step. Given a translation from an SMT system, we first determine the position pr at which to generate a Chinese measure word. Centered on pr, a surrounding word window with specified size is determined. From translation alignments, the corresponding source position ps aligned to pr can be referred. In the same way, a source window centered </context>
</contexts>
<marker>Chen, Goodman, 1998</marker>
<rawString>Stanley F. Chen and Joshua Goodman. 1998. An Empirical study of smoothing techniques for language 3 http://www.systransoft.com/ modeling. Technical Report TR-10-98, Harvard University Center for Research in Computing Technology, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Daniel M Bikel</author>
</authors>
<title>Recovering latent information in treebanks.</title>
<date>2002</date>
<booktitle>Proceedings of COLING &apos;02,</booktitle>
<contexts>
<context position="14967" citStr="Chiang and Bikel, 2002" startWordPosition="2496" endWordPosition="2499">ed in a similar way as does with target features. The source head word feature is defined to be a function f4 to indicate whether a word ei is the source head word in English according to a parse tree of the source sentence. Similar to the definition of lexical features, we also use a set of features based on POS tags of source language. 3 Model Training and Application 3.1 Training We parsed English and Chinese sentences to get training samples for measure word generation model. Based on the source syntax parse tree, for each measure word, we identified its head word by using a toolkit from (Chiang and Bikel, 2002) which can heuristically identify head words for sub-trees. For the bilingual corpus, we also perform word alignment to get correspondences between source and target words. Then, the collocation between measure words and head words and their surrounding contextual information are extracted to train the measure word selection models. According to word alignment results, we classify exp(âˆ‘ ğ‘– ğœ†ğ‘– ğ‘“ğ‘–(ğ‘š,ğ¶) ) ğ‘ƒ(ğ‘š|â„, ğ¶) = â€² 92 measure words into two classes based on whether they have non-null translations. We map Chinese measure words having non-null translations to a unified symbol {NULL} as mentioned</context>
</contexts>
<marker>Chiang, Bikel, 2002</marker>
<rawString>David Chiang and Daniel M. Bikel. 2002. Recovering latent information in treebanks. Proceedings of COLING &apos;02, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>263--270</pages>
<contexts>
<context position="2658" citStr="Chiang, 2005" startWordPosition="405" endWordPosition="406">ls and indefinite articles are directly followed by countable nouns to denote the quantity of objects. Therefore, in the English-to-Chinese machine translation task we need to take additional efforts to generate the missing measure words in Chinese. For example, when translating the English phrase three books into the Chinese phrases â€œä¸‰æœ¬ä¹¦â€, where three corresponds to the numeral â€œä¸‰â€ and books corresponds to the noun â€œä¹¦â€, the Chinese measure word â€œæœ¬â€ should be generated between the numeral and the noun. In most statistical machine translation (SMT) models (Och et al., 2004; Koehn et al., 2003; Chiang, 2005), some of measure words can be generated without modification or additional processing. For example, in above translation, the phrase translation table may suggest the word three be translated into â€œä¸‰â€, â€œä¸‰æœ¬â€, â€œä¸‰åªâ€, etc, and the word books into â€œä¹¦â€, â€œä¹¦æœ¬â€, â€œåå†Œâ€ (scroll), etc. Then the SMT model selects the most likely combination â€œä¸‰æœ¬ä¹¦â€ as the final translation result. In this example, a measure word candidate set consisting of â€œæœ¬â€ and â€œåªâ€ can be generated by bilingual phrases (or synchronous translation rules), and the best measure word â€œæœ¬â€ from the measure 2 There are some exceptional cases, su</context>
<context position="18125" citStr="Chiang (2005)" startWordPosition="3030" endWordPosition="3031"> measure word generation process. We do not integrate our measure word generation module into the SMT decoder since there is only little target contextual information available during SMT decoding. Moreover, as we will show in experiment section, a pre-processing method does not work well when only source information is available. 4 Experiments 4.1 Data In the experiments, the language model is a Chinese 5-gram language model trained with the Chinese part of the LDC parallel corpus and the Xinhua part of the Chinese Gigaword corpus with about 27 million words. We used an SMT system similar to Chiang (2005), in which FBIS corpus is used as the bilingual training data. The training corpus for Mo-ME model consists of the Chinese Peen Treebank and the Chinese part of the LDC parallel corpus with about 2 million sentences. The Bi-ME model is trained with FBIS corpus, whose size is smaller than that used in Mo-ME model training. We extracted both development and test data set from years of NIST Chinese-to-English evaluation data by filtering out sentence pairs not containing measure words. The development set is extracted from NIST evaluation data from 2002 to 2004, and the test set consists of sente</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In Proceedings of ACL 2005, pages 263-270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz J Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL</booktitle>
<pages>127--133</pages>
<contexts>
<context position="2643" citStr="Koehn et al., 2003" startWordPosition="401" endWordPosition="404">asure words2. Numerals and indefinite articles are directly followed by countable nouns to denote the quantity of objects. Therefore, in the English-to-Chinese machine translation task we need to take additional efforts to generate the missing measure words in Chinese. For example, when translating the English phrase three books into the Chinese phrases â€œä¸‰æœ¬ä¹¦â€, where three corresponds to the numeral â€œä¸‰â€ and books corresponds to the noun â€œä¹¦â€, the Chinese measure word â€œæœ¬â€ should be generated between the numeral and the noun. In most statistical machine translation (SMT) models (Och et al., 2004; Koehn et al., 2003; Chiang, 2005), some of measure words can be generated without modification or additional processing. For example, in above translation, the phrase translation table may suggest the word three be translated into â€œä¸‰â€, â€œä¸‰æœ¬â€, â€œä¸‰åªâ€, etc, and the word books into â€œä¹¦â€, â€œä¹¦æœ¬â€, â€œåå†Œâ€ (scroll), etc. Then the SMT model selects the most likely combination â€œä¸‰æœ¬ä¹¦â€ as the final translation result. In this example, a measure word candidate set consisting of â€œæœ¬â€ and â€œåªâ€ can be generated by bilingual phrases (or synchronous translation rules), and the best measure word â€œæœ¬â€ from the measure 2 There are some except</context>
<context position="15984" citStr="Koehn et al., 2003" startWordPosition="2665" endWordPosition="2668">ğ‘š,ğ¶) ) ğ‘ƒ(ğ‘š|â„, ğ¶) = â€² 92 measure words into two classes based on whether they have non-null translations. We map Chinese measure words having non-null translations to a unified symbol {NULL} as mentioned in Section 2.4, indicating that we need not generate these kind of measure words since they can be translated from English. In our work, the Berkeley parser (Petrov and Klein, 2007) was employed to extract syntactic knowledge from the training corpus. We ran GIZA++ (Och and Ney, 2000) on the training corpus in both directions with IBM model 4, and then applied the refinement rule described in (Koehn et al., 2003) to obtain a many-to-many word alignment for each sentence pair. We used the SRI Language Modeling Toolkit (Stolcke, 2002) to train a fivegram model with modified Kneser-Ney smoothing (Chen and Goodman, 1998). The Maximum Entropy training toolkit from (Zhang, 2006) was employed to train the measure word selection model. 3.2 Measure word generation As mentioned in previous sections, we apply our measure word generation module into SMT output as a post-processing step. Given a translation from an SMT system, we first determine the position pr at which to generate a Chinese measure word. Centered</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of HLT-NAACL 2003, pages 127-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Einat Minkov</author>
<author>Kristina Toutanova</author>
<author>Hisami Suzuki</author>
</authors>
<title>Generating complex morphology for machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of 45th Annual Meeting of the ACL,</booktitle>
<pages>128--135</pages>
<contexts>
<context position="28604" citStr="Minkov et al., 2007" startWordPosition="4750" endWordPosition="4753">% respectively, which are also lower than our method. 5 Related Work Most existing rule-based English-to-Chinese MT systems have a dedicated module handling measure word generation. In general a rule-based method uses manually constructed rule patterns to predict measure words. Like most rule based approaches, this kind of system requires lots of human efforts of experienced linguists and usually cannot easily be adapted to a new domain. The most relevant work based on statistical methods to our research might be statistical technologies employed to model issues such as morphology generation (Minkov et al., 2007). 6 Conclusion and Future Work In this paper we propose a statistical model for measure word generation for English-to-Chinese SMT systems, in which contextual knowledge from both source and target sentences is involved. Experimental results show that our method not only achieves high precision and recall for generating measure words, but also improves the quality of English-to-Chinese SMT systems. In the future, we plan to investigate more features and enlarge coverage to improve the quality of measure word generation, especially reduce the errors found in our experiments. Acknowledgements Sp</context>
</contexts>
<marker>Minkov, Toutanova, Suzuki, 2007</marker>
<rawString>Einat Minkov, Kristina Toutanova, and Hisami Suzuki. 2007. Generating complex morphology for machine translation. In Proceedings of 45th Annual Meeting of the ACL, pages 128-135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In Proceedings of 38th Annual Meeting of the ACL,</booktitle>
<pages>440--447</pages>
<contexts>
<context position="15853" citStr="Och and Ney, 2000" startWordPosition="2641" endWordPosition="2644">ormation are extracted to train the measure word selection models. According to word alignment results, we classify exp(âˆ‘ ğ‘– ğœ†ğ‘– ğ‘“ğ‘–(ğ‘š,ğ¶) ) ğ‘ƒ(ğ‘š|â„, ğ¶) = â€² 92 measure words into two classes based on whether they have non-null translations. We map Chinese measure words having non-null translations to a unified symbol {NULL} as mentioned in Section 2.4, indicating that we need not generate these kind of measure words since they can be translated from English. In our work, the Berkeley parser (Petrov and Klein, 2007) was employed to extract syntactic knowledge from the training corpus. We ran GIZA++ (Och and Ney, 2000) on the training corpus in both directions with IBM model 4, and then applied the refinement rule described in (Koehn et al., 2003) to obtain a many-to-many word alignment for each sentence pair. We used the SRI Language Modeling Toolkit (Stolcke, 2002) to train a fivegram model with modified Kneser-Ney smoothing (Chen and Goodman, 1998). The Maximum Entropy training toolkit from (Zhang, 2006) was employed to train the measure word selection model. 3.2 Measure word generation As mentioned in previous sections, we apply our measure word generation module into SMT output as a post-processing ste</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz J. Och and Hermann Ney. 2000. Improved statistical alignment models. In Proceedings of 38th Annual Meeting of the ACL, pages 440-447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<pages>30--417</pages>
<marker>Och, Ney, 2004</marker>
<rawString>Franz J. Och and Hermann Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics, 30:417-449.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>ToddWard</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the ACL,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="22443" citStr="Papineni et al., 2002" startWordPosition="3761" endWordPosition="3764">istribution of head words in Table 1. The quality of the SMT output also affects the quality of measure word generation since our method is performed in a post-processing step over the SMT output. Although translation errors degrade the measure word generation accuracy, we achieve about 15% improvement in precision and a 10% increase in recall over baseline. We notice that the recall is relatively lower. Part of the reason is some positions to generate measure words are not successfully identified due to translation errors. In addition to precision and recall, we also evaluate the Bleu score (Papineni et al., 2002) changes before and after applying our measure word generation method to the SMT output. For our test data, we only consider sentences containing measure words for Bleu score evaluation. Our measure word generation step leads to a Bleu score improvement of 0.32 where the window size is set to 10, which shows that it can improve the translation quality of an English-to-Chinese SMT system. 4.4 Evaluation over reference data To isolate the impact of the translation errors in SMT output on the performance of our measure word generation model, we conducted another experiment with reference bilingua</context>
</contexts>
<marker>Papineni, Roukos, ToddWard, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, ToddWard, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of 40th Annual Meeting of the ACL, pages 311-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of HLTNAACL,</booktitle>
<contexts>
<context position="15749" citStr="Petrov and Klein, 2007" startWordPosition="2623" endWordPosition="2626">target words. Then, the collocation between measure words and head words and their surrounding contextual information are extracted to train the measure word selection models. According to word alignment results, we classify exp(âˆ‘ ğ‘– ğœ†ğ‘– ğ‘“ğ‘–(ğ‘š,ğ¶) ) ğ‘ƒ(ğ‘š|â„, ğ¶) = â€² 92 measure words into two classes based on whether they have non-null translations. We map Chinese measure words having non-null translations to a unified symbol {NULL} as mentioned in Section 2.4, indicating that we need not generate these kind of measure words since they can be translated from English. In our work, the Berkeley parser (Petrov and Klein, 2007) was employed to extract syntactic knowledge from the training corpus. We ran GIZA++ (Och and Ney, 2000) on the training corpus in both directions with IBM model 4, and then applied the refinement rule described in (Koehn et al., 2003) to obtain a many-to-many word alignment for each sentence pair. We used the SRI Language Modeling Toolkit (Stolcke, 2002) to train a fivegram model with modified Kneser-Ney smoothing (Chen and Goodman, 1998). The Maximum Entropy training toolkit from (Zhang, 2006) was employed to train the measure word selection model. 3.2 Measure word generation As mentioned in</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved inference for unlexicalized parsing. In Proceedings of HLTNAACL, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of International Conference on Spoken Language Processing,</booktitle>
<volume>2</volume>
<pages>901--904</pages>
<contexts>
<context position="16106" citStr="Stolcke, 2002" startWordPosition="2686" endWordPosition="2687"> words having non-null translations to a unified symbol {NULL} as mentioned in Section 2.4, indicating that we need not generate these kind of measure words since they can be translated from English. In our work, the Berkeley parser (Petrov and Klein, 2007) was employed to extract syntactic knowledge from the training corpus. We ran GIZA++ (Och and Ney, 2000) on the training corpus in both directions with IBM model 4, and then applied the refinement rule described in (Koehn et al., 2003) to obtain a many-to-many word alignment for each sentence pair. We used the SRI Language Modeling Toolkit (Stolcke, 2002) to train a fivegram model with modified Kneser-Ney smoothing (Chen and Goodman, 1998). The Maximum Entropy training toolkit from (Zhang, 2006) was employed to train the measure word selection model. 3.2 Measure word generation As mentioned in previous sections, we apply our measure word generation module into SMT output as a post-processing step. Given a translation from an SMT system, we first determine the position pr at which to generate a Chinese measure word. Centered on pr, a surrounding word window with specified size is determined. From translation alignments, the corresponding source</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an extensible language modeling toolkit. In Proceedings of International Conference on Spoken Language Processing, volume 2, pages 901-904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Le Zhang</author>
</authors>
<title>MaxEnt toolkit.</title>
<date>2006</date>
<note>http://homepages.inf.</note>
<marker>Le Zhang, 2006</marker>
<rawString>Le Zhang. MaxEnt toolkit. 2006. http://homepages.inf.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>