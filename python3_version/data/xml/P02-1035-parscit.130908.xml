<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001361">
<note confidence="0.9521395">
Proceedings of the 40th Annual Meeting of the Association for
Computational Linguistics (ACL), Philadelphia, July 2002, pp. 271-278.
</note>
<title confidence="0.9952">
Parsing the Wall Street Journal using a Lexical-Functional Grammar and
Discriminative Estimation Techniques
</title>
<author confidence="0.975233">
Stefan Riezler Tracy H. King Ronald M. Kaplan
</author>
<affiliation confidence="0.951707">
Palo Alto Research Center Palo Alto Research Center Palo Alto Research Center
</affiliation>
<address confidence="0.914022">
Palo Alto, CA 94304 Palo Alto, CA 94304 Palo Alto, CA 94304
</address>
<email confidence="0.995666">
riezler@parc.com thking@parc.com kaplan@parc.com
</email>
<author confidence="0.946549">
Richard Crouch John T. Maxwell III Mark Johnson
</author>
<affiliation confidence="0.93966">
Palo Alto Research Center Palo Alto Research Center Brown University
</affiliation>
<address confidence="0.843704">
Palo Alto, CA 94304 Palo Alto, CA 94304 Providence, RI 02912
</address>
<email confidence="0.993446">
crouch@parc.com maxwell@parc.com mj@cs.brown.edu
</email>
<sectionHeader confidence="0.996603" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999929761904762">
We present a stochastic parsing system
consisting of a Lexical-Functional Gram-
mar (LFG), a constraint-based parser and
a stochastic disambiguation model. We re-
port on the results of applying this sys-
tem to parsing the UPenn Wall Street
Journal (WSJ) treebank. The model com-
bines full and partial parsing techniques
to reach full grammar coverage on unseen
data. The treebank annotations are used
to provide partially labeled data for dis-
criminative statistical estimation using ex-
ponential models. Disambiguation perfor-
mance is evaluated by measuring matches
of predicate-argument relations on two
distinct test sets. On a gold standard of
manually annotated f-structures for a sub-
set of the WSJ treebank, this evaluation
reaches 79% F-score. An evaluation on a
gold standard of dependency relations for
Brown corpus data achieves 76% F-score.
</bodyText>
<sectionHeader confidence="0.999165" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999933023809524">
Statistical parsing using combined systems of hand-
coded linguistically fine-grained grammars and
stochastic disambiguation components has seen con-
siderable progress in recent years. However, such at-
tempts have so far been confined to a relatively small
scale for various reasons. Firstly, the rudimentary
character of functional annotations in standard tree-
banks has hindered the direct use of such data for
statistical estimation of linguistically fine-grained
statistical parsing systems. Rather, parameter esti-
mation for such models had to resort to unsupervised
techniques (Bouma et al., 2000; Riezler et al., 2000),
or training corpora tailored to the specific grammars
had to be created by parsing and manual disam-
biguation, resulting in relatively small training sets
of around 1,000 sentences (Johnson et al., 1999).
Furthermore, the effort involved in coding broad-
coverage grammars by hand has often led to the spe-
cialization of grammars to relatively small domains,
thus sacrificing grammar coverage (i.e. the percent-
age of sentences for which at least one analysis is
found) on free text. The approach presented in this
paper is a first attempt to scale up stochastic parsing
systems based on linguistically fine-grained hand-
coded grammars to the UPenn Wall Street Journal
(henceforth WSJ) treebank (Marcus et al., 1994).
The problem of grammar coverage, i.e. the fact
that not all sentences receive an analysis, is tack-
led in our approach by an extension of a full-
fledged Lexical-Functional Grammar (LFG) and a
constraint-based parser with partial parsing tech-
niques. In the absence of a complete parse, a so-
called “FRAGMENT grammar” allows the input to be
analyzed as a sequence of well-formed chunks. The
set of fragment parses is then chosen on the basis
of a fewest-chunk method. With this combination of
full and partial parsing techniques we achieve 100%
grammar coverage on unseen data.
Another goal of this work is the best possible ex-
ploitation of the WSJ treebank for discriminative es-
timation of an exponential model on LFG parses. We
define discriminative or conditional criteria with re-
</bodyText>
<figure confidence="0.999307278846154">
✂ NPzero
N
share
golden
scheduled
✆ PARTinf
☎VPall[bas
e]
✁ to
✆ PPcl
V[base]
☎
CS 1: FRAGMENTS
Sadj[fin]
S[fin]
VPall[fin]
� D
NPadj
✂
☎VP[pass,fin]
✁ the
AP[attr]
✄
NPzero
✂
✄AUX[pass,fin]
☎ VPv[pass]
NP
✞ FRAGMENTS
TOKEN
of
N
A
was
V[pass]
VPinf
expire
✆ PP
NP
VPinf−pos
☎
VPv[base]
P
D
at
NPadj
✁ the
beginning
✝
&amp;quot;The golden share was scheduled to expire at the beginning of&amp;quot;
67
PASSIVE +, STMT−TYPE decl, VTYPE main
PRED
’expire&lt;[11:share]&gt;’
164
ADV-TYPE vpadv, PSEM locative, PTYPE sem
132
INF−FORM to, PASSIVE−, VTYPE main
PRED ’schedule&lt;NULL, [132:expire]&gt;[11:share]’
�
PRED
’share’
PRED ’golden&lt;[11:share]&gt;’
SUBJ [11:share]
ADEGREE positive
� , ADJUNCT−TYPE nominal, ATYPE attributive
NTYPE
� � �
DET−FORM the_, DET−TYPE def
�
DET
SPEC
11 CASE nom
� , NUM � 3
� sg, PERS
SUBJ [11:share]
PRED ’at&lt;[170:beginning]&gt;’
PRED �
’beginning’
NTYPE GERUND +, GRAIN unspecified
�
ADJUNCT
DET−FORM the_, DET−TYPE def
TET
SPEC
�
OBJ
170 CASE acc, NUM
� sg, PCASE at, PERS 3
�
GRAIN unspecified
SUBJ
�
XCOMP
ADJUNCT
23
TNS−ASP MOOD indicative, TENSE past
�
REST
3218
3188
FIRST 229
TOKEN of
FIRST
</figure>
<figureCaption confidence="0.999979">
Figure 1: FRAGMENT c-/f-structure for The golden share was scheduled to expire at the beginning of
</figureCaption>
<bodyText confidence="0.999687772727273">
spect to the set of grammar parses consistent with
the treebank annotations. Such data can be gathered
by applying labels and brackets taken from the tree-
bank annotation to the parser input. The rudimen-
tary treebank annotations are thus used to provide
partially labeled data for discriminative estimation
of a probability model on linguistically fine-grained
parses.
Concerning empirical evaluation of disambigua-
tion performance, we feel that an evaluation measur-
ing matches of predicate-argument relations is more
appropriate for assessing the quality of our LFG-
based system than the standard measure of match-
ing labeled bracketing on section 23 of the WSJ
treebank. The first evaluation we present measures
matches of predicate-argument relations in LFG f-
structures (henceforth the LFG annotation scheme)
to a gold standard of manually annotated f-structures
for a representative subset of the WSJ treebank. The
evaluation measure counts the number of predicate-
argument relations in the f-structure of the parse
selected by the stochastic model that match those
in the gold standard annotation. Our parser plus
stochastic disambiguator achieves 79% F-score un-
der this evaluation regime.
Furthermore, we employ another metric which
maps predicate-argument relations in LFG f-
structures to the dependency relations (henceforth
the DR annotation scheme) proposed by Carroll et
al. (1999). Evaluation with this metric measures the
matches of dependency relations to Carroll et al.’s
gold standard corpus. For a direct comparison of our
results with Carroll et al.’s system, we computed an
F-score that does not distinguish different types of
dependency relations. Under this measure we obtain
76% F-score.
This paper is organized as follows. Section 2
describes the Lexical-Functional Grammar, the
constraint-based parser, and the robustness tech-
niques employed in this work. In section 3 we
present the details of the exponential model on LFG
parses and the discriminative statistical estimation
technique. Experimental results are reported in sec-
tion 4. A discussion of results is in section 5.
</bodyText>
<sectionHeader confidence="0.883867" genericHeader="method">
2 Robust Parsing using LFG
</sectionHeader>
<subsectionHeader confidence="0.994874">
2.1 A Broad-Coverage LFG
</subsectionHeader>
<bodyText confidence="0.99988480952381">
The grammar used for this project was developed in
the ParGram project (Butt et al., 1999). It uses LFG
as a formalism, producing c(onstituent)-structures
(trees) and f(unctional)-structures (attribute value
matrices) as output. The c-structures encode con-
stituency. F-structures encode predicate-argument
relations and other grammatical information, e.g.,
number, tense. The XLE parser (Maxwell and Ka-
plan, 1993) was used to produce packed represen-
tations, specifying all possible grammar analyses of
the input.
The grammar has 314 rules with regular expres-
sion right-hand sides which compile into a collec-
tion of finite-state machines with a total of 8,759
states and 19,695 arcs. The grammar uses several
lexicons and two guessers: one guesser for words
recognized by the morphological analyzer but not
in the lexicons and one for those not recognized.
As such, most nouns, adjectives, and adverbs have
no explicit lexical entry. The main verb lexicon con-
tains 9,652 verb stems and 23,525 subcategorization
frame-verb stem entries; there are also lexicons for
adjectives and nouns with subcategorization frames
and for closed class items.
For estimation purposes using the WSJ treebank,
the grammar was modified to parse part of speech
tags and labeled bracketing. A stripped down ver-
sion of the WSJ treebank was created that used
only those POS tags and labeled brackets relevant
for determining grammatical relations. The WSJ la-
beled brackets are given LFG lexical entries which
constrain both the c-structure and the f-structure of
the parse. For example, the WSJ’s ADJP-PRD la-
bel must correspond to an AP in the c-structure and
an XCOMP in the f-structure. In this version of the
corpus, all WSJ labels with -SBJ are retained and
are restricted to phrases corresponding to SUBJ in
the LFG grammar; in addition, it contains NP under
VP (OBJ and OBJth in the LFG grammar), all -LGS
tags (OBL-AG), all -PRD tags (XCOMP), VP under
VP (XCOMP), SBAR- (COMP), and verb POS tags
under VP (V in the c-structure). For example, our
labeled bracketing of wsj 1305.mrg is [NP-SBJHis
credibility] is/VBZ also [PP-PRD on the line] in the
investment community.
Some mismatches between the WSJ labeled
bracketing and the LFG grammar remain. These
often arise when a given constituent fills a gram-
matical role in more than one clause. For exam-
ple, in wsj 1303.mrg Japan’s Daiwa Securities Co.
named Masahiro Dozen president., the noun phrase
Masahiro Dozen is labeled as an NP-SBJ. However,
the LFG grammar treats it as the OBJ of the ma-
trix clause. As a result, the labeled bracketed version
of this sentence does not receive a full parse, even
though its unlabeled, string-only counterpart is well-
formed. Some other bracketing mismatches remain,
usually the result of adjunct attachment. Such mis-
matches occur in part because, besides minor mod-
ifications to match the bracketing for special con-
structions, e.g., negated infinitives, the grammar was
not altered to mirror the idiosyncrasies of the WSJ
bracketing.
</bodyText>
<subsectionHeader confidence="0.999461">
2.2 Robustness Techniques
</subsectionHeader>
<bodyText confidence="0.999896428571428">
To increase robustness, the standard grammar has
been augmented with a FRAGMENT grammar. This
grammar parses the sentence as well-formed chunks
specified by the grammar, in particular as Ss, NPs,
PPs, and VPs. These chunks have both c-structures
and f-structures corresponding to them. Any token
that cannot be parsed as one of these chunks is
parsed as a TOKEN chunk. The TOKENs are also
recorded in the c- and f-structures. The grammar has
a fewest-chunk method for determining the correct
parse. For example, if a string can be parsed as two
NPs and a VP or as one NP and an S, the NP-S
option is chosen. A sample FRAGMENT c-structure
and f-structure are shown in Fig. 1 for wsj 0231.mrg
(The golden share was scheduled to expire at the
beginning of), an incomplete sentence; the parser
builds one S chunk and then one TOKEN for the
stranded preposition.
A final capability of XLE that increases cov-
erage of the standard-plus-fragment grammar is a
SKIMMING technique. Skimming is used to avoid
timeouts and memory problems. When the amount
of time or memory spent on a sentence exceeds
a threshhold, XLE goes into skimming mode for
the constituents whose processing has not been
completed. When XLE skims these remaining con-
stituents, it does a bounded amount of work per sub-
tree. This guarantees that XLE finishes processing
a sentence in a polynomial amount of time. In pars-
ing section 23, 7.2% of the sentences were skimmed;
26.1% of these resulted in full parses, while 73.9%
were FRAGMENT parses.
The grammar coverage achieved 100% of section
23 as unseen unlabeled data: 74.7% as full parses,
25.3% FRAGMENT and/or SKIMMED parses.
</bodyText>
<sectionHeader confidence="0.9923885" genericHeader="method">
3 Discriminative Statistical Estimation
from Partially Labeled Data
</sectionHeader>
<subsectionHeader confidence="0.99284">
3.1 Exponential Models on LFG Parses
</subsectionHeader>
<bodyText confidence="0.99782125">
We employed the well-known family of exponential
models for stochastic disambiguation. In this paper
we are concerned with conditional exponential mod-
els of the form:
</bodyText>
<equation confidence="0.995221">
pλ(xly) = Zλ(y)−1eλ&apos;f(x)
</equation>
<bodyText confidence="0.992553764705882">
where X(y) is the set of parses for sentence y,
Zλ(y) = PxEX(y) eλ&apos;f(x) is a normalizing con-
stant, λ = (λ1, ... , λn) E IRn is a vector of
log-parameters, f = (f1, ... , fn) is a vector of
property-functions fi : X IR for i = 1, ... , n
on the set of parses X, and λ f(x) is the vector dot
product Pni=1 λifi(x).
In our experiments, we used around 1000
complex property-functions comprising information
about c-structure, f-structure, and lexical elements
in parses, similar to the properties used in Johnson
et al. (1999). For example, there are property func-
tions for c-structure nodes and c-structure subtrees,
indicating attachment preferences. High versus low
attachment is indicated by property functions count-
ing the number of recursively embedded phrases.
Other property functions are designed to refer to
f-structure attributes, which correspond to gram-
matical functions in LFG, or to atomic attribute-
value pairs in f-structures. More complex property
functions are designed to indicate, for example, the
branching behaviour of c-structures and the (non)-
parallelism of coordinations on both c-structure and
f-structure levels. Furthermore, properties refering
to lexical elements based on an auxiliary distribution
approach as presented in Riezler et al. (2000) are
included in the model. Here tuples of head words,
argument words, and grammatical relations are ex-
tracted from the training sections of the WSJ, and
fed into a finite mixture model for clustering gram-
matical relations. The clustering model itself is then
used to yield smoothed probabilities as values for
property functions on head-argument-relation tuples
of LFG parses.
</bodyText>
<subsectionHeader confidence="0.992397">
3.2 Discriminative Estimation
</subsectionHeader>
<bodyText confidence="0.999149">
Discriminative estimation techniques have recently
received great attention in the statistical machine
learning community and have already been applied
to statistical parsing (Johnson et al., 1999; Collins,
2000; Collins and Duffy, 2001). In discriminative es-
timation, only the conditional relation of an analysis
given an example is considered relevant, whereas in
maximum likelihood estimation the joint probability
of the training data to best describe observations is
maximized. Since the discriminative task is kept in
mind during estimation, discriminative methods can
yield improved performance. In our case, discrimi-
native criteria cannot be defined directly with respect
to “correct labels” or “gold standard” parses since
the WSJ annotations are not sufficient to disam-
biguate the more complex LFG parses. However, in-
stead of retreating to unsupervised estimation tech-
niques or creating small LFG treebanks by hand, we
use the labeled bracketing of the WSJ training sec-
tions to guide discriminative estimation. That is, dis-
criminative criteria are defined with respect to the set
ofparses consistent with the WSJ annotations.1
The objective function in our approach, denoted
by P(λ), is the joint of the negative log-likelihood
−L(λ) and a Gaussian regularization term −G(λ)
on the parameters λ. Let {(yj, zj)Imj=1 be a set of
training data, consisting of pairs of sentences y and
partial annotations z, let X(y, z) be the set of parses
for sentence y consistent with annotation z, and let
X(y) be the set of all parses produced by the gram-
mar for sentence y. Furthermore, let p[f] denote the
expectation of function f under distribution p. Then
P(λ) can be defined for a conditional exponential
model pλ(zIy) as:
</bodyText>
<equation confidence="0.997552">
log X eλ&apos;f(x)
X(yj,zj)
</equation>
<bodyText confidence="0.981449888888889">
Intuitively, the goal of estimation is to find model pa-
&apos;An earlier approach using partially labeled data for estimat-
ing stochastics parsers is Pereira and Schabes’s (1992) work on
training PCFG from partially bracketed data. Their approach
differs from the one we use here in that Pereira and Schabes
take an EM-based approach maximizing the joint likelihood of
the parses and strings of their training data, while we maximize
the conditional likelihood of the sets of parses given the corre-
sponding strings in a discriminative estimation setting.
</bodyText>
<equation confidence="0.999849095238095">
P(λ) = −L(λ) − G(λ)
= − log m pλ(zjIyj) + Xn λ2i
Y i=1 2σ2
j=1 i
lo PX(yj,zj) eλ&apos;f(x) +
g PX(yj) eλ&apos;f(x)
Xm
j=1
λ2i
Xn
i=1
2σ2
i
Xm
j=1
m
+X
j=1
X eλ&apos;f(x) + Xn λ2i
log i=1 .
X(yj) 2σ2 i
</equation>
<bodyText confidence="0.999971153846154">
rameters which make the two expectations in the last
equation equal, i.e. which adjust the model param-
eters to put all the weight on the parses consistent
with the annotations, modulo a penalty term from
the Gaussian prior for too large or too small weights.
Since a closed form solution for such parame-
ters is not available, numerical optimization meth-
ods have to be used. In our experiments, we applied
a conjugate gradient routine, yielding a fast converg-
ing optimization algorithm where at each iteration
the negative log-likelihood P(λ) and the gradient
vector have to be evaluated.2 For our task the gra-
dient takes the form:
</bodyText>
<equation confidence="0.994760285714286">
∇P(λ) = C ∂∂λλ)�
, ∂a(λ), ... , ∂a(λ) &gt; , and
eλ·f(x)fi(x)
Ex∈X(yj,zj) eλ·f(x)
eλ·f(x)fi(x) λi
Ex∈X(yj) eλ·f(x)) + .
σ2i
</equation>
<bodyText confidence="0.995254">
The derivatives in the gradient vector intuitively are
again just a difference of two expectations
</bodyText>
<equation confidence="0.855592">
λi
pλ[fi|yj] + .
σ2 i
</equation>
<bodyText confidence="0.998966333333333">
Note also that this expression shares many common
terms with the likelihood function, suggesting an ef-
ficient implementation of the optimization routine.
</bodyText>
<sectionHeader confidence="0.99981" genericHeader="evaluation">
4 Experimental Evaluation
</sectionHeader>
<subsectionHeader confidence="0.998267">
4.1 Training
</subsectionHeader>
<bodyText confidence="0.99957425">
The basic training data for our experiments are sec-
tions 02-21 of the WSJ treebank. As a first step, all
sections were parsed, and the packed parse forests
unpacked and stored. For discriminative estimation,
this data set was restricted to sentences which re-
ceive a full parse (in contrast to a FRAGMENT or
SKIMMED parse) for both its partially labeled and
its unlabeled variant. Furthermore, only sentences
2An alternative numerical method would be a combination
of iterative scaling techniques with a conditional EM algorithm
(Jebara and Pentland, 1998). However, it has been shown exper-
imentally that conjugate gradient techniques can outperform it-
erative scaling techniques by far in running time (Minka, 2001).
which received at most 1,000 parses were used.
From this set, sentences of which a discriminative
learner cannot possibly take advantage, i.e. sen-
tences where the set of parses assigned to the par-
tially labeled string was not a proper subset of the
parses assigned the unlabeled string, were removed.
These successive selection steps resulted in a fi-
nal training set consisting of 10,000 sentences, each
with parses for partially labeled and unlabeled ver-
sions. Altogether there were 150,000 parses for par-
tially labeled input and 500,000 for unlabeled input.
For estimation, a simple property selection pro-
cedure was applied to the full set of around 1000
properties. This procedure is based on a frequency
cutoff on instantiations of properties for the parses
in the labeled training set. The result of this proce-
dure is a reduction of the property vector to about
half its size. Furthermore, a held-out data set was
created from section 24 of the WSJ treebank for ex-
perimental selection of the variance parameter of the
prior distribution. This set consists of 120 sentences
which received only full parses, out of which the
most plausible one was selected manually.
</bodyText>
<subsectionHeader confidence="0.997343">
4.2 Testing
</subsectionHeader>
<bodyText confidence="0.99720715">
Two different sets of test data were used: (i) 700 sen-
tences randomly extracted from section 23 of the
WSJ treebank and given gold-standard f-structure
annotations according to our LFG scheme, and (ii)
500 sentences from the Brown corpus given gold
standard annotations by Carroll et al. (1999) accord-
ing to their dependency relations (DR) scheme.3
Annotating the WSJ test set was bootstrapped
by parsing the test sentences using the LFG gram-
mar and also checking for consistency with the
Penn Treebank annotation. Starting from the (some-
times fragmentary) parser analyses and the Tree-
bank annotations, gold standard parses were created
by manual corrections and extensions of the LFG
parses. Manual corrections were necessary in about
half of the cases. The average sentence length of
the WSJ f-structure bank is 19.8 words; the average
number of predicate-argument relations in the gold-
standard f-structures is 31.2.
Performance on the LFG-annotated WSJ test set
</bodyText>
<footnote confidence="0.990942">
3Both corpora are available online. The WSJ f-structure
bank at www.parc.com/istl/groups/nltt/fsbank/, and Carroll et
al.’s corpus at www.cogs.susx.ac.uk/lab/nlp/carroll/greval.html.
</footnote>
<equation confidence="0.9946807">
∂P(λ) �m �
∂λi j=1 (
x∈X(yj,zj)
�−
x∈X(yj)
pλ[fi|yj,zj] + �m
j=1
−
�m
j=1
</equation>
<bodyText confidence="0.999842727272727">
was measured using both the LFG and DR metrics,
thanks to an f-structure-to-DR annotation mapping.
Performance on the DR-annotated Brown test set
was only measured using the DR metric.
The LFG evaluation metric is based on the com-
parison of full f-structures, represented as triples
relation(predicate, argument). The predicate-
argument relations of the f-structure for one parse of
the sentence Meridian will pay a premium of $30.5
million to assume $2 billion in deposits. are shown
in Fig. 2.
</bodyText>
<equation confidence="0.995232">
number($:9, billion:17) number($:24, million:4)
detform(premium:3, a) mood(pay:0, indicative)
tense(pay:0, fut) adjunct(million:4, ’30.5’:28)
adjunct(premium:3, of:23) adjunct(billion:17, ’2’:19)
adjunct($:9, in:11) adjunct(pay:0, assume:7)
obj(pay:0, premium:3) stmttype(pay:0, decl)
subj(pay:0, ’Meridian’:5) obj(assume:7, $:9)
obj(of:23, $:24) subj(assume:7, pro:8)
obj(in:11, deposit:12) prontype(pro:8, null)
stmttype(assume:7, purpose)
</equation>
<figureCaption confidence="0.946979">
Figure 2: LFG predicate-argument relation represen-
tation
</figureCaption>
<bodyText confidence="0.818620333333333">
The DR annotation for our example sentence, ob-
tained via a mapping from f-structures to Carroll et
al’s annotation scheme, is shown in Fig. 3.
</bodyText>
<figure confidence="0.4987755">
(aux pay will) (subj pay Meridian )
(detmod premium a) (mod million 30.5)
(mod $ million) (mod of premium $)
(dobj pay premium ) (mod billion 2)
(mod $ billion) (mod in $ deposit)
(dobj assume $ ) (mod to pay assume)
</figure>
<figureCaption confidence="0.9350315">
Figure 3: Mapping to Carroll et al.’s dependency-
relation representation
</figureCaption>
<bodyText confidence="0.999515166666666">
Superficially, the LFG and DR representations are
very similar. One difference between the annotation
schemes is that the LFG representation in general
specifies more relation tuples than the DR represen-
tation. Also, multiple occurences of the same lex-
ical item are indicated explicitly in the LFG rep-
resentation but not in the DR representation. The
main conceptual difference between the two an-
notation schemes is the fact that the DR scheme
crucially refers to phrase-structure properties and
word order as well as to grammatical relations in
the definition of dependency relations, whereas the
LFG scheme abstracts away from serialization and
phrase-structure. Facts like this can make a correct
mapping of LFG f-structures to DR relations prob-
lematic. Indeed, we believe that we still underesti-
mate by a few points because of DR mapping diffi-
culties. 4
</bodyText>
<subsectionHeader confidence="0.949923">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.9478005">
In our evaluation, we report F-scores for both types
of annotation, LFG and DR, and for three types
of parse selection, (i) lower bound: random choice
of a parse from the set of analyses (averaged over
10 runs), (ii) upper bound: selection of the parse
with the best F-score according to the annotation
scheme used, and (iii) stochastic: the parse selected
by the stochastic disambiguator. The error reduc-
tion row lists the reduction in error rate relative to
the upper and lower bounds obtained by the stochas-
tic disambiguation model. F-score is defined as 2 ×
precision × recall/(precision + recall).
</bodyText>
<tableCaption confidence="0.8784795">
Table 1 gives results for 700 examples randomly
selected from section 23 of the WSJ treebank, using
both LFG and DR measures.
Table 1: Disambiguation results for 700 randomly
selected examples from section 23 of the WSJ tree-
bank using LFG and DR measures.
</tableCaption>
<table confidence="0.9875594">
LFG DR
upper bound 84.1 80.7
stochastic 78.6 73.0
lower bound 75.5 68.8
error reduction 36 35
</table>
<bodyText confidence="0.999862777777778">
The effect of the quality of the parses on disam-
biguation performance can be illustrated by break-
ing down the F-scores according to whether the
parser yields full parses, FRAGMENT, SKIMMED, or
SKIMMED+FRAGMENT parses for the test sentences.
The percentages of test examples which belong to
the respective classes of quality are listed in the first
row of Table 2. F-scores broken down according to
classes of parse quality are recorded in the follow-
</bodyText>
<footnote confidence="0.5880046">
4See Carroll et al. (1999) for more detail on the DR an-
notation scheme, and see Crouch et al. (2002) for more de-
tail on the differences between the DR and the LFG annotation
schemes, as well as on the difficulties of the mapping from LFG
f-structures to DR annotations.
</footnote>
<bodyText confidence="0.996849482758621">
ing rows. The first column shows F-scores for all
parses in the test set, as in Table 1. The second col-
umn shows the best F-scores when restricting atten-
tion to examples which receive only full parses. The
third column reports F-scores for examples which
receive only non-full parses, i.e. FRAGMENT or
SKIMMED parses or SKIMMED+FRAGMENT parses.
Columns 4-6 break down non-full parses according
to examples which receive only FRAGMENT, only
SKIMMED, or only SKIMMED+FRAGMENT parses.
Results of the evaluation on Carroll et al.’s Brown
test set are given in Table 3. Evaluation results for
the DR measure applied to the Brown corpus test set
broken down according to parse-quality are shown
in Table 2.
In Table 3 we show the DR measure along with an
evaluation measure which facilitates a direct com-
parison of our results to those of Carroll et al.
(1999). Following Carroll et al. (1999), we count
a dependency relation as correct if the gold stan-
dard has a relation with the same governor and de-
pendent but perhaps with a different relation-type.
This dependency-only (DO) measure thus does not
reflect mismatches between arguments and modi-
fiers in a small number of cases. Note that since
for the evaluation on the Brown corpus, no heldout
data were available to adjust the variance parame-
ter of a Bayesian model, we used a plain maximum-
likelihood model for disambiguation on this test set.
</bodyText>
<tableCaption confidence="0.9851365">
Table 3: Disambiguation results on 500 Brown cor-
pus examples using DO measure and DR measures.
</tableCaption>
<table confidence="0.996682166666667">
DO DR
Carroll et al. (1999) 75.1 -
upper bound 82.0 80.0
stochastic 76.1 74.0
lower bound 73.3 71.7
error reduction 32 33
</table>
<sectionHeader confidence="0.999411" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999075204081633">
We have presented a first attempt at scaling up a
stochastic parsing system combining a hand-coded
linguistically fine-grained grammar and a stochas-
tic disambiguation model to the WSJ treebank.
Full grammar coverage is achieved by combining
specialized constraint-based parsing techniques for
LFG grammars with partial parsing techniques. Fur-
thermore, a maximal exploitation of treebank anno-
tations for estimating a distribution on fine-grained
LFG parses is achieved by letting grammar analyses
which are consistent with the WSJ labeled bracket-
ing define a gold standard set for discriminative es-
timation. The combined system trained on WSJ data
achieves full grammar coverage and disambiguation
performance of 79% F-score on WSJ data, and 76%
F-score on the Brown corpus test set.
While disambiguation performance of around
79% F-score on WSJ data seems promising, from
one perspective it only offers a 3% absolute im-
provement over a lower bound random baseline.
We think that the high lower bound measure high-
lights an important aspect of symbolic constraint-
based grammars (in contrast to treebank gram-
mars): the symbolic grammar already significantly
restricts/disambiguates the range of possible analy-
ses, giving the disambiguator a much narrower win-
dow in which to operate. As such, it is more appro-
priate to assess the disambiguator in terms of reduc-
tion in error rate (36% relative to the upper bound)
than in terms of absolute F-score. Both the DR and
LFG annotations broadly agree in their measure of
error reduction.
The lower reduction in error rate relative to the
upper bound for DR evaluation on the Brown corpus
can be attributed to a corpus effect that has also been
observed by Gildea (2001) for training and testing
PCFGs on the WSJ and Brown corpora.5
Breaking down results according to parse quality
shows that irrespective of evaluation measure and
corpus, around 4% overall performance is lost due
to non-full parses, i.e. FRAGMENT, or SKIMMED, or
SKIMMED+FRAGMENT parses.
Due to the lack of standard evaluation measures
and gold standards for predicate-argument match-
ing, a comparison of our results to other stochastic
parsing systems is difficult. To our knowledge, so
far the only direct point of comparison is the parser
of Carroll et al. (1999) which is also evaluated on
Carroll et al.’s test corpus. They report an F-score
</bodyText>
<tableCaption confidence="0.65589">
5Gildea reports a decrease from 86.1%/86.6% re-
call/precision on labeled bracketing to 80.3%/81% when
going from training and testing on the WSJ to training on the
WSJ and testing on the Brown corpus.
Table 2: LFG F-scores for the 700 WSJ test examples and DR F-scores for the 500 Brown test examples
broken down according to parse quality.
</tableCaption>
<table confidence="0.9976506">
WSJ-LFG all full non-full fragments skimmed skimmed+fragments
% of test set 100 74.7 25.3 20.4 1.4 3.4
upper bound 84.1 88.5 73.4 76.7 70.3 61.3
stochastic 78.6 82.5 69.0 72.4 66.6 56.2
lower bound 75.5 78.4 67.7 71.0 63.0 55.9
Brown-DR all full non-full fragments skimmed skimmed+fragments
% of test set 100 79.6 20.4 20.0 2.0 1.6
upper bound 80.0 84.5 65.4 65.4 56.0 53.5
stochastic 74.0 77.9 61.5 61.5 52.8 50.0
lower bound 71.1 74.8 59.2 59.1 51.2 48.9
</table>
<bodyText confidence="0.998907666666667">
of 75.1% for a DO evaluation that ignores predicate
labels, counting only dependencies. Under this mea-
sure, our system achieves 76.1% F-score.
</bodyText>
<sectionHeader confidence="0.99872" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999668081967213">
Gosse Bouma, Gertjan von Noord, and Robert Malouf.
2000. Alpino: Wide-coverage computational analysis
of Dutch. In Proceedings of Computational Linguis-
tics in the Netherlands, Amsterdam, Netherlands.
Miriam Butt, Tracy King, Maria-Eugenia Ni˜no, and
Fr´ed´erique Segond. 1999. A Grammar Writer’s Cook-
book. Number 95 in CSLI Lecture Notes. CSLI Publi-
cations, Stanford, CA.
John Carroll, Guido Minnen, and Ted Briscoe. 1999.
Corpus annotation for parser evaluation. In Proceed-
ings of the EACL workshop on Linguistically Inter-
preted Corpora (LINC), Bergen, Norway.
Michael Collins and Nigel Duffy. 2001. Convolution
kernels for natural language. In Advances in Neural
Information Processing Systems 14(NIPS’01), Van-
couver.
Michael Collins. 2000. Discriminative reranking for nat-
ural language processing. In Proceedings of the Seven-
teenth International Conference on Machine Learning
(ICML’00), Stanford, CA.
Richard Crouch, Ronald M. Kaplan, Tracy H. King, and
Stefan Riezler. 2002. A comparison of evaluation
metrics for a broad-coverage stochastic parser. In Pro-
ceedings of the ”Beyond PARSEVAL” Workshop at the
3rd International Conference on Language Resources
and Evaluation (LREC’02), Las Palmas, Spain.
Dan Gildea. 2001. Corpus variation and parser per-
formance. In Proceedings of 2001 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), Pittsburgh, PA.
Tony Jebara and Alex Pentland. 1998. Maximum con-
ditional likelihood via bound maximization and the
CEM algorithm. In Advances in Neural Information
Processing Systems 11 (NIPS’98).
Mark Johnson, Stuart Geman, Stephen Canon, Zhiyi Chi,
and Stefan Riezler. 1999. Estimators for stochastic
“unification-based” grammars. In Proceedings of the
37th Annual Meeting of the Association for Computa-
tional Linguistics (ACL’99), College Park, MD.
Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz,
Robert MacIntyre, Ann Bies, Mark Ferguson, Karen
Katz, and Britta Schasberger. 1994. The Penn tree-
bank: Annotating predicate argument structure. In
ARPA Human Language Technology Workshop.
John Maxwell and Ron Kaplan. 1993. The interface be-
tween phrasal and functional constraints. Computa-
tional Linguistics, 19(4):571–589.
Thomas Minka. 2001. Algorithms for maximum-
likelihood logistic regression. Department of Statis-
tics, Carnegie Mellon University.
Fernando Pereira and Yves Schabes. 1992. Inside-
outside reestimation from partially bracketed corpora.
In Proceedings of the 30th Annual Meeting of the
Association for Computational Linguistics (ACL’92),
Newark, Delaware.
Stefan Riezler, Detlef Prescher, Jonas Kuhn, and Mark
Johnson. 2000. Lexicalized Stochastic Modeling of
Constraint-Based Grammars using Log-Linear Mea-
sures and EM Training. In Proceedings of the 38th
Annual Meeting of the Association for Computational
Linguistics (ACL’00), Hong Kong.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.490181">
<note confidence="0.997947">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), Philadelphia, July 2002, pp. 271-278.</note>
<title confidence="0.9929145">Parsing the Wall Street Journal using a Lexical-Functional Grammar and Discriminative Estimation Techniques</title>
<author confidence="0.999868">Stefan Riezler Tracy H King Ronald M Kaplan</author>
<affiliation confidence="0.99703">Palo Alto Research Center Palo Alto Research Center Palo Alto Research Center</affiliation>
<address confidence="0.999824">Palo Alto, CA 94304 Palo Alto, CA 94304 Palo Alto, CA 94304</address>
<email confidence="0.996767">riezler@parc.comthking@parc.comkaplan@parc.com</email>
<author confidence="0.999947">Richard Crouch John T Maxwell Mark Johnson</author>
<affiliation confidence="0.99926">Palo Alto Research Center Palo Alto Research Center Brown University</affiliation>
<address confidence="0.999503">Palo Alto, CA 94304 Palo Alto, CA 94304 Providence, RI 02912</address>
<email confidence="0.999425">crouch@parc.commaxwell@parc.commj@cs.brown.edu</email>
<abstract confidence="0.998253714285714">We present a stochastic parsing system consisting of a Lexical-Functional Grammar (LFG), a constraint-based parser and a stochastic disambiguation model. We report on the results of applying this system to parsing the UPenn Wall Street Journal (WSJ) treebank. The model combines full and partial parsing techniques to reach full grammar coverage on unseen data. The treebank annotations are used to provide partially labeled data for discriminative statistical estimation using exponential models. Disambiguation performance is evaluated by measuring matches of predicate-argument relations on two distinct test sets. On a gold standard of manually annotated f-structures for a subset of the WSJ treebank, this evaluation reaches 79% F-score. An evaluation on a gold standard of dependency relations for</abstract>
<note confidence="0.532645">Brown corpus data achieves 76% F-score.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Gosse Bouma</author>
<author>Gertjan von Noord</author>
<author>Robert Malouf</author>
</authors>
<title>Alpino: Wide-coverage computational analysis of Dutch.</title>
<date>2000</date>
<booktitle>In Proceedings of Computational Linguistics in the Netherlands,</booktitle>
<location>Amsterdam, Netherlands.</location>
<marker>Bouma, von Noord, Malouf, 2000</marker>
<rawString>Gosse Bouma, Gertjan von Noord, and Robert Malouf. 2000. Alpino: Wide-coverage computational analysis of Dutch. In Proceedings of Computational Linguistics in the Netherlands, Amsterdam, Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
<author>Tracy King</author>
<author>Maria-Eugenia Ni˜no</author>
<author>Fr´ed´erique Segond</author>
</authors>
<title>A Grammar Writer’s Cookbook. Number 95 in CSLI Lecture Notes.</title>
<date>1999</date>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<marker>Butt, King, Ni˜no, Segond, 1999</marker>
<rawString>Miriam Butt, Tracy King, Maria-Eugenia Ni˜no, and Fr´ed´erique Segond. 1999. A Grammar Writer’s Cookbook. Number 95 in CSLI Lecture Notes. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Guido Minnen</author>
<author>Ted Briscoe</author>
</authors>
<title>Corpus annotation for parser evaluation.</title>
<date>1999</date>
<booktitle>In Proceedings of the EACL workshop on Linguistically Interpreted Corpora (LINC),</booktitle>
<location>Bergen, Norway.</location>
<contexts>
<context position="6257" citStr="Carroll et al. (1999)" startWordPosition="970" endWordPosition="973">res (henceforth the LFG annotation scheme) to a gold standard of manually annotated f-structures for a representative subset of the WSJ treebank. The evaluation measure counts the number of predicateargument relations in the f-structure of the parse selected by the stochastic model that match those in the gold standard annotation. Our parser plus stochastic disambiguator achieves 79% F-score under this evaluation regime. Furthermore, we employ another metric which maps predicate-argument relations in LFG fstructures to the dependency relations (henceforth the DR annotation scheme) proposed by Carroll et al. (1999). Evaluation with this metric measures the matches of dependency relations to Carroll et al.’s gold standard corpus. For a direct comparison of our results with Carroll et al.’s system, we computed an F-score that does not distinguish different types of dependency relations. Under this measure we obtain 76% F-score. This paper is organized as follows. Section 2 describes the Lexical-Functional Grammar, the constraint-based parser, and the robustness techniques employed in this work. In section 3 we present the details of the exponential model on LFG parses and the discriminative statistical es</context>
<context position="19404" citStr="Carroll et al. (1999)" startWordPosition="3096" endWordPosition="3099">or to about half its size. Furthermore, a held-out data set was created from section 24 of the WSJ treebank for experimental selection of the variance parameter of the prior distribution. This set consists of 120 sentences which received only full parses, out of which the most plausible one was selected manually. 4.2 Testing Two different sets of test data were used: (i) 700 sentences randomly extracted from section 23 of the WSJ treebank and given gold-standard f-structure annotations according to our LFG scheme, and (ii) 500 sentences from the Brown corpus given gold standard annotations by Carroll et al. (1999) according to their dependency relations (DR) scheme.3 Annotating the WSJ test set was bootstrapped by parsing the test sentences using the LFG grammar and also checking for consistency with the Penn Treebank annotation. Starting from the (sometimes fragmentary) parser analyses and the Treebank annotations, gold standard parses were created by manual corrections and extensions of the LFG parses. Manual corrections were necessary in about half of the cases. The average sentence length of the WSJ f-structure bank is 19.8 words; the average number of predicate-argument relations in the goldstanda</context>
<context position="24056" citStr="Carroll et al. (1999)" startWordPosition="3814" endWordPosition="3817">n 23 of the WSJ treebank using LFG and DR measures. LFG DR upper bound 84.1 80.7 stochastic 78.6 73.0 lower bound 75.5 68.8 error reduction 36 35 The effect of the quality of the parses on disambiguation performance can be illustrated by breaking down the F-scores according to whether the parser yields full parses, FRAGMENT, SKIMMED, or SKIMMED+FRAGMENT parses for the test sentences. The percentages of test examples which belong to the respective classes of quality are listed in the first row of Table 2. F-scores broken down according to classes of parse quality are recorded in the follow4See Carroll et al. (1999) for more detail on the DR annotation scheme, and see Crouch et al. (2002) for more detail on the differences between the DR and the LFG annotation schemes, as well as on the difficulties of the mapping from LFG f-structures to DR annotations. ing rows. The first column shows F-scores for all parses in the test set, as in Table 1. The second column shows the best F-scores when restricting attention to examples which receive only full parses. The third column reports F-scores for examples which receive only non-full parses, i.e. FRAGMENT or SKIMMED parses or SKIMMED+FRAGMENT parses. Columns 4-6</context>
<context position="25815" citStr="Carroll et al. (1999)" startWordPosition="4116" endWordPosition="4119">unt a dependency relation as correct if the gold standard has a relation with the same governor and dependent but perhaps with a different relation-type. This dependency-only (DO) measure thus does not reflect mismatches between arguments and modifiers in a small number of cases. Note that since for the evaluation on the Brown corpus, no heldout data were available to adjust the variance parameter of a Bayesian model, we used a plain maximumlikelihood model for disambiguation on this test set. Table 3: Disambiguation results on 500 Brown corpus examples using DO measure and DR measures. DO DR Carroll et al. (1999) 75.1 - upper bound 82.0 80.0 stochastic 76.1 74.0 lower bound 73.3 71.7 error reduction 32 33 5 Discussion We have presented a first attempt at scaling up a stochastic parsing system combining a hand-coded linguistically fine-grained grammar and a stochastic disambiguation model to the WSJ treebank. Full grammar coverage is achieved by combining specialized constraint-based parsing techniques for LFG grammars with partial parsing techniques. Furthermore, a maximal exploitation of treebank annotations for estimating a distribution on fine-grained LFG parses is achieved by letting grammar analy</context>
<context position="28196" citStr="Carroll et al. (1999)" startWordPosition="4496" endWordPosition="4499">orpus effect that has also been observed by Gildea (2001) for training and testing PCFGs on the WSJ and Brown corpora.5 Breaking down results according to parse quality shows that irrespective of evaluation measure and corpus, around 4% overall performance is lost due to non-full parses, i.e. FRAGMENT, or SKIMMED, or SKIMMED+FRAGMENT parses. Due to the lack of standard evaluation measures and gold standards for predicate-argument matching, a comparison of our results to other stochastic parsing systems is difficult. To our knowledge, so far the only direct point of comparison is the parser of Carroll et al. (1999) which is also evaluated on Carroll et al.’s test corpus. They report an F-score 5Gildea reports a decrease from 86.1%/86.6% recall/precision on labeled bracketing to 80.3%/81% when going from training and testing on the WSJ to training on the WSJ and testing on the Brown corpus. Table 2: LFG F-scores for the 700 WSJ test examples and DR F-scores for the 500 Brown test examples broken down according to parse quality. WSJ-LFG all full non-full fragments skimmed skimmed+fragments % of test set 100 74.7 25.3 20.4 1.4 3.4 upper bound 84.1 88.5 73.4 76.7 70.3 61.3 stochastic 78.6 82.5 69.0 72.4 66.</context>
</contexts>
<marker>Carroll, Minnen, Briscoe, 1999</marker>
<rawString>John Carroll, Guido Minnen, and Ted Briscoe. 1999. Corpus annotation for parser evaluation. In Proceedings of the EACL workshop on Linguistically Interpreted Corpora (LINC), Bergen, Norway.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Nigel Duffy</author>
</authors>
<title>Convolution kernels for natural language.</title>
<date>2001</date>
<booktitle>In Advances in Neural Information Processing Systems 14(NIPS’01),</booktitle>
<location>Vancouver.</location>
<contexts>
<context position="13902" citStr="Collins and Duffy, 2001" startWordPosition="2189" endWordPosition="2192">model. Here tuples of head words, argument words, and grammatical relations are extracted from the training sections of the WSJ, and fed into a finite mixture model for clustering grammatical relations. The clustering model itself is then used to yield smoothed probabilities as values for property functions on head-argument-relation tuples of LFG parses. 3.2 Discriminative Estimation Discriminative estimation techniques have recently received great attention in the statistical machine learning community and have already been applied to statistical parsing (Johnson et al., 1999; Collins, 2000; Collins and Duffy, 2001). In discriminative estimation, only the conditional relation of an analysis given an example is considered relevant, whereas in maximum likelihood estimation the joint probability of the training data to best describe observations is maximized. Since the discriminative task is kept in mind during estimation, discriminative methods can yield improved performance. In our case, discriminative criteria cannot be defined directly with respect to “correct labels” or “gold standard” parses since the WSJ annotations are not sufficient to disambiguate the more complex LFG parses. However, instead of r</context>
</contexts>
<marker>Collins, Duffy, 2001</marker>
<rawString>Michael Collins and Nigel Duffy. 2001. Convolution kernels for natural language. In Advances in Neural Information Processing Systems 14(NIPS’01), Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative reranking for natural language processing.</title>
<date>2000</date>
<booktitle>In Proceedings of the Seventeenth International Conference on Machine Learning (ICML’00),</booktitle>
<location>Stanford, CA.</location>
<contexts>
<context position="13876" citStr="Collins, 2000" startWordPosition="2187" endWordPosition="2188">ncluded in the model. Here tuples of head words, argument words, and grammatical relations are extracted from the training sections of the WSJ, and fed into a finite mixture model for clustering grammatical relations. The clustering model itself is then used to yield smoothed probabilities as values for property functions on head-argument-relation tuples of LFG parses. 3.2 Discriminative Estimation Discriminative estimation techniques have recently received great attention in the statistical machine learning community and have already been applied to statistical parsing (Johnson et al., 1999; Collins, 2000; Collins and Duffy, 2001). In discriminative estimation, only the conditional relation of an analysis given an example is considered relevant, whereas in maximum likelihood estimation the joint probability of the training data to best describe observations is maximized. Since the discriminative task is kept in mind during estimation, discriminative methods can yield improved performance. In our case, discriminative criteria cannot be defined directly with respect to “correct labels” or “gold standard” parses since the WSJ annotations are not sufficient to disambiguate the more complex LFG par</context>
</contexts>
<marker>Collins, 2000</marker>
<rawString>Michael Collins. 2000. Discriminative reranking for natural language processing. In Proceedings of the Seventeenth International Conference on Machine Learning (ICML’00), Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Crouch</author>
<author>Ronald M Kaplan</author>
<author>Tracy H King</author>
<author>Stefan Riezler</author>
</authors>
<title>A comparison of evaluation metrics for a broad-coverage stochastic parser.</title>
<date>2002</date>
<booktitle>In Proceedings of the ”Beyond PARSEVAL” Workshop at the 3rd International Conference on Language Resources and Evaluation (LREC’02),</booktitle>
<location>Las Palmas,</location>
<contexts>
<context position="24130" citStr="Crouch et al. (2002)" startWordPosition="3829" endWordPosition="3832"> 80.7 stochastic 78.6 73.0 lower bound 75.5 68.8 error reduction 36 35 The effect of the quality of the parses on disambiguation performance can be illustrated by breaking down the F-scores according to whether the parser yields full parses, FRAGMENT, SKIMMED, or SKIMMED+FRAGMENT parses for the test sentences. The percentages of test examples which belong to the respective classes of quality are listed in the first row of Table 2. F-scores broken down according to classes of parse quality are recorded in the follow4See Carroll et al. (1999) for more detail on the DR annotation scheme, and see Crouch et al. (2002) for more detail on the differences between the DR and the LFG annotation schemes, as well as on the difficulties of the mapping from LFG f-structures to DR annotations. ing rows. The first column shows F-scores for all parses in the test set, as in Table 1. The second column shows the best F-scores when restricting attention to examples which receive only full parses. The third column reports F-scores for examples which receive only non-full parses, i.e. FRAGMENT or SKIMMED parses or SKIMMED+FRAGMENT parses. Columns 4-6 break down non-full parses according to examples which receive only FRAGM</context>
</contexts>
<marker>Crouch, Kaplan, King, Riezler, 2002</marker>
<rawString>Richard Crouch, Ronald M. Kaplan, Tracy H. King, and Stefan Riezler. 2002. A comparison of evaluation metrics for a broad-coverage stochastic parser. In Proceedings of the ”Beyond PARSEVAL” Workshop at the 3rd International Conference on Language Resources and Evaluation (LREC’02), Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Gildea</author>
</authors>
<title>Corpus variation and parser performance.</title>
<date>2001</date>
<booktitle>In Proceedings of 2001 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="27632" citStr="Gildea (2001)" startWordPosition="4409" endWordPosition="4410">bank grammars): the symbolic grammar already significantly restricts/disambiguates the range of possible analyses, giving the disambiguator a much narrower window in which to operate. As such, it is more appropriate to assess the disambiguator in terms of reduction in error rate (36% relative to the upper bound) than in terms of absolute F-score. Both the DR and LFG annotations broadly agree in their measure of error reduction. The lower reduction in error rate relative to the upper bound for DR evaluation on the Brown corpus can be attributed to a corpus effect that has also been observed by Gildea (2001) for training and testing PCFGs on the WSJ and Brown corpora.5 Breaking down results according to parse quality shows that irrespective of evaluation measure and corpus, around 4% overall performance is lost due to non-full parses, i.e. FRAGMENT, or SKIMMED, or SKIMMED+FRAGMENT parses. Due to the lack of standard evaluation measures and gold standards for predicate-argument matching, a comparison of our results to other stochastic parsing systems is difficult. To our knowledge, so far the only direct point of comparison is the parser of Carroll et al. (1999) which is also evaluated on Carroll </context>
</contexts>
<marker>Gildea, 2001</marker>
<rawString>Dan Gildea. 2001. Corpus variation and parser performance. In Proceedings of 2001 Conference on Empirical Methods in Natural Language Processing (EMNLP), Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Jebara</author>
<author>Alex Pentland</author>
</authors>
<title>Maximum conditional likelihood via bound maximization and the CEM algorithm.</title>
<date>1998</date>
<booktitle>In Advances in Neural Information Processing Systems</booktitle>
<volume>11</volume>
<pages>98</pages>
<contexts>
<context position="17767" citStr="Jebara and Pentland, 1998" startWordPosition="2829" endWordPosition="2832">on of the optimization routine. 4 Experimental Evaluation 4.1 Training The basic training data for our experiments are sections 02-21 of the WSJ treebank. As a first step, all sections were parsed, and the packed parse forests unpacked and stored. For discriminative estimation, this data set was restricted to sentences which receive a full parse (in contrast to a FRAGMENT or SKIMMED parse) for both its partially labeled and its unlabeled variant. Furthermore, only sentences 2An alternative numerical method would be a combination of iterative scaling techniques with a conditional EM algorithm (Jebara and Pentland, 1998). However, it has been shown experimentally that conjugate gradient techniques can outperform iterative scaling techniques by far in running time (Minka, 2001). which received at most 1,000 parses were used. From this set, sentences of which a discriminative learner cannot possibly take advantage, i.e. sentences where the set of parses assigned to the partially labeled string was not a proper subset of the parses assigned the unlabeled string, were removed. These successive selection steps resulted in a final training set consisting of 10,000 sentences, each with parses for partially labeled a</context>
</contexts>
<marker>Jebara, Pentland, 1998</marker>
<rawString>Tony Jebara and Alex Pentland. 1998. Maximum conditional likelihood via bound maximization and the CEM algorithm. In Advances in Neural Information Processing Systems 11 (NIPS’98).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Stuart Geman</author>
<author>Stephen Canon</author>
<author>Zhiyi Chi</author>
<author>Stefan Riezler</author>
</authors>
<title>Estimators for stochastic “unification-based” grammars.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL’99),</booktitle>
<location>College Park, MD.</location>
<contexts>
<context position="2392" citStr="Johnson et al., 1999" startWordPosition="348" endWordPosition="351">ts have so far been confined to a relatively small scale for various reasons. Firstly, the rudimentary character of functional annotations in standard treebanks has hindered the direct use of such data for statistical estimation of linguistically fine-grained statistical parsing systems. Rather, parameter estimation for such models had to resort to unsupervised techniques (Bouma et al., 2000; Riezler et al., 2000), or training corpora tailored to the specific grammars had to be created by parsing and manual disambiguation, resulting in relatively small training sets of around 1,000 sentences (Johnson et al., 1999). Furthermore, the effort involved in coding broadcoverage grammars by hand has often led to the specialization of grammars to relatively small domains, thus sacrificing grammar coverage (i.e. the percentage of sentences for which at least one analysis is found) on free text. The approach presented in this paper is a first attempt to scale up stochastic parsing systems based on linguistically fine-grained handcoded grammars to the UPenn Wall Street Journal (henceforth WSJ) treebank (Marcus et al., 1994). The problem of grammar coverage, i.e. the fact that not all sentences receive an analysis,</context>
<context position="12507" citStr="Johnson et al. (1999)" startWordPosition="1990" endWordPosition="1993">s paper we are concerned with conditional exponential models of the form: pλ(xly) = Zλ(y)−1eλ&apos;f(x) where X(y) is the set of parses for sentence y, Zλ(y) = PxEX(y) eλ&apos;f(x) is a normalizing constant, λ = (λ1, ... , λn) E IRn is a vector of log-parameters, f = (f1, ... , fn) is a vector of property-functions fi : X IR for i = 1, ... , n on the set of parses X, and λ f(x) is the vector dot product Pni=1 λifi(x). In our experiments, we used around 1000 complex property-functions comprising information about c-structure, f-structure, and lexical elements in parses, similar to the properties used in Johnson et al. (1999). For example, there are property functions for c-structure nodes and c-structure subtrees, indicating attachment preferences. High versus low attachment is indicated by property functions counting the number of recursively embedded phrases. Other property functions are designed to refer to f-structure attributes, which correspond to grammatical functions in LFG, or to atomic attributevalue pairs in f-structures. More complex property functions are designed to indicate, for example, the branching behaviour of c-structures and the (non)- parallelism of coordinations on both c-structure and f-st</context>
<context position="13861" citStr="Johnson et al., 1999" startWordPosition="2183" endWordPosition="2186">er et al. (2000) are included in the model. Here tuples of head words, argument words, and grammatical relations are extracted from the training sections of the WSJ, and fed into a finite mixture model for clustering grammatical relations. The clustering model itself is then used to yield smoothed probabilities as values for property functions on head-argument-relation tuples of LFG parses. 3.2 Discriminative Estimation Discriminative estimation techniques have recently received great attention in the statistical machine learning community and have already been applied to statistical parsing (Johnson et al., 1999; Collins, 2000; Collins and Duffy, 2001). In discriminative estimation, only the conditional relation of an analysis given an example is considered relevant, whereas in maximum likelihood estimation the joint probability of the training data to best describe observations is maximized. Since the discriminative task is kept in mind during estimation, discriminative methods can yield improved performance. In our case, discriminative criteria cannot be defined directly with respect to “correct labels” or “gold standard” parses since the WSJ annotations are not sufficient to disambiguate the more </context>
</contexts>
<marker>Johnson, Geman, Canon, Chi, Riezler, 1999</marker>
<rawString>Mark Johnson, Stuart Geman, Stephen Canon, Zhiyi Chi, and Stefan Riezler. 1999. Estimators for stochastic “unification-based” grammars. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL’99), College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Grace Kim</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Robert MacIntyre</author>
<author>Ann Bies</author>
<author>Mark Ferguson</author>
<author>Karen Katz</author>
<author>Britta Schasberger</author>
</authors>
<title>The Penn treebank: Annotating predicate argument structure.</title>
<date>1994</date>
<booktitle>In ARPA Human Language Technology Workshop.</booktitle>
<contexts>
<context position="2900" citStr="Marcus et al., 1994" startWordPosition="429" endWordPosition="432">ual disambiguation, resulting in relatively small training sets of around 1,000 sentences (Johnson et al., 1999). Furthermore, the effort involved in coding broadcoverage grammars by hand has often led to the specialization of grammars to relatively small domains, thus sacrificing grammar coverage (i.e. the percentage of sentences for which at least one analysis is found) on free text. The approach presented in this paper is a first attempt to scale up stochastic parsing systems based on linguistically fine-grained handcoded grammars to the UPenn Wall Street Journal (henceforth WSJ) treebank (Marcus et al., 1994). The problem of grammar coverage, i.e. the fact that not all sentences receive an analysis, is tackled in our approach by an extension of a fullfledged Lexical-Functional Grammar (LFG) and a constraint-based parser with partial parsing techniques. In the absence of a complete parse, a socalled “FRAGMENT grammar” allows the input to be analyzed as a sequence of well-formed chunks. The set of fragment parses is then chosen on the basis of a fewest-chunk method. With this combination of full and partial parsing techniques we achieve 100% grammar coverage on unseen data. Another goal of this work</context>
</contexts>
<marker>Marcus, Kim, Marcinkiewicz, MacIntyre, Bies, Ferguson, Katz, Schasberger, 1994</marker>
<rawString>Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz, Robert MacIntyre, Ann Bies, Mark Ferguson, Karen Katz, and Britta Schasberger. 1994. The Penn treebank: Annotating predicate argument structure. In ARPA Human Language Technology Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Maxwell</author>
<author>Ron Kaplan</author>
</authors>
<title>The interface between phrasal and functional constraints.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>4</issue>
<contexts>
<context position="7431" citStr="Maxwell and Kaplan, 1993" startWordPosition="1143" endWordPosition="1147">on LFG parses and the discriminative statistical estimation technique. Experimental results are reported in section 4. A discussion of results is in section 5. 2 Robust Parsing using LFG 2.1 A Broad-Coverage LFG The grammar used for this project was developed in the ParGram project (Butt et al., 1999). It uses LFG as a formalism, producing c(onstituent)-structures (trees) and f(unctional)-structures (attribute value matrices) as output. The c-structures encode constituency. F-structures encode predicate-argument relations and other grammatical information, e.g., number, tense. The XLE parser (Maxwell and Kaplan, 1993) was used to produce packed representations, specifying all possible grammar analyses of the input. The grammar has 314 rules with regular expression right-hand sides which compile into a collection of finite-state machines with a total of 8,759 states and 19,695 arcs. The grammar uses several lexicons and two guessers: one guesser for words recognized by the morphological analyzer but not in the lexicons and one for those not recognized. As such, most nouns, adjectives, and adverbs have no explicit lexical entry. The main verb lexicon contains 9,652 verb stems and 23,525 subcategorization fra</context>
</contexts>
<marker>Maxwell, Kaplan, 1993</marker>
<rawString>John Maxwell and Ron Kaplan. 1993. The interface between phrasal and functional constraints. Computational Linguistics, 19(4):571–589.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Minka</author>
</authors>
<title>Algorithms for maximumlikelihood logistic regression.</title>
<date>2001</date>
<institution>Department of Statistics, Carnegie Mellon University.</institution>
<contexts>
<context position="17926" citStr="Minka, 2001" startWordPosition="2855" endWordPosition="2856">ll sections were parsed, and the packed parse forests unpacked and stored. For discriminative estimation, this data set was restricted to sentences which receive a full parse (in contrast to a FRAGMENT or SKIMMED parse) for both its partially labeled and its unlabeled variant. Furthermore, only sentences 2An alternative numerical method would be a combination of iterative scaling techniques with a conditional EM algorithm (Jebara and Pentland, 1998). However, it has been shown experimentally that conjugate gradient techniques can outperform iterative scaling techniques by far in running time (Minka, 2001). which received at most 1,000 parses were used. From this set, sentences of which a discriminative learner cannot possibly take advantage, i.e. sentences where the set of parses assigned to the partially labeled string was not a proper subset of the parses assigned the unlabeled string, were removed. These successive selection steps resulted in a final training set consisting of 10,000 sentences, each with parses for partially labeled and unlabeled versions. Altogether there were 150,000 parses for partially labeled input and 500,000 for unlabeled input. For estimation, a simple property sele</context>
</contexts>
<marker>Minka, 2001</marker>
<rawString>Thomas Minka. 2001. Algorithms for maximumlikelihood logistic regression. Department of Statistics, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Yves Schabes</author>
</authors>
<title>Insideoutside reestimation from partially bracketed corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics (ACL’92),</booktitle>
<location>Newark, Delaware.</location>
<marker>Pereira, Schabes, 1992</marker>
<rawString>Fernando Pereira and Yves Schabes. 1992. Insideoutside reestimation from partially bracketed corpora. In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics (ACL’92), Newark, Delaware.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Detlef Prescher</author>
<author>Jonas Kuhn</author>
<author>Mark Johnson</author>
</authors>
<title>Lexicalized Stochastic Modeling of Constraint-Based Grammars using Log-Linear Measures and EM Training.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL’00),</booktitle>
<location>Hong Kong.</location>
<contexts>
<context position="2188" citStr="Riezler et al., 2000" startWordPosition="316" endWordPosition="319">n Statistical parsing using combined systems of handcoded linguistically fine-grained grammars and stochastic disambiguation components has seen considerable progress in recent years. However, such attempts have so far been confined to a relatively small scale for various reasons. Firstly, the rudimentary character of functional annotations in standard treebanks has hindered the direct use of such data for statistical estimation of linguistically fine-grained statistical parsing systems. Rather, parameter estimation for such models had to resort to unsupervised techniques (Bouma et al., 2000; Riezler et al., 2000), or training corpora tailored to the specific grammars had to be created by parsing and manual disambiguation, resulting in relatively small training sets of around 1,000 sentences (Johnson et al., 1999). Furthermore, the effort involved in coding broadcoverage grammars by hand has often led to the specialization of grammars to relatively small domains, thus sacrificing grammar coverage (i.e. the percentage of sentences for which at least one analysis is found) on free text. The approach presented in this paper is a first attempt to scale up stochastic parsing systems based on linguistically </context>
<context position="13257" citStr="Riezler et al. (2000)" startWordPosition="2095" endWordPosition="2098">gh versus low attachment is indicated by property functions counting the number of recursively embedded phrases. Other property functions are designed to refer to f-structure attributes, which correspond to grammatical functions in LFG, or to atomic attributevalue pairs in f-structures. More complex property functions are designed to indicate, for example, the branching behaviour of c-structures and the (non)- parallelism of coordinations on both c-structure and f-structure levels. Furthermore, properties refering to lexical elements based on an auxiliary distribution approach as presented in Riezler et al. (2000) are included in the model. Here tuples of head words, argument words, and grammatical relations are extracted from the training sections of the WSJ, and fed into a finite mixture model for clustering grammatical relations. The clustering model itself is then used to yield smoothed probabilities as values for property functions on head-argument-relation tuples of LFG parses. 3.2 Discriminative Estimation Discriminative estimation techniques have recently received great attention in the statistical machine learning community and have already been applied to statistical parsing (Johnson et al., </context>
</contexts>
<marker>Riezler, Prescher, Kuhn, Johnson, 2000</marker>
<rawString>Stefan Riezler, Detlef Prescher, Jonas Kuhn, and Mark Johnson. 2000. Lexicalized Stochastic Modeling of Constraint-Based Grammars using Log-Linear Measures and EM Training. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL’00), Hong Kong.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>