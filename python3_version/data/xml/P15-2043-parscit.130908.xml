<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004073">
<title confidence="0.990978">
Synthetic Word Parsing Improves Chinese Word Segmentation
</title>
<author confidence="0.998835">
Fei Cheng Kevin Duh Yuji Matsumoto
</author>
<affiliation confidence="0.999122">
Graduate School of Information Science
Nara Institute of Science and Technology
</affiliation>
<address confidence="0.687179">
8916-5 Takayama, Ikoma, Nara, 630-0192, Japan
</address>
<email confidence="0.999515">
{fei-c,kevinduh,matsu}@is.naist.jp
</email>
<sectionHeader confidence="0.997398" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999643928571429">
We present a novel solution to improve
the performance of Chinese word seg-
mentation (CWS) using a synthetic word
parser. The parser analyses the inter-
nal structure of words, and attempts to
convert out-of-vocabulary words (OOVs)
into in-vocabulary fine-grained sub-words.
We propose a pipeline CWS system that
first predicts this fine-grained segmenta-
tion, then chunks the output to recon-
struct the original word segmentation stan-
dard. We achieve competitive results on
the PKU and MSR datasets, with substan-
tial improvements in OOV recall.
</bodyText>
<sectionHeader confidence="0.999391" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999419375">
Since Chinese has no spaces between words to in-
dicate word boundaries, Chinese word segmenta-
tion is a task to determine word boundaries be-
tween characters. In recent years, research in Chi-
nese word segmentation has progressed signifi-
cantly, with state-of-the-art performing at around
96% in precision and recall (Xue, 2003; Zhang
and Clark, 2007; Li and Sun, 2009).
However, frequent OOVs are still a crucial issue
that causes low accuracy in word segmentation.
Li and Zhou (2012) defined those words that are
OOVs but consisting of frequent internal parts as
pseudo-OOV words and estimated that over 60%
of OOVs are pseudo-OOVs in five common Chi-
nese corpora. For instance, PKU corpus does not
contain the word 陈列室 (exhibition room), even
though the word 陈列 (exhibit) and 室 (room) ap-
pear hundreds of times. Goh et al. (2006) also
claimed that most OOVs are proper nouns taking
the form of Chinese synthetic words.
These previous works suggest that by analysing
the internal structure of the synthetic words, we
can transform pseudo-OOVs into in-vocabulary
words (IVs). By running a synthetic word parser
on each of the words in a CWS training set, we can
generate a fine-grained segmentation standard that
contains more IVs. Since the current conditional
random field (CRF) word segmenters (Tseng et al.,
2005; Sun and Xu, 2011) perform well on IVs, this
transforming process can conceivably improve the
handling of pseudo-OOV words, as long as we can
recover the original word segmentation standard
from the fine-grained sub-word segmentation.
In recent years, some related works about im-
proving OOV problem in CWS have been ongo-
ing. Sun et al. (2012) presented a joint model for
Chinese word segmentation and OOVs detection.
Their models achieved fast training speed, high ac-
curacies and increase on OOV recall. Sun (2011)
proposed a similar sub-word structure which is
generated by merging the segmentations provided
by different segmenters (a word-based segmenter,
a character-based segmenter and a local character
classifier). However, her models does not predict
the sub-words of all the synthetic words, but those
words with different segmented results of the three
segmenters. Her work maximizes the agreement
of different models to improve CWS performance.
Different from her work, we aim to provide an uni-
fied way to incorporate morphological information
of the synthetic words into the CWS task.
In this paper, we propose a pipeline word seg-
mentation system to address the pseudo-OOV
problem. Our word segmentation system first con-
verts the original training data into a fine-grained
standard by parsing all words with a synthetic
word parser (Section 2.1), then trains a CRF-
based sub-word segmenter (Section 2.2). A sec-
ond CRF chunker is trained to recover the origi-
nal word segmentation given the fine-grained re-
sults of the first CRF. The intuition is that fine-
grained sub-word segmentations resolve pseudo-
OOVs into IVs, which are easier to predict cor-
rectly by the first CRF. Secondly, by training an-
</bodyText>
<page confidence="0.881626">
262
</page>
<bodyText confidence="0.850206">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 262–267,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
other CRF that predicts the original word segmen-
tation given the fine-grained segmentation as in-
put, we can recover the fine-grained output into
original word segmentation standard (Section 2.3).
The flow chart of our word segmentation system is
shown in Figure 1.
</bodyText>
<figureCaption confidence="0.9763235">
Figure 1: The Flow Chart of the Chinese Word
Segmentation System.
</figureCaption>
<sectionHeader confidence="0.946624" genericHeader="method">
2 System Components
</sectionHeader>
<subsectionHeader confidence="0.983745">
2.1 Synthetic Word Parser
</subsectionHeader>
<bodyText confidence="0.999764375">
Intuitively, Chinese synthetic words contain inter-
nal morphological information that is helpful to
recognize OOVs. Cheng et al. (2014) proposed
a character-based parser to parse the internal tree
structure of words. For instance, the tree and flat
segmented result of the word 市 政 府 (munici-
pal government) are shown in Figure 2. In this
work, we train a graph-based parser (McDonald,
2006) on the data released by Cheng et al. (2014)
and include the dictionary (NAIST Chinese Dic-
tionary1) features and Brown clustering features
extracted from a large unlabeled corpus (Chinese
Gigaword Second Edition2) as described in Cheng
et al. (2014).
For native Chinese speakers, single character
and two character words are usually treated as the
</bodyText>
<footnote confidence="0.999454">
1http://cl.naist.jp/index.php?%B8%F8%B3%AB%A5%E
A%A5%BD%A1%BC%A5%B9%2FNCD
2https://catalog.ldc.upenn.edu/LDC2005T14
</footnote>
<bodyText confidence="0.999625666666667">
smallest units. In this work, we parse all the words
in the PKU and MSR training data with character
length greater than two. By replacing the words
with the flat segmented results, we convert the
training data into a fine-grained word segmenta-
tion standard as shown in Figure 3.
</bodyText>
<figureCaption confidence="0.9958745">
Figure 2: The Tree Structure of a Sample Word
and the Flat Segmented Result.
</figureCaption>
<figure confidence="0.74278575">
Original 市政府 / 办公厅 / 等 / 单位
CWS tags BIE/BIE/S/BE
Fine-grained 市 / 政府 / 办公 / 厅 / 等 / 单位
CWS tags S/BE/BE/S/S/BE
</figure>
<figureCaption confidence="0.999119">
Figure 3: A Sample Sentence of Labeling Chinese
</figureCaption>
<bodyText confidence="0.882589833333333">
word segmentation tags on the Original and Fine-
grained Standard. In this work, we adopt 4-tag set
for word segmentation. ”B” denotes the beginning
character of a word. ”I” denotes the middle char-
acter of a word. ”E” denotes the end character of
a word. ”S” denotes a single character word.
</bodyText>
<subsectionHeader confidence="0.99834">
2.2 CRF-based Word Segmenter
</subsectionHeader>
<bodyText confidence="0.999804529411765">
Xue et al. (2003) proposed a method which treated
Chinese word segmentation as a character-based
sequential labeling problem and exploited sev-
eral discriminative learning algorithms. Tseng
et al. (2005) adopted the CRFs as the learning
method and obtained the best results in the second
international Chinese word segmentation bakeoff-
2005. Moreover, Sun and Xu (2011) attempted to
extract information from large unlabeled data to
enhance the Chinese word segmentation results.
In this work, we train a traditional CRF-based
supervised model on the fine-grained training data,
include the dictionary (NAIST Chinese Dictio-
nary) features and access variety features extracted
from a large unlabeled corpus (Chinese Giga-
word Second Edition) as described in Sun and
Xu (2011).
</bodyText>
<page confidence="0.989">
263
</page>
<subsectionHeader confidence="0.992773">
2.3 CRF-based Chunking Model
</subsectionHeader>
<bodyText confidence="0.952135722222222">
In order to obtain the word segmentation result
with original word segmentation standard, we
train a CRF-based chunking model on the original
and fine-grained training data. We show a sam-
ple sentence of labeling chunking tags in Figure 4.
Comparing two sentences, we label all common
units with the tag ”S”. The words 市 and 政府 are
tagged as ”B” and ”E”, since 市 is the beginning
part of the synthetic word 市政府 and 政府 is the
ending part. In the chunking process, the frequent
prefix 市 is coordinated with neighbouring units to
compose the synthetic word 市政府.
For each labeling, we include previous, current
and next word as the features for the chunking
model.
Original
Fine-grained
Chunking tags
</bodyText>
<figureCaption confidence="0.937881">
Figure 4: A Sample Sentence of Labeling Chunk-
</figureCaption>
<bodyText confidence="0.565482">
ing Tags. In this work, we adopt 4-tag set for
chunking. ”B” denotes the beginning part of a syn-
thetic word. ”I” denotes the middle part. ”E” de-
notes the end part. ”S” denotes a single word.
</bodyText>
<sectionHeader confidence="0.999474" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.980335">
3.1 Settings
</subsectionHeader>
<bodyText confidence="0.999958052631579">
Cheng et al. (2014) released a dictionary of
31,849 synthetic words with internal structure an-
notated. Since transliteration words (e.g. 贝克
汉 姆 Becham) exist in Chinese, our synthetic
word parser should perform well not only on syn-
thetic words but also on transliteration words.
We extracted 6,574 transliteration words from the
NAIST Chinese Dictionary and automatically as-
signed flat structures for these words. As a result,
we obtained 38,423 words as the training data for
our parser.
The second international Chinese word seg-
mentation bakeoff-2005 provided two annotated
simplified Chinese corpora: PKU and MSR. We
conducted all word segmentation experiments on
these two corpora.
We used CRF++3 (version 0.58) as the imple-
mentation of CRFs in our experiments with the de-
fault regularization algorithm L2.
</bodyText>
<footnote confidence="0.998076">
3The CRF++ package can be found in the following web-
site: http://taku910.github.io/crfpp/
</footnote>
<subsectionHeader confidence="0.988919">
3.2 Word Segmentation Results
</subsectionHeader>
<bodyText confidence="0.999976487179488">
Table 1 summarizes the word segmentation re-
sults on PKU and MSR corpora. For compari-
son, we give a baseline result by training a CRF
word segmenter on the original PKU and MSR
data sets with the same features. Our proposed
system is expected to improve the word segmen-
tation performance on pseudo-OOVs. Compared
to the baseline, there are significant increases on
OOV recall from 0.792 to 0.822 on PKU and 0.682
to 0.717 on MSR. We also evaluated the pseudo-
OOV recall and observed 4% increases from the
baseline to the proposed system. Our proposed
system achieves higher F-score with 0.961 on
PKU and 0.971 on MSR. Comparing to other sys-
tems, our proposed method obtains the state-of-
the-art F-score as the results of Zhang et al. (2013)
who extracted dynamic statistical features from
both in-domain and out-domain corpus and our
OOV recall significantly outperforms theirs with
a 9% lead. In MSR, we obtain very close OOV
recall and slightly lower F-score than the state-of-
the-art system (Sun et al., 2009), which adopted a
latent variable CRF model. However, our system
significantly outperforms their system in PKU. In
both corpora, our proposed system outperforms
the best ”Bakeoff-2005” results.
We also test the statistical significance of the
results by using the criterion (Sproat and Emer-
son, 2003; Emerson, 2005). The 95% confidence
interval is given as ±2�/p(1 − p)/n, where n is
the number of words in the test data. They treat
two systems as significantly different (at the 95%
confidence level), if at least one of their precision-
based confidences ”Cp” or recall-based ”Cr” are
different. As the results shown in Table 2, the
baseline and proposed method are significantly
different on precision and recall in both PKU and
MSR corpus. In conclusion, our proposed method
significantly outperforms the baseline.
</bodyText>
<subsectionHeader confidence="0.998822">
3.3 Additional Experiments
</subsectionHeader>
<bodyText confidence="0.999924">
We conducted additional experiments to evaluate
the performance of the synthetic word parser and
CRF-based chunking model.
First, we are interested in how much parsing ac-
curacy is needed for good results. Figure 5 dis-
plays the OOV recall results of our word segmen-
tation system when the synthetic word parser is
trained with amounts of labeled synthetic words
data. As the data size increases, our word segmen-
</bodyText>
<equation confidence="0.992736333333333">
市政府 / 办&amp;T / 4 / *4A
市 / 政府 / 办&amp; / T / 4 / *4A
B/E/B/E/S/S
</equation>
<page confidence="0.994467">
264
</page>
<table confidence="0.999428571428571">
System PKU MSR
P R F Roov Rpseudo P R F Roov Rpseudo
Baseline 0.957 0.960 0.959 0.792 0.797 0.971 0.968 0.970 0.682 0.689
Proposed method 0.960 0.962 0.961 0.822 0.838 0.972 0.970 0.971 0.717 0.73
Zhang et al. (2013) 0.965 0.958 0.961 0.731 - - - - - -
Sun et al. (2009) 0.956 0.948 0.952 0.778 - 0.973 0.973 0.973 0.722 -
Bakeoff-2005 0.953 0.946 0.950 0.636 - 0.962 0.966 0.964 0.717 -
</table>
<tableCaption confidence="0.908287333333333">
Table 1: Comparison of the Proposed Method to the Baseline and Previous works on PKU and MSR
Corpora. Here, ”Rpseudo” denotes the recall of pseudo-OOV words. ”Bakeoff-2005” denotes the best
results of the second international Chinese word segmentation bakeoff-2005 on two corpora. Since
we use extra resources and our proposed method replies on the synthetic word parser trained on an
dictionary with internal structure annotated, the results cannot be directly compared with the state-of-
the-art systems.
</tableCaption>
<table confidence="0.999506">
System PKU MSR
Words P Cp R Cr Words P Cp R Cr
Baseline 104372 0.957 10.00126 0.960 10.00121 106873 0.971 10.00103 0.968 10.00108
Proposed 104372 0.960 10.00121 0.962 10.00118 106873 0.972 10.00101 0.970 10.00104
</table>
<tableCaption confidence="0.999559">
Table 2: The Statistical Significance Test of the Word Segmentation Results on PKU and MSR Corpora.
</tableCaption>
<bodyText confidence="0.999907233333333">
tation system obtains consistent gains on OOV re-
call on both corpora. On the whole 38K words
training data, our system reaches the highest OOV
recall. An interesting observation is that the OOV
recall on MSR is more sensitive on data size
changing. The main reason is the different anno-
tation standard of the two corpus. PKU is a cor-
respondingly fine-grained annotated corpus with
shorter average word length than MSR. Our syn-
thetic word parser reaches high parsing accuracy
on short length words (three-character and four-
character words) even with a small training data
size. With the increase of word length, the parser
needs more training data. These factors cause that
our system reaches high OOV recall on PKU start-
ing from a small training data size and obtains
more OOV recall gains on MSR when increasing
the training data size.
Our pipeline system adopts a chunking model
to recover the original standard from the fine-
grained standard. One question is how difficult
is this task. Unfortunately, we do not have the
gold fine-grained input to evaluate the perfor-
mance of our chunking model directly; i.e. it is
not clear whether a segmentation error is due to
mis-predictions in the first or second CRF. There-
fore, we use the synthetic word parser to parse all
the words in the gold testing data and generate an
artificial gold fine-grained input for the chunking
model. This data keeps the original word bound-
</bodyText>
<figure confidence="0.439488">
Training data size (thousands of words)
(c) Parsing Performance
</figure>
<figureCaption confidence="0.65874275">
Figure 5: The OOV Recall Evaluation and
the Character Labeled Accuracy (5-fold cross-
validation) of the Synthetic Word Parser on Train-
ing Data Size.
</figureCaption>
<bodyText confidence="0.99839675">
aries and can be used to observe the chunking per-
formance. Table 3 shows that the chunking model
on the artificial data obtains a 0.822 to 0.847 im-
provement in OOV recall. We can interpret this
to mean that 0.025 improvement is possible if the
first CRF was perfect; on the other hand, the gap
between 0.847 and 1.0 shows that potentially the
second CRF is a harder task. However, the real
</bodyText>
<figure confidence="0.997790580645161">
Training data size (thousands of words) Training data size (thousands of words)
(a) PKU Corpus (b) MSR Corpus
OOV recall (percentage)
82.5
81.5
80.5
83
82
81
80
5 10 15 20 25 30 35 40
PKU
OOV recall (percentage)
69.5
72.5
71.5
70.5
72
71
70
5 10 15 20 25 30 35 40
MSR
Labeled Accuracy (percentage)
97
96
95
94
93
92
5 10 15 20 25 30 35 40
Synthetic Word Parser
</figure>
<page confidence="0.996291">
265
</page>
<bodyText confidence="0.8988095">
gap is less for the lose of the parsing step and the
existence of non-pseudo OOVs.
</bodyText>
<table confidence="0.9991325">
System PKU MSR
F Roov F Roov
Proposed 0.961 0.822 0.971 0.717
Artifical gold 0.965 0.847 0.973 0.743
</table>
<tableCaption confidence="0.998005">
Table 3: The Word Segmentation evaluation of
</tableCaption>
<bodyText confidence="0.819402">
the Chunking Model. ”Artificial gold” denotes
the word segmentation result when the chunking
model runs on the artificial gold input.
</bodyText>
<subsectionHeader confidence="0.968145">
3.4 Analysis
</subsectionHeader>
<bodyText confidence="0.9999748">
As we expected, the proposed method obtains sig-
nificant improvement on OOV recall. In both cor-
pora, we observed a number of OOVs are seg-
mented correctly. For instance, 管3EM (manage-
ment law) is an OOV word in PKU corpus. In this
word, 管3E (management) appears frequently and
M (law) is a common suffix in Chinese synthetic
words, such as 行政M (administrative law) or 国
际M (international law). This type of pseudo-
OOVs share a major contribution to upgrade the
system performance. We also observed that some
polysemous words bring ambiguities to the chunk-
ing step. The character 会 carries the meanings
”will” as an auxiliary verb or ”meeting” in a syn-
thetic word 运动会 (sports meeting).
</bodyText>
<sectionHeader confidence="0.999613" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.9999774">
In this paper, we presented a series processes to
reduce OOV rate and extract morphological infor-
mation inside Chinese synthetic words on a fine-
grained word segmentation standard. As a result,
we can improve the Chinese word segmentation
performance (especially on pseudo-OOVs) with-
out introducing any new feature types. Our pro-
posed method achieved the state-of-the-art F-score
and OOV recall on two common corpus PKU and
MSR. However, note that we only exploited the
flat segmented results of internal word structure
here. As future work, we plan to exploit the full
tree structure of synthetic words to improve not
only CWS but also additional downstream tasks
such as sentence parsing.
</bodyText>
<sectionHeader confidence="0.998999" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999053859649123">
Fei Cheng, Kevin Duh, and Yuji Matsumoto. 2014.
Parsing chinese synthetic words with a character-
based dependency model. In Proceedings of the
Ninth International Conference on Language Re-
sources and Evaluation (LREC’14), Reykjavik, Ice-
land, may. European Language Resources Associa-
tion (ELRA).
Thomas Emerson. 2005. The second international chi-
nese word segmentation bakeoff. In Proceedings of
the fourth SIGHAN workshop on Chinese language
Processing, volume 133.
Chooi-Ling Goh, Masayuki Asahara, and Yuji Mat-
sumoto. 2006. Machine learning-based methods to
chinese unknown word detection and pos tag guess-
ing. Journal of Chinese Language and Computing,
16(4):185–206.
Zhongguo Li and Maosong Sun. 2009. Punctuation as
implicit annotations for chinese word segmentation.
Computational Linguistics, 35(4):505–512.
Zhongguo Li and Guodong Zhou. 2012. Unified de-
pendency parsing of chinese morphological and syn-
tactic structures. In Proceedings of the 2012 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning, pages 1445–1454. Association for
Computational Linguistics.
Ryan McDonald. 2006. Discriminative learning and
spanning tree algorithms for dependency parsing.
Ph.D. thesis, PhD Thesis. University of Pennsylva-
nia.
Richard Sproat and Thomas Emerson. 2003. The
first international chinese word segmentation bake-
off. In Proceedings of the second SIGHAN work-
shop on Chinese language processing-Volume 17,
pages 133–143. Association for Computational Lin-
guistics.
Weiwei Sun and Jia Xu. 2011. Enhancing chinese
word segmentation using unlabeled data. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing, pages 970–979. As-
sociation for Computational Linguistics.
Xu Sun, Yaozhong Zhang, Takuya Matsuzaki, Yoshi-
masa Tsuruoka, and Jun’ichi Tsujii. 2009. A dis-
criminative latent variable chinese segmenter with
hybrid word/character information. In Proceedings
of Human Language Technologies: The 2009 An-
nual Conference of the North American Chapter
of the Association for Computational Linguistics,
pages 56–64. Association for Computational Lin-
guistics.
Xu Sun, Houfeng Wang, and Wenjie Li. 2012. Fast on-
line training with frequency-adaptive learning rates
for chinese word segmentation and new word de-
tection. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics: Long Papers-Volume 1, pages 253–262. Asso-
ciation for Computational Linguistics.
</reference>
<page confidence="0.977001">
266
</page>
<reference confidence="0.999638666666667">
Weiwei Sun. 2011. A stacked sub-word model
for joint chinese word segmentation and part-of-
speech tagging. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies-Volume
1, pages 1385–1394. Association for Computational
Linguistics.
Huihsin Tseng, Pichuan Chang, Galen Andrew, Daniel
Jurafsky, and Christopher Manning. 2005. A condi-
tional random field word segmenter for sighan bake-
off 2005. In Proceedings of the fourth SIGHAN
workshop on Chinese language Processing, volume
171.
Nianwen Xue. 2003. Chinese word segmentation as
character tagging. Computational Linguistics and
Chinese Language Processing, 8(1):29–48.
Yue Zhang and Stephen Clark. 2007. Chinese seg-
mentation with a word-based perceptron algorithm.
In ANNUAL MEETING-ASSOCIATION FOR COM-
PUTATIONAL LINGUISTICS, volume 45, page 840.
Longkai Zhang, Houfeng Wang, Xu Sun, and Mairgup
Mansur. 2013. Exploring representations from un-
labeled data with co-training for Chinese word seg-
mentation. In Proceedings of the 2013 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 311–321, Seattle, Washington, USA,
October. Association for Computational Linguistics.
</reference>
<page confidence="0.997299">
267
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.852720">
<title confidence="0.999906">Synthetic Word Parsing Improves Chinese Word Segmentation</title>
<author confidence="0.997495">Fei Cheng Kevin Duh Yuji Matsumoto</author>
<affiliation confidence="0.9996905">Graduate School of Information Nara Institute of Science and</affiliation>
<address confidence="0.948921">8916-5 Takayama, Ikoma, Nara, 630-0192,</address>
<abstract confidence="0.993234266666667">We present a novel solution to improve the performance of Chinese word segmentation (CWS) using a synthetic word parser. The parser analyses the internal structure of words, and attempts to convert out-of-vocabulary words (OOVs) into in-vocabulary fine-grained sub-words. We propose a pipeline CWS system that first predicts this fine-grained segmentation, then chunks the output to reconstruct the original word segmentation standard. We achieve competitive results on the PKU and MSR datasets, with substantial improvements in OOV recall.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Fei Cheng</author>
<author>Kevin Duh</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Parsing chinese synthetic words with a characterbased dependency model.</title>
<date>2014</date>
<journal>European Language Resources Association (ELRA).</journal>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14),</booktitle>
<location>Reykjavik, Iceland,</location>
<contexts>
<context position="4626" citStr="Cheng et al. (2014)" startWordPosition="716" endWordPosition="719"> Papers), pages 262–267, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics other CRF that predicts the original word segmentation given the fine-grained segmentation as input, we can recover the fine-grained output into original word segmentation standard (Section 2.3). The flow chart of our word segmentation system is shown in Figure 1. Figure 1: The Flow Chart of the Chinese Word Segmentation System. 2 System Components 2.1 Synthetic Word Parser Intuitively, Chinese synthetic words contain internal morphological information that is helpful to recognize OOVs. Cheng et al. (2014) proposed a character-based parser to parse the internal tree structure of words. For instance, the tree and flat segmented result of the word 市 政 府 (municipal government) are shown in Figure 2. In this work, we train a graph-based parser (McDonald, 2006) on the data released by Cheng et al. (2014) and include the dictionary (NAIST Chinese Dictionary1) features and Brown clustering features extracted from a large unlabeled corpus (Chinese Gigaword Second Edition2) as described in Cheng et al. (2014). For native Chinese speakers, single character and two character words are usually treated as t</context>
<context position="7964" citStr="Cheng et al. (2014)" startWordPosition="1261" endWordPosition="1264"> 市 is the beginning part of the synthetic word 市政府 and 政府 is the ending part. In the chunking process, the frequent prefix 市 is coordinated with neighbouring units to compose the synthetic word 市政府. For each labeling, we include previous, current and next word as the features for the chunking model. Original Fine-grained Chunking tags Figure 4: A Sample Sentence of Labeling Chunking Tags. In this work, we adopt 4-tag set for chunking. ”B” denotes the beginning part of a synthetic word. ”I” denotes the middle part. ”E” denotes the end part. ”S” denotes a single word. 3 Experiments 3.1 Settings Cheng et al. (2014) released a dictionary of 31,849 synthetic words with internal structure annotated. Since transliteration words (e.g. 贝克 汉 姆 Becham) exist in Chinese, our synthetic word parser should perform well not only on synthetic words but also on transliteration words. We extracted 6,574 transliteration words from the NAIST Chinese Dictionary and automatically assigned flat structures for these words. As a result, we obtained 38,423 words as the training data for our parser. The second international Chinese word segmentation bakeoff-2005 provided two annotated simplified Chinese corpora: PKU and MSR. We</context>
</contexts>
<marker>Cheng, Duh, Matsumoto, 2014</marker>
<rawString>Fei Cheng, Kevin Duh, and Yuji Matsumoto. 2014. Parsing chinese synthetic words with a characterbased dependency model. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), Reykjavik, Iceland, may. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Emerson</author>
</authors>
<title>The second international chinese word segmentation bakeoff.</title>
<date>2005</date>
<booktitle>In Proceedings of the fourth SIGHAN workshop on Chinese language Processing,</booktitle>
<volume>133</volume>
<contexts>
<context position="10199" citStr="Emerson, 2005" startWordPosition="1620" endWordPosition="1621">sults of Zhang et al. (2013) who extracted dynamic statistical features from both in-domain and out-domain corpus and our OOV recall significantly outperforms theirs with a 9% lead. In MSR, we obtain very close OOV recall and slightly lower F-score than the state-ofthe-art system (Sun et al., 2009), which adopted a latent variable CRF model. However, our system significantly outperforms their system in PKU. In both corpora, our proposed system outperforms the best ”Bakeoff-2005” results. We also test the statistical significance of the results by using the criterion (Sproat and Emerson, 2003; Emerson, 2005). The 95% confidence interval is given as ±2�/p(1 − p)/n, where n is the number of words in the test data. They treat two systems as significantly different (at the 95% confidence level), if at least one of their precisionbased confidences ”Cp” or recall-based ”Cr” are different. As the results shown in Table 2, the baseline and proposed method are significantly different on precision and recall in both PKU and MSR corpus. In conclusion, our proposed method significantly outperforms the baseline. 3.3 Additional Experiments We conducted additional experiments to evaluate the performance of the </context>
</contexts>
<marker>Emerson, 2005</marker>
<rawString>Thomas Emerson. 2005. The second international chinese word segmentation bakeoff. In Proceedings of the fourth SIGHAN workshop on Chinese language Processing, volume 133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chooi-Ling Goh</author>
<author>Masayuki Asahara</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Machine learning-based methods to chinese unknown word detection and pos tag guessing.</title>
<date>2006</date>
<journal>Journal of Chinese Language and Computing,</journal>
<volume>16</volume>
<issue>4</issue>
<contexts>
<context position="1644" citStr="Goh et al. (2006)" startWordPosition="251" endWordPosition="254">on has progressed significantly, with state-of-the-art performing at around 96% in precision and recall (Xue, 2003; Zhang and Clark, 2007; Li and Sun, 2009). However, frequent OOVs are still a crucial issue that causes low accuracy in word segmentation. Li and Zhou (2012) defined those words that are OOVs but consisting of frequent internal parts as pseudo-OOV words and estimated that over 60% of OOVs are pseudo-OOVs in five common Chinese corpora. For instance, PKU corpus does not contain the word 陈列室 (exhibition room), even though the word 陈列 (exhibit) and 室 (room) appear hundreds of times. Goh et al. (2006) also claimed that most OOVs are proper nouns taking the form of Chinese synthetic words. These previous works suggest that by analysing the internal structure of the synthetic words, we can transform pseudo-OOVs into in-vocabulary words (IVs). By running a synthetic word parser on each of the words in a CWS training set, we can generate a fine-grained segmentation standard that contains more IVs. Since the current conditional random field (CRF) word segmenters (Tseng et al., 2005; Sun and Xu, 2011) perform well on IVs, this transforming process can conceivably improve the handling of pseudo-O</context>
</contexts>
<marker>Goh, Asahara, Matsumoto, 2006</marker>
<rawString>Chooi-Ling Goh, Masayuki Asahara, and Yuji Matsumoto. 2006. Machine learning-based methods to chinese unknown word detection and pos tag guessing. Journal of Chinese Language and Computing, 16(4):185–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongguo Li</author>
<author>Maosong Sun</author>
</authors>
<title>Punctuation as implicit annotations for chinese word segmentation.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>4</issue>
<contexts>
<context position="1183" citStr="Li and Sun, 2009" startWordPosition="172" endWordPosition="175">m that first predicts this fine-grained segmentation, then chunks the output to reconstruct the original word segmentation standard. We achieve competitive results on the PKU and MSR datasets, with substantial improvements in OOV recall. 1 Introduction Since Chinese has no spaces between words to indicate word boundaries, Chinese word segmentation is a task to determine word boundaries between characters. In recent years, research in Chinese word segmentation has progressed significantly, with state-of-the-art performing at around 96% in precision and recall (Xue, 2003; Zhang and Clark, 2007; Li and Sun, 2009). However, frequent OOVs are still a crucial issue that causes low accuracy in word segmentation. Li and Zhou (2012) defined those words that are OOVs but consisting of frequent internal parts as pseudo-OOV words and estimated that over 60% of OOVs are pseudo-OOVs in five common Chinese corpora. For instance, PKU corpus does not contain the word 陈列室 (exhibition room), even though the word 陈列 (exhibit) and 室 (room) appear hundreds of times. Goh et al. (2006) also claimed that most OOVs are proper nouns taking the form of Chinese synthetic words. These previous works suggest that by analysing th</context>
</contexts>
<marker>Li, Sun, 2009</marker>
<rawString>Zhongguo Li and Maosong Sun. 2009. Punctuation as implicit annotations for chinese word segmentation. Computational Linguistics, 35(4):505–512.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongguo Li</author>
<author>Guodong Zhou</author>
</authors>
<title>Unified dependency parsing of chinese morphological and syntactic structures.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>1445--1454</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1299" citStr="Li and Zhou (2012)" startWordPosition="191" endWordPosition="194">ntation standard. We achieve competitive results on the PKU and MSR datasets, with substantial improvements in OOV recall. 1 Introduction Since Chinese has no spaces between words to indicate word boundaries, Chinese word segmentation is a task to determine word boundaries between characters. In recent years, research in Chinese word segmentation has progressed significantly, with state-of-the-art performing at around 96% in precision and recall (Xue, 2003; Zhang and Clark, 2007; Li and Sun, 2009). However, frequent OOVs are still a crucial issue that causes low accuracy in word segmentation. Li and Zhou (2012) defined those words that are OOVs but consisting of frequent internal parts as pseudo-OOV words and estimated that over 60% of OOVs are pseudo-OOVs in five common Chinese corpora. For instance, PKU corpus does not contain the word 陈列室 (exhibition room), even though the word 陈列 (exhibit) and 室 (room) appear hundreds of times. Goh et al. (2006) also claimed that most OOVs are proper nouns taking the form of Chinese synthetic words. These previous works suggest that by analysing the internal structure of the synthetic words, we can transform pseudo-OOVs into in-vocabulary words (IVs). By running</context>
</contexts>
<marker>Li, Zhou, 2012</marker>
<rawString>Zhongguo Li and Guodong Zhou. 2012. Unified dependency parsing of chinese morphological and syntactic structures. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1445–1454. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
</authors>
<title>Discriminative learning and spanning tree algorithms for dependency parsing.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>PhD Thesis. University of Pennsylvania.</institution>
<contexts>
<context position="4881" citStr="McDonald, 2006" startWordPosition="762" endWordPosition="763">al word segmentation standard (Section 2.3). The flow chart of our word segmentation system is shown in Figure 1. Figure 1: The Flow Chart of the Chinese Word Segmentation System. 2 System Components 2.1 Synthetic Word Parser Intuitively, Chinese synthetic words contain internal morphological information that is helpful to recognize OOVs. Cheng et al. (2014) proposed a character-based parser to parse the internal tree structure of words. For instance, the tree and flat segmented result of the word 市 政 府 (municipal government) are shown in Figure 2. In this work, we train a graph-based parser (McDonald, 2006) on the data released by Cheng et al. (2014) and include the dictionary (NAIST Chinese Dictionary1) features and Brown clustering features extracted from a large unlabeled corpus (Chinese Gigaword Second Edition2) as described in Cheng et al. (2014). For native Chinese speakers, single character and two character words are usually treated as the 1http://cl.naist.jp/index.php?%B8%F8%B3%AB%A5%E A%A5%BD%A1%BC%A5%B9%2FNCD 2https://catalog.ldc.upenn.edu/LDC2005T14 smallest units. In this work, we parse all the words in the PKU and MSR training data with character length greater than two. By replaci</context>
</contexts>
<marker>McDonald, 2006</marker>
<rawString>Ryan McDonald. 2006. Discriminative learning and spanning tree algorithms for dependency parsing. Ph.D. thesis, PhD Thesis. University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sproat</author>
<author>Thomas Emerson</author>
</authors>
<title>The first international chinese word segmentation bakeoff.</title>
<date>2003</date>
<booktitle>In Proceedings of the second SIGHAN workshop on Chinese language processing-Volume 17,</booktitle>
<pages>133--143</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10183" citStr="Sproat and Emerson, 2003" startWordPosition="1615" endWordPosition="1619">fthe-art F-score as the results of Zhang et al. (2013) who extracted dynamic statistical features from both in-domain and out-domain corpus and our OOV recall significantly outperforms theirs with a 9% lead. In MSR, we obtain very close OOV recall and slightly lower F-score than the state-ofthe-art system (Sun et al., 2009), which adopted a latent variable CRF model. However, our system significantly outperforms their system in PKU. In both corpora, our proposed system outperforms the best ”Bakeoff-2005” results. We also test the statistical significance of the results by using the criterion (Sproat and Emerson, 2003; Emerson, 2005). The 95% confidence interval is given as ±2�/p(1 − p)/n, where n is the number of words in the test data. They treat two systems as significantly different (at the 95% confidence level), if at least one of their precisionbased confidences ”Cp” or recall-based ”Cr” are different. As the results shown in Table 2, the baseline and proposed method are significantly different on precision and recall in both PKU and MSR corpus. In conclusion, our proposed method significantly outperforms the baseline. 3.3 Additional Experiments We conducted additional experiments to evaluate the per</context>
</contexts>
<marker>Sproat, Emerson, 2003</marker>
<rawString>Richard Sproat and Thomas Emerson. 2003. The first international chinese word segmentation bakeoff. In Proceedings of the second SIGHAN workshop on Chinese language processing-Volume 17, pages 133–143. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Sun</author>
<author>Jia Xu</author>
</authors>
<title>Enhancing chinese word segmentation using unlabeled data.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>970--979</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2148" citStr="Sun and Xu, 2011" startWordPosition="332" endWordPosition="335">陈列室 (exhibition room), even though the word 陈列 (exhibit) and 室 (room) appear hundreds of times. Goh et al. (2006) also claimed that most OOVs are proper nouns taking the form of Chinese synthetic words. These previous works suggest that by analysing the internal structure of the synthetic words, we can transform pseudo-OOVs into in-vocabulary words (IVs). By running a synthetic word parser on each of the words in a CWS training set, we can generate a fine-grained segmentation standard that contains more IVs. Since the current conditional random field (CRF) word segmenters (Tseng et al., 2005; Sun and Xu, 2011) perform well on IVs, this transforming process can conceivably improve the handling of pseudo-OOV words, as long as we can recover the original word segmentation standard from the fine-grained sub-word segmentation. In recent years, some related works about improving OOV problem in CWS have been ongoing. Sun et al. (2012) presented a joint model for Chinese word segmentation and OOVs detection. Their models achieved fast training speed, high accuracies and increase on OOV recall. Sun (2011) proposed a similar sub-word structure which is generated by merging the segmentations provided by diffe</context>
<context position="6548" citStr="Sun and Xu (2011)" startWordPosition="1024" endWordPosition="1027">his work, we adopt 4-tag set for word segmentation. ”B” denotes the beginning character of a word. ”I” denotes the middle character of a word. ”E” denotes the end character of a word. ”S” denotes a single character word. 2.2 CRF-based Word Segmenter Xue et al. (2003) proposed a method which treated Chinese word segmentation as a character-based sequential labeling problem and exploited several discriminative learning algorithms. Tseng et al. (2005) adopted the CRFs as the learning method and obtained the best results in the second international Chinese word segmentation bakeoff2005. Moreover, Sun and Xu (2011) attempted to extract information from large unlabeled data to enhance the Chinese word segmentation results. In this work, we train a traditional CRF-based supervised model on the fine-grained training data, include the dictionary (NAIST Chinese Dictionary) features and access variety features extracted from a large unlabeled corpus (Chinese Gigaword Second Edition) as described in Sun and Xu (2011). 263 2.3 CRF-based Chunking Model In order to obtain the word segmentation result with original word segmentation standard, we train a CRF-based chunking model on the original and fine-grained tra</context>
</contexts>
<marker>Sun, Xu, 2011</marker>
<rawString>Weiwei Sun and Jia Xu. 2011. Enhancing chinese word segmentation using unlabeled data. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 970–979. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xu Sun</author>
<author>Yaozhong Zhang</author>
<author>Takuya Matsuzaki</author>
<author>Yoshimasa Tsuruoka</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>A discriminative latent variable chinese segmenter with hybrid word/character information.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>56--64</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9884" citStr="Sun et al., 2009" startWordPosition="1571" endWordPosition="1574">822 on PKU and 0.682 to 0.717 on MSR. We also evaluated the pseudoOOV recall and observed 4% increases from the baseline to the proposed system. Our proposed system achieves higher F-score with 0.961 on PKU and 0.971 on MSR. Comparing to other systems, our proposed method obtains the state-ofthe-art F-score as the results of Zhang et al. (2013) who extracted dynamic statistical features from both in-domain and out-domain corpus and our OOV recall significantly outperforms theirs with a 9% lead. In MSR, we obtain very close OOV recall and slightly lower F-score than the state-ofthe-art system (Sun et al., 2009), which adopted a latent variable CRF model. However, our system significantly outperforms their system in PKU. In both corpora, our proposed system outperforms the best ”Bakeoff-2005” results. We also test the statistical significance of the results by using the criterion (Sproat and Emerson, 2003; Emerson, 2005). The 95% confidence interval is given as ±2�/p(1 − p)/n, where n is the number of words in the test data. They treat two systems as significantly different (at the 95% confidence level), if at least one of their precisionbased confidences ”Cp” or recall-based ”Cr” are different. As t</context>
<context position="11469" citStr="Sun et al. (2009)" startWordPosition="1845" endWordPosition="1848">irst, we are interested in how much parsing accuracy is needed for good results. Figure 5 displays the OOV recall results of our word segmentation system when the synthetic word parser is trained with amounts of labeled synthetic words data. As the data size increases, our word segmen市政府 / 办&amp;T / 4 / *4A 市 / 政府 / 办&amp; / T / 4 / *4A B/E/B/E/S/S 264 System PKU MSR P R F Roov Rpseudo P R F Roov Rpseudo Baseline 0.957 0.960 0.959 0.792 0.797 0.971 0.968 0.970 0.682 0.689 Proposed method 0.960 0.962 0.961 0.822 0.838 0.972 0.970 0.971 0.717 0.73 Zhang et al. (2013) 0.965 0.958 0.961 0.731 - - - - - - Sun et al. (2009) 0.956 0.948 0.952 0.778 - 0.973 0.973 0.973 0.722 - Bakeoff-2005 0.953 0.946 0.950 0.636 - 0.962 0.966 0.964 0.717 - Table 1: Comparison of the Proposed Method to the Baseline and Previous works on PKU and MSR Corpora. Here, ”Rpseudo” denotes the recall of pseudo-OOV words. ”Bakeoff-2005” denotes the best results of the second international Chinese word segmentation bakeoff-2005 on two corpora. Since we use extra resources and our proposed method replies on the synthetic word parser trained on an dictionary with internal structure annotated, the results cannot be directly compared with the st</context>
</contexts>
<marker>Sun, Zhang, Matsuzaki, Tsuruoka, Tsujii, 2009</marker>
<rawString>Xu Sun, Yaozhong Zhang, Takuya Matsuzaki, Yoshimasa Tsuruoka, and Jun’ichi Tsujii. 2009. A discriminative latent variable chinese segmenter with hybrid word/character information. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 56–64. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xu Sun</author>
<author>Houfeng Wang</author>
<author>Wenjie Li</author>
</authors>
<title>Fast online training with frequency-adaptive learning rates for chinese word segmentation and new word detection.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1,</booktitle>
<pages>253--262</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2472" citStr="Sun et al. (2012)" startWordPosition="384" endWordPosition="387">s into in-vocabulary words (IVs). By running a synthetic word parser on each of the words in a CWS training set, we can generate a fine-grained segmentation standard that contains more IVs. Since the current conditional random field (CRF) word segmenters (Tseng et al., 2005; Sun and Xu, 2011) perform well on IVs, this transforming process can conceivably improve the handling of pseudo-OOV words, as long as we can recover the original word segmentation standard from the fine-grained sub-word segmentation. In recent years, some related works about improving OOV problem in CWS have been ongoing. Sun et al. (2012) presented a joint model for Chinese word segmentation and OOVs detection. Their models achieved fast training speed, high accuracies and increase on OOV recall. Sun (2011) proposed a similar sub-word structure which is generated by merging the segmentations provided by different segmenters (a word-based segmenter, a character-based segmenter and a local character classifier). However, her models does not predict the sub-words of all the synthetic words, but those words with different segmented results of the three segmenters. Her work maximizes the agreement of different models to improve CWS</context>
</contexts>
<marker>Sun, Wang, Li, 2012</marker>
<rawString>Xu Sun, Houfeng Wang, and Wenjie Li. 2012. Fast online training with frequency-adaptive learning rates for chinese word segmentation and new word detection. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 253–262. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Sun</author>
</authors>
<title>A stacked sub-word model for joint chinese word segmentation and part-ofspeech tagging.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>1385--1394</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2644" citStr="Sun (2011)" startWordPosition="413" endWordPosition="414"> more IVs. Since the current conditional random field (CRF) word segmenters (Tseng et al., 2005; Sun and Xu, 2011) perform well on IVs, this transforming process can conceivably improve the handling of pseudo-OOV words, as long as we can recover the original word segmentation standard from the fine-grained sub-word segmentation. In recent years, some related works about improving OOV problem in CWS have been ongoing. Sun et al. (2012) presented a joint model for Chinese word segmentation and OOVs detection. Their models achieved fast training speed, high accuracies and increase on OOV recall. Sun (2011) proposed a similar sub-word structure which is generated by merging the segmentations provided by different segmenters (a word-based segmenter, a character-based segmenter and a local character classifier). However, her models does not predict the sub-words of all the synthetic words, but those words with different segmented results of the three segmenters. Her work maximizes the agreement of different models to improve CWS performance. Different from her work, we aim to provide an unified way to incorporate morphological information of the synthetic words into the CWS task. In this paper, we</context>
</contexts>
<marker>Sun, 2011</marker>
<rawString>Weiwei Sun. 2011. A stacked sub-word model for joint chinese word segmentation and part-ofspeech tagging. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 1385–1394. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huihsin Tseng</author>
<author>Pichuan Chang</author>
<author>Galen Andrew</author>
<author>Daniel Jurafsky</author>
<author>Christopher Manning</author>
</authors>
<title>A conditional random field word segmenter for sighan bakeoff</title>
<date>2005</date>
<booktitle>In Proceedings of the fourth SIGHAN workshop on Chinese language Processing,</booktitle>
<volume>171</volume>
<contexts>
<context position="2129" citStr="Tseng et al., 2005" startWordPosition="328" endWordPosition="331">ot contain the word 陈列室 (exhibition room), even though the word 陈列 (exhibit) and 室 (room) appear hundreds of times. Goh et al. (2006) also claimed that most OOVs are proper nouns taking the form of Chinese synthetic words. These previous works suggest that by analysing the internal structure of the synthetic words, we can transform pseudo-OOVs into in-vocabulary words (IVs). By running a synthetic word parser on each of the words in a CWS training set, we can generate a fine-grained segmentation standard that contains more IVs. Since the current conditional random field (CRF) word segmenters (Tseng et al., 2005; Sun and Xu, 2011) perform well on IVs, this transforming process can conceivably improve the handling of pseudo-OOV words, as long as we can recover the original word segmentation standard from the fine-grained sub-word segmentation. In recent years, some related works about improving OOV problem in CWS have been ongoing. Sun et al. (2012) presented a joint model for Chinese word segmentation and OOVs detection. Their models achieved fast training speed, high accuracies and increase on OOV recall. Sun (2011) proposed a similar sub-word structure which is generated by merging the segmentation</context>
<context position="6383" citStr="Tseng et al. (2005)" startWordPosition="998" endWordPosition="1001"> 市 / 政府 / 办公 / 厅 / 等 / 单位 CWS tags S/BE/BE/S/S/BE Figure 3: A Sample Sentence of Labeling Chinese word segmentation tags on the Original and Finegrained Standard. In this work, we adopt 4-tag set for word segmentation. ”B” denotes the beginning character of a word. ”I” denotes the middle character of a word. ”E” denotes the end character of a word. ”S” denotes a single character word. 2.2 CRF-based Word Segmenter Xue et al. (2003) proposed a method which treated Chinese word segmentation as a character-based sequential labeling problem and exploited several discriminative learning algorithms. Tseng et al. (2005) adopted the CRFs as the learning method and obtained the best results in the second international Chinese word segmentation bakeoff2005. Moreover, Sun and Xu (2011) attempted to extract information from large unlabeled data to enhance the Chinese word segmentation results. In this work, we train a traditional CRF-based supervised model on the fine-grained training data, include the dictionary (NAIST Chinese Dictionary) features and access variety features extracted from a large unlabeled corpus (Chinese Gigaword Second Edition) as described in Sun and Xu (2011). 263 2.3 CRF-based Chunking Mod</context>
</contexts>
<marker>Tseng, Chang, Andrew, Jurafsky, Manning, 2005</marker>
<rawString>Huihsin Tseng, Pichuan Chang, Galen Andrew, Daniel Jurafsky, and Christopher Manning. 2005. A conditional random field word segmenter for sighan bakeoff 2005. In Proceedings of the fourth SIGHAN workshop on Chinese language Processing, volume 171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Chinese word segmentation as character tagging.</title>
<date>2003</date>
<booktitle>Computational Linguistics and Chinese Language Processing,</booktitle>
<volume>8</volume>
<issue>1</issue>
<contexts>
<context position="1141" citStr="Xue, 2003" startWordPosition="166" endWordPosition="167">s. We propose a pipeline CWS system that first predicts this fine-grained segmentation, then chunks the output to reconstruct the original word segmentation standard. We achieve competitive results on the PKU and MSR datasets, with substantial improvements in OOV recall. 1 Introduction Since Chinese has no spaces between words to indicate word boundaries, Chinese word segmentation is a task to determine word boundaries between characters. In recent years, research in Chinese word segmentation has progressed significantly, with state-of-the-art performing at around 96% in precision and recall (Xue, 2003; Zhang and Clark, 2007; Li and Sun, 2009). However, frequent OOVs are still a crucial issue that causes low accuracy in word segmentation. Li and Zhou (2012) defined those words that are OOVs but consisting of frequent internal parts as pseudo-OOV words and estimated that over 60% of OOVs are pseudo-OOVs in five common Chinese corpora. For instance, PKU corpus does not contain the word 陈列室 (exhibition room), even though the word 陈列 (exhibit) and 室 (room) appear hundreds of times. Goh et al. (2006) also claimed that most OOVs are proper nouns taking the form of Chinese synthetic words. These p</context>
</contexts>
<marker>Xue, 2003</marker>
<rawString>Nianwen Xue. 2003. Chinese word segmentation as character tagging. Computational Linguistics and Chinese Language Processing, 8(1):29–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>Chinese segmentation with a word-based perceptron algorithm.</title>
<date>2007</date>
<booktitle>In ANNUAL MEETING-ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,</booktitle>
<volume>45</volume>
<pages>840</pages>
<contexts>
<context position="1164" citStr="Zhang and Clark, 2007" startWordPosition="168" endWordPosition="171">se a pipeline CWS system that first predicts this fine-grained segmentation, then chunks the output to reconstruct the original word segmentation standard. We achieve competitive results on the PKU and MSR datasets, with substantial improvements in OOV recall. 1 Introduction Since Chinese has no spaces between words to indicate word boundaries, Chinese word segmentation is a task to determine word boundaries between characters. In recent years, research in Chinese word segmentation has progressed significantly, with state-of-the-art performing at around 96% in precision and recall (Xue, 2003; Zhang and Clark, 2007; Li and Sun, 2009). However, frequent OOVs are still a crucial issue that causes low accuracy in word segmentation. Li and Zhou (2012) defined those words that are OOVs but consisting of frequent internal parts as pseudo-OOV words and estimated that over 60% of OOVs are pseudo-OOVs in five common Chinese corpora. For instance, PKU corpus does not contain the word 陈列室 (exhibition room), even though the word 陈列 (exhibit) and 室 (room) appear hundreds of times. Goh et al. (2006) also claimed that most OOVs are proper nouns taking the form of Chinese synthetic words. These previous works suggest t</context>
</contexts>
<marker>Zhang, Clark, 2007</marker>
<rawString>Yue Zhang and Stephen Clark. 2007. Chinese segmentation with a word-based perceptron algorithm. In ANNUAL MEETING-ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, volume 45, page 840.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Longkai Zhang</author>
<author>Houfeng Wang</author>
<author>Xu Sun</author>
<author>Mairgup Mansur</author>
</authors>
<title>Exploring representations from unlabeled data with co-training for Chinese word segmentation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>311--321</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="9613" citStr="Zhang et al. (2013)" startWordPosition="1528" endWordPosition="1531">training a CRF word segmenter on the original PKU and MSR data sets with the same features. Our proposed system is expected to improve the word segmentation performance on pseudo-OOVs. Compared to the baseline, there are significant increases on OOV recall from 0.792 to 0.822 on PKU and 0.682 to 0.717 on MSR. We also evaluated the pseudoOOV recall and observed 4% increases from the baseline to the proposed system. Our proposed system achieves higher F-score with 0.961 on PKU and 0.971 on MSR. Comparing to other systems, our proposed method obtains the state-ofthe-art F-score as the results of Zhang et al. (2013) who extracted dynamic statistical features from both in-domain and out-domain corpus and our OOV recall significantly outperforms theirs with a 9% lead. In MSR, we obtain very close OOV recall and slightly lower F-score than the state-ofthe-art system (Sun et al., 2009), which adopted a latent variable CRF model. However, our system significantly outperforms their system in PKU. In both corpora, our proposed system outperforms the best ”Bakeoff-2005” results. We also test the statistical significance of the results by using the criterion (Sproat and Emerson, 2003; Emerson, 2005). The 95% conf</context>
<context position="11415" citStr="Zhang et al. (2013)" startWordPosition="1831" endWordPosition="1834">he synthetic word parser and CRF-based chunking model. First, we are interested in how much parsing accuracy is needed for good results. Figure 5 displays the OOV recall results of our word segmentation system when the synthetic word parser is trained with amounts of labeled synthetic words data. As the data size increases, our word segmen市政府 / 办&amp;T / 4 / *4A 市 / 政府 / 办&amp; / T / 4 / *4A B/E/B/E/S/S 264 System PKU MSR P R F Roov Rpseudo P R F Roov Rpseudo Baseline 0.957 0.960 0.959 0.792 0.797 0.971 0.968 0.970 0.682 0.689 Proposed method 0.960 0.962 0.961 0.822 0.838 0.972 0.970 0.971 0.717 0.73 Zhang et al. (2013) 0.965 0.958 0.961 0.731 - - - - - - Sun et al. (2009) 0.956 0.948 0.952 0.778 - 0.973 0.973 0.973 0.722 - Bakeoff-2005 0.953 0.946 0.950 0.636 - 0.962 0.966 0.964 0.717 - Table 1: Comparison of the Proposed Method to the Baseline and Previous works on PKU and MSR Corpora. Here, ”Rpseudo” denotes the recall of pseudo-OOV words. ”Bakeoff-2005” denotes the best results of the second international Chinese word segmentation bakeoff-2005 on two corpora. Since we use extra resources and our proposed method replies on the synthetic word parser trained on an dictionary with internal structure annotate</context>
</contexts>
<marker>Zhang, Wang, Sun, Mansur, 2013</marker>
<rawString>Longkai Zhang, Houfeng Wang, Xu Sun, and Mairgup Mansur. 2013. Exploring representations from unlabeled data with co-training for Chinese word segmentation. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 311–321, Seattle, Washington, USA, October. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>