<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.593226">
Structured Lexical Similarity via Convolution Kernels on Dependency Trees
Danilo Croce
DII
</note>
<affiliation confidence="0.856361">
University of Tor Vergata
</affiliation>
<address confidence="0.659512">
00133 Roma, Italy
</address>
<email confidence="0.990343">
croce@info.uniroma2.it
</email>
<author confidence="0.624078">
Alessandro Moschitti
</author>
<affiliation confidence="0.7375625">
DISI
University of Trento
</affiliation>
<address confidence="0.737602">
38123 Povo (TN), Italy
</address>
<email confidence="0.996739">
moschitti@disi.unitn.it
</email>
<author confidence="0.571945">
Roberto Basili
</author>
<affiliation confidence="0.6790705">
DII
University of Tor Vergata
</affiliation>
<address confidence="0.657515">
00133 Roma, Italy
</address>
<email confidence="0.994889">
basili@info.uniroma2.it
</email>
<sectionHeader confidence="0.994666" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999023125">
A central topic in natural language process-
ing is the design of lexical and syntactic fea-
tures suitable for the target application. In this
paper, we study convolution dependency tree
kernels for automatic engineering of syntactic
and semantic patterns exploiting lexical simi-
larities. We define efficient and powerful ker-
nels for measuring the similarity between de-
pendency structures, whose surface forms of
the lexical nodes are in part or completely dif-
ferent. The experiments with such kernels for
question classification show an unprecedented
results, e.g. 41% of error reduction of the for-
mer state-of-the-art. Additionally, semantic
role classification confirms the benefit of se-
mantic smoothing for dependency kernels.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999953867924528">
A central topic in Natural Language Processing is
the design of lexical and syntactic features suitable
for the target application. The selection of effective
patterns composed of syntactic dependencies and
lexical constraints is typically a complex task.
Additionally, the availability of training data is
usually scarce. This requires the development of
generalized features or the definition of seman-
tic similarities between them, e.g. as proposed in
(Resnik, 1995; Jiang and Conrath, 1997; Schtze,
1998; Pedersen et al., 2004a; Bloehdorn and Mos-
chitti, 2007b; Davis et al., 2007) or in semi-
supervised settings, e.g. (Chapelle et al., 2006).
A semantic similarity can be defined at structural
level over a graph, e.g. (Freeman, 1977; Bunke and
Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as
well as combining structural and lexical similarity
over semantic networks, e.g. (Cowie et al., 1992; Wu
and Palmer, 1994; Resnik, 1995; Jiang and Conrath,
1997; Schtze, 1998; Leacock and Chodorow, 1998;
Pedersen et al., 2004a; Budanitsky and Hirst, 2006).
More recent research also focuses on mechanisms
to define if two structures, e.g. graphs, are enough
similar, as explored in (Mihalcea, 2005; Zhao et al.,
2009; F¨urstenau and Lapata, 2009; Navigli and La-
pata, 2010).
On one hand, previous work shows that there is
a substantial lack of automatic methods for engi-
neering lexical/syntactic features (or more in gen-
eral syntactic/semantic similarity). On the other
hand, automatic feature engineering of syntactic or
shallow semantic structures has been carried out
by means of structural kernels, e.g. (Collins and
Duffy, 2002; Kudo and Matsumoto, 2003; Cumby
and Roth, 2003; Cancedda et al., 2003; Daum´e III
and Marcu, 2004; Toutanova et al., 2004; Shen et al.,
2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov
and Henderson, 2006; Zelenko et al., 2002; Bunescu
and Mooney, 2005; Zhang et al., 2006). The main
idea of structural kernels is to generate structures
that in turn represent syntactic or shallow semantic
features. Most notably, the work in (Bloehdorn and
Moschitti, 2007b) encodes lexical similarity in such
kernels. This is essentially the syntactic tree ker-
nel (STK) proposed in (Collins and Duffy, 2002) in
which syntactic fragments from constituency trees
can be matched even if they only differ in the leaf
nodes (i.e. they have different surface forms). This
implies matching scores lower than 1, depending on
the semantic similarity of the corresponding leaves
in the syntactic fragments.
Although this kernel achieves state-of-the-art per-
formance in NLP tasks, such as Question Classifica-
</bodyText>
<page confidence="0.967753">
1034
</page>
<note confidence="0.957837">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1034–1046,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999389224489796">
tion (Bloehdorn and Moschitti, 2007b) and Textual trees. Section 5 presents the experimental evaluation
Entailment (Mehdad et al., 2010), it offers clearly for QC and SRL. Section 6 derives the conclusions.
possibility of improvement: (i) better possibility to 2 Kernel Background
exploit semantic smoothing since, e.g., trivially STK In kernel-based machines, both learning and classi-
only matches the syntactic structure apple/orange fication algorithms only depend on the inner prod-
when comparing the big beautiful apple to a nice uct between instances. This in several cases can be
large orange; and (ii) STK cannot be effectively ap- efficiently and implicitly computed by kernel func-
plied to dependency structures, e.g. see experiments tions by exploiting the following dual formulation:
and motivation in (Moschitti, 2006a). Additionally, P
to our knowledge, there is no previous study that i=1..lyiαiφ(oi)φ(o) + b = 0, where oi and o are
clearly describes how dependency structures should two objects, φ is a mapping from the objects to fea-
be converted in trees to be fully and effectively ex- ture vectors ~xi and φ(oi)φ(o) = K(oi, o) is a ker-
ploitable by convolution kernels. Indeed, although nel function implicitly defining such mapping. In
the work in (Culotta and Sorensen, 2004) defines a case of structural kernels, K determines the shape of
dependency tree also using node similarity, it is not the substructures describing the objects above. The
a convolution kernel: this results in a much poorer most general kind of kernels used in NLP are string
feature space. kernels, e.g. (Shawe-Taylor and Cristianini, 2004),
In this paper, we propose a study of convolution the Syntactic Tree Kernels (Collins and Duffy, 2002)
kernels for dependency structures aiming at jointly and the Partial Tree Kernels (Moschitti, 2006a).
modeling syntactic and lexical semantic similarity. 2.1 String Kernels
More precisely, we define several dependency trees The String Kernels (SK) that we consider count
exploitable by the Partial Tree Kernel (PTK) (Mos- the number of subsequences shared by two strings
chitti, 2006a) and compared them with STK over of symbols, s1 and s2. Some symbols during the
constituency trees. Most importantly, we define matching process can be skipped. This modifies
an innovative and efficient class of kernels, i.e. the the weight associated with the target substrings as
Smoothed Partial Tree Kernels (SPTKs), which can shown by the following SK equation:
measure the similarity of structural similar trees XSK(s1, s2) = φu(s1) - φu(s2) =
whose nodes are associated with different but re- uEE*
lated lexicals. Given the convolution nature of such X X X λd(�I1)+d(�I2)
kernels any possible node path of lexicals provide uEE* �I1:u=s1[�I1] �I2:u=s2[�I2]
a contribution smoothed by the similarity accounted where, E∗ = S∞n=0 En is the set of all strings, ~I1 and
by its nodes. ~I2 are two sequences of indexes I~ = (i1, ..., i|u|),
The extensive experimentation on two datasets of with 1 &lt; i1 &lt; ... &lt; i|u |&lt; |s|, such that u = si1..si|u|,
question classification (QC) and semantic role label- d(~I) = i|u |− i1 + 1 (distance between the first and
ing (SRL), shows that: (i) PTK applied to our depen- last character) and λ E [0, 1] is a decay factor.
dency trees outperforms STK, demonstrating that It is worth noting that: (a) longer subsequences
dependency parsers are fully exploitable for feature receive lower weights; (b) some characters can be
engineering based on structural kernels; (ii) SPTK omitted, i.e. gaps; (c) gaps determine a weight since
outperforms any previous kernels achieving an un- the exponent of λ is the number of characters and
precedented result of 41% of error reduction with re- gaps between the first and last character; and (c)
spect to the former state-of-the-art on QC; and (iii) the complexity of the SK computation is O(mnp)
the experiments on SRL confirm that the approach (Shawe-Taylor and Cristianini, 2004), where m and
can be applied to different tasks without any tuning n are the lengths of the two strings, respectively and
and again achieving state-of-the-art accuracy. p is the length of the largest subsequence we want to
In the reminder of this paper, Section 2 provides consider.
the background for structural and lexical similar-
ity kernels. Section 3 introduces SPTK. Section 4
provides our representation models for dependency
1035
</bodyText>
<subsectionHeader confidence="0.998684">
2.2 Tree Kernels
</subsectionHeader>
<bodyText confidence="0.990935625">
Convolution Tree Kernels compute the number
of common substructures between two trees T1
and T2 without explicitly considering the whole
fragment space. For this purpose, let the set
T = {f1, f2, ... , f|F|} be a tree fragment space and
Xi(n) be an indicator function, equal to 1 if the
target fi is rooted at node n and equal to 0 oth-
erwise. A tree-kernel function over T1 and T2 is
</bodyText>
<equation confidence="0.9447262">
TK(T1,T2) = � �n2∈NT2 O(n1,n2), NT1
n1∈NT1
and NT2 are the sets of the T1’s and T2’s nodes,
respectively and O(n1, n2) = E|F|
i=1 Xi(n1)Xi(n2).
</equation>
<bodyText confidence="0.9952726">
The latter is equal to the number of common frag-
ments rooted in the n1 and n2 nodes. The O func-
tion determines the richness of the kernel space and
thus different tree kernels. Hereafter, we consider
the equation to evaluate STK and PTK 1.
</bodyText>
<subsectionHeader confidence="0.737357">
2.2.1 Syntactic Tree Kernels (STK)
</subsectionHeader>
<bodyText confidence="0.999107">
To compute STK is enough to compute
OSTK(n1, n2) as follows (recalling that since
it is a syntactic tree kernels, each node can be
associated with a production rule): (i) if the
productions at n1 and n2 are different then
OSTK(n1, n2) = 0; (ii) if the productions at
n1 and n2 are the same, and n1 and n2 have
only leaf children then OSTK(n1,n2) = A; and
(iii) if the productions at n1 and n2 are the
same, and n1 and n2 are not pre-terminals then
</bodyText>
<equation confidence="0.9999515">
OSTK(n1,n2) = A�l(n1)
j=1 (1 + OSTK(cjn1,cjn2)),
</equation>
<bodyText confidence="0.996796428571429">
where l(n1) is the number of children of n1 and cjn
is the j-th child of the node n. Note that, since the
productions are the same, l(n1) = l(n2) and the
computational complexity of STK is O(|NT1||NT2|)
but the average running time tends to be linear,
i.e. O(|NT1|+|NT2|), for natural language syntactic
trees (Moschitti, 2006a).
</bodyText>
<subsubsectionHeader confidence="0.50272">
2.2.2 The Partial Tree Kernel (PTK)
</subsubsectionHeader>
<bodyText confidence="0.99827">
The computation of PTK is carried out by the
following OPTK function: if the labels of n1
and n2 are different then OPTK(n1,n2) = 0; else
</bodyText>
<equation confidence="0.8343505">
OPTK(n1, n2) =
IOP T K(cn1(�I1j), cn2(�I2j))
</equation>
<footnote confidence="0.700002">
1To have a similarity score between 0 and 1, a normalization
in the kernel space, i.e. T K(T1 ,T2) is applied.
</footnote>
<equation confidence="0.893588">
√T K (T1 ,T1) × T K (T2 ,T2 )
</equation>
<bodyText confidence="0.995925846153846">
where d(I1) = I1l(~I1)− �I11+1 and d( �I2) = �I2l(~I2)−
I21 + 1. This way, we penalize both larger trees and
child subsequences with gaps. PTK is more general
than the STK as if we only consider the contribu-
tion of shared subsequences containing all children
of nodes, we implement the STK kernel. The com-
putational complexity of PTK is O(pρ2|NT1||NT2|)
(Moschitti, 2006a), where p is the largest subse-
quence of children that we want consider and ρ is the
maximal outdegree observed in the two trees. How-
ever the average running time again tends to be lin-
ear for natural language syntactic trees (Moschitti,
2006a).
</bodyText>
<subsectionHeader confidence="0.998905">
2.3 Lexical Semantic Kernel
</subsectionHeader>
<bodyText confidence="0.999179333333333">
Given two text fragments d1 and d2 E D (the text
fragment set), a general lexical kernel (Basili et al.,
2005) defines their similarity as:
</bodyText>
<equation confidence="0.998883">
K(d1, d2) = � (ω1ω2) X Q(w1, w2) (1)
w1∈d1,w2∈d2
</equation>
<bodyText confidence="0.974979482758621">
where ω1 and ω2 are the weights of the words (fea-
tures) w1 and w2 in the documents d1 and d2, re-
spectively, and Q is a term similarity function, e.g.
(Pedersen et al., 2004b; Sahlgren, 2006; Corley and
Mihalcea, 2005; Mihalcea et al., 2005). Technically,
any Q can be used, provided that the resulting Gram
matrix, G = K(d1, d2) bd1, d2 E D is positive
semi-definite (Shawe-Taylor and Cristianini, 2004)
(D is typically the training text set).
We determine the term similarity function through
distributional analysis (Pado and Lapata, 2007), ac-
cording to the idea that the meaning of a word can
be described by the set of textual contexts in which it
appears (Distributional Hypothesis, (Harris, 1964)).
The contexts are words appearing in a n-window
with target words: such a space models a generic
notion of semantic relatedness, i.e. two words
close in the space are likely to be either in paradig-
matic or syntagmatic relation as in (Sahlgren, 2006).
The original word-by-word context matrix M is de-
composed through Singular Value Decomposition
(SVD) (Golub and Kahan, 1965) into the product
of three new matrices: U, 5, and V so that 5 is di-
agonal and M = U5V T. M is approximated by
Ml = Ul5lV T
l in which only the first l columns of
U and V are used, and only the first l greatest singu-
lar values are considered. This approximation sup-
plies a way to project a generic term wi into the l-
</bodyText>
<equation confidence="0.9930645">
µ (A2 _+ E _
I1,I2,l(�I1)=l(I2)
Ad(�I1)+d(�I2)
l( �I1)
H
j=1
</equation>
<page confidence="0.913589">
1036
</page>
<bodyText confidence="0.993553176470588">
dimensional space using W = UlS1/2
l , where each
row corresponds to the representation vectors ~wi.
Therefore, given two words w1 and w2, the term
similarity function σ is estimated as the cosine simi-
larity between the corresponding projections ~w1, ~w2,
11 ~w11111 ~w211. The latent semantic ker-
nels (Siolas and d’Alch Buc, 2000; Cristianini et al.,
2001) derive G by applying LSA, resulting in a valid
kernel.
Another methods to design a valid kernel is to rep-
resent words as word vectors and compute σ as their
scalar product between such vectors. For example,
in (Bloehdorn et al., 2006), bag of hyponyms and
hypernyms (up to a certain level of WordNet hierar-
chy) were used to build such vectors. We will refer
to such similarity as WL (word list).
</bodyText>
<sectionHeader confidence="0.951081" genericHeader="method">
3 Smoothing Partial Tree Kernel (SPTK)
</sectionHeader>
<bodyText confidence="0.999932555555555">
Combining lexical and structural kernels provides
clear advantages on all-vs-all words similarity,
which tends to semantically diverge. Indeed syn-
tax provides the necessary restrictions to com-
pute an effective semantic similarity. Following
this idea, Bloedhorn &amp; Moschitti (2007a) mod-
ified step (i) of ASTK computation as follows:
(i) if n1 and n2 are pre-terminal nodes with
the same number of children, ASTK(n1, n2) =
</bodyText>
<equation confidence="0.6110695">
λ llnc(n1)
j=1 σ(lex(n1), lex(n2)), where lex returns
</equation>
<bodyText confidence="0.999983090909091">
the node label. This allows to match fragments hav-
ing same structure but different leaves by assigning a
score proportional to the product of the lexical sim-
ilarities of each leaf pair. Although it is an inter-
esting kernel, the fact that lexicals must belong to
the leaf nodes of exactly the same structures limits
its applications. Trivially, it cannot work on depen-
dency trees. Hereafter, we define a much more gen-
eral smoothed tree kernel that can be applied to any
tree and exploit any combination of lexical similari-
ties, respecting the syntax enforced by the tree.
</bodyText>
<subsectionHeader confidence="0.990273">
3.1 SPTK Definition
</subsectionHeader>
<bodyText confidence="0.9915255">
If n1 and n2 are leaves then Aσ(n1, n2) =
µλσ(n1,n2); else
</bodyText>
<equation confidence="0.99588025">
Aσ(n1, n2) = µσ(n1, n2) x λ2 +
� E
~I1,~I2,l(~I1)=l( ~I2)
~I1j), cn2( ~I2j)) , (2)
</equation>
<bodyText confidence="0.87589625">
�
where σ is any similarity between nodes, e.g. be-
tween their lexical labels, and the other variables are
the same of PTK.
</bodyText>
<subsectionHeader confidence="0.999236">
3.2 Soundness
</subsectionHeader>
<bodyText confidence="0.999995166666667">
A completely formal proof of the validity of the
Eq. 2 is beyond the purpose of this paper (mainly
due to space reason). Here we give a first sketch:
let us consider σ as a string matching between
node labels and λ = µ = 1. Each recursive
step of Eq. 2 can be seen as a summation of (1 +
</bodyText>
<equation confidence="0.9927415">
lll(~I1)
j=1 ASTK(cn1(~I1j),cn2(~I2j))), i.e. the ASTK
</equation>
<bodyText confidence="0.99613">
recursive equation (see Sec. 2.2.1), for all subse-
quences of children cn1(~I1j). In other words, PTK
is a summation of an exponential number of STKs,
which are valid kernels. It follows that PTK is a ker-
nel. Note that the multiplication by λ and µ elevated
to any power only depends on the target fragment.
Thus, it just gives an additional weight to the frag-
ment and does not violate the Mercer’s conditions.
In contrast, the multiplication by σ(n1, n2) does de-
pend on both comparing examples, i.e. on n1 and n2.
However, if the matrix [σ(n1, n2)]bn1, n2 E f E T
is positive semi-definite, a decomposition exists
such that σ(n1, n2) = φ(n1)φ(n2) =:�, Aσ(n1, n2)
can be written as����
</bodyText>
<equation confidence="0.866099666666667">
i=1 φ(n1)χi(n1)φ(n2)χi(n2)
= ����
i=1φσ(n1)φσ(n2) (see Section 2.2), which
</equation>
<bodyText confidence="0.884261">
proves SPTK to be a valid kernel.
</bodyText>
<subsectionHeader confidence="0.996425">
3.3 Efficient Evaluation
</subsectionHeader>
<bodyText confidence="0.9998105">
We followed the idea in (Moschitti, 2006a) for effi-
ciently computing SPTK. We consider Eq. 2 evalu-
ated with respect to sequences of different length p;
it follows that
</bodyText>
<equation confidence="0.984451">
m
A(n1, n2) = µσ(n1, n2)(λ2 + E Ap(cn1,cn2)),
p=1
</equation>
<bodyText confidence="0.9973498">
where Ap evaluates the number of common sub-
trees rooted in subsequences of exactly p children
(of n1 and n2) and m = min{l(cn1), l(cn2)}.
Given the two child sequences s1a = cn1 and
s2b = cn2 (a and b are the last children)
</bodyText>
<equation confidence="0.9721325">
Ap(s1a, s2b) = A(a, b) x
xAp−1(s1[1 : i],s2[1 : r])
</equation>
<bodyText confidence="0.999979">
where s1[1 : i] and s2[1 : r] are the child subse-
quences from 1 to i and from 1 to r of s1 and s2. If
we name the double summation term as Dp, we can
</bodyText>
<equation confidence="0.9865208">
i.e σ(w1,w2) =
~w1-~w2
λd(~I1)+d(~I2) l(~I1) � Aσ(cn1(
j=1
λ|s1|−i+|s2|−r x
E |s1|
i=1
|s2|
E
r=1
</equation>
<page confidence="0.965584">
1037
</page>
<figure confidence="0.995624090909091">
SQ S1 .
VP SBARQ
?::.
ROOT
VBZ
P
.
PRD
NN
?::.
NMOD
</figure>
<page confidence="0.990641">
1039
</page>
<bodyText confidence="0.997549">
and PSTK applied to it simulates a standard SK and
an SK with smoothing, respectively.
</bodyText>
<subsectionHeader confidence="0.999164">
4.3 Structural Features
</subsectionHeader>
<bodyText confidence="0.9997948">
Section 2 has already described the kind of features
generated by SK, STK and PTK. However, it is
interesting to analyze what happens when SPTK is
applied. For example, given the following sentence
syntactically and semantically similar to s1:
</bodyText>
<equation confidence="0.670368">
(s2) What is the dimension ofan ice hockey goal?
</equation>
<bodyText confidence="0.949000619047619">
Figure 8 shows the corresponding GRCT, whose
largest PTK fragment shared with the GRTC of s1
(Fig. 3) is: (ROOT (SBJ (WP (what::w))) (PRD (NMOD
(DT (the::d))) (NN) (NMOD (IN (of::i)) (PMOD (NMOD (DT))
(NMOD (NN)) (NN)))) (P (. (?::.)))). If smoothing is ap-
plied the matching is almost total, i.e. also the chil-
dren: width::n/dimension::n, football::n/hockey::n
and field::n/goal::n will be matched (with a smooth-
ing equal to the product of their similarities).
The matching using LCT is very interesting:
without smoothing, the largest subtree is: (be::v
(what::w (SBJ) (WP)) (ROOT)); when smoothing is used
only the fragment (NMOD (NN (ice::n)) will not be part
of the match. This suggests that LCT will probably
receive the major benefit from smoothing. Addition-
ally, with respect to all the above structures, LCT is
the only one that can produce only lexical fragments,
i.e. paths only composed by similar lexical nodes
constrained by syntactic dependencies. All the other
trees produce fragments in which lexicals play the
role of features of GR or PoS-Tag nodes.
</bodyText>
<sectionHeader confidence="0.999541" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.998986">
The aim of the experiments is to analyze different
levels of representation, i.e. structure, for syntactic
dependency parses. At the same time, we compare
with the constituency trees and different kernels to
derive the best syntactic paradigm for convolution
kernels. Most importantly, the role of lexical simi-
larity embedded in syntactic structures will be inves-
tigated. For this purpose, we first carry out extensive
experiments on coarse and fine grained QC and then
we verify our findings on a completely different task,
i.e. Argument Classification in SRL.
</bodyText>
<subsectionHeader confidence="0.930004">
5.1 General experimental setup
</subsectionHeader>
<footnote confidence="0.564213666666667">
Tools: for SVM learning, we extended the SVM-
LightTK software3 (Moschitti, 2006a) (which in-
3http://disi.unitn.it/moschitti/Tree-Kernel.htm
</footnote>
<bodyText confidence="0.999616520833333">
cludes structural kernels in SVMLight (Joachims,
2000)) with the smooth match between tree nodes.
For generating constituency trees, we used the Char-
niak parser (Charniak, 2000) whereas we applied
LTH syntactic parser (described in (Johansson and
Nugues, 2008a)) to generate dependency trees.
Lexical Similarity: we used the Eq. 1 with ω1 =
ω2 = 1 and Q is derived with both approaches de-
scribed in Sec. 2.3. The first approach is LSA-based:
LSA was applied to ukWak (Baroni et al., 2009),
which is a large scale document collection made by
2 billion tokens. More specifically, to build the ma-
trix M, POS tagging is first applied to build rows
with pairs (lemma, ::POS), or lemma::POS in brief.
The contexts of such items are the columns of M
and are short windows of size [−3, +3], centered on
the items. This allows for better capturing syntactic
properties of words. The most frequent 20,000 items
are selected along with their 20k contexts. The en-
tries of M are the point-wise mutual information be-
tween them. The SVD reduction is then applied to
M, with a dimensionality cut of l = 250. The sec-
ond approach uses the similarity based on word list
(WL) as provided in (Li and Roth, 2002).
Models: SVM-LightTK is applied to the different
tree representations discussed in Section 4. Since
PTK and SPTK are typically used in our experi-
ments, to have a more compact acronym for each
model, we associate the latter with the name of the
structure, i.e. this indicates that PTK is applied to
it. Then the presence of the subscript WL and LSA
indicates that SPTK is applied along with the corre-
sponding similarity, e.g. LCTWL is the SPTK ker-
nel applied to LCT structure, using WL similarity.
We experiment with multi-classification, which we
model through one-vs-all scheme by selecting the
category associated with the maximum SVM mar-
gin. The quality of such classification is measured
with accuracy. We determine the statistical signi-
cance by using the model described in (Yeh, 2000)
and implemented in (Pad´o, 2006).
The parameterization of each classifier is carried on
a held-out set (30% of the training) and concerns
with the setting of the trade-off parameter (option -
c) and the Leaf Weight (LeW) (see Sec. 5.2), which
is used to linearly scale the contribution of the leaf
nodes. In contrast, the cost-factor parameter of the
SVM-LightTK is set as the ratio between the num-
</bodyText>
<page confidence="0.906404">
1040
</page>
<figure confidence="0.99828325">
0 1000 2000 3000 4000 5000
Number of Examples
0 1000 2000 3000 4000 5000
Number of Examples
</figure>
<figureCaption confidence="0.99964">
Figure 10: Learning curves: comparison with similarity
</figureCaption>
<bodyText confidence="0.992495">
ber of negative and positive examples for attempting
to have a balanced Precision/Recall.
</bodyText>
<subsectionHeader confidence="0.989465">
5.2 QC experiments
</subsectionHeader>
<bodyText confidence="0.999840357142857">
For these experiments, we used the UIUC dataset
(Li and Roth, 2002). It is composed by a training
set of 5,452 questions and a test set of 500 ques-
tions4. Question classes are organized in two levels:
6 coarse-grained classes (like ENTITY or HUMAN)
and 50 fine-grained sub-classes (e.g. Plant, Food
as subclasses of ENTITY).
The outcome of the several kernels applied to sev-
eral structures for the coarse and fine grained QC
is reported in Table 1. The first column shows
the experimented models, obtained by applying
PTK/SPTK to the structures described in Sec. 4. The
last two rows are: CT-STK, i.e. STK applied to a
constituency tree and BOW, which is a linear ker-
</bodyText>
<footnote confidence="0.863782">
4http://cogcomp.cs.illinois.edu/Data/QA/QC/
</footnote>
<bodyText confidence="0.999931375">
nel applied to lexical vectors. Column 2, 3 and 4
report the accuracy using no, LSA and WL similar-
ity, where LeW is the amplifying parameter, i.e. a
weight associated with the leaves in the tree. The
last three columns refer to the fine grained task.
It is worth nothing that when no similarity is ap-
plied: (i) BOW produces high accuracy, i.e. 88.8%
but it is improved by STK (the current state-of-the-
art5 in QC (Zhang and Lee, 2003; Moschitti et al.,
2007)); (ii) PTK applied to the same tree of STK
produces a slightly lower value (non-statistically
significant difference); (iii) interestingly, when PTK
is instead applied to dependency structures, it im-
proves STK, i.e. 91.60% vs 91.40% (although not
significantly); and (iv) LCT, strongly based on lexi-
cal nodes, is the least accurate, i.e 90.80% since it is
obviously subject to data sparseness (fragments only
composed by lexicals are very sparse).
The very important results can be noted when lex-
ical similarity is used, i.e. SPTK is applied: (a) all
the syntactic-base structures using both LSA or WL
improve the classification accuracy. (b) CT gets the
lowest improvement whereas LCT achieves an im-
pressive result of 94.80%, i.e more than 41% of rel-
ative error reduction. It seems that the lexical similar
paths when driven by syntax produces accurate fea-
tures. Indeed, when syntax is missing such as for the
unstructured lexical path of LSTLSA, the accuracy
does not highly improve or may also decrease. Ad-
ditionally, the result of our best model is so high that
its errors only refer to questions like What did Jesse
Jackson organize ?, where the classifier selected En-
tity instead of Human category. These refer to clear
cases where a huge amount of background knowl-
edge is needed for deriving the exact solution.
Finally, on the fine grained experiments LCT
still produces the most accurate outcome again ex-
ceeding the state-of-the-art (Zhang and Lee, 2003),
where WL significantly improves on all models (CT
included).
</bodyText>
<subsectionHeader confidence="0.999008">
5.3 Learning curves
</subsectionHeader>
<bodyText confidence="0.998743666666667">
It is interesting to study the impact of syntac-
tic/semantic kernels on the learning generalization.
For this purpose, Fig. 9 reports the learning curve
</bodyText>
<footnote confidence="0.852662333333333">
5Note that in (Bloehdorn and Moschitti, 2007b), higher ac-
curacy values for smoothed STK are shown for different param-
eters but the best according to a validation set is not highlighted.
</footnote>
<figure confidence="0.987516714285714">
PCT
LPST
CT
LOCT
GRCT
LCT
BOW
</figure>
<figureCaption confidence="0.931782">
Figure 9: Learning curves: comparison with no similarity
</figureCaption>
<figure confidence="0.999470652173913">
Accuracy
94%
92%
90%
88%
86%
84%
82%
80%
PCT-WL
LPST-WL
CT-WL
LOCT-WL
GRCT-WL
LCT-WL
PCT
Accuracy 92%
90%
88%
86%
84%
82%
80%
</figure>
<page confidence="0.962118">
1041
</page>
<table confidence="0.99297375">
COARSE FINE
LeW NO LSA LeW WL LeW NO LeW LSA LeW WL
Acc. LeW Acc. Acc. Acc. Acc. Acc.
CT 4 90.80% 2 91.00% 5 92.20% 4 84.00% 5 83.00% 7 86.60%
GRCT 3 91.60% 4 92.60% 2 94.20% 3 83.80% 4 83.20% 2 85.00%
LCT 1 90.80% 1 94.80% 1 94.20% 0.33 85.40% 1 86.20% 0.33 87.40%
LOCT 1 89.20% 1 93.20% 1 91.80% 1 85.40% 1 86.80% 1 87.00%
LST 1 88.20% 1 85.80% 1 89.60% 1 84.00% 1 80.00% 1 85.00%
LPST 3 89.40% 1 89.60% 1 92.40% 3 84.20% 4 82.20% 1 84.60%
PCT 4 91.20% 4 92.20% 5 93.40% 4 84.80% 5 84.00% 5 85.20%
CT-STK - 91.20% - - - - - 82.20% - - - -
BOW - 88.80% - - - - - 83.20% - - - -
</table>
<tableCaption confidence="0.999897">
Table 1: Accuracy of structural several kernels on different structures for coarse and fine grained QC
</tableCaption>
<figure confidence="0.9941295">
0 10 20 30 40 50 60
Number of Nodes
</figure>
<figureCaption confidence="0.999713">
Figure 11: Micro-seconds for each kernel computation
</figureCaption>
<bodyText confidence="0.999955888888889">
of the previous models without lexical similarity
whereas Fig. 10 shows the complete SPTK behavior
through the different structures. We note that when
no similarity is used the dependency trees better
generalize than constituency trees or non-syntactic
structures like LPST or BOW. When WL is acti-
vated, all models outperform the best kernel of the
previous pool, i.e. PCT (see dashed line of Fig. 10
or the top curve in Fig. 9).
</bodyText>
<subsectionHeader confidence="0.996033">
5.4 Kernel Efficiency
</subsectionHeader>
<bodyText confidence="0.999976411764706">
We plotted the average running time of each compu-
tation of PTK/SPTK applied to the different struc-
tures. We divided the examples from QC based
on the number of nodes in each example. Fig-
ure 11 shows the elapsed time in function of the
number of nodes for different tree representations.
We note that: (i) when the WL is not active, LCT
and GRCT are very fast as they impose hierarchical
matching of subtrees; (ii) when the similarity is ac-
tivated, LCTWL and GRCTWL tend to match many
more tree fragments thus their complexity increases.
However, the equations of the curve fit, shown in the
figure, suggests that the trend is sub-quadratic (x1.7).
Only LPSTWL, which has no structure, matches a
very large number of sequences of nodes, when the
similarity is active. This increases the complexity,
which results in an order higher than 2.
</bodyText>
<subsectionHeader confidence="0.926365">
5.5 FrameNet Role Classification Experiments
</subsectionHeader>
<bodyText confidence="0.99656375862069">
To verify that our findings are general and that our
syntactic/semantic dependency kernels can be effec-
tively exploited for diverse NLP tasks, we experi-
mented with a completely different application, i.e.
FrameNet SRL classification (gold standard bound-
aries). We used the FrameNet version 1.3 with
the 90/10% split between training and test set (i.e
271,560 and 30,173 examples respectively), as de-
fined in (Johansson and Nugues, 2008b), one of the
best system for FrameNet parsing. We used the LTH
dependency parser. LSA was applied to the BNC
corpus, the source of the FrameNet annotations.
For each of 648 frames, we applied SVM along
with the best models for QC, i.e. GRCT and LCT, to
learn its associated binary role classifiers (RC) for
a total of 4,254 classifiers. For example, Figure 12
shows the LCT representation of the first two roles
of the following sentence:
[Bootleggers]CREATOR, then copy [the film]ORIGINAL
[onto hundreds of VHS tapes]GOAL
Table 2 shows the results of the different multi-
classifiers. GRCT and LCT show a large ac-
curacy, i.e. 87.60. This improves up to 88.74
by activating the LSA similarity. The combina-
tion GRCTLSA+LCTLSA significantly improves the
above model, achieving 88.91%. This is very close
to the state-of-the-art of SRL for classification (us-
ing a single classifier, i.e. no joint model), i.e.
89.6%, achieved in (Johansson and Nugues, 2008b).
</bodyText>
<figure confidence="0.901812833333333">
microseconds
120
100
40
80
60
20
0
LPST-WL
GRCT-WL
GRCT
LCT-WL
LCT
LPST
y = 0.051x2.005
y = 0.081x1.705
y = 0.068x1.213
y = 0.030x1.609
</figure>
<page confidence="0.923411">
1042
</page>
<table confidence="0.860081666666667">
copy::v
film::n ROOT VBP
SBJ NNS the::d OBJ NN
</table>
<tableCaption confidence="0.992301">
Table 2: Argument Classification Accuracy
</tableCaption>
<bodyText confidence="0.99607">
Finally, it should be noted that, to learn and test the
SELF MOTION multi-classifier, containing 14,584
examples, distributed on 22 roles, SVM-SPTK em-
ployed 1.5 h and 10 minutes, respectively6.
</bodyText>
<sectionHeader confidence="0.855189" genericHeader="method">
6 Final Remarks and Conclusion
</sectionHeader>
<bodyText confidence="0.999945291666667">
In this paper, we have proposed a study on repre-
sentation of dependency structures for the design of
effective structural kernels. Most importantly, we
have defined a new class of kernel functions, i.e. SP-
TKs, that carry out syntactic and lexical similarities
on the above structures. SPTK exploits the latter
by providing generalization trough lexical similar-
ities constrained in them. This allows for automat-
ically generating feature spaces of generalized syn-
tactic/semantic dependency substructures.
To test our models, we carried out experiments
on QC and SRL. These show that by exploiting the
similarity between two sets of words carried out ac-
cording to their dependency structure leads to an un-
precedented result for QC, i.e. 94.8% of accuracy.
In contrast, when no structure is used the accuracy
does not significantly improves. We have also pro-
vided a fast algorithm for the computation of SPTK
and empirically shown that it can easily scale.
It should be noted that our models are not abso-
lutely restricted to QC and SRL. Indeed, since most
of the NLP applications are based on syntactic and
lexical representations, SPTK will have a major im-
pact in most of them, e.g.:
</bodyText>
<footnote confidence="0.975252">
6Using one of the 8 processors of an Intel(R) Xeon(R) CPU
E5430 @ 2.66GHz machine, 32Gb Ram.
</footnote>
<listItem confidence="0.888470783783784">
• Question Answering, the high results for QC
will positively impact on the overall task.
• SRL, SPTK alone reaches the state-of-the-art
(SOA) (only 0.7% less) in FrameNet role clas-
sification. This is very valuable as previous
work showed that tree kernels (TK) alone per-
form lower than models based on manually en-
gineered features for SRL tasks, e.g., (Mos-
chitti, 2004; Giuglea and Moschitti, 2004; Giu-
glea and Moschitti, 2006; Moschitti, 2006b;
Che et al., 2006; Moschitti et al., 2008). Thus
for the first time in an SRL task, a general
tree kernel reaches the same accuracy of heavy
manual feature design. This also suggests an
improvement when used in combinations with
manual feature vectors.
• Relation Extraction and Pronominal Corefer-
ence, whose state-of-the-art for some tasks is
achieved with the simple STK-CT (see (Zhang
et al., 2006) and (Yang et al., 2006; Versley et
al., 2008), respectively).
• In word sense disambiguation tasks, SPTK can
generalize context according to syntactic and
semantic constraints (selectional restrictions)
making very effective distributional semantic
approaches.
• In Opinion Mining SPTK will allow to match
sentiment words within their corresponding
syntactic counterparts and improve the state-
of-the-art (Johansson and Moschitti, 2010b; Jo-
hansson and Moschitti, 2010a).
• Experiments on Recognizing Textual Entail-
ment (RTE) tasks, the use of SSTK (in-
stead of STK-CT) improved the state-of-the-art
(Mehdad et al., 2010). SPTK may provide fur-
ther enhancement and innovative and effective
dependency models.
</listItem>
<bodyText confidence="0.999837">
The above points also suggest many promising fu-
ture research directions, which we would like to ex-
plore.
</bodyText>
<sectionHeader confidence="0.977168" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.560278666666667">
This work has been partially supported by the EC
project FP247758: Trustworthy Eternal Systems via
Evolving Software, Data and Knowledge (EternalS).
</bodyText>
<figure confidence="0.383447066666667">
copy::v
VBP
ROOT
bootlegger::n
NMOD DT
12: LCT Examples for argument
Kernel Accuracy
GRCT 87.60%
GRCTLSA 88,61%
LCT 87.61%
LCTLSA 88.74%
GRCT + LCT 87.99%
GRCTLSA + LCTLSA 88.91%
Figure
roles
</figure>
<page confidence="0.92271">
1043
</page>
<sectionHeader confidence="0.924989" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998018221153846">
Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and
Eros Zanchetta. 2009. The wacky wide web: a
collection of very large linguistically processed web-
crawled corpora. Language Resources and Evalua-
tion, 43(3):209–226.
Roberto Basili, Marco Cammisa, and Alessandro Mos-
chitti. 2005. Effective use of WordNet semantics
via kernel-based learning. In Proceedings of CoNLL-
2005, pages 1–8, Ann Arbor, Michigan. Association
for Computational Linguistics.
Stephan Bloehdorn and Alessandro Moschitti. 2007a.
Combined syntactic and semantic kernels for text clas-
sification. In Proceedings of ECIR 2007, Rome, Italy.
Stephan Bloehdorn and Alessandro Moschitti. 2007b.
Structure and semantics for expressive text kernels. In
In Proceedings of CIKM ’07.
Stephan Bloehdorn, Roberto Basili, Marco Cammisa, and
Alessandro Moschitti. 2006. Semantic kernels for text
classification based on topological measures of feature
similarity. In Proceedings of ICDM 06, Hong Kong,
2006.
Ulrik Brandes. 2001. A Faster Algorithm for Between-
ness Centrality. Journal of Mathematical Sociology,
25:163–177.
Alexander Budanitsky and Graeme Hirst. 2006. Eval-
uating WordNet-based measures of semantic distance.
Computational Linguistics, 32(1):13–47.
Razvan Bunescu and Raymond Mooney. 2005. A short-
est path dependency kernel for relation extraction. In
Proceedings of HLT and EMNLP, pages 724–731,
Vancouver, British Columbia, Canada, October.
Horst Bunke and Kim Shearer. 1998. A graph distance
metric based on the maximal common subgraph. Pat-
tern Recogn. Lett., 19(3-4):255–259, March.
Nicola Cancedda, Eric Gaussier, Cyril Goutte, and
Jean Michel Renders. 2003. Word sequence kernels.
Journal of Machine Learning Research, 3:1059–1082.
O. Chapelle, B. Schlkopf, and A. Zien. 2006. Semi-
Supervised Learning. Adaptive computation and ma-
chine learning. MIT Press, Cambridge, MA, USA, 09.
Eugene Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of NAACL’00.
Wanxiang Che, Min Zhang, Ting Liu, and Sheng Li.
2006. A hybrid convolution tree kernel for semantic
role labeling. In Proceedings of the COLING/ACL on
Main conference poster sessions, COLING-ACL ’06,
pages 73–80, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Michael Collins and Nigel Duffy. 2002. New Rank-
ing Algorithms for Parsing and Tagging: Kernels over
Discrete Structures, and the Voted Perceptron. In Pro-
ceedings of ACL’02.
Courtney Corley and Rada Mihalcea. 2005. Measur-
ing the semantic similarity of texts. In Proceedings of
the ACL Workshop on Empirical Modeling of Semantic
Equivalence and Entailment, pages 13–18, Ann Arbor,
Michigan, June. Association for Computational Lin-
guistics.
Jim Cowie, Joe Guthrie, and Louise Guthrie. 1992. Lex-
ical disambiguation using simulated annealing. In in
COLING, pages 359–365.
Nello Cristianini, John Shawe-Taylor, and Huma Lodhi.
2001. Latent semantic kernels. In Carla Brodley and
Andrea Danyluk, editors, Proceedings of ICML-01,
18th International Conference on Machine Learning,
pages 66–73, Williams College, US. Morgan Kauf-
mann Publishers, San Francisco, US.
Aron Culotta and Jeffrey Sorensen. 2004. Dependency
tree kernels for relation extraction. In Proceedings of
ACL, pages 423–429, Barcelona, Spain, July.
Chad Cumby and Dan Roth. 2003. Kernel Methods for
Relational Learning. In Proceedings of ICML 2003.
Hal Daum´e III and Daniel Marcu. 2004. Np bracketing
by maximum entropy tagging and SVM reranking. In
Proceedings of EMNLP’04.
Jason V. Davis, Brian Kulis, Prateek Jain, Suvrit Sra, and
Inderjit S. Dhillon. 2007. Information-theoretic met-
ric learning. In Proceedings of the 24th international
conference on Machine learning, ICML ’07, pages
209–216, New York, NY, USA. ACM.
Linton C. Freeman. 1977. A Set of Measures of Central-
ity Based on Betweenness. Sociometry, 40(1):35–41.
Hagen F¨urstenau and Mirella Lapata. 2009. Graph align-
ment for semi-supervised semantic role labeling. In
In Proceedings of EMNLP ’09, pages 11–20, Morris-
town, NJ, USA.
Ana-Maria Giuglea and Alessandro Moschitti. 2004.
Knowledge Discovering using FrameNet, VerbNet and
PropBank. In In Proceedings of the Workshop on On-
tology and Knowledge Discovering at ECML 2004,
Pisa, Italy.
A.-M. Giuglea and A. Moschitti. 2006. Semantic role
labeling via framenet, verbnet and propbank. In Pro-
ceedings of ACL, Sydney, Australia.
Alfio Gliozzo, Claudio Giuliano, and Carlo Strapparava.
2005. Domain kernels for word sense disambiguation.
In Proceedings of ACL’05, pages 403–410.
G. Golub and W. Kahan. 1965. Calculating the singular
values and pseudo-inverse of a matrix. Journal of the
Society for Industrial and Applied Mathematics: Se-
ries B, Numerical Analysis, 2(2):pp. 205–224.
Zellig Harris. 1964. Distributional structure. In Jer-
rold J. Katz and Jerry A. Fodor, editors, The Philos-
ophy of Linguistics. Oxford University Press.
</reference>
<page confidence="0.991193">
1044
</page>
<note confidence="0.90823125">
J. J. Jiang and D. W. Conrath. 1997. Semantic Similarity
Based on Corpus Statistics and Lexical Taxonomy. In
International Conference Research on Computational
Linguistics (ROCLING X).
</note>
<reference confidence="0.999210411764706">
T. Joachims. 2000. Estimating the generalization per-
formance of a SVM efficiently. In Proceedings of
ICML’00.
Richard Johansson and Alessandro Moschitti. 2010a.
Reranking models in fine-grained opinion analysis. In
Proceedings of the 23rd International Conference of
Computational Linguistics (Coling 2010), pages 519–
527, Beijing, China.
Richard Johansson and Alessandro Moschitti. 2010b.
Syntactic and semantic structure for opinion expres-
sion detection. In Proceedings of the Fourteenth Con-
ference on Computational Natural Language Learn-
ing, pages 67–76, Uppsala, Sweden.
Richard Johansson and Pierre Nugues. 2008a.
Dependency-based syntactic–semantic analysis with
PropBank and NomBank. In CoNLL 2008: Proceed-
ings of the Twelfth Conference on Natural Language
Learning, pages 183–187, Manchester, United King-
dom.
Richard Johansson and Pierre Nugues. 2008b. The effect
of syntactic representation on semantic role labeling.
In Proceedings of COLING, Manchester, UK, August
18-22.
Taku Kudo and Yuji Matsumoto. 2003. Fast methods for
kernel-based text analysis. In Proceedings of ACL’03.
Taku Kudo, Jun Suzuki, and Hideki Isozaki. 2005.
Boosting-based parse reranking with subtree features.
In Proceedings of ACL’05.
Claudia Leacock and Martin Chodorow, 1998. Combin-
ing Local Context and WordNet Similarity for Word
Sense Identification, chapter 11, pages 265–283. The
MIT Press.
X. Li and D. Roth. 2002. Learning question classifiers.
In Proceedings of ACL’02.
Yashar Mehdad, Alessandro Moschitti, and Fabio Mas-
simo Zanzotto. 2010. Syntactic/semantic structures
for textual entailment recognition. In HLT-NAACL,
pages 1020–1028.
Rada Mihalcea, Courtney Corley, and Carlo Strappar-
ava. 2005. Corpus-based and knowledge-based mea-
sures of text semantic similarity. In Proceedings of the
American Association forArtificial Intelligence (AAAI
2006), Boston, July.
Rada Mihalcea. 2005. unsupervised large-vocabulary
word sense disambiguation with graph-based algo-
rithms for sequence data labeling. In In HLT/EMNLP
2005, pages 411–418.
Alessandro Moschitti, Silvia Quarteroni, Roberto Basili,
and Suresh Manandhar. 2007. Exploiting syntactic
and shallow semantic kernels for question/answer clas-
sification. In Proceedings of ACL’07.
Alessandro Moschitti, Daniele Pighin, and Roberto
Basili. 2008. Tree kernels for semantic role labeling.
Computational Linguistics, 34(2):193–224.
A. Moschitti. 2004. A study on convolution kernels
for shallow semantic parsing. In Proceedings of ACL,
Barcelona, Spain.
Alessandro Moschitti. 2006a. Efficient convolution ker-
nels for dependency and constituent syntactic trees. In
Proceedings of ECML’06, pages 318–329.
Alessandro Moschitti. 2006b. Making tree kernels prac-
tical for natural language learning. In Proccedings of
EACL’06.
Roberto Navigli and Mirella Lapata. 2010. An Experi-
mental Study of Graph Connectivity for Unsupervised
Word Sense Disambiguation. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 32(4):678–
692.
Sebastian Pado and Mirella Lapata. 2007. Dependency-
based construction of semantic space models. Compu-
tational Linguistics, 33(2).
Sebastian Pad´o, 2006. User’s guide to sigf: Signifi-
cance testing by approximate randomisation.
Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004a. WordNet::Similarity -Measuring the Re-
latedness of Concept. In Proc. of 5th NAACL, Boston,
MA.
Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004b. Wordnet::similarity - measuring the re-
latedness of concepts. In Daniel Marcu Susan Du-
mais and Salim Roukos, editors, HLT-NAACL 2004:
Demonstration Papers, pages 38–41, Boston, Mas-
sachusetts, USA, May 2 - May 7. Association for
Computational Linguistics.
Philip Resnik. 1995. Using information content to eval-
uate semantic similarity in a taxonomy. In In Proceed-
ings of the 14th International Joint Conference on Ar-
tificial Intelligence, pages 448–453.
Magnus Sahlgren. 2006. The Word-Space Model. Ph.D.
thesis, Stockholm University.
Hinrich Schtze. 1998. Automatic word sense discrimi-
nation. Journal of Computational Linguistics, 24:97–
123.
John Shawe-Taylor and Nello Cristianini. 2004. Kernel
Methods for Pattern Analysis. Cambridge University
Press.
Libin Shen, Anoop Sarkar, and Aravind k. Joshi. 2003.
Using LTAG Based Features in Parse Reranking. In
Empirical Methods for Natural Language Processing
(EMNLP), pages 89–96, Sapporo, Japan.
Georges Siolas and Florence d’Alch Buc. 2000. Sup-
port vector machines based on a semantic kernel for
</reference>
<page confidence="0.744447">
1045
</page>
<reference confidence="0.992356733333334">
text categorization. In Proceedings of the IEEE-INNS-
ENNS International Joint Conference on Neural Net-
works (IJCNN’00)-Volume 5, page 5205. IEEE Com-
puter Society.
Ivan Titov and James Henderson. 2006. Porting statisti-
cal parsers with data-defined kernels. In Proceedings
of CoNLL-X.
Kristina Toutanova, Penka Markova, and Christopher
Manning. 2004. The Leaf Path Projection View of
Parse Trees: Exploring String Kernels for HPSG Parse
Selection. In Proceedings of EMNLP 2004.
Yannick Versley, Alessandro Moschitti, Massimo Poe-
sio, and Xiaofeng Yang. 2008. Coreference sys-
tems based on kernels methods. In The 22nd Interna-
tional Conference on Computational Linguistics (Col-
ing’08), Manchester, England.
Zhibiao Wu and Martha Palmer. 1994. Verb semantics
and lexical selection. In 32nd. Annual Meeting of the
Association for Computational Linguistics, pages 133
–138, New Mexico State University, Las Cruces, New
Mexico.
Xiaofeng Yang, Jian Su, and Chewlim Tan. 2006.
Kernel-based pronoun resolution with structured syn-
tactic knowledge. In Proc. COLING-ACL 06.
Alexander S. Yeh. 2000. More accurate tests for the sta-
tistical significance of result differences. In COLING,
pages 947–953.
Dmitry Zelenko, Chinatsu Aone, and Anthony
Richardella. 2002. Kernel methods for relation
extraction. In Proceedings of EMNLP-ACL, pages
181–201.
Dell Zhang and Wee Sun Lee. 2003. Question classifica-
tion using support vector machines. In Proceedings of
the 26th annual international ACM SIGIR conference
on Research and development in informaion retrieval,
pages 26–32. ACM Press.
Min Zhang, Jie Zhang, and Jian Su. 2006. Explor-
ing Syntactic Features for Relation Extraction using a
Convolution tree kernel. In Proceedings of NAACL.
Peixiang Zhao, Jiawei Han, and Yizhou Sun. 2009. P-
Rank: a comprehensive structural similarity measure
over information networks. In CIKM ’09: Proceed-
ing of the 18th ACM conference on Information and
knowledge management, pages 553–562, New York,
NY, USA. ACM.
</reference>
<page confidence="0.991058">
1046
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.828683">
<title confidence="0.999277">Structured Lexical Similarity via Convolution Kernels on Dependency Trees</title>
<author confidence="0.958687">Danilo</author>
<affiliation confidence="0.999912">University of Tor</affiliation>
<address confidence="0.999967">00133 Roma, Italy</address>
<email confidence="0.994009">croce@info.uniroma2.it</email>
<author confidence="0.921701">Alessandro</author>
<affiliation confidence="0.999898">University of</affiliation>
<address confidence="0.994739">38123 Povo (TN), Italy</address>
<email confidence="0.998817">moschitti@disi.unitn.it</email>
<author confidence="0.969981">Roberto</author>
<affiliation confidence="0.999951">University of Tor</affiliation>
<address confidence="0.999966">00133 Roma, Italy</address>
<email confidence="0.99492">basili@info.uniroma2.it</email>
<abstract confidence="0.999070235294118">A central topic in natural language processing is the design of lexical and syntactic features suitable for the target application. In this paper, we study convolution dependency tree kernels for automatic engineering of syntactic and semantic patterns exploiting lexical similarities. We define efficient and powerful kernels for measuring the similarity between dependency structures, whose surface forms of the lexical nodes are in part or completely different. The experiments with such kernels for question classification show an unprecedented results, e.g. 41% of error reduction of the former state-of-the-art. Additionally, semantic role classification confirms the benefit of semantic smoothing for dependency kernels.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Silvia Bernardini</author>
<author>Adriano Ferraresi</author>
<author>Eros Zanchetta</author>
</authors>
<title>The wacky wide web: a collection of very large linguistically processed webcrawled corpora. Language Resources and Evaluation,</title>
<date>2009</date>
<pages>43--3</pages>
<contexts>
<context position="19432" citStr="Baroni et al., 2009" startWordPosition="3231" endWordPosition="3234"> for SVM learning, we extended the SVMLightTK software3 (Moschitti, 2006a) (which in3http://disi.unitn.it/moschitti/Tree-Kernel.htm cludes structural kernels in SVMLight (Joachims, 2000)) with the smooth match between tree nodes. For generating constituency trees, we used the Charniak parser (Charniak, 2000) whereas we applied LTH syntactic parser (described in (Johansson and Nugues, 2008a)) to generate dependency trees. Lexical Similarity: we used the Eq. 1 with ω1 = ω2 = 1 and Q is derived with both approaches described in Sec. 2.3. The first approach is LSA-based: LSA was applied to ukWak (Baroni et al., 2009), which is a large scale document collection made by 2 billion tokens. More specifically, to build the matrix M, POS tagging is first applied to build rows with pairs (lemma, ::POS), or lemma::POS in brief. The contexts of such items are the columns of M and are short windows of size [−3, +3], centered on the items. This allows for better capturing syntactic properties of words. The most frequent 20,000 items are selected along with their 20k contexts. The entries of M are the point-wise mutual information between them. The SVD reduction is then applied to M, with a dimensionality cut of l = 2</context>
</contexts>
<marker>Baroni, Bernardini, Ferraresi, Zanchetta, 2009</marker>
<rawString>Marco Baroni, Silvia Bernardini, Adriano Ferraresi, and Eros Zanchetta. 2009. The wacky wide web: a collection of very large linguistically processed webcrawled corpora. Language Resources and Evaluation, 43(3):209–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Basili</author>
<author>Marco Cammisa</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Effective use of WordNet semantics via kernel-based learning.</title>
<date>2005</date>
<booktitle>In Proceedings of CoNLL2005,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="11084" citStr="Basili et al., 2005" startWordPosition="1792" endWordPosition="1795">aps. PTK is more general than the STK as if we only consider the contribution of shared subsequences containing all children of nodes, we implement the STK kernel. The computational complexity of PTK is O(pρ2|NT1||NT2|) (Moschitti, 2006a), where p is the largest subsequence of children that we want consider and ρ is the maximal outdegree observed in the two trees. However the average running time again tends to be linear for natural language syntactic trees (Moschitti, 2006a). 2.3 Lexical Semantic Kernel Given two text fragments d1 and d2 E D (the text fragment set), a general lexical kernel (Basili et al., 2005) defines their similarity as: K(d1, d2) = � (ω1ω2) X Q(w1, w2) (1) w1∈d1,w2∈d2 where ω1 and ω2 are the weights of the words (features) w1 and w2 in the documents d1 and d2, respectively, and Q is a term similarity function, e.g. (Pedersen et al., 2004b; Sahlgren, 2006; Corley and Mihalcea, 2005; Mihalcea et al., 2005). Technically, any Q can be used, provided that the resulting Gram matrix, G = K(d1, d2) bd1, d2 E D is positive semi-definite (Shawe-Taylor and Cristianini, 2004) (D is typically the training text set). We determine the term similarity function through distributional analysis (Pa</context>
</contexts>
<marker>Basili, Cammisa, Moschitti, 2005</marker>
<rawString>Roberto Basili, Marco Cammisa, and Alessandro Moschitti. 2005. Effective use of WordNet semantics via kernel-based learning. In Proceedings of CoNLL2005, pages 1–8, Ann Arbor, Michigan. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Bloehdorn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Combined syntactic and semantic kernels for text classification.</title>
<date>2007</date>
<booktitle>In Proceedings of ECIR 2007,</booktitle>
<location>Rome, Italy.</location>
<contexts>
<context position="1652" citStr="Bloehdorn and Moschitti, 2007" startWordPosition="231" endWordPosition="235">enefit of semantic smoothing for dependency kernels. 1 Introduction A central topic in Natural Language Processing is the design of lexical and syntactic features suitable for the target application. The selection of effective patterns composed of syntactic dependencies and lexical constraints is typically a complex task. Additionally, the availability of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough sim</context>
<context position="3184" citStr="Bloehdorn and Moschitti, 2007" startWordPosition="477" endWordPosition="480">ther hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms). This implies matching scores lower than 1, depending on the semantic similarity of the corresponding leaves in the syntactic fragments. Although this kernel achieves state-of-the-art performance in NLP tasks, such as Question Classifica1034 Proceedings of the 2011 Conference on Empirical Methods in Natural La</context>
<context position="24496" citStr="Bloehdorn and Moschitti, 2007" startWordPosition="4082" endWordPosition="4085">d Jesse Jackson organize ?, where the classifier selected Entity instead of Human category. These refer to clear cases where a huge amount of background knowledge is needed for deriving the exact solution. Finally, on the fine grained experiments LCT still produces the most accurate outcome again exceeding the state-of-the-art (Zhang and Lee, 2003), where WL significantly improves on all models (CT included). 5.3 Learning curves It is interesting to study the impact of syntactic/semantic kernels on the learning generalization. For this purpose, Fig. 9 reports the learning curve 5Note that in (Bloehdorn and Moschitti, 2007b), higher accuracy values for smoothed STK are shown for different parameters but the best according to a validation set is not highlighted. PCT LPST CT LOCT GRCT LCT BOW Figure 9: Learning curves: comparison with no similarity Accuracy 94% 92% 90% 88% 86% 84% 82% 80% PCT-WL LPST-WL CT-WL LOCT-WL GRCT-WL LCT-WL PCT Accuracy 92% 90% 88% 86% 84% 82% 80% 1041 COARSE FINE LeW NO LSA LeW WL LeW NO LeW LSA LeW WL Acc. LeW Acc. Acc. Acc. Acc. Acc. CT 4 90.80% 2 91.00% 5 92.20% 4 84.00% 5 83.00% 7 86.60% GRCT 3 91.60% 4 92.60% 2 94.20% 3 83.80% 4 83.20% 2 85.00% LCT 1 90.80% 1 94.80% 1 94.20% 0.33 85</context>
</contexts>
<marker>Bloehdorn, Moschitti, 2007</marker>
<rawString>Stephan Bloehdorn and Alessandro Moschitti. 2007a. Combined syntactic and semantic kernels for text classification. In Proceedings of ECIR 2007, Rome, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Bloehdorn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Structure and semantics for expressive text kernels. In</title>
<date>2007</date>
<booktitle>In Proceedings of CIKM ’07.</booktitle>
<contexts>
<context position="1652" citStr="Bloehdorn and Moschitti, 2007" startWordPosition="231" endWordPosition="235">enefit of semantic smoothing for dependency kernels. 1 Introduction A central topic in Natural Language Processing is the design of lexical and syntactic features suitable for the target application. The selection of effective patterns composed of syntactic dependencies and lexical constraints is typically a complex task. Additionally, the availability of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough sim</context>
<context position="3184" citStr="Bloehdorn and Moschitti, 2007" startWordPosition="477" endWordPosition="480">ther hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms). This implies matching scores lower than 1, depending on the semantic similarity of the corresponding leaves in the syntactic fragments. Although this kernel achieves state-of-the-art performance in NLP tasks, such as Question Classifica1034 Proceedings of the 2011 Conference on Empirical Methods in Natural La</context>
<context position="24496" citStr="Bloehdorn and Moschitti, 2007" startWordPosition="4082" endWordPosition="4085">d Jesse Jackson organize ?, where the classifier selected Entity instead of Human category. These refer to clear cases where a huge amount of background knowledge is needed for deriving the exact solution. Finally, on the fine grained experiments LCT still produces the most accurate outcome again exceeding the state-of-the-art (Zhang and Lee, 2003), where WL significantly improves on all models (CT included). 5.3 Learning curves It is interesting to study the impact of syntactic/semantic kernels on the learning generalization. For this purpose, Fig. 9 reports the learning curve 5Note that in (Bloehdorn and Moschitti, 2007b), higher accuracy values for smoothed STK are shown for different parameters but the best according to a validation set is not highlighted. PCT LPST CT LOCT GRCT LCT BOW Figure 9: Learning curves: comparison with no similarity Accuracy 94% 92% 90% 88% 86% 84% 82% 80% PCT-WL LPST-WL CT-WL LOCT-WL GRCT-WL LCT-WL PCT Accuracy 92% 90% 88% 86% 84% 82% 80% 1041 COARSE FINE LeW NO LSA LeW WL LeW NO LeW LSA LeW WL Acc. LeW Acc. Acc. Acc. Acc. Acc. CT 4 90.80% 2 91.00% 5 92.20% 4 84.00% 5 83.00% 7 86.60% GRCT 3 91.60% 4 92.60% 2 94.20% 3 83.80% 4 83.20% 2 85.00% LCT 1 90.80% 1 94.80% 1 94.20% 0.33 85</context>
</contexts>
<marker>Bloehdorn, Moschitti, 2007</marker>
<rawString>Stephan Bloehdorn and Alessandro Moschitti. 2007b. Structure and semantics for expressive text kernels. In In Proceedings of CIKM ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Bloehdorn</author>
<author>Roberto Basili</author>
<author>Marco Cammisa</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Semantic kernels for text classification based on topological measures of feature similarity.</title>
<date>2006</date>
<booktitle>In Proceedings of ICDM 06,</booktitle>
<location>Hong Kong,</location>
<contexts>
<context position="13215" citStr="Bloehdorn et al., 2006" startWordPosition="2170" endWordPosition="2173">�I1)+d(�I2) l( �I1) H j=1 1036 dimensional space using W = UlS1/2 l , where each row corresponds to the representation vectors ~wi. Therefore, given two words w1 and w2, the term similarity function σ is estimated as the cosine similarity between the corresponding projections ~w1, ~w2, 11 ~w11111 ~w211. The latent semantic kernels (Siolas and d’Alch Buc, 2000; Cristianini et al., 2001) derive G by applying LSA, resulting in a valid kernel. Another methods to design a valid kernel is to represent words as word vectors and compute σ as their scalar product between such vectors. For example, in (Bloehdorn et al., 2006), bag of hyponyms and hypernyms (up to a certain level of WordNet hierarchy) were used to build such vectors. We will refer to such similarity as WL (word list). 3 Smoothing Partial Tree Kernel (SPTK) Combining lexical and structural kernels provides clear advantages on all-vs-all words similarity, which tends to semantically diverge. Indeed syntax provides the necessary restrictions to compute an effective semantic similarity. Following this idea, Bloedhorn &amp; Moschitti (2007a) modified step (i) of ASTK computation as follows: (i) if n1 and n2 are pre-terminal nodes with the same number of chi</context>
</contexts>
<marker>Bloehdorn, Basili, Cammisa, Moschitti, 2006</marker>
<rawString>Stephan Bloehdorn, Roberto Basili, Marco Cammisa, and Alessandro Moschitti. 2006. Semantic kernels for text classification based on topological measures of feature similarity. In Proceedings of ICDM 06, Hong Kong, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrik Brandes</author>
</authors>
<title>A Faster Algorithm for Betweenness Centrality.</title>
<date>2001</date>
<journal>Journal of Mathematical Sociology,</journal>
<pages>25--163</pages>
<contexts>
<context position="1866" citStr="Brandes, 2001" startWordPosition="269" endWordPosition="270">terns composed of syntactic dependencies and lexical constraints is typically a complex task. Additionally, the availability of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineerin</context>
</contexts>
<marker>Brandes, 2001</marker>
<rawString>Ulrik Brandes. 2001. A Faster Algorithm for Betweenness Centrality. Journal of Mathematical Sociology, 25:163–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Evaluating WordNet-based measures of semantic distance.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>1</issue>
<contexts>
<context position="2146" citStr="Budanitsky and Hirst, 2006" startWordPosition="311" endWordPosition="314">them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 20</context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2006. Evaluating WordNet-based measures of semantic distance. Computational Linguistics, 32(1):13–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Raymond Mooney</author>
</authors>
<title>A shortest path dependency kernel for relation extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT and EMNLP,</booktitle>
<pages>724--731</pages>
<location>Vancouver, British Columbia, Canada,</location>
<contexts>
<context position="2980" citStr="Bunescu and Mooney, 2005" startWordPosition="445" endWordPosition="448">, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms). This implies matching scores lower than 1, depending on the semantic similarity of the corresponding leave</context>
</contexts>
<marker>Bunescu, Mooney, 2005</marker>
<rawString>Razvan Bunescu and Raymond Mooney. 2005. A shortest path dependency kernel for relation extraction. In Proceedings of HLT and EMNLP, pages 724–731, Vancouver, British Columbia, Canada, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Horst Bunke</author>
<author>Kim Shearer</author>
</authors>
<title>A graph distance metric based on the maximal common subgraph.</title>
<date>1998</date>
<journal>Pattern Recogn. Lett.,</journal>
<pages>19--3</pages>
<contexts>
<context position="1851" citStr="Bunke and Shearer, 1998" startWordPosition="265" endWordPosition="268">election of effective patterns composed of syntactic dependencies and lexical constraints is typically a complex task. Additionally, the availability of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods</context>
</contexts>
<marker>Bunke, Shearer, 1998</marker>
<rawString>Horst Bunke and Kim Shearer. 1998. A graph distance metric based on the maximal common subgraph. Pattern Recogn. Lett., 19(3-4):255–259, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Cancedda</author>
<author>Eric Gaussier</author>
<author>Cyril Goutte</author>
<author>Jean Michel Renders</author>
</authors>
<title>Word sequence kernels.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--1059</pages>
<contexts>
<context position="2793" citStr="Cancedda et al., 2003" startWordPosition="412" endWordPosition="415">o focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even</context>
</contexts>
<marker>Cancedda, Gaussier, Goutte, Renders, 2003</marker>
<rawString>Nicola Cancedda, Eric Gaussier, Cyril Goutte, and Jean Michel Renders. 2003. Word sequence kernels. Journal of Machine Learning Research, 3:1059–1082.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Chapelle</author>
<author>B Schlkopf</author>
<author>A Zien</author>
</authors>
<title>SemiSupervised Learning. Adaptive computation and machine learning.</title>
<date>2006</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA,</location>
<contexts>
<context position="1734" citStr="Chapelle et al., 2006" startWordPosition="246" endWordPosition="249">tural Language Processing is the design of lexical and syntactic features suitable for the target application. The selection of effective patterns composed of syntactic dependencies and lexical constraints is typically a complex task. Additionally, the availability of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 20</context>
</contexts>
<marker>Chapelle, Schlkopf, Zien, 2006</marker>
<rawString>O. Chapelle, B. Schlkopf, and A. Zien. 2006. SemiSupervised Learning. Adaptive computation and machine learning. MIT Press, Cambridge, MA, USA, 09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of NAACL’00.</booktitle>
<contexts>
<context position="19121" citStr="Charniak, 2000" startWordPosition="3178" endWordPosition="3179">e of lexical similarity embedded in syntactic structures will be investigated. For this purpose, we first carry out extensive experiments on coarse and fine grained QC and then we verify our findings on a completely different task, i.e. Argument Classification in SRL. 5.1 General experimental setup Tools: for SVM learning, we extended the SVMLightTK software3 (Moschitti, 2006a) (which in3http://disi.unitn.it/moschitti/Tree-Kernel.htm cludes structural kernels in SVMLight (Joachims, 2000)) with the smooth match between tree nodes. For generating constituency trees, we used the Charniak parser (Charniak, 2000) whereas we applied LTH syntactic parser (described in (Johansson and Nugues, 2008a)) to generate dependency trees. Lexical Similarity: we used the Eq. 1 with ω1 = ω2 = 1 and Q is derived with both approaches described in Sec. 2.3. The first approach is LSA-based: LSA was applied to ukWak (Baroni et al., 2009), which is a large scale document collection made by 2 billion tokens. More specifically, to build the matrix M, POS tagging is first applied to build rows with pairs (lemma, ::POS), or lemma::POS in brief. The contexts of such items are the columns of M and are short windows of size [−3,</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A maximum-entropy-inspired parser. In Proceedings of NAACL’00.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wanxiang Che</author>
<author>Min Zhang</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>A hybrid convolution tree kernel for semantic role labeling.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main conference poster sessions, COLING-ACL ’06,</booktitle>
<pages>73--80</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="30547" citStr="Che et al., 2006" startWordPosition="5128" endWordPosition="5131">tions, SPTK will have a major impact in most of them, e.g.: 6Using one of the 8 processors of an Intel(R) Xeon(R) CPU E5430 @ 2.66GHz machine, 32Gb Ram. • Question Answering, the high results for QC will positively impact on the overall task. • SRL, SPTK alone reaches the state-of-the-art (SOA) (only 0.7% less) in FrameNet role classification. This is very valuable as previous work showed that tree kernels (TK) alone perform lower than models based on manually engineered features for SRL tasks, e.g., (Moschitti, 2004; Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti, 2006b; Che et al., 2006; Moschitti et al., 2008). Thus for the first time in an SRL task, a general tree kernel reaches the same accuracy of heavy manual feature design. This also suggests an improvement when used in combinations with manual feature vectors. • Relation Extraction and Pronominal Coreference, whose state-of-the-art for some tasks is achieved with the simple STK-CT (see (Zhang et al., 2006) and (Yang et al., 2006; Versley et al., 2008), respectively). • In word sense disambiguation tasks, SPTK can generalize context according to syntactic and semantic constraints (selectional restrictions) making very </context>
</contexts>
<marker>Che, Zhang, Liu, Li, 2006</marker>
<rawString>Wanxiang Che, Min Zhang, Ting Liu, and Sheng Li. 2006. A hybrid convolution tree kernel for semantic role labeling. In Proceedings of the COLING/ACL on Main conference poster sessions, COLING-ACL ’06, pages 73–80, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Nigel Duffy</author>
</authors>
<title>New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete Structures, and the Voted Perceptron.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL’02.</booktitle>
<contexts>
<context position="2722" citStr="Collins and Duffy, 2002" startWordPosition="400" endWordPosition="403">rsen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) i</context>
<context position="5647" citStr="Collins and Duffy, 2002" startWordPosition="855" endWordPosition="858">rs ~xi and φ(oi)φ(o) = K(oi, o) is a kerploitable by convolution kernels. Indeed, although nel function implicitly defining such mapping. In the work in (Culotta and Sorensen, 2004) defines a case of structural kernels, K determines the shape of dependency tree also using node similarity, it is not the substructures describing the objects above. The a convolution kernel: this results in a much poorer most general kind of kernels used in NLP are string feature space. kernels, e.g. (Shawe-Taylor and Cristianini, 2004), In this paper, we propose a study of convolution the Syntactic Tree Kernels (Collins and Duffy, 2002) kernels for dependency structures aiming at jointly and the Partial Tree Kernels (Moschitti, 2006a). modeling syntactic and lexical semantic similarity. 2.1 String Kernels More precisely, we define several dependency trees The String Kernels (SK) that we consider count exploitable by the Partial Tree Kernel (PTK) (Mos- the number of subsequences shared by two strings chitti, 2006a) and compared them with STK over of symbols, s1 and s2. Some symbols during the constituency trees. Most importantly, we define matching process can be skipped. This modifies an innovative and efficient class of ker</context>
</contexts>
<marker>Collins, Duffy, 2002</marker>
<rawString>Michael Collins and Nigel Duffy. 2002. New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete Structures, and the Voted Perceptron. In Proceedings of ACL’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Courtney Corley</author>
<author>Rada Mihalcea</author>
</authors>
<title>Measuring the semantic similarity of texts.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment,</booktitle>
<pages>13--18</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="11379" citStr="Corley and Mihalcea, 2005" startWordPosition="1847" endWordPosition="1850">t we want consider and ρ is the maximal outdegree observed in the two trees. However the average running time again tends to be linear for natural language syntactic trees (Moschitti, 2006a). 2.3 Lexical Semantic Kernel Given two text fragments d1 and d2 E D (the text fragment set), a general lexical kernel (Basili et al., 2005) defines their similarity as: K(d1, d2) = � (ω1ω2) X Q(w1, w2) (1) w1∈d1,w2∈d2 where ω1 and ω2 are the weights of the words (features) w1 and w2 in the documents d1 and d2, respectively, and Q is a term similarity function, e.g. (Pedersen et al., 2004b; Sahlgren, 2006; Corley and Mihalcea, 2005; Mihalcea et al., 2005). Technically, any Q can be used, provided that the resulting Gram matrix, G = K(d1, d2) bd1, d2 E D is positive semi-definite (Shawe-Taylor and Cristianini, 2004) (D is typically the training text set). We determine the term similarity function through distributional analysis (Pado and Lapata, 2007), according to the idea that the meaning of a word can be described by the set of textual contexts in which it appears (Distributional Hypothesis, (Harris, 1964)). The contexts are words appearing in a n-window with target words: such a space models a generic notion of seman</context>
</contexts>
<marker>Corley, Mihalcea, 2005</marker>
<rawString>Courtney Corley and Rada Mihalcea. 2005. Measuring the semantic similarity of texts. In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment, pages 13–18, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jim Cowie</author>
<author>Joe Guthrie</author>
<author>Louise Guthrie</author>
</authors>
<title>Lexical disambiguation using simulated annealing.</title>
<date>1992</date>
<booktitle>In in COLING,</booktitle>
<pages>359--365</pages>
<contexts>
<context position="1991" citStr="Cowie et al., 1992" startWordPosition="287" endWordPosition="290">lity of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature enginee</context>
</contexts>
<marker>Cowie, Guthrie, Guthrie, 1992</marker>
<rawString>Jim Cowie, Joe Guthrie, and Louise Guthrie. 1992. Lexical disambiguation using simulated annealing. In in COLING, pages 359–365.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nello Cristianini</author>
<author>John Shawe-Taylor</author>
<author>Huma Lodhi</author>
</authors>
<title>Latent semantic kernels.</title>
<date>2001</date>
<booktitle>Proceedings of ICML-01, 18th International Conference on Machine Learning,</booktitle>
<pages>66--73</pages>
<editor>In Carla Brodley and Andrea Danyluk, editors,</editor>
<publisher>Morgan Kaufmann Publishers,</publisher>
<location>Williams College, US.</location>
<contexts>
<context position="12980" citStr="Cristianini et al., 2001" startWordPosition="2128" endWordPosition="2131">= Ul5lV T l in which only the first l columns of U and V are used, and only the first l greatest singular values are considered. This approximation supplies a way to project a generic term wi into the lµ (A2 _+ E _ I1,I2,l(�I1)=l(I2) Ad(�I1)+d(�I2) l( �I1) H j=1 1036 dimensional space using W = UlS1/2 l , where each row corresponds to the representation vectors ~wi. Therefore, given two words w1 and w2, the term similarity function σ is estimated as the cosine similarity between the corresponding projections ~w1, ~w2, 11 ~w11111 ~w211. The latent semantic kernels (Siolas and d’Alch Buc, 2000; Cristianini et al., 2001) derive G by applying LSA, resulting in a valid kernel. Another methods to design a valid kernel is to represent words as word vectors and compute σ as their scalar product between such vectors. For example, in (Bloehdorn et al., 2006), bag of hyponyms and hypernyms (up to a certain level of WordNet hierarchy) were used to build such vectors. We will refer to such similarity as WL (word list). 3 Smoothing Partial Tree Kernel (SPTK) Combining lexical and structural kernels provides clear advantages on all-vs-all words similarity, which tends to semantically diverge. Indeed syntax provides the n</context>
</contexts>
<marker>Cristianini, Shawe-Taylor, Lodhi, 2001</marker>
<rawString>Nello Cristianini, John Shawe-Taylor, and Huma Lodhi. 2001. Latent semantic kernels. In Carla Brodley and Andrea Danyluk, editors, Proceedings of ICML-01, 18th International Conference on Machine Learning, pages 66–73, Williams College, US. Morgan Kaufmann Publishers, San Francisco, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Jeffrey Sorensen</author>
</authors>
<title>Dependency tree kernels for relation extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>423--429</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="5204" citStr="Culotta and Sorensen, 2004" startWordPosition="784" endWordPosition="787">computed by kernel funcplied to dependency structures, e.g. see experiments tions by exploiting the following dual formulation: and motivation in (Moschitti, 2006a). Additionally, P to our knowledge, there is no previous study that i=1..lyiαiφ(oi)φ(o) + b = 0, where oi and o are clearly describes how dependency structures should two objects, φ is a mapping from the objects to feabe converted in trees to be fully and effectively ex- ture vectors ~xi and φ(oi)φ(o) = K(oi, o) is a kerploitable by convolution kernels. Indeed, although nel function implicitly defining such mapping. In the work in (Culotta and Sorensen, 2004) defines a case of structural kernels, K determines the shape of dependency tree also using node similarity, it is not the substructures describing the objects above. The a convolution kernel: this results in a much poorer most general kind of kernels used in NLP are string feature space. kernels, e.g. (Shawe-Taylor and Cristianini, 2004), In this paper, we propose a study of convolution the Syntactic Tree Kernels (Collins and Duffy, 2002) kernels for dependency structures aiming at jointly and the Partial Tree Kernels (Moschitti, 2006a). modeling syntactic and lexical semantic similarity. 2.1</context>
</contexts>
<marker>Culotta, Sorensen, 2004</marker>
<rawString>Aron Culotta and Jeffrey Sorensen. 2004. Dependency tree kernels for relation extraction. In Proceedings of ACL, pages 423–429, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chad Cumby</author>
<author>Dan Roth</author>
</authors>
<title>Kernel Methods for Relational Learning.</title>
<date>2003</date>
<booktitle>In Proceedings of ICML</booktitle>
<contexts>
<context position="2770" citStr="Cumby and Roth, 2003" startWordPosition="408" endWordPosition="411">re recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency tr</context>
</contexts>
<marker>Cumby, Roth, 2003</marker>
<rawString>Chad Cumby and Dan Roth. 2003. Kernel Methods for Relational Learning. In Proceedings of ICML 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Daniel Marcu</author>
</authors>
<title>Np bracketing by maximum entropy tagging and SVM reranking.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP’04.</booktitle>
<marker>Daum´e, Marcu, 2004</marker>
<rawString>Hal Daum´e III and Daniel Marcu. 2004. Np bracketing by maximum entropy tagging and SVM reranking. In Proceedings of EMNLP’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason V Davis</author>
<author>Brian Kulis</author>
<author>Prateek Jain</author>
<author>Suvrit Sra</author>
<author>Inderjit S Dhillon</author>
</authors>
<title>Information-theoretic metric learning.</title>
<date>2007</date>
<booktitle>In Proceedings of the 24th international conference on Machine learning, ICML ’07,</booktitle>
<pages>209--216</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1674" citStr="Davis et al., 2007" startWordPosition="236" endWordPosition="239"> dependency kernels. 1 Introduction A central topic in Natural Language Processing is the design of lexical and syntactic features suitable for the target application. The selection of effective patterns composed of syntactic dependencies and lexical constraints is typically a complex task. Additionally, the availability of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (</context>
</contexts>
<marker>Davis, Kulis, Jain, Sra, Dhillon, 2007</marker>
<rawString>Jason V. Davis, Brian Kulis, Prateek Jain, Suvrit Sra, and Inderjit S. Dhillon. 2007. Information-theoretic metric learning. In Proceedings of the 24th international conference on Machine learning, ICML ’07, pages 209–216, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linton C Freeman</author>
</authors>
<date>1977</date>
<journal>A Set of Measures of Centrality Based on Betweenness. Sociometry,</journal>
<volume>40</volume>
<issue>1</issue>
<contexts>
<context position="1826" citStr="Freeman, 1977" startWordPosition="263" endWordPosition="264">lication. The selection of effective patterns composed of syntactic dependencies and lexical constraints is typically a complex task. Additionally, the availability of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial </context>
</contexts>
<marker>Freeman, 1977</marker>
<rawString>Linton C. Freeman. 1977. A Set of Measures of Centrality Based on Betweenness. Sociometry, 40(1):35–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hagen F¨urstenau</author>
<author>Mirella Lapata</author>
</authors>
<title>Graph alignment for semi-supervised semantic role labeling. In</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP ’09,</booktitle>
<pages>11--20</pages>
<location>Morristown, NJ, USA.</location>
<marker>F¨urstenau, Lapata, 2009</marker>
<rawString>Hagen F¨urstenau and Mirella Lapata. 2009. Graph alignment for semi-supervised semantic role labeling. In In Proceedings of EMNLP ’09, pages 11–20, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Giuglea</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Knowledge Discovering using FrameNet, VerbNet and PropBank. In</title>
<date>2004</date>
<booktitle>In Proceedings of the Workshop on Ontology and Knowledge Discovering at ECML 2004,</booktitle>
<location>Pisa, Italy.</location>
<contexts>
<context position="30482" citStr="Giuglea and Moschitti, 2004" startWordPosition="5117" endWordPosition="5120">e most of the NLP applications are based on syntactic and lexical representations, SPTK will have a major impact in most of them, e.g.: 6Using one of the 8 processors of an Intel(R) Xeon(R) CPU E5430 @ 2.66GHz machine, 32Gb Ram. • Question Answering, the high results for QC will positively impact on the overall task. • SRL, SPTK alone reaches the state-of-the-art (SOA) (only 0.7% less) in FrameNet role classification. This is very valuable as previous work showed that tree kernels (TK) alone perform lower than models based on manually engineered features for SRL tasks, e.g., (Moschitti, 2004; Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti, 2006b; Che et al., 2006; Moschitti et al., 2008). Thus for the first time in an SRL task, a general tree kernel reaches the same accuracy of heavy manual feature design. This also suggests an improvement when used in combinations with manual feature vectors. • Relation Extraction and Pronominal Coreference, whose state-of-the-art for some tasks is achieved with the simple STK-CT (see (Zhang et al., 2006) and (Yang et al., 2006; Versley et al., 2008), respectively). • In word sense disambiguation tasks, SPTK can generalize context according to syntactic</context>
</contexts>
<marker>Giuglea, Moschitti, 2004</marker>
<rawString>Ana-Maria Giuglea and Alessandro Moschitti. 2004. Knowledge Discovering using FrameNet, VerbNet and PropBank. In In Proceedings of the Workshop on Ontology and Knowledge Discovering at ECML 2004, Pisa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A-M Giuglea</author>
<author>A Moschitti</author>
</authors>
<title>Semantic role labeling via framenet, verbnet and propbank.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="30511" citStr="Giuglea and Moschitti, 2006" startWordPosition="5121" endWordPosition="5125">s are based on syntactic and lexical representations, SPTK will have a major impact in most of them, e.g.: 6Using one of the 8 processors of an Intel(R) Xeon(R) CPU E5430 @ 2.66GHz machine, 32Gb Ram. • Question Answering, the high results for QC will positively impact on the overall task. • SRL, SPTK alone reaches the state-of-the-art (SOA) (only 0.7% less) in FrameNet role classification. This is very valuable as previous work showed that tree kernels (TK) alone perform lower than models based on manually engineered features for SRL tasks, e.g., (Moschitti, 2004; Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti, 2006b; Che et al., 2006; Moschitti et al., 2008). Thus for the first time in an SRL task, a general tree kernel reaches the same accuracy of heavy manual feature design. This also suggests an improvement when used in combinations with manual feature vectors. • Relation Extraction and Pronominal Coreference, whose state-of-the-art for some tasks is achieved with the simple STK-CT (see (Zhang et al., 2006) and (Yang et al., 2006; Versley et al., 2008), respectively). • In word sense disambiguation tasks, SPTK can generalize context according to syntactic and semantic constraints (se</context>
</contexts>
<marker>Giuglea, Moschitti, 2006</marker>
<rawString>A.-M. Giuglea and A. Moschitti. 2006. Semantic role labeling via framenet, verbnet and propbank. In Proceedings of ACL, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alfio Gliozzo</author>
<author>Claudio Giuliano</author>
<author>Carlo Strapparava</author>
</authors>
<title>Domain kernels for word sense disambiguation.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL’05,</booktitle>
<pages>403--410</pages>
<contexts>
<context position="2886" citStr="Gliozzo et al., 2005" startWordPosition="429" endWordPosition="432">red in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms). This implies</context>
</contexts>
<marker>Gliozzo, Giuliano, Strapparava, 2005</marker>
<rawString>Alfio Gliozzo, Claudio Giuliano, and Carlo Strapparava. 2005. Domain kernels for word sense disambiguation. In Proceedings of ACL’05, pages 403–410.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Golub</author>
<author>W Kahan</author>
</authors>
<title>Calculating the singular values and pseudo-inverse of a matrix.</title>
<date>1965</date>
<journal>Journal of the Society for Industrial and Applied Mathematics: Series B, Numerical Analysis,</journal>
<volume>2</volume>
<issue>2</issue>
<pages>205--224</pages>
<contexts>
<context position="12241" citStr="Golub and Kahan, 1965" startWordPosition="1987" endWordPosition="1990"> the term similarity function through distributional analysis (Pado and Lapata, 2007), according to the idea that the meaning of a word can be described by the set of textual contexts in which it appears (Distributional Hypothesis, (Harris, 1964)). The contexts are words appearing in a n-window with target words: such a space models a generic notion of semantic relatedness, i.e. two words close in the space are likely to be either in paradigmatic or syntagmatic relation as in (Sahlgren, 2006). The original word-by-word context matrix M is decomposed through Singular Value Decomposition (SVD) (Golub and Kahan, 1965) into the product of three new matrices: U, 5, and V so that 5 is diagonal and M = U5V T. M is approximated by Ml = Ul5lV T l in which only the first l columns of U and V are used, and only the first l greatest singular values are considered. This approximation supplies a way to project a generic term wi into the lµ (A2 _+ E _ I1,I2,l(�I1)=l(I2) Ad(�I1)+d(�I2) l( �I1) H j=1 1036 dimensional space using W = UlS1/2 l , where each row corresponds to the representation vectors ~wi. Therefore, given two words w1 and w2, the term similarity function σ is estimated as the cosine similarity between th</context>
</contexts>
<marker>Golub, Kahan, 1965</marker>
<rawString>G. Golub and W. Kahan. 1965. Calculating the singular values and pseudo-inverse of a matrix. Journal of the Society for Industrial and Applied Mathematics: Series B, Numerical Analysis, 2(2):pp. 205–224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<title>Distributional structure.</title>
<date>1964</date>
<booktitle>The Philosophy of Linguistics.</booktitle>
<editor>In Jerrold J. Katz and Jerry A. Fodor, editors,</editor>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="11865" citStr="Harris, 1964" startWordPosition="1928" endWordPosition="1929"> d2, respectively, and Q is a term similarity function, e.g. (Pedersen et al., 2004b; Sahlgren, 2006; Corley and Mihalcea, 2005; Mihalcea et al., 2005). Technically, any Q can be used, provided that the resulting Gram matrix, G = K(d1, d2) bd1, d2 E D is positive semi-definite (Shawe-Taylor and Cristianini, 2004) (D is typically the training text set). We determine the term similarity function through distributional analysis (Pado and Lapata, 2007), according to the idea that the meaning of a word can be described by the set of textual contexts in which it appears (Distributional Hypothesis, (Harris, 1964)). The contexts are words appearing in a n-window with target words: such a space models a generic notion of semantic relatedness, i.e. two words close in the space are likely to be either in paradigmatic or syntagmatic relation as in (Sahlgren, 2006). The original word-by-word context matrix M is decomposed through Singular Value Decomposition (SVD) (Golub and Kahan, 1965) into the product of three new matrices: U, 5, and V so that 5 is diagonal and M = U5V T. M is approximated by Ml = Ul5lV T l in which only the first l columns of U and V are used, and only the first l greatest singular valu</context>
</contexts>
<marker>Harris, 1964</marker>
<rawString>Zellig Harris. 1964. Distributional structure. In Jerrold J. Katz and Jerry A. Fodor, editors, The Philosophy of Linguistics. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Estimating the generalization performance of a SVM efficiently.</title>
<date>2000</date>
<booktitle>In Proceedings of ICML’00.</booktitle>
<contexts>
<context position="18998" citStr="Joachims, 2000" startWordPosition="3159" endWordPosition="3160">tuency trees and different kernels to derive the best syntactic paradigm for convolution kernels. Most importantly, the role of lexical similarity embedded in syntactic structures will be investigated. For this purpose, we first carry out extensive experiments on coarse and fine grained QC and then we verify our findings on a completely different task, i.e. Argument Classification in SRL. 5.1 General experimental setup Tools: for SVM learning, we extended the SVMLightTK software3 (Moschitti, 2006a) (which in3http://disi.unitn.it/moschitti/Tree-Kernel.htm cludes structural kernels in SVMLight (Joachims, 2000)) with the smooth match between tree nodes. For generating constituency trees, we used the Charniak parser (Charniak, 2000) whereas we applied LTH syntactic parser (described in (Johansson and Nugues, 2008a)) to generate dependency trees. Lexical Similarity: we used the Eq. 1 with ω1 = ω2 = 1 and Q is derived with both approaches described in Sec. 2.3. The first approach is LSA-based: LSA was applied to ukWak (Baroni et al., 2009), which is a large scale document collection made by 2 billion tokens. More specifically, to build the matrix M, POS tagging is first applied to build rows with pairs</context>
</contexts>
<marker>Joachims, 2000</marker>
<rawString>T. Joachims. 2000. Estimating the generalization performance of a SVM efficiently. In Proceedings of ICML’00.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Reranking models in fine-grained opinion analysis.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference of Computational Linguistics (Coling</booktitle>
<pages>519--527</pages>
<location>Beijing, China.</location>
<contexts>
<context position="31366" citStr="Johansson and Moschitti, 2010" startWordPosition="5249" endWordPosition="5252"> in combinations with manual feature vectors. • Relation Extraction and Pronominal Coreference, whose state-of-the-art for some tasks is achieved with the simple STK-CT (see (Zhang et al., 2006) and (Yang et al., 2006; Versley et al., 2008), respectively). • In word sense disambiguation tasks, SPTK can generalize context according to syntactic and semantic constraints (selectional restrictions) making very effective distributional semantic approaches. • In Opinion Mining SPTK will allow to match sentiment words within their corresponding syntactic counterparts and improve the stateof-the-art (Johansson and Moschitti, 2010b; Johansson and Moschitti, 2010a). • Experiments on Recognizing Textual Entailment (RTE) tasks, the use of SSTK (instead of STK-CT) improved the state-of-the-art (Mehdad et al., 2010). SPTK may provide further enhancement and innovative and effective dependency models. The above points also suggest many promising future research directions, which we would like to explore. Acknowledgements This work has been partially supported by the EC project FP247758: Trustworthy Eternal Systems via Evolving Software, Data and Knowledge (EternalS). copy::v VBP ROOT bootlegger::n NMOD DT 12: LCT Examples fo</context>
</contexts>
<marker>Johansson, Moschitti, 2010</marker>
<rawString>Richard Johansson and Alessandro Moschitti. 2010a. Reranking models in fine-grained opinion analysis. In Proceedings of the 23rd International Conference of Computational Linguistics (Coling 2010), pages 519– 527, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Syntactic and semantic structure for opinion expression detection.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>67--76</pages>
<location>Uppsala,</location>
<contexts>
<context position="31366" citStr="Johansson and Moschitti, 2010" startWordPosition="5249" endWordPosition="5252"> in combinations with manual feature vectors. • Relation Extraction and Pronominal Coreference, whose state-of-the-art for some tasks is achieved with the simple STK-CT (see (Zhang et al., 2006) and (Yang et al., 2006; Versley et al., 2008), respectively). • In word sense disambiguation tasks, SPTK can generalize context according to syntactic and semantic constraints (selectional restrictions) making very effective distributional semantic approaches. • In Opinion Mining SPTK will allow to match sentiment words within their corresponding syntactic counterparts and improve the stateof-the-art (Johansson and Moschitti, 2010b; Johansson and Moschitti, 2010a). • Experiments on Recognizing Textual Entailment (RTE) tasks, the use of SSTK (instead of STK-CT) improved the state-of-the-art (Mehdad et al., 2010). SPTK may provide further enhancement and innovative and effective dependency models. The above points also suggest many promising future research directions, which we would like to explore. Acknowledgements This work has been partially supported by the EC project FP247758: Trustworthy Eternal Systems via Evolving Software, Data and Knowledge (EternalS). copy::v VBP ROOT bootlegger::n NMOD DT 12: LCT Examples fo</context>
</contexts>
<marker>Johansson, Moschitti, 2010</marker>
<rawString>Richard Johansson and Alessandro Moschitti. 2010b. Syntactic and semantic structure for opinion expression detection. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 67–76, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Pierre Nugues</author>
</authors>
<title>Dependency-based syntactic–semantic analysis with PropBank and NomBank.</title>
<date>2008</date>
<booktitle>In CoNLL 2008: Proceedings of the Twelfth Conference on Natural Language Learning,</booktitle>
<pages>183--187</pages>
<location>Manchester, United Kingdom.</location>
<contexts>
<context position="19203" citStr="Johansson and Nugues, 2008" startWordPosition="3188" endWordPosition="3191">igated. For this purpose, we first carry out extensive experiments on coarse and fine grained QC and then we verify our findings on a completely different task, i.e. Argument Classification in SRL. 5.1 General experimental setup Tools: for SVM learning, we extended the SVMLightTK software3 (Moschitti, 2006a) (which in3http://disi.unitn.it/moschitti/Tree-Kernel.htm cludes structural kernels in SVMLight (Joachims, 2000)) with the smooth match between tree nodes. For generating constituency trees, we used the Charniak parser (Charniak, 2000) whereas we applied LTH syntactic parser (described in (Johansson and Nugues, 2008a)) to generate dependency trees. Lexical Similarity: we used the Eq. 1 with ω1 = ω2 = 1 and Q is derived with both approaches described in Sec. 2.3. The first approach is LSA-based: LSA was applied to ukWak (Baroni et al., 2009), which is a large scale document collection made by 2 billion tokens. More specifically, to build the matrix M, POS tagging is first applied to build rows with pairs (lemma, ::POS), or lemma::POS in brief. The contexts of such items are the columns of M and are short windows of size [−3, +3], centered on the items. This allows for better capturing syntactic properties</context>
<context position="27398" citStr="Johansson and Nugues, 2008" startWordPosition="4608" endWordPosition="4611">a very large number of sequences of nodes, when the similarity is active. This increases the complexity, which results in an order higher than 2. 5.5 FrameNet Role Classification Experiments To verify that our findings are general and that our syntactic/semantic dependency kernels can be effectively exploited for diverse NLP tasks, we experimented with a completely different application, i.e. FrameNet SRL classification (gold standard boundaries). We used the FrameNet version 1.3 with the 90/10% split between training and test set (i.e 271,560 and 30,173 examples respectively), as defined in (Johansson and Nugues, 2008b), one of the best system for FrameNet parsing. We used the LTH dependency parser. LSA was applied to the BNC corpus, the source of the FrameNet annotations. For each of 648 frames, we applied SVM along with the best models for QC, i.e. GRCT and LCT, to learn its associated binary role classifiers (RC) for a total of 4,254 classifiers. For example, Figure 12 shows the LCT representation of the first two roles of the following sentence: [Bootleggers]CREATOR, then copy [the film]ORIGINAL [onto hundreds of VHS tapes]GOAL Table 2 shows the results of the different multiclassifiers. GRCT and LCT s</context>
</contexts>
<marker>Johansson, Nugues, 2008</marker>
<rawString>Richard Johansson and Pierre Nugues. 2008a. Dependency-based syntactic–semantic analysis with PropBank and NomBank. In CoNLL 2008: Proceedings of the Twelfth Conference on Natural Language Learning, pages 183–187, Manchester, United Kingdom.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Pierre Nugues</author>
</authors>
<title>The effect of syntactic representation on semantic role labeling.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>18--22</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="19203" citStr="Johansson and Nugues, 2008" startWordPosition="3188" endWordPosition="3191">igated. For this purpose, we first carry out extensive experiments on coarse and fine grained QC and then we verify our findings on a completely different task, i.e. Argument Classification in SRL. 5.1 General experimental setup Tools: for SVM learning, we extended the SVMLightTK software3 (Moschitti, 2006a) (which in3http://disi.unitn.it/moschitti/Tree-Kernel.htm cludes structural kernels in SVMLight (Joachims, 2000)) with the smooth match between tree nodes. For generating constituency trees, we used the Charniak parser (Charniak, 2000) whereas we applied LTH syntactic parser (described in (Johansson and Nugues, 2008a)) to generate dependency trees. Lexical Similarity: we used the Eq. 1 with ω1 = ω2 = 1 and Q is derived with both approaches described in Sec. 2.3. The first approach is LSA-based: LSA was applied to ukWak (Baroni et al., 2009), which is a large scale document collection made by 2 billion tokens. More specifically, to build the matrix M, POS tagging is first applied to build rows with pairs (lemma, ::POS), or lemma::POS in brief. The contexts of such items are the columns of M and are short windows of size [−3, +3], centered on the items. This allows for better capturing syntactic properties</context>
<context position="27398" citStr="Johansson and Nugues, 2008" startWordPosition="4608" endWordPosition="4611">a very large number of sequences of nodes, when the similarity is active. This increases the complexity, which results in an order higher than 2. 5.5 FrameNet Role Classification Experiments To verify that our findings are general and that our syntactic/semantic dependency kernels can be effectively exploited for diverse NLP tasks, we experimented with a completely different application, i.e. FrameNet SRL classification (gold standard boundaries). We used the FrameNet version 1.3 with the 90/10% split between training and test set (i.e 271,560 and 30,173 examples respectively), as defined in (Johansson and Nugues, 2008b), one of the best system for FrameNet parsing. We used the LTH dependency parser. LSA was applied to the BNC corpus, the source of the FrameNet annotations. For each of 648 frames, we applied SVM along with the best models for QC, i.e. GRCT and LCT, to learn its associated binary role classifiers (RC) for a total of 4,254 classifiers. For example, Figure 12 shows the LCT representation of the first two roles of the following sentence: [Bootleggers]CREATOR, then copy [the film]ORIGINAL [onto hundreds of VHS tapes]GOAL Table 2 shows the results of the different multiclassifiers. GRCT and LCT s</context>
</contexts>
<marker>Johansson, Nugues, 2008</marker>
<rawString>Richard Johansson and Pierre Nugues. 2008b. The effect of syntactic representation on semantic role labeling. In Proceedings of COLING, Manchester, UK, August 18-22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Fast methods for kernel-based text analysis.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL’03.</booktitle>
<contexts>
<context position="2748" citStr="Kudo and Matsumoto, 2003" startWordPosition="404" endWordPosition="407">itsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragment</context>
</contexts>
<marker>Kudo, Matsumoto, 2003</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2003. Fast methods for kernel-based text analysis. In Proceedings of ACL’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Jun Suzuki</author>
<author>Hideki Isozaki</author>
</authors>
<title>Boosting-based parse reranking with subtree features.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL’05.</booktitle>
<contexts>
<context position="2905" citStr="Kudo et al., 2005" startWordPosition="433" endWordPosition="436">; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms). This implies matching scores lo</context>
</contexts>
<marker>Kudo, Suzuki, Isozaki, 2005</marker>
<rawString>Taku Kudo, Jun Suzuki, and Hideki Isozaki. 2005. Boosting-based parse reranking with subtree features. In Proceedings of ACL’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Leacock</author>
<author>Martin Chodorow</author>
</authors>
<title>Combining Local Context and WordNet Similarity for Word Sense Identification, chapter 11,</title>
<date>1998</date>
<pages>265--283</pages>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="2093" citStr="Leacock and Chodorow, 1998" startWordPosition="303" endWordPosition="306"> or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, </context>
</contexts>
<marker>Leacock, Chodorow, 1998</marker>
<rawString>Claudia Leacock and Martin Chodorow, 1998. Combining Local Context and WordNet Similarity for Word Sense Identification, chapter 11, pages 265–283. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Li</author>
<author>D Roth</author>
</authors>
<title>Learning question classifiers.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL’02.</booktitle>
<contexts>
<context position="20134" citStr="Li and Roth, 2002" startWordPosition="3358" endWordPosition="3361">ally, to build the matrix M, POS tagging is first applied to build rows with pairs (lemma, ::POS), or lemma::POS in brief. The contexts of such items are the columns of M and are short windows of size [−3, +3], centered on the items. This allows for better capturing syntactic properties of words. The most frequent 20,000 items are selected along with their 20k contexts. The entries of M are the point-wise mutual information between them. The SVD reduction is then applied to M, with a dimensionality cut of l = 250. The second approach uses the similarity based on word list (WL) as provided in (Li and Roth, 2002). Models: SVM-LightTK is applied to the different tree representations discussed in Section 4. Since PTK and SPTK are typically used in our experiments, to have a more compact acronym for each model, we associate the latter with the name of the structure, i.e. this indicates that PTK is applied to it. Then the presence of the subscript WL and LSA indicates that SPTK is applied along with the corresponding similarity, e.g. LCTWL is the SPTK kernel applied to LCT structure, using WL similarity. We experiment with multi-classification, which we model through one-vs-all scheme by selecting the cat</context>
<context position="21652" citStr="Li and Roth, 2002" startWordPosition="3610" endWordPosition="3613">of the training) and concerns with the setting of the trade-off parameter (option - c) and the Leaf Weight (LeW) (see Sec. 5.2), which is used to linearly scale the contribution of the leaf nodes. In contrast, the cost-factor parameter of the SVM-LightTK is set as the ratio between the num1040 0 1000 2000 3000 4000 5000 Number of Examples 0 1000 2000 3000 4000 5000 Number of Examples Figure 10: Learning curves: comparison with similarity ber of negative and positive examples for attempting to have a balanced Precision/Recall. 5.2 QC experiments For these experiments, we used the UIUC dataset (Li and Roth, 2002). It is composed by a training set of 5,452 questions and a test set of 500 questions4. Question classes are organized in two levels: 6 coarse-grained classes (like ENTITY or HUMAN) and 50 fine-grained sub-classes (e.g. Plant, Food as subclasses of ENTITY). The outcome of the several kernels applied to several structures for the coarse and fine grained QC is reported in Table 1. The first column shows the experimented models, obtained by applying PTK/SPTK to the structures described in Sec. 4. The last two rows are: CT-STK, i.e. STK applied to a constituency tree and BOW, which is a linear ker</context>
</contexts>
<marker>Li, Roth, 2002</marker>
<rawString>X. Li and D. Roth. 2002. Learning question classifiers. In Proceedings of ACL’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Alessandro Moschitti</author>
<author>Fabio Massimo Zanzotto</author>
</authors>
<title>Syntactic/semantic structures for textual entailment recognition.</title>
<date>2010</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>1020--1028</pages>
<contexts>
<context position="4048" citStr="Mehdad et al., 2010" startWordPosition="602" endWordPosition="605">des (i.e. they have different surface forms). This implies matching scores lower than 1, depending on the semantic similarity of the corresponding leaves in the syntactic fragments. Although this kernel achieves state-of-the-art performance in NLP tasks, such as Question Classifica1034 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1034–1046, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics tion (Bloehdorn and Moschitti, 2007b) and Textual trees. Section 5 presents the experimental evaluation Entailment (Mehdad et al., 2010), it offers clearly for QC and SRL. Section 6 derives the conclusions. possibility of improvement: (i) better possibility to 2 Kernel Background exploit semantic smoothing since, e.g., trivially STK In kernel-based machines, both learning and classionly matches the syntactic structure apple/orange fication algorithms only depend on the inner prodwhen comparing the big beautiful apple to a nice uct between instances. This in several cases can be large orange; and (ii) STK cannot be effectively ap- efficiently and implicitly computed by kernel funcplied to dependency structures, e.g. see experim</context>
</contexts>
<marker>Mehdad, Moschitti, Zanzotto, 2010</marker>
<rawString>Yashar Mehdad, Alessandro Moschitti, and Fabio Massimo Zanzotto. 2010. Syntactic/semantic structures for textual entailment recognition. In HLT-NAACL, pages 1020–1028.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Courtney Corley</author>
<author>Carlo Strapparava</author>
</authors>
<title>Corpus-based and knowledge-based measures of text semantic similarity.</title>
<date>2005</date>
<booktitle>In Proceedings of the American Association forArtificial Intelligence (AAAI</booktitle>
<location>Boston,</location>
<contexts>
<context position="11403" citStr="Mihalcea et al., 2005" startWordPosition="1851" endWordPosition="1854"> the maximal outdegree observed in the two trees. However the average running time again tends to be linear for natural language syntactic trees (Moschitti, 2006a). 2.3 Lexical Semantic Kernel Given two text fragments d1 and d2 E D (the text fragment set), a general lexical kernel (Basili et al., 2005) defines their similarity as: K(d1, d2) = � (ω1ω2) X Q(w1, w2) (1) w1∈d1,w2∈d2 where ω1 and ω2 are the weights of the words (features) w1 and w2 in the documents d1 and d2, respectively, and Q is a term similarity function, e.g. (Pedersen et al., 2004b; Sahlgren, 2006; Corley and Mihalcea, 2005; Mihalcea et al., 2005). Technically, any Q can be used, provided that the resulting Gram matrix, G = K(d1, d2) bd1, d2 E D is positive semi-definite (Shawe-Taylor and Cristianini, 2004) (D is typically the training text set). We determine the term similarity function through distributional analysis (Pado and Lapata, 2007), according to the idea that the meaning of a word can be described by the set of textual contexts in which it appears (Distributional Hypothesis, (Harris, 1964)). The contexts are words appearing in a n-window with target words: such a space models a generic notion of semantic relatedness, i.e. tw</context>
</contexts>
<marker>Mihalcea, Corley, Strapparava, 2005</marker>
<rawString>Rada Mihalcea, Courtney Corley, and Carlo Strapparava. 2005. Corpus-based and knowledge-based measures of text semantic similarity. In Proceedings of the American Association forArtificial Intelligence (AAAI 2006), Boston, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
</authors>
<title>unsupervised large-vocabulary word sense disambiguation with graph-based algorithms for sequence data labeling.</title>
<date>2005</date>
<booktitle>In In HLT/EMNLP</booktitle>
<pages>411--418</pages>
<contexts>
<context position="2288" citStr="Mihalcea, 2005" startWordPosition="335" endWordPosition="336"> or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; </context>
<context position="11379" citStr="Mihalcea, 2005" startWordPosition="1849" endWordPosition="1850">onsider and ρ is the maximal outdegree observed in the two trees. However the average running time again tends to be linear for natural language syntactic trees (Moschitti, 2006a). 2.3 Lexical Semantic Kernel Given two text fragments d1 and d2 E D (the text fragment set), a general lexical kernel (Basili et al., 2005) defines their similarity as: K(d1, d2) = � (ω1ω2) X Q(w1, w2) (1) w1∈d1,w2∈d2 where ω1 and ω2 are the weights of the words (features) w1 and w2 in the documents d1 and d2, respectively, and Q is a term similarity function, e.g. (Pedersen et al., 2004b; Sahlgren, 2006; Corley and Mihalcea, 2005; Mihalcea et al., 2005). Technically, any Q can be used, provided that the resulting Gram matrix, G = K(d1, d2) bd1, d2 E D is positive semi-definite (Shawe-Taylor and Cristianini, 2004) (D is typically the training text set). We determine the term similarity function through distributional analysis (Pado and Lapata, 2007), according to the idea that the meaning of a word can be described by the set of textual contexts in which it appears (Distributional Hypothesis, (Harris, 1964)). The contexts are words appearing in a n-window with target words: such a space models a generic notion of seman</context>
</contexts>
<marker>Mihalcea, 2005</marker>
<rawString>Rada Mihalcea. 2005. unsupervised large-vocabulary word sense disambiguation with graph-based algorithms for sequence data labeling. In In HLT/EMNLP 2005, pages 411–418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Silvia Quarteroni</author>
<author>Roberto Basili</author>
<author>Suresh Manandhar</author>
</authors>
<title>Exploiting syntactic and shallow semantic kernels for question/answer classification.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL’07.</booktitle>
<contexts>
<context position="22753" citStr="Moschitti et al., 2007" startWordPosition="3799" endWordPosition="3802">described in Sec. 4. The last two rows are: CT-STK, i.e. STK applied to a constituency tree and BOW, which is a linear ker4http://cogcomp.cs.illinois.edu/Data/QA/QC/ nel applied to lexical vectors. Column 2, 3 and 4 report the accuracy using no, LSA and WL similarity, where LeW is the amplifying parameter, i.e. a weight associated with the leaves in the tree. The last three columns refer to the fine grained task. It is worth nothing that when no similarity is applied: (i) BOW produces high accuracy, i.e. 88.8% but it is improved by STK (the current state-of-theart5 in QC (Zhang and Lee, 2003; Moschitti et al., 2007)); (ii) PTK applied to the same tree of STK produces a slightly lower value (non-statistically significant difference); (iii) interestingly, when PTK is instead applied to dependency structures, it improves STK, i.e. 91.60% vs 91.40% (although not significantly); and (iv) LCT, strongly based on lexical nodes, is the least accurate, i.e 90.80% since it is obviously subject to data sparseness (fragments only composed by lexicals are very sparse). The very important results can be noted when lexical similarity is used, i.e. SPTK is applied: (a) all the syntactic-base structures using both LSA or </context>
</contexts>
<marker>Moschitti, Quarteroni, Basili, Manandhar, 2007</marker>
<rawString>Alessandro Moschitti, Silvia Quarteroni, Roberto Basili, and Suresh Manandhar. 2007. Exploiting syntactic and shallow semantic kernels for question/answer classification. In Proceedings of ACL’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Daniele Pighin</author>
<author>Roberto Basili</author>
</authors>
<title>Tree kernels for semantic role labeling.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="30572" citStr="Moschitti et al., 2008" startWordPosition="5132" endWordPosition="5135">ave a major impact in most of them, e.g.: 6Using one of the 8 processors of an Intel(R) Xeon(R) CPU E5430 @ 2.66GHz machine, 32Gb Ram. • Question Answering, the high results for QC will positively impact on the overall task. • SRL, SPTK alone reaches the state-of-the-art (SOA) (only 0.7% less) in FrameNet role classification. This is very valuable as previous work showed that tree kernels (TK) alone perform lower than models based on manually engineered features for SRL tasks, e.g., (Moschitti, 2004; Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti, 2006b; Che et al., 2006; Moschitti et al., 2008). Thus for the first time in an SRL task, a general tree kernel reaches the same accuracy of heavy manual feature design. This also suggests an improvement when used in combinations with manual feature vectors. • Relation Extraction and Pronominal Coreference, whose state-of-the-art for some tasks is achieved with the simple STK-CT (see (Zhang et al., 2006) and (Yang et al., 2006; Versley et al., 2008), respectively). • In word sense disambiguation tasks, SPTK can generalize context according to syntactic and semantic constraints (selectional restrictions) making very effective distributional </context>
</contexts>
<marker>Moschitti, Pighin, Basili, 2008</marker>
<rawString>Alessandro Moschitti, Daniele Pighin, and Roberto Basili. 2008. Tree kernels for semantic role labeling. Computational Linguistics, 34(2):193–224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Moschitti</author>
</authors>
<title>A study on convolution kernels for shallow semantic parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="30453" citStr="Moschitti, 2004" startWordPosition="5114" endWordPosition="5116">SRL. Indeed, since most of the NLP applications are based on syntactic and lexical representations, SPTK will have a major impact in most of them, e.g.: 6Using one of the 8 processors of an Intel(R) Xeon(R) CPU E5430 @ 2.66GHz machine, 32Gb Ram. • Question Answering, the high results for QC will positively impact on the overall task. • SRL, SPTK alone reaches the state-of-the-art (SOA) (only 0.7% less) in FrameNet role classification. This is very valuable as previous work showed that tree kernels (TK) alone perform lower than models based on manually engineered features for SRL tasks, e.g., (Moschitti, 2004; Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti, 2006b; Che et al., 2006; Moschitti et al., 2008). Thus for the first time in an SRL task, a general tree kernel reaches the same accuracy of heavy manual feature design. This also suggests an improvement when used in combinations with manual feature vectors. • Relation Extraction and Pronominal Coreference, whose state-of-the-art for some tasks is achieved with the simple STK-CT (see (Zhang et al., 2006) and (Yang et al., 2006; Versley et al., 2008), respectively). • In word sense disambiguation tasks, SPTK can generalize c</context>
</contexts>
<marker>Moschitti, 2004</marker>
<rawString>A. Moschitti. 2004. A study on convolution kernels for shallow semantic parsing. In Proceedings of ACL, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Efficient convolution kernels for dependency and constituent syntactic trees.</title>
<date>2006</date>
<booktitle>In Proceedings of ECML’06,</booktitle>
<pages>318--329</pages>
<contexts>
<context position="4739" citStr="Moschitti, 2006" startWordPosition="707" endWordPosition="708">bility of improvement: (i) better possibility to 2 Kernel Background exploit semantic smoothing since, e.g., trivially STK In kernel-based machines, both learning and classionly matches the syntactic structure apple/orange fication algorithms only depend on the inner prodwhen comparing the big beautiful apple to a nice uct between instances. This in several cases can be large orange; and (ii) STK cannot be effectively ap- efficiently and implicitly computed by kernel funcplied to dependency structures, e.g. see experiments tions by exploiting the following dual formulation: and motivation in (Moschitti, 2006a). Additionally, P to our knowledge, there is no previous study that i=1..lyiαiφ(oi)φ(o) + b = 0, where oi and o are clearly describes how dependency structures should two objects, φ is a mapping from the objects to feabe converted in trees to be fully and effectively ex- ture vectors ~xi and φ(oi)φ(o) = K(oi, o) is a kerploitable by convolution kernels. Indeed, although nel function implicitly defining such mapping. In the work in (Culotta and Sorensen, 2004) defines a case of structural kernels, K determines the shape of dependency tree also using node similarity, it is not the substructure</context>
<context position="9966" citStr="Moschitti, 2006" startWordPosition="1593" endWordPosition="1594">ifferent then OSTK(n1, n2) = 0; (ii) if the productions at n1 and n2 are the same, and n1 and n2 have only leaf children then OSTK(n1,n2) = A; and (iii) if the productions at n1 and n2 are the same, and n1 and n2 are not pre-terminals then OSTK(n1,n2) = A�l(n1) j=1 (1 + OSTK(cjn1,cjn2)), where l(n1) is the number of children of n1 and cjn is the j-th child of the node n. Note that, since the productions are the same, l(n1) = l(n2) and the computational complexity of STK is O(|NT1||NT2|) but the average running time tends to be linear, i.e. O(|NT1|+|NT2|), for natural language syntactic trees (Moschitti, 2006a). 2.2.2 The Partial Tree Kernel (PTK) The computation of PTK is carried out by the following OPTK function: if the labels of n1 and n2 are different then OPTK(n1,n2) = 0; else OPTK(n1, n2) = IOP T K(cn1(�I1j), cn2(�I2j)) 1To have a similarity score between 0 and 1, a normalization in the kernel space, i.e. T K(T1 ,T2) is applied. √T K (T1 ,T1) × T K (T2 ,T2 ) where d(I1) = I1l(~I1)− �I11+1 and d( �I2) = �I2l(~I2)− I21 + 1. This way, we penalize both larger trees and child subsequences with gaps. PTK is more general than the STK as if we only consider the contribution of shared subsequences c</context>
<context position="15963" citStr="Moschitti, 2006" startWordPosition="2650" endWordPosition="2651">d µ elevated to any power only depends on the target fragment. Thus, it just gives an additional weight to the fragment and does not violate the Mercer’s conditions. In contrast, the multiplication by σ(n1, n2) does depend on both comparing examples, i.e. on n1 and n2. However, if the matrix [σ(n1, n2)]bn1, n2 E f E T is positive semi-definite, a decomposition exists such that σ(n1, n2) = φ(n1)φ(n2) =:�, Aσ(n1, n2) can be written as���� i=1 φ(n1)χi(n1)φ(n2)χi(n2) = ���� i=1φσ(n1)φσ(n2) (see Section 2.2), which proves SPTK to be a valid kernel. 3.3 Efficient Evaluation We followed the idea in (Moschitti, 2006a) for efficiently computing SPTK. We consider Eq. 2 evaluated with respect to sequences of different length p; it follows that m A(n1, n2) = µσ(n1, n2)(λ2 + E Ap(cn1,cn2)), p=1 where Ap evaluates the number of common subtrees rooted in subsequences of exactly p children (of n1 and n2) and m = min{l(cn1), l(cn2)}. Given the two child sequences s1a = cn1 and s2b = cn2 (a and b are the last children) Ap(s1a, s2b) = A(a, b) x xAp−1(s1[1 : i],s2[1 : r]) where s1[1 : i] and s2[1 : r] are the child subsequences from 1 to i and from 1 to r of s1 and s2. If we name the double summation term as Dp, we </context>
<context position="18884" citStr="Moschitti, 2006" startWordPosition="3149" endWordPosition="3150">s of representation, i.e. structure, for syntactic dependency parses. At the same time, we compare with the constituency trees and different kernels to derive the best syntactic paradigm for convolution kernels. Most importantly, the role of lexical similarity embedded in syntactic structures will be investigated. For this purpose, we first carry out extensive experiments on coarse and fine grained QC and then we verify our findings on a completely different task, i.e. Argument Classification in SRL. 5.1 General experimental setup Tools: for SVM learning, we extended the SVMLightTK software3 (Moschitti, 2006a) (which in3http://disi.unitn.it/moschitti/Tree-Kernel.htm cludes structural kernels in SVMLight (Joachims, 2000)) with the smooth match between tree nodes. For generating constituency trees, we used the Charniak parser (Charniak, 2000) whereas we applied LTH syntactic parser (described in (Johansson and Nugues, 2008a)) to generate dependency trees. Lexical Similarity: we used the Eq. 1 with ω1 = ω2 = 1 and Q is derived with both approaches described in Sec. 2.3. The first approach is LSA-based: LSA was applied to ukWak (Baroni et al., 2009), which is a large scale document collection made by</context>
<context position="30511" citStr="Moschitti, 2006" startWordPosition="5124" endWordPosition="5125">on syntactic and lexical representations, SPTK will have a major impact in most of them, e.g.: 6Using one of the 8 processors of an Intel(R) Xeon(R) CPU E5430 @ 2.66GHz machine, 32Gb Ram. • Question Answering, the high results for QC will positively impact on the overall task. • SRL, SPTK alone reaches the state-of-the-art (SOA) (only 0.7% less) in FrameNet role classification. This is very valuable as previous work showed that tree kernels (TK) alone perform lower than models based on manually engineered features for SRL tasks, e.g., (Moschitti, 2004; Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti, 2006b; Che et al., 2006; Moschitti et al., 2008). Thus for the first time in an SRL task, a general tree kernel reaches the same accuracy of heavy manual feature design. This also suggests an improvement when used in combinations with manual feature vectors. • Relation Extraction and Pronominal Coreference, whose state-of-the-art for some tasks is achieved with the simple STK-CT (see (Zhang et al., 2006) and (Yang et al., 2006; Versley et al., 2008), respectively). • In word sense disambiguation tasks, SPTK can generalize context according to syntactic and semantic constraints (se</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006a. Efficient convolution kernels for dependency and constituent syntactic trees. In Proceedings of ECML’06, pages 318–329.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Making tree kernels practical for natural language learning.</title>
<date>2006</date>
<booktitle>In Proccedings of EACL’06.</booktitle>
<contexts>
<context position="4739" citStr="Moschitti, 2006" startWordPosition="707" endWordPosition="708">bility of improvement: (i) better possibility to 2 Kernel Background exploit semantic smoothing since, e.g., trivially STK In kernel-based machines, both learning and classionly matches the syntactic structure apple/orange fication algorithms only depend on the inner prodwhen comparing the big beautiful apple to a nice uct between instances. This in several cases can be large orange; and (ii) STK cannot be effectively ap- efficiently and implicitly computed by kernel funcplied to dependency structures, e.g. see experiments tions by exploiting the following dual formulation: and motivation in (Moschitti, 2006a). Additionally, P to our knowledge, there is no previous study that i=1..lyiαiφ(oi)φ(o) + b = 0, where oi and o are clearly describes how dependency structures should two objects, φ is a mapping from the objects to feabe converted in trees to be fully and effectively ex- ture vectors ~xi and φ(oi)φ(o) = K(oi, o) is a kerploitable by convolution kernels. Indeed, although nel function implicitly defining such mapping. In the work in (Culotta and Sorensen, 2004) defines a case of structural kernels, K determines the shape of dependency tree also using node similarity, it is not the substructure</context>
<context position="9966" citStr="Moschitti, 2006" startWordPosition="1593" endWordPosition="1594">ifferent then OSTK(n1, n2) = 0; (ii) if the productions at n1 and n2 are the same, and n1 and n2 have only leaf children then OSTK(n1,n2) = A; and (iii) if the productions at n1 and n2 are the same, and n1 and n2 are not pre-terminals then OSTK(n1,n2) = A�l(n1) j=1 (1 + OSTK(cjn1,cjn2)), where l(n1) is the number of children of n1 and cjn is the j-th child of the node n. Note that, since the productions are the same, l(n1) = l(n2) and the computational complexity of STK is O(|NT1||NT2|) but the average running time tends to be linear, i.e. O(|NT1|+|NT2|), for natural language syntactic trees (Moschitti, 2006a). 2.2.2 The Partial Tree Kernel (PTK) The computation of PTK is carried out by the following OPTK function: if the labels of n1 and n2 are different then OPTK(n1,n2) = 0; else OPTK(n1, n2) = IOP T K(cn1(�I1j), cn2(�I2j)) 1To have a similarity score between 0 and 1, a normalization in the kernel space, i.e. T K(T1 ,T2) is applied. √T K (T1 ,T1) × T K (T2 ,T2 ) where d(I1) = I1l(~I1)− �I11+1 and d( �I2) = �I2l(~I2)− I21 + 1. This way, we penalize both larger trees and child subsequences with gaps. PTK is more general than the STK as if we only consider the contribution of shared subsequences c</context>
<context position="15963" citStr="Moschitti, 2006" startWordPosition="2650" endWordPosition="2651">d µ elevated to any power only depends on the target fragment. Thus, it just gives an additional weight to the fragment and does not violate the Mercer’s conditions. In contrast, the multiplication by σ(n1, n2) does depend on both comparing examples, i.e. on n1 and n2. However, if the matrix [σ(n1, n2)]bn1, n2 E f E T is positive semi-definite, a decomposition exists such that σ(n1, n2) = φ(n1)φ(n2) =:�, Aσ(n1, n2) can be written as���� i=1 φ(n1)χi(n1)φ(n2)χi(n2) = ���� i=1φσ(n1)φσ(n2) (see Section 2.2), which proves SPTK to be a valid kernel. 3.3 Efficient Evaluation We followed the idea in (Moschitti, 2006a) for efficiently computing SPTK. We consider Eq. 2 evaluated with respect to sequences of different length p; it follows that m A(n1, n2) = µσ(n1, n2)(λ2 + E Ap(cn1,cn2)), p=1 where Ap evaluates the number of common subtrees rooted in subsequences of exactly p children (of n1 and n2) and m = min{l(cn1), l(cn2)}. Given the two child sequences s1a = cn1 and s2b = cn2 (a and b are the last children) Ap(s1a, s2b) = A(a, b) x xAp−1(s1[1 : i],s2[1 : r]) where s1[1 : i] and s2[1 : r] are the child subsequences from 1 to i and from 1 to r of s1 and s2. If we name the double summation term as Dp, we </context>
<context position="18884" citStr="Moschitti, 2006" startWordPosition="3149" endWordPosition="3150">s of representation, i.e. structure, for syntactic dependency parses. At the same time, we compare with the constituency trees and different kernels to derive the best syntactic paradigm for convolution kernels. Most importantly, the role of lexical similarity embedded in syntactic structures will be investigated. For this purpose, we first carry out extensive experiments on coarse and fine grained QC and then we verify our findings on a completely different task, i.e. Argument Classification in SRL. 5.1 General experimental setup Tools: for SVM learning, we extended the SVMLightTK software3 (Moschitti, 2006a) (which in3http://disi.unitn.it/moschitti/Tree-Kernel.htm cludes structural kernels in SVMLight (Joachims, 2000)) with the smooth match between tree nodes. For generating constituency trees, we used the Charniak parser (Charniak, 2000) whereas we applied LTH syntactic parser (described in (Johansson and Nugues, 2008a)) to generate dependency trees. Lexical Similarity: we used the Eq. 1 with ω1 = ω2 = 1 and Q is derived with both approaches described in Sec. 2.3. The first approach is LSA-based: LSA was applied to ukWak (Baroni et al., 2009), which is a large scale document collection made by</context>
<context position="30511" citStr="Moschitti, 2006" startWordPosition="5124" endWordPosition="5125">on syntactic and lexical representations, SPTK will have a major impact in most of them, e.g.: 6Using one of the 8 processors of an Intel(R) Xeon(R) CPU E5430 @ 2.66GHz machine, 32Gb Ram. • Question Answering, the high results for QC will positively impact on the overall task. • SRL, SPTK alone reaches the state-of-the-art (SOA) (only 0.7% less) in FrameNet role classification. This is very valuable as previous work showed that tree kernels (TK) alone perform lower than models based on manually engineered features for SRL tasks, e.g., (Moschitti, 2004; Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti, 2006b; Che et al., 2006; Moschitti et al., 2008). Thus for the first time in an SRL task, a general tree kernel reaches the same accuracy of heavy manual feature design. This also suggests an improvement when used in combinations with manual feature vectors. • Relation Extraction and Pronominal Coreference, whose state-of-the-art for some tasks is achieved with the simple STK-CT (see (Zhang et al., 2006) and (Yang et al., 2006; Versley et al., 2008), respectively). • In word sense disambiguation tasks, SPTK can generalize context according to syntactic and semantic constraints (se</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006b. Making tree kernels practical for natural language learning. In Proccedings of EACL’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Mirella Lapata</author>
</authors>
<title>An Experimental Study of Graph Connectivity for Unsupervised Word Sense Disambiguation.</title>
<date>2010</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>32</volume>
<issue>4</issue>
<pages>692</pages>
<contexts>
<context position="2363" citStr="Navigli and Lapata, 2010" startWordPosition="345" endWordPosition="349">semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu</context>
</contexts>
<marker>Navigli, Lapata, 2010</marker>
<rawString>Roberto Navigli and Mirella Lapata. 2010. An Experimental Study of Graph Connectivity for Unsupervised Word Sense Disambiguation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(4):678– 692.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pado</author>
<author>Mirella Lapata</author>
</authors>
<title>Dependencybased construction of semantic space models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="11704" citStr="Pado and Lapata, 2007" startWordPosition="1898" endWordPosition="1901">5) defines their similarity as: K(d1, d2) = � (ω1ω2) X Q(w1, w2) (1) w1∈d1,w2∈d2 where ω1 and ω2 are the weights of the words (features) w1 and w2 in the documents d1 and d2, respectively, and Q is a term similarity function, e.g. (Pedersen et al., 2004b; Sahlgren, 2006; Corley and Mihalcea, 2005; Mihalcea et al., 2005). Technically, any Q can be used, provided that the resulting Gram matrix, G = K(d1, d2) bd1, d2 E D is positive semi-definite (Shawe-Taylor and Cristianini, 2004) (D is typically the training text set). We determine the term similarity function through distributional analysis (Pado and Lapata, 2007), according to the idea that the meaning of a word can be described by the set of textual contexts in which it appears (Distributional Hypothesis, (Harris, 1964)). The contexts are words appearing in a n-window with target words: such a space models a generic notion of semantic relatedness, i.e. two words close in the space are likely to be either in paradigmatic or syntagmatic relation as in (Sahlgren, 2006). The original word-by-word context matrix M is decomposed through Singular Value Decomposition (SVD) (Golub and Kahan, 1965) into the product of three new matrices: U, 5, and V so that 5 </context>
</contexts>
<marker>Pado, Lapata, 2007</marker>
<rawString>Sebastian Pado and Mirella Lapata. 2007. Dependencybased construction of semantic space models. Computational Linguistics, 33(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
</authors>
<title>User’s guide to sigf: Significance testing by approximate randomisation.</title>
<date>2006</date>
<marker>Pad´o, 2006</marker>
<rawString>Sebastian Pad´o, 2006. User’s guide to sigf: Significance testing by approximate randomisation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>WordNet::Similarity -Measuring the Relatedness of Concept.</title>
<date>2004</date>
<booktitle>In Proc. of 5th NAACL,</booktitle>
<location>Boston, MA.</location>
<contexts>
<context position="1620" citStr="Pedersen et al., 2004" startWordPosition="227" endWordPosition="230">ification confirms the benefit of semantic smoothing for dependency kernels. 1 Introduction A central topic in Natural Language Processing is the design of lexical and syntactic features suitable for the target application. The selection of effective patterns composed of syntactic dependencies and lexical constraints is typically a complex task. Additionally, the availability of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structu</context>
<context position="11335" citStr="Pedersen et al., 2004" startWordPosition="1841" endWordPosition="1844"> the largest subsequence of children that we want consider and ρ is the maximal outdegree observed in the two trees. However the average running time again tends to be linear for natural language syntactic trees (Moschitti, 2006a). 2.3 Lexical Semantic Kernel Given two text fragments d1 and d2 E D (the text fragment set), a general lexical kernel (Basili et al., 2005) defines their similarity as: K(d1, d2) = � (ω1ω2) X Q(w1, w2) (1) w1∈d1,w2∈d2 where ω1 and ω2 are the weights of the words (features) w1 and w2 in the documents d1 and d2, respectively, and Q is a term similarity function, e.g. (Pedersen et al., 2004b; Sahlgren, 2006; Corley and Mihalcea, 2005; Mihalcea et al., 2005). Technically, any Q can be used, provided that the resulting Gram matrix, G = K(d1, d2) bd1, d2 E D is positive semi-definite (Shawe-Taylor and Cristianini, 2004) (D is typically the training text set). We determine the term similarity function through distributional analysis (Pado and Lapata, 2007), according to the idea that the meaning of a word can be described by the set of textual contexts in which it appears (Distributional Hypothesis, (Harris, 1964)). The contexts are words appearing in a n-window with target words: s</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi. 2004a. WordNet::Similarity -Measuring the Relatedness of Concept. In Proc. of 5th NAACL, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>Wordnet::similarity - measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004: Demonstration Papers,</booktitle>
<volume>2</volume>
<pages>38--41</pages>
<location>Boston, Massachusetts, USA,</location>
<contexts>
<context position="1620" citStr="Pedersen et al., 2004" startWordPosition="227" endWordPosition="230">ification confirms the benefit of semantic smoothing for dependency kernels. 1 Introduction A central topic in Natural Language Processing is the design of lexical and syntactic features suitable for the target application. The selection of effective patterns composed of syntactic dependencies and lexical constraints is typically a complex task. Additionally, the availability of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structu</context>
<context position="11335" citStr="Pedersen et al., 2004" startWordPosition="1841" endWordPosition="1844"> the largest subsequence of children that we want consider and ρ is the maximal outdegree observed in the two trees. However the average running time again tends to be linear for natural language syntactic trees (Moschitti, 2006a). 2.3 Lexical Semantic Kernel Given two text fragments d1 and d2 E D (the text fragment set), a general lexical kernel (Basili et al., 2005) defines their similarity as: K(d1, d2) = � (ω1ω2) X Q(w1, w2) (1) w1∈d1,w2∈d2 where ω1 and ω2 are the weights of the words (features) w1 and w2 in the documents d1 and d2, respectively, and Q is a term similarity function, e.g. (Pedersen et al., 2004b; Sahlgren, 2006; Corley and Mihalcea, 2005; Mihalcea et al., 2005). Technically, any Q can be used, provided that the resulting Gram matrix, G = K(d1, d2) bd1, d2 E D is positive semi-definite (Shawe-Taylor and Cristianini, 2004) (D is typically the training text set). We determine the term similarity function through distributional analysis (Pado and Lapata, 2007), according to the idea that the meaning of a word can be described by the set of textual contexts in which it appears (Distributional Hypothesis, (Harris, 1964)). The contexts are words appearing in a n-window with target words: s</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi. 2004b. Wordnet::similarity - measuring the relatedness of concepts. In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004: Demonstration Papers, pages 38–41, Boston, Massachusetts, USA, May 2 - May 7. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity in a taxonomy. In</title>
<date>1995</date>
<booktitle>In Proceedings of the 14th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>448--453</pages>
<contexts>
<context position="1558" citStr="Resnik, 1995" startWordPosition="219" endWordPosition="220">r state-of-the-art. Additionally, semantic role classification confirms the benefit of semantic smoothing for dependency kernels. 1 Introduction A central topic in Natural Language Processing is the design of lexical and syntactic features suitable for the target application. The selection of effective patterns composed of syntactic dependencies and lexical constraints is typically a complex task. Additionally, the availability of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recen</context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Philip Resnik. 1995. Using information content to evaluate semantic similarity in a taxonomy. In In Proceedings of the 14th International Joint Conference on Artificial Intelligence, pages 448–453.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Sahlgren</author>
</authors>
<title>The Word-Space Model.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>Stockholm University.</institution>
<contexts>
<context position="11352" citStr="Sahlgren, 2006" startWordPosition="1845" endWordPosition="1846"> of children that we want consider and ρ is the maximal outdegree observed in the two trees. However the average running time again tends to be linear for natural language syntactic trees (Moschitti, 2006a). 2.3 Lexical Semantic Kernel Given two text fragments d1 and d2 E D (the text fragment set), a general lexical kernel (Basili et al., 2005) defines their similarity as: K(d1, d2) = � (ω1ω2) X Q(w1, w2) (1) w1∈d1,w2∈d2 where ω1 and ω2 are the weights of the words (features) w1 and w2 in the documents d1 and d2, respectively, and Q is a term similarity function, e.g. (Pedersen et al., 2004b; Sahlgren, 2006; Corley and Mihalcea, 2005; Mihalcea et al., 2005). Technically, any Q can be used, provided that the resulting Gram matrix, G = K(d1, d2) bd1, d2 E D is positive semi-definite (Shawe-Taylor and Cristianini, 2004) (D is typically the training text set). We determine the term similarity function through distributional analysis (Pado and Lapata, 2007), according to the idea that the meaning of a word can be described by the set of textual contexts in which it appears (Distributional Hypothesis, (Harris, 1964)). The contexts are words appearing in a n-window with target words: such a space model</context>
</contexts>
<marker>Sahlgren, 2006</marker>
<rawString>Magnus Sahlgren. 2006. The Word-Space Model. Ph.D. thesis, Stockholm University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Schtze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Journal of Computational Linguistics,</journal>
<volume>24</volume>
<pages>123</pages>
<contexts>
<context position="1597" citStr="Schtze, 1998" startWordPosition="225" endWordPosition="226">tic role classification confirms the benefit of semantic smoothing for dependency kernels. 1 Introduction A central topic in Natural Language Processing is the design of lexical and syntactic features suitable for the target application. The selection of effective patterns composed of syntactic dependencies and lexical constraints is typically a complex task. Additionally, the availability of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms t</context>
</contexts>
<marker>Schtze, 1998</marker>
<rawString>Hinrich Schtze. 1998. Automatic word sense discrimination. Journal of Computational Linguistics, 24:97– 123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
</authors>
<title>Kernel Methods for Pattern Analysis.</title>
<date>2004</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="5544" citStr="Shawe-Taylor and Cristianini, 2004" startWordPosition="838" endWordPosition="841">wo objects, φ is a mapping from the objects to feabe converted in trees to be fully and effectively ex- ture vectors ~xi and φ(oi)φ(o) = K(oi, o) is a kerploitable by convolution kernels. Indeed, although nel function implicitly defining such mapping. In the work in (Culotta and Sorensen, 2004) defines a case of structural kernels, K determines the shape of dependency tree also using node similarity, it is not the substructures describing the objects above. The a convolution kernel: this results in a much poorer most general kind of kernels used in NLP are string feature space. kernels, e.g. (Shawe-Taylor and Cristianini, 2004), In this paper, we propose a study of convolution the Syntactic Tree Kernels (Collins and Duffy, 2002) kernels for dependency structures aiming at jointly and the Partial Tree Kernels (Moschitti, 2006a). modeling syntactic and lexical semantic similarity. 2.1 String Kernels More precisely, we define several dependency trees The String Kernels (SK) that we consider count exploitable by the Partial Tree Kernel (PTK) (Mos- the number of subsequences shared by two strings chitti, 2006a) and compared them with STK over of symbols, s1 and s2. Some symbols during the constituency trees. Most importa</context>
<context position="7886" citStr="Shawe-Taylor and Cristianini, 2004" startWordPosition="1220" endWordPosition="1223">oting that: (a) longer subsequences dependency parsers are fully exploitable for feature receive lower weights; (b) some characters can be engineering based on structural kernels; (ii) SPTK omitted, i.e. gaps; (c) gaps determine a weight since outperforms any previous kernels achieving an un- the exponent of λ is the number of characters and precedented result of 41% of error reduction with re- gaps between the first and last character; and (c) spect to the former state-of-the-art on QC; and (iii) the complexity of the SK computation is O(mnp) the experiments on SRL confirm that the approach (Shawe-Taylor and Cristianini, 2004), where m and can be applied to different tasks without any tuning n are the lengths of the two strings, respectively and and again achieving state-of-the-art accuracy. p is the length of the largest subsequence we want to In the reminder of this paper, Section 2 provides consider. the background for structural and lexical similarity kernels. Section 3 introduces SPTK. Section 4 provides our representation models for dependency 1035 2.2 Tree Kernels Convolution Tree Kernels compute the number of common substructures between two trees T1 and T2 without explicitly considering the whole fragment </context>
<context position="11566" citStr="Shawe-Taylor and Cristianini, 2004" startWordPosition="1878" endWordPosition="1881">hitti, 2006a). 2.3 Lexical Semantic Kernel Given two text fragments d1 and d2 E D (the text fragment set), a general lexical kernel (Basili et al., 2005) defines their similarity as: K(d1, d2) = � (ω1ω2) X Q(w1, w2) (1) w1∈d1,w2∈d2 where ω1 and ω2 are the weights of the words (features) w1 and w2 in the documents d1 and d2, respectively, and Q is a term similarity function, e.g. (Pedersen et al., 2004b; Sahlgren, 2006; Corley and Mihalcea, 2005; Mihalcea et al., 2005). Technically, any Q can be used, provided that the resulting Gram matrix, G = K(d1, d2) bd1, d2 E D is positive semi-definite (Shawe-Taylor and Cristianini, 2004) (D is typically the training text set). We determine the term similarity function through distributional analysis (Pado and Lapata, 2007), according to the idea that the meaning of a word can be described by the set of textual contexts in which it appears (Distributional Hypothesis, (Harris, 1964)). The contexts are words appearing in a n-window with target words: such a space models a generic notion of semantic relatedness, i.e. two words close in the space are likely to be either in paradigmatic or syntagmatic relation as in (Sahlgren, 2006). The original word-by-word context matrix M is de</context>
</contexts>
<marker>Shawe-Taylor, Cristianini, 2004</marker>
<rawString>John Shawe-Taylor and Nello Cristianini. 2004. Kernel Methods for Pattern Analysis. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Anoop Sarkar</author>
<author>Aravind k Joshi</author>
</authors>
<title>Using LTAG Based Features in Parse Reranking.</title>
<date>2003</date>
<booktitle>In Empirical Methods for Natural Language Processing (EMNLP),</booktitle>
<pages>89--96</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="2864" citStr="Shen et al., 2003" startWordPosition="425" endWordPosition="428">h similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surfac</context>
</contexts>
<marker>Shen, Sarkar, Joshi, 2003</marker>
<rawString>Libin Shen, Anoop Sarkar, and Aravind k. Joshi. 2003. Using LTAG Based Features in Parse Reranking. In Empirical Methods for Natural Language Processing (EMNLP), pages 89–96, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georges Siolas</author>
<author>Florence d’Alch Buc</author>
</authors>
<title>Support vector machines based on a semantic kernel for text categorization.</title>
<date>2000</date>
<booktitle>In Proceedings of the IEEE-INNSENNS International Joint Conference on Neural Networks (IJCNN’00)-Volume 5,</booktitle>
<pages>5205</pages>
<publisher>IEEE Computer Society.</publisher>
<marker>Siolas, Buc, 2000</marker>
<rawString>Georges Siolas and Florence d’Alch Buc. 2000. Support vector machines based on a semantic kernel for text categorization. In Proceedings of the IEEE-INNSENNS International Joint Conference on Neural Networks (IJCNN’00)-Volume 5, page 5205. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>James Henderson</author>
</authors>
<title>Porting statistical parsers with data-defined kernels.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL-X.</booktitle>
<contexts>
<context position="2932" citStr="Titov and Henderson, 2006" startWordPosition="437" endWordPosition="440">; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms). This implies matching scores lower than 1, depending on th</context>
</contexts>
<marker>Titov, Henderson, 2006</marker>
<rawString>Ivan Titov and James Henderson. 2006. Porting statistical parsers with data-defined kernels. In Proceedings of CoNLL-X.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Penka Markova</author>
<author>Christopher Manning</author>
</authors>
<title>The Leaf Path Projection View of Parse Trees: Exploring String Kernels for HPSG Parse Selection.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="2845" citStr="Toutanova et al., 2004" startWordPosition="421" endWordPosition="424">, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they ha</context>
</contexts>
<marker>Toutanova, Markova, Manning, 2004</marker>
<rawString>Kristina Toutanova, Penka Markova, and Christopher Manning. 2004. The Leaf Path Projection View of Parse Trees: Exploring String Kernels for HPSG Parse Selection. In Proceedings of EMNLP 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Versley</author>
<author>Alessandro Moschitti</author>
<author>Massimo Poesio</author>
<author>Xiaofeng Yang</author>
</authors>
<title>Coreference systems based on kernels methods.</title>
<date>2008</date>
<booktitle>In The 22nd International Conference on Computational Linguistics (Coling’08),</booktitle>
<location>Manchester, England.</location>
<contexts>
<context position="30977" citStr="Versley et al., 2008" startWordPosition="5199" endWordPosition="5202">orm lower than models based on manually engineered features for SRL tasks, e.g., (Moschitti, 2004; Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti, 2006b; Che et al., 2006; Moschitti et al., 2008). Thus for the first time in an SRL task, a general tree kernel reaches the same accuracy of heavy manual feature design. This also suggests an improvement when used in combinations with manual feature vectors. • Relation Extraction and Pronominal Coreference, whose state-of-the-art for some tasks is achieved with the simple STK-CT (see (Zhang et al., 2006) and (Yang et al., 2006; Versley et al., 2008), respectively). • In word sense disambiguation tasks, SPTK can generalize context according to syntactic and semantic constraints (selectional restrictions) making very effective distributional semantic approaches. • In Opinion Mining SPTK will allow to match sentiment words within their corresponding syntactic counterparts and improve the stateof-the-art (Johansson and Moschitti, 2010b; Johansson and Moschitti, 2010a). • Experiments on Recognizing Textual Entailment (RTE) tasks, the use of SSTK (instead of STK-CT) improved the state-of-the-art (Mehdad et al., 2010). SPTK may provide further </context>
</contexts>
<marker>Versley, Moschitti, Poesio, Yang, 2008</marker>
<rawString>Yannick Versley, Alessandro Moschitti, Massimo Poesio, and Xiaofeng Yang. 2008. Coreference systems based on kernels methods. In The 22nd International Conference on Computational Linguistics (Coling’08), Manchester, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhibiao Wu</author>
<author>Martha Palmer</author>
</authors>
<title>Verb semantics and lexical selection.</title>
<date>1994</date>
<booktitle>In 32nd. Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<institution>New Mexico State University, Las Cruces,</institution>
<location>New Mexico.</location>
<contexts>
<context position="2012" citStr="Wu and Palmer, 1994" startWordPosition="291" endWordPosition="294">a is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or </context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Zhibiao Wu and Martha Palmer. 1994. Verb semantics and lexical selection. In 32nd. Annual Meeting of the Association for Computational Linguistics, pages 133 –138, New Mexico State University, Las Cruces, New Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaofeng Yang</author>
<author>Jian Su</author>
<author>Chewlim Tan</author>
</authors>
<title>Kernel-based pronoun resolution with structured syntactic knowledge.</title>
<date>2006</date>
<booktitle>In Proc. COLING-ACL 06.</booktitle>
<contexts>
<context position="30954" citStr="Yang et al., 2006" startWordPosition="5195" endWordPosition="5198">els (TK) alone perform lower than models based on manually engineered features for SRL tasks, e.g., (Moschitti, 2004; Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti, 2006b; Che et al., 2006; Moschitti et al., 2008). Thus for the first time in an SRL task, a general tree kernel reaches the same accuracy of heavy manual feature design. This also suggests an improvement when used in combinations with manual feature vectors. • Relation Extraction and Pronominal Coreference, whose state-of-the-art for some tasks is achieved with the simple STK-CT (see (Zhang et al., 2006) and (Yang et al., 2006; Versley et al., 2008), respectively). • In word sense disambiguation tasks, SPTK can generalize context according to syntactic and semantic constraints (selectional restrictions) making very effective distributional semantic approaches. • In Opinion Mining SPTK will allow to match sentiment words within their corresponding syntactic counterparts and improve the stateof-the-art (Johansson and Moschitti, 2010b; Johansson and Moschitti, 2010a). • Experiments on Recognizing Textual Entailment (RTE) tasks, the use of SSTK (instead of STK-CT) improved the state-of-the-art (Mehdad et al., 2010). SP</context>
</contexts>
<marker>Yang, Su, Tan, 2006</marker>
<rawString>Xiaofeng Yang, Jian Su, and Chewlim Tan. 2006. Kernel-based pronoun resolution with structured syntactic knowledge. In Proc. COLING-ACL 06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander S Yeh</author>
</authors>
<title>More accurate tests for the statistical significance of result differences.</title>
<date>2000</date>
<booktitle>In COLING,</booktitle>
<pages>947--953</pages>
<contexts>
<context position="20925" citStr="Yeh, 2000" startWordPosition="3490" endWordPosition="3491">ym for each model, we associate the latter with the name of the structure, i.e. this indicates that PTK is applied to it. Then the presence of the subscript WL and LSA indicates that SPTK is applied along with the corresponding similarity, e.g. LCTWL is the SPTK kernel applied to LCT structure, using WL similarity. We experiment with multi-classification, which we model through one-vs-all scheme by selecting the category associated with the maximum SVM margin. The quality of such classification is measured with accuracy. We determine the statistical signicance by using the model described in (Yeh, 2000) and implemented in (Pad´o, 2006). The parameterization of each classifier is carried on a held-out set (30% of the training) and concerns with the setting of the trade-off parameter (option - c) and the Leaf Weight (LeW) (see Sec. 5.2), which is used to linearly scale the contribution of the leaf nodes. In contrast, the cost-factor parameter of the SVM-LightTK is set as the ratio between the num1040 0 1000 2000 3000 4000 5000 Number of Examples 0 1000 2000 3000 4000 5000 Number of Examples Figure 10: Learning curves: comparison with similarity ber of negative and positive examples for attempt</context>
</contexts>
<marker>Yeh, 2000</marker>
<rawString>Alexander S. Yeh. 2000. More accurate tests for the statistical significance of result differences. In COLING, pages 947–953.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Zelenko</author>
<author>Chinatsu Aone</author>
<author>Anthony Richardella</author>
</authors>
<title>Kernel methods for relation extraction.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP-ACL,</booktitle>
<pages>181--201</pages>
<contexts>
<context position="2954" citStr="Zelenko et al., 2002" startWordPosition="441" endWordPosition="444">09; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms). This implies matching scores lower than 1, depending on the semantic similarity </context>
</contexts>
<marker>Zelenko, Aone, Richardella, 2002</marker>
<rawString>Dmitry Zelenko, Chinatsu Aone, and Anthony Richardella. 2002. Kernel methods for relation extraction. In Proceedings of EMNLP-ACL, pages 181–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dell Zhang</author>
<author>Wee Sun Lee</author>
</authors>
<title>Question classification using support vector machines.</title>
<date>2003</date>
<booktitle>In Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval,</booktitle>
<pages>26--32</pages>
<publisher>ACM Press.</publisher>
<contexts>
<context position="22728" citStr="Zhang and Lee, 2003" startWordPosition="3795" endWordPosition="3798">TK to the structures described in Sec. 4. The last two rows are: CT-STK, i.e. STK applied to a constituency tree and BOW, which is a linear ker4http://cogcomp.cs.illinois.edu/Data/QA/QC/ nel applied to lexical vectors. Column 2, 3 and 4 report the accuracy using no, LSA and WL similarity, where LeW is the amplifying parameter, i.e. a weight associated with the leaves in the tree. The last three columns refer to the fine grained task. It is worth nothing that when no similarity is applied: (i) BOW produces high accuracy, i.e. 88.8% but it is improved by STK (the current state-of-theart5 in QC (Zhang and Lee, 2003; Moschitti et al., 2007)); (ii) PTK applied to the same tree of STK produces a slightly lower value (non-statistically significant difference); (iii) interestingly, when PTK is instead applied to dependency structures, it improves STK, i.e. 91.60% vs 91.40% (although not significantly); and (iv) LCT, strongly based on lexical nodes, is the least accurate, i.e 90.80% since it is obviously subject to data sparseness (fragments only composed by lexicals are very sparse). The very important results can be noted when lexical similarity is used, i.e. SPTK is applied: (a) all the syntactic-base stru</context>
<context position="24217" citStr="Zhang and Lee, 2003" startWordPosition="4039" endWordPosition="4042">s accurate features. Indeed, when syntax is missing such as for the unstructured lexical path of LSTLSA, the accuracy does not highly improve or may also decrease. Additionally, the result of our best model is so high that its errors only refer to questions like What did Jesse Jackson organize ?, where the classifier selected Entity instead of Human category. These refer to clear cases where a huge amount of background knowledge is needed for deriving the exact solution. Finally, on the fine grained experiments LCT still produces the most accurate outcome again exceeding the state-of-the-art (Zhang and Lee, 2003), where WL significantly improves on all models (CT included). 5.3 Learning curves It is interesting to study the impact of syntactic/semantic kernels on the learning generalization. For this purpose, Fig. 9 reports the learning curve 5Note that in (Bloehdorn and Moschitti, 2007b), higher accuracy values for smoothed STK are shown for different parameters but the best according to a validation set is not highlighted. PCT LPST CT LOCT GRCT LCT BOW Figure 9: Learning curves: comparison with no similarity Accuracy 94% 92% 90% 88% 86% 84% 82% 80% PCT-WL LPST-WL CT-WL LOCT-WL GRCT-WL LCT-WL PCT Acc</context>
</contexts>
<marker>Zhang, Lee, 2003</marker>
<rawString>Dell Zhang and Wee Sun Lee. 2003. Question classification using support vector machines. In Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval, pages 26–32. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Jie Zhang</author>
<author>Jian Su</author>
</authors>
<title>Exploring Syntactic Features for Relation Extraction using a Convolution tree kernel.</title>
<date>2006</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="3001" citStr="Zhang et al., 2006" startWordPosition="449" endWordPosition="452">ious work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity). On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (Collins and Duffy, 2002; Kudo and Matsumoto, 2003; Cumby and Roth, 2003; Cancedda et al., 2003; Daum´e III and Marcu, 2004; Toutanova et al., 2004; Shen et al., 2003; Gliozzo et al., 2005; Kudo et al., 2005; Titov and Henderson, 2006; Zelenko et al., 2002; Bunescu and Mooney, 2005; Zhang et al., 2006). The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features. Most notably, the work in (Bloehdorn and Moschitti, 2007b) encodes lexical similarity in such kernels. This is essentially the syntactic tree kernel (STK) proposed in (Collins and Duffy, 2002) in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms). This implies matching scores lower than 1, depending on the semantic similarity of the corresponding leaves in the syntactic fr</context>
<context position="30931" citStr="Zhang et al., 2006" startWordPosition="5190" endWordPosition="5193">ork showed that tree kernels (TK) alone perform lower than models based on manually engineered features for SRL tasks, e.g., (Moschitti, 2004; Giuglea and Moschitti, 2004; Giuglea and Moschitti, 2006; Moschitti, 2006b; Che et al., 2006; Moschitti et al., 2008). Thus for the first time in an SRL task, a general tree kernel reaches the same accuracy of heavy manual feature design. This also suggests an improvement when used in combinations with manual feature vectors. • Relation Extraction and Pronominal Coreference, whose state-of-the-art for some tasks is achieved with the simple STK-CT (see (Zhang et al., 2006) and (Yang et al., 2006; Versley et al., 2008), respectively). • In word sense disambiguation tasks, SPTK can generalize context according to syntactic and semantic constraints (selectional restrictions) making very effective distributional semantic approaches. • In Opinion Mining SPTK will allow to match sentiment words within their corresponding syntactic counterparts and improve the stateof-the-art (Johansson and Moschitti, 2010b; Johansson and Moschitti, 2010a). • Experiments on Recognizing Textual Entailment (RTE) tasks, the use of SSTK (instead of STK-CT) improved the state-of-the-art (M</context>
</contexts>
<marker>Zhang, Zhang, Su, 2006</marker>
<rawString>Min Zhang, Jie Zhang, and Jian Su. 2006. Exploring Syntactic Features for Relation Extraction using a Convolution tree kernel. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peixiang Zhao</author>
<author>Jiawei Han</author>
<author>Yizhou Sun</author>
</authors>
<title>PRank: a comprehensive structural similarity measure over information networks.</title>
<date>2009</date>
<booktitle>In CIKM ’09: Proceeding of the 18th ACM conference on Information and knowledge management,</booktitle>
<pages>553--562</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1886" citStr="Zhao et al., 2009" startWordPosition="271" endWordPosition="274">of syntactic dependencies and lexical constraints is typically a complex task. Additionally, the availability of training data is usually scarce. This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in (Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Pedersen et al., 2004a; Bloehdorn and Moschitti, 2007b; Davis et al., 2007) or in semisupervised settings, e.g. (Chapelle et al., 2006). A semantic similarity can be defined at structural level over a graph, e.g. (Freeman, 1977; Bunke and Shearer, 1998; Brandes, 2001; Zhao et al., 2009), as well as combining structural and lexical similarity over semantic networks, e.g. (Cowie et al., 1992; Wu and Palmer, 1994; Resnik, 1995; Jiang and Conrath, 1997; Schtze, 1998; Leacock and Chodorow, 1998; Pedersen et al., 2004a; Budanitsky and Hirst, 2006). More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in (Mihalcea, 2005; Zhao et al., 2009; F¨urstenau and Lapata, 2009; Navigli and Lapata, 2010). On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic </context>
</contexts>
<marker>Zhao, Han, Sun, 2009</marker>
<rawString>Peixiang Zhao, Jiawei Han, and Yizhou Sun. 2009. PRank: a comprehensive structural similarity measure over information networks. In CIKM ’09: Proceeding of the 18th ACM conference on Information and knowledge management, pages 553–562, New York, NY, USA. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>